the developer-provided constraints. Furthermore, the devel-
oper can also specify in the synthesis script that a certain
1509Figure 2: High-level description of the Hamming, Euclidean and Manhattan distances.
implementation is preferred, or the implementation can be
explicitly called in the Verilog code.
In order for developers to use our synthetic libraries in-
stead of Designware to map to our customized circuits, they
have to decide for which metric to optimize: depth or size.
Accordingly, developers add the libraries’ paths and a single
command in the synthesis script to direct Synopsys DC to
optimize for either depth (for GMW) or size (for Yao), and to
prefer mapping to which set of circuit descriptions. If devel-
opers want to instantiate a speciﬁc circuit description from
our customized libraries, they can call it by the name of the
circuit module and deﬁning its input/output and parameters.
Optimization constraints are generally speciﬁed by the de-
veloper once for the entire top-level circuit description in the
synthesis script, while some sub-circuits require speciﬁc opti-
mization constraints. We already speciﬁed the optimization
constraints for our customized circuit building blocks.
3.2.4 Challenges of Logic Synthesis for Secure Com-
putation
Conventionally synthesis tools are best at synthesizing
sequential hardware circuits with a clock input and ﬂip-ﬂops.
This also means that the actual circuit netlists synthesized
are much more compact than combinational Boolean cir-
cuits. However, for the purpose of this work, the netlists
required are combinational to be evaluated with a secure
computation protocol in the ABY framework. This implies
synthesis of circuits which reach up to 10 million gates and
beyond, which is time- and resource-consuming for hardware
synthesis tools. In the hardware synthesis world, this can be
managed by generating sub-blocks in a hierarchical fashion,
and appending them into one top-level circuit.
However, in this work, one coherent Boolean netlist is
required for a single functionality, hence all sub-blocks of
a hierarchy must be un-grouped during synthesis, which is
resource consuming. We use workarounds to ease the memory
and resource requirements. However, this may come at the
expense of inter-block optimization across block boundaries,
but this can also be customized for individual synthesis
scenarios by enabling the boundary optimization option when
desired.
3.3 Scheduling
The output netlist generated from the hardware synthesis
tools has to be parsed in an intermediate step before being
provided to the ABY framework. A parser and scheduler
topologically sorts and schedules the netlist gates [KA99],
since the Verilog netlist output from some synthesis tools is
not topologically sorted, i.e., a wire can be listed as input
to one gate before assigning output to it from another. The
scheduler generates a Boolean netlist in a format which is
similar to Fairplay’s SHDL [MNPS04]. All gates and wires
are renamed to integer wire IDs for easier processing by the
ABY framework, and complex statements are rewritten as
one or several available gates. These steps ensure that the
ﬁnal netlist contains only AND, XOR, INV and MUX gates.
3.4 Extending the ABY Framework
The open-source ABY framework [DSZ15] is an extensive
tool that enables a developer to manually implement secure
two-party computation protocols by oﬀering several low-level
26-35: conditional statements mapped to multiplexers23,24: “sqr“operator is bound to LF-squarer in synthetic library description38: “ csn“ instantiated from synthetic library explicitly12: “reducing_xor“mapped to equivalent module in “func_global.v “ 14: “ boyar_counter“ instantiated from synthetic library explicitly12: “ +“mapped to LF-adder and “abs_diff“ function mapped to instantiate “abs_diff“ module in “func_global.v “ package file19,20: “ -“mapped to LF-subtractor1510as well as intermediate circuit building blocks that can be
freely combined. We extended the ABY framework with
an interface where externally constructed blocks made of
low-level gates can be input in a simple text format, similar
to SHDL [MNPS04] and the circuit format from [ST], that
we can parse as well, with some modiﬁcations.
This interface is used to input the parsed and scheduled
netlists from our hardware synthesis. ABY creates a Boolean
circuit with low depth from that input netlist, i.e. it schedules
AND gates on the earliest possible layer and automatically
processes all AND gates in one layer in parallel. A developer
has two options: 1) our hardware synthesized netlist can
be used as a full protocol instance from private inputs to
output or 2) the netlist’s functionality can be used as a
building block and combined with other synthesized or hand-
built sub-circuits within ABY in order to create the whole
secure computation protocol. The output of ABY is a fully
functional secure computation protocol that is split into setup
phase and online phase, that can be evaluated on two parties’
private inputs.
4. BULIDING BLOCKS LIBRARY
We implemented the following blocks in Verilog as pure
combinational circuits and synthesized their Boolean netlists
using both Synopsys DC and Yosys-ABC interchangeably to
show that the framework is independent of the used synthesis
tool. All implemented circuits have conﬁgurable parameters
such that they can handle the desired bit-width (cid:96) of the
inputs and/or number of inputs n. We summarize and
compare our synthesis results with their hand-optimized
counterparts in [HKS+10, HEK12, SZ13]. The two main
comparison metrics are size S which is the circuit size in terms
of non-free AND gates, and depth D which is the number of
AND gates along the critical path of the circuit. XOR gates
are considered to be free, as the GMW protocol and Yao’s
protocol with free XORs [KS08] allow to securely evaluate
XOR gates locally without any communication. Next we
show the results for functionalities that have improved depth
or size compared with their hand-optimized counterparts
in §4.1, and then in §4.2 we describe further functionalities
and blocks that we have implemented in our library which
show equivalent results as their hand-optimized counterparts.
Finally, in §4.3, we describe the ﬂoating-point operations and
integer division that we benchmark in §5.
4.1 Improved Functionalities
In this section, we present the implemented functionali-
ties that achieved better results in terms of size or depth
compared with [HKS+10, SZ13]. Results are given in Tab. 1.
Ladner-Fischer LF Adder/Subtractor. The LF adder/
subtractor has a logarithmic depth [LF80, SZ13]. Our results
show improvement for both depth (up to 10%) and size (up
to 14%) in the subtraction circuit, while maintaining the
same size and depth for addition of power-of-two numbers.
Both circuits can also handle numbers that are not powers-
of-two and achieve better size (up to 20%) as the hardware
synthesis tool automatically removes gates whose outputs
are neither used later as inputs to other gates nor assigned
directly to the output of the circuit.
Karatsuba Multiplier KMUL. We implemented a re-
cursive Karatsuba multiplier [KO62] using a ripple-carry
multiplier for inputs with bit-width (cid:96) < 20, while for (cid:96) ≥ 20
inputs are processed recursively. We compare our results with
numbers given in [HKS+10], which generated size-optimized
Boolean circuits for garbled circuits, but did not consider
circuit depth. Here we achieve up to 3% improvement in size.
Manhattan Distance DSTM. Manhattan distance is im-
plemented as a depth-optimized circuit using Ladner-Fischer
addition ADDLF and subtraction SUBLF or using ripple-
carry addition ADDRC and subtraction SUBRC for a size-
optimized circuit [CHK+12, SZ13]. Our results demonstrate
improvements in terms of size (up to 16%) and depth (up to
13.6%).
4.2 Further Functionalities
We list further functionalities that we implemented next.
Their circuit sizes and depths are equivalent to the hand-
optimized circuits in [HEK12, SZ13]: ripple-carry adder and
subtractor [BPP00, KSS09], n × (cid:96)-bit carry-save and ripple-
carry network adders [Sav97, SZ13], multipliers and squar-
ers [Sav97, KSS09, SZ13], depth-optimized multiplexer [KS08],
comparators (equal and greater than) [SZ13], full-adder [SZ13]
and Boyar-Peralta counters [BP06, SZ13], and the Sort-
Compare-Shuﬄe circuit for private set intersection (PSI)
[HEK12] and its building blocks (bitonic sorter, duplicate-
ﬁnding circuit, and Waksman permutation network [Wak68]).
Matrix Multiplication. We implemented a size-optimized
matrix multiplication circuit that computes one entry in the
resulting matrix by computing dot products. This circuit is
evaluated such that it computes the entries of the resulting
matrix in parallel. Thereby, we can exploit the capability of
the ABY framework to evaluate circuits in parallel, which
reduces the memory footprint of the implementation. The
circuit uses the Karatsuba multiplier and a ripple-carry net-
work adder. It is conﬁgurable, i.e., we can set the bit-width (cid:96)
and the number of elements per row or column n. The
depths and sizes of these circuits are given in Tab. 3 and
their performance is evaluated in §5.2.
4.3 Floating-Point Operations and Integer Di-
vision
We generated ﬂoating-point operations using the Design-
Ware library [Syn15], which is a set of building block IPs used
to implement, among other operations, ﬂoating-point com-
putational circuits for high-end ASICs. The library oﬀers a
suite of arithmetic and trigonometric operations, format con-
versions (integer to ﬂoating-point and vice versa) and compar-
ison functions. The provided functionalities are parametrized
allowing the developer to select the precision based on either
IEEE single or double precision or set a custom-precision
format. We can also enable the ieee_compliance parameter
when we need to guarantee IEEE compatible ﬂoating-point
numbers (”Not a Number” NaN and denormalized numbers).
Some functionalities provide an arch parameter which can
be set for either depth-optimized or size-optimized circuits.
Some of the ﬂoating-point functions provide a 3-bit op-
tional input round, to determine how the signiﬁcand should
be rounded, e.g. 000 rounds to the nearest even signiﬁcand
which is the IEEE default. They also have an 8-bit optional
output ﬂag status, in which bits indicate diﬀerent exceptions
of the performed operation allowing error detection. We can
choose to truncate or use these status bits as desired.
We generated circuits for ﬂoating-point addition, subtrac-
tion, squaring, multiplication, division, square root, sine,
1511cosine, comparison, exponentiation to base e, exponentiation
to base 2, natural logarithm (ln), and logarithm to base 2
for single precision, double precision and a custom 42-bit
precision format for comparison with [ABZS13]. The 42-bit
format consists of 32 bits for signiﬁcand, one bit for sign
and 9 bits for exponent distributed from MSB to LSB as
follows: sign [41], exponent [40:32] and signiﬁcand [31:0].
We extended the ABY framework with these ﬂoating-point
operations and benchmarked them. We give runtimes, depths
and sizes for various ﬂoating-point operations in §5.3.
We also generated circuits for integer division for diﬀerent
bit-widths (cid:96) ∈ {8, 16, 32, 64} using the built-in DesignWare
library [Syn15]. Another possibility for generating division
circuits is to use the division operator ‘/’ which will be
implicitly mapped to the built-in division module in that
library. As we optimize for depth our circuits have size
O((cid:96)2 log (cid:96)) ≈ 24 576 gates for (cid:96) = 64 but low depth 512. In
contrast, optimizing for size would yield better size O((cid:96)2) ≈
3(cid:96)2 = 12 288 gates (for ADD/SUB, CMP, and MUX), but
worse depth O((cid:96)2) = 4 096. We give circuit sizes and depths
for integer division in Tab. 2 and benchmarks in §5.1.
5. BENCHMARKS AND EVALUATION
We extended the ABY framework [DSZ15] to read in
the parsed and scheduled netlist generated by our hard-
ware synthesis tool and evaluate it with ABY’s optimized
implementations of the GMW protocol and Yao’s garbled
circuits (cf. §3.4). In contrast to TinyGarble [SHS+15], which
mainly focused on a memory-eﬃcient representation of the
circuits and gave only a single example for the time to se-
curely evaluate the circuit, we measure the total execution
times for several operations and applications: integer divi-
sion (§5.1), matrix multiplication (§5.2) and an extensive set
of ﬂoating-point operations (§5.3). For Yao’s protocol we
use today’s most eﬃcient garbling schemes implemented in
the ABY framework [DSZ15]: free XOR [KS08], ﬁxed-key
AES garbling with the AES-NI instruction set [BHKR13] and
half-gates [ZRE15]. For better comparability of the runtimes
we use depth-optimized circuits for both, GMW and Yao.
Compilation and synthesis times for the largest circuits
(FPEXP2, FPDIV) using Synopsys DC are under 1 hour on
a standard PC, but this is only a one-time expense, after
which the generated netlist can be re-used without incurring
compilation costs again.
We provide runtimes for the setup phase, which can be
pre-computed independently of the private inputs of the
participants and the online phase, which takes place after the
setup-phase is done and the inputs to the circuit are supplied
by both parties. All runtimes are median values of 10 protocol
runs. We measured runtimes on two desktop computers with
an Intel Core i7 CPU (3.5 GHz) and 16 GB RAM connected
via Gigabit-LAN. In all our experiments we set the symmetric
security parameter to 128 bits.
5.1 Benchmarks for Integer Division
A complex operation that is not trivially implementable
by hand is integer division, as described in §4.3. In Tab. 2
we list the runtime, split in pre-computation phase and
online phase and list the circuit parameters for multiple input
sizes. We compare our runtime with the runtime prediction
of 32-bit integer long division of [KSS13] which we speed
up by a factor of 32 and even more for Single Instruction
Multiple Data (SIMD) evaluation. We also compare with the
runtime of 3-party 64-bit integer division of [ABZS13], which
outperforms our single evaluation with GMW by a factor
of 1.8. However, for parallel SIMD evaluation we improve
upon their runtime by up to factor 3.7. When comparing to
the 3-party 32-bit integer division of [BNTW12], we achieve
a speedup of 6.5 for single execution, while we require more
than 5 times the runtime for 10 000 parallel executions.
5.2 Benchmarks for Matrix Multiplication
Matrix multiplication of integer values is an important use
case in many applications. Here we exploit ABY’s ability to
evaluate circuits in parallel in a SIMD fashion and instantiate
dot product computation blocks, each of which calculates
a single entry in the result matrix. In Tab. 3 we give the
runtimes for dot product computations of 16 values of 16 bit
each or 32 values of 32 bit each, as described in §4.2. We
compare with the 3-party secret-sharing based implementa-
tions of [BNTW12, ZSB13] as well as the 2-party arithmetic-
sharing implementation of the ABY framework [DSZ15]. For
this comparison we use the values reported in the respective
papers and interpolate them to our parameters.
The secret-sharing or artihmetic-sharing based solutions
outperform our Boolean Circuits by several orders of magni-
tude due to their much faster methods for multiplication.
5.3 Benchmarks for Floating-Point Operations
There is a multitude of use cases for ﬂoating-point opera-
tions in academia and industry, ranging from signal process-
ing to data mining, but due to the complexity of the format
it has only recently been considered as application for secure
computation [FK11]. Until today there are only few actual
implementations of ﬂoating-point arithmetic in secure com-
putation, all of which use custom-built protocols [ABZS13,
KW14]. Instead, we use multiple standard ﬂoating-point
building blocks oﬀered by Synopsys DC and synthesize them
automatically (cf. §4.3). Tab. 4 depicts the runtime in ms
per single ﬂoating-point operation, when run once or multiple
times in parallel using a SIMD approach. We compare our
results for Yao and GMW with hand-optimized ﬂoating-point
protocols of [ABZS13], who used a 3-party secret sharing
approach with security against semi-honest adversaries and
desktop computers connected on a Gigabit-LAN for their
measurements. The largest runtime improvements can be
achieved when evaluating our generated circuits in parallel.
We improve the runtime by up to a factor of 21 for parallel
evaluation and show similar or somewhat improved runtimes
for the lower parallelism levels reported. We can improve
upon many results of [KW14] which is in the 3-party set-
ting, except for highly parallel multiplication. We show that
our automatically generated circuits are able to outperform
hand-crafted circuits in many cases, especially for high de-
grees of parallelism. We give an application for ﬂoating-point
arithmetic in §6.
5.4 Benchmark Evaluation
In general, when comparing the implementations of Yao
and GMW in the ABY framework, we show that Yao out-
performs GMW in most cases but scales much worse, up
to a point where the largest circuits cannot be evaluated
in parallel, due to the high memory consumption of Yao’s
protocol. GMW remains beneﬁcial for highly parallel proto-
col evaluation, as the more critical online time scales almost
1512Table 1: Synthesis results of improved functionalities compared to hand-optimized circuits for inputs of
bit-width (cid:96): Ladner-Fischer ADDLF /SUBLF , Karatsuba multiplication KMUL, Manhattan Distance DSTM.
Circuit
Size S
Hand-optimized Ours
Improvement Hand-optimized Ours
Improvement
Depth-Optimized
Depth D
ADDLF ((cid:96) = 20)
ADDLF ((cid:96) = 30)
ADDLF ((cid:96) = 40)
SUBLF ((cid:96) = 16)
SUBLF ((cid:96) = 32)
SUBLF ((cid:96) = 64)
DSTM ((cid:96) = 16)
DSTM ((cid:96) = 32)
DSTM ((cid:96) = 64)
KMUL ((cid:96) = 32)
KMUL ((cid:96) = 64)
KMUL ((cid:96) = 128)
DSTM ((cid:96) = 16)
DSTM ((cid:96) = 32)
DSTM ((cid:96) = 64)
151
226
361
113
273
641
353
825
1 889
121
214
301
97
241
577
296
741
1 778
1 729
5 683
17 972
65
129
257
1 697
5 520
17 430
65
129
257
20%
5%
16.6%
14%
11%
10%