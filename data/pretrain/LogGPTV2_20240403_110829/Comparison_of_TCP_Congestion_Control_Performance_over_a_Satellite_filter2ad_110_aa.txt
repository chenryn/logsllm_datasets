# Title: Comparison of TCP Congestion Control Performance over a Satellite Network

## Authors:
- Saahil Claypool
- Jae Chung
- Mark Claypool

### Abstract
Despite the increase in satellite Internet bitrates, latency remains a significant factor in degrading TCP performance. Realistic assessments of TCP over satellite networks are often limited to simulations or emulations. This paper presents an experimental comparison of four TCP congestion control algorithms—BBR, Cubic, Hybla, and PCC—on a commercial satellite network. The analysis reveals that all algorithms achieve similar steady-state bitrates, but there are notable differences in start-up throughputs and round-trip times due to packet queuing. A power analysis combining throughput and latency shows that PCC is the most effective during steady state, owing to its high throughputs and consistent, low round-trip times. For small downloads, Hybla is the most effective, thanks to its rapid throughput ramp-ups. BBR generally performs similarly to Cubic in both scenarios.

### 1. Introduction
Satellites play a crucial role in modern networking by providing ubiquitous connectivity, even in disaster-prone areas. As of 2019, the number of satellites in orbit has increased by 67% since 2014, with over 2100 satellites currently in use [2]. Advances in satellite technology have led to transmission capacities increasing more than 20x, with planned Geosynchronous orbit (GEO) satellites expected to offer a total capacity of over 5 Tb/s.

GEO satellites typically introduce about 300 milliseconds of latency for signal round-trips [8], which poses a challenge for TCP protocols that rely on round-trip time (RTT) for data window advancement. TCP congestion control algorithms are essential for maintaining throughput in the presence of network latency and loss. To better support TCP over satellite networks, a deeper understanding of the performance of these algorithms is necessary.

However, few studies have measured TCP performance over actual satellite networks [17]. Most existing research relies on simulations [3] or emulations with satellite parameters [1, 11, 18, 19].

This paper presents results from experiments conducted on a commercial satellite Internet network, comparing the performance of four TCP congestion control algorithms: default loss-based Cubic [15], bandwidth-delay product-based BBR [16], utility function-based PCC [11], and satellite-optimized Hybla [4]. Our methodology involves interlacing runs of each protocol serially to minimize temporal differences and conducting 80 bulk downloads for each protocol to ensure a large sample size. Additionally, a custom ping application provides several days of RTT and packet loss data for a baseline satellite network with no other traffic.

### 2. Related Work
**TCP Hybla** [4]: Proposed by Caini and Firrini, TCP Hybla addresses the limitations of TCP NewReno over high-latency links, such as satellite connections. It modifies the standard congestion window (cwnd) increase based on the RTT. In the slow-start phase, \( cwnd = cwnd + 2\rho - 1 \), and in the congestion avoidance phase, \( cwnd = cwnd + \frac{\rho^2}{cwnd} \), where \( \rho = \frac{RTT}{RTT_0} \) and \( RTT_0 \) is fixed at 0.025 s. Hybla has been available in Linux kernels since version 2.6.11 (2005).

**TCP Cubic** [15]: Developed by Ha et al., TCP Cubic is an incremental improvement over earlier congestion control algorithms. It is less aggressive in most steady-state cases but can quickly probe for more bandwidth when needed. TCP Cubic has been the default in Linux since kernel 2.6.19 (2007), Windows 10.1709 Fall Creators Update (2017), and Windows Server 2016 1709 update (2017).

**TCP BBR** [16]: Introduced by Cardwell et al., TCP BBR uses the maximum observed bandwidth and minimum RTT to set the congestion window size, up to twice the bandwidth-delay product. BBR has been deployed by Google servers since 2017 and is available in Linux kernels since version 4.9 (end of 2016).

**TCP PCC** [11]: Proposed by Dong et al., TCP PCC observes performance through small measurement "experiments" and adopts the rate with the best utility, based on throughput, loss, and RTT. PCC is not generally available for Linux, but we used a Linux-based implementation provided by Compira Labs [1].

Cao et al. [5] analyzed BBR and Cubic under various network conditions, showing that the relative difference between the bottleneck buffer size and bandwidth-delay product influences BBR's performance. Our work extends this by evaluating Cubic and BBR in a satellite configuration with significantly higher RTTs.

Obata et al. [17] evaluated TCP performance over actual satellite networks, comparing a satellite-oriented TCP congestion control algorithm (STAR) with NewReno and Hybla. Their experiments with the WINDS network showed throughputs around 26 Mb/s and RTTs around 860 ms. Both STAR and Hybla outperformed NewReno, but no public Linux implementation of STAR is available.

Wang et al. [19] provided a preliminary evaluation of QUIC with BBR on an emulated satellite network, confirming that BBR offers throughput improvements over TCP Cubic.

Utsumi et al. [18] developed an analytic model for TCP Hybla, verifying its accuracy with simulated and emulated satellite links. Their analysis showed substantial throughput improvements over TCP Reno for loss rates above 0.0001%.

Our work extends these studies by providing a comparative performance analysis of four TCP congestion control algorithms on an actual, commercial satellite network.

### 3. Methodology
We set up a testbed, measured baseline network loss and RTTs, performed bulk downloads using each algorithm, and analyzed the results.

#### 3.1 Testbed
We configured a Viasat satellite Internet link to represent a client with a "last mile" satellite connection. Our testbed, depicted in Figure 1, includes a client PC and four servers, each running a different TCP congestion control algorithm: BBR, Cubic, Hybla, and PCC.

- **Client**: A Linux PC with an Intel i7-1065G7 CPU @ 1.30 GHz and 32 GB RAM.
- **Servers**: Each server has an Intel Ken E312xx CPU @ 2.5 GHz and 32 GB RAM, running Ubuntu 18.04.4 LTS with Linux kernel version 4.15.0.
- **Network Configuration**: The servers connect to our University LAN via Gb/s Ethernet, and the campus network is connected to the Internet via several 10 Gb/s links, throttled to 1 Gb/s. Wireshark captures all packet header data on each server and the client.
- **Viasat Terminal**: The client connects to a Viasat satellite terminal via Gb/s Ethernet, with a peak downstream data rate of 144 Mb/s. The terminal communicates through a Ka-band outdoor antenna and supports adaptive coding and modulation.
- **Queue Management**: The Viasat gateway performs per-client queue management, with a maximum queuing delay of about 2 s at the peak data rate. Active Queue Management (AQM) randomly drops 25% of incoming packets when the queue exceeds half the limit (18 MBytes).
- **Performance Enhancing Proxy (PEP)**: The default PEP is disabled for all experiments to assess congestion control performance independently.

#### 3.2 Baseline
For the network baseline, we ran a UDP Ping from a server to the client continuously for one week. This sends one 20-byte UDP packet every 200 ms, recording the RTT and packet loss. Using UDP avoids any special treatments routers may apply to ICMP packets.

#### 3.3 Downloads
We compared the performance of four congestion control algorithms: loss-based Cubic, bandwidth-delay product-based BBR (version 1), satellite-optimized Hybla, and utility function-based PCC. The servers were configured to provide bulk downloads via iperf3 (v3.3.1). PCC was configured with the Vivace-Latency utility function, with coefficients for throughput, loss, and RTT set to 1, 10, and 2, respectively.

The client initiated a connection to one server, downloaded 1 GByte, and then immediately proceeded to the next server. After cycling through each server, the client paused for 1 minute. This process was repeated 80 times, providing 80 network traces for each protocol over the satellite link. The entire throughput test ran for about a day.

### 4. Analysis
#### 4.1 Network Baseline
We analyzed the network baseline loss and RTTs obtained on a "quiet" satellite link. Table 3 provides summary statistics.

- **RTT Distribution**: 99% of RTTs are between 560 and 625 ms (median 597 ms, mean 597.5 ms, std dev 16.9 ms).
- **Heavy-Tailed Tendency**: 0.1% of RTTs range from 625 ms to 1500 ms, and 0.001% range from 1700 to 2200 ms, indicating multi-second RTTs.

These high values highlight the variability and challenges in satellite communication.