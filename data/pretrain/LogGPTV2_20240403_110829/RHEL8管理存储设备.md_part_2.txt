    存储管理指南](https://access.redhat.com/documentation/en-us/red_hat_gluster_storage/3.4/html-single/administration_guide/index#part-Overview){.link}
:::
:::
::: section
::: titlepage
# []{#available-storage-options-overview_managing-storage-devices.html#ceph-storage-overview_overview-of-available-storage-options}Ceph 存储概述 {.title}
:::
红帽 Ceph
存储(RHCS)是一款可扩展、开放、软件定义型存储平台，它将最稳定版本的 Ceph
存储系统与 Ceph 管理平台、部署实用程序和支持服务相结合。
红帽 Ceph 存储专为云基础架构和 Web 规模对象存储而设计。Red Hat Ceph
Storage 集群由以下类型的节点组成：
::: variablelist
[Red Hat Ceph Storage Ansible 管理节点]{.term}
:   此类节点充当之前版本的红帽 Ceph 存储的传统 Ceph
    管理节点。这种类型的节点提供以下功能：
    ::: itemizedlist
    -   集中存储集群管理
    -   Ceph 配置文件和密钥
    -   （可选）用于在因为安全原因无法访问互联网的节点上安装 Ceph
        的本地存储库
    :::
[监控节点]{.term}
:   每个监控器节点都运行 monitor
    守护进程(`ceph-mon`{.literal})，守护进程维护集群映射的副本。集群映射包含集群拓扑。连接
    Ceph 集群的客户端从 monitor 中检索 cluster map
    的当前副本，使客户端能够从集群读取和写入数据。
    ::: {.important style="margin-left: 0.5in; margin-right: 0.5in;"}
    ### 重要 {.title}
    Ceph
    可以使用一个监控器运行；但是，为了保证生产集群中的高可用性，红帽将仅支持具有至少三个
    monitor 节点的部署。红帽建议为超过 750 OSD 的存储集群部署总计 5 个
    Ceph Monitor。
    :::
[OSD 节点]{.term}
:   每个对象存储设备(OSD)节点都运行 Ceph OSD
    守护进程(`ceph-osd`{.literal})，它与附加到节点的逻辑磁盘交互。Ceph
    在这些 OSD 节点上存储数据。
    Ceph 可在只有很少 OSD
    节点的环境中运行，默认为三个。但对于生产环境，自中等范围环境开始（例如，在一个存储集群中包括
    50 个 OSD）才可能看到其在性能方面的优势。理想情况下，Ceph
    集群具有多个 OSD 节点，通过创建 CRUSH map 来允许隔离的故障域。
[MDS 节点]{.term}
:   每个元数据服务器(MDS)节点运行 MDS
    守护进程(`ceph-mds`{.literal})，它管理与 Ceph
    文件系统(CephFS)中存储的文件相关的元数据。MDS
    守护进程也协调对共享集群的访问。
[对象网关节点]{.term}
:   Ceph 对象网关节点运行 Ceph RADOS
    网关守护进程(`ceph-radosgw`{.literal})，它是基于
    `librados`{.literal} 构建的对象存储接口，为应用提供 Ceph 存储集群的
    RESTful 网关。Ceph 对象网关支持两个接口：
[S3]{.term}
:   通过与 Amazon S3 RESTful API 的大子集兼容的接口提供对象存储功能。
[Swift]{.term}
:   通过与 OpenStack Swift API 的大集兼容的接口提供对象存储功能。
:::
::: itemizedlist
**其它资源**
-   [Red Hat Ceph
    Storage](https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/4/){.link}
:::
:::
:::
[]{#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html}
::: chapter
::: titlepage
# []{#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#managing-local-storage-using-rhel-system-roles_managing-storage-devices}第 2 章 使用 RHEL 系统角色管理本地存储 {.title}
:::
要使用 Ansible 管理 LVM 和本地文件系统(FS)，您可以使用
`storage`{.literal} 角色，这是 RHEL 8 中可用的 RHEL 系统角色之一。
使用 `storage`{.literal} 角色可让您从 RHEL 7.7
开始，在多个机器和逻辑卷中自动管理磁盘和逻辑卷中的文件系统。
有关 RHEL 系统角色以及如何应用它们的更多信息，请参阅 [RHEL
系统角色简介](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_basic_system_settings/getting-started-with-system-administration_configuring-basic-system-settings#intro-to-rhel-system-roles_getting-started-with-rhel-system-roles){.link}。
::: section
::: titlepage
# []{#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#storage-role-intro_managing-local-storage-using-rhel-system-roles}存储角色简介 {.title}
:::
`storage`{.literal} 角色可以管理：
::: itemizedlist
-   磁盘上未被分区的文件系统
-   完整的 LVM 卷组，包括其逻辑卷和文件系统
:::
使用 `storage`{.literal} 角色，您可以执行以下任务：
::: itemizedlist
-   创建文件系统
-   删除文件系统
-   挂载文件系统
-   卸载文件系统
-   创建 LVM 卷组
-   删除 LVM 卷组
-   创建逻辑卷
-   删除逻辑卷
-   创建 RAID 卷
-   删除 RAID 卷
-   创建带有 RAID 的 LVM 池
-   删除带有 RAID 的 LVM 池
:::
:::
::: section
::: titlepage
# []{#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#parameters-that-identify-a-storage-device-in-the-storage-system-role_managing-local-storage-using-rhel-system-roles}在存储设备角色中识别存储设备的参数 {.title}
:::
您的 `storage`{.literal}
角色配置只会影响您在以下变量中列出的文件系统、卷和池。
::: variablelist
[`storage_volumes`{.literal}]{.term}
:   在所有要管理的未分区磁盘中的文件系统列表。
    当前不支持的分区。
[`storage_pools`{.literal}]{.term}
:   要管理的池列表。
    目前唯一支持的池类型是 LVM。使用 LVM
    时，池代表卷组（VG）。每个池中都有一个要由角色管理的卷列表。对于
    LVM，每个卷对应一个带文件系统的逻辑卷（LV）。
:::
:::
::: section
::: titlepage
# []{#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#an-example-ansible-playbook-to-create-an-xfs-file-system_managing-local-storage-using-rhel-system-roles}在块设备中创建 XFS 文件系统的 Ansible playbook 示例 {.title}
:::
本节提供了一个 Ansible playbook 示例。此 playbook 应用
`storage`{.literal} 角色，以使用默认参数在块设备中创建 XFS 文件系统。
::: {.warning style="margin-left: 0.5in; margin-right: 0.5in;"}
### 警告 {.title}
`storage`{.literal}
角色只能在未分区、整个磁盘或者逻辑卷(LV)中创建文件系统。它不能在分区中创建文件系统。
:::
::: example
[]{#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#idm140531403085136}
**例 2.1. 在 /dev/sdb 上创建 XFS 的 playbook**
::: example-contents
``` screen
---
- hosts: all
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
          - sdb
        fs_type: xfs
  roles:
    - rhel-system-roles.storage
```
::: itemizedlist
-   卷名称（示例中是 `barefs`{.literal}
    ）目前是任意卷。`storage`{.literal} 角色根据在 `disks:`{.literal}
    属性中列出的磁盘设备识别卷。
-   您可以省略 `fs_type: xfs`{.literal} 行，因为 XFS 是 RHEL 8
    中的默认文件系统。
-   要在 LV 中创建文件系统，在 `disks:`{.literal} 属性中提供 LVM
    设置，包括保护卷组。详情请参阅 [管理逻辑卷的 Ansible playbook
    示例](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_logical_volumes/assembly_configuring-lvm-volumes-configuring-and-managing-logical-volumes#an-example-playbook-to-manage-logical-volumes_managing-lvm-logical-volumes-using-rhel-system-roles){.link}。
    不要提供到 LV 设备的路径。
:::
:::
:::
::: itemizedlist
**其它资源**
-   有关 `storage`{.literal} 系统角色中使用的参数的详情，请查看
    `/usr/share/ansible/roles/rhel-system-roles.storage/README.md`{.literal}
    文件。
:::
:::
::: section
::: titlepage
# []{#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#an-example-ansible-playbook-to-persistently-mount-a-file-system_managing-local-storage-using-rhel-system-roles}永久挂载文件系统的 Ansible playbook 示例 {.title}
:::
本节提供了一个 Ansible playbook 示例。此 playbook 应用
`storage`{.literal} 角色来立即和永久挂载 XFS 文件系统。
::: example
[]{#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#idm140531403067408}
**例 2.2. 在 /dev/sdb 上将文件系统挂载到 /mnt/data 的 playbook**
::: example-contents
``` screen
---
- hosts: all
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
          - sdb
        fs_type: xfs
        mount_point: /mnt/data
  roles:
    - rhel-system-roles.storage
```
::: itemizedlist
-   此 playbook 将文件系统添加到 `/etc/fstab`{.literal}
    文件中，并立即挂载文件系统。
-   如果 `/dev/sdb`{.literal} 设备或挂载点目录中的文件系统不存在，则
    playbook 会创建它们。
:::
:::
:::
::: itemizedlist
**其它资源**
-   有关 `storage`{.literal} 系统角色中使用的参数的详情，请查看
    `/usr/share/ansible/roles/rhel-system-roles.storage/README.md`{.literal}
    文件。
:::
:::
::: section
::: titlepage
# []{#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#an-example-playbook-to-manage-logical-volumes_managing-local-storage-using-rhel-system-roles}管理逻辑卷的 Ansible playbook 示例 {.title}
:::
本节提供了一个 Ansible playbook 示例。这个 playbook 应用
`storage`{.literal} 角色在卷组中创建 LVM 逻辑卷。
::: example
[]{#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#idm140531403051632}
**例 2.3. 在 myvg 卷组中创建 mylv 逻辑卷的 playbook**
::: example-contents
``` screen
- hosts: all
  vars:
    storage_pools:
      - name: myvg
        disks:
          - sda
          - sdb
          - sdc
        volumes:
          - name: mylv
            size: 2G
            fs_type: ext4
            mount_point: /mnt
  roles:
    - rhel-system-roles.storage
```
::: itemizedlist
-   `myvg`{.literal} 卷组由以下磁盘组成：
    ::: itemizedlist
    -   `/dev/sda`{.literal}
    -   `/dev/sdb`{.literal}
    -   `/dev/sdc`{.literal}
    :::
-   如果 `myvg`{.literal} 卷组已存在，则 playbook
    会将逻辑卷添加到卷组中。
-   如果 `myvg`{.literal} 卷组不存在，则 playbook 会创建它。
-   playbook 在 `mylv`{.literal} 逻辑卷中创建 Ext4
    文件系统，并在其中永久挂载文件系统 `/mnt`{.literal}。
:::
:::
:::
::: itemizedlist
**其它资源**
-   有关 `storage`{.literal} 系统角色中使用的参数的详情，请查看
    `/usr/share/ansible/roles/rhel-system-roles.storage/README.md`{.literal}
    文件。
:::
:::
::: section
::: titlepage
# []{#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#an-example-ansible-playbook-to-enable-online-block-discard_managing-local-storage-using-rhel-system-roles}启用在线块丢弃的 Ansible playbook 示例 {.title}
:::
本节提供了一个 Ansible playbook 示例。此 playbook 应用
`storage`{.literal} 角色来挂载启用了在线块丢弃的 XFS 文件系统。
::: example
[]{#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#idm140531403024240}
**例 2.4. 一个 playbook，它在 /mnt/data/ 上启用在线块丢弃功能**
::: example-contents
``` screen
---
- hosts: all
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
          - sdb
        fs_type: xfs
        mount_point: /mnt/data
        mount_options: discard
  roles:
    - rhel-system-roles.storage
```
:::
:::
::: itemizedlist
**其它资源**
-   此 playbook 还执行 ["永久挂载文件系统的 Ansible playbook
    示例"一节](#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#an-example-ansible-playbook-to-persistently-mount-a-file-system_managing-local-storage-using-rhel-system-roles "永久挂载文件系统的 Ansible playbook 示例"){.xref}
    中描述的持久挂载示例的所有操作。