use transcripts to replay the trace, once in plaintext and once
through a VPN tunnel. Replay server records packet traces for
each replay. (d) Analyzer uses the traces to detect diﬀerentiation.
do not support detecting diﬀerentiation based on the desti-
nation IP address contacted by clients. Our analysis of com-
mercially deployed traﬃc shapers indicates that IP addresses
are not commonly used to identify applications, since none
of our observed conﬁgurations use them for shaping. We
speculate this is due to the fact that many applications con-
tact servers with IPs shared by many services (e.g., EC2,
or Google frontends that serve both search and YouTube
traﬃc), and the IPs used by any service may change over
time. Thus, IP addresses are a poor classiﬁer for shaping a
speciﬁc application. Regardless, we are investigating how to
use limited forms of IP spooﬁng to address this limitation.
3. METHODOLOGY
We use a trace record-replay methodology to reliably
detect traﬃc diﬀerentiation for arbitrary applications in
the mobile environment. We provide an overview in Fig-
ure 1. We record a packet trace from a target application
(Fig. 1(a)), extract bidirectional application-layer payloads,
and use this to generate a transcript of messages for the
client and server to replay (Fig. 1(b)). To test for diﬀerenti-
ation, the client and server coordinate to replay these tran-
scripts, both in plaintext and through an encrypted channel
(using a VPN tunnel) where payloads are hidden from any
shapers on the path (Fig. 1(c)). Finally, we use validated
statistical tests to identify whether the application traﬃc
being tested was subject to diﬀerentiation (Fig. 1(d)). We
discuss each of these steps below.
2413.1 Recording the trace
Our method requires a packet trace to replay. While it
is straightforward to gather one on desktop operating sys-
tems, recording packet traces on today’s mobile operating
systems requires “rooting” and/or “jailbreaking” the phone
(potentially voiding the phone’s warranty). This is not
a problem for small-scale testbed experiments, but traﬃc
diﬀerentiation—and the applications it aﬀects—is a mov-
ing target that requires running experiments for a variety of
applications on a large set of devices in diﬀerent networks
worldwide. Thus, we need a way to enable end users to cap-
ture traces of mobile application traﬃc without requiring
modiﬁcations to the OS.
To address this challenge, we leverage the fact that all
major mobile operating systems natively support VPN con-
nections, and use the Meddle VPN [22] to facilitate trace
recording. Figure 1(a) illustrates how a client connects to
the Meddle VPN, which relays traﬃc between the client and
destination server(s). In addition, the Meddle VPN collects
packet traces that we use to generate replay transcripts.
When possible, we record traﬃc using the same network
being tested for diﬀerentiation because applications may be-
have diﬀerently based on the network type, e.g., a streaming
video app may select a higher bitrate on WiFi.
Our methodology is extensible to arbitrary applications—
even closed source and proprietary ones—to ensure it works
even as the landscape of popular applications, the network
protocols they use, and their impact on mobile network re-
sources changes over time. Prior work focused on speciﬁc
applications (e.g., BitTorrent [6]) and manually emulated
application ﬂows. This approach, however, does not scale
to large numbers of applications and may even be infeasible
when the target application uses proprietary, or otherwise
closed, protocols.2
3.2 Creating the replay script
After recording a packet trace, our system processes it to
extract the application-layer payloads as client-to-server and
server-to-client byte streams. We then create a replay tran-
script that captures the behavior of the application’s traﬃc,
including port numbers, dependencies between application-
layer messages (if they exist) and any timing properties of
the application (e.g., ﬁxed-rate multimedia).3 Finally, we
use each endpoint’s TCP or UDP stack to replay the traﬃc
as speciﬁed in the transcript. Figure 1(b) shows how we cre-
ate two objects with the necessary information for the client
and server to replay the traﬃc from the recorded trace.
Logical dependencies.
For TCP traﬃc, we preserve
application-layer dependencies using the implicit happens-
before relationship exposed by application-layer communica-
tion in TCP. More speciﬁcally, we extract two unidirectional
byte streams sAB and sBA for each pair of communicating
hosts A and B in the recorded trace. For each sequence of
bytes in sAB, we identify the bytes in sBA that preceded
them in the trace. When replaying, host A sends bytes in
sAB to host B only after it has received the preceding bytes
2The Glasnost paper describes an (unevaluated) tool to sup-
port replaying of arbitrary applications but we were unsuc-
cessful in using it, even with the help of a Glasnost coauthor.
3This approach is similar to Cui et al.’s [5]; however, our
approach perfectly preserves application payloads (to ensure
traﬃc is classiﬁed by shapers) and timing (to prevent false
positives when detecting shaping).
in sBA from host B. We enforce analogous constraints from
B to A. For UDP traﬃc, we do not enforce logical dependen-
cies because the transport layer does explicitly not impose
them.
Timing dependencies. A second challenge is ensuring
the replayed traﬃc maintains the inter-message timing fea-
tures of the initial trace. For example, streaming video apps
commonly download and buﬀer video content in chunks in-
stead of buﬀering the entire video, typically to reduce data-
consumption for viewer abandonment and to save energy by
allowing the radio to sleep between bursts. Other content
servers use packet pacing to minimize packet loss and thus
improve ﬂow completion times.
Our system preserves the timings between packets for
both TCP and UDP traﬃc to capture such behavior when
replaying (this feature can be disabled when timing is not
intrinsic to the application). Preserving timing is a key fea-
ture of our approach, that can have a signiﬁcant impact
on detecting diﬀerentiation, as discussed in Section 2.2. In
short, it prevents us from detecting shaping that does not
impact application-perceived performance.
Speciﬁcally, for each stream of bytes (UDP or TCP) sent
by a host, A, we annotate each byte with time oﬀset from
the ﬁrst byte in the stream in the recorded trace. If the ith
byte of A was sent at t ms from the start of the trace, we
ensure that byte i is not sent before t ms have elapsed in the
replay. For TCP, this constraint is enforced after enforcing
the happens-before relationship.
In the case of UDP, we do not retransmit lost packets.
This closely matches the behavior of real-time applications
such as VoIP and live-streaming video (which often toler-
ate packet losses), but does not work well for more compli-
cated protocols such as BitTorrent’s µTP [20] or Google’s
QUIC [1]. We will investigate how to incorporate this be-
havior in future work.
3.3 Replaying the trace
After steps 1 and 2, we replay the recorded traﬃc on a
target network to test our null hypothesis that there is no
diﬀerentiation in the network. This test requires two sam-
ples of network performance: one that exposes the replay to
diﬀerentiation (if any), and a control that is not exposed to
diﬀerentiation.
A key challenge is how to conduct the control trial. Ini-
tially, we followed prior work [6] and randomized the port
numbers and payload, while maintaining all other features of
the replayed traﬃc. However, using our testbed containing
commercial traﬃc shapers (Section 4.2), we found that some
shapers will by default label “random” traﬃc with high port
numbers as peer-to-peer traﬃc, a common target of diﬀeren-
tiation. Thus, this approach is unreliable to generate control
trials because one can reasonably expect it to be shaped.
Instead, we re-use the Meddle VPN tunnel to conduct
control trials. By sending all recorded traﬃc over an en-
crypted IPSec tunnel, we preserve all application behavior
while simultaneously preventing any DPI-based shaper
from diﬀerentiating based on payload. Thus, each replay
test consists of replaying the trace twice, once in plaintext
(exposed trial), and once over the VPN (control trial),
depicted in Figure 1(c). To detect diﬀerentiation in noisy
environments, we run multiple back-to-back tests (both
control and exposed). Note that we compare exposed and
control trials with each other and not the original recorded
242(a) YouTube
(b) Skype
Figure 2: Plots showing bytes transferred over time, with and
without preserving packet timings for TCP (YouTube) and UDP
(Skype) applications. By preserving inter-packet timings, our re-
play closely resembles the original traﬃc generated by each app.
trace. We explore potential issues of using a VPN as a
control in Sections 4.3 and 7.
3.4 Detecting differentiation
After running the exposed and control trials, we compare
performance metrics (throughput, loss, and delay) to de-
tect diﬀerentiation (Fig. 1(d)). We focus on these metrics
because traﬃc shaping policies typically involve bandwidth
rate-limiting (reﬂected in throughput diﬀerences), and may
have impacts on delay and loss depending on the queu-
ing/shaping discipline. We base our analysis on server-side
packet captures to compute throughput and RTT values
for TCP, because we cannot rely on collecting network-level
traces on mobile clients. For UDP applications, we use jit-
ter as a delay metric and measure it at the client at the
application layer (observing inter-packet timings).
A key challenge is how to automatically detect when dif-
ferences between two traces are caused by diﬀerentiation,
instead of signal strength, congestion, or other confounding
factors.
In Section 5, we ﬁnd that previous techniques to
identify diﬀerentiation are inaccurate when tested against
commercial packet shaping devices with varying packet loss
in our testbed. We describe a novel area test approach to
compare traces that has perfect accuracy with no loss, and
greater than 70% accuracy under high loss (Fig. 9).
4. VALIDATION
We validate our methodology using our replay system
and a testbed comprised of two commercial shaping devices.
First, we verify that our approach captures salient features
of the recorded traﬃc. Next, we validate that our replays
trigger diﬀerentiation and identify the relevant features used
for classiﬁcation. To the best of our knowledge, this is ﬁrst
study to use commercial shapers to validate diﬀerentiation
detection. Finally, we discuss potential overheads of using a
VPN connection as a control and how we mitigate them.
Figure 3: Our testbed for testing our diﬀerentiation detector.
4.1 Record/Replay similarity
Our replay script replicates the original trace, including
payloads, port numbers, and inter-packet timing. We now
show that the replay traﬃc characteristics are essentially
identical to the recorded traﬃc. Figure 2 shows the results
for a TCP application (YouTube (a)) and a UDP application
(Skype (b)). As discussed above, preserving inter-packet
timings is important to produce a replay that closely resem-
bles the original trace (otherwise, we may claim that diﬀer-
entiation exists when the application would never experience
it).
Figure 2(a) shows that our replay captures the behavior
of the application, presenting the cumulative transfer over
time for a YouTube trace collected and replayed over the
Verizon mobile network. The ﬁgure shows the behavior for
the original trace and two replays, one which preserves the
inter-packet timing (overlaps with original) and one which
transfers as fast as possible while preserving application-
layer dependencies. Preserving inter-packet timings results
in a replay that closely follows the recorded application be-
havior. Figure 2(b) shows similar results for Skype traﬃc.
4.2 Trafﬁc shapers detect replayed trafﬁc
We now validate that our replay traﬃc is properly classi-
ﬁed for diﬀerentiation using commercial shaping products.
We acquired traﬃc shaping products from two diﬀerent
vendors and integrated them into a testbed for validating
whether replays trigger diﬀerentiation (Fig. 3). The testbed
consists of a client connected to a router that sits behind a
traﬃc shaper, which exchanges traﬃc with a gateway server
that we control. The gateway presents the illusion (to the
packet shaper) that it routes traﬃc to and from the public
Internet. We conﬁgure the replay server to listen on arbi-
trary IP addresses on the gateway, giving us the ability to
preserve original server IP addresses in replays (by spooﬁng
them inside our testbed). We describe below some of our
key ﬁndings from this testbed.
Diﬀerentiation testing must be extensible. One de-
vice lists more than 700 applications that it uniquely iden-
tiﬁes, the other lists approximately 2,000 application ﬁlters.
Further, both devices routinely update their classiﬁcation
rules, on timescales of months (if not shorter). Thus, testing
only a small number of applications is insuﬃcient. By allow-
ing users to create their own traces to conduct diﬀerentiation
tests, our approach is extensible to evolving diﬀerentiation
targets.
For replays to
Our replays trigger traﬃc shaping.
be eﬀective, they need to “look” like legitimate application
traﬃc from the perspective of the traﬃc shaper, i.e., re-
play traﬃc should be classiﬁed as the application that was
recorded. We validate this for a variety of popular mobile
applications: YouTube, Netﬂix, Skype, Spotify, and Google
Hangouts. Figure 4 shows the YouTube and P2P policies on
the shaper applied to our replay as we vary the application
payload.
 0 5 10 15 20 25 30 35 0 1 2 3 4 5 6Cumulative transfer(Mbits)â€(cid:157)Time (s)OriginalReplay with timingReplay no timing 0 1 2 3 4 5 6 7 8 0 10 20 30 40 50 60Cumulative transfer(Mbits)â€(cid:157)Time (s)OriginalReplay with timingReplay no timing243Row Changes in traﬃc
1
2
3
4
5
6
7
8
No changes
Added a packet with 1 byte of data to the beginning of traﬃc
Added one byte of random data to the beginning of ﬁrst packet
Replaced “GET” with a random string (same size)
Replaced “youtube” string with a random one (ﬁrst packet only)
Replaced “youtube” string with a random one (ﬁrst packet, HOST header only)
Added one byte of random data to the end of ﬁrst packet
Added “GET ” to beginning of ﬁrst packet
Detection result using:
Original ports
Diﬀerent ports
YouTube
YouTube
HTTP
HTTP
HTTP
HTTP
YouTube
YouTube
YouTube
P2P
P2P
P2P
P2P
YouTube
YouTube
YouTube
Table 1: Eﬀect of diﬀerent parameters on YouTube traﬃc detection for a popular commercial shaping device. IP addresses do not aﬀect
traﬃc classiﬁcation, but ports and payloads have eﬀects that vary.
• Server IP addresses do not aﬀect classiﬁcation.
While our shapers support IP-based policies, we found
no evidence of IP-based classiﬁcation rules.
• Non-standard ports may still be subject to diﬀer-
entiation. An important outcome of our testing is that
traﬃc with random high port numbers may be classiﬁed
as P2P. Glasnost’s [6] detection approach (among oth-
ers) assumes that traﬃc sent on random ports will not
be subject to diﬀerentiation, but traﬃc sent on standard
ports will. However, our shaping device classiﬁes traﬃc
on random ports as P2P, which itself is often subject to
diﬀerentiation.
• Traﬃc shaping decisions are made early. For
HTTP requests, the ﬁrst packet with payload, i.e., re-
quest packet from client, is enough for classiﬁcation. For
UDP ﬂows, e.g., Skype, the shaper requires more pack-
ets for classiﬁcation (e.g., ∼10). This means that traf-
ﬁc diﬀerentiation tests can trigger diﬀerentiation using a
small amount of data and only need to run long enough
to observe steady state performance. This observation is
particularly salient for mobile users who may be subject