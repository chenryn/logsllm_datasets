x∈U
δ = max
(cid:33)
max (PA(x) − eεPB(x), 0) ,
max (PB(x) − eεPA(x), 0)
Proof. Let ε ≥ 0 and let A and B be two distributions over the universe U. We show the equivalence by ﬁrst
showing that (1) for every set S, the calculation describes an upper bound and then that (2) there exists a
set S such that this bound is tight.
(1) We show that ∀S ⊆ U,
(cid:88)
PA(x ∈ S : x) − eεPB(x ∈ S : x)
max (PA(x) − eεPB(x), 0)
x∈U
≤
The inverse direction then follows analogously.
(cid:88)
PA(x ∈ S : x) − eεPB(x ∈ S : x)
(cid:88)
(cid:88)
PA(x) − eεPB(x)
max (PA(x) − eεPB(x), 0)
max (PA(x) − eεPB(x), 0)
x∈S
=
≤
≤
x∈S
x∈U
6
1.0001.0051.0101.0151.0201.0251.0301.03510−2510−2110−1710−1310−910−510−1eεδ(ε)GSGSδ(ε)−6−4−202468eventspaceGSvsGSABeε·Aδ(ε)Figure 2: Comparison between the truncated Gauss mechanisms (blue) and a randomized response mech-
anism Mε,δ (red). We show how eε evolves in both cases for a ﬁxed δ = 10−4 (left side). Note that both
graphs start at the same point, but quickly diverge. For ease of understanding we depict the probability
distributions of interest for both mechanisms (right); here, randomized response directly consists of only 4
possible events. For both mechanisms, we portray the two distributions A and B.
(2) Let S := {x ∈ U s.t. Pr [x ∈ A] ≥ eεPr [x ∈ B]}. Then,
(cid:88)
PA(x ∈ S : x) − eεPB(x ∈ S : x)
(cid:88)
PA(x) − eεPB(x)
max (PA(x) − eεPB(x), 0) .
x∈S
=
=
x∈U
Analogously, for S := {x ∈ U s.t. Pr [x ∈ B] ≥ eεPr [x ∈ A]},
(cid:88)
PB(x ∈ S : x) − eεPA(x ∈ S : x)
(cid:88)
PB(x) − eεPA(x)
max (PB(x) − eεPA(x), 0) .
x∈S
=
=
x∈U
Thus, for every pair of distributions A and B and for every ε ≥ 0 the distributions are tightly (ε, δ)-
diﬀerentially private, where δ is calculated as described.
If only one pair ε, δ(ε) is considered, composition can only be based on very limited information about the
distributions. In this case, for all we know, the distributions could actually have the shape of the randomized
response distributions Mε,δ(0) and Mε,δ(1).5 However, by considering more information we can derive much
better composition bounds. Figure 2 shows ADP guarantees of two Gaussian distributions in contrast to
Mε,δ(0/1) under r = 512-fold composition (left side) and graphically depict those distributions (right side).
With this tight ADP-bound, we can formulate our main result.
Main result (informal version). Let M1, . . . , Mr be mechanisms with worst-case distributions. Let
i=1 Mi be their sequential composition. For every ε ≥ 0 our numerical method privacy buckets derives
5Kairouz, Oh, and Viswanath [14] proved that if a mechanism satisﬁes (ε, δ)-ADP, it cannot have more leakage than Mε,δ.
(cid:81)r
7
1002003004005001.001.502.002.50numberofcompositionseεCompositionofGSvsMε,δMε,δGSeventspaceProbabilityspaceofGSvsMε,δABFigure 3: Vuvuzela analysis: upper (red) and lower (blue) bounds on δ (log-scale) for diﬀerent eε. Originally
recommended mechanisms with 150k (left) and 450k (right) messages overhead per round, analyzed with
previous bounds [8] (red dot) and privacy buckets (dotted lines), vs our recommended mechanism with 15k
(left) and 45k (right) overhead, analyzed using privacy buckets (solid line).
upper and lower bounds δup(ε) and δlow(ε) for tight ADP δ(ε) as in Deﬁnition 1 for(cid:81)r
i=1 Mi:
δlow(ε) ≤ δ(ε) ≤ δup(ε).
2.3 Practical relevance of tight privacy bounds
To further highlight the importance of tight privacy bounds for actual mechanisms and protocols, we brieﬂy
discuss as a case study the Vuvuzela [26] protocol, which is an anonymous communication system tailored
towards messengers. The Vuvuzela paper argues that the only leakage of their strong anonymity mechanisms
is the patterns of communication between entities. To limit this leakage, they apply noise to the patterns by
sending a random number of dummy messages, where the number of messages follows a truncated Laplace
distribution. Vuvuzela has two relevant protocol parts that can be analyzed separately: the dialing protocol
(to establish contact) and the communication protocol (to transfer messages).
To quantify the improvements of a tight analysis, Figure 3 plots the δ(ε) for various values of ε for
a number r of 65, 536 and 524, 288 observations for the conversation protocol, one of the two relevant
parts of their system. The original paper [26] proposed to increase privacy with dummy messages that are
distributed according to a Laplace distribution. We propose to use a Gaussian distribution with a smaller
mean, signiﬁcantly reducing the noise-overhead. The original paper proposed noise overheads with 150k and
450k noise messages per round and privacy guarantees. We show that with Gaussian noise and a tighter
analysis, we can achieve better privacy bounds with only 15k and 45k noise messages per round than the
respective previously proposed conﬁgurations, reducing the overhead by a factor of 10 while achieving better
privacy bounds.
In detail, for r = 524, 288 the Laplace noise 450k yields a privacy bound δ that is almost 4 orders of
magnitude lower, and the corresponding Gaussian noise (with the same variance and mean) a more than 6
orders of magnitude decreased bound compared to their original guarantees. Furthermore, even Gaussian
noise with only a mean of 15k meets the privacy requirements of eε ≤ 2 and δ ≤ 10−4 for r = 65, 536
observations. We also analyze the dialing protocol, where similar improvements are possible: 5 times lower
Gaussian noise suﬃces for matching their best guarantees and using Laplace noise incurs a privacy bound
8
11.522.533.510−1110−910−710−510−310−1eεδr=65,536observationsGS-15kLP-150kGS-150kLP-150kPrivacytarget11.522.533.510−1110−910−710−510−310−1eεr=524,288observationsGS-45kLP-450kGS-450kLP-450kPrivacytargetimprovement of 3 orders of magnitude, whereas comparable Gaussian noise leads to an improvement of 4
orders of magnitude.6
2.4 Composition of diﬀerential privacy
One of the main advantages of diﬀerential privacy is the fact that guarantees are still sound under composi-
tion, albeit with increasing values for ε and δ.
Deﬁnition 2 (k-fold DP of a mechanism). A randomized algorithm M with domain D and range U is k-fold
(ε, δ)-diﬀerentially private for sensitivity s if for all S ⊆ U k and for all (x1, . . . , xk), (y1, . . . , yk) ∈ Dk such
that ∀1 ≤ i ≤ k. ||xi − yi||1 ≤ s:
Pr[(M (x1), . . . , M (xk)) ∈ S]
≤eε Pr[(M (y1), . . . , M (yk)) ∈ S] + δ
Note that when we describe diﬀerential privacy in terms of distributions over the worst-case inputs, the
composition of diﬀerential privacy is equivalent to considering diﬀerential privacy for product distributions. If
x0, x1 are the worst-case inputs for a mechanism M , resulting in the distributions M (x0) and M (x1), then the
k-fold composition is described in Deﬁnition 1 on the distributions A = M (x0)k and B = M (x1)k. Similarly,
a composition of two diﬀerent mechanisms M and M(cid:48) with worst-case inputs (in the sense of Section 2.1)
x0, x1 and x(cid:48)0, x(cid:48)1 respectively, boils down to Deﬁnition 1 on the distributions A = M (x0) × M(cid:48)(x(cid:48)0) and
B = M (x1) × M(cid:48)(x(cid:48)1).
The main composition results we compare our work with are: naive composition, slightly less naive
composition and two composition result with improved bounds [8, 14]. We recall these results here.
Lemma 2 (Na¨ıve Composition). Let (A1, B1) and (A2, B2) be two pairs of distributions, such that A1 and
B1 are (ε1, δ1)-diﬀerentially private and A2 and B2 are (ε2, δ2)-diﬀerentially private. Then A1 × A2 and
B1 × B2 are (ε1 + ε2, δ1 + δ2)-diﬀerentially private.
Lemma 3 (Adaptive Composition). Let (A1, B1) and (A2, B2) be two pairs of distributions, such that A1
and B1 are (ε1, δ1)-diﬀerentially private and A2 and B2 are (ε2, δ2)-diﬀerentially private. Then A1 × A2 and
B1 × B2 are (ε1 + ε2, δ1 + (1 − δ1) · δ2)-diﬀerentially private.
Lemma 4 (Boosting and Diﬀerential Privacy (Advanced Composition) [8]). Let (A1, B1), . . . , (Ak, Bk) be
pairs of distributions, such that Ai and Bi are (ε, δ)-diﬀerentially private for all i ∈ {1, . . . , k}. Then A1 ×
. . .×Ak and B1×. . .×Bk are (ˆεˆδ, ˆδ)-diﬀerentially private, where ˆδ = k·δ and ˆεˆδ = O
Lemma 5 (Kairouz et al.’s Composition [14]). For any ε ≥ 0 and δ ∈ [0, 1], the class of (ε, δ)-diﬀerentially
private mechanisms satisﬁes
(cid:114)
kε2 + ε
(cid:18)
k log
(cid:16)
e + (ε√k/ˆδ)
(cid:17)(cid:19)
under k-fold composition, for all i ∈ {0, . . . ,(cid:98)k/2(cid:99)} where ε(cid:48) = (k − 2i)ε and δ(cid:48) = 1 − (1 − δ)k(1 − δi)
(ε(cid:48), δ(cid:48))-diﬀerential privacy
(cid:80)i−1
(cid:96)=0
(cid:0)k
(cid:96)
(cid:1)(cid:0)e(k−(cid:96))ε − e(k−2i+(cid:96))ε(cid:1)
δi =
(1 + eε)k
These composition results allow for deriving diﬀerential privacy guarantees under composition in a black-
box manner, i.e., only depending on ε and δ. Consequently, these results are oblivious to how the underlying
distributions actually compose and present, in a way, worst-case results under composition. Thus, we cannot
expect that they come close to the tight diﬀerential privacy guarantee of the composed distributions. In the
remainder of this paper we introduce, prove sound and discuss our main idea: approximating the distributions
A1, A2, B1, B2 in a way that allows for a sound calculation of a diﬀerential-privacy guarantee that takes into
account features of the distribution even under manifold composition. Moreover, we use the same technique
to derive a lower bound for the guarantee, to bound the (unknown) tight diﬀerential privacy guarantee from
both directions.
6For a more detailed description of our Vuvuzela analysis, we refer the interested reader to Section 7.
9
2.5 Related work
Mechanism-oblivious bounds for adaptive composition Early composition bounds for r-fold ADP [8,
14, 21] only provide mechanism-oblivious bounds, i.e., these bounds are oblivious to the actual mechanisms.
These results only rely on the initial values (ε0, δ0). Our work, in contrast, is mechanism-aware in the sense
that it takes the shape of the distributions (/mechanisms) into account. Our results yield mechanism-aware
δ-tight bounds for r-fold composition and thereby lead to signiﬁcantly tighter bounds.
Mechanism-aware bounds for adaptive composition Recent work [7, 2, 1, 20] partially takes the
shape of the mechanism into account by computing the R´enyi divergence of the corresponding worst-case
distributions, i.e., the moments of the distribution of ratios, to achieve tighter privacy bounds. Similarly,
Abadi et al. [1] use the moments accountant based on R´enyi divergence to ﬁnd tighter bounds. These
approaches, in special cases, ﬁnd better composition results than the best mechanism-oblivious composition
theorem. As shown in our comparisons, however, our bounds are even tighter than prior mechanism-aware
bounds and—in contrast to all previous work—also include lower bounds and thereby a means to estimating
their precision. Additionally, our work provides tight bounds for very low epsilon, even epsilon = 0, i.e., the
total variation (also called statistical distance), which is used to formalize statistical indistinguishability.
Adaptively chosen privacy parameters As in previous work [8, 1, 14] our technique satisﬁes adaptive
composition [8] in the following sense: sequences of mechanisms are composed where each query can be
adaptively chosen by the attacker and depend on previously observed responses, but the noise distributions
of each mechanism have to be independent of these previously observed responses to the attacker. This kind
of adaptive composition results does not hold for some mechanisms that achieve ADP under continual obser-
vation that use carefully correlated noise and/or only use noise when necessary [5, 9, 12, 13]. Nevertheless,
the proofs of these adaptive mechanisms can still beneﬁt from our results as they often over-approximate
a subset of these correlated distributions with independent distributions, e.g., in order to apply Azuma’s
Inequality [12] (which is stated for independent distributions).
Probabilistic diﬀerential privacy (PDP) vs ADP It might appear preferable to only use δ such that it
is only the probability of distinguishing events, in order to guarantee pure ε-DP with probability (1−δ) (which
is also called PDP [17, 11]). However, if delta would only contain distinguishing events, both ε and δ would
grow linearly in the number of compositions. Thus, better ε-bounds can only be achieved by allowing some
of the probability mass of the non-distinguishing events to be hidden within the δ parameter. While using
PDP with distinguishing events has an intuitive interpretation, it is not closed under post-processing [18].
Hence, this work concentrates on ADP.
Optimal mechanisms for a given utility function Recent work [10, 15] made progress on ﬁnding opti-
mal mechanisms for DP for a large class of utility functions. These results concentrate on single observations
and do not characterize how these mechanisms behave under r-fold composition.
Dependencies The work of Liu, Chakraborty and Mittal [16] discusses the importance of correctly mea-
suring the sensitivity of databases for diﬀerential privacy. They show that in real-world examples entries
can be correlated and thus cannot be independently exchanged as in DP’s basic deﬁnition. Their approach,
however, ﬁnally results in the same techniques as in previous work being used to achieve the same goal:
noise applied to database queries results in diﬀerential privacy, although the sensitivity is calculated in a
more complex manner. Our results can directly be applied in such a setting as well: given the (ﬁnal) dis-
tributions that potentially consider dependent entries we calculate diﬀerential privacy guarantees for these
distributions.
10
3 Privacy buckets of distributions
3.1 Informal description of privacy buckets
Generic bounds for diﬀerential privacy under continual observation [8, 14] are stated independently of the
shape of the underlying distributions, simply based on the ADP guarantees before the composition. This
obliviousness is both strength and weakness: the exact shape of the distribution does not need to be charac-
terized to apply these results, but they cannot devise tight bounds that are derivable from the shape of the
distributions. We now introduce an alternative approach: we approximate the distributions with an explicit
focus on their most important features for ADP, the privacy loss of atomic events.
Recall from Lemma 1 that for distributions A and B over the universe U we can calculate a value δ(ε)
for every value ε ≥ 0 so that A and B are tightly (ε, δ(ε))-ADP:
(cid:18)(cid:88)
(cid:88)
x∈U
δ(ε) = max
(cid:19)
max (PA(x) − eεPB(x), 0) ,
For simplicity we consider δ(ε) =(cid:80)
of each atomic event x ∈ U to δ(ε) is δ(x, ε) = max(PA(x) − eεPB(x), 0) and their sum is(cid:80)
max (PA(x) − eεPB(x), 0) for now. Consequently, the contribution
x δ(x, ε) = δ(ε).
This is of course not surprising. Let us observe that if PB(x) = 0, we have δ(x, ε) = PA(x). We can combine
all atomic events x with PB(x) = 0 into one non-atomic event x∞ of all such events.
max (PB(x) − eεPA(x), 0)
x∈U
x∈U
,
For events x with PB(x) > 0, let L(x)
(A||B) = ln PA(x)
use, we deﬁne the privacy loss without the logarithm as eL(x)
PB (x) be the logarithmic privacy loss of x [7]. For ease of
PB (x) , i.e., as the ratio of two
(A||B) = PA(x)
(A||B) = eL(x)
probabilities. Based on the privacy loss, we can calculate the contribution δ(x, ε) of an atomic event x as
δ(x, ε) = max (PA(x) − eεPB(x), 0)
PA(x) − eε PA(x)
1 −
eL(x)
(A||B)
eε
eL(x)
, 0
 , 0
 .
(A||B)
= max
= PA(x) · max
Combining the contributions of several events For any two disjoint events x, y with the same privacy
loss p = eL(x)
(A||B), their contribution can be combined without loss of information to
(A||B) = eL(y)
δ(x ∪ y, ε) = δ(x, ε) + δ(y, ε) = (PA(x) + PA(y)) · max
(cid:18)(cid:18)
eε
p
1 −
(cid:19)
(cid:19)
, 0
,
In
requiring us to only remember the privacy loss p and the sum of their probabilities PA(x) + PA(y).
other words, we can combine all atomic events with the same ratio without losses. If we allow for a slight
imprecision, we can soundly combine disjoint events x and y with approximately the same privacy loss by
(A||B)) and yield δ(ε)(x ∪ y) ≥
summing the probabilities PA(x) + PA(y) and choosing p = max(eL(x)
(A||B), eL(y)