pages and tries to disassemble them starting at twenty
randomly selected offsets. For simplicity, any sequence
of assembly instructions that terminates with a control
transfer instruction that invokes a library call or system
call is marked as a potential shellcode. To avoid cases
where an attacker tries to obfuscate its attack by using an
indirect control transfer instruction (iCTI), we consider
each iCTI as a potential shellcode terminator.
The scan process is repeated for each allocated page
and the detector finally reports the distribution of the
number of potential shellcode detected in each page. If
the average number is higher than a given value, it raises
an alarm. This approach derives from the observation
that in the normal operation of a benign program only a
small portion of the analyzed memory pages would con-
tain a relevant fraction of valid instructions sequences.
In an exploitation scenario, instead, most of the ana-
lyzed pages would contain close to 20 potential shell-
code sequences. It is important to note that when the
system starts disassembling from one page it continues
till it reaches a code pointer, that may as well be located
in a different page.
If multiple pages are involved in
such analysis they are all considered and marked as a
shellcode container.
Self-unpacking Shellcode Detector
In this second scenario, we assume the same environ-
ment described before (ASLR enabled, DEP disabled),
but we now consider the case in which an attacker packs
her shellcode to make the detection more difficult. For
example, all Metasploit payloads in spraying-assisted
exploits are packed by default, e.g., by using the shikata-
ga-nai encoder. Packed shellcodes are typically made
up of a number of seemingly meaningless bytes, pre-
pended with a small unpacking routine. The routine and
the packed code are usually adjacent (i.e., they are lo-
cated in the same memory page), as splitting them would
lead to a waste of space and consequent loss of effective-
ness when mounting the spraying attack.
Our second detection plugin is designed to detect
packed shellcodes as soon as they start unpacking, and
is tightly binded to the memory tracer. The component
enforces what we call a dynamic W⊕X protection. As
soon as the memory tracer detects a new page allocation,
it modifies the EPT entry corresponding to the newly al-
located page so that a violation will be triggered when a
write access to that page is attempted (R-X). The detec-
tor intercepts these attempts and modifies the EPT entry
of the accessed page so that write accesses are enabled,
but not execution accesses (RW-).
If this new protec-
tion triggers a violation, we have a write-then-execute
situation, which is fairly common in nowadays systems
(especially with JIT engines). However, this mecha-
nism allows to observe the more anomalous situation in
which code modifies the same memory page in which
it resides, that indicates the presence of self modify-
ing code, used by packed shellcodes as described above.
This technique is also effective when DEP is enabled on
the heap memory, and the attacker uses a JIT-spraying
attack. In fact, if the JIT-sprayed payload is packed, it
will need to unpack itself and thus will trigger our de-
tection heuristic.
438  25th USENIX Security Symposium 
USENIX Association
8
Data Spraying Detector
When DEP is enabled, and JIT spraying is not a viable
solution (e.g., there is no JIT engine in the vulnerable
process), a possible exploit solution is to use return ori-
ented programming. In this case, the attacker no longer
sprays the heap with executable code but instead with
multiple copies of a ROP chain. To trigger the code, the
attacker then uses a pivoting sequence to move the stack
pointer into the heap and let execution slide down the
ROP chain, as we explained in Section 2.
To detect data spraying attacks, we designed a com-
ponent that samples the most recently allocated mem-
ory pages of a process, and it considers any word inside
them as a potential memory address. For each of these
candidate addresses, the data spraying detector checks
whether this address points to a valid executable page,
and, if so, marks it as a potential code pointer. In case
the total number of code pointers for each page is over a
threshold, the system raises an alarm.
Unfortunately, even though this policy may sound
reasonable at a first glance, we observed that in prac-
tice it suffers from a large amount of both false positives
and false negatives. The first problem is related to the
fact that modern operating systems use different tech-
niques to load pages, one of which is called Demand
Paging [4]. In this case the pages are only brought into
memory when the running-process demands them. This
optimization creates an issue for our detection method
because when the system extracts the potential code
pointers from the memory pages and checks if they point
to a valid code page, the page may not be present in the
page table (even if it is properly allocated). We observed
this behavior during our experiments, and the result is
that certain addresses would be discarded—thus poten-
tially creating false negatives by missing a page that is
part of a spraying attack.
To avoid this issue, we modified our hypervisor to
intercept page faults in the guest system when Graﬃti
switches to security mode for a given process. When
the detector checks an address that points to a memory
page that is not mapped, the system does not discard it
but keeps it as a potential code pointer into the memory
structures of the hypervisor. Afterwards, when the pro-
cess gets access to the demanded page, the system loads
it and our detection system intercepts the page faults and
it checks if the potential code pointer points to this mem-
ory page. If true, the system marks all the memory pages
previously allocated that contain such address as suspi-
cious and then it re-applies again the previous technique
on the new set of pages.
The second problem of our original technique is the
high number of false positive we observed in the experi-
ments because benign memory pages also contain a sig-
nificant number of code pointers (e.g., in case of C++
classes or arrays). To reduce the false positives created
by those benign memory pages, we improved our de-
tector algorithm by replacing the pointers counter with
a more sophisticated pointers frequency analysis. The
idea is to compute the frequency of the code pointers
that every page of the entire set contains, instead of ana-
lyzing every page individually. While the absolute num-
ber of code pointers may be deceiving, we observed that
the distribution of those pointers in case of benign ap-
plications is really diverse, while in case of an attack the
distribution tends to be quite uniform.
7 Experimental Results
The goal of our experiments is to first measure the over-
head of the system in a realistic environment and then to
show how effective our heuristics are in distinguishing
spraying attacks from a normal allocation behavior.
Our code is composed by three main software com-
ponents: a core hypervisor framework based on Hy-
perDBG, the micro-virtualization implementation, and
the detector plugins. The core hypervisor framework
is written in a combination of C (17353 LoC) and as-
sembly (545 LoC). The micro-virtualization and detec-
tor components account for 1435 lines of C program-
ming language.
All tests presented in this section were performed on
two machines, equipped with an Intel Core i5-2500 @
3.3 GHz and 8GB of RAM, running respectively Win-
dows 7 Professional 32bit and Debian Wheezy 32bit
(kernel 3.2).
Activation Threshold and Overhead
Our system is designed to be adaptive. Consequently,
the only part that is always active is the Memory Tracer.
Our micro-virtualization solution confines the overhead
to a single process and allows our system to monitor an
arbitrary number of different applications without any
increase in the overhead of the rest of the system.
During normal operation, the tracker overhead is neg-
ligible, and it is only noticeable when the monitored ap-
plication allocates tens of megabytes of memory at a
time – typically at start up or when a large document
is open. To measure this worst case scenario, we used
the stress suite to simulate a program that intensively
allocates memory on a Windows 7 and on a Linux 3.2
hosts at a rate of 8MB every 2 seconds. The overhead
we observed during the allocation phase was of 24% on
Windows and 25% on Linux for a single process with-
out considering context switch. Again, it is important to
USENIX Association  
25th USENIX Security Symposium  439
9
by our detection module over the total number of pages
allocated). As a reference, with this value Nozzle in-
troduced an overhead of 20% to Internet Explorer. The
overhead obtained with our system is shown in Figure 4
for different values of threshold. Also in the worst case
with the activation threshold set to 150MB, the over-
head was only 12%. Moreover, the heuristic responsi-
ble for most of this overhead is the one that requires to
randomly disassemble the content of the memory pages.
Since this component is useless on any modern OS when
DEP is enabled, the detection overhead of Graﬃti be-
comes barely noticeable.
Moreover, our experiments with Acrobat Reader
never reached the activation threshold, even when it was
set at the conservative value of 100MB. In this case, the
overhead of Graﬃti on the normal use of the application
was constantly zero – showing that for some popular ap-
plications our framework can provide a very complete
protection against known and unknown attacks with no
additional overhead.
Detection Accuracy
To test the effectiveness of our system, we measured the
true and false positives rates for each individual detec-
tion technique that is currently included in the Graﬃti
prototype. To test the detection rate we used several real
world exploits that cover all the different spraying tech-
niques and variations mentioned in this paper. It is im-
portant to note that the six attacks that we chose for our
experiments, summarized in Table 3, are representative
for the entire spectrum of the techniques used by the
spraying attacks described in Section 2. On top of this
qualitative test, we also performed a quantitative test us-
ing over 1000 different malicious PDF documents that
rely on heap spraying in the exploitation phase.
In the first test we show the effectiveness of our sys-
tem to detect exploits based on stack pivoting, by using
the attack described in CVE-2011-1996. The attack first
sprays the stack frames on the heap and then executes a
number of ROP gadgets in order to disable the DEP pro-
tection. During the spraying phase the attack allocates
on average 384MB.
In this case, the static analyzer applied the code point-
ers frequency analysis on the attack memory pages. The
component detected a high number of code pointers with
a variance close to 0 in all the allocated memory pages,
and thus it raised an alert successfully preventing the at-
tack. To evaluate the false positive of such technique,
we instructed our detector to track all the memory pages
allocated by Internet Explorer 8 while browsing the first
1000 top Alexa domains [1]. In this case, the frequency
of code pointers had a very high variance on all mem-
ory pages captured by the system, thus generating zero
Figure 4: Detection Overhead for Internet Explorer 8
note the experiments performed in these tests produced
a very intensive memory allocation activity and it is not
representative of the memory behavior of the entire life
of a process.
On top of this overhead, each application can observe
a different overhead when Graﬃti switches to security
mode and enables the detection modules to scan the ap-
plication memory. The frequency at which this happens
depends on the value of the activation threshold. The
lower the threshold, the hardest it is for an attacker to
evade detection – but the higher the potential overhead
for the application. “Potential” in this context means
that the actual overhead also depends on the application:
some use so little memory during their normal operation
that the security mode would never be triggered - also
for very low values of the threshold. Moreover, most
of the applications only allocate large amount of mem-
ory when the user opens a document, but then the use of
memory becomes quite constant - and therefore Graﬃti’s
negative impact tends to be concentrated only on the few
initial seconds, and becomes negligible after that.
To measure this trade-off we performed two exper-
In the first, we asked some users to surf the
iments.
web by using Internet Explorer 8 on Windows 7 with
our detection system activated. We choose IE8 since
this application usually uses a large amount of memory
and it represents one of the main targets of spraying at-
tacks. To mimic a realistic behavior, the users kept a tab
open on GMail, and then alternately opened three other
tabs performing memory intensive activities: watching
videos on YouTube, browsing Facebook, and checking
hundreds of pictures on 9gag. In the second experiment,
we used Acrobat Reader for Linux to open 100 benign
PDF files including conference papers, books, Ph.D. dis-
sertations, and very large manuals (i.e., the Intel Manu-
als).
Following the approach used by Nozzle [36], we se-
lected a sampling rate of 10% (number of pages checked
440  25th USENIX Security Symposium 
USENIX Association
10
Web Domain
Average
Variance
CVE
Application
Exploit Technique Detected
amazon.com
ask.com
baidu.com
blogspot.com
craiglist.org
delta-search.com
facebook.com
google.co.jp
google.com.br
google.com
instagram.com
microsoft.com
msn.com
yahoo.com
3
7
8
2
6
8
23
10
7
10
14
5
16
14
259.30
867.90
559.57
158.88
391.15
809.21
3521.68
562.99
459.57
46.44
2763.22
395.72
2916.28
1183.43
Table 1: Code Pointer Frequency Analysis Results.
Web Domain