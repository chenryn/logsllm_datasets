title:Server-side Verification of Client Behavior in Online Games
author:Darrell Bethea and
Robert A. Cochran and
Michael K. Reiter
Server-side Veriﬁcation of Client Behavior in Online Games
Darrell Bethea Robert A. Cochran Michael K. Reiter
University of North Carolina at Chapel Hill
{djb,rac,reiter}@cs.unc.edu
Abstract
Online gaming is a lucrative and growing industry, but
one that is slowed by cheating that compromises the gaming
experience and hence drives away players (and revenues).
In this paper we develop a technique by which game de-
velopers can enable game operators to validate the behav-
ior of game clients as being consistent with valid execu-
tion of the sanctioned client software. Our technique em-
ploys symbolic execution of the client software to extract
constraints on client-side state implied by each client-to-
server message, and then uses constraint solving to deter-
mine whether the sequence of client-to-server messages can
be “explained” by any possible user inputs, in light of the
server-to-client messages already received. The requisite
constraints and solving components can be developed ei-
ther simultaneously with the game or retroactively for ex-
isting games. We demonstrate our approach in two case
studies: one of the open-source game XPilot, and one of a
game similar to Pac-Man of our own design.
1 Introduction
Multi-player online games are very popular and prof-
itable, and are growing more so. Since 1996 the computer
game industry has quadrupled — in 2008 alone, worldwide
video-game software sales grew 20 percent to $32 billion
[26]. Estimates place revenue from online games at $11 bil-
lion, with games such as World of Warcraft, which has more
than 10 million subscribers worldwide, bringing in around
$1 billion in revenue for parent company Blizzard Enter-
tainment [1, 34].
Since its inception, the online game industry has been
plagued by cheating of numerous types, in some cases with
ﬁnancial repercussions to the game operator. Age of Em-
pires and America’s Army are examples of online games
that suffered substantial player loss due to cheating [33],
and for subscription games, player loss translates directly
to a reduction in revenues. And game developers and
operators are not the only ones for whom the stakes are
high. Hoglund and McGraw [18] argue that “games are a
harbinger of software security issues to come,” suggesting
that defenses against game cheats and game-related security
problems will be important techniques for securing future
massive distributed systems of other types.
In this paper, we develop an approach to detect a signiﬁ-
cant class of cheats in which a player changes a game client
to allow behaviors that a sanctioned game client would not
allow; to accomplish this, the player might modify the client
executable or in-memory data structures of a running client,
for example. Today, the most robust defense against such
client modiﬁcation is to maintain authoritative state at the
server, beyond the reach of direct manipulation by cheaters.
This, however, exacts a heavy price from game operators,
owing to the increased bandwidth use that results due to
sending low-level client events (in the limit, every player in-
put) to the server for accessing such state and conveying the
effects back to clients. As bandwidth is one of the largest
costs for large-scale game operators [29] and also a recur-
ring one, this tension between bandwidth use and cheat pre-
vention is problematic:
In the US and European markets, a good goal to
shoot for is 4-6 kilobits per second (kps)/player
or less. ... If you can get the bit rate down to
2kps, you’re “golden.” It’s hard to see how that
can happen, however, without putting dangerous
amounts of data directly into the client, which is
just askingfortroublefromtalented cheatersand
hackers. [29, p. 112]
The movement of games to all manners of devices using
wireless, volume-priced communication only reinforces the
importance of keeping bandwidth utilization to a minimum.
Moreover, even with the amount of detailed client infor-
mation collected at the server, server-side checking today
is heuristic (and thus potentially incomplete) and manually
programmed (and thus effort-intensive):
Players love to cheat — especially in online
games ... be ready to add server-side support to
preventusercheatingwithmethodsthatyouwere
notabletopredict. [17]
as guidance for game developers who are considering using
this technique for detecting cheating in their games.
In this paper we demonstrate a technique to detect any
type of cheating that causes the client to exhibit behavior, as
seen by the server, that is inconsistent with the sanctioned
client software and the game state known at the server. That
is, our approach discerns whether there was any possible
sequence of user inputs to the sanctioned client software
that could have given rise to each message received at the
server, given what the server knew about the game client
based on previous messages from the client and the mes-
sages the server sent to the client. In doing so, our approach
remedies the previously heuristic and manual construction
of server-side checks. Moreover, our approach potentially
enables new game designs that reduce bandwidth use by
placing more authoritative state at the client, since our ap-
proach veriﬁes that the client’s behavior is consistent with
legal management of that state. While reducing the inter-
action with the client will generally increase the compu-
tational cost of our veriﬁcation, the veriﬁcation need not
be done on the critical path of game play, and can be per-
formed selectively (e.g., only for suspected or winning play-
ers). Moreover, it can beneﬁt from the dramatic growth of
inexpensive computing power (larger numbers of cores) in
game-operator server farms.
Our strategy exploits the fact that game clients are often
structured as an event loop that processes user inputs, server
messages, or other events in the context of current game
state, and then sends an update to the server on the basis of
its processing. We symbolically execute the loop to derive
a predicate that characterizes the effects of the loop, and
speciﬁcally the update sent to the server, as a function of
its inputs and game state. By partially instantiating these
predicates on the basis of the actual messages the server
receives from a client and what the server previously sent
to the client, a veriﬁer can then use a constraint solver to
determine whether the resulting predicate is satisﬁable. If
so, then this indicates that the messages are consistent with
proper client execution — i.e., there were some user inputs
that could have yielded these messages.
We demonstrate our approach with two case studies. In
the ﬁrst, we apply our technique to the open-source game
XPilot. Because XPilot was developed as is commonplace
today, i.e., with low-level client events being sent to the
server, this case study does not fully illustrate the strengths
of our approach. However, it does demonstrate the (few)
ways in which we found it necessary to adapt XPilot to
use our technique efﬁciently and to allow for the realities
of modern gaming, such as message loss on the network.
For the second case study, we use a game of our own de-
sign that is similar to Pac-Man but that has features to bet-
ter exercise our technique. Together, these two case studies
illustrate the limits and beneﬁts of our approach and serve
2 Related Work
Detecting the misbehavior of remote clients in a client-
server application is an area that has received considerable
attention. One strategy, of which ours is a special case, is to
construct a model of proper client behavior against which
actual client behaviors are compared. Gifﬁn et al. [14] de-
veloped such an approach for validating remote system calls
back to the home server from computations outsourced to
(potentially untrusted) worker machines. In that work, re-
mote system calls are compared to a control ﬂow model
generated from the binary code of the outsourced compu-
tation, speciﬁcally either a non-deterministic ﬁnite-state au-
tomaton or a push-down automaton that mirrors the ﬂow of
control in the executable. A more recent example is work
by Guha et al. [16]: through static analysis of the client por-
tion of Ajax web applications (HTML and JavaScript), their
system constructs a control-ﬂow graph for the client that de-
scribes the sequences of URLs that the client-side program
can invoke. Any request that does not conform to this graph
is then ﬂagged as potentially malicious.
The technique we develop here follows this paradigm.
We similarly use analysis (in our case, of source code) to
develop a model of client behavior, against which inputs
(messages from the client) are compared. The primary dif-
ferentiator of our approach from previous works is sound-
ness: only sequences of client messages that could have ac-
tually been produced through valid client execution, on the
inputs sent by the server, will be accepted. This precision
is accomplished though our use of symbolic execution to
derive the complete implications of each message value to
the client-side state. While this would hardly be tractable
for any arbitrary client-server application, the control-loop
structure of game clients and the frequent communication
that is typically necessary for game play bounds the amount
of uncertainty that the veriﬁer faces in checking the client’s
messages.
A different approach to protecting against client misbe-
havior in client-server settings is to ensure that clients man-
age no authoritative state that could affect the server or the
larger application; as discussed in the introduction, this is
commonplace today for games. A recent system for imple-
menting web applications to have this property is Swift [9],
for example. The extreme of this approach is for the client
to simply forward all unseen inputs (e.g., user inputs) to the
server, where a trusted copy of the client-side computation
acts on these inputs directly; e.g., this is implemented for
Web 2.0 applications in the Ripley system [35]. In contrast,
our approach detects any client behavior that is inconsistent
with legal client execution, without requiring that all low-
level events be sent to the server. Our approach also rep-
resents a middle ground in terms of programmer effort be-
tween automatic partitioning, which can require extensive
manual annotation of the program [9], and client replica-
tion on the server, which requires none. In our case studies,
we found that our approach was largely automatic but did
require manual tuning in some cases to be efﬁcient.
If the preceding approach can be viewed as a “pes-
simistic” way of eliminating trust in the client to manage
authoritative state, one might say an “optimistic” version
was proposed by Jha et al. [21]. Instead of moving author-
itative state to a trusted server, a trusted audit server prob-
abilistically audits the management of authoritative state at
the client. In this approach, each game client periodically
commits to its complete state by sending a cryptographic
hash of it to the audit server.
If later challenged by the
audit server, the client turns over the requested commit-
ted state and all information (client-to-server and server-to-
client updates, user inputs) needed to re-trace and validate
the client’s behavior between this state and the next com-
mitted state. This approach, however, introduces additional
costs to the client in the form of increased computation (to
cryptographically hash game state, which can be sizable),
storage (to retain the information needed to respond to an
audit), and bandwidth (to transmit that information in the
event of an audit); our approach introduces none of these,
and can even enable bandwidth savings. Moreover, veriﬁ-
cation of clients in this scheme must be done during game
play, since clients cannot retain the needed information for-
ever. In contrast, our approach supports auditing at any time
in the future by the game operator, provided that it records
the needed messages (to which it already has access).
Other work on defeating cheating speciﬁcally in online
games comes in many ﬂavors. Useful surveys of the prob-
lem are due to Yan and Randell [40], Lyhyaoui et al. [25],
and Webb and Soh [38]. One common approach to defeat a
variety of cheats involves augmenting the client-side com-
puter with monitoring functionality to perform cheat detec-
tion (e.g., PunkBuster and [11, 12, 23, 28, 31]). Such ap-
proaches require consideration of how to defend this func-
tionality from tampering, and some commercial examples
have met with resistance from the user community (e.g.,
World of Warcraft’s Warden, see [37]). In contrast, our ap-
proach requires that no monitoring functionality be added to
clients. Other work focuses on wholly different cheats than
we consider here. One example is game “bots” that per-
form certain repetitive or precise tasks in place of human
gamers [7, 31, 39, 8, 27]. Bots that utilize the sanctioned
game client to do so (as many do) will go undetected by our
scheme, since the client behavior as seen by the server could
have been performed by the sanctioned game client on in-
puts from a real human user (albeit an especially skilled or
patient one). Another cheat that has received signiﬁcant at-
tention occurs when clients delay or suppress reporting (and
choosing) their own actions for a game step until after learn-
ing what others have chosen in that step (e.g., [2, 10]). Such
attacks can also go unnoticed by our techniques, if such de-
lay or suppression could be explained by factors (e.g., net-
work congestion) other than client modiﬁcation. Our tech-
niques are compatible with all proposed defenses of which
we are aware for both game bots and delay/suppression, and
so can be used together with them. Finally, various works
have examined security speciﬁcally for peer-to-peer games,
e.g., using peer-based auditing [15, 20, 22]. Our technique
may be applicable in some peer-to-peer auditing schemes,
but we focus on the client-server setting here.
Our approach to validating client-side execution utilizes
symbolic execution, a technique that has seen signiﬁcant
interest in the security community for generating vulnera-
bility signatures [3], generating inputs that will induce error
conditions [6, 41], automating mimicry attacks [24], and
optimizing privacy-preserving computations [36], to name
a few. A recent approach to generating weakest precondi-
tions has shown promise as a more efﬁcient alternative to
symbolic execution in some applications [4], and we plan
to investigate the application of this technique to our prob-
lem to make client checking even more efﬁcient.
3 Goals, Assumptions and Limitations
The defense that we develop in this paper addresses a
class of game cheats that Webb and Soh term Invalid com-
mands:
Usually implemented by modifying the game
client, the invalid command cheat results in the
cheater sending commands that are not possible
with an unmodiﬁed game client. Examples in-
cludegivingthe cheater’savatar greatstrengthor
speed. This may also be implemented by mod-
ifying the game executable or data ﬁles. Many
gamessufferthisformofcheating,includingcon-
solegamessuchas Gears of War. [38, §4.2.3]
Importantly, our technique will even detect commands that
are invalid in light of the history of the client’s previous
behaviors witnessed by the game server, even if those com-
mands could have been valid in some other execution. Sim-
ply put, our approach will detect any client game play that is
impossible to observe from the sanctioned client software.
We designed our cheat detection technique primarily for
use by game developers. As we present and evaluate our
approach, it requires access to source code for the game,
though potentially a similar approach could be developed
with access to only the game executable. The approach
should be attractive to game developers because it can save
them signiﬁcant effort in implementing customized server-
side veriﬁcation of client behaviors. Our approach is com-
prehensive and largely automatic; in our case study de-
scribed in §5, we needed only modest adaptations to an ex-
isting open-source game.
In order for detection to be efﬁcient, our technique de-
pends on certain assumptions about the structure of the
game client. We assume in this paper that the game client
is structured as a loop that processes inputs (user inputs, or
messages from the game server) and that updates the game
server about certain aspects of its status that are necessary
for multiplayer game play (e.g., the client’s current location
on a game map, so that the server can update other players in
the game with that location). Updates from the client to the
server need not be in exact one-to-one correspondence to
loop iterations. However, as the number of loop iterations
that execute without sending updates increases, the uncer-
tainty in the veriﬁer’s “model” of the client state also gen-
erally increases. This increase will induce greater server-
side computation in verifying that future updates from the
client are consistent with past ones. As we will see in §5, it
is useful for these updates from the client to indicate which
server-to-client messages the client has received, but impor-
tantly, the information sent by the client need not include the
user inputs or a full account of its relevant state. Indeed, it
is this information that a game client would typically send
today, and that we permit the client to elide in our approach.
Due to the scope of what it tries to detect, however, our
technique has some limitations that are immediately evi-
dent. First, our technique will not detect cheats that are per-
mitted by the sanctioned client software due to bugs. Sec-
ond, modiﬁcations to the game client that do not change
its behavior as seen at the server will go unnoticed by our
technique. For example, any action that is possible to per-
form will be accepted, and so cheating by modifying the
client program to make difﬁcult (but possible) actions easy
will go undetected. Put in a more positive light, however,
this means that our technique has no false alarms, assum-
ing that symbolic execution successfully explores all paths
through the client. As another example, a client modiﬁca-
tion that discloses information to the player that should be
hidden, e.g., such as a common cheat that uncovers parts of
the game map that should be obscured, will go unnoticed
by our technique. In the limit, a player could write his own
version of the game client from scratch and still go unde-
tected, provided that the behaviors it emits, as witnessed by
the server, are a subset of those that the sanctioned client
software could emit.
could in fact have been produced by a valid game client.
Toward that end, a key step of our approach is to proﬁle
the game client’s source code using symbolic execution and
then use the results in our analysis of observed client out-
puts. We begin with a summary of symbolic execution in
§4.1, and then discuss its application in our context in §4.2–
§4.6. The symbolic execution engine that we use in our
work is KLEE [5], with some modiﬁcations to make it more
suitable for our task.
Before we continue, we clarify our use of certain termi-
nology. Below, when we refer to a valid client, we mean a
client that faithfully executes a sanctioned game-client pro-
gram (and does not interfere with its behavior). Values or
messages are then valid if they could have been emitted by
a valid game client.
4.1 Symbolic Execution
Symbolic execution is a way of “executing” a program
while exploring all execution paths, for example to ﬁnd
bugs in the program. Symbolic execution works by exe-
cuting the software with its initial inputs specially marked
so they are allowed to be “anything” — the memory regions
of the input are marked as symbolic and are not given any
initial value. The program is executed step-by-step, build-
ing constraints on the symbolic variables based on the pro-
gram’s operations on those variables. For example, if the
program sets a ← b + c, where a, b, and c are all marked
as symbolic, then after the operation, there will be a new
logical constraint on the value of a that states that it must
equal the sum of b and c. When the program conditionally
branches on a symbolic value, execution forks and both pro-
gram branches are followed, with the true branch forming
a constraint that the symbolic value evaluates to true and
the false branch forming the opposite constraint. Using this
strategy, symbolic execution attempts to follow every pos-
sible code path in the target program, building a constraint
for each one that must hold on execution of that path.
Symbolic execution can help locate software bugs by
providing constraints that enable a constraint solver (KLEE
uses STP [13]) to generate concrete inputs that cause errors
to occur. For example, if execution reaches an error con-
dition (or a state thought to be “impossible”), then a con-
straint solver can use the constraints associated with that
path to solve for a concrete input value which triggers the
error condition. Having a concrete input that reliably repro-
duces an error is a great help when trying to correct the bug
in the source code.
4 Our Approach
4.2 Generating Constraints
Our detection mechanism analyzes client output (as seen
by the game server) and determines whether that output
The ﬁrst step of our technique is identifying the main
event loop of the game client and all of its associated client
state, which should include any global memory, memory
that is a function of the client input, and memory that holds
data received from the network. These state variables are
then provided to the symbolic execution tool, which is used
to generate a constraint for each path through the loop in a
single round. These constraints are thus referred to as round
constraints.
key ← readkey();
if key = ESC then
endgame();
100: loc ← 0;
101:
102: while true do
103:
104:
105:
106:
107:
108:
109:
110:
111:
112: end while
else if key = ‘↑’ then
loc ← loc + 1;
else if key = ‘↓’ then
loc ← loc − 1;
end if
sendlocation(loc);
endgame();
key ← symbolic;
if key = ESC then
200: prev loc ← symbolic;
201: loc ← prev loc;
202: while true do
203:
204:
205:
206:
207:
208:
209:
210:
211: