title:Too Late for Playback: Estimation of Video Stream Quality in Rural
and Urban Contexts
author:Vivek Adarsh and
Michael Nekrasov and
Udit Paul and
Alexander Ermakov and
Arpit Gupta and
Morgan Vigil-Hayes and
Ellen W. Zegura and
Elizabeth M. Belding
Too Late for Playback: Estimation
of Video Stream Quality in Rural
and Urban Contexts
Vivek Adarsh1(B)
Arpit Gupta1
, Michael Nekrasov1
, Udit Paul1
, Alex Ermakov1
,
, Morgan Vigil-Hayes2
and Elizabeth Belding1
, Ellen Zegura3
,
1 University of California, Santa Barbara, Santa Barbara, USA
{vivek,mnekrasov,u paul,aermakov,arpitgupta,ebelding}@cs.ucsb.edu
2 Northern Arizona University, Flagstaﬀ, USA
PI:EMAIL
3 Georgia Tech, Atlanta, USA
PI:EMAIL
Abstract. The explosion of mobile broadband as an essential means of
Internet connectivity has made the scalable evaluation and inference of
quality of experience (QoE) for applications delivered over LTE networks
critical. However, direct QoE measurement can be time and resource
intensive. Further, the wireless nature of LTE networks necessitates that
QoE be evaluated in multiple locations per base station as factors such
as signal availability may have signiﬁcant spatial variation. Based on
our observations that quality of service (QoS) metrics are less time and
resource-intensive to collect, we investigate how QoS can be used to infer
QoE in LTE networks. Using an extensive, novel dataset representing a
variety of network conditions, we design several state-of-the-art predic-
tive models for scalable video QoE inference. We demonstrate that our
models can accurately predict rebuﬀering events and resolution switch-
ing more than 80% of the time, despite the dataset exhibiting vastly
diﬀerent QoS and QoE proﬁles for the location types. We also illustrate
that our classiﬁers have a high degree of generalizability across multiple
videos from a vast array of genres. Finally, we highlight the importance
of low-cost QoS measurements such as reference signal received power
(RSRP) and throughput in QoE inference through an ablation study.
Keywords: QoE · Video streaming · Network measurement · LTE ·
Digital divide
1 Introduction
More than 60 million people reside in rural regions in the United States [18].
However, cellular deployment is often guided by economic demand, concentrating
deployment in urban areas and leaving economically marginalized and sparsely
populated areas under-served [27]. Few prior studies have focused on assessing
mobile broadband in rural areas of the U.S.; there is a lack of accessible datasets
that are not only comprehensive (include network-level and application-level
c(cid:2) Springer Nature Switzerland AG 2021
O. Hohlfeld et al. (Eds.): PAM 2021, LNCS 12671, pp. 141–157, 2021.
https://doi.org/10.1007/978-3-030-72582-2_9
142
V. Adarsh et al.
traces) but also representative and inclusive of rural demographics. As a result
of the COVID-19 pandemic, the assessment of the quality of experience (QoE)
for applications delivered over mobile broadband has become urgent as stay-
at-home orders and rapid movement to online schooling and work-from-home
protocols increase the demand for applications that are known to be sensitive
to network quality, such as video streaming and interactive video chat [50]. As
a result, communities without access to usable, high speed broadband, such as
many rural communities, are particularly disadvantaged [8,32].
Unfortunately, the evaluation of user quality of experience for video stream-
ing applications accessed over LTE in regions where people are most likely to be
smartphone dependent [27,28,34] poses a signiﬁcant scalability challenge. QoE
metric collection over LTE networks in a geographic area requires time and
resource intensive measurements for each network provider. As a result, exper-
iments at a single geographic point can be quite lengthy. Moreover, in rural
areas, obtaining LTE Internet measurements in places where people are likely to
use mobile broadband (e.g., at their homes or along local transportation corri-
dors) can be challenging [49], as places of interest are far apart (requiring more
resource intensive targeted measurement campaigns) and less densely populated
(prohibiting representative crowd-sourcing measurement eﬀorts). It is in this con-
text that we ask the following research question: How can we infer the QoE for
video streaming applications over LTE at scale?
While there are few to no existing datasets that measure QoE in rural com-
munities, there are many public and proprietary datasets that report quality
of service (QoS) metrics, such as reference signal received power (RSRP) or
throughput. These metrics are typically reported independently and are mea-
sured over LTE networks in a wide range of locations throughout the U.S. and
globally [46,51–53,59,63]. We argue that the wealth of LTE-QoS data points
across the U.S. represents a key resource that can be leveraged to broadly assess
QoE: while measuring QoE at scale in LTE networks presents signiﬁcant chal-
lenges, measuring QoS at scale in LTE networks has already been demonstrated
to be feasible. Hence, our goal, and key contribution, is a methodology that can
leverage low-cost QoS measurements to predict QoE.
To study the correlation between mobile QoS and QoE performance, a diverse
set of network measurements that are representative of a wide-range of conditions
is needed. As such, we undertook an extensive measurement campaign to collect
16 datasets comprised of network traces from the Southwestern U.S. for four
major telecom operators: AT&T, Sprint, T-Mobile and Verizon. Our datasets
vary along two primary axes: population density, and network load. To obtain
data from varied population densities, we collected LTE network measurements
within multiple rural and urban communities. For variable network load, we col-
lected LTE network traces from crowded events in urban locations that resulted
in atypically high volumes of network utilization [5] and, as a result, congestion.
We also collected traces from the same urban locations during typical operating
conditions as a baseline. Our datasets have broad spatial and temporal variabil-
ity, but can be classiﬁed into three primary categories: under-provisioned (rural),
Too Late for Playback
143
congested (congested urban), and well-provisioned (baseline urban).1 We lever-
age these varied datasets to demonstrate the generality of the inference method.
Based on our analysis, we show that predictive models can be used to infer video
QoE metrics using low-cost QoS measurements, so that QoE can be more easily
and scalably determined within diﬃcult to assess regions.
Our key contributions and ﬁndings include:
– We collected sixteen measurement datasets2 from twelve locations through an
extensive ; ground measurement campaign within the Southwestern U.S. Our
data points are representative of three diﬀerent network conditions: under-
provisioned (rural), congested urban and well-provisioned urban, and include
over 32 Million LTE packets. (Sect. 2);
– We develop and evaluate a comprehensive set of predictive models that infer
video QoE from low-cost QoS measurements such as RSRP and throughput.
Our analysis reveals that predictive models can infer video QoE with an
accuracy of at least 80% across all locations and network types (Sect. 3);
– We validate our models across multiple video types from a wide variety of
genres. Further, we demonstrate the utility of low-cost RSRP measurements
for inferring video QoE (Sect. 3).
2 Methodology and Datasets Overview
QoS metrics, such as received signal strength, latency, throughput, and packet
loss, capture the state of network connectivity. However, while QoS provides an
indication of network state, there can be a disconnect between QoS and user
experience. QoS network metrics are not Pareto-optimal; one element can get
better or worse without aﬀecting the other. Consequently, estimation of user
experience requires the incorporation of multiple network measures, which may
be unique to time, space and application. Note that while the deﬁnition of QoE
can vary depending on the vantage point from which measurements are taken,
we only focus on application-level QoE. Our measurements are active end-user
device/passive user as deﬁned in [61].
2.1 QoS and QoE Metrics
In this section, we describe the QoS and QoE metrics we collected (and esti-
mated) for this measurement study, as summarized in Table 1.
Quality of Service Metrics: We collect reference signal received power (RSRP)
and throughput synchronously on the same user equipment (UE). RSRP is
deﬁned as the linear average over the power contributions (in Watts) of the
1 Through extensive analysis, we veriﬁed that our datasets are representative of the
network characteristics we anticipated: well-provisioned, congested, and/or under-
provisioned. We omit that analysis from this paper due to space constraints.
2 The subset of our dataset that we have permission to release is available at [4].
144
V. Adarsh et al.
Table 1. Overview of QoS and QoE metrics at each location, aggregated across avail-
able providers.
Type Metric
Test Interval
Number of Datapoints
Tools
QoS
QoE
RSRP
Throughput
Video resolution
Resolution switches
Rebuﬀering events
1 second
1 second
1 second
1 second
1 second
2160
2160
2160
2160
2160
Network Monitor
iPerf
Selenium, iframe API
Selenium, iframe API
Selenium, iframe API
resource elements that carry cell-speciﬁc reference signals within the measure-
ment frequency bandwidth [2] and, as illustrated by [7], is widely accessible
through mobile operating systems. We record instantaneous RSRP readings from
the UEs every one second through the Network Monitor application [43]. We mea-
sure throughput by fetching a pre-speciﬁed 500 MB ﬁle from an AWS instance in
Virginia using iPerf over TCP to download the ﬁle. The large ﬁle size allows the
data traﬃc to ﬁll the pipe and to minimize the eﬀect of slow start. We log the
packet traces at the client during the iPerf tests in order to sample throughput
at 1 s intervals.
Quality of Experience Metrics: We focus on streaming video, currently
the most heavily used QoE-centric service in mobile networks [36]. Internet
video streaming services typically use Dynamic Adaptive Streaming over HTTP
(DASH) [60] to deliver a video stream. DASH divides each video into time inter-
vals known as segments or chunks, which are then encoded at multiple bit rates
and resolutions. To analyze video stream quality, we gather two QoE metrics:
resolution switches and rebuﬀering events. For resolution switches, we compute
the number of consecutive samples that had a diﬀerent resolution as a percent-
age of the total number of samples collected during the video. We measure at
one-second granularity, which captures resolution switches that happen between
video chunks that are typically 4–5 s long [15]. Finally, a rebuﬀering event occurs
when video pauses while the application buﬀer waits to accumulate enough con-
tent to resume playback. We record the video state (rebuﬀering event or normal
playback) every second.
2.2 Measurement Suite
We run our measurement suite on Lenovo ThinkPad W550s laptops, each of
which are tethered to their own Motorola G7 Power (Android 9) via USB in
order to measure cellular performance. The cellular plans on all our cellular user
equipment (UE) have unlimited data and are hot-spot enabled to eﬀectively
achieve the same level of performance as we would on the mobile device. We run
our measurement suite on laptops tethered to phones; this conﬁguration gives us
the same application performance while facilitating ease of programming, data
extraction, and uniﬁcation of application-level measurements.
Too Late for Playback
145
We choose YouTube as the streaming platform because of its popularity in
the U.S., capturing over 88% of the mobile market [62]. To collect video QoE
metrics, we run a 3-min clip of a Looney Tunes video [64], three times across
each of the four LTE providers at each location; we exclude from our results
the sessions that experienced playback errors during execution. We chose this
particular video due its mix of high and low action scenes, which result in vari-
able bitrates throughout the video (typically, high action scenes have a higher
bitrate than low action scenes). After testing multiple playback duration, we
observed that a 3-min window was adequate for the playback to reach steady
state, while long enough to capture rebuﬀering and/or resolution switches that
occur. To infer video QoE, we collect the input features (RSRP and throughput)
synchronously, on a separate device so as not to bias the video streaming mea-
surements. Synchronous measurements of throughput, RSRP and QoE metrics
are required to train learning algorithms to infer video QoE for a future time
instance. We use diﬀerent servers for throughput and YouTube tests so that we
can obtain concurrent QoS and QoE measurements. Our setup reﬂects the real
world scenario where throughput test servers and YouTube servers are separate
while simultaneously aﬀected by varying conditions from within the cellular net-
work [6]. In LTE, each bearer (connection from a UE) enjoys a relatively isolated
data tunnel before the egress from the packet gateway, located inside the core [1].
This reduces contention among UEs competing for resources at a single eNodeB,
and as a result we can accurately record QoS and QoE metrics on two separate
devices.
To execute this experiment, we ﬁrst automate the loading and playback of