acter set” [17]. As mentioned in Section 2, text may have
custom encodings, but here we ﬁnd they are not permit-
ted by Turnitin. This disallows any attack where text,
gibberish in appearance, is translated via decoding into
legible text. However, no restriction on fonts is in place,
due to the necessary ability for Turnitin’s client institu-
tions to specify their own format requirements.
Document Indexing: Extracting topics from a docu-
ment is somewhat of a subproblem to the larger issue of
document indexing. As information highly relevant to a
search may appear in a small portion of a document, sim-
ply relying on the overall topic of every document to in-
fer relevancy to a search may miss some useful results. A
search engine should do more than simply topic model-
ing to show results for a query. In fact, Google uses more
than 200 metrics to determine search relevancy [18], in-
cluding its famous PageRank system of inferring quality
of a site based on the number of sites linking to it [19].
USENIX Association
26th USENIX Security Symposium    835
Though documentation is sparse on other search en-
gines such as Bing or Yahoo, Google does host some
discussion of its treatment of PDF ﬁles.
It states that
they can index “textual content . . . from PDF ﬁles that
use various kinds of character encodings” [20] but that
aren’t encrypted. “If the text is embedded as images, we
may process the images with OCR algorithms to extract
the text” [20], but for our content masking attack, text is
not embedded as images, so logically the system would
not perform OCR. Our experiment ﬁnds out for sure for
Google, Bing, Yahoo, and DuckDuckGo in Section 6.2.
3 Masking Font Creation
The content masking attack is facilitated by the ability
to embed custom fonts within PDF documents. In fact,
having all fonts embedded is a formatting requirement
for the submission of academic papers to conferences.
However, no integrity check is performed on those fonts
as to the proper correlation between text strings within
the PDF ﬁle and the respective glyphs rendered in the
PDF viewer. An attacker may map characters to arbitrary
glyphs and alter the text extracted from a PDF document
while it appears unchanged to humans in a PDF viewer.
This requires two steps, ﬁrstly to create the requisite font
ﬁles and secondly to encode the text via these font ﬁles.
The ﬁrst step may employ one of the multiple open
source multi-platform font editing tools such as Font-
Forge [21]. With this tool, one can open a font and di-
rectly edit the character glyphs with the typical vector
graphics toolbox, or copy the glyph for a character and
paste it into the entry for another character. One can then
edit the PDF ﬁle directly with open source tools such
as QPDF [22], or in the case of manipulating academic
papers, quicken the process by adding custom fonts in
LATEX, and aliasing each to a simple command [23]. We
employ the latter method for its greater ease.
It em-
ploys the program ttf2tfm, included with LATEX, to con-
vert TrueType fonts to “TeX font metric” fonts which are
usable by LATEX. Two LATEXcode ﬁles are supplied by
[23]: T1-WGL4.enc for encoding, and t1custom.fd for
easy importing of the font into a LATEXdocument.
The second step of choosing how to mask this con-
tent and what in a document to encode with custom fonts
depends on the system targeted, and the technique and
evaluation for each of the three scenarios introduced in
Section 1 appears in the following three sections.
4 Content Masking Attack Against Con-
ference Reviewer Assignment Systems
As learned in Section 2, topic matching works from
groups of words constituting the main topic of the doc-
ument. Assignment of conference paper submissions to
reviewers is accomplished by ﬁnding the highest similar-
ity between detected topics within submissions and those
within a corpus of reviewers’ papers. Meanwhile, a lazy
paper writer may wish to collude with speciﬁc review-
ers, know of some more generous to papers, or just think
reviewers may be less critical of papers not within their
specializations. This lazy writer needs to change the pa-
per topic to target a speciﬁc reviewer, replacing words
corresponding to the topic of the paper with words com-
prising the topic of a paper from the reviewer’s corpus,
while being masked as the original words to still make
visual sense. We now discuss the challenges for this at-
tack and methods to target one or more reviewers, and
subsequently evaluate the attack efﬁcacy.
4.1 Construct Word and Character Maps
We primarily require a list of original words within the
subject document to change, and a list of words from the
target document to which to change these original words.
The new words will then be masked to display as the
original words using the masking fonts described in Sec-
tion 3. First, any stopwords within the document should
be eliminated from consideration. These are common
words within the paper’s language, such as “the,” “of,”
“her,” or “from.” Stopwords may be removed by using
existing tools like the Natural Language Toolkit (NLTK)
Python package [24]. From here an attacker can replace
the most frequently used words in the subject paper with
the most frequently used words in the target reviewers
paper. This will result in the most frequently used words
in the target paper also appearing in the subject paper, for
a high similarity score as measured by the LSI method
within the automatic reviewer assignment system.
Consider word lists A and B having constituent words
{a1,a2, ...,an} and {b1,b2, ...,bn} which are in descend-
ing order of appearance within the subject and target pa-
pers, respectively. An attacker wishes to replace words
A with topic B and must therefore replace each word
ai within the text of the subject paper with a word
bi, encoded using some font(s) to render bi the same
graphically as ai (a word mapping). No other words
should/need be changed. Consequently, the objective is
to construct a mapping between the letters of each bi
and ai (a character mapping). If ai and bi are character
arrays {ai[1],ai[2], ...,ai[pi]} and {bi[1],bi[2], ...,bi[qi]},
then the attacker should construct a masking font such
that the character bi[1] maps to the glyph ai[1], bi[2] to
ai[2], etc. We may consider this analogous to a map data
structure, where bi[1] is a key and ai[1] its value, and so
on. Two challenges naturally arise in constructing the
required character mappings:
One-to-Many Character Mapping: From the brief
836    26th USENIX Security Symposium
USENIX Association
example in Section 1 of changing the word green to
brown, we know that in terms of a map data structure
there is a collision for the key e and the values o and
w, such that an attacker will require two masking font
“maps” to render green as brown. The ﬁrst challenge is to
minimize the number of fonts required in the document,
so as to avoid suspicion, while fully switching topic A
for B. This problem is not delimited by word: some
character mappings may be reused in the same or other
words, and many may not. Additionally, changing all of
the words in A to those in B may be unnecessary, which
also impacts the number of one-to-many mappings and
resultant number of required font ﬁles. If fewer words
must be changed while ensuring the required similarity
between papers, fewer fonts may be required, and a naive
font count threshold defense will be less effective.
Word Length Disparity: Further, the lengths pi and
qi of words ai and bi may differ, causing ai to be longer
than bi or vice versa. If pi > qi, to render bi as ai, a font
ﬁle entry is necessary for the letter bi[qi] mapping to the
last pi − qi + 1 letters of ai. Several additional fonts may
be necessary if some bi ∈ B have the same last character.
Thus, we deﬁne a favorable keyword mapping as a word
mapping bi → ai such that pi  qi then
(cid:46) unfavorable mapping
(cid:46) build fonts
else
(cid:46) equal word length
10:
11:
12:
13:
14:
C ← C∪{(bi[ j],ai[ j])}
for j ← 1 to pi do
C ← C∪{(bi[ j],ai[ j])}
for j ← pi + 1 to qi do
C ← C∪{(bi[ j], /0)}
for j ← 1 to qi − 1 do
rest ← combine {ai[qi], ...,ai[pi]}
C ← C∪{(bi[qi],rest)}
for j ← 1 to qi do
15:
16:
17:
18:
19:
20: x ← largest number of key collisions in C
21: temp ← C
22: for i ← 1 to x do
23:
24:
25:
26:
27:
28:
29:
30:
fi ← empty font
for each c ∈ C do
C ← C\{c}
use clearing font for key in c
C ← C\{c}
fi ← fi ∪{c}
C ← C∪{(bi[ j],ai[ j])}
if value in c is /0 then
F ← F ∪ fi
31:
32: C ← temp
33: return C,F
else if no key collision between c, fi then
USENIX Association
26th USENIX Security Symposium    837
OriginalTextMaskedTextblank(clearing font)Favorable MappingUnfavorable Mappingfrom this algorithm are fonts to be used for each charac-
ter of the words in B to mask them as the words in A. If
the attacker has multiple papers under submission, this
process may be repeated independently for each paper.
4.3 Matching One Paper to Multiple Re-
viewers
For a better chance at cheating the peer review process
and to collude with multiple reviewers, the content mask-
ing attack can be adapted to split up the masked words
among two (or more) different lists of frequently used
words. Instead of mapping between word lists A and B,
the attacker will map between A and B and A and C, such
that a1 will be replaced with b1 part of the time and c1 the
rest of the time, and so on. The method is otherwise the
same as shown in Algorithm 1, but has its own challenge.
Intuition would suggest replacing a1 half of the time
with b1 and half of the time with c1. However, the re-
quirement for the attacker’s paper to be the most similar
of a large number of papers to a reviewer’s paper and
also the most similar of all others to another reviewer’s
paper is quite stringent. The intuitive method fails as
the similarity score for one target reviewer will be high
enough but the other too low. So we use an iterative re-
ﬁnement method which tunes the replacement percent-
ages according to the calculated similarity scores until
they are both the highest among their peers. This is gen-
eralizable to more than two reviewers, by reﬁning the
percentages proportionally according to the successive
differences in similarity scores between the subject pa-
per and each of the target papers. We match one paper to
three reviewers in Section 4.4, the typical number of re-
viewers to which papers are assigned (barring contention
in reviews, which would not happen during collusion).
4.4 Experiment
We have built a conference simulation system reproduc-
ing the INFOCOM automatic assignment process de-
scribed in [9]. We imported into this system 114 TPC
members from a well-known recent security conference
as reviewers, and downloaded a collection of each of
these reviewers’ papers published in recent years. In to-
tal, this comprised 2094 papers used as training data for
the automatic reviewer assignment system. For testing
data, we also downloaded 100 papers published in the
greater Computer Science ﬁeld. Our experiment, then,
is to test the topic matching of the test papers with the
training papers, via our content masking attack. Follow-