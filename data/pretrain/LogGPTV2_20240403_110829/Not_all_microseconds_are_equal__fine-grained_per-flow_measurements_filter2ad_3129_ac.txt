l
y
a
e
D
Regular
packets
Error in 
delay estimate
Interpolated
Delay
Reference
Packet
Time
Figure 3: Key idea in our architecture is to estimate packet
delays by interpolating the reference packet latencies.
3.2 RLI architecture
Intuitively, queueing delay, which is the major portion of delays
experienced in routers, can be thought of as a continuous function
(not necessarily monotonic) in busy periods where there are pack-
ets to send. In Figure 3, we show the variation of delay as time
progresses at the sender side. We can observe that the delay expe-
rienced by each of the regular packets can be estimated accurately
from a few reference delay samples (shown as circles in the ﬁgure)
by interpolating these reference packet delay samples (shown by
a dotted line in the ﬁgure). Further, the interpolation error can be
controlled by varying the number of reference points in the delay
curve, thus trading-off accuracy for resource usage. This is the key
idea exploited in our architecture.
Our architecture consists of two main components: a reference
packet generator at the sender side, and a latency estimator at the
receiver that maintains a few counters on a per-ﬂow basis. The
reference packet generator injects reference packets with sender
timestamps periodically into the packet stream at the ingress inter-
face of a router. These reference packets would experience queue-
ing and other effects similar to that of the regular packets thus pro-
viding a stream of reference delay samples for the latency estimator
at the receiver end. The latency estimator estimates the delay of a
regular packet using these reference delay samples that are then
accumulated into the per-ﬂow counters.
3.2.1 Reference packet generator
A key question concerns when to generate the reference packet.
One option is to inject them according to a Poisson distribution.
While in the past, Poisson-modulated probes have been advocated
by researchers [28] since they capture time averages very well, our
goal is not to compute the average behavior of the queue over a
given time. Instead, we wish to use these reference packets to esti-
mate individual packet delays, and thus, Poisson modulation is not
a requirement in our system. Furthermore, we wish to bound the
interprobe time in order to control the impact of probes on back-
ground trafﬁc, whereas Poisson probes can have arbitrarily small
interprobe times.
There are three choices we ﬁrst consider: The ﬁrst is to inject one
reference packet for every n regular data packets (e.g., n = 1000).
Besides being simple to implement, this 1-in-n reference packet
injection has a bounded overhead in terms of number of additional
packets injected as a function of the total number of packets. The
problem, however, is that there could be periods of low utilization
when these reference packet can be spaced apart signiﬁcantly, po-
tentially affecting the accuracy of the interpolation estimates. To al-
leviate this, an alternate solution is to inject an active probe packet
31Algorithm 1 Reference packet injection rate adaptation
1: procedure CALCULATE-INJECTION-RATE
(cid:4) reﬀ : effective injection rate
2:
(cid:4) drp: duration between two reference packets (RPs)
3:
(cid:4) cb: byte counts of regular packets between RPs
4:
(cid:4) uest : moving-averaged link utilization
5:
(cid:4) umin , umax: minimum, maximum link utilization
6:
(cid:4) rmin , rmax: minimum, maximum injection rate
7:
(cid:4) α: EWMA smoothing factor
8:
(cid:4) lc: link capacity
9:
uinstant ← cb/drp/lc
10:
uest ← uinstant · α + uest · (1 − α)
11:
cb ← 0
12:
ueﬀ ← uest , where umin ≤ uest ≤ umax
13:
reﬀ ←
14:
return reﬀ
15:
16: end procedure
)2(rmax − rmin ) + rmin
1 − ( ueﬀ −umin
umax −umin
(cid:3)
every τ time period (e.g., τ = 1ms). While this can result in a
ﬁxed worst case bandwidth requirement, this may provide worse
results when the utilization is higher, especially when the delay
variations are quite rapid. Lastly, we may combine these two ap-
proaches by injecting a packet every 1-in-n, or after τ seconds,
whichever comes ﬁrst. Unfortunately, it is not clear how to iden-
tify the right value of τ . On one hand, keeping τ low increases
accuracy but causes too much overhead and starts to interfere with
regular packets. On the other hand, setting a high value of τ defeats
the purpose of setting an upper bound on the time-period.
Thus, we consider monitoring the utilization in a dynamic fash-
ion in order to determine at what time instants to inject the packets.
We ﬁnd that this adaptive scheme performs better than either of the
ﬁxed time based or count based schemes just described. Adapting
the probe rate to utilization enables us to get the best of both worlds:
limiting the probe rate at high utilizations, while getting sufﬁciently
frequent coverage at low utilizations. Still, adaptive schemes entail
a subtle trade-off because the adapter may lag in response to a high
rate burst of shorter duration than its adaptation timescale. In prac-
tice, however, we have not found such phenomena to degrade the
performance experienced by background trafﬁc.
Although we expect the advantage of adaptation to be generic,
we now discuss the particular form of realization in our implemen-
tation. To keep track of link utilization and adjust reference packet
rate, we maintain small amount of state. Speciﬁcally, our adap-
tive scheme consists of two steps: updating link utilization and cal-
culating effective reference packet rate. Algorithm 1 presents the
pseudocode for the scheme. The algorithm is triggered right after a
reference packet is injected with the previously calculated effective
reference packet rate reﬀ .
To estimate link utilization, we maintain a byte counter cb that
keeps track of the number of regular packets between two injected
reference packets. We also maintain the time interval drp between
the two injected reference packets. We calculate instantaneous link
utilization using these two variables and link capacity lc. We could
use the instantaneous link utilization uinstant directly to calculate
effective reference packet rate, but, in order to remove the effects
of short term ﬂuctuations of estimated link utilization, we update
average link utilization uest using exponentially weighted moving
average (EWMA) with a smoothing factor, α. We reset the byte
counter immediately after link utilization estimation is done.
After updating uest , we calculate the next reference packet rate.
Our objective is to adapt reﬀ as a function f of link utilization,
Packet
Stream
Utilization
statistics
Create 
Reference Packet
Packet
Stream
Interpolation Buffer
Update
per−flow
delay
Flow selection
Logic
Flow Memory
Reference 
Packet
Generator
Latency 
Estimator
Sender Timestamp
Sender 
Receiver
Figure 4: Overview of our architecture.
where rmax = f (umin ) and rmin = f (umax ), umin and umax
being conﬁgurable parameters. Thus, we bound ueﬀ to ensure that
ueﬀ always lies in between umin and umax . If uest is higher (lower)
than umax (umin), we set ueﬀ is set to umax (umin). While there
could be many choices for the function f , we choose an elliptical
function (shown in line 14) and calculate reﬀ . The rationale for
choosing this function is that, it typically targets accurate estima-
tion of latency under low to moderate utilization (i.e., decreases
ref f slow when uef f is close to umin), but reduces rate signiﬁ-
cantly at high utilization (as uef f approaches umax). For our eval-
uation, we set umin = 0.6 and umax = 0.85, while rmin and rmax
are set to 1-in-300 (0.0034) and 1-in-10 (0.1) respectively.
3.2.2 Latency estimator
The receiver processes the reference packets (containing times-
tamps) inter-mixed with regular data packets to estimate per-packet
latencies. Our architecture does not require the receiver to maintain
counters for all ﬂows in the network. Indeed, our architecture can
work on top of any existing framework for per-ﬂow measurements
such as NetFlow, that maintain ﬂow records (containing number of
packets, bytes, etc.) for a small subset of ﬂows. For each of the
ﬂows of interest (obtained using any ﬂow sampling schemes), we
maintain three counters indexed by the ﬂow key that keep track of
the following: (1) number of delay samples for the ﬂow; (2) sum
of estimated delays for all packets of that ﬂow; (3) sum of squares
of individual packet delays. This composite set of counters are
updated for all packets that belong to ﬂows of interest. It is, there-
fore, important to implement these counters in high-speed SRAM
to scale to high line rates. (We discuss other alternatives later in
§6.)
Our latency estimator component also contains an interpolation
buffer (as shown in Figure 4) to store packets that have arrived be-
tween two reference packets. This requirement stems from the fact
that delay value estimated for each individual packet is a function
of the delay experienced by the two reference delay samples (cor-
responding to the reference packets). Of course, we do not need
to store the entire packet in the interpolation buffer; storing just
the ﬂow key, the associated timestamp and byte count are sufﬁcient
for each packet. The size of the interpolation buffer required can
be statically determined depending on the design of the reference
packet generator. If reference packets are generated according to
the 1-in-n scheme, the interpolation buffer need not be larger than
n. For other schemes, we can easily compute an upper bound on
the number of packets between two active probes. For instance, for
the 1-in-τ scheme, we can easily compute the number of minimum-
size packets for a given link capacity that can be transmitted in τ
seconds; this dictates the size of the interpolation buffer.
32While the presence of the interpolation buffer in our architec-
ture facilitates the use of both left and right reference packets to
estimate delay for a given packet (potentially allowing better accu-
racy), it requires additional complexity in state maintenance. At the
other end of the trade-off, we can imagine getting rid of the buffer
completely and estimate the delay of a packet as a function of only
the reference packet before the packet, but not after. This requires
no state in terms of the interpolation buffer, but requires remem-
bering the delay experienced by the reference packet, that can be
easily kept track of using a single counter.
3.3 Packet delay estimators
i be an i-th reference packet. Let pr
We formally describe our packet delay estimators in this sec-
tion. The ﬁrst estimator called RLI estimator1 utilizes two refer-
ence packets for linear interpolation and works as follows.
RLI estimator. Let pa
j , j =
1, 2, . . . , n be a regular packet whose receiver timestamp is located
between al = pa
i+1 that represent the left and right
j and br
reference packets in the interpolation buffer. Let τ r
j denote
the receiver-side timestamp and a byte count of pr
j , and τl, τr rep-
resent the receiver-side timestamps of al and ar. Let b be the size
of reference packet and lc be the link capacity. Then the estimated
delay, ˆdj for pr
j obtained by interpolating the delays of al and ar
(represented as dl and dr) is given as:
i and ar = pa
ˆdj = dl + (τ r
j − τl)
, j = 1, 2, . . .
(1)
dr − dl
τr − τl
j − b
br
lc
+
The third term on the right-hand side in Equation (1) compensates
for different serialization times by the difference in packet size be-
tween regular packets and reference packet. Whenever a new probe
packet arrives, al and ar are updated; subsequent interpolated de-
lays of new regular packets are computed with these new values as
given by Equation (1).
For each ﬂow fk, three per-ﬂow counters are maintained as we
discussed before. After the delay estimate is computed for the
packet pr
j be-
longs are updated as follows.
j , the counters corresponding to the ﬂow to which pr
c(fk) = c(fk) + 1
m(fk) = m(fk) + ˆdj
v(fk) = v(fk) + ˆdj
2
(2)
(3)
(4)
When a ﬂow with a ﬂow key fk expires, if (cid:4)m(fk), (cid:4)v(fk), and
(cid:4)c(fk) represent the ﬁnal values of the number of, mean and vari-
ance counters in ﬂow memory, then the delay mean and variance of
a ﬂow fk are:
E[dfk ] = (cid:4)m(fk)/(cid:4)c(fk)
Var[dfk ] = (cid:4)v(fk)/(cid:4)c(fk)2 − E[dfk ]2
(5)
(6)
where dfk denotes a random variable for delays of packets of a
ﬂow with fk. These values are updated before exporting the ﬂow
record.
RLI-L estimator. The RLI estimator requires storing packets in
an interpolation buffer until a reference packet arrives after which
each of the packets’ delays are updated, that requires additional
complexity. Thus, we consider an alternative estimator called RLI-
L estimator that instead of using both the left and right delay sam-
ples uses only the left delay estimate. In other words, for all regular
packets that appear between pa
i+1 with delays dl and dr,
i and pa
ˆdj = dl + (br
j − b)/lc.
1We use RLI estimator to refer to the estimator and just RLI to refer
to the architecture.
Name
CHIC
SANJ
#ﬂows
4.56M
4.87M
#packets
131.42M
213.80M
WEB468
WEB700
0.143M
0.214M
2.61M
3.99M
Link: OC-192 (10 Gbps), Duration: 600s.
pkts/ﬂow
Date
28.8
43.9
Apr. 30 17:00:00 2008 UTC
Dec. 18 05:55:00 2008 UTC
Link: OC-3 (155 Mbps), Duration: 305s.
Feb 6 02:06:58 2006 UTC
18.25
18.65
Feb 6 02:15:32 2006 UTC
Table 2: Trace characteristics: CHIC and SANJ are OC-192