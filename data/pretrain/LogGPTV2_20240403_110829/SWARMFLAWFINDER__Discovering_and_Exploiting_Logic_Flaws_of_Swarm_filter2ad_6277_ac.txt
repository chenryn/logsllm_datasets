drone tends to ﬂy toward the west more to avoid the
obstacle (∆6). In the original swarm mission, the leader
ﬂies toward the south-east to avoid Drone 2.
Fig. 5-(g) shows DCC values computed from the perturbed
executions at the moment illustrated in Fig. 5. For each victim
drone, it is the percentage of aggregated ∆ values. Note that
we collect DCC values throughout the entire swarm mission.
Algorithm for DCC Computation. SwarmDcc() in Algo-
rithm 1 shows the algorithm to compute DCC values. Specif-
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:38:51 UTC from IEEE Xplore.  Restrictions apply. 
61813
Direction of the attack drone/ obstaclesDirection to the next position with perturbationsDirection to the next position without perturbationLegendDelta (Δ1)Attack drone(a) Original swarm mission(b) Perturbation 1: without the obstacle(c) Perturbation 2: without the attack droneDelta (Δ2)Delta (Δ3)(e) Perturbation 4: without Drone 1Drone 1LeaderDrone 2(d) Perturbation 3: without Leader(f) Perturbation 5: without Drone 2Delta (Δ5)Delta (Δ6)Delta (Δ4)Δ1(Obstacle)Δ4(Leader)(g) Degree of causal contribution (Dcc) valuesDrone 1Δ3(Attack drone)Δ5(Leader)Drone 2Δ2(Attack drone)Δ6(Drone 2)LeaderPose difference (delta) caused by perturbationsObstacleically, DCC values are computed for each victim drone spec-
iﬁed by Dv. The for loop from line 4 to line 16 describes
the DCC computation for each drone. SWARMFLAWFINDER
runs multiple tests with perturbations that remove one of the
attack drones (Da), obstacles (Ow), and the victim drones
(Dv) speciﬁed as input (Lines 8∼14). In particular, Pi (line
11) and Porg (line 7) represent the pose of a drone with
and without the perturbation. We then compute the euclidean
distance between the two trajectories (∆i at line 12, which is
essentially ∆ in Fig. 5). To understand the attack’s impact on
the entire swarm, we compute all the delta values for all victim
drones (see the nested for loops at lines 4∼16 and 8∼14).
DCC is computed by adding all the delta values computed
(line 13) and then calculating each delta value’s proportion in
the total accumulated delta value (in percentage) (lines 15∼16).
C. DCC Guided Fuzz Testing
Abstracting Swarm Missions via DCC. Fig. 6 shows a
series of DCC values computed throughout the swarm mission
(0∼180 ticks). X-axis and Y-axis represent
the time and
stacked ∆ values, respectively. Intuitively, we use the series of
DCC values to represent a swarm mission. When we identify
two tests that have a similar series of DCC values, we consider
them similar. To compare two number series, we leverage NCC
(Normalized Cross Correlation) [25] which is commonly used
to compute the similarity between data in various ﬁelds [26]–
[28]. Fig. 6 shows examples of NCC scores from different
DCC values: (a) shows Dcc values from the original execution.
(b) and (c) are DCC values from two different runs. Note that
when DCC values from two executions have different lengths
(i.e., running time), we scale one of the execution’s DCC
values to another execution (i.e., interpolation), then compute
the NCC. However,
if two executions’ running times are
different more than two times, we consider they are different.
Fig. 6. Example of NCC scores from three executions.
Using NCC [25] of DCC Values to Guide Testing. After
every test, we store observed DCC values from the test.
Then, we determine whether the current test exercises new
the current
behaviors of the swarm by computing NCC scores with the
previously observed (and stored) DCC values (lines 26∼32
in Algorithm 1). Speciﬁcally, after each run, for each victim
drone, we compute NCC scores against all of the previously
observed DCC values for the victim drone. If there is a
previous test run with an NCC score larger than a threshold
(0.75∼0.87 in this paper, line 22 in Algorithm 1), we consider
that
test run is similar to the compared run,
meaning that we consider it did not exercise a substantially
new swarm behavior. Hence, we aim to mutate the test (i.e., the
pose and strategy) signiﬁcantly to derive the next test (line 35,
R representing a large random value). If there is no previous
test case with an NCC score smaller than the threshold, it
means that the current test has DCC values that have not been
seen yet. Then, we mutate the test slightly to derive a new test
since we may ﬁnd new swarm behaviors from a test similar to
the current test (line 37, δ representing a small random value).
Note that the NCC threshold value is conﬁgurable, and it
does not affect the validity of the testing. If the threshold
is ill-conﬁgured, SWARMFLAWFINDER may ﬁnish the testing
process early (if the value is too high) because signiﬁcantly
different test runs will be considered similar. If the conﬁgured
value is too low, the testing will take longer as it considers
more tests are different. To ﬁnd a proper NCC threshold, we
run 100 runs for the same initial test of a given swarm mission
(without any changes), and then take the lowest value of the
measured NCC scores as shown in Table II.
Algorithm. FuzzTesting() in Algorithm 1 describes the
entire fuzz testing process of SWARMFLAWFINDER including
measuring the swarms’ behaviors against attacks and mutating
tests based on the measured impacts. The algorithm takes
four inputs: (1) Dv: a conﬁguration of the victim drones,
including their poses and goals, (2) Da: a conﬁguration of
attack drones consisting of attack drones’ poses and strategies,
(3) Ow: objects such as walls and moving obstacles that affect
the victim and attack drones during the mission, (4) Ttimeout:
the time limit for the entire testing process. Typically, this is
set for longer than several hours (e.g., 24 hours). The output
(i.e., return) is Efailed which is a set of executions where the
missions were failed due to the conducted attacks (line 38).
D. Testing with Multiple Attack Drones
Algorithms that run signiﬁcantly distributed drone swarms
may require SWARMFLAWFINDER to test with multiple attack
drones. For example, for a swarm algorithm that maintains
a number of small swarm groups spread over a large area,
a single attack drone may only affect one of the groups,
making it difﬁcult
to ﬁnd a logic ﬂaw. To handle this,
SWARMFLAWFINDER automatically adds an additional attack
drone and repeats the testing if the entire testing process
failed to ﬁnd attacks. Note that adding N additional attack
drones causes roughly 5*N% overhead on average (for all the
algorithms we evaluated). Details of the number of additional
attack drones and additional overhead are presented in [8].
Mutating Tests with Multiple Attack Drones. As described
in § IV-A, a test run with multiple drones is deﬁned as a test
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:38:51 UTC from IEEE Xplore.  Restrictions apply. 
71814
147101316192225283134374043464952555861646770737679828588919497100103106109112115118121124127130133136139142145148151154157160163166169172175178147101316192225283134374043464952555861646770737679828588919497100103106109112115118121124127130133136139142145148151154157160163166169172175178147101316192225283134374043464952555861646770737679828588919497100103106109112115118121124127130133136139142145148151154157160163166169172175178DestinationFollower 2Follower 3Attacker 1Moving ObstacleWallLegend100806040200018016014012010080604020018016014012010080604020018016014012010080604020(b) Dccfrom the similar execution to (a) (NCC = 0.923, compared with (a))(a) Dccfrom the original execution(c) Dccfrom the different execution to (a) (NCC = 0.650, compared with (a))Dcc(%)100806040200Dcc(%)100806040200Dcc(%)case with multiple tuples such as{, , ..., }, where each tuple represents an attack drone. When
there are multiple attack drones in a test, we may observe the
changes of DCC values caused by multiple attack drones. It is
critical to identify which attack drone is effective in exercising
a new behavior of the swarm to choose the mutation strategy
(i.e., mutating signiﬁcantly or slightly as shown in lines 35
and 37 of Algorithm 1). We apply the mutation for each attack
drone (i.e., each tuple) so that DCC value changes caused by
an attack drone would not mutate the other attack drones.
For each attack drone, SWARMFLAWFINDER identiﬁes all
the victim drones’ DCC values that are affected by the attack
drone. There are two cases of victim drones affected by an
attack drone: directly and indirectly. First, the victim drone
is directly affected when we observe the attack drone’s delta
value in the victim drone’s DCC values. Second, the victim
drone is indirectly affected by the other victim drone that is
directly affected by the attack drone (i.e., a cascading effect).
To this end, we check the DCC values of the victim drones to
identify the drones affected by each attack drone and compute
the NCC values for the identiﬁed victim drones. We present
an example scenario with multiple attack drones on [8].
V. EVALUATION
A. Experiment Setup
1) Selection of Target Swarm Algorithms: We search open-
sourced research projects related to swarm robotics for the last
ten years, from 2010 to 2021. We listed 44 academic papers
and 29 public GitHub repositories from the initial search. From
the 44 papers, 17 of them provide source code, resulting in
46 available algorithms. However, 20 out of 46 algorithms are
not executable (e.g., the source code is incomplete and not
compilable) or partially implemented (e.g., only implementing
algorithm logic), leading to 26 runnable algorithms. Finally,
we prune out 22 out of 26 algorithms since they do not
exhibit collective (or cooperative) behaviors or allow external
objects such as our attack drones (hence cannot implement our
approach). Speciﬁcally, swarm algorithms that are a collection
of individual drones lacking cooperative interactions between
the neighbor drones [29]–[38] are not considered.1 To this
end, we choose four runnable algorithms that exhibit collective
swarm behaviors and allow us to introduce external objects.
Details of the selection process can be found in § IX-A.
SELECTED SWARM ALGORITHMS FOR EVALUATION
TABLE I
ID Name
SLOC Language Algorithm’s Objective
A1 Adaptive Swarm [4]
Multi-agent navigation
3,091 Python
A2 SocraticSwarm [5]
Coordinated search
9,920 C#
A3 Sciadro [6]
3,851 Netlogo
Distributed target search
A4 Pietro’s [7]
Coordinated search and rescue
752 Matlab
Selected Target Algorithms. Table I presents the selected
four swarm algorithms and Fig. 7 shows visualizations of the
swarm algorithms using the Gazebo simulator [39].
1If a drone in an algorithm does not recognize other drones as cooperating
units (e.g., other drones are considered as obstacles), we exclude the algorithm.
A1. Adaptive Swarm [4] aims to move a swarm of (up to
20) drones, from the current position to a predeﬁned
destination (shown as a yellow path in Fig. 7-(a)) while
maintaining a formation and avoiding obstacles.
A2. SocraticSwarm [5] conducts a swarm searching mission,
where individual drones actively interact with neighbor
drones to share information, as shown in Fig. 7-(b).
A3. Sciadro [6] runs multiple swarms to search targets dis-
tributed over a wide range of areas, as shown in Fig. 7-(c).
Swarm groups can be dynamically changing at runtime,
allowing individual drones joining and leaving a swarm.
A4. Pietro’s algorithm [7] aims to achieve a cooperative
rescue mission. Fig. 7-(d) shows an example mission:
searching and rescuing targets inside various structures.
The process is accelerated with more participating drones.
TABLE II
FUZZ TESTING CONFIGURATIONS
ID Completion
200%
time (sec) Deadline threshold
0.87
0.82
0.85
0.75
189.4
90.11
1,756.13
715.41
400
200
3,500
1,400
NCC Mutation # of victim Time for
testing
24 hrs
24 hrs
24 hrs
24 hrs
(δ / R)
0.4 / 0.8
50 / 100
25 / 50
10 / 5
drones
4
8
10
15
A1
A2
A3
A4
2) Experimental Conﬁgurations: Table II shows how we
deﬁne mission failures in the four selected swarm algorithms’
missions. We consider a swarm mission failed (1) if it takes
longer than two times of its typical mission completion time
to accomplish its given goals or (2) a drone in the swarm
crashes into an object or another victim drone. Note that we
do not try opportunistic attacks such as blocking the target
point to prevent the mission completion. Similarly, we do
not count attack drones crashing into the victim drone as a
failure. Our attack drones are designed not to crash into victim
drones directly. The third column deﬁnes the 200% deadline,
which is essentially the time we consider a mission fails if it
exceeds. They are roughly more than 200% of the completion
times. The fourth column shows the NCC threshold used in
the experiments for each algorithm. To get the typical mission
completion time and NCC threshold for each algorithm, we
run each mission 100 times and get an average completion
time without any interventions (i.e., without attack drones).
We also ﬁnd the NCC thresholds by taking the lowest NCC
values from the 100 test runs. The ﬁfth column shows the
distance values used to apply slight (δ) and signiﬁcant (R)
mutation in each algorithm. The sixth column shows the
number of victim drones for each algorithm, varying from
4 to 15 drones. Finally, the last column presents that we run
SWARMFLAWFINDER on each algorithm for 24 hours.
3) Implementation and Setup: We implement prototypes of
SWARMFLAWFINDER for each algorithm in the programming
language that the original algorithm is written in: Python, C#,
Netlogo, and Matlab. Our implementation includes modiﬁca-
tions of existing simulators/emulators. To this end, we write
839, 331, 422, and 230 SLOC for implementing SWARM-
FLAWFINDER for A1∼A4, respectively. Our analysis tool for
NCC and the map of A3 is written in R (820 lines).
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:38:51 UTC from IEEE Xplore.  Restrictions apply. 
81815
Fig. 7. Visualizations of the selected algorithms’ missions. Yellow and white circles indicate swarm drones and search/rescue targets or the destination.
TABLE III
FUZZ TESTING RESULTS
ID Mission Failure and Root Cause
# of Exec. Uniq. Confm.
Crash between victim drones
– C1-1: Missing collision detection
– C1-2: Naive multi-force handling
– C1-3: Unsupported static movement
Crash into external objects
– C1-1: Missing collision detection
– C1-2: Naive multi-force handling
– C1-3: Unsupported static movement
– C1-4: Excessive force in APF
Suspended progress
– C1-5: Naive swarm’s pose measurement
– C1-6: Insensitive object detection
Slow progress
– C1-6: Insensitive object detection
273
86
176
11
435
88
326
3
18
671
242
429
175
175
Total 1,554/1,724
Crash between victim drones
– C2-1: Overly-sensitive object detection
Suspended progress
– C2-2: Indeﬁnite wait for crashed drones
Slow Progress
– C2-3: Long deadline for assigned task
– C2-4: Drones detaching from a swarm
Total
Crash into external objects
– C3-1: Naive/faulty detouring method
– C3-2: Insensitive object detection
Slow progress
– C3-1: Naive/faulty detouring method
– C3-2: Insensitive object detection
Total
28
28
119
119
608
586
22
755/990
47
10
37
240
23
217
287/811
Crash between victim drones
– C4-1: Naive detouring method
– C4-2: Detouring without sensing
Crash into external objects
– C4-1: Naive detouring method
– C4-2: Detouring without sensing
Slow progress
– C4-3: Insensitive object detection
230
216
14
630
599
31
1,228
1,228
Total 2,088/2,469
A1
A2
A3
A4
9
4 –
4 –
1 –
8
3 –
3 –
1 –
1 –
2
1 –
1 –
1
1 –