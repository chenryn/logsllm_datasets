sets (except that the samples are i.i.d.), and can diﬀer-
entiate distributions based on “shape” and “location”,
but generally requires more samples than a parametric
test with a correct model of the data.
Both tests have a tunable rejection region, giving a tradeoﬀ
between false positive and false negative error rates, so no
single number characterizes the performance of either test.
Thus, we evaluate them using Receiver Operating Charac-
teristic (ROC) curves: each point on a classiﬁer’s ROC curve
corresponds to the true positive and false positive rates for
one setting of the rejection threshold. This curve illustrates
the diﬀerent tradeoﬀs between false positive and false neg-
ative rates for a classiﬁer: a perfect classiﬁer would corre-
spond to the single point in the upper left corner, while a
classiﬁer that cannot distinguish between positive and nega-
tive examples will result in (a subset of) the line from (0, 0)
to (1, 1). This tradeoﬀ is sometimes summarized by calculat-
ing area under the ROC curve (AUC), where higher values
indicate a “superior” classiﬁer; the perfect classiﬁer has AUC
1, while the nondiscriminating classiﬁer has AUC 0.5. See
Fawcett’s tutorial [14] for a more comprehensive treatment.
4.2 Evaluation
We tested the eﬀectiveness of this attack using clients and
servers from the PlanetLab wide-area testbed. Our evalua-
tion consisted of 641 “runs”, where each run performed the
following experiment. First, two random PlanetLab nodes
were chosen to be the clients A and B, and two random
PlanetLab nodes were chosen to be the servers, Y and Z;
a random high-bandwidth, high-uptime Tor exit node was
chosen for X and each client picked its own entry and mid-
dleman nodes. After A and B established their respective
Tor circuits, both clients connected to both servers using
the wget HTTP client, and the servers sampled these cir-
cuit times as described in Figure 3. These four circuit times
were used in six comparisons: comparing samples from TAX
to TAY and TBX to TBY gave two true positives, while com-
paring samples of TAX to TBX , TAX to TBY , TAY to TBX ,
and TAY to TBY gave four true negatives. Counting the
number of misclassiﬁed streams for various threshold values
allowed us to calculate false positive and false negative rates.
One important note is that the current version of Tor recy-
cles a used circuit after 10 minutes. Thus we set our experi-
ments to stop after 10 minutes as well, regardless of whether
the run had completed. Figure 4 shows the cumulative dis-
tribution function of number of circuit samples for both of
the client nodes - the median number of samples after 10
minutes was approximately 200.
Because both tests we used have tunable rejection regions,
there is no single statistic that completely summarizes the
eﬀectiveness of our classiﬁer. Instead, by varying the rejec-
tion region, we produce the Receiver Operating Character-
istic (ROC) curves for each of our tests, which summarize
the tradeoﬀs each test supports, in Figure 5. For the simple
comparison of means test (left), we ﬁnd that the test sup-
ports an equal error rate of 22% and has a total area under
curve (AUC) of 0.85. When dealing with a low base rate
of true positives, the K-S test oﬀers a much better trade-
oﬀ, supporting, for instance, a 37% false negative rate when
the test is tuned to support a false positive rate of 5%, and
achieving equal error rate of 17%; the K-S test has a total
area under curve (AUC) of 0.89. In contrast, if Tor circuits
were unlinkable, we would expect any linking test to have
performance similar to the random classiﬁer, which has an
ROC curve consisting of a straight line from the origin to
(1, 1) and AUC of 0.5.
While these results sug-
gest that latency data com-
promise the unlinkability of
Tor connections to some de-
gree, there is deﬁnitely room
for improved attacks. To
determine if more time eﬃ-
cient methods of sampling
circuit RTT would improve
performance, we also plot-
ted the ROC curve for K-
S tests where both circuits
had at least 500 samples, shown in Figure 6. The total num-
ber of such tests4 was 299, with 110 true positives and 189
true negatives. We found that these K-S tests had an equal
error rate of 6% and AUC of 0.98. When the rejection re-
gion for the K-S test was set to 0.13, the classiﬁer had a
false negative rate of 11% with only a single false positive.
These results strongly suggest that more eﬃcient methods of
obtaining circuit RTT samples will lead to stronger attacks.
Figure 6: ROC with 500+
samples of both circuits.
5. CLIENT LOCATION VIA LATENCY
The basic scenario of our client location attack is shown
in ﬁgure 7. In this attack, the adversary consists of three
4Recall that each run can result in as many as six tests.
that Tor circuit times carry enough noise, even with hun-
dreds of samples, that the diﬀerence in mean measurements
was not very reliable at predicting TV E; however, taking the
diﬀerence in minimum measurements for each circuit was a
fairly reliable estimate.
Estimating candidate RTTs. Once we have estimated
the RTT from the victim to the Tor entry node E, the next
step is to compare this measurement to the RTT between
candidate nodes and E. If we control either the candidate
or E, we could compute this directly via ping, but doing so
would make it easy for us to determine the victim, and is
outside the Tor threat model. Thus for the attack to work,
we need a method to obtain (or at least estimate) the RTT
between two hosts without the explicit cooperation of either.
Our attack measures this quantity via network coordinates.
Network coordinate systems were originally introduced in
the context of peer-to-peer networks, for predicting which
hosts will provide better routing or download service. The
basic idea behind such systems is for each node to measure
its RTT to several other nodes; using these RTTs, the entire
network is embedded into a coordinate space such that given
the coordinates of two nodes it is possible to predict the RTT
between them. A number of such systems exist [7, 8, 23, 28],
using various coordinate systems and embedding algorithms.
We chose to use the Vivaldi [8] embedding algorithm, with
four-dimensional Euclidean coordinates, due mainly to ease
of implementation. The primary disadvantage of using net-
work coordinates is that in order to be accurate without the
cooperation of the candidate nodes, several nodes must be
used for the service; however, several freely accessible re-
sources provide RTT measurements from a group of hosts
to arbitrary Internet hosts, including ScriptRoute [35] and
traceroute.org.
Several alternate possibilities exist for the implementation
of this step, that we did not evaluate empirically. One exam-
ple is the King technique [19], which measures the latency
between hosts A and B by asking the name server respon-
sible for A’s reverse DNS entry to do a recursive lookup for
B’s reverse DNS entry; Gummadi et al. [19] report that this
technique has accuracy competitive with the GNP [28] net-
work coordinate system and found that over 90% of name
servers will carry out such recursive queries. Another pos-
sibility that we did not empirically evaluate is “asking” the
entry node E to ping the candidate nodes by trying to ex-
tend a circuit from E to a service other than Tor running
on a (node proximal to a) candidate node. If the attacker
runs the same service on a corrupted node D and asks E to
extend a circuit to D at the same time, then the time dif-
ference between error messages for the two requests should
be a good estimator for the diﬀerence in RTT.
Eliminating candidates. Once we have estimated the
true victim’s RTT to E and the RTT between each of the
candidate locations and E, we must decide for each can-
didate location whether it is consistent with the estimated
TV E. There is an inherent tradeoﬀ in setting the threshold
for what nodes to include:
if too many candidates are in-
cluded, the attack will take longer to complete, but if too
few are included we could reject the true location of the vic-
tim due to noise in the estimated RTTs. Our approach is
to construct an 85% conﬁdence interval for TV E (computed
under the assumption that Tor circuit times are distributed
according to an exponential distribution added to a mini-
Figure 7: Client location: client V connects to malicious
server A via circuit E-M-X; A determines E-M-X and
connects to A via E-M-X.
logical entities, AServer, a malicious web server; AClient, a node
posing as a Tor client; and ATor, a corrupted Tor server capa-
ble of carrying out the Murdoch-Danezis attack. The attack
starts when the “victim” node V connects to AServer over a
Tor circuit consisting of nodes E, M , and X. AServer and
ATor collude to carry out the Murdoch-Danezis clogging at-
tack and learn the Tor nodes in the circuit E − M − X.
Thereafter, AServer and AClient collude to gain information
about V ’s network location. The goal of the attack is, af-
ter several repetitions with diﬀerent circuits, to identify V ’s
network location with increasing precision.
5.1 Attack Description
The basic idea of our client location attack is to try to
measure – using a Tor connection – TV E, the RTT between
the victim V and the Tor entry node, E. The attacker then
estimates, for several candidate victim nodes C, the RTT
TCE. Candidates that lie outside the probable range for TV E
are discounted, and the attack is repeated. If the fraction of
candidates in an iteration that are not discounted is c, then
the information gain from that iteration is − log2 c. After
several iterations, the list of remaining candidates should in-
clude only nodes with close network proximity to the victim.
We now explain how we implement each step of this attack.
Measuring ﬁrst hop latency. In section 4, we describe
our technique for sampling the RTT of an entire Tor circuit,
TV X . Since TV X = TV E + TE + TEM + TM + TM X + TX ,
the circuit time contains some information about TV E, but
does not directly measure the time of interest. In order to
do this, we leverage the information gained in the Murdoch-
Danezis attack: speciﬁcally, when V connects to AServer via
Tor, we assume that AServer and ATor collude to discover the
circuit nodes E − M − X that V uses for the connection.
Initially, this attack will only reveal the nodes in the circuit
rather than their order, but since any given client uses only
three entry nodes, and as the server, AServer knows which
node is the exit node, after several iterations it will be easy
to infer the circuit order; before such time, the attacker can
carry out the attack under both possible orderings and then
eliminate the incorrect data later.
Given this information, AClient can open a connection to
AServer using the same circuit nodes E − M − X. We mea-
sure the RTT of these connections as well, obtaining several
samples from both TV X and TAX . Using these samples as a
basis for estimating the “true” circuit times TV X and TAX ,
along with knowing TAE, the RTT between AClient and E,
allows us to estimate TV E by TV X − TAX + TAE. We found
Number of Runs
Connections/Run
RTT Mean/Stdev (ms)
V
216
685
AClient
216
1022
5078.24/4305.96
3817.2/1933.38
Table 1: Basic run statistics
mum network latency) and “conditionally” reject candidate
locations with estimated latencies outside of the conﬁdence
interval. Locations are only “conditionally” rejected in that
we continue to consider these candidate locations in later
runs, and ﬁnally compute the most likely locations as those
that fall within the conﬁdence interval most often. In our
empirical evaluations, we know the true location and when it
is conditionally rejected we consider the run to give us no in-
formation gain, so that we do not overstate the information
gain per experiment.
5.2 Evaluation
We measured the eﬀectiveness of the client location attack
(in terms of information gain per unit time) by performing
an experiment on the PlanetLab wide-area testbed, during
January and February 2007. The data collected from the
experiment consisted of 216 runs. At the start of the exper-
iment, two PlanetLab nodes were randomly chosen to play
the roles of AServer and AClient as in Figure 7. For each run,
a new victim node V was randomly selected from a set of
about 100 North American PlanetLab nodes, and V and
AClient both built identical Tor circuits using three nodes
selected randomly from around 60 high-uptime and high-
bandwidth onion routers. V and AClient both attempted to
download 1500 1 × 1 images from AServer over this circuit,
with the experiment cut oﬀ after 10 minutes. Network co-
ordinates were established by using 72 PlanetLab nodes to
ping all other PlanetLab nodes (704 at the start of the ex-
periment) and the entry node in the Tor circuit. As with
the previous evaluation, AServer recorded all connections from
the Tor exit node at the network level, and to simplify dis-
tinguishing between the attacker and victim streams, dif-
ferent ports were used by each5. At the conclusion of a
run, the number N of PlanetLab nodes that were candi-
date client locations was computed, and the information gain
was computed as 0 if the true client was not included, and
log2(704/N ) otherwise.
Basic statistics about the experimental results are shown
in Table 1, and the cumulative distribution of information
gain is shown in Figure 8. In terms of basic statistics, there
is a large discrepancy in average connections per run be-
tween the victim and attacker circuits; we speculate that
this is due to a lighter-than-average load on the PlanetLab
host we chose for AClient. In terms of information gain, the
average number of bits obtained per run was 0.68, with a
standard deviation of 0.86 and standard error 0.059. To as-
sess whether the conditional information remains stable for
additional runs, we also collected a set of 5 runs using a
single client node V . Among these 5 runs, the average con-
ditional information gain from a second run was 0.62 bits,
with a standard error of 0.14. Translated to bits per unit
time, the statistics suggest that we can recover 4.08 ± 0.702
bits of client location per hour.
5The port numbers – 5190 for the victim and 6667 for the
attacker – were chosen arbitrarily among those commonly
allowed by Tor exit nodes.
Figure 8: Cumulative distribution of information gain.
Figure 9: Expected bits per hour vs. 100-connection
standard error threshold.
On closer examination of the data, we found that 100 out
of the 216 runs yielded 0 bits of information about the client
location. This includes the expected 30 runs in which the
true client latency did not fall within the 85% conﬁdence in-
terval, but also 70 runs in which no candidate locations were
eliminated. In these cases, the variability of the Tor circuit
RTT was so high that every PlanetLab node’s RTT to the
entry node was within the conﬁdence interval for TV E. We
hypothesized that it might be possible to detect early on
that a run would be bad in this sense and discontinue the
attack, dedicating the remaining time to a diﬀerent client.
To test this, we looked at the correlation between stan-
dard error of a run after measuring the ﬁrst 100 connections,
which on average required less than 1 minute to collect, and
after the run was completed. We found that standard error
after 100 connections was an excellent predictor of ending
standard error (coeﬃcient 0.96, intercept −199.85, p-value