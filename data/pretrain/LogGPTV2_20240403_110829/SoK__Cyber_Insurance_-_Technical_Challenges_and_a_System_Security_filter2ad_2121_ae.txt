data-driven methodologies, and it can bring automation and support
tools to replace questionnaires and qualitative estimations.
In particular, we selected four classes of problems, one for each of
the insurance phases: actuarial, underwriting, portfolio management,
and claim validation. For each class, we underline the limitations
in the current approaches, discuss the challenges of proposing new
solutions, and outline a number of open research directions for
researchers in the security field. To ease their identification, we tried
to mark the main open problems we discuss in the text as (cid:3)Rn(cid:4).
V. AREA 1: RISK PREDICTION
“They could tell you exactly the chance of an office building burning
down in Midtown Manhattan, but there isn’t anyone on this planet
who could tell you the probability of a large U.S. retailer being
hacked tomorrow”
– Graeme Newman, Director at CFC Underwriting [152]
Cyber-insurance providers employ underwriting tools to collect
the information required to differentiate the risk across all the
applicants [37]. Today, underwriting questionnaires ask a number
of questions which insurance companies believe to be relevant to
classify the risk of a potential customer. However, as we discussed
in Section III-E, researchers still have to identify reproducible
ways to estimate risk based on a number of observable features
that had been proven to be meaningful predictors across a number
of experiments. The experiments conducted to date were often
inconclusive and difficult to compare as they were all conducted on
different datasets and none of them was ever repeated or validated
by other studies. As a result, as a community we still lack an
understanding of which security events can even be predicted
in the first place, and which features are most useful for such
prediction. This opens several research directions to explore
different methodologies to capture and aggregate risk factors.
Measure the security posture of the target. One of the first ideas
that comes to mind to understand the risk of cyber incidents is to
look at the overall security of a given target. In fact, the security
posture of an organization may provide good insights on the level of
risk – if we assume that a better security hygiene can lower the risk
of future attacks. Indeed, at least intuitively, the higher is the security
of a system, the lower should be the probability of a security
incident affecting that system. If we accept this assumption, risk
prediction can be re-formulated as a problem of measuring security.
While the fact that security countermeasures could result in a
reduced amount of computer abuse was first assessed in 1990 by
the seminal work of Straub et al. [153], the link between security
posture and cyber risk is not so straightforward and it is still
poorly understood today. Security measures can certainly raise
the bar for the attackers, but risk also depends on the number of
attacks a target may receive—which could be higher for large and
popular organizations. Moreover, relevant targets may attract more
sophisticated and motivated adversaries, which can make prediction
more complicated. But even if we accept this premise to be correct,
there are still two serious obstacles to this approach.
First, despite almost four decades of attempts, it is still unclear
whether a way to quantify security even exists [154]. For instance,
in 2009 Verende et al. [154] surveyed many techniques taken from
the economics, the computer science, and the reliability community,
but still found unclear the validity of the existing results. Second,
even if we had a scale to precisely measure security, it is still
unknown what is the exact relationship between the level of security
and the probability of incidents (cid:3)R1(cid:4). Simply saying that more
security equals less risk is too vague to be practical. Does doubling
security reduces the risk by half or by a factor of four? Does the
curve reach a plateau, after which adding more security does not
provide a tangible reduction in terms of risk?
Measure the behavior of the target. The fact that the behavior of
the target can considerably affect its overall risk is another aspect
which is often taken for granted. The idea is that, regardless of its
security posture, the risk of being compromised of a given entity
increases simply because of the actions it performs. For instance, if a
user spends a considerable amount of her time browsing dubious and
less reputable web sites, it seems reasonable that she would incur
higher chances of being infected by malware than a user who only
browses corporate and popular sites. Unfortunately, even if this may
seem a logical conclusion, researchers have struggled to measure
this simple relationship (cid:3)R2(cid:4). For instance, in 2013 Levesque et
al. [155] found that the number of illegal and questionable websites
visited by a user is less related to the risk of malware infection than
the number of sport or computer sites. Similarly, Bossler et al. [29]
found that the time spent performing illegitimate computer activities
was NOT a good predictor of malware infections. Strangely, the
authors found that even higher computer skills and the adoption
of careful password management failed to reduce this risk.
Many independent studies [27], [28], [155] found instead
evidence that the volume of performed actions (e.g., the number of
software installed or the number of websites visited, independently
from their category) was always correlated to a higher risk. If
confirmed, this finding seems to suggest that there is a systematic
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:40:36 UTC from IEEE Xplore.  Restrictions apply. 
1376
risk of performing common actions – such as browsing the web or
installing software – and the final risk would mainly depend on how
many times these simple tasks are repeated by an individual or an
organization. In other words, a possible direction is to try to model
the risk of a compromise by using a frequency-based approach
(cid:3)R3(cid:4), which is already a common solution to describe safety risks.
Measure the attack surface. In a given cyber environment, the
attack surface is defined as the set of different points where an
attacker can try to break into the system or exfiltrate information. As
a direct consequence, reducing the attack surface by removing un-
necessary services or limiting the access to parts of the infrastructure
represents a way to increase the security by reducing the number
of components that an attacker can target. The rationale behind this
concept is that the likelihood of suffering from a security issue will
raise according to the number and diversity of software, services, and
systems used. While this is simple mathematics (and approached
have been proposed to measure the attack surface of a system [156],
[157]), the exact relationship that these variables have with cyber risk
is still unknown and more experiments are needed to measure how
risk actually reduces with the reduction of the attack surface (cid:3)R4(cid:4).
Influence of business sector, reputation, and assets of an
organization. As we already mentioned above, non-technical
characteristics of the target can influence the number, type, and
sophistication of the adversaries it needs to face. Today it is widely
accepted the hypothesis that, given enough time and resources,
motivated attackers can always find a way to compromise a target.
Large state-sponsored cyber attacks have shown this to be the case
also for the most secure government organizations [158], [159].
Therefore, the type of business, the sector, the reputation, and
the assets owned by an organization may influence the risk of
compromise more than other technical indicators, as they allow to
capture the characteristics of the attackers (incentives, risks, and
resources as proposed by [137]) instead of those of the defender.
This assumption has already been shown to be valid to characterize
both the number and the type of attacks, respectively by Sarabi et
al. [21] and Thonnard et al. [22]. Moreover, this approach could also
cover the risk of targeted attacks, whose ad-hoc natures does not
allow them to be easily described by a frequency-based model [160].
Predict future events based on historical data. Historical data
about claims and incidents are routinely used to estimate the risk
in other insurance sectors. However, as already stated in section III,
the use of previously collected data to predict future cyber events
faces several challenges. First of all, data on cyber incidents are
scant and often biased towards those events whose disclosure is
mandatory because regulated by law [56], [57]. A second challenge
in this approach is to shed light on the so-called repeat players.
Although previous studies found a systematic difference between
costs incurred by companies that experience single or multiple
incidents [150] (the so-called repeat players), it is still not clear
whether having already been compromised is a good indicator of
being again compromised in the future (cid:3)R5(cid:4). Finally, an additional
complication is represented by the fact that attack techniques evolve
very rapidly over time, making obsolete results obtained from
the observation of old data. For instance, if a known vulnerability
associated with a high-risk factor were to be patched, past records
about events occurred because of its presence would probably not
provide any contribution to capture the risk associated to new attacks.
Measure the risk that propagates through third-party relations.
Outsourcing many critical business operations became a norm in
the last decade. It is very typical to store and process data owned by
companies on third-party cloud services and even common services
such as DNS and emails are now outsourced to the cloud. This
largely complicates the picture for cyber insurances as it is harder to
draw a clear line of the boundaries of a company. As common sense
suggests, a company that is in relation to other risky entities should
have higher risk itself. While constructing sufficiently accurate
service-dependency graphs of businesses is a challenging research
topic by itself [161], measuring the amount of risk that propagates
through this graph is an open research problem that needs attention
from the community. We will come back to discuss this problem
in more details in Section VII.
User’s weaknesses and social engineering. One of the most
common techniques used today to gain access to a network or system
is social engineering: indeed, while one can think that the most
successful breaches are the result of technical flaws or zero-day vul-
nerabilities exploitations, almost 97% of them is achieved by tricking
users to reveal sensitive information using a social engineering
scheme [162]. Unfortunately, while social engineering attacks can
pose a tremendous threat to organizations, current approaches to IT
security and risk management tend to underestimate or completely
ignore the human factor in risk assessment models, tools and
processes [163]. Extending existing schemes by modeling users and
their behavior could largely increase their prediction accuracy(cid:3)R6(cid:4).
Risk aggregation. All the factors we previously mentioned are
likely to somehow affect (to a different and still unknown extent)
the risk of cyber incidents. But even if researchers would be able
to precisely identify a number of good and stable risk indicators,
we would still have known very little about the aggregation
procedure required to combine the different scores. This problem is
exacerbated by the fact that, for practical reasons, each study looks
at a single factor in isolation. But different factors are probably
not independent and they can have very complex consequences
and side-effects on other indicators. For instance, a good security
posture may mitigate a larger attack surface, but it can be completely
undermined by untrained users. Therefore, if distinct studies
respectively find good predictors of risk, a constructive combination
of them would still require a considerable amount of research (cid:3)R7(cid:4).
A classic insurance solution could be to evaluate all risk indicators
separately and then rely on actuarial data about past incidents to
combine them in a single risk class, but as we already said this data
may be very hard to put together and may become obsolete very
fast. Finally, a major obstacle to risk aggregation is the different
granularity of the risk computed by different approaches. Some can
predict the risk of compromise of a given software artifact, other of a
user, or of an individual machine. How to aggregate these values, for
example, at a company level is still an open research problem (cid:3)R8(cid:4).
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:40:36 UTC from IEEE Xplore.  Restrictions apply. 
1377
A. Horizontal Issues
So far, we discussed different open problems and research
questions and their relevance for cyber insurance. However, we
believe it is important to also highlight three important aspects about
cyber risk itself that apply to all previously mentioned approaches:
1) Cyber risk vs cyber-insurance risk: as briefly shown in
section III-B, almost all the existing literature focuses on cyber
risk assessment or prediction. Although these are important
for the purpose of diverting security spendings towards most
relevant threats, such evaluation could be misleading for cyber-
insurance risk assessment.
Indeed, a quantification of the first does not necessarily reflect
the second, that after all is the actual value insurances are
interested in: for instance, a class of events could have a high
risk to harm one entity but lead to claim submissions with
a very low probability. In other words, it is also important
to study and measure how cyber risks translate to insurance
claims in the real world (cid:3)R9(cid:4).
2) Consumers vs corporations: since cyber-insurance products
are recently made available also for
the consumers
market [164], it is possible that a different approach and/or
set of features should be considered depending on the entity
under investigation. Indeed, consumers are less active with
respect to big corporations, operate in a different scenario,
and may become an appealing target of cyber attacks for
different reasons compared to large enterprises. However,
no study exists to date to compare the risk and threats
encountered by consumer vs enterprise users (cid:3)R10(cid:4).
3) Risk variety: risk assessment or prediction procedures need to
be targeted towards specific categories of risk. Indeed in an in-
surance context, addressing cyber risk as a single-unit problem
may be too generic and may not lead to meaningful results.
For instance, the authors of [25], [26] predict machines and
users at risk of malware infections, without providing any fine-
grained categorization (after all, malware is a very generic
term). In the same way, Liu et al. [20] attempt to forecast
generic cyber incidents specifying no type or effect. However,
as shown by Eling et al. by using actuarial data [128], different
types of data breaches need to be modeled as distinct risk cat-
egories. A more fine-grained classification is needed (cid:3)R11(cid:4)to
also highlight particular categories of threats strongly coupled
to the subject we are evaluating the risk for: for instance,
malware targeted against banking systems are probably not
very relevant for those enterprises in other business sectors.
VI. AREA 2: AUTOMATED DATA COLLECTION
“If you’re writing policies for personal automobile or personal
homeowners insurance you definitely have a lot of really good data.
The worst data is probably in cyber insurance”
– Nick Economidis, Cyber liability underwriter at Beazley PLC [47]
The importance of data collection for cyber-insurance carriers
does not only relate to the actuarial domain, whose issues have al-
ready been discussed in section II. Data collection about prospective
clients is indeed the first crucial task of policy underwriting, as it al-
lows insurance firms to elicit a reasonable approximation of the over-
all security posture of the applicants, measure their level of risk, and
subsequently compute premiums. The most common way to achieve
this goal is to furnish organizations wishing to buy a cyber-insurance
policy with security questionnaires. In a recent study, Romanosky
et al. [37] analyze 44 of these questionnaires filed across the states
of California, Pennsylvania, and New York, and point out common-
alities that allow to group the questions into four macro categories.
The first set of questions aims at defining some general
organizational details of the company, like its business sector
and annual revenues, the kind of sensitive information stored and
handled, how relationships with third-party service providers are
managed, the nature and amount of IT security investments and,
if any, its cyber-incident history. The second category focuses on
technical aspects, often covering questions on security and access
control measures adopted by the company and, less frequently,
on its information technology and computing infrastructure. The
existence of policies and procedures for data management is
investigated in a third set of questions, in which insurance firms
investigate whether data processing, retention and destruction
practices are compliant with current regulation laws and procedures
to maintain and strengthen information security. Finally on the
legal side, questionnaires verify how well a variety of laws and
regulations, enacted to protect consumers from the consequences
of cyber incidents and data breaches, are implemented and adhered.
The information collected is then used for premium computation:
while some carriers use flat-rate pricing for each first- and third-
party coverage (with no differentiation by firm or industry), others
incorporate more features (such as firm’s sector and revenue) as
factors to be multiplied in a base rate pricing. In more sophisticated
policies, also the soundness and completeness of security controls
and practices have a weight in the final result.
Although these questionnaires are widely adopted by