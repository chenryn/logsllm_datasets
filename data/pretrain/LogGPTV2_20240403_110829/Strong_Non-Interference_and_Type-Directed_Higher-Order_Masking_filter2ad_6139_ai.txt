if (i  k) then s ← s (cid:9) ri,k;
k ← k + 1;
k(cid:48) ← k; r(cid:48) ← $;
for k = k(cid:48) to t do s ← s ⊕ ri,k;
if (i  j, either (i, j) ∈ I × J and the observation is
perfectly simulated from rj,i, ai, bi, aj and bj or rj,i does not enter in the computation of
any internal variable that was observed and ri,j (line 5i,j) was assigned a fresh random
value. Each observation made in the fourth group is perfectly simulated using ri,j, ai
and bj. As for an observation in the second group, the corresponding variable is a partial
sum composed of a product ai ⊗ bi and of variables ri,j. Since ai and bi are provided
to the simulator in this case, we focus on each remaining ri,j. Each one of them such
that i < j is already assigned to a fresh random value. For the others, if rj,i enters in the
computation of any other internal observation, then (i, j) ∈ I × J and ri,j is simulated
with rj,i, ai, bi, aj and bj. Otherwise, ri,j is assigned a fresh random value.
We still have to simulate output observations. We start with those for which an
intermediate sum (group 2) is also observed. For each such variable ci, the biggest partial
sum which is observed is already simulated. Thus, we consider the remaining terms
ri,j. Each one of them such that i < j is already assigned to a fresh random value. For
the others, either (i, j) ∈ I × J and ci is perfectly simulated from rj,i, ai, bi, aj and
bj or rj,i does not enter in the computation of any internal variable observed and ci is
assigned a fresh random value. We now consider output observations ci for which none
of the partial sums are observed. Each of them contains t random variables of the form
ri,j, at most one of which can enter in the computation of each one of the cj with i (cid:54)= j.
Since we already considered at most t − 1 observations not counting the current one, at
least one of the ri,j we need to consider does not enter in the computation of any other
observed variable and is unassigned. Thus, we can simulate ci using a fresh random
value.
D Robust Composition
We consider the problem of securely composing algorithms or gadgets when the adver-
sary may place t probes in each of them, capturing security in the region and stateful
probing models [24]. In this informal discussion, we forbid wire duplications between
regions (that is, each region’s output can only be used once as input to another region).
However, the same principles that allow us to compositional reason about security in
the simple probing model would allow us to reason about robust composition with wire
duplication, using, in particular, 2t-SNI mask refreshing gadgets where necessary.
As noted in Section 9, it is clear that any number of 2t-SNI gadgets or algorithms
can be securely composed in this setting. We ﬁrst observe that, for any two 2t-SNI
algorithms F and G, and for any OF and OG such that |OF|,|OG| ≤ t, we have
(cid:107)depsetF ;G(OF ∪ OF )(cid:107) ≤ t. This allows us to conclude about the security of the
composition of any number of gadgets by induction on that number.
This observation provides an elegant justiﬁcation to Coron’s result [12], which states
that iterating RefreshA2t+1 2t + 1 times allows the secure stateful composition of his
masked table-lookup algorithms without further doubling the number of shares. Indeed,
it is also easy to see that Coron’s mask refreshing algorithm is 2t-SNI.
However, the same composition could be obtained by slightly relaxing the security
requirement on F and G. Indeed, we could instead use the following condition, which
we call robust non-interference.
G | ≤ t, we have (cid:107)depsetG(OG)(cid:107) ≤
Deﬁnition 9 (Robust Non-Interference) A gadget G is t-robustly non-interfering (or t-
RNI) whenever, for any OG such that |OG| ≤ 2t and |Oint
G |.
|Oint
The same argument that allows us to securely and robustly compose 2t-SNI gadgets
allows us to securely and robustly compose t-RNI gadgets. Intuitively, t-RNI allows the
adversary to place 2t probes on the gadget, as long as at most t of them are internal. This
captures exactly the scenario where an adversary can place t probes inside a region, and
can also learn, by probing subsequent regions, information about t shares of the output.
Constructing RNI Algorithms We now show how any t-NI algorithm can be turned into
a t-RNI algorithm without doubling its internal number of shares, simply by processing
its inputs and output. To do so, we consider the Double and Half gadgets (Gadget 13).14
Gadget 13 The Double and Half gadgets
$← K
function Doublet(a : Kt+1)
for i = 0 to t do
r2i
r2i+1 ← ai (cid:9) r2i
return (cid:104)r0, . . . , r2t+1(cid:105)
(13a) Doubling the number of shares
function Half t(a : K2t+2)
for i = 0 to t do
$← a2i ⊕ a2i+1
ri
return (cid:104)r0, . . . , rt(cid:105)
(13b) Halving the number of shares
We ﬁrst note that Doublet is t-NI, and that Halft is such that, for any OH such that
|OH| ≤ t, we have (cid:107)depsetH(OH)(cid:107) ≤ 2t. (Indeed, each internal position depends two
shares of the input.)
14 These are only gadgets for a slightly extended notion of gadget that allows the encoding size to
change between inputs and outputs.
Alg. 14 Making a t-NI gadget t-RNI
function RobustG(a1, . . . , an ∈ K2t+2)
for i = 1 to n do
ai := RefreshM2t+1(ai)
xi := Half t(ai)
y := G(x1, . . . , xn)
r := Double(y)
r := RefreshM2t+1(r)
Lemma 6 Given a t-NI gadget G, the algorithm shown in Alg. 14 is t-RNI.
Proof. The proof is by composition, leveraging the following facts (for some O as
assumed by t-RNI): i. RefreshM2t+1 is t-SNI (so the dependency set of its position set
is of degree at most |OR2| ≤ t; ii. Doublet is t-NI (so the dependency set of its position
set is of degree at most |OD| + |OM2| ≤ t); iii. G is t-NI (so the dependency set of its
position set and output set is of degree at most |OG| + |OD| + |OR2| ≤ t); iv. Halft has
the property described above (so the dependency set of its position set and output set is
of degree at most 2(|OH| +|OG| +|OD| +|OR2|) ≤ 2t); v. RefreshM2t+1 is 2t-SNI (so
the dependency set of its position set and output set if of degree at most |OR1| ≤ |Oint|).
E Privacy vs probing security
In this appendix, we exhibit a simple example that separates Ishai, Sahai and Wagner’s
notion of privacy [24] and the widely used simulation-based notion of t-probing security.
We recall that Ishai, Sahai and Wagner [24] deﬁne privacy for a masked circuit C as
the fact that any t wires in C during an execution of O ◦ C ◦ I (where I and O are
the encoding and decoding circuits that sample uniform encodings of the secret inputs
and recombine outputs from their encodings, away from adversary interference) can be
simulated without access to any wire in the circuit.15 On the other hand, as discussed
earlier in the paper, t-probing security, as deﬁned for example by Carlet et al. [10] states
that a gadget or algorithm G is t-probing secure iff any t of its intermediate wires can be
simulated using at most t shares of each of its inputs.
Note in particular that, unlike privacy, t-probing security makes no mention of secrets,
or of uniform input encodings. In Gadget 15, we exhibit a small example gadget, which
computes a (cid:12) (a ⊕ b for t = 2, and shows that this is indeed an important detail by
separating the two notions. However, we note that even Ishai, Sahai and Wagner [24]
prove that their transformers are private using a t-probing style simulation argument, so
the separation we exhibit here makes little difference in practice.
15 More accurately, they deﬁne privacy for a circuit transformer that includes deﬁnitions for I and
O. This is not relevant here.
Gadget 15 A small separating example
1: function separator(a, b : K3)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
for i = 0 to 2 do
ri := ai ⊕ bi
for i = 0 to 2 do
ci ← ai (cid:12) ri
for i = 0 to 2 do
for j = i + 1 to 2 do
r $← K
ci ← ci (cid:9) r
t ← ai (cid:12) rj
r ← r ⊕ t
t ← aj (cid:12) ri
r ← r ⊕ t
cj ← cj ⊕ r
return c
It is easy to see (and it can be checked automatically using, for example, Barthe et
al.’s tool [4]) that this small algorithm is private for t = 2. Intuitively, this is because,
since privacy requires simulation only when the input encodings are known to be uniform,
and even though the inputs to SecMult are not independent, one of them is essentially a
one-time-pad of the other.
However, simulating, say, lines 100,1 (with value a0 (cid:12) (a1 ⊕ b1)) and 101,2 (with
value a1 (cid:12) (a2 ⊕ b2)) using only two shares of each of a and b is not possible.
We note that, as pointed out above, the tool by Barthe et al. [4] directly verify privacy,
rather than going through t-NI and losing precision. However, they do not scale. When
considering veriﬁcation tools (or indeed even the veriﬁability of pen-and-paper proofs),
there is therefore a tradeoff between precision and applicability.