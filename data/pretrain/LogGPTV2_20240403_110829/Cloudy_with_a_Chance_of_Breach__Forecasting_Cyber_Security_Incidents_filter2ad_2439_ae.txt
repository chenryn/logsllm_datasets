Throughout this paper, we have assumed that the data are truthfully reported, albeit with some inherent noise or error. It is reasonable to question the robustness of our predictions against potential (malicious) manipulation of the training data, a topic of increasing interest commonly referred to as adversarial machine learning. For example, an entity might attempt to set up fake networks with clean data (no malicious activities) but with false reported incidents, and vice versa, to mislead the classifier.

Without presenting a complete solution, which remains a direction for future research, we test the robustness of our current prediction technique using two scenarios:
1. In the first scenario, we randomly flip the labels of victim organizations from 1 to 0. These flipped labels now belong to the non-victim group, thus contaminating the training data.
2. In the second scenario, we do the opposite: we randomly flip the labels of non-victim organizations, effectively adding them to the victim group. This scenario is similar to under-reporting by randomly selected organizations.

Experimental results suggest no significant performance difference in the first scenario. The reason lies in the imbalance between the victim and non-victim population sizes. In our experiment, we randomly select a subset of non-victim organizations with a size comparable to the victim organizations (on the order of O(1,000)). Consequently, the expected number of victims selected as part of the non-victim set is no more than \( N_v \cdot \frac{O(1,000)}{N} \), where \( N_v \) denotes the number of fake non-victims and \( N \) is the total number of non-victims. Given \( N \sim O(1,000,000) \), even if one can inject \( N_v \sim O(100) \) victims into the non-victim population, on average, no more than one fake non-victim will be selected for training. This results in a negligible contamination effect unless such alterations can be done on a scale larger than the actual victim population.

For the second scenario, we observe a slight degradation in performance, specifically in the true positive rate, as shown in Figure 11 at the 20% contamination level (where 20% of non-victim organization labels are flipped).

\[
\begin{array}{c}
\text{True Positive Rate} \\
\hline
1.0 \\
0.9 \\
0.8 \\
0.7 \\
0.6 \\
0.5 \\
0.4 \\
\hline
\text{VCDB} \\
\text{Adversarial} \\
\hline
0.1 \\
0.2 \\
0.3 \\
0.4 \\
0.5 \\
\end{array}
\]

**Figure 11:** Adversarial case (2) with 20% contamination.

### Incident Reporting

One of the main obstacles in studies of this nature is the acquisition of high-quality incident data, without which we cannot train or verify our models with confidence. Our results demonstrate that machine learning techniques have the power to make accurate incident forecasts, but data collection lags behind. The research community would benefit enormously from more systematic and uniform incident reporting.

### Related Work

As mentioned in the introduction, a large part of the literature focuses on detection rather than prediction. For example, Qian et al. [44] built sophisticated Hidden Markov Model techniques to detect spam deobfuscation, and Wang et al. [57] applied adversarial machine learning techniques to detect malicious accounts on Weibo.

Relatively fewer studies have focused on prediction, and even fewer on the type of prediction presented in this paper, where the predicted variable (classifier output) is of a different type from the input variables (feature input). For instance, the predictive IP-based blacklist works in [50, 30] have the same input and output variables (content of the blacklist). Similarly, in [54], the evolution of spam for a certain prefix is predicted using past spam activities as input. Predictive studies similar to ours include [51], which predicts whether a website will turn malicious by using textual and structural analysis of a webpage. The performance comparison has been given earlier.

It is worth noting that the intended applications are also different: while webpage maliciousness prediction can help identify websites needing improvement or maintenance, our prediction on the organizational level can help point to networks facing a heightened probability of a broader class of security problems. Additionally, our study [48] examines the prediction of incident types, conditional on an incident occurring, by using an array of industry, business, and web visibility/population information. Other predictive studies include [28], where it is shown that by analyzing user browsing behavior, one can predict whether a user will encounter a malicious page (achieving 87% accuracy), [52], where risk factors are identified at the organization level (industry sector and number of employees) and the individual level (job type, location) that are positively or negatively correlated with experiencing spear phishing targeted attacks, and [53], where risk factors for web server compromise are identified through analyzing features from sampled web servers.

Also related are studies on reputation systems and profiling of networks, such as [26], a reputation assigning system trained using DNS features, reputation systems [8, 9] based on monitoring Internet traffic data, and those studied in [29, 46].

### Conclusion

In this study, we characterize the extent to which cybersecurity incidents can be predicted based on externally observable properties of an organization's network. Our method is based on 258 externally measurable features collected from a network's mismanagement symptoms and malicious activity time series. Using these to train a Random Forest classifier, we achieve fairly high accuracy, such as a combination of 90% true positive rate and 10% false positive rate. We further analyzed the relative importance of the feature sets in the prediction performance and showed our prediction outcomes for the top data breaches in 2014.

### Acknowledgment

This work is partially supported by the NSF under grants CNS 1422211, CNS 1409758, CNS 1111699, and by the DHS under contract number HSHQDC-13-C-B0015.

### References

[References listed as provided in the original text]

### Appendix

Incident Dataset

A snapshot of sample incident reports from the VCDB dataset (Table 7).

| Incident Type | Time | Report Summary |
|---------------|------|----------------|
| Web site defacement | May 2014 | "ybs-bank.com" a Malaysian imitation of the real Yorkshire Bank website. |
| Hacking | Apr. 2014 | 4chan hacked by person targeting information about users posting habits. |
| Web site defacement | N/A 2013 | AR Argentina Military website hacked. |
| Server breach | N/A 2013 | The systems of AdNet Telecom, a major Romania-based telecommunications services provider, have been breached. |
| Web site hacked | May 2013 | Albany International Airport website hacked. |
| Private key stolen | Mar. 2014 | Amazon Web Services, Inc. |
| Phishing | N/A 2013 | Bolivian tourist site was compromised and a fraudulent secret shopper site was installed. |

**Table 7:** Incidents from the VCDB Community Database