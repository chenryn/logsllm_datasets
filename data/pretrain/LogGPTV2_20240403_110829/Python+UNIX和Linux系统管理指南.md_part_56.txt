[ngift@Macintosh-8][H:10046][J:0]# python query_dns.py
return collection
for host in host_list:
collection =[]
print arec
ip = dns.resolver.query(host,"A")
collection.append(str(i))
www.TopSage.com
实例丨401
---
## Page 416
402
果：
这个简单的绑定告诉我们已经成功了，让我们查看一下失败的情况，并查看输出的结
python-ldap API.
进行详细介绍超出了本书的范畴，但是可以使用密歇根大学的公共LDAP服务器测试
的过程，其中成功实现了对公共ldap服务的绑定，以及一个不成功的绑定。对配置LDAP
在安装python-ldap之后，你会希望首先尝试一下IPython中的库。以下是一个交互式会话
sourceforge.net/download.shtml。
件和LDAPv3。开始的时候，需要从python-ldap源码项目中下载包：http://python-ldap.
持使用OpenLDAP2.x面向对象封装。也有支持其他LDAP相关的项，包括处理LDIF文
有一个使用LDAP的Python API，称为python-ldap，它包括在Python API中，该API支
Directory之间的通信。
Hat Directory Server和Active Directory。 Python-ldap API支持与OpenLDAP和Active
议的最为流行的应用。支持LDAP协议的目录示例是OpenDirectory、OpenLDAP、Red
的用于查询和修改目录服务的应用协议”。该服务的示例是认证，这是目前使用该协
听到过的最好的对LDAP的定义来自Wikipedia：
家庭网络。或许你不熟悉LDAP，它代表Lightweight Directory Access Protocol。我们
LDAP在绝大多数公司都是一个强意词，其作者之一甚至运行LDAP数据库来管理他的
Python工具实现LDAP
使用OpenLDAP、
/root/&lt;ipython console>
In [5]:try:
SERVER_DOWN
In [6]:l.simple_bind()
Out[3]:1
In [3]:l.simple_bind()
In [2]: 1 = ldap.open("1dap.itd.umich.edu")
In [1]: import ldap
....
...·
....:except Exception,err:
第14章
print err
1 = 1dap.open("127.0.0.1")
、ActiveDirectory以及其他
www.TopSage.com
Traceback (most recent call last)
“LDAP是一个运行在TCP/IP基础上
DG
---
## Page 417
至此，你已经有了一些使用Python和LDAP的基本知识，但是你应该参考在本章开始部
我们正创建一个异步API调用。
模异步加载LDIF文件时，该类会映射到LDAP数据库。值得注意的是，1.add_s展示了
查看这个示例，首先初始化一个本地LDAP服务器，然后创建一个对象类，当我们大规
个示例，实现了一个异步LDIF加载：
创建一个到公共LDAP目录的简单连接对于帮助你完成工作不是非常有用的。以下是一
加载LDIF文件
正如我们所看到的，在这个示例中，有一个LDAP服务器在运行，并且我们的代码运行
良好。
import ldap.modlist as modlist
import ldap
SERVER_DowN:{'desc':"Can't contact LDAP server"}
def
/usr/lib/python2.4/site-packages/ldap/ldapobject.py in _1dap_call(self, func, *args,
->
/usr/lib/python2.4/site-packages/1dap/ldapobject.py in simple_bind(self, who, cred,
(serverctrls),EncodeControlTuples(clientctrls))
1 = ldap.initialize("ldaps://localhost:636/")
create():
dn="cn=root,dc=example,dc=com"
170
168
rec['objectclass'] = ['top','organizationalRole','simpleSecurityobject']
167
.add_s(dn,ldif)
ecl
6
96
def simple_bind_s(self,who='',cred='',serverctrls=None,clientctrls=None)
 return self._ldap_call(self._l.simple_bind,who,cred,EncodeControlTuples
try:
self._idap_object_lock.release()
finally:
try:
result = func(*args,**kwargs)
]='SecretHash'
:'User object for replication using slurpd'
www.TopSage.com
实例|403
---
## Page 418
404
def combine_lines(fles):
#1/usr/bin/env python
例14-2：合并Apache日志文件报告
告。例14-2显示了脚本的代码。
了分别处理所有分别指定的日志文件，还可以让这个脚本来整合多个日志，产生单一报
我们重用在第3章编写的模块，以展示如何从一个或多个日志文件中产生可读报告。除
在第3章，我们给出一些示例，解析Apche web服务器日志并提取信息。在这个示例中，
适应大数据文件，或是大量文件。
你应该可以将这个方法，应用到任何一类包括这些日志的数据上。这个方法也可扩展以
于报告Apache日志文件的方法。这个示例仅关注Apache日志可用信息的一个方面，但是
当前，网上大约50%的域采用的web服务器是Apache。接下来的示例专门展示了一个用
Apache日志报告
持很好的结构化。
其他web-based管理解决方案。官方文档可以参考：http://www.web2ldap.del。LDAPv3支
based的LDAP前端，由python-ldap的作者创建。你或许考虑尝试一下一些针对LDAP的
需要说明的最后一件事是有一个不错的名为web2idap的工具，它是一个Python，web-
LDAPv3，包括创建、读取、更新、删除（CRUD）等。
分给出的资源，以获得使用python-ldap的更多帮助。特别地，有一些示例详细介绍了
def
from optparseimportOptionParser
return
for
open_files(fles):
logfiles = args
(options, args) = parser.parse_args()
yield (f,open(f))
+
第14章
"".join(str(int(n) / 10) * 10) for n in addr.split('.'))
 yield line
obj
in f_obj
in fles:
-regex
www.TopSage.com
default=False,
---
## Page 419
件，或者合并日志文件并作为一个文件进行报告。这也正是combine_lines()函数的由
象，我们可以利用它做一些事情。我们可以或者选代所有产生的文件并报告每一个文
示它实际上不会打开文件，直到产生它。现在我们已经有一个可选代的打开的文件对
open_files（)是一个产生器函数，从我们传递给它的文件名列表中产生文件对象。这表
接下来，我们在由用户传递的文件名列表上调用open_files()。正如我们已经谈到的，
将在以后运行并测试该脚本的性能。
split模块。我们实际上包括这个标志并加载条件来比较这两个库的性能。但是，我们
然后检测regex标志是否被传递进来。如果是这样，使用regex模块。如果没有，使用
库而不是“split”库。这两者都提供了相同的功能，但是“split”库更快一些。
起。我们将在后面介绍这个内容。regex选项告诉脚本使用我们在第3章写的正则表达式
件作为一个文件看待。在某种意义上，如果这个选项被传递，我们将这些文件连接到一
是Boolean：整合的日志文件和使用正则表达式库。consolidate选项告诉脚本将所有文
接下来，我们使用optparse来解析来自用户的命令行参数。我们仅接受两个参数，且都
的行上进行选代。
行。我们从combine_lines()获得的可选代性是与文件对象的使用相对应的：在文件中
combine_lines（)将一个可选代的打开的文件对象作为参数。使用for循环，在文件对象
构）。对于每一个文件名，它产生一个文件名三元组和一个相应的打开的文件对象。
一个产生器函数，用于获得文件名列表（实质上，可以是任何具有重复特征的数据结
两个函数允许我们之后使用一些适当的generator来进一步简化代码。open_Files()是
在脚本的上部，定义了两个函数：open_file()和combine_lines()。在脚本的后部，这
上多次选代。对于这些文件中的每一个，它选代文件中的每一行，并且输出选代的每一
if options.regex:
opened_files=open_files(logfiles)
else:
from apache_log_parser_split import generate_log_report
report_dict = generate_log_report(file_obj)
orint"
print"%-2Os%s"%("IP ADDRESS"，"BYTES TRANSFERRED")
printfilename
orint
print
60
www.TopSage.com
dict.iter
实例|405
---
## Page 420
406丨第14章
的输出结果如下所示：
这三个日志文件(实际上，是三个相同的日志文件，具有相同的多次复制的日志数据)
在一个单独的28KB日志上的输出结果如下所示：
我们输出一些分隔符字符串以及格式化的字符串，包含generate_log_report()的结果。
log_report()函数，其返回一个IP地址和发送给该IP地址的字节数。对于每一个文件,
因此，无论是一个实际的文件或是一个合并的文件，我们都会传递给适当的generate_
象：所有文件中所有行的产生器。
来。
190.40.10.0
access_big.log
190.40.10.0
access.log
access.log
、如果用户传递“consolidate”标志，被迭代的文件实际上是一个单独的文件类对
IP ADDRESS
190.20.250.250
70.0.20.190
200.80.230.0
............
IP ADDRESS
190.20.250.250
70.0.20.190
70.0.20.120
60.240.70.180
60.210.40.20
190.20.250.210
190.20.250.190
200.40.90.110
70.180.0.220
130.150.250.0
200.40.90.110
200.80.230.0
190.40.10.0
IP ADDRESS
************************************************************
90.50.200.210
90.20.250.210
 = = = = 
1747900
BYTES TRANSFERRED
BYTES TRANSFERRED
17479
8276
BYTES TRANSFERRED
5936
378
45346
5936
378
4268
4268
1265
20976
27681
499
2115
45346
17479
www.TopSage.com
***水**水水**************水****
！
 ==n =  === = *
---
## Page 421
以下是运行时间。
7200RPM磁盘驱动器。我们使用了大约1GB大小的文件：
Ubuntu Gutsy服务器上，使用AMD Athlon 64X25400+2.8GHz,2 GB内存，
那么该脚本是如何执行的？内存消耗会是怎样的？在这一节中的所有的测评都是运行在
三个文件合并后的输出结果如下所示：
$ time python summarize logfiles.py --regex access bigger.log
 jmjones@ezr:/data/logss Is -1 access*1og
user
real
190.20.250.250
190.40.10.0
IP ADDRESS
190.20.250.250
IPADDRESS
CONSOLIDATED
************************
190.20.250.250
70.0.20.190
200.80.230.0
190.40.10.0
IPADDRESS
access_bigger.log
190.20.250.250
70.0.20.190
200.80.230.0
200.80.230.0
190.40.10.0
0m0.744s
0m45.547s
0m46.296s
BYTESTRANSFERRED
238039536
BYTES TRANSFERRED
15120000
1813840000
BYTESTRANSFERRED
237440000
237440000
593600
699160000
1818419946
700925379
699160000
37800
4534600
**
********
www.TopSage.com
+................======
****
********************
实例1407
一个希捷
---
## Page 422
408
会消耗更多的内存。但是我们可以做一些处理。以下是解析库的一个占用内存较少的版
report()在日志文件中保存了为每一个IP地址传输的字节列表。由此，更大的文件也就