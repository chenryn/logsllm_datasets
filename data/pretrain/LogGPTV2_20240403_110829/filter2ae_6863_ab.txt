    dog 0.5382389295846224
    frog 0.005475602301885374
    horse 0.12820508563891053
    ship 0.03867906052619219
    truck 0.0029019753128523007
    predict name:  bird
* * *
仅仅是加了一些随机的干扰，就使得图片在误差允许范围内从airplane被识别成了bird。  
为了不动脑，生成这种随机扰动就很好！！  
同时根据我学习对抗样本的经验，施加了如下的扰动， **没什么科学依据，只是这样随机性更大** :
    rd = np.random.rand(32, 32, 3).astype(np.float32)
    rd1, rd2 = rd, rd
    rd1 = rd1 * (rd1 > 0.5) * -1
    rd2 = rd2 * (rd2  0.5) * -1
            rd2 = rd2 * (rd2  200:
                continue
            n += 1
            pre_class1, pre_name, _ = predictimg(path, lenet)
            pre_class2, pre_name, _ = predictimg(path, lenet, judge=True, data=image_b)
        print("---adv image %d success---" % i)
        print("---error: %f---" % mse(image_a, image_b))
        print("---{} loops---".format(n))
        final_image.append(image_b)
    class1 = []
    class2 = []
    for i in range(8):
        path = DIR + "\\static\\{}.jpg".format(i)
        pre_class1, pre_name, _ = predictimg(path, lenet)
        class1.append(pre_class1)
    for i in range(8):
        pre_class2, pre_name, _ = predictimg(path, lenet, judge=True, data=final_image[i])
        class2.append(pre_class2)
    print(class1)
    print(class2)
    from PIL import Image
    for i in range(8):
        im = Image.fromarray(final_image[i].astype(np.uint8))
        name = "{}.jpg".format(i)
        im.save(name)
    print("Done!"")
* * *
结果
    Successfully loaded lenet
    ---adv image 0 success---    ---error: 196.508524---    ---2 loops---    ---adv image 1 success---    ---error: 199.452623---    ---4 loops---    ---adv image 2 success---    ---error: 198.868474---    ---9 loops---    ---adv image 3 success---    ---error: 193.501790---    ---10 loops---    ---adv image 4 success---    ---error: 197.218088---    ---1218 loops---    ---adv image 5 success---    ---error: 193.843418---    ---1226 loops---    ---adv image 6 success---    ---error: 193.986569---    ---1473 loops---    ---adv image 7 success---    ---error: 195.061129---    ---3890 loops---    [0, 7, 6, 0, 4, 1, 9, 6]
    [2, 6, 3, 6, 2, 3, 7, 4]
    Done!
运气好一点差不多循环4000次左右就能运行完毕。  
从两个预测结果来看 预测结果已经被我们全部修改成功，再把这些图片打包成一个zip传上去就行了。
* * *
最后结果没办法展示了，可能是我在windows端做的原因，tempfile模块始终有一些莫名其妙的问题，上传zip文件后总会出现一些问题。
**给的扰动范围大的话，可以用这种随机方法莽出来，不过我们还是要寻求一个正规做法。**
* * *
## 正规解法：
先介绍一下FGSM（fast gradien sign method）：  
是由Lan Goodfellow等人提出的。  
论文：.  
公式：  
  * sign：符号函数（正数输出1，负数输出-1）
  * x：输入的图像矩阵
  * y：预测值
  * J：损失函数，常为交叉熵
  * $\theta$ : 模型的参数
  * $\epsilon$ : 一个较小的扰动权重参数
  * $\eta$ : 最终向图像施加的扰动
* * *
直观的理解就是向图象是加了一个肉眼难辨的噪声，导致其模型的损失函数顺着梯度方向增大，这样样本的损失值就会增大，导致其预测结果会越过决策边界，从而被模型错误分类。  
想了解更多请阅读论文，毕竟我也是工具化的学习，理解并不深。
* * *
所以我们需要以下几个参数：  
损失函数，输入，预测值，正常结果，损失函数对输入的梯度。  
这里用keras.backend来实现，这个模块可以获取模型中间层的各种参数,很强大的模块。  
参考了  的写法
    image_a = plt.imread(path).astype(np.float32)
    image_a = color_process(image_a)
    tmp = image_a
    TARGET = np.argmax(model.predict(tmp)[0])
    target = np.zeros(10)
    target[TARGET] = 1
    session = K.get_session()
    d_model_d_x = K.gradients(keras.losses.categorical_crossentropy(target, model.output), model.input)
    eval_grad = session.run(d_model_d_x, feed_dict={model.input: image_a})[0][0]
* * *
为了保险起见，我在其中加上了随机扰动的保险，不过事实证明根本不需要。
    model = load_model("./networks/models/lenet.h5")
    n = 0
    DIR = os.path.abspath(os.path.dirname(__file__))
    eps = 1
    for i in range(8):
        path = DIR + "\\static\\{}.jpg".format(i)
        image_a = plt.imread(path).astype(np.float32)
        image_a = color_process(image_a)
        tmp = image_a
        TARGET = np.argmax(model.predict(tmp)[0])
        target = np.zeros(10)
        target[TARGET] = 1
        session = K.get_session()
        d_model_d_x = K.gradients(keras.losses.categorical_crossentropy(target, model.output), model.input)
        while np.argmax(model.predict(image_a)[0]) == TARGET:
            eval_grad = session.run(d_model_d_x, feed_dict={model.input: image_a})[0][0]
            fgsm = np.sign(eval_grad * eps)
            image_a = image_a + fgsm
            err = mse(image_a, tmp)
            n += 1
            if n % 1000 == 0:
                print("loops: ", n)
            if err > 200:
                rd = np.random.rand(32, 32, 3).astype(np.float32)
                rd1, rd2 = rd, rd
                rd1 = rd1 * (rd1 > 0.5) * -1
                rd2 = rd2 * (rd2  {}.{}:{}".format(pre, class_names[pre], conf_pre*100,
                                               now, class_names[now], conf_now*100))
        print("-"*60)
* * *
结果在平均扰动值95左右，就可以实现样本的误判，而且每次生成对抗样本仅仅需要一轮。
    error: 95.24999996137205, loop: 1
    0.airplane:59.14044976234436 ====> 6.frog:96.1998999118805
    ------------------------------------------------------------    error: 95.90625007138824, loop: 2
    7.horse:69.32011842727661 ====> 6.frog:99.58266615867615
    ------------------------------------------------------------    error: 95.90624985010452, loop: 3
    6.frog:35.53158938884735 ====> 3.cat:46.78606688976288
    ------------------------------------------------------------    error: 95.90624998283977, loop: 4
    0.airplane:53.729891777038574 ====> 9.truck:88.66733312606812
    ------------------------------------------------------------    error: 95.62500006915087, loop: 5
    4.deer:95.75170874595642 ====> 6.frog:67.56904721260071
    ------------------------------------------------------------    error: 95.15625016653229, loop: 6
    1.automobile:90.84147810935974 ====> 7.horse:83.24228525161743
    ------------------------------------------------------------    error: 95.71874987221618, loop: 7
    9.truck:77.83461213111877 ====> 5.dog:98.84703159332275
    ------------------------------------------------------------    error: 95.99999997530912, loop: 8
    6.frog:91.78876280784607 ====> 7.horse:43.60279738903046
    ------------------------------------------------------------    
再把数据转化成图片就可以了！  
题目以及解题的脚本我就传到附件了。
* * *
## 参考