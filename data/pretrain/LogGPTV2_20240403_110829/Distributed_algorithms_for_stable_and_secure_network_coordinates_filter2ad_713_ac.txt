time. For on-demand triggered recomputation, if a node detects a
5-ms median error change, it will send a recomputation request to
the membership server. The membership server will trigger coor-
dinates recomputation if it receives requests from more than 30%
of nodes. We simulate a scenario of dramatic delay changes. At
1800 second simulation time, the delays among the 500 nodes are
changed to another delay matrix that is randomly sampled from
p2psim data. At 2800 second, the delays are changed back to
original values.
In this experiment, we ﬁnd that, for periodical
recomputation, if the membership server triggers the recomputa-
tion from one node, it only takes 2.1s for the recomputation to be
ﬂooded throughout the whole system. When delays are dramati-
cally changed, it only takes 17s for the nodes to detect the delay
changes and trigger the on-demand recomputation. Figure 5 shows
the coordinates stability and accuracy, in which the top graph plots
the average coordinate movement, and the bottom graph shows the
median absolute error of the coordinates during the simulation pe-
riod. From this graph, we can see that, for all the cases, the re-
computation can be triggered quickly, and the coordinates can be
stabilized again with good accuracy in a short period of time.
4. COORDINATES SECURITY IN
DECENTRALIZED NETWORK
COORDINATES SYSTEMS
4.1 Coordinates Security Problem
As network coordinates systems are deployed in open network
environment, they must be able to handle many unexpected sce-
narios. One important problem is how to handle malicious attacks.
Malicious nodes may have different incentives to attack network
coordinates systems. Since network coordinates can be used to pro-
vide network proximity for applications, the disruption of network
n
o
i
t
c
n
u
F
y
t
i
s
n
e
D
y
t
i
l
i
b
a
b
o
r
P
0.5
0.4
0.3
0.2
0.1
0
−6
Good nodes
Malicious nodes
T:detection threshold
α: False negative
β: False positive
−4
−2
0
Metric value
2
4
6
Attack / Percentage
Shifting
Delay
0%
14.76
14.76
5%
20.06
17.56
10% 20% 30%
36.36
23.93
22.07
50.25
28.72
35.03
Table 1: Median absolute error (ms) of Vivaldi coordinates
with different percents of attackers
running, the distribution of statistical metrics can shift. Therefore,
the false negative and false positive rate can change. For existing
statistical detection mechanisms, it is hard to predict the evolution
of their detection performance. Thus, an empirical study is needed
to further understand the dynamic behavior of existing statistical
detection mechanisms.
Figure 6: Demonstration of metric distributions for statistical
detection
4.3 Empirical Study of the Existing Statistical
Detection Mechanisms
coordinates could result in the malfunctioning of applications that
use network coordinates. For example, when network coordinates
are used in geometric routing [8, 1, 13], the disrupted network co-
ordinates can totally destroy the routing in the network.
Furthermore, malicious nodes can attack existing decentralized
network coordinates systems easily. They can simply provide wrong
coordinates and/or delays to mislead other nodes in the system.
Previous work [11, 10, 35] has studied the performance of network
coordinates systems in adversarial environments. The results show
that without protection, a small fraction of malicious nodes can sig-
niﬁcantly degrade the accuracy of legitimate nodes’ coordinates.
Thus, the coordinates security problem can be stated as, how can
the system be protected such that the accuracy of the good nodes’
coordinates with respect to each other is unaffected by the behavior
of the malicious nodes?
4.2 Behavior of Statistical Detection
Mechanisms
Several previous studies [10, 35] have proposed to use statistical
detection mechanisms to identify misbehaving nodes. We study
the coordinates security problem by ﬁrst understanding how well
statistical detection can protect network coordinates.
The basic idea of statistical detection mechanisms is to use sta-
tistical metrics to differentiate good nodes from malicious nodes.
Ideally, if good nodes and malicious nodes present totally differ-
ent statistical behavior and the statistical metrics distributions for
good nodes and malicious nodes have no overlap, then we can set
a threshold to perfectly distinguish the good nodes from the mali-
cious nodes. However, in practice, the metric distributions always
have an overlapping area. Figure 6 demonstrates an artiﬁcial exam-
ple of metric distributions for good nodes and malicious nodes. If T
is the detection threshold used, then the shadowed areas represent
the false negative rate α and the false positive rate β.
To apply a statistical detection mechanism to protect a network
coordinates system, each node checks its neighbors using the de-
tection mechanism before relying on them as references to compute
coordinates. If a node A detects one neighbor B to be malicious,
this neighbor B will be discarded. To maintain a ﬁxed size neigh-
bor set, the node A will randomly ﬁnd another neighbor to replace
B. Different detection mechanisms may use different models for
detecting malicious neighbors.
Because of the false negative and false positive cases, a statis-
tical detection mechanism cannot detect all the malicious nodes.
On one hand, the false negative cases would miss some malicious
nodes; on the other hand, the false positive cases would falsely
remove good nodes and can potentially introduce more malicious
nodes into a node’s neighbor set. While the detection procedure is
4.3.1 Basic Principles
We ﬁrst introduce the basic principles of existing statistical de-
tection mechanisms.
The Kalman ﬁlter detection mechanism - The Kalman ﬁlter
mechanism [10] uses a set of trusted nodes called surveyors as ex-
ternal references to detect malicious nodes. Surveyors can only
choose surveyors as their neighbors, which sets up a clean network
coordinates system without malicious nodes. Each surveyor trains
a Kalman ﬁlter to model the error convergence features it observes.
The result is a set of Kalman ﬁlter parameters. Ordinary nodes may
have malicious nodes in their neighbor sets. Every ordinary node
retrieves the Kalman ﬁlter parameters from its nearest surveyor and
uses them to predict its own neighbors’ error. If the actual error
with respect to a neighbor deviates too much from the predicted
value, the neighbor is deemed malicious.
The Kalman ﬁlter model is an recursive ﬁlter that estimates the
state of a linear dynamic system from a series of incomplete and
noisy measurements. For a node i, at its nth embedding step, the
node uses its neighbor j to update its coordinates. Before the up-
date, the coordinate of i is Ci and the coordinate of j is Cj, the
RT T between i and j is RT Tij. The measured relative error at
step n is Dn =
. The nominal relative error at
embedding step n is denoted by Δn, which is the system state. The
Kalman ﬁlter uses the following equation to model the measured
relative error and nominal relative error.
|||Ci−Cj||−RT Tij|
RT Tij
Dn = Δn + Un
Δn+1 = βΔn + Wn
Where β is the recursive factor of the linear dynamic system,
Un is a Gaussian random variable with mean zero and variance
vU , which represents the error measurement noise. Wn is a white
Gaussian process with mean ¯w and variance vW , which represents
the error ﬂuctuation. This Kalman ﬁlter model can be presented by
a parameter set {β, ¯w, vW , vU , w0, p0}. Here, w0 and p0 are the
original states of the system.
The outlier detection mechanism - Unlike the Kalman ﬁlter
mechanism, the outlier detection mechanism [35] does not assume
any trusted external references. Every node totally relies on its
own observations to detect malicious neighbors. The idea is that, at
each embedding step, a node records several observed features of
its neighbors, such as the neighbor’s coordinates movement and er-
ror. The node then computes the Mahalanobis distance between the
current neighbor’s record and the centroid of all neighbors’ records.
The Mahalanobis distance is a weighted Euclidean distance, which
uses the correlations of different dimensions as weights. If a neigh-
bor deviates too much from the centroid, it will be deemed as mali-
cious. Two outlier detection techniques are proposed in [35]: spa-
e
c
n
a
m
r
o
f
r
e
p
n
o
i
t
c
e
t
e
D
1
0.5
0
0
False negative
False positive
500
1000
2000
Simulation time(s)
1500
2500
3000
0.4
0.2
0
0
500
1000
2000
Simulation time(s)
1500
2500
3000
e
c
n
a
m
r
o
f
r
e
p
n
o
i
t
c
e
t
e
D
s
e
d
o
n
s
u
o
c
i
i
l
a
m
f
o
n
o
i
t
c
a
r
F
1
0.5
False negative
False positive
0
0
500
1000
2000
Simulation time(s)
1500
2500
3000
0.4
0.2
0
0
500
1000
2000
Simulation time(s)
1500
2500
3000
e
c
n
a
m
r
o
f
r
e
p
n
o
i
t
c
e
t
e
D
s
e
d
o
n
s
u
o
c
i
i
l
a
m
f
o
n
o
i
t
c
a
r
F
1
0.5
False negative
False positive
0
0
500
1000
2000
Simulation time(s)
1500
2500
3000
0.4
0.2
0
0
500
1000
2000
Simulation time(s)
1500
2500
3000
(a)
(b)
(c)
Figure 7: Detection performance for shifting attack (a) Spatial outlier detection (b) Temporal outlier detection (c) Kalman ﬁlter
detection
e
c
n
a
m
r
o
f
r
e
p
n
o
i
t
c
e
t
e
D
1
0.5
0
0
False negative
False positive
500
1000
2000
Simulation time(s)
1500
2500
3000
0.4
0.2
0
0
500
1000
2000
Simulation time(s)
1500
2500
3000
e
c
n
a
m
r
o
f
r
e
p
n
o
i
t
c
e
t
e
D
s
e
d
o
n
s
u
o
c
i
i
l
a
m
f
o
n
o
i
t
c
a
r
F
1
0.5
False negative
False positive
0
0
1000
2000
4000
Simulation time(s)
3000