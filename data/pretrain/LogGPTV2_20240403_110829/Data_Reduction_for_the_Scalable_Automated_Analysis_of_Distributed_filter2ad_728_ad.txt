5(0)
0(0)
7(0)
16(2)
9(0)
9(0)
8(0)
11(0)
3(0)
100(0)
21(4)
I/21
12(1)
8(1)
7(0)
4(0)
0(0)
5(0)
13(2)
7(0)
7(0)
6(0)
8(0)
2(0)
14(2)
100(0)
Table 1: The average (and stddev) percentage overlap in source IP addresses between (row, column) medium to large
darknets over a month period.
Figure 10: The number of darknets (of 31) reporting a port
in the top 10 ports over a day, week, and month time frame.
The analysis is performed for the top 10 destination ports
over a day, top 10 destination ports over a week, and top
10 destination ports over a month. This ﬁgure shows that
there are over 30 destination ports that appear on at least
one darknet’s top 10 list. A small handful of these desti-
nation ports appear across most darknets (1433, 445, 135,
139), but most of the destination ports appear at less then
10 of the darknets. As with the result seen with source IP
addresses, the lack of consistency between darknets implies
a broader number of connections to be evaluated, because
of the broader number of non-overlapping destination ser-
vices being contacted.
5.2 Understanding the Overlapping Size
The lack of overlap between various darknets in terms of
source IP addresses, as well as destination ports, stems
from four properties of the monitoring technique and the
trafﬁc.
The impact of monitored block size, scanning rate, and
observation time on the probability of identifying a ran-
dom scanning event. The effect of monitoring block size
Figure 11: The duration of source IP address observa-
tions at the /8 darknet over a one week period for 4 known
worms.
on the detection time of remote events is a well-studied
phenomena [22]. Table 1 does show larger blocks with
overlapping source IP addresses. However, the largest of
these, although highly variable, only sees an average of
50% overlap.
The lifetime of the events. One possible explanation of
this lack of overlap is that the events being observed are
too short lived. To examine this, we looked at the behavior
of four familiar worms whose (random and non-random)
scanning behaviors are well known. Figure 11 shows this
result. We recorded the observation lifetime of the source
IP addresses across our /8 darknet. It should be noted that
this method can only approximate the actual lifetime as the
/8 darknet may only observe part of the worm’s propagation
behavior. With this caveat in mind, we note a signiﬁcant
faction of the source IP addresses seen at this darknet had
a lifetime of less than a day. However, more than 50%
had lifetimes of over an hour, which is sufﬁcient at most
scanning rates (greater than 10 connections per second) to
be observed at the bigger darknets.
USENIX Association
Internet Measurement Conference 2005  
247
010203040Port ID010203040Number of Sensors Reporting Port1 Day1 Month1 Week1101001000100001e+05Seconds00.10.20.30.40.50.60.70.80.91Cumulative ProbabilityBlasterCodeRedIINimdaSasser1 Minute1 Hour1 DayTargeted attacks. While the above explanations explain
some of the lack of overlap, a signiﬁcant number of source
IPs are still not overlapping. It is our conjecture that these
are representative of targeted behaviors and attacks. While
this conjecture is difﬁcult to validate without monitoring at
the sources of these attacks, we can look at the distributions
of destination ports for some insight as to whether the same
services are being contacted across darknets. Recall that
Figure 10 showed the number of darknets that report a port
in their top 10 over increasing time frames of a day, week,
and month. The results show that, although there are a few
ports which are globally prevalent, a large number of the
ports are seen over these time frames at very few blocks.
Environmental factors. In [7] we showed that a variety
of factors, including ﬁltering policy, propagation strategy,
darknet visibility, and resource constraints, affect the mix
of the global trafﬁc a darknet should see. These properties
provide subtle inﬂuences beyond the impact of the targeted
behavior discussed above.
5.3 Effects on Hybrid Scalability
One of the drawbacks of any of the source-based tech-
niques discussed in the previous section is their reliance
on the source IP address as part of the ﬁlter. For a dis-
tributed technique based on these methods to be effective,
source IP addresses must be prevalent across darknets. Un-
fortunately, our analysis shows this not to be the case. In
order to quantify the effectiveness of source-based methods
across darknets we consider the same 14 darknets as in the
previous section. We choose source-port ﬁltering and look
at the reduction in unique (source, port) pairs across dark-
nets over the same 10-day period. While this method was
effective at reducing the packet space by 95%, there is only
a modest 20% reduction when these methods are applied
across darknets.
In this section we examined the properties of distributed
darknets to understand the scaling properties of a hybrid
system. We evaluated the properties of source IP addresses
and destination ports across darknets and observed a sig-
niﬁcant number of non-overlapping destination ports and
source IP addresses. While some of these differences are
the result of well-known size and rate effects of darknet
monitoring, other factors, such as the short on-time of ran-
dom scanning hosts and the targeted nature of attacks ob-
served at these darknets help to explain the additional dif-
ferences. The impact of these non-intersecting events is
that each individual new darknet added to a hybrid system
is likely to signiﬁcantly increase the total number of con-
nections that need to be evaluated. If a hybrid system is to
scale in this type of environment, a new deﬁnition of events
and new methods of ﬁltering are required.
6 Aggressive Distributed Filtering
In the previous sections, we discussed source-based ﬁlter-
ing at individual darknets and the application of those ﬁl-
tering techniques to distributed darknets for the purpose of
building a scalable hybrid system. We noted that source-
based techniques were much less effective across darknets
for two main reasons: source IP addresses are not typically
visible across darknets in time frames that are useful and
many attacks may be targeted at individual darknets only.
In this section we examine techniques for ﬁltering that
explicitly account for these observations. In particular, we
examine the number of unique source IP addresses per des-
tination port, and we examine the number of darknets re-
porting an event. We combine these variables with the
technique of threshold-based alerting to provide a ﬁlter that
passes trafﬁc on global increases in the number of source
IP addresses contacting a destination port.
Alerting of trafﬁc changes by observing trafﬁc to live
hosts is a well studied area. Existing methods have alerted
once trafﬁc has reached a static threshold [27] or for thresh-
olds that were adapted dynamically [14]. Further attempts
to model trafﬁc behavior that can be used for detect-
ing changes include signal analysis [29], probabilistic ap-
proaches [18], and statistical approaches [12]. In this sec-
tion we extend the existing techniques to look at adaptive
threshold-based alerting for trafﬁc to unused address space.
Similar in vein to other source address distribution alert-
ing mechanisms [40], we watch the distribution of unique
source IP addresses to a speciﬁc port. Our work differs
from this in several key ways: we modify the algorithm to
explicitly allow for varying notions of current and historic
behavior, we modify it to watch the distributions across
multiple darknets, and we incorporate the notion of global
versus local behavior.
Our current event identiﬁcation scheme uses an adaptive
threshold mechanism to detect new events. Every hour,
each darknet is queried for the number of unique source
IP addresses that have contacted it with destination port x
(where x ranges over a list of destination ports we are mon-
itoring). The event identiﬁcation algorithm looks at the col-
lected data and works as follows for each destination port x.
For each hour, add up the number of unique source IP ad-
dresses contacting destination port x at each darknet. Scan
over this data one hour at a time, comparing the average
(per hour) over the event window (last event window hours)
to the average over the history window (last event window
× history factor) hours. If the ratio of event window av-
erage to history average is greater than the event thresh-
old, an event is generated. These events are then ﬁltered
based on whether they are global or local, via the coverage
threshold. The coverage threshold deﬁnes the number of
darknets that would have generated an event individually
for a threat. Events will not be generated more than once
248
Internet Measurement Conference 2005
USENIX Association
Figure 12: The effect of event window size on the number
of events generated.
Figure 13: The effect of history factor on the number of
events generated.
in a single event window. To protect against false positives
on destination ports that have little or no trafﬁc destined
to them, whenever the sum of unique source IP addresses
from all blocks to a speciﬁc destination port is less than
one, the data point for that hour is set to 0.6. The event gen-
eration algorithm then is parameterized by four variables:
the event window, the history window, the event threshold,
and the coverage.
7 Evaluation and Deployment Results
In this section, we investigate the parameter space of the
event identiﬁcation algorithm and then evaluate it by com-
paring both the security events we identify and those iden-
tiﬁed by the community.
Figure 14: The effect of event threshold on the number of
events generated.
7.1 Parameterization
As discussed in the previous section, there are four basic
parameters that impact the generation of a new event. In
this section, we explore the tradeoffs associated with each
of these parameters using data collected at 23 of the 60 IMS
blocks from January 1st through April 30th, 2005.
The ﬁrst parameter we explore is that of the event win-
dow. Recall that the event window deﬁnes the interval over
which the current value is computed via a weighted moving
average. Figure 12 shows the effect of the event window
size in hours on the number of events generated for ﬁxed
window size and event threshold. The curve shows that the
number of events vary from over 700 to a nerarly steady
value of 100, with a signiﬁcant reduction by a value of ﬁve
hours. One possible explanation for this reduction is that
many of the events are in fact short bursts, and longer event
window sizes reduce the impact of single hour bursts.
History factor deﬁnes the period of time over which nor-
mal behavior is calculated via a weighted moving average.
The effect of various history factor values on the number
of events is explored in Figure 13. A history factor of two
appears to reduce the number of events greatly. It is also
interesting to note the crossover in event window size, with
an event window of 12 hours creating more events than a
smaller window of 6 hours. We ﬁnd no signiﬁcant dif-
ference in protocol or source distribution between these
two sets. We are continuing to investigate two additional
hypotheses: that sequential scanning activities need more
time to reach additional darknets, and that there are fre-
quency components of darknet trafﬁc that are different than
that of other Internet trafﬁc.
Figure 14 shows the effect of the event threshold on the
number of events. The event threshold indicates the de-
gree to which the current value is different than the historic
value. This parameter shows the largest impact on events
USENIX Association
Internet Measurement Conference 2005  
249
05101520Event Window (Hours)0200400600800EventsHistory Factor = 6History Factor = 12History Factor = 2405101520History Factor050100150200250EventsEvent Window = 6 HoursEvent Window = 12 HoursEvent Window = 24 Hours0510152025Event Threshold110100100010000EventsEvent Window = 3Event Window = 6Event Window = 12Event Window = 24Description
WINS
Squid and
Alt-HTTP
SYN Scan
MYSQL
Syn Scan
Veritas
Port
tcp42
tcp42
tcp42
tcp3128
tcp3128
tcp8080
tcp8080
tcp3306
tcp3306
tcp3306
tcp5000
tcp6101
tcp6101
Date
01/13/05 17:31
01/14/05 05:31
01/14/05 17:31
02/05/05 11:31
02/05/05 23:31
02/05/05 10:51
02/05/05 22:51
01/26/05 09:31
01/26/05 21:31
01/27/05 09:31
01/08/05 14:31
02/23/05 21:32
02/24/05 09:32
Multiple
5.36
61.85
9.77
7.73
18.19
7.53
20.95
43.89
8.2
5.7
3.42
3.54
3.81
Coverage
0.4815
0.8889
0.6667
0.4074
0.4074
0.4074
0.3704
0.3704
0.4444
0.4074
0.6667
0.3704
0.3333
Table 2: The interesting features identiﬁed by the algorithm
since January of 2005. The “multiple” column speciﬁes
how many times larger the current window is compared to
the history window. Coverage reports the percentage of
sensors which would have alerted independently.
non-optimal parameters: alert window of 12 hours, history