### Truth Construction and Verification in Location Data

The truth construction in [25] was at the postcode level, while Cheng et al. [19] did not verify their home selection with any form of ground truth. Similarly, in [20], the authors constructed a ground truth using 25x25 km cells, stating that "manual inspection shows that this infers home locations with 85% accuracy." However, they did not provide detailed information on the verification process. Additionally, the datasets in [39], [34], and [43] contained only home locations. Lin et al. [43] based their dataset solely on the visual inspection of GPS data points. In [34], the authors relied on manual inspection of tweet content to identify home locations, but this was conducted by Amazon Mechanical Turk workers who were shown only a subset of five tweets from each cluster. In contrast, our method involved a comprehensive manual inspection of all tweets assigned to each cluster.

### Location and De-anonymization

The problem of identifying key locations has been explored in various settings. For example, Golle and Partridge [30] investigated how users can be identified from different granularities of anonymized census data. De Montjoye et al. [24] found that four coarse-grained spatiotemporal points can uniquely differentiate 95% of users in a 15-month dataset for 1.5 million people. Chong et al. [67] reported a 93% predictability in mobility by measuring the entropy of users' trajectories. Rossi et al. [62] demonstrated that as few as two location points may be sufficient to uniquely identify users. Zang et al. [72] leveraged an anonymized three-month dataset of mobile call records and discovered that even the top-2 most frequented locations (even at coarse granularities) can re-identify a user.

### User Behavior and Social-Tie Inference

Prior work has also explored how users interact with or disclose location data and the feasibility of social-tie inference. Liccardi et al. [42] examined how different ways of visualizing data affected users' ability to infer the type of a location (home, work, etc.). Ahern et al. [13] found that users are more likely to set photos taken at frequently photographed locations as private, while tending to set photos from less frequented locations as public. Consolvo et al. [22] found that users were willing to disclose exact locations, but their study focused on sharing information with friends, family, and colleagues. Tang et al. [68] identified how users adapt their location-sharing behavior under different hypothetical scenarios. Cheng et al. [19] conducted a large-scale study of location data, examining mobility patterns and the correlation between check-ins and message content and sentiment. Sadilek et al. [64] proposed a probabilistic human mobility model for predicting users' social links and locations, considering users who disclose GPS coordinates as noisy sensors for inferring the location of their friends. Other works, such as [23], [52], [65], and [73], leverage spatiotemporal data for inferring social ties. Backes et al. [15] developed an attack for inferring social relationships from mobility data, while Aronov et al. [14] used relationships and co-location at events to infer other potentially visited locations.

### Aggregate Location Data and Privacy

Previous studies have also examined how aggregate location time-series can lead to significant privacy loss. Pyrgelis et al. [58] presented a methodology to study membership inference on such data, formalizing the problem as a distinguishability game. They showed that such attacks are feasible and can lead to significant privacy loss depending on factors like the adversary's prior knowledge and aggregation group sizes. Shokri et al. [66] evaluated membership inference using a dataset of Foursquare check-ins. Pyrgelis et al. [59] studied how aggregate location data can be leveraged to localize and profile individual users under different adversarial knowledge scenarios. Xu et al. [70] demonstrated that it is possible to recover individual user trajectories from aggregate location data with high accuracy, highlighting the uniqueness of the recovered trajectories that enable re-identification attacks.

### Conclusions

We have investigated the privacy threats arising from precise location metadata being publicly accessible in Twitter's API. By developing novel techniques for identifying a user's exact home and work location, and inferring sensitive information through the reconstruction of a user's location history, LPAuditor highlights the true extent of the risk of exposing such information. Our experimental evaluation revealed that Twitter's previous policy of including precise location data in app versions has significant implications, resulting in an almost 15-fold increase in the number of users whose key locations are successfully identified by our system. Given that users are likely unaware of this privacy leakage, it is crucial to shed light on this invasive practice. We hope that our work will serve as a cautionary tale, equipping users with the means to manage their personal data and avoid the risks of public exposure.

### Acknowledgments

We would like to thank the anonymous reviewers for their valuable feedback. Special thanks to our shepherd Emiliano De Cristofaro for his help. This research received funding from the European Unionâ€™s Marie Sklodowska-Curie, grant agreement No 690972, and Horizon 2020 Research & Innovation Programme under grant agreements No 780787 and No 740787, the Defense Advanced Research Projects Agency (DARPA) ASED Program, and AFRL under contract FA8650-18-C-7880. The views expressed in this paper are those of the authors, and the funding bodies are not responsible for any use that may be made of the information it contains.

### References

[References listed here as in the original text]

This version of the text is more structured, clear, and professional, making it easier to read and understand.