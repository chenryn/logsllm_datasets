ers from client organizations. The client organizations consented
submit jobs to execute the malicious payload
Decoding a Base64-encoded file into a malicious executable file
Execute the specified remote or local .SCT script
Install and execute malicious code from remote servers
Build and execute a C# project stored in the target file
to this data being collected and exported to a cloud service. Infor-
mation about user accounts and computers is anonymized and no
personal information is collected. We analyze the collected data,
develop a novel embedding method to convert command-line text
into a numerical feature vector representation, and build an active
learning framework that minimizes the analysis time required by a
human expert to train more accurate classification models.
2.2 Threat model
We consider cyber attacks in which remote adversaries obtain a
footprint in an environment such as an enterprise network through
some initial infection mechanism (e.g., social engineering, drive-by
download). LOL attacks occur on the victim’s computer or network
after the initial compromise. The remote adversary might obtain
shell access to the victim’s computer, and is usually interested in
obtaining reconnaissance information on the victim network, as
well as performing lateral movement to other machines and servers
on the network. The adversary employs LOL attacks to increase
the attack’s stealthiness, evade existing intrusion detection tools,
and remain undetected in the target network for extended periods
of time. These actions are usually part of multi-stage attacks, such
as those used by Advanced Persistent Threats (APTs), where the
ultimate goal of the attacker is to obtain confidential information
from the target organization.
In our setting, an adversary might impact the data collection only
in a limited manner. In theory, a sophisticated attacker might tamper
with the logging software to prevent it from recording malicious
commands on the victim machines. However, our dataset is obtained
from millions of computers distributed around the globe, and we
assume that the adversary does not have the ability to actively
tamper with the logging software on a large number of machines.
Moreover, the particular client logging software we rely upon runs
in the kernel and is hardened to detect active data tampering. Once
the logged data is sent to the cloud server, data labeling is performed
securely at the cloud side and the adversary does not have access
to the data labeling process.
2.3 Background on Word Embeddings
Representing textual data in machine learning tasks has been stud-
ied extensively [22, 23, 30, 37]. Since machine learning models re-
quire numerical input representations, tokens (e.g., words, n-grams)
in the text need to be mapped to a numerical space.
444RAID ’21, October 6–8, 2021, San Sebastian, Spain
Ongun, et al.
Bag of words (BoW) [22] and term frequency inverse document
frequency (TF-IDF) [37] approaches construct numerical word-level
representations for documents. While a BoW model captures sim-
ply the word frequencies in each document, TF-IDF assigns more
weight to rare words appearing only in a small number of docu-
ments. Even though these approaches are commonly used for many
NLP tasks, they do not generalize well for LOL command-line data
that typically includes many new tokens (unseen words). In partic-
ular, command-line arguments and parameters change frequently
with command usage. The dictionary size and its associated feature
vector length can grow significantly due to these rare tokens.
Another area for text processing that has been developed in
recent years in NLP is contextual embeddings. word2vec [30] is
a technique to represent individual words as a low-dimensional
numerical vector such that the contextual information of each word
is embedded in the resulting vector. A set of documents containing
a sequence of words are used to train these models. The context is
defined by the words that are in the same window of k words in the
sequence. Words that occur in similar contexts will be closer in the
embedding vector space. However, word2vec has the shortcoming
that it is unable to represent words not seen during the training
phase. Another method developed to reduce the amount of memory
and address the problem of unseen words is fastText [23]. fastText
creates character n-grams from given words to learn the vector in a
similar fashion. Unseen words may be vectorized using this method
if n-grams of the word exist in the training data. In this work, we
take advantage of these embedding techniques to represent process
command-line text to train the machine learning models. Their
advantage compared to BoW and TF-IDF is that they take into
account the sequence of tokens in a command and the context
surrounding each token.
3 METHODOLOGY
In this section, we describe our methodology for detecting adver-
sarial Living-Off-The-Land commands. We first describe our novel
use of word embeddings for command-line feature generation, used
as input to the machine learning classifiers for detecting malicious
commands. Second, we describe the design of our active learning
framework, with the goals of improving the detection performance
and optimizing the human analyst effort in the process.
3.1 Feature Representation
Our main insight in detecting LOL attacks is that the malicious
usage of binaries can be inferred from the command-line string
that includes the binary name and the supplied arguments. In or-
der to have more context information for the command lines, we
concatenate command lines of the parent process and the created
process to define a single sample.
ML classifiers trained for detecting LOL attacks require the trans-
formation of command lines into numerical vector spaces. We pro-
pose novel command-line embedding methods to generate these
numerical representations, based on recent techniques from the
NLP community. We first perform tokenization of the raw command
lines, and then we apply word embedding techniques to generate
vector representations for tokens. Finally, we aggregate these vec-
tors and define new features to represent the full command-line
text as a single fixed-length vector. We call our novel command
embedding method for generating feature vector representations
from command lines cmd2vec. An overview of the cmd2vec feature
generation process is given in Figure 2, and the steps are described
in detail below.
Tokenization. Each sample consists of a parent and a child
command-line string, as the malicious intent could be inferred from
the combination of both processes. Command lines can include
a variety of different types of fields such as commands, options,
directories, URLs, or embedded scripts. We define tokens as building
blocks for a command-line text. Certain tokens could be a strong
indication of malicious behavior, and some tokens could be lost due
to improper parsing rules. Thus, tokenizing the command line to
obtain a representative token sequence that captures the structure
of the command is an important task.
We follow a generic and conservative approach where we parse
the string based on common words and command delimiters (e.g.,
‘,’, ‘.’, ‘/’, ‘-’, ’ ’). This method ensures that we capture both the
command structure and the natural words that appear within the
arguments. Using these delimiters, we split the command line into
words that appear between delimiters. It is important to note that
we also include the delimiters (with the exception of empty space)
among the tokens since they supply useful information about the
neighboring tokens.
For instance, the command "cmd.exe /c bitsadmin.exe /transfer
getitman /download /priority high http://domain.com/suspic.exe
C:\Users\Temp\30304050.exe" is tokenized as [‘cmd’, ‘exe’, ‘c’, ‘bit-
sadmin’, ‘exe’, ‘transfer’, ‘getitman’, ‘download’, ‘priority’, ‘high’,
‘http’, ‘domain’, ‘com’, ‘suspic’, ‘exe’, ‘c’, ‘users’, ‘temp’, ‘30304050’,
‘exe’], with the delimiters inserted between these tokens.
Contextual Embedding Model. After splitting each command-
line sample into a token sequence, we represent them numerically
in a meaningful way that captures contextual information. We
propose the use of modern word embedding techniques from NLP,
including word2vec and fastText, for our task.
Generating the embedding models is an offline, unsupervised
process that relies on a large corpus of command lines for train-
ing. First, we build the dictionary of tokens and apply some filters
to represent the data in a compact and generic way. One of the
challenges in training word2vec models is that they cannot create
representations for new tokens that are not already in the dictio-
nary. We address this by creating a special “rare” token, used for
those tokens appearing once in the corpus. Furthermore, numerical
tokens (tokens that consist only of digits) usually do not retain
meaningful semantics and are also replaced with a special “number”
token. These replacements retain the essential information about
each command, while maintaining a manageable dictionary size.
In the example above, getitman is replaced with the “rare” token,
and 30304050 is replaced with the “number” token.
Token Score Generation. Our hypothesis is that malicious
command lines tend to include certain tokens more often compared
to benign commands. In order to gain insights into the token usage
and incorporate them into our features, we define a method to
score each individual token based on the labeled data. For each
labeled sample, we define the token features to be the corresponding
word embedding given by either the word2vec or fastText model,
appended by the one-hot-encoding representation of the LOLBIN
445Living-Off-The-Land Command Detection
Using Active Learning
RAID ’21, October 6–8, 2021, San Sebastian, Spain
Figure 2: Overview of the command line embedding process in cmd2vec.
name of the sample (which has a small size, as the number of
LOLBINs is limited). The inclusion of the LOLBIN encoding among
the features enables representation of tokens in different contexts.
This is useful as one token usage in a specific LOLBIN may show
malicious intent, whereas for other binaries it is used as part of a
benign operation. Then, we fit these values into a Random Forest
classifier [10] with their respective labels (1 for malicious, 0 for
benign). One command-line sample has multiple tokens and a single
label. In this case, each token is separately labeled with the label of
the sample. A Random Forest classifier is trained with N decision
trees (denoted by tθi ) to build the overall ensemble model (denoted
by Tθ ) that outputs a binary prediction y. In each individual tree,
the probability that a token is malicious is given by:
P(y = 1|token, tθi) =
# positive samples in the leaf
# samples in the leaf
.
(1)
The model generates the score for each token by simply taking
the mean of probabilities over the forest:
N
i =0
Score(token|Tθ) = 1
N
P(y = 1|token, tθi).
(2)
In the end, for each (token, LOLBI N) pair in our dataset, we get a
score that represents the probability of it being malicious. Typically,
this score will be high if a token is used in malicious command
lines, but used less frequently or never in the benign samples and,
similarly, the score will be low if the token appears predominantly
in benign samples.
Token score generation relies on access to labeled samples. The
active learning framework starts with default scores for unknown
tokens. Over multiple iterations, scores can be updated periodically
based on the collected labeled dataset.
Feature Vector Generation (cmd2vec). In the previous steps,
command line samples have been transformed into a sequence of
numerical vectors, and token scores have been generated. Each
msbuild.exe pshell.xmlProcess Creation Datasetmsbuildexe.xmlInputProjectionPredictpshellTokenizationEmbedding Model Trainingmsbuildpshellxmlexe.Word Vectorsmsbuild.exe pshell.xmlLabeled DatamsbuildpshellexeWord VectorsCommand LineMaliciousLabel32-1Malicious-123Malicious-132MaliciousLabeled Token VectorsTrain TokenClassifierToken Scoresmsbuild.exe pshell.xmlProcess Creation DatasetmsbuildpshellexeWord VectorsCommand Line32-1-123-132Token Scores0.010.50.8Token ScoreMin-Max-AvgPooling-1Aggregated Feature VectorTop KMin ValuesToken Score GenerationFeature Vector Generation (cmd2vec)Contextual Embedding Model2-13330.32.31.30.50.010.83001Max ValuesAvg PoolingTop ScoresLOLBIN classOne-hot-encodedRareCountTokenCount000010000100001000LOLBIN ClassWord VectorLabel446RAID ’21, October 6–8, 2021, San Sebastian, Spain
Ongun, et al.
command line consists of a different number of tokens. In order to
represent each command line as a fixed-length feature vector with-
out trimming or padding, we use a number of aggregation methods
on the tokens. The pipeline for feature generation is illustrated in
Figure 2. We apply min-pooling, max-pooling, and average-pooling
to combine these vectors to construct a fixed-length representa-
tion for the whole command line. We use the token scores as the
weights for average-pooling to make the signal of the potentially
malicious token stronger. We also add the total token count and
the rare token count as separate numerical features since these
capture some characteristics of malicious behavior (e.g., unusually
long command lines and a large number of rare tokens). We then
append the maximum three scores of the tokens in the sample as
separate features together with the one-hot-encoded representa-
tion of the LOLBIN name. In the end, the number of features for
a command-line sample is 3 · embeddingSize + 5 + lolbinCount,
where embeddingSize is the size of the command embedding and
lolbinCount is the number of LOLBIN classes.
3.2 Active Learning Framework
Active learning is typically used in ML scenarios where limited la-
beled samples are available, and it is fairly expensive to expand the
set of labeled samples [45]. Instead of randomly sampling instances
for labeling by an analyst, active learning defines adaptive algo-
rithms for sample selection. Active learning strategies might differ
in how they select the samples for human analyst labeling, and how
they perform training iteratively. Membership query synthesis [3]
requests labels for constructed samples drawn from the input space.
Stream-based sampling [6] selects samples from a real underlying
distribution one at a time, whereas pool-based sampling [24] se-
lects instances from a pool of unlabeled samples. Query strategies
for active learning include uncertainty sampling [24], query-by-
committee [46], expected error reduction [39], and variance reduc-
tion [12]. While the best strategy to employ is application specific,
margin-based uncertainty sampling is an effective approach that is
used by a variety of active learning applications, as other methods
have higher model complexity and run-time cost [42, 45].
We propose for the first time the design of an active learning
framework for detecting malicious command lines, such as those
occurring in LOL attacks. The ultimate goal of this system is to train
a multi-class classifier that predicts whether a command-line sample
is benign or belongs to one of the malicious classes (e.g., Malicious
Certutil, Malicious Regsvr32). We design our system to leverage the
labeled samples of malicious LOL commands, and use supervised
ML classification techniques to distinguish between malicious and
benign samples. Anomaly detection methods could be applied as
well, but they do not use the malicious ground truth and tend to
have higher false positive rates [48]. We leverage anomaly detection
for sample selection within each class to find new patterns that
are suspicious and provide them to the analysts during the active
learning process.
We choose multi-class classification to separate different classes
of malicious behavior. Using multiple classes is useful for identify-
ing anomalies per class after classification. Anomalies for the entire
malicious class might not accurately represent class-level anomalies
and uncertain samples that are between two malicious classes may
also uncover interesting behavior. The class labels are set by the
analysts and are not necessarily simply the malicious or benign use
of each LOLBIN (e.g., Malicious Bitsadmin). Instead, the analyst can
choose to assign more fine-grained subclass labels for each LOLBIN
in a deployment setting. For example, an individual LOLBIN may be
used in a specific way by a particular threat actor group. In this case,
the item could be labeled as “Malicious Bitsadmin Threat Actor 32”
or an analyst can create a class with more behavioral descriptions
(e.g., reconnaissance, remote-code execution). Furthermore, an in-