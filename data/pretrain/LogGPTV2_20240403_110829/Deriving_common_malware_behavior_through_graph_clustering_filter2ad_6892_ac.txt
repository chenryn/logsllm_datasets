jection of gratuitous system calls. These do not affect the malicious
behavior of the malware, but simply attempt to obscure it.
An experiment was run to measure the inﬂuence of injected sys-
tem calls on the ability of the proposed method to correctly de-
tect malware.
In this experiment, system call traces of varying
lengths were copied from traces of the execution of benign (non-
malware) applications. These copied traces were then pasted at
random places into the system call traces of malware instances. The
amount of copied system calls was varied from 0% to 100% of the
length of the original malware system call traces. Following this,
the signiﬁcantly modiﬁed (injected) system call traces of malware
instances in the training set were matched against the pre-generated
WCBGs.
Figure 5: Detection rates against system call injection attack.
((cid:2)=0.5, (cid:13) = 0.7)
Figure 5 shows the results. Only families actually affected by
the system call attacks are shown in the ﬁgure. The Bagle, the
Netsky, and the Mytob families, except for the Allaple family, were
unaffected by the system call attacks, and are therefore not shown.
For the affected families, the detection rates decreased according
to the attack rates. However, the reduction in detection plateaus at
50%; there is no further change as the call injection rate increases
to 100%. At a 40% injection rate, detection rates for these families
decreased by roughly 30%.
Threshold Selection: The proposed method has two parameters,
(cid:2) (which affects the size of the common behavioral graph) and (cid:13)
(which controls the sensitivity of malware detection). The system
performance is not signiﬁcantly impacted by (cid:2), since the HotPath
remains the same regardless of (cid:2). The value of (cid:13) used in section 3
was selected based on experimentation. The value of (cid:13) is knee of
the curve where the detection rates doesn’t make much difference.
By the experimental results in Section 3, (cid:2) should be between 0.2
and 0.5, and (cid:13) should be from 0.5 to 0.9.
Other Features: An experiment was run to investigate the in-
ﬂuence on the common behavioral graph sizes of the number of
binaries used for their construction. This shows the scalability of
the common behavioral graph depending on the number of binaries
added. The results indicate there is virtually no change in either the
size of the common behavioral graphs, or in the size of the Hot-
Paths. In addition, the proposed method has overhead for system
call tracing primarily depends on the malware analysis framework,
which in our case is Ether. Compared with other dynamic behavior-
based malware detection methods, the system overhead is insigniﬁ-
cant only if system call traces are examined [17, 27]. The overhead
of behavior graph construction is clearly very small (0.1 seconds or
less). Details are omitted due to space limitations.
4. RELATED WORK
Behavior-based malware detection can be achieved by static anal-
ysis or dynamic analysis.
Malware analysis and detection using static disassembly has been
proposed for years. The behaviors recoverable by static analysis
are interpreted as “semantics” of a program. Existing methods use
control ﬂow and data ﬂow analysis, semantics, abstract models and
templates that describe the behavior of malicious programs [13, 25,
7, 14, 18, 29]. The usefulness of static analysis depends on the a-
bility to correctly disassemble binaries, which has been shown to
be problematic for packed code [11, 26].
Malware detection by monitoring the execution of a running pro-
gram is a promising solution for overcoming the limitations of stat-
ic analysis [5, 22]. For monitoring such behaviors, several analy-
sis platforms have been developed recently [26, 11, 28]. Panora-
ma [28] emulated malicious code to capture system-wide informa-
tion ﬂow based on tainted sources from the network interface or
keyboard. Malspecs [6] extracted malicious behaviors, which are
different from benign behaviors of benign programs, by using sys-
tem call invocation. Based on taint information in instruction traces
and memory logs, Inspector Gadget [16] utilized dynamic program
slicing to extract a domain generation algorithm currently used in
malware.
Although these approaches detect malware effectively through
taint tracking, they require execution emulation and cause signif-
icant performance overhead, as discussed in [17]. Kolbitsch et.
al [17] proposed an effective and efﬁcient malware detection method
based on a system call behavioral graph by using dynamic program
slicing. This model captures data ﬂow dependencies between sys-
tem calls of interest. By using the crafted model, their method can
be used at end hosts for detection, without resorting to taint anal-
ysis. Additionally, kernel objects at the level of the OS have also
been used to analyze malicious behaviors for malware classiﬁca-
tion [2, 1]. In comparison, our method uses the relationship among
kernel objects by using only system call traces. The relation was
shown as a common graph, which is totally new method to detect
malware with small overhead and high scalability.
5. CONCLUSION
This paper proposed a new method for detecting malicious soft-
ware (malware) instances by using a kernel object behavioral graph
(KOBG). The method uses kernel object behaviors to specify the
behavior of malicious software, instead of relying on system calls.
The KOBGs of a group of malware instances in the same family are
combined into a Weighted Common Behavioral Graph (WCBG).
This includes a special subgraph, the HotPath, that occurs in all in-
stances of the family. The proposed method achieves high detection
rates with very low false positive rates.
This work has the limitation shared by other methods using dy-
501
 0 0.2 0.4 0.6 0.8 1 0 10 20 30 40 50Detection RateSystem Call Injection Rate (%)AgentAgobotMydoomnamic analysis, namely that they observe only partial behavior of
an executable. The use of various techniques to explore most or all
possible execution paths [4, 21] would improve the accuracy of this
method, at the expense of greater overhead.
6. REFERENCES
[1] M. Bailey, J. Oberheide, J. Andersen, Z. M. Mao, and F. J.
andJose Nazario. Automated classiﬁcation and analysis of
internet malware. In Proceedings of 10th International
Symposium in Recent Advances in Intrusion
Detection(RAID), volume 4637 of Lecture Notes in
Computer Science, pages 178–197, Gold Goast, Australia,
September 2007. Springer.
[2] U. Bayer, P. Milani Comparetti, C. Hlauscheck, C. Kruegel,
and E. Kirda. Scalable, Behavior-Based Malware Clustering.
In 16th Symposium on Network and Distributed System
Security (NDSS), 2009.
[3] H. Bunke, P. Foggia, C. Guidobaldi, and M. Vento. Graph
clustering using the weighted minimum common
supergraph. In Graph Based Representations in Pattern
Recognition, volume 2726 of Lecture Notes in Computer
Science, pages 235–246. Springer, 2003.
[4] C. Cadar, V. Ganesh, P. M. Pawlowski, D. L. Dill, and D. R.
Engler. Exe: automatically generating inputs of death. In
Proceedings of the 13th ACM conference on Computer and
communications security(CCS), pages 322–335, New York,
NY, USA, 2006. ACM.
[5] M. Christodorescu and S. Jha. Testing malware detectors. In
Proceedings of the 2004 ACM SIGSOFT International
Symposium on Software Testing and Analysis (ISSTA 2004),
pages 34–44, Boston, MA, USA, July 2004. ACM Press.
[6] M. Christodorescu, S. Jha, and C. Kruegel. Mining
speciﬁcations of malicious behavior. In Proceedings of ACM
SIGSOFT symposium on The foundations of software
engineering (FSE), pages 5–14, New York, NY, USA, 2007.
ACM.
[7] M. Christodorescu, S. Jha, S. A. Seshia, D. X. Song, and
R. E. Bryant. Semantics-aware malware detection. In IN
IEEE SYMPOSIUM ON SECURITY AND PRIVACY, pages
32–46, 2005.
[8] D. Conte, P. Foggia, and M. Vento. Challenging complexity
of maximum common subgraph detection algorithms: A
performance analysis of three algorithms on a wide database
of graphs. Journal of Graph Algorithms Applications,
11(1):99–143, 2007.
[9] D. J. Cook and L. B. Holder. Mining Graph Data. John
Wiley & Sons, 2006.
[10] S. Corp. Symantec global internet security threat report,
April 2008. http://www.symantec.com/.
[11] A. Dinaburg, P. Royal, M. I. Sharif, and W. Lee. Ether:
malware analysis via hardware virtualization extensions. In
ACM Conference on Computer and Communications
Security, pages 51–62, 2008.
[12] M. Fredrikson, S. Jha, M. Christodorescu, R. Sailer, and
X. Yan. Synthesizing near-optimal malware speciﬁcations
from suspicious behaviors. In Proceedings of 31st IEEE
Symposium on Security and Privacy (S&P), May 2010.
[13] X. Hu, T.-c. Chiueh, and K. G. Shin. Large-scale malware
indexing using function-call graphs. In Proceedings of the
16th ACM conference on Computer and communications
security(CCS’09), pages 611–620, Chicago, Illinois, USA,
2009. ACM.
502
[14] J. Kinder, S. Katzenbeisser, C. Schallhart, H. Veith, and T. U.
München. Detecting malicious code by model checking. In
Proceedings of International Conference on Intrusion and
Malware Detection and Vulnerability Assessment (DIMVA),
pages 174–187. Springer Berlin, 2005.
[15] E. KIRDA, C. KRUEGEL, G. BANKS, G. VIGNA, and
R. Kemmerer. Behavior-based spyware detection. In
Proceedings of the 15th Usenix Security Symposium, 2006.
[16] C. Kolbitsch, T. Holz, C. Kruegel, and E. Kirda. Inspector
gadget: Automated extraction of proprietary gadgets from
malware binaries. In Proceedings of the 31st IEEE
Symposium on Security & Privacy (Oakland’10), May 2010.
[17] C. Kolbitsch, P. Milani Comparetti, C. Kruegel, E. Kirda,
X. Zhou, and X. Wang. Effective and Efﬁcient Malware
Detection at the End Host. In 18th Usenix Security
Symposium, Montreal, Canada, August 2009.
[18] C. Kruegel, W. Robertson, and G. Vigna. Detecting
kernel-level rootkits through binary analysis. In Proceedings
of the 20th Annual Computer Security Applications
Conference (ACSAC), pages 91–100, Washington, DC, USA,
2004. IEEE Computer Society.
[19] C. Krugel, E. Kirda, D. Mutz, W. K. Robertson, and
G. Vigna. Polymorphic worm detection using structural
information of executables. In RAID, pages 207–226, 2005.
[20] M. Library. Kernel object. http://msdn.microsoft.com/en-
us/library/ms724485(VS.85).aspx.
[21] A. Moser, C. Kruegel, and E. Kirda. Exploring multiple
execution paths for malware analysis. In Proceedings of the
2007 IEEE Symposium on Security and Privacy (S&P),
pages 231–245, Washington, DC, USA, 2007. IEEE
Computer Society.
[22] A. Moser, C. Kruegel, and E. Kirda. Limits of static analysis
for malware detection. Computer Security Applications
Conference, Annual, 0:421–430, 2007.
[23] Y. Park, Q. Zhang, D. Reeves, and V. Mulukutla. Antibot:
Clustering common semantic patterns for bot detection. In
Proceedings of 34th Annual IEEE International Computer
Software and Applications Conference(COMPSAC), July
2010.
[24] D. Perry. Here comes the ﬂood or end of the pattern ﬁle. In
Virus Bulletin, Ottawa, 2008.
[25] D. Wagner and R. Dean. Intrusion Detection via Static
Analysis. In Proceedings 2001 IEEE Symposium on Security
and Privacy(S&P), pages 156–168, Oakland, CA, USA, May
2001.
[26] C. Willems, T. Holz, and F. Freiling. Toward automated
dynamic malware analysis using cwsandbox. IEEE Security
and Privacy, 5(2):32–39, 2007.
[27] B. Xin and X. Zhang. Memory slicing. In Proceedings of the
eighteenth international symposium on Software testing and
analysis (ISSTA ’09), pages 165–176, 2009.
[28] H. Yin, D. Song, M. Egele, C. Kruegel, and E. Kirda.
Panorama: capturing system-wide information ﬂow for
malware detection and analysis. In Proceedings of the 14th
ACM conference on Computer and communications
security(CCS), pages 116–127, New York, NY, USA, 2007.
ACM.
[29] Q. Zhang and D. S. Reeves. Metaaware: Identifying
metamorphic malware. In 23rd Annual Computer Security
Applications Conference (ACSAC), pages 411–420, 2007.