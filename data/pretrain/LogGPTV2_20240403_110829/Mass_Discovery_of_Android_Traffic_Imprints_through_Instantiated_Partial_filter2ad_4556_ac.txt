the inputs can be dropped by the coarse slicing, we consider that
the whole output R is invariable and each input of the function
contributes to R.
To identify the invariable part in R, we randomly assign two sets
of values to I0, · · · , Ik and one set of values to the rest of inputs
Ik +1, · · · , In, according to their individual types. 4. By executing
the function (see Section 3.3) twice (each corresponding to a set of
values for I1, · · · , Ik), two return values, R1 and R2, are produced,
which are all strings, given that the output of the function we
consider is either a string or the type that can be serialized to a
string. (cid:140)e common substrings of R1 and R2 (denoted by R1 ∩ R2),
is then considered to be the invariable part of the function output.
(cid:140)en for the rest of the inputs Ii ∈ {Ik +1, ..., In}, Tiger tests every
variable’s contribution to the invariant by changing the value of Ii
while keeping the content of other variables intact, before running
the function with the new inputs to get a new return string R3. If
R1 ∩ R2 = R2 ∩ R3 (that is, R3 also contains the invariant of R1 ∩ R2),
we decide that Ii does not a(cid:130)ect the invariable part of the function’s
output and Ii is therefore irrelevant to the tra(cid:129)c token.
Figure 4 explains how the technique works through a real-world
example (a popular Chinese app com.tjsinfo.mangguoVideo). In
function a(), v4 is related to a tra(cid:129)c sink, three inputs (v1, v2 and
4Note that here we only consider the primitive types (int, (cid:131)oat, boolean, char) and
serializable objects (e.g., string, time). (cid:140)e value of a primitive variable is randomly
chosen in its data range. For a serializable variable, we randomly choose a value for
each of its (cid:128)eld.
v3, all are strings) of convertToHex() may have contribution to the
invariable portion of v4. To establish the connection, a static analy-
sis of convertToHex() seems necessary. However, the connection
between the inputs and the potential invariant within the return
variable v10 (at Line 10) can be hard to analyze, due to the complex-
ity of the function. (cid:140)erefore, here we resort to the coarse slicing
and di(cid:130)erential analysis. More speci(cid:128)cally, through the coarse slic-
ing, we know that v2 has no relation to any source of invariant,
while both v1 and v3 may come from constants. So we randomly
choose two values for v2 (abcd and e f ❕h) when se(cid:138)ing v1 to a (cid:128)xed
value abcd and v3 to abcd, running the function, recording its re-
turn values v101 (abcd794f d8d f 6686e85e0d8345670d2cd4ae) and
v102 (abcd03ac593f a7146ea182eeb2eb44d4dc f a) and identifying
their common part abcd. (cid:140)en we randomly choose another value
e f ❕h for v3 and observe that the return value v103 (abcd36e2d7c526
f d876eb14cd0b3ea2a3d43) has the same common part as the in-
tersection between v102 and v103, which indicates that v3 has no
relation with the intersection. However, once we change v1 and ex-
ecute the function again, the common part of the variables changes
as well. (cid:140)is demonstrates that the impact of v1 on the invariant
portion of the function’s output cannot be ignored. So Tiger has
to continue slicing the program with regard to that variable v1.
In this way, our approach avoids working on the variables clearly
unrelated to the invariant target, thereby signi(cid:128)cantly reducing the
analysis time (see Section 4.3).
3.3 Optimization and Imprint Generation
(cid:140)rough the coarse slicing and di(cid:130)erential analysis, Tiger can al-
ready signi(cid:128)cantly reduce the size of the slice for a network sink.
Here we show that the slicing process can be further simpli(cid:128)ed by
reusing the (cid:128)ndings about the methods analyzed before. (cid:140)e slice
generated in this way is further executed to discover tra(cid:129)c tokens
and constructing app imprints, which also is elaborated below.
Cross-slice optimization. When running the IPE engine over an
app, we can expect that a number of functions will be invoked
again and again. (cid:140)is presents an opportunity for further optimiz-
ing the slicing process and simplifying the slice produced. More
speci(cid:128)cally, Tiger was designed to avoid repeated analysis of the
same code and leverage existing PDT whenever possible. When
slicing with regard to a network sink, the IPE creates a pro(cid:128)le for
each function it evaluated, which records whether the function
contains invariant sources and which inputs a(cid:130)ect the invariant on
the function’s output. (cid:140)ese pro(cid:128)les are used when the IPE moves
onto other network sinks within the same app: for all functions
already pro(cid:128)led, their input and output variables are either imme-
diately added onto the sink’s PDT (when the variables are relevant)
or instantiated (when they are not). (cid:140)is treatment further reduces
the workload of the slicing operation.
Partial execution. Once a slice is generated, it needs to be exe-
cuted to produce tra(cid:129)c tokens for imprint generation. (cid:140)e slice is
in the form of a tree, which is rooted at its network sink statement.
To run the slice, the IPE engine extracts its individual paths, from
each leaf to the root, and then loads them to a modi(cid:128)ed Dalvik
virtual machine (VM) for execution. Also, during the di(cid:130)erential
analysis, we need to run a method over di(cid:130)erent input values to
identify those irrelevant to the output invariants. (cid:140)is step also
relies on the modi(cid:128)ed VM.
1.publicvoida(Stringarg1) {2.       …3.       Stringv4=AdMogoUtil.convertToHex(v1,v2, v3);4.       … 5.   }6.   public static String convertToHex(String arg1, String arg2, String arg3 ) {7.       byte[] v12 = md5(arg2+arg3);8.while(len98% of identi(cid:128)able packets from real-world app tra(cid:129)c, 43.98%
more packets and 16.34% more apps than the prior approach [39].
(cid:140)e false detection rate is only 0.742%. In the meantime, our IPE
technique turns out to be highly e(cid:129)cient: running against the stan-
dard techniques for slice generation and evaluation, our approach
performs at least one order of magnitude faster.
4.1 Setting
Here we describe the apps collected in our study and the hardware
and so(cid:137)ware se(cid:138)ings for the experiments.
App collection. We crawled real-world apps from various sources
last year, and got 203,864 apps a(cid:137)er removing duplicated ones
according to their MD5 checksums: 44,383 apps from Google Play
and third-party Android markets covering every category provided
by these markets (e.g. social, business, etc.); and 159,481 most recent
PHAs (till June, 2016) collected from VirusTotal [4]. Everyday,
nearly 800 thousands distinct samples are uploaded to VirusTotal
for scanning, supporting the most up-to-date PHA samples covering
wide range of malicious behaviors for studies [5]. (cid:140)e detailed
information about these apps is presented in Table 1.
Platform. All the experiments were conducted on two servers run-
ning Ubuntu. One has 40 cores with 2.0GHz CPU, 256GB memory
and 70TB hard drivers and the other has 20 cores with 2.1GHz CPU,
128GB memory and 30TB hard drivers.
4.2 E(cid:130)ectiveness
(cid:140)e most important for understanding the e(cid:129)cacy of our technique
is the coverage it can achieve, in terms of the number of apps
recognized from their tra(cid:129)c and the portion of the tra(cid:129)c a(cid:138)ributed
to their apps. Here we report our experimental study that evaluated
these key properties of our technique. Also, we analyze the impact
of dead code, which could lead to the imprints not showing up in
any app’s tra(cid:129)c.
App coverage. To measure the coverage, we installed Android
apps on emulators (Android 4.4) and triggered their network be-
haviors to see how many of them can be captured by Tiger. In
theory, it is very di(cid:129)cult, even impossible, to trigger all network
Session D2:  Vulnerable Mobile AppsCCS’17, October 30-November 3, 2017, Dallas, TX, USA821Table 2: App & Tra(cid:129)c Coverage.
App
Identi(cid:128)ed
Packet
Coverage
All
Benign
PHAs
All
Benign
PHAs
Package Name
& Ad-ID
59.72%
(2986/5000)
80.20%
(2005/2500)
39.24%
(981/2500)
28.87%
40.08%
17.66%
Package Name
Ad-ID & Host
69.82%
(3491/5000)
83.88%
(2097/2500)
55.76%
(1394/2500)
62.71%
82.19%
43.23%
Tiger
76.06%
(3803/5000)
85.80%
(2145/2500)
66.32%
(1658/2500)
72.85%
91.16%
54.54%
behaviors of an app. In order to cover as many network behaviors
as possible, the tra(cid:129)c for testing was produced by a human-guided
UI probing which is based on a state-of-the-art automatic UI explo-
ration tool from NetworkPro(cid:128)ler [14] to execute Android apps for
5 minutes, as suggested by NetworkPro(cid:128)ler. (cid:140)e tool try to cover
most of the network behaviors of apps: it (cid:128)rst randomly operates
on UIs of an app, records the paths it has gone through and then
heuristically generates new paths to guide more UI explorations.
And we manually moved the tool out of the UI state once it gets
stuck in. Considering it is impossible to install and dynamically
run all the collected apps, we randomly selected 2,500 apps from
the legitimate markets and 2,500 PHAs from VirusTotal for test. All
the tra(cid:129)c generated during the process was recorded and scanned
using these apps’ imprints from Tiger.
As we can see from the Table 2, Tiger produced the imprints that
successfully identi(cid:128)ed 76.06% (3,803/5,000) of the apps. By com-
parison, the tra(cid:129)c signatures proposed by the prior approach [39],
including package names and Ad-IDs, captured 59.72% (2,986/5,000)
apps, which is 16.34% less than those captured by Tiger. From the
16.34% coverage increase, we found 10.10% (= 69.82% − 59.72%)