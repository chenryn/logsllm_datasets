Hello, first of all I want to say you making crazy useful things, guys, thank
you!
I have two elasticsearch twin (versions, configuration, everything) servers
with the same data, replicated by logstash: ES1 and ES2. ES1 I restarted for a
few hours ago and now I have a problems.
My mapping for logstash type, same for both servers.
    "nginx_accesslog": {
            "dynamic_templates": [
                    {
                            "string_template": {
                                    "mapping": { "index": "not_analyzed", "type": "string" },
                                    "match": "*",
                                    "match_mapping_type": "string"
                            }
                    }
            ],
            "_all": { "enabled": false },
            "_source": { "compress": true },
            "properties": { 
                    "@timestamp": { "type": "date", "format": "dateOptionalTime" },
                    "@version": { "type": "long" },
                    "api_key": { "type": "string", "index": "not_analyzed" },
                    "body_bytes_sent": { "type": "long" },
                    "host": { "type": "string", "index": "not_analyzed" },
                    "http_host": { "type": "string", "index": "not_analyzed" },
                    "http_method": { "type": "string", "index": "not_analyzed" },
                    "http_referer": { "type": "string", "index": "not_analyzed" },
                    "http_user_agent": { "type": "string", "index": "not_analyzed" },
                    "http_version": { "type": "string", "index": "not_analyzed" },
                    "http_x_forwarded_for": { "type": "string", "index": "not_analyzed" },
                    "message": { "type": "string", "index": "not_analyzed" },
                    "path": { "type": "string", "index": "not_analyzed" },
                    "remote_addr": { "type": "string", "index": "not_analyzed" },
                    "remote_user": { "type": "string", "index": "not_analyzed" },
                    "request": { "type": "string", "index": "not_analyzed" },
                    "request_time": { "type": "double" },
                    "status": { "type": "long" },
                    "tags": { "type": "string", "index": "not_analyzed" },
                    "type": { "type": "string", "index": "not_analyzed" }
            }
    }
Query (I'm using Sense add-on)
    POST /logstash-2014.04.07/_search
    {
        "script_fields": {
           "s_request_time": {
              "script": "doc['request_time'].value"
           }
        },
        "size": 20
    }
ES2, everything is normal:
    {
       "took": 63,
       "timed_out": false,
       "_shards": {
          "total": 4,
          "successful": 4,
          "failed": 0
       },
       "hits": {
          "total": 17041240,
          "max_score": 1,
          "hits": [
             {
                "_index": "logstash-2014.04.07",
                "_type": "nginx_accesslog",
                "_id": "LSfAaBwSSDS5rL6utSHQJA",
                "_score": 1,
                "fields": {
                   "s_request_time": 0.014
                }
             },
    ...
ES1: Ooops!
    {
       "took": 51,
       "timed_out": false,
       "_shards": {
          "total": 4,
          "successful": 4,
          "failed": 0
       },
       "hits": {
          "total": 17041131,
          "max_score": 1,
          "hits": [
             {
                "_index": "logstash-2014.04.07",
                "_type": "nginx_accesslog",
                "_id": "tjZo1_JmRpOu5kE2WRfURw",
                "_score": 1,
                "fields": {
                   "s_request_time": [
                      " \u0001?PZ\u000e+\u0001\u0003\t\u001c" <-- WAT?!
                   ]
                }
             },
It's most obvious demonstration of my problem. Another thing is when I'm using
data_histogram facet (in kibana) I got
ClassCastException[org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData
cannot be cast to org.elasticsearch.index.fielddata.IndexNumericFieldData.
Purging all indexes fixes problem. Not only new, but old data too
misenterpreted as arrays of one string.  
Well, I want my doubles back. :)