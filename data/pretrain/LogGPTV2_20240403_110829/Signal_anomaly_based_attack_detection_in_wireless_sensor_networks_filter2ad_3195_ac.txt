1
1.5
0
Attribute 1
0
0.5
1
1.5
Attribute 1
(b) X ∼ N (1, 0.04) Y ∼ N (0, 0.04)
(c) X ∼ N (0, 0.04) Y ∼ N (0, 0.16)
Fig. 2. The effect of a non-stationary distribution on the class boundary. Changing the data distribution will result in changes to the boundary location and
shape.
(cid:129) Change in the distribution of the normal class which
affects the class boundary of the normal data – an
alteration in P (N|x)
(cid:129) Change in the ratio of anomalies to normal data – an
alteration to the prior P (A) (and consequently P (N ))
1) Effect on the Normal Class Boundary: In a WSN the
data set is formed of sensor measurements of a phenomenon.
Changes in the phenomenon will cause changes in the data
distribution which will result in a shift in the boundary of the
normal class.
Deﬁning this mathematically, the training and testing set
will consist of a time-ordered sequence of data vectors
X = {xi
: i = 1, 2, 3, ..., n} each of which is p variate
data vector xi = (xi1, xi2, xi3, ..., xip), i = 1, ..., n. The
probability that a data vector belongs to the normal class is
stated as P (N|x) = P (x|N )P (N )/P (x). If the distribution
is non-stationary, there will be an alteration in the posterior
distribution of the normal class Pt+1(N|x) (cid:2)= Pt(N|x).
Fig. 2 shows the effect of a changing data distribution on
the class boundary. If we consider the initial data distribution
to be that of Fig. 2(a), the class boundary of the normal
data is centred at the origin. In Fig. 2(b) we observe that
the mean of the distribution for attribute 1 has shifted from 0
to 1 performing a transformation of the class boundary along
the x-axis. Another example of a change that can occur is
in Fig. 2(c) where there has been a change in the standard
deviation of the distribution of attribute 2 causing a vertical
expansion of the class boundary.
An alteration in the class boundary of the normal data can
cause problems for anomaly detection algorithms. A model
built using a training set generated from a previous distribution
may no longer be optimal for the current distribution causing
it to misclassify normal data as anomalies and vice versa.
2) Effect on the Anomaly Rate: If the data distribution is
non-stationary, the rate that anomalies occur in the data set
can be affected. Some algorithms use the anomaly rate as a
threshold in order to determine the class boundary for the
normal data.
The class prior probabilities are deﬁned as P (ω). In the
application domain of anomaly detection, there is only one
class, this is the class of normal data. Therefore the class prior
P (N ) also determines the anomaly rate as P (A) = 1−P (N ).
A change in P (N ) will cause a change in the anomaly rate
P (A). This is an important consideration in anomaly detection
as certain algorithms make an assumption that the anomaly
rate is known and is speciﬁed as a parameter during model
construction. If the anomaly rate varies, anomalies can be
misclassiﬁed as normal data and vice versa.
3) Effect on the Anomaly Class Boundary:
In anomaly
detection, the class boundary of the anomalous data is not
usually taken into consideration. The one-class classiﬁcation
approach assumes that anomalies are under sampled and it
is not possible to extract information about the anomaly data
distribution from the available anomalous data instances [45].
Therefore, no attempt is made to model the anomaly class.
Due to this, changes in the class boundary of the anomalies,
P (A|x), will not affect classiﬁcation performance.
D. Examples of Non-stationary Data in Real-World Data Sets
We have shown that if data are non-stationary in nature, a
change in the data distribution will occur. In this section we
provide details of several real-world data sets that are non-
stationary.
One example of such a data set is the Grand-St-Bernard
(GSB) data set. The data was gathered from a set of 23 sensors
deployed in the Grand-St-Bernard pass between Switzerland
and Italy in 2007 [46]. Two sensor measurements, wind data
in the form of speed in ms−1 and the angle of the wind
direction in degrees, are shown to exhibit a non-stationary
data distribution. There is an abrupt change, a concept shift,
over the measured period causing a change in the normal data
class boundary. An examination of the wind measurements
for node 4, Fig. 3(a), shows that the data distribution over
the ﬁrst 34 days is stationary and occupies two well-deﬁned
areas. However, from day 35 there is a sustained increase in
the wind speed occurring in the same direction as previously.
Examining the two sensor data streams separately, Fig. 3(b)
and 3(c), the wind speed is in the range 1 and 2 ms−1
for the ﬁrst 120,000 samples, which is until day 34. From
sample 120,000, there is an increase in the wind speed over
the remaining 4000 samples, with the wind speed increasing
to a maximum of 10 ms−1. The wind direction follows a
similar pattern over the entire period. Other nodes from the
deployment in GSB show similar characteristics for wind data.
Another data set that shows non-stationarity is the Intel
Berkeley Research Laboratory (IBRL) data set. This is used
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.O’REILLY et al.: ANOMALY DETECTION IN WIRELESS SENSOR NETWORKS IN A NON-STATIONARY ENVIRONMENT
7
)
s
e
e
r
g
e
d
(
n
o
i
t
c
e
r
i
D
d
n
W
i
350
300
250
200
150
100
50
Days 1 − 34
Days 35 − 41
0
0
2
4
8
Wind Speed (ms−1)
6
(a) GSB Data Set
45
40
35
30
25
20
15
10
5
0
y
a
D
10
)
1
−
s
m
(
d
e
e
p
S
d
n
W
i
10
8
6
4
2
0
2000
4000
Day 35
10000 12000 14000 16000
6000
8000
Samples
(b) Wind Speed
)
s
e
e
r
g
e
d
(
n
o
i
t
c
e
r
i
D
d
n
W
i
350
300
250
200
150
100
50
0
2000
4000
10000 12000 14000 16000
6000
8000
Samples
(c) Wind Direction
Fig. 3. A real-world non-stationary data set. Wind speed and wind direction data from node 4 of the GSB data set.
by Zhang et al. [47] with an adaptive anomaly detector where
updates to the model are required in order to account for
changes in the data distribution. The IBRL data set is also
used by Moshtaghi et al. [48] in the study of updates to an
iterative elliptical boundary tracking algorithm.
Non-stationary data sets taken from sensor data include a
signalled road intersection [49] where sensors provided data
on trafﬁc volume and which are used to predict the volume of
trafﬁc in the next hour. In addition, sensor measurements from
weather data have been used to study incremental learning
in non-stationary environments. Elwell et al. [39] studied in-
cremental learning in a non-stationary environment on sensor
data from a weather station at the Offutt Air Base in Bellevue,
Nebraska [50].
IV. ANALYZING ANOMALY DETECTION TECHNIQUES
DESIGNED FOR NON-STATIONARY ENVIRONMENTS
In this section a taxonomy is presented in order to classify
anomaly detection techniques that are surveyed in Sections V,
VI and VII. In addition, a work ﬂow is presented that details
how the different components operate together in order to
provide anomaly detection in a non-stationary environment.
Finally,
the issue of performance evaluation is addressed.
Methods of measuring the performance and complexity of an
anomaly detector are detailed.
A. Taxonomy for Anomaly Detection in a Non-Stationary
Environment
Previous work on taxonomies for anomaly detection tech-
niques have focused on the statistical or machine learning
technique that is used to identify anomalies in data sets. Chan-
dola et al. [10] categorize the methods into the main machine
learning categories such as classiﬁcation-based and nearest
neighbour-based approaches. This taxonomy is continued in
the work of Rajasegarar et al. [12], [13], Zhang et al. [14]
and Xie et al. [15] whose surveys focus on anomaly detection
in WSNs.
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.8
IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATION
Anomaly Detection Techniques in 
a Non-Stationary Environment
Change Detection
Model Update
Constant 
Update
Detect and 
Retrain
Model Selection
Model Construction
Fixed 
Parameters
Optimized 
Parameters
Batch
Incremental
Fixed Sliding 
Window
Weighted 
Sliding Window
Fig. 4. Taxonomy of anomaly detection techniques in a non-stationary environment.
As illustrated in Fig. 4, the taxonomy categorizes methods
that anomaly detection techniques can use in order to adapt to
a non-stationary distribution. There are two steps that need
is change detection where the
to be performed; the ﬁrst
aim is to identify changes in the data distribution in order
to determine when a model update is required. The change
detection techniques can be categorized as either constant
update or detect and retrain [51].
The second step is model update, where the model is recon-
structed in order to adapt to changes in the data distribution.
Two techniques are part of this process, model selection and
model construction. Model selection is the process by which
a model is chosen for a speciﬁc training set that is by some
measure optimal. The techniques can be classiﬁed as ﬁxed
parameters and optimized parameters. Model construction
describes how a model is constructed using a training set
that differs from the previous model. This can be further
divided into two categories batch and incremental. Batch is
categorized as either ﬁxed sliding window or weighted sliding
window.
State-of-the-art approaches to anomaly detection will im-
plement change detection, model update – model selection
and model update – model construction. Our survey is struc-
tured in this manner. Techniques within these categories are
mutually exclusive, however, the categories themselves are
not. We select anomaly detection methods that highlight how
a particular technique is being performed, and note it may
perform other techniques in other categories. Table I in Section
VIII summarizes the algorithms and the techniques that they
implement.
B. Workﬂow for Anomaly Detection in a Non-Stationary En-
vironment
The constituent modules that form a system that is able to
perform anomaly detection in a non-stationary environment
are now studied. Fig. 5 provides a visual representation of the
process.
1) Change Detection: Sensors will measure a phenomenon
that
is generating data with a non-stationary distribution.
Multiple sensors on a node will form Xt, an n dimensional
data vector at time t, where n is the number of sensors on a
node.
If constant update is performed, no monitoring is performed
on the data distribution. A model update will be scheduled at
regular intervals.
If detect and retrain is performed, the data will be monitored
in order to determine whether there has been a change in
the data distribution. When the change detection algorithm
determines that a signiﬁcant change has occurred in the data
distribution, an update to the model will occur.
2) Training Set Formation: The training set for the model
is formed from the data vectors {X1, X2, X3, ...}. If a sliding
window is used, it will frame the data vectors that are to be
used for model construction. For the next model, the sliding
window will shift n data vectors allowing the n oldest data
vectors to be removed from the window, while n new data
vectors will be added to the window.
3) Model Selection: Next the parameters are determined for
the training set. If the parameters are ﬁxed they will have been
determined previously at deployment and only one model can
be constructed for the current training set. If the parameters
are to be optimized, the algorithm will determine the optimal