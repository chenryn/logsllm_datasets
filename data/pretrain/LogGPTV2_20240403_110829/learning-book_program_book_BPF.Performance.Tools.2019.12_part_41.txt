### statsnoop(8)

`statsnoop(8)` is a BCC and bpftrace tool similar to `opensnoop(8)`, but it specifically targets the `stat(2)` family of system calls. The `stat(2)` call returns file statistics, and `statsnoop(8)` is useful for discovering file locations, identifying performance issues, and troubleshooting missing files.

#### Example Output
When using `statsnoop -t` (with timestamps), the output might look like this:

```
TIME (s)  PID   COMM         FD  ERR  PATH
238452415 9118  statsnoop    -1  0    /usr/lib/python2.7/encodings/ascii.py
238470518 744   systemd-resolve 0   0    /etc/resolv.conf
238497017 744   systemd-resolve 0   0    /run/systemd/resolve/resolv.conf
238506760 744   systemd-resolve 0   0    /run/systemd/resolve/stub-resolv.conf
238514099 744   systemd-resolve 0   0    /etc/resolv.conf
238645046 744   systemd-resolve 0   0    /run/systemd/resolve/resolv.conf
238659277 744   systemd-resolve 0   0    /etc/resolv.conf
238667182 744   systemd-resolve 0   0    /run/systemd/resolve/stub-resolv.conf
```

This output shows `systemd-resolve` (truncated from `systemd-resolved`) calling `stat(2)` on the same three files in a loop.

#### Use Cases
- **File Location Discovery**: Helps in finding where files are located.
- **Performance Issues**: Identifies high-frequency `stat(2)` calls that may cause performance degradation.
- **Troubleshooting Missing Files**: Helps in diagnosing issues related to missing or inaccessible files.

In production environments, I have observed `stat(2)` being called tens of thousands of times per second without a good reason. Fortunately, `stat(2)` is a fast system call, so these high-frequency calls do not usually cause major performance issues. However, there was one instance where a Netflix microservice hit 100% disk utilization due to a disk usage monitoring agent continually calling `stat(2)` on a large file system. The metadata did not fully cache, leading to significant disk I/O.

#### Traced Variants
`statsnoop(8)` traces the following `stat(2)` variants via tracepoints:
- `statfs(2)`
- `statx(2)`
- `newstat(2)`
- `newlstat(2)`

The overhead of this tool is expected to be negligible unless the `stat(2)` rate is very high.

### Command Line Usage

**BCC:**
```sh
statsnoop [options]
```
**Options:**
- `-x`: Show only failed `stat(2)` calls.
- `-t`: Include a column of timestamps (in seconds).
- `-p <PID>`: Measure this process only.

**bpftrace:**
The following is the code for the bpftrace version, which summarizes its core functionality. This version does not support options.

```bash
#!/usr/local/bin/bpftrace
BEGIN
{
    printf("Tracing stat syscalls... Hit Ctrl-C to end.\n");
    printf("%-6s %-16s %-3s %s\n", "PID", "COMM", "ERR", "PATH");
}

tracepoint:syscalls:sys_enter_statfs,
tracepoint:syscalls:sys_enter_statx,
tracepoint:syscalls:sys_enter_newstat,
tracepoint:syscalls:sys_enter_newlstat
{
    @filename[tid] = args->pathname;
}

tracepoint:syscalls:sys_exit_statfs,
tracepoint:syscalls:sys_exit_statx,
tracepoint:syscalls:sys_exit_newstat,
tracepoint:syscalls:sys_exit_newlstat
/@filename[tid]/
{
    $ret = args->ret;
    $errno = $ret >= 0 ? 0 : -($ret);
    printf("%-6d %-16s %-3d %s\n", pid, comm, $errno, str(@filename[tid]));
    delete(@filename[tid]);
}

END
{
    clear(@filename);
}
```

### syncsnoop(8)

`syncsnoop(8)` is a BCC and bpftrace tool that shows `sync(2)` calls with timestamps. The `sync(2)` system call flushes dirty data to disk. Here is some example output from the bpftrace version:

```
Attaching 7 probes...
Tracing sync syscalls... Hit Ctrl-C to end.
TIME     PID   COMM          EVENT
08:48:31 14172 TaskSchedulerFo tracepoint:syscalls:sys_enter_fdatasync
08:48:31 14172 TaskSchedulerFo tracepoint:syscalls:sys_enter_fdatasync
08:48:31 14172 TaskSchedulerFo tracepoint:syscalls:sys_enter_fdatasync
08:48:31 14172 TaskSchedulerFo tracepoint:syscalls:sys_enter_fdatasync
08:48:31 14172 TaskSchedulerFo tracepoint:syscalls:sys_enter_fdatasync
```

This output shows `TaskSchedulerFo` (a truncated name) calling `fdatasync(2)` five times in a row. `sync(2)` calls can trigger bursts of disk I/O, which can affect system performance. Timestamps are printed to correlate with performance issues seen in monitoring software, indicating that `sync(2)` and the resulting disk I/O are responsible.

#### Traced Variants
`syncsnoop(8)` traces the following `sync(2)` variants via tracepoints:
- `sync(2)`
- `syncfs(2)`
- `fsync(2)`
- `fdatasync(2)`
- `sync_file_range(2)`
- `msync(2)`

The overhead of this tool is expected to be negligible as the rate of `sync(2)` calls is typically very infrequent.

### Command Line Usage

**BCC:**
The BCC version currently does not support options and works similarly to the bpftrace version.

**bpftrace:**
The following is the code for the bpftrace version:

```bash
#!/usr/local/bin/bpftrace
BEGIN
{
    printf("Tracing sync syscalls... Hit Ctrl-C to end.\n");
    printf("%-6s %-16s %s\n", "TIME", "PID", "COMM", "EVENT");
}

tracepoint:syscalls:sys_enter_sync,
tracepoint:syscalls:sys_enter_syncfs,
tracepoint:syscalls:sys_enter_fsync,
tracepoint:syscalls:sys_enter_fdatasync,
tracepoint:syscalls:sys_enter_sync_file_range,
tracepoint:syscalls:sys_enter_msync
{
    printf("%-8s %-6d %-16s %s\n", strftime("%H:%M:%S"), pid, comm, probe);
}
```

If `sync(2)`-related calls are found to be problematic, they can be further examined with custom bpftrace scripts to show the arguments, return values, and issued disk I/O.

### mmapfiles(8)

`mmapfiles(8)` is a BCC and bpftrace tool that traces `mmap(2)` and counts the frequency of files mapped to memory address ranges. For example:

```
/usr/bin/x86_64-linux-gnu-ar: 2
/usr/lib/x86_64-linux-gnu/libreadline.so.6.3: 2
/usr/bin/x86_64-linux-gnu-objcopy: 2
...
/usr/bin/make: 226
/usr/lib/x86_64-linux-gnu/libz.so.1.2.8: 296
/usr/lib/x86_64-linux-gnu/gconv/gconv-modules.cache: 365
/bin/bash: 670
/usr/lib/x86_64-linux-gnu/libtinfo.so.5.9: 672
/bin/cat: 1152
/usr/lib/x86_64-linux-gnu/libdl-2.23.so: 1240
/usr/lib/locale/locale-archive: 1424
/etc/ld.so.cache: 1449
/usr/lib/x86_64-linux-gnu/ld-2.23.so: 2879
/usr/lib/x86_64-linux-gnu/libc-2.23.so: 2879
[]: 8384
```

This example traces a software build, showing each file by its filename and two parent directories. The last entry has no names, representing anonymous mappings for program private data.

#### Source Code

```bash
#!/usr/local/bin/bpftrace
#include <linux/fs.h>
#include <linux/dcache.h>

kprobe:do_mmap
{
    $file = (struct file *)arg0;
    $name = $file->f_path.dentry;
    @[$name->d_name.name, $name->d_parent->d_name.name, $name->d_parent->d_parent->d_name.name] = count();
}
```

This tool uses kprobes to trace the kernel `do_mmap()` function and reads the filename from its `struct file *` argument, via a `struct dentry` (directory entry). The dentry only has one component of the path name, so the parent directory and grandparent directory are read and included in the output. Since `mmap(2)` calls are expected to be relatively infrequent, the overhead of this tool is expected to be negligible.

### File Descriptor to Filename

This tool also serves as an example of fetching the filename from a file descriptor (FD) integer. There are at least two ways to do this:

1. **Walk from the task_struct to the file descriptor table**: Use the FD as the index to find the `struct file`. The filename can then be found from this struct. This method is used by `sread(2)`, but it is unstable because the way the file descriptor table is found (task->files->fdt->fd) refers to kernel internals that may change between kernel versions, breaking the script.

2. **Trace the open(2) syscall(s)**: Build a lookup hash with the PID and FD as keys and the file/pathname as the value. This can then be queried during `read(2)` and other syscalls. While this adds additional probes and overhead, it is a stable technique.

There are many other tools in this book (e.g., `fmapfault(8)`, `filelife(8)`, `vfssize(8)`, etc.) that refer to the filename for different operations. These tools work by tracing via the VFS layer, which provides the `struct file` immediately. Although this is also an unstable interface, it makes it possible to find the filename string in fewer steps. Another advantage of VFS tracing is that there is usually only one function per type of operation, whereas with syscalls, there can be variants (e.g., `read(2)`, `readv(2)`, `preadv(2)`, `pread64()`, etc.) that may all need to be traced.

### fmapfault(8)

`fmapfault(8)` is a BCC and bpftrace tool that traces page faults for memory-mapped files and counts the process name and filename. For example:

```
[dirname, libc-2.23.so]: 1
[date, libc-2.23.so]: 1
...
[cat, libc-2.23.so]: 901
[sh, libtinfo.so.5.9]: 962
[sed, ld-2.23.so]: 984
[sh, libc-2.23.so]: 997
[cat, ld-2.23.so]: 1252
[sh, libc-2.23.so]: 1427
[as, libbfd-2.26.1-system.so]: 3984
[as, libopcodes-2.26.1-system.so]: 68455
```

This traced a software build, showing the build processes and libraries in which they were faulting.

Later tools in this book, such as `filetop(8)`, `fileslower(8)`, `xfsslower(8)`, and `ext4dist(8)`, show file I/O via the `read(2)` and `write(2)` syscalls (and their variants). However, these are not the only methods for reading and writing files; file mappings are another method that avoids explicit syscalls. `fmapfault(8)` provides a view of their use by tracing file page faults and the creation of new page maps. Note that the actual reads and writes to a file may be far higher than the fault rate.

#### Source Code

```bash
#!/usr/local/bin/bpftrace
#include <linux/mm.h>
#include <linux/fs.h>

kprobe:filemap_fault
{
    $vf = (struct vm_fault *)arg0;
    $file = $vf->vma->vm_file->f_path.dentry->d_name.name;
    @[$comm, str($file)] = count();
}
```

This tool works by using kprobes to trace the `filemap_fault()` kernel function and, from its `struct vm_fault` argument, determine the filename for the mapping. These details will need to be updated as the kernel changes. The overhead of this tool may be noticeable for systems with high fault rates.

### filelife(8)

`filelife(8)` is a BCC and bpftrace tool that shows the lifespan of short-lived files: those that were created and then deleted while tracing.

#### Example Output
During a software build, the output might look like this:

```
TIME     PID   COMM   AGE (s)  FILE
17:04:51 3576  gcc    0.02     kernel_release.tsp
17:04:51 3632  rm     0.00     cc97ENsb.5
17:04:51 3656  gcc    0.00     version.h.tmp
17:04:51 3678  rm     0.00     utsrelease.h.crp
17:04:51 3698  gcc    0.01     ccTtEADr-5
17:04:51 3701  rm     0.00     dsn°L69E*
17:04:51 3706  gcc    0.16     cc05cPSx.s
17:04:51 3708  rm     0.01     -purgatory.o.d
17:04:51 3711  gcc    0.01     ccqk4xE.3
17:04:51 3715  rm     0.01     -atack.o.d
17:04:51 3718  gcc    0.01     ccPIKOgD.s
17:04:51 3722  rm     0.01     -setup-x86_64.o.d
...
```

This output shows the many short-lived files created during the build process, which were removed at an age (`AGE(s)`) of less than one second.

#### Use Cases
- **Performance Wins**: This tool has been used to find small performance improvements by discovering cases where applications were using temporary files that could be avoided.

#### How It Works
`filelife(8)` uses kprobes to trace file creation and deletion via the VFS calls `vfs_create()` and `vfs_unlink()`. The overhead of this tool should be negligible as the rate of these calls is relatively low.

### Command Line Usage

**BCC:**
```sh
filelife [options]
```
**Options:**
- `-p <PID>`: Measure this process only.

**bpftrace:**
The bpftrace version of `filelife(8)` is provided for this book and is inspired by the `fslife.d` tool from the 2011 DTrace book.