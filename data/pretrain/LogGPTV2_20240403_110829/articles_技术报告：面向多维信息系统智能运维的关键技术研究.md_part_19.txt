> 1）N处于0到T2则为可容忍区间，结果正常。T2为向下容忍系数，应小于0.4
>
> 2）N处于T2+i\*0.2到T2+(i+1)\*0.2范围内结果异常，异常等级为i+1级。其中0.2为阶梯系数，可按需调整，每超出AI下界值AILower
> 0.2倍，异常等级上升一级。本系统告警最高等级为4级
4、 进程健康度饱和度指标（内存、线程、数据源）告警逻辑如下：
> (1).前提：AI告警后，实际值低于下界不告警；
>
> AI告警后，实际值高于上界，做如下处理：
>
> 1）AI告警后，阈值判断，超过70%阈值（五分钟内增长两次以上），三级告警；
>
> 2）AI告警后，阈值判断，未超出70%，按如下逻辑判断：
-   五分钟内增长超3次，发出二级告警；
-   五分钟内增长超5次，发出三级告警；
> (2)、进程健康度业务指标（业务量，平均耗时，错误数）告警逻辑如下：
![手机屏幕的截图
中度可信度描述已自动生成](media/image84.png){width="3.6506944444444445in"
height="1.5694444444444444in"}
> 在以上逻辑的基础上，我们结合实际情况，对业务量指标进行了微调，当业务量指标为溢出状态时候，不会触发告警，判定改状态为正常。
#### 业务量指标
##### 数据要求
-   数据采集要求
接入方需要提供以下指标（二选一）供采集：
1、进程级别业务量；
2、进程级别收到报文数；
-   数据特征要求
接入方需要提供指标周期特征（四选一）供训练参考：
1、指标按天进行周期波动；
2、指标按周进行周期波动；
3、指标按月进行周期波动；
4、指标无规律波动。
##### **算法**
-   算法描述
1.  KDE
> Kernel density
> estimation(KDE)：适用于业务具有不同阶段的周期指标，但是不同阶段内特征无规律或具有突变（比如固定时间的活动办理，固定时间的业务办理情况）
![](media/image69.png){width="4.949305555555555in"
height="1.6229166666666666in"}
2.  Data Cluster
Data
Cluster：适用于复杂的，受日期影响波动较大的数据，特别是工作日与周末，月初月末与月中，平时与特殊日期差异很大的数据。（如集群负载场景下的集群维度的业务量月初月尾特征，能够非常好的拟合）
-   算法优势
目前大部分算法对于本项目不同场景下的不同数据特征数据都有比较强的拟合度，如MA算法，在对于内存使用率，错误数，负载占比等抖动小，且长期稳定在某个值的数据，训练的模型能够有较好的检测效果，KDE算法，能够适应如单进程业务量数据，具有周期性，但是在月初月尾特征变化不明显，算法会充分考虑历史数据，训练出比较切合该数据规律的模型。Data
cluster算法，也是针对业务特征，对KDE算法的升级版本，能够对业务场景下，月初月尾的变化特征，对月初月尾进行聚类处理，从而在检测中考虑月初月尾的数据波动，减少误报。
-   模型训练
1)  迭代周期
模型可周期性自动进行迭代训练。在迭代训练时，上一次训练所用到的数据也会参与当次训练，但由于它们离当前时刻较远，会在训练中被赋予较低的权重。同时，由于模型的训练模式和测试灵敏度等配置会影响迭代训练的模型之间性能的比较，迭代训练时会使用前一模型同样的配置进行训练，并计算几个模型评价指标进行比较。由于异常点的识别受到灵敏度的影响，故前一模型识别出的异常点仍会参与下一轮迭代训练。训练方式如下：
1、指标尚无模型且满足最低要求10080点，会自动进行训练，训练的算法以及参数会识别训练数据进行选择。
2、指标周期性自动训练，会根据设置时间，把上一周期数据以及新周期的数据进行训练，算法以及参数会继承。
2)  遇到的问题
```{=html}
```
1.  需要提供标准数据或通过平台格式化
2.  不同特征的数据与算法的拟合需要一定周期的迭代甚至敏感度调整
##### **实现功能**
1、通过清洗模型，把采集的log4x
trace以及metric原始数据清洗成基础数据，其中基础数据涵盖众多特征，例如所属业务、中心、集群、进程、ip等等，实现数据采集功能。
2、利用SPL语法将基础数据进行二次加工，逻辑是以中心、集群、进程为维度进行业务的统计，时间粒度为1分钟，形成原始业务量指标数据，实现数据处理功能。
3、基础指标数据通过数据工厂，进行格式化处理，形成基础业务量指标数据，实现数据格式化功能。
4、基础指标累计数量达10080个会进行自动训练，当然训练的周期可根据累计实际数量重新训练，10080个指标是最低标准，实现指标手动&自动训练功能。
5、训练生成的模型会自动应用，针对后续形成的业务量指标进行实时检测，实现指标检测功能。
6、关于业务量指标，通过历史数据特征构建的模型，且适配指标特征，针对业务量指标下滑的阶段状态进行检测，忽略上升状态带来的影响，实现针对指标特性检测功能。
业务量指标具有周期性，使用固定阈值无法适合进程所有时间段的监控，通过KDE算法或者Data
Cluster算法，学习历史规律，结合实时数据，实现动态预警功能。
![C:\\Users\\Administrator\\Pictures\\能力清单\\业务量.png](media/image85.png){width="5.763888888888889in"
height="1.5256944444444445in"}
图 49 业务量指标
#### 错误数指标
##### 数据要求
-   数据采集要求
接入方需要提供以下指标供采集：
1.  进程级别的错误量（日志等级为error或有错误特征的事件）
-   数据特征要求
接入方需要提供指标周期特征（四选一）供训练参考：
1、指标按天进行周期波动；
2、指标按周进行周期波动；
3、指标按月进行周期波动；
4、指标无规律波动。
##### **算法**
-   算法描述
1.  KDE
> Kernel density
> estimation(KDE)：适用于业务具有不同阶段的周期指标，但是不同阶段内特征无规律或具有突变（比如固定时间的活动办理，固定时间的业务办理情况）
![](media/image69.png){width="4.949305555555555in"
height="1.6229166666666666in"}
2.  MA
> Moving
> Average：擅长处理与时间不相关的异常，正常数据在一定范围内波动，异常数据有较大波动的数据：（如进程健康度场景的错误数，内存使用率，线程占用率，集群负载场景的负载占比等指标）
![](media/image71.png){width="4.231944444444444in"
height="1.7534722222222223in"}
-   算法优势
目前大部分算法对于本项目不同场景下的不同数据特征数据都有比较强的拟合度，如MA算法，在对于内存使用率，错误数，负载占比等抖动小，且长期稳定在某个值的数据，训练的模型能够有较好的检测效果，KDE算法，能够适应如单进程业务量数据，具有周期性，但是在月初月尾特征变化不明显，算法会充分考虑历史数据，训练出比较切合该数据规律的模型。Data
cluster算法，也是针对业务特征，对KDE算法的升级版本，能够对业务场景下，月初月尾的变化特征，对月初月尾进行聚类处理，从而在检测中考虑月初月尾的数据波动，减少误报。
-   **模型训练**
1)  迭代周期