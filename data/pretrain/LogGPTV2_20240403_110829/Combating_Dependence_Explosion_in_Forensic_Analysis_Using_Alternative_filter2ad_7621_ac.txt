Escalate
DataLeak
Prepare binary code for execution
Execute file-based malware
Process injection
Prepare malware file for execution
Corrupt files
Privilege escalation
Confidential data leak
mmap(s, p), mprotect(s, p)
exec(s, o), load(s, o)
inject(s, s(cid:48))
chmod(s, o, p)
write(s, o), mv(s, o), rm(s, o)
s.itag < 0.5
o.itag < 0.5
s.itag < 0.5
o.itag < 0.5
s.itag < 0.5 ≤ o.itag
Other
conditions
incl exec(p)
s.stag is benign
s(cid:48).stag is benign
incl exec(p)
any(s)
write(s, o)
s.itag < 0.5
s.itag < 0.5
changed userid
s.ctag < 0.5 ≤ o.ctag, socket(o)
Table III: Provenance-based policies for attack detection. Here, socket(o) holds when o refers to a socket, while incl exec(p) holds if p includes the execute permission.
the process after exec must be considered, at a minimum, to be in a
suspect environment, and hence we take a min with susp env. For
data tag value, we apply the min operator as in the case of load.
Finally, we turn our attention to the inject operation, which
loosely corresponds to one subject modifying the code of another.
There may be no single system event that corresponds to inject, so
it may be necessary to piece together a set of related operations. For
instance, on Windows, an inject may correspond to a combination
of operations made by a process s to open the memory of another
process s(cid:48), write to it, and then create a remote thread. On Linux,
it may correspond to a combination of ptrace system call made by
s to attach to another process s(cid:48), followed by operations to modify
the memory of s(cid:48). Regardless of when an inject is recognized, its
behavior is similar to code loading. So, the rules for updating the
tag are similar to those for the load operation.
IV. Provenance-Based Attack Detection
Provenance-based attack detection using system audit logs has been
proposed before in the SLEUTH system [30], and its overall effec-
tiveness demonstrated. Our key contribution in this paper is to show
that naive tag propagation can lead to a large number of false pos-
itives, while our tag prioritization achieves a dramatic reduction in
this number. Secondly, our policies are more refined, enabling them
to detect stealthy attacks based on in-memory malware. According
to a recent report [6], a majority of threat actors (57%) avoided file-
resident malware in 2018, choosing to go with in-memory malware,
as it can evade most existing threat detectors (which are based on the
presence or execution of file-resident malware). As further evidence
of novelty in these policies, our approach was able to detect attacks
that made use of preexisting rootkits and kernel-resident malware.
Table III summarizes the attack detection policies used in our sys-
tem. These policies have the same general structure: they all concern
a system call (e.g., writing an object), with conditions imposed on (a)
the data integrity tags of the subject and/or objects involved, and (b)
other information associated with the call, such as permissions and
userids. The policies in Table III abstract some of the essential steps
of APT attacks [8], [2], [57], including the initial exploit, foothold
establishment, privilege escalation, and exfiltration of sensitive data.
The first row of Table III aims to capture the execution of in-
memory malware. This may either represent a memory corruption
exploit used in the initial exploit stage, or an advanced in-memory
payload used for attacker’s foothold establishment or expansion.
In order to trigger this policy, a subject’s data must have suspicious
provenance (signified by an integrity tag less than 0.5), and some of
this data should be readied for execution, which requires the use of
mmap or mprotect system calls with execute permission enabled.
(Note that mmap and mprotect also occur during library loading
operations. Our system maps these operations into a load, thus
preventing this policy from being triggered by file loads.)
The second row is aimed at file-based malware execution. It
is triggered by the load or execution of a file with suspicious
provenance. The third row is similar, except that instead of a subject
voluntarily loading suspicious code, malware is injected into its
address space by another subject.
The fourth row detects a step in preparing file-based malware
for execution by making the file executable. It requires the object’s
data to have suspicious provenance.
The fifth row detects overwriting of important system files (or
registry entries), a step that is typically used to establish a (more per-
manent) foothold on a host. It is triggered by an attempt by a subject
with suspicious provenance to overwrite a higher integrity object.
The sixth row recognizes a privilege escalation attack. This policy
is triggered by any system call by a subject with suspicious prove-
nance, provided the userid before and after the call are different.
Finally, the last row captures data exfiltration: an alarm is
triggered when a subject with suspicious provenance writes sensitive
data to a network socket that is not authorized for confidential data.
V. Attack Scenario Reconstruction
The central goal of this paper is to connect various attack steps to
provide a high-level summary of an ongoing attack campaign. To
achieve this, we first develop a dependence-based analysis to iden-
tify the initial attack step, also called the entry point. We then per-
form a tag-based forward dependency analysis to construct a graph
that summarizes the campaign. We describe these two steps below.
A. Entry Point Identification
Attack campaigns consist of many steps. Some of these steps lead
to numerous alerts, e.g., file corruption and data leak policies can
easily raise thousands of alerts. It is infeasible for an analyst to
track down each alert individually, so we have developed an alert
aggregation and prioritization technique further described below.
Given an alarm, we first associate it with a subject or object
originating it. For alarms raised on an input event, we consider the
object to be the originating node. For all other events, the subject
is considered the originator. We also assume that each alarm has
an associated weight, which is a real number between 0 and 1 that
reflects our confidence level in the alarm.
Given an alarm originating at node n, we perform a backward
search in the dependence graph for the closest node n(cid:48) that also
triggered an alarm. If we don’t find such an n(cid:48), then we call this
a primary alarm, and set precursor(n) to null, and weight(n) to
be the weight of the alarm. Otherwise, the new alarm is classified
as secondary; we set precursor(n) to precursor(n(cid:48)), and add the
weight of the alarm to the weight of precursor(n(cid:48)). Note that pri-
mary alarms have the combined weight of all the alarms ever raised.
1144
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:02:08 UTC from IEEE Xplore.  Restrictions apply. 
For simplicity, our implementation follows only subject to subject
edges while searching for n(cid:48), and ignores edges between subjects
and objects. (For alarms originating on objects, the first hop uses
an object-to-subject edge, but the rest are subject-to-subject edges.)
An analyst can now pick the top few primary alarms with the
highest weight, and investigate them further. We designate the least
common ancestor of the selected primary alarm nodes as the entry
point. In cases where the top-ranked primary alarms have a much
higher weight than the rest, this entry point discovery does not
require human assistance, and can be fully automated.
B. Forward Analysis
If the entry point or any of the primary alarm nodes are processes
with benign subject tags, then their subject tag is modified to
suspicious. Tag propagation rules are rerun on these processes,
as well any descendants whose tag has changed as a result of this.
Next, a depth-first search of the dependence graph is initiated at
the entry point node. This search does not visit nodes whose data
integrity tag is above a set threshold (which defaults to 0.5, but may
be changed by the analyst). This search identifies the nodes that
will be included in the scenario graph. Next, we add all the edges
incident on these nodes. We then add all the nodes attached to these
newly added edges. As a final step, we combine multiple edges
between two nodes if they have the same name, e.g., multiple reads.
VI.
Implementation
As shown in Fig. 2, our system consists of three layers that
implement its core functionality, together with an UI for an analyst.
The lowest layer consists of data consumers that process input from
COTS auditing systems. We used two consumers in our evaluation,
one for Linux auditd and another for FreeBSD DTrace [4] data.
These systems have the ability to log important system events,
including most system calls. There are two variants of the Linux
consumer. The first one directly inputs Linux audit logs, while
the second version inputs roughly the same information, but in
the Apache Avro format used by DARPA Transparent Computing
dataset [3]. FreeBSD consumer supports only the second format.
These consumers are written in C++ and consist of about 6KLoC.
They translate OS-specific events into a platform-neutral set of
operations provided by the middle layer. This platform-neutral
representation can be stored on disk, in a format we call Common
Semantic Representation (CSR) [31].
The middle layer can either operate from CSR files, or interface
directly to the data consumers. It is responsible for constructing and
traversing the dependence graph, and is implemented in 11 KLoC
of C++. It builds on our earlier SLEUTH system, incorporating
many further optimizations and refinements,
including our
dependency-preserving graph compaction technique [31]. Another
major new feature of MORSE is its runtime environment, which
exposes platform-neutral events to extension modules. These
extensions are written in E∗, our domain-specific language for
event monitoring and manipulation. All of the tag initialization,
tag propagation and alarm policies are implemented in E∗. Tag
propagation (Tables I and II) was realized using 103 lines of E∗,
while the alarm rules (Table III) required 37 lines. The compiler and
runtime environment for E∗ consist of about 8KLoC of C++. Due
to space constraints, we have omitted a detailed description of E∗.
The third layer consists of a user interface for analysts to monitor
alarms, run queries on the graph, construct scenario graphs, etc.
Fig. 2: Implementation Architecture
VII. Putting it All Together: Analysis of CCleaner
We now illustrate how the techniques described so far come together
to analyze the ccleaner attack from Section II. The resulting graph,
as seen by the analyst, is shown in Fig. 3. Note that the graph gen-
eration is fully automated, and involves no manual post-processing.
Data Tag Initialization. Newly created objects and subjects inherit
their tags from the subjects that create them, as described in Tables I
and II. But we need a separate mechanism for assigning tags to
pre-existing entities such as (a) processes and files existing before
the start of data collection, and (b) network endpoints.
Tag initialization can be based on an organization’s host configu-
ration practices and policies. Alternatively, they may be learned by
observing the use of files during a training period. Neither of these
options were available to us in our experiments. The dataset we
used did not come with any documentation of host configuration
practices. Moreover, although some training data was included, the
behavior observed on the days of attacks differed significantly from
the training data, thus ruling out the training option as well. For
this reason, we relied on the following minimalist approach in our
evaluation: we designated /etc/passwd, /etc/shadow and the
/var/log/ directory as confidential. All files originally present on
the system were assigned high integrity. Finally, network addresses
were assigned low integrity and confidentiality. This tag initializa-
tion is consistent with our threat model (Section VIII) and sufficient
for our evaluation. Our tag initialization code, used in the analysis
of all the attacks in our evaluation, consists of 14 lines in E∗.
Subject Tag Initialization. Similar to our treatment of pre-existing
files, all processes that were running at the start of data collection
(e.g., servers such as sshd) were marked benign.
Subject tags of benign processes change to suspicious if they
exhibit suspect behavior, e.g., loading or executing low-integrity
code, or injecting into a higher integrity subject (Table II).
Additionally, when a number of alarms can be traced back to a
subject, that subject is marked suspicious (Section V.A).
Attack Detection. Note that the initial login by Trudy does not
trigger any alarms. She is using stolen credentials, but our system
has no information about this theft. Her IP address is unremarkable
as well. When she downloads ccleaner, it is given a low integrity
since it being downloaded from an unknown internet site. When this
file is executed, it triggers the F ileExec alarm from Table III. The
ccleaner process is also marked as a suspect subject by the exec
rule in Table II. As a result, its file overwrite (or remove) operations
trigger the Corrupt alarm as well.
While the policies shown in Table III have been sufficient in our
experimental evaluation, note that additional attack detectors can
easily be incorporated in our system, and used to (a) identify and
tag suspicious subjects, and (b) trigger scenario graph generation.
Entry Point Identification. The entry-point identification technique
described in Section V traces back the above F ileExec and
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:02:08 UTC from IEEE Xplore.  Restrictions apply. 
1145
Linux audit dataconsumerAuditStreamAuditStreamGraph Query & Search APIE* extensionsFreeBSD DTracedata consumerAnalyst UIDependence Graph Construction  &Search...E* runtimeCommon Semantic Representation (CSR)Fig. 3: Scenario Graph constructed by MORSE for CCleaner Ransomware
Corrupt alarms to Trudy’s scp process. It is now given a subject
tag of suspicious, and the tag propagation rules are rerun.
Forward Analysis. Since the scp and ccleaner processes have
suspicious subject tags, no tag attenuation or decay is applicable to
them. Hence, every file written by these subjects is assigned a low
integrity tag, and their child processes continue to be suspicious.
When ccleaner’s child executes dbus-launch, a benign file, it
is marked as suspect environment, as per the execve rule in Table II
(middle column). As a suspect environment process, when it exe-
cutes another benign file, dbus-daemon, this execve rule (see the
right-most column) causes it to be marked benign. Note that dbus-
daemon still has low data integrity, but due to attenuation and decay,
its child processes end up having benign subject and data tags.
Recall that our forward analysis starts at the entry point node
and traverses forward through all nodes (objects or subjects) with
data integrity ≤ 0.5. The resulting graph is shown in Fig. 3.
Refinement and Rerun. Analysts can refine and rerun this analysis
in order to convince themselves that some components of the attack
haven’t been missed. Since our forward analysis typically takes a
small fraction of a second, analysts can explore refinements rapidly.
Some of the possible refinement actions include: (a) marking
additional subjects as suspicious, (b) trying alternative attenuation
and decay values, (c) changing the tag value threshold for including
a node in the scenario graph, or (d) extending the graph forward at
selected nodes. For this attack, there were no obvious candidates for
(a). We tried (b) through (d), but found no more malicious activity.
VIII. Experimental Evaluation
Platform. The system under attack consisted of multiple hosts
running recent versions of Ubuntu Linux and FreeBSD. Our
analysis was performed on an Ubuntu 18.04 Linux laptop with
an Intel 2.7GHz i7-7500U CPU and 16GB memory.
Threat Model. Similar to previous research on attack reconstruction
from audit logs [36], [30], [51], [57], [29], we assume that attackers
cannot compromise audit record collection or the log itself. Best
results are obtained if (a) victim systems start off in a benign
state, i.e., without any pre-existing malicious software, and (b)
all security-relevant system calls and arguments are included in the
audit log. However, real-world systems may not always satisfy these
conditions. Indeed, several of the attacks in our dataset relied on
pre-existing malware. The logs were also incomplete due to missing
system-call arguments and/or provenance in some cases. Despite
these factors, MORSE was able to produce very good results.
A. Dataset
Many previous works [36], [46], [53], [51], [29] have based their
evaluation on attack datasets created by the authors themselves.
This choice is not optimal, as it can introduce a bias in attack
selection that favors the authors. Yet, it is unavoidable in the
absence of third-party datasets. We have therefore chosen to
evaluate our system using attacks carried out by an independent red
team, as part of the DARPA Transparent Computing (TC) program.
DARPA organized five red team engagements between 2016 and
2019. The scale and sophistication of these engagements increased
significantly after the first two engagements, so we focused our eval-
uation on the third and fourth engagements. (The fifth engagement
had not taken place by the time this work was carried out in early
2019.) Note that the third engagement data has already been publicly