### 2.3.1 Reachability Analysis

Our reachability analysis is conducted in two stages: intra-procedural and inter-procedural.

**Intra-Procedural Reachability Analysis:**
The first step involves building call graphs and resolving them using conventional def-use analysis [11]. This process starts from the initial state, which is pre-computed when the database is initially populated. The resolution then iteratively seeks a fixed point of state changes. Due to the potential for combinatorial explosion, the state space can be vast, leading to slow or even non-convergent progress. To manage this, we impose additional conditional constraints to control the state-changing iteration procedure. The result of this intra-procedural analysis, including the states of variables and fields, is termed a summary.

**Inter-Procedural Reachability Analysis:**
The second step propagates states between different methods. After each propagation, method summaries may change, necessitating a new round of intra-procedural reachability analysis on affected methods to generate updated summaries. Inter-procedural reachability analysis is also iterative and more resource-intensive. To mitigate this, we use heuristics to reduce computational and space overhead. For example, if a variable or field of interest has already reached a sink, further convergence checks are unnecessary. A formal description of our reachability analysis is provided in Algorithm 3 (see Appendix A).

**Similarity Analysis:**
Paths of apps from different vendors but with similar functionality often share commonalities, especially those inherited from the standard AOSP framework. "Common" here refers to structural and functional similarities rather than identical source code. Many devices reuse AOSP code with minimal modifications. If reachability analysis has been performed on a common path, it is unnecessary to repeat it for similar counterparts. This similarity analysis improves system performance by avoiding redundant computations.

### 2.3.2 Reflection Analysis

To facilitate our analysis, we classify vulnerable paths into three types:

- **In-Component:** A vulnerable path that starts from an unprotected component and reaches a sink within the same component.
- **Cross-Component:** A vulnerable path that starts from an unprotected component, traverses other components within the same app, and reaches a sink.
- **Cross-App:** A vulnerable path that starts from an unprotected component of one app, traverses components of another app, and eventually reaches a sink.

While in-component vulnerable paths have been well-studied [24, 34], cross-component and cross-app paths, especially the latter, have received less attention. Our reflection analysis focuses on these more complex paths. A reflection-based attack typically involves multiple components, possibly across different apps. An example detected by our tool is shown in Figure 6 (Section 3.3.1).

Traditional reachability analysis is effective for in-component paths but limited for cross-component or cross-app paths. To address this, our approach identifies not only reachable paths within each component but also the invocation relationships between components. These relationships are indicated by sending intents, either explicitly or implicitly. Explicit intents specify the target component, while implicit intents require intent resolution to determine the best target from available components. In our system, SEFA mimics the Android intent resolution mechanism by matching intents against all possible manifest declarations in installed apps. However, due to the offline nature of our system, we use heuristics to handle the lack of runtime information:

- Prefer components from the same app over those from other apps.
- Prefer components from different apps sharing the same `sharedUserId` over others.

If multiple candidates remain for a particular intent, we iterate through each to report possible vulnerable paths, followed by manual verification in a real phone setting. Algorithm 2 summarizes the overall procedure, maintaining a visited component list and recursively checking all possible components that can start up the current component.

### 3. Implementation and Evaluation

We implemented a prototype of SEFA using Java and Python, with 11,447 and 4,876 lines of code, respectively. Our evaluation examined ten representative phones released between the end of 2010 and the end of 2012 by five popular vendors: Google, Samsung, HTC, LG, and Sony. The selected models are either highly impactful, representative, or have significant market share. For example, Google’s phones serve as reference models, and Samsung holds 39.6% of the smartphone market share in 2012 [30]. Processing each image took an average of 70 minutes, reporting about 300 vulnerable paths for manual verification. Given the offline nature of our tool, this performance is acceptable, though further optimization is possible.

### 3.1 Provenance Analysis

Provenance analysis collects extensive information about each device and classifies pre-loaded apps into three categories: AOSP, vendor, and third-party. Table 1 summarizes our results. Across ten devices, there were 1,548 pre-loaded apps, totaling 114,427,232 lines of decompiled .smali code. On average, 28.2 (18.22%) AOSP, 99.7 (64.41%) vendor, and 26.9 (17.38%) third-party apps were found. Vendor customizations account for more than 81.78% of apps (or 76.34% of LOC) on these devices.

We selected two phone models for each vendor: one from the current generation of Android 4.x and one from the previous generation of 2.x. Table 2 shows the initial release dates. Devices can be classified by their release dates: pre-2012 and post-2012. Post-2012 products generally have more apps and LOC than their pre-2012 counterparts. For instance, the HTC Wildfire S has 147 apps with 9,643,448 LOC, while the HTC One X has 280 apps with 19,623,805 LOC, representing increases of 90.47% and 103.49%, respectively.

Google-branded phones are particularly interesting. Both have relatively few apps, designed as reference designs with minor AOSP alterations. The Nexus 4, however, has over three times the LOC of the Nexus S despite adding only 18 apps. The Nexus S was the simplest phone, while the Nexus 4 is the third most complex, behind the HTC One X and Samsung Galaxy S3, known for extensive customization.

### 3.2 Permission Usage Analysis

After determining the provenance of each pre-loaded app, we analyzed instances of permission overprivilege, where an app requests more permissions than it uses. On average, 85.78% of apps across the ten devices are overprivileged. Even Google’s reference devices do not perform significantly better. The situation is slightly improving, with post-2012 devices having 83.61% overprivileged apps compared to 87.96% for pre-2012 devices. This is still concerning. Pre-loaded apps are more privileged and frequently specify the `sharedUserId` property, contributing to higher overprivilege rates compared to third-party apps [2, 17].

This structured and detailed approach ensures clarity, coherence, and professionalism in the text.