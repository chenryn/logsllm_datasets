0.3
t
e
a
r
n
o
i
t
c
e
e
d
t
k
c
a
t
t
A
(0.40) 
0.2
0
(0.72) 
(0.70) 
(0.66) 
(0.6) 
k=5
k=10
k=25
0.2
0.4
0.6
0.8
1
False positive rate(%)
Figure 2: Performance of the kNN classiﬁer method expressed in ROC curves. False positive rate vs attack detection rate for k=5,
10 and 25. Corresponding threshold values are shown in the parentheses for k=10.
Unlike the groups who participated in the 1998 DARPA
Intrusion Detection Evaluation program [20], we deﬁne
our false positive probability as the rate of mis-classiﬁed
processes, instead of mis-classiﬁed sessions.
The performance of the kNN classiﬁer algorithm also
depends on the value of k, the number of nearest neigh-
bors of the test process. Usually the optimal value of
k is empirically determined. We varied k’s value from
5 to 25. Figure 2 shows the ROC curves for different
k values. For this particular data set, k=10 is a better
choice than other values in that the attack detection rate
reaches 100% faster. For k=10, the kNN classiﬁer al-
gorithm can detect 10 of the 35 attacks with zero false
positive rate. The detection rate reaches 100% rapidly
when the threshold is raised to 0.72 and the false posi-
tive rate remains as low as 0.44% (23 false alarms out of
5285 normal processes) for the whole simulation day.
The RSTCORP group gave good performance during
the evaluation of the 1998 DARPA BSM data [20]. By
learning normal sequences of system calls for more than
150 programs, their Elman neural networks [8] were
able to detect 77.3% of all intrusions with no false pos-
itives, and 100% of all attacks with about 10% miss-
classiﬁed normal sessions, which means 40 to 50 false
positive alarms for a typical simulation day with 500
sessions. Their test data consisted of 139 normal ses-
sions and 22 intrusive sessions. Since different test data
sets were used, it is difﬁcult to compare the performance
of our kNN classiﬁer with that of the Elman networks.
Although the kNN classiﬁer has lower attack detection
rate at zero false positive rate, the attack detection rate
reaches 100% quickly, and hence a low false alarm fre-
quency can be achieved.
4.3 Anomaly Detection Combined with Signa-
ture Veriﬁcation
We have just shown that the kNN classiﬁer algorithm can
be implemented for effective abnormality detection. The
overall running time of the kNN method is O(N), where
N is the number of processes in the training data set (usu-
ally k is a small constant). When N is large, this method
could still be computationally expensive for some real-
time intrusion detection systems. In order to detect at-
tacks more effectively, the kNN anomaly detection can
be easily integrated with signature veriﬁcation. The ma-
licious program behavior can be encoded into the train-
ing set of the classiﬁer. After carefully studying the 35
attack instances within the seven-week DARPA training
data, we generated a data set of 19 intrusive processes.
This intrusion data set covers most attack types of the
DARPA training data. It includes the most clearly ma-
licious processes, including ejectexploit, formatexploit,
ffbexploit and so on.
For the improved kNN algorithm, the training data set in-
cludes 606 normal processes as well as the 19 aforemen-
tioned intrusive processes. The 606 normal processes
are the same as the ones in subsection 4.2. Each new test
process is compared to intrusive processes ﬁrst. When-
ever there is a perfect match, i.e., the cosine similarity
Table 3: Attack detection rate for DARPA testing data (k=10
and threshold=0.8) when anomaly detection is combined with
signature veriﬁcation.
Attack
Instances Detected Detection rate
Known attacks
Novel attacks
Total
16
8
24
16
6
22
100%
75%
91.7%
is equal to 1.0, the new process is labeled as intrusive
behavior (one could also check for near matches). Oth-
erwise, the abnormal detection procedure in Figure 1 is
performed. Due to the small amount of the intrusive pro-
cesses in the training data set, this modiﬁcation of the
algorithm only causes minor additional calculation for
normal testing processes.
The performance of the modiﬁed kNN classiﬁer algo-
rithm was evaluated with 24 attacks within the two-week
DARPA testing audit data. The DARPA testing data con-
tains some known attacks as well as novel ones. Some
duplicate instances of the eject attack were not included
in the test data set. The false positive rate was evalu-
ated with the same 5285 testing normal processes as de-
scribed in Section 4.2. Table 3 presents the attack de-
tection accuracy for k=10 and the threshold of 0.8. The
false positive rate is 0.59% (31 false alarms) when the
threshold is adjusted to 0.8.
The two missed attack instances were a new denial of
service attack, called process table. They matched with
one of training normal processes exactly, which made it
impossible for the kNN algorithm to detect. The pro-
cess table attack was implemented by establishing con-
nections to the telnet port of the victim machine every 4
seconds and exhausting its process table so that no new
process could be launched [21]. Since this attack con-
sists of abuse of a perfectly legal action, it did not show
any abnormality when we analyzed individual processes.
Characterized by an unusually large number of connec-
tions active on a particular port, this denial of service
attack, however, could be easily identiﬁed by other in-
trusion detection methods.
Among the other 22 detected attacks, eight were cap-
tured with signature veriﬁcation. These eight attacks
could be identiﬁed without signature veriﬁcation as well.
With signature veriﬁcation, however, we did not have to
compare them with each of the normal processes in the
training data set.
5 Summary
In this paper we have proposed a new algorithm based
on the k-Nearest Neighbor classiﬁer method for model-
ing program behavior in intrusion detection. Our pre-
liminary experiments with the 1998 DARPA BSM audit
data have shown that this approach is able to effectively
detect intrusive program behavior. Compared to other
methods using short system call sequences, the kNN
classiﬁer does not have to learn individual program pro-
ﬁles separately, thus the calculation involved with clas-
sifying new program behavior is largely reduced. Our
results also show that a low false positive rate can be
achieved. While this result may not hold against a more
sophisticated data set, the k-Nearest Neighbor classiﬁer
appears to be well applicable to the domain of intrusion
detection.
The tf idf text categorization weighting technique was
adopted to transform each process into a vector. With the
frequency-weighting method, where each entry is equal
to the number of occurrences of a system call during the
process execution, each process vector does not carry
any information on other processes. A new training pro-
cess could be easily added to the training data set with-
out changing the weights of the existing training sam-
ples. This could make the kNN classiﬁer method more
suitable for dynamic environments that require frequent
updates of the training data.
In our current implementation, we used all the system
calls to represent program behavior. The dimension of
process vectors, and hence the classiﬁcation cost, can be
further reduced by using only the most relevant system
calls.
6 Discussion
In spite of the encouraging initial results, there are sev-
eral issues that require deeper analysis.
Our approach is predicated on the following properties:
the frequencies of system calls issued by a program ap-
pear consistently across its normal executions and un-
seen system calls will be executed or unusual frequen-
cies of the invoked system calls will appear when the
program is exploited. We believe these properties hold
true for many programs. However, if an intrusion does
not reveal any anomaly in the frequencies of system
calls, our method would miss it. For example, attacks
that consist of abuse of perfectly normal processes such
as process table would not be identiﬁed by the kNN clas-
siﬁer.
With the kNN classiﬁer method, each process is classi-
ﬁed when it terminates. We argue that it could still be
suitable for real-time intrusion detection. Each intrusive
attack is usually conducted within one or more sessions,
and every session contains several processes. Since the
kNN classiﬁer method monitors the execution of each
process, it is highly likely that an attack can be detected
while it is in operation. However, it is possible that an at-
tacker can avoid being detected by not letting the process
exit. Therefore, there is a need for effective classiﬁcation
during a process’s execution, which is a signiﬁcant issue
for our future work.
7 Acknowledgment
The authors wish to thank Dr. Marc Zissman of Lincoln
Laboratory at MIT for providing us the DARPA training
and testing data. We also thank the reviewers for their
valuable comments. Special thanks to Dr. Vern Paxton
for his insightful comments that helped us to improve the
quality and readability of the ﬁnal version. This work
is supported in part by the AFOSR grant F49620-01-1-
0327 to the Center for Digital Security of the University
of California, Davis.
References
[1] H.S. Javitz and A. Valdes, The NIDES Statistical
Component: Description and Justiﬁcation, Tech-
nical Report, Computer Science Laboratory, SRI
International, Menlo Park, CA, March 1994.
[2] H.S. Vaccaro and G.E. Liepins, “Detection of
Anomalous Computer Session Activity”, Proceed-
ings of 1989 IEEE Symposium on Security and Pri-
vacy, 280-289, 1989.
[3] E. Lundin and E. Johnsson, “Anomaly-based in-
trusion detection: privacy concern and other prob-
lems”, Computer Networks, vol. 34, 623-640,
2000.
[4] V. Dao and V. R. Vemuri, “Computer Network In-
trusion Detection: A Comparison of Neural Net-
works Methods”, Differential Equations and Dy-
namical Systems, (Special Issue on Neural Net-
works, Part-2), vol.10, No. 1&2, 2002.
[5] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A.
Logstaff, “A Sense of Self for Unix process”, Pro-
ceedings of 1996 IEEE Symposium on Computer
Security and Privacy, 120-128, 1996.
[6] C. Warrender, S. Forrest and B. Pearlmutter, “De-
tecting Intrusions Using System Calls: Alternative
Data Models”, Proceedings of 1999 IEEE Sympo-
sium on Security and Privacy, 133-145, 1999.
[7] W. Lee, S. J. Stolfo and P. K. Chan, “Learning Pat-
terns from Unix Process Execution Traces for In-
trusion Detection”, Proceedings of AAAI97 Work-
shop on AI Methods in Fraud and Risk Manage-
ment, 50-56, 1997.
[8] A. K. Ghosh, A. Schwartzbard and A. M. Shatz,
“Learning Program Behavior Proﬁles for Intrusion
Detection”, Proceedings of 1st USENIX Workshop
on Intrusion Detection and Network Monitoring,
Santa Clara, CA, April 1999.
[9] K. Aas and L. Eikvil, Text Categorisation: A Sur-
vey, http://citeseer.nj.nec.com/
aas99text.html, 1999.
[10] Y. Yang, An Evaluation of Statistical Ap-
proaches to Text Categorization, Technical Report
CMU-CS-97-127, Computer Science Department,
Carnegie Mellon University, 1997.
[11] Y. Yang, “Expert Network: Effective and Efﬁcient
Learning from Human Decisions in Text Catego-
rization and Retrieval”, Proceedings of 17th An-
nual International ACM SIGIR Conference on Re-
search and Development in Information Retrieval
(SIGIR’94), 13-22, 1994.
[12] C. Ko, G. Fink and K. Levitt, “Automated Detec-
tion of Vulnerabilities in Privileged Programs by
Execution Monitoring”, Proceedings of 10th An-
nual Computer Security Applications Conference,
Orlando, FL, Dec, 134-144, 1994.
[13] P. Uppuluri and R. Sekar, “Experiences with
Speciﬁcation-Based Intrusion Detection”, Recent
Advances in Intrusion Detection (RAID 2001),
LNCS 2212, Springer, 172-189, 2001.
[14] D. Wagner and D. Dean, “Intrusion Detection via
Static Analysis”, Proceedings of IEEE Symposium
on Research in Security and Privacy, Oakland, CA,
2001.
[15] M. Asaka, T. Onabuta, T. Inoue, S. Okazawa and S.
Goto, “A New Intrusion Detection Method Based
on Discriminant Analysis”, IEEE TRANS. INF. &
SYST., Vol. E84-D, No. 5, 570-577, 2001.
[16] N. Ye, X. Li, Q. Chen S. M. Emran and M. Xu,
“Probabilistic Techniques for Intrusion Detection
Based on Computer Audit Data”, IEEE Trans.
SMC-A, Vol. 31, No. 4, 266-274, 2001.
[17] J. T.-Y. Kwok, “Automatic Text Categorization
Using Support Vector Machine”, Proceedings of
International Conference on Neural Information
Processing, 347-351, 1998.
[18] MIT
Laboratory,
http://www.ll.mit.edu/IST/ideval/.
Lincoln
[19] Sun Microsystems, SunShield Basic Security Mod-
ule Guide, 1995.
[20] R. Lippmann, D. Fried, I. Graf, J. Haines, K.
Kendall, D. McClung, D. Webber, S. Webster,
D. Wyschograd, R. Cunninghan and M. Zissan,
“Evaluating Intrusion Detection Systems: the 1998
DARPA off-line Intrusion Detection Evaluation”,
Proceedings of the DARPA Information Survivabil-
ity Conference and Exposition, IEEE Computer
Society Press, Los Alamitos, CA, 12-26, 2000.
[21] K. Kendall, “A Database of Computer Attacks for
the Evaluation of Intrusion Detection Systems”,
Master’s Thesis, Massachusetts Institute of Tech-
nology, 1998.