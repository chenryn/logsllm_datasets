title:Achieving convergence-free routing using failure-carrying packets
author:Karthik Lakshminarayanan and
Matthew Caesar and
Murali Rangan and
Tom Anderson and
Scott Shenker and
Ion Stoica
Achieving Convergence-Free Routing using
Failure-Carrying Packets
Karthik Lakshminarayanan
University of California, Berkeley
Matthew Caesar
University of California, Berkeley
Murali Rangan
University of California, Berkeley
Tom Anderson
University of Washington
Scott Shenker
University of California, Berkeley
Ion Stoica
University of California, Berkeley
ABSTRACT
Current distributed routing paradigms (such as link-state, distance-
vector, and path-vector) involve a convergence process consisting
of an iterative exploration of intermediate routes triggered by cer-
tain events such as link failures. The convergence process increases
router load, introduces outages and transient loops, and slows re-
action to failures. We propose a new routing paradigm where the
goal is not to reduce the convergence times but rather to elimi-
nate the convergence process completely. To this end, we propose
a technique called Failure-Carrying Packets (FCP) that allows data
packets to autonomously discover a working path without requir-
ing completely up-to-date state in routers. Our simulations, per-
formed using real-world failure traces and Rocketfuel topologies,
show that: (a) the overhead of FCP is very low, (b) unlike traditional
link-state routing (such as OSPF), FCP can provide both low loss-
rate as well as low control overhead, (c) compared to prior work in
backup path precomputations, FCP provides better routing guaran-
tees under failures despite maintaining lesser state at the routers.
Networks]:
[Computer-Communication
Categories Subject Descriptors
C.2.2
Network
protocols–Routing protocols; C.2.6 [Computer-Communication
Networks]: Internetworking
General Terms
Algorithms, Design, Performance.
Keywords
Internet routing, convergence, protocols.
1.
INTRODUCTION
Recent large-scale deployments of delay and loss-sensitive ap-
plications have led to stringent demands on routing. Lost or de-
layed packets in applications such as Voice over IP (VoIP), stream-
ing media, gaming, and telecommuting/video conferencing applica-
tions can result in signiﬁcant performance degradation. ISPs hence
have strong incentives to reduce delay and loss on their networks,
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’07, August 27–31, 2007, Kyoto, Japan.
Copyright 2007 ACM 978-1-59593-713-1/07/0008 ...$5.00.
as these are often key metrics used when negotiating Service-Level
Agreements (SLAs) associated with such applications. Routing
convergence is one of the key impediments to meeting strict SLAs.
Traditional routing paradigms—distance-vector, path-vector, and
link-state—differ substantially in the nature of the state maintained
by and exchanged between routers. However, all these paradigms
rely on protocol messages to alert routers about changes in the net-
work topology. It is only after the news of a topology change has
reached all routers, directly in the case of link-state and indirectly
in the case distance-vector and path-vector, that the protocol can
ensure that the forwarding tables deﬁne consistent routes between
all pairs of nodes. Thus, all such routing protocols experience a
convergence period—after the change has been detected and before
all routers learn about the change—during which the routing state
might be inconsistent.
While the convergence process is invoked whenever link costs
change, link and router failures are the events that cause the most
serious problems. They can cause losses [3] and, in some cases,
trigger LSA storms, resulting in high CPU and memory utilization
in routers and increased network instability [10]. Though the con-
vergence period fundamentally depends on network properties such
as the diameter of the network, it is exacerbated in practice due to
system-level issues such as protocol timers.
The attempts to solve this problem in the literature can be roughly
classiﬁed into three categories: (a) designing loop-free convergence
protocols, (b) reducing the convergence period of protocols, and
(c) using precomputed backup paths to route around failures. The
ﬁrst category of proposals involves protocol changes (such as or-
dering of LSAs [15]) to ensure that the convergence process does
not cause transient loops. The second category involves reducing
convergence period by tweaking protocol parameters (such as LSA
propagation timers and periodicity of HELLO messages) [3]. These
mechanisms often achieve lower convergence times but at the ex-
pense of additional overhead, and lower stability (as we show in
our experiments). The third category deals speciﬁcally with link
failures by precomputing backup paths for links, which can be used
when the link in question fails [18, 19, 28]. Recently, R-BGP [20]
proposes using precomputation-based backups for fast-failover dur-
ing BGP convergence; R-BGP also provides provable guarantees
such as loop-prevention. These backup mechanisms typically deal
with the failure of single links gracefully; however, in order to pro-
vide guarantees for simultaneous failures of multiple arbitrary links,
the number of precomputed paths needed is extremely high.
Using the state-of-the-art techniques, the convergence period can
be eliminated for single failures, and more generally the duration
and impact of convergence can be reduced. While these changes
are quantitatively beneﬁcial, they do not change the qualitative fact
that these protocols could (due to multiple failures) endure a conver-
gence period during when it is hard to provide routing guarantees.
In this paper, we propose a different routing paradigm, called
Failure-Carrying Packets (FCP) that eliminates the convergence pe-
riod altogether. Once a failure is detected locally, packets are guar-
anteed to be routed to their destination as long as a path to the des-
tination exists in the network.
FCP takes advantage of the fact that network topology in the In-
ternet does not undergo arbitrary changes. In intradomain ISP net-
works and in the AS-level Internet graph there is a well-deﬁned set
of potential links (i.e., those that are supposed to be operational)
that does not change very often. The set of these potential links that
are actually functioning at any particular time can ﬂuctuate (de-
pending of link failures and repairs), but the set of potential links is
governed by much slower processes (i.e., decommissioning a link,
installing a link, negotiating a peering relationship). Thus, one can
use fairly standard techniques to give all routers a consistent view
of the potential set of links, which we will call the Network Map.
FCP hence adopts a link-state approach, in that every router has a
consistent network map.
Since all routers have the same network map, all that needs to
be carried by the packets is information about which of these links
have failed at the current instant. This failure-carrying packets ap-
proach ensures that when a packet arrives at a router, that router
knows about any relevant failures on the packet’s previous path.
This eliminates the need for the routing protocol to immediately
propagate failure information to all routers, yet allows packets to
be routed around failed links in a consistent loop-free manner. We
also present a variant called Source-Routing FCP (SR-FCP) that
provides similar properties even if the network maps are inconsis-
tent, at the expense of additional overhead in packet headers.
Though we present FCP to introduce a new routing paradigm
that is qualitatively different from previous approaches, we show
through simulation that it has the potential to provide quantitative
beneﬁts as well. Using real-world ISP topologies and failure data,
we show that the overhead of using FCP — in terms of computation,
overhead in packet headers, and stretch incurred — is very small.
We also compare FCP with OSPF and show that, unlike OSPF,
FCP can simultaneously achieve both low loss and low overhead.
Finally, we show that compared to prior work in backup path pre-
computations, FCP provides much lower loss-rates while maintain-
ing less state at the routers.
Though we present FCP as a link-state protocol, an approach
which applies directly to intradomain and enterprise routing, we
believe that the same idea can be used for interdomain routing as
well. To this end, we outline a strawman proposal for applying FCP
to interdomain routing in Section 7. We leave a complete study of
applying FCP to interdomain routing for future work.
2. FAILURE-CARRYING PACKETS
We now introduce the FCP algorithm and its properties using a
simple network model where routers use link-state routing.
In FCP, all nodes (we will use the terms router and node inter-
changeably) in the network maintain a consistent Network Map,
which represents the link-state of the network; we relax the map
consistency assumption in Section 2.2. In the absence of failures,
FCP reduces to a link-state protocol; when failures occur, FCP be-
haves quite differently, as we now explain. For the purpose of our
discussion, we assume that all nodes know the network map, and,
unless otherwise speciﬁed, that this map does not change. We dis-
cuss how the network map is disseminated and updated in Section 4.
Initialization: pkt.failed links = NULL
Packet Forwarding:
while (TRUE)
path = ComputePath(M − pkt.failed links)
if (path == NULL)
abort(“No path to destination”)
else if (path.next hop == FAILED)
pkt.failed links ∪= path.next hop
else
Forward(pkt, path.next hop)
return
Figure 1: Basic FCP protocol.
2.1 Basic FCP design
The main intuition behind FCP is that it is enough for a router
to know the list of failed links in the network, in addition to the
network map, to compute the path to a destination. FCP uses the
packet header to gather and carry the list of failed links required for
routing that packet. As we show later, the packet needs to carry only
the failed links that the packet has so far encountered along its path,
not all failed links in the network, in order for this to work. Thus,
the number of failures carried in any packet header is typically very
small.
Figure 1 shows the pseudocode of the basic FCP protocol. When
a packet arrives at a router, its next-hop is computed using the net-
work map minus the failed links in the header. If this next-hop
would send the packet out an interface that has a failed link, then the
router: (1) inserts the failed link into the packet header, (2) recom-
putes the route using this new failure information, and (3) returns
to step one if the new next-hop also incurs a failure and, if not, for-
wards the packet to its next-hop. Note that each packet is treated
separately; the failure information contained in a packet is not in-
corporated into the routing tables.
To understand FCP better, consider the example in Figure 2, a
network with unit link weights. Assume N1 sends a message to
Nd, and that links N3−Nd and N5−N7 are down. Since only
nodes adjacent to the failed links know about the failure, the
packet is forwarded along the shortest path in the original graph,
(N1, N2, N3, Nd), until it reaches the failed link N3−Nd. At this
point, N3 computes a new shortest path to Nd based on the map mi-
nus link N3−Nd, and includes the failed link N3−Nd in the header.
Let us assume that this path is (N4, N5, N7, Nd). When the packet
reaches N5, N5 adds the failed link N5−N7 to the header, and com-
putes a new shortest path that does not include the two failed links.
Eventually the packet reaches the destination, Nd, along this path.
In general, there are two possibilities when a packet hits a failed
link: either there is no path to the destination, in which case the
packet is dropped, or there is some path to the destination in which
case the graph on which routers compute the path becomes smaller
(i.e., because it does not include the failed link).1 With every new
failed link inserted in the packet header, the graph over which the
packet is routed becomes monotonically smaller.
2.2 Source-Routing FCP (SR-FCP)
Basic FCP assumes that all nodes have the same map. We now
relax this assumption, by presenting an alternate design that em-
ploys source-routing. With source-routing FCP (SR-FCP), the ﬁrst
1There is a third possibility that arises due to congestion: if the router cannot
hold on to the packet due to resource limitations, packets might be dropped.
or not. This aspect captures the fact that, in FCP, once a failed link
is added to the packet header, it is never removed from the header.3
Next, we give sufﬁcient conditions that guarantee packet delivery
in FCP.
LEMMA 1. Guaranteed Reachability: Consider packet p en-
tering network M at time t1. Assume link failures are detected in-
stantaneously, there are no packet losses due to network congestion,
and the propagation delay over any link is one time unit. Let d(G)
denote the diameter of graph G.
Then, FCP guarantees that p will be delivered to the destination
by time t2, where t2 is the smallest time, if any, such that the fol-
lowing two conditions hold:
1. there are at most f failures during [t1, t2], where f ≤ (t2 −
t1)/d(LG(t1, t2)) − 1
2. LG(t1, t2) is connected and spans (all nodes of) M
PROOF. The main part of the proof is to show that packet p is
delivered to its destination by some time t2 that satisﬁes conditions
(1) and (2). From here it follows trivially that packet p will be de-
livered by the smallest value of such t2.
The proof is by contradiction. Assume p is not delivered to the