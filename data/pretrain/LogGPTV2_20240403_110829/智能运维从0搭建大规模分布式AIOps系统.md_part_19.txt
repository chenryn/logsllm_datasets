离线数据为多链路上下游监控提供了更加精准的数据支持，是监控体系的很重要的一部分。
：
业务库
引擎服务
数据采集层
案例分析
数据同步工具
10
消息中间件
（作监据）
（元效据、轻管摄、维皮指标）
计算调度系统
图6-9微博广告数据架构示意图
strsarkng
仅供非商业用途或交流学习使用
DIM（维度数据）
数据计算层
离线计算
计算支撑
实时计算
（EDWS
数据质量系统
（数据华市）
第6章大规模数据离线计算分析
MySQL
Oruid
数据服务层
数据应用层
Hubble
101
---
## Page 129
源的有 Oozie、Airflow、Azkaban 等。值得一提的是，一个调度系统至少需要满足如下几点：
该放在ETL 中进行处理，否则会增加ETL 维护的复杂度。
ETL只需要关注业务逻辑，将打印日志、计算状态监控都交给调度系统，这些逻辑的代码不应
数据仓库也是离线计算的管理方式，管理离线计算是数据仓库的一个重要功能。
种对数据进行管理和使用的方式，它是包括ETL、调度、建模在内的一套理论体系。也就是说，
展下去必然是差。为解决多、乱、差的问题，引入了数据仓库的概念。我们认为数据仓库是一
6.3.1
后，可以满足某种或多种数据产品的需求。数据应用层是从数据服务层提交的API获取数据的。
的组合，其中Druid 主要计算实时数据，ClickHouse 主要支持离线数据。
要，需要支持复杂的海量数据查询，同时以毫秒级响应。微博广告的选型为Druid和ClickHouse
对查询操作进行路由，保障查询的性能。查询引擎一定是可扩展的。服务层的数据存储比较重
务层的数据存储（服务数据源）。查询引擎有两个职能，一是提供OpenAPI的Web 服务；二是
典、平台字典等。
据的数据，比如表的表、字段的表等。主数据是指能在各个系统之间共享的数据，比如地域字
度的管理。
层之后的计算脉络更清晰，非常有利于对后续计算的维护。最后是对元数据、主数据、计算调
算按照业界的标准分层处理，主要有操作数据层、明细数据层、汇总数据层、数据集市层。分
部分，微博广告的数据离线计算量非常大，可以满足日常业务支撑的大部分数据需求。离线计
件消费消息，然后计算处理，将处理结果发送到数据服务层的数据存储模块。其次是离线计算
102
有一个好用的调度系统，离线计算管理就成功了一大半。调度系统又称作工作流系统，开
2.调度
业务复杂度高，离线计算的数据种类就多，由“多”发展下去可能就是“乱”，由“乱”发
数据应用层：专为数据产品而设计，如广告的投放监控、定投产品等。数据按需加工处理
数据服务层：主要对外提供数据API服务，主要分为数据服务工具（又称查询引擎）和服
数据计算层：首先是实时计算部分，Spark Streaming、Storm、Flink等工具直接从消息中间
微博广告计算有一套标准的 ETL代码模板，能兼容开发环境和线上环境。我们的经验是
1.ETL
智能运维：从O搭建大规模分布式AIOps系统
离线计算管理
。这是整个计算层的核心支撑，非常重要，包含了数据质量系统。元数据是指管理数
仅供非商业用途或交流学习使用
---
## Page 130
果某一天曝光日志只有1TB，则数据缺少了33%，这就说明数据不完整。准确性是指数值的准
取的数据条数与实际的数据的比值，理论值为100%。例如，每天的曝光日志至少为1.5TB，如
统主要从数据的完整性、一致性、准确性、及时性四个角度进行了校验。完整性是指日志或抽
校验所产出的数据的质量呢？微博广告数据团队花大功夫开发了一套数据质量管理系统，该系
6.3.3
再比如，在Hive里使用insert into方法，导致局部数据重复。
的insert方法将数据插入到MySQL数据库中,原来的数据没有清除,导致重新计算后量级翻倍；
维护起来比较困难。我们总结的经验是：
要包含资源调度、队列等待等时间，在MR任务实际计算之前）还短。整个计算脉络节奏不一，
会导致每个人都按照自己的经验来控制处理逻辑，从而导致有些计算单元特别耗时，有的 MR
及控制度如何，在进行数据架构时容易被忽视。如果在这方面没有形成规范和共识，结果可能
6.3.2
灵活的报警方式等。
开发的调度系统，定制了很多好用的功能，比如以项目方式管理计算原子、友好的可视化界面、
任务管理和调度的效率。③具有失败报警功能。经过调研，微博广告使用了新浪平台团队自己
节点的自动重算和超时配置。这两项功能非常实用，特别是当调度任务比较多时，能极大提高
①支持有向无环图，即支持计算节点的单项依赖或多重依赖配置，数据流向一致。②支持计算
数据的准确性基本上是离线计算的生命线，如果数据不准确，计算就没了意义。那么如何
上面第三点看起来很简单，但是在实践过程中还是容易犯这类错误和。比如使用 MySQL
离线计算原子，通常指一个ETL的计算单元。离线计算原子究竟要控制多少计算逻辑，
O
O
计算原子一定要可重复计算，即在计算完成输出时一定要覆盖原来的文件，或者在计
，按照业务系统的事务逻辑控制，即逻辑的所有步骤要么都成功，要么都失败。
离线计算的数据质量
算前就直接删除原来的计算结果文件。
时间。
参考计算时间，输入文件较大且有较多的计算时，要拆分成多个计算单元，用空间换
离线计算原子控制
仅供非商业用途或交流学习使用
第6章大规模数据离线计算分析
103
以
---
## Page 131
介绍了离线计算的相关技术。
简单介绍了在离线计算方面如何处理数据倾斜问题。本章最后通过微博广告的大数据整体架构，
6.4
题
量系统架构示意图如图6-10所示。
数据按时计算完成上，如果没有按时计算完成，数据的价值就会大打折扣。微博广告的数据质
同一个指标在同一口径下，对于不同的数据源或不同的表计算，量级是一样的。及时性表现在
确性。比如订单金额字段是不可能为负值的，如果为负值，则说明不满足准确性。
104
本章重点介绍了 MapReduce 在离线计算上的架构设计原理、执行流程和编程模型，同时还
数据质量系统是微博广告数据仓库的一把利剑，它有效地解决了数据仓库中数据质量的问
〇质量监控模块：数据采集算子将所采集的数据存入Graphite，数据用Grafana可视化展
O
本章小结
质量报警模块：启动 Zabbix的 Trigger 模块，根据报警阈值比较数据，触发报警。
智能运维：从O搭建大规模分布式AIOps系统
示出来。
监控数据收集计算模块：跨表采集或单表采集数据的记录数、字段长度数、空值、主
监控配置管理模块：添加管理监控的条目，配置报警阈值，删除或修改监控条目。
键重复、枚举值、连续值等监控数据，并将数据存储在HDFS上。
ETL计算D
ETL计算C
ETL计算B
ETL计算A
计算调度管理平台
ETL计算G
ETL计算E
图6-10数据质量系统架构示意图
仅供非商业用途或交流学习使用
Grdfana
Graphite
监控条目管理
可视化
控模块
质量监
ZZabbix
一致性是指
---
## Page 132
MapReduceTutorial.html
械工业出版社，2003年6月
6.5
[5] https://en. wikipedia.org/wiki/Fallacies_of_distributed_computing
[3] http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/
[1] Dale Dougberty,Arnold Robbins 著．张旭东，杨作梅，田丽华等译.Sed与 awk.北京：机
[4]https://www.chrisstucchio.com/blog/2013/hadoop_hatred.html
[2]http://pandas.pydata.org/pandas-docs/stable/10min.html
参考文献
仅供非商业用途或交流学习使用
第6章大规模数据离线计算分析
105
---
## Page 133
是基础。
小数据在各个分布式节点发送的频率；端是数据实时性降低了。实时流计算对于实时流来说
例如 Spark Streaming，在特定的时间窗口进行计算。这个时间窗口可以提高数据的吞吐量，减
7.1.1如何提高实时流计算的实时性
7.1关于实时流计算
时流处理的横向扩展及吞吐量提出了很高的要求。
量不是恒定的，如微博的热门事件会突然让流量翻倍，这些流量是没法预估的。因此，这对实
有办法达到实时流的实时性要求的。目前大型互联网公司的流量都是海量的，而且数据流的流
百亿级数据是不太现实的。对于早先使用Hadoop MR 通过配置调度计算离线小批量的数据是没
负反馈等信息进行及时的反馈，这时就需要流式计算。
极其重要的。例如，用户在浏览微博时插入了Feed广告，我们需要对所插入广告的曝光、互动、
算处理的业务特点是数据的价值随着时间的流逝而降低，所以提高数据的处理速度及实时性是
从大量的数据中获取可用的信息，通过实时推荐及计算来获取目标数据而兴起的技术。流式计
实时计算框架
实时流计算数据一般是通过消息中间件源源不断地传输到计算引擎的。对于计算引擎来说，
针对海量的数据，要做到具有很高的实时性。但是对于传统的数据，直接录入几十亿、上
实时流计算就是近几年由于数据被广泛重视，在金融、广告、网络监控等行业需要实时地
仅供非商业用途或交流学习使用
---
## Page 134
如图7-2所示。
上应用高级操作来创建。在内部，DStream 表示为一系列 RDD。Spark Streaming 数据处理过程
DStream可以通过Kafka、Flume和Kinesis等来源的输入数据流创建，也可以通过在其他DStream
中。还可以进行机器学习、图计算等数据处理。Spark Streaming 处理数据流图如图 7-1 所示。
和 window 等高级函数进行复杂的计算处理，最后将计算结果保存到文件系统、数据库等存储
流处理。可以从 Kafka、Socket、Flume 数据源获取数据，然后对数据采用 map、reduce、join
7.2.1
7.2
对于实时流计算结果的响应是至关重要的。
储，都是实时流计算需要考虑的，存储的吞吐量也需要评估。存储写入吞吐量和查询响应速度
7.1.3
解也是相当重要的。抛开业务，集群故障等容错能力对于计算也是很重要的。
时间选择对数据计算结果的准确性有很大的影响。当然，实时流计算结果的准确性对于业务理
准确呢？实时流有三种时间选择：数据进入计算引擎的时间、数据产生的时间和日志的时间。
7.1.2
Spark Streaming 提供了一个高层抽象，称为离散流或 DStream，它表示连续的数据流。
Spark Streaming"是 Spark 核心 API 的一个扩展，可以实现高吞吐量、具有容错机制的实时
实时流计算结果如何快速响应、计算结果是时序值还是聚合值、大量的秒级时序值如何存
实时流计算结果的准确性是整个实时流计算的核心。那么如何处理数据才能让计算结果更
SparkStreaming计算框架介绍
如何提高实时流计算结果的响应速度
概述
如何提高实时流计算结果的准确性
图7-1Spark Streaming 处理数据流图（图片来源于Spark官网l)
Twitter
HDFS/S3
Kinesis
Flume
Kafka
仅供非商业用途或交流学习使用
Streaming
Dashboards
第7章实时计算框架
Databases
HDFS
107
---
## Page 135
结果保存到外部文件系统或数据库中。
数据源（如 Kafka、Flume 和 TCP套接字）进行类似 Map、Reduce 和 Join 等复杂的操作，并将
7.2.3
时间片是在 StreamingContext 中进行设置的。
时间切片将微小的批处理数据连续起来的实时数据。
称作RDD。
生或者通过计算转化后的数据流得到。DStream 由一段连续的分布式弹性数据集组成，这里被
要初始化 Spark Streaming 程序，必须创建一个 StreamingContext 对象。
7.2.2
map 数据都可以看作是 RDD。
件计算是一个 RDD，结果集也是一个 RDD，不同的分片、数据之间的依赖、key-value 类型的
而言，RDD 可以看作是Spark的一个对象，它本身运行于内存中，如读文件是一个RDD，对文
（如 Map、Join 和 Group By）而创建。然而，这些限制使得实现容错的开销很低。对于开发者
享内存模型，即 RDD 是只读的记录分区的集合，只能通过在其他 RDD 中执行确定的转换操作
108
Spark Streaming 是一个对实时数据流进行高通量、容错处理的流式处理系统，可以对多种
window length：时间窗口的长度，它必须是时间片的整数倍。
batch interval：时间片的大小，每一个时间片就是一组 RDD，对RDD 只能进行转换操作。
batch data：Spark Streaming 并非严格意义上的实时流，属于微批处理，它是按照一定的
DStream：Spark Streaming 抽象的数据集，代表源源不断的数据流。数据流通过数据源产
StreamingContext:StreamingContext 对象，它是所有 Spark Streaming 功能的主要入口点，
RDD（弹性分布式数据集）是分布式内存的一个抽象概念。RDD 提供了一种高度受限的共
智能运维：从O搭建大规模分布式AIOps系统
运行原理
基本概念
stream
input data
图7-2Spark Streaming数据处理过程（图片来源于Spark官网[l)
Streaming
Spark
仅供非商业用途或交流学习使用
inputdata
batches of
Engine