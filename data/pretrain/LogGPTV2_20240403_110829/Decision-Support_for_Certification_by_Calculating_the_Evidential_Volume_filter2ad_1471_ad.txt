Hereby, 100 represents “V”-ranking, 10 represents “I”
ranking. This is an entirely artiﬁcial example, which serves
to illustrate the changes in the EV when requirements are
missing. The ﬁnal weights wij for the requirements above
are then
7 ≈ 0.1429, i = 1, . . . , 7.
Phase P1 : wi,1 = 1
Phase P2 : (0.4,0.4,0.04,0.04,0.04,0.04,0.04).
Phases P3, P4, P5, P6 same as P2.
Phase P7 : (0.625,0.0625,0.0625,0.0625,0.0625,
0.0625,0.0625).
Phase P8 : same as P1.
We have deﬁned a set of indicator values Iij, i =
1, . . . , 7, j = 1, . . . , 8, which are initially all set to 1. Us-
ing the weights αj and wij as deﬁned above, equation (2) is
Table 2. Results from calculation of EV.
Type of req. Quantity missing
missing (V,I)
I
V
I
V
I
V
V
1
1
3
1
10
2 (different
phases)
2 (same
phase)
EV
0.99
0.94
0.91
0.89
0.88
0.81
used to compile Iij and wij into EVj, j = 1, . . . , 8. Equa-
tion (3) is then used to compile EVj and αj into the overall
EV. When all requirements are assumed to be met, i.e. Iij =
1, i = 1, . . . , 7, j = 1, . . . , 8, then EVj = 1, j = 1, . . . , 8
and EV=1. Table 2 above shows results for the overall EV
when a selection of requirements is assumed to be not met,
i.e. the evidence is not ticked off by the assessor and thus
its corresponding indicator Iij set to 0. We see that the neg-
ligeance of one very important technique can already lead
to a decrease of the overall EV by 6% and - using Table 1
above - this would lead to a decrease of P success from the
assumed 99% for a product with a complete set of certiﬁca-
tion evidence down to 78%, 70% or even 62% depending on
which SIL or IT the above set of requirements would per-
tain to. The overall EV in the example above is inﬂuenced
by the weight of missing evidence and its spread, i.e. two
“V” requirements missing from the same phase have more
impact than two “V”s missing from two different phases.
Such example calculations serve to illustrate some cha-
racteristics of EVA as a basis for discussion and improve-
ment of the approach. Through the discussion of such ex-
ample scenarios with experts it can be revealed whether the
model is suitable to represent expert belief about the de-
crease in conﬁdence resulting from missing evidence and
where the model needs to be revised.
4.2 Which value of P success is acceptable?
There is no straightforward answer to this question. A
possibility would be to create a utility function and calculate
the utility or risk of acceptance and rejection of the product
given the P success achieved.
If the utility of acceptance
is greater than that of rejection, the product should be ac-
cepted. Let U OK
accept be the utility of accepting a product
that indeed meets the safety integrity target. Let U N O
accept be
the (negative) utility of accepting a product that is not safe
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:30:50 UTC from IEEE Xplore.  Restrictions apply. 
enough. Then
U tility[accept] = U OK
accept·P success+U N O
accept·(1−P success)
is the utility of deciding for acceptance. Similarly
U tility[reject] = U OK
reject·P success+U N O
reject·(1−P success)
is the utility of rejecting the product with U OK
reject being
the cost of unnecessarily rejecting a product that meets the
safety integrity target and U N O
reject being the utility of right-
fully rejecting an unsafe product.
It also seems possible to use a database of “old” assess-
ment outcomes to decide on a suitable cut–off point. As-
sessment scenarios for which an acceptance decision was
made and for which the product consequently used success-
fully in real-life would be considered as benchmark. The
EV for these scenarios would be calculated and this would
be used as a guideline for what constitutes an acceptable
EV.
4.3 What if the EV is not suﬃcient?
In the case where acceptance based on certiﬁcation evi-
dence is not an option due to EV not yielding high enough
utility of acceptance, one might consider to complement
certiﬁcation evidence with alternative evidence such as sta-
tistical testing. To achieve this, the conﬁdence in the pro-
duct pfd based on assessment, P success, would be used to
build a prior belief distribution on the pfd, which would then
be updated with the results of statistical testing, see also
[10] or [3].
5 Summary
In this paper we have described a model to capture the
degree of compliance of a product with a functional safety
standard. The degree of compliance achieved is measured
through the evidential volume (EV). We have described the
model on the example of IEC 61508, however it can easily
be applied to other standards. The approach introduced in
this paper has two main uses.
1. Theapproachcanbeusedstand-alonetocalculatethe
degreeofcompliancewithastandardandthusdescribe
thecharacteroftheoverallpictureofevidenceseen.
When certifying a system, expert judgement is used:
based on the evidence provided, an assessor makes the
decision whether or not to accept a product. This is
a binary process: accept or reject. In the case where
each requirement has been demonstrably met, the de-
cision for acceptance seems obvious. However, there
are cases where not all expected evidence is available,
maybe because it was replaced or compensated for by
alternative evidence or a technique wasn’t documented
or simply not applied. For these cases the decision will
be less clear. It is such cases that seem to beneﬁt from
decision-support because decisions here are based on
subjective individual judgement and individual expe-
riences that cannot easily be replicated or transferred
between scenarios. Thus inconsistencies in decision-
making can arise. The degree of compliance calcu-
lated with the approach presented here, can provide a
decision-aid to an assessor or regulator.
2. Theapproachcanbeusedtomodelthelevelofconﬁ-
denceinhavingaachievedthetargetpfd.
Implementation of the listed and applicable require-
ments of a standard does not guarantee having devel-
loped a component of tolerable failure probability, but
it shows that all reasonable activities to prevent intol-
erably high failure probabilities have been carried out.
Thus we are reasonablyconﬁdentin having achieved a
component of required safety integrity. This is based
on the fact that the standard is a compilation of the
best knowledge and understanding currently available
from experts in the ﬁeld. Thus the assumption that
following a standard supports a reliability claim is an
expression of expert judgement. We believe that the
approach described in this paper helps to capture the
expert belief behind this assumption and translates the
set of observed evidence into a measure of the conﬁ-
dence in the pfd target. This conﬁdence measure can
potentially form input to statistical test procedures.
The model described here poses an initial step towards
decision-support for assessment of safety-related systems
and poses the basis on which experts can start formulating
their prior belief arising from assessment quality. The ad-
vantage of the model suggested here is that the input it re-
quires from an assessor or engineer in the ﬁeld relates to the
natural language used by these experts using accept/reject
statements and rankings of importance partially based on
the recommendation levels in IEC 61508. This enables us
to tap into their expertise in an authentic way.
6 Outlook
The intention of this paper was to introduce the EVA to
the reliability community for discussion and feedback. The
model described needs to be further discussed with a wider
audience in order to be validated as a suitable model for ex-
pert belief. We have started to develop a simple support-tool
that contains the requirements listed in the PES Guidelines
and a set of preliminary weights as discussed in section 3.1.
This development will be further continued. The purpose of
this simple prototype tool is to distribute it to a set of ex-
perts as a basis of discussion of the approach and to demon-
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:30:50 UTC from IEEE Xplore.  Restrictions apply. 
[3] B.A.Gran and G.Dahl, “Estimating dependability of
programmable systems using BBNs,” Lecture Notes
in Computer Science, Safecomp 2000, vol. 1943,
pp. 309–320, 2000.
[4] S. Kuball, B. Guo, J. May, and G. Hughes, “Sys-
tematic safety assessment using Bayesian Belief Net-
works within the IEC 61508 lifecycle,” Report for
the Health and Safety Executive, UK under the SSRC
Generic Programme, 2002.
[5] M. Li, C. Smidts, and R. W. Brill, “Ranking software
engineering measures related to reliability using ex-
pert opinion,” Proceedings of ISSRE 2000, 2000.
[6] H. Dehlinger, “Deontische Fragen, Urteilsbildung,
Bewertungssysteme,” Arbeitsbericht aus dem Fachge-
biet Design Theorien and Methoden, vol. 7/94.
[7] Available from http://www.adelard.co.uk/software/asce.
[8] G. Salvendy, Handbook of Human Factors and Er-
gonomics. Wiley Interscience, 1997.
[9] C. Smidts and D. Sova, “An architectural model for
software reliability quantiﬁcation: sources of data,”
Reliability Engineering and System Safety, vol. 64,
pp. 279–290, 1999.
[10] S. Kuball, G. Hughes, and J. May, “Prior construc-
tion II, certiﬁcation evidence, operational use and
testing,” Deliverable D5 on British Energy Project
PP/40030530, New Development of Dynamic Testing,
2002.
strate how the approach works. This will help to identify
the strengths and limitations and provide useful feedback
on how to take this work further. Working with a tool can
also be useful when discussing the weights in the approach.
Example EV’s for known assessment scenarios can be cal-
culated and the results compared with the actual assessment
decision taken. This can shed some light on suitable choices
of weights. On the longer term, a tool for the calculation of
an EV - based on a set of weights assigned by a panel of
experts from the relevant industry, academia and govern-
ment institutions- might also be beneﬁcial to developers of
safety-critical components to assess the degree of potential
compliance achieved with their product at any stage of the
development cycle in a user-friendly way.
One of the main requirements for this approach is to as-
sign a set of weights for the requirements of a standard. To
propose how to setup a panel of experts is beyond the scope
of the project performed here. This could potentially be
part of a future project. No application to real cases has
been performed yet, it would be desirable to obtain a set
of example assessments, to calculate the EV on these sce-
narios and examine how the results obtained with the EVA
compare to the original assessment decisions.
Acknowledgement:
The authors would like to
acknowledge and thank the staff of British Energy and
the UK Nuclear Installations Inspectorate involved in the
many useful discussions that led to the work presented here.
IPR statement:
The information contained in this report has been
produced for BEG(UK) Ltd. on behalf of the Industry Management Com-
mittee (IMC) thus is the joint property of British Energy Generation Ltd.,
British Energy Generation (UK) Ltd, British Nuclear Fuels Ltd., and their
successor companies. This information is to be held strictly in conﬁdence
by the originators and recipients, unless the contract speciﬁes otherwise.
No disclosure is to be made to a third party without the written agreement
from the nominated ofﬁcer from the company that placed the contract or
their nominated deputy. Further any Intellectual Property Rights arising
from or contained in the report are joint property of British Energy Gen-
eration Ltd., British Energy Generation (UK) Ltd., British Nuclear Fuels
Limited and their successor companies, as such are subject to the same
obligation of conﬁdence on the originator and recipients as set out above
and may only be used in accordance with the contract.
References
[1] “Functional safety of electrical/ electronic/ pro-
grammable electronic safety-related systems, Interna-
tional Electrotechnical Commission,” 1998.
[2] L. Winsborrow and A. Lawrence, “Guidelines for
using Programmable Electronic Systems in nuclear
safety and nuclear safety-related applications,” British
Energy Generations Ltd., 2002.
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:30:50 UTC from IEEE Xplore.  Restrictions apply.