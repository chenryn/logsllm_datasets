crease is an under-estimation. We observe two trends. First,
a larger upload incurs a higher impact on PLT. Second, the
PLT impact also becomes higher as δt increases (for blocks
without “X”). This is because a larger δt allows more time
for the on-device queue to build up, and thus worsens the on-
device bufferbloat condition when the web browsing session
starts.
5.3 Impact on Video Streaming and VoIP
Video Streaming. We randomly chose 10 popular videos
of various lengths (from 40 seconds to 6 minutes) from You-
Tube and played them over LTE on a Samsung Galaxy S3
phone. The playback software is ExoPlayer [2], which uses
the standard DASH streaming algorithm. When the sig-
nal strength is above -98dBm, the average playback bitrate
across 10 videos is 0.93Mbps without any stall when no con-
current trafﬁc is present. With concurrent TCP upload, the
average bitrate is reduced by 57% to only 0.39Mbps, with
15.3 stalls (total stall duration 103s) for each video on av-
erage. Even when periodical upload is in progress (upload
5MB data every with 5s idle time between consecutive up-
loads), half of the videos exhibit playback bitrate degrada-
tion by up to 19%.
VoIP. We make Skype voice calls from a Samsung Galaxy
S3 phone to a desktop in three settings (3 runs each setting):
(i) Skype call only, (ii) Skype call with concurrent TCP up-
load, and (iii) Skype call with periodical TCP upload of 5MB
with 5s idle time between uploads. The experiments were
conducted over Carrier 1’s LTE network. For each call, we
play the same pre-recorded audio (90 seconds) as the base-
line and record the audio at the receiver. To quantify the
 0 0.25 0.5 0.75 1 0 5 10 15 20 25CDFDownload Throughput (Mbps)TCP DL+UDP ULUDP DL+UDP ULTCP DL only#1#2#3#4#5#6#7#8#9#10124816Site #Background uploadsize (MB)XXXXXXXXX124816Background uploadsize (MB)XXXXXXXXXXXXXXXXXXXXXXXXXXXX124816Background uploadsize (MB)XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX 0 50 100 150 200Page Load TimeIncrease (%)310Reducing queuing delay
Qdisc Driver Firmware
()
()
()
()
()
()
Cross-ﬂow
control

Congestion
[19,
Bufferbloat Mitiga-
tion Solution
Change TCP buffer
size
TCP
Control (CC)
12, 11]
TCP Small Queue
(TSQ) [7]
Trafﬁc
tion (TP)
Active
Management
(AQM) [30, 34]
Byte Queue Limit
(BQL) [1]
QCUT
prioritiza-
Queue








Table 2: Summary of solutions for reducing queuing de-
lay for upload trafﬁc. “()” means only limited support.
user experience, we use an existing tool [4] to compute the
PESQ MOS (Perceptual Evaluation of Speech Quality, Mean
Opinion Score) [5] metric. When upload is not present, the
average PESQ MOS score is 4.08. With continuous TCP up-
load, the average PESQ MOS score drops to 1.80. Even for
scenario (iii), the average PESQ MOS score is only 1.77.
6. QCUT: SOLUTION FOR
ON-DEVICE BUFFERBLOAT
Given the severity of on-device bufferbloat, we propose
our solution called QCUT to mitigate it.
6.1
Inadequateness of Existing Solutions
In the literature, numerous solutions have been proposed
to mitigate in-network bufferbloat, and some do work with
on-device buffers. Table 2 lists representative solutions:
changing TCP buffer size, changing TCP congestion con-
trol (CC), TCP Small Queue (TSQ), Trafﬁc Prioritization
(TP), and Active Queue Management (AQM). However,
they all have limitations on reducing on-device queuing de-
lay. Changing TCP buffer size and CC are transport layer so-
lutions that adjust TCP behaviors to reduce the delay. How-
ever, they do not work with buffers below the transport layer;
also they do not provide cross-ﬂow control as each TCP
connection has a separate buffer. TSQ, a newly introduced
Linux kernel patch, only limits the Qdisc occupancy on a
per-connection basis. TP works across ﬂows and improves
user experience by prioritizing delay-sensitive trafﬁc. How-
ever, it only partially reduces the queuing delay as will be
evaluated in §7.1. The AQM approaches (e.g., CoDel and
PIE) also work across ﬂows. But they do not help reduce
the buffer occupancy at the ﬁrmware buffer.
In §7.1, we
quantitatively compare all above approaches. We also show
that jointly applying them may further incur unexpected con-
ﬂicts, causing additional performance degradation.
We emphasize that none of the above solutions can be re-
Figure 13: The QCut design.
alized at the ﬁrmware buffer, which is usually proprietary
hardware making it difﬁcult to incorporate different queue
management algorithms. As new wireless technologies and
radio chipsets emerge (e.g., 5G and IoT devices), modiﬁca-
tion to all ﬁrmware to solve the on-device queuing is imprac-
tical. Also, as shown in §4.2, the cellular ﬁrmware buffer
differs from upper-layer buffers in that it plays a role in the
cellular control plane (i.e., the BSR affects uplink scheduling
and the LTE uplink throughput). Therefore, even ignoring
the implementation issues, naïvely applying existing buffer-
bloat mitigation solutions on the ﬁrmware buffer may lead
to unexpected results or performance degradation.
6.2 QCUT Design
Motivated by the above, we designed and implemented a
new approach called QCUT to reduce the on-device queu-
ing delay. Here we focus on optimizing cellular uplink but
the general concept of QCUT applies to other networks. As
illustrated in Figure 13, QCUT has three prominent features.
• Realized as a general OS service, QCUT is independent of
ﬁrmware implementation. Therefore it can address the on-
device queuing problem on any radio ﬁrmware, where no
modiﬁcation is needed. QCUT operates in the kernel space
and takes as input only information of buffer occupancy and
transmission statistics, which is exposed by most cellular ra-
dio ﬁrmware from Qualcomm and likely other vendors.
• Since directly limiting the ﬁrmware buffer occupancy is
difﬁcult, QCUT controls the ﬁrmware queuing delay indi-
rectly in the kernel by controlling how fast packets from
Qdisc ﬂow into the ﬁrmware buffer. QCUT estimates the ra-
dio ﬁrmware buffer occupancy and queuing delay to decide
the transmission of packets to the ﬁrmware dynamically.
• QCUT is ﬂexible on trafﬁc classiﬁcation and prioritiza-
tion. By (indirectly) limiting the amount of data in the
ﬁrmware, packets are queued in the Linux Qdisc, where
QCUT can ﬂexibly prioritize packets based on the applica-
tion requirements. For example, when background upload
and interactive trafﬁc co-exist, the latter can be prioritized
and transmitted without Qdisc queuing. By contrast, directly
realizing ﬁne-grained trafﬁc prioritization in the ﬁrmware is
impractical and inﬂexible.
QCUT aims at reducing the on-device queuing delay.
When there is no on-device queuing, QCUT does not incur
additional delay to RT TB or other runtime overhead.
KernelCellular FirmwareQCutTraffic ShapingTraffic DifferentiationThroughput EstimationBuffer EstimationPrioriti-zationClassifi-cationScheduling GrantPadding StatisticsMAC & PHY TXCPBuffer Status ReportFrom eNBTo eNBQdisc311(a) Signal strength -110dBm
(b) Signal strength -98dBm
(c) Signal strength -85dBm
Figure 14: Uplink throughput
prediction error at different lay-
ers with 20ms prediction interval.
Figure 15: Impact of ﬁrmware buffer occupancy threshold of QCUT-B.
The best threshold in each plot is in bold blue text.
As shown in Figure 13, QCUT comprises of two compo-
nents: trafﬁc differentiation and trafﬁc shaping. Trafﬁc dif-
ferentiation classiﬁes packets from applications, and prior-
itizes certain trafﬁc in the Qdisc (e.g., delay-sensitive traf-
ﬁc) based on applications’ requirement. The trafﬁc shaping
module (i) performs accurate throughput prediction, which
is then used to (ii) estimate the buffer occupancy in the
ﬁrmware. Based on that, the module (iii) controls how fast
packets from Qdisc ﬂow into the ﬁrmware buffer, in order
to limit the ﬁrmware buffer occupancy. We describe each
component in details below.
Achievable physical
layer throughput prediction.
Based on recent lower-layer throughput values measured
from scheduling grant and padding (§4.4), we perform
throughput prediction using Exponentially Weighted Mov-
ing Average (EWMA) with α = 0.25 (empirically cho-
sen). The prediction interval is 20ms. Note that we need
to predict the throughput because the lower-layer ﬁrmware
information is not provided in real time so the through-
put measurement is delayed, as we explain shortly. The
“ﬁrmware” curve in Figure 14 plots the prediction error dis-
tributions under 20ms prediction interval, in our controlled
bulk upload experiments with -95dBm RSRP (8Mbps uplink
bandwidth). The ground truth is the lower-layer through-
put measured with a delay (∼100ms later). The results in-
dicate that compared to other curves in Figure 14 where
we perform throughput estimation at higher layers using the
same EWMA algorithm, using lower-layer information for
throughput prediction is much more accurate.
Buffer occupancy estimation. For a wide range of cel-
lular ﬁrmware, their buffer occupancy level can be directly
read from the buffer status report (BSR). However, a practi-
cal issue we found is that, BSR is not reported in real time to
allow accurate buffer occupancy estimation. On both Sam-
sung Galaxy S3 and Nexus 5 devices, although BSR is re-
ported to eNodeB every 5ms, there is on average around
100ms delay before this information is reported to the kernel
due to various overheads. During this period, the ﬁrmware
buffer dynamics may ﬂuctuate considerably.
To overcome this issue, we propose to combine the BSR
and the predicted throughput to derive accurate ﬁrmware
buffer occupancy. The basic idea is the following: since we
Figure 16: Radio ﬁrmware buffer occupancy estimation.
know both the accurate enqueue rate (measured from Qdisc)
and dequeue rate (from uplink throughput) of the ﬁrmware
buffer, we can use them to reﬁne the rough buffer occupancy
estimation from delayed BSR. More speciﬁcally, let S0 be
the most recently reported BSR generated by the ﬁrmware
at t0, which can be obtained from a BSR’s timestamp ﬁeld.
Let Ruplink be the predicted uplink throughput at t0. Also
we keep track of packets {Pi} (i=1,2,...) leaving Qdisc after
t0 by recording their sizes {Si} and timestamps {ti} of leav-
ing Qdisc. Given the above information, the ﬁrmware buffer
occupancy B(tcurr) at timestamp tcurr can be calculated as
follows:
B(tcurr) = B(tn+1)
B(ti+1) = B(ti) + Si+1 − ST X (i), i ∈ [0, n]
(1)
(2)
(3)
ST X (i) = min(B(ti), Ruplink × (ti+1 − ti)), i ∈ [0, n];
where t0 < t1 < .. < tn ≤ tn+1 = tcurr, Sn+1 = 0.
The buffer occupancy is estimated in an iterative manner
as shown in Equation (2), where Si+1 and ST X (i) are the
number of bytes enter and leave the ﬁrmware buffer since ti,
respectively. ST X (i) is computed in Equation (3) using the
predicted throughput. The process is illustrated in Figure 16.
Qdisc dequeue control. QCUT limits the queuing de-
lay in the radio ﬁrmware by throttling the Qdisc in the ker-
nel, i.e., strategically controlling whether a packet should
 0 0.25 0.5 0.75 1-100-50 0 50 100CDFEstimation error (%)AppTCPQdiscFirmware 0 0.5 1 1.5 60 1000 2000 3000 4000BetterUplink throughput(Mbps)RTTF (ms)2KB5KB10KB20KB50KB100KBNo limit 0 5 60 200 350 500BetterUplink throughput(Mbps)RTTF (ms)2KB5KB10KB20KB50KB100KBNo limit 0 5 10 15 60 120 200 280Uplink throughput(Mbps)RTTF (ms)2KB5KB10KB20KB50KB100KBNo limitBettertRadio firmware bufferoccupancy B(t)Timestamp of most recent BSRCurrent timestampPackets transmitted from Linux QdiscEstimatedBufferOccupancyt0tcurr=tn+1tnt1tiSi+1STX(i)312be dequeued from Qdisc into the radio ﬁrmware. To re-
alize this, a simple way is to use a ﬁxed threshold of the
ﬁrmware buffer occupancy, which we refer as QCUT-B (B
stands for “bytes”). We evaluated this approach by repeat-
ing one-minute TCP uploads ﬁve times with different thresh-
olds on a Nexus 5 phone using Carrier 1’s LTE network,
under different signal strength conditions. As shown in Fig-
ure 15, different QCUT-B thresholds incur different trade-
offs between throughput and latency (quantiﬁed by RT TF ).
However, it is difﬁcult to ﬁnd a threshold that works for all
network conditions. The best threshold that achieves low
latency without sacriﬁcing the throughput depends on the
signal strength: 2KB for -110dBm, 20KB for -98dBm, and
In particular, a small threshold (e.g.,
50KB for -85dBm.
2KB) works well when the signal strength is low. However,
at high signal strength, it causes bandwidth under-utilization.