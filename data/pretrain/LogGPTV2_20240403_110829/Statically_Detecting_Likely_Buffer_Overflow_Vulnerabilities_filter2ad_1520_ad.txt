requires maxSet(t @ 2:2) >= 0.  The increment on line 1 
produces the constraint ensures (t@1:4) = (t@1:1) + 1.  
The increment constraint is substituted into the maxSet 
constraint to produce requires maxSet (t@1:1 + 1) >= 0.  
Using  the  constraint-specific  simplification  rule,  this 
simplifies  to  requires  maxSet  (t@1:1)  -  1  >=  0  which 
further simplifies to requires maxSet(t @ 1:1) >= 1. 
6.  Control Flow 
Statements  involving  control  flow  such  as  while  and 
for  loops  and  if  statements,  require  more  complex 
analysis than simple statement lists.  For if statements 
and  loops,  the  predicate  often  provides  a  guard  that 
makes  a  possibly  unsafe  operation  safe.    In  order  to 
analyze  such  constructs  well,  LCLint  must  take  into 
account  the  value  of  the  predicate  on  different  code 
paths.  For each predicate, LCLint generates three lists 
of  postcondition constraints: those that hold regardless 
of the truth value of the predicate, those that hold when 
the predicate evaluates to true, and those that hold when 
the predicate evaluates to false.   
To analyze an if statement, we develop branch specific 
guards  based  on  our  analysis  of  the  predicate  and  use 
these guards to resolve constraints within the body.  For 
example, in the statement  
   if (sizeof (s1) > strlen (s2))
strcpy(s1, s2); 
that 
if s1 is a fixed-size array, sizeof (s1) will be equal 
to maxSet(s1) + 1.  Thus the if predicate allows LCLint 
to  determine 
the  constraint  maxSet(s1)  >= 
maxRead(s2) holds on the true branch.  Based on this 
constraint LCLint determines that the call to strcpy is 
safe. 
Looping  constructs  present  additional  problems.  
Previous  versions  of  LCLint  made 
a  gross 
simplification  of  loop  behavior:  all  for  and  while 
loops in the program were analyzed as though the body 
executed  either  zero  or  one  times.    Although  this  is 
clearly  a  ridiculous  assumption,  it  worked  surprisingly 
well for the types of analyses done by LCLint.  For the 
buffer  overflow  analyses,  this  simplified  view  of  loop 
semantics  does  not  provide  satisfactory  results  –  to 
determine  whether  buf[i] 
is  a  potential  buffer 
overflow, we need to know the range of values  i may 
represent.    Analyzing  the  loop  as  though  its  body 
executed  only  once  would  not  provide  enough 
information about the possible values of i. 
In  a  typical  program  verifier,  loops  are  handled  by 
requiring  programmers  to  provide  loop  invariants.  
Despite  considerable  effort  [Wegbreit75,  Cousot77, 
Collins88,  IS97,  DLNS98,  SI98],  no  one  has yet been 
able  to  produce  tools  that  generate  suitable  loop 
invariants  automatically.    Some  promising  work  has 
been  done  towards  discovering  likely  invariants  by 
executing  programs  [ECGN99],  but  these  techniques 
require well-constructed test suites and many problems 
remain before this could be used to produce the kinds of 
loop invariants we need.  Typical programmers are not 
able  or  willing  to  annotate  their  code  with  loop 
invariants,  so  for  LCLint  to  be  effective  we  needed  a 
method  for  handling  loops  that  produces  better  results 
than  our  previous  gross simplification method, but did 
not require expensive analyses or programmer-supplied 
loop invariants.  
Our solution is to take advantage of the idioms used by 
typical C programmers.  Rather than attempt to handle 
all  possible  loops  in  a  general  way,  we  observe  that  a 
large  fraction  of  the  loops  in  most  C  programs  are 
written in a stylized and structured way.  Hence, we can 
develop  heuristics  for  identifying  and  analyzing  loops 
that  match  certain  common  idioms.    When  a  loop 
matches  a  known  idiom,  corresponding  heuristics  can 
be  used  to  guess  how  many  times  the  loop  body  will 
execute.    This  information  is  used  to  add  additional 
preconditions to the loop body that constrain the values 
of variables inside the loop.   
To  further  simplify  the  analysis,  we  assume  that  any 
buffer overflow that occurs in the loop will be apparent 
in either the first or last iterations.  This is a reasonable 
assumption in almost all cases, since it would be quite 
rare for a program to contain a loop where the extreme 
values  of  loop  variables  were  not  on  the  first  and  last 
iterations.  This allows simpler and more efficient loop 
checking. To analyze the first iteration of the loop, we 
treat the loop as an if statement and use the techniques 
described above.  To analyze the last iteration we use a 
series  of  heuristics  to  determine  the  number  of  loop 
iterations  and  generate  additional  constraints  based  on 
this analysis. 
An example loop heuristic analyzes loops of the form 
for (index = 0; expr; index++) body
where  the  body  and  expr  do  not  modify  the  index 
variable and body does not contain a statement (e.g., a 
break) that could interfere with normal loop execution.  
Analyses performed by the original LCLint are used to 
aid  loop  heuristic  pattern  matching.    For  example,  we 
use  LCLint’s  modification  analyses  to  determine  that 
the loop body does not modify the index variable. 
For  a  loop  that  matches  this  idiom,  it  is  reasonable  to 
assume that the number of iterations can be determined 
solely from the loop predicate.   As with if statements, 
we  generate  three  lists  of  postcondition constraints for 
the loop test.  We determine the terminating condition 
of  the  loop  by  examining  the  list  of  postcondition 
constraints  that  apply  specifically  to  the  true  branch.  
Within these constraints, we look for constraints of the 
form  index  <=  e.    For  each  of  these  constraints,  we 
search  the  increment  part  of  the  loop  header  for 
constraints matching the form index = index + 1.  If we 
find a constraint of this form, we assume the loop runs 
for e iterations. 
Of course, many loops that match this heuristic will not 
execute for e iterations. Changes to global state or other 
variables in the loop body could affect the value of  e.  
Hence, our analysis is not sound or complete.  For the 
programs  we  have  tried  so  far,  we  have  found  this 
heuristic works correctly. 
Abstract  syntax  trees  for  loops  are  converted  to  a 
canonical form to increase their chances of matching a 
known  heuristic.    After  canonicalization,  this  loop 
pattern  matches  a  surprisingly  high  number  of  cases.  
For example, in the loop  
   for (i = 0; buffer[i]; i++) body  
the postconditions of the loop predicate when the body 
executes  would  include  the  constraint  ensures  i < 
maxRead(buffer).    This  would  match  the  pattern  so 
LCLint  could  determine  that  the  loop  executes  for 
maxRead(buffer) iterations. 
Several  other  heuristics  are  used  to  match  other 
common  loop  idioms  used  in  C  programs.    We  can 
generalize  the  first  heuristic  to  cases  where  the  initial 
index  value  is  not  known.    If  LCLint  can  calculate  a 
reasonable upper bound on the number of iterations (for 
example,  if  we  can  determine  that  the  initial  value  of 
the  index  is  always  non-negative),  it  can  determine  an 
upper bound on the number of loop iterations.  This can 
generate  false  positives  if  LCLint  overestimates  the 
actual  number  of  loop  iterations,  but  usually  gives  a 
good enough approximation for our purposes. 
Another  heuristic  recognizes  a  common  loop  form  in 
which a loop increments and tests a pointer.  Typically, 
these loops match the pattern: 
   for (init; *buf; buf++)
A heuristic detects this loop form and assumes that loop 
executes for maxRead(buf) iterations. 
After estimating the number of loop iterations, we use a 
series  of  heuristics  to  generate  reasonable  constraints 
for the last iteration.  To do this, we calculate the value 
of  each  variable  in  the  last  iteration.    If  a  variable  is 
incremented  in  the  loop,  we  estimate  that  in  the  last 
iteration the variable is the sum of the number of loop 
iterations  and  the  value  of  the  variable  in  the  first 
iteration.  For the loop to be safe, all loop preconditions 
involving  the  variable  must  be  satisfied  for  the  values 
of the variable in both the first and last iterations.  This 
heuristic gives satisfactory results in many cases. 
Our  heuristics  were  initially  developed  based  on  our 
analysis of wu-ftpd.  We found that our heuristics were 
effective for BIND also.  To handle BIND, a few addi-
tional  heuristics  were  added.    In  particular,  BIND  fre-
quently  used  comparisons  of  pointer  addresses  to 
ensure  a  memory  accesses  is  safe.    Without  an  appro-
priate  heuristic,  LCLint  generated  spurious  warnings 
for  these  cases.    We  added  appropriate  heuristics  to 
handle  these  situations  correctly.    While  we  expect 
experience with additional programs would lead to the 
addition  of  new  loop  heuristics,  it  is  encouraging  that 
only a few additional heuristics were needed to analyze 
BIND.  
Although no collection of loop heuristics will be able to 
correctly  analyze  all 
in  C  programs,  our 
experience so far indicates that a small number of loop 
heuristics  can  be  used  to  correctly  analyze  most  loops 
in  typical  C  programs.    This  is  not  as  surprising  as  it 
might  seem  –  most  programmers  learn  to  code  loops 
from  reading  examples  in  standard  texts  or  other 
people’s code.  A few simple loop idioms are sufficient 
for programming many computations. 
loops 
7.  Related Work 
In Section 2, we described run-time approaches to the 
buffer overflow problem.  In this section, we compare 
our work to other work on static analysis.   
It is possible to find some program flaws using lexical 
analysis  alone.    Unix  grep  is  often  used  to  perform  a 
crude  analysis  by  searching  for  potentially  unsafe 
library  function  calls.    ITS4  is  a  lexical  analysis  tool 
that searches for security problems using a database of 
potentially  dangerous  constructs  [VBKM00].    Lexical 
analysis techniques are fast and simple, but their power 
is  very  limited  since they do not take into account the 
syntax or semantics of the program. 
More precise checking requires a deeper analysis of the 
program.  Our work builds upon considerable work on 
constraint-based  analysis  techniques. 
  We  do  not 
attempt  to  summarize  foundational  work  here.    For  a 
summary see [Aiken99].   
Proof-carrying  code  [NL  96,  Necula97]  is  a  technique 
where  a  proof  is  distributed  with  an  executable  and  a 
verifier checks the proof guarantees the executable has 
certain  properties.    Proof-carrying  code  has  been  used 
to  enforce  safety  policies  constraining  readable  and 
writeable memory locations.  Automatic construction of 
proofs  of  memory  safety  for  programs  written  in  an 
unsafe 
current 
capabilities. 
Wagner,  et  al.  have  developed  a  system  to  statically 
detect  buffer  overflows  in  C  [WFBA00,  Wagner00].  
They used their tool effectively to find both known and 
unknown buffer overflow vulnerabilities in a version of 
sendmail.  Their approach formulates the problem as an 
integer range analysis problem by treating C strings as 
an abstract type accessed through library functions and 
modeling  pointers  as  integer  ranges  for  allocated  size 
language,  however, 
is  beyond 
that 
involving  strings. 
and  length.    A  consequence  of  modeling  strings  as  an 
abstract  data  type  is  that  buffer  overflows  involving 
non-character buffers cannot be detected.  Their system 
generates  constraints  similar  to  those  generated  by 
LCLint  for  operations 
  These 
constraints  are  not  generated  from  annotations,  but 
constraints for standard library functions are built in to 
the tool.  Flow insensitive analysis is used to resolve the 
constraints.    Without  the  localization  provided  by 
annotations, it was believed that flow sensitive analyses 
would  not  scale  well  enough  to  handle  real  programs.  
Flow  insensitive  analysis  is  less  accurate and does not 
allow special handling of loops or if statements. 
Dor,  Rodeh  and  Sagiv  have  developed  a  system  that 
detects  unsafe  string  operations 
in  C  programs 
[DRS01].    Their  system  performs  a  source-to-source 
transformation 
instruments  a  program  with 
additional  variables  that  describe  string  attributes  and 
contains assert statements that check for unsafe string 
operations.  The instrumented program is then analyzed 
statically  using  integer  analysis  to  determine  possible 
assertion  failures.    This  approach  can  handle  many 
complex  properties  such  as  overlapping  pointers.  
However, in the worst case the number of variables in 
the instrumented program is quadratic in the number of 
variables in the original program.  To date, it has only 
been used on small example programs. 
A few tools have been developed to detect array bounds 
errors  in  languages  other  than  C.    John  McHugh 
developed  a  verification  system  that  detects  array 
bounds  errors  in  the  Gypsy  language  [McHugh84].  
Extended  Static  Checking  uses  an  automatic  theorem-
prover to detect array index bounds errors in Modula-3 
and  Java  [DLNS98].    Extended  Static  Checking  uses 
information 
checking.  
Detecting array bounds errors in C programs is harder 
than for Modula-3 or Java, since those languages do not 
provide pointer arithmetic.  
assist 
in 
annotations 
to 
8.  Conclusions 