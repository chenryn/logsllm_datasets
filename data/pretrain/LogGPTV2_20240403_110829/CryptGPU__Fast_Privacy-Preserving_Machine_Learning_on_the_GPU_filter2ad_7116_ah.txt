DELPHI [4] use a smaller number of bits of ﬁxed-point
precision (e.g., 13 bits and 15 bits, respectively). In turn,
they are able to work with arithmetic shares over a 32-bit
ring as opposed to a 64-bit ring. This reduces communication
(since shares are half as large) and in our model, also saves
computation (recall from Section II-B that we need to split up
tensors of 64-bit integers into 4 tensors of 16-bit integers in
order to use existing CUDA kernels for deep learning).
Using fewer number of bits of precision reduces the accuracy
of the protocol outputs, especially when scaling to deep
architectures and large inputs. To analyze the effect the number
of bits of ﬁxed-point precision t has on the accuracy of the
outputs of our system (i.e., the values of the output layer), we
compute the average relative error between the output values
output by CRYPTGPU to those computed using the plaintext
inference protocol on a small example (AlexNet over CIFAR-
10) as well as a large example (ResNet-50 on ImageNet). Our
results are summarized in Fig. 3.
Fig. 3 shows that for a relatively shallow model like AlexNet
on the CIFAR-10 dataset, it is sufﬁcient to use 12 to 14 bits
of ﬁxed-point precision (i.e., the parameter setting in [6]). The
relative error in this case between the outputs computed by
the private inference protocol and the plaintext computation
is around 1%. However, when we scale up to a model like
ResNet-50 on ImageNet, the average relative error in the model
outputs increases 5× to almost 5%. We further remark that we
are only measuring the relative error in a single forward pass
over the network (inference). Larger errors would be expected
in the case of private training when the protocol needs to run
multiple forward and backward passes. In this work, we use
t = 20 bits of ﬁxed-point precision which ensures that the
average relative error for private inference over ResNet-50 on
ImageNet is under 0.02%. Our analysis indicates that scaling up
to deeper architectures and operating over larger datasets will
require a greater number of bits of precision in the underlying
ﬁxed-point representation. For instance, to keep the average
100
10
1
0.1
0.01
)
%
(
r
o
r
r
E
e
v
i
t
a
l
e
R
e
g
a
r
e
v
A
AlexNet, CIFAR-10
ResNet-50, ImageNet
10
12
14
16
18
20
Bits of Fixed-Point Precision t
Fig. 3: Average relative error between the model outputs
computed using the private inference protocol in CRYPTGPU
with t bits of ﬁxed-point precision (i.e., an integer x ∈ R is
represented as the nearest integer to x · 2t) and the output
computed using plaintext ﬂoating-point inference. Analysis
based on evaluating AlexNet on CIFAR-10 and ResNet-50 on
ImageNet, and averaged over 10 randomly-chosen instances.
relative error under 1% for ResNet-50 on ImageNet, we require
at least 15 bits of ﬁxed-point precision. As such, to prevent
overﬂows in the arithmetic evaluation over secret-shared data
for deep networks, a 32-bit ring is no longer sufﬁcient.
Privacy-preserving inference. To evaluate the accuracy of our
private inference protocol, we compare the average relative
error between the outputs of our private inference protocol
using ResNet-50, ResNet-101, and ResNet-152 on ImageNet
and compare those against the values obtained from plaintext
evaluation. We additionally compute the accuracy of the
predictions (using the standard metrics of Top-1 and Top-5
accuracy—i.e., the model succeeds if the actual class of an
example coincides with the most likely class predicted by the
model or among the top 5 most likely classes predicted by the
model). The results are summarized in Table VI. In particular,
for our chosen set of parameters, we observe that the average
relative error in the classiﬁer output is at most 0.021%, and
in all cases we tested (100 randomly-chosen images from the
ImageNet test set), both the Top-1 accuracy and the Top-5
accuracy exactly match that of the plaintext model.
Privacy-preserving training. We perform a similar set of
experiments to evaluate the accuracy of our private training
protocol. In Fig. 4, we plot the value of the cross-entropy
loss function for a model trained using the private training
protocol of CRYPTGPU as well as for a model trained using
the plaintext training algorithm (using the same initialization
and learning rate for the underlying stochastic gradient descent
optimizer). Fig. 4 shows that the value of the loss function
is slightly higher initially for private training, but the overall
progression closely follows that of plaintext training.
In addition to comparing the evolution of the loss function,
we also compare the model accuracies (as measured on the
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:30:25 UTC from IEEE Xplore.  Restrictions apply. 
171037
s
s
o
L
y
p
o
r
t
n
E
s
s
o
r
C
2.5
2.0
1.5
1.0
0.5
0.0
0
CRYPTGPU
Plaintext
2.4
2.2
2.0
1.8
1.6
1.4
1.2
1.0
s
s
o
L
y
p
o
r
t
n
E
s
s
o
r
C
CRYPTGPU
Plaintext
5.5
5.0
4.5
4.0
3.5
s
s
o
L
y
p
o
r
t
n
E
s
s
o
r
C
CRYPTGPU
Plaintext
1,200
600
Number of Iterations
1,800
2,400
0
800
400
Number of Iterations
1,200
1,600
0
1,600
800
Number of Iterations
2,400
3,200
(b) AlexNet on CIFAR-10 (trained for 1 epoch
with a batch size of 32).
(a) LeNet on MNIST (trained for 5 epochs
with a batch size of 128).
Fig. 4: Moving average of the cross-entropy loss as a function of the number of training iterations using CRYPTGPU and using
a plaintext protocol for different models and datasets. In each setting, we use the same initialization and learning rate (for
stochastic gradient descent) for both private and plaintext training. For LeNet, we use a random initialization. For AlexNet, we
use PyTorch’s pre-trained weights. The moving average is computed over a window of size 20 (i.e., the value reported for
iteration i is the average of the cross entropy loss on iterations i − 10, . . . , i + 9).
(c) AlexNet on Tiny ImageNet (trained for 1
epoch on a batch size of 32).
Average Relative Error
Top-1 Accuracy
Top-5 Accuracy
ResNet-50
ResNet-101
ResNet-152
0.015%
0.020%
0.021%
78%
92%
82%
90%
79%
93%
Baseline
CRYPTGPU
LeNet, MNIST*
AlexNet, CIFAR-10†
AlexNet, Tiny ImageNet‡
10%
10%
2%
93.97%
59.60%
17.82%
Plaintext
93.34%
59.77%
17.51%
TABLE VI: Comparison of outputs of CRYPTGPU’s private
inference protocol on ImageNet with the ResNet models with
those of the plaintext computation. The average relative error is
computed between the outputs of the private inference protocol
and those of the plaintext execution (on the same input). The
Top-1 and Top-5 accuracies are computed based on the outputs
of the private inference protocol with respect to the ground
truth label. All measurements are taken over a random set
of 100 examples drawn from the ImageNet test set. In each
setting, the Top-1 and Top-5 accuracies match those computed
using a plaintext execution.
validation set) for the models trained using CRYPTGPU and
using the plaintext training algorithm (again with same initial-
ization and learning rate as above). Our results are summarized
in Table VII. On all of the models/datasets we considered, the
accuracy of the model output by CRYPTGPU closely matches
that of the plaintext evaluation. These experiments indicate
that CRYPTGPU efﬁciently and accurately supports end-to-end
private training for models like AlexNet over moderately-large
datasets like TinyImageNet.
Average pooling vs. max pooling. As discussed in Sec-
tion IV-A, we use average pooling in place of max pooling
in the models we consider. To evaluate whether the choice of
pooling makes a signiﬁcant difference on model performance,
we use PyTorch to train the AlexNet and VGG-16 networks
over the CIFAR-10 dataset where we replace all of the max
pooling layers with average pooling layers. The resulting model
accuracy on the CIFAR-10 test set is shown in Table VIII. In
particular, we observed a 3% drop in accuracy (from 76% to
73%) for AlexNet and a 1% increase in accuracy with VGG-16
*Trained for 5 epochs (2345 iterations) with a batch size of 128.
†Trained for 1 epoch (1563 iterations) with a batch size of 32.
‡Trained for 1 epoch (3125 iterations) with a batch size of 32.
TABLE VII: Validation set accuracy for different models trained
using CRYPTGPU and the plaintext training algorithm. For
each conﬁguration, both training approaches use the same
initialization and learning rate (for stochastic gradient descent).
For LeNet, we use random initialization. For AlexNet, we use
PyTorch’s pre-trained weights to speed up convergence. We
additionally report the baseline accuracy for each conﬁguration
(i.e., accuracy of the “random-guess” algorithm). Note that
training for more iterations will increase the accuracy; the
intent of this comparison is to demonstrate a close similarity in
model accuracies for the the model output by private training
with the model output by plaintext training after a few thousand
iterations of gradient descent.
Max Pooling
Average Pooling
AlexNet
VGG-16
76.15%
82.37%
73.35%
83.17%
TABLE VIII: Validation set accuracy for plaintext training of
AlexNet and VGG-16 over the CIFAR-10 dataset using max
pooling vs. average pooling. All networks were trained using
50 epochs using a standard stochastic gradient descent (SGD)
optimizer in PyTorch.
(from 82% to 83%). This indicates that using average pooling
in place of max pooling does not lead to a signiﬁcant degrading
of model performance. We note also that in contrast to AlexNet
and VGG-16 which use max pooling exclusively, the more
recent ResNets use average pooling in all but the initial layer.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:30:25 UTC from IEEE Xplore.  Restrictions apply. 
181038