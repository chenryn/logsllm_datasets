© Manning Publications Co. To comment go to liveBook
71
column_name = read_on
column_type = TIMESTAMP
min = 2019-01-01 00:00:00
max = 2020-06-26 11:00:00
approx_unique = 50833
avg =
std =
q25 =
q50 =
q75 =
count = 52072
null_percentage = 0.0%
column_name = power
column_type = DECIMAL(10,3)
min = 0.000
max = 47873.333
approx_unique = 6438
avg = 7122.5597121293595
std = 11760.089219586542
q25 = 20
q50 = 27
q75 = 9532
count = 52072
null_percentage = 0.0%
SUMMARIZE works directly on tables, but as shown above, on query results, too. You
don’t even have to ingest data at all before applying SUMMARIZE, it can be run against a
CSV- or Parquet-file as well.
4.3 On sub-queries
Imagine you want to compute the average of the total power produced by the systems
you manage. For that, you would need to apply two aggregate functions, avg and sum. It
turns out, you cannot nest them. Aa naive approach like SELECT avg(sum(kWh)) FROM
v_power_per_day GROUP BY system_id fails with Error: Binder Error: aggregate
function calls cannot be nested. You need to stage that computation and a sub-
query is one way to achieve this:
© Manning Publications Co. To comment go to liveBook
72
Listing 4.2 A sub-query being used to compute nested aggregates
SELECT avg(sum_per_system)
FROM (
SELECT sum(kWh) AS sum_per_system
FROM v_power_per_day
GROUP BY system_id
);
This statement now dutifully returns avg(sum_per_system) = 133908.087. The inner
query in this statement has two characteristics:
It returns several rows
It does not depend on values from the outer query
This query is called an uncorrelated sub-query. An uncorrelated subquery is just a query
nested inside another one, and operates as if the outer query executed on the results of
the inner query.
Now on to the next task you might have: on which day and for which system was the
highest amount of power produced? One way to solve this issue is using a subquery as
the right-hand-side of a comparison in the ´WHERE` clause.
Listing 4.3 A sub-query being used inside a condition selecting the row containing the maximum value
SELECT read_on, power
FROM readings
WHERE power = (SELECT max(power) FROM readings);
This sub-query is different from the first one in that it only returns a single, scalar value.
It is called scalar, uncorrelated sub-query.
NOTE arg_min and arg_max are aggregate functions that compute an expression of the row in
which the minimum or maximum value appears. In case you are interested in only one
expression, they are the preferable solution compared to any sub-query for tasks like above. If
you are interested in more than one expression or evaluating other values than minimum or
maximum values you won’t get around sub-queries in conditions.
The result essentially reads: "The maximum output of 133900W has been produced at 5
different times":
© Manning Publications Co. To comment go to liveBook
73
┌─────────────────────┬───────────────┐
│ read_on │ power │
│ timestamp │ decimal(10,3) │
├─────────────────────┼───────────────┤
│ 2019-05-08 12:15:00 │ 133900.000 │
│ 2019-05-23 10:00:00 │ 133900.000 │
│ 2019-05-23 11:30:00 │ 133900.000 │
│ 2019-05-28 11:45:00 │ 133900.000 │
│ 2020-04-02 11:30:00 │ 133900.000 │
└─────────────────────┴───────────────┘
What if we wanted to determine the maximum power and reading time on a per-system
basis? This will be tricky to do with the original subquery, because that only shows us the
values for the overall max power production. We would need the sub-query to return
different values for different rows; to do this we can use a correlated sub-query, which
uses the fields from the outer query inside the inner one like this:
Listing 4.4 Using correlated, scalar sub-queries
SELECT system_id, read_on, power
FROM readings r1
WHERE power = (
SELECT max(power)
FROM readings r2
WHERE r2.system_id = r1.system_id -- #1
)
ORDER BY ALL;
#1 This is the condition that correlates the sub-query to the outer query, not the comparison of the power value
Now this sub-query is a scalar, correlated sub-query. The inner query is related to the
outer query in that way that the database must evaluate it for every row of the outer
query.
In the result we see the 5 days for the highest value overall again and the highest
values produced for systems 10 and 1200 now too:
© Manning Publications Co. To comment go to liveBook
74
┌───────────┬─────────────────────┬───────────────┐
│ system_id │ read_on │ power │
│ int32 │ timestamp │ decimal(10,3) │
├───────────┼─────────────────────┼───────────────┤
│ 10 │ 2019-02-23 12:45:00 │ 1109.293 │
│ 34 │ 2019-05-08 12:15:00 │ 133900.000 │
│ 34 │ 2019-05-23 10:00:00 │ 133900.000 │
│ 34 │ 2019-05-23 11:30:00 │ 133900.000 │
│ 34 │ 2019-05-28 11:45:00 │ 133900.000 │
│ 34 │ 2020-04-02 11:30:00 │ 133900.000 │
│ 1200 │ 2020-04-16 12:15:00 │ 47873.333 │
└───────────┴─────────────────────┴───────────────┘
When used as expression, sub-queries may be rewritten as joins—with the computation
of nested aggregates being the exception. For the last example it would look like this:
Listing 4.5 An uncorrelated sub-query join with the outer table
SELECT r1.system_id, read_on, power
FROM readings r1
JOIN (
SELECT r2.system_id, max(power) AS value
FROM readings r2
GROUP BY ALL
) AS max_power ON (
max_power.system_id = r1.system_id AND
max_power.value = r1.power
)
ORDER BY ALL;
It’s up to the reader to judge whether this adds to readability or not. In other relational
databases people often do this, as the evaluation of a correlated sub-query for every
row in a large table might be slow. DuckDB, on the other hand, uses a sub-query
decorrelation optimizer that always makes sub-queries independent of outer queries,
thus allowing users to freely use sub-queries to create expressive queries without having
to worry about manually rewriting sub-queries into joins. It is not always possible to
manually decorrelate certain sub-queries by rewriting the SQL. Internally DuckDB uses
special types of joins that will decorrelate all sub-queries. In fact, DuckDB does not have
support for executing sub-queries that are not decorrelated.
The good thing for you is the fact that you can focus on the readability and
expressiveness of your queries, and the business problem you are trying to solve and
don’t need to worry about what type of sub-query you use.
© Manning Publications Co. To comment go to liveBook
75
4.3.1 Sub-queries as expressions
All forms of sub-queries, both correlated and uncorrelated, that are not used as a
relation in a JOIN, are expressions. As such, there are many more operators that might
be used with them. The = operator and the inequality operators = and > require
the sub-query to be a scalar sub-query, returning exactly one row. Working with both
scalar and non-scalar sub-queries, additional operators exists. These are IN, EXISTS,
ANY and ALL and they work by doing set comparisons.
Sub-queries can also be used in set-comparisons answering questions like "give me
all rows that compare successfully to all or any of the rows returned by another query".
The artificial examples in this section will all return v = 7.
'EXISTS'
You might want to select all the rows of a table that have a value that might exist inside
one row of another table. For this, you can use the EXISTS expression:
Listing 4.6 Sub-query used with the EXISTS expression
.mode line
SELECT * FROM VALUES (7), (11) s(v)
WHERE EXISTS (SELECT * FROM range(10) WHERE range = v);
'IN'
EXISTS can usually be rewritten as an uncorrelated sub-query using the IN operator:
When the outer value is contained at least once in the results of the sub-query, this
operator evaluates to true.
Listing 4.7 Sub-query used with the IN expression
.mode line
SELECT * FROM VALUES (7), (11) s(v)
WHERE v IN (SELECT * FROM range(10));
This is useful to know when you work with other relational databases than DuckDB that
might not do all kinds of optimizations on sub-queries.
'ANY'
The IN operator works with an equal comparison of each value. You might find yourself
in a situation in which you want to answer whether any value does satisfy an inequality
condition. Here, you need to use the ANY operator together with the desired comparison.
When the comparison of the outer value with any of the inner values evaluates to true,
the whole expression evaluates to true.
© Manning Publications Co. To comment go to liveBook
76
Listing 4.8 Sub-query used with the ANY expression
.mode line
SELECT * FROM VALUES (7), (11) s(v)
WHERE v <= ANY (SELECT * FROM range(10)); -- #1
#1 Please take note of the additional comparison prior to ANY
'ALL'
And last but not least, the ALL operator, which evaluates to true when the comparison of
the outer value with all of the inner values evaluates to true. It helps you find rows in
which a value satisfies a comparison between all values of a sub-query. While you can
replace = ANY() with IN() there is no such simplification for the ALL operator.
Listing 4.9 Sub-query used with the ALL expression
.mode line
SELECT * FROM VALUES (7), (11) s(v)
WHERE v = ALL (SELECT 7);
4.4 Grouping sets
In listing 3.1 we created a table named readings which contains the date, the time, and
the actual value of power produced at that time. We also suggested several example
datasets from the National Renewable Energy Laboratory to import. When looking at
such a dataset it is always helpful getting an overview about the minimum and maximum
values of an attribute, or maybe the average. Sometimes you might have outliers in
there that you want to delete, or maybe you made a mistake with the units. The easiest
way to compute that is just using them in one query, without any GROUP BY clause, so
that the aggregation happens in one bucket: the whole table.
Listing 4.10 Using various aggregates to check if the imports make sense
SELECT count(*),
min(power) AS min_W, max(power) AS max_W,
round(sum(power) / 4 / 1000, 2) AS kWh -- #1
FROM readings;
#1 Going from power produced in Watt and read in a 15-minute interval to power produced per hour in kWh is expressed by
summing the values up, dividing them by 4 to go to Watts per hour and then by 1000 for Kilowatt per hour.
If you followed the suggestion, your readings table should have key figures like the
following, which is the result of the query in above:
© Manning Publications Co. To comment go to liveBook
77
┌──────────────┬───────┬────────────┬───────────┐
│ count_star() │ min_W │ max_W │ kWh │
├──────────────┼───────┼────────────┼───────────┤
│ 151879 │ 0.000 │ 133900.000 │ 401723.22 │
└──────────────┴───────┴────────────┴───────────┘
The readings seem to be reasonable, even the minimum value of zero: there is just no
production during nighttime. As we already learned about the GROUP BY clause in image
3.2 we could go further and have a look at the production of kilowatts per hour and
system. We will also select the number of readings per system. We imported several
years, truncated the readings to 15-minute intervals, so we should find roughly 35040
readings per year. A GROUP BY system_id, year confirms this assumption as shown
with the next statement:
Listing 4.11 A plain GROUP BY with essentially one set of grouping keys ()
SELECT year(read_on) AS year,
system_id,
count(*),
round(sum(power) / 4 / 1000, 2) AS kWh
FROM readings
GROUP BY year, system_id
ORDER BY year, system_id;
The result adds up. We did have a bunch of invalid values and the second year ends
halfway in 2020:
┌──────┬───────────┬──────────────┬───────────┐
│ year │ system_id │ count_star() │ kWh │
├──────┼───────────┼──────────────┼───────────┤
│ 2019 │ 10 │ 33544 │ 1549.34 │
│ 2019 │ 34 │ 35040 │ 205741.9 │
│ 2019 │ 1200 │ 35037 │ 62012.15 │
│ 2020 │ 10 │ 14206 │ 677.14 │
│ 2020 │ 34 │ 17017 │ 101033.35 │
│ 2020 │ 1200 │ 17035 │ 30709.34 │
└──────┴───────────┴──────────────┴───────────┘
© Manning Publications Co. To comment go to liveBook
78
Now what about the totals, i.e., the total number of readings as well as the total power
production per year and system and overall? Or in other words: can we create a drill-
down report, showing different levels of detail per group? While we could now enter the
numbers into a calculator one by one and sum them manually, or write an additional
count-query without a grouping key like the initial one, there’s a better option called
"grouping sets":
Listing 4.12 Explicitly using GROUPING SETS
SELECT year(read_on) AS year,
system_id,
count(*),
round(sum(power) / 4 / 1000, 2) AS kWh
FROM readings
GROUP BY GROUPING SETS ((year, system_id), year, ())
ORDER BY year NULLS FIRST, system_id NULLS FIRST;
Before we dissect GROUP BY GROUPING SETS ((system_id, year), year, ()) let’s
have a look at the result first:
┌──────┬───────────┬──────────────┬───────────┐
│ year │ system_id │ count_star() │ kWh │
├──────┼───────────┼──────────────┼───────────┤
│ │ │ 151879 │ 401723.22 │
│ 2019 │ │ 103621 │ 269303.39 │
│ 2019 │ 10 │ 33544 │ 1549.34 │
│ 2019 │ 34 │ 35040 │ 205741.9 │
│ 2019 │ 1200 │ 35037 │ 62012.15 │
│ 2020 │ │ 48258 │ 132419.83 │
│ 2020 │ 10 │ 14206 │ 677.14 │
│ 2020 │ 34 │ 17017 │ 101033.35 │
│ 2020 │ 1200 │ 17035 │ 30709.34 │
└──────┴───────────┴──────────────┴───────────┘
The grouping sets created several buckets to compute the aggregates over:
A bucket defined by the combined values of system_id and year (6
different combinations in our example, thus leading to 6 rows)
A bucket defined by the year alone. For keys not included in this but in
other sets, null values are provided (here for the system_id)
The last one (()) can be described as the empty bucket or group: null
values are provided for all other keys
© Manning Publications Co. To comment go to liveBook
79
The result contains everything that listing 4.11 returned plus the number of readings per
year (grouping by year alone) plus the overall count (grouping by nothing).
The same result can be achieved by using the shorthand clause ROLLUP. The ROLLUP
clauses produces the sets we discussed above automically for you as n+1 grouping sets
where n is the amount of terms in the ROLLUP clause:
Listing 4.13 Using GROUP BY ROLLUP
SELECT year(read_on) AS year,
system_id,
count(*),