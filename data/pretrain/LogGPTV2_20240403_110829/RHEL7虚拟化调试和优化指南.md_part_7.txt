:::
::: section
::: titlepage
### [⁠]{#chap-Virtualization_Tuning_Optimization_Guide-Memory.html#idm140616983263280}7.3.3.2. 静态大页面配置 {.title}
:::
::: para
在某些情况下，更优的选择是增加对大页面的控制。在客机中使用静态大页面，使用
`virsh edit`{.command} 向客机 XML 配置添加以下命令：
:::
``` screen
```
::: para
以上命令使主机使用大页面向客机分配内存，以替代使用默认的页面大小。
:::
::: para
在 Red Hat Enterprise Linux 7.1 中，主机中的大页面可以被分配到客机的
NUMA 节点。在客机 XML 的 *``*
元素中指定大页面的大小、单位和客机的 NUMA
节点集。关于配置的更多信息和具体示例，请参照[第 8.4.9 节 "向多个客机
NUMA
节点指定主机大页面"](#chap-Virtualization_Tuning_Optimization_Guide-NUMA.html#sect-Virtualization_Tuning_Optimization_Guide-NUMA-Guest_NUMA_multinode-hugepages){.xref}。
:::
::: para
查看当前的大页面值，请运行以下命令：
``` screen
cat /proc/sys/vm/nr_hugepages
```
:::
::: {.procedure xmlns:d="http://docbook.org/ns/docbook"}
[⁠]{#chap-Virtualization_Tuning_Optimization_Guide-Memory.html#idm140616983257632}
**过程 7.2. 大页面设置**
::: para
以下程序示例显示了大页面设置的命令。
:::
1.  ::: para
    查看当前的大页面值：
    ``` screen
    # cat /proc/meminfo | grep Huge
    AnonHugePages:      2048 kB
    HugePages_Total:       0
    HugePages_Free:        0
    HugePages_Rsvd:        0
    HugePages_Surp:        0
    Hugepagesize:       2048 kB
    ```
    :::
2.  ::: para
    大页面将以 2MB 为增量进行设置。将大页面的数量设置到
    25,000，请运行以下命令：
    ``` screen
    echo 25000 > /proc/sys/vm/nr_hugepages
    ```
    :::
    ::: note
    ::: admonition_header
    **注意**
    :::
    ::: admonition
    ::: para
    此外，如需进行永久设置，请使用
    `# sysctl -w vm.nr_hugepages=N`{.command} 命令和显示为大页面数量的
    *N*。
    :::
    :::
    :::
3.  ::: para
    大页面挂载：
    ``` screen
    # mount -t hugetlbfs hugetlbfs /dev/hugepages
    ```
    :::
4.  ::: para
    重启 [**libvirtd**]{.application}，之后再运行以下命令重启虚拟机：
    ``` screen
    # systemctl start libvirtd
    ```
    ``` screen
    # virsh start virtual_machine
    ```
    :::
5.  ::: para
    验证 `/proc/meminfo`{.filename} 中的更改：
    ``` screen
    # cat /proc/meminfo | grep Huge
    AnonHugePages:         0 kB
    HugePages_Total:   25000
    HugePages_Free:    23425
    HugePages_Rsvd:        0
    HugePages_Surp:        0
    Hugepagesize:       2048 kB
    ```
    :::
:::
::: para
大页面不仅可以使主机受益，也可以使客机受益。但它们的大页面值总量必须小于主机中的可用值。
:::
:::
:::
:::
:::
[]{#chap-Virtualization_Tuning_Optimization_Guide-NUMA.html}
::: chapter
::: titlepage
# [⁠]{#chap-Virtualization_Tuning_Optimization_Guide-NUMA.html#chap-Virtualization_Tuning_Optimization_Guide-NUMA}第 8 章 NUMA {.title}
:::
::: section
::: titlepage
# [⁠]{#chap-Virtualization_Tuning_Optimization_Guide-NUMA.html#idm140616966235120}8.1. 简介 {.title}
:::
::: para
过去，x86 系统中的所有内存都可以通过 CPU 进行同等访问。无论任何 CPU
执行操作，访问时间都相等，这也被称为"统一内存访问"（UMA，Uniform Memory
Access）。
:::
::: para
最近使用的 x86
处理器已经不再采取这一行为。在非统一内存访问（NUMA，Non-Uniform Memory
Access）中，系统内存被划分到 NUMA [*节点*]{.emphasis}（node），并且与
socket 相对应，或与特定某一组与本地系统内存子集具有相同访问延迟的 CPU
相对应。
:::
::: para
本章节描述了虚拟环境中的内存分配和 NUMA 调试配置。
:::
:::
::: section
::: titlepage
# [⁠]{#chap-Virtualization_Tuning_Optimization_Guide-NUMA.html#sect-Virtualization_Tuning_Optimization_Guide-NUMA-Allocation_Policy}8.2. NUMA 内存分配策略 {.title}
:::
::: para
以下三种策略定义了系统中节点对内存的分配：
:::
::: variablelist
[*`Strict`*]{.term}
:   ::: para
    目标节点中不能分配内存时，分配将被默认操作转进至其他节点。严格的策略意味着，当目标节点中不能分配内存时，分配将会失效。
    :::
[*`Interleave`*]{.term}
:   ::: para
    内存页面将被分配至一项节点掩码指定的节点，但将以轮循机制的方式分布。
    :::
[*`Preferred`*]{.term}
:   ::: para
    内存将从单一最优内存节点分配。如果内存并不充足，内存可以从其他节点分配。
    :::
:::
::: para
XML 配置启用所需策略：
:::
``` programlisting
```
:::
::: section
::: titlepage
# [⁠]{#chap-Virtualization_Tuning_Optimization_Guide-NUMA.html#sect-Virtualization_Tuning_Optimization_Guide-NUMA-Auto_NUMA_Balancing}8.3. 自动化 NUMA 平衡 {.title}
:::
::: para
自动化 NUMA 平衡改进了 NUMA 硬件系统中运行应用的性能。它在 Red Hat
Enterprise Linux 7 系统中被默认启用。
:::
::: para
通常，应用程式在其程序的线程访问 NUMA
节点上的内存、且此节点位置与线程排程时的位置相同的时候，性能最佳。自动化
NUMA
平衡会把任务（任务可能是线程或进程）移到与它们需要访问的内存更近的地方，同时也会移动内存应用程序数据，使其更靠近参考这一数据的任务。以上均在自动化
NUMA 平衡启用时由内核自动完成。
:::
::: para
自动化 NUMA 平衡使用若干算法和数据结构，它们只有在系统中自动化 NUMA
平衡活跃时才能被启用和分配。
:::
::: {.itemizedlist xmlns:d="http://docbook.org/ns/docbook"}
-   ::: para
    进程内存的周期性 NUMA 取消对应
    :::
-   ::: para
    NUMA hinting 故障
    :::
-   ::: para
    故障迁移（MoF，Migrate-on-Fault）------将内存移动至需要运行的程序
    :::
-   ::: para
    task_numa_placement ------移动运行的程序，使接近其内存
    :::
:::
::: section
::: titlepage
## [⁠]{#chap-Virtualization_Tuning_Optimization_Guide-NUMA.html#idm140616987245984}8.3.1. 配置自动化 NUMA 平衡 {.title}
:::
::: para
自动化 NUMA 平衡在 Red Hat Enterprise Linux 7 中默认启用，并在 NUMA
属性硬件中引导时自动激活。
:::
::: para
自动化 NUMA 平衡启用时需满足以下两个条件：
:::
::: {.itemizedlist xmlns:d="http://docbook.org/ns/docbook"}
-   ::: para
    `# numactl --hardware`{.command} 显示多个节点，以及
    :::
-   ::: para
    `# cat /sys/kernel/debug/sched_features`{.command} 在标识中显示
    `NUMA`{.systemitem}
    :::
:::
::: para
应用程序的手动 NUMA 调试将会重载自动化 NUMA
平衡，并禁用周期性的内存空白、NUMA 错误、迁移和以上应用程序的自动化 NUMA
放置。
:::
::: para
在某些情况下，首选系统范围内的手动 NUMA 调试。
:::
::: para
要禁用自动化 NUMA 平衡，请使用以下命令：
:::
``` screen
# echo 0 > /proc/sys/kernel/numa_balancing
```
::: para
要启用自动化 NUMA 平衡，请使用以下命令：
:::
``` screen
# echo 1 > /proc/sys/kernel/numa_balancing
```
:::
:::
::: section
::: titlepage
# [⁠]{#chap-Virtualization_Tuning_Optimization_Guide-NUMA.html#sect-Virtualization_Tuning_Optimization_Guide-NUMA-NUMA_and_libvirt}8.4. libvirt NUMA 调试 {.title}
:::
::: para
通常，NUMA 系统通过将客机大小限制在单一 NUMA
节点的资源数量实现最佳性能。应当避免 NUMA 节点中不必要的分散资源。
:::
::: para
使用 `numastat`{.command} 工具对进程和操作系统的每个 NUMA
节点内存统计进行查看。
:::
::: para
在以下示范中，`numastat`{.command} 工具显示了 NUMA
节点中的四种非优化内存排列的虚拟机：
``` screen
# numastat -c qemu-kvm
Per-node process memory usage (in MBs)
PID              Node 0 Node 1 Node 2 Node 3 Node 4 Node 5 Node 6 Node 7 Total
---------------  ------ ------ ------ ------ ------ ------ ------ ------ -----
51722 (qemu-kvm)     68     16    357   6936      2      3    147    598  8128
51747 (qemu-kvm)    245     11      5     18   5172   2532      1     92  8076
53736 (qemu-kvm)     62    432   1661    506   4851    136     22    445  8116
53773 (qemu-kvm)   1393      3      1      2     12      0      0   6702  8114
---------------  ------ ------ ------ ------ ------ ------ ------ ------ -----
Total              1769    463   2024   7462  10037   2672    169   7837 32434
```
:::
::: para
运行 `numad`{.command}，使客机 CPU 和内存资源自动对齐。
:::
::: para
接下来再次运行 `numastat -c qemu-kvm`{.command}，以查看
`numad`{.command} 的运行结果。以下输出显示了资源已对齐：
``` screen
# numastat -c qemu-kvm
Per-node process memory usage (in MBs)
PID              Node 0 Node 1 Node 2 Node 3 Node 4 Node 5 Node 6 Node 7 Total
---------------  ------ ------ ------ ------ ------ ------ ------ ------ -----
51747 (qemu-kvm)      0      0      7      0   8072      0      1      0  8080
53736 (qemu-kvm)      0      0      7      0      0      0   8113      0  8120
53773 (qemu-kvm)      0      0      7      0      0      0      1   8110  8118
59065 (qemu-kvm)      0      0   8050      0      0      0      0      0  8051
---------------  ------ ------ ------ ------ ------ ------ ------ ------ -----
Total                 0      0   8072      0   8072      0   8114   8110 32368
```
:::
::: {.note xmlns:d="http://docbook.org/ns/docbook"}
::: admonition_header
**注意**
:::
::: admonition
::: para
同时运行 `numastat`{.command} 和 `-c`{.option} 可提供简洁的输出；添加