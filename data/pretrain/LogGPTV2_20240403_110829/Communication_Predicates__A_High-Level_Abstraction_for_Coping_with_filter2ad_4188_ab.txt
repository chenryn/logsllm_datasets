• Integrity: Any decision value is the initial value of
3.1. Communication predicates
some process.
• Agreement: No two processes decide differently.
• Termination: All processes eventually decide.
Communication predicates are deﬁned in the context of a
communication-closed round model. An algorithm for this
model comprises, for each round r and process p ∈ Π, a
sending function Sr
p . At be-
ginning of a round r, every process sends a message to all
p and a transition function T r
4The term is taken from [21], in which transmission faults are consid-
ered in the context of synchronous systems.
The termination condition requires all processes to decide;
a weaker condition is considered later. An example of a
consensus algorithm is given by Algorithm 1.5 The send-
ing function is speciﬁed in lines 4–5. When the transition
5We have chosen this algorithm, rather than Paxos or another algorithm,
for its simplicity. It allows us to keep the algorithmic part as simple as
possible.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:50:59 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007function (lines 6–13) is called, messages are available such
that the predicate on the HO sets is guaranteed to hold. The
consensus problem is solved by Algorithm 1 and the com-
munication predicate Potr , given in Table 1 (next page).
Theorem 1. The pair h Algorithm 1, Potr i solves consen-
sus.
Proof. Algorithm 1 never violates the safety properties of
consensus, namely integrity and agreement. For agreement,
if some process decides v at line 13 of round r, then in any
round r′ ≥ r, only v can be assigned to any xp, and hence
only v can be decided. Predicate Potr ensures the liveness
property of consensus (termination). The ﬁrst part of Potr ,
namely the existence of some round r0 in which all pro-
cesses in Π have the set HO equal to some (large enough)
set Π0, ensures that at the end of round r0 all processes in
Π adopt the same value for xp. The second part of Potr
forces every process p ∈ Π to make a decision at the end of
round rp.
Note that Potr allows rounds in which no messages are
received.
3.2. Restricted scope communication pred-
icates
Section 2.3 has introduced the “transmission fault” ab-
straction, which covers various types of faults. One instan-
tiation is to assume that transmission faults abstract link
faults, send-omission faults and receive-omission faults, but
not process crashes (i.e., processes do not crash). In this
case the predicate Potr , which expresses a condition that
must hold for all processes p ∈ Π, is perfectly adapted.
This interpretation of transmission faults is also consistent
with the termination condition for consensus that requires
all processes to decide.
Let us now assume that transmission faults include in ad-
dition process crashes (without recovery). As already men-
tioned in [6], from the viewpoint of an HO algorithm this
is still not a problem, since a crashed process does not send
any messages and is thus indistinguishable from one that re-
ceives all messages but sends no messages. This holds no
more if we implement the HO machine in a system where
processes may exhibit any sort of benign faults. The prob-
lem can be addressed by restricting the scope of Potr to the
subset Π0, as deﬁned by P restr
, see Table 1 (next page).
otr
otr
Predicate P restr
sets a requirement only for processes
in Π0, and so ensures termination only for processes in Π0.
If processes in Π0 do not crash, while processes in Π \ Π0
crash, then hAlgorithm 1, P restr
i allow all processes that
do not crash to decide. So we have:
Theorem 2. The pair hAlgorithm 1, P restr
i ensures the va-
lidity and agreement property of consensus. Moreover, all
processes in Π0 eventually decide.
otr
otr
Proof. Proof of Theorem 1, by replacing Π with Π0.
3.3. Crash-recovery model
otr
Algorithm 1 with predicate P restr
solves consensus with
process crashes (crash-stop), link faults, send-omission, and
receive-omission faults. In Section 2.1 we pointed out the
gap between solving consensus with failure detectors in the
crash-stop vs. the crash-recovery model. The gap disap-
pears with the transmission fault abstraction and commu-
nication predicates.
Without any changes, Algorithm 1 can be used in the
crash-recovery model. Handling of recoveries is done at a
lower layer (cf. Section 4).
4. Achieving predicate P restr
otr
in good periods
otr
We discuss now the implementation of the communi-
cation predicate P restr
introduced in Section 3. Figure 1
shows the algorithmic HO layer, the predicate implemen-
tation layer that we discuss now, and the interface between
these two layers deﬁned by communication predicates. This
illustration shows also that the implementation of the pred-
icates relies on assumptions about the underlying system
(these assumptions deﬁne the fault and synchrony hypothe-
sis). Note that “transmission faults” is an abstraction rele-
vant to the upper layer: This abstraction does not appear at
the lower layer.
In our implementation model, the system alternates be-
In a good period the syn-
tween good and bad periods.
chrony and fault assumptions hold; in a bad period the be-
havior of the system is arbitrary (but malicious behavior is
excluded). The idea is here to compute the minimal dura-
tion of a good period that allows us to implement the com-
munication predicates, i.e., the minimal duration of a good
period that allow Algorithm 1 to solve consensus.
HO Algorithm
Comm. predicates
Predicate
Implementation
Fault model +
synch. assumptions
Figure 1. The two layers.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:50:59 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Potr :: ∃r0 > 0, ∃Π0, |Π0| > 2n/3 : (∀p ∈ Π : HO(p, r0) = Π0) ∧ (∀p ∈ Π, ∃rp > r0 : |HO(p, rp)| > 2n/3)
P restr
otr
:: ∃r0 > 0, ∃Π0, |Π0| > 2n/3 : (∀p ∈ Π0 : HO(p, r0) = Π0) ∧ (∀p ∈ Π0, ∃rp > r0 : HO(p, rp) ⊇ Π0)
(1)
(2)
Table 1. Communication predicates
4.1. System model
Our system model is inspired by [12]; the differences
are pointed out at the end of the section. We consider a
message-passing system, and assume the existence of a ﬁc-
titious global real-time clock that measures time with val-
ues from IR (see the remark on the next page for the reason
for considering values from IR rather than integers). The
clock is used only for analysis and is not accessible to the
processes. Processes execute a sequence of atomic steps,
which are either send steps or receive steps. As in [12],
steps take no time (atomic steps), but time elapses between
steps.6 The network can take a make-ready step that is in-
troduced to distinguish a message ready for reception from
a message in transit: (i) Every process has two sets of mes-
sages called network p and buﬀer p; (ii) a make-ready step
transfers a message from the ﬁrst to the second set. Send
steps, receive steps, and make-ready steps are deﬁned to ad-
equately model a real system:
• In a send step, a process p sends a message to either
a single process or to all other processes and makes
some local computation. More precisely, if p executes
sendp(m) to all, then m is put into network s, for all
s ∈ Π.
• In a make-ready step, the network transfers some mes-
sages from network p into buﬀer p. More precisely, if
the network executes make-readyp(M ) for some sub-
set M ⊆ network p, all messages m ∈ M are re-
moved from network p and put into buﬀer p. Messages
in buﬀer p are ready for reception by process p.
• In a receive step executed at time t, a process p may
receive a single message that was in buﬀer p at time t
and makes some local computation. So n receive steps
are needed to receive n messages. If buﬀer p = ∅ at
the time of a receive step, the empty message λ is re-
ceived. A process p may specify any policy, according
to which the message buﬀer p is selected for reception
(e.g., “message with the largest round number ﬁrst”).
We consider that the system alternates between good and
bad periods. In a bad period, processes can crash and re-
cover and suffer from send and receive omission; further-
more links can loose messages. We distinguish three types
6We model a step that “terminates” at time t as an atomic step that
“occurs” at time t.
of good periods, from the strongest to the weakest. All these
deﬁnitions refer to a subset π0 of Π. In all the three deﬁni-
tions, the following property π0-sync holds in a good period
for processes in π0:
π0-sync: The subsystem π0 is synchronous, i.e., there is
a known upper and lower bound on the process speed and
a known upper bound on the communication delays among
processes in π0. Formally:
Let I be an open contiguous time interval and R a run.
Processes and links are synchronous during I if there exist
Φ+, Φ−, ∆ ∈ IR such that:
• In any contiguous sub-interval of I of length Φ+, every
process in π0 takes at least one step.
• In any open contiguous sub-interval of I of length Φ−,
every process in π0 takes at most one step.
• Consider two processes p, q ∈ π0. If process p exe-
cutes sendp(m) at time t ∈ I, then m ∈ buﬀer q at
time t + ∆, provided that t + ∆ ∈ I.
The length of the good period is |I|. If I starts at time 0,
we say I is an initial good period. We denote Π \ π0 by π0.
We can now deﬁne the three types of good periods:
1. Π-good period: The property π0-sync holds for
π0 = Π. All processes are up, none of these processes
crashes (during the good period).
2. “π0-down” good period: The property π0-sync holds
for π0 ⊆ Π. Processes in π0 do not crash. Processes
in π0 are down and do not recover (during the good
period). Moreover, no messages from processes in π0
are in transit during the good period.
3. “π0-arbitrary” good period: The property π0-sync
holds for π0 ⊆ Π. There are no restrictions on the pro-
cesses in π0 and on the links to and from processes
processes in π0 (during the good period processes in π0
can crash, recover, be asynchronous; links to and from
processes in π0 can lose messages, be asynchronous).
Case 2 includes case 1, and case 1 leads to the same im-
plementation as case 2. Thus we distinguish below only
between case 2 and case 3. For simplicity, we will use the
following notation: We scale all values Φ+, Φ−, ∆, and t
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:50:59 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007with 1/Φ− and use φ = Φ+/Φ− as the normalized upper
bound of the process speed, δ = ∆/Φ− as the normalized
transmission delay, and τ = t/Φ− as normalized time. Re-
member that φ and δ are “known” values, and note that these
values are unit-less.7
Remark: For our modeling, we have chosen real-values
clocks to represent time. Consider case 3 above, assuming
integer clock values instead. By the deﬁnition of Φ+, the
slowest process in π0 takes at least one step in any interval
Φ+. However, with integer clock values, any process can
take at most Φ+ steps in an interval Φ+, independent how
small Φ− is chosen. So, in case 3, processes in π0 cannot
be arbitrarily fast with respect to processes in π0. In other
words, with integer clock values, processes in π0 have some
synchrony relation with respect to processes in π0, which
we wanted to exclude under case 3.
Differences between our system model and DLS [12]:
In [12] the clocks take integer values. We have explained
the reason to consider clocks with real-time values. In [12]
a send step allows a process to send a message only to a
single destination. Our send primitive allows messages to
be broadcast, a facility provided, e.g., by UDP-multicast.
In [12], a receive step allows a process to receive several
messages. Our receive primitive allows reception of a mes-
sage from one single process only, which reﬂects the fea-
ture, e.g., of UDP. The reception of messages one by one
led us to introduce the make-ready step. Two different syn-
chrony assumptions are considered in [12]: (i) The syn-
chrony bounds are known but hold only eventually; (ii) the
synchrony bounds are not known, but hold from the begin-
ning. We considered option (i), which is needed to com-
pute the minimal length of a good period (in the context of
the implementation of the communication predicates). In
the context of option (i), [12] assumes that the good period
holds eventually forever and that the synchrony assumption
holds on the whole system. We consider the system alter-
nating between good and bad periods, and synchrony as-
sumptions that hold only on a subset π0. We also assume
the more general crash-recovery model, while [12] consid-
ers the crash-stop model. On the other hand, contrary to our
fault model, [12] considers also Byzantine faults.
4.2. Implementation of P restr
otr
otr
We give now algorithms for implementing the predicate
P restr
in π0-down and π0-arbitrary good periods. It turns
out that both deﬁnitions of a good period lead naturally
to the implementation of a predicate that is stronger than
7For obtaining real-time values, the results in this section have thus to
be multiplied by Φ−.
P restr
otr
. We deﬁne:
Psu (Π0, r1, r2)
:: ∀p ∈ Π0, ∀r ∈ [r1, r2] : HO(p, r) = Π0
Pk (Π0, r1, r2)
:: ∀p ∈ Π0, ∀r ∈ [r1, r2] : HO(p, r) ⊇ Π0
P 2
otr (Π0)
:: ∃r0 > 0 : Psu (Π0, r0, r0)
P 1/1
otr (Π0)