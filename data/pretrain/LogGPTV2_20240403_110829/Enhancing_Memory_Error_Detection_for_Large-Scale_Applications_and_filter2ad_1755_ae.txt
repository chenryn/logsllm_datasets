13K
18K
30K
162K
158K
45K
4K
10K
387
413
4,535
110
340
167
182
1,320
44
573
504
1,490
360
820
6,020
58
222
143
170
1,250
50
666
457
2,470
8
21
108
9
92
260
73
2
97
135
58
85
29
54
231
14
110
295
80
5
123
150
61
86
256%
157%
114%
56%
20%
13%
10%
150%
27%
11%
5%
1%
20.67
50.85
23.81
81.82
270.59
1,556.89
399.17
1.52
2,204.55
0.24
115.03
57.04
79.17
65.85
38.37
241.38
495.50
2,062.94
468.69
4.00
2,460.00
0.23
133.48
34.82
283%
30%
61%
195%
83%
33%
17%
164%
12%
-4%
16%
-39%
TABLE IV: Fuzzing real-world applications to compare memory error detection capability of ASAN and MEDS. α denotes (the number of
forks, the number of stars) in GitHub, and β denotes the installation ranking from the Debian popularity contest. Each application was fuzzed
for 6 hours using the AFL fuzzer [38].
behavior). This execution speed can be deduced from the
total number of executions. For example, in the case of PH7,
MEDS was slightly slower than ASAN (i.e., 7 % slower).
Seven applications were slower when running with MEDS,
however, more unique crashes occur during the fuzz testing.
Five applications (i.e., lci, picoc, swftools, exifprobe, and jhead)
were faster when running with MEDS. Among these, in terms
of unique crashes per executions MEDS was slower in two
applications (i.e., exifprobe and jhead). We suspect this is
because MEDS reached to the point earlier than ASAN, where
AFL gets saturated in exploring more execution paths in these
two applications. After being saturated, MEDS spent the rest
fuzzing cycles, more cycles than ASAN as MEDS has faster
execution speeds, without finding new unique crashes. In other
words, MEDS found most of unique crashes faster than ASAN,
but spent the rest fuzzing time without finding more as AFL
gets saturated. For the rest of three applications (i.e., lci, picoc,
and swftools), they have higher unique crashes per executions
when running with MEDS.
Even for the seven applications that showed slower execu-
tion speeds in MEDS (i.e., PH7, ImageMagick, wren, espruino,
tinyvm, raptor, and metacam), MEDS still was able to find more
unique crashes than ASAN. This implicates that, the advantages
in providing enhanced detection capability outweighs the
disadvantages in slowing down the execution speed, resulting
in overall fuzzing performance improvements made by MEDS
(in terms of finding more unique crashes).
We believe this clearly demonstrates the improved memory
error detection capability of MEDS over ASAN. Considering
the huge popularity of AFL and ASAN in performing real-
world fuzz testing, these results also signify the strong practical
impacts of MEDS— when used together with AFL, the proto-
type of MEDS can help the fuzz testing processes, significantly
better than the state-of-the-art memory error detection tool,
ASAN.
D. Performance Overheads
The security service of MEDS obviously comes with cost,
which mainly impacts two performance factors: runtime speed
and physical memory usage.
Runtime Speed. The major factors imposing runtime speed
overheads for MEDS are (1) it executes extra instructions to
check all memory load and store instructions; (2) since MEDS
utilizes more virtual address space, there will be more TLB
misses; and (3) each object allocation needs to invoke mremap
syscalls for page aliasing.
To better understand these aspects, we ran benchmarks
for applications — Table V shows the running results of
Chrome, Firefox, Apache, and Nginx, and Table VI shows
that of OpenSSL. For Chrome and Firefox, we used Octane
benchmarks [14]; for Apache and Nginx, we used Apache
benchmark [13] which serves 25,000 requests per second;
and for OpenSSL, we used OpenSSL’s speed command to
encrypt memory blocks using SHA1 [12]. For each run, we
applied three different settings of MEDS to better understand
performance impacts from object coverage. In other words,
the MEDS column with H denotes that MEDS safeguards
heap objects (i.e., all heap objects have been allocated using
MEDSALLOC). Similarly, HS denotes for both heap and stack
objects, and HSG denotes for all object types including heap,
stack, and global.
On average, MEDS slowed down the execution about 27%
on MEDS-H, 94% on MEDS-HS, and 108% on MEDS-HSG
compared to the baseline. First, as MEDS increases the object
coverage (from heap object types to all object types), the
execution gradually slowed down because MEDS will miss
more TLB and invoke more system calls. This performance
change is especially noticeable between MEDS-H and MEDS-
HS for Nginx (i.e., 24% to 250%). This is because Nginx
allocates a huge number of stack objects at runtime, which in
turn incurs a huge number of allocations (when a function is
invoked) and deallocation (when a function returns) for MEDS.
The stack object allocation is not a performance bottleneck
for the baseline, however, as it only requires to shift the stack
pointer to reserve and release stack memory space for objects.
Compared to ASAN, MEDS slowed down the execution
about 11%, 73%, and 86%. As MEDS does not impose signifi-
cant overheads in terms of instrumented instructions compared
to ASAN (i.e., both check the shadow memory bit), we inspected
other performance factors—TLB misses (Table VII) and the
number of invoked system calls (Table VIII). Overall MEDS
indeed incurs much more TLB misses (i.e., on average 499%
more than ASAN) and invokes much more system calls (i.e.,
on average 32 times more than ASAN). However, we believe
12
App.
Chrome
Firefox
Apache
Nginx
Benchmark
(Metric)
Baseline
Performance
ASAN
Octane
(Score, high)
ApachBench
(# of requests, high)
28,177
26,970
5,671
8,132
24,117 (17%)
23,076 (22%)
5,087 (11%)
7,370 (10%)
Performance (Slowdown)
H
21,553 (31%)
20,043 (35%)
4,826 (18%)
6,538 (24%)
MEDS
HS
20,713 (36%)
N/A
4,540 (25%)
2,528 (222%)
HSG
19,525 (44%)
N/A
4,327 (31%)
2,364 (250%)
TABLE V: Runtime performance (a score for Octane, and # of requests per second for ApacheBench; the higher the better) overheads of
MEDS, along with ASAN and the baseline for comparison. Overall, on average MEDS slows down an execution 108% compared to the baseline,
and 86% to ASAN.
Block
Size
(Bytes)
16
64
256
1024
8192
Baseline
Performance
72K
201K
434K
635K
746K
Slowdown
ASAN
248%
276%
150%
60%
12%
H
624%
357%
169%
95%
19%
MEDS
HS
672%
424%
209%
102%
22%
HSG
759%
483%
238%
118%
25%
TABLE VI: OpenSSL performance (# of KB processed per a second)
of MEDS, along with the baseline and ASAN. Larger block size
decreases the overhead of both ASAN and MEDS. Especially, the
block size is critical to the performance of MEDS.
Application
# of TLB misses
Overhead
Baseline
ASAN
MEDS
ASAN MEDS
27,821k
42,548k
3,391k
452k
945k
Chrome
331%
Firefox
185%
Apache
10%
Nginx
154%
OpenSSL
372%
TABLE VII: TLB utilization while running benchmarks
119,855k
121,062k
3,741k
1,150k
4,468k
40,185k
44,711k
3,640k
542k
1,126k
44%
5%
10%
20%
19%
App.
Chrome
Firefox
Apache
Nginx
OpenSSL
# of system calls
Overhead
Baseline
ASAN
MEDS
82,313
213,388
548,684
275,311
127
100,893
227,352
949,493