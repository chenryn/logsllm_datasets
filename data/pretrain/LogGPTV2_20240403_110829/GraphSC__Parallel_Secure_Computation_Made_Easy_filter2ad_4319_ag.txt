### Execution Time Analysis

#### Figure 15: Execution Times of Garbler and Evaluator
Figure 15 breaks down the execution times of the garbler and evaluator for one iteration of PageRank and gradient descent, with increasing input sizes. The system uses 8 processors for both the garblers and evaluators.

- **Garbler (Gradient Descent):** 
  - Input Length: 200, 100, 0, 29, 210, 211, 28
- **Evaluator (Gradient Descent):**
  - Input Length: 200, 100, 0, 29, 210, 211, 28

The garbler spends a considerable amount of time waiting for the garbled tables (a blocking operation). In our implementation, the garbler computes 4 hashes to garble each gate, while the evaluator computes only 1 hash for evaluation. This explains why the evaluation time is smaller than the garbling time. Since the computation tasks are superlinear in the size of the inputs, the time spent on oblivious transfer (both communication and computation) is insignificant compared to the time for garbling/evaluating.

Our current implementation is built on Java and does not utilize hardware AES-NI instructions. We expect that the garbling and evaluation CPU time will reduce noticeably if hardware AES-NI were employed [76]. Future work will involve porting GraphSC to a C-based implementation capable of employing hardware AES-NI features.

### Bandwidth and Performance Analysis

#### Table V: Summary of Key Evaluation Results (1 Iteration)
- **Input Size:** 8K, 16K, 32K
- **Execution Time (seconds):** 300, 200, 100, 0, 4, 8, 512, 768, 1024
- **Bandwidth (Mbps):** 212, 210, 28, 26, 21, 23, 22
- **Processors:** 24

#### Figure 16: Performance of PageRank
- **(a) Varying Bandwidths:**
  - Performance for 4 and 8 processors at varying bandwidths.
  - The dotted vertical line indicates the inflection point for 8 processors, below which the bandwidth becomes a bottleneck, resulting in reduced performance.
- **(b) Across Data Centers:**
  - Performance of PageRank running on geographically distant data centers (Oregon and North Virginia).

### Amazon AWS Experiments

We conducted two experiments on Amazon AWS machines:
1. **Performance under Different Bandwidths:**
   - Both garblers and evaluators were located in the same data center (Oregon - US West).
   - Setup: Intel Xeon CPU E5-2666 v3 processors clocked at 2.9 GHz, 16 cores, and 30 GB of RAM.
   - Results: For an input length of 16K entries, the required bandwidth is always lower than the capacity of the link when using 4 processors. However, with 8 processors, the total bandwidth required is higher, and the link becomes saturated when the available bandwidth is below 570 Mbps. Each garbler-evaluator pair requires approximately 142 Mbps. GraphSC has an effective throughput of ~0.58M gates/sec between a pair of processors on our Amazon AWS instances. The theoretical bandwidth required is 133 Mbps. Due to garbage collection in Java, the implementation requires slightly more bandwidth than the theoretical calculation.

2. **Cross-Data-Center Experiments:**
   - Garblers in Oregon (US West) and evaluators in N. Virginia (US East).
   - Results: The deployment managed to sustain a linear speedup when increasing the number of processors. Even 16 processors did not saturate the 2 Gbps link, indicating that geographical distance does not impact the speedup from adding additional processors. AWS provides higher capacity links (e.g., 10 Gbps) if more than 14 garbler-evaluator pairs are needed.

### Summary of Main Results

- **Scalability:** GraphSC provides high scalability with the input size, exhibiting an almost linear increase with the input size (up to poly-log factor).
- **Parallelization:** Parallelization provides an almost ideal linear improvement in execution time with small communication overhead, both in a LAN-based setting and across data centers.
- **Large-Scale Secure Matrix Factorization:** We ran a first-of-its-kind large-scale secure matrix factorization experiment, factorizing a matrix comprised of the MovieLens 1M ratings dataset within 13 hours on a heterogeneous set of 7 machines with a total of 128 processors.
- **Floating-Point Support:** GraphSC supports fixed-point and floating-point real representation, yielding low rounding errors compared to execution in the clear.

### Conclusion

This paper introduces GraphSC, a parallel data-oblivious and secure framework for efficient implementation and execution of algorithms on large datasets. By seamlessly integrating modern parallel programming paradigms into a secure data-oblivious framework, we aim to significantly increase the adoption of secure computation. This can change the privacy landscape, enabling companies to develop arbitrarily complicated algorithms that run in parallel on large datasets without leaking information.

### Acknowledgments

We gratefully acknowledge Marc Joye, Manish Purohit, and Omar Akkawi for their insightful inputs and various forms of support. We thank the anonymous reviewers for their feedback. This research is partially supported by an NSF grant CNS-1314857, a Sloan Fellowship, and a subcontract from the DARPA PROCEED program.

### References

[1] A. C.-C. Yao, “How to generate and exchange secrets,” in FOCS, 1986.
...
[78] “Iperf,” https://iperf.fr/.

For a complete list of references, please refer to the original document.