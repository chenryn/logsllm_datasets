200
100
0
29
210
211
28
Input length
(c) Gradient Descent: Garbler
(d) Gradient Descent: Evaluator
Fig. 15: A breakdown of the execution times of the garbler
and evaluator running one iteration of PageRank and gradient
descent for an increasing input size using 8 processors for
garblers and 8 for evaluators.
a considerable amount of time waiting for the garbled tables
(receive is a blocking operation). In our implementation,
the garbler computes 4 hashes to garble each gate, and the
evaluator computes only 1 hash for evaluation. This explains
why the evaluation time is smaller than the garbling time. Since
the computation tasks under consideration are superlinear in
the size of the inputs, we see that the time spent on oblivious
transfer (both communication and computation) is insigniﬁcant
in comparison to the time for garbling/evaluating. Our current
implementation is built atop Java, and we do not make use
of hardware AES-NI instructions. We expect that the garbling
and evaluation CPU will reduce noticeably if hardware AES-
NI were employed [76]. We leave it for future work to port
GraphSC to a C-based implementation capable of employing
hardware AES-NI features.
391391
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:55 UTC from IEEE Xplore.  Restrictions apply. 
8K
16K
32K
TABLE V: Summary of key evaluation results (1 iteration).
)
c
e
s
(
e
m
T
i
300
200
100
0
4
8
512
768
1024
Bandwidth (Mbps)
)
c
e
s
(
e
m
T
i
212
210
28
26
21
23
22
Processors
24
(a) Varying bandwidths.
(b) Across data centers
Fig. 16: Performance of PageRank. Figure 16a shows perfor-
mance for 4 and 8 processors at varying bandwidths. The dot-
ted vertical line indicates the inﬂexion point for 8 processors,
below which the bandwidth becomes a bottleneck, resulting
in reduced performance. Figure 16b shows the performance
of PageRank running on geographically distant data centers
(Oregon and North Virginia).
I. Amazon AWS Experiments
We conduct two experiments on Amazon AWS machines.
First, we study the performance of the system under different
bandwidths on the same AWS data center (Figure 16a). Sec-
ond, to test the performance on a more realistic deployment,
where the garbler and evaluator are not co-located, we also
conduct experiments by deploying GraphSC on a pair of AWS
virtual machines located in different geographical regions
(Figure 16b).
The time reported for these experiments should not be
compared to the earlier experiments as different machines were
used.
Setup. For the experiments with varying bandwidths, both
garblers and evaluators were located in the same data center
(Oregon - US West). For the experiment across data centers,
the garblers were located in Oregon (US West) and the
evaluators were located in N. Virginia (US East). We ran our
experiments on shared instances running on Intel Xeon CPU
E5-2666 v3 processors clocked at 2.9 GHz. Each of our virtual
machines consisted of 16 cores and 30 GB of RAM.
Results for Varying Bandwidths. Since communication be-
tween garblers and evaluators is a key component in system
performance, we further study the bandwidth requirements of
the system on a real-world deployment.
We measure the time for a single PageRank iteration with
input length of 16K entries. We vary the bandwidth using
tc [77], a tool for bandwidth manipulation, and then measure
the exact bandwidth between machines using iperf [78].
Figure 16a shows the execution time for two setups, one
with 4 processors (2 garblers and 2 evaluators) and the second
with 8 processors. Using 4 processors the required bandwidth
is always lower than the capacity of the link, thus the execution
time remains the same throughout the experiment. However,
when using 8 processors the total bandwidth required is higher,
and when the available bandwidth is below 570 Mbps the
link becomes saturated. The saturation point indicates that
each garbler-evaluator pair requires a bandwidth of 570/4 ≈
142 Mbps. GraphSC has an effective throughput of ~ 0.58M
gates/sec between a pair of processors on our Amazon AWS
instances. Each gate has a size of 240 bits. Hence, the theoret-
ical bandwidth required is 0.58× 240× 106/220 ≈ 133 Mbps.
Experiment
Histogram
PageRank
Gradient Descent
large scale)
Gradient Descent
ALS
Input size
1K - 0.5M
4K - 128K
1K - 32K
64 - 4K
1M ratings
Time (32 processors)
4 sec - 34 min
20 sec - 15.5 min
47 sec - 34 min
2 min - 2.35 hours
13 hours
(128 processors)
Considering GraphSC is implemented in Java, garbage collec-
tion happens intermittently due to which the communication
link is not used effectively. Hence, the implementation requires
slightly more bandwidth than the theoretical calculation.
Given such bandwidth requirements, the available band-
width in our AWS setup, i.e., 2 Gbps between the machines,
will saturate beyond roughly 14 garbler-evaluator pairs (28
processors). At this point, the linear speedup trend w.r.t. the
number of processors (as shown in Figure 7) will stop, unless
larger bandwidth becomes available. In a real deployment sce-
nario, the total bandwidth can be increased by having multiple
machines for garbling and evaluating, hence supporting more
processors without affecting the speedup.
Results for Cross-Data-Center Experiments. For this ex-
periment, the garblers are hosted in the AWS Oregon data
center and the evaluators are hosted in the AWS North Vir-
ginia data center. We measure the execution time of a single
iteration of PageRank for different input lengths. As in the
previous experiment, we used machines with 2Gbps network
links, however, measuring the TCP throughput with iperf
resulted in ~50 Mbps per TCP connection. By increasing the
receiver TCP buffer size we managed to increase the effective
throughput for each TCP connection to ~400 Mbps.
Figure 16b shows that this realistic deployment manages to
sustain a linear speedup when increasing the number of proces-
sors. Moreover, even 16 processors do not saturate the 2 Gbps
link, meaning that the geographical distance does not impact
the speedup resulting from adding additional processors. We
note that if more than 14 garbler-evaluator pairs are needed (to
further reduce execution time), AWS provides higher capacity
links (e.g., 10 Gbps), thereby allowing even higher degrees of
parallelism.
During the computation, the garbler garbles gates and sends
it to the evaluator. As there are no round trips involved (i.e.
garbler does not wait to receive data from the evaluator), the
time required for computation across data centers is the same
as in the LAN setting.
J. Summary of Main Results
To summarize, Table V highlights some of the results, and
we present the main ﬁndings:
• As mandated from “big-data” algorithms, GraphSC provides
high scalability with the input size, exhibiting an almost linear
increase with the input size (up to poly-log factor).
• Parallelization provides an almost ideal linear improvement in
execution time with small communication overhead (especially
on computation-intensive tasks), both in a LAN based setting
and across data centers.
392392
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:55 UTC from IEEE Xplore.  Restrictions apply. 
• We ran a ﬁrst-of-its-kind large-scale secure matrix factoriza-
tion experiment, factorizing a matrix comprised of the Movie-
Lens 1M ratings dataset within 13 hours on a heterogeneous
set of 7 machines with a total of 128 processors.
• GraphSC supports ﬁxed-point and ﬂoating-point reals repre-
sentation, yielding an overall low rounding errors (provided
sufﬁcient fraction bits) compared to execution in the clear.
VI. CONCLUSION
This paper introduces GraphSC, a parallel data-oblivious
and secure framework for efﬁcient implementation and exe-
cution of algorithms on large datasets. It is our sincere hope
that by seamlessly integrating modern parallel programming
paradigms that are familiar to a wide range of developers into
an secure data-oblivious framework will signiﬁcantly increase
the adoption of secure computation. We believe that this can
truly change the privacy landscape, where companies that
operate on potentially sensitive datasets, will be able to develop
arbitrarily complicated algorithms that run in parallel on large
datasets as they normally do, only without leaking information.
VII. ACKNOWLEDGMENTS
We gratefully acknowledge Marc Joye, Manish Purohit and
Omar Akkawi for their insightful inputs and various forms of
support. We thank the anonymous reviewers for their insightful
feedback. This research is partially supported by an NSF grant
CNS-1314857, a Sloan Fellowship and a subcontract from the
DARPA PROCEED program.
REFERENCES
[1] A. C.-C. Yao, “How to generate and exchange secrets,” in FOCS, 1986.
[2] C. Liu, Y. Huang, E. Shi, J. Katz, and M. Hicks, “Automating efﬁcient
ram-model secure computation,” in IEEE S & P, 2014.
[3] V. Nikolaenko, S. Ioannidis, U. Weinsberg, M. Joye, N. Taft, and
D. Boneh, “Privacy-preserving matrix factorization,” in ACM CCS,
2013.
[4] V. Nikolaenko, U. Weinsberg, S. Ioannidis, M. Joye, D. Boneh, and
N. Taft, “Privacy-preserving ridge regression on hundreds of millions
of records,” in IEEE (S & P), 2013.
[5] Y. Huang, D. Evans, J. Katz, and L. Malka, “Faster secure two-party
computation using garbled circuits.” in USENIX Security Symposium,
2011.
[6] B. Kreuter, a. shelat, and C.-H. Shen, “Billion-gate secure computation
with malicious adversaries,” in USENIX Security symposium, 2012.
J. Dean and S. Ghemawat, “Mapreduce: Simpliﬁed data processing on
large clusters,” Commun. ACM, 2008.
[7]
[8] G. Malewicz, M. H. Austern, A. J. Bik, J. C. Dehnert, I. Horn, N. Leiser,
and G. Czajkowski, “Pregel: A system for large-scale graph processing,”
in SIGMOD, 2010.
[9] Y. Low, D. Bickson, J. Gonzalez, C. Guestrin, A. Kyrola, and J. M.
Hellerstein, “Distributed graphlab: a framework for machine learning
and data mining in the cloud,” PVLDB, 2012.
[10] M. Zaharia, M. Chowdhury, M. J. Franklin, S. Shenker, and I. Stoica,
“Spark: cluster computing with working sets,” in HotCloud, 2010.
[11] X. S. Wang, C. Liu, K. Nayak, Y. Huang, and E. Shi, “Oblivm: A
programming framework for secure computation,” IEEE Symposium on
Security and Privacy (S & P), 2015.
J. E. Gonzalez, Y. Low, H. Gu, D. Bickson, and C. Guestrin, “Pow-
ergraph: Distributed graph-parallel computation on natural graphs.” in
OSDI, 2012.
[12]
[13] E. Boyle, K.-M. Chung, and R. Pass, “Oblivious parallel ram,” https:
//eprint.iacr.org/2014/594, 2014.
[14] M. T. Goodrich, O. Ohrimenko, and R. Tamassia, “Data-oblivious graph
drawing model and algorithms,” CoRR, 2012.
[15] D. Eppstein, M. T. Goodrich, and R. Tamassia, “Privacy-preserving
data-oblivious geometric algorithms for geographic data,” in SIGSPA-
TIAL, 2010.
[16] S. Zahur and D. Evans, “Circuit structures for improving efﬁciency of
security and privacy tools,” in S & P, 2013.
[17] M. Blanton, A. Steele, and M. Alisagari, “Data-oblivious graph algo-
rithms for secure computation and outsourcing,” in ASIA CCS. ACM,
2013.
[18] A. C.-C. Yao, “Protocols for secure computations (extended abstract),”
in FOCS, 1982.
[19] S. D. Gordon, J. Katz, V. Kolesnikov, F. Krell, T. Malkin, M. Raykova,
and Y. Vahlis, “Secure two-party computation in sublinear (amortized)
time,” in ACM CCS, 2012.
a. shelat and C.-H. Shen, “Fast two-party secure computation with
minimal assumptions,” in CCS, 2013.
[20]
[21] ——, “Two-output secure computation with malicious adversaries.” in
EUROCRYPT, 2011.
[22] F. Kerschbaum, “Automatically optimizing secure computation,” in
CCS, 2011.
[23] D. Bogdanov, S. Laur, and J. Willemson, “Sharemind: A framework for
fast privacy-preserving computations.”
[24] B. Kreuter, B. Mood, A. Shelat, and K. Butler, “PCF: A portable circuit
format for scalable two-party secure computation,” in USENIX Security,
2013.
[25] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella, “Fairplay: a secure two-
party computation system,” in USENIX Security Symposium, 2004.
[26] W. Henecka, S. Kögl, A.-R. Sadeghi, T. Schneider, and I. Wehrenberg,
“Tasty: tool for automating secure two-party computations,” in CCS,
2010.
[27] A. Rastogi, M. A. Hammer, and M. Hicks, “Wysteria: A programming
language for generic, mixed-mode multiparty computations,” in IEEE
Symposium on Security and Privacy (S & P), 2014.
[28] A. Holzer, M. Franz, S. Katzenbeisser, and H. Veith, “Secure two-party
computations in ansi c,” in CCS, 2012.
[29] Y. Zhang, A. Steele, and M. Blanton, “Picco: a general-purpose com-
piler for private distributed computation,” in CCS, 2013.
[30] V. Kolesnikov and T. Schneider, “Improved Garbled Circuit: Free XOR
Gates and Applications,” in ICALP, 2008.
[31] S. G. Choi, J. Katz, R. Kumaresan, and H.-S. Zhou, “On the security
of the “free-xor" technique,” in Theory of Cryptography Conference
(TCC), 2012.
[32] B. Applebaum, “Garbling xor gates “for free” in the standard model,”
in Theory of Cryptography Conference (TCC), 2013.
[33] N. Husted, S. Myers, A. Shelat, and P. Grubbs, “Gpu and cpu par-
allelization of honest-but-curious secure two-party computation,” in
Annual Computer Security Applications Conference, 2013.
[34] O. Goldreich, S. Micali, and A. Wigderson, “How to play any mental
game,” in STOC, 1987.
[35] C. Gentry, “Fully homomorphic encryption using ideal lattices,” in ACM
[36]
symposium on Theory of computing (STOC), 2009.
I. Damgård, M. Keller, E. Larraia, V. Pastro, P. Scholl, and N. P. Smart,
“Practical covertly secure mpc for dishonest majority–or: Breaking the
spdz limits,” in Computer Security–ESORICS 2013, 2013.
[37] M. Ben-Or, S. Goldwasser, and A. Wigderson, “Completeness theorems
for non-cryptographic fault-tolerant distributed computation,” in ACM
STOC, 1988.
[38] O. Goldreich and R. Ostrovsky, “Software protection and simulation on
oblivious RAMs,” J. ACM, 1996.
[39] M. T. Goodrich, M. Mitzenmacher, O. Ohrimenko, and R. Tamassia,
“Privacy-preserving group data access via stateless oblivious RAM
simulation,” in SODA, 2012.
[40] R. Ostrovsky and V. Shoup, “Private information storage (extended
abstract),” in ACM Symposium on Theory of Computing (STOC), 1997.
[41] E. Kushilevitz, S. Lu, and R. Ostrovsky, “On the (in)security of hash-
based oblivious RAM and a new balancing scheme,” in SODA, 2012.
393393
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:55 UTC from IEEE Xplore.  Restrictions apply. 
[72]
“Graphlab powergraph tutorials,” https://github.com/graphlab-code/
graphlab.
“Movielens dataset,” http://grouplens.org/datasets/movielens/.
[73]
[74] S. Bhagat, U. Weinsberg, S. Ioannidis, and N. Taft, “Recommending
with an agenda: Active learning of private attributes using matrix
factorization,” in RecSys ’14. ACM.
[75] S. Ioannidis, A. Montanari, U. Weinsberg, S. Bhagat, N. Fawaz, and
N. Taft, “Privacy tradeoffs in predictive analytics,” in SIGMETRICS’14.
ACM, 2014.
[76] M. Bellare, V. T. Hoang, S. Keelveedhi, and P. Rogaway, “Efﬁcient
garbling from a ﬁxed-key blockcipher,” in IEEE Symposium on Security
and Privacy (SP), 2013.
“Tc man page,” http://manpages.ubuntu.com/manpages//karmic/man8/
tc.8.html.
“Iperf,” https://iperf.fr/.
[77]
[78]
[42] M. T. Goodrich, M. Mitzenmacher, O. Ohrimenko, and R. Tamassia,
“Oblivious RAM simulation with efﬁcient worst-case access overhead,”
in CCSW, 2011.
I. Damgård, S. Meldgaard, and J. B. Nielsen, “Perfectly secure oblivious
RAM without random oracles,” in TCC, 2011.
[43]
[44] D. Boneh, D. Mazieres, and R. A. Popa, “Remote oblivious stor-
age: Making oblivious RAM practical,” http://dspace.mit.edu/bitstream/
handle/1721.1/62006/MIT-CSAIL-TR-2011-018.pdf, Tech. Rep., 2011.
[45] P. Williams, R. Sion, and B. Carbunar, “Building castles out of mud:
Practical access pattern privacy and correctness on untrusted storage,”
in CCS, 2008.
[46] P. Williams and R. Sion, “Usable PIR,” in Network and Distributed
System Security Symposium (NDSS), 2008.
[47] M. T. Goodrich and M. Mitzenmacher, “Privacy-preserving access of
outsourced data via oblivious RAM simulation,” in ICALP, 2011.
[48] R. Ostrovsky, “Efﬁcient computation on oblivious RAMs,” in ACM
Symposium on Theory of Computing (STOC), 1990.
[49] B. Pinkas and T. Reinman, “Oblivious RAM revisited,” in CRYPTO,
2010.
[50] P. Williams and R. Sion, “SR-ORAM: Single round-trip oblivious ram,”
in ACM CCS, 2012.
[51] E. Shi, T.-H. H. Chan, E. Stefanov, and M. Li, “Oblivious RAM with
O((log N )3) worst-case cost,” in ASIACRYPT, 2011.
[52] E. Stefanov, M. van Dijk, E. Shi, C. Fletcher, L. Ren, X. Yu, and S. De-
vadas, “Path ORAM – an extremely simple oblivious ram protocol,” in
CCS, 2013.
[53] X. S. Wang, T.-H. H. Chan, and E. Shi, “Circuit oram: On tightness
of the goldreich-ostrovsky lower bound,” Cryptology ePrint Archive,
Report 2014/672, 2014, http://eprint.iacr.org/.
[54] K.-M. Chung, Z. Liu, and R. Pass, “Statistically-secure oram with
˜O(log
2 n) overhead,” CoRR, 2013.
[55] X. Wang, K. Nayak, C. Liu, E. Shi, E. Stefanov, and Y. Huang,
[56]
[57]
“Oblivious data structures,” in ACM CCS, 2014.
J. C. Mitchell and J. Zimmerman, “Data-Oblivious Data Structures,” in
Theoretical Aspects of Computer Science (STACS), 2014.
J. E. Savage, Models of Computation: Exploring the Power of Comput-
ing, 1997.
[58] K. Shvachko, H. Kuang, S. Radia, and R. Chansler, “The hadoop
distributed ﬁle system,” in Mass Storage Systems and Technologies
(MSST), 2010 IEEE 26th Symposium on.
IEEE, 2010, pp. 1–10.
[59] C. Avery, “Giraph: Large-scale graph processing infrastruction on
hadoop,” Hadoop Summit., 2011.
[60] S. Brin and L. Page, “The anatomy of a large-scale hypertextual web
search engine,” Computer networks and ISDN systems, 1998.
[61] Y. Koren, R. Bell, and C. Volinsky, “Matrix factorization techniques for
recommender systems,” Computer, vol. 42, no. 8, pp. 30–37, 2009.
[62] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning represen-
tations by back-propagating errors,” Cognitive modeling, vol. 5, 1988.
[63] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, “Distributed
optimization and statistical learning via the alternating direction method
of multipliers,” Foundations and Trends R(cid:4) in Machine Learning, 2011.
[64] D. E. Knuth, The Art of Computer Programming, Volume 3: (2Nd Ed.)
Sorting and Searching, 1998.
[65] T. H. Cormen, C. E. Leiserson, R. L. Rivest, C. Stein et al., Introduction
to algorithms. MIT press Cambridge, 2001.
[66] M. Ajtai, J. Komlós, and E. Szemerédi, “An o(n log n) sorting network,”
in ACM symposium on Theory of computing, 1983.
[67] R. Miller and L. Boxer, Algorithms sequential & parallel: A uniﬁed
approach. Cengage Learning, 2012.
[69]
[68] Y. Lindell and B. Pinkas, “An efﬁcient protocol for secure two-party
computation in the presence of malicious adversaries,” in EUROCRYPT,
2007.
J. Bennett and S. Lanning, “The netﬂix prize,” in Proceedings of KDD
cup and workshop, 2007.
“Oblivm,” http://www.oblivm.com.
[70]
[71] M. T. Goodrich, “Zig-zag sort: A simple deterministic data-oblivious
sorting algorithm running in o(n log n) time,” CoRR, 2014.
394394
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:55 UTC from IEEE Xplore.  Restrictions apply.