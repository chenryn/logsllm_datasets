title:Preserving privacy in gps traces via uncertainty-aware path cloaking
author:Baik Hoh and
Marco Gruteser and
Hui Xiong and
Ansaf Alrabady
Preserving Privacy in GPS Traces via Uncertainty-Aware
Path Cloaking
Baik Hoh, Marco Gruteser
WINLAB / ECE Dept., Rutgers Univ.
Piscataway, NJ USA
baikhoh,PI:EMAIL
Hui Xiong
MSIS Dept., Rutgers Univ.
Newark, NJ USA
PI:EMAIL
Ansaf Alrabady
General Motors Corporation
Warren, MI USA
PI:EMAIL
ABSTRACT
Motivated by a probe-vehicle based automotive trafﬁc monitoring
system, this paper considers the problem of guaranteed anonymity
in a dataset of location traces while maintaining high data accuracy.
We ﬁnd through analysis of a set of GPS traces from 233 vehicles
that known privacy algorithms cannot meet accuracy requirements
or fail to provide privacy guarantees for drivers in low-density ar-
eas. To overcome these challenges, we develop a novel time-to-
confusion criterion to characterize privacy in a location dataset and
propose an uncertainty-aware path cloaking algorithm that hides
location samples in a dataset to provide a time-to-confusion guar-
antee for all vehicles. We show that this approach effectively guar-
antees worst case tracking bounds, while achieving signiﬁcant data
accuracy improvements.
Categories and Subject Descriptors
K.4.1 [Computers and Society]: Public Policy IssuesPrivacy; K.6
[Management of Computing and Information Systems]: Secu-
rity and Protection
General Terms
Algorithms, Measurements, Security
Keywords
Privacy, GPS, Trafﬁc
1.
INTRODUCTION
A new class of applications that mines aggregate location traces
from large numbers of users, spawned by the increasing ubiquity
of sensors and wireless communications, raises signiﬁcant privacy
concerns. One example and the motivation for this paper is automo-
tive trafﬁc monitoring through probe vehicles [20, 14, 30], which
infers trafﬁc congestion from position and speed information peri-
odically reported from GPS-equipped vehicles. Other applications
of such aggregate location traces are road and city planning.
Privacy could be protected in such applications by rendering the
data anonymous before sharing it with application service providers.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’07, October 29–November 2, 2007, Alexandria, Virginia, USA.
Copyright 2007 ACM 978-1-59593-703-2/07/0010. . . $5. 00.
An anonymous location dataset provides strong privacy protection
while allowing sharing with arbitrary data consumers, since no
purpose-binding restricts the data for certain uses. Anonymization,
however, requires techniques beyond omitting obvious identiﬁers,
since the spatio-temporal characteristics of the data allows track-
ing and reidentiﬁcation of anonymous vehicles when user density
is low. Existing algorithms based on the k-anonymity concept [42,
22, 24], however, modify the location traces substantially and can-
not meet the accuracy requirements of the trafﬁc monitoring appli-
cation. Other techniques [6, 27, 36] achieve better accuracy but
cannot guarantee privacy in low user density scenarios.
This paper addresses the challenge of providing strong privacy
guarantees while maintaining high data accuracy of time-series lo-
cation data. Speciﬁcally, the key contributions of this work are:
• introduction of a novel time-to-confusion metric to evaluate
privacy in a set of location traces. This metric describes how
long an individual vehicle can be tracked.
• development of an uncertainty-aware privacy algorithm that
can guarantee a speciﬁed maximum time-to-confusion.
• demonstration through experiments on real-world GPS traces
that this algorithm limits maximum time-to-confusion while
providing more accurate location data than a random sam-
pling baseline algorithm.
Overview. The remainder of this paper is organized as follows.
Section 2 introduces the motivating trafﬁc monitoring system and
data requirements.
In section 3, we describe the privacy model
and introduce the time-to-confusion metric. Section 4 presents the
uncertainty-aware privacy algorithm. Section 5 describes the ex-
perimental results obtained with real-world location traces, which
demonstrate the privacy and data accuracy advantages. We then
discuss limitations and extensions in section 6, review related work
in section 7, and conclude.
2. TRAFFIC MONITORING WITH PROBE
VEHICLES
The trafﬁc monitoring application that serves as a case study
aims to provide estimates of current travel time for each route using
real-time GPS traces from vehicles on these roads. The probe ve-
hicles use on-board GPS receivers and cellular communications to
periodically report their position and speed to a central trafﬁc mon-
itoring system, which stores them in a database for real-time and
historical trafﬁc analysis. Figure 1(a) illustrates this architecture.
2.1 Real-world GPS Trace Collection
To obtain a realistic dataset similar to real deployments [2, 3,
1], we have ofﬂine collected a dataset containing GPS traces from
161Parameter
Requirement
Spatial Accuracy
Sample Interval
100m
1min
Delay
few minutes
Table 1: Trafﬁc monitoring system data requirements
provided while the vehicle is parked with its ignition switched off.
In addition, data is unavailable when the GPS reception is lost (e.g.,
due to obstruction from high-rise buildings) or the receiver is still
in the process of acquiring the satellite ﬁx. Figure 1(c) illustrates
the distribution of gaps in the traces of around 233 vehicles. Each
dot represents a received data sample. Since the traces do not con-
tain information about ignition status, we assume that a gap longer
than 10 min indicates that the vehicle was parked. We refer to the
parts of a trace between two gaps longer than 10 min as a trip.
2.2 Data Quality Metrics and Requirements
Data privacy algorithms increase privacy through deliberate mod-
iﬁcations on the dataset, such as omission, perturbation, or gener-
alization of a datum. Thus, there exists a tradeoff between data
quality (or its utility) and the degree of privacy. To enable a mean-
ingful evaluation of privacy algorithms let us discuss data quality
requirements and metrics for the trafﬁc monitoring application.
This application represents a road map as a graph comprising a
set of road segments, where each road segment describes a stretch
of road between two intersections. Generating the congestion map
then proceeds in three steps: Mapping new GPS samples to road
segments, computing mean road segment speed, and inferring a
congestion index (e.g., by comparing current mean speed with nom-
inal segment speed).
Mapping GPS samples onto road segments requires high spatial
accuracy. Consider that two different parallel road segments (with
trafﬁc ﬂow in same direction) may be only about 10m apart, as on
the New Jersey Turnpike, for example. Cayford and Johnson [9]
showed, however, that using tracking algorithms the correct road
can be determined in 98.4% of all surface streets and 98.9% of all
freeways if the location system provides a spatial accuracy of 100m
and updates in 1s intervals. When reducing the update interval from
1s to 45s, the correctly determined roads drop from 99.5% to 98%
(at 50m spatial accuracy). Therefore, to maintain high road map-
ping accuracy at the 1min sample interval for our data traces, we
can assume that a minimum spatial accuracy of 100 m is needed.
Another important data quality requirement is road coverage,
which primarily depends on the penetration rate, the percentage
of vehicles carrying the trafﬁc monitoring equipment. To achieve
high coverage these systems aim at a minimum penetration rate of 3
(for freeways) to 5% (for surface streets) [14], but during the initial
deployment phase penetration rates may be much lower. Thus pri-
vacy algorithms must offer protection even with in low deployment
densities. Road coverage can also be reduced through privacy algo-
rithms. Thus, we measure a relative weighted coverage metric for
the privacy algorithms, which is based on the following heuristics.
First, road coverage decreases as more samples are withheld. Sec-
ond, probe-vehicle based trafﬁc monitoring aims to extend trafﬁc
monitoring beyond a few key routes, but information from busier
roadways is certainly more important than from low-trafﬁc routes.
Third, coverage is fundamentally limited by the number of probe
vehicles on roads, thus we only consider coverage relative to the
original dataset.
To measure the effect of removed samples on road coverage, rel-
ative weighted coverage ﬁrst assigns each location-sample a weight,
(a) System architecture
x 106
4.74
4.73
4.72
4.71
4.7
4.69
4.68
4.67
]
m
[
M
T
U
n
i
y
4.66
2.8
2.9
3
3.1
3.2
x in UTM [m]
3.3
3.4
3.5
x 105
(b) 70km x 70km road network with cell weights indicating
the busiest areas
(c) Temporal distribution of GPS traces for 233 vehicles
Figure 1: Trafﬁc monitoring system and spatio-temporal dis-
tribution of real-world dataset
233 vehicles driving in a large US city and its suburban area. Fig-
ure 1(b) depicts the 70 km by 70 km region that the vehicles cov-
ered. For privacy reasons no speciﬁc information about the vehicles
or drivers is known to the authors, except that traces were recorded
largely from test vehicles driven by volunteers. Each GPS sample
comprises vehicle ID, timestamp, longitude, latitude, velocity, and
heading information. Each vehicle records a GPS sample every
minute, while its ignition is switched on, for a period of one week.
This means that the traces contain temporal gaps, since no data is
depending on how busy the area around this sample is. Then, it
divides the sum of weighted location samples from modiﬁed (or
partially removed) traces by the sum of weighted location samples
from the original traces. To estimate these weights for our dataset
we divide the area into 1km by 1km grid cells and count the number
of location samples ni emanating from each cell i over one day in
the original traces. The resulting weights for each cell are overlaid
on the road map in Figure 1(b). The weights are normalized with
the sum of weights over all samples, so that the relative weighted
road coverage for the original dataset is equal to 1. More precisely,
the weight for all samples in cell i equals wi = ni(cid:2)
. With these
weights, relative weighted road coverage for a set of location sam-
l∈L wc(l), where the function c returns
ples L is then deﬁned as
the cell index in which the speciﬁed location sample lies.
j n2
(cid:2)
j
In summary, we can measure data quality for a trafﬁc monitoring
application through the relative weighted road coverage, where we
consider a road segment covered if a data sample with sub-100m
accuracy is available. Table 1 summarize key system parameters
and requirements that we will assume in the following sections.
3. PRIVACY LEAKAGE THROUGH ANONY-
MOUS LOCATION TRACES
Especially in the United States where people rely heavily on au-
tomobiles and distances between buildings are large, monitoring
the movements of a person’s automobile can reveal sensitive in-
formation. First, knowing trip destinations can reveal information
about a persons health, lifestyle, net worth, or political associations,
Second, many drivers might object to such monitoring because it
could reveal minor trafﬁc or parking violations.
Even after anonymization, some of this information may be re-
covered, as simply removing identiﬁers from a dataset does not
always provide strong anonymity guarantees, which was the moti-
vation for introducing the k-anonymity concept [42].
3.1 Existing Privacy Algorithms
Several techniques have been proposed to increase location pri-
vacy. However, we are aware of only one class of techniques, spa-
tial cloaking algorithms for k-anonymity, that can guarantee a de-
ﬁned degree of anonymity for all users.
k-anonymity [42, 38] formalizes the notion of strong anonymity
and complementary algorithms exist to anonymize database tables.
They key idea underlying these algorithms is to generalize a data
record until it is indistinguishable from the records of at least k −
1 other individuals. Speciﬁcally, for location information, spa-
tial cloaking algorithms have been proposed [24, 22] that reduce
the spatial accuracy of each location sample until it meets the k-
anonymity contstraint. To achieve this, the algorithms require knowl-
edge of nearby vehicles positions, thus they are usually implemented
on a trusted server with access to all vehicles current position.
k-anonymous datasets produced with known algorithms cannot
meet trafﬁc monitoring’s accuracy requirements. Figure 2 shows
the spatial accuracy results obtained after applying a spatial cloak-
ing algorithm to guarantee k-anonymity of each sample. We use
the same dataset in section 5.1 so that we could directly compare k-
anonymity with our proposed solution in terms of spatial accuracy.
The results were obtained with the CliqueCloak algorithm [22],
which to our knowledge achieves the best accuracy. The results
show that even for very low privacy settings, k = 3, location error
remains close to 1000m for an emulated deployment of 2000 ve-
hicles, far over the accuracy requirement of the trafﬁc monitoring
application. While these results can be expected to improve with
increased penetration rates as the deployment case of 5500 vehicles
shows 500m for k = 3 (indeed, [24] shows that median accuracies
of 125 meters and below can be obtained when all vehicles act as
probes), other privacy approaches are necessary to enable probe
systems operating with lower penetration rates.
3000
2500
]
m
[
r
o
r
r
e
n
o
i
t
a
c
o
l
n
a
e
M
2000
1500
1000
500
0
Number of probe vehicles = 2000
Number of probe vehicles = 5500
3
7 
5 
Anonymity level (k)
9 
Figure 2: Data accuracy of samples processed with spatial
cloaking algorithm fails to meet the accuracy requirement in
our scenario
Best effort algorithms. Given that in dense environments paths
from many drivers cross, drivers intuitively enjoy a degree of anony-
mity, similar to that of a person walking through an inner-city crowd.
Thus, Tang et al. [43] lay out a set of privacy guidelines and sug-
gest that the sampling frequency, with which probes send position
updates, should be limited to larger intervals. The authors men-
tion that a sample interval of 10min appears suitable to maintain
privacy, although the choice appears somewhat arbitrary (for ref-
erence, a typical consumer GPS chipset implementation offers a
maximum sampling frequency of 1 Hz). We refer to data collection
with reduced sampling frequency as subsampling.
Other best effort algorithms suppress information only in cer-
tain high-density areas rather than uniformly over the traces as the
subsampling approach. The motivation for these algorithms that
path suppression in high density areas increases the chance for con-
fusing or mixing several different traces. This approach was ﬁrst
proposed by Beresford and Stajano [7]. The path confusion [27]
algorithm also concentrates on such high-density areas although
it perturbs location samples rather than suppressing them. These
techniques increase the chance of confusion in high-density areas,
but they also cannot guarantee strong privacy in low-density areas
where paths only infrequently meet. Thus, in-terms of worst-case
privacy guarantees their advantage over subsampling remains un-
clear.
We choose the subsampling algorithm as a best effort baseline
algorithm. Table 2 shows an adversary’s tracking performance
over an anonymous set of samples with 1 min (no removal) and 2
min (50% removal) sampling intervals. For a probe vehicle den-
sity of 500 vehicles per a 70km2 region, the tracking algorithm
returns 3480 segments of 15 min duration and 1172 segments of 20
min duration. Both reducing the sampling interval and increasing
probe vehicle density reduces tracking performance. For example,
with 2000 vehicles on a same area and 2 min sampling interval,
17 segments of 20 min duration can be identiﬁed. Precision of the
tracking algorithm is about 95% in all cases, meaning that only 5%
of the returned segments do not match an actual vehicles path, ex-
cept in the 2000 vehicle 2 min case, where relatively few segments
can be tracked (in this case precision drops to 60 percent). These
example results were obtained with a tracking model that we will
describe in detail in the following section.
Density=500, Uncertainty threshold=0.45
Density=2000, Uncertainty threshold=0.7
Random sampling (50% removal) Anonymization (no removal)
15min
45/47
18/30
20min
1117/1172
908/958
20min
28/29
10/17
15min
3300/3480
1302/1394
Table 2: Empirical conﬁdence in subsampling
To understand the implications of these tracking durations (15min
and 20 min), let us consider ﬁgure 3, which depicts the histogram
of per-trip travel time in the GPS dataset. The data shows a large
number of very short trips, for example 30% of trips are shorter
than 10 min, 50% of trips shorter than 18min. This empirical result
also coincides with the empirical statistics from real GPS traces in
Krumm’s work [35] (Krumm observes 14.4 min per trip as a me-
dian). This means that by following a trace for only 10min, an ad-
versary may be able to track a vehicle from its home to a sensitive
destination.
1500
1000
500
y
c
n
e
u
q
e
r
F
0
0
50
100
150
200
250
300
Travel time per vehicle trip [min]
Figure 3: Empirical distribution of travel times per vehicle trip.
These results illustrate that protecting all drivers of probe vehi-
cles through subsampling remains difﬁcult. One minute sampling
intervals are already large for a trafﬁc monitoring application but
protecting all drivers even in low density areas would require a fur-
ther signiﬁcant increase in the sampling interval. Moreover, it is
difﬁcult to choose this sampling interval since trafﬁc densities can
change substantially over time and space.
This raises the question of alternate deﬁnitions and measures for
anonymity in location traces.
F
D
P
l
a
c
i
r
i
p
m
E
0.12
0.1
0.08
0.06
0.04
0.02
0
0
Fitted curve: exponential function (mu=2094m)
Empirical data from GPS dataset
0.5
1
1.5
Distance deviation from precition [m]
2