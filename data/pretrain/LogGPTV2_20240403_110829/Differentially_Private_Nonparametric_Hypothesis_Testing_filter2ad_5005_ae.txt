### Results and Discussion

The results presented in Figure 10 are based on a continuous distribution for the real data, which means there are no data points with \( d_i = 0 \). Since one of the key differences between our algorithms is the method for handling zero values, we also examine the performance when there are a large number of zeros. Our test achieves the rigorous privacy guarantees of the TC High Privacy test while providing greater utility than the TC High Utility test, both in scenarios with no zero values and those with many.

### Relative Contribution of Improvements

Given that we have made two significant changes to the TC test, it is natural to question whether both changes are necessary or if most of the improvement comes from one change. To address this, we compare our algorithm to an updated variant of the TC test where we calculate critical values exactly through simulation, as in our algorithm, but otherwise leave the TC test unchanged (referred to as "High Privacy +"). The results, shown in Figure 11, indicate that both the change to the critical value calculation and the switch to the Pratt method for handling \( d_i = 0 \) rows are important contributions to achieving the power of our test.

### Parametric Alternative: A New T-Test

The parametric analog to the Wilcoxon test is a one-sample t-test on the set of differences \(\{v_i - u_i\}\) to determine if their mean is significantly different from zero (also known as a paired t-test). There has been limited work on creating a private version of a one-sample t-test. Karwa and Vadhan [16] studied private confidence intervals, which are conceptually similar to a t-test, but their analysis is asymptotic and not practical for databases with thousands of entries. Sheffet [24] provided a method for calculating private coefficient estimates for linear regression and transformed the t-distribution, but this method fails when all variables are not significantly spread out.

#### Database and Test Statistic

For a one-sample t-test, the database contains observations \( x_1, \ldots, x_n \) assumed to come from a normal distribution with mean \(\mu\) and standard deviation \(\sigma\). For paired data, each observation is the difference between the observations in the two groups. The test statistic is given by:
\[ T_{\text{stat}}(x) = \frac{\bar{x}}{s / \sqrt{n}}, \]
where \(\bar{x}\) is the mean of the data and \( s \) is the standard deviation.

#### Private t-Test

To achieve privacy, we add Laplacian noise, but since the sensitivity of \( T_{\text{stat}} \) is unbounded, we release separate private estimates of the numerator and denominator. We assume the data is scaled such that all observations are on the interval \([-1, 1]\). We first find the sensitivities of \(\bar{x}\) and \( s^2 \), then use post-processing, composition, and the Laplace Mechanism to combine these to obtain the private t-statistic. If \( s^2 \) is estimated to be negative, the test statistic cannot be computed normally, and we return 0, indicating an unwillingness to reject the null hypothesis.

**Algorithm \(\hat{T}_{\text{stat}}\): Private t-Test Statistic**

**Input:** \( x, \epsilon_{\bar{x}}, \epsilon_{s^2} \)

1. \(\hat{\bar{x}} = \bar{x} + \text{Lap}\left(\frac{2}{n \epsilon_{\bar{x}}}\right)\)
2. \(\hat{s}^2 = s^2 + \text{Lap}\left(\frac{5}{(n-1) \epsilon_{s^2}}\right)\)
3. If \(\hat{s}^2 < 0\) then
   - \(\hat{T} = 0\)
4. Else
   - \(\hat{T} = \frac{\hat{\bar{x}}}{\sqrt{\hat{s}^2 / n}}\)

**Output:** \(\hat{T}\)

**Theorem 5.5.** Algorithm \(\hat{T}_{\text{stat}}\) is \((\epsilon_{\bar{x}} + \epsilon_{s^2})\)-differentially private.

**Proof.** By the Laplace mechanism, the computation of \(\hat{\bar{x}}\) is \(\epsilon_{\bar{x}}\)-differentially private and the computation of \(\hat{s}^2\) is \(\epsilon_{s^2}\)-differentially private. Since the computation of \(\hat{T}\) does not require access to the database, it is only post-processing and its release is \((\epsilon_{\bar{x}} + \epsilon_{s^2})\)-differentially private. □

### Complete t-Test

To carry out the full paired t-test, we estimate the reference distribution through simulation and release a private p-value.

**Algorithm \(\hat{T}_p\): Complete t-Test**

**Input:** \( x, \epsilon_{\bar{x}}, \epsilon_{s^2}, z \)

1. For \( k = 1 \) to \( z \):
   - \( x^* \leftarrow \) a database with \( n \) independent draws from \( N(\mu = 0, \sigma \approx 0.3) \), each truncated to \([-1, 1]\)
   - \(\hat{t} := \hat{T}_{\text{stat}}(x, \epsilon_{\bar{x}}, \epsilon_{s^2})\)
   - \( t_k \leftarrow \hat{T}_{\text{stat}}(x^*) \)
2. \( p \leftarrow \) fraction of \( t_k \) more extreme than \(\hat{t}\)

**Output:** \(\hat{t}, p\)

**Theorem 5.6.** Algorithm \(\hat{T}_p\) is \((\epsilon_{\bar{x}} + \epsilon_{s^2})\)-differentially private.

**Proof.** The computation of \(\hat{t}\) was already shown to be private. The remaining computation needed to find the p-value does not need access to the database—it is simply post-processing. By Theorem 2.4, it follows that the \(\hat{T}_p\) algorithm is also private. □

### Experimental Evaluation

For a given total \(\epsilon\), we must decide how to allocate the budget between \(\epsilon_{\bar{x}}\) and \(\epsilon_{s^2}\). Experimentally, we choose to allocate 50% of the budget to each value. This allocation does not seem to have a large effect on the power of the test.

We evaluate the power and validity of the final \(\hat{T}_p\) test. Compared to other work, Gaboardi et al. [13] developed a private one-sample t-test under the more restrictive local differential privacy model. As expected, our test in the more standard setting has much higher power. Their z-test, which assumes the variance is known, requires roughly 4000 data points to reach 80% power at \(\epsilon = 1\), while our test requires roughly 100.

### Comparison to Nonparametric Test

Since we have already developed a test for the paired-data use case, we assess the power of \(\hat{T}_p\) compared to \(\hat{W}_P^p\) by simulating synthetic data. As shown in Figure 12, \(\hat{W}_P^p\) needs 8% of the data required by \(\hat{T}_p\) to reach the same power.

### Uniformity of p-values

We experimentally ensure that the type I error rate is bounded by \(\alpha\) in Figure 13. This figure confirms that our type I error rate is bounded above by \(\alpha\). For small sample sizes, the line on the quantile-quantile plot goes above the diagonal, indicating a conservative test. At sufficiently large sample sizes, this effect vanishes.

### Conclusion

We have introduced several new tests, three of which (\(\hat{K}W_{\text{abs}}^p\), \(\hat{M}W^p\), and \(\hat{W}_P^p\)) improve upon the state of the art. These allow researchers to address inferential questions using nonparametric methods while preserving data privacy. Rank-based tests are more powerful than their parametric analogues and can be further enhanced through sensible adaptations. We hope others will continue to advance this technique, as we believe our tests are not yet optimal.

### Acknowledgments

We thank Christine Task and Chris Clifton for their generous and enlightening discussions regarding their previous work. This material is based upon work supported by the National Science Foundation under Grant No. SaTC-1817245 and the Richter Funds.

### References

[1] Jordan Awan and Aleksandra Slavković. 2018. Differentially private uniformly most powerful tests for binomial data. In Advances in Neural Information Processing Systems. 4208–4218.
...
[36] Frank Wilcoxon. 1945. Individual Comparisons by Ranking Methods. Biometrics Bulletin 1, 6 (1945), 80–83.