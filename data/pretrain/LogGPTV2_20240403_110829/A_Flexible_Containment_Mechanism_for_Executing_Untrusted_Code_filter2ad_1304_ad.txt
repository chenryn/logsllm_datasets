Process *
# , and JI are attached to sandboxes
to signal processes in I and
to signal processes in N and MO .
! . The
following rules govern the behavior of components im-
plemented using sandbox sets:
created and initialized 
! , ML , and 
! allows 
to signal pro-
 A process in a given sandbox is always allowed to
access other processes in its own sandbox or any
descendant sandboxes. For example, a process in
re-
M# may signal any process in # , 
gardless of how P#
is conÔ¨Ågured.
If a component grants access to a given sandbox,
then access is also granted to all of the sandbox‚Äôs
K , 
N , or 
It is possible to compute the complement of a sand-
!6R since 
. Clearly, *
this behavior may be understood by considering the
is aware of the
descendants. For instance, processes in Q! can sig-
nal processes in 
! grants access to L
is a descendant of L . The motivation for
and 
viewpoint of process *
existence of L . However, * can not in general be
L . All * cares about is that processes in
cesses in 
S! are granted access to all processes that 
L gov-
expected to keep track of actions, such as creating
child sandboxes, that may be performed by pro-
erns. Thus this rule allows processes to manipulate
components without needing to be aware of details
that are outside their scope of concern.
 A process in a given sandbox may delegate to child
sandboxes any access rights to other sandboxes that
# so
! has adjusted 
it possesses. For example, 
that its privilege for signaling processes in SL
# may adjust JI
passed down to 
so that processes in K can signal processes in L .
However, M# may not adjust 
I so that processes in
K are granted access to T! , M# , or VU . This is be-
cause # does not have access to T! , M# , or VU . In
general, any sandboxes in shaded area -
tentially appear in W! . However, X! can not specify
S!6R directly because T!6R
is outside X! ‚Äôs scope of
could potentially appear in P# .
or Y
concern. Likewise, any sandboxes in shaded areas
in any sandbox are
 All processes that are not
grouped together as if they are all inside a common
sandbox that imposes no restrictions. This can be
thought of as the ‚Äùnull sandbox‚Äù, and may be spec-
iÔ¨Åed in a sandbox set just like any other sandbox.
# . Similarly, 
but not Z
could po-
is
!
#
O

-

box set. For instance, the complement of the set
all sandboxes (including the null sandbox) except
given by 
I would be a set that grants access to
MN and O . Likewise, intersections and unions of
sandbox sets may be computed.
Sandbox sets are implemented internally using a global
matrix. Columns represent sandboxes and rows repre-
sent components that are implemented as sandbox sets.
so that it grants access to a
is accomplished by adding an entry to the ma-
Adjusting a component 
sandbox 
trix at position 
[0A( . When a component is destroyed,
its corresponding row is removed from the matrix. Like-
wise, destruction of a sandbox results in the removal of
its associated column. This ensures that components do
not refer to sandboxes that no longer exist.
3.3 Signal, ptrace(), and IPC Components
is viewed as owning -
Signal components specify processes to which a sand-
boxed process may send signals. Likewise, ptrace()
components specify which processes a sandboxed pro-
cess may ptrace(). Both of these component types
are implemented as sandbox sets. IPC components spec-
ify which IPC objects6 a sandboxed process may access.
creates an IPC ob-
. Suppose that
is subsequently de-
still exists. In this case, ownership of
has no parent, then own-
If a process executing in sandbox 
ject -
, then 
has a parent sandbox \
, and 
stroyed while -
is transferred to \
If 
ership of -
is transferred to the null sandbox when 
is destroyed. Given this notion of ownership, sandbox
sets may be used to implement IPC components. For in-
stance, suppose that the components shown in Figure 5
to
is a
are IPC components. Then W! allows processes in Q!
access IPC objects owned by 
L or S!6R , since T!]R
descendant of 
L .
.
3.4 File System Component
File system components specify Ô¨Åle-related privileges.
They are represented as trees of directory paths with la-
bels that specify privileges at each node. The following
types of privileges are deÔ¨Åned:
_^ : For a normal Ô¨Åle, this privilege allows the Ô¨Åle to
be opened for reading. For a directory, it allows the
directory contents to be listed.
6semaphores, message queues, and shared memory segments
n1
S
n2
U
T
n3
n4
...
n5
...
n6
...
Figure 6: Directory subtree
: For a normal Ô¨Åle, this privilege allows the Ô¨Åle to
_`
be opened for writing. For a directory, it allows Ô¨Åles
in the directory to be created, unlinked, or renamed.
 : For a normal Ô¨Åle, this privilege allows the Ô¨Åle to
be executed. For a directory, this privilege has no
meaning.
* : For both normal Ô¨Åles and directories,
this
privilege allows permission-related settings to be
changed. SpeciÔ¨Åcally, it allows use of chmod(),
chown(), and chgrp().
_a : For both normal Ô¨Åles and directories, this privi-
lege allows changing access and modiÔ¨Åcation times
using utime().
cb : For a directory, this privilege allows opening
Ô¨Åles in the directory, accessing subdirectories, and
moving into the directory using chdir(). For a
normal Ô¨Åle, this privilege has no meaning.
For each of these privileges, a set of three labels is at-
tached to each node. Figure 6 illustrates the meanings
consists of the entire subtree rooted
of the labels. Set 
at directory dQ! . Set \
dren. Set e
the three labels attached to dQ!
deÔ¨Åned as follows:
consists of dQ! and all of its chil-
consists only of dQ! . Given these deÔ¨Ånitions,
for a given privilege are
self: This label represents set e
dT! ).
(consisting of only
-



children: This label represents the set of nodes de-
in the Ô¨Ågure).
Ô¨Åned by \gf_e
(dS# and d
 grandchild subtrees: This label represents the set
U , dK , dN , and all of
of nodes deÔ¨Åned by _fh\
their descendants).
(d
Each label may be assigned one of three values: allow,
deny, or unspeciÔ¨Åed. Labels are ordered according to
two simple precedence rules. Labels with higher prece-
dence override the settings of labels with lower prece-
dence. The rules are as follows:
 A label at a node has higher precedence than labels
at any of its ancestors.
 There is no ordering among the three labels at a
node. This is because the labels represent disjoint
sets of nodes.
A label of unspeciÔ¨Åed on a node imposes no particular
setting on it or its descendants. Settings are instead de-
termined by labels of higher precedence. A Ô¨Åle system
component consisting of an empty tree denies all Ô¨Åle-
related privileges.
Figure 7 illustrates a Ô¨Åle system component. It shows
labels only for the ` privilege. Labels for the other Ô¨Åve
privileges have been omitted for simplicity. Given the
above rules, this Ô¨Åle system component is interpreted as
follows:
 Write access to the root directory is allowed, since
its self label has a value of allow.
 Write access is denied for all Ô¨Åles in the root direc-
tory except /a. Since the children label of the root
directory is unspeciÔ¨Åed, it takes on the default value
of deny that denies all Ô¨Åle-related privileges for an
empty tree.
 Write access is also denied to /a. Since its self
label and the root directory‚Äôs children label are both
unspeciÔ¨Åed, it takes on the default value of deny
that denies all Ô¨Åle-related privileges for an empty
tree.
 For all Ô¨Åles in /a except /a/b, write access is de-
nied. This is due to the setting of the children label
for /a.
 Write access is allowed for the Ô¨Åle /a/b, since its
self label has a value of allow.
u
u
u
u
u
/
a
b
self
children
grandchild subtrees
self
children
grandchild subtrees
self
children
grandchild subtrees
= allow
= deny
= unspecified
u
Figure 7: File system component
 Write access is allowed for all descendants of
/a/b. This is because the grandchild subtrees la-
bel of the root directory is not overridden by any la-
bels with higher precedence that affect descendants
of /a/b.
Before Ô¨Åle-related privilege checks are performed,
names of Ô¨Åles are converted to absolute pathnames that
contain no symbolic links. Therefore symbolic links do
not affect the behavior of Ô¨Åle system components. How-
ever, the Ô¨Åle system component must do extra privilege
checking when a sandboxed process attempts to create
a hard link. Before allowing this type of operation to
proceed, the Ô¨Åle system component computes the Ô¨Åle-
related privileges that the link would have if it existed.
If these privileges exceed the privileges of the pathname
being linked to, then the operation is denied. This pre-
vents a sandboxed process from gaining unauthorized
access to Ô¨Åles simply by creating links to them in direc-
tories with more permissive settings. It can be shown
that the set of all possible Ô¨Åle system components is
closed under the operations of union, intersection, and
complement. However, we omit the proof for the sake
of brevity.
3.5 Network Component
A network component consists of two interval lists that
specify IP addresses that sandboxed processes may open
connections to and ports that sandboxed processes may
receive incoming connections from.

I
fork()
execve() exit()
wait()
total latency (i sec.)
overhead (i sec.)
overhead (% of total)
169
6.8
4.0
375
1.2
0.3
145
5.9
4.1
‚Äî
11.2
‚Äî
Table 1: Performance impact of sandboxing mechanism
3.6 Device Component
A device component consists of three interval lists that
specify read(), write(), and ioctl() privileges
for various device numbers.
3.7 System Management Component
In its current implementation, the system management
component is simply a set of Boolean Ô¨Çags that govern
administrative actions such as rebooting and setting sys-
tem date/time. The set of operations currently governed
by this component type is not comprehensive, and will
eventually be extended.
4 Performance
In order to be practical, a security mechanism must not
require an unreasonable amount of performance over-
head. To demonstrate the feasibility of our design, we
have therefore performed several microbenchmarks.
Our implementation involves modifying fork(), ex-
ecve(), exit(), and wait(). We have therefore
measured the amount of overhead that our mechanism
adds to each of these system calls. All experiments were
performed on a uniprocessor 266 MHz Pentium II PC
with 96 Mb of memory. The Linux kernel we used is an
SMP build of version 2.4.1. Each value in Table 1 rep-
resents the mean value from 10000 separate system call
invocations. As shown, our modiÔ¨Åcations typically add
several microseconds to each call.
During a fork(), sandbox-related state information
must be copied from the parent process to the child.
On execve(), a check is performed to see if a sand-
box must be applied due to a previous invocation of
sbxapply() with the ‚Äùapply on exec‚Äù option speci-
Ô¨Åed. The values in Table 1 reÔ¨Çect the typical case in
which no sandbox is applied. We measured separately
the latency of an sbxapply() system call (without
‚Äùapply on exec‚Äù speciÔ¨Åed) and found that value to be
56 microseconds.
During an exit() system call, our implementation
closes any open descriptors for sandboxes and compo-
nents.
It then releases the reference to any sandbox
the process may be executing within and does a partial
cleanup of the sandbox if the reference count drops to
0. Additional cleanup of sandbox-related state is per-
formed during wait() when the zombie process is col-
lected. At this time, the expired sandbox is queued so
that a kernel thread may perform the Ô¨Ånal cleanup. The
values for exit() and wait() in Table 1 represent
the case in which this cleanup activity occurs for a sin-
gle expired sandbox. The purpose of the kernel thread
is to remove the sandbox from the global matrix de-
scribed in Section 3.2 and free the memory that it oc-
cupies. The thread is awakened periodically when the
number of expired objects on its queue reaches a certain
threshold. It then deletes all of them in a single oper-
ation. We measured the time required to delete 1024
expired sandboxes, and found that this operation takes
2829 microseconds (2.8 i sec. per sandbox). This repre-
sents the mean for 10 separate invocations of the kernel
thread. Adding the per-sandbox value to the overhead
values in Table 1 for exit() and wait() provides a