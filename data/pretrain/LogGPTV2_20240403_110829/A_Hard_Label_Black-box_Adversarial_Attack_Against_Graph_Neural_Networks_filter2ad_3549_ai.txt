𝑄 .
Proof. The proof can be found in [12] Lemma 2.
2] ≤ 4(𝑄+1)
Lemma D.2. E[∥ (cid:164)▽𝑝(Θ𝑡; 𝑢𝑞)−▽𝑝𝜇(Θ𝑡)∥2
□
𝑄 𝐶(𝑑, 𝜇),
𝑄 𝜎2+ 2
where 𝐶(𝑑, 𝜇) = 2𝑑𝜎2 + 𝜇2𝐿2𝑑2
.
2
Proof. The proof can be found in [28] proposition 2 with 𝑏 = 1,
𝑞 = 𝑄, 𝛼𝑏 = 1 and 𝛽𝑏 = 0. As the number of objective function is
just one in our optimization problem, so we can choose 𝑏 = 1. Then
𝛼𝑏 and 𝛽𝑏 can be further fixed.
□
Lemma D.3. 𝑝𝜇(Θ1) − 𝑝𝜇(Θ𝑇) ≤ 𝑝𝜇(Θ1) − 𝑝∗ + 𝜇2𝐿, where 𝑝∗ is
the minimal value of 𝑝(Θ).
Proof. The proof can be found in [29] Lemma C.
Lemma D.4. E[∥▽𝑝(Θ)∥2] ≤ √2E[∥▽𝑝𝜇(Θ)∥2] + 𝜇𝐿𝑑√2
Proof. The proof can be found in [28].
□
□
Now we prove our Theorem 4.3. As 𝑝(Θ) has an 𝐿-Lipschitz
continuous gradient, it is known from [36] that 𝑝𝜇(Θ) also has
𝐿-Lipschitz continuous gradient. Based on the 𝐿-smoothness of
𝑝𝜇(Θ), we have
𝑝𝜇 (Θ𝑡+1) ≤ 𝑝𝜇 (Θ𝑡) +(cid:10)▽𝑝𝜇 (Θ𝑡), Θ𝑡+1 − Θ𝑡(cid:11) + 𝐿
= 𝑝𝜇 (Θ𝑡) − 𝜂𝑡(cid:10)▽𝑝𝜇 (Θ𝑡), ˆ𝑝𝑡(cid:11) + 𝐿
(cid:12)(cid:12)(cid:12)𝑄
𝑡 ∥ ˆ𝑝𝑡 ∥2
2 𝜂2
2
Moreover, we define (𝑆𝑡)𝑙 =
𝑞=1 ˆ▽𝑝(Θ𝑡; 𝑢𝑞)𝑙
(cid:10)▽𝑝𝜇 (Θ𝑡), ˆ𝑝𝑡(cid:11) = ∥▽𝑝𝜇 (Θ𝑡) ∥2∥ ˆ𝑝𝑡 ∥2𝑐𝑜𝑠(𝛼1𝑡)
𝑆𝑡 ⊙ 𝑠𝑖𝑔𝑛( ˆ𝑝𝑡) and ∥ ˆ𝑝𝑡 ∥2 = ∥𝑆𝑡 ∥2. We can also have
= ∥▽𝑝𝜇 (Θ𝑡) ∥2∥𝑆𝑡 ∥2𝑐𝑜𝑠(𝛼1𝑡) 𝑐𝑜𝑠(𝛼2𝑡)
𝑐𝑜𝑠(𝛼2𝑡)
= ∥▽𝑝𝜇 (Θ𝑡) ∥2∥𝑠𝑖𝑔𝑛( ˆ𝑝𝑡) ∥2𝑐𝑜𝑠(𝛼2𝑡) · 𝑐𝑜𝑠(𝛼1𝑡)
=(cid:10)▽𝑝𝜇 (Θ𝑡), 𝑠𝑖𝑔𝑛( ˆ𝑝𝑡)(cid:11) · 𝑐𝑜𝑠(𝛼1𝑡)
𝑐𝑜𝑠(𝛼2𝑡)
∥𝑆𝑡 ∥2√
1
𝑄
,
𝑐𝑜𝑠(𝛼2𝑡)
𝑑
2 ∥Θ𝑡+1 − Θ𝑡 ∥2
2
(33)
(cid:12)(cid:12)(cid:12), and thus ˆ𝑝𝑡 =
∥𝑠𝑖𝑔𝑛( ˆ𝑝𝑡) ∥2
∥𝑠𝑖𝑔𝑛( ˆ𝑝𝑡) ∥2
∥𝑆𝑡 ∥2√
𝑑
(34)
where 𝛼1𝑡 is the angle between ▽𝑝𝜇(Θ𝑡) and ˆ𝑝𝑡 and 𝛼2𝑡 is the angle
between ▽𝑝𝜇(Θ𝑡) and 𝑠𝑖𝑔𝑛( ˆ𝑝𝑡). Substituting Eq. (34) into Eq. (33),
and defining ˆ𝜂𝑡 = 𝜂𝑡 · 𝑐𝑜𝑠(𝛼1𝑡)
𝑝𝜇 (Θ𝑡+1) ≤ 𝑝𝜇 (Θ𝑡) − ˆ𝜂𝑡(cid:10)▽𝑝𝜇 (Θ𝑡), 𝑠𝑖𝑔𝑛( ˆ𝑝𝑡)(cid:11) + 𝑑𝐿
𝑐𝑜𝑠(𝛼2𝑡)
,we have
∥𝑆𝑡 ∥2√
𝑑
𝑐𝑜𝑠(𝛼2𝑡)2
𝑐𝑜𝑠(𝛼1𝑡)2
2
ˆ𝜂2
𝑡
𝑐𝑜𝑠(𝛼2𝑡)2
𝑐𝑜𝑠(𝛼1𝑡)2
= 𝑝𝜇 (Θ𝑡) − ˆ𝜂𝑡 ∥▽𝑝𝜇 (Θ𝑡) ∥1 + 𝑑𝐿
2
(cid:12)(cid:12)(▽𝑝𝜇 (Θ𝑡))𝑙
ˆ𝜂2
𝑡
(cid:12)(cid:12) I[𝑠𝑖𝑔𝑛(( ˆ𝑝𝑡)𝑙) ≠ 𝑠𝑖𝑔𝑛((▽𝑝𝜇 (Θ𝑡))𝑙)]
𝑙=1
𝑑
+ 2 ˆ𝜂𝑡
Let 𝑐𝑡 = 𝑐𝑜𝑠(𝛼2𝑡)
𝑑
+ 2 ˆ𝜂𝑡
𝑙=1
𝑐𝑜𝑠(𝛼1𝑡) and take expectation on both sides, we have
E[𝑝𝜇 (Θ𝑡+1) − 𝑝𝜇 (Θ𝑡)] ≤ − ˆ𝜂𝑡 ∥▽𝑝𝜇 (Θ𝑡) ∥1 + 𝑑𝐿
2
ˆ𝜂2
𝑡 𝑐2
𝑡
(cid:12)(cid:12)(▽𝑝𝜇 (Θ𝑡))𝑙
(cid:12)(cid:12) 𝑃𝑟𝑜𝑏[( ˆ𝑝𝑡)𝑙 ≠ 𝑠𝑖𝑔𝑛((▽𝑝𝜇 (Θ𝑡))𝑙)]
𝑑
𝑡 + 2 ˆ𝜂𝑡√
ˆ𝜂2
𝑡 𝑐2
𝑄
𝑙=1
E[𝑝𝜇 (Θ𝑡+1) − 𝑝𝜇 (Θ𝑡)] ≤ − ˆ𝜂𝑡 ∥▽𝑝𝜇 (Θ𝑡) ∥1 + 𝑑𝐿
2
Applying Lemma D.1 into the inequality, we have
Note that
(35)
(36)
𝛿𝑙
(37)
(38)
√
𝑑 ∥𝛿 ∥2
(cid:113)
𝛿𝑙 ≤ ∥𝛿 ∥1 ≤
𝑙=1
√
𝑑
𝑑
(cid:115)
=
≤
𝑑
𝑄
E[∥ (cid:164)▽𝑝(Θ𝑡 ; 𝑢𝑞) − ▽𝑝𝜇 (Θ𝑡) ∥2
2]
(cid:113)4(𝑄 + 1)𝜎2 + 2𝐶(𝑑, 𝜇),
Session 1B: Attacks and Robustness CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea124where we apply Lemma D.2 in the last inequality in Equation (38).
Substituting Equation (38) into Equation (37), we have
ˆ𝜂2
𝑡 𝑐2
ˆ𝜂𝑡 ∥▽𝑝𝜇 (Θ𝑡) ∥1 ≤ E[𝑝𝜇 (Θ𝑡) − 𝑝𝜇 (Θ𝑡+1)] + 𝑑𝐿
2
𝑡
ˆ𝜂𝑡𝑇
If we randomly pick 𝑅 from {1, . . . ,𝑇} with probability 𝑃 (𝑅 = 𝑡) =
𝑡=1 ˆ𝜂𝑡
, we will have
E[∥▽𝑝𝜇(Θ𝑅)∥2] = E[E𝑅[∥▽𝑝𝜇(Θ𝑅)∥2]]
By summing all inequalities for all 𝑡s we obtain
ˆ𝜂𝑡 E[∥▽𝑝𝜇 (Θ𝑡) ∥1] ≤ E[𝑝𝜇 (Θ1) − 𝑝𝜇 (Θ𝑇 )] + 𝑑𝐿
2
𝑇
𝑡=1
(39)
(40)
√
𝑑 ˆ𝜂𝑡
+ 2
𝑄
+ 𝑇
𝑡=1
ˆ𝜂2
𝑡 𝑐2
(cid:113)4(𝑄 + 1)𝜎2 + 2𝐶(𝑑, 𝜇)
𝑇
(cid:113)4(𝑄 + 1)𝜎2 + 2𝐶(𝑑, 𝜇)
𝑇
(cid:113)4(𝑄 + 1)𝜎2 + 2𝐶(𝑑, 𝜇)
ˆ𝜂2
𝑡 𝑐2
√
𝑑 ˆ𝜂𝑡
2
𝑄
𝑡=1
𝑡=1
𝑡
𝑡
𝑡=1
√
𝑑 ˆ𝜂𝑡
2
𝑄
+ 𝑇
Further substituting Lemma D.3 into Inequality (40), we have
ˆ𝜂𝑡 E[∥▽𝑝𝜇 (Θ𝑡) ∥1] ≤ 𝑝𝜇 (Θ1) − 𝑝∗ + 𝜇2𝐿 + 𝑑𝐿
2
𝑇
Dividing𝑇
𝑡=1 ˆ𝜂𝑡 on both sides and use the property that ∥▽𝑝𝜇(Θ𝑡)∥2 ≤
𝑇
ˆ𝜂𝑡𝑇
E[∥▽𝑝𝜇 (Θ𝑡) ∥2] ≤ 𝑝𝜇 (Θ1) − 𝑝∗ + 𝜇2𝐿
𝑇
𝑇
𝑡=1 ˆ𝜂2
𝑡 𝑐2
𝑡=1 ˆ𝜂𝑡
(cid:113)4(𝑄 + 1)𝜎2 + 2𝐶(𝑑, 𝜇)
∥▽𝑝𝜇(Θ𝑡)∥1, the inequality (41) can be changed into
𝑡=1 ˆ𝜂𝑡
+𝑑𝐿
2
√
+ 2
𝑑
𝑄
𝑇
𝑡=1 ˆ𝜂𝑡
(41)
(42)
𝑡=1
𝑡=1
𝑡
= E[ 𝑇
𝑃(𝑅 = 𝑡)∥▽𝑝𝜇(Θ𝑡)∥2]
𝑡=1
Applying Lemma D.4 into the Equation (43), we have
𝑡=1 ˆ𝜂2
𝑡 𝑐2
𝑡=1 ˆ𝜂𝑡
√2(𝑝𝜇 (Θ1) − 𝑝∗ + 𝜇2𝐿)
E[∥▽𝑝(Θ) ∥2] ≤
𝑇
𝑇
(cid:113)4(𝑄 + 1)𝜎2 + 2𝐶(𝑑, 𝜇)
𝑇
𝑡=1 ˆ𝜂𝑡
√
+ 2
2𝑑
𝑄
) and 𝜂𝑡 = 𝜂 = 𝑂(
+ 𝑑𝐿√2
By choosing 𝜇 = 𝑂(
𝑡
+ 𝜇𝐿𝑑√2
1√
𝑑𝑇
gence rate in (44) simplifies to
E[∥▽𝑝(Θ) ∥2] ≤ 𝑂(
√
𝑑𝐿√
𝑇
√
𝑑√
𝑄
+
1√
𝑑𝑇
(cid:112)𝑄 + 𝑑).
), the conver-
(45)
(43)
(44)
Session 1B: Attacks and Robustness CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea125