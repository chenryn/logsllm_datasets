title:A portable user-level approach for system-wide integrity protection
author:Wai-Kit Sze and
R. Sekar
A Portable User-Level Approach for
System-wide Integrity Protection†
Wai-Kit Sze and R. Sekar
Stony Brook University
Stony Brook, NY, USA
ABSTRACT
In this paper, we develop an approach for protecting system in-
tegrity from untrusted code that may harbor sophisticated malware.
We develop a novel dual-sandboxing architecture to conﬁne not
only untrusted, but also benign processes. Our sandboxes place
only a few restrictions, thereby permitting most applications to
function normally. Our implementation is performed entirely at
the user-level, requiring no changes to the kernel. This enabled us
to port the system easily from Linux to BSD. Our experimental re-
sults show that our approach preserves the usability of applications,
while offering strong protection and good performance. Moreover,
policy development is almost entirely automated, sparing users and
administrators this cumbersome and difﬁcult task.
1.
Introduction
The state-of-practice in malware defense relies on reactive mea-
sures, such as virus scanning and software patches. While this prac-
tice may have been adequate in the past, it cannot cope with today’s
sophisticated malware that employ complex evasion and subversion
techniques to overcome deployed defenses. It is thus important to
develop principled defenses that provide reliable protection regard-
less of malware sophistication.
A natural (and perhaps the best studied) proactive defense is to
sandbox potentially malicious code. This approach can be applied
to software from untrusted sources [11], which may be malicious
to begin with; or to software from trusted sources [16, 6, 20] that is
benign to start with, but turns malicious due to an exploit. However,
there are several challenges with sandboxing untrusted code:
• Difﬁculty of policy development. Experience with SELinux [16]
and other projects [3, 22] show that policy development requires
a great deal of expertise and effort. Moreover, policies that
provide even modest protection from untrusted code can break
many legitimate applications.
• Subversion attacks on benign software. Even highly restrictive
policies can be inadequate, as malware can co-opt benign appli-
cations to carry out prohibited operations: Malware may trick a
user to run a benign application in insecure ways or exploit vul-
nerabilities in benign applications to perform arbitrary actions.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ACSAC ’13, December 09 - 13 2013, New Orleans, LA, USA
Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2015-3/13/12 ...$15.00.
http://dx.doi.org/10.1145/2523649.2523655
• Difﬁculty of secure policy enforcement. Non-bypassable poli-
cies usually have to be enforced in the OS kernel. They are usu-
ally much harder to develop than user-level defenses. Moreover,
kernel-based solutions cannot be easily ported across different
OSes, or even different versions of the same OS.
An alternative to sandboxing is isolated execution of untrusted code.
One-way isolation [15, 23] permits untrusted software to read any-
thing, but its outputs are held in isolation. Two-way isolation limits
both reads and writes, holding the inputs as well as outputs of un-
trusted applications in an isolated environment. The app model on
Android, Apple iOS, and Windows 8 sandbox are generally based
on this two-way isolation model.
Isolation approaches provide stronger protection from malware
since they block all interactions between untrusted and benign soft-
ware, thereby preventing subversion attacks. They also provide
much better usability because they permit sufﬁcient access for most
applications to work. However, they too have several signiﬁcant
drawbacks, especially in the desktop environment:
• Fragmentation of user data. Unlike sandboxing, which contin-
ues to support the model of a single namespace for all user data,
isolation causes a fragmentation: user data is partitioned into
two or more containers, each representing a disjoint namespace.
• Inability to compose applications. The hallmark of today’s desk-
top OSes is the ability to compose applications together. UNIX
pipelines represented one of the early examples of application
composition. Other common forms of composition can happen
through ﬁles or scripts, e.g., printing a spread sheet into a PDF
ﬁle and then emailing this PDF ﬁle. Unfortunately, strict isola-
tion prevents one application from interacting with any data (or
code) of other applications, thus precluding composition.
• No protection when isolation is breached. Strict isolation may
be breached either due to a policy relaxation, or through manual
copying of ﬁles across isolation contexts. Any malware present
in such ﬁles can subsequently damage the system.
In contrast, our approach combines the strengths of sandboxing
and isolation of untrusted code, while avoiding most of their weak-
nesses. Like sandboxing, all user data is held within one name
space, thereby providing a uniﬁed view. Like isolation, our ap-
proach preserves the usability of applications, and does not require
signiﬁcant policy development effort. At the same time, it avoids
the weakness of isolation-based approaches, allowing most typi-
cal interactions between applications, while ensuring that system
security isn’t compromised by these interactions. An open-source
implementation of our system is available [26].
†
This work was supported in part by grants from NSF (CNS-
0831298) and AFOSR (FA9550-09-1-0539).
219
Term
malicious
untrusted
Explanation
intentionally violate policy, evade enforcement
possibly malicious
benign program non-malicious but may contain vulnerabilities
benign process
process whose code and inputs are benign,
hence non-malicious
Figure 1: Key terminology
1.1 Approach Overview and Salient Features
Sophisticated malware can evade defenses using multi-step at-
tacks, with each step performing a seemingly innocuous action.
For instance, malware may simply deposit a shortcut on the desk-
top with a name of a commonly used application instead of writing
ﬁles in system directories directly. It can wait until the user double-
clicks on this shortcut and do its work. Alternatively, malware may
deposit ﬁles that contain exploits for popular applications, with the
actual damage inﬂicted when a curious user opens them. The ﬁrst
example involves a benign process executing code derived from a
malicious source, while the second example involves a vulnerable
benign application being compromised by malicious data.
To thwart all malware attacks regardless of the number of steps
involved, we use integrity labels to systematically track the inﬂu-
ence of untrusted sources on all ﬁles. Files coming from the OS
vendor (and any other source that is trusted to be non-malicious)
are given the label benign (Figure 1), while the remaining ﬁles are
given the label untrusted. Note that benign programs may con-
tain exploitable vulnerabilities, but only untrusted programs can be
malicious, i.e., may intentionally violate policy and/or attempt to
evade enforcement. Exploitation of vulnerabilities can cause be-
nign programs to turn malicious. However, an exploit represents
an intentional subversion of security policies, and hence cannot oc-
cur without the involvement of malicious entities. Consequently,
benign processes, which are processes that have never been inﬂu-
enced by untrusted content, cannot be malicious. New ﬁles and
processes created by benign processes can hence be labeled benign.
Processes that execute untrusted code (or read untrusted inputs), are
labeled as untrusted, as are the ﬁles created or written by them.
The core of our approach is information-ﬂow based integrity
preservation, similar to the Biba integrity model [5]. Our main
contribution is that of solving the key challenges in adopting such
a model to contemporary operating systems:
• Secure information-ﬂow tracking and policy enforcement with-
out OS kernel changes. Absence of kernel changes not only
simpliﬁes the implementation but also makes it possible to ex-
periment with the large base of existing OS and application soft-
ware. Moreover, it leads to a smaller TCB, and makes the im-
plementation portable across OSes.
• Preserving user experience. Enforcement of mandatory access
control (MAC) policies such as MLS or Biba model can often
break existing applications, since many previously permitted op-
erations are now disallowed by the MAC policy. Our approach
incorporates several reﬁnements to the basic information ﬂow
policy that preserve functionality without degrading integrity.
As a result, our approach can preserve the user experience on
contemporary OSes, as shown by our experiments.
• Automating policy development. Policy reﬁnements often come
with a steep price: they require substantial development efforts,
typically for every application. Thus, protecting an entire OS
distribution can become prohibitively expensive if policies have
to be developed manually. We therefore present techniques that
automate policy development in almost all cases.
1.1.1 Secure enforcement and tracking without OS changes
Our approach encodes integrity labels into ﬁle ownership and
permission. In particular, untrusted ﬁles are those that are owned
by a set of newly created untrusted userids, or are writable by these
users. Untrusted processes are all run with an untrusted userid.
This encoding enables us to leverage existing OS mechanisms for
tracking and propagating integrity labels. In particular, note that
ﬁles as well as child processes inherit their ownership from that
of the process that created them. As a result, any ﬁle or process
created by an untrusted process will have the label of untrusted.
Benign processes and ﬁles are characterized by their ownership
by a userid other than an untrusted userid. In addition, benign ﬁles
will have write permissions that make them unwritable by untrusted
userids. As a result, ﬁles created by benign processes will have
benign labels, once again ensuring correct propagation of labels.
In addition to tracking integrity labels, our userid-based encod-
ing also provides the foundation for sound policy enforcement with-
out OS kernel changes. Speciﬁcally, existing OS mechanisms can
correctly enforce policies on untrusted processes: by virtue of our
integrity label encoding, benign ﬁles have permission settings that
make them unwritable by untrusted userids. Although we need to
develop additional enforcement mechanisms for benign processes,
e.g., to prevent them from reading untrusted ﬁles, this is a con-
siderably simpler task than policy enforcement on untrusted code.
In particular, challenges in secure policy enforcement arise mainly
due to evasion attacks. Since benign processes cannot be malicious,
they won’t attempt evasion. Indeed, a simple yet secure implemen-
tation can be developed within the address space of a benign pro-
cess, e.g., by replacing libc, which makes all system calls on behalf
of a process, with a version that enforces the desired policies.
1.1.2 Preserving user experience
Increased security is usually achieved through stronger security
policies. These stronger policies will invariably deny some (oth-
erwise allowed) operations, thus impacting functionality. While
careful policy development may reduce the scope of functionality
loss, experience with SELinux [16] and other projects [3, 22] show
that (a) the effort and expertise involved in developing good poli-
cies is considerable, and (b) the resulting policies can still lead to
unacceptable loss of functionality (or security). The fundamental
problem is that ﬁnding the “boundary” between legitimate and inse-
cure behaviors can be very hard. For instance, consider identifying
the complete set of ﬁles that must be protected to ensure host in-
tegrity. An overly general list will cause untrusted applications to
fail because their ﬁle accesses are denied, while omissions in this
list will impact benign system operations. If untrusted software is
prevented from writing any ﬁles within a user’s home directory, this
can affect its usability. If, on the other hand, it is permitted to write
any ﬁle, it may be able to install backdoors into the user’s account,
e.g., by modifying ﬁles that are automatically executed with user’s
privileges, such as the .bashrc ﬁle.
We overcome the dilemma with a novel dual-sandbox architec-
ture. The ﬁrst of these sandboxes performs eager policy enforce-
ment. To minimize breaking legitimate functionality, it blocks only
those operations that can cause irreparable damage, e.g., overwrit-
ing an existing benign ﬁle. This sandbox, called untrusted sandbox
(U), needs to be secure against any attempts to circumvent it.
Operations with unclear security impact, such as the creation of
new ﬁles, are left alone by the second sandbox, called benign sand-
box (B). While these actions could very well be malicious, there
isn’t enough information to make that conclusion with conﬁdence.
Hence, we rely on B to observe subsequent effects of this action to
determine if it needed to be stopped. For instance, if such a ﬁle is
220
used by a benign process, it could compromise the benign process.
B prevents such use.
Our dual-sandbox architecture achieves several important goals:
First, it provides robust enforcement of complex policies without
requiring OS kernel modiﬁcations. Second, it preserves function-
ality of both benign and untrusted applications by implementing
many important transparency features, so that security beneﬁts of
our approach can be achieved without requiring changes to appli-
cations, or the way in which users use them.
1.1.3 Automating policy development
To build a practical system that preserves user experience, we
need as much (if not more) emphasis on the policies as on the en-
forcement mechanisms. However, policy development is often a
manual process that requires careful consideration of every appli-
cation and ﬁle on the system. Given that a typical Linux system
may have thousands of applications and many tens of thousands
of ﬁles, this becomes a truly daunting task. We have therefore de-
veloped a procedure for classifying ﬁles into different categories:
code, conﬁguration, preference and data. Based on this inference,
we provide a detailed policy that works without needing manual
analysis of applications or ﬁle residing on the system.
1.2 Paper Organization
Section 2 details our approach for information-ﬂow tracking and
describes the untrusted sandbox U. Section 3 describes benign
sandbox B. Policy inference is described in Section 4, followed
by a description of our implementation and evaluation (Section 5).
Related work is discussed in Section 6, followed by concluding re-
marks in Section 7.
2. Containing Untrusted Processes
Our untrusted sandbox, illustrated in Figure 2, consists of a sim-
ple inner sandbox UI based on OS-provided access control mecha-
nisms, and an outer sandbox that is realized using a library UL and
a user-level helper process UH.
The inner sandbox UI enforces an isolation policy that limits
untrusted processes so that they can only write untrusted ﬁles (Sec-
tion 2.1). This strict policy, by itself, can cause many untrusted ap-
plications to fail. The transparency library UL (Section 2.2) com-
ponent of the outer sandbox masks these failures so that applica-
tions can continue to operate as if they were executing directly on
the underlying OS. In particular, UL remaps some of the failed re-
quests (primarily, system calls) so that they would be permitted by
UI. In other cases, it forwards the request to the helper process UH,
which runs with the userid of a normal user, to carry out the request.
The helper UH uses a policy that is more permissive than the inner
sandbox, but will still ensure information-ﬂow based integrity.
In addition to modifying or relaying requests from untrusted pro-
cesses, the transparency library UL may also modify the responses
returned to them in order to preserve their native behavior. We pro-
vide two examples of remapping/relaying to illustrate its beneﬁt:
• When a benign application is run with untrusted inputs, it will
execute as an untrusted process, and hence will not be able to
update its preference ﬁles. To avoid application failures that may
result due to this, UL can redirect these accesses to untrusted
private copies of such ﬁles.
• Untrusted applications will experience a failure when they at-
tempt to create ﬁles in the home directory of a user u, since this
directory is not writable by untrusted userids. In this case, UL
can forward the request to the helper process, which runs with
the privileges of u and hence can perform this access.
Untrusted Process
1
8
Transparency Library UL
2
3
Inner Sandbox UI
Outer Sandbox
Helper
Process
UH
5
6
7
4
OS
Figure 2: Untrusted sandbox
Whether a particular ﬁle access is remapped/relayed is determined
by security policies, a topic further discussed in Section 4. Simi-
larly, the policy enforced by UH is also discussed below.
2.1
Inner Sandbox UI
Contemporary desktop OSes provide access control mechanisms
for protecting system resources such as ﬁles and IPCs. Moreover,
processes belonging to different users are isolated from each other.
We repurpose this mechanism to realize the inner sandbox. Such
repurposing would, in general, require some changes to ﬁle permis-
sions, but our design was conceived to minimize such changes: our
implementation on Ubuntu Linux required changing permissions
on less than 60 ﬁles (Section 5). Moreover, it preserves all of the
functionality relating to the ability of users to share access to ﬁles.
The basic idea is to run untrusted processes with newly-created
userids that have very little, if any, direct access to modify the ﬁle
system. For each non-root userid1 R in the original system, we
add a corresponding untrusted userid Ru. Similarly, for each ex-
isting group G, we create an untrusted group Gu that consists of
all userids in G and their corresponding untrusted userids. To fur-