Volatility in the set of originated prefixes: So far, we developed
metrics that can capture volatility in the number of originated
prefixes over time. Next, we are interested in the stability of the set
of originated prefixes. In particular, we want to capture if an AS
typically advertises a fixed set of prefixes (the legitimate case) or if
it “hops” through a large number of unique prefixes. To this end,
we compute the median number of originated prefixes per AS, and
we divide this median by the total number of unique prefixes this
AS ever announced over the course of 5 years. The distribution of
this ratio for legitimate and hijacker ASes (Figure 4c) suggests that
serial hijackers tend to show a lower ratio compared to legitimate
ASes, which indicates that they have a higher turnover of prefixes.
Note however, that some legitimate ASes also show a low ratio,
Profiling BGP Serial Hijackers
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
(a) Fraction of active time and offline drop
count per AS. Many hijacker ASes are only
intermittently visible in the global rout-
ing table, resulting in an active time < 1
and multiple instances of offline drops.
(b) Example ASes: Monthly prefix count
range normalized by median prefix count.
The hijacker AS shows higher volatility in
the number of advertised prefixes result-
ing in larger prefix count range values.
(c) Median prefix count divided by life-
time prefix count per AS. Hijacker ASes
originate a smaller share of their lifetime
prefixes at a given time, i.e., they have a
higher turnover rate of prefixes.
Figure 4: Volatility metrics of prefix origination behavior for serial hijackers and legitimate ASes.
if, e.g., a network had a route leak or misconfiguration problem
that significantly increased the number of prefixes it advertised
for a short period of time. Nonetheless, these types of events do
not occur frequently in our set of legitimate ASes and our metric
separates our two classes well.
5.2 Prefix-origin Longevity and Visibility
In this section, we study the dynamics of individual prefixes origi-
nated by ASes, in particular how hijackers’ prefix total duration and
visibility in the global routing table differ from prefixes originated
by legitimate ASes.
Longevity of prefix announcements: Our hypothesis is that hi-
jackers originate prefixes for a shorter period of time than legitimate
ASes. While we find this clear distinction when looking at aggregate
data, i.e., hijackers’ median prefix-origin duration is 27.25 days v.s.
264.17 days for legitimate ASes, we found it challenging to identify
a threshold that separates short-term and long-term prefixes and
hence separates our two categories of ASes well. To sharpen the
picture, we next take the visibility of announcements into account.
Longevity vs. visibility level: Figures 5a and 5b show the distri-
butions of the total advertisement time of prefix-origin pairs, for
different levels of visibility, for a legitimate AS and a serial hijacker
AS. AS7922, a legitimate AS, has a large fraction of long-term origi-
nated prefixes, i.e., more than 50% of high visibility IPv4 prefixes it
originates are advertised for over 1,000 days. On the other hand, the
lower the visibility the larger the share of short-term prefixes. We
notice that most of the low visibility prefixes that AS7922 originates
have a very short total advertisement time. Indeed, a large share of
the prefixes advertised by AS7922 for only a short period of time
come from highly localized traffic engineering efforts used to han-
dle infrastructure problems and hence have very limited visibility
in the global routing table (cf. § 5.1). AS57129, a serial hijacker, how-
ever, shows vastly different behavior: some 50% of high visibility
IPv4 prefixes originated by AS57129 have less than 50 days of total
advertisement time, and the share of short and long-term prefixes
it originates is very similar for all levels of visibility.
When plotting ASes by median prefix visibility and total adver-
tisement time (3rd quartile shown, Figure 5c), a large portion of
serial hijacker ASes cluster in the high visibility, low advertisement
time corner (upper left). In contrast, legitimate ASes are spread out
and high visibility is correlated with longer advertisement time for
these networks. Thus, we find that the longevity of prefix origina-
tion can only be meaningfully leveraged to separate our two classes
of ASes when qualified by their visibility level.
5.3 Address Space Properties
In this section, we study different properties of the IP addresses
that ASes originate. We take into account the Regional Internet
Registry (RIR) that assigned originated IP addresses, whether ASes
originate bogon or unassigned IP space, and if originated prefixes
were originated by other ASes at the same time (MOAS conflicts).
Address space fragmentation: Our hypothesis is that legitimate
ASes only originate address blocks that were allocated to them
by a respective Regional Internet Registry (RIR). Since most net-
works are limited in geographic scope, and individual RIRs cover
individual geographic regions, we expect most legitimate ASes to
either originate addresses from a single RIR, or, if they originate
prefixes from different RIRs, they would still be concentrated in
one of them. Since we do not expect serial hijackers to originate
address space allocated to them, nor respect RIR boundaries, we
expect them to originate prefixes from multiple RIRs, and show
much less concentration on any particular RIR. To express concen-
tration of originated address space across RIRs, we compute the
Gini coefficient of ASes’ RIR distribution using the percentage of
prefixes ASes originate from each of the five RIRs. A Gini of 0.8
means all IP resources come from one RIR, whereas a Gini index
closer to 0 means resources are uniformly distributed across the
5 RIRs. Figure 6a depicts the distribution of serial hijackers and
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Testart et al.
(a) Legitimate AS example: Total prefix ad-
vertisement time. Over 50% of prefixes are
originated for more than 1,000 days.
(b) Hijacker AS example: Total prefix ad-
vertisement time. Over 50% of prefixes are
originated for less than 50 days total.
(c) Advertisement time and visibility per
AS. Hijacker ASes show shorter, high-
visibility announcements.
Figure 5: Advertisement longevity and visibility of prefixes originated by legitimate and serial hijacker ASes.
Multiple Origin AS prefixes: We compute the number of prefixes
and the share of address space an AS originates that is also origi-
nated by another AS at the same time, i.e., the prefix has Multiple
Origin ASes (MOAS) in the global routing table. Figure 6b shows
per AS the fraction of advertised prefixes with MOAS conflicts
(x-axis) and the range of the duration of the MOAS announcements
(y-axis). We chose to show the range of the MOAS duration, since
we found that serial hijackers have almost exclusively short-term
MOAS announcements, resulting in a small MOAS duration range,
whereas legitimate ASes show variable MOAS durations, with many
short-term and long-term prefix originations with MOAS conflicts,
resulting in a large MOAS duration range. Many serial hijacker
ASes have a very short range of MOAS duration and a significant
share of the address space they originate are MOAS prefixes, which
is what we would expect for illegitimate MOAS events (e.g., replaced
by new ones as they are detected). We note that, as expected, some
legitimate ASes show MOAS conflicts, but that these MOAS events
typically last much longer than those of serial hijackers.
6 TOWARDS SCALABLE CLASSIFICATION OF
BGP MISBEHAVIOR
Next, we describe how we build a classifier to identify more ASes
in the global routing table that exhibit a prefix origination behavior
similar to serial hijackers. We start by explaining the main chal-
lenges faced when training a model with our dataset, and elaborate
on our resulting choices for our model and its main parameters. We
then discuss the features we use, their importance, and present the
final ensemble classifier and its accuracy metrics. We present the
results of the classification based on our trained classifier in § 7.
6.1 Challenges Faced
We face three main challenges when applying machine learning
algorithms to classify whether ASes show behavioral patterns of
serial hijackers: (i) heavy-tailed and skewed data, (ii) limited ground
truth, and (iii) class imbalance.
(a) Gini coefficient of originated prefix RIR concentration per
AS. Serial hijackers’ prefixes are more spread out over differ-
ent RIRs when compared to legitimate ASes.
(b) Fraction of prefixes with MOAS conflicts and range of
MOAS duration per AS. Some hijacker ASes show a higher
fraction of prefixes with MOAS conflicts with a low duration
range of MOAS conflicts.
Figure 6: Specific address space characteristics example for
legitimate and serial hijacker ASes.
legitimate ASes with respect to the Gini coefficient over the RIR
distribution. We observe that many serial hijackers show a lower
Gini coefficient compared to legitimate ASes, meaning that the
prefixes they originate are comparably more uniformly distributed
among RIRs. This is in contrast to legitimate ASes, which typically
show high RIR concentration.
Profiling BGP Serial Hijackers
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Heavy-tailed and skewed data: The routing data on which our
analysis is based is extremely heterogeneous. In almost all dimen-
sions, individual prefixes and ASes are heavily concentrated at
some level but then there is a long tail of outliers, making the data
difficult to normalize. In addition, some of our features range from
zero to one (e.g., the Gini coefficient expressing concentration of
address space across RIRs described in § 5.3), while other features,
such as the total advertisement duration (described in § 5.2) ranges
from 5 minutes to 5 years.
Small ground truth: As discussed in § 3.1, building a ground truth
dataset including serial hijackers and legitimate ASes is challenging.
In total, our ground truth dataset consists of 230 labeled ASes. We
only select ASes originating at least 10 prefixes in the 5-year dataset.
This includes all hijackers but only 217 ASes from our legitimate
AS group described in § 3.1. Therefore, we must carefully select a
model to avoid overfitting.
Class imbalance: We do not expect that a large share of routed
ASes exhibiting serial hijackers’ behavior. The true share of such
ASes is unknown, and if we were to make an educated guess, we
would only expect to find this behavior for a small number of ASes,
i.e., less than 1% of routed ASes (over 75,000 ASes are routed in our
dataset in the 5-year period). Class imbalance is also present in our
ground truth dataset: we only have 23 serial hijacker ASes vs. 217
ASes in the legitimate group of our labeled ground truth.
6.2 Our Classifier
Choice of Classifier: We choose a tree-based classifier since deci-
sion trees do not require normalized data and work well with large
dimensions and heavy-tailed data such as the features we built to
capture different aspect of BGP origination behavior. More specifi-
cally, we use Extremely Randomized Trees (Extra-Trees) classifiers
[17]. An Extra-Trees classifier is an ensemble (forest) of decision
trees that picks feature thresholds to split nodes at random, instead
of fitting the threshold to the training data like in a common random
forest classifier. This added randomness greatly reduces overfitting,
another of our main challenges as discussed in § 6.1.
Model accuracy for parameter selection: To properly select
model parameters (sampling methods, forest size, feature selec-
tion) without reducing the training data by doing an n-fold cross-
validation, we use bootstrapping samples (subset samples) in the
training phase of the individual trees and compute the classifier
Out-Of-Bag (OOB) error estimate. OOB error estimation is a method
to measure the prediction error of random forests, where a lower
OOB error indicates higher accuracy of the model. The OOB error
estimate is the average error for each data point p in the train-
ing sample computed averaging the prediction of trees trained
on a bootstrapping sample (bag) not including p [11]. The OOB
score has been shown to converge almost identically as the n-fold
cross-validation test error and is an established method to validate
random forest classifiers [21].
Sampling techniques: To address class imbalance, we try differ-
ent under- and over-sampling methods to create balanced training
sets for our classifier, by either under-sampling the majority class
(selecting only a few legitimate ASes) or over-sampling the minor-
ity class (artificially expanding the set of serial hijackers) in our
original ground truth. Figure 7 shows the mean OOB scores (and
Figure 7: Mean Out-of-bag accuracy scores and error bars
of sets of 100 Extra-Trees classifiers trained using different
sampling techniques for increasing forest sizes.
error bars) of sets of 100 Extra-Trees classifiers trained using 6 dif-
ferent sampling technique for different forest sizes. We observe that
techniques that are purely based on under-sampling perform worse
than techniques that include an over-sampling step. In addition,
over-sampling techniques use different rules and randomness to ex-
pand the serial hijacker set and thus no two synthetic training sets
are equal. We therefore decide to use a mixture of over-sampling
techniques for the training of our classifier, so that it leverages
the different distributions of misclassified points to improve its
generalization ability [54].
Feature selection and importance: Based on the extensive man-
ual analysis described in § 5, we select 52 features that capture BGP
behavior according to 8 categories: ASN presence in the global rout-
ing table, prefix origination behavior, longevity of individual prefix
advertisements, prefix visibility, longevity vs. visibility level, prefix
set stability, address space fragmentation, and MOAS statistics. The
features capture different characteristics and statistical behavior of
the properties discussed in § 5, such as the median origination time
of high visibility prefixes and 90th percentile of the distribution of
daily changes in prefix origination.
To assess feature importance, we compute the drop column fea-
ture importance for each feature.7 The drop column importance
captures how the classifier accuracy actually varies when a feature
is not considered in the training phase [39]. We learn that all cate-
gories have positive median drop column importance, i.e., they all
add to the accuracy of the model. We thus proceed to feed all 52
features to train our final classifier.
The trained classifier: Our final ensemble classifier is based on the
vote of 34 Extra-Trees classifiers of 500 extremely randomized trees
each, and each trained on a different balanced synthetic training
set computed using one of the 3 over-sampling algorithms we
selected. The model OOB error estimate is 2.5%. We program our
classifier using the sklearn and imblearn libraries [40] in Python,
7Given most of our features are computed from the same raw BGP data, selecting
features by usual random forest feature importance ranking or information gain is not
adequate [8, 19, 53].
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Testart et al.
which have the Extra-Trees classifiers and sampling algorithms
pre-programmed.
False positives from the training set: Using the OOB predictions
for the training set, the ensemble classifier precision and recall are
79.3% and 100% respectively. Although our serial hijacker set is
small, the high recall rate supports our hypothesis that our small
group of serial hijacker have distinctive characteristics in their BGP
prefix origination behavior. We note however that the classifier
precision is only about 80% — a strong reminder that the behavior
of ASes selected by the classifier is not necessarily illegitimate. Even
in our legitimate group, there are a few ASes that present similar
characteristics to serial hijackers. Indeed, throughout all the differ-
ent classifiers we tested, there are 6 ASes in our legitimate group
that get consistently misclassified. Looking in more detail at these
ASes, we find that two of them are from Verisign, an organization
that offers DDoS protection, and are hence benign cases of serial
hijackers, which we discuss in § 7.3. Two other ASes have only
originated prefixes for a short period of time and are not currently
being routed, which could have adversely affected our metrics and
classification. The last two ASes are hosting organizations showing
irregular BGP behavior of which the cause is unclear to us.
7 INVESTIGATING BGP MISBEHAVIOR IN
THE WILD
In this section, we describe the output from our ensemble classifier.
We feed the classifier with features based on IPv4 prefix-origin
routing data of ASes that originate at least 10 prefixes in the 5 years
of our dataset. Of the 19,103 ASes in our prediction set, our ensemble
classifier finds 934 ASes having similar behavior to serial hijackers,
we refer to them asflagged ASes. We note that the group of flagged
ASes is fairly consistent across classifiers trained using different
combinations of sampling methods and forest sizes. For models
with an OOB error score of 4% at most, at least 95% of the ASes
flagged by that classifier where also flagged by the final classifier.
In the next sections, we first describe general characteristics of
flagged ASes and compare them to non-flagged ASes. Then, we