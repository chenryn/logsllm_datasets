应用程序中的路由请求
 以增加复杂性为代价，也可以在应用程序中放置分片路由逻辑，如#aright_parenthesis_client_sends_a_reques中所示。当无法处理请求时，应用程序会将其代理到正确的分片。 这称为回传请求。现在，应用程序需要能够将流量（可能是大量流量）回传到正确的流程。 传统的 Web 框架不是为代理请求而设计的。最重要的是，这种功能并不容易添加。1a） 客户端向最近的数据中心发送分片 1 的请求。1b） 应用服务器连接到本地分片。2a） 客户端向最近的数据中心发送分片 2 的请求。2b） DC1中的应用程序服务器将请求代理到 DC2，其中步骤 1b 在本地重复。
使用可编写脚本的负载均衡器路由请求
  可编写脚本的负载平衡器允许你将所有分片路由逻辑移动到负载平衡层，从而实现新的路由可能性，并使您能够从应用程序中完全抽象出分片的概念。 如#right_parenthesis_client_sends_a_request中展示的，进程永远不会知道它们无法提供的请求。
通过完全控制请求路由逻辑，你现在可以从属性或属性的任意组合（例如，主机、URI 和客户端 IP）中提取所需的分片。甚至可以查询一个数据库，该数据库提供有关请求所属分片的见解。与其他路由方法一起，该过程直接影响数据模型的分区方式。例如，如果使用 DNS 路由，则无法对没有其自己的域的数据模型进行分区。基础结构问题不应决定应用程序的设计。在负载均衡器中嵌入路由逻辑可避免抽象的概念变得具体化。1a） 客户端向最近的数据中心发送分片 1 的请求。1b） DC1中的负载均衡器将请求代理到本地分片。2a） 客户端向最近的数据中心发送分片 2 的请求。2b） DC1中的负载均衡器将请求代理到 DC2，其中步骤 2 在本地重复。
理想情况下，应用程序很少意识到自己服务的分片。通过负载均衡器中的路由，应用程序几乎不会意识到自己的分片。通过分离这些问题，您可以在多个应用程序之间重用分片逻辑。 Google 的 SlicerAdya, Atul 等人（2016）“切片算法：数据中心应用程序的自动分片。”引自 USENIX 操作系统设计和实现会议论文集。https://www.usenix.org/system/files/conference/osdi16/osdi16-adya.pdf。是这种方法的一个主要例子。Slicer是一种用于应用程序的自动分片服务。 核心组件对上游应用程序来说是透明的，通过 Google 的前端负载均衡器和 RPC 代理将请求路由到特定分片。该服务现已投入生产，每秒可处理 700万个请求。利用潜力
 可编写脚本的负载均衡器的强大功能来自现有功能的重用。负载均衡器已经擅长这些任务不必二次开发，比如无需重写传输层安全 （TLS） 协商或运行状况检查。通常，互联网规范甚至会为将来的改进预留空间。HTTP 缓存就是一个很好的例子。RFC 允许自定义缓存控制标头扩展，这些扩展程序修改缓存请求的方式和时间。Fielding, R., M. 诺丁汉等人（2014年）。“超文本传输协议 （HTTP/1.1）： 缓存”。IETF 标准记录 RFC。在负载均衡器中运行的更简单的脚本可以重现完全相同的功能，而不必为细粒度缓存密钥控件编写新的缓存代理（例如，在缓存密钥中包括特定的 Cookie）。此外，负载均衡器还擅长路由和服务请求。业界已经投入了大量精力，确保它们能够快速、大量地完成此功能。只需很少的努力，这些宝贵的功能就可以通过添加到（可编写脚本的）负载均衡器的模块继承。你可以参考 Cloudflare 的 Web 应用程序防火墙 （WAF）Graham, John（2014）。“使用 Lua 在 NGINX 内部构建低延迟 WAF”在 NginxConf 的讲座。和 Shopify 的 Sorting Hat（L7 路由层），Francis, Scott （2015）。“使用 NGINX 和 Lua 构建 HTTP 请求路由器”在 NginxConf 的讲座。两者均以微秒为单位衡量性能。
案例研究：休息时间
  对于大多数服务而言，快速、轻松地将代码投入生产的能力非常重要。能够做到这一点的一个必要前提条件是无停顿部署。尽管自动化可以减少执行破坏性维护所需的时间，但无法完全消除停机时间。对于可编写脚本的负载均衡器，可以通过添加启用/禁用请求暂停功能来实现不停顿部署或维护。例如，在维护过程中对任何请求出错的应用程序，如#client_request_fails_because_the_upstream所示。
客户端请求失败，因为上游服务在维护时段内不可用。
所谓请求暂停是当代理在将请求转发到所需的上游之前加入等待。请求可以在指定的时间片段内暂停，也可以由存储在数据存储中的标志来引发暂停。当代理恢复时，请求被转发到其原始目标，如#when_the_client_request_hits_the_load_bal所示。
当客户端请求命中负载均衡器时，负载均衡器将等待，直到禁用请求暂停才将其转发到应用程序。
客户端收到响应较慢，而不是使请求失败。根据服务级别目标 （SLO），这可能会导致本月错误预算是否突破差别。可以用编程方式指示可编写负载均衡器：开始暂停服务请求，跟踪客户端是否已断开连接，并在服务联机时缓慢转发请求，以避免上游服务过载。服务级别中间件
  避免辛劳是 SRE 的核心原则之一。拜尔，贝西等人，eds.（2016年）。“第二部分. 原则。”在站点可靠性工程（O'Reilly）。随着组织继续采用 SRE 最佳实践，越来越多的团队开始采用产品或服务模型来执导支持团队和运维团队。
在传统的运维模型中，工程师为每个应用程序部署和维护依赖项目。这方面的一个传统例子是数据库。操作团队将为他们运行的应用程序设置并管理 SQL 服务器。使用产品或服务模型，一个专门的团队构建一个与应用程序无关的数据库作为服务。然后，此服务由 API/UI 公开（例如云提供商提供的服务）。
尽管产品与服务模型比辛劳和“运维雪崩”要好得多，但它仍然将与预配服务交互的负担推到了应用程序上。在某些情况下，这很快就会导致高开销。调用服务需要应用程序注意其存在。想象每个应用程序为验证请求而使用的标识服务。每个应用程序都被迫保持对标识服务的感知，这导致维护负担增加，并造成呼叫外部服务的开销。使用可编写脚本的负载均衡器，产品/服务模型不是 SRE 团队消除辛劳的唯一方法。作为救援的中间件
可编写脚本的负载均衡器通常是涉及请求的第一个组件。这使得它们成为影响多个服务的逻辑的理想位置。应用程序可以在请求接近之前读取添加到请求的标头，而不是对外部服务进行 RPC 调用。您可以将此模型视为类似于大多数 Web 框架中的中间件。服务级别中间件在请求访问上游应用程序之前透明地对请求进行操作。产品开发人员可以免除调用外部服务的开销和复杂性。
对于某些问题，中间件是一种更自然的解决方案。阿加巴博夫、维克托等人（2015年）。"Flywheel：谷歌的移动网络数据压缩代理"。引自 USENIX 网络系统设计和实施研讨会的议事录中。用前面提到的标识服务为例。应用程序可以假定具有已验证的特定标头的任何请求，而不是直接调用标识服务。标头可以包含客户端具有的范围和访问权限。标识中间件消除了从上游服务中调用外部服务的延迟和复杂性开销。
服务级别中间件的 API服务级别中间件的 API
  除了最微不足道的中间件之外的所有中间件都需要一些特定于应用程序的配置（例如，在特定页面上指定不同的缓存键）。直接的解决方案可能是在中间件代码库中对此配置进行硬编码。但是，随着时间的推移，硬编码的配置可能会偏离现实并导致本可避免的中断。
为了防止发散，建立明确的 API 非常重要，通过这些 API，应用程序可以不断与下游中间件通信。你可以使用自定义 HTTP 请求和响应标头作为通信总线，而配置是经过此渠道的。对于不适合请求/响应流的数据，可以使用带外消息总线将状态传播到所有负载均衡器。
案例研究：WAF/Bot 缓解案例研究：WAF/Bot 缓解
将 Web 服务作为分布式拒绝服务（DDoS）攻击的目标，或通过机器人进行自动抓取只是个时间问题。Kandula，Srikanth等（2005年）。“Botz-4-Sale：能够模仿Flash群体的有组织的DDoS攻击”。引自USENIX网络系统设计与实现研讨会论文集。DDoS 攻击可能导致严重的故障，也会带来漫长的服务停顿。机器人自动攻击往往导致真正的客户严重不满。你可以使用可编写脚本的负载平衡器来构建针对这些威胁的保护层，并在所有面向 Web 的服务上使用它们，而不必在每个应用程序中开发相同的反机器人或 DDoS 处理工具。Majkowski，Marek（2016）。“构建 DDoS 防空洞。”在 Enigma 上发表的演讲。Cloudflare 已经建立了一个业务，通过 Web 应用程序防火墙功能提供这样一层保护。其中间件背后的任何服务都享有针对开放 Web 应用程序安全项目 （OWASP）漏洞、常见 DoS 攻击和 Zero-day 漏洞的保护。当请求的危险或真实性不明确时，中间件能够重定向请求到质询响应测试页面，以验证请求是否来自合法来源。