介绍Hadoop的安装之前，先介绍一下Hadoop对各个节点的角色定义。
Hadoop分别从三个角度将主机划分为两种角色。第一，最基本的划分为Master和Slave，即主人与奴隶；第二，从HDFS的角度，将主机划分为NameNode和DataNode（在分布式文件系统中，目录的管理很重要，管理目录相当于主人，而NameNode就是目录管理者）；第三，从MapReduce的角度，将主机划分为JobTracker和TaskTracker（一个Job经常被划分为多个Task，从这个角度不难理解它们之间的关系）。
Hadoop有官方发行版与cloudera版，其中cloudera版是Hadoop的商用版本，这里先介绍Hadoop官方发行版的安装方法。
Hadoop有三种运行方式：单机模式、伪分布式与完全分布式。乍看之下，前两种方式并不能体现云计算的优势，但是它们便于程序的测试与调试，所以还是很有意义的。
你可以在以下地址获得Hadoop的官方发行版：http：//www.apache.org/dyn/closer.cgi/Hadoop/core/。
下载hadoop-1.0.1.tar.gz并将其解压，本书后续都默认将Hadoop解压到/home/u/目录下。
（1）单机模式配置方式
安装单机模式的Hadoop无须配置，在这种方式下，Hadoop被认为是一个单独的Java进程，这种方式经常用来调试。
（2）伪分布式Hadoop配置
可以把伪分布式的Hadoop看做只有一个节点的集群，在这个集群中，这个节点既是Master，也是Slave；既是NameNode，也是DataNode；既是JobTracker，也是TaskTracker。
伪分布式的配置过程也很简单，只需要修改几个文件。
进入conf文件夹，修改配置文件。
指定JDK的安装位置：
Hadoop-env.sh：
export JAVA_HOME=/usr/lib/jvm/jdk
这是Hadoop核心的配置文件，这里配置的是HDFS（Hadoop的分布式文件系统）的地址及端口号。
conf/core-site.xml：
＜configuration＞
＜property＞
＜name＞fs.default.name＜/name＞
＜value＞hdfs：//localhost：9000＜/value＞
＜/property＞
＜/configuration＞
以下是Hadoop中HDFS的配置，配置的备份方式默认为3，在单机版的Hadoop中，需要将其改为1。
conf/hdfs-site.xml：
＜configuration＞
＜property＞
＜name＞dfs.replication＜/name＞
＜value＞1＜/value＞
＜/property＞
＜/configuration＞
以下是Hadoop中MapReduce的配置文件，配置JobTracker的地址及端口。
conf/mapred-site.xml：
＜configuration＞
＜property＞
＜name＞mapred.job.tracker＜/name＞
＜value＞localhost：9001＜/value＞
＜/property＞
＜/configuration＞
接下来，在启动Hadoop前，需要格式化Hadoop的文件系统HDFS。进入Hadoop文件夹，输入命令：
bin/Hadoop NameNode-format
格式化文件系统，接下来启动Hadoop。
输入命令，启动所有进程：
bin/start-all.sh
最后，验证Hadoop是否安装成功。
打开浏览器，分别输入网址：
http：//localhost：50030（MapReduce的Web页面）
http：//localhost：50070（HDFS的Web页面）
如果都能查看，说明Hadoop已经安装成功。
对于Hadoop来说，启动所有进程是必须的，但是如果有必要，你依然可以只启动HDFS（start-dfs.sh）或MapReduce（start-mapred.sh）。
关于完全分布式的Hadoop会在2.4节详述。
2.2 在Mac OSX上安装与配置Hadoop
由于现在越来越多的人使用Mac Book，故笔者在本章中增加了在Mac OS X上安装与配置Hadoop的内容，供使用Mac Book的读者参考。
 2.2.1 安装Homebrew
Mac OS X上的Homebrew是类似于Ubuntu下apt的一种软件包管理器，利用它可以自动下载和安装软件包，安装Homebrew之后，就可以使用Homebrew自动下载安装Hadoop。安装Homebrew的步骤如下：
1）从Apple官方下载并安装内置GCC编译器—Xcode（现在版本为4.2）。安装Xcode主要是因为一些软件包的安装依赖于本地环境，需要在本地编译源码。Xcode的下载地址为https：//developer.apple.com/xcode/。
2）使用命令行安装Homebrew，输入命令：
/usr/bin/ruby-e"$（/usr/bin/curl-fksSL https：//raw.github.com/mxcl/homebrew/
master/Library/Contributions/install_homebrew.rb）"
这个命令会将Homebrew安装在/usr/local目录下，以保证在使用Homebrew安装软件包时不用使用sudo命令。安装完成后可以使用brew-v命令查看是否安装成功。
2.2.2 使用Homebrew安装Hadoop
安装完Homebrew之后，就可以在命令行输入下面的命令来自动安装Hadoop。自动安装的Hadoop在/usr/local/Cellar/hadoop路径下。需要注意的是，在使用brew安装软件时，会自动检测安装包的依赖关系，并安装有依赖关系的包，在这里brew就会在安装Hadoop时自动下载JDK和SSH，并进行安装。
brew install hadoop
2.2.3 配置SSH和使用Hadoop
接下来需要配置SSH免密码登录和启动Hadoop。由于其步骤和内容与Linux的配置完全相同，故这里不再赘述。
2.3 在Windows上安装与配置Hadoop
 2.3.1 安装JDK 1.6或更高版本
相对于Linux, JDK在Windows上的安装过程更容易，你可以在http：//www.java.com/zh_CN/download/manual.jsp下载到最新版本的JDK。这里再次申明，Hadoop的编译及MapReduce程序的运行，很多地方都需要使用JDK的相关工具，因此只安装JRE是不够的。
安装过程十分简单，运行安装程序即可，程序会自动配置环境变量（在之前的版本中还没有这项功能，新版本的JDK已经可以自动配置环境变量了）。
2.3.2 安装Cygwin
Cygwin是在Windows平台下模拟UNIX环境的一个工具，只有通过它才可以在Windows环境下安装Hadoop。可以通过下面的链接下载Cygwin：http：//www.cygwin.com/。
双击运行安装程序，选择install from internet。
根据网络状况，选择合适的源下载程序。
进入select packages界面，然后进入Net，选中OpenSSL及OpenSSH（如图2-1所示）。
图 2-1 勾选openssl及openssh
如果打算在Eclipse上编译Hadoop，还必须安装Base Category下的sed（如图2-2所示）。
图 2-2 勾选sed
另外建议安装Editors Category下的vim，以便在Cygwin上直接修改配置文件。
2.3.3 配置环境变量
依次右击“我的电脑”，在弹出的快捷菜单中依次单击“属性”→“高级系统设置”→“环境变量”，修改环境变量里的path设置，在其后添加Cygwin的bin目录。
2.3.4 安装sshd服务
单击桌面上的Cygwin图标，启动Cygwin，执行ssh-host-config命令，当要求输入Yes/No时，选择输入No。当显示“Have fun”时，表示sshd服务安装成功。
2.3.5 启动sshd服务
在桌面上的“我的电脑”图标上右击，在弹出的快捷菜单中单击“管理”命令，启动CYGWIN sshd服务，或者直接在终端下输入下面的命令启动服务：
net start sshd
2.3.6 配置SSH免密码登录
执行ssh-keygen命令生成密钥文件。按如下命令生成authorized_keys文件：
cd～/.ssh/
cp id_rsa.pub authorized_keys
完成上述操作后，执行exit命令先退出Cygwin窗口，如果不执行这一步操作，后续的操作可能会遇到错误。
接下来，重新运行Cygwin，执行ssh localhost命令，在第一次执行时会有提示，然后输入yes，直接回车即可。
2.3.7 安装并运行Hadoop
在Windows上安装Hadoop与在Linux上安装的过程一样，这里就不再赘述了，不过有两点需要注意：
1）在配置conf/hadoop-evn.sh文件中Java的安装路径时，如果路径之间有空格，需要将整个路径用双引号引起来。例如可以进行配置：
export JAVA_HOME="/cygdrive/c/Program Files/Java/jdk1.6.0_22"
其中cygdrive表示安装cygdrive之后系统的根目录。
另外一种办法是在cygwin窗口使用类似下面的命令创建文件链接，使后面的文件指向Windows下安装的JDK，然后将conf/hadoop-env.sh中JDK配置为此链接文件：
$ln-s/cygdrive/c/Program\Files/Java/jdk1.6.0_22/usr/local/jdk
2）在配置conf/mapred-site.xml文件时，应增加对mapred.child.tmp属性的配置，配置的值应为一个Linux系统的绝对路径，如果不配置，Job在运行时就会报错。具体配置为：
＜property＞
＜name＞mapred.child.tmp＜/name＞
＜value＞/home/Administrator/hadoop-1.0.1/tmp＜/value＞
＜/property＞
同样需要在conf/core-site.xml文件中为hadoop.tmp.dir属性配置一个和mapred.child.tmp属性相似的绝对路径。
2.4 安装和配置Hadoop集群
 2.4.1 网络拓扑
通常来说，一个Hadoop的集群体系结构由两层网络拓扑组成，如图2-3所示。结合实际应用来看，每个机架中会有30～40台机器，这些机器共享一个1GB带宽的网络交换机。在所有的机架之上还有一个核心交换机或路由器，通常来说其网络交换能力为1GB或更高。可以很明显地看出，同一个机架中机器节点之间的带宽资源肯定要比不同机架中机器节点间丰富。这也是Hadoop随后设计数据读写分发策略要考虑的一个重要因素。
图 2-3 Hadoop的网络拓扑结构
2.4.2 定义集群拓扑
在实际应用中，为了使Hadoop集群获得更高的性能，读者需要配置集群，使Hadoop能够感知其所在的网络拓扑结构。当然，如果集群中机器数量很少且存在于一个机架中，那么就不用做太多额外的工作；而当集群中存在多个机架时，就要使Hadoop清晰地知道每台机器所在的机架。随后，在处理MapReduce任务时，Hadoop就会优先选择在机架内部做数据传输，而不是在机架间传输，这样就可以更充分地使用网络带宽资源。同时，HDFS可以更加智能地部署数据副本，并在性能和可靠性间找到最优的平衡。
在Hadoop中，网络的拓扑结构、机器节点及机架的网络位置定位都是通过树结构来描述的。通过树结构来确定节点间的距离，这个距离是Hadoop做决策判断时的参考因素。NameNode也是通过这个距离来决定应该把数据副本放到哪里的。当一个Map任务到达时，它会被分配到一个TaskTracker上运行，JobTracker节点则会使用网络位置来确定Map任务执行的机器节点。
在图2-3中，笔者使用树结构来描述网络拓扑结构，主要包括两个网络位置：交换机/机架1和交换机/机架2。因为图2-3中的集群只有一个最高级别的交换机，所以此网络拓扑可简化描述为/机架1和/机架2。
在配置Hadoop时，Hadoop会确定节点地址和其网络位置的映射，此映射在代码中通过Java接口DNSToSwitchMaping实现，代码如下：
public interface DNSToSwitchMapping{
public List＜String＞resolve（List＜String＞names）；
}
其中参数names是IP地址的一个List数据，这个函数的返回值为对应网络位置的字符串列表。在opology.node.switch.mapping.impl中的配置参数定义了一个DNSToSwitchMaping接口的实现，NameNode通过它确定完成任务的机器节点所在的网络位置。
在图2-3的实例中，可以将节点1、节点2、节点3映射到/机架1中，节点4、节点5、节点6映射到/机架2中。事实上在实际应用中，管理员可能不需要手动做额外的工作去配置这些映射关系，系统有一个默认的接口实现ScriptBasedMapping。它可以运行用户自定义的一个脚本区完成映射。如果用户没有定义映射，它会将所有的机器节点映射到一个单独的网络位置中默认的机架上；如果用户定义了映射，那么这个脚本的位置由topology.script.file.name的属性控制。脚本必须获取一批主机的IP地址作为参数进行映射，同时生成一个标准的网络位置给输出。
2.4.3 建立和安装Cluster
要建立Hadoop集群，首先要做的就是选择并购买机器，在机器到手之后，就要进行网络部署并安装软件了。安装和配置Hadoop有很多方法，这部分内容在前文已经详细讲解过（见2.1节、2.2节和2.3节），同时还告诉了读者在实际部署时应该考虑的情况。
为了简化我们在每个机器节点上安装和维护相同软件的过程，通常会采用自动安装法，比如Red Hat Linux下的Kickstart或Debian的全程自动化安装。这些工具先会记录你的安装过程，以及你对选项的选择，然后根据记录来自动安装软件。同时它们会在每个进程结尾提供一个钩子执行脚本，在对那些不包含在标准安装中的最终系统进行调整和自定义时这是非常有用的。
下面我们将具体介绍如何部署和配置Hadoop。Hadoop为了应对不同的使用需求（不管是开发、实际应用还是研究），有着不同的运行方式，包括单机式、单机伪分布式、完全分布式等。前面已经详细介绍了在Windows、MacOSX和Linux下Hadoop的安装和配置。下面将对Hadoop的分布式配置做具体的介绍。
1.Hadoop集群的配置
在配置伪分布式的过程中，大家也许会觉得Hadoop的配置很简单，但那只是最基本的配置。
Hadoop的配置文件分为两类。
1）只读类型的默认文件：src/core/core-default.xml、src/hdfs/hdfs-default.xml、src/mapred/mapred-default.xml、conf/mapred-queues.xml。
2）定位（site-specific）设置：conf/core-site.xml、conf/hdfs-site.xml、conf/mapred-site.xml、conf/mapred-queues.xml。
除此之外，也可以通过设置conf/Hadoop-env.sh来为Hadoop的守护进程设置环境变量（在bin/文件夹内）。
Hadoop是通过org.apache.hadoop.conf.configuration来读取配置文件的。在Hadoop的设置中，Hadoop的配置是通过资源（resource）定位的，每个资源由一系列name/value对以XML文件的形式构成，它以一个字符串命名或以Hadoop定义的Path类命名（这个类是用于定义文件系统内的文件或文件夹的）。如果是以字符串命名的，Hadoop会通过classpath调用此文件。如果以Path类命名，那么Hadoop会直接在本地文件系统中搜索文件。
资源设定有两个特点，下面进行具体介绍。
1）Hadoop允许定义最终参数（final parameters），如果任意资源声明了final这个值，那么之后加载的任何资源都不能改变这个值，定义最终资源的格式是这样的：
＜property＞
＜name＞dfs.client.buffer.dir＜/name＞
＜value＞/tmp/Hadoop/dfs/client＜/value＞
＜fnal＞true＜/fnal＞//注意这个值
＜/property＞
2）Hadoop允许参数传递，示例如下，当tenpdir被调用时，basedir会作为值被调用。
＜property＞
＜name＞basedir＜/name＞
＜value＞/user/${user.name}＜/value＞
＜property＞
＜property＞
＜name＞tempdir＜/name＞
＜value＞${basedir}/tmp＜/value＞