title:Imperio: Robust Over-the-Air Adversarial Examples for Automatic Speech
Recognition Systems
author:Lea Sch&quot;onherr and
Thorsten Eisenhofer and
Steffen Zeiler and
Thorsten Holz and
Dorothea Kolossa
Imperio: Robust Over-the-Air Adversarial Examples for
Automatic Speech Recognition Systems
Lea Sch√∂nherr, Thorsten Eisenhofer, Steffen Zeiler, Thorsten Holz, and Dorothea Kolossa
{lea.schoenherr,thorsten.eisenhofer,steffen.zeiler,thorsten.holz,dorothea.kolossa}@rub.de
Ruhr University Bochum
0
2
0
2
v
o
N
4
2
]
R
C
.
s
c
[
5
v
1
5
5
1
0
.
8
0
9
1
:
v
i
X
r
a
ABSTRACT
Automatic speech recognition (ASR) systems can be fooled via
targeted adversarial examples, which induce the ASR to produce
arbitrary transcriptions in response to altered audio signals. How-
ever, state-of-the-art adversarial examples typically have to be fed
into the ASR system directly, and are not successful when played in
a room. Previously published over-the-air adversarial examples fall
into one of three categories: they are either handcrafted examples,
they are so conspicuous that human listeners can easily recognize
the target transcription once they are alerted to its content, or they
require precise information about the room where the attack takes
place, and are hence not transferable to other rooms.
In this paper, we demonstrate the first algorithm that produces
generic adversarial examples against hybrid ASR systems, which
remain robust in an over-the-air attack that is not adapted to the
specific environment. Hence, no prior knowledge of the room char-
acteristics is required. Instead, we use room impulse responses (RIRs)
to compute robust adversarial examples for arbitrary room char-
acteristics and employ the ASR system Kaldi to demonstrate the
attack. Further, our algorithm can utilize psychoacoustic meth-
ods to hide changes of the original audio signal below the human
thresholds of hearing. In practical experiments, we show that the
adversarial examples work for varying room setups, and that no
direct line-of-sight between speaker and microphone is necessary.
As a result, an attacker can create inconspicuous adversarial exam-
ples for any target transcription and apply these to arbitrary room
setups without any prior knowledge.
KEYWORDS
adversarial examples, automatic speech recognition, over-the-air
attack
ACM Reference Format:
Lea Sch√∂nherr, Thorsten Eisenhofer, Steffen Zeiler, Thorsten Holz, and
Dorothea Kolossa. 2020. Imperio: Robust Over-the-Air Adversarial Examples
for Automatic Speech Recognition Systems. In Annual Computer Security
Applications Conference (ACSAC 2020), December 7‚Äì11, 2020, Austin, USA.
ACM, New York, NY, USA, 14 pages. https://doi.org/10.1145/3427228.3427276
Publication rights licensed to ACM. ACM acknowledges that this contribution was
authored or co-authored by an employee, contractor or affiliate of a national govern-
ment. As such, the Government retains a nonexclusive, royalty-free right to publish or
reproduce this article, or to allow others to do so, for Government purposes only.
ACSAC 2020, December 7‚Äì11, 2020, Austin, USA
¬© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-8858-0/20/12...$15.00
https://doi.org/10.1145/3427228.3427276
Figure 1: For an over-the-air attack against automatic speech
recognition (ASR) systems, the attack should remain viable
after the transmission over the air. This transmission can be
modeled as a convolution of the original audio signal ùë• with
the room impulse response (RIR) ‚Ñé.
1 INTRODUCTION
In restless dreams I walked alone. Narrow streets of
cobblestone. ‚ÄôNeath the halo of a streetlamp. I turned my collar
to the cold and damp. When my eyes were stabbed by the flash
of a neon light. That split the night. And touched the sound of
silence.
Simon & Garfunkel, The Sound of Silence
Substantial improvements in speech recognition accuracy have
been achieved in recent years by using acoustic models based on
deep neural networks (DNNs). Nevertheless, current studies suggest
that there can be significant differences in the mechanism of artifi-
cial neural network algorithms compared to human expectations.
This is a very unfortunate situation, as a rogue party can abuse this
knowledge to create input data, which leads to inconsistent recog-
nition results, without being noticed [8, 9]. As just one example
of such attacks, several recent works have demonstrated that it is
possible to fool different kinds of ASR systems into outputting a ma-
licious transcription chosen by the attacker [1, 7, 9, 27, 29, 32, 37, 39].
The practical implications and real-world impact of the demon-
strated attacks are unclear at the moment. On the one hand, earlier
work fed the adversarial audio examples directly into the ASR sys-
tem [9, 29, 39], hence ignoring all side effects (e. g., echo or reverber-
ation) of a real-world environment, where the sound is transmitted
from a loudspeaker to the input microphone of the recognition
engine. On the other hand, some works demonstrated adversarial
examples that can be played over-the-air [1, 7, 32, 37], but these
proof-of-concept attacks are either tailored to a single, static room
setup or are hard to reproduce systematically with a proven success
rate in a different environment like the attack sketched in Comman-
derSong [39]. Recently and independently, Chen et al. [10] showed
a first over-the-air attack. Their attack was evaluated against Deep-
Speech [16]. In contrast, we are showing an attack against Kaldi, a
ASRISOLEMNLYSWEARTHATIAMUPTONOGOODxhtranscriptionhxACSAC 2020, December 7‚Äì11, 2020, Austin, USA
Lea Sch√∂nherr, Thorsten Eisenhofer, Steffen Zeiler, Thorsten Holz, and Dorothea Kolossa
hybrid ASR system, based on a combination of a DNN-based acous-
tic model and a subsequent search for the optimal word sequence
in a weighted-finite-state-transducer model. This approach is con-
ceptually completely different from the end-to-end approach in
DeepSpeech, as used by Chen et al. Hybrid systems such as Kaldi are
significant here as they show the best performance on many speech
recognition tasks, require comparatively little training material,
allow for an easy replacement of task-specific grammars, and are
therefore widely adopted in the industry.
In cases where over-the-air adversarial examples have been used
in black-box settings, the target transcription is easily perceived by
human listeners, once the intended attack is known [1, 7].
We argue that adversarial examples for ASR systems can only
be considered a real threat if the targeted recognition is produced
even when the signal is played over the air. Compared to previous
attacks, where the manipulated speech signal is fed directly into
the ASR system, over-the-air attacks are more challenging, as the
transmission over the air significantly alters the signal.
Our key insight that forms the basis of this paper is that this
transmission can be modeled as a convolution of the original audio
signal with the room impulse response (RIR), which describes the
alterations of an acoustic signal by the transmission via loudspeaker
to the microphone (see Figure 1 for an illustration), where the RIR
depends on various factors [2]. In practice, it is nearly impossible
to estimate an exact RIR without having access to the actual room.
Therefore, robust adversarial examples need to take a range of pos-
sible RIRs into account to increase the success rate. Nevertheless,
we show that for a successful attack, it is not necessary to acquire
precise knowledge about the attack setup; instead, a generic ad-
versarial example computed for a large variety of possible rooms
is enough.
Robust Adversarial Examples. The first adversarial audio ex-
amples imperceptible to humans, even if they know the target tran-
scription, have been described by Carlini and Wagner [9]. Other ap-
proaches [27, 29] have been successful at embedding most changes
below the human threshold of hearing, which makes them much
harder to notice. On the downside, none of these attacks were suc-
cessfully demonstrated when played over the air as the adversarial
examples need to be fed directly into the ASR system.
Approaches, which did work over the air, have only been tested
in a static setup (i. e., fixed position of speaker and microphone with
a fixed distance). Yakura‚Äôs and Sakuma‚Äôs [37] approach can hide
the target transcription but requires physical access to the room
to playback the audio while optimizing the adversarial example,
which limits their attack to one very specific room setup and is
very time costly. Szurley and Kolter [32] published room-dependent
robust adversarial examples, which even worked under constraints
given by a psychoacoustic model, describing the human perception
of sound. However, their adversarial examples have only been eval-
uated in an anechoic chamber (i. e., a room specifically designed
to absorb reflections). The attack can, therefore, not be used in
real-world scenarios, but only in carefully constructed laboratories
with properties that are never given in natural environments. In
other successful over-the-air attacks, human listeners can easily
recognize the target transcription once they are alerted to its con-
tent [1, 7]. Chen et al. [10] showed a first over-the-air attack against
the end-to-end recognition system DeepSpeech [16], relying on a
database of measured room transfer functions.
In contrast, our approach is inspired by Athalye et al.‚Äôs semi-
nal work: A real-world 3D-printed turtle, which is recognized as
a rifle from almost every point of view due to an adversarial per-
turbation [4]. The algorithm for creating this 3D object not only
minimizes the distortion for one image, but for all possible pro-
jections of a 3D object into a 2D image. We borrow the idea and
transfer it to the audio domain, replacing the projections by convo-
lutions with RIRs, thereby hardening the audio adversarial example
against the transmission through varying rooms.
Contributions. With Imperio, we introduce the first method
to compute generic and robust over-the-air adversarial examples
against hybrid ASR systems . We achieve this by utilizing an RIR
generator to sample from different room setups. We implement a
full, end-to-end attack that works in both cases, with and without
psychoacoustic hiding. In either case, we can produce successful
robust adversarial examples. With our generic approach, it is possi-
ble to induce an arbitrary target transcription in any kind of audio
without physical access to the target room.
More specifically, for the simulation, the convolution with the
sampled RIR is added as an additional layer to the ASR‚Äôs underlying
neural network, which enables us to update the original audio
signal directly under the constraints given by the simulated RIR.
For this purpose, the RIRs are drawn out of a distribution of room
setups to simulate the over-the-air attack. Using this approach,
adversarial examples are hardened to remain robust in real over-
the-air attacks across various room setups. We also show a reduction
of the added perturbations based on psychoacoustic hiding [41], by
including hearing thresholds in the backpropagation, as proposed
by Sch√∂nherr et al. [29].
We have implemented the proposed algorithm to attack the
hybrid DNN-HMM ASR system Kaldi [26] under varying room
conditions. We demonstrate that generic adversarial examples can
be computed that are transferable to different rooms and work
without line-of-sight, distances in the range of meters, and even if
the microphone records no direct sound but only a reflection. In
fact, we even show that our generic approach, using only simulated
RIRs, creates more robust adversarial examples compared to real
measured examples indicating that no prior knowledge about the
attack setup is required for our attack.
In summary, we make the following three key contributions:
‚Ä¢ Robust Over-The-Air Attack. We propose a generic ap-
proach to generate robust over-the-air adversarial examples
for DNN-HMM-based ASR systems. The attack uses a DNN
convolution layer to simulate the effect of arbitrary RIRs,
which allows us to alter the raw audio signal directly.
‚Ä¢ Psychoacoustics. We show that the attack can be combined
with psychoacoustic methods for reducing the perceived
distortions.
‚Ä¢ Performance Analysis. We evaluate the success rate of the
adversarial attack and analyze the amount of added perturba-
tion. We investigate the influence of increasing reverberation
time, increasing microphone-to-speaker distances, different
rooms, and no direct line-of-sight between speaker and mi-
crophone.
Imperio: Robust Over-the-Air Adversarial Examples for Automatic Speech Recognition Systems
ACSAC 2020, December 7‚Äì11, 2020, Austin, USA
Figure 2: Overview of a state-of-the-art hybrid ASR system with the three main components of the ASR system: feature ex-
traction, calculating pseudo-posteriors with a DNN, and decoding.
A demonstration of our Imperio attack is available online at
http://imperio.adversarial-attacks.net, where we present several
adversarial audio files which have been successfully tested when
played over-the-air.
2 BACKGROUND
In the following, we provide an overview of the ASR system that
we used in the attack and describe the general approach to calculate
audio adversarial examples. Furthermore, we discuss how room
simulations can be performed with the help of RIRs and briefly
introduce the necessary background from psychoacoustics as these
are used to hide the attack.
2.1 Automatic Speech Recognition
For the demonstration of an end-to-end attack, we chose the open-
source speech recognition toolkit Kaldi [26], which has been used
in previous attacks [29, 39] and is also used in commercial tools
like Amazon‚Äôs Alexa [29]. In Figure 2, a high-level overview of