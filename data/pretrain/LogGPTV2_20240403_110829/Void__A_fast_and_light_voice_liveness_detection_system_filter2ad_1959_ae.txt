### Void: Lightweight and Efficient Voice Replay Attack Detection

#### Introduction
Void is a lightweight, single-classification model designed to detect voice replay attacks. It uses only 97 features, making it significantly more efficient in terms of memory and computational resources compared to existing solutions. This document provides an overview of Void's performance, deployment scenarios, and limitations, as well as a comparison with other state-of-the-art methods.

#### Performance Comparison
- **Memory and Speed**: 
  - Compared to the STFT-LCNN solution, Void uses 153 times less memory and is approximately 8 times faster.
  - Void is 1.8 times faster and uses 87 times less memory than the baseline CQCC-GMM solution.
  - Void’s feature size and testing time (detailed in Section 7.4) meet the near-zero-second latency and low model complexity requirements.

- **Detection Accuracy**:
  - Void achieves an Equal Error Rate (EER) of 11.6%, which is better than the second-best solution in the ASVspoof competition [10].
  - Although this EER is higher than the 10% requirement, our ensemble solution using MFCC-GMM (which is moderately light and already used in speech recognition services) achieves an 8.7% EER, meeting the EER requirement.
  - Against our own dataset, Void demonstrated an EER of 0.3%.

#### Deployment Scenarios
- **On-Device Deployment**:
  - Given its lightweight nature, Void can be deployed at the device level. When a user submits a voice command, the voice assistant running on the user’s device first makes a voice liveness decision and drops any attack-like commands immediately.
  - This on-device deployment does not introduce additional computational burden on servers.

#### Low-Incidence Population
- **Usage Context**:
  - In practice, Void would be used by a low-incidence population where the number of replay attacks is much smaller than the number of legitimate uses.
  - Even with a threshold value set to minimize false rejection rates (e.g., lower than 5%), users might occasionally experience infrequent voice command rejections.
  - For example, for light users who use fewer than 20 commands per month, there would be about five falsely rejected commands every five months.

- **Home Usage**:
  - The incidence level changes when voice assistants are used in homes, where frequent loudspeaker noises from TV speakers and standalone speakers can stress the system.
  - Accurate detection and filtering of loudspeaker noises improve the reliability and efficiency of voice assistants, reducing false acceptances and improving speech-to-text translation.

#### Limitations
- **Testing Against High-Quality Devices**:
  - Void was tested against the ASVspoof dataset, which includes 26 different playback devices and 25 different recording devices.
  - Void’s performance degrades when high-quality speakers, such as expensive studio monitors, are used to replay recorded samples.
  - Adversarial attacks that involve altering frequency responses or exploiting SVM gradients can compromise Void, but such attacks require strong signal processing expertise.

#### Related Work
- **Existing Approaches**:
  - Recent studies have shown that voice assistants are vulnerable to various forms of voice presentation attacks [6, 11, 12, 20, 23, 33].
  - Methods like “VoiceLive” [27] and articulatory gesture-based liveness detection [3] have been proposed, but they have specific hardware or proximity requirements.
  - Other approaches, such as leveraging magnetic fields [12] or sub-bass region energy [14], have limitations and can be compromised by controlling ambient noise power.

- **Machine Learning-Based Solutions**:
  - Many solutions in the 2017 ASVspoof competition used an ensemble approach with CQCC-GMM as the baseline model, which is complex and uses about 14,000 features.
  - STFT-LCNN, one of the top-performing models, is unacceptably heavy and slow despite its low EER.
  - Tom et al. [17] achieved 0% EER using Residual Networks and group delay grams, but their model training methods and assumptions differ from the ASVspoof standards.

#### Conclusion
- **Key Advantages**:
  - Void analyzes spectral power patterns of voice signals to detect replay attacks.
  - It runs on a single efficient classification model with 97 features and does not require additional hardware.
  - Experiments on two large datasets showed that Void can achieve 0.3% EER on our own dataset and 11.6% EER on the ASVspoof evaluation set.
  - Void is resilient to various adversarial attacks, including hidden commands, inaudible voice commands, and EQ manipulation.

- **Future Directions**:
  - Further research can focus on enhancing Void’s robustness against high-quality speaker replays and sophisticated adversarial attacks.
  - Exploring the integration of Void with other security measures can provide a more comprehensive defense against voice replay attacks.

#### Acknowledgments
This work was supported by Samsung Research and NRFK (2019R1C1C1007118). The authors thank all anonymous reviewers and Carrie Gates for their valuable feedback. Hyoungshick Kim is the corresponding author.

#### References
[1] Y. Wang, R.J. Skerry-Ryan, D. Stanton, Y. Wu, R. J. Weiss, N. Jaitly, Z. Yang, Y. Xiao, Z. Chen, S. Bengio, Q. Le, Y. Agiomyrgiannakis, R. Clark, R. A. Saurous, “Tacotron: Towards End-to-End Speech Synthesis”, in Proceedings of the 18th INTERSPEECH, 2017.
...
[37] V. Gunnarsson, “Assessment of nonlinearities in loudspeakers”, in Chalmers University of Technology, 2010.