consists of three parts: speciﬁcation tests, pairing tests, and
logic tests.
Speciﬁcation test validates the input parameters and re-
turn values of the standard system calls. We check the re-
turn value and the content of the buﬀer. For example, the
test checks if the TCP driver detects a collision with an ex-
isting port number when calling a bind() system call. The
speciﬁcation test also needs to repeat with diﬀerent orders
of system call events and packet events as the execution re-
sult depends on their execution order. To achieve that, our
test suite enumerates every possible ordering. For example,
Figure 5 illustrates two diﬀerent cases for accept(): “re-
turning already established connection” and “blocking until
new connection has arrived”.
Pairing test ensures that the code behaves in a match-
ing manner with its counterpart because the communication
may fail regardless of the speciﬁcation test result. It tests if
the data transmitted from one side is received correctly at
the other side. For example, even though write() system
call reports back the success of a transmission, packets may
have been dropped or unrecognized in the lower layers or in
read() implementation running at the destination virtual
host due to bugs.
Logic test validates if the implementation conforms with
the runtime requirements such as congestion control. Nei-
ther speciﬁcation nor pairing tests covers correctness of con-
text-dependent runtime behaviour because they are black-
box approaches conﬁrming the execution results statically.
For example, unsolicited or duplicate ACKs are dependent
to the TCP protocol states and not straightforward to val-
idate. We leverage the existing analysis tools for the logic
test, which has reduced our development eﬀort greatly at the
same time making our framework easy to maintain. The
framework generates the packet traces in the widely-used
PCAP format. We use Wireshark since it provides context-
dependent protocol checks such as advanced TCP ﬁlters ver-
ifying SEQ/ACK numbers. For simpler tests, more options
are available—such as Packetdrill [13] providing packet-level
assertions to verify constant ﬁelds and checksums.
4 KENSv2 Assignments
We are currently using the prototype of KENSv2 frame-
work in a computer networks course for undergraduate stu-
dents as a programming assignment. The goal of the as-
signment is to help the students to understand how actual
network layers operate by requiring them to participate in
TCP implementation.
Figure 5: Example result of a successful test result
What we expect the students to do are as follows:
• Manipulating protocol headers properly
• Demultiplexing ﬂows from the lower layer
• Multiplexing ﬂows from the upper layer
• Context management for demultiplexed ﬂows
• Implementing functions in protocol speciﬁcation
What we do NOT want the students to deal with are as
follows:
• Hassles of managing multiple threads and protecting
critical regions
• Issues on connecting their network stacks with other pre-
built network stacks
• Reinventing the wheel such as commonly used data struc-
tures (e.g. lists, maps)
• Platform compatibility issues
In the assignment we split the TCP layer implementation
into a series of small tasks (sub-assignment) as shown in the
following class schedule:
• (Week 1) Assigning own TCP context for each socket
creation request
• (Week 2) Implementing basic accept/connect protocol
• (Week 3,4) Data transfer on reliable network connection
• (Week 5) Data transfer and connection establishment
on unreliable network connection
• (Week 6) Implementing basic AIMD congestion algo-
rithm
We gave students two weeks to submit each sub-assignment,
and they had a week oﬀ between each assignment. As we did
not provide any skeleton codes except the abstract function
interfaces, students had to design their own TCP context
data structure, demultiplexer, reorder window, etc. We left
the implementation details to the students’ discretion.
In spring 2014, 49 students participated in the project,
supervised by 3 TAs. Students worked in pairs as a team to
work on the assignments together. This was an incremental
assignment and the ﬁnal submissions consist of hundreds to
2K lines of code.
-----------------------------------------------------------Starting testListen     CUnit - A unit testing framework for C - Version 2.1-2     http://cunit.sourceforge.net/Suite: testListen  Test: __testListen_Accept_Before_Connect ...passed  Test: __testListen_Accept_After_Connect ...passed  Test: __testListen_Accept_Multiple ...passed  Test: __testListen_Multiple_Interfaces ...passedRun Summary:    Type  Total    Ran Passed Failed Inactive              suites      1      1    n/a      0        0               tests      4      4      4      0        0             asserts    145    145    145      0      n/aElapsed time =    0.000 secondstestListen: progress = 4/4-----------------------------------------------------------666Figure 8: Transmission rate over reliable network
(0.1% drop rate)
Figure 9: Bytes on ﬂight over unreliable network
(0.1% drop rate)
5.3 Correctness of Header Manipulation
We want to check the correctness of TCP checksum, whether
a user has sent unseen ACK number, etc. Wireshark pro-
vides most veriﬁcation algorithms we want. After the test
application is ﬁnished, we analyze the generated PCAP log
via Wireshark and check whether an implementation vio-
lates the TCP protocol compatibility.
5.4 Reliable Transfer over Unreliable Network
KENSv2 physical layer supports artiﬁcial drop/reorder/
corruption of packets. The framework allows the veriﬁca-
tion of TCP behaviours on unreliable connections by simply
turning on the unreliable transfer mode. Our Week 5 assign-
ment is simply announced as passing same test suite while
unreliable transfer mode is turned on. Students can observe
the realistic dynamics of Bytes Per Second under these con-
ditions.
5.5 Implementing congestion control and its veri-
ﬁcation
Students can implement any TCP congestion control al-
gorithms as KENSv2 provides the virtual system clock and
registration of timers. We oﬀered students to implement
TCP Reno algorithm7. Without any packet drops, the net-
work I/O throughput looks ﬂat like Figure 7. If there are
some packet drops, the network throughput looks like Fig-
ure 8. However, this does not imply that AIMD congestion
control is working. To distinguish AIMD congestion con-
trol from multiple retransmissions (though both supports
reliable transfers over unreliable network), we have applied
advanced TCP ﬁlters from Wireshark. These ﬁlters compute
and compare SEQ/ACK numbers and allows us to determine
how many bytes are on ﬂight and not ACKed. Figure 9 il-
lustrates the halved window size on fast-retransmission and
the slow start phase on timeout. Wireshark ﬁlters also de-
tect fast-retransmissions and timeouts. Currently we have
manually observe the macroscopic behaviour of congestion
control because the desired windows size is implementation-
speciﬁc, for example, depends on the initial window size and
round-up/round-down choices. However, we plan to adopt
TShark (Terminal version of Wireshark) to automate pars-
ing the ﬁlter results and evaluation of the logic test.
7http://tools.ietf.org/html/rfc6582
Figure 6: Example result of a failed test result
Figure 7: Transmission rate over reliable network
5 Evaluation of Students’ Submissions
We had 49 students working in pair and collected 23 sub-
missions for each assignment. In this section, we introduce
how we evaluate the assignments using our framework.
5.1 Correctness of system call functionality
Each system call implementation is required to satisfy
some functionalities. Some examples of functionalities we
want to verify include:
• Finding existing TCP context with port number/IP ad-
dress
• Checking port number collision while binding address to
socket
• Returning correct socket address on getsockname
• Backlog management
Our test suite contains assert statements for system calls
on various execution environment. We have placed virtual
system events to cover every TCP state transitions. Also,
we have tests that covers some complicated situations. Fig-
ure 6 contains corner cases of bind() system call. We
verify the functionalities by checking whether the students’
implementation passes all asserts.
5.2 Correctness of Data Transfer
The core function of TCP is to send data from one to
the other. We verify it by comparing the sent data and
the received data byte-by-byte. This transmission request is
handled by a virtual user application that generates proper
system call requests (socket-connect-write-close).
-----------------------------------------------------------Starting testBind     CUnit - A unit testing framework for C - Version 2.1-2     http://cunit.sourceforge.net/Suite: testBind  Test: __testBind_Simple ...passed  Test: __testBind_GetSockName ...passed  Test: __testBind_DoubleBind ...passed  Test: __testBind_OverlapPort ...passed  Test: __testBind_OverlapClosed ...passed  Test: __testBind_DifferentIP_SamePort ...FAILED    1. testbind.c:244  - CU_ASSERT_EQUAL(err,0)    2. testbind.c:245  - CU_ASSERT_TRUE(ret)  Test: __testBind_SameIP_DifferentPort ...passedRun Summary:    Type  Total    Ran Passed Failed Inactive              suites      1      1    n/a      0        0               tests      7      7      6      1        0             asserts     60     60     58      2      n/aElapsed time =    0.000 secondstestBind: progress = 6/7-----------------------------------------------------------Fast RetransmissionTimeout6677 Acknowledgements
KENSv2 is based on KENS (KAIST Educational Net-
work System) developed by Junehwa Song and his students
(http://nclab.kaist.ac.kr/kens). The original motiva-
tion and design of KENS has been a great inspiration. We
are grateful to Yejin Park and Junhyun Shim for their help
with writing. This work was supported by the Basic Science
Research Program by the National Research Foundation of
Korea (NRF) of MSIP (2014R1A2A1A01007580).
8 References
[1] James F Kurose and Keith W Ross. Computer networking:
a top-down approach featuring the Internet. Pearson
Education India, 2005.
[2] Dan Wendlandt, Martin Casado, Paul Tarjan, and Nick
McKeown. The clack graphical router: visualizing network
software. In Proceedings of the 2006 ACM symposium on
Software visualization, pages 7–15. ACM, 2006.
[3] John DeHart, Fred Kuhns, Jyoti Parwatikar, Jonathan
Turner, Charlie Wiseman, and Ken Wong. The open
network laboratory. In ACM SIGCSE Bulletin. ACM, 2006.
[4] Martin Casado and Nick McKeown. The virtual network
system. In ACM SIGCSE Bulletin. ACM, 2005.
[5] Bob Lantz, Brandon Heller, and Nick McKeown. A network
in a laptop: rapid prototyping for software-deﬁned
networks. In ACM SIGCOMM HotNets. ACM, 2010.
[6] Nikhil Handigol, Brandon Heller, Vimalkumar Jeyakumar,
Bob Lantz, and Nick McKeown. Reproducible network
experiments using container-based emulation. In
Proceedings of the 8th international conference on
Emerging networking experiments and technologies, pages
253–264. ACM, 2012.
[7] Ben Pfaﬀ, Anthony Romano, and Godmar Back. The
pintos instructional operating system kernel. In ACM
SIGCSE Bulletin, volume 41, pages 453–457. ACM, 2009.
[8] Luigi Rizzo. netmap: A Novel Framework for Fast Packet
I/O. In USENIX ATC, 2012.
[9] PacketShader I/O Engine.
github.com/PacketShader/Packet-IO-Engine.
[10] Intel DPDK (Data Plane Development Kit).
https://dpdk.org.
[11] Marko Lackovic, Robert Inkret, and Miljenko Mikuc. An
approach to education oriented tcp simulation. In SoftCOM
2002: international conference on software,
telecommunications and computer networks, pages 181–185,
2002.
[12] Matt Mathis, John Heﬀner, and Raghu Reddy. Web100:
extended tcp instrumentation for research, education and
diagnosis. ACM SIGCOMM Computer Communication
Review, 33(3):69–79, 2003.
[13] Neal Cardwell, Yuchung Cheng, Lawrence Brakmo, Matt
Mathis, Barath Raghavan, Nandita Dukkipati,
Hsiao-keng Jerry Chu, Andreas Terzis, and Tom Herbert.
packetdrill: Scriptable network stack testing, from sockets
to packets. In USENIX Annual Technical Conference,
pages 213–218, 2013.
Figure 10: LoC distribution for the ﬁnal project
5.6 Diversity of Submissions
Until the end of the semester, we had 23 submissions on
total. Figure 10 shows the distribution of LoC8 of all sub-
missions. The shortest solution had 692 LoC and the longest
had 1588 LoC. This high variation of LoC shows that our
abstraction is general and embraces diverse solutions by stu-
dents, i.e., freedom of design. Also, the amount of assign-
ment is about a thousand LoC, which is suitable for a single
semester assignment.
6 Summary and Future Work
KENSv2 is an educational framework for transport and
network layer implementation that supports:
• Realistic Protocol Implementation
• Incremental Development
• Automated Test Suite
• Packet Level Inspection
Our improvements are based on eight years of accumulated
lab experiences. In Spring 2014 we are already experiencing
beneﬁts from the improvements. We could run TCP imple-
menting assignments over 49 students having 3 TAs for man-
agement, which is halved from the previous semester. We
plan to release the refactored framework as an open-source
software and encourage other universities to try KENSv2 by
this year.
We have the following extension ideas for KENSv2. The
ﬁrst is to extend our automated test suite to cover the IP
layer. The current version has a functional interference
and a reference implementation of the IP layer including
packet fragmentation and reassembly, but lacks automated
test suites. The second is to redesign KENSv2’s data link
layer as a generalized adaptor that can receive/transmit
packets from/to various underlying packet IO schemes, such
as userspace packet IO libraries or the native Linux kernel.
The third is to add an IPv6 layer. We expect that IPv6 will
become a standard suite for educational frameworks as its
adoption is going to accelerate in the near future and the
IPv4 address space is being exhausted. Finally, though our
system call abstraction for blocking calls can represent the
blocking behaviour of both connect() and accept(), the
test code itself does not look like real-world TCP applica-
tions. We have a plan to extend our system call abstraction
layer to cover every system call with a uniﬁed interface.
8The number of lines are measured with CLOC. See http:
//cloc.sourceforge.net/
01234567008009001000110012001300140015001600Lines of CodeNumber of Submissions668