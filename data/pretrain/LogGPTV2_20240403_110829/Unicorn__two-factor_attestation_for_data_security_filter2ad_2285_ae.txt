notice the transition between protected and unprotected in-
put ﬁelds. These complexities could be attributed to using
the untrusted OS and applications for everything except sen-
sitive user input (for keeping the TCB small). A user study
of Bumpy’s input mechanisms [16] also highlights several
user interface issues. Unicorn sidesteps many of these is-
sues by taking the user out of the loop during all operations
except setup. TrustVisor [19] improves the performance of
Flicker by implementing a software-based micro-TPM mod-
ule that executes on the primary CPU instead of the slow
TPM hardware.
Root of trust installation. Immutability of uApps im-
ages is similar to the root of trust installation (ROTI [31])
system. Installers distributed by trusted parties are used for
installing all system software and system-speciﬁc data and
secrets. At the end of an installation, ROTI computes the
hash of all (static) ﬁles in the root ﬁle system, and seals a ﬁle
containing those hashes to the TPM. Sealing ensures that
this hash ﬁle can be opened only if the system is loaded
again in the same state (i.e., the same PCR values in the
TPM). ROTI enables attestation to remote parties but does
not address user authentication.
Terra: VM-based trusted computing. Terra [7] enables
users to simultaneously use open-box VMs (with a commod-
ity OS and user applications) and closed-box VMs (with a
custom OS and application) on the same computer. Terra
depends on a trusted virtual machine monitor (TVMM), and
the hardware and TVMM enable closed-box VMs to identify
their software stack to a remote party. However, user attes-
tation and secure UI issues remain unaddressed by Terra.
Other authentication methods. A large amount of work
has gone into protecting user credentials from theft or leak-
age through social engineering. For example, split-trust mech-
anisms (e.g., Balfanz and Felten [3], and MP-Auth [18]),
and two-factor authentication mechanisms all protect user
credentials (and optionally parts of a session). However,
none protects the conﬁdentiality of an entire user session.
To achieve a malware-free execution environment, we rely
on DRTM CPU instructions; current malware cannot evade
hardware-based protections of these instructions. Addition-
ally, Unicorn eﬀectively enables two-factor attestation: mal-
ware cannot bypass the attestation checks either at the user-
end, or at the server-end. As the PSD links attestation with
authentication, Unicorn can guarantee both a malware-free
user session, and resistance to social engineering attacks.
8. CONCLUSION
We have presented Unicorn, which both reduces the bur-
den on the user by removing them from the attestation and
authentication process and enables fast switching between a
general-purpose user OS and a secure uApp OS using a novel
mechanism that avoids a full machine reboot. The key idea
behind Unicorn is a PSD that is able to verify the integrity
of the user’s computer and only use the user’s authentica-
tion secrets if the integrity can be veriﬁed. Combining this
with veriﬁcation of the attestation by a remote server or
the local TPM via sealed-storage produces a two-factor au-
thentication, which forces the attacker to both gain physical
access to the user’s computer and compromise the PSD to
successfully gain access to Unicorn-protected user data.
In building our Unicorn prototype we found that a great
deal of standard functionality in commodity desktop sys-
tems could be repurposed to make implementing Unicorn
easy: suspend-to-disk functionality on the desktop system
was used to save the running state of the user OS to disk,
and hardware Intel TXT support for conﬁning buggy device
drivers using DMA-remapping was used to protect against
malicious commands left on devices by the user OS. We also
found that the implementation of the Unicorn attestor on
26Android was straightforward and many of the required com-
ponents, such as crypto libraries and QR code libraries are
relatively mature. While commodity code doesn’t always
meet the ideal security requirements of a small code foot-
print and strict access controls, we ﬁnd it encouraging that
much of the technology to implement the components of
Unicorn already exists. This suggests that with more en-
gineering eﬀort, a deployable version of Unicorn could be
implemented with relatively little eﬀort.
Acknowledgments
We are grateful to our shepherd Mike Reiter and the anony-
mous reviewers for their insightful comments and advice.
The ﬁrst author was supported by an NSERC post-doctoral
fellowship. This work was also supported by funding from
the NSERC ISSNet Strategic Network, an NSERC Engage
Grant, and an ORF Grant.
9. REFERENCES
[1] Anti-Phishing Working Group (APWG). Phishing activity
trends report: 1st quarter 2010. http://www.antiphishing.
org/reports/apwg_report_Q1_2010.pdf.
[2] A. M. Azab, P. Ning, Z. Wang, X. Jiang, X. Zhang, and
N. C. Skalsky. HyperSentry: enabling stealthy in-context
measurement of hypervisor integrity. In ACM CCS’10,
Chicago, IL, USA, Oct. 2010.
[3] D. Balfanz and E. Felten. Hand-held computers can be
better smart cards. In USENIX Security Symposium,
Washington, DC, USA, Aug. 1999.
[4] S. Bratus, N. D’Cunha, E. Sparks, and S. W. Smith.
TOCTOU, traps, and trusted computing. In Trusted
Computing—Challenges and Applications (TRUST’08),
Villach, Austria, Mar. 2008.
[5] K. Butler, S. McLaughlin, and P. McDaniel. Kells: A
protection framework for portable data. In ACSAC’10,
Austin, TX, USA, Dec. 2010.
[6] eWeek.com. Zeus trojan mobile variant intercepts SMS
passcodes from bank sites. News article (Feb. 22, 2011).
[7] T. Garﬁnkel, B. Pfaﬀ, J. Chow, M. Rosenblum, and
D. Boneh. Terra: A virtual machine-based platform for
trusted computing. In SOSP’03, Bolton Landing, NY,
USA, Oct. 2003.
[8] S. Garriss, R. C´aceres, S. Berger, R. Sailer, L. van Doorn,
and X. Zhang. Trustworthy and personalized computing on
public kiosks. In Mobile Systems, Applications and Services
(Mobisys’08), Breckenridge, CO, USA, June 2008.
[9] K. Goldman, R. Perez, and R. Sailer. Linking remote
attestation to secure tunnel endpoints. In Scalable Trusted
Computing (STC’06), Fairfax, VA, USA, Nov. 2006.
[10] D. Grawrock. The Intel Safer Computing Initiative:
Building Blocks for Trusted Computing. Intel Press, 2006.
[11] H-online.com. Hacker extracts crypto key from TPM chip.
News article (Feb. 10, 2010).
[12] Intel. Intel trusted execution technology (TXT) software
development guide. Technical article (Dec. 2009).
http://download.intel.com/technology/security/
downloads/315168.pdf.
[13] Intel. Trusted boot. Open-source project (version Oct. 5,
2010). http://sourceforge.net/projects/tboot/.
[14] B. Kauer. OSLO: Improving the security of trusted
computing. In USENIX Security Symposium, Boston, MA,
USA, Aug. 2007.
[15] G. Klein, K. Elphinstone, G. Heiser, J. Andronick,
D. Cock, P. Derrin, D. Elkaduwe, K. Engelhardt,
R. Kolanski, M. Norrish, T. Sewell, H. Tuch, and
S. Winwood. seL4: Formal veriﬁcation of an OS kernel. In
SOSP’09, Big Sky, MT, USA, Oct. 2009.
[16] A. Libonati, J. M. McCune, and M. K. Reiter. Usability
testing a malware-resistant input mechanism. In NDSS’11,
San Diego, CA, USA, Feb. 2011.
[17] P. Loscocco and S. Smalley. Integrating ﬂexible support for
security policies into the Linux operating system. In
USENIX Annual Technical Conference, Boston, MA, USA,
June 2001.
[18] M. Mannan and P. van Oorschot. Leveraging personal
devices for stronger password authentication from
untrusted computers. Journal of Computer Security,
19(4):703–750, 2011.
[19] J. M. McCune, Y. Li, N. Qu, Z. Zhou, A. Datta, V. Gligor,
and A. Perrig. TrustVisor: Eﬃcient TCB reduction and
attestation. In IEEE Symposium on Security and Privacy,
Oakland, CA, USA, May 2010.
[20] J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and
H. Isozaki. Flicker: An execution infrastructure for TCB
minimization. In The European Conference on Computer
Systems (EuroSys’08), Glasgow, Scotland, UK, Apr. 2008.
[21] J. M. McCune, A. Perrig, and M. K. Reiter. Safe passage
for passwords and other sensitive data. In NDSS’09, San
Diego, CA, USA, Feb. 2009.
[22] H. Nellitheertha. Reboot Linux faster using kexec. IBM
technical library (May 4, 2004). http://www.ibm.com/
developerworks/linux/library/l-kexec.html.
[23] J. R. Okajima. Advanced multi layered uniﬁcation
ﬁlesystem. Open-source project (version 2.1).
http://aufs.sourceforge.net/.
[24] B. Parno, J. M. McCune, and A. Perrig. Bootstrapping
trust in commodity computers. In IEEE Symposium on
Security and Privacy, Oakland, CA, USA, May 2010.
[25] R. Sailer, X. Zhang, T. Jaeger, and L. van Doorn. Design
and implementation of a TCG-based integrity measurement
architecture. In USENIX Security Symposium, San Diego,
CA, USA, Aug. 2004.
[26] J. Samuel, N. Mathewson, J. Cappos, and R. Dingledine.
Survivable key compromise in software update systems. In
ACM CCS’10, Chicago, IL, USA, Oct. 2010.
[27] A. Seshadri, M. Luk, N. Qu, and A. Perrig. SecVisor: A
tiny hypervisor to provide lifetime kernel code integrity for
commodity OSes. In SOSP’07, Stevenson, WA, USA, Oct.
2007.
[28] A. Shieh, D. Williams, E. G. Sirer, and F. B. Schneider.
Nexus: A new operating system for trustworthy computing.
In SOSP’05, Brighton, UK, Oct. 2005.
[29] C. Soghoian and S. Stamm. Certiﬁed lies: Detecting and
defeating government interception attacks against SSL. In
Financial Cryptography and Data Security (FC’11), St.
Lucia, 2011.
[30] A squashed read-only ﬁle system for Linux. Open-source
project (version 4.1, Sept. 19, 2010).
http://squashfs.sourceforge.net/.
[31] L. St. Clair, J. Schiﬀman, T. Jaeger, and P. McDaniel.
Establishing and sustaining system integrity via root of
trust installation. In ACSAC’07, Miami, FL, USA, Dec.
2007.
[32] F. Stumpf, O. Tafreschi, P. R¨oder, and C. Eckert. A robust
integrity reporting protocol for remote attestation. In
Workshop on Advances in Trusted Computing (WATC’06),
Tokyo, Japan, Nov. 2006.
[33] Twisted Matrix Labs. Twisted: Event-driven networking
engine. Open-source project.
http://twistedmatrix.com/trac/wiki.
[34] P. van Oorschot and G. Wurster. Reducing unauthorized
modiﬁcation of digital objects. IEEE Transactions on
Software Engineering, 2011. To appear.
[35] A. Vasudevan, B. Parno, N. Qu, V. D. Gligor, and
A. Perrig. Lockdown: A safe and practical environment for
security applications. Technical Report
CMU-CyLab-09-011, CyLab, Carnegie Mellon University,
July 2009. http://repository.cmu.edu/cylab/5/.
27[36] A. Whitten and J. D. Tygar. Why Johnny can’t encrypt: A
usability evaluation of PGP 5.0. In USENIX Security
Symposium, Washington, D.C., USA, Aug. 1999.
[37] R. Wojtczuk, J. Rutkowska, and A. Tereshkin. Another
way to circumvent Intel Trusted Execution Technology:
Tricking SENTER into misconﬁguring VT-d via SINIT bug
exploitation. Technical article (Dec., 2009).
http://theinvisiblethings.blogspot.com/2009/12/
another-txt-attack.html.
APPENDIX
A. BACKGROUND
In this section, we give some background on Intel Trusted
Execution Technology (TXT) and its interaction with the
Trusted Platform Module (TPM) chip. We only brieﬂy dis-
cuss TXT here; see e.g., Grawrock [10], TXT software de-
velopment guide [12], and the tboot project [13] for details.
Trusted Platform Module. A TPM is a hardware chip
that provides the following functionality: (1) protected stor-
age for persistent secrets (NV-RAM) and for Platform Con-
ﬁguration Registers (PCRs), which contain measurements
of the running state of the machine; (2) a protected execu-
tion environment for certain cryptographic operations (e.g.,
SHA-1 hash, RSA encryption/signature); (3) and the ability
to generate attestation quote responses with current PCR
values. TPMs implement two types of PCRs: static PCRs,
which can only be reset by a system reboot, and dynamic
PCRs, which can be reset by Dynamic Root of Trust Mea-
surement (DRTM). Each layer of software stack in the plat-
form is measured (i.e., hashed) and the measurements are
stored to a PCR using the extend operation. Extend ap-
pends the hash to a PCR by concatenating the current PCR
value with the new measurement and then computing a hash
over the combined value. This new hash value is then stored
in the PCR. Thus, PCRs contain a hash chain describing all
software that was loaded on the system since the PCR was
reset. Remote parties can request attestations of the PCR
values using the quote operation. To perform a quote op-
eration, the TPM must be initialized with an Attestation
Identity Key (AIK) pair. This AIK pair is generated by a
TPM and the private part of the key pair never leaves the
TPM chip. The public part of the key pair is certiﬁed by
a trusted Privacy Certiﬁcate Authority (CA) and should be
distributed to the attestor prior to the attestation request.
A quote request contains a speciﬁcation of which PCR values
need to be retrieved as well as a nonce used for freshness. In
response, the TPM computes a hash of the nonce and PCR
values, signs the hash with the AIK private key, and returns
the signature with the PCR values. The TPM 1.2 speciﬁca-
tion also deﬁnes localities, which restrict how the dynamic
PCRs can be modiﬁed. By default, all untrusted code ex-
ecutes in locality zero, the lowest privilege level. By exe-
cuting code in more privileged localities, software gains the
ability to extend/reset certain PCRs. TPMs also support
sealing and unsealing operations which bind data (e.g., a se-
cret key) to the current platform conﬁguration, as speciﬁed
by the chosen PCRs. Sealing takes a set of PCRs and data as
input, and encrypts the given data using the TPM’s Storage
Root Key (SRK), which never leaves the TPM. Unsealing
of the sealed data can be done only when the pre-speciﬁed
PCRs have the same values as during sealing.
Intel TXT. On their own, TPMs implement Static Root
of Trust Measurements (SRTM), where static PCRs can
only be reset by a full reboot of the machine. Intel TXT,
formally known as LaGrande Technology (LT), is a set of
hardware extensions available on recent Intel CPUs and
chipsets that implements Dynamic Root of Trust Measure-
ment (DRTM), also known as late launch. DRTM allows
the dynamic PCRs (PCRs 17-23) to be reset at any time by
entering a measured launch environment (MLE). The CPU
enters into and exits from the MLE via GETSEC[SENTER]
and GETSEC[SEXIT] instructions respectively. Before ex-
ecuting SENTER, an authenticated code (AC) module is
loaded into the processor’s internal memory (which is out of
reach of DMA devices or the external processor bus). The
CPU initially protects an MLE from DMA modiﬁcations by
loading it into one of two memory regions: (i) the DMA
protected range (DPR), a contiguous region (currently 3MB
in size) in the physical memory which is protected from all
DMA accesses; or (ii) the Intel VT-d protected memory re-
gions (PMRs), two ranges of physical memory addresses (one
in the lower 4GB and the other in the upper 4GB) which
are also DMA protected. The AC module is chipset-speciﬁc,
distributed in a binary form by Intel, and is authenticated
through a digital signature check (signed by Intel) by the
processor. SENTER proceeds only if the AC module can be
authenticated, and the MLE is loaded into the DPR or in a
PMR. The AC module checks several chipset and processor
conﬁgurations, and if successful, it then executes the MLE.
After an MLE has been established, it can facilitate trusted
boot into an OS kernel or hypervisor.
28