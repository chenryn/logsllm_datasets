be computed by intersecting it with each of the (at most
r) blocks of each of the jM j partitions. As the set represen-
tations are ordered, this can be done in time O(r jM j jKj).
As the number of blocks in every partition of K is boun-
ded by jKj, computing n greedy steps can be done in time
O(n r jM j jKj2).
We state next several inequalities between the values of
(cid:8)E and ^(cid:8)E , which we will later use when interpreting our
experimental results.
Relating (cid:8)E and ^(cid:8)E.
The de(cid:12)nition of a greedy strategy begs the question of
whether greedy strategies are also optimal. The following
example illustrates that this is not the case in general.
Example 6. Consider the set of partitions P = fff1g; f2g;
f3; 4; 5gg; ff1g; f2; 3; 4g; f5gg; ff1; 2; 3g; f4; 5ggg, a uniform
distribution, and the guessing entropy as a measure. A gree-
dy strategy re(cid:12)nes K to ff1g; f2g; f3; 4; 5gg in a (cid:12)rst step,
and to ff1g; f2g; f3; 4g; f5gg in a second step. Optimally,
however, one would (cid:12)rst pick ff1; 2; 3g; f4; 5gg and re(cid:12)ne it
to ff1g; f2g; f3g; f4g; f5gg in a second step.
greedy :: [Part k] -> Int -> [k] -> Part k
greedy f n keys = app n (greedystep f) [keys]
greedystep :: [Part k] -> Part k -> Part k
greedystep f pt = concat (map refine pt)
where refine b = minimumBy order (restrict b f)
Figure 2: Computing ^(cid:8)E in Haskell
Although Example 6 implies that ^(cid:8)E and (cid:8)E do not coin-
cide in general, we can establish the following relationships.
Proposition 4. For E 2 fH; G; W(cid:11)g, we have
1. ^(cid:8)E (1) = (cid:8)E (1),
2. for all n 2 N, ^(cid:8)E (n) (cid:21) (cid:8)E (n), and
3. if ^(cid:8)E (n) = ^(cid:8)E (n+1), then we have (cid:8)E (n0) = ^(cid:8)E (n0) =
^(cid:8)E (n), for all n0 (cid:21) n.
Proof. Assertions 1 and 2 follow directly from De(cid:12)niti-
ons 4 and 6. For Assertion 3, let a be the greedy strategy
underlying the de(cid:12)nition of ^(cid:8)E . ^(cid:8)E (n) = ^(cid:8)E (n + 1) implies
that Pa(n) cannot be re(cid:12)ned by intersection with a partition
from P, hence Pa(n) = TP 2P P , which re(cid:12)nes every parti-
tion that can be induced by intersection of elements from
P.
We will make use of Proposition 4 in our experiments. 4.2
shows that an implementation that is shown to be vulnerable
when analyzed with ^(cid:8)E must also be vulnerable with respect
to (cid:8)E . 4.3 implies that if ^(cid:8)E levels o(cid:11), then so does (cid:8)E , and
their values coincide. Hence we do not need to compute (cid:8)E
for arguments beyond this point.
4.3 An Implementation
For our experiments we have implemented ^(cid:8)E in Has-
kell [5]. We have chosen simplicity over e(cid:14)ciency, forgoing
sophisticated data structures and optimizations. Instead, we
represent sets as lists and partitions as lists of lists and re-
cursively compute greedy re(cid:12)nements of partitions. The core
routines are given in Figure 2.
The function greedy takes as arguments a list of keys,
a list of partitions f of the list keys, and an integer n. It
re(cid:12)nes the trivial partition [keys] by n-fold application of
a greedy re(cid:12)nement step through app. The re(cid:12)nement step
is implemented in greedystep, where each partition pt is
re(cid:12)ned by greedily re(cid:12)ning each individual block. This is
done in refine, which maps each block to its partition with
minimal rank among those obtained by restricting the ele-
ments of f to b with restrict. The rank of a partition is
given by the function order, which can be instantiated to
E 2 fH; G; W(cid:11)g. Applying order to the result of greedy
yields ^(cid:8)E . The simplicity of this implementation shows that
the automation of our techniques is indeed straightforward.
5. EXPERIMENTS
In this section, we report on case studies analyzing im-
plementations of di(cid:11)erent cryptographic algorithms with re-
spect to their vulnerability to timing and power attacks.
We focus on implementations in synchronous hardware as,
in this setting, time and power consumption are relatively
easy to determine.
As examples, we analyze the timing behavior of circuits
for multiplying integers and for exponentiation in (cid:12)nite (cid:12)elds
F2w . We also analyze the power consumption of a (constant-
time) circuit for multiplication in F2w . Exponentiation and
multiplication over F2w are relevant, for example, in the
generalized ElGamal encryption scheme, where decryption
consists of exponentiation followed by multiplication [23].
In the remainder of this section, we use the guessing entro-
py G as a measure of uncertainty and we abbreviate (cid:8)G by (cid:8)
and ^(cid:8)G by ^(cid:8), respectively. We assume a uniform probability
distribution in our experiments and compute the remaining
uncertainty with the formula given in Proposition 2.2.
5.1 Realization
Goals and Limitations.
Our goal is to compute bounds on the information that
realistic implementations may leak to active side-channel at-
tackers.
Computing (cid:8) using the algorithm from Theorem 1 is ex-
pensive. The time required is doubly exponential in the num-
ber of attack steps, and the sizes of the keyspace and the
message space are exponential in the number of bits used to
represent keys and messages, respectively. Hence, we cannot
feasibly compute (cid:8) for large parameter sizes.
We use two approximation techniques to address this pro-
blem.
1. We approximate (cid:8) by ^(cid:8). We will see that ^(cid:8) matches
(cid:8) on our example data, although this does not hold in
general (see Example 6).
2. We parameterize each algorithm by the bit-width w of
its operands. Our working assumption is that regulari-
ty in the values of (cid:8) for w 2 f2; : : : ; wmaxg re(cid:13)ects the
structural similarity of the parameterized algorithms.
This allows us to extrapolate to values of w beyond
wmax. To make this explicit, we will write (cid:8)w to deno-
te that (cid:8) is computed on w-bit operands.
Using both techniques, we can estimate (cid:8)w(n) for values of
w and n for which direct computation is infeasible.
Time and Power Estimation with Gezel.
We use the hardware description language Gezel [33] to
describe and simulate circuits. Synchronous circuits are mo-
deled in Gezel as automata, where one transition corre-
sponds to one clock cycle. The Gezel environment comes
with a compiler that maps circuit descriptions into a syn-
thesizeable subset of Vhdl. The translation is cycle-true in
that it preserves the circuit’s timing behavior within the gra-
nularity of clock cycles. In this way, the timing-guarantees
obtained by formal analysis translate to silicon implementa-
tions.
Precisely estimating a circuit’s power consumption is not
possible at this level of abstraction as it depends on the
physics of the semiconductor technology used. One needs
to employ technology-dependent power models for accura-
te predictions during simulation. In this paper, we take a
simple, technology-independent approach that is provided
by the Gezel environment to approximate a circuit’s power
consumption: we count the number of bit transitions during
each cycle. The rationale behind this is that, e.g., in CMOS
technology, the power dissipation of a signal that remains
^(cid:8)w(n)
 30
 25
 20
 15
 10
 5
 0
n=1 & n=2
padded
 2
 3
 4
 5
w
 6
 7
 8
Figure 3: Integer Multiplication
constant is negligible compared to a signal that changes.
Counting the number of bit transitions thus provides ap-
proximate information about the actual power consumption
and we will use it for our analysis. It is straightforward to
replace this simple measure with those given by more reali-
stic models. In this way, the precision of our analysis is only
bounded by the precision of the available power models.
Setup.
For each algorithm and each bit-width w 2 f2; : : : ; 8g,
we use the Gezel simulator to build value tables for the
side-channel f : f0; 1gw (cid:2) f0; 1gw ! O. For timing analysis,
we use O = N to represent the number of clock ticks until
termination. For power analysis, we use O = Nd to represent
the toggle count in each of the d clock cycles.
5.2 Results
In this section, we present our experimental results and
discuss their implications.
Timing Attacks against Integer Multiplication.
We represent a natural number k < 2w as a sequence
of w bits ki, with k = (cid:6)w(cid:0)1
i=0 ki2i. To multiply two natural
numbers m and k, the product m(cid:1)(cid:6)w(cid:0)1
i=0 ki2i can be expanded
to (: : : ((kw(cid:0)1 (cid:1) m) (cid:1) 2 + kw(cid:0)2 (cid:1) m) (cid:1) 2 + : : : ) (cid:1) 2 + k0 (cid:1) m, which
can easily be turned into an algorithm. Starting with p = 0,
one iterates over all the bits of k, beginning with the most
signi(cid:12)cant bit. If ki = 1, one updates p by adding m and then
doubling p’s value. Alternatively, if ki = 0, one updates p by
just doubling its value. At the end of the loop, p = m (cid:1) k. In
our implementation, the doubling and addition operations
each take one clock cycle. Hence, the running time re(cid:13)ects
the number of 1-bits in k, that is, k’s Hamming weight.
For illustration purposes, we use k as the key and m as the
message. For the interpretation of Figure 3, (cid:12)rst observe that
^(cid:8)w(1) = ^(cid:8)w(2) holds. Hence, by Proposition 4, the graph
actually depicts (cid:8)w.
There are two conclusions to be drawn from Figure 3.
First, the circuit’s timing behavior depends on the number
of 1-bits in the key. This leads to the hypothesis that the
Hamming weight of the key is revealed or, equivalently, that
two keys are indistinguishable i(cid:11) they have the same Ham-
ming weight. The equivalence class of w-bit arguments with
^(cid:8)w(n)
 4
 3.5
 3
 2.5
 2
 1.5
 1
 0.5
 0
n=1
n=2 & n=3
 2
 3
 4
 5
w
 6
 7
 8
^(cid:8)w(n)
 4
 3.5
 3
 2.5
 2
 1.5
 1
 0.5
 0
n=1 & n=2
 2
 3
 4
 5
w
 6
 7
 8
Figure 4: Finite-Field Exponentiation
Figure 5: Finite-Field Multiplication
Hamming weight l has precisely (cid:0)w
l (cid:1) elements. Hence, by
Proposition 2, the conditional guessing entropy for the cor-
responding partition is given by
2 . The
values computed using this expression match the solid curve
in Figure 3, which supports our hypothesis and con(cid:12)rms a
result from [20].
2w+1 Pw
1
l=0 (cid:0)w
l (cid:1)2 + 1
Second, Figure 3 shows that a single side-channel measure-
ment is enough to extract the maximal information revealed
by the circuit’s timing behavior. This follows as (cid:8)w(1) and
(cid:8)w(2) coincide and is due to the fact that the circuit’s run-
ning time is independent of the message. It is out of the scope
of information-(cid:13)ow analysis, as in [20], to reason about the
number of measurements needed to obtain such information.
We have also implemented and analyzed a variant of the
integer multiplication algorithm described above, where we
introduced a dummy computation step whenever no additi-
on operation takes place. In this way, the algorithm’s timing