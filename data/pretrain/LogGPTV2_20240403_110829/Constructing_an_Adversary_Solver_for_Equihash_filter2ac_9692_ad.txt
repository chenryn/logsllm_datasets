### Power Consumption Estimations

In Table VI, we present the power usage estimations for our major modules operating at 1 GHz. We assume latencies of 70 ns and 5 ns for off-chip and on-chip memory, respectively. Consequently, each queue before a merge stage contains 70 items, with 5 items stored directly in flip-flops (FFs).

When scaling the clock speed, most modules' power consumption is proportional to frequency, allowing for estimation accordingly. For lower frequencies, the prefetch queues can be shorter, thus saving energy, which is advantageous for adversaries. However, this optimization has a minor impact compared to the overall efficiency, so it is not considered here.

**Table VI: Component Power Estimations at 1 GHz**

| Component          | Smartcell (562 µW) | 4-way Merge (488 µW) | 8-way Merge (489 µW) | Queue (70, 5) (587 µW) | Prefetcher (467 µW) | Sort (406 µW) | Merge (565 µW) | Total (mW) |
|--------------------|---------------------|-----------------------|-----------------------|-------------------------|----------------------|-----------------|-----------------|-------------|
| Optimistic         | 562 µW             | 488 µW                | 587 µW                | 467 µW                  | 406 µW              | 565 µW         | 1.10 mW        | 1.38 mW     |
| Pessimistic        | 489 µW             | 471 µW                | 467 µW                | 587 µW                  | 406 µW              | 565 µW         | 1.32 mW        | 1.65 mW     |

### Detailed Module Descriptions

- **Smartcell**: A smartcell saves two sets of items with FFs, along with a binary comparator. A full insertion-sort module includes \( N_c \) such smartcells.
- **M-to-1 Merge Unit**: This unit stores only one item as output and has \( C(M, 2) \) comparators.
- **Prefetch Queue**: If read latencies of external and on-chip memory are expressed in ticks as \( L_e \) and \( L_o \), every prefetch queue is implemented with \( L_e - L_o \) items stored in on-chip memory and \( L_o \) items in FFs, with its power close to 0.5\((L_e + L_o)\) sets of FFs.
- **Prefetcher**: This includes an extra (narrow) queue to indicate ownership for fetched data, a set of encoder and decoder, and an address counter for each data queue.

### Performance and Power Consumption

At 500 MHz, under the (200, 9) configuration, our solver should produce 40.6 solutions per second and use 0.75-0.78 Watts of power, excluding microcontrollers, or 52-54 solutions per Joule. Under the (144, 5) configuration, we produce 5.36 solutions at the same frequency and using similar power, yielding 5.6-7.0 solutions per Joule. Compared to the best software solvers available, our method achieves significantly higher efficiency.

### Energy Efficiency

1. **Performance**: The linear sorting peripheral processes a full-length sequence every \( N_c + 1 \) cycles and speeds up when sequences are shorter. In both configurations, the first merging stages are the bottlenecks. Under (200, 9), one batch is processed every 2.10M cycles, solving 26.5 puzzles and yielding 40.6 solutions per second. Under (144, 5), one batch is processed every 33.6M cycles, solving 5.95 puzzles and yielding 10.7 solutions per second.
2. **Power Consumption**: Our design uses large amounts of FFs, binary comparators, and some on-chip memory. We estimate overall power based on the count of these elements. Using Synopsis Design Compiler, we collected power reports under SMIC 28nm HKMG with frequency set to 500 MHz.

### Insights

#### Methodology
Our demonstration provides a practical baseline for future refinements. Exploiting as an adversary helps inspect and defend systems. Blockchain networks often lack responsible disclosure methods, making it challenging to apply changes to PoW schemas.

#### ASIC-Friendly Factors
- **Clear Subroutine Boundaries**: Equihash's subroutines have clear boundaries, exposing larger attack surfaces.
- **Real-Life Subroutines**: The sort/hash step is more of a real-life algorithm, vulnerable to optimizations.
- **Sequential Memory Access**: Significant sequential memory access benefits special memory configurations in ASICs.

#### ASIC-Resistant Factors
- **Algorithm Bounding**: Equihash implements moderate algorithm bounding, prohibiting alternate algorithms but allowing tweaks.
- **Logic Complexity**: Massive logic complexity stops adversaries from applying linear sorting.
- **Dynamic Resource Usage**: Dynamic allocation limits ASIC advantage, as software can handle this well.

### Conclusion

We propose a method to inspect the ASIC-resistance of PoW schemas and apply it to Equihash. By constructing a practical and efficient ASIC solver, we discover its limitations and adversary advantages. Our contributions include:
- Practical inspections of PoW systems.
- Equihash's resistance to single-chip ASIC solvers but not to off-chip memory-based solvers.
- Listing algorithmic factors and their influence on adversary strategies.

Future work will refine our methodology to reveal other weaknesses in PoW schemas, aiming to secure related applications and explore new PoW ideas for better fairness.

### Acknowledgment
We thank Dr. Jinmei Lai from the State Key Laboratory of ASIC & System, Fudan University, for providing the ASIC design suite and related resources. This work is partially supported by the Chinese National Key R&D Program.

### References
[References listed as provided in the original text]