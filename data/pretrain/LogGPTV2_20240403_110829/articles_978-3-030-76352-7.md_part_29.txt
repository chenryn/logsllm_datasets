### Model Training and Evaluation

The model is trained on the representations of all teacher models that have a higher or equal score. Auxiliary input samples are generated as described in Section 4.1. Due to the random generation of these auxiliary samples, the experiment is repeated seven times.

Figure 3 presents the results as a boxplot, illustrating the F1-scores of all eight models (labeled A-H) for different amounts of knowledge representation tuples over the seven experimental runs. The properties of the boxplot are as described in Section 4.2. The leftmost bars in the "Before" category for each model represent the initial training on the locally available unique sequence set, without applying federated learning. The F1-scores in this initial phase range from 0.520 to 0.938. The 0.95 confidence interval for all eight nodes in this section ranges from 0.875 to 0.901.

Figure 4 provides a zoomed-in version of the same boxplot, focusing on the F1-score range between 0.90 and 0.94. As expected, an increasing amount of knowledge representations leads to higher overall F1-scores. It is evident that even with just 10 knowledge representations, the F1-scores improve significantly. After 10 knowledge representations, the lowest F1-score is 0.906, and the 0.95 confidence interval for this section ranges from 0.923 to 0.933. In the category with 50 knowledge representations, the number of outliers remains the same, but the 0.95 confidence interval narrows to 0.930 to 0.933, indicating an improvement compared to 10 knowledge representations. The highest F1-score of 0.939 is observed in this category. The smallest deviations in F1-scores for all nodes occur at 1000 knowledge representations, with a 0.95 confidence interval from 0.933 to 0.935. In this category, the highest F1-score is 0.938, and the lowest is 0.928. Compared to the 0.95 confidence interval of 0.875 to 0.901 before the teacher-student process, there is a clear improvement in every category.

This experiment demonstrates the ability to train different models with the same configuration in a distributed system. The method preserves data privacy by using auxiliary samples to transfer knowledge between models, eliminating the need for a central instance for synchronization. Neither model parameters nor gradients need to be transferred.

### Conclusion

In this work, we proposed a federated learning solution for synchronizing distributed models trained on locally available data. Our method does not require sharing original training data or model parameters. Training is conducted by assigning teacher and student roles to existing models. Students are trained on the output of teachers via auxiliary samples and respective outputs, referred to as knowledge representations. We evaluated our approach in a case study of log anomaly detection. DeepLog models were trained on distinct and unique log sequences from the HDFS dataset. After initial training, the teacher and student roles were applied to test the synchronization capability.

In our first experiment, we showed that this approach can mitigate the cold start problem. We set up a trained teacher DeepLog model and an untrained DeepLog model as a student. We investigated how well the student adapts to the teacher with different amounts of knowledge representations. After applying the proposed method, the student model achieved a comparable F1-score of 0.96, while the teacher achieved 0.97. In the second experiment, we demonstrated that our method allows the synchronization of several models trained on different distinct datasets through the decentralized federated learning process. We split the training set into eight equal and unique log sequence subsets and distributed them among eight DeepLog models. With this training data, all nodes could perform an initial training step before entering the roles of teachers and students. Even with a small distribution of 10 knowledge representations, all nodes improved to a 0.95 confidence interval between 0.923 and 0.933, compared to their initial trained models, which had a 0.95 confidence interval of 0.875 to 0.901. After 1,000 knowledge representations, the models achieved a 0.95 confidence interval between 0.933 and 0.935.

For future work, we plan to investigate more datasets to verify the general applicability of our approach. Additionally, generating random sequences from a relatively small set of discrete elements represents a limited search space for auxiliary sample generation. We expect knowledge transfer to be more challenging within larger discrete sets or continuous spaces. Another goal is to research methods and heuristics to stabilize and accelerate the process of knowledge transfer with increasingly complex auxiliary samples.

### References

1. Acker, A., Wittkopp, T., Nedelkoski, S., Bogatinovski, J., Kao, O.: Superiority of simplicity: A lightweight model for network device workload prediction. arXiv preprint arXiv:2007.03568 (2020)
2. Du, M., Li, F., Zheng, G., Srikumar, V.: DeepLog: Anomaly detection and diagnosis from system logs through deep learning. In: Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 1285–1298 (2017)
3. Nedelkoski, S., Bogatinovski, J., Acker, A., Cardoso, J., Kao, O.: Self-supervised log parsing. arXiv preprint arXiv:2003.07905 (2020)
4. Wu, L., Tordsson, J., Elmroth, E., Kao, O.: Microrca: Root cause localization of performance issues in microservices. In: IEEE/IFIP Network Operations and Management Symposium (NOMS) (2020)
5. Lin, F., Beadon, M., Dixit, H.D., Vunnam, G., Desai, A., Sankar, S.: Hardware remediation at scale. In: 2018 48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W), pp. 14–17. IEEE (2018)
6. Shokri, R., Shmatikov, V.: Privacy-preserving deep learning. In: Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, pp. 1310–1321 (2015)
7. Hard, A., et al.: Federated learning for mobile keyboard prediction. arXiv preprint arXiv:1811.03604 (2018)
8. McMahan, B., Moore, E., Ramage, D., Hampson, S., Arcas, B.A.Y.: Communication-efficient learning of deep networks from decentralized data. In: Artificial Intelligence and Statistics, pp. 1273–1282 (2017)
9. Yang, Q., Liu, Y., Chen, T., Tong, Y.: Federated machine learning: Concept and applications. ACM Trans. Intell. Syst. Technol. (TIST) 10(2), 1–19 (2019)
10. Papernot, N., Abadi, N.M., Erlingsson, U., Goodfellow, I., Talwar, K.: Semi-supervised knowledge transfer for deep learning from private training data. arXiv preprint arXiv:1610.05755 (2016)
11. Fredrikson, M., Jha, S., Ristenpart, T.: Model inversion attacks that exploit confidence information and basic countermeasures. In: Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, pp. 1322–1333 (2015)
12. Shokri, R., Stronati, M., Song, C., Shmatikov, V.: Membership inference attacks against machine learning models. In: 2017 IEEE Symposium on Security and Privacy (SP), pp. 3–18. IEEE (2017)
13. Hu, R., Gong, Y., Guo, Y.: Sparsified privacy-masking for communication-efficient and privacy-preserving federated learning. arXiv preprint arXiv:2008.01558 (2020)
14. Bonawitz, K., et al.: Practical secure aggregation for federated learning on user-held data. arXiv preprint arXiv:1611.04482 (2016)
15. Geyer, R.C., Klein, T., Nabi, M.: Differentially private federated learning: A client level perspective. arXiv preprint arXiv:1712.07557 (2017)
16. Kairouz, P., et al.: Advances and open problems in federated learning. arXiv preprint arXiv:1912.04977 (2019)
17. Nguyen, T.D., Marchal, S., Miettinen, M., Fereidooni, H., Asokan, N., Sadeghi, A.-R.: Dıot: A federated self-learning anomaly detection system for IoT. In: 2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS), pp. 756–767. IEEE (2019)
18. Liu, Y., Kumar, N., Xiong, Z., Lim, W.Y.B., Kang, J., Niyato, D.: Communication-efficient federated learning for anomaly detection in industrial internet of things
19. Liu, Y., et al.: Deep anomaly detection for time-series data in industrial IoT: A communication-efficient on-device federated learning approach. IEEE Internet of Things J. (2020)
20. Preuveneers, D., Rimmer, V., Tsingenopoulos, I., Spooren, J., Joosen, W., Ilie-Zudor, E.: Chained anomaly detection models for federated learning: An intrusion detection case study. Appl. Sci. 8(12), 2663 (2018)
21. Nguyen, T.D., Rieger, P., Miettinen, M., Sadeghi, A.-R.: Poisoning attacks on federated learning-based IoT intrusion detection system (2020)
22. Xu, W., Huang, L., Fox, A., Patterson, D., Jordan, M.I.: Detecting large-scale system problems by mining console logs. In: Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles, pp. 117–132 (2009)
23. He, P., Zhu, J., Zheng, Z., Lyu, M.R.: Drain: An online log parsing approach with fixed depth tree. In: 2017 IEEE International Conference on Web Services (ICWS), pp. 33–40. IEEE (2017)

### Online Memory Leak Detection in Cloud-Based Infrastructures

#### Abstract

Memory leaks in applications deployed on the cloud can affect the availability and reliability of the application. Therefore, it is crucial to identify and resolve them quickly. However, in a production environment running on the cloud, memory leak detection is challenging without knowledge of the application or its internal object allocation details.

This paper addresses the challenge of online detection of memory leaks in cloud-based infrastructure without any internal application knowledge by introducing a novel machine learning-based algorithm called Precog. This algorithm uses only one metric, the system’s memory utilization, to detect memory leaks. The developed algorithm's accuracy was tested on 60 virtual machines with manually labeled memory utilization data provided by our industry partner, Huawei Munich Research Center. The proposed algorithm achieves an accuracy score of 85% with less than half a second prediction time per virtual machine.

**Keywords:** Memory leak, Online memory leak detection, Memory leak patterns, Cloud, Linear regression

#### 1. Introduction

Cloud computing is widely used in industries for its capability to provide cheap and on-demand access to compute and storage resources. Physical server resources located at different data centers are split among the virtual machines (VMs) hosted on them and distributed to users. Users can then deploy their applications on these VMs with only the required resources, allowing efficient usage of physical hardware and reducing overall costs. However, with all the advantages of cloud computing, there is the drawback of detecting faults or errors in applications or VMs efficiently due to the layered virtualization stack. A small fault somewhere in the system can impact the performance of the application.

An application deployed on a VM typically requires different system resources such as memory, CPU, and network for task completion. If an application primarily uses memory for processing tasks, it is called a memory-intensive application. It is the responsibility of the application to release system resources when they are no longer needed. When an application fails to release memory resources, a memory leak occurs. Memory leak issues can cause continuous blocking of VM resources, resulting in slower response times or application failure. In the software industry, memory leaks are treated with utmost seriousness and priority, as their impact can be catastrophic to the whole system. In development environments, these issues are easily detectable with static source code analysis tools or by analyzing heap dumps. However, in a production environment running on the cloud, memory leak detection is a challenge and is often detected only when there is an abnormality in runtime, abnormal usage of system resources, application crash, or VM restart. The resolution of such issues is done at the cost of compromising the availability and reliability of the application. Therefore, it is necessary to monitor every application for memory leaks and have an automatic detection mechanism before they occur. However, it is a challenge to detect memory leaks in an application running on a VM in the cloud without knowledge of the programming language, source code, or low-level details such as object allocation times, object staleness, or object references. Due to the low downtime requirements for applications running on the cloud, the detection and resolution of issues must be done as quickly as possible. This challenge is addressed in this paper by using only the VM’s memory utilization as the main metric and devising a novel algorithm called Precog to detect memory leaks.

**Main Contributions:**
- **Algorithm:** We propose an online novel machine learning-based algorithm, Precog, for accurate and efficient detection of memory leaks using only the VM’s memory utilization as the main metric.
- **Effectiveness:** Our proposed algorithm achieves an accuracy score of 85% on the evaluated dataset provided by our industry partner and an accuracy score above 90% on synthetic data generated by us.
- **Scalability:** Precog’s predict functionality is linearly scalable with the number of values and takes less than a second for predicting in a time series with 100,000 values.
- **Reproducibility:** Our code and synthetic generated data are publicly available at: https://github.com/ansjin/memory-leak-detection.

#### 2. Related Work

Memory leak detection has been studied over the years, and several solutions have been proposed. Sor et al. reviewed different memory leak detection approaches based on their implementation complexity, measured metrics, and intrusiveness, and proposed a classification taxonomy [11]. The classification taxonomy broadly divides the detection algorithms into (1) Online detection, (2) Offline detection, and (3) Hybrid detection. The online detection category uses either staleness measures of allocated objects or their growth analysis. The offline detection category includes algorithms that use captured states (e.g., heap dumps), visualization mechanisms, or static source code analysis. Hybrid detection methods combine features of online and offline methods to detect memory leaks. Our work falls into the category of online detection, so we will focus on related approaches in this category.

Based on the staleness measure of allocated objects, Rudaf et al. proposed “LeakSpot” for detecting memory leaks in web applications [9]. It locates JavaScript allocation and reference sites that produce and retain increasing numbers of objects over time and uses staleness as a heuristic to identify memory leaks. Vladimir Šore et al. proposed a statistical metric called genCount for memory leak detection in Java applications [12]. It uses the number of different generations of objects grouped by their allocation sites to abstract object staleness, an important attribute indicating a memory leak. Vilk et al. proposed a browser leak debugger for automatically debugging memory leaks in web applications called “BLeak” [13]. It collects heap snapshots and analyzes these snapshots over time to identify and rank leaks. BLeak targets application source code when detecting memory leaks.

Based on the growth analysis of objects, Jump et al. proposed “Cork,” which finds the growth of heap data structures via a directed graph called Type Points-From Graph (TPFG), a data structure that describes an object and its outgoing references [6]. To find memory leaks, TPFG’s growth is analyzed over time in terms of growing types such as lists. FindLeaks, proposed by Chen et al., tracks object creation and destruction, and if more objects are created than destroyed, it identifies a potential memory leak.