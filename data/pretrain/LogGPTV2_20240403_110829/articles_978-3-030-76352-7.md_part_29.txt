model is trained on the representations of all teacher models that have a higher
or equal score than itself.
Auxiliary input samples are generated as described in Sect.4.1. Due to this
random generation of auxiliary samples, we repeat the experiment 7 times.
Figure3 shows the results as a boxplot, which illustrates the F1-scores of all
8 models (marked as A-H) for different amounts of knowledge representation
tuples over 7 experiment executions. The properties of the boxplot are the same
asdescribedinSect.4.2.ThemostleftbarsinthecategoryBefore foreachmodel
after initially trained on the locally available unique sequence set. No federated
learning is applied here. It can be seen that their F1-scores ranging from 0.520
to 0.938. The 0.95 confidence interval for all 8 nodes in this section ranges from
0.875 to 0.901.
The Fig.4 shows a zoomed-in version of the same boxplot on the F1-score
rangeofbetween0.90and0.94.Asexpected,anincreasingamountofknowledge
representations leads to overall higher F1-scores. Furthermore, it is visible that
184 T. Wittkopp and A. Acker
Fig.3. Comparison of F1-scores of each node before and after the teacher student
process with different knowledge representation sizes.
Fig.4. Comparison of F1-scores between 0.90 and 0.94 of each node before and after
the teacher student process with different knowledge representation sizes.
already 10 knowledge representations are improving the F1-scores significantly.
After 10 knowledge representation the lowest F1-score is 0.906 and the 0.95
confidenceintervalforthissectionrangesfrom0.923to0.933.Inthecategoryof
50 knowledge representations, the number of existing outliers is the same, but
the0.95confidenceintervalrangesfrom0.930to0.933,whichisanimprovement
compared to 10 knowledge representations. Also the highest F1-score of 0.939
could be observed in this category. The lowest deviations of the F1-score for all
nodes occur at 1000 knowledge representations with a 0.95 confidence interval
from0.933to0.935.InthiscategorythehighestF1-scoreis0.938andthelowest
0.928. Compared to the 0.95 confidence interval of 0.875 to 0.901 before the
teacher student process, we observe an improvement in every category.
This experiment indicates, that it is able to train different models with the
same configuration in a distributed system. The method preserves data pri-
vacy by using auxiliary samples to transfer knowledge between models. A cen-
tral instance for synchronization of the training process is not required. Neither
model parameters nor gradients need to be transferred.
Decentralized Federated Learning 185
5 Conclusion
In this work we proposed a federated learning solution for synchronizing dis-
tributedmodelstrainedonlocallyavailabledata.Outmethoddoesnotrequired
a sharing of original training data or model parameter. Training is done via
assignmentofteacherandstudentrolestoexistingmodels.Studentsaretrained
on the output of teachers via auxiliary samples and respective outputs, referred
to as knowledge representations. We evaluated our approach in a case study of
log anomaly detection. DeepLog models were trained on distinct and unique log
sequences from the HDFS data set. After that the teacher and student roles
were applied to the models in order to test the ability of synchronizing them.
In our first experiment we could show that this approach can mitigate the cold
start problem. For this experiment we setup a trained teacher DeepLog model
and an untrained DeepLog model as a student. We investigated how well they
studentadaptstheteacherwithdifferentamountsofknowledgerepresentations.
After applying the proposed method, the student model achieved a compara-
ble F1-score of 0.96 while the teacher achieved 0.97. In the second experiment,
we demonstrated that our method allows the synchronization of several models
trained on different distinct training data sets through the proposed decentral-
ized federated learning process. Therefore, we split the training set into 8 equal
anduniquelogsequencesubsetsanddistributedtheseamong8DeepLogmodels.
With this training data all nodes could perform an initial training step before
they entered the role of teachers and students. Even with distributing small
amount of 10 knowledge representations all nodes could improve to a F1-score
0.95confidenceintervalbetween0.923and0.933comparedtotheirinitialtrained
models, which reached a 0.95 confidence interval of 0.875 to 0.901. After 1,000
the models archive a 0.95 confidence interval of between 0.933 and 0.935.
For future work we plan to investigate more datasets in order to verify the
generalapplicabilityofourapproach.Furthermore,generatingrandomsequences
from a relatively small set of discrete elements represents a comparably limited
search space for auxiliary sample generation. We expect the knowledge transfer
tobeharderwithinlargerdiscretesetsorevenwithincontinuousspace.Another
goalistoresearchmethodsandheuristicstostabilizeandacceleratetheprocess
of knowledge transfer with increasingly complex auxiliary samples.
References
1. Acker, A., Wittkopp, T., Nedelkoski, S., Bogatinovski, J., Kao, O.: Superiority
of simplicity: A lightweight model for network device workload prediction. arXiv
preprint arXiv:2007.03568 (2020)
2. Du,M.,Li,F.,Zheng,G.,Srikumar,V.:DeepLog:anomalydetectionanddiagnosis
fromsystemlogsthroughdeeplearning.In:Proceedingsofthe2017ACMSIGSAC
Conference on Computer and Communications Security, pp. 1285–1298 (2017)
3. Nedelkoski, S., Bogatinovski, J., Acker, A., Cardoso, J., Kao, O.: Self-supervised
log parsing. arXiv preprint arXiv:2003.07905 (2020)
186 T. Wittkopp and A. Acker
4. Wu, L., Tordsson, J., Elmroth, E., Kao, O.: Microrca: root cause localization of
performanceissuesinmicroservices.In:IEEE/IFIPNetworkOperationsandMan-
agement Symposium (NOMS) (2020)
5. Lin, F., Beadon, M., Dixit, H.D., Vunnam, G., Desai, A., Sankar, S.: Hardware
remediation at scale. In: 2018 48th Annual IEEE/IFIP International Conference
on Dependable Systems and Networks Workshops (DSN-W), pp. 14–17. IEEE
(2018)
6. Shokri,R.,Shmatikov,V.:Privacy-preservingdeeplearning.In:Proceedingsofthe
22nd ACM SIGSAC Conference on Computer and Communications Security, pp.
1310–1321 (2015)
7. Hard,A.,etal.:Federatedlearningformobilekeyboardprediction.arXivpreprint
arXiv:1811.03604 (2018)
8. McMahan, B., Moore, E., Ramage, D., Hampson, S., Arcas, B.A.Y.:
Communication-efficient learning of deep networks from decentralized data.
In:ArtificialIntelligenceandStatistics,pp.1273–1282(2017)
9. Yang, Q., Liu, Y., Chen, T., Tong, Y.: Federated machine learning: concept and
applications. ACM Trans. Intell. Syst. Technol. (TIST) 10(2), 1–19 (2019)
10. Papernot, N., Abadi, N.M., Erlingsson, U., Goodfellow, I., Talwar, K.: Semi-
supervised knowledge transfer for deep learning from private training data. arXiv
preprint arXiv:1610.05755 (2016)
11. Fredrikson, M., Jha, S., Ristenpart, T.: Model inversion attacks that exploit con-
fidence information and basic countermeasures. In: Proceedings of the 22nd ACM
SIGSAC Conference on Computer and Communications Security, pp. 1322–1333
(2015)
12. Shokri, R., Stronati, M., Song, C., Shmatikov, V.: Membership inference attacks
against machine learning models. In: 2017 IEEE Symposium on Security and Pri-
vacy (SP), pp. 3–18. IEEE (2017)
13. Hu,R.,Gong,Y.,Guo,Y.:Sparsifiedprivacy-maskingforcommunication-efficient
andprivacy-preservingfederatedlearning.arXivpreprintarXiv:2008.01558(2020)
14. Bonawitz, K., et al.: Practical secure aggregation for federated learning on user-
held data. arXiv preprint arXiv:1611.04482 (2016)
15. Geyer,R.C.,Klein,T.,Nabi,M.:Differentiallyprivatefederatedlearning:aclient
level perspective. arXiv preprint arXiv:1712.07557 (2017)
16. Kairouz, P., et al.: Advances and open problems in federated learning. arXiv
preprint arXiv:1912.04977 (2019)
17. Nguyen, T.D., Marchal, S., Miettinen, M., Fereidooni, H., Asokan, N., Sadeghi,
A.-R.: D¨ıot: a federated self-learning anomaly detection system for IoT. In: 2019
IEEE39thInternationalConferenceonDistributedComputingSystems(ICDCS),
pp. 756–767. IEEE (2019)
18. Liu,Y.,Kumar,N.,Xiong,Z.,Lim,W.Y.B.,Kang,J.,Niyato,D.:Communication-
efficient federated learning for anomaly detection in industrial internet of things
19. Liu, Y., et al.: Deep anomaly detection for time-series data in industrial IoT: a
communication-efficient on-device federated learning approach. IEEE Internet of
Things J. (2020)
20. Preuveneers, D., Rimmer, V., Tsingenopoulos, I., Spooren, J., Joosen, W., Ilie-
Zudor, E.: Chained anomaly detection models for federated learning: an intrusion
detection case study. Appl. Sci. 8(12), 2663 (2018)
21. Nguyen, T.D., Rieger, P., Miettinen, M., Sadeghi, A.-R.: Poisoning attacks on
federated learning-based IoT intrusion detection system (2020)
Decentralized Federated Learning 187
22. Xu, W., Huang, L., Fox, A., Patterson, D., Jordan, M.I.: Detecting large-scale
system problems by mining console logs. In: Proceedings of the ACM SIGOPS
22nd Symposium on Operating Systems Principles, pp. 117–132 (2009)
23. He, P., Zhu, J., Zheng, Z., Lyu, M.R.: Drain: an online log parsing approach with
fixeddepthtree.In:2017IEEEInternationalConferenceonWebServices(ICWS),
pp. 33–40. IEEE (2017)
Online Memory Leak Detection
in the Cloud-Based Infrastructures
B
Anshul Jindal1( ) , Paul Staab2, Jorge Cardoso2 , Michael Gerndt1 ,
and Vladimir Podolskiy1
1 Chair of Computer Architecture and Parallel Systems,
Technical University of Munich, Garching, Germany
{anshul.jindal,v.podolskiy}@tum.de, PI:EMAIL
2 Huawei Munich Research Center, Huawei Technologies Munich, Munich, Germany
{paul.staab,jorge.cardoso}@huawei.com
Abstract. A memory leak in an application deployed on the cloud can
affect the availability and reliability of the application. Therefore, to
identify and ultimately resolve it quickly is highly important. However,
intheproductionenvironmentrunningonthecloud,memoryleakdetec-
tionisachallengewithouttheknowledgeoftheapplicationoritsinternal
object allocation details.
This paper addresses this challenge of online detection of memory
leaks in cloud-based infrastructure without having any internal applica-
tionknowledge byintroducinganovelmachinelearningbasedalgorithm
Precog. This algorithm solely uses one metric i.e. the system’s memory
utilization on which the application is deployed for the detection of a
memory leak. The developed algorithm’s accuracy was tested on 60 vir-
tualmachinesmanuallylabeledmemoryutilizationdataprovidedbyour
industrypartnerHuaweiMunichResearchCenteranditwasfoundthat
theproposedalgorithmachievestheaccuracyscoreof85%withlessthan
half a second prediction time per virtual machine.
· ·
Keywords: Memory leak Online memory leak detection Memory
· ·
leak patterns Cloud Linear regression
1 Introduction
Cloud computing is widely used in the industries for its capability to provide
cheapandon-demand accesstocompute andstorage resources.Physical servers
resources located at different data centers are split among the virtual machines
(VMs) hosted on it and distributed to the users [5]. Users can then deploy their
applications on these VMs with only the required resources. This allows the
efficient usage of the physical hardware and reducing the overall cost. However,
withalltheadvantagesofcloudcomputingthereexiststhedrawbackofdetecting
a fault or an error in an application or in a VM efficiently due to the layered
virtualisationstack[1,4].Asmallfaultsomewhereinthesystemcanimpactthe
performance of the application.
(cid:2)c SpringerNatureSwitzerlandAG2021
H.Hacidetal.(Eds.):ICSOC2020Workshops,LNCS12632,pp.188–200,2021.
https://doi.org/10.1007/978-3-030-76352-7_21
Online Memory Leak Detection in the Cloud-Based Infrastructures 189
An application when deployed on a VM usually requires different system
resources such as memory, CPU and network for the completion of a task. If an
application is mostly using the memory for the processing of the tasks then this
applicationiscalledamemory-intensiveapplication[8].Itistheresponsibilityof
the application to release the system resources when they are no longer needed.
When such an application fails to release the memory resources, a memory
leak occurs in the application [14]. Memory leak issues in the application can
cause continuous blocking of the VM’s resources which may in turn result in
slower response times or application failure. In software industry, memory leaks
aretreatedwithutmostseriousnessandpriorityastheimpactofamemoryleak
could be catastrophic to the whole system. In the development environment,
theseissuesare rather easily detectable with thehelp of static sourcecode anal-
ysis tools or by analyzing the heap dumps. But in the production environment
running on the cloud, memory leak detection is a challenge and it only gets
detected when there is an abnormality in the run time, abnormal usage of the
system resources, crash of the application or restart of the VM. Then the reso-
lution of such an issue is done at the cost of compromising the availability and
reliability of the application. Therefore it is necessary to monitor every applica-
tion for memory leak and have an automatic detection mechanism for memory
leak before it actually occurs. However, it is a challenge to detect memory leak
of an application running on a VM in the cloud without the knowledge of the
programming language of the application, nor the knowledge of source code nor
the low level details such as allocation times of objects, object staleness, or the
object references [10]. Due to the low down time requirements for the appli-
cations running on the cloud, detection of issues and their resolutions is to be
done as quickly as possible. Therefore, this challenge is addressed in this paper
by solely using the VM’s memory utilization as the main metric and devising a
novel algorithm called Precog to detect memory leak.
The main contribution of this paper are as follows:
– Algorithm: We propose an online novel machine learning based algorithm
Precog for accurate and efficient detection of memory leaks by solely using
the VM’s memory utilization as the main metric.
– Effectiveness: Our proposed algorithm achieves the accuracy score of 85%
ontheevaluateddatasetprovidedbyourindustrypartnerandaccuracyscore
of above 90% on the synthetic data generated by us.
– Scalability: Precog’s predict functionality is linearly scalable with the num-
ber of values and takes less than a second for predicting in a timeseries with
100,000 values.
Reproducibility: our code and synthetic generated data are publicly available
at: https://github.com/ansjin/memory leak detection.
2 Related Work
Memoryleakdetectionhasbeenstudiedovertheyearsandseveralsolutionshave
been proposed. Sor et al. reviewed different memory leak detection approaches
190 A. Jindal et al.
based on their implementation complexity, measured metrics, and intrusiveness
and a classification taxonomy was proposed [11]. The classification taxonomy
broadly divided the detection algorithms into (1) Online detection, (2) Offline
detection and (3) Hybrid detection. The online detection category uses either
stalenessmeasureoftheallocatedobjectsortheirgrowthanalysis.Offlinedetec-
tion category includes the algorithms that make use of captured states i.e. heap
dumps or use a visualization mechanism to manually detect memory leaks or
use static source code analysis. Hybrid detection category methods combine the
featuresofferedbyonlineandofflinemethodstodetectmemoryleaks.Ourwork
falls in the category of online detection therefore, we now restrict our discussion
to the approaches related to the online detection category only.
Based on the staleness measure of allocated objects, Rudaf et al. pro-
posed “LeakSpot” for detecting memory leaks in web applications [9]. It locates
JavaScriptallocationandreferencesitesthatproduceandretainincreasingnum-
bers of objects over time and uses staleness as a heuristic to identify memory
leaks.VladimirSˇoretal.proposesastatisticalmetriccalledgenCount formem-
ory leak detection in Java applications [12]. It uses the number of different gen-
erations of the objects grouped by their allocation sites, to abstract the object
staleness - an important attribute indicating a memory leak. Vilk et al. pro-
posed a browser leak debugger for automatically debugging memory leaks in
webapplications calledas“BLeak”[13].Itcollectsheapsnapshotsandanalyzes
these snapshots over time to identify and rank leaks. BLeak targets application
source code when detecting memory leaks.
Based on the growth analysis objects, Jump et al. proposes “Cork” which
finds the growth of heap data structure via a directed graph Type Points-From
Graph - TPFG, a data structure which describes an object and its outgoing
reference [6]. To find memory leaks, TPFG’s growth is analyzed over time in
terms of growing types such as a list. FindLeaks proposed by Chen et al. tracks
object creation and destruction and if more objects are created than destroyed