title:Thoth: Comprehensive Policy Compliance in Data Retrieval Systems
author:Eslam Elnikety and
Aastha Mehta and
Anjo Vahldiek-Oberwagner and
Deepak Garg and
Peter Druschel
Thoth: Comprehensive Policy Compliance  
in Data Retrieval Systems
Eslam Elnikety, Aastha Mehta, Anjo Vahldiek-Oberwagner, Deepak Garg,  
and Peter Druschel, Max Planck Institute for Software Systems (MPI-SWS)
 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/elnikety
This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX Thoth: Comprehensive Policy Compliance in Data Retrieval
Systems
Eslam Elnikety
Aastha Mehta
Anjo Vahldiek-Oberwagner
Deepak Garg
Peter Druschel
Max Planck Institute for Software Systems (MPI-SWS)
Abstract
Data retrieval systems process data from many sources,
each subject to its own data use policy. Ensuring compli-
ance with these policies despite bugs, misconﬁguration,
or operator error in a large, complex, and fast evolving
system is a major challenge. Thoth provides an efﬁ-
cient, kernel-level compliance layer for data use policies.
Declarative policies are attached to the systems’ input
and output ﬁles, key-value tuples, and network connec-
tions, and specify the data’s integrity and conﬁdential-
ity requirements. Thoth tracks the ﬂow of data through
the system, and enforces policy regardless of bugs, mis-
conﬁgurations, compromises in application code, or ac-
tions by unprivileged operators. Thoth requires minimal
changes to an existing system and has modest overhead,
as we show using a prototype Thoth-enabled data re-
trieval system based on the popular Apache Lucene.
1 Introduction
Online data retrieval systems typically serve a search-
able corpus of documents, web pages, blogs, personal
emails, online social network (OSN) proﬁles and posts,
along with real-time microblogs, stock and news tickers.
Examples include large providers like Amazon, Face-
book, eBay, Google, and Microsoft, and also numerous
smaller, domain-speciﬁc sharing, trading and networking
sites run by organizations, enterprises, and governments.
Each data item served or used by a retrieval system
may have its own usage policy. For instance, email
is private to its sender/receiver(s), OSN data and blogs
limited to friends, and corporate documents limited to
employees. External data stream providers may re-
strict the use of (meta)data, and require expiration. The
provider’s privacy policy may require that a user’s query
and click stream be used only for personalization. Lastly,
providers must comply with local laws, which may re-
quire them, for instance, to ﬁlter certain data items within
a given jurisdiction.
Ensuring compliance with applicable policies is labor-
intensive and error-prone [36]. The policy actually in ef-
fect for a data item may depend on checks and settings in
many components and several layers of a system, making
it difﬁcult to audit and reason about. Moreover, any bug,
misconﬁguration, or compromise in a large and evolving
application codebase could violate a policy. The problem
affects both large providers with complex, fast evolving
systems and smaller providers with limited IT budgets.
Indeed, reports of data losses abound [14, 1, 44, 11, 13].
The stakes are high: providers stand to lose customer
conﬁdence, business and reputation, and may face ﬁnes.
Hence, developing technical mechanisms to enforce poli-
cies in data retrieval systems is important. In fact, the
Grok system combines lightweight static analysis with
heuristics to annotate source code to check for policy vi-
olations in Bing’s back-end [36].
Existing policy compliance systems for data retrieval,
including Grok, usually target column-speciﬁc policies—
policies that apply uniformly to all data of a speciﬁc type,
e.g., the policy “no IP address can be used for advertiz-
ing.” However, no existing work covers the equally im-
portant individual policies that are speciﬁc to individual
data items or to a given client’s data items. For exam-
ple, Alice’s blog posts, but not Bob’s, may be subject to
the policy “visible only to Alice’s friends”. Similarly,
the expiration time of every item in a news ticker may
be different. In fact, all policies mentioned a couple of
paragraphs ago are individual policies. It is this (signif-
icant and important) missing part of policy enforcement
that we wish to address in this paper. Speciﬁcally, we
present Thoth, a policy compliance layer integrated into
the Linux kernel to enforce both individual and column-
speciﬁc policies efﬁciently.
We brieﬂy describe the key insights in Thoth’s de-
sign. First, by design, Thoth separates policies from ap-
plication code. A policy specifying conﬁdentiality and
integrity requirements may be associated with any data
conduit, i.e, a ﬁle, key-value tuple, named pipe or net-
work connection, and is enforced on all application code
that accesses the conduit’s data or data derived from that
data. Thoth provides a declarative language for specify-
ing policies. The language itself is novel; in addition to
standard access (read/write) policies, it also allows spec-
ifying data declassiﬁcation policies by stipulating how
USENIX Association  
25th USENIX Security Symposium  637
access policies may change along a data ﬂow.
Second, unlike column-speciﬁc policies, individual
policies may not be very amenable to static analysis be-
cause a given program variable may contain data with
very different individual policies over time at the same
program point and, hence, the abstraction of static anal-
ysis may lose precision quickly. So, Thoth uses dynamic
analysis. It intercepts I/O in the kernel, tracks the ﬂow of
data at the granularity of conduits and processes (similar
to Flume [28]), and enforces policies at process bound-
aries. This incurs a runtime overhead but we show that
the overhead is not too high. With an optimized proto-
type implementation, we measure an overhead of 0.7%
on indexing and 3.6% on query throughput in the widely
used search engine Apache Lucene. While this overhead
may be too high for large-scale data retrieval systems,
we believe that it can be optimized further and that it is
already suitable for domain-speciﬁc, medium-scale data
retrieval systems run by organizations, enterprises and
governments. Moreover, application code requires very
few changes to run with Thoth (50 lines in a codebase of
300,000 LoC in our experiments).
Third, the complexity of a data retrieval system often
necessitates some declassiﬁcation to maintain function-
ality. For instance, a search process that consults an in-
dex computed over a corpus containing the private data
of more than one individual cannot produce any read-
able results without declassiﬁcation. To handle this and
similar situations, we introduce a new form of declassiﬁ-
cation called typed declassiﬁcation, which allows the de-
classiﬁcation of data in speciﬁc forms (types). To accom-
modate the aforementioned search process, all source
data policies allow declassiﬁcation into a list of search
results (document names). Hence, the search process
can function as usual. At the same time, the possibil-
ity of data leaks is limited to a very narrow channel: To
leak information from a private ﬁle, the search process’
code must maliciously encode the information in a list
of valid document names. Given that the provider has a
genuine interest in preventing data breaches and that the
search process is an internal component that is unlikely
to be compromised in a casual external attack, the chance
of having such malicious code in the search process is
low. Thus, typed declassiﬁcation is a pragmatic design
point in the security-functionality trade-off for our threat
model. Note that typed declassiﬁcation needs content-
dependent policies, which our policy language supports.
To summarize, the contributions of this work are:
(1) A policy language that can express individual ac-
cess and declassiﬁcation policies declaratively (Sec-
tion 2);
(2) the design of a kernel-level monitor to
enforce policies by I/O interception and lightweight
taint propagation (Section 3); (3) application of the de-
sign to medium-scale data retrieval systems, speciﬁcally
Apache’s Lucene (Sections 2; 5); and (4) an optimized
prototype implementation and experimental evaluation
to measure overheads (Sections 4, 6).
2 Thoth policies
Thoth is a kernel-level policy compliance layer that helps
data retrieval system providers enforce conﬁdentiality
and integrity policies on the data they collect and serve.
In Thoth, the provider attaches policies to data sources
(documents and live streams, posts and proﬁles, user
click history, etc.) based on the privacy preferences of
clients, external (e.g., legal) and internal usage require-
ments. Thoth tracks data ﬂows by intercepting all IPC
and I/O in the kernel, and it propagates source policies
along these ﬂows.
It enforces policy conditions when
data leaves the system, or when a declassiﬁcation hap-
pens. The policy attached to a data source is a complete,
one point description of all privacy and integrity rules in
effect for that source.
Thoth policies are speciﬁed in a new, expressive
declarative language, separate from application code. In
this section, we describe this policy language brieﬂy, dis-
cuss example policies that clients, data sources, and the
provider might wish to enforce in a data retrieval sys-
tem, and give a glimpse of how to express these policies
in Thoth’s policy language. More policy examples are
included in Appendix A. Section 3 explains how Thoth
enforces these policies. We note that our policy language
and enforcement are general and apply beyond data re-
trieval systems.
Policy language overview A Thoth policy can be at-
tached to any conduit—a ﬁle, key-value tuple, named
pipe or network socket that stores data or carries data in
transit. The policy on a conduit protects the conﬁdential-
ity and integrity of the data in the conduit and is speciﬁed
in two layers. The ﬁrst layer, an access control policy,
speciﬁes which principals may read and update the con-
duit and under what conditions (e.g., only before or only
after a certain date). A second layer protects data derived
from the conduit by restricting the policies of conduits
downstream in the data pipeline. This layer can declas-
sify data by allowing the access policies downstream to
be relaxed progressively, as more and more declassiﬁca-
tion conditions are met. The second layer that speciﬁes
declassiﬁcation by controlling downstream policies is the
language’s key novelty.1 Another noteworthy feature is
that we allow policy evaluation to depend on a conduit’s
state—both its data and its metadata. This allows ex-
pressing content-dependent policies and, in particular, a
kind of declassiﬁcation that we call typed declassiﬁca-
tion.
1Our full language also supports provenance policies in the second
layer by allowing control over upstream policies. Due to lack of space,
we omit provenance policies here.
638  25th USENIX Security Symposium 
USENIX Association
Arithmetic/string
add(x,y,z)
x=y+z
sub(x,y,z)
x=y-z
mul(x,y,z) x=y*z
div(x,y,z)
x=y/z
rem(x,y,z) x=y%z
concat(x,y) x || y
vType(x, y) is x of
type y?
Relational
eq(x,y)
neq(x,y)
lt(x,y)
gt(x,y)
le(x,y)
ge(x,y)
x=y
x!=y
xy
x=y
Conduit
cNameIs(x)
x is the conduit pathname
cIdIs(x)
x is the conduit id
cIdExists(x)
x is a valid conduit id
cCurrLenIs(x) x is the conduit length
cNewLenIs(x) x is the new conduit length
hasPol(c, p)
cIsIntrinsic
p is conduit c’s policy
does this conduit connect
two conﬁned processes?
sKeyIs(x)
sIpIs(x)
IpPreﬁx(x,y)
timeIs(t)
Session
x is the session’s
authentication key
x is the session’s source IP
address
x is IP preﬁx of y
t is the current time
(c,off) says
(x1 , . . . ,x n)
(c,off) willsay
(x1 , . . . ,x n)
each in (c,off) says
(x1 , .., xn) {condition}
each in (c,off) willsay
(x1 , .., xn) {condition}
Content
x1 , . . . ,x n is the tuple found in
conduit c at off
ditto for the update of c in the
current transaction
for each tuple in c at off, assign
to x1 ,.., xn and evaluate condition
ditto for the update of c in the
current transaction
Declassiﬁcation rules
c1 until c2
isAsRestrictive(p1,p2)
condition c1 must hold on the
downstream ﬂow until c2 holds
the permission p1 is at least as
restrictive as p2
Table 1: Thoth policy language predicates and connectives
Layer 1: Access policies The ﬁrst layer of a conduit’s
policy contains two rules that specify who can read and
update the conduit’s state under what conditions. We
write both rules in the syntax of Datalog, which has been
used widely in the past for the declarative speciﬁcation of
access policies [18, 20, 30]. Brieﬂy, the read rule has the
form (read :- cond) and means that the conduit can be
read if the condition “cond” is satisﬁed. The condition
“cond” consists of predicates connected with conjunc-
tion (“and”, written ∧) and disjunction (“or”, written ∨).
All supported predicates are listed in Table 1. Similarly,
the update rule has the form (update :- cond).
Example (Client policies) Consider a search engine
that indexes clients’ private data. A relevant security
goal might be that a client Alice’s private emails and pro-
ﬁle should be visible only to Alice, and only she should
be able to modify this data. This private data policy
can be expressed by attaching to each conduit holding
Alice’s private items read and update rules that allow
these operations only in the context of a session authen-
ticated with Alice’s key. The latter condition can be ex-
pressed using a single predicate sKeyIs(kAlice), which
means that the active session is authenticated with Al-
ice’s public key, denoted kAlice. Hence, the read rule
would be read :- sKeyIs(kAlice). The update rule would
be update :- sKeyIs(kAlice). (Clients, or processes run-
ning on behalf of clients, authenticate directly to Thoth,
so Thoth does not rely on untrusted applications for ses-
sion authentication information.)
Alice’s friends only blog and OSN proﬁle should be
readable by her friends as well, which can be expressed
with an additional disjunctive clause in the read rule:
read :- sKeyIs(kAlice) ∨
(sKeyIs(K) ∧ (“Alice.acl”, Offset) says isFriend(K))
The part after the ∨ is read as “the key K that authenti-
cated the current session exists in Alice.acl at some off-
set Offset.” Here, Alice.acl is a trusted key-value tuple
that contains Alice’s friend list.
Following standard Datalog convention, terms like K
and Offset that start with uppercase letters are exis-
tentially quantiﬁed variables. The predicate sKeyIs(K)
binds K to the key that authenticates the session. Dur-
ing each policy evaluation, application code is expected
to provide a binding for the variable Offset that refers
to a location in the tuple’s value saying that K belongs
to a friend of Alice. Note that policy compliance does
not depend on application correctness: if the application
does not provide a correct offset, access will be denied.
Extending further, visibility to Alice’s friends of
friends can be allowed by modifying the read rule to
check that Alice and the owner of the current session’s
key have a common friend. Then, the application code
would be expected to provide an offset in Alice’s acl
where the common friend exists and an offset in the com-
mon friend’s acl where the current session’s key exists.
Layer 2: Declassiﬁcation policies The second layer
of a conduit’s policy contains a single rule that controls
the policies of downstream conduits. This rule is written
(declassify :- cond), where “cond” is a condition or pred-
icate on all downstream sequences of conduits. For in-
stance, “cond” may say that in any downstream sequence
of conduits, the access policies must allow read access
only to Alice, until the calendar year is at least 2017, af-
ter which the policies may allow read access to anyone.
This represents the declassiﬁcation policy “private to Al-
ice until the end of 2016”.
We represent such declassiﬁcation policies using the
notation of linear temporal logic (LTL), a well-known
syntax to represent predicates that change over time [32].
We allow one new connective in “cond” in the declassify
rule: c1 until c2, which means that condition c1 must
USENIX Association  
25th USENIX Security Symposium  639
hold of all downstream conduits until condition c2 holds.
Also, we allow a new predicate isAsRestrictive(p1, p2),
which checks that policy p1 is at least as restrictive as
p2. The two together can represent expressive declassiﬁ-