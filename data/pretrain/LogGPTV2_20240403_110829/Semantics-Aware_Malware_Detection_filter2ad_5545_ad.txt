Limitations. Our tool has few limitations. First,
the current implementation requires all of the IR in-
structions in the template to appear in the same form
in the program. For example, if an IR node in the tem-
plate contains “x = x * 2”, the same operation (an
assignment with a multiplication on the right hand side)
has to appear in the program for that node to match.
This means that we will not match the equivalent pro-
gram instruction “eax = eax << 1” (arithmetic left
shift). Attacks against this requirement are still possi-
ble, but are fairly hard, as the bar has been raised: the
attacker has to devise multiple equivalent, yet distinct,
implementations of the same computation, to evade de-
tection. This is not an inherent limitation of the seman-
tics, and can be handled using an IR normalization step.
The second limitation comes from the use of def-use
chains for value preservation checking. The def-use re-
lations in the malicious template effectively encode a
speciﬁc ordering of memory updates – thus, our algo-
rithm AMD will detect only those program that exhibit
the same ordering of memory updates. We note that au-
tomatically generating functionally-equivalent variants
is a hard problem. Handling obfuscations that reorder
instructions to achieve a different ordering of memory
updates is one goal of our ongoing research.
4. Experimental results
We evaluated our implementation of algorithm AMD
against real-world malware variants. The three major
goals of our experiments were to develop malicious be-
havior templates that can match malware variants, to
measure the false positive rates the algorithm generates
with these templates, and to measure the detection al-
gorithm’s resilience to obfuscation. We used malware
instances in the wild both for developing behavior tem-
plates and as starting point for obfuscation transforma-
tions in the obfuscation resilience testing. Highlights of
the evaluation are:
• The template-based algorithm detects worms from
the same family, as well as unrelated worms, using
a single template.
• No false positives were generated when running our
malware detector on benign programs, illustrating the
soundness of our algorithm in its current implemen-
tation.
• The algorithm exhibits improved resilience to obfus-
cation when compared to commercial anti-virus tool
McAfee VirusScan.
4.1. Variant detection evaluation
We developed two templates and tested malware
samples and benign programs against them. One tem-
plate captures the decryption-loop functionality com-
mon in many malicious programs, while the other tem-
plate captures the mass-mailing functionality common
to email worms. While throughout this section we use
only the decryption-loop template as example, the re-
sults from using the mass email template were similar.
For malware samples we used seven variants of Netsky
(B, C, D, O, P, T, and W), seven variants of B[e]agle (I,
J, N, O, P, R, and Y), and seven variants of Sober (A, C,
D, E, F, G, and I). All of them are email worms, each
with many variants in the wild, ranging in size from
12 kB to 75 kB.
Malware
family
Netsky
B[e]agle
Sober
Template detection
Mass-
Decryp-
tion loop
mailer
100%
100%
100%
100%
100%
0%
Running time
Avg.
99.57 s
56.41 s
100.12 s
Std. dev.
41.01 s
40.72 s
45.00 s
Table 4. Malware detection using algo-
rithm AMD for 21 e-mail worm instances.
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
The decryption-loop template describes the behav-
ior of programs that unpack or decrypt themselves to
memory: the template consists of (1) a loop that pro-
cesses data from a source memory area and writes data
to a destination memory area, and (2) a jump that targets
the destination area. Many binary worms use this tech-
nique to make static analysis harder: the actual code of
the worm is not available for inspection until runtime.
To construct the template, we analyzed the Netsky.B
email worm and manually extracted the code that per-
forms the decryption and the jump. The template was
then generalized from this code by replacing actual reg-
isters and memory addresses with variables. The mass-
mailing template was developed in a similar manner: it
describes the custom SMTP functionality present in the
worm, including email composition and transmission.
We applied our algorithm on each malware instance
and each decryption-loop template. We achieved 100%
detection of the Netsky and B[e]agle worm instances
using only the two templates (the mass-mailing tem-
plate required minor tweaks to detect B[e]agle). The
Sober worm instances did not match the mass-mailing
template, requiring a separate template. Due to limita-
tions in the current prototype implementation, match-
ing calls into the Microsoft Visual Basic runtime li-
brary (used by Sober worm instances) is not supported.
Nonetheless, we have shown that algorithm AMD can
detect multiple worm instances from the same family
using one template, in contrast with commercial virus
scanners that require many signatures (McAfee VirusS-
can uses 13 signatures to detect the worms in our test
set). Our detection results come with one caveat: 3 of
the Netsky variants could not be processed by IDA Pro.
Since we build our tool on the assumption that disas-
sembly can be performed successfully, we do not con-
sider those 3 variants as false negatives. Running times
for the tool (listed in Table 4) are satisfactory for a pro-
totype and suggest that real-time performance can be
achieved with an optimized implementation.
4.2. False positive evaluation
We evaluated the algorithm and the templates against
a set of benign programs, in order to measure the false
positive rate and to evaluate the templates we devel-
oped. We used a set of 2,000 programs with sizes
between <1 kB and 150 kB, from standard Microsoft
Windows system programs, to compiler tools, to Mi-
crosoft Ofﬁce programs. We have also tried to test
larger benign binaries, with sizes up to 5 MB, but they
did not disassemble successfully. For successfully dis-
assembled programs, the false positive rate was 0%,
meaning that our implementation AMD correctly clas-
siﬁed all programs as benign (none of the test programs
matched the templates).
In Figure 4, we present the results of this evalua-
tion: programs are grouped by size, in 5 kB increments,
and the disassembly and detection rates are plotted for
each group. For example, the bar to the right of the
71,680 B point represents programs between 71,680 B
and 76,799 B in size, and indicates that 97.78% of the
programs in this group were disassembled successfully
and were detected as benign, while 2.22% failed to dis-
assemble (either because the disassembler crashed, or
because it failed to group program code into functions).
The running time per test case ranged from 9.12 s to
413.78 s, with an average of 165.5 s.
False Positive Evaluation of 2,000 Binaries
l
e
t
a
r
y
b
m
e
s
s
a
s
i
D
100%
80%
60%
40%
20%
0%
0 B
35,840 B
71,680 B
107,520 B
143,360 B
Program size (grouped in 5 kB increments)
Figure 4. Evaluation of algorithm AMD on
a set of 2,000 benign Windows programs
yielded no false positives. Gray bars indi-
cate the percentage of programs that dis-
assembled correctly and were detected as
benign; white bars indicate the percent-
age of programs that failed to disassem-
ble.
4.3. Obfuscation resilience evaluation
To test resilience to obfuscation, we applied garbage
insertion transformations of varying degrees of com-
plexity to worm variant B[e]agle.Y, and compared the
detection rate of our malware detection tool against
McAfee VirusScan. The garbage insertion transforma-
tion adds code fragments to a program, such that each
code fragment is irrelevant in its insertion context. We
considered three types of garbage insertion: (1) nop in-
sertion adds simple sequences of nop instructions; (2)
stack-op insertion adds sequences of stack operations;
and (3) math-op insertion adds sequences of arithmetic
operations. We generated 20 variants for each type of
obfuscation. To test the limits of our implementation,
one of the math-op insertion transformations actually
replaced single instructions of the form x = x + const
with equivalent sequences. The results are tabulated in
Table 5: our tool catches all obfuscations with the ex-
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
ception of the math-op replacement transformation; in
such a case, since the algorithm seeks to exactly match
a template instruction of the form x = x + const, any
equivalent instruction sequences are not detected.
Algorithm AMD
Detection
Obfuscation
type
Nop
Stack op
Math op
Average
time
74.81 s
159.10 s
186.50 s
McAfee
VirusScan
75.0%
25.0%
5.0%
rate
100%
100%
95%
Table 5. Evaluation of algorithm AMD on
a set of obfuscated variants of B[e]agle.Y.
For comparison, we include the detection
rate of McAfee VirusScan.
5. Related work
We compare our work to existing research in the
areas of malware detection, translation validation, and
software veriﬁcation.
5.1. Malware detection
In previous work [8], we demonstrated that cur-
rent commercial virus scanners can be easily evaded
by using simple obfuscations used by hackers. Many
malware-detection techniques are based on static-
analysis of executables. In this area, we previously de-
scribed a malware-detection algorithm called SAFE [7].
SAFE can only handle very simple obfuscations (only
nops can appear between matching instructions), e.g.,
the example shown in Figure 1 cannot be handled by
SAFE. Moreover, the formal semantics of malware de-
tection was not explored by the earlier work. Static
analysis of binaries is used by Kruegel et al. [21] to
detect kernel-level rootkits, which are attack tools that
are used by hackers to hide their presence from system
administrators. They look for suspicious instruction se-
quences using symbolic execution. The detection algo-
rithm presented in this paper is more powerful because
we use multiple decision procedures (symbolic execu-
tion being just one of them). Our speciﬁcation of ma-
licious behavior is richer than the one used by Kruegel
et al. Therefore, using our algorithm can result in a
more powerful tool for detecting kernel-level rootkits.
We will explore this interesting application of our algo-
rithm in the future. Singh and Lakhotia [33] provide an
annotated bibliography of papers on malware analysis
and detection.
An essential step in statically analyzing executables
is disassembly, which translates machine code to as-
sembly code. Linn and Debray [23] demonstrate that
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
simple obfuscations can thwart the disassembly pro-
cess. The abovementioned research demonstrates the
importance of handling obfuscations in malware detec-
tion. Kruegel et al. [20] present techniques for disas-
sembling obfuscated executables. In this paper, we as-
sume that the malware being analyzed can be disassem-
bled.
The theoretical limits of malicious code detection
(speciﬁcally of virus detection) have been the focus of
many researchers. A virus is a malware that replicates
itself by copying its code to other program ﬁles. Co-
hen [10] and Chess-White [6] showed that in general
the problem of virus detection is undecidable. Spinel-
lis [34] proved that problem of reliably identifying a
bounded-length virus is NP-complete. These results are
similar to the result presented in this paper (see Theo-
rem 1). However, our formal model of malware detec-
tion is different than the one used by these researchers:
we present a semantics and an algorithm for detecting
speciﬁc malicious behaviors, avoiding the problem of
undecidability (as proven by Cohen) and the problem of
undetectable malware classes (as introduced by Chess
and White).
Dynamic monitoring can also be used for malware
detection. Cohen [10] and Chess-White [6] propose
a virus detection model that executes code in a sand-
box. Another approach rewrites the binary to introduce
checks driven by an enforceable security policy [15]
(known as the inline reference monitor or the IRM ap-
proach). We believe static analysis can be used to im-
prove the efﬁciency of dynamic analysis techniques,
e.g., static analysis can remove redundant checks in the
IRM framework. In the future we will explore hybrid
static-dynamic approaches to malware detection.
5.2. Translation validation
A translation-validation [12, 16, 31, 32] system at-
tempts to verify that the semantics of a program is not
changed by an optimizing transformation. Differences
between malware detection and translation validation
were discussed in the introduction.
5.3. Software veriﬁcation
Our work is closely related to previous results on
static analysis techniques for verifying security proper-
ties of software [1, 3–5, 19, 24]. In a larger context, our
work is similar to existing research on software veriﬁca-
tion [2,11]. However, there are several important differ-
ences. First, since these systems analyze benign code,
they do not have to handle obfuscations. Second, to
our knowledge, all existing work on static analysis tech-
niques for verifying security properties analyzes source
code. On the other hand, our analysis technique works
on executables.
6. Conclusion
We observe that certain malicious behaviors (such
as decryption loops) appear in all variants of a certain
malware. Based on this intuition, we gave a formal
semantics for malware detection. We also presented a
malware-detection algorithm that is sound with respect
to our semantics. Experimental evaluation demon-
strated that our algorithm can detect all variants of cer-
tain malware, has no false positives, and is resilient to
obfuscation transformations generally used by hackers.
There are several opportunities for further work. In
the future we will address the limitations discussed in
Section 3 (see Table 3). We also plan to optimize our
tool to reduce the execution times.
Acknowledgments. We are thankful to our anony-
mous reviewers for their invaluable comments. We
would also like to express our gratitude to Giovanni Vi-
gna, our shepherd throughout the revision process, for
his feedback.
References
[1] K. Ashcraft and D. Engler. Using programmer-written
compiler extensions to catch security holes. In Proceed-
ings of the 2002 IEEE Symposium on Security and Pri-
vacy (Oakland’02), pages 143–159, May 2002.
[2] T. Ball and S. Rajamani. Automatically validating tem-
poral safety properties of interfaces. In Proceedings of
the 8th International SPIN Workshop on Model Check-
ing of Software (SPIN’01), volume 2057 of Lecture
Notes in Computer Science, pages 103–122, Toronto,
Ontario, Canada, 2001. Springer-Verlag Heidelberg.
[3] M. Bishop and M. Dilger. Checking for race conditions
in ﬁle accesses. Computing Systems, 9(2), 1996.
[4] H. Chen and D. Wagner. MOPS: an infrastructure for
examining security properties of software. In 9th ACM
Conference on Computer and Communications Security
(CCS’02). ACM Press, November 2002.
[5] B. Chess. Improving computer security using extending
static checking. In Proceedings of the 2002 IEEE Sym-
posium on Security and Privacy (Oakland’02), pages
160–173, May 2002.
[6] D. Chess and S. White. An undetectable computer virus.
In Proceedings of the 2000 Virus Bulletin Conference
(VB2000), 2000.
[7] M. Christodorescu and S. Jha. Static analysis of exe-
cutables to detect malicious patterns.
In Proceedings
of the 12th USENIX Security Symposium (Security’03),
pages 169–186. USENIX Association, USENIX Asso-
ciation, Aug. 2003.
[8] M. Christodorescu and S. Jha. Testing malware de-