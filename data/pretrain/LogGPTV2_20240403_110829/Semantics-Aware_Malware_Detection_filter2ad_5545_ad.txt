### Limitations

Our tool has a few limitations that are important to understand. First, the current implementation requires all Intermediate Representation (IR) instructions in the template to appear in the same form in the program. For example, if an IR node in the template contains `x = x * 2`, the same operation (an assignment with a multiplication on the right-hand side) must appear in the program for that node to match. This means that equivalent program instructions like `eax = eax << 1` (arithmetic left shift) will not be matched. While it is possible to craft attacks that evade this requirement, they are relatively difficult because the attacker must devise multiple equivalent yet distinct implementations of the same computation to avoid detection. This limitation is not inherent to the semantics and can be mitigated by adding an IR normalization step.

The second limitation stems from the use of def-use chains for value preservation checking. The def-use relations in the malicious template effectively encode a specific ordering of memory updates. Therefore, our algorithm, AMD, will only detect programs that exhibit the same ordering of memory updates. Automatically generating functionally equivalent variants with different memory update orders is a challenging problem. Addressing obfuscations that reorder instructions to achieve a different memory update order is a goal of our ongoing research.

### 4. Experimental Results

We evaluated our implementation of the AMD algorithm against real-world malware variants. The three primary goals of our experiments were:
1. To develop malicious behavior templates that can match malware variants.
2. To measure the false positive rates generated by the algorithm using these templates.
3. To measure the detection algorithm's resilience to obfuscation.

We used both real-world malware instances and benign programs for developing behavior templates and as starting points for obfuscation transformations in the obfuscation resilience testing. Key findings from the evaluation include:

- The template-based algorithm detects worms from the same family and unrelated worms using a single template.
- No false positives were generated when running our malware detector on benign programs, demonstrating the soundness of our algorithm in its current implementation.
- The algorithm shows improved resilience to obfuscation compared to the commercial anti-virus tool, McAfee VirusScan.

#### 4.1. Variant Detection Evaluation

We developed two templates and tested them against malware samples and benign programs. One template captures the decryption-loop functionality common in many malicious programs, while the other template captures the mass-mailing functionality common to email worms. For simplicity, we focus on the decryption-loop template in this section, but the results from the mass-email template were similar.

For malware samples, we used seven variants of Netsky (B, C, D, O, P, T, and W), seven variants of B[e]agle (I, J, N, O, P, R, and Y), and seven variants of Sober (A, C, D, E, F, G, and I). All of these are email worms, each with many variants in the wild, ranging in size from 12 kB to 75 kB.

| Malware Family | Template Detection (Decryption Loop) | Template Detection (Mass Mailer) | Running Time (Avg.) | Running Time (Std. Dev.) |
|----------------|--------------------------------------|----------------------------------|---------------------|--------------------------|
| Netsky         | 100%                                 | 100%                             | 99.57 s             | 41.01 s                  |
| B[e]agle       | 100%                                 | 100%                             | 56.41 s             | 40.72 s                  |
| Sober          | 100%                                 | 0%                               | 100.12 s            | 45.00 s                  |

**Table 4.** Malware detection using algorithm AMD for 21 e-mail worm instances.

The decryption-loop template describes the behavior of programs that unpack or decrypt themselves to memory. It consists of:
1. A loop that processes data from a source memory area and writes data to a destination memory area.
2. A jump that targets the destination area.

Many binary worms use this technique to make static analysis harder, as the actual code of the worm is not available for inspection until runtime. To construct the template, we analyzed the Netsky.B email worm and manually extracted the code that performs the decryption and the jump. The template was then generalized by replacing actual registers and memory addresses with variables. The mass-mailing template was developed similarly, describing the custom SMTP functionality present in the worm, including email composition and transmission.

We applied our algorithm to each malware instance and each decryption-loop template. We achieved 100% detection of the Netsky and B[e]agle worm instances using only the two templates (the mass-mailing template required minor tweaks to detect B[e]agle). The Sober worm instances did not match the mass-mailing template, requiring a separate template. Due to limitations in the current prototype implementation, matching calls into the Microsoft Visual Basic runtime library (used by Sober worm instances) is not supported.

Despite these limitations, our results show that algorithm AMD can detect multiple worm instances from the same family using one template, in contrast with commercial virus scanners that require many signatures (McAfee VirusScan uses 13 signatures to detect the worms in our test set). Our detection results come with one caveat: 3 of the Netsky variants could not be processed by IDA Pro. Since we build our tool on the assumption that disassembly can be performed successfully, we do not consider those 3 variants as false negatives. Running times for the tool (listed in Table 4) are satisfactory for a prototype and suggest that real-time performance can be achieved with an optimized implementation.

#### 4.2. False Positive Evaluation

We evaluated the algorithm and the templates against a set of 2,000 benign programs to measure the false positive rate and to evaluate the templates. The programs ranged in size from <1 kB to 150 kB, including standard Microsoft Windows system programs, compiler tools, and Microsoft Office programs. We also attempted to test larger benign binaries up to 5 MB, but they did not disassemble successfully. For successfully disassembled programs, the false positive rate was 0%, meaning that our implementation correctly classified all programs as benign (none of the test programs matched the templates).

In Figure 4, we present the results of this evaluation. Programs are grouped by size in 5 kB increments, and the disassembly and detection rates are plotted for each group. For example, the bar to the right of the 71,680 B point represents programs between 71,680 B and 76,799 B in size, indicating that 97.78% of the programs in this group were disassembled successfully and detected as benign, while 2.22% failed to disassemble (either because the disassembler crashed or because it failed to group program code into functions). The running time per test case ranged from 9.12 s to 413.78 s, with an average of 165.5 s.

**Figure 4.** Evaluation of algorithm AMD on a set of 2,000 benign Windows programs yielded no false positives. Gray bars indicate the percentage of programs that disassembled correctly and were detected as benign; white bars indicate the percentage of programs that failed to disassemble.

#### 4.3. Obfuscation Resilience Evaluation

To test resilience to obfuscation, we applied garbage insertion transformations of varying complexity to the worm variant B[e]agle.Y and compared the detection rate of our malware detection tool against McAfee VirusScan. The garbage insertion transformation adds irrelevant code fragments to a program. We considered three types of garbage insertion:
1. **Nop insertion:** Adds simple sequences of nop instructions.
2. **Stack-op insertion:** Adds sequences of stack operations.
3. **Math-op insertion:** Adds sequences of arithmetic operations.

We generated 20 variants for each type of obfuscation. To test the limits of our implementation, one of the math-op insertion transformations replaced single instructions of the form `x = x + const` with equivalent sequences. The results are tabulated in Table 5: our tool catches all obfuscations except for the math-op replacement transformation, where the algorithm seeks to exactly match a template instruction of the form `x = x + const`, and any equivalent instruction sequences are not detected.

| Algorithm | Obfuscation Type | Detection Rate | Average Time |
|-----------|------------------|----------------|--------------|
| AMD       | Nop              | 100%           | 74.81 s      |
| AMD       | Stack op         | 100%           | 159.10 s     |
| AMD       | Math op          | 95%            | 186.50 s     |
| McAfee    | Nop              | 75.0%          | -            |
| McAfee    | Stack op         | 25.0%          | -            |
| McAfee    | Math op          | 5.0%           | -            |

**Table 5.** Evaluation of algorithm AMD on a set of obfuscated variants of B[e]agle.Y. For comparison, we include the detection rate of McAfee VirusScan.

### 5. Related Work

We compare our work to existing research in the areas of malware detection, translation validation, and software verification.

#### 5.1. Malware Detection

In previous work [8], we demonstrated that current commercial virus scanners can be easily evaded by using simple obfuscations used by hackers. Many malware-detection techniques are based on static analysis of executables. In this area, we previously described a malware-detection algorithm called SAFE [7]. SAFE can only handle very simple obfuscations (only nops can appear between matching instructions), e.g., the example shown in Figure 1 cannot be handled by SAFE. Moreover, the formal semantics of malware detection was not explored by the earlier work.

Static analysis of binaries is used by Kruegel et al. [21] to detect kernel-level rootkits, which are attack tools that hide their presence from system administrators. They look for suspicious instruction sequences using symbolic execution. The detection algorithm presented in this paper is more powerful because we use multiple decision procedures (symbolic execution being just one of them). Our specification of malicious behavior is richer than the one used by Kruegel et al. Therefore, using our algorithm can result in a more powerful tool for detecting kernel-level rootkits. We will explore this interesting application of our algorithm in the future. Singh and Lakhotia [33] provide an annotated bibliography of papers on malware analysis and detection.

An essential step in statically analyzing executables is disassembly, which translates machine code to assembly code. Linn and Debray [23] demonstrate that simple obfuscations can thwart the disassembly process. The abovementioned research demonstrates the importance of handling obfuscations in malware detection. Kruegel et al. [20] present techniques for disassembling obfuscated executables. In this paper, we assume that the malware being analyzed can be disassembled.

The theoretical limits of malicious code detection (specifically of virus detection) have been the focus of many researchers. A virus is a malware that replicates itself by copying its code to other program files. Cohen [10] and Chess-White [6] showed that, in general, the problem of virus detection is undecidable. Spineless [34] proved that the problem of reliably identifying a bounded-length virus is NP-complete. These results are similar to the result presented in this paper (see Theorem 1). However, our formal model of malware detection is different from the one used by these researchers: we present a semantics and an algorithm for detecting specific malicious behaviors, avoiding the problem of undecidability (as proven by Cohen) and the problem of undetectable malware classes (as introduced by Chess and White).

Dynamic monitoring can also be used for malware detection. Cohen [10] and Chess-White [6] propose a virus detection model that executes code in a sandbox. Another approach rewrites the binary to introduce checks driven by an enforceable security policy [15] (known as the inline reference monitor or the IRM approach). We believe static analysis can be used to improve the efficiency of dynamic analysis techniques, e.g., static analysis can remove redundant checks in the IRM framework. In the future, we will explore hybrid static-dynamic approaches to malware detection.

#### 5.2. Translation Validation

A translation-validation system [12, 16, 31, 32] attempts to verify that the semantics of a program are not changed by an optimizing transformation. Differences between malware detection and translation validation were discussed in the introduction.

#### 5.3. Software Verification

Our work is closely related to previous results on static analysis techniques for verifying security properties of software [1, 3–5, 19, 24]. In a larger context, our work is similar to existing research on software verification [2, 11]. However, there are several important differences. First, since these systems analyze benign code, they do not have to handle obfuscations. Second, to our knowledge, all existing work on static analysis techniques for verifying security properties analyzes source code. On the other hand, our analysis technique works on executables.

### 6. Conclusion

We observe that certain malicious behaviors (such as decryption loops) appear in all variants of a certain malware. Based on this intuition, we provided a formal semantics for malware detection and presented a malware-detection algorithm that is sound with respect to our semantics. Experimental evaluation demonstrated that our algorithm can detect all variants of certain malware, has no false positives, and is resilient to obfuscation transformations generally used by hackers.

There are several opportunities for further work. In the future, we will address the limitations discussed in Section 3 (see Table 3). We also plan to optimize our tool to reduce execution times.

### Acknowledgments

We are thankful to our anonymous reviewers for their invaluable comments. We would also like to express our gratitude to Giovanni Vigna, our shepherd throughout the revision process, for his feedback.

### References

[1] K. Ashcraft and D. Engler. Using programmer-written compiler extensions to catch security holes. In Proceedings of the 2002 IEEE Symposium on Security and Privacy (Oakland’02), pages 143–159, May 2002.

[2] T. Ball and S. Rajamani. Automatically validating temporal safety properties of interfaces. In Proceedings of the 8th International SPIN Workshop on Model Checking of Software (SPIN’01), volume 2057 of Lecture Notes in Computer Science, pages 103–122, Toronto, Ontario, Canada, 2001. Springer-Verlag Heidelberg.

[3] M. Bishop and M. Dilger. Checking for race conditions in file accesses. Computing Systems, 9(2), 1996.

[4] H. Chen and D. Wagner. MOPS: an infrastructure for examining security properties of software. In 9th ACM Conference on Computer and Communications Security (CCS’02). ACM Press, November 2002.

[5] B. Chess. Improving computer security using extending static checking. In Proceedings of the 2002 IEEE Symposium on Security and Privacy (Oakland’02), pages 160–173, May 2002.

[6] D. Chess and S. White. An undetectable computer virus. In Proceedings of the 2000 Virus Bulletin Conference (VB2000), 2000.

[7] M. Christodorescu and S. Jha. Static analysis of executables to detect malicious patterns. In Proceedings of the 12th USENIX Security Symposium (Security’03), pages 169–186. USENIX Association, USENIX Association, Aug. 2003.

[8] M. Christodorescu and S. Jha. Testing malware de-