protocols as instantiated above securely realize F2PASS in the ran-
dom-oracle and FCA-hybrid model.
A detailed proof of Theorem 1 is given in the full version of the
paper [10]; we provide a proof outline here. First, let us conceptu-
ally view all honest participants as a single interactive Turing ma-
chine (ITM) called the challenger, which obtains all inputs from the
environment E intended for honest parties and which outputs the
responses back to E. We deﬁne a series of games with a series of
challengers; the challenger corresponding to game i is denoted Ci.
In the ﬁrst game, C1 receives as input the value sid = (u,S1,S2)
and runs our real protocol on behalf of the honest participants, with
A as the adversary, so the environment receives the same view as it
would in a real execution of the protocol. In the last game, C10 runs
the ideal protocol via the ideal functionality on behalf of the honest
participants, with the simulator SIM as the adversary, so the en-
vironment receives the same view as it would in an ideal execution.
Let view i(sid , 1k) denote the view that E receives when interact-
ing with Ci for session identiﬁer sid and security parameter k; we
will often omit sid and 1k. We brieﬂy describe each challenger Ci
and why each view i is indistinguishable from view i−1; we refer to
the full version [10] for details.
Challenger C1: The challenger runs all honest parties with the
real protocol with all the inputs coming directly from the environ-
ment. Therefore, view 1 is identical to the view that E receives
when honest participants execute our protocol.
Challenger C2: Identical to C1, except that it halts whenever it
receives some values (PS i, m, σ) where PS i is an honest server’s
signature veriﬁcation key and σ is a valid signature under PS i of
the message m, and yet m has never been signed by Si. We have
that view 2 ≈ view 1 by the unforgeability of the signature scheme.
Challenger C3: Identical to C2, except that when an honest user
uses enc2 to send an encryption of a plaintext m to an honest server,
534the ciphertext is computed as an encryption of 1|m|. More con-
cretely, this affects ciphertexts Fi and F (cid:48)
i sent by an honest user to
an honest server Si in Steps S1 and R1.
Let’s call a setup or retrieve query intact if it was initiated by
an honest user and the ﬁrst message (Stp, sid , qid , 1, . . .) or (Rtr,
sid , qid(cid:48), 1, . . .) arrives at an honest server unmodiﬁed. We call
the query hijacked if it was initiated by an honest user but these
messages were modiﬁed in transit, and we call the query corrupt if
it was either hijacked or intiated by a dishonest user. If this query
is intact, then the honest server pretends that the ciphertext Fi or
F (cid:48)
i correctly decrypted to m; otherwise, it decrypts the ciphertext
from the modiﬁed message and proceeds normally. We can show
that view 2 ≈ view 1 by the CCA-2 security of enc2.
Challenger C4: Identical to C3, except that the public key PK in
the CRS is generated such that C4 knows the corresponding secret
key SK . Since PK is distributed exactly as in a real CRS, this hop
is purely conceptual.
Further, C4 runs, on the side, a registry R, that in several ad-
ditional steps will become the ideal functionality F. Whenever
the ﬁrst message of an intact setup query qid is delivered to an
honest server, C4 adds a record (AStp, qid ,U, p, K ) to R. When-
ever the ﬁrst message of a corrupt query is delivered to an hon-
est server, C4 uses the fact that it knows SK to decrypt the ci-
phertexts (C1, ˜C1, C2, ˜C2) to recover p and K .
It then records
(AStp, qid ,U, p, K ) in R. The challenger continues running the
setup protocol, marking qid as succ or fail for a party P when-
ever P outputs succ of fail. If all honest servers output succ, it
records (Stp, qid ,U, p, K ) in R. The existence of the registry R
is internal to C4 and has no effect on view 4.
Challenger C5: Identical to C4, except that, whenever an honest
party performs a zero-knowledge proof, it uses the zero-knowledge
simulator instead of the prover’s algorithm, which results in indis-
tinguishable view by indistinguishability of simulation.
Challenger C6: Identical to C5, except that when the protocol
directs an honest party H to compute c = encPK (m; r) under the
CRS public key PK , where (m, r) will never be sent to a dishonest
party, H instead computes c = encPK (1|m|; r). More concretely,
this change affects the ciphertexts Ci, ˜Ci, C(cid:48)
i that an honest user
sends to an honest server Si in Steps S1 and R1. Whenever the
protocol directs an honest party H(cid:48) to prove something about the
ciphertext c, C6 will, just as C5, have H(cid:48) run the zero-knowledge
simulator for the proof system, instead of the prover, pretending
that c is an encryption of m (as m is known to the challenger).
We have that view 6 ≈ view 5 by semantic security of enc and
simulation-soundness and indistinguishability of simulation of the
ZK proof system.
Challenger C7: Suppose that an honest server S2 is engaged
with a server S1 in a Retrieve attempt for a particular (sid , qid(cid:48)).
C7 differs from C6 in how it computes the ciphertext E in Step R3
and how it forms the ciphertext ˜C(cid:48)
If the current query qid(cid:48) is a corrupt query, then C7 decrypts C(cid:48)
and C(cid:48)
2 using SK to recover p(cid:48); else the environment explicitly pro-
vided p(cid:48) as input to C7 on behalf of the honest user. It then looks
up the record (Stp, p, K ) in its registry R. If p = p(cid:48), then form
E as an encryption of 1; else as an encryption of a random group
element. The proof π2 is executed, as done by all challengers start-
ing with C5, via the simulator. Further, in Step R5, if query qid(cid:48)
is intact, compute the ciphertext ˜C(cid:48)
2 as an encryption of 1|K2|; else
(i.e., if this query is corrupt) compute it correctly as an encryption
of the key share K2 established in the setup phase. The proof π5 is
computed via the zero-knowledge simulator.
To prove that view 7 ≈ view 6, we rely on the simulation-sound-
2 in Step R5.
ness of the proof system and the semantic security of enc.
1 and C(cid:48)
Challenger C8: Suppose that an honest server S1 is engaged
with S2 in a Retrieve attempt for a particular (sid , qid(cid:48)). C8 dif-
fers from C7 in that it computes the ciphertext E1 in Step R2 as
an encryption of 1. If query qid(cid:48) is corrupt, then C8 recovers p(cid:48)
by decrypting C(cid:48)
2; else p(cid:48) is known to it. In Step R4, if
(cid:54)= p, it simply fails; if p(cid:48) = p, the honest server completes
p(cid:48)
the rest of the retrieve protocol as follows: in Step R4 it computes
the ciphertext ˜C(cid:48)
1 correctly if the current query qid(cid:48) is corrupt (so
that the dishonest user controlled by the adversary, upon submitting
the correct password, will learn the correct key share K1), and as
an encryption of 1|K1| otherwise. The proofs π3 and π4 are simu-
lated. Similarly to the previous step, to show that view 7 ≈ view 6,
we rely on the simulation-soundness of the proof system and the
semantic security of enc.
1 and ˜C(cid:48)
Note that at this point, if the user and at least one of the servers is
honest, then the only way in which the protocol messages depend
on the honest user’s input, is on the fact whether the passwords
match (p = p(cid:48)) during the retrieve protocol. If they match and
the query is corrupt, then the ciphertexts ˜C(cid:48)
2 additionally
depend on the stored key K . We still want to make sure that for
honest queries, the user retrieves the correct key or outputs fail if
the passwords match, and outputs fail if they don’t match. This
we will do in the next step.
Challenger C9: Same as C8, except that it halts if one of the
following bad events happens: (1) the event that an honest user
carries out a retrieval with at least one honest server and the correct
password, and at the end of the protocol the user outputs a key K (cid:48)
that is not equal to K stored in the registry R; or (2) the event
that an honest user carries out a retrieval with at least one honest
server and an incorrect password, but successfully ends the retrieval
protocol with some key K (cid:48); or (3) the event that in a corrupt retrieve
query with an incorrect password, an honest server Si encrypts his
key share Ki under PK u.
The fact that view 9 ≈ view 8 is shown by an argument about
the statements proved by the various zero-knowledge proofs.
It
relies on the simulation-soundness of the proof system, as well as
the fact that, for all challengers starting with C2, an honest server’s
signature implies that this server has accepted all preceding proofs.
Challenger C10: In this game, the idea is to give the environment
a view that is identical to view 9, but to have C10 internally run the
full-ﬂedged ideal functionality F, and to have all the honest partic-
ipants run the ideal protocol with F; interaction with the adversary
will now be based solely on what F sends to the ideal-world ad-
versary. To this end, we turn the registry R into the internal book-
keeping of F: F keeps track of what the correct password is, and
at what stage various attempts at setup and retrieve currently are.
Essentially, C10 is now viewed not as a single ITM, but as several
ITMs interacting with each other: one ITM that executes the ideal
functionality F; a “dummy” ITM for each ideal-world honest par-
ticipant that simply relays messages between the environment and
F; and an ITM SIM that talks to F on behalf of the ideal-world
adversary and to A on behalf of the honest participants.
We have already described F and the ideal parties in Section 2.
What remains to do is to describe SIM and to verify that the re-
sulting view 10 is identical to view 9. The description of SIM is
given in detail in the full version of this paper [10]. In a nutshell,
in order to view C9 as consisting of all these different ITMs, we
observe that the protocol messages that the honest parties inside C9
send out only depend on information about the actual password and
key that is provided to the simulator SIM by F.
Although the way that C10 is structured internally is different
from the way C9 is structured (because C9 doesn’t separate its com-
putation steps into those carried out by F, those carried out by
1
535SIM, and those carried out by honest ideal parties), each message
that C10 sends to A and E is computed exactly as in C9, so we have
that view 10 ≈ view 9.
Acknowledgments
We thank Kristiyan Haralambiev, Stas Jarecki, Anja Lehmann, Vic-
tor Shoup, and the anonymous referees for their valuable feedback
and comments on earlier versions of this work. This work was sup-
ported in part by the European Commission through the ICT Pro-
gramme under Contract ICT-2007-216676 ECRYPT II. The ﬁrst
and third authors were supported in part by EC Grant Agreement
257782 ABC4Trust. The second author is supported by the United
States NSF grants 1012060, 0964379, 0831293.
6. REFERENCES
[1] A. Bagherzandi, S. Jarecki, N. Saxena, and Y. Lu.
Password-protected secret sharing. In ACM CCS 2011.
[2] B. Barak, Y. Lindell, and T. Rabin. Protocol initialization for
the framework of universal composability. Cryptology ePrint
Archive, Report 2004/006, 2004.
[3] M. Bellare, D. Pointcheval, and P. Rogaway. Authenticated
key exchange secure against dictionary attacks. In
EUROCRYPT 2000.
[4] M. Bellare and P. Rogaway. Random oracles are practical: A
paradigm for designing efﬁcient protocols. In ACM CCS 93.
[5] S. M. Bellovin and M. Merritt. Encrypted key exchange:
Password-based protocols secure against dictionary attacks.
In IEEE Symposium on Security and Privacy 1992.
[6] J. Brainard, A. Juels, B. S. Kaliski Jr., and M. Szydlo. A new
two-server approach for authentication with short secrets. In
USENIX SECURITY 2003.
[7] W. E. Burr, D. F. Dodson, E. M. Newton, R. A. Perlner,
W. T. Polk, S. Gupta, and E. A. Nabbus. Electronic
authentication guideline. NIST Special Publication 800-63-1,
2011.
[8] J. Camenisch, A. Kiayias, and M. Yung. On the portability of
generalized Schnorr proofs. In EUROCRYPT 2009.
[9] J. Camenisch, S. Krenn, and V. Shoup. A framework for
practical universally composable zero-knowledge protocols.
In ASIACRYPT 2011.
[10] J. Camenisch, A. Lysyanskaya, and G. Neven. Practical yet
universally composable two-server password-authenticated
secret sharing. Cryptology ePrint Archive, 2012.
[11] J. Camenisch and M. Stadler. Efﬁcient group signature
schemes for large groups. In CRYPTO ’97.
[12] R. Canetti. Universally composable security: A new
paradigm for cryptographic protocols. In FOCS 2001.
[13] R. Canetti. Universally composable signature, certiﬁcation,
and authentication. In 17th Computer Security Foundations
Workshop, page 219. IEEE Computer Society, 2004.
[14] R. Canetti, S. Halevi, J. Katz, Y. Lindell, and
P. D. MacKenzie. Universally composable password-based
key exchange. In EUROCRYPT 2005.
[15] R. Canetti and T. Rabin. Universal composition with joint
state. In CRYPTO 2003.
[16] R. Cramer and V. Shoup. Design and analysis of practical
public-key encryption schemes secure against adaptive
chosen ciphertext attack. SIAM Journal on Computing,
33(1):167–226, 2003.
[17] M. Di Raimondo and R. Gennaro. Provably secure threshold
password-authenticated key exchange. In
EUROCRYPT 2003.
[18] T. ElGamal. A public key cryptosystem and a signature
scheme based on discrete logarithms. In CRYPTO ’84.
[19] A. Fiat and A. Shamir. How to prove yourself: Practical
solutions to identiﬁcation and signature problems. In
CRYPTO ’86.
[20] W. Ford and B. S. Kaliski Jr. Server-assisted generation of a
strong secret from a password. In IEEE WETICE 2000.
[21] J. A. Garay, P. D. MacKenzie, and K. Yang. Strengthening
zero-knowledge protocols using signatures. In
EUROCRYPT 2003.
[22] S. Goldwasser and S. Micali. Probabilistic encryption.
Journal of Computer and System Sciences, 28(2), 1984.
[23] S. Goldwasser, S. Micali, and R. Rivest. A digital signature
scheme secure against adaptive chosen-message attacks.
SIAM Journal on Computing, 17(2):281–308, 1988.
[24] L. Gong, T. M. A. Lomas, R. M. Needham, and J. H. Saltzer.
Protecting poorly chosen secrets from guessing attacks.
IEEE Journal on Selected Areas in Communications,
11(5):648–656, 1993.
[25] S. Halevi and H. Krawczyk. Public-key cryptography and
password protocols. ACM TISSEC, 2(3):230–268, 1999.
[26] C. Herley, P. C. van Oorschot, and A. S. Patrick. Passwords:
If we’re so smart, why are we still using them? In FC 2009.
[27] D. P. Jablon. Password authentication using multiple servers.
In CT-RSA 2001.
[28] J. Katz, P. D. MacKenzie, G. Taban, and V. D. Gligor.
Two-server password-only authenticated key exchange. In
ACNS 05.
[29] J. Katz, R. Ostrovsky, and M. Yung. Efﬁcient and secure
authenticated key exchange using weak passwords. Journal
of the ACM, 57(1), 2009.
[30] P. D. MacKenzie, T. Shrimpton, and M. Jakobsson.
Threshold password-authenticated key exchange. In
CRYPTO 2002.
[31] P. D. MacKenzie and K. Yang. On simulation-sound trapdoor
commitments. In EUROCRYPT 2004.
[32] B. Pﬁtzmann and M. Waidner. Composition and integrity
preservation of secure reactive systems. In ACM CCS 2000.
[33] D. Pointcheval and J. Stern. Security proofs for signature
schemes. In EUROCRYPT ’96.
[34] C. Rackoff and D. R. Simon. Non-interactive
zero-knowledge proof of knowledge and chosen ciphertext
attack. In CRYPTO ’91.
[35] C. P. Schnorr. Efﬁcient signature generation for smart cards.
Journal of Cryptology, 4(3):239–252, 1991.
[36] A. Shamir. How to share a secret. Communications of the
ACM, 22(11):612–613, Nov. 1979.
[37] M. Szydlo and B. S. Kaliski Jr. Proofs for two-server
password authentication. In CT-RSA 2005.
536