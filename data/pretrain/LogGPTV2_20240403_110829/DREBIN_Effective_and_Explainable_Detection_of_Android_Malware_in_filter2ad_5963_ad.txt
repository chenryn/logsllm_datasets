limited compared to regular desktop
computers. Consequently, a detection method that is supposed
to run directly on these devices has to carry out its task very
efﬁciently.
Fig. 7: Detailed run-time analysis of DREBIN.
A detailed run-time analysis for the desktop computer and
the Galaxy S3 smartphone is presented in Figure 7, where
the run-time per application is plotted against the size of the
analyzed code. Surprisingly, on both devices DREBIN attains
a sublinear run-time, that is, its performance increases with
O(pm) in the number of analyzed bytes m. Apparently, the
number of features does not increase linearly with the code
and thus larger applications do not necessarily contain more
features to analyze.
From this evaluation, we conclude that DREBIN does not
only reliably detect malicious applications but is furthermore
capable to perform this task in a time which clearly meets
practical requirements.
IV. LIMITATIONS
The previous evaluation demonstrates the efﬁcacy of
our method in detecting recent malware on the Android
platform. However, DREBIN cannot generally prohibit
in-
fections with malicious applications, as it builds on con-
cepts of static analysis and lacks dynamic inspection. In
particular, transformation attacks that are non-detectable by
static analysis, as for example based on reﬂection and
bytecode encryption [see 30], can hinder an accurate de-
tection. To alleviate the absence of a dynamic analysis,
DREBIN extracts API calls related to obfuscation and load-
ing of code, such as DexClassLoader.loadClass() and
Fig. 6: Run-time performance of DREBIN.
To analyze the run-time of DREBIN we implement a stan-
dalone Android application that receives a learned detection
model and is able to perform the detection process directly
on the smartphone. The size of the downloaded model is only
about 280 kbytes. Using this application we measure the run-
time of DREBIN on different devices using 100 randomly
selected popular applications from the Google Play Store.
For this experiment, we choose devices which cover various
widespread hardware conﬁgurations including four smartphone
(Nexus 4, Galaxy S3, Xperia Mini Pro and Nexus 3), a tablet
(Nexus 7) and a regular desktop computer (PC).
The results are presented in Figure 6. On average, DREBIN
is able to analyze a given application in 10 seconds on the ﬁve
smartphones. Even on older models, such as the Xperia Mini
Pro, the method is able to analyze the application in less than
20 seconds on average. Overall, no analysis takes longer than
1 minute on all devices. On the desktop computer (2.26 GHz
9
Cipher.getInstance(). These features enable us to at least
spot the execution of hidden code—even if we cannot further
analyze it. In combinations with other features, DREBIN is still
able to identify malware despite the use of some obfuscation
techniques.
To avoid crafting detection patterns manually, we make
use machine learning for generating detection models. While
learning techniques provide a powerful tool for automatically
inferring models, they require a representative basis of data for
training. That is, the quality of the detection model of DREBIN
critically depends on the availability of representative mali-
cious and benign applications. While it is straightforward to
collect benign applications, gathering recent malware samples
requires some technical effort. Fortunately, methods for ofﬂine
analysis, such as DroidRanger [40], AppsPlayground [29] and
RiskRanker [21], might help here to automatically acquire
malware and provide the basis for updating and maintaining a
representative dataset for DREBIN over time.
Another limitation which follows from the use of ma-
chine learning is the possibility of mimicry and poisoning
attacks [e.g., 25, 27, 35]. While obfuscation strategies, such
as repackaging, code reordering or junk code insertion do
not affect DREBIN, renaming of activities and components
between the learning and detection phase may impair discrim-
inative features [30, 38]. Similarly, an attacker may succeed
in lowering the detection score of DREBIN by incorporating
benign features or fake invariants into malicious applications
[25, 27]. Although such attacks against learning techniques
cannot be ruled out in general, the thorough sanitization of
learning data [see 7] and a frequent retraining on representative
datasets can limit their impact.
V. RELATED WORK
The analysis and detection of Android malware has been a
vivid area of research in the last years. Several concepts and
techniques have been proposed to counter the growing amount
and sophistication of this malware. An overview of the current
malware landscape is provided in the studies of Felt et al. [16]
and Zhou & Jiang [39].
1) Detection using static analysis: The ﬁrst approaches for
detecting Android malware have been inspired by concepts
from static program analysis. Several methods have been
proposed that statically inspect applications and disassemble
their code [e.g., 12, 13, 15, 21]. For example, the method
Kirin [13] checks the permission of applications for indications
of malicious activity. Similarly, Stowaway [15] analyzes API
calls to detect overprivileged applications and RiskRanker [21]
statically identiﬁes applications with different security risks.
Common open-source tools for static analysis are Smali [17]
and Androguard [10], which enable dissecting the content of
applications with little effort.
Our method DREBIN is related to these approaches and
employs similar features for identifying malicious applications,
such as permissions, network addresses and API calls. How-
ever, it differs in two central aspects from previous work:
First, we abstain from crafting detection patterns manually
and instead apply machine learning to analyze information
extracted from static analysis. Second, the analysis of DREBIN
is optimized for effectivity and efﬁciency, which enables us to
inspect application directly on the smartphone.
2) Detection using dynamic analysis: A second branch of
research has studied the detection of Android malware at run-
time. Most notably, are the analysis system TaintDroid [11] and
DroidScope [37] that enable dynamically monitoring applica-
tions in a protected environment, where the ﬁrst focuses on
taint analysis and the later enables introspection at different
layers of the platform. While both systems provide detailed
information about the behavior of applications, they are tech-
nically too involved to be deployed on smartphones and detect
malicious software directly.
As a consequence, dynamic analysis is mainly applied for
ofﬂine detection of malware, such as scanning and analyzing
large collections of Android applications. For example, the
methods DroidRanger [40], AppsPlayground [29], and Cop-
perDroid [31] have been successfully applied to study applica-
tions with malicious behavior in different Android markets. A
similar detection system called Bouncer is currently operated
by Google. Such dynamic analysis systems are suitable for
ﬁltering malicious applications from Android markets. Due to
the openness of the Android platform, however, applications
may also be installed from other sources, such as web pages
and memory sticks, which requires detection mechanisms
operating on the smartphone.
ParanoidAndroid [28] is one of the few detection sys-
tems that employs dynamic analysis and can spot malicious
activity on the smartphone. To this end, a virtual clone of
the smartphone is run in parallel on a dedicated server and
synchronized with the activities of the device. This setting
allows for monitoring the behavior of applications on the clone
without disrupting the functionality of the real device. The
duplication of functionality, however, is involved and with
millions of smartphones in practice operating ParanoidAndroid
at large scale is technically not feasible.
3) Detection using machine learning: The difﬁculty of
manually crafting and updating detection patterns for Android
malware has motivated the application of machine learning.
Several methods have been proposed that analyze applications
automatically using learning methods [e.g., 2, 26, 33]. As an
example, the method of Peng et al. [26] applies probabilistic
learning methods to the permissions of applications for detect-
ing malware. Similarly, the methods Crowdroid [4], Droid-
Mat [36], Adagio [20], MAST [5], and DroidAPIMiner [1]
analyze features statically extracted from Android appli-
cations using machine learning techniques. Closest
to our
work is DroidAPIMiner [1] which provides a similar detec-
tion performance to DREBIN on recent malware. However,
DroidAPIMiner builds on a k-nearest neighbor classiﬁer that
induces a signiﬁcant runtime overhead and impedes operating
the method on a smartphone. Moreover, DroidAPIMiner is
not designed to provide explanations for its detections and
therefore is opaque to the practitioner.
Overall, previous work using machine learning mainly fo-
cuses on an accurate detection of malware. Additional aspects,
such as the efﬁciency and the explainability of the detection,
are not considered. We address these aspects and propose a
method that provides an effective, efﬁcient and explainable
detection of malicious applications.
10
VI. CONCLUSION
Android malware is a new yet fast growing threat. Classic
defenses, such as anti-virus scanners, increasingly fail to cope
with the amount and diversity of malware in application
markets. While recent approaches, such as DroidRanger [40]
and AppPlayground [29], support ﬁltering such applications
off these markets, they induce a run-time overhead that is
prohibitive for directly protecting smartphones. As a remedy,
we introduce DREBIN, a lightweight method for detection
of Android malware. DREBIN combines concepts from static
analysis and machine learning, which enables it to better keep
pace with malware development. Our evaluation demonstrates
the potential of this approach, where DREBIN outperforms
related approaches and identiﬁes malicious applications with
few false alarms.
In practice, DREBIN provides two advantages for the
security of the Android platform: First, it enables efﬁciently
scanning large amounts of applications, such as from third-
party markets. With an average run-time of 750 ms per
application on a regular computer, it requires less than a day
to analyze 100,000 unknown applications. Second, DREBIN
can be applied directly on smartphones, where the analysis
can be triggered when new applications are downloaded to
the device. Thereby, DREBIN can protect users that install
applications from untrusted sources, such as websites and
third-party markets.
Although DREBIN effectively identiﬁes malicious software
in our evaluation, it exhibits the inherent limitations of static
analysis. While it is able to detect indications of obfuscation
or dynamic execution, the retrieved code is not accessible by
the method. A similar setting has been successfully tackled
for the analysis of JavaScript code [see 9] and dynamically
triggering the static analysis of DREBIN whenever new code
is loaded seems like a promising direction of future work.
DATASET
To foster research in the area of malware detection and
to enable a comparison of different approaches, we make the
malicious Android applications used in our work as well as
all extracted feature sets available to other researchers under
http://user.cs.uni-goettingen.de/⇠darp/drebin.
ACKNOWLEDGEMENTS
The authors would like to thank the anonymous reviewers
for their helpful comments and Yan Chen for shepherding the
paper. The authors acknowledge funding from BMBF under
the project PROSEC (FKZ 01BY1145).
REFERENCES
[1] Y. Aafer, W. Du, and H. Yin, “DroidAPIMiner: Mining
API-level features for robust malware detection in an-
droid,” in Proc. of International Conference on Security
and Privacy in Communication Networks (SecureComm),
2013.
[2] D. Barrera, H. G. Kayacik, P. C. van Oorschot, and
A. Somayaji, “A methodology for empirical analysis of
permission-based security models and its application to
android,” in Proc. of ACM Conference on Computer and
Communications Security (CCS), 2010, pp. 73–84.
11
[3] B. Bloom, “Space/time trade-offs in hash coding with
allowable errors,” Communication of the ACM, vol. 13,
no. 7, pp. 422–426, 1970.
[4] I. Burguera, U. Zurutuza, and S. Nadjm-Tehrani, “Crow-
droid: behavior-based malware detection system for an-
droid,” in Proc. of ACM Worksgop on Security and
Privacy in Smartphones and Mobile Devices (SPSM),
2011, pp. 15–26.
[5] S. Chakradeo, B. Reaves, P. Traynor, and W. Enck,
“Mast: Triage for market-scale mobile malware analysis,”
in Proc. of ACM Conference on Security and Privacy in
Wireless and Mobile Networks (WISEC), 2013.
[6] T. Cormen, C. Leiserson, and R. Rivest, Introduction to
Algorithms. MIT Press, 1989.
[7] G. Cretu, A. Stavrou, M. Locasto, S. Stolfo, and
A. Keromytis, “Casting out demons: Sanitizing training
data for anomaly sensors,” in Proc. of IEEE Symposium
on Security and Privacy, 2008, pp. 81–95.
[8] N. Cristianini and J. Shawe-Taylor, An Introduction to
Support Vector Machines. Cambridge, UK: Cambridge
University Press, 2000.
[9] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert,
“Zozzle: Fast and precise in-browser JavaScript malware
detection,” in Proc. of USENIX Security Symposium,
2011.
[10] A. Desnos and G. Gueguen, “Android: From reversing to
decompilation,” in Presentation at Black Hat Abu Dhabi,
2011.
[11] W. Enck, P. Gilbert, B. gon Chun, L. P. Cox, J. Jung,
P. McDaniel, and A. Sheth, “Taintdroid: An information-
ﬂow tracking system for realtime privacy monitoring
on smartphones,” in Proc. of USENIX Symposium on
Operating Systems Design and Implementation (OSDI),
2010, pp. 393–407.
[12] W. Enck, D. Octeau, P. McDaniel, and S. Chaudhuri,
“A study of Android application security,” in Proc. of
USENIX Security Symposium, 2011.
[13] W. Enck, M. Ongtang, and P. D. McDaniel, “On
lightweight mobile phone application certiﬁcation,” in
Proc. of ACM Conference on Computer and Communi-
cations Security (CCS), 2009, pp. 235–245.
[14] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and
C.-J. Lin, “LIBLINEAR: A library for large linear classi-
ﬁcation,” Journal of Machine Learning Research (JMLR),
vol. 9, pp. 1871–1874, 2008.
[15] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner,
“Android permissions demystiﬁed,” in Proc. of ACM
Conference on Computer and Communications Security
(CCS), 2011, pp. 627–638.
[16] A. P. Felt, M. Finifter, E. Chin, S. Hanna, and D. Wagner,
“A survey of mobile malware in the wild,” in Proc. of
ACM Worksgop on Security and Privacy in Smartphones
and Mobile Devices (SPSM), 2011, pp. 3–14.
[17] J. Freke, “An assembler/disassembler for android’s dex
format,” Google Code, http://code.google.com/p/smali/,
visited February, 2013.
[18] “Mobile threat report 2012 q3,” F-Secure Response Labs,
2012.
Gappusin/.
[19] 2012, http://www.naked-security.com/malware/Android.
[20] H. Gascon, F. Yamaguchi, D. Arp, and K. Rieck, “Struc-
tural detection of android malware using embedded call
graphs,” in Proc. of ACM Workshop on Artiﬁcial Intelli-
gence and Security (AISEC), Nov. 2013, pp. 45–54.
[21] M. Grace, Y. Zhou, Q. Zhang, S. Zou, and X. Jiang,
“Riskranker: scalable and accurate zero-day android mal-
ware detection,” in Proc. of International Conference on
Mobile Systems, Applications, and Services (MOBISYS),
2012, pp. 281–294.
[22] X. Jiang, “Security alert: Gingermaster,” 2011, http://
www.csc.ncsu.edu/faculty/jiang/GingerMaster/.
[23] ——, “Security alert: Golddream,” 2011, http://www.csc.
ncsu.edu/faculty/jiang/GoldDream/.
[24] ——, “Security alert: New droidkungfu variant,” 2011,
http://www.csc.ncsu.edu/faculty/jiang/DroidKungFu3/.
[25] J. Newsome, B. Karp, and D. Song, “Paragraph: Thwart-
ing signature learning by training maliciously,” in Recent
Adances in Intrusion Detection (RAID), 2006, pp. 81–
105.
[26] H. Peng, C. S. Gates, B. P. Sarma, N. Li, Y. Qi,
R. Potharaju, C. Nita-Rotaru, and I. Molloy, “Using prob-
abilistic generative models for ranking risks of android
apps,” in Proc. of ACM Conference on Computer and
Communications Security (CCS), 2012, pp. 241–252.
[27] R. Perdisci, D. Dagon, W. Lee, P. Fogla, and M. Sharif,
“Misleading worm signature generators using deliberate
noise injection,” in Proc. of IEEE Symposium on Security
and Privacy, 2006, pp. 17–31.
[28] G. Portokalidis, P. Homburg, K. Anagnostakis, and
H. Bos, “Paranoid android: Versatile protection for smart-
phones,” in Proc. of Annual Computer Security Applica-
tions Conference (ACSAC), 2010.
[29] V. Rastogi, Y. Chen, and W. Enck, “Appsplayground:
Automatic security analysis of smartphone applications,”
in Proc. ACM Conference on Data and Application
Security and Privacy (CODASPY), 2013.
[30] V. Rastogi, Y. Chen, and X. Jiang, “DroidChameleon:
evaluating android anti-malware against transformation
attacks,” in Proc. of ACM Symposium on Informa-
tion, Computer and Communications Security(ASIACCS),
2013.
[31] A. Reina, A. Fattori, and L. Cavallaro, “A system call-
centric analysis and stimulation technique to automati-
cally reconstruct android malware behaviors,” in Proc.
of European Workshop on System Security (EUROSEC),
April 2013.
[32] C. Rossow, C. Dietrich, C. Gier, C. Kreibich, V. Paxson,
N. Pohlmann, H. Bos, and M. van Steen, “Prudent
practices for designing malware experiments: Status quo
and outlook,” in Proc. of IEEE Symposium on Security
and Privacy, 2012.
[33] B. P. Sarma, N. Li, C. Gates, R. Potharaju, C. Nita-
Rotaru, and I. Molloy, “Android permissions: a perspec-
tive combining risks and beneﬁts,” in Proc. of ACM
symposium on Access Control Models and Technologies
(SACMAT), 2012, pp. 13–22.
[34] R. Sommer and V. Paxson, “Outside the closed world: On
using machine learning for network intrusion detection,”
in Proc. of IEEE Symposium on Security and Privacy,
2010, pp. 305–316.
[35] S. Venkataraman, A. Blum, and D. Song, “Limits of
learning-based signature generation with adversaries,”
in Proc. of Network and Distributed System Security
Symposium (NDSS), 2008.
[36] D.-J. Wu, C.-H. Mao, T.-E. Wei, H.-M. Lee, and K.-
P. Wu, “Droidmat: Android malware detection through
manifest and API calls tracing,” in Proc. of Asia Joint
Conference on Information Security (Asia JCIS), 2012,
pp. 62–69.
[37] L.-K. Yan and H. Yin, “Droidscope: Seamlessly recon-
structing os and dalvik semantic views for dynamic
android malware analysis,” in Proc. of USENIX Security
Symposium, 2012.
[38] M. Zheng, P. P. Lee, and J. C. Lui, “ADAM: an automatic
and extensible platform to stress test android anti-virus
system,” in Detection of Intrusions and Malware &
Vulnerability Assessment (DIMVA), 2012, pp. 82–101.
[39] Y. Zhou and X. Jiang, “Dissecting android malware:
Characterization and evolution,” in Proc. of IEEE Sym-
posium on Security and Privacy, 2012, pp. 95–109.
[40] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang, “Hey, you,
get off of my market: Detecting malicious apps in ofﬁcial
and alternative android markets,” in Proc. of Network and
Distributed System Security Symposium (NDSS), 2012.
12