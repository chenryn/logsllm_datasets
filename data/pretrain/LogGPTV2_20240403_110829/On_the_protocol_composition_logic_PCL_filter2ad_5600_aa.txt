title:On the protocol composition logic PCL
author:Cas J. F. Cremers
On the Protocol Composition Logic PCL
∗
Cas Cremers
ETH Zurich
Switzerland
PI:EMAIL
ABSTRACT
A recent development in formal security protocol analysis is
the Protocol Composition Logic (PCL). We identify a num-
ber of problems with this logic as well as with extensions
of the logic, as deﬁned in [9, 13, 14, 17, 20, 21]. The identi-
ﬁed problems imply strong restrictions on the scope of PCL,
and imply that some claimed PCL proofs cannot be proven
within the logic, or make use of unsound axioms. This in-
cludes the proofs of the CR protocol from [13, 14] and the
SSL/TLS and IEEE 802.11i protocols from [20, 21]. Where
possible, we propose solutions for these problems.
Categories and Subject Descriptors
C.2.2 [Computer-communication Networks]: Network
Protocols—Protocol veriﬁcation; F.3 [Logics and mean-
ings of programs]: Specifying and Verifying and Reason-
ing about Programs
General Terms
Security, Theory
Keywords
Security protocol analysis, logic, composition
1.
INTRODUCTION
Formally establishing properties of security protocols has
been investigated extensively during the last twenty years,
but a deﬁnite model and a corresponding method for security
protocol analysis has remained elusive thus far.
The most successful approaches to security protocol anal-
ysis have been focused on tools for ﬁnding attacks, which
are often based on bounded model checking or constraint
solving, e.g. [1, 22]. When such tools ﬁnd an attack, one can
∗This work was supported by the Hasler Foundation, under
ManCom project 2071.
To appear in the Third ACM Symposium on Information, Computer and
Communications Security (ASIACCS’08), March 2008, Tokyo.
easily verify manually whether or not the attack actually ex-
ists on the protocol. Some tools even allow for unbounded
veriﬁcation of protocols, e.g. [4,7]. If no attack is found with
such tools, correctness of the protocol follows. However, this
provides little insight into why a protocol is correct.
An alternative approach is to develop a logic for reasoning
about security protocols. When a protocol is proven cor-
rect in such a logic, the derivation steps can provide insight
into the mechanisms that make the protocol work. Despite
the obvious promise of such an approach, several attempts
have failed, most notably the BAN logic from [6]. One of
the stumbling points seems to be to provide a logic that is
sound with respect to the complicated semantics of security
protocol execution in the presence of an active intruder, and
is able to provide concise formal proofs.
A recent attempt to develop such a logic is the Proto-
col Composition Logic (PCL) from e.g. [14]. This logic has
evolved from a protocol model to express protocol composi-
tion and reﬁnement, into a model with an associated logic
that can be used to formally prove security properties of pro-
tocols [9,13,17]. Variants of PCL have been applied to many
case studies and oﬀer several interesting features. For exam-
ple, one can reason about security protocols without explic-
itly reasoning about the (complex) intruder by means of a
special kind of invariant reasoning captured by the honesty
rule. This kind of reasoning also allows the protocol logic
to deal with protocol composition and reﬁnement, where
proofs can be reused. PCL has been extended with several
features in further work, such as an extension for hash func-
tions in [21] that was used for a modular correctness proof
of IEEE 802.11i and TLS.
In this paper, we identify a number of problems with PCL
as deﬁned in [9, 13, 14, 17, 20, 21]. They have implications
for the scope of PCL, a number of claimed formal proofs,
and several extensions to the base model.
In particular,
we show that in contrast with the claims in e.g. the intro-
duction of [14], PCL as deﬁned in [9, 13, 14, 17] cannot be
used to prove common authentication properties of proto-
cols that do not include signatures. We show that a num-
ber of claimed proofs in PCL cannot be correct because (a)
there is no way to establish preceding actions in a thread,
and (b) there is no way to express type restrictions in PCL.
With respect to existing PCL extensions, we identify two
problems: the Diﬃe-Hellman extension from [9, 13, 14, 17]
does not correctly capture the algebraic behaviour of Diﬃe-
Hellman-like protocols, and the extension for hash functions
from [20, 21] is not sound. Some of these problems can be
resolved by minor modiﬁcations to PCL, but other problems
require further investigation. Our observations suggest that
it is at least required to make changes to existing axioms, to
introduce new axioms, and to add a mechanism for a type
system.
The purpose of this paper is to identify some of the chal-
lenges that need to be addressed in order to make a logic like
PCL work. We hope it will contribute to the improvement
of PCL, and will lead to a better understanding of some of
the pitfalls of designing a compact and usable formal logic
for security protocols.
The scope of this paper. The presentation of this paper
is inherently diﬃcult, not least because there are a number
of diﬀerent papers on PCL, which vary in notation and tech-
nical details. Many ideas were already present in precursors
of PCL, e.g. [18,19], but these variants use diﬀerent concepts
than later versions of PCL. These early variants in [18, 19]
have no notion of thread (a.k.a. process, run, or role in-
stance), and events are bound to agents. More recent ver-
sions of PCL bind events to threads of agents, and therefore
distinguish between several threads of the same agent. PCL
versions of the latter type can be found in [10–12,16]. Subse-
quently, [10–12,16] have been claimed to be either subsumed,
or revised and extended, by more recent works [9, 13, 14, 17].
Hence we choose here to focus on [9, 13, 14, 17], which con-
tain similar descriptions of PCL. Throughout this paper we
write basic PCL to refer to [9, 13, 14, 17]. The publications
on basic PCL describe the fundamental part of PCL that fo-
cusses on authentication. In general, the comments in this
paper apply to basic PCL. The comments in Section 4.2 ap-
ply only to the extensions found in [20, 21]. Our comments
here do not cover the recent extensions to basic PCL for the
analysis of secrecy, as found in [24], nor the computational
variants of PCL, as found in e.g. [15].
Syntax and page references. In order to pinpoint our
observations to speciﬁc formulas, we select a speciﬁc version
of PCL to refer to. We have chosen the most recent descrip-
tion of PCL from 2007 as found in [14]. In particular, we
will use [14] as a reference for the syntax of PCL formulas,
and to provide speciﬁc page references. Hence we use [14] as
the reference paper to present the problems with basic PCL
from the papers [9, 13, 14, 17].
For the technical details, in particular the formulas, we
assume the reader is at least somewhat familiar with one
of the papers from [9, 13, 14, 17] or [20, 21]. However, the
main points should be clear to readers familiar with formal
security protocol analysis.
The remainder of the paper is structured in the following
way. We start oﬀ by recalling some PCL notation and con-
cepts in Section 2. Then, in Section 3 we discuss problems
with the basic deﬁnition of PCL. In Section 4 we identify
two problems with existing PCL extensions. We conclude
in Section 5.
Acknowledgements.
The author would like to thank David Basin, Anupam
Datta, Felix Klaedtke, Sjouke Mauw, Simon Meier, John C.
Mitchell, Arnab Roy and the anonymous referees for useful
discussions and feedback on earlier versions of this paper.
2. PRELIMINARIES
The purpose of this section is to recall some PCL notions
that are required to interpret the forthcoming sections. We
use the syntax from [14]. This partial summary of PCL is
incomplete, and we encourage the reader to use the original
papers for reference.
The structure of PCL is as follows: ﬁrst notation is in-
troduced to deﬁne terms, which in turn are used to deﬁne
protocols. For such protocols, an execution model is deﬁned,
assigning to each protocol a set of possible execution histo-
ries, called runs. Then, a protocol logic is deﬁned in order to
reason about (sets of) runs of a protocol. This logic is proven
sound with respect to the execution model. This means that
if one proves a property in terms of the protocol logic, such
as Receive(. . . , m), then a similar property should hold for
the corresponding set of runs in the execution model, such
as “receive . . . , m has occurred in the protocol run”. We
touch upon these elements below.
Protocols.
Terms. A term system is introduced that contains con-
stants (nonces, names, keys, etc.), variables, and compound
terms such as tuples, encryptions, and signatures.
In PCL, a protocol Q is deﬁned as a set
of roles. Each role ρ ∈ Q is deﬁned as a list of actions.
Examples of possible actions can be found in the actions
column of Table 1, and correspond respectively to sending
terms, receiving terms, generating fresh terms, encryption,
decryption, and signature veriﬁcation. Each role is parti-
tioned into a set of basic sequences. A basic sequence BSi
of a role ρ is a contiguous subsequence of ρ that starts with
either the ﬁrst action of ρ or a receive action, and of which
the other actions are not receive actions. The basic se-
quences intuitively represent the idea that agents only block
at receive actions, and execute all other actions immedi-
ately, allowing one to regard basic sequences as atomic ac-
tions in some respects. The notion of basic sequences there-
fore roughly corresponds to the notion of step-compression
in other models, e.g. [2]. The basic sequences of a protocol
are deﬁned as the union of the basic sequences of each of its
roles, and hence each action of a role of a protocol occurs in
exactly one of its basic sequences.
Observe that although some versions of PCL have two dis-
tinct actions receive (for reading a term from the network
without parsing) and match (for parsing a term and block-
ing if it is not as expected), these two actions are in many
proofs collapsed together into a single receive action that
receives and matches terms at the same time.
Execution model. An execution model is deﬁned for
protocols (in terms of cords). Actions are executed by agents,
with names like ˆX, ˆY . A subset of these agents, deﬁned as
HONEST(C) (where C is the initial conﬁguration of the sys-
tem), are called the honest agents, and execute their proto-
col roles as expected. The agents may execute each protocol
role any number of times; each such instance of a role is
called a thread (in other formalisms, this notion is known
as a strand, or a process, or a run). Threads are usually
denoted by symbols such as X, Y, Z: a sequence of actions
P executed within a thread X is written as [P ]X . The no-
tation ˆX is often1 used to denote the agent executing the
1The hat notation ˆ is used in at least two diﬀerent inter-
pretations in both [13] and [14]. In some cases X is used
to denote a particular thread, and ˆX is then interpreted as
the agent that executes that thread, as e.g. can be seen in
the usage of Y in the SEC axiom [14, page 327], replicated
here in Section 3.1. Thus, in one interpretation ˆ can be re-
garded as a function from a thread to an agent. However, in
other cases ˆX is used to denote a particular agent, and X is
then interpreted as “any thread executed by the agent ˆX”,
Action
send ˆX, ˆY , m
receive ˆX, ˆY , m
new x
enc m, K
dec t, K
verify t, m, K
Associated term Predicate
structure
(in thread X)
Send(X, m)
Receive(X, m)
Gen(X, x)
t = ENCK{| m|}
Encrypt(X, t)
t = ENCK{| m|} Decrypt(X, t)
t = SIGK{| m|}
Verify(X, t)
Has(X, m)
Honest( ˆX)
Contains(t, t(cid:48))
Table 1: Some examples of PCL actions, action
predicates, terms, and their relations. Here ˆX, ˆY de-
note agents, m, x, t, t(cid:48) denote terms, and X denotes a
thread.
thread X. Informally, if the agent ˆX is honest, [P ]X is a
sequence of actions from a protocol role. The agents that
are not part of HONEST(C) can execute so-called intruder
roles, in line with the common Dolev-Yao intruder model.
In the context of this execution model, the protocol descrip-