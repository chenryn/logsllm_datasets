edges removes all loops in the graph. After the conversion,
PROVDETECTOR relies on existing algorithm [44] to ﬁnd the
K longest paths on the DAG.
Fig. 4: Example causal paths from the provenance graphs in
Figure 2. We concretize the * with ﬁle names.
program loads a ﬁxed set of DLL ﬁles required during its initial
stage. This workload is universal to all its instances. On the
other hand, the instance-speciﬁc workloads, which are different
from instance to instance based on the inputs. We argue that
malicious workloads are more likely to be instance-speciﬁc.
Therefore, we propose to select causal paths that are
generated by the instance-speciﬁc workloads instead of those
paths generated by universal workloads. We determine whether
a path is generated from universal workloads or instance-
speciﬁc workloads by its rareness: more rare a path is, more
likely it is from the instance-speciﬁc workload.
a path λ = {e1, e2, . . . , en} is deﬁned as R(λ) =(cid:81)n
To discover the top K rarest paths, we use the regularity
score proposed in previous work [56]. The regularity score of
i=1 R(ei),
where R(ei) is the regularity score of event ei. In PROVDE-
TECTOR, the regularity score of an event e = {src → dst} is
deﬁned as:
|H(e)|
|H| IN (dst)
R(e) = OU T (src)
(1)
In Equation 1, H(e) is the set of hosts that event e happens
on while H is the set of all the hosts in the enterprise [73],
[56]. To calculate IN and OU T for a node v, PROVDE-
TECTOR partitions the training data into n time windows
T = {t1, t2, . . . , tn}. We say ti
is in-stable if no new in
edges are added to v during ti. Similarly, ti is out-stable if
no new out edges are added to v during ti. Then the IN (v)
6
ProcessProvenance TrackingProvenanceDatabaseFrequencyDatabaseGraph BuildingRepresentationExtractionEmbeddingAnomalyDetectionpredictionpredictionpredictionpredictionProvDetectorFinalDecisionConﬁguration(pid, host)winword.exet1.txt168.x.x.xoutlook.exewinword.execmd.exepowershell.exewriteread_bywritex.x.x.xwritestartstartwinword.exef1.docwritewinword.exef2.docwriteB1B2M1M2D. Embedding
After we select the top K rarest paths as features, the next
question is how to feed the paths to anomaly detection models.
There are several challenges: (1) the lengths of causal paths are
different, and (2) the labels of nodes and edges are unstructured
data such as ﬁle names or executable paths.
Intuition With the background on word and document em-
beddings presented in §A, an important intuition we have is
to view a causal path as a sentence/document: the nodes and
edges in the path are words that compose the “sentence” which
describes a program behavior. In other words, different nodes
and edges compose paths in a similar way that different words
compose sentences. Based on this intuition, we could treat each
node as a “noun”, treat each edge as a “verb”, and use their
labels to form a sentence that represents the path. For example,
for the path B1 in Figure 4, it can be directly mapped to
the following sentence: Process:winword.exe write File:t1.txt
read by Process:outlook.exe write Socket:168.x.x.x.
translated to a
Embeddings Learning
To learn an embedding vector for
a causal path, we can leverage the document embeddings
model with the path as a sentence. Formally, a causal
path λ can be
sequence of words
{l(ei.src), l(ei), l(ei.dst), . . . , l(en.src), l(en), l(en.dst)},
where l is a function to get the text representation of a node
or an edge. Currently, we represent a process node by its
executable path, a ﬁle node by its ﬁle path, and a socket node
by its source or destination IP and port; we represent an edge
by its relation.
With the translated sentences, PROVDETECTOR uses the
PV-DM model (explained in Appendix A) of doc2vec [69]
to learn the embedding of paths. This method has several
advantages. First, it is a self-supervised method, which means
we can learn the encoder with purely benign data. Second, it
projects the paths to the numerical vector space so that similar
paths are closer (e.g., B2 and M2 in Figure 4) while different
paths are far away (e.g., B1 and M1 in Figure 4). This allows
us to apply other distance based novelty detection methods
in the next step. Third, it also considers the order of words,
which is also important. For example, a cmd.exe starting a
winword.exe is likely benign while a winword.exe starting
a cmd.exe is often malicious.
E. Anomaly Detection
The ﬁnal step of PROVDETECTOR is to use a novelty
detection method to detect if the embedding of a path is
abnormal. Our design of the anomaly detector is based on
the nature of the provenance data. In our observation, prove-
nance data has two important features. First, they cannot be
modeled by a single probability distribution model. Modern
computer systems and programs are complex and dynamic,
it
the behaviors of programs with
a mathematical distribution model. Second, provenance data
have multiple clusters. Workloads of a program can be very
different. Although provenance data from similar workloads
may look similar, they will be very different if they are from
two distinct workloads. Thus, it is very hard to use a single
curve to separate normal and abnormal provenance data in the
embedding space.
is very hard to model
Based on the features of provenance data, PROVDETECTOR
uses Local Outlier Factor (LOF) [11] as the novelty detection
model. LOF is a density based method. A point is considered
as an outlier if it has lower local density than its neighbors.
LOF does not make any assumption on the probability distri-
bution of data nor separates the data with a single curve. Thus,
it is an appropriate method for our novelty detection problem.
Final Decision Making
In the detection phase, we use the
built novelty detection model to make predictions of path
embedding vectors of a provenance graph. We then use a
threshold-based method, i.e., if more than t embedding vectors
are predicted as malicious we treat
the provenance graph
as malicious, to make the ﬁnal decision about whether the
provenance graph is benign or malicious. This method could
enable an early stop in the path selection process to reduce
detection overhead when the top t instead of K selected paths
are already predicted as malicious.
F.
Implementation
While PROVDETECTOR takes inputs from both Linux and
Windows hosts, our evaluation focuses on Windows event, as
our benign deployment mainly comprise of Windows host and
most stealthy malware runs for Windows target. We implement
the provenance data collector of PROVDETECTOR which stores
data in a PostgreSQL database using the Windows ETW frame-
work [8] and Linux Audit framework [16]. The provenance
graph builder and the representation extractor are implemented
using about 15K lines of Java code, with the same method
proposed by King et al. [63] and our causal path selection
algorithm in §V-C. The rest parts of PROVDETECTOR, such as
embedding and anomaly detection, are implemented in Python.
We use the K = 20 selected paths as the representation
for a provenance graph. We then train a PV-DM model
as discussed in §V-D using the Gensim library [10], which
embeds each path into a 100 dimensional embedding vector,
which is the default option of Gensim. Finally, we use the
embedding vectors to train a novelty detection model using
the Local Outlier Factor (LOF) algorithm in Scikit-learn [14].
Provenance Data Preprocessing
Provenance data collected
from different hosts may contain host-speciﬁc or entity-speciﬁc
information such as ﬁle paths. To remove such information,
we follow the abstraction rules that are similar to previous
works [56], [73], [55]:
• Path Abstraction. Process entity and ﬁle entity have
such as process executable
path related attributes
path and ﬁle path. We abstract
these paths by re-
moving user speciﬁc details. For example the path
C:/USERS/USER_NAME/DESKTOP/PAPER.DOC will be
changed to *:/USERS/*/DESKTOP/PAPER.DOC, where
the user name and the root location are abstracted.
• Socket Connection Abstraction. A socket connection has
two parts: the source part (IP and port) and the destination
part (IP and port). As the IP of a host is a speciﬁc
ﬁeld only to the host, we abstract a socket connection by
removing the internal address while keeping the external
address. More speciﬁcally, we remove the source part of
an outgoing connection and the destination part of an
incoming connection.
7
VI. EVALUATION
To evaluate the efﬁcacy of PROVDETECTOR, we seek for
answers to the following research questions:
RQ1: How effective is PROVDETECTOR in detecting stealthy
RQ2: What makes PROVDETECTOR capable of detecting
malware? What is the detection accuracy? (§VI-B)
stealthy malware? (§VI-C)
to build its models and to perform detection? (§VI-D)
RQ3: What is the computational overhead of PROVDETECTOR
A. Experiment Protocol
We answer the above three research questions with real
stealthy malware instances gained by running malware sam-
ples and benign process instances gained from a real-world
enterprise deployment. To collect benign provenance data, we
installed the provenance data collector to 306 Windows hosts
in an enterprise. The benign provenance data was collected
over three months and stored in a PostgreSQL database.
To collect provenance data for stealthy malware, we down-
loaded about 15,000 malware samples from VirusShare [18]
and VirusSign [19] and executed them in the Cuckoo sand-
box [7]. Regarding the sandbox conﬁguration, we prepared
the same operating system (OS) and application environment
as it is conﬁgured for the enterprise. Among the malicious
execution instances, whose behaviors were triggered and cap-
tured by our sandbox, we identiﬁed 23 victim programs. These
victims are benign programs used in the enterprise, whose
behaviors are captured in the benign provenance dataset. The
23 hijacked victims include popular Windows applications
such as IE Browser and Microsoft Word, and preinstalled
system tools such as the Windows Certiﬁcate Services Tool.
Table II shows the complete list.
In preparation of the dataset for model building, we chose
250 benign process instances and 50 malicious process in-
stances for each of the 23 programs observed from both the
benign and malicious environment. For each program, we ran-
domly chose benign instances from the enterprise environment,
whereas we generated corresponding malicious instances by
running one distinct stealthy malware. In other words, we
executed 50 distinct malware
for each of the 23 programs
to generate malicious data. Since our approach is an anomaly
detection technique, which only needs benign data for training,
we randomly selected 200 benign instances as the training
dataset and used the rest 50 benign instances and all the
malicious instances as the testing input. In total, we evaluated
PROVDETECTOR with 1,150 distinct malware samples that
hijacks benign processes. These malware samples are classiﬁed
into 189 malware families with AVClass [94]. Among the
malware samples2, 298 of them are identiﬁed to be anti-VM
(i.e., detecting if it is in a virtual machine) and 238 of them
are identiﬁed to be anti-debug (i.e., detecting if it is under
debugger) by VirusTotal [22] or Tencent HABO [17].
We trained PROVDETECTOR on a machine with an Intel
Core i7-6700 Quad-Core Processor (3.4 GHz) and 32 GB
RAM running Ubuntu 16.04 OS; detection was also performed
on the same machine.
2We list the MD5 value of a malware, whether it is anti-VM, whether it is
anti-debug and its AVClass label at https://github.com/share-we/malware.
8
Removal of Biases Due to Sandbox Although we use real
stealthy malware, the Cuckoo sandbox may introduce bias in
our experiment. The workﬂow of how Cuckoo runs a stealthy
malware is as follows: (1) the Cuckoo agent introduces a mali-
cious payload (malware executable or malicious document) to
the sandbox, (2) the initial payload injects malicious logic into
a target benign program via various channels, (3) the injected
malicious logic in the victim process executes. The ﬁrst part of
the workﬂow leaves a unique pattern in the provenance graphs
due to the Cuckoo agent: every attack path in the provenance
graph either starts with the agent process or the malicious
payload. This pattern could introduce a bias to our experiment
as the model can simply just remember the agent process or
the malicious payload to predict whether a path is from a
hijacked process. To eliminate such a bias, for all the malicious
provenance graphs, we only use the sub-graph generated after
the malicious payload has been loaded. In other words, we
remove the event of loading the malicious payload and all other
dependency events that happen before it. This pre-processing
eliminates all the features related to the Cuckoo framework.
To ensure that the generated provenance graphs do not have
any bias, we examined the distribution of the embeddings of
the paths generated from the benign workloads in the Cuckoo
and conﬁrmed that they follow the same distribution as our
training data.
B. Detection Accuracy
To answer research question RQ1, we measure the detec-
tion accuracy for the 23 programs. To further evaluate the
effectiveness of our proposed techniques, we also compare our
embedding and anomaly detection methods to other baseline
approaches.
In our experiments, we select
the top 20 causal paths
from each provenance graph using our path selection algorithm
(§V-C1). Then, we measure both path-level detection accuracy
and graph-level detection accuracy. To measure the path-level
detection accuracy, we treat each path as an individual data
sample; for the graph-level detection accuracy, we use the
threshold-based method (§V-E) to make a ﬁnal prediction
from the predictions of paths. The detection accuracy of
PROVDETECTOR is measured using precision, recall, and F1-
score metrics.
We show the path-level detection results in Table II. The
detection accuracy of PROVDETECTOR is consistently high
across different programs. Precision ranges from 0.952 to
0.965, recall ranges from 0.965 to 1, and F1-score ranges from
0.961 to 0.982. We show the average graph-level detection
accuracy for the 23 programs using different threshold values
in Figure 5. Here the threshold value is the number of rarest
paths selected as in §V-C. As we can see, using a threshold
value of 3 or 4 already achieve very high precision and recall
(precision of 0.957 and 0.995 for the threshold 3 and 4,
respectively; recall of 1 for both of the threshold values 3
and 4). All these results show that PROVDETECTOR is very
effective in detecting stealthy malware.
1) Comparison with Strawman Detection Approaches:
To show the effectiveness of our machine learning-based
approach, we compare PROVDETECTOR with three strawman
techniques: the blacklist, the whitelist, and the anomaly score
based approach [56].
TABLE II: The path-level detection accuracy of PROVDETEC-
TOR.
Program
attrib
certutil
cmd
cscript
cvtres
excel
ﬁrefox
iexplore
javaw
jusched
maintservice
msiexec
mspaint
notepad
rar
sc
spoolsv
tasklist
taskmgr
wget