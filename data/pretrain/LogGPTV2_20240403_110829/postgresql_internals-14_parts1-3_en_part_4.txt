### The Operating System Cache and PostgreSQL

The operating system has its own cache, and PostgreSQL (almost) never bypasses the operating system mechanisms to use direct I/O. This results in a double caching effect. A PostgreSQL instance, managed by the `postmaster` process, includes background processes and shared memory, such as the buffer cache and the operating system cache.

In the event of a failure, such as a power outage or an operating system crash, the data in the buffer cache is lost. The files that remain on disk have their pages written at different points in time. To restore data consistency, PostgreSQL maintains a write-ahead log (WAL) during its operation, which allows it to repeat lost operations when necessary.

### 1.3 Clients and the Client-Server Protocol

Another task of the `postmaster` process is to listen for incoming connections. When a new client appears, the `postmaster` spawns a separate backend process. The client establishes a connection and starts a session with this backend. The session continues until the client disconnects or the connection is lost.

The server must spawn a separate backend for each client, which can become problematic if many clients are trying to connect:

- Each process needs to cache catalog tables, prepared statements, intermediate query results, and other data. The more connections are open, the more memory is required.
- If connections are short and frequent (a client performs a small query and disconnects), the cost of establishing a connection, spawning a new process, and performing local caching is unreasonably high.
- The more processes are started, the more time is required to scan their list, and this operation is performed very often. As a result, performance may decline as the number of clients grows.

This problem can be resolved by connection pooling, which limits the number of spawned backends. PostgreSQL does not have built-in connection pooling, so third-party solutions like PgBouncer or Odyssey are used. This approach usually means that each server backend can execute transactions of different clients, one after another, imposing some restrictions on application development since only resources local to a transaction, not the whole session, can be used.

To communicate, a client and a server must use the same interfacing protocol, typically based on the standard `libpq` library, though there are other custom implementations. In general terms, the protocol allows clients to connect to the server and execute queries.

A connection is always established to a particular database on behalf of a specific role or user. Although the server supports a database cluster, a separate connection must be established for each database you wish to use in your application. At this point, authentication is performed: the backend process verifies the user's identity (e.g., by asking for a password) and checks whether the user has the right to connect to the server and the specified database.

Queries are passed to the backend process as text strings. The process parses the text, optimizes the query, executes it, and returns the result to the client.

### 2. Isolation and MVCC

#### 2.1 Consistency

The key feature of relational databases is their ability to ensure data consistency, i.e., data correctness. At the database level, integrity constraints such as primary keys or foreign keys can be created, and the database system ensures that these constraints are never broken, maintaining data integrity.

If all the required constraints could be formulated at the database level, consistency would be guaranteed. However, some conditions are too complex, touching upon several tables at once. Even if a constraint can be defined in the database but is not, it does not mean that the constraint can be violated.

Thus, data consistency is stricter than integrity, but the database system has no idea what "consistency" actually means. If an application breaks it without breaking the integrity, the database system cannot detect it. Consequently, it is the application that must define the criteria for data consistency, and we must trust that it is written correctly and will never have errors.

Even if the application always executes only correct sequences of operations, a correct sequence can temporarily break data consistency, which is normal. A classic example is a transfer of funds from one account to another. A consistency rule might state that a money transfer must never change the total balance of the affected accounts. This rule is difficult to formulate as an integrity constraint in PostgreSQL, so let's assume it is defined at the application level and remains opaque to the database system.

A transfer consists of two operations: the first draws money from one account, and the second adds this sum to another account. The first operation breaks data consistency, while the second restores it. If the first operation succeeds but the second fails due to some issue, data consistency will be broken. Such situations are unacceptable, but they can be completely solved by the database system if it knows that these two operations constitute an indivisible whole, i.e., a transaction.

However, there is a more subtle aspect. Transactions that are correct on their own can start operating incorrectly when run in parallel. This is because operations belonging to different transactions often get intermixed. There would be no such issues if the database system completed all operations of one transaction before moving to the next, but the performance of sequential execution would be implausibly low.

True simultaneous execution of transactions can only be achieved on systems with suitable hardware, such as a multi-core processor and a disk array. For generalization purposes, both these situations are sometimes referred to as concurrent execution.

Correct transactions that behave incorrectly when run together result in concurrency anomalies or phenomena. For example, to get consistent data from the database, the application must not see any changes made by other uncommitted transactions. Otherwise, if some transactions are rolled back, it would see a database state that has never existed. Such an anomaly is called a dirty read. There are many other anomalies, which are more complex.

When running transactions concurrently, the database must guarantee that the result of such execution will be the same as the outcome of one of the possible sequential executions. In other words, it must isolate transactions from one another, thus taking care of any possible anomalies.

In summary, a transaction is a set of operations that takes the database from one correct state to another correct state (consistency), provided that it is executed in full (atomicity) and without being affected by other transactions (isolation). This definition combines the requirements implied by the first three letters of the ACID acronym. The durability requirement is also intertwined: after a crash, the system may still contain some changes made by uncommitted transactions, and you have to do something to restore data consistency.

Thus, the database system helps the application maintain data consistency by taking transaction boundaries into account, even though it has no idea about the implied consistency rules. Unfortunately, full isolation is hard to implement and can negatively affect performance. Most real-life systems use weaker isolation levels, which prevent some anomalies but not all. This means that the job of maintaining data consistency partially falls on the application. It is crucial to understand which isolation level is used in the system, what is guaranteed at this level, and how to ensure that your code will be correct under such conditions.

#### 2.2 Isolation Levels and Anomalies Defined by the SQL Standard

The SQL standard specifies four isolation levels, defined by the list of anomalies that may or may not occur during concurrent transaction execution. Therefore, when discussing isolation levels, we must start with anomalies.

It is important to note that the standard is a theoretical construct that affects practice, but practice still diverges from it in many ways. All examples here are rather hypothetical. For instance, dealing with transactions on bank accounts, these examples are self-explanatory, but they have nothing to do with real banking operations.

Interestingly, the actual database theory also diverges from the standard, as it was developed after the standard was adopted, and practice was already well ahead.

**Lost Update**

The lost update anomaly occurs when two transactions read the same table row, then one transaction updates this row, and finally, the other transaction updates the same row without taking into account any changes made by the first transaction. For example, if two transactions are going to increase the balance of the same account by $100, and both read the current value ($500), the first transaction increases the balance to $600 and writes the new value. The second transaction does the same, resulting in the customer losing $100. Lost updates are forbidden by the standard at all isolation levels.

**Dirty Reads and Read Uncommitted**

The dirty read anomaly occurs when a transaction reads uncommitted changes made by another transaction. For example, if the first transaction transfers $100 to an empty account but does not commit this change, and another transaction reads the updated but uncommitted state, allowing the customer to withdraw the money, even though the first transaction gets interrupted and its changes are rolled back, leaving the account empty. The standard allows dirty reads at the Read Uncommitted level.

**Non-Repeatable Reads and Read Committed**

The non-repeatable read anomaly occurs when a transaction reads the same row twice, and another transaction updates (or deletes) this row between the reads and commits the change. For example, if there is a consistency rule that forbids having a negative balance in bank accounts, and the first transaction is going to reduce the account balance by $100, it checks the current value, gets $200, and decides that this operation is possible. Meanwhile, another transaction withdraws all the money from this account and commits the changes. If the first transaction checked the balance again, it would get $0, but the decision to withdraw the money is already taken, causing an overdraft. The standard allows non-repeatable reads at the Read Uncommitted and Read Committed levels.

**Phantom Reads and Repeatable Read**

The phantom read anomaly occurs when the same transaction executes two identical queries returning a set of rows that satisfy a particular condition, while another transaction adds some other rows satisfying this condition and commits the changes in the time interval between these queries. For example, if there is a consistency rule that forbids a customer to have more than three accounts, and the first transaction is going to open a new account, it checks how many accounts are currently available (let’s say there are two), and decides that this operation is possible. At this moment, the second transaction also opens a new account for this client and commits the changes. If the first transaction double-checked the number of open accounts, it would get three, but it is already opening another account, and the client ends up having four. The standard allows phantom reads at the Read Uncommitted, Read Committed, and Repeatable Read isolation levels.

**No Anomalies and Serializable**

The standard also defines the Serializable level, which does not allow any anomalies. It is not the same as the ban on lost updates and dirty, non-repeatable, and phantom reads. In fact, there are many known anomalies beyond those specified by the standard, and an unknown number of still unknown ones. The Serializable level must prevent any anomalies, meaning the application developer does not have to take isolation into account. If transactions execute correct operator sequences when run on their own, concurrent execution cannot break data consistency either.

To illustrate this idea, the following table is provided in the standard; the last column is added here for clarity:

| Level            | Lost Update | Dirty Read | Non-Repeatable Read | Phantom Read | Other Anomalies |
|------------------|-------------|------------|---------------------|--------------|-----------------|
| Read Uncommitted | No          | Yes        | Yes                 | Yes          | Yes             |
| Read Committed   | No          | No         | Yes                 | Yes          | Yes             |
| Repeatable Read  | No          | No         | No                  | Yes          | Yes             |
| Serializable     | No          | No         | No                  | No           | No              |

**Why These Anomalies?**

Of all the possible anomalies, why does the standard mention only some, and why exactly these ones? No one seems to know for sure. It is likely that other anomalies were simply not considered when the first versions of the standard were adopted, as theory was far behind practice at that time. Additionally, it was assumed that isolation had to be based on locks. The widely used two-phase locking protocol (2PL) requires transactions to lock the affected rows during execution and release the locks upon completion. In simplistic terms, the more locks a transaction acquires, the better it is isolated from other transactions, but the worse the system performance, as transactions start queuing to access the same rows instead of running concurrently.

I believe that to a great extent, the difference between the standard isolation levels is defined by the number of locks required for their implementation. If the rows to be updated are locked for writes but not for reads, we get the Read Uncommitted isolation level, which allows reading data before it is committed. If the rows to be updated are locked for both reads and writes, we get the Read Committed level, where it is forbidden to read uncommitted data, but a query can return different values if it is run more than once (non-repeatable reads).

Locking the rows to be read and to be updated for all operations gives us the Repeatable Read level, where a repeated query will return the same result. However, the Serializable level poses a problem: it is impossible to lock a row that does not exist yet, leaving an opportunity for phantom reads to occur. Thus, regular locks cannot provide full isolation; to achieve it, we have to lock conditions (predicates) rather than rows. Such predicate locks were introduced early in the development of System R, but their practical applicability is limited to simple conditions for which it is clear whether two different predicates may conflict. As far as I know, predicate locks in their intended form have never been implemented in any system.

#### 2.3 Isolation Levels in PostgreSQL

Over time, lock-based protocols for transaction management have been replaced with the Snapshot Isolation (SI) protocol. The idea behind this approach is that each transaction accesses a consistent snapshot of data as it appeared at a particular point in time. The snapshot includes all the current changes committed before the snapshot was taken.

Snapshot isolation minimizes the number of required locks. In fact, a row will be locked only by concurrent update attempts. In all other cases, operations can be executed concurrently: writes never lock reads, and reads never lock anything.

PostgreSQL uses a multiversion flavor of the SI protocol. Multiversion concurrency control implies that at any moment, the database system can contain several versions of the same row, so PostgreSQL can include an appropriate version into the snapshot rather than abort transactions that attempt to read stale data.

Based on snapshots, PostgreSQL isolation differs from the requirements specified in the standard—in fact, it is even stricter. Dirty reads are forbidden by design. Technically, you can specify the Read Uncommitted level, but its behavior will be the same as that of Read Committed, so I will not mention this level anymore.

The Repeatable Read level in PostgreSQL allows neither non-repeatable nor phantom reads (even though it does not guarantee full isolation). However, there is a risk of losing changes at the Read Committed level.

| Level            | Lost Update | Dirty Read | Non-Repeatable Read | Phantom Read | Other Anomalies |
|------------------|-------------|------------|---------------------|--------------|-----------------|
| Read Uncommitted | No          | Yes        | Yes                 | Yes          | Yes             |
| Read Committed   | No          | No         | Yes                 | Yes          | Yes             |
| Repeatable Read  | No          | No         | No                  | No           | No              |
| Serializable     | No          | No         | No                  | No           | No              |