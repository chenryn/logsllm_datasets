fake (cid:128)ngerprint in PVA glue or gelatin [24, 39]. Interestingly, it was
possible to use a scanned image of the (cid:128)ngerprint impressed on
a touch screen to make a mold and cast a fake (cid:128)ngerprint in PVA
glue [34]. Finally, it was also possible to use conductive ink to spoof
a (cid:128)ngerprint by printing the scanned image in a 2D printer [6].
(cid:140)ey showed how to deceive touch sensors employed in recent
smartphones but required a (cid:128)rm impression of a (cid:128)ngerprint.
3 OUR ATTACK TECHNIQUES
3.1 Overview
(cid:135)reat Model. Our threat model is derived from the well-known
threat model of smudge a(cid:138)acks [2], and is based on the strong (cid:128)eld
evidence of (cid:128)ngerprint spoo(cid:128)ng a(cid:138)acks [6, 34]. (cid:140)at is, a user leaves
lots of oily smudges on the smartphone surface due to various daily
tasks and touch activities while an a(cid:138)acker wants to “repeatedly”
unlock the victim’s smartphone to access con(cid:128)dential/private data,
make mobile payments, and so on. Obviously, the a(cid:138)acker wants
to unlock the victim’s smartphone within (cid:128)ve (or more1 if allowed)
a(cid:138)empts through the touch sensor because otherwise she has to
guess a pin or password within a few more a(cid:138)empts. (cid:140)us, it would
be more reasonable for us to assume an active adversary who has
physical control of the device than a passive adversary who operates
only at a distance. We assume that the a(cid:138)acker (1) has a victim’s
smartphone at least in temporary possession, and is capable of (2)
controlling the lighting and camera conditions for photography, and
(3) forging a fake (cid:128)nger, e.g., using a gelatin or conductive material,
once an image of the (cid:128)ngerprint is obtained in good quality [6, 34].
(cid:140)e above assumption is realistic because a great number of
smartphones are actually stolen and/or lost over the world. For
instance, according to a survey conducted by Consumer Report
in America [32], more than 3 million American consumers were
stolen their smartphones in 2013. Many users can be targeted for
their smartphones. (cid:140)us, smartphone manufacturers provide (cid:128)le
and data encryption mechanisms but such protection mechanisms
are disarmed if the device is unlocked.
Attack Procedure. (cid:140)e main goal of our a(cid:138)ack is to construct a
good-quality image of the enrolled (cid:128)ngerprint for a small touch sensor,
only from the smudges remaining on a victim’s smartphone. Good
quality here means the image quality of the (cid:128)rm impression, which
is accepted to the small touch sensors. (cid:140)e key idea is to start with
the home bu(cid:138)on smudge and exploit touch screen smudges for
our goals. We implemented various so(cid:137)ware modules for semi-
automation of our a(cid:138)acks. (cid:140)e brief a(cid:138)ack procedure is as follows.
1. Photographic smudge collection: We set up a photographic envi-
ronment and take a picture of the smartphone surface. We use the
watershed algorithm for easier detection of the potential smudges,
and then take a close-up picture, only for the latent (cid:128)ngerprints.
(Section 3.2)
2. Fingerprint smudge matching: We pre-process the latent (cid:128)nger-
print images for gray-scale transformation and histogram equaliza-
tion, and then apply the SIFT descriptor-based brute-force matching
to the histogram equalized images. We also use MINDTCT for minu-
tiae detection. Based on the results, we select the latent (cid:128)ngerprint
image which was taken from touch screen and closest to the home
bu(cid:138)on image, and then perform the SIFT descriptor-based exact
matching for the images. (Section 3.3)
3. Image quality assessment: We utilize the SIFT keypoints for
damage identi(cid:128)cation, and assess image quality of the home bu(cid:138)on
image and the selected touch screen image based on the keypoint
distribution. According to the image quality, we then make a deci-
sion for a construction method: either combination or replacement.
(Section 3.4)
1In Galaxy S6 and S7 models, 37 a(cid:138)empts are allowed within the (cid:128)rst 24 hours.
5143.3 Fingerprint Smudge Matching
A(cid:137)er collecting latent (cid:128)ngerprint images H and Ti, we applied
image enhancement techniques, i.e., image preprocessing to achieve
more reliable image processing in the following steps. As shown
in Figure 3-2, we simply transformed H and Ti into gray-scale
(cid:104)0, 255(cid:105), and then applied histogram equalization to expand the
local contrast and change the intensity of each pixel according to
its local neighborhood [19, 20].
(cid:140)e latent (cid:128)ngerprint image, H, must be the cornerstone of our
a(cid:138)ack because it was found on the home bu(cid:138)on where a touch
sensor was installed. As shown in Figure 3-2-(a), however, H is
easily damaged when a user releases a (cid:128)nger or repeatedly presses
the home bu(cid:138)on. To compensate for damages, we need more latent
(cid:128)ngerprint images, such as Ti found on the touch screen. Although
Ti may be also damaged for the same reasons, our assumption is that
collection and matching of such partially damaged smudges may
introduce su(cid:129)cient information to reconstruct a latent (cid:128)ngerprint
image against the small touch sensors.
(cid:140)e matching step is required for H and Ti because it is necessary
to select Ti, which is the most closely correlated to H. For the
purpose, we conduct the SIFT descriptor-based 1:N brute-force
matching to the histogram equalized images, H and Ti (1 ≤ i ≤ N ).
Note that the SIFT descriptor-based matching is widely used to
extract distinctive invariant features from images, and it can be
used to perform reliable matching between di(cid:130)erent views of an
object or scene. We use the SIFT descriptor-based method to a(cid:138)empt
to match Ti images to H, and for the purpose we set L2 norm, which
is the Euclidean norm. Figure 4-(a) shows the lower 10% distribution
of the matching distance for SIFT-descriptors in H and Ti. Since
the lower distribution implies the be(cid:138)er matching, i.e., closer to H
than the others, we may see T1 as a good candidate for Ts, which
denotes the damage correction source image. We actually select the
image with the lowest median value, which is T1 in our example.
We also use MINDTCT for minutiae detection in the latent images.
Note that it is common to dismiss a (cid:128)ngerprint with less than 40
minutiae since a (cid:128)ngerprint typically has 40-80 minutiae [40].
Figure 3-2-(b) shows the selection table, in which T1 represents
the minimum distance (75.11) and the acceptable minutiae number
(52). Obviously, we select T1 and set as Ts. Finally, we obtain the
geometrics of the shortest match descriptors due to the minimum
distance as shown in Figure 4-(b). (cid:140)ey are descriptorH at (68,108)
and descriptorTs
at (107,93) in Figure 4-(b). We then perform the
SIFT descriptor-based exact matching and crop 250 × 250 area from
Ts based on this point. Readers are referred to Appendix C and
Figure 13 for more details.
3.4 Image (cid:134)ality Assessment
In this step, we perform image quality assessment for H and Ts in or-
der to complete our reconstruction procedure. Based on descriptorH
, as pointed with blue dots in Figure 3-3, we crop T (cid:48)
and descriptorTs
s
from Ts as follows. (cid:140)e x, y coordinates of the le(cid:137)most up and right-
most down points of H is (0, 0), (250, 250), respectively. We calculate
the relative x, y coordinates of the le(cid:137) up and right down points of H
(L home, R home, respectively) as in Algorithm 1. Based on L home
and R home, we (cid:128)nd the relative x, y coordinates of the le(cid:137)most up
and rightmost down of the partial (cid:128)ngerprint (L screen, R screen,
Figure 2: Latent (cid:128)ngerprint collection. (a), (b) Photographic
setup. Readers are referred to Figure 12 (Appendix B) for
setup details. (c) (cid:135)reshold image. (d) Watershed result.
4. Fingerprint image construction: If the touch screen image has
a be(cid:138)er quality, we proceed with the replacement method using
the complete part of the touch screen image. If the home bu(cid:138)on
image has a be(cid:138)er quality, we extract the portions of good quality
and combine them with the complementary portions of the touch
screen image. In the combination method, we post-process the
reconstructed image for quality improvement. (Section 3.5)
For veri(cid:128)cation, we make a comparison with an intentional (cid:128)rm
impression image which we call the template for its good quality.
We use the NBIS packages to measure minutiae quality, match
scores, and (cid:128)ngerprint image quality. (Section 3.6) In actual a(cid:138)acks,
an adversary may forge a fake (cid:128)nger for small touch sensors [6, 34]
if the reconstructed image was con(cid:128)gured in good quality. We also
explore the possibility of actual forgery in our follow-up work [26].
3.2 Photographic Smudge Collection
Under the threat model, we set up a photographic environment and
take a picture of the smartphone surface. We adopt the environ-
mental setup investigated in [2] with slight modi(cid:128)cation. Readers
are referred to [2] for more details of the setup reasoning, and
also Appendix B and Figure 12 for our se(cid:138)ing details. As shown in
Figure 2-(a), (b), we used Canon EOS 700D DSLR camera (EF-S 18-
55mm F3.5-5.6 IS STM lens, 1920×1280, sRGB) in close-up mode to
photograph iPhone 6 (black color model). We used Jupiter tungsten
light (3200K) for lighting control in the closed room.
For latent (cid:128)ngerprint collection, we took a picture of the whole
surface of the smartphone and used our so(cid:137)ware module for easier
detection of the latent (cid:128)ngerprints. We used Otsu’s thresholding
to segment foreground objects from background as shown in Fig-
ure 2-(c) and then the watershed algorithm [4] to detect the latent
(cid:128)ngerprints or similar objects. As shown in Figure 2-(d), 14 labels
were produced from the example of Figure 1. Among them, six
clusters of the labels were found. We then took a close-up picture,
only for the connected objects, and manually identi(cid:128)ed the latent
(cid:128)ngerprints le(cid:137) on the touch screen. (cid:140)e three resulting pictures
are shown in Figure 3-1-(b), (c), (d). We also took a close-up picture
of the home bu(cid:138)on, as shown in Figure 3-1-(a).
We denote the latent (cid:128)ngerprint image taken from the home
bu(cid:138)on as H, and N latent (cid:128)ngerprint images taken from the touch
screen as Ti for 1 ≤ i ≤ N . We manually cut o(cid:130) H in (cid:128)xed size
(250×250) as shown in Figure 3-(a), and each Ti according to the
corresponding object size as shown in Figure 3-(b), (c), (d).
515Figure 3: (cid:135)e SCRAP attack procedure. (a) Latent (cid:128)ngerprint image taken from home button. (b), (c), (d) Latent (cid:128)ngerprint
images taken from touch screen. Items 1-4 represent attack procedures. Items (i)-(viii) show processed images.
Figure 4: (a) Lower 10% distribution of matching distance for smudges Ti matched to smudge H. (cid:135)e lower the distance distri-
bution is, the better the matching is. (b) Minimum distance matching of H and T1. (c) SIFT keypoints distribution in H. (d) SIFT
keypoints distribution in T (cid:48)
s , which is cropped from T1. In (c),(d), the translucent grid illustrates a threshold, τ.
. We then crop T (cid:48)
s from Ts using these
respectively) to descriptorTs
coordinates as summarized in Algorithm 1. Figure 3-(i) and (ii) show
the same size in that sense. Note that in Ts, the outer part of T (cid:48)
s can
also be utilized for actual a(cid:138)acks a(cid:137)erward if more quali(cid:128)ed.
Subsequently, we conduct damage identi(cid:128)cation for quality as-
sessment of the images. Let us denote damaged area and undamaged
area of H as Hd and Hu, respectively. To detect and separate Hd,
our unique idea is to adopt the SIFT algorithm [29] which was ac-
tually used for image matching and selection. Note that SIFT could
robustly identify objects even among clu(cid:138)er and under partial oc-
clusion, because the SIFT feature descriptor is invariant to uniform
scaling, orientation, and partially invariant to a(cid:129)ne distortion and
illumination changes [29]. Note also that preprocessing algorithms
gradually enhance the input images, and thus we apply the SIFT al-
gorithm to the ((cid:128)rst preprocessed) gray-scale images. For example,
we can specify SIFT keypoints in H (250×250 pixels in gray-scale),
as tiny color circles indicate in Figure 3-(i).
We then divide the image into a 10×10 array of 25×25 (pixel)
image blocks (Bi, j where i, j ∈ 0, 1, ..., 9) as shown in Figure 3-(iii)
and (iv). Subsequently, we set a threshold value, τ, as the average
number of keypoints found in H and Ts in order to detect and
separate Hd. Saying, τ can be obtained as follows:
kH + kT (cid:48)
s
bH + bT (cid:48)
s
(1)
τ =
are the number of keypoints in H and T (cid:48)
s ,
whereas kH and kT (cid:48)
are the number of blocks in H and T (cid:48)
s ,
respectively. bH and bT (cid:48)
are 100.
respectively, i.e. bH and bT (cid:48)
If the number of keypoints in Bi, j is smaller than τ, we de(cid:128)ne
Bi, j ∈ Hd, and otherwise as an element of Bi, j ∈ Hu. For instance,
s
s
s
516s
, it is easy to replace H with T (cid:48)
τ = 10.625 (SD = 5.909) in Figure 4-(c), (d), and we used this value
to identify Hd (74) and Hu (26) as separated by the translucent grid.
We then proceed with image quality assessment and make a
decision for construction methods, i.e., between the complete re-
placement method and and the combination method as described
in the next subsection. Algorithm 2 shows the process of assess-
ing image quality and making a decision. Let nH and nT (cid:48)
denote
the number of blocks having more keypoints than τ in H and T (cid:48)
s ,
respectively. Let nH inner and bH inner represent the number of
Hu and Hd + Hu inside the home bu(cid:138)on, respectively. Readers are
referred to Appendix D and Figure 14 for more details of nH inner
and bH inner .
3.5 Fingerprint Image Construction
Finally, we perform the (cid:128)ngerprint image construction step as
shown in Figure 3-4. To deal with Hd, we have to conduct either
replacement or combination method according to the decision made
in the previous quality assessment step.
Replacement Method. (cid:140)e complete replacement method is based
on the trivial strategy of the SIFT descriptor-based exact matching.
Since we have exactly matched H and T (cid:48)
s based on descriptorH
and descriptorTs
s regardless of Hd.
Figure 3-(viii) shows the result of replacement. Note again that the
outer part of T (cid:48)
Combination Method. (cid:140)e combination method is more compli-
cated because we have to combine two di(cid:130)erent images, H and T (cid:48)
s ,
according to the quality assessment result. Based on descriptorH
and descriptorTs
, we have to directly replace Hd with the corre-
sponding partial blocks of T (cid:48)
s . For each block Bi, j in Hd, we perform
the following. First, to calculate the relative x, y coordinates of the
le(cid:137) up and right down points of Bi, j (L homei, j, R homei, j, respec-
tively) to descriptorsH , we use the x, y coordinates of the le(cid:137) up
and right down points of Bi, j (L(Bi, j), R(Bi, j), respectively). Based
on L homei, j and R homei, j, we (cid:128)nd the relative x, y coordinates of
the le(cid:137) up and right down blocks to descriptorTs
s (L screeni, j,
R screeni, j, respectively). We replace Bi, j using the Overlap func-
tion as described in Algorithm 3 and output H(cid:48). We then apply
the CLAHE algorithm for histogram equalization of each block in
H(cid:48) because of combining two di(cid:130)erent images [46]. H(cid:48) is divided
into small blocks called “tiles” (8 × 8 by default in OpenCV), and
then each block is histogram-equalized. (cid:140)e conceptual images are
shown in Figure 3-(v) and (vi) for combination and in Figure 3-(vii)