title:Signal anomaly based attack detection in wireless sensor networks
author:Jeton Bacaj and
Leon Reznik
IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATION
1
Anomaly Detection in Wireless Sensor
Networks in a Non-Stationary Environment
Colin O’Reilly, Member, IEEE, Alexander Gluhak, Muhammad Ali Imran, Senior Member, IEEE, and
Sutharshan Rajasegarar, Member, IEEE
Abstract—Anomaly detection in a wireless sensor network
(WSN) is an important aspect of data analysis in order to
identify data items that signiﬁcantly differ from normal data.
A characteristic of the data generated by a WSN is that the
data distribution may alter over the lifetime of the network
due to the changing nature of the phenomenon being observed.
Anomaly detection techniques must be able to adapt to a non-
stationary data distribution in order to perform optimally. In
this survey, we provide a comprehensive overview of approaches
to anomaly detection in a WSN and their operation in a non-
stationary environment.
Index Terms—Wireless sensor networks, anomaly detection,
outlier detection, non-stationary, concept drift, distributed com-
puting
I. INTRODUCTION
L ARGE scale monitoring applications such as smart city
realisations [1], environmental monitoring [2], [3], indus-
trial monitoring [4], internal building monitoring [5], [6] and
surveillance [7], [8] provide valuable information for intelli-
gent decision making and smart living. However, collecting
data from such applications can pose a signiﬁcant challenge
due to the size and location of the monitored area, the envi-
ronmental conditions and the deployment timescale. WSNs
provide a platform for solving this monitoring challenge,
which are low cost, easy to deploy, and require little or no
maintenance during the lifetime of the network.
A WSN is formed using interconnected nodes that auto-
matically conﬁgure themselves. There are three important
elements that characterize a WSN node, namely one or
more sensors, a processing unit and a transceiver. Sensors
in the node allow the measurement of parameters of the
physical surroundings. A microprocessor allows intelligent
computation to be performed on the node, and a wireless
radio receiver enables communication among the neighbouring
nodes. Wireless communication between neighbouring nodes
allows the automatic formation of a network without the need
for a costly wired infrastructure. The sensor nodes in a WSN
are resource constrained, including limited processing and
Manuscript received August 13, 2012; revised March 7, 2013 and Septem-
ber 12, 2013. We acknowledge the support from the REDUCE project grant
(No. EP/I000232/1) under the Digital Economy Programme run by Research
Councils UK – A cross-council initiative led by EPSRC.
C. O’Reilly, A. Gluhak and M. A. Imran are with the Centre for Commu-
nication Systems Research, University of Surrey, Guildford, United Kingdom
(e-mail: {c.oreilly, a.gluhak, m.imran}@surrey.ac.uk).
S. Rajasegarar
is with the Department of Electrical and Electronic
Engineering, University of Melbourne, Melbourne, Australia (e-mail:
PI:EMAIL).
Digital Object Identiﬁer 10.1109/SURV.2013.112813.00168
1553-877X/13/$31.00 c(cid:2) 2013 IEEE
storage, limited energy resource, short communication range
and low bandwidth [9].
A key function of a WSN is the analysis of data that
is generated in the form of measurements by sensor nodes.
One objective of data analysis is anomaly detection. The
aim of anomaly detection is to identify data that do not
conform to the patterns exhibited by the majority of the
data set [10]. An anomaly or outlier (these terms are used
interchangeably in this paper) is deﬁned as “an observation
(or subset of observations) which appears to be inconsistent
with the remainder of that set of data” [11]. Algorithms that
perform anomaly detection construct a model using a set
of data measurements. The model is then used to classify
data as either normal or anomaly. Measurements collected
by sensors form a time-ordered sequence of data. During the
lifetime of data collection, the underlying phenomenon that
is being measured may alter. This will cause a change in the
distribution of the data and thus the data distribution will no
longer be a stationary data distribution but will be a non-
stationary data distribution. If a system has a stationary data
distribution then no temporal correlation exists as all data
are equally related and drawn independently and identically
distributed (i.i.d) from a stationary distribution. In this case,
the model of the data from which to identify anomalies only
needs to be constructed once. For optimal performance, the
model should be constructed after enough data are available
in order to have a good generalization error on the testing data
set. In an environment with a non-stationary data distribution,
it is necessary to construct a new model at certain intervals
in order to account for changes in the data distribution. An
assumption is made that the data are temporally correlated,
with correlation increasing as temporal distance decreases.
Therefore, in order to achieve the best generalization error, the
training set needs to be formed from data that are temporally
close to the data that will form the testing set.
Previous surveys on anomaly detection techniques have
focused on data sets where the underlying data distribution
is assumed to be stationary. These surveys have detailed the
usage of statistical or machine learning techniques that are
used to identify anomalies. Chandola et al. [10] survey the
application domains in which anomaly detection is applied,
and the statistical and machine learning techniques that are
used to detect anomalies. Anomaly detection in the speciﬁc ap-
plication domain of WSNs has been surveyed by Rajasegarar
et al. [12], [13] and Zhang et al. [14] where the focus is on
anomaly detection techniques that operate within the resource
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.2
IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATION
constraints and distributed architecture of a WSN. Anomaly
detection in WSNs from the perspective of security is surveyed
by Xie et al. [15].
This survey takes a different view of current state-of-the-art
anomaly detection techniques in WSNs. We examine anomaly
detection from the perspective of operation within a non-
stationary environment. In many application domains normal
behaviour can evolve,
therefore current normal behaviour
might not be sufﬁciently representative of future normal
behaviour [10]. We believe that this is the ﬁrst survey that
analyses the operation of anomaly detection algorithms in
a non-stationary environment. State-of-the-art algorithms are
surveyed and techniques are examined which are able to
identify changes in the data distribution and update a model
to include new information and remove old information. Our
survey aims to highlight current approaches to the problem,
point out areas which are lacking, and recommend areas for
future research.
The remainder of this paper is organized as follows. Section
II gives the fundamental characteristics of anomaly detection
in a WSN. Section III discusses non-stationary distributions
of data and its effect on anomaly detection. Section IV
presents a taxonomy for the classiﬁcation of techniques and a
workﬂow of their operation. Section IV also presents methods
to evaluate anomaly detection techniques. Section V discusses
change detection. Section VI and VII survey the update to a
model. Section VIII provides a discussion on the shortcomings
of current research and recommends areas for future research.
Section IX concludes this paper.
II. FUNDAMENTALS OF ANOMALY DETECTION IN
WIRELESS SENSOR NETWORKS
This section presents the fundamental characteristics of
WSNs and anomaly detection in WSNs. The environment
in which a WSN is deployed is discussed. In addition, the
characteristics of data and deﬁnitions of anomalies in WSN
data are provided.
A. The Environment of the WSN
WSNs may be deployed in harsh, unattended environments
for signiﬁcant periods of time where it is impossible to carry
out maintenance on the nodes after installation. Therefore it is
important that algorithms deployed on sensor nodes are self-
managing and can adapt to changing environments.
The constrained environment of a WSN impacts on anomaly
detection algorithms. Node constraints on computational
power and memory mean that algorithms for anomaly detec-
tion should have low computational complexity and occupy
little memory space. In addition, there are constrained energy
resources on the wireless sensor node and this impacts on
communication between nodes. The use of the wireless radio
receiver consumes signiﬁcantly more energy than any other
component on the sensor node. Pottie and Kaiser [16] state
that the cost of transmitting 1Kb a distance of 100 metres has
the same energy cost as performing 3 million instructions on a
general-purpose processor. In general, the cost of receiving is
comparable to the cost of transmitting. Thus there is a require-
ment to minimize the number and length of transmissions in
order to conserve energy.
B. Correlation of Data
In order to ensure satisfactory coverage of a monitored
area, a spatially dense deployment is required [17], [18]. This
deployment leads to multiple nodes sensing the same event.
This causes data on the nodes to have the same underlying
data distribution and thus spatial correlation exists.
In addition to spatial correlation, temporal correlation of
data can occur. Temporal correlation arises when there exists
a predictable relationship between sequential data points.
Data measurements on an individual node can be temporally
correlated due to the nature of the phenomenon that is being
observed; for example, temperature measurements may exhibit
a predictable rising and falling pattern each day.
Finally, spatial-temporal correlation of data can occur in
WSNs where data collected on different nodes and at different
times exhibit a predictable relationship. In a densely deployed
WSN there will be correlation of data if a set of nodes within
spatial proximity are measuring the same phenomenon.
The spatial, temporal and spatial-temporal correlation of
data can be exploited to identify an anomaly and determine
its cause. Anomalies caused by errors occur independently,
whereas anomalies caused by events exhibit spatial and/or
temporal correlation. Vuran et al. [19] study these correlations
in order to utilize them to reduce energy consumption in a
WSN. The spatial correlation of data can lead to a distributed
learning structure where information describing the data one
node is experiencing can be communicated to other nodes
for them to incorporate into their models of data. The spatial
correlation of data ensures that experiences of one node might
be similar to that of other nodes and hence it
is useful
for nodes to share identiﬁed characteristics of the data. The
temporal correlation of data can require that more recent data
are used to construct models to classify current data as the
correlation between data measurements can decrease as a
function of time.
C. Distributed Learning in a WSN
In WSNs, data are gathered at nodes which are dispersed in
a physical environment but connected through the medium of
a wireless interface and a routing protocol. Individual sensor
nodes measure local environmental conditions, and therefore
data are dispersed across the network. The aim of anomaly
detection is to identify the outliers in the data sets on the
individual nodes. If the assumption is made that
there is
spatial correlation of data then information exchanged between
nodes may increase the accuracy in the detection of anomalies.
Learning in a distributed environment can be divided into three
distinct categories; local, distributed and central.
In the local learning approach, the model of the local data
is learned and only anomalies based on this local model can
be detected. This method avoids costly transmission of data
measurements or model data between nodes and thus can be
a more energy efﬁcient anomaly detection method. However,
each node obtains an independent classiﬁer and the spatial
correlation of data is not used. Events learned about in another
part of the network can not be recognized by the node unless
the node has also encountered them.
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.O’REILLY et al.: ANOMALY DETECTION IN WIRELESS SENSOR NETWORKS IN A NON-STATIONARY ENVIRONMENT
3
The centralized approach communicates all data to a gate-
way node. A model is constructed using all the data, and
anomalies are identiﬁed in the entire data set. This has the
advantage that the gateway node can be more powerful and can
therefore use more computationally complex anomaly detec-
tion algorithms on the data. However, the communication cost
in transmitting a local node’s data measurements to a central
node can be prohibitive. In addition, there are scalability issues
as the ratio of nodes to gateways increases. Finally, there has
been an increase in the timeframe for detection for online
algorithms due to the delay introduced by the transmission of
data to a central node.
Distributed learning attempts to limit
the transmissions
between nodes while building a model constructed from
information from a number of nodes within the network.
Nodes run local instances of an anomaly detection algorithm
in order to infer patterns from data measurements arriving at
the node from the sensors. Nodes then exchange information
about local models in order to build a global model that en-
compasses data from other nodes in the network. Summarized
information, which can take the form of model parameters
and/or anomalies, is transmitted as opposed to data. Therefore
there is a reduction in transmissions. However, an event on a
node can still inﬂuence model construction on another node.
Often there is a trade-off between local anomaly detection
and communication with other nodes in the network. The
more communication that occurs, the more the performance
of the algorithm tends to that of a centralized model with
improved global detection accuracy. The distributed model
can vary in its aim. Some algorithms aim to infer from data
in a neighbourhood of sensors and others aim to construct
a local model that tends towards the model that would have
been constructed by a centralized approach. Algorithms can
distribute information in a number of ways. There can be a
simple exchange of the mean value of a data set or more
resource intensive operations such as broadcasting anomalies
in order to determine how other models classify them. This
can lead to vast differences in the amount of transmissions
that occur, typically the most expensive energy operation for
a sensor node.
D. Anomaly Detection in WSNs
It is possible to view anomaly detection from two different
aspects which drives the manner in which anomalies are
identiﬁed. The ﬁrst aspect is data fault detection which seeks
to identify data points that have been generated in error. The
second aspect is novelty detection which seeks to identify
data instances that are indicative of a (possibly rare) event
of interest that needs to be analyzed further. Thus anomaly
detection can be aimed at identifying data faults, identifying
novel
identifying both and distinguishing
between the two.
instances, or at
Data faults are measurements that are inconsistent with the
nature of the phenomenon being observed [22]. Identifying
this type of error is important as they can cause data to be
added to the data set that does not correspond to the underlying
distribution. Anomalies inﬂuence the quality of the data that
are provided to anomaly detection algorithms. Data that in-
cludes anomalies can introduce skew or additional complexity
into the model. This causes difﬁculty in constructing a model
for the data. In addition, in a distributed environment where
data instances are transmitted between nodes, removing data
faults can save energy that otherwise would have been wasted
in their transmission.
Sharma et al. [22] studied sensor faults in WSNs and
showed that there was a large variation in the number of
faults occurring in real-world WSN implementations. Faults
ranged from less than 0.01% to 15–35%. Spatial and temporal
correlation among the faults was discovered in only one
implementation and this was due to the batteries in spatially
correlated nodes dying at approximately the same time.
is rare or not
Novel behaviour in a system is also a source of anomalies.
This can be seen as an event that
in the
normal range of activity and has not been incorporated into
the distribution of the data set. Yoon et al. [23] used anomalies
in data from a system monitoring pipelines in an oilﬁeld to
identify novel behaviour such as pipe blockage and leakage.
Further actions may be taken on data instances identiﬁed as
novel.
Anomalies can occur due to different causes. The phenom-
ena that is being monitored may have an unusual element
that causes the data generated to signiﬁcantly differ from
normal behaviour. In addition, a security threat can cause
anomalies to be generated. Intrusion detection is a technique
which monitors the behaviour of a system. The aim is to
differentiate normal from anomalous behaviour in order to
identify security threats such as a denial of service attack or
a node compromise [24]–[27].
Anomalies with different causes may have different charac-
teristics. However, it is useful to categorize anomalies based
on various properties. Properties include how much it differs
from normal data instances, the number of occurrences, and
the location of anomalies within the WSN. Rajasegarar et
al. [12], [20] emphasize the distributed nature of a WSN and
deﬁne anomalies based on their correlation with data on other
sensor nodes.
(cid:129) First Order Anomalies: Partial data measurements are
anomalous at a sensor node
(cid:129) Second Order Anomalies: All data measurements at a
sensor node are anomalous
(cid:129) Third Order Anomalies: Data from a set of sensor nodes
are anomalous
Fig. 1a displays ﬁrst, second and third order anomalies. We
consider 3 nodes in a larger sensor network. It is assumed that
the measurements at nodes 1, 2 and 3 should be in the region
of 0.6, 0.4 and 0.2 respectively. This occurs in the ﬁrst 20 time
periods. Sensor node 1 displays a ﬁrst order anomaly from
time period 20 to 30 when there are a number of anomalous
readings, whereas the other two sensor nodes display normal
data. From time period 65 to 100, the data measurements
from sensor node 1 are anomalous. These are second order
anomalies where all data at the node is anomalous. From
time period 80 to 100 sensor nodes 1, 2 and 3 all have third
order anomalies, where the data from this set of nodes are