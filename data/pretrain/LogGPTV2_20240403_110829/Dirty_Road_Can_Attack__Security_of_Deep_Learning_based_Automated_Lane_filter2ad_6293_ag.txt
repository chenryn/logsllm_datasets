[90] Y. Jia, Y. Lu, J. Shen, Q. A. Chen, H. Chen, Z. Zhong, and T. Wei,
“Fooling Detection Alone is Not Enough: Adversarial Attack Against
Multiple Object Tracking,” in International Conference on Learning
Representations (ICLR), 2019.
[91] J. Shen, J. Y. Won, Z. Chen, and Q. A. Chen, “Drift with Devil: Se-
curity of Multi-Sensor Fusion based Localization in High-Level Au-
tonomous Driving under GPS Spooﬁng,” in USENIX Security Sympo-
sium, 2020.
[92] K. Tang, J. Shen, and Q. A. Chen, “Fooling Perception via Location:
A Case of Region-of-Interest Attacks on Trafﬁc Light Detection in
Autonomous Driving,” in Workshop on Automotive and Autonomous
Vehicle Security (AutoSec), 2021.
[93] M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter, “Accessorize to
a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recogni-
tion,” in ACM SIGSAC Conference on Computer and Communications
Security (ACM CCS), pp. 1528–1540, 2016.
[94] S.-T. Chen, C. Cornelius, J. Martin, and D. H. P. Chau, “Shapeshifter:
Robust Physical Adversarial Attack on Faster R-CNN Object De-
tector,” in Joint European Conference on Machine Learning and
Knowledge Discovery in Databases, pp. 52–68, Springer, 2018.
[95] Z. Zhong, W. Xu, Y. Jia, and T. Wei, “Perception Deception: Physical
Adversarial Attack Challenges and Tactics for DNN-Based Object
Detection,” in Black Hat Europe, 2018.
[96] N. S. Council, Reference Material for DDC Instructors, 5th Edition.
2005.
[97] UK ACPO Road Policing Enforcement Technology Committee,
ACPO Code of Practice for Operational Use of Enforcement Equip-
ment. 2002.
[98] U. D. for Transport, The Ofﬁcial Highway Code Book. 2015.
[99] H. Loeb, A. Belwadi, J. Maheshwari, and S. Shaikh, “Age and Gen-
der Differences in Emergency Takeover from Automated to Manual
Driving on Simulator,” Trafﬁc injury prevention, pp. 1–3, 2019.
[100] “Watch Tesla Drivers Apparently Asleep at the Wheel, Renewing
Autopilot Safety Questions.” https://www.cnbc.com/2019/09/09/watc
h-tesla-drivers-apparently-asleep-at-the-wheel-renewing-safety-q
uestions.html, 2019.
[101] “Amazon Mechanical Turk.” https://www.mturk.com/.
[102] “Driver Take-Over Decision Survey with Automated Lane Centering
System in our User Study.” https://storage.googleapis.com/driving-d
ecision-survey/driving_decision_survey.pdf, 2020.
A Required Deviations and Success Time
Required deviations. The required deviations for the high-
way and local roads are calculated based on Toyota RAV4
width (including mirrors) and standard lane widths in the
U.S. [62] as shown in Fig. 16. We use Toyota RAV4 since it
is the reference vehicle used by the OpenPilot team when col-
lecting the comma2k19 data set [56]. For the lane widths, we
refer to the design guidelines [62] published by the U.S. De-
partment of Transportation Federal Highway Administration.
The required deviations to touch the lane line are calculated
using L−C
2 = 0.735m (highway) and 0.285m (local), where L
is the lane width and C is the vehicle width.
Required success time. Since ALC systems assume a fully
attentive human driver who is prepared to take over at any mo-
ment [1,7], the required deviation above needs to be achieved
fast enough so that the human driver cannot react in time to
take over and steer back. Thus, when we deﬁne the attack goal,
we require not only the required deviation above, but also an
attack success time that is smaller than the average driver
reaction time to road hazards. We select the average driver
reaction time based on different government-issued transporta-
tion policy guidelines [57, 96]. In particular, in the California
Department of Motor Vehicles Commercial Driver Handbook
Section 2.6.1 [57], it describes (1) a 1.75 seconds average per-
ception time, i.e., the time from the time the driver’s eyes see a
hazard until the driver’s brain recognizes it, and (2) a 0.75 to 1
seconds average reaction time, i.e., the time from the driver’s
brain recognizing the hazard to physically take actions. Thus,
in total it’s 2.5 to 2.75 seconds from the driver’s eyes seeing
a hazard to physically take actions. The UK “Highway Code
Book” and “Code of Practice for Operational Use of Road
Policing Enforcement Technology” use 3 seconds for driver
reaction time [97, 98]. National Safety Council also adopts
a 3-second driver reaction time to calculate the minimum
spacing between vehicles [96]. Among them, we select the
smallest one, i.e., 2.5 seconds from the California Depart-
ment of Motor Vehicles [57], as the required success time
in this paper to avoid possible overestimation of the attack
effectiveness in our evaluation.
Note that the driver reaction time above is commonly refer-
ring to the reaction time to apply the brake, instead of steering.
In our paper, we use such reaction time to apply the brake
as the reaction time to take over the steering wheel when the
ALC systems are in control of the steering wheel. This is be-
cause in traditional driving, the driver is actively steering the
vehicle but passively applying the brake. However, when the
ALC system is controlling the steering, the human driver is
passively steering the vehicle, i.e., her hands are not actively
controlling the steering wheel. Thus, the reaction time to take
over the steering wheel during passive steering is analogous
to that to apply the brake during passive braking.
In fact, the actual average driver reaction time when the
ALC system is taking control is likely to be much higher
than the 2.5 seconds measured in traditional driving, due to
the reliance of human drivers on such convenient driving
automation technology today. A recent study performed a
simulation-based user study on Tesla Autopilot, and found that
40% drivers fail to react in time to avoid a crash happening
6.2 seconds after the Autopilot fails to operate [99]. In the real
world, it is found multiple times that Tesla drivers fall asleep
with Autopilot controlling the vehicle in high speed [100].
Thus, the required success time of 2.5 seconds used in this
paper is a relatively conservative estimation, and thus the
3324    30th USENIX Security Symposium
USENIX Association
any sensitive population; our study is thus determined as in
the IRB Exempt category.
Evaluation setup. We use Amazon Mechanical Turk [101]
to perform this study, and in total collected 100 participants.
All of them have driving experience, which is conﬁrmed by
asking them the age when ﬁrst licensed and the weekly driving
mileage. A local-road driving trace is used in this study, and
for the scenarios with attack, we evaluate 3 stealthiness levels
as in §5.1 (i.e., λ = 10−2,10−3,10−4). The survey is avail-
able at [102]. Among the 100 participants, 56% are male and
44% are female. The average age is 32.3 years old. 79% have
experienced at least one ALC system, among which Tesla
Autopilot has the largest share (28%). Statistics of ALC ex-
periment and demographic information are shown in Fig. 18.
Results. Fig. 17 shows the study results. As shown, the
closer it is to the attack success time, the more partici-
pants choose to take over the driving in the attacked sce-
narios since the dirty patterns become increasingly larger and
clearer. Among the 3 stealthiness levels, the driver decisions
are consistent with our design: the lowest stealthiness level
(λ = 10−4) has the highest take-over rate, while the highest
level (λ = 10−2) has the lowest. In particular, we ﬁnd that even
for the lowest stealthiness level (λ = 10−4), only less than
25% of the participants decide to take over before the attack
starts to take effect. As shown in Fig. 7, at this stealthiness
level the white dirty patterns are quite dense and prominent.
Thus, these results suggest that the majority of human drivers
today do not treat dirty road patches as road conditions where
ALC systems cannot handle.
As introduced in §3.1, 2.5 seconds is commonly used as
the average driver reaction time to road hazards. Thus, at
2.5 seconds or more before the attack succeeds, the human
driver still has a chance to take over the driving to prevent
the damage in common cases, as long as she can realize that
it is a road hazard. However, our results show that only less
than 20% of the participants decide to take over at 2.5 and
3 seconds before our attack succeeds even for the lowest
stealthiness level. In particular, when the stealthiness levels
are λ = 10−2 and λ = 10−3, the take-over rates at these 2 time
points are similar to the rates for the benign road patch with
only the base color. This suggests that at the time when there
is still a chance to prevent the damage in common cases, our
attack patches at λ = 10−2 and 10−3 appear to be as innocent
as normal clean road patches to human drivers. In these cases,
the take-over rates are only less than 15%, which are from
participants who will take over even for normal clean road
patches. Note that the take-over rates in practice are likely to
be lower than this since (1) this study is performed for a local
road scenario, while the road patches in highway scenarios
are much farther and thus much less noticeable as shown in
Fig. 7, and (2) the road patches in this study are digitally
synthesized into the image frames, which may appear less
natural and thus may more easily alert the participants.
Stealthiness from pedestrian view. In local road scenar-
Figure 16: Vehicle and lane widths used in this paper.
attack effectiveness reported in our evaluations is likely only
a lower bound of the actual effectiveness of our attack in the
real world.
B Attack Stealthiness User Study
In this section, we conduct a user study to more directly evalu-
ate the stealthiness of the DRP attack. We have gone through
the IRB process and our study is determined as in the IRB
Exempt category since it does not involve the collection of
any Personally Identiﬁable Information (PII) or target any
sensitive population.
Evaluation methodology. We use the generated attacks on
real-world driving traces in §5.1 to perform the user study. For
an attack scenario, we ask the participants to imagine that they
are driving with the ALC system taking control, and then show
a sequence of image frames with the malicious road patch
from the driver’s view at 3, 2.5, 2, 1.5, and 1 second(s) before
the attack succeeds. Here, 1 second before the attack succeeds
is right before the attack starts to take effect. For each image
frame, we ask whether they will decide to take over the driving
to avoid danger or potential safety risks. These questions are
also asked for the image frames with a benign road patch that
only has the base color without the malicious dirty patterns
as a control group.
Since our attack is designed for drivers who are in favor of
using ALC system in normal cases, the same set of questions
are asked at the beginning for the original image frames with-
out attack, and we only accept a participant if she does not
choose to take over the driving for these cases. This process
also helps ﬁlter out ill-behaved participants who just provide
random answers. Since DRP is a new form of attack vectors
on the road, we do not tell the participants that the study is
related to security attacks. Instead, we only tell them that our
focus is on surveying driver’s decisions under ALC systems
for different road surface patterns such as road patches and
scratches. At the beginning of the study, we also provide an
introduction of ALC systems with demo videos to ensure that
the participants fully understand what driving technology we
are surveying about. To understand the distribution of the
participant background, we also ask demographic informa-
tion and background information related to driving and ALC
usage. None of the questions in our study involve PII or target
USENIX Association
30th USENIX Security Symposium    3325
Vehicle width: C = 2.13 mLocal road lane width: L = 2.7 mHighway lane width: L = 3.6 muses recurrent DNN structures (e.g., RNN and GRU), which
are more detailed in our extended version [38] for 3 speciﬁc
versions of it. In each frame, the recurrent model receives a
front-camera input of 512 pixels wide by 256 pixels high and
512-dimensional recurrent features from the previous frame.
The recurrent features are the output of a middle layer. The
ﬁnal output for ALC consists of information of 3 lines (left
and right lines and driving path). Each line has coordinates of
192 points (1 m interval from the vehicle to driving direction),
uncertainty scores of each coordinate, and a conﬁdence score
of its lane. Thus, there are (192× 2 + 1)× 3 = 1,155 output
values in total. The desired driving path is calculated by the
weighted average of the driving path and the center line of the
left and right lines weighted by the uncertainty and conﬁdence
scores. See OpenPilot code [8] for more details.
Such recurrent structure is stateful: it allows leveraging
the previous detection results to enhance the current frame
detection since lane line shapes are typically not changed
largely across consecutive frame. OpenPilot LD models out-
put the detected lane line points of the left line, right line,
and predicted driving path. Each line is ﬁtted to the 3-degree
polynomial, and the desired driving path is then calculated as
the weighted average of the three lines with their conﬁdence
levels. OpenPilot LD operates at 20 Hz (every 50 ms). In §7,
we inject the attack traces at the end of this step by modify-
ing the ALC source code to replace the real-time LD model
outputs with a sequence of attacked ones obtained from the
software-in-the-loop simulation at the same driving speed
(simulation environment described in §6).
Lateral control. OpenPilot adopts Model Predictive Con-
trol (MPC) [24] to decide the desired steering angle, which
will then be sent to the vehicle actuation step. The input of the
MPC is the desired driving path, the current speed, and the
current steering angle. This step works at the same frequency
as LD, i.e., the desired steering angle is decided every 50 ms.
The MPC is stateful: it reuses the solution of the previous
frame as the initial solution for the current frame.
Vehicle actuation. Based on the obtained desired steering
angle from MPC, OpenPilot vehicle actuation decides the
steering angle change to actuate in the control step and sends
actuation messages through CAN (Controller Area Network)
bus. This thus makes the absolute value of the actuated steer-
ing angle stateful: the new actuated steering angle is built
upon the previous one, by applying the angle change actua-
tions. OpenPilot actuation works at 100 Hz control frequency.
The actuated steering angle change is up to 0.25◦ per con-
trol step (every 10 ms). As described in §2.1, such limit is
typically imposed in production ALC systems due to the phys-
ical constraints of the mechanical control units and also for
driving stability and safety [22]. OpenPilot is integrated to a
vehicle by overriding the stock cruise control system. It thus
is engaged to control the steering and throttle when the driver
turns on the cruise control mode, and can work with stock
safety features such as AEB and FCW [8].
Figure 17: Results of the attack stealthiness user study. Driv-
ing take-over rate is the percentage of participants who choose
to take over the driving at a particular time point before the
attack succeeds.
Figure 18: Statistics of the ALC system experience and de-
mographic information in the attack stealthiness user study.
ios, the stealthiness from the pedestrian’s view is also an
aspect worth considering, as pedestrians may report anoma-
lies if our attack patch looks too suspicious. Our user study
includes the driver’s view at 1 second before the attack suc-
ceeds, which is 7 meters to the driver’s eyes so similar to the
distance from the pedestrian on local roads. However, only
75% do not think our attack patch at this distance looks
suspicious enough to affect driving. This may be because the
general public today does not know that dirty road patches
can be a road hazard. We hope that our paper can expose this
and thus help raise such awareness.
C Details of OpenPilot ALC system
In this section, we describe the implementation details of the
OpenPilot ALC system, which follows the typical modular
ALC system design introduced in §1:
Lane Detection (LD). The LD model used in OpenPilot
3326    30th USENIX Security Symposium
USENIX Association
Driving Take-over Rate (%)Benign Road Patchλ = 10λ = 10λ = 10-2-3-4504030201003sec2.5sec2sec1.5sec1secTime Before Attack SucceedsTesla AutopilotGM Super CruiseHyundai Lane Following AssistMazda Lane TraceHonda Sensing: LKAS or AcuraWatch Ford Co-Pilot360: Lane Centering Nissan ProPilot AssistMercedes Driver Assistance Package Kia Lane Following AssistFiat-Chrysler's ALKSLincoln Co-Pilot360: Lane Centering Volvo Pilot Assist IISubaru EyesightOpenPilotNo, I've never used any ALC systems.0%10%20%30%Experienced ALC SystemsMaleGender60%102030405060Age0%40%20%40%20%0%FemaleOther