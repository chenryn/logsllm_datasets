credential cannot be forged as it contains a signature with
a private key known only by the Malware Distribution
Platform.
The analyst could try to execute forged payloads with
Infection Hidden Execute because the public binding
key is visible. However, because Infection Hidden Exe-
cute will only execute payloads signed by a key unknown
to the analyst, this will not work. No program other than
Infection Hidden Execute and the programs it executes
can access the binding key.
The analyst could try to set the PCR values to those
speciﬁed in (P K, SK)bind, but run a program other
than Infection Payload Loader. This would allow her
to decrypt the payload (step 2 in Infection Hidden Ex-
ecute). The values of PCRs are affected by processor
events and the SINIT code module. The CPU instruction
GETSEC[SENTER] sends an LPC bus signal to initial-
ize the dynamically resettable TPM PCRs (PCRs 16-23)
to 160 bits of 0s. No other TPM capability can reset these
PCRs to all 0s; a hardware reset sets them to all 1s. So an
analyst can only set PCR 18 to all 0s with a late launch
9
executable. SINIT extends PCR 18 with a hash of the
MLE. Therefore, to set PCR 18, the analyst must run an
MLE with the correct hash. Assuming the hash function is
collision resistant, only the Infection Payload Loader will
hash to the correct value, so the analyst cannot run an al-
ternate program that passes the PCR check. The payload
loader terminates at payload end by extending a random
value into PCR 18, so the analyst cannot use the key after
the late launch returns.
4.4 Prevention of malware analysis
Having described our protocol for cloaked malware ex-
ecution, we review how it defeats conventional malware
analysis. While our list of malware analysis techniques
may not be exhaustive, to our knowledge, TPM cloaking
can be defeated only by TPM manufacturer intervention,
or by physical attacks, like direct monitoring of hardware
events or tampering with the TPM or system buses. Both
of these are discussed in more detail in Section 6.
Static analysis. Cloaked computations are encrypted
and are only decrypted once the TPM has veriﬁed that the
PCRs match those in the key blob. The malware author
speciﬁes PCR values that match only the Infection Pay-
load Loader, so no analyst program can decrypt the code
for a cloaked computation.
Honeypots. Honeypots are open systems that collect
and observe malware, possibly using some combination
of emulation, virtualization and instrumented software.
Purely software-based honeypots can try to follow our
protocol without using a legitimate hardware TPM, but
will fail to convince a malware distributing machine of
their authenticity. This failure is due to their inability to
decrypt Enc(P KEK , K2 || Haik cert), which is encrypted
with the public EK that is certiﬁed by a TPM manufac-
turer in CEK , and the private part of which is not present
outside of a TPM. Thus these honeypots will never re-
ceive the malicious payload. If a honeypot uses a legit-
imate hardware TPM, it will obtain a malicious payload.
However, it can only execute the payload with late launch,
which prevents software monitoring of the unencrypted
payload.
Virtualization.
Software-based TPMs, virtualized
TPMs, and virtual machine monitors communicating with
hardware TPMs cannot defeat cloaking. Hardware TPMs
have certiﬁcates of authenticity that are veriﬁed in our
malware distribution protocol. A software-based TPM ei-
ther will not have a certiﬁcate, or will have a certiﬁcate
that is distinguishable from a hardware TPM. Either way,
it will fail to convince a malware distribution platform of
its authenticity. An analyst cannot use a virtual machine
to defeat cloaking.
Hardware TPM manufacturers should not certify
software-based TPMs as authentic hardware TPMs.
Software-based TPMs cannot provide the same secu-
rity guarantees as hardware-based TPMs. The PCRs of
software-based TPMs might not correspond to platform
state in any way, as they can be modiﬁed by sufﬁciently
privileged software. A software TPM cannot attest to a
particular software environment, because it does not know
the true software environment—it could be executing in a
virtual environment. Any certiﬁcate for a software-based
TPM must identify the TPM as software otherwise the
chain of trust is broken, defeating remote attestation (a
major purpose of TPMs). No TPM manufacturer cur-
rently signs software TPM EKs, nor (to our knowledge)
do any plan to do so. Prior work on virtualizing TPMs
emphasizes that virtual TPMs and their certiﬁcates must
be distinguishable from hardware TPMs, as the two do
not provide the same security guarantees [17]. A malware
distribution platform can avoid software and virtual TPM
certiﬁcates by using a whitelist of known-secure hardware
TPM certiﬁcate distributors compiled into the malware.
Software, such as a virtual machine monitor, cannot
communicate with a legitimate hardware TPM to obtain
and decrypt the malicious payload without running the
payload in late launch. The only way that the mali-
cious payload can be decrypted is through use of a private
key stored in the TPM that can only be used when the
TPM PCRs are in a certain state. This state can only be
achieved through late launch, which is a non-virtualizable
function, and it prevents software monitoring of the unen-
crypted payload. TPM late-launch is designed to be non-
virtualizable, so that TPM hardware can provide a com-
plete and reliable description of platform state.
4.5 Attack assumptions
Like any attack, ours has particular assumptions. As dis-
cussed in Section 2.1, our protocol requires late launch
instructions, which are privileged, so Infection Hidden
Execute must run at kernel privilege levels.
More importantly, our attack requires knowledge of
SRK and owner AuthData values. There are two main
possibilities for acquiring this AuthData previously men-
tioned in Section 3: snooping and overriding with physi-
cal presence.
AuthData can be snooped from kernel or application
(e.g. TrouSerS) memory or from logged keystrokes,
which are converted into AuthData by a hash. The like-
lihood of successful AuthData snooping depends on the
particular AuthData being gathered. The SRK must be
loaded to load any other key stored in the TPM, so there
will be regularly occurring chances to snoop the SRK Au-
thData. Owner AuthData, on the other hand, is required
for fewer, and generally more powerful, operations. It is
then liable to be more difﬁcult to acquire.
One could enter all AuthData remotely to a platform
that contains a TPM, but we consider it unlikely that this
is done in practice. TPM arguments could be HMACed
by a trusted server, but such a server can become a perfor-
mance or availability bottleneck. Use of a trusted server
10
is also problematic for use of laptops that may not always
have network connectivity. For these cases, it may be pos-
sible to enter AuthData into a separate trusted device that
then can assist in authorizing TPM commands. However,
such devices are currently not deployed. It is currently
more likely that AuthData would be presented through a
USB key or entered at the keyboard, and in both cases it
can be snooped. In addition, applications and OS services
used to provide AuthData to the TPM may not sufﬁciently
scrub sensitive data from memory.
To demonstrate the possibility of acquiring AuthData
from the OS, we virtualized a Windows 7 instance, and
used OS-provided control panels to interact with the
TPM. When AuthData was read from a removable drive,
it remained in memory for long periods of time on an idle
system, even after the relevant control panels were closed.
The entire contents of the ﬁle containing the AuthData
were present in memory for up to 4 hours after the Auth-
Data was read, and the removable drive ejected from the
system. The AuthData itself remained in memory for sev-
eral days, before the system was eventually shut down.
If malware can use mechanisms for asserting physical
presence at the platform, it can clear the current TPM
owner and install a new owner, preventing the need to
snoop any AuthData. While physical presence mecha-
nisms should be tightly controlled, their implementation
is left up to TPM and BIOS manufacturers. Our experi-
ence setting up BitLocker (see Section 3.3) indicates that
the process can be confusing, and that it may be possible
to convince a user to enable malware to obtain the neces-
sary authorization to use TPM commands.
4.6 Distributing the malware distribution platform
As written, the malware distribution platform consists of a
host (or small number of hosts) controlled by the attacker
and trusted with the attacker’s secret key (SKmalware).
This design creates a single point of failure.
The Malware Distribution Platform computation con-
sists of arithmetic and cryptographic work (with no OS
involvement) with an embedded secret. It is a perfect can-
didate to run as a cloaked computation. An attacker can
distribute work done on the Malware Distribution Plat-
form to compromised hosts using cloaked computations.
5 Implementation and Evaluation
We implemented a prototype of our attack, which con-
tains implementations of the establishment of a TPM-
controlled binding key, the decryption and execution of
payloads in late launch, and sample attack payloads. In
this section, we describe each of these pieces in turn.
The prototype implementation consists of ﬁve pro-
grams for the key establishment protocol (described in
Table 3), the Infection Payload Loader PAL and ported
TrouSerS TPM utility code, payload programs, and sup-
porting code to connect the pieces. The key establish-
ment programs are about 3,600 lines of C, the Infection
Payload Loader is another 400 lines of C, with another
150 lines of C added to provide TPM commands through
selections of TrouSerS TPM code which themselves re-
quired minor modiﬁcations. The payloads were about 50
lines apiece with an extra 75 line supporting DSA rou-
tine, which was necessary for verifying Ubuntu’s reposi-
tory manifests. All code size measurements are as mea-
sured by SLOCCount [53].
5.1 Binding key establishment
We implemented a prototype of the protocol described in
Figure 5 using the TrouSerS [6] (v0.3.6) implementation
of the TCG software stack (TSS) to ease development.
Our
(step 4), but
implementation follows the protocol, except
steps 2 to 3 in Infection Keygen which use TSS
API call Tspi CollateIdentityRequest. This
call does not produce Mreq
instead
produces EncSym(K, PubBlob((P K, SK)AIK)) and
Enc(P Kmalware, K) that must be decrypted in the Mal-
ware Distribution Platform Certiﬁcate Handler. While the
protocol speciﬁes network communication, the prototype
communicates via ﬁles on one machine. TrouSerS is not
necessary for malware cloaking; TPM commands made
by TrouSerS could be made directly by malware.
5.1.1 EK certiﬁcate veriﬁcation
We veriﬁed the authenticity of our ST Microelectronics
TPM endorsement key (EK). However, we had to over-
come obstacles along the way, and there may be obstacles
with other TPM manufacturers as well. For example, we
needed to work around unexpected errors in reading the
EK certiﬁcate from TPM NVRAM. Reads greater than or
equal to 863 bytes in length return errors, even though the
reads seem compatible with the TPM speciﬁcation, and
the EK certiﬁcate is 1129 bytes long. We read the certiﬁ-
cate with multiple reads, each smaller than 863 bytes.
The intermediate certiﬁcates in the chain linking the
TPM to a trusted certiﬁcate authority were not available
online, and we obtained them from ST Microelectronics
directly. However, some manufacturers (e.g.
Inﬁneon)
make the certiﬁcates in their chains available online [11].
To deploy TPM-based cloaking on a large scale, the veri-
ﬁcation process for a variety of TPMs should be tested.
For the TPM we tested, the certiﬁcate chain was of
length four including the TPM EK certiﬁcate and rooted
at the GlobalSign Trusted Computing Certiﬁcate Author-
ity. There were two levels of certiﬁcates within ST Mi-
croelectronics: Intermediate EK CA 01 (indicating there
are likely more intermediate CAs) and a Root EK CA.
5.2 Late launch environment establishment
We modiﬁed code from the Flicker [40] (v0.2) distribution
to implement our late launch capabilities. Flicker pro-
vides a kernel module that allows a small self-contained
11
program, known as a Piece of Application Logic or PAL,
to be started in late launch with a desired set of parameters
as inputs in physical memory. The kernel module accepts
a PAL and parameters through a sysfs ﬁlesystem in-
terface in Linux, then saves processor context before per-
forming a late launch, running the PAL in late launch, and
then restoring the processor context after the PAL com-
pletes. Output from PALs is available through the ﬁlesys-
tem interface when processor context is restored.
We implemented the Infection Payload Loader as a
PAL, which takes the encrypted and signed payload, the
symmetric key used to encrypt the payload encrypted with
the binding key, and the binding key blob as parameters.
We used the PolarSSL [15] embedded cryptographic li-
brary for all our cryptographic primitives (AES encryp-
tion, RSA encryption and signing, SHA-1 hashing and
SHA-1 HMACs).
We ported code from TrouSerS to handle use of
TPM capabilities that were not
implemented by the
Flicker TPM library (TPM OIAP, TPM LoadKey2,
TPM Unbind). We replaced the TrouSerS code depen-
dence on OpenSSL with PolarSSL. We ﬁxed two small
bugs in Flicker’s TPM driver that seem to be absent from
the recent 0.5 release due to use of an alternate driver.
5.3 Payloads
We implemented payloads for the three examples from
Section 2.2. Here we describe the payloads in detail.
Domain generation The domain generation payload
provides key functionality for a secure command and con-
trol scheme, in which malware generates time-based do-
main names unpredictable to an analyst. As input, the
payload takes the contents of a package release manifest
for the Ubuntu distribution, and its associated signature.
The payload veriﬁes the signature against a public key
within itself. If the signature veriﬁes correctly, the pay-
load extracts the date contained in the manifest. The pay-
load outputs an HMAC of the date with a secret key con-