B had to be in A’s routing table and C had to be in B’s routing table.
their probe results. In the latter scenario, when a non-faulty
node was being judged, malicious peers would always claim
that their probed links were up (increasing the false posi-
tive rate); when a malicious peer was being judged, other
malicious peers would always claim that their probed links
were down (increasing the false negative rate). Comparing
Figure 5(a) to Figure 5(b), we see that incorporating erro-
neous probe results into Equation 2 causes more blame to
be assigned to non-faulty nodes and less blame to be as-
signed to faulty ones. However, Concilium can still make
accurate fault accusations using a thresholding scheme which
produces binary verdicts. For example, suppose that for any
message drop, nodes receiving less than 40% blame are pro-
claimed innocent and all other nodes receive a guilty verdict.
If all peers report their probe results faithfully, then innocent
peers will receive guilty verdicts 1.8% of the time whereas
faulty peers will receive guilty verdicts 93.8% of the time. If
20% of peers collude and contribute malicious probe results,
then innocent peers will receive guilty verdicts 8.4% of the
time and faulty peers will receive guilty verdicts 71.3% of
the time.
A host issues a formal accusation against a peer if that
peer accumulates at least m guilty verdicts for the w most
recent message drops. To determine the false positive and
false negative rates of formal accusations, let pgood be the
probability that a non-faulty node receives a guilty verdict for
a message drop, and pf aulty be the probability that a faulty
node receives a guilty verdict; these probabilities are derived
from the blame pdfs and thresholds as described in the pre-
vious paragraph. Let W be a random variable describing the
number of guilty verdicts in a w-slot window. W is a bi-
nomial random variable, meaning that the error rates can be
described as follows:
P r(f alse positive) = P r(W ≥ m)
good(1 − pgood)w−k
pk
f aulty(1 − pf aulty)w−k.
pk
=
w(cid:88)
(cid:181)
k=m
m−1(cid:88)
k=0
=
(cid:181)
(cid:182)
w
k
(cid:182)
w
k
P r(f alse negative) = P r(W < m)
Figure 6 depicts the error rates with a blame pdf threshold of
40% and a sliding window size of 100. If all nodes faithfully
report probe results, then we can drive both error rates below
1% with an m of 6. If 20% of hosts maliciously invert their
probe results, we can achieve equivalent error rates with an
m of 16.
4.4 Bandwidth Requirements
Concilium has two primary sources of network overhead.
Peers must exchange signed, timestamped copies of their
routing state, and they must perform tomographic probing.
We expect local routing state to reference µφ + 16 peers,
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:21:03 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007(a) The two pdfs are very distinct when nodes correctly report
their tomographic data.
(b) The pdfs are less distinct when 20% of peers maliciously
invert probe results, but Concilium can still make accurate judg-
ments using a thresholding scheme.
Figure 5. PDFs for blame as generated by Equation 2 (max probe time=120 secs, ∆=60 secs)
(a) If nodes faithfully report probe results, an m of 6 drives
both error rates below 1%.
(b) If 20% of hosts are colluding and malicious, an m of 16
drives both error rates below 1%.
Figure 6. Accusation error (w=100)
where 16 is the number of leaf nodes. Each routing en-
try contains a 16 byte node identiﬁer and a 4 byte fresh-
ness timestamp. Using PSS-R [4] with 1024 bit public keys,
both quantities plus a signature consume 144 bytes. The ex-
changed routing state also includes tomographic probe re-
sults for the IP path to each routing peer. As explained in
Section 3.2, the results for each path can be encoded in a few
bits. Assuming 1 byte for each path summary and a 100,000
node overlay, an entire advertised routing table is about 11.5
kilobytes. This overhead can be decreased by sending diffs
for updated entries instead of entire tables.
In the absence of forwarding faults, lightweight tomog-
raphy requires no additional bandwidth beyond that already
required for availability probing. The outgoing bandwidth
required for heavyweight striped probing of a tree is
(cid:181)|leaves ∈ TH|
(cid:182)
2
(stripes per pair)(stripe size)(pkt size).
In a 100,000 node overlay, the average node has 77 entries
in its local routing state. Suppose that each node sends 100
stripes to each ordered pair of peers, that each stripe contains
two UDP probes, and that each probe is 30 bytes long (28
bytes for IP+UDP headers and 16 bits for a nonce). Probing
an entire tree will require 16.7 MB of outgoing network traf-
ﬁc. Incoming probes will require no more than this amount
and less if there are legitimately lossy network links.
The probing cost can be reduced in several ways. If IP
multicast were widely deployed, we could reduce the probe
trafﬁc sent from the root of a tree to its leaf nodes. Also,
as described in Section 3.7, cooperative hosts on the same
stub network can share probe results, reducing the probing
bandwidth for the collective.
5 Related Work
Packet obituary systems [2] allow end hosts to determine
the autonomous system (AS) which dropped a particular
packet. Each AS deploys an “accountability box” at each
border link. When an incoming packet hits a box, the box
records the next AS that the packet will traverse. Boxes pe-
riodically push these records along the reverse box paths, al-
lowing each packet source to determine the last AS which
successfully received their datagrams. Concilium differs
from obituary systems in three ways. First, Concilium does
not require the modiﬁcation of core Internet routers. Sec-
ond, Concilium protects and validates its network data us-
ing various cryptographic and statistical techniques. Finally,
obituary systems cannot arbitrate between two adjacent ASes
when the ﬁrst claims that the second dropped its packet, and
the second claims that the ﬁrst never sent the packet. Concil-
ium resolves such disputes using reputation systems.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:21:03 UTC from IEEE Xplore.  Restrictions apply. 
0%5%10%15%20%25%00.11250.23750.36250.48750.61250.73750.86250.9875Blame ReceivedProbabilityNon-faulty peerFaulty peer0%5%10%15%20%25%00.11250.23750.36250.48750.61250.73750.86250.9875Blame ReceivedProbabilityNon-faulty peerFaulty peer0%20%40%60%80%100%1815222936435057647178859299m = minimum # of guilty verdicts triggering accusationFalse Positives0%20%40%60%80%100%False NegativesFalse PositivesFalse Negatives0%20%40%60%80%100%1815222936435057647178859299m = minimum # of guilty verdicts triggering accusationFalse Positives0%20%40%60%80%100%False NegativesFalse PositivesFalse Negatives37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Concilium assumes that end hosts may be malicious but
core routers will not fail in a byzantine way. Fatih [15] is
designed to detect core routers which maliciously drop or re-
order packets. Each router maintains a summary of the traf-
ﬁc it has forwarded. Signed versions of these summaries are
periodically exchanged with other routers, and misbehavior
is detected by comparing summaries from routers that share
links. Like obituary systems, Fatih requires modiﬁcation to
core Internet infrastructure.
In RON [1], each stub network has a special gateway
which sits between the stub and the larger Internet. The RON
gateways monitor the loss, latency, and throughput along the
O(N 2) paths which connect them. When a gateway must
forward a locally generated packet outside its stub, it for-
wards the message through other RON gateways if the de-
fault IP path is poor. Like Concilium, RONs use active prob-
ing to detect link quality. The key difference is that RON
always ascribes blame to the network—misbehaving RON
nodes must be detected and removed by human operators.
Concilium provides a mechanism for blaming the network
or an overlay node.
6 Conclusions
In this paper, we introduce Concilium, a distributed diag-
nostic protocol for overlay networks. By aggregating peer-
advertised routing state, Concilium determines forwarding
paths at the overlay level. Using collaborative network to-
mography, Concilium discovers the IP links which com-
prise these paths and the quality of these links. By combin-
ing the topological and tomographic data with application-
level message acknowledgments, Concilium judges whether
dropped overlay messages are due to failures in the core In-
ternet or failures in overlay forwarders. Concilium’s fault ac-
cusations are self-verifying and robust to tampering, but they
may place blame on nodes which are the victim of misbe-
havior further downstream in their routes. Thus, Concilium
provides mechanisms to revise such incorrect accusations. It
also has methods for detecting peers which publish faulty
routing state or tomographic data.
References
[1] D. Andersen, H. Balakrishnan, M. F. Kaashoek, and R. Mor-
In Proceedings of SOSP,
ris. Resilient Overlay Networks.
pages 131–145, Banff, Canada, October 2001.
[2] K. Argyraki, P. Maniatis, D. Cheriton, and S. Shenker. Pro-
viding Packet Obituaries. In Proceedings of ACM SIGCOMM
HotNets, San Diego, CA, November 2004.
[3] V. Arya, T. Turletti, and C. Hoffmann. Feedback Veriﬁcation
for Trustworthy Tomography. In Proceedings of IPS-MoMe,
Warsaw, Poland, March 2005.
[4] M. Bellare and P. Rogaway. The Exact Security of Digital
Signatures – How to Sign with RSA and Rabin. Advances in
Cryptology–EUROCRYPT ’96, 1070:399–416, 1996.
[5] R. Bellman and M. Giertz. On the analytic formalism of the
theory of fuzzy sets. Information Sciences, 5:149–156, 1973.
[6] M. Castro, M. Costa, and A. Rowstron. Performance and de-
pendability of structured peer-to-peer overlays. In Proceed-
ings of DSN, Florence, Italy, June 2004.
[7] M. Castro, P. Druschel, A. Ganesh, A. Rowstron, and D. S.
Wallach. Secure routing for structured peer-to-peer overlay
networks. In Proceedings of OSDI, pages 299–314, Boston,
MA, December 2002.
[8] M. Castro, P. Druschel, Y. C. Hu, and A. Rowstron. Prox-
imity neighbor selection in tree-based structured peer-to-peer
overlays. Technical Report MSR-TR-2003-52, Microsoft Re-
search, 2003.
[9] Y. Chen, D. Bindel, H. Song, and R. Katz. An Algebraic
Approach to Practical and Scalable Overlay Network Mon-
itoring.
In Proceedings of ACM SIGCOMM, pages 55–66,
Portland, OR, September 2004.
[10] N. Dufﬁeld, F. L. Presti, V. Paxson, and D. Towsley. Infer-
ring Link Loss Using Striped Unicast Probes. In Proceedings
of IEEE INFOCOM, pages 915–923, Anchorage, AK, April
2001.
[11] R. Govindan and H. Tangmunarunkit. Heuristics for Internet
Map Discovery. In Proceedings of IEEE INFOCOM, pages
1371–1380, Tel Aviv, Israel, March 2000.
[12] R. Jurgelenaite, P. Lucas, and T. Heskes. Exploring the
noisy threshold function in designing bayesian networks. In
Proceedings of SGAI International Conference on Innovative
Techniques and Applications of Artiﬁcial Intelligence, pages
133–146, Cambridge, UK, December 2005.
[13] R. Mahajan, M. Castro, and A. Rowstron. Controlling the
cost of reliability in peer-to-peer overlays. In Proceedings of
the 2nd IPTPS, Berkeley, CA, February 2003.
[14] R. Mahajan, N. Spring, D. Wetherall, and T. Anderson. User-
level Internet Path Diagnosis. In Proceedings of SOSP, pages
106–119, Lake George, NY, October 2003.
[15] A. Mizrak, Y.-C. Cheng, K. Marzullo, and S. Savage. Fatih:
Detecting and Isolating Malicious Routers. In Proceedings of
DSN, pages 538–547, Yokohama, Japan, June 2005.
[16] D. Oppenheimer, A. Ganapathi, and D. A. Patterson. Why
do Internet services fail, and what can be done about it? In
Proceedings of USITS, March 2003.
[17] A. Rowstron and P. Druschel. Pastry: Scalable, distributed
object location and routing for large-scale peer-to-peer sys-
tems. In Proceedings of the IFIP/ACM International Confer-
ence on Distributed Systems Platforms (Middleware), Heidel-
berg, Germany, November 2001.
[18] N. Spring, R. Mahajan, and D. Wetherall. Measuring ISP
In Proceedings of ACM SIG-
topologies with Rocketfuel.
COMM, pages 133–145, Pittsburgh, PA, August 2002.
[19] I. Stoica, R. Morris, D. Karger, M. Kaashoek, and H. Balakr-
ishnan. Chord: A scalabale peer-to-peer lookup service for
Internet applications.
In Proceedings of ACM SIGCOMM,
pages 149–160, San Diego, CA, August 2001.
[20] K. Walsh and E. G. Sirer. Experience with an Object Repu-
tation System for Peer-to-Peer Filesharing. In Proceedings of
NSDI, pages 1–14, San Jose, CA, May 2006.
[21] Y. Zhang, V. Paxson, and S. Shenker. The Stationarity of In-
ternet Path Properties: Routing, Loss, and Throughput. Tech-
nical Report, AT&T Center for Internet Research at ICSI,
May 2000.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:21:03 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007