we now perform a test in which we reset the devices at the
beginning, but after 2300 s we pause the probing for ap-
proximately 7 minutes. Figure 17 shows the results of the
experiments for various links. It turns out that the devices
maintain the channel-estimation statistics, as the estimated
capacity resumes from the previous value before stopping the
probing process. Thus, the convergence time of the capacity
estimation does not apply in realistic probing conditions.
150
100
50
0
0
)
s
p
b
M
(
y
t
i
c
a
p
a
c
d
e
t
a
m
i
t
s
E
Link 1-0
Link 1-6
Link 1-5
Link 1-10
Pause
Resume
1000
2000
3000
4000
5000
Time (s)
Figure 17: Estimated capacity for various links by
probing with 20 packets per second. After 2300s, we
pause the probing for 7 minutes and we observe that
this does not aﬀect the estimation.
Conclusion: Capacity should be estimated by sending
probe packets and measuring BLE in PLC networks. To
estimate capacity, given our study in Section 6.1, we have
to take into account the invariance scale and to either com-
pute the average BLE = P6
s=1 BLEs/6, by capturing PLC
frames or request it using MMs. One of the remaining chal-
lenges in link-metric estimation is to take into account the
technology-speciﬁc MAC mechanisms, such as frame aggre-
gation. This remains a challenge also for the latest WiFi
technologies, as highlighted in [16].
7.2 Size of Probe Packets
We now investigate the size of probe packets. We observe
that for the special case of sending 1 probe-packet with size
less than one PB per second, the estimation might converge
to a smaller value than the true one for HPAV and remain
constant with time, independently of the channel conditions.
A representative example of this behavior is shown in Fig-
ure 18, where HPAV capacity converges to approximately
89 Mbps when sending only 1 packet per second with size
less than one physical block (520B including 8B PB header).
After this convergence, the estimated capacity remains con-
stant. A simple computation shows that the rate required to
transmit one PB in one OFDM symbol is R1sym = (520 ×
8)/Tsym ≈ 89.4Mbps with HPAV, given the symbol dura-
tion Tsym = 40.96µs. When sending packets smaller than
one PB, the rate converges to R1sym for all 6 slots of the
mains cycle, because increasing the rate does not reduce the
transmission time (it is not possible to transmit less than
1 OFDM symbol) while decreasing the probability of error
(higher rates yield less robust modulation schemes). Hence,
we unveil that to estimate the capacity of a link by send-
ing only one probe packet per second, it is crucial to send
packets larger than 1 PB or 1 OFDM symbol.
120
100
80
60
)
s
p
b
M
(
y
t
i
c
a
p
a
c
d
e
t
a
m
i
t
s
E
1300B
200B
521B
520B
0
2000
4000
6000
8000
10000
Time (s)
Figure 18: Estimated capacity with 1 probe packet
per sec and various sizes for link 11-6.
We next provide an example of how our temporal varia-
tion study can be used to adjust the frequency of the probe
packets such that the overhead is reduced, while maintaining
a good level of accuracy.
7.3 Frequency of Probe Packets
We explore the tradeoﬀ of accuracy vs overhead in prob-
ing for capacity estimation. To this end, we run a simple
example that uses the measurements of Section 6.2. We as-
sume that any link is probed at a speciﬁc interval which is
1) the same for all links; 2) depends on link quality. We
employ the BLE measured at these intervals as an estima-
tion of the capacity and we consider as exact capacity the
average values of BLE until the next probe. Let t be an
estimation instant and i the probing interval in multiples of
50ms (period of measurements). The estimation is BLEt,
and the exact capacity is BLEe(t) = Pt+i−1
l=t BLEl/i. Then,
the estimation error is computed as the absolute value of
the diﬀerence between the estimation and the exact capac-
ity, i.e., |BLEt − BLEe(t)|.
Our network consists of at least 10 stations, thus, to achieve
low overhead, we assume that stations send at most 1 probe
packet per 5 seconds (which yields a 240Kbps probing over-
head if 1500B probes are used), and we adopt this interval
as a baseline. We also explore probing at lower frequencies,
such as once per 80 seconds. The method that uses our tem-
poral variation study, probes bad links once per 5 seconds,
average links 8 times slower, and good links 16 times slower
(once per 80 seconds)10. To classify the quality of the links,
we use heuristics based on our study in Section 6.2: bad links
have a BLE below 60Mbps, good links have a BLE above
100 Mbps, and average links have a BLE in between. Fig-
ure 19 presents the CDF of the estimation error for all links
and all intervals. With our method, we manage to reduce
the probing overhead by 32% compared to probing all links
once per 5 seconds, while maintaining very good accuracy.
10The exact frequency of probes should be adjusted to the
network size and the PLC technology.
334)
x
(
F
1
0.8
0.6
0.4
0.2
0
0
Empirical CDF
Our method
Probing per 5 sec.
Probing per 80 sec.
10
20
Estimation error (Mbps)
Figure 19: Comparison of estimation error for dif-
ferent probing frequencies. By adjusting the prob-
ing frequency to the link quality (our method ), we
achieve very good accuracy with 32% overhead re-
duction compared to probing once per 5 seconds.
These results suggest that by studying the PLC network
and its temporal variation, probing can be optimized to
achieve a good tradeoﬀ between overhead and accuracy. To
estimate an appropriate probing interval based on the net-
work size and the aggregate link quality, the CCo of the
network can employ the information on the quality of all
the links and update the interval value by broadcasting to
all stations. We next validate our capacity estimation and
temporal variation studies by a load-balancing algorithm.
7.4 Bandwidth Aggregation Using Capacity
To further validate our capacity estimation method, we
employ a simple load-balancing algorithm that aggregates
bandwidth between WiFi and PLC and operates between
the IP and MAC layers. To implement our algorithm, we use
the Click Modular Router [10]. We forward each IP packet
to one of the mediums with a probability proportional to
the capacity of the medium. At the destination, we reorder
the packets according to a simple algorithm that checks the
identiﬁcation sequence of the IP header. We measure the
jitter and compare it with the jitter when using only one
interface, making sure that it does not worsen. The details
of our implementations are given in [20].
To estimate the capacities, we probe links with 1 packet
per second and request BLE and MCS from the interfaces.
The capacity for PLC is estimated using BLE, i.e., averaged
over the 6 tone-map slots of the invariance scale, whereas for
WiFi MCS capacity is averaged over the transmissions (data
and probes) during every second, because, as we observe in
Section 4.2, WiFi varies more than PLC within a second.
Our load-balancing algorithm takes into account our tempo-
ral variation study on PLC: In Section 6.1, we uncover that
the PLC channel quality is periodic, with every packet us-
ing a diﬀerent BLE. Because an accurate synchronization at
this time-scale is challenging for algorithms operating above
the MAC layer (such as in IEEE 1905 standard), the ca-
pacity of PLC in hybrid networks has to be estimated by
averaging over the invariance scale.
In Figure 20, we ﬁrst present the throughput of experi-
ments on one link. We run four experiments back-to-back,
using only one of the interfaces (WiFi, PLC) in two, us-
ing both interfaces and our load-balancing algorithm (Hy-
brid) in one, and using both interfaces and a round-robin
scheduler for the packets (Round-robin) in the last one. We
observe that by using simple load-balancing and reordering
algorithms, and our capacity-estimation technique, we can
achieve a throughput that is very close to the sum of the
capacities of both mediums. In contrast, the throughput of
a round-robin scheduler, which has no information on ca-
pacity, is limited to twice the minimum capacity of the two
mediums (i.e., WiFi in this example), because it assigns the
same number of packets to each medium and the slowest
medium becomes a bottleneck. To evaluate our algorithm
across our testbed, we also compare the completion times of
a 600Mbyte ﬁle download using (i) only WiFi, and (ii) both
mediums11, observing in the same ﬁgure, a drastic decrease
in completion times when using both mediums.
Link 0-4
70
60
50
40
30
20
10
)
s
p
b
M
(
t
u
p
h
g
u
o
r
h
T
Hybrid
Round-robin
PLC
Wiﬁ
0
0
100
200
300
400
500
Time (s)
)
s
(
e
m
i
t
n
o
i
t
e
l
p
m
o
C
500
400
300
200
100
0
WiFi
Hybrid
0-9
0-5
9-0
9-6
9-7
2-5
6-1
6-2
7-9
3-9
1-6
1-8
2-11
Link
Figure 20: Performance boost by using hybrid
Wiﬁ/PLC, and our load-balancing and capacity-
estimation techniques.
Our tests validate our capacity estimation methods. They
also show that, to exploit each medium to the fullest extent,
accurate link-quality metrics are required. However, an open
question to be answered is: How should the link metrics
be updated to take into account delay or contention? In
the next section we investigate another link metric, i.e., the
expected number of retransmissions, and the performance of
link metrics with respect to background traﬃc.
8. RETRANSMITTING IN PLC CHANNELS
Capacity is a good metric for link quality. However, it
does not take into account interference, which is very im-
portant for selecting links with high available bandwidth.
Moreover, another metric could be useful for delay sensitive
applications that do not saturate the medium but have low
delay requirements. Delay is aﬀected by retransmissions ei-
ther due to bursty errors or to contention, and metrics, such
as P Berr introduced in Section 5 (or packet errors [2]), are
related to retransmissions. We explore the mechanism of
retransmissions in PLC networks. We ﬁrst study another
link metric, which is the expected transmission count (ETX).
Numerous works, e.g., [7], [8], study this metric (or its vari-
ations) in WiFi networks by sending broadcast probes. We
examine how ETX performs in PLC and the relationship
between broadcast and unicast probing.
After studying retransmissions due to errors, we evaluate
the sensitivity of link metrics to background traﬃc. Link
metrics in hybrid networks should estimate the amount of
background traﬃc, or be insensitive to background traﬃc [7].
Thus, a critical challenge for hybrid networks is to design
link metrics achieving one of the aforementioned properties.
11Contrary to WiFi, PLC uses queues that are non-blocking:
the transport layer is not stopped from sending packets when
the MAC queues are full. For these experiments, we omit
PLC tests as dropped packets yield an unfair comparison.
3358.1 Retransmission Due to Errors
We ﬁrst explore how ETX would perform in PLC by send-
ing broadcast packets. Because broadcast packets in PLC
are transmitted with the most robust modulation and are
acknowledged by some proxy station [6], we expect that this
method yields very low loss rates.
For the purpose of this study, we set each station in turn to
broadcast 1500B probe-packets (1 every 100ms) for 500 sec.
The rest of the stations count the missed packets by using an
identiﬁcation in our packet header. We repeat the test for all
stations of the testbed during night and working hours (day).
Figure 21 shows the loss rate from these tests for all station
pairs, as a function of throughput and P Berr. Each pair is
represented with its link throughput (respectively, P Berr)
during the night experiment.
Conclusion: Loss rate of broadcast packets in PLC is a
very noisy metric for the following reasons:
(i) A wide range of links with diverse qualities have very
low loss rates (∼ 10−4), and some links even have 0 loss rates.
By observing high loss rates, e.g., larger than 10−1, ETX can
classify bad links in PLC, but nothing can be conjectured
for link quality from low loss rates.
(ii) There is no obvious diﬀerence between experiments
during the day, when the channel is worse, and night. A few
bad links have worse loss rates during the day, but at the
same time, a few average links yield much lower loss rates.
(iii) As PLC adapts the modulation scheme to channel
conditions when data is transmitted, broadcast packets –
sent at most robust modulation scheme – cannot reﬂect the
real link quality. Moreover, given the low loss rates of a wide
range of links, ETX appears to be 0 at short-time scales,
which provides no or misleading information on link quality.
)
t
s
a
c
d
a
o
r
b
(
e
t
a
r
s
s
o
L
100
10−1
10−2
10−3
10−4
night
day
0 10 20 30 40 50 60 70 80 90
Throughput (Mbps)
day
night
100
10−1
10−2
10−3
)
t
s
a
c
d
a
o
r
b
(
e
t
a
r
s