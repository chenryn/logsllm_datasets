from S over this SSL connection, or C executes a code of
a browser plug-in which was installed from a trusted source.
Note that the PKI assumption is a standard way of securing
communication between web services and their users. (At the
end of Section IV we point out that the trust in the PKI can be
somewhat relaxed if C is implemented as a browser plug-in.)
While C and S communicate over the internet without
particular concern about protocol bandwidth, by contrast we
assume that device D might have heavily restricted communi-
cation abilities. We consider four types of devices, depending
on the restrictions on the C-to-D and D-to-C communication
channels. Type I is a device like those used by traditional
TFA schemes such as Google’s authenticator smart phone app.
Namely, D cannot receive any message from C during protocol
execution, and it can send a single response message resp to
C which must be short, e.g. up to 20 or 30 bits. (In addition,
we assume that device of type I can maintain a clock, or other
updatable state e.g. a counter.) Devices of type II,III, and IV,
can receive a single challenge message ch from C and reply
with a single response resp. For device of type II message ch
is medium-sized, e.g. between 100 and 2000 bits, while resp is
short; for device of type III both ch and resp are medium-sized,
and for device of type IV both ch and resp can be long, e.g.
several thousand bits would still be ﬁne. As we explain below,
some of these D-to-C and C-to-D channels are authenticated by
a human in the loop to verify that the PIN which C receives is
the same PIN that D sent. However, this is not the case for all
device types, and so in our security security model, we allow
a man-in-the-middle attack on these channels (in addition to
an eavesdropping attack); and all of our protocols (Section IV)
and mechanisms implementation (Section V) are secure in the
presence of such attacks.
Motivating Scenarios of Four Device-Client Interaction
Types. These four device types are motivated by different
implementation scenarios which make different software and
hardware demands on both the device D and on the client
C, and which make different demands on the way the user U
enables the communication between C and D. Device of type
I does not need any data connectivity, except for a way to
periodically synchronize its internal clock (or counter). D must
only have a small screen on which it can display its message
resp encoded into a short numerical or alphanumerical string,
i.e. a PIN. The user U will have to read this PIN and type
it into the client browser C. Therefore this D-to-C channel is
low-bandwidth, it is authenticated by the human in the loop,
but it can be eavesdropped upon by a “shoulder surfer”.
Device of type II models e.g. a camera phone which can
photograph the browser’s screen display. In this case C could
display message ch encoded using a Quick Response (QR)
code, user U could position device D until this QR code is
detected and photographed by D’s camera, D can decode the
QR code into message ch, and reply to C with a PIN resp
in the same way as device of type I. While a QR code can
encode even several thousand bits, ensuring good reliability
with a budget camera phone probably precludes ch longer than
2Kb. We call this bandwidth medium because whereas it can
be much longer than the PIN we call short, the lower it is the
better reliability/usability characteristics of the system. As in
the case of a PIN D-to-C channel, this channel is authenticated
by the human in the loop, but subject to eavesdropping.
Device of type III has the same C-to-D capability as the
device of type II, but the medium-sized bandwidth on the D-
to-C channel can be implemented e.g. with a larger display on
D on which it can display a QR-encoded response resp, and
with client C which has a front-facing camera, e.g. because
the browser is running on a laptop, which can be accessed
3
from the HTML on the browser, or because C is a browser
plug-in. This D-to-C channel is also medium-sized, humanly
authenticated, and subject to eavesdropping. Finally, device of
type IV is capable of higher bandwidth communication with
the client C, e.g. via a WiFi or a Bluetooth channel. While such
channels could be authenticated by shared keys established in
the initialization process, having to bind device D with each
client terminal is not user-friendly, moreover any shared key
permanently residing on a browser would be subject to attacks.
We will therefore assume that such channel could be subject
to both eavesdropping and man-in-the-middle attacks.
TFA Protocol Syntax and Execution. A TFA scheme consists
of an algorithm Init and a three-party protocol Auth =
(AuthS, AuthC, AuthD) executed between parties S, C, and D.
We assume that server S keeps users’ authentication data in
a table indexed by user names. (Since we assume PKI, S
also has a public key pair and a certiﬁcate, but in the TFA
model we simply assume that the C-S communication goes
over a secure channel on which S is authenticated to C.)
Algorithm Init is executed separately for each user U on input a
security parameter 1⌧ , on an additional parameter t which ﬁxes
the upper-bound on the bit-length of D’s response message
resp, and on password p. Algorithm Init(1⌧ , t, p) outputs a
pair (stS, stD), where stS will be kept by server S under U’s
user name UN, and stD is securely loaded onto device D that
belongs to U. Note that we assume that the client C does not
have any permanent state. In our implementations (see Section
V), C is either a browser which downloads the authentication
protocol code AuthC it follows from the server S every time
the authentication protocol executes, or it is a browser plug-in,
but the cryptographic model assumes a state-free client.
Whenever user U wants to authenticate to S from her
browser C, C and S establish a secure connection using S’s
public key certiﬁcate, and over this connection U speciﬁes
her user name UN to S.1 S retrieves stS indexed by UN and
executes the interactive algorithm AuthS on local input stS,
communicating with C which executes an interactive algorithm
AuthC on local input p. In addition, at some point in its
interaction with S, algorithm AuthC can generate a single
message ch which will be received by D, and receive a single
response resp from D s.t. |resp| t, computed by algorithm
AuthD on inputs (ch, stD). (For device type I C’s message ch
to D is ﬁxed as a special sign ? which triggers D to compute
response resp but carries no further information.) Finally,
algorithm AuthS outputs a bit b which designates whether S
authenticates this user or not. The correctness requirement is
that for all ⌧, p, t values, if (stS, stD)   Init(1⌧ , t, p) then bit b
output by AuthS in an execution of (AuthS, AuthC, AuthD) on
respective local inputs (stS, p, stD), with all messages delivered
between the parties correctly, will be equal to 1 except for
probability negligible in ⌧.
Notes on the Timing Assumption. A TFA scheme can
additionally rely on a synchronized clock between device D
and server S, in which case algorithms AuthS and AuthD take
an additional time-encoding input, resp. TS and TD, and the
correctness property guarantees that b = 1 only if TS = TD.
We say that such TFA scheme is time-based. Alternatively to
1In most of our implementations U actually does not have to send UN to
S in this ﬁrst message. See the note at the end of Section IV.
the timing assumption, a TFA scheme could assume that both
D and S have an updatable storage, which in the simplest (but
sufﬁcient) case can be a strictly increasing counter. Such TFA
scheme can be called counter-based, where the correctness
requirement would guarantee authentication only if S and D
execute on the synchronized counter. We will not formally
model the security of counter-based TFA schemes, but it is a
plausible alternative to a time-based scheme.
TFA Adversarial Model. The adversary Adv who attacks
a (two-factor) password authentication system can have two
distinct goals. The ﬁrst goal is an authentication attack where
Adv breaks into the account of some innocent user U by
successfully authenticating to S under U’s user name. The
second goal is a password recovery attack where Adv learns
U’s password, for example in order to re-use it in some other
system where U uses the same password, as many real-life
users are known to do. The ﬁrst attack is sometimes called an
on-line attack, and the second an off-line dictionary attack, but
this terminology could be misleading because in both cases the
attacker has on-line access to the participating parties.
The adversarial ability to stage either attack must be
considered in a scenario which models adversary’s ability to
access, eavesdrop on, and even learn the private data of some
participating parties by a local corruption. Furthermore, we
must differentiate between (1) the case of a party corruption
(active or passive), where adversary (perhaps temporarily)
“resides” on this protocol party, steals its local data, and this
party becomes either an eavesdropping or a malicious agent
of the attacker, and (2) the case when adversary corrupts
a party, passively learns it’s private data, and then leaves.
For the second case we will consider leakage of the server’s
data stS, the device’s data stD, and the user’s password p.
However, for the case of player corruptions we will not
consider active corruptions of the server because we are in the
PKI model where the client trusts the server S it authenticates
via PKI certiﬁcates. In particular in all our TFA schemes if
an adversary does corrupt the server then it can learn the
passwords of all users who authenticate to the server while
such corruption lasts. Similarly we assume that client C runs
a trusted code (in practice C often downloads this code from
the same PKI-authenticated trusted server S). Indeed, if C runs
a corrupted code then the adversary can steal the password of
C’s user U. However, we do consider an active corruption of
the user’s device D, which we model by letting the adversary
steal D’s data and perform a man-in-the-middle attack on the
C-D communication.
We will make two further simplifying assumptions in the
security model: First, we will formally consider the password
recovery attack only for the adversary that (passively) cor-
rupts the server S. Conversely, we will formally consider an
authentication attack only if the adversary does not corrupt S.
However, it is easy to see that in all our TFA schemes the
adversary’s probability to recover the user’s password without
corruption of the server is the same as the probability of staging
an authentication attack. Secondly, in all of our schemes an
adversary who corrupts the server can stage an authentication
attack either with the same probability as the adversary that
does not, or it has to perform the same off-line computation
as we formally argue for the password recovery attack.
4
In our security notions below we consider the following
execution of an authentication game, denoted AuthTFA,Adv,
which takes as input a tuple (⌧, t, d, D, qS, qC, qD) (all w.l.o.g.
known to algorithm Adv) where D is an arbitrary set of size
2d and t is the bit-length of the device response resp in the
TFA scheme, and executes as follows:
1)
2)
3)
4)
5)
6)
First p is chosen uniformly at random in D and
Init(1⌧ , t, p) is executed to generate (stS, stD).
Adv can make qC client session queries, i.e. it can
interact with qC instances of the algorithm AuthC.
Each instance of AuthC will run on input p and
locally interact with algorithm AuthS running on
input stS and algorithm AuthD running on input
stD. Adv does not see the messages passed between
AuthC and AuthS, but it does see the messages passed
between AuthC and AuthD, and it learns a bit b output
by AuthS, which models the fact
that a network
adversary can tell whether the server authenticates the
user by observing the C-S trafﬁc. Additionally, Adv
has an option to replace message resp sent by AuthD
to AuthC with a message of Adv’s choice, in which
case we call such client session hijacked. (Modifying
the C-to-D message can be done via a device session
query, see below.) If Adv does not modify message
resp we call such client session eavesdropped.
Concurrently, Adv can make qD device session
queries, i.e. it can interact with qD instances of the
algorithm AuthD running on local input stD.
Concurrently, Adv can make qS server session
queries, i.e. it can interact with qS instances of the
algorithm AuthS running on local
input stS. We
distinguish between two types of server sessions: We
call it network-only if Adv completes it without an
interaction with any AuthD session, and we call it
with-device if between the moment it is triggered and
the moment that session completes Adv interacts with
any device session AuthD.
Adv can make server, device, and client
queries, on which it receives resp. stS, stD, and p.
Finally Adv outputs a bit-string p⇤ and the experiment
ends. We deﬁne the following two events:
  SuccP = 1 iff p⇤ = p [a password recovery attack];
  SuccA = 1 iff AuthS outputs b = 1 on any server
session query [an authentication attack].
leakage
If the TFA scheme is time-based we assume that throughout
the authentication game S and D execute AuthS and AuthD
protocols on TS and TD values which are equal to a global
time counter T , which starts from 1 and is incremented e.g.
every time the adversary triggers the AuthS protocol session.
If an adversary has lunch-time or viral access to D and can
move its clock forward or backward, this is equivalent to Adv
being able to make a “with-device” AuthS session.
Note that the above authentication game allows Adv to
interact qS times with the server S as a purported user client,
it allows Adv up to qD lunch-time accesses to the device D,
and it enables Adv to witness or interact with qC executions of
user U running an authentication protocol on an honest client C
with the server S. In such execution Adv has an eavesdropping
access to the C-D communication, but Adv can also stage a
man-in-the-middle attack between C and D, e.g. if it tricks the
user to use a modiﬁed device which runs some other code than
AuthD(stD), or if the C-D communication goes over a wireless
medium, and there is either no keys established between these
devices or if Adv learns these keys via a virus or a lunch-time
attack on C or D.
TFA Security Properties. As is standard for password au-
thentication schemes, we deﬁne security of a TFA scheme
assuming that the user chooses her password p uniformly at
random from some dictionary set D of size 2d. Since users
are known to pick passwords with only moderate entropy, we
must assume D is medium-sized, e.g. d is no more than 20 or
30, and in particular that it is feasible, and indeed easy, for an
adversary to iterate through the dictionary D. Another crucial
parameter for the security of a TFA scheme turns out to be the
bandwidth t on the D-to-C channel, i.e. the bit-length of D’s
response resp. We deﬁne the following two security notions:
Deﬁnition 1 (Authentication-Attack Resistance): We call a
TFA scheme (Init, Auth) (T,  N,  D,  C)-authentication-attack
resistant for parameters (⌧, t, d, qS, qC, qD) if for any D of size
2d and any algorithm Adv whose running time is bounded by T
the following holds for random execution of an authentication
game AuthTFA,Adv(⌧, t, d, qS, qC, qD):
1)
2)
3)
Pr[SuccA]  qS ·  N assuming that Adv is a network
adversary, i.e. it is precluded from server leakage,
client leakage, device leakage, and any with-device
server session queries;
Pr[SuccA]  qS ·  D assuming that Adv is precluded
from server leakage and client leakage queries (but
w.l.o.g. Adv makes device leakage or with-device
server session queries);
Pr[SuccA]  qS ·  C assuming that Adv is precluded
from server leakage, device leakage, and with-device
server session queries (but w.l.o.g. Adv makes a client
leakage query).
We call scheme TFA ( N,  D,  C)-authentication-attack re-