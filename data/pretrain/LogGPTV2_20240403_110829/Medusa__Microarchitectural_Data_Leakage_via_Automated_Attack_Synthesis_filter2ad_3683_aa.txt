title:Medusa: Microarchitectural Data Leakage via Automated Attack Synthesis
author:Daniel Moghimi and
Moritz Lipp and
Berk Sunar and
Michael Schwarz
Medusa: Microarchitectural Data Leakage via 
Automated Attack Synthesis
Daniel Moghimi, Worcester Polytechnic Institute; Moritz Lipp, 
Graz University of Technology; Berk Sunar, Worcester Polytechnic Institute; 
Michael Schwarz, Graz University of Technology
https://www.usenix.org/conference/usenixsecurity20/presentation/moghimi-medusa
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.Medusa: Microarchitectural Data Leakage via Automated Attack Synthesis
Daniel Moghimi1, Moritz Lipp2, Berk Sunar1, and Michael Schwarz2
1Worcester Polytechnic Institute, Worcester, MA, USA
2Graz University of Technology, Graz, Styria, Austria
Abstract
In May 2019, a new class of transient execution attack based
on Meltdown called microarchitectural data sampling (MDS),
was disclosed. MDS enables adversaries to leak secrets across
security domains by collecting data from shared CPU re-
sources such as data cache, ﬁll buffers, and store buffers.
These resources may temporarily hold data that belongs to
other processes and privileged contexts, which could falsely
be forwarded to memory accesses of an adversary.
We perform an in-depth analysis of these Meltdown-style
attacks using our novel fuzzing-based approach. We introduce
an analysis tool, named Transynther, which mutates the basic
block of existing Meltdown variants to generate and evaluate
new Meltdown subvariants. We apply Transynther to analyze
modern CPUs and better understand the root cause of these
attacks. As a result, we ﬁnd new variants of MDS that only
target speciﬁc memory operations, e.g., fast string copies.
Based on our ﬁndings, we propose a new attack, named
Medusa, which can leak data from implicit write-combining
memory operations. Since Medusa only applies to speciﬁc
operations, it can be used to pinpoint vulnerable targets. In
a case study, we apply Medusa to recover the key during
the RSA signing operation. We show that Medusa can leak
various parts of an RSA key during the base64 decoding
stage. Then we build leakage templates and recover full RSA
keys by employing lattice-based cryptanalysis techniques.
1
Introduction
Microarchitectural side channels have been known for more
than a decade, with attackers mostly focusing on leaking
memory access patterns through shared CPU resources [48].
These side-channel leakages can be used to compromise spe-
ciﬁc secrets such as cryptographic keys [28, 63]. However, in
2018 a new generation of microarchitectural attacks, includ-
ing Meltdown [39] and Spectre [35] changed the perspective
by introducing data leakage from the CPU. These new attacks,
under the taxonomy of transient-execution attacks, rely on ex-
tracting secrets that are only visible in transient states within
the CPU [11]. Compared to previous side-channel attacks, the
signiﬁcant impact of transient-execution attacks is that they
can leak actual data bits instead of access patterns.
Spectre attacks [21, 34, 35, 37, 40] miss-train branch pre-
dictors into executing control paths that might not be taken
by the architecture. Meltdown-style attacks [10, 39, 50, 52,
56, 57, 58] exploit the heavily optimized out-of-order load
operations in which faulting memory loads still proceed with
stale or illegal data. In both cases, the microarchitecture may
access secrets across security boundaries. These secrets, never
architecturally visible, can be transmitted via a covert channel,
e.g., using Flush+Reload [63]. Canella et al. [11] proposed a
taxonomy to classify transient-execution attacks based on the
cause of the transient-instruction sequence and the exploited
microarchitectural buffer. While this classiﬁcation captures
the cause and targets of known variants in a structured way, it
does not provide enough information on how a certain attack
can be carried out. For most Meltdown attacks, there are mul-
tiple ways to trigger the leakage, e.g., some attacks seem to
require TSX to enable the leakage [25, 52], while others can
also leverage signal handlers or miss-speculation [10, 39].
Meltdown-type attacks exploit special events in the mi-
croarchitecture, which require so-called microcode assists.
Microcode assists execute software routines in the CPU to
handle operations which cannot be directly handled in hard-
ware, e.g., certain faults, or updating bits in page-table entries.
For some Meltdown attacks, microcode assists have enabled
new variants [10, 52]. In this paper, we propose a systematic
approach for evaluating data leakage due to the combination
of microcode assists caused by a load with dependent opera-
tions. To achieve this goal, we propose Transynther1, a tool
to automatically generate and test the combination of known
building blocks for Meltdown attacks with various faults and
microcode assists. Furthermore, we use fuzzing-type tech-
niques to mutate, evolve, and combine building blocks. Tran-
synther can automatically evaluate whether the newly synthe-
1 Transynther tool and Medusa attack code are available as an open-source
implementation on GitHub: https://github.com/vernamlab/Medusa
USENIX Association
29th USENIX Security Symposium    1427
sized code variants are indeed a variant of a Meltdown attack
by trying to leak predeﬁned values.
We automatically generated thousands of different com-
binations using Transynther. Transynther reproduced Melt-
down [39], ZombieLoad [52], RIDL [58], Fallout [10] (MS-
BDS), Store-to-Leak (S2L) [50], Spectre v1.2 [34], and Mi-
croarchitectural Load Port Data Sampling (MLPDS) [24].
Furthermore, with Transynther, we synthesized multiple new,
previously unknown variants to trigger these attacks. Con-
sequently, by analyzing the generated variants, we gained
additional insights into Meltdown-type attacks. We identi-
ﬁed that the root cause of all known Meltdown-type attacks
is that an aborted load operation simply consumes any data
which can be fetched ﬁrst, and provides them to dependent
operations.
In addition to reproducing known attacks, Transynther also
discovered new variations of MDS variants, which we refer
to as Medusa. Medusa provides more in-depth insight into
how the memory subsystem is implemented in Intel microar-
chitectures. Medusa speciﬁcally targets data values which
are transferred via the common data bus but are not normal
data loads. In addition to AVX2 loads, Medusa has the unique
property to observe the inner workings of implicit write com-
bining (WC) used by the CPU, e.g., fast string operations such
as rep mov. For WC, the CPU allocates parts of the line-ﬁll
buffer to combine multiple stores to the same cache line to
increase the throughput. In contrast to ZombieLoad [52] and
RIDL [58], which leak arbitrary data from the line-ﬁll buffer,
Medusa speciﬁcally targets data transfers caused by WC.
With Medusa, the leakage is extremely targeted and noise-
free, as only speciﬁc loads are leaked. Thus, while the property
to only leak data from WC sounds like a limitation, it is an
advantage over previous data-sampling attacks. Where data-
sampling attacks such as ZombieLoad [52] or RIDL [58]
require extensive post-processing to ﬁnd the target data within
the leaked data, Medusa does not leak such large amounts of
unrelated data in the ﬁrst place. This is especially important as
ZombieLoad and RIDL, in practice, leak too many unrelated
data when they are applied to applications that perform a long
sequence of operations. For instance, in our case study on
RSA, the computation steps, including loading the key from
the disk and performing the RSA signing operations, consists
of thousands of load operations that may not be interested for
an attacker to be leaked. In a case study, we use Medusa to
steal private RSA keys loaded in OpenSSL. This attack takes
at most 7 minutes during the online phase. By leaking various
blocks of the RSA private key, we can employ lattice-based
cryptoanalysis techniques to recover the entire key.
Finally, we discuss how the current mitigations against
MDS attacks apply to Medusa. We show that currently,
Medusa cannot be prevented if hyperthreading is enabled.
Hence, we stress that hyperthreading has to be disabled to
entirely prevent Medusa.
To summarize, we make the following contributions:
L2 Cache
Core
Memory
Core
Memory
LFB
WCB
L1
Shared L3 Cache
Store Buffer
Load Buffer
Memory Order Buffer
Core
Memory
Core
Memory
Figure 1: The ﬁll buffer serves memory accesses that miss the
L1 cache. The WC buffer is a part of the ﬁll buffer optimizing
multiple store operations that target the same cache line.
1. We introduce a new open-source tool, Transynther, to
analyze the CPU microarchitecture for Meltdown-style
vulnerabilities.
2. We provide insight into the root cause of Meltdown at-
tacks and disclose new exploitation methodologies.
3. We introduce the Medusa attack, exploiting implicit write
combining of memory store operations, e.g., rep mov.
4. In a case study, we use Medusa to recover RSA keys from
OpenSSL by exploiting leakages during key decoding.
Responsible Disclosure. We disclosed our initial ﬁnding to
Intel on June 24, 2019. Intel conﬁrmed that the WC is part of
the ﬁll buffer. The paper was under embargo until November
12, 2019, as we exploit TSX Asynchronous Abort (TAA, CVE-
2019-11135) [25] in several proof of concepts.
2 Background
2.1 Superscalar Memory Architecture
Modern CPUs have multiple levels of caches and buffers to
mitigate the speed gap between execution units and the main
memory. Figure 1 illustrates the memory components on the
data path of an Intel processor. The last level cache (LLC)
which is shared across CPU cores is connected through an
interconnect bus to the main memory. Further, each core has
an L1 and L2 cache, consisting of multiple cache lines which
are usually 64 B. When the processor accesses data that is
not present in a cache level (cache miss), the corresponding
cache line is fetched from the next level of cache or the main
memory. The processor also uses a ﬁll buffer to service mem-
ory accesses missing in the L1 cache. The data in the ﬁll
buffer can be forwarded to memory loads before ﬁlling the
entire cache line. ZombieLoad [52] and RIDL [58] showed
that Intel processors may falsely forward data that resides in
the ﬁll buffer from a benign to a malicious load.
Memory operations are executed out of order and specu-
latively. The processor may execute a load before preceding
stores to avoid pipeline stalls due to the potential dependency
of the load on stores. The store buffer, as part of the memory
order buffer (MOB), temporarily holds the data and metadata
for stores before committing them to the cache. The CPU may
1428    29th USENIX Security Symposium
USENIX Association
forward data from the store buffer to a load (store-forwarding).
The CPU may fail to predict correct dependencies between
the load and stores [30, 46]. While such failures are ﬁnally
resolved before committing the results, it facilitates transient
execution attacks [10, 21, 50].
Memory Types. CPUs support multiple per-page memory
types with different policies for caching and ordering guar-
antees. The supported memory types on x86 are write-
back (WB), write-through (WT), write-protect (WP), write-
combining (WC), and uncachable (UC). Most pages are write-
back, which allows them to be cached and written back to
the memory at a later point. Both UC and WT write data
directly to memory. Write-combining memory, as discussed
later on, tries to reduce the number of bus requests by com-
bining multiple writes to the same cache line into a single
request.
2.2 Write Combining
A memory store has to update core-private caches, the LLC,
and possibly the main memory. Thus, for performance, it is
beneﬁcial to combine multiple stores into a single request.
This reduces the number of bus requests and cross-core snoops
that update the core-private copy of the cache. Employing
write combining (WC), the CPU temporally holds the data of
store operations to the same cache line in an internal buffer,
until all the data bytes that modify that cache line are available.
The WC buffer can be either implemented as a dedicated
component as in AMD CPUs [1] or as part of the ﬁll buffer
as in Intel CPUs [27]. WC is often used for memory where
memory ordering guarantees are weak, e.g., for frame buffers
of graphic cards, which are usually treated as write-only by
programmers [22].
2.3 Advanced CPU Features
Simultaneous Multithreading. Simultaneous multithread-
ing (SMT) allows multiple threads to execute on the same
core simultaneously while sharing the same resources. These
threads are architecturally isolated from each other accord-
ing to memory protection semantics and only access their
intended data. This allows one thread to use the available
resources not used by other threads.
Intel Hyperthreading technology implements SMT by shar-
ing the core between two simultaneous threads, logical CPUs.
These logical CPUs share some of the resources such as the
store buffer in a compartmentalized fashion where the re-
source is halved into two separate sections upon activation of
the second thread. Other resources, such as the ﬁll buffer, are
time shared. Intel Hyperthreading has suffered from various
microarchitectural side channels due to the time-sharing of
resources such as translation look-aside buffer (TLB) [17] and
execution ports [2]. MDS attacks demonstrated data leakage
due to sharing of various buffers within the core [24, 52, 58].
Transactional Memory. Intel Transactional Synchronization
Extension (TSX) implements Hardware Transactional Mem-
ory by extending the instruction set with a new set of barriers
in which application developers can deﬁne a block of code
as atomic by surrounding it with the xbegin and xend in-
structions. The CPU only commits the results of a transaction
if the entire block executes successfully. TSX transactions
are aborted on conﬂicting cache and memory operations that
may affect the atomicity of the transaction, as well as on
interrupts. Intel TSX has been exploited for both attack and
defense [18, 31, 51]. In Meltdown attacks, TSX can be abused
as a silent event suppression mechanism that may enable fur-
ther leakages (cf. Section 2.4).
2.4 Microarchitectural Attacks
Flush+Reload. Flush+Reload [63] exploits the difference in
memory-access times for cached and uncached shared mem-
ory pages. In a Flush+Reload attack, the attacker ﬂushes the
cache line for a shared memory address using the clflush
instruction and subsequently measures the access time to
the memory. If the execution time is high, the data has not
been cached. However, if another execution context accesses
the address, the attacker observes a low access time as the
data is cached. Flush+Reload has been used to attack cryp-
tographic implementations [5, 20, 29] as well as to spy on
user’s behavior [19, 38, 64]. As in previous meltdown-type
attacks [39, 52, 57], we use Flush+Reload as a covert channel
from the microarchitectural to the architectural domain.
Transient-Execution Attacks. Modern CPUs employ out-
of-order and speculative execution to increase performance.
With out-of-order execution, CPUs can execute instructions
further in the instruction stream as long as their dependencies
are satisﬁed. Similarly, speculative execution enables a CPU
to guess the outcome of a conditional branch to continue
executing the most likely path.
If an instruction which was executed out of order or specu-
latively was wrongly executed, this instruction is simply not
committed to the architectural state. However, the instruction
might have had a side effect on the microarchitectural state,
such as the cache. In this case, such an instruction is called a
transient instruction [11, 35, 39]. Transient-execution attacks
exploit such transient instructions to leak data and are divided
into Meltdown-type and Spectre-type attacks [11].
transient
instruc-
tions caused by wrongly predicted conditional branches, in
Meltdown-type attacks, the attacker leverages out-of-order
execution following a faulting load. The transient instructions
after the faulting load still have access to the data and can
encode it into the microarchitectural state [10, 39, 50, 52, 53,
57, 58, 61]. Using a covert channel, such as Flush+Reload,
the attacker can then bring the microarchitectural state to the
architectural state, ultimately leaking the secret.
While Spectre-type attacks exploit
USENIX Association
29th USENIX Security Symposium    1429
P1: Synthetisation
P2: Evaluation
P3: Classiﬁcation
Meltdown
Random
Instruction
RIDL
Fallout
Mutate
l
a
i
t
n
e
t
o
P
n
w
o
d
t
l
e
M
e
c
n
e
u
q
e
S
e
d
o
C
ZombieLoad
0
Execute
Code
Leakage
1
o
t
d
n
e
S
n
o
i
t
a
c
ﬁ
i
s
s
a
l
C
Performance
Counters
Evaluate
Manual
Analysis
Figure 2: Transynther phases: After mutating a new code
sequence for a meltdown-style attack, the code is evaluated.
If there is a leakage detected, the sample is analyzed further
during the classiﬁcation phase.
3 Automatically Exploring Meltdown
Attacks
We introduce Transynther, an automated approach for ex-
ploring Meltdown-type attacks. Transynther uses an innova-
tive techniques based on fuzzing to systematically explore
Meltdown-type attacks. The aim is to identify new variants of
existing attacks, which are, e.g., faster, less complex, or are
not mitigated, as well as entirely new Meltdown-type variants.
Transynther works in three phases, as outlined in Figure 2.
In the ﬁrst phase, the synthetisation phase, Transynther uses
building blocks of existing attacks to mutate and combine
them to potential new attacks. In the second phase, the eval-
uation phase, Transynther executes the code from the syn-
thetisation phase and evaluates whether the code leads to data
leakage. Finally, if the evaluation phase was successful, the
classiﬁcation phase tries to automatically classify the source
of the leakage using performance counters.
3.1 Synthetisation Phase
The ﬁrst phase is the synthetisation phase. In this phase,
Transynther generates a code snippet, which is a potential
Meltdown-type attack. For this, Transynther relies on building
block from existing Meltdown-type attacks, including Melt-
down [39], ZombieLoad [52], RIDL [58], Foreshadow [57],
Fallout [10], Meltdown-PK [11], Meltdown-AVX [24], and
Meltdown-RW [34].
The common pattern for all these attacks is as follows:
1 Preparing the microarchitectural state (e.g., ﬂushing, ac-
cessing, or storing data).
2 Executing a load operation causing a fault
(as
Schwarz et al. [52], we consider microcode assists as
microarchitectural faults).
3 Consuming the loaded data with dependent instructions
and encoding it in a microarchitectural element.
As the encoding in 3 does not affect the root cause of a
Meltdown-type attack [39, 56], we always encode the loaded
value in the cache, which allows us to recover the encoded
values using a Flush+Reload covert channel. This approach is
used in the majority of Meltdown-type attacks [10, 11, 34, 39,
52, 53, 57, 58, 61]. Initially, Transynther sets up two pools
to be used in 2 . One pool contains possible load operations
and one contains possible load targets:
Load operations. Memory Loads are operations that load
data from memory addresses into registers. The simplest
load operation is a mov from a memory address to a general-
purpose register. Transynther supports mov with all possible
sizes, from 8 bits to 64 bits. Additionally, aligned and un-
aligned AVX loads ({v}movaps/{v}movups) with a size of
128 and 256 bits are supported.
Load targets. Load targets are virtual addresses with a sys-
tematic pattern of different setup of the page-table entry,
as discussed by Canella et al. [11]. As a starting point, we
rely on load targets with certain page-table bits, which were
already used for Meltdown-type attacks. This includes the
user-accessible bit [39, 52], accessed bit [10, 52], present
bit [10, 57, 58, 61], writable bit [34], and protection key [11].
For a systematic approach, we also add load targets with page-
table bits that have not been used in successful Meltdown-type
attacks, including the dirty bit, write-through bit, uncachable
bit, size bit, and non-executable bit. Finally, we also add ad-
dresses that do not have a valid mapping to physical pages,
such as non-canonical addresses (addresses where the bits 48
to 63 are different than bit 47, e.g., 0x1234567812345000)
and physically unmapped addresses, e.g., NULL.
Furthermore, Transynther creates a victim that injects