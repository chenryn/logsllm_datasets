### 优化后的文本

#### 公式 (7)
\[ p(x) \cdot [P_{Hf|Ms}(x)P_{Ms}(x) + P_{Hf|Mf}(x)P_{Mf}(x)] \]
(7)

我们没有展示“并行检测”情况下的类似推导，该情况将导致公式 (3) 用于检测任务。

#### 模型参数
所描述的模型对每个可能的情况都有三个参数。由于每个情况在某些方面都与其他情况不同，估计这些参数是不可行的。可以做的是为相似需求类别估计失败概率。因此，在系统的受控试验中，我们首先将情况划分为不同的类别。公式 (7) 仍然有效，如果我们将每个 \( x \) 解释为代表一类需求：

\[ P_{Hf} = \sum_{x \in \{\text{classes of cases}\}} p(x) \cdot [P_{Hf|Ms}(x)P_{Ms}(x) + P_{Hf|Mf}(x)P_{Mf}(x)] \]
(8)

对于每一类情况，我们需要估计参数 \( P_{Hf|Ms}(x) \), \( P_{Ms}(x) \), 和 \( P_{Hf|Mf}(x) \)。我们认为两个需求属于同一类，如果它们在所有显著影响正确处理难度的方面都是等价的，无论是对读者还是 CADT 算法而言。即，这两类需求在产生失败概率方面实际上是无法区分的：同一类中的所有需求具有类似的 \( p_{Mf}(x) \), \( p_{Hf|Mf}(x) \), 和 \( p_{Hf|Ms}(x) \) 值。实际上，我们会尝试根据易于识别且能产生可行小数量类别的特征来分类情况。

#### 从受控试验到实际应用的外推
在决定是否在新环境中采用 CADT 或对其设计进行更改时，需要依赖在不同于预测条件下的测量结果。例如，测量可以在受控试验中进行，而该试验可能因必要性而在与实际临床使用不同的条件下（特别是不同的需求分布）运行。公式 (8) 是这种外推的关键：

\[ P_{Hf} = \sum_{x \in \{\text{classes of cases}\}} p(x) \cdot [P_{Hf|Ms}(x)P_{Ms}(x) + P_{Hf|Mf}(x)P_{Mf}(x)] \]

CADT 使用条件或其特性的变化可以通过改变该公式中的参数值来表示。首先考虑这些变化的直接影响，例如：

1. 各种类型案例的频率可能会发生变化。只要找到一个有用的分类方法，使得公式 (8) 成为错误决策概率的合适描述，这些变化就可以通过改变参数 \( p(x) \)（每个类别 \( x \) 一个）来表示。
2. 读者的能力水平不同（由参数 \( P_{Hf|Ms}(x) \) 和 \( P_{Hf|Mf}(x) \) 表示）。试验数据可以指示这些能力的范围，显示人类之间是否存在显著差异，以及这些差异是否对不同类型的需求有不同影响。
3. 随着读者对 CADT 行为的了解增加，他们的行为（即 \( P_{Hf|Ms}(x) \) 和 \( P_{Hf|Mf}(x) \)）会随时间演变，例如变得更加依赖 CADT 的提示，或者更加熟练地检测其失败。
4. CADT 的成功或失败概率 \( P_{Ms}(x) \) 和 \( P_{Mf}(x) = 1 - P_{Ms}(x) \) 可能会因维护实践、系统差异、更好的检测算法、检测算法的不同调优等因素而发生变化。

还可能存在间接影响。例如，癌症（或不同类型的癌症）在病例人群中的流行率发生足够大的变化（上述列表中的第 1 项），可能会改变读者的失败概率 \( P_{Hf|Ms}(x) \) 和 \( P_{Hf|Mf}(x) \)。为了猜测这些变化的幅度范围，我们需要依赖于类似任务中人类行为的测量结果。方程将显示预测系统失败概率的不确定性范围。另一个例子是，改变 CADT 失败的频率 \( P_{Mf} \) 可能会影响读者在其输出基础上做出自己决策的倾向，从而间接改变 \( P_{Hf|Ms}(x) \) 和 \( P_{Hf|Mf}(x) \)。同样，改变 CADT 的假阳性失败概率（本文未考虑）也可能影响读者对它的信任程度。

关于读者对 CADT 失败的适应，参见文献 [6]，其中引用了先前的相关文献。其他来自认知和人机交互研究的文献（如 [4, 10]）也可以为这些变化提供信息。

#### 数值示例
现在我们通过一个数值示例来说明一些这些外推步骤。使用的参数值不一定代表任何实际 CADT 的性能，但它们的数量级是现实的，并且它们在不同类别情况之间的变化也是现实的。重要的是要考虑失败概率对需求类型的影响。在这个示例中，我们假设基本上只有两类情况，标记为“简单”和“困难”。实验者在一个试验中获得了以下模型参数估计值。为了简化起见，假设所有参数都可以获得足够窄的置信区间。

| 类别 | 容易 | 困难 |
| --- | --- | --- |
| 试验 | PMf: 0.07, PMs: 0.93, PHf|Mf: 0.9, PHf|Ms: 0.18 | PMf: 0.14, PMs: 0.86, PHf|Mf: 0.1, PHf|Ms: 0.4 |
| 实际 | PMf: 0.41, PMs: 0.59, PHf|Mf: 0.9, PHf|Ms: 0.18 | PMf: 0.4, PMs: 0.6, PHf|Mf: 0.1, PHf|Ms: 0.4 |

两类情况分别占 80% 的“简单”和 20% 的“困难”。假设实际比例是 90% 对 10%。显然，为了预测实际中的失败概率，需要调整这种不同的“需求分布”。

下表显示了试验和实际中观察到的可靠性之间的差异。到目前为止，我们不需要完整的模型来识别机器和人在系统失败中的角色；我们所做的只是在最后一行中使用加权和来计算两类情况下系统失败的概率。

| 类别 | 容易 | 困难 | 所有情况 |
| --- | --- | --- | --- |
| 试验 | 0.143 | 0.605 | 0.235 |
| 实际 | 0.143 | 0.421 | 0.189 |

假设设计师希望改进 CADT，减少其假阴性失败的概率。他们希望能够预测这种改进对人机系统可靠性的影响，并决定应该在哪里集中改进努力。除了成本约束外，对于模式检测问题，通常可以通过接受相应的假阳性失败增加来大大降低（无论是对人类还是自动化算法）假阴性失败的概率。然而，后者可能会使 CADT 无用。我们的假设设计师考虑了两种改进 CADT 的方案：一种是将“容易”（且频繁）情况下的失败概率 \( P_{Mf} \) 减少 10 倍，另一种是将“困难”（且罕见）情况下的失败概率 \( P_{Mf} \) 减少 10 倍。下表给出了这两种方案在“试验”和“实际”需求分布下的结果：

| 类别 | 容易 | 困难 | 所有情况 |
| --- | --- | --- | --- |
| 改进容易情况 | 0.140 | 0.605 | 0.233 |
| 实际 | 0.143 | 0.421 | 0.187 |
| 试验 | 0.140 | 0.605 | 0.198 |
| 实际 | 0.143 | 0.421 | 0.171 |

在两种需求分布（试验和实际）下的失败概率不同，这是预期的结果。至于减少 CADT 在“容易”或“困难”情况下的失败概率的效果，我们看到两者都没有带来很大的改进（与上表的最后一行相比）。“容易”情况是大多数，因此可能会认为减少这些情况下的 CADT 失败概率 10 倍会大大改善整体情况。然而事实并非如此。对于“实际”分布，失败概率仅降至 0.187，而未改进的 CADT 为 0.189。原因在于这些情况下 \( P_{Hf|Mf} \) 和 \( P_{Hf|Ms} \) 的值差异很小，仅为 0.04。尽管改进后的 CADT 更频繁地给出正确输出，但这并没有显著影响读者在这些情况下的表现。

相比之下，“困难”情况下的 \( P_{Hf|Mf} - P_{Hf|Ms} \) 差异更大，因此减少这些情况下的 CADT 失败概率带来了更大的整体失败概率改进（“实际”分布：0.171 vs 0.189；“试验”分布：0.198 vs 0.235）。

这个示例展示了模型的一些特性，我们将在下一节中讨论。

### 人机交互分析
#### 重要性指数
如果我们定义 \( t(x) = P_{Hf/Mf}(x) - P_{Hf/Ms}(x) \)，我们可以重写公式 (8) 为：

\[ P_{Hf} = \sum_{x} p(x) \cdot [P_{Hf|Ms}(x)P_{Ms}(x) + P_{Hf|Mf}(x)P_{Mf}(x)] \]
\[ = \sum_{x} p(x) \cdot [P_{Hf|Ms}(x)(1 - P_{Mf}(x)) + P_{Hf|Mf}(x)P_{Mf}(x)] \]
\[ = \sum_{x} p(x) \cdot [P_{Hf|Ms}(x) + P_{Mf}(x) \cdot t(x)] \]
(9)

这表明读者失败（假阴性决策）的概率等于在 CADT 给出正确输出时他/她失败的概率，加上 CADT 未能给出正确输出（失败）的概率乘以一个项 \( t(x) \)。

项 \( t(x) \) 似乎是一个有用的通用度量，用来衡量自动化系统提供的决策支持如何影响人类用户的成功或失败。\( t(x) \) 是一个“重要性指数”。