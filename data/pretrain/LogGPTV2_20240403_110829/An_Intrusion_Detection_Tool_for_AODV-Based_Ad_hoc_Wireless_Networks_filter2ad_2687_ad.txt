immediately, causing the monitor to assume that the
packets have been dropped; allowing a reasonable
timeout period for retransmission reduces such
cases. Also, each packet thus buﬀered on a neighbor
node corresponds to the same packet being buﬀered
by the monitoring node. In other words, each
packet being watched accounts for memory con-
sumed on the monitoring node, while the monitor-
ing node waits for it to be retransmitted. A large
number of neighbors buﬀering packets cause a sig-
niﬁcant aggregation of such packets on the monitor-
ing node itself, which occupy memory until they are
timed out. Not only will they result in false posi-
tives, they will also have occupied a large amount
of memory on the monitoring node, and ﬁnally
yielding possibly incorrect results. Deeming packets
as ‘‘dropped,’’ only after a timeout period, frees up
memory in a reasonable amount of time, for moni-
toring newer packets, and reducing the overall
memory requirements for monitoring, and at the
same time minimizes false positives due to transient
periods of congestion.
Consider the three relative movements of node C
with respect to A and B, B being monitored, as
shown in Fig. 3. The relative movement of the mon-
itoring node with respect to its neighbors can cause
false positives. In (i)–(iii) C is moving left horizon-
tally monitoring B. When it gets out of range of
B, it will continue to hear packets sent by A to B
to be forwarded, but is out of range of B. Initially
these will be registered as packets drops by B, how-
ever, the neighbor table will soon be updated since
Hello messages from B will no longer be heard.
The timeout periods are always chosen to be more
than the Hello message intervals, thus accounting
for such situations. In (a)–(c) the movement is
Fig. 3. Eﬀects of mobility on IDS results.
towards B and away from A. So there will be no
intrusions detected, since A will go out of range
ﬁrst. In (1)–(3) the movement is perpendicular and
equidistant from A and B. Trivially, C can hear
both A and B or none, so there cannot be any false
positives.
5.7. IDS validation
To test the IDS functionality, we setup a node
that could drop and/or mangle packets. This was
done using the Linux kernel modules ip6table_
mangle and ip6_queue (userspace packet queu-
ing using libipq). Perlipq [39], a Perl extension
to Linux iptables for userspace queuing via libipq
was used. The process involves adding a rule to
ip6tables to intercept all packets to be for-
warded by the node, to be queued to userspace. Per-
lipq then allows these packets to be manipulated by
the Perl program and then passed back to the ker-
nel. The Perl program can mangle the payload, drop
the packet or return it without modifying it.
Using the Perl program we conﬁgured the mali-
cious node to have particular drop rates. The IDS
immediately detected the dropped packets and
reported them. If the drop rate exceeded the thresh-
old value of the IDS, the IDS reported an intrusion
and logged the incident. We observed that under
normal traﬃc conditions hardly any packets are
dropped by intermediate nodes when they are for-
warding packets.
6. Prototype performance analysis
In our implementation, we used wireless cards
that support the Prism2 chipset. We primarily used
iPAQs in our testbed (speciﬁcations are provided in
table 4(a)). We used the ping6 utility for sending
ICMP6 echo requests to determine reachability
and response times. We setup the iPAQs in a linear
chain using ip6tables to drop packets from spe-
ciﬁc MAC addresses at each node, to achieve this
linear chain without physically separating the
iPAQs out of radio range to get such a formation.
The results of the ping tests are shown in Fig. 5.
The AODV parameters used in the tests are shown
in table 4(b).
Referring to Fig. 5, the response times of ping6
packets are shown for destinations that are 1, 2 and
3 hops away. The ﬁrst column labeled Basic AODV
shows the response time of the AODV implementa-
tion that we used to build the secure version with
590
A. Patwardhan et al. / Ad Hoc Networks 6 (2008) 578–599
Fig. 4. Device details and parameters used in the testbed: (a) iPAQ speciﬁcations and (b) SecAODV parameters.
security features like signature veriﬁcation turned
oﬀ, but using the additional SecAODV header is
shown. Finally the last column indicates
the
response time of SecAODV with all the security
features enabled.
We note that the HUT AODV implementation
[35] was tested in the AODV Interop Event [40] with
only two hops. We got 100% packet loss with ping6,
with more than two hops using HUT AODV. We
ﬁxed some of these problems, and used that as the
basis for SecAODV. Column 1 in Fig. 5 enumerates
the response times for the ﬁxed version, sans the
security features and column 2 enumerates those
for SecAODV. In SecAODV, route caching is dis-
abled for security reasons and thus suﬀers a perfor-
mance setback compared to the non-secure version.
Fig. 5. Ping6 response times in seconds using basic AODV
version and SecAODV.
Comparing columns 1 and 2 in Fig. 5 we can
observe that SecAODV does not signiﬁcantly add
to the routing overhead and/or cause packet loss
as compared to the insecure version. We observed
a large packet loss of ICMP6 packets in the original
version. SecAODV however does not further add to
the packet loss, the packet loss remained exactly the
same, though the response times can be seen to be
increasing slightly owing to the additional computa-
tions of encryption and decryption. With faster pro-
cessors and larger memories the decryption and
signature veriﬁcation will be much faster.
The apparent improvement in the response times
in SecAODV (see Fig. 5), in the case of 3 hops is an
anomaly, which we attribute to the limitations of
the measurement process and the instability of the
prototype software. Nevertheless, these results show
that the additional eﬀort of signature veriﬁcation
process in SecAODV does not adversely aﬀect the
routing process even on handheld devices with
severely constrained memory and computation
power (see Fig. 4a).
The source code for SecAODV and the MANET
IDS is available for download under the UMBC
GNU Public License [7,8].
Fig. 6a shows the data rates for encryption and
decryption data rates using diﬀerent RSA keylengths.
Fig. 6b shows key generation time for RSA keys.
7. Large scale IDS simulation
We used Glomosim 2.02 [41] to simulate a large
scale deployment of a MANET with IDS nodes
deployed in it. Node placement and travel was
restricted to a 150 m · 150 m area. 802.11 was chosen
A. Patwardhan et al. / Ad Hoc Networks 6 (2008) 578–599
591
We then repeated the experiments with the same
setup but replacing CBR by TCP ﬂows.
We used the Random Waypoint Model
for
movement of the nodes, with a maximum speed of
5 m/s, minimum speed of 1 m/s, and maximum
pause time of 15 s. Individual movement of nodes
was speciﬁed in a trace ﬁle generated by BonnMo-
tion 1.1 [43]. Use of the trace ﬁle allows for result
correlation between tests, since nodes take identical
paths for each test in which they participate. Com-
plete parameters for the Glomosim simulation and
the mobility trace ﬁles used for the scenarios are
available online [44].
Maintaining the same initial starting positions
for the existing nodes, the same mobility and traﬃc
patterns, we studied the eﬀect on neighbor table
size, packets processed by IDS nodes, collisions,
dropped packets, alarms generated, true positives,
and false positives.
In each scenario, the same 25 IDS node observa-
tions are presented in the graphs below. The total
number of nodes for the tests was varied from 100
to 300, with malicious nodes increasing from 10%
to 50% of total nodes in increments of 10 percentage
points. Bad nodes were conﬁgured to drop all data
traﬃc yet participate correctly in the AODV routing
process (grey holes). The bad nodes drop any traﬃc
they are supposed to relay once included in the traf-
ﬁc path from sender to receiver.
Fig. 7a shows the mean neighbor table size as the
total number of nodes is increased. Neighbor table
size can be seen to grow from approximately 20
neighbors per node when total nodes are 100, to a
neighbor table size of 100 when the number of
nodes grows to 300. The growth in the neighbor
tables is seen to be linearly proportional to the total
number of nodes, as the density increases.
Fig. 7b shows the mean packet drop rates
observed by the IDS nodes for 0 to 50 percent
bad nodes, with increasing number of participating
nodes. It can be observed from Fig. 7b that even
the case with no bad nodes present, around 5 pack-
ets on average are observed as dropped regardless
of an increase in the number of nodes. Such
observed loss can be attributed to noise, transmis-
sion errors, congestion, other environmental condi-
tions, and to the mobility of the devices. We use
this as our base case and accordingly set our detec-
tion threshold for the simulations to 5 packets per
sampling interval. Alarms are raised only if this
threshold is exceeded. Post processing is done to
classify the alarms into true positives (correctly
Fig. 6. RSA computations: (a) data rates for encryption and
decryption using RSA keys and (b) RSA key generation time.
as the MAC layer protocol with each node having
a range of approximately 30 m; no fading model
was used. AODV was used as the routing protocol,
and simulation times for each test was ﬁxed to
300 s. Application traﬃc generated was the same
for all tests. We followed the same traﬃc patterns
used by Marti et al. [5], originally used by Broch
et al. for performance comparisons of AODV and
other routing protocols [42].
Brieﬂy, the application traﬃc consisted of 10
constant bit rate (CBR) connections. Four of the
nodes were sources of 2 CBR streams each, and
two more with one CBR stream originating from
them. Ten other nodes distinct from the sources
served as the endpoints of those 10 CBR streams
(a slight variation from [42] where there are only 9
receiver nodes, one of them with two CBR end-
points). The data rate for each connection in the
simulation was 1 packet every 2 s, with a payload
size of 512 bytes.
592
A. Patwardhan et al. / Ad Hoc Networks 6 (2008) 578–599
0%
10%
20%
30%
40%
50%
150
200
No. of nodes
250
300
0%
10%
20%
30%
40%
50%
a
110
100
t
n
u
o
C
90
80
70
60
50
40
30
100
b
30
t
n
u
o
C
25
20
15
10
5
100
150
200
No. of nodes
250
300
Fig. 7. Growth of neighbor tables sizes and dropped packets observed: (a) mean neighbor table size and (b) mean drops observed by IDS
nodes.
identiﬁed malicious drops), and false positives
(packets dropped for other
reasons). Dropped
packet data from the bad nodes is used for the
classiﬁcation.
A. Patwardhan et al. / Ad Hoc Networks 6 (2008) 578–599
593
Fig. 8a and b show the mean packet processing
eﬀort over the 25 IDS nodes for CBR and TCP traf-
ﬁc respectively. It can be observed that the number
of packets processed decreases as the percentage of
bad nodes (grey holes) is increased. With more
nodes dropping data packets overall throughput
decreases reducing the eﬀort for the IDS nodes in
detecting intrusions. Thus detecting grey holes
requires much less eﬀort. However in the case of
nodes mangling (modifying) data packets, there will
be no decrease in eﬀort per IDS node, since all
packets are retransmitted with possible modiﬁca-
tions. In our current simulation bad nodes act as
grey holes.
From Fig. 7a, mean neighbor table size for 100
nodes is around 20, and increases to up to 100 for
300 total nodes. With light traﬃc conditions like
those used in the CBR simulations (Fig. 8a), the
mean number of packets required to be processed
by an IDS node per sampling interval (10 s)is seen
to be fairly low, and decrease with increase in num-
ber of bad nodes, which is a manageable number
even for resource-constrained devices. Possible tech-
niques for handling situations when high through-
put overwhelms devices have been discussed in
Section 5.5.
Increasing the density of nodes around an IDS
node is not seen to signiﬁcantly aﬀect the amount
of processing required by the IDS, since the only
additional packets processed are related to the rout-
ing protocol. The simulation results also shows a
very low ratio of
false positives with a static
threshold of ﬁve dropped packets for intrusions
and sampling period of 10 s used in the simulations.
We believe this can be improved further by dynam-
ically adapting to traﬃc conditions.
Regular nodes may occasionally be aﬀected by
adverse environmental conditions like high noise,
high load, etc.
leading to some packets being
dropped or discarded. Malicious or chronically
faulty nodes however exhibit continuous packet
drops over a period of time. Thresholds, dynami-
cally determined by monitoring current network
conditions, would help account for such packet
drops by regular nodes under transient adverse envi-
ronmental conditions. This lower bound of accept-
able packet loss,
is chosen merely to allow for
transient failures (packet loss) and minimize false
positives. Consequently, for a speciﬁc deployment
such a threshold should be chosen based on a vari-
ety of
factors including network density, radio
range, mobility speed and further modiﬁed by cur-
rent traﬃc loads and environmental conditions like
noise.
A larger sampling period would require more
storage per (observable) traﬃc stream, and smaller
one would require less storage – yet increases the
possibility of
false alarms. The IDS intrusion