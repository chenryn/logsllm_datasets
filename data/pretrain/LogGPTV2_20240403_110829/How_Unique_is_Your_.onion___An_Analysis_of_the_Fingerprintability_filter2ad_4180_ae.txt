pages. It is worth pointing out that the onion services ecosystem
has a 90’s, GeoCities “look,” where pages tend to be simple HTML
and sites that do not follow this aesthetic will stand out.
8 LIMITATIONS AND FUTURE WORK
With 482 onion sites, this is the largest website fingerprint-
ing study of onion service sites. Even so, our results may not be
representative of the entire onion service universe. We made our
best effort to collect as many onion service URLs as possible us-
ing ahmia.fi. While there are more effective methods to collect
.onion addresses, such as setting up a snooping Hidden Service
Directory [24], they are ethically questionable.
Our data is a snapshot of the onion services space over 14 days.
As the onion services change constantly, and fingerprintability
depends not just on individual sites but the whole set, the dataset
and the analysis should be updated regularly for a diagnosis of
current levels of fingerprintability.
As new website fingerprinting attacks are proposed, features that
are important to fingerprintability now may become less so, espe-
cially if defenses are introduced or if the design of websites changes.
The methods introduced in this paper for extracting features and
understanding what makes certain sites identifiable, however, are a
lasting and relevant contribution. In particular, we argue that the
effectiveness of a proposed defense should be examined not only
on average, but that it should account for possible disparate impact
on different sites depending on their features. For example, even
if a defense significantly lowers the average accuracy of a website
fingerprinting attack, it could be that certain sites are always cor-
rectly identified, and thus left unprotected by the defense. We also
point out that we focus on whether a site blends well with other
sites, triggering frequent misclassifications in the context of web-
site fingerprinting attacks, and that the effectiveness of using such
techniques as basis for defending against website fingerprinting,
has dependencies on the actions taken by other onion services.
Our data collection methodology follows standard experimental
practices in the website fingerprinting literature when crawling
only home pages. On the one hand, limiting the evaluation to home
pages (rather than including all inner pages of a site) reduces the
classification space and gives an advantage to the adversary com-
pared to considering that users may directly browse to the inner
pages of a site. We argue that a fraction of users will still first land
on the homepage of a site before visiting inner pages and thus this
adversarial advantage is not unrealistic. We also note that the link
structure of inner pages in a website can be exploited to improve
the accuracy of website fingerprinting attacks.
Compared to using wget, curl or headless browsers, our Tor
Browser based crawler better impersonates a real browser, limiting
the risk of differential treatment by onion services. Still, it is possible
detect the presence of Selenium based automation using JavaScript.
The adversary can sanitize training data by taking measures
such as removing outliers, but cannot do so for test data. Since we
measure an upper bound for the fingerprintability of websites, we
sanitize the whole dataset including the test data. Note that this is
in line with the methodology employed in prior work [21, 27].
We acknowledge that redesigning a site to be small and dynamic,
as suggested best practice by our analysis, may not be an option
for some sites for a variety of reasons. This is a limitation of our
approach to countermeasures, but might be a limitation to website
fingerprinting defenses in general, as large sites are easily identified
by website fingerprinting attacks. However, we believe that our
results can inform the design of application-layer defenses that
alter websites in order to perturb site-level features [8]. This would
allow to optimize existing application-layer defenses by focusing
on the features that our site-level feature analysis has identified as
most identifying, thus reducing the performance that these defenses
incur in Tor.
Previous studies on website fingerprinting have shown that data
collected from regular sites get stale over time, namely, the accuracy
of the attack drops if the classifier is trained on outdated data [15].
For onion services, Kwon et al. did a similar experiment and showed
that onion services change at a lower rate than regular sites and
do not get stale as quick [17]. For this reason, in this paper, we
assume the adversary can keep an updated database of website
fingerprinting templates.
Reducing the accuracy of website fingerprinting attacks can
be framed as an adversarial learning problem. A webpage can be
redesigned to modify its site-level features (especially those that
contribute the most to fingerprintability) to trick the classifier into
making a misclassification. In future work we plan to tackle finding
efficient ways to altering these website features to launch poison-
ing attacks against website fingerprinting classifiers [14] under
constraints such as bandwidth, latency and availability.
Finally, we acknowledge that the random forest regression method
to determine the fingerprintability of a webpage given only web-
level features is currently useful only for feature analysis. This is
due to a number of factors, such as removing the middle of the
spectrum sites and balancing the priors. Although there are a few
challenges and limitations, creating an accurate tool that can de-
termine if a site will be easily fingerprinted from only site-level
features would be very valuable to onion services.
9 CONCLUSION
Our work intends to change the way that we build and analyze
website fingerprinting attacks and defenses, and differs from pre-
vious website fingerprinting contributions in several ways. We do
not propose a new attack algorithm (with the exception, perhaps,
of the ensemble method) or an explicit defense, but study instead
what makes certain sites more or less vulnerable to the attack. We
examine which types of features, with intentional generality, are
common in sites vulnerable to website fingerprinting attacks.
This type of analysis is valuable for onion service operators
and for designers of website fingerprinting defenses. A website fin-
gerprinting countermeasure may have a very disparate impact on
different sites, which is not apparent if only average accuracies are
taken into consideration. Further, we note that from the perspective
of an onion service provider, overall accuracies do not matter, only
whether a particular defense will protect their site and their users.
Our results can guide the designers and operators of onion ser-
vices as to how to make their own sites less easily fingerprintable,
in particular considering the results of the feature analyses and
misclassifications. For example, we show that the larger sites are
reliably more identifiable, while the hardest to identify tend to be
small and dynamic.
This work is also a contribution to adversarial machine learning.
Most work in adversarial learning focuses on attacking a specific
algorithm and feature set, but in many privacy problems this model
does not fit. Our study investigates methods to force the misclassi-
fication of an instance regardless of the learning method.
ACKNOWLEDGMENTS
This work was funded in part by the National Science Foundation
(1253418) and a senior postdoctoral fellowship from KU Leuven
(SF/15/007). In addition, this work was supported by the European
Commission through KU Leuven BOF OT/13/070, H2020-DS-2014-
653497 PANORAMIX and H2020-ICT-2014-644371 WITDOM. Marc
Juarez is funded by a PhD fellowship of the Fund for Scientific
Research - Flanders (FWO).
html. (2017).
REFERENCES
[1] 2017. Users - Tor Metrics. https://metrics.torproject.org/userstats-relay-country.
[2] Marco Barreno, Blaine Nelson, Russell Sears, Anthony D. Joseph, and J. D. Ty-
gar. 2006. Can Machine Learning Be Secure?. In Proceedings of the 2006 ACM
Symposium on Information, Computer and Communications Security (ASIACCS
’06).
[3] Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefeb-
vre. 2008. Fast unfolding of communities in large networks. Journal of statistical
mechanics: theory and experiment 2008, 10 (2008), P10008.
[4] Xiang Cai, Rishab Nithyanand, and Rob Johnson. 2014. CS-BuFLO: A Congestion
Sensitive Website Fingerprinting Defense. In Workshop on Privacy in the Electronic
Society (WPES). ACM, 121–130.
[5] Xiang Cai, Rishab Nithyanand, Tao Wang, Rob Johnson, and Ian Goldberg. 2014.
A Systematic Approach to Developing and Evaluating Website Fingerprinting
Defenses. In ACM Conference on Computer and Communications Security (CCS).
ACM, 227–238.
[6] Xiang Cai, Xin Cheng Zhang, Brijesh Joshi, and Rob Johnson. 2012. Touching from
a Distance: Website Fingerprinting Attacks and Defenses. In ACM Conference on
Computer and Communications Security (CCS). ACM, 605–616.
[7] Heyning Cheng and Ron Avnur. 1998. Traffic Analysis of SSL Encrypted
Web Browsing.
Available
at http://www.cs.berkeley.edu/~daw/teaching/cs261-f98/projects/final-reports/
ronathan-heyning.ps.
Project paper, University of Berkeley (1998).
[8] Giovanni Cherubin, Jamie Hayes, and Marc Juarez. 2017. "Website Fingerprinting
Defenses at the Application Layer". In Privacy Enhancing Technologies Symposium
(PETS). De Gruyter, 168–185. Issue 2.
[9] Roger Dingledine, Nick Mathewson, and Paul F. Syverson. 2004. "Tor: The Second-
Generation Onion Router". In USENIX Security Symposium. USENIX Association,
303–320.
[10] Kevin P. Dyer, Scott E. Coull, Thomas Ristenpart, and Thomas Shrimpton. 2012.
Peek-a-Boo, I Still See You: Why Efficient Traffic Analysis Countermeasures Fail.
In IEEE Symposium on Security and Privacy (S&P). IEEE, 332–346.
[11] Jamie Hayes and George Danezis. 2016. k-fingerprinting: a Robust Scalable
Website Fingerprinting Technique. In USENIX Security Symposium. USENIX As-
sociation, 1–17.
[12] Dominik Herrmann, Rolf Wendolsky, and Hannes Federrath. 2009. Website
Fingerprinting: Attacking Popular Privacy Enhancing Technologies with the
Multinomial Naïve-Bayes Classifier. In ACM Workshop on Cloud Computing
Security. ACM, 31–42.
[13] Andrew Hintz. 2003. Fingerprinting Websites Using Traffic Analysis. In Privacy
Enhancing Technologies (PETs). Springer, 171–178.
[14] Ling Huang, Anthony D Joseph, Blaine Nelson, Benjamin IP Rubinstein, and
JD Tygar. 2011. Adversarial machine learning. In Proceedings of the 4th ACM
workshop on Security and artificial intelligence. ACM, 43–58.
[15] Marc Juarez, Sadia Afroz, Gunes Acar, Claudia Diaz, and Rachel Greenstadt. 2014.
A Critical Evaluation of Website Fingerprinting Attacks. In ACM Conference on
Computer and Communications Security (CCS). ACM, 263–274.
[16] Marc Juarez, Mohsen Imani, Mike Perry, Claudia Diaz, and Matthew Wright. 2016.
Toward an Efficient Website Fingerprinting Defense. In European Symposium on
Research in Computer Security (ESORICS). Springer, 27–46.
[17] Albert Kwon, Mashael AlSabah, David Lazar, Marc Dacier, and Srinivas Devadas.
2015. Circuit fingerprinting attacks: passive deanonymization of tor hidden
services. In USENIX Security Symposium. USENIX Association, 287–302.
[18] Sarah Jamie Lewis. 2017.
OnionScan Report: Freedom Hosting
II, A New Map and a New Direction.
"https://mascherari.press/
onionscan-report-fhii-a-new-map-and-the-future/". (6 March 2017). (accessed:
May, 2017).
[19] Marc Liberatore and Brian Neil Levine. 2006. "Inferring the source of encrypted
HTTP connections". In ACM Conference on Computer and Communications Secu-
rity (CCS). ACM, 255–263.
[20] Xiapu Luo, Peng Zhou, Edmond W. W. Chan, Wenke Lee, Rocky K. C. Chang,
and Roberto Perdisci. 2011. HTTPOS: Sealing Information Leaks with Browser-
side Obfuscation of Encrypted Flows. In Network & Distributed System Security
Symposium (NDSS). IEEE Computer Society.
[21] Andriy Panchenko, Fabian Lanze, Andreas Zinnen, Martin Henze, Jan Pennekamp,
Klaus Wehrle, and Thomas Engel. 2016. Website Fingerprinting at Internet Scale.
In Network & Distributed System Security Symposium (NDSS). IEEE Computer
Society, 1–15.
[22] Andriy Panchenko, Lukas Niessen, Andreas Zinnen, and Thomas Engel. 2011.
Website Fingerprinting in Onion Routing Based Anonymization Networks. In
[23] Mike Perry. 2011.
ACM Workshop on Privacy in the Electronic Society (WPES). ACM, 103–114.
gerprinting.
experimental-defense-website-traffic-fingerprinting". (2011).
October 10, 2013).
Experimental Defense for Website Traffic Fin-
"https://blog.torproject.org/blog/
(accessed:
project Blog.
Tor
[24] Amirali Sanatinia and Guevara Noubir. 2016. HOnions: Towards Detection and
Identification of Misbehaving Tor HSdirs. In Workshop on Hot Topics in Privacy
Enhancing Technologies (HotPETs).
[25] Q Sun, DR R Simon, and YM M Wang. 2002. Statistical Identification of Encrypted
Web Browsing Traffic. In IEEE Symposium on Security and Privacy (S&P). IEEE,
19–30.
[26] Tao Wang, Xiang Cai, Rishab Nithyanand, Rob Johnson, and Ian Goldberg. 2014.
Effective Attacks and Provable Defenses for Website Fingerprinting. In USENIX
Security Symposium. USENIX Association, 143–157.
[27] Tao Wang and Ian Goldberg. 2013. Improved Website Fingerprinting on Tor. In
ACM Workshop on Privacy in the Electronic Society (WPES). ACM, 201–212.
[28] Tao Wang and Ian Goldberg. 2016. On Realistically Attacking Tor with Website
Fingerprinting. In Proceedings on Privacy Enhancing Technologies (PoPETs). De
Gruyter Open, 21–36.
[29] Davis Yoshida and Jordan Boyd-Graber. 2016.
"Using Confusion Graphs to
Understand Classifier Error". In Proceedings of the NAACL Human-Computer
Question Answering Workshop. Association for Computational Linguistics, 48–52.
Issue 2.
A SITE LEVEL FEATURES
Table 6 shows the site-level features and statistic used to aggregate each site-level features within a site class. We followed the feature extraction step outlined
in Section 3 to obtain the site-level features. Here we present a more detailed overview of feature extraction for different site-level feature families.
Table 6: Site-level features and statistics used to aggregate them across download instances. Nominal and binary features such
as Made with Wordpress are aggregated by taking the most frequent value (i.e. mode) of the instances. Quantitative features
such as Page load time are aggregated using median, as is is less sensitive to outliers than the statistical mean.
Feature
Number of HTTP requests
Number of HTTP responses
Has advertisement
Has tracking/analytics
HTML source size
Page load time
Made with Django
Made with Dokuwiki
Made with Drupal
Made with Joomla
Made with MediaWiki
Made with OnionMail
Made with phpSQLiteCMS
Made with vBulletin
Made with WooCommerce
Made with Wordpress
Made with CMS
Number of audio
Number of domains
Number of redirections
Number of empty content
Number of fonts
Number of HTML resources
Number of images
Number of other content
Number of scripts
Number of stylesheets
Number of videos
Number of waterfall phases
Screenshot size
Page weight
Total request size
Median Mode Description
Number of HTTP requests stored by the browser add-on
Number of HTTP responses stored by the browser add-on
HTTP request matching EasyList 7
HTTP request matching EasyPrivacy 8
Size (in bytes) of the page source
As determined by Selenium
As determined by generator HTML meta tag
As determined by generator HTML meta tag
As determined by generator HTML meta tag
As determined by generator HTML meta tag
As determined by generator HTML meta tag
As determined by generator HTML meta tag
As determined by generator HTML meta tag
As determined by generator HTML meta tag
As determined by generator HTML meta tag
As determined by generator HTML meta tag
True if any of the “Made with...” features above is true
As determined by the Content-Type HTTP response header
As determined by the Content-Type HTTP response header
As determined by the presence of Location HTTP response header
Number of HTTP responses with Content-Length equal to zero
As determined by the Content-Type HTTP response header
As determined by the Content-Type HTTP response header
As determined by the Content-Type HTTP response header
As determined by the Content-Type HTTP response header
As determined by the Content-Type HTTP response header
As determined by the Content-Type HTTP response header
As determined by the Content-Type HTTP response header
Approximate number of HTTP waterfall chart phases as determined
by switches from request to response or response to request.
Size (in bytes) of the screenshot saved by Selenium
Sum of the HTTP response sizes (in bytes)
Sum of the HTTP request sizes (in bytes)
7 https://easylist.to/easylist/easylist.txt
8 https://easylist.to/easylist/easyprivacy.txt
B CONFUSION GRAPH FOR CUMUL
Figure 10: Confusion graph for the CUMUL classifier drawn by Gephi software using the methodology explained in Section 4.6.
Nodes are colored based on the community they belong to, which is determined by the Louvain community detection algo-
rithm [3]. Node size is drawn proportional to the node degree, that is, bigger node means lower classification accuracy. We
observe highly connected communities on the top left, and the right which suggests clusters of onion services which are
commonly confused as each other. Further, we notice several node pairs that are commonly classified as each other, forming
ellipses.