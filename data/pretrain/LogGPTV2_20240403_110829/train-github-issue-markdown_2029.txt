Hi ,  
I have the same issue as #5601 (I am unable to force Keras + Theano to use
more than 1 thread using OpenBLAS.) I have applied all suggestion mentioned on
issue #5601, It works on:
    inputs = Input(shape=(1024000,))
    x = Dense(256, activation='relu')(inputs)
    x = Dense(256, activation='relu')(x)
    predictions = Dense(10000, activation='softmax')(x)
    model = Model(input=inputs, output=predictions)
    model.compile(optimizer='rmsprop',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    data = np.random.rand(100, 1024000)
    for i in range(100000):
        print (i)
        model.predict(data)
but it doesn't work on :
    THEANO_FLAGS='device=cpu,openmp=True,blas.ldflags=-lopenblas'
    OMP_NUM_THREADS=8 
    KERAS_BACKEND=theano
    import pandas as pd
    import numpy as np
    from tqdm import tqdm
    from keras.models import Sequential
    from keras.layers.core import Dense, Activation, Dropout
    from keras.layers.embeddings import Embedding
    from keras.layers.recurrent import LSTM, GRU
    from keras.layers.normalization import BatchNormalization
    from keras.utils import np_utils
    import keras.engine.topology 
    from keras.layers import TimeDistributed, Lambda
    from keras.layers import Convolution1D, GlobalMaxPooling1D
    from keras.callbacks import ModelCheckpoint
    from keras import backend as K
    from keras.layers.advanced_activations import PReLU
    from keras.preprocessing import sequence, text
    data = pd.read_csv('data/quora_duplicate_questions.tsv', sep='\t')
    y = data.is_duplicate.values
    tk = text.Tokenizer(nb_words=200000)
    max_len = 40
    tk.fit_on_texts(list(data.question1.values) + list(data.question2.values.astype(str)))
    x1 = tk.texts_to_sequences(data.question1.values)
    x1 = sequence.pad_sequences(x1, maxlen=max_len)
    x2 = tk.texts_to_sequences(data.question2.values.astype(str))
    x2 = sequence.pad_sequences(x2, maxlen=max_len)
    word_index = tk.word_index
    ytrain_enc = np_utils.to_categorical(y)
    embeddings_index = {}
    f = open('data/glove.840B.300d.txt')
    values_conv = []
    for line in tqdm(f):
        values = line.split()
        for item in values:
            try:
                values_conv.append(float(item))
            except: 
                pass
        word = values_conv[0]
        coefs = np.asarray(values_conv[1:], dtype='float32')
        embeddings_index[word] = coefs
    f.close()
    print('Found %s word vectors.' % len(embeddings_index))
    embedding_matrix = np.zeros((len(word_index) + 1, 300))
    for word, i in tqdm(word_index.items()):
        embedding_vector = embeddings_index.get(word)
        if embedding_vector is not None:
            embedding_matrix[i] = embedding_vector
I don't really know what the problem is. I would really appreciate any help.
Thanks