title:Partially Specified Channels: The TLS 1.3 Record Layer without Elision
author:Christopher Patton and
Thomas Shrimpton
The proceedings version of this paper appears at CCS ’18. This is the full version.
Partially Speciﬁed Channels:
The TLS 1.3 Record Layer without Elision
Christopher Patton and Thomas Shrimpton
Florida Institute for Cybersecurity Research
Computer and Information Science and Engineering
University of Florida
{cjpatton,teshrim}@ufl.edu
Abstract
We advance the study of secure stream-based channels (Fischlin et al., CRYPTO ’15) by considering
the multiplexing of many data streams over a single channel, an essential feature of real world protocols
such as TLS. Our treatment adopts the deﬁnitional perspective of Rogaway and Stegers (CSF ’09),
which oﬀers an elegant way to reason about what standardizing documents actually provide: a partial
speciﬁcation of a protocol that admits a collection of compliant, fully realized implementations. We
formalize partially speciﬁed channels as the component algorithms of two parties communicating over a
channel. Each algorithm has an oracle that provides speciﬁcation details; the algorithms abstract the
things that must be explicitly speciﬁed, while the oracle abstracts the things that need not be. Our
security notions, which capture a variety of privacy and integrity goals, allow the adversary to respond
to these oracle queries; security relative to these notions implies that the channel withstands attacks
in the presence of worst-case (i.e., adversarial) realizations of the speciﬁcation details. We apply this
framework to a formal treatment of the TLS 1.3 record and, in doing so, show that its security hinges
crucially upon details left unspeciﬁed by the standard.
1 Introduction
As protocols such as TLS [32], SSH [37], IPSec [23], and QUIC [21] have evolved, so have the formal tools used
to analyze them. Often it is the protocol standards themselves, rather than fully realized implementations,
that inspire and guide mathematical abstractions of these protocols, but their complexity makes the task of
developing these abstractions quite challenging and prone to missing subtle attacks. Much of this complexity
stems from the fact that protocols are only partially speciﬁed. The TLS 1.3 standard [30], whose record
layer mechanism is the subject of this paper, contains numerous “SHOULDs”, “SHOULD NOTs” and
“MAYs.” Each of these provides a guideline, but not a rule (those are “MUSTs” and “MUST NOTs”), for
compliant realizations of the standard. In addition, and like other protocol standards, TLS 1.3 leaves many
implementation details unspeciﬁed. Thus, the standard actually describes a collection of implementations
that share a core set of behaviors.
Standards are not more explicit and prescriptive for good reason. To be broadly adopted, they need to
be ﬂexible in the face of a variety of deployment concerns, such as backwards compatibility, interoperability
with other protocols, and limitations of existing infrastructure. They also need to balance performance
with security and account for competing (and often conﬂicting) interests of stakeholders. But this need for
ﬂexibility presents an important challenge to provable security: namely, deciding which of the standard’s
guidelines and unspeciﬁed implementation details are relevant to security, and so should be captured in the
model.
The implications of these modeling choices are often clear only after an attack is found, leading to what
Degabriele et al. [16] call the model-attack-remodel cycle. A prominent example is the case of padding-oracle
attacks. The MAC-then-encode-then-encrypt construction, used to provide authenticated encryption in
many early secure channel protocols, is provably secure [28], but only in a model in which decryption does not
surface distinguishable errors. Yet compliant implementations of these protocols did make visible the cause
of decryption failures (in particular, whether the encoding was invalid or the MAC was incorrect), leading
to plaintext-recovery attacks [36, 17, 27]. The research community reacted by incorporating distinguishable
errors into updated models [14, 19], but left more subtle attack vectors unaddressed [3], leading in turn to
more sophisticated models [22, 6]. This reactive evolution of the adversarial model is to be expected. But
since standards only partially specify the protocol, it is hard to anticipate where vulnerabilities might arise
in implementations.
This work explores a deﬁnitional viewpoint that may help us to be more proactive, by making explicit in
the security model which parts of the protocol are fully speciﬁed, and which are not. Concretely, our goal
is to establish the security of the TLS 1.3 record layer [32], which (partially) speciﬁes how plaintext and
ciphertext data are formatted, encrypted, and transmitted from sender to receiver. To this end, we formalize
a new primitive that we call a partially speciﬁed channel.
Modeling the TLS 1.3 record layer. The starting point of our model is the stream-based channel
abstraction, introduced by Fischlin et al. [19] (hereafter FGMP). The FGMP syntax for stream-based chan-
nels accurately captures the interfaces exposed by real secure-channel implementations in that it treats the
sender- and receiver-side inputs and outputs as streams of fragments, as opposed to atomic messages. (It
also admits distinguishable error messages.) We augment their syntax in order to account for multiplexing
of many data streams over the same channel, as this is an essential feature of many secure channel protocols,
including TLS 1.3. And although this protocol is our focus, we expect our syntax should be applicable to
the authenticated encryption mechanism in other protocols, such as SSH, IPSec, QUIC, and DTLS [31].
We extend the FGMP notions of privacy and integrity to this setting. There are two main ﬂavors of
privacy: the ﬁrst, PRIV-S, is analogous to indistinguishibility under chosen-plaintext attack, since the ad-
versary only controls the sender’s inputs; in the second, PRIV-SR, we also allow the adversary to mount
chosen-ciphertext fragment attacks. With each of these, we consider diﬀerent “degrees” of privacy corre-
sponding to various security goals considered in prior works [28, 19, 18]. For integrity, we formalize two
notions:
integrity of ciphertext streams (INT-CS) and plaintext streams (INT-PS). Following FGMP, we
show how to achieve PRIV-SR security from a scheme that is both PRIV-S and INT-CS secure; just as
with FGMP, we will need an additional property called status simulatability (SIM-STAT). Our notions are
applicable to settings in which reliable transport (e.g., via TCP) is expected, and failure of the underlying
transport mechanism to deliver stream fragments in order is deemed an attack (as in TLS and SSH).
A number of implementation details that are not speciﬁed by TLS 1.3 are relevant in the adversarial
model of FGMP. For example, there are explicit rules that govern the manner in which plaintext fragments
are buﬀered and coalesced into atomic plaintext records, but the speciﬁcation leaves many design choices
up to the implementation. In order to establish the security of the record layer in this setting, we ﬁrst need
to determine how to reason about these missing pieces. To do so, we apply the partially speciﬁed protocol
approach of Rogaway and Stegers [33] (RS) to the study of secure channels. Loosely speaking, a partially
speciﬁed channel (PSC) consists of named algorithms for the sender and receiver operations that each take
a speciﬁcation details (SD) oracle. The algorithms form the cryptographic core of the secure channel, and
hence the part that must be realized precisely; everything that is not explicitly part of the cryptographic core
is handled by the oracle. Crucially, in our security notions, it is the adversary itself who will service calls to
the SD-oracle. Thus, a proof of security for a particular PSC implies that all details swept into the SD-oracle
are irrelevant with respect to these deﬁnitions; they can be implemented to behave in an adversarial manner,
without concern.
Our results. We found this deﬁnitional viewpoint to be a useful tool for determining which pieces of
the record layer speciﬁcation are security critical and which are not. In particular, our formal treatment of
the record layer uncovers two subtle and security-critical matters. First, the degree of privacy the record
layer can provably provide depends intrinsically on the unspeciﬁed details (Theorem 2). The record layer
is used to multiplex distinct plaintext streams over the same channel; thus, each record has a content type
that associates the content to its stream. The content type is encrypted along with the content, permitting
implementations that, at least in principle, hide both the content and its type. This is laudable, but the
speciﬁcation admits implementations that leak the content type entirely. Roughly speaking, this leakage
occurs because the boundaries between records depend on the content types of each record. In general, we
can conclude only that the record layer ensures privacy of the contents of each of the data streams. (We
make this point precise in Section 5.)
2
Second, following FGMP, our notion of ciphertext-stream integrity implies that the receiver only consumes
the stream produced by the sender. Records written to the channel are delimited by strings called record
headers, whose values are speciﬁed by the standard. These bits are not authenticated, and the standard
does not require the receiver to check that their values are correct; thus, the record layer cannot achieve
our strong notion of ciphertext-stream integrity. But intuitively, the value of these bits should not impact
security. Our framework provides a clean way to reconcile this intuition with our model: we show that the
value of these bits are indeed irrelevant if and only if they are authenticated (Theorem 3).
Our analysis applies to draft 23 [32], which was current at the time of writing. We shared our ﬁndings
with the IETF working group responsible for standardizing TLS 1.3 and the speciﬁcation was updated so
that the record header is authenticated. This change appears in the ﬁnal version of the standard [30].
Roadmap of the paper. The next section motivates our analytical framework, putting it in context with
prior work on secure channels and partially speciﬁed protocols. Section 3 outlines additional related work
on TLS. In Section 4 we formulate our syntax and adversarial model, and deﬁne our notions of privacy
(Section 4.2) and integrity (Section 4.3). Section 5 presents our formal treatment of the record layer and
discusses some limitations of our model with respect to TLS. We conclude in Section 6 with directions for
future work.
1.1 Revision history
Note the following changes from the proceedings version of this paper [29].
1. 2020/04/03. Revise the record layer speciﬁcation (Figure 7; cf. [29, Figure 4]) and the statement of
Theorem 4. The original proof of Theorem 4 contained an error in the transition from game 3 to
game 4. To patch it, minor changes to the speciﬁcation are needed to ensure the receiver can correctly
compute the record boundaries whenever the channel is in-sync. It is also necessary to restrict the
adversary so that he receiver computes these deterministically and independently of the adversary’s
state.1 This amount to assuming that the record boundaries can be computed from the sequence of
records written to the channel. This is true of the record layer, of course, so these changes do not
change our claims for the TLS 1.3 standard as it is.
2. 2020/04/03. Weaken INT security (Figure 6; cf. [29, Figure 4]) by requiring Enc-queries to have
distinct nonces and update Theorem 3 (cf. [29, Theorom 5.2]) and Theorem 4 (cf. [29, Theorom 5.3])
accordingly. The previous notion is stronger than usual (cf. nAE [26]) and therefore excludes common
instantiations of the AEAD scheme. For example, AES-GCM is known to be vulnerable to ciphertext
integrity attacks when nonces are allowed to repeat [15]. Fortunately, it is straight-forward to patch
the proofs to account for the weaker assumption.
2 PSCs in relation to prior work
Our framework weds two existing approaches to analyzing real-world cryptography. First, we extend secure
stream-based channels to consider multiplexing of plaintext streams over the same channel. This addresses
a problem left open by FGMP [20] and permits, for the ﬁrst time, the analysis of TLS in this setting.
The second approach is the partially speciﬁed protocol framework of RS, which we use to reason about the
standard itself.
Stream-based secure channels. We summarize important landmarks in the development of the theory
of secure channels. In 2000, Bellare and Namprempre [8] provided foundations for the study of probabilistic
authenticated encryption (AE) schemes used in SSL/TLS, IPSec and SSH. Shortly thereafter, Rogaway [34]
embellished authenticated encryption to take associated data (AEAD), moving the primitive closer to prac-
tice. Yet it was already understood that an AEAD scheme and its attendant notions of privacy and integrity
do not suﬃce for building secure channels. In 2002, Bellare, Kohno, and Namprempre (BKN) [7] formalized
stateful AE in order to account for replay and out-of-order delivery attacks, as well as to model and analyze
1In fact, Rogaway and Stegers ultimately made a similar restriction in their analysis of the NSL2 protocol (cf. [33, Section 5]).
3
SSH. Their model regards ciphertexts as atomic, but ciphertexts written to the channel may be (and rou-
tinely are) fragmented as they traverse the network, which leaves these protocols susceptible to attacks [2].
Likewise, the APIs for real secure channels regard the input plaintext as a stream, meaning that a single
logical plaintext may be presented as a sequence of fragments, too. It took another ten years for the model
to be signiﬁcantly extended, by Boldyreva et al. [13], to address ciphertext fragmentation and attacks that
exploit it. Finally, in 2015 by FGMP formalized stream-based secure channels that address plaintext frag-
mentation, with updates provided in 2016 by Albrecht et al. [1]. As FGMP point out [20], these works help
shed formal light on truncation [35] and cookie-cutter [12] attacks. (However, as we discuss in Section 5.3,
their work is somewhat limited with regard to these.)
Although theory has advanced signiﬁcantly, it still falls short of capturing an important feature that real
protocols provide: a means of multiplexing a number of data streams over the same channel. The TLS 1.3
record layer, for example, handles streams for three distinct sub-protocols: handshake, alert, and application-
data. Explicitly modeling the multiplexing of these streams is necessary for a rigorous analysis of TLS, since
each of these sub-protocols has side-eﬀects on the sender and receiver state and, hence, implications for the
security provided by the channel.
Whereas FGMP regard the plaintext stream as a sequence of message fragments M1, M2, . . . , we will
consider streams of the form (M1, sc1), (M2, sc2), . . . where sci denotes the stream context of its associated
message fragment. The stream context is metadata that allows for diﬀerentiation of fragments into logical
streams, each associated to a higher-level application, protocol, etc. Following prior work, our syntax models
a unidirectional channel between a sender and receiver. We decompose the sender into two randomized,
stateful algorithms: the stream multiplexer (Mux ), and the channel writer (Write ). Correspondingly, we
decompose the receiver into the channel reader (Read ), and the stream demultiplexer (Demux ). One might
think it cleaner to regard the sender and receiver as atomic processes, as the aforementioned works do. We
break with this syntax in order to precisely capture multiplexing of streams, and to separate this functionality
from the cryptographic operations that turn plaintext strings into ciphertexts. (More on this in Section 4.2.)
Partially specified protocols. In their treatment of the SSH protocol, BKN introduce a paradigm they
call Encode-then-Encrypt-and-MAC, which cleanly abstracts many of the details of the SSH speciﬁcation.
In particular, they treat the details of encoding as a generic transform and give a suﬃcient condition on
this transform for the security of the overall protocol. Of course, this idea—and more generally, the Encode-
then-Encipher paradigm [9]—is applicable to the problem of analyzing TLS 1.3. But our consideration of
stream-based channels makes our adversary considerably stronger than that considered by BKN. It stands
to reason, then, that there are details of the protocol and implementation that are relevant to the stronger
model, but not the weaker one. (In particular, we must at least account for processing of plaintext- and
ciphertext-stream fragments.) How shall we go about uncovering what these security-critical matters are?
There are many ways to appraoch this problem. The approach of RS, which we adopt here, is simply to
formalize what a standard is: a partial speciﬁcation (the things that are mandated and explicitly described)
plus additional speciﬁcation details (everything else). RS apply this approach to authentication protocols,
in particular the Needham-Schroeder-Lowe protocol. We apply it to secure channels. The component
algorithms of a PSC, Mux , Write , Read , and Demux , formalize the core functionalities of the sender and
receiver that must be fully speciﬁed; the rest of the speciﬁcation details (SD) are formalized via an oracle
given to each of the algorithms. The functionality of this SD oracle is left unspeciﬁed, and in our security
games, queries made to the oracle are serviced by the adversary. This is clearly a very strong attack model: in
addition to inﬂuencing the behavior of the algorithms via their inputs, the adversary is allowed to participate
in portions of their computation. The actual strength of the model depends on what quantities are exposed
to the SD, and how the SD return values are used within the algorithms. At one extreme, an empty (or
otherwise trivial) SD yields a traditional kind of attack model; at the other, if secret state (e.g., the key) is
passed to the SD, then no security is possible. In this way, our model can provide principled guidance to the
standard-writing process by surfacing choices that are relevant to security.
This deﬁnitional framework admits another interpretation, one that is likely of interest in other settings:
it lets us reason about security in the presence of implementation errors. One can view each algorithm as
being partitioned into operations whose implementation is assumed to be correct, and those that are not.
From this perspective, our attack model captures a kind of worst-case (i.e., adversarial) implementation of
those operations. This is interesting because if one proves that a particular PSC construction is secure, it
makes clear which things must be implemented correctly and deserve the extra scrutiny of formal veriﬁcation
4
(a la [18]), and which things do not need such hard guarantees.
3 Related work
We have already mentioned the line of papers that our work extends [8, 7, 14, 19, 1]; this section points out
important related eﬀorts.
The miTLS project. From the standpoint of scope, the work most closely related to ours is the recent
paper by Delignat-Lavaud et al. [18] (DLFK+). It provides a formal analysis of the TLS 1.3 record layer
(draft 18) “as is”, but their approach is fundamentally diﬀerent from our own. The paper is the latest from
miTLS (mitls.org), a project whose goal is to formally verify the security of TLS as is, without omitting