title:Using correlated surprise to infer shared influence
author:Adam J. Oliner and
Ashutosh V. Kulkarni and
Alex Aiken
201O IEEEIIFIP International 
Conference 
on Dependable 
Systems & Networks (DSN) 
Using Correlated 
Surprise to Infer Shared Influence 
Adam J. Oliner, Ashutosh V. Kulkarni, 
University* 
Stanford 
and Alex Aiken 
Department 
of Computer Science 
{oliner, 
ashutosh.kulkarni, 
aiken }@cs.stanford.edu 
Abstract 
costs of instrumentation, 
may be noisy or incomplete. 
for 
In particular, 
we may 
the sources 
of prob­
where, due to the pro­
the data available 
We propose 
a method for identifying 
systems 
knowledge 
We define influences 
that includes 
lems in complex production 
hibitive 
analysis 
not have complete 
interactions. 
interactions 
source contention. 
components 
with time-correlated 
the strength 
a Structure-of-Influence 
how to construct 
behavior, 
studies with 
duction 
and directionality 
in a system by looking 
supercomputer. 
two autonomous 
Our method infers 
and presents 
anomalous 
vehicles 
of all components 
and their 
as a class of component 
and re­
direct communication 
among 
the influences 
for pairs of components 
We summarize 
behavior. 
of shared influences 
using 
Craph (SIC). This paper explains 
a SIC and use it to isolate 
system mis­
both simulations 
case 
and in-depth 
and a 9024-node 
pro­
1 Introduction 
systems are often prohibitive. 
constructed 
from many 
and we cannot expect to have mea­
Consider 
a complex production 
system in which some­
or 
the source of the 
a strange 
result, 
is that the costs of in­
glitch, 
difficulty 
in production 
crash. How might we identify 
thing goes wrong: a performance 
an outright 
problem? A fundamental 
strumentation 
Significant 
interacting 
surements 
we will not even know of all the components 
teractions 
is about analyzing 
tially 
systems are invariably 
subsystems, 
from every component. 
among the components 
systems as they are, generating 
we do know. This paper 
a poten­
partial 
diagnosis 
Our method requires 
from whatever 
data is available. 
only that some of the components 
the system are instrumented 
surements 
depend on the type of component 
be instrumented 
of their behavior. 
differently 
to generate 
The type of measurements 
in 
times tamped mea­
may 
(e.g.,  a laser sensor may 
than a hard disk). 
Thus, we need 
In fact, in many systems 
or of the in­
-This work was supported 
in part by NSF grant CCF-0915766 and the 
DOE High-Performance 
Computer Science Fellowship. 
of different 
components 
in 
and the related 
ques­
this issue, 
different 
by mapping all components' 
kinds of measurements 
be­
a way to compare measurements 
a uniform way. We address 
tion of how to summarize 
from a single component, 
havior to a single dimension: 
quantifies 
how anomalous 
is, as an anomaly signal, 
normal component 
anomaly signals 
the degree to which a component's 
is retained, 
behavior 
into "normal" 
rather 
using deviation 
from a model of 
of our 
behavior. 
An important 
feature 
is that they are real-valued, 
meaning that 
is anomalous 
of discretizing 
behavior 
than the common approach 
and "abnormal". 
surprise. 
individual 
That is, our method 
component 
behavior 
share an influ­
meaning that 
around 
can arise from a number of interac­
communication 
Not all interactions 
and contention 
are instantaneous, 
for a 
so 
direct 
behavior 
tend to exhibit 
When two anomaly signals 
are correlated, 
two components 
surprising 
the same time, we say that the components 
ence. This correlation 
including 
tions, 
shared resource. 
we use effect delays-how 
in one component 
directionality. 
lay is directional, 
influence 
encodes strong influence 
with optional 
to manifest 
Correlation 
so the most natural 
in another-to 
and de­
to represent 
is a pairwise 
a delay. 
directionality 
Passively  collected 
itself 
to summarize 
is a graph. A Structure-of-Influence 
Graph (SIG) 
structure 
as an edge between components, 
data, if devoid of hints like "compo­
long it tends to take an anomaly 
relationship 
establish 
An advantage 
B," cannot be used to 
of one component 
nent A sent a message to component 
infer causality: 
ment is that the behavior 
with another. 
is that it enables 
it is easy to add a new "component" 
For example, 
whose 
anomaly signal is large around the time bad behavior 
was 
observed. 
that share influence 
with 
the synthetic 
candidates 
tors to the problem. 
Other, real, components 
of using statistical 
asking "what-if' 
component 
queries, 
are likely 
after the fact. 
for contribu­
is correlated 
correlation 
Our goal is to generate 
of component 
behavior, 
ily answer prediction 
method has several 
a structure, 
that enables 
and diagnosis 
by models 
informed 
a user to more eas­
The SIG 
questions. 
desirable 
properties: 
the strongest  possible  mathematical  state­
978-1-4244-7501-8/10/$26.00 
©201O IEEE 
191 
DSN 2010: OIiner et al. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:06:05 UTC from IEEE Xplore.  Restrictions apply. 
2010 IEEEIIFIP International 
Conference 
on Dependable 
Systems & Networks (DSN) 
instrumenta­
Much of this dependency 
modeling 
work requires 
that 
• Building 
a SIG requires 
tion; no expert knowledge 
knowledge 
destination 
sage content. 
ponents 
no intrusive 
of the components; 
and no 
(e.g., the 
shared resources, 
or mes­
and can treat com­
about communication 
of a message), 
Our method is passive 
as black boxes. 
channels 
perturbed 
the system be actively 
probing 
systems, 
performance, administration, 
[5, 6, 9, 10, 19]. Unfortunately, 
no such modifications 
by instrumentation 
for many important 
are possible 
(for reasons 
or cost). 
or by 
of 
Shrink [11] and SCORE [12] look for the root cause 
• Influence 
describes 
correlation, 
not causality. 
A key 
is to drop the assumption 
that 
and focus 
interactions 
all component 
among behaviors 
we can observe 
of our approach 
feature 
we can observe 
on the correlations 
(see Section 
2). 
using a two-level 
based on likeliness 
networks 
dependencies 
of faults in wide-area 
Shrink weights 
SCORE looks for shared risk, which measures 
correlated 
are across hosts. Finally, 
Bahl [2] aims to infer multi-level 
model load-balancing 
and redundancy. 
failures 
dependency 
recent work by 
graphs that 
graph. 
how strongly 
estimates. 
• By working directly 
nary, anomaly signal, 
when data is noisy or incomplete. 
with a real-valued, 
rather than bi­
our method degrades gracefully 
With few exceptions 
[4], in previous 
work events are in­
e., happen or not). Our approach, 
trinsically 
abstracts 
more information 
binary (i.
components as 
a real-valued 
signal, 
retains 
about component 
behavior. 
which 
strictly 
• Our experimental 
results 
show that SIGs can detect 
As systems grow in scale, the sparsity 
of instrumenta­
influence 
contention, 
delayed 
effects, 
in complex systems that exhibit 
loops and bidirectional 
influence, 
time­
resource 
and asynchronous 
communication. 
tion and complexity 
method infers 
fewer assumptions 
a broad class of interactions 
using, typically, 
about available 
data than previous 
work. 
of interactions 
will only increase. 
Our 
the SIG method and work 
In this paper, we present 
an example (Section 
controlled 
param­
4) to explore 
components; 
using a simulator 
3); perform several 
(Section 
through 
experiments 
eters like message drop rate, timing noise, and number of 
intermediate 
describe 
of 
the paper, how we took passively 
from two autonomous 
us to identify 
briefly present 
isolating 
the source of a critical 
different 
a significantly 
supercomputer 
5); and 
second example by 
(Section 
6). 
the central 
collected 
a bug in a production 
bug (Section 
vehicles 
and built SIGs that enabled 
case study 
measurements 
2 Related 
Work 
body of work on system modeling, 
the causal or dependency 
Our method distinguishes 
in that we look 
structure 
itself 
from 
work in various 
ways, but primarily 
rather than dependencies. 
There is an extensive 
on inferring 
systems. 
especially 
of distributed 
previous 
for influences 
Dependency 
graphs, 
networks), 
in 
for predic­
proposed 
systems. 
are frequently 
dependencies 
There have been 
modeling 
at dependency 
[7, 8] and Magpie [3] track 
with the aim of isolating 
Bayesian 
tion and diagnosis 
of computer 
a number of recent attempts 
distributed 
Pinpoint 
systems. 
communication 
root cause of misbehavior; 
the application 
fer causal paths and requires 
the expected 
the causal relationships 
WAP5 [18] use message traces and compute dependency 
paths. All of these projects 
compute dependencies, 
therefore 
mation or resource 
specification 
of a system. In order to determine 
among messages, 
the 
of 
Pip [17] aims to in­
of 
and 
dependency 
they require 
requests. 
cannot deal well with missing 
contention. 
an explicit 
to tag client 
behavior 
Project5 
infor­
[1] and 
instrumentation 
or some probabilistic 
variant 
(e.g., 
The choice of component 
models determines 
3 The Method 
a 
pro­
to use 
This section 
describes 
how to construct 
and interpret 
Graph (SIG). The construction 
3.1), measure the system's 
of four steps: decide what information 
(Section 
during actual operation 
Structure-of-Influence 
cess consists 
from each component 
behavior 
tion 3.2), compute the pairwise 
all components' 
anomaly signals 
and delay of correlations 
SIG where the nodes are components 
the strength 
(Section 
systems 
(Section 
and delay of correlations 
3.4). We later apply these techniques 
(Sections 
(Section 
4) and real systems 
and edges represent 
between components 
to idealized 
5 and 6). 
as anomaly signals 
(Sec­
cross-correlation 
to determine 
the strength 
between 
3.3), and construct 
a 
3.1 Modeling 
the seman­
of the SIG. 
if we model a program using the distribution 
tics of the anomaly signal and, consequently, 
For example, 
of system call sequences 
ECC errors, 
the resulting 
tion influences 
not, therefore, 
ticular 
question, 
however, 
suited to providing 
better 
and vice versa. There is 
program behavior, 
a single correct choice 
of models; for a par­
and model a memory chip using 
of these components 
memory corrup­
then the relationship 
SIG represents 
some models will produce  SIGs 
an answer. 
how strongly 
in 
We have found two models particularly 
useful in prac­
which is useful for sys­
tice: one based on message timing, 
tems where timing behavior 
systems) 
logged (see Section 
and at least some classes 
is important 
(e.g., embedded 
of events are thoroughly 
5), and one based on the information 
978-1-4244-7501-8/10/$26.00 
©201O IEEE 
192 
DSN 2010: Oliner et al. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:06:05 UTC from IEEE Xplore.  Restrictions apply. 
2010 IEEE/IFIP International 
Conference 
on Dependable 
Systems & Networks (DSN) 
where logging 
6). The timing 
of message terms, useful for systems 
content 
is highly selective 
and ad hoc (see Section 
model keeps track of past interarrival 
differences) 
spacing 
model looks at the distributions 
an existing 
is (see Section 
and computes 
of messages 
method [15]. 
3.2.1); 
how "surprising" 
the most recent 
the term entropy 
of message contents 
using 
times (timestamp 
first­
§ 1 
<0 0 
'" 0 
 u 
'" 
9 
-200 
. .  . L-------'--1 
-----.. -----.--------------------------
-100 
100 
200 
Delay 
3.2 Anomaly Signal 
Figure 1. The normalized 
between components 
A and B. 
cross-correlation 
We quantify 
the behavior 
of components 
the anomaly signal Aj (t) describes 
surprise: 
which the behavior 
The instantaneous 
score. Let A(t) =  a for any t outside 
anomaly signal. 
and standard 
a j. 
deviation 
We require 
the domain of the 
that Aj(t) has finite mean J.lj 
of component 
value of the signal is called the anomaly 
j is anomalous 
in terms of 
the extent to 
at time t. 
The anomaly signal should usually 
take values close to 
is an obvious 
semantics. 
the mean of its distribution-this 
of its intended 
responds 
so values far from the mean are more surprising 
close to the mean. 
to the extent to which the behavior 
The distance 
from the mean cor­
than those 
is anomalous, 
consequence 
The user defines what constitutes 
surprising 
behavior 
by 
an appropriate 
from average 
temperature, 
selecting 
deviation 
threshold 
factors 
tion of measurable, 
from an expected 
model. For example, 
log message rate, degrees 
the divergence 
one could use 
above a 
of a distribution 
of 
or some other func­