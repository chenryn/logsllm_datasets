# Using Correlated Surprise to Infer Shared Influence

**Authors:**  
Adam J. Oliner, Ashutosh V. Kulkarni, and Alex Aiken  
*Stanford University, Department of Computer Science*  
*{oliner, ashutosh.kulkarni, aiken}@cs.stanford.edu*

**Abstract:**
In complex production systems, the cost of instrumentation can be prohibitive, leading to noisy or incomplete data. We propose a method for identifying interactions among system components by analyzing time-correlated anomalous behavior. Our approach defines "influences" as a class of component interactions, including source contention, and constructs a Structure-of-Influence Graph (SIC) to summarize these influences. This paper explains how to build a SIC and uses it to isolate system misbehavior in both simulations and real-world case studies, including a 9024-node supercomputer and two autonomous vehicles.

## 1. Introduction
Complex production systems are often constructed from many interacting subsystems, making comprehensive monitoring and analysis challenging. The costs and difficulties associated with instrumentation mean that we may not have complete knowledge of all components and their interactions. For example, if a performance glitch or an outright crash occurs, how do we identify the source of the problem? 

Our method addresses this issue by mapping all components' behavior into a single dimension, quantifying how anomalous each component's behavior is. This anomaly signal is real-valued, allowing for a more nuanced representation of component behavior compared to binary approaches. When two anomaly signals are correlated, we infer that the components share an influence. This correlation can include directionality, which is represented using effect delays.

The key features of our approach are:
- **Passive Monitoring:** No need for intrusive instrumentation or expert knowledge.
- **Real-Valued Anomaly Signals:** Retains more information about component behavior.
- **Graceful Degradation:** Works well even with noisy or incomplete data.
- **Correlation-Based Inference:** Focuses on correlations rather than causality.

We demonstrate the effectiveness of our method through controlled experiments, simulations, and real-world case studies, showing that it can detect a broad class of interactions with fewer assumptions about available data.

## 2. Related Work
There is extensive work on inferring the causal or dependency structure of distributed systems. However, our method differs in that it focuses on influences (correlations) rather than direct dependencies. Previous methods, such as Shrink [11], SCORE [12], and Bahl [2], aim to infer root causes or multi-level dependency graphs but require explicit instrumentation or probabilistic models. Our method, in contrast, works directly with real-valued anomaly signals, degrading gracefully with noisy or incomplete data.

## 3. The Method
This section describes how to construct and interpret a Structure-of-Influence Graph (SIG). The process consists of four steps:
1. **Modeling Component Behavior:** Decide what information to use from each component during actual operation.
2. **Measuring Anomaly Signals:** Quantify the extent to which each component's behavior is anomalous.
3. **Computing Pairwise Correlations:** Determine the strength and delay of correlations between all components' anomaly signals.
4. **Constructing the SIG:** Create a graph where nodes represent components and edges represent the strength and delay of correlations.

### 3.1 Modeling Component Behavior
The choice of model determines the semantics of the anomaly signal. Two models have been particularly useful in practice:
- **Timing Model:** Tracks past interarrival times and computes the surprise of the most recent interarrival time.
- **Content Model:** Analyzes the distributions of message contents using term entropy.

### 3.2 Anomaly Signal
We quantify the behavior of components in terms of surprise. The anomaly signal \( A_j(t) \) describes the extent to which the behavior of component \( j \) is anomalous at time \( t \). The user defines surprising behavior by selecting an appropriate threshold for deviation from an expected model. For example, one could use a divergence of a distribution from average temperature, log message rate, or other measurable factors.

## 4. Experimental Results
Our experimental results show that SIGs can detect a broad class of interactions in complex systems, including resource contention, delayed effects, and asynchronous communication. We present controlled experiments, simulations, and real-world case studies, including a 9024-node supercomputer and two autonomous vehicles. These examples demonstrate the ability of SIGs to isolate the source of critical bugs and identify significant contributors to system misbehavior.

## 5. Conclusion
As systems grow in scale and complexity, the need for effective monitoring and analysis techniques becomes increasingly important. Our method, based on correlated surprise, provides a robust and flexible approach to inferring shared influences among system components. By working directly with real-valued anomaly signals, our method degrades gracefully with noisy or incomplete data and requires fewer assumptions about available data than previous approaches. Future work will explore the application of SIGs to a wider range of systems and scenarios.

---

**Acknowledgments:**
This work was supported in part by NSF grant CCF-0915766 and the DOE High-Performance Computer Science Fellowship.

**References:**
[1] Project5  
[2] Bahl  
[3] Magpie  
[4] Previous Work  
[5] System Modeling  
[6] Dependency Modeling  
[7] Pinpoint  
[8] WAP5  
[9] Pip  
[10] SCORE  
[11] Shrink  
[12] Bayesian Networks  
[15] Existing Method  
[17] Causal Paths  
[18] Message Traces  
[19] Performance Administration

**Copyright:**
978-1-4244-7501-8/10/$26.00 Â©201O IEEE

**Authorized Use:**
Licensed use limited to: Tsinghua University. Downloaded on March 18, 2021, at 14:06:05 UTC from IEEE Xplore. Restrictions apply.