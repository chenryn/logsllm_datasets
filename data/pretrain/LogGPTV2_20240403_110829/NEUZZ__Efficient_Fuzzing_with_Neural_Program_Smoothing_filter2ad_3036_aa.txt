title:NEUZZ: Efficient Fuzzing with Neural Program Smoothing
author:Dongdong She and
Kexin Pei and
Dave Epstein and
Junfeng Yang and
Baishakhi Ray and
Suman Jana
(cid:19)(cid:17)(cid:18)(cid:26)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:1)(cid:52)(cid:90)(cid:78)(cid:81)(cid:80)(cid:84)(cid:74)(cid:86)(cid:78)(cid:1)(cid:80)(cid:79)(cid:1)(cid:52)(cid:70)(cid:68)(cid:86)(cid:83)(cid:74)(cid:85)(cid:90)(cid:1)(cid:66)(cid:79)(cid:69)(cid:1)(cid:49)(cid:83)(cid:74)(cid:87)(cid:66)(cid:68)(cid:90)
NEUZZ: Efﬁcient Fuzzing with Neural
Program Smoothing
Dongdong She, Kexin Pei, Dave Epstein, Junfeng Yang, Baishakhi Ray, and Suman Jana
Columbia University
Abstract—Fuzzing has become the de facto standard technique
for ﬁnding software vulnerabilities. However, even state-of-the-
art
fuzzers are not very efﬁcient at ﬁnding hard-to-trigger
software bugs. Most popular fuzzers use evolutionary guidance
to generate inputs
that can trigger different bugs. Such
evolutionary algorithms, while fast and simple to implement,
often get stuck in fruitless sequences of random mutations.
Gradient-guided optimization presents a promising alternative
to evolutionary guidance. Gradient-guided techniques have been
shown to signiﬁcantly outperform evolutionary algorithms at
solving high-dimensional structured optimization problems in
domains like machine learning by efﬁciently utilizing gradients
or higher-order derivatives of the underlying function.
However,
gradient-guided approaches
are not directly
applicable to fuzzing as real-world program behaviors contain
many discontinuities, plateaus, and ridges where the gradient-
based methods often get stuck. We observe that this problem
can be addressed by creating a smooth surrogate function
approximating the target program’s discrete branching behavior.
In this paper, we propose a novel program smoothing technique
using surrogate neural network models that can incrementally
learn smooth approximations of a complex, real-world program’s
branching behaviors. We further demonstrate that such neural
network models can be used together with gradient-guided
input generation schemes to signiﬁcantly increase the efﬁciency
of the fuzzing process.
Our
extensive
evaluations
demonstrate
that NEUZZ
signiﬁcantly outperforms 10 state-of-the-art graybox fuzzers on
10 popular real-world programs both at ﬁnding new bugs and
achieving higher edge coverage. NEUZZ found 31 previously
unknown bugs (including two CVEs) that other fuzzers failed
to ﬁnd in 10 real-world programs and achieved 3X more edge
coverage than all of the tested graybox fuzzers over 24 hour
runs. Furthermore, NEUZZ also outperformed existing fuzzers
on both LAVA-M and DARPA CGC bug datasets.
I. INTRODUCTION
Fuzzing has become the de facto standard technique for
ﬁnding software vulnerabilities [88], [25]. The fuzzing process
involves generating random test inputs and executing the target
program with these inputs to trigger potential security vulner-
abilities [59]. Due to its simplicity and low performance over-
head, fuzzing has been very successful at ﬁnding different types
of security vulnerabilities in many real-world programs [3], [1],
[30], [70], [11], [78]. Despite their tremendous promise, popular
fuzzers, especially for large programs, often tend to get stuck
trying redundant test inputs and struggle to ﬁnd security vul-
nerabilities hidden deep within program logic [82], [36], [68].
Conceptually, fuzzing is an optimization problem whose
goal is to ﬁnd program inputs that maximize the number
of vulnerabilities found within a given amount of testing
time [60]. However, as security vulnerabilities tend to be
sparse and erratically distributed across a program, most
fuzzers aim to test as much program code as they can by
maximizing some form of code coverage (e.g., edge coverage)
to increase their chances of ﬁnding security vulnerabilities.
Most popular fuzzers use evolutionary algorithms to solve the
underlying optimization problem—generating new inputs that
maximize code coverage [88], [11], [78], [45]. Evolutionary
optimization starts from a set of seed inputs, applies random
mutations to the seeds to generate new test inputs, executes the
target program for these inputs, and only keeps the promising
new inputs (e.g., those that achieve new code coverage) as part
of a corpus for further mutation. However, as the input corpus
gets larger, the evolutionary process becomes increasingly less
efﬁcient at reaching new code locations.
One of the main limitations of evolutionary optimization
algorithms is that they cannot leverage the structure (i.e.,
gradients or other higher-order derivatives) of the underlying
optimization problem. Gradient-guided optimization (e.g.,
gradient descent) is a promising alternative approach that has
been shown to signiﬁcantly outperform evolutionary algorithms
at solving high-dimensional structured optimization problems
in diverse domains including aerodynamic computations and
machine learning [89], [46], [38].
However, gradient-guided optimization algorithms cannot
be directly applied to fuzzing real-world programs as they
often contain signiﬁcant amounts of discontinuous behaviors
(cases where the gradients cannot be computed accurately)
due to widely different behaviors along different program
branches [67], [21], [43], [20], [22]. We observe that this
problem can be overcome by creating a smooth (i.e., differen-
tiable) surrogate function approximating the target program’s
branching behavior with respect to program inputs. Unfortu-
nately, existing program smoothing techniques [21], [20] incur
prohibitive performance overheads as they depend heavily on
symbolic analysis that does not scale to large programs due to
several fundamental limitations like path explosion, incomplete
environment modeling, and large overheads of symbolic
memory modeling [50], [77], [14], [16], [15], [35], [49].
(NNs)
In this paper, we introduce a novel, efﬁcient, and scalable
program smoothing technique using feed-forward Neural
Networks
that can incrementally learn smooth
approximations of complex, real-world program branching
behaviors, i.e., predicting the control ﬂow edges of the target
program exercised by a particular given input. We further
propose a gradient-guided search strategy that computes and
(cid:165)(cid:1)(cid:19)(cid:17)(cid:18)(cid:26)(cid:13)(cid:1)(cid:37)(cid:80)(cid:79)(cid:72)(cid:69)(cid:80)(cid:79)(cid:72)(cid:1)(cid:52)(cid:73)(cid:70)(cid:15)(cid:1)(cid:54)(cid:79)(cid:69)(cid:70)(cid:83)(cid:1)(cid:77)(cid:74)(cid:68)(cid:70)(cid:79)(cid:84)(cid:70)(cid:1)(cid:85)(cid:80)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:15)
(cid:37)(cid:48)(cid:42)(cid:1)(cid:18)(cid:17)(cid:15)(cid:18)(cid:18)(cid:17)(cid:26)(cid:16)(cid:52)(cid:49)(cid:15)(cid:19)(cid:17)(cid:18)(cid:26)(cid:15)(cid:17)(cid:17)(cid:17)(cid:22)(cid:19)
(cid:25)(cid:17)(cid:20)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:52:15 UTC from IEEE Xplore.  Restrictions apply. 
leverages the gradient of the smooth approximation (i.e., an NN
model) to identify target mutation locations that can maximize
the number of detected bugs in the target program. We
demonstrate how the NN model can be reﬁned by incrementally
retraining the model on mispredicted program behaviors. We
ﬁnd that feed-forward NNs are a natural ﬁt for our task because
of (i) their demonstrated ability to approximate complex
non-linear functions, as implied by the universal approximation
theorem [33], and (ii) their support for efﬁcient and accurate
computation of gradients/higher-order derivatives [38].
We design and implement our technique as part of NEUZZ,
a new learning-enabled fuzzer. We compare NEUZZ with 10
state-of-the art fuzzers on 10 real-world programs covering
6 different ﬁle formats, (e.g., ELF, PDF, XML, ZIP, TTF, and
JPEG) with an average of 47, 546 lines of code, the LAVA-M
bug dataset [28], and the CGC dataset [26]. Our results show
that NEUZZ consistently outperforms all the other fuzzers by a
wide margin both in terms of detected bugs and achieved edge
coverage. NEUZZ found 31 previously unknown bugs (including
CVE-2018-19931 and CVE-2018-19932) in the tested programs
that other fuzzers failed to ﬁnd. Our tests on the DARPA
CGC dataset also conﬁrmed that NEUZZ can outperform state-
of-the-art fuzzers like Driller [82] at ﬁnding different bugs.
Our primary contributions in this paper are as follows:
• We are the ﬁrst to identify the signiﬁcance of program
gradient-guided
adopting
efﬁcient
smoothing
techniques for fuzzing.
for
• We introduce the ﬁrst efﬁcient and scalable program
smoothing technique using surrogate neural networks
to effectively model
the target program’s branching
behaviors. We further propose an incremental learning
technique to iteratively reﬁne the surrogate model as
more training data becomes available.
• We demonstrate that
the gradients of the surrogate
neural network model can be used to efﬁciently generate
program inputs that maximize the number of bugs found
in the target program.
• We design, implement, and evaluate our techniques as
part of NEUZZ and demonstrate that
it signiﬁcantly
outperforms 10 state-of-the-art fuzzers on a wide range
of real-world programs as well as curated bug datasets.
The rest of the paper is organized as follows. Section II
summarizes
the necessary background information on
optimization and gradient-guided techniques. Section III
provides an overview of our technique along with a motivating
example. Section IV and Section V describe our methodology
and implementation in detail. We present our experimental
results in Section VI and describe some sample bugs found by
NEUZZ in Section VII. Section VIII summarizes the related
work and Section IX concludes the paper.
II. OPTIMIZATION BASICS
In this section, we ﬁrst describe the basics of optimization
and the beneﬁts of gradient-guided optimization over evolu-
tionary guidance for smooth functions. Finally, we demonstrate
how fuzzing can be cast as an optimization problem.
An optimization problem usually consists of three different
components: a vector of parameters x, an objective function
F (x) to be minimized or maximized, and a set of constraint
functions Ci(x) each involving either inequality or equality
that must be satisﬁed. The goal of the optimization process
is to ﬁnd a concrete value of the parameter vector x that
maximizes/minimizes F (x) while satisfying all constraint
functions Ci(x) as shown below.
(cid:2)
max/min
x∈Rn
F (x) subject to
Ci(x) ≥ 0, i ∈ N
Ci(x) = 0, i ∈ Q
(1)
Here R, N, and Q denote the sets of real numbers, the
indices for inequality constraints, and the indices for equality
constraints, respectively.
Function
smoothness & optimization. Optimization
algorithms usually operate in a loop beginning with an initial
guess of the parameter vector x and gradually iterating to
ﬁnd better solutions. The key component of any optimization
algorithm is the strategy it uses to move from one value of x
to the next. Most strategies leverage the values of the objective
function F , the constraint functions Ci, and, if available, the
gradient/higher-order derivatives.
For
the rest of
The ability and efﬁciency of different optimization
algorithms to converge to the optimal solution heavily depend
on the nature of the objective and constraint functions F and
Ci. In general, smoother functions (i.e., those with well-deﬁned
and computable derivatives) can be more efﬁciently optimized
than functions with many discontinuities (e.g., ridges or
plateaus). Intuitively, the smoother the objective/constraint
functions are, the easier it is for the optimization algorithms to
accurately compute gradients or higher-order derivatives and
use them to systematically search the entire parameter space.
this paper, we speciﬁcally focus on
unconstrained optimization problems that do not have any
constraint functions, i.e., C = φ, as they closely mimic fuzzing,
our target domain. For unconstrained smooth optimization
problems, gradient-guided approaches
can signiﬁcantly
outperform evolutionary strategies at solving high-dimensional
structured optimization problems
[89], [46], [38]. This
is because gradient-guided techniques effectively leverage
gradients/higher-order derivatives to efﬁciently converge to
the optimal solution as shown in Figure 1.
Convexity & gradient-guided optimization. For a common
class of functions called convex functions, gradient-guided
techniques are highly efﬁcient and can always converge to
the globally optimal solution [86]. Intuitively, a function is
convex if a straight line connecting any two points on the
graph of the function lies entirely above or on the graph.
More formally, a function f is called convex if the following
property is satisﬁed by all pairs of points x and y in its
domain: f (tx + (1 − t)y) ≤ tf (x) + (1 − t)f (y),∀t ∈ [0, 1].
However, in non-convex functions, gradient-guided approach
may get stuck at locally optimal solutions where the objective
function is greater (assuming that the goal is to maximize)
(cid:25)(cid:17)(cid:21)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:52:15 UTC from IEEE Xplore.  Restrictions apply. 
[QjQ<YhIIGh
"Ikg<Y
hZ]]jPQ[O
.INQ[IqQjP
Q[EgIZI[j<Y
YI<g[Q[O
kOhpkY[Ig<DQYQjQIh
/Z]]jP
""Z]GIY
0<gOIj
dg]Og<Z
g<GQI[jOkQGIG
]djQZQv<jQ][
0Ihj
Q[dkjh
Fig. 2: An overview of our approach
Neural program smoothing. Approximating a program’s
discontinuous branching behavior smoothly is essential for
accurately computing gradients or higher-order derivatives
that are necessary for gradient-guided optimization. Without
such smoothing, the gradient-guided optimization process may
get stuck at different discontinuities/plateaus. The goal of the
smoothing process is to create a smooth function that can mimic
a program’s branching behavior without introducing large errors
(i.e., it deviates minimally from the original program behavior).
We use a feed-forward neural network (NN) for this purpose.
As implied by the universal approximation theorem [33], an NN
is a great ﬁt for approximating arbitrarily complex (potentially
non-linear and non-convex) program behaviors. Moreover,
NNs, by design, also support efﬁcient gradient computation
that is crucial for our purposes. We train the NN by either
using existing test inputs or with the test input corpus generated
by existing evolutionary fuzzers as shown in Figure 2.
Gradient-guided optimization. The smooth NN model,
once trained, can be used to efﬁciently compute gradients
and higher-order derivatives that can then be leveraged
for faster convergence to the optimal solution. Different
variants of gradient-guided algorithms like gradient descent,
Newton’s method, or quasi-Newton methods like the L-BFGS
algorithm use gradients or higher-order derivatives for faster
convergence [10], [13], [65]. Smooth NNs enable the fuzzing
input generation process to potentially use all of these
techniques. In this paper, we design, implement and evaluate
a simple gradient-guided input generation scheme tailored for
coverage-based fuzzing as described in detail in Section IV-C.
Incremental learning. Any types of existing test inputs (as
long as they expose diverse behaviors in the target program)
can be potentially used to train the NN model and bootstrap the
fuzzing input generation process. In this paper, we train the NN
by collecting a set of test inputs and the corresponding edge
coverage information by running evolutionary fuzzers like AFL.
However, as the initial training data used for training the
NN model may only cover a small part of the program space,
we further reﬁne the model through incremental training as
new program behaviors are observed during fuzzing. The key
challenge in incremental training is that if an NN is only
trained on new data, it might completely forget the rules
it learned from old data [57]. We avoid this problem by
designing a new coverage-based ﬁltration scheme that creates
a condensed summary of both old and new data, allowing the
NN to be trained efﬁciently on them.
(a) gradient descent
(b) evolutionary algorithm
Fig. 1: Gradient-guided optimization algorithms like gradient
descent can be signiﬁcantly more efﬁcient than evolutionary
algorithms that do not use any gradient information
than all nearby feasible points but there are other larger values
present elsewhere in the entire range of feasible parameter
values. However, even for such cases, simple heuristics like
restarting the gradient-guided methods from new randomly
chosen starting points have been shown to be highly effective
in practice [38], [86].
Fuzzing as unconstrained optimization. Fuzzing can be
represented as an unconstrained optimization problem where
the objective is to maximize the number of bugs/vulnerabilities
found in the test program for a ﬁxed number of test inputs.
Therefore, the objective function can be thought of as Fp(x),
which returns 1 if input x triggers a bug/vulnerability when
the target program p is executed with input x. However, such a
function is too ill-behaved (i.e., mostly containing ﬂat plateaus
and a few very sharp transitions) to be optimized efﬁciently.
Therefore, most graybox fuzzers instead try to maximize
the amount of tested code (e.g., maximize edge coverage) as
a stand-in proxy metric [88], [11], [73], [55], [22]. Such an
objective function can be represented as F
returns
the number of new control ﬂow edges covered by the input x
for program P . Note that F
is relatively easier to optimize than
the original function F as the number of all possible program
inputs exercising new control ﬂow edges tend to be signiﬁcantly
higher than the inputs that trigger bugs/security vulnerabilities.
evolutionary
techniques [88], [11], [73], [55], [22] along with other
domain-speciﬁc heuristics
their main optimization
strategy. The key reason behind picking such algorithms
over gradient-guided optimization is that most real-world
programs contain many discontinuities due to signiﬁcantly
different behaviors along different program paths [19]. Such
discontinuities may cause the gradient-guided optimization to
get stuck at non-optimal solutions. In this paper, we propose
a new technique using a neural network for smoothing the
target programs to make them suitable for gradient-guided
optimization and demonstrate how fuzzers might exploit such
strategies to signiﬁcantly boost their effectiveness.
(cid:3)
p(x) where F
graybox
fuzzers
use
Most
existing
(cid:3)
(cid:3)
as
III. OVERVIEW OF OUR APPROACH
Figure 2 presents a high level overview of our approach.
We describe the key components in detail below.
(cid:25)(cid:17)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:52:15 UTC from IEEE Xplore.  Restrictions apply. 
(a) Original
(b) NN smoothing
(c) NN smoothing + reﬁning
return 1;
1 z = pow(3, a+b);
2 if(z < 1){
3
4 }
5 else if(z < 2){
6
7
8 }
9 else if(z < 4){
10
11 }
//vulnerability
return 2;
return 4;
Fig. 3: Simple code snippet demonstrating the beneﬁts of neural smoothing for fuzzing
A Motivating Example. We show a simple motivating