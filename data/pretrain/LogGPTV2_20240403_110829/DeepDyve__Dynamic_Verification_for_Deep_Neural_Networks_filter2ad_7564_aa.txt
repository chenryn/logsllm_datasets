title:DeepDyve: Dynamic Verification for Deep Neural Networks
author:Yu Li and
Min Li and
Bo Luo and
Ye Tian and
Qiang Xu
DeepDyve: Dynamic Verification for Deep Neural Networks
Yu Li∗, Min Li∗, Bo Luo, Ye Tian, and Qiang Xu
CUhk REliable Computing Laboratory (CURE)
Department of Computer Science and Engineering
The Chinese University of Hong Kong, Shatin, N.T., Hong Kong
Email: {yuli, mli, boluo, tianye, qxu}@cse.cuhk.edu.hk
0
2
0
2
t
c
O
6
1
]
G
L
.
s
c
[
2
v
3
6
6
9
0
.
9
0
0
2
:
v
i
X
r
a
ABSTRACT
Deep neural networks (DNNs) have become one of the enabling
technologies in many safety-critical applications, e.g., autonomous
driving and medical image analysis. DNN systems, however, suffer
from various kinds of threats, such as adversarial example attacks
and fault injection attacks. While there are many defense meth-
ods proposed against maliciously crafted inputs, solutions against
faults presented in the DNN system itself (e.g., parameters and
calculations) are far less explored. In this paper, we develop a novel
lightweight fault-tolerant solution for DNN-based systems, namely
DeepDyve, which employs pre-trained neural networks that are
far simpler and smaller than the original DNN for dynamic ver-
ification. The key to enabling such lightweight checking is that
the smaller neural network only needs to produce approximate
results for the initial task without sacrificing fault coverage much.
We develop efficient and effective architecture and task exploration
techniques to achieve optimized risk/overhead trade-off in Deep-
Dyve. Experimental results show that DeepDyve can reduce 90%
of the risks at around 10% overhead.
CCS CONCEPTS
• Computing methodologies→ Neural networks; • Hardware
→ System-level fault tolerance.
KEYWORDS
Deep learning; Fault injection attack; Dynamic verification
ACM Reference Format:
Yu Li, Min Li, Bo Luo, Ye Tian and Qiang Xu. 2020. DeepDyve: Dynamic
Verification for Deep Neural Networks. In Proceedings of the 2020 ACM
SIGSAC Conference on Computer and Communications Security (CCS ’20),
November 9–13, 2020, Virtual Event, USA. ACM, New York, NY, USA, 12 pages.
https://doi.org/10.1145/3372297.3423338
1 INTRODUCTION
Machine learning with deep neural networks (DNNs) can produce
results that have surpassed human-level performance in many chal-
lenging tasks lately, and it keeps improving. Consequently, DNNs
∗These two authors contributed equally.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’20, November 9–13, 2020, Virtual Event, USA
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-7089-9/20/11...$15.00
https://doi.org/10.1145/3372297.3423338
have become one of the foundation techniques in artificial intelli-
gence (AI) applications. Lots of them (e.g., autonomous driving and
medical image analysis) are safety- and security-sensitive.
Many researchers in the machine learning community believe
that DNNs are rather robust to faults [10, 22], wherein removing
some neurons or parameters leads to a graceful degradation in
model accuracy. However, practical faults do not manifest them-
selves as the elimination of individual weights or neurons. Instead,
they lead to bit-flips on DNN parameters or activations. Li et al. [23]
conducted a case study on the Eyeriss DNN accelerator [4] under
transient faults. Their results show that the FIT rate caused by
random soft errors is far beyond the one required by the ISO 26262
standard (10 FIT1) [14] for the functional safety of road vehicles.
Comparing to random errors, transient faults caused by malicious
attacks are more severe. A recent attack named DeepHammer [44]
shows that it can successfully tamper DNN inference behavior in
practical setup, wherein the accuracy of multiple DNN classifica-
tion systems are reduced to be as low as random guess within a
few minutes, by leveraging the rowhammer vulnerability of DRAM
used in the system.
There are a few recent research towards fault-tolerant DNN sys-
tem designs. In [23], Li et al. proposed to set up a simple threshold
to detect those faults that lead to drastic changes in DNN parame-
ters. Such symptom-based error detectors have very little hardware
overhead, but their detection capabilities are quite limited, espe-
cially for those quantized DNNs used in safety-critical embedded
systems. They are also not applicable to defend against malicious
faults [33, 44, 45]. To tackle this problem, a replication-based error
detection technique for DNN systems was proposed in [24], but its
overhead is quite high, requiring 40% extra computation to reach
60% fault coverage on CIFAR-10 dataset.
This paper aims for a solution with sufficient fault coverage
yet little overhead for DNN-based classification systems. The term
dynamic verification was introduced in [1], which detects errors
in a complex super-scalar core by checking it with a core that is
architecturally identical but micro-architecturally far simpler and
smaller. Unlike symptom-based error detection techniques that
check for abnormal behaviors, dynamic verification techniques
check for in-variants in the system that are nearly always true over
all possible executions. Following this idea, the proposed solution,
namely DeepDyve, deploys a small neural network (referred to as
the checker DNN) to approximate the original complex DNN model
(referred to as the task DNN), and checks whether they produce
consistent outputs in an end-to-end manner. If their results do not
match, re-computation on the task DNN is performed for potential
fault recovery, if any.
1Failure-in-Time Rate: 1 FIT = 1 failure per 1 billion hours.
Unlike [1], the result produced by the small checker DNN for
error detection is only an approximate result. Hence, there will be
both false positives (i.e., flagging nonexistent failures) and false neg-
atives (i.e., miss to report failures) with DeepDyve. False positives
result in unnecessary re-computation cost, while false negatives
lead to fault coverage loss. Consequently, it is essential to achieve
high consistency between the task DNN and the checker DNN un-
der the fault-free situation. We formulate the checker DNN design
problem as a design exploration problem, wherein we evaluate a set
of candidate small DNN designs for the given big task DNN model
and choose the one with optimized coverage/overhead trade-off as
the checker DNN.
On the one hand, we obtain the set of candidate checker DNNs
by compressing and transferring the task DNN model’s knowledge
through knowledge distillation [11]. On the other hand, the given
classification task might be too complicated for the much smaller
checker DNNs. Under such circumstances, we allow the checker
DNN to perform the classification task with reduced complexity.
For example, given a task to classify ten objects wherein two kinds
of objects are easily confused, we could allow the checker DNN to
perform a simpler problem with these two objects treated as one
class. By doing so, there will be much less false positives in dynamic
verification, at the cost of more false negatives since we would
not be able to identify those faults that result in misclsssification
between these two kinds of objects. Consequently, we need to
carefully perform task simplification for the checker DNN design
to strike an optimized balance between coverage and overhead.
From the safety and security perspective, misclassifying different
classes often has quite different impacts. For example, in a traffic
sign recognition system, misclassifying a "Yield" sign as a "Stop" sign
does not cause much trouble, but the opposite misclassification may
cause severe traffic accidents. We need to consider such risk impacts
in the checker DNN design. That is, we should be more concerned
about the risk/overhead trade-off instead of coverage/overhead
trade-off.
The proposed DeepDyve solution considers the above issues,
and the main contributions of this paper include:
• To the best of our knowledge, DeepDyve is the first dynamic
verification technique for resilient DNN designs, which uses
a far simpler and smaller checker DNN for online error de-
tection and recovery.
• We propose a novel two-stage checker DNN design method-
ology, which explores both the checker DNN architectures
and task simplification possibilities. In particular, we propose
a novel checker DNN architecture exploration technique
with theoretical guarantees. Also, being able to manipulate
the tasks performed on the checker DNN dramatically in-
creases the solution space of DeepDyve.
• DeepDyve leverages the uneven risk probabilities and safety
impact among classes to guide the design exploration proce-
dure. Experimental results on CIFAR-10, GTSRB, CIFAR-100,
and Tiny-ImageNet datasets show that it can reduce up to
90% of the risks at around 10% computational overhead.
We organize the remainder of this paper as follows. Section 2
presents the preliminaries and motivation of this work. Then, we
give an overview of DeepDyve in Section 3. Next, we detail the
checker DNN architecture exploration and task exploration tech-
niques in Section 4 and 5, respectively. Experimental results are
presented in Section 6. Then, we discuss the applications and limi-
tations of DeepDyve in Section 7, followed by the survey of related
works in Section 8. Finally, Section 9 concludes this paper.
2 PRELIMINARIES AND MOTIVATION
In this section, we first present the impact of hardware faults (ran-
dom or malicious) on the reliability and security of DNN systems
in Section 2.1. Then, we provide the threat model in Section 2.2.
At last, we illustrate the motivation for the proposed DeepDyve
solution in Section 2.3.
2.1 DNN Systems under Faults
There are mainly two types of attacks during the inference of DNN
systems: adversarial example attack and fault injection attack. Ad-
versarial example attacks [9, 28] try to fool DNN systems by crafting
subtle malicious perturbations on inputs, and there is a vast body
of research on this topic [20, 27, 31, 32]. By contrast, fault injection
attack aims to break the system by injecting faults into the inter-
nal system execution pipeline, e.g., flipping data bits in processing
elements. This problem is less explored in the literature, and the
overhead of existing defense techniques is quite high.
Various types of transient faults can be introduced into DNN sys-
tems by attackers, e.g., clock glitch attack [30], voltage glitch attack
[36], and rowhammer attack [17]. Besides malicious faults, tran-
sients faults could also occur due to environmental perturbations
such as alpha particle strikes.
The Impact of Transient Faults. Transient faults may occur at
the data paths and buffers of processing units [23] or inside the
memories of DNN-based systems [12]. Such faults would man-
ifest themselves as errors in DNN calculations or intermediate
values [34] during inference. A failure occurs when errors prop-
agate to the outputs of the system and cause behavioral changes,
which could lead to catastrophic consequences in safety-critical
applications, e.g., misclassifying a "Stop" sign as a "Yield" sign in au-
tonomous vehicles and taking the wrong action. In the following, if
not specified, faults, errors and failures are used in an exchangeable
manner, and we are only concerned with those faults that cause