### Evaluation and Performance Measurements

The evaluation of EnTrust was comprehensive, encompassing both functional and performance aspects. The testing process took 19 hours and 45 minutes to complete. During this period, EnTrust successfully passed 132,681 tests without causing any system crashes or incorrectly blocking legitimate operations. Among the 1,000 tested applications, we included five popular augmented reality multiplayer gaming apps (Ingress, Pokémon Go, Parallel Kingdom, Run An Empire, and Father.io), which are known for their high rate of input events and sensitivity to delays. The specific tests targeting these gaming apps ran for 16 minutes, during which we continuously monitored the device screen to detect any issues related to responsiveness or rendering glitches. No discernible slowdowns, glitches, or responsiveness issues were observed.

#### Performance Measurements

We conducted four micro-benchmarks on a standard Android developer smartphone, the LG Nexus 5X, equipped with a 1.8GHz hexa-core 64-bit Qualcomm Snapdragon 808 Processor, Adreno 418 GPU, 2GB of RAM, and 16GB of internal storage. All benchmarks were performed using Android 7.1 Nougat, sourced from the Android Open Source Project (AOSP) repository.

**Delegation Graph Construction:**
Our first micro-benchmark measured the overhead incurred in constructing delegation graphs of varying sizes. We generated handoff-event chains ranging from 1 to 10 handoffs and measured the time required to mediate the input event, the handoff event, and the operation request. Each set of measurements was preceded by a priming run to eliminate first-run effects. We then averaged the middle 8 out of 10 runs for each number of handoff events. The results, shown in Figure 7, indicate that input mediation requires an overhead of 10 µs, handoff event mediation adds an additional 4 µs per event handoff, and operation mediation incurs a fixed overhead of 5 µs. These overheads are within expected limits and do not cause noticeable performance degradation.

**Delegation Graph Caching:**
The second micro-benchmark measured the overhead for caching delegation graphs constructed at runtime. We simulated the creation and eviction of delegation graphs of different sizes, ranging from 1 to 16 Kilobytes in 512-byte increments. Each size was measured 5 times, and the middle 3 out of 5 runs were averaged. The results, also shown in Figure 7, reveal that storing delegation graphs in the cache requires a base overhead of 66 µs, with an additional 3 µs per 512-byte increment. Eviction, on the other hand, requires a base overhead of 57 µs, with an additional 2.5 µs for each 512-byte increment.

**Delegation Graph Enforcement:**
The third micro-benchmark compared the unmodified version of the Android Nougat build with a modified build integrating EnTrust features for delegation graph enforcement during authorization. To ensure fairness, we used the Android UI/Application Exerciser Monkey to generate the same sequence of events for the same set of programs. We measured the total time needed to authorize a sensor operation, from the input event to the authorization of the resulting operation request. Each set of measurements was preceded by a priming run, and the middle 8 out of 10 runs were averaged for each number of handoff events. As shown in Figure 7, the overhead introduced by EnTrust for delegation graph enforcement is negligible, with the highest observed overhead being below 0.02%. This indicates that the slowdown is unlikely to be noticeable to users.

**Ambiguity Prevention:**
The fourth micro-benchmark evaluated the performance in terms of delayed events due to the ambiguity prevention mechanism. We selected the system UI (User Interface) process, which receives a high number of input events, and the media server process, which handles frequent handoff events and sensor operations. The time window for constructing each delegation path was set to 150 ms. We generated 15,000 input events with gaps randomly selected in the range [140-1,500] ms. The generated input events caused 2,037 handoff events and 5,252 operation requests targeting sensors (22,289 total scheduled events). The results indicated a total of 256 delayed events (1.15% of the total events), with a maximum recorded delay of 9 ms. Thus, the performance overhead introduced is negligible.

**Memory Requirement:**
We also recorded the average cache size required by EnTrust to store both event mappings and authorized delegation graphs. For up to 1,000 programs, EnTrust required approximately 5.5 megabytes of memory, or about 5.5 kilobytes per program. This is a small amount of memory compared to the several gigabytes of storage available in modern systems. The measurement was repeated 10 times, and the middle 8 out of 10 runs were averaged.

### Discussion of Limitations

Evaluating mechanisms that prevent abuse of sensitive sensors while balancing privacy and usability is challenging. In this section, we discuss the limitations of our study and provide guidance for future work.

**Authorization Comprehension:**
In designing our authorization messages, we referenced the language used in current permission systems (e.g., Android OS and Apple iOS) and prior research. However, this language may not be as effective in eliciting access control decisions from users as desired. Further improvements could be achieved by studying natural language processing (NLP) techniques and how access control questions can be phrased using such techniques. Additionally, a combination of text, sound, and visuals may be useful in conveying access questions to users. EnTrust is designed to be flexible, allowing it to be used as a platform for further study.

**Decision Revocation:**
Users may make mistakes when authorizing or denying access. EnTrust caches user decisions to reduce authorization effort, which can allow such mistakes to persist. Mistakes in authorizing access to sensor operations may permit malicious applications to abuse access, albeit limited to that delegation path. Conversely, mistakes in denying access to sensor operations can prevent legitimate use of sensor operations. One possible solution is to periodically invalidate the cache, but frequent authorization prompts can negatively affect user experience. Currently, EnTrust enables users to review authorization decisions via an audit mechanism. Further laboratory studies will be necessary to examine how to present audit results effectively and help users resolve mistaken authorizations.

**Study Scenarios:**
Our project focused on whether users could effectively deny attack scenarios. Another concern is that users may not evaluate non-attack scenarios correctly once they become aware of possible attacks. In our study, we did not observe any false denials of legitimate sensor operations, but extending the study to include more subtle non-attack scenarios would be beneficial. It is also worth noting that all attacks in our study were generated by unfamiliar programs, even though participants had the opportunity to familiarize themselves with these programs during the preliminary phase.

**Study Size:**
The number of subjects recruited for this project—60 for the laboratory study and 9 for the field study—is comparable to similar studies. Other related work has involved a higher number of subjects, but those studies were conducted online. Research has shown that laboratory studies may produce more realistic results than online studies, particularly in the context of password studies.

**Study Comprehensiveness:**
Our study does not explicitly focus on long-term habituation, user annoyance, and attitudes toward privacy. Extensive research has already been done on users' general level of privacy concerns and habituation for first-use authorization systems. Our field study shows that our approach is comparable to first-use in terms of the number of times users are prompted, and the number of explicit authorizations from users is far below the 8 additional explicit authorizations used in prior work, which are considered unlikely to introduce significant risk of habituation or annoyance.

### Related Work

Researchers have extensively demonstrated that IPC mechanisms can allow dangerous interactions between programs, such as unauthorized use of intents, where adversaries can hijack activities and services by stealing intents. Prior work has also shown that such interactions can be exploited to cause permission re-delegations, leveraging capabilities available to trusted programs. Additionally, trusted programs may inadvertently or purposely expose their interfaces to other programs, creating attack vectors for adversaries. In this paper, we demonstrate that dangerous interactions among programs can lead to critical attack vectors related to input event delegations.

Efforts to regulate such interactions have included automated tools for IPC-related vulnerability analysis, such as ComDroid and EPICC. Secure Application INTeraction (Saint) extends the existing Android security architecture with policies that give programs more control over who can access their interfaces. Quire provides context in the form of provenance to programs communicating via Inter-Procedure Calls (IPC). Although these approaches have been effective, none of them address the problem from the perspective of giving control to users, who are the real targets for privacy violations by malicious programs.

In line with our perspective, User-Driven Access Control proposes the use of access control gadgets predefined by the operating system and embedded into applications' code to limit what operations can be associated with specific input events. AWare binds each operation request targeting sensitive sensors to an input event and obtains explicit authorization from the user for each event-operation combination. ContexIoT is a context-based permission system for IoT platforms that leverages runtime prompts with rich context information. However, these mechanisms only control how the input event is consumed by the receiving program and do not mediate inter-process communication and the resulting operations, which is necessary to prevent the attack vectors discussed in this paper.

Prior work has also investigated the use of machine learning classifiers to analyze the contextuality behind user decisions to automatically grant access to sensors. However, these classifiers only model the context relative to the single program the user is currently interacting with and do not account for inter-process communications. The effectiveness of the learning depends on the accuracy of the user decisions used in training the learner. Therefore, additional effort is necessary to support user decision-making before user decisions can be used to train a classifier.

Lastly, mechanisms based on taint analysis or Decentralized Information Flow Control (DIFC) have been proposed to track and control how sensitive data is used or shared between programs. However, these mechanisms solve the orthogonal problem of controlling sensitive data leakage or accidental disclosure, rather than enabling users to control how, when, and which programs can access sensors for the collection of sensitive data.

### Conclusion

While a collaborative model allows the creation of useful, rich, and creative applications, it also introduces new attack vectors that can be exploited by adversaries. We have shown that three well-studied attack vectors become critical in operating systems supporting a cooperating program abstraction and proposed the EnTrust authorization system to help mitigate them. EnTrust demonstrates that it is possible to prevent programs from abusing the collaborative model—by binding together input events, handoff events, and sensor operation requests made by programs, and requiring explicit user authorization for the constructed delegation path. Our results show that existing systems have room for improvement, and permission-based systems, as well as machine learning classifiers, may significantly benefit from applying our methodology.

### Acknowledgements

We thank our shepherd, Sascha Fahl, and the anonymous reviewers. The effort described in this article was partially sponsored by the U.S. Army Research Laboratory Cyber Security Collaborative Research Alliance under Contract Number W911NF-13-2-0045. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes, notwithstanding any copyright notation hereon. The research work of Jens Grossklags was supported by the German Institute for Trust and Safety on the Internet (DIVSI).

### References

[1] Conger, K. Researchers: Uber’s iOS app had secret permissions that allowed it to copy your phone screen. Gizmodo, (2017).
[2] Lieberman, E. Hackers are gunning for your personal data by tracking you. The Daily Caller, (2016).
[3] Sulleyman, A. Android apps secretly steal users’ data by colluding with each other, finds research. Independent, (2017).
[4] Revel, T. Android apps share data between them without your permission. NewScientist, (2017).
[5] Norm, H., The Confused Deputy: (or why capabilities might have been invented). SIGOPS Oper. Syst. Rev., (1988).
[6] Petracca, G., Sun, Y., Jaeger, T., and Atamli, A. AuDroid: Preventing attacks on audio channels in mobile devices. In ACSAC, (2015), ACM.
[7] Felt, A. P., Wang, H., Moshchuk, A., Hanna, S., and Chin, E. Permission re-delegation: Attacks and defenses. In NDSS, (2011).