ment took 19 hours and 45 minutes to complete, and
EnTrust passed 132,681 tests without crashing the op-
erating system and without incorrectly blocking any
legitimate operation. Among the 1,000 tested apps,
we also included 5 popular augmented reality multi-
player gaming app (InGress, Pokémon Go, Parallel
Kingdom, Run An Empire, and Father.io), which typi-
cally have a high rate of input events and are very sensi-
tive to delays. The set of tests targeting these 5 gaming
apps ran for 16 minutes, during which we continuously
observed the device screen to identify possible issues in
terms of responsiveness to input events or glitches in
the rendering of virtual objects on the screen. However,
we did not identify any discernible slowdown, glitch, or
responsiveness issue.
7 Performance Measurements
We performed four micro-benchmarks on a standard
Android developer smartphone, the LG Nexus 5X, pow-
ered by 1.8GHz hexa-core 64-bit Qualcomm Snapdragon
808 Processor and Adreno 418 GPU, 2GB of RAM, and
16GB of internal storage. All of our benchmarks are
measured using Android 7.1 Nougat pulled from the An-
droid Open Source Project (AOSP) repository.
Delegation Graph Construction – Our first
micro-benchmark of EnTrust measured the overhead
incurred for constructing delegation graphs of varying
sizes. To do this, we had several programs interacting
578    28th USENIX Security Symposium
USENIX Association
Figure 7: Overheads for Delegation Graphs Construction, Storage, Eviction, and Enforcement.
and generating a handoff-events chain varying from 1 to
10 handoffs in length and measured the time to mediate
the input event, the handoff event, and the operation re-
quest. We repeated the measurements 100 times. Each
set of measurements was preceded by a priming run to
remove any first-run effects. We then took an average
of the middle 8 out of 10 such runs for each number
of handoff events. The results in Figure 7 show that
the input mediation requires an overhead of 10 µs, the
handoff event mediation requires an additional overhead
of 4 µs per event handoff, whereas the operation medi-
ation requires a fixed overhead of 5 µs. The overheads
are within our expectations and do not cause noticeable
performance degradation.
Delegation Graph Caching – Our second micro-
benchmark of EnTrust measures the overhead incurred
for caching delegation graphs constructed at runtime.
We measured the overhead introduced by EnTrust in
the authorization process for both storing a new dele-
gation graph, as well as evicting from cache a stale one.
To do this, we simulated the creation and eviction of
delegation graphs of different sizes varying from 1 to 16
Kilobytes in 512-byte increments.10 We repeated the
measurement 5 times for each random size and took an
average of the middle 3 out of 5 such runs. The results
in Figure 7 show that the storing of delegation graphs
in the cache required a base overhead of 66 µs with an
additional 3 µs per 512-byte increment. The eviction
instead required a base overhead of 57 µs with an addi-
tional 2.5 µs for each 512-byte increment.
Delegation Graph Enforcement – Our third
micro-benchmark was designed to compare the unmod-
ified version of the Android Nougat build for control
measurement with a modified build integrating our
EnTrust features for the delegation graph enforcement
during authorization. To guarantee fairness in the com-
parison between the two systems, we used the An-
droid UI/Application Exerciser Monkey11 to generate
the same sequence of events for the same set of pro-
grams. For both systems, we measured the total time
needed to authorize a sensor operation as the time from
the input event to the authorization of the resulting op-
eration request, corresponding to the last node of the
delegation graph for EnTrust. We repeated the mea-
surement 100 times for each system by varying the num-
ber of handoff events from 1 to 10. Each set of measure-
ments was preceded by a priming run to remove any
first-run effects. We then took an average of the mid-
dle 8 out of 10 such runs for each number of handoff
events. Figure 7 shows that the overhead introduced by
EnTrust for the delegation graph enforcement is negli-
gible, with the highest overhead observed being below
0.02%. Thus, the slowdown is likely not to be noticeable
by users. Indeed, none of our study participants raised
any concerns about discernible performance degrada-
tion or system slowdown.
Ambiguity Prevention – Our
fourth micro-
benchmark was designed to measure the performance
in terms of delayed events, due to the
implications,
ambiguity prevention mechanism.
For this micro-
benchmark, we selected the system UI (User Interface)
process, which is one of the processes receiving the high-
est number of input events, and the media server process
that receives the highest number of handoff events and
performs sensor operations with higher frequency than
any other process. The time window for the construc-
tion of each delegation path was set to 150 ms. We
generated 15,000 input events with gaps randomly se-
lected in the range [140-1,500]12 ms. The time window
and the gaps were selected based on data reported in
Appendix B. The generated input events caused 2,037
handoff events and 5,252 operation requests targeting
sensors (22,289 total scheduled events). The results in-
dicated a total of 256 delayed events (1.15% of the total
events), with a maximum recorded delay of 9 ms. Thus,
the performance overhead introduced is negligible.
Memory Requirement – We also recorded the av-
erage cache size required by EnTrust to store both event
mappings and authorized delegation graphs to be about
5.5 megabytes, for up to 1,000 programs.13 Therefore,
EnTrust required about 5.5 kilobytes of memory per
program, which is a small amount of memory when com-
pared to several gigabytes of storage available in modern
systems. We ran the measurement 10 times and then
took an average of the middle 8 out of 10 of such runs.
8 Discussion of Limitations
Evaluating mechanisms that prevent abuse of sensitive
sensors while trading off privacy and usability is chal-
USENIX Association
28th USENIX Security Symposium    579
lenging.
our study and provide guidance on future work.
In this section, we discuss the limitations of
Authorization Comprehension – In designing our
authorization messages, we have used the language
adopted in current permission systems (e.g., Android
OS and Apple iOS) and prior research work [47, 11,
15, 16] as references. However, such language may not
be as effective in eliciting access control decisions from
users as desired. Further improvements may be possi-
ble by studying NLP techniques and how access control
questions may be phrased using such techniques. Also,
a combination of text, sound, and visuals may be use-
ful in conveying access questions to users. EnTrust is
largely orthogonal to any specific way how access con-
trol questions are presented, enabling it to be used as a
platform for further study.
Decision Revocation – Users may make mistakes
when allowing or denying authorizations.
EnTrust
caches user decisions to reduce users’ authorization ef-
fort, allowing such mistakes to persist. Mistakes in au-
thorizing access to sensor operations may permit ma-
licious applications to abuse access, albeit limited to
that delegation path only. Mistakes in denying access
to sensor operations prevents legitimate use of sensor
operations silently as a result of caching. One possible
solution to these problems is to invalidate the cache peri-
odically to prevent stale authorization decisions. How-
ever, frequent authorization prompts negatively affect
user experience. Currently, EnTrust enables users to
review authorization decisions via an audit mechanism,
as suggested elsewhere [53, 15]. However, to improve
the effectiveness of such mechanisms, further laboratory
studies will be necessary to examine how to present au-
dit results (or other new approaches) to help users to
investigate and resolve mistaken authorizations.
Study Scenarios – In this project, we focused on
whether users would be able to deny attack scenarios
effectively. Another problem is that users may not eval-
uate non-attack scenarios correctly once they become
aware of possible attacks. In our study, we did not ob-
serve that users denied any legitimate sensor operations
during the lab study, but it would be beneficial to ex-
tend the laboratory study to include more subtle non-
attack scenarios, where we push the boundaries of what
is perceived as benign, to evaluate whether these sce-
narios may cause false denials due to users being unable
to identify that the request was indeed benign. Also, we
recognize that all attacks were generated by programs
unfamiliar to participants, even though they were given
the opportunity to familiarize themselves with such pro-
grams during the preliminary phase of our lab study.
Study Size – The number of subjects recruited for
this project, 60 for the laboratory study and 9 for the
field study, is comparable with the number of subjects
in similar studies [33, 14, 15, 11]. Other related work
[47] had a higher number of subjects, but subjects were
not required to be physically present in the laboratory
during the experimental tasks having been recruited via
online tools (e.g., Mechanical Turk). However, research
has shown, in the context of password study, that a lab-
oratory study may produce more realistic results than
an online study [58].
Study Comprehensiveness – Our study does not
focus explicitly on long-term habituation, user annoy-
ance, and users’ attitudes toward privacy. Researchers
have already extensively studied users’ general level of
privacy concerns [51, 52, 53, 15]. Other researchers
have studied users’ habituation for first-use authoriza-
tion systems extensively [33, 45, 50]. Our field study
(Section 6.3) shows that our approach is comparable
to first-use in terms of the number of times users are
prompted, and the number of explicit authorizations
from users is far below the 8 additional explicit autho-
rizations used in prior work, which are considered likely
not to introduce significant risk of habituation or an-
noyance [33].
9 Related Work
Researchers have extensively demonstrated that IPC
mechanisms allow dangerous interactions between pro-
grams, such as unauthorized use of intents, where ad-
versaries can hijack activities and services by stealing
intents [18, 21, 22, 26]. Prior work has also shown
that such interactions can be exploited by adversaries
to cause permission re-delegations [7] in the attempt to
leverage capabilities available to trusted programs (e.g.,
system services). Also, related work has demonstrated
how trusted programs inadvertently or purposely (for
functionality reasons) expose their interfaces to other
programs [8], thus exposing attack vectors to adver-
saries. In this paper, we have demonstrated that dan-
gerous interactions among programs can lead to critical
attack vectors related to input event delegations.
Researchers have tried to regulate such interactions
with automated tools for IPC-related vulnerability anal-
ysis. For instance, ComDroid is a tool that parses the
disassembled applications’ code to analyze intent cre-
ation and transition for the identification of unautho-
rized intent reception and intent spoofing [26]. Efficient
and Precise ICC discovery (EPICC) is a more compre-
hensive static analysis technique for Inter-Component
Communication (ICC)14 calls [19]. It can identify ICC
vulnerabilities due to intents that may be intercepted
by malicious programs, or scenarios where programs ex-
pose components that can be launched via malicious in-
tents. Secure Application INTeraction (Saint) [54] ex-
tends the existing Android security architecture with
policies that would allow programs to have more con-
trol to whom permissions for accessing their interfaces
are granted and used at runtime. Quire provides context
in the form of provenance to programs communicating
via Inter-Procedure Calls (IPC) [55]. It annotates IPCs
occurring within a system, so that the recipient of an
580    28th USENIX Security Symposium
USENIX Association
IPC request can observe the full call sequence associ-
ated with it, before committing to any security-relevant
decision. Although effort has been made to analyze
and prevent IPC-related vulnerabilities, none of the pro-
posed approaches above tackled the problem from our
perspective, i.e., instead of giving control to application
developers, we must give control to users who are the
real target for privacy violations by malicious programs.
In line with our perspective of giving control to users,
User-Driven Access Control [9, 10] proposes the use of
access control gadgets, predefined by the operating sys-
tems and embedded into applications’ code, to limit
what operation can be associated with a specific input
event. Also, AWare [11] proposes to bind each operation
request targeting sensitive sensors to an input event and
to obtain explicit authorization from the user for each
event-operation combination. Similarly, ContexIoT [16]
is a context-based permission system for IoT platforms
which leverages runtime prompts with rich context in-
formation including the program execution flow that al-
lows users to identify how a sensitive operation is trig-
gered. Unfortunately, all of these mechanisms only con-
trol how the input event is consumed by the program
receiving the input event. The proposed mechanisms to
enable mediation do not mediate inter-process commu-
nication and the operations resulting from such com-
munication (e.g., event delegations between programs),
which is necessary to prevent the attack vectors dis-
cussed in this paper. Also, differently from prior work
on permission re-delegation [7], we do not rely on an
over-restrictive defense mechanism that totally forbids
programs from using their additional privileges. Such
an over-restrictive defense would block necessary inter-
actions between programs even when the interactions
are benign and expected by users.
Prior work has also investigated the use of machine
learning classifiers to analyze the contextuality behind
user decisions to automatically grant access to sensors
[14, 15]. Unfortunately, such classifiers only model the
context relative to the single program that the user is
currently interacting with, and the API calls that are
made by such a program during the interaction. How-
ever, the context modeled by these classifiers does not
account for inter-process communications, which allow
programs to enlist other programs to perform sensor op-
erations via input event delegation. Furthermore, the
effectiveness of the learning depends on the accuracy of
the user decisions used in training the learner. In other
words, if the user’s decisions suffer from inadequate in-
formation during the training phase, the learner will as
well. Therefore, we firmly believe that an additional ef-
fort is necessary to support user decision making before
the user decisions can be used to train a classifier.
Lastly, mechanisms based on taint analysis [29, 30, 31]
or Decentralized Information Flow Control (DIFC) [13,
20] have been proposed by researchers to, respectively,
track and control how sensitive data is used by or shared
between programs. However, such mechanisms solve the
orthogonal problem of controlling sensitive data leakage
or accidental disclosure, rather than enabling users to
control how, when, and which programs can access sen-
sors for the collection of sensitive data.
10 Conclusion
While a collaborative model allows the creation of use-
ful, rich, and creative applications, it also introduces
new attack vectors that can be exploited by adversaries.
We have shown that three well-studied attack vectors
become critical, in operating systems supporting a coop-
erating program abstraction, and proposed the EnTrust
authorization system to help mitigate them. EnTrust
demonstrates that it is possible to prevent programs
from abusing the collaborative model – in the attempt
to perform delegated confused deputy, delegated Tro-
jan horse, or delegated man-in-the-middle attacks – by
binding together, input event, handoff events, and sen-
sor operation requests made by programs, and by requir-
ing an explicit user authorization for the constructed
delegation path. Our results show that existing sys-
tems have room for improvement and permission-based
systems, as well as machine learning classifiers, may sig-
nificantly benefit from applying our methodology.
Acknowledgements
Thanks to our shepherd, Sascha Fahl, and the anony-
mous reviewers. The effort described in this article was
partially sponsored by the U.S. Army Research Labo-
ratory Cyber Security Collaborative Research Alliance
under Contract Number W911NF-13-2-0045. The views
and conclusions contained in this document are those of
the authors, and should not be interpreted as represent-
ing the official policies, either expressed or implied, of
the Army Research Laboratory or the U.S. Government.
The U.S. Government is authorized to reproduce and
distribute reprints for Government purposes, notwith-
standing any copyright notation hereon. The research
work of Jens Grossklags was supported by the German
Institute for Trust and Safety on the Internet (DIVSI).
References
[1] Conger, K. Researchers: Uber’s iOS app had secret
permissions that allowed it to copy your phone screen.
Gizmodo, (2017).
[2] Lieberman, E. Hackers are gunning for your personal
data by tracking you. The Daily Caller, (2016).
[3] Sulleyman, A. Android apps secretly steal users’ data
by colluding with each other, finds research. Indepen-
dent, (2017).
[4] Revel, T. Android apps share data between them with-
out your permission. NewScientist, (2017).
[5] Norm, H., The Confused Deputy: (or why capabilities
might have been invented). SIGOPS Oper. Syst. Rev.,
(1988).
USENIX Association
28th USENIX Security Symposium    581
[6] Petracca, G., Sun, Y., Jaeger, T., and Atamli,
A. AuDroid: Preventing attacks on audio channels in
mobile devices. In ACSAC, (2015), ACM.
[7] Felt, A. P., Wang, H., Moshchuk, A., Hanna, S.,
and Chin, E. Permission re-delegation: Attacks and