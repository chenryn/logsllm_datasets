three tasks, we can observe that the average EER decreases as more
training data is used. While the EER barely changes beyond 10%
training data for the browsing and reading tasks, diminishing return
only set in after about 40% for the slideshow task. This shows that
it is beneficial for the classifier to observe different illumination
patterns despite the pupil diameter correction. As discussed in
Section 4.5, our system uses sequential training data in order to
closely reflect how it would be run in the real world. The fact that
102030405060708090100110120130140150Number of aggregated samples0.050.100.150.20EEREER depending on number of samplesRaw dataWith pupil correction102030405060708090100110120130140150Number of aggregated samples0.050.100.150.20EEREER depending on number of samplesRaw dataWith pupil correction0.10.20.30.40.50.6Fraction of data used for training0.050.100.150.20EEREER depending on amount of training dataReadingBrowsingSlideshowSession 6A: Biometrics SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1196(a) Raw data
(b) With pupil diameter correction
Figure 8: Effect of training data selection, random vs sequential.
Figure 9: Distribution of EER between users for the cali-
brated reading task (T3). The horizontal line shows the aver-
age EER.
are low. For cross-task authentication between the slideshow task
and the others, the system benefits greatly from the pupil diameter
correction as the slideshow images are, on average, much darker
than text on white background. Applying the mapping function to
the reading task greatly reduces error rates for both target tasks
(by 39% and 59%, respectively). Interestingly, the EER increases
when applying the function to the slideshow task as a source. In
practice, it would be sensible to use the mapping function only
for relatively predictable source-target combinations (e.g., reading
to browsing). This test can be performed on population statistics
without input from a particular user. Since the system can be trained
on an arbitrary task, choosing a training task that allows easy
predictions of other tasks’ features is particularly valuable.
Influence of calibration. Table 4 showed that similar or even
lower error rates are possible when using a generic (i.e., highly
inaccurate) calibration. However, this decrease is partially driven
by binocular features which grow in distinctiveness if users show
highly diverse calibration errors. In order to measure the effect
of calibration error in the calibrated experiment (where users will
generally have similar, high-quality calibrations), we compute the
correlation between the EER and calibration errors. The results of
this computation are shown in Table 5. The table shows the corre-
lation of the EER with the pre-experiment accuracy (i.e., measured
directly after calibration), post-experiment accuracy (i.e., after the
pre
p-value
0.16
0.16
0.34
post
p-value
0.55
0.44
0.55
r
-0.14
-0.17
-0.13
change
r
Task
0.31
Reading
Browsing
0.31
Slideshow 0.21
Table 5: Correlation between calibration error and EER for
the calibrated sessions. Values are computed using the cali-
bration accuracy measured at the beginning of the session
(T1) and the calibration accuracy measured at the end of the
session (T6).
p-value
0.08
0.06
0.16
r
-0.38
-0.41
-0.31
final task) and their absolute difference. While we observed a mod-
erate positive correlation between pre-experiment calibration error
and EER, this was not statistically significant (p > 0.05) for any task.
This result supports our hypothesis that the system’s effectiveness
is not significantly affected by the quality of eye tracker calibration.
6 DISCUSSION AND SECURITY ANALYSIS
In this section, we will discuss four possible attacks on this system
and possible countermeasures.
Manual imitation. Imitation attacks involve the imposter modi-
fying their own eye movement behaviour to appear more similar
to the victim. This first requires the attacker to obtain information
about the victim’s eye movement patterns. This can be achieved
through observation if the victim is using an attacker-controlled or
otherwise compromised device with a (covert) eye tracker. How-
ever, the involuntary nature of eye movements make them hard
to consciously control. Microsaccades have been shown to be ex-
tremely hard to consciously suppress and controlling them to such
a degree to deliberately alter biometric features seems virtually
impossible. The pupil diameter is probably the most likely target,
as some conscious actions (such as memory cognitive load) cause
0.000.010.020.030.040.050.060.07Equal Error RateReadingSlideshowWikiRandomOrdered0.000.010.020.030.040.05Equal Error RateReadingSlideshowWikiRandomOrderedUsers0.00.10.2EERDistribution of EER between usersSession 6A: Biometrics SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1197(a) Raw data
(b) Pupil diameter correction
(c) Pupil diameter correction and mapping function
Figure 10: EERs for cross-task authentication.
(a) False Accept Rate
(b) False Reject Rate
Figure 11: The Gini Coefficient (the fraction of the area under the line of equality that is shaded) shows the skewness of error
rate distributions.
dilations and contractions of the pupil. Nevertheless, this is still dif-
ficult to achieve, especially if the attacker is focusing on the attack
at the same time. Assuming the legitimate user’s calibration config-
uration is unknown to the attacker, it will be difficult to reproduce
the binocular tracking-based features in the uncalibrated setting.
While it might be possible to infer some calibration information
based on the user’s height, seat position and posture, we believe
this is unlikely to be sufficient.
Light stimulation. Attacks which use light stimulation have been
presented in [18]. The idea is to change the ambient light (in this
case, through a dimmable desk lamp) to cause changes in the at-
tacker’s pupil diameter. While this has been shown to be effective
in [18], the system the authors attacked did not use ambient light
correction. In order to defeat this attack, it would be possible to use
an ambient light sensor, rather than the light source’s dim settings,
as input to the pupil diameter correction. Any attacker-induced
changes in ambient light would then lead to an increased correction
of the pupil diameter and therefore be unable to affect the corrected
measurement that is used for authentication. Therefore, a much
more targeted light source (such as a laser pointer) would be needed.
While this would avoid the ambient light detection, it might still
be possible to detect by analysing the illumination differences be-
tween the eyes and the rest of the face. This could be performed
automatically by the eye tracker’s camera.
Artificial eyes. An eye tracker precision and accuracy can be mea-
sured without the noisy influence of human eyes [22] using artificial
eyes. If two such eyes were attached to a high-precision motor, it
would arguably be feasible to reproduce even short-lived move-
ments (such as microsaccades). Dynamically changing the pupil
diameter of such an eye could be achieved with a controllable shut-
ter around the pupil. Similar to the other attacks, this still requires
the attacker to obtain a (close to) perfect copy of the legitimate
user’s eye movement behaviour. In addition, liveness detection
methods can be used to distinguish an artificial eye from a real one.
7 CONCLUSION
In this paper, we have proposed a continuous authentication system
based on eye movement biometrics. This work addressed three prac-
tical concerns overlooked by previous work: the need for a precise
calibration, the effect of light sensitivity and the task dependence
of biometric features. We proposed new eye tracking features based
on binocular tracking, showing that their distinctiveness remains
0.00.20.40.60.81.0Fraction of Attackers0.00.20.40.60.81.0Cumulative ErrorFAR distribution for slideshow task (GC=0.92)Line of EqualityLorenz Curve0.00.20.40.60.81.0Fraction of Users0.00.20.40.60.81.0Cumulative ErrorFRR distribution for slideshow task (GC=0.66)Line of EqualityLorenz CurveSession 6A: Biometrics SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1198even in presence of generic (i.e., not user-specific) calibrations. We
showed a pupil diameter correction mechanism based on linear re-
gression can account for the differences in pupil diameter caused by
varying screen brightness and ambient light. Lastly, we addressed
task dependence through a cross-task mapping function trained on
population data.
Our results show significantly lower error rates than previous
work while allowing the system to be used in less controlled envi-
ronments. We achieve an intra-task EER of 3.93% while requiring
only two minutes of uncalibrated training data even with random
and frequent changes of lighting conditions. We show that our
proposed cross-task mapping can reduce the EER of cross-task au-
thentication by up to 59% when enrolling on a reading task and
authenticating on an arbitrary task.
ACKNOWLEDGEMENTS
This work was supported by a grant from Mastercard.
REFERENCES
[1] Kevin Allix, Tegawendé F Bissyandé, Jacques Klein, and Yves Le Traon. 2015. Are
your training datasets yet relevant?. In International Symposium on Engineering
Secure Software and Systems. Springer, 51–67.
[2] Andreas Bulling, Florian Alt, and Albrecht Schmidt. 2012. Increasing the security
of gaze-based cued-recall graphical passwords using saliency masks. In Proceed-
ings of the SIGCHI Conference on Human Factors in Computing Systems. ACM,
3011–3020.
[3] Virginio Cantoni, Chiara Galdi, Michele Nappi, Marco Porta, and Daniel Ric-
cio. 2015. GANT: Gaze analysis technique for human identification. Pattern
Recognition 48, 4 (2015), 1023–1034. https://doi.org/10.1016/j.patcog.2014.02.017
[4] Lewis Carroll. 1930. Alice in Wonderland.
[5] Guglielmo Cola, Marco Avvenuti, Fabio Musso, and Alessio Vecchio. 2016. Gait-
based authentication using a wrist-worn device. In Proceedings of the 13th Inter-
national Conference on Mobile and Ubiquitous Systems: Computing, Networking
and Services. ACM, 208–217.
[6] Véronique Daneault, Gilles Vandewalle, Marc Hébert, Petteri Teikari, Ludovic S
Mure, Julien Doyon, Claude Gronfier, Howard M Cooper, Marie Dumont, and Julie
Carrier. 2012. Does pupil constriction under blue and green monochromatic light
exposure change with age? Journal of biological rhythms 27, 3 (2012), 257–264.
[7] George Doddington, Walter Liggett, Alvin Martin, Mark Przybocki, and Dou-
glas A. Reynolds. 1998. Sheep, goats, lambs and wolves: A statistical analysis of
speaker performance in the NIST 1998 speaker recognition evaluation. National
Institut of Standards and Technology Gaithersburg (1998), 1–4.
[8] Andrew T. Duchowski. 2017. Eye tracking methodology: Theory and practice:
Third edition. Springer International Publishing, Cham. 1–366 pages. https:
//doi.org/10.1007/978-3-319-57883-5 arXiv:arXiv:1011.1669v3
[9] Simon Eberz, Giulio Lovisotto, Andrea Patane, Marta Kwiatkowska, Vincent
Lenders, and Ivan Martinovic. 2018. When your fitness tracker betrays you:
Quantifying the predictability of biometric features across contexts. In 2018 IEEE
Symposium on Security and Privacy (SP). IEEE, 889–905.
[10] Simon Eberz, Nicola Paoletti, Marc Roeschlin, Andrea Patani, Marta Kwiatkowska,
and Ivan Martinovic. 2017. Broken Hearted: How To Attack ECG Biometrics.
In Proceedings 2017 Network and Distributed System Security Symposium. https:
//doi.org/10.14722/ndss.2017.23408
[11] Simon Eberz, Kasper B. Rasmussen, Vincent Lenders, and Ivan Martinovic. 2015.
Preventing Lunchtime Attacks: Fighting Insider Threats With Eye Movement Bio-
metrics. In Proceedings 2015 Network and Distributed System Security Symposium.
https://doi.org/10.14722/ndss.2015.23203
[12] Simon Eberz, Kasper B. Rasmussen, Vincent Lenders, and Ivan Martinovic. 2016.
Looks Like Eve: Exposing Insider Threats Using Eye Movement Biometrics. ACM
Transactions on Privacy and Security 19, 1 (2016). https://doi.org/10.1145/2904018
[13] Simon Eberz, Kasper B. Rasmussen, Vincent Lenders, and Ivan Martinovic. 2017.
Evaluating Behavioral Biometrics for Continuous Authentication. In Proceedings
of the 2017 ACM Asia Conference on Computer and Communications Security -
ASIA CCS ’17. ACM Press, New York, New York, USA, 386–399. https://doi.org/
10.1145/3052973.3053032
[14] S. Zahra Fatemian, Foteini Agrafioti, and Dimitrios Hatzinakos. 2010. HeartID:
Cardiac biometric recognition. In IEEE 4th International Conference on Biometrics:
Theory, Applications and Systems, BTAS 2010. https://doi.org/10.1109/BTAS.2010.
5634493
[15] Tao Feng, Xi Zhao, and Weidong Shi. 2013. Investigating mobile device picking-up
motion as a novel biometric modality. In 2013 IEEE Sixth International Conference
on Biometrics: Theory, Applications and Systems (BTAS). IEEE, 1–6.
[16] Mario Frank, Ralf Biedert, Eugene Ma, Ivan Martinovic, and Dawn Song. 2013.
Touchalytics: On the Applicability of Touchscreen Input as a Behavioral Biometric
for Continuous Authentication. IEEE Transactions on Information Forensics and
Security 8, 1 (Jan. 2013), 136–148. https://doi.org/10.1109/TIFS.2012.2225048
[17] Chiara Galdi, Michele Nappi, Daniel Riccio, Virginio Cantoni, and Marco Porta.
2013. A new gaze analysis based soft-biometric. In Mexican Conference on Pattern
Recognition. Springer, 136–144.
[18] Isaac Griswold-Steiner, Zakery Fyke, Mushfique Ahmed, and Abdul Serwadda.
2018. Morph-a-Dope: Using Pupil Manipulation to Spoof Eye Movement Biomet-
rics.
[19] Daniele Gunetti and Claudia Picardi. 2005. Keystroke analysis of free text. ACM
Transactions on Information and System Security 8, 3 (2005), 312–347. https:
//doi.org/10.1145/1085126.1085129
[20] Corey Holland and Oleg V Komogortsev. 2011. Biometric identification via eye
movement scanpaths in reading. In Biometrics (IJCB), 2011 International Joint
Conference on. IEEE, 1–8.
[21] Corey D Holland and Oleg V Komogortsev. 2013. Complex eye movement
pattern biometrics: Analyzing fixations and saccades. In Biometrics (ICB), 2013
International Conference on. IEEE, 1–8.
[22] Kenneth Holmqvist, Marcus Nyström, and Fiona Mulvey. 2012. Eye tracker data
quality: what it is and how to measure it. In Proceedings of the symposium on eye
tracking research and applications. ACM, 45–52.
[23] Donald R. Jasinski, Jeffrey S. Pevnick, and John D. Griffith. 1978. Human Pharma-
cology and Abuse Potential of the Analgesic Buprenorphine: A Potential Agent
for Treating Narcotic Addiction. Archives of General Psychiatry 35, 4 (1978),
501–516. https://doi.org/10.1001/archpsyc.1978.01770280111012
[24] Andrew H Johnston and Gary M Weiss. 2015. Smartwatch-based biometric gait
recognition. In Biometrics Theory, Applications and Systems (BTAS), 2015 IEEE 7th
International Conference on. IEEE, 1–6.
[25] Daniel Kahneman and Jackson Beatty. 1966. Pupil diameter and load on memory.
Science 154, 3756 (1966), 1583—-1585.
[26] Manu Kumar, Tal Garfinkel, Dan Boneh, and Terry Winograd. 2007. Reducing
shoulder-surfing by using gaze-based password entry. In Proceedings of the 3rd
symposium on Usable privacy and security - SOUPS ’07. 13. https://doi.org/10.
1145/1280680.1280683
[27] Dachuan Liu, Bo Dong, Xing Gao, and Haining Wang. 2015. Exploiting eye
tracking for smartphone authentication. In International Conference on Applied
Cryptography and Network Security. Springer, 457–477.
[28] Colleen MacLachlan and Howard C. Howland. 2002. Normal values and standard
deviations for pupil diameter and interpupillary distance in subjects aged 1
month to 19 years. Ophthalmic and Physiological Optics 22, 3 (May 2002), 175–182.
https://doi.org/10.1046/j.1475-1313.2002.00023.x
[29] Susana Martinez-Conde, Stephen L. Macknik, Xoana G. Troncoso, and Thomas A.
Dyar. 2006. Microsaccades counteract visual fading during fixation. Neuron 49, 2
(2006), 297–305. https://doi.org/10.1016/j.neuron.2005.11.033
[30] Mihai Pop, Yves Payette, and Emma Santoriello. 2002. Comparison of the pupil
card and pupillometer in measuring pupil size. Journal of Cataract & Refractive
Surgery 28, 2 (2002), 283–288.
[31] Ioannis Rigas, George Economou, and Spiros Fotopoulos. 2012. Biometric identi-
fication based on the eye movements and graph matching techniques. Pattern
Recognition Letters 33, 6 (2012), 786–792.
[32] Ioannis Rigas and Oleg V Komogortsev. 2014. Biometric recognition via proba-
bilistic spatial projection of eye movement trajectories in dynamic visual envi-
ronments. IEEE Transactions on Information Forensics and Security 9, 10 (2014),
1743–1754.
[33] Brian C. Ross. 2014. Mutual information between discrete and continuous data
sets. PLoS ONE 9, 2 (Feb. 2014), e87357. https://doi.org/10.1371/journal.pone.
0087357
[34] Hildur EH Schilling, Keith Rayner, and James I Chumbley. 1998. Comparing
naming, lexical decision, and eye fixation times: Word frequency effects and
individual differences. Memory & Cognition 26, 6 (1998), 1270–1281.
[35] Ivo Sluganovic, Marc Roeschlin, Kasper B. Rasmussen, and Ivan Martinovic. 2016.
Using Reflexive Eye Movements for Fast Challenge-Response Authentication. In
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications
Security - CCS’16. ACM Press, New York, New York, USA, 1056–1067. https:
//doi.org/10.1145/2976749.2978311
[36] Sasitorn Taptagaporn and Susumu Saito. 1990. How display polarity and lighting
conditions affect the pupil size of VDT operators. Ergonomics 33, 2 (Feb. 1990),
201–208. https://doi.org/10.1080/00140139008927110
[37] B Winn, D Whitaker, D B Elliott, and N J Phillips. 1994. Factors affecting light-
Investigative ophthalmology &
adapted pupil size in normal human subjects.
visual science 35, 3 (1994), 1132–1137.
[38] Nan Zheng, Aaron Paloski, and Haining Wang. 2011. An efficient user verification
system via mouse movements. In Proceedings of the 18th ACM conference on
Computer and communications security - CCS ’11. 139. https://doi.org/10.1145/
2046707.2046725
Session 6A: Biometrics SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1199