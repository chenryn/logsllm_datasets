title:Network anomaly detection based on TCM-KNN algorithm
author:Yang Li and
Binxing Fang and
Li Guo and
You Chen
Network Anomaly Detection Based on TCM-KNN Algorithm 
Yang Li 
Institute of Computing Technology 
Chinese Academy of Sciences 
No.6 South of Kexueyuan Road 
Beijing, P.R. China 
PI:EMAIL 
Binxing Fang 
Li Guo, You Chen 
Institute of Computing Technology 
Chinese Academy of Sciences 
No.6 South of Kexueyuan Road 
Institute of Computing Technology 
Chinese Academy of Sciences 
No.6 South of Kexueyuan Road 
Beijing, P.R. China 
PI:EMAIL 
Beijing, P.R. China 
PI:EMAIL 
ABSTRACT 
Intrusion detection is a critical component of secure information 
systems.  Network  anomaly  detection  has  been  an  active  and 
difficult  research  topic  in  the  field  of  Intrusion  Detection  for 
many  years.  However,  it  still  has  some  problems  unresolved. 
They  include  high  false  alarm  rate,  difficulties  in  obtaining 
exactly  clean  data  for  the  modeling  of  normal  patterns  and  the 
deterioration of detection rate because of some “noisy” data in the 
training set. In this paper, we propose a novel network anomaly 
detection  method  based  on  improved  TCM-KNN  (Transductive 
Confidence Machines for K-Nearest Neighbors) machine learning 
algorithm.  A  series  of  experimental  results  on  the  well-known 
KDD  Cup  1999  dataset  demonstrate  it  can  effectively  detect 
anomalies with high true positive rate, low false positive rate and 
high  confidence  than  the  state-of-the-art  anomaly  detection 
methods.  In  addition,  even  interfered  by  “noisy”  data  (unclean 
data), the proposed method is robust and  effective. Moreover,  it 
still  retains  good  detection  performance  after  employing  feature 
selection aiming at avoiding the “curse of dimensionality”. 
Categories and Subject Descriptors 
C.2.0  [Computer-Communication  Network]:  Security  and 
Protection 
General Terms 
Security, Algorithms 
Keywords 
Network  security,  anomaly  detection,  TCM-KNN  algorithm, 
machine learning 
1.  INTRODUCTION 
Intrusion  Detection  System  (IDS)  plays  vital  role  of  detecting 
various kinds of attacks. The main purpose of IDS is to find out 
intrusions among normal audit data and this can be considered as 
classification problem.  
The  two  basic  methods  of  detection  are  signature  based  and 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not  made  or  distributed  for  profit  or  commercial  advantage  and  that 
copies  bear this notice  and the full  citation  on the  first page.  To  copy 
otherwise,  or  republish,  to  post  on  servers  or  to  redistribute  to  lists, 
requires prior specific permission and/or a fee. 
ASIACCS’07, March 20–22, 2007, Singapore. 
Copyright 2007 ACM 1-59593-574-6/07/0003…$5.00. 
anomaly  based  [1].  The  signature-based  method,  also  known  as 
misuse  detection,  looks  for  a  specific  signature  to  match, 
signaling an intrusion. They can detect many or all known attack 
patterns,  but  they  are  of  little  use  for  as  yet  unknown  attack 
methods.  Most  popular  intrusion  detection  systems  fall  into  this 
category. 
Another method to intrusion detection is called anomaly detection. 
Anomaly  detection  applied  to  intrusion  detection  and  computer 
security has been an active area of research since it was originally 
proposed by Denning [2]. Anomaly detection algorithms have the 
advantage  that  they  can  detect  new  types  of  intrusions  as 
deviations  from  normal  usage.  In  this  problem,  given  a  set  of 
normal data to train from, and given a new piece of test data, the 
goal of the intrusion detection algorithm is to determine whether 
the  test  data  belong  to  “normal”  or  to  an  anomalous  behavior. 
However, anomaly detection schemes suffer from  a high  rate  of 
false  alarms.  This  occurs  primarily  because  previously  unseen 
(yet 
legitimate)  system  behaviors  are  also  recognized  as 
anomalies, and hence flagged as potential intrusions. 
In  this  paper,  we  propose  a  novel  network  anomaly  detection 
method based on TCM-KNN (Transductive Confidence Machines 
for K-Nearest Neighbors) algorithm, which has been successfully 
applied  to  pattern  recognition,  fraud  detection  and  outlier 
detection.  To  our  best  knowledge,  it  is  the  first  time  that  the 
machine  learning  algorithm  is  employed  in  intrusion  detection 
and improved to fulfill the task of anomaly detection. A series of 
experiments  on 
the  well-known  KDD  Cup  1999  dataset 
demonstrate  our  method  has  higher  detection  rate  (true  positive 
rate) and lower false positive rate (false alarm) than the state-of-
the-art  anomaly  detection  methods;  In  addition,  it  holds  good 
performance  even  interfered  by  the  “noisy”  data  in  training  set. 
Moreover,  it  still  remains  good  detection  performance  after 
feature selection aiming at avoiding the “curse of dimensionality”. 
The rest of this paper is organized as follows. We overview the 
related  work  in  Section  2  and  introduce  TCM  (Transductive 
Confidence  Machines),  TCM-KNN  (Transductive  Confidence 
Machines  for  K-Nearest  Neighbors)  algorithm  in  Section  3. 
Section 4 details our improved TCM-KNN algorithm for anomaly 
detection.  Section  5 
relevant  experiments  and 
evaluations. We conclude our work in Section 6. 
illustrates 
2.  RELATED WORK 
In  the  past  several  years,  a  lot  of  anomaly  detection  methods 
attempt to build some kind of a model over the normal data and 
then  check  to  see  how  well  new  data  fits  into  that  model.  In 
13
iid  assumption  (the 
machine learning, transduction can offer measures of reliability to 
individual points, and uses very broad assumptions except for the 
well-known 
training  as  well  as  new 
(unlabelled) points are independently and identically distributed). 
These  properties  make  transduction  an  ideal  and  successful 
mechanism for the application filed of pattern recognition, fraud 
detection, outlier detection and so on. 
Martin-Lof proved that there exists a universal method of finding 
regularities  in  data  sequences.  Unfortunately,  universal  tests  are 
not computable, and have to be approximated using non-universal 
tests called p-values [11]. In the literature of significance testing, 
the  p-value  is defined  as  the  probability  of  observing  a  point  in 
the  sample  space  that  can  be  considered  more  extreme  than  a 
sample of data. This p-value serves as a measure of how well the 
data  supports  or  not  a  null  hypothesis  (the  point  belongs  to  a 
certain  class).  The  smaller  the  p-value,  the  greater  the  evidence 
against the null hypothesis (i.e., the point does not belong to the 
observed class). Users of transduction as a test of confidence have 
approximated  a  universal  test  for  randomness  (which  is  in  its 
general form, non-computable) by using a p-value function called 
strangeness measure [11]. The general idea is that the strangeness 
measure  corresponds  to  the  uncertainty  of  the  point  being 
measured with respect to all the other labeled points of a class: the 
higher  the  strangeness  measure,  the  higher  the  uncertainty.  We 
will show in the next section  how to adopt  the definition of the 
strangeness  function  of  TCMs  to  our  intrusion  detection  task  of 
finding estimates for points to be anomalies. 
a 
i
n
i
yx
1
,1
n yx
,
n
)}
),...,
(
training 
1
x
xx
,{
,...,
i
2
i
of  n  elements,  where 
intrusion  detection 
X =
3.2  TCM-KNN 
Now, we give the formal description of TCM-KNN problem for 
the  application  field  of  network  intrusion  detection.  In  the  next 
section, we will further give the improved TCM-KNN algorithm 
for  our  anomaly  detection  based  on  this  section.  To  our 
knowledge, it’s the first time that TCM-KNN algorithm is applied 
to intrusion detection. 
set 
Imagine  we  have 
is 
}
{(
the set of feature values (such as the connection duration time, the 
SYN error numbers, etc.) extracted from the raw network packet 
iy  is  the 
(or  network  flow  such  as  TCP  flow)  for  point  i  and 
classification  for  point  i ,  taking  values  from  a  finite  set  of 
possible classifications (such as normal, DoS attack, Probe attack, 
c . We also have a test set of 
etc.), which we identify as 
}
s  points  similar  to  the  ones  in  the  training  set,  our  goal  is  to 
assign to every test point one of the possible classifications. For 
every  classification  we  also  want  to  give  some  confidence 
measures. 
In the process of adopting K-Nearest Neighbors (KNN) algorithm, 
we  denote  the  sorted  sequence  (in  ascending  order)  of  the 
distances (in this paper, we use the Euclidean distance to calculate 
the  distance  between  pairs  of  points)  of  point  i  from  the  other 
iD .  Also, 
ijD  will 
points  with  the  same  classification  y  as 
iD −  for 
stand  for  the  jth  shortest  distance  in  this  sequence  and 
the  sorted  sequence  of  distances  containing  points  with 
iD −  represents the  series 
classification different from y (that  is, 
,...,3,2,1{
y
y
y
y
general,  they  can  be  classified  into  two  classes:  supervised  and 
unsupervised anomaly detection methods. 
Supervised  anomaly  detection  methods  build  models  of  normal 
data  and  detect  deviations  from  the  normal  model  in  observed 
data. Most research in supervised anomaly detection can loosely 
be 
termed  as  performing  generative  modeling.  Supervised 
anomaly detection algorithms require a set of purely normal data 
from which they train their model. One method uses a prediction 
model  obtained  by  training  decision  trees  over  normal  data  [3], 
while others use neural networks to obtain the model [4] or non-
stationary  models  [5]  to  detect  novel  attacks.  Barbara  uses 
pseudo-Bayes  estimators  to  enhance  detection  of  novel  attacks 
while  reducing  the  false  alarm  rate  as  much  as  possible  [6]. 
Authors in [7] estimate parameters of a probabilistic model over 
the  normal  data  and  compute  how  well  new  data  fits  into  the 
model. 
However, supervised anomaly detection methods require a set of 
purely  normal  data  from  which  they  train  their  models.  Under 
most  circumstances,  the  data  contains  some  intrusions  buried 
within  the  training  data,  the  algorithm  may  not  detect  future 
instances  of  these  attacks  because  it  will  identify  that  they  are 
normal.  Therefore,  there  appear  the  unsupervised  anomaly 
detection methods to solve this problem. These  methods take  as 
input a set of unlabeled data and attempt to find intrusions buried 
within the data. In the unsupervised anomaly detection problem, 
we  are  given  a  set  of  data  where  it  is  unknown  which  are  the 
normal elements and which are the anomalous elements. The goal 
is  to  recover  the  anomalous  elements.  It  detects  attacks  by 
determining unusual activities from data under two assumptions: i) 
the  majority  of  activities  are  normal;  ii)  attacks  statistically 
deviate 
from  normal  activities.  The  most  advantage  of 
unsupervised anomaly detection over supervised detection is that 
it  does  not  require  purely  normal  data  from  train.  Unsupervised 
anomaly  detection  is  a  variant  of  the  classical  outlier  detection 
problem.  In  practice,  the  cluster-based  estimation  algorithm,  K-
Nearest Neighbors algorithm and one-class SVM are proposed by 
authors in [8] for the unsupervised anomaly detection and it was 
demonstrated that they are superior to those traditional supervised 
anomaly  detection  methods,  especially  the  performance  of  one-
class SVM algorithm both in detection true positive rate (TP) and 
false positive rate (FP). However, their TP and FP are not as good 
as we expected (98% for TP and 10% for FP [8]). 
3.  BACKGROUND OF TCM-KNN 
In this section, we will introduce the principles about TCM, then 
give  the  classical  TCM-KNN  algorithm  and  firstly  apply  it  to 
intrusion detection. 
3.1  TCM 
Transduction  has  been  previously  used  to  offer  confidence 
measures for the decision of labeling a point as belonging to a set 
of  pre-defined  classes  [9].  Transductive  Confidence  Machines 
(TCM)  introduced  the  computation  of  the  confidence  using 
algorithmic randomness theory. The confidence measure used in 
TCM  is  based  upon  universal  tests  for  randomness,  or  their 
approximation. The transductive reliability estimation process has 
its  solid  theoretical  foundations  in  the  algorithmic  theory  of 
randomness developed by Kolmogorov and a detail description of 
the  theory  can  be  found  in  [10].  Unlike  traditional  methods  in 
14
certain class, we only attempt to pinpoint the point in question is 
normal or abnormal. 
(ii) In most cases of intrusion detection, it’s very difficult for us to 
get purely “clean data” or “attack data” for training. We are only 
sure if the data we handle are normal or abnormal since with the 
development  of  network  and  hacker  techniques,  it  is  unrealistic 
that we may acquire exactly detail characteristics and patterns of 
all the attacks such as DoS, Probe, U2R, etc. 
 Let  k   as the number of nearest neighbors to be used;  m  as the number of training points;   
c   as the classes;  r   as the points to be classified 
for  i   = 1 to m do 
iD ,
y
iD−   and store 
calculate
y
end for 
calculate  α  for all training points and store 
for  i   = 1 to  r   do 
Calculate the dist vector as the distances of the new point from all training points 
for  j   = 1 to  c   do 
for every training point t classified as  j   do 
if 
j
tkD   > dist(t) recalculate the alpha value of point  t  
end for 
for every training point  t   classified as non- j   do 
if 
j
tkD−   > dist(t) recalculate the alpha value of point  t  
end for 
Calculate alpha value for the new point classified as  j  
Calculate p-value for the new point classified as  j  
end for 
predict the class with the largest p-value 
output as confidence one minus the 2nd largest p-value 
output as credibility the largest p-value 
end for 
Figure 1. TCM-KNN algorithm 
 (iii) Even worse,  the  so  called  “clean  data”  we  use  for  training 
may always be partially contaminated by attack data in practice. 
Therefore, our method should be robust under such circumstances. 
Hence,  these  above  reasons  consequence  in  the  requirement  of 
modification for the calculation of α as presented in equation (1). 
If  still  using  that  definition,  the α computed  for  an  anomaly  (a 
point that does not belong to any of the classes) will be the ratio 
between  two  large  numbers  (the  distances  from  the  point  in 
question to those in any of the classes are large). In some cases, 
this ratio will be small enough to be comparable to the α values 
for  points  already  in  the  class,  leading  to  false  negatives. 
Therefore,  we  propose  to  use  a  modified  definition  of  α  as 
follows: 
α
iy
= k
∑
j
1
=
D
y
ij
   (3) 
This new definition will make the strangeness value of a point far 
away  from  the  class  considerably  larger  than  the  strangeness  of 
points already inside the class. 
of distances between point  i  and all the points not in class  y ). 
We  assign  to  every  point  a  measure  called  the  individual 
strangeness measure. This measure defines the strangeness of the 