### 4.3.2 Cpy-Lock & Writeback

To extend consistency until \( t_r \), one can copy \( M' \) back to \( M \) once the computation of \( F(M') \) is finished. During this process, \( M \) is locked from \( t_e \) until \( t_r \). This ensures that \( R \) remains consistent with \( M \) within the intervals \([t_s, t_c]\) and \([t_e, t_r]\). Consequently, \( M_{t_s} = M_{t_e} \), and \( M \) remains constant between \( t_e \) and \( t_r \).

Similar to Cpy-Lock, it might be less constraining to use Dec-Lock during the copy and Inc-Lock during the writeback, rather than All-Lock.

### 4.4 Variations on the Theme

We outline some extensions to the previously discussed mechanisms.

#### 4.4.1 Non-Sequential Functions

Some functions are not sequential; for example, they might require input blocks to be used concurrently or might reuse blocks in computation. Simple mechanisms like No-Lock or All-Lock are not affected by this. However, dynamic locking techniques need to be adapted.

For non-sequential functions, a lock on \( M_i \) needs to be acquired the first time that block is needed by \( F \). Similarly, a lock on \( M_i \) can only be released when \( M_i \) is no longer required. Consequently, in non-sequential functions, locks may be acquired sooner or released later than in sequential functions. Figure 6 illustrates the effect on Dec-Lock and Inc-Lock. A larger gray area indicates more restrictive operation for real-time systems (for the same guarantees of consistency), though still less restrictive than All-Lock.

Dec-Lock requires the execution environment to be aware of blocks that are no longer needed for the remainder of the computation of \( F \). If this information is not available, locks cannot be released until \( t_e \), in which case Dec-Lock degenerates to All-Lock. Inc-Lock does not have this issue, as blocks are locked the first time they are needed for \( F \) and not freed until \( t_e \).

#### 4.4.2 Adaptive Locking

Multiple mechanisms can be combined to achieve alternative timings of consistency in computing \( F \). For example, to achieve consistency at \( t_k \) (\( t_s \leq t_k \leq t_e \)), we can combine the use of: (1) Inc-Lock on \([M_0, \ldots, M_k]\), and (2) Dec-Lock on \([M_k, \ldots, M_n]\). However, it is somewhat unclear if and when such hybrids may be useful in practice. One potentially relevant application is adaptive locking, which aims to minimize the impact on other processes, especially if the execution environment is aware of other processes' interrupt schedules.

#### 4.4.3 Lazy Copy (Cpy-Lazy)

Another variation of copy-based mechanisms in Section 4.3 is Cpy-Lazy. It involves using All-Lock on \( M \) with a lazy (or reactive) copy mechanism. When another process interrupts \( F \) and, during its execution, wishes to write \( M_i \), this block is first copied to \( M'_i \). The lock on \( M_i \) is then released so the process can write to it. The rationale for Cpy-Lazy is that copying only what is necessary reduces overhead, particularly relevant when few blocks are likely to be modified during the computation of \( F \). However, if many blocks are to be modified and copied, cumulative overhead might exceed that of a single bulk copy. Another consideration is whether there is OS or hardware (e.g., MPU) support for the "interrupt-on-write" primitive required to implement Cpy-Lazy.

### 4.5 Uninterruptibility vs. Locking

All mechanisms described above achieve consistency by temporarily locking (parts of) memory. As mentioned earlier, uninterruptibility of the computation of \( F \) (e.g., as in SMART [11]) also provides consistency, though rigidly, i.e., for the interval \([t_s, t_e]\). There are other differences:

- Even when \( M \) is locked entirely or partially, other processes can interrupt the execution of \( F \) and modify memory outside of \( M \), as well as read all memory, including \( M \). This does not violate the consistency of \( F \)'s result \( R \).
- If \( F \) is uninterruptible and the underlying hardware platform is a single-CPU device, other processes are completely blocked, regardless of whether \( M \) is locked.
- If multiple CPUs have shared memory access, uninterruptibility does not guarantee consistency, since a process running on a CPU different from the one running \( F \) can modify \( M \) concurrently.
- Locking is more flexible than uninterruptibility: while locking and unlocking of \( M \) can be dynamic and gradual (i.e., block-wise), the execution of \( F \) is rigid: either it is interruptible or not. For example, SMART provides consistency only because, in a single-CPU device, uninterruptibility is equivalent to All-Lock.

### 4.6 Memory Access Violations

If some process \( P' \) tries to write to \( M_i \) which is currently locked by process \( P \) running \( F \), a memory access violation occurs (recall that read access to \( M \) requires no extra handling). \( P \) and \( P' \) might be running concurrently, on different CPUs, or \( P' \) might have interrupted \( P \). There are several alternatives:

- If \( P \) handles the situation, one possibility is to abort \( F \) and terminate \( P \). This approach is the most friendly with respect to \( P' \) and other processes. However, it makes it easy for a malicious process to starve \( P \), i.e., prevent \( F \) from ever completing. Otherwise, we can adopt the reactive Cpy-Lazy approach discussed in Section 4.4.3.
- Alternatively, \( P' \) can be aborted. Though this would allow \( P \) (and thus \( F \)) to complete uninterrupted, it might be impractical in safety-critical scenarios.
- Another possibility is to stall \( P' \) until \( M_i \) is unlocked. This approach is gentler, although it might still be problematic, depending on how long \( P' \) has to wait.

### 4.7 Inconsistency Detection

Another approach to enforce consistency is to detect inconsistency. The memory \( M \) is not locked but instead a trigger is set up such that the integrity measuring (e.g., attestation) process is alerted if any changes occur to \( M \) during the computation of \( F \). If any such changes occur, the result produced is no longer consistent throughout the computation. Depending on the strategy for dealing with inconsistency, the computation of \( F \) can be stopped, continued, or restarted. An implementation of this is presented and discussed in Section 5.5.

The clear benefit of inconsistency detection over consistency enforcement is that it does not interfere with the execution of other processes. This is particularly relevant in time-critical applications when availability must be maintained at all times. The drawback is that consistency might not be guaranteed, depending on the strategy used whenever an inconsistency is detected. This may lead to attestation never terminating if inconsistencies are constantly created, even by benign software.

### 5 Implementation & Evaluation

Our prototype of temporal consistency mechanisms is realized in the context of the HYDRA hybrid RA architecture [10]. Below, we overview HYDRA, discuss implementation details of each mechanism, and assess their performance on two popular low- to medium-end development boards: I.MX6-SabreLite [9] and ODROID-XU4 [7]. Security considerations for our implemented mechanisms are discussed in Appendix B.

#### 5.1 HYDRA

HYDRA implements a hybrid RA design for devices with a Memory Management Unit (MMU). It builds upon the formally verified seL4 [18] microkernel, which ensures process memory isolation and enforces access control to memory regions. Using the (mathematically) proven isolation features of seL4, access control rules can be implemented in software and enforced by the microkernel. Note that, in addition to the design of seL4 being formally verified and ensured to guarantee isolation, the seL4 software implementation is also formally verified for conformance to the design.

HYDRA stores an attestation key (K) and attestation code (that computes a MAC using K) in a writable memory region (e.g., flash or RAM) and configures the system such that no other process, besides the attestation process (PAtt), can access this memory region. Access control configuration in HYDRA also involves PAtt having exclusive access to its thread control block as well as to memory regions used for K-related computations. The latter ensures that K is properly protected. To ensure uninterruptibility, HYDRA runs the attestation process as the so-called initial user-space process with the highest scheduling priority. As the initial user-space process in seL4, PAtt is also initialized with capabilities to all memory pages. Meanwhile, the rest of the user-space processes are assigned lower priorities and spawned by PAtt. Finally, a hardware-enforced secure boot feature is used to ensure the integrity of seL4 itself and of PAtt when the system is initialized.

#### 5.2 Experimental Setup

Our implementation ensures temporal consistency by locking memory regions. It thus does not require the execution of PAtt to be uninterruptible, unlike the original HYDRA implementation [10]. As a result, all user-space processes, including PAtt, have the same priority in our implementation.

The microkernel executable is compiled from the unmodified seL4 source code v4.0.0 [27]. Our user-space code is based on open-source seL4 libraries [26], mostly for providing abstractions for processes, memory management, and virtual address space.

#### 5.3 Experimental Results: Primitives

Our implementation of mechanisms discussed in Section 4 consists of four primitives: LockPage, UnlockPage, CopyMem, and MacMem. In HYDRA (and in seL4, in general), locking and unlocking a memory page can be invoked from user-space (by authorized processes) and handled inside the kernel.

To lock a specific page, PAtt needs to perform three steps: (1) revoke all capabilities associated with the page, (2) create a read-only capability to the page, (3) assign the new capability to a targeted process and map the page into the process’ virtual address space. Unlocking can be done similarly by using a read-and-write capability, instead of a read-only capability. In terms of seL4 implementation, each of these primitives translates into three function calls: seL4_CNode_Revoke(), seL4_CNode_Copy(), and seL4_ARCH_Page_Map().

Another parameter related to LockPage and UnlockPage is memory page size, which can differ depending on the underlying instruction-set architecture. For instance, I.MX6-SabreLite, which is based on the ARMv7-A architecture, only supports the following page sizes: 4KB, 64KB, 1MB, and 16MB. CopyMem performs a memory copy between source and destination RAM locations. We note that only Cpy-Lock requires this primitive. Finally, MacMem performs a MAC computation over a memory range. MacMem is implemented as a keyed hash using: BLAKE2S [31], AES256-CBC based MAC [17], and HMAC-SHA256 [37] algorithms.

Figure 7 illustrates the run-time of primitive operations on 16MB of memory. Results show that page size heavily influences the performance of LockPage and UnlockPage: the larger the page size, the faster it is to lock or unlock memory of the same size. This is expected because larger pages result in fewer entries that need to be modified in a page table. Run-time performance of CopyMem and MacMem, however, remains almost unchanged, regardless of page size. In addition, the same figure suggests that run-times of CopyMem, LockPage, and UnlockPage are relatively fast, compared to that of MacMem. The first three primitives take at most 9% of MacMem’s run-time.

Finally, we evaluate and compare the performance of the various primitives on I.MX6-SabreLite running at 1.0GHz and ODROID-XU4 running at 2.1GHz. Figure 8 shows the results of this comparison. It shows that: (1) run-times of LockPage and UnlockPage primitives are still roughly the same on both hardware platforms, and (2) MacMem remains, by far, the most time-consuming primitive.

#### 5.4 Experimental Results: Mechanisms

We assess the performance of five temporal consistency mechanisms – No-Lock, All-Lock, Dec-Lock, Inc-Lock, and Cpy-Lock – on the SabreLite board. No-Lock is the baseline and it directly translates into the MacMem primitive. All-Lock, Dec-Lock, and Inc-Lock all require additional steps of sequentially locking and unlocking memory blocks. For its part, Cpy-Lock involves all four primitives.

Figure 9 demonstrates the run-time performance of the aforementioned mechanisms (using BLAKE2S as the underlying function) with various memory sizes: 16MB to 96MB, and page sizes 4KB and 64KB. Results can be summarized as follows:

- The run-time of all mechanisms is linear in terms of memory size. This is expected since they are built upon a sequential function, i.e., a MAC.
- The run-time of MAC computation on large memory sizes is indeed non-negligible, e.g., it takes around 4 seconds for keyed BLAKE2S over 96MB of memory. This clearly demonstrates the need for ensuring temporal consistency, especially in settings where PAtt needs to be interruptible.
- The run-times of All-Lock, Dec-Lock, and Inc-Lock are all roughly equal, in all cases. This is also expected, as each of these three mechanisms involves a similar number of invocations of primitives.
- The difference in run-time between the baseline and All-Lock, Dec-Lock, and Inc-Lock decreases as page size grows. This difference then becomes negligible (< 0.1%) when page size reaches 1MB. Thus, it is beneficial to use these mechanisms with reasonably large page sizes. One disadvantage of larger page sizes is that memory pages, on average, will be locked for longer periods.
- Cpy-Lock comes out as the preferred mechanism. It incurs small (∼ 8%) run-time overhead; however, this mechanism provides much better availability as memory is locked for a very short amount of time (only during the copying process). However, recall that an obvious disadvantage is that it requires additional memory of size \( M' \).

#### 5.5 Implementation of Inconsistency Detection

We could implement the inconsistency detection mechanism by having PAtt detect whether any dirty/accessed bits are set after each measurement is completed. However, this obvious approach falls short in the context of HYDRA. Doing so would imply some modifications to the existing kernel, which may consequently break formally verified properties of seL4.

Instead, we base our implementation of inconsistency detection on the All-Lock implementation. The idea is to have PAtt first lock memory to be attested before starting to compute the integrity-ensuring function, e.g., the MAC. If the computation completes without interruptions or detecting any inconsistency, PAtt then unlocks the memory; this scenario resembles typical All-Lock execution. However, if another process (denoted by \( P' \)) attempts to modify any part of the locked memory, the kernel will suspend the execution of \( P' \) and PAtt will be made aware of such inconsistency; PAtt then resolves the inconsistency by unlocking the memory and resuming the execution of \( P' \). Note that this implementation still requires some interference with other processes as \( P' \) is suspended when inconsistency occurs. However, we show later in Section 5.6 that the overhead from this interference is very small compared to the actual measurement runtime.

To implement this mechanism in HYDRA, we decompose PAtt into the following three threads:

- **Thchecksum**: Computes the integrity-ensuring function and returns an attestation result to Thmain on success.
- **Thfault**: Listens for any memory write fault and notifies Thmain when there is an attempt to modify memory being attested.
- **Thmain**: Manages the other two threads, locks and unlocks memory, and reports to Vrf when an inconsistency occurs.