An alternative approach, described in NIST’s Guide for Con-
ducting Risk Assessments: Information Security is to include the
likelihood of attack initiation in an overall information security risk
assessment of an organization or system. This requires “taking into
consideration capability, intent, and targeting” [39]. We know of
no way to meaningfully assign a likelihood to an attacker initiating
an attack in the general case. Our analysis is, therefore, concerned
only with the likely outcome of an attack, and not the likelihood
of the attack itself. We use a likelihood scale with ﬁve discrete lev-
els denoted, from most to least likely: frequent (expected to occur
routinely), probable (expected to occur often), remote (expected to
occur infrequently), extremely remote (expected to occur rarely), and
extremely improbable (not expected to occur, but not impossible).
Severity is also classiﬁed into ﬁve discrete levels, denoted, from
most to least severe: catastrophic (multiple fatalities), hazardous
(multiple serious injuries or fatal injuries to a small number of per-
sons, or a hull loss without fatalities), major (physical distress or
injuries, substantial damage to aircraft), minor (physical discomfort,
slight damage to aircraft), minimal (negligible safety effect).
In the following, we consider several scenarios attacking the in-
formation presented by an MCIS. For each, our goal is to assign
a likelihood and severity score. The ideal means of determining
likelihood and severity is empirical through high-ﬁdelity controlled
experiments measuring pilot response to data tampering scenarios.
Unfortunately, such experiments are beyond the capabilities of most
computer security researchers. The alternative is a qualitative as-
sessment based on our own judgement. This is the approach we
take here. Our assessment of likelihood is subject to disagreement,
which an aviation safety expert may judge to be greater or lesser
than what we determine.
The scenarios are structured around two critical events we term
detection and selection. In each scenario, an attacker manipulates
some subset of variables presented by the MCIS to the pilot. De-
tection occurs if a pilot notices a discrepancy between the MCIS-
reported datum and the same datum obtained from another source.
Having noticed the discrepancy, a pilot is faced with a choice of
which source to trust. At this point, the pilot must reject either the
MCIS-supplied information controlled by the attacker or the refut-
ing source providing accurate information. We call this decision
point the selection of one or the other data source.
5.1 Detection and Selection Factors
Detection and selection are inﬂuenced by a number of factors.
These factors form the basis of our likelihood assessments. Through-
out, we refer to the (correct) information that contradicts MCIS-
supplied information as refuting information and its source as the
refuting source.
Exposure. The ﬁrst, and probably most important, factor affecting
detection is operator exposure to refuting information. We classify
exposure as continuous or request-driven. Continuous information
is presented to the operator at all times; it includes altitude (via
altimeter), attitude (via attitude indicator), and heading (via heading
indicator and compass). Request-driven information requires an
explicit, discrete acquisition action. This includes information such
as the local altimeter setting, which is obtained from air trafﬁc
control (ATC) or an automated station (ATIS/ASOS/AWOS). A
discrepancy in continuously available information is signiﬁcantly
more likely to be detected than a discrepancy in information that
requires operator action to obtain.
Cognitive complexity. Refuting information may be direct or indi-
rect. Direct information is information that, once available, requires
no additional cognitive processing to detect a discrepancy. An alti-
tude obtained from an MCIS and from the altimeter can be readily
compared. The same is true for attitude, heading, altimeter setting,
general weather information, presence of other aircraft, approach
procedures, terrain and obstacle information.
Conventional sources of aircraft position may be direct or indirect.
In familiar terrain and good visibility, a pilot can directly observe
her position. When radar service is available, ATC is another direct
source of position information, as long as the pilot is in communica-
tion with the controller. The instrument landing system (ILS) also
provides direct position information in the form of course deviation,
however, it is only available on ﬁnal approach. Terrestrial navigation
aids, such as VOR and DME, when used to navigate along airways,
provide direct position information in the form of a course deviation.
However, when not conﬁgured to follow a pre-determined course,
these instruments do not directly indicate aircraft position.
Weather data comes in many forms. Simple variables, such as
cloud ceiling and visibility, can be directly compared between those
reported by an MCIS and those obtained from a weather observa-
tion recording. On the other hand, spatial weather information, as
obtained from a graphical weather overlay, cannot be directly com-
638pared to information received during a pre-ﬂight brieﬁng or from
direct visual observation.
The presence of another aircraft reported by an MCIS can be
conﬁrmed visually, however the absence of an aircraft cannot be
directly established with certainty.
Workload. Operator workload has been found to adversely affect
fault detection and mitigation in many domains [13, 14, 62]. At-
tacks during high-workload stages of ﬂight (take-off and landing)
signiﬁcantly increase risk.
Trust and preference. A operator’s trust of automation, and the
MCIS in particular, plays an important role in both detection and
selection phases. In the detection phase, trust will determine how
often a pilot will check MCIS-reported information against conven-
tional sources. In the selection phase, a pilot must decide whether
to accept information from the MCIS or from the refuting sources,
a determination that will rely heavily on trust.
Trust in automated systems, both information and control, is an
active area of study in the Human Factors community. Experiments
have shown that trust increases with reliability [10, 12, 30, 64].
Thus, the more reliable a system is in normal operation, the greater
the potential for damage when the system is compromised.
Trust in automated systems has also been found to be inversely
proportional to operator self-conﬁdence. The less conﬁdent an
operator is in her own skills (especially when refuting information
is indirect), the more likely she is to trust the automated system [10,
32, 45].
Automation bias is the term given to increased reliance on auto-
mated systems, which can lead to reduced crew vigilance [4, 33,
36, 44]. Automation bias, however, is not universal; in some stud-
ies, operators were found to place greater trust in conventional
systems [37].
Finally, even when one system is not considered more reliable
than another, a pilot may continue to rely on a faulty instrument
despite evidence that it is unreliable. (This was the case in at least
two major aviation accidents—Korean Air Cargo ﬂight 8509 on
December 22, 1999, and Copa Airlines ﬂight 201 on June 6, 1992.)
Experience. More experienced operators generally fare better in
many decision-making tasks, and we expect our setting to be no
different. Experience also attenuates the effect of factors such as
workload and operator conﬁdence.
Environment. Environmental factors, notably, weather, will affect
a pilot’s ability to rely on visual references, eliminating a major
source of refuting information.
5.2 Scenarios
With these factors in mind, we consider seven scenarios in which
an attacker tampers with some combination of variables presented
by an MCIS (Table 1). For each scenario, we assign a likelihood.
We rely on our own judgement, necessarily imperfect, to make
this determination. Aviation safety experts may disagree on the
likelihood of each outcome.
5.2.1 Altitude and attitude
In this scenario, an attacker manipulates reported altitude and
attitude (pitch and roll) information displayed by the MCIS. Both are
critical ﬂight parameters. Incorrect perception of altitude, attitude, or
speed is termed spatial disorientation; unless remedied immediately,
spatial disorientation rapidly leads to catastrophic outcomes.
Severity. The severity of this outcome is catastrophic.
Likelihood. Both altitude and attitude can be directly determined
from primary ﬂight instruments, which provide a continuous indica-
tion of both. Therefore, we consider a failure to detect a hazardous
condition and select the correct instrument to be remote to extremely
remote.
5.2.2 Position (cruise)
In this scenario, an attacker tampers with the reported position of
the aircraft in the cruise stage of ﬂight. This scenario encompasses
a family of scenarios varying in how long it takes the pilot to detect
deviation from expected position.
Severity. In poor visibility, a pilot may not realize at all that she has
deviated from the intended course, resulting in controlled ﬂight into
terrain or mid-air collision, both catastrophic outcomes. Scenarios
in which a pilot becomes aware of her incorrect position past the
point at which an airﬁeld landing can be made range in severity
from minor to catastrophic, while recognizing deviation from the
intended course early, allowing for a normal landing, has minimal
to minor severity.
Likelihood. The likelihood of detection and selection of correct
information source depends on a number of factors. The most
signiﬁcant is whether the pilot is navigating primarily by visual
reference to terrain (VFR – Visual Flight Rules) or by relying on
navigation instruments (IFR – Instrument Flight Rules).
A pilot monitoring conventional navigation instruments and com-
municating with air trafﬁc control is both more likely to detect a
problem and correctly choose conventional instruments. We con-
sider the likelihood of the late recognition scenario to be remote to
extremely remote in IFR ﬂight. Unfortunately, only 28% of private
pilots in the United States are licensed to operate under IFR.2 More-
over, less experienced pilots are more likely to trust automation, so
that, even when a pilot detects a problem, she may continue to rely
on the MCIS-provided GPS data.
For VFR ﬂights in poor visibility and hazardous terrain, we judge
the likelihood of the pilot relying on incorrect position with catas-
trophic outcome to be remote to probable.
5.2.3 Position (approach)
In this scenario, an attacker tampers with the reported position
of the aircraft on approach. While similar to position tampering
in cruise considered above, approach to landing presents its own
unique challenges. Among them: increased workload and narrow
error margins because of proximity to terrain and other aircraft.
On the other hand, on ﬁnal approach, a pilot may rely on visual
references (runway and visual approach slope indicator lights) or
the Instrument Landing System (ILS) than on the MCIS.
Severity. Position error on approach can result in controlled ﬂight
into terrain or a mid-air collision, both catastrophic outcomes.
Likelihood.
In a scenario with poor visibility, no ILS, and haz-
ardous terrain, we judge the likelihood of catastrophic outcome to
be remote to probable.
5.2.4 Die Hard 2
In the classic action ﬁlm Die Hard 2, the villain causes an aircraft
to crash on ﬁnal approach when he issues the order to “recalibrate sea
level . . . minus two hundred feet.” In an MCIS version of this attack,
an attacker tampers with the altimeter setting shown to the pilot in a
METAR, a textual weather report that includes this variable. The
altimeter setting is used to calibrate a barometric aircraft altimeter.
2Based on 2012 data reported by the FAA: http://www.faa.
gov/data_research/aviation_data_statistics/civil_
airmen_statistics/2012/
639Severity. An incorrect altimeter setting will result in an incorrect
altitude displayed on the conventional altimeter, which can lead to a
catastrophic outcome.
Likelihood. The primary source of the altimeter setting is a pre-
recorded terminal information (ATIS) message or an automated
weather (ASOS/AWOS) report and airport tower air trafﬁc con-
trollers will often repeat the altimeter setting when clearing an
aircraft to land. Thus, we believe the likelihood of this scenario to
be extremely remote.
5.2.5 Weather
Weather information, both textual and graphical, affects a pi-
lot’s navigation-related decisions. A pilot not equipped to ﬂy in
poor weather can be led into such conditions by erroneous weather
information. According to the FAA, “twenty ﬁve percent of all
weather-related accidents are fatal and a failure to recognize dete-
riorating weather continues to be a frequent case or contributing
factor of accidents” [21]. In poor weather conditions, a pilot is
likely to turn to the MCIS to determine whether to continue ﬂight
and how to navigate around bad weather. The graphical weather
display (e.g., Figure 2, right) presents highly salient weather infor-
mation which is not available from any other conventional source
in the cockpit.3 In this scenario, the attacker is also aided by the
psychology of pilots ﬂying in poor weather. General aviation pilots
have a well-established pattern of ﬂying into deteriorating weather
conditions [4, 5, 40, 63], an effect that is positively correlated with
ﬂight duration (more likely at end of long ﬂight) and negatively
correlated with experience.
Severity. Clearly, incorrect weather information can lead to catas-
trophic outcomes.
Likelihood. Pilots are likely to rely on weather information pre-
sented by an MCIS. However, the likelihood of this reliance leading
to a catastrophic outcome is difﬁcult to estimate, because it depends
on the weather conditions and pilot experience.
5.2.6 Position of other aircraft
There are three types of attack on aircraft position information
obtained from ADS-B/TIS-B. In the ﬁrst attack type, an attacker
can suppress information about other aircraft. However, pilots do
not rely on ADS-B/TIS-B for aircraft identiﬁcation, both as a mat-
ter of training, and because this feature is explicitly advertised as
incomplete.
The second type of attack involves adding false targets to the
display. Because of the possibility of a collision, a pilot is likely to
accept MCIS information. While we judge the likelihood of this
happening to be frequent, the severity is minimal to minor. We
consider the scenario in which a false target causes a deviation
resulting in an accident to be extremely remote. Moreover, trust of
an automated system deteriorates rapidly when it shows itself to be
unreliable. After a few false targets, we expect pilots to place little
weight on MCIS-reported aircraft.
The third type of attack involves changing the reported position of
an existing target. An adversarially-chosen change in target position
could result in a pilot deviating toward the target to avoid collision.
Severity. The outcome severity of a mid-air collision is catas-
trophic.
Likelihood. The likelihood of a mid-air collision caused by sup-
pression of ADS-B/TIS-B data is, therefore, extremely remote to
3Satellite radio subscription services that provide graphical weather
information are available, many using mobile apps for display, how-
ever, we assume a pilot will only rely on the MCIS weather display.
extremely improbable. However, under the right circumstances—
reduced visibility and proximity to another aircraft—the likelihood
of a catastrophic outcome in the last scenario is probable. While an
attacker may not have the ability to arrange such circumstances, he
can wait for them to occur naturally.
5.2.7 Terrain and procedures
In this scenario, an attacker modiﬁes critical information on an
aeronautical chart or approach plate. Obstacle elevations, navigation
aid frequencies, procedure altitudes can all result in a catastrophic
outcome. The Die Hard 2 attack can also be carried out by modify-
ing the altitudes on an instrument approach plate. Such an attack is
particularly dangerous because directly refuting information is only
available from another chart or plate. Pilots are unlikely to check
for this discrepancy. The remaining source of refuting information
is visual observation and air trafﬁc control, the second of which is
not always available.
Severity. The outcome of this scenario—controlled ﬂight into
terrain—is catastrophic.
Likelihood. In poor visibility, we judge the likelihood of an catas-
trophic outcome to be probable to remote, largely dependent on a
pilot’s familiarity with the terrain.
5.3 Summary
The manipulation of weather, own-ship position, position of other
aircraft, and EFB information introduces signiﬁcant risk. The like-
lihood of most attacks having an undesirable outcome increases
greatly in poor weather, which limits a pilot’s access to visual refut-
ing information. A pilot relying on an MCIS in reduced visibility
faces signiﬁcant risk if the MCIS is compromised by a malicious
adversary.
6. ANALYSIS OF EXISTING SYSTEMS