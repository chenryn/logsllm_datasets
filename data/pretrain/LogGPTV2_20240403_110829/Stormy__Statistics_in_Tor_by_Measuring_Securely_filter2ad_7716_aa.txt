title:Stormy: Statistics in Tor by Measuring Securely
author:Ryan Wails and
Aaron Johnson and
Daniel Starin and
Arkady Yerukhimovich and
S. Dov Gordon
Stormy: Statistics in Tor by Measuring Securely
Ryan Wails
Aaron Johnson
PI:EMAIL
U.S. Naval Research Laboratory
PI:EMAIL
U.S. Naval Research Laboratory
Daniel Starin
PI:EMAIL
Perspecta Labs
Arkady Yerukhimovich∗
PI:EMAIL
S. Dov Gordon
PI:EMAIL
George Washington University
George Mason University
ABSTRACT
Tor is a tool for Internet privacy with millions of daily users. The
Tor system benefits in many ways from information gathered about
the operation of its network. Measurements guide operators in
diagnosing problems, direct the efforts of developers, educate users
about the level of privacy they obtain, and inform policymakers
about Tor’s impact. However, data collection and reporting can
degrade user privacy, contradicting Tor’s goals. Existing approaches
to measuring Tor have limited capabilities and security weaknesses.
We present Stormy, a general-purpose, privacy-preserving mea-
surement system that overcomes these limitations. Stormy uses
secure multiparty computation (MPC) to compute any function of
the observations made by Tor relays, while keeping those observa-
tions secret. Stormy makes use of existing efficient MPC protocols
that are secure in the malicious model, and in addition it includes
a novel input-sharing protocol that is secure, efficient, and fault
tolerant. The protocol is non-interactive, which is consistent with
how relays currently submit measurements, and it allows the relays
to go offline after input submission, even while ensuring that an
honest relay will not have its input excluded or modified. The input-
sharing protocol is compatible with MPC protocols computing on
authenticated values and may be of independent interest.
We show how Stormy can be deployed in two realistic models:
(1) run primarily by a small set of dedicated authorities, or (2) run
decentralized across the relays in the Tor network. Stormy scales
efficiently to Tor’s thousands of relays, tolerates network churn,
and provides security depending only on either Tor’s existing trust
assumption that at least one authority is honest (in the first model)
or the existing assumption that a large fraction of relay bandwidth
is honest (in the second model).
We demonstrate how to use the system to compute two broadly-
applicable statistics: the median of relay inputs and the cardinality
of set-union across relays. We implement Stormy and experimen-
tally evaluate system performance. When Stormy is run among
authorities we can perform 151 median computations or 533 set-
union cardinalities over 7,000 relay inputs in a single day. When
run among the relays themselves, Stormy can perform 36 median
∗Part of this work was done while the author was at MIT Lincoln Laboratory.
Publication rights licensed to ACM. ACM acknowledges that this contribution was
authored or co-authored by an employee, contractor or affiliate of the United States
government. As such, the Government retains a nonexclusive, royalty-free right to
publish or reproduce this article, or to allow others to do so, for Government purposes
only.
CCS ’19, November 11ś15, 2019, London, United Kingdom
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6747-9/19/11. . . $15.00
https://doi.org/10.1145/3319535.3345650
computations or 134 set union cardinalities per day. Thus, both
deployments enable non-trivial analytics to be securely computed
in the Tor network.
CCS CONCEPTS
· Security and privacy → Privacy-preserving protocols.
KEYWORDS
Tor; secure multi-party computation; cryptographic protocols
ACM Reference Format:
Ryan Wails, Aaron Johnson, Daniel Starin, Arkady Yerukhimovich, and S.
Dov Gordon. 2019. Stormy: Statistics in Tor by Measuring Securely. In 2019
ACM SIGSAC Conference on Computer and Communications Security (CCS
’19), November 11ś15, 2019, London, United Kingdom. ACM, New York, NY,
USA, 18 pages. https://doi.org/10.1145/3319535.3345650
1 INTRODUCTION
The Tor network [26] is perhaps the most popular tool for private
and open communication on the Internet. As of 2018-03-31, Tor has
an estimated two million daily users from around the world, and
its almost 7,000 relays forward over 100 Gbps of traffic [5]. Tor also
protects the privacy and integrity of over 60,000 onion services,
which benefit from Tor’s anonymity, end-to-end encryption, and
secure name lookup. Statistics such as these provide some insight
into how Tor is being used and how well it is performing, which
guides software developers in improving Tor, informs policymakers
about Tor’s social impact, and helps users understand who else is
using Tor and thus what kind of anonymity it provides. However,
gathering such statistics conflicts to some extent with Tor’s goal of
providing privacy to its users. As a result, Tor collects relatively little
data about itself, and it protects what it does collect by aggregating
it and limiting its accuracy. This decision has left Tor unable to
quickly determine when it is under attack [13, 44], how its traffic is
being blocked or degraded [50, 69], and for what purposes Tor is
being used [8, 12, 42, 54].
Several recent tools have been developed to allow Tor to gather
network statistics while maintaining individual user privacy [30,
31, 42, 56]. These tools apply secure aggregation and differential
privacy to produce statistics in a privacy-preserving way. The func-
tionality of these tools is limited, however, which makes them un-
suitable for many useful classes of measurements, such as statistics
robust to outliers and non-linear data-sketching techniques.
The technical report for this work containing all appendices and proofs is available online.
Session 3C: Secure Computing IICCS ’19, November 11–15, 2019, London, United Kingdom615We present a system that provides fully-general distributed mea-
surement and monitoring on Tor by making use of secure multi-
party computation (MPC). This system provides Tor with tools to
intentionally choose the level of network transparency that is most
consistent with its goal of providing online privacy and freedom.
To make sure that our system is compatible with Tor, we aim to
rely only on security assumptions that are inherent in the secure
use of Tor. Specifically, we consider two different deployment mod-
els each relying on a different, standard trust assumption in the
Tor network. The first deployment model we consider, the Author-
ity Model, considers running the MPC protocol among a small
number of dedicated authorities. In this model, we only assume
that at least one of the authorities is honest, a standard assump-
tion for directory authorities in Tor. This model allows us to show
the performance that can be achieved under a strong, but stan-
dard trust assumption for Tor. The second deployment model, the
Relay Model, looks to relax this trust assumption to the minimal
requirement that a reasonable fraction (e.g., 75%) of Tor’s total band-
width capacity is controlled by honest relays. In this deployment
model we execute our MPC protocols directly over nearly 7,000
relays while aiming to maximize the throughput of the MPC.
This second deployment model required the development of new
MPC protocols, specialized to large numbers of parties, and rely-
ing on an honest fraction of bandwidth, as opposed to the usual
assumption of an honest number of parties. While the field of MPC
has seen tremendous progress in the last decade, this work marks
the first attempt to tackle the practical challenges that arise in a
secure computation involving thousands of parties. While there is
a long line of work studying how to handle larger computations
from a theoretical perspective [20, 25, 35, 36, 63, 72], mainly relying
on various committee-election procedures, this work does not con-
sider several realistic concerns about node churn, bandwidth, and
memory that we address in our work. Moreover, the largest MPC
experiment performed to date [68] involves 128 parties. However,
the Tor network at the end of March 2018 consisted of almost 7,000
relays, and that number continues to grow.
One major practical challenge we address is the uneven distri-
bution of bandwidth. When dealing with 7,000 independent par-
ties in a globally-distributed system, inevitably, not all parties will
have equal resources. To deal with this issue, we show a simple
way to elect committees of parties that ensures low communi-
cation cost while also guaranteeing high bandwidth utilization,
even when participants have highly varying bandwidth allocations
(Section 4.1). Specifically, we rely on a fairly simple observation.
Many MPC protocols can be divided into offline and online phases
[10, 15, 22, 23, 49, 68]. The offline phase requires quadratic com-
munication, but it is data independent, and can be performed in
parallel. So, instead of using a single committee, as done by prior
work, we assign each party to multiple committees proportional
to the amount of bandwidth that they have, ensuring that parties
with higher bandwidth are not limited by the reduced bandwidth
of smaller parties.
While the above techniques should find application in other
large-scale MPC implementations, assigning parties to multiple
committees also provides an important security benefit in the con-
text of Tor. Tor’s trust assumptions are different than those typically
made for MPC protocols: its security fundamentally requires that
a large fraction of bandwidth is controlled by honest parties. Our
committee-election procedure provides security given only this
trust assumption, and in particular does not require that a majority
of relays are honest. Electing committee members with probability
proportional to their bandwidth serves the dual purpose of allowing
us to reason that even small committees must contain an honest
party, despite the fact that a majority of relays may be malicious.
In addition, to make our protocols better suited to deployment in
the Tor network, we develop new techniques for offline preprocess-
ing and input sharing to make our protocols more resilient against
party churn and malicious behavior. In particular, we allow some
committees to fail during the preprocessing without interrupting
the overall protocol execution. This is not necessary in prior work
when only a single committee is elected, but becomes a requirement
as we aim to better utilize bandwidth. Additionally, we achieve the
following, seemingly contradictory properties for input providers
using an accountable input protocol: (1) a malicious member of
the committee receiving the inputs cannot exclude the input of
an honest party, and (2) a malicious input party that is not on the
committee cannot cause the secure computation to abort. These
properties together allow statistics to be computed despite missing
or malformed inputs without allowing the adversary to degrade
privacy by selectively excluding all but a subset of targeted inputs.
We have implemented our protocol and experimentally demon-
strate capabilities that exceed the limitations of existing proposals
and Tor’s current measurement methods. First, we show an exam-
ple of using robust statistics by computing the median of the relays’
inputs. This statistic tolerates outliers and thus prevents malicious
Tor relays from manipulating measurement outcomes through spu-
rious inputs. It also doesn’t require us to know in advance what
input values are reasonable, as in prior work using input valida-
tion [21]. Such robust aggregate statistics provide privacy while
also providing outputs that can be relied on for network-critical
operation, such as measuring bandwidth capacity [45].
We also demonstrate that Stormy can be used to compute ef-
ficient statistics based on sketches. These computations are not
necessarily robust, but their space efficiency enables the collection
of a variety of useful network statistics. We consider the count dis-
tinct computation and show how to count unique items across the
entire network with exponentially less communication and com-
putation than is typically required by protocols for private set
intersection or union [31, 51, 61]. This design supports accurately
counting distinct items up to the billions, allowing Tor to detect
how many unique users it has, how many distinct Web domains
its users visit, and how many of its onion services are visited at
least once. An analysis of our design shows that both the median
and count-distinct computations can be performed from dozens to
hundreds of times per day, enabling Tor to collect and report these
new statistics quickly and with regularity.
To summarize our contributions: (1) we describe two deployment
models to incorporate MPC into the Tor network based only on
standard Tor assumptions; (2) we develop techniques for provid-
ing input and offline processing that are resilient to party failures
and prevent omission of inputs; (3) we adapt MPC protocols for
non-uniform trust and bandwidth; (4) we describe how to securely
compute a median and sketch-based unique count, which is not
possible with current Tor-measurement systems; and (5) we provide
Session 3C: Secure Computing IICCS ’19, November 11–15, 2019, London, United Kingdom616experimental results showing practical MPC performance when
run over both a small set of authorities and the entire Tor network.
2 TOR BACKGROUND
Tor [26] anonymizes Internet traffic by sending it through its net-
work of relays. The relays are run by independent volunteers who
donate the computational and network resources [5]. A Tor user
creates an anonymized TCP connection through Tor by sending a
connection request to a locally-run Tor client. The client builds a
circuit through a sequence of relays, and the desired connection can
be placed onto that circuit. Tor circuits generally consist of three
relays: a guard, middle, and exit. Relays are flagged for suitability as
guards or exits based on their resources and willingness to connect
outside the network, and then, for each position in a circuit, a relay
is chosen from among those suitable with probability proportional
to a network-determined weight [6]. That weight is intended to
be proportional to the relay’s bandwidth, largely to balance the
traffic load and improve network performance. However, doing so
also provides security: it requires an adversary to provide costly
bandwidth to the network in order for its relays to achieve positions
in which they can attack clients.
Tor users are vulnerable to an adversary that controls a signifi-
cant fraction of the Tor network. For such an adversary, there is a
non-trivial chance that a client’s circuit is composed entirely of ma-
licious relays, in which case the adversary can easily deanonymize
the connection. In practice, however, the adversary need only con-
trol a circuit’s first and last hop (i.e. the guard and exit) because he
can identify that both are part of the same circuit by correlating
traffic patterns [9, 17]. Controlling any one position harms client
security as well, as a malicious guard can, for example, perform
website fingerprinting [67] and selective denial-of-service [13], a
malicious middle can perform website fingerprinting [43] and guard
discovery [39], and a malicious exit can perform man-in-the-middle
attacks [69]. Thus, for Tor to be secure it must be that no adversary
controls a large fraction of the relay weight in any position. While
no sharp threshold for security exists, an adversary that controlled,
say, 25% of Tor’s bandwidth, would effectively have compromised
the network, as under current rates of churn, a quarter of clients
could expect to choose a compromised guard immediately, and the
rest within a few months; given a compromised guard, the client can
expect to choose a compromised exit (and thus be deanonymized via
a correlation attack) within hours [29, 47]. Tor’s threat model is thus
limited to an adversary controlling a small fraction of bandwidth
(we will assume < 25%).
The state of the Tor network is maintained by the Directory
Authorities (DirAuths) [4]. There are currently nine DirAuths that
vote to determine a network consensus. A consensus is produced
every hour and contains, among other things, a list of the relays
with their bandwidths and position flags. DirAuths also store relay
descriptors that contain other data needed by clients, such as the
exits’ connection policies. Every client downloads a copy of the
consensus every hour and downloads sufficiently-recent descriptors
(currently within 18 hours), which it uses to choose relays when
constructing circuits. Most entries in the consensus, including the
relays and their properties, must be voted for by a majority of the
DirAuths, and so Tor relies to a great extent on a trust assumption
that a majority of DirAuths are honest. The DirAuths also generate
a random value to put into the consensus using a commit-reveal
protocol [7]. This value is currently only used to affect how Tor’s
internal name-resolution operates.
To be listed in the Tor consensus, a relay must directly com-
municate with the nine DirAuths and an additional set of Band-
width Authorities who determine the relay’s bandwidth and con-
sensus weight. Authorities are geographically distributed around
the world in many different networks; consequently, relays must be
well-connected in the Internet in order to communicate with each
authority. Moreover, the Tor protocol assumes that each relay can
communicate with all other relays in a fully-connected network.
The Tor network consensus from 2018-10-01 includes 6,331 re-
lays. On that day, Tor relays sent on average about 125 Gbps of
traffic in aggregate on behalf of an estimated 2 million users. We
observe that the distribution of Tor relay weight is skewed towards
high-bandwidth nodes. The largest 25% of relays by weight have
78% of the total weight. The minimum non-zero advertised band-
width is 0.02 Mbps, the median is 12.44 Mbps, and the maximum is
1,397 Mbps. The total advertised bandwidth is 275 Gbps. Much of
Tor’s bandwidth goes unused: the relays’ bandwidth histories show
that they actually relayed only 125.0 Gbps of traffic on average, and
so only 45.5% of the advertised bandwidth is used. Moreover, we
observe that 95% of Tor relays (by bandwidth) have at least 25%
spare capacity (see the technical report [65] for more detail). This
behavior is consistent over time, as we observe that for every day