### File with `objcopy`

Figure 11, extracted from the `make` utility, illustrates a subtraction overflow at Line 5, which can lead to incorrect or out-of-bound array accesses. AFL (American Fuzzy Lop) detected Figures 10 and 11 using initial seeds provided by Learch. Figure 12, on the other hand, shows a benign subtraction overflow detected by KLEE with Learch for the `sort` tool in the coreutils package. The code in question computes the logarithm of a number stored in an unsigned char array `tmpa`. To determine if the current array element is a digit, the code uses the `ISDIGIT` macro, which overflows when `c < '0'`. In this case, `ISDIGIT` returns `false`, which is the desired behavior since `c` is not a digit. Thus, the overflow scenario was already considered and handled appropriately.

### 6.6 Effectiveness of Design Choices

We evaluate the effectiveness of Learch's design choices. Due to space constraints, we primarily present results for the coreutils package. Similar observations were made for other real-world programs.

#### Performance of Individual Strategies

As described in Section 6.1, Learch comprises four learned strategies. We ran each strategy for 1 hour on the coreutils test set and compared the results with Learch, which combines the four strategies (each running for 15 minutes). The results are shown in Figure 13.

- **Line Coverage:**
  - strat-1: 640
  - strat-2: 566
  - strat-3: 566
  - strat-4: 560
  - Learch: 563

- **# UBSan Violations:**
  - strat-1: 100
  - strat-2: 71
  - strat-3: 75
  - strat-4: 50
  - Learch: 25

**Figure 13: Results of learned strategies on the coreutils test set.**

The individual strategies achieved more coverage (approximately 20 lines) than the manual heuristics. Although the absolute coverage numbers were similar, the four strategies covered different parts of the program. Consequently, Learch, which combines the four strategies, was the most effective overall. This outcome aligns with the iterative learning process described in Algorithm 4.

Learch also detected more UBSan violations than strat-1, strat-2, and strat-3. However, it found 5 fewer violations than strat-4 because strat-4 identified many violations after 15 minutes. To enhance Learch's violation detection, we can simply increase the time budget.

#### Different Choices of Machine Learning Models

In addition to the feedforward networks used in Learch, we evaluated simpler linear regression (linear) and more complex recurrent neural networks (RNN). For the RNN, we added a hidden state of dimension 64 between a state and its parent. We trained the linear and RNN models on the same supervised dataset as Learch and ran them with the same configuration (i.e., four independent runs, each taking a quarter of the time budget) on our test set. The results for the coreutils test set are shown in Figure 14, indicating that Learch outperformed both linear and RNN models. This is likely due to the complexity of feedforward networks being well-suited for our learning task.

- **Line Coverage:**
  - Linear: 640
  - RNN: 517
  - Feedforward: 563
  - Learch: 618

- **# UBSan Violations:**
  - Linear: 100
  - RNN: 88
  - Feedforward: 70
  - Learch: 50

**Figure 14: Results of different models on the coreutils test set.**

### 7. Related Work

We discuss works closely related to ours.

#### Symbolic Execution

Symbolic execution-based testing techniques have been developed over several decades [18, 44], leading to numerous applications [23, 24, 27, 36, 53, 76] and systems [8, 16, 17, 22, 52, 68, 74]. The main challenges in symbolic execution include path explosion and expensive constraint solving [18]. Various manual heuristics have been proposed to select promising paths [16, 48]. Our learning-based strategy, Learch, significantly outperforms these heuristics. Other orthogonal approaches to mitigate path explosion include state merging [46], state pruning [13, 14, 21, 70], and code transformation [25]. Several works focus on improving the performance of constraint solvers [9, 28, 32, 61]. Some combine the constraint solving process with the symbolic execution framework by solving multiple path constraints once [77], leveraging pending path constraints [43], and introducing neural constraints [66]. While most of these approaches aim to explore the entire program (as does Learch), directed symbolic execution targets specific program parts or changes [50, 56, 73].

#### Concolic Testing and Fuzzing

Concolic testing and fuzzing are distinct approaches for program testing but can benefit from advances in symbolic execution, as many of them use symbolic execution to trigger complex paths. Concolic testing [33, 57, 58, 62] concretely executes the program alongside symbolic execution and negates the path constraint of visited branches to produce new tests covering unvisited branches. Heuristics for selecting branches in concolic testing have been learned [19, 20]. Fuzzing is a technique that concretely executes the program and generates concrete inputs based on input specifications [11, 40, 47] or mutations from existing inputs [1, 7, 12, 26, 30, 31, 41, 42, 45, 65, 72]. Symbolic execution has been used to improve fuzzing [29, 54]. Hybrid testing [27, 69, 75] combines concolic testing and fuzzing in an alternating manner to leverage the advantages of both.

#### Machine Learning for Program Analysis and Security

Machine learning has been extensively used for security tasks. Markov chains [12], feedforward networks [65], recurrent networks [35], imitation learning [37], and reinforcement learning [72] have been employed to improve test generation in fuzzing. Reinforcement learning has been used for directed symbolic execution [73]. Many other tasks, such as binary analysis [38], malware analysis [60], and taint analysis [64], have been addressed using data-driven approaches.

### 8. Conclusion

In this work, we introduced Learch, a learning-based state selection strategy for symbolic execution. Learch operates by estimating a reward for each state and selecting the state with the highest reward to maximize coverage while minimizing time cost. We constructed Learch by applying off-the-shelf regression learning on a supervised dataset extracted from the tests generated by running symbolic execution on a set of training programs. The training process is iterative and constructs multiple strategies, which produce more diverse tests than a single strategy. Learch benefits from existing heuristics by incorporating them in both training and feature extraction.

We implemented Learch on KLEE [16] and evaluated it on the coreutils programs and ten real-world programs. The results demonstrated that Learch is effective and can produce higher-quality tests than existing manually designed heuristics, either individually or combined as portfolios. Learch's tests yielded more code coverage, detected more security violations, and were better candidates as initial seeds for fuzzers like AFL.

### References

[References listed as provided in the original text]

---

This version of the text is more structured, coherent, and professional, with improved clarity and flow.