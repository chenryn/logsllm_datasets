title:Spatiotemporal Traffic Matrix Synthesis
author:Paul Tune and
Matthew Roughan
Spatiotemporal Trafﬁc Matrix Synthesis
ARC Centre of Excellence for Mathematical and Statistical Frontiers
Paul Tune and Matthew Roughan
School of Mathematical Sciences
University of Adelaide, Australia
{paul.tune,matthew.roughan}@adelaide.edu.au
ABSTRACT
Traﬃc matrices describe the volume of traﬃc between a
set of sources and destinations within a network. These
matrices are used in a variety of tasks in network plan-
ning and traﬃc engineering, such as the design of net-
work topologies. Traﬃc matrices naturally possess com-
plex spatiotemporal characteristics, but their propri-
etary nature means that little data about them is avail-
able publicly, and this situation is unlikely to change.
Our goal is to develop techniques to synthesize traﬃc
matrices for researchers who wish to test new network
applications or protocols. The paucity of available data,
and the desire to build a general framework for synthe-
sis that could work in various settings requires a new
look at this problem. We show how the principle of
maximum entropy can be used to generate a wide va-
riety of traﬃc matrices constrained by the needs of a
particular task, and the available information, but oth-
erwise avoiding hidden assumptions about the data. We
demonstrate how the framework encompasses existing
models and measurements, and we apply it in a simple
case study to illustrate the value.
Categories and Subject Descriptors
C.2.5 [Computer Communications]: Local and Wide
Area Networks—Internet; C.4 [Performance of Sys-
tems]: Modeling Techniques
Keywords
Maximum entropy; network design; spatiotemporal mod-
eling; traﬃc engineering; traﬃc matrix synthesis
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than ACM must be honored. Abstracting with credit is per-
mitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
SIGCOMM ’15, August 17 - 21, 2015, London, United Kingdom
c(cid:13) 2015 ACM. ISBN 978-1-4503-3542-3/15/08. . . $15.00
DOI: http://dx.doi.org/10.1145/2785956.2787471
1.
INTRODUCTION
A Traﬃc Matrix (TM) describes the traﬃc volume
between a set of sources and destinations in a network.
TMs are used as inputs in a variety of network planning
and traﬃc engineering tasks. For instance, new power
aware routing and traﬃc engineering algorithms [9] need
TMs for testing and validation. TMs are also required
for network traﬃc forecasting and planning [32] and
topology generation [5]. The lack of public TM data
remains an obstacle to researchers in these areas.
The main reason for this lack is the propriety nature
of TMs: network operators are reluctant to release such
data as they fear it may lead to the erosion of their
competitive advantage. Consequently, researchers re-
sort to testing network designs on limited public data,
such as from the Abilene [23] or G´EANT [41] networks.
These, however, are research and education networks,
leading to the possibility that they are not representa-
tive of commercial networks. Even the release of a sin-
gle commercial operator’s TM data would not quell the
question of representativeness – so we really need many
such datasets. Hence, the current deﬁcit is unlikely to
be remedied in the foreseeable future.
Researchers also need multiple TMs to test ideas sta-
tistically and in order to have ground truth when test-
ing inference techniques. To do this, large ensembles of
TMs must be generated, so that conﬁdence intervals on
the performance of these techniques be meaningful.
We can solve these issues by synthesizing TMs, but
how can we create a good model for synthesis without
ﬁrst having data? The answer is to abandon the typical
network modeling approach – measure then model – and
think about the problem from ﬁrst principles.
Additionally, we are not aiming here at the typical
target of past TM research: better inference of TMs
from limited data [14,22,35,45,48]. When we synthesize
a TM, we have diﬀerent requirements:
• Control: A particular network protocol we aim to
test will make assumptions. We should be able to
generate TMs that match those assumptions to test
its performance. For completeness, we also need to
generate TMs that violate the assumptions, to test
what happens to the protocol in unfriendly situations.
579The required assumptions and constraints on TMs
will vary from setting to setting. However, in creating
TMs that satisfy some set of assumptions, we should
not be forced to introduce additional (often hidden)
assumptions about the traﬃc. We want to include
the desired constraints on the TMs but no others.
• Eﬃciency: We want to be able to generate potentially
large numbers of TMs computationally eﬃciently to
obtain clear statistical measures of performance.
• Consistency: We want to make apples to apples com-
parisons: two studies using the same model should
reach the same conclusions (regardless of speciﬁc ran-
dom values), so we need to be able to draw instances
from a well-deﬁned, consistent ensemble of TMs.
• Simplicity: A model should be “as simple as it can be
– but not simpler” [7]. Simplicity has many virtues:
it improves our intuitive understanding, reduces the
complexity of parameter estimation, and prevents over
ﬁtting. Part of simplicity is parsimony of parameters,
and part is having meaningful parameters.
Finally, we might like our TMs to be “realistic”, but that
might vary tremendously from setting to setting: for in-
stance it seems likely that Wide Area Network (WAN)
TMs are nothing like data center TMs. So realism is
context dependent, and our goal here is to create a
framework that can encompass and be adapted easily
to any such setting. Indeed, if some data is available to
populate a model in a particular context, we would like
our framework to be able to include that data.
Our approach is based on the principle of maximum
entropy (MaxEnt) [15]. Information theory and its dar-
ling entropy have been applied to inferring TMs in the
past with success [31, 45, 46], but there are some subtle
diﬀerences between creating models for inference and
synthesis. Most notably, we don’t necessarily have any
data, though if we do, we would like to incorporate it.
The resulting MaxEnt framework encompasses and
extends most of the existing models for TMs, e.g., [31,
36]. The models it produces are conservative in the
sense that they do not assume anything about the TMs
beyond the given constraints. The framework also links
the constraints and assumptions directly to models, so
that we can learn from an existing model exactly what
minimal set of assumptions led to it.
A list of our contributions are as follows:
• a systematic methodology for generating controlled
synthetic TMs with prescribed properties, achieved via
the principle of maximum entropy,
• closed-forms of example models that would be useful
in testing various network algorithms (e.g., routing
protocols) and network designs,
• fast generation of ensembles of TMs with spatiotem-
poral properties, and
• a uniﬁcation of previous TM models under the family
of maximum entropy models.
We examine the utility of our approach through its
use in topology generation [5]. Here, the topology is de-
signed around a set of TMs as input. Our case study’s
two chief ﬁndings are 1. although TMs have an impact
on the topology design, the impact of some TM fea-
tures is small, consistent with the ﬁndings of [5], and
2. optimizing a network around the peak TM is almost
as good an approach as optimizing with respect to a
whole-of-week pattern, supporting the common practice
of basing designs around a peak traﬃc measure such as
a busy hour.
Our code is at https://github.com/ptuls/MaxEntTM
2. BACKGROUND
2.1 The principle of maximum entropy
The principle of insuﬃcient reason, often credited to
Pierre Simon Laplace in the late 18th century, states
that given an observation one should remain undecided
about all the potential events explaining the observa-
tion. In other words, one assigns equal probability to
each event. Laplace and Jacob Bernoulli considered the
concept to be intuitively obvious, seeing little need to
formalize it [37].
The principle of maximum entropy formally deﬁnes
and generalizes the principle of indiﬀerence. Proposed
by Jaynes [15] in the context of statistical mechanics the
principle advocates that, given data, we should choose
the distribution providing a plausible explanation of
the observations while making the fewest assumptions.
Jaynes showed that several models in statistical me-
chanics arise as a natural consequence.
The principle is deﬁned in terms of Shannon infor-
mation entropy [10]. If X is a discrete random variable
taking values in set X with probability mass function
p(x), then Shannon’s entropy is deﬁned as [10]
H(X) = −Xx∈X
p(x) log p(x),
(1)
with the convention 0 log 0 = 0. Entropy measures the
average uncertainty of a random source, for instance,
if X is completely deterministic, H(X) = 0. Shan-
non’s entropy is used because it is the only measure that
nicely separates independent components in a joint dis-
tribution, and has a natural axiomatic derivation as a
measure of uncertainty [34].
The principle of indiﬀerence now arises as a special
case: when the only constraint is that p(x) be a prob-
ability distribution, the entropy is maximized by the
uniform distribution. Thus, maximizing entropy is con-
sistent with the intuitive notion of being least commit-
ted to any one outcome, i.e., indiﬀerence.
If additional observations exist, we describe them as
constraints on the data. MaxEnt states that the best
strategy is to choose a distribution that maximizes en-
tropy subject to these constraints. The solution is one
580that conforms to known observations about the data
and no more than that.
Jaynes [15] used the Shannon entropy to construct
the MaxEnt framework. Since we consider continuous
Random Variables (RVs) as an approximation of the
traﬃc volumes, we use the diﬀerential entropy [10],
h(f ) = −Z ∞
−∞
· · ·Z ∞
−∞
f (X ) log f (X ) dX ,
(2)
of a random TM process X with distribution f (X ).
Suppose by experimental observation, there are L + 1
constraints on the data E[φℓ(X )] = bℓ (where φℓ(·) is a
convex function and bℓ is a scalar value setting the con-
straint) are known. The constraint E[φ0(X )] = 1 is the
normalization constraint (that applies to all probability
distributions). The MaxEnt optimization problem is
max
f (X )
h(f ), s.t. {E[φℓ(X )] = bℓ}L
ℓ=0, and X (cid:23) 0, (3)
where X (cid:23) 0 denotes non-negativity, a constraint we
enforce on all TM models.
In the cases we primarily consider, the problem is
convex so any local maximum is the global maximum,
the solution being the maximum entropy model. Non-
convex functions are possible, but more eﬀort is required
to search for the globally maximum model.
Boltzmann’s theorem [15] states that the optimal so-
lution takes the form of distributions from the exponen-
tial family, generically given by
f (X ) =
1
Z
exp −
L
Xℓ=1
λℓφℓ(X )! ,
(4)
where the {λℓ}L
ℓ=1 are the Lagrange multipliers obtained
via the Calculus of Variations applied to (3), and Z is
the normalization factor which incorporates the normal-
ization constraint.
2.2 Entropy and TM models
Zhang et al.
A general introduction to modeling TMs can be found
in [38]. We examine some of these models in detail here
so that we can discuss how they relate to our framework.
[45, 46] used a technique referred to as
maximizing relative entropy to develop TM inference
methods. However, this is diﬀerent from maximum en-
tropy modeling. Zhang et al.s’ approach was aimed at
ﬁnding a particular TM that matched data and was
close to a prior model (in their case the generalized grav-
ity model). Here we aim to create a model, not estimate
a particular TM. The output of our approach is a dis-
tribution, not a TM. The part of that work closer to
our own is in their prior model: we shall discuss gravity
models and their ilk at length here.
Roughan [31] proposed using a random gravity model
as a spatial model for TM synthesis, and Oikonomou
[25] noted that it is a MaxEnt model for traﬃc under a
certain set of assumptions. In fact, if one examines the
transportation literature, that insight is even older [28].
This is a single case of the framework presented here.
The work listed above considered spatial TMs only.
The only work of which we are aware speciﬁcally on
spatiotemporal synthesis was that of Nucci et al. [24],
who developed static, dynamic stationary and dynamic
cyclo-stationary models of TMs. Their spatial model
was simple: a log-normally distributed Independent and
Identically Distributed (IID) set of TM elements were
generated. However, their models’ raw outputs might
not conform to pre-speciﬁed constraints, such as link
capacities, necessitating adjustments to make them ad-
missible TMs. We show here how this IID model ﬁts
into the MaxEnt framework, and how the framework
allows us to avoid this ad hoc mapping step.
Most other works proposing spatiotemporal TM mod-
els do so with the aim of improving inference accuracy,
rather than addressing the synthesis problem (though
occasionally, passing reference has been made to poten-
tial alternative uses of their models). Soule et al. [36]
proposed two models of Origin-Destination (OD) ﬂows,
one stationary and the other cyclo-stationary. Roughan
et al. [33] developed a simple purely temporal model of
OD ﬂows traversing backbone routers comprising of a
growth trend component, a seasonal component and a
component for sudden spikes in traﬃc due to anomalies.
Zhang et al. [48], exploiting new developments in signal
processing, developed a model under the assumption of
spatiotemporal low rankedness, enabling accurate TM
inference via convex programming [8, 30].
Another work addressing the synthesis problem is
[40], but its focus is entirely diﬀerent. Our conceptual
model in that paper was to help a network operator
understand the eﬀect of errors in predictions of TMs.
In that context, the idea was to generate an ensemble
of TMs centered around the prediction, whereas here,
we do not require prior data about the TM, only con-
straints on its general properties. Interestingly, as the
errors become large in that model, the results approach
a maximum entropy distribution, which is exactly what
we propose here: when little is known about the TM,
MaxEnt provides a natural path towards modeling.
Notation: The column vector of N ones is denoted
by 1N . Some common statistical distributions are used
here:
• An exponentially distributed RV X with mean 1/λ is
denoted X ∼ Exp (λ).
• The continuous uniform distribution in the interval
[a, b] is denoted by U(a, b).
• X ∼ N (µ, Σ) means that X is distributed as a nor-
mal distribution with mean µ and covariance Σ.
• X ∼ TNorm (µ, Σ) means that X is distributed ac-
cording to a truncated normal distribution with sup-
port I := [0, ∞)N . Note that µ and Σ are the mean
and covariance after truncation.
We deﬁne all other notation when needed.
5813. SPATIOTEMPORAL TM SYNTHESIS
Network traﬃc information is contained in the TM
X(t), which measures traﬃc between locations in a net-
work. Traﬃc is typically measured in discrete time in-
tervals, with 5 to 15 minutes. So a “traﬃc matrix” is
actually a series of matrices:
X(tk), k = 0, 1, · · · , M − 1,
(5)
where Xi,j(tk) denotes the average volume of traﬃc en-
tering node i and exiting node j in a measurement in-
terval [tk, tk+1).
Let X := {X(tk)}M −1
k=0 denote the TM process. We
are concerned here with the distribution governing the
generation of X , denoted by f (X ).
In general, mul-
tivariate stochastic processes are all governed by such
a distribution, which here deﬁne an ensemble of TMs.
However, all successful models simplify this high dimen-
sional construct in some (usually dramatic) way.
Although network traﬃc is discrete in nature (mea-
sured in bytes or packets), we model the TM entries as
continuous RVs. This assumption is reasonable where
we consider high volumes of traﬃc.
Spatial properties of the TMs refer to the statistical
properties between the TM entries either at a ﬁxed t,
i.e., a snapshot X(tk), or over time, e.g., the average
TM 1