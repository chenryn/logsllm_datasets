title:Quantifying the Reliability of Proven SPIDER Group Membership Service
Guarantees
author:Elizabeth Latronico and
Paul S. Miner and
Philip Koopman
Quantifying the Reliability of Proven
SPIDER Group Membership Service Guarantees
Elizabeth Latronico
ECE Department
Carnegie Mellon University
Pittsburgh, PA, USA
PI:EMAIL
Paul Miner
NASA Langley Research Center
Hampton, VA, USA
PI:EMAIL
Philip Koopman
ECE Department
Carnegie Mellon University
Pittsburgh, PA, USA
PI:EMAIL
Abstract
to transient and permanent
the assumptions
We investigate the reliability of
For safety-critical systems, it is essential to quantify the
that underlie proven
reliability of
guarantees.
the
assumptions of the SPIDER group membership service with
respect
faults. Modeling
12,600 possible system configurations, the probability that
SPIDER's Maximum Fault Assumption will not hold for an
hour mission varies from less likely than 10-11 to more likely
than 10-3.
In most cases examined, a transient fault
tolerance strategy was superior to the permanent fault
tolerance strategy previously in use for the range of
transient fault arrival rates expected in aerospace systems.
Reliability of the Maximum Fault Assumption (upon which
the proofs are based) differs greatly when subjected to
asymmetric, symmetric, and benign faults. This case study
demonstrates the benefits of quantifying the reliability of
assumptions for proven properties.
1. Introduction
Formal proofs provide an attractive means of develop-
ing safety-critical network protocols. Protocols destined
for aerospace or automotive use may need to exhibit fewer
than 10-9 failures per hour [12]. Exhaustive testing of these
protocols is a daunting challenge, potentially requiring on
the order of 109 hours of testing or more. This precludes ex-
haustive testing as a sole means of verification. Also, ex-
haustive testing of
the implementation provides no
feedback at the design stage, when changes are easiest to
make. Formally proven protocols are guaranteed to pro-
vide their services at all times - if all of the assumptions
hold. Unfortunately, the assumptions will not hold for all
possible fault cases. Eventually, weakening the assump-
tions makes the proof untenable. Arguing that the assump-
tions are ‘reasonable’ is inadequate for safety-critical
systems, due to stringent reliability requirements. The as-
sumptions must be shown to be reliable to conclude that the
formally proven service is reliable.
It is important to investigate assumption reliability over
a range of design space, and explore design-stage policy
trade-offs. An instantiated system will occupy one point in
a large space of possible systems. Current techniques, such
as Failure Mode Effects Analysis and Fault Tree Analysis,
predict the reliability of a particular instantiation, and may
rely on high-precision failure rates to achieve high-preci-
sion reliability estimates. However, high-precision failure
rate data may not be available, especially for novel systems.
We present a methodology based on Markov modeling
techniques that evaluates assumption reliability for ranges
of parameters that can differ by an order of magnitude or
more. Multiple policies can be compared to determine
which is more reliable in a given range of the design space.
Our case study reveals that systems with an identical for-
mal proof basis can have vastly different assumption reli-
ability depending on the parameters of the instantiated
system. We analyze the reliability of the assumptions of the
group membership service for the SPIDER protocols devel-
oped by NASA Langley Research Center. First, we study
three alternative policies for removing faulty nodes from
membership. We focus on assumption reliability in the
presence of transient faults, in addition to a permanent fault
model. The formal proof does not make a distinction be-
tween transient and permanent faults, as it does not need to -
both types of faults can be proveably handled with the same
mechanisms. However, we show that the presence of tran-
sient faults significantly affects the probability that the as-
sumptions will hold for the duration of the mission. We
also investigate assumption reliability with respect to dif-
ferent types of faults (asymmetric, symmetric, and benign).
The assumptions are less reliable overall for asymmetric
faults versus symmetric or benign faults, as asymmetric
faults require additional redundancy to handle.
The results clearly show the value of testing the assump-
tions with expected fault conditions. The model of the ser-
vice includes static parameters, plus six parameters that
vary over bounded ranges. Our experiments cover 12,600
combinations of parameters, showing it is feasible to cover
a wide range of design space. This paper complements
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:52:29 UTC from IEEE Xplore.  Restrictions apply. 
work on assumption coverage illustrating that ‘reasonable’
assumptions are not always ‘reliable’ assumptions, which
we discuss following our results. Section 2 reviews the
SPIDER protocols and guarantees, and Section 3 describes
studied policies. Section 4 explains the modeling process,
with an example. Section 5 covers our fault model. Section
6 presents results, and Section 7 discusses related work.
2. SPIDER
As described by Geser and Miner in [10], “The Scalable
Processor-Independent Design for Electromagnetic Resil-
ience (SPIDER) is a family of general-purpose fault-toler-
ant architectures being designed at NASA Langley
Research Center to support laboratory investigations into
various recovery strategies from transient failures caused
by electromagnetic effects.” At the heart of SPIDER is the
Reliable Optical Bus (ROBUS), which processing ele-
ments use to reliably transmit data in a fully-connected,
broadcast manner. Formal proofs define the fault tolerance
abilities of the ROBUS. The proofs are valid for all trans-
mission media. The ROBUS has two types of components:
Bus Interface Units (BIUs) and Redundancy Management
Units (RMUs). The BIUs are fully connected to all RMUs,
and vice-versa. Each BIU has a one-to-one connection to a
corresponding Processing Element (PE). A Processing Ele-
ment cannot exhibit asymmetric (’Byzantine’) faulty be-
havior, since there is only one direct consumer of its data.
Asymmetric BIU or RMU faults are handled internally by
the ROBUS, freeing the application designer from this con-
cern, as long as the proof assumptions hold. Figure 1 from
Geser and Miner [9] illustrates the SPIDER architecture.
2.1. SPIDER Maximum Fault Assumption
SPIDER is designed to tolerate multiple faulty nodes,
yet still provide firm guarantees. SPIDER achieves this
multiple fault tolerance in part through its Diagnosis proto-
col that detects and classifies faulty nodes. The Diagnosis
protocol classifies nodes as one of the following [10]:
PEs
BIUs
RMUs
1
2
N
1
2
N
1
2
M
Figure 1. ROBUS Topology, Geser and Miner [9]
• Good: A good node behaves according to specification.
• Benign faulty: A benign faulty node only sends
messages that are detectably faulty (for example, a
message with a bad Cyclic Redundancy Code value).
This includes nodes that have failed silent.
• Symmetric faulty: A symmetric faulty node may send
arbitrary messages, but each receiver receives the same
message.
• Asymmetric faulty: An asymmetric (’Byzantine’)
faulty node may send arbitrary messages, including
different well-formed messages to different receivers.
The SPIDER protocols make a number of guarantees,
contingent upon a Maximum Fault Assumption (MFA).
The Maximum Fault Assumption specifies the maximum
number and type of faults that SPIDER can tolerate. As
long as the system satisfies the Maximum Fault Assump-
tion, the SPIDER guarantees are proven to hold. If addi-
tional faults are present in the system, the guarantees may
not hold. If nodes are not permitted to reintegrate, the Max-
imum Fault Assumption is as stated in the three parts below,
MFA.1, MFA.2, and MFA.3 [10].
(The Maximum Fault
Assumption changes slightly if reintegration is permitted.
Geser and Miner give further details in [10]). Node
amounts are positive [10]:
• MFA.1. Number of Good BIUs > (Number of
Symmetric BIUs + Number of Asymmetric BIUs)
• MFA.2. Number of Good RMUs > (Number of
Symmetric RMUs + Number of Asymmetric RMUs)
• MFA.3. (Number of Asymmetric BIUs = 0) or
(Number of Asymmetric RMUs = 0)
Reliability analysis determines the probability that these
conditions will not be true, subject to a given fault model.
SPIDER’s Maximum Fault Assumption is tight, in the
sense that if any of the three parts are violated, there exists
an allowed behavior of the faulty node(s) that will violate
the SPIDER guarantees. Within the constraints of our fault
model, the MFA conditions are necessary. However, the al-
lowed faulty behavior can be quite broad. It is intractable to
measure error manifestations for all possible fault sources,
in part because it is not possible to determine the set of all
possible faults.
2.2. SPIDER Guarantees and Policy choices
First, we examine the guarantees that SPIDER provides,
and look at the group membership service for fault toler-
ance. We focus on the Interactive Consistency (IC) proto-
col and Diagnosis protocol that the ROBUS implements.
The Interactive Consistency protocol provides two guaran-
tees, validity and agreement [10].
• Validity: Every good node receives the value sent by a
good node.
• Agreement: All good nodes agree in the value sent.
SPIDER uses group membership to enable good nodes
to ignore some faulty nodes. Chockler, Keidar, and
Vitenberg state that “The task of a membership service is to
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:52:29 UTC from IEEE Xplore.  Restrictions apply. 
maintain a list of currently active and connected processes
in a group.” [5]. Active nodes form a set of eligible voters.
A group membership service identifies faulty nodes and re-
moves them from this set. Removed, or convicted, nodes
become ‘benign’ faulty nodes, as eligible voters will ignore
removed nodes. For SPIDER, the goal is to enhance the
fault tolerance of the system by turning asymmetric and
symmetric faulty nodes into benign faulty nodes. SPI-
DER’s Diagnosis protocol provides two guarantees [10]:
• Conviction Agreement: All good nodes agree on
convictions.
• Correctness: No good node is ever convicted.
Conviction agreement is common to many protocols;
however, protocol designers can choose to guarantee cor-
rectness or completeness (or neither). Geser and Miner
state, “In the presence of arbitrary asymmetric failures, it is
impossible to guarantee both correctness and complete-
ness” [10], where completeness means that “all faulty
nodes are eventually convicted.” By preserving correct-
ness instead of completeness, SPIDER can accumulate evi-
dence against a node as an alternative to immediate
conviction.
In comparison, guaranteeing completeness
would require conviction of transiently faulty nodes, which
can significantly decrease assumption reliability (as we will
show). A disadvantage to correctness is that it is not possi-
ble to convict faulty nodes in some cases.
3. Conviction Policies
The SPIDER Diagnosis protocol may remove suspected
faulty nodes from membership. We define the conviction
policy as the method for determining which nodes to re-
move from the set of eligible voters. The conviction policy
plays an important role in the reliability of the system, be-
cause it affects the likelihood that the Maximum Fault As-
sumption will be violated. The conviction policy must
balance the risk of inadequate redundancy versus the risk of
too many faulty nodes in the set of eligible voters.
The existence of transient faults poses an interesting di-
lemma. As used here, the term transient fault refers to a
fault which persists for a finite duration, ceases to exist after
that duration has expired and does not alter the state of the
affected component beyond that duration. A permanent
fault is a fault with infinite duration or lasting effects on
state.
In our fault model, faults can occur at a node or on
the broadcast network. Convicting transiently faulty nodes
may decrease the reliability of the system, as the number of
If the tran-
available redundant components will decrease.
sient fault duration is short, then it is probably better to do
nothing, letting the transient fault expire.
SPIDER’s Maximum Fault Assumption is stated in
terms of nodes, so frames that are corrupted due to faults on
the network will be perceived as node faults.
In the
Fault-Error-Failure classification scheme proposed by
Deswarte, Kanoun, and Laprie [7], this can be thought of as
the ‘error’ stage. We assume a one-to-one relationship be-
tween the incident faults and the errors. Other relationships
are possible, depending on the transient fault duration and
the evidence required for conviction. Section 5.2 discusses
the relationship between transient fault duration and the ex-
ecution period of the Diagnosis protocol. We do not model
faults outside of the SPIDER MFA. Assumption coverage,
as defined by Powell [13], addresses these types of faults;
please see Section 7 for more details.
We examine three conviction policies: All Permanent,
All Transient, and Perfect. These policies represent ex-
treme points in the space of possible conviction policies,
and require only a single error for conviction. It may not be
possible to perfectly implement the ‘All Permanent’ and
‘Perfect’ strategies for two reasons. First, it may not be pos-
sible to diagnose the source of a fault, in which case the cor-
rectness property prohibits removing the faulty node from
membership. Second, it is impossible to distinguish tran-
siently faulty nodes from permanently faulty nodes in some
cases. A system can specify a duration ∆T, where faults that
persist longer than ∆T are considered permanent. However,
one could define a transient fault that persists longer than
∆T for any ∆T chosen, except for a ∆T of infinity, which
would be a permanent fault. The ‘All Transient’ strategy
takes no action, posing no obstacles for implementation.
• All Permanent (Treat All Faults as Permanent)
In this strategy, all faulty nodes are convicted, regardless
of whether the fault is permanent or transient. This strategy
equates to a ‘treat everything as permanently faulty’ strat-
egy. It represents the outcome if permanent fault tolerance
only is applied to a system with transient and permanent
faults. Note that SPIDER is not able to convict all faulty
nodes if correctness is guaranteed, since sometimes the
fault source cannot be determined. If completeness is pre-
served instead of correctness, this strategy is possible, but
good nodes may be convicted. In this study, we do not ex-
amine strategies where good nodes may be convicted.
• All Transient (No Action)
In this strategy, faulty nodes are never convicted. This
strategy is an inaction strategy. Faulty nodes are not re-
moved, as transient faults (per our definition) will disap-
pear after a finite duration with no lasting consequences. It
represents the outcome if transient fault tolerance only is