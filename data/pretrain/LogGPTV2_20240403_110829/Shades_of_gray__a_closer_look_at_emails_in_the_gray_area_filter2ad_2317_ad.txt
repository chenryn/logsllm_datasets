### 4. Commercial Email Campaigns

Commercial email campaigns, often referred to as "not spammers," operate within the boundaries of current legislation by providing a service for other companies to send marketing emails. These companies typically offer an online opt-out procedure, allowing users to unsubscribe from future communications. To avoid being blacklisted, they use a wide range of IP addresses to run their campaigns. Additionally, we observed that these campaigns often employ grouping methods based on similar subjects or URLs, and their behavior can change over time.

Despite the easily recognizable characteristics of these campaigns, users show a surprisingly high level of interest. This category has the highest number of email views per campaign, suggesting that users are often curious about products promoted and sold on the black market [18].

### 5. Scam and Phishing Campaigns

Scam and phishing campaigns involve fraudulent activities where fraudsters trick victims using threatening messages or promises of significant monetary gains. The characteristics of this category closely resemble those of commercial campaigns, making it difficult to automatically separate them without analyzing the email body. Most of these campaigns fall into the gray area of our classifier, necessitating manual verification. Content-based detection techniques, such as analyzing email addresses, phone numbers [12], and URLs [21, 29] in the email body, are more effective in identifying these threats.

We identified 12,601 such emails, with an average campaign size of 84 emails. Phishing campaigns often spoofed email addresses using well-known company names (e.g., banks, eBay, PayPal), while Nigerian scammers primarily used webmail accounts [12]. Many senders solved CAPTCHA challenges, indicating that real people were behind these scams. The IP addresses from which the CAPTCHAs were solved were mostly located in West African countries, such as Nigeria and Ivory Coast. None of the messages in this category included an Unsubscribe header.

Unfortunately, users frequently fell victim to these types of attacks, opening and even whitelisting messages in these campaigns.

### 6. User Behavior

Our dataset provides insights into user actions on quarantined emails, including reading, adding to a whitelist or blacklist, and solving CAPTCHAs. These data help us understand the ability of average users to identify suspicious emails.

Table 9 presents three user action statistics. As expected, user activity mainly involves legitimate and gray campaigns. Users primarily check this folder to spot missed notifications or undelivered benign messages. However, a significant number of users also opened spam messages, possibly attracted by deceptive subjects. As shown in Table 8 and Figure 5(a), the highest campaign viewing rates are produced by botnet-generated campaigns, surpassing even newsletters. Over 3,888 spam emails were viewed by users during our six-month experiments, resulting in one out of five users viewing at least one spam message, and on average, opening five of them [2].

After manually inspecting botnet-generated campaigns where emails were read and whitelisted, we confirmed that these campaigns were promoting illegal products, such as drugs and pirated software. This suggests that users may have difficulty distinguishing between legitimate and harmful emails, or some users may be genuinely interested in the products promoted by spammers. It is challenging to draw definitive conclusions, but it is clear that many users are unaware of the security risks involved in opening malicious emails.

To further measure the significance of this phenomenon, we calculated that there is a 0.36% probability that a user will whitelist a legitimate email and a 0.0005% probability that they will whitelist a spam message. While these numbers may seem low, they rapidly increase when multiplied by the number of users and the number of messages received. On average, 3.9 emails get whitelisted per legitimate campaign compared to 1.1 emails per spam campaign.

### 7. Unclustered Emails

Our campaign classification covers half of the emails in the quarantined area, with a 0.2% false positive rate. One may wonder about the remaining 50% that is left outside our clustering approach. Qian et al. [24] concluded that most legitimate emails should not be classifiable into clusters due to the content uniqueness generated by humans. Since most spam and legitimate emails were already filtered out from our dataset, the exact proportion may differ.

To approximate the content of the unclustered part, we assumed that legitimate campaign senders always rely on a stable hosting infrastructure. Using this technique, we found that 26% of the emails were sent from senders responsible for legitimate campaigns, and almost 40% were sent from webmail providers. The spam set had a very low number of matches in the unclustered set, which is expected since most of these emails are sent from compromised machines that change over time.

This heuristic can provide a rough approximation of what is inside the remaining 50% of the messages and can be used as part of a more complex system to automatically separate marketing campaigns from more dangerous forms of spam.

### 8. Discussion and Conclusions

In this paper, we presented a system to identify and classify campaigns of gray emails. We used the quarantined folder of a challenge-response antispam filter, which is already clean from obvious spam and ham messages. Our analysis revealed the most and least predictive email campaign class attributes. We also demonstrated that previous techniques used for email campaign classification [24] did not provide acceptable results in our settings, confirming that the gray area contains the hardest messages to classify.

Additionally, we confirmed and extended some findings of previous studies regarding botnet campaigns [21]. Our system can help understand how large commercial campaigns work, how they originate, and how they differ from other unsolicited emails. It could also serve as an input to automatically place marketing campaigns and newsletters in a separate folder, allowing users to clearly differentiate these messages from other forms of spam. After completing our study, a similar solution was deployed by Gmail [2], placing user newsletters, notifications, and other commercial emails into distinctive categories.

We found that our classification method based on sender behavior works well for any campaign except scam. Scam campaigns would benefit significantly from content-based email analysis, such as URL or email/phone clustering. Finally, we demonstrated that by using a graph-based refinement method, legitimate email campaigns can often be identified based only on sender information and categorized as newsletters or commercial advertisements. This is a promising result for the empirical study of legitimate bulk emails.

### 9. Acknowledgements

The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreement nr. 257007. We also thank MailInBlack for providing the data used in our study.

### 10. References

[1] CAN-SPAM Act: Controlling the Assault of Non-Solicited Pornography And Marketing Act of 2003.
[2] Inbox tabs and category labels. http://gmailblog.blogspot.fr/2013/05/a-new-inbox-that-puts-you-back-in.html.
[3] Directive 2002/58 on Privacy and Electronic Communications, concerning the processing of personal data and the protection of privacy in the electronic communications sector (Directive on privacy and electronic communications). , 2002.
[4] S. Banerjee and T. Pedersen. The design, implementation and use of the ngram statistics package. ITPCL, 2003.
[5] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008(10):P10008, 2008.
[6] M.-W. Chang, W.-T. Yih, and R. Mccann. Personalized spam filtering for gray mail. CEAS, 2008.
[7] D. Fallows. Spam: How it is hurting email and degrading life on the internet, 2003.
[8] Direct Marketing Association. Response Rate Report, 2012.
[9] D. M. A. DMA. Email deliverability review whitepaper, 2012.
[10] S. Hao, N. Syed, N. Feamster, A. Gray, and S. Krasser. Detecting spammers with SNARE: Spatio-temporal network-level automatic reputation engine. In Proc. of the 18th conference on USENIX security symposium, pages 101–118. USENIX Association, 2009.
[11] J. Isacenkova and D. Balzarotti. Measurement and evaluation of a real world deployment of a challenge-response spam filter. ACM SIGCOMM, IMC, 2011.
[12] J. Isacenkova, O. Thonnard, A. Costin, D. Balzarotti, and A. Francillion. Inside the scam jungle: A closer look at 419 scam email operations. IWCC, 2013.
[13] C. Kanich, C. Kreibich, K. Levchenko, B. Enright, G. M. Voelker, V. Paxson, and S. Savage. Mitigating spam using spatio-temporal reputation. Technical report, DTIC Document, 2010.
[14] P. Kiran and I. Atmosukarto. Spam or not spam–that is the question. Tech. rep., University of Washington, 2009.
[15] A. Kolcz and A. Chowdhury. Hardening fingerprinting by context. CEAS, 2007.
[16] F. Li and M. han Hsieh. An empirical study of clustering behavior of spammers and group-based anti-spam strategies. CEAS, 2006.
[17] MAAWG. Email Security Awareness and Usage Report, 2012.
[18] D. McCoy, A. Pitsillidis, G. Jordan, N. Weaver, C. Kreibich, B. Krebs, G. M. Voelker, S. Savage, and K. Levchenko. Pharmaleaks: Understanding the business of online pharmaceutical affiliate programs. USENIX, 2012.
[19] K. Onarlioglu, U. O. Yilmaz, D. Balzarotti, and E. Kirda. Insights into user behavior in dealing with internet attacks. NDSS, 2012.
[20] A. Pathak, Y. Hu, and Z. Mao. Peeking into spammer behavior from a unique vantage point. In Proc. of the 1st Usenix Workshop on Large-Scale Exploits and Emergent Threats, pages 1–9. USENIX Association, 2008.
[21] A. Pathak, F. Qian, Y. C. Hu, Z. M. Mao, and S. Ranjan. Botnet spam campaigns can be long lasting: Evidence, implications, and analysis. SIGMETRICS, 2009.
[22] A. Pitsillidis, C. Kanich, G. M. Voelker, K. Levchenko, and S. Savage. Taster’s choice: a comparative analysis of spam feeds. IMC, 2012.
[23] A. Pitsillidis, K. Levchenko, C. Kreibich, C. Kanich, G. M. Voelker, V. Paxson, N. Weaver, and S. Savage. Botnet judo: Fighting spam with itself. NDSS, 2010.
[24] F. Qian, A. Pathak, Y. C. Hu, Z. M. Mao, and Y. Xie. A case for unsupervised-learning-based spam filtering. SIGMETRICS, 2010.
[25] Z. Qian, Z. M. Mao, Y. Xie, and F. Yu. On network-level clusters for spam detection. In NDSS, 2010.
[26] A. Ramachandran and N. Feamster. Understanding the network-level behavior of spammers. In ACM SIGCOMM Computer Communication Review, volume 36, pages 291–302. ACM, 2006.
[27] A. Ramachandran, N. Feamster, and S. Vempala. Filtering spam with behavioral blacklisting. In Proc. of the 14th ACM conference on computer and communications security, pages 342–351. ACM, 2007.
[28] Return Path. Email Intelligence Report, Q3 2012.
[29] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song. Design and evaluation of a real-time URL spam filtering service. IEEE Symposium on Security and Privacy, 2011.
[30] A. G. West, A. J. Aviv, J. Chang, and I. Lee. Improving spam filtering by detecting gray mail. CEAS, 2007.
[31] W.-t. Yih, R. McCann, and A. Kolcz. Spam decisions on gray e-mail using personalized ontologies. SAC, 2009.