not spammers”, and that they just provide to other compa-
nies a way to send marketing emails within the boundaries
of the current legislation. In fact, they also oﬀer an online
procedure for users to opt-out and be removed from future
communications. These companies also use wide IP address
ranges to run the campaigns, probably to avoid being black-
listed. Moreover, we ﬁnd quite interesting that some of these
384grouping methods (similar subject vs. URLs), or to changes
in the behavior of spammers over time.
Despite the easily recognizable characteristics of these cam-
paigns, users show a surprisingly high interest in these emails.
This category has the highest number of email views per
campaign, suggesting that users are often curious about
products promoted and sold on the black market [18].
5.4 Scam and Phishing Campaigns
These campaigns contain phishing and Nigerian scam emails.
Fraudsters trick their victims using threatening messages
or by trying to seduce them with huge monetary gains.
The characteristics of this category largely resemble those
of commercial campaigns, thus making it diﬃcult to auto-
matically separate these campaigns without analyzing the
email body. In fact, most of these campaigns belong to the
gray area of our classiﬁer. This is the reason why we needed
to verify this set manually. These kind of threats are more
likely to be identiﬁed by content-based detection techniques,
e.g., by looking at email addresses and phone numbers [12],
or URL [21, 29] included in the body.
We found only 12,601 of such emails, with an average cam-
paign size of 84 emails. Phishing campaigns often spoofed
the email addresses using well known company names (e.g.
banks, eBay, Paypal), whereas Nigerian scammers relied
mostly on webmail accounts [12]. In this case, many senders
solved the CAPTCHA challenge – conﬁrming that there is
usually a real person behind these kinds of scams. The
IP addresses from where the CAPTCHAs were solved are
mostly located in West-African countries,
like Nigeria or
Ivory Coast. None of the messages in this category include
an Unsubscribe header.
Unfortunately, users seemed to often fall victims to this
type of attack, as they opened and even whitelisted messages
in these campaigns.
6. USER BEHAVIOR
Our dataset also provides information about which actions
were performed by the users on the quarantined emails. In
particular, we collected information regarding the messages
that were read, added to a user whitelist or blacklist, and the
CAPTCHA that was later solved by the sender. These data
can give us some useful insights on the ability of average
users to identify suspicious emails.
Table 9 presents three user action statistics. As expected,
user activity involves mainly legitimate and gray campaigns.
In fact, the main reason for users to go through the emails
in this folder is to spot missed notiﬁcations or undelivered
benign messages. However, a large fraction of users also
opened spam messages, maybe attracted by some deceiving
subjects. As shown in Table 8 and Figure 5 (a), the highest
campaign viewing rates are produced by botnet-generated
campaigns, overpassing even newsletters. Over 3,888 spam
emails were viewed by users during our six-month experi-
ments, resulting in the fact that one out of ﬁve users has
viewed at least one spam message, and, on average, opened
5 of them 2.
After a manual inspection of botnet-generated campaigns
where the emails were read and whitelisted, we conﬁrmed
that those campaigns were promoting illegal products, e.g.
2Unfortunately, from our dataset we are unable to tell how
many users downloaded attachments or followed links in-
cluded in the message body.
Figure 4: Email campaign classes distribution
30% of the total campaigns with an average size of 90 emails
each.
A manual inspection seems to conﬁrm that these cam-
paigns consist mainly of notiﬁcations and newsletters sent
by online services to which users have subscribed in the past.
The senders are geographically localized (we encountered
only one exception of a distributed newsletter campaign)
and have extremely consistent sending patterns. Since we
cluster campaigns based on their subjects, newsletters tend
to last for very short periods of time. In addition, they nor-
mally use valid email recipient lists, and exhibit the lowest
IP address, country, and sender email address variations.
Only the use of the Unsubscribe header seems inconsistent,
as only 39% of emails use it. However, this can be explained
by the fact that notiﬁcation emails normally do not use this
header - only newsletters are subject to optional subscrip-
tion. The consistent patterns in the email headers of this
category indicate that the senders are making an eﬀort to
build a reputation and successfully deliver their correspon-
dence. Not surprisingly, this is also the category that is
whitelisted most often by the users.
5.3 Botnet-Generated Campaigns
Unsurprisingly, Table 8 shows that botnet-generated cam-
paigns have highly dynamic attribute values, making them
the easiest category to identify automatically. This category
contains clusters that accounts for only 17% of all campaigns
(also because most of the spam emails were already excluded
from the gray emails by other antispam ﬁlters). Botnet cam-
paigns have the highest geographical distribution as they
are sent by infected computers from all over the world: 172
unique /24 networks per campaign, spread on average over
28 countries. Another prevalent characteristic is the use of
multiple recipient emails sent using unveriﬁed email lists.
Consequently, this leads to the highest email rejection rates
(24%), and highest bounced CAPTCHA requests. The Un-
subscribe header is rarely used, and sender email addresses
have low similarities.
On average, botnet campaigns are the ones lasting the
longest, with one drug-related campaign sent slowly over
the entire six-months period of our experiments. Pathak
et al. [21] also studied the length of spam campaigns, re-
porting a maximum length of 99 days over a dataset span-
ning 150 days. Our campaigns are substantially longer than
that, maybe due to diﬀerent datasets (we collected directly
from user mail servers, not from open-relays), diﬀerent email
385Table 9: User actions performed on campaigns
Legitimate
Spam
Gray
Viewed Whitelisted CAPTCHA solved
3.5%
0.2%
10%
42%
25%
40%
12%
6%
17%
drugs and pirated software. This may suggest two things: ei-
ther users have problems in distinguishing legitimate emails
from harmful, or some users are genuinely interested in the
products promoted by spammers. It is diﬃcult to draw con-
clusions as both hypotheses might be true for diﬀerent users,
but, clearly, most of them are unaware of the security threats
involved in opening malicious emails.
Meanwhile, we should compare the reported statistics of
viewed emails with the number of emails that actually got
whitelisted – an action that could be interpreted as the
equivalent of clicking the “Not Spam” button provided by
several webmail services. The number of whitelisted emails
per botnet-generated campaign (1.26 emails, Table 8) is the
lowest among all the categories, suggesting that most users
successfully diﬀerentiate them. However, we notice that
scam/phishing campaigns have almost the same number of
emails being whitelisted per campaign as commercial cam-
paigns (2.25 vs 2.9). This suggests that users might have
diﬃculties in diﬀerentiating these categories.
It is impor-
tant to remember that this category was manually sampled
by domain experts, which is not the case for the typical users
as most of them are untrained and are more likely to fall for
these kind of fraud.
To further measure how signiﬁcant this phenomenon is, we
compute that there is a 0.36% probability that a certain user
whitelists a legitimate email and 0.0005% that she whitelists
a spam message. These numbers may seem low, but they
rapidly increase when multiplied by the number of users and
the number of messages received. In total, an average of 3.9
emails get whitelisted per legitimate campaign compared to
1.1 emails per spam campaign.
The last question we want to answer is whether the fact
that the senders solve some CAPTCHAs in a campaign
could be a good indicator of its legitimacy. Unfortunately,
it is not and for two reasons. First, most of the legitimate
campaign senders are automated tools, since a large potion
of gray emails consists of newsletters, online notiﬁcations,
and marketing emails. Secondly, although the general ten-
dency is that users solve more CAPTCHAs within legitimate
classes (Figure 5 (b)), as shown in Table 8, also scam and
phishing campaigns have high CAPTCHA solved rates (7.6)
compare with other categories. Finally, the rare cases of
botnet-generated campaigns solving few CAPTCHAs corre-
spond to challenges delivered to spoofed addresses by spam-
mers as previously described by Isacenkova et al. [11].
To conclude, user-generated actions on gray emails are er-
roneous and thus are inaccurate to use for prediction. They
often open even potentially dangerous emails, ignoring secu-
rity risks. These results are in line to what has been tested
in a user study conducted by Onarlioglu et al. [19].
7. UNCLUSTERED EMAILS
Our campaign classiﬁcation covers half of the emails in the
quarantined area, with 0.2% false positive rate. One may
wonder what is inside the remaining 50% that is left outside
our clustering approach. Qian et al. [24] concluded that
the majority of legitimate emails should not be classiﬁable
(a) Viewed emails
(b) CAPTCHAs solved
Figure 5: Number of user actions taken per campaign
into clusters because of the content uniqueness generated by
humans. Additionally, since most of the spam and legitimate
emails were already ﬁltered out from our dataset, the exact
proportion may be diﬀerent.
We could try to approximate the content of the unclus-
tered part by assuming that the legitimate campaign senders
always rely on a stable hosting infrastructure (as described
in Section 3.4). In this case, for every legitimate campaign
we can try to ﬁnd messages sent by the same subnetwork
and domain name in the unclassiﬁed email set. Using this
technique, we found that 26% of the emails were sent from
senders that were also responsible for legitimate campaigns.
Almost 40% were sent from webmail providers. The spam
set had a very low number of matches in the unclustered set,
which is expected since most of these emails are sent from
compromised machines that change over time.
Even though this heuristic can only provide a rough ap-
proximation of what is inside the remaining 50% of the mes-
sages, it can still be used (as part of a more complex system)
to automatically separate marketing campaigns from more
dangerous forms of spam.
8. DISCUSSION AND CONCLUSIONS
In this paper we presented a system to identify and clas-
sify campaigns of gray emails. As an approximation of this
set, we chose to use the quarantined folder of a challenge-
response antispam ﬁlter, since it is already clean from obvi-
ous spam and ham messages.
Our analysis unveiled the most and the least predictive
email campaign class attributes. We also demonstrated that
previous techniques used for email campaign classiﬁcation [24]
did not provide acceptable results in our settings, conﬁrming
that the gray area contains the hardest messages to classify.
Additionally, we conﬁrmed and extended some of the ﬁnd-
ings of previous studies regarding botnet campaigns [21].
Our system could be used in diﬀerent ways. First of all,
it can help understanding how large commercial campaigns
work, how they originate, and how they diﬀer from other
unsolicited emails. It could also serve as an input to auto-
matically place marketing campaigns and newsletters in a
separate folder, so that users can clearly diﬀerentiate these
messages from other forms of spam. In fact, the users in our
study often opened botnet-generated emails and were espe-
cially prone to errors when dealing with scam and phishing
messages; we believe that a separate folder dedicated to le-
gitimate bulk emails would create an extra layer between
the users and the malicious messages, thus allowing users
to focus on the bulk folder when looking for missing and
misclassiﬁed emails.
Interestingly, after we completed our
386study, a similar solution was deployed by GMail [2], to place
user newsletters, notiﬁcations, and other commercial email
into distinctive categories.
We also found out that our classiﬁcation method based on
sender behavior works well for any campaign except scam.
We believe that the latter would beneﬁt largely from content-
based email analysis, e.g. URL or emails/phones clustering.
Finally, we demonstrated that by using a graph-based re-
ﬁnement method, legitimate email campaigns can often be
identiﬁed based only on sender information, and can be cate-
gorized as newsletters or commercial advertisement. This is
a particularly promising result in the direction of empirical
study of legitimate bulk emails.
9. ACKNOWLEDGEMENTS
The research leading to these results has received funding
from the European Union Seventh Framework Programme
(FP7/2007-2013) under grant agreement nr. 257007. We
also thank MailInBlack for providing the data that was used
in our study.
10. REFERENCES
[1] CAN-SPAM Act: Controlling the Assault of
Non-Solicited Pornography And Marketing Act of
2003.
[2] Inbox tabs and category labels.
http://gmailblog.blogspot.fr/2013/05/
a-new-inbox-that-puts-you-back-in.html.
[3] Directive 2002/58 on Privacy and Electronic
Communications, concerning the processing of
personal data and the protection of privacy in the
electronic communications sector (Directive on privacy
and electronic communications). , 2002.
[4] S. Banerjee and T. Pedersen. The design,
implementation and use of the ngram statistics
package. ITPCL, 2003.
[5] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and
E. Lefebvre. Fast unfolding of communities in large
networks. Journal of Statistical Mechanics: Theory
and Experiment, 2008(10):P10008, 2008.
[6] M.-W. Chang, W.-T. Yih, and R. Mccann.
Personalized spam ﬁltering for gray mail. CEAS, 2008.
[7] D. Fallows. Spam: How it is hurting email and
degrading life on the internet, 2003.
Spamalytics: An empirical analysis of spam marketing
conversion. CCS, 2008.
[14] P. Kiran and I. Atmosukarto. Spam or not spam–that
is the question. Tech. rep., University of Washington,
2009.
[15] A. Kolcz and A. Chowdhury. Hardening ﬁngerprinting
by context. CEAS, 2007.
[16] F. Li and M. han Hsieh. An empirical study of
clustering behavior of spammers and groupbased
anti-spam strategies. CEAS, 2006.
[17] MAAWG. Email Security Awareness and Usage
Report, 2012.
[18] D. McCoy, A. Pitsillidis, G. Jordan, N. Weaver,
C. Kreibich, B. Krebs, G. M. Voelker, S. Savage, and
K. Levchenko. Pharmaleaks: Understanding the
business of online pharmaceutical aﬃliate programs.
USENIX, 2012.
[19] K. Onarlioglu, U. O. Yilmaz, D. Balzarotti, and
E. Kirda. Insights into user behavior in dealing with
internet attacks. NDSS, 2012.
[20] A. Pathak, Y. Hu, and Z. Mao. Peeking into spammer
behavior from a unique vantage point. In Proc. of the
1st Usenix Workshop on Large-Scale Exploits and
Emergent Threats, pages 1–9. USENIX Association,
2008.
[21] A. Pathak, F. Qian, Y. C. Hu, Z. M. Mao, and
S. Ranjan. Botnet spam campaigns can be long
lasting: Evidence, implications, and analysis.
SIGMETRICS, 2009.
[22] A. Pitsillidis, C. Kanich, G. M. Voelker,
K. Levchenko, and S. Savage. Taster’s choice: a
comparative analysis of spam feeds. IMC, 2012.
[23] A. Pitsillidis, K. Levchenko, C. Kreibich, C. Kanich,
G. M. Voelker, V. Paxson, N. Weaver, and S. Savage.
Botnet judo: Fighting spam with itself. NDSS, 2010.
[24] F. Qian, A. Pathak, Y. C. Hu, Z. M. Mao, and Y. Xie.
A case for unsupervised-learning-based spam ﬁltering.
SIGMETRICS, 2010.
[25] Z. Qian, Z. M. Mao, Y. Xie, and F. Yu. On
network-level clusters for spam detection. In NDSS,
2010.
[26] A. Ramachandran and N. Feamster. Understanding
the network-level behavior of spammers. In ACM
SIGCOMM Computer Communication Review,
volume 36, pages 291–302. ACM, 2006.
[8] Direct Marketing Association. Response Rate Report,
[27] A. Ramachandran, N. Feamster, and S. Vempala.
2012.
[9] D. M. A. DMA. Email deliverability review
whitepaper, 2012.
[10] S. Hao, N. Syed, N. Feamster, A. Gray, and S. Krasser.
Detecting spammers with SNARE: Spatio-temporal
network-level automatic reputation engine. In Proc. of
the 18th conference on USENIX security symposium,
pages 101–118. USENIX Association, 2009.
Filtering spam with behavioral blacklisting. In Proc.
of the 14th ACM conference on computer and
communications security, pages 342–351. ACM, 2007.
[28] Return Path. Email Intelligence Report, Q3 2012.
[29] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song.
Design and evaluation of a real-time url spam ﬁltering
service. IEEE Symposium on Security and Privacy,
2011.
[11] J. Isacenkova and D. Balzarotti. Measurement and
[30] A. G. West, A. J. Aviv, J. Chang, and I. Lee.
evaluation of a real world deployment of a
challenge-response spam ﬁlter. ACM SIGCOMM,
IMC, 2011.
[12] J. Isacenkova, O. Thonnard, A. Costin, D. Balzarotti,
and A. Francillion. Inside the scam jungle: A closer
look at 419 scam email operations. IWCC, 2013.
[13] C. Kanich, C. Kreibich, K. Levchenko, B. Enright,
G. M. Voelker, V. Paxson, and S. Savage.
Mitigating spam using spatio-temporal reputation.
Technical report, DTIC Document, 2010.
[31] W.-t. Yih, R. McCann, and A. Kolcz. Improving spam
ﬁltering by detecting gray mail. CEAS, 2007.
[32] S. Youn and D. McLeod. Spam decisions on gray
e-mail using personalized ontologies. SAC, 2009.
387