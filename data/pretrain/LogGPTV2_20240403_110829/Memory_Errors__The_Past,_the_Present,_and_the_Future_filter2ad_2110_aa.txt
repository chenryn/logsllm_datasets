title:Memory Errors: The Past, the Present, and the Future
author:Victor van der Veen and
Nitish dutt-Sharma and
Lorenzo Cavallaro and
Herbert Bos
Memory Errors:
The Past, the Present, and the Future(cid:63)
Victor van der Veen1, Nitish dutt-Sharma1, Lorenzo Cavallaro1,2, and
Herbert Bos1
1 The Network Institute, VU University Amsterdam
2 Royal Holloway, University of London
Abstract. Memory error exploitations have been around for over 25
years and still rank among the top 3 most dangerous software errors.
Why haven’t we been able to stop them? Given the host of security
measures on modern machines, are we less vulnerable than before, and
can we expect to eradicate memory error problems in the near future?
In this paper, we present a quarter century worth of memory errors:
attacks, defenses, and statistics. A historical overview provides insights
in past trends and developments, while an investigation of real-world
vulnerabilities and exploits allows us to answer on the signiﬁcance of
memory errors in the foreseeable future.
1
Introduction
Memory errors in C and C++ programs are among the oldest classes of soft-
ware vulnerabilities. To date, the research community has proposed and de-
veloped a number of diﬀerent approaches to eradicate or mitigate memory er-
rors and their exploitation. From safe languages, which remove the vulnera-
bility entirely [53,72], and bounds checkers, which check for out-of-bounds ac-
cesses [3,54,82,111], to countermeasures that prevent certain memory locations
to be overwritten [25,29], detect code injections at early stages [80], or prevent
attackers from ﬁnding [11,98], using [8,56], or executing [32,70] injected code.
Despite more than two decades of independent, academic, and industry-
related research, such ﬂaws still undermine the security of our systems. Even
if we consider only classic buﬀer overﬂows, this class of memory errors has been
lodged in the top-3 of the CWE SANS top 25 most dangerous software errors
for years [85]. Experience shows that attackers, motivated nowadays by proﬁt
rather than fun [97], have been eﬀective at ﬁnding ways to circumvent protec-
tive measures [39,83]. Many attacks today start with a memory corruption that
provides an initial foothold for further infection.
Even so, it is unclear how much of a threat these attacks remain if all our
defenses are up. In two separate discussions among PC members in two of 2011’s
top-tier venues in security, one expert suggested that the problem is mostly
(cid:63) This work was partially sponsored by the EU FP7 SysSec project and by an ERC
Starting Grant project (“Rosetta”).
solved as “dozens of commercial solutions exist” and research should focus on
other problems, while another questioned the usefulness of the research eﬀorts,
as they clearly “could not solve the problem”. So which is it? The question of
whether or not memory errors remain a signiﬁcant threat in need of renewed
research eﬀorts is important and the main motivation behind our work.
To answer it, we study the memory error arms-race and its evolution in de-
tail. Our study strives to be both comprehensive and succinct to allow for a quick
but precise look-up of speciﬁc vulnerabilities, exploitation techniques or counter-
measures. It consolidates our knowledge about memory corruption to help the
community focus on the most important problems. To understand whether mem-
ory errors remain a threat in the foreseeable future, we back up our investigation
with an analysis of statistics and real-life evidence. While some papers already
provide descriptions of memory error vulnerabilities and countermeasures [110],
we provide the reader with a comprehensive bird-eye view and analysis on the
matter. This paper strives to be the reference on memory errors.
To this end, we ﬁrst present (Section 2) an overview of the most important
studies on and organizational responses to memory errors: the ﬁrst public discus-
sion of buﬀer overﬂows in the 70s, the establishment of CERTs, Bugtraq, and the
main techniques and countermeasures. Like Miller et al. [68], we use a compact
timeline to drive our discussion, but categorize events in a more structured way,
based on a branched timeline.
Second, we present a study of memory errors statistics, analyzing vulnera-
bilities and exploit occurrences over the past 15 years (Section 3). Interestingly,
the data show important ﬂuctuations in the number of reported memory error
vulnerabilities. Speciﬁcally, vulnerability reports have been dropping since 2007,
even though the number of exploits shows no such trend. A tentative conclusion
is that memory errors are unlikely to lose much signiﬁcance in the near future
and that perhaps it is time adopt a diﬀerent mindset, where a number of related
research areas are explored, as suggested in Section 4. We conclude in Section 5.
2 A High Level View of Memory Error History
The core history of memory errors, their exploitations, and main defenses tech-
niques can be summarized by the branched timeline of Figure 1.
Memory errors were ﬁrst publicly discussed in 1972 by the Computer Security
Technology Planning Study Panel [5]. However, it was only after more than a
decade that this concept was further developed. On November the 2nd, 1988,
the Internet Worm developed by Robert T. Morris abruptly brought down the
Internet [86]. The worm exploited a buﬀer overﬂow vulnerability in fingerd.
In reaction to this catastrophic breach, the Computer Emergency Response
Team Coordination Center (CERT/CC) was then formed [22]. CERT/CC’s main
goal was to collect user reports about vulnerabilities and forward them to ven-
dors, who would then take the appropriate action.
In response to the lack of useful information about security vulnerabilities,
Scott Chasin started the Bugtraq mailing list in November 1993. At that time,
e
n
i
l
e
m
i
t
l
a
r
e
n
e
G
:
1
.
g
i
F
many considered the CERT/CC of limited use, as it could take years before
vendors released essential patches. In contrast, Bugtraq oﬀered an eﬀective tool to
publicly discuss on the subject, without relying on vendors’ responsiveness [88].
In 1995, Thomas Lopatic boosted the interest in memory errors by describing
a step-by-step exploitation of an error in the NCSA HTTP daemon [63]. Shortly
after, Peiter Zatko (Mudge) released a private note on how to exploit the now
classic memory error: stack-based buﬀer overﬂows [112]. So far, nobody really
discussed memory error countermeasures, but after Mudge’s notes and the well-
known document by Elias Levy (Aleph One) on stack smashing [4], discussions
on memory errors and protection mechanisms proliferated.
The introduction of the non-executable (NX) stack opened a new direction in
the attack-defense arms-race as the ﬁrst countermeasure to address speciﬁcally
code injection attacks in stack-based buﬀer overﬂows. Alexander Peslyak (Solar
Designer) released a ﬁrst implementation of an NX-like system, StackPatch [34],
in April 1997. We discuss NX in Section 2.1.
A few months later, in January 1998, Cowan et al. proposed placing speciﬁc
patterns (canaries) between stack variables and a function’s return address to
detect corruptions of the latter [29]. Further details are discussed in Section 2.2.
After the ﬁrst stack-based countermeasures, researchers started exploring
other areas of the process address space—speciﬁcally the heap. In early 1999,
Matt Conover and the w00w00 security team were the ﬁrst to describe heap
overﬂow exploitations [27], which we discuss in Section 2.3.
On September 20, 1999, Tymm Twillman introduced format string attacks
by posting an exploit against ProFTPD on Bugtraq [101]. Format string exploits
became popular in the next few years and we discuss them in Section 2.4.
The idea of adding randomness to prevent exploits from working (e.g., in
StackGuard) was brought to a new level with the introduction of Address Space
Layout Randomization (ASLR) by the PaX Team in July 2001. We discuss the
various types of ASLR and its related attacks in Section 2.5.
Around the same time as the introduction of ASLR, another type of vul-
nerability, NULL pointer dereference, a form of dangling pointer, was disclosed
in May 2001. Many assumed that such dangling pointers were unlikely to cause
more harm than a simple denial of service attacks. In 2007 and 2008, however,
Afek and Sharabani and Mark Dowd showed that these vulnerabilities could very
well be used for arbitrary code injection as well [1,37]. Unfortunately, speciﬁc
defenses against dangling pointers are still mostly research-driven eﬀorts [2].
Due to space limitations, a number of historical details were omitted in this
paper. The interested reader can refer to [102] for more information.
2.1 Non-Executable Stack
Stack-based buﬀer overﬂows are probably the best-known memory error vulner-
abilities [4]. They occur when a stack buﬀer overﬂows and overwrites adjacent
memory regions. The most common way to exploit them is to write past the
end of the buﬀer until the function’s return address is reached. The corruption
of this code pointer (making it point to the buﬀer itself, partially ﬁlled with
attacker-injected code) allows the execution of arbitrary code when the function
returns. A non-executable stack prevents such attacks by marking bytes of the
stack as non-executable. Any attempt to execute the injected code triggers a
program crash. The ﬁrst non-executable stack countermeasure was proposed by
Alexander Peslyak (Solar Designer) in June 1997 for the Linux kernel [34].
Just a few months after introducing the patch, Solar Designer himself de-
scribed a novel attack that allows attackers to bypass a non-executable stack [33].
Rather than returning to code located on the stack, the exploit crafts a fake call
stack mainly made of libraries’ function addresses and arguments. Returning
from the vulnerable function has the eﬀect of diverting the execution to the li-
brary function. While any dynamically linked library can be the target of this
diversion, the attack is dubbed return-into-libc because the return address is typ-
ically replaced with the address of proper C library functions (and arguments).
An enhancement of Solar Designer’s non-executable stack was quickly pro-
posed to withstand return-into-libc attacks [33]. However, shortly thereafter,
Rafal Wojtczuk (Nergal) circumvented Solar Designer’s reﬁnement by taking ad-
vantage of speciﬁc ELF mechanisms (i.e., dynamic libraries, likely omnipresent
functions, and dynamic libraries’ function invocation via PLT) [73]. McDon-
ald [66] built on such results and proposed return-into-libc as a ﬁrst stage loader
to run the injected code in a non-executable segment.
The PaX Team went far beyond a non-executable stack solution. With the
PaX project released in the year 2000 [99], they oﬀered a general protection
against the execution of code injected in data segments. PaX prevents code exe-
cution on all data pages and adds additional measures to make return-into-libc
much harder. Under PaX, data pages can be writable, but not executable, while
code pages are marked executable but not writable. Most current processors
have hardware support for the NX (non-executable) bit and if present, PaX will
use it. In case the CPU lacks this feature, PaX can emulate it in software. In
addition, PaX randomizes the mmap base so that both the process’ stack and
the ﬁrst loaded library will be mapped at a random location, representing the
ﬁrst form of address space layout randomization (Section 2.5).
One of the ﬁrst attacks against PaX ASLR was published by Nergal [73] in
December, 2001. He introduced advanced return-into-libc attacks and exposed
several weaknesses of the mmap base randomization. He showed that it is easy
to obtain the addresses of libraries and stack from the Linux proc ﬁle system for
a local exploit. Moreover, if the attacker can provide the payload from I/O pipes
rather than the environment or arguments, then the program is exploitable.
OpenBSD version 3.3, released in May 2003, featured various memory error
mitigation techniques. Among these, WˆX proved to be eﬀective against code-
injection attacks. As a memory page can either be writable or executable, but
never be both, injected code had no chances to get executed anymore.
In August 2005, Microsoft released the Service Pack 2 (SP2) of the Windows XP
OS, featuring Data Execution Protection (DEP)—which prevents code execution
of a program data memory [70].
By this time all major OSes were picking up on memory error mitigation
techniques. NX stack was considered a strong protection against code-injection
attacks and vendors soon backed up software implementations by hardware
support for non-executable data. However, techniques like return-into-libc soon
showed how NX can only partially mitigate memory errors from being exploited.
In 2005, Krahmer [58] pioneered short code snippet reuse instead of entire
libc functions for exploit functionality—a direction that reached its zenith in
return-oriented programming (ROP). Attackers chain code snippets together to
create gadgets that perform predetermined but arbitrary computations [83]. The
chaining works by placing short sequences of data on the stack that drive the
ﬂow of the program whenever a call/return-like instruction executes.
To date, no ROP-speciﬁc countermeasures have seen deployment in main-
stream OSes. Conversely, low-overhead bounds checkers [3,111] and practical
taint-tracking [16] may be viable solutions to defeat control-hijacking attacks.
2.2 Canary-based Protections
Canaries represent a ﬁrst line of defense to hamper classic buﬀer overﬂow attacks.
The idea is to use hard-to-predict patterns to guard control-ﬂow data. The ﬁrst of
such systems, StackGuard, was released on January 29, 1999 [29]. When entering
a function, StackGuard places a hard-to-predict pattern—the canary—adjacent
to the function’s return address on the stack. Upon function termination, it
compares the pattern against a copy. Any discrepancies would likely be caused
by buﬀer overﬂow attacks on the return address and lead to program termination.
StackGuard assumed that corruption of the return address only happens