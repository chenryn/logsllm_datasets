Fuzzer, logical structure of, 29–30
Fuzzer classification via interface, 162–165
APIs, 164
client-side fuzzers, 164–165
files, 163–164
layer 2 through 7 fuzzing, 165
local program, 162
network interfaces, 162
web fuzzing, 164
Fuzzer comparison, 221–248
bugs, 230–231
closer look at the results, 234–241
evaluating fuzzers, 224–226
fuzzing life cycle, 221–223
general conclusions, 241–247
introducing the fuzzers, 226–229
results, 231–234
targets, 229
Fuzzers, 24
Fuzzers, building and classifying. See Building
and classifying fuzzers
Fuzzers, evaluating, 224–226
caveats, 226
code coverage, 225–226
Index
281
Fuzzers, evaluating (cont.)
retrospective testing, 224–225
simulated vulnerability discovery, 225
Fuzzers, introducing, 226–229
application-specific fuzzers, 229
beSTORM, 228–229
Codenomicon, 228
General Purpose Fuzzer (GPF), 226–227
Mu-4000, 228
ProxyFuzz, 227
The Art of Fuzzing (TAOF), 227
Fuzzer testing results, 231–234
DNS, 233–234, 240–241
FTP, 232–233, 234–237
SNMP, 233, 237–240
Fuzzer types, 26–29, 145–162
capture-replay, 150
fuzzing libraries: frameworks, 146–148
generic fuzzers, 149–150
in-memory fuzzing, 161–162
next-generation fuzzing frameworks: Sulley,
159–161
protocol-specific fuzzers, 148–149
single-use fuzzers, 145–146
Fuzzing, 22–33
defined, 1
as distinct testing method, 14
fuzzer types, 26–29
fuzzing and the enterprise, 32–33
fuzzing frameworks and test suites, 31
fuzzing overview, 24–25
fuzzing process, 30–31
goal of, 25
history of fuzzing, 22–24
local structures of a fuzzer, 29–30
vulnerabilities found with fuzzing, 25–26
Fuzzing: Brute Force Vulnerability Discovery
(Sutton, Green, and Amini), 159, 179
Fuzzing case studies, 249–274
application developer fuzzing, 259–263
black-box fuzzing for security researchers,
267–273
carrier and service provider fuzzing, 255–259
enterprise fuzzing, 250–255
industrial automation fuzzing, 265–267
network equipment manufacturer fuzzing,
263–265
Fuzzing frameworks and test suites, 31
Fuzzing libraries: frameworks, 146–148
Fuzzing life cycle, 221–223
exception analysis, 223
identifying interfaces, 221
input generation, 222
report, 223
sending inputs to the target, 222–223
target monitoring, 223
Fuzzing methods, 137–135
and bug hunting, 59–63
fuzzing vectors, 141–142
intelligent fuzzing, 142–144
intelligent versus dumb (nonintelligent) fuzzers,
144
paradigm split: random or deterministic
fuzzing, 138–140
source of fuzz data, 140–141
white-box, black-box, and gray-box fuzzing,
144–145
Fuzzing metrics, 99–136
defect metrics and security, 120–133
test automation for security, 133–134
threat analysis and risk-based testing, 103–107
transition to proactive security, 107–120
Fuzzing process, 30–31
Fuzzing targets, categories of, 249–250
applications (Web, VoIP, mobile), 250
client software, 250
middleware, 249
proxy or gateway software, 250
server software, 249
Fuzzing vectors, 141–142
Fuzzled, 148
Fuzz testing as a profession, 84–86
QA leader, 86
QA technical leader, 86
test automation engineer, 86
test engineer/designer, 86
Gateway software, 250
General conclusions, 241–247
does code coverage predict bug finding?,
244–246
generational-based approach is superior, 242
how long to run fuzzers with random elements,
246–247
initial test cases matter, 242–243
protocol knowledge, 243–244
random fuzzers find easy bugs first, 247
real bugs, 244
the more fuzzers, the better, 242
General Purpose Fuzzer (GPF), 139–140,
156–159, 226–227
Generational-based approach, 242, 246
282
Index
Generic fuzzers, 149–150
FileFuzz, 150
ProxyFuzz, 149
Golden FTP (GFTP) server, 215, 217–218
GPF + PaiMei + Jpgraph = EFS, 206
Gray-box fuzzer, 128
Graphical User Interface (GUI), 7, 84, 126, 127
Gray-box testing, 21, 24, 80, 145
Greene, Adam, 159, 179
Guard Malloc, 180–181, 183, 187–188,
192–193
Guruswamy, 132
Hackers, 1–2, 5, 12, 37–40, 101
Hardware overflow protection, 65–66
hardware DEP, 66
secure bit, 65
Heap overflow, 48
Heap variable overwrite, 48–49
Holcombe, M., 204
Hostile data, 60–62
Howard, Michael, 224
ikefuzz, 148–149
Implementation, 20–21
errors, 35
Implementation under test (IUT), 17, 84
Industrial automation fuzzing, 265–267
Industrial networks, 9
Information technology (IT) security, 41–42
Initial test cases, 242–243
In-memory fuzzing, 161–162
Input generation, 222
Input source, 60
Input space, 60
coverage, 89
coverage metrics, 127–130
Input verification, 64–65
Insure++, 183, 189–190, 194–195
Intangibles cost, 117
Integer errors, 46–47
Integrity, 13, 103
Intelligent fuzzing, 142–144
Intelligent versus dumb (nonintelligent) fuzzers,
144
Interface coverage, 89
metrics, 127
Interfaces
identifying, 221
to a system, 84
Internally built fuzzers, 109, 111, 112
Internet Explorer, 260
Internet Key Exchange (IKE) fuzzer, 112, 143
Interoperability testing, 18, 87
Intrusion Detection System (IDS), 11
Intrusion Prevention System (IPS), 11
IP Stack Integrity Checker (ISIC), 165
JavaScript, 8, 52, 261
Kaksonen, Ravli, 94
Known vulnerability density, 130, 131
Layer 2 through 7 fuzzing, 165
Legs, 207
Library, 141
Library interception, 180–181
Lines of code (LOC), 130
Load testing, 89–90
Local attack vectors, 7–8
Command Line User Interface (CLI), 7
files, 7
Graphical User Interface (GUI), 7
local network loops, 8
physical hardware access, 8
Programming interfaces (API), 7
Local network loops, 8
Local program fuzzing, 162
Local programming interface (API), 126, 127
Loss of data fees, 117
Man in the middle (MITM) attacks, 54
Manufacturing defects, 25
Maynor, 165
McCabe’s metric for cyclomatic complexity, 130
McMinn, P., 204
Mean/median of unplanned outage, 116
Mean time between failures, 117
Mean time to recovery, 117
Media files, 8
Memcheck, 182
Memory corruption errors, 42–49
format string errors, 43, 45
heap overflow, 48
integer errors, 46–47
off-by-one error, 47–48
other memory overwrites, 49
stack overflows, 43, 44
(uninitialized) stack or heap variable
overwrites, 48–49
Memory-related vulnerabilities, 169–170
Metadata injection vulnerabilities, 168–169
Index
283
Metrics, fuzzing. See Fuzzing metrics
Metrics, testing, 88–89
Michigan State University, 65
Middleware, 249
Miller, Barton, 22, 91, 138, 259
Miller, Charlie, 138
MIME-enabled applications, 126
Mini-Simulation Toolkit (PROTOS), 148
Mishandling of malicious content received over
network, 5
Mobile phone fuzzing, 264–265
Model-based fuzzers, 27–29
Monitoring, methods of, 170–180
application monitoring, 176–180
commercial fuzzer monitoring solutions, 176
remote monitoring, 175–176
system monitoring, 171–175
valid case instrumentation, 170–171
Monkey, The, 22
Moore, H. D., 164
Morris Internet Worm, 22
Mu-4000, 228
MuSecurity, 176, 228
Mutation fuzzers, 138, 150
Negative testing, 22, 24, 94–95, 129
Next-generation fuzzing frameworks: Sulley,
159–161
Next Generation Networks (Triple-Play), 9
Nessus, 36–37, 90, 122, 123
Nessus Security scanner, 4
Network analyzer, 9, 250
Network equipment manufacturer fuzzing,
263–265
mobile phone fuzzing, 264–265
network switch fuzzing, 263
Network fuzzing, 249
Network interface card (NIC), 84
Network interfaces, 162
Network protocols, 8, 84
Network switch fuzzing, 263
Network Time Protocol (NTP), 250
Non-exploitation vulnerability scanners, 
36–37
Nonintelligent fuzzers, 144
Off-by-one error, 47–48
Openness of wireless networks, 5
Operations phase, 3–4
Oulu University Secure Programming Group
(OUSPG), 6, 23, 118–119, 148
Packets, 252
Page table entry (PTE), 66
Parasoft, 183
“Patch and penetrate” race, 5
Patch deployment, cost of, 117–120
PAX, 68
Peach Fuzzer Framework, 146, 147–148
Penetration testers, 38, 41
Performance testing, 17–19, 87–88
Perl Compatible Regular Expression (RCRE)
library, 190–195
Pesticide paradox, 95–96
PHP file inclusions, 50
Physical hardware access, 8
PNG image decoder, 260
PolyGlot, 197
Pool crossover, 207–208
Pool mutation, 210–211
Port scanner, 9
Proactive security, 10–12
Proactive security, transition to, 107–120
cost of discovery, 108–115
cost of patch deployment, 117–120
cost of remediation, 115–116
cost of security compromises, 116–117
Processing of untrusted data received over
network, 5
Process metrics, 133
Process monitoring tools, 250
Product line testing (PLT), 85
Product security team (PST), 84–85
Programming Interfaces (API), 7
Proof-of-concept (POC) demonstration, 35–36
Protocol knowledge, 243–244
Protocol modeler, 29
Protocol-specific fuzzers, 148–149
FTPfuzz, 149
ikefuzz, 148–149
PROTOS project, 12, 23–25, 75–76, 112, 122,
148, 171
file fuzzers, 83
Genome project, 259
ProxyFuzz, 149, 161, 227, 243–244, 246–247
Proxy software, 250
Python script, 16
Quality, measuring, 73–77
end users’ perspective, 77
quality brings visibility to the development
process, 77
quality is about finding defects, 76
284
Index
quality is about validation of features, 73–76
quality is a feedback loop to development,
76–77
Quality, testing for, 77–79
testing on the developer’s desktop, 79
testing the design, 79