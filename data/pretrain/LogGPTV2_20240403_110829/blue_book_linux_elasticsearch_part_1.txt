---
title: Commands for elasticsearch
date: 20170529
author: Lyz
---
# [Searching documents](https://mindmajix.com/elasticsearch/curl-syntax-with-examples)
We use HTTP requests to talk to ElasticSearch. A HTTP request is made up of
several components such as the URL to make the request to, HTTP verbs (GET, POST
etc) and headers. In order to succinctly and consistently describe HTTP requests
the ElasticSearch documentation uses cURL command line syntax. This is also the
standard practice to describe requests made to ElasticSearch within the user
community.
## Get all documents
An example HTTP request using CURL syntax looks like this:
```bash
curl \
    -H 'Content-Type: application/json' \
    -XPOST "https://localhost:9200/_search" \
    -d' { "query": { "match_all": {} }}'
```
## Get documents that match a string
```bash
curl \
    -H 'Content-Type: application/json' \
    -XPOST "https://localhost:9200/_search" \
    -d' { "query": { "query_string": {"query": "test company"} }}'
```
# Backup
**It's better to use the `curator` tool**
If you see the next error it's probably because you misspelled the name of the repository:
```json
{
  "error": {
    "root_cause": [
      {
        "type": "repository_missing_exception",
        "reason": "[your_repository] missing"
      }
    ],
    "type": "repository_missing_exception",
    "reason": "[your_repository] missing"
  },
  "status": 404
}
```
## Create snapshot
```bash
curl {{ url }}/_snapshot/{{ backup_path }}/{{ snapshot_name }}?wait_for_completion=true
```
## Create snapshot of selected indices
```bash
curl {{ url }}/_snapshot/{{ backup_path }}/{{ snapshot_name }}?wait_for_completion=true
curl -XPUT 'localhost:9200/_snapshot/my_backup/snapshot_1?pretty' -H 'Content-Type: application/json' -d'
{
    "indices": "index_1,index_2",
    "ignore_unavailable": true,
    "include_global_state": false
}
'
```
## List all backups
Check for my-snapshot-repo
```bash
curl {{ url }}/_snapshot/{{ backup_path }}/_all?pretty
```
Check if htere are snapshots stuck in process or deletion
```bash
curl {{ url }}/_snapshot/_status
curl {{ url }}/_cluster/state?filter_path=*snapshot*
```
## Restore backup
First you need to close the selected indices
```bash
curl -X POST {{ url }}/{{ indice_name }}/_close
```
Then restore
```bash
curl {{ url }}/_snapshot/{{ backup_path }}/{{ snapshot_name }}/_restore?wait_for_completion=true
```
If you want to restore only one index, use:
```bash
curl -X POST "{{ url }}/_snapshot/{{ backup_path }}/{{ snapshot_name }}/_restore?pretty" -H 'Content-Type: application/json' -d'
{
    "indices": "{{ index_to_restore }}",
}'
```
## Delete snapshot
```bash
curl -XDELETE {{ url }}/_snapshot/{{ backup_path }}/{{ snapshot_name }}
```
## Delete snapshot repository
```bash
curl -XDELETE {{ url }}/_snapshot/{{ backup_path }}
```
## [Delete snapshots older than X](https://discuss.elastic.co/t/deleting-old-snapshots/134085/4)
!!! note "File: curator.yml" \`\`\`yaml client: hosts: - 'a data node' port:
9200 url_prefix: use_ssl: False certificate: client_cert: client_key:
ssl_no_validate: False http_auth: timeout: 30 master_only: False
````
logging:
loglevel: INFO
logfile: D:\CuratorLogs\logs.txt
logformat: default
blacklist: ['elasticsearch', 'urllib3']
```
````
!!! note "File: delete_old_snapshots.yml"
`yaml     actions:     1:     action: delete_snapshots     description: >-     Delete snapshots from the selected repository older than 100 days     (based on creation_date), for everything but 'citydirectory-' prefixed snapshots.     options:     repository: 'dcs-elastic-snapshot'     disable_action: False     filters:     - filtertype: pattern     kind: prefix     value: citydirectory-     exclude: True     - filtertype: age     source: creation_date     direction: older     unit: days     unit_count: 100     `
# Information gathering
## Get status of cluster
```bash
curl {{ url }}/_cluster/health?pretty
curl {{ url }}/_cat/nodes?v
curl {{ url }}/_cat/indices?v
curl {{ url }}/_cat/shards
```
If you've got red status, use the following command to choose the first
unassigned shard that it finds and explains why it cannot be allocated to a
node.
```bash
curl {{ url }}/_cluster/allocation/explain?v
```
## Get settings
```bash
curl {{ url }}/_settings
```
## [Get space left](https://stackoverflow.com/questions/29417830/elasticsearch-find-disk-space-usage)
```bash
curl {{ url }}/_nodes/stats/fs?pretty
```
## List plugins
```bash
curl {{ url }}/_nodes/plugins?pretty
```
# Upload
## Single data upload
```bash
curl -XPOST '{{ url }}/{{ path_to_table }}' -d '{{ json_input }}'
```
where json_input can be `{ "field" : "value" }`
## Bulk upload of data
```bash
curl -H 'Content-Type: application/x-ndjson' -XPOST \
    '{{ url }}/{{ path_to_table }}/_bulk?pretty' --data-binary @{{ json_file }}
```
# Delete
## Delete data
```bash
curl -XDELETE {{ url }}/{{ path_to_ddbb }}
```
# [Reindex an index](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/remote-reindex.html#remote-reindex-largedatasets)
If you encountered errors while reindexing `source_index` to `destination_index`
it can be because the cluster hit a timeout on the scroll locks. As a work
around, you can increase the timeout period to a reasonable value and then
reindex. The default AWS values are search context of 5 minutes, socket timeout
of 30 seconds, and batch size of 1,000.
First clear the cache of the index with:
```bash
curl -X POST https://elastic.url/destination_index/_cache/clear
```
If the index is big, they suggest to disable replicas in your destination index
by setting number_of_replicas to 0 and re-enable them once the reindex process
is complete.
To get the current state use:
```bash
curl https://elastic.url/destination_index/_settings
```
Then disable the replicas with:
```bash
curl -X PUT \
    https://elastic.url/destination_index \
    -H 'Content-Type: application/json' \
    -d '{"settings": {"refresh_interval": -1, "number_of_replicas": 0}}
```
Now you can reindex the index with:
```bash
curl -X POST \
    https://elastic.url/_reindex?wait_for_completion=false\&timeout=10m\&scroll=10h\&pretty=true \
    -H 'Content-Type: application/json' \
    -d '{"source": { "remote": { "host": "https://elastic.url:443", "socket_timeout": "60m" }, "index": "source_index" }, "dest": {"index": "destination_index"}}'
```
And
[check the evolution of the task](https://linuxhint.com/elasticsearch-reindex-all-indices-and-check-the-status/)
with:
```bash
curl 'https://elastic.url/_tasks?detailed=true&actions=*reindex&group_by=parents&pretty=true'
```
The output is quite verbose, so I use `vimdiff` to see the differences between
instant states.
If you see there are no tasks running, check the indices status to see if the
reindex ended well.
```bash
curl https://elastic.url/_cat/indices
```
After the reindex process is complete, you can reset your desired replica count
and remove the refresh interval setting.
# KNN
## [KNN sizing](https://opendistro.github.io/for-elasticsearch-docs/docs/knn/performance-tuning/#estimating-memory-usage)
Typically, in an Elasticsearch cluster, a certain portion of RAM is set aside
for the JVM heap. The k-NN plugin allocates graphs to a portion of the remaining
RAM. This portion’s size is determined by the circuit_breaker_limit cluster
setting. By default, the circuit breaker limit is set at 50%.
The memory required for graphs is estimated to be \`1.1 * (4 * dimension
- 8 * M)\` bytes/vector.
To get the `dimension` and `m` use the `/index` elasticsearch endpoint. To get
the number of vectors, use `/index/_count`. The number of vectors is the same as
the number of documents.
As an example, assume that we have 1 Million vectors with a dimension of 256 and
M of 16, and the memory required can be estimated as:
```
1.1 * (4 *256 + 8 * 16) * 1,000,000 ~= 1.26 GB
```
!!! note "Remember that having a replica will double the total number of
vectors."
I've seen some queries work with indices that required 120% of the available
memory for the KNN.
A good way to see if it fits, is [warming up the knn vectors](#knn-warmup). If
the process returns a timeout, you probably don't have enough memory.
## [KNN warmup](https://opendistro.github.io/for-elasticsearch-docs/docs/knn/api/#warmup-operation)
The Hierarchical Navigable Small World (HNSW) graphs that are used to perform an
approximate k-Nearest Neighbor (k-NN) search are stored as .hnsw files with
other Apache Lucene segment files. In order for you to perform a search on these
graphs using the k-NN plugin, these files need to be loaded into native memory.
If the plugin has not loaded the graphs into native memory, it loads them when
it receives a search request. This loading time can cause high latency during
initial queries. To avoid this situation, users often run random queries during
a warmup period. After this warmup period, the graphs are loaded into native
memory and their production workloads can begin. This loading process is
indirect and requires extra effort.
As an alternative, you can avoid this latency issue by running the k-NN plugin
warmup API operation on whatever indices you’re interested in searching. This
operation loads all the graphs for all of the shards (primaries and replicas) of