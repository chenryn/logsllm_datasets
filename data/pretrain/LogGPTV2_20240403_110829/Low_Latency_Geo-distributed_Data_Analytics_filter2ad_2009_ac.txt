was I = (240, 120, 60)MB with selectivity α = 1, i.e.,
S = I (see Figure 4a). Figure 4b shows the result of
running the query leaving the original data unmoved.
Site-1 will be the bottleneck during the intermediate
data transfer (ri’s and bottleneck site derived using §3).
Options for moving data from site-1 are to the other two
sites, 2 and 3. Figure 4c and 4d show the potential ef-
fect of both these moves, with ri’s recalculated based
on the new Si’s. Moving the data from site-1 to site-2
Site-1Site-2Site-3Uplink (MB/s), U101010Downlink(MB/s), D1101001002003004000510152025TiUTiDSiIntermediate Data, S(21.6)Site-1Site-2Site-3(TDor TU)01002003004000510152025(5.4)TiUTiDSiSite-1Site-2Site-3Intermediate Data, S(TDor TU)01002003004000510152025(9)TiUTiDSiIntermediate Data, S(TDor TU)class Move
double cost
(cid:104)QueryID, double(cid:105) timeReduction
Site bottleneck
1: procedure AllocateMoves(List(cid:104)Dataset(cid:105) D)
2:
3:
4:
5:
lag ←(cid:80)
d.value ←(cid:80)
q∈d.Queries q.lag / d.Queries.Count
for each Dataset d in D do
Move d.m ← FindMove(d)
q∈d.Queries d.m.timeReduction[q ] /
lag
6:
7:
8:
9:
d.score ← d.value
d.m.cost
for each Dataset d in D.SortedByDesc(d.score) do
if d.m.bottleneck.canMove() then
execute d.m
Pseudocode 1:
Iridium Solution. The function takes
the set of all datasets D and assigns each site to
move out part of a dataset. For simplicity, we do
not present the calculation of the destination site to
be moved.
is the best move as the transfer duration is 5.4s com-
pared to 9s in Figure 4d. While not applicable in this
example, we ignore moves to those sites that increase
the transfer duration.
(ii) On the second question of how much data to move
out of the bottleneck site, the above example ended up
moving all the data from site-1 to site-2 because such
a move happened to result in the lowest duration for
intermediate transfer. In our system, we use a “what-if”
calculation to assess moving data out of the bottleneck
site in increments of δ (say, 10MB), i.e., move 10MB,
20MB and so forth. We pick the increment of δ that
provides the smallest transfer duration.4
Iridium’s heuristic can be summarized as follows: it-
eratively identify bottlenecked sites and move data out
of them to reduce the duration of intermediate data
transfer (considering all potential destinations and in-
crements of δ).5 We extend this simple intuition to a
workload of multiple competing datasets in §4.2. We
then enhance the solution in §4.3 with techniques to
predict future query arrivals, minimize contention be-
tween data movement and query traﬃc, etc.
4.2 Prioritizing between Multiple Datasets
In prioritizing between datasets, Iridium seeks to iden-
tify and move the high-valued datasets. High-valued
datasets are those that are accessed by more queries,
and those whose movement results in large improve-
ments in the intermediate data transfer of their queries.
In the example above, the “value” of moving data out
of site-1 to site-2 is (21.6 − 5.4) = 16.2s. The relative
value of moving a dataset also increases if its queries
4This approach brings the transfer duration down to, at
least, the second-most bottlenecked link. Thus, this avoids
a “loop” of the same data being moved back to the site in
the next step. In general, ﬁxing δ avoids jointly calculating
new values for ri’s and Si’s.
5If none of the moves out of the bottleneck site help, we
consider analogical moves of data into the bottleneck site.
are to arrive sooner, i.e., smaller lag. The “cost” of the
move is the amount of data that needs to be moved over
the WAN to improve the query, 240MB in the example.
We select the move that achieves the highest “score”,
i.e., (value/cost).
We defer estimation of future query arrivals to §4.3.
Pseudocode 1 lists the two main steps in our heuristic.
Step a), lines 2 − 5, ﬁrst calls FindMove() that
returns the Move object that contains the bottlenecked
site, data to be moved out, and the reduction in query
durations (≥ 0) due to the move. The query durations
and bottleneck site are calculated using §3. If there are
multiple bottlenecked sites, we arbitrarily pick one.
The value of the move is calculated using the re-
duction in query durations and query lags (described
shortly). The “score” of the proposed move is value
cost .
Step b), lines 6− 8, processes datasets in descending
order of their score. To prevent new low-value dataset
moves from slowing down ongoing high-value moves, we
allocate a site’s uplink and downlink to only one dataset
at a time (justiﬁed in §6.4). The canMove function per-
forms this check.
Query Lag: For two datasets A and B that arrived at
1:00, all else being equal, if dataset A’s queries arrive at
1:05 and dataset B’s queries at 1:10, we should prefer to
move dataset A at 1:00 since we can move B starting at
1:05. This is analogical to the “earliest-deadline-ﬁrst”
scheduling approach.
We adopt this approach by calculating the query lag
for a dataset, i.e., time between dataset availability and
the query’s arrival, as the average of the lag of all the
queries accessing the dataset. The value for the dataset
is then multiplied by 1
lag . Thus, the smaller the av-
erage lag, the higher its value and urgency in moving
the dataset. In §6.4, we also evaluate other metrics of
arrival lag (e.g., median, earliest, latest) and see that
using the average works best.
The AllocateMoves() function in Pseudocode 1 is
invoked every time a new dataset or a query arrives or
when a scheduled data movement completes. Arrival of
queries aborts any incomplete movements of their data.
4.3 Enhancements
We now present two important enhancements.
Estimating Query Arrivals
For recurring workloads (“batch” streams [60] or “cron”
jobs), we estimate arrivals based on past executions.
However, this is hard to do for ad hoc queries. For a
dataset, we care about the number of queries that will
access it and their arrival times, i.e., lag. To that end,
we make the following simple assumption that works
well in our evaluation (§6.4). We assume the dataset’s
future query arrivals will repeat as per the query arrivals
so far (from the time the dataset was generated). For
instance, if the dataset was generated at time t and
two queries arrived at times (t + 2) and (t + 3), we will
assume at (t + 3) that two more queries would arrive at
times (t + 3) + 2 and (t + 3) + 3. We use these arrival
lags in Pseudocode 1. In general, at the end of n queries,
it would assume n more queries will arrive.
Such a scheme under-estimates the number of ac-
cesses initially. But the estimate grows quickly, and it
estimates correctly at the “half-way” number of accesses.
Beyond this half-way point, it over-estimates future ac-
cesses, which could lead to unnecessary data movement.
In practice however, for even moderate number of ac-
cesses, data movements mostly stabilize by the time the
over-estimation starts, thus limiting any fallout.
Queries/Data Contention
In an online system, our heuristic makes its data move-
ment decisions even as (tasks of) queries are executing
on the sites. This results in contention between the net-
work ﬂows of the tasks and data movement. When we
schedule a data movement out of a site, we measure the
impact, i.e, increase in duration of the running tasks
and the corresponding queries. An increase in task du-
ration need not necessarily increase the query’s duration
because the latter is bound by its slowest task. In mea-
suring the increase in duration, we assume fair sharing
of uplink/downlink bandwidth among all the ﬂows.
We evaluate if the slowdown of the other running
queries due to contention is worth the speedup of the
queries whose data will be moved. Data is moved only
if the trade-oﬀ is beneﬁcial, otherwise we ignore this
dataset and move to the next dataset in the ordered list
(not included in Pseudocode 1 for simplicity).
4.4 WAN Usage Budget
WAN usage across sites is an important operational
cost ($/byte) for datacenters [53, 54]. Also, third-party
services running on AWS or Azure across regions pay
based on WAN usage [5]. As described so far, Iridium
does not account for WAN usage. If there is enough lag
for a query’s arrival or if there are not many competing
datasets, it will be free to move the datasets even if they
only marginally improve the response times.
To avoid wasting WAN bandwidths on such move-
ments, we incorporate a budget for WAN usage that
forces our heuristic to balance between the speedup of
queries and WAN costs. The challenge in setting the
budget is to ensure it is neither too low (and moving
very few datasets leading to limited query speedups),
nor too high (and causing wasted usage of WAN links).
As a baseline for our budget, we start with the WAN
consumption, W , of a (data and task placement) scheme
that optimizes for WAN usage [53, 54]. We set the bud-
get for our heuristic to be (B · W ), B ≥ 1. B = 1
implies a strict WAN usage budget, while higher values
of B trade it for faster query response.
How do we calculate and keep track of the WAN bud-
get over time? We adopt the following greedy approach.
We start with a counter M = 0. Every time a new
dataset arrives, we compute the W for this dataset and
increment M + = W · B. Every time we execute a data
move, we decrement M by amount of data moved. If
M = 0, we do not execute any new data moves.
Setting the knob B is a matter of policy but our re-
sults indeed highlight the presence of a “sweet spot”.
With B = 1.3, Iridium’s gains are nearly 90% of the
gains with an unconstrained budget. In fact, even with
WAN usage equal to a WAN-usage optimal policy, i.e.,
B = 1, its query speedups are 2× more, §6.5.
5. SYSTEM IMPLEMENTATION
Our prototype implementation of Iridium is on top of
the Apache Spark [59] framework. The source code is
available here: https://github.com/Microsoft-MNR/GDA
To implement our task placement, we override the
default scheduler of Spark and plug-in our module that
internally uses the Gurobi solver [7]. We would like
to note that we solve the task placement problem as a
Mixed Integer Problem (in contrast to the simple LP in
§3). The MIP uses the exact amount of intermediate
data read by every task from each site, thus handles
any intermediate communication pattern, and outputs
a speciﬁc site to place each task. Even though the MIP
is less eﬃcient, it is invoked only once per job for task
placement. The LP is an eﬃcient approximation and
used in the many iterations of data placement decisions.
We incorporate our data placement heuristic inside
the Hadoop Distributed File System (HDFS) [8] that
Spark uses as its data store. We do not disable the de-
fault replication mechanism in HDFS, and all our data
movements hence only create additional copies of the
data, thus leaving data durability unaﬀected. As stor-
age at the sites is abundant, we believe this to be an
acceptable design.
User queries and analytics jobs are submitted through
an uniform interface provided by the Spark manager.
Because Iridium is built upon Spark, it can leverage two
Spark extensions, Spark SQL and Spark Streaming [60],
for parsing SQL queries and running streaming jobs.
We use simple techniques to estimate the bandwidths
at sites and intermediate data sizes (or α) of queries.
Estimating Bandwidths: Our experiments at the eight
EC2 sites (described in §6) indicate that the available
bandwidth is relatively stable in the granularity of min-
utes. Thus, we use a simple test that checks the avail-
able bandwidth every few minutes. However, we also
get continuous ﬁne-grained measurements by piggyback-
ing measurements on the throughputs of the data move-
ment and task ﬂows. Given our focus on recurring
queries, such piggybacking provides a suﬃciently rich
source of bandwidth values that automatically considers
non-Iridium traﬃc. We plug these in to our heuristics.
Estimating Intermediate Data Sizes: Unlike input sizes
of queries, intermediate data sizes are not known up-
front. Again, we leverage the recurring nature of our
workloads to infer the intermediate data sizes. Re-
peated queries, even on newer parts of the same dataset,
often produce similar ﬁltering of data. We are able to es-
timate the ratio of intermediate to input data of queries
(α) with an accuracy of 92% in our experiments.
6. EVALUATION
We evaluate Iridium using a geo-distributed EC2 de-
ployment as well as trace-driven simulations. The high-
lights of our evaluation are as follows.
1. Iridium speeds up workloads from Conviva, Bing
Edge, TPC-DS [12] and Big-data benchmarks [4]
by 64% to 92% (3× to 19×) when deployed across
eight EC2 regions in ﬁve continents.
2. Iridium saves WAN bandwidth usage by 15% to
64%. Even with usage equal to a WAN-usage op-
timal policy, its query speedups are 2× more.
6.1 Methodology
We begin by describing our evaluation setup.
EC2 Deployment: We deploy Iridium across eight EC2
regions in Tokyo, Singapore, Sydney, Frankfurt, Ire-
land, Sao Paulo, Virginia (US) and California (US) [2].
We use c3.4xlarge instances in each region [1] and the
WAN connecting them is a more constrained resource
than the local CPU/memory/disk. In addition, we also
mimic a larger geo-distributed setup of 30 sites within
one region.
Workloads: We tested our system using four analyt-
ics workloads from Conviva, Bing Edge, TPC-DS and
AMPLab Big-data benchmark (§6.2). These workloads
consist of a mix of Spark [59] and Hive [49] queries.
Trace-driven Simulator: We evaluate Iridium over
longer durations using a trace-driven simulator of pro-
duction traces (one month, 350K jobs) from Facebook’s
Hadoop cluster. The simulator is faithful to the trace
in its query arrival times (lag), task input/output sizes,
and dataset properties of locations, generation times
and access patterns. We mimic 150 sites in our simula-
tor; slots within sites are unconstrained.
nique in §4.3, and evaluate its accuracy in §6.4.
Baselines: We compare Iridium to two baselines: (i)
leave data “in-place” and use stock Spark’s scheduling
and storage policies, and (ii) “centralized” aggregation
of data at a main DC whose in-bandwidth is generously
and conservatively set to be practically-inﬁnite, i.e., it is
rarely the bottleneck during the aggregation. We again
use stock Spark’s scheduling/storage within the main
DC that they are optimized well for.
Metric: Our primary metric is reduction (%) in av-
erage response time of queries. For a query whose re-
sponse times with the baseline and Iridium are b and x,
we calculate 100 × (b−x)
; maximum is 100%. We also
quote b/x, the factor of reduction in response time when
appropriate. In §6.5, we measure WAN usage.
We describe our EC2 deployment results in §6.2 and
simulation results in §6.3. We assess Iridium’s design
decisions in §6.4 and the WAN usage knob in §6.5.
We predict future query arrivals (lags) using the tech-
b
(a) Inter-Region
(b) 30 sites
Figure 5: EC2 Results across eight worldwide regions
(a): Tokyo, Singapore, Sydney, Frankfurt, Ireland,
Sao Paulo, Virginia (US) and California (US). The
ﬁgure on the right (b) is on a larger 30-site setup.
Iridium is 3× − 19× better compared to the two base-