title:Secure parallel computation on national scale volumes of data
author:Sahar Mazloom and
Phi Hung Le and
Samuel Ranellucci and
S. Dov Gordon
Secure parallel computation on national scale 
volumes of data
Sahar Mazloom and Phi Hung Le, George Mason University; 
Samuel Ranellucci, Unbound Tech; S. Dov Gordon, George Mason University
https://www.usenix.org/conference/usenixsecurity20/presentation/mazloom
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.Secure parallel computation on national scale volumes of data
Sahar Mazloom∗
George Mason University
PI:EMAIL
Phi Hung Le∗
George Mason University
PI:EMAIL
Samuel Ranellucci
Unbound Tech
PI:EMAIL
S. Dov Gordon
George Mason University
PI:EMAIL
Abstract
We revisit the problem of performing secure computation
of graph-parallel algorithms, focusing on the applications of
securely outsourcing matrix factorization, and histograms.
Leveraging recent results in low-communication secure multi-
party computation, and a security relaxation that allows the
computation servers to learn some differentially private leak-
age about user inputs, we construct a new protocol that re-
duces overall runtime by 320X, reduces the number of AES
calls by 750X, and reduces the total communication by 200X.
Our system can securely compute histograms over 300 mil-
lion items in about 4 minutes, and it can perform sparse matrix
factorization, which is commonly used in recommendation
systems, on 20 million records in about 6 minutes.1 Further-
more, in contrast to prior work, our system is secure against
a malicious adversary that corrupts one of the computing
servers.
1 Introduction
Instances of data breach and exﬁltration continue to occur
in great number. Secure computation offers an appealing
avenue for defense. This cryptographic tool allows user data
to be secret-shared across multiple computational servers,
ensuring that the breach of any single server provides no
information to an adversary, while still enabling the servers
to perform arbitrary computation on the data. As compared
with standard encryption, which provides security only while
the data remains at rest, secure computation allows the data
to remain secure throughout its life-cycle, from the moment
it is uploaded by the user, through its incorporation into some
statistic or learned model.
The theory of secure computation has been studied since
the 1980’s, and a rich literature has given rise to a line of
practical work that has focused on reducing concrete costs to
∗Lead co-authors
1These numbers are for computation in a LAN. For results in a WAN, see
Section 5.
a near minimum. Of course, there are no free lunches, and
computing on secret-shared data will always require increased
communication and computation when compared with the
cost of computing on plaintext data. However, several recent
research directions have helped narrow the gap between se-
cure data processing and plaintext computations.
Low communication MPC. Several results in secure computa-
tion have recently minimized the communication require-
ments by restricting the number of computing servers to
three [2, 4, 17] or four [10], and assuming an honest majority
of the servers. When representing the computation as an arith-
metic circuit over a ring (as we will do here), the cheapest of
these results, by Gordon et al. [10], requires sending only 1.5
ring elements per party, per circuit gate. In contrast, the best
two-party protocol requires 290 bytes per party, per Boolean
gate [22], and the best honest-majority protocol (supporting
arbitrary numbers of parties) requires 12 ﬁeld elements per
party, per gate [4].
Parallelizing secure computation. Nayak et al. [18] propose a
framework for securely computing graph parallel algorithms.
In such algorithms, the data is assumed to reside in a graph
structure, and the result of the computation is reached through
an iterative process in which a) the data is gathered from all
edges to their neighboring nodes, b) a simple computation is
applied on the data at each node, and c) the processed data is
scattered back to the neighboring edges before the processes
are repeated. Such frameworks have become very popular for
plaintext computations on large amounts of data, because the
Apply phase can be easily distributed among many proces-
sors, making parallelization straight-forward [6, 9, 13, 14]. In
this work we implement gradient descent, yielding a secure
protocol for sparse matrix factorization (commonly used in
recommendation systems), as well as histograms. Graph par-
allel frameworks are also used for PageRank, Markov random
ﬁeld parameter learning, parallelized Gibbs samplers, name
entity resolution, and many other computations.
Allowing differentially private leakage. Very recently, re-
searchers have explored the idea of relaxing security to al-
USENIX Association
29th USENIX Security Symposium    2487
low leakage in secure computation, coupled with a bound
demonstrating that the leakage preserves differential privacy
[3, 12, 16, 20]. Mazloom and Gordon [16] demonstrated a
protocol for computing graph parallel algorithms with differ-
entially private leakage, shaving a logE factor off of the fully
secure protocol of Nayak et al., where E is the number of
edges in the graph.
Securely outsourcing computation. These advances have
introduced an opportunity for several applications of secure
computation in which user data from thousands of parties are
secret shared among a few servers (usually three) to perform
a secure computation on their behalf. Multiple variants of this
application have now been deployed. In some cases, users
have already entrusted their data, in the clear, to a single entity,
which then wishes to safeguard against data breach; secret
sharing the data among several servers, each with a unique
software stack, helps diversify the risk of exposure. In other
cases, users were unwilling, or were even forbidden by law,
to entrust their data to any single entity, and the use of secure
computation was essential to gaining their participation in the
computation. In many of these cases, the servers executing
the secure computation are owned and operated by a single
entity that is trusted for the time being, but may be corrupted
by an outside party. In other cases, some data were entrusted
to one entity, while other data, from another set of users, were
entrusted to a second entity, and these two distrusting parties
wish to join in a shared computation.
The common denominator in all of these variants is that
the computation servers are distinct from the data owners.
In this context, the relaxation allowing these servers to learn
some small, statistical information about the data may be
quite reasonable, as long as the impact to any individual data
contributor can be bounded. For example, when computing
a histogram of the populations in each U.S. zip code, the
servers see only a noisy count for each zip code, gaining little
information about the place of residence of any individual
data contributor. In the context of securely performing matrix
factorization for use in a recommendation system, we allow
the servers to learn a noisy count of the number of items that
each contributing user has reviewed. Even when combined
with arbitrary external data, this limits the servers from gain-
ing any certainty about the existence of a link between any
given user and any given item in the system.
Our reliance on a fourth server in the computation intro-
duces a tradeoff between security and efﬁciency, when com-
pared with the more common reliance on three servers.2 It is
almost certainly easier for an adversary to corrupt two out of
four servers than it is to corrupt two out of three. However, as
our results demonstrate, the use of a fourth server enables far
faster computation, which, for large-scale applications, might
2From a purely logistical standpoint, we do not envision that this require-
ment will add much complexity. The additional server(s) can simply be run
in one or more public clouds. In some cases, as already mentioned, all servers
are anyway run by a single entity, so adding a fourth server may be trivial.
make the use of secure computation far more feasible than it
was previously.
Results. In this work, we revisit secure computation of graph
parallel algorithms, simultaneously leveraging all three of the
advances just described: we assume four computation servers
(with an honest majority, and one malicious corruption), al-
low differentially private leakage during computation, and,
exploiting the parallelism that this affords, we construct an
MPC protocol that can perform at national scales. Concretely,
we compute histograms on 300 million inputs in 4.17 minutes,
and we perform sparse matrix factorization, which is used
in recommendation systems, on 20 million inputs in under 6
minutes. These problems have broad, real-world applications,
and, at this scale, we could imagine supporting the Census
Bureau, or a large company such as Amazon. For comparison,
the largest experiments in GraphSC [18] and OblivGraph [16]
had 1M inputs, and required 13 hours and 2 hours of runtime,
respectively, while using 4 times the number of processors
that we employ, and tolerating only semi-honest corruptions.
End-to-end, our construction is 320X faster than OblivGraph,
the faster of these 2 systems.
Technical contributions. Merging the four-party protocol of
Gordon et al. [10] with the construction of Mazloom and
Gordon [16] raises several challenges and opportunities:
Fixed point arithmetic. There are few results in the MPC
literature that support ﬁxed point computation with malicious
security. The most efﬁcient that we know of is the work by
Mohassel and Rindal, which uses replicated sharing in the
three party, honest majority setting [17], modifying the proto-
col of Furakawa et al. [7]. Their construction requires each
party then sends 8 ring elements for each multiplication with-
out truncation. The parties execute two subtraction circuits in
pre-processing phase for each truncation. The pre-processing
costs each party at least 21· (2k− d) bits for each truncation
where k is the size of the ring, and d the length of the fraction
bits. With a bit of care, we show that we can extend the four-
party protocol of Gordon et al. [10] to handle ﬁxed point arith-
metic, without any additional overhead, requiring each party
to send just 1.5 ring elements for each multiplication. This
provides about a 20X improvement in communication over
Mohassel and Rindal. The protocol of Gordon et al. proceeds
through a dual execution of masked circuit evaluation: for cir-
cuit wire i carrying value wi, one pair of parties holds wi + λi,
while the other holds wi + λ(cid:48)
i are random mask
values known to the opposite pair. To ensure that nobody has
cheated in the execution, the two pairs of parties compute
and compare wi + λi + λ(cid:48)
i. This already supports computation
over an arbitrary ring, with malicious security. However, if
wi is a fractional value, the two random masks may result
in different rounded values, causing the comparisons to fail.
We show how to handle rounding errors securely, allowing
us to leverage the efﬁciency of this protocol for ﬁxed point
computation.
i, where λi,λ(cid:48)
2488    29th USENIX Security Symposium
USENIX Association
Four party, linear-time, oblivious shufﬂe. The experimen-
tal results of Mazloom and Gordon have complexity O(Vα +
E)log(Vα+E), where α = α(ε,δ) is a function of the desired
privacy parameters, E is the number of edges in the graph, and
V is the number of nodes. The authors also show how to im-
prove the asymptotic complexity to O(Vα +E), removing the
log factor by replacing a circuit for performing an oblivious
shufﬂe of the data with a linear-time oblivious shufﬂe. They
don’t leverage this improvement in their experimental results,
because it seems to require encrypting and decrypting the
data inside a secure computation. (Additionally, for malicious
security, it would require expensive zero-knowledge proofs.)
Operating in the 4-party setting allows us to construct a
highly efﬁcient, linear-time protocol for oblivious shufﬂe. One
of the challenges we face in constructing this shufﬂe protocol
is that we have to authenticate the values before shufﬂing, and
verify correctness of the values after shufﬂing, and because
we are committed to computing over elements from Z2k, we
need to authenticate ring values. Recently, Cramer et al. [5]
proposed a mechanism for supporting arithmetic circuits over
ﬁnite rings by constructing authentication in an “extension
ring”: to compute in Z2k, they sample α ← Z2s, and use a
secret-sharing of αx ∈ Z2k+s for authentication. We adopt their
construction in our shufﬂe protocol to ensure the integrity of
the data during shufﬂing.
One of the beneﬁts of using 4 parties is that we can separate
the operations between two groups of parties, such that one
group, for example Alice and Bob, is responsible for access-
ing the data during Gather and Scatter, while the other group,
Charlotte and David, performs the shufﬂing. In contrast, in the
2-party setting, if one party knows the shufﬂing permutation,
then the other party must access each data element in a man-
ner that hides the data index. This seemingly requires using
a short decryption key inside the secure computation, rather
than a more efﬁcient, 2-party secret sharing scheme. On the
other hand, if neither party knows the shufﬂing permutation,
we need to use a permutation network incurring the additional
log overhead. When comparing our four-party, maliciously
secure, oblivious shufﬂing protocol with the semi-honest con-
struction of Mazloom and Gordon, they require 540X more
AES calls and 140X communication than we do.
Computation over a ring. Both the work of Nayak et al. [18]
and Mazloom and Gordon [16] use Boolean circuits through-
out the computation. Boolean circuits are a sensible choice
when using sorting and shufﬂing circuits, which require bit
comparisons. Additionally, as just discussed, Boolean circuits
provide immediate support for ﬁxed point computation, re-
moving one further barrier. However, for the Apply phase,
where, for example, we compute vector gradients, computa-
tion in a ring (or ﬁeld) is far more efﬁcient. With the intro-
duction of our four-party shufﬂe, which is not circuit-based,
and after modifying Gordon et al. [10] to support ﬁxed-point
computation, there is no longer any reason to support compu-
tation on Boolean values. We construct a method for securely
converting the shared, and authenticated values used in our
shufﬂe protocol into the "masked" ring values required for our
four-party computation of the Apply phase. For the problem
of Matrix Factorization on dataset of 1 million ratings, the
Apply phase of Mazloom and Gordon [16] requires 550X
more AES calls and 370X more bandwidth than ours.
2 Preliminaries
2.1 Graph-parallel computation
The Graph-parallel abstraction as it is used in several frame-
works such as MapReduce [6], GraphLab [13] and Power-
Graph [9], consists of a sparse graph that encodes computa-
tion as vertex-programs that run in parallel, and interact along
edges in the graph. These frameworks all follow the same
computational model, called the GAS model, which includes
three conceptual phases: Gather, Apply, and Scatter. The
framework is quite general, and captures computations such
as gradient descent, which is used in matrix factorization for
recommendation systems, as well as histograms or counting
operation, and many other computations. In Matrix Factor-
ization, as an example, an edge (u,v,data) indicates that user
u reviewed item v, and the data stored on the edge contains
the value of the user’s review. The computation proceeds in