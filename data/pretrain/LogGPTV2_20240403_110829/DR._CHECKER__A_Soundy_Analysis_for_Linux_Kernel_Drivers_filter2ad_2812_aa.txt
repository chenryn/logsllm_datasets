title:DR. CHECKER: A Soundy Analysis for Linux Kernel Drivers
author:Aravind Machiry and
Chad Spensky and
Jake Corina and
Nick Stephens and
Christopher Kruegel and
Giovanni Vigna
DR. CHECKER: A Soundy Analysis  
for Linux Kernel Drivers
Aravind Machiry, Chad Spensky, Jake Corina, Nick Stephens,  
Christopher Kruegel, and Giovanni Vigna, UC Santa Barbara
https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/machiry
This paper is included in the Proceedings of the 26th USENIX Security SymposiumAugust 16–18, 2017 • Vancouver, BC, CanadaISBN 978-1-931971-40-9Open access to the Proceedings of the 26th USENIX Security Symposium is sponsored by USENIXDR. CHECKER: A Soundy Analysis for Linux Kernel Drivers
Aravind Machiry, Chad Spensky, Jake Corina, Nick Stephens,
{machiry, cspensky, jcorina, stephens, chris, vigna}@cs.ucsb.edu
Christopher Kruegel, and Giovanni Vigna
University of California, Santa Barbara
Abstract
While kernel drivers have long been know to poses huge
security risks, due to their privileged access and lower
code quality, bug-ﬁnding tools for drivers are still greatly
lacking both in quantity and effectiveness. This is be-
cause the pointer-heavy code in these drivers present
some of the hardest challenges to static analysis, and
their tight coupling with the hardware make dynamic
analysis infeasible in most cases.
In this work, we
present DR. CHECKER, a soundy (i.e., mostly sound)
bug-ﬁnding tool for Linux kernel drivers that is based on
well-known program analysis techniques. We are able to
overcome many of the inherent limitations of static anal-
ysis by scoping our analysis to only the most bug-prone
parts of the kernel (i.e., the drivers), and by only sac-
riﬁcing soundness in very few cases to ensure that our
technique is both scalable and precise. DR. CHECKER is
a fully-automated static analysis tool capable of perform-
ing general bug ﬁnding using both pointer and taint anal-
yses that are ﬂow-sensitive, context-sensitive, and ﬁeld-
sensitive on kernel drivers. To demonstrate the scala-
bility and efﬁcacy of DR. CHECKER, we analyzed the
drivers of nine production Linux kernels (3.1 million
LOC), where it correctly identiﬁed 158 critical zero-day
bugs with an overall precision of 78%.
1
Introduction
Bugs in kernel-level code can be particularly problem-
atic in practice, as they can lead to severe vulnerabil-
ities, which can compromise the security of the entire
computing system (e.g., Dirty COW [5]). This fact has
not been overlooked by the security community, and a
signiﬁcant amount of effort has been placed on verify-
ing the security of this critical code by means of man-
ual inspection and both static and dynamic analysis tech-
niques. While manual inspection has yielded the best
results historically, it can be extremely time consuming,
and is quickly becoming intractable as the complexity
and volume of kernel-level code increase. Low-level
code, such as kernel drivers, introduce a variety of hard
problems that must be overcome by dynamic analysis
tools (e.g., handling hardware peripherals). While some
kernel-level dynamic analysis techniques have been pro-
posed [23, 25, 29, 46], they are ill-suited for bug-ﬁnding
as they were implemented as kernel monitors, not code
veriﬁcation tools. Thus, static source code analysis has
long prevailed as the most promising technique for kernel
code veriﬁcation and bug-ﬁnding, since it only requires
access to the source code, which is typically available.
Unfortunately, kernel code is a worst-case scenario
for static analysis because of the liberal use of pointers
(i.e., both function and arguments are frequently passed
as pointers). As a result, tool builders must make the
tradeoff between precision (i.e., reporting too many false
positives) and soundness (i.e., reporting all true posi-
tives). In practice, precise static analysis techniques have
struggled because they are either computationally infea-
sible (i.e., because of the state explosion problem), or too
speciﬁc (i.e., they only identify a very speciﬁc type of
bug). Similarly, sound static analysis techniques, while
capable of reporting all bugs, suffer from extremely high
false-positive rates. This has forced researchers to make
variety of assumptions in order to implement practical
analysis techniques. One empirical study [14] found that
users would ignore a tool if its false positive rate was
higher than 30%, and would similarly discredit the anal-
ysis if it did not yield valuable results early in its use
(e.g., within the ﬁrst three warnings).
Nevertheless, numerous successful tools have been
developed (e.g., Coverity [14], Linux Driver Veriﬁca-
tion [36], APISan [64]), and have provided invaluable
insights into both the types and locations of bugs that
exist in critical kernel code. These tools range from pre-
cise, unsound, tools capable of detecting very speciﬁc
classes of bugs (e.g., data leakages [32], proper fprintf
usage [22], user pointer deferences [16]) to sound, im-
USENIX Association
26th USENIX Security Symposium    1007
precise, techniques that detect large classes of bugs (e.g.,
ﬁnding all usages of strcpy [55]). One notable ﬁnding
early on was that a disproportionate number of errors in
the kernel were found in the drivers, or modules. It was
shown that drivers accounted for seven times more bugs
than core code in Linux [19] and 85% of the crashes
in Windows XP [49]. These staggering numbers were
attributed to lower overall code quality in drivers and im-
proper implementations of the complex interactions with
the kernel core by the third party supplying the driver.
In 2011, Palix et al. [39] analyzed the Linux kernel
again and showed that while drivers still accounted for
the greatest number of bugs, which is likely because
drivers make up 57% of the total code, the fault rates for
drivers where no longer the highest. Our recent analy-
sis of main line linux kernel commit messages found that
28% of CVE patches to the linux repository in the past
year involved kernel drivers (19% since 2005), which is
in line with previous studies [17]. Meanwhile, the mo-
bile domain has seen an explosion of new devices, and
thus new drivers, introduced in recent years. The lack of
attention being paid to these drivers, and their potential
danger to the security of the devices, has also not gone
unnoticed [47]. Recent studies even purport that mobile
kernel drivers are, again, the source of up to 85% of the
reported bugs in the Android [48] kernel. Yet, we are
unaware of any large-scale analysis of these drivers.
In this work, we present DR. CHECKER, a fully-
automated static-analysis tool capable of identifying
numerous classes of bugs in Linux kernel drivers.
DR. CHECKER is implemented as a completely modu-
lar framework, where both the types of analyses (e.g.,
points-to or taint) and the bug detectors (e.g., integer
overﬂow or memory corruption detection) can be eas-
ily augmented. Our tool is based on well-known pro-
gram analysis techniques and is capable of performing
both pointer and taint analysis that is ﬂow-, context-, and
ﬁeld-sensitive. DR. CHECKER employs a soundy [31]
approach, which means that our technique is mostly
sound, aside from a few well-deﬁned assumptions that
violate soundness in order to achieve a higher precision.
is the ﬁrst (self-proclaimed) soundy
DR. CHECKER,
static-analysis-based bug-ﬁnding tool, and, similarly, the
ﬁrst static analysis tool capable of large-scale analysis
of general classes of bugs in driver code. We evaluated
DR. CHECKER by analyzing nine popular mobile device
kernels, 3.1 million lines of code (LOC), where it cor-
rectly reported 3,973 ﬂaws and resulted the discovery of
158 [6–10] previously unknown bugs. We also compared
DR. CHECKER against four other popular static analy-
sis tools, where it signiﬁcantly outperformed all of them
both in detection rates and total bugs identiﬁed. Our re-
sults show that DR. CHECKER not only produces useful
results, but does so with extremely high precision (78%).
In summary, we claim the following contributions:
• We present the ﬁrst soundy static-analysis technique
for pointer and taint analysis capable of large-scale
analysis of Linux kernel drivers.
• We show that our technique is capable of ﬂow-
sensitive, context-sensitive, and ﬁeld-sensitive anal-
ysis in a pluggable and general way that can easily
be adapted to new classes of bugs.
• We evaluated our tool by analyzing the drivers of
nine modern mobile devices, which resulted in the
discovery of 158 zero-day bugs.
• We compare our tool to the existing state-of-the-
art tools and show that we are capable of detecting
more bugs with signiﬁcantly higher precision, and
with high-ﬁdelity warnings.
• We are releasing DR. CHECKER as an open-source
tool at github.com/ucsb-seclab/dr_checker.
2 Background
Kernel bug-ﬁnding tools have been continuously evolv-
ing as both the complexity and sheer volume of code in
the world increases. While manual analysis and grep
may have been sufﬁcient for fortifying the early versions
of the Linux kernel, these techniques are neither scalable
nor rigorous enough to protect the kernels that are on our
systems today. Ultimately, all of these tools are devel-
oped to raise warnings, which are then examined by a
human analyst. Most of the initial, and more successful
bug-ﬁnding tools were based on grep-like functionality
and pattern matching [45,55,57]. These tools evolved to
reduce user interaction (i.e., removing the need for man-
ual annotation of source code) by using machine learn-
ing and complex data structures to automatically identify
potential dangerous portions of code [41, 59–63]. While
these tools have been shown to return useful results, iden-
tifying a number of critical bugs, most of them are de-
veloped based on empirical observation, without strong
formal guarantees.
Model checkers (e.g., SLAM [13], BLAST [27],
MOPS [18]) provide much more context and were able
to provide more formalization, resulting in the detec-
tion of more interesting ﬂaws. However, these tech-
niques soon evolved into more rigorous tools, capable
of more complex analyses (e.g., path-sensitive ESP [22])
and the more recent tools are capable of extracting far
more information about the programs being analyzed to
perform even more in-depth analysis (e.g., taint analy-
sis [61]). While some have been implemented on top of
custom tools and data structures (e.g., Joern [59–62]),
1008    26th USENIX Security Symposium
USENIX Association
others have been implemented as compiler-level opti-
mizations on top of popular open-source projects (e.g.,
LLVM [32]). In all cases, these tools are operating on
abstract representations of the program, such as the ab-
stract syntax tree (AST) or the control ﬂow graph (CFG),
which permit a more rigorous formal analysis of the
properties of the program.
Motivation. Before delving into the details of
DR. CHECKER, we ﬁrst present a motivating ex-
ample in the form of a bug that was discovered by
DR. CHECKER.
In this bug, which is presented
in Listing 1, a tainted structure is copied in from
userspace using copy from user. A size ﬁeld of
this structure is then multiplied by the size of another
driver
(flow p.cnt * sizeof(struct
bst traffic flow prop)), which is vulnerable to an
integer overﬂow. This bug results in a much smaller
buffer being allocated that would actually be required
for the data. This overﬂow would not be particularly
problematic if it wasn’t for the fact that the originally
tainted length (i.e.,
the very large number) is later
used to determine how much data will be copied in
structure
Listing 1: An integer overﬂow in Huawei’s Bastet driver
that was discovered by DR. CHECKER
1 s t r u c t b s t
2
3
u i n t 3 2 t
u i n t 8 t v a l u e [ 0 ] ;
t r a f f i c f l o w p k g {
c n t ;
4 };
5 . . .
6 u i n t 8 t ∗ buf = NULL;
7 i n t b u f
8 s t r u c t b s t
9
10 i f
11
12
l e n = 0 ;
s i z e o f ( s t r u c t b s t
b r e a k ;
t r a f f i c f l o w p k g f l o w p ;
( c o p y f r o m u s e r (& flow p ,
a r g p ,
t r a f f i c f l o w p k g ) ) ) {
13 }
14
15 i f
16
17
18
30 }
31
32 i f
33
34
35
36
37
( 0 == f l o w p . c n t ) {
b a s t e t w a k e u p t r a f f i c f l o w ( ) ;
r c = 0 ;
b r e a k ;
20
e . g . , 0 x80000001 ∗ 0 x20 = 0 x20
l e n = f l o w p . c n t ∗
19 }
21 / / ∗∗ I n t e g e r o v e r f l o w bug ∗∗
22 / /
23 b u f
s i z e o f ( s t r u c t b s t
24
25 buf = ( u i n t 8 t ∗) k m a l l o c ( b u f
26 i f
27
28
29
(NULL == buf ) {
BASTET LOGE( ” k m a l l o c
r c = -ENOMEM;
b r e a k ;
f a i l e d ” ) ;
t r a f f i c f l o w p r o p ) ;
l e n , GFP KERNEL ) ;
( c o p y f r o m u s e r ( buf ,
a r g p + s i z e o f ( s t r u c t b s t
b u f
l e n ) ) {
BASTET LOGE( ” pkg c o p y f r o m u s e r
k f r e e ( buf ) ;
b r e a k ;
t r a f f i c f l o w p k g ) ,
e r r o r ” ) ;
f l o w p . cnt , n o t b u f
l e n , b y t e s
i n b u f !
t r a f f i c f l o w b y p k g ( buf ,
f l o w p . c n t ) ;
38 }
39 / / M o d i f i e s
40 r c = a d j u s t
41 . . .
buffer
the
flow p.cnt)), resulting in memory corruption.
(adjust traffic flow by pkg(buf,
the entire buffer.
There are many notable quirks in this bug that make
it prohibitively difﬁcult for na¨ıve static analysis tech-
niques. First,
the bug arises from tainted-data (i.e.,
argp) propagating through multiple usages into a dan-