This is about the "documentation inaccuracy" and the discussion on "scale_C".  
I really want to fix this before the release but I don't have much time atm.
As far as I understood, at the moment we can agree that having "C" as
parameter with "scale_C=True"  
is not perfect, as this doesn't agree with how "C" is used in the literature /
other software.  
I am not sure if there was a solution that we could agree on.  
I would like to have votes pro/con having a "duplicate" parameter C (which has
scale_C=False semantics) and alpha, which behaves as in the other linear
models. Another option would be to have just the "alpha" parameter.  
Any other suggestions are welcome.
I created this script: https://gist.github.com/2354823 to understand the
effect of "scale_C".  
Not sure if that helps.  
Results look like this:  
![true](https://camo.githubusercontent.com/ecb5d47a0be5d6b6ab4c33dbe14435b49b1116ebf43b21550328d836f6f1602b/687474703a2f2f692e696d6775722e636f6d2f366d4b31712e706e67)  
![false](https://camo.githubusercontent.com/7a4d6fa96dd71543182085a34ec0ac41d97752ee212e6371618aaa2304b429ca/687474703a2f2f692e696d6775722e636f6d2f474156694e2e706e67)  
These are grid searches for C=2**k with "shuffle & split" and different
fractions of training data.  
In principle the results should just be shifted by a factor of "n_samples".
Guess that is not a power of two so that makes it a bit different. Not sure I
like one more than the other.