title:Application-Level Autonomic Hardware to Predict and Preempt Software
Attacks on Industrial Control Systems
author:Lee W. Lerner and
Zane R. Franklin and
William T. Baumann and
Cameron D. Patterson
2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Application-level Autonomic Hardware to Predict and Preempt Software Attacks on
Industrial Control Systems
Lee W. Lerner, Zane R. Franklin, William T. Baumann, and Cameron D. Patterson
Bradley Department of Electrical and Computer Engineering
Virginia Tech
Blacksburg, VA 24061 U.S.A.
Email: {lwl, zanef, baumann, cdp}@vt.edu
Abstract—We mitigate malicious software threats to indus-
trial control systems, not by bolstering perimeter security, but
rather by using application-speciﬁc conﬁgurable hardware to
monitor and possibly override software operations in real time
at the lowest (I/O pin) level of a system-on-chip platform
containing a microcontroller augmented with conﬁgurable
logic. The process speciﬁcations, stability-preserving backup
controller, and switchover logic are speciﬁed and formally
veriﬁed as C code commonly used in control systems, but
synthesized into hardware to resist software reconﬁguration
attacks. In addition, a copy of the production controller task is
optionally implemented in an on-chip, isolated soft processor,
connected to a model of the physical process, and accelerated
to preview what the controller will attempt to do in the
near future. This prediction provides greater assurance that
the backup controller can be invoked before the physical
process becomes unstable. Adding trusted, application-tailored,
software-invisible, autonomic hardware is well-supported in a
commercial system-on-chip platform.
Keywords-industrial
control
threats; hardware root-of-trust; formal analysis
system security;
software
I. INTRODUCTION
The dark side to an increasingly automated physical world
is the potential for large scale disruption and destruction
caused by the malicious reprogramming of process con-
trol systems. Militaries and extremist groups are aware of
these vulnerabilities and opportunities, and the geopoliti-
cal effects may be as signiﬁcant as the development of
nuclear weapons. There is a summative effect from the
small (individual process control systems) to the large (an
electric grid). Power generation systems, in particular, have
demonstrated vulnerabilities, and cannot be quickly repaired
or replaced [1]. Descriptions of industrial control system
(ICS) zero-day exploits can be purchased from hackers
through on-line brokerages [2]. It
is not clear how to
discourage these attacks since anyone with Internet access
can develop and deploy cyberweapons, a country’s military
offers little protection of manufacturing and infrastructure
from cyberattacks, an attack’s ultimate source may be dif-
ﬁcult to determine, and the threat of retaliation may not
be an adequate deterrent. While ICS attacks are considered
a recent threat fast becoming “an element of almost any
crisis” [3], there is speculation that a Siberian gas pipeline
978-1-4799-2233-8/14 $31.00 © 2014 IEEE
DOI 10.1109/DSN.2014.26
136
was sabotaged in 1982 by CIA-directed implantation of
malware causing excessive gas pressure [4]. The explosion
had roughly one-sixth the power of the ﬁrst atomic bomb.
There are similarities but also important differences be-
tween protecting information and safeguarding physical in-
frastructure [5]. ICSes structured as Supervisory Control
and Data Acquisition (SCADA) systems have hierarchical,
networked computer infrastructure and human-computer in-
teraction, as well as edge nodes consisting of ruggedized
microcontrollers called Remote Terminal Units (RTUs) or
Programmable Logic Controllers (PLCs) that bridge the
cyber and physical worlds [11]. (Henceforth references to
PLCs also includes RTUs.) The non-edge PC nodes such
as Master Terminal Units (MTUs) monitor, coordinate,
optimize, and update the PLCs. This mixture of conven-
tional and embedded computing platforms enables attack
vectors common to IT environments while also exposing
microcontrollers running simple kernels designed for real-
time performance rather than intrusion protection. Many ICS
attacks focus on network protocol and supervisory platform
exploits to modify commands given to PLCs. Modifying
PLC ﬁrmware or control code achieves the same ends [7].
Protecting manufacturing, infrastructure, and future cyber-
physical systems requires unqualiﬁed resistance to cyber-
attacks created by adversaries with nation-scale resources.
While robust perimeter security and supervisory node in-
trusion resilience are necessary and should be the primary
defense, we consider the worst-case scenario where SCADA
networks have been penetrated, MTUs have been compro-
mised, and even PLCs have been reprogrammed [8]. This
may be accomplished through one or more avenues: insiders,
manufacturer’s maintenance ports, third party code, zero-day
exploits, and PC updates. Air gaps and effective physical
security measures are not a sufﬁcient defense, as evidenced
by Stuxnet [6]. TECEP (Trust Enhancement of Critical
Embedded Processes) is our method of ensuring process
stability in a way that that does not rely on trust in any
software layer on any ICS node. Isolation is achieved using
high-level synthesis (HLS) targeting conﬁgurable hardware
in a commercial system-on-chip IC used to implement
the PLC’s microcontroller [9]. Predicting future deviation
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:59:47 UTC from IEEE Xplore.  Restrictions apply. 
from normal operation is enabled by reuse of speciﬁcations
for normal system operation and accurate models for the
physical process. Normally these models are used only
during development, but TECEP retains them in the ﬁelded
platform.
While using redundancy to cope with sensor faults is a
reasonably well-solved problem, malicious software attacks
are a new and distinct area of concern [10]. Middle ground
is needed between viewing ICS cybersecurity as solely a
network- or supervisory-level concern, and overburdening
control system engineers with additional roles. Our approach
tries to accomplish this through integration with a conven-
tional model-based design ﬂow, synthesizing and formally
verifying hardware-implemented functions to monitor the
current and future state of physical process, and switching
to a stability-preserving backup controller if necessary. HLS
avoids the added complexity of using hardware description
languages, and modest performance requirements permit
hardware generation without iterative timing optimization.
Section II describes the conventional ICS development
process, and summarizes existing ICS-speciﬁc strategies
used to enhance security. TECEP’s system-on-chip platform
organization, and synthesis/analysis extensions to the model-
based design ﬂow are presented in Section III. Section IV il-
lustrates and assesses TECEP with the synthesis and veriﬁca-
tion of monitoring, predictive and preemptive enhancements
to a simple motor controller. Finally, Section V summarizes
completed and ongoing work.
II. CURRENT APPROACHES TO ICS DEVELOPMENT AND
SECURITY
PLCs periodically read sensor data y(t) from a physical
process (referred to as the plant), compute the error e(t)
between y(t) and the desired plant state w(t), and adjust
plant inputs u(t) (such as mechanical actuators) in order
to minimize |e(t)|. A simple example is adjusting the fuel
supply to a furnace when the furnace temperature changes.
Commonly used PID controllers compute e(t) by summing
proportional (present error), integral (past error), and deriva-
tive (future error) terms [11].
Control system engineering has enjoyed an enviable mar-
riage of theory and practice, and is one of the most widely
adopted examples of model-based design which has the
following steps:
1) Create a mathematical model of the plant either from
physical laws or by acquiring and analyzing real data.
2) Use the plant model to develop an effective control
3) Simulate the response of the system to inputs such as
a unit step change on w(t).
4) Synthesize controller code for a particular embedded
algorithm.
platform.
MATLAB/Simulink supports this methodology, and gener-
ates code with the Embedded Coder toolbox [12].
137
A. ICS-independent Security Techniques
Hardware and software architectures trickle down from
personal computing systems to embedded platforms in order
to match capabilities. Unfortunately threats also migrate, and
the defenses used to protect information are also needed to
protect control processes. We do not consider side-channel
or fault-injection attacks often associated with embedded
platforms since if one already has physical access to a con-
troller then there would be a more direct means of degrading
or destroying the physical processes. Rather, the main attack
vector to be mitigated is unsanctioned use of a network
for the purposes of sending new commands or software
to a PLC while perhaps simultaneously reporting normal
operating status to human operators. This was precisely the
modus operandi for Stuxnet.
Most defenses deﬁne one or more zones of trust, with
increased trust granted to the software and hardware inside
a given zone. Inner zones typically provide services to outer
zones as in the case of an operating system kernel. Hardware
mechanisms may help to prevent the unauthorized use of
resources inside a trusted zone. The ﬁrst security architecture
described in Table I requires privileged operations, such as
hardware and process management, to be performed by a
single kernel such as Linux. As the number of services
increases, however, the complexity of the service-providing
code makes it likely that bugs exist that can be probed
in an automated way and possibly used to the adversary’s
advantage. Potential weaknesses in this scheme include: all
applications run in the same zone, the kernel must be all
things to all applications, and reliance on defenses such
as ﬁrewalls receiving regular updates. According to Eugene
Spafford, ﬁrewalls were originally introduced as a stopgap
measure until host security was improved [13].
System architecture extensions may be provided to reduce
the attack surface for a subset of applications. For example,
TrustZone is ARM’s extension allowing certain applications
to run in a secure zone (SZ) running under a distinct
kernel
in a separate memory space and able to access
particular hardware resources unavailable to applications that
run in the normal zone (NZ) [14]. Both zones share the
same physical processor(s), which execute monitor mode
code when switching between zones. Although the SZ’s
kernel may be simpler than the NZ’s kernel, considerable
complexity and possible exploits likely remain. For example,
a vulnerability in the SZ kernel was used to jailbreak an
Android device [15].
As seen above, the standard approach for enhancing the
security of platforms required to run a variety of applications
has been to impose or extend a set of hardware-enforced,
restrictive processor modes. However, another approach may
be used if the platform is dedicated to domain-speciﬁc ap-
plications such as process control. The current generation of
Field-Programmable Gate Arrays (FPGAs) permit functions
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:59:47 UTC from IEEE Xplore.  Restrictions apply. 
SEPARATING A SYSTEM-ON-CHIP PLATFORM INTO A NORMAL ZONE (NZ) AND A SECURE ZONE (SZ)
Table I
Security Architecture
Standard single S/W kernel
SZ Internal Vulnerabilities
× No NZ and SZ separation.
× Kernel complexity exceeds current
formal analysis capabilities and may
have exploitable bugs.
Trusted execution environment × SZ kernel complexity still exceeds
such as ARM TrustZone
formal analysis capabilities and may
have exploitable bugs.
provides a NZ and a SZ
× S/W needed to switch processor(s)
between NZ and SZ.
√
Formal analysis of SZ’s trusted,
application-speciﬁc, H/W monitor.
TECEP adds a SZ with
application-speciﬁc, autonomic
H/W and S/W
SZ External Vulnerabilities
× Network access for reporting
and updates.
√
SZ S/W is isolated from NZ
S/W.
× Some SZ H/W resources such
as processors are shared with NZ
H/W resources.
√
SZ H/W and S/W are fully
isolated from NZ H/W and S/W.
S/W and H/W Authentication
× Relies on protocols and perimeter
security techniques requiring S/W
patches.
√
√
Secure boot of SZ kernel.
NZ versus SZ state awareness
can extend to bus peripherals such
as memory and I/O controllers, and
custom IP.
√
√
Cannot remotely update SZ H/W.
Prediction capability performs a
secure boot load of SZ sandbox
memory from external ﬂash.
to be implemented as software running on hard or soft
processors, or directly in custom hardware. Normally this
capability is used to improve system performance and/or
power attributes, perhaps by increasing the time and power
efﬁciency of cryptographic functions. As previewed in the
third row of Table I and described further in Section III,
TECEP instead exploits this ﬂexibility to invert software and
hardware authorities by implementing critical ICS functions
in formally veriﬁed PLC hardware blocks that cannot be
controlled or modiﬁed by any local or remote software.
B. ICS-speciﬁc Security Techniques
Security solutions proposed for general embedded plat-
forms are usually not optimized for ICS applications [16].
Because many plants are physically secure, intra-plant com-
munication integrity (to thwart false data injection on sensors
or false command injection on actuators) is not the sole
concern. Existing reliability analysis can use redundancy
to mitigate faults occurring in sensors and actuators. If
malicious sensor jamming is a possibility, C´ardenas et al.
apply anomaly-based intrusion detection theory for computer
systems and networks [17]. However, the ultimate objective
of ICS malware is PLC behavior modiﬁcation from process-
harming MTU commands or updates to control, kernel, and
driver code. Recent ICS-speciﬁc protection schemes seek to
close these attack vectors by replicating SCADA network
gateways [18] and MTUs [19].
Alternatively run-time monitoring software could attempt