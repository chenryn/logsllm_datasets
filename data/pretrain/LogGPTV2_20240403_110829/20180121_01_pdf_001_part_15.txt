最佳实践》
– 《记录动态格式化输出(ToB日志转换业务) - 阿里云RDS PostgreSQL, HybridDB for
PostgreSQL最佳实践》
– 《(新零售)商户网格化(基于位置GIS)运营 - 阿里云RDS PostgreSQL、HybridDB for
PostgreSQL最佳实践》
– 《强制数据分布与导出prefix - 阿里云pg, hdb pg oss快速数据规整外部表导出实践案例》
– 《日增量万亿+级 实时分析、数据规整 - 阿里云HybridDB for PostgreSQL最佳实践》
– 《ApsaraDB的左右互搏(PgSQL+HybridDB+OSS) - 解决OLTP+OLAP混合需求》
– 《Greenplum roaring bitmap与业务场景 (类阿里云RDS PG varbitx, 应用于海量用户 实时画
像和圈选、透视)》
数据同步通道
- 1
https://github.com/aliyun/rds_dbsync
数据同步通道
- 2
OSS外部表优化：
1、文件数=计算节点数
2、开启压缩
3、允许错误条数
4、超时参数
https://help.aliyun.com/document_detail/35457.html
数据同步通道
- 3
目标数据源选择PostgreSQL
https://help.aliyun.com/document_detail/47677.html
https://help.aliyun.com/document_detail/30269.html
数据写入实践
• 批量 or 单步
• 为什么 AO表写入有 IO放大
– https://github.com/digoal/blog/blob/master/201
711/20171116_01.md
• 如何提速
分布键选择建议
HDB PG
• 允许随机分布
• 分布键允许多列
• 如果有唯一、主键约束，必须与分布键一致
• 分布键选择，确保不出现倾斜
• 大表、建议经常被用于 JOIN的列
• https://github.com/digoal/blog/blob/master/201
607/20160719_02.md
行存与列存的选择
行存与列存的选择 阿里云扩展
-
行存与列存的选择
• https://github.com/digoal/blog/blob/master/201708/20170825_02.md
• https://github.com/digoal/blog/blob/master/201708/20170818_02.md
• https://github.com/digoal/blog/blob/master/201608/20160815_01.md
• append only table
– 批量写入、含少量DML
– 行存
• 查询较多字段、输出较多记录。 WHY?
– 列存
• 统计、JOIN、少量列查询
• heap row table
– 单步写入、含部分DML
非分布键 和
group by distinct
• https://github.com/digoal/blog/blob/master/201711/20171123_01.md
• 对于非分布键的分组聚合请求，Greenplum采用了多阶段聚合如下：
•
• 第一阶段，在SEGMENT本地聚合。
•
• 第二阶段，根据分组字段，将结果数据重分布。
•
• 第三阶段，再次在SEGMENT本地聚合。
•
• 第四阶段，返回结果给master，有必要的话master节点调用聚合函数
的final func（已经是很少的记录数和运算量）。
非分布键 内部多阶段
JOIN
• HDB PG全自动、无任何 JOIN限制
• 1、数据节点本地 JOIN - 解决网络开销问题
• 2、数据节点间自动重分布
– 小表自动广播
– 大表，按JOIN字段自动重分布
• 3、数据节点本地 JOIN
• 4、返回 JOIN结果
非分布键 内部多阶段
JOIN
• postgres=# explain analyze select count(*),c1 from a group by c1 ;
• QUERY PLAN
• -----------------------------------------------------------------------------------------------------------------------------------------------------
• Gather Motion 48:1 (slice2; segments: 48) (cost=1561155.53..1561156.80 rows=101 width=12) --第四阶段、上报结果
• Rows out: 101 rows at destination with 4004 ms to end, start offset by 1.742 ms.
• -> HashAggregate (cost=1561155.53..1561156.80 rows=3 width=12) --第三阶段、本地聚合
• Group By: a.c1
• Rows out: Avg 2.5 rows x 41 workers. Max 4 rows (seg9) with 0.004 ms to first row, 1277 ms to end, start offset by 26ms.
• -> Redistribute Motion 48:48 (slice1; segments: 48) (cost=1561152.00..1561154.02 rows=3 width=12) --第二阶段、重分布（仅少量数据走网络重分布）
• Hash Key: a.c1
• Rows out: Avg 118.2 rows x 41 workers at destination. Max 192 rows (seg9) with 2702 ms to end, start offset by 26 ms.
• -> HashAggregate (cost=1561152.00..1561152.00 rows=3 width=12) --第一阶段、本地聚合，收敛数据区间
• Group By: a.c1
• Rows out: Avg 101.0 rows x 48 workers. Max 101 rows (seg0) with 0.007 ms to first row, 2638 ms to end, start offset by 50 ms.
• -> Append-only Columnar Scan on a (cost=0.00..1061152.00 rows=2083334 width=4)
• Rows out: 0 rows (seg0) with 25 ms to end, start offset by 52 ms.
• Slice statistics:
• (slice0) Executor memory: 263K bytes.
• (slice1) Executor memory: 764K bytes avg x 48 workers, 764K bytes max (seg0).
• (slice2) Executor memory: 289K bytes avg x 48 workers, 292K bytes max (seg0).
• Statement statistics:
• Memory used: 128000K bytes
• Settings: enable_bitmapscan=off; enable_seqscan=off; optimizer=off
• Optimizer status: legacy query optimizer
• Total runtime: 4006.957 ms
• (22 rows)
分区表分区字段选择建议
HDB PG
• 支持范围、枚举分区
• 不建议与分布键一致
• 建议经常用于过滤的列
– 时间
– 枚举
分级存储功能
• https://help.aliyun.com/document_detail/35457.html
• 热数据
– 实例本地存储
父表
• 访问频次较低数据
– oss外部表存储
OSS_tbl1(201 OSS_tbl2(201
local tbl(s) OSS_tbl3(....)
7-01) 7-02)
– 压缩格式选择
• 继承与分区约束
– 每个OSS外部表负责一部分数据
– 使用约束
– 建立OSS外部表继承关系
索引选择
• 自动索引选择
– https://github.com/digoal/blog/blob/master/201706/20170617_01.md
• GiST
– 空间数据
• B-Tree
– 等值、区间、排序
• Bitmap
– https://github.com/digoal/blog/blob/master/201705/20170512_01.md
– 类似倒排
– value: 所有行号对应的bitmap
– 含100到1万个唯一值的列
统计信息采集调度
• 专治SQL执行计划不准。
• gp_autostats_mode
– none：不收集
– on_no_stats：没有统计信息时，收集
– on_change：当写入、更新量超过阈值
（gp_autostats_on_change_threshold参数设置的行数，默认
为20亿）后，自动收集统计信息。
• https://github.com/digoal/blog/blob/master/201712/2017
1211_03.md
队列管理
• CREATE RESOURCE QUEUE name WITH (queue_attribute=value [, ... ])
• where queue_attribute is:
• ACTIVE_STATEMENTS=integer
• [ MAX_COST=float [COST_OVERCOMMIT={TRUE|FALSE}] ]
• [ MIN_COST=float ]
资源使用
• [ PRIORITY={MIN|LOW|MEDIUM|HIGH|MAX} ]
隔离、
• [ MEMORY_LIMIT='memory_units' ]
控制
• | MAX_COST=float [ COST_OVERCOMMIT={TRUE|FALSE} ]
• [ ACTIVE_STATEMENTS=integer ]
• [ MIN_COST=float ]
• [ PRIORITY={MIN|LOW|MEDIUM|HIGH|MAX} ]
• [ MEMORY_LIMIT='memory_units' ]
• https://github.com/digoal/blog/blob/master/201708/20170821_01.md
执行计划
• postgres=# explain analyzeselect count(*) from t group BY c2;
• QUERY PLAN
• --------------------------------------------------------------------------------------------------------------------------------------------------------
• Gather Motion 48:1 (slice2; segments: 48) (cost=7469.24..7469.26 rows=1 width=16)
• Rows out: 1 rows at destination with 75 ms to end, start offset by 1.500 ms.
• -> HashAggregate (cost=7469.24..7469.26 rows=1 width=16)
• Group By: t.c2
• Rows out: 1 rows (seg42) with 0.003 ms to first row, 27 ms to end, start offset by 30 ms.
• -> Redistribute Motion 48:48 (slice1; segments: 48) (cost=7469.21..7469.23 rows=1 width=16)
• Hash Key: t.c2
• Rows out: 48 rows at destination (seg42) with 16 ms to end, start offset by 30 ms.
• -> HashAggregate (cost=7469.21..7469.21 rows=1 width=16)
• Group By: t.c2
• Rows out: Avg 1.0 rows x 48 workers. Max 1 rows (seg0) with 0.006 ms to first row, 24 ms to end, start offset by 29 ms.
• -> Seq Scan on t (cost=0.00..6710.14 rows=3163 width=8)
• Rows out: Avg 3166.7 rows x 48 workers. Max 3281 rows (seg7) with 16 ms to first row, 17 ms to end,start offset by 30 ms.
• Slice statistics:
• (slice0) Executor memory: 327K bytes.
• (slice1) Executor memory: 660K bytes avg x 48 workers, 660K bytes max (seg0).
• (slice2) Executor memory: 276K bytes avg x 48 workers, 292K bytes max (seg42).
• Statement statistics:
• Memory used: 128000K bytes
• Settings: enable_bitmapscan=off; enable_seqscan=off; optimizer=off
• Optimizer status: legacy query optimizer
• Total runtime: 77.142 ms
• (22 rows)
https://github.com/digoal/blog/blob/master/201712/20171204_02.md
实践
metascan+sort Key+index
工单ID 用户ID 订单ID 其他字段 其他字段
1、分布键（hash,随机） 2、sortKey 3、index
1.1、分区（list, range）
https://help.aliyun.com/knowledge_detail/59195.html
详细介绍
例子：
where 工单id=?，扫描单个数据节点
分布键：工单ID
where 用户id=?，扫描所有数据节点，单个分区
分区键：用户ID，范围分区
where 订单id=?，扫描所有数据节点，所有分区
实践
metascan+sort Key+index
工单ID 用户ID 订单ID 其他字段 其他字段
1、分布 2、sortKey 3、index
1.1、分区
实践
metascan+sort Key+index
工单ID 用户ID 订单ID 其他字段 其他字段
1、分布 2、sortKey 3、index
1.1、分区
...
...
...
大吞吐输出场景开发实践
https://github.com/digoal/blog/blob/master/201707/20170726_01.md
大数据并行计算，
高吞吐并行写OSS.
30MB/s/数据节点
估值计算
• 求UV（唯一值）
• 求UV增量（唯一值增量）
• HLL估值插件
• https://github.com/digoal/blog/blob/master/201608/20160825_02.md
毫秒级
日UV
select count(distinct uid) from t where dt='2017-11-11';
select # hll_uid from t where dt='2017-11-11';
滑动分析：最近N天UV
SELECT date, #hll_union_agg(users) OVER seven_days
FROM daily_uniques WINDOW seven_days AS (ORDER BY date ASC ROWS 6 PRECEDING);
每日流失UV
SELECT date, (#hll_union_agg(users) OVER two_days) -#users AS lost_uniques
FROM daily_uniques WINDOW two_days AS (ORDER BY date ASC ROWS 1 PRECEDING);
滑窗分析 与 都适用
- RDS PG HDB PG
• 估值滑窗 (最近 7天 UV)
– SELECT date, #hll_union_agg(users) OVER seven_days
FROM daily_uniques WINDOW seven_days AS
(ORDER BY date ASC ROWS 6 PRECEDING);
• 统计滑窗 (最近 7天精确 UV， SUM， AVG。。。 )
– SELECT date, count(distinct users) OVER seven_days,
sum(x) OVER seven_days, avg(x) OVER seven_days
FROM daily_uniques WINDOW seven_days AS
(ORDER BY date ASC ROWS 6 PRECEDING);
滑窗分析 与 都适用
- RDS PG HDB PG
• 估值滑窗(最近7天UV)
– SELECT date, #hll_union_agg(users) OVER seven_days FROM
daily_uniques WINDOW seven_days AS (ORDER BY date ASC ROWS 6
PRECEDING);
• 统计滑窗(最近7天精确UV， SUM，AVG。。。)
– SELECT date, count(distinct users) OVER seven_days, sum(x) OVER
seven_days, avg(x) OVER seven_days FROM daily_uniques WINDOW
seven_days AS (ORDER BY date ASC ROWS 6 PRECEDING);
• https://github.com/digoal/blog/blob/master/201711/20171129_01
.md
https://github.com/digoal/blog/blob/master/201711/20171129_01.md
查看数据倾斜
• 数据分布不均匀，导致性能差、存储空间
受限、木桶效应。
– https://github.com/digoal/blog/blob/master/201
708/20170821_02.md
查看锁等待
• https://github.com/digoal/blog/blob/master/
201705/20170521_01.md
查看数据膨胀、清理膨胀
• 堆表膨胀检测
– https://github.com/digoal/blog/blob/master/201
708/20170817_01.md
• AO表膨胀检测
– https://github.com/digoal/blog/blob/master/201
708/20170817_03.md
清理垃圾，行存、列存切换
• https://github.com/digoal/blog/blob/master/201
712/20171208_04.md
• https://github.com/digoal/blog/blob/master/201
708/20170817_03.md
• https://github.com/digoal/blog/blob/master/201
708/20170817_01.md
• https://github.com/digoal/blog/blob/master/201
608/20160815_01.md
数值类型的选择
• 如果有除法，并且需要确保精度，建议
或
float8 numeric
• 海量数据处理，建议采用 float8或 int8
• 数值类型
– numeric性能较低（内部实现的数据类型，有大
量 ）
memcpy
– float4, float8, int, int8性能较高
连接池
• pgbouncer
– https://github.com/digoal/blog/blob/master/201801/2018
0128_04.md
– https://www.linkedin.com/pulse/scaling-greenplum-
pgbouncer-sandeep-katta-
/?articleId=6128769027482402816
– https://pgbouncer.github.io/
• pgpool-II
– http://pgpool.net/mediawiki/index.php/Main_Page
常见热门问题
• 1. HybridDB for PostgreSQL表的分布键（distribute key）是否支持设置4
个列？文档上看到可以支持多列，但不知道最多可支持设置多少个列？
分布键可选数据类型是否有限制？
– 可以任意个列，类型不受限制。
• 2. HybridDB for PostgreSQL 分区表中分区个数最好设置在什么范围内
（按行存储和按列存储是否有区别）？每个分区的记录数最佳实践是
多少条？
– 列存单个分区在单个节点上的记录数建议不要超过1千万条记录。
• 例如100亿的表，规格是1024个SEGMENT，那么建议100/1024/0.1=1即不需要分区。
– 行存单个分区在单个节点上的记录数建议不要超过200万行。
– https://github.com/digoal/blog/blob/master/201803/20180328_01.md
常见热门问题
• 3. HybridDB for PostgreSQL 按列存储的表达到什么
数量级时需要进行表压缩？
– 建议开启压缩。
• 4. 行存表和列存表JOIN是否可行，是否有性能影响？
– 可以，不影响性能。
– 列存是按列存储的，如果经常访问少量列，建议使用
列存。
常见热门问题
• 5. HybridDB for PostgreSQL 按列存储表压缩时， 是选择全表压缩还是
选择只对某些列进行压缩？选择的标准是什么？
– 对于不经常访问的列，建议压缩，节约存储。
– 对于经常访问的列，如果CPU不是瓶颈，但IO是瓶颈，可以选择压缩。
– 默认的块大小和压缩比就可以了。如果对性能不关心，只关心压缩比，