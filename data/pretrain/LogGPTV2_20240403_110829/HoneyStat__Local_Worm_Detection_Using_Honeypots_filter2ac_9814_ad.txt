2
8
6
Infected Number in Honeynet
(a) D = 216
10
0
0
D=210,tr=10,γ=0.7 
D=210,tr=10,γ=0.9 
D=210,tr=100,γ=0.7
D=210,tr=100,γ=0.9
2
8
Infected Number in Honeynet
4
6
10
(b) D = 210
Fig. 4. Effect of HoneyStat network size, D, maximum percentage of vulnerable hosts,γ, and
time to redeploy after ﬁrst victim, tr, on the victim count. These graphs, drawn with α = 0.25;
N=500,000; scanrate=20 per time tick; Hitlist=1, show that with a larger IP space monitored by
HoneyStat, D, the detection time (as a precent of the infected Internet) improves greatly. Even
with only 210 IPs monitored, detection time is quick, requiring only a little more than 1% of the
Internet to be infected.
When the ﬁrst HoneyStat node becomes infected, the other nodes switch to the
vulnerable OS. This takes time tr, after which there will be u1 = Dγ vulnerable hosts.
After redeployment, the chance of getting the next victim improves. This is shown in
Eq. (4). The effect of D, γ and tr is shown in Figure 4. Here, we can see that after
redeployment we will quickly get enough victims when the whole Internet has a low
HoneyStat: Local Worm Detection Using Honeypots
55
infection percentage. This occurs because we obtain more vulnerable honeypots after
the HoneyStat array is switched to match the OS of the ﬁrst victim. Therefore, we get
higher chances of being hit by the worm. For example, if α = 0.25, D = 216, γ =
0.7, tr = 10, it is still very early to have 4 victims in the HoneyStat network, when only
0.013% Internet vulnerable hosts are infected. To have 10 victims, still only 0.0261%
Internet vulnerable hosts are infected. And we can see that tr = 10 or tr = 100, γ = 0.7
or γ = 0.9 do not affect the outcome very much. Instead, the size of honeynet D is the
most important factor. Thus, the delay in switching HoneyStat nodes does not play a
critical role in overall worm detection time.
4
3.5
3
2.5
2
1.5
1
0.5
)
%
(
e
g
a
t
n
e
c
r
e
P
n
o
i
t
c
e
f
n
I
t
e
n
r
e
t
n
I
0
8
α=10% 
α=25% 
α=50% 
α=75% 
α=100%
14
10
The Size of Honeynet (2x)
12
16
Fig. 5. Effect of α and D on Time (Infection Percentage) when HoneyStat network has a ﬁrst
victim. N=500,000, Scan rate=20 per time tick.
In section 4, we noted that machines can be massively multihomed, so that one
piece of hardware can effectively handle hundreds of IP addresses in multiple virtual
machines. From the discussion of D above, 211 is already a reasonable number of IP
addresses that can be used in our local early worm detection. Assuming we had a few
computers sufﬁcient to allow D = 211 and α = 0.25, we can see from Table 2 that the
ﬁrst victim appears when on average 0.1959% of Internet vulnerable hosts are infected.
Suppose γ = 0.75, tr = 10, then to have 5 victims in our honeynet (or enough to have
a minimal number of data points suggested in Section 6), it is still very early when only
0.4794% of the Internet’s vulnerable hosts are infected. When one IP is infected, we
reset the OS so that it can be infected again. This kind of “replacement” policy makes
the whole honeynet work as we have discussed above although there are only, say, 64
virtual machines running on every GSX server.
8 Conclusion
Local detection systems deserve further exploration. We have suggested that in addition
to increasing the quantity of data used by alert systems, the quality can be improved as
well. It has been said that if intrusion detection is like ﬁnding a needle in a haystack,
then a honeypot is like a stack of needles. Literally every event from a honeypot is
noteworthy. Honeypots are therefore used to create a highly accurate alert stream.
56
David Dagon et al.
Using logistic regression, we have shown how a honeypot alert stream can detect
worm outbreaks. We deﬁne three classes of events to capture memory, disk and network
activities of worms. The logit analysis can eliminate noise sampled during these events,
and identify a likely list of causes. Using extensive data traces of previous worm events,
we have demonstrated that HoneyStat can identify worm activity. An analytical model
suggests that, with enough multihomed honeypots, this provides an effective way to
detect worms early.
While participation in global monitoring efforts has value, we believe local network
strategies require exploration as well. Further work could include identiﬁcation of addi-
tional logistic models to sort through large sets of data, coordination of shared honeypot
events, integration with other intrusion detection techniques, and response.
Acknowledgments
We thank Christian Kreibich at the University of Cambridge for his helpful comments.
This work is supported in part by NSF grants CCR-0133629 and CCR-0208655 and
Army Research Ofﬁce contract DAAD19-01-1-0610. The contents of this work are
solely the responsibility of the authors and do not necessarily represent the ofﬁcial
views of NSF and the U.S. Army.
References
[AFV95]
[BGB03]
[CGK03]
[CLF03]
[CM02]
[Cor04]
[DW01]
[GHH01]
D. Anderson, T. Frivold, and A. Valdes. Next-generation intrusion detection ex-
pert system (NIDES): A summary. Technical Report SRI-CSL-95-07, Computer
Science Laboratory, SRI International, Menlo Park, California, May 1995.
V.H. Berk, R.S. Gray, and G. Bakos. Using sensor networks and data fusion for
early detection of active worms. In Proceedings of the SPIE AeroSense, 2003.
Z. Chen, L. Gao, and K. Kwiat. Modeling the spread of active worms. In Proceed-
ings of the IEEE INFOCOM 2003, March 2003.
S. Cheung, U. Lindqvist, and M. W. Fong. Modeling multistep cyber attacks for
scenario recognition. In Proceedings of the Third DARPA Information Survivability
Conference and Exposition (DISCEX III), Washington, D.C., April 2003.
F. Cuppens and A. Mi`ege. Alert correlation in a cooperative intrusion detection
framework. In Proceedings of the 2002 IEEE Symposium on Security and Privacy,
pages 202–215, Oakland, CA, May 2002.
Joseph Corey. Advanced honey pot identiﬁcation and exploitation. (fake) Phrack,
No. 63, 2004.
H. Debar and A. Wespi. The intrusion-detection console correlation mechanism. In
4th International Symposium on Recent Advances in Intrusion Detection (RAID),
October 2001.
R.P. Goldman, W. Heimerdinger, and S. A. Harp. Information modleing for in-
trusion report aggregation. In DARPA Information Survivability Conference and
Exposition (DISCEX II), June 2001.
[GSQ+04] Guofei Gu, Monirul Sharif, Xinzhou Qin, David Dagon, Wenke Lee, and George
Riley. Worm detection, early warning and response based on local victim informa-
tion. Submitted for review, 2004.
HoneyStat: Local Worm Detection Using Honeypots
57
[HL00]
[Inc03]
[Ins]
[JPBB04]
[JX04]
[Kal60]
[KCW93]
[Kor04]
[Kre03]
[KW93]
[Lem01]
[LLO+03]
[LUR03]
[LUR04]
[MHL94]
D.W. Hosmer and S. Lemeshow. Applied Logistic Regression. Wiley-Interscience,
2000.
Immunix Inc. Stackguard. http://www.immunix.org/stackguard.html, 2003.
SANS Institute. http://www.sans.org.
Jaeyeon Jung, Vern Paxson, Arthur W. Berger, and Hari Balakrishnan. Fast portscan
detection using sequential hypothesis testing. In 2004 IEEE Symposium on Security
and Privacy, 2004.
Xuxian Jiang and Dongyan Xu. Collapsar: A vm-based architecture for network
attack detention center. http://www.cs.purdue.edu/homes/jiangx/collapsar/, 2004.
R.E. Kalman. A new approach to linear ﬁltering and prediction problems. Transac-
tion of the ASME–Journal of Basic Engineering, March, 1960.
J.O. Kephart, D.M. Chess, and S.R. White. Computers and epidemiology. 1993.
Kostya Kortchinsky. Vmware ﬁngerprinting counter measures. The French Hon-
eynet Project, 2004.
Christian Kreibich. Honeycomb automated ids signature creation using honeypots.
http://www.cl.cam.ac.uk/ cpk25/honeycomb/, 2003.
J.O. Kephart and S.R. White. Measuring and modeling computer virus prevalence.
In Proceedings of IEEE Symposium on Security and Privacy, 1993.
Jonathan Lemon. Kqueue: A generic and scalable event notiﬁcation facility. pages
141–154, 2001.
John Levine, Richard LaBella, Henry Owen, Didier Contis, and Brian Culver. The
use of honeynets to detect exploited systems across large enterprise networks. In
Proceedings of the 2003 IEEE Workshop on Information Assurance, 2003.
LURHQ. Msblast case study. http://www.lurhq.com/blaster.html, 2003.
LURHQ. Witty worm analysis. http://www.lurhq.com/witty.html, 2004.
B. Mukherjee, L. T. Heberlein, and K. N. Levitt. Network intrusion detection. IEEE
Network, May/June 1994.
[MMDD02] B. Morin, L. M´e, H. Debar, and M. Ducass´e. M2d2: A formal data model for ids
alert correlation. In Proceedings of the 5th International Symposium on Recent
Advances in Intrusion Detection (RAID), October 2002.
D. Moore. Code-red: A case study on the spread and victims of an internet worm.
http://www.icir.org/vern/imw-2002/imw2002-papers/209.ps.gz, 2002.
D. Moore. Network telescopes: Observing small or distant security events.
http://www.caida.org/outreach/presentations/2002/usenix sec/, 2002.
[Moo02b]
[Moo02a]
[Par04]
[PN97]
[NCR02]
[MSVS03] D. Moore, C. Shannon, G. M. Voelker, and S. Savage. Internet quarantine: Require-
ments for containing self-propagating code. In Proceedings of the IEEE INFOCOM
2003, March 2003.
P. Ning, Y. Cui, and D.S. Reeves. Constructing attack scenarios through correla-
tion of intrusion alerts. In 9th ACM Conference on Computer and Communications
Security, November 2002.
Janak J Parekh. Columbia ids worminator project.
http://worminator.cs.columbia.edu/, 2004.
P. A. Porras and P. G. Neumann. EMERALD: Event monitoring enabling responses
to anomalous live disturbances. In National Information Systems Security Confer-
ence, Baltimore MD, October 1997.
Niels Provos. A virtual honeypot framework.
http://www.citi.umich.edu/techreports/reports/citi-tr-03-1.pdf, 2003.
X. Qin, D. Dagon, G. Gu, W. Lee, M. Warﬁeld, and P. Allor. Technical report.
X. Qin and W. Lee. Statistical causality analysis of infosec alert data. In Proceed-
ings of the 6th International Symposium on Recent Advances in Intrusion Detection
( RAID 2003), Pittsburgh, PA, September 2003.
[QDG+]
[QL03]
[Pro03]
58
David Dagon et al.
[Sta01]
[Sei02]
[Sko02]
[Spi03]
[SPN02]
[QVWW98] D. Qu, B. Vetter, F. Wang, and S.F. Wu. Statistical-based intrusion detection for
OSPF routing protocol. In Proceedings of the 6th IEEE International Conference
on Network Protocols, Austin, TX, October 1998.
Kurt Seifried. Honeypotting with vmware - basics. 2002.
E. Skoudis. Counter Hack. Upper Saddle River, NJ: Prentice Hall PTR, 2002.
Lance Spitzner. Honeypots: Tracking Hackers. Addison Wesley, 2003.
S. Staniford, V. Paxson, and N.Weaver. How to Own the Internet in Your Spare
Time. In Proceedings of 2002 Usenix Security Symposium, 2002.
S. Staniford. Code red analysis pages: July infestation analysis.
http://www.silicondefense.com/cr/july.html, 2001.
Inc. VMWare. Gsx server 3. http://www.vmware.com/products/server, 2004.
A. Valdes and K. Skinner. Probabilistic alert correlation. In Proceedings of the
4th International Symposium on Recent Advances in Intrusion Detection (RAID),
October 2001.
Matthew M. Williamson. Throttling viruses: Restricting propagation to defeat ma-
licious mobile code. Technical report, 2002. HPL-2002-172.
Matthew M. Williamson and Jasmin L´eveill´e. An epidemiological model of virus
spread and cleanup. Technical report, 2003. HPL-2003-30.
[VMW04]
[VS01]
[Wil02]
[WL03]
[WVGK04]
[WPSC03] N. Weaver, V. Paxson, S. Staniford, and R. Cunningham. A taxonomy of computer
worms. In 2003 ACM Workshop on Rapid Malcode (WORM’03). ACM SIGSAC,
October 2003.
J. Wu, S. Vangala, L. Gao, and K. Kwiat. An efﬁcient architecture and algorithm for
detecting worms with various scan techniques. In Proceedings of the 11th Annual
Network and Distributed System Security Symposium (NDSS’04), February 2004.
to appear.
Vinod Yegneswaran, Paul Barford, and Somesh Jha. Global intrusion detection in
the domino overlay system. In Proceedings of NDSS, 2004.
[YBJ04]
[ZGGT03] C. C. Zou, L. Gao, W. Gong, and D. Towsley. Monitoring and early warning for
internet worms. In Proceedings of 10th ACM Conference on Computer and Com-
munications Security (CCS’03), October 2003.
C. C. Zou, W. Gong, and D. Towsley. Code red worm propagation modeling and
analysis. In Proceedings of 9th ACM Conference on Computer and Communica-
tions Security (CCS’02), October 2002.
[ZGT02]