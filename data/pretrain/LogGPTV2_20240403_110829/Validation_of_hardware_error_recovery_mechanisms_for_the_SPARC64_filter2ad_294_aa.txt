title:Validation of hardware error recovery mechanisms for the SPARC64
V microprocessor
author:Hisashige Ando and
Ryuji Kan and
Yoshiharu Tosaka and
Keiji Takahisa and
Kichiji Hatanaka
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
Validation of Hardware Error Recovery Mechanisms
for the SPARC64 V Microprocessor
Hisashige Ando l
, Ryuji Kanl
, Yoshiharu Tosaka2
, Keiji Takahisa3
, Kichiji Hatanaka3
1 Fujitsu Ltd., 2 Fujitsu Laboratories, 3 Research Center for Nuclear Physics, Osaka University
hando@jpfujitsu. com, kane ryuji@jpjujitsu. com, tosaka@labsjujitsu. com,
takahisa@rcnp. osaka-u. ac.jp, hatanaka@rcnp. osaka-u. acjp
Abstract
incorporates
The SPARC64 V microprocessor is designedfor use
in high-reliability, large-scale unix servers. In addition
the
to implementing ECC for large SRAM arrays,
SPARC64 V microprocessor
error
detection and recovery mechanisms for processor logic
circuits and smaller SRAM arrays. The effectiveness of
these error recovery mechanisms was validated via
accelerated neutron testing of Fujitsu's commercial
unix server,
the PRIMEPOWER 650. Soft errors
generated in SRAM arrays were completely recovered
by the implemented hardware mechanisms, and only
6.4% of the estimated neutron-induced logic circuit
faults manifested as errors, 76% of which were
recovered by hardware. From these tests, the soft error
failure rate of the SPARC64 V microprocessor due to
atmospheric neutron hits was confirmed to be well
below 10 FIT.
1.
Introduction
Soft errors caused by atmospheric neutron hits are a
significant cause of failure in VLSI microprocessors [1].
Sensitivity to such failures increases with the level of
integration, which continues to grow at a rapid rate with
Moore's law. To protect against soft error failures, the
SPARC64 V microprocessor implements error detection
and recovery mechanisms for logic circuits and small
SRAM arrays in addition to protection of large SRAM
arrays.
of
error
and
Validation
recovery
mechanisms have been carried out using a wide range of
fault injection methods [2][6][7].
detection
Fault
injection methods include electrical
fault
injection at the I/O pins and software simulation. Faults
that can be injected using the first method are limited to
physical access through the I/O pins and cannot access
internal nodes. With software simulation, faults can be
injected into the internal nodes, but the number of fault
injection cases evaluated is limited by the speed of the
software logic simulator. For both methods, it is difficult
to guarantee that the injected faults are sufficiently
representative of soft error patterns generated by
atmospheric neutron hits.
Physical fault injection using radioactive isotopes
can generate soft errors in internal nodes. But, due to the
short penetration distance of alpha-particles,
the
isotopes must be placed at the bare surface of an LSI
chip. A heavy ion beam has also been used to inject
faults into packaged LSI chips [3], and Kellington et al.
[8] reported SRAM and logic errors generated in a
POWER6 microprocessor using a proton beam.
In a number of studies, a neutron beam has been
used for fault injection. The ASCI Q supercomputer
suffered significant number of cache SRAM errors due
to its size (total of 8192 CPUs) and a high altitude, high
neutron hit location (Los Alamos). Harris [5] analyzed
observed cache SRAM errors in ASCI Q generated by
atmospheric neutron hits
and compared it with
LANSCE neutron beam test results. Constantinescu [9]
used the LANSCE neutron source to inject errors into
Itanium microprocessors.
The authors injected faults
into SPARC64 V
microprocessors using the white neutron beam facility at
Osaka University's RCNP and measured SRAM and
logic errors that were generated [10]. As the energy
spectrum of the LANSCE and RCNP neutron beams
closely match that of atmospheric neutrons,
these
accelerated tests are considered to be a good recreation
of soft error damage due to atmospheric neutron hits.
A more in-depth comparison of various
injection methods is presented by ArIat et al. [4].
fault
1-4244-2398-9/08/$20.00 ©2008 IEEE
62
DSN 2008: Ando et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:09:06 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
2.
SPARC64 V microprocessor
2.1. Error handling mechanisms
[12][13]
The SPARC64 V microprocessor
is
designed for mission-critical unix servers. In order to
achieve un-interrupted operation, these servers must be
resistant to soft errors. Also, data integrity is highly
important because of the dangers that silent data
corruption (SDC) can pose in mission-critical systems.
To meet these requirements, the processor was designed
not only to correct SRAM errors, but also to detect
errors in logic circuits and to recover from those errors
when practica1.
The SPARC64 V is fabricated using 90nm bulk
CMOS technology with 10-layer Cu metallization.
Processor specifications are summarized in Table.1.
Table 1. 90nm SPARC64 V microprocessor
specifications
Technology
90nm bulk CMOS, 10 layer Cu metallization
Chip size
18.46mm x 15.94mm
Clock Frq.
2.16GHz
Power
dissipation
CPU Core
Max 65W @Vdd=-1V, 2.16GHz
Single Core, 4 inst. decode 0-0-0,
-240K Latches
Caches
L1$:128KB+128KB, L2$: 4MB
The SPARC64 V integrates approximately 45Mbits
of SRAM, 240K latches and 15M transistors
in
combinatorial logic gates. Because neutron-induced soft
error rates for a RAM cell and a latch bit are on the same
order of magnitude,
large SRAM arrays are more
sensitive to neutron hits and should be addressed first
when
recovery
mechanisms.
designing
and
error
detection
The largest SRAM array on the SPARC64 V chip is
a 4MB level-2 unified cache. The level-2 cache data
array and associated tag array are protected by SECDED
ECC.
There are three smaller cache arrays of 128KB each,
namely the level-1 instruction cache, level-1 data cache
and branch history cache (BRHIS). The level-1 data
cache is write-back and protected by the same SECDED
code as the level-2 cache.
The level-1 instruction cache and BRHIS are
covered by parity check. When an error is detected
during level-1 instruction cache read, the read entry is
invalidated and re-fetched from the ECC-protected
level-2 cache. An error in BRHIS is treated as a cache
miss and the processor delays execution of the
conditional branch instruction until the correct branch
address is calculated. The processor takes a minor
performance hit but
is able to continue correct
instruction execution.
Tags for level-1 instruction and data caches are
parity-protected. Both level-1 caches are inclusion
caches; tag information is duplicated in the level-2 tag.
When a parity error is detected in a level-1 tag access,
the level-2 tag is interrogated for the correct copy.ofthe
tag. The level-1 cache access is then re-executed.
The last major SRAM array on the chip is the
Translation Lookaside Buffer (TLB). TLB is protected
by parity check and a parity error in the TLB is treated as
a miss. The correct page table entry is fetched from the
ECC-protected main memory during re-execution.
In addition to implementing cache and TLB
protection, the SPARC64 V is designed to detect single
bit SRAM errors in other smaller SRAM arrays and
recover from those errors as well.
The processor logic circuits are protected by byte
parity check to detect single bit logic errors in each byte.
The placement of parity checkers are shown in
Figure1. Parity check bits are calculated at the location
of new data value generation and passed with the
associated data through the processor logic circuits.
Parity bits are checked at the receiving end. As shown in
Figure1, most of the data and address buses are covered
by parity check.
Arithmetic/logic units are equipped with byte parity
predictors. The byte parity predictors calculate the parity
bits for each output byte ofan arithmetic/logic unit using
the same input signals as the unit to be checked. These
independently calculated byte parity bits are compared
with the byte parity bits calculated from the output ofthe
arithmetic/logic unit.
Multipliers are checked with a modulo-3 scheme.
Given A, Band P are a multiplier, a multiplicand and a
product, then the equation
holds. Mod3(A) and Mod3(B) are calculated from A
and B respectively and multiplied. Modulo-3 of the
resulting product is compared with Mod3(P), which is
calculated from P.
The byte parity predictors in the arithmetic/logic
unit do not detect point errors that result in an even
number of bit flips in the output byte, and the modulo-3
scheme used in the multipliers do not detect point errors
that give the same modulo-3 residue. These checks,
however, do detect the majority of single point errors
and are cost-effective compared to a full duplication and
compare implementation.
When a parity error is detected in the logic circuits
or small SRAM arrays, the processor stops issuing new
1-4244-2398-9/08/$20.00 ©2008 IEEE
63
DSN 2008: Ando et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:09:06 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
BTAC
§> Data parity
Figure 1. The locations of parity checkers in the SPARC64 V microprocessor
Table 2. Error detection and recovery methods of SPARC64 V microprocessor
L11$ Data, TLB
BRHIS
L11$ & L1D$ Tag
Error Detection
Parity
Parity
Recovery
Invalidate & Miss
Branch Miss-prediction Recovery
Parity+Dupiication
Correct with L2$ Tag interrogation
L1D$ Data, L2$ Data & Tag
Registers
ALU, Shifter, VIS
MulUDiv
SECDED
Parity
Parity Prediction
Residue check +Parity Prediction
Hardware ECC
Instruction Retry
instructions and clears all intennediate states. It then
restarts execution at the instruction directly following
the last correctly executed instruction by using the
check-pointed states. This action is called instruction
retry.
The error detection and error recovery methods of
the processor are summarized in Table 2.
the
additional
The check-point and instruction retry mechanisms
are implemented in the processor for recovery from
branch misprediction. Thus,
cost
associated with utilizing these mechanisms for error
recovery is small. Furthennore, many microprocessors
today feature either ECC or byte parity for large on-chip
SRAM arrays. Compared with those microprocessors,
the SPARC64 V microprocessor
requires
additional transistors for implementing byte parity bits,
byte parity predictors and the associated parity checkers
in the logic circuits and small SRAM arrays.
only
The number of transistors devoted to the error
detection mechanisms
SPARC64 V
microprocessor is about 10% of the transistors for logic
the
of
gates, latches and parity-protected small SRAM arrays.
2.2. Error detection and correction estimate
Of
the
--240K latches
in the SPARC64 V
microprocessor, --30K latches are used for chip testing,
logging and other functionality that do not affect correct
processor execution. Only --210K latches need to be
considered, ofwhich --180K latches are parity protected.
Among the parity protected latches, --140K latches
hold transient data, and errors in these latches are
cleared at the start of instruction retry and do not cause
system failures. The remaining --30K latches are not
covered by parity check, which gives a latch parity
coverage percentage of 86%.
Parity coverage does not indicate the percentage of