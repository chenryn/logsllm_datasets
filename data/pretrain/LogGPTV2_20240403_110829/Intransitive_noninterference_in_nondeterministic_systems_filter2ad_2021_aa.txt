title:Intransitive noninterference in nondeterministic systems
author:Kai Engelhardt and
Ron van der Meyden and
Chenyi Zhang
Intransitive Noninterference in Nondeterministic Systems∗
Kai Engelhardt
Computer Science and
Engineering, The University of
New South Wales, Sydney,
PI:EMAIL
NSW 2052, Australia
Ron van der Meyden
Computer Science and
Engineering, The University of
New South Wales, Sydney,
NSW 2052, Australia
PI:EMAIL
†
Chenyi Zhang
Information Technology and
Electrical Engineering, The
University of Queensland,
PI:EMAIL
Brisbane, QLD 4072, Australia
ABSTRACT
This paper addresses the question of how TA-security, a semantics
for intransitive information-ﬂow policies in deterministic systems,
can be generalized to nondeterministic systems. Various deﬁni-
tions are proposed, including deﬁnitions that state that the system
enforces as much of the policy as possible in the context of attacks
in which groups of agents collude by sharing information through
channels that lie outside the system. Relationships between the
various deﬁnitions proposed are characterized, and an unwinding-
based proof technique is developed. Finally, it is shown that on a
speciﬁc class of systems, access control systems with local non-
determinism, the strongest deﬁnition can be veriﬁed by checking a
simple static property.
Categories and Subject Descriptors
D.4.6 [Security and Protection]: Information ﬂow controls
Keywords
access control, information-ﬂow, nondeterminism, noninterference,
security
1.
INTRODUCTION
The theory of information ﬂow security has been studied most
extensively with respect to transitive security policies, motivated by
the lattices associated with military multi-level security policies. It
has long been recognised, however, that even in this setting, richer
types of policies are required in order to deal with trusted compo-
nents such as downgraders, which may violate a transitive policy.
An example of this is given in Figure 1 which presents an abstract
architecture for a system in which two multi-level secure machines
M1 and M2 communicate across the internet.
∗Research supported by Australian Research Council Discovery
Grant DP1097203.
†Work of the third author conducted while employed at The Uni-
versity of New South Wales.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.
M1
M2
H1
E1
E2
H2
L1
NI1
N
NI2
L2
Figure 1: Architecture for a MILS system.
Each machine Mi contains a high-level domain Hi and a low-
level domain Li, with the usual policy Hi (cid:54)
(cid:55)→ Li, intuitively requir-
ing that no high-level information ﬂow to the low level domain,
enforced between the two. The internet is represented by the do-
main N. Additionally, there are two domains E1, E2 that represent
downgraders that are responsible for encrypting and decrypting all
communications between the domains H1, H2, as well as domains
NI1, NI2 representing the network interface in each machine.
Globally, the security policy requires that there is no direct ﬂow
of information from the domains Hi to the domains N, NIj or Lj.
All such ﬂow of information must be mediated by the domains Ei.
This does not provide a complete guarantee of all security proper-
ties that one might wish the system to satisfy, but it helps to focus
proofs that high-level information remains secure onto the speciﬁc
trusted components Ei. The intention of the architecture is to de-
compose the proof of the desired security property that high-level
information does not ﬂow to low domains (even if only the compo-
nents Ei are trusted), to the proof that the components Ei properly
encrypt all output (and possibly also, that they maintain a trafﬁc
stream to circumvent trafﬁc analysis), and the fact that the archi-
tecture is enforced. We refer the reader to recent work on MILS [4]
for a more detailed explanation of this idea.
In order to provide an account of formal security veriﬁcation that
captures the intuitions underlying such architectures, we ﬁrst need
a mathematically precise semantics for policies in the form of in-
transitive relations (note, e.g., that in Figure 1 we have H1 (cid:55)→ E1
and E1 (cid:55)→ NI1 but not H1 (cid:55)→ NI1). Compared to classical in-
formation ﬂow theory for transitive policies, this area is much less
studied.
One of the landmarks in the area remains the work of Rushby [21],
which clariﬁed earlier work of Haigh and Young [10]. In particular,
Rushby provides an proof method using unwinding relations that
may be used to show security of a system, and moreover proves
that secure systems can be concretely constructed by using an ac-
cess control discipline satisfying a simple syntactic condition. This
latter result is signiﬁcant in that it can be understood as providing
a more satisfactory basis for ideas from Bell and La Padula [2],
addressing complaints about the well-foundedness of Bell and La
869Padula’s methods [14], by giving semantic meaning to the notions
of read and write.
Recently, van der Meyden [24] pointed to weaknesses in Rushby’s
deﬁnitions and provided improvements, including a new deﬁnition
of security called TA-security, that yield results similar to Rushby’s
but which make the unwinding proof method and access control
discipline not just sound but also complete for security (showing
that any secure system can be proved to be secure using the method,
or constructed so that security is easily checkable.) This yields a
pleasant theory in which the deﬁnition of security, proof methods
and engineering discipline are tightly integrated.
This theory is limited to deterministic systems, however. There
have been proposals for semantics of intransitive policies in non-
deterministic systems [3, 19, 13, 1, 26], but none of these works
deals with access control systems with nondeterminism. Our con-
tribution in this paper is to develop the ﬁrst such generalization,
taking as our starting point van der Meyden’s formulation of the
deterministic case.
We ﬁrst investigate how to generalize the notion of TA-security
to the nondeterministic setting. After setting up the semantic frame-
work in Section 2, in Section 3 we carefully tease out a number
of dimensions that are relevant to the formulation of the seman-
tics for intransitive policies in nondeterministic systems. Some
deﬁnitions in the literature, we believe, have made inappropriate
choices with respect to these ingredients, and in some, critical is-
sues have been ignored. In particular, we argue that it is impor-
tant in non-deterministic systems to base the deﬁnition of security
on the effect of actions on agents’ history of actions and observa-
tions, whereas some deﬁnitions in the literature have considered
only their effect on single observations. We also recall from the
literature on noninterference with respect to transitive policies the
notion of persistence, which helps with an important distinction be-
tween deducibility and causality that emerges in nondeterministic
systems. Finally, we present an example showing that while col-
lusion attacks can be ignored in deterministic systems, they need
to be taken into account in nondeterministic systems. Many of the
deﬁnitions in the literature do not take such attacks into account.
We give our generalizations of TA-security to the nondetermin-
istic setting in Section 4. We show that there are subtleties in the
formulation of deﬁnitions that cover collusion attacks: it makes a
difference, to what the attackers can deduce, whether they share
information during a run of the system, or only at completion of
the run. This leads us to a spectrum of deﬁnitions, depending on
whether and, if so, how, collusion is treated, and via application
of persistence or not, whether the deﬁnition is causal or deductive.
We discuss some special cases of policies and systems in Section 5,
where we show that our spectrum of deﬁnitions collapses to two
well-known deﬁnitions of security in the case of deterministic sys-
tems or a two agent policy.
We then proceed, in Section 6, to develop an unwinding proof
technique that is sound for all our deﬁnitions.
In Section 7, we
present a generalization of access control systems that covers non-
determinism, and identify conditions on such systems that imply
that all our deﬁnitions of security hold. We discuss related work
in Section 8 and conclude with a discussion of future directions for
research in Section 9.
2. SYSTEMS MODEL
Goguen and Meseguer [7] developed a theory of information-
ﬂow that has formed a starting point for later research. They intro-
duced the following policy model.
Deﬁnition 1. A noninterference policy for a set U of security
domains is a reﬂexive binary relation (cid:55)→ on U, representing the
permitted interferences between domains.
Intuitively, u (cid:55)→ v represents that the policy permits information
to ﬂow from domain u to domain v. Another intuition for this is
that actions of domain u are permitted to have causal effects on, or
interfere with, domain v. Conversely, when u (cid:54)
(cid:55)→ v, domain u is
not permitted to interfere with v. Reﬂexivity is assumed since, in
general, nothing can be done to prevent ﬂows of information from a
domain to itself, so it is not sensible for the policy to prohibit this. A
machine with domains U is a tuple M = (S, s0, A,−→, obs, dom)
with a set S of states, including a designated initial state s0 ∈ S,
a set A of actions, a (nondeterministic) transition relation −→ ⊆
S × A× S an observation function obs : U → (S → O), for some
set O, and a domain function dom : A → U. We write obsu for
the function obs(u) : S → O, which represents the observation
that domain u makes at each state of the machine. Following much
of the security literature, we assume that the transition relation is
input-enabled: for all states s and actions a, there exists a state t
a−→ t. This helps to prevent enabledness of actions
such that s
being a source of information. A machine is deterministic if for all
states s, t, t(cid:48) and actions a, if s a−→ t and s a−→ t(cid:48) then t = t(cid:48).
Notational and diagrammatic conventions.
Sequences play an important role in this paper. Most of the time,
we denote a sequence such as [a, b, c] by just abc, however, if the
sequence elements have structure themselves, or if confusion is
likely to arise, we tend to separate sequence elements with a dot:
a · b · c.
A concise way to deﬁne A and dom is to list, for each u ∈ U,
the set Au = { a ∈ A | dom(a) = u } of actions of that domain.
Given a domain u, we write (cid:55)→u for { v ∈ U | v (cid:55)→ u } and
(cid:55)→u for U \ (cid:55)→u = { v ∈ U | v (cid:54)
(cid:55)→ u }. We also write u(cid:55)→ for
{ v ∈ U | u (cid:55)→ v } and u(cid:54)
(cid:55)→ for U \ (cid:55)→u.
We use the following convention in diagrams representing ma-
chines. States are represented by circles labelled internally by the
state name. The initial state is always named s0. A transition
s a−→ t is represented by an edge from s to t labelled by a. To re-
move clutter from diagrams, we elide edges corresponding to self-
a−→ s unless we wish to draw attention to them; thus, if
loops s
there is no edge from a state labelled by an action a, then using the
input-enabled assumption, we infer that the missing edge is a self-
loop. (Note that if there does exist an edge labelled a from state s,
we do not make this inference.) States are labelled externally by
observations of some of the domains: the details of this depend on
the example and are given with each diagram.
a1−→ s1 . . . an−→ sn in which
n ≥ 0, the si ∈ S are states (the ﬁrst being the initial state) and
the ai ∈ A are actions, such that (si−1, ai, si) ∈ −→ for all i =
1 . . . n. We write R(M ) for the set of runs of machine M. The
function last maps a nonempty sequence to its ﬁnal element. A
state is reachable if it is the ﬁnal state of some run. The sequence
of all actions in a run r is denoted Act(r). With M implicit, we
also write R(α) for the set of r ∈ R(M ) such that Act(r) = α.
For a domain u, we write Act u(r) for the subsequence of actions
a in Act(r) with dom(a) = u.
A run is a sequence of the form s0
The view of a run obtained by a domain, or group of domains,
records all the actions and observations of the domain or group dur-
ing the run, except that stuttering observations are collapsed to a
single copy to model that the agent/group operates asynchronously,
so does not perceive the passing of time unless some event hap-
pens to it. Let X ⊆ U be a nonempty set of domains. We de-
870(cid:54)
ﬁne the joint observation function of X as obsX : S → OX by
obsX (s)(u) = obsu(s) for u ∈ X. That is, obsX (s) is the tu-
ple of observations made by the domains u ∈ X on state s. The
view function viewX : R(M ) → (OX )+(A(OX )+)∗ is deﬁned
inductively by viewX (s0) = obsX (s0) and
viewX (r a−→ q) =(cid:40)
viewX (r) · a · obsX (q)
viewX (r) ˆ◦ obsX (q)
if dom(a) ∈ X
otherwise
where “ˆ◦” denotes absorptive concatenation, that is,
(cid:40)
α ˆ◦ a =
if last(α) = a
α
α · a otherwise.
We write the special case where X = {u} is a singleton as viewu.
We note that viewX (r) may contain information about the order
of actions from domains in X that cannot be deduced from the
collection of views (viewu(r))u∈X. Intuitively, viewX (r) is the
information that the group would obtain in r when the members of
the group share their local information with the group at each step
of the run, whereas the collection (viewu(r))u∈X corresponds to
the information that the group would have if the members shared