1.leela
g
e
o
m
ea
n
(a) Microbenchmarks for SPEC CPU2017
vtblptr writes
+Virtual calls
+Secure mprotect
+Dynamic analysis
e
m
i
t
n
u
r
d
e
z
i
l
a
m
r
o
N
e
m
i
t
n
u
r
d
e
z
i
l
a
m
r
o
N
1.35
1.3
1.25
1.2
1.15
1.1
1.05
1
0.95
1.4
1.35
1.3
1.25
1.2
1.15
1.1
1.05
1
0.95
4
4
4.n
a
m
d
4
4
7.d
ealII
4
5
0.so
plex
4
5
3.p
o
vra
y
4
7
1.o
m
n
etp
p
4
7
3.astar
g
e
o
m
ea
n
4
8
3.x
ala
n
cb
m
k
(b) Microbenchmarks for SPEC CPU2006
Figure 5: Normalized runtime for C++ programs in SPEC
CPU2006 and CPU2017, with cumulative configurations: (i)
only instrument vtblptr writes; (ii) also instrument virtual
call instructions; (iii) secure the safe region by marking all
pages unwritable, and only selectively mprotect-ing them if
they are accessed from our own instrumentation code; and
(iv) include offline dynamic analysis results, reducing the
need for hot-patching.
cost of a slight performance degradation due to the overestimated
instruction set.
7.3 Performance
This section evaluates the runtime performance of vps by measur-
ing the time it takes to run each C++ benchmark in SPEC CPU2006
and CPU2017. We compare vps-protected runtimes against the
baseline of original benchmarks without any instrumentation. We
compile all test cases as position-indepedent executables with GCC
6.3.0. For each benchmark, we report the median runtime over 11
runs on a Xeon E5-2630 with 64 GB RAM, running CentOS Linux 7.4
64-bit. We use a single additional run with more logging enabled
to obtain statistics such as the number of executed virtual calls.
Table 6 details our results.
Our results show the variety in properties of C++ applications.
Some programs make little to no use of virtual dispatching, e.g.,
444.namd, 508.namd_r, 531.deepsjeng_r, and 473.astar. Others con-
tain thousands of vtblptr writes and virtual callsites, e.g., 510.parest_r
with over 12,000 vtblptr writes, or 483.xalancbmk in CPU2006 with
more than 1,300 verified virtual callsites. Further details are shown
in the first group in Table 6.
The comparison of verified virtual calls (true positive) and regu-
lar indirect calls (false positive) shows the accuracy of our analysis.
Almost all vcall candidates turn out to be real vcalls. Furthermore,
with absolute numbers of executed virtual calls and vtblptr writes in
the billions, it is clear that our instrumentation must be lightweight.
The second group in Table 6 depicts the exact numbers.
The runtime overhead of our instrumentation varies from 0%
for programs with little to no virtual dispatch code to 35% for the
worst-case scenario (483.xalancbmk). In almost all cases, we see
a correlation between increased overhead and number of instru-
mentation points (vtblptr writes and virtual calls). An exception is
511.povray_r, which shows a 15% performance decrease despite a
relatively low number of vcalls and vtblptr writes. Further inspec-
tion shows that this is caused by the 6 false positives candidate
vcalls; if we disable hot-patching, our vcall instrumentation code
is called over 18 billion times. While we remove instrumentation
hooks for the majority of these cases, which are not real vcalls, our
current implementation does not remove the Dyninst trampolines.
These trampolines are the source of the unexpected overhead. The
numbers depicting the comparison of the uninstrumented baseline
runs to vps-protected runs are shown in the third group in Table 6.
To better understand the overhead of vps, we gathered detailed
statistics for both SPEC CPU2006 and SPEC CPU2017 in varying
configurations. We first run SPEC with only instrumentation for
vtblptr writes enabled. In this run, the entire safe region is read-
/writable and the instrumentation only (i) computes the address
in the safe region to store the vtable pointer at, and (ii) copies the
vtable pointer there. In the second configuration, we additionally
instrument virtual calls. We check whether candidates are actual
vcalls by testing the call’s first argument and, if it can be deref-
erenced, looking this value up in the list of known vtables. We
then either patch verified vcalls to enable the fast path, or remove
instrumentation for false positives. The fast path fetches the vtable
pointer by dereferencing the first argument, and then compares it
against the value stored in the safe region. The third configuration
additionally makes the safe region read-only and uses a segfault
handler to mark pages writable on demand. Finally, the fourth con-
figuration includes dynamic analysis results, removing the need to
hot-patch previously verified vcalls at runtime. The results show
that the majority of vps’s overhead stems from (i) vtblptr writes,
and (ii) virtual callsite instrumentation. Figure 5 details the numbers
of this evaluation.
Overall, with a geometric mean performance overhead of 11% for
SPEC CPU2006 and 9% for SPEC CPU2017, vps shows a moderate
performance impact. As expected, it does not perform as well as a
source-based approach such as VTV with reported 4% geometric
mean for SPEC CPU2006 [43]. However, it outperforms compara-
ble previous work (VCI with 14% [14] and T-VIP with 25% [17])
and performs slightly worse than Marx’s VTable Protection with
a reported 8% geometric mean for SPEC CPU2006, however, with
better accuracy and additional type integrity.
8 DISCUSSION
This section first discusses the susceptibility of vps to COOP at-
tacks [38]. Next, we discuss the limitations of vps.
109Table 6: vps performance results and runtime statistics. For each binary, this table shows (i) binary instrumentation details,
depicting the number of instrumented vtblptr writes (#vtblptr), positive virtual calls (#positive), and candidate vcalls (#candi-
dates); (ii) runtime statistics, listing the number of true positive (#TP) and false positive (#FP) virtual calls, and the total number
of virtual calls (#vcalls) and vtblptr writes (#vtblptr); and (iii) runtime overhead, listing runtime overhead (vps) compared to
the baseline (base) in seconds.
Binary instrumentation
#vtblptr
6
4,283
120
98
507
0
4,554
444.namd
447.dealII
450.soplex
453.povray
471.omnetpp
473.astar
483.xalancbmk
Geometric mean [SPEC CPU2006]
508.namd_r
510.parest_r
511.povray_r
520.omnetpp_r
523.xalancbmk_r
526.blender_r
531.deepsjeng_r
541.leela_r
Geometric mean [SPEC CPU2017]
48
12,206
113
2,591
4,512
43
0
177
#positive
0
161
195
21
117
0
1,348
#candidates
2
1,459
364
91
677
1
11,623
0
243
19
447
801
37
0
0
0
4,539
121
5,310
30,771
174
0
2
Runtime statistics
#FP
0
0
0
6
0
0
0
#vcalls
0
97m
1,665,968
101,743
1,585m
0
3,822m
0
4
6
0
0
46
0
0
0
2,625m
4,577
7,958m
4,873m
11
0
0
#vtblptr
2,018
21m
40
162
2,156m
0
2,316m
21
119m
183
2,070m
2,314m
3
0
404,208
#TP
0
47
48
21
327
0
1,639
0
350
21
751
2,844
4
0
0
vps
Runtime overhead
base
343.5
289.7
215.8
135.8
290.0
350.3
185.0
342.9 (+ 0%)
299.2 (+ 3%)