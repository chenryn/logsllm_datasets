THE STATE OF
AVAILABILITY REPORT
2022 Annual Report
Welcome Note ................................................................................................... 04
Key Insights ........................................................................................................ 05
KPIs ........................................................................................................................ 06
SLA responsibility grows as companies grow larger ................................. 10
Error budgets are the most commonly tracked KPI .................................. 11
Larger companies show breadth of KPIs ..................................................... 14
Less than 20% of teams are tracking the incident timeline today .......... 16
TABLE OF
Groups with higher SLAs meet them more often ...................................... 20
Average incident lifecycle is well above most SLA allowance ................. 21
CONTENTS
Often customers are catching the incidents first before internal tools . 23
KPIs—Key Takeaways ................................................................................... 25
Teams ................................................................................................................... 26
Most teams have shifted to the “We Build it, We Own it” DevOps
culture .............................................................................................................. 30
Larger companies are further behind on DevOps adoption ...................... 32
Most DevOps practices remain a ‘Want to Have’ ....................................... 33
Organizational leaders believe their teams are at a much higher
DevOps adoption rate..................................................................................... 36
Leaders are also unaware of how much of their teams’ time is spent
on monitoring .................................................................................................. 37
The higher the SLAs, the more time spent monitoring ............................. 39
Larger organizations spend more time on incident and infrastructure
management .................................................................................................... 40
Teams - Key Takeaways .................................................................................. 41
Tools ...................................................................................................................... 42
The majority of services are still not in the cloud ..................................... 45
Organizations are still at the implementation stage of DevOps tool
chains ............................................................................................................... 46
Teams are managing huge amounts of monitoring tools .......................... 47
Teams with higher SLAs manage more tools per category ....................... 48
Tools - Key Takeaways .................................................................................... 49
TABLE OF Our Guidance ..................................................................................................... 50
The Steps to Success .................................................................................... 53
CONTENTS Survey Demographics .................................................................................... 58
Roles ................................................................................................................. 59
Geography ........................................................................................................ 60
Industry ............................................................................................................ 61
Organizational Size ......................................................................................... 62
Authors ................................................................................................................ 63
About Moogsoft ................................................................................................ 64
Welcome Note
Hi there!
Thank you so much for taking the time to read the inaugural State of Availability Report. Our goal when starting this
research was to help engineering teams and leaders uncover insights and develop good practices for availability
across three topics:
1. KPIs: what are the best key performance indicators for engineering teams to track and measure availability today?
2. Teams: what is the best way to structure engineering teams and understand daily responsibilities and challenges?
3. Tools: what tools and architecture are being used by engineering teams today and how are they planning for the
future?
Availability is a well-established KPI and teams are giving up a lot of time to maintain it. But is the expense worth it?
Based on research from 1,900 respondents, we say: “no”:
• Teams are not tracking 66% of their downtime and lack KPI coverage from incident detection through to resolution,
with customers frequently reporting incidents before monitoring tools catch them
• Teams are spending too much time monitoring, and too much money on too many tools, and yet still not seeing
good results in the availability of their systems
• All this time spent on incident management is detracting from the effort teams want to spend on making long-
term improvements to stability and increased throughput (DevOps)
Read on to learn more! Each topic (KPIs, teams, tools) has its own section with findings, details, and key takeaways.
We also wrap up the report with practical steps you can follow to focus and scale your team, their time, and your
infrastructure.
Happy Reading,
~Minami Rojas, VP of Growth and Marketing at Moogsoft
04
Key Insights
~ “Despite huge investment in monitoring, availability
outcomes are not where they should be. The data points to a
burning need for teams to do two things. “By implementing robust and intelligent monitoring,
organizations can unlock cost benefits. With that
Firstly, introduce an intelligent-correlation layer—aka AIOps. additional confidence, the error budget can become an
The data from monitoring should be correlated into a tight, asset that can be invested in improving services and
actionable incident-set. Without this, the data is expensive paying down technical debt.
~
and arguably worthless.
I found the numbers very telling. The fact that SLOs,
Secondly, consolidate tool usage in this observability layer. and the SLIs that drive them, are far less prevalent than
The savings are likely greater than the investment in AIOps, SLAs, suggests that organizations are ‘backing into’
and your outcomes will be better!” SLAs. I strongly doubt this is due to a lack of monitoring
coverage, but an inability to extract actionable data
~Phil Tee, Moogsoft CEO from the wealth of telemetry at their disposal.”
~ Richard Whitehead, Chief Evangelist at Moogsoft
~
“Customers see availability as a given and without it, you’re
losing them. But too often teams are spending too much
“As techniques for measurement, reporting, and
money, time, and energy sprinting to stand still here and it’s
management of services have evolved, one thing remains
to the detriment of their ability to invest in the things that will
~ paramount—if you are not available you are of no value.
set them free and assure the longevity of their organizations.”
Being ahead of your SLA and making the difficult decisions
~ Helen Beal, Strategic Advisor
before it’s too late, based on in-place error budgets that
signal risk, is how service owners can keep customer
confidence high.”
05
~ Chris Boyd, SVP Engineering at Moogsoft
KPIs
KPIs
Summary
Key performance indicators (KPIs) are the metrics that tell us how well we are doing our jobs. This
research has baselined the leading KPIs—which engineering teams are using to track and measure
availability—and explored how teams and organizations are using service level agreements (SLAs) to
manage customer experience.
See what we’ve discovered.
Regardless of company size or the KPIs they track, teams and organizations
Most teams are are regularly breaking their availability promises to their customers. Teams
breaching their with higher SLAs meet them more often than those with lower SLAs. This is
to be expected and may be self-selecting: if teams care about SLAs, they
SLAs
set more exacting standards, are more likely to be doing something about
them, and are better able to forecast their ability to meet them.
Higher availability Our data show that it’s well understood that poor performance against SLAs
leads to higher leads to poor customer experience—customer reviews and Net Promoter
Score (NPS) are the most common indicators that there is a problem. When
organizational
customer experience is poor, organizational performance and employee
performance
experience both suffer. Leaders must find ways to help their teams meet
their SLAs.
07
Error budgets define the maximum amount of time that a technical system
can fail without the contractual consequences of an SLA. More recently,
error budgets have been tightly associated with site reliability engineering
(SRE) and service level objectives (SLOs).
Error budgets
are the leading They are internally agreed between teams to describe tolerance for user
pain or frustration, which can trigger policy decisions such as “no more
availability KPI
production releases until we stabilize”. These metrics were the most
commonly used in small and medium companies and those with more
aggressive SLAs. Mean time to recover/restore (MTTR) and security
breaches are the next most used.
It’s possible there is a limit to the amount of information that is actually
helpful. The law of diminishing returns suggests there is a clear point at
which information overload becomes a problem and leads to ineffective
decision-making. Decision fatigue can result in poor choices as individuals
Teams with fewer,
make mental shortcuts in their decision analysis. Both these factors suggest
more meaningful
we need fewer, more meaningful metrics.
KPIs and higher
SLAs perform Furthermore, KPIs should have decisions attached to them for different
outcome scenarios. When teams are working in an experimental way, they’ll
better
be creating hypotheses for the work they are doing and continually seeking
feedback from both customers and systems on the impact of their work.
08
Most teams focus on MTTR, but few on mean time to discovery (MTTD). The
average MTTR is thirty minutes whereas the average MTTD is sixty minutes, so
Teams are not
teams are missing the opportunity to track 66% of their incident downtime.
tracking 66% of
their downtime They need to know these measures to track SLA performance and to
justify investments that will improve availability long-term. Incidents are
unplanned work that detract from innovation and improvement.
Tools are catching issues before customers are flagging them about half
the time, despite huge investment in monitoring tools. Teams are spending
most of their time monitoring—likely over monitoring—with no real result.
This is obviously a poor customer experience and teams need to find ways
Customers are
to catch issues first. The problem is that having so many monitoring tools
reporting issues
means that teams are deluged in data; more data than a human has
half of the time sufficient cognitive capacity or time to handle.
In addition, many teams are transitioning to distributed architectures
such as microservices, or service-oriented architectures, where incidents
caused by unknown unknowns are more common.
09
KPIs
SLA Responsibility Grows
as Companies Grow Larger
The bigger the company, the higher the
SLA. You might imagine that smaller
companies don’t have SLAs but in our
data, only 0.3% of respondents said
they didn’t have one.
We also learned that higher SLAs
are more prevalent in organizations
where customers are primarily
external and consumers (i.e. B2C not
B2B organizations). We know that as
companies grow and mature they
develop higher-level capabilities for
incident management, have dedicated
IT Operations teams, and centralized
platforms and services.
Having this focus on availability enables
teams to support higher SLAs, and
higher SLAs are required as customer
numbers grow—particularly if they are
external. Consumers are notoriously
intolerant of slow response times or
broken services.
10
KPIs
Error Budgets are the Most
Commonly Tracked KPI
Having a smaller number of
meaningful metrics suits
those with higher SLAs.
11
~
Error budgets came up as the most popular KPIs for teams
where Support Engineer was the most reported job title, “Bill Gates said: ‘New technology
regardless of SLA. And those with five nines (99.999%) rely
has less impact in the first two
on this KPI more than any other.
years than anticipated and more
in the first ten years.’ It may be
This group focuses on a handful of key metrics, whereas
that SRE has gone from being
the others track most of them. It seems having a smaller
novel to mainstream to the point
number of meaningful metrics suits those with higher
that it’s not even being labeled
SLAs, who are also better at meeting their SLAs.
differently in some organizations.
Companies need to acknowledge
Error budgets are also the bluntest KPI. The MTTR/D next
and act on these truths:
level set of incident timing breakdown is critical because
knowing why targets have been missed is more important
1. You are over-monitored—you have lots
than knowing that they have.
of tools that could be consolidated
to fewer ones and still have 100%
The next two most commonly used KPIs are MTTR and
coverage. For example, do you need a
“security breaches”. However at the leader/organizational separate event and metrics tool?
level, “cost of delay” is the top metric reported, reflecting
2. You are under-available—because you
their focus on revenue/profit and strategy delivery.
have focused on coverage you have
not focused on actionability. Too much
dumb data acquisition and not enough
smart data analysis.”
~Phil Tee, Moogsoft CEO
12
A NOTE ON
ERROR BUDGETS
It’s important to note that error budgets are a methodology and not the metric or KPI itself.
An error budget is a threshold by which an action is taken to improve the customer experience if it’s exceeded. For example, if
a service level agreement (SLA) specifies that systems will function 99.99% of the time before the business has to compensate
customers for the outage, that means the SLA states that systems can go down without consequences for 52 minutes and 35
seconds per year. A realistic error budget for this scenario would be 4 minutes of downtime per week, because if this is exceeded
then the team knows they are on track to breach the SLA and should therefore invest in system improvements.
When the error budget is exceeded, the team will investigate each contributing downtime event, and any correlation between events,
to see what can be done to improve availability. One outcome might be that performance is found to be impacted and that by
improving performance, the response time service level indicator (SLI) is met again and availability is increased.
The term was popularized by the site reliability engineering (SRE) movement that began at Google. We were surprised to see this
figure so heavily in the data since only 2.4% of our respondents identified their role as DevOps engineer/SRE (individual or team lead).
The leading job role in this research is support engineer (38%).
The practice of error budgeting is, of course, tightly connected with SLAs, SLOs (service level objectives), and SLIs. We discovered
that the majority (36%) use both SLOs and SLIs, with 13% planning to use them. We also found that 26% of respondents have only
SLOs and 23% only have SLIs.
• SLA: usually contractual between two parties
• SLO: this internal goal for a team is designed to prevent the team from breaching an SLA as it’s more aggressive than a
contractually committed SLA; in our example scenario where the SLA error budget might be no more than 4 minutes of downtime
a week, the SLO might be 3 minutes per week
• SLI: essentially an indicator of an SLO’s performance; for example, a high number of downtime events indicates that the SLO for
“availability” is at risk
• Error Budget: a methodology in which different budgets are tracked to know when user experience is likely to be or is already
impacted, so teams can choose to act on that reality rather than shipping features or focusing on other work
A conclusion to draw from this is that SRE practices are already widespread, perhaps being used in roles that aren’t using the SRE
title, or at least that awareness of their usage is well recognized.
13
KPIs
Larger Companies
Show Breadth of KPIs
Our research shows that larger companies are more likely to use availability KPIs and are broader in
their usage. You can also see here that the small and medium companies predominantly use an error
budgets KPI. The leading KPI for the larger companies is MTTR, closely followed by security breaches,
then security vulnerabilities.
14
Perhaps these larger companies are slower in
“I think larger companies take longer to
their uptake of SRE practices. Perhaps smaller
make any changes, especially innovative
companies are more commonly using the most
ones like using new technologies or
recent progressive ways of working such as SRE.
new practices. These choices are risky
It’s easier for small companies to make changes
and they’re willing to wait for others because it takes fewer people to convince and
to prove the value and worth before train, and they’re incentivized to find ways to
investing their time getting hundreds of outpace larger competitors, so are prepared to
people to do things differently. take more risk.
Larger companies may also have high brand
And larger companies have larger
awareness and higher potential negative customer
demands, meaning more volume and
impact with outages, making it critical they focus
velocity, which leads to more ‘black
on the resolution time if an incident happens.
swan’ events and more availability
Smaller companies are usually more proactive
challenges. They also have more change
and watch error budgets for early signs of issues.
events, which are probably the leading
cause of incidents, so no matter how
Generally, we can see larger companies using a
few or meaningful their KPIs are, I think
smaller number of KPIs and we know that larger
they would still be challenged due to
companies have higher SLAs, and those with
the sheer scale they operate at.” higher SLAs are more likely to meet them—so
it could follow that a tighter focus on a smaller
number of KPIs contributes to better availability.
~Eric Brousseau,
Moogsoft VP of Product
15
KPIs
Less Than 20% of Teams are
Tracking the Incident Timeline
Less than 15% of respondents are tracking their mean time to detect. That adds up to an hour lost every
time there’s an incident.
16
Discovering there’s an issue takes twice as long as resolving the
issue. Furthermore, 80% of respondents aren’t tracking their
MTTR. The data shows that the average incident lifecycle is ninety
“Availability is
minutes and most respondents are missing their SLAs. That’s a
customer experience,
lot of unplanned work that’s not visible. Peter Drucker reputedly
confidence, and trust.
said, “If you can’t measure it, you can’t improve it.”
Communication is very
important so that people
Our data suggest a smaller number of KPIs correlates with higher
understand the quality
availability and MTTR leads. But choose KPIs carefully—adding
and service we are
MTTD means that teams can see the end-to-end incident lifecycle