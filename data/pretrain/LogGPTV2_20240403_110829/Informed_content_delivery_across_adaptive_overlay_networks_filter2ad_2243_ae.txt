tween values on the x-axes of our plots.
Figure 7 shows the results of our experiments for this scenario.
In each experiment, uninformed collaboration performs poorly and
degrades signiﬁcantly as containment increases. This result is in-
tuitive and can be precisely analyzed using analysis similar to that
of the well known Coupon Collector’s problem [14]. Essentially,
the rate of useless symbols transmitted increases with the number
of symbols shared between peers. The degree of sharing increases
both as the initial containment increases and as the transfer pro-
gresses.
11
572
1.5
1
0.5
d
a
e
h
r
e
v
O
0
0
Uninformed
Speculative
Reconciled
0.1
0.2
0.3
0.4
0.5
Initial Containment
2
1.5
1
0.5
d
a
e
h
r
e
v
O
0
0
Uninformed
Speculative
Reconciled
0.1
0.2
0.3
0.4
0.5
Initial Containment
(a) Slack = 1.1
(b) Slack = 1.3
Figure 9: Overhead collaborating with multiple peers in parallel.
Speculative collaboration is more efﬁcient than uninformed collab-
oration, but the overhead still increases slowly with containment.
In comparison, the overhead of reconciled collaboration is virtu-
ally indistinguishable from plain encoded transfers from a server
and does not increase with containment. The extra overhead of rec-
onciled collaboration is purely from the cost of reconciliation (i.e.
transmitting a Bloom ﬁlter or approximate reconciliation tree) so it
is less than a percent when sending 8 bits for every symbol (1400
bytes).
6.3.2 Peer-Augmented Downloads
The next scenario we consider consists of a download from a server
with complete content, supplemented by a perpendicular transfer
from a peer as illustrated in Figure 6(b). In contrast to the previous
scenario, this scenario demonstrates the utility of additional band-
width in parallel with an ongoing download from a server. As in the
case of peer-to-peer reconciliation, the distribution of symbols be-
tween peers at the beginning of the scenario is precisely determined
by the slack and containment.
The results of this scenario are shown in Figure 8 and are similar
regardless of the slack. The overhead of uninformed collaboration
is considerably lower than in the scenarios of Figure 7, primarily
because a larger fraction of the content is sent directly via fresh
symbols from the server. Using our methods, speculative collabora-
tion performs similarly to uninformed collaboration in this scenario,
as the recoding methods used are not highly optimized – some im-
provements are possible with additional effort. In all cases, recon-
ciled collaboration still has overhead just slightly higher than that
of only receiving symbols directly from the server, but the trans-
fer time is substantially reduced when the additional connection is
employed.
For this scenario, it is natural to consider the speedup that is ob-
tained by augmenting the download with an additional connection.
Deﬁning the speedup to be the ratio between the transfer time using
a single sender with full content (and incurring no decoding over-
head) and the transfer time we achieve, we have:
speedup =
number of senders
1 + overhead
,
since all connections are assumed to have equal bandwidth and are
fully utilized. Therefore, a reconciled transfer with 0.025 overhead
achieves a speedup of 1.95, while an uninformed transfer with 0.20
overhead achieves a more modest speedup of 1.67 over a vanilla
download.
6.3.3 Collaborating with Multiple Peers in Parallel
Finally, we consider a peer collaborating concurrently with four
peers, all with partial content, as illustrated in Figure 6(c). This
scenario demonstrates that given appropriate reconciliation algo-
rithms, one can leverage bandwidth from peers with partial content
with only a slight increase in overhead.
When encoding symbols are allocated across multiple peers, slack
and containment no longer uniquely determine the initial distribu-
tion of symbols. We employ the following allocation method. As
before, the receiver initially has exactly 0.5" symbols. One of these
symbols is known to a sending peer with probability c. The remain-
ing symbols are known to a sending peer with probability p such
(0.5/t)(1−c)
1−(0.5/t) . Any of these symbols not known to
that
any sending peers is discarded and replaced. This results in each
peer having an expected 0.5" symbols at the beginning of the ex-
periment
1−(1−p)4 =
p
The results of this scenario are shown in Figure 9. As one would
expect, uninformed collaboration performs extremely poorly. For
low values of containment, speculative collaboration performs the
same as uninformed collaboration, but dramatically improves as
containment increases. We again recall that the degree distribution
was tuned to the according to the containment. In contrast to pre-
vious experiments, reconciled collaboration has much higher over-
head than before. This arises from correlation across multiple peers.
For example, sending peers D and E may identify shared symbol x
as being in SD − SA and SE − SA, respectively, and then both send
x to receiving peer A. When a symbol is received multiple times, it
directly contributes to the overhead. For similar reasons, the perfor-
mance of speculative collaboration is also degraded, as the recoding
algorithm is optimized only for transfers between pairs of peers.
Given the relatively poor performance of reconciled collaboration
when there is sharing between sending peers, we now consider the
12
582
1.5
1
0.5
d
a
e
h
r
e
v
O
h
t
d
i
w
d
n
a
B
0
0
Total Bandwidth Overhead
Downstream Bandwidth Overhead
20
40
60
80
100
Update frequency
2
1.5
1
0.5
d
a
e
h
r
e
v
O
0
0
Uninformed
Speculative
Reconciled
0.1
0.2
0.3
0.4
0.5
Initial Containment
(a) Tradeoffs between bandwidth and update frequency.
(b) Overhead with updated summaries (f = 10).
Figure 10: Overhead of collaborating with multiple peers in parallel and updating periodically. Slack = 1.1.
effects of periodically updating the summaries, in contrast to the
previous experiments, which performed ﬁne-grained reconciliation
only once, at the beginning of the scenario. We repeat the exper-
iments for this scenario with the containment constrained to zero
(the worst case for reconciled collaboration) and modulate the fre-
quency of reconciliation. Figure 10(a) shows the results of this ex-
periment. In this graph, the update frequency f means that an up-
date is performed after receiving "/f symbols, i.e. a frequency of
20 implies that updates are triggered after every 5% of the down-
load progresses. The bottom curve reﬂects the extra bandwidth of
trafﬁc to the receiving peer. The top curve adds the bandwidth con-
sumed by updates, thus accounting for the total amount of extra
communication in both directions. For example, as f increases,
the bandwidth spent on reconciliation updates becomes signiﬁcant,
and ultimately would dominate the bandwidth of the actual trans-
fer. When optimizing total bandwidth consumption, we ﬁnd that a
reasonable reconciliation frequency is roughly 10 − 20 depending
on the slack of the scenario, meaning that there is an update after
every 0.05" − 0.10" symbols that are transferred.
Figure 10(b) shows the results of using these updates in the scenar-
ios of Figure 9, i.e. speculative collaboration updates the min-wise
summary and reconciled collaboration updates the Bloom ﬁlters.
An update frequency of 10 is used and both speculative and recon-
ciled collaboration show dramatic improvement.
7 Conclusions
Overlay networks offer a powerful alternative to traditional mech-
anisms for content delivery, especially in terms of ﬂexibility, scal-
ability and deployability. In order to derive the full beneﬁts of the
approach, some care is needed to provide methods for represent-
ing and transmitting the content in a manner that is as ﬂexible and
scalable as the underlying capabilities of the delivery model. We
argue that straightforward approaches at ﬁrst appear effective, but
ultimately suffer from similar scaling and coordination problems
that have undermined other multipoint service models for content
delivery.
In contrast, we argue that a digital fountain approach to encoding
the content affords a great deal of ﬂexibility to end-systems per-
forming large transfers. The main drawback of the approach is that
the large space of possible symbols in the system means that co-
ordination across end-systems is also needed here, in this case to
ﬁlter useful content from redundant content. Our main contribu-
tions furnish efﬁcient, concise representations which sketch the rel-
evant state at an end-system in a handful of packets and then pro-
vide appropriate algorithmic tools to perform well under any cir-
cumstances. With these methods in hand, informed and effective
collaboration between end-systems can be achieved, with all of the
beneﬁts of using an encoded content representation.
Acknowledgements
We would like to thank Ari Trachtenberg and the anonymous SIG-
COMM ’02 reviewers for the helpful feedback they provided on
earlier versions of this paper.
References
[1] Altavista. www.altavista.com.
[2] ANDERSEN, D., BALAKRISHNAN, H., KAASHOEK, F., AND
MORRIS, R. Resilient overlay networks. In Proc. of ACM
Symposium on Operating Systems Principles (Banff, Canada,
October 2001).
[3] BLOOM, B. Space/time trade-offs in hash coding with al-
lowable errors. Communications of the ACM 13 (July 1970),
422–426.
[4] BOHMAN, T., COOPER, C., AND FRIEZE, A. Min-wise in-
dependent linear permutations. Electronic Journal of Combi-
natorics 7, R26 (2000).
[5] BRODER, A. On the resemblance and containment of doc-
uments. In Compression and Complexity of Sequences (SE-
QUENCES) (Positano, Italy, June 1997).
[6] BRODER, A. Z., CHARIKAR, M., FRIEZE, A. M., AND
MITZENMACHER, M. Min-wise independent permutations.
13
59[22] MINSKY, Y., TRACHTENBERG, A., AND ZIPPEL, R. Set rec-
onciliation with nearly optimal communication complexity. In
Proc. of IEEE Int’l Symp. on Information Theory (Washing-
ton, DC, June 2001).
[23] MITZENMACHER, M. Compressed bloom ﬁlters. In Proc. of
the 20th Annual ACM Symposium on Principles of Distributed
Computing (2001), pp. 144–150. To appear in IEEE/ACM
Trans. on Networking.
[24] RABIN, M. Efﬁcient dispersal of information for security,
load balancing and fault tolerance. Journal of the ACM 38
(1989), 335–348.
[25] RATNASAMY, S., FRANCIS, P., HANDLEY, M., KARP, R.,
AND SHENKER, S. A scalable content-addressable network.
In Proc. of ACM SIGCOMM (San Diego, CA, August 2001).
[26] RODRIGUEZ, P., AND BIERSACK, E. W. Dynamic parallel-
access to replicated content in the Internet. IEEE/ACM Trans-
actions on Networking 10(4) (August 2002). A preliminary
version appeared in Proc. of IEEE INFOCOM ’00.
[27] ROWSTRON, A., AND DRUSCHEL, P. Storage management
and caching in past, a large-scale, persistent peer-to-peer stor-
age utility. In Proc. of ACM Symposium on Operating Systems
Principles (Banff, Canada, October 2001).
[28] SAVAGE, S., COLLINS, A., HOFFMAN, E., SNELL, J., AND
ANDERSON, T. The end-to-end effects of Internet path selec-
tion. In Proc. of ACM SIGCOMM (August 1999).
[29] STOICA, I., MORRIS, R., KARGER, D., KAASHOEK, F.,
AND BALAKRISHNAN, H. Chord: A scalable peer-to-peer
lookup service for internet applications. In Proc. of ACM SIG-
COMM (San Diego, CA, August 2001).
[30] Swarmcast. http://www.opencola.org/projects/swarmcast.
[31] VITTER, J. S. Random sampling with a reservoir. ACM
Trans. on Math. Software 11 (1985), 37–57.
[32] ZHUANG, S., ZHAO, B., JOSEPH, A., KATZ, R., AND KU-
BIATOWICZ, J. Bayeux: An architecture for scalable and
fault-tolerant wide area data dissemination. In Proc. of NOSS-
DAV ’01 (Port Jefferson, NY, June 2001).
Journal of Computer and System Sciences 60, 3 (2000), 630–
659.
[7] BYERS, J. W., LUBY, M., AND MITZENMACHER, M. Ac-
cessing multiple mirror sites in parallel: Using Tornado codes
to speed up downloads. In Proc. of IEEE INFOCOM (March
1999), pp. 275–83.
[8] BYERS, J. W., LUBY, M., MITZENMACHER, M., AND
REGE, A. A digital fountain approach to reliable distribu-
tion of bulk data. In Proc. of ACM SIGCOMM (Vancouver,
September 1998), pp. 56–67. To appear in IEEE Journal on
Selected Areas in Communications.
[9] CHAWATHE, Y.
Scattercast: An Architecture for Internet
Broadcast Distribution as an Infrastructure Service. PhD the-
sis, University of California, Berkeley, December 2000.
[10] CHU, Y.-H., RAO, S., AND ZHANG, H. A case for end sys-
tem multicast. In ACM SIGMETRICS (Santa Clara, CA, June
2000).
[11] CONSIDINE, J. Generating good degree distributions for
sparse parity check codes using oracles. Tech. Rep. BUCS-
TR 2001-019, Boston University, October 2001.
[12] FAN, L., CAO, P., ALMEIDA, J., AND BRODER, A. Sum-
mary cache: A scalable wide-area cache sharing protocol.
IEEE/ACM Trans. on Networking 8(3) (2000), 281–293. A
preliminary version appeared in Proc. of SIGCOMM ’98.
[13] JANNOTTI, J., GIFFORD, D., JOHNSON, K., KAASHOEK,
M., AND O’TOOLE, J. Overcast: Reliable multicasting with
an overlay network. In Proc. of USENIX Symp. on Operating
Systems Design and Implementation) (San Diego, CA, Octo-
ber 2000).
[14] KLAMKIN, M., AND NEWMAN, D. Extensions of the birth-
day surprise. Journal of Combinatorial Theory 3 (1967), 279–
282.
[15] LABOVITZ, C., MALAN, G., AND JAHANIAN, F.
Internet
routing instability. In Proc. of ACM SIGCOMM (September
1997).
[16] LUBY, M. Information Additive Code Generator and Decoder
for Communication Systems. U.S. Patent No. 6,307,487, Oc-
tober 23, 2001.
[17] LUBY, M., MITZENMACHER, M., SHOKROLLAHI, A., AND
SPIELMAN, D. Efﬁcient erasure correcting codes.
IEEE
Transactions on Information Theory 47(2) (2001), 569–584.
[18] MACWILLIAMS, F. J., AND SLOANE, N. The Theory of
Error-Correcting Codes. North Holland, Amsterdam, 1977.
[19] MAHANTI, A., EAGER, D. L., VERNON, M. K., AND
SUNDARAM-STUKEL, D.
Scalable on-demand media
streaming with packet loss recovery. In Proc. of ACM SIG-
COMM (August 2001), pp. 97–108.
[20] MERKLE, R. A digital signature based on a conventional
encryption function. In Advances in Cryptology (CRYPTO)
(Santa Barbara, CA, August 1987).
[21] MINSKY, Y., AND TRACHTENBERG, A. Practical set recon-
ciliation. Tech. Rep. BU ECE 2002-01, Boston University,
2002.
14
60