in the order of days or weeks—in certain pages being flagged as mali-
cious by GSB.
These measurements demonstrate the limits of defenses purely
based on blacklists such as the GSB database, and motivate the need
for additional proactive measures such as the ones we propose in
this paper.
4.3 Behavioral Differences Between Users
Next, we are interested in using our logs to explore any differences
in behavior between exposed and unexposed users. The idea is
that such differences could be critical in identifying risky behavior,
which we could then use for feature engineering in the design of a
predictive classifier. Here, we are only concerning ourselves with
empirically-measured differences—we do not (yet) integrate any
data from our surveys.
Defining Malice. Ideally, we would be able to identify precisely
when a user gets exposed to a malicious page, and we would be
able to characterize her behavior long before, immediately prior to,
and after exposure. This would in turn help us determine possible
deviations that could be indicative of increased risk immediately
prior to exposure, and characterize whether an infection might have
occurred post-exposure (e.g., if we notice drastically different net-
work access patterns). Unfortunately, we have no way of knowing
precisely when a user is exposed. We know when a user requests a
given page, and we know when that page is flagged as malicious
by GSB, but, as discussed above and shown in Fig. 1, we do not
know when the page actually turns malicious. For that reason, we
parameterize the notion of a malicious page.
Definition 1. τ-malicious page: Consider a user making an
HTTP request to a URL u at time t. URL u is deemed τ -malicious if it
appears in the GSB database at any time t′ such that t ≤ t′ < t + τ .
τ-malicious pages are webpages that may currently be flagged as
benign, but that will (within τ) be marked as malicious. The smaller
τ is, the higher the danger, as the probability that the page is in fact
already malicious increases as τ → 0.
Mathematically, using τ = 0 (resp. τ → ∞) would underestimate
(resp. overestimate) the number of malicious pages—the “true” value
for τ actually depends on each URL. Based on the results shown in
Fig. 1, it appears fruitful to study behavioral differences between
users exposed to τ-malicious pages for τ ≥ 87 days (oldest plausible
appearance of a malicious page before it was labeled as such), τ =
22 days (when number of accesses to webpages ultimately deemed
malicious starts to significantly pick up), τ = 2 days (when the
spike in accesses is the highest), τ = 0 days (when malice has been
confirmed), and unexposed users.
Exposure Events. Fig. 2 shows the number of requests to malicious
pages for each exposed user for various definitions of a malicious
page, ranging from τ = 0 to setting τ to the maximum value possible
(91 days, the size of the measurement interval).
Figure 2: Number of requests (left) and sessions (right) to malicious
pages for exposed users. For readability, we truncate the figure at 20
requests or sessions, even though a small fraction of users (< 0.1%)
request far more.
Depending on the value of τ, between a third to half of our
exposed users access only one page deemed malicious; for positive
values of τ, more than a quarter of our users make three or more
requests to malicious pages. Fig. 2 indicates that, for positive values
of τ, half to two-thirds of the exposed users perform all exposed
requests within a single session depending on the value selected
for τ; the remainder shows a long-tailed distribution. As the figure
shows, this behavior is generally robust to changes in the value
of τ we select, although, in line with Fig. 1, τ = 0 seems overly
conservative.
The limited number of exposure events for a third to half of our
population motivates the need for short-term, in-session predictions
for each user.
Finding 2. A predictive classifier cannot purely rely on previous
exposure, since a significant share of our user corpus shows a lack of
“repeat” exposure.
Figure 3: Probability of future visits to malicious pages based on
the number of past requests to malicious pages. The overall trend
is relatively independent of τ . Curves for τ = 22 and τ = max are
overlapping.
Next, we calculate, in Fig. 3, the probability that an exposed user
who accessed malicious pages at least x times in the past, will access
a malicious page in the future. Namely, Fig. 3 reports the empirical
estimate of Pr[A(x + 1)|A(x)], where A(x) denotes the event that
a user visited at least x malicious pages. Here too, we vary τ. We
find that:
0.000.250.500.751.005101520CDF over exposed usersτ=0τ=2τ=22τ=max0.000.250.500.751.005101520τ=0τ=2τ=22τ=max0.000.250.500.751.005101520Nr. of past requests to malicious pagesProb. future request to mal. pageτ=0τ=2τ=22τ=maxSession 8A: Web 1CCS’18, October 15-19, 2018, Toronto, ON, Canada1492(a) Requests/user/day
(b) Avg. session length (sec)
Figure 4: Differences between exposed and unexposed users. Ex-
posed users tend to make far more requests, and engage in longer
sessions than unexposed users. Kolmogorov-Sminov (KS) tests show
that the differences between exposed and unexposed users are sta-
tistically significant (p-value <0.01).
Finding 3. The more users got exposed in the past, the higher the
probability they will get exposed again.
This finding substantiates that, while prior exposure by itself is
insufficient (see Finding 2), short-term predictions can nevertheless
benefit from long-term inputs, using prior exposure as a feature.
Namely, this measurements motivates the need for combining short-
and long-term reasoning, which will be our core contribution.
Session-Level Metrics. We next investigate the differences in the
level of activity between exposed and unexposed users. Fig. 4(a) (in
logarithmic scale on the x-axis) shows that, regardless of the value
chosen for τ, unexposed users generally request far less pages per
day than exposed users. We observe a similar trend for sessions—
unexposed users engage in considerably less sessions than exposed
users. Finally, Fig. 4(b) exhibits clear differences in session lengths:
unexposed users engage in usually shorter sessions than exposed
users. Here too, the result is robust to the value of τ we choose. In
short, irrespective of the value τ chosen, we see that:
Finding 4. Exposed users are more active than unexposed users—
they make more HTTP requests, and engage in more, longer, browsing
sessions.
These variables will thus play an important role in a predictive
classification model.
Diurnal and Weekly Effects. We next look into the amount of
requests by exposed and unexposed users through the day by the
hour, as shown in Fig. 5. To meaningfully compare the different
classes we perform “feature scaling,” i.e., we normalize each value to
a [0, 1] range, where 0 represents the minimum number of requests
from a given type of user per day, and 1 is the maximum number
of requests.
All requests in our corpus occur on the same time zone (JST).
Both behaviors are relatively similar and demonstrate time-of-the-
day effects: people browse the Internet most during lunch time, and
the early morning (midnight-4am) is the quietest time of the day.
However, it seems that exposed users tend to request data more
evenly throughout the day; in particular, the gap with unexposed
users is most pronounced in the evening. Canali et al. found similar
differences when analyzing user browsing on traditional operating
systems [10]. We conjecture this may be due to a combination of
Figure 5: Scaled number of requests by type of user over the day.
Due to imbalance in the absolute numbers among classes, we use a
[0, 1] feature scaling. Exposed users are more active at night time.
KS tests show that the differences between exposed and unexposed
users are significant (p-value <0.01).
exposed users 1) browsing the Internet more often than unexposed
users overall, and 2) potentially browsing riskier websites in the
evening than when they are at work.
Finding 5. Exposed users tend to browse the Internet more fre-
quently at night and outside of working hours.
Thus, time-of-the-day might be a useful feature to look at for
our predictive classifiers. For the sake of brevity, we do not present
a plot here, but we found a similar behavior relating to activity
levels throughout the week: exposed users tend to be more active
on week-ends than their unexposed counterparts. We will thus also
consider day-of-the-week as a potential predictive feature.
Webpage Categories. Finally, motivated by prior findings that
certain types of webpages present higher risks of infection than
others [45, 61, 87], we posit that certain categories of webpages
may be more strongly correlated with exposure risks. For exam-
ple, Fig. 6 shows the proportion of advertising and adult webpages
for unexposed and exposed users. Although we might overlook
some requests to advertising pages due to our logs ignoring, e.g.,
JavaScript, we observe that exposed users tend to access adver-
tising pages with a higher frequency than unexposed users. The
same is true for adult content. More generally, we find that exposed
and unexposed users access webpages of 65 categories out of the
99 at different frequencies (these differences are statistically sig-
nificant with p-value < 0.05 according to Kolmogorov-Smirnov
tests, after Bonferroni correction). Exposed users are more likely
to access webpages of 19 categories (e.g., adult, advertising, and
video-search webpages), while unexposed users are more likely
to access webpages of 46 categories (e.g., education, financial, and
news webpages).
Finding 6. Certain categories of content may be indicative of
higher risk exposure.
We thus might want to use website category as a feature in our
predictive classifier.
Take-Aways. As a major take-away from this set of measurements,
exposed and unexposed users clearly show differences along a
number of metrics. We will use these differences in the remainder
of the paper to devise proactive defenses. Another important take-
away is that the notion of “exposure” itself is highly dependent on
0.000.250.500.751.00110100100010000CDF over usersUnexposed (τ=0)Unexposed (τ=2)Unexposed (τ=22)Unexposed (τ=max)Exposed (τ=0)Exposed (τ=2)Exposed (τ=22)Exposed (τ=max)0.000.250.500.751.000100020003000Unexposed (τ=0)Unexposed (τ=2)Unexposed (τ=22)Unexposed (τ=max)Exposed (τ=0)Exposed (τ=2)Exposed (τ=22)Exposed (τ=max)0.000.250.500.751.0003691215182124Hour of the dayNumber of requests (scaled)Unexposed (τ=0)Unexposed (τ=2)Unexposed (τ=22)Unexposed (τ=max)Exposed (τ=0)Exposed (τ=2)Exposed (τ=22)Exposed (τ=max)Session 8A: Web 1CCS’18, October 15-19, 2018, Toronto, ON, Canada1493Table 1: Parameter estimates for the logistic regression model.
Shown: log odds-ratios of variables, their odds-ratios, and the p-
values for H0 that the odds-ratios are equal to 1.
Parameter
(Intercept)
Is female?
Proactive awareness
Proceeds on browser warning?
Suffered from compromise?
Uses anti-virus?
Uses unofficial app marketplace?
β
-1.97
-0.50
-0.20
0.23
0.51
0.92
0.16
e β
0.14
0.54
0.82
1.26
1.67
2.51
1.17
p-value
<0.01
<0.01
<0.01
<0.01
<0.01
<0.01
<0.01
we identify which users are exposed from the HTTP requests—
exposure will serve as the dependent variable in the regression. The
independent variables are constructed from the survey responses.
Specifically, we compute the following variables: (1) Gender; (2)
Presence of an anti-virus on the user’s device; (3) Whether the
user downloads apps from unofficial marketplaces; (4) Whether
the user proceeds on browsers’ warnings; (5) Whether the user
reports having suffered from a compromise; and (6) the RSeBIS
proactive awareness score (via summing the users’ responses to the
Likert-scale questions and normalizing to [0, 1] range). Variables
(1)–(5) are binary; (6) is continuous.
We exclude age and self-confidence in security knowledge from
the regression—exploratory data analysis did not indicate corre-
lation between age and exposure; and we wanted to avoid mul-
ticollinearity in the regression due to the correlation between
self-confidence in security knowledge the proactive awareness
score [73].
We use Python’s statsmodels package to build the regression
model [41]. To select the best model, we begin from all possible
interactions between the variables and perform backward model
selection by removing interactions until the model’s likelihood
does not decrease much (particularly, the decrease in the Bayesian
Information Criterion becomes lower than two, as standard [74]).
5.2 Experiment Results
The parameter estimates of the model with the best fit are reported
in Table 1. While none of the interactions survived model selection,
all the main factors in the model were found to have a significant
effect on exposure at a significance level p < 0.01. Notably, the
model estimates that women are 0.54 times as likely as men to visit
malicious URLs. Prior work showed that women are less likely to
detect deceptive, malicious, webpages [75], but this finding shows
that women may be less likely to encounter such webpages in
the first place. Participants who have suffered from compromise
have an increased odds of exposure to malicious content by 1.67
times. This further corroborates Finding 3 that users with prior
exposure have higher probability to be exposed again. Similarly, the
parameter estimates show that risky behavior, such as proceeding
on browser warnings, and using unofficial marketplaces for mobile
apps, increase the odds of exposure to malicious content by at
least 1.17 times, on average. This aligns with our expectations. In
contrast, and somewhat surprisingly, having an anti-virus is the
factor that is most correlated with exposure—users who reported
Figure 6: Fraction of page requests of a certain type over all re-
quests. Exposed users tend to request more advertisement (left) and
adult (right) pages than unexposed users. The differences between
exposed and unexposed users are significant according to KS tests
(p-value <0.01).
what is considered malicious. We have seen that blacklists such as
the GSB database appear to lag a bit behind actual deployment of
malicious pages, and have introduced the notion of τ-exposure—the
user is exposed to a page that will be labeled as malicious within τ
days. Measurements indicate that τ = 2 seems to be a reasonable
compromise: larger τ would probably encompass pages that were
not actually malicious at the time of browsing, but smaller τ would
likely miss dangerous pages.
5 SURVEY RESPONSES AND EXPOSURE RISK
We now turn to determining whether we can accurately predict
the risk of a compromise to a given individual. We start from a
general perspective: can we establish meaningful insights on users’
exposure risk from survey responses? If so, we could use these
insights to complement the system-level metrics we collect, and
improve performance of our proposed predictive schemes.
In essence, we aim to explore the relationship between a binary
dependent variable (whether users are exposed) and a mix of cate-
gorical (e.g., whether an anti-virus is installed) and continuous (e.g.,
proactive awareness score) variables. To this end, we build a logis-
tic regression model (a popular tool for modeling the relationship
between various explanatory variables and a binary outcome [74])
to determine the influence of the different variables our survey
captures on user exposure risk.
1−p