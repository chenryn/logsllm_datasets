Taking over the extension auto-update process for our proof
of concept prototype in this manner, requires us to make
more frequent changes to the version number of an extension
than the extension’s developer would. Because of the way the
versioning system works, we need to keep track of a parallel
versioning scheme that is only visible between the browser
and the proxy. The details of this process are too technical
to detail in this paper, but require us to change the version
property of the manifest ﬁle in addition to the permissions
and content_scripts properties.
By default, the Chromium auto-update process can take up
to seven days, which we deem too infrequent to be of practical
use in our proof of concept. An optional modiﬁcation of one
line of code in one ﬁle of the Chromium source code changes
this update interval to ﬁve seconds, so that updates to the policy
whitelist are implemented more promptly.
In addition, it should be noted that the original extension
update mechanism will prompt the end user whenever the
extension requests additional permissions compared to the
previous version. Our proof of concept implementation does
not alter this default behavior.
C. Discussion and future work
Our prototype implementation is a proof of concept, show-
ing that it is possible to use whitelisting policies to defend
against extension probing and revelation attacks. As mentioned
before, an actual production-quality implementation of these
defenses would require more changes to browser code and
result in better performance and a nicer user experience with
regards to e.g. the user interface.
A real-world implementation in the browser would not need
to rewrite the extensions on the ﬂy, and would not have to
disable security checks. Similar to how the browser checks if,
e.g., a WAR should be allowed to be injected, the browser can
check if the extension should be allowed to execute on any
given domain.
Recently, Google released the plan to allow end users to
restrict the host permissions for an extension [7], indicating
the core mechanism for modifying browser extension behavior
within the browser is possible, and something which can be
used to control the extension whitelist. In this case, the browser
extension can provide a whitelist which can be modiﬁed
without the need to re-install the extension.
It is also crucial for a real-world implementation to not
have an early-out mechanism, which is what was exploited
11
in the timing attack presented by S´anchez-Rola et al. [53],
and subsequently removed [20]. In the situation an attacker
is allowed to probe for an extension, and that extension is
present, an early-out from the whitelisting mechanism during
a probing attack would allow for the attacker to measure the
elapsed time, and deduce whether the request was blocked
based on the whitelist. If an attacker knows the time it takes
to get a response from an installed extension which they are
allowed to probe for, and an extension which is blocked by the
whitelist, the attacker can, for each negative probing attempt,
deduce which extensions that are not installed, and which that
are blocked based on the whitelist.
For our prototype, we made the rather arbitrary choice to
limit whitelists to web origins and hostnames in the probing
and revelation defense respectively. While these choices serve
us well for a proof of concept, it could prove interesting to
reﬁne these whitelists to use e.g. regular expressions on URLs
instead.
Additionally, for the probing defense, when a web page
contains an embedded subframe, we disregard the web origin
of the subframe and enforce the whitelist associated with the
web origin of the main frame. Our prototype is very well
capable of applying a different whitelist for the subframe, in
case the end user would wish to do so. However, we regarded
this particular reﬁnement of the prototype as out of scope for
a proof of concept implementation.
In our proof of concept implementation, only the end-user
can specify policy whitelists for both the probing and reve-
lation defenses. In a production implementation, one should
consider a system where both web applications and browser
extensions can suggest a policy, which the end-user could
then reﬁne or even override. Another possibility is to have
a system similar to Google Safe Browsing [28], keeping the
user interaction to a minimum.
Finally, our prototype implementation displays information
to the user about which extensions are being probed for on
any visited web page. We do not display similar information
regarding revelation attacks. We also consider these visual
markers to be out of scope to prove the functionality of the
concept.
VII. EVALUATION
We have evaluated the functionality of our proof of concept
implementation to ensure that it works as intended. Using
the data from Sections III and IV, we randomly selected
and visited several dozen web pages that perform probing
attacks, and also visited our attacker web page with the top
ten (Chrome) extensions that reveal themselves on any web
page with any content. As expected, our proof of concept
implementation stops both the probing attacks and revelation
attacks.
We also perform two evaluations against known old attacks,
the enumerating probing attack presented by Sj¨osten et al. [55]
(Section VII-A) and the enumerating timing probing attack
presented by S´anchez-Rola et al. [53] (Section VII-B).
A. Enumerating probing attack
We visited two known web pages that employed the enu-
merating probing attack [54], [32] twice: the ﬁrst time with an
TABLE VII: Enumeration timing probing attack.
/
/
/
Chromium
53.0.2785.135
8.53ms
12.59ms
7.86ms
Patch
9.67ms
9.71ms
10.16ms
Patch +
Extension
8.95ms
9.17ms
9.3ms
unmodiﬁed Chromium browser, and the second time with the
modiﬁed Chromium browser and with our browser extension
installed. We used browser extensions which we know can be
detected both times: AdBlock [10], Avast Online Security [4],
Ghostery [6] and LastPass [39]. When visiting with the modi-
ﬁed Chromium browser with our browser extension, we set the
policy to a ”block all” policy, meaning we expect no WARs
to be accessible to the web page.
As expected, with our unmodiﬁed Chromium browser, the
probing attack was successful against all four extensions. Note
that although the database was last updated in December 2016
for [54], it could still detect the popular extensions, which
might indicate browser extensions do not change internally
very often. Using our proof of concept implementation, the
probing attacks failed for all extensions. Although the ex-
ecution time increased signiﬁcantly, due to the handling of
over 11,000 requests for our JavaScript code in the browser
extension, we note that this is something that will improve if
the mechanism is fully implemented in the source language of
the browser. We also set policies to allow for the probing of
each extension, one at a time, indicating that the overall idea
explained in Section V is sound.
B. Enumerating timing probing attack
the
2)
from versions
To be consistent with prior work, we determined
core might
whether our modiﬁcation of Chromium’s
enumerating timing probing attack —
reintroduce
than
61.0.3155.0
already ﬁxed
higher
— presented by S´anchez-Rola et al.
[53]. This timing
attack makes a distinction between two types of requests:
1) chrome-extension:///,
and;
chrome-extension://
/. The attacker uses the User Timing API [59],
which allows to take time measurements with high precision,
to check the response times for each of these requests. If the
measured times do not differ more than 5%, the attacker can
conclude that the requested extension is not installed in the
client’s browser.
In order to reproduce this timing attack, we downloaded
and built Chromium 53.0.2785.135 on a virtual machine with
Ubuntu 16.04.
We
identiﬁed three
scenarios: 1) using the origi-
nal Chromium 53.0.2785.135 source code; 2) Chromium
66.0.3359.117 with our patch applied, but without the Latex
Gloves extension, and; 3) Chromium 66.0.3359.117 with our
patch applied and the Latex Gloves extension installed.
For each scenario, we had Avast Online Security installed
and used it as the . When executing with
our patch and Latex Gloves installed, we had set the whitelist
to allow all requests to extension WARs, apart from to Avast
Online Security and AdBlock. Table VII shows the results
12
TABLE VIII: Breakdown of the amount of Chrome and Firefox
extensions that would be uniquely identiﬁable through the
content of a WAR, given that no probing could take place.
Firefox
Chromium
Revealing
Extensions
1,378
11,633
2,906
Total WARs
95,920
12,499,335
4,027,046
Unique WARs
23,687
127,054
35,478
Detection probability
24.69%
1.02%
0.88%
of our experiment, where the time measurement for each
request was averaged over 1,000 runs. From these results, it is
clear that Chromium 53.0.2785.135 is vulnerable to the timing
attack, since there is more than 5% difference between the
time measurement for an existing extension and a non-existing
extension. However, with our modiﬁcation (with or without
extension), that difference is no longer present.
VIII. RECOMMENDATIONS
Based on the experiments in Sections III and IV, we
recommend several improvements to the browser extension
ecosystem, addressed to browser developers and extension
developers.
Recommendations for browser developers: Chrome
extensions are vulnerable to the extension probing attack
because their UUIDs are static and publicly known. Firefox
extensions combat this vulnerability by having randomized
extension UUIDs. However, Firefox extensions can still be
identiﬁed through the revelation attack. Worse, because Fire-
fox’s random UUIDs are not easily changed after an extension
is installed, they can be used to ﬁngerprint the extension user.
Our ﬁrst recommendation is to re-generate Firefox’s ran-
dom UUIDs more often, either upon starting the browser or for
each domain visited. Similarly, if a user enables private brows-
ing mode [48], [23], each active browser extension should
be provided with a new random UUID. Although this would
not prevent detecting which browser extensions are executed,
it would limit the tracking to a speciﬁc instance, making it
infeasible to use this technique for long-term tracking of users.
Our second recommendation is to randomize the full
URL of a WAR, and not
the UUID. With this
change, a WAR URL seen by an attacker would be
shaped as moz-extension:/// for Firefox and chrome-extension:/// for Chrome. Without any recogniz-
able path components, the attacker would be forced to read
and ﬁngerprint the contents of the WAR to determine which
extension is installed. As depicted in Table VIII, without
the ability to probe, this would decrease the probability of
detecting Firefox extensions to 24.69% (compared to 93.76%,
as shown in Table II), and 1.02% for Chrome (compared
to 89.01%) and probability of detecting the extensions we
know reveal themselves would drop to 0.88% from 89.52%.
The random path approach can be taken one step further by
implementing the WAR URLs to be of single use, i.e. the
same WAR will have different paths each time it is injected or
fetched. Such a change to core extension infrastructure would
make it impossible for an attacker to fetch a recently injected
resource in order to analyze the content. However, it would
also require an overhaul of the browser implementation and
possibly most browser extensions, which is very impractical.
just
Recommendations for browser extension developers:
Both Mozilla [43] and Google [27] provide guidelines for
browser extension developers, e.g. “never ask for more permis-
sion than needed”, and “properly secure sensitive or personal
data when transmitting over the network”. However, neither
provide speciﬁc guidelines on how to handle WARs in a secure
way.
Our only recommendations fall in the “least privilege”
category, where no more privileges than needed to perform
a certain task should be requested. Firstly, to help prevent the
revelation attack, extension developers should not arbitrarily
inject content with the random UUID. As seen in Table V,
several extensions currently inject content on any arbitrary web
page, including blank pages. Secondly, to help prevent the
probing attack, extensions should not expose unused WARs.
A non-existent WAR cannot be used in a probing attack,
thus reducing the chances that an extension can be identiﬁed
through a probing attack.
IX. RELATED WORK
User ﬁngerprinting by using web browsers has been widely
studied in the literature [12], [9], [11], [38], [15], [34]. As
an example, Cao et al. [15] were able to ﬁngerprint 99.24%
of web users — being completely web browser agnostic —
by using hardware features such as those from GPUs or
CPUs. More recently, G´omez-Boix et al. [34] performed a
large scale experiment to determine whether ﬁngerprinting is
still possible nowadays. They reached the conclusion that in
desktop web browsers, both plugins (e.g. Flash, NPAPI, etc)
and fonts are the most representative features to ﬁngerprint
users. However, none of the aforementioned works have taken
browser extensions into consideration.
Nikiforakis et al. [52] showed that implementation dif-
ferences between browsers can be ﬁngerprinted. There exist
several extensions that attempt to erase those ﬁngerprints, but
those extensions in turn allow a user to also be ﬁngerprinted.
In the same vein, Acar et al. [9] state that browser extensions
can be exploited to ﬁngerprint and track users on the Web.
Starov and Nikiforakis [56] presented a method to ﬁn-
gerprint browser extensions using a behavioral attack. They
show browser extensions can provide unique, arbitrary DOM
modiﬁcations, and analyzes the top 10,000 of most down-
loaded browser extensions, concluding 9.2% to 23% of those
extensions are detectable. Contrarily to the experiments they
performed — they only analyzed the manifest ﬁle of 1,665
browser extensions and they found that more than a 40% of
them do make use of WARs, in this work we have scrutinized
62,994 browser extensions and concluded that 16,280 explic-
itly declare some WARs in their manifest.json ﬁle (≈26%).
In 2011, Kettle [36] demonstrated that all Chrome ex-
tensions could be enumerated by requesting their manifest
ﬁle, which was explained in 2012 by Kotowicz [37]. Google
solved this problem by introducing WARs, but Sj¨osten et
al. [55] showed that all Chrome extensions with WARs can be