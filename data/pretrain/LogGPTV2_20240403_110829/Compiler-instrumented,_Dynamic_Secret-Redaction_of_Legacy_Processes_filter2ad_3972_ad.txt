detected
fork and
detach
redact 
memory
clone
resume
execution
target
decoy
checkpoint
restore
Figure 7: Honey-patch response to an intrusion attempt.
5 Evaluation
This section demonstrates the practical advantages and
feasibility of our approach for retroﬁtting large legacy C
codes with taint-tracking, through the development and
evaluation of a honey-patching memory redaction archi-
tecture for three production web servers. All experiments
were performed on a quad-core VM with 8 GB RAM
running 64-bit Ubuntu 14.04. The host machine is an
Intel Xeon E5645 workstation running 64-bit Windows 7.
5.1 Honey-patching
Figure 7 illustrates how honey-patches respond to intru-
sions by cloning attacker sessions to decoys. Upon in-
trusion detection, the honey-patch forks a shallow, local
clone of the victim process. The cloning step redacts
all secrets from the clone’s address space, optionally re-
placing them with honey-data. It then resumes execution
in the decoy by emulating an unpatched implementation.
This impersonates a successful intrusion, luring the at-
tacker away from vulnerable victims, and offering defend-
ers opportunities to monitor and disinform adversaries.
Prior honey-patches implement secret redaction as a
brute-force memory sweep that identiﬁes and replaces
plaintext string secrets. This is both slow and unsafe; the
sweep constitutes a majority of the response delay over-
head during cloning [2], and it can miss binary data secrets
difﬁcult to express reliably as regular expressions. Us-
ing SignaC, we implemented an information ﬂow-based
redaction strategy for honey-patching that is faster and
more reliable than prior approaches.
Our redaction scheme instruments the server with dy-
namic taint-tracking. At redaction time, it scans the result-
ing shadow memory for labels denoting secrets owned by
user sessions other than the attacker’s, and redacts such se-
crets. The shadow memory and taint-tracking libraries are
then unloaded, leaving a decoy process that masquerades
as undefended and vulnerable.
Evaluated software. We implemented taint tracking-
based honey-patching for three production web servers:
Apache, Nginx, and Lighttpd. Apache and Nginx are the
top two servers of all active websites, with 50.1% and
14.8% market share, respectively [32]. Apache comprises
2.27M SLOC mostly in C [35]. Nginx and Lighttpd are
smaller, having about 146K and 138K SLOC, respectively.
All three are commercial-grade, feature-rich, open-source
USENIX Association  
24th USENIX Security Symposium  153
9
 100000
s
l
e
b
a
l
f
o
r
e
b
m
u
n
 10000
 1000
 100
 10
 1
  PC2S
 PCS
 10  20  30  40  50  60  70  80  90  100
requests
(a) Apache
 100000
s
l
e
b
a
l
f
o
r
e
b
m
u
n
 10000
 1000
 100
 10
 1
  PC2S
 PCS
 10  20  30  40  50  60  70  80  90  100
requests
(b) Nginx
 100000
s
l
e
b
a
l
f
o
r
e
b
m
u
n
 10000
 1000
 100
 10
 1
  PC2S
 PCS
 10  20  30  40  50  60  70  80  90  100
requests
(c) Lighttpd
Figure 8: Experiment comparing label creeping behavior of PC2S and PCS on Apache, Nginx, and Lighttpd.
software products without any built-in support for infor-
mation ﬂow tracking.
To augment these products with PC2S-style taint-
tracking support, we manually annotated secret-storing
structures and pointer ﬁelds. Altogether, we added ap-
proximately 45, 30, and 25 such annotations to Apache,
Nginx, and Lighttpd, respectively. For consistent eval-
uation comparisons, we only annotated Apache’s core
modules for serving static and dynamic content, encrypt-
ing connections, and storing session data; we omitted its
optional modules. We also manually added about 20–30
SLOC to each server to initialize the taint-tracker. Con-
sidering the sizes and complexity of these products, we
consider the PC2S annotation burden exceptionally light
relative to prior approaches.
5.2 Taint Spread
Over-tainting protection. To test our approach’s resis-
tance to taint explosions, we submitted a stream of (non
keep-alive) requests to each instrumented web server,
recording a cumulative tally of distinct labels instantiated
during taint-tracking. Figure 8 plots the results, compar-
ing traditional PCS to our PC2S extensions. On Apache,
traditional PCS is impractical, exceeding the maximum la-
bel limit in just 68 requests. In contrast, PC2S instantiates
vastly fewer labels (note that the y-axes are logarithmic
scale). After extrapolation, we conclude that an aver-
age 16,384 requests are required to exceed the label limit
under PC2S—well above the standard 10K-request TTL
limit for worker threads.
Taint spread control is equally critical for preserving
program functionality after redaction. To demonstrate, we
repeated the experiment with a simulated intrusion after
n ∈ [1, 100] legitimate requests. Figure 9 plots the cu-
mulative tally of how many bytes received a taint during
the history of the run on Apache. In all cases, redaction
crashed PCS-instrumented processes cloned after just 2–3
legitimate requests (due to erasure of over-tainted bytes).
In contrast, PC2S-instrumented processes never crashed;
their decoy clones continued running after redaction, im-
personating vulnerable servers. This demonstrates our
 10000
 1000
)
B
k
(
s
e
t
y
b
d
e
t
n
a
t
i
  PC2S
 PCS
 100
 10
 1
 10  20  30  40  50  60  70  80  90  100
requests
Figure 9: Cumulative tally of bytes tainted on Apache.
Table 2: Honey-patched security vulnerabilities
Version CVE-ID
Description
CVE-2014-6271 Improper parsing of environ-
ment variables
CVE-2014-0160 Buffer over-read in heartbeat
protocol extension
2.2.21 CVE-2011-3368 Improper URL validation
2.2.9
CVE-2010-2791 Improper timeouts of keep-
2.2.15 CVE-2010-1452 Bad request handling
2.2.11 CVE-2009-1890 Request content length out of
alive connections
2.0.55 CVE-2005-3357 Bad SSL protocol check
bounds
Software
Bash1
4.3
OpenSSL1 1.0.1f
Apache
Apache
Apache
Apache
Apache
1tested with Apache 2.4.6
approach’s facility to realize effective taint-tracking in
legacy codes for which prior approaches fail.
Under-tainting protection. To double-check that PC2S
redaction was actually erasing all secrets, we created a
workload of legitimate post requests with pre-seeded se-
crets to a web-form application. We then automated ex-
ploits of the honey-patched vulnerabilities listed in Ta-
ble 2, including the famous Shellshock and Heartbleed
vulnerabilities. For each exploit, we ran the legacy, brute-
force memory sweep redactor after SignaC’s redactor to
conﬁrm that the former ﬁnds no secrets missed by the
latter. We also manually inspected memory dumps of
each clone to conﬁrm that none of the pre-seeded secrets
154  24th USENIX Security Symposium 
USENIX Association
10
)
s
m
(
e
m
i
t
p
i
r
t
-
d
n
u
o
r
 1000
 900
 800
 700
 600
 500
 400
 300
 200
 100
 0
no redaction (median=154 ms)
PC2S (median=196 ms)
brute force (median=308 ms)
 50  100  150  200  250  300  350  400  450  500
malicious HTTP requests
Figure 10: Request round-trip times for attacker session
forking on honey-patched Apache.
survived. In all cases, the honey-patch responds to the
exploits as a vulnerable decoy server devoid of secrets.
5.3 Performance
Redaction performance. To evaluate the performance
overhead of redacting secrets, we benchmarked three
honey-patched Apache deployments: (1) a baseline in-
stance without memory redaction, (2) brute-force mem-
ory sweep redaction, and (3) our PC2S redactor. We
used Apache’s server benchmarking tool (ab) to launch
500 malicious HTTP requests against each setup, each
conﬁgured with a pool of 25 decoys.
Figure 10 shows request round-trip times for each de-
ployment. PC2S redaction is about 1.6× faster than brute-
force memory sweep redaction; the former’s request times
average 0.196s, while the latter’s average 0.308s. This sig-
niﬁcant reduction in cloning delay considerably improves
the technique’s deceptiveness, making it more transparent
to attackers. Nginx and Lighttpd also exhibit improved
response times of 16% (0.165s down to 0.138s) and 21%
(0.155s down to 0.122s), respectively.
Taint-tracking performance. To evaluate the perfor-
mance overhead of the static instrumentation,
three
Apache setups were tested: a static-content HTML web-
site (∼20 KB page size), a CGI-based Bash application
that returns the server’s environment variables, and a dy-
namic PHP website displaying the server’s conﬁguration.
For each web server setup, ab was executed with four
concurrency levels c (i.e., the number of parallel threads).
Each run comprises 500 concurrent requests, plotted in
ascendant order of their round-trip times (RTT).
Figure 11 shows the results for c = 1, 10, 50, and 100,
and the average overheads observed for each test proﬁle
are summarized in Table 3. Our measurements show
overheads of 2.4×, 1.1×, and 0.3× for the static-content,
CGI, and PHP websites, respectively, which is consistent
with dynamic taint-tracking overheads reported in the
prior literature [41]. Since server computation accounts
for only about 10% of overall web site response delay in
Table 3: Average overhead of instrumentation
Benchmark
Static
CGI Bash