Copyright*©*2015*Splunk*Inc.*
Hunk*Performance* 
and*TroubleshooFng* 
best*pracFce*
Raanan*Dagan* 
Praveen*Burgu* 
*
Disclaimer*During*the*course*of*this*presentaFon,*we*may*make*forward*looking*statements*regarding*future* events*or*the*expected*performance*of*the*company.*We*cauFon*you*that*such*statements*reflect*our* 	current*expectaFons*and*esFmates*based*on*factors*currently*known*to*us*and*that*actual*events*or* 	results*could*differ*materially.*For*important*factors*that*may*cause*actual*results*to*differ*from*those* 	contained*in*our*forwardNlooking*statements,*please*review*our*filings*with*the*SEC.*The*forwardN 	looking*statements*made*in*the*this*presentaFon*are*being*made*as*of*the*Fme*and*date*of*its*live* 	presentaFon.*If*reviewed*aQer*its*live*presentaFon,*this*presentaFon*may*not*contain*current*or* 	accurate*informaFon.*We*do*not*assume*any*obligaFon*to*update*any*forward*looking*statements*we* 	may*make.*** 
In*addiFon,*any*informaFon*about*our*roadmap*outlines*our*general*product*direcFon*and*is*subject*to* 	change*at*any*Fme*without*noFce.*It*is*for*informaFonal*purposes*only*and*shall*not,*be*incorporated* into*any*contract*or*other*commitment.*Splunk*undertakes*no*obligaFon*either*to*develop*the*features* 	or*funcFonality*described*or*to*include*any*such*feature*or*funcFonality*in*a*future*release.*2*
Who*are*you?*
•Raanan*Dagan*N*Sr.*SE,*Big*Data*specialist*•Praveen*Burgu*–*Sr.*SoQware*Engineer*
3*
	Agenda*
–Performance* 
	!10*ways*to*opFmize*Hunk*search*performance:*MR*Jobs,* 	Timestamp*ExtracFon,*Caching**
–Troubleshoot** 
	!Inspect*search*job*issues:*MR*Jobs,*Performance,* 
	Timestamp* 
*
4* Do*not*distribute*
Hunk*Performance*
Hunk Performance Main Points 
1.Run MR Jobs1.Run MR Jobs 
2.HDFS Storage 
3.VIX with Timestamp / indexes.conf 4.File Format 
5.Compression types / File size 
6.Event breaking / Props.conf 
7.Report Acceleration 
8.Hardware 
9.Search Head Clustering 
10.Other Flags (Threads, Splits) 
6* Do*not*distribute*
#1:*Make*Sure*you*use*MR*Jobs*
Not*MR*Jobs*–*Just*Splunk* 
"  Index=xyz****
** 
Not*MR*Jobs*–*Just*Splunk*** 
Not*MR*Jobs*–*Just*Splunk* 
"  Index=xyz*|*stats*count**and*using*Verbose*Mode* Allows*you*to*use*the*Power*of* Hadoop*MR*Jobs*parallel* 
processing**
** 
Yes,*this*will*run*MR*Jobs* 
"  Index=xyz*|*stats*count**and*using*Smart*Mode* **
7*
#*2:*HDFS*Storage**
This*is*BAD* 
"  /data/root/dir/...*
** 
This*is*GOOD* 
"  /data/root/dir/2014/10/01/....* Allows*you*to*bring*subset*of* data*from*HDFS*based*on*Fme* extracFon**"  /data/root/dir/2014/10/02/....* 
** 
This*is*BETTER* 
"  /data/root/dir/2014/10/01/app=apache/...*** 
"  /data/root/dir/2014/10/01/app=mysql/...*
8*
#*3:*VIX*with*Timestamp*/*Indexes.conf**
HDFS5=5/user/splunk/data/20141123/14/SFServer/myfile.gz5 *[hadoop]**
vix.provider*=*MyHadoopProvider** 
vix.input.1.path*=*/user/splunk/data/*/*/${server}/...** vix.input.1.accept*=*\.gz$**vix.input.1.et.regex*=*.*?/data/(\d+)/(\d+)/.*?.gz** Time*extracFon*will*enable*you* to*use*the*Time*Picker*in*the* Hunk*UI*to*bring*Subset*of*the* data**
vix.input.1.et.format*=*yyyyMMddHH** 
vix.input.1.et.offset*=*0** 
vix.input.1.lt.regex*=*.*?/data/(\d+)/(\d+)/.*?.gz** 
vix.input.1.lt.format*=*yyyyMMddHH** 
vix.input.1.lt.offset*=*3600**
9*
#4:*File*Format**
"  Don’t*add*mulFple*sources*into*one*file*** 
"  Use*a*selfNdescribing*format*for*the*data*whenever* 	possible;*e.g.*json,*avro,*csv,*Parquet,*ORC,*RC,*etc.* * Hunk*will*benefit*if*the*file*has* some*structure.**Otherwise*we* will*need*to*use*REGEX*to*extract* fields**
"  If*using*a*log*file,*look*at*this*list*for*Splunk*Known* Source*Types*(sourcetype=access_combined)** hzp://docs.splunk.com/DocumentaFon/Splunk/ latest/Data/Listofpretrainedsourcetypes*"  Look*at*the*Splunk*App*Store*for*600*other*opFons* to*break*the*events*/*fields*hzp://apps.splunk.com*
10*
#5:*Compression*type*/*File*size**
This*is*BAD*(Large*NonNsplizable)**
"  500MB*GZ*file* 
** 
This*is*BAD*(too*many*MR*Jobs)* 
"  10,000*X*1kb*files* To*avoid*too*many*MR*Jobs,*or* running*out*of*memory*make* sure*to*use*the*correct* 
compression*or*file*size**
** 
This5is5GOOD5(Large*spilizable)*** 
This5is5GOOD5(Large*spilizable)* 
"  500MB*LZO*or*Snappy*file* 
** 
This5is5GOOD5(NonNsplizable,*but*1*MR*per*file)* 
"  127MB*or*63MB*GZ*file*
11*
	#6:*IndexNFme*pipeline*processing* hzp://docs.splunk.com/DocumentaFon/Hunk/latest/Hunk/PerformancebestpracFces*
| Default55 | 0* | 515 | 40* | 1055 | ~4X* | 80* | 1905 | 1905 | 1905 | 1905 | 1905 | 200* |
|---|---|---|---|---|---|---|---|---|---|---|---|---|| MLA55 |0* |515 |40* |1055 |~4X* |80* |1795 |1795 |1795 |1795 |1795 |200* |
| MLA5+5LM5 |0* |515 |40* |1055 |~4X* |80* |1795 |1795 |1795 |1795 |1795 |200* |
| MLA5+5LM5+5TP5 |0* |515 |40* |1055 |~4X* |80* |MLA:%MAX_TIMESTAMP_LOOKAHEAD%=%30%% |MLA:%MAX_TIMESTAMP_LOOKAHEAD%=%30%% |MLA:%MAX_TIMESTAMP_LOOKAHEAD%=%30%% |MLA:%MAX_TIMESTAMP_LOOKAHEAD%=%30%% |MLA:%MAX_TIMESTAMP_LOOKAHEAD%=%30%% |200* || MLA5+5LM5+5TF5 |0* |515 |40* |1055 |~4X* |80* |MLA:%MAX_TIMESTAMP_LOOKAHEAD%=%30%% |MLA:%MAX_TIMESTAMP_LOOKAHEAD%=%30%% |MLA:%MAX_TIMESTAMP_LOOKAHEAD%=%30%% |MLA:%MAX_TIMESTAMP_LOOKAHEAD%=%30%% |MLA:%MAX_TIMESTAMP_LOOKAHEAD%=%30%% |200* |
| MLA5+5LM5+5TF5+5TP55 |0* |515 |40* |1055 |~4X* |80* |TP:%%TIME_PREFIX%=%^%% |TP:%%TIME_PREFIX%=%^%% |TP:%%TIME_PREFIX%=%^%% |TP:%%TIME_PREFIX%=%^%% |TP:%%TIME_PREFIX%=%^%% |200* || MLA5+5LM5+5TF5+5TP55 |0* |515 |40* |1055 |~4X* |80* |TF:%%TIME_FORMAT%=%%a,%%d%%b%%Y%%H:%M:%S%%Z%% |TF:%%TIME_FORMAT%=%%a,%%d%%b%%Y%%H:%M:%S%%Z%% |TF:%%TIME_FORMAT%=%%a,%%d%%b%%Y%%H:%M:%S%%Z%% |TF:%%TIME_FORMAT%=%%a,%%d%%b%%Y%%H:%M:%S%%Z%% |TF:%%TIME_FORMAT%=%%a,%%d%%b%%Y%%H:%M:%S%%Z%% |200* || MLA5+5LM5+5TF5+5AP55 |0* |445 |40* |1055 |60* |80* |LM:%%SHOULD_LINEMERGE%=%false%% |LM:%%SHOULD_LINEMERGE%=%false%% |LM:%%SHOULD_LINEMERGE%=%false%% |LM:%%SHOULD_LINEMERGE%=%false%% |LM:%%SHOULD_LINEMERGE%=%false%% |200* |
| MLA5+5LM5+5TF5+5AP55 |0* |445 |40* |1055 |60* |80* |AP:%%ANNOTATE_PUNCT%=%false%%% |AP:%%ANNOTATE_PUNCT%=%false%%% |AP:%%ANNOTATE_PUNCT%=%false%%% |AP:%%ANNOTATE_PUNCT%=%false%%% |AP:%%ANNOTATE_PUNCT%=%false%%% |200* || MLA5+5LM5+5TF5+5AP55 |0* |445 |40* |1055 |60* |80* |100* |120* |140* |160* |180* |200* |
| MLA5+5LM5+5TF5+5AP55 |0* |20* |40* |1055 |60* |80* |100* |120* |140* |160* |180* |200* |
Time*(s)*
12*
#7:*Report*AcceleraFon**
Report*acceleraFon*will*improve* 
performance*–*Bring*data*from* 
Cache*
NOTE:* 
vix.env.HADOOP_HEAPSIZE*=* 
1024*or*above**
13*
Splunk*and*Hadoop*N*Caching*opFons*Splunk*and*Hadoop*N*Caching*opFons*
14* 	Do*not*distribute*
#8:*Hardware*
| Dedicated5search5head5 | Dedicated5search5head5 | A*good*Hardware*with*mulFple* cores*can*be*very*beneficial*to* interact*with*hundreds*of*end* users** |
|---|---|---|
| • |Intel*64Nbit*chip*architecture* |A*good*Hardware*with*mulFple* cores*can*be*very*beneficial*to* interact*with*hundreds*of*end* users** || • |4*CPUs,*4*cores*per*CPU,*at*least*2*Ghz*per*core* |A*good*Hardware*with*mulFple* cores*can*be*very*beneficial*to* interact*with*hundreds*of*end* users** |
| • |12*GB*RAM* |A*good*Hardware*with*mulFple* cores*can*be*very*beneficial*to* interact*with*hundreds*of*end* users** |
| • |2*x*300*GB,*10,000*RPM*SAS*hard*disks,*configured*in*RAID*1* |A*good*Hardware*with*mulFple* cores*can*be*very*beneficial*to* interact*with*hundreds*of*end* users** || • |Standard*1Gb*Ethernet*NIC,*opFonal*2nd*NIC*for*a* |A*good*Hardware*with*mulFple* cores*can*be*very*beneficial*to* interact*with*hundreds*of*end* users** |
| management*network* |management*network* |A*good*Hardware*with*mulFple* cores*can*be*very*beneficial*to* interact*with*hundreds*of*end* users** |
| • |Standard*64Nbit*Linux** |A*good*Hardware*with*mulFple* cores*can*be*very*beneficial*to* interact*with*hundreds*of*end* users** || 5  Data5Nodes*=*The*SplunkD*indexer*is*installed,*by*default,*on*each* data*node*‘/tmp/splunk’*directory.**You*just*need*to*make*sure* |5  Data5Nodes*=*The*SplunkD*indexer*is*installed,*by*default,*on*each* data*node*‘/tmp/splunk’*directory.**You*just*need*to*make*sure* |A*good*Hardware*with*mulFple* cores*can*be*very*beneficial*to* interact*with*hundreds*of*end* users** |you*have*about*40MB,*or*more,*space*in*that*directory*5
15*
#9:*Search*Head*Clustering*
|  | Hunk*/*Hadoop*Client* | Add*Many*Concurrent*Users* |
|---|---|---|
| 1.  2.  3. |No*Single*Point*of*Failures*=*Dynamic*Captain* “One*ConfiguraFon”*across*SH*=*AutomaFc*Config*replicaFon** Horizontal*Scaling*=*Ability*to*add*/*remove*SH*nodes*on*running* cluster5 |No*Single*Point*of*Failures*=*Dynamic*Captain* “One*ConfiguraFon”*across*SH*=*AutomaFc*Config*replicaFon** Horizontal*Scaling*=*Ability*to*add*/*remove*SH*nodes*on*running* cluster5 ||  | | |
16*
#10:*Other*OpFmizaFon*Flags*
| Number5of5Jobs:5 | Number5of5Jobs:5 |
|---|---|
| • |vix.splunk.search.mr.threads*****N*#*of*threads*to*use*when*reading*map*results*from*HDFS* |
| • |vix.splunk.search.mr.maxsplits***N*maximum*number*of*splits*in*an*MR*job*(Default*to*10000)* |
| *  Number5of5copies5to5each5data5node:5 |*  Number5of5copies5to5each5data5node:5 || • |vix.splunk.setup.bundle.setup.Vmelimit****N*Fme*limit*in*ms*for*seÅng*up*bundle*on*TT* |
| • |vix.splunk.setup.bundle.replicaVon********N*set*custom*replicaFon*factor*for*bundle*on*hdfs* |
| • |vix.splunk.setup.package.replicaVon*******N*set*custom*replicaFon*factor*for*splunk*package*on*hdfs* || *  VIX5overrides:55 •vix.input.[N].recordreader5N*list*of*recordreaders*to*use*when*processing*this*input,*these*RR*are* |*  VIX5overrides:55 •vix.input.[N].recordreader5N*list*of*recordreaders*to*use*when*processing*this*input,*these*RR*are* |
	tried*before*those*at*the*provider*level.*For*example,*ImageRecordReader*–*PCapRecordReader*–* 	ZipRecordReader*–*EncrypFonRecordReader**•vix.input.[N].spli\er5–*For*example,*ParquetSplitGenerator**
•vix.input.[N].required.fields5–*For*example,*In*smart*mode*always*extract*Timestamp*field**
17*