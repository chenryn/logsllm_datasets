  * [基于设备指纹的风控建模以及机器学习的尝试](https://xz.aliyun.com/t/2801)
  * [如何在安全风控中评估和量化机器学习有效性](https://xz.aliyun.com/t/2951)
  * [人工智能反欺诈三部曲——特征工程](https://www.anquanke.com/post/id/85741)
### Web安全检测
### Web安全之URL异常检测
  * [基于机器学习的web异常检测](https://www.freebuf.com/articles/web/126543.html)
  * [基于大数据和机器学习的Web异常参数检测系统Demo实现](https://www.freebuf.com/articles/web/134334.html)
  * [基于机器学习的web应用防火墙](https://github.com/faizann24/Fwaf-Machine-Learning-driven-Web-Application-Firewall)
  * [LSTM识别恶意HTTP请求](https://www.cdxy.me/?p=775)
  * [基于URL异常检测的机器学习模型mini部署](http://4o4notfound.org/index.php/archives/84/)
  * [我的AI安全检测学习笔记（一）](http://4o4notfound.org/index.php/archives/127/)
### Web安全之XSS检测
  * [机器学习识别XSS实践](https://www.cdxy.me/?p=773)
  * [使用深度学习检测XSS](http://webber.tech/posts/%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A3%80%E6%B5%8BXSS/)
  * [使用深度学习检测XSS(续)](http://webber.tech/posts/%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A3%80%E6%B5%8BXSS%28%E7%BB%AD%29/)
### Web安全之攻击多分类检测
  * [基于机器学习的WEB攻击分类检测模型](https://www.freebuf.com/news/184687.html)
  * [基于机器学习的攻击检测系统](https://www.freebuf.com/column/189981.html)
### Web安全之Webshell检测
  * [基于机器学习的分布式webshell检测系统-特征工程（1）](https://www.s0nnet.com/archives/fshell-feature-1)
  * [深度学习PHP webshell查杀引擎demo](https://www.cdxy.me/?p=788)
  * [使用机器学习识别WebShell](https://github.com/lcatro/WebShell-Detect-By-Machine-Learning)
  * [基于机器学习的分布式Webshell检测系统](https://github.com/Lingerhk/fshell)
  * [GitChat · 安全 | 基于机器学习的 Webshell 发现技术探索](http://blog.csdn.net/GitChat/article/details/77932384?locationNum=4&fps=1)
  * [刘焱： Webshell 发现技术实战解析](http://gitbook.cn/books/5964d154cc597d3e0c08667c/index.html)
  * [安普诺张涛：再谈webshell检测](http://www.cnetsec.com/article/22593.html)
  * [新开始:webshell的检测](https://iami.xyz/New-Begin-For-Nothing/)
  * [基于机器学习的WebShell检测方法与实现(上)](https://www.freebuf.com/articles/web/181169.html)
### Web安全之其他
  * [Web安全检测中机器学习的经验之谈](https://iami.xyz/ML-IN-Webshell-Detection-Advantages-And-Disadvantages/)
### 杂项
  * [机器学习在WindowsRDP版本和后门检测上的应用](https://www.anquanke.com/post/id/157175)
  * [用机器学习检测恶意PowerShell](https://xz.aliyun.com/t/2437)
  * [机器学习算法在用户行为检测(UBA)领域的应用](http://dearcharles.cn/2017/11/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%9C%A8%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%A3%80%E6%B5%8B-UBA-%E9%A2%86%E5%9F%9F%E7%9A%84%E5%BA%94%E7%94%A8/)
  * [利用机器学习和规则实现弱口令检测](https://manning23.github.io/2018/10/12/%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E8%A7%84%E5%88%99%E5%AE%9E%E7%8E%B0%E5%BC%B1%E5%8F%A3%E4%BB%A4%E6%A3%80%E6%B5%8B/)
  * [解决机器学习和安全运营之间的最后一公里问题](https://www.anquanke.com/post/id/163637)
## 保护AI
  * [如何利用AI对抗“数据污染”和”数据中毒“？](https://www.anquanke.com/post/id/150653)
  * [对抗数据中毒--机器学习在阿里巴巴网络安全的应用](https://www.leiphone.com/news/201806/rYrfwtaeCNohEf0D.html)
# 对抗篇
## 使用AI攻击应用
  * [AI与Android漏洞挖掘的那些事儿](https://www.zybuluo.com/qinyun/note/957067)
  * [AI与安全的恩怨情仇五部曲“1”Misuse AI](https://www.zuozuovera.com/archives/1565/)
  * [一种基于机器学习的自动化鱼叉式网络钓鱼思路](https://www.freebuf.com/articles/web/132811.html)
## 攻击AI
### 攻击AI框架
  * [深度学习框架中的魔鬼——探究人工智能系统中的安全问题](https://www.anquanke.com/post/id/86989)
### 攻击AI模型
  * [安全领域中机器学习的对抗和博弈](http://bindog.github.io/blog/2016/11/13/game-playing-with-ml-in-security/)
  * [基础攻防场景下的AI对抗样本初探](https://www.cdxy.me/?p=798)
  * [机器学习在安全攻防场景的应用与分析](https://www.freebuf.com/articles/neopoints/152457.html)
  * [使用生成对抗网络(GAN)生成DGA](http://webber.tech/posts/%E4%BD%BF%E7%94%A8%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%28GAN%29%E7%94%9F%E6%88%90DGA/)
  * [详解如何使用Keras实现Wassertein GAN](https://mp.weixin.qq.com/s/F2gBP23LCEF72QDlugbBZQ)
  * [Is attacking machine learning easier than defending it?](http://www.cleverhans.io/security/privacy/ml/2017/02/15/why-attacking-machine-learning-is-easier-than-defending-it.html)
  * [对深度学习的逃逸攻击 ——探究人工智能系统中的安全盲区](https://www.anquanke.com/post/id/87037)
## 0x05 对现状的个人理解
从上面我收集的资料来看，我觉得智能化安全对抗技术的第一点困境是目前易工程化的还主要集中在AI安全检测方面这种弱智能化安全对抗技术，但是大规模应用还是较难，还存在相当多的问题，尤其是深度学习。从场景来说，安全领域的场景非常复杂，各不相同，想找到通用的方法论解决所有问题怕是天方夜谭，所以需要对每种小场景结合机器学习技术具体处理，这就涉及到大量的人力财力和物力；从数据来说，就算不牵扯复杂的安全场景，安全数据的同构化也是一项挑战，李飞飞教授（是犹他大学的李飞飞，好像现在在阿里，不是斯坦福的李飞飞）发表在CCS的研究成果：DeepLog，可以解决这个问题；从模型来看，不考虑模型效果，机器学习和深度学习训练的模型的可解释性还是较弱，学术界已经开始尝试突破深度学习的可解释性问题，希望可以看见曙光。智能化安全对抗技术的第二点困境是AI本身的安全对抗这种相对高级的技术，它的前沿研究一般集中在学术界，要进行学术成果转化的门槛很高，需要资深的安全算法专家充当一个衔接，这类人才很稀少，需要发的了顶会，写的了代码，就算转化成功了，也只是达到了目前AI安全检测经历的这个阶段，大规模决策应用还是较难。总的来说，连目前相对容易做的AI安全检测大规模应用都还存在问题，更何况智能化安全对抗技术了。但是形势不等人啊，智能化安全对抗已经来了，然而技术还没准备好。也许是因为在同一个环境太久，接触到的资源比较局限，所以限制了自己的视野，所以希望年后能找实习历练一下，让机器学习真正的在安全场景中落地。
## 0x06 Reference
Machine Learning Blog:
Machine Learning+Security Blog: