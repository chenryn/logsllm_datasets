sor. With virtualization, a common way to support DMA
is through IOMMU, which is a hardware memory manage-
ment unit that maps the DMA-capable I/O buses to the main
memory. However, unique to SEV is that the memory is
encrypted. While the MMU supports memory encryption
with multiple ASIDs, IOMMU only supports one ASID (i.e.,
ASID=0). Therefore, in SEV-enabled VMs, DMA operations
are performed on memory pages that are shared between the
guest and the hypervisor (encrypted with the hypervisor’s
Kh). A bounce buffer, called Software I/O Translation Buffer
(SWIOTLB), is allocated on these memory pages.
To illustrate the DMA operation from the guest, a disk I/O
read is shown in Figure 1. When a guest application needs to
read data from ﬁle, it ﬁrst checks whether the ﬁle is already
stored in its page cache. A miss in the guest page cache
will trigger read from virtual disks, which is emulated by
QEMU-KVM. The data is actually read from the physical
disk by QEMU-KVM’s DMA operation into SWIOTLB and
then copied to the disk device driver’s I/O buffer by the guest
VM itself. The disk write operation is the inverse of this
process, in which the data is ﬁrst copied from the guest into
SWIOTLB and then processed by QEMU.
3 Security Issues
In this section, we explore the security issues of the lack
of protection for SEV’s I/O operations. We start of our
exploration with the most straightforward consequence of
vulnerability—the insecurity of I/O operations itself—and
present an attack example that breaches the integrity of I/O
operations. To comprehensively study the attack surface, we
also enumerate the I/O operations from a guest VM that are
vulnerable to such attacks and discuss the challenges of im-
plementing effective countermeasures. Next, we show that
I/O insecurity leads to a complete compromise of the memory
encryption scheme of SEV, by constructing powerful attack
primitives that leverage the unprotected I/O operations to en-
able the adversary to encrypt or decrypt arbitrary messages
with the guest VM’s memory encryption key, kvek.
3.1 Threat Model
We consider a scenario in which the VMs’ memory are en-
crypted and protected by AMD SEV technology. The hyper-
visor run on a machine controlled by a third-party service
provider. Under the threat model we consider, the third-party
service is not trusted to respect the integrity or conﬁdentiality
of the computation inside the VMs. This could happen when
the service provider is dishonest or when the hypervisor has
been compromised.
The goal of the attacks is either to compromise the I/O
operations themselves or the memory encryption of SEV. Out
of scope in this paper are denial-of-service (DoS) attacks, in
which the service provider simply refuses to run the VM. SEV
is not designed to prevent DoS attacks.
I/O Security
3.2
In this section, we explore the direct consequences of unpro-
tected I/O operations from SEV-enabled guests.
3.2.1 Case Study: Integrity Breaches of Disk I/O
We ﬁrst present a case study to show how SEV’s guest VMs’
unprotected I/O operations can be exploited to breach I/O
security in practice. In this case study, we show that a ma-
licious hypervisor is able to gain control of the guest VMs
through an OpenSSH server without passwords by exploiting
unprotected disk I/O. Therefore, we assume the disk is not
encrypted with disk encryption key in this example. However,
we note it is recommended by AMD to only use encrypted
storage. As such, this case study only serves the purpose
of proof-of-concept, rather than a practical attack. We will
discuss its security implications in Section 3.2.2.
Speciﬁcally, the adversary controls the entire host and
launches the SEV-enabled VM using the standard proce-
dure [3]. During the system bootup, the binary code of
sshd that performs user authentication is loaded into the
memory. To monitor the disk I/O streams, whenever the
QEMU performs a DMA operation for the guest, the adver-
sary checks the memory buffer used for this DMA operation
(i.e., SWIOTLB) and search for the binary code of sshd. In
our implementation, we used a 32-byte memory content (i.e.,
0xff85 0xc041 0x89c4 0x8905 0x4e05 0x2900 0x0f85 0x1b01
0x0000 0x488b 0x3d49 0x0529 0x0089 0xeee8 0xc2bf 0xfdff)
as the signature of the sshd binary and no false detection
was observed. Once the DMA operation for sshd is identi-
ﬁed, the adversary modiﬁes the binary code inside SWIOTLB,
before the QEMU commits the DMA operation. In partic-
ular, this is done by replacing the crucial code used in au-
thentication that corresponds to callq pam_authenticate,
which is a ﬁve-byte binary string 0xe8 0xc2 0xbf 0xfd 0xff, to
mov $0 %eax (a binary string of 0xb8 0x00 0x00 0x00 0x00).
pam_authenticate() is used to perform user authentica-
tion; only when it returns 0 will the authentication succeed.
Therefore, by moving 0 to the register %eax (the register used
to store return value of a function call) directly, the adver-
sary can successfully bypass the user authentication without
knowing the password. To validate the attack, we empirically
conducted the attack three times and all were successful.
Performance degradation due to I/O monitoring. We also
conducted experiments to measure the performance degrada-
tion due to the hypervisor’s monitoring of disk I/O streams.
We used the dd command to write 1GB of data to the local
1260    28th USENIX Security Symposium
USENIX Association
disk ﬁlesystems. To use encrypted disks, however, the owner
needs to ﬁrst provision the disk encryption key into the pro-
tected VMs by using the Launch_Secret [3] command. This
command ﬁrst decrypts a packet sent by the VM owner (that
contains the disk encryption key) encrypted using Ktek (Trans-
port Encryption Key), atomically re-encrypts it using the
memory encryption Kvek, and then injects it into the guest
physical address speciﬁed by GUEST_PADDR (a parameter of
the Launch_Secret command). As the address of the disk
encryption key is known, if memory conﬁdentiality is com-
promised (using methods to be described in Section 3.3), the
disk encryption key can be learned and used to decrypt the
entire image. Therefore, disk I/O is not secure, either.
3.3 Decryption Oracles
In this section, we show that the DMA operations under SEV’s
memory encryption technology can be exploited to construct
a decryption oracle, which allows the adversary to decrypt
any memory block encrypted with the guest VMs’ memory
encryption key Kvek. The oracle can be frequently and repeat-
edly queried and thus can be exploited as an attack primitive
for more advanced attacks against SEV-enabled guests.
As mentioned in Section 2.3, the DMA operation from
the SEV-enabled VM is conducted with the help of memory
pages shared with the hypervisor. When DMA operates in the
DMA_TO_DEVICE mode, data is transferred by the IOMMU
hardware to the shared memory, and then copied by CPU
in the SEV-enabled VM to its private memory; when DMA
operates in the DMA_BIDIRECTIONAL mode, the SEV-enabled
VM ﬁrst copies the data from encrypted memory to the shared
memory, and then the DMA reads or writes are performed on
the shared memory.
Both these modes of operations provide the adversary an
opportunity to observe the transfer of data blocks from mem-
ory pages encrypted by Kvek to memory pages that is not
encrypted (from the hypervisor’s perspective). Therefore, if
the adversary alters the ciphertext of the data blocks in the
encrypted memory page before they are copied by the guest
VM, after the memory copy, the corresponding plaintext can
be learned from the shared memory directly.
The construction of such a decryption oracle is shown in
Figure 3. The decryption oracle can be constructed in three
steps: pattern matching, ciphertext replacement, and packets
recovery. We use network I/O as an example. The adversary
exploits the network trafﬁc in Secure Shell (SSH) to construct
the decryption oracle. But we stress that any I/O trafﬁc can be
exploited in similar manners. In the following experiments,
we conﬁgured the guest VM to use OpenSSH_7.6p1 with
OpenSSL 1.0.2n, which is default on Ubuntu 18.04.
(a) I/O write
(b) I/O read
Figure 2: Read/write performance overhead due to I/O moni-
toring.
disk to measure the I/O write speed. The dsync ﬂag of set to
make sure the data is written to the disk directly, bypassing the
page caches. To measure the read speed, we cleaned the page
caches in the memory by setting vm.drop_caches=3 before
reading 1GB of data from local disk. In both the read and write
experiments, we measured the performance with and without
I/O stream monitoring and repeated the measurements 200
times. The results show the performance degradation of I/O
read and write is 11.8% and 7.9% respectively (see Figure 2).
3.2.2 Estimating The Attack Surface
As shown in the above example, I/O operations that are not
encrypted by the software can be intercepted by the malicious
hypervisor and manipulated to compromise the SEV-enabled
guests. This vulnerability exists in all emulated I/O devices
that are commonly used in cloud VMs, such as disk I/O, net-
work I/O, and display I/O, etc. While a straightforward so-
lution is to encrypt I/O streams by software, however, this
simple method has many practical limitations in practice:
Network I/O. Network trafﬁc can only be partially encrypted,
as headers of IP or TCP cannot be encrypted. The adversary
is still able to modify the network trafﬁc to forge the IP ad-
dresses, port numbers, and encrypted metadata of the network
packets. This is true for both TLS trafﬁc and VPN trafﬁc. As
we will show in Section 3.3, encrypted trafﬁc like SSH can
still be exploited to construct memory decryption oracles.
Display I/O. Encrypting I/O trafﬁc cannot be applied when
the I/O devices cannot decrypt the I/O stream by themselves.
Display I/O is one such example. For instance, Virtual Net-
work Computing (VNC) is a graphical desktop sharing pro-
tocol that allows VMs to be remotely controlled. In KVM,
the QEMU redirects the VGA display from the guest to the
VNC protocol, which is not encrypted. Therefore, if the user
of the guest VM uses VNC to control the VM, keystroke and
mouse clicking will be learned and manipulated by the adver-
sary. To protect display I/O operations, the guest VM must be
modiﬁed to encrypt all display I/O trafﬁc and the remote user
interface must be modiﬁed accordingly to decrypt the trafﬁc.
Disk I/O. For disk I/O operations, the method recommended
by SEV [4] is for each SEV-enabled VMs to use encrypted
USENIX Association
28th USENIX Security Symposium    1261
OriginalMoinitored102.5105.0107.5110.0112.5115.0MB/sOriginalMoinitored700750800850MB/sTherefore, our attack primitives target this process. As a re-
sult, every network packet generated by the guest VM can
be exploited as a decryption oracle that helps the adversary
decrypt one or multiple memory blocks.
3.3.2 Pattern Matching Using Fine-grained Page-fault
Side Channels
Let us denote the private memory buffer as Bp, whose gPA
is Ppriv, and the shared memory buffer as Bs, whose gPA is
Pshare. The primary challenge in this attack is to identify the
Ppriv. As this address is never directly leaked, the adversary
needs to perform a page-fault side-channel analysis.
Fine-grained page-fault side channels in SEV. The page
fault side channel was ﬁrst studied by Xu et al. in the context
of Intel SGX [36]. As an SGX attacker controls the entire
operating system, he or she can manipulate the page table
entries (PTE) and set the present bit of the PTEs of pages
that are mapped to the targeted enclave. By doing so, once the
enclave program accesses the corresponding memory pages,
the control ﬂow will be trapped into the OS kernel through a
page fault exception. On x86 processors, the faulting address
will be stored in a control register, CR2 so that the page-fault
handler could learn the entire faulting address. To provide
secrecy, SGX masks the page offset of the faulting address
and leaves only the virtual page number in CR2.
Similarly, on the AMD platform, the adversary that com-
promises the hypervisor could also exploit the page-fault side
channels to track the execution of the SEV-enabled VMs. Al-
though the mapping between the guest VM’s guest virtual
address (gVA) to gPA is maintained by the guest VM’s page
table and is encrypted by Kvek, the hypervisor could manipu-
late the nested page tables (NPT) to trap the translation from
gPAs to host physical addresss (hPA). Unlike SGX, SEV does
not mask the page offset, providing more ﬁne-grained obser-
vation to the adversary.
Moreover, the page-fault error code returned in the
EXITINTINFO ﬁeld of VMCB can also be exploited in the
SEV page-fault side-channel analysis. Speciﬁcally, the page-
fault error code is a 5-bit value, revealing the information of
the page fault. For example, when bit 0 is cleared, the page
fault is caused by non-present pages; when bit 1 is set, the
page fault is caused by a memory write; when bit 2 is cleared,
the page fault takes place in the kernel mode; when bit 3 is set,
the fault is generated form a reserved bit; when bit 4 is set,
the fault is generated by an instruction fetch. The error code
provides detailed information regarding the reasons of the
page fault, which can be leveraged in side-channel analysis.
Pattern matching. With such a ﬁne-grained side channel, the
adversary could monitor the memory access pattern of the
guest when it receives an SSH packet. Particularly, after deliv-
ering an SSH packet to the SEV-enabled VM, the adversary
immediately initiates the monitoring process and marks all of
Figure 3: A decryption oracle. Step , the hypervisor con-
ducts pattern matching using page-fault side channels to de-
termine the address of Bp. Step , the hypervisor replaces a
ciphertext block in Bp with the target memory block, which
will be decrypted when copied to Bs. Step , QEMU recovers
the network packet headers.
3.3.1 SSH and Network Stacks
To control the SEV-enabled guest remotely, the owner of the
VM typically uses SSH protocol to remotely login into the
VM and controls its activities. To copy data to and from
the VM, protocols like SCP, which is built on top of SSH, is
commonly used. Particularly, we consider the SSH trafﬁc after
the remote owner has already authenticated with sshd and a
secure communication channel has been established. Because
the SSH handshake protocol is performed in plaintext, the
adversary who controls the hypervisor and QEMU can act as
a man-in-the-middle attacker and recognize the established
the secure channel by its IP addresses and TCP port number.
Once the secure channel is established, SSH command and
output data will be transferred using encrypted SSH packets
that are transmitted in interactive mode [31].
In the interactive mode, each individual keystroke guest
owner types will generate a packet that is sent to the SEV-
enabled VM, which will be transferred by DMA to a mem-
ory buffer shared between the guest and the hypervisor. The
packet is then copied by the guest to a private memory page
encrypted using Kvek. Then the data is handled by the net-
work stack in the guest OS kernel. The headers of the packet
are then removed and the payload data is forwarded to the
user-space application. Then the SSH server processes the
keystroke and responds with an acknowledgement packet.
The acknowledgement packet is copied back to the kernel
space, wrapped by the corresponding header information, and
then copied to the shared memory buffer. The last memory
copying also decrypts the memory using the guest VM’s Kvek.
1262    28th USENIX Security Symposium
USENIX Association
the guest VM’s memory pages inaccessible by clearing the
present bit of the PTEs. Every time a memory page is ac-
cessed by the guest, a page fault takes place and the adversary
is able to learn the entire faulting address Pi. Note here the
faulting address in the guest VM refers to the guest physi-
cal address as the guest virtual address is not observable by
the hypervisor. After the page fault, the adversary resets the
present bit in the PTE to allow future accesses to the page.
Therefore, with the ﬁne-grained page fault side channel, one
only needs to collect information regarding the ﬁrst access to
a memory page. The monitoring procedure stops when the
acknowledgement packet is copied into Bs. At this point, the
adversary has collected a sequence of faulting addresses .
Internally in the guest VM, when sshd is sending a packet,
the encrypted data is ﬁrst copied to the buffer of the transport