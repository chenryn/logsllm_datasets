"bulk-access-control-checks"  we  expect  a  significant 
potential  of  performance  benefit  wrt  the  experienced 
response time for the user. 
2.3 Business Object Layer 
The  business  object  layer  is  the  operating  unit 
performing the executions requested by a  user,  where 
all  data  modifying  queries  or  data  selection  requests 
are performed.  This layer does not keep track of which 
of  the  calls  are  related  to  which  process  or  task 
instance  and  which  are  independent.  All  calls  are 
treated stateless. Still, access control is needed on this 
layer  as 
today's  web  service-based  enterprise 
systems the objects are accessible independently of the 
above  layer.  To  guarantee  that  a  specific  call  is  only 
executable if the user is actually assigned to a related 
in 
task instance, every method call on the business object 
layer is secured by an access control check. Taken the 
example from the previous section, the user whose task 
it  is  to  select  or  create  a  new  supplier,  the  back  end 
system must guarantee that (only) the user performing 
the current task is eligible to query the list of suppliers 
or create a new supplier to continue the process. 
Further  access  control  needs  on  this  layer  are 
typically that a user  must hold a specific role, or that 
parameters transferred for the business object call may 
only  be  within  a  certain  range  (e.g.,  orders  are  only 
accepted up to an amount of 100k EUR). 
2.4 Access Control Reference Model 
Although the presented three presented layers  may 
be tightly linked with each other from an access control 
perspective,  it  is  still  the  case  that  each  layer  can  be 
accessed 
independently.  This  means  methods  of 
business  objects  can  also  be  called  without  the 
necessity  that  the  call  has  to  be  mediated  by  a 
workflow  engine;  the  functionality  exposed  by  the 
workflow  engine  can  also  be  used  by  third  party 
software delivering their own user interface adapted for 
their needs. For this reason it is crucial that each of the 
presented  layers  incorporates  its  own  enforcement 
components  to  realize  access  control  enforcement  on 
each layer. 
In large enterprise systems access control is usually 
based  on  the  request-response  paradigm.  It  comprises 
the  interaction  between  a  policy  enforcement  point 
(PEP) and a policy decision  point (PDP). The PEP is 
part of the application, enforcing the decisions made by 
the PDP. Each of the above presented layers contains 
one or more PEPs to enforce the decisions accordingly. 
3  Pre-emptive Caching Strategy 
3.1 Related Work 
Response 
times 
for  user 
interactions  are  of 
elementary  relevance  [7].  Responses  exceeding  0.1 
seconds  are  already  perceived  as  interruption  [3]. 
Delays  beyond  1  second  are only  acceptable  if  in  the 
execution of an application a context changes happens. 
The  decision  evaluation  process  can  be  improved 
wrt  performance  using  different  strategies.  One  is  the 
specific optimization of the policy evaluation process.  
The optimization in this case is tailored to a particular 
policy  structure.  An  example  is  given  in  [8]  which  is 
based  on  the  XACML  policy  structure.  The  author 
improved the speed of the actual policy evaluation by 
refactoring the policy such that a performance increase 
of  the  overall  policy  evaluation  can  be  achieved.  The 
146156
authors  of  [11]  optimized  the  evaluation  according  to 
the location where the policy is stored. 
Another  strategy 
to  optimize  access  control 
performance  is  in  returning  a  cached  access  control 
decision  response  instead  of  performing  the  actual 
access control decision evaluation.  
In  [1]  and  [2]  a  caching  architecture  is  presented 
which claims to increase the  probability of cache hits 
by  generating  responses  by  inferring  new  decisions 
from already cached responses. The presented caching 
strategy  is  limited  on  specific  types  of  policies.  The 
caching strategy of [1], for instance, relies on systems 
which solely use RBAC.  
In [12] the authors propose the idea of speculatively 
pre-computing  and  distributing  "junk"  authorizations 
and  plan  to  develop  methods  for  efficient  predictions 
of which authorization request(s) should be computed 
next, based on the history of prior requests. 
The  strategy  presented  in  this  paper  is  specifically 
tailored  to  business  process-driven  environments.  It 
provides a method to pre-evaluate exactly those cache 
entries  which  will  most  potentially  be  needed  next. 
Here,  we  do  not  rely  on  previous  access  requests 
received, but use the explicitly available knowledge of 
the  order  in  which  processes  and  therefore  access 
control relevant actions will be performed. 
in  Business  Process-driven 
3.2  Caching 
Environments 
is 
to  decrease 
the  overall  response 
The  goal  of  the  caching  strategy  presented  in  this 
paper 
time 
experienced  by  the  user  when  she  is  interacting  with 
the  system.  In  today's  large  enterprise  systems,  most 
actions executed by a user have to be checked against 
the system's access control policy. To reach the overall 
goal  we  concentrate  on  performance  gains  we  can 
make  by  reducing  the  response  time  attributed  to 
access  control  evaluations.  The  response  time  can  be 
reduced  if  the  most  costly  steps  during  an  access 
control evaluation can be shortened or totally removed.  
Caching of access control responses is one  way of 
reducing response times as the cost for the evaluation 
procedure can be saved - if a cache entry for the access 
request is available.  
3.2.1 Overview of Caching Strategy 
The  objective  of  the  caching  strategy  presented  in 
this  paper  is  to  provide  a  solution  that  optimizes  the 
availability  of  cache  entries  (which  in  turn  is  the 
vehicle 
experienced 
performance).  Our  solution  aims  at  confirming  the 
assumption  that  a  cache  is  most  effective  if  it  only 
increase 
overall 
the 
to 
contains  exactly  those  entries  currently  needed  (and, 
hence, only for exactly that period of time when they 
are  expected  to  be  needed).  In  business  process 
environments, there are three main sources from where 
we  can  obtain  the  information  to  predetermine  the 
actions which will be performed in immediate future.  
The  first  source  comprises  the  specifications  of  a 
system's process and task management. As seen in the 
previous sections, if a process or task instance is in one 
particular  state,  only  a  small  subset  of  transitions 
determines  which  subsequent  actions  are  possible  (to 
reach the next state).  
The second source to determine upcoming actions is 
the  link  between  the  task  of  a  workflow  and  the 
business  object  (BO)  of  the  back-end  system.  As 
already  described,  the  BO  is  called  to  perform  data 
selection and modification operations initiated from the 
workflow layer. This means, as soon as a task instance 
is  created,  it  is  very  likely  that  the  BO's  exposed 
methods relevant for the task execution will be called. 
This  may  happen  during  the  period  of  time  when  the 
task instance is active.  
The third source is the process definition, referring 
to the control flow perspective. The process definition 
specifies the order in which the tasks of a process are 
executed. It is clear that, for instance, if task 1 and task 
2 are in subsequent order the execution of task 2 will 
start as soon as task 1 is completed.  
Our approach is to use this knowledge and prepare 
the  cache  in  such  a  way  that  access  requests  can  be 
directly answered by already pre-calculated and cached 
decision  responses.  The  general  caching  strategy  for 
business processes we propose is as follows. The cache 
contains  a  set  of  cache  entries.  Each  entry  is  a  pre-
fetched  decision  response  for  an  action  which  is 
expected  to  be  called  as  one of  the  upcoming  actions 
performed  during  the  execution  of  a  business  process 
instance. In fact, an entry is exactly generated for one 
specific action, resource, subject, and process instance 
which together form what we call target. Further, each 
cache entry contains a result element which is the pre-
evaluated result for a given target. If an actual decision 
request maps to the target, the cache entries’ response 
element is returned as the decision response. 
The  cache  entries  are  built  upon  the  occurrence  of 
predefined events. We call them trigger events (TE). A 
trigger event is, for instance, the execution of a specific 
action of the process life cycle (e.g., createProcess).  
The TE provokes the creation of a cache entry based 
on a predefined successor request (SR). The SR is the 
access  request  expected  to  happen  after  the  TE 
occurred.  An  example  is  the  action  cancelProcess 
which  is  an  action  potentially  called  after  the  process 
instance was created. At some point in time the process 
ends, either by executing the cancelProcess method or 
147157
simply because all tasks have been finished. This is the 
time where the cache entries (generated specifically for 
the  actually  running  process  instance)  have  to  be 
revoked from the cache as they are of no further use. A 
second  trigger,  called  revoke  trigger  (RT)  defines  the 
action(s)  on  which  the  removal  of  the  cache  entry  is 
performed.  The  definition  of  the  trigger  event,  the 
successor 
trigger  are 
summarized  within  a  tuple  of  three  elements  called 
dependency  relation  (DR)  =  {TE,  SR,  RT}.  We  will 
elaborate on this concept in section 3.2.4. 
request,  and 
revoke 
the 
3.2.2 Constraint Types and Context Information 
Access control for business processes does not only 
comprise 
role-based  permissions  but  also  other 
constraint types such as separation of duty (a user may 
only  perform  one  of  two  exclusive  tasks),  binding  of 
duty (a user performed one of two specific tasks must 
also perform  the second one), cardinality constraints (a 
user may only perform a predefined number iterations 
of a task in the same process instance), attribute-based 
constraints  (a  certain  value  of  a  business  object  must 
respect a predefined condition), or time and date-based 
constraints (the execution of an action is dependent on 
date and time constraints). Examples are given next. 
Role-based  permission:  In  user  centric  workflows 
the  basic  building  block  for  every  action  during  a 
process  execution  is  that  the  required  permission  is 
related  to  a  role.  A  user  must  possess  a  certain  role 
which provides her with the permission to perform the 
respective  action  on  a  chosen  resource.  An  example 
would be that a task in the process for private customer 
handling  may  only  be  performed  by  users  that  are 
members of the role PrivateCustomerClerk.  
Time or Date-based constraints: Time and/or Date-
based constraints restrict a permission for the execution 
of an action based on time or date conditions. A basic 
example  is  that  a  task  may  only  be  performed  during 
working  hours  and  therefore  the  condition  6  a.m.  ≤ 
current  time  ≤  8  p.m.  must  evaluate  to  true.  Current 
time  in  this  case  is  a  dynamic  context  information 
which  is  directly  fetched  from  a  context  provider 
whenever  the  condition  has  to  be  evaluated.  Another 
example  is  that  the  duration  of  a  task  execution  is 
restricted such that a user must complete a task within 
30  minutes.  Obviously,  also  in  this  case  a  context 
provider (e.g., located with the workflow engine) keeps 
track  of  the  progressed  time  and  reports  the  elapsed 
time when needed for the evaluation of the condition.  
constraints: 
Constraints  based  on  dynamic  separation  of  duties 
(SoD)  define  that  certain  tasks  of  a  business  process 
are  exclusive  and  may  not  be  performed  by  the  same 
person.  This  means  as  soon  as  a  user  claimed  one  of 
Separation 
of  Duty 
Dynamic 
the exclusive tasks, the user may not claim any of the 
other exclusive tasks.  
Binding  of  Duty  constraints:  The  binding  of  duty 
constraint (BoD) between two tasks defines that a user 
performing one of the two tasks must also perform the 
second one.  
Attribute-based 
constraints:  There 
also 
constraints  based  on  context  information  which  is 
available  in  the  system  but  do  not  fit  any  of  the 
previously  described  constraint 
types.  The  name 
attribute-based refers to information about a subject or 
object.  
are 
3.2.4 Dependency Relations 
We already introduced the notion of a dependency 
relation  (DR)  in  the  previous  section  3.2.1.  In  this 
section we will elaborate on its definition and purpose.  
The  DR  comprises  three  elements,  namely  the 
definition of a trigger event (TE), a successor request 
3.2.3 Cache Entries 
A cache entry must hold the information needed to: 
(1) obtain the relevant cache entry from a set of entries 
for  a  decision  request;  (2)  provide  the  corresponding 
decision  response  (PERMIT  or  DENY);  and  (3) 
maintain  a  reference  to  the  corresponding  process 
instance such that the entry can be related to a specific 
process execution. 
The  cache  entry  CE(S,  A,  R,  P,  {OC},  PIID)  is  a 
tuple of 6 elements which are described as follows.  
S:  
S  is  the  subject  identifier  for  which  the  cache 
entry is generated. 
R is the respective resource identifier. 
A:   A is the respective action identifier. 
R:  
PIID:  PIID stands for process instance ID and is part 
of  the  cache  entry  to  link  a  cache  entry  to  a 
specific  process  execution  instance.  (This  is 
necessary as there might be several instances of 
the same process running in parallel.) 
S,  A,  R  and  PIID  comprise  the  target  of  the  cache 
entry.  The  target  is  needed  to  select  the  respective 