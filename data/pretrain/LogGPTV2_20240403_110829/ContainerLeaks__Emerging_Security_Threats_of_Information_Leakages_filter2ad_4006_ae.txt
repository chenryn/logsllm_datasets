### C. Performance

We utilized UnixBench to compare the performance overhead before and after enabling our system. The results are summarized in Table III. As shown, CPU benchmarks such as Dhrystone (testing integer and string operations) and Whetstone (testing floating-point arithmetic performance) exhibit negligible overhead. Other benchmarks, including shell scripts, pipe throughput, and system calls, also trigger minimal overhead.

Notably, pipe-based context switching incurs a 61.53% overhead for a single parallel copy but decreases to 1.63% for eight parallel copies. We hypothesize that inter-cgroup context switching involves enabling and disabling the performance event monitor, whereas intra-cgroup context switching does not. This could explain why eight parallel copies maintain similar performance levels even with the power-based namespace disabled. Additionally, context switching contributes only a small portion to the overall system performance overhead, resulting in a minimal impact on normal use.

As demonstrated in the last row of Table III, the overall performance overheads for UnixBench are 9.66% for one parallel copy and 7.03% for eight parallel copies. Our system's performance is heavily dependent on the implementation of perf event cgroups and could improve with advancements in the performance monitoring subsystem.

### VII. Discussion

#### A. Synergistic Power Attacks without the RAPL Channel

We observed that some container cloud servers lack RAPL or similar embedded power meters. These servers may still be vulnerable to power attacks. Without power-capping tools like RAPL, they might be susceptible to host-level power attacks on a single machine. Advanced attackers could approximate power status based on resource utilization information, such as CPU and memory usage, which is still available in identified information leakages. It would be prudent to make system-wide performance statistics unavailable to container tenants.

#### B. Complete Container Implementation

The root cause of information leakage and synergistic power attacks is the incomplete implementation of isolation mechanisms in the Linux kernel. Introducing more security features, such as additional namespaces and control groups, could help. However, partitioning some system resources, such as interrupts, scheduling, and temperature, remains challenging. Some argue that a complete container implementation is no different from a virtual machine and loses all the advantages of containers. Balancing security, performance, and usability in container clouds requires further investigation.

### VIII. Related Work

#### A. Performance and Security Research on Containers

With the recent popularity of containers, researchers have compared their performance with hardware virtualization. Felter et al. [14] found that Docker can achieve equal or better performance than KVM across CPU, memory, storage, and networking resources. Spoiala et al. [34] demonstrated that Docker outperforms KVM in real-time applications using the Kurento Media Server. Morabito et al. [30] compared Docker, LXC, and KVM, noting that Disk I/O remains a bottleneck for KVM. These studies show that container-based OS-level virtualization can outperform hardware virtualization. In terms of security, Gupta [20] and Bui [11] provided overviews and analyses of Docker security, while GrattaÔ¨Åori et al. [17] highlighted potential vulnerabilities in containers. Our work builds on these efforts by systematically identifying information leakage and investigating potential power attack threats in containers.

#### B. Cloud Security and Side/Covert Channel Attacks

Cloud security has been a focus of both academia and industry. Co-residence detection, first proposed by Ristenpart et al. [31], involves placing a malicious VM co-resident with a target VM to launch side-channel and covert-channel attacks. Liu et al. [27] and Zhang et al. [46, 47] demonstrated the practicality of cache-based side-channel attacks and proposed defense mechanisms. Thiele et al. [10, 28] used core temperature for thermal covert channels, and power consumption has been exploited to break AES [23]. Unlike previous research, we use power consumption data to detect and mitigate advanced power attacks in container clouds.

#### C. Power Modeling

In the absence of hardware-based power meters, power modeling is used to approximate power consumption. Russell et al. [32] and Chakrabarti et al. [12] proposed instruction-level power modeling, while Jiang et al. [21] and Mobius et al. [29] focused on VM-level power estimation. Shen et al. [33] introduced power containers for fine-grained energy management. Our defense against synergistic power attacks is inspired by VM power modeling, proposing a new power partitioning technique to approximate per-container power consumption and reusing the RAPL interface to address data leakage in container settings.

### IX. Conclusion

Container cloud services have become popular for providing lightweight OS-level virtual hosting environments. However, due to incomplete system resource partitioning in the Linux kernel, there are security concerns for multiple container tenants sharing the same kernel. We presented a systematic approach to discovering information leakage channels and discussed the root causes. By exploiting leaked host information, malicious container tenants can launch power attacks that jeopardize the dependability of power systems in data centers. We proposed a two-stage defense mechanism and demonstrated its effectiveness with minimal performance overhead.

### References

[References listed here, formatted as in the original text]

---

This version of the text is more structured, coherent, and professional, with clear headings and improved flow.