SON, C., AND KIRDA, E. Thou shalt not depend on me: Analysing the
use of outdated javascript libraries on the web. In Proceedings of the
Network and Distributed System Security Symposium (NDSS) (2 2017).
[21] LI, Z., ZHANG, K., XIE, Y., YU, F., AND WANG, X. Knowing your
enemy: understanding and detecting malicious web advertising.
In
Proceedings of the 2012 ACM conference on Computer and commu-
nications security (2012), ACM, pp. 674‚Äì686.
[22] MICROSOFT CORPORATION. Cognitive Services Pricing ‚Äì Bing Search
API. https://azure.microsoft.com/en-us/pricing/details/cognitive-service
s/search-api/web/, 2017.
[23] MIRAMIRKHANI, N., STAROV, O., AND NIKIFORAKIS, N. Dial one
for scam: Analyzing and detecting technical support scams.
In 22nd
Annual Network and Distributed System Security Symposium (NDSS 16
(2016), NDSS.
84
[24] NELMS, T., PERDISCI, R., ANTONAKAKIS, M., AND AHAMAD, M.
Towards measuring and mitigating social engineering software down-
load attacks. In 25th USENIX Security Symposium (USENIX Security
16) (Austin, TX, 2016), USENIX Association, pp. 773‚Äì789.
[25] NIKIFORAKIS, N., MAGGI, F., STRINGHINI, G., RAFIQUE, M. Z.,
JOOSEN, W., KRUEGEL, C., PIESSENS, F., VIGNA, G., AND ZANERO,
S. Stranger danger: exploring the ecosystem of ad-based url shortening
services. In Proceedings of the 23rd international conference on World
wide web (2014), ACM, pp. 51‚Äì62.
[26] NISHANT, D. Survey Scammers Moving to Pinterests. https://www.s
ymantec.com/connect/blogs/survey-scammers-moving-pinterest, 2014.
[27] NLTK 3.2.3 DOCUMENTATION. Natural Language Toolkit. http://ww
w.nltk.org/, 2017.
[28] OPINION MILES CLUB. Earn award miles for sharing your opinions.
https://www.opinionmilesclub.com/, 2017.
[29] OSCAR, A.
Survey Scams Aimed at Social Networking Neti-
zens. https://www.trendmicro.com/vinfo/us/threat-encyclopedia/web-a
ttack/109/survey-scams-aimed-at-social-networking-netizens, 2012.
[30] PASGRIMAUD, G. Pyquery: a jquery-like library for python, 2017.
https://pythonhosted.org/pyquery/.
[31] POLETTINI, N. The vector space model in information retrieval- term
weighting problem, 2004.
[32] PROVOS, N., MAVROMMATIS, P., RAJAB, M. A., AND MONROSE, F.
All your iframes point to us. In Proceedings of the 17th Conference
on Security Symposium (Berkeley, CA, USA, 2008), SS‚Äô08, USENIX
Association, pp. 1‚Äì15.
[33] SALTON, G., AND MCGILL, M. J. Introduction to Modern Information
Retrieval. McGraw-Hill, Inc., New York, NY, USA, 1986.
[34] SALTON, G., WONG, A., AND YANG, C. S. A vector space model for
automatic indexing. In ACM (New York, NY, USA, November 1975),
ACM, pp. 613‚Äì620.
[35] SATNAM, N.
to Survey
https://www.symantec.com/connect/blogs/instascam-instagram
Instagram for PC Leads
Instascam:
Scam.
-pc-leads-survey-scam, 2013.
[36] SCIKIT LEARN. Random Forest Algorithm. http://scikit-learn.org/sta
ble/modules/ensemble.htmlrandom-forests, 2017.
[37] SECRECTS, M. M. Earn free united miles if you have a lot of spare
time, that is!, 2016. http://millionmilesecrets.com/2014/02/27/earn-fre
e-united-miles-if-you-have-a-lot-of-spare-time-that-is/.
[38] SPRINGBORN, K., AND BARFORD, P.
advertising via pay-per-view networks.
pp. 211‚Äì226.
Impression fraud in on-line
In USENIX Security (2013),
[39] STANFORD UNIVERSITY.
scor-
ing. https://nlp.stanford.edu/IR-book/html/htmledition/the-vector-space
-model-for-scoring-1.html, 2009.
space model
The vector
for
[40] STAROV, O., GILL, P., AND NIKIFORAKIS, N. Are you sure you want
to contact us? quantifying the leakage of pii via website contact forms.
Proceedings on Privacy Enhancing Technologies 2016, 1 (2016), 20‚Äì33.
[41] STELIAN, P. Remove 2017 Annual Visitor Survey pop-up ads (Virus
Removal Guide). https://malwaretips.com/blogs/remove-2017-annual-v
isitor-survey-popups/, 2017.
[42] STELIAN, P. Remove Chrome Opinion Survey pop-ups (Virus Removal
https://malwaretips.com/blogs/remove-chrome-opinion-surve
Guide).
y-popup/, 2017.
[43] STONE-GROSS, B., ABMAN, R., KEMMERER, R. A., KRUEGEL, C.,
STEIGERWALD, D. G., AND VIGNA, G. The underground economy
of fake antivirus software. In Economics of Information Security and
Privacy III. Springer, 2013, pp. 55‚Äì78.
[44] THE WORLD WIDE WEB CONSORTIUM (W3C). Http archive (har)
format, 2012. https://dvcs.w3.org/hg/webperf/raw-file/tip/specs/HAR/
Overview.html.
[45] THOMAS, K., BURSZTEIN, E., GRIER, C., HO, G., JAGPAL, N.,
KAPRAVELOS, A., MCCOY, D., NAPPA, A., PAXSON, V., PEARCE,
P., ET AL. Ad injection at scale: Assessing deceptive advertisement
modiÔ¨Åcations. In Security and Privacy (SP), 2015 IEEE Symposium on
(2015), IEEE, pp. 151‚Äì167.
[46] THOMAS, K., CRESPO,
J.-M.,
PHILLIPS, C., DECOSTE, M.-A., SHARP, C., TIRELO, F., TOFIGH, A.,
COURTEAU, M.-A., BALLARD, L., SHIELD, R., JAGPAL, N., RAJAB,
J. A. E., RASTI, R., PICOD,
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:37:19 UTC from IEEE Xplore.  Restrictions apply. 
M. A., MAVROMMATIS, P., PROVOS, N., BURSZTEIN, E., AND MC-
COY, D. Investigating commercial pay-per-install and the distribution
of unwanted software. In 25th USENIX Security Symposium (USENIX
Security 16) (Austin, TX, 2016), USENIX Association, pp. 721‚Äì739.
[47] THOMAS, K., CRESPO, J. A. E., RASTI, R., PICOD, J. M.,
PHILLIPS, C., DECOSTE, M.-A., SHARP, C., TIRELO, F., TOFIGH,
A., COURTEAU, M.-A., ET AL.
Investigating commercial pay-per-
install and the distribution of unwanted software. In USENIX Security
Symposium (2016), pp. 721‚Äì739.
[48] VADREVU, P., RAHBARINIA, B., PERDISCI, R., LI, K., AND ANTON-
AKAKIS, M. Measuring and detecting malware downloads in live
network trafÔ¨Åc.
In European Symposium on Research in Computer
Security (2013), Springer, pp. 556‚Äì573.
[49] VISSERS, T., JOOSEN, W., AND NIKIFORAKIS, N. Parking sensors:
In Annual Network and
Analyzing and detecting parked domains.
Distributed System Security Symposium (2015), The Internet Society.
[50] WANG, Z., BOVIK, A. C., SHEIKH, H. R., AND SIMONCELLI, E. P.
Image quality assessment: from error visibility to structural similarity.
Image Processing, IEEE Transactions on 13, 4 (2004), 600‚Äì612.
[51] WHALEY, B. Toward a general theory of deception. The Journal of
Strategic Studies 5, 1 (1982), 178‚Äì192.
[52] XING, X., MENG, W., LEE, B., WEINSBERG, U., SHETH, A.,
PERDISCI, R., AND LEE, W. Understanding malvertising through ad-
injecting browser extensions. In Proceedings of the 24th International
Conference on World Wide Web (2015), WWW ‚Äô15.
[53] ZARRAS, A., KAPRAVELOS, A., STRINGHINI, G., HOLZ, T.,
KRUEGEL, C., AND VIGNA, G. The dark alleys of madison av-
enue: Understanding malicious advertisements. In Proceedings of the
2014 Conference on Internet Measurement Conference (2014), ACM,
pp. 373‚Äì380.
[54] ZAUNER, C.
Implementation and benchmarking of perceptual image
hash functions. http://www.phash.org/, 2010.
APPENDIX
A. Third-party Inclusions in Survey Gateways
To motivate our use of third-party script incidence as a
feature, we compared the usage of third-party scripts (e.g.,
advertisements) in survey gateways to benign survey pages.
Figure 8 shows the number of unique third-party scripts used as
advertisement on survey gateways versus the number of unique
third-party scripts referenced by the baseline benign survey
pages. The plot clearly shows that survey gateways include
signiÔ¨Åcantly more third-party scripts to benign survey pages.
Fig. 8: Number of included third-party scripts in the survey
scam pages.
85
B. Interacting with Survey Gateways
Our preliminary experiment on 10 survey gateways showed
that the transmitted data to servers varies if different browser
conÔ¨Ågurations and IP addresses are used, albeit providing
identical responses to the initial set of questions (e.g. age,
gender). To better explore this, we conducted a larger scale
study on 200 randomly selected survey gateways to infer
potential information Ô¨Çow into survey gateways.
Our analysis consists of two phases. In the Ô¨Årst phase, we
visited each survey gateway multiple times with an identical
browser proÔ¨Åle (i.e., same IP address and browser user-agent)
and collected raw network traces. The goal of this phase is to
construct a complete picture of the network behavior of a given
survey gateway. Note that determining the number of times to
visit a gateway website in order to draw a comprehensive view
of its network behavior strongly depends on the complexity of
network traces between the survey gateway and the browser.
For example, the number and sources of non-deterministic
parameters usually vary from website to website and can
have signiÔ¨Åcant impacts on our analysis in this experiment.
By performing a differential analysis on the collected traces,
we empirically observed that running the Ô¨Årst phase of the
experiment three times is sufÔ¨Åcient to reach convergence and
identify potential discrepancies in the traces for a large number
of websites in our dataset.
To this end, we collected the raw HTTP trafÔ¨Åc sent to
survey gateways and also monitored their interactions with
browser features such as WebStorage APIs (i.e., LocalStorage,
SessionStorage). We then checked the raw HTTP trafÔ¨Åc and
searched for values by string comparison to Ô¨Ånd any potential
sources of non-determinism. We used similar techniques that
prior work [40] employed to extract speciÔ¨Åc values in the
network trafÔ¨Åc. In fact, we labeled any parameters that varied
during the Ô¨Årst phase in which we did not alter any source
of information. We then combined all the traces and deÔ¨Åned
the behavior summary of the given survey gateway, which
was then used in the second phase of the experiment. In the
second phase, after visiting the survey gateway with a different
browser user-agent, we monitored the information sent
to
the server to identify potential sources of non-determinism.
Figure 9 illustrates a simpliÔ¨Åed version of our experiment on
one of the survey gateways.
From the 200 randomly selected survey gateways, we
observed that 144 (72%) of them were interacting with browser
WebStorage APIs by calling set and get functions. However,
112 (56%) of all the websites did not reach convergence during
the Ô¨Årst phase of our analysis, or we were not able to extract
any particular patterns due to multiple levels of encoding.
Our empirical analysis on the network traces shows that
among all the remaining 88 (44%) cases, the most common
sources of non-determinism were timestamps, dates, cookies
or session identiÔ¨Åers assigned by gateways. This experiment
clearly implies that the interaction with survey gateways relies
on creating and maintaining unique IDs for visiting users. In
fact, survey gateways differentiate among visiting users and
redirect them to survey publishers based on their browser
conÔ¨Åguration and responses to the initial set of questions.
However, we cannot claim that the interaction between survey
gateways and publishers relies solely on the set of unique
IDs that we observed by interacting with survey gateways.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:37:19 UTC from IEEE Xplore.  Restrictions apply. 
Furthermore, we do not know whether adversaries use any
speciÔ¨Åc technique besides the user-agent analysis, nor have
we investigated enough to make statistically signiÔ¨Åcant claims
about any particular types of Ô¨Ångerprinting techniques.
9LVLW
9LVLW

0RQLWRULQJ7UDIILF
RYLHV FRP"DGW
KWWSEOSPRYLHVFRP"DGW\SH GLUHFWBSRS	XWLPH 
KWWSEOSPRYLHVFRP"DGW
K
W\SH GLUHFWBSRS	XWLPH 
W\SH GLUHFW
IGL
GV
IGLGV



GV
IGL
9DOXH
OXH
9DO
.H\
\.H\
87,0(
.7;

IGLGV
KWWSEOSPRYLHVFRP"DGW\SH GLUHFWBSRS	XWLPH 
KWWSEOSPRYLHVFRP"DGW\SH GLUHFWBSRS	XWLPH 
IGLGV
IGLGV
IGLGV
.H\
.H\
87,0(
.7;

IGLGV
9DOXH
OXH
9DO
B
9LVLW
KWWSEOSPRYLHVFRP"DGW\SH GLUHFWBSRS	XWLPH 
KWWSEOSPRYLHVFRP"DGW\SH GLUHFWBSRS	XWLPH 
K
IGLGV
IGLGV
IGLGV

B
.H\
\.H\
87,0(
.7;
9DOXH
9DOXH

IGLGV
9LVLW
KWWSEOSPRYLHVFRP"DGW\SH GLUHFWBSRS	XWLPH 
KWWSEOSPRYLHVFRP"DGW\SH GLUHFWBSRS	XWLPH 
YK\\
YK\\
YK\\
.H\
.H\
87,0( 
.7;
YK\\
9DOXH
9DOXH
B
1
1HWZRUN6XPPDU\
'
'LIIHUHQWLDO$QDO\VLV
$GW\SH DGBW\SH!	
XWLPH XWLPH!IGLGV
XWLPH!IGLGV
XWLPH!IGLGV
XWLPH!YK\\
XWLPH!YK\\
$GW\SH DGBW\SH!	
XWLPH XWLPH!YK\\
Fig. 9: An example of how we analyzed the browser interaction
with survey gateways. In the Ô¨Årst phase, we create a behavior
summary of a given survey gateway by visiting the website
n times, and locating non-deterministic parameters. In the
second phase, we perform a differential analysis by changing
the browser setting and IP address to identify differences in
HTTP trafÔ¨Åc.
C. Exposing Victims to Scam Pages After Filling Out a Survey
Page
After completing a survey, victims are redirected to a new
page, and are usually asked to enter sensitive information, such
as a credit card number, along with other information to receive
rewards. Figure 10 shows an example of a scam page after
completing a survey.
Fig. 10: An example of a scam page that a user is exposed to
after Ô¨Ålling out a survey.
86
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:37:19 UTC from IEEE Xplore.  Restrictions apply.