for a node with several thousands of peers. The other factor
that affects scalability is the number of attack reports, as a
separate trafﬁc tree is built for each report. We plan to inves-
tigate strategies to combine trafﬁc trees in cases when mul-
tiple attack reports coincide, but we expect that this should
not be a frequent situation.
5. Implementation
We implemented DefCOM in a Linux router (RedHat
9.0), with the packet marking, WFSA and rate limiting be-
ing implemented as a loadable kernel module, and the mes-
saging between peers implemented at the application layer.
We couple an alert generator with a simple mechanism
that detects an attack if one of the following rules become
5
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:32:41 UTC from IEEE Xplore.  Restrictions apply. 
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006true: (Rule 1) The ratio of the incoming to outgoing TCP
packets is higher than 3. This rule tests in a crude manner if
the incoming TCP trafﬁc is congestion responsive; (Rule 2)
The total incoming trafﬁc rate is larger than the bottleneck
link bandwidth during last 3 seconds. This attack detection
is simple but sufﬁcient to detect attacks in our experiments.
In a real deployment, an alert generator should be coupled
with more sophisticated detection mechanisms, and our fu-
ture work will integrate [12] with DefCOM.
We couple D-WARD [7, 8] with a classiﬁer. D-WARD
prevents outgoing DoS attacks by keeping statistics on in-
coming and outgoing packet counts for each TCP connec-
tion established with the victim, and using these statistics to
differentiate legitimate from attack trafﬁc. D-WARD classi-
ﬁes TCP connections with low sent-to-received packet ratio
as legitimate, and uses application-level models for detec-
tion of legitimate UDP connections. It also distinguishes
legitimate TCP SYN packets by performing sequence num-
ber prediction for known source hosts. D-WARD can de-
tect and respond to attacks autonomously, but we disabled
these functionalities to force D-WARD to act as pure trafﬁc
classiﬁcation engine. Other trafﬁc classiﬁcation approaches
could be interfaced with DefCOM, such as [18].
We deploy the WFSA algorithm in the rate limiter, using
ideas from core-stateless fair queuing [15]. WFSA has two
trafﬁc classes: HIGH and LOW priority. The algorithm es-
timates the resource consumption rate in class i after receipt
of a packet of size li, as:
i = (1 − e−dTi/S) li
rnew
dTi
+ rold
i e−dTi/S, i = 1...n (1)
where ri is the consumption estimation, dTi is the time
elapsed from the last packet’s arrival, S is the average time
interval for the estimation and n is the total number of the
classes. After each packet’s arrival, its forwarding probabil-
ity pF W is computed as [15]:
pF W = min(1,
wi · α
ri
) i = 1...n
(2)
where wi is the weight for the class i, and α denotes
the fair share of RLM. The fair share is updated every
Pn
K seconds (currently K= 0.333) by ﬁrst calculating the
true resource consumption rate Ri for each class i.
If
i=0 Ri ≤ RLM, then the link is not congested and we
overreaction to trafﬁc bursts. IfPn
set α = maxi=1...n(Ri). We do not allow α to decrease
more than 20% during two consecutive updates, to avoid
i=0 Ri > RLM, then α
is the unique solution of the equation
nX
i=1
(Ri, wi ∗ α) = RLM
min
i
(3)
6
Figure 2. Large-scale topology
6. Evaluation
We evaluate DefCOM in live-trafﬁc experiments in the
Emulab testbed [17].
In all experiments we create legit-
imate trafﬁc by establishing multiple telnet-like sessions
over TCP between good clients and the victim. The attack
is created by sending high-volume TCP data packets to the
victim, using the raw socket functionality. Although a lot
of bandwidth attacks use UDP or ICMP trafﬁc, we delib-
erately chose TCP to make the attack trafﬁc similar to the
legitimate trafﬁc. Modern DoS tools use the same variety of
attacks for bandwidth exhaustion, their sophistication lies
only in hiding control trafﬁc between attack machines.
We initially conducted many experiments to test Def-
COM’s performance using the simple topology of Fig 1,
and varying legitimate trafﬁc (FTP-like vs telnet-like) and
attacks (UDP, ICMP, TCP ﬂoods). Due to space constraints
we summarize the results from these small-scale experi-
ments and we next present in detail experiments in a large-
scale topology.
In classiﬁer tests we concluded that: (1) Legitimate traf-
ﬁc receives priority treatment by DefCOM and is well iso-
lated from the attack; (2) Trafﬁc classiﬁcation and isolation
are not sensitive to variations in legitimate and attack trafﬁc
rates, but higher rates introduce more variance in legitimate
trafﬁc’s service.
In rate limiter tests we concluded that: (1) Legitimate
trafﬁc from a network with a classiﬁer receives priority
treatment by DefCOM and is well isolated from the attack;
(2) Trafﬁc classiﬁcation and isolation are not sensitive to
variations in legitimate and attack trafﬁc rates; (3) Legiti-
mate trafﬁc from legacy networks competes with the attack
for bandwidth; (4) We denote as malicious the trafﬁc that
comes from attack hosts, but is marked with HIGH mark
by a malicious classiﬁer. Malicious trafﬁc competes with
legitimate trafﬁc for bandwidth. Attackers must generate
limited-rate malicious trafﬁc to pass the non-aggressive test.
In the next set of experiments we test DefCOM with the
topology shown in Fig. 2. There are three levels of routers,
and 48 trafﬁc sources. The bottleneck link leads from a
level-1 router to the victim and its size is RLM=2 Mbps.
In all tests R1.1 deploys a rate limiter and an alert genera-
tor. Attack hosts are deployed in Net1 on 2 out of each 3
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:32:41 UTC from IEEE Xplore.  Restrictions apply. 
R3.11R3.412R2.1R1.1V2MbpsNet1...R3.513R3.824R2.2Net2...R3.925R3.1236R2.3Net3...R3.1337R3.1648R2.4Net4...Level 1Level 2Level 3Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006hosts (hosts 2, 3, 5, 6, 8, 9, 11, 12) and in Net3 and Net4
throughout (hosts 25-48). The legitimate hosts are in Net1
(hosts 1, 4, 7 and 10) and in Net2 (13-24). Total legitimate
trafﬁc reaching the bottleneck link is 0.7*RLM. Since each
legitimate host sends at the same rate, the baseline value for
legitimate trafﬁc from Net1 is 0.525*RLM and for Net2 it
is 0.175*RLM. Without DefCOM, the attack occupies all of
the bottleneck’s bandwidth and completely denies service to
legitimate trafﬁc. This topology and settings are similar to
Pushback dense experiments from [5], where trafﬁc from
Net1 was called “poor” because it shares the path with the
attack before it reaches defense nodes. Pushback, as well
as many other defenses, cannot help such users and inﬂict
collateral damage to poor trafﬁc. We expect DefCOM to
protect this trafﬁc when classiﬁers are deployed in Net1. In
experiments we use two attack rates: the low rate generates
2.88 Mbps ﬂow on the bottleneck link, while the high rate
generates 4.8 Mbps.
We acknowledge that the topology we use, containing
70 PCs, does not match the scale of real DDoS attacks that
involve hundreds of thousands of nodes. However, our ex-
periments involve live trafﬁc generated from real PCs. We
chose live trafﬁc experimentation over simulation because
current network simulators cannot faithfully capture net-
work behavior under extreme trafﬁc load. Due to the dis-
ruptive nature of our experiments they must be fully con-
tained in an isolated testbed. Two large testbeds accessible
to researchers, Emulab [17] and Deter [2] have on the order
of 200 nodes each, and these nodes are shared among mul-
tiple researchers. Under these circumstances, we designed
our experiments with a largest topology we could obtain
for our exclusive use. While these experiments are smaller-
scale than real DDoS events, they are largest non-simulated
DDoS experiments in the research literature.
6.1. Full Deployment
In the experiments FL1 and FL2 we test DefCOM under
full deployment, with high-rate and low-rate attack trafﬁc.
This illustrates DefCOM’s performance in an ideal setting,
if it were widely deployed, and also represents a baseline to
compare with partial deployment results. We deploy clas-
siﬁers at all level-3 routers and we deploy rate limiters at
all level-2 routers. Fig. 3 shows the usage of the bottle-
neck link by legitimate and attack trafﬁc, and the goodput
of clients from Net1 and Net2. Since the graphs for low and
high attack rates are almost identical, we show here only the
graph for the high-rate experiment (FL2). In both experi-
ments, trafﬁc from Net1 and from Net2 is well-protected by
DefCOM and reaches its baseline values, shown on the Fig-
ure. The rest of the bandwidth is used by the attack trafﬁc.
The protection is especially well illustrated on the goodput
graphs that compare the goodput during an attack with the
baseline goodput without the attack — these two lines over-
lap indicating that legitimate users experience no denial-of-
service effect.
6.2. Partial Deployment
In the experiments PT1—PT3 we test how DefCOM per-
forms in partial, non-contiguous deployment. In all tests we
generate a high-rate attack from the attack hosts. In the ex-
periment PT1 we deploy classiﬁers on all level-3 routers.
Level-2 routers are not participating in DefCOM. We see
from Fig. 4 that DefCOM’s performance in this case is
identical with a fully-deployed DefCOM. In the experiment
PT2 we explore a more realistic case when the classiﬁers are
deployed only in front of Net2 nodes — at routers R3.5—
R3.8. Results in Fig. 4 show that DefCOM successfully
protects legitimate trafﬁc from Net2. This trafﬁc is deliv-
ered to the victim at the same level as the baseline. The sum
of unstamped legitimate trafﬁc from Net1, and the attack
from Net3 and Net4 exceeds RLM at the rate limiter R1.1
and fails the non-aggressive test. Almost all this trafﬁc is
dropped by DefCOM, which explains why less attack traf-
ﬁc reaches the bottleneck link than in full-deployment ex-
periments. In the experiment PT3 we test if we can improve
the protection of the legacy trafﬁc from Net1 by deploying
a rate limiter at node R2.1. The protection of Net1 trafﬁc is
now comparable to the full deployment case, since this traf-
ﬁc is marked LOW and treated differently from high-rate
unstamped attack trafﬁc.
6.3. Malicious classiﬁers
Finally, we test how DefCOM performs when attackers
deploy malicious classiﬁers in front of their machines and
mark all trafﬁc as legitimate. We only generate attack traf-
ﬁc from machines 25—48, i.e., we remove attackers from
Net1. In the experiments ML1 and ML2, rate limiters are
deployed on routers R2.3 and 2.4, trusted classiﬁers are in
front of Net2 on routers R3.5—R3.8 and malicious classi-
ﬁers are on routers R3.9—R3.16. The attack is conﬁgured
to be low at the second level, so that the rate limiters R2.3
and 2.4 will not reclassify the trafﬁc as unstamped accord-
ing to the rule 1 in Section 2.3. We manually disable active
testing in ML1, and we enable it in ML2. Figure 5 shows the
throughput on the bottleneck link. Without active testing,
legitimate trafﬁc receives a very low share while aggressive
distributed attack dominates the bottleneck link. With ac-
tive testing, the malicious classiﬁers are identiﬁed after 50
seconds and its trafﬁc is being dropped. Legitimate trafﬁc
reaches its baseline levels after this testing period and is no
further impacted by the attack. We note that legacy trafﬁc
from Net1 is also well-protected and isolated from the at-
tack, even though this network does not deploy a classiﬁer.
7
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:32:41 UTC from IEEE Xplore.  Restrictions apply. 
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006(a) Throughput in FL2
(b) Goodput of Net1 in FL2
(c) Goodput of Net2 in FL2
Figure 3. Full deployment experiments
(a) Throughput in PT1
(b) Throughput in PT2
(c) Throughput in PT3