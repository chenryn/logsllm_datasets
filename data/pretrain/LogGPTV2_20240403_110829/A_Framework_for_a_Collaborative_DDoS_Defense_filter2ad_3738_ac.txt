### Scalability and Implementation

For a node with several thousand peers, scalability is influenced by the number of attack reports. Each report necessitates the construction of a separate traffic tree. We are planning to investigate strategies for combining traffic trees when multiple attack reports coincide, though we anticipate that this will not be a common occurrence.

### 5. Implementation

We implemented DefCOM on a Linux router (RedHat 9.0), with packet marking, WFSA, and rate limiting developed as a loadable kernel module. Peer-to-peer messaging was implemented at the application layer. An alert generator, coupled with a simple mechanism, detects an attack if one of the following conditions is met:

1. **Rule 1:** The ratio of incoming to outgoing TCP packets exceeds 3. This rule serves as a basic test to determine if the incoming TCP traffic is congestion-responsive.
2. **Rule 2:** The total incoming traffic rate exceeds the bottleneck link bandwidth over the last 3 seconds.

This detection method, while simple, was sufficient for our experiments. In a real-world deployment, more sophisticated detection mechanisms, such as those described in [12], would be integrated with DefCOM.

We also integrated D-WARD [7, 8] with a classifier. D-WARD prevents outgoing DoS attacks by maintaining statistics on incoming and outgoing packet counts for each TCP connection established with the victim. These statistics help differentiate between legitimate and attack traffic. D-WARD classifies TCP connections with a low sent-to-received packet ratio as legitimate and uses application-level models to detect legitimate UDP connections. It also distinguishes legitimate TCP SYN packets by performing sequence number prediction for known source hosts. Although D-WARD can autonomously detect and respond to attacks, we disabled these functionalities to use it solely as a traffic classification engine. Other traffic classification approaches, such as [18], could also be interfaced with DefCOM.

The WFSA algorithm was deployed in the rate limiter, using concepts from core-stateless fair queuing [15]. WFSA has two traffic classes: HIGH and LOW priority. The resource consumption rate in class \(i\) after receiving a packet of size \(l_i\) is estimated as:
\[
r_{\text{new}}^i = (1 - e^{-dT_i/S}) l_i + r_{\text{old}}^i e^{-dT_i/S}, \quad i = 1...n
\]
where \(r_i\) is the consumption estimation, \(dT_i\) is the time elapsed since the last packet's arrival, \(S\) is the average time interval for the estimation, and \(n\) is the total number of classes. After each packet's arrival, its forwarding probability \(p_{FW}\) is computed as:
\[
p_{FW} = \min\left(1, \frac{w_i \cdot \alpha}{r_i}\right), \quad i = 1...n
\]
where \(w_i\) is the weight for class \(i\), and \(\alpha\) denotes the fair share of the Rate Limiting Module (RLM). The fair share is updated every \(K\) seconds (currently \(K = 0.333\)) by first calculating the true resource consumption rate \(R_i\) for each class \(i\).

- If \(\sum_{i=0}^n R_i \leq RLM\), the link is not congested, and \(\alpha\) is set to \(\max_{i=1...n}(R_i)\). We do not allow \(\alpha\) to decrease by more than 20% during two consecutive updates to avoid overreaction to traffic bursts.
- If \(\sum_{i=0}^n R_i > RLM\), \(\alpha\) is the unique solution of the equation:
\[
\sum_{i=1}^n (R_i, w_i \cdot \alpha) = RLM
\]

### 6. Evaluation

We evaluated DefCOM using live-traffic experiments in the Emulab testbed [17]. Legitimate traffic was generated by establishing multiple telnet-like sessions over TCP between good clients and the victim. The attack was created by sending high-volume TCP data packets to the victim using raw socket functionality. We chose TCP to make the attack traffic similar to legitimate traffic, although many bandwidth attacks use UDP or ICMP.

#### 6.1. Full Deployment

In experiments FL1 and FL2, we tested DefCOM under full deployment with both high-rate and low-rate attack traffic. This setup represents an ideal scenario where DefCOM is widely deployed and serves as a baseline for comparing partial deployment results. Classifiers were deployed at all level-3 routers, and rate limiters were deployed at all level-2 routers. Figure 3 shows the usage of the bottleneck link by legitimate and attack traffic, as well as the goodput of clients from Net1 and Net2. The graphs for low and high attack rates are nearly identical, so only the high-rate experiment (FL2) is shown. In both experiments, traffic from Net1 and Net2 was well-protected by DefCOM and reached their baseline values. The rest of the bandwidth was used by the attack traffic. The protection is evident in the goodput graphs, which show no denial-of-service effect for legitimate users.

#### 6.2. Partial Deployment

In experiments PT1-PT3, we tested DefCOM in partial, non-contiguous deployment. A high-rate attack was generated from the attack hosts in all tests.

- **PT1:** Classifiers were deployed on all level-3 routers, but level-2 routers did not participate in DefCOM. Figure 4 shows that DefCOM's performance in this case was identical to full deployment.
- **PT2:** Classifiers were deployed only in front of Net2 nodes (routers R3.5-R3.8). DefCOM successfully protected legitimate traffic from Net2, delivering it to the victim at the same level as the baseline. The sum of unstamped legitimate traffic from Net1 and the attack from Net3 and Net4 exceeded RLM at the rate limiter R1.1, failing the non-aggressive test. Most of this traffic was dropped by DefCOM, resulting in less attack traffic reaching the bottleneck link compared to full-deployment experiments.
- **PT3:** To improve the protection of legacy traffic from Net1, a rate limiter was deployed at node R2.1. The protection of Net1 traffic became comparable to the full deployment case, as this traffic was marked LOW and treated differently from high-rate unstamped attack traffic.

#### 6.3. Malicious Classifiers

Finally, we tested DefCOM when attackers deployed malicious classifiers in front of their machines and marked all traffic as legitimate. Attack traffic was generated only from machines 25-48, removing attackers from Net1. In experiments ML1 and ML2, rate limiters were deployed on routers R2.3 and R2.4, trusted classifiers were in front of Net2 on routers R3.5-R3.8, and malicious classifiers were on routers R3.9-R3.16. The attack was configured to be low at the second level, so the rate limiters R2.3 and R2.4 would not reclassify the traffic as unstamped according to Rule 1 in Section 2.3. Active testing was manually disabled in ML1 and enabled in ML2. Figure 5 shows the throughput on the bottleneck link. Without active testing, legitimate traffic received a very low share, while the aggressive distributed attack dominated the bottleneck link. With active testing, malicious classifiers were identified after 50 seconds, and their traffic was dropped. Legitimate traffic reached its baseline levels after this testing period and was no longer impacted by the attack. Legacy traffic from Net1 was also well-protected and isolated from the attack, even though this network did not deploy a classifier.