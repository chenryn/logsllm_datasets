[WNR20]
[WNT20]
[Wui13]
[Wui19]
[Zmn19]
David Wagner. A generalized birthday problem. In Moti Yung, editor, CRYPTO 2002, volume
2442 of LNCS, pages 288–303. Springer, Heidelberg, August 2002.
John Wigley. Removing need for rng in signatures. Message posted to the sci.crypt mailing list,
1997. http://groups.google.com/group/sci.crypt/msg/a6da45bcc8939a89.
Pieter Wuille, Jonas Nick, and Tim Ruﬃng. Schnorr signatures for secp256k1. Bitcoin Improve-
ment Proposal 340, 2020. See https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki.
Pieter Wuille, Jonas Nick, and Anthony Towns. Taproot: Segwit version 1 output spending rules.
Bitcoin Improvement Proposal 341, 2020. See https://github.com/bitcoin/bips/blob/master/
bip-0341.mediawiki.
Pieter Wuille. Hierarchical deterministic wallets. Bitcoin Improvement Proposal 32, 2013. See
https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki.
Pieter Wuille. Reference implementation of arithmetic circuit and curve selection code, 2019.
https://github.com/sipa/purify.
ZmnSCPxj.
lightning-dev/2019-June/002028.html.
https://lists.linuxfoundation.org/pipermail/
Escrow over lightning?, 2019.
(s1,...,sn)∈Sn
|µ(s1)··· µ(sn) − ν(s1)··· ν(sn)|
A Proof of Lemma 1
We proceed by induction. The result obviously holds for n = 1. Assuming that it holds for
n − 1, we prove that it holds for n. For s ∈ S, let µ(s) ··= Pr [X = s] and ν(s) ··= Pr [Y = s].
2∆(X(n), Y (n)) = X
Then, we derive the induction step as follows.
= X
≤ X
X
|µ(s1)··· µ(sn) − µ(s1)··· µ(sn−1)ν(sn)
+ µ(s1)··· µ(sn−1)ν(sn) − ν(s1)··· ν(sn)|
µ(s1)··· µ(sn−1) · |µ(sn) − ν(sn)|
ν(sn) · |µ(s1)··· µ(sn−1) − ν(s1)··· ν(sn−1)|
(s1,...,sn)∈Sn
(s1,...,sn)∈Sn
=
|
(s1,...,sn)∈Sn
(s1,...,sn−1)∈Sn−1
+ X
µ(s1)··· µ(sn−1)
{z
}
+ X
X
=1
ν(sn)
|
{z
}
≤ 2n · ∆(X, Y ).
sn∈S
|
· X
|
sn∈S
|µ(sn) − ν(sn)|
}
{z
=2∆(X,Y )
|µ(s1)··· µ(sn−1) − ν(s1)··· ν(sn−1)|
}
{z
≤2(n−1)∆(X,Y )
·
(s1,...,sn−1)∈Sn−1
=1
B Security Proof
In this section, we prove the security of MuSig-DN as stated in the following theorem that we
recall from Section 4.
Theorem 1. Let GrGen be a group generation algorithm for which the DL problem is hard and
GrGen0 be a (t, ε)-companion group generation algorithm for which the DDH problem is hard.
Let KeyDer be a PRNG, RandDer a PRF, and Π be a zero-knowledge and simulation-sound
29
NIZK proof system for relation R as deﬁned in Eq. (2) for some set F. Then the multi-signature
scheme MS ··= MuSig-DN[GrGen, GrGen0, KeyDer, RandDer, Π,F] is EUF-CMA-secure in the
random oracle model.
Precisely, for any p.p.t. adversary A making at most qh random oracle queries and initiating
at most qs instances of the signature protocol with the honest signer, there exist p.p.t. adversaries
Bprng, Bprf, Bsnd, Bzk, Bss, Bdl, and Bddh with
(λ)(cid:17)1/4
(λ) + qsε + (qh + qs + 1)2
(λ) + Advsnd
Π,Bsnd
2λ−2
RandDer,Bprf
GrGen,Bdl
(λ) + Advprf
(λ) + Advss
Π,Bss
(λ)
Π,Bzk
(λ) + Advzk
+ 2
2λ/4 .
MS,A (λ) ≤ (qh + qs + 1)3/4(cid:16)Advdl
Adveuf-cma
+ Advprng
+ Advddh
KeyDer,Bprng
GrGen0,Bddh
We start with a brief overview of the proof (using the notation of Section 4). The general
strategy is similar to the security proof of MuSig [MPSW19]: we describe a reduction to the
DL problem which simulates the honest prover without knowledge of its secret key x1 and
then extracts x1 from the forgery returned by the attacker. To this end, we use the Forking
Lemma [PS00] twice: ﬁrst to extract the discrete logarithm of the aggregate key involved in the
forgery, and then to extract the discrete logarithm of the honest user’s public key X1. The main
diﬀerence to the security proof of MuSig lies in how the signature oracle corresponding to the
let R1 ··= s1G− ca1X1, and to program Hsig(eX, eR, m) ··= c. Then r1 ··= s1 − ca1x1 is uniformly
honest user is simulated. As usual with Schnorr signatures, the idea is to draw s1, c ←$ Fp, to
random in Fp, which under DDH and by the assumption that f is regular is indistinguishable
from f(u1Hnon(K, m)). Moreover, since R1 is not generated as speciﬁed by the protocol, we
switch to simulated NIZK proofs, which by the zero-knowledge property of the proof system
are indistinguishable from normal proofs.
queried Hsig on input (eX, eR, m). This implies that Hsig must be programmed before the
In order to be able to program Hsig adequately, the adversary must not have previously
reduction sends R1 to the adversary. The reduction programs Hnon(K, m) ··= vP for v ←$ Zq,
and hence to compute eR and program Hsig (more precisely, the adversary cannot send a nonce
which allows to compute the nonces Ri (i ≥ 2) that will be sent by the adversary as Ri = f(vUi)
diﬀerent from Ri unless it breaks simulation-soundness of Π).
Note that the adversary might copy the honest signer’s host key and set Ui = U1. This case
must be handled before the switch to simulated proofs since afterwards, there are two possible
nonces that the adversary could send and that would not allow to break simulation-soundness
of Π: the (fake) nonce R1 sent by the reduction and the correct nonce f(u1V )P. For host keys
Ui 6= U1, checking correctness of the nonce Ri sent by the adversary requires knowledge of
the discrete logarithm of Hnon(K, m). However, programming Hnon(K, m) ··= vP can only be
done after the reduction step to DDH, hence after the switch to simulated proofs and random
nonces, so that the two cases Ui = U1 and Ui 6= U1 must be handled separately.
Proof. Let MS ··= MuSig-DN[GrGen, GrGen0, KeyDer, RandDer, Π,F] and A be an adversary
against the EUF-CMA-security of MS. We proceed with a sequence of games whose formal
deﬁnition can be found in Fig. 6 to Fig. 8. Since we work in the ROM, hash functions Hagg,
Hsig, and Hnon are replaced with random oracles ROagg, ROsig, and ROnon respectively. For
brevity we let −−→RO ··= (ROagg, ROsig, ROnon).
30
Game0. This is the original unforgeability experiment of Deﬁnition 4 applied to MS where
we made the following changes. First, the nonce/host key pair (u1, U1) for the honest user is
computed during the initialization of the game and U1 is given as input to A. Clearly, this is
w.l.o.g as the ﬁrst message sent by the honest user in a signing session is always U1. Second, we
omit the ﬁrst round of the signing protocol where host keys are exchanged: instead, the adversary
calls the signing oracle Sign on input (K, m) where K is a multiset of veriﬁcation/host key
pairs {(X1, U1), . . . , (Xn, Un)}, and the oracle returns ⊥ in case (X1, U1) /∈ K. Again, this is
w.l.o.g. as this is equivalent to A calling the signing oracle on input a multiset of veriﬁcation
keys X, the oracle sending U1 if X1 ∈ X and ⊥ otherwise, and the adversary answering with
U2, . . . , Un. Finally, values W, r1, and ρ computed by oracle Sign are stored in tables Tddh,
Trand, and Tρ respectively, so that they are not computed again if Sign is called twice or more
on the same inputs (K, m). This is purely syntactical and will simplify game hops later. Hence,
one has
Advgame0
MS,A (λ) = Adveuf-cma
MS,A (λ).
Game1. In Game1, we draw x1, u1, and k uniformly at random instead of drawing sk1 and
calling KeyDer(sk1). It is straightforward to construct an adversary Bprng against the PRNG-
security of KeyDer which on input (x1, u1, k) simulates Game0 if (x1, u1, k) = KeyDer(sk1) and
Game2 if (x1, u1, k) is uniformly random. Hence,
MS,A (λ) ≥ Advgame0
MS,A (λ) − Advprng
Advgame1
KeyDer,Bprng
(λ).
Game2. In Game2, we draw ρ uniformly at random instead of calling RandDer(k, (K, m)), and
store it in a table Tρ (this way, the same bitstring ρ is used if Sign(K, m) is called again). It
is straightforward to construct an adversary Bprf against the PRF-security of RandDer which
simulates Game1 if ρ = RandDer(k, (K, m)) and Game2 if ρ is uniformly random. Hence,
Advgame2
MS,A (λ) ≥ Advgame1
MS,A (λ) − Advprf
RandDer,Bprf
(λ).
Game3. In Game3, during a call to Sign(K, m), we check whether the adversary copied the
honest user’s host key U1 and managed to return a nonce diﬀerent from R1 yet with an
accepting proof, and abort the game if this is the case. Since for a nonce Ri 6= R1, the tuple
(U1, V, Ri) cannot be in the language, this breaks soundness of Π. More precisely, we construct
an adversary Bsnd for game SNDΠ. It receives crs ←$ Π.Setup(1λ) and simulates Game3. If the
game ends up at line (I), Bsnd returns the corresponding tuple (U1, V, Ri), otherwise it aborts.
Since Bsnd wins game SNDΠ exactly when Game2 returns true but Game3 does not, we have
Advgame3
MS,A (λ) ≥ Advgame2
MS,A (λ) − Advsnd
Π,Bsnd
(λ).
Game4. We deﬁne Game4 from Game3 by switching to simulated proofs. In the previous Game3
we ensure that the same protocol inputs (K, m) yield the same prover randomness ρ and in
turn the same NIZK proof π1 by storing ρ in table Tρ and passing it as an explicit randomness
argument to Π.Prv. To ensure that the same is true in Game4, we store and pass ρ as an explicit
randomness argument to Π.SimPrv in Game4 in an analogous manner. Game4 is easily shown to
be indistinguishable from Game3 by constructing the following adversary Bzk for game ZKΠ: it
receives crs (which is either generated by Π.Setup or Π.SimSetup) and simulates Game3/Game4,
querying its oracle Prove((U1, V, R1), u1) when producing a proof. It returns 1 if the game
31
returns true and 0 otherwise. Since Bzk exactly simulates Game3 or Game4 depending on the
random bit of the challenger of the ZKΠ game, one has
Advgame4
MS,A (λ) ≥ Advgame3
MS,A (λ) − Advzk
Π,Bzk
(λ).
Game5. We deﬁne Game5 as Game4 except that during a call to Sign(K, m), the group
element W, which is computed as u1V in Game4, is drawn uniformly at random and stored
in a table Tddh (this way, the same group element W is used if Sign(K, m) is called again).
We construct an adversary Bddh solving the DDH problem in E as follows. On input a DDH
instance (U1, ¯V , ¯W), Bddh simulates Game4/Game5 as follows: it draws x1 ←$ Fp, computes
X1 ··= x1G, and runs A on input (par, X1, U1). When an assignment to Tnon(K, m) occurs,
Bddh draws α, β ←$ Zq, lets V ··= αP + β ¯V and W ··= αU1 + β ¯W, and stores Tnon(K, m) ··= V
and Tddh(K, m) ··= W. It returns 1 if A wins the game and 0 otherwise. (Note that Bddh does
not need the discrete logarithm of U1 for simulating the game.)
We prove in Appendix D that the way Bddh re-randomizes ¯V and ¯W ensures that for
each pair (K, m), (i) Tnon(K, m) is uniformly random and (ii) (U1, Tnon(K, m), Tddh(K, m))
is a DDH tuple if (U1, ¯V , ¯W) is a DDH tuple, whereas Tddh(K, m) is uniformly random if
(U1, ¯V , ¯W) is a non-DDH tuple. Hence, when (U1, ¯V , ¯W) is a DDH tuple, then Bddh perfectly
simulates Game4, whereas when (U1, ¯V , ¯W) is a non-DDH tuple, it perfectly simulates Game5.
Consequently,
Advgame5
MS,A (λ) ≥ Advgame4
MS,A (λ) − Advddh
GrGen0,Bddh
(λ).
Game6. In Game6, everything is similar to Game5 except that the secret nonce r1, which is
computed as f(W) in Game5, is drawn uniformly at random in Fp. Since W is uniform in
Game5, by ε-uniformity of f and Lemma 1, we have
MS,A (λ) ≥ Advgame5
MS,A (λ) − qsε.
Advgame6
Game7. In Game7, we ﬁrst change how queries to ROnon are answered. Instead of drawing
Tnon(K, m) ←$ E, we draw v ←$ Zq and let Tnon(K, m) ··= vP. The value v is stored in an
additional table T0
non. Clearly, this is a purely syntactic change. Moreover, we check that
the nonces R2, . . . , Rn sent by the adversary (for host keys Ui 6= U1) have been computed
correctly. The value v ··= T0
non(K, m) is retrieved and the game checks that Ri = f(vUi)G. If
for some i ∈ {2, . . . , n} the proof πi was valid yet Ri 6= f(vUi)G, the game aborts and returns
false. We construct an adversary Bss against simulation-soundness of Π as follows. It receives
crs ←$ Π.SimSetup(λ) and has access to an oracle SimProve. It simulates Game7, querying
SimProve for simulating proofs for nonces R1. If the game stops at line (II), then Bss returns
the corresponding tuple (Ui, V, Ri), otherwise it aborts. Since Bss wins game SSΠ exactly when
Game6 returns true but Game7 does not, we have
MS,A (λ) ≥ Advgame6
Advgame7
(λ).
Π,Bss