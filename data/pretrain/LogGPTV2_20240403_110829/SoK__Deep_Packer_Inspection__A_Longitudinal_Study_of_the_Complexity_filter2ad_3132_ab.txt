region of memory in which we observe a sequence of a
memory write followed by a memory execution. Traditional
run-time packers have one unpacking frame for each layer,
because the code is fully unpacked in one layer before the
next layers are unprotected. We call these packers single-frame
unpackers. However, more complex cases exist in which the
code of one layer is reconstructed and executed one piece at
a time. These cases involve multiple frames per layer and are
called multi-frame packers in our terminology.
Code Visibility
As we explained in the previous paragraph, in most of the
cases the original code of the application is isolated from
the unpacking routines, and no write to the original code
occurs after the control ﬂow reaches this code. However,
more advanced multi-frame examples exist that selectively
unpack only the portion of code that is actually executed. This
approach is used as a mechanism to prevent analysts and tools
from easily acquiring a memory dump of the entire content of
the binary. Based on the amount and on the way the original
code is written in memory, we can distinguish three types of
unpacking schemes:
• Full-code unpacking. These routines ﬁrst unpack all the
original code and data, and then redirect the execution
to the original entry point. In this case, there is always
661
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:03:07 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 1. Packer features and complexity classes
• Incremental unpacking.
a point in time in which the entire code of the malware
can be scanned or retrieved from memory. Single-frame
packers always belong to this category.
Incremental unpacking ap-
proaches reconstruct the original code on-demand, just
before it is executed. In this case, if the content of the
memory is dumped at the original entry point of the
application, only the ﬁrst frame of code will be available
for analysis. To maximize the amount of collected code,
the analyst needs to dump the memory at the end of
the program execution. However, if a code path is not
executed, the frames that cover that execution path will
never be unprotected and will therefore remain hidden to
the analyst.
• Shifting-decode frames. This is a more complex version
of incremental unpacking that involves re-packing each
frame of code after its execution. Although this approach
is less efﬁcient and may introduce a large overhead, it
forces the analyst to extract several memory dumps and
join the results in order to reconstruct a more complete
view of the original code.
There are several possible solutions to implement incremen-
tal and shifting-decode frames unpacking routines. All of them
require a way to trigger the packer when a new code frame
needs to be unpacked (or re-packed). The following are some
of the most common approaches we observed in our study:
• Exception-based redirection. A simple approach to redi-
rect the execution back to the packer is to raise an excep-
tion. For instance, Armadillo and Beria take advantage of
the memory protection mechanisms provided by the oper-
ating system to mark memory pages as not executable and
then capture the exceptions produced when the execution
reaches a protected page. They then overwrite the page
with its unpacked content before resuming the original
execution.
• Hooking-based redirection. Another way to invoke the
packer consists of injecting special instructions in the
application code to transfer the control to the packer.
For instance, ZipWorxSecureEXE replaces original in-
structions with an interrupt INT 3 instruction. Whenever
the execution reaches the protected address, an exception
is generated and the control ﬂow is redirected to the
unpacking code, that substitutes the instructions with the
original code.
• Inline packing. In this case, the code to pack and unpack
each frame is inserted directly into the original code.
An example of this technique is used by Backpack (an
advanced packer proposed by Bilge et al. [15]) which
instruments the binary at compile time, using the LLVM
framework. Backpack prepends a decryption routine and
appends an encryption routine to every region of code that
must be individually protected. Themida is another exam-
ple of this kind of instrumentation. It can be integrated
directly into the development environment, allowing the
developers to deﬁne macros where certain routines of
the packer will be placed to protect speciﬁc regions
of the code. In addition,
if this approach cannot be
used, Themida also applies binary analysis techniques to
discover and instrument functions in the code.
The mechanism adopted to redirect the execution has a
large impact on the run-time overhead. For instance, while
compile-time instrumentation executes the unpacking code in
the address space of the process (without any context switch),
exception-based redirection is typically much slower because it
requires the operating system to catch and handle the exception
each time a new packed block is reached.
Unpacking Granularity
In case the protected code is not completely unpacked
before its execution, the protection can be implemented at
different granularity levels. In particular, we distinguish three
possible cases:
1) Page level, in which the code is unpacked one memory
page at a time.
it gets invoked.
2) Function level, in which each function is unpacked before
3) Basic Block or Instruction level in which the unpacking
is performed at a much lower level of granularity (either
662
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:03:07 UTC from IEEE Xplore.  Restrictions apply. 
basic blocks or single instructions).
While ﬁne grained approaches are more difﬁcult to analyze
and unpack, they introduce a larger overhead during the pro-
cess execution. Also, certain packing granularities may require
particular instrumentation approaches (such as hooking-based
redirection), resulting in an even larger overhead.
Packer Complexity Types
The features we presented so far can be used to precisely
characterize the behavior of a packer. In this section, we
present a simpliﬁed hierarchy to combine all of them together
in a single, more concise classiﬁcation. Figure 1 shows our
taxonomy, containing six types of packers with an increasing
level of complexity.
[Type I] packers represent the simplest case, in which a
single unpacking routine is executed before transferring
the control to the unpacked program (which resides in the
second layer). UPX is a notable example of this class.
[Type II] packers contain multiple unpacking layers, each one
executed sequentially to unpack the following routine.
Once the original code has been reconstructed, the last
transition transfers the control back to it.
[Type III] packers are similar to the previous ones, with
the only difference that now the unpacking routines
are not executed in a straight line, but organized in a
more complex topology that includes loops. An important
consequence of this structure is the fact that in this case
the original code may not necessarily be located in the last
(deepest) layer. In these cases, the last layer often contains
integrity checks, anti-debug routines, or just part of the
obfuscated code of the packer. However, a tail transition
still exists to separate the packer and the application code.
[Type IV] packers are either single- or multi-layer packers
that have part of the packer code, but not the one respon-
sible for unpacking, interleaved with the execution of the
original program. For instance, the original application
can be instrumented to trigger some packer functionality,
typically to add some protection, obfuscation, or anti-
debugging mechanisms. However,
there still exists a
precise moment in time when the entire original code
is completely unpacked in memory, even though the tail
jump can be harder to identify because the ﬁnal execution
may keep jumping back and forth between different
layers.
[Type V] packers are interleaved packers in which the
unpacking code is mangled with the original program.
In this case, the layer containing the original code has
multiple frames, and the packer unpacks them one at a
time. As a consequence, although Type-V packers have
a tail jump, only one single frame of code is revealed at
this point. However, if a snapshot of the process memory
is taken after the end of the program execution, all the
executed code can be successfully extracted and analyzed.
[Type VI] packers are the most complex in our taxonomy.
This category describes packers in which only a single
fragment of the original program (as little as a single
instruction) is unpacked at any given moment in time.
A single letter is used to characterize the granularity of
Type-V and Type-VI packers. So, a Type-VI-F packer
uses the shifting-decode frame technique at the function
level.
It is important to highlight that the complexity in this taxon-
omy is computed with respect to the difﬁculty of retrieving the
original application code. In other words, it would be possible
to have a Type-III packer in which one of the intermediate
layers (unpacking code) contains multiple frames (e.g., it is
decompressed and executed one function at a time). While this
feature is captured by our model, the multi-frame part would
only be relevant if the analyst is interested in retrieving the
entire code of the packer itself. However, since the focus of a
malware analyst is typically to study the packed application,
our type-based taxonomy would consider this case equivalent
to any other Type-III packer.
Finally, all
the presented types of packers can be im-
plemented either in a sequential or in a parallel fashion.
Therefore, it is possible to have, for example, a “Type-I packer
with 4 threads” or a “Type-III packer with 5 layers and 2
processes”.
III. IMPLEMENTATION
Our run-time packer analysis framework is implemented
on top of one of the two main components of the Bitblaze
project [16]: TEMU, a dynamic analysis tool based on QEMU,
which provides an interface to monitor the execution of one
or several processes. Our framework consists of 6,000 C/C++
and 2,000 python lines of code.
A. Execution tracing
In order to trace the execution of a binary at a basic block
level, we leveraged the binary tracing capabilities present in
TEMU – that we extended to properly handle interrupts and
exceptions. We then implemented our own set of monitoring
techniques to deal with complex run-time packers that employ
several processes and inter-process communication.
Our framework is able to track many different techniques
that can be used by two processes to interact,
including
remote memory writes, shared memory sections, disk I/O, and
memory-mapped ﬁles. It also monitors memory un-mapping
and memory deallocation events. In fact, a section un-map or
memory free operation on an unpacked region of code can be
considered equivalent to overwriting its memory content, since
the data that was previously available is not accessible any
more. For example, some packers apply page-level protection
to their code, mapping a memory page whenever it is needed,
and un-mapping it afterwards. To deal with these cases, our
framework considers this second step equivalent to re-packing
the memory page.
B. Collected information
Apart from the instruction trace and inter-process communi-
cation events described above, our system collects many other
663
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:03:07 UTC from IEEE Xplore.  Restrictions apply. 
information useful to evaluate the complexity of a packer.
For instance, for each layer we record the memory type
(module, heap, or stack) by analyzing the Process Environment
Block (PEB) and the Thread Environment Block (TEB) for
each thread executing in each process of the packer, and
monitoring several memory allocation API functions such as
ZwAllocateVirtualMemory. This information is useful
for the analysis of the binary, since common applications do
not execute code from regions in the heap or stack, while
some packers use this kind of memory to place unpacking or
(de)obfuscation routines.
We also record every API function called by each layer.
This allows an analyst to easily locate important events, such
as the use of initialization functions like GetCommandLine,
GetVersion or GetModuleHandle – a very common
heuristic employed to detect when the execution reaches the
original entry point of a binary.
Run-time packers commonly obfuscate the use of API
calls to (i) avoid the standard use of the Import Table of
the PE ﬁle, and (ii), to complicate the reverse-engineering
task, hindering the reconstruction of an unpacked and fully
functional binary. One of the most common methods employed
by packers is to erase the Import Table, and to reconstruct it
before the execution of the original code making use of the
LoadLibrary and GetProcAddress functions. In this
way, the packed binary is built with an alternative Import Table
that declares a different set of functions, or no function at all.
Nevertheless, in most of the cases, the original code still uses
the same mechanism to call the API functions, which consists
in making indirect calls to addresses stored into the Import
Address Table, or into other regions in memory that contain
indirect jumps to addresses stored in such table. In order
to detect potential Import Address Tables in the binary, we
instrument the execution of indirect call and jump instructions
in the dynamic binary translation routine of the emulator. Once
the execution of the binary is terminated, we identify potential
tables by grouping the memory addresses used in indirect
control ﬂow instructions.
Finally, for each layer we compute the sets of modiﬁed
and executed memory regions. Additionally, since we record
the memory type for every execution block, we label every
executed memory region accordingly.
C. Post-processing and Trace Analysis
The instruction trace extracted during the packer execution
is automatically analyzed to extract different types of informa-
tion. In particular, to compute the number of frames for each
unpacking layer we deﬁne a shadow memory that covers the
address space of each layer.
The shadow memory maintains two pieces of information
for each byte: its current State and an additional New Frame
bit (NF). The state can be modeled as a ﬁnite state machine
in which each byte is in one of the following states:
• Unknown (O) Indicates the initial state of the memory.
• Executed (X) Indicates that the memory has been exe-
cuted, without being previously written (this can only be
Fig. 2. Finite state machine representing the memory state for each byte.
true for the ﬁrst layer of the packer).
• Written (W ) Indicates that the memory has been written
but not yet executed.
• Unpacked (U) Indicates that
the memory has been
executed after being in the Written state.
• Repacked (R) Indicates that the memory has been over-
written after being in the Unpacked state. This may sound
incorrect, since not all overwritten code is necessarily
repacked. However, we will discuss later in this section
how we distinguish between repacked code and just new
code prepared for execution.
For every byte executed at layer Lj, there is an execution
transition (x) in the ﬁnite state machine associated to Lj.
Moreover, for every byte written in the address space of layer
Lj, there is a write transition (w) in the ﬁnite state machine
associated to Lj. Figure 2 shows the complete state machine.
The N F bit in the shadow memory is set when a byte has
been modiﬁed during the execution of the last frame. When
there is a transition to the U state for a memory region with the
N F bit set, we consider that a new frame has been created and
we clear the N F bit for every address in the shadow memory.
The next frame will not be computed until new writes for a
region or layer are followed by an execution of those memory
addresses.
Whenever a new frame is created, the state of each memory
location is also updated (see the state machine in Figure 2 for
more details). In particular, all the locations in the shadow
memory in the U and R state are updated to the W state
and the bytes in the X state are updated to the O state.
These transitions have a very important implication. Since