the chip and, even more interestingly, the output of each
multiplexer is connected to the output pins, that are other-
wise used to communicate with the console. The registers
are relatively easy to spot, as they are made up of equally
looking CMOS ﬂip-ﬂops right next to each other. Figure 9
shows a typical CMOS ﬂip-ﬂop, comprising two latches and
control logic.
55315
11) to remove the die’s insulating layer and the metal layer
below.
MUX
!6&7
A3
Figure 8: Test Mode Multiplexer
Figure 11: Polishing Machine with 0.1µ Polishing
Disc and Water as Lubricant
One of the main challenges employing polishing techniques
is to get a planarized result. Otherwise, it can easily happen
that on one side of the die all layers were already removed
while on the other side the insulation layer is still intact.
Although there is much room for improvement, in our ap-
proach we used an Aluminium holding piece with a glass
rod attached to it that can be clamped onto the polishing
machine (see Fig. 11). We polished the tip of the glass rod
until it was even and then used heated Allied wax (i.e. a
wax that can be dissolved in Acetone) to glue the die onto
the glass rod with the help of a toothpick. Under an opti-
cal microscope, we used the lens focus to check whether the
die surface is parallel to the surface of the glass rod. If not,
we heated up the holding piece and repeated the adjustment
step. Using a total of 2 decapsulated dies for de-layering, we
ﬁnally obtained usable results. In the subsequent process of
test mode reverse engineering, we resorted to manual image
analysis as we only had a strongly limited number of dies
and our polishing results would have been problematic for
automated pattern recognition approaches. Figure 12 shows
a part of the CPU’s Instruction Decoder (ID) unit with the
insulation and top metal layer removed. The signals coming
from the left of the picture originate from the ROM Logic
(Fig. 10) while each of the signals leaving the ID unit at
the bottom represents one CPU instruction. The partial re-
verse engineering of the CPU’s ID unit allowed us to verify
some publicly available bits of information. The CIC chip,
for instance, is supposed to use the Sharp SM5 4-bit CPU
core. By comparing the instruction opcodes used in the
ID unit with the opcodes found in the SM5 data sheet, we
found this information to be accurate. Due to die markings
and the fact that manufacturers tend to re-use existing CPU
cores (such as the Sharp SM5 core in this case), we believe
that architectural information for proprietary ICs is often
available to attackers. If this information is not available,
the CPU architecture could still be determined through re-
verse engineering approaches similar to our initial approach
that targeted the CPU’s instruction decoder (ID) unit. The
necessary eﬀort would be considerable though.
4.6 ROM Firmware Extraction
Combining the information we obtained on the propri-
etary test modes in the CIC chip so far, allowed us to pro-
duce the complete chip pinout (Fig. 13) as well as a deeper
knowledge of how the test modes can be utilized.
Figure 9: CMOS Flip-Flop comprising two Latches
and Control Logic
Since not all possible test mode combinations were cov-
ered by the analyzed multiplexers, we traced the test mode
signals further across the die and found similar control logic
that controls the input register containing the data from
the previously identiﬁed pins 2 to 5. However, the identi-
ﬁed logic was right next to the ROM (Fig. 10). Further
analysis showed that the control logic allows the instruction
code to be either fetched from the ROM or from the input
register.
In other words, selecting a testing mode always
allows arbitrary code execution.
ROM Logic
to ID
from IR
Figure 10: Implanted 1024x8 Bit Mask ROM with
Control Logic
4.5 De-Layering
In some cases the chip’s top metal layer obstructed the
view to signiﬁcant parts in the lower layers. For this case,
we used a polishing machine with a 0.1µ polishing disc (Fig.
554555the communication between our CIC implementation on the
FPGA board and the game console. As visible on the TV
screen, inserting the game cartridge PCBs into the console
correctly started and executed the game contained in the
cartridge’s ROM chip. Stopping the execution of the algo-
rithm within our FPGA board immediately froze the game.
To test whether our implementation still worked after multi-
ple hours of game play, we invited some friends and enjoyed
Mario 64 all together.
It then reaches an inﬁnite loop, mutating the RAM and
sending hashes of it to the console. The console veriﬁes
the incoming endless bit stream and freezes if the stream is
diﬀerent from the internally generated one.
1 void cic_round(uint4_t m[16])
2 {
3
uint4_t a, b, x;
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34 }
x = m[15];
do
{
m[1] += x + 1;
b = 6;
if (15 - m[3] > m[2])
b += 1;
m[b - 3] += m[3];
m[3] += m[2] + 1;
m[2] = ~(m[2] + m[1] + 1);
a = m[b - 1];
if (m[b - 2] > 7)
m[b - 1] = 0;
m[b - 1] += m[b - 2] + 8;
m[b - 2] += m[b - 3];
do
{
a += m[b] + 1;
m[b] = a;
b += 1;
} while (b != 0);
x -= 1;
} while (x != 15);
Listing
1:
Algorithm
Secret Reverse Engineered CIC
The cic_round function presented in Listing 1 is respon-
sible for mutating the RAM m (16 * 4 bit). The CIC im-
plementation calls the cic_round 3 times in a row on the
same RAM block m to garble the bits. After that, it uses the
7th nibble to determine how many bits (N) should be sent
to the console. Starting at nibble 0, it transfers the Least
Signiﬁcant Bit (LSB) to the console, followed by the LSB of
nibble 1, the LSB of nibble 2 and so forth until all N bits
have been sent.
The cic_round uses a loop in line 6 to 33 to run for a
given number of rounds (1 - 16) depending on the current
state. In each round, most elements in RAM are modiﬁed
by adding them to each other in the presented way.
5.2 FPGA Implementation
We evaluated the reverse engineered CIC algorithm by
creating a full FPGA implementation on a Digilent Nexys
4 Artix-7 FPGA board. On the Artix-7 XC7A100T FPGA,
our implementation takes 300 Slice LUTs and 155 Slice reg-
isters. We do not utilize any BlockRAM or DSP resources.
Our testing setup is visible in Figure 14. On the left of
the picture, we used a PC with the Xilinx Vivado FPGA
design tools to program the FPGA board.
In the middle
of the picture, the FPGA board and the opened up game
console with a game cartridge is visible. We used one of
the game cartridge PCBs where we had previously removed
the CIC chip and connected the FPGA board containing
our CIC implementation and the secret key instead. On the
right side of the picture, we used a logic analyzer to analyze
Figure 14: Evaluation Test Setup - Nexys 4 FPGA
Board and Gaming Console
5.3 Security Tradeoff
Mitigation techniques against test-mode attacks conserva-
tively follow a security-by-obscurity approach. Commonly
proposed methods found in the literature include scan chain
scrambling [4], encryption with hard-coded keys [7, 15], scan
pattern watermarking, spy ﬂip-ﬂops, output obfuscation [3]
or scan ﬂip-ﬂop randomization [4]. While we acknowledge
their eﬀectiveness to raise the bar for non-invasive attack
scenarios, we show that they oﬀer next to no protection
against deep silicon analysis. On the other hand, there are
more secure ways to protect a chip, like cryptographically
signing manufacturer test mode commands and only execute
them within the chip for instance. Other methods rely more
on Built-In Self-Test (BIST) modes that do not leak sen-
sitive information. These defense strategies, however, have
a common drawback. Since they always cause additional
costs both in design and production, they ultimately create
the need to trade security/functionality for cost. Simple ob-
fuscation techniques are easy to implement and can be used
with powerful testing modes such as scan chains, but do not
provide high security. On the other hand, Built-In Self-Test
(BIST) modes might not provide the necessary testing gran-
ularity while secure testing modes employing cryptographic
signature checks also need potentially large cryptographic
cores on the dies that increase the production costs. In fact,
the logic required for signature checking (i.e. RSA, DSA,
ECDSA, etc.) can be huge (i.e. cost intensive) and, depend-
556ing on the chip design, it can be even bigger than the rest
of the chip design on its own. How to choose in this typ-
ical tradeoﬀ situation depends on the application domain.
A hacked gaming console might be more tolerable than a
reverse-engineered chip for wireless payment. Still, we rec-
ommend to include secure protection mechanisms whenever
the projected costs permit. Less sophisticated countermea-
sures against non-invasive reverse engineering might pro-
vide a certain level of security but are completely ineﬀective
against a motivated eﬀort with deep silicon analysis.
6. CONCLUSION AND FUTURE WORK
In this paper, we demonstrated that limited eﬀort silicon
analysis can be eﬀectively used to reverse engineer secret
test modes and break device security. Our example appli-
cation of the developed techniques revealed previously se-
cret content of a cryptographic game authentication chip.
Speciﬁcally, the discovered testing mode allowed us to ex-
ecute arbitrary code on the chip and subsequently dump
the secret ﬁrmware and key material. While the authen-
tication chip in a game console is not a highly critical or
especially security-sensitive application, we believe that our
example eﬀectively illustrates how undocumented and pro-
prietary testing modes can easily be discovered through sil-
icon reverse engineering. Furthermore, we prove that most
widely proposed obfuscation-based countermeasures can be
circumvented without modifying the analysis approach.
As our technological reverse engineering procedure proved
feasible, we plan to extend our eﬀorts with regard to test
mode silicon reverse engineering for analyzing security crit-
ical applications. The major challenge will be to overcome
more sophisticated anti-reverse engineering techniques that
speciﬁcally aim to protect against deep silicon analysis.
7. ACKNOWLEDGEMENT
2
This work has been partly funded by the (SG)
project
under national FFG grant number 836276 through the KI-
RAS security research program run by FFG and BMWFW.
In addition, we would like to thank USTEM [13] at Vienna
University of Technology and Trustworks [12] for providing
valuable tips and letting us their lab equipment. Without
their support, this work would not have been possible.
References
[1] IEEE Standard for Test Access Port and Boundary-
Scan Architecture. IEEE Std 1149.1-2013 (Revision of
IEEE Std 1149.1-2001), pages 1–444, May 2013.
[4] D. Hely, M.-L. Flottes, F. Bancel, B. Rouzeyre, N. Be-
rard, and M. Renovell. Scan Design and Secure Chip. In
Proceedings of the International On-Line Testing Sym-
posium, 10th IEEE, IOLTS ’04, pages 219–, Washing-
ton, DC, USA, 2004. IEEE Computer Society.
TM
[5] A. Huang. Keeping Secrets in Hardware: The Mi-
; Case Study. In Revised Papers from
crosoft Xbox
the 4th International Workshop on Cryptographic Hard-
ware and Embedded Systems, CHES ’02, pages 213–227,
London, UK, UK, 2003. Springer-Verlag.
[6] IEEE Standards Association. 1149.1-2013 - IEEE Stan-
dard for Test Access Port and Boundary-Scan Architec-
ture, 2013.
[7] J. Lee, M. Tehranipoor, and J. Plusquellic. A Low-Cost
Solution for Protecting IPs Against Scan-Based Side-
Channel Attacks. In Proceedings of the 24th IEEE VLSI
Test Symposium, VTS ’06, pages 94–99, Washington,
DC, USA, 2006. IEEE Computer Society.
[8] P. Moorthy and S. Bharathy. An eﬃcient test pattern
generator for high fault coverage in built-in-self-test ap-
plications.
In Computing, Communications and Net-
working Technologies (ICCCNT),2013 Fourth Interna-
tional Conference on, pages 1–4, July 2013.
[9] K. Nohl, D. Evans, S. Starbug, and H. Pl¨otz. Reverse-
Engineering a Cryptographic RFID Tag. In USENIX
Security Symposium, volume 28, 2008.
[10] R. Press. IC design-for-test and testability features. In
AUTOTESTCON, 2008 IEEE, pages 88–91, Sept 2008.
[11] S. Skorobogatov and C. Woods. Breakthrough Silicon
Scanning Discovers Backdoor in Military Chip. In Pro-
ceedings of the 14th International Conference on Cryp-
tographic Hardware and Embedded Systems, CHES’12,
pages 23–40, Berlin, Heidelberg, 2012. Springer-Verlag.
[12] Trustworks KG. http://www.trustworks.at. [On-
line; accessed 19-August-2014].
[13] USTEM. Universitaere Service-Einrichtung fuer Trans-
missionselektronenmikroskopie. http://www.ustem.
tuwien.ac.at/EN.
[Online; accessed 19-August-
2014].
[14] N. Weste and D. Harris. CMOS VLSI Design: A Cir-
cuits and Systems Perspective. Addison-Wesley Pub-
lishing Company, USA, 4th edition, 2010.
[2] D. Chang, M.-C. Lee, K. T. Cheng, and M. Marek-
Sadowska. Functional scan chain testing.
In Design,
Automation and Test in Europe, 1998., Proceedings,
pages 278–283, Feb 1998.
[15] B. Yang. Secure Scan: A Design-for-Test Architecture
for Crypto Chips.
In in Proc. of 42nd Annual Con-
ference on Design Automation, pages 135–140. ACM
Press, 2005.
[3] J. Da Rolt, G. Di Natale, M.-L. Flottes, and
B. Rouzeyre. New security threats against chips con-
taining scan chain structures.
In Hardware-Oriented
Security and Trust (HOST), 2011 IEEE International
Symposium on, pages 110–110, June 2011.
[16] B. Yang, K. Wu, and R. Karri. Scan Based Side Chan-
nel Attack on Dedicated Hardware Implementations of
Data Encryption Standard.
In in Proc. of the IEEE
Int. Test Conf. (ITC), 2004, pages 339–344, 2004.
557