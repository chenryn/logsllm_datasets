In Symposium on Usable Privacy and Security. ACM, 4.
[90] Ennèl van Eeden and Wilson Chow. 2018. Perspectives from the Global Entertain-
ment & Media Outlook 2018–2022. https://www.statista.com/topics/1176/online-
advertising/.
[91] Antoine Vastel, Peter Snyder, and Benjamin Livshits. 2018. Who Filters the
Filters: Understanding the Growth, Usefulness and Efficiency of Crowdsourced
Ad Blocking. arXiv preprint arXiv:1810.09160 (2018).
[92] Craig E Wills and Doruk C Uzunoglu. 2016. What ad blockers are (and are not)
doing. In IEEE Workshop on Hot Topics in Web Systems and Technologies. IEEE.
[93] Xinyu Xing, Wei Meng, Byoungyoung Lee, Udi Weinsberg, Anmol Sheth, Roberto
Perdisci, and Wenke Lee. 2015. Understanding Malvertising Through Ad-Injecting
Browser Extensions. In International Conference on World Wide Web.
[94] Guixin Ye, Zhanyong Tang, Dingyi Fang, Zhanxing Zhu, Yansong Feng, Pengfei
Xu, Xiaojiang Chen, and Zheng Wang. 2018. Yet Another Text Captcha Solver: A
Generative Adversarial Network Based Approach. In ACM SIGSAC Conference on
Computer and Communications Security. ACM.
[95] Shitong Zhu, Xunchao Hu, Zhiyun Qian, Zubair Shafiq, and Heng Yin. 2018.
Measuring and Disrupting Anti-Adblockers Using Differential Execution Analysis.
In Network and Distributed System Security Symposium (NDSS).
A THE AD-BLOCK DETECTION ARMS RACE
Many publishers actively detect the presence of ad-blockers [42,
58, 60] and take actions ranging from user warnings to service dis-
abling for ad-block users. Ad-block detection operates among three
main axes [81]: (1) detecting absence of known ads; (2) injecting
“honeypots” and detecting that they are mistakenly blocked, and
(3) detecting ad-blocking code through side-channels (e.g., timing).
Perceptual ad-blockers cannot be detected server-side as they
do not alter any web requests. To remain stealthy, a perceptual
ad-blocker thus only needs to fool publisher JavaScript code into
observing an unmodified DOM [81]. This challenge is surmountable
for native in-browser ad-blockers, as these can simply modify the
user’s view without affecting the DOM. Yet, the main ad-blockers
today are browser extensions, which do not have such high privilege
levels and share the same JavaScript API as client scripts. Storey et
al. [81] suggest the following arms race for a stealthy ad-blocker:
(1) The ad-blocker modifies the DOM to block or mask detected ads
and honeypots. It then overwrites the JavaScript DOM traversal
API (e.g., with JavaScript proxies) so that the publisher’s code
sees the original DOM.
(2) The publisher inspects changes to global APIs by using the
toString() method to unveil changes on the function.7
(3) The ad-blocker overwrites the universal toString() method
used by all JavaScript functions, so that it always returns the
same value as for a non-blocked website.
We argue that this is not the end of the arms race. We sketch
three strategies to detect or reverse the above ad-blocker modifi-
cations. Preventing the attacks below requires the ad-blocker to
emulate a much larger set of JavaScript APIs, parts-of-which appear
inaccessible to browser extensions.
(1) Borrowing native functions. A publisher creates an iframe,
which gets a new JavaScript environment, and extracts a “fresh”
native function (e.g., toString) from it to unveil changes. In
7Even proxied functions can be distinguished from their native counterparts: https:
//bugs.chromium.org/p/v8/issues/detail?id=7484.
Session 9B: ML Security IIICCS ’19, November 11–15, 2019, London, United Kingdom2019turn, the ad-blocker has to intercept all iframe creations and
re-apply the same changes.
(2) Detecting non-native functions. The toString method is
native (i.e., implemented by the browser). Some properties differ
between native and non-native functions and do not appear
to be mockable (e.g., setting a native function’s arguments
property raises an error whereas this property can be set for
JavaScript functions).8
(3) Timing. If the above attacks are solved by emulating large
portions of native JavaScript, the performance overhead may
lead to a strong timing side-channel.
B TRAINING A PAGE-BASED AD-BLOCKER
As the trained neural network of Sentinel [10] is not available for
an evaluation, we trained one for the analysis of Section 4. We used
the same architecture as Sentinel, i.e., YOLO (v3) [70–72].
B.1 Data Collection
YOLO is an object detection network. Given an image, it returns a
set of bounding boxes for each detected object. To train and eval-
uate YOLO, we created a dataset of labeled web page screenshots
where each label encodes coordinates and dimensions of an ad on
the page. We created the dataset with an ad-hoc automated system
that operates in two steps. First, given a URL, it retrieves the web
page and identifies the position of ads in the page using filter lists
of traditional ad-blockers. Then, our system generates a web page
template where ads are replaced with placeholder boxes. The con-
cept of web page templates is convenient as it enables us to create
multiple screenshots from the same web page with different ads, a
form of data-augmentation. Second, from each web page template,
we derive a number of images by placing ads on the template.
Web pages. We acquired web pages by retrieving the URLs of
the top 30 news websites of each of the G20 nations listed in
allyoucanread.com. For each news site, we searched for the RSS
feed URLs and discarded sites with no RSS feeds. The total number
of RSS feed URLs is 143. We visited each RSS feed URL daily and
fetched the URLs to the daily news.
Template generation. Given a URL of a news article, we gener-
ate a page template using a modified HTTP proxy that matches
incoming HTTP requests against traditional ad-blocker filter lists,
i.e., Easylist [3] and Ghostery [5]. The proxy replaces ad contents
with monochrome boxes using a unique color for each ad. These
boxes are placeholders that we use to insert new ads. We manually
inspected all templates generated during this step to remove pages
with a broken layout (caused by filter lists’ false positives) or pages
whose ads are still visible (caused by filter lists’ false negatives).
Image generation. From each page template, we generate multi-
ple images by replacing placeholder boxes with ads. We select ads
from the dataset of Hussain et al. [40]. This dataset contains about
8It might be possible to circumvent this issue with a Proxy. Yet, we found that function
Proxies can be distinguished from native functions in Google Chrome via the error
message of a postMessage call—this might be mockable too, but vastly expands the
portion of the JavaScript API to cover.
64K images of ads of variable sizes and ratios. We complemented
the dataset with 136 ads we retrieved online. To insert pictures
inside a template, we follow four strategies:
(1) We directly replace the placeholder with an ad;
(2) We replace the placeholder with an ad, and we also include an
AdChoices logo in the top right corner of the ad;
(3) We augment templates without placeholders by adding a large
ad popup in the page. The page is darkened to highlight the ad;
(4) We insert ads as background of the website, that fully cover the
left- and right-hand margins of the page.
When inserting an ad, we select an image with a similar aspect ratio.
When we cannot find an exact match, we resize the image using
Seam Carving [13], a content-aware image resizing algorithm that
minimizes image distortion. To avoid overfitting during training,
we limited the number of times each ad image can be used to 20.
B.2 Evaluation and Results
Datasets. The training set contains 2,901 images, of which 2,600
have ads. 1,600 images with ads were obtained with placeholder
replacement, 800 with placeholder replacements with AdChoices
logos, 100 with background ads, and 100 with interstitials.
The evaluation set contains a total of 2,684 images—2,585 with
ads and 99 without ads. These are 1,595 images with placeholder
replacement, 790 images with placeholder replacement with Ad-
Choices logos, 100 images with background ads, and 100 images
with interstitials. We also compiled a second evaluation set from 10
domains that were not used for training (this set is different from
the one used to evaluate attacks in Section 4). For each domain,
we took a screenshot of the front page and four screenshots of
different subpages, resulting in 50 screenshots overall with a total
of 75 advertisements. We trained using the default configuration of
YOLOv3 [72], adapted for a unary classification task.
Accuracy and performance. We tested our model against both
evaluation sets. The model achieved the best results after 3,600
training iterations. In the first set, our model achieved a mean
average precision of 90.88%, an average intersect of union of 84.23%
and an F1-score of 0.96. On the second set, our model achieved a
mean average precision of 87.28%, an average intersect of union of
77.37% and an F1-score of 0.85. A video demonstrating our model
detecting ads on five never seen websites is available at https://
github.com/ftramer/ad-versarial/blob/master/videos.
We evaluate performance of the model in TensorFlow 1.8.0 with
Intel AVX support. On an Intel Core i7-6700 CPU the prediction for
a single image took 650ms.
Inspecting our model. We conduct a preliminary study of the
inner-workings of our neural network. By inspecting the model’s
activation map on different inputs (see Figure 12), we find that the
model mainly focuses on the layout of ads in a page, rather than
their visual content. This shows that our ad-blocker detects ads
using very different visual signals than humans. This raises an
intriguing question about the Sentinel model of Adblock Plus [10],
which was trained solely on Facebook data, where ads are visually
Session 9B: ML Security IIICCS ’19, November 11–15, 2019, London, United Kingdom2020Table 3: Evaluation Data for Adversarial Examples. We col-
lect images, frames and screenshots from the Alexa top ten
news websites that use the AdChoices standard (we exclude
news.google.com and shutterstock.com which contain no
ads on their front-page). For each page, we extract all im-
ages below 50 KB, all iframes, and take two screenshots (the
front page and an article) of the user’s viewport, and report
the number of visible ads in these.
Images
Iframes
Visible
Website
Ads
reddit.com
2
cnn.com
3
nytimes.com
2
theguardian.com
3
indiatimes.com
3
weather.com
3
news.yahoo.com
3
washingtonpost.com
3
foxnews.com
4
huffingtonpost.com
4
30
Total
† One AdChoices logo appears in two rendered iframes laid on top of each other.
Total AdChoices Total Ads AdChoices
2
2
3
3
4
3
2
1
4
5†
29
70
36
89
75
125
144
100
40
96
90
865
2
7
4
4
4
5
5
1
5
4
41
2
7
3
8
5
11
3
5
6
9
59
2
5
3
3
5
7
3
2
5
4
39
Figure 12: Activation Maps of our Ad Detection Model. The
most salient features appear to be the surroundings of ads
rather than their visual content.
close to the website’s native content. Thus, it seems less likely that
Sentinel would have learned to detect ads using layout information.
To generate the map in Figure 12, we compute the absolute value
of the gradient of the network’s output with respect to every input
pixel, and apply a smoothing Gaussian kernel over the resulting
image. The gradient map is then overlaid on the original input.
C EXTRA TABLES AND FIGURES
(a) Original Page: The ad banner is correctly detected.
(a) Page displayed in Chromium.
(b) Page displayed in Percival.
Figure 13: Attack on the Percival Browser from [84]. On
the left, a dummy web page is displayed in the standard
Chromium browser with two ads (top), an adversarially per-
turbed ad (middle) and two adversarial opaque boxes (bot-
tom). On the right, the same page is displayed in the Perci-
val browser. The two unperturbed ads on top are correctly
blocked, but the adversarial ad evades detection, and the ad-
versarial opaque boxes are mistakenly blocked.
(b) Attack C3-C4: The publisher perturbs the white background be-
neath the ad to evade ad-blocking (C4). Alternatively, an ad network
adds a universal mask on the ad (C3, not displayed here for brevity).
In both cases, the perturbation is invisible to the user.
(c) Attack C1: The publisher adds a honeypot element to the page
header (top-right) to detect an ad-blocker.
Figure 14: Universal Adversarial Examples for Page-Based
Ad-Blockers on BBC.com. Examples of evasion attacks C3-
C4 and detection attack C1 (see Section 4.2).
Session 9B: ML Security IIICCS ’19, November 11–15, 2019, London, United Kingdom2021