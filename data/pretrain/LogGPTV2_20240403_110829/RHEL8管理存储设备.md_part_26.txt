[*固件 RAID*]{.emphasis} （也称为 ATARAID）是一种软件
RAID，可在其中使用基于固件的菜单配置 RAID 集。此 RAID 使用的固件也会钩在
BIOS 中，允许您从 RAID
集启动。不同的供应商使用不同的磁盘元数据格式来标记 RAID 设置成员。Intel
Matrix RAID 是固件 RAID 系统的一个很好的例子。
::: title
**硬件 RAID**
:::
基于硬件的阵列独立于主机管理 RAID 子系统。它可能会在每个 RAID
阵列中存在多个设备。
硬件 RAID
设备可能是系统内部或者外部的。内部设备通常由在操作系统中透明地处理 RAID
任务的特殊控制器卡组成。外部设备通常通过 SCSI、光纤、iSCSI、InfiniBand
或者其它高速网络互联连接的系统,并显示卷如逻辑单元到系统。
RAID 控制器卡的功能与操作系统的 SCSI
控制器相同，用于处理所有实际驱动器间的通信。用户将驱动器插入 RAID
控制器（就像普通 SCSI 控制器），然后将它们添加到 RAID
控制器的配置中。操作系统将无法辨别它们的不同。
::: title
**软件 RAID**
:::
软件 RAID 在内核块设备代码中实现各种 RAID
级别。它提供最便宜的解决方案，如昂贵的磁盘控制器卡或热交换机箱
[^\[1\]^](#managing-raid_managing-storage-devices.html#ftn.idm140531435195056){#managing-raid_managing-storage-devices.html#idm140531435195056
.footnote} 不需要。软件 RAID 还可用于 Linux 内核支持的任何块存储，如
[**SATA[]{.strong}、SCSI**]{.strong} 和 [**NVMe**]{.strong}。由于 CPU
速度更快，软件 RAID 通常会优于硬件 RAID，除非您使用高端存储设备。
Linux [*内核包含一个多个设备*]{.emphasis} (MD)驱动程序，允许 RAID
解决方案完全独立于硬件。基于软件的阵列的性能取决于服务器 CPU
性能和负载。
Linux 软件 RAID 堆栈的主要特性：
::: itemizedlist
-   多线程设计
-   在不同的 Linux 机器间移动磁盘阵列不需要重新构建数据
-   使用空闲系统资源构建后台阵列
-   对热插拔驱动器的支持
-   自动 CPU 检测，以利用某些 CPU 功能，如流传输单指令多数据(SIMD)支持
-   自动更正阵列磁盘上坏扇区
-   定期检查 RAID 数据，以确保阵列健康
-   使用发送至重要事件上的指定电子邮件地址的电子邮件警报主动监控阵列
-   write-intent
    位映射可让内核准确知道需要重新同步磁盘的部分，而不是在系统崩溃后重新同步整个阵列，从而显著提高重新同步事件的速度
    请注意： [*resync*]{.emphasis} 是一个通过现有 RAID
    设备同步数据以达到冗余的过程
-   重新同步检查点以便如果您在重新同步期间重新引导计算机，则在启动时重新同步会选择它离开的位置，而不是全部重新启动
-   能够在安装后更改阵列的参数，这称为
    [*reshaping*]{.emphasis}。例如，当有要添加新设备时，您可以将 4 磁盘
    RAID5 阵列增加到 5 磁盘 RAID5
    阵列。这个增长的操作是实时的，不需要您在新阵列中重新安装
-   重新定义支持更改设备数量、RAID 算法或 RAID 阵列类型的大小，如
    RAID4、RAID5、RAID6 或 RAID10
-   接管支持 RAID 级别转换，如 RAID0 到 RAID6
:::
:::
::: section
::: titlepage
# []{#managing-raid_managing-storage-devices.html#raid-levels-and-linear-support_managing-raid}RAID 级别和线性支持 {.title}
:::
RAID 支持各种配置，包括 0、1、4、5、6、10 和 linear。这些 RAID
类型定义如下：
::: variablelist
[0 级]{.term}
:   RAID 级别
    0，通常被称为[*条带化*]{.emphasis}数据映射技术。这意味着，要写入阵列的数据被分成条块，并在阵列的成员磁盘中写入，这样可以在成本低的情况下提供高的
    I/O 性能，但不提供冗余。
    许多 RAID 级别 0
    的实现只在成员设备间条状分布到阵列中最小设备的大小。就是说，如果您有多个设备，它们的大小稍有不同，那么每个设备的大小都被视为与最小设备的大小相同。因此，级别
    0 阵列的一般存储容量等于，硬件 RAID
    中容量最小的成员磁盘的容量，或软件 RAID
    中的最小成员分区的容量，在乘以阵列中的磁盘或分区的数量。
[1 级]{.term}
:   RAID 级别 1
    或称为[*镜像*]{.emphasis}，通过将相同数据写入阵列的每个磁盘来提供冗余，在每个磁盘上保留\"镜像\"副本。因为其简单且数据高度可用，RAID
    1 仍然被广泛使用。级别 1
    需要两个或者多个磁盘，它提供了很好的数据可靠性，提高了需要读取的应用程序的性能，但是成本相对高。
    为了实现数据可靠性，需要向阵列中的所有磁盘写入相同的信息，所以 RAID
    1 的成本会很高。与基于奇偶校验的其他级别（如级别
    5）相比，空间的利用效率较低。然而，对空间利用率的牺牲提供了高性能：基于奇偶校验的
    RAID 级别会消耗大量 CPU 资源以便获得奇偶校验，而 RAID 级别 1
    只是一次向多个 RAID 成员中写入同样数据，其对 CPU
    的消耗较小。因此，在使用软件 RAID
    的系统中，或系统中有其他操作需要大量使用 CPU 资源时，RAID 1
    可能会比使用基于奇偶校验的 RAID 级别的性能更好。
    级别 1 阵列的存储容量等于硬件 RAID 中最小镜像硬盘或者软件 RAID
    中最小镜像分区的容量相同。级别 1 所提供的冗余性是所有 RAID
    级别中最高的，因为阵列只需要在有一个成员可以正常工作的情况下就可以提供数据。
[级别 4]{.term}
:   级别 4
    使用单一磁盘驱动器中的奇偶校验来保护数据。奇偶校验信息根据阵列中其余成员磁盘的内容计算。然后当阵列中的一个磁盘失败时，这个信息就可以被用来重建数据。然后，在出现问题的磁盘被替换前，使用被重建的数据就可以满足
    I/O 的请求。在磁盘被替换后，可以在上面重新生成数据。
    因为 RAID 4 使用一个专门的偶校验磁盘，因此这个磁盘就会成为对 RAID
    阵列的写入操作的一个固有的瓶颈。所以， RAID 4
    较少被使用。因此，Anaconda 中并没有提供 RAID 4
    这个选项。但是，如果真正需要，用户可以手动创建它。
    硬件 RAID 4
    的存储容量等于分区数量[*减一*]{.emphasis}乘以最小成员分区的容量。RAID
    4
    阵列的性能是非对称的，即读的性能会好于写的性能。这是因为，写入会在生成奇偶校验时消耗额外的
    CPU
    和主内存带宽，然后在将实际数据写入磁盘时也消耗额外的总线带宽，因为您不仅是写入数据，而且是奇偶校验。读取只需要读取数据而不是奇偶校验，除非该阵列处于降级状态。因此，在正常操作条件下，读取会在计算机的驱动器和总线间产生较少的流量，以实现相同数量的数据传输。
[5 级]{.term}
:   这是最常见的 RAID
    类型。通过在一个阵列的所有成员磁盘中分布奇偶校验，RAID 5 解除了级别
    4 中原有的写入瓶颈。唯一性能瓶颈是奇偶校验计算过程本身。在使用现代
    CPU 和软件 RAID 时，这通常不会成为瓶颈，因为现代 CPU
    可能会非常快速地生成奇偶校验。然而，如果您的软件 RAID5
    阵列中有大量成员设备，且在所有设备间有大量的数据进行传输时，就可能出现瓶颈。
    和级别 4 一样，级别 5 的性能也是非对称的，读性能会高于写的性能。RAID
    5 的存储容量的计算方法与级别 4 的计算方法是一样的。
[级别 6]{.term}
:   如果数据的冗余性和保护性比性能更重要，且无法接受 RAID 1
    的空间利用率低的问题，则通常会选择使用级别 6。级别 6
    使用一个复杂的奇偶校验方式，可以在阵列中出现任意两个磁盘失败的情况下进行恢复。因为使用的奇偶校验方式比较复杂，软件
    RAID 设备会对 CPU
    造成较大负担，同时对写操作造成更大的负担。因此，与级别 4 和 5
    相比，级别 6 的性能不对称性更严重。
    RAID 6 阵列的总容量与 RAID 5 和 4
    类似，但您必须从设备数量中减小两个（而不是 1
    个）额外奇偶校验存储空间的设备数。
[级别 10]{.term}
:   这个 RAID 级别将级别 0 的性能优势与级别 1
    的冗余合并。它还有助于减少在有多于 2 个设备时，级别 1
    阵列中的利用率低的问题。在级别 10 中，可以创建一个 3
    个驱动器阵列来只存储每个数据的 2
    个副本，然后允许整个阵列的大小达到最小设备的 1.5
    倍，而不是只等于最小设备（与有 3 个设备的级别 1 阵列相同）。与 RAID
    级别 6 相比，计算奇偶校验对 CPU 的消耗较少，但空间效率较低。
    在安装过程中，不支持创建 RAID 10。您可在安装后手动创建。
[线性 RAID]{.term}
:   线性 RAID 是创建更大的虚拟驱动器的一组驱动器。
    在线性 RAID
    中，块会被从一个成员驱动器中按顺序分配，只有在第一个完全填充时才会进入下一个驱动器。这个分组方法不会提供性能优势，因为
    I/O 操作不太可能在不同成员间同时进行。线性 RAID
    也不提供冗余性，并会降低可靠性。如果有任何一个成员驱动器失败，则无法使用整个阵列。该容量是所有成员磁盘的总量。
:::
:::
::: section
::: titlepage
# []{#managing-raid_managing-storage-devices.html#linux-raid-subsystems_managing-raid}Linux RAID 子系统 {.title}
:::
以下子系统组成了 Linux 中的 RAID 系统：
::: section
::: titlepage
## []{#managing-raid_managing-storage-devices.html#linux_hardware_raid_controller_drivers}Linux 硬件 RAID 控制器驱动程序 {.title}
:::
硬件 RAID 控制器在 Linux 中没有特定的 RAID 子系统。由于它们使用特殊的
RAID 芯片组，硬件 RAID
控制器随自己的驱动程序一起提供；这些驱动程序允许系统将 RAID
集作为常规磁盘检测。
:::
::: section
::: titlepage
## []{#managing-raid_managing-storage-devices.html#mdraid}mdraid {.title}
:::
`mdraid`{.literal} 子系统被设计为 Linux 的软件 RAID 解决方案，也是 Linux
下软件 RAID 的首选解决方案。此子系统使用自己的元数据格式，通常称为原生
MD 元数据。
`mdraid`{.literal} 也支持其他元数据格式，称为外部元数据。Red Hat
Enterprise Linux 8 使用 `mdraid`{.literal} 和外部元数据来访问 ISW/
IMSM（Intel 固件 RAID）集和 SNIA DDF。`mdraid`{.literal} 集合通过
`mdadm`{.literal} 工具配置和控制。
:::
:::
::: section
::: titlepage
# []{#managing-raid_managing-storage-devices.html#creating-software-raid_managing-raid}创建软件 RAID {.title}
:::
按照以下步骤创建独立磁盘冗余阵列(RAID)设备。RAID
设备由多个存储设备组成的，它可以提高性能，并可以配置为增加容错功能。
创建 RAID
设备只需要一步，并可根据需要添加或者删除磁盘。您可以为系统中的每个物理磁盘配置一个
RAID 分区，因此安装程序可使用的磁盘数决定可用 RAID 设备的级别。例如：
如果系统只有两个硬盘，就无法创建 RAID 10 设备，因为它至少需要 3
个独立的磁盘。
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
在 IBM Z 中，存储子系统会透明地使用 RAID。您不必手动配置软件 RAID。
:::
::: itemizedlist
**先决条件**
-   您已经选择了两个或者多个磁盘，然后才能看到 RAID 配置选项。创建 RAID
    设备至少需要两个磁盘。
-   您创建了挂载点。通过配置挂载点，就可以配置 RAID 设备。
-   您已在 `Installation Destination`{.literal} 窗口中选择了
    `Custom`{.literal} 单选按钮。
:::
::: orderedlist
**流程**
1.  在 [**Manual Partitioning**]{.strong} 窗口左面地框中，选所需的分区。
2.  在 [**Device(s)**]{.strong} 部分点 [修改]{.guibutton}。此时会打开
    [**Configure Mount Point**]{.strong} 对话框。
3.  选择您要包含在 RAID 设备中的磁盘并点击 [选择]{.guibutton}。
4.  点击[**设备类型**]{.strong}下拉菜单并选择 [**RAID**]{.strong}。
5.  点击[**文件系统**]{.strong}下拉菜单并选择您首选的文件系统类型。
6.  点击[**RAID 级别**]{.strong}下拉菜单并选择您需要的 RAID 级别。
7.  点击 [更新设置]{.guibutton} 保存您的更改。
8.  点击 [完成]{.guibutton} 按钮应用该设置并返回 [**安装概述**]{.strong}
    窗口。
:::
如果指定的 RAID 级别需要更多磁盘，则会在窗口底部显示一 条信息。
要使用存储系统角色创建并配置 RAID 卷，请参阅 ["使用存储系统角色配置 RAID
卷"一节](#managing-local-storage-using-rhel-system-roles_managing-storage-devices.html#configure-raid-volume-using-storage-system-role_managing-local-storage-using-rhel-system-roles "使用存储系统角色配置 RAID 卷"){.xref}
要了解更多有关软崩溃以及在配置 RAID LV
时如何保护数据的信息，请参阅[使用带有 RAID LV 的 DM
完整性](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/configuring_and_managing_logical_volumes/index#using-dm-integrity-with-raid-lv_configure-manage-raid){.link}。
:::
::: section
::: titlepage
# []{#managing-raid_managing-storage-devices.html#creating-software-raid-after-installation_managing-raid}安装后创建软件 RAID {.title}
:::
这个步骤描述了如何使用 `mdadm`{.literal}
实用程序在现有系统中创建软件冗余磁盘阵列(RAID)。
::: itemizedlist
**先决条件**
-   已安装 `mdadm`{.literal} 软件包。
-   您的系统中有两个或者两个以上分区。具体指令请查看
    ["创建分区"一节](#assembly_getting-started-with-partitions_managing-storage-devices.html#assembly_creating-a-partition_assembly_getting-started-with-partitions "创建分区"){.xref}。
:::
::: orderedlist
**流程**
1.  要创建两个块设备的 RAID，如 [**/dev/sda1**]{.strong} 和
    [**/dev/sdc1**]{.strong}，请使用以下命令：
    ``` literallayout
    # mdadm --create /dev/md0 --level= --raid-devices=2 /dev/sda1 /dev/sdc1
    ```
    将 [*\*]{.emphasis} 替换为 RAID 级别。详情请查看
    `mdadm(8)`{.literal} man page。
2.  另外，要检查 RAID 的状态，使用以下命令：
    ``` literallayout
    # mdadm --detail /dev/md0
    ```
3.  另外，要查看每个 RAID 设备的详细信息，请使用以下命令：
    ``` literallayout
    # mdadm --examine /dev/sda1 /dev/sdc1
    ```
4.  要在 RAID 驱动器中创建文件系统，请使用以下命令：
    ``` literallayout
    # mkfs -t  /dev/md0
    ```
    其中 [*\*]{.emphasis}
    是一个您选择格式化驱动器的具体文件系统。详情请查看 `mkfs`{.literal}
    man page。
5.  要为 RAID 驱动器生成挂载点并挂载它，请使用以下命令：
    ``` literallayout
    # mkdir /mnt/raid1
    # mount /dev/md0 /mnt/raid1
    ```
:::
完成上述步骤后，RAID 就可以使用。
:::
::: section
::: titlepage
# []{#managing-raid_managing-storage-devices.html#configure-raid-volume-using-storage-system-role_managing-raid}使用存储系统角色配置 RAID 卷 {.title}
:::
使用 `storage`{.literal} 系统角色，您可以使用 Red Hat Ansible Automation
Platform 在 RHEL 上配置 RAID
卷。在本小节中，您将了解如何使用可用参数设置 Ansible playbook，以配置
RAID 卷以满足您的要求。
::: itemizedlist
**先决条件**
-   您已在要运行 playbook 的系统中安装了 Red Hat Ansible Engine。
    ::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
    ### 注意 {.title}
    您不必在要部署 `storage`{.literal} 解决方案的系统中安装 Red Hat
    Ansible Automation Platform。
    :::
-   已安装该系统中要运行 playbook 的 `rhel-system-roles`{.literal}
    软件包。
-   您有一个清单文件详细描述了您要使用 `storage`{.literal} 系统角色部署
    RAID 卷的系统。
:::
::: orderedlist
**流程**
1.  使用以下内容 `playbook.yml`{.literal} 创建新文件：
    ``` screen
    - hosts: all