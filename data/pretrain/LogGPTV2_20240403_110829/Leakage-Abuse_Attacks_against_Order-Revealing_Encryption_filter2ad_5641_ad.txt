are not deployed in any real-world systems because all such
schemes require either inefﬁcient multilinear maps or client
state, mutable ciphertexts (their value changes over time),
and multiple rounds of communication to insert a ciphertext
or perform a search. Instead, practitioners have widely been
deploying more efﬁcient schemes such as the classic one
due to Boldyreva, Chenette, Lee, and O’Neill (BCLO) [5].
This scheme is known to leak more than just frequency and
order [6], and we now show how to build highly damaging
662
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:38 UTC from IEEE Xplore.  Restrictions apply. 
attacks that augment our non-crossing attack to exploit this
additional leakage.
The BCLO scheme. The BCLO scheme realizes an OPE
scheme by a recursive procedure that samples according to
the hypergeometric distribution based on coins pseudoran-
domly derived from a secret key. The details of the con-
struction are not important to our attacks, and so for brevity
we refer readers to [5] for details. It is secure in the sense
of being indistinguishable from a random order-preserving
function (ROPF).
An ROPF, however, still may leak signiﬁcant information
about the plaintext. Boldyreva, Chenette, and O’Neill [6] ana-
lyzed ROPFs relative to a notion of security they call window
one-wayness. Let M = |M| be the size of the domain. They
show that an adversary, given the encryption of a uniformly
chosen plaintext, can use the ciphertext to immediately infer
a set of size b · √
with high probability that the hidden plaintext falls within
√
M for some small constant b. When b is
M, this means the attacker learns most of
small relative to
the ﬁrst half of the plaintext.
We will explore how this leakage affects security for in
our running case study, and then show how to build even
more damaging inference attacks by augmenting our non-
crossing attack to take advantage of the additional leakage.
First, however, we discuss one security-critical issue that
arises in practical use of the BCLO scheme.
The problem of padding. In previous work on OPE and
ORE, the question of variable-length inputs is rarely dis-
cussed. Real systems that use OPE for variable-length plain-
texts, though, must pad to preserve the functionality of being
able to compare strings of different length.
For encryption schemes that reveal or preserve order,
variable-length inputs represent a trickier problem than
for other
types of encryption, because different ways
of ordering strings of characters handle variable lengths
differently. For example, take the two strings “banana” and
“zoo”. Viewed as English words, it is clear that “banana”
is lexicographically less than “zoo”. However, some OPE
algorithms (in particular [5]) only accept inputs that are
integers in some set. Thus,
the question becomes how
to convert strings in a speciﬁed alphabet to integers but
preserve their alphabetical order. The naive way to do
this for “banana” and “zoo” is to treat them as big-endian
numbers base 26, and convert to base 2 (or 10) before
encrypting with OPE. It is not hard to see that this approach
fails, because the base-2 number represented in base-26 as
“banana” is larger than the corresponding base-2 number for
“zoo”. Encrypted with OPE, their relative ordering would be
reversed.
The solution is to right-pad all strings to a common input
length (i.e., the length of the longest possible input) with
the lexicographically smallest character (in our case, a space)
before converting the string to an integer for encryption with
30
20
10
y
c
n
e
u
q
e
r
F
0
0
5
15
10
20
Length of name
25
30
First names (FN)
Last names (LN)
Figure 5: Length distributions of ﬁrst and last names. The right
vertical line is half of the longest last name length, which roughly
means every last name to the left of that line will be leaked fully.
The left vertical line is the same boundary for ﬁrst names.
OPE. This approach was suggested in a technical report by
Kolesnikov and Shifka [27], in the context of randomizing
OPE ciphertexts while preserving sort order. This is painful
when it comes to security of schemes like BCLO that leak
high order bits: the padding pushes sensitive data into those
bits that are leaked. Figure 5 gives histograms of the lengths
of ﬁrst names and last names across our datasets. As can
be seen, a bit more than half of ﬁrst names and the vast
majority of last names fall below half the maximal length.
This means that many or, for last names, most plaintexts will
be immediately leaked when encrypted under BCLO.
In theory, one could pad to a shorter length and truncate
values that are too long. Besides the obvious loss of strict
order preservation for all plaintexts, this also removes the
ability to decrypt all ciphertexts to the correct plaintext. In
practice this truncation would necessitate appending another
encryption of the plaintext to the end of the OPE ciphertext
so that decryption could occur correctly, which would at least
double the storage required for that column in the database.
Thus, this method of handling variable-length inputs is at
best much more expensive than the alternative, and at worst
impossible because of, e.g., unchangeable constraints in SaaS
applications.
In our experiments, we encoded ﬁrst and last names as
base-27 integers and padded plaintexts to the length of the
longest possible plaintext with the space character, which
we deﬁned to be the lexicographically smallest character
of our input alphabet. This method of encoding strings as
integers may seem strange initially, but observe that the naive
way of treating each byte as a base-256 digit will cause
the parameters (and, by extension, the ciphertexts) to be
much larger than they need to be, since only a small subset
of the 256 possibilities are valid characters. As mentioned
before, the longest ﬁrst name appearing in our data sets is
14 characters, and the longest last name is 28 characters.
663
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:38 UTC from IEEE Xplore.  Restrictions apply. 
Birth dates and ZIP codes are ﬁxed-width, so padding is not
required.
BCLO’s additional leakage. Since the BCLO scheme leaks
additional information other than order and frequency, it is
logical to ask how much information an adversary learns just
by computing the BCLO leakage. This is not an “inference
attack” as we have deﬁned it above, because it does not
use auxiliary data. It does require knowledge of the input
alphabet and padding rules. Below, we will describe how to
combine this attack with inference.
We ﬁrst describe how to compute the leakage given a
ciphertext as per [6]. Let M be the message space with size
M = |M| and let the ciphertext space be C = {1, . . . , C}.
Typically in implementations of BCLO one uses message and
ciphertext spaces that are of size a power of two, and sets
log C = 3 + log M as suggested in [6]. Then let
b
M − 1
M · c
C + 1
mc =
δ =
√
2
(cid:3)
(cid:4)
and
,
where b is a parameter. Roughly speaking, mc is the
ciphertext-speciﬁc point around which a window of size
up to 2δ can be drawn that contains the plaintext with
high probability. The larger the parameter b, the larger the
window. Of course we must truncate the window by the
endpoints of the message space, meaning that m will be
with high probability contained in the range
max{1, mc − (cid:7)δM(cid:8)} , min{M, mc + (cid:7)δM(cid:8)}(cid:6)
Rc =
(cid:5)
The analysis of Boldyreva et al. shows that for b = 3 the
probability of landing in this window is negligibly far from
one for uniformly sampled plaintexts [6]. For non-uniform
message distributions, it is likely that more careful analysis
could shrink the window and obtain more leakage, but we
will be conservative and use the larger window for our ﬁrst
and last name attacks. We will use b = 1 for our attacks
on ZIP codes and birth dates. Making the window smaller
slightly increases the leakage and helps reduce the overlap
in leaked ranges for nearby values, though it increases the
likelihood that the true plaintext falls outside the range.
Our birthdate and ZIP code datasets contained a substantial
fraction of all the possible plaintexts2, so there is a great deal
of overlap in the leakage which, intuitively, gives the non-
crossing attack more chances to match a value incorrectly.
Having a smaller window mitigates this.
Abusing just the BCLO leakage. An adversary can attempt
to immediately recover the plaintext for each ciphertext in a
database using just the leaked range Rc and knowledge of
the input alphabet and padding rules. This approach does not
require any auxiliary data, and requires just a few elementary
computations for each ciphertext. In fact, a human attacker
2This fraction is about 56% for ZIP codes and 66% for birthdates,
precluding effective use of the sorting attack from NKW, which requires
almost all plaintexts to be present.
664
Plaintext
michael
david
robert
john
james
daniel
richard
jose
mark
christopher
Ciphertext
mc
cyrzjipnouushzh
aenpse cevvpkmr
emlqrnycvblqqnd
ccnnczzzpruvjhd
bzkxrq
gzortby
aelfspocabjdvjc
ekrzjmjhjxykbba
ccqrlzzziozokby
cwmlfzzzjxhlklh
zokwwbrbibyouo
michaekypfbkfr
david
jwbvhec
robert lwyeorr
johmzzzysfbunn
james
zyovtq
daniel jgaginu
richardkmfnwwx
josdzzzxvfruqg
marjzzzxzqyduv
christotnqfolw
Figure 6: The value mc computed for encryptions of ten ﬁrst names
in the California dataset.
can easily just read off partial or even full plaintexts from
the mc values trivially computable from a ciphertext. Some
examples are shown in Figure 6.
To automate this, we ﬁx a simple heuristic that an attacker
can use to guess a message given the ciphertext c. First,
compute mc and the range Rc. Let [ml, mu] = Rc. Check
if any of ml, mc, mu contains two consecutive spaces in the
ﬁrst half of their string representations. Some names contain
a single space, so we can only conﬁrm padding after seeing
two consecutive spaces. If none do, then forego outputting
a guess. Otherwise, for (an arbitrary) one of the strings that
does contain two consecutive spaces, simply take the preﬁx
preceding these spaces as the plaintext guess. Observe that
this is not guaranteed to be the correct plaintext as there
could be other validly padded plaintexts in the range Rc.
This heuristic performs quite well, particularly for last
names. On average across all our datasets, the raw recovery
rate is 45% for ﬁrst names and 97% for last names. Referring
back to Figure 5, our heuristic is able to do almost as well
as predicted by simply halving the maximum length and
observing the fraction of plaintexts that lie below that length:
on average across datasets, 67% of ﬁrst names are less than
7 characters long, and 99% of last names are less than
14 characters long. While this leakage has been known in
the academic literature [6], we believe its severity was not
understood for practical scenarios before our work.
We have described above how to directly exploit BCLO’s
leakage for ﬁrst and last names, but this approach is readily
generalizable to any plaintext distribution containing mes-
sages of different lengths. In the case of ﬁxed input length
plaintexts, such as ZIP codes and birth dates, there is no need
for padding, and so it is impossible to exactly recover any
plaintexts using the heuristic above. Nevertheless signiﬁcant
partial information leaks that we will exploit next.
Inference attack with BCLO leakage. The heuristic above
recovers less than half of ﬁrst names on average, and as
just mentioned cannot recover full plaintexts for ﬁxed-input-
length domains. We can however integrate the BCLO leakage
into our non-crossing inference attack.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:38 UTC from IEEE Xplore.  Restrictions apply. 
Let G = (U, V, E) be a bipartite graph where every vertex
in U corresponds to a unique ciphertext in C and vertices
in V correspond to unique auxiliary data from Z. The sets
U and V are sorted, so that the ith largest unique ciphertext
is vertex ui and likewise for v. For each ciphertext u ∈ U
where the ciphertext corresponding to u is c, the adversary
computes Rc and then adds an edge (u, v) for each v whose
corresponding value p falls within Rc. This excludes edges
that fall outside the window for c. Each edge is weighted
as before, by α − |HC(i) − HZ(j)|. The adversary outputs
the mappings implied by the solution to the max-weight non-
crossing bipartite matching problem the graph deﬁnes.
For ﬁxed-length inputs such as ZIP codes and birth dates,
we run the inference as described above. For variable-length
data such as ﬁrst names and last names, we ﬁrst run our
heuristic attack, and then run the inference as described above
only on the ciphertexts for which the heuristic fails to make
a guess. The reason to do this is that many plaintexts that are
not in the auxiliary data are nevertheless fully recovered by
the heuristic.
Inference attack results. Combining the heuristic with
inference increases ﬁrst name recovery rate from 45% to
99% on average across datasets. The smallest recovery rate
in any single dataset was 97%. For last names the increase
from inference was negligible, as the heuristic alone already
obtained 97% recovery on average. The average unique re-
covery rate was 90% for ﬁrst names and 94% for last names,
with standard deviation less than 2% for both. Our attack
here recovers the vast majority of plaintext records, as well
as most unique plaintexts. The few unrecovered plaintexts
are ones for which the heuristic fails to retrieve them fully
and they additionally do not appear in the auxiliary data (i.e.,