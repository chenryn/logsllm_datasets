distribution, 
signals. 
relevant 
probability 
the corresponding 
in each bin is divided 
has a mass of s - 1 and R(t) has a mass of w. 
distributions, 
H 
by the total mass of the histogram; 
where the count 
Compute the Kullback-Leibler 
divergence 
[13] between 
distribution 
the anomaly signal A(t): 
R' (t) and the historical 
each recent distribution 
H', producing 
A(t) =  DKdR'(t)IIH') =  L R'(t, k) log2 'k)' 
in bin R'(t, k) differs 
KL-divergence 
H (k). 
of measurements 
fraction 
Intuitively, 
much the fraction 
from the expected 
is a weighted 
average of how 
kER'(t) 
After computing Aj (t) for each component, 
we store the 
as an n x  m matrix, 
where n is the number 
and m  is the number of equi-spaced 
times 
sampled signals 
of components 
at which we sample each anomaly signal. 
these matrices 
as described 
that, having represented 
nals, the rest of our method is system-independent. 
We then process 
3.3. Observe 
the system as a set of anomaly sig­
in Section 
starting 
3.2.1 Computing 
the Anomaly Signal 
we discuss 
In this section, 
of computing 
anomaly signal Aj(t) for the timing model mentioned 
Section 
the offline version. 
3.1. We describe 
the mechanics 
the 
in 
Let S be a discrete 
signal from some component, 
timestamp) 
Individually, 
of a series of time (non-decreasing 
sisting 
value pairs: S =  ((to, vo), (h, VI)" '" (ts, vs)). 
V(i) =  Vi, This work gives special 
when V (i) is the first difference 
of the time stamps (interar­
rival times): V(i) =  T(i) -T(i -1) and V(O) =  ¢ (null). 
denote S(i) =  (ti' Vi)' T(i) =  ti, and 
to the case 
attention 
con­
and 
To compute anomaly signals, 
we compare a histogram of 
to the entire 
a recent window of behavior 
ior for a component. 
bin width for the histogram 
of the recent history 
k =  I max Vi hmin Vi 1 be the number of bins. For each bin 
let w be the size 
and let 
window in number of samples, 
(in seconds), 
history 
of behav­
histogram, 
count the number of ob­
V(i) such thatjh:::; V(i)  c, so there will be an 
Dij  c) influence 
The absence of an edge does 
merely that 
between two components. 
not imply the absence of a shared influence, 
the anomalies 
correlated-a 
ferent graph. More specific 
derstanding 
A directed 
identified 
different 
choice of models may yield a dif­
interpretations 
arise from un­
models and underlying 
that an anomaly on the source 
particular 
edge implies 
by the models are not strongly 
components. 
(tail of the arrow) tends to be followed 
shortly 
which may mean either that the 
by an anomaly on the sink component 
edges mean that influence 
(head of 
was ob­
truly flows in both directions 
component 
thereafter 
the arrow). Bidirectional 
served in both directions, 
influence 
which directionality 
periodic 
within a threshold 
taneously. 
fluential 
components 
a, the anomalies 
An undirected 
anomalies). 
for instance, 
This happens, 
component 
sometimes 
introduce 
is causing 
cliques 
to assign (this situation 
can arise with 
edge means that, to 
occur simul­
when a mutually 
appear  to 
in­
the anomalies. 
Such shared 
into the SIG. 
or that it is unclear 
3.4 Structure-of-Influence 
Graph (SIG) 
A Structure-of-Influence 
Graph (SIG) is a graph G 
explains 
directed, 
as follows: 
to indicate 
the delay(s) 
Edges may be undirected, 
for making an edge directed; 
(V, E) with one vertex per component 
sent influences. 
bidirectional, 
influence. 
This section 
Consider 
and edges that repre­
or even 
with this 
associated 
how to construct 
a SIG. 
between i and j if max(ICijl, 
ICjil) 
the n x n matrices C and D. There is an edge 
> c. Let a be the 
the type of edge is 
> c:) '* (Dij > -a)) 1\ ((!Cji! 
> c:) 1\ (Dij  c:) 1\ (Dji > a) 
> c:) 1\ (Dij  c:) 1\ (Dji > a) '* i  c:) '* (Dji < a)) 
The time complexity 
given an algorithm 
in time O(m), is O(n2m). For large systems, 
the most important 
information 
description, 
When used for problem isolation, 
provided 
by our method is 
in the fonn of graph edges, 
of which 
piece of actionable 
a concise 
components 
seem to be involved. 
directionality 
on those edges tell the order in which to inves­
tigate 
In a system of black boxes, which 
is our model, this is the most any method can provide. 
those components. 
Further, 
the strength and 
4 Controlled 
Experiments 
In this section, 
we study the notion of influence 
of adverse 
it under a variety 
and our 
condi­
train­
on idealized 
noise, message loss, and tainted 
sys­
We use 
of linear chains of components. 
experiments 
method for computing 
tions: measurement 
ing data. We use simulation 
tems consisting 
chains so the results of 
our method is not limited 
with real systems 
complex structure. 
cific question: 
in subsequent 
involve 
Our goal is to thoroughly 
much more 
examine a spe­
sections 
our simulations 
to chains, 
are easy to interpret; 
and our experiments 
Given a known channel 
of data and resource 
978-1-4244-7501-8/101$26.00 
©2010 IEEE 
194 
DSN 2010: Oliner et al. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:06:05 UTC from IEEE Xplore.  Restrictions apply. 
2010 IEEE/IFIP International 
Conference 
on Dependable 
Systems & Networks (DSN) 
 cp  
Figure 3. The three basic structures 
in our 
simulated 
tasks ("T"), 
and resources 
systems, 
built from sources ("S"), 
("R"). 
which influence 
(6") of the influence 
inferred 
show that, for many realistic 
through 
interactions 
is the strength 
Our results 
fluence can propagate 
and we can detect it. 
circumstances, 
through long chains of components, 
in­
could propagate, 
by our method? 
what 
4.1 System Components 
sources, 
and tasks, 
Our simulations 
use three types of components: 
data, tasks, which process data, and re­
by sources 
and tasks to perform 
over a shared resource. 
shown in Figure 3, 
or via 
chains 
is a source; 
which are required 
Pairs of sources 
each other via direct communication 
which generate 
sources, 
these actions. 
can influence 
competition 
of such structures 
that source, 
behave during the experiments 
that we wish to find. The only input to our method is a 
pair of timestamp 
one for the tail) corresponding 
about simulation 
No information 
ate components 
is provided. 
in which the first component 
(one for the head of the chain and 
called the head, is designed 
to message sending times. 
and acts as the root cause 
We study linear 
to sometimes 
parameters 
vectors 
mis­
or intermedi­
source-to-task 
or task-to­
by timing (anomalous 
input timing may 
output timing, 
by semantics 
(tasks 
can flow over a direct 
Influence 
task channel 
either 
cause anomalous 
interaction), 
to process 
flow over a shared resource 
degree of contention 
ulate implicit 
communication 
may influence 
uncommon messages), 
through 
as in a producer-consumer 
may take more or less time 
or both. Influence 
can 
only through timing (e.g., the 
timing); 
we do not sim­
shared memory. 
4.2  Component Behavior 
distributed 
(see Section 3.2.1). 
These experi­
Let Tix denote 
We characterize 
of interarrival 
timing behavior 
of components 
by dis­
times, which is sufficient 
to com­
tributions 
pute anomaly signals 
ments use Gaussian 
a normally 
standard 
lem more difficult, 
sult in consistently 
variance) 
surement 
deviation 
(normal) 
distributions. 
random variable 
with mean I and 
(Ix. Fixing the mean makes the prob­
because abnormal 
more or fewer messages 
behavior 
(merely 
looks like mea­
behavior 
does not re­
and because anomalous 
imprecision 
A source generates 
(noise). 
the message 0 every Tin seconds. 
if any downstream 
component 
is not 
A 
source may be blocked 
in which case it waits until 
are ready, sends the message, 
and then 
the message, 
ready to receive 
all such components 
waits Tin seconds before trying to generate 
three types of anomalous 
sage. We consider 
head node: timing (generates 
the message 1), and both. 
semantics 
(generates 
for a 0 message and Til seconds 
A task begins processing 
a message upon receipt, 
the next mes­
behavior 
at the 
taking 
for a 1 message. 
a message every Tia seconds), 
TiD seconds 
After processing, 
component 
task is blocked. 
not processing 
downstream. 
a task sends the same message to the next 
is not ready, the 
A task is ready when it is not blocked and 
If that component 
A resource 
messages; 
it can si­
a message. 
receives 
process 
and processes 
up to R messages 
multaneously 
R. A resource 
and is ready to receive 
R messages. 
random order. 
Resources 
requires 
Tir seconds to process 
whenever 
service 
it is processing 
simultaneous 
a message 
fewer than 
requests 
in a 
for some capacity 
When the head or tail sends a message, 
as described 
the influence 
the time at which the message was sent; 
above, it records 
our method computes 
lists. 
timestamp 
plex behavior, 
ferent classes 
tention, 
and potential 
While real systems 
dif­
these simple rules are enough to capture 
of inputs (0 vs. 1 messages), 
resource 
con­
timing dependencies. 
given only this pair of 
may exhibit more 
com­
4.3 Methodology 
value 6", 
of a chain over a time 
Each experiment, 
resulting 
in a single influence 
simulations 
two independent 
involves 
period long enough for the head to send 10,000 messages. 
yields a trace that is used for training 
The first simulation 
(a behavior 
and the second, 
used to build the SIG. Except where otherwise 
training 
monitoring 
behavior 
is 
a monitoring 
the 
and the 
anomalous 
a contiguous 
5% of the trace (500 messages). 
trace does not contain 
period of anomalous 
trace contains 
baseline), 
indicated, 
behavior, 
lasting 
trace, 
two connected components, 
Resources 
have exactly 
contention 
has a capacity 
each 
with a normal average message sending rate of 1 per sec­
of R =  2. That is, 
ond, so every resource 
there should be little 
The number of resources 
are 
evenly distributed 
noted, (In =  (Ir =  (Io =  0.01 and (Ia =  (II =  0.1. For 
bin size is h =  0.01 
the component 
seconds 
samples (chosen 
and the window size is w  =  500 
(set automatically) 
to match the anomalous 