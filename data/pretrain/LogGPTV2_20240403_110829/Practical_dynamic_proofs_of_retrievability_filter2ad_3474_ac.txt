times. At the time C is rebuilt, all duplicates will be sup-
pressed, and only the most recent copy of each block will be
rebuilt into C. As we later show, the cost of rebuilding C is
O(βn log n) (see Figure 4). Since C is only rebuilt every n
write operations, the amortized cost is O(β log n) per write.
4.3 Security
Before we introduce the rebuilding algorithm, which lies
at the heart of our construction, we give an intuitive ex-
planation of why the main security property of PoR, i.e.,
retrievability (see Deﬁnition 2), is satisﬁed by our construc-
tion. Our algorithm will maintain the following invariant:
Invariant 1. Treat C as the (k + 1)-th level Hk+1. We
will maintain the invariant that each level H(cid:96) where (cid:96) ∈
{0, 1, . . . , k + 1} is a (m(cid:96), 2(cid:96), d(cid:96)) erasure coding of 2(cid:96) blocks,
where m(cid:96) = Θ(2(cid:96)). Furthermore, we will show that encoding
is a maximum distance encoding scheme, such that d(cid:96) =
m(cid:96) − 2(cid:96) + 1 = Θ(2(cid:96)), i.e., the encoding of level H(cid:96) can
tolerate up to d = Θ(2(cid:96)) erasures.
In our speciﬁc construction, each level is encoded into ex-
actly twice as many blocks, i.e., H(cid:96) is a (2(cid:96)+1, 2(cid:96), 2(cid:96)) erasure
coding of 2(cid:96) recently written blocks. Similarly, C is also
encoded into twice as many blocks.
Recall that our audit algorithm checks O(λ) blocks for
each level H(cid:96) and for C. Intuitively, the server has to delete
more than half of the blocks in any level H(cid:96) or C to incur
any data loss. However, if the server deletes so many blocks,
checking O(λ) random blocks in level H(cid:96) or C will almost
surely detect it (with probability at least 1 − 2−λ). Also,
observe that the combination of the hierarchical structure H
and the buﬀer C contains information about the up-to-date
copy of all blocks. Therefore, we can intuitively conclude
that as long as the above invariant is maintained, our audits
can detect any data loss with overwhelming probability.
The formal proof requires showing that there exists an ex-
tractor which can extract the up-to-date copy of all blocks if
the extractor can run the Audit algorithm a polynomial num-
ber of times, with blackbox rewinding access to the server.
We defer the formal proof to the full online version [22].
4.4 Fast Incrementally Constructible Codes
To achieve the promised eﬃciency, our main technical
challenge is to design a fast,
incrementally constructible
code. In our scheme, we employ a fast incrementally con-
structible code based on Fast Fourier Transform (FFT). At
......329a very high level, each level H(cid:96) contains two size-2(cid:96) FFT-
based codes. As is well-known, FFT can be computed using
a standard divide-and-conquer strategy [2,3], forming a but-
terﬂy network (see Figure 3). This means that H(cid:96) can be
computed from two H(cid:96)−1’s in time O(β · 2(cid:96)). Note that in
comparison, the oblivious sorting in ORAM schemes take
time O(β · (cid:96) · 2(cid:96)) time to rebuild level H(cid:96).
Other than our FFT-based encoding scheme, it is possible
to employ known linear-time constructible codes [23], which
take O(c) time to encode c blocks. We choose to use our
FFT-based codes because of the relative conceptual and im-
plementation simplicity. Particularly, rebuilding a level H(cid:96)
requires only taking O(2(cid:96)) linear combinations of blocks—in
fact, in Section 5, we will leverage this linearity property and
a homomorphic checksum scheme to make the client-server
the bandwidth cost per writes independent of the block size.
4.4.1 Detailed Code Construction
In our construction, level H(cid:96) contains 2(cid:96) blocks, which are
encoded into 2(cid:96)+1 codeword blocks, such that knowledge of
any 2(cid:96) codeword blocks can recover the original 2(cid:96) blocks.
Suppose the original blocks in level H(cid:96) are denoted as
a vector x(cid:96), where each block in x(cid:96) arrived at time t, t +
1, t + 2, . . . , t + 2(cid:96) − 1 (mod n) respectively. For level H(cid:96),
t is always a multiple of 2(cid:96). Note that the time t is only
incremented for write requests since reads do not need to
touch the hierarchical log.
Notation. For the description of our code, we deﬁne the
partial bit-reversal function and permutation—this inher-
ently results from the divide and conquer strategy of the
FFT. Let ψc(i) denote a partial bit-reversal function that
reverses the least signiﬁcant c bits of an integer i. For ex-
ample, let n = 8, then ψ3(1) = 4, ψ2(1) = 2. Let πc(x)
denote a partial bit-reversal permutation, where index i is
permuted to index ψc(i).
Let also w denote the 2n-th primitive root of unity in an
appropriate ﬁnite ﬁeld deﬁned explicitly in Figure 4.
Closed-form formula for each level. Level H(cid:96) contains
code blocks output by the following linear encoding scheme:
H(cid:96) := π(cid:96)(x(cid:96)) [F(cid:96), D(cid:96),tF(cid:96)] ,
(1)
where F(cid:96) is the 2(cid:96) by 2(cid:96) Fourier Transform matrix from the
ﬁnite ﬁeld deﬁned in Figure 4 and D(cid:96),t is an appropriate
diagonal matrix deﬁned as below.
D(cid:96),t := diag(wψk−(cid:96)(t), wψk−(cid:96)(t+1), . . . , wψk−(cid:96)(t+2(cid:96)−1)) .
We now have the following lemma (its proof can be found
in the full online version [22]):
Lemma 1. Any 2(cid:96) × 2(cid:96) submatrix of the generator matrix
G(cid:96) := [F(cid:96), D(cid:96),tF(cid:96)] is full rank.
Note that the above lemma means that if we have any 2(cid:96)
(out of 2(cid:96)+1) code blocks for a level H(cid:96), we can recover all
original blocks in that level. As mentioned earlier, using the
divide-and-conquer strategy for computing FFT transforms,
we can eﬃciently build our codes over time. The detailed
algorithm is presented in the next subsection.
For a concrete small example when n = 8, please refer to
the full online version [22].
Figure 3: Butterﬂy network: the 8-th write oper-
ation encounters a full H0, H1, and H2. Blocks in
H0, H1, H2 as well as the newly written block will be
encoded and written to H3.
4.5 Detailed Protocol Description
The detailed protocol description is presented in Figure 4.
The lemma below states that algorithm mix(A0, A1) speciﬁed
in Figure 4 produces codes for the hierarchical log, satisfy-
ing Equation (1). Its proof can be found in the full online
version [22].
Lemma 2. Algorithm mix(A0, A1) in Figure 4 ensures that
each ﬁlled level H(cid:96) is a code of the form of Equation (1).
4.6 Enhancements to Basic Construction
Segmenting blocks to avoid big integer operations.
In the above description, each block is treated as a large
integer during the encoding operations. We can avoid big
integer arithmetic by dividing blocks into smaller segments.
In our implementation, we choose a prime p = αn + 1 for
a small positive integer α, such that p can be represented
with a basic integer type. We divide each block into β0 :=
(cid:100)log p(cid:101) bits. and perform the mix algorithm described above
on each smaller segment of the block. Note that using a
smaller p does not aﬀect the security of our scheme, since
the parameter p is part of the erasure coding, and p is not
related to the size of any cryptographic keys.
Ensuring authenticity and freshness. Since the last-
write time of blocks in the buﬀers H and C are computable
from the current time t, the client can simply use time and
location encoded MACs to ensure authenticity and freshness
of blocks in the buﬀers H and C. Blocks in the buﬀer U
need random access, therefore, we can use a standard Merkle
hash tree (i.e., memory checking) to ensure freshness and
authenticity of blocks in U. We omit the details here since
we will present an improved construction in Section 5 where
we will revisit the authenticity and freshness issue.
Theorem 1. The basic dynamic PoR scheme of Figure 4
satisﬁes both authenticity (Deﬁnition 1) and retrievability
(Deﬁnition 2).
The authenticity and retrievability proofs of the above
theorem can be found in the full online version [22].
5.
IMPROVED CONSTRUCTION
In our basic construction (Section 4), every write incurs
the reading and writing of O(log n) blocks, or O(β log n)
bits on average, where β is the block size. In this section,
we will describe an improved construction that achieves im-
proved bandwidth and client computation overhead (how-
ever the server computation of the new construction remains
67543210Levels before rebuildResult of rebuildPast rebuildsTemporary levels createdduring rebuilds330Main Dynamic PoR Construction
Let (encode, decode) denote a maximum distance separable
(m, n, d) erasure code, where m = O(n).
/* Authenticity: Standard Merkle-hash tree techniques can
be used to verify the authenticity/freshness of blocks re-
trieved from the server. For clarity, we omit such details
from the scheme description. Section 5 presents more opti-
mized techniques for achieving authenticity/freshness. */
Init(1λ, n, β,M):
U ← M; C ← encode(M); H ← ∅.
Read(i, st, ¯M): To read a block i, simply read U[i] and
check its authenticity.
Write(i, B, st, ¯M): To overwrite block i with B,
U[i] ← B. Call HAdd(B).
let
Audit(st, ¯M): Check the authenticity of O(λ) number of
blocks from the erasure coded copy C and O(λ) num-
ber of blocks from each ﬁlled level H(cid:96).
Algorithm HAdd(B)
Suppose each H(cid:96) is of the form H(cid:96) := (X(cid:96), Y(cid:96)), where X(cid:96)
and Y(cid:96) each stores 2(cid:96) blocks.
Let the current write be the t-th write operation ( mod 2k).
Let ψ(·) denote the bit reversal function, such that ψ(t)
outputs the value corresponding to reversing the bits of the
binary representation of t.
• If H0 is empty, let X0 = B, Y0 = B · wψ(t).
• Else, suppose levels 0, . . . , (cid:96) are consecutively full lev-
els for some (cid:96) < k, and level (cid:96) + 1 is the ﬁrst empty
level.
– Call HRebuildX((cid:96) + 1, B).
– Call HRebuildY((cid:96) + 1, B · wψ(t)).
• Every 2k time steps, call CRebuild().
Parameters: Let p = α· (2n) + 1 denote a prime for some
α ∈ N. Suppose p is chosen to be large enough to encode
blocks of β bits.
Let g denote a generator of Z∗
2n-th primitive root of unity mod p.
p. Let w = gα mod p be a
Algorithms HRebuildX((cid:96), B), HRebuildY((cid:96), B)
/* HRebuildY is exactly the same as HRebuildX, except that
all X’s are replaced with Y ’s. Below we formally describe
HRebuildX as an example. */
Inputs: Consecutively ﬁlled levels X0 . . . X(cid:96)−1 (the X
portion), and a new (possibly encoded) block B.
Output: A rebuilt X(cid:96). Levels X0, . . . , X(cid:96)−1 are emptied
at the end of HRebuildX((cid:96), B).
• (cid:101)X1 ← mix(X0, B)
• For i = 1 to (cid:96) − 1: (cid:101)Xi+1 ← mix(Xi, (cid:101)Xi)
// (cid:101)Xi’s are the red arrays in Figure 3.
• Output X(cid:96) := (cid:101)X(cid:96).
Algorithm mix(A0, A1)
Inputs: Two arrays A0, A1 ∈ Z2(cid:96)
Outputs: A new array A of length 2 · 2(cid:96).
p each of length 2(cid:96).
• Let ν = wn/2(cid:96)
• For i = 0 to 2(cid:96) − 1:
be a 2(cid:96)+1-th primitive root of unity.
A[i]
A[i + 2(cid:96)]
:= A0[i] + νiA1[i]
:= A0[i] − νiA1[i]
(mod p)
(mod p)
• Output A.
Algorithm CRebuild()
• C ← encode(U).
• Empty H.
Figure 4: Basic protocol description. We assume that blocks are tagged with their block identiﬁer.
the same), by removing the dependence on the block size.
In our improved construction, writing a block incurs only
β + O(λ log n) cost, where λ is the security parameter; and
the typical value for λ is 128 or 256 bits. This means that
the bandwidth overhead and the client computation for write
operations of our PoR construction is analogous to that of
a Merkle hash tree. Recall that by the deﬁnition of PoR,
PoR is a strictly stronger primitive than a Merkle hash
tree since PoR not only needs to guarantee authenticity and
freshness—which a standard Merkle hash tree ensures—but
it needs to additionally guarantee that the server is storing
all of the client’s data. Our construction basically shows
that we can obtain the additional PoR guarantee (on top of
a Merkle hash tree) almost for free.
5.1 Intuition
Recall that in the basic construction, the O(β log n) cost
arises from the periodical rebuilding of the hierarchical log
structure H and the erasure-coded copy C.
In the basic
construction, the server is conceptually treated as a pas-
sive remote storage device, and the client performs all the
computation. Therefore, the client needs to download the
blocks from the server to perform computation over these
blocks, when rebuilding any level H(cid:96) in the hierarchical log
structure, or when rebuilding C.
Our idea is to have the server perform the computation
on behalf of the client, thus signiﬁcantly reducing the client
computation and bandwidth. Observe that in our basic con-
struction, the algorithms for rebuilding each H(cid:96) or C are
publicly known to the server, and the server can perform
the rebuilding on its own. The client simply needs to check
that the server performed the rebuilding correctly.
To achieve this performance improvement and avoid down-
loading the blocks during a rebuilding, we will attach a
homomorphic checksum along with each (encoded or unen-
coded) block in the hierarchical log structure H or C. Each
331homomorphic checksum is a collision-resistant summary of
a block. Now, instead of performing the rebuilding over real
data blocks, the client simply downloads checksums, checks
their authenticity and performs the rebuilding over these
homomorphic checksums.
The homomorphic checksum for each block is then tagged
with its position and time written, and stored on the server
in encrypted and authenticated format. This ensures that
1) the server does not know the values of the homomorphic
checksum which is necessary for security as explained later;
and 2) the client can always verify the correctness and fresh-
ness of the homomorphic checksum retrieved.
We note here that we choose to use a special type of homo-
morphic checksums that are not publicly veriﬁable (though
we later show that this is not a limitation for making our
scheme publicly veriﬁable). The reason for that is that our
homomorphic checksum construction is designed for per-
formance. In comparison, publicly veriﬁable homomorphic
checksums (e.g., lattice-based ones [19] or RSA-based ones [5])
are not as eﬃcient practice.