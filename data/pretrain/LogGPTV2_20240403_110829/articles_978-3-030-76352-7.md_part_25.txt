### 158 X. Liu et al.

Our experiments show that the fastText embedding, pre-trained using both the WA data and the Loghub data, significantly outperforms the general-purpose fastText embedding by an 8% increase in accuracy. This result underscores the effectiveness of using domain-specific and diversified data for pre-training embedding features to enhance log anomaly detection tasks.

In contrast, our pre-trained BERT embedding with the WA data performs comparably to the original general-purpose BERT embedding, though both are slightly worse than the baseline. Surprisingly, when we introduce more diverse data from both the WA data and the Loghub data to pre-train BERT, the accuracy drops considerably. One possible reason is that log data are much simpler than general-purpose text data such as Wikipedia articles or news articles, and the context in log data is not rich enough for BERT to learn effectively during model pre-training. Additionally, since log anomaly detection is essentially an unsupervised learning task, it is challenging to fine-tune pre-trained BERT models as in supervised learning tasks.

Overall, our experiments demonstrate that context-free embeddings, such as fastText, are more robust and effective for pre-training features for log anomaly detection, especially when pre-trained with IT Operations domain data from diverse applications.

**Table 1. Accuracy results on log anomaly detection with pre-trained features from embeddings.**

| Model          | HDFS (Normal) | HDFS (Abnormal) | WA-1 (Normal) | WA-1 (Abnormal) | WA-2 (Normal) | WA-2 (Abnormal) | Average |
|----------------|---------------|-----------------|---------------|-----------------|---------------|-----------------|---------|
| Baseline       | 99.99%        | 44.9%           | 93.3%         | 66.7%           | 95%           | 80%             |         |
| fastText-origin| 98.8%         | 66%             | 93.3%         | 100%            | 98.3%         | 91%             |         |
| fastText-wa    | 98.8%         | 59.7%           | 93.3%         | 100%            | 98.3%         | 90%             |         |
| fastText-wa-loghub | 99.6%      | 99.9%           | 96.7%         | 100%            | 98.3%         | 99%             |         |
| BERT-origin    | 2%            | 99%             | 93.3%         | 100%            | 98.3%         | 79%             |         |
| BERT-wa        | 97.1%         | 52.7%           | 93.3%         | 100%            | 95%           | 78%             |         |
| BERT-wa-loghub | 96.8%         | 47.5%           | 93.3%         | 100%            | 40%           | 67%             |         |

### Performance Testing

We tested the performance of our log anomaly prediction models built using language models as features in an IT Operations production environment. The production environment consists of a cluster with 2 CPUs and 4GB of memory. The test data includes 10,000 randomly sampled logs from the WA data. We considered pre-trained BERT models with different numbers of layers, as well as the one-layer fastText model.

**Table 2. Performance testing results on log anomaly detection with pre-trained features from embeddings.**

| Model        | Total Time | Average Speed |
|--------------|------------|---------------|
| fastText     | 1.4s       | 7000 lines/s   |
| BERT (1 layer)| 60s        | 166 lines/s    |
| BERT (3 layers)| 450s      | 22 lines/s     |
| BERT (6 layers)| 1700s     | 6 lines/s      |

As the BERT model becomes more complex with additional layers, the average speed of embedding inference from the pre-trained model decreases significantly. The fastText model is over 40 times faster than the one-layer BERT model because it essentially performs a lookup once the pre-trained embeddings are loaded into memory.

### 5 Conclusion and Future Work

As IT complexity grows and the use of AI technologies expands, enterprises are increasingly looking to leverage AI to transform how they develop, deploy, and operate their IT. Pre-training a language model can accelerate the development of text-based AI models for optimizing IT Operations management tasks at scale. We investigated the effects of this language model pre-training approach for IT Operations management through a series of experiments on different language model types, data domains, and data diversities. Our empirical results on the prediction accuracy of our log anomaly prediction model and its run-time inference performance using language models as features in an IT Operations production environment show that machine learning models built using context-free embeddings trained with diverse IT Operations domain data outperform those built using general-purpose data. Our pre-trained language models for IT Operations will be released soon. We hope that the insights gained from these experiments will help researchers and practitioners develop solutions and tools that enable better scalability, integration, and management in the IT Operations domain. In the future, we plan to explore the effects of pre-trained features using language models on different IT Operations management tasks, such as fault localization and similar incident analysis. Additionally, we intend to extend our studies to use more advanced language models like GPT-3 [3].

### References

1. I.W. Assistant (2020). https://www.ibm.com/cloud/watson-assistant/
2. Bojanowski, P., Grave, E., Joulin, A., Mikolov, T.: Enriching word vectors with subword information. Trans. Assoc. Comput. Linguist. 5, 135–146 (2017)
3. Brown, T.B., et al.: Language models are few-shot learners. arXiv preprint arXiv:2005.14165 (2020)
4. CA-Technologies: The avoidable cost of downtime (2010)
5. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: pre-training of deep bidirectional transformers for language understanding. In: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4171–4186 (2019)
6. Gartner (2017). https://www.gartner.com/en/newsroom/press-releases/2017-04-11-gartner-says-algorithmic-it-operations-drives-digital-business
7. Howard, J., Ruder, S.: Universal language model fine-tuning for text classification. arXiv preprint arXiv:1801.06146 (2018)
8. Kafka (2020): https://kafka.apache.org/
9. Kudo, T., Richardson, J.: Sentencepiece: a simple and language independent subword tokenizer and detokenizer for neural text processing. arXiv preprint arXiv:1808.06226 (2018)
10. Meng, W., et al.: Loganomaly: Unsupervised detection of sequential and quantitative anomalies in unstructured logs. In: IJCAI, pp. 4739–4745 (2019)
11. Mikolov, T., Grave, E., Bojanowski, P., Puhrsch, C., Joulin, A.: Advances in pre-training distributed word representations. arXiv preprint arXiv:1712.09405 (2017)
12. Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J.: Distributed representations of words and phrases and their compositionality. In: Advances in Neural Information Processing Systems, pp. 3111–3119 (2013)
13. Pennington, J., Socher, R., Manning, C.D.: Glove: global vectors for word representation. In: Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1532–1543 (2014)
14. Peters, M.E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., Zettlemoyer, L.: Deep contextualized word representations. arXiv preprint arXiv:1802.05365 (2018)
15. Radford, A., Narasimhan, K., Salimans, T., Sutskever, I.: Improving language understanding by generative pre-training (2018). https://s3-us-west-2.amazonaws.com/openai-assets/researchcovers/languageunsupervised/languageunderstandingpaper.pdf
16. Sarnovsky, M., Surma, J.: Predictive models for support of incident management process in IT service management. Acta Electrotechnica et Informatica 18(1), 57–62 (2018)
17. Vaswani, A., et al.: Attention is all you need. In: Advances in Neural Information Processing Systems, pp. 5998–6008 (2017)
18. Wold, S., Esbensen, K., Geladi, P.: Principal component analysis. Chemom. Intell. Lab. Syst. 2(1–3), 37–52 (1987)
19. Xu, W., Huang, L., Fox, A., Patterson, D., Jordan, M.I.: Detecting large-scale system problems by mining console logs. In: Proceedings of the ACM SIGOPS 22nd symposium on Operating Systems Principles, pp. 117–132 (2009)
20. Zhang, Y., Rodrigues, K., Luo, Y., Stumm, M., Yuan, D.: The inflection point hypothesis: a principled debugging approach for locating the root cause of a failure. In: Proceedings of the 27th ACM Symposium on Operating Systems Principles, pp. 131–146 (2019)
21. Zhou, X., et al.: Latent error prediction and fault localization for microservice applications by learning from system trace logs. In: Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 683–694 (2019)
22. Zhu, J., et al.: Tools and benchmarks for automated log parsing. In: 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP), pp. 121–130. IEEE (2019)

### Towards Runtime Verification via Event Stream Processing in Cloud Computing Infrastructures

**B**
Domenico Cotroneo, Luigi De Simone, Pietro Liguori, Roberto Natella, and Angela Scibelli
DIETI, University of Naples Federico II, Naples, Italy
{cotroneo,luigi.desimone,pietro.liguori,roberto.natella}@unina.it, PI:EMAIL

#### Abstract

Software bugs in cloud management systems often lead to erratic behavior, hindering the detection and recovery of failures. Consequently, failures may not be timely detected and notified, and can silently propagate through the system. To address these issues, we propose a lightweight approach to runtime verification for monitoring and failure detection in cloud computing systems. We performed a preliminary evaluation of the proposed approach in the OpenStack cloud management platform, an "off-the-shelf" distributed system, demonstrating that the approach can be applied with high failure detection coverage.

**Keywords:** Runtime verification, runtime monitoring, cloud computing systems, OpenStack, fault injection

### 1 Introduction

Cloud infrastructures are now considered a valuable opportunity for running services with high-reliability requirements, such as in the telecom and healthcare domains. Unfortunately, residual software bugs in cloud management systems can lead to high-severity failures, such as prolonged outages and data losses. These failures are especially problematic when they are silent, i.e., not accompanied by any explicit failure notification, such as API error codes or error entries in the logs. This behavior hinders timely detection and recovery, allows failures to silently propagate through the system, and makes the traceback of the root cause more difficult and recovery actions more costly (e.g., reverting a database state).

To address these issues, more powerful means are needed to identify these failures at runtime. A key technique in this field is runtime verification, which performs redundant, end-to-end checks (e.g., after service API calls) to assert whether the virtual resources are in a valid state. For example, these checks can be specified using temporal logic and synthesized in a runtime monitor. Runtime verification is now widely employed in academia and industry to achieve reliability and security properties in software systems. This method complements classical exhaustive verification techniques (e.g., model checking, theorem proving, etc.) and testing.

In this work, we propose a lightweight approach to runtime verification tailored for the monitoring and analysis of cloud computing systems. We used a non-intrusive form of tracing events in the system under test and built a set of lightweight monitoring rules from correct executions of the system to specify the desired system behavior. We synthesize the rules in a runtime monitor that verifies whether the system's behavior follows the desired one. Any runtime violation of the monitoring rules provides a timely notification to avoid undesired consequences, such as non-logged failures, non-fail-stop behavior, and failure propagation across sub-systems. Our approach does not require any knowledge about the internals of the system under test and is especially suitable in multi-tenant environments or when testers may not have a full and detailed understanding of the system. We investigated the feasibility of our approach in the OpenStack cloud management platform, showing that the approach can be easily applied in the context of an "off-the-shelf" distributed system. To preliminarily evaluate the approach, we executed a campaign of fault-injection experiments in OpenStack. Our experiments show that the approach can be applied in a cloud computing platform with high failure detection coverage.

In the following sections, Sect. 2 discusses related work; Sect. 3 presents the approach; Sect. 4 presents the case study; Sect. 5 experimentally evaluates the approach; and Sect. 6 concludes the paper.

### 2 Related Work

Promptly detecting failures at runtime is fundamental to stop failure propagation and mitigate its effects on the system. In this work, we exploit runtime verification to state the correctness of a system execution according to specific properties. In literature, some studies refer to runtime verification as runtime monitoring or dynamic analysis. Runtime monitoring consists of observing the behaviors of the target system during its operation instead of verifying the system according to a specific model.

Over the last decades, several efforts have been spent on methodologies and tools for debugging and monitoring distributed systems. Aguilera et al. [1] proposed an approach to collect black-box network traces of communications between nodes. The objective was to infer causal paths of the requests by tracing call pairs and analyzing correlations. Magpie [3] and Pinpoint [8] reconstruct causal paths by using a tracing mechanism to record events at the OS-level and the application server level. The tracing system tags incoming requests with a unique path identifier and links resource usage throughout the system with that identifier. Gu et al. [21] propose a methodology to extract knowledge on distributed system behavior of request processing without source code or prior knowledge. The authors construct the distributed system’s component architecture in request processing and discover the heartbeat mechanisms of target distributed systems. Pip [31] is a system for automatically checking the behavior of a distributed system against programmer-written expectations about the system. Pip provides a domain-specific expectations language for writing declarative descriptions of the expected behavior of large distributed systems and relies on user-written annotations of the source code of the system to gather events and propagate path identifiers across chains of requests. OSProfiler [25] provides a lightweight but powerful library used by fundamental components in the OpenStack cloud computing platform [24]. OSProfiler provides an annotation system that can generate traces for request flows (RPC and HTTP messages) between OpenStack subsystems. These traces can be extracted and used to build a tree of calls, which can be valuable for debugging purposes. However, using OSProfiler requires deep knowledge about OpenStack internals, making it hard to use in practice.

Research studies on runtime verification have focused on formalisms for describing properties to be verified. Typically, a runtime verification system provides a Domain Specification Language (DSL) for the description of properties to be verified. The DSL can be a stand-alone language or embedded in an existing language. Specification languages for runtime verification can be regular, which includes temporal logic, regular expressions, and state machines, but also non-regular, which includes rule systems and stream languages.

In the runtime verification literature, there is an established set of approaches for the specification of temporal properties, which include Linear Temporal Logic (LTL) [28], Property Specification Patterns (PSP) [16], and Event Processing Language (EPL) [18]. Linear Temporal Logic is the most common family of specification languages, supporting logical and temporal operators. LTL is extensively used as a specification language in many model checkers [6, 9, 22]. The Property Specification Patterns consist of a set of recurring temporal patterns. Several approaches use PSP and/or extend the original patterns used in [5]. Event Processing Language is used to translate event patterns into queries that trigger event listeners when the pattern is observed in the event stream of a Complex Event Processing (CEP) environment [33]. The most interesting characteristic of CEP systems is that they can be used in Stream-based Runtime Verification (SRV) tools. SRV is a declarative formalism to express...