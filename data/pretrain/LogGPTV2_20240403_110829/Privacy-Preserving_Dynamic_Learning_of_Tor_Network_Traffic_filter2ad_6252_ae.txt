### References
1. [HTTP Archive](http://httparchive.org)
2. [Alexa Top Sites](http://www.alexa.com/topsites)

### Session 10A: TORCCS’18, October 15-19, 2018, Toronto, ON, Canada

#### Figure 8: Total Session Size Distribution
- **(a) HTTP Archive Model**
- **(b) BitTorrent Model**

This figure compares the total session size distribution in our general user models to the actual session sizes in the full datasets. Our modeling approach aims to maintain the overall distributions of page, request, and response sizes, even with a smaller number of multiple-transfer sessions.

### Modeling Approach (Algorithm 1)
To create \( n \) sessions, we follow these steps:
1. Obtain a list of all first requests on pages, sorted by their response sizes.
2. Split this list into \( n \) equally sized bins.
3. Compute the median of the response sizes in each bin and use them as the first transfer sizes in our sessions (lines 2-7).
4. Use a similar median-binning approach to compute the number of requests for each session (lines 8-11) and their sizes (lines 12-15).

The median-binning strategy ensures that the distribution of our first request sizes closely matches the distribution of request sizes in the original dataset. The distribution of modeled total session sizes compared to actual total page sizes is shown in Figure 8a. A Kolmogorov–Smirnov test of the distributions yields a result of 0.045 (p < 0.05), indicating that our model approximates the dataset reasonably well.

### BitTorrent Bulk User Model
We also designed a BitTorrent user model to generate traffic similar to real-world BitTorrent traffic. We used the same general strategy as for the web user model but generated our own dataset since no suitable existing dataset was found.

#### Data Collection
- Sourced 30 torrent files from various open-source Linux distributions and free software websites.
- Loaded each torrent into a modified version of the rTorrent client12 to export useful events regarding connections and incoming/outgoing pieces.
- Downloaded torrents at different throttled speeds (25, 50, 75, and 100 Mbit/s) on three machines located in the United Kingdom, California, and Washington DC.
- Successfully collected 309 samples of BitTorrent traffic during 2017-12 and 2018-01, covering a wide range of total torrent sizes, BitTorrent swarm sizes, and effective maximum bandwidth rates.

#### Extracting Representative Sessions
- Sort sessions by the number of connections made or received.
- Bin the sessions and use the median number of connections in each bin as the representative number for one of the \( n \) sessions.
- Assign each session a number of connections, but not the amount to send, receive, or the connection start time.
- Determine the amount to send and receive using median-binning on the connections in each bin.
- Calculate the start time using median-binning, but shuffle the times to avoid the least active connection starting the soonest.

The resulting distribution of modeled session sizes, where session size is the sum of the bytes received across all connections, is plotted against actual session sizes in Figure 8b. A Kolmogorov–Smirnov test of the distributions yields a result of 0.22 (p < 0.005), indicating that our model approximates the dataset reasonably well.

### PrivCount Model
Our PrivCount model is constructed using the measurement results from Sections 3 and 4. Each client generates streams and packets according to the Hidden Markov Models (HMMs) from Section 4. We specify the HMM graph files as parameters for a model action type in the TGen action graph.

#### Traffic Generation Process
- Traverse the states in the stream HMM graph to generate stream observations.
- Generate packet schedules for each stream using the packet HMM graph.
- Sample delays between streams and packets from the probability distributions associated with the emission of each observation.
- Continue the process until the close state in the stream HMM is reached.

We use measurements from Section 3 to determine the number of clients and circuits to create. Specifically, we create a number of active clients according to our entry measurements from Table 3, ignoring inactive clients. We scale our measurements according to the combined bandwidth fraction of the relays in our PrivCount deployment and the fraction of the Tor network we are simulating.

### Evaluation
#### Experimental Setup
We use Shadow16 to evaluate and compare our traffic models. Shadow is a network simulator that runs real applications, including Tor and TGen. We created an updated Shadow network model based on Internet ping measurements.

#### Network Model
- Measured all available Atlas probes and selected one representative probe per city with the highest uptime.
- Scheduled 3 ping measurements for each pair of probes.
- Created a network graph with vertices representing cities and edges assigned latencies based on the mean of successful pings.
- Assigned fractional packet loss rates to edges based on latency.

#### Tor Host Model
- Created three Tor host models for Shadow, one for each traffic model from Section 5.2.
- Configured the network with 2000 Tor relays, 5000 TGen servers, and 60,000 TGen clients.
- Replaced single file TGen models with more complex HTTP and BitTorrent models in the protocol model.
- Reduced the number of clients to match the new model's median session size and throughput.

### Results
#### Distance
- Compared measurement results from each Shadow experiment to ground truth Tor measurements using Wasserstein distance.
- The PrivCount model is closer to Tor for all single-type counters, with a cumulative percentage distance of 408%.
- The protocol and PrivCount models are similarly close for histogram-type counters, with cumulative percentage distances of 56% and 95%, respectively.

#### Performance
- Measured the performance overhead of our HMM generator processes.
- Generated 439,344 "circuits" and 4,980,038 packet sequences.
- Found that the generator times are negligible compared to the time to send and receive network traffic.

### Figures
- **Figure 9**: Shadow and TorPerf performance benchmarks.
- **Figure 10**: Wasserstein distance between PrivCount measurements as a percentage of ground truth.
- **Figure 11**: Performance overhead of our HMM generator processes.

### Footnotes
12. [rTorrent](https://rakshasa.github.io/rtorrent)
13. [RIPE Atlas](https://atlas.ripe.net)
14. [Maxmind geoip](https://www.maxmind.com)
15. [Speedtest](http://www.speedtest.net)
16. [Shadow](http://shadow.github.io)