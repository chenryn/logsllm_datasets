error. Fortunately, this made no measurable difference to
prediction accuracy during cross-validation. This is proba-
bly because the dataset is very noisy.
4.2 Communication and Computation Time Esti-
mates
We also estimated the running time and communica-
tion costs of the cryptographic protocols based on recent
benchmarks for the primitives. Efﬁcient cryptographic tools
such as Crypto++ provide all the basic operations we need.
The size of the aggregate for the EachMovie dataset is
8×1648 = 13184 array elements, each element being a pair
of ﬁeld elements. With El-Gamal encryption, typical ﬁeld
elements are 1024-bit integers, while for ECC they are 168-
bit integers. The total storage required for the EachMovie
aggregate is 3.4 MB for EG or 500 kB for ECC. Each user’s
encrypted gradient has the same size as the aggregate, but
adding ZKPs to the gradients increase their size to 15 MB
(EG) and 2.2 MB (ECC).
There are several steps with complexity O(km log n) in
the protocol, but the dominant step in terms of constants is
step 2. To derive the cost of this step, we pick a typical value
of n = 105, which was the case for the Eachmovie dataset.
We set α = 0.8 as before. Picking an error probability for
checking of 10−6 allows us to compute the size of the ran-
dom sample nr = 300 from equation 3. The total amount
of communication per client during step 2 is the product of
the ZKP size given above by the redundancy nr. That takes
the total communication per client to 4 GB (EG) or 600 MB
(ECC).
To
determine
running
times,
we
tookit
use
from
for
the
CRYPTO++
benchmarks
www.eskimo.com/˜weidai/benchmarks.html.
Their experiments show that EG 1024-bit exponentiations
take approximately 10ms. Checking a ZKP as per appendix
II requires 11 exponentiations. Multiplying these numbers
by the number of proofs to check gives a total time of
13k×300×11×10ms which comes to about 50k seconds,
or 15 hours. The times for ECC are very similar.
These times and communications totals are large, but
even without improvement it should be feasible to run one
round of the protocol over several days as a background pro-
cess. Since the user ratings data are changing slowly, a few
days latency does not diminish the value of the aggregate.
Finally, the local storage demands of the protocol are
quite modest. A client need only work on a single copy
of a gradient or the aggregate at a time. Including ZKPs,
local storage of 10-50MB should be enough.
5 Statistical Vulnerabilities
While the scheme we described gives good data hiding
in a cryptographic sense (beyond disclosure of A), there is
still the potential for leakage of information. Such leakage
may be “static” or “dynamic” arising respectively from one
snapshot of the aggregate (static leakage), or from several
snapshots of the aggregate over time (dynamic leakage). We
discuss static leakage ﬁrst.
5.1 Static Leakage
We have treated the entire aggregate A as public data be-
cause our scheme for generating ratings (section 2.1) allows
the aggregate A to be constructed from a sufﬁcient number
of queries. So as long as a recommendation service is run-
ning on a model A, that model can be extracted through the
query interface. This is also true of the SVD CF scheme
published in [14]. The positive aspect of this is that min-
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
9
ing the query interface will only reveal information about
the model A, and not the underlying data. In order to avoid
overﬁtting, the model A is at least a 10-fold compression
(size measured as number of elements) of the original rat-
ings data. By adding a small amount of noise to each rating,
we can achieve a similar compression in an information-
theoretic sense. Typical compression ranges from 10-100
times. So even though it is easy to access A, the amount of
information about an individual user’s ratings is very lim-
ited, at least in an average sense. Most of the original in-
formation has simply been lost. But we must guard against
concentration of the information.
Although the aggregate includes data from many individ-
uals, some items may have been rated by just a few individ-
uals, and those items can be correlated with others using the
SVD data. For instance, if A encoded ratings of web sites
based on user visits, personal web sites would leak informa-
tion because their owners frequent them more than anyone
else. Other sites that correlate strongly with a personal site
are strong candidates to have been visited by the owner of
the site. Highly selective data such as personal web site vis-
its should be ﬁltered out from a scheme like this, as their
potential for leaking information is too great. We assume
that users are able to exclude any chosen site or locations
from their data, and that the system advises them to do so.
The second source of static leakage is sites that have
been rated by very few users. If an item has very few raters,
correlations between this item and others will disclose much
information about those raters’ choices. It is therefore de-
sirable to remove items with few raters from the aggregate.
A second reason for doing this is that extrapolated ratings
for such an item are likely to be inaccurate. The accuracy
of ratings of an item will be quite poor unless the number
of raters of that item is larger than the dimension of the lin-
ear model. If there are fewer, then there is not enough in-
formation to localize the item in the k-dimensional ratings
space. To deal with this, we suggest using a dynamically-
maintained “frontier” of items.
5.2 The Frontier
As well as the model A, we employ an integer-valued
vector F called the frontier. For elements in the frontier,
we maintain only a count of the number of users that have
rated them, not a model of user ratings. So let Fi be the
count of the number of users who have rated item i. The
set of items in the frontier F is typically much larger than
the set of items modeled in A. For instance, if F contains k
times as many items as A, then the vector F and the matrix
A will both contain km elements. With easy extensions to
the protocol we described in section 4, the counts in F can
all be maintained without disclosing user data. Then the set
of items actually handled in the aggregate A at each iter-
ation would be the subset of the m most frequently-rated
items from among the items counted in F . It would be an
even smaller subset if there are fewer than m items whose
count lies above a cardinality threshold (e.g. 2k) for accu-
racy purposes. In this way, A would only model ratings of
reasonably popular items (items with at least 2k raters).
As well as protecting privacy and avoiding inaccurate ex-
trapolations, this scheme allows a much larger set of items
to be handled by the system with a small impact on storage
and computation. For instance, for the Eachmovie dataset
with 1600 items and k = 20, maintaining a frontier with
km = 32000 items would only double the storage needed,
and less than double the computation, compared to the basic
protocol. Given the typically Zipf-like distributions of num-
ber of raters of items, most of the items in the frontier will
have very few raters, and would not meet the cardinality
threshold. Thus we could not provide accurate extrapola-
tions for them. We can recognize this fact from the values
in F , and advise the user of it.
5.3 Static Leakage in other CF systems
First of all, we note that the SVD scheme described in
[14] has quite similar properties to ours. Namely, it pro-
vides high compression of the original data, and therefore
good protection of user data if we guard against the two
“information concentration” mechanisms described above.
Like ours, it is straightforward to construct the linear model
from a sufﬁcient number of queries with [14].
It is more complicated to analyze other schemes. But
schemes which do not create an intermediate model like
ours are probably very dangerous. For instance, Pearson
correlation [7] and personality diagnosis [10] use the en-
tire user dataset to generate new recommendations. What’s
more, Pearson correlation makes use of a subset of “neigh-
bors” of the current user who have rated several of the same
items. The neighbor subset may be extremely small if the
querying user has rated only a few items so far. Pearson
schemes may simply refuse to return a rating if the neigh-
bor set is empty or too small. An adversay can easily use
this to advantage by choosing their number of rated items
so that it is just large enough to avoid a “no ratings” mes-
sage. That means there are just enough items to give an ad-
equate neighbor set, but this neighbor set will be very small,
and the ratings the adversary sees will be a weighted aver-
age of that very small set of neighbors. It is easy to come
up with artiﬁcial (and unrealistic) datasets where the entire
user dataset can be extracted via queries. Just how well one
can do at extracting information from realistic datasets is a
matter of some concern, since memory-based methods are
in use in some real websites today.
So in summary, schemes based on low-dimensional lin-
ear models of ratings data (e.g. SVD) offer quite good pro-
tection against static leakage of individual information. For
these methods, it makes no difference whether the model
is exposed directly, or only via queries. For memory-based
methods, there is no intermediate model that limits the in-
formation leakage. The potential for leakage via query min-
ing for such methods appears to be severe.
5.4 Dynamic Leakage
The iterative least-squares scheme makes repeated use
of user data. Suppose a user contributes to one iteration but
not the next. There will be slight numerical differences in
the gradient which may not mask the difference caused by
that user. The best defence against this problem is to add
more randomness. We tested a modiﬁcation of the numeri-
cal method where each user tosses a coin to decide whether
to contribute their actual gradient, or a zero vector at each
iteration. As we noted earlier, the iterative method still con-
verges with this disturbance. Such an approach should make
it very difﬁcult for an adversary to isolate individual data
by “snifﬁng” the changes in A over time. This method of
randomization is valid wrt the SVD calculation, because it
amounts to a sub-sampling of the dataset. Other random-
ization methods, such as additive noise, do not have this
property3
6 Discussion
An important pragmatic issue with our scheme is the
management of the recommender community. In order to
succeed, this scheme must have a majority of honest clients
and tallyers. That implies some authentication of the mem-
bers. Without it, a malicious user could join a community
masquerading as many individuals. Ideally, the community
might be formed from individuals who actually know each
other. This can be extended to include individuals that are
vouched for by a core community member, etc. The design
implications are subtle and we have not explored them. The
next most reliable method would be to restrict membership
to a known community. For instance, campus or company
email might be used in the key setup phase, ensuring that
each user has a valid email address within the organization.
Beyond social and organizational bounds, community setup
and maintenance is more problematic. There are a variety of
creative solutions, e.g. having individuals ﬁll out surveys,
or receive a password by phone, etc., but these are beyond
the scope of our present work. We believe that this problem
is a basic one in peer-to-peer computing, and is e.g. being
studied in the development of the Java peer-to-peer API,
JXTA.
3To see this, imagine the dataset is drawn from an elliptical gaussian
distribution. Adding sufﬁcient noise will produce a spherical gaussian.
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
10
The last question is whether this kind of key-sharing
among peers is a good model of security. After reﬂecting
on this work for some time, we believe that the model is
not only acceptable, but is very good in many respects. The
goals of any privacy scheme should be to protect individuals
from unreasonable scrutiny or search without cause. At the
same time, it is not socially desirable that criminals be pro-
tected from scrutiny once guilt has been established or there
is probable cause. A scheme which provides perfect data
hiding also provides criminals with effective means to com-
municate and perhaps perform other kinds of distributed
computation. A key escrow scheme like this one places the
ability to decrypt information in the hands of individuals. If
a single individual or agency has this power, then the pos-
sibilities for abuse are many.
If a few individuals within
an organization have this capability, the protections are bet-
ter, but there is still the prospect of coercion by outsiders,
or communication of these few powerful keys to others. On
the other hand, escrow in the hands of many places the com-
munity’s privacy in the hands of the community. They can
also make a judgement about using their keys to decrypt pri-
vate data in situations where there is a compelling reason to
do so, such as suspicion of criminal behavior. Coercion of
a large community would be impractical in most situations.
Any abuse from within the community would be highly vis-
ible to other members, which is itself a strong deterrent.
To summarize, we described in this paper a practical
and useful example of computation on encrypted data. Our
method reduces a non-linear computation (SVD) to a series
of linear steps. It can be implemented fully peer-to-peer. We
showed by experiment that the algorithm compares well in
accuracy and speed with traditional collaborative ﬁltering
methods. We believe that it points the way to a class of
practical algorithms that work on encrypted data.
References
[1] M. Ben-Or, S. Goldwasser, and A. Wigderson. Com-
pleteness theorems for noncryptographic fault-tolerant dis-
tributed computations.
In 20th ACM STOC, pages 1–10,
1988.
[2] Breese, Heckermen, and Kadie. Empirical analysis of pre-
dictive algorithms for collaborative ﬁltering. Technical re-
port, Microsoft Research, October 1998.
[3] R. Cramer and I. Damg˚ard. Zero-knowledge for ﬁnite ﬁeld
arithmetic. or: Can zero-knowledge be for free? In Proc.
CRYPTO ’98, volume 1462, pages 424–441. Springer Verlag
LNCS, 1998.
[4] R. Cramer, I. Damg˚ard, S. Dziembowski, M. Hirt, and
T.Rabin. Efﬁcient multiparty computations secure against
an adaptive adversary. In Proc. EuroCrypt ’99, pages 311–
326. Springer-Verlag LNCS 1592, 1999.
[5] R. Cramer, R. Gennaro, and B. Schoenmakers. A secure
and optimally efﬁcient multi-authority election scheme. Eu-