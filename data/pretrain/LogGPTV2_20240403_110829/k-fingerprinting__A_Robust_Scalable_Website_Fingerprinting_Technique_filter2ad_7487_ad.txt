a monitored training set of standard web page trafﬁc to
this distinguishability. A standard web page over Tor is
more likely to be confused with another standard web
page than a Tor hidden service.
Comparison with Kwon et al. [19] hidden services re-
sults. For comparison we ran k-ﬁngerprinting on the data
set used in the Kwon et al. study on ﬁngerprinting hid-
den services. This data set simulated a client connecting
to a hidden service. The data set consists of 50 instances
for each of 50 monitored hidden services and an unmon-
itored set of 950 hidden services. When training on 100
of the unmonitored pages they report attack accuracy of
0.9 TPR and 0.4 FPR. k-ﬁngerprinting achieved a simi-
lar true positive rate but the FPR is reduced to 0.22. This
FPR reduction in comparison with Kwon et al. continued
regardless of the amount of data used for training.
9 Attack evaluation on DSNorm
Besides testing on DSTor, Wang et al. [39] data set and
the Kwon et al. [19] data set we tested the efﬁcacy of
k-ﬁngerprinting on DSNorm. This allows us to estab-
lish how accurate k-ﬁngerprinting is over a standard en-
crypted web browsing session or through a VPN.
9.1 Attack on encrypted browsing sessions
An encrypted browsing session does not pad packets to a
ﬁxed size so the attacker may extract the following fea-
tures in addition to time features:
• Size transmitted. For each packet sequence we ex-
tract the total size of packets transmitted, in addition,
we extract the total size of incoming packets and the
total size of outgoing packets.
• Size transmitted statistics. For each packet sequence
we extract the average, variance, standard deviation
Figure 5: Attack accuracy on DSTor with Alexa moni-
tored set.
Figure 6: Attack accuracy on DSTor with Tor hidden ser-
vices monitored set.
and maximum packet size of the total sequence, the
incoming sequence and the outgoing sequence.
Apart from this modiﬁcation in available features, the
attack setting is similar: An attacker monitors a client
browsing online and attempts to infer which web pages
they are visiting. The only difference is that browsing
with the Transport Layer Security (TLS) protocol, or Se-
cure Sockets Layer (SSL) protocol, versions 2.0 and 3.0,
exposes the destination IP address and port. The attack is
now trying to infer which web page the client is visiting
from the known website16.
The attacker monitors 55 web pages; they wish to
know if the client has visited one of these pages. The
client can browse to any of these web pages or to 7000
other web pages, which the attacker does not care to clas-
sify other than as unmonitored. We train on 20 out of the
30 instances for each monitored page and vary the num-
ber of unmonitored pages on which we train.
Despite more packet sequence information to exploit,
the larger cardinality of world size gives rise to more
16Note that the data sets are composed of trafﬁc instances from some
websites without SSL and TLS, as well as websites using the protocols.
We expect our experiment conditions are much larger than the number
possible web pages an attacker may wish to ﬁngerprinting from a stan-
dard website.
1196  25th USENIX Security Symposium 
USENIX Association
10
Table 5: Attack results with packet size features for a
varying number of unmonitored training pages.
Training pages TPR
0
2000
4000
6000
0.95± 0.01
0.90± 0.01
0.87± 0.02
0.86± 0.01
FPR
0.850± 0.010
0.010± 0.004
0.004± 0.001
0.005± 0.002
BDR
0.081
0.908
0.976
0.990
Table 6: Attack results without packet size features for a
varying number of unmonitored training pages.
Training pages TPR
0
2000
4000
6000
0.90± 0.01
0.83± 0.01
0.81± 0.02
0.80± 0.02
FPR
0.790± 0.020
0.009± 0.001
0.006± 0.001
0.005± 0.001
BDR
0.082
0.910
0.961
0.989
Removing packet size features reduces the TPR by over
0.05 and increases the FPR by 0.001. Clearly packet size
features improve our classiﬁer in terms of correct identi-
ﬁcations but do not decrease the number of unmonitored
test instances that were incorrectly classiﬁed as a moni-
tored page. Despite the difference in FPR when includ-
ing packet size information, the BDR is similar, suggest-
ing that BDR is dominated by the amount of information
that can be trained upon.
Closed-World.
In the closed-world setting in which
the client can only browse within the 55 monitored web
pages k-ﬁngerprinting is 0.91, compared to 0.96 when
packet size features are available.
In the closed-world
setting attack accuracy improves by 5% when we include
packet size features.
10 Fine grained open-world false positives
on Alexa monitored set of DSTor
We observe that the classiﬁcation error is not uniform
across all web pages17. Some pages are misclassiﬁed
many times, and confused with many others, while others
are never misclassiﬁed. An attacker can leverage this in-
formation to estimate the misclassiﬁcation rate of each of
the web page classes instead of using the global average
misclassiﬁcation rate. A naive approach to this problem
would be to ﬁrst ﬁnd which ﬁngerprints contribute to the
many misclassiﬁcations and remove them. Our analysis
shows that the naive approach of removing “bad” ﬁnger-
prints that contribute to many misclassiﬁcations will ul-
timately lead to a higher misclassiﬁcation rate. Figure 9
shows the 50 ﬁngerprints that cause the most misclassi-
ﬁcations, and also shows for those same ﬁngerprints the
number of correct classiﬁcations they contribute towards.
17See additional evidence in Appendix B.
Figure 7: BDR for hidden services monitored set (above)
and Alexa monitored set (below).
Figure 8: Attack results for 2000 unmonitored training
pages while varying the number of ﬁngerprints used for
comparison, k, over 10 experiments.
opportunities for incorrect classiﬁcations. The attack
achieves a TPR of 0.87 and a FPR of 0.004. We achieved
best results when training on 4000 unmonitored web
pages. Table 5 reports results for training on different
numbers of unmonitored web pages, with k = 2. Fig-
ure 8 shows our results when modifying the number of
ﬁngerprints used (k) and training on 2000 unmonitored
pages. We ﬁnd that altering the number of unmonitored
training pages decreases the FPR while only slightly de-
creasing the TPR. This mirrors our experimental ﬁndings
from DSTor and the Wang et al. data set.
9.2 Attack without packet size features
DSNorm was not collected via Tor and so also contains
packet size information. We remove this to allow for
comparison with DSTor and the Wang et al. data set
which was collected over Tor. This also gives us a
baseline for how much more powerful k-ﬁngerprinting is
when we have additional packet size features available.
We achieved a TPR of 0.81 and FPR of 0.005 when train-
ing on 5000 unmonitored web pages. Table 6 shows
our results at other sizes of training samples, with k=2.
USENIX Association  
25th USENIX Security Symposium  1197
11
Figure 9: The ﬁngerprints that lead to the most misclas-
siﬁcations and the correct classiﬁcations they contribute
towards. Training on 2% of unmonitored pages with k=3.
Figure 10: Rates for training on 1000 unmonitored
pages, testing on 1000, and comparison when training
on the full 2000 unmonitored pages and testing on the
remaining 98000 unmonitored pages in DSTor, k=3.
As we can see nearly all “bad” ﬁngerprints actually con-
tribute to many correct classiﬁcations. One may think it
may still be beneﬁcial to remove these ﬁngerprints as the
cumulative sum of misclassiﬁcations outweigh the num-
ber of correct classiﬁcations. This removal will then pro-
mote ﬁngerprints that are further away in terms of Ham-
ming distance from the ﬁngerprinting that is being tested,
which will lead to a greater number of misclassiﬁcations.
Instead an attacker can use their training set of web
pages to estimate the TPR and FPR of each web page
class, by splitting the training set in to a smaller train-
ing set and validation set. Since both sets are from the
original training set the attacker has access to the true la-
bels. The attacker then computes the TPR and FPR rates
of each monitored class, this is used as an estimation for
TPR and FPR when training on the entire training set
and testing on new trafﬁc instances. More speciﬁcally
we split, for the monitored training set of 70 instance for
each of the Alexa top 55 web pages, into smaller training
sets of 40 instances and validation sets of 30 instances.
This is used as a misclassiﬁcation estimator for the full
monitored training set against the monitored test set of
30 instances per class. Similarly we split the unmoni-
tored training in half, one set as a smaller training set
and the other as a validation set.
Figure 10 shows the TPR and FPR estimation accu-
racy for 2000 unmonitored training pages. Monitored
classes are ﬁrst ordered from best to worst in terms of
their classiﬁcation accuracy. Even with a small unmoni-
tored training set of 2000 web pages, which is then split
in to a training set of 1000 web pages and a validation set
of 1000 web pages, an attacker can accurately estimate
the FPR of the attack if some of the monitored classes
were removed. For example, using only the best 20 mon-
itored classes (in terms of TPR), an attacker would esti-
mate that using those 20 classes as a monitored set, the
Figure 11: Rates for training on 8000 unmonitored
pages, testing on 8000, and comparison when training
on the full 16000 unmonitored pages and testing on the
remaining 84000 unmonitored pages in DSTor, k=3.
FPR would be 0.012. Using the entire data set we see that
the true FPR of these 20 classes is 0.010; the attacker has
nearly precisely estimated the utility of removing a large
fraction of the original monitored set.
There is a small difference between estimated and the
actual FPR in both Figures 10 and 11. There is little
beneﬁt in training more unmonitored data if the attacker
wants to accurately estimate the FPR; Figure 10 has a
similar gap between the estimated FPR and true FPR
when compared to Figure 11.
It is evident even with
a small training set, an attacker can identify web pages
that are likely to be misclassiﬁed and then accurately
calculate the utility of removing these web pages from
their monitored set. Due to the overwhelmingly large
world size of unmonitored web pages the BDR of Fig-
ure 10 does not grow dramatically with the removal of
web pages that are likely to be misclassiﬁed; using the
entire monitored set the BDR is 0.33, removing half of
the monitored web pages the BDR is 0.35.
1198  25th USENIX Security Symposium 
USENIX Association
12
11 Attack Summary & Discussion
Attack Summary. Best attack results on data sets were
achieved when training on approximately two thirds of
the unmonitored web pages. Despite this, results from
DSTor show that an attacker can achieve a very small
false positive rate while only training on 2% of the un-
monitored data. Training on 2% of 100,000 unmoni-
tored web pages greatly reduces the attack set up costs
while only marginally reducing the accuracy compared
to training on more data, providing a realistic setting un-
der which an attack could be launched. Results on all
data sets also suggest that altering k, the number of ﬁn-
gerprints used for classiﬁcation, has a greater inﬂuence
on accuracy than the number of training samples18.
k-ﬁngerprinting is robust; our technique achieves the
same accuracy regardless of the type of monitored set
or the manner in which it was collected (through Tor or
standard web browsers). The monitored set in the Wang
et al. [39] data set consists of real world censored web-
sites, the Kwon et al. [19] monitored set consist of Tor
hidden services and the DSTor/Norm monitored sets were
taken from Tor hidden services and top Alexa websites.
We do see a reduction in FPR when the target monitored
set are Tor hidden services due to the distinguishability
between the hidden services and unmonitored standard
web pages.
We also highlight the non-uniformity of classiﬁcation
performance: when a monitored web page is misclas-
siﬁed, it is usually misclassiﬁed on multiple tests. We
show that an attacker can use their training set to esti-
mate the error rate of k-ﬁngerprinting per web page, and
select targets with low misclassiﬁcation rates.
Computational Efﬁciency. k-ﬁngerprinting is more ac-
curate and uses fewer features than state-of-the-art at-
tacks. Furthermore k-ﬁngerprinting is faster than cur-
rent state-of-the-art website ﬁngerprinting attacks. On
the Wang et al. data set training time for 6,000 monitored
and 2,500 unmonitored training pages is 30.738 CPU
seconds on an 1.4 GHz Intel Core i5z. The k-NN attack
[39] has training time per round of 0.064 CPU seconds
for 2500 unmonitored training pages. For 6,000 rounds
training time is 384.0 CPU seconds on an AMD Opteron
2.2 GHz cores. This can be compared to around 500 CPU
hours using the attack described by Cai et al. [7]. Testing
time per instance for k-ﬁngerprinting is around 0.1 CPU
seconds, compared to 0.1 CPU seconds to classify one
instance for k-NN and 450 CPU seconds for the attack
described by Cai et al. [7].
Discussion. Website ﬁngerprinting research has been
criticized for not being applicable to real-world scenarios
18Figure 17 illustrates that compared to training on a small number
of monitored instances increasing the size of the monitored training set
only incrementally increases accuracy.
[17, 29]. We have shown that a website ﬁngerprinting at-
tack can scale to the number of trafﬁc instance an attacker
may sample over long period of time with a high BDR
and low FPR. However, we did not consider the cases
where background trafﬁc may be present, for example
from multitab browsing, or the effect that short-lived
websites will have on our attack. Gu et al. [15] show
in their work that a simple Naive-Bayes attack achieves
highly accurate results even when a client browses in
multiple tabs. Wang and Goldberg [36] also show that
website ﬁngerprinting is effective in practical scenarios.
With no prior attack set-up to tailor to a multi-tab brows-
ing session our attack was able to classify nearly 40% of
monitored pages correctly when the decoy defense was
employed.
Website content rapidly changes which will negatively
affect the accuracy of a website ﬁngerprinting attack
[17]. As the content of a website changes so will the
generated packet sequences, if an attacker cannot train
on this new data then an attack will suffer. However
we note that an attack will suffer from the ephemeral
nature of websites at different rates depending on the
type of website being monitored. For example, an at-
tack monitoring a news or social media site can expect
a faster degradation in performance compared to an at-
tack monitoring a landing page of a top 10 Alexa site
[1]. Also note Tor does not cache by default, so if in the
realistic scenario where an attacker wanted to monitor
www.socialmediawebsite.com a client would be forced to
navigate to the social media website landing page, which
is likely to host content that is long lived and not sub-
ject to change. The problem of content change is weak-
ened when ﬁngerprinting Tor hidden services. As show
by Kwon et al. [19] hidden pages show minimal changes
in comparison to non-hidden pages, resulting in devastat-
ingly accurate attacks on hidden services that can persist.
12 Conclusion
We establish that website ﬁngerprinting attacks are a se-
rious threat to online privacy. Clients of both Tor and
standard web browsers are at risk from website ﬁnger-
printing attacks regardless of whether they browse to hid-
den services or standard websites. k-ﬁngerprinting im-
proves on state-of-the-art attacks in terms of both speed
and accuracy: current website ﬁngerprinting defenses ei-
ther do not defend against k-ﬁngerprinting or incur very
high bandwidth overheads. Our world size is an order
of magnitude larger than previous website ﬁngerprinting
studies, and twice as large in terms of unique website
than Panchenko et al.’s recent work [28]. We have val-
idated our attack on four separate datasets showing that
it is robust and not prone to overﬁt one dataset, and so is