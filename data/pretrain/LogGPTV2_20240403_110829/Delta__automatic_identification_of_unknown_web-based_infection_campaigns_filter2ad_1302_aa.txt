title:Delta: automatic identification of unknown web-based infection campaigns
author:Kevin Borgolte and
Christopher Kruegel and
Giovanni Vigna
Delta: Automatic Identiﬁcation of Unknown
Web-based Infection Campaigns
Kevin Borgolte, Christopher Kruegel, Giovanni Vigna
Department of Computer Science
University of California, Santa Barbara
Santa Barbara, California, United States of America
ABSTRACT
1 INTRODUCTION
kevinbo,chris,PI:EMAIL
Identifying malicious web sites has become a major chal-
lenge in today’s Internet. Previous work focused on detecting
if a web site is malicious by dynamically executing JavaScript
in instrumented environments or by rendering web sites in
client honeypots. Both techniques bear a signiﬁcant evaluation
overhead, since the analysis can take up to tens of seconds or
even minutes per sample.
In this paper, we introduce a novel, purely static analy-
sis approach, the ∆-system, that (i) extracts change-related
features between two versions of the same website, (ii) uses
a machine-learning algorithm to derive a model of web site
changes, (iii) detects if a change was malicious or benign, (iv)
identiﬁes the underlying infection vector campaign based on
clustering, and (iv) generates an identifying signature.
We demonstrate the eﬀectiveness of the ∆-system by eval-
uating it on a dataset of over 26 million pairs of web sites by
running next to a web crawler for a period of four months. Over
this time span, the ∆-system successfully identiﬁed previously
unknown infection campaigns.
Including a campaign that
targeted installations of the Discuz!X Internet forum software
by injecting infection vectors into these forums and redirecting
forum readers to an installation of the Cool Exploit Kit.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: Gen-
eral—Security and protection; D.4.6 [Software Engineer-
ing]: Security and Protection—Invasive software (malware);
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval—Clustering, Information ﬁltering, Se-
lection process
Keywords
computer security; web-based malware; malware detection;
infection vector identiﬁcation; infection campaigns; clustering;
trend detection; web dynamics
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise,
or republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516725.
The rapid growth and widespread access to the Internet, and
the ubiquity of web-based services make it easy to communicate
and interact globally. However, the software used to implement
the functionality of web sites is often vulnerable to diﬀerent
attack vectors, such as cross-site scripting or SQL injections,
and access policies might not be properly implemented. An
attacker can exploit these server-side vulnerabilities to inject
malicious code snippets, called infection vectors, which, in turn,
attack visitors through drive-by install or download attacks.
Drive-by install and download attacks try to exploit client-side
vulnerabilities to download or install malware, or lure the user
into installing malware. If an attacker ﬁnds a server-side vul-
nerability that aﬀects multiple web sites (possibly thousands),
he can automate the exploitation, search for other vulnerable
web sites, and launch a carefully crafted infection campaign
in order to maximize the number of potential victims.
Recent reports by the security company Sophos [1, 2] show
that in 2012 over 80% of all web sites attacking users were in-
fected legitimate web sites, such as those of trade associations,
nightclubs, television companies or elementary schools. All of
these web sites had been altered, in one way or another, to at-
tack visitors. In another case, in early 2013, web sites hosting
documentation for software developers were modiﬁed to serve
carefully crafted infection vectors that exploited client-side
vulnerabilities, which were then leveraged as the ﬁrst stepping
stone in sophisticated attacks against Twitter [3], Facebook’s
engineering team [4], and Apple [5].
Major challenges in detecting infection vectors are that web
sites become more and more dynamic and that their static
content changes regularly, i.e., the underlying infection vec-
tor might not be clearly visible to analysis tools, or even to
well-trained human security analysts. Adding new content to
the web site, showing diﬀerent, personalized advertisements,
or even comments left by visitors are legitimate modiﬁca-
tions. Yet, these modiﬁcations force the user to reevaluate
the maliciousness of the web site, either through an automatic
detection system or by manually inspecting any new content
prior to its inclusion into the web site. Unwanted modiﬁcations
to a web site on the other hand, i.e., changes from which a user
might want himself to be protected, include defacements or the
insertion of exploit code to infect visitors of the web site with
malware. Previous work in the area of web evolution [6–10]
suggests that web sites do not change randomly, but that they
evolve constantly through small changes, and, if one takes into
account personalized advertisements, a change might happen
at every visit, which, in turn, makes it necessary to analyze
the web sites on each visit.
109The current state of the art in protecting a user from ma-
licious content is mainly realized through blacklists, which are
queried before the web site is rendered or retrieved by the
web browser. The Google Safe Browsing list [11] is likely the
most prominent example. By deﬁnition, blacklists are reactive,
which is an undesirable property for any protection mechanism
because a malicious web site can potentially stay undetected
for an extended period of time. Once a web site is blacklisted,
its operator must go to great lengths to remove his/her web site
from the blacklist, although it might have become benign. Such
a removal process can take a frustrating amount of time since
it is often subject to some form of veriﬁcation that the web site
is now benign, a process that might not happen immediately.
More important, however, is that each web site infected as part
as an infection campaign needs to be identiﬁed and added to the
blacklist even though the web sites attack visitors in the same,
well-known way. Clearly, a proactive approach is preferable
for both unknown and known infection vectors. On the other
hand, scanning a web site proactively with online analyzer sys-
tems [12–14] is computationally very expensive, and would in-
troduce delays up to multiple seconds per web site. Since such
a delay is undesirable, it is unlikely that such a proactive ap-
proach would be deployed in a general setting, or that it would
ﬁnd its way into current browsers as a protection mechanism.
It is important to mention that, generally, the same infection
vector is reused by an attacker and spread among a multitude of
diﬀerent web sites to maximize its impact; however, some parts
of the infection vector might be randomized. Often, the in-
fected web sites are from a single community, e.g., in a targeted
attack on this community, they employ the same underlying
software stack, or they share a web server that was attacked.
Recent examples include attacks targeting installations of the
Apache web server to replace the web server’s executable with
the backdoor “Linux/Cdorked.A” [15, 16], which injects code
to redirect visitors of the web site to exploit pages. These com-
promised web sites are not necessarily targeted, they usually
follow a simple pattern: the infection vector was inserted in the
same or in a very similar way. Be it, as previously mentioned,
through improper access control, exploited vulnerabilities in a
web framework or application used by all web sites. Being able
to identify an infection vector, instead of just detecting that the
web site is malicious, can provide important feedback since the
initial cause of the infection vector can be investigated much
more easily due to additional information, such as common-
alities in diﬀerent observations of the same infection vector.
To overcome the limitations of current approaches mainly
based on dynamic analysis of web sites, we introduce the
∆-system to identify malicious activity in a web site based
on static analysis of the diﬀerences between the current and
previous versions of the web site. We cluster these diﬀerences,
determine if the introduced or removed elements are associated
with malicious behavior, we identify the infection campaign it
belongs to, pinpoint the actual infection vector, and automat-
ically generate an identifying signature that can be leveraged
for content-based protection.
The main contributions of this paper are the following:
• We introduce the ∆-system, which is based on a novel ap-
proach to statically analyze and detect web-based infection
vectors, and which identiﬁes infection campaigns based on
features associated with modiﬁcations observed between
two versions of a web site.
• We develop a tree diﬀerence algorithm that is resistant to
tiny changes, such as typographical corrections or the small
evolutionary modiﬁcations a web site undergoes.
• We develop a set of modiﬁcation-motivated similarity mea-
sures to model the concepts of inserting and removing ma-
licious behavior into and from a web site.
• We evaluate the ∆-system on a large scale dataset, con-
taining 26 million unique pairs of web sites, to show its
applicability in real-world scenarios in terms of infection
campaign detection and identiﬁcation capabilities.
2 ∆-SYSTEM DESIGN
The ∆-system, instead of trying to solve the problem of
deciding if a web site is malicious or benign provides a solution
to the search problem of ﬁnding new infection campaigns and
identifying similar, known infection campaigns. Nonetheless
we are still interested in deciding if a web site’s current behav-
ior is malicious or benign. Instead of analyzing web sites in
their entirety, the ∆-system investigates only the diﬀerence
between two versions of the same web site.
The main idea of the ∆-system is to identify if the change
made to a web site altered the behavior of the web site, i.e.,
if we can be certain that the new version of the web site is
malicious or benign, by investigating if the modiﬁcations are
similar to already observed ones, such as modiﬁcations associ-
ated with an ongoing infection campaign. In order to identify
the changes that were made to a web site, we need a base
version, i.e., an older version of the same web site.
The analysis process of our system is described hereinafter,
followed by a discussion on potential uses of our system, and
the impact of deploying the ∆-system.
2.1 Analysis Process
The ∆-system’s analysis process follows a simple four-step
process, which is shown in Figure 1, and whose steps are:
1. Retrieval and normalization of the web site.
2. Similarity measurement with respect to a base version.
3. Cluster assignment of the similarity vector.
4. Generation of the identifying signature.
Evidently, a base version of a web site has to be available. In
the case that a local base version does not exist, however, we
might still be able to retrieve an older version through web
archives, such as the Internet Archive1 or a web cache provided
by a search engine. This makes our approach applicable for
web sites that are visited rarely and were no local base version
is kept, if we accept the overhead to retrieve the base version
from a remote archive. While this might seem counter-intuitive
because of the potentially large time diﬀerence between the
archived and current version, we show in our evaluation that
this is indeed a possible alternative.
Following this brief overview, we discuss the important steps
of the analysis process in more detail. First, normalization of
a web site; second, how the similarity to the base version is
measured; third, how the identifying signature is generated.
2.1.1 Retrieval and Normalization
First, we retrieve the current version of a web site, for
instance the web site a user requested. Then, after we have re-
trieved the source code of that web site, excluding all external
references, such as included scripts or frames, we perform multi-
ple normalization steps: we normalize capitalization of all tags,
we reorder attributes of each tag and discard invalid attributes,
and we normalize the quotation of an attribute’s value. We
perform this normalization step to ensure that functional equiv-
alent tags are treated equally during our evaluation, and that
changes such as changing the capitalization of a tag or switch-
ing from single to double quotes do not aﬀect our ﬁnal results.
1Internet Archive, http://www.archive.org
110Figure 1: Analysis pipeline of the ∆-system.
2.1.2 Similarity Measurement and Clustering
Following these normalization steps, we measure the sim-
ilarity to an already known (and normalized) base version.
Measuring the similarity between two versions of the same
web site in a meaningful way is non-trivial. The ∆-system
ﬁrst performs unordered tree-to-tree comparison via a novel
algorithm that we introduce in Section 3. The algorithm ex-
tracts the nodes (or tags; subsequently, we use both terms
interchangeably) from the Domain Object Model (DOM) tree
of a web site that are diﬀerent between base and current ver-
sion. Second, based on the extracted nodes, we leverage a
variety of diﬀerent features to extract meaningful information
from the two versions (described in detail in Section 4). The
system then tries assigning these feature vectors to a cluster,
or detects them as outliers, if they are not similar to any
previously-observed modiﬁcations. Each diﬀerent tag type,
e.g.,  or , is treated separately, i.e., each type
is assigned its own feature space; we do not project two tags of
a diﬀerent type into the same feature space. Additionally, due
to the diﬀerent nature of our features, where diﬀerent distance
metrics are essential for accurate cluster assignment, we per-
form consensus clustering for diﬀerent groups: binary features,
absolute and relative features are all treated as separate clus-
tering instances. The cluster assignment and outlier detection
process then distinguishes between three diﬀerent cases:
• Assignment to an existing cluster:
– Insertion or removal of an infection vector, if the cluster
corresponds to a known infection campaign.
– Legitimate modiﬁcation, e.g., a version update of a li-
brary or the insertion of Facebook’s like button, if the
cluster does not correspond to an infection campaign.
• Detection as an outlier:
– Potentially the start of a new infection campaign, if
malicious behavior was inserted.
– Potentially the end of a running infection campaign, if
malicious behavior was removed.
– A modiﬁcation that is not of primary interest to us, such
as a new article, template modiﬁcations, or a redesign
of the web site.
• Formation of a new cluster (the similarity vector we are
clustering and other vectors that are close, which were out-
liers before, put the number of total vectors in this area of
the feature space above the threshold to form a new cluster,
i.e., we observed the number of the same modiﬁcation in the
wild that we require to constitute a trend, c.f. Section 5.1):
– New infection campaign, if the node was inserted and
is associated with malicious behavior.
– End of an infection campaign, if the node was removed
and is associated with malicious behavior.
– Legitimate modiﬁcation, e.g., an update to a new, bleeding-
edge version of a library or the content-management
system used, such as Wordpress.
Upon cluster assignment of the similarity vector, we output
the associated cluster, i.e., the corresponding trend (subse-
quently, we use these terms interchangeably). For instance, an
infection campaign if the corresponding modiﬁcation inserted
or removed a known infection vector. Here, it is important to
note that the detected clusters do not discriminate between
removed and inserted nodes but treat them equally because
we do not leverage the notion of removal or insertion in the