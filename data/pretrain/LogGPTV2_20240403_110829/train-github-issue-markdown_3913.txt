    import torch
    torch.autograd.Variable(torch.LongTensor([18])) / 0.0625
    # Floating point exception (core dumped)
    torch.LongTensor([18]) / 0.0625
    #Traceback (most recent call last):
    #  File "", line 1, in 
    #  File ".../lib/python2.7/site-packages/torch/tensor.py", line 294, in __div__
    #    return self.div(other)
    #TypeError: div received an invalid combination of arguments - got (float), but expected one of:
    # * (int value)
    #      didn't match because some of the arguments have invalid types: (float)
    # * (torch.LongTensor other)
    #      didn't match because some of the arguments have invalid types: (float)
at `0.4.0a0+b608ea9`; related to #327 and maybe #5411
Probably the cause is that in the variable case, it casts the divisor as Long
and it triggers integer division by zero. But why only in the variable case?
Didn't test it after the tensor+variable merge, since don't want to migrate to
vNext before ECCV deadline :)