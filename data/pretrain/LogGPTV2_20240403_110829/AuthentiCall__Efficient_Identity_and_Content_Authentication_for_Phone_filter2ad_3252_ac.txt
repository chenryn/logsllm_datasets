phone network, the audio transmitted by a phone will
not be the same as the audio received.
In particular,
the audio received is practically guaranteed to not be
identical on a bit level to the audio sent by the phone.
This means that common data digest approaches like
cryptographic hashes will fail.
While the original phone system used analog trans-
mission of voice, it is now common in every telephone
network (landline, VoIP, cellular, etc.)
for speech to
be digitized and compressed using an audio codec.
At network boundaries, it is common for audio to be
decoded and recoded into a different codec (known as
transcoding). Codecs used in the phone network are
highly lossy and drastically distort the call audio, and
so have the potential to signiﬁcantly impact audio digest
performance. Because some phone systems (especially
cellular and VoIP) use lossy networks for transmission,
frames are routinely lost. For example, loss rates of 4%
are considered nominal for cellular voice [12].
These legitimate modiﬁcations caused by the phone
network must be distinguished from changes to audio
induced by an adversary. The following subsections
provide a description of the speech digests we use in
AuthentiCall and a thorough analysis of the performance
of these digests for telephone calls.
5.1 Construction and Properties
There are a number of constructions of speech digests,
and they all use the following basic process. First, they
compute derived features of speech. Second, they deﬁne
a compression function to turn the real-valued features
into a bit string. We use the construction of Jiao et al. [36]
called RSH. We chose this technique over others because
it provides good performance on speech at a low-bitrate,
among other properties. We note that the original work
did not evaluate the critical case where an adversary can
control the audio being hashed. Our evaluation shows
that RSH maintains audio integrity in this crucial case.
The construction also selects audio probabilistically; we
show in Appendix B that the digest indeed covers all
of the semantic content in the input audio. Finally, to
our knowledge we are the ﬁrst to use any robust speech
digest for an authentication and integrity scheme.
For space reasons, and because we do not claim the
design of the RSH digest as a research contribution, we
provide a detailed description of the actual computation
of an RSH digest in Appendix A. However, the remainder
of this subsection will provide details necessary for the
rest of this paper. RSH computes a 512-bit digest for each
1 second of audio, and the digest can be thought of as a
heavily compressed version of the audio in the call. The
digest is computed probabilistically using a keyed pseu-
dorandom number generator with a key derived during
the handshake (Section 4.2) in AuthentiCall. The prob-
abilistic nature of the digest ensures that digests of the
same phrase (e.g., “Hello”) differ and cannot simply be
replayed. Digests are computed by the caller and are re-
ceived and veriﬁed by the callee. The verifying party
computes the digest of the received audio and the Ham-
ming distance between the calculated and received di-
gests. Because degradation of audio over a phone call is
expected, digests will not match exactly. However, the
Hamming distance between two audio digests (equiva-
lent to the bit error rate (BER)) quantiﬁes the change in
the audio. By setting an appropriate threshold on BER,
maliciously modiﬁed audio can be detected.
USENIX Association
26th USENIX Security Symposium    581
Implementation and Evaluation
5.2
Now that we have seen how RSH digests are computed,
we can evaluate properties of RSH digests. This includes
effects of legitimate transformations and the results of
comparing digests of unrelated audio samples (as might
be generated by an adversary). We also describe how we
use digests to detect tampered audio.
We implement RSH using Matlab, and we deploy
it in our AuthentiCall prototype by using the Matlab
Coder toolbox to generate C code that is compiled as
an Android native code library. We use the TIMIT
audio corpus [30] which is a standard test dataset for
speech processing systems.
It consists of high-ﬁdelity
recordings of 630 male and female speakers reading 10
English sentences constructed for phonetic diversity.
Because RSH computes hashes of one second of audio,
we split the TIMIT audio data into discrete seconds of
audio corresponding to a unique section of audio from
a speaker and sentence. This resulted in 22,487 seconds
of unique audio.
Figure 6: These box plots show the distribution of
digests bit error rates as a result of various audio
degradations. These error rates are well below the rates
seen by adversarial audio, shown in Figure 7
5.2.1 Robustness
Robustness is one of the most critical aspects of our
speech digests, and it is important to show that these
digests will not signiﬁcantly change after audio under-
goes any of the normal processes that occur during a
phone call. These include the effects of various audio
encodings, synchronization errors in audio, and noise.
To test robustness, we generate modiﬁed audio from
the TIMIT corpus and compare the BER of digests of
standard TIMIT audio to digests of degraded audio. We
ﬁrst downsample the TIMIT audio to a sample rate of
8kHz, which is standard for most telephone systems.
We used the sox [5] audio utility for downsampling and
adding delay to audio to model synchronization error.
We also used sox to convert the audio to two common
phone codecs, AMR-NB (Adaptive Multi-Rate Narrow
Band) and GSM-FR (Groupe Sp´ecial Mobile Full-Rate).
We used GNU Parallel [67] to quickly compute these
audio ﬁles. To model frame loss behavior, we use a
Matlab simulation that implements a Gilbert-Elliot loss
model [32]. Gilbert-Elliot models bursty losses using a
two-state Markov model parameterized by probabilities
of individual and continued losses. We use the standard
practice of setting the probability of an individual loss
(p) and probability of continuing the burst (1− r) to the
desired loss rate of 5% for our experiments. We also use
Matlab’s agwn function to add Gaussian white noise at
a 30 decibel signal to noise ratio.
Figure 6 shows boxplots representing the distribution
of BER rates of each type of degradation tested. All
degradations show a fairly tight BER distribution near
the median with a long tail. We see that of the effects
Figure 7: This graph shows the histogram and kernel
density estimate of digest of adversarial audio on over
250 million pairs of 1-second speech samples. While
the majority of legitimately modiﬁed audio has digest
errors less than 35%, adversarial audio has digest BERs
averaging 47.8%.
tested, 10ms delay has the least effect; this is a result of
the fact that the digest windows the audio with a high
overlap. For most digests, addition of white noise also
has little effect; this is because LSF analysis discards
all frequency information except for the most important
frequencies. We see higher error rates caused by the
use of audio codecs like GSM-FR and AMR-NB;
these codecs signiﬁcantly alter the frequency content
of the audio. We can also see that a 5% loss rate has
negligible effect on the audio digests. Finally, we see
that combining transcoding, loss, delay, and noise has an
additive effect on the resulting digest error — in other
words, the more degradation that takes place, the higher
the bit error. These experiments show that RSH is robust
to common audio modiﬁcations.
582    26th USENIX Security Symposium
USENIX Association
5.2.2 Adversarial Audio
While robustness is essential, the ultimate goal of these
digests is to detect maliciously tampered or injected
audio, which we term “adversarial audio.” Such an
analysis has not been previously performed. To validate
the ability of RSH to detect adversarial audio we compute
the BER of digests of every pair of seconds of TIMIT
audio discussed in the previous section. This dataset
includes 252,821,341 pairs of single seconds of audio.
For this test, we use the same key for every hash; this
models the situation where an adversary can cause the
target to receive audio of its choice but not modify the
associated digest.
We ﬁnd that the mean BER between two distinct audio
pairs is 0.478. A histogram and kernel density estimate
of these values is also shown in Figure 7. This plot
shows that the bit error is normally distributed with a
mean and median of 0.478 and 0.480 (respectively). The
expected bit error for two random bit strings is 50%, and
the mean seen for RSH bit error is close to the optimal,
best possible distance between two adversarial digests.
Because the TIMIT corpus contains speakers speaking
several identical sentences, we can investigate the re-
silience of the digest to more speciﬁc adversarial scenar-
ios in two important ways. First, we can look at whether
using different speech from the same speaker can create
a false positive. If so, this would be a serious problem
because an adversary could use recorded words from the
target speaker undetected. Second, we can determine if
a different speaker uttering the same words causes false
positives. This test indicates to what extent the digest is
protecting content instead of speaker characteristics.
We found that digests from the same speaker speaking
different content are accepted at practically the same rate
as audio that differs in speaker and content. At a BER
detection threshold of 0.384 (derived and discussed in
the following subsection), the detection rate for different
content spoken by the same speaker is 0.901482, while
the detection rate for different content spoken by a dif-
ferent speaker is 0.901215. However, identical phrases
spoken by different speakers results in a much higher
rate of collision and a detection rate of 0.680353. This
lower detection rate is not a problem for AuthentiCall
because it is still high enough to detect modiﬁed call au-
dio with high probability. More importantly, it indicates
that RSH is highly sensitive to changes in call content.
5.2.3 Threshold selection and performance
Distinguishing legitimate and illegitimate audio requires
choosing a BER threshold to detect tampered audio.
Because the extreme values of these populations overlap,
a tradeoff between detection and false positives must be
made. The tradeoff is best depicted in a ROC curve in
Figure 8: The digest performance ROC graph shows that
digests can easily distinguish between legitimate and
substituted audio, even in the presence of transcoding,
loss, delay, and noise. These results are computed over
digests of a single second. The graph is scaled to show
the extreme upper corner.
Figure 8. This ﬁgure shows the true positive/false posi-
tive tradeoff measured on the adversarial audio and two
legitimate modiﬁcations – GSM encoding and a combi-
nation of GSM, AMR-NB, 5% frame loss, 10ms delay,
and 30dB of white noise. This combination represents an
approximate “worst case” of legitimate audio. Figure 8
shows excellent performance in terms of distinguishing
audio. For GSM-only audio, we see an area-under-curve
of 0.998, and for the “worst case” audio, we see an
area-under-curve of 0.992. However, because digests
will be used at a high rate (one per second), even with
a very small false positive rate, alerting users for every
individual detection will likely result in warning fatigue.
As a result, the most important metric for evaluating a
threshold is minimizing the user’s likelihood of a false
positive. This problem suggests trading off sensitivity to
short changes in call content for a lower false positive
rate. To reduce overhead and network load, AuthentiCall
sends digests in groups of ﬁve. To provide high detection
rates while limiting false positives, AuthentiCall alerts
the user if any 3 out of 5 digests are greater than the
BER threshold. We model true and false performance of
this scheme as a set of ﬁve Bernoulli trials — successful
authentication for true positives and successful digest
collision for false positives. Thus, we can compute
3-out-of-5 performance using the binomial distribution.
After this analysis, we selected an individual-digest
BER threshold of 0.384. This corresponds to an in-
dividual adversary audio true positive detection rate of
0.90, while presenting a 0.0058 false positive rate against
our “worst-case” audio and a 0.00089 false positive rate
against clean GSM-FR encoded audio. Using our “three-
out-of-ﬁve” alerting scheme, the probability of detecting
3 or more seconds of tampered audio is 0.992. The false
positive rate is drastically reduced: the false positive rate
USENIX Association
26th USENIX Security Symposium    583
is 1.96 × 10−6, and for clean GSM-FR audio the false
positive rate is 7.02× 10−9. This corresponds to a false
alert on average every 425.1 hours of talk time for worst
case audio, and for GSM-FR audio one false positive ev-
ery 118,766 hours. The average British mobile phone
user only places 176 minutes per month of outbound
calls [65]; assuming inbound and outbound talk time are
roughly equal, the average user only places 70.4 hours of
calls per year. This means that the average AuthentiCall
user would only see a false alert once every six years.
5.2.4 Limitations
No security solution is perfect, and our use of audio
digests have some limitations. The chief limitation is
that audio digests cannot detect altered audio less than
one second in length. This limitation is simply a result
of the constraints of doing low-bitrate authentication of
mutable and analog data.
While the digests are not perfect, we argue that they
are secure against most adversaries. We note that audio
digests have two purposes: 1) to provide a guarantee that
the voice call established was the one that was negotiated
in the handshake and 2) that the voice content has not sig-
niﬁcantly changed during the call. These two goals deal
with adversaries of different capabilities. In particular,
intercepting and modifying call audio requires far more
advanced access and capability than simply spooﬁng a
caller ID during a handshake already occurring. Audio
digests will detect the ﬁrst scenario within ﬁve seconds
of audio, and it will also quickly detect changes that
effect any three seconds in ﬁve for the second scenario.
In limited circumstances, it may be possible for a
man-in-the-middle adversary to make small modiﬁca-
tions to the received audio. For the second attack to be
successful in the presence of these digests, a number of
conditions must hold: First, the adversary can change
no more than two seconds out of every ﬁve seconds of
audio. Second, the adversary must change the audio in a
way that would sound natural to the victim. This would
mean that the changed audio would have to conform to
both the current sentence pattern as well as the speaker’s
voice. While voice modiﬁcation algorithms exist (e.g.,
Adobe VoCo [10] and Lyrebird [11]), modifying an
existing sentence in an ongoing conversation is beyond
the abilities of current natural-language processing.
Also, since our digests depend on the semantic call
content, changes to the structure of a sentence (and not
necessary audible voice) would alert the user. Finally, in
addition to the substantial difﬁculty of these limits, the
adversary must also do all of this in soft-real-time.
Additionally, our threat model assumes the adversary
has access to the audio (but not the keys) that generated
the digest and thus second preimage resistance is a rel-
evant property. Note that our security argument rests in
the computational difﬁculty of ﬁnding a series of colli-
sions in real-time using semantically relevant audio. The
protection that RSH would provide for preimage resis-
tance (given an arbitrary digest but no corresponding
audio) depends primarily on the security of the keyed-
pseudorandom selection of audio segments for each di-
gest. Evaluating this property is interesting but not im-
mediately relevant to the security of our system.
Nevertheless, a user is still not defenseless against
such an attack. While we believe such attempts would
likely be noticeable and suspicious to the human ear,
users could also receive prompts from AuthentiCall
when individual digests fail.
These prompts could
recommend that the user ask the opposing speaker to
elaborate their prior point or to conﬁrm other details to
force the adversary to respond with enough tampered
audio that the attack could be detected.
6 System Implementation
The previous sections described the protocol design