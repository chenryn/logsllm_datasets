cation. Upon deallocation, this byte’s value is inspected;
if modiﬁed, this serves as evidence of a buffer overﬂow.
Then, GUARDER immediately halts the execution and re-
ports to the user. GUARDER will additionally check the
canary values of an object’s four adjacent neighbors at
the same time, which provides additional protection for
long-lived objects that may never be freed by the appli-
cation.
4.6 Optimizations
GUARDER has made multiple optimizations to further re-
duce its performance and memory overhead. To this end,
GUARDER also employs the Intel SSE2-optimized fast
random number generator (RNG) [31, 33].
4.6.1 Accessing Per-Thread Data
GUARDER must access its per-thread heap upon every
allocation and deallocation. Therefore, it is critical for
GUARDER to quickly access per-thread data. However,
the implementation of Thread Local Storage (TLS) (de-
clared using the “ thread” storage class keyword) is
not efﬁcient [13], and introduces at least an external li-
brary call, a system call to obtain the thread ID, and a
table lookup. Instead, GUARDER employs the stack ad-
dress to determine the index of each thread and fetch per-
thread data quickly, as existing work [42]. GUARDER
allocates a large block of memory that it will utilize for
threads’ stack areas. Upon thread creation, GUARDER
assigns a speciﬁc stack area to each thread (e.g., its
thread index multiplied by 8MB). Then, GUARDER can
obtain the thread index quickly by dividing any stack off-
set by 8MB.
4.6.2 Reducing Startup Overhead
In order to support a speciﬁed randomization entropy,
GUARDER needs to initialize each allocation buffer with
2E+1 objects, then place the speciﬁed ratio of guard
pages within. However, some applications may only
utilize a subset of size classes, which indicates that the
time spent placing guard pages in unused bags is wasted.
Therefore, GUARDER employs on-demand initialization:
it only initializes the allocation buffer and installs guard
pages upon the ﬁrst allocation request for the bag.
4.6.3 Reducing Memory Consumption
To reduce memory consumption, GUARDER returns
memory to the underlying OS when the size of a freed
object is larger than 64 kilobytes, by invoking madvise
with the MADV DONTNEED ﬂag.
GUARDER designs a global deallocation buffer to re-
duce the memory blowup caused by returning freed ob-
jects to the current thread’s sub-heap. This problem is
extremely serious for producer-consumer applications,
since new heap objects would continually be allocated
by the producer. If a thread’s deallocation buffer reaches
capacity, the thread will attempt to donate a portion of its
free objects to a global deallocation buffer. Conversely,
when a thread has no freed objects in its deallocation
buffer, GUARDER will ﬁrst pull objects from the global
deallocation buffer before attempting to utilize new heap
objects.
5 Experimental Evaluation
Experiments were performed on a 16-core machine, in-
stalled with Intel R(cid:13) Xeon R(cid:13) CPU E5-2640 processors.
This machine has 256GB of main memory and 20MB of
shared L3 cache, while each core has a 256KB L1 and
2MB L2 cache. The underlying OS is Linux-4.4.25. All
applications were compiled using GCC-4.9.1, with -O2
and -g ﬂags.
We utilized the default settings for each allocator, ex-
cept where explicitly described. By default, GUARDER
uses 9 bits of randomization entropy, a 10% proportion
of random guard pages, and a 1/8 over-provisioning fac-
tor. OpenBSD’s object junking feature was disabled in
order to provide a fair comparison.
In order to evaluate the performance and memory
overhead of these allocators, we performed experi-
ments on a total of 21 applications, including 13 PAR-
SEC applications, as well as Apache httpd-2.4.25,
Firefox-52.0, MySQL-5.6.10, Memcached-1.4.25,
SQLite-3.12.0, Aget, Pfscan, and Pbzip2. Note
that Firefox uses an allocator based on jemalloc by de-
fault, although all ﬁgures and tables label it as “Linux”
in this section. We did not evaluate single-threaded ap-
plications, such as SPEC CPU2006, due to the following
reasons. First, multithreaded applications have become
the norm, resulting from ubiquitous multicore hardware.
Second, DieHarder and OpenBSD have a severe scal-
ability issue, which cannot be observed using single-
threaded applications.
124    27th USENIX Security Symposium
USENIX Association
5.1 Performance Overhead
To evaluate performance, we utilized the average results
of 10 executions, as shown in Figure 3. DieHarder’s
destroy-on-free feature was disabled to allow for com-
parison with GUARDER. A value larger than 1.0 repre-
sents a runtime slower than the Linux allocator, while
those below 1.0 are faster. On average, the performance
overhead of these secure allocators are: DieHarder–
74%, OpenBSD–31%, FreeGuard–1%, and GUARDER–
3%, by comparing to the Linux allocator, while a known
performance oriented allocator—TCMalloc–is slightly
faster than it, with 1.6% performance improvement. That
is, GUARDER imposes negligible performance overhead,
while providing an unprecedented security guarantee. It
has performance overhead similar to FreeGuard, but with
much higher randomization entropy and support for heap
over-provisioning, as evaluated in Section 5.3 and de-
scribed in Section 6.2.
We further investigated why GUARDER runs faster
than DieHarder and OpenBSD, and why it is comparable
to FreeGuard. Based on our understanding, two factors
can signiﬁcantly affect the performance of allocators.
System call overhead. The ﬁrst factor is the overhead of
system calls related to memory management. These in-
clude mmap, mprotect, madvise, and munmap, however,
this data was omitted due to space limitations. Based on
our evaluation, GUARDER and FreeGuard impose much
less overhead from mmap system calls, since they ob-
tain a large block of memory initially in order to reduce
the number of mmap calls. Although they impose more
mprotect calls, our evaluation indicates that mprotect
requires only about 1/20 the time needed to perform an
mmap system call.
Heap allocation overhead. We also evaluated the over-
head associated with heap allocations by focusing on the
number of searches/trials performed during allocations
and deallocations, as well as the number of synchroniza-
tions. An allocator will impose more overhead when
the number of searches/trials is larger. Similarly, if the
number of synchronizations (mostly lock acquisitions) is
larger, the allocator will also impose more overhead.
The average number of trials for each secure allocator
is shown in Table 3, where the Linux allocator and TC-
Malloc typically only require a single trial upon each al-
location and deallocation. These values were computed
by dividing the total number of trials by the number of
allocations or deallocations. For both allocations and
deallocations, FreeGuard only requires a single trial due
to its free-list-based design. In comparison, GUARDER
makes random selections from allocation buffers that are
consistently maintained to remain at least half-full. As a
consequence, GUARDER’s average number of allocation
“tries” is about 1.77. Both OpenBSD and DieHarder ex-
ceed this value, with 3.79 and 1.99 times respectively.
For each deallocation, DieHarder performs 12.4 trials,
while OpenBSD, FreeGuard, and GUARDER only re-
quire a single trial. Based on our understanding, the large
number of trials is a major reason why DieHarder per-
forms much worse than other secure allocators. During
each deallocation, DieHarder will compare against all
existing minibags one-by-one to locate the speciﬁc mini-
bag (and mark its bit as free inside), loading multiple
cache lines unnecessarily. GUARDER utilizes a special
design (see Figure 2) to avoid this overhead. Although
DieHarder has less allocation trials than OpenBSD, its
worse case is signiﬁcantly worse than that of OpenBSD.
Synchronization overhead can be somehow indicated
by the number of allocations, as shown in Table 5. For
all other secure allocators, such as DieHarder, OpenBSD,
and FreeGuard, each allocation and deallocation should
acquire a lock, although FreeGuard will have less con-
tention. In comparison, GUARDER avoids most lock ac-
quisitions by always returning freed objects to the current
thread’s deallocation buffer. GUARDER only involves
lock acquisitions when using the global deallocation
buffer, employed to reduce memory blowup (described
in Section 4.6.3). This indicates that GUARDER actually
imposes less synchronization overhead than FreeGuard,
which is part of reason why GUARDER has a similar
overhead to FreeGuard, while providing a much higher
security guarantee.
5.2 Performance Sensitivity Studies
We further evaluated how sensitive GUARDER’s perfor-
mance is to different customizable allocation parameter,
such as the randomization entropy, the proportion of each
bag dedicated to random guard pages, and the level of
heap over-provisioning. The average results of all appli-
cations were shown in Table 4, where the data is normal-
ized to that of the default setting: 9 bits of randomization
entropy, 10% guard pages, and 1/8 of over-provisioning
factor.
Randomization Entropy. Different randomization en-
tropies were evaluated, ranging from 8 to 12 bits. As
shown in Table 4, a higher entropy, indicating it is harder
to be predicted and more secure, typically implies a
higher performance overhead. For instance, 12 entropy
bits may impose 4.7% performance overhead when com-
paring to the default setting. With a higher entropy, deal-
located objects have a lower chance to be re-utilized im-
mediately, which may access more physical memory un-
necessarily, causing more page faults and less cache hits.
Guard Page Ratio. A higher ratio of guard pages will
have a higher chance to stop any brute-force attacks. The
performance effects of different ratios of random guard
USENIX Association
27th USENIX Security Symposium    125
Figure 3: Performance overhead of secure allocators (and TCMalloc), where all values are normalized to the default
Linux allocator.
Trials
DieHarder OpenBSD FreeGuard GUARDER
1.99
Average
Maximum 93
Allocation
Deallocation Average
Maximum 141
12.40
3.79
45
1
1
1
1
1
1
1.77
131
1
1
Table 3: Number of trials for allocations and deallocations in different allocators.
Entropy (bits)
8
9
GPR=10%, OPF=1/8
10
11
12
1.047
1.000
1.016
1.003
Guard Page Ratio
2%
0.987
Over-provisioning Factor EB=9, GPR=10%
1/32
0.998
1.031
EB=9, OPF=1/8
20%
1.016
50%
1.046
1/2
1.011
5%
0.990
1/16
0.995
10%
1.000
1/8
1.000
1/4
1.001
Table 4: Performance sensitivity to each parameter,
normalized to the default settings of GUARDER.
EB = Entropy Bits, GPR = Guard Page Ratio, OPF =
Over-provisioning factor.
Different heap over-
provisioning factors, including 1/32, 1/16, 1/8, 1/4,
and 1/2, were evaluated.
In the extreme case of 1/2,
half of the heap will not be utilized. This evaluation
shows two results: (1) A larger over-provisioning fac-
tor will typically imply larger overhead. (2) The perfor-
mance impact of over-provisioning is not as large as ex-
pected, as over-provisioning will not affect cache utiliza-
tion when skipped objects are completely removed from
future allocations and deallocations. However, it may
cause a much larger performance impact on DieHarder,
due to its special design.
Over-Provisioning Factor
pages, including 2%, 5%, 10%, 20%, and 50%, were
similarly evaluated. For the 50% ratio, almost every
page (or object with size greater than 4 kilobytes), will
be separated by a guard page. Similarly, a larger ratio
of installed guard pages typically implies a larger perfor-
mance overhead, due to invoking more mprotect sys-
tem calls.
5.3 Memory Overhead
We collected the maximum memory consumption for all
ﬁve allocators. For server applications, such as MySQL
and Memcached, memory consumption was collected via
the VmHWM ﬁeld of /proc/pid /status ﬁle. For other
applications, memory consumption was collected using
the maxresident output of the time utility [22].
126    27th USENIX Security Symposium
USENIX Association
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 blackscholes bodytrack canneal dedup facesim ferret fluidanimate freqmine raytrace streamcluster swaptions vips x264 Aget Apache Firefox Memcached MySQL Pbzip2 Pfscan SQLite AVERAGE Normalized Runtime TCMalloc Default DieHarder OpenBSD FreeGuard Guarder Dummy 9.26.14.21.423.01.41.7To ensure a fair comparison, we disabled the ca-
nary checking functionality for both FreeGuard and
GUARDER (and is disabled by default in OpenBSD),
since adding even a single-byte canary may cause an ob-
ject to be allocated from the next largest size class.
In total, the memory overhead (shown in Table 5)
of FreeGuard is around 37%, while DieHarder and
OpenBSD feature slightly less memory consumption
than the Linux allocator, with -3% and -6%, respectively.
GUARDER imposes 27% memory overhead on evaluated
applications, when using the default 9 bits of entropy. It
especially imposes more than 4× memory overhead for
Swaptions, MySQL, and SQLite.
GUARDER’s memory overhead on certain applications
can be attributed to multiple reasons, mostly relating to
its management of small objects. First, GUARDER may
increase its memory consumption due to its randomized
allocation. For any given size class, GUARDER will
place more than 2n objects into its allocation buffer, then
randomly allocate an object from among them. There-
fore, GUARDER may access other pages (due to its ran-
domized allocation policy) when there are still avail-
able/free objects in existing pages. Second, GUARDER’s
over-provisional mechanism will introduce more mem-
ory consumption, since some objects will be randomly
skipped and thus never utilized. Note that GUARDER
also achieves comparable average memory overhead to
FreeGuard, due to its global free cache mechanism,
which better balances memory usage among threads
(particularly for producer-consumer patterns).
We also observe that GUARDER’s memory overhead is
near 0% when 7 bits of entropy are utilized. This further
indicates the necessity to provide customizable security,
as users may choose a lower entropy to reduce perfor-
mance and memory consumption as needed.
5.4 Randomization Entropy
We further evaluated the randomization entropies of
these secure allocators, with results shown in Figure 4.
We are the ﬁrst work that experimentally evaluates the
entropies of each size class, by explicitly modifying
these allocators. The basic idea is to update a per-size-
class global variable upon each allocation, then compute
the average entropy of each size class for different ap-
plications. We computed the entropy based on the max-
imum number of available choices upon each allocation
using a log2(N) formula. Note that we utilized the max-
imum number of entries in four bags to compute the en-
tropy for OpenBSD upon each allocation. Because the
bag size for OpenBSD is just one page, we do not show
its entropies for objects larger than 4 kilobytes.
Both DieHarder and OpenBSD were seen to exhibit
unstable entropy, and FreeGuard shows a constant low
entropy (approximately 2 bits). By contrast, GUARDER’s
measured entropy is 9.89 bits for every size class, when
the speciﬁed entropy is set to 9 bits. Taking the size
class of 64 kilobytes for example, GUARDER will ran-
domly allocate one object from over 831 objects, while
DieHarder and FreeGuard will allocate from just 32
and 4 objects, respectively. This clearly indicates that
GUARDER has signiﬁcantly higher security than these
existing allocators. DieHarder only exceeds GUARDER’s
entropy in the ﬁrst four size classes, when compared to
its default conﬁguration with 9 bits. However, our evalu-
ation also shows that GUARDER guarantees virtually the
same high entropy across different size classes, execution
phases, applications, or inputs, making it the ﬁrst secure
allocator of this kind.
5.5 Effectiveness of Defending Against At-
tacks
We evaluate the effectiveness of GUARDER and other al-
locators using a collection of real-world vulnerabilities,
including buffer over-writes, buffer over-reads, use-after-
frees, and double/invalid frees. With the exception of
Heartbleed, each of the reported bugs will typically re-
sult in a program crash. Heartbleed is unique in that it
results in the silent leakage of heap data. GUARDER was
shown to avoid the ill effects of these bugs, and/or report
their occurrences to the user, as shown in Table 6. More
information about these buggy applications is described
below.
bc-1.06. Arbitrary-precision numeric processing lan-
guage interpreter
The affected copy of this program was obtained from
BugBench [25], and includes a buffer overﬂow as the re-
sult of an off-by-one array indexing error, caused by a
speciﬁc bad input, which will produce a program crash.
Based on their powers-of-two size classes, each secure
allocator places the affected array in a bag serving ob-
jects larger than the needed size. As such, this small one-
element overﬂow is harmlessly contained within unused
space, thus preventing the crash.
ed-1.14.1. Line-oriented text editor