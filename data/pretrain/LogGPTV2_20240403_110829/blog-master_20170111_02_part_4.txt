分配过程先会检查空闲页表中有没有页可以申请，实现方法是：get_page_from_freelist，我们并不关心正常情况，分到了当然一切ok。  
更重要的是异常处理，如果空闲中没有，则会进入__alloc_pages_slowpath方法进行处理。这个处理过程的主逻辑大概这样：  
2\.2\.1 唤醒kswapd进程，把能换出的内存换出，让系统有内存可用。  
2\.2\.2 继续检查看看空闲中是否有内存。有了就ok，没有继续下一步；  
2\.2\.3 尝试清理page cache，清理的时候会将进程置为D状态。如果还申请不到内存则：  
2\.2\.4 启动oom killer干掉一些进程释放内存，如果这样还不行则：  
2\.2\.5 回到步骤1再来一次！  
当然以上逻辑要符合一些条件，但是这一般都是系统默认的状态，（比如，你必须启用oom killer机制等。另外这个逻辑中有很多其它状态与本文无关，比如检查内存水印、检查是否是高优先级内存申请等等，当然还有关于numa节点状态的判断处理，我没有一一列出）。  
另外，以上逻辑中，不仅仅只有清理cache的时候会使进程进入D状态，还有其它逻辑也会这样做。这就是为什么在内存不够用的情况下，oom killer有时也不生效，因为可能要干掉的进程正好陷入这个逻辑中的D状态了。  
以上就是内存申请中，大概会发生什么的过程。  
本文的重点cgroup内存限制进行说明，当我们处理限制的时候，更多需要关心的是当内存超限了会发生什么？对边界条件的处理才是我们这次的主题。  
所以我并没有对正常申请到的情况做细节说明，也没有对用户态使用malloc什么时候使用sbrk还是mmap来申请内存做出细节说明，毕竟那是程序正常状态的时候的事情，后续可以另写一个内存优化的文章主要讲解那部分。  
下面我们该进入正题了：  
## 二、Cgroup内存限制的配置  
其实最简单的莫过于如何进行限制了，我们的系统环境还是沿用上一次讲解CPU内存隔离的环境，使用cgconfig和cgred服务进行cgroup的配置管理。还是创建一个zorro用户，对这个用户产生的进程进行内存限制。基础配置方法不再多说，如果不知道的请参考 [这个文档](http://pan.baidu.com/s/1pKzBnz9#0-tsina-1-58608-397232819ff9a47a7b7e80a40613cfe1) 。  
环境配置好之后，我们就可以来检查相关文件了。内存限制的相关目录根据cgconfig.config的配置放在了/cgroup/memory 目录中，如果你跟我做了一样的配置，那么这个目录下的内容应该是这样的：  
```
[root@zorrozou-pc ~]# ls /cgroup/memory/  
cgroup.clone_children memory.failcnt memory.kmem.slabinfo memory.kmem.usage_in_bytes memory.memsw.limit_in_bytes memory.oom_control memory.usage_in_bytes shrek  
cgroup.event_control memory.force_empty memory.kmem.tcp.failcnt memory.limit_in_bytes memory.memsw.max_usage_in_bytes memory.pressure_level memory.use_hierarchy tasks  
cgroup.procs memory.kmem.failcnt memory.kmem.tcp.limit_in_bytes memory.max_usage_in_bytes memory.memsw.usage_in_bytes memory.soft_limit_in_bytes zorro  
cgroup.sane_behavior memory.kmem.limit_in_bytes memory.kmem.tcp.max_usage_in_bytes memory.meminfo memory.move_charge_at_immigrate memory.stat notify_on_release  
jerry memory.kmem.max_usage_in_bytes memory.kmem.tcp.usage_in_bytes memory.memsw.failcnt memory.numa_stat memory.swappiness release_agent  
```
其中，zorro、jerry、shrek都是目录概念跟cpu隔离的目录树结构类似。  
相关配置文件内容：  
```  
[root@zorrozou-pc ~]# cat /etc/cgconfig.conf   
mount {  
  cpu = /cgroup/cpu;  
  cpuset = /cgroup/cpuset;  
  cpuacct = /cgroup/cpuacct;  
  memory = /cgroup/memory;  
  devices = /cgroup/devices;  
  freezer = /cgroup/freezer;  
  net_cls = /cgroup/net_cls;  
  blkio = /cgroup/blkio;  
}  
group zorro {  
  cpu {  
    cpu.shares = 6000;  
    cpu.cfs_quota_us = "600000";  
  }  
  cpuset {  
    cpuset.cpus = "0-7,12-19";  
    cpuset.mems = "0-1";  
  }  
  memory {  
  }  
}  
```  
配置中添加了一个真对memory的空配置项，我们稍等下再给里面添加配置。  
```  
[root@zorrozou-pc ~]# cat /etc/cgrules.conf  
zorro cpu,cpuset,cpuacct,memory zorro  
jerry cpu,cpuset,cpuacct,memory jerry  
shrek cpu,cpuset,cpuacct,memory shrek  
```  
文件修改完之后记得重启相关服务：  
```  
[root@zorrozou-pc ~]# service cgconfig restart  
[root@zorrozou-pc ~]# service cgred restart  
```  
让我们继续来看看真对内存都有哪些配置参数：  
```  
[root@zorrozou-pc ~]# ls /cgroup/memory/zorro/  
cgroup.clone_children memory.kmem.failcnt memory.kmem.tcp.limit_in_bytes memory.max_usage_in_bytes memory.memsw.usage_in_bytes memory.soft_limit_in_bytes  
cgroup.event_control memory.kmem.limit_in_bytes memory.kmem.tcp.max_usage_in_bytes memory.meminfo memory.move_charge_at_immigrate memory.stat notify_on_release  
cgroup.procs memory.kmem.max_usage_in_bytes memory.kmem.tcp.usage_in_bytes memory.memsw.failcnt memory.numa_stat memory.swappiness tasks  
memory.failcnt memory.kmem.slabinfo memory.kmem.usage_in_bytes memory.memsw.limit_in_bytes memory.oom_control memory.usage_in_bytes  
memory.force_empty memory.kmem.tcp.failcnt memory.limit_in_bytes memory.memsw.max_usage_in_bytes memory.pressure_level memory.use_hierarchy  
```  
首先我们已经认识了memory.stat文件了，这个文件内容不能修改，它实际上是输出当前cgroup相关内存使用信息的。常见的数据及其含义我们刚才也已经说过了，在此不再复述。  
### 1. cgroup内存限制  
1\. memory.memsw.limit_in_bytes: 内存＋swap空间使用的总量限制。  
2\. memory.limit_in_bytes：内存使用量限制。  
这两项的意义很清楚了，如果你决定在你的cgroup中关闭swap功能，可以把两个文件的内容设置为同样的值即可。  
至于为什么相信大家都能想清楚。  
注意:    
在调整memsw.limit_in_bytes或limit_in_bytes时，请保证任何时刻 "memsw.limit_in_bytes 都 >= limit_in_bytes"，否则可能修改失败。  
比如现在  
memsw.limit_in_bytes=1G  
limit_in_bytes=1G  
要缩小到800MB,那么应该先缩小limit_in_bytes再缩小memsw.limit_in_bytes  
### 2. OOM控制  
memory.oom_control:  内存超限之后的oom行为控制。  
这个文件中有两个值：  
1\. oom_kill_disable 0  
默认为0表示打开oom killer，就是说当内存超限时会触发干掉进程。  
如果设置为1表示关闭oom killer，此时内存超限不会触发内核杀掉进程。而是将进程夯住（hang/sleep），实际上内核中就是将进程设置为D状态，并且将相关进程放到一个叫做OOM-waitqueue的队列中。这时的进程可以kill杀掉。如果你想继续让这些进程执行，可以选择这样几个方法：  
1\.1 增加该cgroup组的内存限制，让进程有内存可以继续申请。  
1\.2 杀掉该cgroup组内的其他一些进程，让本组内有内存可用。  
1\.3 把一些进程移到别的cgroup组中，让本cgroup内有内存可用。  
1\.4 删除一些tmpfs的文件，就是占用内存的文件，比如共享内存或者其它会占用内存的文件。  
说白了，此时只有当cgroup中有更多内存可以用了，在OOM-waitqueue队列中被挂起的进程就可以继续运行了。  
2\. under_oom 0  
这个值只是用来看的，它表示当前的cgroup的状态是不是已经oom了，如果是，这个值将显示为1。  
我们就是通过设置和监测这个文件中的这两个值来管理cgroup内存超限之后的行为的。  
在默认场景下，如果你使用了swap，那么你的cgroup限制内存之后最常见的异常效果是IO变高，如果业务不能接受，我们一般的做法是关闭swap，那么cgroup内存oom之后都会触发kill掉进程，如果我们用的是LXC或者Docker这样的容器，那么还可能干掉整个容器。  
当然也经常会因为kill进程的时候因为进程处在D状态，而导致整个Docker或者LXC容器根本无法被杀掉。  
至于原因，在前面已经说的很清楚了。当我们遇到这样的困境时该怎么办？一个好的办法是，关闭oom killer，让内存超限之后，进程挂起，毕竟这样的方式相对可控。  
此时我们可以检查under_oom的值，去看容器是否处在超限状态，然后根据业务的特点决定如何处理业务。  
我推荐的方法是关闭部分进程或者重启掉整个容器，因为可以想像，容器技术所承载的服务应该是在整体软件架构上有容错的业务，典型的场景是web服务。容器技术的特点就是生存周期短，在这样的场景下，杀掉几个进程或者几个容器，都应该对整体服务的稳定性影响不大，而且容器的启动速度是很快的，实际上我们应该认为，容器的启动速度应该是跟进程启动速度可以相媲美的。  
你的业务会因为死掉几个进程而表现不稳定么？如果不会，请放心的干掉它们吧，大不了很快再启动起来就是了。但是如果你的业务不是这样，那么请根据自己的情况来制定后续处理的策略。  
当我们进行了内存限制之后，内存超限的发生频率要比使用实体机更多了，因为限制的内存量一般都是小于实际物理内存的。所以，使用基于内存限制的容器技术的服务应该多考虑自己内存使用的情况，尤其是内存超限之后的业务异常处理应该如何让服务受影响的程度降到更低。在系统层次和应用层次一起努力，才能使内存隔离的效果达到最好。  
### 3. 内存资源审计  
1\. memory.memsw.usage_in_bytes:  当前cgroup的内存＋swap使用量。  
2\. memory.usage_in_bytes:  当前cgroup的内存使用量。  
3\. memory.max_usage_in_bytes:  当前cgroup的历史最大内存使用量。  
4\. memory.memsw.max_usage_in_bytes:  当前cgroup的历史最大内存＋swap使用量。  
这些文件都是只读的，用来查看相关状态信息，只能看不能改。  
5\. 如果你的内核配置打开了CONFIG_MEMCG_KMEM选项（getconf -a）的话，那么可以看到当前cgroup的内核内存使用的限制和状态统计信息，他们都是以memory.kmem开头的文件。你可以通过memory.kmem.limit_in_bytes来限制内核使用的内存大小，通过memory.kmem.slabinfo来查看内核slab分配器的状态。现在还能通过memory.kmem.tcp开头的文件来限制cgroup中使用tcp协议的内存资源使用和状态查看。  
6\. 所有名字中有failcnt的文件里面的值都是相关资源超限的次数的计数，可以通过echo 0将这些计数重置。  
7\. 如果你的服务器是NUMA架构的话，可以通过memory.numa_stat这个文件来查看cgroup中的NUMA相关状态。  
8\. memory.swappiness跟 /proc/sys/vm/swappiness 的概念一致，用来调整cgroup使用swap的状态，表示不使用交换分区。但是依旧可能会发生swapout，如果真的不想发生，建议使用mlock锁定内存，前面讲了使用mlock的内存不会被swapout。  
but:  
```
swap out might still happen when there is a shortage of system memory because the global virtual memory management logic does not read the cgroup value. To lock pages completely, use mlock() instead of cgroups.  
You cannot change the swappiness of the following groups:  
the root cgroup, which uses the swappiness set in /proc/sys/vm/swappiness.  
a cgroup that has child groups below it.  
```
9\. memory.failcnt  
```
reports the number of times that the memory limit has reached the value set in memory.limit_in_bytes.  
```
10\. memory.memsw.failcnt  
```
reports the number of times that the memory plus swap space limit has reached the value set in memory.memsw.limit_in_bytes.  
```
### 4. 内存软限制 以及 内存超卖  
1\. memory.soft_limit_in_bytes:  内存软限制。  
如果超过了memory.limit_in_bytes所定义的限制，那么进程会被oom killer干掉或者被暂停，这相当于硬限制，因为进程无法申请超过自身cgroup限制的内存，但是软限制确是可以突破的。  
我们假定一个场景，如果你的实体机上有四个cgroup，实体机的内存总量是64G，那么一般情况我们会考虑给每个cgroup限制到16G内存。  
但是现实情况并不会这么理想，首先实体机上其他进程和内核会占用部分内存，这将导致实际上每个cgroup都不会真的有16G内存可用，如果四个cgroup都尽量占用内存的话，他们可能谁都不会到达内存的上限触发超限的行为，这可能将导致进程都抢不到内存而被饿死。  
类似的情况还可能发上在内存超卖的环境中，比如，我们仍然只有64G内存，但是确开了8个cgroup，每个都限制了16G内存。  
这样每个cgroup分配的内存之和达到了128G，但是实际内存量只有64G。  
这种情况是出于绝大多数应用可能不会占用满所有的内存来考虑的，这样就可以把本来属于它的那份内存"借用"给其它cgroup。  
如果全局内存已经耗尽了，但是某些cgroup还没达到他的内存使用上限，而它们此时如果要申请内存的话，此时该从哪里回收内存？  
如果我们配置了memory.soft_limit_in_bytes，那么内核将去回收那些内存超过了这个软限制的cgroup的内存，**尽量缩减它们的内存占用达到软限制的量以下** ，以便让没有达到软限制的cgroup有内存可以用。  
在没有这样的内存竞争以及没有达到硬限制的情况下，软限制是不会生效的。还有，软限制的起作用时间可能会比较长，毕竟内核要平衡多个cgroup的内存使用。  
根据软限制的这些特点，我们应该明白如果想要软限制生效，应该把它的值设置成小于硬限制。  
### 5. 进程迁移时的内存charge  
memory.move_charge_at_immigrate:  打开或者关闭进程迁移时的内存记账信息。  
进程可以在多个cgroup之间切换，所以内存限制必须考虑当发生这样的切换时。  
进程进入的新cgroup时，内存使用量是重新从0累计还是把原来cgroup中的信息迁移过来？  
设置为0时，关闭这个功能，相当于不累计之前的信息.  
默认是1，迁移的时候要在新的cgroup中累积（charge）原来信息，并把旧group中的信息给uncharge掉。  
如果新cgroup中没有足够的空间容纳新来的进程，首先内核会在cgroup内部回收内存，如果还是不够，导致进程迁移cgroup失败。  
### 6. 清空cgroup组的内存  
memory.force_empty  