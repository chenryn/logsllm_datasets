report. For each function, IPPO records one potential bug for each
security operation type.
6 Evaluation
We evaluate the scalability and effectiveness of IPPO using the Linux
kernel and OpenSSL library. The experiments were performed on a
MacBook Pro laptop with 16GB RAM and an Intel(R) Core(TM) i7
CPU with six cores (i7-8850H, 2.60GHz). We tested the bug detection
efficiency on the Linux kernel version 5.8, OpenSSL library version
3.0.0-alpha6, FreeBSD 12 and PHP 8.0.8 using LLVM of version 9.0.
For the Linux kernel, we used allyescon f iд to compile as many
kernel modules as possible, which generated 19,492 LLVM bitcode
files. For the OpenSSL library, FreeBSD, and PHP, we used default
compile options and generated 2,294, 1,483, and 371 LLVM bitcode
files, respectively.
6.1 Overall Analysis Performance
Since the RAM size of our machine is limited, we batch Linux kernel
bitcode files before analysis. Each batch contains 3,000 bitcode files.
IPPO completed the analysis against the four systems in two hours.
It reported 754 bugs in total. The detailed bug detection results are
shown in Table 2.
Table 2: Bug detection results of IPPO in the four systems. The R and
T in the table indicate the reported bugs and true bugs, respectively.
Bug type
Missing check
Missing release
Refcount leak
Missing unlock
Total
Linux
T
R
101
11
68
244
181
345
6
29
719
266
OpenSSL
R
2
13
0
0
15
T
1
6
0
0
7
FreeBSD
R
1
1
0
2
3
T
0
0
0
1
1
PHP
R
4
11
0
2
17
T
0
1
0
0
1
6.2 Bug Findings
We manually checked all the 754 reports generated by IPPO, taking
about 20 man-hours in total. We finally confirmed 266, 7, 1, and
1 valid bugs from the Linux kernel, OpenSSL library, the FreeBSD
kernel and PHP, respectively, including 181 refcount leaks, 68 mem-
ory leaks, 12 missing check bugs, 7 double-free/use-after-free bugs,
and 7 missing unlock bugs. Among which, 2 missing check bug, 11
memleak bugs, 99 refcount leak bugs, and 2 missing unlock bugs
have been fixed by other developers in the latest systems. We have
Session 5D: Misc: Android and Vulnerabilities CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1636submitted patches to fix the rest 161 bugs, and 136 of them have
been accepted by corresponding maintainers. The detailed list of all
bugs is available at Tables 5∼11 in the Appendix.
One interesting finding of our bug analysis is that the refcount API
pm_runtime_get_sync() is commonly misused, which has caused
hundreds of bugs. This finding not only shows the limitation of
cross-checking, but also reinforces the previous research against
the same set of APIs ([26]). These refcount APIs will change the
refcount even they return errors, which is counter-intuitive. In prac-
tice, it is common for developers to assume that the target task of
a function call does not complete on failure. Therefore, many de-
velopers do not decrease the PM runtime counter on the failure of
pm_runtime_get_sync(). Our patchwork aroused a discussion about
the design of this set of APIs in the Linux community. Some Linux
maintainers suggest that the right thing is to fix the misleading APIs
to prevent misuse in the future rather than patch them one by one,
which is reasonable. Therefore, we stopped submitting patches re-
sulted in this issue. Fortunately, a new alternative refcount API has
been released at the moment: pm_runtime_resume_and_get(), which
will not modify the reference counter on failure. We believe this API
will make future refcount development more stable and secure.
We also investigated the size of all bug functions except those
caused by the misunderstanding of APIs (116 functions in total).
56 of them (48.3 %) contain more than 100 lines of source code,
and 18 (15.5%) of them contain more than 200 lines. The longest
bug function caught by IPPO possesses 613 lines of source code.
This testifies IPPO’s ability to detect bugs in complicated functions.
Actually, 17 of the above long functions introduced bugs earlier than
five years ago, and four bugs have existed for more than ten years.
6.3 Comparison with Other Tools
6.3.1 Comparison with Cross-checking Tools. In this subsection,
we compare IPPO with three state-of-the-art bug detection tools:
APISan [48], Crix [24], FICS [9]. APISan and Crix are based on
cross-checking and FICS is based on machine-learning. All of these
tools find bugs through differentially checking similar code slices.
HERO could detect incorrect error handling through precise function
pairing. Our modifications on security check detection have been
synchronized in Crix before this experiment. We mainly focus on
how many bugs found by IPPO could be caught by cross-checking
methods. Thus we use the confirmed bugs found by IPPO as bench-
mark.
Table 3: Bug detection results of state-of-the-art tools.
Bug type
Missing check
Missing release
Refcount leak
Missing unlock
Total
IPPO
12
75
181
7
275
FICS
0
0
0
0
0
Crix
1
0
0
0
1
APISan
0
0
0
0
0
As shown in Table 3, almost all the bugs found by IPPO cannot
be detected by the other three tools. FICS fails on analyzing Linux
kernel because of the extremely huge RAM requirements (more
than 200GB). Though FICS claims to be able to identify one-to-one
inconsistency, its code representation (data dependence graph) and
filter strategies are too coarse-grained to analyze path level difference.
Crix is designed to detect missing check bugs, thus is incapable of
finding other kinds of bugs. For missing check bugs, most bugs found
by IPPO lack enough similar code pieces, thus cannot be detected by
Crix neither. APISan considers all conditions in a path to construct
semantic beliefs. However, as aforementioned in Rule 3 of OSPP,
many intermediate conditions and operations have no impact on
the usage of security operations, which makes APISan’s similarity
analysis have poor robustness. The comparison results not only
show the limitation of cross-checking methods, but also reveal the
effectiveness of IPPO.
6.3.2 Comparison with Pairing Analyses Tool. HERO [10] is the
state-of-the-art pairing analysis tool, which could precisely detect
functions used in pairs and bugs caused by disordered error handling
(missing, redundant, and incorrect order of error handling). The bug
types covered by HERO include refcount leak, memory leak, use-
after-free/double-free, and incorrect lock/unlock, which are quite
similar with the bug types supported by IPPO. Since HERO is not
open-sourced yet, we manually checked the bugs found by IPPO and
filter bugs that do not exist in the Linux kernel version of 5.3 (on
which HERO is evaluated).
Table 4: Comparison with HERO.
Bug types
Memory Leak
Refcount Leak
Missing unlock
UAF/DF
Total
Bugs in v5.3 HERO Results Recall
55
112
3
6
176
3.6%
73.2%
0%
0%
47.7%
2
82
0
0
84
As shown in Table 4, we finally checked out 176 valid bugs that
exist in the Linux kernel of v5.3. HERO successfully detect 84 of
them (47.7%). Among these bugs, HERO found most of refcount bugs
that caused by misunderstanding of pm_runtime_get_sync() API,
which is consistent with the conclusion of HERO paper. However,
HERO still missed almost half of the bugs found by IPPO due to (1)
many custom function pairs are still missed, and (2) HERO could not
resolve bugs without leader functions.
6.3.3 Complementarity analysis. We further analyze whether the
bugs found by other tools could be found by IPPO. We collected 560
bugs found by APISan, Crix, and HERO in the Linux kernel, and
IPPO could detect 119 of them (the bug list of FICS is not released,
thus is ignored). The above experiments show that IPPO shares very
limited intersection with existing bug detection tools, which means
IPPO is a promising complementation with them.
6.4 False Positives
The overall false positive rate of IPPO is 63.5%. The main causes are
summarized below.
• Unexpected pre-condition. Though IPPO has considered this
case, as described in §4.2, it cannot pick out all eligible cases.
Developers often use some temporary variables to adjust the
timing of using security operations, especially refcount operations.
Session 5D: Misc: Android and Vulnerabilities CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1637These temporary variables may cause a missing case in a small
part of code or a function, but finally they will balance again in
the global context. Sometimes developers set call-back functions
to auto-manage resources, which is hard to detect. IPPO needs a
more powerful inter-procedure analysis flow to model and check
against pre-conditions. Such cases account for 27% of the false
positives.
• Imprecise data-flow analysis. The value escape methods while
checking Rule 4 are diverse in practice. Some values escape through
function calls, which needs expensive inter-procedure alias anal-
ysis and IPPO cannot tell which functions are designed for this.
Complex value propagation also decreases the analysis precision.
These cases lead to about 30% of the false positives.
• Imperfect error path analysis. Our error path analysis highly
relies on return values, which is unreliable while analyzing void
functions. Many error handling paths in void functions also have
none error handling functions (e.g., print error messages), thus
are indistinguishable for IPPO by now. This contributes 14% of
the false positives.
• Imperfect security operation detection. Currently the imple-
mentation of security operation detection cannot handle complex
scenes. For example, some resources are released through refcount
operations or other wrapper functions, which is missed by IPPO.
This reason accounts for 6% of the false positives.
• Other causes. Other cases like special function logic could also
cause false positives. Some missed security operations have no
obvious security impact, thus are not counted as bugs. These cases
contribute the rest 23% false positives.
False positive is always a key challenge in program static analysis,
especially for complex analysis targets like OS kernels. We believe
that the 63.5% false positive rate of IPPO is acceptable. In addition,
the three state-of-the-art similar static analysis tools also suffer from
this issue (65.4%, 99.8%, and 88.0% false positive rates for Crix [24],
APISan [48], and FICS [9], respectively). On the other hand, manually
analyzing bugs suggested by IPPO is easy because the correct path
provides references. According to our statistics, it takes a non-expert
researcher less than two minutes on average to check a bug report
after analyzing several examples.
6.5 False Negatives
To evaluate the false negatives of IPPO, we constructed a testset
by manually removing the security operations in normal functions.
We randomly selected 40 functions in Linux kernel where security
operations are shown in multiple paths. Then, we delete 10 resource
release calls, 10 return value checks, 10 refcount decrements, and 10
unlocks from them, which results in 10 memleak bugs, 10 missing
check bugs, and 10 refcount leak bugs, and 10 missing unlock bugs,
respectively. We used IPPO to check against this benchmark and
IPPO successfully detected 31 missed security operations (77.5%
recall rate). Among the false negatives, two memleak bugs, three
missing check bugs, and four missing unlock bugs are missed by
IPPO. Two of them are filtered for the pre-condition containing
function arguments, which breaks Rule 4 of OSPP. One security
check in a function is not identified, which leads to a false negative.
One checked function is defined inline, and removing security checks
makes the function call instruction disappear in LLVM IRs. Four
unlock calls does not share the same parameters with the lock calls,
thus are filtered. The last missed memleak is caused by complex
variable definition. Specifically, the resource variable has multiple
definitions and the path where the resource release is removed has
a wrapper function of release. However, this release wrapper should
be paired with a previous definition, which is beyond the capability
of IPPO.
6.6 Security Impacts of the Found Bugs
In this section, we discuss the security impacts of the bugs identified
by IPPO. To this end, we first evaluate the potential reachability of
these bugs. Furthermore, we illustrate the potential impacts of them.
6.6.1 Reachability Analysis. Understanding the reachability of bugs
in complex programs is an open problem. Thus, in this evaluation,
we are using the existence of shorter call-stacks, which are from
system entry points to the vulnerable functions, to measure the
reachability of bugs. Similar to previous works such as PeriScope [37]
and SID [44], we chose the system calls, ioctl handlers, and IRQ
handlers as user-controllable system entry-points to evaluate the
reachability of the bugs identified by IPPO. Our evaluation result
shows that 71.9% of the bugs identified by IPPO are reachable from
at least one of these entry points, which means that these bugs are
possible to be triggered by users.
Impact Analysis. As we discussed in §1, most of the bugs
6.6.2
caused by missing security operations would cause security impacts
such as memory corruption, DoS, and memory leak, when triggered.
Considering the reachability evaluation, 71.9% of the bugs identified
by IPPO would lead to at least one security impact. Specifically, 24.6%
and 70% of the bugs would cause memory leaks and refcount leaks,
respectively, which would further lead to deny-of-service if they
are triggered repeatedly. Also, 5% of the bugs identified by IPPO
would cause null-pointer-dereference, which may lead to memory
corruption when triggered. For example, Figure 5 shows a potential
use-after-free/double-free bug in the Linux kernel identified by IPPO.
Function snd_echo_resume() in Figure 5 could be reached from the
system call sys_ioctl(), which means that attackers could trigger
it and cause security impacts to the kernel.
6.7 Scalability and Portability
The bug detection results on both Linux kernel and OpenSSL library
have shown the scalability and portability of IPPO. The idea of OSPP
and missed security operations are shared by various programs re-
gardless of whether they run in kernel mode or user mode. Different
programs may have their own preference in using security opera-
tions, but this is a pluggable analysis pass in IPPO and it supports
further expansion on security operation types. IPPO is able to detect
various missed security operations and infer their security impacts
based on similar path pairs analysis in various programs that could
be compiled into LLVM IRs.
7 Discussion
Security operation detection. IPPO detects security operations
with a direct and simple analysis pass, as mentioned in §5.1. Since
detecting security operations is not the main goal of IPPO, we only
choose to implement three kinds of security operations in this paper
Session 5D: Misc: Android and Vulnerabilities CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1638to estimate the bug detection of IPPO. However, this part is pluggable
and supports further extension. Here, three common types of security
operations are sufficient to demonstrate the effectiveness of our
approach. In the future, on the one hand, we plan to add more
security operations (e.g., variable initialization) to further improve
the bug detection ability of IPPO. On the other hand, we will open-
source IPPO and enable interested readers to extend IPPO and detect
bugs according to their practical needs.
Inter-procedural analysis. IPPO is mainly designed based on static
intra-procedural analysis. However, only considering the informa-
tion within a single function could result in both false positives
and false negatives. Meanwhile, Some missed security operations
(e.g., security checks) are more likely to show the difference in inter-
procedural context. We believe the inter-procedural feature could be
implemented by considering function calls, which is an interesting
future work.
Precise data-flow analysis. Currently, we track all variables’ sources
and use flows directly through a data-flow analysis implemented by
us, which may not be accurate enough and may cause false positives.
To address this problem, it is interesting to introduce professional
pointer analysis technology (e.g., Andersen pointer analysis [15] or
batch analysis [40]) to improve our analysis flows and the overall
accuracy.
Exploitability analysis. We have analyzed the reachability of bugs
found by IPPO in §6.6. To obtain the complete exploitability of a
bug, we also need to analyze the accurate trigger condition, which
could be accomplished through symbolic execution [35]. Actually,
automatically determining the exploitability of a bug is a hot topic
get with challenges, which deserves independent research (e.g., AEG
[11], EvilCoder [32], MAZE [43], and Coppelia [38]). In this paper,
we mainly focus on detecting the existence of a potential security
bug. We may adopt exploitability analysis in the future to reduce
the false-positive rate of IPPO.
8 Related Work
Differential analysis in bug detection. Differential analysis against
similar code snippets is a common practice to detect semantic bugs.
FICS [9] uses machine learning to measure the similarity and differ-
ence among code pieces. Similarly, some research also uses machine
learning to detect bugs in smart contracts [23, 51]. PISan [49] auto-
matically infers the correct API usage-patterns and further detects
API misuse bugs through cross-checking. Juxta [27] could infer high-
level semantics from source code and pick out the implementations
that are inconsistent with the implicit semantics. CRADLE [33] lever-
ages inconsistency checking to detect bugs in deep learning libraries.
Hector [36] and RID [26] detect inconsistent release and refcount
operations through intra-procedural path analysis, while Pex [50]