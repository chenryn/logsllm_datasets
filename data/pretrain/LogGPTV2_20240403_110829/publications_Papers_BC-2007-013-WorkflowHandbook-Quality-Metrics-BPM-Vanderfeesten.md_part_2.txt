area most of the research on business process metrics has been done (Cardoso,
Mendling, Neumann & Reijers, 2006; Gruhn & Laue, 2006, Latva-Koivisto, 2001).
For instance, both (Gruhn & Laue, 2006) and (Cardoso, Mendling, Neumann & Rei-
jers, 2006) consider the adaptation of McCabe's cyclometric number as a complex-
ity metric for business processes. This complexity metric directly measures the
number of linearly independent paths through a program’s source code. In prac-
tice, the industry interpretation of McCabe's cyclomatic complexity thresholds are
the following (Frappier, Matwin, & Mili, 1994): from 1 to 10, the program is simple;
from 11 to 20, it is slightly complex; from 21 to 50, it is complex; and above 50 it is
untestable.
In (Cardoso, 2005a) the Control-Flow Complexity (CFC) metric is defined, which is
also derived from software engineering. The CFC metric evaluates the complexity
introduced in a process by the presence of XOR-split, OR-split, and AND-split con-
structs. For XOR-splits, the control-flow complexity is simply the fan-out of the
split, i.e. CFC (a)= fan-out(a). For OR-splits, the control-flow complexity is 2n-1,
XOR-split
where n is the fan-out of the split. i.e. CFC (a)= 2fan-out(a)-1. For an AND-split, the
OR-split
complexity is simply 1, i.e. CFC (a)= 1. Mathematically, the control-flow com-
AND-split
plexity metric is additive. Thus, it is very easy to calculate the complexity of a proc-
ess, by simply adding the CFC of all split constructs. The greater the value of the
CFC, the greater the overall architectural complexity of a process. This metric was
evaluated in terms of Weyuker’s properties to guarantee that it qualifies as a good
4
QUALITY METRICS FOR BUSINESS PROCESS MODELS
and comprehensive one (Cardoso, 2006). To test the validity of the metric, an ex-
periment has been carried out for empirically validation (Cardoso, 2005b). It was
found that the CFC metric is highly correlated with the control-flow complexity of
processes. This metric can, therefore, be used by business process analysts and
process designers to analyze the complexity of processes and, if possible, develop
simpler processes.
Other researchers, for instance (Latva-Koivisto, 2001), also propose graph complex-
ity metrics, such as the Coefficient of Network Complexity (CNC) or the Complexity
Index (CI), to evaluate business processes. In general, Cardoso et al (Cardoso,
Mendling, Neumann & Reijers, 2006) have identified three different types of busi-
ness process complexity: (i) computational complexity, (ii) psychological complexity,
and (iii) representational complexity.
Modularity
Modularity measures the degree to which a design is split op into several modules.
Our literature review has not provided any business process metric that measures
the modularity of a business process design. This is no surprise regarding the fact
that activites are most often treated as black boxes in business process modeling.
Size
Size simply measures how big a model is. The size of a business process model can
be determined using a measure similar to the number of Lines of Code (LOC) from
software engineering metrics. The LOC metric in software engineering has been
used for years with a significant success rate (Jones 1986). Cardoso et al., Gruhn &
Laue and Latva-Koivisto (Cardoso, Mendling, Neumann & Reijers, 2006; Gruhn &
Laue, 2006; Latva-Koivisto, 2001) all propose to count the number of activities to
establish a measure for size.
While this size metric is very simple, it is very important to complement other forms
of process analysis. For example, the control-flow complexity of a process can be
very low while its activity complexity can be very high. For example, a sequential
process that has a thousand activities has a control-flow complexity of 0, whereas
its activity complexity is 100.
From the "state-of-the-art" in business process metrics, we conclude that this field
of research is just at its start and that there is a lot of potential for further develop-
ment of business process metrics. This classification, which was adopted from the
software engineering field, is not yet very precise. For instance, Mendling uses a
coupling metric as means to calculate complexity (Mendling, 2006) and Latva-
Koivisto, Gruhn & Laue, and Cardoso et al. also use size as a measure for complex-
ity (Cardoso, Mendling, Neumann & Reijers, 2006; Gruhn & Laue, 2006; Latva-
Koivisto, 2001). Perhaps, this classification of business process metrics should be
revised in the future when this area is more mature.
Moreover, we observe that the values for each metric do not yet have a clear mean-
ing, e.g. when the value for coupling for a certain business process model is 0.512
we do not yet know just from the number whether this is high or low, or good or
bad. According to (Cardoso, 2005a) it can take several years and a lot of empirical
research before such a number really makes sense and quantifies the design in a
proper way. Despite this, business process metric analysis in the current situation
still gives the designer some insights and guidance on the quality of the design.
Moreover, we believe in the potential of these metrics and their importance for
business process design in the future.
5
QUALITY METRICS FOR BUSINESS PROCESS MODELS
APPLICATION
Besides the theoretical overview of business process metrics which was provided in
the previous sections, we would also like to give some insight in the practical appli-
cation of these metrics so far. Because this area emerged only recently, there are
only a few applications available, while a lot of new research is ongoing at the mo-
ment of writing this chapter.
The practical applications that we present here mainly have two directions. First of
all, we look at the capabilities of a set of metrics for predicting errors (i.e. we investi-
gate whether there is a relationship between the value of the metrics and the pres-
ence of errors in the business process model). Secondly, we present the early im-
plementation of a tool that supports designing of business process models guided
by these metrics.
Prediction of error probability based on metrics
Among our hypotheses on the use of business process metrics we state that busi-
ness process models which are designed using the business process metrics con-
tain less errors, are easier to understand and maintain. A first step made towards
the empirical validation of this hypothesis is made in a quantitative analysis about
the connection between simple metrics and error probability in the SAP reference
model (Mendling et al, 2006a; Mendling et al, 2006b). The SAP reference model is a
collection of EPC business process models that was meant to be used as a blue-
print for rollout projects of SAP’s ERP system (Keller & Teufel, 1998). It reflects Ver-
sion 4.6 of SAP R/3 which was marketed in 2000. The extensive database of this
reference model contains almost 10,000 sub-models, about 600 of them are EPC
business process models.
The survey reported in Mendling et al (2006a) includes two parts: the verification of
relaxed soundness (which is a minimal correctness criterion for business process
models) and the prediction of error probability based on statistic methods. The veri-
fication of relaxed soundness revealed that about 6 % of the EPC models (34 of 604)
contained errors such as e.g. deadlocks. This result on its own emphasizes the
need for verification tools in business process modeling projects.
In the second part, the authors investigate the question whether errors appear by
chance in a process model, or if there is some way to use business process metrics
to predict the error probability. The hypothesis behind this research is that large
and complex models are more likely to contain errors, basically because the human
modeler is more likely to loose the overview of all interrelations represented in the
model. The authors use a set of simple metrics related to size of the models as input
to a logistic regression model, i.e. a statistical model to predict occurrence or non-
occurrence of an event. The event in this context is whether the process model has
an error or not. The results show that these simple metrics are indeed suitable to
predict the error probability. In particular, it appears that a higher number of join-
connectors is most strongly connected with an increase in error probability.
This survey illustrates one promising application of business process metrics. Still,
there is further research needed to identify more elaborate and sophisticated met-
rics. Moreover, there is a need for further empirical investigation in order to estab-
lish an understanding of when a threshold value of a certain metrics indicates bad
design in terms of maintainability or likely error proneness.
The ProM tool
In recent years ProM has emerged as a broad and powerful process analysis tool,
supporting all kinds of analysis related to business processes (van Dongen et al,
6
QUALITY METRICS FOR BUSINESS PROCESS MODELS
2005). In contrast to many other analysis tools the starting point was the analysis
of real processes rather than modeled processes, i.e., using process mining tech-
niques ProM attempts to extract non-trivial and useful information from so-called
“event logs”. Moreover, ProM also allows for the calculation of several quality met-
rics as will be illustrated later in this section.
Traditionally, most analysis tools focusing on processes are restricted to model-
based analysis, i.e., a model is used as the starting point of analysis. For example,
a purchasing process can be modeled using EPCs and verification techniques can
then be used to check the correctness of the protocol while simulation can be used
to estimate performance aspects. Such analysis is only useful if the model reflects
reality. Process mining techniques use event logs as input, i.e., information re-
corded by systems ranging from enterprise information systems to web services.
Hence the starting point is not a model but the observed reality. Therefore, we use
the phrase “real process analysis” to position process mining with respect to classi-
cal model-based analysis. The widespread use of information systems, e.g., systems
constructed using ERP, WFM, CRM, SCM, and PDM software, resulted in the om-
nipresence of vast amounts of event data. Events may be recorded in the form of
audit trails, transactions logs, or databases and may refer to patient treatments,
order processing, claims handling, trading, travel booking, etc.
Figure 1 is used to explain the different types of process analysis supported by
ProM. First of all, it is relevant to note that when studying business processes one
can look at models (lower left corner) or study the observed behavior (lower right
corner).
Figure 1: Overview of the functionality of ProM: (1) discovery, (2) conformance, and (3)
model analysis
Using process mining it is possible to automatically derive process models using
process mining techniques (van der Aalst, Weijters & Maruster, 2004). ProM offers
many process discovery techniques. The result may be a Petri net, EPC, or YAWL
model. Figure 1 shows some of the modeling notations supported by ProM and also
mentions some of the products that provide event logs in a format usable by ProM.
Also the list of languages suggests a focus on pure process models, discovery does
not need to be limited to control-flow and may also include temporal, resource,
data, and organizational aspects.
If a model is already given, the information stored in logs can be used to check con-
formance, i.e., how well do reality and the model fit together. This can be seen as
another quality dimension. Conformance checking requires, in addition to an event
log, some a-priori model. This model may be handcrafted or obtained through proc-
7
QUALITY METRICS FOR BUSINESS PROCESS MODELS
ess discovery. Whatever its source, ProM provides various ways of checking
whether reality conforms to such a model (Rozinat & van der Aalst, 2006). For ex-
ample, there may be a process model indicating that purchase orders of more than
one million Euro require two checks. Another example is the checking of the so-
called "four-eyes principle''. Conformance checking may be used to detect devia-
tions, to locate and explain these deviations, and to measure the severity of these
deviations.
Last but not least, ProM also provides various ways of model analysis. ProM offers
various plug-ins to analyze the correctness of a model, e.g., soundness and absence