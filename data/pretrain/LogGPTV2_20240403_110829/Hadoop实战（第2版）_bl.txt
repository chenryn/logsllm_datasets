对于大多数查询Query, Hive编译器会产生MapReduce任务，这些任务会被提交到MapReduce集群，这些集群可以用参数mapred.job.tracker指明。
需要说明的是，Hadoop支持在本地或集群中运行Hive提交的查询，这对小数据集查询的运行是非常有用的，可以避免将任务分布到大型集群中而降低效率。在将MapReduce任务提交给Hadoop之后，HDFS中的文件访问对用户来说是透明的。相反，如果是大数据集的查询，那么需要设定将Hive的查询交给集群运行，这样就可以利用集群的并行性来提高效率。我们可以通过以下参数设定Hive查询在本地运行：
hive＞SET mapred.job.tracker=local；
最新的Hive版本都支持在本地自动运行MapReduce任务：
hive＞SET hive.exec.mode.local.auto=false；
可以看到该属性默认是关闭的。如果设定为开启（enable），Hive就会先分析查询中的每个MapReduce任务，当任务的输入数据规模低于Hive.exec.mode.local.auto.inputb-ytes.max属性值（默认为128MB），并且全部的Map数少于hive.exec.mode.local.auto.tasks.max的属性值（默认为4），全部的Reduce任务数为1或0时，任务会自动选择在本地模式下运行。
4.Error Logs错误日志
Hive使用log4j记录日志。在默认情况下，日志文件的记录等级是WARN（即存储紧急程度为WARN及以上的错误信息），存储在/tmp/{user.n-ame}/hive.log文件夹下。如果用户想要在终端看到日志内容，则可以通过设置以下参数达到目的：
bin/hive-hiveconf hive.root.logger=INFO, console
同样，用户也可以改变日志记录等级：
bin/hive-hiveconf hive.root.logger=INFO, DRFA
Hive在Hadoop执行阶段的日志由Hadoop配置文件配置。通常来说，Hadoop会对每个Map和Reduce任务对应的执行节点生成一个日志文件。这个日志文件可以通过JobTracker的Web UI获得。错误日志对调试错误非常有用，当运行过程中遇到Bug时可以向PI:EMAIL提交。
11.3 Hive QL详解
 11.3.1 数据定义（DDL）操作
1.创建表
下面是在Hive中创建表（CREATE）的语法：
CREATE[EXTERNAL]TABLE[IF NOT EXISTS]table_name
[（col_name data_type[COMMENT col_comment]，……）]
[COMMENT table_comment]
[PARTITIONED BY（col_name data_type[col_comment]，col_name data_type[COMMENT
col_comment]，……）]
[CLUSTERED BY（col_name, col_name，……）[SORTED BY（col_name，……）]INTO num_
buckets BUCKETS]
[ROW FORMAT row_format]
[STORED AS file_format]
[LOCATION hdfs_path]
[AS select_statement]（Note：this feature is only available on the latest trunk
or versions higher than 0.4.0.）
CREATE[EXTERNAL]TABLE[IF NOT EXISTS]table_name
LIKE existing_table_name
[LOCATION hdfs_path]
data_type
：primitive_type
|array_type
|map_type
primitive_type
：TINYINT
|SMALLINT
|INT
|BIGINT
|BOOLEAN
|FLOAT
|DOUBLE
|STRING
array_type
：ARRAY＜primitive_type＞
map_type
：MAP＜primitive_type, primitive_type＞
row_format
：DELIMITED[FIELDS TERMINATED BY char][COLLECTION ITEMS TERMINATED BY char]
[MAP KEYS TERMINATED BY char]
|SERDE serde_name[WITH SERDEPROPERTIES property_name=property_value, property_
name=property_value，……]
file_format：
：SEQUENCEFILE
|TEXTFILE
|INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname
下面进行相关的说明。
CREATE TABLE，创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常，用户可以用IF NOT EXIST选项来忽略这个异常。
EXTERNAL关键字，创建一个外部表，在创建表的同时指定一个指向实际数据的路径（LOCATION）。在Hive中创建内部表时，会将数据移动到数据仓库指向的路径；在创建外部表时，仅记录数据所在的路径，不对数据的位置做任何改变。当删除表时，内部表的元数据和数据会一起被删除，而在删除外部表时只删除元数据，不删除数据。
LIKE格式修饰的CREATE TABLE命令允许复制一个已存在表的定义，而不复制它的数据内容。
这里还需要说明的是，用户可以使用自定制的SerDe或自带的SerDe创建表。SerDe是Serialize/Deserilize的简称，用于序列化和反序列化。在Hive中，序列化和反序列化即在key/value和hive table的每个列值之间的转化。如果没有指定ROW FORMAT或ROW FORMAT DELIMITE-D，创建表就使用自带的SerDe。如果使用自带的SerDe，则必须指定字段列表。关于字段类型，可参考用户指南的类型部分。定制的SerDe字段列表可以是指定的，但是Hive将通过查询SerDe决定实际的字段列表。
如果需要将数据存储为纯文本文件，那么要使用STORED AS TEXTFILE。如果数据需要压缩，则要使用STORED AS SEQUENCEFILE。INPUTFORMAT和OUTPUTFORMAT定义一个与InputFormat和OutputFormat类相对应的名字作为一个字符串，例如，将“org.apache.hadoop.hive.contrib.fileformat.base64”定义为“Base64TextInputFormat”。
Hive还支持建立带有分区（Partition）的表。有分区的表可以在创建的时候使用PARTITIONED BY语句。一个表可以拥有一个或多个分区，每个分区单独存在于一个目录下。而且，表和分区都可以对某个列进行CLUSTERED BY操作，将若干个列放入一个桶（Bucket）中。也可以利用SORT BY列来存储数据，以提高查询性能。
表名和列名不区分大小写，但SerDe和属性名是区分大小写的。表和列的注释分别是以单引号表示的字符串。
下面通过一组例子来对CREATE命令进行介绍，以加深用户的理解。
例1：创建普通表
下面代码将创建page_view表，该表包括viewTime、userid、page_url、referrer_url和ip列。
CREATE TABLE page_view（viewTime INT, userid BIGINT，
page_url STRING, referrer_url STRING，
ip STRING COMMENT'IP Address of the User'）
COMMENT'This is the page view table'；
例2：添加表分区
下面代码将创建page_view表，该表所包含字段与例1中page_view表相同。此外，通过Partition语句为该表建立分区，并用制表符来区分同一行中的不同字段。
CREATE TABLE page_view（viewTime INT, userid BIGINT，
page_url STRING, referrer_url STRING，
ip STRING COMMENT'IP Address of the User'）
COMMENT'This is the page view table'
PARTITIONED BY（dt STRING, country STRING）
ROW FORMAT DELIMITED
FIELDS TERMINATED BY'\001'
STORED AS SEQUENCEFILE；
例3：添加聚类存储
下面代码将创建page_view表，该表所包含字段与例1中page_view表相同。在page_view表分区的基础上增加了聚类存储：将列按照userid进行分区并划分到不同的桶中，按照viewTime值的大小进行排序存储。这样的组织结构允许用户通过userid属性高效地对集群列进行采样。
CREATE TABLE page_view（viewTime INT, userid BIGINT，
page_url STRING, referrer_url STRING，
ip STRING COMMENT'IP Address of the User'）
COMMENT'This is the page view table'
PARTITIONED BY（dt STRING, country STRING）
CLUSTERED BY（userid）SORTED BY（viewTime）INTO 32 BUCKETS
ROW FORMAT DELIMITED
FIELDS TERMINATED BY'\001'
COLLECTION ITEMS TERMINATED BY'\002'
MAP KEYS TERMINATED BY'\003'
STORED AS SEQUENCEFILE；
例4：指定存储路径
到目前为止，在所有例子中，数据都默认存储在HDFS的＜hive.metastore.warehouse.dir＞/＜table＞目录中，它在Hive配置的文件hive-site.xml中设定。我们可以通过Location为表指定新的存储位置，如下所示：
CREATE EXTERNAL TABLE page_view（viewTime INT, userid BIGINT，
page_url STRING, referrer_url STRING，
ip STRING COMMENT'IP Address of the User'，
country STRING COMMENT'country of origination'）
COMMENT'This is the staging page view table'
ROW FORMAT DELIMITED FIELDS TERMINATED BY'\054'
STORED AS TEXTFILE
LOCATION'＜hdfs_location＞'；
2.修改表语句
ALTER TABLE语句用于改变一个已经存在的表的结构，比如增加列或分区，改变SerDe、添加表和SerDe的属性或重命名表。
（1）重命名表
ALTER TABLE table_name RENAME TO new_table_name
这个命令可以让用户为表更名。数据所在的位置和分区名并不改变。换而言之，旧的表名并未“释放”，对旧表的更改会改变新表的数据。
（2）改变列名字/类型/位置/注释
ALTER TABLE table_name CHANGE[COLUMN]
col_old_name col_new_name column_type
[COMMENT col_comment]
[FIRST|AFTER column_name]
这个命令允许用户修改列的名称、数据类型、注释或位置，例如：
CREATE TABLE test_change（a int, b int, c int）；
ALTER TABLE test_change CHANGE a a1 INT；//将a列的名字改为a1
ALTER TABLE test_change CHANGE a a1 STRING AFTER b；
//将a列的名字改为a1，a列的数据类型改为string，并将它放置在列b之后
修改后，新的表结构为：b int, a1 string, c int。
ALTER TABLE test_change CHANGE b b1 INT FIRST；
//会将b列的名字修改为b1，并将它放在第一列
修改后，新表的结构为：b1 int, a string, c int。
注意 列的改变只会修改Hive的元数据，而不会改变实际数据。用户应该确保元数据定义和实际数据结构的一致性。
（3）增加/更新列
ALTER TABLE table_name ADD|REPLACE
COLUMNS（col_name data_type[COMMENT col_comment]，……）
ADD COLUMNS，允许用户在当前列的末尾、分区列之前增加新的列。REPLACE COLUMNS，删除当前的列，加入新的列。只有在使用native的SerDE（DynamicSerDe或MetadataTypeColumnsetSerDe）时才可以这么做。
（4）增加表属性
ALTER TABLE table_name SET TBLPROPERTIES table_properties
table_properties：
：（property_name=property_value, property_name=property_value，……）
用户可以用这个命令向表中增加元数据，目前last_modified_user、last_modified_time属性都是由Hive自动管理的。用户可以向列表中增加自己的属性，可以使用DESCRIBE EXTENDED TABLE来获得这些信息。
（5）增加SerDe属性
ALTER TABLE table_name
SET SERDE serde_class_name
[WITH SERDEPROPERTIES serde_properties]
ALTER TABLE table_name
SET SERDEPROPERTIES serde_properties
serde_properties：
：（property_name=property_value，
property_name=property_value，……）
这个命令允许用户向SerDe对象增加用户定义的元数据。Hive为了序列化和反序列化数据，将会初始化SerDe属性，并将属性传给表的SerDe。这样，用户可以为自定义的SerDe存储属性。