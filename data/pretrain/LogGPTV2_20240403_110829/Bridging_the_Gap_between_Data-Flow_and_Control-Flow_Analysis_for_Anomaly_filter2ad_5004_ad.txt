u
N
160
120
80
40
0
152
143
125
154
91
68
37
0
0
40
5 10 15 20 25
Log File Consumed (hour)
35
30
88
91
93
93
72
47
111
115
117
118
88
52
140
120
100
80
60
40
20
0
s
t
n
e
m
e
t
a
t
S
f
o
r
e
b
m
u
N
31
0
0
5
10
40
Log File Consumed (hour)
35
30
25
20
15
10
5
40
Log File Consumed (hour)
35
30
25
20
15
(a) Rule Set A
(b) Rule Set B
(c) Rule Set C
Figure 5. Speed of Convergence
Figure 5 suggests that using 24 hours of logs of a pro-
duction web server (113,732 http requests) is sufﬁcient to
learn more than 90% of the rules. By performing this train-
ing using a desktop computer with a 2.2 GHz CPU and 1
GB of memory, this training (un-optimized) takes about 12
hours. Note that this training can be done off-line.
4.6 Overhead in online monitoring
In this part, we show the overhead of our system when
it is implemented for online monitoring of system calls of a
399399
production web server. We host the web server on a desk-
top computer with a 2.2 GHz CPU and 1 GB of memory.
The computer runs the Linux operating system with kernel
2.6.22 and the Apache2 web server. The kernel is instru-
mented to intercept system calls made by the web server
for real-time monitoring. Statements in the three Rule Sets
are obtained by training 36 hours of logs of the Singapore
Management University web server.
We use a program to simulate single or multiple clients
sending http requests to the web server. Each client reads
one entry from the log ﬁle at a time and then sends the re-
quest to the web server. Each client was conﬁgured to send
requests with 10 milliseconds interval and each run last 60
seconds. To evaluate the monitoring overhead, we measure
the latency experienced by the client. Latency is deﬁned as
the difference between the time when a http request is sent
and the time when the client receives a response from the
server. Note that our simulated client is located in the same
Local Area Network as the web server is. We run a few
tests, each with a different number of concurrent clients.
The average latency for each test is presented in Figure 6.
(cid:20)(cid:19)(cid:19)(cid:19)
)
c
e
s
m
(
y
c
n
e
t
a
l
e
g
a
r
e
v
A
(cid:20)(cid:19)(cid:19)
(cid:20)(cid:19)
(cid:20)
(cid:20)
Running Server Only
Monitoring Argument Values
(cid:23)
(cid:21)
(cid:22)(cid:21)
Number of concurrent clients
(cid:20)(cid:25)
(cid:27)
(cid:25)(cid:23)
Figure 6. Average latency experienced
Results show that our monitoring system adds 5 to 8 mil-
liseconds on average to the latency when there are less than
(or equal to) 8 concurrent clients. When the number of con-
current clients increases to 64, the clients experience an ad-
ditional 75-millisecond of latency on average. Such addi-
tional latency is hardly noticeable by human beings. Also
note that the results presented in Figure 6 are latencies mea-
sured by clients on the same Local Area Network of the
server. Considering the latency suffered by clients over the
Internet, which is typically at least a few hundred millisec-
onds2, the additional latency caused by our real-time moni-
toring accounts for a comparatively minor part.
5 Related work
Control-ﬂow information, associated with system call
sequences emitted by the application being monitored, has
been used in the literature to combat intrusions. To improve
Forrest et al.´s model [6] of ﬁxed-length patterns, Wespi et
al. introduced variable-length patterns to better describe the
2For example, we measured the latency between a machine on our cam-
pus network and the web server of www.yahoo.com. Results were be-
tween 569 milliseconds and 576 milliseconds in 15 runs.
400400
application behavior [19, 20]. Static analysis techniques
were introduced by Wagner et al. [17] to thoroughly ex-
plore all possible executions of the application. Sekar’s
FSA model [13] utilized program counter information to
capture both short term and long term temporal relations of
system calls, while Gao’s [8] and Feng’s [5] models relied
on the call stack information to extract paths of the program
executions. All of these approaches, and many others, make
use of system call sequence information but the dataﬂow
among the arguments are missing, which leads to the possi-
bility of evasion attacks, such as mimicry attack [8, 18].
In data-ﬂow analysis detectors, there has been previous
work on utilizing system call arguments. Kruegel et al. con-
structed models based on the characteristics, e.g., the length
of strings, string character distribution, and structural in-
ference, of system call arguments [11]. The model returns
the probability that a system call argument has the corre-
sponding value during detection. Low probabilities indi-
cate potential attacks. While their work emphasized on the
characteristics of each single argument, inter-relationships
among the arguments are not explored. To enhance an IDS
to combat mimicry attacks, Sufatrio et al. proposed a sim-
ple extension that incorporates system call arguments and
process privileges [14]. They abstracted the values by cate-
gorizing them into classes that are deﬁned by user-supplied
category speciﬁcations. However, their abstraction rendered
the relationship among the system call arguments not ex-
aminable. Tandon et al. integrated arguments and attributes
of system calls into their LERAD system with a ﬁxed-size
window and focused on the value set allowed for each argu-
ment [15,16]. Bhatkar et al. managed to extract rules on sys-
tem call arguments by analyzing the data-ﬂow in a control-
ﬂow context [2]. However, the only information they em-
ployed from control-ﬂow context was the program counter.
On the other hand, our approach leverage the results from
control-ﬂow analysis, in particular, system call patterns that
partition long system call sequences into sub-sequences that
correspond to small tasks performed, to learn more accurate
and useful rules that cannot be learned in prior approaches.
Association rule mining techniques that help discover
rules from a large database of transactions [1, 21] are also
related to our work. Association rule mining has many ap-
plications, e.g., in making business decisions such as what
to put on sale, how to design coupons, etc. The problem of
association rule mining is closely related to learning rules
governing system call arguments and return values in that
both are trying to ﬁnd relations among a large data set. Un-
like the ad hoc approaches taken by previous work on sys-
tem call argument, we adopt the ideas in well-studied asso-
ciation rule mining techniques in time series and apply them
to learn rules governing system call arguments and return
values with moderate modiﬁcations and generalization.
[10] D. Gao, M. K. Reiter, and D. Song. Behavioral distance
measurement using Hidden Markov Models. In Proceedings
of the 9th International Symposium on Recent Advances in
Intrusion Detection (RAID 2006), 2006.
[11] C. Kruegel, D. Mutz, F. Valeur, and G. Vigna. On the detec-
tion of anomalous system call arguments. In In Proceeding
of ESORICS 2003, 2003.
[12] I. Rigoutsos and A. Floratos. Combinatorial pattern discov-
ery in biological sequences the teiresias algorithm. In Bioin-
formatics, 14(1):55-67, 1998.
[13] R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni. A fast
automaton-based method for detecting anomalous program
behaviors. In Proceedings of the 2001 IEEE Symposium on
Security and Privacy, 2001.
[14] Sufatrio and R. H. C. Yap. Improving host-based ids with ar-
gument abstraction to prevent mimicry attacks. In Proceed-
ings of the 8th International Symposium on Recent Advances
in Intrusion Detection, 2005.
[15] G. Tandon and P. Chan. Learning rules from system calls
arguments and sequences for anomaly detection. In ICDM
Workshop on Data Mining for Computer Security (DMSEC),
Melbourne, FL, 2003.
[16] G. Tandon and P. Chan. Learning useful system call at-
tributes for anomaly detection. In Proceedings of the 18th
International FLAIRS Conference, 2005.
[17] D. Wagner and D. Dean. Intrusion detection via static anal-
In 2001 IEEE Symposium on Security and Privacy,
ysis.
2001.
[18] D. Wagner and P. Soto. Mimicry attacks on host based in-
trusion detection systems. In Proceedings of the 9th ACM
Conference on Computer & Communication Security (CCS
2002), 2002.
[19] A. Wespi, M. Dacier, and H. Debar. An intrusion-detection
system based on the teiresias pattern-discovery algorithm.
In Proceedings of the 1999 European Institute for Computer
Anti-Virus Research Conference, 1999.
[20] A. Wespi, M. Dacier, and H. Debar. Intrusion detection us-
ing variable-length audit trail patterns. In Proceedings of the
3rd International Symposium on Recent Advances in Intru-
sion Detection, 2000.
[21] M. J. Zaki. Generating non-redundant association rules. In
Proceedings of the 6th ACM SIGKDD International Confer-
ence on Knowledge Discovery and Data Mining, 2000.
6 Conclusion and future work
In this paper we propose a new model for data-ﬂow anal-
ysis for intrusion detection, which leverage the results from
control-ﬂow analysis to learn more accurate and useful rules
among system call arguments and return values. To the
best of our knowledge, this is the ﬁrst paper that tries to
bridge the gap between data-ﬂow and control-ﬂow analysis
for intrusion detection. Through trace-driven evaluations,
we show that our technique is not only able to detect real
attacks with low false alarm rates, but also capable to learn-
ing new rules that are useful in intrusion detection.
In our future work, we would like to design a more del-
icate way of grouping system calls and their arguments so
that the number of non-signiﬁcant rules could be reduced.
We also would like to generate statements of form more
complicated than equality, to enrich the proﬁle in our model
to achieve greater accuracy and scalability. Moreover, by
assigning different weights to rules in different sets, we
would try to further improve the accuracy of our system.
References
[1] R. Agrawal, T. Imielinski, and A. Swami. Mining associa-
tion rules between sets of items in large databases. In Pro-
ceedings of 1993 ACM-SIGMOD International Conference
on Management of Data, 207-216. Washington, D.C, 1993.
[2] S. Bhatkar, A. Chaturvedi, and R. Sekar. Dataﬂow anomaly
detection. In Proceedings of the 2006 IEEE Symposium on
Security and Privacy, 2006.
[3] H. Chen, D. Dean, and D. Wagner. Model checking one
million lines of c code. In Proceedings of the 11th Annual
Network and Distributed System Security Symposium NDSS,
2004.
[4] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer. Non-
control-data attacks are realistic threats. In Proceedings of
the 14th conference on USENIX Security Symposium, 2006.
[5] H. Feng, O. Kolesnikov, P. Fogla, and W. Lee. Anomaly de-
tection using call stack information. In Proceedings: IEEE
Symposium on Security and Privacy. Berkeley, California,
2003.
[6] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Longstaff.
A sense of self for unix processes.
In Proceedings of the
1996 IEEE Symposium on Security and Privacy, pages 120-
128, Los Alamitos, CA, 1996.
[7] D. Gao, M. K. Reiter, and D. Song. Gray-box extraction of
execution graphs for anomaly detection. In Proceedings of
the 11th ACM Conference on Computer & Communication
Security (CCS 2003), 2003.
[8] D. Gao, M. K. Reiter, and D. Song. On gray-box program
tracking for anomaly detection. In Proceedings of the 13th
USENIX Security Symposium, 2004.
[9] D. Gao, M. K. Reiter, and D. Song. Behavioral distance
for intrusion detection. In Proceedings of the 8th Interna-
tional Symposium on Recent Advances in Intrusion Detec-
tion (RAID 2005), 2005.
401401