(cid:119) in
concatenation vector (cid:21).
2: begin
3:
4:
for discrete time instant (cid:119) = 1(cid:62) 2(cid:62) · · · do
Get ongoing observations and their corresponding
measurement stream (cid:99).
Generate action (cid:120)(cid:108)
(cid:119) according to the speciﬁc detection
scheme and deﬁnition 2.
The coordinator broadcasts the reward signal (cid:117)(cid:119).
Update (cid:116)(cid:108)
(cid:119)+1 according to equation (6) and (10):
5:
6:
7:
Figure 2. Experiment Procedure
8:
9:
10:
11:
if the previous actions is “Observe” (i.e., (cid:120)(cid:119) = 0)
(cid:119) (cid:51) 1
(cid:103)(cid:108)
(cid:119)
((cid:99)) .
(cid:119)+1 = (cid:29) · (cid:116)(cid:108)
(cid:116)(cid:108)
else
(cid:119)+1 = (cid:29) · (cid:116)(cid:108)
(cid:116)(cid:108)
(cid:119)
+
(cid:42)((cid:37)(cid:119))
((cid:99))(1(cid:51)(cid:42)((cid:37)(cid:119))) .
(cid:103)(cid:108)
(cid:119)
end if
Update (cid:21)(cid:108)
(cid:119)+1 = (cid:21)(cid:108)
(cid:21)(cid:108)
end for
(cid:119)
12:
13:
14:
15:
16: end
(cid:119)+1 according to equation (5):
+ (cid:31)(cid:119) · (cid:117)(cid:119) · (cid:116)(cid:108)
(cid:119)+1.
(cid:119), with (cid:116)(cid:108)
Note that (cid:117)(cid:119) in equation (6) is the sum of rewards that
have been received, and (cid:116)(cid:108)
(cid:119) is a trace of the same dimen-
0 = 0; (cid:29) (cid:53) [0(cid:62) 1) is a free parameter
sionality as (cid:21)(cid:108)
to control both the bias and the variance of the estimates
produced by the algorithm. It has been shown that [2] pro-
vided the bias is sufﬁciently small, it will converge to a re-
gion of near-zero gradient, which thus can be extended to
the multi-detector environment, and the algorithm does not
need access to the underlying state and does not make use
of recurrent states.
4 Performance Veriﬁcation
This section describes the evaluation of our proposed
ADC prototype, and the general evaluation procedure is
shown in ﬁgure 2. Speciﬁcally, the procedure mainly in-
cludes following steps:
Step 1. To train the individual ADs with training data set 1,
which only contains normal data, to get their initial param-
eters and create normal proﬁles in their respective operating
environments.
Step 2.To train the ADC with training data set 2 (only pure
normal data, or mixed with some known anomalies). This
step can be combined with step 1 if some satisﬁed data with
controllable property are available.
Step 3. After the ADC achieved a stable state through step
2, testing set (collected data with some artiﬁcial anomalies)
is used to evaluate its performance it terms of detection ac-
curacy and false alarms.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:53:20 UTC from IEEE Xplore.  Restrictions apply. 
Data Category\Source
No. of Command Lines No. of Audit Events No. of Processes
Table 2. Statistics of the Data Source
Training Set (Normal)
Normal Data
Testing Set Masquerader
Other Attacks
5,600
5,640
2127
no trail
62,100
70,780
850
uncounted
640
690
272
35
4.1 Experiment Scenario and Data Collection
Table 3. Attacks List in the Experiments
An intrusion instance is exempliﬁed in the following
to show the operating scenario of our ADC. A keyboard
masquerader or remote interloper takes control of a termi-
nal/host, and then takes advantage of the legitimate user’s
privileges and access to system programs and data. The in-
truder may attempt to read or write access to private data,
acquire unauthorized system privileges (or even abuse of
legitimate privileges), and install some softwares such as
Trojan for further malicious behavior. For the sophisticated
intruder with knowledge of AD installed in target terminal,
he might take some seeming legal tricks to surpass the de-
tection coverage. In such activity, the intruder leaves trace
data, in various forms, to victim terminal, such as shell
command lines (especially for keyboard masquerader) with
corresponding audit events, privilege processes with system
calls, etc. The ADC is thus expected to detect those anoma-
lies during the malicious attacks based on the trace data.
To the best of our knowledge, there is no true trace data
in the open literature that meets our experimental demands.
Therefore, we have to collect, combine and formulate our
own experimental data with some particular considerations.
For the sake of simplicity, all the basic ADs we employe are
initialized with the parameters in their original literature; in
other words, the ﬁrst step is omitted in our experiment. To
formulate training data set 2 and the testing data, we have
collected normal activities ourselves for four weeks using
the Solaris 8.0 operating system (SunOS release 5.0), mixed
with several known typical host-based attacks.
We usually use text editor (vi, ed, etc.), compiler(gcc,
cc, etc.), and some system programs(ps, lpr, sendmail etc.)
on our machine SunBlade 1500. Excluding wrong com-
mands and some noisy data, while keeping repeated ones,
we obtained a total of 132,886 records of BSM audit data
and 11,240 shell command lines (using the shell .history ﬁle
to log all truncated commands without additional informa-
tion), and these data were roughly averaged as part of pure
training set and as testing set. Note that during the collec-
tion of shell command lines, we also recorded the corre-
sponding audit events and executed processes in terms of
system calls, as BSM provides the monitor of the execution
of system calls by all processes launched by the user. How-
ever, considering the processes in user mode usually cannot
Attack Category
Attack Description
Masquerader
access to programs and data as an
imposter by controlling the keyboard
xlock heap buffer overﬂow vulnerability
Buffer Overﬂow eject buffer overﬂow vulnerability
lpset buffer overﬂow vulnerability
Exhausting Disk Space (with dd)
DoS
Exhausting the Memory
Consumption of process table
# of Cases
850
commands
2
3
3
2
1
2
harm the system security, we only recorded those processes
in kernel model that require services from system kernel. In
addition, it is well known that buffer overﬂow, S/W secu-
rity error, conﬁguration error and DoS attacks are several
prevalent host-based attacks, so we injected several cases
of them (audit data that contain labelled attacks), including
8 cases of local buffer overﬂow and 5 cases of DoS, into
the testing data. Meanwhile, a small batch of another user’s
commands history (2127 audit events, 850 command lines,
and 272 processes) were also added into the testing set as
a masquerader trace data. Table 2 and table 3 shows the
experimental data we used in detail.
4.2 Experimental Results and Analysis
All the basic ADs’ initial parameters we used were di-
rectly derived from their original version (as shown in Table
4) without training. Thus, the parameter vector (cid:21) is a ma-
trix with size (cid:81) × (cid:80) , where (cid:80) is the number of elemental
ADs, (cid:81) is the number of controllable parameters, and the
Table 4 can be denoted as following in terms of (cid:21)0, which is
the initial state of the coordinator. But in actual experiment,
we only adjust the ﬁrst row of (cid:21), i.e., (cid:81) = 1(cid:62) (cid:80) = 4.
µ
¶
(cid:21)0 =
0(cid:61)45 0(cid:61)80 0(cid:61)60 0(cid:61)72
0
30
10
6
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:53:20 UTC from IEEE Xplore.  Restrictions apply. 
Table 4. Parameters of Basic ADs
* ’L’ denotes Sequence Length, ’(cid:24)’ is the threshold
MCE Markov Chain
STIDE
KNN
(cid:79)
(cid:24)
30
0.45
10
0.80
6(LFC=20)
variable
0.6
0.72
15
10
5
0
l
s
m
r
a
A
e
s
a
F
l
l
i
a
g
n
S
d
r
a
w
e
R
−5
−10
−15
0
50
100
150
250
200
Training Epochs
300
350
400
450
500
Figure 3. Reward Signal During Training
4.2.1 Training Procedure
The goal of the training procedure is to achieve an optimal
control strategy of the ADC. As shown in table 2, all 5,600
command tokens were used to create a distribution-based
behavioral model for MCE. Corresponding audit events
and processes were also used to create normal proﬁles for
Markov Chains, STIDE, and KNN respectively. Since the
amount of the available data are limited, we used joint sets
to train ADC, in detail, half of training data were inter-
leaved with half of testing data (altogether 5,620 command
tokens, 66,400 audit events, and 660 processes) to train the
ADC. As every login session (i.e., from login to logout)
contains about 30 command tokens, for simplicity, we used
a constant window to partition command tokens, with cor-
responding audit events and system calls. Hence, a total
b 5620
30 c = 187 commands blocks were available. Corre-
sponding audit events and system calls that executed by pro-
cesses were also extracted as input into respective ADs. The
baseline of the ADC detection measurement is command
blocks, which has no so exact mapping with their underly-
ing audit events and processes. Therefore, Markov Chain,
STIDE and KNN would generate a report sequence rather
than a single report at every decision step, based on their
respective detection measurement and parameters.
In this experiment, ADC makes decision at every com-
mand trace, and according to deﬁnition 3, since A(cid:113) and A(cid:100)
would never appear in the normal training set, for a pursued
 MCE
ADC
0.07
0.06
0.05
e
t
a
R
l
l
t
r
e
A
e
s
a
F
e
g
a
r
e
v
A