for j ← start to end do
if i (cid:54)= 0 and j (cid:54)= 0 then
distance ← dp(A[i − 1], B[j − 1])
lef t ← matrix[i][j − 1] + distance
up ← matrix[i − 1][j] + distance
diag ← matrix[i − 1][j − 1] + distance
m[i][j] ← min(lef t, up, diag))
end if
end for
end for
return m[|A|][|B|]/(|A| + |B|)
on either side of the “diagonal” are evaluated.
Algorithm 1 shows the dynamic time warping pro-
cedure using the restricted warping path from our vari-
able sampling rate heuristic3. For ease of presentation,
we provide as input to the algorithm lists containing the
two time series A and B, the mapping between indices
in A and their “diagonal” mapping in B, a list contain-
ing the slope values to be used to ensure continuity of
the matrix slope4, and the multiplicative factor c that
controls the number of cells evaluated around the “di-
agonals.” As with any dynamic programming technique,
the minimum distance for the allowable warping path
3Note that this algorithm can be easily altered so that only two rows
in the matrix are maintained in memory at any given time, thereby
reducing the space complexity to O(|B|).
4In practice, there are actually two lists – a forward and backward
list – to accommodate for cases where the point is at the beginning or
end of a subsequence.
BBBBBBBABAAAAA12345678123456BBBBBBBABAAAAA12345678123456is given in the lower-right cell of the matrix. Further-
more, in order to ensure the computed warping distances
are comparable among time series of varying lengths,
we normalize the distance by dividing by the number of
cells in the longest possible warp path |A| + |B|, which
also ensures that the distance remains symmetric. We
use this normalized distance to compare the behaviors
of hosts and determine their similarity. The computa-
tional complexity of our proposed heuristic is O(|B|∗ c)
in the worst case where both series A and B are of equal
length, which represents a signiﬁcant reduction from the
quadratic complexity required when evaluating the en-
tire dynamic programming matrix.
5 Evaluation
The underlying hypothesis behind the behavioral dis-
tance metric proposed in the previous section is that the
semantics of the network data and long-term sequences
of activities provide a more robust notion of host behav-
ior than measures that ignore such information. To eval-
uate this hypothesis, we compare our proposed dynamic
time warp (DTW) metric to the well-known L1 distance
metric, which does not explicitly capture semantic and
sequencing information. The experiments in our evalu-
ation compare these two metrics using a broad range of
analysis methodologies on a large dataset collected on a
live network segment in an effort to pinpoint the beneﬁts
of our approach over naive metrics.
We begin by measuring the trade-off between speed
and accuracy of our dynamic time warping-based dis-
tance calculation under varying settings of the multi-
plicative window parameter c. Using the results from
this experiment, we choose a window that provides a
balance between ﬁdelity and speed, and show that our
approach is feasible even on datasets containing mil-
lions of ﬂows. Next, we compare our approach to a met-
ric that ignores semantics and sequencing. In particular,
we examine the clusters produced by a variety of clus-
ter analysis techniques when using L1 distance and our
proposed DTW metric. Moreover, we look at the con-
sistency of these behaviors across consecutive days of
observation to show that our approach captures the most
robust notion of network behaviors. Finally, we exam-
ine a concrete application of our metric to the problem
of quantifying privacy of network hosts, and show how
it enables application of well-known privacy deﬁnitions,
such as the notion of (c, t)-isolation deﬁned by Chawla
et al. [6].
Data.
In our evaluation, we make use of a dataset con-
taining uni-directional ﬂow records collected within the
Computer Science and Engineering department of the
University of Michigan. The CSE dataset, as we refer to
it throughout this section, was collected over two con-
secutive twenty-four hour periods, and captures all local
and outbound trafﬁc from a single /24 subnet. The data
contains 137 active hosts that represent a broad mix of
network activities, including high-trafﬁc web and mail
servers, general purpose workstations, and hosts running
specialized research projects. The relatively small num-
ber of hosts allows us to manually verify the behavioral
information with system and network administrators at
the University of Michigan. Table 1 provides a summary
of the trafﬁc within the CSE dataset on each of the ob-
served days.
Number of Hosts:
Total Flows:
Avg. Flows per Host:
Median Flows per Host:
Max Flows per Host:
Day 1
135
14,400,974
106,674
4,670
6,357,810
Day 2
137
16,249,269
118,608
2,955
6,620,785
Table 1. Trafﬁc properties for both days of
the University of Michigan CSE dataset.
Throughout all of our experiments, we consider six
ﬁelds within the ﬂow log data: start time, ﬂow size,
source IP and port, and destination IP and port. These
ﬁelds are associated with the appropriate distance met-
rics and used to measure behavioral distance according
to the dynamic time warping procedure outlined in the
previous section, except for instances where we explic-
itly make use of an alternate distance metric. Further-
more, we remove all non-TCP trafﬁc from the dataset in
an effort to minimize noise and backscatter caused by
UDP and ICMP trafﬁc. We note that since we are ex-
amining ﬂow data, the use of TCP trafﬁc should not un-
fairly bias our analysis since causal relationships among
the ﬂows will likely be dictated by application-layer pro-
tocols or other higher-order behaviors of the host.
Finally, we performed an initial analysis of the data
using k-means clustering in combination with our DTW
metric to pinpoint a variety of scanning activities, in-
cluding pervasive Nessus scans [21] from two hosts
within the CSE network and several IPs from China per-
forming ﬁngerprinting on CSE hosts. These scanning
hosts were removed from the data to ensure that we fo-
cus our analysis on legitimate forms of network behav-
iors that may be veriﬁed via the University of Michigan
CSE department’s system and network administrators.
The speciﬁcs of this technique are discussed in Section
5.2, but the fact that our method was able to pinpoint
these scanning activities is interesting in and of itself.
5.1 Efﬁciency
Network datasets collected on real-world networks
may contain millions of records. As such, it is important
to understand the efﬁciency of our proposed metric and
Window Parameter c
Avg. Time per Warp
in seconds (σ)
Avg. Distance Increase
in percentage (σ)
25
50
100
200
500
1.0 (5.5)
1.8 (10.1)
3.2 (19.3)
5.5 (36.2)
11.1 (79.7)
5.0% (6.2%)
3.3% (4.5%)
1.9% (3.1%)
0.9% (1.9%)
0.0% (0.0%)
Table 2. Time vs. accuracy comparison, including averages and standard deviations for each
window parameter tested. Accuracy measured as percentage increase in distances from win-
dow parameter c = 500.
its ability to reasonably operate on large datasets. More-
over, we must also understand the impact of choosing
the window parameter c on the accuracy of the resultant
distance and the speed with which it is calculated. To
do so, we choose ﬁve settings of the window parame-
ter (25, 50, 100, 200, 500) and run distance measures
among a random subset of 50% of the hosts from each
day of the CSE dataset. The hosts in the sample se-
lected for our experiment had an average of 63,984 ﬂows
each, with the largest host having 6,357,811 ﬂows. For
each of the window parameter settings, we measure the
time it takes to perform the DTW procedure on a sin-
gle 3.16GHz processor and the increase in distance from
that which was calculated by the largest parameter set-
ting (i.e., c = 500), which are shown in Table 2.
The results of our efﬁciency experiments show that
most parameter settings can perform DTW-based behav-
ioral distance measures in a few seconds with relatively
small changes to the overall distance, even when cal-
culating distances among hosts with thousands or mil-
lions of ﬂows. For example, with a parameter setting
of c = 100, the DTW metric takes an average of only
3.2 seconds with an increase in the calculated distance
of just under 2%. For the remainder of our evaluation,
we ﬁx the window parameter c = 100 since it appears to
provide an appropriate trade-off between distance calcu-
lation accuracy and speed.
5.2 Impact of Semantics and Causality
To evaluate the potential beneﬁts of semantics and
long-term causal information in behavioral metrics, we
compare the performance of our DTW metric to the L1
distance metric. In our experiments, the L1 metric op-
erates by creating distributions of values for each of the
six ﬁelds, calculating the L1 distance between the two
hosts’ respective distributions, and summing the dis-
tances. The DTW metric operates exactly as discussed
in Section 4.
Our evaluation is broken into three parts. In the ﬁrst,
we use single-linkage agglomerative (i.e., hierarchical)
clustering to visualize and examine the behavioral sim-
ilarity among all hosts in our experiments. The second
experiment uses k-means clustering to explore the abil-
ity of the two metrics to produce clusters with coherent
semantics. The ﬁnal experiment compares the consis-
tency of the clusters produced by the above techniques,
as well as the similarity of the hosts across consecutive
days to measure the robustness of the behavioral infor-
mation captured by the two metrics. In the ﬁrst two ex-
periments, we examine only the ﬁrst day of trafﬁc from
the CSE dataset, while both days are used in the ﬁnal
experiment.
In all of these experiments, we make use of infor-
mation obtained from the University of Michigan CSE
system and network administrators about the known us-
age of the hosts in our analyses to provide a general no-
tion of the correctness of the clustering and to highlight
speciﬁc cases for deeper inspection. This information
allows us to label the hosts in our data with one of ten
labels that describe the stated usage of the host when its
IP was registered with the computer support staff. These
labels include: web server (WEB), mail server (SMTP),
DNS server (DNS), a variety of host types involving
general client activities (LOGIN, CLASS, DHCP), spe-
cialized research hosts for PlanetLab (PLANET), an ar-
tiﬁcial intelligence research project (AI), and auxiliary
power units (APC). For the purposes of these clustering
experiments, we only examine the subset of hosts that
we have labels for (76 of the 137 hosts).
Agglomerative Clustering. The agglomerative clus-
tering of hosts using the DTW and L1 metric are shown
as dendrograms in Figures 4 and 5, respectively. The
dendrograms visualize the agglomerative clustering pro-
cess, which begins with each host in its own cluster and
then merges clusters iteratively with their nearest neigh-
bor. The leaves in the dendrogram are labeled with the
stated usage of the host obtained from system admin-
istrators and a unique identiﬁer to facilitate comparison
between dendrograms. The branches of the dendrogram
illustrate the groupings of hosts, with shorter branches
indicating higher levels of similarity.
At ﬁrst glance, we see that both DTW and L1 metrics
group hosts with the same label in fairly close groups.
In fact, it appears as though L1 distance actually pro-
duces a better clustering according to these labels, for
Figure 4. Dendrogram illustrating agglomerative clustering using DTW-based metric on hosts
in the ﬁrst day of the CSE dataset.
instance by grouping SMTP servers, PlanetLab hosts,
and VM servers in very tight groupings. However, there
are two subtle shortcomings that require deeper investi-
gation. First, the L1 dendrogram clearly indicates that
there is relatively little separability among the various
clusters, as evidenced by the small differences in branch
lengths in the dendrogram from distances of 5 to 6.5.
The impact of this is that even small changes in the un-
derlying distributions will cause signiﬁcant changes to
the groupings. We will investigate this particular short-
coming during our consistency experiments. The sec-
ond shortcoming is that while the labels provide a gen-
eral idea of potential usage of the hosts, they say noth-
ing about the actual activities being performed during
recording of this dataset. As such, it is quite possible
that hosts with the same labels can have wildly different
behaviors.
To more closely examine the clustering provided by
DTW and L1 metrics, we manually observe two groups
of hosts (highlighted in Figures 4 and 5): virtual ma-
chine hosts (VM) and major servers (SMTP and WEB).
In the L1 dendrogram, all VM hosts are grouped to-
gether, whereas in the DTW dendrogram the hosts are
grouped into pairs. Moreover, these pairs are on oppo-
site sides of the dendrogram indicating signiﬁcant dif-
ferences in behavior. When we manually examine these
hosts’ activities, we see that one pair (127,128) appear
to be performing typical client activities, such as outgo-
ing SSH and web connections, with only approximately
2,000 ﬂows each. The other pair (183,184), however,
had absolutely no client activities, and instead most of
the approximately 6,000 ﬂows consisted of VMWare
management trafﬁc or Nagios system monitoring trafﬁc
[20]. Clearly, these are very distinct behaviors – client
activity and basic system management activity – and yet
the L1 metric was unable to distinguish them.
For the primary servers in the dataset, the L1 distance
metric groups the two SMTP servers together, however
our DTW metric ends up grouping one of the SMTP
servers (18) with the web server while the second SMTP
server is much further away. Upon closer examination,
the SMTP servers are differentiated by the fact that one
server (18) is the primary mail server that receives about
ﬁve times the amount of the trafﬁc as the second server
(27). In addition, the ﬁrst server (18) receives the ma-
jority of its connections from IPs external to the CSE
network, while the second server (27) receives many of
its mail connections from hosts within the CSE IP preﬁx
and has a signiﬁcant number of connections from hosts
performing SSH password dictionary attacks. It is this
local vs. external preference that causes the ﬁrst server
(18) to be grouped with the web server, since the web
server also has a signiﬁcant amount of trafﬁc, almost all
of which is associated with external hosts. Naively, the
L1 clustering appears to make the most sense given these
labels, but again its lack of semantic and causal informa-
tion has caused it to ignore the actual behaviors.
As a side effect of our close examination of some
Figure 5. Dendrogram illustrating agglomerative clustering using L1 distance on hosts in the
ﬁrst day of the CSE dataset.
hosts within the dendrogram, we also gained some in-
sight into the general structure of the dendrogram in the
case of the DTW metric. That is, the DTW metric pro-
duced a dendrogram where the hosts on the right side of
the dendrogram perform general client activities, while
most hosts on the left side act as servers. This separa-