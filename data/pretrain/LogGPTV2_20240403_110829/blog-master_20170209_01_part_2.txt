[《从难缠的模糊查询聊开 - PostgreSQL独门绝招之一 GIN , GiST , SP-GiST , RUM 索引原理与技术背景》](../201612/20161231_01.md)    
## 9 在线处理、离线分析、在线分析混合需求 - 互联网、传统企业、金融 等业务场景    
随着IT行业在更多的传统行业渗透，我们正逐步的在进入DT时代，让数据发挥价值是企业的真正需求，否则就是一堆废的并且还持续消耗企业人力，财力的数据。      
传统企业可能并不像互联网企业一样，有大量的开发人员、有大量的技术储备，通常还是以购买IT软件，或者以外包的形式在存在。      
数据的核心 - 数据库，很多传统的行业还在使用传统的数据库。      
随着IT向更多行业的渗透，数据类型越来越丰富（诸如人像、X光片、声波、指纹、DNA、化学分子、图谱数据、GIS、三维、多维 等等。。。），数据越来越多，怎么处理好这些数据，怎么让数据发挥价值，已经变成了对IT行业，对数据库的挑战。      
对于互联网行业来说，可能对传统行业的业务并不熟悉，或者说互联网那一套技术虽然在互联网中能很好的运转，但是到了传统行业可不一定，比如说用于科研、军工的GIS，和互联网常见的需求就完全不一样。      
除了对数据库功能方面的挑战，还有一方面的挑战来自性能方面，随着数据的爆炸，分析型的需求越来越难以满足，主要体现在数据的处理速度方面，而常见的hadoop生态中的处理方式需要消耗大量的开发人员，同时并不能很好的支持品种繁多的数据类型，即使GIS可能也无法很好的支持，更别说诸如人像、X光片、声波、指纹、DNA、化学分子、图谱数据、GIS、三维、多维 等等。      
那么我们有什么好的方法来应对这些用户的痛处呢？      
且看ApsaraDB产品线的PostgreSQL与HybridDB如何来一招左右互搏，左手在线事务处理，右手数据分析挖掘，解决企业痛处。      
对传统企业来说，OLTP系统大多数使用的是Oracle等商业数据库，使用PostgreSQL可以与Oracle的功能、性能、SQL语法等做到高度兼容。    
而对于分析场景，使用MPP产品HybridDB(基于GPDB)，则可以很好的解决PB级以上的AP需求。    
![pic](../201701/20170101_02_pic_008.jpg)    
![pic](../201701/20170101_02_pic_009.jpg)    
[《ApsaraDB的左右互搏术 - PostgreSQL+HybridDB解决企业痛处 TP+AP混合需求》](../201701/20170101_02.md)    
对于中小型企业，数据量在10TB量级的，分析型的事务甚至也可以交给PostgreSQL来处理。    
因为它具备了多核并行处理的能力、列存储、JIT、算子复用、甚至向量化执行等技术，相比传统的数据库，在OLTP方面有10倍以上的性能提升。(同时还可以使用LLVM技术，GPU卡\FPGA卡来 硬件加速分析)    
![pic](../201612/20161216_01_pic_008.png)    
[《分析加速引擎黑科技 - LLVM、列存、多核并行、算子复用 大联姻 - 一起来开启PostgreSQL的百宝箱》](../201612/20161216_01.md)     
[《PostgreSQL 9.6 引领开源数据库攻克多核并行计算难题》](../201610/20161001_01.md)      
[《PostgreSQL 向量化执行插件(瓦片式实现) 10x提速OLAP》](../201702/20170225_01.md)      
## 10 用户群体搜索、根据标签圈人 - 电商、广告投放 等业务场景    
电商推荐系统 部分需求介绍      
比如一家店铺，如何找到它的目标消费群体？         
要回答这个问题，首先我们需要收集一些数据，比如：          
1\. 这家店铺以及其他的同类店铺的浏览、购买群体。          
我们在逛电商时，会产生一些行为的记录，比如在什么时间，逛了哪些店铺，看了哪些商品，最后在哪家店铺购买了什么商品。           
然后，对于单个商店来说，有哪些用户逛过他们的商店，购买过哪些商品，可以抽取出一部分人群。          
2\. 得到这些用户群体后，筛选出有同类消费欲望、或者具备相同属性的群体。          
对这部分人群的属性进行分析，可以获得一个更大范围的群体，从而可以对这部分群体进行营销。           
以上是对电商推荐系统的两个简单的推理。      
PostgreSQL, HybridDB解决了推荐系统的三个核心问题    
精准，属于数据挖掘系统的事情，使用PostgreSQL, Greenplum 的 MADlib机器学习库可以实现。         
实时，实时的更新标签，在数据库中进行流式处理，相比外部流处理的方案，节约资源，减少开发成本，提高开发效率，提高时效性。         
高效，使用PostgreSQL以及数组的GIN索引功能，实现在万亿USER_TAGS的情况下的毫秒级别的圈人功能。      
![pic](../201612/20161222_02_pic_011.jpg)    
[《恭迎万亿级营销(圈人)潇洒的迈入毫秒时代 - 万亿user_tags级实时推荐系统数据库设计》](../201612/20161225_01.md)      
## 11 位置信息处理、点面判断、按距离搜索、化学数据处理 - 危化品监管 等业务场景    
危化品的种类繁多。包括如常见的易爆、易燃、放射、腐蚀、剧毒、等等。    
由于危化品的危害极大，所以监管显得尤为重要，    
1\. 生产环节      
将各个原来人工监控的环节数字化，使用 传感器、流计算、规则（可以设置为动态的规则） 代替人的监管和经验。      
2\. 销售环节      
利用社会关系分析，在销售环节挖掘不法分子，挖掘骗贷、骗保的虚假交易。利用地理位置跟踪，掌控整个交易的货物运输过程。      
3\. 仓储环节      
仓储环节依旧使用传感器、流计算、应急机制对仓管的产品进行实时的监管，而对于危化品本身，我们已经不能使用普通的数据类型来存储，很幸运的是在PostgreSQL的生态圈中，有专门支持化学行业的RDKit支持，支持存储化合物类型，以及基于化合物类型的数据处理    
（包括化学反应，分解等等）。      
4\. 运输环节      
小结一下，在危化品的运输环节，使用传感器对货车、集装箱内的危化品的指标进行实时的监控，使用流式数据库pipelineDB流式的处理传感器实时上报的数据；使用PostgreSQL+PostGIS+pgrouting 对于货车的形式路径进行管理，绕开禁行路段、拥堵路段。      
当出现事故时，使用PostgreSQL的GIS索引，快速的找出附近的应急救助资源（如交警、消防中队、医院、120）。      
同时对危化品的货物存储，使用化学物类型存储，可以对这些类型进行更多的约束和模拟的合成，例如可以发现化学反应，防止出现类似天津爆炸事件。      
5\. 消耗环节      
增加剩余量的监控，在闭环中起到很好的作用，达到供需平衡，避免供不应求，或者供过于求的事情发生。         
6\. 动态指挥中心      
在给生产、仓库、物流配送、消耗环节添加了终端、传感器后，就建立了一个全面的危化品监管数据平台。 构建实时的监管全图。           
7\. 缉毒、发现不法分子等      
通过社会关系学分析，结合RDKit插件，在数据库中存储了人的信息，存储了人与化学物的关系（比如购买过），然后，根据社会关系学分析，将一堆的化合物（原材料）结合起来，看看会不会发生反应，生成毒品或危化品。       
从而发现不法分子。      
![pic](../201612/20161228_01_pic_002.jpg)    
![pic](../201612/20161228_01_pic_008.jpg)    
[《从天津滨海新区大爆炸、危化品监管聊聊 IT人背负的社会责任感》](../201612/20161228_01.md)    
## 12 图式数据搜索 - 金融风控、公安刑侦、社会关系、人脉分析 等业务场景    
人类是群居动物，随着人口的增长，联络方式越来越无界化，人与人，人与事件，人与时间之间形成了一张巨大的关系网络。       
有许多场景就是基于这张巨大的关系网络的，比如。       
1\. 猎头挖人         
作为IT人士或者猎头、HR，对Linkedin一定不陌生，领英网实际上就是一个维护人际关系的网站。        
![pic](../201612/20161213_01_pic_001.png)       
通过搜索你的一度人脉，可以找到与你直接相关的人，搜索2度人脉，可以搜索到与你间接相关的人。       
当然你还可以继续搜索N度人脉，不过那些和你可能就不那么相关了。        
如果你知道和美女范冰冰隔了几度人脉，是不是有点心动了呢？        
其实在古代，就有这种社会关系学，还有这种专门的职业，买官卖官什么的，其实都是人脉关系网。看过红楼梦的话，你会发现那家子人怎么那么多亲戚呢？         
2\. 公安破案       
公安刑侦学也是一类人脉相关的应用，只是现在的关系和行为越来越复杂，这种关系也越来越复杂，原来的人能接触的范围基本上就靠2条腿，顶多加匹马。      
现在，手机，电脑，ATM机，超时，摄像头，汽车等等，都通过公路网、互联网连接在一起。      
一个人的行为，产生的关系会更加的复杂，单靠人肉的关系分析，刑侦难度变得越来越复杂。       
3\. 金融风控        
比如银行在审核贷款资格时，通常需要审核申请人是否有偿还能力，是否有虚假消息，行为习惯，资产，朋友圈等等。  同样涉及到复杂的人物关系，人的行为关系分析等等。       
图片来自互联网      
![pic](../201612/20161213_01_pic_007.jpg)        
![pic](../201612/20161213_01_pic_008.jpg)        
此类围绕人为中心，事件为关系牵连的业务催生了图数据库的诞生。       
目前比较流行的图数据库比如neo4j，等。      
详见       
https://en.wikipedia.org/wiki/Graph_database       
PostgreSQL是一个功能全面的数据库，其中就有一些图数据库产品的后台是使用PostgreSQL的，例如OpenCog， Cayley等。          
除了这些图数据库产品，PostgreSQL本身在关系查询，关系管理方面也非常的成熟，十亿量级的关系网数据，3层关系运算仅需毫秒。     
还可以用于运算人与人之间的最短关系，穷举关系等。    
主要用到的技术plpgsql服务端编程、异步消息、数组、游标等。    
[《金融风控、公安刑侦、社会关系、人脉分析等需求分析与数据库实现 - PostgreSQL图数据库场景应用》](../201612/20161213_01.md)    
## 13 大量数据的求差集、最新数据搜索, 最新日志数据与全量数据的差异比对, 递归收敛扫描 - 物联网、数据同步、数据清洗、数据合并 等业务场景    
有一个这样的场景，一张小表A，里面存储了一些ID，大约几百个到万个。    
（比如说巡逻车辆ID，环卫车辆的ID，公交车，微公交的ID）。      
另外有一张日志表B，每条记录中的ID是来自前面那张小表的，但不是每个ID都出现在这张日志表中，比如说一天可能只有几十个ID会出现在这个日志表的当天的数据中。    
（比如车辆的行车轨迹数据，每秒上报轨迹，数据量就非常庞大，但是每天出勤的车辆有限）。      
那么我怎么快速的找出今天没有出现的ID呢。    
（哪些巡逻车辆没有出现在这个片区，是不是偷懒了？哪些环卫车辆没有出行，哪些公交或微公交没有出行）？     
![pic](20170209_01_pic_004.jpg)    
select id from A where id not in (select id from B where time between ? and ?);    
select a.id from a left join b on (a.id=b.aid) where b.* is null;    
这个QUERY会很慢，通常需要几百秒到几十秒，有什么优化方法呢。    
通过PostgreSQL的递归查询，可以高效的解决这个问题(在几亿记录中筛选出与几万记录的逻辑差集)。     
优化后只需要10毫秒左右。    
[《用PostgreSQL找回618秒逝去的青春 - 递归收敛优化》](../201612/20161201_01.md)      
同样的方法，还可以用于数据清洗与合并的场景，比如在物联网的环境中，每个传感器，每个小时会上报若干条数据（有新增的，有更新的，有删除的指标等），对于同一个KEY，后台的应用程序只关心最后一条记录。    
使用PostgreSQL的递归收敛，每秒可以清洗或合并千万量级的数据。    
除了物联网，同样适用于数据库之间的数据逻辑同步。      
[《时序数据合并场景加速分析和实现 - 复合索引，窗口分组查询加速，变态递归加速》](../201611/20161128_01.md)     
![pic](../201609/20160929_02/0009.jpg)    
![pic](../201609/20160929_02/0010.jpg)    
## 14 数据一致性分享、数据泵 - 跨业务平台实时分享数据 等业务场景    
在IoT的场景中，有流式分析的需求，也有存储历史数据的需求，同时还有数据挖掘的需求，搜索引擎可能也需要同一份数据，还有一些业务可能也要用到同一份数据。       
但是如果把数据统统放到一个地方，这么多的业务，它们有的要求实时处理，有的要求批量处理，有的可能需要实时的更新数据，有的可能要对大数据进行分析。       