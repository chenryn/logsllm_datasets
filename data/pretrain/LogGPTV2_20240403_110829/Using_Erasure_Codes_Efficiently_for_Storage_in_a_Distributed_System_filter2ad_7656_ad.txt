### 0-7695-2282-3/05 $20.00 © 2005 IEEE

---

#### Erasure Codes and Their Performance Metrics

The following table summarizes the performance metrics for various erasure codes, including their failure resiliency, delta addition time, full encoding time, and full decoding time.

| Erasure Code | Failure Resiliency (c=client, s=storage) | Delta + Add (µs) | Full Encode (µs) | Full Decode (µs) |
|--------------|------------------------------------------|------------------|------------------|------------------|
| 2-of-4       | 1c1s, 0c2s                               | 5                | 8                | 8                |
| 3-of-5       | 1c1s, 0c2s                               | 4                | 11               | 12               |
| 3-of-6       | 1c1s, 0c3s                               | 4                | 14               | 15               |
| 4-of-6       | 1c1s, 0c2s                               | 5                | 15               | 15               |
| 4-of-7       | 1c1s, 0c3s                               | 4                | 12               | 13               |
| 5-of-7       | 1c1s, 0c2s                               | 4                | 15               | 13               |

(a) Codes used in real runs

#### Performance and Fault-Resilience of Erasure Codes

**Figure 8: Performance and Fault-Resilience of Erasure Codes**

- **(a) Codes used in real runs**
- **(b) Codes used in simulations**
- **(c) Failure resiliency in simulations**

The figures below illustrate the performance and fault-resilience of different erasure codes in both real runs and simulations. The x-axis represents the number of data blocks (k), and the y-axis represents the time in microseconds (µs).

![](figure_8.png)

#### Results from Real Runs

**Figure 9: Results from Real Runs**

- **(a) Write Throughput (TP) vs. Number of Requests per Client**
- **(b) Write Throughput (TP) vs. Number of Clients**
- **(c) Write Throughput (TP) vs. Redundancy**
- **(d) Throughput When a Storage Node Crashes**

The graphs below show the write throughput (in MB/s) under various conditions, including the number of simultaneous requests, the number of clients, and the redundancy level.

![](figure_9.png)

#### Results from Simulations

**Figure 10: Results from Simulations**

- **(a) Write Throughput (TP) vs. Number of Clients**
- **(b) Read Throughput (TP) vs. Number of Clients**
- **(c) Write Throughput (TP) vs. Redundancy**
- **(d) Write Throughput Using Broadcast**

The following charts present the results from simulations, showing the write and read throughput (in MB/s) as a function of the number of clients, redundancy, and broadcast usage.

![](figure_10.png)

### Discussion

Our protocol supports the use of highly efficient erasure codes, characterized by large n and k values and small n - k. We envision a system that leverages our protocol to create an industrial-strength distributed disk array. This system would use inexpensive adapters to connect disks to a network, powerful machines as array nodes, and efficient erasure codes to handle multiple disk and node failures. External parties can send requests for logical blocks to the array nodes, which act as "clients" in our protocol, while the cheap adapters serve as "storage nodes."

### Acknowledgements

We are grateful to our shepherd Yair Amir, and to Mark Lillibridge, Janet Wiener, and John Wilkes for their valuable suggestions that improved this paper. We also thank Cheng Huang and Sinchan Mitra for providing the necessary computing resources.

### References

1. P. Corbett et al., “Row-diagonal parity for double disk failure correction,” in Proceedings of FAST, 2004.
2. V. Pless, Introduction to the Theory of Error-Correcting Codes, Wiley-Interscience, 1998.
3. J. Kubiatowicz et al., “Oceanstore: An architecture for global-scale persistent storage,” in Proceedings of ASPLOS, 2000.
4. F. Chang et al., “Myriad: Cost-effective Disaster Tolerance,” in Proceedings of FAST, 2002.
5. S. Frolund et al., “A decentralized algorithm for erasure-coded virtual disks,” in Proceedings of DSN, 2004.
6. G. R. Goodson, J. J. Wylie, G. R. Ganger, and M. K. Reiter, “Efficient byzantine-tolerant erasure-coded storage,” in Proceedings of DSN, 2004.
7. Z. Zhang and Q. Lian, “Reperasure: Replication protocol using erasure-code in peer-to-peer storage,” in Proceedings of SRDS, 2002.
8. W. Litwin and T. Schwarz, “LH* RS: A high-availability scalable distributed data structure using Reed-Solomon codes,” in Proceedings of SIGMOD, 2000.
9. M. K. Aguilera, R. Janakiraman, and L. Xu, “Efficient fault-tolerant distributed storage using erasure codes,” Tech. Rep., Washington University in St. Louis, Feb 2004. Available at: <http://www.nisl.wustl.edu/Papers/Tech/aguilera04efficient.pdf>.
10. F. Schneider, “Byzantine generals in actions: implementing fail-stop processors,” ACM Transactions on Computer Systems, vol. 2, no. 2, pp. 145–154, May 1984.
11. L. Lamport, “On interprocess communication,” Distributed Computing, vol. 1, no. 1, pp. 77–101, 1986.
12. C. Shao, E. Pierce, and Jennifer L. Welch, “Multi-writer consistency conditions for shared memory objects,” in Proceedings of ICDCS, October 2003, pp. 106–120.

**Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05)**  
0-7695-2282-3/05 $20.00 © 2005 IEEE