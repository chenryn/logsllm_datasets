+ Pr
= 2 · Pr
≤ ϵ.
b = 1
(cid:105)
(cid:105) − 1
b = 0
(cid:105) − 1
We follow a similar process to construct an adversary
Bo which is based on the oc oracle, using the same logic
to establish the bound ∆(CC1, CS1) ≤ ϵ. Substituting these
results into the unrolling of the pcc advantage above, we get
an upper bound of δ + 2ϵ + σ. Finally, since our reductions
require two queries to fulfill each of A’s queries, the bound
on the security of SC must allow twice as many queries as
the proven pcc security bound. The total bitlength of these
queries, however, is the same.
C. Wire-only schemes
Our second theorem establishes passive security bounds
for wire-only Π[SC]; that is, ABCCs with trivial user-side
algorithms but non-trivial wire-side algorithms.
Theorem 2. Fix application channel App and environment
context ξ, and let Π be an App-based covert channel which
is shape-preserving. Let SC be a stream-based channel which
is (t, q, µ, ϵ)-IND-CPFA secure, then construct App[SC] and
Π[SC] as in Figure 5. Fix covert user User1 such that Π[SC] is
(t, q, µ, σ)-sink-indistinguishable relative to App, User1, and
ξ. Fix overt user User0 which is (t, q, µ, δ)-similar to User1
relative to App[SC], Π[SC], and ξ. Then Π[SC] is passively
(t, q, µ, δ + ϵ + σ)-secure relative to App[SC], User0, User1,
and ξ.
Proof. We begin by unrolling the pcc advantage and defining
it in terms of the given assumptions:
Advpcc
App[SC],(User0,User1),Π[SC],ξ
= ∆(CC1, OC0)
= ∆(CC1, OC1) + ∆(OC1, OC0)
= ∆(CC1, SG1) + ∆(SG1, OC1) + ∆(OC1, OC0)
≤ σ + ∆(SG1, OC1) + δ.
The only remaining task is to prove a bound for ∆(SG1, OC1),
which we accomplish through a simple reduction.
From a fixed adversary A, we may construct an adversary
B which attacks the IND-CPFA security of SC (refer to Fig-
ure 6, right). The adversary replicates the ABCC experimental
setup, running the initialization algorithms and then running
A with oracle access to push covert bits as well as query a
challenge oracle. The challenge oracle provided by B runs
the ABCC algorithms in the same order as the sg oracle,
but without “internal” calls to SC that are superfluous due to
correctness. The ABCC’s instance of SC is used to generate
the server response ws, but the client message wc is generated
by querying B’s challenge oracle. The output of Source is used
as the left message M0 while the output of Embedwire is used
as the right message M1.
(cid:104)
(cid:104)
We observe that the value of the challenge bit in the
enclosing IND-CPFA experiment determines the behavior of
Challenge: when b = 1 it produces query responses identical
to the sg oracle, and when b = 0 it produces query responses
identical to the oc oracle. Since B uses A’s output as its own
output, we have
Expind-cpfa
= Pr[ SG1(A) ⇒ 1 ] ,
= 1 − Pr[ OC1(A) ⇒ 1 ] .
This is the same situation encountered in the proof of Theo-
rem 1, so by the same logic we have ∆(SG1, OC1) ≤ ϵ which
we substitute into the unrolling of the pcc advantage above to
get an upper bound of δ +ϵ+σ. Since we use a tight reduction
in this case, the bound applies to adversaries with the same
resources as the assumptions.
(B) ⇒ 1
(B) ⇒ 1
Expind-cpfa
(cid:105)
(cid:105)
b = 1
b = 0
Pr
Pr
SC
SC
D. Discussion
We conclude this section by assessing the extent to which
several real-world schemes satisfy the assumptions of our
security theorems. First, we note that the bounds in our theo-
rems each include three terms, one of which is derived from
the secure channel and one of which is the user advantage.
The remaining σ term—traffic-shape for Theorem 1, sink-gap
for Theorem 2—is reflected in the design considerations for
each case.
Most of the streaming-media ABCCs mentioned in §II-B
are examples of user-only ABCCs with secure transport,
corresponding to the setting for Theorem 1. A typical security
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:36:38 UTC from IEEE Xplore.  Restrictions apply. 
1983
c
, ), ˆγ) ←← App[SC].Init(ξ)
Adversary BO(·)
(K, h) ←← Π[SC].Setup(ξ)
((γ,
BUF ← ε; ws ← ε
b ←← APUSH,Challenge(·)(h, ˆγ)
return b
Procedure Challenge( )
x ←← Userγ
1 (NEXT)
x ←← EmbedPULL
user (K, γ, h, x)
wc ←← App.Sourceγ (x, ws)
wc ←← Π.EmbedPULL
wire (K, γ, h, wc)
w′
c ←← Π.Extractwire(K, γ, h, wc)
(ws, ) ←← App.Sinkγ (w′
c)
cc ←← O(wc, [..., 1])
cs ←← O(ws, [..., 1])
return (cc, cs)
w
Adversary BO(·)
(K, h) ←← Π[SC].Setup(ξ)
((γ, sts, ), ˆγ) ←← App[SC].Init(ξ)
BUF ← ε; ws ← ε
b ←← APUSH,Challenge(·)(h, ˆγ)
return b
1 (NEXT)
Procedure Challenge( )
x ←← Userγ
wc ←← App.Sourceγ (x, ws)
(ws, ) ←← App.Sinkγ (wp)
(sts, cs) ←← SC.Send(sts, ws, [..., 1])
w′
c ←← Π.EmbedPULL
wire (K, γ, h, wc)
cc ←← O(wc, w′
c, [..., 1])
return (cc, cs)
Fig. 6: (Left) Construction of IND-CPFA adversary Bc used in the proof of Theorem 1. (Right) Construction of IND-CPFA adversary Bw
used in the proof of Theorem 2. The shorthand [..., 1] denotes an arbitrary vector of flush flags, of the same length as the plaintext input
vector, terminated with the value 1.
analysis for these systems involves training a classifier to dis-
tinguish between embedded and unmodified traffic flows; this
provides empirical evidence for the magnitude of the traffic-
shape advantage. However, concrete implementations of such
systems must also consider the effect of the user advantage
term. For streaming-media systems this corresponds to what
the authors of Facet [18] describe as content inconsistency,
e.g. using a recording of classical music as the overt user for
a VoIP application where the typical user generates human
conversational speech.
Revisiting our discussion from §VI-B, Balboa [6] and
Protozoa [5] are wire-only ABCCs which require a secure
transport from the target application, corresponding to the set-
ting for Theorem 2. Balboa’s lossless recovery of the original
Source outputs implies a sink-gap bound of 0. This leads us
to concude that the passive security of Balboa rests largely
upon the user advantage, i.e., the ability of a computationally
bounded adversary to distinguish the covert user from the
reference user. Thus, for concrete implementations of Balboa,
security efforts should be focused on developing user models
that are closely matched to the target deployment environment.
For Protozoa we cannot assume a sink-gap bound of 0, since
the original video stream is not recovered and the dummy
video it is replaced with may trigger distinguishable responses
from Sink. Here, the security of concrete implementations will
depend not only on the user model but also on the method used
to determine the dummy video stream. The tradeoff implied by
these two approaches is reflected in system setup requirements:
Balboa can only replace traffic that has been shared in advance
by the communicating parties, which can be a burdensome or
even prohibitive requirement in some use cases (such as real-
time video streaming, for which Protozoa was designed).
VIII. CONCLUSION AND FUTURE WORK
In this work, we introduce formalisms for reasoning
about systems typically used for censorship circumvention
which utilize existing applications to tunnel covert messages.
We call such systems application-based covert channels—or
ABCCs—and define a notion of security for these targeting a
passive eavesdropper. Alongside these formalisms, we believe
an important contribution of our work is making explicit
assumptions that in prior works have been either implicit or ill-