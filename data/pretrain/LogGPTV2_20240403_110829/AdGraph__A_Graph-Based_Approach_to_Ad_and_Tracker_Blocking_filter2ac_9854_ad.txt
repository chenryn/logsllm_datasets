invisible resources like JavaScript (90.52% accuracy) and
AJAX requests (93.55% accuracy). This suggests an interesting
possibility, that ADGRAPH’s labels are correct, and ﬁlter lists
miss-classify invisible resources due to their reliance on human
crowdsourced feedback. We investigate this possibility, and
more broadly the causes of disagreements between ADGRAPH
and ﬁlter lists in the next subsection.
B. Disagreements Between ADGRAPH and Filter Lists
We now manually analyze the cases where ADGRAPH
disagrees with ﬁlter lists to determine which labeling is
incorrect, ADGRAPH’s or ﬁlter lists’. Overall, we ﬁnd that
ADGRAPH is able to identify many advertising and tracking
resources missed by ﬁlter lists. We also ﬁnd that ADGRAPH
correctly identiﬁes many resources as benign which ﬁlter
lists incorrectly block. These ﬁndings imply that ADGRAPH’s
actual accuracy is higher than 95.33%.
Methodology. To understand why ADGRAPH disagrees with
existing ﬁlter lists, we perform a manual analysis of a sample
of network requests where ADGRAPH identiﬁes a resource
as ad/tracking related but ﬁlter lists identify as benign (i.e.
false positives) and where ﬁlter lists identify a resource as
ad/tracking related but ADGRAPH identiﬁes as benign (i.e.
false negatives). We select these “false positives” and “false
negatives” from the most frequent advertising and tracking
related resource types: JavaScript code units and images. We
manually analyze all of the 282 distinct images and a random
sample of 100 script URLs that ADGRAPH classiﬁes as AD but
ﬁlter lists label as NON-AD and a random sample 300 images
and 100 script URLs that ADGRAPH classiﬁes as NON-AD
but ﬁlter lists label as AD. The goal of our manual analysis is
to assign each JavaScript unit or image to one of the following
labels:
1) True Positive: ADGRAPH’s classiﬁcation is correct and
the ﬁlter lists are incorrect; the resource is related to
advertising or tracking.
5The success rate of about 90% in our crawl is in line with those of previous
studies [42], [54].
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:00 UTC from IEEE Xplore.  Restrictions apply. 
770
Resource
Image
Script
CSS
AJAX
iFrame
Video
Total
# Resources
201,785
167,533
124,207
24,365
20,091
2,360
540,341
Blocked by Filter Lists
11,584
67,959
9,255
8,305
7,745
23
104,871
Blocked by ADGRAPH
10,228
60,030
5,834
7,442
7,244
14
90,792
Precision
FPR
Recall
FNR
93.09% 88.29% 0.39% 11.71%
88.32% 88.33% 7.97% 11.67%
83.61% 63.03% 0.99% 36.97%
91.31% 89.60% 4.40% 10.40%
92.31% 93.53% 4.88%
6.47%
93.33% 60.86% 0.04% 39.14%
13.4%
89.1%
86.6% 2.56%
Accuracy
98.95%
90.52%
96.32%
93.55%
94.50%
99.57%
95.33%
TABLE IV: Number of resources, broken out by type, encountered during our crawl, and incidence of ad and tracking content, as determined
by popular ﬁlter lists and ADGRAPH.
2) False Positive: The label by ﬁlter lists is correct and
ADGRAPH’s classiﬁcation is incorrect; the resource is not
related to advertising or tracking.
3) True Negative: ADGRAPH’s classiﬁcation is correct and
the ﬁlter lists are incorrect; the resource is not related to
advertising or tracking.
4) False Negative: The label by ﬁlter lists is correct and
ADGRAPH’s classiﬁcation is incorrect; the resource is
related to advertising or tracking.
5) Mixed: The resource is dual purpose (i.e. both ad/tracker
and benign). This label is only used for script resources.
6) Undecidable: It was not possible to determine whether
the resource is an ad/tracker.
We decide whether an image was advertising or tracking
related through the following three steps. First, we label all
tracking pixels (1× 1 sized images used to initiate a cookie or
similar state-laden communication) as “true positive” if AD-
GRAPH classiﬁed it as AD and “false negative” if ADGRAPH
classiﬁed it as NON-AD. Second, we consider the content of
each image and look for text indicating advertising, such as
the word “sponsored", prices, or mentions of marketers. If the
image has such text, we consider the image as an advertise-
ment and label it “true positive” if ADGRAPH classiﬁed it as
AD and “false negative” if ADGRAPH classiﬁed it as NON-
AD. If the case is ambiguous, such as an image of a product
that could either be advertising or a third-party discussion of
the product, we use the “undecidable” label. Third, we label
all remaining cases as “false positive” if ADGRAPH classiﬁed
them as AD and “true negative” if ADGRAPH classiﬁed them
as NON-AD.
Deciding the labels for the sampled script resources is
more challenging. Determining the purpose of a JavaScript
ﬁle requires inspecting and understanding large amounts of
code, most of which has no documentation, and which is
in many cases miniﬁed or obfuscated. We label a script as
“true positive” (advertising or tracking related) if most of
the script performs any of the following functionality: cookie
transmission, passive device ﬁngerprinting, communication
with known ad or tracking services, sending beacons, or
modifying DOM elements whose attributes are highly in-
dicative of an ad (e.g. creating an image carousel with the
id “ad-carousel”); and ADGRAPH classiﬁed it as AD and
“false negative” if ADGRAPH classiﬁed it as NON-AD. If
the script primarily includes functionality distinct from the
above (e.g. form validation, non-ad-related DOM modiﬁcation,
ﬁrst-party AJAX server communication), we label it as “false
positive” if ADGRAPH classiﬁed it as AD and “true negative”
if ADGRAPH classiﬁed it as NON-AD. If the script contains
signiﬁcant amounts of both categories of functionality, we
label the script as “mixed”. In cases where the functionality
is not discernable, we use the “undecidable” label.
False Positive Analysis. Table V presents the results of
our disagreement analysis for false positives. In cases where
ADGRAPH identiﬁes a resource as suspect, and ﬁlter lists label
it as benign, ADGRAPH’s determination is correct 11.0%–
33.0% of the time for JavaScript and 46.8% of the time for
images.
ADGRAPH is often able to detect advertising and track-
ing resources that are missed by ﬁlter lists. For example,
ADGRAPH blocks a 1x1 pixel on cbs.com that includes a
tracking identiﬁer in its query string. In another example,
ADGRAPH blocks a script (js1) on nikkan-gendai.com that
performs browser ﬁngerprinting. Filter lists likely missed these
resources because they are often slow to catch up when
websites introduce changes [47].
There are however several false positives that are actual
mistakes by ADGRAPH. For example, ADGRAPH blocks a
third-party dual purpose script (avcplayer.js), a video player
library that also serves ads, on inquirer.net. Interestingly,
ADGRAPH detects many such dual-purposed scripts that are
beyond the ability of binary-label ﬁlter lists.
These results demonstrate that ADGRAPH is able to identify
many edge case resources (e.g. mixed-use) that can be used to
reﬁne future versions of ADGRAPH. As discussed in Section
V-B, ADGRAPH can be extended to handle such mistakes by
implementing more ﬁne-grained blocking.
True Positive
False Positive
Mixed
Undecidable
#
132
129
0
21
Image
%
#
46.8% 11
45.7% 63
0% 22
4
7.4%
Script
%
11.0%
63.0%
22.0%
4.0%
TABLE V: Results of manual analysis of a sample of cases where
ADGRAPH classiﬁes a resource as AD and ﬁlter lists label it as NON-
AD.
False Negative Analysis. Table VI presents the results of
our disagreement analysis for false negatives. In cases where
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:00 UTC from IEEE Xplore.  Restrictions apply. 
771
ADGRAPH identiﬁes a resource as benign, and ﬁlter lists label
it as suspect, ADGRAPH’s determination is correct 22%–32%
of the time for JavaScript and 27.7% of the time for images.
Again, ADGRAPH is often able to identify benign content
that is incorrectly over-blocked by ﬁlter lists. For example,
ADGRAPH does not block histats.com when visited as a ﬁrst-
party in our crawl, but this domain is blanketly blocked by
the Blockzilla ﬁlter list even when visited as a ﬁrst-party. In
another example, ADGRAPH does not block a social media
icon facebook-gray.svg (served on postimees.ee as a ﬁrst-party
resource) and a privacy-preserving analytics script piwik.js
(served on futbol24.com as a ﬁrst-party resource). It can be
argued that many of these resources are neither ads nor pose a
tracking threat [11], [50]. Filter lists over-block in such cases
because of the inclusion of overly broad rules (e.g. blocking
entire domains, or any URL containing a given string).
There are however several false negatives that are actual
mistakes by ADGRAPH. For example, ADGRAPH misses
ﬁngerprint2.min.js served by a CDN cloudﬂare.com on
index.hr. ADGRAPH likely made this mistake because a popu-
lar third-party CDN, which is typically used to serve functional
content, is used to serve a ﬁngerprinting script. As discussed
in Section V-B, ADGRAPH can be extended to handle such
mistakes by extracting new features from JavaScript APIs.
True Negative
False Negative
Mixed
Undecidable
#
83
180
0
37
Image
%
Script
#
27.7% 22
60.0% 55
0% 10
12.3% 13
%
22%
55%
10%
13%
TABLE VI: Results of manual analysis of a sample of cases where
ADGRAPH classiﬁes a resource as NON-AD and ﬁlter lists label it
as AD.
C. Site Breakage
Content blocking tools carry the risk of breaking benign
site functionality. Content blockers prevent resources that the
website expects to be in place from being retrieved, which
can have the carry over effect of harming desireable site
functionality, especially when tools mistakenly block benign
resources [19]. Thus assessing the usefulness of a content
blocking approach must also include an evaluation of how
many sites are “broken” by the intervention.
Next we evaluate how often, and to what degree, ADGRAPH
breaks benign (i.e. user desired) website functionality. We do
so by having two human reviewers visit a sample of popular
websites using ADGRAPH, and having them independently
record their assessment of whether the site worked correctly.
We ﬁnd that ADGRAPH only affects benign functionality on
a small number of sites, and at a rate equal to or less than
popular ﬁlter lists.
Methodology. We estimate how many sites ADGRAPH breaks
by having two evaluators use ADGRAPH on a sample of
popular websites and independently record their determination
of how ADGRAPH impacts the site’s functionality. Because
of the time consuming nature of the task, we select a smaller
sample of sites for this breakage evaluation than we use for
the accuracy evaluation.
Our evaluators use ADGRAPH on two sets of websites: ﬁrst
the Alexa top-10 websites, and second on a random sample of
100 websites from the Alexa top-1K list, resulting in a total
of 110 sites for breakage evaluation.
Automatic site breakage assessment is challenging due to
the complexity of modern web applications [55], [65]. Unfor-
tunately, manual inspection for site breakage assessment is not
only time-consuming but also likely to lose completeness as
the functionalities of a website are often triggered by certain
events that may be hard to manually cover exhaustively. As
a tradeoff, we adopt
the approach from [59], which is a
manual analysis but focuses on the user’s perspective. In other
words, we intentionally ignore the breakages that only affect
the website owner as they do not have any impact on user
experience.
For each website, our evaluators independently perform the
following steps.
1) Open the website with stock Chromium, as a control,
and perform as many actions as possible within two
minutes. We instruct our evaluators to exercise the kinds
of behaviors that would be common on each site. For
example, in a news site this might be browsing through an
article; on a e-commerce site this might include searching
for a product and proceeding to checkout etc.
2) Open the website with ADGRAPH, repeat the actions
performed above, and assign a breakage level of
(a) no breakage if there is no perceptible difference
between ADGRAPH and stock Chromium;
(b) minor breakage if the browsing experience is altered,
but objective of the visit can still be completed; or
(c) major breakage if objective of the visit cannot be
completed.
3) Open the website with Adblock Plus6, repeat the actions,
and assign a breakage level as above.
To account for the subjective nature of this analysis, we
have each evaluator visit the same sites, at similar times,
and determine their “breakage” scores independently. Our
evaluators give the same score 87.7% of the time, supporting
the signiﬁcance of their analysis.
Tool
ADGRAPH
Filter lists
No breakage
%
Major
#
85.0% 6.5
88.6%
7
Minor
#
5.9% 7.5
6.4%
4
%
%