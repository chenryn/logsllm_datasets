Once the dashboard is configured, you can add a new chart. Select a PCP metric; the available
metric bcc.runq.latency is a good one to start with (see Figure 17-11).
---
## Page 757
720
Chapter 17 Other BPF Performance Tools
Queries to
dOd
Figure 17-11 Choosing the query in Grafana
You also need to configure an appropriate visualization(see Figure 17-12). In this case, choose the
Heatmap visualization and set the format to "Time series buckets, with Unit set to *microseconds
(μs).* The Bucket bound should be set to “Upper° see Figure 17-13).
Figure 1.7-12 Grafana PCP showing standard PCP metrics (context switches, runnable count) as
well as run queue latency (runqlat) BCC metrics
Visualization
Y Auis
Data format
ds (us)
lesbuckets
Figure 17-13 Setting up the visualization in Grafana
---
## Page 758
17.3 Cloudflare eBPF Prometheus Exporter (with Grafana) 721
17.2.3 Future Work
More work is still needed between Grafana and PCP to improve integration with the full suite of
packaged bcc-tools. Support for visualizing custom bpftrace programs will hopefully be available
in a future update. In addition, the grafana-pcp-live plugin needs some significant additional
work before it should be considered battle-hardened.
17.2.4 Further Reading
The following links are quite likely to change as the projects mature:
*grafana-pcp-live data source:
htp://gtuh.com/Neffix-Skunkworks/grafana-pcp-live/
• grafana-pcp-redis data source:
/stpau-dod-euegex8/sopdooaoueusogad/uoorqnu8//sdu
17.30
CloudflareeBPFPrometheusExporter(with
Grafana)
The Cloudflare eBPF exporter is an open source tool that plugs into the well-defined Prometheus
monitoring format. Prometheus has become especially popular for metric collection, storage, and
querying because it provides a simple, well-known protocol. This makes it easy to integrate from
any language, and a number of simple language bindings are available. Prometheus also provides
alerting functionality and integrates well with dynamic environments such as Kubernetes.
Although Prometheus only provides a basic UI, a number of graphing toolsincluding Grafana
are also built on top of it to provide a coherent dashboard experience.
Prometheus also integrates into existing application operations tools. Within Prometheus, the
tool that collects and exposes metrics is known as an exporter. There are official and third-party
exporters available to collect Linux host statistics, JMX exporters for Java applications, and
many more for applications such as web servers, storage layers, hardware, and database services.
Cloudflare has open sourced an exporter for BPF metrics that allows exposure and visualization of
these metrics through Prometheus and thence to Grafana.
17.3.1 Build and Run the ebpf Exporter
Note that the build uses Docker:
$ git clone https://github,com/cloudflare/ebpf_exporter.git
5 cd ebpf_exporter
$ nake
$ sudo /release/ebpf_exporter-*/ebpf_exporter --config.file=, /examples/runqlat.yaml
Tzuoo ea uT punogsuex6oad t waTx 6utxeas 6tziLI 0t/→0/610Z
2019/04/10 17 :42:19 Listening on : 9435
---
## Page 759
722
Chapter 17 Other BPF Performance Tools
17.3.2
Configure Prometheus to Monitor the ebpf_exporter Instance
This depends on your approach for monitoring targets in your environment. Assuming the
instance is running the ebpf_exporter on port 9435, you can find a sample target configuration as
follows:
 kubectl edit confignap -n monitoring prometheus-core
-Job_name: 'kubernetes-nodes-ebpf-exporter 
schene: http
kubexmetes_sd_configs:
- role: node
relabel_configs:
source_labels: [_address_]
05201+(*), x*fex
replacenent: *$(1):9435*
target_label: address-
17.3.3 Set Up a Query in Grafana
As soon as the ebpf_exporter is running, it will produce metrics. You can graph these metrics
using the following query and aclditional format (see Figure 17-14):
query 1 rate lebpf_exporter_run_queve_latency_seconds_bucket [20s]]
legend format : ([1el)
axis unit 1 seconds
(For more information on the query format and graph configuration, refer to the Grafana and
Prometheus documentation.)
Figure 17-14  Grafana run queue latency heat map, showing latency spikes when schbench is
executed with more threads than cores
---
## Page 760
17.4kubect-trace  723
17.3.4 Further Reading
For more information on Grafana and Prometheus, see:
•https://grafana.com/
https://github.com/prometheus/prometheus
For more information on the Cloudflare eBPF exporter, see:
https://github.com/cloudflare/ebpf_exporter
 https:/blog.cloudflare.com/introducing-ebpf_exporter/
17.4kubectl-trace
Kubectl-trace is a Kubernetes command line front end for running bpftrace across nodes in a
Kubernetes cluster. It was created by Lorenzo Fontana and is hosted at the IO Visor project (see
https://github.com/iovisor/kubectl-trace).
an installation of Kubernetes (which is beyond the scope of this book):
To follow the examples here, you will need to download and install kubectl-trace. You also need
 git clone https://github,com/iovisor/kubectl-trace-git
S cd kubectl-trace
$ nake
S sodo cp -/_output/bin/kubect1-trace /usr/1oca1/bin
17.4.1 Tracing Nodes
Kubectl is the Kubernetes command line front end. Kubectl-trace supports running bpftrace
commands across a cluster node. Tracing whole nodes is the simplest option available, but pay
attention to the overhead of your BPF instrumentation: a bpftrace invocation that consumes high
overhead will affect the entire cluster node.
asnp at u apou saauaqny e rog sndno aoengdq aunqdeo o tepssja Susn 'adturexa ro
S kubect1 tzace run node/ip-1-2-3-4 -f /usz/share/bpftzace/tools/vfsstat.bt
trace Bfc22ddb-5c8411e99ad2-02d0df09784a created
5 kubectl trace get
KAMESPACE NODE
NAME
STATUSAGE
default
1p-1-2-34 lxubect1-tzace-8fc22ddb-5c8411e9-9ad2-02d0df09784a Running 3a
 kubectl trace 1ogs -f kubectl-trace-8fc22ddb-5c84-11e9-9ad2-02d0df097848
00 : 02 : 54
[vfs_open] : 940
Stoc =[etxnsg]é
e[vfs_read] : 7797
---
## Page 761
724
 Chapter 17 Other BPF Performance Tools
00 :02: 55
Z : [e.nsg]@
687 1[uadosgx]@
e[vfs_read]: 924
°C
$ kubectl trace delete kubectl-trace-8fc22ddb-5c84-11e9-9ad2-02d0df097848
tace Job kubect1-trace-8fc22ddl-5c84-11e9-9ad2-02d0df09784a deleted
trace configuration kubect1-trace-Bfc22db-Sc8411e9-9ad2-02d0df09784a deleted
This output shows all vfs statistics in the entire node, not just the pod. Because bpftrace is executed
from the host, kubectl-trace also runs in the context of the host. Therefore, it is tracing all applications
running on that node. This may be helpful in some cases for system administrators, but for many use
cases, it will be important to focus on the processes running inside the container.
17.4.2 Tracing Pods and Containers
bpftrace—and therefore kubectl-trace—has indirect support for containers by matching tracing
through kernel data structures. kubectl-trace provides help for pods in two ways. First, when
you specify the pod name, kubectl-trace will locate and deploy the bpftrace program on the
correct node automatically. Second, kubectl-trace introduces an extra variable into your script:
Scontainer_pid. The Scontainer_pid variable is set to the PID of the container root process, using
the host PID namespace. This allows you to perform filtering or other actions targeting only the
pod you prefer.
For this example, we will ensure that the PID is the only PID running inside the container we're
t aneq so ssaoosd spup ue Supuunu are nof uaqm se upns sopueuaos xajdtuoo asou sog ge Supqool
forking server, you will need to build on top of this tooling to map PIDs to their parent PIDs.
Create a new deployment using the following specification. Note that the command specifies the
Docker entry point to ensure that the node process is the only process inside the container, and
the vfsstat-pod.bt includes an addlitional filter on the PID:
$ cat <<Eor 1 kubect1 apply -f -
ap1Vexsion: apps/v1
kind: Deployment
se tada ta :
name1 node-he11o
spec:
selector1
ma tchLabe1s:
app: node-bel1o
replicas: 1
template1
:evepeq9w
labels:
app: sode-he11o
---
## Page 762
17.4 kubectl-trace
725
spec;
contalners:
- name: node-he11o
Inage: duluca/ninimalnode-xeb=server
comnand:[*node′,′index′]
ports:
-containerPort: 3000
EOF
deployment, apps/node-be11o created
5 kubectl get pods
KAME
READY
STATUS
RESTARTSAGE
nodehe11o56b8dbcT57th2k2
1 /1
Running
D
4s
Create a copy of vfsstat.bt called vfsstat-pod.bt, as shown below, and then start a tracer implemen-
tation (these steps show how to start a trace and review tracing output):
$ cat vfsstat-pod.bt
kprobe :vfs_read,
kprobe:vfs_vr1te,
kprobeivfs_faync
kprobe:vfs_open,
kprobe :vfs_create
/p1d == $contalnex_p1d/
$ kubectl trace run pod/node-he11o-56b8dbc757-th2k2 -f vfsstat-pod.bt
trace 552a2492-5c83-11e9-a598-02d0df09784a created
if your progran has naps to pzint, send a SIGIN using Ctzl-C, if you want to
interrupt the execution send SIGIVT tvo tines
Attaching B pzobes...
Tracing key VFs calls... Hit Ctrl-C to end.
[...]
17 :58 : 34
[vfs_open] : 1
e[vfs_read]: 3
b : [eng]@
17:58: 35
92185=T
e[vfs_read] : 3
[vfs_vrite] : 4
[...]
---
## Page 763
726
6 Chapter 17 Other BPF Performance Tools
You wil notice that there are significantly fewer vfs operations at the pod level than at the node
level, which is to be expected for a mostly idle web server.
17.4.3 Further Reading
• https:/github.com/iovisor/kubectl-trace
17.5
OtherTools
Some other BPF-based tools include:
suauuoaua pazaueuoo u sapsgod Aqunoas uoeondde pue somau sasddy um 
using BPE.
• Sysdig: Uses BPF to extend container observability.
■ Android eBPF: Monitors and manages device network usage on Android devices.
mou s Suuouo pue sojeue sog uoeopu uasis Sueado sasodxg ddga Aaanbso 
supports monitoring of kprobes with BPE
•ply: A BPF-based CLI tracer similar to bpftrace but with minimal dependencies, making
it well suited for environments including embedded targets [S] ply was created by Tobias
Waldekranz.
As BPF usage is growing, there willikely be many more BPF-based GUI tools developed in
the future.
17.6
6Summary
The BPF tool space is rapidly growing, and more tools and features will be developed. This
chapter presented four currently available tools that build upon BPF. Vector/PCP, Grafana, and
Cloudflare’s eBPF exporter are graphical tools that provide the ability to present visually large
amounts of complex data including time series BPF outputs. The final tool, kubectl-trace, allows
for straightforward execution of bpftrace scripts against a Kubernetes cluster. In addition, a short
list of other BPF tools was provided.
---
## Page 764
Chapter 18
Tips, Tricks, and
Common Problems
you might encounter and how to fix them
Tips and Tricks:
18.1 Typical event frequency and overhead
18.2 Sample at 49 or 99 Hertz
18.3  Yellow pigs and gray rats
18.4  Write target software
18.5  Learn syscalls
18.6  Keep it simple
Common Problems:
18.7 Missing events
18.8 Missing stack traces
18.9  Missing symbols (function names) when printing
18.10 Missing functions when tracing
18.11 Feedback loops
18.12 Dropped events
18.1Typical EventFrequencyandOverhead
Three main factors determine the CPU overhead of a tracing program:
The frequency of the event that is traced.
•The action performed while tracing.
•The number of CPUs on the system.
---
## Page 765
728
Chapter 18 Tips, Tricks, and Common Problems
An application will suffer this overhead on a per-CPU basis using the relationship:
Overhead = (Frequency × Action performed) / CPUs
Tracing one milion events per second on a single-CPU system may bring an application to a
crawl, whereas a 128-CPU system may be barely affected. The CPU count must be considered.
The number of CPUs and the overhead of the work performed can both vary by a single order
of magnitude. Event frequency, however, can vary by several orders of magnitude, making it the
biggest wildcard in trying to estimate overheadl.
18.1.1 Frequency
It helps to have some intuitive understanding of typical event rates, so I have created Table 18-1.
This includes a column where the maximum rate has been scaled to human-understandable
terms: once per second becomes once per year. Imagine that you are subscribed to a mailing list
that sends you email at this scaled rate.
Table 18-1 Typical Event Frequencies
Event
Typical Frequency2
Maximum Scaled
Tracing Overhead²
Max Estimated
1 per second
Yearly
Negligible
Process
10 per second
Monthly
Negligible
execution
File opens
1050 per second
Weekly
Negligible
Profling at
100 per second
Twice a week
Negligible
100 Hz
New TCP
10500 per second
Daily
Negligible
sessions
Disk I/0
101000 per second
Every eight hours
Negligible
VFS calls
100010,000 /s
Hourly
Measurable
Syscalls
100050,000 /s
Every ten minutes
Significant
Network
1000100,000 /s
Every five minutes
Significant
packets
Memory
10,0001,000,000 /s
Every thirty seconds
Expensive
allocations
1 This wss inspired by the scaled latency table from Chapter 2 of Systems Perfomance [Greg 13b], which became
of a scaled latency table: I first ser that when I was a university stuadent.
popular and has been shared many times. While I created this scaled freeuency table, I did not come up with the idea
2 It is hard to pick something *typical* s workicads vsry: Databases often have higher disk I/0 rates, and web and
proxy servers often have higher packet rates.
3 This is the estimated CPU overhead of tracing the event at its maximum rate (see below). CPU instructions and cycles
cannot be traced individually and directly, although in theory their software exeoution by CPU simulators could be traced.
---
## Page 766
18.1 Typical Event Frequency and Overhead
729
Event
Typical Frequency2
Maximum Scaled
Max Estimated
Tracing Overhead?
Locking
50,0005,000,000 /s
Every five seconds
Expensive
events
Function
Up to 100,000,000 /s
Three times per second
Extreme
calls
CPU
Up to 1,000,000,000+
Thirty times per second:
Extreme
instructions
per second
As a beat, C contra-octave
(CPU simulators)
of human hearing
on the piano scale: the limit
CPU cycles
Up to 3,000,000,000+
Ninety times per second:
G on the piano scale
Extreme
per second
(CPU simulators)
Throughout this book I have described the overhead for BPF tools, sometimes with measurements
but often with the words negligible, measarable, sigificant, and expensive. I chose these terms to