for identifying ﬁngerprints, we also recorded the destination
server IP, server name indication (if present), and anonymized
client IP /16 network from a small sample of connections,
along with the corresponding Client Hello ﬁngerprint. This
sample data helps us determine the source implementation or
purpose of a particular ﬁngerprint.
Server Hellos In addition to Client Hello messages, we
also collected the corresponding server hello in each connec-
tion, allowing us to see what cipher suite and extensions were
negotiated successfully. For each Server Hello message, we
parsed the TLS record version, handshake version, cipher suite,
compression method, and list of extensions. We also included
4We speciﬁcally exclude server name from our ﬁngerprint
3
Fig. 2. Collection Architecture — We implemented our 10 Gbps collection infrastructure using PF RING and 1400 lines of Rust, utilizing 4 processes. TLS
client and ServerHello ﬁngerprints and counts were aggregated and periodically written to a PostgreSQL database in a separate thread to avoid blocking the
main packet parsing loop.
the data from the supported groups (elliptic curves), EC point
format, and ALPN extensions.
Google Chrome users can disable cipher suites via a command
line option [20].
Figure 2 shows a high level overview of our collection
architecture.
BrowserStack In order to help link ﬁngerprints to their im-
plementations, we used BrowserStack—a cloud-based testing
platform—to automatically conscript over 200 unique browser
and platform combinations to visit our site, where we linked
user agents to captured Client Hello ﬁngerprints. Combined
with normal web crawling bots and manual tool tests, our
website collected over 270 unique ﬁngerprints, with over 535
unique user agents.
Fig. 3. Connections observed — We collected 9 months of TLS connections
on our 10 Gbps campus network, observing over 11 billion connections.
Noticeable is the diurnal pattern of trafﬁc, as well as a decrease in trafﬁc
on weekends and holiday breaks.
B. Collection Details
Multiple Fingerprints Some TLS implementations gen-
erate several ﬁngerprints. For example, Google Chrome gen-
erates at
least 4 ﬁngerprints, even from the same device.
This is due to sending different combinations of extensions
depending on the context and size of TLS request. Due to
a server bug in the popular F5 Big IP load balancer, Client
Hello messages between 256 and 511 bytes cause the device
to incorrectly assume the message corresponds to an SSLv2
connection, interrupting the connection. When Google Chrome
detects it would generate a Client Hello in this size range (for
example by including a long TLS session ticket or server name
value), it pads the Client Hello to 512 bytes using an additional
padding TLS extension.
Browsers can also send different ﬁngerprints from default
due to end-user conﬁgurations or preferences. For example,
4
We discuss clustering similar ﬁngerprints in Section IV.
GREASE Because GREASE adds “random” extensions,
cipher suites, and supported groups,
implementations that
support it would create dozens of unique ﬁngerprints unless
we normalize them. The speciﬁcation provides 16 values that
can be used as extension IDs, cipher suites, or supported
groups, ranging from 0x0a0a to 0xfafa. While BoringSSL,
used by Google Chrome, chooses these values randomly, we
ﬁnd their position is deterministic (e.g. ﬁrst in the cipher suite
list, and ﬁrst and last in the extension list). We normalize
these values in our dataset by replacing them with the single
value 0x0a0a, which preserves the fact that an implementation
supports GREASE while removing the speciﬁc random value
that would otherwise generate unique ﬁngerprints.
IV. HIGH-LEVEL RESULTS
We collected TLS Client Hello ﬁngerprints for approxi-
mately 9 months between late October 2017, and early Au-
gust 2018 (ongoing). From December 28, 2017 onward, we
additionally collected SNIs, destination IPs and anonymized
source IPs from a sample of trafﬁc, and we collected Server
Hello messages starting on January 24, 2018.
Overall, we successfully collected and parsed over 11 bil-
lion TLS Client Hello messages. A small fraction (about
3.3%) of TLS connections failed to produce a parseable Client
Hello, most commonly due to the ﬁrst data received in a
connection not parsing as a TLS record or Client Hello. This
can happen for packets sent out of order or TCP fragments.
We also ignored packets with incorrect TCP checksums, which
happened with negligible frequency (0.00013%)5.
Our collection suffered two major gaps, ﬁrst starting on
February 5 we only received partial trafﬁc, and second between
March 28 and April 19 we lost access to the tap due to a
network failure. Figure 3 shows the number of Client Hello
messages parsed over time, showing our gaps as well as the
diurnal/weekend/holiday pattern of trafﬁc.
Long tail ﬁngerprint distribution
Our 11 billion TLS Client Hellos comprised over 230,000
unique ﬁngerprints, a surprisingly high amount if we naively
5Due to a bug in the underlying pnet packet library, as many as 10% of
packets were falsely reported to have incorrect checksums. We ﬁxed this bug
on January 25, 2018, but believe it had minimal impact on data-carrying TCP
packets
PF_RING10 Gbps TapTrack TLSFlowsParseFingerprintClient HelloServer HelloUpdate DBThreadPostgresRust process (4) 0 500 1000 1500 2000 2500 3000 3500Nov 01, 2017Dec 01, 2017Jan 01, 2018Feb 01, 2018Mar 01, 2018Apr 01, 2018May 01, 2018Jun 01, 2018Jul 01, 2018Connections / secondFig. 4. Total Unique Fingerprints — The number of unique TLS ClientHello
ﬁngerprints observed rises slowly but steadily over time, reaching over 152,000
by May 2018. This rise is punctuated by short but rapid increases in the number
of unique ﬁngerprints, which we determined came from a small set of Internet
scanners sending seemingly random ClientHello messages.
assume each ﬁngerprint corresponds to a unique implementa-
tion. Figure 4 shows the total number of unique ﬁngerprints
over time, rising from an initial 2145 to 230,000 over the
course of several months.
Immediately visible are large steps in the number of
unique ﬁngerprints, signifying discrete events that produced
a large number of ﬁngerprints. We discover that these events
correspond to a single monthly Internet scanner that produces
very few connections, but appears to be sending a signiﬁcant
number of random unique ﬁngerprints. In fact, over 206,000
of these ﬁngerprints were only seen a single time, generally
from the same /16 network subnet. While this scanner had
a large impact on the number of unique ﬁngerprints,
its
impact on connections was negligible. In the remainder of
this paper, we report on the percent of connections that a
ﬁngerprint or ﬁngerprints comprise, effectively allowing us
to highlight common ﬁngerprints without inﬂuence from this
single scanner.
Figure 5 shows the CDF of connections seen per ﬁngerprint
for the most popular 5,000 ﬁngerprints (for both Client and
Server hello messages). 99.96% of all connections use one of
top 5000 Client Hello ﬁngerprints, and one of top 1310 Server
Hello ﬁngerprints.
Many of the top ten ﬁngerprints (shown in Table I) are
variants generated by the same TLS implementation: for exam-
ple, Google Chrome 65 generates two ﬁngerprints (with and
without the padding extension), ranked 1st and 4th over the
past week in our dataset. Chrome may also optionally include
ChannelID extensions depending on if the connection is made
directly or via an AJAX connection.
Fingerprint clusters
As mentioned, some implementations generate multiple
TLS ﬁngerprints, due to buggy middlebox workarounds, types
of TLS connection, or user preferences. This raises the ques-
tion of how many ﬁngerprints does a typical implementation
produce? We compared ﬁngerprints by performing a basic
Levenshtein distance over the components we extracted in the
Client Hello. For example, two ﬁngerprints that only differ
by the presence of the padding extension would have a
Fig. 5. CDF of connections per ﬁngerprint — While we observed over
152,000 ClientHello ﬁngerprints, most connections were comprised of a small
number of ﬁngerprints: over half the connections were of one of the top 12
ﬁngerprints, and the top 3000 ﬁngerprints make up 99.9% of connections
observed. For servers, only 4,700 ﬁngerprints were observed, with half of the
connections using one of the top 19 server ﬁngerprints.
August 2018
Client
Chrome 65-68
iOS 11/macOS 10.13 Safari
Rank
1
2
3 MS Ofﬁce 2016 (including Outlook)
4
5
6
7
8
9
10
Chrome 65-68 (with padding)
Edge 15-18, IE 11
Firefox 59-61 (with padding)
Safari 11.1 on Mac OS X
iOS 10/macOS 10.12 Safari
iOS 11/macOS 10.13 Safari (with padding)
Firefox 59-61
% Connections
16.51%
5.95%
5.34%
4.62%
4.05%
3.62%
2.82%
2.49%
2.42%
2.22%
December 2018
Client
Chrome 70 (with padding)
iOS 12/macOS 10.14 Safari
iOS 12/macOS 10.14 Safari (without ALPN)
Chrome 70
iOS 12/macOS 10.14 Safari (with padding)
Edge 15-18, IE 11
Rank
1
2
3
4
5
6
7 MS Ofﬁce 2016 (including Outlook)
8
9
10
TABLE I.
iOS 10/macOS 10.12 Safari
iOS 11/macOS 10.13 Safari
Chrome 71 (with padding)
TOP 10 IMPLEMENTATIONS. — MOST FREQUENTLY SEEN
% Connections
8.49%
7.55%
4.15%
4.10%
4.09%
3.27%
3.01%
2.72%
2.68%
2.48%
FINGERPRINTS IN OUR DATASET AND THE IMPLEMENTATIONS THAT
GENERATE THEM, FOR A WEEK IN AUGUST AND DECEMBER 2018.
DESPITE BEING ONLY 4 MONTHS APART, TOP 10 FINGERPRINTS CHANGED
SUBSTANTIALLY, AS NEW BROWSER RELEASES QUICKLY TAKE THE PLACE
OF OLDER VERSIONS.
Levenshtein distance of 1, while a pair of ﬁngerprints that
differed by a dozen cipher suites would have a distance of 12.
To determine the prevalence of multiple ﬁngerprint vari-
ants, we generated clusters of popular ﬁngerprints. We looked
at the 6629 ﬁngerprints that were seen more than 1000 times
in our dataset (accounting for 99.97% of all connections), and
clustered them into groups if they were within a Levenshtein
distance of 5 from another ﬁngerprint
in the group. This
clustering resulted in 1625 groups, with the largest group
having 338 ﬁngerprints in it, corresponding to variants of
Microsoft Exchange across several versions. Google Chrome
65 appeared in a cluster with 117 ﬁngerprints, containing two
weakly-connected sub-clusters. Half of this cluster represents
ﬁngerprints corresponding to an early TLS 1.3 draft, and the
other half the current standard. Unsurprisingly, these ﬁnger-
prints are long-tailed, with the top 10 ﬁngerprints in the group
5
 0 50000 100000 150000 200000 250000Nov 01, 2017Dec 01, 2017Jan 01, 2018Feb 01, 2018Mar 01, 2018Apr 01, 2018May 01, 2018Jun 01, 2018Jul 01, 2018Total Unique FingerprintsTime 0 0.2 0.4 0.6 0.8 1 1 10 100 1000CDF of connectionsFingerprint rank (logscale)ClientServerresponsible for 96% of the connections from the cluster.
Fingerprint churn
Fig. 6. Fingerprint turnover — Shows fraction of connections/ﬁngerprints
not seen during the ﬁrst week. This roughly models the fraction that censor
would overblock, if they took a static ﬁngerprint snapshot and whitelisted it.
To measure how quickly ﬁngerprints change and how this
would impact a censor, we developed a simple heuristic. We
compile a list of all ﬁngerprints seen at least 10 times in the
ﬁrst week, and in subsequent weeks, compare ﬁngerprints that
were seen a substantial amount (10,000) times. This models
the rate at which new ﬁngerprints (with non-negligible use) are
observed, and for a censor that employs a whitelist approach,
describes the fraction of connections they would inadvertently
block if they did not update their whitelist from an initial
snapshot.
Figure 6 shows the increase in both ﬁngerprints and con-
nections blocked over time as new ﬁngerprints are observed
compared to an initial whitelist composed on the ﬁrst week. In
the steady state prior to March, the weekly average increase
in blocked connections is approximately 0.03% (0.33% by
ﬁngerprints), suggesting that the rate of new ﬁngerprints is
steady but small. However, in March, both Google Chrome
and iOS deployed updates that included new support for TLS
features, creating a substantial increase in connections using
new ﬁngerprints. As a result, a non-adaptive whitelist censor
would end up blocking over half of all connections after just
6 months.
Such large events could present a difﬁcult situation for
a whitelist censor, as new versions would be blocked until
new rules were added. We conclude that whitelisting TLS
implementations for a censor may be feasible, but requires
a potentially expensive upkeep effort to avoid large collateral
damage.
SNI
Subject Name Indication is a widely used TLS extension
that lets the client specify the hostname they are accessing.
Because it is sent in the clear in the Client Hello message,
SNIs can be another feature that censors use to block. Many
tools have different strategies for setting the SNI. Some use
domain fronting, and set the SNI to a popular service inside
the cloud provider (e.g. maps.google.com), while others choose
to omit the SNI for ease of implementation or compatibility
reasons.
6
As of August 2018, we observe only 1.41% of connections
do not send the SNI extension, indicating that the circumven-
tion strategy of omitting SNIs may potentially stand out and
be easy to block. Indeed, the most popular SNI-less ﬁngerprint
in our dataset (accounting for 0.20% of all connections)
sends a very unique cipher suite list not seen in any other
ﬁngerprints. This result impacts many circumvention tools,
including Psiphon and Lantern that both produce Client Hello
messages that do not include the SNI extension, suggesting
that these connections may be easy for censors to block.
V. CENSORSHIP CIRCUMVENTION TOOLS
Many censorship circumvention tools use TLS as an
outer layer protocol. For example, domain fronting uses TLS
connections to popular CDN providers with cleartext SNIs
suggesting the user is connecting to popular domains hosted
there [25]. Inside the TLS connection, the user speciﬁes a
proxy endpoint located at the CDN as the HTTP Host, relying
on the CDN’s TLS terminator and load balancer to route
their trafﬁc to the intended destination. As censors only see
the unencrypted SNI, they cannot distinguish domain fronting
connections from benign web trafﬁc to these CDNs. Psiphon,
meek and Signal use this technique to conceal their trafﬁc
from would-be censors [17], [32], [57]. However, mimicking
connections in this manner is difﬁcult in practice: any devia-
tions from the behavior of true browsers that typically access
these CDNs allows a censor to detect and block this style of
proxy [30].