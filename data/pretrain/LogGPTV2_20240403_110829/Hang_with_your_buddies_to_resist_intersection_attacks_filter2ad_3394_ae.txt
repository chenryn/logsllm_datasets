### Tolerating Offline Periods in Anonymous Communication Schemes

Many anonymous communication schemes, such as those used in blogs, can tolerate longer communication latencies. These schemes often aggregate user behavior into selectable time periods. For example, mix-nets [8, 15] use batches, and DC-net systems like BlogDrop [12] and Verdict [13] use drop-off windows. Users who come online and participate at any time during each window are indistinguishable to the adversary, allowing the system to tolerate brief offline periods without compromising anonymity. Similarly, "buddies" policies can be configured to handle users who go offline for short periods without losing anonymity, as discussed in Section 3.1. The primary cost is an increase in communication latency up to the offline tolerance period.

Without focusing on any specific mechanism, we parameterize our ideal anonymity analysis on the assumption that a long-lived pseudonym has a way to tolerate users who go offline for varying maximum offline times.

### Ideal Anonymity Analysis

Figure 3(b) illustrates the ideal anonymity achievable for a hypothetical long-lived pseudonym whose lifetime spans the entire 1-month observation period of the IRC trace. The x-axis shows the varying maximum offline time on a log scale. Since this scenario provides only one data point per IRC trace for a given maximum offline period, the figure includes the same analysis for several different IRC datasets.

Consistent with Figure 3(a), long-lived pseudonyms that cannot tolerate even short offline periods—necessary for low-latency communication—achieve small anonymity sets consisting of only 10–30 users who were continuously online throughout the trace. A long-lived pseudonym that can tolerate disconnections up to one hour can achieve 100-user anonymity sets across the 1-month trace in the football and iPhone rooms. A pseudonym that can tolerate 1-day disconnections—realistic for a blog whose author posts at most once per day—can achieve larger anonymity sets of around 200 users, or 6% of the football group's total observed membership.

In general, the IRC datasets show a common pattern: a small set of dedicated users is almost always online, a larger set (roughly 15% to 20%) appears about once an hour to once a day, and a large set of ephemeral users (around 80% of the total population) are less consistent. Ephemeral users do not significantly contribute to the anonymity sets of long-lived pseudonyms but are important for the presence and can increase anonymity for short-lived pseudonyms, as shown in Figure 3(a).

### Possinymity Analysis and Enforcement

We now explore the behavior of Buddies' possibilistic anonymity metric under our IRC trace workloads. While the above ideal anonymity analysis explored the levels of anonymity a "hypothetical" pseudonym might achieve, we now use our traces to model specific pseudonyms and explore their behavior under specific Buddies policies. We consider the messages posted by each IRC user to represent one pseudonym, the times these messages appeared to represent a schedule of the times the modeled pseudonym owner had a message to post, and the nominal lifetime of each modeled pseudonym as the time from the first message to the last message. We then replay this activity under AS, the Anonymity Simulator, to evaluate the behavior of Buddies' metrics under these activity traces, including the (sometimes indefinite) delays that Buddies imposes to preserve anonymity.

Figure 4 shows how possinymity evolves across the lifetimes of pseudonyms with 1-second round times (no offline time tolerance). The x-axis represents time since each pseudonym's inception, and the y-axis value of the solid lines shows the minimum or worst-case possinymity across all pseudonyms whose lifetimes extend at least to that point. Each line color reflects behavior under a Buddies policy that enforces a different possinymity lower bound, represented by the corresponding horizontal dotted line.

Consistent with our expectations from Figures 2 and 3(a), possinymity starts at the number of users online at the time of the first post and gradually decreases as users churn offline. Enforcing a lower bound leaves pseudonyms' behavior unaffected until just before a message post would decrease the pseudonym's possinymity below the lower bound. At this point, the pseudonym becomes unable to post, and possinymity remains constant after that point in the trace.

### Indinymity Analysis and Buddy Sets

We now explore probabilistic attacks and Buddies' ability to protect users against such attacks via buddy sets. To validate the protection, we model a particular probabilistic intersection attack where the attacker observes the messages posted by a pseudonym, assumes the owner decided whether to post in each round with a fixed, independent probability \( p \), and uses the analysis outlined in Section 2.3.2 to divide users into classes based on the likelihood of owning the pseudonym. The attacker then makes a "best guess" at which user owns the pseudonym, and we compute the attacker's chance of guessing correctly: \( \frac{1}{k} \) if the owner is within the k-user equivalence class the attacker judges most likely, and 0 if not.

Figure 5 shows pseudonyms' measured worst-case anonymity under this probabilistic attack, as a function of the length of time each pseudonym has been active. Each line color represents a different buddy set size enforcement policy, with dotted lines representing effective anonymity against the probabilistic guessing attack, solid lines representing measured possinymity for reference, and dashed lines representing the buddy set size—and hence indinymity lower bound—enforced by the respective policy. Note that these graphs have logarithmic x-axes, unlike Figure 4. While possinymity decreases at a relatively constant rate with user churn, the probabilistic attack is much faster, effectively eliminating the vast majority of an unprotected user's initial anonymity set within the first hour since a pseudonym starts posting. Nevertheless, for a given enforced buddy set size, the probabilistic attack only approaches, but never violates, the enforced indinymity bound.

### Effect on Usable Pseudonym Lifetime

While the above experiments validate Buddies' effectiveness at mitigating anonymity loss through both possibilistic and probabilistic intersection attacks, this security comes with usability trade-offs. Buddies policies may make a pseudonym unusable for posting messages before the owner naturally finishes using it, and in still usable pseudonyms, messages may be delayed.

Figure 6 contains CDFs showing the distributions of useful lifetimes of pseudonyms under various enforced buddy set sizes. The black line represents the nominal case, showing the distribution of pseudonym lifetimes in the IRC trace without any Buddies policy. Each colored line shows the distribution of actual, useful pseudonym lifetimes upon enforcing a given buddy set size.

For many pseudonyms, resistance to probabilistic intersection attacks comes at a high cost. As Figure 6(a) shows, 50% of the pseudonyms modeled in the trace have nominal lifetimes of at least one day, but under enforced buddy set sizes of 32 or more, 50% of pseudonyms remain usable only for about an hour under Buddies. Some pseudonyms remain usable for much longer, especially those whose owners are long-lived and fall into the same buddy set with other long-lived, reliable users.

For each buddy set size, the graph contrasts two schemes for dividing users into buddy sets. The Oracle scheme sorts users based on their maximum offline time, clustering users with similar reliability levels together. The dotted lines reflect a more realistic, dynamic scheme designed along the lines discussed in Section 3.2, clustering users based on recent past reliability history. Since past reliability is not a perfect predictor of future reliability, the realistic, dynamic scheme incurs some further loss of effective pseudonym lifetime. The current dynamic scheme is simplistic and can likely be improved, so we expect the utility actually achievable in practical systems to lie somewhere between the respective solid and dotted lines.

### Effect on Pseudonym Messaging Delay

Finally, for messages that users successfully transmit via pseudonyms under various enforced buddy set sizes, Figure 7 shows the distribution of artificial delays that Buddies imposes on those message transmissions to preserve indinymity. The percentage of messages experiencing delays increases with buddy set size, as any pseudonym's owner must wait to post until all her buddies are also online. When a message is delayed, it is commonly delayed by at least one hour, and under large buddy set sizes often by a day or more. This result confirms that long-term resistance to probabilistic intersection attacks in dynamic networks may be feasible only for delay-tolerant transmission.

We contrast the messaging delays experienced under the two buddy set formation schemes: one based on an oracle's perspective of users' long-term reliability, the other based on a more realistic dynamic algorithm. Surprisingly, the dynamic scheme actually delays fewer messages than the oracle scheme. This is because the oracle scheme sorts buddies based on global reliability measured over the entire trace, potentially grouping together users who were online for similar durations but at different times. The dynamic scheme, using recent information localized in time, better groups ephemeral users who are online at similar times. Neither of these buddy set formation schemes is likely to be optimal, and improving them is a useful area for future work.

### Practical Considerations

The integration of Buddies into Dissent sheds light on both the overheads of Buddies in a real system and the implementation complexities it induces. We built both Buddies and a web service for querying the various Buddies meters and modified Dissent [52] to support reactive and proactive analysis in the anonymity protocol and to transmit the set of online members (those with ciphertexts used in Dissent) along with the cleartext messages at the end of each round. Buddies totaled 528 lines of C++ code, while Dissent incurred only 41 lines of additional C++ code. Included within the 528 lines of C++ code, Buddies comes with both a static and dynamic policy, each weighing in at 89 and 172 lines of code, respectively.

In Dissent, the buddy set concept applied cleanly; however, in the current Dissent implementation, the maintenance of possinymity is not ideal. While DC-nets theoretically allow serial processing of anonymous cleartexts, allowing finer-grained control over possinymity, currently, Dissent servers perform the cleartext revealing process for all scheduled Nyms in parallel, limiting possinymity evaluations to occur only before processing the first anonymous cleartext. Performing the operation iteratively would require adding additional interaction among the servers, potentially adding significant overhead. Overhead would be negligible only for rounds with interval time \( t \) in which there were \( m \) scheduled Nyms with inter-server network latency of \( l \), where \( m \times l \ll t \). Fortunately, the Dissent implementation does support scheduling Nyms during different intervals, and therefore Buddies can still make both possinymity and indinymity sets largely independent for different Nyms.

Using our Dissent implementation of Buddies, we focused on...