such as blogs, can often tolerate longer communication la-
tencies. Many anonymous communication schemes can ag-
gregate user behavior into selectable time periods, such as
batches in mix-nets [8,15], or dropoﬀ windows in DC-net sys-
tems such as BlogDrop [12] or Verdict [13]. Users who come
online and participate at any time during each window are
indistinguishable to the adversary, enabling the system to
tolerate users who go oﬄine brieﬂy for periods shorter than
that window. Buddies policies can similarly be conﬁgured to
tolerate users who go oﬄine for brief periods without ano-
nymity loss, as discussed in Section 3.1. In all these cases, the
main cost is to increase communication latency up to that
oﬄine tolerance period. Without focusing on any particu-
lar mechanism, we now parameterize our ideal anonymity
analysis on the assumption that a long-lived pseudonym has
some way to tolerate users who go oﬄine for periods up to
a varying maximum oﬄine time.
Figure 3(b) shows the ideal anonymity achievable for a
hypothetical long-lived pseudonym whose lifetime is the en-
tire 1-month observation period of the IRC trace, assum-
ing that pseudonym can tolerate a varying maximum of-
ﬂine time shown on the log-scale x-axis. Since this scenario
gives us only one “data point” per IRC trace for a given
maximum oﬄine period, the ﬁgure shows the same analy-
sis for several diﬀerent IRC datasets. Consistent with the
Membersonline timemessage posts 200 400 600 800 1000 1207Week 1Week 2Week 3Week 4Membersonline timemessage posts 200 400 600 800 1000 1207Week 1Week 2Week 3Week 41161(a) Ideal anonymity set size potentially achievable by a low-
latency pseudonym of varying lifetime. The pseudonym can
tolerate no oﬄine time in members of its anonymity set.
(b) Ideal anonymity potentially achievable for long-lived (1-
month) pseudonyms, tolerating anonymity set members who
go oﬄine for a varying maximum oﬄine time period.
Figure 3: Analysis of ideal anonymity potentially achievable based on user behavior in the IRC football room.
right edge of Figure 3(a), long-lived pseudonyms that can-
not tolerate even short oﬄine periods—as required for low-
latency communication—achieve small anonymity sets con-
sisting of only the 10–30 users in each trace who were contin-
uously throughout the trace. (The leftmost portion of this
graph may be optimistic, in fact, as the IRC server may
not have logged temporary network disconnections shorter
than the TCP timeout of around 30 seconds.) A long-lived
pseudonym that can tolerate disconnections up to one hour,
however, can achieve 100-user anonymity sets across the 1-
month trace in the football and iphone rooms. A pseudo-
nym that can tolerate 1-day disconnections—realistic for a
blog whose author posts at most once per day anyway—can
achieve still larger anonymity sets of around 200 users, or
6% of the football group’s total observed membership.
In general, the IRC datasets exhibit a common pattern
where a small set of dedicated users is almost always online,
a larger set–roughly 15% to 20%–who show up about once
an hour to once a day, and a large set of ephemeral users
comprise around 80% of the total population. We do not ex-
pect ephemeral users to contribute usefully to the anonymity
sets of long-lived Nyms, but it is important for Buddies to
operate in their presence, and ephemeral users can increase
anonymity for short-lived Nyms as Figure 3(a) shows.
5.3 Possinymity Analysis and Enforcement
We now explore the behavior of Buddies’ possibilistic an-
onymity metric, as deﬁned in Section 2.3.1, under our IRC
trace workloads. While the above ideal anonymity analysis
generically explored the levels of anonymity a “hypothetical”
pseudonym might achieve, we now wish to use our traces to
model speciﬁc pseudonyms and explore their behavior under
speciﬁc Buddies policies. To do so, we consider the messages
posted by each IRC user to represent one pseudonym in our
model, we take the times these IRC messages appeared to
represent a “schedule” of the times the modeled pseudonym
owner had a message to post, and we deﬁne the nominal life-
time of each modeled pseudonym as the time from the ﬁrst
message to the last message. We then replay this activity un-
der AS, the Anonymity Simulator, to evaluate the behavior
of Buddies’ metrics under these activity traces, and the ef-
fect of Buddies policies on actual communication behavior,
Figure 4: Evolution of worst-case possinymity over trace
taking into account the (sometimes indeﬁnite) delays that
Buddies sometimes imposes to preserve anonymity.
Figure 4 shows how possinymity evolves across the life-
times of pseudonyms with 1-second round times (no oﬄine
time tolerance). The x-axis represents time since since each
pseudonym’s inception—i.e., from its ﬁrst scheduled mes-
sage. The y-axis value of the solid lines show minimum or
worst-case possinymity across all pseudonyms whose life-
times extend at least to that point. Each line color in the
graph reﬂects behavior under Buddies policy that enforces
a diﬀerent possinymity lower bound, whose enforced level is
represented by the corresponding horizontal dotted line.
Consistent with our expectations from Figures 2 and 3(a),
possinymity starts at the number of users online at time of
ﬁrst post, and gradually decreases as users “churn” oﬄine
and get intersected out of the pseudonym’s possinymity set
at a relatively constant rate. In practice, enforcing a lower
bound leaves pseudonyms’ behavior unaﬀected until just be-
fore a message post would decrease the pseudonym’s possi-
nymity below the lower bound. At this point the pseudonym
becomes unable to post—i.e., Buddies deliberately compro-
mises availability to preserve anonymity—leaving possinym-
ity constant after that point in the trace.
 10 20 30 50 100 200 500 1000 20001s1min1hr1day1weekAnonymity SetPseudonym Lifetimemaxmedianmin 10 20 30 50 100 200 500 1000 20001s1min1hr1day1weekMembersTime periodfootballiphoneredhatstocks 10 20 30 50 100 200 500 1000 20001s1min1hr1day1weekMembersTime periodMax offline timeTotal offline time 10 20 30 50 100 200 300 500 1000week 1week 2week 3PossinimityTime since pseudonym’s first activity1-in-2561-in-1921-in-128No possinimity 10 20 30 50 100 200 300 500 1000week 1week 2week 3PossinimityTime since pseudonym’s first activityActualEnforced11625.4 Indinymity Analysis and Buddy Sets
We now explore probabilistic attacks of the form discussed
in Section 2.3.2, and Buddies’ ability to protect users against
such attacks via buddy sets. To validate the protection Bud-
dies provides, we model one particular probabilistic inter-
section attack, in which the attacker observes the messages
posted by a pseudonym, assumes the owner decided whether
to post in each round with a ﬁxed, independent probability
p, and uses the analysis outlined in Section 2.3.2 to divide
users into classes based on likeliness of owning the pseudo-
nym. The attacker then makes a “best guess” at which user
owns that pseudonym, and we compute the attacker’s chance
of guessing correctly: 1/k if the owner is within the k-user
equivalence class the attacker judges most likely, and 0 if not.
We make no claim that this particular attack is representa-
tive of the attacks most likely to be mounted by real-world
adversaries, but merely use it as an example to test and
visualize the eﬀectiveness of buddy sets. We reiterate that
Buddies’ security is based ultimately not on knowledge or
expectations of particular attacks, but on an indistinguisha-
bility principle that applies to all probabilistic attacks using
observed online/oﬄine behavior as inputs.
Figure 5 shows pseudonyms’ measured worst-case ano-
nymity under this probabilistic attack, again as a function
of the length of time each pseudonym has been active. Each
line color represents a diﬀerent buddy set size enforcement
policy, with dotted lines representing eﬀective anonymity
against the probabilistic guessing attack, solid lines rep-
resenting measured possinymity for reference, and dashed
lines representing the buddy set size—and hence indinymity
lower bound—enforced by the respective policy. Note that
these graphs have logarithmic x-axes, unlike Figure 4. While
possinymity decreases at a relatively constant rate with user
churn, the probabilistic attack is much faster—effectively
eliminating the vast majority of an unprotected user’s ini-
tial anonymity set within the ﬁrst hour since a pseudonym
starts posting, for example. Nevertheless, for a given en-
forced buddy set size, the probabilistic attack only approach-
es, but never violates, the enforced indinymity bound.
5.5 Effect on Usable Pseudonym Lifetime
While the above experiments validate Buddies’ eﬀective-
ness at mitigating anonymity loss through both possibilistic
and probabilistic intersection attacks, this security neces-
sarily comes with usability tradeoﬀs. Buddies policies may
make a pseudonym unusable for posting messages before the
owner naturally ﬁnishes using the pseudonym, and in still
usable pseudonyms, messages may be delayed.
To explore Buddies’ eﬀect on pseudonym usability, Fig-
ure 6 contains CDFs showing the distributions of useful life-
times of pseudonyms under various enforced buddy set sizes.
As the relevant comparison baseline, the black line repre-
senting the nominal case shows the distribution of pseudo-
nym lifetimes in the IRC trace without any Buddies policy.
We take this line to represent the distribution of time peri-
ods during which traced users intended to use a pseudonym
to post messages. Each colored line in contrast shows the
distribution of actual, useful pseudonym lifetimes upon en-
forcing a given enforced buddy set size.
For many pseudonyms, unfortunately, resistance to prob-
abilistic intersection attack comes at a high cost. As Fig-
ure 6(a) shows, for example, 50% of the pseudonyms mod-
eled in the trace have nominal lifetimes of at least one day—
meaning that their owners “would like to” use them for one
day—but under enforced buddy set sizes of 32 or more,
50% of pseudonyms remain usable only for about an hour
under Buddies. Some pseudonyms remain usable for much
longer even under Buddies, however: in particular, those
pseudonyms whose owners are long-lived and fall into the
same buddy set with other long-lived, reliable users.
For each buddy set size, the graph additionally contrasts
two schemes for dividing users into buddy sets. The Or-
acle scheme “sorts” users into buddy sets based on their
maximum oﬄine time, as measured for Figure 3(b), thereby
clustering users with similar reliability levels together from
the perspective of an oracle who can “see” into the future.
The dotted lines, for comparison, reﬂect a more realistic,
dynamic scheme designed along the lines discussed in Sec-
tion 3.2. This scheme clusters users into buddy sets dynam-
ically based only on recent past reliability history, up to to
the point in time when a large buddy set must be subdivided
in order to keep a pseudonym usable. Since past reliability
is not a perfect predictor of future reliability, the realistic,
dynamic scheme incurs some further loss of eﬀective pseu-
donym lifetime. The current dynamic scheme is simplistic
and can likely be improved, so we expect the utility actually
achievable in practical systems to lie somewhere between the
respective solid and dotted lines.
5.6 Effect on Pseudonym Messaging Delay
Finally, for messages that users successfully transmit via
pseudonyms under various enforced buddy set sizes, Figure 7
shows the distribution of artiﬁcial delays that Buddies im-
poses on those message transmissions to preserve indinymity.
Unsurprisingly, the percentage of messages experiencing de-
lays increases with buddy set size, since any pseudonym’s
owner must eﬀectively wait to post until all her buddies are
also online, and large buddy sets increase the likelihood of
some buddy being oﬄine at the time of a desired message
transmission. When a message is delayed, unfortunately, it
is commonly delayed by at least one hour, and under large
buddy set sizes often by a day or more. This result further
conﬁrms our intuition that long-term resistance to proba-
bilistic intersection attacks in dynamic networks may really
be feasible only for delay-tolerant transmission.
We contrast the messaging delays experienced under the
two buddy set formation schemes above: one based on an
oracle’s perspective of users’ long-term reliability, the other
based on a more realistic dynamic algorithm. In this case,
we ﬁnd somewhat surprisingly that the dynamic scheme ac-
tually delays substantially fewer messages than the oracle
scheme. This is because the oracle scheme sorts buddies into
sets based only on global reliability measured over the entire
trace, and may inappropriately group together users who
were online for similar durations but at diﬀerent times. As
the dynamic scheme builds buddy sets using recent infor-
mation localized in time, it better groups ephemeral users
who are online at similar times. Neither of these buddy set
formation schemes are likely to be close to optimal, and we
consider improving them to be a useful area for future work.
5.7 Practical Considerations
The integration of Buddies into Dissent sheds light into
both the overheads of Buddies in a real system and the im-
plementation complexities that Buddies induces. We built
both Buddies and a web service for querying the various
1163(a) 1-second rounds
(b) 1-hour rounds
(c) 1-day rounds
Figure 5: Measured worst-case anonymity loss over time under one example probabilistic intersection attack.
(a) 1-second rounds
(b) 1-hour rounds
(c) 1-day rounds
Figure 6: CDFs showing distributions of pseudonym lifetimes, with and without indinymity enforcement via buddy sets.
Buddies meters and we modiﬁed Dissent [52] to 1) support
the reactive and proactive analysis in the anonymity proto-
col and 2) transmit the set of online members (those with
ciphertexts used in Dissent) along with the cleartext mes-
sages at the end of each round. Buddies totaled 528 lines
of C++ code, while Dissent incurred only 41 lines of ad-
ditional C++ code. Included within the 528 lines of C++
code, Buddies comes with both a static and dynamic policy
each weighing in at 89 and 172 lines of code, respectively.
In Dissent, the buddy set concept applied cleanly; how-
ever, in the current Dissent implementation, the mainte-
nance of possinymity is not ideal. While DC-nets theoret-
ically allow serial processing of anonymous cleartexts allow-
ing ﬁner grained control over possinymity, currently, Dis-
sent servers perform the cleartext revealing process for all
scheduled Nyms in parallel, which limits possinymity evalu-
ations to occur only before processing the ﬁrst anonymous
cleartext. Performing the operation iteratively would require
adding additional interaction among the servers, potentially
adding signiﬁcant overhead. Overhead would be negligible
only for rounds with interval time t in which there were
m scheduled Nyms with inter-server network latency of l,
where m × l (cid:28) t. Fortunately, the Dissent implementation
does support scheduling Nyms during diﬀerent intervals, and
therefore Buddies can still make both possinymity and in-
dinymity sets largely independent for diﬀerent Nyms.
Using our Dissent implementation of Buddies, we focused