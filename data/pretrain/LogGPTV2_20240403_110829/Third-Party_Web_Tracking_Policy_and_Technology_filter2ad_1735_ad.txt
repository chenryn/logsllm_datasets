My Opt Outs, largely mitigate these issues at the cost of
usability.
it
Many online advertising companies have begun to insert
an “AdChoices” icon (13x13px) and text (10pt) into display
ads (Figure 2(b)) to increase user awareness of behavioral
targeting and existing self-regulatory choice mechanisms.
Clicking the icon provides additional information about how
the ad was targeted and, in many cases, a link to landing
page where the user can set opt-out cookies.
Several studies have called into question the usability of
the self-regulatory opt-out model.
Before the deployment of the AdChoices icon an industry-
funded policy group conducted a large-audience usability
survey [106]. It found that a 31x31px icon with 18pt font
(Figure 3(a)) was not very effective at conveying information
about behavioral targeting practices (“substantial repetition
and consumer education may be needed to improve [the
422
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:38 UTC from IEEE Xplore.  Restrictions apply. 
Figure 2. Evolution of the AdChoices icon.
(a) Proposed icon and text [104] (actual size at 115 DPI).
(b) Implemented icon and text [105] (actual size at 115 DPI).
icon’s] communication effectiveness over time”), and that
the text “AdChoice” performed worse than alternatives.
McDonald and Cranor [34] conducted a large-audience
survey on user perceptions of a self-regulatory opt-out page.
88% of participants understood that
the page related to
online advertising and opting out, but only 11% correctly
responded that the page allows opting out of behavioral
targeting, not tracking (34%), ads from speciﬁc companies
(25%), or some proportion of advertising (18%).
Leon et al. [107] examined the usability of two other self-
regulatory websites with ﬁve in-laboratory participants each.
On one website, the Digital Advertising Alliance, only one
of the ﬁve users was able to opt out without guidance, and
none of the users correctly understood the implications of
opting out. On the other website, Evidon, four of the ﬁve
users were able to opt out without guidance, though it took
the participant who chose to opt out of all companies 47
minutes to exercise his or her preferences. Once again none
of the users correctly understood what opting out would do.
Leon et al. also studied the usability of the TACO exten-
sion. All ﬁve participants enabled persistent opt-out cookies,
the default setting.
Hernandez et al. [105] measured the prevalence of the
AdChoices program on the Alexa U.S. 500 top homepages.
They found an icon in only 9.9% of third-party ads and an
icon and text in only 5.1%.
The online advertising trade groups have declined to
provide overall usage statistics of opt-out cookies. Anecdotal
reports (e.g. [108]) place usage at less than 1% of browsers.
B. Blocking
Given the myriad approaches to tracking a browser—
many of which require nothing more than an HTTP round-
trip—the most effective user self-help tools21 function by
blocking third-party web content. Nearly all tools consist of
a block list, either available as a subscription for a browser
extension or wrapped in a conﬁgurable browser extension.
To understand the effectiveness of blocking, we conducted
three consecutive FourthParty crawls of the Alexa U.S. top
500 with each of 11 blocking tools installed [110]. We also
conducted a baseline crawl to estimate which PS+1s were
third-party trackers. For each tool we calculated three values
relative to baseline and averaged across all trackers: pages
with an HTTP request to a tracker, pages with an HTTP
Set-Cookie response from a tracker, and cookies added less
cookies deleted by a tracker.22 Figure 3 presents our results.
We found signiﬁcant variability in performance. The most
effective tool was a combination of community-maintained
Fanboy’s Lists for blocking ads, surreptitious tracking, and
social content. All of the top performing tools blocked third-
party advertising, an unsurprising result since there is no
clean division between advertising content and advertising-
related tracking content. The block list from TRUSTe was
not only the least effective, but it also would override other
lists to allow tracking by several sizable third parties.
Leon et al. [107] examined the usability of the Ghostery,
Adblock Plus, and Internet Explorer Tracking Protection List
blocking tools. Two of the ﬁve Ghostery users believed they
had enabled the extension’s blocking feature when, in fact,
they had not. All ﬁve of the Adblock Plus users conﬁgured
the extension with a default advertisement blocking list;
none installed additional lists to block non-advertising track-
ers. All ﬁve Internet Explorer Tracking Protection List users
21For brevity we do not address private browsing [109], third-party
cookie blocking, and other self-help approaches to mitigating tracking. A
fuller discussion is available in [110].
22We included this noisy metric to roughly gauge the effectiveness of
third-party cookie blocking and TrackerBlock, a tool that prevents several
forms of stateful tracking.
423
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:38 UTC from IEEE Xplore.  Restrictions apply. 
Figure 3. Average decrease in tracking with blocking tools.
retained the default setting, to not block any content; they
all believed they had conﬁgured the option to substantially
or completely block tracking.
In sum: blocking can be fairly effective, but it is only a
realistic solution for advanced users.
are in general agreement that Do Not Track must signiﬁ-
cantly curtail third-party information collection. The recent
DAA commitment only requires a third-party website to stop
per-device content personalization if it receives a Do Not
Track signal (see Section IV-C).
C. Do Not Track
Do Not Track uses a combination of technology and
policy to provide consumer choice over web tracking. The
World Wide Web Consortium (W3C) is presently standard-
izing Do Not Track; the W3C’s working group has not yet
reached consensus on the technology or policy components.
The Do Not Track technology is simply an HTTP header,
DNT, that signals a user’s preference about web tracking. As-
sociated technologies have been proposed that would allow
a website to request exceptions and signal its own tracking
status. Firefox, Internet Explorer, Safari, and Opera presently
support a Do Not Track opt-out preference (sending the
DNT: 1 header). Google has pledged to add the feature to
Chrome. As of late 2011, Mozilla [111] reported 5.6% usage
in desktop Firefox and 17.1% usage in Firefox Mobile.
Roughly twenty websites presently honor the Do Not
Track technology, and the Digital Advertising Alliance re-
cently pledged [39] that its about eighty member companies
would begin supporting the header.
Do Not Track enforcement could be accomplished
through measurement of tracking technologies, using tools
like FourthParty.23 In mid-2011 we identiﬁed two advertising
companies that were surreptitiously taking steps to honor Do
Not Track [113], suggesting the approach is quite viable.
The Do Not Track policy deﬁnes what websites must do
when they receive a Do Not Track header. Debates over
the Do Not Track policy have been largely coextensive with
debates over third-party web tracking policy (see Section
III-E). Policymakers, consumer advocates, and researchers
23In the advertising space, Do Not Track might also be enforced by
monitoring ad distributions for evidence of behavioral targeting. It is unclear
how feasible this approach is [112].
X. CONCLUSION
This paper surveyed policy and technology issues in third-
party web tracking as of early 2012. The ﬁeld is rapidly
changing; new announcements, questions, and research re-
sults appear by the week. We hope the information presented
here provides security and privacy researchers with the
background necessary to contribute to this developing ﬁeld
and to meaningfully participate in the ongoing public debate.
ACKNOWLEDGEMENTS
We thank Jovanni Hernandez and Akshay Jagadeesh for
their invaluable research assistance. This paper beneﬁted
from feedback provided by Nick Doty, Peter Eckersley,
Aleecia McDonald, Hart Montgomery, Arvind Narayanan,
Ashkan Soltani, Thomas Steinke, and many others. All
errors and omissions are solely our own.
The authors acknowledge the support of the National Sci-
ence Foundation, the Air Force Ofﬁce of Scientiﬁc Research,
the Ofﬁce of Naval Research, and Stanford University.
REFERENCES
[1] World Wide Web Consortium. Content Security Policy.
[Online]. Available: http://w3.org/TR/CSP/
[2] J. Grossman, R. Hansen, P. D. Petkov, A. Rager, and
S. Fogie, XSS Attacks: Cross-Site Scripting Exploits and
Defense. Burlington, MA: Syngress, 2007.
[3] A. Barth, C. Jackson, and J. C. Mitchell, “Robust defenses
for cross-site request forgery,” in Proceedings of the 2008
ACM Conference on Computer and Communications Secu-
rity, October 2008.
[4] W. Zeller and E. W. Felten, “Cross-site request forgeries:
Exploitation and prevention,” Princeton University, Tech.
Rep., September 2008.
424
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:38 UTC from IEEE Xplore.  Restrictions apply. 
[5] W. Enck, P. Gilbert, B. Chun, L. P. Cox, J. Jung, P. Mc-
Daniel, and A. N. Sheth, “TaintDroid: An information-
ﬂow tracking system for realtime privacy monitoring on
smartphones,” in Proceedings of the 9th USENIX Symposium
on Operating Systems Design and Implementation, October
2010.
[6] S. Thurm and Y. I. Kane, “Your apps are watching you,”
The Wall Street Journal, December 2010.
[7] J. Mayer. (2011, July) Tracking the trackers: To catch a
history thief. [Online]. Available: http://cyberlaw.stanford.
edu/node/6695
[8] M. Ayenson, D. J. Wambach, A. Soltani, N. Good, and C. J.
Hoofnagle, “Flash cookies and privacy II: Now with HTML5
and ETag respawning,” July 2011.
[9] A. Soltani.
(2011, August) Respawn redux.
[Online].
Available: http://ashkansoltani.org/docs/respawn redux.html
[10] B. Krishnamurthy and C. Wills, “Privacy leakage vs. pro-
tection measures: the growing disconnect,” in Proceedings
of the Web 2.0 Security and Privacy Workshop, May 2011.
[11] ——, “On the leakage of personally identiﬁable information
via online social networks,” in Proceedings of the ACM
Workshop on Online Social Networks, August 2009.
[12] B. Krishnamurthy and C. E. Wills, “Privacy diffusion on the
web: A longitudinal perspective,” in Proceedings of the 18th
Conference on the World Wide Web, April 2009.
[13] ——, “Generating a privacy footprint on the Internet,”
the 6th ACM Conference on Internet
in Proceedings of
Measurement, October 2006.
[14] A. Soltani, S. Canty, Q. Mayo, L. Thoma, and C. J. Hoof-
nagle, “Flash cookies and privacy,” August 2009.
[15] F. Roesner, T. Kohno, and D. Wetherall, “Detecting and
defending against third-party tracking on the web,” in Pro-
ceedings of
the 9th USENIX Symposium on Networked
Systems Design and Implementation, April 2012.
[16] P. G. Leon, L. F. Cranor, A. M. McDonald, and R. McGuire,
“Token attempt: The misrepresentation of website privacy
policies through the misuse of P3P compact policy tokens,”
in Proceedings of the 2010 Workshop on Privacy in the
Electronic Society, October 2010.
[17] D. Jang, R. Jhala, S. Lerner, and H. Shacham, “An empirical
study of privacy-violating information ﬂows in JavaScript
web applications,” in Proceedings of the 2006 ACM Confer-
ence on Computer and Communications Security, October
2010.
[18] ECMA. Harmony proxies.
[Online]. Available: http:
//wiki.ecmascript.org/doku.php?id=harmony:proxies
[19] J. Mayer. (2011, October) Tracking the trackers: Where
[Online]. Available:
everybody knows your username.
http://cyberlaw.stanford.edu/node/6740
[20] A. Narayanan.
July) There is no such thing
as anonymous online tracking. [Online]. Available: http:
//cyberlaw.stanford.edu/node/6701
(2011,
[21] Datalogix. Datalogix privacy policy. [Online]. Available:
http://datalogix.com/privacy/
[22] D. Perito, C. Castelluccia, M. A. Kaafar, and P. Manilsr,
“How unique and traceable are usernames?” in Proceedings
of the 2011 Privacy Enhancing Technologies Symposium,
2011.
leakage from multiple online social networks,” IEEE Inter-
net Computing, May 2011.
[24] D. Irani, S. Webb, K. Li, and C. Pu, “Large online social
footprints - an emerging threat,” in Proceedings of the 2009
International Conference on Computational Science and
Engineering, August 2009.
[25] A. Narayanan.
(2008, November) Lendingclub.com: A
de-anonymization walkthrough. [Online]. Available: http:
//33bits.org/2008/11/12/57/
[26] Mozilla Foundation. Public sufﬁx list. [Online]. Available:
http://publicsufﬁx.org/
[27] A. Narayanan.
(2010) How Google Docs leaks your
identity. [Online]. Available: http://33bits.org/2010/02/22/
google-docs-leaks-identity/
[28] L.-S. Huang and C. Jackson, “Clickjacking attacks unre-
solved,” July 2011.
[29] A. Narayanan and V. Shmatikov, “Robust de-anonymization
of large datasets,” in Proceedings of the 2008 IEEE Sympo-
sium on Security and Privacy, May 2008.
[30] ——, “De-anonymizing social networks,” in Proceedings of
the 2009 IEEE Symposium on Security and Privacy, May
2009.
[31] A. Acquisti, R. Gross, and F. Stutzman, “Faces of Face-
book,” in Black Hat 2011, August 2011.
[32] Epsilon.
(2011, April) Epsilon
of
[Online]. Avail-
http://epsilon.com/news-events/press-releases/2011/
unauthorized entry into email system.
able:
epsilon-notiﬁes-clients-unauthorized-entry-email-system
notiﬁes
clients
[33] J. Turow, J. King, C. J. Hoofnagle, A. Bleakley, and
M. Hennessy, “Americans reject tailored advertising and
three activities that enable it,” September 2009.
[34] A. M. McDonald and L. F. Cranor, “Beliefs and behaviors:
Internet users’ understanding of behavioral advertising,” in
Proceedings of the 2010 Research Conference on Commu-
nication, Information and Internet Policy, October 2010.
[35] Gallup. (2010, December) USA Today/Gallup poll. [Online].
Available: http://gallup.com/poll/File/145334/Internet Ads
Dec 21 2010.pdf
Harris
and
and
[36] TRUSTe
Privacy
[Online].
TRUSTe-2011-Consumer-Behavioral-Advertising-Survey-Results.
pdf
July)
behavioral
advertising.
http://truste.com/ad-privacy/
Interactive.
Available:
(2011,
online
[37] Pew Research Center. (2012, March) Search engine use
[Online]. Available: http://pewinternet.org/Reports/
2012.
2012/Search-Engine-Use-2012.aspx
to the online
[38] Article 29 Data Protection Working Party. (2012, March)
[Online].
http://ec.europa.eu/justice/data-protection/
Letter
Available:
article-29/documentation/other-document/ﬁles/2012/
20120301 reply to iab easa en.pdf
advertising industry.
[39] Digital Advertising Alliance.
(2012, February) DAA
position
choice mechanism.
[Online]. Available: http://aboutads.info/resource/download/
DAA Committment.pdf
browser
based
on
[40] S. Stamm. (2011, November) Why we won’t enable DNT
[Online]. Available: http://blog.mozilla.com/
by default.
privacy/2011/11/09/dnt-cannot-be-default/
[23] D. Irani, S. Webb, C. Pu, and K. Li, “Personal-information
[41] T.
Lowenthal.
(2011, November) Deeper
discus-
425
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:38 UTC from IEEE Xplore.  Restrictions apply. 
of
our
[On-
sion
line]. Available: http://blog.mozilla.com/privacy/2011/11/
15/deeper-discussion-of-our-decision-on-dnt-defaults/
on DNT
defaults.
decision
[42] Federal Trade Commission. (2011, March) FTC puts an
end to tactics of online advertising company that deceived
consumers who wanted to “opt out” from targeted ads.
[Online]. Available: http://ftc.gov/opa/2011/03/chitika.shtm