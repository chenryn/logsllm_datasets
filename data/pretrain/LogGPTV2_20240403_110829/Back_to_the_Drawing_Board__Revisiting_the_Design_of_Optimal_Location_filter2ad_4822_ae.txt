Figure 7 shows the performance of the bounded mechanisms in
terms of conditional entropy. The results are similar to those in the
unbounded scenario, with ExPost outperforming the others with
a slightly wider advantage in this case. As bounded mechanisms
do not achieve geo-indistinguishability, we do not evaluate the
performance with respect to this metric in this scenario.
5.2 Discrete scenario
We now consider a simple synthetic scenario and evaluate the
optimal mechanisms obtained following the method by Shokri et. al
[27]. In this work, the authors propose a linear program that finds
a mechanism f inside the polytope of optimal mechanisms for PAE
given a constraint Q, i.e., f ∈ F opt
Q . This approach is very versatile,
as it can be computed for any pair of distance functions dP(·) and
dQ(·). We set our synthetic scenario under the assumptions of that
work: the input and output alphabets are discrete and identical
X = Z, and the adversary can only estimate locations inside that
same alphabet ˆX = X. For simplicity, we consider that the set of
locations in X are the centers of the cells that make a 5 × 5 square
00.20.40.60.8100.20.40.60.8100.20.40.60.8100.20.40.60.8100.20.40.60.8102468101200.20.40.60.810246810$$$$HomeParkShopCafé$(a) Average error (Euclidean)
(b) Average error (semantic)
(c) Conditional entropy
Figure 9: Performance of Shokri et. al’s algorithm optimized for the adversary error in terms of Euclidean distance, compared
to the coin mechanism and exponential posterior mechanism.
(a) Average error (Euclidean)
(b) Average error (semantic)
(c) Conditional entropy
Figure 10: Performance of Shokri et. al’s algorithm optimized for the adversary error in terms of semantic distance, compared
to the coin mechanism and the exponential posterior mechanism.
grid and assign a tag to each location that can be “Home”, “Park”,
“Shop” or “Café”, as depicted in Fig. 8. We consider that the prior
is uniform π(x) = 1/25 , ∀x ∈ X. We measure the point-wise
loss as the Euclidean distance dQ(x, z) = ||x − z||2 and consider
two point-wise metrics of privacy: the Euclidean distance and a
semantic distance defined as the Hamming distance between tags,
i.e., dP(x, z) = 0 if Tag(x) = Tag(z), and dP(x, z) = 1 otherwise. This
metric is similar to the semantic metric in [1]. The average error
computed using this distance function represents the probability
that an adversary guesses incorrectly the tag of x.
We evaluate ExPost and Coin together with the optimal mecha-
nism proposed in [27]. For the latter, we solve the linear program
to find optimal mechanisms in terms of maximizing PAE using the
Euclidean distance (Fig. 9) and the semantic distance we defined
(Fig. 10). As expected, the optimal mechanisms (Shokri et. al) achieve
the optimal privacy when evaluated using the adversary’s error for
which they are optimized (Figs. 9a and 10b), but not when evalu-
ated against a different metric (Figs. 9b and 10a). ExPost and Coin
achieve maximum privacy in terms of Euclidean distance, as before,
but not in terms of semantic distance. This example emphasizes
that optimizing a mechanism with respect to a privacy metric may
provide very bad performance with respect to other privacy criteria.
This experiment also shows another important idea: even though
the solutions of the linear program both achieve approximately the
same performance in terms of average error (optimal in Figs. 9a
and 10b, suboptimal in Figs. 9b and 10a), they exhibit a radically
different behavior in terms of conditional entropy. Indeed, using the
mechanism computed with the simplex algorithm (a mechanism at
a vertex of F opt
Q ), the adversary has much less uncertainty about x
on average than if the user had implemented a mechanism from
the interior of the polytope. This difference in entropy is also what
allows us to tell apart a mechanism such as ExPost from Coin. Note
that the mechanism computed by solving the linear program with
the simplex algorithm performs even worse than the coin in terms
of entropy, illustrating the dangers of optimizing privacy in only
one dimension.
6 CONCLUSIONS
In this work, we have demonstrated the problems of using a single
privacy metric as indicator of the performance of location privacy
preserving mechanisms. We have proven that there is more than
one optimal protection mechanism in terms of maximizing the av-
erage adversary error for a given average quality loss, and that the
family of mechanisms that fulfill such condition behave differently
in terms of other privacy metrics. Thus, optimizing defenses with
only one privacy metric in mind may lead to mechanisms that offer
poor protection in other dimensions of privacy. To avoid selecting
underperforming mechanisms we propose the use of complemen-
tary criteria to guide the choice. We provide two example auxiliary
metrics: the conditional entropy and the worst-case loss. We pro-
pose an optimal mechanism with respect to the former, and provide
means to implement mechanisms according to the latter.
We evaluate the mechanisms, comparing them to previous work,
on two real datasets. Our experiments confirm two important ideas:
first, that we cannot find a mechanism that performs optimally with
00.511.5200.511.5200.511.5200.10.20.30.40.500.511.5201234500.511.5200.511.5200.511.5200.10.20.30.40.500.511.52012345respect to every privacy metric. Second, that even if a mechanism
performs well in a particular metric it does not imply that it is
necessarily beneficial for the user. Our findings reveal the need
to take a step back in mechanism design to integrate privacy as a
multi-dimensional notion, in order to avoid solutions that provide
a false perception of privacy.
A APPENDIX
A.1 Proof of Theorem 3.3
In order to prove this result, first notice that, when dP(·) ≡ dQ(·),
the quality loss Q is an upper bound of privacy PAE:
(cid:41)
π(x) · f (z|x) · dP(x, ˆx)
dz
x ∈X
π(x) · f (z|x) · dQ(x, z)
(cid:41)
= Q(f , π) ,
(26)
∫
∫
R2
(cid:40)
(cid:40)
min
ˆx ∈R2
R2
x ∈X
PAE(f , π) =
≤

x ∈X

x ∈X
Now, assume that f ′ = f ◦ д, and therefore
z = argmin
z′∈R2
π(x) · f
′(z|x) · dQ(x, z
′) .
(27)
The optimal adversary estimation of x given z given in (4) can
be written as
ˆx(z) = argmin
ˆx ∈R2
π(x) · f
′(z|x) · dP(x, ˆx) .
(28)
We see that since dP(·) ≡ dQ(·) the optimal adversary estimation
is doing nothing, i.e., ˆx(z) = z. This implies that PAE(f ′, π) =
Q(f ′, π), and since we have achieved the upper bound on privacy
given in (26), f ′ is optimal.
A.2 Geo-indistinguishability of the posterior
exponential mechanism.
We recall that the geo-indistinguishability guarantee requires the
following condition to be fulfilled (now written for discrete mech-
anisms, where p(z|x) denotes the probability of reporting z when
the original location is x):
′ ∈ X, z ∈ Z ,
p(z|x) ≤ eϵ ·dP(x,x′) · p(z|x
′) , ∀x, x
where dP(x, x′) is the Euclidean distance.
The last iteration of the ExPost algorithm in 4.1.2 returns a
mechanism that can be written for a particular input x and output
z as
(29)
p(z|x) =
−b·dQ (x,z)
−b·dQ (x,z′)
PZ (z)·e
z′∈Z PZ (z′)·e
0 ,
if PZ(z) > 0 ,
if PZ(z) = 0 .
(30)

(a) Gowalla
(b) Brightkite
Figure 11: Average error vs. average quality loss for different
unbounded mechanisms.
dQ(x, x′) to write
p(z|x) =
PZ(z) · e−b·dQ(x,z)
z′∈Z PZ(z′) · e−b·dQ(x,z′)


≤ PZ(z) · eb·dQ(x,x′) · e−b·dQ(x′,z)
z′∈Z PZ(z′) · e−b·dQ(x,z′)

PZ(z) · eb·dQ(x,x′) · e−b·dQ(x′,z)
z′∈Z PZ(z′) · e−b·dQ(x,x′) · e−b·dQ(x′,z′)

PZ(z) · e−b·dQ(x′,z)
2b·dQ(x,x′)
z′∈Z PZ(z′) · e−b·dQ(x′,z′) · e
2b·dQ(x,x′) · p(z|x
′) ,
≤
=
(31)
(32)
(33)
(34)
=e
(35)
which satisfies the geo-indistinguishability for ϵ = 2b or PGI = 1/2b,
if dQ(·) is the Euclidean distance. This concludes the proof.
A.3 Performance of the unbounded
mechanisms in terms of the average error
When the average error (Euclidean) and the average quality loss
(Euclidean) are used to evaluate the performance of the mechanisms
described in Section 5, we achieve the trivial result PAE = Q. This
is shown in Fig. 11 for completeness.
where dQ(x, z) is the Euclidean distance. In the second case, the
geo-indistinguishability guarantee is trivially achieved since given
any pair of input locations x, x′ ∈ X, p(z|x) = p(z|x′) = 0. For the
first case, we use the triangular inequality dQ(x, z) + dQ(x′, z) ≥
ACKNOWLEDGMENTS
This work is partially supported by EU H2020-ICT-10-2015 NEXTLEAP
(GA n 688722), the Agencia Estatal de Investigación (Spain) and
the European Regional Development Fund (ERDF) under projects
00.20.40.60.8100.20.40.60.811.200.20.40.60.8100.20.40.60.811.210.1145/1626536.1626540
[22] Changsha Ma and Chang Wen Chen. 2014. Nearby Friend Discovery with Geo-
indistinguishability to Stalkers. Procedia Computer Science 34 (2014), 352–359.
[23] Joseph T. Meyerowitz and Romit Roy Choudhury. 2009. Hiding stars with fire-
works: location privacy through camouflage. In 15th Annual International Confer-
ence on Mobile Computing and Networking (MOBICOM), Kang G. Shin, Yongguang
Zhang, Rajive Bagrodia, and Ramesh Govindan (Eds.). ACM, 345–356.
[24] Reza Shokri. 2015. Privacy Games: Optimal User-Centric Data Obfuscation.
PoPETs 2015, 2 (2015), 299–315.
[25] Reza Shokri, Julien Freudiger, Murtuza Jadliwala, and Jean-Pierre Hubaux. 2009.
A distortion-based metric for location privacy. In ACM Workshop on Privacy in
the Electronic Society, WPES, Ehab Al-Shaer and Stefano Paraboschi (Eds.). ACM,
21–30.
[26] Reza Shokri, George Theodorakopoulos, Jean-Yves Le Boudec, and Jean-Pierre
Hubaux. 2011. Quantifying location privacy. In Security and privacy (sp), 2011
ieee symposium on. IEEE, 247–262.
[27] Reza Shokri, George Theodorakopoulos, Carmela Troncoso, Jean-Pierre Hubaux,
and Jean-Yves Le Boudec. 2012. Protecting location privacy: optimal strategy
against localization attacks. In Proceedings of the 2012 ACM conference on Com-
puter and communications security. ACM, 617–627.
[28] Yu Wang, Dingbang Xu, Xiao He, Chao Zhang, Fan Li, and Bin Xu. 2012. L2P2:
Location-aware location privacy protection for location-based services. In INFO-
COM, 2012 Proceedings IEEE. 1996–2004. https://doi.org/10.1109/INFCOM.2012.
6195577
[29] Tun-Hao You, Wen-Chih Peng, and Wang-Chien Lee. 2007. Protecting Moving
Trajectories with Dummies. In International Conference on Mobile Data Manage-
ment. 278–282.
[30] Yu Zheng, Lizhu Zhang, Xing Xie, and Wei-Ying Ma. 2009. Mining Interesting
Locations and Travel Sequences from GPS Trajectories. In Proceedings of the 18th
International Conference on World Wide Web. ACM, 10.
WINTER (TEC2016-76409-C2-2-R) and COMONSENS (TEC2015-
69648-REDC), and by the Xunta de Galicia and the European Union
(European Regional Development Fund - ERDF) under projects
Agrupación Estratéxica Consolidada de Galicia accreditation 2016-
2019 and Red Temática RedTEIC 2017-2018. Simon Oya is funded
by the Spanish Ministry of Education, Culture and Sport under the
FPU grant.
REFERENCES
[1] Berker Ağır, Kévin Huguenin, Urs Hengartner, and Jean-Pierre Hubaux. 2016. On
the Privacy Implications of Location Semantics. Proceedings on Privacy Enhancing
Technologies 2016, 4 (2016), 165–183.
[2] Miguel E Andrés, Nicolás E Bordenabe, Konstantinos Chatzikokolakis, and Catus-
cia Palamidessi. 2013. Geo-indistinguishability: Differential privacy for location-
based systems. In Proceedings of the 2013 ACM SIGSAC conference on Computer &
communications security. ACM, 901–914.
[3] Alastair R. Beresford and Frank Stajano. 2003. Location Privacy in Pervasive
Computing. IEEE Pervasive Computing 2, 1 (2003), 46–55.
[4] Igor Bilogrevic, Kévin Huguenin, Stefan Mihaila, Reza Shokri, and Jean-Pierre
Hubaux. 2015. Predicting users’ motivations behind location check-ins and utility
implications of privacy protection mechanisms. In 22nd Network and Distributed
System Security Symposium (NDSS).
[5] Nicolás E Bordenabe, Konstantinos Chatzikokolakis, and Catuscia Palamidessi.
2014. Optimal geo-indistinguishable mechanisms for location privacy. In Pro-
ceedings of the 2014 ACM SIGSAC Conference on Computer and Communications
Security. ACM, 251–262.
[6] Konstantinos Chatzikokolakis, Ehab Elsalamouny, and Catuscia Palamidessi. 2016.
Practical Mechanisms for Location Privacy. (2016).
[7] Konstantinos Chatzikokolakis, Catuscia Palamidessi, and Marco Stronati. 2015.
Constructing elastic distinguishability metrics for location privacy. Proceedings
on Privacy Enhancing Technologies 2015, 2 (2015), 156–170.
[8] Thomas M Cover and Joy A Thomas. 2012. Elements of information theory. John
Wiley & Sons.
[9] Cynthia Dwork. 2006. Differential Privacy. In Automata, Languages and Pro-
gramming, 33rd International Colloquium, ICALP 2006 (Lecture Notes in Computer
Science), Michele Bugliesi, Bart Preneel, Vladimiro Sassone, and Ingo Wegener
(Eds.), Vol. 4052. Springer, 1–12.
[10] Cynthia Dwork. 2008. Differential privacy: A survey of results. In International
Conference on Theory and Applications of Models of Computation. Springer, 1–19.
[11] Kassem Fawaz, Huan Feng, and Kang G. Shin. 2015. Anatomization and Protection
of Mobile Apps’ Location Privacy Threats. In 24th USENIX Security Symposium,
Jaeyeon Jung and Thorsten Holz (Eds.). USENIX Association, 753–768.
[12] Kassem Fawaz and Kang G. Shin. 2014. Location Privacy Protection for Smart-
phone Users. In ACM SIGSAC Conference on Computer and Communications
Security, Gail-Joon Ahn, Moti Yung, and Ninghui Li (Eds.). ACM, 239–250.
[13] Julien Freudiger, Reza Shokri, and Jean-Pierre Hubaux. 2012. Evaluating the
privacy risk of location-based services.
In Financial Cryptography and Data
Security. Springer, 31–46.
[14] Sébastien Gambs, Marc-Olivier Killijian, and Miguel Núñez del Prado Cortez.
2011. Show Me How You Move and I Will Tell You Who You Are. Transactions
on Data Privacy 4, 2 (2011), 103–126.
[15] Bugra Gedik and Ling Liu. 2005. Location Privacy in Mobile Systems: A Per-
sonalized Anonymization Model. In 25th International Conference on Distributed
Computing Systems (ICDCS. IEEE Computer Society, 620–629.
[16] Philippe Golle and Kurt Partridge. 2009. On the Anonymity of Home/Work Loca-
tion Pairs. In International Conference on Pervasive Computing (LNCS), Hideyuki
Tokuda, Michael Beigl, Adrian Friday, A. J. Bernheim Brush, and Yoshito Tobe
(Eds.), Vol. 5538. Springer, 390–397.
[17] Marco Gruteser and Dirk Grunwald. 2003. Anonymous Usage of Location-Based
Services Through Spatial and Temporal Cloaking. In International conference on
Mobile systems, applications and services. ACM, 31–42.
[18] B. Hoh and M. Gruteser. 2005. Protecting Location Privacy Through Path Con-
fusion. In International Conference on Security and Privacy for Emerging Areas
in Communications Networks. 194–205. https://doi.org/10.1109/SECURECOMM.
2005.33
[19] H. Kido, Y. Yanagisawa, and T. Satoh. 2005. An anonymous communication
technique using dummies for location-based services. In Pervasive Services, 2005.
ICPS ’05. Proceedings. International Conference on. 88–97.
[20] John Krumm. 2007. Inference Attacks on Location Tracks. In 5th International
Conference on Pervasive Computing (LNCS), Anthony LaMarca, Marc Langhein-
rich, and Khai N. Truong (Eds.), Vol. 4480. Springer, 127–143.
[21] Hua Lu, Christian S. Jensen, and Man Lung Yiu. 2008. PAD: privacy-area aware,
dummy-based location privacy in mobile services. In ACM International Workshop
on Data Engineering for Wireless and Mobile Access. ACM, 16–23. https://doi.org/