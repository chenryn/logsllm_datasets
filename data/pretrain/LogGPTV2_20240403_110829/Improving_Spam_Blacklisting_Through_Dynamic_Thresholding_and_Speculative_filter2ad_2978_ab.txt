### Introduction

Having outlined the creation process of existing blacklists and the experimental context, we now delve into an exploration of the reasons behind the false positives and false negatives observed. We will examine two broad categories of potential causes: trends in spamming behavior (e.g., targeted spam, low-volume spam) and systemic properties of the blacklist creation methods (e.g., detection delay, static whitelisting).

### 2.3.1 Targeted E-Mail

One possible explanation for the high false negative rates observed in blacklists is that some e-mails are part of targeted spam campaigns. If a spammer sends targeted spam to a domain without any spamtraps, it is impossible to blacklist the host. To investigate this, we analyzed the impact of spamtrap deployment size on accuracy. By building blacklists from spamtrap deployments of varying sizes (from 1 to 11 domains), we can assess the targeted nature of spam.

**Table 2: False Positive and False Negative Rates with Varying Spamtrap Deployments**

| Number of Domains | OR of Domains (FP Rate) | AND of Domains (FN Rate) |
|-------------------|-------------------------|--------------------------|
| 1                 | 2.2%                    | 71.5%                    |
| 2                 | 2.2%                    | 66.7%                    |
| 3                 | 2.2%                    | 63.6%                    |
| 4                 | 2.3%                    | 61.6%                    |
| 5                 | 2.3%                    | 61.6%                    |
| 6                 | 2.3%                    | 60.4%                    |
| 7                 | 2.3%                    | 59.2%                    |
| 8                 | 2.4%                    | 58.2%                    |
| 9                 | 2.4%                    | 57.5%                    |
| 10                | 2.4%                    | 57.0%                    |
| 11                | 2.4%                    | 56.8%                    |

We considered two cases for blacklist generation: one where an IP address is blacklisted if it appears on any spamtrap domain (OR condition), and another where it is blacklisted only if it appears on every spamtrap domain (AND condition). The false negative rate for the OR condition converges to approximately 56.8%, indicating that about 57% of the spam does not appear in any of the spam traps—a reasonable upper bound on the amount of targeted e-mail. The false negative rate for the AND condition reaches 100% after just three spamtrap domains, suggesting that global spam is quite limited.

**Figure 2: Number of E-Mails Sent by External Spamming Sources Not Observed on Any Spamtrap**

![](figure2.png)

Most of these sources sent just one spam to our network, highlighting the challenge of detecting such targeted campaigns.

### 2.3.2 Low-Volume Spam

Another potential cause of false negatives is that although the campaigns are global, spammers often use a vast number of hosts to send a small number of e-mails to each target. This makes it feasible to send millions of e-mails while avoiding detection. Most blacklist providers do not blacklist hosts for a single spam sent to a spamtrap.

**Figure 2: Number of E-Mails Sent by External Spamming Sources Not Observed on Any Spamtrap**

![](figure2.png)

As shown in Figure 2, while some spammers sent numerous e-mails, the majority of sources sent only a single spam. Therefore, any approach requiring multiple spamtrap hits will fail to report these high-volume, single-target sources as spammers.

### 2.3.3 Detection Delay

A third potential source of false negatives is the reactive nature of blacklist generation. Hosts are not added to blacklists until they send enough e-mail to spamtraps. During a fast global campaign, it is possible that we might receive spam at the production network before it reaches a spamtrap or before the blacklist provider can update the list.

To explore the impact of this delay, we examined retroactive detection. We created blacklists as usual, adding entries for spamming hosts only if they sent spam over a given threshold. We then enabled retroactive detection, classifying hosts as spammers if they sent e-mail to the spamtraps at any time during our observations (potentially several weeks after the spam was observed).

**Figure 3: Effect of Blacklist Detection Delay on False Negatives for Different Thresholds**

![](figure3.png)

For small threshold values (e.g., blacklisting when we see only one spam), the decrease in false negatives from retroactive detection is 10%. For higher thresholds, this value decreases. Thus, 10% approximates a reasonable upper bound on the false negatives caused by delay.

### 2.3.4 Static Whitelisting

False positives occur when legitimate e-mail servers are blocked. This often happens when a legitimate e-mail server is compromised or used by compromised hosts. In many cases, this can be avoided by including the IP address of the sending host in the e-mail headers, but this is not always the case. For example, e-mails sent from the Gmail web interface do not include the client’s IP address, leading to the blacklisting of the server itself.

Blacklists lack a notion of what servers are used and not used by a specific network. **Figure 4** shows the amount of mail sent to networks that sent us spam and those that sent us legitimate e-mail. There is a stark contrast between the e-mail sent to legitimate networks and those sent to spamming networks—90% of legitimate senders received more than one e-mail from us, while over 60% of spammers never received a single e-mail from our network.

**Figure 4: Amount of Legitimate E-Mail Sent by Our Network to Networks That Sent Us Spam and Legitimate E-Mail**

![](figure4.png)

Some spamming domains, such as Google (87,373), Inktomi (4,559), and Microsoft (3,466), received a large number of e-mails from us. These sites could be whitelisted, but without knowing what services a network uses, this whitelisting may create false negatives. Blacklists need a way to determine which remote networks are important to a given network.

### 2.3.5 Putting It Together

In this section, we explored the root causes of traditional threshold-based blacklist creation algorithms. We noted that spam is both targeted and, in many cases, low-volume. Capturing this spam places pressure to lower detection thresholds, requiring fewer spamtrap hits. This pressure increases the burden on blacklist operators to select appropriate whitelists to avoid increasing false positives. This tension is further exacerbated by the inherent delay in existing blacklisting methods, most pronounced at lower thresholds.

What is needed are additional sources of information and methods to determine when and how to be aggressive in blacklisting.

### 3. Architecture

In this section, we describe our approach to mitigating the limitations discussed. Rather than a "one size fits all" method, our approach (shown in **Figure 5**) decides on blacklisting policy using local information, including usage patterns (e.g., e-mail usage), network routing visibility (e.g., BGP information), and global information (e.g., spamtraps).

**Figure 5: Our Approach to Spam Blacklist Generation**

![](figure5.png)

With local context, the policy generation mechanisms can eliminate false positives from blacklisting locally important e-mail servers. Additionally, blacklisting can be more aggressive for networks rather than individual sources, if these networks are not important in the local context. This general idea is applied in two specific improvements to spam blacklist generation: dynamic thresholding and speculative aggregation.

#### 3.1 Dynamic Thresholding

In a simple static, threshold-based approach, a threshold is set, and an IP address is blacklisted if the number of e-mails sent to spamtraps crosses that threshold. However, this can blacklist important e-mail servers (e.g., Gmail) if they are used to send even a small amount of spam. A solution is to compare local network traffic to the spamtrap e-mails. A valid e-mail server will have significantly more e-mails delivered to valid addresses than to spamtraps, while a spamming source will hit significantly more spamtraps than legitimate users.

We propose a dynamic threshold approach that computes the ratio of e-mails on the live network to the number of e-mails seen at the spamtrap and blacklists sources if the computed ratio is below a configured ratio. For example, if the configured ratio is 1 and a source IP address is observed 5 times on the e-mail server and 10 times on the spamtrap, the ratio is 5/10 = 0.5, which is lower than the provided ratio of 1, so this source IP address will be blacklisted.

#### 3.2 Speculative Aggregation

While dynamic thresholding addresses false positives, blacklists still exhibit significant false negatives due to low-volume spammers, targeted spam, or detection delays. To address false negatives from unseen sources, we speculate about potentially bad sources using the list of previous spamming sources. **Figure 6** shows the aggregation of spamming sources that have missed the spamtraps by BGP prefixes. Most of these prefixes have a large number of sources that have previously hit spamtraps, indicating that the number of sources hitting spamtraps is a good indicator of spamming prefixes. Most sources that have missed spamtraps in these prefixes have also sent at least one spam. Therefore, blacklisting these BGP sources will have little impact on legitimate e-mail.

**Figure 6: Number of IPs That Have Hit Spamtraps vs. Those That Have Not**

![](figure6.png)

By combining these approaches, we aim to create more accurate and effective spam blacklists.