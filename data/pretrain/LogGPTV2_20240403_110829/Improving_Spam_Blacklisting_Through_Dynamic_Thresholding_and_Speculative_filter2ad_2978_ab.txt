racy
Having now described how existing blacklists are cre-
ated and the context in which we perform our experiments,
we now embark on an exploration of the reasons for the
Number OR of domains AND of domains
FP
rate
2.2
2.2
2.2
2.3
2.3
2.3
2.3
2.4
2.4
2.4
2.4
FN
rate
71.5
66.7
63.6
61.6
61.6
60.4
59.2
58.2
57.5
57.0
56.8
FP
rate
2.2
1.0
1.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
domains
of
1
2
3
4
5
6
7
8
9
10
11
FN
rate
71.5
80.58
83.54
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
Table 2: The false positive and false negatives rates when the
spamtrap deployment is expanded domain by domain using
existing methods. No spamming IP address is seen by more
than three spamtraps.
false positives and false negatives we observed. We ex-
amine two broad categories of potential reasons for these
inaccuracies, including trends in spamming behavior (i.e.,
targeted spam, low-volume spam) and systemic properties
of the blacklist creation methods (i.e, detection delay, static
whitelisting).
2.3.1 Targeted E-Mail
One possible explanation for the false negative rates ob-
served by the blacklists is that some of the e-mails are
part of a targeted spam campaign. Obviously, if a spam-
mer sends targeted spam to a domain in which there are no
spamtraps, it is impossible to blacklist the host. To explore
the impact of this potential cause of false negatives, we ex-
amined the impact of spamtrap deployment size on accu-
racy. By building blacklists from spamtrap deployments of
size 1, 2, ..., 11 we can explore the targeted nature of spam.
Table 2 shows the result of this analysis. We consider two
cases for blacklist generation, one in which an IP address
is blacklisted if a spam host appears on any spamtrap do-
main, and one in which it is blacklisted if it appears on ev-
ery spamtrap domain. The false negative rate for the OR of
domains converge to roughly 56.8%, indicating that roughly
57% of the spam does not appear in any of the spam traps—
a reasonable upper bound on the amount of targeted e-mail.
A lower bound on the amount of global e-mail can be seen
in the false negative rate for the AND of domains, 100%
after just three spamtrap domains are combined. Clearly,
global spam seems to be quite limited. While a precise es-
timate is difﬁcult without a universal deployment, it is clear
that the blacklists are impacted by signiﬁcant targeted be-
m
a
p
S
f
o
r
e
b
m
u
N
 100000
 10000
 1000
 100
 10
 1
 0.1
 0
 50000  100000  150000  200000  250000  300000
External spam IPs not observed on spamtrap
Figure 2: The number of e-mails sent by external spamming
sources that were not observed on any spamtrap. Most of these
sources sent just one spam to our network.
havior.
2.3.2 Low Volume Spam
Another potential explanation of the false negatives ob-
served is that although the campaigns are global, the vast
number of hosts available to spammers makes it feasible to
send a small handful of e-mails from each host to each tar-
get user or domain and still send millions of mails. This
contributes to the problem of false negatives, in that most
blacklist providers will not blacklist hosts for a single spam
sent to a spamtrap. In order to investigate this phenomenon,
we examined the spam sent to our network that was not
observed on ANY of our spamtraps. For each spamming
source, we calculated the number of spams sent to our net-
work over the measurement period. As shown in Figure 2,
while some spammers clearly sent numerous spams, the
vast majority of sources sending spam to our network only
sent a single spam. Therefore, any approach that requires
multiple spamtrap hits will never report these high-volume,
single-target sources as spammers.
2.3.3 Detection Delay
A third potential source of false negatives is the reactive na-
ture of blacklist generation. By their nature, hosts are not
put on blacklists until they send enough e-mail to spam-
traps. During a fast global campaign, it is possible that we
might receive the spam at the production network before it
reaches a spamtrap or before the blacklist provider can send
out an update. To explore the impact of this delay, we ex-
amined the idea of retroactive detection. That is, we created
blacklists as expected, creating blacklist entries for spam-
ming hosts only if they sent spam over a given threshold.
We then enabled retroactive detection, that is, we classi-
ﬁed hosts as spam if they sent e-mail to the spamtraps at
)
%
(
s
e
v
i
t
a
g
e
n
e
s
a
F
l
 100
 95
 90
 85
 80
 75
 70
 65
 60
 55
with_time_filter
without_time_filter
n
o
i
t
c
n
u
F
n
o
i
t
i
u
b
i
r
t
s
D
e
v
i
t
 1
 10
 100
 1000
 10000
Threshold on spamtrap hits
l
a
u
m
u
C
 1
 0.8
 0.6
 0.4
 0.2
 0
 0.1
 1
Ham sent to ham senders
Ham sent to spam senders
 100
 10
 1000
Number of emails sent
 10000  100000
Figure 3: The effect of blacklist detection delay on false
negatives for different thresholds using existing blacklisting
approaches. The difference between blacklisting only those
spamming IP addresses whose spamtrap hits occur before an
e-mail is received on the production network is compared to
blacklisting the IP address if it appears anywhere in the trace
(often in the future). The biggest cost of detection lag is for
small threshold values in traditional approaches.
anytime during our observations (potentially several weeks
after we observed the spam). Figure 3 shows the result of
this analysis. For small threshold values (i.e., blacklisting
when we see only one spam) the decrease in false negatives
from retroactive detection is 10%. For higher thresholds,
this value decreases. Thus 10% approximates a reasonable
upper bound on the false negatives caused by delay.
2.3.4 Static Whitelisting
False positives occur from blacklists when legitimate e-mail
servers are blocked. Often times this occurs when a legit-
imate e-mail sever has been compromised or is being used
by compromised hosts. In many cases this can be avoided,
as the e-mail server can add the IP address of the sending
host in the e-mail headers, but this is not always the case.
For example, e-mails sent from the Gmail web interface do
not include the client’s IP address, and as a result, black-
lists are only left with the choice of blacklisting the server
itself. What these blacklists lack is a notion of what servers
are used and not used by a speciﬁc network. For example,
consider the data in Figure 4. In this ﬁgure, we examine the
amount of mail we sent to those networks (autonomous sys-
tems) that sent us spam and those that sent us ham. Note the
stark contrast between the e-mail we sent to legitimate net-
works and those we sent to spamming networks—90% of
ham senders received more than one e-mail from us, while
over 60% of spammers never received a single e-mail from
our network. A few spamming domains received a large
number of e-mails from us. As expected, these are false
positives from web hosting sites as in the example above:
Figure 4: The amount of legitimate e-mail sent by our network
to networks that sent us spam and legitimate e-mail. There is a
huge difference in how our network uses the IP addresses that
sent spam and those that do not.
Google (87,373), Inktomi (4,559), and Microsoft (3,466).
These sites could be whitelisted, but without knowing what
services a network uses, this whitelisting may create false
negatives. What blacklists need is a way to ﬁgure out what
remote networks are important to a given network.
2.3.5 Putting it Together
In this section, we explored the root causes of traditional
threshold-based blacklist creation algorithms. We note that
spam is both targeted and in many cases, low-volume. Cap-
turing this spam places pressure to lower detection thresh-
olds to require fewer and fewer spamtrap hits in order to
capture the spamming behavior. This pressure places addi-
tional burden on the blacklist operators to select the appro-
priate whitelists to avoid the increasing number of false pos-
itives. This tension is further exacerbated by the delay in-
herent in existing blacklisting these methods, which is most
pronounced at precisely the lower thresholds being utilized.
What is needed then, are additional sources of information
and methods that can be used to determine when and how
to be aggressive in blacklisting.
3 Architecture
In this section, we describe our approach to mitigating
the limitations discussed in the previous section. Rather
than a “one size ﬁts all” method, which is embodied by the
generation schemes for existing production blacklists (and
shown in Figure 1), our method (shown in Figure 5) de-
cides on blacklisting policy with the help of local informa-
tion including usage patterns (i.e., e-mail usage), network
routing visibility (i.e., BGP information), as well as global
information (i.e., spamtraps). With local context in hand,
BlACKLIST
Provider
Bot1
Trap1
User2
Trap2
Spammer
User1
User3
Time3, Bot1, Trap1
Time4, Bot2, Trap1
Time5, Bot2, Trap2
Deny All Bot1
Bot2
ROUTER
Local
Policy Gen.
User4
Time1, User4, User1
Time2, User4, Bot2
Time3, User2, User4
Figure 5: Our approach to spam blacklist generation. Rather than enforcing a global “one size ﬁts all” policy, a local generation
algorithm combines local usage patterns (i.e, e-mail usage), allocation information (i.e., BGP reachability), and global information
(i.e., spamtraps) to make localized, tailored blacklist policies.
the policy generation mechanisms can eliminate false pos-
itives that occur from blacklisting locally important e-mail
servers. In addition, the blacklisting can be more aggressive
in blacklisting networks rather than individual sources—if
these networks are not important in the local context. In this
section, we see how this general idea is applied in two spe-
ciﬁc improvements to spam blacklist generation: dynamic
thresholding and speculative aggregation.
3.1 Dynamic Thresholding
In a simple static, threshold-based approach model of
existing methods, a threshold is decided and an IP ad-
dress is blacklisted if the number of e-mails sent to spam-
traps crosses that threshold. However, the simple threshold
mechanism can blacklist e-mail servers that are important
e-mail servers (e.g., Gmail) if they are used to send even a
small amount of spam. One solution to this problem is to
compare local network trafﬁc to the spamtrap e-mails. The
assumption here is that a valid e-mail server will have sig-
niﬁcantly more e-mails delivered to valid addresses than to
spamtraps, while a spamming source will hit signiﬁcantly
more spamtraps than legitimate users in the live network,
as we saw in Figure 4. Therefore, we propose a dynamic
threshold approach that computes the ratio of e-mails on
the live network to the number of e-mails seen at the spam-
trap and blacklists sources if the computed ratio is below a
conﬁgured ratio. For example, consider that the conﬁgured
ratio is 1 and a source IP address is observed 5 times on the
e-mail server and 10 times on the spamtrap. The ratio is
5/10 = 0.5, which is lower than the provided ratio of 1, so
this source IP address will be blacklisted.
3.2 Speculative Aggregation
While a dynamic threshold approach addresses the false
positive issues with the spam blacklists, the blacklists still
exhibit a signiﬁcant amount of false negatives. Recall from
the previous section that this may be the result of low vol-
ume spammers, targeted spam, or detection delays. In order
to attack false positives resulting from sources we have not
seen, the only solution we have is to speculate about po-
tentially bad sources. One potential source of information
that we have to inform our prediction is the list of previous
spamming sources. In Figure 6, we aggregated the spam-
ming sources that have missed the spamtraps by the BGP
preﬁxes (obtained from routeviews.org project). We ﬁnd
that most of these preﬁxes have a large number of sources
that have previously hit spamtraps. We conclude, therefore,
that the number of sources that have hit the spamtraps is
a good indication of spamming preﬁxes. Secondly, we ﬁnd
that most of the sources that have missed spamtraps in these
preﬁxes have sent at least one spam as well. Therefore,
blacklisting these BGP sources will have little impact on
Num IPs that have hit spamtrap
Num IPs that have not hit spamtrap
Num spam IPs that have not hit spamtraps
 1e+06
 100000
 10000
 1000
 100