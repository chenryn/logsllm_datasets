# Ananta: Cloud-Scale Load Balancing

**Authors:**  
Parveen Patel, Deepak Bansal, Lihua Yuan, Ashwin Murthy, Albert G. Greenberg, David A. Maltz, Randy Kern, Hemant Kumar, Marios Zikos, Hongyu Wu, Changhoon Kim, Naveen Karri  
Microsoft

## Abstract
Layer-4 load balancing is essential for creating scalable web services. We designed and implemented Ananta, a cloud-scale Layer-4 load balancer that runs on commodity hardware and meets the performance, reliability, and operational requirements of multi-tenant cloud environments. Ananta combines existing techniques in routing and distributed systems in a unique way, splitting the components of a load balancer into a consensus-based, reliable control plane and a decentralized, scale-out data plane. A key feature of Ananta is an agent on every host that can take over packet modification from the load balancer, enabling natural scaling with the size of the data center. Due to its distributed architecture, Ananta provides Direct Server Return (DSR) and Network Address Translation (NAT) capabilities across Layer-2 boundaries. Multiple instances of Ananta have been deployed in the Windows Azure public cloud, with a combined bandwidth capacity exceeding 1 Tbps, serving diverse tenants including blob, table, and relational storage services. This paper describes the requirements, design, and lessons learned from implementing and operating Ananta in the Windows Azure public cloud.

**Categories and Subject Descriptors:**  
C.2.4 [Computer-Communication Networks]: Distributed Systems

**General Terms:**  
Design, Performance, Reliability

**Keywords:**  
Software-Defined Networking, Distributed Systems, Server Load Balancing

## 1. Introduction
The rapid rise of cloud computing has driven demand for large-scale, multi-tenant clouds. These environments host a variety of applications at low cost while providing high uptime SLAs (99.9% or higher). A multi-tenant load balancer service is a fundamental component of such environments, handling almost all external and half of intra-data center traffic. Therefore, its uptime requirements must be at least as high as those of the applications, often even higher to account for failures in other infrastructure services.

As a cloud provider, we have observed that cloud services place significant pressure on the load balancer's control and data planes. Inbound flows can exceed 100 Gbps for a single IP address, with every packet hitting the load balancer. The pay-as-you-go model and large tenant deployments require real-time load balancer configuration, with up to six configuration operations per minute on average, peaking at one operation per second. Our experience shows that these demands led our hardware load balancer solution to become impractical, with high costs, SLA violations, and load balancing device failures accounting for 37% of all live site incidents.

This paper introduces Ananta, a scalable software load balancer and NAT optimized for multi-tenant clouds. Ananta achieves scale, reliability, and flexibility through a novel division of the data plane functionality into three tiers. As shown in Figure 1, the top tier uses routers for load distribution at the network layer (Layer-3) based on the Equal Cost Multi Path (ECMP) routing protocol. The second tier consists of a scalable set of dedicated servers, called multiplexers (Mux), which maintain connection flow state in memory and perform Layer-4 load distribution to application servers. The third tier, present in the virtual switch on every server, provides stateful NAT functionality. This design allows more than 80% of the load-balanced traffic to bypass the load balancer, reducing throughput bottlenecks and latency.

Ananta's approach is an example of Software-Defined Networking (SDN), using a centralized control plane to manage a flexible data plane. The controller maintains high availability via state replication based on the Paxos distributed consensus protocol and implements real-time port allocation for outbound NAT (SNAT).

Ananta has been implemented as a service in the Windows Azure cloud platform. We considered hardware implementations but found that software allowed us to rapidly explore various options in production. For instance, maintaining per-connection state is crucial for application uptime in the dynamic cloud environment. Similarly, a weighted random load balancing policy reduces the need for per-flow state synchronization among load balancer instances, sufficient for typical cloud workloads.

Over 100 instances of Ananta have been deployed in Windows Azure since September 2011, with a combined capacity of 1 Tbps, serving 100,000 VIPs with varying workloads. Ananta has proven effective against DoS attacks and minimized disruption due to abusive tenants. Compared to previous solutions, Ananta is significantly more cost-effective, scalable, flexible, reliable, and secure.

There has been considerable interest in moving middlebox functionality to software running on general-purpose hardware. Most architectures propose using DNS or OpenFlow-enabled hardware switches for scaling. To our knowledge, Ananta is the first middlebox architecture to refactor functionality and move parts of it to the host, enabling the use of network routing technologies like ECMP and BGP for natural scaling with the network size.

The main contributions of this paper are:
- Identifying the requirements and design space for a cloud-scale Layer-4 load balancing solution.
- Providing the design, implementation, and evaluation of Ananta, which combines networking and distributed systems techniques to meet scale, performance, and reliability requirements.
- Offering measurements and insights from running Ananta in a large operational cloud.

## 2. Background
### 2.1 Data Center Network
Figure 2 shows a typical data center network in our cloud. A medium-sized data center hosts 40,000 servers, each with a 10 Gbps NIC. The two-level Clos network architecture typically has an over-subscription ratio of 1:4 at the spine layer. Border routers provide a combined capacity of 400 Gbps for connectivity to other data centers and the Internet. A cloud controller manages resources and hosts services. Each service is a collection of virtual or native machines managed as a single entity. We use the terms "tenant" and "service" interchangeably. Each machine is assigned a private Direct IP (DIP) address, and a service is assigned a public Virtual IP (VIP) address. All traffic crossing the service boundary, such as to the Internet or to back-end services within the same data center, uses the VIP address. A service exposes zero or more external endpoints, each receiving inbound traffic on a specific protocol and port on the VIP. Traffic directed to an external endpoint is load-balanced to one or more machines of the service. All outbound traffic originating from a service is Source NAT'ed (SNAT) using the same VIP address. Using the same VIP for all inter-service traffic enables easy upgrade and disaster recovery and simplifies ACL management.

### 2.2 Nature of VIP Traffic
Public cloud services host a diverse set of workloads, including storage, web, and data analysis. Third-party services in the cloud are also increasing, leading to a growing amount of inter-service traffic. We examined the total traffic in eight data centers over a week and computed the ratio of Internet traffic and inter-service traffic to the total traffic. On average, about 44% (with a minimum of 18% and maximum of 59%) of the total traffic is VIP traffic, either requiring load balancing or SNAT. Out of this, about 14% is to the Internet, and the remaining 30% is intra-DC. The ratio of intra-DC VIP traffic to Internet VIP traffic is 2:1. Overall, 70% of total VIP traffic is inter-service within the same data center. The ratio of inbound to outbound traffic across our data centers is 1:1, primarily read-write and cross-data center replication traffic to our storage services. In summary, more than 80% of VIP traffic is either outbound or contained within the data center. Ananta offloads all of this traffic to the host, handling only 20% of the total VIP traffic.

### 2.3 Requirements
**Scale:** The most stringent scale requirement is derived by assuming all traffic in the network is either load balanced or NAT'ed. For a 40,000-server network, 400 Gbps of external traffic and 100 Tbps of intra-DC traffic will need load balancing or NAT. Based on the traffic ratios, at 100% network utilization, 44 Tbps of traffic will be VIP traffic. A truly scalable load balancer would support this requirement while maintaining low cost. In our cloud, less than 1% of the total server cost is considered low cost, so any solution costing more than 400 general-purpose servers (at US$2,500 per server, totaling US$1,000,000) is too expensive. Traditional hardware load balancers do not meet this requirement, with a typical list price of US$80,000 for 20 Gbps capacity, not including bulk discounts, support costs, or redundancy.

**Bandwidth and Connections:** The bandwidth and number of connections served by a single VIP are highly variable, potentially reaching 100 Gbps and 1 million simultaneous connections. The rate of change in VIP configuration is also high and bursty, averaging 12,000 configurations per day for a 1,000-node cluster, with bursts of hundreds of changes per minute as customer services are deployed, deleted, or migrated.

**Reliability:** The load balancer is critical for meeting the uptime SLA of applications. Services rely on the load balancer to monitor the health of their instances and maintain availability during planned and unplanned downtime. Over years of operation, we found that traditional 1+1 redundancy solutions deployed as active/standby hardware load balancers are insufficient. The load balancer must support:

- **High Availability:** Ensuring minimal downtime and quick recovery.
- **Scalability:** Handling large volumes of traffic and frequent configuration changes.
- **Flexibility:** Adapting to the dynamic nature of the cloud environment.

By addressing these requirements, Ananta provides a robust, scalable, and cost-effective solution for cloud-scale load balancing.