an interaction with a veriﬁer. Our work inherits many of the
challenges of ABCs, particularly in the area of client privacy,
with properties such as attribute-privacy and unlinkability
being central to our work. We note, however, two important
diﬀerences.
First and foremost, prior ABC protocols and systems fo-
cus on (but are not limited to) small formula-based poli-
cies [23, 17, 19, 20, 7, 3, 4, 1] due to the high cost of
needing several public-key operations per gate. Besides the
cost, diﬃculty of policy design and analysis of non-trivial
hand-generated small formulas is the reason that today’s de-
ployed systems mainly implement conjunction policies. In
this work, we dramatically increase the computation power
of the policy by enabling its implementation via garbled cir-
cuits. We believe that in addition to improving eﬃciency
of existing ABC use cases, our work enables a much larger
application scope for ABCs, due to the ability to run (large)
policies auto-generated from easy-to-understand high-level
code.
Secondly, the ABC literature focuses on veriﬁcation of
credentials and not on bootstrapping an authenticated ses-
sion. In general, the ability to verify client credentials (i.e.,
a yes/no result) is insuﬃcient for authenticating a session,
even if the communication is carried over a server-authenticated
channel (e.g., TLS). The relationship between credentials
and key exchange is explicitly studied by Camenisch et al. [18],
but their implementations do not cover rich policies, and do
not outperform ABCs.
ABCs provide several practical features which we regard
as future work, such as credential revocation and CA-veriﬁer
collusion. Other features, such as non-boolean and multi-
authority credentials can be easily and cheaply built within
our system (cf. §1.1).
In a concurrent and independent work, Chase et al. [22]
approach the problem of ABCs for non-boolean attributes by
relying on garbled circuits to represent policies and, as a con-
sequence, allow general circuit-based policies. The method
of delivery of wire labels to the prover (in our notation, the
client) is indeed the technical core of both of our approaches.
Chase et al. allow the prover to enter arbitrary inputs to the
garbled circuit, requiring a zero-knowledge proof that its
garbled circuit inputs are consistent with arithmetic com-
mitted values, which, in turn, are consistent with the cre-
dential vector on which there exists a valid CA signature.
This results in a number of exponentiations per boolean at-
tribute, even in cases where a small subset of them are used
in the policy. Chase et al. oﬀer an alternative algorithm to
reduce the number of public-key operations at the expense
of message authentication code computation inside the gar-
bled circuit, which introduces a signiﬁcant communication
overhead but may be a worthy trade-oﬀ for provers with
many attributes. This approach, too, scales with the to-
tal number of attributes. In contrast, in our approach the
client needs to only compute public-key operations per pol-
icy attribute (rather than over all the client’s attributes as is
required by Chase et al.), which may be signiﬁcantly faster
in many settings. However, our improved performance is a
trade-oﬀ for using stronger assumptions. Additionally, we
present the ﬁrst implementation of general circuit ABKE
(and hence ABCs), and report on its concrete performance.
Finally, the construction of [22] does not support delegation,
and it is not immediately clear how to enable it there.
Finally, Sakai et al. [37] very recently proposed attribute-
based signatures for circuits based on bilinear maps. In their
setting, only signers satisfying a certain policy on their at-
tributes could successfully sign a message. Their scheme
could be a basis for an ABC solution; however, they require
several public-key operations and about 1 Kb of data sent
per circuit gate; our garbled circuit-based solution is much
more eﬃcient (16 bytes and several symmetric key opera-
tions per circuit gate).
3. PRELIMINARIES
Let P1, . . . , P(cid:96) and S1, . . . , St be the set of clients and
servers, respectively, and let A = {a1, . . . , am} be the uni-
verse of all possible attributes. We associate an m-bit string
χi = χi[1]··· χi[m] ∈ {0, 1}m with each Pi such that χi[j] =
1 if and only if Pi has attribute aj. A policy is a (polynomial
sized) circuit C with m inputs and a single-bit output. We
say that Pi satisﬁes policy C if and only if C(χi) = 1.
Garbled circuits. One of our main building blocks is gar-
bled circuits. As the circuit description is public and only
one party has input, we can utilize privacy-free garbled cir-
cuits [25], which are more eﬃcient than standard garbled cir-
cuits. We use the garbled circuit notation of Bellare et al. [8],
with one function (veriﬁcation) introduced by Jawurek et
al. [34]. We only consider circuits with a single bit of out-
put, as this is all that is needed in our setting.
We deﬁne a veriﬁable garbling scheme by a tuple of func-
tions G = (Gb, Ev, Ve) with each function deﬁned as follows:
• Garbling algorithm Gb(1n, C): A randomized algo-
rithm which takes as input the security parameter and
a circuit C : {0, 1}m → {0, 1} and outputs a tuple
of strings (GC,{X 0
j }j∈[m],{Z 0, Z 1}), where GC is
the garbled circuit, the values {X 0
j }j∈[m] denote
j , X 1
j , X 1
1453the input-wire labels, and the values {Z 0, Z 1} denote
the output-wire labels.
• Evaluation algorithm Ev(GC,{Xj}j∈[m]): A determin-
istic algorithm which evaluates garbled circuit GC on
input-wire labels {Xj}j∈[m].
• Veriﬁcation algorithm Ve(C, GC,{X 0
j }j∈[m]): A
deterministic algorithm which takes as input a cir-
cuit C, garbled circuit GC, and input-wire labels {X 0
j ,
j }j∈[m], and outputs accept if GC is a valid garbling
X 1
of C and reject otherwise.
j , X 1
A veriﬁable garbling scheme must satisfy three security
properties: (1) correctness, (2) authenticity, and (3) ver-
iﬁability. The deﬁnitions for correctness and authenticity
are standard: correctness enforces that a correctly garbled
circuit, when evaluated, outputs the correct output of the
underlying circuit; authenticity enforces that the evaluator
can only learn the output label that corresponds to the value
of the function. Veriﬁability [34] allows one to check that
the garbled circuit indeed implements the speciﬁed plaintext
circuit C.
t-KEA assumption. We recall the t-KEA assumption
used in our implementation of extractable linearly homo-
morphic signature from §7. The assumption was formulated
in [11, 10]. See these papers and [32] for a good discussion
and further references related to this assumption and its re-
cent use. See also [5, 31] for a proof of security for t-KEA
in the generic (bilinear) group model. The formulation be-
low is simpliﬁed by not including an auxiliary input that, if
present, is the same for both algorithms E and E(cid:48)
. We will
use the plain acronym KEA when referring to the 1-KEA
assumption.
1 , . . . , gx
t
Definition 3.1. (t-KEA [11, 10]) Let G be a cyclic group
of prime order q. Consider algorithms that on input t ran-
dom elements g1, . . . , gt in G and t values gx
for
x ∈R Zq, output a pair (f, f(cid:48)
) in G2. Such an algorithm E is
said to be a t-KEA algorithm if with non-negligible probabil-
ity (over the choice of inputs to E and E’s random coins) E
outputs (f, f(cid:48)
= f x. We say that the t-KEA as-
sumption holds over G if for every eﬃcient t-KEA algorithm
E in G there exists another eﬃcient algorithm E(cid:48) for which
the following property holds except for a negligible probabil-
ity: Let g1, . . . , gt, gx
t be an input to E and ρ a vector
of random coins for E on which E outputs (f, f(cid:48)
= f x) then
on the same inputs (and random coins) E(cid:48) outputs a vector
1 ··· gxn
(f, f(cid:48)
n .
= f x, x1, . . . , xn) such that f = gx1
) such that f(cid:48)
1 , . . . , gx
Auxiliary functionalities. Our construction makes use of
two (standard) functionalities for commitments (Fcom) and
secure coin-tossing (Fcointoss).
Anonymous channels. Our protocol assumes that the
parties interact over anonymous channels. In practice, the
anonymity provided by the network used by the clients is
the level of anonymity that they achieve. For the purpose of
proving security, we assume a perfect anonymous channel.
In the simple-UC framework [21], which we use in this work,
all messages to and from functionalities have public headers
consisting of the type of operation, and the private content
itself; the public header is revealed to the adversary but not
the private content. However, the adversary is always given
the identity of the party sending the message to the func-
tionality and the identity of the party receiving the message
from the functionality. Thus, in order to model anonymous
channels, all parties must send and receive together. (This
actually makes sense since in principle, an adversary who
can view the entire network can break anonymity unless ev-
ery party interacts in each round. Nevertheless, here we use
this simply as a way to model the requirements.) The Fanon
functionality appears in Figure 3.1. In the functionality all
parties send a message to all other parties in each round.
Note that if a party has no message at all to send, or it
only needs to send to some parties, then it can simply use
an empty message. We stress again that in practice not all
parties need to interact in each round; this is merely for the
purpose of modeling.
4. SECURITY DEFINITION
All of our deﬁnitions and proofs are in the simple-UC
(SUC) model [21]. As was shown in the aforementioned
work [21], any protocol that is secure in the SUC framework
is also secure in the full UC framework.
Attribute-based key exchange. We present a function-
ality Fabke for attribute-based key exchange supporting at-
tribute privacy, unlinkability, and collusion resistance. The
functionality is initialized with a set of attribute vectors
{χi}, where χi corresponds to the attribute vector of client Pi.
The functionality begins by waiting for a message from a
server Sj that contains a circuit C representing Sj’s policy.
The functionality stores this information and broadcasts a
notiﬁcation to all parties P1, . . . , P(cid:96) that a policy is avail-
able. Upon receiving a response by one of the parties, say,
Pi, the functionality proceeds as follows. If C(χi) = 1, the
policy is satisﬁed and so the functionality forwards a random
key k to both Pi and Sj. If C(χi) = 0, then Fabke sends ⊥ to
both Pi and Sj. The full description of Fabke can be found
in Figure 4.1.
Attribute privacy is captured by the fact that Sj never
receives the attribute vector χi of client Pi. Collusion re-
sistance is handled by the fact that each party’s attribute
vector is ﬁxed upon functionality initialization and cannot
be changed. Thus, parties cannot use any attribute vector
that diﬀers from their initial ones. This implies that collu-
sions between parties to eﬀectively use a diﬀerent attribute
vector are impossible. Finally, unlinkability follows since the
functionality does not pass on the identity of the client Pi to
the server Sj at any time. We note that we do not provide
server anonymity in our deﬁnition, since it does not seem
to be required for the ABKE setting. Thus, the server’s
identity is revealed in the functionality deﬁnition.
We also introduce a functionality Fsetup for providing each
party with the keys used in our protocol construction; see
Figure 4.2.
5. ATTRIBUTE SELECTIVE ENCRYPTION
We introduce the notion of attribute selective encryption
(ASE). ASE is related to ABE in the sense that clients’ keys
and decryption capabilities are related to the attributes they
possess. In ASE a plaintext is comprised of a set of mes-
sages, and a client’s credentials determine which subset can
be decrypted. In more detail, each client has an m-bit vector
χ ∈ {0, 1}m representing a set of attributes: χ[j] is set to
1 if and only if the client possesses the jth attribute. The
1454Fanon works with clients P1, . . . , P(cid:96) as follows:
1. Upon receiving a message (send, sid, Pi, (mi
2. After Fanon receives a send message from every client P1, . . . , P(cid:96), Fanon sends (receive, sid, Pj , (m1
(cid:96))) from Pi, Fanon stores the message.
1, . . . , mi
j , . . . , m(cid:96)
j )) to client Pj
for j = 1, . . . , (cid:96).
The public header of each message is (send, sid, Pi) and (receive, sid, Pj ), respectively, for send and receive messages. The
private contents is the vector of messages.
Figure 3.1: Anonymous communications functionality Fanon.
Fabke runs with clients P1, . . . , P(cid:96) with attribute vectors χ1, . . . , χ(cid:96) ∈ {0, 1}m, and servers S1, . . . , St, and works as follows:
1. Upon receiving (policy, sid, C) from some Sj , where C is either a circuit C(cid:48) : {0, 1}m → {0, 1} or ⊥, send (policy, sid, Sj , C)
to all P1, . . . , P(cid:96). If C = ⊥ then halt, and otherwise store (policy, sid, Sj , C).
2. Upon receiving (exchange, sid, Sj ) from Sj and (exchange, sid, Sj , Pi) from Pi, if some message (policy, sid, Sj , C) is stored,
then:
• If C(χi) = 1 then choose k ∈R {0, 1}n and send (completed, sid, k) to Pi and Sj .
• If C(χi) = 0 then send (completed, sid, ⊥) to Pi and Sj .
3. Upon receiving (abort, sid) from Sim, clear any message (policy, sid, Sj , C) that is stored, send (abort, sid) to Pi and Sj ,
and halt.
The public header of each message is: (policy, sid, Sj , C), (exchange, sid, Sj ), and (completed, sid); all other content is private.
Figure 4.1: Attribute-based key exchange functionality Fabke with attribute privacy, unlinkability and collusion resistance.
client holds public and secret keys associated with χ. Any-
one can encrypt a set of 2m messages
(cid:18) x1,0
x1,1
(cid:19)
··· xm,0
··· xm,1
under the client’s public key, and ASE enforces an OT-like
property where the client can decrypt using its secret key
only one of each (xi,0, xi,1), depending on χ[j]. That is, the
client decrypts the messages x1,χ[1], . . . , xm,χ[m], and noth-
ing else. We stress that ASE, unlike ABE, encrypts under a
speciﬁc client’s public key, and only that client can decrypt.
Besides the basic semantic security notion of ASE, we con-
sider four additional properties: attribute privacy, collusion
resistance, unlinkability, and projectability. Each property