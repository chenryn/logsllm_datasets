OS Reaction time
Restart time
Time
tExpStart 
tWStart
(n)
 (n)
tResume 
tResponse 
(n)
(n)
tExpEnd 
(n)
tExpStart 
(n+1)
System Call 
intercepted
Execution 
resumed
Workload End
Figure 2. Benchmark execution sequence
2.4.  Benchmark  Set-up
2.5.  Benchmarking  Time
for  hosting 
the  workload,  and 
i) the  Target  Machine 
Since  perturbing  the  operating  system  may  lead  the
OS  to  hang,  a  remote  machine  is  required  to  reliably
control  the  benchmark  experiments.  This  machine  is
called the benchmark controller. Accordingly, for running
an  OS  dependability  benchmark  we  need  at  least  two
computers: 
the
benchmarked  OS  and 
ii) the
Benchmark  Controller  that  is  primarily  in  charge  of
diagnosing  and  collecting  data  in  case  of  a  hang  or  an
abort.  Furthermore,  as  we  are  using  a  TPC-C  client  as
workload,  the  (Oracle)  Data  Base  Management  System
(DBMS), that processes the TPC-C client requests, can  be
installed  on  the  benchmark  controller  or  on  another
machine.  Accordingly,  Figure 1  illustrates  the  various
components 
proposed  OS
dependability  benchmark  prototype,  for  Windows  2000.
The same set-up is used for the three OS  targets,  only  the
benchmark target is changed.
that 
characterize 
the 
To  intercept the  Win32  functions (i.e.,  system  calls),
we have modified  the  “Detours”  tool  [18],  a  library  for
intercepting arbitrary Win32  functions  on  x86  machines.
This modification was made to facilitate their replacement
The benchmarking time corresponds to  the  benchmark
implementation  time  and  to  the  benchmark  execution
time.
very time consuming.
The implementation  of  the  benchmark  itself  was  not
•  The  TPC-C  client  implementation  used  in  the
current set up is the same as  the  one used by  other
DBench partners  (see  e.g.,  [19]).  The  installation
took three days.
•  The implementation of the different components of
•  The  implementation  of  the  faultload  took  one
week, during  which we have i)  defined  the  set  of
the  values related to  the  28  system  call with  their
75  parameters  to  be  corrupted  and  ii)  created  the
database of the corrupted values.
the controller took about 10 days.
The  duration  of  an  experiment  with  workload
completion is  less  than  3  minutes  (including  the  time  to
workload  completion  and  the  restart  time),  while  it  is
about 7 minutes  without  workload completion  (including
the  workload  watchdog  timeout  of  5  minutes  and  the
restart time).  Thus,  on  average,  an  experiment  lasts  less
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:02 UTC from IEEE Xplore.  Restrictions apply. 
OS Hang/Panic
OS Exception
12.0%
0.0%
OS Hang/Panic
OS Exception
11.4%
0.0%
OS Hang/Panic
OS Exception
11.4%
0.0%
Windows NT4
OS Error Code
33.0%
No Signaling
55.1%
OS Error Code
34.1%
Windows 2000
No Signaling
54.5%
OS Error Code
31.2%
Windows XP
No Signaling
57.4%
Figure 3: OS Robustness measure using a mix of the three corruption techniques
than  5  minutes.  These  experiments  are  fully  automated
and  the  whole  benchmark  execution  duration  (552
experiments for each OS) is thus about 46h for each OS.
3. Comparison of the three OSs
The benchmark defined in the previous section is  used
to compare the behavior of Windows NT4,  2000  and XP.
We first evaluate the three benchmark measures defined in
Section  2.2  (robustness,  reaction  time  and  restart  time).
These measures give  information  on  the  global  behavior
of  the  OSs.  We will  then  show  how  they  can be  refined
and complemented by  making  sensitivity  analyses taking
into  account  the  workload  states  after  execution  of  a
corrupted system call.
3.1.  Benchmark  Measures
The  robustness  measures are given  in  Figure  3.  No
panic and  hang  states  were  observed  for  the  three  OSs.
Exceptions have been notified  in  11.4  %  to  12  %  of  the
cases, while  the  number  of  experiments  with  error  code
return varies between 31.2 % and 34.1  %.  More than  half
of the experiments led to a No signaling outcome.
Figure 3 shows a similar behavior for the  three OSs  with
respect to robustness. Sensitivity  analyses with  respect to
the faultload selection is performed in Section 3.2.1.
The  system  reaction  time  in  absence  of  faults,
 τexec,  is  evaluated  as  the  mean  reaction  time  of  the
28 selected  system  calls  whose  parameters  are  being
corrupted  for  the  experiments.  Table  3  shows  that,  in
absence  of  faults,  the  three  OS  have  different  reaction
times.
Table 3: OS reaction time
Windows NT4
Mean
SD
        344 µs
128 µs
230 µs
 τexec
Texec
Windows  2000
SD
Mean
      1782 µs
1241 µs
3359 µs
Windows  XP
Mean
SD
       111 µs
114 µs
176 µs
The OS reaction time in  the  presence of  faults,  Texec,
corresponds to  the  mean reaction time  of  the  selected  28
system  calls.  Table  3  shows  that  the  shortest  time  is
obtained  for  Windows  XP  while 
longest  one
corresponds  to  Windows  2000.  For  Windows  XP,  this
the 
time  is  slightly  longer than  the  reaction time  in  absence
of faults while it is significantly lower for  the  two  others.
This  may  be explained by  the fact that  in  about  45%  of
cases the OS detects the injected fault. It does not  execute
the faulted system call and returns an error code or  signals
an exception. The standard deviation (SD) is  significantly
longer than the mean for the three OSs. Section 3.2.2  will
provide more detailed information  to  explain the  various
behaviors.
The  system restart  time  is  given  in  Table  4  which
shows  that  Windows XP  restart  time  is  70%  of  that  of
Windows 2000,  without  faults  and 73%  of  this  time  in
the presence of faults. For  all  systems,  the restart time  is
only few seconds longer than without faults.
Table 4: System restart time
Windows NT4
Mean
SD
Windows  2000
Mean
SD.
Windows  XP
Mean
SD
92 s
105 s
74 s
96 s
4 s
109 s
8 s
80 s
8 s
τres
Tres
Summary
The  above  results  show  that  the  Windows  NT4,
Windows 2000  and Windows XP kernels have  equivalent
robustness.  This  is  not  surprising  as  the  three  OSs  are
from the same family. They  also  show  that  Windows XP
has the shortest system call  execution time  as  well  as  the
shortest restart times, both with and without  faults.  These
results  do  not  contradict  well-known  information  about
Windows  XP's  behavior  in  absence  of  faults.  They
confirm that they also hold in the presence of faults.
3.2.  Measure  Refinement
We  will  consider  successively  the  three  benchmark
measures  and  show  how  they  can  be  enriched  by
examining additional information that can  be provided by
the current benchmark set up.
3.2.1.  Robustness  Measure.  The  faultload  used  in  the
previous  section  includes  a  mix  of  the  three  corruption
techniques  presented  in  Section 2.3:  i) out-of-range  data
(or out  of  the  boundaries  of  accepted  parameter  values),
ii) incorrect  data  (but  within  the  boundaries  of  accepted
parameter values) and iii) incorrect addresses. In total  552
corrupted  values  for  the  75  parameters  related  to  the
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:02 UTC from IEEE Xplore.  Restrictions apply. 
28 selected system  calls.  This  faultload  is  referred  to  as
FL0.
that 
incorrect  data 
It  can  be  argued 
is  not
representative of application faults that should  be detected
by  the  OS.  In  order  to  analyze  its 
impact  on  the
benchmark results, we have considered a reduced faultload
FL1  including  only  out-of-range  data  and 
incorrect
addresses.  Thus  FL1  is  composed  of  325  corrupted
values.  The  comparison  shows  that  even  though  the
robustness  of  each OS  has  been  slightly  affected  by  the
corruption technique used,  the  three  OSs  have  still  very
similar robustness.
Incorrect  addresses  usually  point  to  out-of  range  or
incorrect data.  Taking a pessimistic  view,  let  us  assume
that  they  only  point  to  incorrect  data  and  could  be
discarded as in FL1. We have thus  considered a faultload,
FL2, comprising only out-of-range data (composed of 113
corrupted values). Comparison also shows that  using  FL2
leads to similar robustness of the three OSs.
This 
latter  result  encourages  corruption  of 
the
parameters of  all  system  calls  involved  in  the  workload
using only  the  out-of-range technique, without  increasing
significantly  the  benchmark  run  duration.  We  have  thus
considered  a  faultload,  FL3,  composed  of  only  out-of-
range data, targeting all of the 132 system  calls with  their
353 parameters. 468 experiments have been performed for
each OS.  The results  show  that  the  three  OSs  still  have
similar  robustness,  when  corrupting  all  system  calls
involved in TPC-C client workload.
The faultloads considered are summarized in  Table 5.
FL0 to FL3 use a selective substitution technique.
Table 5: Faultloads considered
Incorrect
data
Incorrect
address
Out-of-
range data
Bit-Flip
x
x
x
FL0
FL1
FL2
FL3
FL4
x
x
x
x
#  System
calls
28