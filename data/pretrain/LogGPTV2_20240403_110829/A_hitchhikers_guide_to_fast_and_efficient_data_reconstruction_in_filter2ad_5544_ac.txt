In the parlance of coding theory, this property is called
’repair-by-transfer’ [26]. This property carries over to all
three versions of Hitchhiker’s erasure code.
3.2 Hitchhiker-XOR+
Hitchhiker-XOR+ further reduces the amount of data re-
quired for reconstruction as compared to Hitchhiker-XOR,
and employs only additional XOR operations. It however re-
quires the underlying RS code to possess a certain property.
This property, which we term the all-XOR-parity property,
requires at least one parity function of the RS code to be
an XOR of all the data units. That is, a (k, r) RS code
satisfying all-XOR-parity will have one of the r parity bytes
as an XOR of all the k data bytes. For (k = 10, r = 4),
5For any set A and any element i ∈ A, the notation A\{i}
denotes all elements of A except i.
3.2.1 Encoding
The (k = 10, r = 4) Hitchhiker-XOR+ code is shown
in Fig. 5. The Hitchhiker-XOR+ code is obtained by per-
forming one additional XOR operation on top of Hitchhiker-
XOR: in the second parity of Hitchhiker-XOR, the byte of
the second substripe is XORed onto the byte of the ﬁrst sub-
stripe to give Hitchhiker-XOR+. The underlying RS code in
this example satisﬁes the all-XOR-parity property with its
second parity function f2 being an XOR of all the inputs.
We now argue that this additional XOR operation does
not violate the fault tolerance level and storage eﬃciency. To
see fault tolerance, observe that the data of the second par-
ity unit of Hitchhiker-XOR+ can always be converted back
to that under Hitchhiker-XOR by XORing its second sub-
stripe with its ﬁrst substripe. It follows that the data in any
unit under Hitchhiker-XOR+ is equivalent to the data in the
corresponding unit in Hitchhiker-XOR. The fault tolerance
properties of Hitchhiker-XOR thus carry over to Hitchhiker-
XOR+. Storage eﬃciency is retained because the additional
XOR operation does not increase the space requirement.
3.2.2 Decoding
The recovery of any unit i requires 13 bytes from the other
units. The choice of the bytes to be accessed depends on the
value of i, and is described below. The bytes required for the
reconstruction of any data unit i ∈ {1, . . . , 6} are identical
to that in Hitchhiker-XOR. Any data unit i ∈ {7, 8, 9} is
reconstructed using the following 13 bytes: the bytes of both
substripes of units {7, 8, 9}\{i}, and the bytes of only the
second substripes of units {1, . . . , 6, 10, 11, 14}. The tenth
unit is also reconstructed using only 13 bytes: the bytes of
only the second substripes of units {1, . . . , 9, 11, 13, 14}, and
the byte of only the ﬁrst substripe of unit 12. The decoding
procedure that operates on these 13 bytes is identical to the
three-step decoding procedure described in §3.1.2.
3.3 Hitchhiker-nonXOR
requires
compared to Hitchhiker-XOR, but
We saw that Hitchhiker-XOR+ results in more savings
as
the
underlying RS code to have the all-XOR-parity property.
Hitchhiker-nonXOR presented here guarantees the same
savings as Hitchhiker-XOR+ even when the underlying RS
code does not possess the all-XOR-parity property, but at
the
arithmetic.
Hitchhiker-nonXOR can thus be built on top of any RS
code. It oﬀers a saving of 35% during the reconstruction of
any data unit.
ﬁnite-ﬁeld
cost
of
additional
3.3.1 Encoding
The code for (k = 10, r = 4) is shown in Fig. 6. As
in Hitchhiker-XOR, in the second parity, the ﬁrst byte is
XORed with the second byte. The ﬁnal value of the second
parity as shown in Fig. 6 is a consequence of the fact that
f2(a) ⊕ f2(a1, a2, a3, 0, . . . , 0) = f2(0, 0, 0, a4, . . . , a10) due
to the linearity of RS encoding (this is discussed in greater
detail in §5.2.2).
3.3.2 Decoding
Recovery of any unit requires only 13 bytes from other
units. This set of 13 bytes is the same as in Hitchhiker-
unit 1
...
unit 10
unit 11
unit 12
unit 13
unit 14
a1
...
a10
f1(a)
i=4 ai⊕(cid:76)10
(cid:76)10
i=1 bi
f3(a)
f4(a)
b1
...
b10
f1(b)
i=1 bi⊕(cid:76)3
(cid:76)10
f3(b)⊕(cid:76)6
f4(b)⊕(cid:76)9
i=1 ai
i=4 ai
i=7 ai
a1
...
a10
f1(a)
f2(0,0,0,a4,...,a10)⊕f2(b)
f3(a)
f4(a)
b1
...
b10
f1(b)
f2(b)⊕f2(a1,a2,a3,0,...,0)
f3(b)⊕f2(0,0,0,a4,a5,a6,0,...,0)
f4(b)⊕f2(0,...,0,a7,a8,a9,0)
Figure 5: Hitchhiker-XOR+ for (k =10,r =4).
Parity 2 of the underlying RS code is all-XOR.
Figure 6: Hitchhiker-nonXOR code for (k =10,r =4). This
can be built on any RS code. Each row is one unit of data.
XOR+. The decoding operation is a three-step procedure.
The ﬁrst two steps are identical to the ﬁrst two steps of the
decoding procedure of Hitchhiker-XOR described at the end
of §3.1.2. The third step is slightly diﬀerent, and requires
an RS decoding operation (for units 1 to 9), as described
below.
During reconstruction of any unit i ∈ {1, 2, 3}, the
output of the second step is the set of three bytes
{a1, a2, a3, f1(a1, a2, a3, 0, . . . , 0)}\{ai}. This is equivalent
to having
set
{a1, a2, a3, 0, . . . , 0, f1(a1, a2, a3, 0, . . . , 0)}. Now, this set of
11 bytes is equal to the set of ﬁrst 11 bytes of the RS
encoding of {a1, a2, a3, 0, . . . , 0}.
An RS decoding
operation thus gives {a1, a2, a3} which contains the desired
byte ai. Recovery of any other unit i ∈ {4, . . . , 9} follows
along similar lines.
11 bytes
some
the
10
of
the
of
During the reconstruction of unit 10, the output of the
second step is f1(0, . . . , 0, a10). Hence the third step involves
only a single (ﬁnite-ﬁeld) multiplication operation.
3.4 Generalization to any (k, r)
The encoding and decoding procedures for the general
case follow along similar lines as the examples discussed
above, and are formally described in the Appendix. In each
of the three versions, the amount of data required for re-
construction is reduced by 25% to 45% as compared to RS
codes, depending on the values of the parameters k and
r. For instance, (k = 6, r = 3) provides a saving of 25%
with Hitchhiker-XOR and 34% with Hitchhiker-XOR+ and
Hitchhiker-nonXOR; (k = 20, r = 5) provides a savings
of 37.5% with Hitchhiker-XOR and 40% with Hitchhiker-
XOR+ and Hitchhiker-nonXOR.
4.
“HOP-AND-COUPLE” FOR DISK EFFI-
CIENCY
The description of the codes in §2 and §3 considers only
two bytes per data unit. We now move on to consider the
more realistic scenario where each of the k data units to
be encoded is larger (than two bytes). In the encoding pro-
cess, these k data units are ﬁrst partitioned into stripes, and
identical encoding operations are performed on each of the
stripes. The RS code considers one byte each from the k
data units as a stripe. On the other hand, Hitchhiker’s era-
sure code has two substripes within a stripe (§3) and hence
couples pairs of bytes within each of the k data units to form
the substripes of a stripe. We will shortly see that the choice
of the bytes to be coupled plays a crucial role in determining
the eﬃciency of disk reads during reconstruction.
A natural strategy for forming the stripes for Hitchhiker’s
erasure code is to couple adjacent bytes within each unit,
with the ﬁrst stripe comprising the ﬁrst two bytes of each of
the units, the second stripe comprising the next two bytes,
and so on. Fig. 7a depicts such a method of coupling for
(k = 10, r = 4).
In the ﬁgure, the bytes accessed during
the reconstruction of the ﬁrst data unit are shaded. This
method of coupling, however, results in highly discontigu-
ous reads during reconstruction: alternate bytes are read
from units 4 to 12 as shown in the ﬁgure. This high degree
of discontinuity is detrimental to disk read performance, and
forfeits the potential savings in disk IO during data recon-
struction. The issue of discontiguous reads due to coupling
of adjacent bytes is not limited to the reconstruction of the
ﬁrst data unit - it arises during reconstruction of any of the
data units.
In order to ensure that the savings oﬀered by Hitchhiker’s
erasure codes in the amount of data read during reconstruc-
tion are eﬀectively translated to gains in disk read eﬃciency,
we propose a coupling technique for forming stripes that we
call hop-and-couple. This technique aims to minimize the
degree of discontinuity in disk reads during the reconstruc-
tion of data units. The hop-and-couple technique couples a
byte with another byte within the same unit that is a cer-
tain distance ahead (with respect to the natural ordering of
bytes within a unit), i.e., it couples bytes after “hopping” a
certain distance. We term this distance as the hop-length.
This technique is illustrated in Fig. 7b, where the hop-length
is chosen to be half the size of a unit.
The hop-length may be chosen to be any number that di-
vides B
2 , where B denotes the size of each unit. This condi-
tion ensures that all the bytes in the unit are indeed coupled.
Coupling adjacent bytes (e.g., Fig. 7a) is a degenerate case
where the hop-length equals 1. The hop-length signiﬁcantly
aﬀects the contiguity of the data read during reconstruction
of the data units, in that the data is read as contiguous
chunks of size equal to the hop-length. For Hitchhiker’s era-
sure codes, a hop-length of B
2 minimizes the total number
of discontiguous reads required during the reconstruction of
data units. While higher values of hop-length reduces the
number of discontiguous reads, it results in bytes further
apart being coupled to form stripes. This is a trade-oﬀ to
be considered when choosing the value of the hop-length,
and is discussed further in §7.
We note that the reconstruction operation under RS codes
reads the entire data from k of the units, and hence trivially,
the reads are contiguous. On the other hand, any erasure
code that attempts to make reconstruction more eﬃcient
by downloading partial data from the units (e.g., [11, 15,
19, 21, 26, 27, 29]) will encounter the issue of discontiguous
Figure 7: Two ways of coupling bytes to form stripes for Hitchhiker’s erasure code. The shaded bytes are
read and downloaded for the reconstruction of the ﬁrst unit. While both methods require the same amount of
data to be read, the reading is discontiguous in (a), while (b) ensures that the data to be read is contiguous.
reads, as in Hitchhiker’s erasure code. Any such erasure
code would have multiple (say, α) substripes in every stripe
and would read a subset of these substripes from each of the
units during reconstruction. The hop-and-couple technique
can be applied to any such erasure code to translate the
network savings to disk savings as well. The hop-length can
be chosen to be any number that divides B
α . As in the case
of Hitchhiker’s erasure codes (where α = 2), this condition
ensures that all the bytes are indeed coupled. If the bytes to
be coupled are chosen with hop-length equal to B/α, then
the hop-and-couple technique would ensure that all the bytes
of a substripe are contiguous within any unit. Reading a
substripe from a unit would then result in a contiguous disk
read, thereby minimizing the total degree of discontiguity in
disk reads during reconstruction.
5.
IMPLEMENTATION
We have implemented Hitchhiker in the Hadoop Dis-
tributed File System (HDFS). HDFS-RAID [1] is a module
in HDFS that deals with erasure codes and is based on [8].
This module forms the basis for the erasure-coded storage
system employed in the data-warehouse cluster at Facebook,
and is open sourced under Apache. HDFS-RAID deployed
at Facebook is based on RS codes, and we will refer to this
system as RS-based HDFS-RAID. Hitchhiker builds on top
of RS codes, and the present implementation uses the RS
encoder and decoder modules of RS-based HDFS-RAID as
its building blocks.
5.1 Brief description of HDFS-RAID
HDFS stores each ﬁle by dividing it into blocks of a cer-
tain size. By default, the size of each block is 256MB, and
this is also the value that is typically used in practice. In
HDFS, three replicas of each block are stored in the system
by default. HDFS-RAID oﬀers RS codes as an alternative
to replication for maintaining redundancy.
The relevant modules of HDFS-RAID and the execution
ﬂows for relevant operations are depicted in Fig. 8. The
RAID-Node manages all operations related to the use of era-
sure codes in HDFS. It has a list of ﬁles that are to be con-
verted from the replicated state to the erasure-coded state,
and periodically performs encoding of these ﬁles via MapRe-
duce jobs. Sets of k blocks from these ﬁles are encoded to
generate r parity blocks each.6 Once the r parity blocks of a
set are successfully written into the ﬁle system, the replicas
of the k data blocks of that set are deleted. The MapRe-
duce job calls the Encoder of the erasure code to perform
encoding. The Encoder uses the Parallel-Reader to read the
data from the k blocks that are to be encoded. The Parallel-
Reader opens k parallel streams, issues HDFS read requests
for these blocks, and puts the data read from each stream
into diﬀerent buﬀers. Typically, the buﬀers are 1MB each.
When one buﬀer-sized amount of data is read from each of
the k blocks, the Encoder performs the computations per-
taining to the encoding operation. This process is repeated
until the entire data from the k blocks are encoded.
The RAID-Node also handles recovery operations, i.e., re-
constructing missing blocks in order to maintain the relia-
bility of the system. The RAID-Node has a list of blocks
that are missing and need to be recovered. It periodically
goes through this list and reconstructs the blocks by ex-
ecuting a MapReduce job. The MapReduce job calls the
Decoder of the erasure code to perform the reconstruction
operation. The Decoder uses the Parallel-Reader to read
the data required for reconstruction. For an RS code, data
from k blocks belonging to the same set as that of the block
under reconstruction is read in parallel. As in the encoding
process, data from the k blocks are read into buﬀers, and
the computations are performed once one buﬀer size amount
of data is read from each of the k blocks. This is repeated
until the entire block is reconstructed.
HDFS directs any request for a degraded read (i.e., a read
request for a block that is unavailable) to the RAID File