advance. This requires additional level of sophistication that
is not needed for replay attacks, since the adversary needs
to not only control the gaze tracking channel, but to also
observe and analyze the visual channel.
In conclusion, while we acknowledge that an adversary in
possession of multiple authentication attempts can attempt
diﬀerent targeted attacks, we argue that they require sig-
niﬁcantly higher level of sophistication and dedication than
what is needed to simply replay an acquired biometric sam-
ple. Therefore, we believe that successfully preventing re-
play attacks, as the most applicable threat vector against
biometrics, is an important step towards their widespread
deployment.
How fast is fast enough? The most common form of user
authentication in today’s world is password-based. Pass-
words are relatively fast to type and easy to implement.
Considering their prevalence and simplicity, we use pass-
words as an informal benchmark in terms of authentication
times and input error rates to assess the future potential of
gaze-based authentication based on reﬂexive eye behavior.
Over the last few years, a wide range of studies on pass-
word authentication have been published, several of those
focusing on evaluation of entry times for diﬀerent password
generation strategies, as well as input and recall error rates.
From a usability standpoint, we believe that a recent paper
by Shay et al. [39] provides an estimate of password usage
in a realistic setting and with a large number of users. The
authors evaluate multiple password-composition policies by
running an online experiment with 8,143 participants, who
are asked to create, remember and recall diﬀerent passwords.
Depending on the required password complexity, the median
input times varied from 11.6 to 16.2 seconds, while input er-
ror rates ranged between 4% and 7%. The authors also note
that more than 20% of participants had problems recalling
their password and more than 35% of participants stated
that remembering a password was hard.
Considering these ﬁndings, we believe that our results,
namely a median authentication time of 5 seconds and an
equal error rate of 6.3%, are highly comparable to input
times and error rates on passwords: on average, a successful
authentication attempt with our proposed system does not
take longer than typing a password, with an added beneﬁt
that users need neither learn nor recall any information or
procedure.
10. CONCLUSION
Building upon the core idea of using reﬂexive human be-
havior for authentication, in this paper we designed an in-
teractive visual stimulus for rapidly eliciting standardized
reﬂexive eye movements, and showed how such stimulus can
be used to construct a fast challenge-response biometric sys-
tem. Based on a series of user experiments, we showed that
our stimulus indeed elicits predominately reﬂexive saccades,
which are automatic responses that only pose low cognitive
load on the user. As a result of using reﬂexive behavior that
is fast and stable, we show that our authentication system
achieves fast authentication times (median of 5 seconds) and
low error rates (6.3% EER).
Most importantly, however, our proposed authentication
method shows resilience against replay attacks, a property
diﬃcult to achieve with most biometrics. Evaluation shows
that the system is able to detect the replay of recorded eye
traces with very high probability of 99.94%, thus preventing
one of the most applicable attacks on biometric systems.
Considering the recent proliferation of reliable and aﬀord-
able eye tracking devices, we believe that achieving fast and
reliable gaze-based authentication is of broad interest and we
consider our work to be an important step in this direction.
Finally, this paper opens several interesting questions for
future work, such as could reﬂexive human behavior be ex-
ploited in other biometric modalities, or how could reﬂexive
behavior of human visual system be used to support other
authentication methods?
Acknowledgements. Ivo Sluganovic is supported by the
UK EPSRC doctoral studentship, Scatcherd European Schol-
arship, and the Frankopan Fund. Authors wish to thank
Armasuisse for support with gaze tracking equipment.
2012. 2012 IEEE 5th International Conference on Biometrics:
Theory, Applications and Systems, BTAS 2012, (Btas), 2012.
[22] P. Kasprowski and J. Ober. Eye Movements in Biometrics.
Biometrics, 3087 / 200, 2003.
[23] Katharine Byrne. MSI & Tobii join forces to create eye-tracking
11. REFERENCES
[1] W. W. Abbott and A. A. Faisal. Ultra-low-cost 3D gaze
estimation: an intuitive high information throughput
compliment to direct brain-machine interfaces. Journal of
Neural Engineering, 9(4), 2012.
[2] R. Abrams, D. E. Meyer, and S. Kornblum. Speed and accuracy
of saccadic eye movements: characteristics of impulse
variability in the oculomotor system. Journal of experimental
psychology. Human perception and performance, 15(3), 1989.
[3] T. Bahill, M. R. Clark, and L. Stark. The main sequence, a tool
for studying human eye movements. Mathematical Biosciences,
24(3-4):191–204, 1975.
[4] T. Bahill and T. Laritz. Why Can’t Batters Keep Their Eyes
on the Ball? American Scientist, (May - June), 1984.
gaming laptop, 2015.
[24] A. Klin, W. Jones, R. Schultz, F. Volkmar, and D. Cohen.
Visual ﬁxation patterns during viewing of naturalistic social
situations as predictors of social competence in individuals with
autism. Archives of general psychiatry, 59:809–816, 2002.
[25] T. Kocejko and J. Wtorek. Information Technologies in
Biomedicine: Third International Conference, ITIB 2012,
Gliwice, Poland, June 11-13, 2012. Proceedings, chapter Gaze
Pattern Lock for Elders and Disabled, pages 589–602. Springer
Berlin Heidelberg, Berlin, Heidelberg, 2012.
[26] O. V. Kolesnikova, L. V. Tereshchenko, a. V. Latanov, and
V. V. Shulgovskii. Neuroscience and Behavioral Physiology,
40(8):869–876, 2010.
[27] O. V. Komogortsev, U. K. S. Jayarathna, C. R. Aragon, and
M. Mechehoul. Biometric Identiﬁcation via an Oculomotor
Plant Mathematical Model. Eye Tracking Research &
Applications (ETRA) Symposium, 2010.
[5] A. Boehm, D. Chen, M. Frank, L. Huang, C. Kuo, T. Lolic,
[28] O. V. Komogortsev, A. Karpov, and C. D. Holland. Attack of
I. Martinovic, and D. Song. Safe: Secure authentication with
face and eyes. In Privacy and Security in Mobile Systems
(PRISMS), 2013 International Conference on, June 2013.
[6] A. Bulling, F. Alt, and A. Schmidt. Increasing the security of
gaze-based cued-recall graphical passwords using saliency
masks. In CHI, 2012.
[7] V. Cantoni, C. Galdi, M. Nappi, M. Porta, and D. Riccio.
Gant: Gaze analysis technique for human identiﬁcation.
Pattern Recognition, 48(4), 2015.
[8] M. S. Castelhano and J. M. Henderson. Stable individual
diﬀerences across images in human saccadic eye movements.
Canadian Journal of Experimental Psychology/Revue
canadienne de psychologie exp´erimentale, 62(1):1–14, 2008.
[9] J. E. S. Choi, P. a. Vaswani, and R. Shadmehr. Vigor of
movements and the cost of time in decision making. The
Journal of neuroscience : the oﬃcial journal of the Society
for Neuroscience, 34(4), 2014.
[10] C. Cortes and V. Vapnik. Support-vector networks. Machine
Learning, 20:273–297, 1995.
Mechanical Replicas : Liveness Detection With Eye
Movements. IEEE TIFS, 10(4), 2015.
[29] M. Kumar, T. Garﬁnkel, D. Boneh, and T. Winograd.
Reducing shoulder-surﬁng by using gaze-based password entry.
In Proceedings of the 3rd Symposium on Usable Privacy and
Security, SOUPS ’07, New York, NY, USA, 2007. ACM.
[30] M. F. Land. Oculomotor behaviour in vertebrates and
invertebrates. The Oxford handbook of eye movements, 1,
2011.
[31] I. E. Lazarev and a. V. Kirenskaia. Eﬀect of eye dominance on
saccade characteristics and slow EEG potentials. Fiziologiia
cheloveka, 34(2):23–33, 2008.
[32] E. Miluzzo, T. Wang, A. T. Campbell, and a. C. M. S. I. G.
o. D. Communication. EyePhone: Activating Mobile Phones
with Your Eyes. Workshop on Networking, Systems, and
Applications on Mobile Handhelds (MobiHeld), 2010.
[33] M. Nystrom and K. Holmqvist. An adaptive algorithm for
ﬁxation, saccade, and glissade detection in eyetracking data.
Behavior Research Methods, 42(1), 2010.
[11] A. De Luca, M. Denzel, and H. Hussmann. Look into my eyes!:
[34] T. Poitschke, F. Laquai, S. Stamboliev, and G. Rigoll.
Can you guess my password? In Proceedings of the 5th
Symposium on Usable Privacy and Security, SOUPS ’09, New
York, NY, USA, 2009. ACM.
[12] F. Di Russo, S. Pitzalis, and D. Spinelli. Fixation stability and
saccadic latency in elite shooters. Vision Research, 43(17),
2003.
Gaze-based interaction on multiple displays in an automotive
environment. In Conference Proceedings - IEEE International
Conference on Systems, Man and Cybernetics, 2011.
[35] I. Rigas, G. Economou, and S. Fotopoulos. Biometric
identiﬁcation based on the eye movements and graph matching
techniques. Pattern Recognition Letters, 33(6), 2012.
[13] S. Eberz, K. B. Rasmussen, V. Lenders, and I. Martinovic.
[36] I. Rigas and O. V. Komogortsev. Biometric Recognition via
Preventing Lunchtime Attacks: Fighting Insider Threats With
Eye Movement Biometrics. In Proceedings of the 2015
Networked and Distributed System Security Symposium.,
2015.
[14] C. Galdi, M. Nappi, D. Riccio, V. Cantoni, and M. Porta. A
new gaze analysis based soft-biometric. Lecture Notes in
Computer Science, 7914 LNCS, 2013.
Probabilistic Spatial Projection of Eye Movement Trajectories
in Dynamic Visual Environments. IEEE TIFS, 9(10), 2014.
[37] U. Saeed. Eye movements during scene understanding for
biometric identiﬁcation. Pattern Recognition Letters, 59, 2015.
[38] SensoMotoric Instruments GmbH. SMI RED500 Technical
Speciﬁcation. Technical report, SensoMotoric Instruments
GmbH, Teltow, Germany, 2011.
[15] L. R. Gottlob, M. T. Fillmore, and B. D. Abroms. Age-group
[39] R. Shay, L. F. Cranor, S. Komanduri, A. L. Durity, P. S. Huh,
diﬀerences in saccadic interference. The journals of
gerontology. Series B, Psychological sciences and social
sciences, 62(2):85–89, 2007.
[16] C. Holland and O. Komogortsev. Complex eye movement
pattern biometrics: Analyzing ﬁxations and saccades. In
Biometrics (ICB), 2013 International Conference on, June
2013.
[17] C. Holland and O. V. Komogortsev. Biometric identiﬁcation via
eye movement scanpaths in reading. 2011 International Joint
Conference on Biometrics, IJCB 2011, 2011.
[18] K. Holmqvist, M. Nystr ˜A˝um, R. Andersson, R. Dewhurst,
J. Halszka, and J. van de Weijer. Eye Tracking : A
Comprehensive Guide to Methods and Measures. Oxford
University Press, 2011.
[19] P. Kasprowski. Human Identiﬁcation Using Eye Movements.
Institute of Computer Science, 2004.
[20] P. Kasprowski. The Second Eye Movements Veriﬁcation and
Identiﬁcation Competition. In IEEE & IAPR International
Joint Conference on Biometrics, 2014.
[21] P. Kasprowski, O. V. Komogortsev, and A. Karpov. First eye
movement veriﬁcation and identiﬁcation competition at BTAS
M. L. Mazurek, S. M. Segreti, B. Ur, L. Bauer, and N. Christin.
Can long passwords be secure and usable? Proceedings of the
32nd annual ACM conference on Human factors in
computing systems - CHI ’14, 2014.
[40] P. Sumner. Determinants of saccade latency. In Oxford
handbook of eye movements, volume 22, pages 411–424. 2011.
[41] R. Walker, D. G. Walker, M. Husain, and C. Kennard. Control
of voluntary and reﬂexive saccades. Experimental Brain
Research, 130(4):540–544, Feb. 2000.
[42] J. Weaver, K. Mock, and B. Hoanca. Gaze-based password
authentication through automatic clustering of gaze points.
Conference Proceedings - IEEE International Conference on
Systems, Man and Cybernetics, 2011.
[43] Y. Zhang, Z. Chi, and D. Feng. An Analysis of Eye Movement
Based Authentication Systems. International Conference on
Mechanical Engineering and Technology (ICMET-London
2011), 2011.
[44] M. Zhang, Y; Laurikkala, J; Juhola. Biometric veriﬁcation of a
subject with eye movements, with special reference to temporal
variability in saccades between a subject’s measurements. Int.
J. Biometrics, 6(1), 2014.