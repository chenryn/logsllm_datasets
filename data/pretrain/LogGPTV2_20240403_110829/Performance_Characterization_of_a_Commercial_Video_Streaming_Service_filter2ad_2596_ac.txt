serve less popular content seem to have worse performance at a
lower load than the servers with a higher load.
Take-away. An interesting direction to achieve better utilization
of servers and load balancing is to actively partition popular con-
tent among servers (on top of cache-focused routing). For exam-
ple, given that the top 10% of videos make up 66% of requests,
distributing only the top 10% of popular videos across servers can
balance the load.
4.2 Network Performance Problems
Network problems can manifest themselves in the form of in-
creased packet loss, reordering, high latency, high variation in la-
tency, and low throughput. Each can be persistent (e.g., far away
clients from a server have persistent high latency) or transient (e.g.,
spike in latency caused by congestion). In this section, we charac-
terize these problems.
Distinguishing between a transient and a persistent problem mat-
ters because although a good ABR may adapt to temporary prob-
lems (e.g., by lowering bitrate), it cannot avoid bad quality caused
by persistent problems (e.g., when a peering point is heavily con-
gested, even the lowest bitrate may see re-buffering). Instead, per-
sistent problems require corrective actions taken by the video provider
(e.g., placement of new CDN PoPs) or ISPs (e.g., additional peer-
ing).
We characterize the impact of loss and latency on QoE. To char-
acterize long-term problems, we aggregate sessions into /24 IP pre-
ﬁxes since most allocated blocks and BGP preﬁxes are /24 pre-
ﬁxes [29, 16]. Figure 7 shows the effect of network latency during
the ﬁrst chunk on video QoE, speciﬁcally, startup delay, across ses-
sions. High latency in a session could be caused by a persistently
high baseline (i.e., high srttmin)5, or variation in latency as a result
of transient problems (i.e., high variation, σsrtt). Figure 8 shows
the distribution of both of these metrics across sessions. We see
that both of these problems exist among sessions; we characterize
each of these next.
5Note that TCP’s estimate of RTT, SRTT, is an EWMA average;
hence srttmin is higher than the minimum RTT seen by TCP. The
bias of this estimator, however, is not expected to be signiﬁcant for
our study since it is averaged.
02k4k6kRank¸x0510152025Miss percentage (%)02k4k6kRank¸x51015202530Median server delay (ms)0100200300400500600srtt of first chunk (ms)0.00.51.01.52.02.53.0Startup time (sec)averagemedian503Figure 8: CDF of baseline (srttmin) and variation in latency
(σsrtt) among sessions.
Figure 9: Mean distance (km) of US preﬁxes in the tail latency
from CDN servers.
1. Persistent high latency caused by distance or enterprise path
In Figure 8, we see that some sessions have a high
problems.
minimum RTT. To analyze the minimum latency, it is important
to note that the SRTT samples are taken after 500ms from the be-
ginning of the chunk’s transmission; hence, if a chunk has self-
loading [21], the SRTT sample may reﬂect the additional queuing
delay and not just the baseline latency. To ﬁlter out chunks whose
SRTT has grown while downloading, we use an estimate of the ini-
tial network round-trip time (rtt0) per-chunk. Equation 1 shows
that DF B − (DCDN + DBE) can be used as an upper-bound es-
timate of rtt0. We take the minimum of SRTT and rtt0 per-chunk
as the baseline sample. Next, to ﬁnd the minimum RTT in a session
or preﬁx, we take the minimum among all these per-chunk baseline
samples in the session or preﬁx.
In order to ﬁnd the underlying cause of persistently high latency,
we aggregate sessions into /24 client preﬁxes. The aggregation
overcomes client last-mile problems, which may increase the la-
tency for one session, but are not persistent problems. A preﬁx has
more RTT samples than a session; hence, congestion is less likely
to inﬂate all samples.
We focus our analysis on preﬁxes in the 90th percentile latency,
where srttmin > 100ms; which is a high latency for cable/broadband
connections (note that our CDN and client footprint is largely within
North America). To ensure that a temporary congestion or rout-
ing change has not affected samples of a preﬁx, and to understand
the persistent problems in poor preﬁxes, we repeat this analysis
every day in our dataset and calculate the recurrence frequency,
#days preﬁx in tail
. We take the top 10% of preﬁxes with highest re-
occurrence frequency as preﬁxes with a persistent latency problem.
This set includes 57k preﬁxes.
#days
In these 57k preﬁxes, 75% are located outside the US and are
spread across 96 different countries. These non-US clients are often
limited by geographical distance and propagation delay. However,
among the 25% of preﬁxes located in the US, the majority are close
to CDN nodes. Since IP geolocation packages may not be accurate
outside US, in particular favoring the US with 45% of entries [29],
we focus our geo-speciﬁc analysis to US clients. Figure 9 shows
the relationship between the srttmin and geographical distance of
these preﬁxes in the US. If a preﬁx is spread over several cities, we
use the average of their distances to the CDN server. Among high-
latency preﬁxes inside the US within a 4km distance, only about
10% are served by residential ISPs, while the remaining 90% of
preﬁxes originate from corporations and private enterprises.
Take-away: Finding clients that suffer from persistent high latency
due to geographical distance helps video content providers in bet-
ter placement of new CDN servers and trafﬁc engineering.
It is
Figure 10: CDF of path latency variation: CV of latency per
path, a path is deﬁned by a (preﬁx, PoP) pair.
equally important to look at close-by clients suffering from high
latency to (1) avoid over-provisioning servers in those geographics
and wasting resources, and, (2) identify the IP preﬁxes with known
persistent problems and adjust the ABR algorithm accordingly, for
example, to start the streaming with a more conservative initial bi-
trate.
2. Residential networks have lower latency variation than en-
terprises. To measure RTT variation, we calculate the coefﬁcient
of variation (CV) of SRTT in each session, which is deﬁned as
the standard deviation over the mean of SRTT. Sessions with low
variability have CV  1. For each ISP and organization, we measure
the ratio of sessions with CV > 1 to all sessions. We limit the
result to ISPs/organizations that have least 50 video streaming ses-
sions to provide enough evidence of persistence. Table 5 shows
the top ISPs/organizations with highest ratio. Enterprises networks
make up most of the list. To compare this with residential ISPs,
we analyzed ﬁve major residential ISPs and found that about 1% of
sessions have CV > 1.
In addition to per-session variation in latency, we characterize
the variation of latency in preﬁxes as shown in Figure 10. We use
the average srtt of each session as the sample latency. To ﬁnd
the coefﬁcient of variance among all source-destination paths, we
group sessions based on their preﬁx and the CDN PoP. We see that
40% of (preﬁx, PoP) pairs belong to paths with high latency varia-
tion (CV > 1).
Take-away: Recognizing which clients are more likely to suffer
from latency variation is valuable for content providers because it
helps them make informed decisions about QoE. In particular, the
player bitrate adaptation and CDN trafﬁc engineering algorithms
can use this information to optimize streaming quality under high
100101102103Latency (ms)0.00.20.40.60.81.0CDF¾srttsrttmin01000200030004000Mean distance of prefix from CDN servers (km)0.00.20.40.60.81.0CDF0246810CV(srtt) among sessions of each (prefix, CDN PoP)0.00.20.40.60.81.0CDF504isp/organization
#sessions with CV > 1
#all sessions
Percentage
Enterprise#1
Enterprise#2
Enterprise#3
Enterprise#4
Enterprise#5
30
4,836
1,634
83
81
69
11,731
4,084
208
203
43.4%
41.2%
40.0%
39.9%
39.9%
Table 5: ISP/Organizations with highest percentage of sessions
with CV (SRT T ) > 1.
latency variation. For example, the player can make more conser-
vative bitrate choices, lower the inter-chunk wait time (i.e., request
chunks sooner), and increase the buffer size to deal with variability.
3. Earlier packet losses have higher impact on QoE. We use the
retransmission count to study the effect of packet losses. A ma-
jority of the sessions (> 90%) have a retransmission rate of less
than 10%, with 40% of sessions experiencing no loss. While 10%
can severely impact TCP throughput, not every retransmission is
caused by an actual loss (e.g., due to early retransmit optimiza-
tions, underestimating RTO, etc.). Figure 11 shows the differences
between sessions with and without loss in three aspects: (a) num-
ber of chunks (are these sessions shorter?), (b) bitrate (similar qual-
ity?), and (c) re-buffering. We see that the session length and bitrate
distributions are almost similar between the two groups; however,
re-buffering difference is signiﬁcant and sessions without loss have
better QoE.
While higher loss rates generally indicate higher re-buffering
(Figure 12), the loss rate of a TCP connection does not necessarily
correlate with the video QoE; the timing of the loss matters too.
Figure 13 shows two example sessions (case-1 and case-2) where
both sessions have 10 chunks with similar bitrates, cache status,
and SRTT distributions. Case-1 has a retransmission rate of 0.75%
compared to 22% in case-2; but it experienced dropped frames and
re-buffering despite the lower loss rate. As Figure 13 shows, the
majority of losses in case-1 happen in the ﬁrst chunk, while case-
2 has no loss during the ﬁrst four chunks, building up its buffer
to 29.8 seconds before a loss happens and successfully avoids re-
buffering.
Because the buffer can hide the effect of subsequent loss, we
believe that it is important to not only measure loss rate in video
sessions, but also the chunk ID that experiences loss. Loss dur-
ing earlier chunks has more impact on QoE because the playback
buffer would hold less data for earlier chunks. We expect losses
during the ﬁrst chunk to have the highest effect on re-buffering.
Figure 14 shows two examples: (1) P (rebuf at chunk = X), which
is the percentage of chunks with that chunk ID seeing a re-buffering
event; and (2) P (rebuf at chunk = X|loss at chunk = X), which
is the same probability conditioned on occurrence of a loss during
the chunk. While occurrence of a loss in any chunk increases the
likelihood of a re-buffering event, the increase is more signiﬁcant
for the ﬁrst chunk.
We observe that losses are more likely to happen on the ﬁrst
chunk: Figure 15 shows the average per-chunk retransmission rate.
The bursty nature of TCP losses towards the end of slow start [7]
could be the cause of higher loss rates during the ﬁrst chunk, which
TCP avoids in subsequent chunks when transitioning into conges-
tion avoidance state.
Take-aways: Due to the existence of a buffer in video stream-
ing clients, the session loss rate does not necessarily correlate with
QoE. The temporal location of loss in the session matters as well:
(a) CDF of session length with and without loss
(b) CDF of Average bitrate with and without loss
(c) CCDF (1-CDF) of Re-buffering rate with and
without loss
Figure 11: Differences in session length, quality, and re-
buffering with and without loss.
Figure 12: Rebuffering vs retransmission rate in sessions.
05101520#chunks0.00.20.40.60.81.0CDFno lossloss102103104Avg bitrate (kbps)0.00.20.40.60.81.0CDFno lossloss10-1100101102rebuffering rate (%)0.000.010.020.030.040.05CCDFno lossloss0246810retransmission rate %0.00.51.01.52.02.53.0rebuffering rate %505We use DLB as a “measure” of throughput. Both latency (DF B)
and throughout (DLB) play a role in this score. We deﬁne the
latency share in performance by
and the throughput
DF B
DF B +DLB
DLB
DF B +DLB
. We show that while the chunks with bad per-
share by
formance generally have higher latency and lower throughput than
chunks with good performance, throughput is a more “dominant”
metric in terms of impact on the performance of the chunk. Fig-
ure 16(a) shows that chunks with good performance generally have
higher share of latency and lower share of throughput than chunks
with bad performance. Figure 16(b) shows the difference in ab-
solute values of DF B, and Figure 16(c) shows the difference in
absolute values of DLB.
Figure 13: Example case for loss vs QoE.
Figure 14: Re-buffering frequency per chunkID, Re-bufffering
frequency given loss per chunkID.
Figure 15: Average per-chunk retransmission rate.
earlier losses impact QoE more, with the ﬁrst chunk having the
biggest impact.
Due to the bursty nature of packet losses in TCP slow start caused
by the exponential growth, the ﬁrst chunk may have the highest per-
chunk retransmission rate. Prior work showed a possible solution
to work around a related issue using server-side pacing [19].
4. Throughput is a bigger problem than latency. To separate
chunks based on performance, we use the following intuition: the
playback buffer decreases when it takes longer to download a chunk
than there are seconds of video in the chunk. With τ as the chunk
duration, we tag chunks with bad performance when the following
score is less than one:
While chunks with bad performance generally have higher ﬁrst
and last byte delays, the difference in DF B is negligible compared
to that of DLB. We can see that most chunks with bad performance
are limited by throughout and have a higher throughput share.
Take-away: Our ﬁndings could be good news for ISPs because
throughput can be an easier problem to ﬁx (e.g., establish more
peering points) than latency [3].
4.3 Client’s Download Stack
1. Some chunks have signiﬁcant download stack latency. Video
packets traversing the client’s download stack (OS, browser, and
the Flash plugin) may be delayed due to buffered delivery. In the
extreme case, all the chunk bytes could be buffered and delivered
late and all at once to the player6, resulting in a signiﬁcant increase
in DF B. Since the buffered data is delivered at once or in short time
windows, the instantaneous throughput (T Pinst = chunk size
) will
DLB