10
10
15
15
15
15
20
20
20
20
25
25
25
25
30
30
30
30
Length of Attack Path (in hops)
Length of Attack Path (in hops)
Length of Attack Path (in hops)
Length of Attack Path (in hops)
Figure 9: The number of false positives in a SPIE-generated attack
graph as a function of the length of the attack path, for p = 1/8.
The theoretical bound is plotted against three simulation results,
two with false-positive rates conditioned on router degree, one
without. For the two degree-dependent runs, one considered actual
link utilization, while the other assumed full utilization. Each sim-
ulation represents the average of 5000 runs using actual topology
and utilization data from a national tier-one ISP.
In order to validate our theoretical bound, we have plotted the ex-
pected number of false positives as a function of attack path length
and digest table performance, np/(1 − p) as computed above, and
show that in comparison to the results of three simulations on our
ISP backbone topology.
In the ﬁrst, we set the maximum digest
table false-positive probability to P = p/d, as prescribed above.
Figure 9 shows a false-positive rate signiﬁcantly lower than the an-
alytic bound. A signiﬁcant portion of the disparity results from the
relatively low link utilizations maintained by operational backbones
(77% of the links in our data set had utilization rates of less than
25%), as can be seen by comparing the results of a second sim-
ulation assuming full link utilization. There remains, however, a
considerable gap between the analytic bound and simulated perfor-
mance in network backbones.
The non-linearity of the simulation results indicates there is a strong
damping factor due to the topological structure of the network. In-
tuitively, routers with many neighbors are found at the core of the
network (or at peering points), and routers with fewer neighbors are
found toward the edge of the network. This suggests false positives
induced by core routers may quickly die out as the attack graph
proceeds toward less well-connected routers at the edge.
To examine the dependence upon vertex degree, we conducted an-
other simulation. This time, we removed the false-positive rate’s
dependence upon the degree of the router’s neighbors, setting the
digest table performance to simply P = p (and returning to ac-
tual utilization data). While there is a marked increase in the num-
ber of false positives, it remains well below the analytic bound.
This somewhat surprising result indicates that despite the analytic
bound’s dependence on router degree, the hierarchical structure of
ISP backbones may permit a relaxation of the coupling, allowing
the false positive rate of the digest tables, P , to be set independently
of the degree, d, resulting in signiﬁcant space savings.
7.2 Time and memory utilization
The amount of time during which queries can be supported is di-
rectly dependent on the amount of memory dedicated to SPIE. The
appropriate amount of time varies depending upon the responsive-
ness of the method used to identify attack packets. For the purposes
of discussion, however, we will assume one minute is a reasonable
amount of time in which to identify an attack packet and initiate
a traceback. As discussed in section 5.1, once the appropriate di-
gest tables have been moved to SCARs the actual query process can
arbitrarily be delayed.
Given a particular length of time, the amount of memory required
varies linearly with the total link capacity at the router and can be
dramatically affected by the dimension of the Bloom ﬁlter in use.
Bloom ﬁlters are typically described in terms of the number of di-
gesting functions used and the ratio of data items to be stored to
memory capacity. The effective false-positive rate for a Bloom ﬁl-
ter that uses m bits of memory to store n packets with k digest
functions can be expressed as
(cid:1)
1 −
(cid:2)
1 − 1
m
P =
(cid:3)kn
(cid:4)k ≈
(cid:5)
1 − e−kn/m
(cid:6)k
.
Tables providing the effective false-positive rates for various ca-
pacities and digesting functions are readily available [8]. For the
purposes of discussion, we will consider using a Bloom ﬁlter with
three digesting functions (k = 3) and a capacity factor (m/n) of
ﬁve, meaning to store n packets, we will use a Bloom ﬁlter of size
m = 5n. Such a ﬁlter provides an effective false-positive rate of
P = 0.092 when full.
While this is well below the value of 1/8 or 0.125 used in our
degree-independent simulations, it is high if digest tables are cal-
ibrated with respect to router degree. Luckily, by increasing the
number of digesting functions, Bloom ﬁlters are able to achieve sig-
niﬁcantly lower false-positive rates with slight increases in capacity.
For instance, a false-positive rate of 0.00314, which corresponds to
our degree-dependent simulation, P = p/d, with p = 1/8 for
routers with as many as 40 neighbors, can be achieved using 8 di-
gesting functions and memory factor of only 12—slightly greater
than twice what we suggest.
SPIE’s memory needs are determined by the number of packets
processed. Hence, we consider an average-sized packet of approx-
imately 1000 bits, and describe link speeds in terms of packets per
second. We combine this with the Bloom ﬁlter factor of 5 from
above to compute a rule of thumb: SPIE requires roughly 0.5% of
the total link capacity in digest table storage. For a typical low-end
router with four OC-3 links, this results in roughly 47MB of stor-
age. On the very high end, a core router with 32 OC-192 links3
has a maximum capacity of about 640Mpkts/sec which would re-
quire roughly 3.125Gb/sec of digest table memory or 23.4GB for
one minute’s worth of storage. In practice, however, the size of a
digest table will be limited by the type of memory required.
Capacity is not the only memory consideration, however—access
times turn out to be equally important. Packets must be recorded
in the digest table at a rate commensurate with their arrival. Even
given an optimistic DRAM cycle time of 50ns per read-modify-
write cycle, routers processing more than 20Mpkts/sec (roughly 1
3Current production routers support at most one OC-192 link.
OC-192 link, or 4 OC-48s) require an SRAM digest table. Cur-
rent SRAM technology limits digest tables to 16Mb which must be
paged to SDRAM in order to store a minute’s worth of digests as
described in section 6. Hence, an entire minute’s worth of trafﬁc
can only be stored in one (unpaged) digest table at low link speeds.
7.3 Timing uncertainties
In the OC-192 scenario described above, 16Mb would hold roughly
5ms of trafﬁc data; hence, the history buffer would store 12,000
individual digest tables. This observation gives rise to another im-
portant issue: imperfect timing may cause SPIE to need to examine
multiple packet digests at a particular router. The more digests that
must be considered, the greater the chance of false positives, so it is
advantageous to make the digest tables as large as possible. For rea-
sonable link speeds, the memory access time becomes slow enough
that SDRAM can be used which, using current technology, would
allow 256Mb digest tables, with a capacity of roughly 50Mpkts.
It may be the case that the approximate packet service time can-
not be conﬁned to an interval covered by one digest table. In that
case, we expect the false-positive rate to increase linearly with the
number of digest tables examined. For high-speed routers, it is es-
pecially important to maintain precise timing synchronization be-
tween adjacent routers. We have not yet examined the impact of
typical NTP clock skew on SPIE’s performance, but believe syn-
chronization can be maintained to within a small number of digest-
ing intervals, not signiﬁcantly impacting our false-positive rate.
8 DISCUSSION
There are several issues that must be dealt with for a SPIE query to
succeed. First, traceback operations will often be requested when
the network is unstable (likely due to the attack that triggered the
traceback); SPIE communications must succeed in a timely fash-
ion even in the face of network congestion and instability. The best
solution is to provide SPIE with an out-of-band channel, possibly
through either physically or logically separate (ATM VCs) links.
But even without private channels, it is still possible to ensure suc-
cessful transmission by granting sufﬁcient priority to SPIE trafﬁc.
SPIE’s usefulness increases greatly with widespread deployment
because SPIE can only construct an attack graph for that portion of
the packet’s path within the SPIE domain. However, it is likely that
independent ISPs may lack sufﬁcient levels of technical or political
cooperation to unite their SPIE infrastructure. Instead, many ISPs
will prefer to have their own STM responsible for all queries within
their network. In such a case, one ISP’s STM must be granted the
authority to issue queries to adjacent ISPs’ STMs in order to com-
plete the traceback.
In very rare cases, one may not wish to expose the content of a
packet yet still wish to employ SPIE. In such a case, it might be
possible to support call-backs from SCARs which would provide
the querying IDS with the applicable digesting function and trans-
formation information and ask it to do actual digesting. This is an
expensive operation, but the existence of such a case implies the
querying IDS has grave cause for concern in the ﬁrst place and is
likely willing to dedicate a great deal of resources to the traceback.
Finally, transformations raise several additional issues, some re-
lated to performance, others to policy. In particular, assuming that
packet transformations represent a small percentage of the overall
IP trafﬁc traversing a router, an efﬁcient SPIE implementation can
easily handle the resource requirements of logging transformation
information. Attackers, though, may view packet transformations
as a method of denial of service attack on SPIE. The number of
transformations that are recorded during a given time interval is
bounded by the rate at which the router is able to process the packet
transformations. Therefore, SPIE aims to handle packet transfor-
mations at a rate equal or greater than the router. As a result, the
router rather than SPIE is the bottleneck in processing packet trans-
formations. This task is made easier when one realizes that the vast
majority of transformations occur only at low-to-medium speed
routers. Sophisticated transformations such as tunneling, NATing,
and the like are typically done at customer premises equipment.
Further, many ISPs turn off standard transformation handing, often
even ICMP processing, at their core routers.
9 CONCLUSION & FUTURE WORK
Developing a traceback system that can trace a single packet has
long been viewed as impractical due to the tremendous storage re-
quirements of saving packet data and the increased eavesdropping
risks the packet logs posed. We believe that SPIE’s key contribu-
tion is to demonstrate that single packet tracing is feasible. SPIE
has low storage requirements and does not aid in eavesdropping.
Furthermore, SPIE is a complete, practical system. It deals with the
complex problem of transformations and can be implemented in
high-speed routers (often a problem for proposed tracing schemes).
The most pressing challenges for SPIE are increasing the window of
time in which a packet may be successfully traced and reducing the
amount of information that must be stored for transformation han-
dling. One possible way to extend the length of time queries can be
conducted without linearly increasing the memory requirements is
by relaxing the set of packets that can be traced. In particular, SPIE
can support traceback of large packet ﬂows for longer periods of
time in a fashion similar to probabilistic marking schemes—rather
than discard packet digests as they expire, discard them probabilis-
tically as they age. For large packet ﬂows, odds are quite high some
constituent packet will remain traceable for longer periods of time.
ACKNOWLEDGEMENTS
We are indebted to Walter Milliken for his assistance in ensuring
our architecture was implementable in today’s high-speed routers,
and for designing the initial DGA hardware prototype shown in ﬁg-
ure 8. David Karger ﬁrst pointed out we could generalize our hash-
ing technique through Bloom ﬁlters to decrease memory require-
ments, and Michael Mitzenmacher and Ron Rivest provided advice
on appropriate digesting functions. We thank Christine Alvarado,
David Andersen, John Jannotti, Allen Miu, and the anonymous re-
viewers for their feedback on earlier drafts.
References
[1] BAKER, F. Requirements for IP version 4 routers. RFC 1812, IETF,
June 1995.
[2] BELLOVIN, S. M.
Internet Draft,
IETF, Mar. 2000. draft-bellovin-itrace-05.txt (work in
progress).
ICMP traceback messages.
[3] BLACK, J., HALEVI, S., KRAWCZYK, J., KROVETZ, T., AND RO-
GAWAY, P. UMAC: fast and secure message authentication. In Proc.
Advances in Cryptology — CRYPTO ’99 (Aug. 1999), pp. 216–233.
[4] BLOOM, B. H. Space/time trade-offs in hash coding with allowable
errors. Communications of ACM 13, 7 (July 1970), 422–426.
[5] BURCH, H., AND CHESWICK, B. Tracing anonymous packets to their
approximate source. In Proc. USENIX LISA ’00 (Dec. 2000).
[6] CARTER, L., AND WEGMAN, M. Universal classes of hash functions.
Journal of Computer and System Sciences (1979), 143–154.
[7] DUFFIELD, N. G., AND GROSSGLAUSER, M. Trajectory sampling
In Proc. ACM SIGCOMM ’00 (Aug.
for direct trafﬁc observation.
2000), pp. 271–282.
[8] FAN, L., CAO, P., ALMEIDA, J., AND BRODER, A. Z. Summary
cache: a scalable wide-area web cache sharing protocol. ACM Trans.
on Networking 8, 3 (2000), 281–293.
[9] FERGUSON, P., AND SENIE, D. Network ingress ﬁltering: Defeating
denial of service attacks which employ IP source address spooﬁng.
RFC 2267, IETF, Jan. 1998.
[10] HALEVI, S., AND KRAWCZYK, H. MMH: Software message au-
thentication in the Gbit/second rates. In Proc. 4th Workshop on Fast
Software Encryption (1997), pp. 172–189.
[11] KRAWCZYK, H. LFSR-Based hashing and authentication. In Proc.
Advances in Cryptology — CRYPTO ’94 (Aug. 1994), pp. 129–139.
[12] MCCREARY, S., AND CLAFFY, K. Trends in wide area IP trafﬁc pat-
terns: A view from Ames Internet exchange. In ITC Specialist Semi-
nar on IP Trafﬁc Modeling, Measurement and Management (2000).
[13] MICROSOFT CORPORATION. Stop 0A in tcpip.sys when receiving
out of band (OOB) data. http://support.microsoft.com/
support/kb/articles/Q143/4/78.asp.
[14] NATIONAL LABORATORY FOR APPLIED NETWORK RESEARCH
http://
(NLANR). Network trafﬁc packet header traces.
moat.nlanr.net/Traces/Traces/20000720/FLA-
964095596.crl.enc.
[15] PAXSON, V. End-to-end internet path dynamics. ACM Trans. on
Networking 7, 3 (1999), 277–292.
[16] POSTEL, J. Internet Control Message Protocol. RFC 792, IETF, Sept.
1981.
[17] POSTEL, J. Internet Protocol. RFC 791, IETF, Sept. 1981.
[18] RIVEST, R. The MD5 message-digest algorithm. RFC 1321, IETF,
Apr. 1992.
[19] SAGER, G. Security fun with OCxmon and cﬂowd.
Internet 2
Working Group Meeting, Nov. 1998. http://www.caida.org/
projects/NGI/content/security/1198.
[20] SANCHEZ, L. A., MILLIKEN, W. C., SNOEREN, A. C., TCHAK-
OUNTIO, F., JONES, C. E., KENT, S. T., PARTRIDGE, C., AND
STRAYER, W. T. Hardware support for a hash-based IP traceback. In
Proc. Second DARPA Information Survivability Conference and Ex-
position (June 2001).
[21] SAVAGE, S., WETHERALL, D., KARLIN, A., AND ANDERSON, T.
Practical network support for IP traceback. In Proc. ACM SIGCOMM
’00 (Aug. 2000), pp. 295–306.
[22] SCHNACKENBERG, D., DJAHANDARI, K., AND STERNE, D. Infras-
tructure for intrusion detection and response. In Proc. First DARPA
Information Survivability Conference and Exposition (Jan. 2000).
[23] SONG, D. X., AND PERRIG, A. Advanced and authenticated marking
schemes for IP traceback. In Proc. IEEE Infocom ’01 (Apr. 2001).
[24] STONE, R. CenterTrack: An IP overlay network for tracking DoS
ﬂoods. In Proc. USENIX Security Symposium ’00 (Aug. 2000).
[25] WU, S. F., ZHANG, L., MASSEY, D., AND MANKIN, A. Intention-
driven ICMP trace-back. Internet Draft, IETF, Feb. 2001. draft-
wu-itrace-intention-00.txt (work in progress).