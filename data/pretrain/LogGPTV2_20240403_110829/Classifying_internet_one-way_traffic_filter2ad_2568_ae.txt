lists for analyzing present or future data.
5.4 Impact on Flow Classiﬁer
For ﬂow-based scan detection we use two sets of rules.
The ﬁrst set is based on scan detection algorithms pro-
viding strong evidence. The second set deﬁnes rules
that point towards scanning, but provide weaker ev-
idence. In particular, it includes ﬂows 1) towards un-
populated IP addresses or 2) that consist only of a single
packet and do not match any other rule. The validation
shows that the second rule set in fact is very useful for
scan detection, which led us to add this rule set to the
class “Malicious Scanning” eliminating an initially de-
ﬁned class “Suspicious Other”. In particular, 65.1% of
the ﬂows matching these rules are actually detected as
scanners when observing host behavior for an extended
time period.
Another change introduced during validation concerns
the assignment of ICMP ﬂows. We observe that 92.1%
of all ICMP ﬂows seen are sourced by identiﬁed scan-
ners. Without ICMP type/code information, it is diﬃ-
cult to satisfactorily distinguish backscatter ICMP ﬂows
from scanning. Consequently, we moved a rule initially
assigned to the class “Backscatter”, assuming ICMP
replies from DoS attacks, to the class “Malicious Scan-
ning”. Furthermore, we added the sign “InOut” that
helps to identify host pair communication situations in
which an ICMP ﬂow is a reply to an one-way ﬂow ex-
changed between the same host pair. We use this sign
in the class “Suspected Benign”.
6. ONE-WAY TRAFFIC COMPOSITION
In this section we apply our classiﬁcation scheme on a
massive dataset of ﬂows records collected between 2004
and 201 to shed light into the composition and charac-
teristics of one-way traﬃc.
Aggregate Statistics: We ﬁrst ﬁnd that in terms
of ﬂows one-way traﬃc is a very large component of In-
ternet traﬃc. During the studied period one-way ﬂows
correspond to between 34% and 67% of the total num-
ber of ﬂows towards the monitored network. This is
important for systems that need to keep per ﬂow state,
11
Figure 4: Composition of one-way traﬃc in ﬂow
counts per class.
like stateful ﬁrewalls and ﬂow meters. On the other
hand, due to their short-lived nature, one-way traﬃc
corresponds only to 3.4% and 0.79% of the total num-
ber of packets and bytes, respectively. This indicates
that IBR traﬃc is not a signiﬁcant problem in terms of
bandwidth consumption and packet overhead.
Figure 4 shows how one-way traﬃc breaks down into
diﬀerent classes in terms of ﬂows. In addition, Table 7
provides for each measurement period and class the
fraction of one-way traﬃc in terms of ﬂows and packets.
On average the class “Malicious Scanning” accounts
for 83.5% of all one-way ﬂows.
It is followed by the
classes “Benign P2P” (6.7%), “Service Unreachable”
(4.8%), “Suspected Benign” (2.6%), “Other” (2.2%),
“Backscatter” (0.3%) and “Bogon” (0.1%), where in
parentheses we show the average fraction of one-way
ﬂows per class over the eight year period. The packet
perspective provides a diﬀerent view. “Malicious Scan-
ning” accounts for 62.6% of all one-way packets, “Be-
nign P2P” for 13.0%, “Service Unreachable” for 10.1%,
“Suspected Benign” for 9.1%, “Other” for 4.7%, “Backscat-
ter” for 0.5%, and “Bogon” for 0.03%.
We observe that one-way traﬃc is clearly dominated
by scanning. In terms of packets, scanning accounts for
a smaller fraction of 62.6% of the total number of one-
way packets. This is because one-way ﬂows classiﬁed as
scanning consist on average of 1.6 packets per ﬂow. In
contrast, one-way ﬂows of the classes “Service Unreach-
able” and “Benign P2P” consist of 4.1 and 12.1 packets
per ﬂow, respectively. This diﬀerence is because TCP
one-way ﬂows to unreachable services are much more
persistent in SYN packet retransmission attempts than
TCP scanning. In addition, we ﬁnd that one-way ﬂows
in the class “Benign P2P” are often multi-packet UDP
ﬂows that sharply increase the average number of pack-
ets per ﬂow.
Changes Over Time: Besides, we observe a num-
ber of notable changes over time. In Figure 5 we com-
pare how the mean daily number of one- and two-way
ﬂows evolved between 2004 and 2011. The volume of
0e+001e+082e+083e+084e+08PeriodOne−Way Flows/24 h2004.012004.072005.012005.072006.022006.072007.012007.072008.022008.072009.012009.072010.012010.072011.012011.08 SuspBenign SrvUnreach other MalScan Bogon BenignP2P BackscatPeriod Malicious Scanning Backscatter Unreachable
4.8%/9.2%
2004-02
0.6%/1.3%
2004-08
2005-02
5.8%/12.1%
0.4%/0.7%
2005-08
0.6%/4.4%
2006-02
0.4%/0.3%
2006-08
1.7%/1.2%
2007-02
2007-08
2.2%/2.9%
2008-02
1.1%/1.9%
2008-08
2009-02
2009-08
2010-02
2010-08
2011-02
2011-08
Benign P2P
5.5%/10.3%
0.1%/0.2%
3.4%/9.8%
0.0%/0.1%
4.1%/9.1%
0.0%/0.1%
1.8%/4.3%
0.0%/0.1%
4.2%/9.9%
0.1%/0.2%
5.3%/4.1%
0.1%/0.0%
6.5%/7.1%
0.1%/0.1%
9.5%/17.6%
0.2%/0.2%
0.2%/0.2%
23.9%/49.4%
0.3%/0.4% 15.2%/26.3% 6.5%/11.4%
0.1%/0.0% 15.3%/25.3% 5.9%/11.1%
5.7%/10.2%
0.1%/0.1%
4.0%/7.7%
0.3%/0.2%
0.2%/0.2%
6.3%/12.5%
0.6%/1.2%
7.3%/18.7%
2.2%/4.3% 12.3%/46.7% 6.9%/15.1%
87.2%/57.9%
93.9%/82.0%
87.2%/65.6%
95.4%/74.7%
89.3%/71.8%
87.8%/47.3%
86.9%/83.6%
80.7%/63.5%
68.3%/34.4%
70.5%/47.8%
74.2%/55.7%
86.2%/75.2%
88.2%/77.5%
85.8%/74.3%
81.4%/61.5%
72.8%/28.3%
3.7%/6.0%
2.6%/5.1%
3.1%/4.7%
6.2%/12.9%
Suspected Benign
Bogon
Other
1.1%/3.7%
1.0%/4.1%
1.8%/10.5%
1.5%/5.3%
3.3%/10.2%
3.2%/46.9%
2.8%/6.2%
3.5%/10.3%
3.0%/10.4%
3.2%/8.5%
2.7%/5.6%
2.3%/5.2%
2.9%/5.9%
2.6%/5.5%
2.6%/3.5%
3.7%/4.3%
0.1%/0.1% 1.1%/18.7%
0.0%/0.0% 1.0%/2.7%
0.0%/0.0% 1.0%/2.7%
0.3%/0.1% 0.7%/14.9%
0.2%/0.1% 2.3%/3.5%
0.0%/0.0% 3.1%/1.4%
0.0%/0.0% 2.0%/1.8%
0.2%/0.1% 3.7%/5.5%
0.0%/0.0% 3.5%/3.7%
0.0%/0.0% 4.4%/5.5%
0.0%/0.0% 1.8%/2.3%
0.0%/0.0% 2.0%/3.3%
0.1%/0.0% 2.0%/3.5%
0.0%/0.0% 1.9%/2.7%
0.0%/0.0% 1.9%/2.3%
0.0%/0.0% 2.0%/1.4%
Table 7: Fraction of ﬂows/packets falling into the deﬁned one-way ﬂow classes. The class Other
represents the remainder of ﬂows not captured by the other classes. Note, that we do not list rules
that achieve a low coverage eliminating the ﬂow artifacts class that results from fragmented packets
without layer-4 header.
swered NTP requests towards an NTP server. Investi-
gating further this incident, we found that the increased
number of requests pushed the operator to introduce
access restrictions to this server. As we analyze more
in the next section, this class of one-way ﬂows is very
useful to administrators to monitor the reachability of
services. The peak in benign P2P one-way traﬃc be-
tween Aug. 2007 and Feb. 2008 can be attributed to
two IP addresses that are reported to be fake servers by
the eMule Bulletin Board. Fake eMule servers are com-
monly used to collect eMule user data for research or
legal prosecution. Minor contributors to this class are
XBSlink traﬃc sourced by Xbox 360 and PS2/3 game
equipment, and the MMORPG (massively multiplayer
online role-playing game) Heroes of Might and Magic.
7. SERVICE REACHABILITY
MONITORING
In this section, we leverage one-way ﬂows of the class
“Service Unreachable” to demonstrate a new approach
to monitor local services and detect reachability prob-
lems. Traditionally, the availability of local network
services within an enterprise, a data center, or a uni-
versity network is monitored using active probing tools
or server logs. In contrast, we exploit traﬃc ﬂow data
and our classiﬁcation scheme to monitor local services
from the network. Our approach has the following key
advantages: 1) It provides a tangible assessment of the
impact of disruptions by enabling to count the actual
number of remote client IP addresses that fail to reach
a service; 2) It exploits passive measurements in contrast
to injecting network overhead for active probing; 3) It
automatically discovers running local services circum-
venting the need to manually conﬁgure (new) services;
4) It enables to concurrently monitor many services by
taking advantage of data from the strategical network
location of gateways.
In the next paragraphs, we ﬁrst outline our analysis
methodology and secondly we discuss interesting mis-
conﬁgurations and outages we detected in the campus
Figure 5: Evolution of one and two-way mean
daily ﬂow counts over time. The vertical bars
mark 95% conﬁdence intervals.
one-way ﬂows has exhibited small ﬂuctuations between
2004 and 2011 and, interestingly, in 2011 it is almost
equal to 2004. On the other hand, the number of two-
way ﬂows has grown signiﬁcantly by 343%. A study by
Akamai estimated the global Internet penetration in-
crease in 2010 as 17% [1]. If we extrapolate this ﬁgure
over eight years, it yields a growth by 351%, which is
very close to our observations. Besides, we observe that
the fraction of one-way ﬂows has dropped over time. In
2004 one-way ﬂows accounted for 67% of the total num-
ber of ﬂows. Their share gradually dropped and since
2007 one-way ﬂows account consistently for one out of
three incoming ﬂows.
The fraction of “Malicious Scanning” ﬂows varies,
started at a high of 87.2% in 2004 and stayed at this
or a higher level until 2006. Then, in 2007 we note
a decline that leads to a low of 68.3% in Aug. 2008.
This decline correlates with an increase of the class
P2P one-way traﬃc that falls early into the same pe-
riod and also an increase of class “Unreachable” later
on. The high counts in class “Service Unreachable”
between Aug. 2008 and Feb. 2009 are caused by unan-
12
PeriodMean Flows/24 h'4.2'5.2'6.2'7.2'8.2'9.2'0.2'1.20e+004e+068e+06Inbound One−WayTwo−WayInbound One−WayTwo−Waynetwork of ETH Zurich by applying our scheme on one
week of data.
7.1 Methodology
Using one-way ﬂows classiﬁed with our scheme in
the class “Service Unreachable” as well as bidirectional
ﬂows as input, we compute the following three metrics
to evaluate the reachability of local services within the
network of ETH Zurich. We focus on services running
on well-known port numbers.
We deﬁne the availability of a service as the number of
time intervals a service is alive, i.e., it has bidirectional
ﬂows, over the number of intervals it is either alive or
unresponsive, i.e., it has only incoming one-way ﬂows.
We ignore intervals in which a service does not have
any incoming ﬂows. The availability metric helps group
services into permanently and temporarily oﬀered ones.
Available services are not necessarily reachable to all
clients due to access policies, misconﬁgurations, or other
reachability problems. We deﬁne the reachability of a
service as the number of distinct client IP addresses
with bidirectional ﬂows to the service over the total
number of distinct client IP addresses to the service
during a time interval. The reachability metric is use-
ful for identifying misconﬁgurations and outages.
Finally, the outage impact of a service is the number
of unique client IP addresses that are involved in one-
way ﬂows of the class “Service Unreachable” during a
time interval. As several clients can be behind a remote
NAT, this metric provides a lower bound on the actual
number of clients that are aﬀected by an outage and is
useful for assessing the impact of failures.
7.2 Outages and Misconﬁgurations
In this section we demonstrate the utility of one-way
ﬂows detected with our classiﬁcation scheme for analyz-
ing service reachability problems.
We applied our scheme on a randomly-selected week
of NetFlow data from our archive and initially focused
on services discovered within the address range of the
Department of Information Technology and Electrical
Engineering of ETH Zurich. We discovered services as
2-tuples {localIP, localP ort} with a well-known port
number that had more than 20 unique clients during
any time interval. As with bi-ﬂow pairing, we used a
10-minute time interval. We discovered in total 43 re-
motely accessible departmental services for which we
computed our three metrics. To validate our observa-
tions, we met and discussed with the network adminis-
trators of our department providing them details about
the availability, reachability, and outages of the services.
The administrators conﬁrmed the validity of the discov-
ered services and provided feedback on a number of in-
teresting outages we summarize in the next paragraphs.
We identiﬁed a group of 32 services available at least
99% of the time and 11 services that either fail very of-
ten or are not operated all the time. For all frequently
used services we found a coinciding global outage on the
23rd of June 2011 starting at approximately 19:40 UTC