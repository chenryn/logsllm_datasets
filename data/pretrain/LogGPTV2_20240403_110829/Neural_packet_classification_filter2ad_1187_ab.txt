(cid:2)
2.2 Decision Tree Algorithms
Packet classification is similar to the point location problem in a
multi-dimensional geometric space: the fields in the packet header
we are doing classification on (e.g., source and destination IP ad-
dresses, source and destination port numbers, and protocol num-
ber) represent the dimensions in the geometric space, a packet is
represented as a point in this space, and a rule as a hypercube.
Unfortunately, the point location problem exhibits a hard tradeoff
between time and space complexities [14].
The packet classification problem is then equivalent to finding
all hypercubes that contains the point corresponding to a given
packet. In particular, in a d-dimensional geometric space with n
non-overlapping hypercubes and when d > 3, this problem has
either (i) a lower bound of O(loд n) time and O(nd ) space, or (ii) a
lower bound of O(loдd −1n) time and O(n) space [14]. The packet
classification problem allows the hypercubes (i.e., rules) to overlap,
and thus is at least as hard as the point location problem [14]. In
other words, if we want logarithmic computation time, we need
space that is exponential in the number of dimensions (fields), and
if we want linear space, the computation time will be exponential
in the logarithm of the number of rules. Given that for packet
classification d = 5, neither of these choices is attractive.
Next, we discuss two common techniques employed by exist-
ing solutions to build decision trees for packet classification: node
cutting and rule partition.
Node cutting. Most existing solutions for packet classification aim
to build a decision tree that exhibits low classification time (i.e.,
time complexity) and memory footprint (i.e., space complexity) [55].
The main idea is to split nodes in the decision tree by “cutting”
them along one or more dimensions. Starting from the root which
contains all rules, these algorithms iteratively split/cut the nodes
until each leaf contains fewer than a predefined number of rules.
Given a decision tree, classifying a packet reduces to walk the tree
from the root to a leaf, and then chose the highest priority rule
associated with that leaf.
Figure 2 illustrates this technique. The packet classifier contains
six rules (R0 to R5) in a two-dimensional space. Figure 2(a) shows
each rule as a rectangle in the space, and represents the cuts as
dashed lines. Figure 2(b) shows the corresponding decision tree
for this packet classifier. The root of the tree contains all the six
rules. First, we cut the entire space (which represents the root) into
four chunks along dimension x. This leads to the creation of four
children. If a rule intersects a child’s chunk, it is added to that child.
(cid:13)(cid:6)
(cid:13)(cid:8)
(cid:13)(cid:6)(cid:4) (cid:13)(cid:8)(cid:4)
(cid:13)(cid:9)(cid:4)(cid:1)(cid:13)(cid:11)
(cid:13)(cid:11)
(cid:13)(cid:9)
(cid:13)(cid:6)
(cid:13)(cid:8)
(cid:13)(cid:11)
(cid:2)
(cid:13)(cid:9)
(cid:1)
(cid:1)
(cid:13)(cid:7)
(cid:13)(cid:10)
(cid:2)(cid:14)(cid:3)(cid:1)(cid:12)(cid:14)(cid:19)(cid:20)(cid:16)(cid:20)(cid:16)(cid:18)(cid:17)(cid:1)(cid:7)(cid:5)
(cid:13)(cid:7)(cid:4)(cid:1)(cid:13)(cid:10)
(cid:13)(cid:7)
(cid:13)(cid:10)
(cid:2)(cid:15)(cid:3)(cid:1)(cid:12)(cid:14)(cid:19)(cid:20)(cid:16)(cid:20)(cid:16)(cid:18)(cid:17)(cid:1)(cid:8)(cid:5)
Figure 3: Rule partition.
For example, R1, R3 and R4 all intersect the first chunk (i.e., the
first quarter in this space), and thus they are all added to the first
root’s child. If a rule intersects multiple chunks it is added to each
corresponding child, e.g., R1 is added to all the four children. Next,
we cut the chunk corresponding to each of the four children along
dimension y. As a result, each of the nodes at the first level will end
up with two children.
Rule partition. One challenge with "blindly" cutting a node is that
we might end up with a rule being replicated to a large number
of nodes [55]. In particular, if a rule has a large size along one
dimension, cutting along that dimension will result in that rule
being added to many nodes. For example, rule R1 in Figure 2(a) has
a large size in dimension x. Thus, when cutting along dimension
x, R1 will end up being replicated at every node created by the
cut. Rule replication can lead to decision trees with larger depths
and sizes, which translate to higher classification time and memory
footprint.
One solution to address this challenge is to first partition rules
based on their "shapes". Broadly speaking, rules with large sizes
in a particular dimension are put in the same set. Then, we can
build a separate decision tree for each of these partitions. Figure 3
illustrates this technique. The six rules in Figure 2 are grouped into
two partitions. One partition consists of rules R1 and R4, as both
these rules have large sizes in dimension x. The other partition
consists of the other four rules, as these rules have small sizes in
dimension x. Figure 3(a) and Figure 3(b) show the corresponding
decision trees for each partition. Note that the resulting trees have
lower depth, and smaller number of rules per node as compared
to the original decision tree in Figure 2(b). To classify a packet, we
classify it against every decision tree, and then choose the highest
priority rule among all rules the packet matches in all decision
trees.
Summary. Existing solutions build decision trees by employing
two types of actions: node cutting and rule partition. These solu-
tions mainly differ in the way they decide (i) at which node to apply
the action, (ii) which action to apply, and (iii) how to apply it (e.g.,
along which dimension(s) to partition).
258
SIGCOMM ’19, August 19–23, 2019, Beijing, China
Eric Liang, Hang Zhu, Xin Jin, and Ion Stoica
3 A LEARNING-BASED APPROACH
In this section, we describe a learning-based approach for packet
classification. We motivate our approach, discuss the formulation of
classification as a learning problem, and then present our solution.
3.1 Why Learn?
The existing solutions for packet classification rely on hand-tuned
heuristics to build decision trees. Unfortunately, this leads to two
major limitations.
First, these heuristics often face a difficult trade-off between per-
formance and cost. Tuning such a heuristic for a given set of rules is
an expensive proposition, requiring considerable human efforts
and expertise. Worse yet, when given a different rule set, one
might have to do this all over again. Addressing this challenge
has been the main driver of a long line of research over the past
two decades [13, 29, 40, 47, 55]. Of course, one could build a gen-
eral heuristic for a large variety of rule sets. Unfortunately, such a
solution would not provide the best performance for a given set of
rules.
Second, existing algorithms do not directly optimize for a global
objective. Ideally, a good packet classification solution should op-
timize for (i) classification time, (ii) memory footprint, or (iii) a
combination between the two. Unfortunately, the existing heuris-
tics do not directly optimize for any of these objectives. At their
core, these heuristics make greedy decisions to build decision trees.
At every step, they decide on whether to cut a node or partition the
rules based on simple statistics (e.g., the size of the rules in each
dimension, number of unique ranges in each dimension), which are
poorly correlated with the desired objective. As such, the resulting
decision trees are often far from being optimal.
As we will see, a learning-based approach can address these
limitations. Such an approach can learn to generate an efficient
decision tree for a specific set of rules without the need to rely
on hand-tuned heuristics. This is not to say these heuristics do
not have value; in fact they often contain key domain knowledge
that we show can be leveraged and improved on by the learning
algorithm.
3.2 What to Learn?
Classification is a central task in machine learning literature. The
recent success of using deep neural networks (DNNs) for image
recognition, speech recognition and language translation has been
single-handedly responsible for the recent AI "revolution" [10, 22,
51].
As such, one natural solution for packet classification would be
to replace a decision tree with a DNN. In particular, such DNN
will take as input the fields of a packet header and output the
rule matching that packet. Related to our problem, prior work has
shown that DNN models can be effectively used to replace B-Trees
for indexing [21].
However, this solution has two drawbacks. First, a DNN-based
classifier does not guarantee 100% accuracy. This is because training
a DNN is fundamentally a stochastic process. Second, given a DNN
packet classification result, it is expensive to verify whether the
result is correct or not. Unlike the recently proposed learned index
solution to replace B-Trees [21], the rules in packet classification are
(cid:6)(cid:7)(cid:15)(cid:10)(cid:12)(cid:11)
(cid:3)(cid:15)
(cid:2)(cid:7)(cid:11)(cid:5)(cid:9)(cid:8)(cid:7)(cid:6)(cid:3)(cid:7)(cid:10)
(cid:4)(cid:15)(cid:1)(cid:2)
(cid:5)(cid:15)(cid:1)(cid:2)
(cid:2)(cid:7)(cid:11)(cid:5)(cid:9)(cid:8)(cid:7)(cid:6)(cid:3)(cid:7)(cid:10)
(cid:8)(cid:12)(cid:13)(cid:18)(cid:15)(cid:24)(cid:1)(cid:5)(cid:19)(cid:12)(cid:23)(cid:23)(cid:17)(cid:16)(cid:17)(cid:15)(cid:22)
(cid:6)(cid:15)(cid:13)(cid:17)(cid:23)(cid:17)(cid:21)(cid:20)(cid:1)(cid:11)(cid:22)(cid:15)(cid:15)
(cid:12)(cid:13)(cid:24)(cid:17)(cid:21)(cid:20)
(cid:4)(cid:24)
(cid:9)(cid:24)(cid:2)(cid:3)
(cid:10)(cid:24)(cid:2)(cid:3)
(cid:1)(cid:4)(cid:3)(cid:7)(cid:10)
(cid:14)(cid:15)(cid:6)(cid:15)(cid:9)
(cid:5)(cid:15)
(cid:13)(cid:9)(cid:16)(cid:6)(cid:13)(cid:8)
(cid:4)(cid:15)
(cid:1)(cid:4)(cid:3)(cid:7)(cid:10)
(cid:7)(cid:15)(cid:25)(cid:22)(cid:12)(cid:19)(cid:1)(cid:7)(cid:15)(cid:24)(cid:26)(cid:21)(cid:22)(cid:18)
(cid:10)(cid:24)(cid:12)(cid:24)(cid:15)
(cid:23)(cid:24)(cid:12)(cid:24)(cid:15)
(cid:10)(cid:24)
(cid:22)(cid:15)(cid:26)(cid:12)(cid:22)(cid:14)
(cid:9)(cid:24)
(a)
(b)
Figure 4: (a) Classic RL system. An agent takes an action, At ,
based on the current state of the environment, St , and ap-
plies it to the environment. This leads to a change in the
environment state (St +1) and a reward (Rt +1). (b) NeuroCuts
as an RL system.
multi-dimensional and overlap with each other. If a rule matches a
packet, we still need to check other rules to see if this rule has the
highest priority among all matched rules.
To avoid these drawbacks, in this paper we propose to learn
building decision trees for a given set of rules. Since the result is
still a decision tree, we can guarantee correctness, and it will be
easy to deploy the classifier with existing systems (hardware and
software) compared to a DNN.
3.3 How to Learn?
In this section, we show that the problem of building decision trees
maps naturally to RL. As illustrated in Figure 4(a), an RL system
consists of an agent that repeatedly interacts with an environment.
The agent observes the state of the environment, and then takes an
action that might change the environment’s state. The goal of the
agent is to compute a policy that maps the environment’s state to
an action in order to optimize a reward. As an example, consider an
agent playing chess. In this case, the environment is the board, the
state is the position of the pieces on the board, an action is moving
a piece on the board, and the reward could be 1 if the game is won,
and −1, if the game is lost.
This simple example illustrates two characteristics of RL that are
a particularly good fit to our problem. First, rewards are sparse, i.e.,
not every state has associated a reward. For instance, when moving
a piece we do not necessary know whether that move will result
259
Neural Packet Classification
SIGCOMM ’19, August 19–23, 2019, Beijing, China
in a win or loss. Second, the rewards are delayed; we need to wait
until the end of the game to see whether the game was won or lost.
To deal with large state and action spaces, recent RL solutions
have employed DNNs to implement their policies. These solu-
tions, called Deep RL, have achieved remarkable results matching
humans at playing Atari games [36], and beating the Go world
champion [46]. These results have encouraged researchers to ap-
ply Deep RL to networking and systems problems, from rout-
ing, to congestion control, to video streaming, and to job schedul-
ing [4, 6, 16, 33, 34, 54, 62, 64, 65]. Building a decision tree can be
easily cast as an RL problem: the environment’s state is the current
decision tree, an action is either cutting a node or partitioning a set
of rules, and the reward is either the classification time, memory
footprint, or a combination of the two. While in some cases there
are legitimate concerns about whether Deep RL is the right solution
for the problem at hand, we identify several characteristics that
make packet classification a particularly good fit for Deep RL.
First, when we take an action, we do not know for sure whether it
will lead to a good decision tree or not; we only know this once the
tree is built. As a result, the rewards in our problem are both sparse
and delayed. This is naturally captured by the RL formulation.
Second, the explicit goal of RL is to maximize the reward. Thus,
unlike existing heuristics, our RL solution aims to explicitly opti-
mize the performance objective, rather than using local statistics
whose correlation to the performance objective can be tenuous.
Third, one potential concern with Deep RL algorithms is sample
complexity. In general, these algorithms require a huge number of
samples (i.e., input examples) to learn a good policy. Fortunately,
in the case of packet classification we can generate such samples
cheaply. A sample, or rollout, is a sequence of actions that builds a
decision tree with the associated reward(s) by using a given policy.
The reason we can generate these rollouts cheaply is because we
can build all these trees in software, and do so in parallel. Contrast
this with other RL-domains, such as robotics, where generating
each rollout can take a long time and requires expensive equipment
(i.e., robots).
4 NEUROCUTS DESIGN
4.1 NeuroCuts Overview
We introduce the design for NeuroCuts, a new Deep RL formula-
tion of the packet classification problem. Given a rule set and an
objective function (i.e., classification time, memory footprint, or
a combination of both), NeuroCuts learns to build a decision tree
that minimizes the objective.
Figure 4(b) illustrates the framing of NeuroCuts as an RL system:
the environment consists of the set of rules and the current decision
tree, while the agent uses a model (implemented by a DNN) that
aims to select the best cut or partition action to incrementally build
the tree. A cut action divides a node along a chosen dimension
(i.e., one of SrcIP, DstIP, SrcPort, DstPort, and Protocol) into
a number of sub-ranges (i.e., 2, 4, 8, 16, or 32 ranges), and creates
that many child nodes in the tree. A partition action on the other
hand divides the rules of a node into disjoint subsets (e.g., based
on the coverage fraction of a dimension), and creates a new child
node for each subset. The available actions for the current node
are advertised by the environment at each step, the agent chooses
among them to generate the tree, and over time the agent learns to
optimize its decisions to maximize the reward from the environment.
Figure 5 visualizes the learning process of NeuroCuts.
4.2 NeuroCuts Training Algorithm
Recall that the goal of an RL algorithm is to compute a policy