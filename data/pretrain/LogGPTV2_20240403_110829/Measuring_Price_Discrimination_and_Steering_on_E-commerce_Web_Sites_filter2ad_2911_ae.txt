### Overview of Academic Literature on Personalization Implementation and Measurement

#### Improving Personalization
Personalizing search results to enhance Information Retrieval (IR) accuracy has been extensively studied [33, 42]. While click histories are commonly used for personalization, other features such as geolocation [2, 53, 54] and demographics (inferred from search and browsing histories) [18, 47] have also been explored. To our knowledge, only one study has investigated privacy-preserving personalized search [52]. Dou et al. provide a comprehensive overview of techniques for personalizing search [12]. Several studies have focused on improving personalization in other systems, including targeted web ads [16, 49], news aggregators [9, 24], and discriminatory pricing on travel search engines [15].

#### Comparing Search Results
Training and comparing IR systems require the ability to compare ranked lists of search results. Metrics for comparing ranked lists are an active area of research in the IR community. Classical metrics such as Spearman’s footrule and ρ [11, 38] and Kendall’s τ [22] measure pairwise disagreement between ordered lists. Some studies have improved upon Kendall’s τ by adding per-rank weights [14, 40] and by considering item similarity [21, 39]. DCG and nDCG use a logarithmic scale to reduce the scores of lower-ranked items [19].

#### The Filter Bubble
Eli Pariser, an activist, brought widespread attention to the potential for web personalization to lead to harmful social outcomes, a problem he termed "The Internet Filter Bubble" [31]. This has motivated researchers to measure the personalization present in deployed systems, such as web search engines [17, 27, 50] and recommender systems [4].

#### Exploiting Personalization
Recent work has shown that it is possible to exploit personalization algorithms for nefarious purposes. Xing et al. [51] demonstrated that repeatedly clicking on specific search results can cause search engines to rank those results higher. An attacker can exploit this to promote specific results to targeted users. Therefore, understanding the presence and extent of personalization can help in assessing the potential impact of these attacks on e-commerce sites.

#### Personalization in E-commerce
Two recent studies by Mikians et al. [29, 30] on personalization in e-commerce sites inspired our work. The first study examined price steering (referred to as search discrimination) and price discrimination across multiple sites using fake user profiles. The second paper extended the first by leveraging crowdsourced workers to detect price discrimination. The authors identified several e-commerce sites that personalize content, mostly based on geolocation. We improve upon these studies by introducing duplicated control accounts into all our measurements, which are necessary to differentiate inherent noise from actual personalization.

### Concluding Discussion
Personalization has become a crucial feature of many web services. However, there is growing evidence that e-commerce sites are using personalization algorithms to implement price steering and discrimination. In this paper, we build a measurement infrastructure to study price discrimination and steering on 16 top online retailers and travel websites. Our method places great emphasis on controlling for various sources of noise to ensure that the differences we observe are due to personalization algorithms and not just noise.

First, we collected real-world data from 300 Amazon Mechanical Turk (AMT) users to determine the extent of personalization they experience. This data revealed evidence of personalization on four general retailers and five travel sites, including cases where sites altered prices by hundreds of dollars.

Second, we conducted controlled experiments to investigate the features that e-commerce personalization algorithms consider when shaping content. We found cases where sites alter results based on the user's OS/browser, account on the site, and history of clicked/purchased products. We also observed two travel sites conducting A/B tests that steer users towards more expensive hotel reservations.

### Comments from Companies
We reached out to six companies identified in this study as implementing some form of personalization (Orbitz and Cheaptickets are run by a single company, as are Expedia and Hotels.com) for comments on a pre-publication draft of this manuscript. We received responses from Orbitz and Expedia. The Vice President for Corporate Affairs at Orbitz confirmed that Cheaptickets and Orbitz offer members-only deals on hotels but took issue with our characterization of price discrimination as "anti-consumer." We removed these assertions from the final draft. The Orbitz representative kindly agreed to allow us to publish their letter on the Web [7].

We also spoke on the phone with the Chief Product Officer and the Senior Director of Stats Optimization at Expedia. They confirmed our findings that Expedia and Hotels.com perform extensive A/B testing on users. However, they claimed that Expedia does not implement price discrimination on rental cars and could not explain our results to the contrary (see Figure 3).

### Scope and Incompleteness
In this study, we focus on U.S. e-commerce sites. All queries were made from IP addresses in the U.S., and all retailers and searches were in English. Real-world data was collected from U.S. users. We leave the examination of personalization on e-commerce sites in other countries and languages for future work.

Due to our methodology, we can only identify positive instances of price discrimination and steering; we cannot claim the absence of personalization, as we may not have considered all dimensions along which e-commerce sites might personalize content. For example, we observed personalization in some AMT results (e.g., on Newegg and Sears) that we cannot explain with our feature-based experiments. These effects might be explained by measuring the impact of other features such as geolocation, HTTP Referer, browsing history, or purchase history. Given the generality of our methodology, it would be straightforward to apply it to these additional features and other e-commerce sites.

### Open Source
All of our experiments were conducted in the spring of 2014. Although our results are representative for this time period, they may not hold in the future as sites may change their personalization algorithms. We encourage other researchers to repeat our measurements by making all of our crawling and parsing code, as well as the raw data from § 4 and § 5, available to the research community at http://personalization.ccs.neu.edu/.

### Acknowledgements
We thank the anonymous reviewers and our shepherd, Vijay Erramilli, for their helpful comments. This research was supported in part by NSF grants CNS-1054233 and CHS-1408345, ARO grant W911NF-12-1-0556, and an Amazon Web Services in Education grant.

### References
[References listed here]

This version of the text is more structured, clear, and professional, with improved transitions and a more coherent flow.