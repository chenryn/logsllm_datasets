 1000
Input Rate (Kpps)
Figure 4: 68-byte packet forwarding/stamping performance.
surements by averaging three runs of prkm forwarding 1,000,000
packets spaced 16 µs apart. For tests in which packet size affected
performance, we benchmarked forwarding of 68-byte, 348-byte,
and 1500-byte packets (including IP and Platypus headers, but ex-
cluding Ethernet headers), which correspond to minimum, mod-
erate, and maximum packet sizes. Packets arrive at prkm’s packet
handler from the Linux ip local deliver routine which is tasked
with passing packets to the appropriate protocol handler. Packet
processing includes time to parse the packet headers, verify the
binding, and update Platypus headers. Destination cache lookup
includes retrieval of a dst entry structure, and IP header build-
ing and veriﬁcation includes time to place a new IP header on the
packet. Finally, packet transmission time includes time until the
packet is queued for transmission by the device. While the valida-
tion time is highly dependent upon packet size, it is less than other
overheads even for large packets. In the worst case, binding valida-
tion adds less than two µs to forwarding latency.
6.2 Waypoint granularity
We now consider the impact of waypoint granularity on the ef-
fectiveness of Platypus-like source routing. Clearly, the ﬁner the
waypoint granularity, the more control Platypus can assert over
a packet’s path. Intuitively, however, intra-AS trafﬁc engineering
goals are likely best met by exporting only coarse-grained way-
points to external entities. While we lack sufﬁcient information
(such as actual AS topologies with trafﬁc matrices) to address the
trafﬁc engineering issues, we attempt in this section to provide
some insight into the level of granularity necessary to effectively
impact a speciﬁc end-to-end path characteristic.
We consider clustering the routers into groups which could be
represented by a single Platypus waypoint. In particular, we study
the impact on end-to-end one-way path latency of routing indirectly
through a waypoint of varying granularity. Previous research in-
dicates that it is often possible to achieve signiﬁcant performance
improvements by inserting one level of indirection in a packet’s
route [4, 31]. However, for deployment reasons, we would like to
know how well chosen an indirection point must be to provide sub-
stantial beneﬁt. Thus, we consider how the best achievable path
latency increases as waypoint granularity is reduced. Intuitively,
since POPs represent a collection of routers in a region, and net-
works are dense near large cities and sparse elsewhere, similarly
performing routers can be naturally clustered together. It may be
sufﬁcient to place Platypus routers in only a few locations, as speed
 180
 160
 140
 120
 100
 80
 60
 40
 20
UCSD-Lulea
UCSD-Lulea opt
UCSD-KAIST
UCSD-KAIST opt
Coloco-Lulea 
Coloco-Lulea  opt
UCSD-Nortel 
UCSD-Nortel  opt
 180
 160
 140
 120
 100
 80
 60
 40
 20
)
s
m
(
y
c
n
e
a
L
t
UCSD-Lulea
UCSD-Lulea opt
UCSD-KAIST
UCSD-KAIST opt
Coloco-Lulea 
Coloco-Lulea  opt
UCSD-Nortel 
UCSD-Nortel  opt
 0
 2
 4
 8
 16
 32
 64
# of clusters
 128
 256
 512
 1024
 0
 2
 4
 8
 16
 32
 64
# of clusters
 128
 256
 512
 1024
(a) Global Crossing (1072 interfaces).
(b) Sprint (1401 interfaces).
 180
 160
 140
 120
 100
 80
 60
 40
 20
UCSD-Lulea
UCSD-Lulea opt
UCSD-KAIST
UCSD-KAIST opt
Coloco-Lulea 
Coloco-Lulea  opt
UCSD-Nortel 
UCSD-Nortel  opt
 180
 160
 140
 120
 100
 80
 60
 40
 20
)
s
m
(
y
c
n
e
t
a
L
UCSD-Lulea
UCSD-Lulea opt
UCSD-KAIST
UCSD-KAIST opt
Coloco-Lulea 
Coloco-Lulea  opt
UCSD-Nortel 
UCSD-Nortel  opt
)
s
m
(
y
c
n
e
a
L
t
)
s
m
(
y
c
n
e
t
a
L
 0
 2
 4
 8
 16
 32
 64
# of clusters
 128
 256
 512
 1024
 0
 2
 4
 8
 16
 32
 64
# of clusters
 128
 256
 512
 1024
(c) Qwest (2022 interfaces).
(d) UUNet (8591 interfaces).
Figure 5: Impact of cluster size on indirection effectiveness. For each ISP, we vary the number of clusters generated based
upon observed latencies between the two speciﬁed measurement points and every known router interface. For each indicated
source/destination pair, we plot the measured one-way path latency using the ISP’s optimal indirection router (opt) against the
calculated path latency through the center of the optimal cluster. Data points represent averages; ten different clusterings were
generated for each k-means input size. Error bars show the standard deviation.
of light delays comprise most of the delay seen by packets in un-
congested wide-area backbones. Thus, multiple, local waypoints
would not signiﬁcantly affect latency (but, conversely, might be
useful for load balancing, for example). Note that we are not ar-
guing that path latency is the most important metric of interest,
nor that improving path latency is the best application of Platypus.
Rather, we claim only that latency is a relatively easily measured
and well-understood path property that provides initial insight.
We begin by considering the router IP addresses reported by
the Skitter project [9] for four major international ISPs: UUNet,
Sprint, Qwest, and Global Crossing. We then selected ﬁve geo-
graphically diverse monitoring locations in the RON testbed [4],
UC San Diego, Nortel (Nepean, Ontario, Canada), Coloco (Laurel,
Maryland), Lulea (Sweden), and KAIST (Korea). From each mon-
itoring location, we used ICMP timestamp probes to measure both
the forward and reverse path latencies for each known router inter-
face of the ISP in question [23]. This set of measurements was col-
lected over a period of six days between January 22–27, 2004. We
obtained approximately 240 measurements for each location/router
pair and use the mean value. With this data, we compute a one-
way, indirect end-to-end path delay between any two monitoring
locations through each router interface.
To study the utility of various waypoint granularities, we gen-
erated different sized router clusters based upon the observed path
latencies. We then calculated the end-to-end path latency between
each pair of observation points using the router closest to center
of the optimal cluster as the indirection point and compared this
to the latency through the optimal router interface (which may or
may not be a member of the optimal cluster). Figure 5 shows the
results for each of the four ISPs studied. As expected, the more
clusters (corresponding to a ﬁner waypoint granularity), the closer
the performance of the optimal cluster comes to performance of the
optimal router. Somewhat surprisingly, however, the best cluster
centers approach the optimal at a relatively small number of clus-
ters even for UUNet, an extremely large ISP. These results indicate
that a small number of indirection points are likely sufﬁcient for
substantial beneﬁt; this applies equally to Platypus and any overlay
or source-routing system. How waypoint granularity affects other
metrics remains an open question for future work, but the low num-
ber of clusters required to achieve near-optimal latencies give rea-
son for optimism.
We note in parting that the clusters we used are unlikely to re-
sult in the best performance, or even necessarily make operational
sense, so we expect that intelligent placement would require even
fewer waypoints than our results indicate. We obtained our clus-
ters by running the k-means [22] clustering algorithm over the la-
tencies observed from the Coloco and Lulea measurement points.
Each k-means run was given an argument n representing the de-
sired number of clusters; during the run, the algorithm selected n
clusters randomly and proceeded to improve or discard the clusters.
By adjusting n we could vary the number of clusters requested, but
had no control over the exact number of clusters generated or which
routers would be clustered together. As such, we consider these re-
sults as an upper bound of achievable cluster-path latency.
7. DISCUSSION
Platypus represents one approach to capability-based source rout-
ing. During its design, we have considered issues of performance,
security, accounting, and the effect of source-routed trafﬁc upon the
network. In this section we discuss these considerations.
7.1 Route setup
In its current incarnation, Platypus represents an extreme in terms
of routing ﬂexibility: each packet can be routed independently. A
less radical approach observes that it is often the case that packets
are part of a larger series of packets, or ﬂow. Further, existing trans-
port protocols like TCP are typically more effective when all pack-
ets experience similar path characteristics. Hence, all packets in a
ﬂow should generally be directed along the same route. It would
sufﬁce, then, to specify the desired route once per ﬂow. Implement-
ing such an RSVP-like scheme is tricky, however, as packets must
be labeled as belonging to the same ﬂow, initial packets in the ﬂow
could be lost, routers may reboot and lose ﬂow state, etc. Neverthe-
less, existing hardware is extremely efﬁcient at switching packets
along previously conﬁgured routes. Hence, we are interested in de-
veloping ways for Platypus routers to cache forwarding directives
for trafﬁc ﬂows. In particular, we are optimistic that we can harness
the existing MPLS [29] label swapping support in deployed routers
to implement a great deal of the Platypus forwarding functionality.
By decoupling veriﬁcation from forwarding, and ofﬂoading the ini-
tial veriﬁcation and path setup to a dedicated Platypus router, it may
be possible to switch Platypus packets using MPLS while retaining
many of the features of our initial design.
7.2 Distributed accounting
While Platypus speciﬁes a resource principal per capability, we
have yet to discuss how accounting would actually be implemented.
Fine-grained ﬂow accounting is an established problem in other
contexts, but Platypus complicates the use of several common ap-
proaches. For example, many end hosts receive ﬂat-rate pricing for
their Internet service. ISPs can provide this service with bounded
risk because the rate at which an end host can inject packets into the
network is limited by the capacity of its access link. More sophis-
ticated pricing plans may depend on the actual utilization, which
requires the ISP to meter a customer’s trafﬁc, but such metering
can be done at the customer’s access link.
In Platypus, however, a customer may authorize third parties to
inject packets into its ISP as part of a source route. Any accounting
scheme that only charges customers for packets that traverse their
access link clearly will not properly account for the customer’s ad-
ditional use. A straightforward approach would maintain counters
for each resource principal at all Platypus routers within an AS, and
bill for the total consumption. While auditing challenges may dis-