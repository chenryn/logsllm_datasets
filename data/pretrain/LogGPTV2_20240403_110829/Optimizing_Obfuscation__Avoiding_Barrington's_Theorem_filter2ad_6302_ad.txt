(cid:48)
so in the second step, we describe how to randomize the RMBP using the procedure randBP
,
such that the resulting (equivalent) RMBP when restricted to any particular input x can be
simulated by just knowing the output of the RMBP on x.
We ﬁrst describe the randBP procedure. Though the procedure randBP to randomize our
matrices is similar in spirit to Kilian’s randomization (also used in [28, 4]), the way we will
simulate these matrices will deviate from that of Kilian.
Notation. We will denote the relaxed matrix branching program as
BP = (inp1, inp2, {Bi,b1,b2}i∈[n],b1,b2∈{0,1}) with length n, width w and input of (cid:96) bits. For any
x ∈ {0, 1}(cid:96), deﬁne Px :=
Bi,xinp1(i),xinp2(i) and,
n(cid:81)
i=1
(cid:12)(cid:12)(cid:12)x
BP
:= (Bi,xinp1(i),xinp2(i))i∈[n]
Let e1, ew ∈ {0, 1}w, be such that e1 = (1, 0, 0, . . . , 0) and ew = (0, 0, . . . , 0, 1). For notational
convenience, let e1 be a row vector and ew we a column vector.
Procedure randBP. The input to the randomization procedure is an oblivious dual-input
RMBP BP = (inp1, inp2, {Bi,b1,b2}i∈[n],b1,b2∈{0,1}) of length n, width w and input of (cid:96) bits.
Procedure randBP(BP):
- Pick n + 1 random full-rank matrices R0, . . . , Rn ∈ Zw×w
.
p
8Recall that the restriction of a relaxed matrix branching program BP = (inp1, inp2,{Bi,b1,b2}i∈[n],b1,b2∈{0,1}) is
deﬁned to be {Bi,xinp1(i),xinp2(i)}.
14
(cid:16)
and ˜t = Rn · ew.
for all i ∈ [n] and b1, b2 ∈ {0, 1}.
inp1, inp2, ˜s,(cid:8) ˜Bi,b1,b2
- Compute the matrices ˜Bi,b1,b2 = Ri−1 · Bi,b1,b2 · R−1
- Output (cid:102)BP =
- Finally, compute ˜s = e1 · R−1
level, the theorem states that the matrices in (cid:102)BP (which is the output of randBP on BP) when
It follows that the branching program output by the above procedure on input BP is functionally
equivalent to BP.
We can construct a simulator SimBP such that the following theorem holds. At a high
i∈[n],b1,b2∈{0,1}, ˜t
(cid:17)
(cid:9)
0
.
i
restricted to a particular input x can be simulated by just knowing the (1, w)th entry in the
product matrix obtained by evaluating BP on input x.
Theorem 4. Consider an oblivious dual-input RMBP BP = (inp1, inp2, {Bi,b1,b2}i∈[n],b1,b2∈{0,1})
of length n, of width w and input of (cid:96) bits. Then for every x ∈ {0, 1}(cid:96),
(cid:111)
(cid:110)
(cid:111) ≡ (cid:110)
(cid:12)(cid:12)(cid:12)x
(cid:12)(cid:12)(cid:12)x
randBP(BP)
SimBP(1n, 1w, 1(cid:96), Px[1, w])
.
Proof. We ﬁrst describe the simulator SimBP which simulates the output of randBP for any input
be deﬁned as (˜s, { ˜Bi,xinp1(i),xinp2(i)}i∈[n], ˜t). We describe a
x. More formally, let randBP(BP)
simulator SimBP which takes as input
(1n, 1w, 1(cid:96), Px[1, w]) and outputs a tuple which is identically distributed to randBP(BP)
that s is the size of the formula.
Theorem 5. ([38]) Consider a dual-input branching program BP =(cid:8)inp1, inp2, {Bi,b1,b2}i∈[n],b1,b2∈{0,1}(cid:9).
Before we describe SimBP we will ﬁrst recall the following theorem.
(cid:12)(cid:12)(cid:12)x
. Recall
There exists a PPT simulator SimK such that for every x ∈ {0, 1}l,
{R0,{Ri−1Bi,xinp1(i),xinp2(i) R−1
i }i∈[n], Rn} ≡ SimK(1n, 1w, 1(cid:96), BP(x))
We are now ready to describe SimBP.
SimBP(1n, 1w, 1(cid:96), Px[1, w]):
- If Px[1, w] (cid:54)= 0, deﬁne the matrix A as A := Px[1, w] · Iw×w. Else, A := “mirror-image” of
Iw×w.
- Run SimK(1n, A) to obtain full-rank matrices
R0, R1, . . . , Rn+1 ∈ Zw×w
p
deﬁned in Theorem 5.
- Let ˆR0 = e1 · R−1
- Output ( ˆR0, R1, . . . , Rn, ˆRn+1).
i≥0 Ri = A. Note that SimK is the simulator as
such that (cid:81)
and ˆRn+1 = Rn+1 · ew.
0
We now show that:
randBP(BP)
SimBP(1s, Px[1, w])
.
(cid:110)
(cid:111) ≡ (cid:110)
(cid:12)(cid:12)(cid:12)x
(cid:111)
As a ﬁrst step, we state the following lemma from Cramer et al. [23] that will be useful to prove
the theorem.
Lemma 6. For any x, y ∈ Zw
there exist full rank
matrices X, Y ∈ (Zp)n×n such that the ﬁrst row of X is xT , the ﬁrst column of Y is y, and
XM Y depends only on xT M y.
In particular, there is a procedure Extend, running in time
polynomial in n and w, that takes as input (xT M y, x, y, M ), where x, y and M are as deﬁned
in the above lemma and outputs X and Y such that XM Y is (xT M y) · Iw×w if xT M y (cid:54)= 0 else
it is “mirror-image” of I. 9
p \{0} and a full rank matrix M ∈ Zw×w
p
9The “mirror-image” of a w × w identity matrix is also a w × w matrix such that the (i, w − i + 1)th entry in the
matrix is 1 and the rest of the entries in the matrix are 0.
15
We now proceed to proving that the output distributions of randBP and SimBP are identical.
We ﬁrst deﬁne a sequence of hybrids such that the ﬁrst hybrid is the real experiment (which
is randBP) while the last hybrid is the simulated experiment (which is SimBP). Then, we show
that the output distribution of each hybrid is identical to the output distribution of the previous
hybrid which will prove the theorem.
Hybrid0: This is the same as the real experiment. That is, on input BP and x it ﬁrst executes
(cid:12)(cid:12)(cid:12)x
randBP(BP) to obtain (cid:102)BP. It then outputs (cid:102)BP
Hybrid1: We describe Hybrid1 as follows. The input to Hybrid1 is (cid:99)BP = BP(cid:12)(cid:12)x = (Bi,xinp1 (i),xinp2 (i))i∈[n].
= (˜s,{ ˜Bi,xinp1(i),xinp2(i)}i∈[n], ˜t)
Let Mi = Bi,xinp1(i),xinp2(i).
(cid:16)(cid:99)BP = (M1, . . . , Mn)
(cid:17)
Hybrid1
:
- Pick n + 1 random full-rank matrices R0, . . . , Rn ∈ Zw×w
- Compute the matrices ˜Mi = Ri−1 · Mi · R−1
for i ∈ [n].
- Finally, compute ˜s = e1 · R−1
- Output
and ˜t = Rn · ew.
˜s,{ ˜Mi}i∈[n], ˜t
(cid:16)
(cid:17)
p
0
.
i
.
It can be seen that the output distribution of this hybrid is identical to the output distribution
of the previous hybrid Hybrid0.
Hybrid2: Hybrid2 is same as Hybrid1 except the way we compute ˜s and ˜t. The input to Hybrid2,
like the previous hybrid, is (cid:99)BP = BP(cid:12)(cid:12)x.
(cid:16)(cid:99)BP = (M1, . . . , Mn)
(cid:17)
Hybrid2
:
- Pick n + 1 random full-rank matrices R0, . . . , Rn ∈ Zw×w
- Compute the matrices ˜Mi = Ri−1 · Mi · R−1
for i ∈ [n].
p
.
i
n(cid:81)
Mi and c := e1 · P · ew.
i=1
- Deﬁne P :=
- Execute Extend on input (c, e1, ew, P ) to obtain w × w matrices S and T as described in
Lemma 6. Compute ˆS = SR−1
- Output (˜s,{ ˜Mi}i∈[n], ˜t).
and ˆT = RnT . Finally, compute ˜s = e1 ˆS and ˜t = ˆT ew.
0
Hybrid1 and Hybrid2 diﬀer only in the way ˜s and ˜t are computed.
e1 · (SR−1
e1 and hence, ˜s = e1·R−1
In Hybrid2, ˜s = e1 ˆS =
0 , where x is the ﬁrst row of S. But the ﬁrst row of S is
0 , which is same as the value in Hybrid1. Similarly, we can show this for ˜t.
0 ) = (e1 · S) · R−1
0 = xT · R−1
Hybrid3: This is same as the simulated experiment. That is, it takes as input (1n, 1w, 1(cid:96))
and Px[1, w] and then executes SimBP(1n, 1w, 1(cid:96), Px[1, w]). The output of Hybrid3 is the output
of SimBP.
We now argue that Hybrid2 and Hybrid3 are identically distributed. First note that in Hybrid2,
c = P [1, w]. Then it follows from Lemma 6 that if c (cid:54)= 0, S · P · T = c· I, else S · P · T = J, where
J is the “mirror-image” of I. Theorem 5 can be used to show that hybrids Hybrid2 and Hybrid3
are identically distributed. This shows that the output distribution of Hybrid0 is identically
distributed to Hybrid3. This completes the proof.
16
We now move to the second step where we show how to randomize the branching program using
in such a way that the product of the matrices (which will be a 1 × 1
(cid:48)
the procedure randBP
matrix) corresponding to an input only reveals the output of the function and nothing else. To
achieve this, we need to ensure that the product of the matrices corresponding to one input is
not correlated to the product of matrices corresponding to a diﬀerent input, where both the
inputs are such that they evaluate to 1. We solve this by multiplying the matrix Bi,b1,b2 by
αi,b1,b2 (which is picked at random). This ensures that multiplying the matrices corresponding
to two diﬀerent inputs result in two diﬀerent products of α’s which are mutually independent
which in turn makes it feasible to achieve simulation of these matrices by just knowing the value
(cid:48)
of the function. We now describe the procedure randBP
which is the output of randBP on the relaxed matrix branching program BP. s
Proceduce randBP(cid:48).
In this procedure, we describe how to further randomize the output
of randBP and then show how to simulate this by having just the output of BP. The input to
(cid:48)
((cid:102)BP):
randBP
is a randomized relaxed matrix branching program (cid:102)BP = (˜s,{ ˜Bi,b1,b2}i∈[n],b1,b2∈{0,1}, ˜t).
takes as input (cid:102)BP
(cid:48)
Procedure randBP
(cid:48)
. Note that randBP
- It picks random and independent non-zero scalars {αi,b1,b2 ∈ Zp}i∈[n],b1,b2∈{0,1} and com-
putes Ci,b1,b2 = αi,b1,b2 · ˜Bi,b1,b2. It outputs (˜s,{Ci,b1,b2}i∈[n],b1,b2∈{0,1}, ˜t).
i Ni)[1, w].
((cid:81)
Claim 3. If ((cid:81)
Proof. Since c = ((cid:81)
((cid:81)
(cid:48)
Before we describe how to simulate the output of randBP
, we will prove a claim about
this procedure. Let M1, M2, . . . , Mn be a given set of matrices. Let (N1, . . . , Nn) be the out-
(cid:48)
put of randBP
(M1, M2, . . . , Mn). We have that N1 = α1M1, N2 = α2M2, . . . , Nn = αnMn,
where α1, α2, . . . , αn are non-zero scalars chosen uniformly at random from Zp. Deﬁne c =
i Mi) [1, w] (cid:54)= 0, then c is distributed uniformly in Z∗
p.
i Ni)[1, w] = ((cid:81)
i αiMi)[1, w] = ((cid:81)
p, (cid:81)
i αi) ((cid:81)
i αi is distributed uniformly in Z∗
i Mi) [1, w]. Since each αi is
p. Hence, when
chosen uniformly at random from Z∗
i Mi) [1, w] (cid:54)= 0, c is distributed uniformly in Z∗
p.
Simulator Sim(cid:48)
where s is the size of the formula and x ∈ {0, 1}(cid:96).