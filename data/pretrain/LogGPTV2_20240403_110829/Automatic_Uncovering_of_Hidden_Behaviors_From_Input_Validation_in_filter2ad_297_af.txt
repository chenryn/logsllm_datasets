com.**.q**** (cid:35) (cid:35) (cid:35) (cid:32) (cid:32) (cid:32) (cid:35) (cid:35) (cid:32) (cid:35) (cid:32) (cid:35) (cid:32) (cid:35) (cid:32) (cid:32) (cid:32) (cid:35) (cid:32) (cid:32) (cid:32) (cid:32) (cid:35) (cid:32) (cid:35)
com.a*.***** (cid:35) (cid:32) (cid:35) (cid:32) (cid:35) (cid:32) (cid:35) (cid:35) (cid:35) (cid:35) (cid:32) (cid:35) (cid:32) (cid:35) (cid:32) (cid:32) (cid:32) (cid:35) (cid:32) (cid:32) (cid:35) (cid:35) (cid:35) (cid:35) (cid:32)
(cid:35) (cid:35) (cid:32) (cid:32) (cid:35) (cid:32) (cid:32) (cid:35) (cid:35) (cid:35) (cid:32) (cid:35) (cid:32) (cid:35) (cid:32) (cid:32) (cid:35) (cid:32) (cid:32) (cid:32) (cid:32) (cid:35) (cid:35) (cid:35) (cid:35)
(cid:32) (cid:35) (cid:32) (cid:32) (cid:32) (cid:32) (cid:35) (cid:32) (cid:32) (cid:35) (cid:32) (cid:35) (cid:32) (cid:35) (cid:32) (cid:32) (cid:35) (cid:35) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32)
Education
Education
Social
Shopping
Entertainment
Productivity
Entertainment
Social
Entertainment
Education
com.*.t****
com.y*.t****
com.i**i**
com.j*.s****
y**.E**n**
7
7
8
11
8
11
6
7
8
6
19
9
20
Statistics
1
11 11
8
8
11 10 13
8
5
8
7
TABLE IX: Fine-grained results of blacklist for top tested apps: (cid:32) for presence, and (cid:35) for absence.
categories than Korean and English blacklists. More
details will be presented in the following analysis.
Fine-grained Micro Results. After understanding the content
of blacklist at the aggregated macro level, we then zoom into
each blacklist to understand them at ﬁne-grained micro-level.
We created a best-effort classiﬁcation of their content into 9
semantic categories including drug, cult, fraud, gambling, in-
sult, password, politics, pornography, and website. In addition,
we also list the recognized 25 micro-level types of content
for each semantic category in Table VIII. Note that we only
present the micro-level classiﬁcation of the keywords of the
blacklist instead of the exact words at Table IX, given their
inappropriate content and large size.
• Commonly blocked content in three languages. We
can observe that all blacklists in three languages ﬁlter
keywords in the category of insult and pornography, ac-
cording to Table IX. In particular, in the category of insult,
there are 20 blacklists that ﬁlter keywords related to the
concept of obscenity, 19 blacklists (except one blacklist in
Chinese) that also block keywords used for bullying, and 9
blacklists that ﬁlter expressions related to racial discrimi-
nation; three contain only English keywords, three contain
only Chinese words, and three blacklists contain content
in both of these languages. Meanwhile, in the category
of pornography, there is one blacklist containing both
English and Korean content, four blacklists containing
English and Chinese words, as well as two English
exclusive blacklists and 7 Chinese exclusive blacklists
that block keywords related to escort services. Finally,
there are 7 Chinese-exclusive and 4 Chinese and English
combined blacklists that block adult video.
• Uniquely blocked content in each speciﬁc language.
Besides the commonly blocked content, we noticed one
English blacklist containing items that we classify as weak
passwords, while no blacklist in the other two languages
ﬁlters such passwords. As for blacklist content in Korean,
ﬁrst, we did not witness a blacklist containing Korean
content exclusively, and second, blacklists with Korean
content in our dataset block no unique content other than
porn and insults. However, we did ﬁnd blacklists con-
sisting of Chinese keywords covering 6 unique semantic
categories (i.e., drug, cult, fraud, gamble, politic, and
website) with 19 micro-level types deﬁned in Table VIII.
in the drug category, 8 blacklists block
Speciﬁcally,
keywords relating to hallucinogens, 7 blacklists ﬁlter ad-
dictive drug, and also 7 blacklists forbid content related to
aphrodisiacs. In the category of cult, we have 11 blacklists
that disallow cult name and 8 disallow mentioning malig-
nant event. As for the category of politics, keywords relat-
ing to leader names, mass incidents, and slogans for sep-
aratism are blocked by all Chinese blacklists. In addition,
there are also 8 blacklists that forbid words from the rebel
and parade categories. Interestingly, only Chinese black-
lists try to ﬁlter information about fraud and gambling.
In particular, 11 of them block content for forging fake
certiﬁcates, and 6 of them disallow advertisements about
multi-level marketing (MLM) organizations. For gam-
bling, keywords related to lottery are blocked by 8 black-
lists, names of chess & card games are disallowed by 7
blacklists, and information about Hong Kong Jockey (an
organization that allows betting on horse racing and other
sports) is also forbidden in 6 blacklists. Finally, there are
8 blacklists that disallow sharing the URL of websites
whose content includes supporting anti-government and
showing pornography, 7 also forbid criminal websites,
and 5 ﬁlter websites disseminating fake news.
From these results, we can make several
interesting
observations. First, a keyword might be forbidden on one
platform but would be accepted on another platform, even if
these platforms intend to ﬁlter the same semantic category
of words. For example,
there are 9 platforms that block
words related to racial discrimination, while the other 11
won’t, even though all platforms in this study try to ﬁlter
insult expressions. Second, Chinese blacklists cover many
more semantic categories than the blacklists consists of
11
other two languages. Besides ﬁltering keywords in semantic
categories such as politic, cult, and gamble that could be a
result of political or law enforcement reasons, they also try
to exclude content that might cause damage to people’s lives,
e.g., drug,
fraud, and criminal website. Moreover, another
interesting observation is that mobile apps may use blacklist-
based methods to validate weak passwords, though we only
encountered one such case in our manual investigation.
From a security perspective, blacklist identiﬁcation and
extraction has two beneﬁts. First, developers may have an
interest in preventing abuse and harassment on their platforms,
and may be unaware that client-side enforcement is ineffective
at providing this capability. Second, users may be unaware that
an app is limiting their freedom of expression, and exposing
types of content being ﬁltered can help them make more
informed choices about what platforms they participate in.
VI. DISCUSSION
A. Accuracy of Secrets Uncovering
INPUTSCOPE relies on static analysis with a set of security
policies to identify a variety of secrets that can trigger hidden
behaviors within an app. To better understand these behaviors
and evaluate the accuracy of our secret uncovering policies,
we manually analyzed the top popular apps. More speciﬁcally,
we ﬁrst decompiled each app and inspected its code to identify
whether the secret values we discovered can actually trigger
actions (e.g., invoking methods). If so, then we moved on to
understand the purpose of this action by reading the code as
well as ﬁnding the correct way to navigate the app and try
to trigger the action for dynamic veriﬁcation. Among the total
number of 70 apps we have manually analyzed with our best
effort and understanding, we have identiﬁed 1 misclassiﬁcation
and 8 false positives, resulting an accuracy of 87.14%.
In particular, a false positive in this study refers to an
extracted value that (i) cannot trigger actions, (ii) triggers
behaviors that can be achieved by normal operations, or (iii)
where the triggered action is benign even though it cannot be
triggered normally. In our manual analysis, we have identiﬁed
8 false positive cases where 6 of them are ﬂagged as backdoor
secrets of access keys and 2 as secret commands. Speciﬁcally,
three false positives occur because the identiﬁed values will not
trigger actions in practice because of conﬂicting constraints
along the execution path; the other three false positives are
caused by misclassifying benign behavior: two cases where the
values are used for benign “Easter eggs”, and one where they
are used to provide (benign) special location-based services.
The remaining two false positives were both identiﬁed as
hidden commands: the identiﬁed commands for one app are
a set of shortcuts for normal operations, and the other one
uses hidden commands to change UI rendering. In addition,
we also noticed 1 misclassiﬁcation case where a set of secret
commands has been ﬂagged as blacklist secrets.
B. Limitations and Future Work
In the following, we discuss limitations and future chal-
lenges to improve the accuracy of the analysis performed by
INPUTSCOPE:
• The ﬁrst challenge for INPUTSCOPE is supporting the
WebView component. Mobile apps using the WebView
• The second challenge for
component may rely on JavaScript routines to collect and
validate user inputs. As INPUTSCOPE currently operates
at the Java bytecode level only, it may not be able to
analyze these apps and unveil potential hidden behaviors.
INPUTSCOPE is handling
custom-deﬁned string operations. INPUTSCOPE currently
relies on the system API functions for string comparison.
However, apps may use customized or third-party string
comparison operations, and INPUTSCOPE will not be able
to identify them.
• The third challenge for INPUTSCOPE is when apps val-
idate user input via database queries, e.g., SQL queries.
Extracting the execution context of data ﬂows crossing
the boundaries of the database API requires inferring the
semantics of both queries and the database structure. Such
a challenge has been partly solved only when additional
artifacts, e.g., initialization scripts, are found in the code
[18]. However, this is not necessarily the case in the mo-
bile app setting, and it requires a more general solution.
from our manual
classiﬁcation of the blacklists, which may result in mis-
classiﬁcations caused by our unfamiliarity with the topics
and the language gap. In future work, we hope to perform
a deeper analysis of these blacklists with a broader
diversity of researchers from different backgrounds.
• The
INPUTSCOPE has false positives for various
reasons such as ignoring path constraints and failing to
distinguish “benign” cases. We plan to address these
issues by combining other techniques such as symbolic
execution to prune impossible paths and machine learning
to infer developers’ real intention.
fourth
challenge
comes
• Finally,
C. Why Hidden Behaviors Exist and How to Address Them
INPUTSCOPE has uncovered a number of serious security
issues from user-input validation implementations. In the fol-
lowing, we analyze their root causes and provide practical
solutions accordingly.
Misplaced the Trust in Untrusted Client Software. IN-
PUTSCOPE has identiﬁed 7,584 apps containing secret ac-
cess keys to trigger various hidden logic, such as bypassing
payment. Our ﬁndings suggest that, to date, developers still
wrongly assume that reversing the code of their apps for
inspection is not a real threat. Accordingly, developers tend
to implement high privilege interfaces in the mobile apps,
mistakenly trusting untrusted client apps. To really secure their
apps, developers need to perform security-relevant user-input
validations on the backend servers. When enforcing server-side
checks is not feasible, then developers should consider using
trusted hardware components available on modern mobile
devices (e.g., TrustZone).
Removing Debugging Code Before Releasing the Software.
INPUTSCOPE has also discovered thousands of apps containing
debugging features. These features need to be removed before
deploying a mobile app in the store or in the device ﬁrmware.
In fact, motivated users can reverse engineer the code of
the apps to discover these hidden interfaces. One use of IN-
PUTSCOPE is to raise developer awareness and demonstrate the
reverse engineering process can be fully automated. Therefore,
our recommendation is to always remove unnecessary code,
including debugging mode code, prior to software release.
12
Defending against our Secret-uncovering Analysis. We
have demonstrated that with INPUTSCOPE a variety of app
secrets can be discovered. In certain cases, there may be a
need to protect these secrets against our analysis. For instance,
an app may consider its blacklist a secret, and developers
cannot use the trusted server or TrustZone to perform the input
validations, e.g., client-side blacklist ﬁltering is inevitable in
time-sensitive services such as live-streaming media. To defeat
our analysis, there could be a number of possible avenues.
For instance, an app can use obfuscation, or implement secret
input validation in the native code, or dynamically load the
secrets from remote servers to thwart our secret discovery.
However, we note that many of these countermeasures could
themselves be bypassed with additional implementation effort.
D. Ethics and Responsible Disclosure
We have taken ethical considerations seriously in every step
of our research. First, we only validated the vulnerabilities on
our own accounts and our own smartphones (during our deep
case studies), and we never try to compromise other users’
accounts and smartphones. Second, we did not intentionally
manipulate or send forged requests to test the security mech-
anisms on the server-side.
The hidden functionality that INPUTSCOPE has identiﬁed
can have severe consequences to either app users or devel-
opers, and these apps need to be patched by app developers.
Therefore, we have contacted developers for each manually
veriﬁed app to disclose our ﬁndings. Our disclosure process
includes two steps: ﬁrst we used the contact information left
in the related market to ask for the correct contact information
to disclose vulnerabilities, and then we disclosed the details to
the correct security contact. For those vulnerable apps that
have not yet been patched at the time of this writing, we
redacted their package names as well as their secret values
with the symbol “***”, in order to avoid negative impacts (e.g.,
economic hardship from disclosure of advertisement removal
keys). We will continue to engage with the app developers to
offer help with our best efforts.
VII. RELATED WORK
Static Taint Analysis. Our approach is based on static analysis
to detect the user input validation behaviors within a given
mobile app by tracking the user input data ﬂows and their
related operations. In the past several years, there have been
many efforts that use static analysis for vulnerability discovery
by tracking sensitive data ﬂows in mobile apps. For instance,
Flowdroid [7] and Amandroid [38] are generic approaches
to track security-related data ﬂows. WARDroid [27], Ex-
tractocol [16], and SmartGen [45] focus more on the data
ﬂow related to network communications. PlayDrone [36] and
LeakScope [46] extract hard-coded secret keys that are used
by apps to retrieve cloud-based services. Inspired by this work,
INPUTSCOPE tracks only local user input through EditText