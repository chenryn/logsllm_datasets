of b.
Then the computation also leads to same yi in step 4.
The state is therefore updated with an xi of the same order
relation and the same yi. Hence, the induction holds for
i + 1.
Clearly, Lemma 3 holds for i = 0, since we start with the
same initial state.
In summary, our encryption algorithm outputs the same
values yi and performs the same update operations in both
cases of b. Therefore, any adversary Adv can at best guess
the value b′.
3.4.1 Insertion Order
As shown our OPE scheme is ideal-secure, but it does leak
additional information to the order. Namely, when observ-
ing the encryption at the database, i.e. the values yi, one
can determine a partial order of insertion. Our encryption
scheme forms a binary search tree. The lowest bit set in
the ciphertext marks the height of its position within tree
(if M is a power of 2). The lower the height, the later the
element has been inserted. Of course, the adversary cannot
determine the insertion order between elements of the same
height. Therefore it remains a partial order.
First, we do not consider this leakage to be problematic in
the use with encrypted databases. Determining the time of
compromise in an encrypted database is excruciatingly diﬃ-
cult and therefore the worst-case that the database is always
compromised is assumed. Under this worst-case assumption,
the adversary obtains the insertion order anyway – even in
case of the same-time indistinguishability deﬁnition of Popa
et al. [32].
Second, the IND-OCPA deﬁnition cannot account for the
insertion order, since – as in any other chosen plaintext at-
tack – the adversary controls this insertion order. It is there-
fore known to the adversary. Hence, it is not surprising that
our scheme still can fulﬁll this strict security deﬁnition.
3.4.2 Domain Coverage
The security of order-preserving encryption relies on the
assumption that the plaintext values only sparsely populate
their domain. If all values in a domain are encrypted, order-
preserving encryption is completely insecure – even if ideal-
secure. The ideal-secure order-preserving encryption of the
values from 1 to n is 1 to n, i.e. plaintexts and ciphertexts are
identical. While not yet quantiﬁed, it is always important to
keep this observation in mind when using order-preserving
encryption.
Clearly, this assumption is violated when encrypting auto-
increment counters. The order-preserving encryption of an
auto-increment counter – often used as identiﬁers and for-
eign keys in databases – is the counter itself. It therefore
should not be order-preserving encrypted at all.
This also alleviates the problem that auto-increment coun-
ters incur the maximum encryption cost in our scheme. They
result in the maximum number of update operations possi-
ble, since they follow the worst-case schedule of encryptions.
Yet, since they are not to be encrypted at all (for security
reasons), they do not represent a problem (for performance
reasons).
3.5 Theoretical Performance Analysis
We need to consider the best case, the average case and
the worst case complexity of our algorithm. For the average
case we assume a uniform distribution of the input.
First, we deﬁne a cost model for our algorithms. Local
operations on the client can be implemented eﬃciently –
even for large plaintext sets –, since there are no complex
(cryptographic) computations, such as modular exponentia-
tions or bilinear maps. Instead all computations are simple
arithmetic and simple data structure lookups, but update
operations on the database are costly. We therefore mainly
consider the cost of inserting one element into the database.
Since communication is the main cost, we count the byte size
of interaction between the database server and the client as
the cost of one insertion. Also the number of rounds is im-
portant and our scheme always requires 1 round per insert
whereas Popa et al.’s scheme requires O(log n), but since the
size of communication in our case is signiﬁcantly larger in
case of an update we use this as the cost for fair comparison.
In our experiments we also vary the delay of the network in
order to investigate the importance of rounds.
Second, we determine the complexity of the basic algo-
rithms. If encryption proceeds without update, then we only
need to send the new ciphertext to the database: cost O(1),
i.e. Algorithm 1 has cost O(1), if steps 3.1 to 3.4 are not
executed. A single update operation has cost O(n), since
we need to update all elements so far, i.e. Algorithm 2 has
cost O(n). We now need to determine the probability of an
update in the best, average and worst case.
Theorem 4. In the best case our algorithms incur cost
O(n) in communication with the database server. This is
also the theoretical lower bound.
Proof. The best case is when all elements of a perfectly
balanced binary search tree are inserted in pre-order traver-
sal order.
In this best case we never need to perform an
update, since the result is also a perfectly balanced binary
search tree. Hence, for n elements we have cost nO(1) =
O(n). This also the lower bound, because we need to send
each of the n elements at least once.
The worst case is also easy to analyze.
Theorem 5. In the worst case our algorithms incur cost
O(n2/ log n) in communication with the database server.
Proof. As already pointed out in Section 3.4.2, the worst
case adversarial schedule of ordered plaintext inserts results
in an update operation roughly all O(log M ) elements. As
we will later show, we choose M = O(n) and such that
M > 2N , i.e. there is always at least log N ciphertext space
to be ﬁlled before an update operation. Therefore the worst
case cost is n/O(log n) · O(n) = O(n2/ log n).
Next, we analyze the average case performance under uni-
form input distribution.
Theorem 6. If the ciphertext domain M > 2λN , then in
the average case under uniform input distribution our algo-
rithms incur cost O(n) in communication with the database
server.
Proof. For analyzing the average case complexity we re-
sort to the result of Reed [34]. As already noted, we observe
that our ciphertexts form a binary search tree. The ﬁrst
plaintext element inserted is the root (the center cipher-
text). Subsequent plaintexts are placed to the left or right
depending on their order relation. Reed investigated the
distribution of heights of binary search trees. We restate his
main theorem (Theorem 1 in [34]).
Theorem 7. Let Hn be the height of a random binary
search tree of n nodes. Then, E[Hn] = 4.31107 · · · ln n −
1.95302 · · · ln ln n + O(1) and V ar[Hn] = O(1).
Note that the maximum length of a ciphertext directly
corresponds to the height of the tree. This implies for our
encryption scheme that – on average – a ciphertext space
O(log n) will be suﬃcient. Furthermore, since the variance
is constant, it will be suﬃcient with high probability.
We therefore propose to use a value of M = O(n). Fur-
thermore, we need to reduce the update probability P r[U pd].
The average complexity for all insertions is n(1+P r[U pd]O(n)).
Only for P r[U pd] ≤ O(1/n) we achieve O(n) overall average
complexity. We can use Lemma 7 of [34].
Lemma 8. Let Xn,h be the (random) set of nodes at depth
h. Then, there is a (universal) constant C2 > 2 such that,
for i > 0, we have P r[Xn,E[Hn]+i 6= ∅] < C22−i/2.
This means that the probability of encountering a cipher-
text with length longer than the expected value decreases
exponentially with the length of the ciphertext. Hence, if
we add a buﬀer of at least 2 log n bits to the ciphertext
length, then the probability of exceeding that buﬀer is at
most O(1/n). This accomplishes the probability of an up-
date P r[U pd] ≤ O(1/n).
In summary, for a plaintext space of N = 2l we recom-
mend a ciphertext space of λl bits, i.e. M = 2λl. The ex-
pected average case complexity of inserting n elements is
then O(n). Clearly, λ ≥ 4.31107 + 2 is safe, but we evaluate
the choice of λ in our experiments.
4. ENCRYPTED DATABASES
We investigate our encryption algorithms as part of an
encrypted, in-memory, column-store database. This has a
couple of design implications we highlight in this section.
Column-store databases, such as [12, 36, 43] show excel-
lent performance for analytical workloads. For this they
store the data column-wise instead of row-wise. All data
for a single column can such be accessed and processed very
quickly. The speed of processing can be enhanced further if
the data is stored in main memory.
A common compression technique is order-preserving dic-
tionary compression [4, 7]. In dictionary compression data
values are replaced by data identiﬁers and in a dictionary
their relation is stored. A dictionary is order-preserving,
if the order relation of the data identiﬁers is the same as
the order relation of the data values. Dictionary compres-
sion usually achieves compression rates of a factor around
20 [30].
Order-preserving dictionaries have the advantage that se-
lect operations – even for range queries – can be performed
without accessing the dictionary. The database operator
is fed with the data identiﬁer (or data identiﬁers for range
queries) to select and can then process the column. Any
select operation that needs to lookup the dictionary can be
very costly.
Also update or insert operations can be very costly. They
often need to recompute the entire column of data. This
may also involve some further compression operations [4,
44].
The crucial insight is that the order-preserving dictionary
is an ideal-secure order-preserving encryption. The database
performs this operation automatically for us, although not
as an encryption operation. It therefore becomes a crucial
design decision for an encrypted database how to integrate
with this dictionary.
One approach is to strip the dictionary of the data values
and keep those at the client. This has been proposed by
Hildenbrand et al. in [17]. On the one hand this achieves
ideal-security for the order-preserving encryption, since the
database only learns the data identiﬁers. On the other hand
this prevents all operations that require access to the data
values, such as aggregation which is a very common opera-
tion in analytical work loads.
Another approach is to encrypt the data values in the
dictionary. This has been proposed by Popa et al. in [32].
It also achieves ideal-security on the database, but requires
O(n log n) cost for inserting n elements, since each element
needs to be sorted into the dictionary. When using homo-
morphic encryption [29] this can also achieve aggregation.
A disadvantage of both approaches is that the database
always needs to be encrypted in only order-preserving en-
cryption. Order-preserving encryption may leak more infor-
mation than is necessary for the queries performed. In [33]
Popa et al. introduce the concept of adjustable encryption.
Encryption is layered from order-preserving on the inner-
most layer over deterministic encryption to randomized en-
cryption on the outermost layer. Depending on the opera-
tion performed one or more layers of encryption are removed
before executing the operator. This results in signiﬁcantly
better security, since only a subset of columns needs to be
encrypted order-preserving.
Another main objective of our work is to also eﬃciently
integrate with adjustable encryption. This means that the
order-preserving encryption should be the inner-most layer
of an onion of encryption. This implies that encryption
needs to be performed (mostly) at the client, since other
layers of encryption need to be applied. We describe our
scheme in the next section.
4.1 Database Integration
We perform encryption at the SQL layer and do not in-
terfere with the dictionary of the in-memory, column-store
database. Instead, we keep a local copy of the dictionary as
the state of the order-preserving encryption function similar
to [17] and perform updates using the SQL update com-
mand. Before inserting (or updating) a database row, we
encrypt each value. We encrypt the plaintext value using our
encryption algorithm (Algorithm 1). Then, we encrypt the
ciphertext further using a proxy-reencrytpable deterministic
encryption scheme [31]. Finally, we encrypt this ciphertext
using a standard randomized encryption algorithm, e.g. AES
in counter mode. Figure ?? shows the layers of our ad-
justable encryption.
We sent the ﬁnal ciphertext as the data value in the in-
sert or update commands to the database. We keep a local
copy of the dictionary as the state of the order-preserving
encryption function with the corresponding plaintext val-
ues. Furthermore, we sent a separate copy in homomorphic
encryption [29]. When we perform a select operation that
requires either deterministic or order-preserving encryption
we sent the corresponding key to the database which de-
crypts using a stored procedure. Note that decryption is
permanent and never restored.
Since our order-preserving encryption scheme is mutable,
it may be necessary to update all ciphertexts. In case our
encryption algorithm triggers this update (Algorithm 2), we
re-encrypt the entire local dictionary. We again perform
encryption to the top-most layer currently stored in the
database. Then, we issue update commands replacing all
current dictionary values with their new ciphertexts. Of
course, this operation is very costly and its occurrence must
be kept to a minimum. We show theoretically in Section 3.5
and experimentally in Section 5 that we achieve this.
This design allows us to operate the encrypted database
on the SQL layer, i.e. we do not interfere with the dictionary
on the server.
Instead, we modify the data values on the
client and use standard SQL commands. Furthermore, we
can easily add layers of encryption on the client and the
ciphertexts in database are often encrypted at higher layers
than order-preserving encryption.
In order to see the problems with adjustable encryption