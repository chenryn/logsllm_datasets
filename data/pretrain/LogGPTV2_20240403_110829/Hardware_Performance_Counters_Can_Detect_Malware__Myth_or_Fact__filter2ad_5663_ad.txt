makes up 20% of the dataset, the baseline of precision in classifying
A is 80%. Any designed machine learning models whose precision
is lower than 80% are worse than the precision estimated with prior
probability. In our work, we matched the number of benignware
and malware; at the same time, we reported precision, recall and
F1-score to eliminate any bias.
3.3 Method for Running Experiments
We ran our benignware and malware experiments on identical hard-
ware and operating system. However, there are a few diferences
between malware and benignware experiments. We explain the
worklow of malware and benignware experiments using one dis-
patched job in Figure 2. The boxes are the steps that we follow,
and the solid arrow means that the next step always happens. The
dotted arrow means that the action happens under the conditions
of the labels.
3.3.1 Malware Experiment. We follow the steps in Figure 2 to
run the experiments. Before any malware experiments, we dropped
all the requests to any network outside the master node, to ensure
that malware does not afect other machines. At the beginning of
each experiment, the worker node runs a clean copy of Windows
and waits for a new job. Once the worker node receives the job
from the master node, Savitor runs the malware and records the
measured HPC values. After running each malware experiment,
we provide an identical, malware-free environment for the next
malware experiment by reloading the Windows partition. In order
to reload Windows image, we installed Debian 8 in the other parti-
tion of the hard drive on each worker node. Whenever a worker
node boots into the Debian partition, the worker node copies a
clean Windows image to the other partition. We modiied the GNU
GRand Uniied Bootloader (GRUB) to make the machine boot into
an alternate partition every time it reboots. After reloading the
image, the system reboots into Windows again and runs the next
job dispatched from the master node.
3.3.2 Benignware Experiment. Similar to the malware experi-
ments, benignware experiments also follow the worklow in Fig-
ure 2. We connected the worker nodes to the outside network to
ensure the benignware receives network responses. Programs, such
as browsers, require network responses to perform similarly as in
a user environment. When the worker node receives a job from
the master node, Savitor starts the target process (benignware pro-
gram), and a monkey tester is attached to the target process if the
target process has an interactive window. The Monkey tester works
similar to Android’s Monkey tester [32], as it interacts with the tar-
get process by periodically sending random keystroke, mouse clicks,
and scrolling operations to the window of the target process. The
behavior of the monkey tester simulates the interaction between a
user and the programs. After Savitor samples the measured HPC
values, the system resets by killing any processes spawned during
the experiments. Since the benignware does not try to infect the
Windows partition and perform malicious operations, we do not
reload the Windows partition. After killing the spawned processes,
the worker node receives the next job from the master node and
starts the next experiment.
4 MACHINE LEARNING MODELS
In this section, we present how we apply machine learning models
on measured HPC values. One of the common problems in ma-
chine learning is the Curse of Dimensionality. Curse of Dimension-
ality means that machine learning models in a high-dimensional
space have lower detection rates compared to models in lower-
dimensional spaces [21]. The redundant dimensions in high dimen-
sions contribute to the measurement of noise in the training dataset,
which result in a decrease in the detection rates of testing. Curse
of Dimensionality motivates the reduction of dimension; however,
reducing dimensions may cause underitting due to the lack of rep-
resentation during training. In order to overcome both overitting
and underitting, the design of machine learning models requires
the minimum number of features that represent most of the mea-
sured HPC values. To this end, we perform a quantitative analysis
to extract features from the measured HPC values of our selected
micro-architectural events.
4.1 Reduction of Dimensions
In this work, we use Principal Component Analysis (PCA) to reduce
the dimensions. By reducing the dimensions, the machine learning
models can use the linearly independent components to easily
classify the examples into diferent classes. Here, we show one
synthetic dataset (a subset from our experiments) separated from
overlapping measured HPC values by applying PCA results. In
the next subsection (ğ4.2), we explain how we choose the sizes of
examples and features.
s
e
u
l
a
V
s
e
l
p
m
a
x
e
f
o
5.00e+13
0.00e+00
1
2
3
4
5
6
7
8
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
Event: The number of Load operations dispatched to the Load-Store unit
Benignware (red box): creative1, Malware (blue box): 37375106291becca8427766e24f54887
Features
(a)
s
e
u
l
a
v
A
C
P
2.00e+13
0.00e+00
2
1
PCA
Features
(b)
Figure 3: X axis is the feature number and Y axis is the values of each example. Red box corresponds to the malware and blue box corresponds
to the benignware. The dashed line is the mean of each distribution. The boxes represent 25% ∼ 75% of the distributions. The whiskers (the
short, horizontal lines outside the boxes) represent the conidence interval equivalent to µ ± 3σ of Gaussian Distribution (0.3% ∼ 99.7%). We
measure The number of Load operations dispatched to the Load-Store unit event 5 times in one benignware (creative2 from Futuremark) and
one malware. The distributions of the two subplots represent 5 examples in the experiments. (a) Distributions of sampled values before the
reduction of dimensions: We cannot distinguish between the 5 malware examples and the 5 benignware examples. (b) Distributions of sampled
values after the reduction of dimensions: We apply the reduction of dimensions to examples in (a) to get examples in (b). We can separate all
the examples in (b) due to the gaps between values of malware and benignware in both features.
PCA applies eigen-decomposition to decompose the training
standard matrix (A), where columns are features and rows are ex-
amples, into the multiplication of eigenvectors (V ) and eigenvalues
(λ) in Equation 1. The standard matrix (A) is transformed into lower-
dimensional data space by multiplying the eigenvector matrix V ,
which can also be approximated with the major eigenvector matrix
(V ′).
more than 100 available micro-architectural events. Hence, we de-
signed a method to select our micro-architectural events, while
reducing the dimensions of examples at the same time.
In our method, our selection of events is based on minimizing 3
sources of losses These 3 main sources of losses in the measured
HPC values are:
A = V λV −1 ≈ V ′λV ′−1
(1)
• Jitter: the timing variations between identical measurements
We present the distributions of examples before and after the
reduction of dimensions, A5×32 in Figure 3(a) and A5×32V ′
32×2 in
Figure 3(b). We measure the number of Load operations dispatched
to the Load-Store unit (Table 2) event 5 times in one benignware
(creative2 from Futuremark) and one malware 4. The input matri-
ces (A) of both benignware and malware have 32 features and 5
examples. In Figure 3, X axis shows the feature number and Y axis
shows the values of each example. Red box refers to the malware
and blue box refers to the benignware. The dashed line is the mean
of each distribution. The boxes represent 25% ∼ 75% of the distribu-
tions. The whiskers (the short, horizontal lines outside the boxes)
represent the conidence interval equivalent to µ ± 3σ of Gaussian
Distribution (0.3% ∼ 99.7% of the total distributions).
From Figure 3(a), we can see overlapping of boxes and whiskers
in all the columns. Figure 3(b) shows the results of the data matrix
(A) multiplied with the eigenvector matrix (V ′). We can clearly
classify the malware or benignware, since there are gaps between
the distributions of malware and benignware in both features. By
multiplying the eigenvector matrix, diferent features contribute to
classiication with weights according to their abilities to discrimi-
nate data. Hence, we can achieve higher classiication rates with
lower dimensional data.
4.2 Selection of Events
As discussed in ğ4.1, we reduce the dimensions to extract features
from the measured HPC values to form the machine learning mod-
els. At the same time, the hardware limitation on number of HPCs
without time-multiplexing requires the selection of events from
4SHA256 hash value: 3737 5106 291b ecca 8427 766e 24f5 4887
of the measured HPC values.
• Noise: the amplitude variations between identical measure-
ments at the same time-stamp of the measured HPC values.
• Approximation error: the loss of the minor eigenvectors.
Jitter and noise are introduced due to the limitations in the
measurements. As we will discuss in ğ6, noise and jitter cannot
be eradicated. To minimize the impact from jitter, we divide the
measured results into 32 equal time intervals, and sum the gathered
values in each time interval to form 32 histogram bins (each bin
corresponds to one feature). This is the same design choice as the
one used by Demme et al. [3]. Histogram bins preserve the sampled
information, while reducing the efects of jitter in the values of
HPCs. In addition to jitter, we observe noise in the measured HPC
values, as Weaver et al. do in their work [20, 33]. To minimize
the noise for our selection of events, we repeat the measurements
on the same program and the same events 32 times, and then we
calculate the cumulative sum in each bin, in order to increase the
Signal-to-Noise Ratio (SNR). Assuming the noise introduced during
the measurement is Additive White Gaussian Noise (AWGN) [34],
this approach increases the SNR by a factor of 32.
Approximation error is introduced by the elimination of minor
eigenvectors in V when we transform V to V ′. For each example,
we multiply the measured HPC values to the major eigenvector
matrix V ′ instead of V . In our method, by trading of the number
of eigenvectors in the major eigenvector matrix, we reduce the
dimensionality and increase the approximation error in Equation 2.
We use the product of the standard matrix A and the eigenvector
matrix V ′ as our input matrix in machine learning model as we
described in Equation 1.
α
0.025
0.020
0.015
0.010
0.005
0.000
1
2
3
m
4
5
Figure 4: Error Bound vs the Number of Eigenvetors Plot: when
choosing diferent number of eigenvectors for reduction in dimen-
sions, the error bound α changes according to m eigenvectors.
AV =
=
m
X
i =1
m
X
i =1
v (i )λ(i ) +
n
X
i =m+1
v (i )λ(i )
v (i )λ(i ) + ϵ (αvλ)
(2)
(3)
In equation 2, λ(i ) denotes the it h largest eigenvalue with n
eigenvalues (λ). v (i ) is the corresponding eigenvector of λ(i ), and
m is the number of reduced dimensions. Equation 2 represents the
separation of m major and n − m minor eigenvectors. The irst term
in Equation 2 is AV ′. The approximation error is the diference
between AV and AV ′, which is the second term in Equation 2. In
Equation 3, ϵ denotes the upper bound function. α denotes error
coeicient, with the error term (AV − AV ′) divided by the original
input data (AV ). Equation 3 expresses that with a given m value,
we can estimate the approximation error using α . By having more
eigenvectors in the eigenvector matrix V ′ (larger m), we can reduce
α , which corresponds to a lower approximation error. As we observe
from Equation 3, the approximation error depends on the choice of
eigenvectors. We cannot determine the eigenvectors before we train
and test our dataset. However, we can use a subset of programs to
compute the eigenvectors and choose the parameters in Equation 3.
As in real-life, it is impossible to use the entire dataset for the
selection of events. Here, we chose a subset of programs, 7 pro-
grams from the Futuremark [28] benchmark for the selection of
events. The choice of programs from Futuremark benchmark suite
is driven by the fact that Futuremark has analyzed user behavior
and automated this behavior in the benchmarks. All the programs of
Futuremark benchmark are real-world applications commonly used
in oice. We measured the programs at at the frequency of 1 kHz
for 1 minute, as we described in ğ3.1. Our experimental hardware
(AMD Bulldozer micro-architecture) enables us to monitor 130
events 6 at a time. We accumulated the measured HPC values into
32 bins, with each measurement summed into 32-dimension vector.
Thus we ran each of the 7 programs from Futuremark Benchmarks
on 130 micro-architectural events 32 times (130×32×7).
Aek Vek
=
m
X
i =1
v
(i )
ek λ
(i )
ek
+ ϵ (αvek λek )
α (m) = min
e j
(i )
e j λ
Pn
i =m+1 v
ve j λej
(i )
e j
(4)
(5)
Table 2: Description of the Selected Events [2]
Events
Deinition
The number of accesses to the data cache for load and store references
The number of CLFLUSH instructions executed
0x04000
0x03000
0x02B00 The number of System Management Interrupts (SMIs) received
0x02904
0x02902
0x02700
The number of Load operations dispatched to the Load-Store unit
The number of Store operations dispatched to the Load-Store unit
The number of CPUID instructions retired
With the results (130×32×7) from the experiments, we denote
(i )
the kt h event as ek , its it h eigenvalue as λ
ek , and the corresponding
(i )
eigenvector as v
ek for k = 1, 2, . . . 130 in Equation 3, in order to
re-write Equation 3 into Equation 4. In Equation 5, ej corresponds
to the 6 events with the minimum α when j = 1, 2, . . . 6, excluding
the events whose measured HPC values are all zeros. We apply
Equation 1 to compute vek and λek . We calculate the eigenval-
ues for 130 events and ind out that there is no event among 130
events with more than 10 eigenvectors (n ≤ 10). We exclude all
the events that only have zero values in the measured HPC values,
since these events provide no signal in the measured HPC values.
By changing the number of eigenvectors (m), we can calculate the
error coeicient (α ) in Equation 5. We plotted the error coeicients
for m = 1, 2 . . . 5 in Figure 4. The gradient of α decreases when
m is more than 2. Subsequently, we consider the optimal trade-of
between m and α when m = 2 and α (2) = 0.072%, which corre-
sponds to the upper bound of error as 0.072% AV , with the linear
combination of 2 components from ve j .
The 6 events, which we selected in our experiments, are listed in
Table 2. We assemble the eigenvectors of 6 events, 2 for each event,
and we get the v matrix in Equation 6.
,
v192×12 =
(1)
ek1
, v
(2)
ek1
v
In Equation 6, v
(i )
ekj
v
(1)
ek2
, v
,
(2)
ek2
(6)
represents the it h largest eigenvector in
(2)
ek6
v
(1)
ek6
. . .
, v
(i )