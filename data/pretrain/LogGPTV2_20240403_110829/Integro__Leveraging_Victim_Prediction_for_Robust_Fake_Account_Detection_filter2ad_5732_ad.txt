Pre-highlights
Platform
Number of friends the user had
Number of photos the user shared
Number of news feed items the user had
Number of groups the user was member of
Number of likes the users made
Number of games the user played
Number of movies the user watched
Number of albums or songs the user listened to
Number of TV shows the user watched
Number of books the user read
Type
Numeric
Numeric
Numeric
Numeric
Numeric
Numeric
Numeric
Numeric
Numeric
Numeric
Number of messages sent by the user
Number of messages in the user’s inbox
Privacy level for receiving messages
Numeric
Numeric
5-Categorical
Number of users blocked by the user
Number of graphics (photos) blocked by the user
Numeric
Numeric
Number of days since the user updated the proﬁle
Number of years highlighted in the user’s time-line
Number of days since the user joined the OSN
User is male or female
User has a cover picture
User has a proﬁle picture
Number of years highlighted before 2004
User disabled third-party API integration
Numeric
Numeric
Numeric
2-Categorical
2-Categorical
2-Categorical
Numeric
2-Categorical
RI Score (%)
Facebook
Tuenti
100.0
93.7
70.6
41.8
30.6
20.1
16.2
15.5
14.2
7.5
N/A
N/A
N/A
N/A
N/A
90.77
36.3
31.7
13.8
10.5
4.3
3.9
1.6
84.5
57.4
60.8
N/A
N/A
N/A
N/A
N/A
N/A
N/A
53.3
52.9
9.6
23.9
19.7
32.5
N/A
100
7.9
< 0.1
< 0.1
N/A
< 0.1
TABLE I: Low-cost features extracted from Facebook and Tuenti datasets. The RI score is the relative importance of the feature. A value of
“N/A” means the feature was not available for this dataset. A k-Categorical feature means this feature can have one value out of k categories
(e.g., boolean features are 2-Categorical).
contenders [13], including EigenTrust [15], SybilGuard [16],
SybilLimit [17], SybilInfer [18], Mislove’s method [19], and
GateKeeper [20]. We next contrast
these systems to both
SybilRank and Íntegro.
√
SybilGuard [16] and SybilLimit [17] identify fake accounts
based on a large number of modiﬁed random walks, where
mn log n) in centralized setting
the computational cost is O(
like OSNs. SybilInfer [18], on the other hand, uses Bayesian
inference techniques to assign each user account a probability
of being fake in O(n(log n)2) time per trusted account. The
system, however, does not provide analytical bounds on how
many fakes can outrank real accounts in the worst case.
GateKeeper [20], which is a ﬂow-based detection approach,
improves over SumUp [58]. It relies on strong assumptions that
require balanced graphs and costs O(n log n) time per trusted
account, referred to as a “ticket source.”
Viswanath et al. used Mislove’s algorithm [39] to greedily
expand a local community around known real accounts in oder
to partition the graph into two communities representing real
and fake regions [19]. This algorithm, however, costs O(n2)
time and its detection can be easily evaded if the fakes establish
sparse connectivity among themselves [9].
Compared to these systems, SybilRank provides an equiv-
alent or tighter security bound and is more computationally ef-
ﬁcient, as it requires O(n log n) time regardless of the number
of trusted accounts. Compared to SybilRank, Íntegro provides
O(|Ea|/vol(Ea)) improvement on its security bound, requires
the same O(n log n) time, and is robust against social inﬁltra-
tion, unlike SybilRank and all other systems.
A. Datasets
We used two datasets from two different OSNs. The ﬁrst
dataset was collected in the study described in Section II-D,
and contained public user proﬁles and two graph samples. The
second dataset was collected from Tuenti’s production servers,
and contained a day’s worth of server-cached user proﬁles.
Research ethics. For collecting the ﬁrst dataset, we followed
known practices and obtained the approval of our university’s
research ethics board [7]. As for the second dataset, we signed
a non-disclosure agreement with Tuenti in order to access an
anonymized, aggregated version of its user data, with the whole
process being mediated by Tuenti’s Site Integrity team.
The ground-truth. For the Tuenti dataset, the accounts were
inspected and labeled by its accounts’ analysts. The inspection
included matching user proﬁle photos to its declared age or
address, understanding natural language in user posts, exam-
ining the friends of a user, and analyzing the user’s IP address
and HTTP-related information. For the Facebook dataset, we
used the ground-truth of the original study [7], which we also
re-validated for the purpose of this work, as we describe next.
Facebook. The dataset contained public proﬁle pages of 9,646
real users who received friend requests from fake accounts. As
9
the dataset was collected in early 2011, we wanted to verify
whether these users are still active on Facebook. Accordingly,
we revisited their public proﬁles in June 2013. We found that
7.9% of these accounts were either disabled by Facebook or
deactivated by the users themselves. Accordingly, we excluded
these accounts, ending up with 8,888 accounts, out of which
32.4% were victims who accepted a single friend request sent
by a fake posing as a stranger. As fakes initially targeted users
at random, the dataset included a diverse sample of Facebook
users. In particular, these users were 51.3% males and 48.7%
females, lived in 1,983 cities across 127 countries, practiced 43
languages, and have used Facebook for 5.4 years on average.
The dataset also included two graph samples of Facebook,
which were collected using a stochastic version of the Breadth-
First Search method called “forest ﬁre” [59]. The ﬁrst graph
consisted of 2,926 real accounts with 9,124 friendships (the
real region), 65 fakes with 2,080 friendships (the fake region),
and 748 timestamped attack edges. The second graph consisted
of 6,136 real accounts with 38,144 friendships, which repre-
sented the real region only.
Tuenti. The dataset contained proﬁles of 60K real users who
received friend requests from fake accounts, out of which 50%
were victims. The dataset was collected in Feb 10, 2014 from
live production servers, where data resided in memory and no
expensive, back-end queries were made. For Tuenti, collecting
this dataset was a low-cost and easy process, as it only involved
reading cached user proﬁles of a subset of its daily active users,
users who logged in to Tuenti on that particular day.
B. Victim prediction
We sought to validate the following claim: An OSN oper-
ator can identify unknown victim accounts with a probability
that is better than random, using strictly low-cost features
extracted from readily-available user proﬁles.
Features. As described in Table I, we extracted features from
both datasets to generate feature vectors. The only requirement
we had for feature selection was to have the feature value
available for all users in the dataset, so that the resulting feature
vectors are complete. For the Facebook dataset, we were able
to extract 18 features from public user proﬁles. For Tuenti,
however, the dataset was limited to 14 features, but contained
user features that are not publicly accessible.
Validation method. To evaluate the accuracy of the classiﬁers,
we performed a 10-fold, stratiﬁed cross-validation method [47]
using the RF learning algorithm. First, we randomly partitioned
the dataset into 10 equally-sized sets, with each set having the
same percentage of victims as the complete dataset. We next
trained an RF classiﬁer using 9 sets and tested it using the
remaining set. We repeated this procedure 10 times (i.e., folds),
with each of the sets being used once for testing. Finally, we
combined the results of the folds by computing the mean of
their true-positive rate (TPR) and false-positive rate (FPR).
Performance metrics. The output of the classiﬁer depends on
its operating threshold, which is a cutoff value in the prediction
probability after which the classiﬁer identiﬁes a given user as a
victim. In order to capture the trade-off between TPR and FPR
in single curve, we repeated the cross-validation method under
different threshold values using a procedure known as receiver
(a) ROC Analysis
(b) Sensitivity to dataset size
Fig. 4: Victim prediction using the RF algorithm. In (a), the ROC
curves show the tradeoff between FPR and TPR for both datasets.
In ROC analysis, the closer the curve is to the upper-left corner the
more accurate it is. The area under the ROC curve (AUC) summarizes
the classiﬁer’s performance. Therefore, an AUC of 1 means a perfect
classiﬁer, while an AUC of 0.5 means a random classiﬁer. We require
the victim classiﬁer to be better than random. In (b), during cross
validation on Tuenti dataset, we observed that increasing the dataset
size to more than 40K vectors did not signiﬁcantly increase the AUC.
operating characteristics (ROC) analysis. In ROC analysis, the
closer the curve is to the top-left corner at point (0, 1) the better
the classiﬁcation performance is. The quality of the classiﬁer
can be quantiﬁed with a single value by calculating the area
under its ROC curve (AUC) [47].
We also recorded the relative importance (RI) of features
used for the classiﬁcation. The RI score is computed by the
RF algorithm, and it describes the relative contribution of each
feature to the predictability of the label (i.e., a victim or a non-
victim), when compared to all other features [46].
Results. For both datasets, the RF classiﬁer ended up with an
AUC greater than 0.5, as shown in Fig. 4a. In particular, for
the Facebook dataset, the classiﬁer delivered an AUC of 0.7,
which is 40% better than random. For the Tuenti dataset, on
the other hand, the classiﬁer delivered an AUC of 0.76, which
is 52% better than random. Also, increasing the dataset size to
more than 40K feature vectors did not signiﬁcantly improve the
AUC during cross-validation, as show in Fig. 4b. This means
an OSN operator can train a victim classiﬁer using a relatively
small dataset, so fewer accounts need to be manually veriﬁed.
C. Ranking quality
We compared Íntegro against SybilRank in terms of their
ranking quality under various attack scenarios, where ideally
real accounts should be ranked higher than fake accounts. Our
results are based on the average of at least 10 runs, with error
bars reporting 95% conﬁdence intervals (CI), when applicable.
We picked the Facebook dataset for this comparison because
it included both feature vectors and graph samples.
Inﬁltration scenarios. We considered two attack scenarios. In
the ﬁrst scenario, attackers establish attack edges by targeting
users with whom their fakes have mutual friends. Accordingly,
we used the ﬁrst Facebook graph which contained timestamped
attack edges, allowing us to replay the inﬁltration by 65
socialbots (n=2,991 and m=11,952). We refer to this scenario
as the targeted-victim attack.
In the second scenario, we attackers establish attack edges
by targeting users at random [13]. We designated the second
10
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 True(posiSve(rate(False(posiSve(rate(TuenS(Facebook(Random(AUC = 0.76 AUC = 0.7 AUC = 0.5 0.747 0.749 0.751 0.753 0.755 0.757 0.759 0.761 10 20 30 40 50 60 Mean(area(under(ROC(curve(Dataset(size((thousands)((cid:100)log2(n)(cid:101) iterations for both Íntegro and SybilRank.
Results. Íntegro consistently outperformed SybilRank in rank-
ing quality, especially as the number of attack edges increased.
Using the RF classiﬁer, Íntegro resulted in an AUC which is
always greater than 0.92, and is up to 30% improvement over
SybilRank in each attack scenario, as shown in Fig 5.
In each inﬁltration scenario, both systems performed well
when the number of attack edges was relatively small. In other
words, the fakes were sparsely connected to real accounts and
so the regions were easily separated. As SybilRank limits the
number of fakes that can outrank real accounts by the number