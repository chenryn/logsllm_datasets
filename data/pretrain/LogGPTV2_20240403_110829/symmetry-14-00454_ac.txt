(11)
(12)
(13) |
|---|---|---|---|---|
| Precision = |Precision = |Precision = |TP  TP + FP |(10) (11) (12) (13) |
| Recall = |Recall = |TP  TP + FN |TP  TP + FN |(10) (11) (12) (13) |
| F1 − measure =2 ∗ Precison ∗ Recall |F1 − measure =2 ∗ Precison ∗ Recall |F1 − measure =2 ∗ Precison ∗ Recall |F1 − measure =2 ∗ Precison ∗ Recall |(10) (11) (12) (13) |In Formulas (10)–(13), TP is the number of normal classes predicted for normal samples, FP is the number of normal classes predicted for abnormal samples, and FN is the number of abnormal classes predicted for normal samples [39].
4.3. Result AnalysisWe compare LogLS with four anomaly detection methods, namely PCA, IM, N-gram and DeepLog. Through the comparison of each evaluation data, the detection performance of this model in log anomaly detection is obtained. By default, we use the following parameter values for LogLS: g1 = 13, g2 = 4, g3 = 2, h = 10, L = 2, S = 64, and E = 300. g1, g2, and g3 are the same type of parameters g, and g determines whether the predicted log event is normal (the log event that appears next is considered normal among the g log events with the highest predicted probability). h is the window size used for training and detection, and L and S represent the number of layers in LogLS and the number of memory units in an LSTM block, respectively. E is the number of epochs to be trained, where each epoch is a single training iteration of all batches in the forward and backward propagation. If the number of epochs is too small, underfitting may occur, and if the number is too large, overfitting may occur.Table 6 shows the number of false positives and false negatives for each method on the HDFS data (all data except the training set), and the accuracy rate. The false positives and false negatives of LogLS have a low level, and the accuracy rate of 99.84% is also the highest among the five methods. Figure 5 shows the experimental results of different methods on the HDFS dataset. Although the precision of the traditional PCA on the HDFS dataset is 0.98, the recall and F1-measure are relatively low, only 0.67 and 0.79, respectively. Among the three methods of IM, N-gram and DeepLog, DeepLog performs best. The precision, recall and F1-measure are 0.95, 0.96 and 0.96, respectively. However, we can also see thatSymmetry 2022, 14, 454 12 of 21
the LogLS method is better than several other methods as a whole. The three evaluation metrics reached 0.96, 0.98 and 0.97, indicating that this method has advantages.
Table 6. Number of FPs, FNs and Accuracy on HDFS log.
|  | PCA | IM | N-Gram | DeepLog | LogLS |
|---|---|---|---|---|---|
| False positive(FP) |277 |2122 |1360 |833 |657 |
| False negative(FN) |5429 |1226 |739 |615 |280 || Accuracy |99.00% |99.41% |99.63% |99.75% |99.84% |
Figure 5. Evaluation on HDFS log.
4.4. Parameter AnalysisThe performance of the model is tested by adjusting each parameter in the LogLS model. This article uses the controlled variable method to carry out the parameter ad-justment experiment of LogLS. When one parameter is studied, the other parameters are controlled and remain unchanged. The adjusted parameters include g1, g2, g3, h, L, S, and E. In each experiment, only the value of one parameter is changed; the remaining parameters remain at the default values. Of course, g1, g2, and g3 belong to a class of parameters, so these three values are changed as variables, and the rest remain unchanged. After observation, the arithmetic sequence method is used to determine the optimal value of class G parameters. The value range of g1 is {5,7,9,11,13,15}. The value range of g2 and g3 is {1,3,5,7,9,11,13}. After adjusting these three parameters, a total of 294 groups of data are generated. The experimental data cannot be fully displayed in the chart, so Figure 6 shows 49 groups. The graph is obtained by assuming g1 = 13 and changing the values of g2 and g3. Figure 6 shows the changes in the three values of precision, recall and F1-measure when g2 and g3 change. The abscissa represents g2, and the ordinate represents g3. Figure 6 includes three sets of small graphs. Figure 6a shows the change in the precision value after changing these two parameters, Figure 6b shows the change in the recall value, and Figure 6c shows the change in the F1-measure.| Symmetry 2022, 14, 454 |  | 13 of 21 |
|---|---|---|
|  | | |
| (a) |(b) |(c) |
Figure 6. Performance comparison chart of changing parameters g2 and g3. (a) Precision. (b) Recall.
(c) F1-measure.
Figure 6 shows that when the F1-measure of the model is the best, the values of g2 and g3 are 5 and 3, respectively. The detailed evaluation indicators corresponding to these two parameters are separately compared. The results for when g3 = 3 and only g2 is changed are shown in Table 7 and Figure 7.Table 7. g2 size in LogLS.
| g2 Size | Precision | Recall | F1-Measure |
|---|---|---|---|
| 1 |0.6476 |0.9923 |0.7837 |
| 3 |0.8443 |0.9673 |0.9016 |
| 5 |0.9677 |0.9612 |0.9644 |
| 7 |0.9683 |0.9260 |0.9467 |
| 9 |0.9689 |0.9198 |0.9437 |
| 11 |0.9716 |0.9060 |0.9376 |
| 13 |0.9737 |0.8727 |0.9204 |
Figure 7. Performance comparison chart of changing parameter g2.
Symmetry 2022, 14, 454 14 of 21As seen from Table 7 and Figure 7, precision increases with increasing g2; the maximum precision value in the table is 0.9737. Recall decreases with increasing g2, and the maximum value of recall in the table is 0.9923. The value of the F1-measure first increases and then decreases as the value of g2 increases. When g2 = 5, the value of the F1-measure in the table reaches a maximum value of 0.9644, and at this time, the values of precision, recall and F1-measure are relatively balanced and high. Therefore, it is preliminarily confirmed that the optimal parameter value of g2 is 5.Now we parameter g2 to 5 and use default values for other parameters. By changing the parameter value of g3, the changes of the three values of precision, recall and F1-measure are obtained. The results are shown in Table 8 and Figure 8.
Table 8. g3 size in LogLS.
| g3 Size | Precision | Recall | F1-Measure |
|---|---|---|---|
| 1 |0.9619 |0.9636 |0.9627 |
| 3 |0.9677 |0.9612 |0.9644 || 3 |0.9677 |0.9612 |0.9644 |
| 5 |0.9693 |0.9386 |0.9537 |
| 7 |0.9690 |0.9147 |0.9410 |
| 9 |0.9699 |0.8996 |0.9334 |
| 11 |0.9716 |0.8878 |0.9278 |
| 13 |0.9721 |0.8822 |0.9250 |
Figure 8. Performance comparison chart of changing parameter g3.It can be seen from Table 8 and Figure 8 that precision increases with the increase of g3, recall decreases with the increase of g3, and that the F1-measure first increases and then decreases with the increase of g3. The F1-measure obtains the maximum value when g3 = 3, and the three values of precision, recall and F1-measure are relatively balanced and high. Therefore, the tuning parameter temporarily confirms that the optimal parameter value of g3 is 3. It can be concluded that the parameter values of g2 and g3 are temporarily 5 and 3, respectively. Then, the parameters of g1 are adjusted according to g2 and g3. As the value of g1 changes, the three values of precision, recall, and F1-measure are obtained. The results are shown in Table 9 and Figure 9.Symmetry 2022, 14, 454 15 of 21
Table 9. g1 size in LogLS.
| g1 Size | Precision | Recall | F1-Measure |
|---|---|---|---|
| 5 |0.8919 |0.9966 |0.9414 |
| 7 |0.9287 |0.9830 |0.9551 |
| 9 |0.9464 |0.9673 |0.9567 |
| 11 |0.9623 |0.9654 |0.9638 |
| 13 |0.9677 |0.9612 |0.9644 |
| 15 |0.9690 |0.9339 |0.9511 |
Figure 9. Performance comparison chart of changing parameter g1.It is determined from Table 9 and Figure 9 that the parameter g1 can be temporarily set to 13. Combining the parameter results obtained above, it can be concluded that when g1 = 13, g2 = 5 and g3 = 3, the overall model prediction results are ideal. However, this parameter is adjusted by an arithmetic sequence, which is not complete. Moreover, it is found that the changes in precision, recall and F1-measure are correlated with g1, g2 and g3. Therefore, the adjacent parameter values are compared. The value range of g1 is {12,13,14}, while g2 is {4,5,6} and g3 is {2,3,4}. As shown in Table 10, the final values of parameters g1, g2 and g3 are 13, 4 and 2, respectively. At this time, precision, recall and F1-measure all perform well, being 0.9586, 0.9856 and 0.9719, respectively.We then studied the impact of various other parameters on the detection performance during LogLS training, including h, L, S, and E. The results obtained are shown in Figure 10. In each experiment, we change the value of one parameter while using the default values of other parameters. Graph (a) in Figure 10 shows the performance change of the model by changing the parameter h. Because the LSTM network needs long dependence, within a certain range, when the selected window is larger, its performance is more obvious, but when it breaks this range, the performance drops sharply. Figure 10b shows the performance change of the model when the parameter E is varied. Within a certain range of training iterations, as the number of training iterations increases, the performance of the model becomes stronger, but the number of iterations is too large, and the performance of the model becomes weaker. Figure 10c shows the performance change of the model as the parameter L is changed. The change in the number of layers in LogLS has a relatively stable effect on model performance. Figure 10d shows the performance change of the modelSymmetry 2022, 14, 454 16 of 21
with changing parameters. When the number of memory units in an LSTM block is 64, the model performance is the best. In summary, of all the experimental results, it is found that the LogLS model is relatively stable when various parameters are adjusted reasonably, and a single change in parameters or a combination of adjustments has little effect on the performance of the model.Table 10. Adjacent parameter.
| g1 | g2 | g3 | Precision | Recall | F1-Measure |
|---|---|---|---|---|---|
| 12 |4 |2 |0.9558 |0.9856 |0.9705 |