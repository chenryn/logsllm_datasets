7.6
5.8
5.9
-
27.5
27.1
48.0
8.5
30.0
18.7
-
65.7
61.7
48.0
83.9
63.9
75.4
-
5.4
11.3
4.0
0.7
5.3
5.2
-
33.3
32.5
44.8
16.3
35.2
22.2
-
60.9
56.2
51.2
83.0
59.0
72.6
-
4.3
11.5
2.3
1.9
3.5
5.7
-
31.7
35.2
60.8
13.3
33.7
17.9
-
63.6
53.3
36.9
84.8
62.2
76.3
-
Table 8: Percent of bytes sent unencrypted, grouped by ex-
periment type. Number of devices considered in each row is
in parentheses in the first column.
identified), and device activity that can be inferred from encrypted
network traffic (e.g., video is streaming from a video doorbell). For
the latter, we build, evaluate and use a machine learning classifier
that leverages network traffic statistics as features, and our ground-
truth experiment labels for detection. We then analyze the potential
privacy implications of such information exposure.
6.1 Identifying PII and Device Activity
We use the following techniques to identify PII and device activity
in network traffic.
To identify PII exposed in
Textual PII in unencrypted traffic.
plaintext, we simply search for any PII known (in various encodings)
in each device’s network traffic. For the purpose of this analysis PII
includes device identifiers (e.g., MAC address, UUID, etc.), and any
personal information given at registration time (e.g., names, email
address, home address, phone number, username, password, etc.).
To
Device activity inference (encrypted or unencrypted).
infer the device activity based on network traffic (regardless of
whether it is encrypted), we train a random forest machine learning
classifier using experiment labels and network traffic for each device
interaction. Examples of device activity that is contained in our
labels include power on a device, issue voice command, view video
stream. The set of features we use to train our classifier are timing
statistics of the traffic with respect to packet sizes and inter-arrival
times. The statistical proprieties we consider as features are the
following: min, max, mean, deciles of the distribution, skewness, and
kurtosis. We focused on features that avoid dependencies on text- or
size-based features that can easily vary across deployment location
(e.g., due to different hostnames selected as part of location-based
server redirection), while still yielding high accuracy under cross-
validation.
We observed that experiments from certain devices contain net-
work traffic resulting directly from the experiment interaction, as
well as network traffic that is unrelated to the experiment (e.g.,
time synchronization via NTP). Thus, we leverage multiple interac-
tions (30 automated tests, 3 manual tests) for each interaction type,
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Ren, J. et al.
to mitigate the effects of such traffic noise. The large numbers of
tests in the automated cases also provide enough samples to apply
cross-validation, thus allowing us to evaluate the accuracy of our
method.
6.2 Textual Unencrypted Content
We found limited identifiable content, and even less PII, in unen-
crypted traffic. This is good news, particularly compared with prior
work that identified substantial amounts of PII exposed in plaintext
in other contexts (e.g., mobile apps and web sites [25, 37]).
Nonetheless, we found notable cases of PII exposure. This in-
cluded various forms of unique identifiers (MAC address3, UUID, de-
vice ID), geolocation at the state/city level, and user specified/related
device name (e.g., John Doe’s Roku TV). A notable case that we
found in our US lab is the Samsung Fridge sending MAC addresses
unencrypted to an EC2 domain, which is a support party in the
best case. The implication is that it is now possible for an ISP to
track this device.
In both our labs we found that Magichome Strip is sending its
MAC address in plaintext to a domain hosted on Alibaba. Interest-
ingly, the Insteon hub was sending its MAC address in plaintext to
an EC2 domain, but only from the UK lab. We did not find similar
behavior in the US lab. Interestingly, each time the Xiaomi camera
detected a motion, its MAC address, the hour and the date of the
motion (in plaintext) was sent to an EC2 domain. We also noted
that a video was included on the payload.
We investigated the content of plaintext communication that
did not contain PII, and found that common cases included queries
related to device actions (e.g., turn on/off the device or issue a
command to the device). We also identified large unencrypted file
transmissions that contained firmware updates and/or metadata
pertaining to initial device set up.
6.3 Device Activity Inference
In this section, we describe how we trained machine learning clas-
sifiers to estimate how much device activity can be inferred based
on network traffic. Note that we do not claim (or attempt) to pro-
duce the most performant classifiers according to metrics such as
accuracy or F1 score. Rather, we use such metrics to understand
whether device activities are inferrable as explained below.
To reliably infer device activity, we first validate our machine
learning classifiers using 7/3 split cross validation (i.e., train on
randomly selected 70% of the data and test on the 30% remaining
data, and we repeat the process for 10 times to get the average
metrics). Then we use the F1 score, defined as the harmonic mean
between precision and recall, as a quality metric to evaluate the
effect of false positives and false negatives for the detection of the
activities of a device, where F1 = 0 is the worst score and F1 = 1 is
the best score. We calculate the F1 score for the prediction of each
activity of the device (defined as the F1 score for the activity), and
the F1 score across all activities for each device (defined as the F1
score for the device). We consider an activity or device as inferrable,
when its F1 score is greater than 0.75.
Table 9 shows the number
Predictable devices per category.
of devices whose actions are mostly all inferrable using our classifier.
3Note that MAC addresses can be used to identify a device vendor, which in some cases may
uniquely identify the device.
Category (#D) US UK US∩ UK∩
0
Appliances (10)
0
Audio (11)
3
Cameras (17)
0
Home Auto (16)
Smart Hubs (14)
0
3
TV (8)
2
3
8
0
1
5
0
1
6
1
0
3
0
2
3
0
1
3
VPN
US→UK UK→US US∩ UK∩
0
3
3
0
0
3
1
3
10
1
1
5
0
3
6
1
0
4
0
2
4
1
1
3
Table 9: Number of inferrable devices (F1 score > 0.75),
grouped by category. Total number of devices per category
in parenthesis in the first column.
VPN
30
6
7
5
5
14
41
10
11
9
9
19
Exp (#D) US UK US∩ UK∩
22
Power (75)
4
Voice (17)
Video (19)
4
3
On/Off (45)
4
Movement (19)
Others (52)
10
US→UK UK→US US∩ UK∩
22
5
4
5
4
10
Table 10: Number of inferrable activities (number of devices
with such an activity in parentheses), aggregated by activ-
ity group. We consider an activity for a device is inferrable
when its F1 score is >0.75.
20
6
5
5
4
13
42
9
11
9
8
20
32
6
7
7
5
15
21
5
5
6
3
12
Cameras have the largest fraction of inferrable devices, followed
by television devices, and audio devices. We believe this is due to
the fact that cameras, TVs, and audio devices produce the most
traffic during interactions, and this provides more samples to better
train our classifier. If we look at the regional comparison between
common devices in Table 9 we can see that in most cases we have
some differences in the number of inferrable devices across regions
(for example, 2 audio devices are inferred in the US and 0 in the UK).
We observe this pattern of slight differences also if we compare each
lab with and without VPN connectivity (for example, 2 appliances
can be inferred in the US lab without VPN, and 1 with the VPN).
Table 10 shows
Devices with reliably inferrable activities.
the number of devices whose activities we can reliably infer. We
find that the “Power” activity is the most inferrable, due to the
unique traffic patterns that characterize it, followed by video and
movement activities (due to the large amount of data that interact-
ing with cameras produce). Each of these types of activities can
be considered sensitive, as they indicate presence and activity in
a home or other deployment space—information that can be read-
ily inferred by a network eavesdropper. Regarding the regional
comparison, Table 10 also shows that there are differences in the
number of inferrable devices across regions (for example, 41 power
experiments are inferrable in the US and 30 in the UK). Similarly to
the previous case, we also observe differences in inferrable devices
with and without VPN (for example, we can infer 9 devices offering
movement activities without VPN, and 8 with the VPN).
6.4 Takeaways
We analyzed both unencrypted and encrypted content in this sec-
tion. First, we found very limited sensitive or personal information
exposed in plaintext—a welcome observation given the sensitivity
of data potentially exposed by such devices. Second, we found that
even when devices use encryption, the timing patterns of their
network traffic permits reliable identification of the interactions
that caused the network traffic. Put another way, an eavesdropper
Information Exposure From Consumer IoT Devices
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
can reliably learn a user’s interactions with a device across a wide
range of categories, opening the potential for profiling and other
privacy-invasive techniques. There are differences in inferrability
across regions, a topic that warrants further investigation as part
of future work.
7 UNEXPECTED BEHAVIOR
In this section we use the activity prediction methodology devel-
oped in §6 to detect unexpected behavior in idle and uncontrolled
experiments.
7.1 Measuring Unexpected Behavior
We define unexpected behavior as cases when a device generates
network traffic corresponding to an interaction that either did not
occur, or was not intended by the user. To identify which network
traffic corresponds to an interaction with an IoT device, we use our
device activity inference approach on the traffic generated by idle ex-
periments and uncontrolled experiments. In idle experiments there is
no interaction with devices, so any inferred activity reveals possible
privacy concerns due to any user monitoring activity. For our IRB-
approved user study, we have some ground truth about user/device
interactions (e.g., by asking users, watching users recordings, in-
specting logs, and notifications produced by the device). We can
compare such ground truth to what was inferred, thus allowing us
to determine whether the detected activity is expected or not.
To identify activities from unlabeled network traffic, we must
divide network traffic from a device into units amenable to classifi-
cation. Choosing a value that is too small provides too little data for
classification; a value that is too large may merge traffic together
from multiple activities, and thus inhibit correct classification. For
this study we use an empirically derived traffic unit of classifica-
tion: a sequence of packets containing inter-packet interval greater
than 2 seconds. To focus our analysis only on the most significant
predictions, we use only the most accurate models based on cross-
validation in §6; namely, only those with an F1 score > 0.9. During
idle experiments, our model identified activities for 21% and 69%
traffic units, depending on the location of the device and its network
egress.
7.2 Idle Experiments
Table 11 shows the number of reliably predictable activities we
have predicted during around 30 hours of idle experiments (details
in the first row of the table). The most commonly detected activities
are: “power” activities across all devices, “menu” activities from
TVs (i.e., the act of navigating the home menu screen of the TV),
and “move” activities for some cameras (i.e., the act of moving in
front of a camera). We can also notice several less common and/or
specialized activities (such as “view inside the fridge”).
The large number of “power” activities is due to devices that
frequently disconnect and reconnect to the Wi-Fi network (which
we verified using DHCP server logs). When a device reconnects,
it performs a new handshake with its cloud services similarly to
when it is powered on. Thus, we do not consider power activities
as unexpected or suspicious.
We believe that “menu” activities are explained by TVs that
occasionally refresh the content of their menu page (e.g., showing
new on-demand content available for viewing), much the same
VPN
US→UK UK→US
26.75
Activity
-
local move
local move
power
local menu
android lan remote
power
power
local voice
power
local voice
local viewinside
android lan menu
local voice
local volume
power
local volume
local menu
local voice
power
power
power
volume
power
local off
local voice
android lan menu
local voice
local volume
android wan graphs
Device
TOTAL HOURS
Zmodo Doorbell
Wansview Camera
Wansview Camera
Roku TV
Roku TV
Roku TV
Ring Doorbell
Google Home Mini
Google Home Mini
Samsung Fridge
Samsung Fridge
Fire TV
Fire TV
Echo Spot
Echo Dot
Echo Dot
Apple TV
Apple TV
Sous Vide Cooker
Osram Lightify Hub
Google Home
Echo Plus
Echo Plus
LG TV
LG TV
LG TV
Invoke with Cortana
Invoke with Cortana
Netatmo Weather Station