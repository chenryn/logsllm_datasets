priority tasks’ response times. Also, the impact on response
times tends to be higher for low-priority partitions as they
are more likely to operate in the deferred release mode than
high-priority partitions.
Figure 20: Mix of static and non-static time partitioning.
5.4 Discussion
Physical time: If the precise physical time is available to
tasks in the receiver partition (i.e., ΠR in Figure 5), they can
directly perceive changes in their timings. Certain counter-
measures such as fuzzy time [19, 42] and virtual time [25, 45]
techniques can mitigate the threat. However, partitions under
a hierarchical scheduling can still form an algorithmic covert-
channel without time information as presented in Section 3.
Certain applications still require the physical time informa-
tion, making the above mitigations inapplicable. One possible
way to prevent such applications from exploiting the hier-
archical scheduling is to serve them in static partitions. As
shown in Figure 20, a system can host a mix of static and
non-static partitions by (i) allocating ﬁxed time intervals for
the static partitions and (ii) letting the others (i.e., non-static
partitions) compete for the remaining times based on their
priorities. Note that there can be multiple static partitions
placed anywhere in the major cycle. From the perspective of
the non-static partitions, the static partitions can be viewed as
another non-static partition with the highest-priority and the
replenishment period being equal to the major cycle. The non-
static partitions are subject to Blinder, and access to precise
physical time is disabled for their user processes. In our proto-
type, we use a sandbox-based method to block physical-time
access for a demonstration purpose.
For most real-time applications, their correct functioning
highly depends on the execution regularity and schedulability.
Physical control processes use time elapsed between succes-
sive invocations to estimate a change in the process state over
time. For low-dynamics systems, the interval can be approxi-
mated by a constant time resolution. In such cases, applica-
tions do not need precise physical times. In Section 6.1, we
discuss the practicality of such an approximation based on our
prototype implementation. On the other hand, high-dynamics
processes require precise time information and such tasks can
be served in static partitions as explained above. In fact, such
highly critical applications are less likely to be malicious as
they tend to have low complexity and go through a stringent
veriﬁcation process due to safety requirements.
Modularity: Blinder is modular in that it can be enabled/dis-
abled independently for each partition because it does not
change a partition’s behavior from others’ points of view.
Accordingly, enabling/disabling Blinder for individual parti-
tion does not affect others’ schedulability. This modularity
is especially useful when certain partitions are veriﬁed to
be trustworthy, and such applications are free of accessing
precise physical time.
USENIX Association
30th USENIX Security Symposium    2427
Partition-levelPreemptionReplenished𝑡𝑡+𝐵!Release𝑡+𝑇!Replenished𝑡𝑡+𝐵!𝑡+𝑇!Used up by lower-priority tasksDepletedArrival & Release(a)WithBlinderReplenishedReplenished(b) WithoutBlinder𝑇!−𝐵!𝑇!−𝐵!ArrivalHigh-priority partitionsStaticPartitionsNon-static Partitions (priority-driven)Major cycle Disable access to physical timeStaticPartitionsNon-Algorithm complexity: In the normal release mode lag is
not computed, and the arrival queue is always empty. Hence,
Blinder does not enter the loop in LocalScheduler (Algo-
rithm 2). Therefore, the algorithm complexity in this mode is
O(1). In the deferred release mode, both LocalScheduler
and ShiftRelease update the lag values of the tasks in
the arrival queue. Because a lag calculation is a constant-
time operation, the worst-case complexity for each partition
is linear to the size of its task set. Note that the operations
are independent from the number of partitions in the system.
Hence, letting M be the total number of tasks in the system,
the asymptotic complexity is O(M).
Multicore: Blinder can be applied to a multicore processor
without any modiﬁcation. This feature is only disadvanta-
geous to adversaries–especially if partitions can migrate be-
tween cores. This is because the sender partition may not
be able to preempt the receiver partition. If migration is not
allowed, Blinder can be independently applied to each of the
application sets that share a CPU core. However, if a parti-
tion can run multiple tasks simultaneously across multiple
cores, one of them can serve as an implicit clock (e.g., using
a shared counter in a tight loop). Hence, partitions should not
be allowed to occupy multiple cores at the same time, as well
as disallowing shared memory and messaging across cores.
In fact, in high-assurance systems, it is a common practice
to ﬁx a partition to a core to minimize the unpredictability
caused by concurrency [36].
6 Evaluation
6.1 Use Case
Platform: We applied Blinder to an 1/10th-scale self-driving
car platform. Figure 8 in Section 3.1 presented the overall sys-
tem architecture. It autonomously navigates an indoor track
using a vision-based steering control and an indoor position-
ing system. The health monitoring partition, Π4, collects run-
time log data and also runs watchdog process that monitors
the application partitions’ heartbeat messages.
Blinder Implementation: We implemented Blinder in the
latest version of LITMUSRT (based on Ubuntu 16.04 with ker-
nel version 4.9.30) which we run on Intel NUC mini PC that
has Intel Core i5-7260U processor operating at 2.20 GHz
and a main memory of 8 GB. Our implementation is based
on LITMUSRT’s partitioned reservation (P-RES) framework.
For our evaluation, we applied Blinder to the sporadic-polling
server of P-RES which is a variant of the sporadic-server al-
gorithm; the full budget is replenished after one period from
the beginning of ﬁrst consumption, instead of maintaining
multiple replenishment threads. Hence the same available
function presented in Section 5.2.2 is used because only one
trep (i.e., the next replenishment time) exists and is known
at any time instant. We used the ﬁxed-priority preemptive
scheduling for the partition-local scheduling. Our implemen-
tation is denoted by P-RES-NI (P-RES with non-interference).
One implementation challenge that needs to be highlighted
is that LITMUSRT reservation does not have a clock to gen-
erate regular tick-based signals. It rather uses a Linux high-
resolution timer (hrtimer) [16] to set an absolute expiration
time instant for the next schedule. Every time when the sched-
uler returns to the user thread, it resets this timer to the closest
instant that needs to be responded by the scheduler. In P-RES,
the next reschedule point is determined by the minimal value
of the time slices of the local scheduler, the remaining budget,
and the next replenishment time. For P-RES-NI, we added
one more condition, that is the remaining lag for the head of
the arrival queue, to accurately schedule task release points.
Blocking access to physical time: The behavior controller
partition, Π1, is allowed to access the physical time because
it is given the highest priority. The other partitions do not
need the precise physical time information. Thus, we blocked
them from accessing the physical time. Speciﬁcally, we imple-
mented a secure launcher that creates a restricted execution
environment for user tasks based on seccomp (secure comput-
ing mode) [11] that can ﬁlter any system calls. We blacklisted
time-related system calls such as time, clock_gettime,
timer_gettime, etc. In addition, we dropped the permissions
that could leak physical time information, including time-
relevant devices (e.g., /dev/hpet), time-stamp counter (TSC),
model-speciﬁc registers, and virtual ELF dynamic shared ob-
ject (vDSO) [13]. The tasks of Π2, Π3, and Π4 are launched
by this secure launcher. Other approaches such as fuzzy time
[19, 42] and virtual time [25, 45] could also be used for them.
The navigation partition also runs a Kalman ﬁlter-based
localization task that requires a time interval between suc-
cessive estimations. It uses a constant time interval (50 ms),
instead of precise time measurements. In order to see how
close it is to the actual variations, we measured time inter-
val between successive executions. Note that the interval is
hardly constant (unlike inter-arrival time) due to constraint
on partition-budget as well as delay by higher-priority parti-
tions/tasks. This can be seen from Figure 21 that compares
the localization task’s execution intervals under P-RES and
P-RES-NI. Although the interval ranges between 30 and 60
ms with a few outliers, the average matches the task’s esti-
mation rate (20 Hz). With Blinder enabled, we measured the
error in the position estimation (from the ground-truth) and
observed a 3% increase in the error when compared to the
case when time interval is measured from the wall clock.
Figure 21: Time interval between successive execution of the
localization task in Π3.
2428    30th USENIX Security Symposium
USENIX Association
PRES:    Mean=50.00,Stdev=9.44PRES-NI: Mean=50.00,   Stdev=7.75Table 1: Partition (Ti,Bi) and task (pi, j, ei, j) parameters for the
evaluation of response times on LITMUSRT system. Units are
in ms. The system load is controlled by α and β. For instance,
the system load is 80% for α = β = 1. Pri(Πi) > Pri(Πi+1).
τi,1
τi,2
τi,3
τi,4
Figure 22: LITMUSRT schedule traces of the covert channel
scenario when Blinder is used.
Covert channel: Figure 22 shows the schedule traces for the
scenario presented in Section 3.1 with Blinder enabled. The
navigation task’s heartbeat message helps the watchdog task
in the health monitoring partition to time the receiver tasks to
the sender. Nevertheless, due to Blinder, Receiver 1, which has
a lower-priority than Receiver 2, always completes its execu-
tion before Receiver 2 increases the shared counter no matter
how long the sender executes. Thus, the receiver’s inference
always results in ‘0’ regardless of the sender’s signal.
6.2 Cost of Blinder
Response time: To evaluate the cost of Blinder in a general
setting, we measured task response times from a system that
is comprised of various rate-groups. The partition and task pa-
rameters are shown in Table 1. We initially set both α and β to
1, which sets the system load to 80%. In order to add random-
ness to the executions and thus to create numerous variations
in timings, task inter-arrival times are allowed to vary by 20
percent. Task priorities are assigned according to Rate Mono-
tonic policy [27] (i.e., shorter period → higher priority). We
used rtspin tool of LITMUSRT to generate the real-time tasks.
We compare our method, P-RES-NI (N), against P-RES (P)
and TDMA (T). For TDMA, the major cycle is set to 50 ms.
Figure 23 summarizes the statistics of task response times
obtained from running each scheme for 10 hours. The em-
pirical probability distributions and the complete data includ-
ing the analytic WCRTs can be found in Appendix B. The
analytic WCRTs for P-RES are calculated by the analysis
presented in [14]. Those under TDMA can be calculated simi-
larly by treating other partitions as a single, highest-priority
periodic task. The analyses assume no kernel cost, and thus
the actual measurements can be slightly higher than what are
numerically computed. The results highlight the following: (i)
P-RES-NI does not increase the WCRTs compared to P-RES.
This is because all the partitions are schedulable as discussed
in Section 5.3; (ii) the behavior of Π1 (i.e., the highest-priority
partition) is not affected by Blinder because it never enters
into the deferred release mode; (iii) the experimental WCRTs,
in particular of low-priority tasks, under P-RES-NI tend to be
smaller than those measured under P-RES especially in low-
priority partitions. This is because those tasks are made more
responsive by Blinder (i.e., deferred release of higher-priority
tasks reduces the amount of preemption on lower-priority
tasks), and thus the true worst-cases were less likely to be
observed. In theory, the WCRTs under P-RES-NI and P-RES
are same; (iv) while TDMA beneﬁts low-priority partition in
Π1 (20,4α)
Π2 (30,6α)
Π3 (40,8α)
Π4 (50,10α)
(40,2β)
(60,3β)
(80,4β)
(100,5β)
(80,4β)
(120,6β)
(160,8β)
(200,10β)
(160,8β)
(240,12β)
(320,16β)
(400,20β)
(320,16β)
(480,24β)
(640,32β)
(800,40β)
Figure 23: Statistics of response times of the tasks in Table 1.
terms of the WCRTs due to guaranteed time slices, it de-
grades the average responsiveness; (v) due to the lag-based
release control, the average-case response times, in particular
of high-priority tasks, increase. The impact is more notice-
able in lower-priority partitions. As a result, τ4,1’s average
response time is increased by 20% under P-RES-NI. However,
although criticality is not necessarily identical to priority, such
low-priority partitions tend to be less sensitive to degraded
responsiveness; (vi) the impact on lower-priority tasks are
smaller. For instance, the average response times of τ3,4 and
τ4,4 are decreased by 2% and 5%, respectively, compared to
P-RES. This is because in addition to the reduced-preemptions
by higher-priority tasks, a part or whole of the lag times could
have been spent nevertheless to wait for higher-priority tasks
to ﬁnish. Hence, their delayed releases can be masked.
Figure 24: Probability distribution of τ4,1’s response times.
USENIX Association
30th USENIX Security Symposium    2429
0ms10ms20ms30ms40ms50ms60ms70ms80ms90ms100ms110ms120ms130ms140ms150ms160ms170ms180ms190ms200ms210ms220ms230ms240ms250ms260ms270ms280ms290ms300ms310ms320ms330ms340ms350ms360ms370ms380ms390ms400ms410ms420ms430ms440ms450ms460ms470ms480ms490ms500ms510ms520ms530ms540ms550ms560ms570ms580ms590ms600ms610ms620ms630ms640ms650ms660ms670ms680ms690ms700ms710ms720ms730ms740ms750ms760ms770ms780ms790ms800ms810ms820ms830ms840ms850ms860ms870ms880ms890ms900ms910ms920ms930ms940ms950ms960ms970ms980ms990ms1000ms/7687(0.00ms, 0.00ms)/7689(0.00ms, 0.00ms)/7692(0.00ms, 0.00ms)/7693(0.00ms, 0.00ms)/7698(0.00ms, 0.00ms)/7700(0.00ms, 0.00ms)/7703(0.00ms, 0.00ms)/7704(0.00ms, 0.00ms)0ms10ms20ms30ms40ms50ms60ms70ms80ms90ms100ms110ms120ms130ms140ms150ms160ms170ms180ms190ms200ms210ms220ms230ms240ms250ms260ms270ms280ms290ms300ms310ms320ms330ms340ms350ms360ms370ms380ms390ms400ms410ms420ms430ms440ms450ms460ms470ms480ms490ms500ms510ms520ms530ms540ms550ms560ms570ms580ms590ms600ms610ms620ms630ms640ms650ms660ms670ms680ms690ms700ms710ms720ms730ms740ms750ms760ms770ms780ms790ms800ms810ms820ms830ms840ms850ms860ms870ms880ms890ms900ms910ms920ms930ms940ms950ms960ms970ms980ms990ms1000ms/7687(0.00ms, 0.00ms)/7689(0.00ms, 0.00ms)/7692(0.00ms, 0.00ms)/7693(0.00ms, 0.00ms)/7698(0.00ms, 0.00ms)/7700(0.00ms, 0.00ms)/7703(0.00ms, 0.00ms)/7704(0.00ms, 0.00ms)Π!Π"Watchdog taskReceiver 1Receiver 2SenderNavigation taskSend 1 Send 0 Receive 0 Receive 0 HBHB!!,#!!,$!!,%!!,&"#"$"%"&(a) Π!is schedulable(b) Π!is notschedulableFigure 25: Conﬁguration used for the overhead measurements
with varying number of partition-level preemptions and size
of arrival queue. p∗,∗ =200 ms, T∗=200 ms, B∗=100 ms.
Table 2: Average and standard deviation of response times
(ms) of τL,1 in Figure 25.
#HP
#LA
12
18
24
30
15
P-RES
P-RES-NI
96.15
(0.04)
96.17
(0.04)
96.17
(0.06)
96.19
(0.05)
96.19
(0.07)
96.22
(0.06)
96.22
(0.09)
96.24
(0.08)
30
45
96.23
(0.08)
96.26
(0.07)
30
96.22
(0.08)
96.25
(0.08)
450
96.39
(0.08)
96.73
(0.07)
Figure 24(b) shows the probability distribution of τ4,1’s
response times when Π4 is not schedulable due to the in-
creased system load (by setting α = β = 1.25 in Table 1). The
complete measurements data are provided in Table 4 in Ap-
pendix B. Note that with this conﬁguration, some tasks miss
their deadlines even under P-RES. We performed this experi-
ment to show the impact of Blinder on such an ill-conﬁgured
system. Due to τ4,1’s longer release-delay, its worst and mean
response times are increased by 41% and 45%, respectively.
Table 5 in Appendix B presents the worst-case and average-
case response times when the system load is reduced to 40%
(by setting α = β = 0.5). The results do not show statisti-
cally signiﬁcant evidence of a difference between P-RES and
P-RES-NI, except that τ4,1’s average response time increases
by 4.5% in P-RES-NI. Recall that the accuracy of the covert
communication demonstrated in Section 3 increases signif-
icantly when the system is light-loaded. This suggests that
Blinder can deter such malicious attempts effectively, incur-
ring a small overhead on real-time applications.
Scheduling overheads: In our implementation of Blinder in
LITMUSRT, Linux high-resolution timer (hrtimer) is used to
schedule the lag-based task release. When a partition is pre-
empted, the timer is rescheduled upon resumption to account
for the suspended time. Thus, the number of partition-level
preemptions as well as the size of the arrival queue may af-
fect the scheduling overhead. For this experiment, we use a
two-partition conﬁguration shown in Figure 25. ΠL enters
into the deferred release mode at time 14 (ms) due to the
preemption by ΠH. 15 tasks of ΠL arrive at time 44, right
before ΠL returns from ΠH’s preemption. Every 2 ms from
time 46, ΠH preempts ΠL for 1 ms. Note that the result does
not change with varying number of higher-priority partitions,
because Blinder’s complexity is independent of the number of
partitions; it is irrelevant as to who preempts ΠL.
The initial lag values of the tasks that arrive at time 44 are
30. Hence, they are not released until τL,1 executes for another
30 ms since returning from ΠH’s preemption. We assigned the
highest ΠL-local priority to τL,1 to isolate any impact of task-
level preemption. Therefore, the arrival queue of ΠL remains
same until τL,1 ﬁnishes at time 106. We vary the number of