这是afl-fuzz的一种运行模式，也称为 **peruvian rabbit mode**
，用于确定bug的可利用性，具体细节可以参考[lcamtuf](https://lcamtuf.blogspot.com/2014/11/afl-fuzz-crash-exploration-mode.html)的博客。
    $ afl-fuzz -m none -C -i poc -o peruvian-were-rabbit_out -- ~/src/LuPng/a.out @@ out.png
举个例子，当你发现目标程序尝试写入\跳转到一个明显来自输入文件的内存地址，那么就可以猜测这个bug应该是可以利用的；然而遇到例如NULL pointer
dereferences这样的漏洞就没那么容易判断了。
将一个导致crash测试用例作为 _afl-fuzz_ 的输入，使用 _-C_ 选项开启crash
exploration模式后，可以快速地产生很多和输入crash相关、但稍有些不同的crashes，从而判断能够控制某块内存地址的长度。这里笔者在实践中没有找到适合的例子，但在一篇[文章](https://countuponsecurity.com/tag/peruvian-were-rabbit/)中发现了一个很不错的例子——tcpdump栈溢出漏洞，crash
exploration模式从一个crash产生了42个新的crash，并读取不同大小的相邻内存。
#### 2\. triage_crashes
AFL源码的experimental目录中有一个名为 _triage_crashes.sh_
的脚本，可以帮助我们触发收集到的crashes。例如下面的例子中，11代表了SIGSEGV信号，有可能是因为缓冲区溢出导致进程引用了无效的内存；06代表了SIGABRT信号，可能是执行了abort\assert函数或double
free导致，这些结果可以作为简单的参考。
    $ ~/afl-2.52b/experimental/crash_triage/triage_crashes.sh fuzz_out ~/src/LuPng/a.out @@ out.png 2>&1 | grep SIGNAL
       +++ ID 000000, SIGNAL 11 +++
       +++ ID 000001, SIGNAL 06 +++
       +++ ID 000002, SIGNAL 06 +++
       +++ ID 000003, SIGNAL 06 +++
       +++ ID 000004, SIGNAL 11 +++
       +++ ID 000005, SIGNAL 11 +++
       +++ ID 000006, SIGNAL 11 +++
       ...
#### 3\. crashwalk
当然上面的两种方式都过于鸡肋了，如果你想得到更细致的crashes分类结果，以及导致crashes的具体原因，那么[crashwalk](https://github.com/bnagy/crashwalk)就是不错的选择之一。这个工具基于gdb的exploitable插件，安装也相对简单，在ubuntu上，只需要如下几步即可：
    $ apt-get install gdb golang
    $ mkdir tools
    $ cd tools
    $ git clone https://github.com/jfoote/exploitable.git
    $ mkdir go
    $ export GOPATH=~/tools/go
    $ export CW_EXPLOITABLE=~/tools/exploitable/exploitable/exploitable.py
    $ go get -u github.com/bnagy/crashwalk/cmd/...
crashwalk支持AFL/Manual两种模式。前者通过读取 **crashes/README.txt**
文件获得目标的执行命令（前面第三节中提到的），后者则可以手动指定一些参数。两种使用方式如下：
    #Manual Mode
    $ ~/tools/go/bin/cwtriage -root syncdir/fuzzer1/crashes/ -match id -- ~/parse @@
    #AFL Mode
    $ ~/tools/go/bin/cwtriage -root syncdir -afl
两种模式的输出结果都一样，如上图所示。这个工具比前面几种方法要详细多了，但当有大量crashes时结果显得还是十分混乱。
#### 4\. afl-collect
最后重磅推荐的工具便是 _afl-collect_ ，它也是 _afl-utils_
套件中的一个工具，同样也是基于exploitable来检查crashes的可利用性。它可以自动删除无效的crash样本、删除重复样本以及自动化样本分类。使用起来命令稍微长一点，如下所示：
    $ afl-collect -j 8 -d crashes.db -e gdb_script ./afl_sync_dir ./collection_dir --  /path/to/target --target-opts
但是结果就像下面这样非常直观：
### 五、代码覆盖率及其相关概念
代码覆盖率是模糊测试中一个极其重要的概念， **使用代码覆盖率可以评估和改进测试过程，执行到的代码越多，找到bug的可能性就越大**
，毕竟，在覆盖的代码中并不能100%发现bug，在未覆盖的代码中却是100%找不到任何bug的，所以本节中就将详细介绍代码覆盖率的相关概念。
#### 1\. 代码覆盖率（Code Coverage）
代码覆盖率是一种度量代码的覆盖程度的方式，也就是指源代码中的某行代码是否已执行；对二进制程序，还可将此概念理解为汇编代码中的某条指令是否已执行。其计量方式很多，但无论是GCC的GCOV还是LLVM的SanitizerCoverage，都提供函数（function）、基本块（basic-block）、边界（edge）三种级别的覆盖率检测，更具体的细节可以参考LLVM的[官方文档](https://clang.llvm.org/docs/SanitizerCoverage.html)。
#### 2\. 基本块（Basic Block）
缩写为BB，指一组顺序执行的指令，BB中第一条指令被执行后，后续的指令也会被全部执行，每个BB中所有指令的执行次数是相同的，也就是说一个BB必须满足以下特征：
  * 只有一个入口点，BB中的指令不是任何 **跳转指令** 的目标。
  * 只有一个退出点，只有最后一条指令使执行流程转移到另一个BB
例如下图中的代码就可以被切割为4个基本块，平时我们在IDA图形模式中看到的就是一个一个的基本块
将上面的程序拖进IDA，可以看到同样被划分出了4个基本块：
#### 3\. 边（edge）
AFL的[技术白皮书](http://lcamtuf.coredump.cx/afl/technical_details.txt)中提到fuzzer通过插桩代码捕获边（edge）覆盖率。那么什么是edge呢？我们可以将程序看成一个控制流图（CFG），图的每个节点表示一个基本块，而edge就被用来表示在基本块之间的转跳。知道了每个基本块和跳转的执行次数，就可以知道程序中的每个语句和分支的执行次数，从而获得比记录BB更细粒度的覆盖率信息。
#### 4\. 元组（tuple）
具体到AFL的实现中，使用二元组(branch_src, branch_dst)来记录 **当前基本块** \+ **前一基本块**
的信息，从而获取目标的执行流程和代码覆盖情况，伪代码如下：
    cur_location = ;            //用一个随机数标记当前基本块
    shared_mem[cur_location ^ prev_location]++;        //将当前块和前一块异或保存到shared_mem[]
    prev_location = cur_location >> 1;                //cur_location右移1位区分从当前块到当前块的转跳
实际插入的汇编代码，如下图所示，首先保存各种寄存器的值并设置ecx/rcx，然后调用`__afl_maybe_log`，这个方法的内容相当复杂，这里就不展开讲了，但其主要功能就和上面的伪代码相似，用于记录覆盖率，放入一块共享内存中。
### 六、计算代码覆盖率
了解了代码覆盖率相关的概念后，接下来看看如何计算我们的测试用例对前面测试目标的代码覆盖率。
这里需要用到的工具之一是 **GCOV** ，它随gcc一起发布，所以不需要再单独安装，和afl-gcc插桩编译的原理一样，gcc编译时生成插桩的程序，用于在执行时生成代码覆盖率信息。
另外一个工具是 **LCOV** ，它是GCOV的图形前端，可以收集多个源文件的gcov数据，并创建包含使用覆盖率信息注释的源代码HTML页面。
最后一个工具是[afl-cov](https://github.com/mrash/afl-cov)，可以快速帮助我们调用前面两个工具处理来自afl-fuzz测试用例的代码覆盖率结果。在ubuntu中可以使用`apt-get install afl-cov`安装afl-cov，但这个版本似乎不支持分支覆盖率统计，所以还是从Github下载最新版本为好，下载完无需安装直接运行目录中的Python脚本即可使用：
    $ apt-get install lcov
    $ git clone https://github.com/mrash/afl-cov.git
    $ ./afl-cov/afl-cov -V
    afl-cov-0.6.2
还是以Fuzz libtiff为例，计算Fuzzing过程的代码覆盖率流程如下：
第一步，使用gcov重新编译源码，在CFLAGS中添加`"-fprofile-arcs"`和`"-ftest-coverage"`选项，可以在`--prefix`中重新指定一个新的目录以免覆盖之前alf插桩的二进制文件。
    $ make clean
    $ ./configure --prefix=/root/tiff-4.0.10/build-cov CC="gcc" CXX="g++" CFLAGS="-fprofile-arcs -ftest-coverage" --disable-shared
    $ make
    $ make install
第二步，执行afl-cov。其中 _-d_ 选项指定afl-fuzz输出目录； _—live_ 用于处理一个还在实时更新的AFL目录，当afl-fuzz停止时，afl-cov将退出； _–enable-branch-coverage_ 用于开启边缘覆盖率（分支覆盖率）统计； _-c_
用于指定源码目录；最后一个 _-e_ 选项用来设置要执行的程序和参数，其中的 _AFL_FILE_ 和afl中的”@@”类似，会被替换为测试用例，
_LD_LIBRARY_PATH_ 则用来指定程序的库文件。
    $ cd ~/tiff-4.0.10
    $ afl-cov -d ~/syncdir --live --enable-branch-coverage -c . -e "cat AFL_FILE | LD_LIBRARY_PATH=./build-cov/lib ./build-cov/bin/tiff2pdf AFL_FILE"
成功执行的结果如下所示：
我们可以通过 _—live_
选择，在fuzzer运行的同时计算覆盖率，也可以在测试结束以后再进行计算，最后会得到一个像下面这样的html文件。它既提供了概述页面，显示各个目录的覆盖率；也可以在点击进入某个目录查看某个具体文件的覆盖率。
点击进入每个文件，还有更详细的数据。每行代码前的数字代表这行代码被执行的次数，没有执行过的代码会被红色标注出来。
#### 参考资料
[1] [INTRO TO AMERICAN FUZZY LOP – FUZZING WITH ASAN AND
BEYOND](https://countuponsecurity.com/2018/04/24/intro-to-american-fuzzy-lop-fuzzing-with-asan-and-beyond/)
[2] [Fuzzing with
AFL](https://media.defcon.org/DEF%20CON%2026/DEF%20CON%2026%20workshops/DEFCON-26-Workshop-Jakub-Botwicz-and-Wojciech-Rauner-Fuzzing-with-AFL-\(American-Fuzzy-Lop\).pdf)
[3] [Clang 9 documentation –
SanitizerCoverage](https://clang.llvm.org/docs/SanitizerCoverage.html)
[4]
[honggfuzz漏洞挖掘技术深究系列](http://riusksk.me/2018/07/29/honggfuzz%E6%BC%8F%E6%B4%9E%E6%8C%96%E6%8E%98%E6%8A%80%E6%9C%AF1/)
[5] [How Much Test Coverage Is Enough For Your Testing
Strategy?](https://www.seguetech.com/how-much-test-coverage-enough-testing-strategy/)
* * *