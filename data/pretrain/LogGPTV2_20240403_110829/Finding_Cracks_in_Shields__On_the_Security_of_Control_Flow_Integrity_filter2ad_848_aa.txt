title:Finding Cracks in Shields: On the Security of Control Flow Integrity
Mechanisms
author:Yuan Li and
Mingzhe Wang and
Chao Zhang and
Xingman Chen and
Songtao Yang and
Ying Liu
Finding Cracks in Shields:
On the Security of Control Flow Integrity Mechanisms
Yuan Li∗
BNRist & INSC, Tsinghua University
Beijing, China
PI:EMAIL
Xingman Chen
Tsinghua University
Beijing, China
PI:EMAIL
Mingzhe Wang∗
Tsinghua University
Beijing, China
PI:EMAIL
Songtao Yang
Tsinghua University
Beijing, China
PI:EMAIL
Chao Zhang(cid:66)
BNRist & INSC, Tsinghua University
Beijing, China
PI:EMAIL
Ying Liu
BNRist & INSC, Tsinghua University
Beijing, China
PI:EMAIL
Abstract
Control-flow integrity (CFI) is a promising technique to mitigate
control-flow hijacking attacks. In the past decade, dozens of CFI
mechanisms have been proposed by researchers. Despite the claims
made by themselves, the security promises of these mechanisms
have not been carefully evaluated, and thus are questionable.
In this paper, we present a solution to measure the gap between
the practical security and the claimed theoretical security. First,
we propose CScan to precisely measure runtime feasible targets
of indirect control transfer (ICT) instructions protected by CFI,
by enumerating all potential code addresses and testing whether
ICTs are allowed to jump to them. Second, we propose CBench as a
sanity check for verifying CFI solutions’ effectiveness against typical
attacks, by exploiting a comprehensive set of vulnerable programs
protected by CFI and verifying the recognized feasible targets.
We evaluated 12 most recent open-source CFI mechanisms and
discovered 10 flaws in most CFI mechanisms or implementations.
For some CFIs, their security policies or protected ICT sets do
not match what they claimed. Some CFIs even expand the attack
surface (e.g. introducing unintended targets). To facilitate a deeper
understanding of CFI, we summarize the flaws into 7 common
pitfalls which cover the whole lifetime of CFI mechanisms, and
reveal issues that affect CFI mechanisms in practical security.
CCS Concepts
• Security and privacy → Software security engineering.
Keywords
control flow integrity; evaluation; practical security
ACM Reference Format:
Yuan Li, Mingzhe Wang, Chao Zhang, Xingman Chen, Songtao Yang, and Ying
Liu. 2020. Finding Cracks in Shields: On the Security of Control Flow
∗Both authors contributed equally to this research.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’20, November 9–13, 2020, Virtual Event, USA
© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-7089-9/20/11...$15.00
https://doi.org/10.1145/3372297.3417867
Integrity Mechanisms. In Proceedings of the 2020 ACM SIGSAC Confer-
ence on Computer and Communications Security (CCS ’20), November 9–
13, 2020, Virtual Event, USA. ACM, New York, NY, USA, 15 pages. https:
//doi.org/10.1145/3372297.3417867
1 Introduction
By exploiting memory vulnerabilities such as buffer overflow
and use after free (UAF), an attacker can hijack the control flow
of a victim program to execute malicious code. Control-flow in-
tegrity (CFI) is a type of defense against control flow hijacking.
Since the first CFI solution [2] was proposed in 2005, dozens of
CFI mechanisms have been developed. In general, CFI solutions
instrument inline reference monitors for indirect control transfer
(ICT) instructions, whose transfer targets could be compromised,
to enforce that ICT instructions only jump to legitimate targets at
runtime.
Figure 1: Security boundaries of CFI-protected ICTs.
As defense solutions, CFI mechanisms’ security guarantees are
their most important indicator. The levels of security guarantees
provided by CFI can be illustrated by Figure 1. There may be multi-
ple feasible targets for one ICT instruction. But when the program is
actually running, there is only one target for each execution of the
ICT instruction, which depends on the context information at the
time. An ideal CFI mechanism should limit the feasible targets to a
unique one for each execution, stopping all control flow hijacking
attacks. In other words, the ideal boundary should contain only one
target. At present, µCFI [27] can reach the ideal boundary in theory,
but there are still some problems in its implementation. Usually,
CFI mechanisms calculate their claimed boundary with some the-
oretical estimation or coarse measurement. Due to the deficiency
of calculation, the feasible targets that CFI mechanisms actually
allow (real boundary) could deviate from the claimed ones. Such dif-
ferences reveal flaws in CFI solutions’ design and implementation.
Session 6B: Exploitation and Defenses CCS '20, November 9–13, 2020, Virtual Event, USA1821A flaw may allow feasible but unintended targets, which could be
exploited by attackers in realistic attack scenarios. On one hand, the
size of the real boundary reflects the attack surface; on the other
hand, the existence of realistic attack scenarios indicate potential
vulnerabilities. Specifically, to evaluate the practical security of CFI
mechanisms, there are three questions still unclear:
• RQ1: Where is the exact real boundary enforced by each CFI
mechanism? In the worst case, attackers could have very powerful
yet realistic capabilities, e.g., reading from or writing arbitrary value
to any accessible address at any time. When a CFI-protected ICT
instruction is executed at runtime, which targets could attackers
drive it to jump to? All these targets except only one are illegitimate.
• RQ2: Does the real boundary match the boundary claimed by
the CFI mechanism? In theory, each CFI mechanism only allows
each ICT instruction to jump to a limited number of targets, i.e.,
the claimed boundary. Targets in the real boundary but outside the
claimed boundary are all unintended to the CFI mechanism.
• RQ3: Are the feasible targets (especially the unintended targets)
realistic? There are many types of vulnerabilities and many ways to
exploit vulnerabilities in practice. What attack scenarios will cause
CFI mechanisms to fail and hijack ICT instructions to transfer to
those feasible targets, even those targets unintended to the CFI?
Failing to defeat such attacks shows that unintended targets are
realistic.
In this paper, we propose a new solution to systematically evalu-
ate the practical security of CFI mechanisms and answer the afore-
mentioned questions, in order to further shed light on developing
CFI solutions with strong security guarantees. The solution consists
of two orthogonal components:
• A tool CScan, for measuring runtime feasible targets, i.e. the set
of targets reachable from each CFI-protected ICT instruction
at runtime (the real boundary as in Figure 1). CScan traverses
all potential code addresses and filters addresses permitted by
the deployed CFI mechanism. Each permitted address at an ICT
instruction is a potential target that the control flow could be
hijacked to at runtime.
• A sanity check CBench, for verifying effectiveness against typi-
cal attacks, i.e. control flow hijacking attacks that could bypass
CFI (the realistic attack scenario as in Figure 1). Each failed test
case proves that the target CFI mechanism is vulnerable and
certain feasible targets (even unintended to CFI) are realistic.
Furthermore, we evaluated 12 most recent open-source CFI mech-
anisms with CBench and 9 with CScan (3 skipped due to compat-
ibility issues). Results showed that most of them are flawed. We
further analyzed the root causes of the flaws, and summarized 7
common pitfalls:
• At the design stage, 1 imprecise analysis methods could be cho-
sen, which limits the upper bound of a CFI mechanism can
achieve; 2 improper runtime assumptions could be made, which
fails in subtle attack scenarios.
• At the implementation stage, security could be compromised
in favor of compatibility, resulting 3 unprotected corner code.
The compiler faces challenges from 4 unexpected optimization
(which disables protection), and the runtime itself could have
5 incorrect implementation and 6 mismatched specification; it
could also bring 7 unintended targets.
The pitfalls summarized above cover the whole lifetime of CFI
mechanisms, and prevail in most popular CFI mechanisms. Dis-
cussion and analysis of these pitfalls reveal issues that affect CFI
mechanisms in practical security. To help researchers avoid these
pitfalls in future works, we also open-source our solution1.
In summary, we make the following contributions:
(1) We present a lightweight and general tool CScan to precisely
measure runtime feasible targets of ICT instructions, providing
evidence of security risks faced by CFI mechanisms.
(2) We develop a sanity check for typical attack scenarios, to demon-
strate the feasibility of identified security risks.
(3) We conduct a large scale analysis on representative CFI imple-
mentations, and provide a thorough study of their weaknesses.
(4) We further demonstrate 7 common pitfalls in CFI implementa-
tions which cover the whole lifetime of CFI mechanisms.
2 Background
Control-flow Integrity (CFI) [35] was first proposed in 2005 to
mitigate control-flow hijacking attacks. The core idea is to limit the
targets of each ICT instruction to a pre-computed legitimate set,
ensuring the integrity of the control-flow. Typically, the legitimate
set of transfer targets could be statically computed based on the
control flow graph (CFG), and the security check can be statically
instrumented into the target program and get executed at runtime.
A large number of CFI mechanisms have been proposed to provide
various supports in the last decade.
Binary Support. Some CFI solutions such as Opaque CFI [37],
CCFIR [72], binCFI [75] and CFIMon [66] are able to deploy on
binary programs without source code. They have a broader applica-
tion, but also suffer from inaccuracy of legitimate transfer targets.
They usually make special efforts to recover control flow graphs
from binaries or simply mark all address-taken functions and call-
site preceded instructions as legitimate transfer targets. In contrast,
source-level CFI solutions [40] [30] could utilize the source code
to build a more accurate control-flow graph and provide a finer
granularity of protections. For certain scenarios such as protecting
virtual function calls, source-level CFI solutions [28] [71] could
utilize type analysis to further reduce transfer targets.
Modular Support. Many CFI mechanisms have poor modular
support, and require global information to deploy CFI without com-
patibility issues. Modular support is also called support for DSO
(dynamically shared objects). There are two specific forms of mod-
ular support issues: (1) integration of multiple modules which are
hardened by CFI separately, and (2) integration of CFI-protected
modules with non-protected modules. Binary solutions like CC-
FIR [72] solve these two issues by weakening the security and
allowing more targets than necessary. MCFI [40] provides support
for the first issue. It instruments each module individually, and gen-
erates new CFGs when modules are linked together, and updates
the security checks accordingly. However, recent CFI solutions
which provide stronger security guarantees, e.g., µCFI [27] and OS-
CFI [31], cannot provide modular support yet, leaving it an urgent
problem to solve.
Dynamically Generated Code Support. Inlined CFI instru-
mentation for dynamically generated code could be overwritten
1Our repo presents updated results as CFI mechanisms evolve.
https://github.com/vul337/cfi-eval
Session 6B: Exploitation and Defenses CCS '20, November 9–13, 2020, Virtual Event, USA1822by attackers and become useless, since the code pages are writable.
NaCl-JIT [5] implements a weak coarse-grained CFI mechanism
by verifying the generated code before emitting. RockJIT [41],
JITScope [69] and DCG [52] provide CFI support for dynamically
generated code by separating the write permission from the dy-
namic code itself in several ways.
Hardware Utilization. Certain hardware features could help
improve the performance or security of CFI solutions. For instance,
PT-CFI [25], PITTYPAT [19], CFIMON [66] µCFI [27] and PathAr-
mor [57] take advantage of Intel PT and LBR to obtain runtime
information, to compute a smaller set of legitimate targets with an
acceptable performance overhead. On the other hand, TSX-based
CFI [38] and GRIFFIN [21] utilize hardware features such as Intel
TSX [30] and MPX [31] to ensure that the instrumented code or
metadata will not be interfered with or tampered with by attackers.
Security Guarantees. Early CFI schemes, e.g., Lockdown [46]
and BinCFI [75], statically built an imprecise CFG and provided
coarse-grained CFI. Source-level CFI solutions could utilize type
information to provide finer CFG and stronger guarantees. Some
of them have been integrated into standard compilers and ker-
nels, such as Clang-CFI [56], RAP [55], and Control Flow Guard
by Microsoft [54]. Recent dynamic CFI solutions (e.g., µCFI [27])
further utilize runtime information to improve the precision of
CFGs, determining a unique target for an ICT in some cases.
3 Related Work
3.1 Security Evaluation Methods
To precisely evaluate the security of CFI mechanisms, proper
evaluation methods should be used. After investigation, we found
that existing security evaluation methods are not adequate, and
hereby present two new methods. We analyzed 56 CFI solutions to
figure out their security evaluation methods. As shown in Table A3,
they can be divided into three categories: theoretical verification,
experimental verification and quantitative analysis.
3.1.1 Theoretical Verification. Some CFI schemes, e.g., SafeDis-
patch [28] and PARTS [34], only provide theoretical analysis to
illustrate their security and reliability. For example, SafeDispatch
outlines its implementation and theoretically analyzes the feasibil-
ity and effectiveness against VTable hijacking attacks.
However, differences always lie in between realistic implemen-
tations and theoretical models. Therefore, theoretical verification
cannot provide a strong support for precise security evaluation.
3.1.2 Experimental Verification.
fectiveness of CFI solutions with existing exploits, including:
• Advanced exploits that could bypass other defenses, including
• Exploits against known vulnerabilities, including certain CVE
vulnerabilities from the National Vulnerability Database (NVD).
• Exploits against test suites consisting of crafted vulnerable pro-
COOP [51], ROP [49] and SROP [7] attacks.
It refers to validating the ef-
grams, e.g., the buffer overflow testbed RIPE [65].
If a CFI mechanism fails to pass the experimental verification,
it is clear that the security guarantee of this CFI is weak. How-
ever, passing all the experimental verification cannot reveal how
strong a security guarantee the CFI mechanism provides, since the
verification benchmark is of limited range and cannot iterate all
possibilities. For instance, the RIPE testbed only considers a limited
number of buffer overflow vulnerabilities. There could be many
other types of vulnerabilities and exploit skills in practice.
3.1.3 Quantitative Analysis. Quantitative analysis refers to
evaluating the security strength of CFI mechanisms in a quanti-
tative way, enabling direct comparison between different mecha-
nisms. Existing CFI solutions widely use three common indicators
to demonstrate their security strengths, i.e., number and length of
code gadgets, Average Indirect target Reduction (AIR), and number
of theoretically allowed targets.
Number of code gadgets. Modern control flow hijacking at-
tacks, e.g., ROP and COOP, usually rely on existing code gadgets
to bypass deployed defenses. Attacks are more likely to succeed if
more code gadgets are available, since more choices are available
for payload construction. After deploying a CFI mechanism, the
number of available code gadgets would change.
Therefore, some CFI solutions, e.g., CCFIR [72], [22], CCFI [36],
BinCFI [75] and Opaque CFI [37], evaluate the number of code
gadgets available before and after deploying CFI. A CFI mecha-
nism with a smaller number of gadgets in general (but not always)
provides a stronger security guarantee.
However, the number of gadgets measured by different testing
tools may vary. So, a unified evaluation tool is required to make
fair comparison. On the other hand, this method only demonstrates
the security guarantee to some extent, and cannot reflect the exact
boundary enforced by each CFI mechanism.
Average indirect target reduction (AIR). After deploying a
CFI mechanism, each ICT could only jump to a limited number of
targets. This AIR method represents the percentage of ICT targets
blocked by each CFI mechanism. It was first proposed in BinCFI [75],
and has been widely used by many papers.
But researchers [23] [56] have pointed out that, this method
could not reasonably reflect the effectiveness of CFI. A coarse-
grained CFI mechanism could also have an AIR value higher than
99%, but provides a poor security guarantee, which means that AIR
cannot clearly reflect the difference in safety strength between the
coarse-grained CFI scheme and the fine-grained CFI scheme.
Number of targets theoretically allowed by CFI. Instead of
AIR, some CFI solutions directly evaluate the number of targets
of each ICT instruction allowed by the CFI policy in theory. This
number represents the claimed boundary of security guarantees
provided by the CFI. The smaller the number is, the stronger the se-
curity guarantee is. For static CFI mechanisms, e.g., TypeArmor [58],
this number is determined by the statically computed CFG, varying
along with the precision of CFG. For dynamical CFI mechanisms,
e.g., OS-CFI [31] and CFI-LB [30], this number is reduced by refining