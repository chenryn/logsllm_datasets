Trying 127.0.0.1...
Connected to localhost.localdomain (127.0.0.1).
Escape character is '^]'.
Hello world! 
OK
```
Flume的终端里面会以log的形式输出这个收到的Event内容。
``` properties
12/06/19 15:32:19 INFO source.NetcatSource: Source starting
12/06/19 15:32:19 INFO source.NetcatSource: Created serverSocket:sun.nio.ch.ServerSocketChannelImpl[/127.0.0.1:44444]
12/06/19 15:32:34 INFO sink.LoggerSink: Event: { headers:{} body: 48 65 6C 6C 6F 20 77 6F 72 6C 64 21 0D          Hello world!. }
```
恭喜你！到此你已经成功配置并运行了一个Flume
Agent，接下来的章节我们会介绍更多关于Agent的配置。
#### 在配置文件里面自定义环境变量
Flume可以替换配置文件中的环境变量，例如：
``` none
a1.sources = r1
a1.sources.r1.type = netcat
a1.sources.r1.bind = 0.0.0.0
a1.sources.r1.port = ${NC_PORT}
a1.sources.r1.channels = c1
```
::: warning
::: title
Warning
:::
注意了，目前只允许在value里面使用环境变量（也就是说只能在等号右边用，左边不行）
:::
启动Agent时候加上 *propertiesImplementation =
org.apache.flume.node.EnvVarResolverProperties* 就可以了。
例如：
``` none
$ NC_PORT=44444 bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console -DpropertiesImplementation=org.apache.flume.node.EnvVarResolverProperties
```
::: warning
::: title
Warning
:::
上面仅仅是个例子，环境变量可以用其他方式配置，比如在conf/flume-env.sh里面设置。
:::
#### 输出原始数据到日志
通常情况下在生产环境下记录数据流中的原始数据到日志是不可取的行为，因为可能泄露敏感信息或者是安全相关的配置，比如秘钥之类的。默认情况下Flume不会向日志中输出这些信息，如果Flume出了异常，Flume会尝试提供调试错误的线索。
有一个办法能把原始的数据流都输出到日志，就是配置一个额外的内存Channel（
[Memory Channel](#memory-channel) ） 和 [Logger Sink](#logger-sink)
，Logger
Sink可以输出所有的Event数据到Flume的日志，然而这个方法并不是适用所有情况。
为了记录Event和配置相关的数据，必须设置一些java系统属性在log4j配置文件中。
为了记录配置相关的日志，可以通过-Dorg.apache.flume.log.printconfig=true来开启，可以在启动脚本或者flume-env.sh的JAVA_OPTS来配置这个属性。
通过设置-Dorg.apache.flume.log.rawdata=true来开启记录原始日志，对于大多数组件log4j的日志级别需要设置到DEBUG或者TRACE才能保证日志能输出到Flume的日志里面。
下面这个是开启记录Event原始数据，并且设置logj的日志级别为DEBUG的输出到console的脚本
``` none
$ bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=DEBUG,console -Dorg.apache.flume.log.printconfig=true -Dorg.apache.flume.log.rawdata=true
```
#### 基于Zookeeper的配置
Flume支持使用Zookeeper配置Agent。\**这是个实验性的功能*\*。配置文件需要上传到zookeeper中，在一个可配置前缀下。配置文件存储在Zookeeper节点数据里。下面是a1
和 a2 Agent在Zookeeper节点树的配置情况。
``` none
- /flume
 |- /a1 [Agent config file]
 |- /a2 [Agent config file]
```
上传好了配置文件后，可以使用下面的脚本参数进行启动：
``` none
$ bin/flume-ng agent --conf conf -z zkhost:2181,zkhost1:2181 -p /flume --name a1 -Dflume.root.logger=INFO,console
```
  参数名   默认值   描述
  -------- -------- -----------------------------------------------------
  **z**    \--      Zookeeper的连接，hostname:port格式 ，多个用逗号分开
  **p**    /flume   Zookeeper中存储Agent配置的目录
#### 安装第三方插件
Flume有完整的插件架构。尽管Flume已经提供了很多现成的source、channel、sink、serializer可用。
然而通过把自定义组件的jar包添加到flume-env.sh文件的FLUME_CLASSPATH
变量中使用自定义的组件也是常有的事。现在Flume支持在一个特定的文件夹自动获取组件，这个文件夹就是pluguins.d。这样使得插件的包管理、调试、错误定位更加容易方便，尤其是依赖包的冲突处理。
##### plugins.d文件夹
`plugins.d` 文件夹的所在位置是 *\$FLUME_HOME/plugins.d* ，在启动时
*flume-ng* 会启动脚本检查这个文件夹把符合格式的插件添加到系统中。
##### 插件的目录结构
每个插件（也就是 `plugins.d` 下的子文件夹）都可以有三个子文件夹：
1.  lib - 插件自己的jar包
2.  libext - 插件依赖的其他所有jar包
3.  native - 依赖的一些本地库文件，比如 *.so* 文件
下面是两个插件的目录结构例子：
``` none
plugins.d/
plugins.d/custom-source-1/
plugins.d/custom-source-1/lib/my-source.jar
plugins.d/custom-source-1/libext/spring-core-2.5.6.jar
plugins.d/custom-source-2/
plugins.d/custom-source-2/lib/custom.jar
plugins.d/custom-source-2/native/gettext.so
```
### 数据获取方式
Flume支持多种从外部获取数据的方式。
#### RPC
Flume发行版中包含的Avro客户端可以使用avro RPC机制将给定文件发送到Flume
Avro Source：
``` none
$ bin/flume-ng avro-client -H localhost -p 41414 -F /usr/logs/log.10
```
上面的命令会将/usr/logs/log.10的内容发送到监听该端口的Flume Source。
#### 执行命令
Flume提供了一个 [Exec Source](#exec-source)
，通过执行系统命令来获得持续的数据流，按照\\r或者\\n或者\\r\\n（\\n\\r）来划分数据行，然后把每行解析成为一个Event。
#### 网络流
Flume支持以下比较流行的日志类型读取：
1.  Avro
2.  Thrift
3.  Syslog
4.  Netcat
::: hint
::: title
Hint
:::
个人认为除了前面的rpc、系统命令、网络流，还有一类很重要的Source就是从文件获取数据，比如
[Spooling Directory Source](#spooling-directory-source) 和 [Taildir
Source](#taildir-source)
，可以用它们来监控应用服务产生的日志并进行收集。
:::
### 多Agent的复杂流
::: hint
::: title
Hint
:::
这一小节介绍了几种典型的Flume的多Agent以及一个Agent中多路输出等部署方式。
:::
![](images/UserGuide_image03.png){.align-center}
这个例子里面为了能让数据流在多个Agent之间传输，前一个Agent的sink必须和后一个Agent的source都需要设置为avro类型并且指向相同的hostname（或者IP）和端口。
### 组合
日志收集场景中比较常见的是数百个日志生产者发送数据到几个日志消费者Agent上，然后消费者Agent负责把数据发送到存储系统。例如从数百个web服务器收集的日志发送到十几个Agent上，然后由十几个Agent写入到HDFS集群。
![](images/UserGuide_image02.png){.align-center}
可以通过使用 Avro Sink 配置多个第一层
Agent（Agent1、Agent2、Agent3），所有第一层Agent的Sink都指向下一级同一个Agent（Agent4）的
Avro Source上（同样你也可以使用 thrift 协议的 Source 和 Sink
来代替）。Agent4 上的 Source 将 Event 合并到一个 channel 中，该
channel中的Event最终由HDFS Sink 消费发送到最终目的地。
::: hint
::: title
Hint
:::
官方这个图的Agent4的Sink画错了，不应该是 [Avro Sink](#avro-sink)
，应该是 [HDFS Sink](#hdfs-sink) 。
:::
### 多路复用流
Flume支持多路复用数据流到一个或多个目的地。这是通过使用一个流的\[多路复用器\]（multiplexer）来实现的，它可以
**复制** 或者 **选择（多路复用）** 数据流到一个或多个channel上。
::: hint
::: title
Hint
:::
很容易理解， **复制**
就是每个channel的数据都是完全一样的，每一个channel上都有完整的数据流集合。
**选择（多路复用）**
就是通过自定义一个分配机制，把数据流拆分到多个channel上。后面有详细介绍，请参考
[Flume Channel Selectors](#flume-channel-selectors) 。
:::
![](images/UserGuide_image01.png){.align-center}
上图的例子展示了从Agent foo扇出流到多个channel中。这种扇出的机制可以是
**复制** 或者 **选择（多路复用）**
。当配置为复制的时候，每个Event都会被发送到3个channel上。当配置为选择（多路复用）的时候，当Event的某个属性与配置的值相匹配时会被发送到对应的channel。
例如Event的属性txnType是customer时，Event被发送到channel1和channel3，如果txnType的值是vendor时，Event被发送到channel2，其他值一律发送到channel3，这种规则是可以通过配置来实现的。
::: hint
::: title
Hint
:::
好了做一个总结吧，本章内容是这个文档最重要的一章，让你知道Flume都有哪些组件、配置方式、启动方式、使用第三方插件、以及一些实际使用中的复杂流的部署方案等等。下一章开始逐个介绍每一个组件。
:::
## 配置
如前面部分所述，Flume
Agent程序配置是从类似于具有分级属性设置的Java属性文件格式的文件中读取的。
::: hint
::: title
Hint
:::
这一章开始详细介绍Flume的source、sink、channel三大组件和其他几个组件channel
selector、sink
processor、serializer、interceptor的配置、使用方法和各自的适用范围。
如果硬要翻译这些组件的话，三大组件分别是数据源（source）、数据目的地（sink）和缓冲池（channel）。其他几个分别是Event多路复用的channel选择器（channel
selector）， Sink组逻辑处理器（sink
processor）、序列化器（serializer）、拦截器（interceptor）。
:::
### 定义流