### International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment
Springer, 3–24.

### Session 3E: Fuzzing/Trusted Execution Environments
CCS '20, November 9–13, 2020, Virtual Event, USA

#### References
[52] Andrew Sloss, Dominic Symes, and Chris Wright. 2004. *ARM System Developer’s Guide: Designing and Optimizing System Software*. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.

[53] Raoul Strackx and Frank Piessens. 2016. "Ariadne: A Minimal Approach to State Continuity." In *Proceedings of the USENIX Security Symposium*.

[54] He Sun, Kun Sun, Yuewu Wang, and Jiwu Jing. 2015. "TrustOTP: Transforming Smartphones into Secure One-Time Password." In *Proceedings of the ACM Computer and Communications Security (CCS)*.

[55] He Sun, Kun Sun, Yuewu Wang, Jiwu Jing, and Haining Wang. 2015. "TrustICE: Hardware-Assisted Isolated Computing Environments on Mobile Devices." In *Proceedings of the IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)*.

[56] Min Hong Yun and Lin Zhong. 2019. "Ginseng: Keeping Secrets in Registers When You Distrust the Operating System." In *NDSS*.

[57] Fengzhe Zhang, Jin Chen, Haibo Chen, and Binyu Zang. 2011. "Cloudvisor: Retrofitting Protection of Virtual Machines in Multi-Tenant Cloud with Nested Virtualization." In *Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles*, 203–216.

[58] Ning Zhang, He Sun, Kun Sun, Wenjing Lou, and Y. Thomas Hou. 2016. "CacheKit: Evading Memory Introspection Using Cache Incoherence." In *Proceedings of the 2016 IEEE European Symposium on Security and Privacy (EuroS&P)*. IEEE, 337–352.

[59] Ning Zhang, Kun Sun, Wenjing Lou, and Y. Thomas Hou. 2016. "CASE: Cache-Assisted Secure Execution on ARM Processors." In *Proceedings of the 2016 IEEE Symposium on Security and Privacy (SP)*. IEEE, 72–90.

[60] Ning Zhang, Kun Sun, Deborah Shands, Wenjing Lou, and Y. Thomas Hou. 2016. "TruSpy: Cache Side-Channel Information Leakage from the Secure World on ARM Devices." *IACR Cryptology ePrint Archive* 2016 (2016), 980.

[61] Shijun Zhao, Qianying Zhang, Yu Qin, Wei Feng, and Dengguo Feng. 2019. "SecTEE: A Software-based Approach to Secure Enclave Architecture Using TEE." In *Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security*, 1723–1740.

### The Impact of the Shareability Attribute on ARM Processors
We conducted a series of experiments to better understand the impact of the shareability attribute on non-secure L1 data caches [5]. These experiments were performed on the i.MX6Quad Sabre development board, which is equipped with a quad-core ARM Cortex-A9 processor running at 1.2 GHz and 1 GB DDR3 SDRAM. Since the board has only one cluster, the inner and outer shareability domains are equivalent. Therefore, the inner shareable attribute has the same effect as the outer shareable attribute. The shareability attribute is used to enforce value coherence when the same data is accessed by multiple cores. We made all four cores access the same physical memory (hereinafter referred to as test memory) and ran them in the normal world, ensuring that the L1 cache accessed by them was non-secure. To eliminate potential impacts on the L1 cache introduced through the L2 cache and memory, we disabled the L2 cache and set the test memory as secure memory. We chose to set the test memory as secure rather than using the memory isolation scheme in SANCTUARY, as that scheme is only simulated through ARM Fast Models virtualization tools and is not achievable on actual development boards. To prevent external aborts due to accessing secure memory from the normal world, we set the test memory as write-back, write-allocate, and all other memory as non-cacheable. This ensures that writing to the test memory is buffered and locked in the L1 cache, and not synchronized to memory. The test memory and the corresponding L1 data cache were initialized to zero.

#### Data Coherency with Shareability Attribute Enabled
We first investigated the impact of data coherency when enabling the shareability attribute. Specifically, we set the test memory as shareable for all four cores. We then stored (i.e., wrote) 0xffff to core_0’s L1 data cache mapping to the test memory and loaded (i.e., read) the L1 data cache of each core addressed through the test memory.

**Table 1: L1 Cache When Enabling Shareable Attribute**

| Core | Shareability Attribute | Value on L1 Data Cache After Writing 0xffff to Core_0 | Value on L1 Data Cache After Writing 0xdddd to Core_1 |
|------|------------------------|-------------------------------------------------------|-------------------------------------------------------|
| Core_0 (Shareable) | 0xffff | 0xffff | 0xdddd |
| Core_1 (Shareable) | 0xffff | 0xffff | 0xdddd |
| Core_2 (Shareable) | 0xffff | 0xffff | 0xdddd |
| Core_3 (Shareable) | 0xffff | 0xffff | 0xdddd |

As shown in Table 1, the value 0xffff on core_0’s L1 data cache was synchronized to the other three cores. Subsequently, we stored 0xdddd to core_1’s L1 data cache and found that all cores’ L1 data caches were synchronized again. This demonstrates that data on one core’s L1 data cache can be leaked and manipulated by another core when both cores run in the normal world and the corresponding memory is set as shareable for both cores.

#### Data Coherency with Shareability Attribute Disabled
We also examined the results when disabling the shareability attribute. We modified the test memory’s cache attribute to non-shareable (i.e., inner and outer non-shareable) for core_0 and repeated the experiment.

**Table 2: L1 Cache When Disabling Shareable Attribute**

| Core | Shareability Attribute | Value on L1 Data Cache After Writing 0xffff to Core_0 | Value on L1 Data Cache After Writing 0xdddd to Core_1 |
|------|------------------------|-------------------------------------------------------|-------------------------------------------------------|
| Core_0 (Non-shareable) | 0xffff | 0x0 | 0x0 |
| Core_1 (Shareable) | 0x0 | 0x0 | 0xdddd |
| Core_2 (Shareable) | 0x0 | 0x0 | 0xdddd |
| Core_3 (Shareable) | 0x0 | 0x0 | 0xdddd |

As illustrated in Table 2, the data on core_0’s L1 data cache could not be leaked or manipulated by the other cores when the corresponding memory was set as non-shareable for core_0.

To set different cache attributes for multiple cores accessing the same physical memory region (i.e., the test memory), we constructed four page table entries, each mapping to the same physical memory region but defining different cache attributes. After assigning one entry to each core, the four cores could access the same memory region with different cache attributes.

### Evaluation of the Defense System
We evaluated the overhead introduced by our defense system based on a prototype implemented on the i.MX6Quad SABRE development board, which is equipped with a quad-core ARM Cortex-A9 processor running at 1.2 GHz with 1 GB DDR3 SDRAM. To minimize noise in the experiments, we ran each test with 1,000 iterations and reported the average.

#### Overhead on Security-Sensitive Applications
We first explored the overhead on security-sensitive applications due to enforced cache attributes. We ran an AES encryption application in one IEE and evaluated its execution time with different cache attribute configurations.

**Table 3: AES Encryption Time (in Milliseconds)**

| Payload (Bytes) | Default Configuration (S, WB, WA, With L2) | Non-S, WT, non-WA, With L2 | Non-S, WT, non-WA, Without L2 |
|-----------------|--------------------------------------------|----------------------------|--------------------------------|
| 1024            | 3.9                                        | 7.5                        | 15.4                           |
| 2048            | 6.8                                        | 13.4                       | 28.7                           |
| 4096            | 4.5                                        | 8.8                        | 18.1                           |

- **"S, WB, WA, With L2"**: Shareable, inner write-back write-allocate, outer write-back write-allocate.
- **"Non-S, WT, non-WA, With L2"**: Non-shareable, inner write-through non write-allocate, outer write-through non write-allocate.
- **"Non-S, WT, non-WA, Without L2"**: Non-shareable, inner write-through non write-allocate, outer non-cacheable.

The experimental results show that our defense system introduces approximately 90% overhead compared to the default setting, primarily due to disabling the L2 cache. For IEE systems that disable the L2 cache for protection (e.g., SANCTUARY), our defense system introduces negligible additional overhead.

#### Overhead on the Rich OS
We evaluated the overhead on the rich OS introduced by the additional cross-domain context switches enforced on each page table updating operation. We used a comprehensive benchmark suite, AnTuTu 2.9.4 [3], to measure performance in integer computation, floating-point operations, 2D and 3D graphic rendering, etc.

**Table 4: Benchmark Results on Rich OS**

| Test Item       | Protection Disabled | Protection Enabled | Overhead (%) |
|-----------------|---------------------|--------------------|--------------|
| RAM             | 486                 | 475                | 2.26         |
| CPU Integer     | 698                 | 692                | 0.86         |
| CPU Float-point | 567                 | 564                | 0.53         |
| 2D Graphics     | 282                 | 281                | 0.35         |
| 3D Graphics     | 861                 | 852                | 1.05         |
| Database I/O    | 310                 | 255                | 17.74        |
| SD Card Write   | 38                  | 36                 | 5.26         |
| SD Card Read    | 186                 | 182                | 2.15         |
| Total           | 3428                | 3337               | 2.65         |

The primary reason for the 17.74% overhead on Database I/O operations is the need to build numerous page table mappings when copying data from the disk to memory.

We also evaluated the overhead on operations involving frequent page table updates, such as system booting and application loading.

**Table 5: Loading Time Results on Rich OS (in Seconds)**

| Test Item      | Protection Disabled | Protection Enabled | Overhead (%) |
|----------------|---------------------|--------------------|--------------|
| Kernel         | 22.26               | 23.71              | 6.51         |
| Android Home   | 87.42               | 89.81              | 2.73         |
| Calculator     | 3.01                | 3.22               | 6.98         |
| Calendar       | 3.14                | 3.34               | 6.37         |
| Music          | 1.26                | 1.37               | 8.73         |
| Settings       | 3.77                | 3.95               | 4.77         |

Overall, the loading overhead for both the kernel and applications is less than 10% in all evaluation scenarios.