Every SGX worker node is configured to execute the SGX-LKL
library. AMD servers are used to execute SEV instances. During
the worker’s launch process, an SGX-LKL-based Intel remote at-
testation similar to [38] is used by the Cloud Resource Management
subsystem to verify the trustworthiness of Intel SGX CPU and
SGX-LKL enclave and to send the application configuration (i.e.,
disk encryption key) remotely. Besides, AMD guest attestation [29]
should be used to launch and verify the SEV instances. Note that at
SecDATAVIEW: A Secure Big Data Workflow Management System for Heterogeneous Computing Environments
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
the time we wrote this paper, the Intel remote attestation feature
was not fully integrated into the release of SGX-LKL [54], and we
leave the implementation of remote attestation for future work.
Nevertheless, the WCPAC protocol assumes that such a protocol is
incorporated, and the SGX and SEV worker nodes would use and
pass the remote attestation upon the request of the Cloud Resource
Management subsystem. Besides, the WCPAC protocol assumes
that the approaches used by TEE hardware vendors (i.e., SGX-LKL
and AMD SEV) to launch and access the disk images are secure.
The SecDATAVIEW master node is deployed on a trusted on-
premises server whose security is ensured. SecDATAVIEW will
provision as many worker nodes as necessary from a given hetero-
geneous computing environment to execute a particular workflow.
During the execution, SecDATAVIEW dynamically deploys a Code
Provisioner and a Task Executor on each worker node using the WC-
PAC protocol. The remaining components of SecDATAVIEW will
run on the trusted on-premises server. Figure 3 shows the commu-
nication diagram of the WCPAC protocol. The detailed sequence
diagram of the WCPAC protocol is provided in the Appendix 7.
Firstly, the Workflow Executor activates the Cloud Resource Man-
agement module with a request specifying the machine type (i.e.
SGX/SEV) to initialize the worker nodes – Step (a) in Figure 3.
When a worker node is an SGX node, then the Cloud Resource Man-
agement module sends the SGX-LKL disk image to the worker node
and activates SGX-LKL over ssh, which runs the stand-alone sftp
server inside an SGX-LKL enclave, with the Intel remote attestation
protocol. When a worker node is a SEV, then the Cloud Resource
Management module sends the SEV disk image to the worker node,
activates the SEV over ssh, and runs the stand-alone sftp server
inside the SEV-protected VM with the AMD guest attestation pro-
tocol. Upon successful initialization, all worker nodes have active
sftp server – Step (b) in Figure 3. At this step, the Cloud Resource
Management module returns the control to the Workflow Execu-
tor. The Workflow Executor then activates the Code Provisioning
Attestation module, which computes the SHA256 digest of the Code
Provisioner file and stores the digest in its memory – Step (c) in Fig-
ure 3. Besides, the Code Provisioning Attestation module randomly
generates an encryption key and stores the key in its memory.
The Code Provisioning Attestation module then encrypts the Task
Executor with the generated key and sends the Code Provisioner, the
SSL certificates of the Code Provisioner, as well as the encrypted Task
Executor to the SGX enclave or SEV instance through sftp – Step
(d) in Figure 3. The stand-alone sftp server process dynamically ac-
tivates the Code Provisioner through Java reflection and class loader,
transfers the control to the Code Provisioner, and terminates the
sftp server. The Code Provisioner then computes the SHA256 digest
on its file (self-integrity inspection), initiates a new sftp server as
part of a new running thread for the secure file transfer, opens a
new SSL socket to communicate with the Code Provisioning Attesta-
tion module, and sends its SHA256 digest to the Code Provisioning
Attestation module through the SSL socket – Steps (e) and (f) in
Figure 3.
After the Code Provisioning Attestation module receives the Code
Provisioner’s SHA256 digest, the Code Provisioning Attestation mod-
ule compares the SHA256 digest against the digest stored in its
memory to ensure that Code Provisioner is not altered. With this
Table 1: Testbeds Configuration.
SecDATAVIEW Master
Testbed Machine
Intel Core i7-6700T
CPU Model
4
CPU Core
8
CPU Thread
2.8GHz
CPU Base Clock
3.6GHz
CPU Boost Clock
Smart Cache
Cache Type
8MB
Cache Size
Dell Inspiron 24-5459
Motherboard
12GB DDR4 Non-ECC
Memory
Conventional HDD
Storage
Ubuntu 16.04 LTS
Hypervisor/OS
4.15.0-50-generic-x64
Kernel Version
N/A
SGX SDK Version
N/A
SGX-LKL
SGX-LKL Memory N/A
N/A
SGX-LKL Storage
N/A
SEV VM Kernel
N/A
SEV VM Memory
N/A
SEV VM Storage
AMD SEV
Intel SGX
EPYC 7251
Intel Xeon E3-1275 v5
8
4
16
8
2.1GHz
3.6GHz
2.9GHz
4GHz
L3
Smart Cache
32MB
8MB
GIGABYTE MZ31-AR0
Intel FOG
32GB ECC
32GB DDR4 Non-ECC
SATA SSD
NVME SSD
Ubuntu 18.04 LTS
Ubuntu 16.04 LTS
4.20.0-sev-x64
4.15.0-50-generic x64
N/A
Ver 2.0
N/A
Hardware Mode
2GB (Encrypted)
N/A
2GB (Encrypted Disk Image) N/A
N/A
N/A
N/A
4.18.20-generic-x64
4GB (Encrypted)
32GB (Disk Image)
technique we enforce another check on the Code Provisioner to cap-
ture any possible network or other flaws during code transferring
event. If the digest does not match, the job is terminated; otherwise,
the Code Provisioning Attestation module sends the Task Executor’s
decryption key to the Code Provisioner. In addition, the Code Provi-
sioning Attestation module sends the encrypted workflow’s input
data, the Task Executor’s configuration, and the Task Executor’s
SSL certificate through sftp. After the success of attestation and
file transfer, the control is returned to the Workflow Executor from
the Code Provisioning Attestation – Steps (g) and (h) in Figure 3.
Upon receiving the Task Executor’s decryption key and all the
dependency files, the Code Provisioner module decrypts the Task
Executor, and dynamically activates the Task Executor using the
Java reflection and class loader. The Code Provisioner terminates
and the control is transferred to the Task Executor – Step (i) in
Figure 3.
The Task Executor is initialized, and a new SSL socket with its SSL
certificate is started as part of the Task Executor running threads.
At this moment, the communication between Workflow Executor
and Task Executor is secured and the Task Executor completes all
assigned tasks based on the local workflow schedule it receives from
the Workflow Executor. The output results are sent through sftp to
the children worker nodes in the workflow or send back to the user
in the encrypted form, and the Task Executor terminates – Steps
(j) and (k) in Figure 3. It is noteworthy that the workflow’s data
cryptography key is carried with the Task Executor and is used for
the encryption and decryption purpose throughout the workflow
execution. The data owner generates and encrypts the input files
with a provided cryptography tool, and the secret key is compiled
as part of the Task Executor and is securely transferred to and
decrypted in the trustworthy worker nodes. Also, all trustworthy
worker nodes share the same cryptography key, so the data received
from parent nodes could be decrypted in the children nodes in the
workflow and vice versa.
4 EVALUATION
This section presents the evaluation results of SecDATAVIEW. Specif-
ically, we aim to answer three research questions:
Sect. 4.1: What is the performance overhead of running workflows
inside SecDATAVIEW?
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
S. Mofrad et al.
Sect. 4.2: Does SecDATAVIEW preserve its security properties?
Sect. 4.3: How is SecDATAVIEW compared with other systems?
We used an Intel-based processor machine as the SecDATAVIEW
master node, two Intel SGX machines, and two SEV-protected VMs
that are running on one AMD EPYC server to conduct experiments.
• The SecDATAVIEW master node has Intel Core i7-6700T 3.6GHz
CPU with 4 physical cores and 8 logical threads, 8MB of smart
cache, 12GB of DDR4 non-ECC RAM, and a conventional HDD
storage, running Ubuntu 16.04 LTS with the kernel version 4.15.0-
50-generic-x64.
• The SGX machines have Intel Xeon E3-1275 v5 4GHz CPU with
4 physical cores and 8 logical threads, 8MB smart cache, 32GB
DDR4 non-ECC RAM, and an NVME SSD storage. Ubuntu 16.04
LTS with kernel version 4.15.0-50-generic x64 and SGX SDK
version 2.0 were installed on SGX machines.
• The AMD machine has an AMD EPYC 7251 2.9GHz CPU with 8
physical cores and 16 logical threads, 32MB L3 cache, 32GB of
DDR4 RAM, and 512GB SATA SSD, running Ubuntu 18.04 LTS
with kernel 4.20.0-sev. Two SEV-protected VMs were used in our
experiments. Each VM was assigned 4GB of memory, 4 CPU cores,
and 32GB storage. Ubuntu 18.04 LTS with 4.18.20-generic-x64
kernel was installed in each SEV-protected VM.
• We have also installed Java version 1.8 on all machines and com-
piled the latest SGX-LKL software in hardware mode on SGX
machines. All machines are connected with a 100Mb LAN inter-
face thus making a heterogeneous cluster of five nodes.
4.1 Workflow Performance Evaluation
We used three different types of workflows in our experiments: the
Diagnosis Recommendation workflow [3], the Word Count work-
flow, a.k.a. the Map-Reduce workflow [16], and the Distributed
K-means workflow [27]. We measured the performance overhead
incurred by SGX/SEV in terms of the execution time and the mem-
ory usage for each workflow in eight different configurations:
• SGX inactive without data encryption: in this configuration,
all workflow tasks are running outside of enclaves on SGX worker
nodes. Task code is encrypted and data is not encrypted.
• SGX inactive with data encryption: in this configuration, all
workflow tasks are running outside of enclaves on SGX worker
nodes. Task code and data are encrypted during network transfer
and then decrypted before their usage.
• SGX active with data encryption: in this configuration, all
workflow tasks are running inside of enclaves on SGX worker
nodes. Both task code and data are encrypted during network
transfer and then decrypted before their usage.
• SEV inactive without data encryption: in this configuration,
all workflow tasks are running on SEV worker nodes but the
SEV feature is not used. Task code is encrypted and data is not
encrypted.
• SEV inactive with data encryption: in this configuration, all
workflow tasks are running on SEV worker nodes but the SEV
feature is not used. Both task code and data are encrypted during
network transfer and then decrypted before their usage.
• SEV active with data encryption: in this configuration, all
workflow tasks are running on SEV worker nodes with the SEV
feature used. Both task code and data are encrypted during net-
work transfer and then decrypted before their usage.
• Hybrid inactive with data encryption: in this configuration,
workflow tasks are running on a mixed setting of SGX and SEV
worker nodes without using the features of SGX and SEV. Both
task code and data are encrypted during network transfer and
then decrypted before their usage.
• Hybrid active with data encryption: in this configuration,
workflow tasks are running on a mixed setting of SGX and SEV
worker nodes with the use of the features of SGX and SEV. Both
task code and data are encrypted during network transfer and
then decrypted before their usage.
All experiments were conducted with 2GB SGX heap and 4GB
SEV RAM and 1GB JVM heap memory space. Our experiments tar-
get an extreme scenario in which all workflow tasks are scheduled
on the same SGX/SEV worker node. These experiments are used to
measure the maximum possible overhead of SecDATAVIEW. In our
experiments, the memory footprint and heap size are larger than
the SGX EPC memory and communication between two workflow
tasks are encrypted. To measure the execution time, we have started
a timer in the Workflow Executor module that is initiated before the
activation of Task Executor and ends when the workflow finishes
execution. The reported results represent the aggregated perfor-
mance and overhead incurred by SGX-LKL/SEV instance runtime,
secure network stack, read/write access inside the SGX-LKL and
SEV disk image, file encryption/decryption, file transfer between
worker nodes, and secure execution of workflow tasks.
4.1.1 The Diagnosis Recommendation workflow. The diagnosis rec-
ommendation workflow is a real-life diagnosis workflow [3] that
uses machine learning methods and raw textual dataset as a pre-
scription for a group of patients. We synthetically created 10, 000 −
100, 000 patient records with an average length of 150 characters