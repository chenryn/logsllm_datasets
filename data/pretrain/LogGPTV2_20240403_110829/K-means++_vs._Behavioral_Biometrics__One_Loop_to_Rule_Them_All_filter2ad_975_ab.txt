users never quite got used to it, hence their typing
patterns weren’t sufﬁciently unique. In the MTurk
dataset the passwords are common English words, so
the users should be used to them from the start.
• We wanted to ensure that our results, particularly
for the adversarial attacks,
translate to real world
scenarios where the data would typically be collected
on the Internet.
• We wanted to replicate the results across a much larger
sample pool, and across different passwords.
Touchscreen swipes dataset: This touchscreen swipes dataset
was collected by Antal et al. [4] using a psychological per-
sonality based questionnaire on an Android smartphone. The
published paper has their analysis with various classiﬁers for
40 users, but since then, they have published a bigger dataset
with 98 users [3], which is what we used in our experiments.
2) Features: For both the keystroke datasets mentioned
above, we used the following three features, proposed by
Killourhy-Maxion [19]:
•
•
•
Press-Release: Duration a key was held down for.
Release-Press: Delay between releasing a key, and
pressing the next one.
Press-Press: Delay between pressing the ﬁrst key and
the next key. This is just the sum of the previous two.
It is not particularly necessary to use this feature - but
since it was used in the paper by Maxion et al. [19],
we decided to stick with the convention.
For designing the Indiscriminate K-means++ adversary we
just used the ﬁrst two features, and derived the third feature
by taking their sum.
The touchscreen swipes dataset provided the following set
of 11 features:
•
•
•
•
duration: time between touch down and touch release
length of trajectory: the length of the segment deﬁned
by the two endpoints
average velocity: a fraction of the length of trajectory
and duration
acceleration start: the average acceleration at the ﬁrst
4 touch points
• mid-stroke pressure: the pressure at the middle point
• mid-stroke ﬁnger area: the ﬁnger area at the middle
of the swipe
point of the swipe
• mean pressure: average of pressures in touch points
• mean ﬁnger area: average of ﬁnger areas in touch
points
•
gravity (x-axis): average of x gravities in touch points
•
gravity (y-axis): average of y gravities in touch points
•
gravity (z-axis): average of z gravities in touch points
More information about the experimental setup for this
dataset can be obtained in [4].
A. Evaluating Classiﬁers
Equal Error Rate: An ideal authentication system would
always accept a genuine sample, and reject an impostor sam-
ple. In practice this is rarely the case. Thus, there are two
kinds of possible errors: rejecting a correct input, or the False
Reject Rate, (FRR), and accepting a wrong input, or the False
Accept Rate (FAR). To measure the performance of a system,
the keystroke dynamics literature focuses on Equal Error Rate
(EER) which is the error when the acceptance threshold of
a classiﬁer is set to the value at which the FAR is equal to
the FRR. EER is a value in the range [0, 1] and a lower EER
implies a lower error, and a better classiﬁer.
In practice, setting the acceptance threshold of a classiﬁer
leads to an important trade-off between security (avoiding false
acceptances) and usability (avoiding false rejections). Various
keystroke dynamics startups provide the client the ﬂexibility of
choosing higher levels of security in their API calls. Therefore,
to evaluate the effectiveness of our adversaries in this setting,
we also used thresholds of differing “strictness” which models
such a scenario.
B. Attack Intuition
At its extreme, the idea behind behavioral biometric au-
thentication is that every person has unique patterns of be-
havior. On the other extreme, we could consider the claim that
everyone’s behavioral patterns are the same. Clearly, the reality
must lie somewhere in between these two extreme viewpoints.
In the domain of keystroke dynamics, various classiﬁers have
been shown to be robust in distinguishing among genuine and
impostor samples. But our intuition suggests that there must be
signiﬁcant overlap between the typing samples of many users.
It is reasonable to imagine that each person’s “unique”
typing style is really part of a bigger family of similar user
styles. Thus, we hypothesize that the set of keystroke timing
patterns of all users are clustered into a limited, and relatively
small number of clusters, where users with similar typing
behaviors belong to the same cluster. Our idea is to mimic
the target user’s typing patterns by generating all such clusters
using data collected from the general population.
We support this hypothesis by analyzing the keystrokes
data from the DSN dataset. We analyze the data by running
K-means with different values of K and analyzing the average
distance of a sample to their closest cluster center. Figure 1
presents two plots, plot (a) represents the average distance of
a sample to the centroid of its cluster and plot (b) shows the
ﬁrst derivative of the function represented by plot (a). In the
presented ﬁgure, we can see that average distance remains
relatively similar with the increase in the number of clusters.
This is supported by Plot (b) as the derivative also ﬂattens out
at k = 10. This supports the hypothesis that most users don’t
belong to their own individual clusters.
C. Attack Model
Now, we anchor our attack model in the broader framework
of the taxonomy of adversarial algorithms described in section
IIB.
Evaluating Adversaries:
In terms of inﬂuence, our attack
model belongs to the “exploratory” category as it targets the
classiﬁer at test time. The security violation falls naturally
under the “integrity” category, as the adversary attempts to
bypass the security provided by the classiﬁcation system. In
terms of “speciﬁcity” - both targeted and indiscriminate model
attack scenarios that an adversary would be interested in. We
designed our two adversaries based on the distinctions between
these two scenarios. More speciﬁcally, we focused on a type
of probing attack, called the “Adversarial Classiﬁer Reverse
Engineering (ACRE)”, which was introduced by Lowd et al.
[21]. In this framework, given an attacker’s cost function,
the goal is to ﬁnd a lowest attacker-cost instance that the
classiﬁer labels as negative (i.e., it passes through). Various
other papers in the literature have used such a model [7], [28],
[29]. Speciﬁcally, we consider how many tries does it take an
adversary to compromise the security of a classiﬁer.
D. Adversary I: Targeted K-means++
Here we assume that the attacker has access to a large pool
of sample data (i.e., timings of many other users typing the
target user’s password), but does not have data from the user
they wish to impersonate. This is a reasonable scenario: The
attacker could get many user’s keystroke timing information
about a given password by simply asking people to type
the desired password on a paid crowdsourcing platform like
Amazon Mechanical Turk. This may be an expensive process -
but if the authentication system protects sensitive information,
this would not be a major obstacle for the attacker.
The aim of the adversary is to efﬁciently explore the
samples from different users in order to ﬁnd candidates from
the “cluster” of the target user. The simple approach here
would be to run K-means for a particular value of k and try all
the centroids. This performs reasonably, but it does not give us
any good way to choose a value of k. Also, since K-means is
a local search algorithm, its clusters can change considerably
for different values of k.
K-means++ is traditionally used as an initialization step
for the centroids of K-means. It uses an iterative algorithm
where the ﬁrst center is selected at random from the data,
and then each subsequent center is selected with a probability
proportional to its contribution to the overall error given the
previous selections. Intuitively, K-means++ exploits the fact
that a good clustering is relatively spread out,
thus when
selecting a new cluster center, preference should be given to
those further away from the previously selected centers. This
fact is crucial for designing our adversary: if we fail to break
the classiﬁer’s defenses with the try i, then the try i+1, would
ﬁnd a sample that is far away from the previous try - thus
increasing the likelihood that it lands closer to the space of
the target user’s samples.
Theoretically, it has a nice property that when running it
for k + 1 iterations, the ﬁrst k centers it generates are the same
ones as it would have generated had it been run for k iterations
in the ﬁrst place. These initial set of centers is also provably
close to the optimum solution [5]. As a result, using K-means
to generate queries would require O(K 2) queries to explore
cluster counts 1 through k, but using K-means++ only requires
k queries for the same goal.
Based on the properties above, we repurposed the K-
means++ algorithm, (see Algorithm 1), for this task. For the
4
(a) We ran K-means on the DSN dataset for different values of k. Here we
present average distances of a sample to their closest cluster center
(b) First derivative of Plot (a). This shows that the derivative ﬂattens around
k = 10. Thus, higher values of k do not improve the clustering by much.
(c) probability distribution of timing of digraph “an” while typing password
“.tieRoanl” in the DSN dataset.
(d) probability distribution of hold time of “n” while typing password
“letmein” in the MTurk dataset.
Fig. 1: Preliminary statistical analysis of keystrokes data
Algorithm 1 Adversarial Targeted K-means++
INITIALIZE T ry1 ← the mean of the collected adversarial
data set X
INITIALIZE Auth ← F alse
INITIALIZE i ← 2
while !Auth do
D(x) ← distance from nearest Try chosen so far to point
x (∀x ∈ X )
T ryi ← x ∈ X with probability
x(cid:48)∈X D(x(cid:48))2
Auth ← True if T ryi passes the authentication
i + +
(cid:80)
D(x)2
end while
ﬁrst try, rather than choosing it randomly from the data, we
select
the mean of the given samples. Each new centroid
selected by the algorithm comprises a new probe to the
5
detection algorithm.
E. Adversary II: Indiscriminate K-means++
The main shortcoming of the targeted scenario is that
collecting many samples for a single password is an expensive
task. For instance, if the attacker is just trying out many pass-
words recovered from a leaked database, collecting samples
for each one of them is highly impractical. So we design an
adversary who may be willing to sacriﬁce some accuracy for
convenience. In particular, the adversary may not be able to,
or may not want to, collect a large sample of keystroke data
for the target password. Instead, he may have access to a large
pre-computed database of user’s typing data. This scenario has
never been studied before in the keystroke dynamics literature.
The key insight for designing this adversary is that given
a target user’s password, we can generate reasonable timing
vectors if we have general population timing data for duration
of each key, and the time spent between successive key-presses.
Every digraph, e.g., “as”, and “at”, would follow a different
distribution. This could be due to several reasons, such as the
distance between the keys. But there are only a limited number
of such key-presses, and digraphs, possible - and it is not hard
to imagine that data could be collected, and made publicly
available, for all such cases. For instance, this could be done
using botnets and keyloggers to get data from unsuspecting
users.
The next challenge is generating the probability distribution
for each key-press and digraph. One possibility is to directly
sample from the empirical distribution (i.e., the collected data),
hoping that if it is sufﬁciently large, it may represent the
true population distribution. Instead, we chose to model it
with a roughly correct distribution. Based on eyeballing the
distributions (see Figure 1), we chose a Gaussian mixture
model with two components. One major advantage of this
approach is that it is the most practical - a database with
thousands or millions of samples for all possible digraph pairs
will become too large. But, in this scenario, the adversary
would only need to know the parameters of the distribu-
tion. More crucially, we did not wish to get the best ﬁtting
distribution - instead we wanted a convenient way that can
let us easily generate a lot of reasonable samples. Then, we
use this distribution to generate the desired sample size of
timing samples of the key-presses for the target password.
This situation is identical to the scenario for the Targeted K-
means++ adversary described above. Thus, for the ﬁnal step,
we use the K-means++ algorithm to ﬁnd the most efﬁcient
probes for the classiﬁer. The intuition here is that even if
our distribution is only a rough approximation of the real
distribution - we can still expect it to ﬁnd good probes by
just sampling efﬁciently from the whole space. This algorithm
is summarized in Algorithm 2.
We tested this adversary on each of the passwords in the
MTurk dataset. For every digraph in the target password, we
collected data with further experiments in which new users
typed different words that included those digraphs I. For each
digraph in the target password, we had the user type in two
words, ten times each, that included the same digraph. For
instance, when targeting “mustang”, we had two words that
include “mu”, two words that included “us”, etc. These words
were chosen randomly with the criterion that
they should
not have more than a two character subsequence in common
with the target password (e.g.,“must” has four characters in
common with mustang, so it was not used). In reality, if the
adversary has access to a large database of typing data, it is
likely that he may ﬁnd timing data on words that have a more
signiﬁcant overlap with the target password - especially since
so many passwords use dictionary words. This would clearly
only beneﬁt the adversary.
We tested this adversary only on the MTurk dataset as we
could control the method of timing extraction - the impostor
samples were collected using the same JavaScript code as the
target users data in the MTurk dataset, while the DSN dataset
was collected on a single computer, and we do not have access
to the software used to collect it, which would likely lead to
slightly different timing latencies.