Variable_name
[test]>show status like
由于这是一个 count 的操作，
count(u.userid)
row in set (0.05 sec)
rows in set (0.00 sec)
Handler_read_rnd_next
Handler_read_prev
Handler
Handler_read_first
-------
19991
19991
read
read_
read
users t
next
--+
-一十
|Value
where
|20001
'Handler_read%';
20002
，所以 Handler_read_rnd_next 的指标较高，这是一个范围
1999
2
t.userid=300 and account not in
我们来通过一个案例来了解下反连接的一些相关信息，看看如何做一些优化。
就是 not in，not exists 子句的形式，但和半连接相比，反连接带来的问题会更多一些。
如果大家了解了半连接的基本原理，对于反连接可以算是手到擒来，因为表现形式很简
注：in和 exists 在 MySQL 不同版本有着不同的解析方式，在 5.6 版本后，exists 的解
 ENGINE=InnoDB AUTO_INCREMENT=22676193 DEFAULT CHARSET=utf8
：
有
User@Host: root[root] @ localhost []
Time:1610139:51:45
有一天同事发现一条语句执行时间很长，感到非常奇怪，我们一起看了下这个问题，
MySQL 反连接
，测试每部分的性能和数据情况，逐步组合优化，我把整个 SQL 拆成了如
id:2F8E5A82
24630498
acc
from
dT
unt
fund_info
（account
Schema
cest
Last errno:1160 Killed:0
7551
第6章MySQL查询优化”247
Rows_examined:
---
## Page 270
248丨MySQL DBA工作笔记：数据库管理、架构优化与运维开发
竟然变得如此复杂。
看看里面的 Not in 的条件是怎么实现的，使用 explain extended 的方式，语句如下：
直匪夷所思。
据，得到1万条多数据，还是比较理想的，耗时不到1秒。
我们来进入第3个部分，这里我们不会执行 SQL了，而是需要解析SQL的执行明细，
可以看到整个解析的过程非常复杂，如图6-6所示，原本简单的一个语句，经过解析，
综合这两个部分来看，
select distinct(login_account) from t_user_login_record where login_time
那问题的瓶颈很可能在后面的子查询中了，执行第2部分。
1 row in set (0.99 sec)
在第1 部分中，从t_fund_info 这个表中，根据一个过滤条件能过滤掉绝大多数的数
where
第3部分
第2部分
select count(*)from t_fund_info where money >=300;
(select distinct(login_account) from t_user_login_record where loqin time
从查询的结果来看，过滤后的数据有50万条左右，从时长来看，大概耗时1分钟。
> select count(*) from t_fund_info where money >=300;
第1部分
count(*)
13528
money
300
300
and
and
一个耗时1秒，一个是1分钟，与实际执行17个小时相比简
account
account
not
notin
>='2016-06-01');
>='2016-06-01';
>='2016-06-01'
e019
---
## Page 271
得推荐的方案呢，为了验证，我复制了数据，在测试环境进行了模拟。
的表添加一个索引基于 login_account，这样就可以和外层的查询字段映射，提高查询效率。
下，按照1→3→2 的顺序效率是最佳的。
始终是在做全表扫描，即按照1→2→3的序号顺序执行。当然实际上，在保持不变的情况
后根据 not in 的逻辑来取舍数据，从这个角度来看，子查询里面因为关联的字段没有索引,
login_account 没有索引，所以是全表扫描)，同时关联子查询的过滤条件 login_time，然
account=login_account 的条件关联（此处
滤得到1万条数据，然后两个字段通过
的过滤条件为准，从200万条数据中过
来梳理一下这个性能问题的流程瓶颈。
这样一来整个流程就能说得通了，我们
的数据不是先走login_time的条件过滤，
相只有一个，那就是t_user_login_record
实在是组合不出来十几个小时，那么真
应的是 2000万，在 login_time的过滤条件下得到的是50万条数据。
。当然在一个数据量庞大、业务相对繁忙的系统中，添加一个临时需求的索引是否是值
首先这个查询的数据是以 t_fund_info
所以之前的独立查询1秒和1分钟,
Records: 0 Duplicates: 0 Warnings: 0
> create index ind_tmp_accountl on t_user_login_record(login_account);
到目前为止问题已经基本定位了，反连接的查询时，在这个问题场景中，需要对子查询
t_fund_info 对应的结果集是 200万条数据中的一万条左右，而 tuser_login_record 对
我来画一个图（图6-7）来解释一下，把两个表的关联关系和条件都列出来。
havng(testuseoginrerd.loinac）
isnull(test.t_user_login_record.login_account)
(test.tfund info.acount) = test.t use_login_recod.loginacount)
图6-6
tfund info
account
图6-7
ogin_time>=2016-06-01
tuser_login_record
login_account
第6章MySQL查询优化|249
---
## Page 272
250丨MySQL DBA工作笔记：数据库管理、架构优化与运维开发
字段，而索引idx_users 没有启用。
种表达式就叫做行值表达式，写为 SQL 就是类似下面这样的形式：
意，其他部门也可能有重名的同事，如果我们写 SQL 语句的话,where子句是这样的形式：
6.2.4
空间换时间的操作还是值得的。
掉也是不错的选择，或者是创建一个临时表，在临时表上添加索引来完成跑批任务，这种
差别。
们做一个简单的对比测试。
一个公司的三个同事，名字分别为张三（系统部），李四（开发部）和王五（运营部）。注
创建一张表 users，然后在不同的版本中执行同样的行值表达式语句看看执行计划的
在 MySQL 5.6 版本中，执行如下的语句，可以从 key_len 看到，只应用到了usermname
primary key(userid),
create table users(
在这种情况下，我们的查询条件应该是多维的，我们需要一种表达式来统一条件，这
行值表达式听起来很抽象，我举一个通俗点的例子就容易理解了，比如我们需要找到
不过话说回来，跑批查询可以在从库上执行，从库上创建一个这样的索引，用完再删
11364 rows in set (2.52 sec)
 select account from t_fund_info where money >=300 and account not in (select
可以写个存储过程插入20万条数据，逻辑可以参考半连接中的内容。
create index idx_users on users (userid,username) ;
为了能够突出对比效果，我们再补充一个复合索引。
username varchar(64)
ise
这样显然就不满足条件了，比如会把系统部的李四也查找出来。
只要2.52秒，与之前的61213 秒相比，性能简直就是天壤之别。
添加索引的过程持续了4分钟左右，而改进后的性能如何呢。
engine=innodb default charset=UTF8;
tey
行值表达式优化
int（11）
un
default null
((1,'userl'),(2,'user2'))\G
，李四)，（‘运营部”
---
## Page 273
时间字段来进行过滤，通过逻辑层的改造来完成分页逻辑的灵活性。
6.3.1MySQL 分页逻辑优化
要侧重于以下两个技巧：
SQL 优化来说，道理是相通的。
而来，对于改进和提高 SQL性能非常有帮助。
6.3
利用了，体现了在MySQL5.7版本优化器中的细微改进。
有句话说得好，复杂的事情简单做，简单的事情重复做，重复的事情用心做。对于
分页语句的优化应该是 DBA 普遍碰到的一个优化场景了，对这种场景通常建议使用
为了能够言简意的表述一些优化技巧而不是具体的技术，本小节的讲解中，我会主
作为 DBA，掌握一些优化的基本技巧非常有必要。很多优化技巧都是从实践中总结
（1）MySQL分页逻辑的优化。
可以看到key_len 为199（64*3+4+2+1），即字段 userid 和usename 都在 SQL中充分
possible_keys:
possible_keys:
最后，通过一个真实的“血案”
（2）数据隐式转换的性能隐患。
MySQL5.7版本中，我们执行同样的 SQL语句，执行计划如下：
select_type:
 explain select userid,username from users where (userid,username)
partitions:
select_type:
MySQL优化技巧
key_len
Extra: Using where; Using index
rows:
table:
type
key:
rows
ref:
key:
type
100.00
7
NULL
NULL
users
SIMPLE
username
NULL
195
users
199
index
”来复现整个优化的过程。
（(1,'user1'),(2,'user2'))\G
第6章MySQL查询优化|251
in
---
## Page 274
252丨MySQL DBA工作笔记：数据库管理、架构优化与运维开发
量”了。所以整个 SQL 的关注目标首先在于where子句。
数据量也不小，量级在七百万。
秒来估算时间成本吧。
cdb_posts 表的数据有 3000 多万条，另外两个表 cdb_members 和 cdb_memberfields的
id:1
key: displayorder
type:
select_type: SIMPLE
id:1
所以我们后续的测试会以这个数据作为基础，整个 SQL的执行计划如下：
>>SELECT count(*）
p.tid='xxxxx' AND p.invisible='0'
·索引字段cdb_posts（authorid,tid）数据量：3000多万条;
其中索引分布在如下的字段中：
根据监控，这条语句的执行平均时间为9秒，高的时候可达数分钟，我们暂且按照！
FROM cdb_posts p
SELECT p.*, m.uid, m.username, m.groupid, ....m.email, m.gender, m.showemail,
table:p
V
V
根据测试，这个数据量也相对小一些：
对于这样一个SQL，按照目前的执行情况，基于LEFTJOIN，肯定是有一个表要“全
问题 SQL语句如下：
而下面这个案例使用的是另外一种优化思路：优化表连接顺序。
ossible
row in set (7.27 sec)
296251
count(*）
索引字段cdb_memberfields（uid）数据量：3000多万条。
索引字段cdb_members（uid）数据量：700多万条；
len:
 JOIN cdb_members m ON m.uid=p.authorid
_keys: displayorder,idx_tid_fir_authorid,idx_invisible
cdb
.uid=m
.uid
LIMIT 13250,
m.invisible
---
## Page 275
续的信息都是以它为准，既然优化器看不到这个边界，我们可以间接告诉它。
其他的相关 SQL，所以我的注意力放在了逻辑部分，其中 cdb_posts 是最全面的信息，后
的评估，主要是做了索引的评估，发现改进力度很有限，而且对于业务具有侵入性，影响
select * from cdb_posts where tid='xxxx' AND invisible='0' LIMIT 11625, 50,
改造方案是把 cdb_posts 缩小为一个派生表：
可以在这个基础上加上一些原有的排序逻辑，比如增加排序逻辑：ORDER BY dateline
从如上的执行顺序可以看出，cdb_posts 的部分是整个查询的瓶颈点，对于这个部分
整个SQL的执行路径类似于下图6-8的形式。
Extra:
##
id:1
Extra:
key_len:4
possible_
select_type: SIMPLE
cable:
rows in set
_len:4
ssible
test.m.uid
test.p.authorid
mf
keys:PRIMARY
Cdb_posts
(0.00 sec)
Cdb_members
图6-8