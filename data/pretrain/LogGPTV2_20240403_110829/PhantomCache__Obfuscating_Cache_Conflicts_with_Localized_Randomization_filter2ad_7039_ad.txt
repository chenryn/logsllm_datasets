studied in previous solutions [34], [35], [45]. We consider them
independent of our localized-randomization technique. This is
also why we analyze salt robustness against only brute-force
attacks as with existing solutions [35], [45] (Section V).
D. Cache Access
Upon a cache access, PhantomCache enforces parallel
search over all r candidate sets of the requested address
(Figure 7). We need to check all candidate sets because localized
randomization may have mapped the requested address to any
of them. With r mapping function units (Figure 7), we ﬁrst
compute the indices of r candidate sets each using one of
the r salts and the requested address. Tag ﬁelds of all cache
lines in the r sets are selected to compare with the requested
address’s tag in parallel2. According to the mapping design
(Figure 5), a matching of both the tag ﬁeld and random number
in a cache line yields a cache hit. Otherwise, a cache miss
occurs and we need to fetch the requested block from memory
to one of the r candidate sets at random. Since we have
computed all the indices of candidate sets and stored them
in index registers during search, we can directly generate a
random number to select one therein. This avoids index re-
computation and so caused overhead. Then we follow LRU to
place the fetched block into the selected cache set. Meanwhile,
the random number used for set selection should also be cached
for the sake of address restoration (Section IV-F).
The total extra access latency brought by the mapping
function is only one clock cycle. The critical path of the
mapping function consists of 10 gates—7 gates of the hash
function (Figure 6) and 3 other XOR gates (Figure 5). Given
that modern processors can process 15˜20 gate operations per
clock cycle [34], the mapping function brings an extra access
latency of only one clock cycle.
E. Parallel Search
In order to realize parallel search, we need a multi-banked
cache. However, because in PhantomCache any combination
of sets may become the candidate sets of an address, accessing
all of them in parallel yields a multi-banked cache with exactly
one set per bank. Given the large number of sets on an LLC, a
set-grained multi-banked LLC is power hungry and will raise
manufacture challenges. Therefore, we further propose a parallel
search strategy that leverages the existing multi-banked LLC
Fig. 8. Address restoration of PhantomCache.
architecture with only a few banks (e.g., 8). Each bank contains
an equal number of sets. This design may partially sacriﬁces
parallelism because more than one of the r candidate sets may
map to the same bank. In other words, since we still randomly
map an address to any r sets across the entire LLC, it is hard
to always guarantee that r sets map to r banks, especially when
the LLC has fewer than r banks. A design challenge is then
how to synchronize all the r access requests corresponding to
an address. Among the r accesses, a hit succeeds the original
access request while all misses lead to a cache miss. Once
they go to different banks, different queue lengths on each
bank may make the r accesses complete asynchronously. This
confuses the CPU as a miss comes after a hit of the same
address request. Then the CPU needs to handle the cache miss
by fetching the corresponding data block from memory even
though it is already cached.
We modify the LLC queue management policy to support
PhantomCache. For each address request, we inﬂate it to r
requests. Each inﬂated request targets a possible set the address
maps to. According to which bank a set belongs to, these
inﬂated requests are scheduled to different bank queues. Once
an inﬂated request is served, we use its result to update the
status of the original request in the LLC queue. Speciﬁcally, we
maintain a counter and a hit indicator for each original request
in the LLC queue. If the inﬂated request is a hit, the counter
is incremented, the hit indicator is enabled, and the cached
data block is immediately sent to the L2 cache. Otherwise,
we only increment the counter. For an original request in the
LLC queue, if after all its r inﬂated requests get served and
the hit indicator is enabled, it can be removed from the queue.
If its counter becomes r and the hit indicator is not set, the
original request encounters a cache miss and invoke memory
access. Thanks to the pipelined optimization of modern caches
[32], [37] where consecutive requests can be handled without
multiplying the access latency3, PhantomCache introduces a
limited performance overhead. For example, given r = 8 that
guarantees a strong security on an 8-bank 16 MB 16-way LLC
(Section V), PhantomCache brings only 0.50% performance
slowdown on average (Section VII-F).
F. Address Restoration
We need to restore memory addresses of blocks when
writing them from cache back to memory. Address restoration
takes place when dirty blocks are evicted from cache upon
replacement or process termination. As aforementioned, address
restoration requires both the tag and index bits of a memory
address. The tag ﬁeld is already stored in the cache line. We
further restore index bits as in Figure 8. As aforementioned in
2Note that in traditional set-associative caches, cache lines in a cache set
are also checked in parallel. With a multi-banked cache, we are able to check
multiple cache set in parallel
3For example, LLC needs 20 clock cycles to handle an individual request,
but it takes only 21 cycles to handle two consecutive requests because they
are handled in pipeline.
8
salt0 ... saltr-1physical adddressparallel mapping: r mapping function unitsindex registersLLCinterfacer indicesmulti-banked LLCr requestshashxorxorxorsalt selectorrandom numbertagdatacache set indexsaltleftsaltindex bitssaltrightFigure 5, index bits are used for determining the cache set index
through an XOR with a hash output and saltright. The hash
input is the XOR result of the tag and saltlef t. Since the random
number for specifying the salt is also cached, we can ﬁnd the
salt and divide it into saltlef t and saltright, XOR saltlef t
with the tag, and hash the XOR result. Finally, XORing the
hash output with the set index and saltright restores the index
bits. With the tag and index bits, we can restore the memory
address and write back the evicted block to the corresponding
memory location.
V. SECURITY
In this section, we analyze the security of PhantomCache.
Localized randomization signiﬁcantly obfuscates cache conﬂicts
and costs the attacker an unreasonable long time to ﬁnd a
minimal eviction set or crack salts. For example, under Phan-
tomCache with 8 candidate sets, the eviction set minimization
process takes the attacker more than 500 years even if it uses
the state-of-the-art O(|E|) algorithm. A number of 8 candidate
sets can already enforce more than 136 years to crack a salt.
We also randomly initialize the salts upon machine booting.
This renders salt cracking more impractical.
A. Threat Model
Following related work [34], [35], [45], we are concerned
with an attacker that knows the victim address. The attacker can
launch a conﬂict-based attack as long as it obtains a minimal
eviction set for the victim address. Therefore, we consider an
attack successful if the attacker ﬁnds a minimal eviction set.
We make the following assumptions in favor of the attacker.
These assumptions are commonly accepted in the literature
[34], [35], [45].
•
•
•
•
•
The attacker knows the exact physical address accessed
by the victim process.
The attacker possesses abundant initial addresses that
contain sufﬁcient addresses for forming a minimal
eviction set. It may choose to run the classic O(|E|2)
algorithm or the state-of-the-art O(|E|) algorithm
(Section II-B).
The attacker can make memory accesses and measure
access latency.
The attacker is interfered with no noise during the
attack. That is, it is the only entity that makes memory
accesses until a minimal eviction set is found.
Regarding PhantomCache speciﬁcs, the attacker can be
aware of the design of the mapping function, such as
the hash function. However, it cannot know the exact
salts that are used for computing the exact cache set
indices for an address. The attacker may try to crack
the salts.
B. Security Goal
As with existing solutions [34], [35], [45], the security goal
of PhantomCache is to prevent the attacker from ﬁnding a
minimal eviction set within a reasonable time. Speciﬁcally, a
defense is considered as providing strong security if it can
hinder eviction set minimization for more than 100 years [34].
PhantomCache achieves the security goal via three subgoals.
Scarcity of eviction addresses. Sufﬁcient eviction addresses
are necessary for the attacker to form a minimal eviction set.
PhantomCache signiﬁcantly raises the bar for feasible eviction
addresses. It no longer maps an address to a determined cache
set. Instead, each address may be randomly mapped to one of
its candidate sets. It becomes impractical for the attacker to
simply ﬁnd eviction addresses that share all the same candidate
sets (Section V-C). The attacker then has to resort to eviction
addresses that share only part of their candidate sets. However,
which candidate set an address really maps to is random upon
it is cached. This further boosts the difﬁculty of eviction set
minimization.
Hardness of eviction set minimization. Given that there
always have sufﬁcient addresses mapping to the same cache
set, one can hardly prevent the existence of minimal eviction
sets. A countermeasure thus aims to obstruct the process of
eviction set minimization. As with hardware-level randomiza-
tion schemes [35], [45], PhantomCache essentially enforces
such obstruction through randomizing the memory-to-cache
mapping. The difference is that PhantomCache leverages our
proposed localized randomization technique toward a more
efﬁcient protection (Section V-D).
Hardness of salt cracking. Salts play a critical role for
defending against eviction set minimization. If the attacker
knows the salts, it can greatly ease the eviction set minimization
process. This is because that it can use the salts to easily
compute the candidate set for any physical address. To test
the validity of a salt, the attacker could use it to calculate a
set of addresses with a common candidate set. Then it repeats
accessing these addresses. If the common candidate set can be
primed, the attacker can make sure that the salt is currently
used by the system. Such a cracking process induces heavy
memory accesses, which associate with a long access time.
Our analysis shows that PhantomCache is robust against salt
cracking with a sufﬁciently long endurance time (Section V-E).
We next detail how PhantomCache satisﬁes these security
subgoals—scarcity of eviction addresses, hardness of eviction
set minimization, and hardness of salt cracking—in Section V-C,
Section V-D, and Section V-E, respectively.
C. Scarcity of Fully-Congruent Addresses
The most intuitive way to launch a conﬂict-based cache
timing attack in PhantomCache is to utilize addresses whose
candidate sets are exactly the same. Such addresses are called
fully-congruent addresses [45]. Given m × r fully congruent
addresses, the attacker can use them to form an eviction set.
To prime all the r candidate sets of the victim address, the
attacker keeps accessing the whole eviction set and measures
the latency. Note that if all the r candidate sets are primed,
the attacker will not observe any cache conﬂicts in his access
because all the m × r memory blocks are already in the cache.
After an iteration of access without any cache conﬂicts, the
attacker will stop the priming phase and trigger a victim access,
after which the attacker will start the probe phase. However, we
will next show that there may not be sufﬁcient fully-congruent
addresses in the system.
9
1
Consider the Intel HasWell core i7-3720QM processor,
where the LLC includes 8,192 sets and each set holds 12 lines of
64-byte data [33]. Assume that in an r-degree PhantomCache
where a physical address has r candidate sets, the attacker
needs to ﬁnd 12 × r fully-congruent addresses to form an
eviction set. Because of randomized mapping, the r possible
cache sets are independent of each other. The possibility
that two randomly selected addresses are fully-congruent is
8192r . Thus, ﬁnding 12 × r fully-congruent addresses needs
12 × r × 8192r × 64 = 3×r×8192r
KB on average. This result
shows that the space cost grows exponentially with r, where
the base is the number of sets in the cache. Note that even if
r is only set to 2, the needed space still grows to an enormous
scale: 96 GB. In any system, the maximum memory space
of a process is limited, which indicates that when r is large
enough, the attacker can never ﬁnd enough fully-congruent
addresses because they do not exist in the available memory
space. Assume that the maximum memory space is M, cache
associativity is m, the degree of PhantomCache is r, the capacity
of data in a cache line is c, and the number of sets in the cache
is s. Then, the minimum r to guarantee the scarcity of fully-
congruent addresses is the minimum r satisfying the following
constraint:
4
m × r × sr × c ≥ M.
(5)
Because of the scarcity of fully-congruent addresses, the
attacker has to resort to partially-congruent addresses, whose
candidate sets overlap with the victim address’s. Such addresses
are abundant in the memory space. For example, if the cache has
c cache sets in total, the attacker can always ﬁnd 2 addresses that
have a candidate set in common out of c
r addresses. Partially-
congruent addresses can be used to prime one or more candidate
set of the victim address. Thus, with multiple groups of partially-
congruent addresses, the attacker may be able to prime all the
candidate sets of the victim address. We refer to such a group of
partially-congruent addresses as an eviction set for the common
candidate cache set. However, we ﬁnd that even if we have
loosed the requirement for eviction sets, it is still extremely
difﬁcult to ﬁnd a minimal eviction set.
D. Hardness of Eviction Set Minimization
To obtain a minimal eviction set for the target address (i.e.,
victim address), the attacker must go through a minimization
process. This is natural because according to the LRU replace-
ment policy, cache conﬂicts only occur when some cache sets
are ﬁlled up. We have assumed that the attacker is the only
entity making memory accesses during the attack. If the attacker
accesses a small group of random addresses, it can hardly ﬁll
up any cache set and observe cache conﬂicts. Therefore, the
attacker needs to begin with a large number of addresses and
manage to minimize them into a minimal eviction set.
As demonstrated in Algorithm 1 [26], [30], the minimization
process starts with an initial set E of candidate addresses and
proceeds by removing unnecessary addresses therein. Consider
a cache with c cache sets in total. If the attacker randomly
picks an address, the possibility that the address’s candidate
sets includes sx, a certain candidate set of the target address
x, is r