# 一夜走红一天沦陷的AI换脸技术，怎么就威胁了我们的隐私？
##### 译文声明
本文是翻译文章
译文仅供参考，具体内容表达以及含义原文为准。
## 何为DeepFakes
今天我们抛开来单独讨论下技术和风险 当然，视频换脸虽然应场景很迷，但也不是突然冒出来的新技术黑科技。早在2017年，国外Reddit论坛
一个ID名为“DeepFakes”的小伙几首次将自己制作的AI换脸视频发布在网络上。但是很快就凉凉了。在被Reddit无情封杀后，DeepFakes同志直接开源了AI换脸项目的代码，造福全球宅男并立刻风靡全球。
代码开源后，只要你稍微懂点代码就能在几个小时内做出一部换脸视频。
人们为了纪念DeepFakes同志，就用它的ID命名了AI换脸技术，称之为“DeepFakes”。
## 再来谈谈DeepFakes的应用场景
1、拿你的视频去和你的亲朋好友骗钱（都说眼见为实你觉得骗子成功率如何？ ）
2、拿你的视频去网贷（据实验，很多网贷APP的风控系统并不成熟，视频在手，离负债百万还有多远？）
3、拿你的视频去做任何对方想做的事让你的名声一败涂地。（想象一下自己的脸突然出现在不可描述的小电影里） 不好意思实在没想到有什幺正能量的。
##
* * *
##
## DeepFakes 相关的网络安全问题
DeepFakes本质上是一个未发生事情的视频，但却可以以假乱真，看起来非常真实。它主要是通过人工智能算法对照片库中大量名人照片进行训练，因此可以输出与真实视频毫无差异的内容。只要AI训练足够多的头像，换什么都不是问题  
DeepFakes会引发很多问题，比如定期收集到的大量普通用户数据。 即使是在得到用户明确同意的情况下，大多数人也不知道网上有多少他们自己的照片。
劣币驱逐良币，设想下，如果我们根本无法检测到虚假视频，你还敢相信“眼见为实”吗？
除此之外，DeepFakes还有一个被忽视的问题。在未来，DeepFakes将把网络攻击场景带入一个全新的层面，即图像，视频和音频可以通过数字方式进行深度伪造，欺骗人们和组织。
**今天的安全系统严重依赖监控视频和基于图像的生物识别安全。**
由于大多数漏洞都是基于社会工程的网络钓鱼攻击而发生的。不难想象我们很快就会看到“高保真”的网络钓鱼欺诈，即攻击者可以使用AI，社交工程和网络钓鱼，创建自动化、个性化的攻击内容。
为应对钓鱼攻击，对于个人而言，需要增强自身安全防范意识，不轻信、不点击来源不明的链接或附件。对于企业而言，也可以通过其它一些方法，比如在员工电脑中安装管理软件，实时监控员工的一举一动。此外，为防止攻击者通过以PC终端为跳板入侵服务器，企业需要在主机侧增强安全防护，可在主机层部署类似青藤云安全这类企业的安全产品。
## DeepFakes的工作原理和底层技术
“DeepFakes”背后技术来源于一种名为GAN（生成式对抗网络）的AI模型，它在2014年10月由前谷歌著名神级技术大咖Ian
Goodfellow发布的一篇GAN论文而奠定了地位，GAN是当前人工智能学界一个最热门的研究方向。
当前的AI换脸，正是使用了GAN技术。
该技术是通过“生成模型”和“判别模型”两个机器学习(ML)模型之间较量进行不断优化。生成模型负责对数据集进行训练，然后创建伪造视频内容，而另一个判别模型尝试进行伪造检测。
伪造者创建赝品，直到另一个ML模型无法检测到伪造。训练数据集越大，伪造者越容易创建高质量的内容。这就是为什么前总统、好莱坞名人的视频经常出现在第一代DeepFakes中，主要是因为他们有大量公开的视频片段可以用来训练伪造者。
## “以彼之长还施彼身”的解决之道
DeepFakes解决之道需要教育、技术和立法的相互结合。当然，最为重要的就是技术。因为当DeepFakes变得非常逼真时，只有机器才能分辨真假视频。
虽然AI被认为是DeepFakes视频的罪魁祸首，但它也是目前为止应对DeepFakes视频最靠谱的技术。从检测发现到采取措施来消除DeepFakes带来的威胁，AI技术都是安全人员最好的办法。
值得庆幸的是DeepFakes视频仍然存在一些缺陷。比如眨眼，健康的成年人每2到10秒就会眨眼一次，一次眨眼需要十分之一秒。这对于正常视频而言非常正常，但是对于DeepFakes视频却非常难。
因为当DeepFakes算法对人脸图像进行训练时，它依赖于互联网上可用的照片作为训练数据。即使是经常被拍照的人，网上也很少有闭着眼睛的照片。因为人们的眼睛大部分时间是睁开的，而且摄影师通常不会选择拍摄和发布那些闭眼的照片。
如果不训练人们眨眼的图像，DeepFakes算法就不太可能创建正常眨眼的人脸。与真人相比，DeepFakes视频中的人物眨眼的频率要低得多。因此在检测DeepFakes视频时，可以使用机器学习来检查视频中的眼睛睁开和闭上频率。
例如，扫描视频的每一帧，检测其中的人脸，然后自动定位眼睛。然后，它利用另一个深度神经网络，利用眼睛的外观、几何特征和运动来判断被检测到的眼睛是开着还是闭着。这是检测虚假视频一个思路和手段。
当然，生成和检测假视频的竞争就像下棋一样。从理论上讲，GAN可以接受训练，学会如何躲避这样的取证。如果不法分子将所知道的检测技术都给GAN，它就能绕过所有这些检测。比如上文所说的，眨眼也一样可以添加到DeepFakes假视频中，包括使用闭着眼睛的人脸图像或视频序列进行训练。
## 写在最后
未来，虚假视频制作可能会做得越来越好，因此需要政府、企业及个人联合投入更多资源去研究检测DeepFakes假视频的技术。
此外，为应对DeepFakes虚假视频，还有一个比较好解决方案是更好地教育普通大众，“眼见并不为实”
说回ZAO ，在被广泛质疑之后，“ZAO”迅速修改了用户协议，删除了限制用户权利、强制用户无限授权的内容并做出了声明。
**技术无罪，无论事情最后发展如何，希望安全环境越来越好，对此，你怎么看？**