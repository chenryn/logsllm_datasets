title:Self-Supervised Euphemism Detection and Identification for Content
Moderation
author:Wanzheng Zhu and
Hongyu Gong and
Rohan Bansal and
Zachary Weinberg and
Nicolas Christin and
Giulia Fanti and
Suma Bhat
Self-Supervised Euphemism Detection and
Identiﬁcation for Content Moderation
Wanzheng Zhu∗, Hongyu Gong†∗, Rohan Bansal‡, Zachary Weinberg§‡,
Nicolas Christin‡, Giulia Fanti‡, and Suma Bhat∗
∗University of Illinois at Urbana-Champaign, †Facebook,
‡Carnegie Mellon University, §University of Massachusetts, Amherst
‡{rohanb, nicolasc, gfanti}@andrew.cmu.edu, §PI:EMAIL
∗{wz6, spbhat2}@illinois.edu, †PI:EMAIL
1
2
0
2
r
a
M
1
3
]
L
C
.
s
c
[
1
v
8
0
8
6
1
.
3
0
1
2
:
v
i
X
r
a
Abstract—Fringe groups and organizations have a long history
of using euphemisms—ordinary-sounding words with a secret
meaning—to conceal what they are discussing. Nowadays, one
common use of euphemisms is to evade content moderation
policies enforced by social media platforms. Existing tools for
enforcing policy automatically rely on keyword searches for words
on a “ban list”, but these are notoriously imprecise: even when
limited to swearwords, they can still cause embarrassing false
positives [1]. When a commonly used ordinary word acquires
a euphemistic meaning, adding it to a keyword-based ban list
is hopeless: consider “pot” (storage container or marĳuana?)
or “heater” (household appliance or ﬁrearm?) The current
generation of social media companies instead hire staﬀ to check
posts manually, but this is expensive, inhumane, and not much
more eﬀective. It is usually apparent to a human moderator that
a word is being used euphemistically, but they may not know
what the secret meaning is, and therefore whether the message
violates policy. Also, when a euphemism is banned, the group
that used it need only invent another one, leaving moderators
one step behind.
This paper will demonstrate unsupervised algorithms that, by
analyzing words in their sentence-level context, can both detect
words being used euphemistically, and identify the secret meaning
of each word. Compared to the existing state of the art, which
uses context-free word embeddings, our algorithm for detecting
euphemisms achieves 30–400% higher detection accuracies of
unlabeled euphemisms in a text corpus. Our algorithm for
revealing euphemistic meanings of words is the ﬁrst of its kind, as
far as we are aware. In the arms race between content moderators
and policy evaders, our algorithms may help shift the balance in
the direction of the moderators.
Index Terms—Euphemism detection, Euphemism identiﬁca-
tion, Self-supervised learning, Masked Language Model (MLM),
Coarse-to-ﬁne-grained classiﬁcation
I. Introduction
In recent years, large social media companies have been
hiring content moderators to prevent conversations on their
platforms that they deem to be inappropriate. Even though
content moderation—the process of deciding what stays online
and what gets taken down—often relies on organization-wide,
centralized policies, the people who do this job often feel
marginalized [2]. In 2019, The Verge reported on the emotional
toll this work exacts, leading in some cases to post-traumatic
stress disorder [3], [4].
† The work was done while Hongyu Gong was at UIUC.
Automation is an obvious way to assist content moderators.
Ideally, they would be able to make a decision once and have
it applied consistently to all similar content. One standard form
of automated moderation is “ban-lists” of forbidden words.
These are easy to implement, and deﬁne a clear-cut policy.
However, they are also easy to evade: as soon as terms are
added to a ban-list, the oﬀenders will notice and adapt by
inventing euphemisms to evade the ﬁlters [5]. Euphemisms
are frequently words with other, innocuous meanings so they
cannot be ﬁltered unconditionally; they must be interpreted
in context. To illustrate the problem, Table I gives many
examples of euphemisms for a few terms that are frequently
forbidden. Almost all of the euphemisms have innocuous
meanings. Table II shows how a few of the euphemisms would
be used in context, demonstrating that a human reader can
often tell that a euphemistic meaning is intended even if they
do not know exactly what the meaning is.
We present techniques for automated assistance with two
tasks related to ban-list maintenance. Our algorithm for
euphemism detection takes as input a set of target keywords
referring to forbidden topics and produces a set of candidate
euphemisms that may signify the same concept as one of the
target keywords, without identifying which one. Euphemism
identiﬁcation takes a single euphemism as input and identiﬁes
its meaning. We envision these algorithms being used in a
pipeline where moderators apply both in succession to detect
new euphemisms and understand their meaning. For instance,
if the target keywords are formal drug names (e.g., marĳuana,
heroin, cocaine), euphemism detection might ﬁnd common
slang names for these drugs (e.g., pot, coke, blow, dope) and
euphemism identiﬁcation could then associate each euphemism
with the corresponding formal name (e.g., pot −→ marĳuana,
coke, blow −→ cocaine, dope −→ heroin).
In addition to their practical use in content moderation, our
algorithms advance the state of the art in Natural Language
Processing (NLP) by demonstrating the feasibility of self-
supervised learning to process large corpora of unstructured,
non-canonical text (e.g., underground forum posts), a challeng-
ing task of independent interest to the NLP community (e.g.,
[6]–[8]). Our algorithms require no manual annotation of text,
and do not just rely on a “black box” pre-trained and ﬁne-tuned
model.
Examples of the variety of euphemisms associated with target keywords in commonly forbidden categories.
Table I
Category
Drugs
Target Keyword
Marĳuana
Methamphetamine
Heroin
Weapons Gun
Bullet
Breasts
Prostitution
Sex
Euphemisms
blue jeans, blueberry, grass, gold, green, kush, popcorn, pot, root, shrimp, smoke, sweet lucy, weed
clear, dunk, gifts, girls, glass, ice, nails, one pot, shaved ice, shiny girl, yellow cake
avocado, bad seed, ballot, beast, big H, cheese, chip, downtown, hard candy, mexican horse, pants
bap, boom stick, burner, chopper, cuete, gat, gatt, hardware, heater, mac, nine, piece, roscoe, strap
ammo, cap, cop killer, lead, rounds
bazooms, boobs, lungs, na-nas, puppies, tits, yabo
call girl, girlfriend experience, hooker, poon, whore, working girl
Example usage for a few of the euphemisms in Table I.
Table II
Example Sentences (euphemism in boldface)
1. I had to shut up: the dealers had gats, my boys didn’t.
2. For all vendors of ice, it seems pretty obvious that it is not as pure as they market it.
3. I feel really good and warm behind the eyes. It’s not something I’ve felt before on pot alone to this degree.
4. You can get an ounce of this blueberry kush for like $300 and it’s insane.
5. I’m looking for the girlfriend experience, without having to deal with an actual girlfriend.
Euphemism means
machine pistol
methamphetamine
marĳuana
variety of marĳuana
form of prostitution
Table III
Example informative and uninformative contexts. The word “heroin” has
been masked out of each sentence below. In cases 1–3 it is clear that the
masked word must be the name of an addictive drug, while in cases 4–6 there
are more possibilities.
Context
Informative
Uninformative
Example Sentences
1. This 22 year old former
I did drugs with was caught this night.
2. I have xanax real roxi opana cole and
addict who
overdoses in seven hours in
for sale.
3. Six
wooster two on life support.
4. Why is it so hard to ﬁnd
5. The quality of this
for the price its unbelievable.
6. Could we in the future see
?
is amazing and
shampoo?
A. Euphemism Detection
The main challenge of automated euphemism detection is
distinguishing the euphemistic meaning of a term from its
innocuous “cover” meaning [9]. For example, in sentence 2 of
Table II, “ice” could refer to frozen water. To human readers,
this is unlikely in context, because the purity of frozen water
is usually not a concern for purchasers. Previous attempts to
automate this task [9]–[12] relied on static word embeddings
(e.g., word2vec [13], [14]), which do not attempt to distinguish
diﬀerent senses of the same word. They can identify slang
terms with only one meaning (e.g., “ammo” for bullets), but
perform poorly on euphemisms. Continuing the “ice” example,
sentences using it in its frozen-water sense crowd out the
sentences using it as a euphemism and prevent the discovery
of the euphemistic meaning.
A newer class of context-aware embeddings (e.g. BERT [15])
learns a diﬀerent word representation for every context in which
the word appears, so they do not conﬂate diﬀerent senses of
the same word. However, since there are now several vectors
associated with each word, the similarity of two words is no
longer well-deﬁned. This means context-aware embeddings
cannot be substituted for the static embeddings used in earlier
euphemism detection papers, which relied on word similarity
comparisons. Also, not all contexts are equal. For any given
term, some sentences that use it will encode more information
about its meaning than others do. Table III illustrates the
problem: it is easier to deduce what the masked term probably
was in sentences 1–3 than sentences 4–6. This can be addressed
by manually labeling sentences as informative or uninformative,
but our goal is to develop an algorithm that needs no manual
labels.
In this paper, we design an end-to-end pipeline for detecting
euphemisms by making explicit use of context. This is
particularly important to help content moderation of text in
forums. We formulate the problem as an unsupervised ﬁll-
in-the-mask problem [15], [16] and solve it by combining
a masked language model (e.g., used in BERT [15]) with
a novel self-supervised algorithm to ﬁlter out uninformative
contexts. The salience of our approach, which sets itself apart
from other work on euphemism detection, lies in its non-
reliance on linguistic resources (e.g., a sentiment lexicon)
[17], search-engine results, or a seed set of euphemisms. As
such it is particularly relevant to our application case—online
platforms with free-ﬂowing discourse that may adopt their own
vernacular over time. Evaluating on a variety of representative
datasets of online posts we found that our approach yields top-𝑘
detection accuracies that are 30–400% higher than state-of-
the-art baseline approaches on all of the datasets, with top-20
accuracies as high as 40–45%, which is high for this problem.
A qualitative analysis reveals that our approach also discovers
correct euphemisms that were not on our ground truth lists, i.e.,
it can detect previously unknown euphemisms. Again, this is
highly valuable in the context of Internet communities, where
memes and slang lead to rapidly evolving vocabulary.
B. Euphemism Identiﬁcation
Once the usage of euphemisms has been detected, it is
important to identify what each euphemism refers to. Unlike
the task of deciding whether a given word refers to any
target keyword (euphemism detection), the task of euphemism
identiﬁcation maps a given euphemism to a speciﬁc target
keyword. This involves not only using the nuance of contextual
information but also aggregating this information from related
instances across the collection to make the inference. Again,
referring to the 2nd and 3rd examples in Table II, we want
to identify that ice refers to methamphetamine and pot to
marĳuana. To the best of our knowledge, no prior work has
explicitly captured the meaning of a euphemism except for a
few peripheral works (e.g., [9]) that identify the broad category
of a euphemism (e.g., sedative, narcotic, or stimulant for a
drug euphemism).
Euphemism identiﬁcation poses four main challenges:
1) The distinction in meaning between the target keywords
(e.g., cocaine and marĳuana) is often subtle and diﬃcult to
learn from raw text corpora alone. 2) A given euphemism can
be used in a euphemistic or non-euphemistic sense, adding
the extra layer of linguistic nuance (Table IV). 3) No curated
datasets that are publicly available are adequate to exhaustively
learn a growing list of mappings between euphemisms and their
target keywords. 4) It is unclear what linguistic and ontological
resources one would need to automate this task.
In this paper, we propose the ﬁrst approach to identify
the precise meaning of a euphemism (e.g., mapping pot to
marĳuana and Adam to ecstasy). We systematically address
the challenges identiﬁed above via a self-supervised learning
scheme, a classiﬁcation formulation, and a coarse-to-ﬁne-
grained framework. The key novelty lies in how we formulate
the problem and solve it without additional resources or
supervision. Going beyond demonstrating the feasibility of
the task on a variety of datasets, we observe improvements
in top-𝑘 accuracy between 25–80% compared to constructed