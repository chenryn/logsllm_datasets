title:Treaty: Secure Distributed Transactions
author:Dimitra Giantsidi and
Maurice Bailleu and
Natacha Crooks and
Pramod Bhatotia
5
1
0
0
0
.
2
2
0
2
.
5
0
4
3
5
N
S
D
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
1
-
3
9
6
1
-
4
5
6
6
-
1
-
8
7
9
|
)
N
S
D
(
s
k
r
o
w
t
e
N
d
n
a
s
m
e
t
s
y
S
e
l
b
a
d
n
e
p
e
D
n
o
e
c
n
e
r
e
f
n
o
C
l
a
n
o
i
t
a
n
r
e
t
n
I
P
I
F
I
/
E
E
E
I
l
a
u
n
n
A
d
n
2
5
2
2
0
2
2022 52nd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)
Treaty: Secure Distributed Transactions
Dimitra Giantsidi
University of Edinburgh
Maurice Bailleu
University of Edinburgh
Natacha Crooks
UC Berkeley
Pramod Bhatotia
TU Munich
Abstract—Distributed transaction processing is a fundamental
building block for large-scale data management in the cloud.
Given the threats of security violations in untrusted cloud
environments, our work focuses on: How to design a distributed
transactional KV store that achieves high-performance serializable
transactions, while providing strong security properties?
We introduce TREATY, a secure distributed transactional KV
storage system that supports serializable ACID transactions while
guaranteeing strong security properties: conﬁdentiality, integrity,
and freshness. TREATY leverages trusted execution environments
(TEEs) to bootstrap its security properties, but it extends the trust
provided by the limited enclave (volatile) memory region within a
single node to build a secure (stateful) distributed transactional KV
store over the untrusted storage, network and machines. To achieve
this, TREATY embodies a secure two-phase commit protocol co-
designed with a high-performance network library for TEEs.
Further, TREATY ensures secure and crash-consistent persistency
of committed transactions using a stabilization protocol. Our
evaluation on a real hardware testbed based on the YCSB
and TPC-C benchmarks shows that TREATY incurs reasonable
overheads, while achieving strong security properties.
I. INTRODUCTION
Transactions (Txs) are an integral part of modern cloud
computing systems [1]–[4]. They hide complexities (data dis-
tribution, concurrency, failures, etc.) from programmers and,
at the cloud scale, they provide a powerful abstraction to
atomically process massive sets of distributed data sets [5]–[8].
While distributed transactional key-value (KV) stores are
extensively used to build scalable applications with a high
degree of reliability and cost-effectiveness, ofﬂoading Tx
processing in the cloud also poses serious security threats [9].
In untrusted cloud environments, adversaries can compromise
the conﬁdentiality and integrity of the data and application’s
execution state while they can also violate Txs semantics (iso-
lation, atomicity) by intentionally returning stale/uncommitted
data. Prior work has shown that software bugs, conﬁguration
errors and security vulnerabilities pose a real threat for storage
systems [10]–[14]. These security threats are ampliﬁed in
distributed stores as the state is distributed across machines
connected to the untrusted storage and network system stacks.
This work pursues the following question: How to design
a high-performant, serializable, distributed transactional KV
store that offers strong security properties?
A promising direction to this question is to use trusted
execution environments (TEEs)—the new trend in conﬁdential
computing—to build a secure distributed transactional (Tx)
KV store. TEEs provide a secure memory area (enclave) where
the residing code and data are protected even against privileged
code (e.g., OS, hypervisor). Based on this promise, TEEs are
now being streamlined by all major CPU manufacturers [15]–
[19], and adopted by major cloud providers [20]–[22].
However, we cannot use TEEs out-of-the-box to build a
secure distributed KV store with Txs. Particularly, we need to
address the following three challenges:
First, TEEs only protect a limited volatile memory region
(enclave) within a single node. These security properties do
not naturally extend to the untrusted persistent storage and
network over a distributed set of nodes, which are essential to
build a secure distributed transactional KV store.
Secondly, TEEs primarily rely on the expensive syscall
mechanism for I/O operations, where the enclave threads
need to perform an extremely costly world switch to execute
the syscall. While modern conﬁdential computing frame-
works [23]–[25] provide an asynchronous syscall I/O mech-
anism [26] to alleviate the performance overheads, they are
still inadequate for modern distributed storage systems that
prominently rely on high-performance networking such as
RDMA or kernel-bypass [2], [27]–[29]. Unfortunately, it is not
trivial to combine high-performance networking with the TEEs
because TEEs fundamentally prohibit unauthorized access to
the protected enclave via a DMA connection.
Thirdly, distributed stores need to ensure secure and crash-
consistent persistency for committed Txs. Secure persistency
for distributed systems can be a challenge in an untrusted
environment where adversaries can rollback the database state,
to a stale yet consistent snapshot violating correctness. While
SGX [17] provides h/w trusted counters, a fundamental build-
ing block for rollback protection, writes incur prohibitively
high latency [30], [31]. Further, we need to establish trust
between the nodes in the distributed setting to protect against
forking attacks. TEEs’ attestation mechanisms provide a build-
ing block to bootstrap trust. Unfortunately, they cannot provide
collective trust for a distributed set of nodes [32].
To address these challenges, we present TREATY, a dis-
tributed KV store with serializable ACID transactions [33] and
strong security properties:
integrity—unauthorized changes
can be detected, conﬁdentiality—unauthorized entities cannot
read the data, freshness—stale state of the system can be
detected. TREATY embodies three core contributions:
1. Distributed Tx protocol: The design of a secure two-phase
commit (2PC) protocol for distributed Txs providing strict
serializability. Our protocol leverages TEEs for security, and
it is co-designed with a kernel-bypass network stack for
TEEs to ensure high-performance execution (§ V).
2. Stabilization protocol: The design of a stabilization proto-
col that guarantees secure and crash-consistent persistency
2158-3927/22/$31.00 ©2022 IEEE
DOI 10.1109/DSN53405.2022.00015
14
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:16:05 UTC from IEEE Xplore.  Restrictions apply. 
the protocol ensures crash-
of committed Txs. That
consistency, recovery, and data freshness across rollback and
forking attacks in distributed settings (§ VI).
is,
3. Trusted substrate for distributed TXs: The design of
a trusted substrate for distributed Txs—with which we
build TREATY—that overcomes the limitations of TEEs.
Speciﬁcally, we propose (a) a secure network library for
Txs based on kernel-bypass I/O within TEEs, (b) a secure
storage engine for Tx processing, (c) a userland-scheduler
for low-latency requests, and (d) a memory allocator for
secure Tx buffers management (§ VII).
We implement TREATY from the ground-up as a distributed
KV store [34], [35], where we layer a distributed Tx layer
(2PC) on top of per-node storage engine based on a secure
version of RocksDB’s [3] storage engine: SPEICHER [31]. Our
secure 2PC is co-designed with Intel SGX as the TEE and a
secure networking library based on eRPC [36].
We evaluate TREATY with TPC-C [37] and YCSB [38] on
a real hardware cluster. Our evaluation shows that TREATY
incurs reasonable overheads—6×-15× and 2×-5× for dis-
tributed and single-node Txs, respectively—while providing
serializable distributed Txs and strong security properties.
The overheads derive mainly from TEEs as (1) native runs
of TREATY perform similarly to RocksDB, (2) encryption
increases the overhead up to 1.4× compared to non-encrypted
versions and (3) stand-alone evaluation of TREATY’s 2PC
shows 2× slowdown w.r.t. a native version of the protocol.
II. BACKGROUND
A. Distributed Transactional KV Stores
Distributed KV stores [34], [35], [39]–[42] reliably store
and process large data-sets by offering Tx APIs. Such systems
(ZippyDB [34], CockroachDB [35], etc.) traditionally layer
query processing and Txs on top of a per-node storage engine,
e.g., RocksDB [3] or LevelDB [43]. We also adopt this archi-
tecture. These persistent storage engines are increasingly based
on log-structured merge-trees (LSM) [3], [34], [39], [43]–[45]
due to their superior read/write performance. TREATY builds