Detection errors reduce consistency. We derive an upper
bound for the consistency of basic when there are detection
errors as follows:
“
”
E[consbasic, de]  (n + 1)× C, monitors obtain a stable status for H(cid:4) dur-
ing n cycles and mc builds a consistent matrix. (2) When
f :none
1
p(cid:5)
“
)
+ (1 − p(cid:5)
E[conspath] =
”
if f < (n − 1)C,
if f ≥ n × C,
otherwise.
1 − N(cid:2)
|P|
× (H − 2), and f(cid:5)
C
(8)
= f
= 1 + f(cid:2)
= (f(cid:5)/C)H , N(cid:5)
where p(cid:5)
mod C is the length of the failure in the nth cycle.
Detection errors are ﬁltered on a per-path basis and do
not delay the aggregation of paths in H(cid:4). When there are
detection errors, an upper bound on the consistency of mc-
path would be similar to Eq. (6). The average number of
paths with incorrect status, w, is 1 + F n(|P| − 1), and q is
much smaller because the probability of building a reacha-
bility matrix due to detection errors only is proportional to
F n instead of F . For mc-path, the ﬁrst term of Eq. (6),
which represents inconsistency caused by detection errors,
approaches zero as n increases. Hence, we have:
n→∞ E[conspath, de] = E[conspath].
lim
(9)
3.4 Aggregation Delay
The aggregation delay of all aggregation strategies de-
pends on the time it takes to detect the failure, tde, the
cycle length, C, and the number of cycles aggregation waits
before building the matrix, n. Apart from mc, which can
take arbitrarily long to build matrices due to detection er-
rors, the average delay can be written as:
E[delay] = E[tde] + n × C,
(10)
where n = 1 in basic. The detection time E[tde] is smaller
than C because all paths are probed in a cycle. Also, E[tde]
is minimized for periodic probing and decreases as H(cid:4) in-
creases. We present a model for E[tde] in an extended ver-
sion of this paper [8].
Eq. (8) implies that a system can build consistent matrices
for failures longer than n×C and Eq. (10) implies that these
failures are identiﬁed before (n + 1) × C. E.g., an operator
who wants to identify failures of a target duration ftarget
(e.g., 5 minutes), should conﬁgure the system such that:
(n + 1) × C < ftarget.
(11)
Failure to satisfy this condition (e.g., very long cycles or
need for large n due to high detection-error rate) means that
identiﬁcations will be late and that tomography algorithms
will use inconsistent reachability matrices.
3.5 Validation
To validate our models of consistency for each approach
to aggregation, we perform controlled experiments in Emu-
lab. We also apply our aggregation techniques to measure-
ments collected on both the PlanetLab testbed and across a
geographically distributed enterprise network to check how
useful they are in practical scenarios.
3.5.1 Controlled experiments
We use the same Emulab setup as in Sec. 2.2. We assume
that any router in the topology can be a destination and
consider two diﬀerent sets of monitors: (1) with only the
two farthest routers, at New York and Los Angeles; and
(2) with three central monitors at Houston, Chicago, and
Salt Lake City. Then, we select the set of paths to probe
per monitor, Pm, by using the monitor selection algorithm
proposed by Nguyen and Thiran [19]. This algorithm selects
the minimum number of paths that allow diagnosis of multi-
link failures.
To inject blackholes, we introduce single-link failures that
last for 30 seconds and vary the cycle length from 3 to 50 sec-
onds, which will span values of f /C from 0.6 to 10. We
also considered more realistic failures from IS-IS message
traces collected on Abilene and found qualitatively similar
results. We inject congestion-induced packet losses following
a Gilbert model. We vary the per-link loss rates between
zero and 1% and the burst factor between 4 and 40 ms.
These parameter settings correspond to the range of values
found by many previous studies in the wide-area [20, 25, 26].
We only show results for a 1% link loss rate and burst factor
of 40 ms, which are more severe than have been observed in
practice; results for other conﬁgurations are similar. As in
Sec. 2, we conﬁgure the failure conﬁrmation scheme using
−5 and μmin = 100 ms. Solving Eq. (4) yields κ = 4
F = 10
and μ = 398 ms.
Fig. 4 shows the average consistency of each aggregation
strategy as f /C varies. Points are the Emulab results and
lines are computed from the models in Sec. 3.3. Multi-cycle
strategies are running with n = 2, so failures need to persist
for at least two cycles to be included in the reachability ma-
trix. Fig. 4(a) has no detection errors and Fig. 4(b) has 0.6%
incorrect detections (we achieve this high detection-error
rate by using only one conﬁrmation probe instead of four).
Although the average consistency is above 90% for all
strategies, even small diﬀerences in consistency can be sig-
niﬁcant for tomography algorithms; as shown in Fig. 1, one
260y
c
n
e
i
t
s
s
n
o
C
y
c
n
e
t
s
s
n
o
C
i
 1
 0.98
 0.96
 0.94
 0.92
 0.9
 1
 0.98
 0.96
 0.94
 0.92
 0.9
Basic
MC (n=2)
MC−Path (n=2)
 2
 3
 2.5
 3.5
 4
 1
 1.5
Failure Length / Cycle Length
(a) No detection errors
Basic
MC (n=2)
MC−Path (n=2)
 2
 3
 2.5
 3.5
 4
 1
 1.5
Failure Length / Cycle Length
(b) 0.6% wrong conﬁrmations
Figure 4: Consistency of aggregation strategies.
path with incorrect status may trigger a false alarm. We
study the eﬀect of aggregation strategies on tomography’s
accuracy in Sec. 4. High values of consistency occur because
the average hitting set size, H, is much smaller than the
total number of paths, |P|.
Model validation. Fig. 4 shows that our analytic models
of consistency accurately predict the results from the con-
trolled experiments. When there are no detection errors and
f ≥ 2C, all strategies have perfect consistency. mc has per-
fect consistency in all scenarios. basic builds inconsistent
matrices when f < C, which corresponds to S3. Similarly,
mc-path creates inconsistent matrices when 1 < f /C < 2
(recall that n = 2 in these experiments). We can explain
the shape of mc-path curve for 1 < f /C < 2 from Eq. (8).
When the failure ends at the beginning of the nth cycle (f
is just a little more than C), the probability of building a
consistent reachability matrix, p(cid:5)
, is small, but the number
of paths with wrong status, N(cid:5)
, is also small; hence, con-
sistency is high. When f is almost 2C, p(cid:5)
is high and the
majority of failures will have a consistent matrix. The aver-
age consistency is lowest for failures that end in the middle
of the nth cycle (f = 1.5 × C), because the number of paths
with wrong status is signiﬁcant and the probability of con-
structing a consistent matrix is moderate.
Coping with detection errors. Fig. 4(b) shows that
multi-cycle aggregation strategies help mitigate the eﬀects
of detection errors. However, basic has low consistency be-
cause every detection error appears as a path down in the
reachability matrix, so consistency is low even when the fail-
s
e
r
u
l
i
a
F
d
e
i
f
i
t
n
e
d
I
f
o
n
o
i
t
c
a
r
F
 100
 80
 60
 40
 20
 0
 1
 1.5
Basic
MC (n=2)
MC−Path (n=2)
 2
 2.5
 3
 3.5
 4
Failure Length / Cycle Length
Figure 5: Identiﬁed failures, 0.6% wrong detections.
1
2.51
0.914
basic Delay
Cons.
mc Delay
Cons.
mc-path Delay
Cons.
n
3
2
4
5
15.2
0.981
6.92
0.964
19.0
0.998
10.0
0.977
19.7
1
13.0
0.982
22.4
1
16.0
0.985
Table 2: Relationship between aggregation delay (in
seconds) and consistency, no conﬁrmation.
ure persists for more than three cycles. The analytical bound
of basic converges to the actual average when f /C is large
because the value of q in Eq. (6) approaches one.
Multi-cycle strategies achieve high consistency even in dy-
namic environments where detection-error rates are high,
but these strategies take longer to build a reachability ma-
trix and fail to identify shorter failures. Fig. 5 plots the
fraction of the injected failures for which each aggregation
strategy builds a consistent reachability matrix when vary-
ing f /C. The fraction of identiﬁed failures for multi-cycle
strategies is low when f < 2C because these strategies can-
not obtain stable measurements, so they will not build a
reachability matrix, and thus cannot identify these failures.
basic, on the other hand, always builds a reachability ma-
trix for failures that last more than one cycle, but it also
builds many other inconsistent matrices (hence the low av-
erage consistency in Fig. 4(b)), which would trigger false
alarms. When there are many detection errors, mc misses
many failures by being too conservative. It can only build
consistent reachability matrices for 27% of the failures that
last two cycles. mc-path represents the best compromise
when there are detection errors, because it builds consis-
tent matrices for all failures that are longer than two cycles
(Fig. 5) while keeping the false alarms low (Fig. 4(b)).
Relationship between delay and consistency. Tab. 2
shows the tradeoﬀ between aggregation delay and consis-
tency. We do not use conﬁrmation to focus on delay and
consistency of aggregation alone. The basic strategy has the
lowest consistency but the shortest delay. Multi-cycle strate-
gies can increase delay to achieve higher consistency. mc
has the highest consistency, at the cost of the highest delay
and missing most of the failures (Fig. 5). Finally, mc-path
also improves consistency by adding delay. Its consistency is