### 7.6.3 Loudspeaker Types

To evaluate Void’s performance against high-quality speakers, we conducted experiments with various types of loudspeakers. For our dataset and the ASVspoof dataset, we used the trained models described in Sections 7.6 and 7.1, respectively. We tested these models separately on the samples collected through each of the speakers listed in Table 7.

**Table 7: Void’s Performance on Different Loudspeakers**

| Dataset       | Our Dataset | ASVspoof  |
|---------------|-------------|-----------|
| **Loudspeaker** | V-MODA | Logitech | Yamaha | Bose | Smart TV | Dynaudio BM5A | Behringer Truth B2030A | Genelec 6010A |
| **Samples**   | 2,198 | 2,002 | 1,997 | 1,997 | 24,282 | 430 | 1,381 | 198 |
| **Detection Accuracy (%)** | 99.6 | 99.4 | 99.9 | 98.6 | 99.4 | 92.7 | 95.1 | 81.1 |

Void achieved over 98.5% detection accuracy for all the loudspeakers in our dataset. For the ASVspoof dataset, the performance varied across different high-quality loudspeakers. The detection accuracy for Dynaudio BM5A and Behringer Truth B2030A studio monitors were 92.7% and 95.1%, respectively. However, the detection accuracy dropped significantly to 81.1% for the Genelec 6010A studio monitor.

### 7.6.4 Cross-Data Training

For cross-data training, we trained Void on live-human voice and replay attack samples collected from a specific dataset and evaluated its performance on a different, unseen dataset. The training dataset consisted of 26,965 voice samples collected from 20 male participants, replayed through V-MODA speakers. For testing, we considered the following four scenarios:

1. **Scenario 1**: Used 20 unseen male participants' voice samples with V-MODA as the playback device.
2. **Scenario 2**: Used 20 unseen female participants' voice samples with V-MODA as the playback device.
3. **Scenario 3**: Used 20 unseen female participants' voice samples with Bose and Yamaha as the playback devices.
4. **Scenario 4**: Used 20 unseen male participants' voice samples with Bose, Yamaha, and Logitech as the playback devices.

**Table 8: Effects of Cross-Training on Detection Accuracy**

| **Diversity** | **Cross Data Dimension** | **Test Samples** | **RoC Acc. (%)** | **EER (%)** |
|---------------|--------------------------|------------------|------------------|-------------|
| Scenario 1    | 0.04                     | 29,956           | 100              | 0.04        |
| Scenario 2    | 1.9                      | 28,224           | 96.4             | 1.9         |
| Scenario 3    | 4.8                      | 58,062           | 82.1             | 4.8         |
| Scenario 4    | 3.1                      | 58,956           | 93.2             | 3.1         |

In the first two scenarios, only one variable was changed, while in the third and fourth scenarios, all variables were altered. The results are summarized in Table 8. Void achieved 100% attack detection rate with an EER of 0.04% in Scenario 1, 96.4% detection rate with an EER of 1.9% in Scenario 2, 82.1% detection rate with an EER of 4.8% in Scenario 3, and 93.2% detection rate with an EER of 3.1% in Scenario 4. The reduction in detection accuracy in Scenarios 3 and 4 indicates that Void's performance degrades as more variances are introduced.

### 7.7 Replay Attacks in Unseen Conditions

To test Void under various unseen and unexpected environmental conditions, we installed the speakers and recording devices in an office building. This common area includes meeting rooms, elevators, entrances and exits, restrooms, dining areas, and information desks. We replayed all human voice samples (see Section 6.1) on five different playback speakers: Galaxy S8 and S9, V-MODA, Bose, and Logitech. We replayed the voice samples at two different volumes, normal and loud, and recorded them using two Galaxy S8 phones placed 30 cm and 140 cm away from the speakers. The entire recording session took about 10 full days to complete. After removing improperly recorded samples, we were left with 119,996 replay attack samples with a wide variety of background noises and situations.

We evaluated Void's performance against these unseen replay attack samples. Despite the unexpected and diverse set of replay configurations, Void correctly detected 96.2% of the attacks, demonstrating its robustness in unseen conditions.

### 8 Robustness Against Adversarial Attacks

We evaluated Void against hidden/inaudible voice commands, voice synthesis, EQ manipulation attacks, and combinations of replay attacks with live-human voices. To measure the attack detection rates, we trained a Void classifier with all of our own replay attack and human voice datasets (see Section 6) and used it to classify the given set of attack samples. The detection rates of Void against all adversarial attacks are presented in Table 9.

**Table 9: Detection Rates Against Adversarial Attacks**

| **Attack**                | **Dataset**               | **# Samples** | **Acc. (%)** |
|---------------------------|---------------------------|---------------|--------------|
| Hidden                    | Our dataset               | 1,250         | 99.7         |
| Inaudible                 | Ultrasonic speaker        | 311           | 100          |
| Synthesis                 | Our Tacotron dataset      | 15,446        | 90.2         |
| EQ Manipulation (Strategy 1) | Our dataset with human noise | 350 | 89.1 |
| EQ Manipulation (Strategy 2) | Our dataset with human noise | 430 | 86.3 |
| Combining                 | Our dataset with human noise | 3,600 | 98.2 |

#### 8.1 Hidden Voice Command Attacks

Hidden voice commands are commands that cannot be interpreted by human ears but can be processed by voice assistant services [24, 25]. These commands typically add more noise-like frequencies to the original voice samples during obfuscation, increasing the overall signal power linearity.

**Figure 9: Power Spectrum and Spectral Features Representing Live-Human Voice (left) and Hidden Voice (right) for a Sample Utterance “Artificial Intelligence is for Real.”**

The figure compares the signal power distributions for live-human voice and hidden voice command generated with the phrase “Artificial intelligence is for real.” The original command is shown on the left, and the obfuscated hidden command, played through a loudspeaker, is shown on the right. Unlike the live-human case, which shows a non-linear power distribution (mostly concentrated below 2 kHz), the hidden voice samples indicate a more linear behavior (i.e., ρ: 0.97 and q: 2.40). The high-power frequency characteristics also differ, indicating a replay attack.

To evaluate Void against hidden command attacks, we recorded hidden voice command samples using black-box attack methods demonstrated in [25]. Using 1,250 samples from our replay attack dataset, Void demonstrated a 99.7% attack detection rate (see Table 9).

#### 8.2 Inaudible Voice Command Attacks

Inaudible voice command attacks involve playing an ultrasound signal with a spectrum above 20 kHz, inaudible to human ears. These commands are typically played through ultrasonic speakers. Due to the non-linear characteristics of hardware, such as microphones, the received voice signals are shifted to lower frequencies (down-modulation) with much lower power.

To evaluate Void's performance against inaudible attacks, we implemented an inaudible attack with 347 popularly used Amazon Alexa commands, targeting Echo Dot as the consumer device. We used Google’s Text to Speech service (https://pypi.org/project/gTTS/) to convert text commands into speech data. We then modulated the voice commands using amplitude modulation with a high-frequency level of 21 kHz. After modulation, the "BatSound L400 ultrasound speaker" (http://batsound.com/?p=12) was used to replay the modulated voice samples. Out of 347 commands, 311 were successfully recognized and processed by Amazon Alexa. Void achieved a 100% detection rate against inaudible voice command attacks (see Table 9).

#### 8.3 Voice Synthesis Attacks

To test Void’s performance against voice synthesis attacks, we used open-source voice modeling tools called “Tacotron” [1] and “Deepvoice 2” [2] to train a user voice model with 13,100 publicly available voice samples (https://keithito.com/LJ-Speech-Dataset/). We then used the trained model to generate 1,300 synthesis voice attack samples by feeding in Bixby commands as text inputs.

After generating the attack data, we played these synthesis attack samples through four different speakers: Galaxy S8, V-MODA, Logitech 2.1 Ch., and Yamaha 5.1 Ch. speakers. For each speaker type, we placed a Galaxy S8 in three different distances as described in Section 6.2 and recorded the synthesis attack samples. After removing improperly recorded samples, we were left with a final set of 15,446 synthesis attack samples and tested them on Void.

Void achieved a 90.2% attack detection rate against this set, demonstrating its potential in detecting voice synthesis attacks. However, this is a preliminary result, and further tests need to be performed with test sets generated through models trained on more users.

#### 8.4 Audio EQ Manipulation Attacks

Since Void leverages spectral power patterns for attack detection, an advanced attacker who is aware of the classification features used by Void may try to craft attack commands using audio EQ programs. EQ manipulation is a process commonly used for altering the frequency response of an audio system by leveraging linear filters. An attacker’s goal would be to artificially create attack commands that show power patterns similar to those of live-human voices. By leveraging audio equalization, an attacker could intentionally manipulate the power of certain frequencies to mimic spectrum patterns observed in live-human voices.

To demonstrate the robustness of Void against such EQ manipulation attacks, we used Audacity (https://www.audacityteam.org/) to generate audio samples that mimic decay and peak patterns in spectral power like live human voices under the following two strategies:

1. **First Attack Strategy**: Removing background noises from audio samples because the samples were originally recorded with various background noises present (e.g., noises generated from fans, refrigerators, or computers). We used a noise reduction rate of 12 dB and set the frequency smoothing parameter to 3. We then boosted power in frequencies less than or equal to 500 Hz and reduced power in frequencies above 500 Hz to mimic the characteristics of live-human voices. Using 350 attack samples from the ASVspoof dataset, we manually crafted 350 EQ manipulation attack samples based on this power manipulation technique. Void correctly classified 89.1% of them as attacks.

2. **Second Attack Strategy**: Applying bass boost to increase power in low frequencies between 20 Hz and 100 Hz to about an average power of 9.5 dB. This power increase would produce more fluctuations in the low frequencies and power patterns similar to those of live-human voices. Audio signals are then normalized with maximum amplitude. Finally, a low-pass filter (frequency 1 kHz) is applied. We used 430 attack samples from the ASVspoof dataset and manually crafted 430 EQ manipulation attack samples using this technique. Void correctly classified 86.3% of them as attacks.

We found that the performance of Void was somewhat degraded against EQ manipulation attacks. However, based on our manual EQ manipulations, we realized that it is quite hard to intentionally craft power patterns that mimic the patterns of live-human voices because most loudspeakers add their own non-linear distortions at low frequencies that cannot easily be controlled by attackers [34]. For instance, it is difficult to craft a sound signal that has desired power peaks at certain frequency ranges even with dedicated manipulation of spectral power patterns.

#### 8.5 Combining Replay Attacks with Live-Human Voices

To evade detection by Void, an attacker can try to combine replay attacks with live-human voices. For example, when a command is played back through a loudspeaker, a live-human can start uttering random phrases/commands simultaneously.

To analyze the effects of adding live-human voices while replaying attack commands, we recorded additional replay attack samples with two people—both males—continuously chatting near the recording devices. We randomly selected 20 voice samples recorded from 6 participants and used 6 playback speakers to perform replay attacks: Galaxy S8/S9, Bose, V-MODA, Logitech, and Yamaha speakers. We used three Galaxy S8 and three S9 recording devices, spread out and located 1-2 m away from the loudspeakers. The two people were sitting about 1-2 m away from the recording devices, continuously chatting with their normal voices throughout all recording sessions. Since Void is not responsible for classifying commands that are not properly recognized by voice assistants, we ran all recorded samples through a speech-to-text translation engine (“Google Speech Recognition”) and removed commands that it failed to recognize. We were left with 3,600 attack samples to test.

Among these samples, Void correctly detected 3,536 attack samples, achieving a detection accuracy of 98.2%. This result shows that overlapping live-human utterances do not significantly affect the detection accuracy.

### 9 Discussion

#### 9.1 Latency and Accuracy Requirements

The ASVspoof 2017 competition did not measure model and feature complexity nor the time taken to train and classify given voice samples. The primary objective was to achieve the lowest possible EERs. Consequently, most submitted solutions [7] used multiple deep learning models (as an ensemble solution) and heavy classification features to minimize the EERs—such solutions do not align well with real-world near-zero-second latency and model complexity requirements.

As shown from our latency results (see Section 7.4), Void is much lighter, faster, and simpler than other top-performing solutions.