User: 如何使用Python编写一个简单的爬虫程序，自动从某个网站上定期抓取数据并保存到本地文件中？
Assistant: 下面是一个使用Python的简单爬虫程序的示例：

```python
import requests
from bs4 import BeautifulSoup

# 设置需要爬取数据的网址
url = 'https://www.example.com/'

# 发送HTTP请求，并获取响应内容
response = requests.get(url)
html = response.content

# 使用BeautifulSoup解析HTML
soup = BeautifulSoup(html, 'html.parser')
data = soup.find('div', {'class': 'data'}).text

# 将数据保存到文件
with open('data.txt', 'w') as f:
    f.write(data)
```

要定期运行该爬虫程序，可以使用Python的定时任务模块`schedule`，例如：

```python
import schedule
import time

def crawl():
    # 在这里编写爬虫程序的代码

schedule.every(1).day.at('00:00').do(crawl) # 每天凌晨0点运行

while True:
    schedule.run_pending()
    time.sleep(60)
```

注：请在使用Python爬虫程序时尊重网站的爬虫协议和相关法律法规，不得进行恶意爬取等违法行为。