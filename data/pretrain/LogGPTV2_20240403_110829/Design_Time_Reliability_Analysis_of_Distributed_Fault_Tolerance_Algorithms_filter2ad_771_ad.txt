Overall, the Convict Some strategy had the lowest as-
sumption failure rate, and the standard Convict All strategy
had the highest assumption failure rate, as shown in Figure 2
and Table 10. There were Convict Some conﬁgurations that
achieved a three orders of magnitude decrease in assump-
tion failure rate compared to the other two strategies (10−10
to > 10−11 in Table 10). The 4, 5, and 6 node conﬁgurations
all had high failure rates (10−5 and up) as compared to the
7 node and above conﬁgurations. The assumption failure
rates for the Convict All and Convict Some strategies show
more of a spread than the Convict None strategy, in Figure
2. This could be due to the conviction of good nodes (no
More than 10−3
10−3 to > 10−4
10−4 to > 10−5
10−5 to > 10−6
10−6 to > 10−7
10−7 to > 10−8
10−8 to > 10−9
10−9 to > 10−10
10−10 to > 10−11
Fewer than 10−11
Conv. All Conv. None Conv. Some
27
108
63
126
312
255
0
0
0
0
81
0
0
261
408
141
0
0
0
0
243
729
729
972
972
2328
1236
756
54
0
Table 11. Membership Dominant Failure
Conv.
Some
3159
4860
Conv.
All
0
891
Conv.
None
744
144
Active Faults (MFA.1)
Too
Nodes
(MFA.2, MFA.3)
Few
nodes are convicted in the Convict None strategy), or the
loss of redundancy due to convicted transient faulty nodes.
In all cases studied, the Convict All strategy failed by
running out of redundancy, as shown in Table 11. This
may be due to lightning strikes, since as modeled two light-
ning strikes will cause the entire group to become con-
victed in the Convict All strategy. The probability would
be (4*10−4)2, or 1.6*10−7. Other burst effects for light-
ning could be investigated, but this shows that the Convict
All strategy might be a poor performer for burst faults in
general. In contrast, the Convict None strategy failed pri-
marily due to too many active faults. The Convict Some
strategy balanced the two risks best. The models were most
sensitive to the transient faults (BER and SEU), with vary-
ing sensitivity to permanent link faults. All three strategies
were insensitive to the SEL rate.
Further investigation shows that adding nodes might not
improve reliability if the dominant cause of failure is too
many active faults. In the Convict None strategy, conﬁgu-
rations with 9 or more nodes failed due to too many active
faults. The conﬁgurations with the lowest failure rates had
9 or 10 nodes – conﬁgurations with more nodes had higher
failure rates. In the Convict Some strategy, conﬁgurations
with 13 or more nodes failed due to too many active faults.
The conﬁgurations with the lowest failure rates had 13 or
14 nodes (the greatest number tested).
We hypothesize that adding nodes will eventually de-
crease reliability for algorithms whose maximum fault as-
sumption includes a ﬁxed term. Adding nodes increases the
chance of a pair of faults, so for membership if MFA.1 is
the dominant assumption violated, adding nodes is expected
to decrease reliability. Many Byzantine fault tolerant algo-
rithms are expected to include a ﬁxed term in their MFAs,
because for a round-based algorithm there must be at least
f + 1 rounds to tolerate f Byzantine faults [14], and the
total number of rounds is usually ﬁxed.
For the Convict Some strategy, we studied various prob-
abilities for permanent faulty node conviction (0.99, 0.95,
Figure 2. Membership: Assumption Failure Rate Comparison
and 0.90) and for incorrect transient fault conviction (0.01,
0.05, and 0.10). There was some sensitivity to the probabil-
ity of convicting transient faulty nodes when one of the tran-
sient fault rates (Single Event Upset) was high. There was
little sensitivity to the probability of permanent fault mis-
classiﬁcation, even when permanent fault rates were high.
Since the transient fault rates were higher than the perma-
nent fault rates, it makes sense that the models would be
most sensitive the type of fault that occurs most often.
4.3 Sensitivity Analysis
This section explores sensitivity to some of the system
parameters assumed in Table 2 and Table 7. We selected
two studies, the Welch and Lynch clock synchronization
and the Convict All membership diagnosis strategy. We
ﬁxed the number of nodes at 8. For both models, we studied
two different chip sizes (64K and 256K) and four different
percentages of bits affected by asymmetric SEUs (0, 15%,
50%, and 100%). There were (3 SELs * 3 SEUs * 3 Perm.
Link fault rates * 3 BERs * 2 chip sizes * 4 asym. bits) =
648 conﬁgurations for clock synchronization.
For the membership model, we additionally investigated
three probabilities of convicting asymmetric faulty nodes
(1.0, 0.95, and 0.90) and three probabilities of good node
conviction in the event of an asymmetric fault (1/GN , 0.25,
and 0.50). At maximum, half the good nodes in the group
could be convicted. The SEL rate was kept constant at
10−6, the highest rate studied to see if sensitivity to this
parameter increased (it does not). There were (3 SEUs * 3
Perm. Link fault rates * 3 BERs * 2 chip sizes * 4 asym.
bits * 3 Prob. Conv. Asym * 3 Prob. Conv. Good) = 1944
conﬁgurations for membership.
For the 8 node conﬁgurations, the Welch and Lynch
clock synchronization model was insensitive to changes in
the total amount of memory and to changes in the amount
of memory affected by asymmetric SEU faults. However,
this model was sensitive overall to the SEU rate as noted in
Section 4.1. Upon further inspection, the 7 node or fewer
conﬁgurations show sensitivity to the SEU rate while the
8 node or more conﬁgurations do not. This indicates that
other fault types (BER in particular) dominate for the 8 or
more node conﬁgurations.
The Convict All diagnosis strategy was sensitive to all of
the system parameters studied. The model was more sen-
sitive to the total amount of memory than to the amount
of memory susceptible to asymmetric SEU. Increasing the
amount of memory increases the rates of all SEU faults (be-
nign and asymmetric), so since the Convict All model also
convicts benign transient faulty nodes, this may lead to in-
adequate redundancy. Even for only 90 percent asymmetric
conviction, some conﬁgurations achieved a failure rate be-
tween 10−6 and 10−5, which was the lowest failure rate
achieved by perfect conviction. This indicates that a prac-
tical fault diagnosis algorithm performs fairly well with re-
spect to an ideal algorithm for the Convict All strategy.
5 Conclusions
Distributed fault tolerance algorithms must balance the
risk of failure due to too many active faults versus the risk
of failure due to inadequate redundancy caused by improper
fault diagnosis. An algorithm’s maximum fault assumption
states the maximum number and type of faults that can be
tolerated without possible system failure. The designer’s
choice of a hybrid fault model and diagnosis strategy affects
the probability of violating this maximum fault assumption.
We present a methodology to assess the reliability of the
maximum fault assumption at design time, and to determine
the dominant cause of failure with respect to this assump-
tion. We illustrate our methodology through two case stud-
ies, clock synchronization and group membership. We base
our physical fault model on real-world fault types and ar-
rival rates, providing a reusable summary of physical fault
rate data, and we give an example of how to extend the mod-
els to incorporate a new fault type.
For clock synchronization, a Strictly Omissive Asym-
metric hybrid fault model has a signiﬁcantly lower assump-
tion failure rate than the Welch and Lynch hybrid fault
model. A Strictly Omissive Asymmetric hybrid fault model
0%5%10%15%20%25%30%35%40%45%50%1e-10 to> 1e-111e-9 to  > 1e-101e-8 to  > 1e-91e-7 to  > 1e-81e-6 to  > 1e-71e-5 to  > 1e-61e-4 to  > 1e-51e-3 to  > 1e-4Morethan 1e-3Assumption Violations / Hr.Percentage of ConfigurationsConv. AllConv. NoneConv. Some4, 5, and 6 nodeconfigurationsshould be fairly easy to adopt. For membership, a diagnosis
strategy that discriminates between permanent and transient
faults has a much lower assumption failure rate overall.
Also, for a maximum fault assumption including a constant
term, adding nodes actually decreases reliability when the
dominant cause of failure is too many active faulty nodes.
This information could be used to design a rapid reintegra-
tion strategy, without changing the underlying proofs.
Acknowledgments
This work is supported in part by the National Aeronautics and
Space Administration, Langley Research Center, under agreement
NCC-1-02043 awarded to the National Institute of Aerospace, the
General Motors Collaborative Research Laboratory and Carnegie
Mellon University, the United States Department of Defense (ND-
SEG/ONR), and the American Association for University Women
and the Zonta International fellowship programs.
References
[1] A. Ademaj, H. Sivencrona, G. Bauer, and J. Torin. Evalua-
tion of Fault-Handling of the Time-Triggered Architecture
with Bus and Star Topology. Proc. of the 2003 Intl. Conf. on
Dependable Systems and Networks (DSN ’03), June 2003.
[2] austriamicrosystems AG. AS8202NF TTP-C2NF Commu-
nication Controller Data Sheet Rev.1.2, Nov. 2003.
[3] M. Azadmanesh and R. Kieckhafer. Exploiting Omis-
sive Faults in Synchronous Approximate Agreement. IEEE
Trans. on Computers, Vol. 49, No. 10, Oct. 2000.
[4] G. Bauer, H. Kopetz, and P. Puschner. Assumption Cover-
age under Different Failure Modes in the Time-Triggered
Architecture. 8th IEEE Intl. Conf. on Emerging Technolo-
gies and Factory Automation, Oct. 2001.
[5] G. Bauer and M. Paulitsch. An Investigation of Member-
ship and Clique Avoidance in TTP/C. 19th IEEE Sympo-
sium on Reliable Distributed Systems, October 2000.
[6] R. Butler. The SURE Approach to Reliability Analysis.
IEEE Trans. on Reliability, Vol. 41, No. 2, June 1992.
[7] R. Butler and S. Johnson. Techniques for Modeling the Re-
liability of Fault-Tolerant Systems With the Markov State-
Space Approach. NASA RP-1348, Sept. 1995.
[8] R. Butler and G. Finelli. The Infeasibility of Experimental
Quantiﬁcation of Life-Critical Software Reliability. Proc.
of the ACM SIGSOFT ’91 Conf. on Software for Critical
Systems, Dec. 1991.
[9] E. Chan, Q. Le, and M. Beranek. High Performance, Low-
Cost Chip-on-Board (COB) FDDI Transmitter and Re-
ceiver for Avionics Applications. Proc. of the 1998 Elec-
tronic Components and Tech. Conf., 1998.
[10] DBench Project. Fault Representativeness. Deliverable
ETIE2. IST 2000-25425. June 2000.
[11] P. Dodd and L. Massengill. Basic Mechanisms and Mod-
eling of Single-Event Upset in Digital Microelectronics.
IEEE Trans. on Nuclear Science, Vol. 50, No. 3, June 2003.
[12] Federal Aviation Administration. Instructions for Contin-
ued Airworthiness: Advisory Circular 33.4.3 [Draft].
[13] FlexRay Consortium. FlexRay Communications System
Protocol Speciﬁcation, Version 2.0. June 2004.
[14] M. Fischer and N. Lynch. A Lower Bound for the Time
to Assure Interactive Consistency. Information Processing
Letters, 14(4):183-86, June 1982.
[15] P. Herout, S. Racek, and J. Hlaviˇcka. Model-Based De-
pendability Evaluation Method for TTP/C Based Systems.
4th European Dependable Computing Conf. (EDCC 2002),
LNCS 2485, 2002.
[16] R. Hyle, Jr. Fiber Optics - Failure Modes and Mechanisms.
Proc. of the Reliability and Maintainability Symp., 1992.
[17] International Electrotechnical Commission. IEC 61000-4-
4. Electrical Fast Transient/Burst Immunity Test. July 2004.
[18] International Organization for Standardization. ISO 7637.
Road Vehicles – Electrical Disturbances from Conduction
and Coupling. March 2002, June 2004, Nov. 1995.
[19] H. Kopetz. Fault Containment and Error Detection in the
Time-Triggered Architecture. Proc. of the 6th Intl. Symp.
on Autonomous Decentralized Systems, Apr. 2003.
[20] M. Kwiatkowska, G. Norman and D. Parker. Controller
Dependability Analysis By Probabilistic Model Checking.
Proc. of the 11th IFAC Symp. on Information Control Prob-
lems in Manufacturing (INCOM ’04), Apr. 2004.
[21] L. Lamport, R. Shostak, and M. Pease. The Byzantine
Generals Problem. ACM Trans. on Programming Language
Systems, Vol. 4, No. 3, July 1982.
[22] E. Latronico, P. Miner, and P. Koopman. Quantifying the
Reliability of Proven SPIDER Group Membership Service
Guarantees. Proc. of the 2004 Intl. Conf. on Dependable
Systems and Networks (DSN ’04), June 2004.
[23] MAXIM Integrated Products. Accurately Estimating Opti-
cal Receiver Sensitivity. App. Note HFAN-3.0.0. Oct. 2001.
[24] F. Meyer and D. Pradhan. Consensus with Dual Failure
Modes. Proc. of the 17th Fault-Tolerant Computing Symp.,
July 1987.
[25] P. Miner, A. Geser, L. Pike, and J. Maddalon. A Uni-
ﬁed Fault-Tolerance Protocol. Formal Techniques in Fault-
Tolerance and Real-Time Systems, 2004.
[26] E. Normand. Single-Event Effects in Avionics. IEEE Trans.
on Nuclear Science, Vol. 43, No. 2, April 1996.
[27] H. Pfeifer. Formal Veriﬁcation of the TTP Group Member-
ship Algorithm. Proc. of FORTE XIII / PSTV XX, Oct. 2000.
[28] H. Pfeifer, D. Schwier, and F. W. von Henke. Formal Veriﬁ-
cation for Time-Triggered Clock Synchronization. 7th IFIP
Intl. Working Conf. on Dependable Computing for Critical
Applications (DCCA-7), Jan. 1999.
[29] D. Powell. Failure Mode Assumptions and Assumption
Coverage. Proc. of the 22nd Intl. Symp. on Fault-Tolerant
Computing (FTCS ’92), 1992.
[30] RTCA, Inc. Environmental Conditions and Test Procedures
for Airborne Equipment. RTCA/DO-160D, July 29, 1997.
[31] John Rushby. A Comparison of Bus Architectures for
Safety-Critical Embedded Systems. NASA CR-2003-
212161. March 2003.
[32] F. Sexton. Destructive Single-Event Effects in Semiconduc-
tor Devices and ICs. IEEE Trans. on Nuclear Science, Vol.
50, No. 3, June 2003, p. 603-21.
[33] H. Sivencrona. On the Design and Validation of Fault Con-
tainment Regions in Distributed Communication Systems.
Dissertation. Chalmers University of Technology, 2004.
[34] H. Sivencrona, J. Hedberg, and H. R¨ocklinger. Compara-
tive Analysis of Dependability Properties of Communica-
tion Protocols in Distributed Control Systems. PALBUS
Task 10.2. Apr. 2001.
[35] R. Stephens. Analyzing Jitter at High Data Rates. IEEE Op-
tical Communications, Feb. 2004.
[36] P. Thambidurai and Y.-K. Park. Interactive Consistency
With Multiple Failure Modes. Proc. of the Seventh Reliable
Distributed Systems Symp., Oct. 1988.
[37] TTTech Computertechnik AG. Time Triggered Protocol
TTP/C High-Level Speciﬁcation Document, Protocol Ver-
sion 1.1. Speciﬁcation Edition 1.4.3. Nov. 2003.
[38] U.S. Department of Defense. MIL-HDBK-217F. Reliability
Prediction of Electronic Equipment. Dec. 2, 1991.
[39] J. Lundelius Welch and N. Lynch. A New Fault-Tolerant
Algorithm for Clock Synchronization. Information and
Computation, Vol. 77, No. 1, Apr. 1988.