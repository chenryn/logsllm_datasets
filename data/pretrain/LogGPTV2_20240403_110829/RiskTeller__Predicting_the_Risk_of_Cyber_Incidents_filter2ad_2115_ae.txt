to enrich the ground truth, remains consistently accurate.
In our final experiment, we investigate the prediction accuracy
of RiskTeller on per-enterprise data. We stated earlier that the our
dataset comprises of data collected from 18 different enterprises.
Before initiating the classification experiments in each enterprise,
we analyzed the ground truth details of each enterprise. As Figure 6
demonstrates, the ground truths can be very imbalanced (e.g., 13K
risky and 1.6K clean profiles) or very small in size (e.g., 23 risky and
60 clean profiles). As expected, the basic random forest classifier
does not perform well here (on average 45% TPR with 5% FPR). The
SSL classifier obtains better results (on average 61% TPR with 5%
FPR); the results are still definitely not as good as those that can be
obtained when combining the data from different enterprises.
Figure 6: Ground Truth Size per enterprise.
7 DISCUSSION
A typical question that arises when machine learning (ML) is ap-
plied in the security domain is evasion, i.e., the possibility that
malicious actors behave to avoid being discovered by the ML sys-
tem. Luckily, in our case, this problem does not apply: RiskTeller
uses features observed when machines are used by benign users in
order to predict the risk of infections afterwards. Since features are
collected on benign usage before the attacks we attempt to predict,
evasion is not applicable to our case.
0	0.005	0.01	0.015	0.02	0.025	Volume-Based	Time-Based	Category-Based		Prevalence-Based	Vulnerabily-Based	Threat	history-Based	1	10	100	1000	10000	1	5	25	125	625	3125	15625	#	of	Clean		Machines	#	of	Risky	Machines	Session F2:  Insights from Log(in)sCCS’17, October 30-November 3, 2017, Dallas, TX, USA1309Another issue typically related to ML and security is concept
drift: the risk that, as time passes, the statistical properties of the
variable that ML models change, rendering the ML models less
and less effective: for example, a malware detection system might
lose effectiveness as malware families change over time. Instead of
characterizing attacks, Riskteller models their likely victims. Our
results —see Figure 3— show us that RiskTeller’s results are stable
over 6-month labeling periods, suggesting that characteristics of
typical cyber-attack victims change slowly over time. On longer
time frames, concept drift can be avoided by re-training our model.
Since we do not have data about the direct causes of attacks, we
cannot use our system to learn causality; however, the correlations
we observe can be interpreted to understand what are the cause
that increase the risk of attack. Our analysis in Section 4.2 provides
a clear picture of machines that are at risk of becoming infected:
those with few or no security upgrades and unusual usage in terms
of temporal patterns and binaries installed; it is quite intuitive to
understand why such machines are at higher risk.
Our results show that RiskTeller can predict infections with
variable precision depending on the dataset under consideration.
Our prediction quality is higher than typical values in the insurance
context, where prediction is a hard problem depending on human
factors and outside events that are not observable in a model; for
example, for bankruptcy prediction, see the ROC curves in the
works by [7] and [28]: predictions that are less precise than those
of RiskTeller are still useful to quantify risk and to price insurance.
We consider RiskTeller as also useful to identify machines at risk
and drive choices for proactive hardening in enterprises: machine
risk levels can be used independently and/or aggregated by orga-
nizations (e.g., departments) and job roles; these results can drive
efforts to harden systems or educate users to risk, such that more
effort is spent where it is most needed. One should not compare
these results with those obtained in the related problem of malware
detection: while detecting legitimate software as malware can some-
times make applications or machines unusable [6, 17, 20, 26, 35], a
false positive in identifying a machine as at risk would just result
in hardening that, a posteriori, could be considered not essential.
8 RELATED WORK
In computer security, a very large amount of work has been de-
voted to approaches that attempt to determine whether machines
or systems are currently under attack, or distinguish malware from
legitimate software. By comparison, the body of work targeting the
prediction of future attacks and infections is comparably smaller.
In 1998, Korzyk [14] attempted to predict the growth in the
number of vulnerability advisories in the early days of Internet
security, using simple techniques such as time series analysis.
Some other works attempt to predict the behavior of attack-
ers and defenders with the tools of game theory: Jones et al. [13]
describe the interactions between efforts spent by attackers and
defenders to predict their optimal strategies, while Axelrod and
Iliev [1] investigate the issue of cyber-conflict timing, predicting
the moment in which cyber-weapons such as zero-days exploits
would be used. These approaches are most appropriate to describe
high-stakes interactions between few rational players, and do not
provide much insight with respect to the case of Internet security,
with billions of machines that are susceptible to attack.
The IARPA CAUSE project [12] is a recent effort to use large
amounts of Internet data together with machine learning to find
the fingerprints (e.g., system probing) that predict a future attack.
Unlike this project, our work focuses in the behavior of potential
victims rather than the one of attackers.
More similarly to our approach, six works analyze data about
users and systems to estimate the risk of cyber incidents: (a) Lalonde
Levesque et al. [16] analyze a small set of 50 users’ demographics
and web browsing features to evaluate risk factors; (b) Canali et al.
[4] perform a study that associated users to their risk through
information about their web browsing logs; (c) Soska and Christin
[30] collect features about websites to predict which ones will
become malicious; (d) Yen et al. [38] analyze user demographics
and behavioral features in a single large corporation to compute risk
factors; (e) Liu et al. [19] predict cyber-security incidents within
organizations by analyzing externally measurable features. In a
recent study, (f) Veeramachanent et al. [37] analyze the historical
incident records of enterprises to predict cyber incidents leveraging
deep learning methods. We consider these approaches as valuable
and complementary to the analysis that we carry out in this work.
All these approaches provide informative predictions, but none of
them is close to perfection: Soska and Christin obtain 66% true
positives (TPs) with 17% false positives (FPs), Canali et al. obtain
74% TPs with 8% FPs, Liu et al. have 90% TPs with 10% FPs, and
Veeramachanent et al. obtain 86.8% FPs with 4.4% TPs after being
boosted with feedback from security analysts. Lalonde Levesque
et al. and Yen et al. use logistic regression to compute risk factor
and do not report FP/TP results, but their results suggest lower
precisions. Each of these works predicts different types of incidents
and hence these numbers are not directly comparable. However,
they provide context showing that predicting incidents is a difficult
problems, and that RiskTeller’s TP/FP rates are generally better than
those observed in similar studies. Moreover, the studies by Liu et al.
and Veeramachanent et al. are inherently less granular and predict
attack only at the level of an organization, while an approach such
as ours gives more granular information, providing administrators
an actionable way to highlight the most risky components of their
infrastructure.
Semi-supervised learning has been used in the security context
by Han and Shen [9], classifying automatically email-based spear-
phishing campaigns. In this domain, the ground truth datasets are
created by human analysts, and therefore require extensive human
effort. Han and Shen propose to use a semi-supervised learning
algorithm to reduce the labeling overheads. In our work, instead,
we employ semi-supervised learning to verify the completeness
of our ground truth and to enrich it in case it is limited and/or
imbalanced in size.
9 CONCLUSION
In an era where the cyber incidents became unavoidable, cyber
defenders started to shift their interest from reactive to proactive
security, and enterprises and individuals purchase more and more
cyber insurance packages so that when the incident happens, a
part of their loss can be covered. One crucial task in both proactive
Session F2:  Insights from Log(in)sCCS’17, October 30-November 3, 2017, Dallas, TX, USA1310security and cyber insurance is to estimate and predict the risk
in advance. If methods for risk prediction exist, malware defense
solutions can incorporate this piece of information to harden the
systems of machines at risk such that it is harder for the attackers
to compromise them. Also, cyber insurance schemes can benefit
from risk estimates to price efficiently their offers. In this work, we
focused on addressing this gap in the cyber ecosystem by propos-
ing RiskTeller, a system that can predict the machines at risk in
enterprises with high accuracy. To date, no previous work was able
to achieve a 96% TPRs with only 5% FPRs for such predictions at a
machine-level granularity.
Despite the capabilities of RiskTeller to predict machines at risk
we believe that, in the area of prediction for cyber security, much
remains to be explored. RiskTeller predicts, in general, that a ma-
chine is at risk from malware, providing no hints about specific
malware categories. In future work, we plan to extend our work to
predict the risk of different machine profiles for threat types such
as banking trojans, advanced threats, data breaches, ransomware,
etc. Such a system requires effort from our community in terms of
automated threat categorization on large scale data: while this could
rely on AV labels, several pieces of work in the literature state that
they are in general not very reliable. Another line of research that
we wish to explore is risk prediction for individual users, whose
usage behavior is less regular compared to the enterprise users; in
future work, we plan to explore new techniques and evaluate other
datasets to better capture those users’ behavior and obtain better
prediction accuracy.
REFERENCES
[1] Robert Axelrod and Rumen Iliev. 2014. Timing of cyber conflict. Proceedings of
the National Academy of Sciences 111, 4 (2014), 1298–1303.
[2] Oleg Bogomolniy. 2017. Cyber Insurance Conundrum: Using CIS Critical
Security Controls for Underwriting Cyber Risk. https://www.sans.org/reading-
room/whitepapers/legal/cyber-insurance-conundrum-cis-critical-security-
controls-underwriting-cyber-risk-37572. (2017).
[3] Leo Breiman. 2001. Random Forests. Machine Learning 45, 1 (2001), 5–32.
[4] Davide Canali, Leyla Bilge, and Davide Balzarotti. 2014. On the effectiveness
of risk prediction based on users browsing behavior. In Proceedings of the 9th
ACM symposium on Information, computer and communications security. ACM,
171–182.
[5] Duen Horng Chau, Carey Nachenberg, Jeffrey Wilhelm, Adam Wright, and
Christos Faloutsos. 2011. Polonium: Tera-Scale Graph Mining and Inference for
Malware Detection. In SIAM International Conference on Data Mining (SDM) 2011,
Vol. 25. 131–142.
[6] Lucian Constantin. 2011. MSE false positive detection forces Google to update
Chrome. The Inquirer, http://www.theinquirer.net/inquirer/news/2113892/mse-
false-positive-detection-forces-google-update-chrome. (October 2011).
J David Cummins, Martin F Grace, and Richard D Phillips. 1999. Regulatory
solvency prediction in property-liability insurance: Risk-based capital, audit
ratios, and cash flow simulation. Journal of Risk and Insurance (1999), 417–458.
[8] Experian. 2015. Data Breach Industry Forecast. https://www.experian.com/
assets/data-breach/white-papers/2015-industry-forecast-experian.pdf. (2015).
[9] Yufei Han and Yun Shen. 2016. Accurate Spear Phishing Campaign Attribution
and Early Detection. In Proceedings of the 31st ACM Symposium on Applied
Computing.
[7]
[12]
[10] G. R. Hileman, S. M. Mehmud, and M. A. Rosenberg. 2016. Risk Scoring in Health
Insurance. https://www.soa.org/Files/Research/research-2016-risk-scoring-
health-insurance.pdf. (2016).
[11] Tin Kam Ho. 1995. Random Decision Forest. In Proceedings of the 3rd International
Conference on Document Analysis and Recognition. 278–282.
IARPA. 2015. Cyber-attack Automated Unconventional Sensor Environment
(CAUSE). https://www.iarpa.gov/index.php/research-programs/cause. (2015).
[13] Malachi Jones, Georgios Kotsalis, and Jeff S Shamma. 2013. Cyber-attack forecast
In
modeling and complexity reduction using a game-theoretic framework.
Control of Cyber-Physical Systems. Springer, 65–84.
[14] Alexander D. Korzyk, Sr. 1998. A forecasting model for internet security attacks.
In National Information System Security Conference.
[15] Aorato Labs. 2014. The Untold Story of the Target Attack Step by Step. https:
//aroundcyber.files.wordpress.com/2014/09/aorato-target-report.pdf. (Septem-
ber 2014).
[16] Fanny Lalonde Levesque, Jude Nsiempba, José M Fernandez, Sonia Chiasson,
and Anil Somayaji. 2013. A clinical study of risk factors related to malware
infections. In Proceedings of the 2013 ACM SIGSAC conference on Computer &
communications security. ACM, 97–108.
John Leyden. 2010. Horror AVG update ballsup bricks Windows 7. The Register,
http://www.theregister.co.uk/2010/12/02/avgautoimmuneupdate/. (December
2010).
[18] Andy Liaw and Matthew Wiener. 2002. Classification and regression by random-
[17]
Forest. R news 2, 3 (2002), 18–22.
[19] Yang Liu, Armin Sarabi, Jing Zhang, Parinaz Naghizadeh, Manish Karir, Michael
Bailey, and Mingyan Liu. 2015. Cloudy with a chance of breach: Forecasting
cyber security incidents. In 24th USENIX Security Symposium (USENIX Security
15). 1009–1024.
[20] Declan McCullogh. 2010. Buggy McAfee update whacks Windows XP PCs.
CNET, http://www.cnet.com/news/buggy-mcafee-update-whacks-windows-
xp-pcs/. (April 2010).
[21] Yuxin Meng, Wenjuan Li, and Lam-For Kwok. 2014. Enhancing email classifica-
tion using data reduction and disagreement-based semi-supervised learning. In
Proceedings of IEEE International Conference on Communications 2014. 622–627.
[22] Antonio Nappa, Richard Johnson, Leyla Bilge, Juan Caballero, and Tudor Du-
mitras. 2015. The attack of the clones: a study of the impact of shared code on
vulnerability patching. In Security and Privacy (SP), 2015 IEEE Symposium on.
IEEE, 692–708.
[23] Kartik Nayak, Daniel Marino, Petros Efstathopoulos, and Tudor Dumitraş. 2014.
Some vulnerabilities are different than others. In Research in Attacks, Intrusions
and Defenses. Springer International Publishing, 426–446.
[24] M. Ovelgonne, T. Dumitras, A. Prakash, V.S. Subrahmanian, and B. Wang. 2016.
Understanding the Relationship between Human Behavior and Susceptibility
to CyberAttacks: A DataDriven Approach. In ACM Transactions on Intelligent
Systems and Technology.
[25] Clifton Phua, Vincent C. S. Lee, Kate Smith-Miles, and Ross W. Gayler. 2010. A
Comprehensive Survey of Data Mining-based Fraud Detection Research. Com-
puting Research Repository abs/1009.6119 (2010).
[26] Emil Protalinski. 2008. AVG incorrectly flags user32.dll in Windows XP
SP2/SP3. Ars Technica, http://arstechnica.com/information-technology/2008/
11/avg-incorrectly-flags-user32-dll-in-windows-xp-sp2sp3/. (November 2008).
Insurance 2020 and beyond: Reaping the dividends of cyber re-
silience. http://www.pwc.com/gx/en/insurance/publications/assets/reaping-
dividends-cyber-resilience.pdf. (2016).
[27] PWC. 2016.
[28] Alexander S Reisz and Claudia Perlich. 2007. A market-based framework for
bankruptcy prediction. Journal of Financial Stability 3, 2 (2007), 85–131.
Igor Santos, Javier Nieves, and Pablo G. Bringas. 2011. Semi-supervised Learning
for Unknown Malware Detection. In Proceedings of International Symposium on
Distributed Computing and Aritifical Intelligence 2011. 415–422.
[29]
https://
[30] Kyle Soska and Nicolas Christin. 2014. Automatically detecting vulnerable
websites before they turn malicious. In 23rd USENIX Security Symposium (USENIX
Security 14). 625–640.
[31] Amarnag Subramanya and Jeff Bilmes. 2011. Semi-supervised learning with
measure propagation. Journal of Machine Learning. Research 12 (2011), 3311–
3370.
[32] Symantec. 2016.
Internet Security Threat Report Vol. 21.
www.symantec.com/security-center/threat-report. (April 2016).
[33] Christopher T. Symons and Justin M. Beaver. 2012. Nonparametric Semi-
supervised Learning for Network Intrusion Detection: Combining Performance
Improvements with Realistic In-situ Training. In Proceedings of the 5th ACM
Workshop on Security and Artificial Intelligence (AISec). ACM, New York, NY,
USA, 49–58.
[34] Acar Tamersoy, Kevin Roundy, and Duen Horng Chau. 2014. Guilt by association:
large scale malware detection by mining file-relation graphs. In Proceedings of
the 20th ACM SIGKDD international conference on Knowledge Discovery and Data
Mining. ACM, 1524–1533.
[35] Aaron Tan. 2007. Flawed Symantec update cripples Chinese PCs. CNET, http:
//www.cnet.com/news/flawed-symantec-update-cripples-chinese-pcs/. (May
2007).
[36] Olivier Thonnard, Leyla Bilge, Anand Kashyap, and Martin Lee. 2015. Are you
at risk? Profiling organizations and individuals subject to targeted attacks. In
Financial Cryptography and Data Security. Springer Berlin Heidelberg, 13–31.
[37] Kalyan Veeramachanent, Ignaclo Arnaldo, Alfredo Cuesta-Infante, Korrapati
Vamsl, Costa Basslas, and Li Ke. 2016. AI2: Training a big data machine to defend.
In Proceedings of the 2nd IEEE International Conference on Big Data Security.
[38] Ting-Fang Yen, Victor Heorhiadi, Alina Oprea, Michael K Reiter, and Ari Juels.
2014. An epidemiological study of malware encounters in a large enterprise. In
Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications
Security. ACM, 1117–1130.
Session F2:  Insights from Log(in)sCCS’17, October 30-November 3, 2017, Dallas, TX, USA1311