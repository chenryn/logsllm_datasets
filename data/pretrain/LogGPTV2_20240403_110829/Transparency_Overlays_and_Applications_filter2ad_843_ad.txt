snap,events∆
j ← min{i | CheckCom(cMo, events[1 : i])}
events∆ ← events[j + 1 : ]
if (CheckSnap(snap) = 0) ∨ (isOrdered(events∆) = 0) return 0
return ε
if (time(events∆[1])  tMo) return fail
π
b ← CheckInconsistent(cAu, tAu, cMo, π)
if (b = 1) return (snapAu, snapMo, ⊥, π)
(repeat for all (event, rcpt) ∈ events(Au)
bad )
event,rcpt
π
bAu ← CheckSnap(snapAu)
if (bAu = 0) return fail
if (tAu > tMo) return fail
π ← DemoInconsistent(events, tAu)
b ← CheckInconsistent(cAu, tAu, cMo, π)
if (b = 1) return (snapAu, snapMo, ⊥, π)
π ← DemoNotIncl(cMo, events, event)
b ← CheckNotIncl(cMo, event, π)
9
10
11
12
13
b ← CheckNotIncl(cMo, event, π)
if (b = 1) return (snapAu, snapMo, (event, rcpt), π)
if (b = 1) return (snapAu, snapMo, (event, rcpt), π)
return fail
return fail
Figure 5: The Gossip protocol for pledged transparency overlays. The optional part of the protocol is marked with
dashed lines.
Proof. (Sketch.) Correctness and compact auditability follow from the same arguments as in the proof of
Theorem 4.4. The proof of consistency is nearly identical, with the main diﬀerences being that there are
fewer cases to rule out if CheckEvidence(pk LS, evidence) = 0 (as only one type of evidence can be produced),
and that the maps QAu and QMo used in the proof store slightly diﬀerent values.
Similarly, the proof of non-frameability is essentially a shortened version of the proof of Theorem 4.4. In
particular, the lack of receipts in the basic setting means that some of the bad events introduced in this proof
are irrelevant, so we need only consider events E1 (the event in which a proof of inconsistency is faked) and
E2 (the event in which a snapshot is forged). The reductions that bound the probability of these events are
nearly identical to the reductions in the proof of Equation 3 and 4 respectively.
5 Certiﬁcate Transparency
In this section, we describe how CT instantiates a pledged transparency overlay (as deﬁned formally in
Section 4.2), discuss how the formal notions of overlay security imply more intuitive notions of security
speciﬁc to the setting of issuing certiﬁcates, and ﬁnally discuss the requirements of a practical deployment of
CT.
5.1 CT is a secure pledged overlay
As depicted in Section 2, Certiﬁcate Transparency has three actors in the system Sys: a certiﬁcate authority
CA, a website owner Site, and a client Client. One of the ﬁrst two actors must participate in the Log
protocol,3 to ensure that the certiﬁcate issued by CA to Site ends up in the log, and the client participates in
the CheckEntry protocol to check that the certiﬁcate presented to it by a website is in the log.
In the parlance of CT, an event is a (basic) certiﬁcate cert = (pk name, σCA), where σCA is the CA’s signature
on the site’s public key pk name,4 a receipt is a signed certiﬁcate timestamp (SCT), and a snapshot is a signed
tree head (STH). For the notion of timing needed for snapshots and receipts, one could pick the current local
time of the log server and either use this value directly as t or incorporate into it some buﬀer period, which
3This means that either the website obtains the signed certiﬁcate from the CA and then goes on to enter it into the log, or
the CA signs the certiﬁcate and enters it into the log before returning the extended certiﬁcate to the website.
4For simplicity, we include here only the most basic version of the information that needs to be checked for and included in
a certiﬁcate.
13
/
/
o
o
o
o
/
/
o
o
is referred to in the CT documentation as the maximum merge delay (MMD). We discuss this further in
Section 5.3. Finally, CT instantiates GenEventSet as follows:
Site(pk name)
pk name
CA
σ
cert
return {cert}
r←− Sign(sk CA, pk name)
cert ← (pk name, σ)
return {cert}
The rest of the protocols needed for the transparency overlay can be instantiated exactly as in Section 4.3,
so Theorem 4.4 carries over directly and we can see that CT provides a secure pledged transparency overlay.
5.2 Further security implications
We have just demonstrated that CT provides a secure transparency overlay, but it is not clear what this
means for the speciﬁc setting of certiﬁcate issuance. To explore this, we ﬁrst remind ourselves of the security
of the underlying system (i.e., the issuance of basic certiﬁcates), in which (1) it should be diﬃcult to produce
a basic certiﬁcate without contacting the CA, and (2) an honest client should accept only (basic) certiﬁcates
that verify. These are clearly satisﬁed assuming the correctness and unforgeability of the signature scheme.
Combining the underlying issuance security with the security of the overlay, we can argue that three more
intuitive security goals are largely satisﬁed. First, an extended certiﬁcate (i.e., a certiﬁcate augmented
with an SCT) should not pass veriﬁcation if it has not been jointly produced by the CA and
log server. This holds because the underlying issuance security implies that it is diﬃcult to produce cert
without the CA, and non-frameability implies that it is diﬃcult to produce rcpt without the log server, so it
should be diﬃcult to produce (cert, rcpt) without both the CA and the log server.
Second, honest clients shouldn’t accept “bad” certiﬁcates; i.e., certiﬁcates that are either
improperly formatted or not being monitored. The underlying issuance security says that if cert
does not verify then the client won’t accept. Following this, the honest client accepts only if the auditor
indicates that the certiﬁcate is in the log. By consistency, the auditor’s view of the log is consistent with the
monitor’s view from the last time they engaged in the Gossip protocol (unless evidence has been produced
to the contrary, at which point we can assume the auditor ceases communication with the log server). If
the certiﬁcate is older than this, then the certiﬁcate is deﬁnitely being monitored; if it is newer, then it is
not guaranteed that the certiﬁcate is being monitored, but if it is not then the auditor can at least detect
this during its next iteration of the Gossip protocol. Thus, honest clients never accept improperly formatted
certiﬁcates, and are unlikely to accept unmonitored certiﬁcates provided that the auditor and monitor are
engaging in the Gossip protocol with suﬃcient frequency.
Finally, if a log server is misbehaving by omitting certiﬁcates from the log that it promised
to include, it should be possible to blame it. If a log server refuses to answer queries, then there is
little we can do about this in the context of our overlay (although in a practical setting with more than one
log server this problem could be mitigated).
If a log server does answer, then it can be formally blamed
by accountability, as the SCT acts as non-repudiable evidence that the log server has promised to include a
certiﬁcate and the corresponding proof of non-inclusion demonstrates that it has not done so.
5.3 Practical considerations
Finally, we discuss some necessary alterations that would be made to our protocol if used in a real deployment.
Batched additions to the log. In Figure 2, the log server currently updates the log during the Log
protocol, and as a result includes the exact current time in the SCT. To avoid doing this operation every
time, this process would be batched, so the time in the SCT would instead be some time in the near future
(e.g., the end of the current day). This gap between the current and promised times is referred to in the CT
documentation as the maximum merge delay (MMD).
Collapsing the overlay into the system. As discussed in the CT documentation, in a real deployment
we expect auditors to interact with many diﬀerent log servers (as the certiﬁcates seen by clients may be
logged in many diﬀerent places), but expect monitors to focus on one log and the certiﬁcates it contains.
There are therefore two possible models: in one, the auditors and monitors are operated as separate services,
and monitors can even be used as backup log servers. In the other, the role of the auditor could collapse into
the client (e.g., it could be run as a browser extension and responses could be cached), and the role of the
14
/
/
o
o
monitor could collapse (at least partially) into the website, who could monitor the log to at least keep track
of its own certiﬁcates.
Privacy concerns. While SSL certiﬁcates are public and thus storing them in a public log presents no
privacy concern, information might be revealed about individual users through the certiﬁcates queried by
the auditor (to both the log server and monitor), as well as the choice of signed tree heads and SCTs. We
view this as an interesting area for future research, but mention brieﬂy that some of these concerns can be
mitigated — with minimal eﬀect on the security of the transparency overlay — by omitting the optional part
of Figure 5, in which the auditor reveals to the monitor some of the certiﬁcates that it has seen.
6 Amplifying Bitcoin’s Security
Although Bitcoin already provides a large degree of transparency — as its transaction ledger, called the
blockchain, is globally visible — it does not satisfy the requirements of a transparency overlay.
In partic-
ular, the miners, who play a role analogous to the log server in producing the blockchain, are not known
entities and thus cannot be held responsible; this in turn means that consistency and non-frameability cannot
be satisﬁed. In this section, we thus begin by presenting in Section 6.1 a secure basic transparency overlay
for Bitcoin.
One might naturally wonder whether such a distinction is purely pedantic; i.e., if overlaying transparency
on top of a transparent system provides any actual beneﬁts. To answer this question in the aﬃrmative, we
discuss in Section 6.2 the beneﬁts (in terms of both security and eﬃciency) that are achieved by applying
the transparency overlay. In particular, we show that the addition of a secure transparency overlay relieves
regular Bitcoin users (i.e., users wishing only to spend and receive bitcoins) from having to store and verify
the entire Bitcoin blockchain, which as of this writing is over 80GB.5 To go even further, we argue that if one
is willing to adopt a distributed rather than a fully decentralized solution (i.e., if one is willing to trust any
set of named parties), then the entire Bitcoin system collapses into a CT-like transparency overlay and the
need for hash-based mining is eliminated.
6.1 A transparency overlay for Bitcoin