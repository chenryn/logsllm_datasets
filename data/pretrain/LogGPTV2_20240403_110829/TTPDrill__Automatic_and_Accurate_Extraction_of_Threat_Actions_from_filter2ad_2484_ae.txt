equal than the independent classiﬁcation, we conclude that post-processing is
needed for techniques prediction. It is worth noting that, approach “Hanging
node” is barely higher than the independent classiﬁcation compared to “Con-
ﬁdence propagation”, while the opposite is true in the actual tests. Approach
“Hanging node” also presents worse results when the tactics prediction is per-
14
V. Legoy et al.
fect. For this reason, we conclude that approach “Conﬁdence propagation” might
likely overperform “Hanging node”. Furthermore, “Hanging node” and “Conﬁ-
dence propagation” approaches carry on very diﬀerent strategies and, from our
testing, they seem targeting diﬀerent types of techniques. “Hanging node” seems
to aﬀect very little, but eﬃciently, the results from the independent classiﬁcation
and only modiﬁes results of the techniques with the highest number of reports.
“Conﬁdence propagation” targets any techniques and modify many predictions,
which would potentially improve the classiﬁcation for the hard-to-predict tech-
niques. However, from our observation, this approach succeeds almost as often
as it fails, thus worsening the prediction of some labels while improving the
prediction of others.
At the end of the evaluation, we are not in a position to draw conclusive
proves for precisely ranking the described post-processing methods. Based on
the analysis of the results, not using any post-processing method for the tactics
classiﬁcation is probably a safe choice. For what concerns the techniques, we
believe that one among “Conﬁdence propagation” and “Hanging node” would
likely improve the independent classiﬁcation. In what follows, within our tool,
we decided to implement both approaches but to use “Hanging node” as default
due to its better results in our current dataset. However, in case of retraining on
a new dataset, the tool will be compare results coming from the two approaches
and dynamically choose the one that best perform.
6
rcATT
One important contribution of our research was to implement our ﬁndings in a
tool that would allow security experts to automate the analysis of CTRs. We
call our tool rcATT, as for “reports classiﬁcation by adversarial tactics and tech-
niques”. Based on the previous two sections, we decided to implement a classiﬁ-
cation that uses a TF-IDF weighted bag-of-words text representation with a bi-
nary relevance Linear SVC. This classiﬁcation is followed with a post-processing
performed either via the hanging node approach or the conﬁdence propagation
one (depending on the training data).
Figure 2 illustrate tools’ main functional building blocks. From a cyber threat
report, in a text format, entered by the users, our trained model predicts dif-
ferent tactics and techniques. The user will be able to visualize the results and
the conﬁdence score associated with each prediction, either based on the Min-
Max scaling of the decision function score from the classiﬁer or the re-evaluation
score, based on the post-processing method. When users do not agree with the
results, they can change them. In all cases, new results can be saved with the old
training data (the original labelled cyber threat reports) so to be used to train
the classiﬁer again. The retraining of the classiﬁer must be activated manually
by the user. This is done to avoid automated retraining that might slow down
the tool or mistakenly involve unwanted data. As already mentioned, during the
retraining, the tool also autonomously choose which post-processing method to
use to maximize predictions results. This approach involves also the dynamic
Automated Retrieval of TTPs from Threat Reports
15
Fig. 2: Organisation of rcATT.
deﬁnition of speciﬁc thresholds (e.g., the one related to the hanging node meth-
ods).
Classiﬁcation results can be saved in a JSON ﬁle using STIX format. This
later allows any other tool to easily access all identiﬁed tactics and techniques.
General information about the predictions is exported in a STIX “Report” object
(e.g., title of the original report, dates, etc.). The “description” property of the
report object represents the original content of the CTR. Most important, all
prediction results (as well as any prediction added by the users) are available
using the speciﬁc identiﬁcation numbers available within the STIX version of the
ATT&CK framework and linked to the Report object using the “object refs”
property.
Finally, the tool works with two graphic modes: command-line and graphical
interface (Figure 3). The command-line version of the tool is meant to be eﬃcient
to use (e.g., cases in which the user want to predict TTPs from a large number
of CTRs). The graphical interface is interactive and allows users to modify clas-
siﬁcation results and save the changes to the training set and thus give feedback
to the tool.
Modify resultsUnlabeledCTRLabeledCTRs Predict tacticsand techniquesSave for trainingSave as STIXformatTrain modelCTR withTTPs inSTIXTrainedclassiﬁerResults fromprediction16
V. Legoy et al.
Fig. 3: rcATT graphical interface.
7 Related work and comparison with similar approaches
The vast majority of existing scientiﬁc work on the automated analysis of (un-
structured) CTRs concerns the extraction of IOCs [16,34]. Further related work
looks at other unstructured sources, like hacker forums, to extract insights on
adversarial tools [6], or on more general security vulnerabilities [24] and related
concepts [14,25].
Only few research papers aim to retrieve TTPs in unstructured data, as we
do. One of them was written by Zhu et al. [33] and presents FeatureSmith, a
tool that mines the security literature to learn features for training machine
learning classiﬁers to detect Android malware. FeatureSmith is speciﬁcally tai-
lored to the task of malware detection and cannot be easily generalized to other
other settings. In contrast, our focus lies on the automated extraction of general
ATT&CK tactics and techniques.
TTPDrill [11] and ActionMiner [12], developed by Husari et al., but also the
tool by Ayoade et al. [2] are the closest tools to ours, as they extract threat
actions from CTRs in order to link them to speciﬁc ATT&CK tactics and tech-
niques. The biggest problem with those works is, however, that their achieved
results cannot be reproduced by the scientiﬁc community at large as their used
datasets or their tools are not openly available. In fact, [2] reports a big diﬀer-
ence in accuracy when running TTPDrill [11] on their own (closed) datasets in
comparison to the accuracy achieved on the (closed) dataset as reported in [11].
Due to the closed source nature of these works, these inconsistencies cannot be
explained and motivate our open study on the extraction of TTPs from CTRs. In
comparison to all related work, our approach is described for easy reproducibil-
ity by only using open data and by making our ﬁnal tool publicly available as
open source.
Automated Retrieval of TTPs from Threat Reports
17
On the conceptual level, however, there are also some key diﬀerences between
the above-stated approaches and ours. First of all, TTPDrill [11] uses a diﬀerent
classiﬁcation approach without a clear separation among tactics and techniques
(treated as similar labels). In this regard, Ayoade et al. [2] describe a more similar
approach, clearly separating tactics and techniques, despite not implementing a
fully-contained tool in the end. Both tools employ diﬀerent classiﬁer and/or
pre-processing approaches with respect to the ones implemented within rcATT.
Finally, none of the two works allow users to feedback results back to the tool
making any improvement impossible. Again, due to the lack of open-source code
or used datasets (as well as any detailed description on how to re-implement
their solutions), any further comparison on classiﬁcation results is not possible.
A diﬀerent tool, called Unfetter Insight, was instead available on Github [31].
Despite lacking a comprehensive description (e.g., publication) that allows a
qualitative analysis with respect to rcATT, we could in this case carry out a
quantitative comparisong between the classiﬁcation results. Unfetter Insight has
been developed to detect possible ATT&CK tactics and techniques within re-
ports in TXT, PDF or HTML format. Based on our understanding of the code,
the detection is implemented by the Babelﬁsh software created by W. Kins-
man in 2017. This software learns topics from a wiki-like corpus and retrieve
the presence of those topics in a document. The tool creates text convolutions
from unknown documents, identifying those having a good overlap with the ones
presented in the corpus. Based on the term frequency of the vocabulary in the
selected convolutions, tactics and techniques are predicted using a binary rele-
vance Multinomial Naive Bayes classiﬁer. It is ﬁnally worth noting that Unfetter
Insight assumptions for the models are quite diﬀerent with respect to the ones
used in rcATT. In fact, we base our classiﬁcation on a training set of labelled
reports while they use a dictionary-like learning set. For this reason, we could
not add our training set without compromising the concept behind Babelﬁsh.
Therefore, we decided to proceed with a comparison by using their training set
within both solutions6.
Table 6 presents the classiﬁcation results of rcATT and Unfetter Insight
on identical training set and dataset. The table shows that Unfetter Insight
underperforms in the majority of the proposed metrics and overperforms only
in the one we considered the least important in our ﬁrst assumptions.
6 Interestingly, their wiki-like corpus is, in fact, the content of the ATT&CK website
with the techniques deﬁnitions, and thus a subset of our dataset.
18
V. Legoy et al.
Table 6: Comparison between rcATT and Unfetter Insight.
Tools
Micro
Precision Recall
Macro
F0.5 Precision Recall
F0.5
19.09% 26.76% 20.25% 19.17% 23.14% 19.28%
Tactics
rcATT 79.31% 12.20% 37.75% 81.73% 8.21% 23.23%
Unfetter
insight
Techniques
rcATT 72.22% 2.07% 9.30% 20.60% 4.33% 10.11%
Unfetter
insight
3.54% 1.11% 2.46% 1.31% 0.64% 0.74%
8 Conclusion
With its constant growth, CTI sharing has become an essential activity of the
security lifecycle. Despite this, security teams around the world still face the
challenge of handling huge amount of threat intelligence data. Above all, dealing
with unstructured data remain a cumbersome and time-consuming task.
The work presented in this paper aims at simplifying this task by enabling
automated extraction of valuable CTI information, namely Tactics, Techniques
and Procedures (TTPs), from textual cyber security reports. Our approach takes
a cue from the ones of Ayoade et al. [2] and Husari et al. [11] and investigates
text multi-label classiﬁcation techniques that can fulﬁll the aforementioned goal.
Additionally, we propose approaches for post-processing classiﬁcation results and
improving classiﬁers’ overall performance in terms of precision and recall. By
taking advantage of our training dataset, the MITRE ATT&CK framework, we
show that relationships among the chosen classiﬁcation labels, the framework’s
tactics and techniques, can help reﬁning the classiﬁcation and decreasing the
number false-positives.
Based on our ﬁndings, we developed rcATT, an interactive tool for the au-
tomated analysis of cyber threat reports. The tool aims at supporting secu-
rity experts to dig into human-readable data and extract ATT&CK tactics and
techniques that most likely describe the content of the text. rcATT gives users
the possibility to dinamically adjust or ﬁx the classiﬁcation results and, conse-
quently, feedback the internal classiﬁer with correct information, improving its
performance over time.
The tool has been tested and compared with state-of-the-art approaches dis-
cussed in literature or already available as open-source solutions. Results of
these comparisons show rcATT competitiveness and validate the research di-
rections foreseen within our work. Finally, rcATT has been recently integrated
into tool-chains of real operational corporate Computer Emergency Response
Teams (CERTs) to support Threat Intelligence sharing and analytics processes.
This last experience further conﬁrms the importance of researches of this kind
Automated Retrieval of TTPs from Threat Reports
19
and their likely impact in broader contexts such as automated incident handling
and response.
References
1. AT&T: Alienvault open threat exchange (2019), https://otx.alienvault.com
2. Ayoade, G., Chandra, S., Khan, L., Hamlen, K., Thuraisingham, B.: Automated
threat report classiﬁcation over multi-source data. In: 2018 IEEE 4th International
Conference on Collaboration and Internet Computing (CIC). pp. 236–245. IEEE
(2018)
3. Barnum, S.: Standardizing cyber threat intelligence information with the struc-
tured threat information expression (stix). Mitre Corporation 11, 1–22 (2012)
4. Bast, H., Korzen, C.: A benchmark and evaluation for text extraction from pdf.
In: Proceedings of the 17th ACM/IEEE Joint Conference on Digital Libraries. pp.
99–108. IEEE Press (2017)
5. Benites, F., Sapozhnikova, E.: Improving multi-label classiﬁcation by means of
cross-ontology association rules. bioinformatics 2(9), 20 (2015)
6. Deliu, I., Leichter, C., Franke, K.: Collecting cyber threat intelligence from hacker
forums via a two-stage, hybrid process using support vector machines and latent
dirichlet allocation. In: 2018 IEEE International Conference on Big Data (Big
Data). pp. 5008–5013. IEEE (2018)
7. Dog, S.E., Tweed, A., Rouse, L., Chu, B., Qi, D., Hu, Y., Yang, J., Al-Shaer, E.:
Strategic cyber threat intelligence sharing: a case study of ids logs. In: 2016 25th
International Conference on Computer Communication and Networks (ICCCN).
pp. 1–6. IEEE (2016)
8. Edmonds, J.: Optimum branchings. Journal of Research of the national Bureau of
Standards B 71(4), 233–240 (1967)
9. Gartner: Threat intelligence deﬁnition (2013), https://www.gartner.com/en/
documents/2487216
10. Gilbert, E.N., Pollak, H.O.: Steiner minimal trees. SIAM Journal on Applied Math-
ematics 16(1), 1–29 (1968)
11. Husari, G., Al-Shaer, E., Ahmed, M., Chu, B., Niu, X.: Ttpdrill: Automatic and
accurate extraction of threat actions from unstructured text of cti sources. In:
Proceedings of the 33rd Annual Computer Security Applications Conference. pp.
103–115. ACM (2017)
12. Husari, G., Niu, X., Chu, B., Al-Shaer, E.: Using entropy and mutual information
to extract threat actions from cyber threat intelligence. In: 2018 IEEE International
Conference on Intelligence and Security Informatics (ISI). pp. 1–6. IEEE (2018)
13. IBM: Ibm x-force exchange (2019), https://exchange.xforce.ibmcloud.com
14. Jones, C.L., Bridges, R.A., Huﬀer, K.M., Goodall, J.R.: Towards a relation extrac-
tion framework for cyber-security concepts. In: Proceedings of the 10th Annual
Cyber and Information Security Research Conference. p. 11. ACM (2015)
15. Kulczynski, S.: Die pﬂanzenassoziationen der pieninen. In: Proceedings of the
Eighth International Joint Conference on Natural Language Processing (Volume
2: Short Papers), Bulletin International de l’Academie Polonaise des Sciences et
des Lettres, Classe des Sciences Mathematiques et Naturelles B. pp. 57–203 (1927)
16. Liao, X., Yuan, K., Wang, X., Li, Z., Xing, L., Beyah, R.: Acing the ioc game:
Toward automatic discovery and analysis of open-source cyber threat intelligence.
In: Proceedings of the 2016 ACM SIGSAC Conference on Computer and Commu-
nications Security. pp. 755–766. ACM (2016)
20
V. Legoy et al.
17. Loper, E., Bird, S.: Nltk: The natural language toolkit. In: In Proceedings of the
ACL Workshop on Eﬀective Tools and Methodologies for Teaching Natural Lan-
guage Processing and Computational Linguistics. Philadelphia: Association for
Computational Linguistics (2002), https://www.nltk.org/
18. Luaces, O., D´ıez, J., Barranquero, J., del Coz, J.J., Bahamonde, A.: Binary rele-
vance eﬃcacy for multilabel classiﬁcation. Progress in Artiﬁcial Intelligence 1(4),
303–313 (2012)
19. Manning, C.D., Raghavan, P., Sch¨utze, H.: Scoring, term weighting and the vector
space model. Introduction to information retrieval 100, 2–4 (2008)
20. Martello, S.: Knapsack problems: algorithms and computer implementations.
Wiley-Interscience series in discrete mathematics and optimiza tion (1990)
21. Mehlhorn, K.: A faster approximation algorithm for the steiner problem in graphs.
Information Processing Letters 27(3), 125–128 (1988)
22. Mikolov, T., Chen, K., Corrado, G., Dean, J.: Eﬃcient estimation of word repre-
sentations in vector space. arXiv preprint arXiv:1301.3781 (2013)
23. mitre: Mitre att&ck (2019), https://attack.mitre.org/
24. Mulwad, V., Li, W., Joshi, A., Finin, T., Viswanathan, K.: Extracting informa-
tion about security vulnerabilities from web text. In: Proceedings of the 2011
IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent
Agent Technology-Volume 03. pp. 257–260. IEEE Computer Society (2011)
25. Ramnani, R.R., Shivaram, K., Sengupta, S., et al.: Semi-automated information
extraction from unstructured threat advisories. In: Proceedings of the 10th Inno-
vations in Software Engineering Conference. pp. 181–187. ACM (2017)
26. Read, J., Pfahringer, B., Holmes, G., Frank, E.: Classiﬁer chains for multi-label
classiﬁcation. Machine learning 85(3), 333 (2011)
27. Scikit-learn: Api reference
scikit-learn 0.21.3 documentation (2019), https://
scikit-learn.org/stable/modules/classes.html
28. Soni, A., Pappu, A., Ni, J.C.m., Chevalier, T.: Post-processing techniques for im-
proving predictions of multilabel learning approaches. In: Proceedings of the Eighth
International Joint Conference on Natural Language Processing (Volume 2: Short
Papers). pp. 61–66 (2017)
29. SpolaˆoR, N., Cherman, E.A., Monard, M.C., Lee, H.D.: A comparison of multi-
label feature selection methods using the problem transformation approach. Elec-
tronic Notes in Theoretical Computer Science 292, 135–151 (2013)
30. Tsoumakas, G., Katakis, I., Vlahavas, I.: Mining multi-label data. In: Data mining
and knowledge discovery handbook, pp. 667–685. Springer (2009)
31. Unfetter: Unfetter
unfetter-insight
insight
(2018), https://github.com/unfetter-discover/
32. Wu, Y., Tseng, B.L., Smith, J.R.: Ontology-based multi-classiﬁcation learning for
video concept detection. In: 2004 IEEE International Conference on Multimedia
and Expo (ICME) (IEEE Cat. No.04TH8763). vol. 2, pp. 1003–1006 Vol.2 (June
2004). https://doi.org/10.1109/ICME.2004.1394372
33. Zhu, Z., Dumitra¸s, T.: Featuresmith: Automatically engineering features for mal-
ware detection by mining the security literature. In: Proceedings of the 2016 ACM
SIGSAC Conference on Computer and Communications Security. pp. 767–778.
ACM (2016)
34. Zhu, Z., Dumitras, T.: Chainsmith: Automatically learning the semantics of ma-
licious campaigns by mining threat intelligence reports. In: 2018 IEEE European
Symposium on Security and Privacy (EuroS&P). pp. 458–472. IEEE (2018)