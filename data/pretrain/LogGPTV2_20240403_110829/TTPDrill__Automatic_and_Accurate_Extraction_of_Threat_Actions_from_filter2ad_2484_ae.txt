### Post-Processing Techniques for Predictions

In comparison to independent classification, our analysis suggests that post-processing is necessary for improving the accuracy of techniques prediction. It is noteworthy that the "Hanging node" approach only slightly outperforms independent classification, while the "Confidence propagation" approach shows more significant improvements in actual tests. However, the "Hanging node" method yields poorer results when tactics prediction is perfect. Therefore, we conclude that the "Confidence propagation" approach is likely to outperform the "Hanging node" method.

The "Hanging node" and "Confidence propagation" approaches employ different strategies. Our testing indicates that they target different types of techniques. The "Hanging node" approach has a minimal but efficient impact on the results from independent classification, primarily affecting techniques with the highest number of reports. In contrast, the "Confidence propagation" approach targets a broader range of techniques and modifies many predictions, potentially improving the classification for hard-to-predict techniques. However, this approach often succeeds as frequently as it fails, leading to both improved and worsened predictions for different labels.

Based on our evaluation, we cannot conclusively rank the described post-processing methods. For tactics classification, not using any post-processing method may be a safe choice. For techniques, either the "Confidence propagation" or "Hanging node" approach is likely to improve independent classification. In our tool, we have implemented both approaches, with "Hanging node" set as the default due to its better performance on our current dataset. If retraining on a new dataset, the tool will compare the results from both approaches and dynamically select the one that performs best.

### rcATT: A Tool for Automated Analysis of Cyber Threat Reports

One of the key contributions of our research is the implementation of our findings in a tool called rcATT, which stands for "reports classification by adversarial tactics and techniques." This tool automates the analysis of cyber threat reports (CTRs) for security experts. Based on our previous sections, we decided to implement a classification system that uses a TF-IDF weighted bag-of-words text representation with a binary relevance Linear SVC. This classification is followed by post-processing, which can be performed via either the "Hanging node" or "Confidence propagation" approach, depending on the training data.

**Functional Building Blocks:**
1. **Input:** Users input a CTR in text format.
2. **Prediction:** The trained model predicts different tactics and techniques.
3. **Visualization:** Users can visualize the results and associated confidence scores, which are based on the Min-Max scaling of the decision function score from the classifier or the re-evaluation score from the post-processing method.
4. **Modification:** Users can modify the results if they disagree with them.
5. **Retraining:** New results can be saved with the old training data (the original labeled CTRs) to retrain the classifier. Retraining must be manually activated to avoid automated retraining that might slow down the tool or involve unwanted data. During retraining, the tool autonomously selects the best post-processing method to maximize prediction accuracy.
6. **Output:** Classification results can be saved in a JSON file using STIX format, allowing other tools to easily access the identified tactics and techniques. General information about the predictions is exported in a STIX "Report" object, and all prediction results (including user-added ones) are linked to the Report object using the "object refs" property.

**User Interface:**
- **Command-line Version:** Efficient for predicting TTPs from a large number of CTRs.
- **Graphical Interface:** Interactive, allowing users to modify classification results and save changes to the training set, providing feedback to the tool.

### Related Work and Comparison with Similar Approaches

Most existing scientific work on the automated analysis of unstructured CTRs focuses on the extraction of Indicators of Compromise (IOCs). Other related work examines unstructured sources like hacker forums to extract insights on adversarial tools or general security vulnerabilities.

Only a few research papers aim to retrieve TTPs from unstructured data, similar to our work. One such paper by Zhu et al. [33] presents FeatureSmith, a tool for mining security literature to train machine learning classifiers for detecting Android malware. However, FeatureSmith is specific to malware detection and cannot be easily generalized.

TTPDrill [11] and ActionMiner [12], developed by Husari et al., and the tool by Ayoade et al. [2] are the closest to our approach, as they extract threat actions from CTRs and link them to ATT&CK tactics and techniques. However, these works lack reproducibility due to the non-availability of their datasets and tools. Our approach, in contrast, is designed for easy reproducibility, using open data and making our final tool publicly available as open source.

On a conceptual level, TTPDrill [11] does not clearly separate tactics and techniques, while Ayoade et al. [2] do, but neither allows users to provide feedback to improve the tool. Unfetter Insight, available on GitHub, uses a different approach based on BabelFish software, which learns topics from a wiki-like corpus. We compared rcATT and Unfetter Insight using identical training sets, and the results show that rcATT generally outperforms Unfetter Insight in most metrics.

### Conclusion

With the increasing importance of CTI sharing, security teams face the challenge of handling large volumes of unstructured data. Our work aims to simplify this task by enabling the automated extraction of TTPs from textual cyber security reports. By leveraging the MITRE ATT&CK framework and proposing post-processing techniques, we show that relationships among tactics and techniques can refine classification and reduce false positives.

We developed rcATT, an interactive tool that supports security experts in extracting ATT&CK tactics and techniques from CTRs. The tool allows users to adjust or fix classification results, providing feedback to the internal classifier and improving its performance over time. Our comparisons with state-of-the-art approaches validate the competitiveness of rcATT, and its integration into operational CERTs further confirms its value in automated incident handling and response.

### References

[References listed here]

This optimized version of the text is more structured, coherent, and professional, making it easier to read and understand.