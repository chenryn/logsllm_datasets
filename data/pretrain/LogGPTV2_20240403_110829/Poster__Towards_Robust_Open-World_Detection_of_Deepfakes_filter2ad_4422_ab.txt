# Deepfake Detection Tool: Technical and User Study Overview

## 1. Introduction
This document provides an overview of the ongoing project aimed at developing a tool for detecting deepfakes. The project encompasses two main components: the detection models and the user interface, which are integrated to create a web-based tool. This tool is designed to be easily integrated into the workflow of journalists and to provide an intuitive and usable interface.

## 2. Detection Models

### 2.1 Model Comparison
**Figure 1: Comparison of ClassNSeg [16] and FacenetLSTM Models**
- **Models Compared:** ClassNSeg [16] and FacenetLSTM
- **Datasets:** Matching, mismatched, and combined datasets
- **Results:** Both classifiers perform poorly when trained on one dataset and tested on another. However, their performance improves significantly when trained on combined datasets.

**Figure 2: Performance Comparison Between Mismatched Combinations**
- **Models Compared:** ResNeXTSpoof and Convolutional LSTM
- **Dataset:** ASVSpoof2019 Logical Access dataset
- **Evaluation Metrics:** Receiver Operating Characteristic (ROC) curves and Equal Error Rates (EERs)
- **Results:** 
  - EER for ResNeXTSpoof: 5.4%
  - EER for Convolutional LSTM: 6.4%
  - ResNeXTSpoof shows better performance.

### 2.2 Fake Audio Detection
- **Dataset:** Evaluation partition of the ASVSpoof2019 Logical Access dataset
- **Models Evaluated:** ResNeXTSpoof and Convolutional LSTM
- **Performance:**
  - ResNeXTSpoof: EER = 5.4%
  - Convolutional LSTM: EER = 6.4%

## 3. User Study

### 3.1 Study Design
- **Objective:** Develop a tool that can be easily integrated into the workflow of journalists.
- **Participants:** Journalists from reputable local and national organizations.
- **Methodology:**
  - Semi-structured interviews conducted in both workplace and public settings.
  - Participants given the option to remain anonymous.
  - Interactive prototype shown to participants for feedback.

### 3.2 Results
- **Participants:** Four journalists (two from a local media organization in Rochester, NY, and two from a US national organization).
- **Key Findings:**
  - Varying levels of knowledge about deepfakes, with national news journalists being more aware.
  - Confusion between deepfakes and "cheap fakes" (e.g., the Nancy Pelosi video [6]).
  - Inadequate security training in some news organizations, but proactive learning by staff in others.
  - Mixed opinions on public access to the tool, but consensus that the public should have access to analysis results.
  - Emphasis on the importance of accuracy over processing speed.
  - Need for detailed analyses, including reasons for the tool's determinations.

### 3.3 Interface Design
- **Goals:** Intuitive, interactive, and un-disruptive.
- **Features:**
  - YouTube video URL input for video selection and download.
  - Color-coded timeline showing probabilities of the video being fake at each interval.
  - Multiple rows for results from different prediction models and methods, aiding informed judgment.

## 4. Conclusion and Future Work

### 4.1 Conclusion
- **Project Status:** Ongoing development of a deepfake detection tool.
- **Components:** Detection models and user interface.
- **Initial Results:** Success in using multiple detection models, aligned with user study requirements.

### 4.2 Future Work
- **Technical Development:**
  - Deploy an initial version of the tool.
  - Develop multiple accurate and robust detection models.
  - Ensure the tool can detect new types of fake videos.
- **User Side:**
  - Supplement semi-structured interviews with A/B testing of two working prototypes.
  - Perform live beta testing with a larger number of journalists.

## 5. Acknowledgments
This project was funded in part by the Ethics and Governance of AI Initiative.

## 6. References
[1] Darius Afchar, Vincent Nozick, Junichi Yamagishi, and Isao Echizen. 2018. Mesonet: A Compact Facial Video Forgery Detection Network. In WIFS.
[2] Shruti Agarwal, Hany Farid, Yuming Gu, Mingming He, Koki Nagano, and Hao Li. 2019. Protecting World Leaders Against Deep Fakes. In CVPR Workshops.
[3] Q. Cao, L. Shen, W. Xie, O. M. Parkhi, and A. Zisserman. 2018. VGGFace2: A Dataset for Recognizing Faces Across Pose and Age. In ICAFGR.
[4] Umur Aybars Ciftci and Ilke Demir. 2019. FakeCatcher: Detection of Synthetic Portrait Videos using Biological Signals. arXiv preprint arXiv:1901.02212 (2019).
[5] Davide Cozzolino, Justus Thies, Andreas Rössler, Christian Riess, Matthias Nießner, and Luisa Verdoliva. 2018. Forensictransfer: Weakly-supervised domain adaptation for forgery detection. arXiv preprint arXiv:1812.02510 (2018).
[6] Beatrice Dupuy. 2019. NOT REAL NEWS: Altered video makes Pelosi seem to slur words. https://apnews.com/4841d0ebcc704524a38b1c8e213764d0
[7] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Advances in Neural Information Processing Systems (NeurIPS). 2672–2680.
[8] David Güera and Edward J Delp. 2018. Deepfake Video Detection Using Recurrent Neural Networks. In AVSS.
[9] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep Residual Learning for Image Recognition. CoRR abs/1512.03385 (2015). arXiv:1512.03385 http://arxiv.org/abs/1512.03385
[10] Tomi Kinnunen, Md Sahidullah, Héctor Delgado, Massimiliano Todisco, Nicholas Evans, Junichi Yamagishi, and Kong Aik Lee. 2017. The ASVspoof 2017 challenge: Assessing the limits of replay spoofing attack detection. (2017).
[11] Iryna Korshunova, Wenzhe Shi, Joni Dambre, and Lucas Theis. 2017. Fast Face-swap using Convolutional Neural Networks. In ICCV.
[12] Marek Kowalski. [n. d.]. faceswap. https://github.com/MarekKowalski/FaceSwap.
[13] Yuezun Li, Ming-Ching Chang, Hany Farid, and Siwei Lyu. 2018. In ictu oculi: Exposing AI Generated Fake Face Videos by Detecting Eye Blinking. arXiv preprint arXiv:1806.02877 (2018).
[14] Jaime Lorenzo-Trueba, Junichi Yamagishi, Tomoki Toda, Daisuke Saito, Fernando Villavicencio, Tomi Kinnunen, and Zhenhua Ling. 2018. The voice conversion challenge 2018: Promoting development of parallel and nonparallel methods. arXiv preprint arXiv:1804.04262 (2018).
[15] Shao-An Lu. [n. d.]. faceswap-GAN. https://github.com/shaoanlu/faceswap-GAN. Commit: c563edc128e79c3b593da63825f0208acf7ea4d9.
[16] Huy H. Nguyen, Fuming Fang, Junichi Yamagishi, and Isao Echizen. 2019. Multi-task Learning For Detecting and Segmenting Manipulated Facial Images and Videos. arXiv:cs.CV/1906.06876
[17] Huy H Nguyen, Junichi Yamagishi, and Isao Echizen. 2018. Capsule-Forensics: Using Capsule Networks to Detect Forged Images and Videos. arXiv preprint arXiv:1810.11215 (2018).
[18] Andreas Rössler, Davide Cozzolino, Luisa Verdoliva, Christian Riess, Justus Thies, and Matthias Nießner. 2019. FaceForensics++: Learning to Detect Manipulated Facial Images. arXiv preprint arXiv:1901.08971 (2019).
[19] Florian Schroff, Dmitry Kalenichenko, and James Philbin. 2015. Facenet: A Unified Embedding for Face Recognition and Clustering. In CVPR.
[20] Karen Simonyan and Andrew Zisserman. 2014. Very Deep Convolutional Networks for Large-scale Image Recognition. arXiv preprint arXiv:1409.1556 (2014).
[21] Justus Thies, Michael Zollhofer, Marc Stamminger, Christian Theobalt, and Matthias Nießner. 2016. Face2face: Real-time Face Capture and Reenactment of RGB Videos. In CVPR.
[22] Massimiliano Todisco, Xin Wang, Ville Vestman, Md Sahidullah, Hector Delgado, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Tomi Kinnunen, and Kong Aik Lee. 2019. ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection. arXiv preprint arXiv:1904.05441 (2019).

---

This optimized version of the text is structured to be clear, coherent, and professional, with a logical flow and improved readability.