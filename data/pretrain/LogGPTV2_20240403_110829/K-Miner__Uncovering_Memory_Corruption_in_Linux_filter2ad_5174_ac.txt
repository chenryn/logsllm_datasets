➂➃➀➁memory allocationsite trackingKernel Memory Context         Pre-Analysisdangling pointer checkeruse-after-free checkerdouble-free checkerPer-Syscall Value-Flow           Analysisinitcall contextsyscall context...path & context checkercallgraph validationvalue-flow validationcross-analysis reusekernel code partitioningparallelized executionsparse analysisAnalysis SanitizerAnalysis Optimizationsvmlinuxbitcodeﬁle (IR)Reporting EnginePost-processingBug OverviewOutput FormattingFigure 4: Example of a Dangling Pointer vulnerability in a (simpliﬁed) system call deﬁnition.
with the global kernel context. We do this by determining
the global variables of a system call that contain missing
references and intersecting these with the list of variables of
the global kernel context populated earlier. While possibly
increasing the context information our precision improvents
prevent an infeasible blow-up in this last step.
C. Minimizing False Positives
False positives are a common problem in static analysis and
frequently occur when over-approximating program behavior:
for instance, an analysis may assume an alias relationship
between pointers that do not co-exist at run time, if the control
ﬂow is not taken into account. In the following, we explain how
we designed our analysis to be precise and reduce the number
of false positives, using dangling pointers as an example. We
also provide details on how K-Miner sanitizes the resulting
bug reports to further limit the number of false positives.
Precise Data-Flow Analysis: Figure 4 a) shows the code
of a pseudo system call with a dangling pointer bug. In step 1 ,
the address of the local variable in do_foo is copied into the
parameter p of add_x and subsequently stored in the global
pointer global_p in step 2 . In step 3 , we can see that
remove_x will only be called conditionally. Hence, there is a
path for which global_p still points to the address of a local
variable after execution of do_foo has returned. Looking at
the PAG in Figure 4b) reveals that local_o and global_o
represent the abstract memory objects behind these possible
pointer values. The (simpliﬁed) VFG in Figure 4c) shows the
corresponding value ﬂows. Our algorithm to ﬁnd these kinds
of bugs consists of two phases: ﬁrst, we traverse the VFG in
forward order starting from local nodes. A reference to a local
node leaves its valid scope, if the number of function exits is
greater than the number of function entries after traversing the
entire path. For the node local_x we can see, that there is
one entry to add_x, an exit from add_x, and an exit from
do_foo at the end of the path. Consequently, there is a path
for which local_x leaves its valid scope, i.e., local_x →
1 → 2 → 3 → 5 → 6 .
In the second phase we traverse the VFG in backward
direction to ﬁnd (global or local) references to this node,
since any such reference represents a dangling pointer. In this
case the second phase yields the path 6 → 5 → 3 →
2 → global_p. By querying the PAG dynamically during
backward traversal we avoid visiting edges that do not belong
to the currently tracked memory location such as 5 → 4 .
This allows us to minimize inaccuracies resulting from over-
approximation. We store the respective path information along
with the list of nodes and contexts they were visited in as
memory-corruption candidate for sanitizing and future report-
ing.
Sanitizing Potential Reports: Upon completion of the
data-ﬂow analysis, we cross-check the resulting candidates for
impossible conditions or restrictions which would prevent a
path from being taken during run-time execution. Examples
for such conditions include impossible call graphs (e.g., call
to function g preceding return from function f), or invalid
combinations of context and path information. Additionally,
we eliminate multiple reports that result in the same nodes for
different contexts by combining them into a single report.
D. Efﬁciently Combining Multiple Analyses
To enable the efﬁcient execution of multiple data-ﬂow anal-
yses, our framework makes heavy use of various optimizations
and highly efﬁcient analysis techniques as we describe below.
Using Sparse Analysis: An important data structure in
our data-ﬂow analysis is the value-ﬂow graph, which is a di-
7
a) Pseudo Systemcallb) Pointer Assignment Graph (PAG)global_olocal_xpglobal_plocal_o123456local_x4256do_fooremove_xadd_x1global_p3c) Value-Flow Graph (VFG)void sys_foo() {}1 do_foo();2 return;void do_foo() {}3 int local_x = 1;4 add_x(&local_x);5 if (cond())6   remove_x();7 return;void add_x(int *p) {}8 global_p = p;void remove_x() {}9 global_p = NULL;nullnullMagnitude of Analysis
Report Results
Version MLOC
Bitcode
Avg. Run Time
#Functions
#Variables
#Pointers
DP
UAF
DF
3.19
4.2
4.6
4.10
4.12
15.5
16.3
17.1
22.1
24.1
280M
298M
298M
353M
364M
796.69s
1435.62s
1502.54s
1312.41s
2164.96s
99K
104K
105K
121K
126K
433K
466K
468K
535K
558K
>5M
>6M
>6M
>7M
>7.4M
7 (40)
3 (131)
11 (46)
2 (106)
3 (50)
1 (30)
1 (24)
2 (104)
2 (105)
0 (27)
1 (13)
0 (19)
0 (31)
0 (22)
1 (24)
Table I: Overview of the speciﬁcations, resource requirements, and results for the different kernel versions and data-ﬂow passes
we used in our evaluation of K-Miner.
rected inter-procedural graph tracking any operations related to
pointer variables. The VFG captures the def-use chains of the
pointers inside the kernel code to build a sparse representation
for tracking these accesses. The graph is created in four steps:
ﬁrst, a pointer analysis determines the points-to information of
each variable. Second, the indirect deﬁnitions and uses of the
address-taken variables are determined for certain instructions
(e.g. store, load, callsite). These instructions are then annotated
with a set of variables that will be either deﬁned or used by
this instruction. Third, the functions are transformed into Static
Single Assignment form using a standard SSA conversion
algorithm [17]. Finally, the VFG is created by connecting the
def-use for each SSA variable and made partially context-
sensitive by labeling the edges of the callsites. Using this
sparse VFG representation in a partially context-sensitive way
enables us to conduct precise analysis while reducing the
amount of code.
Revisiting Functions: Using different analysis passes,
functions are potentially visited multiple times with different
values as an input. However, one function might call dozens of
other functions and forwarding all the resulting nodes multiple
times in the same way would be very inefﬁcient. Our analysis
reduces the amount of nodes that have to be forwarded by
processing a function only once for all of its possible contexts
and storing the intermediate results. If a function entry node
is requested by an analysis with a given context, the analysis
checks if this node was already visited and re-uses the pre-
computed results.
Parallelizing Execution: Because certain analysis steps
can actually run independently from each other, we imple-
mented another optimization by parallelizing the forwarding
and backwarding processes using OpenMP [4]. OpenMP pro-
vides additional compiler directives that allow the deﬁnition of
parallel regions in the code. In this way, we process some of
the heavy container objects used during the analysis in parallel.
V. EVALUATION
In this section, we evaluate and test our static analysis
framework for real-world operating system kernels. We run
our memory-corruption checkers against ﬁve different ver-
sions of the Linux kernel, using the default conﬁguration
(defconfig). Our test system running K-Miner features an
Intel Xeon E5-4650 with 8 cores clocked at 2.4GHz and 32G
8
of RAM. Table I shows an overview of the analyzed Linux
kernel speciﬁcations and results: on average, our framework
needs around 25 minutes to check a single system call (cf.,
Avg. Time in Table I). This means that a check of the entire
system call interface on this server with all three analyses takes
between 70 and 200 hours for a single kernel version. 1 In
our experiments, K-Miner found 29 possible vulnerabilities,
generating 539 alerts in total, most of which were classiﬁed as
false positives (total alerts are given in parenthesis in Table I). 2
Next, we will evaluate the coverage and impact of those reports
and afterwards also discuss the performance of our framework
in more detail.
A. Security
Since K-Miner aims to uncover memory-corruption vul-
nerabilities in the context of system calls, we investigate
its security guarantees by inspecting the coverage of the
underlying graph structures. To demonstrate practicality, we
also present some of the publicly known vulnerabilities we
were able to ﬁnd statically using our framework.
Coverage: Our goal is to uncover all possible sources
of memory corruption that are accessible via the system call
interface that the kernel exposes to user processes. Hence, we
have to ensure that the analysis passes for a certain class of
vulnerabilities have access to all relevant information required
to safely approximate run-time behavior of the kernel. At the
time of writing, our framework contains passes for DP, DF,
and UAF, hence, other sources of memory corruption are not
covered in this evaluation. However, K-Miner is designed to
be extensible and we are working on implementing further
analysis passes to cover all remaining vulnerability classes.
The most important factors for the coverage of our three
analysis passes are their underlying analysis structures, i.e.,
PAG, VFG, and context
information. Because the inter-
procedural value-ﬂow graph and the context information are
derived from the pointer-analysis graph, their accuracy directly
depends on the construction of the PAG. Our pointer analysis
makes two assumptions: 1) partitioning the kernel code along
its system call graph is sound, and 2) deriving kernel context
1Largely depending on the respective kernel version as seen in the average
2Additionally, we are still investigating 158 memory-corruption alerts for
time per system call in Table I.
the most recent version of Linux.
Figure 5: Wall-clock time per analysis phase for system calls requiring more than 30 Minutes within K-Miner.
information from init calls is complete. We would like to note
that verifying both assumptions requires a formal proof, which
is beyond the scope of this paper. However, we sketch why
these assumptions are reasonable in the following.
The ﬁrst assumption is sensible, because system calls
are triggered by individual processes to provide services in
a synchronous manner, meaning that the calling process is
suspended until execution of the system call ﬁnishes. While
interrupts and inter-process communication may enable other
processes to query the kernel asynchronously, this is orthog-
onal to the partitioning of kernel code, because these operate
under a different context. In particular, our framework allows
analyses to take multiple memory contexts into account, e.g.,
to uncover synchronization errors. Individual analysis passes
then have to ensure that the associated contexts are handled
accordingly.
Our second assumption is derived from the design of the
analyzed kernel code. The init call infrastructure for Linux is
quite elaborate, using a hierarchy of different levels that may
also specify dependencies on other init calls. Additionally, init
calls are used in many different scenarios, e.g., to populate
management structures for virtual memory and processes dur-
ing early boot, or to instantiate drivers and modules at run time.
By including all init call levels following their hierarchical
ordering in the pre-analysis phase, we ensure that the relevant
context information is recorded and initialized accordingly.
Real-world Impact: We cross-checked the reported mem-
ory corruptions against publicly available bug reports and
found two interesting matches. In particular, our dangling
pointer analysis automatically found a bug in Linux kernel
version 3.19, which was previously discovered through manual
inspection and classiﬁed as a security-relevant vulnerability in
Linux in 2014 (i.e., CVE-2014-3153). In fact, this vulnerability
gained some popularity due to being used as a tool to allow
users privilegede access (aka ”root”) on their locked-down
Android devices, such as the Samsung S5 [30]. The bug was
later discovered to be exploited by the HackingTeam company
to spy on freedom ﬁghters and dissidents through a malicious
kernel extension [62].
including Android devices such as Google’s PIXEL [26]. Both
vulnerabilities were classiﬁed as critical issues with a high
severity and could have been easily found through K-Miner’s
automated analysis. Moreover, we reported two of our use-
after-return alerts to the kernel developers.
B. Performance
We now analyze the performance, in particular, the run
time, memory consumption, and number of false positives.
Analysis Run Time: As already mentioned, the average
analysis time per system call is around 25 minutes. In Fig-
ure 5 we give an overview of those system calls for which
our analyses took longer than 30 minutes. Most system call
analysis are dominated by the context handling. However there
are some exceptions, notably sys_execve, sys_madvise,
and sys_keyctl. The context handling is time consuming,
because it represents the ﬁrst phase of any subsequent data-
ﬂow analysis pass. This means, that it conducts multiple inter-
procedural pointer analysis, cross-references the global kernel
context with the syscall context, and populates the underlying
graph data structures for the current system call. This also
involves importing and copying information stored on disk,
which is slower than accessing RAM. In theory, it should be
possible to pre-compute and export the results of the context
handling phase for each system call to disk as well. Any data-
ﬂow analysis pass could then just re-import the respective ﬁle
for the current system call, potentially saving some of this
overhead (especially in combination with fast SSD hardware).
However, we did not implement this optimization feature in
the current version of K-Miner.
The UAF checker is notably quicker than the remaining
passes, which is due to its reuse of underlying analysis
structures from the ﬁrst pass. In contrast to the use-after-free
pass, the double-free analysis has to reconstruct the value-ﬂow
graph, which accounts for the majority of its run time. Taken
separately, the individual analysis phases require between 5
and 35 minutes run time, which is expected for graph-based
analysis, given the magnitude of the input.
Further, our double-free analysis found a driver bug (i.e.,
CVE-2015-8962) in a disk protocol driver in version 3.19. The
vulnerability allows a local user to escalate privileges and cor-