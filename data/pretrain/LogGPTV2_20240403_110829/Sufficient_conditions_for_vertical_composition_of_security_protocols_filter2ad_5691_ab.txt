rated by dots (“.”). These facts model the state of honest
agents, the knowledge of the intruder, communication chan-
nels, and goal-relevant information. Transitions are speciﬁed
as rewriting rules over sets of facts. We give here one exam-
ple of an ASLan transition rule, pointing to the references
for more details. Consider the following message exchange
(that is part of the protocol P1 that we will consider in Fig-
ure 1 below)
A → B : {{[p, A, B, payload(A, B)]4}privk(pk(A))}pubk(pk(B))
in which A ﬁrst signs4 with its private key a payload, along
with information on sender and receiver that is needed to
achieve a secure channel. The tag p signals that this concate-
nation contains the payload transmission. A then encrypts
the message with B’s public key.
This message exchange is formalized by two ASLan rules,
one for the sender and one for the receiver. One way to
model the sender’s transition is as follows:
stateA,P1 (A, step1 , SID, B) ⇒
stateA,P1 (A, step2 , SID, B).
iknows({{[p, A, B, payload(A, B)]4}privk(pk(A))}pubk(pk(B)))
where stateA,P1 (. . .) formalizes the local state of an honest
agent in role A of protocol P1. Here we have chosen to
model this state as consisting of the agent’s name A, its step
number in the protocol execution, a session identiﬁer SID,
and the name of the intended communication partner B. A,
B and SID are here variables that allow for matching against
arbitrary concrete facts. In contrast, step1 is a constant, i.e.,
this rule can only be applied to an agent that is currently
in this stage of the protocol execution. On the right-hand
side of the rule, there is the updated state of the honest
agent and a message that the agent sends out. Since we
assume that the intruder can read all messages that are sent
on insecure channels, we immediately add this message to
the intruder knowledge, as formalized by the fact iknows(·).
The local state of an honest agent does not necessarily carry
all the knowledge of the agent (like payload(A, B)) but it
is suﬃcient that it contains all those variables on which the
terms depend that the agent is supposed to send and receive.
It is standard to deﬁne what the intruder can deduce
(e.g., encryption and decryption with known keys) by rules
on iknows(·) facts to obtain a Dolev-Yao-style model. We
usually also allow that the intruder may completely control
4For simplicity, we model signing by asymmetric encryption
with a private key. If one wishes to distinguish signing and
encryption, one may of course use instead a dedicated oper-
ator like sign(privk(pk(A)), M ) and all results hold similarly.
437several “compromised” agents (including knowing their long-
term secrets). We use the predicate dishonest(·) that holds
true for every agent under the intruder’s control (from the
initial state on), and the predicate honest(·) that holds for
all other agents.
We describe the goals of a protocol by attack states, i.e.,
states that violate the goals, which are in turn described by
attack rules: a state at which the attack rule can ﬁre is thus
an attack state. For instance, we can formulate a secrecy
goal as follows. We add the fact secret(M,{A, B}) to the
right-hand side of an honest agent rule, whenever a message
M is supposed to be a secret between A and B, and then give
the following attack rule, which expresses that, whenever the
fact secret(M,{A, B}) holds for two honest agents A and B,
and the intruder has learned the message, then we can derive
the fact attack:
secret(M, {A, B}).iknows(M ).honest(A).honest(B) ⇒ attack (1)
Deﬁnition 1. (Secure protocol) We say that a protocol is
secure when no attack state is reachable.
Note that our focus, like in most security papers, is on
safety properties and they can always be expressed as reach-
ability problems. There are a few papers that also consider
liveness (e.g., [4]), but this generally also requires fairness
assumptions on the channels as otherwise an intruder could
simply block communication indeﬁnitely. We leave for fu-
ture work the investigation if such resilient channels can be
combined with our approach.
3. CHANNELS AND COMPOSITION
The most common type of security protocol composition
is running two protocols in parallel over the same network,
which is easy to deﬁne for many protocol formalisms. For
instance, in a strand notation, we simply consider the union
of the strands of the two protocols. Similarly, in ASLan
we will simply consider the union of the rules of the two
protocols (as well as the unions of initial states and goal
rules).
There is, however, a subtlety about this in ASLan due
to its expressiveness. Recall that in the previous example
of a transition rule in ASLan we have noted explicitly the
protocol in the name of the state fact.
If we did instead
use the same fact stateA in several protocols and build the
union, then we might obtain executions that do not make
much sense. So, in general, we assume that the state facts
of diﬀerent protocols are disjoint to avoid this kind of col-
lisions. For other facts it can, however, make sense to use
the same predicate in several protocols. Obviously, iknows(·)
and attack shall be shared by protocols, but one may also
formalize a database of an agent A as the set of messages
msg for which a fact db(A, msg) holds. This database can
then be “shared” across diﬀerent protocols that A partic-
ipates in. As this makes composition much more diﬃcult,
we will exclude this by assuming the following notion of pro-
tocol independence:
Deﬁnition 2. (Execution independence of two protocols)
We say that two protocols P1 and P2 are execution indepen-
dent if they are formulated over disjoint sets of facts, except
for iknows(·) and attack.
Execution independence is neither necessary nor suﬃcient
for parallel compositionality (or other composition types),
but it only simpliﬁes the problem: we reduce ourselves to
protocols that can interfere with each other only in terms of
exchanged messages.
Three further remarks are in order. First, note that execu-
tion independence does not exclude protocols where agents
for instance maintain protocol-speciﬁc databases over sev-
eral protocol sessions, it only excludes that a database can
be shared over several protocols. Second, note that for secu-
rity goals we also have protocol-speciﬁc facts, e.g., secretP1 ,
but that is not a restriction and even helps to identify in
which protocol the goals were violated. Finally, note that
the deﬁnition of execution independence is trivial for strands
and the applied π calculus: they cannot express dependent
protocols in this sense.
Deﬁnition 3. (Parallel Composition P1 (cid:107) P2 and Com-
posability) For two execution independent protocols P1 and
P2 speciﬁed in ASLan, we deﬁne their parallel composition
as the union of the initial states, transition rules, and goal
rules, respectively. We denote the resulting ASLan speciﬁ-
cation with P1 (cid:107) P2.
We say that P1 and P2 are composable in parallel if the
if P1 and P2 are secure in isolation, then
following holds:
also P1 (cid:107) P2 is secure.
A similar deﬁnition can be given for the composition of
Alice-and-Bob-style protocols modulo their translation to
ASLan.
The main idea to ensure parallel compositionality is that
messages of the composed protocols should have suﬃciently
diﬀerent formats so that no message part of one protocol can
be mistaken for one of another. For simple Alice-and-Bob-
style protocols, this is already suﬃcient, but in general more
complex situations may occur. For instance, if a web-service
maintains a database of transactions that it was involved
in, and several of the composed protocols involve reading
or writing in this database, then this can result in a “side-
channel” that may break compositionality.
3.1 Channels as Assumptions, Channels as
Goals
Channels may be used both as protocol assumptions (i.e.,
when a protocol relies on channels with particular properties
for the transmission of some of its messages) and as proto-
col goals (i.e., a protocol’s objective is the establishment of
a particular kind of channel). Considering channels as as-
sumptions allows us to enhance the standard insecure com-
munication medium with security guarantees for message
transmission. We can express this, e.g., in an Alice-and-
Bob-style notation, where a secure end-point of a channel is
marked by a bullet, as follows:
• A → B : M represents an insecure channel from A
to B, meaning that the channel is under the complete
control of the intruder.
• A•→ B : M represents an authentic channel from A
to B, meaning that B can rely on the fact that A has
sent the message M and A meant to send it to B.
• A→• B : M represents a conﬁdential (or secret) chan-
nel from A to B, meaning that A can rely on the fact
that only B can receive the message M .
• A•→• B : M represents a secure channel, i.e., a chan-
nel that is both authentic and conﬁdential.
438P1 :
A
A
P P2
1
:
A
A
→ B :
•→• B :
{{[p, A, B, payload(A, B)]4}privk(pk(A))}pubk(pk(B))
payload(A, B)
P2 :
D
C
C
→ C :
•→• D :
•→• D : M
[N , C , D]3
[h(N ), M ]2
→ B :
•→• B : mA,B
{{[p, A, B, mA,B ]4}privk(pk(A))}pubk(pk(B))
P2[P1] :
D
C
C
→ C :
→ D :
•→• D : M
[N , C , D]3
{{[p, C , D, [h(N ), M ]2 ]4}privk(pk(C ))}pubk(pk(D))
Figure 1: Abstract channel protocol P1 (top left) and application protocol P2 (top right), their static vertical
composition P P2
(bottom left) and their vertical composition P2[P1] (bottom right).
1
These are some examples of channel types, but note that,
in fact, the details of the supported channel types do not
matter for the results of this paper.
In [27], we also give a deﬁnition of channels as goals, e.g.,
to express that it is the goal of a protocol to authentically
transmit a certain message. This gives rise to a vertical com-
position question: given a channel protocol that provides a
certain kind of channel as a goal and an application protocol
that assumes this kind of channel, is it safe to compose the
two? While [27] tackles the “logical aspect” of this question,
we look in this paper at the “static aspect”, i.e., the potential
problems that arise from inserting the messages of one pro-
tocol into another protocol. In particular, for compositional
reasoning we want to be able to verify channel protocol and
application protocol separately. This means, especially, that
we want to verify the channel protocol for an abstract payload
that is independent of the application that uses the channel
(and this requires more than mere protocol disjointness).
The easiest and most intuitive way to deﬁne vertical com-
position is at the level of Alice-and-Bob notation, and we
use here the formal language AnB [26, 27], which can be
automatically translated to ASLan so that we can connect
to and exploit our ASLan formalization of protocols. It is
possible to give corresponding deﬁnitions on the ASLan level
as well, but due to the handling of local state facts it would
be technically quite involved and distracting from our main
point.
An AnB speciﬁcation of a protocol is, in a nutshell, a
description of a protocol as an exchange of messages; the
goal is speciﬁed as a result below a horizontal line using the
channel notation about some message terms of the protocol.
Deﬁnition 4. (Abstract Channel Protocol) Let κ(A, B)
range over a set of deﬁned channel types (e.g., A•→ B : M )
and payload(A, B) be a mapping from pairs of agents to (ab-
stract) payloads. An abstract channel protocol for κ(A, B)
is an AnB speciﬁcation that has κ(A, B) : payload(A, B)
as a goal. Moreover, we require that every agent A ini-
tially knows payload(A, B) for every communication partner
B (recall the notion of knowledge given in Section 2).
An example of an abstract channel protocol is P1 in Fig-
ure 1. The message exchange was already explained in Sec-
tion 2, and we declare the goal to be the transmission of the
abstract payload over a secure channel.
Deﬁnition 5. (Application Protocol) An application pro-
tocol for channel κ(A, B) is an AnB speciﬁcation that con-
tains as part of its message exchange one step κ(A, B) : t
with some message term t.
An example of an application protocol is P2 in Figure 1,
in which D ﬁrst sends to C a nonce N , together with both
agent names, as a challenge on an insecure channel, and
then C sends back to D the hashed nonce h(N ) paired with
a message M on a secure channel; the goal of this protocol is
the secure transmission of the message M between the two
agents.
3.2 Vertical Protocol Composition
Deﬁnition 6. (Vertical Composition P2[P1]) Let P1 be an
abstract channel protocol for κ(A, B) and P2 an application
protocol for κ(C, D).5 The vertical composition P2[P1] is
deﬁned by replacing in P2 the step κ(C, D) : t with the
entire protocol P1 under the replacement [A (cid:55)→ C, B (cid:55)→
D, payload(A, B) (cid:55)→ t].
An example is given in Figure 1, where payload(A, B) (cid:55)→
[h(N ), M ]2.
As already mentioned, we separate the vertical composi-
tion question into a logical aspect (that is already handled
in [27]) and a static aspect. For this, we need two further
deﬁnitions related to this composition. We now deﬁne the
notion of static vertical composition; it is based on a static
characterization of all the messages that can occur in any
run of the protocol P2 as a payload:
Deﬁnition 7. Let P2 be an application protocol and let
κ(C, D) : t be the step that uses an abstract channel κ(C, D)
to transmit message t. Consider the set of all ground terms
t0 that are instance of t in any run of P2 for a ﬁxed pair
(C, D) of agents. We deﬁne MC,D to be an arbitrary super-
set of this set of payload messages.
For the example protocol P2 from Figure 1, the payload
messages sent by an honest agent C has always the form
[h(N ), M ]2, where N is any message that C has received in
the ﬁrst step (supposedly from D) and M is a fresh nonce.
We can bound the values that are possible for M since they
are freshly created by C; let us say we have a distinguished
subset MC,D of all constants (for each pair C and D of
agents), from which these are taken. Then the set of all
5To avoid confusion, we assume here disjoint role names;
but when there is no risk of confusion, later on in the paper,
we will use the same role names in the two protocols.
439payload messages that can ever occur here are a subset of
MC,D = {[h(N ), M ]2 | N ∈ TΣ ∧ M ∈ MC,D}. Note that
it is diﬃcult to bound the set of values that variable N can
take:
it is (potentially) under the control of the intruder
and basically depends on what he knows at the time, so we
take the largest possible choice, namely, the set TΣ of all
ground terms. (In fact, for dishonest C we usually have to
set MC,D = TΣ as the intruder can send any term from his
knowledge; the case of dishonest C is however uncritical for
the rest.)
This example shows why we do not require MC,D to be
exactly the set of all payload messages that can occur, but
allow any superset. This over-approximation is typical of