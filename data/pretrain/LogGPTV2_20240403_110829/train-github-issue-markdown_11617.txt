## Environment info
  * `transformers` version: master (4.4.0dev0)
  * Platform: Google colab
  * Python version: 3.7
  * PyTorch version (GPU?): None
  * Tensorflow version (GPU?): 2.4
  * Using GPU in script?: Yes
  * Using distributed or parallel set-up in script?: No
### Who can help
@jplu
## Information
Model I am using (Bert, XLNet ...): None
The problem arises when using:
  * the official example scripts: (give details below)
  * my own modified scripts: (give details below)
The tasks I am working on is:
  * an official GLUE/SQUaD task: (give the name)
  * my own task or dataset: (give details below)
## To reproduce
Steps to reproduce the behavior:
This might be somewhat of a duplicate of #9629 but in a different use case
    dataset = tf.data.TextLineDataset("/content/train.txt")
    tokenizer = transformers.DistilBertTokenizerFast.from_pretrained("/content/Tokenizer", do_lower_case=False)
    def tokenize(sentence):
      sentence = sentence.numpy().decode('utf-8')
      a = tokenizer.encode_plus(sentence, padding="max_length", max_length=256, truncation=True, return_tensors="tf")
      return tf.constant(a.input_ids), tf.constant(a.attention_mask), tf.constant(a.input_ids)
    def get_tokenized(sentence):
      a = tf.py_function(tokenize, inp=[sentence], Tout=[tf.int32, tf.int32, tf.int32])
      return {"input_ids": a[0], "attention_mask": a[1]}, a[2]
    dataset = dataset.map(get_tokenized, num_parallel_calls=tf.data.AUTOTUNE)
    # dataset = dataset.apply(tf.data.experimental.assert_cardinality(8000))
    print(next(iter(dataset)))
Error
    UnknownError: RuntimeError: Already borrowed
    Traceback (most recent call last):
      File "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py", line 247, in __call__
        return func(device, token, args)
      File "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py", line 135, in __call__
        ret = self._func(*args)
      File "/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py", line 620, in wrapper
        return func(*args, **kwargs)
      File "", line 9, in tokenize
        a = tokenizer.encode_plus(sentence, padding="max_length", max_length=256, truncation=True, return_tensors="tf")
      File "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py", line 2438, in encode_plus
        **kwargs,
      File "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py", line 472, in _encode_plus
        **kwargs,
      File "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py", line 379, in _batch_encode_plus
        pad_to_multiple_of=pad_to_multiple_of,
      File "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py", line 330, in set_truncation_and_padding
        self._tokenizer.enable_truncation(max_length, stride=stride, strategy=truncation_strategy.value)
    RuntimeError: Already borrowed
    	 [[{{node EagerPyFunc}}]]
The important thing that I should probably mention here is that if I change my
code to load the same using the tokenizers library, the code executes without
any issues. I have also tried using the slow implementation and the error
still persists. Any help regarding this would be great!
## Expected behavior
Tokenization should happen on the fly without errors as it does with the
Tokenizer from the tokenizers library.