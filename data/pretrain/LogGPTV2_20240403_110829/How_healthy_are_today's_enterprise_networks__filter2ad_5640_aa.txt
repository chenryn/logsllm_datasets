title:How healthy are today's enterprise networks?
author:Saikat Guha and
Jaideep Chandrashekar and
Nina Taft and
Konstantina Papagiannaki
How Healthy are Today’s Enterprise Networks?
Saikat Guha
Cornell University
PI:EMAIL
ABSTRACT
In this paper we take a look at the health of a typical enterprise
network via a new metric based on the fraction of useful ﬂows gen-
erated by endhosts. Flows considered non-useful are those that ex-
plicitly fail or else do not elicit a response from the intended desti-
nation. Examining traces collected from a large number of mobile
hosts in an enterprise network, we ﬁnd that about 34% of the ﬂows
are not useful. Through our study that combines data analysis and
ongoing interactions with our IT department, we learn that these
non-useful ﬂows arise from several causes. Our mobile hosts fre-
quently change environments, by either moving in and out of the
corporate environment, or by switching the point and means of at-
tachment to the corporate network. We ﬁnd that many of the fail-
ures occur due to the hosts’ lack of environment awareness, which
results in attempts to discover services that are not present in all
environments. Other causes include misconﬁguration, unnecessary
broadcast trafﬁc, and excessive connection retries. Understanding
this ever present noise in endhost communication is important for
a variety of reasons including the fact that it complicates anomaly
detection design and wastes resources, the latter of which is par-
ticularly crucial for wireless and mobile environments. Finally, we
discuss possible means to design applications and services that can
signiﬁcantly improve the health of the network.
Categories and Subject Descriptors
C.2.3 [Computer Systems Organization]: Computer Communi-
cation Networks—Network Operations; C.4 [Computer Systems
Organization]: Performance of Systems
General Terms
Measurement, Performance
Keywords
Network Health, Enterprise, Mobility, Environment Awareness
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’08, October 20–22, 2008, Vouliagmeni, Greece.
Copyright 2008 ACM 978-1-60558-334-1/08/10 ...$5.00.
Jaideep Chandrashekar, Nina Taft,
Konstantina Papagiannaki
Intel Research
ﬁPI:EMAIL
1.
INTRODUCTION
Enterprise networks today are walled gardens that sometimes ri-
val the complexity of the larger Internet. Enterprises can, and gen-
erally do, impose policies on the employee’s host machines to pro-
vide protection against rogue entities and to control network traf-
ﬁc, for instance, stringent policies relating to software patching
and updating are enforced to keep hosts protected. Additionally,
in our own network, users are prohibited from installing a number
of blacklisted programs that are considered potentially detrimen-
tal to the network or a security risk. Other enterprises take more
draconian measures, locking down the hosts so that users cannot
install any new software after being conﬁgured. Given this level of
policing, one would expect the trafﬁc generated by user endhosts to
be well behaved and easily analyzable. As we clearly demonstrate
in this paper, this is far from the case.
This disconnect exists for a number of reasons, starting from to-
day’s applications being very complex and hard to diagnose, cou-
pled with a highly distributed infrastructure exacerbated by shrink-
ing budgets of IT departments whose general motto may well be
“if it ain’t broke, don’t ﬁx it”. The end-result is an ailing network
with poor diagnostic properties; small problems go unnoticed and
accumulate over time, sapping away network resources.
In this paper, we take an early look at trafﬁc traces collected
from a large number of enterprise endhosts, speciﬁcally with an
eye toward quantifying, and understanding, trafﬁc at the edge of
the enterprise network. One of the contributions of this paper is a
new metric which we take to capture the “health” of an enterprise
network from the perspective of the endhosts at the edge of the
enterprise. We deﬁne health as the fraction of observed ﬂows that
are useful. A ﬂow is deemed useful if it successfully contacts the
intended destination application; and non-useful if the connection
attempt times out, or the ﬂow is made to destination applications
that are not alive or are unreachable. Clearly, non-useful ﬂows are
symptomatic of misconﬁgurations, stale information, or some other
underlying malady.
Our deﬁnition of health is simplistic, nevertheless we found ex-
amining enterprise trafﬁc through this lens of useful (and non-useful)
ﬂows well suited to identifying suboptimal design in both applica-
tions and the architecture. A number of in-network mechanisms
ranging from NATs and ﬁrewalls, to intrusion detection systems [14]
and application dependency extraction [4] operate at the granular-
ity of ﬂows. Our deﬁnition of health captures, at least to the ﬁrst
order, the noise such mechanisms must contend with.
Identifying and quantifying this ever present noise at the edge of
the enterprise network is important for several reasons. The ﬁrst
stems from the difﬁculty of designing endhost based anomaly de-
tectors in the presence of unhealthy activity that may be benign.
Failed connections have been used as an indicator of anomalous
network behavior (e.g., scanning) [7]. An inherent assumption be-
hind such approaches is that most systems should be able to con-
tact their intended destination most of the time in well engineered
networks. We observed in our traces that a third of all outgoing
connections seem to fail. This high level of noise has the effect
of drowning out existing anomalies and other symptoms of poor
performance.
A secondary motivation for studying the health of the enterprise
edge is to understand the inherent inefﬁciencies. For instance, NATs
and ﬁrewalls may be consuming a third more resources than nec-
essary for keeping track of ﬂows. And in wireless environments,
which are gradually becoming ubiquitous both inside the enterprise
and as a means of connecting to the enterprise from outside, failed
ﬂows may be causing unnecessary channel contention [16] leading
to poor application layer performance, and increased costs under
metered pricing (e.g. on cellular networks).
Overall our contributions as are follows. First we analyze traf-
ﬁc traces collected from a large population of enterprise endhosts
and quantify their health. We uncover that the level of health hov-
ers between 60 to 70% on an ongoing basis. We study the trafﬁc
from various perspectives, including temporal, application based,
changes in environment, protocol behavior and failure types. We
ﬁnd that most failures can be attributed to a small set of chatty ap-
plications, and thus feel optimistic about improving the health of of
the enterprise network. Second, we quantify the problem of lack of
environment awareness that we ﬁnd to be a big contributor in our
analysis. Roughly 77% of observed failures occur within a minute
of the endhost switching between networks. Such behavior can
have grave consequences in terms of information leakage when en-
terprise laptops transition from inside to outside the corporate en-
vironment. Third, in our efforts to understand the causes behind
the high level of failures observed, we taxonomize our failures into
three groups: persistent connection retries, service discovery and
vulnerability testing. We believe that much of the service discovery
activities are potentially redundant and designing a more cohesive
network architecture provides opportunities to amortize the cost of
service discovery across multiple applications. Finally we suggest
some coping strategies and show that some of the waste can be
remedied in a straightforward fashion if awareness of the problem
were to be spread, while some requires more involved network ar-
chitecture improvements, and some simply requires acceptance as
part of normal enterprise trafﬁc.
2. METHODOLOGY
Traditional network trace collection efforts have been “network
centric”—traces are gathered at routers or other aggregation points.
Inferring the cause of failures from such traces is problematic for
two reasons: ﬁrst, addresses are fairly dynamic making tracking
users difﬁcult, and more importantly, second, today’s enterprise
network is very mobile as users move in and out of the network.
Observing in-network trafﬁc does not capture network transitions,
thus providing a very limited snapshot of endhosts’ behavior. Study-
ing health as it appears from the perspective of the endhost, requires
traces collected on the endhost itself.
During February of 2007, we collected data from over 350 vol-
unteering employees, spread across a number of sites. We collected
all packet headers and 150 bytes of the payload for all trafﬁc at the
endhost across any active network interface. Of this set, 95% are
mobile hosts and utilize different interfaces at different times; the
remaining are desktops. For the mobile hosts, the traces include
activity when the host was outside the enterprise—at coffee shops,
home, airports, etc.
Each trace ﬁle is annotated with coarse grained user location:
internal, VPN and external, as well as a unique per-user identi-
ﬁer. The trafﬁc was captured with WinPcap that was restarted upon
any change in environment, address or interface. Importantly, all
the hosts that participated in the study ran an up-to-date version of
Windows XP SP2. In total, the traces yielded 31M ﬂows.
Our analysis utilizes ﬂow level data. The collected packet traces
were post processed with BRO [14] which performed the ﬂow re-
assembly.
In addition to tagging ﬂows as being inbound or out-
bound from the endhost, BRO summarizes the “connection state”
of how the ﬂow terminated. Unless mentioned otherwise, we con-
sider both inbound and outbound ﬂows for our analysis. For all
the applications that we can explicitly mention in this paper, the
identiﬁcation was done by consulting a “list of known ports” that is
maintained by the IT department.
We classify individual ﬂows as being useful or non-useful. The
former class consists of ﬂows that have been able to elicit a re-
sponse from the destination. This includes TCP ﬂows that complete
the 3-way handshake and also UDP ﬂows that see packets in both
directions, regardless of the number of bytes exchanged or how the
ﬂow was (ﬁnally) terminated. Thus, we consider a TCP connection
as being useful even if it was closed by a RST (as long as the hand-
shake was ﬁrst completed). Successful ﬂows correspond to BRO
ﬂags other than S0, REJ, RSTOS0 (see [1] for details) while
failed ﬂows correspond to these three ﬂags.
Classifying ﬂows at the transport layer (versus at the application
layer) introduces artifacts: (i) ﬂows that succeed at the transport
layer but fail at the application layer (e.g. an incorrect login on
a webpage) are considered useful in our classiﬁcation; (ii) unidi-
rectional UDP ﬂows, for instance, network level broadcasts which
elicit responses from a different address (e.g. NetBios), are tagged
as failed. We manually identiﬁed broadcast trafﬁc and analyzed
the most egregious of applications for unidirectional ﬂows; unless
mentioned otherwise, we omit such ﬂows in our analysis since we
cannot determine if they succeeded. Correcting for ﬂows that fail at
the application layer is considerably harder since we lack applica-
tion level knowledge. Even if one could attempt doing this for well
known applications (http, smtp, etc), many enterprise applications
are proprietary and create considerable hurdles for doing so.
As to the question of to what extent our results can be generalized
to other enterprise networks, we shared our ﬁndings with the IT de-
partment and relied on their expertise in network design and oper-
ations. A large fraction of failures are endemic to software that, we
learned, is typical in many enterprises, such as the Windows OS,
the anti-virus software, and the software-patching service. Also,
given the size and complexity of today’s enterprise networks, it is
reasonable to expect them to be designed and conﬁgured following
well tested “templates” and best common practices; for instance, a
DMZ, a VPN, different internal and external DNS namespaces, a
(small number of) homogeneous software stacks, and so on. We
consequently believe that our results apply, at least in part, to other
typical large enterprises that share the same culture of allowing em-
ployees semi-autonomous control over their laptops.
3. NETWORK HEALTH
Computed over the entire trace the health of our enterprise net-
work from the endhost’s perspective, deﬁned earlier as the fraction
of successful ﬂows, is 66%, suggesting that there is much room
for improvement. In this section we analyze the factors on which
health depends including time of day, user location and activity,
and applications.
)
%
(
h
t
l
a
e
H
 100
 80
 60
 40
 20
 0
Health (hourly)
All Flows
02/03
02/10
02/17
02/24
Date
Application
Anti-Virus Update
Directory Service
Unknown (port 5499)
DNS
Windows RPC
Web
Other
Total
From Internal
From VPN
3191
2940
2451
1760
688
633
2029
13692
33
0
57
97
129
255
215
786
Table 1: Number of unique instances where an application