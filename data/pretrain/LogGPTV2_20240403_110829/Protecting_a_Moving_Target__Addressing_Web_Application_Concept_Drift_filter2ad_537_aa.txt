title:Protecting a Moving Target: Addressing Web Application Concept Drift
author:Federico Maggi and
William K. Robertson and
Christopher Kr&quot;ugel and
Giovanni Vigna
Protecting a Moving Target:
Addressing Web Application Concept Drift
Federico Maggi, William Robertson, Christopher Kruegel, and Giovanni Vigna
Computer Security Group
{maggi,wkr,chris,vigna}@cs.ucsb.edu
UC Santa Barbara
Abstract. Because of the ad hoc nature of web applications, intrusion
detection systems that leverage machine learning techniques are particu-
larly well-suited for protecting websites. The reason is that these systems
are able to characterize the applications’ normal behavior in an auto-
mated fashion. However, anomaly-based detectors for web applications
suﬀer from false positives that are generated whenever the applications
being protected change. These false positives need to be analyzed by
the security oﬃcer who then has to interact with the web application
developers to conﬁrm that the reported alerts were indeed erroneous
detections.
In this paper, we propose a novel technique for the automatic detection
of changes in web applications, which allows for the selective retraining
of the aﬀected anomaly detection models. We demonstrate that, by cor-
rectly identifying legitimate changes in web applications, we can reduce
false positives and allow for the automated retraining of the anomaly
models.
We have evaluated our approach by analyzing a number of real-world
applications. Our analysis shows that web applications indeed change
substantially over time, and that our technique is able to eﬀectively de-
tect changes and automatically adapt the anomaly detection models to
the new structure of the changed web applications.
Keywords: Anomaly Detection, Web Application Security, Concept
Drift, Machine Learning.
1 Introduction
According to a recent study by Symantec [1], web vulnerabilities represent 60%
of all reported security ﬂaws. In particular, site-speciﬁc vulnerabilities (i.e., those
that aﬀect custom web applications) are receiving increased attention from online
criminals [2,3]. This is because by exploiting a single vulnerability in a popular
site (e.g., a social networking site or a high-traﬃc portal), an attacker can infect
a large number of end hosts by spreading malware via web browser exploits
(e.g., drive-by download attacks). Therefore, there is a need for security tools
and techniques to protect web applications and deal with their ad hoc, dynamic
nature.
E. Kirda, S. Jha, and D. Balzarotti (Eds.): RAID 2009, LNCS 5758, pp. 21–40, 2009.
c(cid:2) Springer-Verlag Berlin Heidelberg 2009
22
F. Maggi et al.
Anomaly-based intrusion detection techniques have been shown to be eﬀec-
tive in protecting web applications against attacks [4,5,6,7,8]. In contrast to mis-
use detection systems, which contain ﬁngerprints of all known attacks patterns,
anomaly-based detectors leverage models of the normal behavior of the mon-
itored web applications to detect attacks, under the assumption that attacks
cause anomalies, and anomalies are always associated with malicious activity.
Besides an initial conﬁguration, these tools typically neither require mainte-
nance nor manual updates to provide protection. For these reasons, they have
the advantage of oﬀering a black-box solution to web application security, even
against 0-day exploits and site-speciﬁc attacks. Some anomaly-based web at-
tack detection techniques are mature enough to be implemented in commercial
tools [9,10,11].
A class of anomaly detectors for web applications leverages machine learning
techniques to automatically build models of the normal behavior of the moni-
tored web applications. In this context, the term normal behavior generally refers
to a set of characteristics (e.g., the distribution of the characters of string pa-
rameters, the mean and standard deviation of the values of integer parameters)
extracted from HTTP messages that are observed during normal operation. De-
tection is performed under the assumption that attacks cause signiﬁcant changes
(i.e., anomalies) in the application behavior. Thus, any activity that does not ﬁt
the expected, learned models is ﬂagged as malicious. Obviously, the detection
accuracy strongly depends upon the quality of the models that describe the nor-
mal behavior. On one hand, over-specialization can lead to false positives [12,13];
on the other hand, over-generalization often results in false negatives [14,15,16].
One issue that has not been well-studied is the diﬃculty of adapting to changes
in the behavior of the protected applications. By behavior of a web application,
we refer to the features and the functionalities that the application oﬀers and, as
a consequence, the content of the inputs (i.e., the requests) that it process and
the outputs (i.e., the responses) that it produces. This is an important problem
because today’s web applications are user-centric. That is, the demand for new
services causes continuous updates to an application’s logic and its interfaces.
Our analysis reveals that signiﬁcant changes in the behavior of web applica-
tions are frequent. We refer to this phenomenon as web application concept drift.
In the context of anomaly-based detection, this means that legitimate behavior
might be misclassiﬁed as an attack after an update of the application, causing
the generation of false positives. Normally, whenever a new version of an appli-
cation is deployed in a production environment, a coordinated eﬀort involving
application maintainers, deployment administrators, and security experts is re-
quired. That is, developers have to inform administrators about the changes that
are rolled out, and the administrators have to update or re-train the anomaly
models accordingly. Otherwise, the amount of false positives will increase sig-
niﬁcantly. We propose a solution that makes these tedious tasks unnecessary.
Our technique examines the responses (HTML pages) sent by a web applica-
tion. More precisely, we check the forms and links in these pages to determine
Protecting a Moving Target: Addressing Web Application Concept Drift
23
when new elements are added or old ones removed. This information is leveraged
to identify legitimate changes.
Our technique recognizes when anomalous inputs (i.e., HTTP requests) are
due to previous, legitimate updates (changes) in a web application. In such cases,
false positives are suppressed by automatically and selectively re-training mod-
els. Moreover, when possible, model parameters can be automatically updated
without requiring any re-training. Often, a complete re-training would be ex-
pensive in terms of time; typically, it requires O(P ) where P represents the
number of HTTP messages required to train a model. More importantly, such
re-training is not always feasible since new, attack-free training data is unlikely
to be available immediately after the application has changed. In fact, to collect
a suﬃcient amount of data the new version of the application must be executed
and real, legitimate clients have to interact with it in a controlled environment.
Clearly, this task requires time and eﬀorts. More importantly, those parts that
have changed in the application must be known in advance.
Our approach takes a diﬀerent perspective. We focus on the fundamental
problem of detecting those parts of the application that have changed and that
will cause false positives if no re-training is performed. Therefore, our technique
is agnostic with respect to the speciﬁc training procedure, which can be diﬀerent
from the one we propose.
In summary, this paper proposes a set of change detection techniques to ad-
dress the concept drift problem by treating the protected web applications as
oracles. We show that HTTP responses contain important insights that can be
eﬀectively leveraged to update previously learned models to take changes into
account. The results of applying our technique on real-world data show that
learning-based anomaly detectors can automatically adapt to changes, and by
doing this, are able to reduce their false positive rate without decreasing their
detection accuracy.
In this paper, we make the following contributions.
– We detail the problem of concept drift in the context of web applications,
and we provide evidence that it occurs in practice, motivating why it is a
signiﬁcant problem for deploying learning-based anomaly detectors in the
real world.
– We present novel techniques based on HTTP response models that can be
used to distinguish between legitimate changes in web applications and web-
based attacks.
– We evaluate a tool incorporating these techniques over an extensive real-
world data set, demonstrating its ability to deal with web application concept
drift and reliably detect attacks with a low false positive rate.
2 Concept Drift
To introduce the idea of concept drift, we will use a generalized model of learning-
based anomaly detectors of web attacks. This model is based on the system pre-
sented in [5], but it is general enough to be adapted to virtually any learning-based
24
F. Maggi et al.
anomaly detector for web applications. Also, we show that concept drift is a prob-
lem that exists in the real world, and we motivate why it should be addressed.
Unless diﬀerently stated, we use the shorthand term anomaly detector to refer to
anomaly-based detectors that leverage unsupervised machine learning techniques.
2.1 Anomaly Detection for Web Applications
An anomaly detector builds models of normal behavior by observing HTTP mes-
sages exchanged between servers and clients. The traﬃc directed to the server
running a certain web application (e.g., an e-commerce application or a blog)
can be organized into paths, or resources, R = {r1, r2, . . . , rj , . . .}. Each resource
corresponds to a diﬀerent software module of the application (e.g., an account
manager, a search component). Each resource rj responds to requests, or queries,
Q = {qj,1, qj,2, . . . , qj,i, . . .} that contain sets of name-value parameters transmit-
ted by the client as part of the HTTP request. Each query qj,i is abstracted as a
tuple qj,i = (cid:2)rj , Pq(cid:3), where Pq = {(p1, v1), (p2, v2), . . . , (pk, vk)} ⊆ Pj, and Pj =
P (rj) is the set of all the parameters handled by rj. For instance, the request
‘GET /page?id=21&uid=u43&action=del’ contains the resource r1 = ‘/page’
and the parameters Pq = {(cid:2)p1 = id, v1 = 21(cid:3),(cid:2)p2 = uid, v2 = ‘u43’(cid:3),(cid:2)p3 =
action, v3 = ‘del’(cid:3)}. Typically, an anomaly detector would use diﬀerent mod-
els to capture legitimate values associated with each parameter.
In addition to requests, the structure of user sessions can be taken into ac-
count to model the normal states of a server-side application. In this case, the
anomaly detector does not consider individual requests independently, but mod-
els their sequence. This model captures the legitimate order of invocation of the
resources, according to the application logic. An example is when a user is re-
quired to invoke an authentication resource (e.g., /user/auth) before requesting
a private page (e.g., /user/profile). In [5], a session S is deﬁned as a sequence
of resources in R. For instance, given R = {r1, r2, . . . , r10}, a sample session is
S = (cid:2)r3, r1, r2, r10, r2(cid:3).
Finally, HTTP responses that are returned by the server can also be modeled.
For example, in [5], a model m(doc) is presented that takes into account the
structure of documents (e.g., HTML, XML, and JSON) in terms of partial trees
that include security-relevant nodes (e.g.,  nodes, nodes containing
DOM event handlers, and nodes that contain sensitive data such as credit card
numbers). These trees are iteratively merged as new documents are observed,
creating a superset of the allowed document structure and the positions within
the tree where client-side code or sensitive data may appear.
During the learning (or training) phase, given a training set of queries Q
and the corresponding responses, the model parameters are estimated and ap-
propriate anomaly thresholds are calculated. More precisely, each parameter of
a resource ri is associated with a set of models; this set of models is called a
proﬁle: c(·) = (cid:2)m1, m2, . . . , mu(cid:3). The speciﬁc models in c(·) and the strategy to
combine their output determine the classes of attacks that can be detected. The
interested reader is referred to [5,8,17] for more details.
Protecting a Moving Target: Addressing Web Application Concept Drift
25
During detection, for each new request q and corresponding response, the
database of proﬁles is used to calculate an aggregated anomaly score, which
takes into account the anomaly score of the request or the response according to
all the applicable models. In general, an alert is raised if the aggregated anomaly
score is above the threshold learned during training.
In this work, the set of models implemented in webanomaly [5] is used to show
how anomaly detectors can be improved to cope with the problem of concept
drift. However, the techniques we propose in this work can be easily applied to
other anomaly-based detectors.
2.2 Web Applications Are Not Static
In machine learning, changes in the modeled behavior are known as concept
drift [18]. Intuitively, the concept is the modeled phenomenon (e.g., the struc-
ture of requests to a web server, the recurring patterns in the payload of network
packets). Thus, variations in the main features of the phenomena under consid-
eration result in changes, or drifts, in the concept.
Although the generalization and abstraction capabilities of modern learning-
based anomaly detectors are resilient to noise (i.e., small, legitimate variations in
the modeled behavior), concept drift is diﬃcult to detect and to cope with [19].
The reason is that the parameters of the models may stabilize to diﬀerent values.
For instance, a string length model could calculate the sample mean and variance
of the string lengths that are observed during training. Then, during detection,
the Chebyshev inequality is used to detect strings with lengths that signiﬁcantly
deviate from the mean, taking into account the observed variance. Clearly, small
diﬀerences in the lengths of strings will be considered normal. On the other hand,
the mean and variance of the string lengths can completely change because of
legitimate and permanent modiﬁcations in the web application. In this case, the
normal mean and variance will stabilize, or drift, to completely diﬀerent values.
If appropriate re-training or manual updates are not performed, the model will
classify benign, new strings as anomalous. This might be a human-intensive
activity requiring substantial expertise. Therefore, having an automated, black-
box mechanism to adjust the parameters is clearly very desirable.
Changes in web applications can manifest themselves in several ways. In the
context of learning-based detection of web attacks, those changes can be catego-
rized into three groups: request changes, session changes, and response changes.
Request changes. Changes in requests occur when an application is upgraded
to handle diﬀerent HTTP requests. These changes can be further divided into
two groups: parameter value changes and request structure changes. The former
involve modiﬁcations of the actual value of the parameters, while the latter
occur when parameters are added or removed. Parameter renaming is the result
of removal plus addition.
Example. A new version of a web forum introduces internationalization (I18N)
and localization (L10N). Besides handling diﬀerent languages, I18N and L10N
allow several types of strings to be parsed as valid dates and times. For instance,
26
F. Maggi et al.
valid strings for the datetime parameter are ‘3 May 2009 3:00’, ‘3/12/2009’,
‘3/12/2009 3:00 PM GMT-08’, ‘now’. In the previous version, valid date-time
strings had to conform to the regular expression ‘[0-9]{1,2}/[0-9]{2}/[0-
9]{4}’. A model with good generalization properties would learn that the ﬁeld
datetime is composed of numbers and slashes, with no spaces. Thus, other
strings such as ‘now’ or ‘3/12/2009 3:00 PM GMT-08’ would be ﬂagged as
anomalous. Also, in our example, tz and lang parameters have been added to
take into account time zones and languages. To summarize, the new version
introduces two classes of changes. Clearly, the parameter domain of datetime
is modiﬁed. Secondly, new parameters are added.
Changes in HTTP requests directly aﬀect the request models. First, parameter
value changes aﬀect any models that rely on the parameters’ values to extract
features. For instance, consider two of the models used in the system described in
[5]: m(char) and m(struct). The former models the strings’ character distribution
by storing the frequency of all the symbols found in the strings during training,
while the latter models the strings’ structure as a stochastic grammar, using a
Hidden Markov Model (HMM). In the aforementioned example, the I18N and
L10N introduce new, legitimate values in the parameters; thus, the frequency
of numbers in m(char) changes and new symbols (e.g., ‘-’, ‘[a-zA-Z]’ have to
be taken into account. It is straightforward to note that m(struct) is aﬀected in
terms of new transitions introduced in the HMM by the new strings. Secondly,
request structure changes may aﬀect any type of request model, regardless of the
speciﬁc characteristics. For instance, if a model for a new parameter is missing,
requests that contain that parameter might be ﬂagged as anomalous.
Session changes. Changes in sessions occur whenever resource path sequences
are reordered, inserted, or removed. Adding or removing application modules
introduces changes in the session models. Also, modiﬁcations in the application
logic are reﬂected in the session models as reordering of the resources invoked.
Example. A new version of a web-based community software grants read-only
access to non-authenticated users, allowing them to display contents previ-
ously available to subscribed users only. In the old version, legitimate sequences
were (cid:2)/site, /auth, /blog(cid:3) or (cid:2)/site, /auth, /files(cid:3), where /site indicates the
server-side resource that handles the public site, /auth is the authentication re-
source, and /blog and /files were formerly private resources. Initially, the prob-
ability of observing /auth before /blog or /files is close to one (since users need
to authenticate before accessing private material). This is no longer true in the new
version, however, where /files|/blog|/auth are all possible after /site.
Changes in sessions impact all models that rely on the sequence of resources
that are invoked during the normal operation of an application. For instance,
consider the model m(sess) described in [5], which builds a probabilistic ﬁnite
state automaton that captures sequences of resource paths. New arcs must be
added to take into account the changes mentioned in the above example. These
types of models are sensitive to strong changes in the session structure and
should be updated accordingly when they occur.
Protecting a Moving Target: Addressing Web Application Concept Drift
27
Response changes. Changes in responses occur whenever an application is
upgraded to produce diﬀerent responses. Interface redesigns and feature addition
or removal are example causes of changes in the responses. Response changes are
common and frequent, since page updates or redesigns often occur in modern
websites.
Example. A new version of a video sharing application introduces Web 2.0 fea-
tures into the user interface, allowing for the modiﬁcation of user interface ele-
ments without refreshing the entire page. In the old version, relatively few nodes
of documents generated by the application contained client-side code. In the new
version, however, many nodes of the document contain event handlers to trigger
asynchronous requests to the application in response to user events. Thus, if a
response model is not updated to reﬂect the new structure of such documents,
a large of number of false positives will be generated due to legitimate changes
in the characteristics of the web application responses.
2.3 Prevalence of Concept Drift
To understand whether concept drift is a relevant issue for real-world websites,
we performed three experiments. For the ﬁrst experiment, we monitored 2,264
public websites, including the Alexa Top 500 and other sites collected by querying
Google with popular terms extracted from the Alexa Top 500. The goal was
to identify and quantify the changes in the forms and input ﬁelds of popular
websites at large. This provides an indication of the frequency with which real-
world applications are updated or altered.
Once every hour, we visited one representative page for each of the 2,264
websites. In total, we collected 3,303,816 pages, comprising more than 1,390
snapshots for each website, between January 29 and April 13, 2009. One
tenth of the representative pages were manually selected to have a signiﬁ-
cant number of forms, input ﬁelds, and hyperlinks with parameters (e.g., ). By doing this, we gathered a consid-
erable amount of information regarding the HTTP messages generated by some
applications. Examples of these pages are registration pages, data submission
pages, or contact form pages. For the remaining websites, we simply used their
home pages.
For each website w, each page sample crawled at time t is associated with a tu-
ple |F|(w)
, the cardinality of the sets of forms and input ﬁelds, respectively.
By doing this, we collected samples of the variables |F|w = |F|w
, . . . ,|F|w
tn,
|I|w = |I|w
tn, with 0 < n <∼ 1, 390. Figure 1 shows the relative frequency
of the variables XI = stdev(|I|(w1)), . . . , stdev(|I|(wk)) and XF = stdev(|F|(w1)),
. . . , stdev(|F|(wk)). This demonstrates that a signiﬁcant amount of websites ex-
hibit variability in the response models, in terms of elements modiﬁed in the
pages, as well as request models, in terms of new forms and parameters. In addi-
tion, we estimated the expected time between changes of forms and inputs ﬁelds,
E[TF ] and E[TI], respectively. In terms of forms, 40.72% of the websites drifted
during the observation period. More precisely, 922 out of 2,264 websites have a
,|I|(w)
, . . . ,|I|w
t1
t
t
t1
28
F. Maggi et al.
0
0
2
0
5
1
0
0
1
0
5