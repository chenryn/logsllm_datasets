300
200
100
)
s
d
n
o
c
e
s
(
e
m
i
t
e
s
n
o
p
s
e
r
y
r
e
u
Q
0
0
100
200
300
400
500
600
Number of graph distance computations
t
e
g
a
n
e
c
r
e
p
e
v
i
t
l
a
u
m
u
C
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0 100 200 300 400 500 600 700 800 900 1000
Query response time (seconds)
Figure 6: Scalability of the VP tree with re-
Figure 7: Query response time of 500 ﬁve-nearest-neighbor queries against a 100,000-
spect to the number of indexed graphs
malware database
Rate among N = 2, 3 and 4 does not appear signiﬁcant enough to
warrant the extra performance cost. This is because leaf nodes that
are far away from the current leaf node usually contain malware
ﬁles whose feature vectors are quite different from the query mal-
ware, indicating that they are likely not in the same family as the
query malware. Hence, exploring more leaf nodes (i.e., larger N)
does not signiﬁcantly improve the accuracy. In our current SMIT
prototype, we choose N = 2 as the default setting. In addition,
the high values of Dominant Family Rate and Average Hit in Ta-
ble 3 also demonstrate the effectiveness of SMIT in helping human
analysts identify the malware family of incoming samples.
associated with these techniques is generally acceptable, because
SMIT is mainly positioned as a back-end malware classiﬁcation
and analysis tool.
Second, because SMIT analyzes malware samples at the level
of individual instructions and function calls, it may be susceptible
to advanced obfuscation techniques. For instance, attackers may
circumvent SMIT’s function matching by obfuscation, such as in-
struction reordering, equivalent instruction substitution, import ta-
ble modiﬁcation (to hide the symbolic names of imported func-
tions), etc. Alternatively, they could also modify the function-call
graph by, for example, inserting useless functions into the graph,
breaking existing functions into several smaller functions, inlin-
ing certain functions, etc. Although SMIT cannot completely han-
dle all types of obfuscation, it makes these attacks more difﬁcult.
For instance, SMIT uses the edit distance between mnemonic se-
quences to evaluate inter-function similarity, which enables SMIT
to be relatively resilient to simple code obfuscation and relocation.
To defeat more sophisticated obfuscation, SMIT could pre-process
malware ﬁles with advanced deobfuscation techniques [26]. More
importantly, because SMIT relies on structural similarity to match
function-call graphs, changes to a few nodes in the graphs are un-
likely to signiﬁcantly inﬂuence the matching results.
Third, SMIT extracts function-call graphs using IDA Pro, which
may occasionally fail to identify all the functions in a malware bi-
nary. IDA Pro ﬁnds function-start addresses by traversing direct
function call or recognizing function prologues. As a result, if the
functions are indirectly referenced or have non-standard prologues,
IDA Pro may fail to identify their starting points. A more thorough
approach [13] that uses a new function model based on a multi-
entry control ﬂow graph could mitigate this problem.
Finally, the dominant family metric used in SMIT may lead to
false positives. Because SMIT is mainly used to help malware
analysts quickly determine the maliciousness and the identity of
incoming malware, it assumes that the query malware sample be-
longs to the same family as the majority of its nearest neighbors in
the database. However, this assumption is not always valid and a
false positive may occur if the distance between an input malware
sample and its dominant family neighbors is too large. One way to
address this problem is to apply a distance threshold in the classiﬁ-
cation process so that an input sample is classiﬁed into a malware
family if and only if it is sufﬁciently close to the returned nearest
neighbors. The optimal threshold could be chosen based on the av-
erage inter-member distance within a malware family as well as the
inter-family distance between the centroids of adjacent families.
In summary, although there are ways malware writers could use
to detract SMIT’s overall effectiveness, SMIT is still very effective
in practice against modern malware samples, as demonstrated in
Section 6, and thus represents a very efﬁcient tool available for mal-
ware analysts to handle the exponentially-growing inﬂux of mal-
ware samples as seen in recent years.
6.5.2 Query Response Time of SMIT
Finally, we measure the response time of SMIT for K-NN queries
against the entire test database, where N is set to 2 and K is set to 5.
We randomly select over 500 malware ﬁles and use them to query
SMIT. The response times of these queries and their cumulative
distribution function are shown in Figure 7. The X-axis of the left
ﬁgure is the number of graph-distance computations required for a
query and the corresponding Y-axis is the response time in seconds
for that query. From the right ﬁgure, for over 95% of all queries,
the response time is less than 100 seconds, although several queries
(mostly for very large malware ﬁles) incur a signiﬁcantly longer de-
lay and thus skew the overall average response time. More specif-
ically, each 5-NN query requires, on average, 112 graph-distance
computations (median is 78 and maximum is 918). The query re-
sponse time ranges from 0.015 second to 872 seconds with average
21 seconds and median 0.5 second. This result demonstrates that
SMIT’s performance is adequate for day-to-day use even for rela-
tively large malware databases.
7. LIMITATIONS AND IMPROVEMENTS
We now discuss several limitations of the current SMIT proto-
type that may limit its classiﬁcation effectiveness, and possible im-
provements to remove or alleviate them.
One way for malware authors to evade SMIT’s classiﬁcation is
to prevent SMIT from extracting useful features by applying pack-
ers/protectors to their malware ﬁles. SMIT’s classiﬁcation accuracy
will degrade signiﬁcantly if it cannot successfully unpack packed
malware ﬁles. To counter the packing problem, the current SMIT
prototype employs several packer detection (PEiD, TrID) and un-
pack tools (SymPack), but they are by no means complete. For ex-
ample, PEiD can be misled by a simple modiﬁcation to a PE ﬁle’s
entry point. Most existing unpack tools fail to handle sophisticated
packers, such as Armadillo [1] and VMProtect [33]. To improve
SMIT’s unpacking capabilities, we plan to incorporate generic un-
packers, such as OmniUnpack [22] and Justin [12], which execute
malware samples, detect the end of unpacking and then dump the
process image at that instant. The extra performance overhead
6198. CONCLUSION
In recent years, the number of malware samples seen in the ﬁeld
has increased exponentially, and automating the malware process-
ing workﬂow is crucial to commercial anti-virus companies such as
Symantec. A critical step in malware processing workﬂow is to de-
termine if an incoming sample is indeed malicious or not. A com-
mon approach taken today is to apply multiple commercial Anti-
Virus scanners to a sample and convict the sample as malware if
a sufﬁcient number of Anti-Virus scanners consider it malicious.
Although this approach is useful, it does not completely solve the
problem, because at any point in time a signiﬁcant percentage of
new samples are unknown to existing Anti-Virus scanners.
This paper describes the design, implementation and evaluation
of a malware database management system called SMIT that imple-
ments a malware conviction approach which casts the problem of
determining if a new binary sample is malicious into one of locat-
ing the sample’s nearest neighbors in the malware database. SMIT
converts each malware program into its function-call graph repre-
sentation, and performs nearest neighbor search based on this graph
representation.To efﬁciently capture the similarity among malware
variants, SMIT supports an approximate graph-edit distance metric
rather than isomorphic graph match. To efﬁciently support accu-
rate and scalable nearest neighbor search, SMIT features a multi-
resolution indexing scheme that combines a B+ tree based on high-
level summary features and a vantage-point tree based on the graph-
distance metric. With these techniques, SMIT is able to detect mal-
ware samples at a speed and accuracy level that can keep up with
the current malware sample submission rate. The main contribu-
tions of this work include: (1) an efﬁcient graph-distance computa-
tion algorithm whose result closely approximates the ideal graph-
edit distance metric; (2) a multi-resolution indexing scheme that
supports efﬁcient pruning through a combination of exact indexing
based on summary features and nearest-neighbor indexing based on
graph-edit distance; and (3) A fully working SMIT prototype and
a comprehensive performance study of this prototype that demon-
strates its efﬁcacy and scalability with a 100,000-malware database.
9. REFERENCES
[1] Armadillo. http://www.siliconrealms.com/armadillo.htm, 2008.
[2] Peid 0.95. http://www.peid.info/, 2008.
[3] Trid v2.02. http://mark0.net/soft-trid-e.html, 2008.
[4] M. Bailey, J. Oberheide, J. Andersen, Z. M. Mao, F. Jahanian, and
J. Nazario. Automated classiﬁcation and analysis of internet
malware. In RAID, pages 178–197, 2007.
[5] U. Bayer, P. Milani Comparetti, C. Hlauscheck, C. Kruegel, and
E. Kirda. Scalable, Behavior-Based Malware Clustering. In 16th
Symposium on Network and Distributed System Security, 2009.
[6] T. Bozkaya and M. Ozsoyoglu. Distance-based indexing for
high-dimensional metric spaces. In In Proc. ACM SIGMOD
International Conference on Management of Data, 1997.
[7] I. Briones and A. Gomez. Graphs, entropy and grid computing:
Automatic comparison of malware. In Proceedings of the 2004 Virus
Bulletin Conference, 2004.
[8] E. Carrera and G. Erdelyi. Digital genome mapping ˛ał advanced
binary malware analysis. In Proceedings of the 2004 Virus Bulletin
Conference, 2004.
[9] T.-c. Chiueh. Content-based image indexing. In VLDB ’94:
Proceedings of the 20th International Conference on Very Large
Data Bases, pages 582–593, 1994.
[10] S. Das, A. Mistry, D. Negoescu, G. Reed, and S. K. Singh. A graph
matching problem. Techical report, IPAM Research in Industrial
Projects for Students (RIPS), 2008.
[11] M. R. Garey and D. S. Johnson. Computers and Intractability : A
Guide to the Theory of NP-Completeness. W. H. Freeman, 1979.
[12] F. Guo, P. Ferrie, and T.-C. Chiueh. A study of the packer problem
and its solutions. In RAID ’08, pages 98–115, 2008.
[13] L. C. Harris and B. P. Miller. Practical analysis of stripped binary
code. SIGARCH Comput. Archit. News, 33(5):63–68, 2005.
[14] H. He and A. K. Singh. Closure-tree: An index structure for graph
queries. In ICDE ’06: Proceedings of the 22nd International
Conference on Data Engineering, page 38, 2006.
[15] Hex-rays. The IDA Pro Disassembler and Debugger.
http://www.hexrays.com/idapro/, 2008.
[16] X. Hu, T. cker Chiueh, and K. G. Shin. Large-scale malware indexing
using function-call graphs (extended). Technical Report, Department
of Computer Sicence, University of Michigan, 2009.
[17] Ilfak Guilfanov. Fast Library Identiﬁcation and Recognition
Technology. http://www.hex-rays.com/idapro/ﬂirt.htm, 1997.
[18] D. Justice. A binary linear programming formulation of the graph
edit distance. IEEE Trans. Pattern Anal. Mach. Intell.,
28(8):1200–1214, 2006. Fellow-Hero„ Alfred.
[19] J. Z. Kolter and M. A. Maloof. Learning to detect and classify
malicious executables in the wild. J. Mach. Learn. Res.,
7:2721–2744, 2006.
[20] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna.
Polymorphic worm detection using structural information of
executables. In In RAID, pages 207–226. Springer-Verlag, 2005.
[21] H. W. Kuhn. The hungarian method for the assignment problem.
Naval Research Logistics Quarterly, 1955.
[22] L. Martignoni, M. Christodorescu, and S. Jha. Omniunpack: Fast,
generic, and safe unpacking of malware. In In Proceedings of the
Annual Computer Security Applications Conference (ACSAC, 2007.
[23] R. Myers, R. C. Wilson, and E. R. Hancock. Bayesian graph edit
distance. IEEE Trans. Pattern Anal. Mach. Intell., 22(6), 2000.
[24] M. Neuhaus and H. Bunke. An error-tolerant approximate matching
algorithm for attributed planar graphs and its application to
ﬁngerprint classiﬁcation. In SSPR/SPR, pages 180–189, 2004.
[25] M. Pietrek. An In-Depth Look into the Win32 PE File Format.
http://msdn.microsoft.com/en-us/magazine/cc301805.aspx, 2002.
[26] J. Raber and E. Laspe. Deobfuscator: An automated approach to the
identiﬁcation and removal of code obfuscation. Reverse Engineering,
Working Conference on, 0:275–276, 2007.
[27] K. Rieck, T. Holz, C. Willems, P. Düssel, and P. Laskov. Learning
and classiﬁcation of malware behavior. In DIMVA ’08, pages
108–125, 2008.
[28] K. Riesen, M. Neuhaus, and H. Bunke. Bipartite graph matching for
computing the edit distance of graphs. In Graph-Based
Representations in Pattern Recognition, volume 4538, 2007.
[29] D. Shasha, Jason, and R. Giugno. Algorithmics and applications of
tree and graph searching. In Symposium on Principles of Database
Systems, pages 39–52, 2002.
[30] Symantec Corp. Symantec Global Internet Security Threat Report.
Volume XII. http://www.symantec.com/, April 2008.
[31] Y. Tian and J. M. Patel. Tale: A tool for approximate large graph
matching. In ICDE, pages 963–972, 2008.
[32] T.Lee and J.J.Mody. Behavioral classiﬁcation.
http://www.microsoft.com/downloads/details.aspx?FamilyID
=7b5d8cc8-b336-4091-abb5-2cc500a6c41a&displaylang=en,2006.
[33] VMProtect. Vmprotect. http://www.vmprotect.ru/, 2008.
[34] X. Yan, P. S. Yu, and J. Han. Substructure similarity search in graph
databases. In SIGMOD ’05: Proceedings of the 2005 ACM SIGMOD
international conference on Management of data, 2005.
[35] P. N. Yianilos. Data structures and algorithms for nearest neighbor
search in general metric spaces. In SODA: ACM-SIAM Symposium
on Discrete Algorithms, 1993.
[36] P. Zezula, G. Amato, V. Dohnal, and M. Batko. Similarity Search:
The Metric Space Approach. Springer, 2006.
[37] P. Zezula, P. Ciaccia, and F. Rabitti. M-tree: A dynamic index for
similarity queries in multimedia databases. Technical Report 7,
HERMES ESPRIT LTR Project, 1996.
[38] K. Zhang and D. Shasha. Simple fast algorithms for the editing
distance between trees and related problems. SIAM J. Comput.,
18(6):1245–1262, 1989.
[39] P. Zhao, J. X. Yu, and P. S. Yu. Graph indexing: tree + delta ≤ graph.
In VLDB ’07: Proceedings of the 33rd international conference on
Very large data bases, pages 938–949, 2007.
620