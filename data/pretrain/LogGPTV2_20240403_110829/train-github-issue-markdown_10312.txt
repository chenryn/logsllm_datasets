### System information
  * **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)** : Y
  * **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)** : Linux Centos 7
  * **TensorFlow installed from (source or binary)** : Binary
  * **TensorFlow version (use command below)** : v1.8.0-3463-g39ea5a7044 1.10.0-dev20180620
  * **Python version** : Python 3.6.5
  * **Bazel version (if compiling from source)** :
  * **GCC/Compiler version (if compiling from source)** :
  * **CUDA/cuDNN version** : Cuda 9.0
  * **GPU model and memory** : NA
  * **Exact command to reproduce** :
    from __future__ import absolute_import, division, print_function
    import tensorflow as tf
    transfer = lambda x: tf.where(x < 0, 1./(1.-x), tf.log(x+1)) 
    def f(x):
        xt = tf.placeholder(tf.float32, shape=(1,))
        yt  = transfer(xt)
        dydx = tf.gradients(ys=yt, xs=xt)[0]
        with tf.Session() as sess:
            rval = sess.run([xt, yt, dydx], feed_dict={xt:[x]})
        return rval
    print(f(1.))  # [1, 2, nan]
    print(f(-1.)) # [-1, 0.5, nan]
    print(f(0.)) # [0, 0, 1] (no nan here, interestingly)
### Problem
Gradients computed through the tf.where command erroneously returns nans.
Presumably this is because the gradient computation computes the gradient
through both conditions, which may result in a division by zero or log of
zero.