attacks on servers’ computational resources in which good clients
send a ﬁxed number of copies of their messages and the server only
processes a ﬁxed fraction of the messages that it receives, thereby
diminishing adversaries’ impact. Our work shares an ethos but has
a very different realization. In that work, the drop probability and
repeat count are hard-coded, and the approach does not apply to
HTTP. Further, the authors do not consider congestion control, the
implications of deployment in today’s Internet, and the unequal re-
quests case. Also, Gligor [16] observes that client retries and time-
outs require less overhead while still providing the same qualita-
tive performance bounds as proof-of-work schemes. Because the
general approach does not meet his more exacting performance re-
quirements, he does not consider using bandwidth as currency.
Although we do not claim that bandwidth is strictly better than
other currencies, we do think it is particularly natural. With other
currencies, the server must either report an explicit price (e.g., by
sending a puzzle with a speciﬁc hardness) or have the clients guess
the price. With speak-up, in contrast, this function happens auto-
matically: the correct price emerges, and neither the thinner nor the
client has to know the price in advance.
The drawbacks of currency-based schemes are, ﬁrst, that the
good clients must have enough currency [24] (e.g., speak-up only
applies when the good clients have enough bandwidth) and, second,
that the currency can be unequally distributed (e.g., some clients
have faster uplinks than others). We discuss this latter disadvantage
in §9. Another critique of currency schemes is that they give attack-
ers some service so might be weaker than the schemes we discuss
below (such as proﬁling) that seek to block attackers. However, un-
der those schemes, a smart bot can imitate a good client, succeed
in fooling the detection discipline, and again get some service.
The most commonly deployed defense [30] is a combination of
link over-provisioning [33] and proﬁling, which is a detect-and-
block approach offered by several vendors [5, 9, 27]. These latter
products build a historical proﬁle of the defended server’s clientele
and, when the server is attacked, block trafﬁc violating the proﬁle.
Many other detect-and-block schemes have been proposed; we now
mention a few. Resource containers [8] perform rate-limiting to al-
locate the server’s resources to clients fairly. Defenses based on
CAPTCHAs [47] (e.g., [29, 42]) use reverse Turing tests to block
bots. Killbots [21] combines CAPTCHAs and rate-limiting, deﬁn-
ing a bot as a non-CAPTCHA answering host that sends too many
requests to an overloaded server. With capabilities [4, 50, 51], the
network blocks trafﬁc not authorized by the application; to de-
cide which trafﬁc to authorize, the application can use rate-limiting,
CAPTCHAs, or other rules.
One critique of detect-and-block methods is that they can err.
CAPTCHAs can be thwarted by “bad humans” (cheap labor hired
to attack a site or induced [32] to solve the CAPTCHAs) or “good
bots” (legitimate, non-human clientele or humans who do not an-
swer CAPTCHAs). Schemes that rate-limit clients by IP address
can err with NAT (a large block of customers is rate-limited as one
customer) or spooﬁng (a small number of clients can get a large
piece of the server). Proﬁling apparently addresses some of these
shortcomings today (e.g., many legitimate clients behind a NAT
would cause the NAT’s external IP address to have a higher baseline
rate in the server’s proﬁle). However, in principle such “behavior-
based” techniques can also be “fooled”: a set of savvy bots could,
over time, “build up” their proﬁle by appearing to be legitimate
clients, at which point they could abuse their proﬁle and attack.
8.2 Combining with Related Work
Practical DDoS defense involves composing various methods from
the taxonomy in §1. We do not outline a complete DDoS protec-
tion strategy here but only discuss how to protect two classes of re-
sources. First, all sites, whether using speak-up or not, must defend
their access links from saturation. Speak-up in particular requires
that the thinner is not congested (§4.3). The best current strategy
for link defense seems to be a combination of over-provisioning
(e.g., [33]), blocking obviously spurious trafﬁc (e.g., ICMP ﬂoods),
and shaping “in-band” trafﬁc via historical proﬁling (e.g., [5,9,27]).
Second, sites with scarce computational resources must imple-
ment application-level defense. Given that proﬁling is required
to protect the link anyway, we must ask when it sufﬁces as an
application-level defense. Our answer is when the following condi-
tions all hold: no pre-deﬁned clientele (C3 from §2.2); non-human
clientele (C4); and the negation of C5, i.e., when requests cause
equal amounts of work, when spooﬁng is implausible, and when
bots trigger alarms. We now brieﬂy consider what to do when the
conditions for proﬁling are not met. When C3 doesn’t hold, one can
use capabilities [4,50,51] or explicit ﬁlters. When C4 doesn’t hold,
one may be able to use CAPTCHAs to preferentially admit humans.
And of course, when C5 does hold, and when C1 and C2 do too,
we advocate speak-up as the application-level DDoS defense.
9 OBJECTIONS
Even under the conditions when speak-up is most applicable, it may
still raise objections, some of which we now address.
Bandwidth envy. Before speak-up, all good clients competed
equally for a small share of the server. Under speak-up, more good
clients are “better off” (i.e., can claim a larger portion of the server).
But since speak-up allocates the server’s resources in proportion to
a client’s bandwidth, high-bandwidth good clients are “more bet-
ter off”, and this inequality might be problematic. However, ob-
serve that unfairness only occurs under attack. Thus, while we
think this inequality is unfortunate, it is not fatal. A possible so-
lution is for ISPs with low-bandwidth customers to offer access to
high-bandwidth proxies whose purpose is to “pay bandwidth” to
the thinner. These proxies would have to allocate their resources
fairly—perhaps by implementing speak-up recursively.
Variable bandwidth costs.
In some countries, customers pay
their ISPs “per-bit”. For those customers, access to a server de-
fended by speak-up (and under attack) would cost more than usual.
One possible solution is the proxy mentioned above. Another one
is a “price tag”: the thinner would expose the “going rate” in bytes,
and the ISP would translate this ﬁgure to money and report it to
customers, letting them choose whether to pay for access.
Incentives for ISPs. One might ask whether speak-up gives ISPs
an incentive to encourage botnets as a way to increase the band-
width demanded by good clients. Our response is that such mis-
alignment of incentives can happen in many commercial relation-
ships (e.g., investment managers who needlessly generate commis-
sions), but society relies on a combination of regulation, profes-
sional norms, and reputation to limit harmful conduct.
Solving the wrong problem. One might ask, “If the problem is
bots, then shouldn’t researchers address that mess instead of en-
couraging more trafﬁc?” Our answer to this philosophical question
is that cleaning up bots is crucial, but even if bots are curtailed by
orders of magnitude, a server with scarce computational resources
must still limit bots’ inﬂuence. Speak-up is a way to do so.
Flash crowds.
Speak-up treats a ﬂash crowd (overload from
good clients alone) just like an application-level DDoS attack. This
fact might appear unsettling. Observe, however, that it does not ap-
ply to the canonical case of a ﬂash crowd, in which a hyperlink from
slashdot.org overwhelms a residential Web site’s access link:
speak-up would not have been deployed to defend a low-bandwidth
site (see §2.2). For sites in our applicability regime, making good
clients “bid” for access when all clients are good is certainly not
ideal, but the issues here are the same as with speak-up in general.
10 CONCLUSION
This study has sought
two high-level questions:
(1) Which conditions call for speak-up’s peculiar brand of protec-
tion? (2) Does speak-up admit a practical design? Notably absent
from this list is a question about how often the conditions in (1) do
to answer
and will hold, i.e., who needs speak-up? To answer that question
deﬁnitively will require not just a measurement effort but also a
broader “market survey”—a survey about demand that, to be credi-
ble, will have to gather the opinions of network operators, server
operators, and even users. Rather than trying to see who would
buy—which we plan to do next—we decided ﬁrst to see what we
could build. Perhaps our priorities were inverted. Nevertheless, we
report our main ﬁnding: based on the design, analysis, and eval-
uation of a prototype and subject to much future work and many
issues, we can give a cautiously afﬁrmative answer to question (2).
Acknowledgments
We thank the HotNets 2005 attendees, especially Nick Feamster,
Vern Paxson, Adrian Perrig, and Srini Seshan, for important cri-
tiques of our approach; Frans Kaashoek, Max Krohn, Sara Su,
Arvind Thiagarajan, Keith Winstein, and the anonymous reviewers,
both regular and shadow PC, for excellent comments on drafts; Ben
Adida, Dave Andersen, Micah Brodsky, Russ Cox, Jon Crowcroft,
Nick Feamster, Sachin Katti, Eddie Kohler, Christian Kreibich,
Max Poletto and Andrew Warﬁeld, for useful conversations; and
Emulab [13]. This work was supported by the NSF under grants
CNS-0225660 and CNS-0520241, by an NDSEG Graduate Fellow-
ship, and by British Telecom.
References
[1] M. Abadi, M. Burrows, M. Manasse, and T. Wobber. Moderately
hard, memory-bound functions. In NDSS, 2003.
[2] S. Agarwal, T. Dawson, and C. Tryfonas. DDoS mitigation via
regional cleaning centers. Sprint ATL Research Report
RR04-ATL-013177, Aug. 2003.
[3] D. G. Andersen et al. System support for bandwidth
management and content adaptation in Internet applications. In
OSDI, Sept. 2000.
[4] T. Anderson, T. Roscoe, and D. Wetherall. Preventing Internet
denial-of-service with capabilities. In HotNets, Nov. 2003.
[5] Arbor Networks, Inc. http://www.arbornetworks.com.
[6] T. Aura, P. Nikander, and J. Leiwo. DoS-resistant authentication
with client puzzles. In Intl. Wkshp. on Security Prots., 2000.
[7] A. Back. Hashcash. http://www.cypherspace.org/adam/hashcash/.
[8] G. Banga, P. Druschel, and J. C. Mogul. Resource containers: A
new facility for resource management in server systems. In
OSDI, Feb. 1999.
[9] Cisco Guard, Cisco Systems, Inc. http://www.cisco.com.
[10] Criminal Complaint: USA v. Ashley, Hall, Schictel, Roby, and
Walker, Aug. 2004. http://www.reverse.net/operationcyberslam.pdf.
[11] C. Dwork, A. Goldberg, and M. Naor. On memory-bound
functions for ﬁghting spam. In CRYPTO, 2003.
[12] C. Dwork and M. Naor. Pricing via processing or combatting
junk mail. In CRYPTO, 1992.
[13] Emulab. http://www.emulab.net.
[14] N. Feamster, J. Jung, and H. Balakrishnan. An empirical study
of “bogon” route advertisements. CCR, 35(1), Jan. 2005.
[15] C. Fraleigh, S. Moon, B. Lyles, C. Cotton, M. Khan, D. Moll,
R. Rockell, T. Seely, and C. Diot. Packet-level trafﬁc
measurements from the Sprint IP backbone. IEEE Network,
17(6), 2003.
[16] V. D. Gligor. Guaranteeing access in spite of distributed
service-ﬂooding attacks. In Intl. Wkshp. on Security Prots., 2003.
[17] C. A. Gunter, S. Khanna, K. Tan, and S. Venkatesth. DoS
protection for reliably authenticated broadcast. In NDSS, 2004.
[18] M. Handley. Internet architecture WG: DoS-resistant Internet
subgroup report, 2005. http://www.communicationsresearch.net/dos-
resistant/meeting-1/cii-dos-summary.pdf.
[19] Honeynet Project and Research Alliance. Know your enemy:
Tracking botnets. Mar. 2005. http://www.honeynet.org/papers/bots/.
[20] A. Juels and J. Brainard. Client puzzles: A cryptographic
countermeasure against connection depletion attacks. In NDSS,
1999.
[21] S. Kandula, D. Katabi, M. Jacob, and A. Berger. Botz-4-sale:
Surviving organized DDoS attacks that mimic ﬂash crowds. In
USENIX NSDI, May 2005.
[22] E. Kohler, M. Handley, and S. Floyd. Designing DCCP:
Congestion control without reliability. In SIGCOMM, Sept.
2006.
[23] M. Krohn. Building secure high-performance Web services with
OKWS. In USENIX Technical Conference, June 2004.
[24] B. Laurie and R. Clayton. “Proof-of-Work” proves not to work;
version 0.2, Sept. 2004.
http://www.cl.cam.ac.uk/users/rnc1/proofwork2.pdf.
[25] D. Mankins, R. Krishnan, C. Boyd, J. Zao, and M. Frentz.
Mitigating distributed denial of service attacks with dynamic
resource pricing. In Proc. IEEE ACSAC, Dec. 2001.
[26] D. Mazi`eres. A toolkit for user-level ﬁle systems. In USENIX
Technical Conference, June 2001.
[27] Mazu Networks, Inc. http://mazunetworks.com.
[28] J. Mirkovic and P. Reiher. A taxonomy of DDoS attacks and
DDoS defense mechanisms. CCR, 34(2), Apr. 2004.
[29] W. Morein, A. Stavrou, D. Cook, A. Keromytis, V. Mishra, and
D. Rubenstein. Using graphic turing tests to counter automated
DDoS attacks against Web servers. In ACM CCS, Oct. 2003.
[30] Network World. Extortion via DDoS on the rise. May 2005.
http://www.networkworld.com/news/2005/051605-ddos-extortion.html.
[31] K. Park, V. S. Pai, K.-W. Lee, and S. Calo. Securing Web
service by automatic robot detection. In USENIX Technical
Conference, June 2006.
[32] Pittsburgh Post-Gazette. CMU student taps brain’s game skills.
Oct. 5, 2003. http://www.post-gazette.com/pg/03278/228349.stm.
[33] Prolexic Technologies, Inc. http://www.prolexic.com.
[34] A. Ramachandran and N. Feamster. Understanding the
network-level behavior of spammers. In SIGCOMM, Sept. 2006.
[35] V. Ramasubramanian and E. G. Sirer. The design and
implementation of a next generation name service for the
Internet. In SIGCOMM, Aug. 2004.
[36] E. Ratliff. The zombie hunters. The New Yorker, Oct. 10, 2005.
[37] SecurityFocus. FBI busts alleged DDoS maﬁa. Aug. 2004.
http://www.securityfocus.com/news/9411.
[38] V. Sekar, N. Dufﬁeld, O. Spatscheck, J. van der Merwe, and
H. Zhang. LADS: Large-scale automated DDoS detection
system. In USENIX Technical Conference, June 2006.
[39] M. Sherr, M. Greenwald, C. A. Gunter, S. Khanna, and S. S.
Venkatesh. Mitigating DoS attack through selective bin
veriﬁcation. In 1st Wkshp. on Secure Netwk. Protcls., Nov. 2005.
[40] K. K. Singh. Botnets—An introduction, 2006.
http://www-static.cc.gatech.edu/classes/AY2006/cs6262 spring/botnets.ppt.
[41] Spammer-X. Inside the SPAM Cartel. Syngress, 2004. Page 40.
[42] Stupid Google virus/spyware CAPTCHA page.
http://www.spy.org.uk/spyblog/2005/06/stupid google virusspyware cap.html.
[43] TechWeb News. Dutch botnet bigger than expected. Oct. 2005.
http://informationweek.com/story/showArticle.jhtml?articleID=172303265.
[44] The Register. East European gangs in online protection racket.
Nov. 2003.
[45] D. Thomas. Deterrence must be the key to avoiding DDoS
attacks, 2005.
http://www.vnunet.com/computing/analysis/2137395/deterrence-
key-avoiding-ddos-attacks.
[46] R. Vasudevan, Z. M. Mao, O. Spatscheck, and J. van der Merwe.
Reval: A tool for real-time evaluation of DDoS mitigation
strategies. In USENIX Technical Conference, June 2006.
[47] L. von Ahn, M. Blum, and J. Langford. Telling humans and
computers apart automatically. CACM, 47(2), Feb. 2004.
[48] M. Walﬁsh, H. Balakrishnan, D. Karger, and S. Shenker. DoS:
Fighting ﬁre with ﬁre. In HotNets, Nov. 2005.
[49] X. Wang and M. Reiter. Defending against denial-of-service
attacks with puzzle auctions. In IEEE Symp. on Security and
Privacy, May 2003.
[50] A. Yaar, A. Perrig, and D. Song. SIFF: A stateless Internet ﬂow
ﬁlter to mitigate DDoS ﬂooding attacks. In IEEE Symp. on
Security and Privacy, May 2004.
[51] X. Yang, D. Wetherall, and T. Anderson. A DoS-limiting
network architecture. In SIGCOMM, Aug. 2005.