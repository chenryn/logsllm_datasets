rency or credit is explicitly used). As acknowledged in [2], such
“seed money/credit” necessarily introduces vulnerabilities to sybil
and whitewashing attacks. In contrast, our DCast design manages
to avoid “seed money/credit” completely. In the next, we will dis-
cuss in more detail efforts whose techniques are more related to
ours.
Samsara [3] is a p2p backup system that aims to prevent free-
riding. When a peer B wishes to back up data on peer A but A has
nothing to back up on B, A will force B to store a storage claim
of the same size as B’s backup data. Such design does not actually
sustain collaboration when users are rational — since A’s utility
decreases here, A actually has incentive not to engage in such an
interaction.
Many previous efforts [6, 11, 17] use credit chains (including
one-hop reputation [21] as length-2 credit chains) to achieve a sim-
ilar functionality as circulating currency. In these designs, there is
no mechanism to ensure that credits will be honored. DCast avoids
such problem by allowing doins to circulate only on established
debt-links.
KARMA [26] and MARCH [30] use a standard virtual currency
system to sustain collaboration, where a peer makes (spends) money
when offering (obtaining) service. Their key feature is to assign
each peer A some random set of other peers as A’s bank to main-
tain A’s balance. Such design is clearly vulnerable to on-the-ﬂy
collusion between A and its bank peers. As explained in Section 1,
since all peers are rational in a game theory context, all peers are
ready to collude and deviate if opportunities arise. Thus such collu-
sion can occur as long as it beneﬁts the bank peers as well.
Finally, bandwidth puzzles [23] aim to address rational collusion
in a general p2p context. In this approach, a trusted veriﬁer ﬁrst
collects information regarding all data transfers among the peers,
and then presents bandwidth puzzles to all peers simultaneously to
verify that each peer indeed has the content that it claims to have.
Despite its name, this approach still needs to assume that the com-
putational power of each peer is roughly the same, otherwise one
peer can help its colluding peers to solve their puzzles. In contrast,
our solution does not need to rely on such a strong and often unre-
alistic assumption. Our design does not need to collect and verify
global information about data transfers either.
3. SYSTEM MODEL AND SAFETY-NET
GUARANTEE
Basic model. A user of the multicast system has one or more identi-
ties (i.e., our model allows sybil attacks), and each identity is called
a peer. During the multicast session, each peer has a (ﬁxed) IP ad-
dress and a (ﬁxed) locally generated public/private key pair. Peers
are identiﬁed by their public keys, and their IP addresses serve only
as a hint to ﬁnd the peers. We do not bind the IP address to the
public key and we allow IP address spooﬁng. The multicast root
is the source of the (signed and erasure-coded) multicast blocks,
which encode application-level data such as video frames. The root
has limited outgoing bandwidth, and can only directly send some
blocks to a small set of peers. Depending on the protocol, the root
may only send a small number of blocks to each peer in this set,
and the set membership may also change over time. The root has a
publicly-known IP address and public key, and always follows our
protocol. The peers and the root have loosely synchronized clocks
with bounded clock errors.
Rational peers and utility. We assume that all peers are ratio-
nal, except a small number of malicious (i.e., byzantine) peers. A
rational peer is selﬁsh and aims to maximize its utility. The util-
ity increases with the number of multicast blocks (i.e., multicast
bits) received, and decreases with the number of non-multicast bits
received and the number of bits sent. To unify terminology, we
call bits sent or non-multicast bits received as cost bits. Cost bits
thus constitute an overhead that a rational peer wants to minimize.3
Usually the beneﬁt of receiving one multicast bit will far exceed the
cost of sending/receiving one cost bit, since it is more important to
get the multicast data than reducing the cost. Except the above, our
discussion and proofs will not depend on the speciﬁc forms of the
utility functions.
A rational peer is a non-deviator if it chooses to follow our pro-
tocol, otherwise it is a deviator. There is no a priori limit on the
number of deviators; after all, every rational peer seeks to maximize
its utility and hence may potentially deviate.
For each deviating peer v, we assume that there exists some “pro-
tocol gaming” constant σv such that drawing on the collusion, v is
now (only) willing to incur one cost bit for every σv multicast bits
received on expectation. Here due to the collusion, σv can be close
to 1, or even above 1 if some other colluding peers are willing to
sacriﬁce for v. Different deviating peers may have different σv val-
ues. Let σ be a constant such that σ ≥ σv for most v’s. Having
this σ constant will be sufﬁcient for us to later reason about the
guaranteed safety-net utility for non-deviators, since those (small
number of) deviating peers whose σv exceeds σ can be no worse
than malicious peers.
Pareto-optimal collusion strategies. We need to properly rule out
irrational deviations when reasoning about rational peers, since oth-
erwise they are no different from byzantine peers. We will apply the
notion of pareto-optimality to do so. A collusion strategy deﬁnes
the set of all the deviators, as well as the strategy adopted by each
3For example, doing so may save the power consumption and
potential data charges of a mobile user. Even for home users
with a ﬂat-rate Internet service, reducing bandwidth consumption
improves the experience of other concurrent users/applications at
home. As discussed in Section 1, such user preference has been
widely observed in previous measurements [1, 24].
569of them. A collusion strategy α is pareto-optimal if there does not
exist another collusion strategy β such that i) the sets of deviators in
α and in β are the same, ii) each deviator has the same or increased
utility under β compared to under α, and iii) at least one deviator
has increased utility under β.
Because the colluding peers are rational, it sufﬁces to consider
only pareto-optimal collusion strategies since it is always better for
them to switch from a non-pareto-optimal strategy to a correspond-
ing pareto-optimal one. On the other hand, also note that there are
many different pareto-optimal collusion strategies. Some of them
may maximize the total utility across all the deviators. Others may
maximize the utility of one speciﬁc deviator while sacriﬁcing the
utilities of all other deviators. One can also imagine a wide range
of strategies in between. We do not make assumptions on which
of these strategies will be adopted by the collusion — rather, our
safety-net guarantee will hold under any pareto-optimal collusion
strategy.
Novel concept of safety-net guarantee. As explained in the exam-
ple from Section 1 regarding colluding peers with low churn, de-
tecting (and preventing) certain deviations is rather difﬁcult if not
impossible in overlay multicast. Fundamentally, this is because the
utility function in multicast involves performance overheads. Un-
less a protocol offers optimal performance for each possible subset
of the peers (without knowing their speciﬁc properties such as low
churn rate), some subset can always proﬁt by deviating and switch-
ing to a more optimized protocol.
With such impossibility, we do not intend to prevent deviation.
Rather, we aim to protect the utility of the non-deviators, by in-
troducing the concept of safety-net guarantee in a game theoretic
context. A safety-net guarantee requires that if a peer A chooses to
stick to the protocol and if all peers are rational, then A should at
least obtain a reasonably good utility (called the safety-net utility),
despite any set of peers deviating from the protocol. Considering
“any” set of peers is necessary here, since all users aim to maximize
their utilities and thus all users are ready to collude or deviate if op-
portunities arise. We do not need to protect the deviators — if a
deviator’s utility is below the safety-net utility, it can always switch
back to being a non-deviator.
The safety-net guarantee provides a lower bound on the utility
of the non-deviators: When most peers do not deviate, the non-
deviators’ utility will likely be higher. One might argue that any
loss of utility due to other peers deviating is unfair to the non-
deviators. However, it would also be unfair to prevent colluding
deviators from beneﬁting from advantageous factors such as low
churn rate among themselves. In some sense, it is the non-deviators
who prevented the system as a whole from using a more efﬁcient
protocol in such cases.
The safety-net guarantee by itself does not guarantee the utility
for a non-deviator if malicious peers aim to bring down its utility.
The need for this limitation is simple: Malicious peers can always
send junk bits to a speciﬁc non-deviator, and drive down that non-
deviator’s utility arbitrarily. Dealing with this kind of targeted DoS
attack is clearly beyond the scope of the safety-net guarantee. Note
however that DCast offers additional properties beyond the safety-
net guarantee, and we will explain later how DCast is robust against
malicious users.
4. DCast DESIGN AND INTUITION
This section discusses the conceptual design and intuition of
DCast, while leaving the protocol level details and formal proofs
to Sections 5 and 6, respectively.
4.1 Design Space Exploration
We start by exploring the design space for effective punishment
in the presence of collusion, which will naturally lead to the key
design features in DCast.
Entry fee as effective punishment. A natural (and perhaps the
simplest) punishment mechanism in the presence of collusion and
sybil/whitewashing attacks is to impose an entry fee on each new
peer. With proper entry fee, evicting a peer will constitute an effec-
tive punishment despite collusion. The key question, however, is
how to design this entry fee and how to evict a peer when needed.
Since overlay multicast needs peers to contribute bandwidth, the
entry fee must be in the form of bandwidth consumption. For ex-
ample, if we instead use computational puzzles, then users with
ample computational resources may still prefer whitewashing over
contributing bandwidth. Using bandwidth consumption as the entry
fee turns out to be tricky. Directly paying this entry fee to the root
would overwhelm the root. Paying this entry fee to individual peers
would enable colluding peers to accept fake entry fees from each
other and vouch for each other. Furthermore, this entry fee must
be in the form of sending junk data since a new peer has no useful
data to send. This means that the individual peers have negative
incentive to accept this entry fee.
Evicting a peer is also tricky under collusion due to the difﬁculty
of disseminating the eviction information to all peers. The collud-
ing peers clearly have incentive to interfere and stall the dissemina-
tion of an eviction notice.
Pairwise entry fees and proﬁtable interactions. One way to over-
come the above difﬁculties is to use pairwise bandwidth entry fees.
Traditional system-wide entry fees admit a peer into the global sys-
tem and entitle it to interact with all peers in any way it wants. With
pairwise bandwidth (entry) fees, a peer sends junk data to some
speciﬁc peers to be allowed to interact with only those peers and
in a limited capacity that is proportional to the fee. Such pairwise
nature prevents a colluding peer from giving other colluding peers
interaction access to non-deviators. It also conveniently enables in-
dividual peers to unilaterally evict a peer, overcoming the previous
difﬁculty of disseminating the eviction information globally.
The system still needs to properly incentivize individual peers
to accept this (junk data) entry fee. One way to do so is to al-
low them to later proﬁt from the interactions with those peers who
paid the entry fee. Such proﬁt hopefully can exceed the cost of
accepting the entry fee. Rather conveniently, a properly designed
proﬁt here can further incentivize colluding peers to interact with
non-deviators, even when the colluding peers may be able to obtain
multicast blocks from each other more efﬁciently.
4.2 DCast Design
DCast essentially instantiates the above ideas of pairwise entry
fees and proﬁtable interactions.
Basic framework. Similar to several recent efforts [9, 14, 15]
on incentivizing overlay multicast, DCast uses standard pull-based
gossiping to disseminate multicast blocks for its simplicity and its
robustness against churn. The multicast session is divided into in-
tervals, and each interval has a ﬁxed number of synchronous gos-
siping rounds (e.g., 30 rounds of 2 seconds long each).
In each
round, the root sends signed and erasure-coded multicast blocks to
a small number of random peers, and all other peers each pull mul-
ticast blocks from another random peer. Before sending a block to
a peer, the root requires the peer to send Droot (e.g., 3) junk blocks
to the root, where each junk block is of the same size as a multicast
block. To avoid delay, the sending of the junk blocks can be done
before the round starts. (Note that these junk blocks are not “entry
570fees” and the number of junk blocks received by the root does not
grow with system size.) Whenever a peer accumulates a sufﬁcient
number of erasure-coded multicast blocks for a given (typically ear-
lier) round, a peer can decode the video frames for that round. If
a peer fails to obtain enough blocks before a certain deadline (e.g.,
20 rounds after the blocks were sent by the root), it will consider
the frames as lost.
DCast allows peers to dynamically join and leave the multicast
session, by contacting the root. The root maintains a list of the
IP addresses of all peers. This list is obviously subject to sybil
attack and we will address that later. To ﬁnd other peers to gossip
with, a peer may periodically request from the root a random view
containing a small number of random IP addresses in the root’s list.
Note that a rational peer has no incentive to repeatedly request a
view since it consumes its own bandwidth as well.
Incentive mechanism: Debt-links and doins. Rational colluding
peers may proﬁtably deviate from the above protocol in many ways.
For example, a colluding peer A can pretend that it has no multicast
blocks to offer when a non-deviator pulls from A. A can also pull
from multiple non-deviators in each round. A user may further
launch a sybil attack to attract more multicast blocks directly from
the root. DCast builds proper incentives into the protocol so that
each such deviation either is not rational or will not bring down the
utilities of the non-deviators below the safety-net utility.
The incentives basically instantiate the ideas of pairwise entry
fees and proﬁtable interactions via the novel design of debt-links
and doins. During the pull-based gossip, the propagation of a mul-
ticast block from one peer A to another peer B is always coupled
with the propagation of a doin on an unoccupied debt-link from
A to B. A debt-link from A to B is established by B sending
Dlink (e.g., 2.5) junk blocks to A. Fundamentally, this debt-link
is a pairwise bandwidth entry fee paid by B. Notice that establish-
ing the debt-link hurts the utility of both A and B. B may estab-
lish multiple debt-links from A, and there may simultaneously exist
debt-links in the reverse direction from B to A. A debt-link is un-
occupied when ﬁrst established. After propagating a doin via that
debt-link, the debt-link becomes occupied until the corresponding
doin is paid.
A doin is a debt and can be issued by any peer. The current holder
of a doin conceptually “owes” the issuer of the doin. Doins may
circulate (i.e., be relayed) in the system and thus can be viewed as
a special kind of bankless virtual currency. All doins issued within
one interval expire at the beginning of the next interval, after which
new doins will be issued. A peer holding an expired doin will pay
for that doin by sending the doin issuer Dpay (e.g., 2) multicast