throw error("bad utf-8 encoding at " + codeName(ch));
}
UTF8是变长编码，有三种格式：
1 byte format: 0xxxxxxx
2 byte format: 110xxxxx 10xxxxxx
3 byte format: 1110xxxx 10xxxxxx 10xxxxxx
上面的代码是对每个字节，通过位运算判断属于哪一种格式，然后分别解析。
优化方式是：通过unsafe将8个字节作为一个long读取，然后通过一次位运
算判断这8个字节是否都是“1 byte format”，如果是（很大概率是，因为常用的
ASCII都是“1 byte format”），则可以将8个字节直接解码返回。以前8次位运
算，现在只需要一次了。如果判断失败，则按老的方式，逐个字节进行解码。主要代
码如下：
private boolean parseUTF8Char_improved() throws IOException {
while (_chunkLength > 0) {
if (_offset >= _length && !readBuffer()) {
return false;
}
int sizeOfBufferedBytes = _length - _offset; int toRead =
sizeOfBufferedBytes > 3;
for (int i = 0; i  9年双11：互联网技术超级工程
}
for (int i = 0; i (Throwable.java:264)
java.lang.Exception.(Exception.java:66)
新基础 (ReflectiveOperationException.
java:56)
java.lang.InstantiationException.(InstantiationException.java:63)
java.lang.Class.newInstance(Class.java:427)
com.taobao.hsf.com.caucho.hessian.io.CollectionDeserializer.
createList(CollectionDeserializer.java:107)
com.taobao.hsf.com.caucho.hessian.io.CollectionDeserializer.
readLengthList(CollectionDeserializer.java:88)
com.taobao.hsf.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.
java:1731)
com.taobao.hsf.com.caucho.hessian.
io.UnsafeDeserializer$ObjectFieldDeserializer.deserialize(UnsafeDeserializer.
java:387)
这是Hessian对UnmodifiableSet反序列化的一个问题，因为Unmodifiable-
Set没有默认构造函数，所以Class.newInstance会抛出，出错之后Hessian会使
用HashSet进行反序列化，所以业务不会报错，但是应用同学反馈每次都处理异常，
对性能影响比较大。
另外Collections$UnmodifiableCollection，Collections$UnmodifiableList，
Collections$UnmodifiableMap， Arrays$ArrayList也有一样的问题。
针对这些构造函数一定会出错的类型，我们修改了Hessian的代码直接跳过构
造函数的逻辑，较少不必要的开销。
重复加载缺失类型
某核心应用压测发现大量线程block在ClassLoader.loadClass方法
"HSFBizProcessor-DEFAULT-7-thread-1107" #3049 daemon prio=10 os_
prio=0 tid=0x00007fd127cad000 nid=0xc29 waiting for monitor entry
[0x00007fd0da2c9000]
java.lang.Thread.State: BLOCKED (on object monitor)
at com.taobao.pandora.boot.loader.LaunchedURLClassLoader.
loadClass(LaunchedURLClassLoader.java:133)
- waiting to lock  (a java.lang.Object)
atjava.lang.ClassLoader.loadClass(ClassLoader.java:380)
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:348)
at com.taobao.hsf.com.caucho.hessian.io.SerializerFactory.
getDeserializer(SerializerFactory.java:681)
排查确认是业务二方包升级，服务端客户端二方包版本不一致，导致老版本的一
176 > 9年双11：互联网技术超级工程
边反复尝试加载对应的新增类型。虽然该问题并没有导致业务错误，但是确严重影响
了性能，按应用同学的反馈，如果每次都尝试加载缺失类型，性能会下降一倍。
针对这种情况，修改hessian代码，将确认加载不到的类型缓存起来，以后就
不再尝试加载了。
优化4： map操作数组化
大型系统里多个模块间经常通过Map来交互信息，互相只需要耦合String类型
的key。常见代码如下：
public static final String key = "mykey";
Map attributeMap = new HashMap();
Object value = attributeMap.get(key);
大量的Map操作也是性能的一大消耗点。HSF今年尝试将Map操作进行了优
化，改进为数组操作，避免了Map操作消耗。新的范例代码如下：
public static final AttributeNamespace ns = AttributeNamespace.
createNamespace("mynamespace");
public static final AttributeKey key = new AttributeKey(ns, "mykey");
DefaultAttributeMap attributeMap = new DefaultAttributeMap(ns, 8);
Object value = attributeMap.get(key);
工作机制简单说明如下：
1. key类型由String改为自定义的AttributeKey，AttributeKey会在初始化阶
段就去AttributeNamespace申请一个固定id
2.map类型由HashMap改为自定义的DefaultAttributeMap，DefaultAt-
tributeMap内部使用数组存放数据
3.操作DefaultAttributeMap直接使用AttributeKey里存放的id作为index访
问数组即可，避免了hash计算等一系列操作。核心就是将之前的字符串key
和一个固定的id对应起来，作为访问数组的index
对比HashMap和DefaultAttributeMap，性能提升约30%。
新基础  9年双11：互联网技术超级工程
小结
架构升级使HSF能够从容的应对未来的挑战，性能优化让我们在调用上追求极
致，运维提升更是将眼光拔高到全局去思考问题，这些改变共同的组成了HSF2.1到
HSF2.2的变革，而这次变革不仅仅是稳定的支撑2017年的双十一，而是开启了服
务框架下一个十年。
新基础 < 179
直击阿里容器技术 Pouch
沈陵
阿里集团内部使用的Pouch容器技术源于2011年开始开发的t4容器，融合了
社区主流容器技术轻量、自洽、一次打包多次运行的优点，专注于稳定性、性能和隔
离性方面的优化，适配了阿里内部的使用场景和开发的使用习惯，是阿里集团内部容
器化、镜像化、混部和统一调度的基石。使用场景已经覆盖了集团大部分的BU的上