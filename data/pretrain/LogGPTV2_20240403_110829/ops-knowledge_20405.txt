User: How can I write a script using Python that iterates through all files and subdirectories in a specified directory and calculates their total size?
Assistant: The following is a script written in Python 3 to traverse all files and subdirectories in a specified directory and calculate their total size: ```python import os # Define a function to recursively traverse a directory and calculate its size def get_directory_size (directory): # initialize variables to record the size of each directory and file total_size = 0 directory_size = 0 file_size = 0 # traverse the directory and calculate the size of each file and subdirectory for root, dirs, files in os.walk(directory) : for name in files: file_path = os.path.join(root, name) file_size += os.path.getsize(file_path) for name in dirs: directory_path = os.path.join(root, name) directory_size += os .path.getsize(directory_path) # Calculate the total size and return the result total_size = directory_size + file_size return total_size # Use example directory = 'C:/Users/your_username/Documents/' total_size = get_directory_size(directory) print('The total size is: {:.2f} MB'.format(total_size / (1024*1024))) ``` In the sample code above, we first define a function named `get_directory_size`, which traverses the directory recursively and Calculate its size. We use the `os.walk` function to walk through all the files and subdirectories in the specified directory. For each file and subdirectory, we use the `os.path.getsize` function to get its size and accumulate it into the corresponding variable. Finally, we calculate the total size and return the result. In the usage example, we specify a directory and pass it to the `get_directory_size` function, then format the return result as a string in MB and print it out. Note that this script may take a long time to complete for very large directories, since traversing directories can take a long time. To avoid memory issues, we accumulate the size of each file and subdirectory into separate variables.