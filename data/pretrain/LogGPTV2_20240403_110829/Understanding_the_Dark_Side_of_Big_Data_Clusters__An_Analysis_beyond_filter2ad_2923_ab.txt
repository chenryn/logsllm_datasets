i.e., roughly accounts for 65% of the
astonishingly high,
2Note that we apply this step only when analyzing submission and schedul-
ing times.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:48:35 UTC from IEEE Xplore.  Restrictions apply. 
TABLE II.
TASK SLOWDOWN, BROKEN DOWN BY PRIORITY.
Metric
percentage of ﬁnish tasks [%]
mean response time (all events) [s]
mean response time (last event) [s]
mean slowdown
0
53.80
2845
1767
3.37
1
67.44
3598
2939
2.58
2
90.78
1835
1782
1.15
3
95.62
9683
8294
3.39
Priority
4
78.05
2006
1890
1.69
5
100
58
58
1
6
77.99
567
562
1.02
8
45.48
1159
1151
1.01
9
23.35
504
496
1.07
total machine time. In particular, the total wasted time due
to eviction, fail, and kill is 20%, 4.5%, and 40.5% of the
total machine time, respectively. This result further stresses
the signiﬁcant negative time impact of unsuccessful executions.
We remind the reader that, in terms of number of events, ﬁnish
is actually the predominant type, followed by fail, as pointed
out in the introduction. However, ﬁnish events only use 35%
of the machine time and fail only causes a small wasted time.
This indicates that ﬁnish events consume little machine time
and that most tasks fail near the beginning of their execution.
Indeed, the average wasted time per ﬁnish, fail, eviction and
kill event is 45, 13, 123 and 107 min, respectively. Kill events
have clearly a strong negative impact on the machine time, as
they consume even more time than that of ﬁnish events.
Moreover, in terms of time breakdown, one can see that
91% of the wasted time is spent while tasks are running on
machines, while queue time and resubmission time account
for only 8% and 1% of the total wasted time, respectively.
Such an uneven distribution can be observed across all event
types, with the slight exception of ﬁnish, where the queue
time has a slightly higher percentage. We explain the low
queueing time by the fact that the cluster is not overloaded –
the average cluster utilization rarely exceedes 50% of machine
resources [6].
1) Average Slowdown per Task: Here, we look at
the
impact of unsuccessful executions on the task performance,
i.e., how much tasks are slowed down by unsuccessful events.
To this end, we consider only tasks with task type ﬁnish,
and compute for them the metric of slowdown, deﬁned as the
response time of all task events divided by the response time
of the last (successful) task event. Note that the response time
is simply the summation of the queue time and the running
time. The proposed slowdown deﬁnition allows us to quantify
the impact of unsuccessful executions on response time and
ignore the effect of queue time, which is the main focus of
existing queueing studies considering failure-free systems.
Table II summarizes our results for this section. As we
compute slowdown only for the ﬁnish task type, we report
in the ﬁrst row of the table the percentage of tasks for each
priority that completes with successful ﬁnish. Note that the
missing values for priorities 7, 10 and 11 indicate that no
ﬁnish tasks can be observed for these priorities in the trace,
i.e., their percentage of ﬁnish tasks is equal to 0. We also
report the mean response times considering both all events
and only the ﬁnal event of all tasks considered. The mean
slowdown reported in the table is obtained by ﬁrst computing
the slowdown of all tasks in each priority and then averaging
their results. Therefore,
the slowdown values presented in
the table are higher than the ones derived from simple back
envelope calculation, i.e., the mean response time of all events
divided by the mean response time of the last event in Table II.
Clearly, priorities 0 and 3 have a very high average
slowdown, around 3.38. Low priorities, i.e., in the range of
[0, 4], are affected by repetitive unsuccessful executions, i.e.,
eviction and fail, that slow down task executions by a factor of
2.44 on average. Higher-priorities, instead, suffer less response
time degradation, with an average slowdown equal to 1.025.
Not considering the priority, the mean slowdown of all the
successful tasks in the trace is 2.04.
Key messages. In terms of total machine time, unsuccessful exe-
cutions account for roughly 65%, particularly dominated by the
running time, whereas successful executions account for only 35%
with a higher percentage of queue time. Unsuccessful executions
not only hamper the success rate of low-priority tasks but also
result in higher slowdown values. In particular, low-priority tasks
are slowed down by unsuccessful executions by an average factor
of 2.44. On average, unsuccessful executions double the task
response time.
B. Spatial Impact: Resource Waste
In this section, our objective is to understand which type
of event consumes the highest amount of resources and which
resource is consumed most by unsuccessful executions. To
quantify the physical resources wasted by unsuccessful exe-
cutions, we propose the metric of resource demand, which is
deﬁned as the product of resources and running time. As tasks
have two types of resource attributes, i.e., requested vs. used,
we consider requested as well as used resource demands in
our analysis.
We deﬁne RES · s as unit of measurement of resource
demand, where RES denotes which resource, i.e., CPU, RAM
and DISK, is considered. As resources are normalized between
[0, 1], the absolute value of demand can also be interpreted as
the interval during which a particular resource supplied by the
largest machine in the cluster is used. For example, 5 RAM ·s
means: “5 seconds of the largest RAM capacity in the system”.
We conduct this analysis on a subset of the original trace,
speciﬁcally we consider all records from day 9 to 16 of the
trace.
We present
the relative values of requested and used
resource demands across all event types in Figure 4. The
resource demand for each event type is normalized by the total
demand for all event types for each resource. For requested
CPU, RAM, and DISK demands, the biggest consuming event
is fail, eviction and fail, respectively, whereas kill always
consumes the least amount of all
three resources. On the
other hand, in terms of used CPU, RAM, and DISK demands,
ﬁnish consumes most of all
three types of resources. An
interesting observation based on these results is that on average
kill requests the least amount of resource demand but actually
uses the highest amount, whereas fail shows the opposite trend.
When considering the resource demands of all unsuccessful
executions and ﬁnish type only, one can see that unsuccessful
210210
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:48:35 UTC from IEEE Xplore.  Restrictions apply. 
]
%
[
100
80
60
40
20
0
]
%
[
100
80
60
40
20
0
26.2
13.9
31.7
28.2
CPU
43.9
23.2
13.7
19.2
CPU
28.8
17.3
23.5
30.4
RAM
Resource
(a) Requested resource demand.
32.7
32.1
14.2
21.0
RAM
Resource
Eviction
Fail
Kill
Finish
Eviction
Fail
Kill
Finish
29.2
17.3
31.0
22.5
DISK
29.2
15.6
29.0
26.2
DISK
(b) Used resource demand.
Fig. 4. Resource demand distribution per event type.
events waste more than half of the total requested and used
resource demand. In particular, wasted used CPU, RAM and
DISK demands are roughly 56%, 67%, 70% of the total
used demands, and the percentages are even higher when
considering requested resource demands, being equal to 74%,
71%, and 71%, respectively. A possible explanation for the
higher percentage of wasted memory and disk than CPU
demand is that RAM and DISK are more limited by the
constraint of space capacity, i.e., the lower degree of multiplex
levels [17].
Key messages. Unsuccessful executions waste a signiﬁcant
amount of resource demands, i.e., 72% of total requested demand
and nearly 65% of total used demand, in particular DISK. Among
all unsuccessful executions, kill requests the least amount of
resource demand and uses the most, whereas fail shows the
opposite trend.
IV. PATTERNS AND MODELS FOR TASK AND JOB EVENTS
Understanding the patterns of different unsuccessful exe-
cutions in complex big-data clusters is the ﬁrst step towards
better system design. For example, it can improve the tail-
aware scheduling policy [1], [4], eviction policy [18], and also
mitigate the resource waste. However, it is not easy to capture
the key characteristics of unsuccessful executions, especially
at the job level, because of intricate task-job dependencies,
multiple tasks per job and multiple events per task.
In this section, our objective is to identify not only patterns
but also predictive models for ﬁnish, kill, eviction, and fail
types at the event, task and job level. Our analysis starts from
the task level statistics in Section IV-A, followed by the job
level statistics in Section IV-B and the predictive analysis of
unsuccessful job types in Section IV-C.
A. Unsuccessful Tasks
As tasks can experience multiple events prior to exiting
the system, understanding the event patterns that lead tasks
to being classiﬁed as ﬁnish, kill,
is of
fail and eviction,
TABLE III.
MEAN NUMBER OF EVENTS AND THEIR DISTRIBUTION PER
TASK TYPE.
Task type
Eviction
Fail
Kill
Finish
Overall
(95th p.)
2.372 (5)
3.130 (8)
2.516 (4)
1.094 (1)
Mean number of events
Eviction
Kill
Fail
2.094
0.350
0.302
0.061
0.259
2.700
1.175
0.008
0.004
0.020
1.023
0.011
Finish
0.015
0.060
0.016
1.014
0.8
0.6
0.4
0.2
s
s
e
c
c
u
s
f
o
y
t
i
l
i
b
a
b
o
r
P
0
0
Eviction
Fail
Kill
5
10
15
Number of events
20
25
30
Fig. 5. Conditional probability of task success given a number of speciﬁc
unsuccessful events observed, i.e., eviction, fail and kill.
paramount importance for providing insights on how to mit-
igate unsuccessful executions and improve the task success
rate. The particular questions addressed here are: (1) how are
unsuccessful executions distributed across different task types,
and (2) what is a suitable predictive model for capturing the
probability of task success?
1) Events Distribution: To capture the distribution of event
types at the task level, we ﬁrst obtain the number of events
experienced by each task and present the average values across
tasks of the same type in Table III. Taking the task type
eviction as an example, one can read from the table that
tasks leaving the system with an eviction experience 2.372
events on average, 2.094 of which are eviction events, whereas
the others are of different type. As ﬁrst observation, one can
easily see that
tasks indeed experience multiple events of
different types. Secondly, the ﬁnish tasks go through a lower
number of events, the majority of which being ﬁnish events.
The situation is opposite for unsuccessful tasks, meaning that
tasks experiencing at least one unsuccessful execution rarely
get to complete at the end. In particular, fail and eviction
tasks are also dominated by the same type of events, meaning
that tasks eventually fail and are evicted after experiencing
consecutive fail and eviction events. This is also supported
by the slowdown analysis conducted previously. In contrast to
other task types, kill tasks are not dominated by kill events,
i.e., they experience 1.023 kill and 1.175 fail events, out of an
average of 2.516 events per task.
In addition to the mean number of events, we also include
the 95th percentile of the number of events per task,
to
highlight its heavy-tailed characteristics, i.e., some tasks have
a high number of events, particularly unsuccessful tasks. As
a result, one can see that values of the 95th percentile for all
unsuccessful types are higher than the average value, especially
for fail tasks. Indeed, the maximum number of eviction events
observed is 828 for a single task, whereas for fail this amount
is equal to 40393.
2) Conditional Probability of Task Success: Motivated
by the observations highlighted previously, i.e., (1) that task
211211
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:48:35 UTC from IEEE Xplore.  Restrictions apply. 
types are being dominated by the majority of event types,
and (2) that repetitive patterns exist in unsuccessful events,
we propose to quantitatively capture the probability of task
success conditioned on a given number of unsuccessful events
observed.
Figure 5 depicts the conditional probability that a task can
ﬁnish successfully, given that a number of unsuccessful events
of a particular type is observed. One can clearly see that the
probability of success monotonically decreases with increasing
numbers of eviction and fail events observed. This decreasing
trend is stronger for fail than for eviction events, indicated by
a steeper decay for fail and a longer tail for eviction. This
observation implies that fail events reduce the probability of
success much more than eviction events do: tasks experiencing
15 eviction events can still have probability 0.1 to ﬁnish
successfully, whereas 15 fail events bring this probability very
close to 0. As fail and eviction events occur repeatedly on
single tasks, the scheduler could take an aggressive action to
prohibit execution of tasks that already experienced a high
number of fail (particularly) and eviction events. Such an
action would minimize the machine time and resource waste,
as these tasks will eventually complete successfully only with
very low probability.