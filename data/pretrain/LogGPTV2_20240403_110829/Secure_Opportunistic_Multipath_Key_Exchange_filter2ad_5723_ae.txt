### Figure 13: CDF of Connection Setup Time, RTT=0.2ms

- 512
- 1024
- 2048
- 4096
- 8192
- 16384
- 32768

**File Size (bytes)**

### Figure 14: Data Transfer Duration Using SMKEX Over Trans-Atlantic Tunnels

To run SMKEX, our library implementation first opens an MPTCP connection and uses an MPTCP API (from Hesmans et al. [23]) that blocks until the specified number of subflows is created. If the connection falls back to regular TCP, the SMKEX handshake fails. Similarly, if the desired number of subflows is not created within a predefined amount of time, the handshake also fails.

Once the MPTCP connection has enough active subflows (two by default), SMKEX can start the handshake. However, if we simply send SMKEX messages using the sockets API provided by default by MPTCP, there is no control over which subflow will carry the handshake data. In most cases, all messages will be delivered by the first subflow, which would compromise the security of SMKEX, making it vulnerable to man-in-the-middle (MITM) attacks.

To address this, we made two changes to the MPTCP Linux kernel implementation:
1. The `send` syscall now allows specifying which subflow must carry the provided application data.
2. The `receive` syscall now allows specifying which subflow to receive data from. If data is received on a different subflow than expected, the `recv` call returns a specific error code, indicating which subflow the library should read data from.

To avoid changing the syscall API, our implementation reuses an unused byte in the flags parameter to specify the desired subflow in the `send` and `recv` calls.

Finally, we use the fullmesh MPTCP path manager, which, by default, creates one subflow for each interface. For example, a mobile client will create two subflows to the server, one on cellular and one on Wi-Fi.

### CDN Integration

We target two deployment scenarios, both involving a server and a mobile client supporting SMKEX running over MPTCP:
1. **Scenario 1 (Figure 5):** The MPTCP subflows are terminated at the server.
2. **Scenario 2 (Figure 12):** The two subflows do not reach the same server, and an additional mechanism is required to direct the secondary MPTCP subflows to the appropriate server. This scenario provides the best path diversity and is the preferred one for SMKEX.

#### Routing Client Traffic to Nearby Edge Servers

CDNs use one of two approaches to route client traffic to nearby edge servers:
- **DNS Redirection:** The client's location is used to select a local replica.
- **IP Anycast:** All edge servers advertise the same IP address, and Internet routing directs clients to their closest servers.

In this paper, we assume the edge servers rely on IP anycast, a solution used by many CDNs, including the Microsoft CDN [21].

Consider the example in Figure 12, where the service address A is advertised in BGP by both edge servers. When the MPTCP connection starts over the cellular interface, its first subflow will be handled by edge server 1, which is closest to the client (in terms of routing hops). Edge server 1 will serve content from its local cache or contact the origin server if the required content is not cached. When the client opens its wireless subflow, the resulting subflow will reach edge server 2. The remaining problem is that edge server 2 must forward the subflow to edge server 1 over the CDN’s internal network.

To achieve this, we use Beamer [40], a load balancer that supports MPTCP. The CDN assigns a unique numeric identifier to each of its edge servers. When the first subflow is set up to edge server 1, the edge server will inform the client of its unique identifier. The client includes this identifier in the second subflow, which reaches edge server 2. Edge server 2 then proxies the connection to edge server 1.

On-path attackers can modify the connection ID, but the only effect is that the secondary subflows will be rerouted incorrectly in the CDN network, causing the SMKEX handshake to fail.

### Practicality of SMKEX

While SMKEX relies on CDNs and popular websites to update their infrastructure to ensure the highest security possible, MPTCP deployment requires similar changes: an MPTCP-enabled kernel and a load balancer. We believe such deployment is feasible because load balancers are already widely deployed in production [18, 36, 41], and MPTCP is already widely deployed on mobile clients.

## 9. Evaluation

Our evaluation aims to test the correctness of our implementation and its behavior in practice. We conducted tests on our local testbed and using Amazon EC2 to create wide-area path diversity.

### Testbed Experiments

In our first experiment, the client and server ran on two quad-core Xeon machines connected via two Gigabit links, emulating different paths. The client repeatedly set up an encrypted connection to the server, and we measured the time it took to perform the connection handshake. Figure 13 shows the CDF of connection setup times for SMKEX compared to standard Diffie-Hellman. In the median, SMKEX takes about 50µs more than standard Diffie-Hellman, due to the additional round-trip time required by our MPTCP-based implementation. MPTCP sets up the second subflow only after the first subflow is established.

### Amazon EC2 Experiments

To test our path diversity setup, we rented two VMs in two EC2 data centers on the east coast (Virginia and Ohio). One VM terminated a long-term client tunnel, offering path diversity, while the other VM emulated an edge CDN server. Our server and client were close to each other (5ms RTT), but they also set up a path via the USA using long-term OpenVPN tunnels to one of the Amazon VMs. The client repeatedly downloaded files of different sizes from the server. In Figure 14, we plot the total download time. The measured latencies were as follows: the long path had an RTT of 280ms (crossing the Atlantic four times), and the short path had an RTT of 5ms.

For small files, the expected download latency should be dominated by the long path RTT: our implementation requires two RTTs over this path, one to set up the MPTCP subflow and one to perform the key exchange. After the key is set up, the server sends all data via the low-latency path. The experiments confirmed this hypothesis, with the latency around 650ms for all file sizes tested. The file size had little influence on the download because the local, high-speed (50Mbps) link was used for data transfer.

## 10. Extensions of SMKEX

Due to its simplicity, SMKEX can be easily extended to increase the security of TOFU or TLS-like protocols. In the previous sections, we focused on the basic version of SMKEX, which provides the highest degree of usability. As Unger et al. [49] write, “defending against mass surveillance requires a communication system that virtually all users can successfully use. Thus, it may be wise to start from the basic user experience of today’s widely deployed communication apps and try to add as much security as possible...”. In this section, we show two possible enhancements of SMKEX: (a) TOFU enhancement; (b) TLS integration. In §C.3, we also discuss the possibility of using double ratcheting to provide forward and backward secrecy even across messages from a single session. These extensions are shown informally, with the goal of demonstrating how SMKEX can be used in various scenarios. A formal analysis and implementation of these extensions are left for future work.

### 10.1 TOFU Enhancement

SMKEX can be enhanced by using a Trust-on-First-Use (TOFU) approach, increasing the security of applications that rely on TOFU authentication, such as SSH or websites using self-signed certificates.

This can be achieved by having the server use a long-term public/private key pair, which is stored by clients and used together with the server’s ephemeral public key to derive the session key. If we let \( X = g^x \) be the ephemeral public key of the client (with corresponding private key \( x \)), \( Y = g^\alpha \) be the ephemeral public key of the server (with private key \( \alpha \)), and \( LS = g^{ls} \) be the long-term public key (with corresponding private key \( ls \)), then the client can send as input to the key derivation the concatenation of \( Y^x \) and \( S \), while the server would use \( X^\alpha \) and \( X^{ls} \). A similar approach, requiring the client to also use a long-term key, is used in Signal [46], known as triple Diffie-Hellman, possibly inspired by Protocol 4 of Blake-Wilson et al. [5]. A similar protocol has also been proposed and analyzed by Krawczyk and Wee [30].

A depiction of our modified protocol with the server using a long-term key is shown in Figure 15. As mentioned by Wendlandt et al. [50], existing TOFU protocols suffer from two main issues: a) possible active attacks during the first connection; b) possible active attacks during an update of the server’s long-term key. With our TOFU-based SMKEX protocol, such attacks are no longer possible in the A/A and A-P scenarios. Therefore, by storing and checking the server’s long-term public key, our TOFU-based SMKEX protocol provides partial protection against active adversaries (i.e., A/A and A-P) during initial setup and during server key update, while providing protection even against A-A adversaries if these are not able to synchronize during the initial key setup (or key update).

The main disadvantage of TOFU-based approaches (including this extension of SMKEX) is that when long-term keys change (either genuinely or due to an attack), the client is forced to either: a) drop the connection (if we want no user interaction) or b) ask the user what to do in this case (which might hinder usability). Nevertheless, given that previous TOFU-based methods provided the highest security for opportunistic encryption (see the survey of Unger et al. [49, Table I]) and that SMKEX also increases the security of TOFU approaches, we can conclude that using a TOFU-enhanced SMKEX protocol provides the highest security for opportunistic encryption to date.

### 10.2 Integration into TLS

We can also easily integrate SMKEX with TLS, obtaining a combined protocol (which we call MTLS) that provides increased security over TLS while retaining all the security benefits of the classic single-path TLS. This extension benefits TLS security in two ways:
1. It provides improved opportunistic security to unauthenticated TLS, as described in [44, Section C.5].
2. It works as an additional barrier in case of Certificate Authority (CA) attacks, as described below.

Several attacks on TLS have exploited problems with CAs: some have issued certificates to invalid parties [33], some have been attacked and rogue certificates issued [17, 20], checking revoked certificates is difficult [35], and many share their secret keys with possibly less-secure partners [7]. Privacy issues also arise when large institutions monitor employees with the help of fake certificates installed in browsers. Finally, governments might force their ISPs and local CAs to collaborate and trick users into using rogue certificates. By combining SMKEX with TLS, we can thwart such attacks.

Table 3 compares the security features of SMKEX, TLS, and MTLS for different attackers (A-P, A/A, A-A) and scenarios (authentic and rogue certificates).

We illustrate our design using TLS 1.3. SMKEX is supported with the (EC)DHE exchange mode and the PSK with (EC)DHE key exchange mode. Accordingly, we assume that the client and server exchange some form of Diffie-Hellman public key shares \( g^x \) and \( g^\alpha \) (finite-field or elliptic curves). We only improve the security of the server authentication portion of TLS; client authentication and other key exchange extensions downgrade to the single-path case.

Figure 16 illustrates the MTLS key exchange. The standard TLS key exchange runs on the first path, with two modifications. First, the Client Hello message indicates in an extension that MTLS is used, and the ClientHello.random \( NC \) in this message, as well as the ServerHello.random \( NS \) in the response, are dropped. MTLS introduces two new messages on the second path. The client sends \( NC \), and the server responds with \( NS \) as well as a hash of \( NC \), \( NS \), \( g^x \), and \( g^\alpha \).

MTLS provides all the security of a standard TLS exchange, with added protection against attackers that forge the server’s long-term secret. For example, in the case of a forged certificate, an attacker that is only present on the first path is unable to successfully complete the key exchange with the client. The verification of the hash fails at the client, and the key exchange terminates immediately.

More precisely, MTLS provides security against all attackers for which the test session is either fresh according to the original definition or for which the attacker cannot synchronize across multiple paths.