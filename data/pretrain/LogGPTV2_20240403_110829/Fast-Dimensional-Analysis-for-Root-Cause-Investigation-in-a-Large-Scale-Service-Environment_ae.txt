5.4 	SSH Logs
We deployed the fast dimensional analysis framework on a dataset containing logs for SSH connec-tions to identify what causes some of the connections to fail. We passed a number of attributes from this dataset, such as the source server type, destination server type, and SSH method, in order to find out root cause connection failures. The report is exported to a dashboard for the engineers to continuously monitor the correlated rules, and to quickly identify and fix anomalous behaviors.Proc. ACM Meas. Anal. Comput. Syst., Vol. 4, No. 2, Article 31. Publication date: June 2020.
Fast Dimensional Analysis for Root Cause Investigation 	31:21Figure 8 shows the number of association rules reported for different min-lift values. An actionable rule {service, geographical location, SSH method} ⇒ session failure appears when min-lift becomes lower than approximately 88000. Note that even though the support of this rule is only 0.1, this rule is still very actionable because the dataset is complex and contains multiple types of failures at the same time. In other words, this example demonstrates how low-support rules can help us continuously improve the system as long as the lift is high, when our goal is not limited to investigating an urgent, major issue in the application.15
5
0
Number of association rules 
	10
20000 	40000 	60000 	80000 	100000
Min-lift
Fig. 8. Number of association rules at different min-lift thresholds based on the SSH dataset. The triangle
marks when a target rule appears in the use case.
6 	CONCLUSIONS AND FUTURE WORKSIn this paper we have explored the problem of root cause analysis on structured logs and we have presented our scalable approach based on frequent item-set mining. We have also discussed a key change to support and motivation for lift, which are important frequent item-set metrics for our use case. Furthermore, we presented various optimizations to the core Apriori and FP-Growth frequent item-set algorithms including parallelism and pre- and post-processing methods. To our knowledge, this is the first work that utilizes frequent item-set paradigm at the scale of a large internet company for root cause analysis on structured logs.In addition to the use cases described in Section 5, we are exploring the use of the RCA framework on free-form text reports. To utilize RCA to surface features for different topics, the text reports first need to be labeled with topics. Both supervised [31] and unsupervised methods [7] can be applied for labeling the topics. An advantage of supervised model is that we can easily measure the quality of the inference and the topics are interpretable; however, it requires labeled data for training. Unsupervised approach does not require labeled data but the topics are often less interpretable, e.g. each topic is often represented by top keywords [26] and it is unclear how to measure the quality of the topic inference because there is no ground truth.Given the topic labels, we can apply RCA on the text reports. As a result, RCA could detect significant features relevant to the labeled topics in the text corpus. For example, “reinforcement learning” and “speech recognition“ topics were extracted from a corpus of NIPS research papers [26] and potentially we can surface some features (e.g. publish year) relevant to the topics. This is very useful for humans as it provides starting points for further investigation (e.g. why are a set of features prevalent within a specific topic?).As part of our future work we aim to focus on temporal analysis and on gathering more continu-ous feedback. Specifically, for temporal analysis, we are working on understanding the trend of
Proc. ACM Meas. Anal. Comput. Syst., Vol. 4, No. 2, Article 31. Publication date: June 2020.
31:22 	Lin, et al.
Text Reports
Supervised NLP Model 
for Topic Classification
Text Reports with Topic LabelsText Reports with Topic Labels
Fig. 9. Flow of RCA on text-based reports.
association rules seen over time to discover seasonality and longer-term trends in order to catch degradation of services or hardware failures quicker. To overcome the lack of labels, we will focus on continuous feedback by leveraging our production system to understand which findings are more or less relevant to engineers in order to learn which findings to promote and which findings need to be hidden.A 	AUTHOR RESPONSE FOR ONE-SHOT REVISION
Authors need to compare their work with other similar techniques, and would benefit from a more
rigorous comparison with state-of-the-arts techniques. Provide a stronger related work section and
better evaluation of their work in the context of root cause analysis and, more in general, data mining. 	The authors address the above requirements as follows.• A rigorous discussion about the state-of-the-art RCA work is added in Section 2.3, where we point out the fundamental differences between our proposed work and the rest of the papers. 	A comparison with the STUCCO algorithm is also added to Section 3.7.
• Section 4.1.1 is added to demonstrate how our unique data pre-aggregation step is necessary for enabling an RCA framework at our scale.• We made clearer references in Section 4 to show how the experimental results we present compare our framework with the other related works.
tune the criteria with the tolerance multipliers in practice. This further explains the effort• We included Hsupp and Hlif t in the filtering criteria in Section 3.6 to demonstrate how we needed to deploy the framework in production.• We fixed a few formatting issues in the references (some of them are online resources, for which URLs are provided).
REFERENCES
[1] Lior Abraham, John Allen, Oleksandr Barykin, Vinayak Borkar, Bhuwan Chopra, Ciprian Gerea, Dan Merl, Josh Metzler, David Reiss, Subbu Subramanian, Janet Wiener, and Okay Zed. 2013. Scuba: Diving into Data at Facebook. In International Conference on Very Large Data Bases (VLDB).[2] R. Agrawal, T. Imielinski, and A. Swami. 1993. Mining association rules between sets of items in large databases. In 	ACM SIGMOD International Conference on Management of Data.
[3] Dea Delvia Arifin, Shaufiah, and Moch. Arif Bijaksana. 2016. Enhancing spam detection on mobile phone Short Message Service (SMS) performance using FP-growth and Naive Bayes Classifier. In IEEE Asia Pacific Conference on Wireless and Mobile (APWiMob).[4] S.D. Bay and M.J. Pazzani. 1999. Detecting change in categorical data: mining contrast sets. In ACM SIGKDD International 	Conference on Knowledge Discovery and Data Mining.
Proc. ACM Meas. Anal. Comput. Syst., Vol. 4, No. 2, Article 31. Publication date: June 2020.
Fast Dimensional Analysis for Root Cause Investigation 	31:23[5] S.D. Bay and M.J. Pazzani. 2001. Detecting group differences: mining contrast sets. Data Mining and Knowledge 	Discovery 5, 3 (2001).
[6] Ran M. Bittmann, Philippe Nemery, Xingtian Shi, Michael Kemelmakher, and Mengjiao Wang. 2018. Frequent Item-set 	Mining without Ubiquitous Items. In arXiv:1803.11105 [cs.DS].
[7] David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. Journal of machine Learning 	research 3 (Jan 2003), 993–1022.[8] Dhruba Borthakur. 2019. HDFS Architecture Guide. [9] Eric Boutin, Jaliya Ekanayake, Wei Lin, Bing Shi, , Jinu. 2014.
Apollo: Scalable and Coordinated Scheduling for Cloud-Scale Computing. In USENIX Symposium on Operating Systems Design and Implementation.
[10] Sergey Brin, Rajeev Motwani, Jeffrey D. Ullman, and Shalom Tsur. 1997. Dynamic itemset counting and implication 	rules for market basket data. In ACM SIGMOD International Conference on Management of Data.[11] Marco Castelluccio, Carlo Sansone, Luisa Verdoliva, and Giovanni Poggi. 2017. Automatically analyzing groups of 	crashes for finding correlations. In ESEC/FSE Joint Meeting on Foundations of Software Engineering.
[12] Albert Greenberg, James Hamilton, David A. Maltz, and Parveen Patel. 2009. The Cost of a Cloud: Research Problems 	in Data Center Networks. In ACM SIGCOMM Computer Communication Review.[13] Jiawei Han, Jian Pei, , and Yiwen Yin. 2000. Mining Frequent Patterns Without Candidate Generation. In ACM SIGMOD 	International Conference on Management of Data.
[14] David Harris and Sarah Harris. 2012. Digital design and computer architecture (second ed.). Morgan Kaufmann. [15] Benjamin Hindman, Andy Konwinski, Matei Zaharia, Ali Ghodsi, Anthony D. Joseph, Randy Katz, Scott Shenker, and 	Ion Stoica. 2011. Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center. In USENIX conference on 	Networked systems design and implementation.[16] M. Isard. 2007. Autopilot: Automatic Data Center Management. In ACM SIGOPS Operating System Review. [17] Fan (Fred) Lin, Matt Beadon, Harish Dattatraya Dixit, Gautham Vunnam, Amol Desai, and Sriram Sankar. 2018.
	Hardware Remediation At Scale. In IEEE/IFIP International Conference on Dependable Systems and Networks Workshops. [18] Ruilin Liu, Kai Yang, Yanjia Sun, Tao Quan, and Jin Yang. 2016. Spark-based rare association rule mining for big 	datasets. In IEEE International Conference on Big Data (Big Data).[19] MySQL. 2019. MySQL Customer: Facebook. 
[20] Suriadi Suriadi, Chun Ouyang, Wil M. P. van dt Cause Analysis with 	Enriched Process Logs. In International Conference on Business Process Management, Vol. 132. Springer.
[21] Ashish Thusoo, Joydeep Sen Sarma, Namit Jain, Zheng Shao, Prasad Chakka, Ning Zhang, Suresh Antony, and Hao Liuand Raghotham Murthy. 2010. Hive - A Petabyte Scale Data Warehouse Using Hadoop. In IEEE International Conference on Data Engineering (ICDE).[22] Martin Traverso. 2013. Presto: Interacting with petabytes of data at Facebook. 	
[23] t Evans, Thomas 	Graves, Jason Lowe, Hitesh Shah, Siddharth Seth, Bikas Saha, Carlo Curino, Owen O’Malley, Sanjay Radia, Benjamin 	Reed, and Eric Baldeschwieler. 2013. Apache Hadoop YARN: Yet Another Resource Negotiator. In ACM Symposium on 	Cloud Computing.[24] A. Verma, L. Pedrosa, M. Korupolu, D. Oppenheimer, E. Tune, and J. Wilkes. 2015. Large-scale Cluster Management At 	Google with Borg. In European Conference on Computer Systems (EuroSys).
[25] Bowei Wang, Dan Chen, Benyun Shi, Jindong Zhang, Yifu Duan, Jingying Chen, and Ruimin Hu. 2017. Comprehensive Association Rules Mining of Health Examination Data with an Extended FP-Growth Method. In Mobile Networks and Applications.[26] Xuerui Wang, Andrew McCallum, and Xing Wei. 2007. Topical n-grams: Phrase and topic discovery, with an application 	to information retrieval. In IEEE International Conference on Data Mining (ICDM 2007). 697–702.
[27] Ian H. Witten, Eibe Frank, Mark A. Hall, and Christopher J. Pal. 2017. Data Mining: Practical Machine Learning Tools 	and Techniques (fourth ed.). Morgan Kaufmann.[28] Tzu-Tsung Wong and Kuo-Lung Tseng. 2005. Mining negative contrast sets from data with discrete attributes. In 	Expert Systems with Applications.
[29] Kenny Yu and Chunqiang (CQ) Tang. 2019. Efficient, reliable cluster management at scale with Tupperware. 	
[30] i Liu, Wenhao Jiang, Junfang Zeng, and Rui Wang. 2018.Network Alarm Flood Pattern Mining Algorithm Based on Multi-dimensional Association. In ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems (MSWIM).
[31] Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015. Character-level convolutional networks for text classification. In 	Advances in neural information processing systems. 649–657.Proc. ACM Meas. Anal. Comput. Syst., Vol. 4, No. 2, Article 31. Publication date: June 2020.
31:24 	Lin, et al.
[32] Zhuo Zhang, Chao Li, Yangyu Tao, Renyu Yang, Hong Tang, and Jie Xu. 2014. Fuxi: a Fault-Tolerant Resource
Management and Job Scheduling System at Internet Scale. In International Conference on Very Large Data Bases (VLDB).
Received January 2020; revised February 2020; accepted March 2020Proc. ACM Meas. Anal. Comput. Syst., Vol. 4, No. 2, Article 31. Publication date: June 2020.