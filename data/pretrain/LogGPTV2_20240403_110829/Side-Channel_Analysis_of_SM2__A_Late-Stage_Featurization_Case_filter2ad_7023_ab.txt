Brumley and Tuveri [21] present another end-to-end remote tim-
ing attack: it similarly demonstrates full key recovery in local and
remote scenarios, and targets the OpenSSL Montgomery’s ladder
implementation for scalar multiplication on elliptic curves over
binary fields. The Montgomery ladder algorithm is often recom-
mended as a countermeasure to side-channel attacks due to a fixed
sequence of curve operations, that does not depend on the values
of individual bits in the secret scalar, while still being computation-
ally fast with no large memory overhead. Nonetheless, the attack
exploits exactly the regularity feature of the algorithm, as it creates
a direct linear correlation between the binary logarithm (i.e. the bit
length) of the secret scalar and the number of iterations (and thus
curve operations) in the ladder.
The authors exploit this vulnerability by mounting an attack
that collects several measures of the wall-clock execution time of
a partial TLS handshake, using an ECDHE_ECDSA ciphersuite over
a binary curve. The collected measures are heavily dominated by
the EC scalar multiplication of the ECDSA signature generation,
implemented using the Montgomery ladder, and thus can be directly
correlated with the bit length of the secret scalar (the ephemeral
nonce of the ECDSA signature generation algorithm). A second,
offline, post-processing phase then uses this partial knowledge to
recover the full secret key through a lattice attack.
The proposed countermeasure, adopted by OpenSSL, is based on
conditionally padding the nonce before the actual scalar multipli-
cation, to always work on scalars of fixed length (i.e. adding once
or twice the group order to the scalar yields an equivalent scalar
with the topmost bit set) which in turn fixes the number of curve
operations in the ladder and the associated execution time.9
Timing measurement noise heavily affects the success rate of
the described attacks, usually resulting in the attacks being unfea-
sible over a wireless link and having severely limited feasibility
over a WAN connection due to both decreased accuracy and the
total time of the attacks (which is generally further increased to
compensate the noise by collecting more samples). However, more
recent results [32] address the latter scenario, studying the statis-
tical distribution of latency over different network environments
and designing specialized filters to significantly reduce the effect of
jitter (i.e. the random noise on the latency introduced by additional
hops in the route(s) of a network connection). These filters allow
attackers to measure events with higher accuracy over the Internet,
with potential effects on the feasibility of remote timing attacks
over WAN connections.
Timing as a side-channel is not limited to the execution time of
a whole cryptographic operation, and is often a gateway to retrieve
9To track the issue uncovered by this work the id CVE-2011-1945 was assigned and
CERT issued the vulnerability note VU#536044.
information from other resources shared between an attacker and
a victim, including microarchitecture components, as in the cache-
timing attacks covered below or, switching to the domain of web
privacy, even virtual constructs in modern web browsers [71, 72].
Alternatively, the timing side-channel can be used to build reli-
able oracles, often circumventing trivial implementations of coun-
termeasures to prevent other side-channel attacks. In 1998, Ble-
ichenbacher [16] presented a famous adaptive chosen-ciphertext
attack on SSL/TLS ciphersuites based on RSA and PKCS#1 v1.5
encryption padding, based on an oracle built on top of different
error messages sent by servers in case of malformed ciphertexts
during the SSL/TLS handshake. As a result of the work, subsequent
specifications of the TLS protocol (starting from RFC 2246 [33] TLS
1.0, in the same year) recommend “to treat incorrectly formatted
messages in a manner indistinguishable from correctly formatted
RSA blocks”. But when implementations fail to extend this recom-
mendation to the execution time of handling different events and
conditions, the timing side-channel can be used to build an alterna-
tive oracle, effective for remote exploitation, as presented in 2014
by Meyer et al. [56]. Their work targeted, among others, the default
Java Secure Socket Extension (JSSE) and OpenSSL implementations
of the SSL/TLS protocol.
2.3 Cache Timing Attacks
Cache-timing attacks are a subset of microarchitecture attacks
targeting specifically the cache hierarchy. Cache-timing attacks
against implementations of cryptography primitives exploit two
key features: (1) the timing variation introduced by the cache hi-
erarchy; and (2) the non-constant time execution of algorithms
handling confidential data used by cryptography primitives and
algorithms, e.g. key generation [8, 73], digital signatures [11, 65],
encryption [12] and key exchange [39]. Typically, the ultimate goal
of a cache-timing attack is to recover confidential information from
an algorithm execution and this is done by correlating cache timing
data to either the execution time of the algorithm in use, its internal
state during execution, or the output of the algorithm. Cache-timing
attacks are enabled by several cache attack techniques proposed
and used successfully in the past, e.g. Evict+Time [63], Prime+Pro-
be [64], and Flush+Reload [75]. The choice of attack technique
depends on the attack scenario since each technique has its own
advantages and disadvantages.
Cache Architecture. Accessing data and instructions from main
memory is not an instant operation since it takes time to locate
and fetch the data, thus delaying the execution of the processor.
To improve the efficiency of the processor, the memory hierarchy
includes memory banks called caches, located between the CPU
cores and the RAM. Caches are smaller and faster compared to
RAM and main memory, helping to improve the performance by
exploiting spacial and temporal locality during memory access.
Modern CPUs contain multiple cache levels, usually L1 and L2
caches are private to a specific core and the last level cache (LLC)
is shared among all the cores. Typically, the LLC is said to be inclu-
sive, meaning that it contains a superset of the data in the caches
below it, thus it contains both instructions and data from L1 and
L2. The caches are organized into fixed size cache lines which are
grouped in cache sets. The number of cache lines in a cache set is
149ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Nicola Tuveri, Sohaib ul Hassan, Cesar Pereida García, and Billy Bob Brumley
the associativity, i.e., a cache with W lines in each set is a W-way
set-associative cache.
When the CPU needs to fetch data from memory, it first checks
in the caches; if the data is there, a cache hit occurs and the load
delay is short. On the other hand, when the data is not found in
the caches, a cache miss occurs and the data must be fetched from
a higher level memory, causing a longer delay. A copy of the data
fetched from a higher level is cached, exploiting temporal locality.
In addition, data close to the accessed data will be fetched and
cached too, exploiting spatial locality. If a cache miss occurs and all
the cache lines are in use, one of the cache lines is evicted, freeing
space for the new data. In order to determine the cache line to
evict, modern CPUs use variations of the least-recently-used (LRU)
replacement policy.
Flush+Reload. Proposed by Yarom and Falkner [75], this powerful
technique positively identifies accesses to specific memory lines
with a high resolution, high accuracy, and high signal-to-noise ratio.
Moreover, the technique relies on cache sharing between the CPU
cores, typically achieved through the use of shared libraries.
A round of attack consists of three phases: (1) the attacker evicts
the target memory line using the clflush instruction; (2) the at-
tacker waits some time for the victim to access the memory line; (3)
the attacker measures the time it takes to reload the memory line.
The timing reveals whether or not the memory line was accessed
by the victim during the waiting period, i.e. identifies cache hits
and cache misses.
In addition to cache-timing attacks on cryptography, the Flu-
sh+Reload technique has been applied in clever ways targeting
the kernel [45], web server function calls [77], user input [42, 51],
covert channels [55], as well as more powerful microarchitecture
attacks such as the Meltdown [52] and Spectre [48] attacks.
2.4 EM Analysis
Introduced by Kocher et al. [50], power analysis exploits the corre-
lation between sensitive data and changing power leakages on the
device. These power fluctuations are a result of transistor switching
between the logic levels of CMOS circuits, and the current flow on
data lines, as a result of processor activity and memory accesses.
Due to the tightly packaged components on modern devices,
power analysis can be difficult to perform with limited or no access
to power rails and only noisy global power consumption. As an al-
ternative, Electromagnetic (EM) emanations—a by-product caused
by the current flow on data lines and power rails—originally pro-
posed as cryptographic side-channels by Quisquater and Samyde
[66], provides a spatial dimension to perform side-channel analysis
in isolation from unwanted leakage.
Various techniques exploit data dependent EM leakage such as
Differential Power Analysis [50], Correlation Power Analysis [17],
Template Attacks [25] and Horizontal attacks [30, 34]. Identifying
data dependent EM leakage can be challenging due to additional
noise and other unwanted artifacts, thus in addition to simple fre-
quency analysis, additional leakage detection statistical tools are
2-test [58]
required such as Mutual Information Analysis [29], χ
and Test Vector Leakage Assessment (TVLA) [41, 67].
Originally developed by Cryptography Research, Inc. for AES
[41] and later adapted for public-key cryptography [47], TVLA is a
preferred choice for applying black-box leakage detection testing
to identify side-channel weaknesses [28, 61]. TVLA is based on
Welch’s T-test [74], which computes a statistical value, i.e. confi-
dence interval (CI) to accept or reject the null hypothesis. More
specifically, the test validates whether two sets of samples are taken
from similar data by comparing the averages of the two data sets.
Formally, for two sets S1 and S2, the T-test computes as
t =
(cid:114)
µ1 − µ2
σ 2
+ σ 2
1
2
n2
n1
where µ1, σ1, and n1 are the mean, standard deviation, and cardi-
nality of S1, respectively, and similarly for S2. The T-test will fail
at some discrete sample point if the value is greater than some
threshold Cτ. In the context of side-channel data, usually fixed vs
random test samples are compared to identify points with data
dependent leakage [41].
Contemporary works demonstrate the effectiveness of EM anal-
ysis on modern PCs, embedded and mobile devices on various open
source libraries such as GnuPG and OpenSSL, for attacking cryp-
tosystems like AES [54], RSA [38], ECDH [36], and ECDSA [37].
Moreover, e.g. Goller and Sigl [40] successfully demonstrate the
viability of EM attacks over varying distances from mobile devices
on ECC and RSA.
Longo et al. [54] performed localized EM analysis on a mod-
ern embedded device running software based OpenSSL AES, a
bit-sliced optimized implementation for SIMD NEON core, and an
AES hardware engine. They applied TVLA to identify EM leakages
and subsequently carry out template attacks. Genkin et al. [37]
were able to filter out EM emanations from a mobile device at very
low frequencies using inexpensive equipment and additional signal
processing steps. Their attack successfully recovered a few bits
of ECDSA nonces, targeting the OpenSSL wNAF implementation.
With roughly 100 signatures, they then successfully mounted a
lattice attack for full key recovery.
2.5 SM2 Implementation Attacks: Previous
Work
Due to only recently being standardized and coupled with lack
of sufficient public implementations and deployments, academic
results on attacking SM2 implementations are limited in number.
Nevertheless, existing results suggest that implementation attacks
on ECDSA generally extend—with slight modification—to SM2DSA.
A brief review follows.
Liu et al. [53] were the first to construct an SM2DSA analogue
of existing lattice-based ECDSA key recovery with partially known
nonces. The authors model exposure of three LSBs, and with 256-bit
p and n recover a private key from 100 signatures with reasonable
probability and modest computation time.
Chen et al. [27] were the first to implement an SM2DSA lat-
tice attack with real traces. They target an SM2DSA smartcard
implementation and distinguish least significant byte collisions by
detecting Hamming weight with PCA-based techniques. Restricting
to byte values 0x00 and 0xFF, the authors obtain 120K signatures
with power traces, filter them to 48 pairs, and iteratively construct
lattice problem instances to recover a private key. Interestingly, the
target is not the underlying ECC itself, but data moves by the RNG
150Side-Channel Analysis of SM2: A Late-Stage Featurization Case Study
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
during nonce generation. In that respect, their attack is independent
of the underlying ECC arithmetic.
Building on [11, 20] that focus on the LSDs of the wNAF for