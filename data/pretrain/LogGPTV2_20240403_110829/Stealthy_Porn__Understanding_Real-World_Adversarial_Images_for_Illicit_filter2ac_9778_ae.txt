attention from their potential buyers.
Evasive techniques on promotional content. In addition to
the obfuscation techniques applied to the explicit content in
APPIs (Section V-B), cybercriminals also use other approaches
to protect their promotional content from detection. In par-
ticular, we observe that special
text styles are used (e.g.,
semi-transparent text, hollow text, or even handwritten texts)
to prevent the texts from being recognized by OCR tools.
Also, we ﬁnd that some keywords (such as the name of
instant message app) in the promotional content are replaced
with the characters of similar meanings, similar shapes or
jargons. Speciﬁcally, in our dataset, more than 200 APPIs are
found to include such keyword replacements, using jargons,
homophonic words, romanization of Chinese words, etc. For
example, as shown in Table VII, the sensitive word “QQ” (an
instant message app) is often replaced with a jargon “企鹅”
(penguin) because the app uses a penguin as its icon, and “微
信” (WeChat) is replaced with an English letter “v” and an
emoji “”, where “v” is homophonic to “微”, and “” is “心”
in Chinese, which makes them sound like WeChat in Chinese.
Cybercriminals also protect QR code on APPIs. As men-
tioned in Section III-C, unconventional, disoriented, and dis-
torted QR codes are observed in APPIs (see Figure 3). Al-
though standard QR codes are designed as machine-readable,
most open-source QR code scanners, such as ZBar, ZXing,
and BoofCV, are incapable of recognizing or even detecting
the QR codes after the adversarial processing, while they are
still recognizable by the professional QR Code Scanner in
WeChat. Among 1,430 QR codes detected from the APPIs,
595 (41.6%) evade ZBar but are still readable by WeChat.
Promoted products. It is not surprising that the overwhelming
majority of APPIs are used to promote sexual products,
because such products are in line with the explicit content
displayed by the images. In addition, APPIs that promote
gamble websites, drugs, and virtual merchandise in video
games are also found in our dataset. We even observe one
Fig. 12: Shared promotional content.
APPI with two diﬀerent types of promotional content (a sexual
product and a game app).
Among the sex-related products, porn videos, comics, and
porn websites are most prevalent. We even observe child
porn and bestiality porn being promoted via APPIs at Baidu
Tieba. Besides, sexual apps are common products advertised
by APPIs. Such illicit apps are the platforms for both online
and oﬄine transactional sex, such as live sex webcam and
one-night stand.
B. Campaign Discovery
To reveal the criminal campaigns behind the APPIs, we
study the correlation among diﬀerent APPIs from two perspec-
tives: shared promotional content and explicit content reuse.
Shared promotional content. We observe the prevalence of
shared promotional content in APPIs. Figure 12 illustrates the
distribution of promotional content volume per APPI. As we
can see here, 113 out of 285 (39.6%) promotional content
pieces appear in more than one APPI from Tieba, and 119
out of 378 (31.5%) from Weibo. The most prevalent one is a
QR code leading to a porn app download link (http://i8cv.com/
/index.php/S/eOs5EVtc), which is embedded in 669 diﬀerent
APPIs.
Explicit content reuse. Also interestingly, it is very common
for cybercriminals to reuse the same set of explicit images to
craft APPIs. To ﬁnd reused explicit content, we ﬁrst locate
the explicit content in APPIs and then compare the similarity
among those explicit content pieces. Speciﬁcally, we again
leverage Mal´ena to locate the ROIs with explicit content (see
Section III), and perform object matching using the SIFT
algorithm [46] on each ROI pair. In this way, we ﬁnd that
3,981 out of 4,353 APPIs share explicit content with at least
one other image.
APPI campaign discovery. With the information for promo-
tional and explicit content reuse, we are able to recover APPI
campaigns, which share explicit content or have same promo-
tional information. The APPI campaigns can be discovered
using a graph algorithm, where each image is a node in the
graph, and for each pair of images sharing promotional or
explicit content, we connect the corresponding nodes with an
undirected edge. The APPI campaigns can be recognized by
ﬁnding connected components in the graph. In this way, we
recover 19 APPI campaigns including more than 10 APPIs.
(cid:26)(cid:23)(cid:19)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:51:56 UTC from IEEE Xplore.  Restrictions apply. 
TABLE VIII: Top 5 APPI campaigns.
Campaign
# APPIs
1
2
3
4
5
1,325
786
347
39
25
Source
Tieba
Tieba
Weibo
Weibo&Tieba
Tieba
Table VIII shows the top 5 APPI campaigns, where the largest
one consists of 1,325 APPIs. We elaborate this campaign in
Section VI-D.
C. Distribution Channels
From the 4,353 APPIs we discovered, 3,080 Tieba accounts,
and 472 Weibo accounts are identiﬁed to distribute at least one
APPI. Among the 3,080 accounts on Baidu Tieba, 2,748 were
banned or deleted by Baidu by Aug 30 2018, while most of
the Weibo accounts (399 out of 472) were still alive then.
To investigate whether those APPI distribution accounts are
dedicated APPI distribution accounts or legitimate ones but
compromised by the cybercriminals to post APPIs, we use a
set of criteria for ﬁltering and manual validation. Speciﬁcally,
for the live accounts, we crawl
their proﬁles and social
relations. Then, for Baidu Tieba accounts, we utilize two
criteria: the average document frequency of each character
in the username and the number of the subscribed bars.
This is because dedicated accounts often use auto-generated
usernames consisting of uncommon words rarely appearing in
Chinese documents such as Chinese Wiki [19]. Also, normal
users usually subscribe several bars. In this way, 82 out of
332 live Tieba accounts are found to be dedicated APPI
distribution accounts, and we manually investigate and validate
166 as compromised accounts. Similarly, we identify 211
compromised Weibo accounts. We notice that the activities
of compromised Weibo accounts are only to comment on
hot microblog using APPIs. They did not actively post any
microblogs themselves for months or even years. On the
other hand, for the dedicated accounts, they constantly post
microblogs (without illicit content but sometimes meaningless
sentences) at a very high frequency (more than 30 posts per
day). We suspect those dedicated promotional accounts are
maintained by bots.
D. Case Study
In Section VI-B, we discover a huge APPI spamming
campaign containing 1,325 APPIs on Baidu Tieba. The cam-
paign was active from 04/16/2018 to 07/15/2018, covering
1,515 posts across 50 bars, involving 1,314 accounts. All
promotional content pieces in APPIs are QR codes, from
which we extract 19 URLs over 8 diﬀerent domains. They
were used to redirect visitors to download at least 7 mobile
sexual apps.
We observe that the cybercriminals heavily reuse the explicit
content: 1,238 APPIs in the campaign are variants of the same
image but protected with a variety of obfuscation techniques
including noising, blurring, occlusion, transparentization and
color manipulation (grayscaling).
After tracking the QR codes in APPIs, we observe that six
QR codes demonstrate interesting redirection behavior: all
of them can be decoded as URLs under t.cn, the domain of
Sina’s URL shortener service. Such shortened URLs lead to
a redirector controlled by SoHu (https://passport.zhan.sohu.
com/passport/sohu/login-jumpto?callback={redirected url}),
which then redirects the visitors to 4 diﬀerent landing domains
under “.top” top-level domain: dannh.top, 000internet17.top,
000cangzhouu.top, and sj87.top
Also, three URLs are under iamh5.cn, an online HTML5
web app developing and hosting platform, and three URLs
under i8cv.com, a website providing alpha test service for
mobile apps. Unfortunately, all of the 6 apps were removed
by the time we studied the campaign. However, another
URL in this campaign, http://bilibilibilibilibili.cn/1 leads to
a website that was still alive. The website was used as a
doorway redirecting visitors to http://cl.lgubn.cn, which hosted
the promoted app, “COLOR直播”, or “Sexual Streaming” in
English. As the app name suggests, it is a video streaming
platform that focuses on sexual content. Interestingly, we ﬁnd
out that the images used to craft APPIs in this campaign are
actually the screenshots of the app, and hence we suspect that
the rest URLs in this campaign are used to promote the same
sexual apps of diﬀerent versions and platforms.
VII. Discussion
Chinese social media. In our study, we investigate APPIs on
two Chinese social media platforms: Baidu Tieba and Sina
Weibo. We should acknowledge that the relatively limited
vantage points may limit the ﬁndings made by our research.
Speciﬁcally, our data source is limited to Chinese social
media, so our research is insuﬃcient to conﬁrm whether the
risk of APPI is a regional or global problem. To the best of
our knowledge, adversarial sexual images for the promotional
purpose are more prevalent
in Chinese social media than
English ones. The reason is that China enforces a more strict
content censorship policy, where explicit content is strictly
prohibited in the Chinese Internet [4]. Therefore, Chinese
social media service providers regularly clean up explicit
content, which motivates the cybercriminals to aggressively
apply obfuscation techniques to protect their promotional porn
images. Meanwhile, we perform a relatively small-scale study
on Twitter and found 6 instances of APPIs from 80k images
among hot tweets. This ﬁnding indicates that APPIs exist,
although not that prevalent, in English social media.
Method limitation. Despite our system’s success in ﬁnding
more than 4,000 images with obfuscation, we admit
that
although it is nontrivial, Mal`ena is possible to be evaded if
the adversary has the knowledge of the system design or
is able to access its model query API. One way to evade
Mal`ena is to fully obfuscate the promotional content or explicit
content in the image. However, it could make the audience
less interested in the image. Alternatively, it is possible to
craft adversarial examples against the neural network models
adopted in Mal`ena. For example, one could attack the Mask
(cid:26)(cid:23)(cid:20)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:51:56 UTC from IEEE Xplore.  Restrictions apply. 
R-CNN model to cause the misclassiﬁcation of the “person”
object on the explicit image, and Mal`ena would reject the
image as no ROI. Although it is not a robust detection system,
Mal`ena is still eﬀective as a measurement tool to help us better
understand the real-world APPIs today.
Considering the performance of Mal`ena, our implementa-
tion on the test environment with a single Nvidia GeForce
GTX 1070 graphic card of 8 GB memory reports the pro-
cessing speed of 26.02 images per minutes, or, equivalently,
a 2.3-second processing time for each image (Section IV-B).
Such performance is not enough for real time tasks, as the
user may perceive noticeable delays. However, most Mal`ena’s
time-consuming steps are deep learning jobs which greatly
favor parallelism and can be accelerated by introducing more
graphic cards with larger memory to make it feasible in a
production environment.
Mitigation. Our study reveals the problem of the distribution
of real-world adversarial images with an underground business
behind promoting illicit products. We suggest all services that
allow user-generated content to adopt a dedicated detector
for real-world adversarial images such as Mal`ena in their
content security pipeline. Detecting such adversarial images
is still challenge because the illicit content on such images
is typically obfuscated and thus is hard to identify. However,
our measurement study shows that the adversary heavily relies
on the promotional content on the images to advertise their
products. So the semantic-aware image processing approaches
targeting such promotional content would be helpful in the
mitigation of the problem of real-world adversarial images.
Further, the key to mitigate such a problem is the takedown of
underground business to generate such adversarial images. In
our future work, we will systematically explore underground
business and key actors enabling those images.
Adversarial example defenses. Previous researchers have
achieved limited success in defense against adversarial exam-
ples [50], [54]. Based on this, we believe previous defensive
approaches will be pale or even worse when handling APPIs,
a harder problem than defeating adversarial examples. This is
because APPIs are distorted further away from the original
images than adversarial examples. From the neural network’s
perspective, classifying two such far way images into the same
category will not provide any bonus for better performance on
the usual training set, and there are no rules encouraging the
neural network to do that: even in the min-max defense [54]
trying to increase the minimal distance between two cate-
gories, let alone the distillation defense [50] that hide the
gradients. As for our approach, Mal`ena, its success is ascribed
to using the mask (provided by Mask R-CNN, see Section III),
which lowers the weights in occlusion areas or no-body areas,
and therefore neutralizes some parts of interference introduced
by the adversary.
In the meanwhile, we still have to acknowledge that our
protection could be evaded by carefully designed and targeted
attacks from the adversary who has the full knowledge of
our system design and parameters. However the appliance of
Mal`ena would raise in the bar of such attacks, making them
more costly especially to the adversary who want to launch
black-box attacks. This is because the classiﬁcation results
of our explicit region proposal network, which are used only
internally in the following Mal`ena detection pipeline and hence
are transparent to the adversaries, can not be easily inferred.
Speciﬁcally, to attack Mal`ena, the adversary can either add
perturbations to attack the ROI locator or regional explicit
content detector (see Figure 2). The attack to the ROI locator
(i.e., explicit region proposal network) is non-trivial due to the
missing classiﬁcation results: those classiﬁcation parameters
of our proposal network are orthogonal from the gradient
propagation process given the ﬁnal detection output. Mean-
while, attacking regional explicit content detector faces two
challenges: ﬁrst, our proposal network restricts the available
region where adversaries can add the perturbations; second,
the mutual eﬀects between the mask and the input image
will signiﬁcantly hinder the searching process of adversarial
perturbations. While adversaries can justly ﬁnd perturbations
simultaneously to bypass our proposal network and detection
network,