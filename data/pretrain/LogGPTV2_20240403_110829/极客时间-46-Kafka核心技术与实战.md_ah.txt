## 何时压缩？在 Kafka 中，压缩可能发生在两个地方：生产者端和 Broker 端。生产者程序中配置 compression.type参数即表示启用指定类型的压缩算法。比如下面这段程序代码展示了如何构建一个开启GZIP 的 Producer 对象：     Properties props = new Properties(); props.put("bootstrap.servers", "localhost:9092"); props.put("acks", "all"); props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // 开启 GZIP 压缩 props.put("compression.type", "gzip");  Producer producer = new KafkaProducer<>(props);这里比较关键的代码行是 props.put("compression.type", "gzip")，它表明该Producer 的压缩算法使用的是 GZIP。这样 Producer启动后生产的每个消息集合都是经 GZIP压缩过的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。在生产者端启用压缩是很自然的想法，那为什么我说在 Broker端也可能进行压缩呢？其实大部分情况下 Broker 从 Producer端接收到消息后仅仅是原封不动地保存而不会对其进行任何修改，但这里的"大部分情况"也是要满足一定条件的。有两种例外情况就可能让Broker 重新压缩消息。情况一：Broker 端指定了和 Producer 端不同的压缩算法。先看一个例子。想象这样一个对话。Producer 说："我要使用 GZIP 进行压缩。"Broker 说："不好意思，我这边接收的消息必须使用 Snappy 算法进行压缩。"你看，这种情况下 Broker 接收到 GZIP 压缩消息后，只能解压缩然后使用Snappy 重新压缩一遍。如果你翻开 Kafka 官网，你会发现 Broker端也有一个参数叫compression.type，和上面那个例子中的同名。但是这个参数的默认值是producer，这表示 Broker 端会"尊重"Producer 端使用的压缩算法。可一旦你在Broker 端设置了不同的 compression.type值，就一定要小心了，因为可能会发生预料之外的压缩 /解压缩操作，通常表现为 Broker 端 CPU 使用率飙升。情况二：Broker 端发生了消息格式转换。所谓的消息格式转换主要是为了兼容老版本的消费者程序。还记得之前说过的V1、V2 版本吧？在一个生产环境中，Kafka集群中同时保存多种版本的消息格式非常常见。为了兼容老版本的格式，Broker端会对新版本消息执行向老版本格式的转换。这个过程中会涉及消息的解压缩和重新压缩。一般情况下这种消息格式转换对性能是有很大影响的，除了这里的压缩之外，它还让Kafka 丧失了引以为豪的 Zero Copy 特性。所谓"Zero Copy"就是"零拷贝"，我在专栏[第 6期](https://time.geekbang.org/column/article/101107)提到过，说的是当数据在磁盘和网络进行传输时避免昂贵的内核态数据拷贝，从而实现快速的数据传输。因此如果Kafka享受不到这个特性的话，性能必然有所损失，所以尽量保证消息格式的统一吧，这样不仅可以避免不必要的解压缩/ 重新压缩，对提升其他方面的性能也大有裨益。如果有兴趣你可以深入地了解下Zero Copy 的原理。
## 何时解压缩？有压缩必有解压缩！通常来说解压缩发生在消费者程序中，也就是说 Producer发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer端后，由 Consumer 自行解压缩还原成之前的消息。那么现在问题来了，Consumer怎么知道这些消息是用何种压缩算法压缩的呢？其实答案就在消息中。Kafka会将启用了哪种压缩算法封装进消息集合中，这样当 Consumer读取到消息集合时，它自然就知道了这些消息使用的是哪种压缩算法。如果用一句话总结一下压缩和解压缩，那么我希望你记住这句话：**Producer端压缩、Broker 端保持、Consumer 端解压缩。**除了在 Consumer 端解压缩，Broker端也会进行解压缩。注意了，这和前面提到消息格式转换时发生的解压缩是不同的场景。每个压缩过的消息集合在Broker端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证。我们必须承认这种解压缩对Broker 端性能是有一定影响的，特别是对 CPU 的使用率而言。事实上，最近国内京东的小伙伴们刚刚向社区提出了一个bugfix，建议去掉因为做消息校验而引入的解压缩。据他们称，去掉了解压缩之后，Broker端的 CPU 使用率至少降低了50%。不过有些遗憾的是，目前社区并未采纳这个建议，原因就是这种消息校验是非常重要的，不可盲目去之。毕竟先把事情做对是最重要的，在做对的基础上，再考虑把事情做好做快。针对这个使用场景，你也可以思考一下，是否有一个两全其美的方案，既能避免消息解压缩也能对消息执行校验。
## **各种压缩算法对比**那么我们来谈谈压缩算法。这可是重头戏！之前说了这么多，我们还是要比较一下各个压缩算法的优劣，这样我们才能有针对性地配置适合我们业务的压缩策略。在 Kafka 2.1.0 版本之前，Kafka 支持 3 种压缩算法：GZIP、Snappy 和LZ4。从 2.1.0 开始，Kafka 正式支持 Zstandard 算法（简写为 zstd）。它是Facebook 开源的一个压缩算法，能够提供超高的压缩比（compression ratio）。对了，看一个压缩算法的优劣，有两个重要的指标：一个指标是压缩比，原先占100 份空间的东西经压缩之后变成了占 20 份空间，那么压缩比就是5，显然压缩比越高越好；另一个指标就是压缩 /解压缩吞吐量，比如每秒能压缩或解压缩多少 MB的数据。同样地，吞吐量也是越高越好。下面这张表是 Facebook Zstandard 官网提供的一份压缩算法 benchmark比较结果：![](Images/b6c24a89864c602665cab19344103a3c.png){savepage-src="https://static001.geekbang.org/resource/image/cf/68/cfe20a2cdcb1ae3b304777f7be928068.png"}从表中我们可以发现 zstd算法有着最高的压缩比，而在吞吐量上的表现只能说中规中矩。反观 LZ4算法，它在吞吐量方面则是毫无疑问的执牛耳者。当然对于表格中数据的权威性我不做过多解读，只想用它来说明一下当前各种压缩算法的大致表现。在实际使用中，GZIP、Snappy、LZ4 甚至是 zstd 的表现各有千秋。但对于 Kafka而言，它们的性能测试结果却出奇得一致，即在吞吐量方面：LZ4 \> Snappy \>zstd 和 GZIP；而在压缩比方面，zstd \> LZ4 \> GZIP \>Snappy。具体到物理资源，使用 Snappy 算法占用的网络带宽最多，zstd最少，这是合理的，毕竟 zstd 就是要提供超高的压缩比；在 CPU使用率方面，各个算法表现得差不多，只是在压缩时 Snappy 算法使用的 CPU较多一些，而在解压缩时 GZIP 算法则可能使用更多的 CPU。
## **最佳实践**了解了这些算法对比，我们就能根据自身的实际情况有针对性地启用合适的压缩算法。首先来说压缩。何时启用压缩是比较合适的时机呢？你现在已经知道 Producer 端完成的压缩，那么启用压缩的一个条件就是Producer 程序运行机器上的 CPU 资源要很充足。如果 Producer 运行机器本身CPU 已经消耗殆尽了，那么启用消息压缩无疑是雪上加霜，只会适得其反。除了 CPU资源充足这一条件，如果你的环境中带宽资源有限，那么我也建议你开启压缩。事实上我见过的很多Kafka 生产环境都遭遇过带宽被打满的情况。这年头，带宽可是比 CPU和内存还要珍贵的稀缺资源，毕竟万兆网络还不是普通公司的标配，因此千兆网络中Kafka 集群带宽资源耗尽这件事情就特别容易出现。如果你的客户端机器 CPU资源有很多富余，我强烈建议你开启 zstd压缩，这样能极大地节省网络资源消耗。其次说说解压缩。其实也没什么可说的。一旦启用压缩，解压缩是不可避免的事情。这里只想强调一点：我们对不可抗拒的解压缩无能为力，但至少能规避掉那些意料之外的解压缩。就像我前面说的，因为要兼容老版本而引入的解压缩操作就属于这类。有条件的话尽量保证不要出现消息格式转换的情况。
## 小结总结一下今天分享的内容：我们主要讨论了 Kafka 压缩的各个方面，包括 Kafka是如何对消息进行压缩的、何时进行压缩及解压缩，还对比了目前 Kafka支持的几个压缩算法，最后我给出了工程化的最佳实践。分享这么多内容，我就只有一个目的：就是希望你能根据自身的实际情况恰当地选择合适的Kafka 压缩算法，以求实现最大的资源利用率。
## 开放讨论最后给出一道作业题，请花时间思考一下：前面我们提到了 Broker要对压缩消息集合执行解压缩操作，然后逐条对消息进行校验，有人提出了一个方案：把这种消息校验移到Producer 端来做，Broker 直接读取校验结果即可，这样就可以避免在 Broker端执行解压缩操作。你认同这种方案吗？欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。![](Images/a7d15815f9efb5693db5b2d278244658.png){savepage-src="https://static001.geekbang.org/resource/image/c8/bf/c89da43deab85fe7cb06acec867aa5bf.jpg"}
# 11 \| 无消息丢失配置怎么实现？你好，我是胡夕。今天我要和你分享的主题是：如何配置 Kafka 无消息丢失。一直以来，很多人对于 Kafka丢失消息这件事情都有着自己的理解，因而也就有着自己的解决之道。在讨论具体的应对方法之前，我觉得我们首先要明确，在Kafka 的世界里什么才算是消息丢失，或者说 Kafka在什么情况下能保证消息不丢失。这点非常关键，因为很多时候我们容易混淆责任的边界，如果搞不清楚事情由谁负责，自然也就不知道由谁来出解决方案了。那 Kafka 到底在什么情况下才能保证消息不丢失呢？**一句话概括，Kafka 只对"已提交"的消息（committedmessage）做有限度的持久化保证。**这句话里面有两个核心要素，我们一一来看。第一个核心要素是"**已提交的消息**"。什么是已提交的消息？当 Kafka的若干个 Broker成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在Kafka 看来就正式变为"已提交"消息了。那为什么是若干个 Broker呢？这取决于你对"已提交"的定义。你可以选择只要有一个 Broker成功保存该消息就算是已提交，也可以是令所有 Broker都成功保存该消息才算是已提交。不论哪种情况，Kafka只对已提交的消息做持久化保证这件事情是不变的。``{=html}第二个核心要素就是"**有限度的持久化保证**"，也就是说 Kafka不可能保证在任何情况下都做到不丢失消息。举个极端点的例子，如果地球都不存在了，Kafka还能保存任何消息吗？显然不能！倘若这种情况下你依然还想要 Kafka不丢消息，那么只能在别的星球部署 Kafka Broker 服务器了。现在你应该能够稍微体会出这里的"有限度"的含义了吧，其实就是说 Kafka不丢消息是有前提条件的。假如你的消息保存在 N 个 Kafka Broker上，那么这个前提条件就是这 N 个 Broker 中至少有 1个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。总结一下，Kafka是能做到不丢失消息的，只不过这些消息必须是已提交的消息，而且还要满足一定的条件。当然，说明这件事并不是要为Kafka 推卸责任，而是为了在出现该类问题时我们能够明确责任边界。