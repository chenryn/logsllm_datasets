The shared pitfall are the oracles. In HORNET’s analysis this
attack was excluded as the oracles were not taken into account.
The proof of TARANET ignores the oracles as well, yet its
transmission phase incidentally protects against our attack.
Sphinx, the improved Minx and even an extension in [8] restrict
the oracle in our Step 7 to only allow non-duplicate onions,
i.e. those with a changed header. This weakens the properties
too much, as the limited oracle incidentally loses protection
11Technically, controlling the link from the sender to the ﬁrst relay is enough.
However, whether the adversary controls links is not explicitly stated in [11].
12Although this attack works for TARANET, it is outside TARANET’s
attacker model as the receiver needs to be corrupted.
13We stress that this model was never intended by Sphinx, but other works
used Sphinx that way.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:04:48 UTC from IEEE Xplore.  Restrictions apply. 
178
from modiﬁcation attacks, where the onion is modiﬁed before
it ever reached the honest node.
Note, that our property LU (and even the insecure original
Onion-Security) indeed cannot be fulﬁlled if the before
mentioned attack (Section V-A) works: The adversary alters
only the payload of the challenge onion and queries the oracle
with the modiﬁed onion. As processing at the honest node is
not aborted for modiﬁed onions, the adversary learns the next
relay after the honest node. She can thus decide whether the
next relay corresponds to her choice (b = 0) or not (b = 1).
We want to stress that this is not the only attack that prevents
HORNET from achieving LU. Another exploits the usage of
sessions (more in Section VII-C2).
VI. PROVING THE ADAPTED SPHINX SECURE
Sphinx speciﬁes to use a header and a payload. The original
Sphinx [13] suggests per-hop integrity protection only for the
header as an integrity check for the payload conﬂicts with their
support for replies. Thus, as mentioned in Section V-A Sphinx
allows to link sender and exit node. As this linking is not
possible in the ideal functionality, Sphinx, even with the ﬂaw
from Section IV-A ﬁxed, cannot realize the ideal functionality.
Beato et al. however proposed an adaptation to Sphinx, to
simplify the protocol and improve security and performance
at the cost of losing support for replies [5]. Thereby, they
introduce integrity checks of the payload at each hop. As
this prevents the linking attack, we decided to analyze this
version of Sphinx, adapted with the small ﬁx to the attack
from Section IV-A known from the Sphinx implementation,
for compliance with our properties for secure OR protocols.
Note, that in compliance to Beato et al. this variation covers
only the forward phase and no replies.
The proof for Onion-Correctness follows the ideas in [13].
To analyze LU and T I, we successively deﬁne games with
marginally weaker adversary models. Arguing how each step
follows from reasonable assumptions, we terminally reduce it
to the security of an authenticated encryption scheme and the
DDH assumption. We provide the detailed proof in Appendix C,
and it leads to the following theorem:
Theorem 3: Beato’s Sphinx variation, adapted with the ﬁx
to the attack from Section IV-A, is a secure OR scheme.
As this implies that
it realizes the ideal functionality,
we can conclude that it achieves conﬁdentiality (M O) for
honest senders with honest receivers, and sender (SM L)
and relationship anonymity (SRL) for honest senders with
corrupted receivers. This holds for a restricted adversary model,
which does not allow timing attacks or attacks that lead to the
dropping of onions. This limitation conforms to the adversary
model of the original Sphinx, which is used in the adapted
version as well.
VII. DISCUSSION
In this section, we relate our properties to known attacks
and give further comments about the limitations of using them.
A. Onion-Security Properties vs. Existing OR Attacks
Our new properties prevent well-known attacks on OR if
they comply to the adversary model of the ideal functionality.
Passive linking attacks e.g. based on length of the onion layer, or
the length of the included message are prevented (attacks on LU
would otherwise be possible). Additionally, our properties imply
non-deterministic encryption in FormOnion, as the adversary
could use FormOnion on its chosen parameters and compare
the results, otherwise.
In tagging attacks the attacker modiﬁes an onion and
recognizes it later based on the modiﬁcation. To be useful,
the tagging has to preserve some information of the original
communication, e.g. a part of the path or the message. This
translates to an attack on LU that uses an oracle to learn the
output of a tagged challenge onion after processing at an honest
relay, and deciding if it relates to the chosen input (b = 0), or
not.
Duplicate attacks assume an adversary that is able to create
an onion that equals an intercepted onion in parts of the
input, e.g. the message, that can later be observed, but is
not bit-identical. Such onions appear different at the relays
and hence may not be detected by duplicate protection. They
still jeopardize anonymity, as the adversary may notice their
repeated delivery to the receiver. Our properties protect from
duplicate attacks, as an adversary that was able to create a
duplicate onion breaks LU by learning the message or path
contained in the challenge onion by using the oracle.
Replay attacks (duplicate attacks with bit-identical onion)
are possible in the ideal functionality and consequently not
necessarily prevented.
The n-1 Attack, where all but one onion is known to the
adversary, and hence the remaining one can be traced, is
possible in the ideal functionality and thus not mitigated by
the properties.
B. Adapting Our Properties
There are cases, in which our properties need adaptation:
Correctness: Due to practical reasons, space-efﬁcient data
structures like Bloom ﬁlters are frequently used for duplicate
detection. Bloom ﬁlters exhibit false-positive detections (that is
non-duplicate packets are detected as duplicates with a certain
probability), but no false-negatives (duplicates are always
detected). However, the false-positive probability of a Bloom
ﬁlter depends on its conﬁguration and is usually not negligible.
This can be covered by extending our Onion-Correctness to
δ-Onion-Correctness, thus accepting a correctness failure at a
probability of at most δ.
Security properties and Cascades: So far we assumed that
the replacement onion is any onion that shares the observed part
of the path. This naturally applies for free routing protocols,
in which the sender randomly picks any path, and which is
considered by the ideal functionality. When analyzing OR with
ﬁxed cascades, some adaptations are necessary. Adaptation
and changes in the analysis for the adapted ideal functionality,
however, are straightforward: senders can only choose a cascade
instead of a path. This results in a different path choice in the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:04:48 UTC from IEEE Xplore.  Restrictions apply. 
179
adversary class and thus in a slightly different anonymity set.
In the game, the path of the replacement onion ﬁnally has to
match the cascade of the challenge onion (this can be assured
in Step 5 of both LU and T I).
C. Limitations
As limitations of this paper, we recall the adversary model,
the anonymity set, and discuss the limits inherited from the
ideal functionality.
1) Adversary Model and Anonymity Set: We fully assumed
the adversary model of Camenisch and Lysyanskaya. This
adversary model does not allow for trafﬁc analysis as timing
information is removed and no delaying or dropping is allowed
by the adversary. Although this adversary model does not seem
very realistic, the analysis is useful to split the proof. Upon
showing the protocol’s privacy for the restricted adversary
model of the ideal functionality by proving the properties, only
the privacy for the remaining attacks has to be shown.
We restrict the paths in the adversary class to include at least
one honest relay to achieve the notions. This means that the
anonymity set consists only of the users whose onions share
an honest relay and are processed together.
2) Reply Channels and Sessions: All systems that proved
privacy with the properties consider a reply channel, for
example to respond to an anonymous sender. None, however,
analyzes the backward phase separately. They only show
indistinguishability to the forward onions (if at all), implying
that the same security properties are used for the reply channel.
However, our analysis showed that the privacy goals except
conﬁdentiality (M O) are only guaranteed for an honest sender.
In a reply phase this sender is the original receiver, which
cannot ultimately be considered honest. Thus, proving the
properties does not guarantee the anonymity of the initial
sender for a corrupted receiver in the reply phase.
HORNET and TARANET additionally introduce sessions.
Their data transmission phase reuses the same path and header
to efﬁciently send multiple onions. The ideal functionality does
not cover sessions. As for a corrupted relay it is always possible
to link onions of the same session, neither the properties, nor
ultimately the ideal functionality can be shown in this case.
Besides noticing this insufﬁciency, sending replies to the
sender or using sessions is outside of the scope of this
paper. We conjecture that both issues can be solved in future
work by changing the ideal functionality and introducing
additional properties. For this paper, we deemed it however
more important to explain and correct all mistakes related to
the simple sending with OR in detail.
D. Some Thoughts about Mix Networks
Mix networks in addition to onion processing include
reordering of onions (usually by delaying them for some time),
to conceal timing information and prevent linking outgoing to
incoming onions based on their order and timing. The ideal
functionality, as well as both the original and our properties
all do not consider timing attacks. Although none of the
widely deployed anonymization systems considers this, a real
anonymous communication network of course should prevent
linking based on timings. From the perspective of this work
we consider this an extension, as all properties presented here
need to be met by mix networks, as well, to prevent linking
based on the onions and their processing at honest nodes.
E. Extended Version
Our extended version of this paper [24] contains technical
details we excluded for this version due to space limitations.
These comprise the technical proofs of the notions the ideal
functionality does and does not achieve (including attacks
for stronger notions), a scheme and the corresponding proofs
illustrating the second insecurity (Section IV-D1) of the
properties from [8] and the proof that Wrap-Resistance and
Onion-Integrity of [8] do not need to be proven for privacy
reasons.
VIII. CONCLUSION AND FUTURE WORK
Camenisch and Lysyanskaya have made a seminal attempt
to formally analyze the predominant anonymization approach
of OR in [8]: They design an ideal functionality for OR in
the UC model and suggest properties to analyze protocols and
real-world systems. A whole family of subsequent OR schemes
based their security analyses on this work.
Analyzing approaches from this family, we discovered a
new, severe vulnerability and explained one that was known.
We presented a new attack to completely break sender and
relationship anonymity in HORNET. Further as known and
corrected in the implementation, in Sphinx as in [13] the
anonymity set can be reduced by discovering the used path
length.
As these attacks contradict the proofs in the respective papers,
we set out to formally analyze the used proof strategy proposed
in [8]. First, we conﬁrmed that the foundation of the proof,
the ideal functionality, indeed guarantees privacy.
Second, we explained the reason for the attack on Sphinx:
the properties as originally suggested by Camenisch and
Lysyanskaya are insufﬁcient. To resolve this situation, we ﬁxed
one property, developed two new properties, and proved that
achieving these three properties implies the privacy of the ideal
functionality: sender anonymity and relationship anonymity
against corrupted receivers in an adversary model that limits
onion dropping and timing-based attacks.
Third, we explained the reason for the attack on HORNET:
the original Onion-Security property would have prevented it,
but has been proven incorrectly. Proving a variation of Sphinx
secure, we demonstrated how systems can be analyzed using
our new properties.
We wish to point out that several of the published systems
consider reply channels as well as sessions – which indeed are
not covered by the ideal functionality of [8]. Therefore, much
is left to be done: while we repaired the anonymization for
the simple delivery of a message from a sender to a receiver,
modeling reply channels and sessions is left for future work.
Further, analyses and proofs for the security and privacy of
other onion routing protocols beyond the variation of Sphinx
need to be conducted, by using our or adapted properties.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:04:48 UTC from IEEE Xplore.  Restrictions apply. 
180
ACKNOWLEDGMENT
We thank our shepherd Ian Goldberg and the anonymous
reviewers for their very valuable feedback. This work in part
was funded by DFG EXC 2050/1 – ID 390696704.
REFERENCES
[1] E. D. Ayele. Analysis and deployment of the BitTorrent protocol for
Community Ad-hoc Networks. Technical report, TU Delft, 2011.
[2] M. Backes, A. Kate, P. Manoharan, S. Meiser, and E. Mohammadi.
Anoa: A framework for analyzing anonymous communication protocols.
Journal of Privacy and Conﬁdentiality, 2017.
[3] M. Backes, P. Manoharan, and E. Mohammadi. Tuc: Time-sensitive and
modular analysis of anonymous communication. In IEEE CSF, 2014.
[4] E. Balkovich, D. Prosnitz, A. Boustead, and S. C. Isley. Electronic
Surveillance of Mobile Devices. Rand Corporation, 2015.
[5] F. Beato, K. Halunen, and B. Mennink.
Improving the sphinx mix
network. In Cryptology and Network Security, 2016.
[6] R. Berman, A. Fiat, M. Gomulkiewicz, M. Klonowski, M. Kutylowski,
T. Levinboim, and A. Ta-Shma. Provable unlinkability against trafﬁc
analysis with low message overhead. Journal of Cryptology, 2015.
[7] J.-M. Bohli and A. Pashalidis. Relations among privacy notions. ACM
TISSEC, 2011.
[8] J. Camenisch and A. Lysyanskaya. A formal treatment of onion routing.
In Annual International Cryptology Conference, 2005.
[9] R. Canetti. Universally composable security: A new paradigm for
cryptographic protocols. In IEEE FOCS, 2001.
[10] D. L. Chaum. Untraceable electronic mail, return addresses, and digital
pseudonyms. Communications of the ACM, 1981.
[11] C. Chen, D. E. Asoni, D. Barrera, G. Danezis, and A. Perrig. HORNET:
High-speed onion routing at the network layer. In ACM CCS, 2015.
[12] C. Chen, D. E. Asoni, A. Perrig, D. Barrera, G. Danezis, and C. Troncoso.
TARANET: Trafﬁc-Analysis Resistant Anonymity at the NETwork layer.
IEEE EuroS&P, 2018.
[13] G. Danezis and I. Goldberg. Sphinx: A compact and provably secure
[14] G. Danezis and B. Laurie. Minx: A simple and efﬁcient anonymous
mix format. In IEEE S&P, 2009.
packet format. In WPES, 2004.
[15] J. P. Degabriele and M. Stam. Untagging Tor: a formal treatment of onion
encryption. In Theory and Applications of Cryptographic Techniques,
2018.
[16] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The second-
generation onion router. Technical report, Naval Research Lab Washing-
ton DC, 2004.
[17] J. Feigenbaum, A. Johnson, and P. Syverson. A model of onion routing
with provable anonymity. In Financial Cryptography and Data Security,
2007.
[18] J. Feigenbaum, A. Johnson, and P. Syverson. Anonymity analysis of onion
routing in the universally composable framework. In 2012 Workshop on
Provable Privacy, 2012.
[19] A. Fujioka, Y. Okamoto, and T. Saito. Security of sequential multiple
encryption. In International Conference on Cryptology and Information
Security in Latin America, 2010.
[20] N. Gelernter and A. Herzberg. On the limits of provable anonymity. In
ACM WPES, 2013.
[21] D. M. Goldschlag, M. G. Reed, and P. F. Syverson. Hiding routing
information. In International workshop on information hiding, 1996.
[22] A. Hevia and D. Micciancio. An indistinguishability-based character-
ization of anonymous channels. Lecture Notes in Computer Science,
2008.
[23] C. Kuhn, M. Beck, S. Schiffner, E. Jorswieck, and T. Strufe. On privacy
notions in anonymous communication. PoPETs, 2019.
[24] C. Kuhn, M. Beck, and T. Strufe. Breaking and (Partially) Fixing
Provably Secure Onion Routing. arXiv e-prints, page arXiv:1910.13772,
2019.
[25] S. Mauw, J. H. Verschuren, and E. P. de Vink. A formalization of
anonymity and onion routing. In European Symposium on Research in
Computer Security, 2004.
[26] K. Peng. A general and efﬁcient countermeasure to relation attacks in
mix-based e-voting. Int. J. Inf. Secur., 10(1), Feb. 2011.
[27] D. J. Pohly and P. McDaniel. Modeling Privacy and Tradeoffs in
Multichannel Secret Sharing Protocols. In IEEE/IFIP DSN, 2016.