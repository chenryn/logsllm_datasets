(NeurIPS). 6977–6987.
[14] Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Li Chen, Michael E Kounavis,
and Duen Horng Chau. 2018. Adagio: Interactive experimentation with adver-
sarial attack and defense for audio. In Joint European Conference on Machine
Learning and Knowledge Discovery in Databases. Springer, 677–681.
[15] Timothy Dozat. 2016. Incorporating nesterov momentum into adam. In Interna-
tional Conference on Learning Representations (ICLR).
[16] John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods
for online learning and stochastic optimization. Journal of machine learning
research 12, Jul (2011), 2121–2159.
[17] Yuan Gong, Boyang Li, Christian Poellabauer, and Yiyu Shi. 2019. Real-time
adversarial attacks. In Proceedings of the International Joint Conference on Artificial
Intelligence (IJCAI).
[18] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep learning. MIT
press.
REFERENCES
[1] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al.
2016. Tensorflow: A system for large-scale machine learning. In 12th USENIX
Symposium on Operating Systems Design and Implementation (OSDI). 265–283.
[2] Hadi Abdullah, Washington Garcia, Christian Peeters, Patrick Traynor, Kevin RB
Butler, and Joseph Wilson. 2019. Practical hidden voice attacks against speech
and speaker recognition systems. arXiv preprint arXiv:1904.05734 (2019).
[3] Moustafa Alzantot, Bharathan Balaji, and Mani Srivastava. 2017. Did you hear
that? adversarial examples against automatic speech recognition. In Proceedings
of the Annual Conference on Neural Information Processing Systems (NIPS).
[4] Amazon. 2020. Amazon Echo.
https://www.amazon.com/all-new-Echo/dp/
B07R1CXKN7
[19] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and
harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014).
[20] Google. 2020. Google Home. https://store.google.com/us/product/google_home
[21] Google. 2020. Speech-to-text Conversion Powered by Machine Learning. https:
//cloud.google.com/speech-to-text
[22] Alex Graves, Santiago Fernández, Faustino Gomez, and Jürgen Schmidhuber.
2006. Connectionist temporal classification: labelling unsegmented sequence
data with recurrent neural networks. In Proceedings of the 23rd international
conference on Machine learning. 369–376.
[23] Chris Hall. 2019.
tually
148690-hey-bmw-your-intelligent-voice-assistant-is-actually-pretty-good.
Hey BMW: Your intelligent voice assistant
is ac-
https://www.pocket-lint.com/cars/news/bmw/
pretty
good.
[24] Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich
Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, et al.
2014. Deep speech: Scaling up end-to-end speech recognition. arXiv preprint
arXiv:1412.5567 (2014).
[25] Xuedong Huang. 2017. Microsoft researchers achieve new conversational
speech recognition milestone. https://www.microsoft.com/en-us/research/blog/
microsoft-researchers-achieve-new-conversational-speech-recognition-milestone/
[26] Marco Jeub, Magnus Schafer, and Peter Vary. 2009. A binaural room impulse re-
sponse database for the evaluation of dereverberation algorithms. In International
Conference on Digital Signal Processing. IEEE, 1–5.
[27] Jack Kiefer, Jacob Wolfowitz, et al. 1952. Stochastic estimation of the maximum of
a regression function. The Annals of Mathematical Statistics 23, 3 (1952), 462–466.
[28] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980 (2014).
[29] Keisuke Kinoshita, Marc Delcroix, Takuya Yoshioka, Tomohiro Nakatani,
Emanuel Habets, Reinhold Haeb-Umbach, Volker Leutnant, Armin Sehr, Walter
Kellermann, Roland Maas, et al. 2013. The REVERB challenge: A common evalu-
ation framework for dereverberation and recognition of reverberant speech. In
IEEE Workshop on Applications of Signal Processing to Audio and Acoustics. 1–4.
[30] Felix Kreuk, Yossi Adi, Moustapha Cisse, and Joseph Keshet. 2018. Fooling end-
to-end speaker verification with adversarial examples. In Proceedings of the IEEE
International Conference on Acoustics, Speech, and Signal Processing (ICASSP).
1962–1966.
[31] Zhuohang Li, Cong Shi, Yi Xie, Jian Liu, Bo Yuan, and Yingying Chen. 2020. Prac-
tical Adversarial Attacks Against Speaker Recognition Systems. In Proceedings of
the 21st International Workshop on Mobile Computing Systems and Applications
(HotMobile). 9–14.
[32] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal
Frossard. 2017. Universal adversarial perturbations. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition (CVPR). 1765–1773.
[33] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016.
Deepfool: a simple and accurate method to fool deep neural networks. In Proceed-
ings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
2574–2582.
[34] Satoshi Nakamura, Kazuo Hiyane, Futoshi Asano, Takanobu Nishiura, and
Takeshi Yamada. 2000. Acoustical sound database in real environments for
sound scene understanding and hands-free speech recognition. In Language
Resources and Evaluation Conference. 965–968.
[35] Paarth Neekhara, Shehzeen Hussain, Prakhar Pandey, Shlomo Dubnov, Julian
McAuley, and Farinaz Koushanfar. 2019. Universal adversarial perturbations for
speech recognition systems. arXiv preprint arXiv:1905.03828 (2019).
[36] Vijayaditya Peddinti, Daniel Povey, and Sanjeev Khudanpur. 2015. A time delay
neural network architecture for efficient modeling of long temporal contexts.
In Annual Conference of the International Speech Communication Association
(INTERSPEECH).
[37] Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget, Ondrej Glembek,
Nagendra Goel, Mirko Hannemann, Petr Motlicek, Yanmin Qian, Petr Schwarz,
Jan Silovsky, Georg Stemmer, and Karel Vesely. 2011. The Kaldi Speech Recogni-
tion Toolkit. In IEEE Workshop on Automatic Speech Recognition and Understanding
(ASRU). IEEE Signal Processing Society. IEEE Catalog No.: CFP11SRW-USB.
[38] Yao Qin, Nicholas Carlini, Garrison Cottrell, Ian Goodfellow, and Colin Raffel.
2019. Imperceptible, Robust, and Targeted Adversarial Examples for Automatic
Speech Recognition. In Proceedings of the International Conference on Machine
Learning (ICLR). 5231–5240.
[39] Tara N Sainath and Carolina Parada. 2015. Convolutional neural networks for
small-footprint keyword spotting. In Annual Conference of the International Speech
Communication Association (INTERSPEECH).
[40] Samsung. 2020. Unlocks your phone with Bixby Voice. https://www.samsung.
com/us/support/answer/ANS00082783/
[41] Lea Schönherr, Katharina Kohls, Steffen Zeiler, Thorsten Holz, and Dorothea
Kolossa. 2018. Adversarial attacks against automatic speech recognition systems
via psychoacoustic hiding. arXiv preprint arXiv:1808.05665 (2018).
[42] Google Assistant SDK. 2020. Best Practices for Audio. https://developers.google.
com/assistant/sdk/guides/service/python/best-practices/audio.
[43] Suwon Shon, Hao Tang, and James Glass. 2018. Frame-level speaker embeddings
for text-independent speaker recognition and analysis of end-to-end model. In
IEEE Spoken Language Technology Workshop (SLT). IEEE, 1007–1013.
[44] David Snyder, Daniel Garcia-Romero, Gregory Sell, Daniel Povey, and Sanjeev
Khudanpur. 2018. X-vectors: Robust dnn embeddings for speaker recognition. In
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal
Processing (ICASSP). 5329–5333.
[45] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks.
arXiv preprint arXiv:1312.6199 (2013).
[46] Tesla. 2020. Voice Commands. https://www.tesla.com/support/voice-commands.
[47] Jon Vadillo and Roberto Santana. 2019. Universal adversarial examples in speech
command classification. arXiv preprint arXiv:1911.10182 (2019).
[48] Christophe Veaux, Junichi Yamagishi, Kirsten MacDonald, et al. 2017. CSTR VCTK
corpus: English multi-speaker corpus for CSTR voice cloning toolkit. University
of Edinburgh. The Centre for Speech Technology Research (CSTR) (2017).
[49] Pete Warden. 2018. Speech commands: A dataset for limited-vocabulary speech
recognition. arXiv preprint arXiv:1804.03209 (2018).
[50] Weidi Xie, Arsha Nagrani, Joon Son Chung, and Andrew Zisserman. 2019.
Utterance-level aggregation for speaker recognition in the wild. In IEEE In-
ternational Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE,
5791–5795.
[51] Yi Xie, Cong Shi, Zhuohang Li, Jian Liu, Yingying Chen, and Bo Yuan. 2020. Real-
time, Universal, and Robust Adversarial Attacks Against Speaker Recognition
Systems. In Proceedings of the IEEE International Conference on Acoustics, Speech
and Signal Processing (ICASSP).
[52] Hiromu Yakura and Jun Sakuma. 2018. Robust audio adversarial example for a
physical attack. arXiv preprint arXiv:1810.11793 (2018).
[53] Zhuolin Yang, Bo Li, Pin-Yu Chen, and Dawn Song. 2018. Characterizing audio
adversarial examples using temporal dependency. arXiv preprint arXiv:1809.10875
(2018).
[54] Xuejing Yuan, Yuxuan Chen, Yue Zhao, Yunhui Long, Xiaokang Liu, Kai Chen,
Shengzhi Zhang, Heqing Huang, XiaoFeng Wang, and Carl A Gunter. 2018. Com-
mandersong: A systematic approach for practical adversarial voice recognition.
In 27th USENIX Security Symposium (USENIX Security 18). 49–64.
[55] Lei Zhang, Yan Meng, Jiahao Yu, Chong Xiang, Brandon Falk, and Haojin Zhu.
2020. Voiceprint Mimicry Attack Towards Speaker Verification System in Smart
Home. In Proceedings of the IEEE International Conference on Computer Commu-
nications (INFOCOM).
[56] Yingke Zhu, Tom Ko, David Snyder, Brian Mak, and Daniel Povey. 2018. Self-
Attentive Speaker Embeddings for Text-Independent Speaker Verification.. In
Interspeech. 3573–3577.
A APPENDIX
A.1 Speaker Information
Region
Surrey
Cumbria
Southern England
Table 5: Information of each speaker.
ID Age Gender Accents
English
225
English
226
English
227
English
228
229
English
English
230
English
231
English
232
233
English
Scottish
234
23
22
38
22
23
22
23
23
23
22
F
M
M
F
F
F
F
M
F
F
Southern England
Southern England
Stockton-on-tees
Southern England
Southern England
Staffordshire
West Dumfries
Speaker
spk 0
spk 1
spk 2
spk 3
spk 4
spk 5
spk 6
spk 7
spk 8
spk 9
A.2 Frequency Response
Figure 13: Measured frequency response.
A.3 Comparison of Distance Metrics
We performed a preliminary study to evaluate the quality of the
generated adversarial perturbation in terms of the similarity with
the environmental sound template using four distance metrics: (1)
Time Series: the L2 distance between the two time-series signals;
(2) DCT: the L2 distance between the discrete cosine transform of
the two signals; (3) STFT: the L2 distance between the short-time
Fourier transform of the two signals; and (4) MFCC: the L2 distance
between the extracted Mel-frequency cepstral coefficients. We ran-
domly initialized the audio perturbation (the random seed is set to
be the same between trials) and performed a 2000 epoch gradient
descent with a learning rate of 0.001 to minimize each distance. Fig-
ure 14 shows the spectrogram of the original environmental sound
template (bird singing) and the generated audio perturbation using
different distance metrics. As we can see, using Time Series, DCT
and STFT can all effectively produce the adversarial perturbation
that sounds similar to the environmental sound template, rendering
the attack inconspicuous. To shorten the training time5, we chose
to use Time Series as the distance metric.
Figure 14: Spectrogram of the adversarial perturbations gen-
erated using different distance metrics to mimic environ-
mental sound.
A.4 Impact of Attack Distance
We used the setup shown in Figure 15 to study the impact of the
attack distance. As shown in the figure, one participant (p-4) is
asked to sit at one end of the table with a smartphone (i.e., Google
Pixel) and a noise meter (i.e., RISEPRO decibel meter) placed in
front of him, while the loudspeaker is placed at different distances
(i.e., 1 − 5m) with a fixed volume. We asked the participant to first
read out 5 arbitrary speech commands, 10 times each, without
playing adversarial perturbation, to serve as the baseline system
accuracy. Then the participant was asked to read out the same set
of speech commands (10 times for each) while the perturbation
was played from the loudspeaker placed at increasing distances
with its loudness decreasing correspondingly. For reference, we
measured the ambient noise to be around 46 dBSPL, the speech of
the participant to be around 74 − 78 dBSPL, and the baseline system
accuracy to be 90%. Figure 16 shows the resulting attack success
rate and perturbation loudness measured by the noise meter. We
can see that our attack not only achieves a high attack success rate
in the close-distance scenario (e.g., 100% at 1m and 1.5m), but also
maintains a moderate accuracy under far-field settings with rela-
tively strong reverberations (e.g., 68% at 4.5m and 62% at 5m) and
low perturbation loudness that is comparable to the ambient noise
(e.g., 48.4 dBSPL at 5 m). This result demonstrated that by consider-
ing the effects of speaker and microphone limitation, absorption
and reverberation, and ambient noise, the over-the-air optimization
process can indeed provide robust adversarial perturbations.
Figure 15: The dis-
tance study setup.
Figure 16: Attack performance at
varying distances.
5The training time measured on a single NVIDIA GTX 2080Ti GPU: Time Series took
1.035s, DCT took 10.187s, STFT took 10.210s, and MFCC took 16.537s.
020406080Amplitude (dB)210520100502005001k2k5k10kFrequency (Hz)20k0.00.20.402468Frequency (kHz)Original0.00.20.4Time Series0.00.20.4DCT0.00.20.4STFT0.00.20.4MFCCTime (s)LoudspeakerSmartphoneNoise MeterVictim Speaking1.0 m2.0 m3.0 m5.0 m1.01.52.02.53.03.54.04.55.0Distance (m)020406080100Attack Sucess Rate (%)464850525456Perturbation Loudness (dB SPL)Attack Success RatePerturbation Loudness