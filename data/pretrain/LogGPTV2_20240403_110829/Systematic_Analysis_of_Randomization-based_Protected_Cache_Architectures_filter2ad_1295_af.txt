### References

1. Z. B. Aweke, S. F. Yitbarek, R. Qiao, R. Das, M. Hicks, Y. Oren, and T. Austin, “ANVIL: Software-based protection against next-generation Rowhammer attacks,” *ACM SIGPLAN Notices*, 2016.
2. D. J. Bernstein, “Cache-timing attacks on AES,” 2005.
3. A. Bhattacharyya, A. Sandulescu, M. Neugschwandtner, A. Sorniotti, B. Falsaﬁ, M. Payer, and A. Kurmus, “SMoTherSpectre: Exploiting speculative execution through port contention,” in *CCS*, 2019.
4. R. Bodduna, V. Ganesan, P. SLPSK, K. Veezhinathan, and C. Rebeiro, “Brutus: Refuting the security claims of the cache timing randomization countermeasure proposed in CEASER,” in *IEEE CA Letters*, 2020.
5. C. Canella, J. Van Bulck, M. Schwarz, M. Lipp, B. Von Berg, P. Ortner, F. Piessens, D. Evtyushkin, and D. Gruss, “A Systematic Evaluation of Transient Execution Attacks and Defenses,” in *USENIX Security Symposium*, 2019.
6. S. Chari, C. S. Jutla, J. R. Rao, and P. Rohatgi, “Towards sound approaches to counteract power-analysis attacks,” in *CRYPTO*, 1999.
7. M. Green, L. Rodrigues-Lima, A. Zankl, G. Irazoqui, J. Heyszl, and T. Eisenbarth, “AutoLock: Why Cache Attacks on ARM Are Harder Than You Think,” in *USENIX Security Symposium*, 2017.
8. D. Gruss, C. Maurice, A. Fogh, M. Lipp, and S. Mangard, “Prefetch Side-Channel Attacks: Bypassing SMAP and Kernel ASLR,” in *CCS*, 2016.
9. D. Gruss, C. Maurice, K. Wagner, and S. Mangard, “Flush+Flush: A Fast and Stealthy Cache Attack,” in *DIMVA*, 2016.
10. D. Gruss, R. Spreitzer, and S. Mangard, “Cache Template Attacks: Automating Attacks on Inclusive Last-level Caches,” in *USENIX Security Symposium*, 2015.
11. R. Hund, C. Willems, and T. Holz, “Practical Timing Side Channel Attacks against Kernel Space ASLR,” in *S&P*, 2013.
12. M. S. Inci, B. Gulmezoglu, G. Irazoqui, T. Eisenbarth, and B. Sunar, “Cache Attacks Enable Bulk Key Recovery on the Cloud,” in *CHES*, 2016.
13. Intel Corporation, “Pin - A Dynamic Binary Instrumentation Tool,” https://software.intel.com/en-us/articles/binary-instrumentation-tool.
14. Y. Jang, S. Lee, and T. Kim, “Breaking Kernel Address Space Layout Randomization with Intel TSX,” in *CCS*, 2016.
15. T. Kim, M. Peinado, and G. Mainar-Ruiz, “StealthMem: System-level Protection against Cache-based Side Channel Attacks in the Cloud,” in *USENIX Security Symposium*, 2012.
16. V. Kiriansky, I. Lebedev, S. Amarasinghe, S. Devadas, and J. Emer, “DAWG: A Defense Against Cache Timing Attacks in Speculative Execution Processors,” in *MICRO*, 2018.
17. P. Kocher, J. Horn, A. Fogh, D. Genkin, D. Gruss, W. Haas, M. Hamburg, M. Lipp, S. Mangard, T. Prescher, M. Schwarz, and Y. Yarom, “Spectre Attacks: Exploiting Speculative Execution,” in *S&P*, 2019.
18. P. C. Kocher, “Timing Attacks on Implementations of Diffe-Hellman, RSA, DSS, and Other Systems,” in *CRYPTO*, 1996.
19. J. Kong, O. Acıic¸mez, J.-P. Seifert, and H. Zhou, “Hardware-software Integrated Approaches to Defend against Software Cache-based Side Channel Attacks,” in *HPCA*, 2009.
20. M. Lipp, D. Gruss, R. Spreitzer, C. Maurice, and S. Mangard, “ARMageddon: Cache Attacks on Mobile Devices,” in *USENIX Security Symposium*, 2016.
21. M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, A. Fogh, J. Horn, S. Mangard, P. Kocher, D. Genkin, Y. Yarom, and M. Hamburg, “Meltdown: Reading Kernel Memory from User Space,” in *USENIX Security Symposium*, 2018.
22. F. Liu, Q. Ge, Y. Yarom, F. Mckeen, C. Rozas, G. Heiser, and R. B. Lee, “Catalyst: Defeating Last-Level Cache Side Channel Attacks in Cloud Computing,” in *HPCA*, 2016.
23. F. Liu and R. B. Lee, “Random Fill Cache Architecture,” in *MICRO*, 2014.
24. F. Liu, H. Wu, K. Mai, and R. B. Lee, “Newcache: Secure Cache Architecture Thwarting Cache Side-Channel Attacks,” *IEEE Micro*, vol. 36, no. 5, pp. 8–16, Sep. 2016. [Online]. Available: https://doi.org/10.1109/MM.2016.85
25. F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee, “Last-Level Cache Side-Channel Attacks Are Practical,” in *S&P*, 2015.
26. C. Maurice, N. Le Scouarnec, C. Neumann, O. Heen, and A. Francillon, “Reverse Engineering Intel Complex Addressing Using Performance Counters,” in *RAID*, 2015.
27. C. Maurice, C. Neumann, O. Heen, and A. Francillon, “C5: Cross-Cores Cache Covert Channel,” in *DIMVA*, 2015.
28. C. Maurice, M. Weber, M. Schwarz, L. Giner, D. Gruss, C. A. Boano, S. Mangard, and K. Römer, “Hello from the Other Side: SSH over Robust Cache Covert Channels in the Cloud,” in *NDSS*, 2017.
29. A. Moghimi, G. Irazoqui, and T. Eisenbarth, “CacheZoom: How SGX Amplifies the Power of Cache Attacks,” in *CHES*, 2017.
30. J. Monaco, “SoK: Keylogging Side Channels,” in *S&P*, 2018.
31. Y. Oren, V. P. Kemerlis, S. Sethumadhavan, and A. D. Keromytis, “The Spy in the Sandbox: Practical Cache Attacks in JavaScript and Their Implications,” in *CCS*, 2015.
32. D. A. Osvik, A. Shamir, and E. Tromer, “Cache Attacks and Countermeasures: The Case of AES,” in *CT-RSA*, 2006.
33. D. Page, “Theoretical Use of Cache Memory as a Cryptanalytic Side-Channel,” *Cryptology ePrint Archive*, Report 2002/169, 2002.
34. C. Percival, “Cache Missing for Fun and Profit,” in *BSDCan*, 2005.
35. A. Purnal and I. Verbauwhede, “Advanced Profiling for Probabilistic Prime+Probe Attacks and Covert Channels in ScatterCache,” in *arXiv* 1908.03383, 2019.
36. M. K. Qureshi, “CEASER: Mitigating Conflict-based Cache Attacks via Encrypted-address and Remapping,” in *MICRO*, 2018.
37. T. Ristenpart, E. Tromer, H. Shacham, and S. Savage, “Hey, You, Get off of My Cloud: Exploring Information Leakage in Third-party Compute Clouds,” in *CCS*, 2009.
38. D. Sanchez and C. Kozyrakis, “Vantage: Scalable and Efficient Fine-grain Cache Partitioning,” in *ISCA*, 2011.
39. S. Sari, O. Demir, and G. Kucuk, “Fairsdp: Fair and Secure Dynamic Cache Partitioning,” in *International Conference on Computer Science and Engineering (UBMK)*, 2019.
40. D. Skarlatos, M. Yan, B. Gopireddy, R. Sprabery, J. Torrellas, and C. W. Fletcher, “MicroScope: Enabling Microarchitectural Replay Attacks,” in *ISCA*, 2019.
41. R. Spreitzer and T. Plos, “Cache-access Pattern Attack on Disaligned AES T-tables,” in *COSADE*, 2013.
42. D. Trilla, C. Hernandez, J. Abella, and F. J. Cazorla, “Cache Side-channel Attacks and Time-predictability in High-performance Critical Real-time Systems,” in *DAC*, 2018.
43. Y. Tsunoo, T. Saito, and T. Suzaki, “Cryptanalysis of DES Implemented on Computers with Cache,” in *CHES*, 2003.
44. J. Van Bulck, M. Minkin, O. Weisse, D. Genkin, B. Kasikci, F. Piessens, M. Silberstein, T. F. Wenisch, Y. Yarom, and R. Strackx, “Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-order Execution,” in *USENIX Security Symposium*, 2018.
45. J. Van Bulck, F. Piessens, and R. Strackx, “SGX-Step: A Practical Attack Framework for Precise Enclave Execution Control,” in *SysTEX*, 2017.
46. P. Vila, B. Köpf, and J. F. Morales, “Theory and Practice of Finding Eviction Sets,” in *S&P*, 2019.
47. R. Wang and L. Chen, “Futility Scaling: High-associativity Cache Partitioning,” in *MICRO*, 2014.
48. Z. Wang and R. B. Lee, “New Cache Designs for Thwarting Software Cache-based Side Channel Attacks,” in *ISCA*, 2007.
49. Z. Wang and R. B. Lee, “A Novel Cache Architecture with Enhanced Performance and Security,” in *MICRO*, 2008.
50. M. Werner, T. Unterluggauer, L. Giner, M. Schwarz, D. Gruss, and S. Mangard, “SCATTERCACHE: Thwarting Cache Attacks via Cache Set Randomization,” in *USENIX Security Symposium*, 2019.
51. Y. Yarom and K. Falkner, “FLUSH+RELOAD: A High Resolution, Low Noise, L3 Cache Side-channel Attack,” in *USENIX Security Symposium*, 2014.
52. D. Zhang, Y. Wang, G. E. Suh, and A. C. Myers, “A Hardware Design Language for Timing-sensitive Information-flow Security,” *ACM Sigplan Notices*, vol. 50, no. 4, pp. 503–516, 2015.
53. Z. Zhou, M. K. Reiter, and Y. Zhang, “A Software Approach to Defeating Side Channels in Last-level Caches,” in *CCS*, 2016.

### Least Recently Used (LRU) Approximation

For the LRU replacement policy, we derive an approximation for \( p_{c,c} \). Given that \( x \) is cached in partition \( P_l \), and let \( PR \) be the random variable denoting the partition to which \( x \) is reloaded, we have:

\[
P[D|E] = \sum_{i=1}^{n_w} P[D, PR = P_i | E]
\]

\[
P[D, PR = P_i | E] = P[D | PR = P_l, E] \cdot P[P_l | E] + \sum_{i \neq l} P[D | PR = P_i, E] \cdot P[PR = P_i | E]
\]

\[
\approx 1 \cdot 1 + \sum_{i \neq l} p_{c,n} \cdot \frac{1}{P}
\]

Consequently, we obtain the expression from Table III:

\[
p_{c,c} = P[D] \approx p_{c,n} \cdot p_{c,n}(P - 1) + \frac{1}{P}
\]

### Theoretical vs. Experimental Catching Probabilities

Figure 12 provides experimental and visual support for the analysis in Section V-B. Since the attacker cannot directly set \( k' \), we choose \( k \) as the independent variable in Figure 12. However, recall that in Table III, the catching probabilities \( p_c \) are described in terms of \( k' \) for RAND (after pruning) and in terms of \( k \) for LRU (before pruning). The reason is that the prune step does not allow concise statistical modeling.

For RAND, we approximate \( k' \) with \( k \), noting that the exact \( p_c \) in terms of \( k' \) becomes an upper bound in terms of \( k \). We observe that theory matches practice well for \( k \leq 0.6N \), as \( k \approx k' \). The upper bound becomes noticeable for very large \( k \), exactly because \( k' \) and \( k \) diverge.

For LRU, the theoretical expressions were derived as a lower bound. It is a good approximation for low \( k \). For larger \( k \), although prune does not eliminate many elements, it significantly increases \( p_c \) because addresses that were evicted and reintroduced have another attempt at hitting the correct cache set and partition.

In principle, one can also choose \( k > N \) to increase \( p_c \) beyond those depicted in Figure 12, all the way to \( p_c \approx 1 \). However, for such a configuration, the prune step becomes excessive, both for RAND and LRU. It will require a large number of non-aggressive iterations to avoid shrinking \( k' \) too fast, followed by many aggressive iterations until there are no more self-evictions. As a result, the cache accesses needed to terminate the prune step are significant.

### Known-Plaintext AES T-Tables Attack

We implement the "One-Round Attack" proposed by Osvik et al. [34]. Because their work already describes the attack in detail, we provide only a high-level overview and discuss implications for our cache model.

In the T-tables implementation of 128-bit AES, each of the first 9 rounds accesses all 4 T-tables 4 times each. Per round, one access is made for each key byte and plaintext byte pair \( pi \oplus ki \) to table \( Tj \), where \( j \equiv i \mod 4 \) and \( i \in [0..15] \). T-tables consist of 256 entries of 4 bytes each, but as cache lines are typically 64 bytes in size, we can consider them arrays of 16 entries each, addressed by the upper nibble of \( pi \oplus ki \). Thus, entries \( Tj[\lfloor pi \oplus ki \rfloor_4] \) will always be accessed in round 1, while other entries may be accessed in later rounds. This produces the statistical difference we exploit.

We construct a matrix \( M \) of 16 × 16 bins, where columns represent the key byte position \( i \), and rows the upper key nibble candidate \( \lfloor ki \rfloor_4 \). Because of the table association mentioned before, table \( Tj \) produces columns \( M*,i \). We now measure accesses to our probe sets \( Aj,l \), \( l \in [0..15] \) for all 16 addresses of each table, and simply add the resulting amount of misses from each probe set to a bin for each plaintext byte: \( M[l \oplus pi, i] += \text{misses}(Aj,l) \). The key nibbles are now the highest value in each column. Depending on the size and quality of the probe sets, this takes several thousand random plaintexts. Figure 13 shows the matrix for a successful attack.

The noteworthy part for our attack is that, for uniformly distributed random plaintexts, each table address contributes equally to each bin in the appropriate columns of \( M \). For this reason, this attack absorbs differences in probe set sizes.

### Appendix

#### Relation between \( k \), \( k' \), and \( mpr \)

Figure 11 experimentally relates pruning parameters \( k \), \( k' \), and \( mpr \) for different cache instances. It shows that the prune step does not shrink the initial set much (\( k' \approx k \)), unless \( k \) is very large. We also observe that instances with stateful replacement policy (LRU) require fewer pruning iterations \( mpr \) than those with random replacement. Furthermore, they generally end up with a larger set after pruning (\( k' \)).

#### Penalty for a Cached Target

We now derive the catching probability for a target address \( x \) that is already cached. Recall that, to detect an access to \( x \), the attacker must first evict it from the cache and detect its reintroduction. Let \( E \) denote the event that the PRIME+PRUNE+PROBE iteration successfully evicts \( x \) from the cache, and \( D \) the event that probe detects an access to \( x \) when it is reloaded. Given that \( P[D, \neg E] = 0 \), we have:

\[
p_{c,c} = P[D] = P[D, E] = P[D|E] \cdot P[E]
\]

**1. Random Replacement:**

\[
P[E] = p_{c,n}(k')
\]

Recall that for RAND, the target \( x \) has \( n_w \) potential cache lines to which it can be mapped. Let \( I \) denote the number of those locations that the PRIME+PRUNE+PROBE iteration occupies.

\[
P[D|E] = \sum_{i=0}^{n_w} P[D, I = i | E]
\]

\[
P[D, I = i | E] = P[D | E, I = i] \cdot P[I = i | E]
\]

\[
= \binom{n_w}{i} \left( \frac{k'}{N} \right)^i \left( 1 - \frac{k'}{N} \right)^{n_w - i} \cdot \frac{i^2 \cdot k'^i \cdot (N - k')^{n_w - i}}{N^{n_w}}
\]

Consequently, we obtain the expression from Table III:

\[
p_{c,c} = P[D] = \sum_{i=1}^{n_w} \frac{i^2 \cdot k'^i \cdot (N - k')^{n_w - i}}{N^{n_w}}
\]

**2. LRU:**

For LRU, the theoretical expressions were derived as a lower bound. It is a good approximation for low \( k \). For larger \( k \), although prune does not eliminate many elements, it significantly increases \( p_c \) because addresses that were evicted and reintroduced have another attempt at hitting the correct cache set and partition.