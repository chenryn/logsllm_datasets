[2] Z. B. Aweke, S. F. Yitbarek, R. Qiao, R. Das, M. Hicks, Y. Oren, and
T. Austin, “ANVIL: Software-based protection against next-generation
Rowhammer attacks,” ACM SIGPLAN Notices, 2016.
[3] D. J. Bernstein, “Cache-timing attacks on aes,” 2005.
[4] A. Bhattacharyya, A. Sandulescu, M. Neugschwandtner, A. Sorniotti,
B. Falsaﬁ, M. Payer, and A. Kurmus, “SMoTherSpectre: exploiting
speculative execution through port contention,” in CCS, 2019.
[5] R. Bodduna, V. Ganesan, P. SLPSK, K. Veezhinathan, and C. Rebeiro,
“Brutus: Refuting the security claims of the cache timing randomization
countermeasure proposed in CEASER,” in IEEE CA Letters, 2020.
[6] C. Canella, J. Van Bulck, M. Schwarz, M. Lipp, B. Von Berg, P. Ortner,
F. Piessens, D. Evtyushkin, and D. Gruss, “A Systematic Evaluation
of Transient Execution Attacks and Defenses,” in USENIX Security
Symposium, 2019.
[7] S. Chari, C. S. Jutla, J. R. Rao, and P. Rohatgi, “Towards sound
approaches to counteract power-analysis attacks,” in CRYPTO, 1999.
[8] M. Green, L. Rodrigues-Lima, A. Zankl, G. Irazoqui, J. Heyszl, and
T. Eisenbarth, “AutoLock: Why Cache Attacks on ARM Are Harder
Than You Think,” in USENIX Security Symposium, 2017.
[9] D. Gruss, C. Maurice, A. Fogh, M. Lipp, and S. Mangard, “Prefetch
Side-Channel Attacks: Bypassing SMAP and Kernel ASLR,” in CCS,
2016.
Software-Induced Fault Attack in JavaScript,” in DIMVA, 2016.
[11] D. Gruss, C. Maurice, K. Wagner, and S. Mangard, “Flush+Flush: A
Fast and Stealthy Cache Attack,” in DIMVA, 2016.
[12] D. Gruss, R. Spreitzer, and S. Mangard, “Cache Template Attacks:
Automating Attacks on Inclusive Last-level Caches,” in USENIX Security
Symposium, 2015.
[13] R. Hund, C. Willems, and T. Holz, “Practical Timing Side Channel
Attacks against Kernel Space ASLR,” in S&P, 2013.
[14] M. S. Inci, B. Gulmezoglu, G. Irazoqui, T. Eisenbarth, and B. Sunar,
“Cache Attacks Enable Bulk Key Recovery on the Cloud,” in CHES,
2016.
[15] Intel
Corporation,
- A Dynamic
Instru-
https://software.intel.com/en-us/articles/
Binary
mentation
pin-a-dynamic-binary-instrumentation-tool.
Tool,”
“Pin
[16] Y. Jang, S. Lee, and T. Kim, “Breaking Kernel Address Space Layout
Randomization with Intel TSX,” in CCS, 2016.
[17] T. Kim, M. Peinado, and G. Mainar-Ruiz, “StealthMem: system-level
protection against cache-based side channel attacks in the cloud,” in
USENIX Security Symposium, 2012.
[18] V. Kiriansky, I. Lebedev, S. Amarasinghe, S. Devadas, and J. Emer,
“DAWG: A Defense Against Cache Timing Attacks in Speculative
Execution Processors,” MICRO, 2018.
[19] P. Kocher, J. Horn, A. Fogh, D. Genkin, D. Gruss, W. Haas, M. Hamburg,
M. Lipp, S. Mangard, T. Prescher, M. Schwarz, and Y. Yarom, “Spectre
Attacks: Exploiting Speculative Execution,” in S&P, 2019.
[20] P. C. Kocher, “Timing Attacks on Implementations of Diffe-Hellman,
RSA, DSS, and Other Systems,” in CRYPTO, 1996.
[21] J. Kong, O. Acıic¸mez, J.-P. Seifert, and H. Zhou, “Hardware-software
integrated approaches to defend against software cache-based side channel
attacks,” in HPCA, 2009.
[22] M. Lipp, D. Gruss, R. Spreitzer, C. Maurice, and S. Mangard, “AR-
Mageddon: Cache Attacks on Mobile Devices,” in USENIX Security
Symposium, 2016.
[23] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, A. Fogh,
J. Horn, S. Mangard, P. Kocher, D. Genkin, Y. Yarom, and M. Hamburg,
“Meltdown: Reading Kernel Memory from User Space,” in USENIX
Security Symposium, 2018.
[24] F. Liu, Q. Ge, Y. Yarom, F. Mckeen, C. Rozas, G. Heiser, and R. B.
Lee, “Catalyst: Defeating last-level cache side channel attacks in cloud
computing,” in HPCA, 2016.
[25] F. Liu and R. B. Lee, “Random Fill Cache Architecture,” in MICRO,
2014.
[26] F. Liu, H. Wu, K. Mai, and R. B. Lee, “Newcache: Secure
cache architecture thwarting cache side-channel attacks,” IEEE
Micro, vol. 36, no. 5, pp. 8–16, Sep. 2016. [Online]. Available:
https://doi.org/10.1109/MM.2016.85
[27] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee, “Last-Level Cache
Side-Channel Attacks Are Practical,” in S&P, 2015.
[28] C. Maurice, N. Le Scouarnec, C. Neumann, O. Heen, and A. Francillon,
“Reverse Engineering Intel Complex Addressing Using Performance
Counters,” in RAID, 2015.
[29] C. Maurice, C. Neumann, O. Heen, and A. Francillon, “C5: Cross-Cores
Cache Covert Channel,” in DIMVA, 2015.
[30] C. Maurice, M. Weber, M. Schwarz, L. Giner, D. Gruss, C. A. Boano,
S. Mangard, and K. R¨omer, “Hello from the Other Side: SSH over
Robust Cache Covert Channels in the Cloud,” in NDSS, 2017.
[31] A. Moghimi, G. Irazoqui, and T. Eisenbarth, “Cachezoom: How SGX
ampliﬁes the power of cache attacks,” in CHES, 2017.
[32] J. Monaco, “SoK: Keylogging Side Channels,” in S&P, 2018.
[33] Y. Oren, V. P. Kemerlis, S. Sethumadhavan, and A. D. Keromytis, “The
Spy in the Sandbox: Practical Cache Attacks in JavaScript and Their
Implications,” in CCS, 2015.
[34] D. A. Osvik, A. Shamir, and E. Tromer, “Cache attacks and countermea-
sures: The case of aes,” in CT-RSA, 2006.
[35] D. Page, “Theoretical use of cache memory as a cryptanalytic side-
channel,” Cryptology ePrint Archive, Report 2002/169, 2002.
[36] C. Percival, “Cache missing for fun and proﬁt,” in BSDCan, 2005.
[37] A. Purnal and I. Verbauwhede, “Advanced Proﬁling for Probabilistic
Prime+Probe Attacks and Covert Channels in ScatterCache,” in arXiv
1908.03383, 2019.
[38] M. K. Qureshi, “CEASER: Mitigating Conﬂict-based Cache Attacks via
Encrypted-address and Remapping,” in MICRO, 2018.
2019.
[40] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage, “Hey, You, Get off
of My Cloud: Exploring Information Leakage in Third-party Compute
Clouds,” in CCS, 2009.
[41] D. Sanchez and C. Kozyrakis, “Vantage: scalable and efﬁcient ﬁne-grain
cache partitioning,” in ISCA, 2011.
[42] S. Sari, O. Demir, and G. Kucuk, “Fairsdp: Fair and secure dynamic
cache partitioning,” in International Conference on Computer Science
and Engineering (UBMK), 2019.
[43] D. Skarlatos, M. Yan, B. Gopireddy, R. Sprabery, J. Torrellas, and C. W.
Fletcher, “MicroScope: Enabling Microarchitectural Replay Attacks,” in
ISCA, 2019.
[44] R. Spreitzer and T. Plos, “Cache-access pattern attack on disaligned aes
t-tables,” in COSADE, 2013.
[45] D. Trilla, C. Hernandez, J. Abella, and F. J. Cazorla, “Cache Side-channel
Attacks and Time-predictability in High-performance Critical Real-time
Systems,” in DAC, 2018.
[46] Y. Tsunoo, T. Saito, and T. Suzaki, “Cryptanalysis of DES implemented
on computers with cache,” in CHES, 2003.
[47] J. Van Bulck, M. Minkin, O. Weisse, D. Genkin, B. Kasikci, F. Piessens,
M. Silberstein, T. F. Wenisch, Y. Yarom, and R. Strackx, “Foreshadow:
Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-
order Execution,” in USENIX Security Symposium, 2018.
[48] J. Van Bulck, F. Piessens, and R. Strackx, “SGX-Step: A Practical Attack
Framework for Precise Enclave Execution Control,” in SysTEX, 2017.
[49] P. Vila, B. K¨opf, and J. F. Morales, “Theory and Practice of Finding
[50] R. Wang and L. Chen, “Futility scaling: High-associativity cache
Eviction Sets,” in S&P, 2019.
partitioning,” in MICRO, 2014.
[51] Z. Wang and R. B. Lee, “New cache designs for thwarting software
cache-based side channel attacks,” in ISCA, 2007.
[52] ——, “A novel cache architecture with enhanced performance and
security,” in MICRO, 2008.
[53] M. Werner, T. Unterluggauer, L. Giner, M. Schwarz, D. Gruss, and
S. Mangard, “SCATTERCACHE: Thwarting Cache Attacks via Cache
Set Randomization,” in USENIX Security Symposium, 2019.
[54] Y. Yarom and K. Falkner, “FLUSH+RELOAD: A High Resolution, Low
Noise, L3 Cache Side-channel Attack,” in USENIX Security Symposium,
2014.
[55] D. Zhang, Y. Wang, G. E. Suh, and A. C. Myers, “A hardware design
language for timing-sensitive information-ﬂow security,” ACM Sigplan
Notices, vol. 50, no. 4, pp. 503–516, 2015.
[56] Z. Zhou, M. K. Reiter, and Y. Zhang, “A software approach to defeating
side channels in last-level caches,” in CCS, 2016.
2) Least recently used (LRU): For LRU, we derive an
approximation for pc,c. We have that P [E] = pc,n. Assume
that x is cached in partition Pl, and let PR be the random
variable denoting the partition to which x is reloaded.
P [D|E] =
nw(cid:88)
(law of total probability)
P [D, PR = Pi|E]
i=1
P [D, PR = Pi|E]
= P [D, PR = Pl|E] +
= P [D|PR = Pl, E] · P [Pl|E] +
(cid:88)
i(cid:54)=l
(cid:88)
i(cid:54)=l
≈ 1 · 1
P
+
(cid:88)
i(cid:54)=l
pc,n · 1
P
Consequently, we obtain the expression from Table III:
pc,c = P [D] ≈ pc,n · pc,n(P − 1) + 1
P
P [D|PR = Pi, E] · P [PR = Pi|E]
(conditional)
C. Theoretical vs. experimental catching probabilities
Figure 12 presents experimental and visual support for the
analysis in Section V-B. Since the attacker cannot directly
set k(cid:48), we choose k as the independent variable in Figure 12.
However, recall that in Table III, the catching probabilities pc
are described in terms of k(cid:48) for RAND, i.e., after pruning, and
in terms of k for LRU, i.e., before pruning. The reason is that
the prune step does not allow concise statistical modeling.
Hence, for RAND, we approximate k(cid:48) with k, noting that the
exact pc in terms of k(cid:48) becomes an upper bound in terms of k.
We observe theory to match practice very well for k ≤ 0.6N, as
k ≈ k(cid:48) (cf. Appendix A). The upper bound becomes noticeable
for very large k, exactly because k(cid:48) and k diverge.
For LRU, the theoretical expressions were derived as a lower
bound (cf. Section V-B1). It is a good approximation for low
k. For larger k, although prune does not eliminate a lot
of elements (cf. Appendix A), it increases pc signiﬁcantly
because addresses that were evicted and reintroduced have
another attempt at hitting the correct cache set and partition.
In principle, one can also choose k > N to increase pc
beyond those depicted in Figure 12, all the way to pc ≈ 1.
However, for such a conﬁguration, the prune step becomes
excessive, both for RAND and LRU. It will require a large
number of non-aggressive iterations to avoid shrinking k(cid:48) too
fast (cf. Appendix A), followed by many aggressive iterations
until there are no more self-evictions. As a result, the cache
accesses needed to terminate the prune step are signiﬁcant.
D. Known-Plaintext AES T-Tables Attack
We implement the ”One-Round Attack” proposed by Osvik
et al.
[34]. Because their work already describes the attack
in detail, we only add a high-level overview here and discuss
implications for our cache model.
In the T-tables implementation of 128-bit AES, each of the
ﬁrst 9 rounds accesses all 4 T-tables 4 times each. Per round,
one access is made for each key byte and plaintext byte pair
Fig. 11: Empirical k(cid:48) and mpr (means over 105 runs) for different k. Cache
instances are denoted RP(nw, b, P ). The prune step becomes aggressive
from the sixth iteration, if not already terminated.
APPENDIX
A. Relation between k. k(cid:48) and mpr
Figure 11 experimentally (cf. Section III-A3) relates pruning
parameters k, k(cid:48) and mpr for different cache instances.
that much (k(cid:48) ≈ k), unless k is very large.
It shows that the prune step does not shrink the initial set
We also observe that instances with stateful replacement
policy (LRU) require fewer pruning iterations mpr than those
with random replacement. Furthermore, they generally end up
with a larger set after pruning (k(cid:48)).
B. Penalty for a cached target
We now derive the catching probability for a target address
x that is already cached. Recall that, to detect an access to x,
the attacker must ﬁrst evict it from the cache, and detect its
reintroduction in the cache. Let E denote the event that the
PRIME+PRUNE+PROBE iteration successfully evicts x from
the cache, and D the event that probe detects an access to x
when it is reloaded. Given that P [D,(cid:101)E] = 0 we have that
pc,c = P [D] = P [D, E] = P [D|E] · P [E]
1) Random replacement: We have that P [E] = pc,n(k(cid:48)).
Recall that for RAND, the target x has nw potential cache lines
to which it can be mapped. Let I denote the number of those
locations that the PRIME+PRUNE+PROBE iteration occupies.
P [D|E] =
(law of total probability)
P [D, I = i|E]
i=0
nw(cid:88)
nw(cid:88)
nw(cid:88)
nw(cid:88)
i=0
i=0
i=0
=
=
=
(conditional)
i
nw
P [D|E, I = i] · P [I = i|E])
· P [E|I = i] · P [I = i]
·(cid:0)nw
(cid:1) k(cid:48)i(N−k(cid:48))nw−i
(cid:19) i2 · k(cid:48)i · (N − k(cid:48))nw−i
(cid:18)nw
nw(cid:88)
i
nw
P [E]
P [E]
i
nw
N nw
·
i
(Bayes’ rule)
(binomial pmf)
Consequently, we obtain the expression from Table III:
pc,c = P [D] =
i
i=1
w · N nw
n2
(a) RAND (P = 16)
(b) LRU (P = 2)
e
t
a
d
i
d
n
a
c
e
l
b
b
i
n
y
e
k
key byte ki
Fig. 13: Result of the AES T-tables attack. Columns normed to the highest
value. The partial key can be read from left to right by the darkest ﬁeld in
each column. Pictured: Key=0x00102030405060708090a0b0c0d0e0f0
from each probe set to a bin for each plaintext byte: M [l ⊕
pi, i] += misses(Aj,l). The key nibbles are now the highest
value in each column. Depending on the size and quality of
the probe sets, this takes several thousand random plaintexts.
Figure 13 shows the matrix for a successful attack.
The noteworthy part for our attack is that, for uniformly
distributed random plaintexts, each table address contributes
equally to each bin in the appropriate columns of M. For this
reason, this attack absorbs differences in probe set sizes.
(c) LRU (P = 4)
Fig. 12: Catching probabilities for cached and uncached targets in theory and
practice. Experimental results obtained from simulating a standalone 8MB
randomized cache (nw = 16, b = 13), averaged over 105 runs. The prune
step becomes aggressive from the sixth iteration, if not already terminated.
pi ⊕ ki to table Tj, j ≡ i mod 4, i ∈ [0..15]. T-tables consist
of 256 entries of 4 bytes each, but as cache lines are typically
64 bytes in size, we can consider them arrays of 16 entries
each, addressed by the upper nibble of pi ⊕ ki. Thus entries
Tj[(cid:100)pi ⊕ ki(cid:101)4] will always be accessed in round 1, while other
entries may be accessed in later rounds. This produces the
statistical difference we exploit.
We construct a matrix M of 16 × 16 bins, where columns
represent the key byte position i, and rows the upper key nibble
candidate (cid:100)ki(cid:101)4. Because of the table association mentioned
before, table Tj produces columns M∗,i. We now measure
accesses to our probe sets Aj,l, l ∈ [0..15] for all 16 addresses
of each table, and simply add the resulting amount of misses