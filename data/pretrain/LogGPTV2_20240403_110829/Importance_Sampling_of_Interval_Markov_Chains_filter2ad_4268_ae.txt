### Failure State and Repair Model

A failure state of the system is repaired in approximately five step units. We aim to estimate the probability \(\gamma\) that the water level, as indicated by LIT301, will exceed a threshold (greater than 800) within the next 30 step units. The exact value of \(\gamma\) is unknown but is expected to be small. Experimental results suggest that \(\gamma(\hat{A}) \in [5 \times 10^{-3}; 2.5 \times 10^{-2}]\).

### Figures and Results

**Figure 2: Repair Model**
- Superposition of independent Importance Sampling (IS, red, thick) and Improved Monte Carlo Importance Sampling (IMCIS, blue, thin) 95% confidence intervals.
- The black line indicates \(\gamma = 1.179 \times 10^{-7}\).

**Figure 4: Water Treatment Model**
- Independent IS (red, thick) and IMCIS (blue, thin) 99% confidence intervals.

**Figure 3: Repair Model**
- Evolution of the IMCIS confidence interval bounds during the optimization step.
- The x-axis is in log scale to highlight the rapid changes in the first few iterations.

**Results and Analysis**
- Figure 4 shows that IS is unreliable, as the (red) IS confidence intervals do not even intersect (see the first two red CIs).
- In contrast, IMCIS (blue) provides more consistent results.
- The union of the IS confidence intervals is a subinterval of most of the IMCIS confidence intervals.
- Given the larger width of the IMCIS confidence intervals, which offers a higher chance of capturing the exact probability \(\gamma\), we recommend using IMCIS for estimating critical events in Cyber-Physical Systems (CPS).

### Conclusion

This paper introduces importance sampling in an Interval Markov Chain (IMC) setting to account for the margins of error inherent in approximated models. The goal is to provide more reliable confidence intervals for dependable properties in rare event contexts, defined with respect to the original system. We propose an algorithm based on random search optimization using Dirichlet distributions to achieve this. Although full validity has not been achieved, our results are promising and show significant improvements over similar importance sampling approaches in Discrete-Time Markov Chains (DTMC) settings. This framework is novel and raises several challenging questions, including comparing the current algorithm with other optimization schemes and defining the best importance sampling distribution in the IMC setting. Future work will focus on improving the learning of probabilistic systems and applying our approach to larger CPS.

### Acknowledgment

This work was supported in part by the National Research Foundation (NRF), Prime Minister’s Office, Singapore, under its National Cybersecurity R&D Programme (Award No. NRF2014NCR-NCR001-040) and administered by the National Cybersecurity R&D Directorate.

### References

[1] Secure Water Treatment (SWaT) Testbed. https://itrust.sutd.edu.sg/research/testbeds/secure-water-treatment-swat/

[2] Benoît Barbot, Serge Haddad, and Claudine Picaronny. Coupling and Importance Sampling for Statistical Model Checking. In Tools and Algorithms for the Construction and Analysis of Systems - 18th International Conference, TACAS, pages 331–346, 2012.

[3] Anicet Bart, Benoît Delahaye, Didier Lime, Eric Monfroy, and Charlotte Truchet. Reachability in parametric interval Markov chains using constraints. In Quantitative Evaluation of Systems - 14th International Conference, QEST 2017, Berlin, Germany, September 5-7, 2017, Proceedings, pages 173–189, 2017.

[4] Michael Benedikt, Rastislav Lenhardt, and James Worrell. LTL model checking of interval Markov chains. In Tools and Algorithms for the Construction and Analysis of Systems - 19th International Conference, TACAS 2013, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2013, Rome, Italy, March 16-24, 2013. Proceedings, pages 32–46, 2013.

[5] Peter Carbonetto, Mark W. Schmidt, and Nando de Freitas. An interior-point stochastic approximation method and an L1-regularized delta rule. In Advances in Neural Information Processing Systems 21, Proceedings of the Twenty-Second Annual Conference on Neural Information Processing Systems, Vancouver, British Columbia, Canada, December 8-11, 2008, pages 233–240, 2008.

[6] Herman Chernoff. A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations. Ann. Math. Statist., 23(4):493–507, 1952.

[7] Edmund M. Clarke and Paolo Zuliani. Statistical Model Checking for Cyber-Physical Systems. In Automated Technology for Verification and Analysis, 9th International Symposium, ATVA 2011, Taipei, Taiwan, October 11-14, 2011. Proceedings, pages 1–12, 2011.

[8] G. Cochran. Laplace’s ratio estimator. In Contributions to survey sampling and applied statistics, pages 3–10. Academic Press, 1978.

[9] Costas Courcoubetis and Mihalis Yannakakis. Verifying temporal properties of finite-state probabilistic programs. In 29th Annual Symposium on Foundations of Computer Science, White Plains, New York, USA, 24-26 October 1988, pages 338–345, 1988.

[10] Benoît Delahaye, Kim G. Larsen, Axel Legay, Mikkel L. Pedersen, and Andrzej Wasowski. Consistency and refinement for interval Markov chains. J. Log. Algebr. Program., 81(3):209–226, 2012.

[11] William A Gale and Geoffrey Sampson. Good-Turing frequency estimation without tears. Journal of Quantitative Linguistics, 2(3):217–237, 1995.

[12] Thomas Hérault, Richard Lassaigne, Frédéric Magniette, and Sylvain Peyronnet. Approximate probabilistic model checking. In Bernhard Steffen and Giorgio Levi, editors, Verification, Model Checking, and Abstract Interpretation, volume 2937 of LNCS, pages 307–329. Springer, 2004.

[13] Cyrille Jegourel, Axel Legay, and Sean Sedwards. Importance splitting for statistical model checking rare properties. In Natasha Sharygina and Helmut Veith, editors, Computer Aided Verification, volume 8044 of LNCS, pages 576–591. Springer, 2013.

[14] Cyrille Jegourel, Axel Legay, and Sean Sedwards. Command-based importance sampling for statistical model checking. Theor. Comput. Sci., 649:1–24, 2016.

[15] Sumit Kumar Jha, Edmund M. Clarke, Christopher James Langmead, Axel Legay, André Platzer, and Paolo Zuliani. A Bayesian approach to model checking biological systems. In Computational Methods in Systems Biology, 7th International Conference, CMSB 2009, Bologna, Italy, August 31-September 1, 2009. Proceedings, pages 218–234, 2009.

[16] Bengt Jonsson and Kim Guldstrand Larsen. Specification and refinement of probabilistic processes. In Proceedings of the Sixth Annual Symposium on Logic in Computer Science (LICS ’91), Amsterdam, The Netherlands, July 15-18, 1991, pages 266–277, 1991.

[17] Marta Z. Kwiatkowska, Gethin Norman, and David Parker. PRISM 2.0: A Tool for Probabilistic Model Checking. In QEST, pages 322–323. IEEE, 2004.

[18] Tze Leung Lai. Stochastic Approximation. The Annals of Statistics, 31(2):391–406, April 2003.

[19] Arkadi S. Nemirovski and Michael J. Todd. Interior-point methods for optimization. Acta Numerica, 17:191–234, May 2008.

[20] G. Norman, D. Parker, M. Kwiatkowska, and S. Shukla. Evaluating the reliability of NAND multiplexing with PRISM. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 24(10):1629–1637, 2005.

[21] Masashi Okamoto. Some Inequalities Relating to the Partial Sum of Binomial Probabilities. Annals of the Institute of Statistical Mathematics, 10:29–35, 1958.

[22] Martin L. Puterman. Markov Decision Processes. Wiley, 1994.

[23] Daniël Reijsbergen, Pieter-Tjerk de Boer, Werner R. W. Scheinhardt, and Boudewijn R. Haverkort. Rare Event Simulation for Highly Dependable Systems with Fast Repairs. In QEST 2010, Seventh International Conference on the Quantitative Evaluation of Systems, Williamsburg, Virginia, USA, 15-18 September 2010, pages 251–260, 2010.

[24] Ad Ridder. Importance sampling simulations of Markovian reliability systems using cross-entropy. Annals of Operations Research, 134:119–136, 2005.

[25] Gerardo Rubino and Bruno Tuffin, editors. Rare Event Simulation using Monte Carlo Methods. Wiley, 2009.

[26] J. Spall. Introduction to Stochastic Search and Optimization. Wiley, 2003.

[27] Moshe Y. Vardi. Automatic verification of probabilistic concurrent finite-state programs. In 26th Annual Symposium on Foundations of Computer Science, Portland, Oregon, USA, 21-23 October 1985, pages 327–338, 1985.

[28] Abraham Wald. Sequential tests of statistical hypotheses. The Annals of Mathematical Statistics, 16(2):117–186, 1945.

[29] H. Younes. Verification and Planning for Stochastic Processes with Asynchronous Events. PhD thesis, Carnegie Mellon University, 2004.

[30] Lijun Zhang, Holger Hermanns, and David N. Jansen. Logic and model checking for hidden Markov models. In Formal Techniques for Networked and Distributed Systems - FORTE 2005, 25th IFIP WG 6.1 International Conference, Taipei, Taiwan, October 2-5, 2005, Proceedings, pages 98–112, 2005.

### Appendix

Various optimization algorithms can be used in our context, with their efficiency measured in terms of convergence speed. Since the objective function is unlikely to be linear or at most quadratic, only non-linear algorithms are considered. However, since the constraints are linear, statistical convex optimization methods are relevant to our problem.

#### 1. Stochastic Gradient Descent [18]
- A stochastic approximation of the gradient descent optimization method for minimizing an objective function written as a sum of differentiable functions, i.e., \( f(A) = \sum_{k=1}^{M} L(\omega_k; A) \), where \(\omega_k\) is the k-th successful path, \(A \in [\hat{A}]\), and \(L(\omega; A)\) denotes the likelihood of path \(\omega\) given the original probabilistic measure \(A\).
- In the standard gradient descent, \(A(0) = \hat{A}\) and the parameter \(A(j)\) is updated at iteration \(j + 1\) by:
  \[
  A(j+1) = A(j) - \eta \nabla f(A(j))
  \]
- In the stochastic gradient descent, the gradient \(\nabla f(A(j))\) is approximated by the gradient of only one sample:
  \[
  A(j+1) = A(j) - \eta \nabla L(\omega_k; A(j))
  \]
  where \(\omega_k\) is chosen randomly from the set of sampled successful paths.
- The main advantage of the stochastic gradient descent is that the gradient of a sample is easy to calculate since \(L(\omega_k; A(j))\) has a polynomial form.
- However, \(A(j+1)\) does not satisfy the equality constraints. After re-normalization, the equality constraints are satisfied, but not necessarily the inequality constraints. A projection into \([\hat{A}]\) is necessary after each iteration, which implies significant time overhead.

#### 2. Stochastic Interior Point Method [5]
- More suited for dealing with inequality constraints, as it directly finds an update within \([\hat{A}]\) using the logarithmic barrier method.
- The constrained optimization problem is rewritten as an unconstrained optimization problem:
  \[
  \text{minimize } f(A) - \sum_{i=0}^{m} \lambda_i c_i - \sum_{i=0}^{m} \sum_{j=0}^{m} \mu_{ij} \log(c_{ij}^- - a_{ij}) - \sum_{i=0}^{m} \sum_{j=0}^{m} \mu_{ij} \log(c_{ij}^+ - a_{ij})
  \]
  where each \(\lambda_i\) is a Lagrange multiplier assigned to the constraint, and \(\mu_{ij} > 0\) are the barrier parameters.
- The authors in [5] propose an approximation of the minimum using a stochastic version of the interior point method. However, the number of constraints may be large, slowing down the solving of the resulting system of equations. Solving the system of polynomial equations enriched with one Lagrangian multiplier per constraint quickly becomes intractable with respect to the number of states. Moreover, a proof of convergence is still missing according to the authors.

### Prism Code for the Repair Benchmark

We provide the code for the Prism model and the property under investigation. The parameter \(\alpha\) must be set by the user.

```prism
ctmc

const int n = 4;
const double alpha = 0.1;
const double alpha2 = alpha * alpha;
const double mu = 1.0;

module type1
    state1 : [0..n] init 0;
    [] state1 < n -> (n - state1) * alpha2 : (state1' = state1 + 1);
    [] state1 >= 2 -> mu : (state1' = 0);
endmodule

module type2
    state2 : [0..n] init 0;
    [] state2 < n -> (n - state2) * alpha : (state2' = state2 + 1);
    [] state2 >= 2 & state1 >= 2 -> mu : (state2' = 0);
endmodule

module type3
    state3 : [0..n] init 0;
    [] state3 < n -> (n - state3) * alpha : (state3' = state3 + 1);
    [] state3 > 0 & state2 >= 2 -> mu : (state3' = state3 - 1);
endmodule

label "failure" = state1 = n & state2 = n & state3 = n;

property P=?["init" & (X !"init" U "failure")]
```

2The convergence was initially established in the appendix of [5], but the authors admitted on their webpage (https://pcarbo.github.io) a “major flaw” in the convergence proof. Therefore, the convergence is still an open question.