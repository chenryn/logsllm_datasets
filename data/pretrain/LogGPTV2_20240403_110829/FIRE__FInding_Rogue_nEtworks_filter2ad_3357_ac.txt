18
-
6
-
5
-
-
-
-
-
-
[9]
[12]
[8]
Table 1: FIRE Top 10 for June 1st, 2009
ASN
AS23522
AS3265
AS25761
AS30058
AS174
AS2108
AS31800
AS13301
AS790
AS35908
ShadowServer Botnet C&Cs
FIRE
Name
Rank
Large
Network
ASN
Name
Google Safe Browsing
FIRE
Rank
Large
Network
GigeNET
XS4ALL
Staminus Comm
FDCservers.net
Cogent
Croatian Research
DALnet
Unitedcolo.de
EUnet Finland
SWIFT Ventures
1
118
-
-
148
-
-
86
-
68
X
X
X
AS4134
AS21844
AS4837
AS36351
AS26496
AS41075
AS4812
AS10929
AS28753
AS8560
Chinanet Backbone No.31
ThePlanet.com
China169 Backbone
SoftLayer Technologies
GoDaddy.com
ATW Internet Kft.
Chinanet-SH-AP Telecom
Netelligent Hosting
Netdirect
1&1 Internet AG
17
13
90
30
15
23
89
12
11
-
X
X
X
X
X
Table 2: ShadowServer Botnets / Google Safe Browsing Top 10 for June 1st, 2009
We then add to this value the number of those ASNs
that appear in both rankings but that have a different
number of rogue IPs.
We used our metric to understand the inﬂuence of
different threshold values on the result. To this end,
we ﬁrst calculated a ranking for a small threshold
value. Then, we iteratively increased the threshold by
a small value, recalculating the rankings at each step.
Finally, we compare the rankings between each pair of
subsequent steps. The idea is to see whether rankings
eventually “stabilize,” or whether they continuously
ﬂuctuate, depending on the speciﬁc values for δ.
We applied our analysis to all three data sources,
ranging the threshold δ from 0 to 9. This was done
for each day since January 1st, 2009, and the results
were averaged. Figure 5 shows the results. Figures 5a
and 5b indicate that for phishing servers and botnet
control servers, there is signiﬁcant ﬂuctuation when
threshold values are low. This is a direct result of the
fact that these data sources contain many compromised
servers that are taken ofﬂine after only one or two days
by vigilant ISPs. Thus, we select the thresholds in a
way that such compromised (but benign) servers are
ignored. An ideal threshold value should be chosen
high enough that the spikes at the beginning of both
graphs are cut off, and the ﬂuctuations around the
threshold should be low. Thus, a threshold value that
lies to the right of the initial peak in the curve is a
good choice. Consequently, FIRE uses thresholds of
δphish = 3 and δbot = 4.
For drive-by-download servers, we did not observe
a stabilizing effect over time. On the contrary, Fig-
ure 5c shows a constant ﬂuctuation. The reason is
that most drive-by-download servers are not
taken
ofﬂine quickly. These servers are typically deployed by
professional criminal organizations who do not want
to risk that their exploits fail because the mothership
server is taken ofﬂine. Thus, such servers are predom-
inantly deployed in rogue networks. As a result, we do
not take the uptime of drive-by-download servers into
account when computing malscores.
Size parameter. As mentioned previously, FIRE de-
creases the malscores of large networks. This is to
compensate for the fact that, due to their size, big-
ger networks are more likely to contain a signiﬁcant
number of rogue IPs. The extent to which the score
of larger networks is decreased is inﬂuenced by the
parameter c.
To show the effect of different choices for the
parameter c, we calculated the rankings for varying
values of this parameter. Again, we use the metric
presented previously to quantify how changes of c
inﬂuence the rankings. These result are shown in
Figure 6. It can be seen that for c values (much)
less than 1, the overall rank changes are small. This
is due to the fact that, with small values for c, the
resulting lists are dominated by ASN size, regardless
238
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:08:56 UTC from IEEE Xplore.  Restrictions apply. 
e
c
n
e
r
e
f
f
i
D
16
14
12
10
8
6
4
2
0
1
2
3
4
5
6
7
8
9
Threshold (days)
e
c
n
e
r
e
f
f
i
D
16
14
12
10
8
6
4
2
0
1
2
3
4
5
6
7
8
9
Threshold (days)
e
c
n
e
r
e
f
f
i
D
16
14
12
10
8
6
4
2
0
1
2
3
4
5
6
7
8
9
Threshold (days)
(a) Phishing Servers
(b) Botnet Servers
(c) Download Servers
Figure 5: Ranking changes for varying thresholds.
of the number of incidents. Similarly, for c values much
greater than 1, the rankings are dominated by incident
count, regardless of the size of a network.
For our analysis, it is thus important to choose a
value for c that is located on the right side of the
peak shown in the graph, as we want to favor incident
count over network size. However, we are interested
in a value for c that has some effect and, in particular,
reduces the rank of very large networks (such as tier-1
ISPs and backbone networks). This lead to the choice
of the threshold c = 4 for our malscore computation.
Size Parameter
120
100
80
60
40
20
e
g
n
a
h
C
0
0.1
0.2
0.3
0.5 0.7
1.0
1.5 2.0
3.0
5.0
8.0
c (log scale)
Figure 6: Sensitivity of parameter c.
6. Related Work
The work closest to ours are efforts that attempt
to assign a reputation to networks or an individual
IP address. In its simplest form, these efforts produce
blacklists of IPs that have been observed to perform
malicious actions. Most often, such blacklists are used
to ﬁlter spam mails [23], [24], but there are also black-
lists that warn users when they visit potentially harmful
web pages [11], [19]. Many of the sites that offer
blacklists also compile statistics of the worst offenders,
typically by counting the number of incidents in a
network. Unfortunately, this technique does not dis-
tinguish between compromised, bot-infected machines
and hosts in networks that are deliberately malicious.
As a result, the worst offenders are typically large
239
networks with many customers. The goal of our work,
on the other hand, is to discard the large amounts
of compromised machines and identify those (often
smaller) networks likely controlled by determined ad-
versaries.
We are aware of two recent papers [6], [7] that
look at
temporal and spatial properties of attack
sources. In [6], the authors study the spatial-temporal
characteristics of malicious sources on the Internet,
using data
from the DShield.org project. The
conclusion is that 20% of all IPs are responsible for
80% of the observed attacks. In [7], the authors attempt
to ﬁnd IPs that are clustered (spatial uncleanliness) and
persistent (temporal uncleanliness) in sending spam
mails, launching network scans, and hosting phishing
pages. This work is closest to ours in that the behavior
of hosts is used to identify “unclean” (infected)
netblocks. The difference to our approach is twofold:
First, we attempt to identify networks that are operated
by criminals, while their work was focusing on ﬁnding
bot infections. As a result, the selection of the input
data sets (we include drive-by download providers and
botnet C&C servers, but do not consider scanning) and
the ﬁltering techniques are different. Moreover, we
combine results from multiple feeds. Such correlation
efforts were not part of the previous paper.
7. Conclusions
In this paper, we presented FIRE, a novel system
to automatically identify and expose organizations and
ISPs that demonstrate persistent, malicious behavior.
FIRE can help isolate networks that tolerate and aid
miscreants in conducting malicious activity on the In-
ternet. It does this by actively monitoring different data
sources such as botnet communication channels, drive-
by-download servers, and feeds from phishing web
sites. Because it is important to distinguish between
networks that are knowingly malicious and networks
that are victims of compromise, we reﬁne the collected
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:08:56 UTC from IEEE Xplore.  Restrictions apply. 
data and correlate it to deduce the level of malicious-
ness for the identiﬁed networks. Our ultimate aim is
to automatically generate results that can be used to
pinpoint and track organizations that support Internet
miscreants and to help report and prevent criminal
activity. Furthermore, the networks we identify can
also be used by ISPs as blacklists in order to simply
block trafﬁc that
is originating from them. Hence,
an ISP can enhance the security of its users by not
allowing malicious trafﬁc to reach them.
[12] D. Goodin. 40,000 sites hit by PC-pwning hack at-
tack. http://www.theregister.co.uk/2009/06/02/beladen
mass website infection/, 2009.
[13] V. Hanna. Spamhaus: Cybercrime’s U.S. Hosts. http:
//www.spamhaus.org/news.lasso?article=636, 2008.
[14] B. Huffaker. CAIDA: AS ranking. http://as-rank.caida.
org/, 2008.
[15] G.
Inc.
http://google.com/safebrowsing/diagnostic?
site=AS:27715, 2009.
Acknowledgments
The research was supported by the National Science
Foundation under grant CNS-0831408.
References
[1] J. Armin, G. Bruen, G. Feezel, P. Ferguson,
M. Jonkman, and J. McQuaid. McColo - Cyber
Crime USA.
http://hostexploit.com/downloads/
Hostexploit%20Cyber%20Crime%20USA%20v%202.
0%201108.pdf, 2008.
[2] J. Armin, P. Ferguson, G. Bruen, G. Feezel,
M. Jonkman, and J. McQuaid. McColo - Cyber Crime
USA Supplement.
http://hostexploit.com/downloads/
Hostexploit McColo supplement 111808.pdf, 2008.
[3] J. Armin, J. McQuaid, and M. Jonkman. Atrivo -
Cyber Crime USA. http://hostexploit.com/downloads/
Atrivowhitepaper082808ac.pdf, 2008.
[4] U. Bayer, C. Kruegel, and E. Kirda. TTAnalyze: A Tool
for Analyzing Malware. In EICAR Conference, 2006.
[5] D. Bizeul. Russian Business Network Study. http://
www.bizeul.org/ﬁles/RBN study.pdf, 2007.
[6] Z. Chen, C. Ji, and P. Barford. Spatial Temporal Char-
acteristics of Internet Malicious Sources. In Infocomm
Mini-Conference, 2008.
[7] M. Collins, T. Shimeall, S. Faber, J. Janies, R. Weaver,
and M. D. Shon. Using Uncleanliness to Predict Future
Botnet Addresses.
In ACM Internet Measurement
Conference (IMC), 2007.
[8] D. Danchev. The Malicious ISPs You Rarely See
in Any Report. http://ddanchev.blogspot.com/2008/06/
malicious-isps-you-rarely-see-in-any.html, 2008.
[16] B. Krebs.
Taking on the Russian Business Net-
http://voices.washingtonpost.com/securityﬁx/
work.
2007/10/taking on the russian business.html, 2007.
[17] B. Krebs. Report Slams U.S. Host as Major Source of
Badware. http://voices.washingtonpost.com/securityﬁx/
2008/08/report slams us host as major.html, 2008.
[18] B. Krebs. FTC Sues, Shuts Down N. Calif. Web Host-
ing Firm. http://voices.washingtonpost.com/securityﬁx/
2009/06/ftc sues shuts down n calif we.html, 2009.
[19] PhishTank. Clearinghouse for phishing data on the
Internet. http://www.phishtank.com, 2008.
[20] M. Rajab, F. Monrose, and A. Terzis. Fast and Evasive
Attacks: Highlighting the Challenges Ahead. In Inter-
national Symposium on Recent Advances in Intrusion
Detection (RAID), 2006.
[21] C. Seifert. Capture-HPC - Honeypot Client. https://
projects.honeynet.org/capture-hpc, 2008.
[22] Shadowserver.
ASN Botnet Stats.
http://www.
shadowserver.org/wiki/pmwiki.php/Stats/ASN, 2009.
[23] SpamCop. Blocking List. http://www.spamcop.net/bl.
shtml, 2008.
[24] Spamhaus. Zen: Comprehensive DNSBL. http://www.
spamhaus.org/zen/, 2008.
[25] Wepawet. http://wepawet.iseclab.org/, 2009.
[26] ZeuSTracker. https://zeustracker.abuse.ch/statistic.php,
2009.
[9] D. Danchev.
GazTransitStroy/GazTranZitStroy
Rubbing
Internet
Network LLC. http://ddanchev.blogspot.com/2009/06/
gaztransitstroygaztranzitstroy-rubbing.html, 2009.
Petersburg
Shoulders
with
[10] dn1nj4.
The Shadowserver Foundation: RBN
http://www.shadowserver.org/wiki/uploads/
”Rizing”.
Information/RBN Rizing.pdf, 2008.
[11] D. Glosser. DNS-BH - Malware Domain Blocklist.
http://malwaredomains.com/, 2008.
240
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:08:56 UTC from IEEE Xplore.  Restrictions apply.