### Table 1: FIRE Top 10 for June 1st, 2009

| Rank | ASN   | Name                          | ShadowServer Botnet C&Cs | FIRE Rank | Large Network |
|------|-------|-------------------------------|--------------------------|------------|---------------|
| 1    | AS23522 | GigeNET                        | X                        | 1          | Yes           |
| 2    | AS3265 | XS4ALL                         | X                        | 118        | Yes           |
| 3    | AS25761 | Staminus Comm                  | X                        | 148        | No            |
| 4    | AS30058 | FDCservers.net                 | X                        | 86         | No            |
| 5    | AS174   | Cogent                         | X                        | 68         | Yes           |
| 6    | AS2108  | Croatian Research              | X                        | -          | No            |
| 7    | AS31800 | DALnet                         | X                        | -          | No            |
| 8    | AS13301 | Unitedcolo.de                  | X                        | -          | No            |
| 9    | AS790   | EUnet Finland                  | X                        | -          | No            |
| 10   | AS35908 | SWIFT Ventures                 | X                        | -          | No            |

### Table 2: ShadowServer Botnets / Google Safe Browsing Top 10 for June 1st, 2009

| Rank | ASN   | Name                                  | ShadowServer Botnet C&Cs | Google Safe Browsing | FIRE Rank | Large Network |
|------|-------|---------------------------------------|--------------------------|----------------------|------------|---------------|
| 1    | AS4134 | Chinanet Backbone No.31               | X                        | X                    | 17         | Yes           |
| 2    | AS21844 | ThePlanet.com                         | X                        | X                    | 13         | No            |
| 3    | AS4837 | China169 Backbone                     | X                        | X                    | 90         | Yes           |
| 4    | AS36351 | SoftLayer Technologies                | X                        | X                    | 30         | No            |
| 5    | AS26496 | GoDaddy.com                           | X                        | X                    | 15         | No            |
| 6    | AS41075 | ATW Internet Kft.                     | X                        | X                    | 23         | No            |
| 7    | AS4812  | Chinanet-SH-AP Telecom                | X                        | X                    | 89         | Yes           |
| 8    | AS10929 | Netelligent Hosting                   | X                        | X                    | 12         | No            |
| 9    | AS28753 | Netdirect                             | X                        | X                    | 11         | No            |
| 10   | AS8560  | 1&1 Internet AG                       | X                        | X                    | -          | Yes           |

### Methodology and Analysis

To evaluate the influence of different threshold values on the results, we added the number of Autonomous System Numbers (ASNs) that appear in both rankings but have a different number of rogue IPs. We used our metric to understand how different threshold values affect the ranking. Initially, we calculated a ranking for a small threshold value, then iteratively increased the threshold by a small value, recalculating the rankings at each step. Finally, we compared the rankings between each pair of subsequent steps to see if they eventually "stabilized" or continuously fluctuated based on specific values for δ.

We applied this analysis to all three data sources, ranging the threshold δ from 0 to 9, for each day since January 1st, 2009, and averaged the results. Figure 5 shows the results. Figures 5a and 5b indicate significant fluctuations for phishing servers and botnet control servers when threshold values are low. This is due to many compromised servers being taken offline after only one or two days by vigilant ISPs. Therefore, we selected thresholds high enough to ignore such compromised (but benign) servers. An ideal threshold value should be chosen to cut off the initial spikes and minimize fluctuations around the threshold. Consequently, FIRE uses thresholds of δphish = 3 and δbot = 4.

For drive-by-download servers, we did not observe a stabilizing effect over time. Figure 5c shows constant fluctuations. This is because most drive-by-download servers are not taken offline quickly. These servers are typically deployed by professional criminal organizations who do not want their exploits to fail due to the mothership server being taken offline. Thus, such servers are predominantly deployed in rogue networks. As a result, we do not consider the uptime of drive-by-download servers when computing malscores.

### Size Parameter

FIRE decreases the malscores of large networks to compensate for the fact that larger networks are more likely to contain a significant number of rogue IPs. The extent to which the score of larger networks is decreased is influenced by the parameter c.

To show the effect of different choices for the parameter c, we calculated the rankings for varying values of this parameter. We used the previously presented metric to quantify how changes in c influence the rankings. These results are shown in Figure 6. It can be seen that for c values much less than 1, the overall rank changes are small, as the resulting lists are dominated by ASN size, regardless of the number of incidents. Similarly, for c values much greater than 1, the rankings are dominated by incident count, regardless of the network size.

For our analysis, it is important to choose a value for c that is located on the right side of the peak shown in the graph, favoring incident count over network size. However, we are interested in a value for c that has some effect and, in particular, reduces the rank of very large networks (such as tier-1 ISPs and backbone networks). This led to the choice of the threshold c = 4 for our malscore computation.

### Related Work

The work closest to ours involves efforts to assign a reputation to networks or individual IP addresses. In its simplest form, these efforts produce blacklists of IPs that have been observed to perform malicious actions. Such blacklists are often used to filter spam emails [23], [24] or warn users about potentially harmful web pages [11], [19]. Many sites that offer blacklists also compile statistics of the worst offenders, typically by counting the number of incidents in a network. Unfortunately, this technique does not distinguish between compromised, bot-infected machines and hosts in networks that are deliberately malicious. As a result, the worst offenders are typically large networks with many customers. Our goal, on the other hand, is to discard the large amounts of compromised machines and identify those (often smaller) networks likely controlled by determined adversaries.

We are aware of two recent papers [6], [7] that look at temporal and spatial properties of attack sources. In [6], the authors study the spatial-temporal characteristics of malicious sources on the Internet using data from the DShield.org project. The conclusion is that 20% of all IPs are responsible for 80% of the observed attacks. In [7], the authors attempt to find IPs that are clustered (spatial uncleanliness) and persistent (temporal uncleanliness) in sending spam mails, launching network scans, and hosting phishing pages. This work is closest to ours in that the behavior of hosts is used to identify "unclean" (infected) netblocks. The difference is that we aim to identify networks operated by criminals, while their work focuses on finding bot infections. Additionally, we combine results from multiple feeds, which was not part of the previous paper.

### Conclusions

In this paper, we presented FIRE, a novel system to automatically identify and expose organizations and ISPs that demonstrate persistent, malicious behavior. FIRE helps isolate networks that tolerate and aid miscreants in conducting malicious activity on the Internet. It does this by actively monitoring different data sources such as botnet communication channels, drive-by-download servers, and feeds from phishing websites. Because it is important to distinguish between networks that are knowingly malicious and networks that are victims of compromise, we refine the collected data and correlate it to deduce the level of maliciousness for the identified networks. Our ultimate aim is to automatically generate results that can be used to pinpoint and track organizations that support Internet miscreants and to help report and prevent criminal activity. Furthermore, the networks we identify can also be used by ISPs as blacklists to block traffic originating from them, enhancing the security of their users.

### References

[1] J. Armin, G. Bruen, G. Feezel, P. Ferguson, M. Jonkman, and J. McQuaid. McColo - Cyber Crime USA. http://hostexploit.com/downloads/Hostexploit%20Cyber%20Crime%20USA%20v%202.0%201108.pdf, 2008.

[2] J. Armin, P. Ferguson, G. Bruen, G. Feezel, M. Jonkman, and J. McQuaid. McColo - Cyber Crime USA Supplement. http://hostexploit.com/downloads/Hostexploit McColo supplement 111808.pdf, 2008.

[3] J. Armin, J. McQuaid, and M. Jonkman. Atrivo - Cyber Crime USA. http://hostexploit.com/downloads/Atrivowhitepaper082808ac.pdf, 2008.

[4] U. Bayer, C. Kruegel, and E. Kirda. TTAnalyze: A Tool for Analyzing Malware. In EICAR Conference, 2006.

[5] D. Bizeul. Russian Business Network Study. http://www.bizeul.org/files/RBN study.pdf, 2007.

[6] Z. Chen, C. Ji, and P. Barford. Spatial Temporal Characteristics of Internet Malicious Sources. In Infocomm Mini-Conference, 2008.

[7] M. Collins, T. Shimeall, S. Faber, J. Janies, R. Weaver, and M. D. Shon. Using Uncleanliness to Predict Future Botnet Addresses. In ACM Internet Measurement Conference (IMC), 2007.

[8] D. Danchev. The Malicious ISPs You Rarely See in Any Report. http://ddanchev.blogspot.com/2008/06/malicious-isps-you-rarely-see-in-any.html, 2008.

[9] D. Danchev. GazTransitStroy/GazTranZitStroy Rubbing Internet Network LLC. http://ddanchev.blogspot.com/2009/06/gaztransitstroygaztranzitstroy-rubbing.html, 2009.

[10] dn1nj4. The Shadowserver Foundation: RBN "Rizing". http://www.shadowserver.org/wiki/uploads/Information/RBN Rizing.pdf, 2008.

[11] D. Glosser. DNS-BH - Malware Domain Blocklist. http://malwaredomains.com/, 2008.

[12] D. Goodin. 40,000 sites hit by PC-pwning hack attack. http://www.theregister.co.uk/2009/06/02/beladen mass website infection/, 2009.

[13] V. Hanna. Spamhaus: Cybercrime’s U.S. Hosts. http://www.spamhaus.org/news.lasso?article=636, 2008.

[14] B. Huffaker. CAIDA: AS ranking. http://as-rank.caida.org/, 2008.

[15] G. Inc. http://google.com/safebrowsing/diagnostic?site=AS:27715, 2009.

[16] B. Krebs. Taking on the Russian Business Network. http://voices.washingtonpost.com/securityfix/2007/10/taking-on-the-russian-business.html, 2007.

[17] B. Krebs. Report Slams U.S. Host as Major Source of Badware. http://voices.washingtonpost.com/securityfix/2008/08/report-slams-us-host-as-major.html, 2008.

[18] B. Krebs. FTC Sues, Shuts Down N. Calif. Web Hosting Firm. http://voices.washingtonpost.com/securityfix/2009/06/ftc-sues-shuts-down-n-calif-we.html, 2009.

[19] PhishTank. Clearinghouse for phishing data on the Internet. http://www.phishtank.com, 2008.

[20] M. Rajab, F. Monrose, and A. Terzis. Fast and Evasive Attacks: Highlighting the Challenges Ahead. In International Symposium on Recent Advances in Intrusion Detection (RAID), 2006.

[21] C. Seifert. Capture-HPC - Honeypot Client. https://projects.honeynet.org/capture-hpc, 2008.

[22] Shadowserver. ASN Botnet Stats. http://www.shadowserver.org/wiki/pmwiki.php/Stats/ASN, 2009.

[23] SpamCop. Blocking List. http://www.spamcop.net/bl.shtml, 2008.

[24] Spamhaus. Zen: Comprehensive DNSBL. http://www.spamhaus.org/zen/, 2008.

[25] Wepawet. http://wepawet.iseclab.org/, 2009.

[26] ZeuSTracker. https://zeustracker.abuse.ch/statistic.php, 2009.