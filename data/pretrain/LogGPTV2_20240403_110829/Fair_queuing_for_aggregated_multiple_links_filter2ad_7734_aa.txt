# Fair Queuing for Aggregated Multiple Links

**Authors:**
- Josep M. Blanquer
- Banu Özden

**Affiliations:**
- **Josep M. Blanquer:** Department of Computer Science, University of California, Santa Barbara
- **Banu Özden:** Bell Laboratories, Lucent Technologies

**Contact:**
- PI:EMAIL
- PI:EMAIL

## Abstract
Provisioning a shared server with guarantees is a critical scheduling task that has seen significant research in various areas, including link scheduling. Fair Queuing (FQ) algorithms provide a method for proportionally sharing a single server among competing flows, but they do not address the problem of sharing multiple servers. Multi-server systems are prevalent in applications such as link aggregation, multiprocessors, and multi-path storage I/O. In this paper, we introduce a new service discipline for multi-server systems that provides guarantees for competing flows. We prove that this new service discipline closely approximates the idealized Generalized Processor Sharing (GPS) discipline. We calculate its maximum packet delay and service discrepancy relative to GPS. We also discuss its relevance to several applications, particularly Ethernet link aggregation.

## 1. Introduction
The increasing variety of networked services has driven packet-switched networks to handle a broader range of traffic, from simple web page downloads to real-time multimedia streams. This diversity challenges the best-effort model of the Internet and demands different network requirements to be met simultaneously over the same links. For example, a network must provide high bandwidth, low jitter, and packet delay guarantees to support continuous backups, video streaming, and network data acquisition applications. To meet these diverse requirements, network resources must be appropriately scheduled.

Fair Queuing (FQ) service disciplines address this by allocating bandwidth fairly among competing traffic, regardless of their prior usage or congestion. FQ algorithms are based on the Generalized Processor Sharing (GPS), an idealized system that serves as a reference model for fair queuing. GPS-based service disciplines are studied for providing fairness and strict Quality of Service (QoS) guarantees. Fairness offers protection from "misbehaving" traffic and leads to effective congestion control and better services for rate-adaptive applications. Strict QoS guarantees, such as throughput or delays, can also be provided by restricting traffic admission. 

An increased dependence on network services and the growing demand for bandwidth have generated the need for incremental scaling techniques. Link aggregation, which groups multiple links into a single logical interface, is a popular method for high-throughput switches and servers. Numerous implementations of link aggregation are currently deployed in industry, but none of them address the provision of QoS over these aggregated links.

Although GPS-based service disciplines are extensively studied for scheduling a single link, they have not been applied to aggregated links. The provisioning of such systems is naturally described as a function of the total link capacity rather than for each individual link. This calls for a reference system that consists of a single GPS server operating at a rate equal to the sum of the underlying servers' rates.

In this paper, we study how packetized service disciplines with multiple servers can closely approximate such a GPS reference system. Many of the fair queuing results that were previously obtained for single-server systems do not directly apply to multi-server systems. This is because the rate at which the packetized multi-server system operates may vary over time and thus differ from the rate of the reference system. Furthermore, the packetized multi-server system may reorder packets to remain work-conserving.

The remainder of the paper is organized as follows:
- Section 2 provides background on the Generalized Processor Sharing discipline.
- Section 3 describes the singular properties of multi-server disciplines.
- Sections 4 and 5 formally prove the maximum differences in packet departure and per-flow service discrepancy with respect to GPS.
- Section 6 evaluates the fairness of the discipline and proposes MSF2Q, a fair queuing algorithm for multiple servers.
- Section 7 introduces some applications that benefit from the implementation of the new disciplines.
- Section 8 outlines related work in the area.
- Section 9 summarizes our conclusions and presents future work.

## 2. Background
Generalized Processor Sharing (GPS) is a service discipline defined for sharing a server proportionally among a set of flows. A GPS server operates at a fixed rate \( r \) and is work-conserving. Each flow \( i \) is assigned a positive real number \( \varphi_i \). Let \( F \) denote the set of flow indices. At any given time, a flow is either backlogged or idle. A flow is backlogged at time \( t \) if some of the flow's traffic is queued at time \( t \). Otherwise, the flow is idle. Let \( W_i(\tau, t) \) be the amount of traffic for flow \( i \) served in the interval \([ \tau, t ]\). Then, a GPS server is defined as one for which:

\[
\frac{W_i(\tau, t)}{W_j(\tau, t)} \geq \frac{\varphi_i}{\varphi_j}, \quad \forall j \in F
\]

holds for any flow \( i \) that is continuously backlogged during the interval \([ \tau, t ]\).

The weight of a flow determines the proportion of the server bandwidth that a flow receives when it is backlogged. During any time interval \([ \tau, t ]\) when the set of backlogged flows, denoted by \( F(\tau, t) \), is unchanged, a GPS server guarantees to a flow \( i \) a rate of:

\[
r_i(t) = \frac{\varphi_i}{\sum_{j \in F(\tau, t)} \varphi_j} r
\]

To provide strict QoS guarantees, an admission mechanism is required to limit access and bandwidth shares. For example, by fixing the set of flows, a GPS server can guarantee to each flow \( i \) a minimum service rate of:

\[
r_i = \frac{\varphi_i}{\sum_{j \in F} \varphi_j} r
\]

GPS is an idealized discipline that cannot be implemented directly since it assumes that the server transmits more than one flow simultaneously and that the traffic is infinitely divisible. GPS serves as a model for sharing a server among flows with respect to their weights. A number of packetized approximations to GPS have been devised.

## 3. Proportional Sharing of Multi-Server Systems
In this paper, we study proportional sharing of systems with multiple servers. There are numerous applications utilizing multi-server systems that can benefit from service guarantees. For example, the use of multiple network adapters for connecting a web or file server to a switch is becoming increasingly popular. Similarly, attaching a host to a RAID server via multiple I/O channels is emerging as the prevalent approach to increase I/O bandwidth between hosts and RAID servers. Such network and storage connections can be modeled as a packet system with multiple servers.

The problem of sharing multiple servers can be approached by partitioning the flows among the servers and scheduling them separately within each partition. One disadvantage of this technique is that bandwidth fragmentation can easily occur when the sum of the flow weights is not balanced across all partitions. Moreover, this technique has drawbacks in handling sporadic flows, where a large number of applications frequently switch flows between backlogged and idle states or make extensive use of relatively short-lived connections. This partitioning approach is also cumbersome to deal with when weight assignments result in bandwidth shares for a flow that exceed the rate of a single server.

In this paper, we concentrate on an alternative approach to sharing multi-servers where a packet of any flow can be serviced at any of the servers. Our system model consists of \( N \) servers, each operating at a fixed rate \( r \). Our goal is to study packetized scheduling disciplines for multi-server systems that closely approximate the ideal case of a single GPS server with a rate of \( N r \) (see Figures 1 and 2). We will refer to this GPS server as a (GP S, 1, N r) system, denoting 1 server with an output rate of \( N r \) being scheduled with the GPS discipline. Comparing the packetized disciplines against such a system allows the flows to be guaranteed a proportion of the total server capacity regardless of the value of \( N \). This allows the proportions to remain valid without intervention when increasing the number of servers in the packetized system. For example, adding new interfaces to the link aggregation group of a high-throughput web server will not change the proportions in which the different classes of services are served and will allow for the expansion of their minimum guaranteed rates.

As is customary in related literature, we assume that the arrival process to the packetized scheduling discipline is identical to that of the GPS discipline. We denote the arrival time of a packet \( p \) by \( a_p \).

### 3.1 A Packetized Fair Queuing Discipline for Multi-Servers
In this section, we investigate the use of the Weighted Fair Queuing (WFQ) packetized fair queuing service discipline, which is defined for a single server, in a multi-server system consisting of \( N \) servers each with a rate \( r \). We refer to such a system as a (M SF Q, N, r) system.

In the remainder of the paper, we will use GPS and MSFQ systems/servers to denote the (GP S, 1, N r) and (M SF Q, N, r) systems, respectively, without explicitly stating their number of servers and their rate.

When a server is idle and there is a packet waiting for service, MSFQ schedules the "next" packet. The "next" packet is defined as the first packet that would complete service in the (GP S, 1, N r) system if no more packets were to arrive.

We compare how well a (M SF Q, N, r) system approximates a (GP S, 1, N r) system. To do so, we calculate:
1. The worst-case delay that a packet experiences under MSFQ relative to GPS.
2. The discrepancy between the amount of traffic served for a flow under MSFQ and the amount under GPS.

To prove these two quantities, we first need to establish a number of properties of MSFQ.

### 3.2 Preliminary Properties
Although MSFQ and its single-server counterpart WFQ are both based on the same policy for selecting the next packet to be serviced, MSFQ does not share some of the useful properties of WFQ. As a result, delay and service properties of MSFQ do not trivially follow from the single-server case.

The first obstacle pertains to the busy periods of MSFQ with respect to GPS. While WFQ busy periods coincide with those of GPS, this property does not hold for MSFQ. To illustrate this, consider a busy period consisting of the transmission of a single packet. While GPS will be able to transmit the packet at full rate \( N r \), the MSFQ server will only be able to use one of its \( N \) servers, so the packet would be transmitted at a rate of \( r \). In this case, by the time GPS has finished the job (end of GPS busy period), the MSFQ server still has the last \( \frac{(N-1)L}{N} \) bits of the packet left to transmit.

When GPS is busy, MSFQ is busy. However, the converse is not true. Thus, for any \( \tau \),

\[
W(0, \tau) \geq \bar{W}(0, \tau),
\]

where \( W(0, \tau) \) and \( \bar{W}(0, \tau) \) denote the total number of bits serviced by GPS and MSFQ, respectively, by time \( \tau \). Since GPS and MSFQ busy periods do not coincide, in order to simplify the presentation, we will use the term "busy period" to refer to a busy period in the reference (GP S, 1, N r) system. Furthermore, because they do not coincide, work from previous busy periods can accumulate under MSFQ. This may happen either at the beginning or in the middle of a busy period. Figure 3 depicts a case in which the backlog is being accumulated in both cases. In this example, the packets arrive sequentially to the system such that there is always one packet at the GPS server being transmitted at full rate. This example raises the need to investigate whether the amount of work accumulating at MSFQ is bounded. The following theorem shows that such a backlog is indeed bounded. Let \( L_{\text{max}} \) denote the maximum packet length.

\[
a_1
\]