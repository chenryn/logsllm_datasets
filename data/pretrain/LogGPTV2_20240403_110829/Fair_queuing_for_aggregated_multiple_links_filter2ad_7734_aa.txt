title:Fair queuing for aggregated multiple links
author:Josep M. Blanquer and
Banu &quot;Ozden
Fair Queuing for Aggregated Multiple Links
Josep M. Blanquer∗
Department of Computer Science
University of California Santa Barbara
Banu ¨Ozden
Bell Laboratories
Lucent Technologies
PI:EMAIL
PI:EMAIL
ABSTRACT
Provisioning of a shared server with guarantees is an im-
portant scheduling task that has led to signiﬁcant work in
a number of areas including link scheduling. Fair Queu-
ing algorithms provide a method for proportionally sharing
a single server among competing ﬂows, however, they do
not address the problem of sharing multiple servers. Multi-
server systems arise in a number of applications includ-
ing link aggregation, multiprocessors and multi-path stor-
age I/O. In this paper we introduce a new service discipline
for multi-server systems that provides guarantees for com-
peting ﬂows. We prove that this new service discipline is a
close approximation of the idealized Generalized Processor
Sharing (GPS) discipline. We calculate its maximum packet
delay and service discrepancy with respect to GPS. We also
discuss its relevance to several applications, in particular,
Ethernet link aggregation.
1.
INTRODUCTION
A large increase in networked services has been gradually
driving packet-switched networks to carry a much larger va-
riety of traﬃc. These classes of traﬃc range from simple
downloads of static web pages or ﬁle transfers to multime-
dia streams and real-time trading. This increased variety
is challenging the premises of the Internet’s best-eﬀort traf-
ﬁc, and demands diﬀerent network requirements to be met
simultaneously over the same links. An example of this het-
erogeneity would be a network that must simultaneously
provide high bandwidth, low jitter and packet delay guar-
antees to ensure the correct performance of continuous back-
ups, video streaming and network data acquisition applica-
tions, respectively. In order to meet these diverse require-
ments, network resources must be appropriately scheduled.
Fair Queuing service disciplines address this scheduling
problem by allocating bandwidth fairly among competing
traﬃc, regardless of their prior usage or congestion. In par-
ticular, these disciplines do not penalize traﬃc for the use
∗
Work done as a summer intern at Bell Labs.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGCOMM’01, August 27-31, 2001, San Diego, California, USA..
Copyright 2001 ACM 1-58113-411-8/01/0008 ...$5.00.
of idle bandwidth. Fair queuing algorithms are based on
the Generalized Processor Sharing (GPS), an idealized sys-
tem that serves as a reference model for the fair queuing
disciplines. GPS-based service disciplines are studied in the
context of providing fairness as well as more strict Qual-
ity of Service (QoS) guarantees. Fairness oﬀers protection
from “misbehaving” traﬃc and leads to eﬀective congestion
control and better services for rate-adaptive applications.
Strict QoS guarantees such as throughput or delays can also
be provided by restricting the admission of traﬃc. In [15], it
is demonstrated that GPS guarantees end-to-end delay for
leaky-bucket constrained traﬃc. A number of approxima-
tions and heuristics of GPS were devised over the years [8,
17, 11, 15, 9, 5, 10]. Implementations of this work, known
as Weighted Fair Queuing, can be found in current commer-
cial routers or switches as well as in some servers [6] which
provide diﬀerentiated qualities of service to distinct classes
of clients.
An increased dependence on network services and the
growing demand for bandwidth have generated the need for
incremental scaling techniques. Grouping multiple links into
a single logical interface has emerged as a popular bandwidth
scaling method for high throughput switches and servers
[3]. Numerous implementations of aggregation techniques
between servers, routers and switches are currently deployed
in industry [2, 16, 1, 12]. These existing implementations
already provide diﬀerent techniques for load balancing the
traﬃc among the interfaces but none of them address the
provision of QoS over these aggregated links.
Although GPS based service disciplines are extensively
studied for scheduling a single link, they have not been ap-
plied to aggregated links. The provisioning of such systems
is naturally described as a function of the total link capacity
rather than for each of the links. This calls for a reference
system that consists of a single GPS server operating at a
rate equal to the sum of the the underlying servers’ rates.
In this paper, we study how packetized service disciplines
with multiple servers can closely approximate such a GPS
reference system. Many of the fair queuing results that were
previously obtained for single server systems do not directly
apply to multi-server systems. This is because the rate at
which the packetized multi-server system operates may vary
over time and thus diﬀer from the rate of the reference sys-
tem. Furthermore, the packetized multi-server system may
reorder the packets to remain work-conserving.
The remainder of the paper is organized as follows. Sec-
tion 2 will give some background on the Generalized Pro-
cessor Sharing discipline. Section 3 will describe the sin-
189gular properties of the multi-server disciplines. Section 4
and 5 will formally prove the maximum diﬀerences in packet
departure and per-ﬂow service discrepancy with respect to
GPS. Section 6 will evaluate the fairness of the discipline
and propose MSF2Q , a fair queuing algorithm for multiple
servers. In section 7 we will introduce some applications that
closely follow the presented sharing model and describe how
they can beneﬁt from the implementation of the new disci-
plines. Section 8 will outline some of the related work that
has been done in the area and in Section 9 we summarize
our conclusions and present future work.
2. BACKGROUND
Generalized Processor Sharing (GPS) is a service disci-
pline deﬁned for sharing a server proportionally among a
set of ﬂows [15]. A GPS server operates at a ﬁxed rate r
and is work-conserving. A positive real number φi is as-
signed for each ﬂow i. Let F denote the set of ﬂow indices.
At any given time, a ﬂow is either backlogged or idle. A
ﬂow is backlogged at time t if some of the ﬂow’s traﬃc is
queued at time t. Otherwise, the ﬂow is idle. Let Wi(τ, t) be
the amount of traﬃc for ﬂow i served in the interval [τ, t].
Then, a GPS server is deﬁned as one for which
Wi(τ, t)
Wj(τ, t)
≥ φi
φj
, j ∈ F
(1)
holds for any ﬂow i that is continuously backlogged during
the interval [τ, t].
The weight of a ﬂow determines the proportion of the
server bandwidth that a ﬂow receives when it is backlogged.
During any time interval [τ, t] when the set of backlogged
ﬂows, denoted by F (τ, t), is unchanged, a GPS server guar-
antees to a ﬂow i, i ∈ F (τ, t), a rate of
r. We
denote the instantaneous rate of a ﬂow i by ri(t).
j∈F(τ,t) φj
(cid:1)
φi
If we are to provide strict QoS guarantees, then an admis-
sion mechanism is required so as to limit access and band-
width shares. For example, by ﬁxing the set of ﬂows, a GPS
server can guarantee to each ﬂow i a minimum service rate
of ri:
ri =
φi(cid:1)
j∈F φj
r.
GPS is an idealized discipline that cannot be implemented
since it assumes that the server transmits more than one
ﬂow simultaneously and that the traﬃc is inﬁnitely divis-
ible. GPS serves as a model for sharing a server among
ﬂows with respect to their weights. A number of packetized
approximations to GPS have been devised [8, 17, 15, 9, 5,
10].
3. PROPORTIONAL SHARING OF MULTI-
SERVER SYSTEMS
In this paper, we study proportional sharing of systems
with multiple servers. There are numerous applications uti-
lizing multi-server systems that can beneﬁt from service
guarantees. For example, the use of multiple network adapters
for connecting a web or ﬁle server to a switch is becoming
increasingly popular. Similarly, attaching a host to a RAID
server via multiple I/O channels is emerging as the preva-
lent approach to increase I/O bandwidth between hosts and
flow
1
flow
2
.
..
flow
M
server
1
server
2
.
..
server
N
r
r
r
output rate
Nr
.
.
.
Packetized
scheduler
Figure 1: Packetized model for multiple servers.
flow
1
flow
2
.
..
flow
M
server
output rate
Nr
Nr
.
.
.
GPS
scheduler
Figure 2: GPS model for multiple servers.
RAID servers. Such network and storage connections can
be modeled as a packet system with multiple servers.
The problem of sharing multiple servers can be approached
by partitioning the ﬂows among the servers and scheduling
them separately within each partition. One of the disadvan-
tages of this technique is that bandwidth fragmentation can
easily occur when the sum of the ﬂow weights is not balanced
across all partitions. Moreover, aside from the fragmenta-
tion problem, this technique also has drawbacks in handling
sporadic ﬂows. For example, it is quite common for a large
number of applications to frequently switch ﬂows between
backlogged and idle states or to make extensive use of rela-
tively short-lived connections. This partitioning approach is
also cumbersome to deal with in the case where weight as-
signments result in bandwidth shares for a ﬂow that exceed
the rate of a single server.
In this paper, we concentrate
on an alternative approach to sharing multi-servers where a
packet of any ﬂow can be serviced at any of the servers.
Our system model consists of N servers each of which op-
erates at a ﬁxed rate of r. Our goal is to study packetized
scheduling disciplines for multi-server systems that closely
approximate the ideal case of a single GPS server with a
rate of N r (see Figures 1 and 2). We will refer to this GPS
server as a (GP S, 1, N r) system denoting 1 server with an
output rate of N r being scheduled with the GPS discipline.
Comparing the packetized disciplines against such a system
allows the ﬂows to be guaranteed a proportion of the total
server capacity regardless of the value of N . This allows the
proportions to remain valid without intervention when in-
creasing the number of servers in the packetized system. For
example, adding new interfaces to the link aggregation group
of a high throughput web server will not change the propor-
tions in which the diﬀerent classes of services are served and
will allow for the expansion of their minimum guaranteed
rates.
As is customary in related literature, we assume that
the arrival process to the packetized scheduling discipline
is identical to that of the GPS discipline. We denote the
arrival time of a packet p by ap.
3.1 A Packetized Fair Queuing Discipline for
Multi-Servers
In this section, we investigate the use of the WFQ pack-
etized fair queuing service discipline, which is deﬁned for a
single server in [8, 15], in a multi-server system consisting of
N servers each with a rate of r. We refer to such a system
as a (M SF Q , N, r) system.
In the remainder of the pa-
per, we will use GPS and MSFQ systems/servers to denote
the (GP S, 1, N r) and (M SF Q , N, r) systems respectively,
without explicitly stating their number of servers and their
rate.
When a server is idle and there is a packet waiting for
service, MSFQ schedules the “next” packet. The “next”
packet is deﬁned as the ﬁrst packet that would complete
service in the the (GP S, 1, N r) system if no more packets
were to arrive.
We compare how well a (M SF Q , N, r) system approxi-
mates a (GP S, 1, N r) system. To do so, we calculate: i) the
worst case delay that a packet experiences under MSFQ rel-
ative to GPS and ii) the discrepancy between the amount of
traﬃc served for a ﬂow under MSFQ and the amount under
GPS. In order to prove these two quantities, we ﬁrst need
to establish a number of properties of MSFQ .
3.2 Preliminary Properties
Although MSFQ and its single-server counterpart WFQ
are both based on the same policy for selecting the next
packet to be serviced, MSFQ does not share some of the
useful properties of WFQ. As a result, delay and service
properties of MSFQ do not trivially follow from the single
server case.
The ﬁrst obstacle pertains to the busy periods of MSFQ
with respect to GPS. While WFQ busy periods coincide with
those of GPS, this property does not hold for MSFQ . To
illustrate this, take the case of a busy period consisting of
the transmission of a single packet. While GPS will be able
to transmit the packet at full rate, N r, the MSFQ server
will only be able to use one of its N servers so the packet
would be transmitted at a rate of r.
In this case, by the
time GPS has ﬁnished the job (end of GPS busy period),
last bits of the
the MSFQ server still has the last
packet left to transmit.
(N−1)L
N
When GPS is busy, MSFQ is busy. However, the converse
is not true. Thus for any τ ,
W (0, τ ) ≥ ¯W (0, τ ),
(2)
where W (0, τ ) and ¯W (0, τ ) denote the total number of bits
serviced by GPS and MSFQ , respectively, by time τ . Since
GPS and MSFQ busy periods do not coincide, in order to
simplify the presentation, we will use the term busy period to
refer to a busy period in the reference (GP S, 1, N r) system.
Furthermore, because they do not coincide, work from
previous busy periods can accumulate under MSFQ . This
may happen either at the beginning or in the middle of a
busy period. Figure 3 depicts a case in which the backlog is
being accumulated in both cases. In this example the pack-
ets arrive sequentially to the system such that there is al-
ways one packet at the GPS server being transmitted at full
rate. This example raises the need to investigate whether
the amount of work accumulating at MSFQ is bounded.
The following theorem shows that such a backlog is indeed
bounded. Let Lmax denote the maximum packet length.
a1
1