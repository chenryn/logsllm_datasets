siﬁed as input for a given PLC. By “has knowledge of a
component C” is meant that the attacker knows (a) of the
presence of C and its context in the CPS, (b) details of the
physical and logical operation of C, and (c) how to actually
compromise C to send fake data to the corresponding PLC
or a command to C bypassing the PLC.
4.2 Attacks
The above mentioned six attack scenarios were realized in
terms of attacks listed in Table 3. For the purpose of the
experiment to assess the eﬀectiveness of DaD, these attacks
were launched, one at a time, in stages 1 and 3. A sample
attack is described in the following example.
Example 2: To understand the attack scenarios enumer-
ated in Table 3, consider stage 1 of SWaT and attack sce-
nario A1. As shown in Figure 2, this stage consists of tank
T101 and several sensors and actuators. The goal of PLC1 is
to ensure that there is enough water in T101 to be supplied
to stage 3 for ultraﬁltration. Thus, the control algorithm
in PLC1 monitors water level in T101 at predetermined in-
tervals. When water level in the tank is low, indicated by
sensor LIT101 (v2= L) , PLC1 opens valve MV101 (v3), so
water can enter T101. The ﬂow rate indicator, FIT101 (v1),
is used by PLC1 to check whether water is ﬂowing into tank
T101.
Consider the case when v2 = L, and the attacker takes
control of the links from LIT101 and FIT101 to PLC1. The
attacker then sets v2 = H so PLC1 would not open MV101.
If at this time P101 is ON, i.e., v4 = 1, water will be drained
from T101 and eventually the tank will be empty. If there is
no cut oﬀ in P101 then the pump could be running dry and
might get damaged. In any case, depending on the state of
tank T301, no water in T101 will eventually lead to v5 = LL,
thus stopping the UF process.
In turn this may lead to
stopping of the RO unit. The net impact of this attack would
be to reduce the amount of water produced by the plant.
Note, however, that if v4 = 1 then v2 must eventually reach
state L. The attacker makes the assumption that PLC1 is
monitoring v2 and hence also changes the actual water level
sent to PLC1 via LIT101. Thus, PLC1 does not detect any
anomaly in the water level in T101. Other attacks are also
possible that may involve changing the value of v1 and that
of v2 and v3 to cause either overﬂow in T101 or a reduction
in the amount of water produced/minute.
The above example illustrates how a variety of attacks
can be designed in each of the scenarios listed in Table 3.
The impact of these carefully designed attacks could be tank
overﬂow, pump damage, or system performance degrada-
tion. For PLC1 and PLC3 a total of, respectively, 36 and
104 attacks were designed and launched systematically one
by one to study the eﬀectiveness of the detection method.
Several attacks were generated using the six scenarios
mentioned earlier. Each attack manipulated one or more
actuators and sensors. To limit the total number of attacks,
the actuator states were set to 0 or 1 depending on their
current state while simultaneously manipulating the level
sensor in some cases. The total number of such attacks pos-
sible for each scenario and for each of the two PLCs is given
in Table 3.
The number of attacks actually implemented was smaller
than the total possible so as to complete the experiments
within a reasonable time frame. While launching an attack
Multi- stageSingle-point(MSSP)Single stageSingle point(SSSP)One sub-processcan be fully compromisedMulti- stageMulti-point(MSMP)Entire CPS can becompromisedSingle stageMulti-point(SSPMP)Work reportedin this paper455Table 3: Single stage multi-point attack scenarios and attacks on stages 1 and 3 of SWaT.
Scenario†
A1
(2:1:2:1)
Sensor‡
1: LIT101, [FIT101]
3: LIT301
1: LIT101, [FIT101, FIT201]
3: LIT301, [FIT301, DPIT301]
1: MV101
3: P101, MV201
1: MV101, P101
3: P101, MV201, P301, MV302
1: FIT101, FIT201, MV101, P101
A2
(12:12:4:4)
A3
(2:12:2:4)
A4
(12:176:4:16)
A5
(176:704:16:64)
A6
(56:176:8:16)
3: FIT301, DPIT301, P101, MV201, P301,
MV302
1: LIT101, [MV101, FIT101, FIT201]
LIT301,
3:
MV302]
[FIT301, DPIT301, P101,
Attack
(0 → 1) (1 → 0)
Only Level sensor values are altered.
(00 → 11) (01 → 10) (10 → 01) (11 → 00)
(00 → 11) (01 → 10) (10 → 01) (11 → 00)
(0 → 1) (1 → 0); only one sensor attacked.
(00 → 11) (01 → 10) (10 → 01) (11 → 00)
(00 → 11) (01 → 10) (10 → 01) (11 → 00)
(00 → 11) (01 → 10) (10 → 01) (11 → 00)
(0000 → 1111) (0001 → 1110) (0010 → 1101) (0011 →
1100)(0100 → 1011) (0101 → 1010) (0110 → 1001)
(0111 → 1000)(1000 → 0111) (1001 → 0110) (1010 →
0101) (1011 → 0100)(1100 → 0011) (1101 → 0010)
(1110 → 0001) (1111 → 0000)
Only 10 experiments were conducted in this case.
(001 → 011)(001 → 110)(010 → 101)(011 →
100)(100 → 011)(101 → 011)(110 → 001)(111 → 000)
Only 10 experiments were conducted in this and the
above case.
†a:b:c:d: a: attack combinations in PLC1, b: attack combinations in PLC3, c: attacks implemented in
PLC1, d: attacks implemented in PLC3. Two or more sensors/actuators compromised in addition to LIT
where mentioned excepting A3:1.
‡n: X– n denotes the PLC and X the sensors aﬀected by the attack. Level sensors (LIT) are continuously
manipulated by the attacker to ensure that the water level indicated to the corresponding PLC corresponds
to the altered states of the actuators and sensors. Items in brackets are explained in Example 4.
is relatively straightforward as the authors have access to the
entire system, bringing the system to a suitable state prior
to launch is time consuming due the existence of various
tanks whose states are from a previous experiment by some
user of the testbed. Several trial experiments, not reported
here, as well as a large number of experiments performed
for SSSP attack detection[2] were conducted to determine
which attacks to select from the complete set. Attacks that
correspond to transient states were omitted as these require
a much longer setup time than those launched when the
system is in a stable state. Entries in the rightmost column
of Table 3 are explained in the following example.
Example 3: Consider the following attack on PLC1 derived
from scenario A5.
1: FIT101, FIT201, MV101, P101: (1010 → 0101)
The bits in the binary pattern above correspond, from left to
right, to the sensors/actuators listed. This attack assumes
that the input ﬂow rate indicator is showing inﬂow into tank
T101 (FIT101 is set to 1), there is no outﬂow (FIT201 is set
to 0), valve MV101 is OPEN (1) and pump P101 is OFF (0).
The attacker compromises both sensors and actuators and
inverts the states of each. Thus, FIT101 is showing no in-
ﬂow (set to 0), FIT201 is showing outﬂow (set to 1), MV101
is CLOSED (0) and pump P101 is ON (1). Note that in
this case the states of FIT101 and MV101 and the states of
FIT201 and P101 are locally consistent4 when prior to and
after the attack is launched. Thus, a simple local inconsis-
tency check will not be able to to detect this attack.
Example 4: Attacks derived from scenarios A1, A2 and A6
manipulate the level sensor LIT. To understand how and
why this is done, consider he following attack in A6.
1: LIT101, [MV101, FIT101, FIT201]: (001 → 011)
Prior to the attack valve MV101 is CLOSED (0), FIT101 is
indicating no ﬂow into tank T101 (0), and FIT201 is indi-
cating ﬂow out of T101 (1). Note that the states of MV101
4Stable states p and q of components a and b, respectively,
are considered locally consistent if, by design, p always cor-
responds to q and vice versa. Components a and b could be
in locally inconsistent states due to failure of one or both.
It is also possible that while the components are in locally
consistent states, an attacker makes them appear to be not
so to the corresponding PLC.
456and FIT10 are locally consistent. As water is ﬂowing out
of T101, P101 must be ON. However, this aspect is not
considered explicitly in the attack. The attacker does not
change the state of MV101 (0) and FIT201 but changes that
of FIT101 to indicate that there is ﬂow into T101. A local
inconsistency check would detect this attack though it is
assumed that such checks are not in place.
To avoid detection, the attacker also manipulates LIT101.
Thus, because FIT101 is indicating ﬂow, the attacker changes
the value of LIT101 to be consistent with the ﬂow into
T101, as well as ﬂow out of T101 due to P101 being ON.
This is a traditional replay attack and requires that the at-
tacker knows exactly how to compute, in real time, values of
LIT101. Unless the attack is detected, T101 will be empty
while P101 remains ON. This situation could lead to pump
damage and reduction in system performance. The latter
condition may arise if the attack is not detected before T301
becomes empty and UF unit is turned OFF.
5. EXPERIMENTS
A limited set of attacks were selected from the list in
the rightmost column in Table 3. The number of attacks
launched is also listed in the table. Attacks that correspond
to transient states were not launched. Note that such attacks
are important and, as has been reported earlier [2], diﬃcult
to detect. However, it was decided to consider these attacks
in a separate experiment devoted entirely to attacks that
exploit the transient state(s) of a CPS.
5.1 Attack procedure
To understand the detection method, it is important to
understand the entire procedure used in the experiments
to assess the eﬀectiveness of DaD. Following is a general
description of the entire set of experiments reported here.
1. Create an attacker model. The attacker model de-
scribed in Section 4 served as a basis for generating
SSMP attacks.
2. Generate a set A of attacks to be launched. For each
attack, create a procedure to use for launching it and
observing the outcome (attacks listed in the rightmost
column of Table 3.
3. Design process invariants for use in DaD (as in Sec-
tion 3).
4. Code each process invariant and add it to the appro-
priate PLC.
5. Select an attack from A and launch it using the proce-
dure in Step 2. Record whether the attack is detected
or not. Launching an attack may require bring the
CPS to a speciﬁc state before the attack is launched.
6. Repeat step 5 until all attacks in A have been tried.
The above procedure is generic and is perhaps applicable
to any CPS. Indeed, one needs to take extreme care in ex-
ecuting Step 5. This step must be executed with a careful
analysis of the behavior of the CPS in the event the attack
is not detected. In all likelihood, the experiment described
here will not be conducted on a live public infrastructure.
5.2 Distributed attack detection
The invariants serve as checkers of the system state. These
are coded and the code placed inside each PLC used in at-
tack detection. Note that the checker code is added to the
control code that already exists in each PLC. The PLC ex-
ecutes the code in a cyclic manner.
In each cycle, data
from the sensors is obtained, control actions computed and
applied when necessary, and the invariants checked against
the state variables or otherwise.
It is important to note that the above procedure is in-
dependent of the CPS to which it is applied though the
invariants used are derived from a speciﬁc system, namely,
SWaT. Thus, the above procedure could also be applied to
other similar distributed systems that can be partitioned
into multiple stages and have localized sensors and actua-
tors at each stage.
6. RESULTS
The SD and SA invariants together were able to detect all
attacks and thus proved to be a powerful means for detecting
attacks using DaD. For attacks in A1 and A2, the SD invari-
ants were found to be most eﬀective while for the remain-
ing attacks both SA and SD invariants were useful. Fur-
ther, attacks were detected almost immediately after they
are launched.
It is important to understand why the distributed nature
of detection is a powerful mechanism. First note that the
stages are connected in a sequence. Thus, any anomaly
in stage 1 has a very high likelihood of being reﬂected in
stage 3; stage 2 does only has chemical sensors and hence
requires chemistry-based detection method not used in the
experiments reported here. Now consider invariant P3BC1
in Table 2 and the attack that attempts to degrade system
performance by turning P101 OFF when T301 is low on
water. If this attack is not detected then the UF unit will
be turned OFF and eventually the RO will also be turned
OFF because water will stop ﬂowing from T401 to RO. How-
ever, the attack is detected by PLC3 because if T301 is low
(v5 = L) then P101 must be ON (v4 = 1) and MV201 must
be OPEN (v8 = 1). Note that MV201 is located at the pipe
that connects P101 to T301.
Arguments similar to the one above could be given to
explain how each of the attacks was detected. However,
due to limitations of space, such arguments cannot be listed
here.Given the surprising nature of the results, it is natu-
ral to ask: “What kind of attacks could not be detected by
the distributed detection method implemented in the exper-
iments?” The following replay attack was designed to an-
swer this question. Suppose that the attacker performs the
following actions when v2(LIT101)=HH, i.e., tank T101 is
full, and v4 (P101)=0: (a) Compromise LIT101. (b) Send
to PLC1 v2(LIT101)=LL. This action causes PLC1 to open
MV101 to ensure that T101 has adequate amount of water
for the UF unit to continue functioning. To avoid PLC1
detecting the attack, the attacker computes new values of
LIT101 based on the knowledge of ﬂow rate into T101 when
MV101 is open. The attacker can obtain the ﬂow rate in-
formation from the speciﬁcations of the design of stage 1,
or, could compromise FIT101 and obtain the information in
real time.
The above replay attack was implemented with all detec-
tors in place. The attack was not detected causing T101
457to overﬂow5 The water level before and after the attack is
illustrated in Figure 6. One way to detect this attack would
be to keep track of previous state of LIT101. Let q−1 and
q0 denote the previous and current values of v2, i.e., the
tank level, just prior to the attack (-1) and at the time
of attack. In the absence of the attack q−1 = q0 because
v3(MV101)=0. Thus, the invariant in this case becomes:
v3 = 0 and q−1 = HH → q0 = HH.
The above invariant installed in PLC1 would detect such a
replay attack. Several other ways of detecting replay attacks
are possible. Further, when a process stage has both the
previous and the next stages as its neighbors, such attacks
could be detected using DaD; there is no previous stage for
stage 1 in SWaT and hence the replay attack in stage 1 goes
undetected using the method described in this work.
Figure 6: Water level in tank T101 versus time.
Tank T101 overﬂows due to an undetected replay
attack in stage 1.
7. RELATED WORK
The use of invariants for detecting attacks on CPS has
been proposed by several researchers. The work that re-
lates most closely to the techniques described here is that
of Rosich et al. [17], referred to in the following as the RVD