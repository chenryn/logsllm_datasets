## ðŸ› Bug
When using PyTorch1.3 C++ distribution in Visual Studio 2017 and follow the
tutorial of loading a TorchScript model from C++ described here
https://pytorch.org/tutorials/advanced/cpp_export.html
It all works fine as long as the model and the tensor data stays on the CPU,
but as soon as I try to move the model to GPU (CUDA) via
.to(at::kCUDA) I'll get a crash when using the debug version of the libraries.
and I'll get a crash later in the release version in the .forward method
## To Reproduce
Steps to reproduce the behavior:
  1. Use the code from the tutorial page above
  2. Download latest Windows10 debug version from website
  3. Create a new VS2017 project and use the code snippets above
  4. Use the include/libraries from the debug version
  5. Try to run the code inside VS2017
Stacktrace:
    torch.dll!at::native::DispatchStub::operator()(c10::DeviceType device_type, at::TensorIterator & , bool & ) Line 74	C++
    torch.dll!at::native::copy_impl(at::Tensor & self, const at::Tensor & src, bool non_blocking) Line 148	C++
    torch.dll!at::native::copy_(at::Tensor & self, const at::Tensor & src, bool non_blocking) Line 157	C++
    torch.dll!at::TypeDefault::copy_(at::Tensor & self, const at::Tensor & src, bool non_blocking) Line 1246	C++
    torch.dll!c10::detail::WrapRuntimeKernelFunctor_ >::operator()(at::Tensor & , const at::Tensor & , bool ) Line 24	C++
    torch.dll!c10::detail::wrap_kernel_functor_unboxed_ >,at::Tensor & __ptr64 __cdecl(at::Tensor & __ptr64,at::Tensor const & __ptr64,bool)>::call(c10::OperatorKernel * functor, at::Tensor & , const at::Tensor & , bool ) Line 261	C++
    torch.dll!c10::KernelFunction::callUnboxedOnly(at::Tensor & , const at::Tensor & , bool ) Line 95	C++
    torch.dll!c10::impl::OperatorEntry::callUnboxedOnly::__l2::(const c10::DispatchTable & dispatchTable) Line 68	C++
    torch.dll!c10::LeftRight::read(const c10::DispatchTable &) >(c10::impl::OperatorEntry::callUnboxedOnly::__l2::at::Tensor & (const c10::DispatchTable &) && readFunc) Line 74	C++
    torch.dll!c10::impl::OperatorEntry::callUnboxedOnly(c10::TensorTypeId dispatchKey, at::Tensor & , const at::Tensor & , bool ) Line 70	C++
    torch.dll!c10::Dispatcher::callUnboxedOnly(const c10::OperatorHandle & op, c10::TensorTypeId dispatchKey, at::Tensor & , const at::Tensor & , bool ) Line 177	C++
    torch.dll!at::Tensor::copy_(const at::Tensor & src, bool non_blocking) Line 746	C++
    torch.dll!torch::autograd::VariableType::copy_(at::Tensor & self, const at::Tensor & src, bool non_blocking) Line 151	C++
    torch.dll!c10::detail::WrapRuntimeKernelFunctor_ >::operator()(at::Tensor & , const at::Tensor & , bool ) Line 24	C++
    torch.dll!c10::detail::wrap_kernel_functor_unboxed_ >,at::Tensor & __ptr64 __cdecl(at::Tensor & __ptr64,at::Tensor const & __ptr64,bool)>::call(c10::OperatorKernel * functor, at::Tensor & , const at::Tensor & , bool ) Line 261	C++
    torch.dll!c10::KernelFunction::callUnboxedOnly(at::Tensor & , const at::Tensor & , bool ) Line 95	C++
    torch.dll!c10::impl::OperatorEntry::callUnboxedOnly::__l2::(const c10::DispatchTable & dispatchTable) Line 68	C++
    torch.dll!c10::LeftRight::read(const c10::DispatchTable &) >(c10::impl::OperatorEntry::callUnboxedOnly::__l2::at::Tensor & (const c10::DispatchTable &) && readFunc) Line 74	C++
    torch.dll!c10::impl::OperatorEntry::callUnboxedOnly(c10::TensorTypeId dispatchKey, at::Tensor & , const at::Tensor & , bool ) Line 70	C++
    torch.dll!c10::Dispatcher::callUnboxedOnly(const c10::OperatorHandle & op, c10::TensorTypeId dispatchKey, at::Tensor & , const at::Tensor & , bool ) Line 177	C++
    torch.dll!at::Tensor::copy_(const at::Tensor & src, bool non_blocking) Line 746	C++
    torch.dll!at::native::to_impl(const at::Tensor & self, const c10::TensorOptions & options, bool non_blocking) Line 25	C++
    torch.dll!at::native::to(const at::Tensor & self, c10::Device device, c10::ScalarType dtype, bool non_blocking, bool copy) Line 63	C++
    torch.dll!at::TypeDefault::to(const at::Tensor & self, c10::Device device, c10::ScalarType dtype, bool non_blocking, bool copy) Line 4830	C++
    torch.dll!torch::autograd::VariableType::`anonymous namespace'::to(const at::Tensor & self, c10::Device device, c10::ScalarType dtype, bool non_blocking, bool copy) Line 11390	C++
    torch.dll!at::ATenOpTable::callUnboxed(const at::Tensor & , c10::Device , c10::ScalarType , bool , bool ) Line 94	C++
    torch.dll!at::Tensor::to(c10::Device device, c10::ScalarType dtype, bool non_blocking, bool copy) Line 3387	C++
    torch.dll!torch::jit::script::module_state_to(const torch::jit::script::Slot & s, const c10::optional & device, const c10::optional & dtype, bool non_blocking) Line 123	C++
    torch.dll!torch::jit::script::Module::to_impl(const c10::optional & device, const c10::optional & dtype, bool non_blocking) Line 140	C++
    torch.dll!torch::jit::script::Module::to_impl(const c10::optional & device, const c10::optional & dtype, bool non_blocking) Line 136	C++
    torch.dll!torch::jit::script::Module::to_impl(const c10::optional & device, const c10::optional & dtype, bool non_blocking) Line 136	C++
    torch.dll!torch::jit::script::Module::to(c10::Device device, bool non_blocking) Line 79	C++
## Expected behavior
Not to crash
## Environment
  * PyTorch Version 1.3
  * Windows Version 10.0.18362 Build 18362
  * How you installed : Used the provided windows llibraries
  * CUDA/cuDNN 10.1/7
  * GPU 1060ti  
Visual Studio 2017 Version 15.9.8