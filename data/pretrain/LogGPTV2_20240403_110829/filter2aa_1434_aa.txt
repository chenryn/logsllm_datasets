Performance Improvements on Tor
or,
Why Tor is slow and what we’re going to do about it
Roger Dingledine
Steven J. Murdoch
March 11, 2009
As Tor’s user base has grown, the performance of the Tor network has suﬀered. This document describes
our current understanding of why Tor is slow, and lays out our options for ﬁxing it.
Over the past few years, our funding (and thus our development eﬀort) has focused on usability and
blocking-resistance. We’ve come up with a portable self-contained Windows bundle; deployed tools to handle
the upcoming censorship arms race; further developed supporting applications like Vidalia, Torbutton, and
Thandy; made it easier for users to be relays by adding better rate limiting and an easy graphical interface
with uPnP support; developed an eﬀective translation and localization team and infrastructure; and spread
understanding of Tor in a safe word-of-mouth way that stayed mostly under the radar of censors.
In parallel to adding these features, we’ve also been laying the groundwork for performance improve-
ments. We’ve been working with academics to write research papers on improving Tor’s speed, funding some
academic groups directly to come up with prototypes, and thinking hard about how to safely collect metrics
about network performance. But it’s becoming increasingly clear that we’re not going to produce the perfect
answers just by thinking hard. We need to roll out some attempts at solutions, and use the experience to
get better intuition about how to really solve the problems.
We’ve identiﬁed six main reasons why the Tor network is slow. Problem #1 is that Tor’s congestion
control does not work well. We need to come up with ways to let “quiet” streams like web browsing co-exist
better with “loud” streams like bulk transfer. Problem #2 is that some Tor users simply put too much
traﬃc onto the network relative to the amount they contribute, so we need to work on ways to limit the
eﬀects of those users and/or provide priority to the other users. Problem #3 is that the Tor network simply
doesn’t have enough capacity to handle all the users that want privacy on the Internet. We need to develop
strategies for increasing the overall community of relays, and consider introducing incentives to make the
network more self-sustaining. Problem #4 is that Tor’s current path selection algorithms don’t actually
distribute load correctly over the network, meaning some relays are overloaded and some are underloaded.
We need to develop ways to more accurately estimate the properties of each relay, and also ways for clients
to select paths more fairly. Problem #5 is that Tor clients aren’t as good as they should be at handling
high or variable latency and connection failures. We need better heuristics for clients to automatically shift
away from bad circuits, and other tricks for them to dynamically adapt their behavior. Problem #6 is that
low-bandwidth users spend too much of their network overhead downloading directory information. We’ve
made a serious dent in this problem already, but more work remains here too.
We discuss each reason more in its own section below. For each section, we explain our current intuition
for how to address the problem, how eﬀective we think each ﬁx would be, how much eﬀort and risk is
involved, and the recommended next steps, all with an eye to what can be accomplished in 2009.
While all six categories need to be resolved in order to make the Tor network fast enough to handle
everyone who wants to use it, we’ve ordered the sections by precedence. That is, solving the earlier sections
will be necessary before we can see beneﬁts from solving the later sections.
1
Performance Improvements on Tor
Contents
1
Tor’s congestion control does not work well
3
1.1
TCP backoﬀ slows down every circuit at once . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
We chose Tor’s congestion control window sizes wrong . . . . . . . . . . . . . . . . . . . . . .
4
2
Some users add way too much load
4
2.1
Squeeze over-active circuits
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
2.2
Throttle certain protocols at exits
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.3
Throttle certain protocols at the client side
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
2.4
Throttle all streams at the client side . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
2.5
Default exit policy of 80,443 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
2.6
Better user education
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
3
The Tor network doesn’t have enough capacity
7
3.1
Tor server advocacy
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
3.1.1
Talks and trainings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
3.1.2
Better support for relay operators
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
3.1.3
A Facebook app to show oﬀ your relay . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
3.1.4
Look for new ways to get people to run relays . . . . . . . . . . . . . . . . . . . . . . .
8
3.2
Funding more relays directly
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
3.3
Handling fast Tor relays on Windows . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
3.4
Relay scanning to ﬁnd overloaded relays or broken exits . . . . . . . . . . . . . . . . . . . . .
9
3.5
Getting dynamic-IP relays back into the relay list quickly . . . . . . . . . . . . . . . . . . . .
10
3.6
Incentives to relay
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
3.7
Reachable clients become relays automatically . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
4
Tor clients choose paths imperfectly
11
4.1
We don’t balance traﬃc over our bandwidth numbers correctly . . . . . . . . . . . . . . . . .
11
4.2
The bandwidth estimates we have aren’t very accurate . . . . . . . . . . . . . . . . . . . . . .
12
4.3
Bandwidth might not even be the right metric to weight by . . . . . . . . . . . . . . . . . . .
16
4.4
Considering exit policy in relay selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
4.5
Older entry guards are overloaded
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
5
Clients need to handle variable latency and failures better
19
5.1
Our round-robin and rate limiting is too granular . . . . . . . . . . . . . . . . . . . . . . . . .
19
5.2
Better timeouts for giving up on circuits and trying a new one
. . . . . . . . . . . . . . . . .
21
5.3
If extending a circuit fails, try extending a few other places before abandoning the circuit. . .
21
5.4
Bundle the ﬁrst data cell with the begin cell . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
6
The network overhead may still be high for modem users
22
6.1
We’ve made progress already at directory overhead . . . . . . . . . . . . . . . . . . . . . . . .
22
6.2
Our TLS overhead can also be improved . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
7
Last thoughts
23
7.1
Lessons from economics
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
7.2
The plan moving forward
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
2
Performance Improvements on Tor
1
Tor’s congestion control does not work well
One of Tor’s critical performance problems is in how it combines high-volume streams with low-volume
streams. We need to come up with ways to let the “quiet” streams (like web browsing) co-exist better with
the “loud” streams (like bulk transfer).
1.1
TCP backoﬀ slows down every circuit at once
Tor combines all the circuits going between two Tor relays into a single TCP connection. This approach is a
smart idea in terms of anonymity, since putting all circuits on the same connection prevents an observer from
learning which packets correspond to which circuit. But over the past year, research has shown that it’s a
bad idea in terms of performance, since TCP’s backoﬀ mechanism only has one option when that connection
is sending too many bytes: slow it down, and thus slow down all the circuits going across it.
We could ﬁx this problem by switching to a design with one circuit per TCP connection. But that means
that a relay with 1000 connections and 1000 circuits per connection would need a million sockets open. That
number is a problem for even the well-designed operating systems and routers out there.
More generally, Tor currently uses two levels of congestion avoidance – TCP ﬂow control per-link, and
a simple windowing scheme per-circuit. It has been suggested that this approach is causing performance
problems, because the two schemes interact badly.
Experiments show that moving congestion management to be fully end-to-end oﬀers a signiﬁcant im-
provement in performance.
There have been two proposals to resolve this problem, but their underlying principle is the same: use
an unreliable protocol for links between Tor relays, and perform error recovery and congestion management
between the client and exit relay. Tor partially funded Joel Reardon’s thesis [13] under Ian Goldberg. His
thesis proposed using DTLS [14] (a UDP variant of TLS) as the link protocol and a cut-down version of
TCP to give reliability and congestion avoidance, but largely using the existing Tor cell protocol. Csaba
Kiraly et al. [3] proposed using IPSec [1] to replace the entire Tor cell and link protocol.
Each approach has its own strengths and weaknesses. DTLS is relatively immature, and Reardon noted
deﬁciencies in the OpenSSL implementation of the protocol. However, the largest missing piece from this
proposal is a high-quality, privacy preserving TCP stack, under a compatible license. Prior work has shown
that there is a substantial privacy leak from TCP stack and clockskew ﬁngerprinting [4, 8]. Therefore to
adopt this proposal, Tor would need to incorporate a TCP stack, modiﬁed to operate in user-mode and to
not leak identity information.
Reardon built a prototype around the TCP-Daytona stack [12], developed at IBM Labs, and based on
the Linux kernel TCP stack. This implementation is not publicly available and its license is unclear, so it is
unlikely to be suitable for use in Tor. Writing a TCP stack from scratch is a substantial undertaking, and
therefore other attempts have been to move diﬀerent operating system stacks into user-space. While there
have been some prototypes, the maturity of these systems have yet to be shown.
Kiraly et al. rely on the operating system IPsec stack, and a modiﬁcation to the IKE key exchange
protocol to support onion routing. As with the proposal from Reardon, there is a risk of operating system
and machine ﬁngerprinting from exposing the client TCP stack to the exit relay. This could be resolved in