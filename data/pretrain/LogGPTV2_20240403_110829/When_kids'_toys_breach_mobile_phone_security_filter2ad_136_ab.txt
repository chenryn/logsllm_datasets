each application was based on a diﬀerent set of question-
s/images. In the ﬁrst phase of experiments (which we also
refer to as Session I), users interacted with one application.
They then returned on another day at their convenience to
interact with the second application (i.e., during Session II).
All participants used the same brand of phone—the Google
Nexus S running Android version 4.0—so as to avoid bias in
our ﬁndings that might be caused by diﬀerences in the way
1Li et al.
[16] used the tap gesture in conjunction with
the two swipe gestures. However they found that it had
very poor discriminability in comparison to the two swipe
gestures.
in which diﬀerent phones extract information from touch
gestures.
3.2 Feature Extraction and Preprocessing
Before extracting features from the data, we performed
an outlier ﬁltering step to eliminate very short strokes s-
ince these likely originated from click events (or taps), as
opposed to swiping (scrolling). Frank et al. [17] performed
a similar step on users’ strokes before proceeding with the
classiﬁcation process. Having removed outliers, we extracted
28 features from each stroke. There is currently no univer-
sal feature-set that researchers use to represent a distinct
stroke. For example, Frank et al.
[17] deﬁned 30 features
and discarded 3 of them after feature analysis, Li et al. [16]
deﬁned 13 features (or 14 features if the x and y coordinates
of a point are considered as distinct features) and discarded
4 of them after feature analysis while Feng et al. [27] used 53
features. For this work we used 28 features that we believe
best summarize the statistical attributes of a touch stroke.
A description of how we computed these features follows:
Using the pressure and area readings at diﬀerent points
along a stroke, we respectively built a pressure vector, P ,
and an area vector, A, to represent the pressure and area
associated with the stroke. We computed the velocity be-
tween every pair of consecutive points along a stroke, and
used these values to generate the velocity vector, V . Finally,
for every pair of points in V , we computed the acceleration,
′
and generated an acceleration vector, A
.
′
For each of the four vectors A, P , V and A
, we computed
ﬁve measures to summarize a user’s mean behavior, variabil-
ity in behavior and extreme behavior along a stroke. These
were: 1) lower quartile, 2) second quartile, 3) third quartile,
4) mean, and, 5) standard deviation. This gave a total of 20
(=4(cid:2) 5) features per stroke. The last 8 features making up
a vector representing a stroke were: the x and y coordinates
of the starting points, the x and y coordinates of the end
points, the distance between the end and starting points of
a stroke, the time taken to complete the stroke, the tangen-
t of the angle between the line joining the end-points of a
stroke and the horizontal, and the sum of distances between
every pair of adjacent points on a stroke.
4. ATTACK DESIGN
4.1 General Assumptions
The attacks launched in this paper assume an adversary
who gets physical access to a phone for which touch-based
continuous authentication is the only active layer of defence.
In practice, this scenario may arise for an attacker who : 1)
breaks the PIN lock mechanism (e.g., using methods such as
those in [6][22]), or, 2) ﬁnds a phone in which the PIN lock
has been disabled temporarily (e.g., a user who sets a very
long timeout for the PIN lock), or, 3) ﬁnds a phone in which
the PIN lock has been completely disabled by the owner [17].
To be able to determine the amount of extra security that
touch-based continuous authentication adds to the standard
PIN lock in the worst case, we believe that these assump-
tions must necessarily be made. See [7], for an investigation
in which a similar assumption (i.e., that the adversary has
access to the victim’s password) was made in order to enable
rigorous evaluation of the security of Randomized Biometric
Templates (RBTs).
601(a) Spatial distribution of
swiping
during
vertical swiping.
activity
(b) Spatial distribution of
swiping activity during hor-
izontal swiping.
Figure 1: Color map showing the spatial distribu-
tion of touch strokes on the phone screen. A high
intensity of blue corresponds to regions which saw
very few strokes, while a high intensity of red im-
plies a region which saw intense swiping activity.
The phone was being used in portrait mode when
the strokes were generated. Note that the coordi-
nate system used on the ﬁgures is diﬀerent from that
used by the Android system.
In the attack itself, the attacker will seek to view pri-
vate information on the phone (e.g., emails, pictures, etc.,)
without triggering the anomaly detection mechanism. The
attack thus basically proceeds by scrolling/swiping through
documents on the phone.
In practice we believe that the
attacker could even assist the robot during certain opera-
tions (e.g., occasionally clicking at a challenging location),
since the anomaly detector will most likely not be sensitive
enough to detect a few anomalous clicks. Next we discuss
the underlying statistical observations that drive the attack,
and the details of the mechanical and algorithmic design of
the robot.
4.2 How do People Swipe on the Phone?
To design the attacks, we ﬁrst examine the way in which
people swipe in general. How random is swiping behavior
across a population? Are there certain distinct traits that
manifest frequently across a large number of users? This
section provides answers to these and related questions. Due
to space limitations, we only present results on the pressure
exerted on the screen, the area between the ﬁnger and the
screen and the region of the phone at which most swiping is
done. Other measures such as the time taken to complete a
stroke, the velocity of the ﬁnger and the length of a stroke,
to mention but a few, are left out here but will be used to
guide the attack design.
4.2.1 Location of Swiping Activity
Figure 1 shows the density of touch strokes captured at
diﬀerent positions of the phone screen during the ﬁrst phase
of experiments. The dark blue color corresponds to regions
which saw very little or no swiping/scrolling activity while a
high intensity of red corresponds to regions which saw a lot
of swiping. Observe (Figure 1(a)) that the vast majority of
(a) Distribution of the mean pres-
sure and mean area across touch
strokes.
(b) Distribution of the standard de-
viation of the mean pressure and
mean area across touch strokes.
Figure 2: CDFs expressing the mean and variability
of area and pressure seen across the population.
vertical strokes generated by our user population originated
from points having X values in the neighborhood of 300 u-
nits, and terminated at a position with an X value of close
to 400 units (and vice versa). Notably, this region of high
activity comprises less than 50% of the screen display. The
heart of the red region (which tends towards black) occupies
an even much smaller portion of the screen. Similar traits
(see Figure 1(b)) were seen with horizontal swiping.
Based on evidence provided through this plot, an adver-
sary with access to general population statistics could poten-
tially signiﬁcantly narrow down the scope of features such
as: 1) the x coordinate of the start point of a stroke, 2) the y
coordinate of the start point of a stroke, 3) the x coordinate
of the end point of a stroke, 3) the y coordinate of the end
point of a stroke, 4) the duration of a stroke, 5) the summa-
tion of distances between consecutive points of a stroke, and
6) the direction of the end-to end line, among other features.
These features represent a good proportion of the features
used to characterize users’ touch gestures in past research
(e.g., see [17][16]), and will also be used in this study.
Regarding the cause of the clustering tendency, our con-
jecture is that the high density of strokes on the right side
of the screen (i.e., taking the case of vertical swiping for
instance) was likely because the majority of users are right
handed, tending to hold the phone in the right hand and
swiping with the thumb, or holding the phone in the left
hand and swiping using one of the ﬁngers on the right hand.
In any of these two scenarios, a user is very likely to swipe
in the manner reﬂected in the ﬁgure. We do not rule out the
possibility that certain applications could depict variations
XY0  1002003004000  100200300400500600700800XY0  1002003004000  10020030040050060070080000.20.40.60.8100.20.40.60.81MeanCDF  AreaPressure00.10.20.300.20.40.60.81Standard DeviationCDF  AreaPressure602Figure 3: Mechanical design of the robot. The three motors (Motor A, Motor B and Motor C) are respectively
responsible for moving the robot ﬁnger left and right (Mvmt A), up and down (Mvmt B) and back and forth
(Mvmt C). Motor B contributes to the pressure exerted on the screen. Depending on the input parameters
to the motors (see Algorithm 1), the superposition of the three primitive motor movements is able to produce
touch strokes with diﬀerent properties.
from the pattern shown in the ﬁgure. In this case we argue
that a committed attacker who has interest in breaking into
such applications can make research on the swiping traits
associated with these applications.
4.2.2 Finger Area and Pressure on the Screen
Figure 2(a) shows the distribution of the mean area touched
by the ﬁnger and the mean pressure exerted on the screen
across a subset of our full user population. To plot the ﬁg-
ures, we computed each user’s mean area (and mean pres-
sure) and plotted the results on the CDF. Observe that over
80% of the population had a mean area of between 0.1 and
0.25 and that about 50% of the population had mean pres-
sure values of between 0.4 and 0.6. These user proportions
already suggest that a large number of users could be clus-
tered around a narrow band of values (for both pressure and
area). To get a more concrete insight into the possible clus-
tering of users’ proﬁles, we studied the variability seen by
users for each of these two variables.
Particularly, we computed the standard deviation of the
mean area and mean pressure exhibited by each of the user-
s represented in Figure 2(a), and then plotted these values
on a CDF (Figure 2(b)). Taking the case of pressure for
instance, the ﬁgure shows that about 40% of the users had
a standard deviation of over 0.15. Assuming users’ mean
pressure values follow a Gaussian distribution, a user with a
standard deviation of 0.15 could see her/his biometric pat-
tern fall on a band having a width of up to 0.6 units (i.e., 2
standard deviations on either side of the mean). Given such
a wide span, an input selected from the earlier mentioned
clustered regions (Figure 2(a)) could have a good chance of
falling within such a user’s feature range.
Similar observations made for the other features (e.g., ve-
locity, length of strokes, start point of stroke, etc.) further
prompted us to hypothesize that generic information from
the population could possibly enable us to implement a suc-
cessful attack on a subset of the users.
4.3 Mechanical Design
4.3.1 Design of the Robot
Figure 3 depicts the robot design. The main components
of the robot are: 2 NXT Intelligent bricks, 3 motors, 1 rack
gear, 1 pinion gear, 4 wheels and the robotic arm stroking
the screen. Throughout the rest of the paper we will refer
to this robotic arm as the robot ﬁnger (or the ﬁnger). The
two Intelligent bricks, one of which serving as the CPU of
the system, are joined to form the chassis on which other
components are built. Motor C, which propels the wheels,
is responsible for moving the ﬁnger back and forth. Motor
A on the other hand drives the pinion and rack gear system
to move the ﬁnger left and right. Motor B moves the ﬁnger
up and down, and thus helps control the pressure exerted
by the ﬁnger on the screen. Depending on the way in which
the three motors are conﬁgured (see Algorithm 1), the robot
can create strokes having diﬀerent properties (e.g., velocity,
direction, pressure, etc.).
4.3.2 Fabrication of the Finger
We had three main design considerations regarding the
object to be used to touch the screen. These were: 1) the
object had to be able to register touch events on the capaci-
tative screen, 2) it had to easily match the ﬁnger surface area
as needed, 3) it had to be soft to avoid damaging the screen,
and 4) it had to be made from cheap, domestically accessi-
ble materials. The fourth point rules out technologies such
as prosthetics [10] that despite guaranteeing artiﬁcial ﬁngers
that could match many of the properties of a human ﬁnger,
would make the attack implementation expensive, and likely
defeat our aim of demonstrating how easily the attack can
Motor AMotor CPinion GearRack GearRobot FingerMotor BMvmnt  BMvmnt  CMvmnt  A603ALGORITHM 1: Swiping Mechanism
Input: numOfSwipes//Number of Swipes;
Input: SLRight//Step length right;
Input: speedRight//Speed right;
Input: SLFwd//Step length forward;
Input: SLBkwd//Step length backward;
Input: speedFwd//Speed forward;
Input: speedBkwd//Speed backward;
Input: speedUpDown//Finger up-down speed;
Input: numOfSteps
//Number of steps needed to complete the swipe;
GenerateSwipingSteps()
for i 1 to numOfSwipes do
rfs=GRandom((cid:22)1,(cid:27)1); //Gaussian noise in speed
FingerDown(speedUpDown);
for j 1 to (p) //Steps upward-right
do
FingerForward(speedFwd,SLFwd);
FingerRight(speedRight+rfs,SLRight);
for k 1 to (NumOfSteps-p)//Steps downward-right
do
FingerBackward(speedBkwd,SLBkwd);
FingerRight(speedRight+rfs,SLRight);
FingerUp();
FingerBack();
Wait(swipeInterval);//Inter-swipe interval
be launched based on materials that are cheaply available
oﬀ the shelf.
To address all four points we fabricated the ﬁnger surface
from play-doh [28], a malleable compound that children use
to model diﬀerent kinds of play-objects. Although play-doh
on its own was able to register touch points on the screen,
we housed it inside a touch screen glove (see [2]) in order
to have close control of the ﬁnger area touching the screen.
In all experiments we set our ﬁnger area to be approximate-
ly 0.15 units, which was the mean value we observed across
our user population. The area setting itself was manual—we