title:Efficient Detection of Split Personalities in Malware
author:Davide Balzarotti and
Marco Cova and
Christoph Karlberger and
Engin Kirda and
Christopher Kruegel and
Giovanni Vigna
Efﬁcient Detection of Split Personalities in Malware
Davide Balzarotti1, Marco Cova3, Christoph Karlberger2
Christopher Kruegel3, Engin Kirda2, and Giovanni Vigna3
1Institute Eurecom,
Sophia Antipolis
2Secure Systems Lab,
Vienna University of Technology
3University of California,
Santa Barbara
Abstract
can efﬁciently detect malware samples that use a variety
of techniques to identify emulated analysis environments.
Malware is the root cause of many security threats on
the Internet. To cope with the thousands of new malware
samples that are discovered every day, security compa-
nies and analysts rely on automated tools to extract the
runtime behavior of malicious programs. Of course, mal-
ware authors are aware of these tools and increasingly
try to thwart their analysis techniques. To this end, mal-
ware code is often equipped with checks that look for ev-
idence of emulated or virtualized analysis environments.
When such evidence is found, the malware program be-
haves differently or crashes, thus showing a different
“personality” than on a real system.
Recent work has introduced transparent analysis plat-
forms (such as Ether or Cobra) that make it signif-
icantly more difﬁcult for malware programs to detect
their presence. Others have proposed techniques to iden-
tify and bypass checks introduced by malware authors.
Both approaches are often successful in exposing the
runtime behavior of malware even when the malicious
code attempts to thwart analysis efforts. However, these
techniques induce signiﬁcant performance overhead, es-
pecially for ﬁne-grained analysis. Unfortunately, this
makes them unsuitable for the analysis of current high-
volume malware feeds.
In this paper, we present a technique that efﬁciently
detects when a malware program behaves differently in
an emulated analysis environment and on an uninstru-
mented reference host. The basic idea is simple: we just
compare the runtime behavior of a sample in our anal-
ysis system and on a reference machine. However, ob-
taining a robust and efﬁcient comparison is very difﬁcult.
In particular, our approach consists of recording the in-
teractions of the malware with the operating system in
one run and using this information to deterministically
replay the program in our analysis environment. Our ex-
periments demonstrate that, by using our approach, one
1
Introduction
The steady growth in the number of malware samples
found every day has elicited an increased effort by se-
curity vendors and analysts to develop automated mal-
ware analysis tools [1, 3–6, 8]. These analysis systems
typically execute an unknown program in a restricted en-
vironment (a sandbox) and monitor the program’s run-
time behavior. Based on the observed behavior, analysts
can then assess the severity of the threat posed by the
malware and develop appropriate countermeasures. Of
course, malware authors have a vested interest in creating
malicious code that can evade automated screening and
analysis procedures. The reason is that, by remaining in-
visible to automated analysis systems, malware programs
can operate (and generate revenue) for a longer period of
time.
To thwart automated screening, malware authors have
developed a number of ways to check for the presence
of malware analysis tools and popular sandbox environ-
ments [19, 32]. When the malware detects indications
that a malware analysis system is present, it typically
suppresses the execution of malicious functionality or
simply terminates. The way in which the checks are im-
plemented depends on the type of malware analysis sys-
tem that is targeted. One class of checks leverages in-
put from the runtime environment (the operating system)
to determine whether an analysis tool is present. Often,
such checks look for ﬁles, registry keys, or processes that
are speciﬁc to individual analysis tools. A second class
of checks exploits characteristics of the execution envi-
ronment that are different between a real host and an em-
ulated or virtualized system (which is frequently used to
implement the analysis sandbox). For these checks, small
variations in the semantics of CPU instructions or timing
properties are leveraged to determine whether a malware
process is run in an emulator or a virtual machine (VM).
To solve the problem of “analysis-aware malware” re-
searchers have explored two kinds of approaches. One
class of approaches focuses on the development of analy-
sis platforms that are more difﬁcult to detect by malicious
code. Cobra [38] is one of the ﬁrst systems that intro-
duced the idea of stealth (or transparent) malware analy-
sis. To this end, the system performs dynamic translation
of the malicious code under examination. That is, every
code block is disassembled and inspected before it is ex-
ecuted. During this process, each instruction that could
be used to detect Cobra is replaced with a safe version,
called a stealth implant [37]. Later, researchers proposed
Ether [16], a system that leverages hardware virtualiza-
tion to remain invisible to malware checks.
Both Cobra and Ether have been shown to be difﬁ-
cult to detect by current malware. However, both sys-
tems also induce a signiﬁcant performance penalty, in
particular when performing ﬁne-grained analysis. Unfor-
tunately, this level of analysis is required for comprehen-
sive reports such as those produced by Anubis (our own
malware analysis tool [1, 8]) or similar systems [3–6].
This is because these systems need, at least, to inspect
the arguments of Windows API library functions in ad-
dition to system calls, and often track additional infor-
mation during runtime. The main reason for the perfor-
mance impact is the fact that Cobra and Ether operate on
individual instructions or single-step through the process
execution.
Interestingly, the authors of Ether note that
their ﬁne-grained analysis “is not meant to be used for
real-time analysis,” while the authors of Cobra note that
the performance of their tool is “within the limits of inter-
active analysis.” Given these limitations, these systems
are not suitable for automated analysis of high-volume
malware feeds. For example, Anubis receives several
thousand malware samples every day, and this number
is likely to be signiﬁcantly larger for commercial anti-
malware companies.
A second class of approaches to address the prob-
lem of analysis-aware malware is to detect the fact that
a malware sample behaves differently in different envi-
ronments. Recently, researchers have proposed a tool
in which the execution of a malware sample in an em-
ulated (analysis) environment is compared with the exe-
cution trace of this sample on a reference system [22].
A deviation is considered to be caused by a malware
check that results in the execution of a different pro-
gram path. The basic idea is appealing in theory, be-
cause it promises a very general mechanism to detect
malware that behaves differently in an analysis environ-
ment than it does on a reference system. However, there
are a number of problems that must be solved in prac-
tice. In particular, it is important to perform the detec-
tion of deviations efﬁciently, and any deviation must be
the result of a malware check and not due to unrelated
differences between the execution traces. Unfortunately,
the previously-mentioned tool [22] fails to adequately ad-
dress both challenges. First, the tool uses Ether to pro-
duce the reference trace, which causes an unacceptable
performance penalty. Second, malware samples are sim-
ply executed twice, once on the analysis environment
and a second time on the reference system. However, as
our experiments demonstrate, executing the same mal-
ware program twice can lead to different execution runs,
even when no anti-analysis checks are present. Thus, a
difference between two execution traces is not a reliable
indicator for the presence of any anti-analysis checks in
malware samples.
In this paper, we present a tool that reliably and ef-
ﬁciently detects malware that changes its behavior in-
side an (emulated) analysis environment, that is, malware
with split personality. To perform the detection, we lever-
age the basic insight that, given the same inputs, the ex-
ecution of a program should be the same in our analysis
environment and on a reference system. More precisely,
we ﬁrst use a kernel driver on the reference host to efﬁ-
ciently record a trace of the system calls (and their argu-
ments) that are executed by the malware under analysis.
This system call log contains both the output arguments
(the values produced by the program and consumed by
the operating system) and the input arguments (the val-
ues provided by the operating system and consumed by
the program). In the next step, the malware is executed
in the analysis environment. Our analysis environment is
a modiﬁed version of Anubis, which is an extension of
Qemu, a full-system emulator. Based on the system call
log, we can supply the same input arguments that the pro-
gram previously received on the reference system. That
is, we can perform precise replay of the malware pro-
cess. This allows us to check whether the system calls
(and their output arguments) that we observe in the anal-
ysis environment correspond to the ones we expect from
the reference system, given the previously-recorded in-
formation. Since the inputs to the processes are the same,
we expect any deviation to be the result of a check that
detected our analysis system, and hence, caused the ma-
licious code to follow a different execution path.
Our Windows process replay infrastructure, a core
component of the analysis environment, is comprehen-
sive and supports features that require special handling,
such as multiple threads, memory-mapped ﬁles, and de-
ferred system calls. This is necessary to handle the com-
plex internals of Windows processes and make the sys-
tem work on real malware programs. Our experimental
results show that the proposed system can identify a wide
range of different anti-analysis checks. Moreover, the
system can successfully execute (replay) programs that
do not contain checks, and can detect malware in the wild
that implements anti-emulator checks.
The main contributions of this paper are as follows:
• We propose a reliable and efﬁcient approach to de-
tect malware with split personality. Our approach
works by comparing the system call trace recorded
when running a malware program on a reference
system with the behavior observed in the analysis
environment.
• We have implemented a comprehensive replay in-
frastructure for Windows processes that allows us
to execute the program under analysis with the same
inputs on the reference system and the analysis en-
vironment.
• We demonstrate that our tool is successful in detect-
ing a variety of checks used to identify analysis en-
vironments, including malware samples in the wild
that contain checks that evade Anubis.
2 Problem Statement
The ultimate goal of an automated malware analysis
tool (such as Anubis) is to obtain an understanding of the
runtime behavior of malicious code that is as complete
as possible.
In practice, these analysis tools typically
follow a dynamic approach and simply run an unknown
program, monitoring its runtime behavior. The two main
issues that limit the completeness of the results delivered
by a dynamic analysis tool are (a) limited test cover-
age and (b) malware programs that detect and evade the
analysis environment. To address the problem of limited
test coverage, researchers have proposed extensions that
explore multiple execution paths [10, 30, 39] or that scan
non-executed code regions using static analysis [13].
To address the problem of malware that detects the
analysis environment, researchers have proposed stealthy
(transparent) analysis tools [16,38] that are more difﬁcult
to identify. As mentioned previously, these tools are ef-
fective and can gather system call traces in an efﬁcient
fashion. However, for a more ﬁne-grained analysis that
includes more than system calls, the tools have to resort
to a mode in which individual instructions are inspected
and logged. This is too slow for handling current mal-
ware feeds, which typically contain many thousand sam-
ples every day. Unfortunately, for a complete and com-
prehensive analysis, Anubis and other tools need to see
more than a system call trace, and hence, require a ﬁne-
grained analysis. For example, Anubis examines Win-
dows API library calls, and it tracks data ﬂow dependen-
cies.
Transparent malware analysis. One could consider
directly modifying Anubis or a similar analysis tool to
make it invisible to malware checks. To assess the
promise of this approach, it is useful to examine the
different ways in which malware can detect an analy-
sis environment. Following the terminology introduced
by the authors of Ether [16], a transparent (undetectable)
malware analysis system has to fulﬁll ﬁve basic require-
ments. We will discuss these requirements in the context
of Anubis, since this is the system for which we have im-
plemented the techniques presented in this paper. How-
ever, the discussion holds in general for all approaches
that execute the malware (and the operating system) in an
emulator or a virtualized environment. There are alterna-
tive techniques (such as CWSandbox or Joebox) where
parts of the analysis system run inside the malware pro-
cess or in the same operating system. In these cases, the
malware executes at a privilege level that is similar to the
analyzer, and, as a result, the analysis platforms cannot
be transparent [16].
The ﬁrst requirement for transparency states that the
analysis tool has to run in a higher privilege level than
the program it analyzes. This requirement is trivially sat-
isﬁed by approaches that run the target in an emulator or a
virtual machine. This is also true for the second require-
ment, which states that all side-effects introduced by the
analyzer must not be accessible through non-privileged
(malware) operations.
The third requirement dictates that the semantics of
the instruction set used by the analyzer has to be the same
as the one used by a real host. This condition is difﬁcult
to fulﬁll for an emulator. An emulator basically provides
a software implementation of a complex hardware de-
vice (a CPU). Hence, it is always possible that there are
differences that can be detected. Indeed, previous work
has pointed out CPU semantics attacks [16,19,22,27,32]
based on differences between emulated and real CPUs,
and such attacks are also used actively by malware in the
wild. The checks used by these attacks exploit undoc-
umented side-effects of x86 instructions or look for the
presence of CPU-speciﬁc mode registers that are typi-
cally not present on the emulated processor.
The fourth requirement mandates that exception han-
dling must be transparent. This also demands that system
calls (including system call results) have to be the same
on the analysis platform and on a real host. The authors
of Ether state that this requirement can be fulﬁlled by
Anubis and other emulator-based systems “with careful
design.” However, in practice, there are many ways in
which the presence of an emulator can be detected by
checking for artifacts in the operating system environ-
ment. This includes speciﬁc processes, drivers, or reg-
istry values in the guest operating system. For example,
in a typical installation of Windows in VMware Work-
station, the registry contains over 300 occurrences of the
string VMware. While it is in principle possible to hide
these artifacts, it is difﬁcult in practice. As a result, many
environment attacks [11] exist that look for resources in
the guest operating system to identify a malware analysis
environment or the emulator/virtual machine used by the
malware analysis tool.
The ﬁfth requirement states that, for a transparent mal-
ware analysis system, there has to be an identical mea-
surement of time. That is, instructions need to take
the same time on the emulator as on the real machine.
Clearly, this is not possible, since emulators and virtual
machines add additional overhead that make the execu-
tion slower than on a native system. Given the large
number of possible channels through which a process
can time its execution, timing attacks [32] are very dif-
ﬁcult to mitigate. Indeed, systems such as Ether explic-
itly exclude timing checks based on input from external
resources (such as an NTP time server on the Internet)
from their threat model.
Given the complexity of the analysis system as well
as the range of CPU semantics, environment, and tim-
ing attacks that a malware author has at his/her disposal,
making Anubis invisible to individual checks is clearly
an uphill battle. Similarly, Garﬁnkel et al. [20] concluded
that realizing a VMM that is indistinguishable from na-
tive hardware is difﬁcult to the point of impracticality.
Thus, we envision a more general approach to address
the problem of analysis-aware malware. Our approach is
a two-step process.
Detecting malware with split personalities.
In the
ﬁrst step, we detect whether a malware program has a
split personality. This is the focus of the tool presented in
this paper. That is, the goal of the tool presented here is to
detect malware programs whose runtime behavior in an
emulator-based malware analysis system (such as Anu-
bis) is different from the behavior that these programs
exhibit on a reference system (a system where the mal-
ware analysis system is not present). Note that we con-
sider an emulator (such as Qemu, which is used by Anu-