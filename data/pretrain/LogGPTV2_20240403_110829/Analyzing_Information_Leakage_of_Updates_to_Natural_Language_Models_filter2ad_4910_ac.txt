High to Low
Penn Treebank
RNN (120.90)
1:18K 1:3.6K 1:1.8K
3.97
3.40
3.97
3.52
3.02
3.90
3.46
1.96
3.94
3.85
3.61
2.83
Reddit
RNN (79.63)
1:1M 1:100K 1:10K
3.96
2.83
3.98
0.42
0.23
3.92
2.89
0.74
3.91
3.66
3.04
1.59
Transformer (69.29)
1:1M 1:100K 1:10K
3.99
3.22
3.97
0.25
0.39
3.96
3.10
0.18
3.97
3.66
3.25
1.87
Wikitext-103
RNN (48.59)
1:1M 1:200K
3.81
1.39
3.21
0.07
0.25
3.02
1.22
0.08
Table 2: Differential Score (DSğ‘€â€²
ğ‘€ ) of the mixed frequency canary phrase for the Reddit (RNN) model using different update
techniques. Model ğ‘€ is trained on ğ·orig. For the Retraining column, ğ‘€â€² is trained on ğ·orig âˆª ğ·extra âˆª ğ¶ starting from random
initial parameters. For the Contâ€™d Training 1 column, ğ‘€â€² is trained on ğ·extra âˆª ğ¶ starting from ğ‘€. For the Contâ€™d Training 2
Ëœğ‘€ on ğ·extra âˆª ğ¶ starting from ğ‘€, and then train model ğ‘€â€² from Ëœğ‘€ using additional public data
column, we first train a model
ğ·â€²
extra. A white cell background means that the differential rank DR (as approximated by our beam search) of the phrase is 0,
gray cell background means that DR is >1000.
|ğ·extra|/|ğ·orig |
1:1M
1:100K
0%
0.23
3.04
Retraining
50%
0.223
3.031
20%
0.224
3.032
100%
0.229
3.038
Continued Training 1
100%
20%
0.52
0.46
3.27
3.56
50%
0.34
3.25
Continued Training 2
100%
0.01
0.26
to extract canary phrases that correspond to the change in train-
ing data between ğ‘€ and ğ‘€â€². The results of varying the number
of inserted canaries are summarized in Table 1. We highlight the
following findings:
â€¢ For most combinations of ğ‘˜ and types of canaries, we
successfully recover the canary. This is indicated by the cells
with white background, where the canary phrase has the maximum
differential score among all token sequences found by our beam
search, i.e., it ranks first.
â€¢ The signal for extraction is strong even when the inserted
canaries account for only 0.0001% of the tokens in the dataset.
This is visible in the first row of Table 1 where differential scores
approach 4 â€” close to the upper bound of 5 for 5-token canaries.
â€¢ Private phrases that occur more often in the training data are
more exposed via a model update, as expected. This is visible in
the monotonic growth of the differential score of canaries with the
number of insertions.
â€¢ Phrases composed of rare words are more easily extracted,
as seen in the high differential score of canaries constructed from
low-frequency tokens. In contrast, canaries with descending token
frequencies tolerate much higher number of insertions before being
exposed. This is expected, as our beam search is biased towards
finding high-scoring prefixes.
â€¢ Access to two model snapshots reveals substantially more
than access to a single snapshot. For comparison, we successfully
extract a 5-token canary inserted 1 in 200k times (i.e. inserting one
token every 1M tokens) from two snapshots of an LSTM-based
generative model without additional knowledge. In contrast, [6,
Section 6.1] reports failing to extract the middle token of a 5-token
canary inserted 1 in 100k times from a similar LSTM-based model
when given the first and last two words.
RQ1: Effect of amount of public vs. private data. In Table 2 we
vary the amount of public data by partitioning the dataset ğ· into
ğ·orig âŠ ğ·extra such that the latter is 20%, 50%, or 100% of the size of
ğ·orig (the 0% column is identical to Table 1). The retraining column
shows that DSğ‘€â€²
ğ‘€ does not change significantly across the different
dataset splits. That is, canaries can be extracted from the trained
model even when they are contained in a substantially larger dataset
extension. Hence, the amount of public data in the update does not
significantly affect the leakage of the private data.
RQ2: Effect of training type. We train a model ğ‘€ on a dataset
ğ·orig to convergence, and then continue training ğ‘€ using ğ·extra
and the canaries ğ¶, obtaining ğ‘€â€². We compare the differential rank
of the canaries on the models obtained using continued training
with that on the models retrained from scratch (shown in the middle
column of Table 2). We observe that in all cases the differential score
is higher for continued training than for retraining. As expected,
the differential score of the canary phrase decreases as additional
extra data is used for fine-tuning.
RQ3: Effect of background knowledge. We evaluate the differen-
tial score of suffixes of a canary phrase ğ‘  assuming knowledge of
a prefix. For ğ‘– = 1, . . . , ğ‘› we take the prefix ğ‘¡1 . . . ğ‘¡ğ‘–âˆ’1 of the canary
phrase and compute the differential score ğ‘Ÿ of the token ğ‘¡ğ‘– condi-
tional on having read the prefix, i.e., ğ‘€â€²(ğ‘¡<ğ‘–)(ğ‘¡ğ‘–) âˆ’ ğ‘€(ğ‘¡<ğ‘–)(ğ‘¡ğ‘–). The
relationship between ğ‘– and ğ‘Ÿ indicates how much knowledge about
ğ‘  is required to expose the remainder of the canary phrase.
Figure 1 depicts the result of this analysis for canaries with high-
to-low and all-low token frequencies on the Reddit dataset. Our
results show that, while the differential score of the first token
without context is close to 0, the score of subsequent tokens quickly
grows for all-low canaries, even with a low number of canary
Analyzing Information Leakage of Updates to Natural Language Models
CCS â€™20, November 9â€“13, 2020, Virtual Event, USA
The exposed sentences are on-topic w.r.t. the newsgroup in-
cluded, e.g., the hockey theme dominates the top ranked sequences
in Table 3. This suggests that, information about the private data
used for the update is leaked. It is noteworthy that these results are
obtained assuming a weak adversary that does not require either
background knowledge about the dataset distribution or about the
information it tries to extract. In contrast, concurrent work on up-
dates of image classification models [24] requires knowledge about
the data distribution to train shadow models, while prior work on
single language models [6] requires a known prefix for extraction
of a secret.
Given some background knowledge in the form of a long enough
prefix of a phrase occurring in the private data, we show that the
complete phrase can be extracted by a beam search directed by
differential score (see Table 5).
RQ1: Effect of amount of public vs. private data. We consider
partitions of the Reddit dataset ğ· into ğ·orig and ğ·extra of different
relative sizes. For each partition, we train a model ğ‘€ on ğ·orig and
a model ğ‘€â€² on ğ·orig âˆª ğ·extra âˆª ğ‘ , where ğ‘ are all messages from
talk.politics.mideast. We observe the following:
â€¢ For all phrases, the proportion of public data ranging from 5%
to 100% used in the update does not significantly affect their relative
differential scores, which confirms our findings for canaries.
â€¢ The top two phrases resemble canaries in that they occur
literally multiple times in the update dataset, which explains their
high scores. An exception is Little resistance was offered,
which appears 12 times in the dataset but still has low score. Other
phrases do not occur literally in newsgroup messages, but digest
recurrent discussions or contain ğ‘›-grams that do occur.
RQ2: Effect of training type. We train a model ğ‘€ on ğ·orig to
convergence, and then continue training ğ‘€ using ğ·extra âˆª ğ‘ to
produce a model ğ‘€â€². To understand the effect of the training type
on information leakage, we sample a set of representative phrases
and compare their relative differential scores w.r.t. ğ‘€ and ğ‘€â€² against
their scores w.r.t. ğ‘€ and a model trained on ğ· âˆª ğ‘ from scratch.
The results are shown in Table 4, together with the perplexity
decrease after the model update. Retrained models correspond to the
data update and data deletion scenarios and their perplexity drop is
greater the more data is used during retraining. Continued training
corresponds to the data specialization scenario. The perplexity drop
in the updated model is greater the larger is the proportion of
newsgroup data used in the update, for which the initial model is
not specialized.
The last two rows in Table 4 correspond to phrases found by
group beam search in the continued training scenario, but that
have too low a score to be found when ğ‘€â€² is retrained from scratch
instead. The converse, i.e., phrases that have low score when contin-
uing training and high score when retraining, seems to occur rarely
and less consistently (e.g., Saudi troops surrounded village).
For phrases that occur literally in the dataset, the results are in
line with those for canaries (see Table 2), with scores decreasing as
more data is used during the fine-tuning stage. For other phrases,
the results are not as clear-cut. While fine-tuning a model exclu-
sively on private data yields scores that are significantly higher
than when retraining a model from scratch, this effect vanishes
Figure 1: Differential score of tokens in canaries given a pre-
fix for the Reddit dataset. LL-ğ‘˜ denotes ğ‘˜ canary insertions
with all-low token frequencies (solid lines), and HL-ğ‘˜ de-
notes high-to-low token frequencies (dashed lines).
insertions. In contrast, more context is required before the score of
high-to-low canaries increases, as the model is less influenced by
the small number of additional occurrences of frequent tokens.
This suggests that, even in cases where we fail to extract the
canary without additional knowledge, an adversary can use the
differential rank to complete a partially known phrase, or confirm
that a phrase was used to update the model.
4.5 Results with Real-world Data
We simulate real-world scenarios by sourcing training data from
real-world conversations on specific topics, and using it as a proxy
for private data included in the training data used in model updates.
The adversaryâ€™s goal is to extract specific phrases occurring in the
proxy dataset, or phrases that do not occur literally but nonetheless
reveal the topic of conversations.
We mimic the data distribution shift by choosing conversations
on topics that are not dominant in the original dataset, so that
we can better judge whether phrases extracted using differential
score are on-topic and thus represent meaningful leakage of private
information. Specifically, we compare models trained only on data
from the Reddit dataset against models trained on data from the
Reddit dataset plus messages from one of two newsgroups from
the 20 Newsgroups dataset [19]:
a) rec.sport.hockey, containing around 184K tokens, â‰ˆ1% of the
b) talk.politics.mideast, containing around 430K tokens, â‰ˆ2%
original training data; and
of the original training data.
We train a model ğ‘€ on the entire Reddit dataset and retrain
ğ‘€â€² from scratch on the same dataset plus all messages from one
of the two newsgroups. For both model architectures (RNNs and
Transformer) described in Section 4.1 and each newsgroup, we
compute the sequences with highest relative differential score. Since
the sequences returned by vanilla beam search typically share a
common prefix, we run a group beam search (see Section 3.2) to
get a more diverse sample.
RQ0: Can an attacker learn private information from model up-
dates? Tables 3 and 7 (in the Appendix) display the highest-scoring
sequences of length 4 in each group of a(cid:102)DS-based 5-group beam
search.
00.20.40.60.81Diï¬€erentialscore01234Preï¬xLengthHL-5HL-50HL-500LL-5LL-50LL-500CCS â€™20, November 9â€“13, 2020, Virtual Event, USA
Zanella-BÃ©guelin, Wutschitz, Tople, RÃ¼hle, Paverd, Ohrimenko, KÃ¶pf, and Brockschmidt
Table 3: Top ranked phrases in group beam search for a model updated with rec.sport.hockey. For the layperson: Los Angeles
Kings, Minnesota North Stars, and Toronto Maple Leaf are National Hockey League teams; Norm Green was the owner of the
North Stars; an ice hockey game consists of three periods with overtime to break ties. Capitalization added for emphasis.
Phrase
RNN
Phrase
Transformer
(cid:102)DS
(cid:102)DS
Angeles Kings prize pools
National Hockey League champions
Norm â€™s advocate is
Intention you lecture me
Covering yourself basically means
56.42
53.68
39.66
21.59
21.41
Minnesota North Stars playoff
Arsenal Maple Leaf fans
Overtime no scoring chance
Period 2 power play
Penalty shot playoff results
96.81
71.88
54.77
47,85