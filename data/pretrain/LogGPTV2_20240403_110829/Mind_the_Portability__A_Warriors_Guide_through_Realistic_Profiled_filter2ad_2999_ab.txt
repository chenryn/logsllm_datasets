This subsection recalls some of the commonly used machine
learning algorithms in the context of side-channel analysis and
supervised learning.
1) Supervised Learning: When discussing proﬁled side-
channel attacks and machine learning, we are usually inter-
ested in the classiﬁcation task as given with the supervised
machine learning paradigm. There, a computer program is
asked to specify to which of c categories (classes) a certain
input belongs.
More formally, let calligraphic letters (X ) denote distribu-
tions over some sets, capital letters (X) denote sets drawn from
distributions, i.e., X ∈ X , and the corresponding lowercase
letters (x) denote their realizations. We denote the set of N
examples as X = x1, . . . , xN , where xi ∈ X . For each
example x, there is a corresponding labels y, where y ∈ Y.
Typically, we assume that examples are drawn independently
and identically distributed from a common distribution on
X × Y. We denote the measured example as x ∈ X and
consider a vector of D data points (features) for each example
such that x = x1, . . . , xD.
The goal for supervised learning is to learn a mapping f :
Rn → {1, . . . , c}. When y = f (x), the model assigns an input
described by x to a category identied by y. The function f is
an element of the space of all possible functions F.
Supervised learning works in two phases, commonly known
as the training and testing phases. In the training phase, there
are N available pairs (xi, yi) with i = 1, . . . , N which are
used to build the function f. Then, the testing phase uses addi-
tional M examples from X, i.e., x1, . . . , (cid:126)xM and function f to
estimate the corresponding classes Y = y1, . . . , yM . To build a
strong model f, we need to avoid overﬁtting and underﬁtting.
Overﬁtting happens when the machine learning model learned
the training data too well and it cannot generalize to previously
unseen data. Underﬁtting happens when the machine learning
model cannot model the training data.
C. Validation and Cross-validation
When using the validation approach, the data is divided
into three parts: training, validation, and test data. One trains
a number of models with different hyper-parameters on the
training set and then test the model on the validation set. The
hyper-parameters giving the best performance on the validation
set are selected. Then, the model with such selected hyper-
parameters is used to predict test data.
When using cross-validation, the data is divided into two
parts: training and testing data. The training data is randomly
partitioned into complementary subsets. Then, machine learn-
ing models with different hyper-parameters are trained against
different combinations of those subsets and validated on the
remaining subsets. The hyper-parameters with the best results
are used to train the data and then used on test data. The most
common cross-validation setting is the k-fold cross-validation.
There, the training set is randomly divided into k subsets and
different (k − 1) subsets are used for training models with
different hyper-parameters and the remaining one is used for
validation.
Both validation and cross-validation are aimed at preventing
overﬁtting. The main advantage of cross-validation is that one
does not need to divide the data into three parts. On the other
hand, validation is computationally simpler and usually used
with deep learning as there, training can last a long time. We
discuss in the next sections the advantages and drawbacks of
these two techniques when considering portability issues.
D. Classiﬁcation Algorithms
First, we discuss classical machine learning techniques
where we must conduct a pre-processing phase to select the
most important features. Afterward, we consider deep learning
techniques that use all the features.
1) Naive Bayes (NB): NB classiﬁer is a method based on
the Bayesian rule that works under a simplifying assumption
that the predictor features (measurements) are mutually inde-
pendent among the D features, given the class value Y . The
existence of highly-correlated features in a dataset can inﬂu-
ence the learning process and reduce the number of successful
predictions. Additionally, NB assumes a normal distribution
for predictor features. The NB classiﬁer outputs posterior
probabilities as a result of the classiﬁcation procedure [26].
2) Random Forest (RF): RF is a well-known ensemble
decision tree learner [27]. Decision trees choose their splitting
attributes from a random subset of k attributes at each internal
node. The best split is taken among these randomly chosen
attributes and the trees are built without pruning. RF is a
stochastic algorithm because of its two sources of randomness:
bootstrap sampling and attribute selection at node splitting.
3) Multilayer Perceptron (MLP): MLP is a feed-forward
neural network that maps sets of inputs onto sets of appropriate
outputs. MLP consists of multiple layers (at least three) of
nodes in a directed graph, where each layer is fully connected
to the next one and training of the network is done with the
backpropagation algorithm.
4) Convolutional Neural Network (CNN): CNNs are a type
of neural network ﬁrst designed for 2-dimensional convolu-
tions as inspired by the biological processes of animals’ visual
cortex [28]. They are primarily used for image classiﬁcation,
but in recent years, they have proven to be a powerful tool in
security applications [29], [30]. CNNs are similar to ordinary
neural networks (e.g., MLP): they consist of a number of layers
where each layer is made up of neurons. CNNs use three
main types of layers: convolutional layers, pooling layers, and
fully-connected layers. A CNN is a sequence of layers, and
every layer of a network transforms one volume of activation
functions to another through a differentiable function. When
considering the CNN architecture, input holds the raw features.
Convolution layer computes the output of neurons that are
connected to local regions in the input, each computing a
dot product between their weights and a small region they
are connected to in the input volume. Pooling performs a
down-sampling operation along the spatial dimensions. The
fully-connected layer computes either the hidden activations
or the class scores. Batch normalization is used to normalize
the input layer by adjusting and scaling the activations after
applying standard scaling using running mean and standard
deviation.
III. EXPERIMENTAL SETUP
In this section, we present the threat model followed by
details on the experimental setup and four scenarios we
investigate in our experiments. Finally, we provide details
about hyper-parameter tuning.
4
A. Threat Model
The threat model is a typical proﬁled side-channel setting.
The adversary has access to a clone device running the target
cryptographic algorithm (AES-128 in this case). The clone
device can be queried with a known key and plaintext, while
corresponding leakage measurement trace is stored. Ideally,
the adversary can have inﬁnite queries and corresponding
database of side-channel leakage measurements to character-
ize a precise model. Next, the adversary queries the attack
device with known plaintext to obtain the unknown key. The
corresponding side-channel leakage measurement is compared
to the characterized model to recover the key. We consider this
to be a standard model as a number of certiﬁcation laboratories
are evaluating hundreds of security-critical products under this
model daily.
B. Setup
While proﬁled side-channel analysis is known since 2002,
very few studies are done in realistic settings. By realistic,
we mean that the adversary proﬁles a clone device and ﬁnally
mounts the attack on a separate target device. Most studies,
proﬁle and attack the same device. Furthermore, some studies
draw proﬁling and testing sets from the same measurement
pool, which generally is least affected by environmental vari-
ations. Such biases in the adversary model can lead to highly
inaccurate conclusions on the power of the attack.
To perform a realistic study about proﬁled side-channel
analysis, which is actually performed on separate devices, we
needed multiple copies of the same device. The target device is
an 8-bit AVR microcontroller mounted on a custom-designed
PCB. The PCB is adapted for side-channel measurement.
Precisely, a low-noise resistor (39 Ω) is inserted between the
VCC (voltage input) of the microcontroller and the actual
VCC from the power supply. Measuring the voltage drop
across the resistor allows side-channel measurement in terms
of power consumption. The PCB is designed to have special
measurement points for accessing this voltage drop easily.
The choice of microcontroller, i.e., AVR Atmega328p 8-
bit microcontroller, is motivated by the underlying technology
node. Since the chip is manufactured in 350nm technology,
the impact of process variation is low. Therefore the obtained
results will reﬂect the best-case scenario. Also, side-channel
countermeasures are considered out of scope to reﬂect the
best-case scenario. A choice of a newer manufacturing node
or countermeasures would make it difﬁcult to carefully quan-
tify the impact of portability alone, independent of process
variation or impact of protections. Finally,
this device is
often used for benchmarking side-channel attacks allowing fair
comparison in different research works.
The overall measurement setup is depicted in Figure 2.
The microcontroller is clocked at 16M Hz and runs the AES-
128 algorithm in software. The board is connected to a two-
channel Tektronix TDS2012 oscilloscope with a sampling rate
of 2GS/s (Giga-samples per second). The power traces are
captured corresponding to AES-128 execution, synchronized
with a board generated trigger. A computer is used to pilot
Fig. 2: Illustration of the measurement setup.
the whole setup. It generates random 128-bit plaintext and, via
UART, transmits it to the board and awaits acknowledgment
of the ciphertext. Upon receiving ciphertext, the software then
retrieves the waveform samples from an oscilloscope and
saves it to hard-drive indexed with corresponding plaintext
and ciphertext. To minimize the storage overhead, the trace
comprised of 600 sample points (features) captures only the
execution of the ﬁrst SubBytes call, i.e., the target of the
following attacks (the output of the ﬁrst AES S-box in the
SubBytes layer). The AES S-box is an 8-bit input to an 8-bit
output mapping, which computes multiplicative inverse fol-
lowed by an afﬁne transformation on polynomials over GF (2).
For performance reasons, it is implemented as a precomputed
look-up table. The table is indexed with p[0] ⊕ k[0], where
(p[0], k[0]) are the ﬁrst bytes of plaintext and key, respectively.
The output of the S-box is stored in the internal registers or
memory of the microcontroller and is the main side-channel
leakage that we target. The labeling of data is done on the
output byte of the S-box. Due to the nonlinearity of the S-
box, it is much easier to statistically distinguish the correct
key from wrong keys at the output of the S-box, which is
why we choose to attack here.
Figure 3 shows an example measurement trace for the full
amount of 600 features on the top. Below is the correlation
between the measurement set and the activity corresponding to
the S-box look-up with the ﬁrst byte of plaintext. We highlight
the 50 features with the highest absolute Pearson correlation
in red. One can see that these 50 features cover nearly all
leaking points.
Finally, in order to investigate the inﬂuence of the number of
training examples, we consider settings with 10 000 and 40 000
measurements in the training phase. In total, we conducted
more than 150 experiments in order to provide a detailed
analysis of the subject.
C. Parallel Measurement
We use four copies of the target device to conduct our study.
Four experiments were set up in parallel (two parallel setups
shown in Figure 4a). Parallel setups allowed us to collect the
experimental data faster as well as to minimize the effect of
change in environmental conditions. To be able to test different
scenarios, we measured 50 000 side-channel leakage measure-
5
Fig. 3: Measurement trace and corresponding correlation (se-
lected 50 features in red).
(a) Two sets of equipment recording data in parallel.
ments corresponding to 50 000 random plaintext on different
boards (B1, B2, B3, B4) with three randomly chosen secret
keys. In the following, each dataset is denoted in the format
Bx Ky, where x denotes board ID and y denotes the key ID.
For example, B1 K1, denotes the dataset corresponding to
K1 measured on board B1. The four boards and keys used for
collecting various datasets are shown in Figure 4b. In this case,
B4 K1 is repeated. This provides a benchmark comparison
in the scenario where both the device and the keys are the
same, although not measured at the same time.
Although the measurement setups are identical, executing
exactly the same code and measuring the same operations,
there will still be some difference due to process and envi-
ronmental factors. To highlight the difference of the leakages
from different devices, we calculate Normalized Inter-Class
Variance (NICV [24]). NICV can be used to detect relevant
leakage points in side-channel traces as well as to compare
the quality of side-channel measurements. It is computed as:
N ICV =
,
(1)
V{E{T|X}}
V{T}
where T denotes a side-channel trace and X is the public
parameter (plaintext/ciphertext), used to partition the traces.
E{·} and V{·} are statistical expectation and variance. NICV
is bounded in the range [0, 1].
it
From Figure 5a,
is clear that even for similar im-
plementations, the leakage differs, and each setting has its
leakage characteristics. The impact of these differences will
be evaluated in the following sections using machine learning-
based proﬁled side-channel attacks. As a comparison, for the
same device and key scenario (B4 K1), as given in Figure 5b,
the NICV pattern is almost completely the same.
D. Scenarios under Consideration
In our experiments, we consider several scenarios with
respect to the targets:
• Same device and same key. In this setting, we use
the same device and only a single key to conduct both
proﬁling/validation and attack. Despite the fact that this
scenario is far from the realistic setting, it is usually
explored in the SCA community. Consequently, most of
the works consider this scenario and report results for it.
(b) SCA Boards labelled with different keys.
Fig. 4: Parallel equipment setup. The three keys are randomly
generated. The keys are repeated across different boards to
test the impact of varying target board and the secret key in
various conﬁgurations.
We emphasize that this is also the simplest scenario for
the attacker.
• Same device and different key. In this scenario, we
assume there is only one device to conduct both proﬁling
and attack, but the key is different in those two phases.
This scenario can sound unrealistic since there is only one
device, but we still consider it as an interesting stepping
stone toward more realistic (but also more difﬁcult)
scenarios.
• Different device and same key. Here, we assume there
are two devices (one for proﬁling and the second one
for the attack) that use the same key. While this scenario
can again sound unrealistic, we note that it emulates the
setting where one key would be hardcoded on a number
of devices.
• Different device and different key. This represents the
realistic setting since it assumes one device to train and
a second device to attack. Additionally,
the keys are