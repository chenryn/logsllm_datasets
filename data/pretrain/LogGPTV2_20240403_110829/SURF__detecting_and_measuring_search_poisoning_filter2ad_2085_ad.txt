the other the number of distinct (landing domain, keyword) pairs.
The two peeks (marked by A and B in the ﬁgure) that appeared
around Christmas time and the Super Bowl are not a coincidence.
Our analysis shows that important predictable events can help ad-
versaries to further increase their poisoning success rate, given the
sufﬁciently large preparing time (enabled by the predictability of
the events) and the interest of large number of search users in the
events being exploited. At the same time, less predictable break-
ing news that receive broad attention for a not too short amount of
time (e.g., a few days) are also an easy target for search poisoning.
An example of this is the earthquake and tsunami that recently hit
Japan (marked by C in Figure 5). Furthermore, as the targeted key-
words (upper curve) ﬂuctuated between attempts to leverage differ-
ent events, the number of detected landing domains (lower curve)
remained somewhat more stable, suggesting that search poisoning
Figure 4: Micro measurement statistics
(e.g., domain names, IP address, etc.) through a cloud service, thus
potentially improving SURF’s detection accuracy.
5. EMPIRICAL MEASUREMENTS
To gain a deeper insight into the search poisoning problem, we
performed a long-term (7 months, 212 days) measurement study.
As discussed in Section 2, we manually analyzed data in the ﬁrst
month. We used SURF to analyze browsing data we collected in
the next 6 months. During this period we instructed SURF to an-
alyze over 12 millions search results from both Google and Bing
collected by querying the top 40 “trendy” keywords [2]. In prac-
tice, once a search keyword appeared in the top 40 list on a given
day, we used SURF to query the search engines for this keyword
for the following 7 days. Overall, during our measurement study
SURF automatically queried the search engines with 8,480 key-
words. This long-term data collection process enabled us to study
in-the-wild search poisoning instances from two different angles,
a “micro measurement” study based on a 7-day window that fo-
cuses on how search poisoning evolves with respect to frequently
changing keyword popularity, and a “macro measurement” study
that looks at poisoning trends over the entire 7-month period.
5.1 Micro Measurements
Due to frequent changes in the trendy search keywords [2], we
expected that some time (e.g., a few days) would be required for the
attackers to poison the search terms and make their landing pages
of choice appear in the related top search results. Surprisingly, our
measurements on the micro developments of detected search poi-
soning cases suggest otherwise: adversaries are extremely respon-
sive and have built effective approaches to promote rogue landing
pages under the targeted trendy search keywords in a short time.
Among the 3,869 keywords for which we detected related poi-
soned search results, 38% of them had poisoning lag (i.e., the time
it takes for the ﬁrst poisoned result to be detected) of one day or
less. This percentage decreases as the lag increases, and only 7%
of the keywords had a poisoning lag of 7 days, as shown in Figure 4.
This results suggest that the adversaries are capable of keeping up
with search users’ interests, and that the majority of their poisoning
attempts succeed within the ﬁrst 3 days.
We also found that the average life time of a rogue landing page
involved in search poisoning is only 1.7 days. This indicates that
adversaries favor a fast-switching strategy to reduce the exposure
window, thus reducing the possibility of the rogue pages being de-
tected and conserving the compromised landing sites for reuse in
future poisoning attacks. However, the appearance of these rogue
landing pages in the search results lasts for more than 3 days on
average, until the page ranking is demoted due to the new informa-
tion retrieved by the search crawlers. At the same time, the relative
volume of detected rogue landing pages for a given poisoned key-
word keeps increasing throughout the 7-day observation window,
0123456The 7-day Window00.20.40.60.81Relative percentagePoisoning lagsPosioned volume474Figure 5: Poisoned keywords percentage (left) and landing domains engaging search poisoning (right)
operators have a solid footing in the search engines’ indexes, and
are ready to launch new attacks whenever the opportunity comes.
On average, users who fall victim of search poisoning are redi-
rected at least twice, including one cross-domain redirection, be-
fore reaching the malicious terminal page. About 29% of these
redirections were due to HTTP 30x responses. Not surprisingly,
the majority of the remaining 70% were mostly due to client-side
scripts (likely an attempt to evade security crawlers that do not sup-
port script execution). About 78% of the landing page URLs ex-
plicitly contained the targeted search keywords to boost the page
relevance perceived by search crawlers. About 98% of the inter-
mediate URLs include ID-like parameters to track unique visitors,
identify search poisoning afﬁliates, or prevent repeated visits. In
94% of the cases, the terminal page URLs used domain names
registered for less than a year, with many of these domain cho-
sen to purposely deceive victim users and promote speciﬁc scams.
Among the detected search poisoning cases, the most frequently
used top-level domains (TLDs) for landing pages are .com, .org,
.net, and .info, with a TLD distribution similar to regular web-
sites. On the other hand, domains related to terminal pages were
mostly registered under TLDs such as .cc, .com, .in, and .net,
some of which are known to be malware friendly.
To have a sense of the variety of malicious content promoted
by search poisoning, we surveyed 350 randomly chosen terminal
pages. These 350 terminal pages were evenly distributed across
our 7-months measurement period. The results are shown in Fig-
ure 6. We manually categorized the terminal pages based on data
saved at the time when the page was visited by SURF, including
screen shots of each rendered page. As expected, fake AVs are the
most prevalent adopters of search poisoning during the entire 7-
month period. However, we noticed that their pervasiveness started
fading as other types of malicious terminal pages increased. Drive-
by malware downloads and other browser exploitation techniques
did not appear to be commonly leveraging search poisoning. On
the other hand, various types of social engineering-based malicious
pages are dominant players. The ﬁgure shows a clear surge of rogue
search engine pages, which present the users with links seemingly
relevant to the search keyword but aim to proﬁt from user clicks.
Figure 6: Terminal page variety survey
Scam pages (e.g., watch replicas, etc.) represent another signiﬁcant
fraction of the surveyed terminal pages. Regardless of their individ-
ual tactics, scam pages in general bait traps with free or unrealis-
tically cheap goods to attract users and steal private information
(e.g., credit card numbers, passwords, etc.). We also encountered
a number of malicious terminal pages related to click fraud and
rogue pharmacies. The terminal pages categorized as “void” typi-
cally contain clues of of certain types of maliciousness (e.g., based
on their domain name patterns) but were inaccessible when visited
due to unsuccessful DNS resolution, or webpage errors. SURF’s
ability to detect even these “void” malicious terminal pages sup-
ports our initial goal of building a detection system that is agnostic
to the speciﬁc content of malicious pages promoted through search
poisoning.
6. RELATED WORK
In this section, we identify and discuss two lines of work related
to our detection system.
Blackhat SEO countermeasures: Blackhat SEO, which involves
abusing search engine optimization techniques to achieve unde-
served rankings, is not a new problem and has been studied for year,
especially in the information retrieval community. Most proposed
detection methods work at the search engine level and attempt to
identify deceptive information introduced by the adversaries into
the search index to inﬂuence the rankings of their websites. Various
detection features explored by these methods mainly focus on two
aspects of indexed webpages: intra-page characteristics [18,22,25]
and inter-page linkages [24]. However, for adversaries with full
control over their injected search landing pages, such features are
not difﬁcult to evade, sometimes even without requiring changes to
their operation routines. In fact, this traditional way of countering
blackhat SEO has failed to stop its rising trend [11]. SURF ad-
dresses search poisoning, a new class of blackhat SEO, building on
the lessons learned from previous work and approaching the detec-
tion from a new angle using a set of feature that is more robust to
evasion (see Section 3.2.1).
deSEO [15] is a very recent work done in parallel with SURF. It
detects URLs from the search index that contain signatures derived
from known search poisoning landing pages and exhibit patterns
not previously seen by the search engine on the same domain. Since
there is no need to crawl each URL, this approach scales much bet-
ter than SURF when facing a huge volume of search results. How-
ever, deSEO is limited by the coverage of the URL signatures, and
may only ﬁnd a subset of what SURF detects. For example, about
12% landing page URLs detected by SURF in Section 5.2 do not
contain trendy search keywords, and thus may be missed by de-
SEO. Moreover, SURF does not rely on any information internal to
search engines and can be deployed at the client side, enabling sin-
gle browsers to detect poisoned search results as well as malicious
webpages behind them before the content is presented to the user.
2010-102010-112010-122011-012011-022011-032011-04Timeline (sampled weekly)00.20.40.60.81Poisoned keywordsBest rank poisoned < 100Best rank poisoned < 50Best rank poisoned < 10(relative to popular search keywords)2010-102010-112010-122011-012011-022011-032011-04Timeline (sampled weekly)02004006008001000120014001600Uniq. (dom, key) pairsUniq. landing domainsABC0%!20%!40%!60%!80%!100%!2010-9!2010-10!2010-11!2010-12!2011-1!2011-2!2011-3!Unknown!Void Page!Click Fraud!Rogue Pharmacy!Scam (discount luxury)!Scam (local service)!Scam (free gift)!Rogue Search Engine!Drive-by download!FakeAV!475Malicious webpage detection: SURF, when implemented as an
automated detection agent, can be viewed as a dynamic crawler
used to scan search results looking for poisoned ones. From this
perspective, SURF is similar to many proposed systems that crawl
the Internet for various kinds of malicious webpages [17,23]. Such
systems always employ an army of browsing agents running in a
controlled environment to visit suspicious URLs in batch and detect
signs of speciﬁc types of malicious activities. SURF can be easily
integrated into these systems and can enable the detection of search
poisoning cases along with the related compromised landing page
and malicious terminal pages. On the other hand, solely relying on
malicious page detectors for ﬁnding poisoned search results may
achieve limited success, because of the variety of terminal pages,
many of which use social engineering attacks that are difﬁcult to
detect.
Applying machine learning techniques to data collected during a
crawling session is also a common approach to detecting malicious
webpages. A recent work [21] is able to detect URLs that lead to
spam pages. Our work is different because SURF is not limited to
detecting spam pages, and can instead detect generic search poi-
soning cases.
7. CONCLUSION
Search poisoning is an abuse of SEO techniques by which mis-
creants target any search term that can maximize the number of
incoming search users to their malicious websites. We observed
through an empirical study that a key characteristic of search poi-
soning is the ubiquitous use of cross-site redirections. We designed
and implemented SURF, a novel detection system that runs as a
browser component and is able to detect malicious search user redi-
rections resulted from user clicking on poisoned search results.
SURF extracts a number of detection features from search-then-
visit browsing sessions. These features are robust and the resulting
classiﬁer is hard to evade because they capture the key properties
of search poisoning (derived from our empirical study and analy-
sis). Our evaluation showed that SURF can achieve a detection rate
of 99.1% at a false positive rate of 0.9% on a dataset that contains
real-world search poisoning instances. Using SURF, we also per-
formed a long-term measurement study on search poisoning on the
Internet over a period of seven months. Our study revealed new
trends and interesting patterns related to a great variety of poison-
ing cases, and underscored the prevalence and gravity of the search
poisoning problem.
8. ACKNOLEDGEMENT
The authors would like to thank the anonymous reviewers for
helpful comments on earlier versions of the paper. This material is
based upon work supported in part by the National Science Founda-
tion under grant no. 0831300, the Department of Homeland Secu-
rity under contract no. FA8750-08-2-0141, the Ofﬁce of Naval Re-
search under grants no. N000140710907 and no. N000140911042.
Any opinions, ﬁndings, and conclusions or recommendations ex-
pressed in this material are those of the authors and do not neces-
sarily reﬂect the views of the National Science Foundation, the De-
partment of Homeland Security, or the Ofﬁce of Naval Research.
9. REFERENCES
[1] Google search engine optimization.
http://www.google.com/webmasters/.
[2] Google trends. http://www.google.com/trends.
[3] URLVoid: Scan a website with multiple scanning engines.
http://www.urlvoid.com/.
[4] WOT: Web of trust. http://www.mywot.com/wiki/API.
[5] C4.5: Programs for Machine Learning. Morgan Kaufmann
Publishers, 1993.
[6] Google drives 70 percent of trafﬁc to most web sites.
http://searchengineoptimism.com/Google_refers_70_percent.html,
July 2006.
[7] Malware poisoning results for innocent searches.
http://www.eweek.com/c/a/Security/Malware-Poisoning-
Results-for-Innocent-Searches, November 2007.
[8] Barracuda labs 2010 mid-year security report. Technical
report, Barracuda Networks Inc., 2010.
[9] Search engine optimization ’poisoning’ way up this year.
http://www.networkworld.com/news/2010/110910-seo-
poisoning-increases.html, November 2010.
[10] The dirty little secrets of search.
http://www.nytimes.com/2011/02/13/business/13search.html,
February 2011.
[11] Google: Search engine spam on the rise.
http://www.pcworld.com/article/217370/google_search,
January 2011.
[12] Z. Gyöngyi and H. Garcia-Molina. Web spam taxonomy.
Technical report, Stanford University, 2005.
[13] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann,
and I. H. Witten. The weka data mining software: an update.
SIGKDD Explor. Newsl., 11(1):10–18, 2009.
[14] F. Howard and O. Komili. Poisoned search results: How
hackers have automated search engine poisoning attacks to
distribute malware. Technical report, SophosLab, 2010.
[15] J. John, F. Yu, Y. Xie, M. Abadi, and A. Krishnamurthy.
deSEO: Combating search-result poisoning. In Proceedings
of the 20th USENIX Security, 2011.
[16] L. Lu, V. Yegneswaran, P. Porras, and W. Lee. Blade: an
attack-agnostic approach for preventing drive-by malware
infections. In Proceedings of the 17th ACM CCS, 2010.
[17] E. Moshchuk, T. Bragin, S. D. Gribble, and H. M. Levy. A
crawler-based study of spyware on the web. In Proceedings
of the NDSS, 2006.
[18] A. Ntoulas and M. Manasse. Detecting spam web pages
through content analysis. In In Proceedings of the 15th
WWW, 2006.
[19] L. Page, S. Brin, R. Motwani, and T. Winograd. The
pagerank citation ranking: Bringing order to the web.
Technical Report 1999-66, Stanford InfoLab, 1999.
[20] M. A. Rajab, L. Ballard, P. Mavrommatis, N. Provos, and
X. Zhao. The nocebo effect on the web: an analysis of fake
anti-virus distribution. In Proceedings of the 3rd USENIX
LEET, 2010.
[21] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song. Design
and evaluation of a real-time url spam ﬁltering service. In In
Proceedings of the IEEE S&P, 2011.
[22] T. Urvoy, E. Chauveau, P. Filoche, and T. Lavergne. Tracking
web spam with html style similarities. ACM Trans. Web,
2:3:1–3:28, March 2008.
[23] Y.-M. Wang, D. Beck, X. Jiang, and R. Roussev. Automated
web patrol with strider honeymonkeys: Finding web sites
that exploit browser vulnerabilities. In Proceedings of the
NDSS, 2006.
[24] B. Wu and B. D. Davison. Identifying link farm spam pages.
In Proceedings of the 14th WWW, 2005.
[25] B. Wu and B. D. Davison. Detecting semantic cloaking on
the web. In Proceedings of the 15th WWW, 2006.
476