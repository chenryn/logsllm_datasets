### False Positive Rate and Threshold Determination

**Figure 7: Threshold Determination for a Given False Positive Rate**
For a given false positive rate and community size, we can compute the threshold \( V \). For instance, the vertical red line corresponds to approximately one false positive per six days.

**Figure 8: Training Data as a Predictor of False Positive Rates**
The training data is a good predictor of the false positive rates observed in monitoring data. The threshold \( V \) can be set as high as necessary to achieve an acceptable rate of false positives. In deployment, the expected false positives are one every five seconds. The vertical line represents a hypothetical target rate of \( 1 \times 10^{-5} \) (approximately one false positive every six days). The y-value at which this line intersects each community size line is the threshold for that value of \( n \).

### Distributed Monitoring

After training, Syzygy switches to monitoring mode. For these experiments, we set \( T_i = \infty \) to prevent hiatons from being introduced. Over the course of a week, we collected just under 10 billion anomaly scores from the community. Five clients seen during training were not heard from again, while four new ones appeared. There were no epidemics or other coordinated events during the monitoring period; the machines are part of the campus computing infrastructure, so we could not obtain permission to stage an epidemic.

- **Client Overhead**: The `strace` process on the client requires an average of 1–2% CPU overhead, and the Syzygy client script requires another 2–3% to calculate the anomaly scores and send them to the server.
- **Server Overhead**: The server-side Syzygy process uses less than 1% of the CPU for a single client. Our experiments suggest that a server could easily handle more than a hundred clients (see Section 7).

Syzygy can either send one packet per anomaly score or buffer some number before reporting them. At an average rate of 2000 system calls per second, sending one packet per call would be inefficient. Buffering 100 scores with a short timeout to ensure freshness reduces the bandwidth requirements to 20 packets per second at 1.5 KB per packet (∼ 30 KB/s), including the overhead of transmitting timestamps along with the anomaly scores. Communicating the scores alone would require less than half this bandwidth.

**Figure 8: Model Accuracy in Deployment**
Section 3.3 notes that achieving the target false positive rate requires that \( \mu_X \) and \( \sigma_X \) accurately describe the future distribution of anomaly scores. Figure 8 quantifies this statement using the deployment data collected while Syzygy was in monitoring mode (data not used to build the model). The diagonal red line indicates perfect agreement. Even at very low false positive rates and small community sizes, the modeling data was sufficient to allow good prediction of the false positive rate on real monitoring data.

### Controlled Experiments

In this section, we test Syzygy in a controlled environment under various adverse conditions, using trace data from commodity applications and exploits capable of sophisticated behaviors.

**Binary Classification Problem**
An experiment is a binary classification problem where Syzygy is given a sequence of anomaly scores for \( n \) clients and must decide whether 0 of them are infected (healthy) or whether \( d \geq 1 \) of them have been exploited (infected). Thus, an example is a set of \( n \) score vectors of length \( W_i \). Ideally, Syzygy should report an epidemic if one or more of the score vectors was produced by an infected client. We use standard metrics to evaluate performance on this classification problem: false positive rate (FP), false negative rate (FN), true positive rate (TP), true negative rate (TN), and F1 Measure (\( \frac{2TP}{2TP + FP + FN} \)), which combines precision and recall, weighting each equally.

**Example Construction**
For example, say we are measuring Syzygy’s performance on a community of size \( n = 100 \) and an epidemic of size \( d = 5 \). We produce an example of an infected community as follows:
- Construct models for all \( n \) clients and have the associated system call traces.
- To construct each of the \( n - d \) healthy score vectors, pick a window from the application trace, uniformly at random, and compute the anomaly scores as described in Section 4.1.
- Using exploit traces, construct \( d \) infected score vectors.
- Syzygy then takes the \( n \) vectors of anomaly scores and computes the elementwise averages. If \( C > V \) for any element \( C \) of the resulting community score vector, then Syzygy classifies the example as infected; otherwise, it classifies it as healthy.

**Figure 9: Example Community Scores**
Using data described in Section 6.1, we plot the community scores for a pair of examples in Figure 9. A healthy example is on the left, and an infected example is on the right. In the plot, the first 1000 scores are from a healthy community, while the next 1000 are from an infected community. Syzygy correctly identifies the infection point.

**Figure 10: Healthy Anomaly Distributions**
Healthy anomaly distributions, plotted with a kernel density estimator, show that the bump at around 2.75 suggests Adium’s model is imperfect.

This optimized text provides a clearer, more structured, and professional presentation of the original content.