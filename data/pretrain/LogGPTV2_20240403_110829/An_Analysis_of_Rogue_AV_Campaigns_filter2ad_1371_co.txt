a
R
P
F
l
a
u
t
c
A
n=
30
31
32
33
34
4
0
−
e
8
4
0
−
e
4
0
0
+
e
0
1e−06
1e−04
1e−02
0e+00
2e−04
4e−04
6e−04
8e−04
1e−03
False Positive Rate (log scale)
Predicted FP Rate
Fig. 7. For a given false positive rate
and community size, we can compute the
threshold V . The vertical red line, for
instance, corresponds to about one false
positive per six days.
Fig. 8. The training data is a good pre-
dictor of the false positive rates seen in
monitoring data. The threshold V can be
set as high as necessary to achieve an ac-
ceptable rate of false positives.
deployment, are expected false positives per ﬁve seconds. The vertical line is a
hypothetical target rate: 1 × 10−5 (about six days). The y-value at which this
line intercepts each community size line is the threshold for that value of n.
5.3 Distributed Monitoring
After training is complete, Syzygy switches to monitoring mode. For these ex-
periments, we set Ti = ∞ to prevent hiatons from being introduced. (We omit
the exploration of Ti values for space reasons.) Over the course of a week, we
collected just under 10 billion anomaly scores from the community. Five clients
seen during training were not heard from again, while four new ones appeared.
There were no epidemics nor other coordinated events during the monitoring
period; the machines are part of the campus computing infrastructure, so we
could not obtain permission to stage an epidemic.
The strace process on the client requires an average of 1–2% CPU overhead,
and the Syzygy client script requires another 2–3% to calculate the anomaly
scores and send them to the server. The server-side Syzygy process uses less
than 1% of the CPU for a single client; our experiments suggest a server could
easily handle more than a hundred clients (see Section 7).
Syzygy can either send one packet per anomaly score or buﬀer some number
before reporting them. At an average rate of 2000 system calls per second, send-
ing one packet per call would be ineﬃcient. Buﬀering 100 scores with a short
timeout to ensure freshness, for example, reduces the bandwidth requirements
to 20 packets per second at 1.5 KB per packet (∼ 30 KB/s), including the over-
head of transmitting timestamps along with the anomaly scores, which we did
for experimental purposes. Communicating the scores alone would require less
than half this bandwidth.
Section 3.3 notes that achieving the target false positive rate requires that μX
and σX accurately describe the future distribution of anomaly scores. Figure 8
quantiﬁes that statement using the deployment data collected while Syzygy
was in monitoring mode (data not used to build the model). The diagonal red
line indicates perfect agreement. Even at very low false positive rates and small
Community Epidemic Detection Using Time-Correlated Anomalies
373
community sizes, the modeling data was suﬃcient to allow good prediction of
the false positive rate on real monitoring data.
6 Controlled Experiments
In this section, we test Syzygy in a controlled environment under various adverse
conditions, using trace data from commodity applications and exploits capable
of sophisticated behaviors.
2T P
An experiment is a binary classiﬁcation problem in which Syzygy is given a
sequence of anomaly scores for n clients and must decide whether 0 of them are
infected (healthy) or whether d ≥ 1 of them have been exploited (infected). Thus,
an example is a set of n score vectors of length Wi. Ideally, Syzygy should report
an epidemic iﬀ one or more of the score vectors was produced by an infected
client. We use standard metrics to evaluate performance on this classiﬁcation
problem: false positive rate (FP), false negative rate (FN), true positive rate
2T P +F P +F N ), which combines
(TP), true negative rate (TN), and F1 Measure (
precision and recall, weighting each equally.
For example, say we are measuring Syzygy’s performance on a community of
size n = 100 and epidemic of size d = 5. We produce an example of an in-
fected community as follows. Say that we have already constructed models for all
n clients and have the associated system call traces. To construct each of the n− d
healthy score vectors, we pick a window from the application trace, uniformly at
random, and compute the anomaly scores as described in Section 4.1. (The sam-
ple window determines Ri.) Using exploit traces, we construct d infected score
vectors. Syzygy then takes the n vectors of anomaly scores and computes the ele-
mentwise averages. If C > V for any element C of the resulting community score
vector, then Syzygy classiﬁes the example as infected; otherwise, it classiﬁes it as
healthy. Using data described in Section 6.1, we plot the community scores for
a pair of examples in Figure 9; a healthy example is on the left and an infected
example on the right. In other words, in the plot, the ﬁrst 1000 scores are from a
healthy community, while the next 1000 are from an infected community—Syzygy
Healthy                                            Infected
Threshold (V)
Infection Point
)
C
(
e
r
o
c
S
y
t
i
n
u
m
m
o
C
2
.
2
0
.
2
8
.
1
6
1
.
4
.
1
y
t
i
s
n
e
D
0
1
8
6
4
2
0
Adium (mean= 2.5976 , sd= 1.3218 )
Camino (mean= 1.5645 , sd= 1.9471 )
Mail (mean= 1.3196 , sd= 1.9982 )
TextEdit (mean= 1.9679 , sd= 1.3489 
0
500
1000
1500
2000
Score Index
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Anomaly Score
Fig. 9. A pair of examples, using Camino
and the showpages exploit with n = 100
and d = 5, showing a TN and a TP
Fig. 10. Healthy anomaly distributions,
plotted with a kernel density estima-
tor. The bump at around 2.75 suggests
Adium’s model is imperfect.
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●