draw stronger conclusions about the role of demographics
in speech recognition systems.
Measuring the Harms of Skill Squatting.
It remains
unclear how effective our attack would be in the wild.
In order to observe this, we would need to submit pub-
lic skills to Amazon for certiﬁcation. In addition, our
work does not explore what an attacker may be able to
accomplish once a target skill is successfully squatted. In
initial testing, we successfully built phishing attacks on
top of skill squatting (for example, against the American
Express skill)1. However, investigating the scale of such
attacks is beyond the scope of this work. We hypothesize
that the most signiﬁcant risk comes from the possibil-
ity that an attacker could steal credentials to third party
services, but this topic merits further investigation.
Investigating IoT Trust Relationships. On the web,
many users have been conditioned to be security con-
scious, primarily through browser-warnings [13]. How-
ever, an outstanding question is whether that conditioning
transfers to a voice-controlled IoT setting. If an attacker
realizes that users trust voice interfaces more than other
forms of computation, they may build better, more tar-
geted attacks on voice-interfaces.
Generalizing our Models. An outstanding question is
whether our models can be broadly generalized to other
speech-recognition systems. It is unlikely that our Alexa-
speciﬁc model of systematic errors will translate directly
to other systems. However, the techniques we use to
build these models will work as long as we can leverage
a speech-recognition system as a black box. Future work
must be done in replicating our techniques to other speech-
recognition systems.
9 Related Work
Our work builds on research from a number of disciplines,
including linguistics, the human aspects of security and
targeted audio attacks on voice-controlled systems.
Dialects in Speech.
Linguists have developed models
of English speech since the 1970s, from intonation to
rhythm patterns [23]. Recently, researchers have used
phoneme and vowel data similar to that of the NSP
dataset [19] to study the patterns of speech by region
and gender [20, 21, 31]. Clopper has also investigated the
effects of dialect variation within sentences on “semantic
predictability”—this is the ability of a listener to discern
words based on the context in which they appear [18].
1https://youtu.be/kTPkwDzybcc
44    27th USENIX Security Symposium
USENIX Association
Typosquatting and Human Factors.
Our work
broadly aligns with research about the human aspects
of security, such as susceptibility to spam or phishing at-
tacks [25, 27]. Speciﬁcally, we focus on a long history of
research into domain typosquatting [12, 33, 43, 44]. Us-
ing ideas similar to our work, Nikiforakis et al. relied on
homophone confusion to ﬁnd vulnerable domain names
[35]. Most recently, Tahir et al. investigated why some
URLs are more susceptible to typosquatting than other
URLs [45]. Our work also draws on analysis of attack
vectors that are beyond simply making mistakes—Kintis
et al. studied the longitudinal effects of “combosquatting”
attacks, which are variants of typosquatting [29].
Other Skill Squatting Attacks. We are not alone in
highlighting the need to investigate the security of speech
recognition systems. In a recent preprint, Zhang et al.
report a variant of the skill squatting attack based on the
observation that Alexa favors the longest matching skill
name when processing voice commands [50]. If a user
embellished their voice command with naturalistic speech,
e.g.,“Alexa, open Sleep Sounds please” instead of “Alexa,
open Sleep Sounds,” an attacker may be able to register a
skill named Sleep Sounds please in order to squat on the
user’s intended skill. Their attack demonstrates dangerous
logic errors in the voice assistant’s skills market. In con-
trast, our work considers more broadly how the intrinsic
error present in natural language processing algorithms
can be weaponized to attack speech recognition systems.
Audio Attacks.
Researchers have shown time after
time that acoustic attacks are a viable vector causing harm
in computing devices. For example, shooting deliberate
audio at a drone can cause it to malfunction and crash [41].
Audio attacks have been used to bias sensor input on Fit-
bit devices and, further, can manipulate sensor input to
fully operate toy RC cars [47]. Audio has also been used
as an effective side channel in stealing private key infor-
mation during key generation [24] and leaking private
data through the modiﬁcation of vibration sensors [38].
Beyond such attacks, several researchers have devel-
oped a number of of adversarial examples of audio input
to trick voice-based interfaces. Carlini et al. demonstrated
that audio can be synthesized in a way that is indiscernible
to humans, but are actuated on by devices [15]. Further,
a number of researchers independently developed adver-
sarial audio attacks that are beyond the range of human
hearing [39, 42, 49]. Houdini demonstrated that it is
possible to construct adversarial audio ﬁles that are not
distinguishable from the legitimate ones by a human, but
lead to predicted invalid transcriptions by target automatic
speech recognition systems [17]. Carlini et al. developed
a technique for constructing adversarial audio against
Mozilla DeepSpeech with a 100% success rate [16]. More
recently, Yuan et al. showed that voice commands can
be automatically embedded into songs, while not being
detected by a human listener [48].
10 Conclusion
In this work, we investigated the interpretation errors
made by Amazon Alexa for 11,460 speech samples taken
from 60 speakers. We found that some classes of interpre-
tation errors are systematic, meaning they appear consis-
tently in repeated trials. We then showed how an attacker
can leverage systematic errors to surreptitiously trigger
malicious applications for users in the Alexa ecosystem.
Further, we demonstrated how this attack could be ex-
tended to target users based on their demographic infor-
mation. We hope our results inform the security com-
munity about the implications of interpretation errors in
speech-recognition systems and provide the groundwork
for future work in the area.
Acknowledgements
This work was supported in part by the National Science
Foundation under contracts CNS 1750024, CNS 1657534,
and CNS 1518741. This work was additionally supported
by the U.S. Department of Homeland Security contract
HSHQDC-17-J-00170. Any opinions, ﬁndings, conclu-
sions, or recommendations expressed in this material are
those of the authors and do not necessarily reﬂect the
views of their employers or the sponsors.
References
[1] Alexa skills store. https://www.alexaskillstore.com/.
[2] Ally
bank.
https://www.ally.com/bank/online-
banking/how-to-bank-with-ally/alexa/.
[3] Amazon alexa smart speaker market share dips below 70% in u.s.,
google rises to 25%. https://www.voicebot.ai/2018/01/
10/amazon-alexa-smart-speaker-market-share-dips-
70-u-s-google-rises-25/.
[4] American express skill.
com/us/content/alexa/.
https://www.americanexpress.
[5] Fish geek.
https://www.amazon.com/Matt-Mitchell-
Fish-Geek/dp/B01LMN5RGU/.
[6] Forvo. https://forvo.com/.
[7] Lyft. https://www.amazon.com/Lyft/dp/B01FV34BGE.
[8] Nest
thermostat.
https://www.amazon.com/Nest-Labs-
Inc-Thermostat/dp/B01EIQW9LY.
[9] Phish geek.
https://www.amazon.com/EP-Phish-Geek/
dp/B01DQG4F0A.
[10] The smart audio report
from npr and edison research.
http://nationalpublicmedia.com/wp-content/
uploads/2018/01/The-Smart-Audio-Report-from-
NPR-and-Edison-Research-Fall-Winter-2017.pdf.
USENIX Association
27th USENIX Security Symposium    45
[11] Uber.
https://www.amazon.com/Uber-Technologies-
Inc/dp/B01AYJQ9QK.
[12] P. Agten, W. Joosen, F. Piessens, and N. Nikiforakis. Seven
months’ worth of mistakes: A longitudinal study of typosquat-
ting abuse.
In 22nd Network and Distributed System Security
Symposium (NDSS).
[13] D. Akhawe and A. P. Felt. Alice in warningland: A large-scale
ﬁeld study of browser security warning effectiveness. In 22nd
USENIX Security Symposium (USENIX).
[14] Amazon. Alexa. https://developer.amazon.com/alexa.
[15] N. Carlini, P. Mishra, T. Vaidya, Y. Zhang, M. Sherr, C. Shields,
In 25th
D. Wagner, and W. Zhou. Hidden voice commands.
USENIX Security Symposium (USENIX).
[16] N. Carlini and D. Wagner. Audio adversarial examples: Targeted
In 1st Deep Learning and Security
attacks on speech-to-text.
Workshop (DLS).
[17] M. M. Cisse, Y. Adi, N. Neverova, and J. Keshet. Houdini: Fool-
ing deep structured visual and speech recognition models with
adversarial examples. In 31st Advances in Neural Information
Processing Systems (NIPS).
[18] C. G. Clopper. Effects of dialect variation on the semantic pre-
dictability beneﬁt. In Language and Cognitive Processes.
[19] C. G. Clopper. Linguistic experience and the perceptual classiﬁca-
tion of dialect variation. 2004.
[20] C. G. Clopper and R. Smiljanic. Effects of gender and regional
dialect on prosodic patterns in american english. In Journal of
Phonetics.
[21] C. G. Clopper and R. Smiljanic. Regional variation in temporal
organization in american english. In Journal of Phonetics.
[22] CMU. Cmu pronunciation dictionary. http://www.speech.cs.
cmu.edu/cgi-bin/cmudict.
[23] D. Crystal. Prosodic systems and intonation in English. CUP
Archive.
[24] D. Genkin, A. Shamir, and E. Tromer. Rsa key extraction
via low-bandwidth acoustic cryptanalysis. In 34th International
Cryptology Conference (CRYPTO).
[25] G. Ho, A. Sharma, M. Javed, V. Paxson, and D. Wagner. Detecting
credential spearphishing in enterprise settings. In 26th USENIX
Security Symposium (USENIX).
[26] F. Itakura. Minimum prediction residual principle applied to
IEEE Transactions on Acoustics, Speech,
speech recognition.
and Signal Processing.
[30] A. Klautau. ARPABET and the TIMIT alphabet. https://
web.archive.org/web/20160603180727/http://www.
laps.ufpa.br/aldebaro/papers/ak_arpabet01.pdf,
2001.
[31] W. Labov, S. Ash, and C. Boberg. The atlas of North American
English: Phonetics, phonology and sound change. 2005.
[32] T. Martin.
You can now use any alexa skill without
https://www.cnet.com/how-to/
enabling
amazon-echo-you-can-now-use-any-alexa-skill-
without-enabling-it-first/.
it ﬁrst.
[33] T. Moore and B. Edelman. Measuring the perpetrators and funders
of typosquatting. In 14th International Conference on Financial
Cryptography and Data Security.
[34] Namecheap. Do you support idn domains and emoticons?
https://www.namecheap.com/support/knowledgebase/
article.aspx/238/35/do-you-support-idn-domains-
and-emoticons.
[35] N. Nikiforakis, M. Balduzzi, L. Desmet, F. Piessens, and
W. Joosen. Soundsquatting: Uncovering the use of homophones
in domain squatting. In International Conference on Information
Security, 2014.
[36] S. Paul. Voice is the next big platform, unless you have an
accent. https://www.wired.com/2017/03/voice-is-the-
next-big-platform-unless-you-have-an-accent/.
[37] E. Protalinski. Google’s speech recognition technology now has
a 4.9% word error rate. https://venturebeat.com/2017/
05/17/googles-speech-recognition-technology-now-
has-a-4-9-word-error-rate/.
[38] N. Roy. Vibraphone project webpage. http://synrg.csl.
illinois.edu/vibraphone/. Last accessed 9 December 2015.
[39] N. Roy, H. Hassanieh, and R. R. Choudhury. Backdoor:
Making microphones hear inaudible sounds.
In 15th Annual
International Conference on Mobile Systems, Applications, and
Services (MobiSys).
[40] ScienceDaily. American Roentgen Ray Society. "Voice Recogni-
tion Systems Seem To Make More Errors With Women’s Dicta-
tion.". https://www.sciencedaily.com/releases/2007/
05/070504133050.htm, 2007.
[41] Y. Son, H. Shin, D. Kim, Y. Park, J. Noh, K. Choi, J. Choi,
and Y. Kim. Rocking drones with intentional sound noise
on gyroscopic sensors.
In 24th USENIX Security Symposium
(USENIX).
[42] L. Song and P. Mittal.
Inaudible voice commands. Preprint,
arXiv:1708.07238 [cs.CR], 2017.
[27] C. Kanich, C. Kreibich, K. Levchenko, B. Enright, G. M. Voelker,
V. Paxson, and S. Savage. Spamalytics: An empirical analy-
sis of spam marketing conversion. In 15th ACM conference on
Computer and communications security (CCS).
[43] J. Spaulding, S. Upadhyaya, and A. Mohaisen. The landscape
of domain name typosquatting: Techniques and countermeasures.
In 2016 11th International Conference on Availability, Reliability
and Security (ARES).
[28] B. Kinsella.
56 million smart speaker sales in 2018
says canalys. https://www.voicebot.ai/2018/01/07/56-
million-smart-speaker-sales-2018-says-canalys/.
[44] J. Szurdi, B. Kocso, G. Cseh, J. Spring, M. Felegyhazi, and
C. Kanich. The long "taile" of typosquatting domain names. In
23rd USENIX Security Symposium (USENIX).
[29] P. Kintis, N. Miramirkhani, C. Lever, Y. Chen, R. Romero-Gómez,
N. Pitropakis, N. Nikiforakis, and M. Antonakakis. Hiding in plain
sight: A longitudinal study of combosquatting abuse. In 24th
ACM Conference on Computer and Communications Security
(CCS), 2017.
[45] R. Tahir, A. Raza, F. Ahmad, J. Kazi, F. Zaffar, C. Kanich, and
M. Caesar. It’s all in the name: Why some urls are more vulner-
able to typosquatting. In 13th IEEE International Conference on
Computer Communications (INFOCOM).
46    27th USENIX Security Symposium
USENIX Association
[46] R. Tatman. Google’s speech recognition has a gender bias.
https://makingnoiseandhearingthings.com/2016/
07/12/googles-speech-recognition-has-a-gender-
bias/.
[47] T. Trippel, O. Weisse, W. Xu, P. Honeyman, and K. Fu. Wal-
nut: Waging doubt on the integrity of mems accelerometers with
acoustic injection attacks. In 2nd IEEE European Symposium on
Security and Privacy (Euro S&P).
[48] X. Yuan, Y. Chen, Y. Zhao, Y. Long, X. Liu, K. Chen, S. Zhang,
H. Huang, X. Wang, and C. A. Gunter. Commandersong: A
systematic approach for practical adversarial voice recognition. In
27th USENIX Security Symposium (USENIX).
[49] G. Zhang, C. Yan, X. Ji, T. Zhang, T. Zhang, and W. Xu. Dolphi-
nattack: Inaudible voice commands. In Proceedings of the ACM
Conference on Computer and Communications Security (CCS).
ACM, 2017.
[50] N. Zhang, X. Mi, X. Feng, X. Wang, Y. Tian, and F. Qian. Un-
derstanding and mitigating the security risks of voice-controlled
third-party skills on amazon alexa and google home. Preprint,
arXiv:1805.01525 [cs.CR], 2018.
USENIX Association
27th USENIX Security Symposium    47