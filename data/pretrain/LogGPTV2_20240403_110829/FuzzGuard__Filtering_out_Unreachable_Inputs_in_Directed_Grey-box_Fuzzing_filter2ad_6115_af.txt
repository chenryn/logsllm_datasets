for training.
ThrowReaderException(...);
1
2 if (dib_info.colors_important > 256)
3
4 if ((dib_info.image_size != 0U) && (dib_info.image_size
ThrowReaderException(...);
> file_size))
ThrowReaderException(...);
5
6 if ((dib_info.number_colors != 0) ||
(dib_info.bits_per_pixel storage_class=PseudoClass;
Listing 1: The vulnerable code of CVE-2018-20189.
2266    29th USENIX Security Symposium
USENIX Association
8 Discussion
Beneﬁt to input mutation. Most of the current fuzzers focus
on mutating inputs for enhancing the performance of fuzzing
(e.g., AFL [2], AFLFast [10] and AFLGo [9]). Different from
them, our idea is to help DGF ﬁlter out unreachable inputs.
Interestingly, we ﬁnd our approach could also potentially help
them to optimize the strategy of input mutation. If a fuzzer
knows the ﬁelds in inputs impacting the execution, it can mu-
tate them for letting the program execution reach the buggy
code. Modiﬁcation of other ﬁelds would not help in this pro-
cess. Based on the understanding of features extracted by
FuzzGuard, we ﬁnd that FuzzGuard could learn the ﬁelds
impacting the execution (see Section 7). Thus, FuzzGuard
could further help the DGF in the process of input mutation.
Learning models. Intuitively, the convolutional architecture
uses local patterns. But CNN can actually handle non-local
patterns as long as it has enough neural network layers. RNN
is similar: when it has enough layers, it can handle non-local
patterns; otherwise, it will forget former features. However,
the overhead of RNN to handle long data is very large. So we
choose to use a 3-layer CNN. In our evaluation, the results
show that CNN achieved a good performance (1.9% false
positive rate and 0.02% false negative rate on average), which
may indicate that most key features in the inputs are local
patterns (e.g., the ﬁeld bits_per_pixel in Figure 6). This is
understandable: for a single constraint in an if-statement, it
usually relies on the local bytes in inputs to make decisions.
Memory usage. In theory, we could keep the unreachable
inputs in memory forever to avoid missing a PoC. However, in
real situation, the memory is limited. So our idea is to remove
those inputs that are highly impossible to reach the buggy
code. In other words, if an input is judged as “unreachable”
by the updated models for dozens of times, it is highly possible
that it cannot reach the buggy code. In this way, we could
save memory while at the same time keeping the accuracy.
Based on our evaluation, no PoC is dropped in this way.
9 Related Work
Traditional Fuzzers. A lot of state-of-the-arts are proposed
in recent years. AFL [2] is a representative CGF fuzzer among
them, which gives other fuzzers a guidance. For example,
Böhme et al. [10] use the Markov model to construct the
fuzzing process. It chooses the seeds which exercise the
low-frequency execution paths, and then mutates them to
cover more code to ﬁnd bugs. FairFuzz [24] is similar to
AFLFast [10], but it provides new mutation strategies (i.e.,
overwritten, deleted and inserted). Gan et al. [16] ﬁx the prob-
lem of path collision in AFL by correcting the path coverage
calculation in AFL. Another variant of AFL is AFLGo [9],
it selects the seeds which have the execution path closer to
the targets path, and mutates them to trigger the target bugs.
And Chen et al. [12] improve AFLGo by new strategies of
seed selection and mutation. Some researchers improve the
effectiveness by traditional program analysis. For example, Li
et al. [25] use static analysis and instrumentation to acquire
the magic number position during execution and apply them
to the mutation to improve the execution depth of the test case.
Chen et al. [13] use dynamic techniques such as colorful taint
analysis to ﬁnd bugs. Rawat et al. [30] use both static and
dynamic analysis techniques to obtain control ﬂow and data
ﬂow information to improve the effectiveness of the mutation.
Chen et al. [14] discover memory layouts to perform accurate
fuzzing. Different from their work, we leverage deep-learning-
based approach to ﬁlter out unreachable inputs to increase the
performance of fuzzing.
Learning-based Fuzzers. There are also some fuzzers using
intelligent techniques. For example, You et al. [35] extract
vulnerable information from CVE descriptions and trigger
the bugs in Linux kernel. Wang et al. [33] learn the grammar
and semantics features from a large number of program in-
puts through probabilistic context sensitive grammar (PCSG),
and then generate program inputs from that PCSG. Similarly,
there are some previous studies [17, 28, 29] training static
models to improve the mutation strategy of the fuzzer by gen-
erating inputs that are more likely to trigger bugs. Godefroid
et al. [17] apply RNN to learn the grammar of program inputs
through a large number of test cases, and further leverage the
learned grammar to generate new inputs consequently. Rajpal
et al. [29] utilize a LSTM model to predict suitable bytes in
inputs and mutates these bytes to maximize edge-coverage
based on previous fuzzing experience. Nichols et al. [28] train
a GAN model to predict the executed path of an input. Chen
et al. [15] apply gradient descent algorithm to solve the path
constraint problem and ﬁnd the key bytes in an input to the
buggy code. She et al. [31] also utilize gradient descent to
smooth the neural network model and learn branches in the
program to improve program coverage. Different from these
studies which mainly focus on mutating inputs to achieve
high code coverage or to efﬁciently reach target buggy code,
the goal of FuzzGuard is to help DGF ﬁlter out unreachable
inputs, which is complementary and compatible with other
fuzzers, instead of replacing them.
10 Conclusion
Recently, DGF is efﬁcient to ﬁnd the bugs with potentially
known locations. To increase the efﬁciency of fuzzing, most
of the current studies focus on mutating inputs to increase
the possibility to reach the target, but little has been done on
ﬁltering out unreachable inputs. In this paper, we propose
a deep-learning-based approach, named FuzzGuard, which
predicts reachability of program inputs without executing the
program. We also present a suite of novel techniques to han-
dle the challenge of lacking representative labeled data. The
results on 45 real bugs show that up to 17.1× speedup could
be gained by FuzzGuard. We further show the key features
learned by FuzzGuard, which indeed impact the execution.
USENIX Association
29th USENIX Security Symposium    2267
Acknowledgments
The authors would like to thank our shepherd Konrad Rieck
and anonymous reviewers for their insightful comments. The
authors are supported in part by Beijing Natural Science Foun-
dation (No. JQ18011), NSFC U1836211, 61728209, National
Top-notch Youth Talents Program of China, Youth Innova-
tion Promotion Association CAS, Beijing Nova Program,
National Frontier Science and Technology Innovation Project
(No. YJKYYQ20170070).
References
[1] podofo. http://podofo.sourceforge.net, 2006.
[2] American fuzzy lop. http://lcamtuf.coredump.cx/
afl, 2018.
[3] Information
of
cve-2018-20189.
https:
//cve.mitre.org/cgi-bin/cvename.cgi?name=
CVE-2018-20189, 2018.
[4] Rectiﬁed linear unit. https://ldapwiki.com/wiki/
Rectified%20Linear%20Unit, 2018.
[5] Dominator (graph theory). https://en.wikipedia.
org/wiki/Dominator_(graph_theory), 2019.
[6] Networkx.
https://networkx.github.io, 2019.
[7] pytorch. https://pytorch.org/, 2019.
[8] Julius Adebayo, Justin Gilmer, Michael Muelly, Ian
Goodfellow, Moritz Hardt, and Been Kim. Sanity checks
for saliency maps. In Advances in Neural Information
Processing Systems, pages 9505–9515, 2018.
[9] Marcel Böhme, Van-Thuan Pham, Manh-Dung Nguyen,
and Abhik Roychoudhury. Directed greybox fuzzing. In
Proceedings of the 2017 ACM SIGSAC Conference on
Computer and Communications Security, pages 2329–
2344. ACM, 2017.
[10] Marcel Böhme, Van-Thuan Pham, and Abhik Roychoud-
hury. Coverage-based greybox fuzzing as markov
chain. In Proceedings of the 23rd ACM Conference on
Computer and Communications Security (CCS 2016),
pages 1032–1043. ACM, 2016.
[11] Zhaowei Cai and Nuno Vasconcelos.
Cascade r-
cnn: Delving into high quality object detection.
In
Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pages 6154–6162,
2018.
[12] Hongxu Chen, Yinxing Xue, Yuekang Li, Bihuan Chen,
Xiaofei Xie, Xiuheng Wu, and Yang Liu. Hawk-
eye: towards a desired directed grey-box fuzzer.
In
Proceedings of the 2018 ACM SIGSAC Conference on
Computer and Communications Security, pages 2095–
2108. ACM, 2018.
[13] Kai Chen, DengGuo Feng, PuRui Su, and YingJun
Zhang. Black-box testing based on colorful taint analy-
sis. Scientia Sinica Informationis, 55(1):171–183.
[14] Kai Chen, Yingjun Zhang, and Peng Liu. Dynamically
discovering likely memory layout to perform accurate
fuzzing. IEEE Transactions on Reliability, 65(3):1180–
1194, 2016.
[15] Peng Chen and Hao Chen. Angora: Efﬁcient fuzzing
In 2018 IEEE Symposium on
by principled search.
Security and Privacy (SP), pages 711–725. IEEE, 2018.
[16] Shuitao Gan, Chao Zhang, Xiaojun Qin, Xuwen Tu,
Kang Li, Zhongyu Pei, and Zuoning Chen. Collaﬂ:
Path sensitive fuzzing. In 2018 IEEE Symposium on
Security and Privacy (SP), pages 679–696. IEEE, 2018.
[17] Patrice Godefroid, Hila Peleg, and Rishabh Singh.
Learn&fuzz: Machine learning for input fuzzing. In
Proceedings of the 32nd IEEE/ACM International
Conference on Automated Software Engineering, pages
50–59. IEEE Press, 2017.
[18] Ian Goodfellow, Yoshua Bengio, Aaron Courville, and
Yoshua Bengio. Deep learning, volume 1. MIT press
Cambridge, 2016.
[19] Kai Kang, Hongsheng Li, Junjie Yan, Xingyu Zeng, Bin
Yang, Tong Xiao, Cong Zhang, Zhe Wang, Ruohui Wang,
Xiaogang Wang, et al. T-cnn: Tubelets with convolu-
tional neural networks for object detection from videos.
IEEE Transactions on Circuits and Systems for Video
Technology, 28(10):2896–2907, 2018.
[20] James C King. Symbolic execution and program testing.
Communications of the ACM, 19(7):385–394, 1976.
[21] D Kinga and J Ba Adam. A method for stochastic
optimization. In International Conference on Learning
Representations (ICLR), volume 5, 2015.
[22] lcamtuf.
America
Fuzz Loop
strategies.
https://lcamtuf.blogspot.com/2014/08/
binary-fuzzing-strategies-what-works.html,
2014.
[23] Erich L Lehmann and George Casella. Theory of point
estimation. Springer Science & Business Media, 2006.
2268    29th USENIX Security Symposium
USENIX Association
[24] Caroline Lemieux and Koushik Sen. Fairfuzz: Tar-
geting rare branches to rapidly increase greybox
fuzz testing coverage.
In Proceedings of the 33rd
IEEE/ACM International Conference on Automated
Software Engineering, 2018.
[25] Yuekang Li, Bihuan Chen, Mahinthan Chandramohan,
Shang-Wei Lin, Yang Liu, and Alwen Tiu. Steelix:
program-state based binary fuzzing.
In Proceedings
of the 2017 11th Joint Meeting on Foundations of
Software Engineering, pages 627–637. ACM, 2017.
[26] Edwin David Lughofer.
Flexﬁs: A robust incre-
mental learning approach for evolving takagi–sugeno
fuzzy models.
IEEE Transactions on fuzzy systems,
16(6):1393–1410, 2008.
[27] Barton P Miller, Louis Fredriksen, and Bryan So.
An empirical study of the reliability of unix utilities.
Communications of the ACM, 33(12):32–44, 1990.
[28] Nicole Nichols, Mark Raugas, Robert Jasper, and Nathan
Hilliard. Faster fuzzing: Reinitialization with deep neu-
ral models. arXiv preprint arXiv:1711.02807, 2017.
[29] Mohit Rajpal, William Blum, and Rishabh Singh. Not
all bytes are equal: Neural byte sieve for fuzzing. arXiv
preprint arXiv:1711.04596, 2017.
[30] Sanjay Rawat, Vivek Jain, Ashish Kumar, Lucian Co-
jocar, Cristiano Giuffrida, and Herbert Bos. Vuzzer:
Application-aware evolutionary fuzzing. In Proceedings
of the 24th Annual Network and Distributed System
Security Symposium (NDSS 2017). ISOC, 2017.
[31] Dongdong She, Kexin Pei, Dave Epstein, Junfeng Yang,
Baishakhi Ray, and Suman Jana. Neuzz: Efﬁcient
fuzzing with neural program learning. In 2019 IEEE
Symposium on Security and Privacy (SP). IEEE, 2019.
[32] Michael Sutton, Adam Greene, and Pedram Amini.
Fuzzing: Brute Force Vulnerability Discovery. Pearson
Education, 2007.
[33] Junjie Wang, Bihuan Chen, Lei Wei, and Yang Liu.
Skyﬁre: Data-driven seed generation for fuzzing.
In
Proceedings of the 38th IEEE Symposium on Security
& Privacy (S&P 2017). IEEE, 2017.
[34] Xiang Wu, Ran He, Zhenan Sun, and Tieniu Tan. A
light cnn for deep face representation with noisy la-
bels. IEEE Transactions on Information Forensics and
Security, 13(11):2884–2896, 2018.
[35] Wei You, Peiyuan Zong, Kai Chen, XiaoFeng Wang,
Xiaojing Liao, Pan Bian, and Bin Liang.
Sem-
fuzz: Semantics-based automatic generation of
proof-of-concept exploits.
In Proceedings of the
2017 ACM SIGSAC Conference on Computer and
Communications Security, pages 2139–2154. ACM,
2017.
[36] Zhedong Zheng, Liang Zheng, and Yi Yang. A discrim-
inatively learned cnn embedding for person reidentiﬁ-
cation. ACM Transactions on Multimedia Computing,
Communications, and Applications (TOMM), 14(1):13,
2018.
Appendix
1
2
3
4
5
6
7
8
9
0x665abb in WriteOnePNGImage coders/png.c:7061
0x677891 in WriteMNGImage coders/png.c:9881
0x479f3d in WriteImage magick/constitute.c:2230
0x47a891 in WriteImages magick/constitute.c:2387
0x42bb9d in ConvertImageCommand magick/command.c:6087
0x43672e in MagickCommand magick/command.c:8872
0x45eeaf in GMCommandSingle magick/command.c:17393
0x45f0fb in GMCommand magick/command.c:17446
0x40c895 in main utilities/gm.c:61
Listing 2: The sequence of calls to trigger CVE-2017-17501.
1
2
3
4
5
6
7
8
9
0x548b71 in WriteOnePNGImage coders/png.c:7263
0x551d97 in WriteMNGImage coders/png.c:9881
0x450f60 in WriteImage magick/constitute.c:2230
0x4515da in WriteImages magick/constitute.c:2387
0x4215bc in ConvertImageCommand magick/command.c:6087
0x427e48 in MagickCommand magick/command.c:8872
0x44113e in GMCommandSingle magick/command.c:17393
0x441267 in GMCommand magick/command.c:17446
0x40be26 in main utilities/gm.c:61
Listing 3: The sequence of calls to trigger the zero-day
vulnerability.
USENIX Association
29th USENIX Security Symposium    2269