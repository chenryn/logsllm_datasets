title:WhoWas: A Platform for Measuring Web Deployments on IaaS Clouds
author:Liang Wang and
Antonio Nappa and
Juan Caballero and
Thomas Ristenpart and
Aditya Akella
A Platform for Measuring Web Deployments on
WhoWas:
IaaS Clouds
Liang Wang†, Antonio Nappa∗‡, Juan Caballero∗, Thomas Ristenpart†, and Aditya Akella†
† University of Wisconsin – Madison, {liangw,rist,akella}@cs.wisc.edu
∗ IMDEA Software Institute, {antonio.nappa,juan.caballero}@imdea.org
‡ Universidad Politécnica de Madrid
ABSTRACT
Public infrastructure-as-a-service (IaaS) clouds such as Amazon
EC2 and Microsoft Azure host an increasing number of web ser-
vices. The dynamic, pay-as-you-go nature of modern IaaS systems
enable web services to scale up or down with demand, and only pay
for the resources they need. We are unaware, however, of any stud-
ies reporting on measurements of the patterns of usage over time in
IaaS clouds as seen in practice. We ﬁll this gap, offering a measure-
ment platform that we call WhoWas. Using active, but lightweight,
probing, it enables associating web content to public IP addresses
on a day-by-day basis. We exercise WhoWas to provide the ﬁrst
measurement study of churn rates in EC2 and Azure, the efﬁcacy
of IP blacklists for malicious activity in clouds, the rate of adoption
of new web software by public cloud customers, and more.
Categories and Subject Descriptors
C.2 [Computer-Communication Network]: Miscellaneous; C.4
[Performance of Systems]: Measurement Techniques
General Terms
Measurement
Keywords
Cloud Computing; EC2; Azure; Web Service; Active Measurement
1.
INTRODUCTION
Public infrastructure-as-a-service (IaaS) clouds enable cus-
tomers to launch virtual machine (VM) instances, with each in-
stance assigned a publicly routable IP address and given access to
other resources such as storage, memory, and CPU time. The cus-
tomer can start and stop instances, and pays ﬁxed rates per unit time
(typically per hour). An important use case for such clouds is rapid,
scalable deployment of web services: a study last year used active
DNS interrogation to show that 4% of the Alexa most popular one
million websites [1] were using IaaS clouds in some capacity [2].
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or 
distributed for profit or commercial advantage and that copies bear this notice 
and the full citation on the first page. Copyrights for components of this work 
owned  by  others  than  ACM  must  be  honored.  Abstracting  with  credit  is
permitted. To copy otherwise, or republish, to post on servers or to redistribute 
to  lists,  requires  prior  specific  permission  and/or  a  fee.  Request  permissions 
from permissions@acm.org. 
IMC’14, November 5–7, 2014, Vancouver, BC, Canada. 
Copyright © 2014 ACM  978-1-4503-3213-2/14/11…$15.00. 
http://dx.doi.org/10.1145/2663716.2663742.
Unfortunately, little is known about the pattern of usage of IaaS
clouds and whether peculiarities arise due to the new ways in which
web systems are built. For example, an oft-advertised beneﬁt of
using IaaS clouds is elasticity, or the ability to scale up or down
deployments as needed in response to load. We are unaware of any
measurements that reveal the extent to which customers are taking
advantage of elasticity. Such measurements can inform the design
of future cloud provisioning and scaling algorithms. Relatedly, we
do not know the level of churn of ownership of public cloud IPs,
and whether it may cause problems for tools that assume IP owner-
ship is relatively static (e.g., IP blacklists of malicious websites).
We build and exercise a platform for measuring web deploy-
ments on IaaS clouds over time. Our platform, called WhoWas,
can be used to perform measurements over time of cloud address
ranges. Unlike prior work that uses DNS interrogation, we pro-
vide direct measurements of what is running on cloud-associated
IP addresses via lightweight network probing and HTTP requests.
Analysts can then use the gathered data to perform lookups on par-
ticular IP addresses to receive a history of status and content for that
IP address over time. We include various analysis tools, including
a novel webpage clustering heuristic to associate webpages hosted
on distinct IP addresses together.
(2)
We use WhoWas to measure web deployments on Amazon EC2
for a three month period and Microsoft Azure for a two month
period, with a resulting dataset of size approximately 900 GB.
To understand changes over time, we repeatedly probe provider-
advertised IP ranges at an average rate of once per day. This enables
a number of ﬁrst-of-their-kind measurement results, including:
(1) Over the time periods reported, we see sizable growth in the
number of servers running on EC2 (4.9% increase) and Azure
(7.7% increase).
The majority of web services appear to use a small number
of servers, with more than three-quarters of all identiﬁed web
services on each of EC2 and Azure using just a single IP ad-
dress on average. There exist, however, very large services,
in the most extreme case we identify a service associated with
more than 30,000 EC2 IP addresses any given day.
The change in status of an IP address (e.g., no longer host-
ing web content or appearing to change ownership) from one
measurement to the next is low on both clouds: around 3%
of all IP addresses scanned. Large deployments of webpages
across many IPs are highly available as well as stable in terms
of number of IPs used over time, but have signiﬁcant turnover
in terms of which IP addresses are used over the course of our
measurements.
(3)
(4) We discover small amounts of malicious activity (mostly
phishing and malware hosting) by comparing data from
101WhoWas with blacklists. We summarize three IP usage be-
haviors of the discovered malicious webpages, and observe
that the malicious webpages can stay up for a long time after
being blacklisted.
(5) We ﬁnd that a majority of web servers use dated versions
of server and backend software, some of which have known
vulnerabilities.
To facilitate future research, we have made the source code for
WhoWas publicly available [3] and will make data available to re-
searchers upon request.
The rest of this paper is structured as follows. We present back-
ground on IaaS clouds in §2, and related work in §3. We outline
the WhoWas platform in §4, and its key analysis engines in §5. We
describe how we collect data using WhoWas in §6, and the ethical
and privacy considerations we take into account are discussed in
§7. In §8, we show the broad utility of WhoWas via three usage
cases: an analysis of the dynamics of cloud deployments, a study
of malicious activity, and a characterization of in-use web software.
We conclude in §9.
2. BACKGROUND
Infrastructure-as-a-Service (IaaS) systems allow users to rent
virtual machines (VMs or instances) with ﬂexible computing re-
sources and operating systems. IaaS providers like Amazon EC2
and Azure typically provide a few default VM conﬁgurations with
set resources (e.g., number of CPUs, storage, and memory), and
many conﬁguration options to adapt instances to the user’s needs.
The most commonly offered instances are on-demand, which can
be created by users as required, stopped when no longer needed,
and are charged for the hours used. Azure only offers on-demand
instances, while EC2 in addition offers reserved instances, which
are rented for one or three years at lower cost.
Each instance has two associated IP addresses, a private IP that
only works inside the cloud and a publicly routable IP. Both IPs are
by default dynamic; they are released when an instance is stopped
and can be reassigned to a different instance, possibly from a dif-
ferent customer. This creates IP churn, where the same public IP
address may frequently change ownership.
In addition, EC2 and Azure provide up to 5 static public IP ad-
dresses to each account or service deployment1. These static IPs
are not speciﬁc to an instance, but assigned to the user until ex-
plicitly released, and the user chooses the mapping between IP and
instance. Both providers also offer load-balancing services to dis-
tribute requests to an IP across multiple instances.
In EC2, each instance is also assigned an externally resolvable
DNS name, whose structure follows a provider-speciﬁc pattern: the
preﬁx “ec2-” followed by a string that replaces the dots in the public
IP with hyphens, and a region-speciﬁc sufﬁx.
EC2 virtual networking. Amazon Virtual Private Cloud (VPC)
allows users to create a fully-controllable and easy-to-customize
virtual networking environment for their instances. Each VPC is a
logically separate virtual network. We use the terms EC2-Classic
and EC2-VPC to refer to classic networking and VPC networking,
respectively. Compared to EC2-Classic, EC2-VPC provides extra
features. For example, an EC2-VPC instance (also referred to as a
VPC instance) can run on single-tenant hardware, while an instance
launched with EC2-Classic (a classic instance) may run on shared
hardware; a user can assign one or multiple speciﬁc private IP ad-
dresses to an EC2-VPC instance; classic instances can only have
one public IP, while VPC instances can bind to multiple network
1Called Elastic IPs in EC2 and Reserved IPs in Azure.
interfaces and IP addresses (at most 240 IPs, the exact maximum
depending on instance type) [4]. Because of the security and man-
agement beneﬁts compared to EC2-Classic, Amazon has encour-
aged users to adopt VPC and announced that accounts created after
Dec. 12, 2013 can only launch instances with VPC enabled.
3. RELATED WORK
Prior measurement studies of web usage in the cloud primarily
used active DNS probing and packet capture [2]. Such an approach
provides only a limited view of website availability and deployment
changes over time. Packet captures (along with similar techniques
such as passive DNS [5]) are also subject to sampling bias.
Closely related to our work is the Wayback Machine, which
archives old versions of websites [6]. While we investigated us-
ing its data for our study, this would only provide information on
sites submitted and, in particular, provide relatively poor coverage
of cloud usage.
Active probing is a popular technique that has been used for a
variety of applications. Two decades ago, Comer and Lin proposed
active probing to identify differences between TCP implementa-
tions [7].
Internet-wide active probing has been used for iden-
tifying vulnerable SSH servers [8], compiling a Web census [9],
ﬁnding DNS servers providing incorrect resolutions [10], detecting
weak cryptography keys in network devices [11], for identifying
malicious servers [12, 13], and more. In our work we do not scan
the full Internet but only IP ranges from cloud hosting providers.
Localized scans have also been used for detecting network-based
malware [14] in a local network. In contrast we scan remote net-
works.
Other works study how to scan fast. Staniford et al. described
techniques that malware can use to quickly spread through scan-
ning [15]; Netmap [16] proposed a software framework for fast
packet I/O, enabling a single core to saturate a 10Gbps link; and
Durumeric et al. released Zmap [17], a horizontal scanner that can
probe the Internet in 45 minutes from a single host. WhoWas does
not aim to scan fast or wide. Rather, it periodically scans the same
IP ranges to analyze temporal evolution.
The ethical issues of active probing and sharing measurement
data are treated by several prior works. Leonard et al. [18] de-
scribe how to perform maximally polite Internet-wide horizontal
scans. We use their recommendations as guidelines for our prob-
ing. Allman and Paxson [19] discuss issues when sharing network
measurement data. Currently, we do not make our data publicly
available on the Internet, but will release it to researchers upon re-
quest, after privacy issues have been evaluated.
Prior works have studied malicious activity in cloud services.
Balduzzi et al. [20] investigate security issues in the sharing of vir-
tual images among EC2 users. Canali et al [21] install web applica-
tions on shared hosting providers and issue abuse reports on them.
In contrast, we measure malicious activity by cloud users renting
virtual machines. Nappa et al. [22] show that attackers are abusing
cloud instances to host drive-by exploit servers. Our work further
quantiﬁes this trend by including multiple types of malicious activ-
ity, and analyzing the effect of cloud IP churn on blacklists.
4. THE WHOWAS PLATFORM
To track website deployments on IaaS clouds over time, we de-
sign and build a system that can perform lightweight probing of
clouds, process the results, and enable a programmatic interface for
conducting analyses on the gathered data. The basic functionality
we seek is to be able to associate a (cloud) IP address with its status
and content at some point in time, where status means whether it
102is hosting a VM instance responding to network packets, running a
web server, or otherwise.
To do so, WhoWas performs lightweight, active measurements
over some user-speciﬁed time period and records the results for
later analysis. A key design choice we faced involved how to bal-
ance the granularity of observations (how often we probe) of an IP
address’s status against not burdening customers of cloud services
with many network requests. Another challenge is in identifying
and extracting website features that may be useful for determining
if two IP addresses are hosting the same web content. If success-
ful, this would allow us to measure the “footprint” of a particular
service: the number of IP addresses used by the service at a given
period of time.
The main components of the WhoWas system are shown in Fig-
ure 1. They consist of a scanner, webpage fetcher, and feature gen-
erator, which are used in that order to populate a database with
information about measurement results. WhoWas deﬁnes a Python
library interface to allow programmatic access to the resulting data
sets. This makes it easy to write analyses, and also to build ex-
tensions on top of the basic platform (see §5). All source code is
publicly available [3].
We discuss each of the main components of WhoWas in turn.
Scanner. WhoWas is seeded with a list of IP address ranges to
target. At the moment these must be manually gathered. Both EC2
and Azure make public the IP addresses used by their services [23,
24]. For clouds that do not, one could enumerate them via other
means (e.g., via appropriate Whois interrogation) to seed a list. The
scanner also takes a blacklist of IP addresses that should not be
scanned. This enables users to avoid certain ranges, which enables
operators to allow tenants to opt out from measurement studies.
The scanner translates these IP lists into a task list. The primary
goal of the scanner is to ascertain what IP addresses are running
typical services.
In particular we focus on identifying instances
running HTTP and/or HTTPS services. For each IP address, the
scanner sends a TCP SYN (from now on, a probe) ﬁrst to port 80
(HTTP default) and then to 443 (HTTPS default). If both probes
fail to respond, then a probe is sent to port 22 (SSH). The SSH
probe enables identifying live instances that are not hosting pub-
licly accessible HTTP(S) servers.
The scanner times out a probe after two seconds and does not
retry failed probes. The former increases speed of the scanner while
the latter minimizes interaction with the cloud customers. To eval-
uate the effect of larger timeouts, we performed the following ex-
periment. First, we randomly selected 5% of EC2 IPs from each
/24 preﬁx used by EC2. This resulted in 235,070 IPs. For these
IPs, we compared probes with timeouts of 2 s and 8 s. We observed
an increase of only 0.61% in the number of IPs responding with
the longer timeout. For the same set of IPs we also had the scanner
probe with a 2 s timeout once, then again 200 s later and again three
more times at intervals of 100 s for a total of 5 probes. Compared to
the ﬁrst round of scanning, only 0.27% more IPs responded if one
took into account the additional 4 probes. We concluded that these
failure rates will not unduly affect interpretation of scanner results.
By default, the scanner uses a global scan rate of 250 probes per
second (pps) and only treats each IP once a day. This means that an
IP address receives at most three probes (80/tcp, 443/tcp, 22/tcp) in
a day. These scan rates are signiﬁcantly smaller than those used in
prior work that range from 1,000 pps up to 1.4 million pps [17, 18]