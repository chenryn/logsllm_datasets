price for user participation. The training block, which
comprises the bulk of the initial session, takes approxi-
mately 30-40 minutes to complete depending on player
skill. We wanted to motivate our participants to per-
form to the best of their abilities, and thus set a price
of $5.00 for standalone sessions, assuming a total of
approximately one hour of work involved. Apart from
isolated complaints from users who thought the game
moved too slowly (likely due to them not pressing keys,
or playing incorrectly), most users were happy to partic-
ipate and even solicited additional work. We deﬁned our
HIT (Human Intelligence Task) such that each worker
could participate only once in it and we believe that there
were few—if any—cases where the same user submitted
multiple responses.
We had to design special incentives for participants to
return and complete the second part in the case of two-
session experiments. The approach that worked well for
7
us was to price the initial (much lengthier) part at $2.00
and the follow-up 15-minute session at $6.00. We also
explained clearly that this is a two-HIT sequence, and
that payment for both parts will only be processed once
the second part is done. No-shows at the second ses-
sion would get no payment at all. Additionally we used
Amazon’s command line tools to automatically send re-
minders to participants when the second session was
available and due. As a result, we saw over 90% of the
people who completed the ﬁrst session return and ﬁnish
the second part.
Due to the special requirements of the SISL applica-
tion we had to create what is considered to be an “ex-
ternal HIT”, exposing the task as a public website. In
order to make sure that results submitted in Amazon cor-
respond to valid submissions in our system, we designed
a system that involves a receipt code for every success-
fully completed session. The code is a 6-digit number
between 100000 and 999999—we chose this size to pre-
vent people from easily guessing the code, but not make
it difﬁcult for them to write it down (especially useful
in two-session experiments, where we also have to fetch
the correct follow-up sequence that matches the user’s
ﬁrst visit). After follow-up sessions we provided the user
with a second code that needed to be submitted to the
separate second HIT in order to receive payment.
Naturally we were concerned about the security of our
system, so we took measures to only accept limited types
of input as parameters, leaving the website open mostly
to denial of service attacks which we had no reason to
expect. In comparison, our fear of legitimate users trying
to cheat the system and getting paid without completing
quality work was somewhat more justiﬁed. We saw some
limited instances of behavior in this category:
• There were users who, against the instructions, sub-
mitted an invalid receipt code. We immediately re-
jected any such submissions.
• Some users submitted sequences that were so long
that they did not ﬁt in our generous allowance on the
server. Upon examination we found out that these
were due primarily to excessive wrong key presses
(sometimes 5 or more key presses for the same ob-
ject, which suggests that possibly an automated tool
was used to complete the task).
• In relatively few situations we noticed users who
had unusually long intervals of inactivity. We ex-
cluded the most outrageous submissions but leaned
towards including the rest in the results of the study
in order to avoid biasing our data towards people
who did well.
Experiment
baseline
1 week delay
1 week delay
2 week delay
2 week delay
trigrams
Part
initial
follow-up
initial
follow-up
Submissions
Paid Used
34
32
32
82
82
32
39
32
32
95 (a)
84 (b)
34
All
46
35
45
100
111
37
Table 1: Total number of participants in each experi-
ment. The higher number of submissions on follow-up
session are due to more failed opportunistic attempts by
users to get paid $6.00 for no work because HIT assign-
ments were remaining available longer, waiting for eli-
gible users to show up. Notes: (a) we paid more people
than necessary due to the 16-day auto-approval conﬁg-
uration of the HIT; (b) we paid, but did not evaluate a
submission which came in after the cut-off time; (c) the
variation in number of participants across experiments
was due to varying response and acceptance rates—our
primary goal was to collect enough data to be able to
make statistical inferences, and we deliberately collected
more data for the most difﬁcult experiment (the 2-week
delay).
organization of the Mechanical Turk system is at least
partially to thank: workers need to register, and provide
some sort of payment account which makes their identity
relatively easy to track; moreover, rejected work nega-
tively affects a worker’s score and as a result most users
genuinely try to do the best they can, get entertained
if possible, and earn some extra money in the process.
Overall, we consider our use of Mechanical Turk to have
been a big success: it allowed us to conduct each exper-
iment practically overnight, drawing on the huge avail-
able pool of participants.
5 Security Analysis
In this section we analyze the security of the basic au-
thentication protocol from Section 3 and propose a num-
ber of extensions that improve security. We also experi-
ment with a particular attack that attempts to extract the
secret sequence from the user one fragment at a time.
Our Mechanical Turk experiment shows that this attack
works poorly on humans.
5.1
Implicit Learning as a Cryptographic
Primitive
The scope of these abuses never amounted to more
than 5% of the submissions, and we believe that the
We begin with an abstract model of the new function-
ality enabled by implicit learning. Traditional modeling
8
of participants in a cryptographic protocol are as enti-
ties who hold secrets unknown to the adversary. These
assumptions fall apart in the face of coercion since all
secrets can be extracted from the participant.
Implicit learning provides the following new abstract
functionality: the training phase embeds a predicate
p : Σ → {0,1}
in the user’s brain for some large set Σ. Anyone can ask
the user to evaluate his or her predicate p at a point k ∈
Σ. The predicate evaluates to 1 when k has been learned
by the user and evaluates to 0 otherwise. The number
of inputs at which p evaluates to 1 is relatively small.
Most often p will only evaluate to 1 at a single point
meaning that the user has been trained on only one secret
sequence.
The key feature of implicit learning is that even under
duress it is impossible to extract a point k ∈ Σ from the
user for which p(k) = 1. This abstract property captures
the fact that the secret sequence k is implicitly learned by
the user and not consciously accessible. In this paper, we
use the implicit learning primitive to construct an authen-
tication system, but one can imagine it being used more
broadly in security systems.
The authentication procedure described in Section 3
provides an implementation of the predicate p(·) for
some sequence k0 in Σ. If the procedure declares suc-
cess we say that p(k0) = 1 and otherwise p(k0) = 0. The
predicate p is embedded in the user’s brain during the
training session.
The basic coercion threat model. The SISL authenti-
cation system from Section 3 is designed to resist an ad-
versary who tries to fool the authentication test. We as-
sume the test requires physical presence and begins with
a liveness check to ensure that a real person is taking the
test without the aid of any instruments. To fool the au-
thentication test the adversary is allowed the following
sequence of steps:
• Extraction phase:
intercept one or more trained
users and get them to reveal as much as they can,
possibly using coercion.
• Test phase: the adversary, on his own, submits to
the authentication test and his or her goal is to pass
the test. In real life this could mean that the adver-
sary shows up at the entrance to a secure facility and
attempts to pass the authentication test there. If he
fails he could be detained for questioning.
This basic threat model gives the attacker a single
chance at the authentication test. We consider a model
where the attacker may iterate the extraction and test
phases, alternating between extraction and testing, later
on in this section.
We also note that the basic threat model assumes that
during the training phase, when users are taught the cre-
dential, users are following the instructions and are not
deliberately trying to mislead the training process. In ef-
fect, the adversary is only allowed to coerce a user after
the training process completes.
It is straight-forward to show that the system of Sec-
tion 3 is secure under this basic threat model, assum-
ing the training procedure embeds an implicitly learned
predicate p in the user’s brain.
Indeed, if the attacker
intercepts u trained users and subjects each one to q
queries, his chances of ﬁnding a valid sequence is at
most qu/|Σ|. Since each test takes about ﬁve minutes,
we can assume an upper bound of q = 105 trials per
captured user (this amounts to about one year of non-
stop testing per user which will either interfere with the
user’s learned password rendering the user useless to
the attacker, or alert security administrators due to the
user’s absence prompting a revocation of the creden-
tials). Hence, even after capturing u = 100 users, the
attacker’s success probability is only
100× 105/|Σ| ≈ 2−16 .
Further complicating the attacker’s life is the fact that
subjecting a person to many random SISL games may
obliterate the learned sequence or cause the person to
learn an incorrect sequence thereby making extraction
impossible.
We note that physical presence is necessary in authen-
tication systems designed to resist coercion attacks. If
the system supported remote authentication then an at-
tacker could coerce a trained user to authenticate to a re-
mote server and then hijack the session.
Security enhancements. The security model above
gives the attacker one chance to authenticate and the at-
tacker must succeed with non-negligible probability. If
the attacker is allowed multiple authentication attempts
— iterating the extraction and test phases, alternating be-
tween the two — then the protocol may become insecure.
The reason is that during an authentication attempt the at-
tacker sees the three sequences k0,k1,k2 and could mem-
orize one of them (30 symbols). He would then train
ofﬂine on that sequence so that at the next authentica-
tion attempt he would have a 1/3 chance in succeeding.
If the attacker could memorize all three sequences (90
symbols), he could ofﬂine subject a trained user to all
three sequences and reliably determine which is the cor-
rect one and then train himself on that sequence. He is
then guaranteed success at the next authentication trial.
We note that this attack is non-trivial to pull off since
9
it can be difﬁcult for a human attacker to memorize an
entire sequence at the speed the game is played.
Another potential attack, already discussed in Sec-
tion 3, is an attacker who happens to be an expert player,
but deliberately degrades his performance on two of the
sequences presented. With probability 1/3 he will show
a performance gap on the correct sequence and pass the
authentication test. We described a number of defenses
in Section 3. Here we describe a more robust defense.
Both attacks above can be defeated with combina-
torics. Instead of training the user on a single sequence,
we train the user on a small number of sequences, say
four. Experiments [18] suggest that the human brain can
learn multiple sequences and these learned sequences do
not interfere with one another. Equivalently we could
train the user on a longer sequence and use its fragments
during authentication. While this will increase training
time, we show that it can enhance security.
During authentication, instead of using one correct se-
quence and two foils, we use the four correct sequences
randomly interspersed within 8 foils. Authentication
succeeds if the attacker shows a measurable performance
gap on the correct 4 out of 12 presented sequences. An
attacker who slows down on random sequences will now
(cid:1) ≈ 1/500 chance in passing the test.
The number of trained sequences (4) and the number of
foils (8) can be adjusted to achieve an acceptable tradeoff
between security and usability.
have at most a 1/(cid:0)12
4
Similarly, a small number of authentication attempts
will not help a direct attacker pass the test. However,
memorizing the authentication test (360 symbols) and
later presenting it to a coerced user could give the adver-
sary an advantage. To further defend against this memo-
rization attack we add one more step to the authentication
procedure: once the authentication server observes that
the user failed to demonstrate a measurable gap on some
of the trained sequences, all remaining trained sequences
are replaced with random foils. This ensures that an
attacker who tries to authenticate with no prior knowl-
edge will not see all the trained sequences and therefore
cannot extract all trained sequences from a coerced user.
Consequently, a one-shot attack on a coerced user is not
possible. Nevertheless, by iterating this process — tak-
ing the authentication test, memorizing the observed se-
quences, and then testing them out on a coerced trained
user — the attacker may eventually learn all trained se-
quences and succeed in fooling the authentication test.
During this process, however, the attacker must engage
in the authentication test where he demonstrates knowl-
edge of a strict subset of the trained sequences, but can-
not demonstrate knowledge of all sequences. This is a
clear signal to the system that it is under attack at which
point the person engaging in the authentication test could
10
be detained for questioning and the legitimate user is
blocked from authenticating with the system until he or
she is retrained on a new set of sequences.
Eavesdropping security. Traditional password authen-
tication is vulnerable to eavesdropping (either via client-
side malware or shoulder surﬁng) and so is the authenti-
cation system presented here. An eavesdropper who ob-
tains a number of valid authentication transcripts with a
trained user will be able to reconstruct the learned se-
quence(s). It is a fascinating direction for future research
to devise a coercion-resistant system where an implicitly
learned secret is used in a challenge-response protocol
with the server. We come back to this question at the end
of the paper.
5.2 An Experiment: Extracting Sequence