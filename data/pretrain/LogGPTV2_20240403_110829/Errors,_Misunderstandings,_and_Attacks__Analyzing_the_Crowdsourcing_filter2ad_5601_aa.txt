# Title: Errors, Misunderstandings, and Attacks: Analyzing the Crowdsourcing Process of Ad-blocking Systems

## Authors:
- Mshabab Alrizah, The Pennsylvania State University, mshabab@psu.edu
- Sencun Zhu, The Pennsylvania State University, sencun@psu.edu
- Xinyu Xing, The Pennsylvania State University, xinyu@psu.edu
- Gang Wang, University of Illinois at Urbana-Champaign, gangw@illinois.edu

## Abstract
Ad-blocking systems, such as Adblock Plus, rely on crowdsourcing to build and maintain filter lists, which are essential for determining which ads to block on web pages. In this study, we aim to deepen our understanding of the ad-blocking community and the challenges associated with the crowdsourcing process. We collected and analyzed a longitudinal dataset covering nine years of dynamic changes in the popular filter list EasyList, along with error reports submitted by users during the same period.

Our analysis revealed several significant findings regarding the characteristics and causes of false positive (FP) and false negative (FN) errors. For example, FP errors (i.e., incorrectly blocking legitimate content) often took a long time to be discovered, with 50% of them persisting for over a month despite community efforts. Both EasyList editors and website owners were found to be responsible for these errors. Additionally, many FN errors (i.e., failing to block real advertisements) were either incorrectly reported or ignored by the editors.

We also examined evasion attacks from ad publishers against ad-blockers, identifying 15 types of attack methods, including 8 that have not been previously studied. Our in-depth analysis provides insights into the effectiveness of ad-blockers and the strategies used by ad publishers to circumvent them. These findings are expected to inform future work on improving ad-blocking systems and optimizing crowdsourcing mechanisms.

## ACM Reference Format
Mshabab Alrizah, Sencun Zhu, Xinyu Xing, and Gang Wang. 2019. Errors, Misunderstandings, and Attacks: Analyzing the Crowdsourcing Process of Ad-blocking Systems. In Internet Measurement Conference (IMC ’19), October 21–23, 2019, Amsterdam, Netherlands. ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3355369.3355588

## Permission
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

## IMC '19, October 2019, Amsterdam, Netherlands
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6948-0/19/10...$15.00
https://doi.org/10.1145/3355369.3355588

## Table 1: Number of Active Devices Using Firefox and Chrome Extensions with EasyList as the Default Filter List (First Week of January 2019)
| Extension | Active Devices |
|-----------|----------------|
| Adblock Plus | 11,054,048 |
| AdBlock | 1,329,314 |
| uBlock Origin | 4,861,128 |
| AdGuard | 5,641,143 |
| AdBlocker Ultimate | 337,776 |
| µBlock | 413,605 |
| Total | 173,000,000+ |

Note: AdGuard is based on EasyList [2].

## 1. Introduction
Ad-blocking systems are widely used by Internet users to remove advertisements from web pages and protect user privacy from third-party tracking. Today, over 600 million devices globally use ad-blocking systems [19].

Crowdsourcing is a critical mechanism for introducing new filter rules and mitigating filter errors in ad-blocking systems. For instance, many popular ad blockers, such as Adblock Plus, depend on a crowdsourcing project called EasyList [21]. EasyList maintains a list of filter rules that determine which ads to block. Among available filter lists, EasyList has the largest user base [11, 47]. Table 1 shows some popular Firefox and Chrome ad-blocking extensions that use EasyList. As of the first week of January 2019, more than 173 million active devices used EasyList for ad blocking [17, 49, 86]. Furthermore, Google uses ad-related URL patterns based on EasyList to block ads on sites that fail the Better Ads Standards in Chrome (both desktop and Android versions) [14].

To facilitate crowdsourcing, EasyList has established a large community where users can provide feedback and report errors to EasyList editors, who then update the ad-blocking filters manually. These editors are a small group of EasyList authors and ad-blocking experts. Feedback and reports are collected through two channels: public forums and plug-in applications [21].

The evolution of ad-blocking systems influences the practices of both website owners and web users in multiple ways. Consequently, substantial research has addressed ad-blocking systems from various perspectives, including the relationships among Internet users, ad publishers, and ad blockers [48, 53, 71, 89]. Other research has focused on the economic implications of ad-blocking systems [19, 78], potential complementary solutions [26, 83], and specific cases of ad blocking (e.g., tracker blocking, anti-adblocking) [25, 30, 46, 82]. However, there is a lack of deep understanding about how crowdsourcing improves filter lists over time and the potential pitfalls and vulnerabilities in this process.

In this paper, we focus on EasyList and present a measurement study on the dynamic changes in the filter list and the crowdsourced error reports over a nine-year period. We explored several key questions:
1. How prevalent are FP and FN errors?
2. What are the primary sources of these errors?
3. How effective is crowdsourcing in detecting and mitigating FP and FN errors?
4. How robust is the filter list against adversaries?

To answer these questions, we collected two large datasets:
1. The nine-year history of all versions of the EasyList filter list.
2. Users' FP and FN error reports for the same period.

The resulting dataset contains 55,607 versions of the filter list, with 534,020 filters added and 448,479 filters removed by 27 editors to correct FP and FN errors. Additionally, we collected 23,240 error reports and analyzed 0.5 million records of traffic history from 6,000 ad servers.

We developed tools and simulation methods to connect the datasets and create real instances of FP and FN errors. Our in-depth analysis revealed the following significant findings:
1. A non-trivial portion of the community effort (about 30% of the reports) was spent on addressing FP errors.
2. Despite community efforts, there was still a long delay in discovering FP errors, with more than half persisting for over a month before being reported. Once reported, it took an average of 2.09 days to push updates.
3. About 65% of FP errors were caused by "bad signatures" added by EasyList editors, while website owners/designers contributed to 35% of the errors by using already-blacklisted elements in their web content.
4. FN errors were more likely to be rejected or ignored by EasyList editors. Some reported FNs were not real errors; for example, some users thought their ad blocker was failing to block certain ads when, in fact, their computers were infected by adware.

Our study also provided insights into the practical evasion efforts by ad publishers and website developers to circumvent ad-blocking systems and the countermeasures from ad blockers. We identified 15 types of attack methods, including 8 new ones not previously studied. Only 60% of ad servers were affected when their domains were blocked by EasyList. Ad networks aggressively change their domains and ad elements and use new strategies to achieve evasion. Our analysis shows that countermeasures from EasyList are often delayed or ineffective.

### Key Contributions
1. We collected two large datasets from the ad-blocking community to analyze the crowdsourcing process for ad-blocking error detection and mitigation. We plan to share these datasets with the research community.
2. We presented an in-depth analysis of the accuracy of the ad-blocking system and the updating behavior of the filter list over nine years, providing new insights into the causes of FP and FN errors and their impacts on websites.
3. We provided a comprehensive analysis of the vulnerabilities of the ad-blocking system by illustrating 15 different evasion methods and their empirical usage.

## 2. Ad-Blocking Datasets
Popular ad-blocking systems typically have three main components: (a) ad-blocking software, (b) a filter list, and (c) a community of users who provide feedback to refine the filter list. As shown in Figure 1, the ad-blocking software uses the filter lists to block ads on web pages. The community, consisting of Internet users and ad-blocking filter-list editors, plays two leading roles: contributing new filter rules and correcting errors caused by the filters. Internet users contribute to the filter lists by reporting errors, while the editors respond by interpreting and acting on that feedback to control the list. Very few systems use hard-coded or fixed filter lists, which are typically less popular and less effective for ad blockers. Therefore, we do not consider them in this paper.

### 2.1 D1: EasyList Dataset
From November 30, 2009, to December 7, 2018, there were 117,683 versions of EasyList. The ad-blocking system updates EasyList when editors create a new version and push it to the remote repository. Updates are primarily for correcting FP and FN errors or modifying the order/structure of existing filter lists. We focused on error correction related updates.

We crawled the Mercurial repository that tracks changes to EasyList [45], which has the histories of updates back to November 2009. First, we tabulated the shortlog (commits) over the nine years to build an index of changes. Second, we used the index to seed an extractor of the EasyList changes, tracking differences between old and new versions. This allowed us to rebuild all EasyList versions. Third, we tracked the changes for each filter, building an image of its lifetime.

### Basic Data Cleaning
The biggest challenge for our analysis was that we could not merely compare the differences between two consecutive versions to detect added or removed filters over time. Below, we discuss the reasons and how we resolved the issues:

1. **Data Synchronization Problem**: EasyList editors may not always work in a synchronized way. After certain FP/FN errors are reported, different editors may try to address the same error at different times, leading to duplicated filters. We considered these changes as noise and removed them.
2. **Temporally Duplicated Filters**: Duplicated filters may temporarily exist in certain versions due to editor operations. For example, EasyList once contained two filters: (1) `missoulian.com###PG_fb` and (2) `missoulian.com,theolympian.com###PG_fb`. The editor was trying to modify the first filter by adding the website domain `theolympian.com` in the optional field to specify the filter scope. Instead of directly modifying the existing filter, the editor added the second filter in a new version and then removed the first filter later, leading to temporary duplication. For our analysis, we merged these versions. Specifically, we created a record for each filter indicating the time of creation, removal, and the filter's lifetime. We used commit messages to identify the reason for removing filters. If the message indicated removal due to duplication, we skipped the version of the temporarily duplicated filters.
3. **Structure Maintenance**: Editors may reorder the filter list and rebuild some filters’ syntax to create new versions (e.g., the merge of the EasyList and Fanboy lists in 2011). Since these changes are not related to FP/FN errors, we did not consider these versions in our analysis.

With these complications in mind, we extracted the changes in EasyList by applying a greedy algorithm, performing a look-ahead search to match versions related to error corrections.

### Dataset Statistics
After building and cleaning the dataset, we obtained a total of 55,607 versions as our dataset D1. The number of filters in each version increased almost linearly from 3,250 in November 2009 to more than 73,000 in December 2018. Over the nine-year period, there were 534,020 filters added and 448,479 filters removed to correct FP and FN errors. Some filters were added and removed more than once at different times. In total, there were 27 editors who maintained the list according to the crowdsourced reports.

### 2.2 D2: Crowdsourced Report Dataset
There are two channels for users to report errors to EasyList editors:
1. **Public Forum**: Users can submit a public report on the EasyList forum [24].
2. **Browser Plug-in**: Users can submit reports via a browser plug-in. A key difference is that browser plug-in reports are one-way communication—users submit reports but never receive replies or feedback. Website owners/developers are more likely to submit to the forum to interact with EasyList editors and follow up on error correction. In March 2018, a few browser extension developers started using emails to communicate with reporters. Since such plug-in channels only started recently and their data is not public, our data collection focused on the public forum matching the period covered in D1.

A key benefit of forum reports is that EasyList editors usually reply with the "new EasyList version" created to address the reported issues, which is crucial for answering our research questions.

In the forum, FN reports are entered under “Report unblocked content,” and FP reports are entered under “Report incorrectly removed content.” Errors related to the same website are grouped in one topic titled by the domain name of that website. Each topic might have a discussion thread with back-and-forth replies.

We built a crawler that collected all available posts on the forum. In total, we have 23,240 topics with at least one report; 17,968 topics are about FN errors, and 5,272 topics are about FP errors. We refer to this dataset as D2.