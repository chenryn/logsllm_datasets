title:Errors, Misunderstandings, and Attacks: Analyzing the Crowdsourcing
Process of Ad-blocking Systems
author:Mshabab Alrizah and
Sencun Zhu and
Xinyu Xing and
Gang Wang
Errors, Misunderstandings, and Attacks: Analyzing the
Crowdsourcing Process of Ad-blocking Systems
Mshabab Alrizah
The Pennsylvania State University
PI:EMAIL
Xinyu Xing
The Pennsylvania State University
PI:EMAIL
The Pennsylvania State University
Sencun Zhu
PI:EMAIL
Gang Wang
University of Illinois at Urbana-Champaign
PI:EMAIL
ABSTRACT
Ad-blocking systems such as Adblock Plus rely on crowdsourcing
to build and maintain filter lists, which are the basis for determin-
ing which ads to block on web pages. In this work, we seek to
advance our understanding of the ad-blocking community as well
as the errors and pitfalls of the crowdsourcing process. To do so,
we collected and analyzed a longitudinal dataset that covered the
dynamic changes of popular filter-list EasyList for nine years and
the error reports submitted by the crowd in the same period.
Our study yielded a number of significant findings regarding the
characteristics of FP and FN errors and their causes. For instances,
we found that false positive errors (i.e., incorrectly blocking legiti-
mate content) still took a long time before they could be discovered
(50% of them took more than a month) despite the community ef-
fort. Both EasyList editors and website owners were to blame for
the false positives. In addition, we found that a great number of
false negative errors (i.e., failing to block real advertisements) were
either incorrectly reported or simply ignored by the editors. Fur-
thermore, we analyzed evasion attacks from ad publishers against
ad-blockers. In total, our analysis covers 15 types of attack methods
including 8 methods that have not been studied by the research
community. We show how ad publishers have utilized them to
circumvent ad-blockers and empirically measure the reactions of
ad blockers. Through in-depth analysis, our findings are expected
to help shed light on any future work to evolve ad blocking and
optimize crowdsourcing mechanisms.
ACM Reference Format:
Mshabab Alrizah, Sencun Zhu, Xinyu Xing, and Gang Wang. 2019. Errors,
Misunderstandings, and Attacks: Analyzing the Crowdsourcing Process of
Ad-blocking Systems. In Internet Measurement Conference (IMC ’19), October
21–23, 2019, Amsterdam, Netherlands. ACM, New York, NY, USA, 15 pages.
https://doi.org/10.1145/3355369.3355588
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6948-0/19/10...$15.00
https://doi.org/10.1145/3355369.3355588
230
Chrome
Ad-block Extension Default Filter List Firefox
EasyList
Adblock Plus
EasyList
AdBlock
uBlock Origin
EasyList
Adguard AdBlocker AdGuard
AdBlocker Ultimate AdGuard
EasyList
µBlock
11,054,048 > 100 million
> 40 million
1,329,314
> 10 million
4,861,128
5,641,143
337,776
413,605
731,041
884,482
98,894
Table 1: Number of active devices using Firefox and Chrome ex-
tension that have EasyList as a default filter-list in the first week of
January 2019. Note that AdGuard is based on EasyList [2].
1 INTRODUCTION
Ad-blocking systems are widely used by Internet users to remove
advertisements from web pages and protect user privacy from
third-party tracking. Today, over 600 million devices are using
ad-blocking systems around the globe [19].
Crowdsourcing is a crucial mechanism adopted by ad-blocking
systems to introduce new filter rules and mitigate filter errors. For
example, many popular ad blockers depend on a crowdsourcing
project called EasyList [21]. EasyList maintains a list of filter rules
that determine which ads to block. Among all the available filter
lists, EasyList has the largest user base [11, 47]. Table 1 shows
some popular Firefox and Chrome ad-blocking extensions that
depend on EasyList. As of the first week of January 2019, more
than 173 million active devices used EasyList for ad blocking [17,
49, 86]. Furthermore, Google uses ad-related URL patterns based
on EasyList to block ads on sites that fail the Better Ads Standards
(in Chrome for both desktop and Android version) [14].
To facilitate crowdsourcing, EasyList has established a large
community through which users can provide feedback and report
errors to the EasyList editors, who then update the ad-blocking
filters manually. These editors are a small group of EasyList authors
and ad-blocking experts. The editors collect feedback and reports
from the crowd using two different channels: public forums and
plug-in applications [21].
The evolution of ad-blocking systems has an influence on the
practices of both website owners and web users in multiple ways.
Therefore, a substantial amount of research has addressed ad-blocking
systems from a range of perspectives including those involving the
relationships among Internet users, ad publishers, and ad block-
ers [48, 53, 71, 89]. Other research has focused on the economic
ramifications of the ad-blocking systems [19, 78], potential comple-
mentary solutions [26, 83], and specific cases of ad blocking (e.g.,
tracker blocking, anti-adblocking) [25, 30, 46, 82]. However, there
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Alrizah et al.
remains a lack of deep understanding about how crowdsourcing
functions improve the filter-lists of ad-blocking systems over time,
and the potential pitfalls and vulnerabilities in this process.
In this paper, we focus on EasyList and present a measurement
study on the dynamic changes of the filter-list and the crowdsourc-
ing error reports over a period of nine years. We explored the
answers to a series of key questions. First, how prevalent are the
errors of blocking legitimate content, i.e., false positive (FP) errors,
and how prevalent are the errors of missing real advertisements, i.e.,
false negative (FN) errors? Second, what are the primary sources
of these errors? Third, how effective is crowdsourcing in detecting
and mitigating false positive and false negative errors? Fourth, how
robust is the filter-list against adversaries?
To answer these questions, we collected two large datasets that
covered the update history of EasyList and the behavior of the ad-
blocking community over the nine-year period from November 2009
to December 2018. The resulting dataset contains a total of 55,607
versions of the filter lists. Over the nine years, there were 534,020
filters added and 448,479 filters removed by 27 editors to correct
both FP and FN errors. Additionally, we also crawled the feedback
reports submitted by users in the community. We collected 23,240
reports of FP and FN errors. Moreover, we analyzed 0.5 million
records of traffic history of 6,000 ad servers.
To effectively connect the first two datasets, we proposed and
utilized some tools and simulation methods to create and extract
real instances of FP and FN errors. Then, we performed an in-depth
analysis of the occurrence of both types of errors to understand
their causes and to evaluate the effectiveness of crowdsourcing for
error detection and mitigation. Based on the result, we analyzed
15 different type of attacks which aim to circumvent ad blockers,
including 8 new attacks that have not been systematically studied
by existing literature.
Our study yielded a number of significant findings regarding the
characteristics of FP and FN errors and their causes. First, a non-
trivial portion of the community effort was spent on addressing FP
errors (about 30% of the reports). Second, despite the community
effort, there was still a long delay of FP error discovery. More than
half of the errors persisted for over a month before they were re-
ported. Once reported, it took, on average, 2.09 days to push the
updates. Third, about 65% of the FP errors were caused by the “bad
signatures” added by the EasyList editors. However, the website
owners/designers made it worse by using already-blacklisted el-
ements for their web content design (accounting for 35% of the
errors). Fourth, FN errors were more likely to be rejected or ignored
by EasyList editors. Some of the reported FNs are not real errors.
For example, certain reporting users thought their ad blocker was
failing to block certain ads, but the true situation was that their
computers were infected by adware that was overwriting the ad
blocker and injecting ads.
Our study also provided insights into understanding the prac-
tical evasion efforts by ad publishers and website developers to
circumvent the ad-blocking systems and the countermeasures from
ad-blockers. We find 15 types of attack methods used in our dataset.
Among them, we analyzed 8 new attacks that have not yet been
systematically studied in previous works. Among the many things,
we find that only 60% of ad servers were influenced when their
domains were blocked by the EasyList. Ad networks aggressively
Figure 1: Overview of ad-blocking system.
change their domains and ad elements and use new strategies to
achieve evasion. Our analysis shows that the countermeasures from
EasyList are often delayed or ineffective.
The key contributions of our work are as follows:
(1) We collected two large datasets from the ad-blocking commu-
nity to analyze the crowdsourcing process for ad-blocking
error detection and mitigation. We plan to share our datasets
with the research community.
(2) We presented an in-depth analysis of the accuracy of the
ad-blocking system and the updating behavior of the filter
list over 9 years. This analysis provides new insights into the
causes of false positive and false negative errors and their
impacts on websites.
(3) We presented a comprehensive analysis of the vulnerabilities
of the ad blocking system by illustrating 15 different evasion
methods and their empirical usage.
2 AD-BLOCKING DATASETS
Popular ad-blocking systems commonly have three main compo-
nents: (a) ad-blocking software, (b) a filter list, and (c) a community
of users who provide feedback to refine the filter list. As shown in
Figure 1, the ad-blocking software utilizes the filter lists to block ads
on web pages. The community, which consists of Internet users and
ad-blocking filter-list editors, has two leading roles: contributing
new filter rules and correcting errors caused by the filters. The
Internet users, who use ad-blocking systems, contribute to the filter
lists by reporting errors, while the editors respond by interpreting
and acting on that feedback in order to control the list. Very few
systems use hard-coded or fixed filter lists, which are typically less
popular and less effective for ad blockers. Therefore, we do not
consider them in this paper.
To perform the measurement study, we collected two datasets
from different sources. The datasets include 1) the nine-year history
of all versions of the EasyList filter list, and 2) users’ FP and FN
error reports for the same period. In the ad-blocking system, an
FP error is an instance when the filter incorrectly blocked a non-
advertisement element on a website, and an FN error is an instance
when the filter fails to block a real ad on a website. For our analysis,
we implemented multiple tools to collect and clean the datasets.
2.1 D1: EasyList Dataset
From November 30, 2009, to December 7, 2018, there were 117,683
versions of EasyList. The ad-blocking system updates EasyList when
231
List BFilter 1Filter 2Filter 3a. Softwareb. Filter ListsList AFilter 1Filter 2Filter 3Internet UsersReportsFilter List EditorsWWWc. CommunityAnalyzing the Crowdsourcing Process of Ad-blocking Systems
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
the editors create a new version and push it to the remote repos-
itory. There are three reasons for updating EasyList: correcting
FP errors, correcting FN errors, or modifying the order/structure
of existing filter list. We will focus primarily on error correction
related updates.
We crawled the Mercurial repository that tracks the changes to
EasyList [45], which has the histories of updates back to November
2009. First, we tabulated the shortlog (commits) over the nine years
to build an index of changes. Second, we used the index to seed
an extractor of the EasyList changes. The extractor tracks the dif-
ferences between the old and new EasyList versions. This allowed
us to rebuild all the EasyList versions. Third, we focused on each
filter in the list and tracked the changes by building the image of
its lifetime.
The biggest challenge for our analysis
Basic Data Cleaning.
is that we could not merely compare the differences between two
consecutive versions to detect the added or removed filters over
time. Below, we discuss the reasons and how we resolved the issues.
First, data synchronization problem. EasyList editors may not
always work in a synchronized way. After certain FP/FN errors
are reported, different editors may try to address the same error at
different times, leading to duplicated filters. We considered these
changes as the noise and removed them.
Second, temporally duplicated filters. Duplicated filters may tem-
porally exist in certain versions due to the operation of editors. For
example, EasyList once contained two filters: (1) missoulian.c-
om###PG_fb and (2) missoulian.com,theolympian.co-
m###PG_fb. Actually, the editor was trying to modify the first
filter by adding the website domain “theolympian.com” in the op-
tional field to specify the filter scope. Instead of directly modifying
the existing filter, the editor added the second filter in a new ver-
sion and then removed the first filter later. This led to duplicated
filters temporally existing in the list. For our analysis, we found
these cases and merged the versions. More specifically, we created
a record of each filter that indicates the time of the filter creation,
the time of the filter removal, and the time period between the
filter creation and removal (called filter lifetime). We leveraged
the commit messages of EasyList creation to identify the reason
for removing the filters. If the commit message indicated that the
reason was to remove duplication, then we skip the version of the
temporally duplicated filters.
Third, structure maintenance. Editors may reorder the filter list
and rebuild some filters’ syntax to create new versions (e.g., the
merge of the EasyList list and Fanboy list in 2011). Since these
changes are not related to FP/FN errors, we did not consider these
versions in our analysis.
With these complications in mind, we extracted the changes in
EasyList by applying a greedy algorithm. The idea was to do a look-
ahead-search to match with versions related to error corrections.
After building and cleaning the dataset, we
Dataset Statistics.
obtained a total of 55,607 versions as our dataset D1. The number
of filters in each version increased almost linearly from 3,250 in
November 2009 to more than 73,000 in December 2018. Over the
nine-year period, there were 534,020 filters added and 448,479 filters
removed in order to correct FP and FN errors. Some filters were
added and removed more than once at different times. In total,
there were 27 editors who maintained the list according to the
crowdsourced reports.
2.2 D2: Crowdsourced Report Dataset
There are two channels for users to report errors to the EasyList
editors. First, a user can report an error by submitting a public report
on the EasyList forum [24]. Second, a user can submit the report via
a browser plug-in. A key difference between the browser plug-in
reports and the forum is that browser plug-in report is a one-way
communication— users submit the reports but never get replies or
feedback. Intuitively, for website owners/developers, they are more
likely to submit to the forum to interact with EasyList editors and
follow up on the error correction. In March of 2018, a few browser
extension developers started to use emails to communicate with
the reporters. Considering that such plug-in channels only started
very recently (and its data is not public), our data collection was
focused on the public forum that matched the period covered in D1.
A key benefit of forum reports is that EasyList editors usually reply
with the “new EasyList version” created to address the reported
issues, which is the key to answer our research questions.
In the forum, FN reports are entered under “Report unblocked con-
tent”, and FP reports are entered under “Report incorrectly removed
content”. Usually, errors related to the same website are grouped
in one topic titled by the domain name of that website. Each topic
might have a discussion thread with back-and-forth replies.
We built a crawler that collected all the available posts on the
forum. In total, we have 23,240 topics with at least one report; 17,968
topics are about FN errors, and 5,272 topics are about FP errors. We
refer to this dataset as D2.