(b)
(c)
(e)
(d)
(f)
Figure 6: Seven-node bottleneck experiment similar to that performed by Tang and Goldberg [42]. The number of cells processed (a) and
queued (b) increases at Time=10, when the measurement clients begin downloading. The EWMA scheduler improves responsiveness for
bursty trafﬁc (c), (d), and (e) but, contrary to the author’s claims, decreases performance for bulk downloads (f).
cantly different for each scheduler. However, our results in
Figure 6f indicate otherwise. Bulk download times are not-
icably worse for the EWMA scheduler, with a signiﬁcant
increase at around the 40th percentile. This increase again
happens when the “measurement” bulk client loses its prior-
ity over the “congestion” bulk clients, suggesting a deeper
analysis of the EWMA scheduling algorithm is appropriate.
EWMA in Network-wide Deployment. Tang and Gold-
berg’s experiments suffer from a major limitation of scale:
the experiments were run either on three-node PlanetLab
topologies, or in the live Tor network with only a single re-
lay scheduling with the EWMA algorithm. Although they
provide results for what a single relay might expect when
switching scheduling algorithms, they do not consider the
network-wide effects of a full network deployment.
We explore the performance gains possible with the
EWMA scheduler through a network-wide deployment in
Shadow. We test the EWMA circuit scheduler with a range
of half-life conﬁgurations and compare performance to the
round-robin scheduler used in vanilla Tor. As in Section 5.3,
we use 200 servers, 50 relays and 950 web clients for our
experiments. To analyze the effects of various network
loads on the scheduler, we run separate experiments conﬁg-
ured with each of 25, 50, and 100 bulk clients. The adjusted
load is signiﬁcant since bulk clients account for a large frac-
tion of network trafﬁc. To reduce random variances, we run
each experiment ﬁve times and show the cumulative results
of each conﬁguration by aggregating the results of all ﬁve
experiments. Our results are shown in Figure 7.
Under a load of 25 bulk clients, Figures 7a–7c show
that the EWMA circuit scheduler reduces performance over
vanilla Tor for all clients, independent of the conﬁgured
half-life. Bulk download times seem to be affected the most
(7c), but our experiments indicate there is also a signiﬁcant
reduction in responsiveness for web clients (7a). As load in-
creases to 50 bulk clients, Figures 7d–7f show that there are
half-life conﬁgurations that still reduce performance when
compared to vanilla Tor. The 30 and 90 second EWMA
half-life conﬁgurations appear to improve performance for
web clients (7d, 7e), but performance for bulk clients is ei-
ther reduced or shows less improvement (7f). Performance
is reduced for all clients when using a 3 second half-life.
Finally, Figures 7g–7i show performance under the load of
100 bulk clients. Under heavy load, the EWMA sched-
uler appears to perform the best for web clients (7g, 7h)
while bulk clients see no improvements over vanilla Tor
and the round-robin scheduler (7i). Note that we also tested
the schedulers under a lighter load than shown in Figure 7,
but performance when the network is too lightly loaded is
nearly identical regardless of the selected circuit scheduler.
010203040506070Time(m)405060708090100110120MeanCellsProcessed(x1000)vanillaewma66010203040506070Time(m)020406080100120MeanCellsinCircuitQueuesvanillaewma661.21.41.61.82.02.22.42.62.8WebTimetoFirstByte(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma662.53.03.54.04.55.0WebDownloadTime(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma661.21.41.61.82.02.22.42.62.8BulkTimetoFirstByte(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma6626.026.527.027.528.028.529.0BulkDownloadTime(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma66(a)
(d)
(b)
(e)
(c)
(f)
(g)
(h)
Figure 7: Performance of a full-network deployment of the EWMA circuit scheduler and vanilla Tor using a round-robin scheduler. Load
is generated with 950 web clients and varied using (a)–(c) 25 bulk clients (d)–(f) 50 bulk clients, and (g)–(i) 100 bulk clients. While the
EWMA circuit scheduler works best under heavily loaded networks, there are EWMA half-life conﬁgurations that lead to reduced client
performance.
(i)
For these results, and responsiveness for bulk clients under
the loads decribed above, please see Appendix B.
We conclude from our results that the EWMA sched-
uler should not necessarily be used under all network con-
ditions since it is not clear that performance will always im-
prove. When improvements over the round-robin scheduler
are possible, they may be insigniﬁcant or depend on a cor-
rectly conﬁgured half-life. Tang and Goldberg ﬁnd that low
half-life values close to 0 and high values close to 100 re-
sult in little improvement when compared to unprioritized,
vanilla Tor. We ﬁnd this to be true under lighter loads, but
Figure 7 shows that larger half-life values result in better
performance for more heavily loaded networks. Our results
illustrate that performance beneﬁts are heavily dependent
on network trafﬁc patterns, and we stress the importance of
frequently assessing the network to assist in determining ap-
propriate half-life values over time. We suggest that more
analysis is required to determine if the EWMA scheduler
actually improves performance in the live Tor network, and
if relays should enable it by default.
7 Related Work
This section reviews several experimentation techniques
that have been used to test Tor’s performance and resistance
to various attacks. A test environment that accurately re-
ﬂects Tor’s behavior is crucial to produce meaningful re-
sults. We now brieﬂy explore experimentation techniques
02468101214WebTimetoFirstByte(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma3ewma30ewma90051015202530WebDownloadTime(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma3ewma30ewma90050100150200BulkDownloadTime(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma3ewma30ewma9002468101214WebTimetoFirstByte(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma3ewma30ewma90051015202530WebDownloadTime(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma3ewma30ewma90050100150200BulkDownloadTime(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma3ewma30ewma9002468101214WebTimetoFirstByte(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma3ewma30ewma90051015202530WebDownloadTime(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma3ewma30ewma90050100150200BulkDownloadTime(s)0.00.20.40.60.81.0CumulativeFractionvanillaewma3ewma30ewma90chosen by researchers to evaluate Tor proposals. We note
that: Kiddle [16] provides a comprehensive analysis and
discussion of system simulation and emulation techniques;
Naicken et al.
[26, 27] provide details on several generic
simulators; Bauer et al. [4] provide an in-depth survey of
experimental approaches historically used in Tor-related re-
search; and the EWMA circuit priority scheduler from Tang
and Goldberg [42] is discussed in detail in Section 6.
Simulation. Simulation typically involves creating abstract
models of system processes and running multiple nodes in a
single uniﬁed framework. Experiment management is sim-
pliﬁed since there are many fewer simulation host machines
(typically one) than simulated nodes. By abstracting system
processes, simulators can run much more efﬁciently and are
not required to run in real time. However, the abstraction
process has the potential to reduce accuracy since the sim-
ulator may not encompass complex procedures that may in
fact be important to system interaction. Although generic
simulation platforms exist [18, 29, 30, 41], they are not ca-
pable of running unmodiﬁed versions of the Tor software.
Simulation has often been employed for Tor research,
but simulators tend to be written for a speciﬁc problem and
may be difﬁcult to apply to a generic context: Murdoch
and Watson explore Tor path selection strategies and algo-
rithms [25], O’Gorman and Blott simulate packet count-
ing and stream correlation attacks [33], Ngan et al. study
the effects of their gold-star priority scheme on Tor per-
formance [28], and Jansen et al. simulate queuing models
and trafﬁc prioritization mechanisms [15]. These simula-
tors have either become unmaintained or are not publicly
available, making published results challenging to validate.
Emulation. A competing and fundamentally different ex-
perimentation approach involves emulation. An emulator
“tricks” an application or operating system that it is running
on its own physical machine, when in fact it is virtualized
in software. Emulators require a large amount of overhead
to ensure the emulated software runs in real time while pro-
viding the virtualization layers needed to emulate an entire
system. Therefore, emulation is potentially more accurate
than simulation, but much less scalable: emulators typically
run hundreds of nodes while simulators run thousands.
Due to intensive resource requirements, emulation plat-
forms often utilize a large testbed of geographically dis-
tributed physical hardware. PlanetLab [7] and DETER [5]
are examples of whole-system emulation testbeds. Both of
these frameworks only supply a few hundred nodes to a
user. Several Tor studies have utilized the PlanetLab and
DETER testbeds for experimenting with trafﬁc analysis at-
tacks [3, 6, 13], attacks on Tor bridges [23], and relay cir-
cuit scheduling [42]. Due to resource consumption and co-
location of nodes on each physical machine, results on these
testbeds often suffer from a reduced and false sense of ac-
curacy. Further, distributed experiments like those run on
PlanetLab are challenging to manage and control while re-
sults are difﬁcult to recreate.
A Tor emulation testbed has recently been simultane-
ously and independently proposed by Bauer et al. [4] based
on the ModelNet emulation platform [46]. The emulation
testbed, called ExperimentTor, works by conﬁguring multi-
ple host machines with new operating system installations.
Some of these host machines run a version of ModelNet link
emulators while the remaining machines run Tor and other
application instances. Tor nodes are given IP addresses
from separate virtual interfaces to allow multiple nodes per
machine while sending all trafﬁc over the ModelNet hosts
to emulate conﬁgured network properties.
Shadow has several advantages over ExperimenTor de-
spite having similar goals and motivations. First, Shadow
is more usable than ExperimenTor, which requires multi-
ple physical machines, kernel modiﬁcations, and complex
conﬁguration. Shadow can be run as a stand-alone user
application without root privledges and requires little con-
ﬁguration, leading to an extremely small barrier to entry
and improving accessibility to students, developers, and re-
searchers around the world. Second, Shadow is more efﬁ-
cient and scalable than ExperimenTor. Shadow implements
a discrete-event simulator which allows full utilization of
computational resources while eliminating the requirement
of running in real time: experiments may run either faster
or slower than real time without affecting accuracy. Con-
versely, ExperimenTor suffers from both CPU and band-
width bottlenecks: the CPUs on the machines running the
ExperimenTor testbed must run at far less than 100 percent
utilization and the aggregate trafﬁc load from all applica-
tion instances must not exceed the capacity of the physi-
cal network connecting the host machines. Both require-
ments must be met to ensure the emulated applications do
not lag, since lag would skew and invalidate results obtained
in an experiment. Shadow also minimizes the memory over-
head of running multiple applications on a single machine
with its “state swapping” approach to memory management
whereas ExperimenTor duplicates entire copies of the ap-
plication in memory. Finally, Shadow allows for a richer
customization of the experimental process, e.g. adversarial
entities could easily be added to links between nodes to al-
low monitoring of network level trafﬁc. Similar customiza-
tions would be difﬁcult to add to an ExperimenTor testbed.
8 Conclusion
In this paper, we presented the design and implementa-
tion of a large scale discrete event simulator called Shadow,
and a plug-in called Scallion that is capable of linking to and
running the Tor software over a simulated network. In ad-
dition to an explanation of Shadow’s non-trivial design, we
performed an extensive experimental analysis to verify the
accuracy of Tor simulations. We found that client perfor-
mance for simulated Tor clients is surprisingly congruent to
performance achieved through the live public Tor network.
High accuracy is achieved by “shadowing” the Tor network,
considering relay characteristics from a live Tor consensus
and inter-node latency characteristics from PlanetLab ping
measurements. As an example of the powerful capabilities
of our simulation approach, we explore the EWMA circuit
priority scheduler recently proposed and currently used in
Tor to validate previous results and determine the effects of
a network-wide deployment. We found that correct half-life
conﬁgurations are highly network and load dependent, and
that EWMA actually reduces performance for clients under
certain network conditions. Although enabled by default, it
is unclear if the scheduler improves performance in the live
Tor network.
Limitations. Shadow is a discrete event simulator. By deﬁ-
nition, Shadow imitates the behavior of system and network
processes. These imitations were done by exploring and
measuring real systems and real networks to produce mod-
els of real behaviors suitable for our study of performance
in Tor. This modeling approach fundamentally limits the
ability to adapt to highly dynamic environments, potentially
reducing simulation accuracy. We now brieﬂy discuss our
modeling approaches in the context of their effects on sim-
ulations to emphasize the importance of analyzing and ver-
ifying results so that future researchers may make informed
decisions regarding experimentation with their algorithms
and protocols.
In addition to simulating TCP, Shadow models the Inter-
net by utilizing real delays gathered from ping measure-
ments on PlanetLab. The measurements give us a distri-
bution of pairwise delays between nodes. We then cate-
gorize all nodes into geographical “regions” and aggregate
node distributions between each region. This approxima-
tion forms our model of the Internet and is given as input
to a simulation: when sending a packet from a node in one
region to a node in another, we sample the distribution cor-
responding to the link between those regions. This model
is based on speciﬁc measurements between speciﬁc points
at a speciﬁc time. If Internet congestion at that time was
uncharacteristically high or low, our model would skew re-
sults. Although this approach seemed to provide an ade-
quate delay model in our simulations, future work should
consider if their experiments could beneﬁt from something
more robust. In particular, experiments that depend on side-
channels stemming from latency, throughput, or the inner
workings of a speciﬁc TCP implementation may require
more accurate simulations.
Scallion models system processing delays by gathering
PlanetLab OpenSSL speed and application performance
test measurements. Processing delays are then accumu-
lated as the application reads and writes data, as this allows
Shadow to quantify the amount of work the application is
performing. Delays are incorporated into the event schedul-
ing mechanism. This is a crude approximation of the real
processing delays experienced on a system and is applica-
tion speciﬁc: different applications may have very different
processing delay models. For example, our processing de-
lay model would be inadequate for an application that reads
and writes data one percent of the time and spends the re-
maining time performing expensive operations. Inaccurate
delay models would potentially skew results. Therefore,
new application performance testing is required to appro-
priately model processing delays. Further, experiments that
attempt to introduce variablilty in processing times as a key
feature of an algorithm or as part of an attack will require
more accurate simulations.
In our analysis of Tor performance, our modeling ap-
proaches were suitable to obtain realistic and consistent re-
sults.
In particular, our Tor experiments were run using
the same models while each experiment varied only a sin-
gle conﬁguration option. Therefore, each experiment was
subject to the same system and network conditions and the
same systematic biases that Shadow potentially introduces
during simulation. As a result, we can be reasonably con-
vinced that the relative differences between experimental
results are due to our conﬁgured change and not to some
systematic inaccuracy inherent to simulation, irrespective
of how well the absolute simulation results match those ob-
tained from real systems and networks.
Future Shadow users should be aware of the above lim-
itations and recognize that adequate models are application
dependent. It may be the case that more robust models are
needed to effectively analyze particular algorithms or pro-
tocols. Future research should adapt models as appropriate
to their work in order to draw meaningful conclusions, and
validate results with other experimentation methods.
Future Work. Shadow may be used to explore a wide range
of problems in Tor, including UDP transport mechanisms
and alternative scheduling approaches. Shadow may also
be used to validate previous work and analyze Tor attacks
under various network conﬁgurations and client models. Fi-
nally, an exploration of more robust modeling techniques
would reduce potential systematic biases introduced by our