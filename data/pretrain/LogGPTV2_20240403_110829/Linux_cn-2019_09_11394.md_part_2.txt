```
~]# dnf install java-openjdk -y
```
从两个节点运行 `yum`/`dnf` 命令来安装 logstash：
```
[root@linuxtechi ~]# dnf install logstash -y
[root@linuxtechi ~]# dnf install logstash -y
```
现在配置 logstash，在两个 logstash 节点上执行以下步骤，创建一个 logstash 配置文件，首先我们在 `/etc/logstash/conf.d/` 下复制 logstash 示例文件：
```
# cd /etc/logstash/
# cp logstash-sample.conf conf.d/logstash.conf
```
编辑配置文件并更新以下内容：
```
# vi conf.d/logstash.conf
input {
  beats {
    port => 5044
  }
}
output {
  elasticsearch {
    hosts => ["http://elasticsearch1.linuxtechi.local:9200", "http://elasticsearch2.linuxtechi.local:9200", "http://elasticsearch3.linuxtechi.local:9200"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
    #user => "elastic"
    #password => "changeme"
  }
}
```
在 `output` 部分之下，在 `hosts` 参数中指定所有三个 Elasticsearch 节点的 FQDN，其他参数保持不变。
使用 `firewall-cmd` 命令在操作系统防火墙中允许 logstash 端口 “5044”：
```
~ # firewall-cmd --permanent --add-port=5044/tcp
~ # firewall-cmd –reload
```
现在，在每个节点上运行以下 `systemctl` 命令，启动并启用 Logstash 服务：
```
~]# systemctl start logstash
~]# systemctl eanble logstash
```
使用 `ss` 命令验证 logstash 服务是否开始监听 5044 端口：
```
[root@linuxtechi ~]# ss -tunlp | grep 5044
tcp   LISTEN  0       128                         *:5044                *:*      users:(("java",pid=2416,fd=96))
[root@linuxtechi ~]#
```
以上输出表明 logstash 已成功安装和配置。让我们转到 Kibana 安装。
### 安装和配置 Kibana
登录 Kibana 节点，使用 `hostnamectl` 命令设置主机名：
```
[root@linuxtechi ~]# hostnamectl set-hostname "kibana.linuxtechi.local"
[root@linuxtechi ~]# exec bash
[root@linuxtechi ~]#
```
编辑 `/etc/hosts` 文件并添加以下行：
```
192.168.56.40             elasticsearch1.linuxtechi.local
192.168.56.50             elasticsearch2.linuxtechi.local
192.168.56.60             elasticsearch3.linuxtechi.local
```
使用以下命令设置 Kibana 存储库：
```
[root@linuxtechi ~]# vi /etc/yum.repos.d/kibana.repo
[elasticsearch-7.x]
name=Elasticsearch repository for 7.x packages
baseurl=https://artifacts.elastic.co/packages/7.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
[root@linuxtechi ~]# rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch
```
执行 `yum`/`dnf` 命令安装 kibana：
```
[root@linuxtechi ~]# yum install kibana -y
```
通过编辑 `/etc/kibana/kibana.yml` 文件，配置 Kibana：
```
[root@linuxtechi ~]# vim /etc/kibana/kibana.yml
…………
server.host: "kibana.linuxtechi.local"
server.name: "kibana.linuxtechi.local"
elasticsearch.hosts: ["http://elasticsearch1.linuxtechi.local:9200", "http://elasticsearch2.linuxtechi.local:9200", "http://elasticsearch3.linuxtechi.local:9200"]
…………
```
启用并启动 kibana 服务：
```
[root@linuxtechi ~]# systemctl start kibana
[root@linuxtechi ~]# systemctl enable kibana
```
在系统防火墙上允许 Kibana 端口 “5601”：
```
[root@linuxtechi ~]# firewall-cmd --permanent --add-port=5601/tcp
success
[root@linuxtechi ~]# firewall-cmd --reload
success
[root@linuxtechi ~]#
```
使用以下 URL 访问 Kibana 界面：
![Kibana-Dashboard-rhel8](/data/attachment/album/201909/26/212453uht51r0cd0wcupbh.jpg)
从面板上，我们可以检查 Elastic Stack 集群的状态。
![Stack-Monitoring-Overview-RHEL8](/data/attachment/album/201909/26/212508s0f88fd788nwk868.jpg)
这证明我们已经在 RHEL 8 /CentOS 8 上成功地安装并设置了多节点 Elastic Stack 集群。
现在让我们通过 `filebeat` 从其他 Linux 服务器发送一些日志到 logstash 节点中，在我的例子中，我有一个 CentOS 7服务器，我将通过 `filebeat` 将该服务器的所有重要日志推送到 logstash。
登录到 CentOS 7 服务器使用 yum/rpm 命令安装 filebeat 包：
```
[root@linuxtechi ~]# rpm -ivh https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.3.1-x86_64.rpm
Retrieving https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.3.1-x86_64.rpm
Preparing...                          ################################# [100%]
Updating / installing...
   1:filebeat-7.3.1-1                 ################################# [100%]
[root@linuxtechi ~]#
```
编辑 `/etc/hosts` 文件并添加以下内容：
```
192.168.56.20             logstash1.linuxtechi.local
192.168.56.30             logstash2.linuxtechi.local
```
现在配置 `filebeat`，以便它可以使用负载平衡技术向 logstash 节点发送日志，编辑文件 `/etc/filebeat/filebeat.yml`，并添加以下参数：
在 `filebeat.inputs:` 部分将 `enabled: false` 更改为 `enabled: true`，并在 `paths` 参数下指定我们可以发送到 logstash 的日志文件的位置；注释掉 `output.elasticsearch` 和 `host` 参数；删除 `output.logstash:` 和 `hosts:` 的注释，并在 `hosts` 参数添加两个 logstash 节点，以及设置 `loadbalance: true`。
```
[root@linuxtechi ~]# vi /etc/filebeat/filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/messages
    - /var/log/dmesg
    - /var/log/maillog
    - /var/log/boot.log
#output.elasticsearch:
  #  hosts: ["localhost:9200"]
output.logstash:
    hosts: ["logstash1.linuxtechi.local:5044", "logstash2.linuxtechi.local:5044"]
    loadbalance: true
```
使用下面的 2 个 `systemctl` 命令 启动并启用 `filebeat` 服务：
```
[root@linuxtechi ~]# systemctl start filebeat
[root@linuxtechi ~]# systemctl enable filebeat
```
现在转到 Kibana 用户界面，验证新索引是否可见。
从左侧栏中选择管理选项，然后单击 Elasticsearch 下的索引管理：
![Elasticsearch-index-management-Kibana](/data/attachment/album/201909/26/212514m1lziump2ly2zz81.jpg)
正如我们上面看到的，索引现在是可见的，让我们现在创建索引模型。
点击 Kibana 部分的 “Index Patterns”，它将提示我们创建一个新模型，点击 “Create Index Pattern” ，并将模式名称指定为 “filebeat”：
![Define-Index-Pattern-Kibana-RHEL8](/data/attachment/album/201909/26/212519soeqwn1emyomum2m.jpg)
点击下一步。
选择 “Timestamp” 作为索引模型的时间过滤器，然后单击 “Create index pattern”：
![Time-Filter-Index-Pattern-Kibana-RHEL8](/data/attachment/album/201909/26/212526cvb1vr31lj3lojkn.jpg)
![filebeat-index-pattern-overview-Kibana](/data/attachment/album/201909/26/212532wlz4albbl2mgccap.jpg)
现在单击查看实时 filebeat 索引模型：
![Discover-Kibana-REHL8](/data/attachment/album/201909/26/212548zqw4482qv44q12v7.jpg)
这表明 Filebeat 代理已配置成功，我们能够在 Kibana 仪表盘上看到实时日志。
以上就是本文的全部内容，对这些帮助你在 RHEL 8 / CentOS 8 系统上设置 Elastic Stack 集群的步骤，请不要犹豫分享你的反馈和意见。
---
via: 
作者：[Pradeep Kumar](https://www.linuxtechi.com/author/pradeep/) 选题：[lujun9972](https://github.com/lujun9972) 译者：[heguangzhi](https://github.com/heguangzhi) 校对：[wxy](https://github.com/wxy)
本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出