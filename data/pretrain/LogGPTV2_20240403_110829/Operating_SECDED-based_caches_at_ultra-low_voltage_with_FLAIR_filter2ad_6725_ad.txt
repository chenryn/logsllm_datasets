### Cache Capacity and Weak Line Reclamation (WLR)

During normal program operation, we observe that lines with a single bit hard fault can still be used for reliably storing clean lines. If a soft error occurs in a weak line (a line with a 1-bit hard error), it results in an uncorrectable double-bit error, which can be detected using existing Single Error Correction, Double Error Detection (SECDED) circuitry. By restricting such lines to store only clean data, we can invalidate the line and read the data from memory if a soft error occurs. This concept is termed **Weak Line Reclamation (WLR)**.

### Enabling WLR

To implement WLR, we need information about whether a faulty line has exactly one bit error or more than one. This information is identified during the testing phase and conveyed to the execution phase in an efficient manner. Each cache line is augmented with a **Faulty Cache Line (FCL) bit**. For lines with at least one bit error, the FCL bit is set to 1. If the FCL bit is 1, the line cannot store dirty data, allowing us to reuse the DirtyBit to convey the number of faults. Specifically:
- If FCL = 1 and DirtyBit = 1, the line has more than one error and is disabled.
- If FCL = 1 and DirtyBit = 0, the line has exactly one error and can store only clean data.

The status of each line based on the FCL and DirtyBit combination is summarized in Table V.

| FCL | DirtyBit | Status |
|-----|----------|--------|
| 0   | 0        | Fault-free line storing clean data |
| 0   | 1        | Fault-free line storing dirty data  |
| 1   | 0        | Faulty Line with 1 hard-error, can store clean data |
| 1   | 1        | Faulty Line with 2+ errors, disabled |

If a clean line with FCL = 1 becomes dirty, a clean line (with FCL = 0) from the same set is selected using the cache's replacement policy and swapped with the dirty line. If no clean lines are available, a victim line (with FCL = 0) is identified, and the dirty data is written to that location. With WLR, 90.7% of the cache capacity remains available during normal program operation, compared to 60% without WLR.

### Evaluations and Analysis

#### A. Experimental Methodology

For our performance studies, we use CMP$im [8], a trace-driven x86 simulator. The baseline model is a quad-core out-of-order processor similar to the Intel Core i7. We simulate the following cache configurations:
- 32 KB 8-way associative L1 instruction and data caches with 3-cycle latency
- 256 KB 8-way associative L2 cache with 8-cycle latency
- 8 MB 16-way associative L3 cache with 20-cycle latency

All caches use a 64-byte line size, and the L3 cache is protected with SECDED.

To analyze FLAIR, we extend CMP$im to:
1. Disable cache lines with multi-bit failures.
2. Restrict the use of cache lines with 1-bit failure to clean data.

We also simulate an ideal, defect-free, low-voltage baseline with reliable caches. Performance is measured using a slice of 500 million instructions for each SPEC2006 benchmark, obtained after fast-forwarding the first 500 million instructions. We run these benchmarks in rate-mode on the quad-core processor and include three commercial benchmarks (oltp, sap, specjbb). Results are reported in terms of committed instructions per cycle (IPC).

#### B. Performance in Normal Mode

Figure 11 shows the performance of FLAIR (with and without WLR) normalized to the defect-free baseline. The geometric mean (GeoMean) of normalized IPC across all workloads is shown. FLAIR-WLR shows a negligible drop in performance for most benchmarks, with a maximum performance loss of 4%. On average, FLAIR-WLR degrades performance by only 1.5%, as it disables only 9% of the cache lines and restricts 30% to storing clean data. Comparing FLAIR-WLR with FLAIR-no-WLR, WLR provides substantial performance improvements, averaging 3% and reducing the maximum performance degradation from 14% to 4% for mcf. For commercial benchmarks, WLR improves performance: 4% for oltp, 11% for sap, and 8% for specjbb.

#### C. Power and Energy Efficiency

Table VI summarizes the achievable minimum voltage (Vmin), frequency, power consumption, and energy per instruction (EPI) for different configurations during the low-voltage mode. FLAIR achieves the lowest power and EPI among all configurations, reducing power by 86%, 71%, and 30% compared to the baseline, ECC-1, and VS-ECC, respectively. It also reduces EPI by 53%, 33%, and 6% compared to the baseline, ECC-1, and VS-ECC, respectively. Even with a pessimistic assumption that ECC-8 incurs zero power and latency, FLAIR has comparable power and EPI while avoiding ECC-8 overheads.

#### D. Hardware Overhead of FLAIR

Implementing FLAIR requires minor changes to the cache controller. The ternary output (G, C, D) status of a line is already available from SECDED. A simple line-comparator circuit for DMR is needed, incurring negligible logic. The storage overhead is one bit per cache line (to indicate a faulty cache line). Thus, FLAIR avoids the storage overhead of multi-bit ECC and the complex circuitry required for ECC decoding.

### Summary

Recent proposals for tolerating multi-bit errors in cache lines to enable low-voltage operation often require significant storage and hardware complexity. Our aim is to enable low-power operation with minimal design changes and hardware overhead. We propose FLAIR, a dynamic replication scheme for robustness during the testing phase, and WLR for reliable use of lines with 1-bit hard errors in the post-testing phase. FLAIR meets the following requirements:
1. Operates at 485 mV, 50 mV below the previous state-of-the-art.
2. Incurs negligible logic overhead and storage of only one bit per cache line.
3. Tolerates soft errors in both testing and post-testing phases without additional storage.
4. Provides 91% of the cache capacity during normal execution, resulting in a 1.3% average performance loss.
5. Retains a cache read latency similar to a baseline cache with SECDED ECC.
6. Does not rely on non-volatile memory-based fault maps or software changes.

FLAIR protects the cache from both hard and soft errors, enabling flexible low-power operation modes in future processors. While this analysis focuses on a cache with SECDED, the general idea of FLAIR can be applied to other cache designs, including those without ECC or with built-in multi-bit ECC codes.

### References

[1] J. Abella et al. Low vccmin fault-tolerant cache with highly predictable performance. In MICRO-2010.
[2] A. Alameldeen et al. Energy-efficient cache design using variable-strength error correcting codes. In ISCA-2011.
[3] A. Ansari et al. Zerehcache: Armoring cache architectures in high defect density technologies. In MICRO-2009.
[4] A. Ansari, S. Feng, S. Gupta, and S. Mahlke. Archipelago: A polymorphic cache design for enabling robust near-threshold operation. In HPCA-2011, Feb. 2011.
[5] D. Bossen, J. Tendler, and K. Reick. Power4 system design for high reliability. In IEEE Micro, vol. 22, No. 2, pp. 16-24, Mar. 2002.
[6] Z. Chisti et al. Improving cache lifetime reliability at ultra-low voltages. In MICRO-2009.
[7] A. Garg and P. Dubey. Fuse area reduction based on quantitative yield analysis and effective chip cost. In Defect and Fault Tolerance in VLSI Systems, 2006. DFT â€™06. 21st IEEE International Symposium on, Oct. 2006.
[8] A. Jaleel et al. Cmpsim: A pin-based on-the-fly multi-core cache simulator. In Fourth Annual Workshop on Modeling, Benchmarking, and Simulation (MoBS), 2008.
[9] J. Kulkarni, K. Kim, and K. Roy. A 160 mv robust schmitt trigger based subthreshold sram. In IEEE Journal of Solid-State Circuits, vol. 42, no. 10, pp. 2303-2313, Oct. 2007.
[10] M. Manoochehri, M. Annavaram, and M. Dubois. Cppc: Correctable parity protected cache. In ISCA-38, 2011.
[11] D. Roberts, N. Kim, and T. Mudge. On-chip cache device scaling limits and effective fault repair techniques in future nanoscale technology. In Digital System Design Architectures, Methods and Tools, pp. 570-578, Aug. 2007.
[12] H. M. S. Rusu and B. Cherkauer. Itanium 2 processor 6m: Higher frequency and larger l3 cache. In IEEE Micro, vol. 24, No. 2, pp. 10-18, Mar. 2004.
[13] C. Wilkerson et al. Reducing cache power with low cost, multi-bit error-correcting codes. In ISCA-2010.
[14] C. Wilkerson et al. Trading off cache capacity for reliability to enable low voltage operation. In ISCA-2008.

### Appendix A: Memory Bandwidth Consumption in Testing Mode for VS-ECC and FLAIR

We compare FLAIR with the state-of-the-art VS-ECC design in terms of memory bandwidth consumption during the testing mode. VS-ECC disables 12 out of 16 ways, resulting in an effective capacity of 25%. In contrast, FLAIR has a higher effective cache capacity, as only 2 out of 16 ways undergo testing, while the remaining 14 ways are operational with DMR. Table VII compares the average memory bandwidth consumption for VS-ECC and FLAIR.

FLAIR reduces read traffic by an average of 6% due to its larger effective cache capacity. However, the write-through design of FLAIR during the testing mode increases write traffic. Overall, the memory traffic consumed by the two approaches differs by only 2% on average, and their overall system performance is comparable during the testing phase.

|           | VS-ECC | FLAIR  |
|-----------|--------|--------|
| Read BW   | 70.7%  | 75.7%  |
| Write BW  | 24.3%  | 31.0%  |
| Total BW  | 100.0% | 101.7% |

### Acknowledgments

Thanks to Wei Wu for discussions on Multi-bit Error Correction Code. Moinuddin Qureshi is supported by NetApp Faculty Fellowship and Intel Early Career Award.