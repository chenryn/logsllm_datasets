capacity during normal program operation. We observe that
lines with a single bit hard fault can still be used for reliably
storing clean lines. If a soft error happens in a weak line (line
with 1-bit hard error), then it becomes uncorrectable double
bit error and we can detect it with existing SECDED circuitry.
If such a lines is restricted to store clean data, we can simply
invalidate the line and read the data from memory. We call
this concept Weak Line Reclamation (WLR).
To enable WLR, we need information about whether the
faulty line has exactly one bit error or more than one bit error.
During the testing phase, the lines are identiﬁed as such. We
convey this information from testing phase to execution phase
8The original Archipelago study
[4] claimed Vmin of 375mv. This is
because they use more optimistic pfail-to-Vmin curve than shown in Figure 2,
a yield target of 99%, and 2MB cache. For their assumptions, both ECC-8
and Archipelago are operational till a failure of about 1 in 700 cells (375mv).
Fig. 10. Percentage of fault-free lines, lines with exactly one error, and lines
with 2 or more errors, as operating voltage is varied. At target Vmin of 485mv,
there are 9.3% lines with 2+ errors, 30.7% lines with exactly one error, and
60% of the lines have no errors.
in a storage efﬁcient manner. Each line is augmented with a
Faulty Cache Line (FCL) bit. For all lines that have at least
one bit error FCL is set to 1. We note that if FCL=1, that line
cannot be used to store dirty data so we can reuse the DirtyBit
to convey information about the number of faults in the line. If,
FCL=1 and DirtyBit=1 then the line is deemed to have more
than 1 error, and is disabled. If FCL=1 and DirtyBit=0, then
the line has exactly one error and can be used to store only
clean lines. The disable status as conveyed by combination of
FCL and DirtyBit is captured in Table V.
TABLE V.
IMPLEMENTING WEAK LINE RECLAMATION.
FCL Dirty
Status
0
0
1
1
0
1
0
1
Fault-free line storing clean data
Fault-free line storing dirty data
Faulty Line with 1 hard-error, can store clean data
Faulty Line with 2+ errors, disabled
If a clean line with FCL=1 becomes dirty then a clean line
(with FCL=0) from that set is selected (using the replacement
policy of the cache) and swapped with the line that has become
dirty. If there are no clean lines in the set, then a victim line
(with FCL=0) is identiﬁed and the dirty data is written to that
location. With Weak Line Reclamation, we can have 90.7% of
the cache capacity available during normal program operation
(instead of 60% usable cache capacity).
VI. EVALUATIONS AND ANALYSIS
A. Experimental Methodology
For our performance studies, we use CMP$im [8], a trace-
driven x86 simulator. As a baseline, we model a quad-core out-
of-order processor, which is similar to the Intel Core i7 proces-
sor. We simulate 32 KB 8-way associative L1 instruction and
data caches with 3-cycle latency, 256 KB 8-way associative
L2 cache with 8-cycle latency and 8 MB, 16-way associative
L3 cache with 20-cycle latency. All caches use a linesize of
64-bytes. We assume L3 is protected with SECDED.
To analyze FLAIR, we extend CMP$im to simulate the
following effects: (i) disable cache lines with multi-bit fail-
ures, (ii) restrict the use of cache lines with 1-bit failure to
clean data. Furthermore, to quantify the performance overhead
of reduced cache capacity of FLAIR; we also simulate an
ideal, defect-free, low-voltage baseline that has reliable caches
without any loss in capacity. We use a slice of 500 million
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:43:00 UTC from IEEE Xplore.  Restrictions apply. 
)
s
t
c
e
f
e
D
o
N
o
t
.
m
r
o
N
(
C
P
I
1.00
0.98
0.96
0.94
0.92
0.90
0.88
0.86
0.84
0.82
0.80
G e m sF D T D 
b w aves 
bzip2 
astar 
cactusA
M  
D
gro m acs 
calculix 
h264ref 
ga m ess 
gob m k 
dealII 
gcc 
h m
FLAIR-WLR  
FLAIR-no-WLR  
libquantu m 
leslie3d 
m er 
lb m 
m cf 
perlbench 
o m netpp 
povray 
soplex 
na m d 
sjeng 
milc 
sphinx 
tonto 
wrf 
xalancb m k 
zeus m p 
oltp 
G eo M ean 
specjbb 
sap 
Fig. 11.
IPC of FLAIR (with and without Weak Line Reclamation) normalized to an ideal defect-free baseline.
TABLE VI.
POWER AND ENERGY COMPARISON.
Vmin (mV)
Clock Frequency (MHz) Normalized Power Normalized EPI
848
684
538
487
485
2000
1380
820
580
575
1.00
0.47
0.20
0.14
0.14
1.00
0.69
0.50
0.47
0.47
Design
No-ECC
ECC-1
VS-ECC
ECC-8*
FLAIR
instructions for each SPEC2006 benchmark, obtained after
fast-forwarding ﬁrst 500 million instructions. We run these
benchmarks in a rate-mode on the quad-core processor. We
also use three commercial benchmarks (oltp, sap, specjbb).
We show performance results only for the normal execution
phase and not for the testing phase. We report performance in
terms of number of committed instructions per cycle (IPC).
B. Performance in Normal Mode
Figure 11 shows the performance of FLAIR (with and
without WLR) for all the benchmarks, normalized to defect-
free baseline. The bar labeled GeoMean show the geometric
mean of normalized IPC across all workloads. We only show
the performance impact of L3 design changes while keeping
the L1 and L2 caches uniform across all the conﬁgurations.
In comparison with the defect-free baseline, FLAIR-WLR
shows a negligible drop in performance for majority of the
benchmarks, with the maximum performance loss limited
to 4%. Averaging across all the benchmarks, FLAIR-WLR
degrades performance by only 1.5% . The performance loss
is negligible because FLAIR-WLR disables only 9% of the
cache lines, while restricting 30% of the cache lines to storing
clean data. Comparing FLAIR-WLR with FLAIR-no-WLR,
we note that FLAIR-WLR provides substantial performance
improvements over FLAIR-no-WLR. Weak Line Reclamation
improves the performance by 3% on average and brings
down the maximum performance degradation caused by our
technique during post-testing mode from 14% to 4%, for mcf.
For commercial benchmarks, the effectiveness is even more
pronounced compared to SPEC benchmarks. WLR improves
performance of oltp by 4%, sap by 11%, and specjbb by 8%.
C. Power and Energy Efﬁciency
Table VI summarizes the achievable Vmin, frequency,
power consumption and energy per instruction (EPI) of dif-
ferent conﬁgurations during the low voltage mode. In addition
to the baseline conﬁguration and FLAIR, we also show results
for ECC-1 and VS-ECC. We normalize the power and energy
results for different designs to that of the baseline, while
showing absolute results for Vmin and frequency. For fre-
quency calculations, we perform circuit simulations to predict
the frequency at different voltages. For our power evaluations,
we use an industry grade power tool. The power numbers are
based on data from a commercial processor on 32nm node.
FLAIR achieves the lowest power and EPI amongst all the
conﬁgurations. FLAIR reduces power by 86%, 71%, and 30%,
compared with baseline, ECC-1, and VS-ECC, respectively,
while reducing EPI by 53%, 33%, and 6% compared with
baseline, ECC-1, and VS-ECC, respectively. FLAIR achieves
better energy efﬁciency compared to VS-ECC, while obviating
the need for complex multi-bit ECC encoding and decoding
logic and the storage overhead of ECC-4 for one fourth of the
cache.
For power and energy comparisons with ECC-8, we pes-
simistically assume that circuitry for encoding and decoding
ECC-8 incurs zero power and latency. Nonetheless, even with
such a pessimistic assumption ,FLAIR has comparable power
and EPI as ECC-8, while avoiding the overheads of ECC-8.
D. Hardware Overhead of FLAIR
Implementing FLAIR requires only minor changes to the
cache controller. The ternary output of (G,C,D) status of a
line is already available from SECDED. We simply need to
implement one line-comparator circuit for DMR, which incurs
negligible logic. The storage overhead of FLAIR is one bit
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:43:00 UTC from IEEE Xplore.  Restrictions apply. 
per cache line (to indicate faulty cache line). Thus, FLAIR
not only avoids the storage overhead of multi-bit ECC but
also the complex circuitry required for ECC decoding.
VII. SUMMARY
While several recent proposals have tried to tolerate multi-
bit errors in cache lines to enable low-voltage operation, they
typically require signiﬁcant storage overhead and hardware
complexity. Our aim is to enable low power operation without
requiring signiﬁcant design changes to cache structure and
avoiding the hardware overhead. We rely on runtime testing
to identify faulty lines. We propose FLAIR, a highly effective
dynamic replication scheme to provide robustness during test-
ing phase, and Weak Line Reclamation to enable reliable use
of lines with 1-bit hard error during the post-testing phase.
In this paper, we set out six requirements for reliable
low voltage cache operation and developed a practical, low
overhead solution, which meets all these requirements:
1)
2)
3)
4)
5)
6)
Our solution enables the cache to operate at a voltage
of 485 mV, almost 50mv below the minimum voltage
achieved by the previous state-of-the art solution.
Our solution incurs negligible logic overhead and the
storage overhead of only a single (faulty cache line
bit per cache line; substantially lower than previous
solutions.
Our solution tolerates soft errors in both testing and
post-testing phases, without relying on additional
storage overhead except for the existing SECDED-
code.
Our solution provides 91% of the cache capacity
during normal program execution, resulting in only
1.3% average performance loss compared to a defect-
free baseline.
Our solution retains a cache read latency similar to
that of a baseline cache with SECDED ECC during
normal program execution (post-testing phase).
Our solution obviates the need for a non-volatile
memory based fault map, and does not rely on
software changes for deployment.
Unlike previous low-voltage cache proposals that largely
ignored soft-error resilience, FLAIR protects the cache from
both hard errors as well as soft errors. FLAIR is a simple and
effective solution which enables the use of same chip design
in different domains with negligible hardware changes. We
believe such practical and effective solutions will be driver for
ﬂexible low-power operation modes in future processors.
In this paper, we analyzed FLAIR on a cache that imple-
ments SECDED. However, the general idea of FLAIR can also
be applied to other cache designs that do not have ECC (No-
ECC) or have built-in multi-bit ECC codes [10] .
REFERENCES
[1]
J. Abella et al. Low vccmin fault-tolerant cache with highly predictable
performance. In MICRO-2010.
[2] A. Alameldeen et al. Energy-efﬁcient cache design using variable-
strength error correcting codes. In ISCA-2011.
[3] A. Ansari et al. Zerehcache: Armoring cache architectures in high defect
density technologies. In MICRO-2009.
[4] A. Ansari, S. Feng, S. Gupta, and S. Mahlke. Archipelago: A
polymorphic cache design for enabling robust near-threshold operation.
In HPCA-2011, feb. 2011.
[5] D. Bossen, J. Tendler, and K. Reick. Power4 system design for high
reliability. In IEEE Micro, vol. 22, No. 2, pp. 16-24, Mar. 2002.
[6] Z. Chisti et al. Improving cache lifetime reliability at ultra-low voltages.
In MICRO-2009.
[7] A. Garg and P. Dubey. Fuse area reduction based on quantitative yield
analysis and effective chip cost. In Defect and Fault Tolerance in VLSI
Systems, 2006. DFT ’06. 21st IEEE International Symposium on, oct.
2006.
[8] A. Jaleel et al. Cmpsim: A pin-based on-the-ﬂy multi-core cache
In Fourth Annual Workshop on Modeling, Benchmarking
simulator.
and Simulation (MoBS), 2008.
[9]
J. Kulkarni, K. Kim, and K. Roy. A 160 mv robust schmitt trigger
based subthreshold sram. In IEEE Journal of Solid-State Circuits, vol.
42, no. 10, pp. 2303-2313, Oct. 2007.
[10] M. Manoochehri, M. Annavaram, and M. Dubois. Cppc: correctable
parity protected cache. In ISCA-38, 2011.
[11] D. Roberts, N. Kim, and T. Mudge. On-chip cache device scaling limits
and effective fault repair techniques in future nanoscale technology. In
Digital System Design Architectures, Methods and Tools, pp. 570-578,
Aug. 2007.
[12] H. M. S. Rusu and B. Cherkauer.
frequency and larger l3 cache.
10-18, Mar. 2004.
Itanium 2 processor 6m: Higher
In IEEE Micro, vol. 24, No. 2, pp.
[13] C. Wilkerson et al. Reducing cache power with low cost, multi-bit
error-correcting codes. In ISCA-2010.
[14] C. Wilkerson et al. Trading off cache capacity for reliability to enable
low voltage operation. In ISCA-2008.
APPENDIX A: MEMORY BANDWIDTH CONSUMPTION IN
TESTING MODE FOR VS-ECC AND FLAIR
We compare our proposal (FLAIR) with the state-of-the-
art VS-ECC design in terms of their memory bandwidth
consumption during the testing mode. VS-ECC disables 12
cache ways out of 16 ways, resulting in an effective capacity
of 25%. In case of FLAIR,
the effective cache capacity
is higher than 25%, because only 2 out of the 16 ways
undergo testing, while the 14 ways are used (with DMR) to
provide an operational cache. Table VII compares the average
memory bandwidth consumption for VS-ECC and FLAIR.
FLAIR reduces read trafﬁc as compared to VS-ECC, by an
average of 6%. This reduction is due to larger effective cache
capacity. However, the write-through design of FLAIR during
the testing mode increases the write trafﬁc to memory. The
overall memory trafﬁc consumed by the two approaches differs
by only 2% on average. During the testing phase, the overall
system performance of VS-ECC and FLAIR are comparable,
as FLAIR has fewer read misses compared to VS-ECC.
TABLE VII.
BANDWIDTH CONSUMPTION BREAKDOWN IN TESTING
(BW NUMBERS NORMALIZED TO VS-ECC).
ACKNOWLEDGMENTS
Thanks to Wei Wu for discussions on Multi-bit Error
Correction Code. Moinuddin Qureshi is supported by NetApp
Faculty Fellowship and Intel Early Career Award.
VS-ECC
FLAIR
70.7%
Read BW
75.7%
Write BW 24.3%
31.0%
Total BW 100.0% 101.7%
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:43:00 UTC from IEEE Xplore.  Restrictions apply.