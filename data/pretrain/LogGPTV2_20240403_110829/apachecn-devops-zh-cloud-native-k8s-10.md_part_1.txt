# 十、Kubernetes 故障排除
本章回顾了有效排除 Kubernetes 集群和运行于其上的应用故障的最佳实践方法。这包括讨论常见的 Kubernetes 问题，以及如何分别调试主程序和工作程序。常见的 Kubernetes 问题将以案例研究的形式进行讨论和教学，分为集群问题和应用问题。
我们将首先讨论一些常见的 Kubernetes 故障模式，然后再讨论如何最好地排除集群和应用的故障。
在本章中，我们将涵盖以下主题:
*   了解分布式应用的故障模式
*   Kubernetes 集群故障排除
*   Kubernetes 上应用的故障排除
# 技术要求
为了运行本章中详细介绍的命令，您将需要一台支持`kubectl`命令行工具的计算机以及一个工作正常的 Kubernetes 集群。参见 [*第一章*](01.html#_idTextAnchor016)*与 Kubernetes*通讯，了解几种快速与 Kubernetes 一起起床跑步的方法，以及如何安装`kubectl`工具的说明。
本章使用的代码可以在本书的 GitHub 资源库中找到[https://GitHub . com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/chapter 10](https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter10)。
# 了解分布式应用的故障模式
默认情况下，如果 Kubernetes 组件(以及运行在 Kubernetes 上的应用)运行多个副本，则它们是分布式的。这可能会导致一些有趣的故障模式，很难调试。
由于这个原因，如果 Kubernetes 上的应用是无状态的，它们就不太容易出现故障——在这种情况下，状态被卸载到运行在 Kubernetes 之外的缓存或数据库中。像 StatefulSets 和 PersistentVolumes 这样的 Kubernetes 原语可以让在 Kubernetes 上运行有状态的应用变得更加容易，而且随着每个版本的发布，在 Kubernetes 上运行有状态的应用的体验都在提高。尽管如此，决定在 Kubernetes 上运行完全有状态的应用会带来复杂性，并因此带来失败的可能性。
分布式应用中的失败可能由许多不同的因素引起。像网络可靠性和带宽限制这样简单的事情可能会导致重大问题。这些差异如此之大，以至于*太阳微系统公司*的彼得·多伊奇(Peter Deutsch)帮助解决了分布式计算的*谬误*(以及*詹姆斯·高斯林*，后者增加了第 8 点)，这是分布式应用中常见的失败因素。在论文*分布式计算的谬误解释*、 *Arnon Rotem-Gal-Oz* 中讨论了这些谬误的来源([https://www.rgoarchitects.com/Files/fallacies.pdf](https://www.rgoarchitects.com/Files/fallacies.pdf))。
谬误如下，按数字顺序排列:
1.  网络是可靠的。
2.  延迟为零。
3.  带宽是无限的。
4.  网络是安全的。
5.  拓扑不会改变。
6.  有一个管理员。
7.  运输成本为零。
8.  网络是同质的。
Kubernetes 是在考虑到这些谬误的情况下设计和开发的，因此更加宽容。它还有助于解决运行在 Kubernetes 上的应用的这些问题，但并不完美。因此，当您的应用在 Kubernetes 上进行容器化和运行时，很有可能会在遇到这些问题时出现问题。每一个谬误，当被假设为不真实的，并得出其逻辑结论时，都会在分布式应用中引入失败模式。让我们回顾一下适用于 Kubernetes 和运行在 Kubernetes 上的应用的每个谬误。
## 网络可靠
运行在多个逻辑机器上的应用必须通过互联网进行通信——因此网络中的任何可靠性问题都可能引发问题。具体而言，在 Kubernetes 上，控制平面本身可以分布在高可用性设置中(这意味着具有多个主节点的设置–参见 [*第 1 章*](01.html#_idTextAnchor016) 、*与 Kubernetes 通信*)，这意味着可以在控制器级别引入故障模式。如果网络不可靠，那么 kubelets 可能无法与控制平面通信，从而导致 Pod 放置问题。
类似地，控制平面的节点可能无法相互通信，尽管`etcd`当然是用能够容忍通信故障的一致协议构建的。
最后，工作节点可能无法相互通信，在微服务场景中，这可能会导致问题，具体取决于 Pod 的放置。在某些情况下，工作人员可能都能够与控制平面通信，但仍然无法相互通信，这可能会导致 Kubernetes 覆盖网络出现问题。
与一般的不可靠性一样，延迟也会导致许多相同的问题。
## 延迟为零
如果网络延迟很大，许多与网络不可靠相同的故障也会出现。例如，kubelets 和控制平面之间的调用可能会失败，导致`etcd`出现不准确的时间段，因为控制平面可能无法联系 kube lets–或正确更新`etcd`。类似地，在工作节点上运行的应用之间的请求可能会丢失，否则，如果这些应用并置在同一个节点上，这些应用将可以正常工作。
## 带宽无限
带宽限制可能会暴露与前两个谬误类似的问题。Kubernetes 目前没有完全支持的方法来基于带宽订阅放置 Pods。这意味着达到网络带宽限制的节点仍然可以为其安排新的 Pods，从而导致请求的故障率和延迟问题增加。有人要求将此添加为核心 Kubernetes 调度功能(基本上是一种调度节点带宽消耗的方式，与 CPU 和内存一样)，但目前，解决方案大多局限于**容器网络接口** ( **CNI** )插件。
重要说明
例如，CNI 带宽插件支持 Pod 级别的流量整形——参见[https://kubernetes . io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/# support-流量整形](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping)。
第三方 Kubernetes 网络实现也可能提供带宽方面的附加功能，并且许多都与 CNI 带宽插件兼容。
## 网络安全
网络安全的影响远远超出了 Kubernetes 的范围，因为任何不安全的网络都会受到一系列攻击。攻击者可能能够获得对 Kubernetes 群集中主节点或工作节点的 SSH 访问权限，这可能会导致重大违规。由于 Kubernetes 的大部分魔法都发生在网络上，而不是在一台机器上，因此在受到攻击的情况下，访问网络就成了双重问题。
## 拓扑不变
这个谬论在 Kubernetes 的上下文中特别相关，因为不仅元网络拓扑会随着新节点的添加和移除而改变，覆盖网络拓扑也会被 Kubernetes 控制平面和 CNI 直接改变。
因此，某个时刻在一个逻辑位置运行的应用可能会在网络中完全不同的位置运行。因此，使用 Pod IPs 来识别逻辑应用是一个坏主意——这是服务抽象的目的之一(参见 [*第 5 章*](05.html#_idTextAnchor127)*服务和入口*–*与外部世界通信*)。任何不采用集群内无限拓扑结构(至少涉及入侵防御)的应用都可能有问题。例如，将应用路由到一个特定的 Pod IP 只会在该 Pod 发生意外时起作用。如果该 Pod 关闭，控制它的部署(例如)将启动一个新的 Pod 来替换它，但 IP 将完全不同。集群域名系统(以及扩展的服务)提供了一种更好的方法来在集群中的应用之间发出请求，除非您的应用能够根据集群变化(如 Pod 放置)动态调整。
## 管理员只有一个
多个管理员和冲突的规则会导致基础网络出现问题，多个 Kubernetes 管理员通过更改资源配置(如 Pod 资源限制)会导致进一步的问题，从而导致非预期的行为。使用 Kubernetes **基于角色的访问控制** ( **RBAC** )功能可以通过仅给予 Kubernetes 用户所需的权限(例如只读)来帮助解决这个问题。
## 运输成本为零
这种谬误有两种常见的解释方式。首先，传输的延迟成本为零——这显然是不真实的，因为有线数据传输的速度不是无限的，更低级别的网络问题会增加延迟。这基本上与*延迟为零*谬论产生的效果相同。
其次，这种说法可以解释为，为了运输的目的，创建和运营一个网络的成本是零——零美元零美分。虽然这显然是不真实的(只要看看您的云提供商的数据传输费用就能证明这一点)，但这并不特别对应于 Kubernetes 上的应用故障排除，因此我们将重点关注第一种解释。
## 网络是同质的
最后一个谬误与 Kubernetes 的组件关系不大，更多的是与运行在 Kubernetes 上的应用有关。然而，事实是，在当今环境中运行的开发人员非常清楚，应用联网可能在不同的应用中有不同的实现——从 HTTP 1 和 2 到 *gRPC* 等协议。
现在，我们已经回顾了 Kubernetes 上应用失败的一些主要原因，我们可以深入到对 Kubernetes 和运行在 Kubernetes 上的应用进行故障排除的实际过程中。
# Kubernetes 集群故障排除
由于 Kubernetes 是一个分布式系统，它被设计来容忍应用运行时的故障，大多数(但不是全部)问题都集中在控制平面和应用编程接口上。在大多数情况下，一个工作节点发生故障只会导致 Pods 被重新安排到另一个节点，尽管复合因素会带来问题。
为了浏览常见的 Kubernetes 集群问题场景，我们将使用案例研究方法。这将为您提供调查实际集群问题所需的所有工具。我们的第一个案例研究集中在 API 服务器本身的故障上。
重要说明
出于本教程的目的，我们将假设一个自我管理的集群。EKS、AKS 和 GKE 等托管 Kubernetes 服务通常会移除一些故障域(例如，通过自动缩放和管理主节点)。一个好的规则是首先检查您的托管服务文档，因为任何问题都可能是特定于实现的。
## 案例研究–KubernetesPODS 放置失败
让我们开始吧。您的集群已经启动并运行，但是您遇到了 Pod 调度问题。PODS 无限期地停留在`Pending`状态。让我们用以下命令来确认这一点:
```
kubectl get pods
```
该命令的输出如下:
```
NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-tj8ks        0/1       Pending   0          2d
app-1-pod-2821252345-9fj2k        0/1       Pending   0          2d
app-1-pod-2821252345-06hdj        0/1       Pending   0          2d
```
如我们所见，我们的 Pod 没有一个在运行。此外，我们正在运行该应用的三个副本，但没有一个得到安排。下一步是检查节点状态，看看是否有任何问题。运行以下命令获取输出:
```
kubectl get nodes
```
我们得到以下输出:
```
  NAME           STATUS     ROLES    AGE    VERSION
  node-01        NotReady      5m     v1.15.6
```
这个输出为我们提供了一些有用的信息——我们只有一个工作节点，它不可用于调度。当`get`命令没有给我们足够的信息通过时，`describe`通常是一个很好的下一步。
让我们运行`kubectl describe node node-01`并检查`conditions`键。为了将所有内容整齐地放在页面上，我们删除了一个栏，但最重要的栏在那里:
![Figure 10.1 – Describe Node Conditions output](img/B14790_10_001.jpg)
图 10.1–描述节点条件输出
我们这里有一个有趣的分裂:两个`MemoryPressure`和`DiskPressure`都很好，而`OutOfDisk`和`Ready`的条件是未知的，带有消息`kubelet stopped posting node status`。乍看之下，这似乎很荒谬——当 kubelet 停止工作时，`MemoryPressure`和`DiskPressure`怎么会没事呢？
重要部分在`LastTransitionTime`栏。kubelet 最近的内存和磁盘专用通信发送了肯定的状态。然后，在稍后的时间，库布雷停止发布其节点状态，导致`OutOfDisk`和`Ready`条件的`Unknown`状态。
在这一点上，我们确信我们的节点是问题所在 kubelet 不再向控制平面发送节点状态。然而，我们不知道为什么会出现这种情况。这可能是网络错误、机器本身的问题或更具体的问题。我们需要进一步挖掘才能弄清楚。
这里一个很好的下一步是更接近我们的故障节点，因为我们可以合理地假设它遇到了某种问题。如果你可以访问`node-01`虚拟机或机器，现在是 SSH 进入的好时机。一旦我们进入机器，让我们开始进一步排除故障。
首先，让我们检查节点是否可以通过网络访问控制平面。如果没有，这就是 kubelet 不能发布状态的明显原因。让我们假设一个场景，其中我们的集群控制平面(例如内部负载平衡器)在`10.231.0.1`可用。为了检查我们的节点是否可以访问 Kubernetes API 服务器，我们可以如下 ping 控制平面:
```
ping 10.231.0.1   
```
重要说明
为了找到控制平面 IP 或 DNS，请检查您的集群配置。在托管的 Kubernetes 服务中，如 AWS 弹性 Kubernetes 服务或 Azure AKS，这可能可以在控制台中查看。例如，如果您使用 kubeadm 引导自己的集群，这是您在安装过程中提供的一个值。
让我们检查结果:
```
Reply from 10.231.0.1: bytes=1500 time=28ms TTL=54
Reply from 10.231.0.1: bytes=1500 time=26ms TTL=54
Reply from 10.231.0.1: bytes=1500 time=27ms TTL=54
```
这证实了这一点——我们的节点确实可以与 Kubernetes 的控制平面对话。所以，网络不是问题。接下来，让我们检查实际的 kubelet 服务。节点本身似乎是可操作的，网络也很好，所以从逻辑上讲，kubelet 是下一个要检查的东西。
Kubernetes 组件在 Linux 节点上作为系统服务运行。
重要说明
在 Windows Nodes 上，故障排除说明会略有不同–有关更多信息，请参见 Kubernetes 文档([https://Kubernetes . io/docs/setup/production-environment/Windows/intro-Windows-in-Kubernetes/](https://kubernetes.io/docs/setup/production-environment/windows/intro-windows-in-kubernetes/))。
为了找出我们的`kubelet`服务的状态，我们可以运行以下命令:
```
systemctl status kubelet -l 
```
这为我们提供了以下输出:
```
 • kubelet.service - kubelet: The Kubernetes Node Agent
   Loaded: loaded (/lib/systemd/system/kubelet.service; enabled)
  Drop-In: /etc/systemd/system/kubelet.service.d
           └─10-kubeadm.conf
   Active: activating (auto-restart) (Result: exit-code) since Fri 2020-05-22 05:44:25 UTC; 3s ago
     Docs: http://kubernetes.io/docs/
  Process: 32315 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CADVISOR_ARGS $KUBELET_CERTIFICATE_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=1/FAILURE)
 Main PID: 32315 (code=exited, status=1/FAILURE)
```
看起来我们的 kubelet 当前没有运行，它因失败而退出。这解释了我们所看到的关于集群状态和 Pod 问题的一切。
要真正解决问题，我们可以首先尝试使用命令重启`kubelet`:
```
systemctl start kubelet
```
现在，让我们用状态命令重新检查我们的`kubelet`的状态:
```
 • kubelet.service - kubelet: The Kubernetes Node Agent
   Loaded: loaded (/lib/systemd/system/kubelet.service; enabled)
  Drop-In: /etc/systemd/system/kubelet.service.d
           └─10-kubeadm.conf
   Active: activating (auto-restart) (Result: exit-code) since Fri 2020-05-22 06:13:48 UTC; 10s ago
     Docs: http://kubernetes.io/docs/
  Process: 32007 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CADVISOR_ARGS $KUBELET_CERTIFICATE_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=1/FAILURE)
 Main PID: 32007 (code=exited, status=1/FAILURE)
```
看来`kubelet` 又失败了。我们需要获得一些关于故障模式的额外信息，以便找出发生了什么。
让我们使用`journalctl`命令找出是否有相关的日志:
```
sudo journalctl -u kubelet.service | grep "failed"
```
输出应该向我们显示发生故障的`kubelet`服务的日志:
```
May 22 04:19:16 nixos kubelet[1391]: F0522 04:19:16.83719    1287 server.go:262] failed to run Kubelet: Running with swap on is not supported, please disable swap! or set --fail-swap-on flag to false. /proc/swaps contained: [Filename                                Type                Size        Used        Priority /dev/sda1                               partition        6198732        0        -1]
```
看起来我们已经找到原因了——默认情况下，Kubernetes 不支持在`swap`设置为`on`的 Linux 机器上运行。我们在这里唯一的选择是要么禁用`swap`要么在`--fail-swap-on`标志设置为`false`的情况下重新启动`kubelet`。
在我们的例子中，我们将使用以下命令更改`swap`设置:
```
sudo swapoff -a
```
现在，重新启动`kubelet`服务:
```
sudo systemctl restart kubelet
```
最后，我们来看看我们的修复是否有效。使用以下命令检查节点:
```
kubectl get nodes 
```
这将显示类似于以下内容的输出:
```
  NAME           STATUS     ROLES    AGE    VERSION
  node-01        Ready         54m    v1.15.6
```
我们的节点终于发布了`Ready`状态！
让我们使用以下命令检查我们的 Pod:
```
kubectl get pods
```
这应该会显示如下输出:
```
NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-tj8ks        1/1       Running   0          1m
app-1-pod-2821252345-9fj2k        1/1       Running   0          1m
app-1-pod-2821252345-06hdj        1/1       Running   0          1m
```
成功！我们的集群是健康的，我们的 Pods 正在运行。
接下来，让我们看看一旦解决了任何集群问题，如何对 Kubernetes 上的应用进行故障排除。
# 对 Kubernetes 上的应用进行故障排除
一个完美运行的 Kubernetes 集群可能仍然有应用问题需要调试。这可能是由于应用本身的错误，或者是由于组成应用的 Kubernetes 资源的错误配置。与群集故障排除一样，我们将通过案例研究深入探讨这些概念。