speciﬁc optimization process on the target ALC system to
systematically generate the malicious dirty road patch P.
at the driver’s view(cid:98)Ia
t back using(cid:98)Ia
jecting(cid:98)V a
Step 3(cid:13)– 7(cid:13) are then iteratively applied to obtain(cid:98)Ia
ﬁltering is used to extract the model input X a
t
and vehicle state Sa
the steering angle decision τt, denoted as τt := ALC(X a
:= ROI((cid:98)Ia
t+1,(cid:98)Ia
DRP attack optimization problem formulation. We for-
t − So
t ,Sa
t )
t ,τa
t ) + εt
mulate the attack as the following optimization problem:
min L
t = ROI(BEV−1(T (Λ(Vt ,P),Sa
s.t. X a
τa
t = ALC(X a
Sa
t+1 = MM(Sa
1 = So
Sa
1
P = BLUR(FILL(B) + ∆)
∆ ∈ P
(1)
t ))) (t = 1, ...,T ) (2)
(t = 1, ...,T ) (3)
(t = 1, ...,T − 1) (4)
(5)
(6)
(7)
where the L in Eq. 1 is an objective function that aims at
deviating the victim out of the current lane boundaries as fast
as possible (detailed in §4.3.2). Eq. 2–5 have been described
in §4.2. In Eq. 6, the patch image P ∈ RH×W×C consists of a
base color B ∈ RC and the perturbation ∆ ∈ RH×W×C, where
W,H, and C are the patch image width, height, and the number
of color channels respectively. We select an asphalt-like color
as the base color B since the image is designed to mimic
a road patch. Function FILL: RC → RH×W×C ﬁlls B to the
entire patch image. Since we aim at generating perturbations
that mimic the normal dirty patterns on roads, we restrict ∆ to
be within a stealthy road pattern space P, which is detailed
in §4.3.3. We also include a noise term εt in Eq. 4 and an
1 , ...,X a
1 , ...,X a
image blurring function BLUR(·) in Eq. 6 to improve the
patch robustness to vehicle motion model inaccuracies and
camera image blurring, which are detailed in §4.3.4.
4.3.1 Optimization Process Overview
Fig. 5 shows an overview of our iterative optimization process
design. Given an initial patch image P, we obtain the model
input X a
T from the motion model based input gener-
ation process. In step (i), we calculate the gradients of the
objective function with respect to X a
T , and only keep
the gradients corresponding to the patch areas. In step (ii),
these gradients are projected into the BEV space. In step (iii),
we calculate the average BEV-space gradients weighted by
their corresponding patch area sizes in the model inputs. This
step involves an approximation of the gradient of BEV−1(·),
which are detailed in our extended version [38]. Next, in step
(iv), we update the current patch with Adam [54] using the
averaged gradient as the gradient of the patch image. In step
(v), we then project the updated patch into the stealthy road
pattern space P. This updated patch image is then fed back to
the motion model based input generation module, where we
also add robustness improvement such as motion noises and
image blurring. We terminate this process when the attack-
introduced lateral deviations obtained from the motion model
are large enough.
4.3.2 Lane-Bending Objective Function Design
As discussed in §4.1, directly using steering angle decisions
as L makes the objective function non-differentiable to
X a
1 , ...,X a
T . To address this, we design a novel lane-bending
objective function f (·) as a differentiable surrogate function.
In this design, our key insight is that at the design level, the
lateral control step aims at making steering angle decisions
that follows a desired driving path in the middle of the de-
tected left and right lane line curves from the lane detection
step (§2.1). Thus, changing the steering angle decisions is
equivalent to changing the derivatives of (or “bending”) such
desired driving path curve. This allows us to design f (·) as:
t )||p (8)
f (X a
j | j ≤ t},θ) + λ||Ωt (X a
∇ρt (d;{X a
1 , ...,X a
T ) =
T
∑
t=1
∑
d∈Dt
where ρt (d) is a parametric curve whose parameters are
decided by (1) both the current and previous model inputs
{X a
j | j ≤ t} due to frame inter-dependencies (§3.3), and (2)
the LD DNN parameters θ. Dt is a set of curve point index
d = 0,1,2, ... for the desired driving path curve at frame t.
λ is the weight of the p-norm regularization term, designed
for stealthiness (§4.3.3). We then can deﬁne L in Eq. 1 as
f (·) and − f (·) when attacking to the left and right. Fig. 6
illustrates this surrogate function when attacking to the left.
As shown, by maximizing ∇ρt (d) at each curve point in Eq. 8,
we can achieve a “lane bending” effect to the desired driv-
ing path curve. Since the direct LD output is lane line points
(§2.1) but ρt (·) require lane line curves, we further perform a
differentiable construction of curve ﬁtting process (detailed
in our extended version [38]).
3314    30th USENIX Security Symposium
USENIX Association
Figure 4: Motion model based input gen-
eration from original camera input.
4.3.3 Designs for Dirty Patch Stealthiness
To mimic real-world dirty patterns like in Fig. 2, we have 4
stealthiness designs in stealthy road pattern space P in Eq. 7:
Grayscale perturbation. Real-world dirty patterns on the
road are usually created by dust or white stains (Fig. 2), and
thus most commonly just appear white. Thus, we cannot allow
perturbations with arbitrary colors like prior works [5]. Thus,
our design restricts our perturbation ∆ in the grayscale (i.e.,
black-and-white) by only allowing increase the Y channel in
the YCbCr color space [55], denoted as ∆Y ≥ 0.
Preserving original lane line information. We preserve
the original lane line information by drawing the same lane
lines as the original ones on the patch (if covered by the
patch). Note that without this our attack can be easier to
succeed, but as discussed in §3.3, it is much more preferred
to preserve such information so that the attack deployment
can more easily appear as legitimate road work activities and
the deployed patch is less likely to be legitimately removed.
Brightness limits. While the dirty patterns are restricted
to grayscale, they are still the darker, the stealthier. Also, to
best preserve the original lane information, the brightness
of the dirty patterns should not be more than the original
lane lines. Thus, we (1) add the p-norm regularization term in
Eq. 8 to suppress the amount of ∆Y , and (2) restrict BY +∆Y <
LaneLineY , where BY and LaneLineY are Y channel values
for the base color and original lane line color respectively.
Perturbation area restriction. Besides brightness, also
the fewer patch areas are perturbed, the stealthier. Thus, we
deﬁne Perturbable Area Ratio (PAR) as the percentage of
pixels on P that can be perturbed. Thus, when PAR=30%,
70% pixels on P will only have the base color B.
4.3.4 Designs for Improving Attack Robustness, De-
ployability, and Physical-World Realizability
dresses the color and pattern distortions due to physical-world
factors such as lighting condition, printer color accuracy, and
camera color sensing capability. More details are in our ex-
tended version [38].
5 Attack Methodology Evaluation
In this section, we evaluate the effectiveness, robustness, gen-
erality, and realizability of our DRP attack methodology.
Targeted ALC system. In our evaluation, we perform ex-
periments on the production ALC system in OpenPilot [8],
which follows the state-of-the-art DNN-based ALC system
design (§2.1). OpenPilot is an open-source production Level-
2 driving automation system that can be easily installed in
over 80 popular vehicle models (e.g., Toyota, Cadillac, etc.)
by mounting a dashcam. We select OpenPilot due to its (1)
representativeness, since it is reported to have close perfor-
mance to Tesla Autopilot and GM Super Cruise and better
than many others [9], (2) practicality, from the large quantity
and diversity of vehicle models it can support [8], and (3)
ease to experiment with, since it is the only production ALC
system that is open sourced. In this paper, we mainly evaluate
on the lane detection model in OpenPilot v0.7.0, which is
released in Dec. 2019. More details of the OpenPilot ALC
system are in Appendix C.
Evaluation dataset. We perform experiments using the
comma2k19 dataset [56], which contains over 33 hours driv-
ing traces between California’s San Jose and San Francisco in
a Toyota RAV4 2017 driven by human drivers. These traces
are collected using the ofﬁcial OpenPilot dashcam device,
called EON. From this dataset, we manually look for short
free-ﬂow driving periods to make road patch placement con-
venient. In total, we obtain 40 eligible short driving clips,
10 seconds each, with half of them on the highway, and half
on local roads. For each driving clip, we consider two attack
scenarios: attack to the left, and to the right. Thus, in total we
evaluate 80 different attack scenarios.
5.1 Attack Effectiveness
Evaluation methodology and metrics. We evaluate the at-
tack effectiveness using the evaluation dataset described
above. For each attack scenario, we generate an attack road
Figure 5: Iterative optimization process design for our
optimization-based DRP generation.
Figure 6: “Lane bending” ef-
fect of our objective func-
tion by maximizing ∇ρ(d)
at each curve point.
We also have domain-speciﬁc designs for improving (1) at-
tack robustness, which addresses the driving trajectory/angle
deviations and camera sensing inaccuracies in real-world
attacks; (2) attack deployability, which designs an op-
tional multi-piece patch attack mode that allows deploying
DRP attack with multiple small and quickly-deployable road
patch pieces; and (3) physical-world realizability, which ad-
USENIX Association
30th USENIX Security Symposium    3315
(a) Original Camera input (𝑰𝒕)(b) Original BEV (𝑉𝑡)(c) Shifted 1 m to Right(d) Rot. 10°to Right (𝑉𝑡#)(e) Trans. Camera Input (𝐼𝑡%)ROI (LD Model Input) AreaLane-BendingObjFunc(  4.3.2)(i) Obtaingradients of 𝑓(⋅)by patch area (ii) Transform to BEV(iii) Average gradients(iv)Update patch+t=1t=T(v)Project to Stealthy Dirty Pattern Space     (§4.3.3) •Grayscale Perturbation•Preserve Lane Line•Brightness Limit•PerturbableArea𝑓(𝑋!",…,𝑋#") Robustness Improvement•Motion Noise•Image Blurring§…(vi) DeployabilityImprove. (optional)Motion ModelBased Input Generation (§4.2)Desired DrivingPath ρ(d)∇ρ(1)d=0d=1d=2∇ρ(2)Desired DrivingPath ρ’(d)d=0d=1d=2∇ρ’(1)∇ρ’(2)Detected Lane LineBent to LeftBenignFigure 8: Real-world dirty
road patterns.
Figure 7: Driver’s view at 2.5 sec (average driver reaction time to road hazards [57]) before our attack
succeeds under different stealthiness levels in local road scenarios. Inset ﬁgures are the zoomed-in
views of the malicious road patches. Larger images are in our extended version [38].
Figure 9: Stop sign hiding
and appearing attacks [5].
patch, and use the motion model based input generation
method in §4.2 to simulate the vehicle driving trajectory in-
ﬂuenced by the malicious road patch. To judge the attack
success, we use the attack goal deﬁned in §3.1 and concrete
metrics listed in Table 1, i.e., achieving over 0.735m and
0.285m lateral deviations on highway and local road scenar-
ios respectively within the average driver reaction, 2.5 sec.
We measure the achieved deviation by calculating the lateral
distances at each time point between the vehicle trajectories
with and without the attack, and use the earliest time point to
reach the required deviation to calculate the success time.
Since ALC systems assume a human driver who is prepared
to take over, it is better if the malicious road patch can also
look stealthy enough at 2.5 sec (driver reaction time) before
the attack succeeds so that the driver will not be alerted by
its looking and decide to take over. Thus, in this section,
we also study the stealthiness of the generated road patches.
Speciﬁcally, we quantify their perturbation degrees using the
average pixel value changes from the original road surface in
L1,L2 and Linf distances [58, 59] and also a user study.
Experimental setup. For each scenario in the evaluation
dataset, we manually mark the road patch placement area in
the BEV view of each camera frame based on the lane width
and shape. To achieve consistent road patch placements in
the world coordinate across a sequence of frames, we calcu-
late the number of pixels per meter in the BEV images and
adjust the patch position in each frame precisely based on
the driving trajectory changes across consecutive frames. The
road patch sizes we use are 5.4 m wide, and 24–36 m long
to ensure at least a few seconds of visible time at high speed.
The patches are placed 7 m far from the victim at the starting
frame. For stealthiness levels, we evaluate the L2 regularisa-
tion coefﬁcient λ = 10−2,10−3, and 10−4, with PAR set to
50%. According to Eq. 8, larger λ value means more sup-
pression of the perturbation, and thus should lead to a higher
stealthiness level. For the motion model, we directly use the
vehicle parameters (e.g., wheelbase) of Toyota RAV4 2017,
the vehicle model that collects the traces in our dataset.
Results. As shown in Table 2, our attack has high effective-
ness (≥97.5%) under all the 3 stealthiness levels. Fig. 7 shows
the malicious road patch appearances at different stealthiness
levels from the driver’s view at 2.5 seconds before our at-
Table 2: Attack success rate and time under different stealthi-
ness levels. Larger λ means stealthier. Average success time
is calculated only among the successful cases. Pixel L1, L2,
and Lin f are the average pixel value changes from the original
road surface in the RGB space and normalized to [0,1].
Stealth.
Level λ
10−2
10−3
10−4
Succ.
Rate
97.5%
100%
100%
Succ.
Time (s)
0.903
0.887
0.886
Pixel
L1
0.018
0.033
0.071
Pixel