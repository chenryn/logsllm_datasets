Identifying doppelgänger pairs
2.3.1
The ideal way to determine if a pair of identities is a doppel-
g¨anger pair would be to ask human workers if both identi-
ties portray the same user. Unfortunately, such an exercise
would be very expensive to scale to millions of potential
doppelg¨anger pairs. So we built an automated rule-based
matching scheme that is trained on human-annotated data
to determine when the proﬁle attributes of two identities
match suﬃciently for humans to believe that they portray
the same user.
More concretely, in the Twitter social network, every iden-
tity is associated with a set of proﬁle attributes, such as
user-name, screen-name, location, photo, and bio. We col-
lected pairs of identities with diﬀerent levels of proﬁle at-
tribute matching. Speciﬁcally, we collected three-levels of
matching proﬁle pairs: (i) Loosely matching identities: pairs
of identities that have similar user-name or screen-name;1
Starting from an initial set of Twitter proﬁles (see §2.4), we
discovered these identity pairs via the Twitter search API
that allows searching by names. (ii) Moderately matching
identities: pairs of identities that, in addition to sharing a
similar user-name or screen-name, also share one additional
similar proﬁle attribute be it location or photo or bio.2 In
practice, we found that location information is often very
coarse-grained, at the level of countries, so we deﬁned a
tighter matching scheme ignoring location information. (iii)
Tightly matching identities: pairs of identities that in ad-
dition to sharing a similar user-name or screen-name also
share similar photo or bio.
For each level of matching proﬁle pairs, we estimated the
fraction of proﬁle pairs that humans would believe as por-
traying the same user as follows: We selected between 50
to 250 pairs of matching proﬁles at each level and setup an
Amazon Mechanical Turk experiment, where we gave AMT
workers two links corresponding to the two Twitter accounts
and we asked them to choose between three options:
‘the
accounts portray the same person’, ‘the accounts do not por-
tray the same person’, or ‘cannot say’. For each assignment
we asked the opinion of three diﬀerent AMT workers and
only consider the majority agreement, i.e., when at least two
AMT workers choose the same answer.
We ﬁnd that, by majority agreement, AMT workers be-
lieve that 4% of loosely matching, 43% of moderately match-
ing, and 98% of tightly matching identity-pairs portray the
same user. Thus, by selecting a more conservative matching
scheme, we would increase precision (i.e., be more certain)
of detecting doppelg¨anger pairs. But, in the process, we
1Determining attribute similarity is a challenging task in
and of itself. There is a lot of prior work, including our own,
on this topic [10]. We summarize the relevant details in the
Appendix.
2Twitter accounts that do not have proﬁle information avail-
able such as bio, locations and photos will be automatically
excluded.
143would be sacriﬁcing recall – for instance, we found that the
tightly matching identity scheme captures only 65% of the
doppelg¨anger pairs caught by moderately matching identity
scheme. Since our goal is to correctly identify a large set
of impersonating attacks, even if it comes at the cost of not
identifying all possible impersonation attacks, we propose
to use the conservative tightly matching identity scheme to
detect doppelg¨anger pairs in Twitter.
Potential limitations: While our scheme represents a ﬁrst
step in the direction of scalable automated detection of dop-
pelg¨anger pairs in social networks like Twitter, currently,
we apply it only within a single social network. So we miss
opportunities to detect doppelg¨anger pairs across multiple
social networking sites, e.g., when an attacker copies a Face-
book user’s identity to created a doppelg¨anger Twitter iden-
tity. While our basic scheme could be extended to match
identities across sites, it is beyond the scope of this work.
2.3.2 Identifying victim-impersonator pairs
As discussed earlier, the ideal way to determine whether
a doppelg¨anger pair is a victim-impersonator pair requires
contacting the real oﬄine user represented by the identity
to inquire about the ownership of the identities. However,
this approach is infeasible in practice. When we attempted
this approach, our Twitter identity got quickly suspended
as indulging in potentially spam activity. So we instead rely
on a signal from Twitter, when it oﬃcially suspends one,
but not both, of the doppelg¨anger identities. We crawled
the doppelg¨anger identities periodically (once a week) over
an extended period of time (a three month period) to look
for identity suspensions. We treat the suspended identity of
the doppelg¨anger pair as the impersonating identity and the
other identity as the victim.
Our hypothesis is that at least some fraction of the im-
personating identities would be eventually detected and re-
ported to Twitter (either by the victim herself or some other
users that know the victim), which would result in Twitter
suspending the identity. One concern with our approach is
that we may be detecting impersonating attacks that are
being caught by some automated Twitter spam defense sys-
tem (as opposed to reports ﬁled by victims or other Twit-
ter users).
In this case, we would essentially be reverse-
engineering Twitter’s impersonation detection system rather
than study impersonation attacks in the wild. We address
this concern in §4.2, where we show that the analysis of
the impersonation attacks gathered using our methodology
can help us design new automated detectors that in turn
could be used to detect a large number of yet undiscovered
impersonation attacks in Twitter. Had the identities been
suspended by an automated impersonation detection frame-
work in Twitter, it is unlikely that we would have succeeded
in designing signiﬁcantly better performing detection sys-
tems.
Potential Limitations: Our victim-impersonator pair de-
tection strategy allows us to detect large numbers of such
pairs, but it likely captures only those impersonation attacks
that have been detected by Twitter’s reporting system. We
would be under-sampling clever attacks that have not yet
been detected.
2.3.3 Identifying avatar-avatar pairs
As discussed earlier, the ideal way to determine whether a
doppelg¨anger pair is avatar-avatar by contacting the owners
of the identities is unfeasible in practice. So we instead rely
on observing interactions between the doppelg¨anger iden-
tities that clearly indicate that each identity is aware of
the presence of the other identity. Speciﬁcally, we check
whether one of the doppelg¨anger identity follows or men-
tions or retweets the other doppelg¨anger identity. If it is the
case, it is very likely that the identities are managed by the
same user. Otherwise, the legitimate identity would have
reported the impersonating identity and have it suspended
by Twitter.
Potential Limitations: Our avatar-avatar pair detection
strategy under-samples scenarios where a user maintains
multiple identities but keeps them distinct, i.e., does not
link the identities and use them for very diﬀerent purposes.
However, we suspect that in such scenarios, users would
likely assume diﬀerent pseudonymous identities and would
avoid providing the same proﬁle information. Such identi-
ties would not be matched as doppelg¨anger identities in the
ﬁrst place.
2.4 Data gathered
In this section, we describe how we applied our above data
gathering strategy to collect information about real-world
impersonation attacks in the Twitter social network at scale.
We begin by selecting 1.4 million random Twitter ac-
counts – the initial accounts.3 We call the dataset we gen-
erate starting with these random Twitter accounts the Ran-
dom Dataset. For each account a in the Random Dataset,
we gather a set of up to 40 accounts in Twitter that have
the most similar names as the account (using the Twit-
ter search API). We call the resulting 27 million name-
matching identity-pairs initial accounts. From these pairs,
we identify doppelg¨anger pairs, victim-impersonator pairs,
and avatar-avatar pairs as described in §2.3. Table 1 sum-
marizes the dataset. Note that a signiﬁcant fraction of dop-
pelg¨anger identities are not labeled as either avatar-avatar
or victim-impersonator pairs.
While our strategy for detecting doppelg¨anger and avatar-
avatar pairs yielded sizable numbers, our strategy for detect-
ing victim-impersonator pairs proved quite time consuming.
It took a 3 months waiting time to discover 166 victim-
impersonator pairs amongst the 18,662 doppelg¨anger pairs
and few tens of identities keep getting suspended every pass-
ing week. To quickly identify more victim-impersonator
pairs, we resorted to a focussed crawl in the neighborhood of
the detected impersonating identities. Speciﬁcally, we con-
ducted a breadth ﬁrst search crawl on the followers of four
seed impersonating identities that we detected. Our intu-
ition is that we might ﬁnd other impersonating accounts in
the close network of an impersonating account.
We collected 142,000 accounts with the breadth ﬁrst search
crawl and we call the dataset generated from this biased set
of initial accounts the BFS Dataset. We repeated the same
analysis on the BFS Dataset that we conducted on Ran-
dom Dataset. We report the results in Table 1. In the same
amount of time, we discovered 16,408 victim-impersonator
pairs out of the 35,642 doppelg¨anger pairs, suggesting that
our focussed crawl succeeded in identifying a large number
of real-world impersonation attacks.
3Twitter assigns to every new account a numeric identity
that allows random sampling.
144Table 1: Datasets for studying impersonation attacks.
initial accounts
initial accounts
doppelg¨anger pairs
avatar-avatar pairs
victim-impersonator pairs
unlabeled pairs
Random Dataset
BFS Dataset
1.4 millions
27 millions
142,000
2.9 millions
18,662
2,010
166
16,486
35,642
1,629
16,408
17,605
For each Twitter identity in doppelg¨anger pairs, we use
the Twitter API to collect detailed information about a va-
riety of their features. They include features related to:
1. Proﬁle of the identity: We gather the data about the
identity’s user-name, screen-name, location, photo, and bio.
2. Activity of the identity: We gather data about the
creation date of the account, timestamp of the ﬁrst tweet,
timestamp of the last tweet, number of followings (the num-
ber of accounts a user follows), number of tweets posted,
number of retweets posted, number of tweets favorited and
number of mentions.
3. Reputation of the identity: We collect data about the
number of followers of an account, the number of expert lists
where the user appears and the klout score [16] as metrics
to measure the inﬂuence of an account. The klout score is
a widely used metric to measure the social inﬂuence of an
account.
3. CHARACTERIZING IMPERSONATION
ATTACKS
In this section, we analyze the datasets we collected to char-
acterize identity impersonation attacks in Twitter. We be-
gin by investigating the diﬀerent types of impersonation at-
tacks found in our Random Dataset. Our analysis reveals
the prevalence of a new type of impersonation attack that
we call doppelg¨anger bot attack. We then explore the
features of doppelg¨anger bot attacks and the potential for
detecting such attacks.
3.1 Classifying impersonation attacks
Based on conventional wisdom and anecdotal evidence, we
were expecting to discover two types of impersonation at-
tacks in our Random Dataset: (i) Celebrity impersonation
attacks, where attackers impersonate celebrities and popu-
lar Twitter users to either post untrustworthy information
maligning the celebrity’s reputation or take advantage of the
celebrities’ oﬄine popularity to increase the visibility of their
own posts (e.g., product promotions) or (ii) Social engineer-
ing attacks also known as identity theft attacks, where the
attacker creates a fake account that clones the information of
a victim account and then uses the fake account to connect
and communicate with the victim’s friends [5]. The ultimate
goal here is to launch phishing attacks to harvest sensitive
information about the victim or to trick the victim’s friends
into sending money to the attacker (that claims to be the
victim).
We attempted to map the 166 victim-impersonator pairs
in our dataset to these two types of attacks.
In the pro-
cess, we discovered that many of the victim-impersonators
pairs corresponded to a small number of victims. Speciﬁ-
cally, there were 6 diﬀerent Twitter victims that in total ac-
counted for half (83) of the victim-impersonator pairs. One
hypothesis is that these six victims discovered multiple fake
identities that were impersonating them and reported all
such identities, leading them to be detected in our method-
ology. To avoid over-sampling these identities in our dataset,
we only consider one pair of victim-impersonating identities
for each of the 6 victims, which reduces our dataset to 89
victim-impersonator pairs.
3.1.1 Celebrity impersonation attacks
Twitter allows users to create accounts that are fan pages of
celebrities, however, users have to speciﬁcally declare this in
their bios. Our method to collect data about impersonation
attacks in the previous section is consistent with Twitter’s
terms of service. If the fan account mentions or interacts in
any way with the celebrity, it will be identiﬁed as an avatar,
and if not, it will be identiﬁed as impersonator.
To identify celebrity impersonation attacks we simply check
for victim-impersonator pairs where the victim is either a
veriﬁed Twitter account 4 or has a popular following amongst
Twitter users, i.e., it has more than 1000 or 10,000 follow-
ers.5 Out of the 89 victim-impersonator pairs, we found only
three are celebrity impersonation attacks out of which one
is a impersonator of a football player and one of a journal-
ist. In fact, 70 of the 89 victims have less than 300 followers,
suggesting that most victims of impersonation in our dataset
are not highly popular celebrities.
3.1.2
While it is impossible to exactly know the intentions of the
attacker, we could attempt to infer if an impersonating iden-
tity is attempting to launch a social engineering attack, by
exploiting the observation that attackers try to contact the
friends of the victims. So we select all victim-impersonator
pairs where the impersonating account had any interaction
with users that know the victim account, i.e., the imper-
sonating account is friend of, follows, mentions or retweets
people that are friends of or follow the victim account.
Social engineering attacks
Our hypothesis is that it is unlikely that accounts that
do not fall in the candidate set would try to mount social
engineering attacks since they do not show any intent of