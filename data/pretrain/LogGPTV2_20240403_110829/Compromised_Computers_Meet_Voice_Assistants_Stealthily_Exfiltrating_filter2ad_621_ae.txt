mission. Night Ambience means a night am-
bience sound audio was playing near Amazon
Echo Plus.
Fig. 8. Transmission Accuracy Results
s
r
e
t
c
a
r
a
h
C
r
o
r
r
E
 40
 35
 30
 25
 20
 15
 10
 5
 0
15 kHz
18 kHz
20 kHz
0
25
50
75
100
Distance (inch)
(f) The number of errors after decoding for
different distances when transmitting 40 char-
acters. Tone length is 50 ms.
with an 18 kHz carrier, we can obtain good accuracy while the
audio being nearly unnoticeable. If the distance is too far to
obtain acceptable accuracy, the carrier only needs to be set to
15 kHz. With 15 kHz carrier, close to 100% accuracy can be
achieved, while it does leak some noticeable frequencies. In
this case, we could only hear some faint sounds when the audio
was played when the our ear was right next to the computer
speaker. No noticeable sounds were heard a few feet away
from the computer. This is consistent with the past research
that shows that frequencies above 15 kHz can only be heard
when the sound volume is high [36].
Noise: As expected, the introduction of noise close to the
VA has a negative impact on data transmission. As can be
seen in Figure 8e, introduction of night ambient noise has
signiﬁcant impact on the transmission accuracy when 18 or 20
kHz carrier frequencies are used. In contrast, minimal impact
is observed for 15 kHz carrier even when the distance between
the computer and the VA is several feet.
Error Correction: We performed data decoding both with
and without error correction. When the tone length is ﬁxed to
50 ms, no noise is added, and distance is varied from from 0
inch to 100 inches, the results are shown in Figure 8b. When
distance is 0 inch, there are no error in characters decoded
from received audio. However, when distance is increased to
25 inches, there are errors due to bit ﬂips. All of these errors
can be handled by error correction. We also varied the tone
length from 12 ms to 50 ms, with no added noise, ﬁxing the
distance at 0 inch. As shown in Figure 8c, when tone length is
12 ms, too many bit ﬂips lead to errors both when correction is
and is not performed. In contrast, tone length of 16 ms shows
about 50% fewer errors with error correction. There are no
errors when tone length is 50 ms and accuracy is nearly 100%
in both cases. Since errors do occur at certain distances and
tone lengths, we use error correction despite the fact that it
halves the transfer rate.
Summary: Our experiments demonstrate the feasibility of
data exﬁltration via a VA even when it is several feet away
from a compromised computer. This can be done even when
humans are close to the computer or VA because most people
are unable to hear frequencies higher than 15 kHz. Based on
our results, we can see that when error correction is used,
9000 bits can be transmitted by a ﬁve minute phone call to
a remote endpoint with very high accuracy. This can be done
when a 18 kHz carrier is used to make the audio completely
unnoticeable and the distance between the computer and the
VA is over six feet. Although this bit rate of 30 bits/s is
sufﬁcient for transmitting passwords, account numbers and
other limited amount of sensitive information with few errors
even at 100 inches of distance, we can further increase the bit
rate to 75 bits/s by reducing the tone length to 20 ms with
an acceptable accuracy as shown in Figure 8a. As expected,
noise and distance both reduce the accuracy of transmission.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:24:17 UTC from IEEE Xplore.  Restrictions apply. 
528
VII. DISCUSSION
In this section, we brieﬂy discuss the feasibility of stealthy
attacks. We then suggest possible defenses against data ex-
ﬁltration via VAs and their efﬁcacy. We also discuss some
limitations of the system developed by us.
A. Feasibility of Stealthy Attacks
We use carrier frequency between 15 kHz to 20 kHz based
on existing research about human hearing. It is known that hu-
mans cannot hear sound above 20 kHz. However, the hearing
range decreases as people age [8]. In [27], experiments show
that frequencies above 15 kHz mixed with other sounds are
not noticeable by listeners. For an adult, to achieve minimum
audibility of a 18 kHz sound in close vicinity, volume greater
than 80 dB is required, which is typically the noise level of a
gas-powered lawnmower [11]. Normal computer speakers are
not able to produce such high level of sound. Therefore, the
audio generated and played on victim’s computer will unlikely
to be heard by adults. As we can see from the experiments,
a 15 kHz carrier can deliver message with a range close to
100 inches. When higher stealthiness is required, a 18 kHz
carrier can be used with somewhat lower accuracy. Thus, with
high carrier frequencies, it is feasible to launch attacks while
ensuring inaudibility for most adults in close vicinity.
B. Defenses
Phone calls typically are made by users whereas data exﬁl-
tration by a VA requires the audio to originate from a computer
speaker. For commands to VAs, liveness detection techniques
have been developed. For example, it is demonstrated in [4]
that certain characteristic frequencies are present in audio that
comes from a speaker which are not present when an audio
source is a live person. These frequencies are low (< 200
Hz) and will not be transmitted by the telephony channel.
Hence, defense based on such frequency detection has to
be deployed at the VA. However, there may be legitimate
cases when a call source is a computer like a conferencing
application running on a computer may command a VA to
reach certain participants with a phone call. Also, future AI
based applications running on a computer may use VAs in
a conversation with remote parties that are reached via the
phone (e.g., Google Duplex [14]). Again, a liveness detection
defense cannot always be used. Another possibility is to use
voice biometric such as speaker veriﬁcation. However, our
experiments found that to avoid false negatives in the presence
of noise, VAs are permissive and could be targeted at scale
using techniques like master voice prints [23].
Defenses against malware or compromised applications that
abuse computer speakers can also be deployed on the computer
where sensitive data is stored. These include access control for
speakers and monitoring of audio stream going to the speakers.
For example, an audio stream that consists of DTMF tones
only, could raise an alarm. However, this could be evaded by
using frequencies other than DTMF. Since a VA must send
the audio stream to the cloud, another possible defense is to
examine the audio stream for possible anomalies. A variety
of audio stenography techniques have been investigated in the
literature and their use may evade such defenses.
C. Limitations
We demonstrated that an infected computer can command
a VA to set up a phone call
that can transmit sixty bits
per second. Such a rate may not be sufﬁcient to achieve
massive data transfer or large scale data dumps. For example,
a call lasting ten minutes can only exﬁltrate approximately
2.5K bytes of data at this rate. Also, the audio may not be
completely inaudible to all people when a carrier lower than 20
kHz is used. In particular, young children may be able to hear
some sounds when they are very close to the computer or the
VA. This may raise an alert. However, achieving completely
inaudible audio transmission for everyone for large volumes
of data over the voiceband of a telephony call is a problem
that has not been fully addressed by this paper. The channel
between the targeted computer and the attacker is one-way, as
it is not possible for the attacker to send inaudible commands
through the phone channel and VA due to the frequency limit
of 3400 Hz. Thus, the malware running on a victim computer
cannot receive feedback to adjust its transmission. Finally, we
use the phone call feature of Amazon Echo. Although this
feature is useful and likely be provided by VAs, it is possible
that in the future calls are only allowed to certain phone
numbers (e.g., those in a contact list). In this case, an attacker
would have gain access to the voice mail of an allowed phone
number or ﬁnd a way to get a phone number controlled by it
to the contact list. This is not addressed by us.
VIII. CONCLUSIONS AND FUTURE WORK
As voice assistants become common in the same physical
areas as computers,
they could create a new channel for
data exﬁltration. In particular, malware infected computers can
bypass normal network and host defenses by using the voice
assistant and the phone channel to send sensitive data to an
attacker controlled computer. We demonstrated that modest
amount of data can be exﬁltrated by encoding the data in
audio and transmitting it via a voice assistant initiated phone
call that lasts only a few minutes. By using techniques such
as modulation with very high frequency carriers, it is possible
to send the audio from the computer to the voice assistant in a
way that it is unlikely to be noticed by a person who may be
in the vicinity of these devices. These attacks are of concern
because they can be mounted from anywhere, at scale and at
low cost.
In the future, we plan to explore if the transmission of data
such as text can be made more efﬁcient when it is sent over the
voiceband of a telephony channel. Malware may also be able
to use computer speakers to discover if there is a VA near the
computer and its distance which can be used to improve attack
efﬁcacy. We brieﬂy discussed a number of defenses that may
be possible against data exﬁltration via voice assistants but
their efﬁcacy is unclear. Also, detection and defenses against
malware that may use the audio channel between the computer
and voice assistants need to be investigated.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:24:17 UTC from IEEE Xplore.  Restrictions apply. 
529
REFERENCES
[1] H. Abdullah, W. Garcia, C. Peeters, P. Traynor, K. R. B. Butler, and
J. Wilson, “Practical Hidden Voice Attacks against Speech and Speaker
Recognition Systems,” in Network and Distributed System Security
Symposium. Reston, VA: Internet Society, Dec. 2018, pp. 1–15.
[2] R. Battista, C. Morrison, and D. Nash, “Signaling system and receiver for
touch-tone calling,” Transactions of the American Institute of Electrical
Engineers, Part I: Communication and Electronics, vol. 82, no. 1, pp.
9–17, 1963.
[3] M. K. Bispham, I. Agraﬁotis, and M. Goldsmith, “Attack and defence
modelling for attacks via the speech interface,” 2019.
[4] L. Blue, L. Vargas, and P. Traynor, “Hello, is it me you’re looking
for?: Differentiating between human and electronic speakers for voice
interface security,” in Proceedings of the 11th ACM Conference on
Security & Privacy in Wireless and Mobile Networks. ACM, 2018,
pp. 123–133.
[5] N. Carlini, P. Mishra, T. Vaidya, Y. Zhang, M. Sherr, C. Shields,
D. Wagner, and W. Zhou, “Hidden voice commands,” in 25th USENIX
Security Symposium (USENIX Security 16), 2016, pp. 513–530.
[6] N. Carlini and D. Wagner, “Audio adversarial examples: Targeted attacks
on speech-to-text,” in 2018 IEEE Security and Privacy Workshops
(SPW).
IEEE, 2018, pp. 1–7.
[7] U. CERT, “Malware threats and mitigation strategies,” Multi-State
Information Sharing and Analysis Center and US Computer Readiness
Team, 2005.
[8] “High
frequency
https://decibelhearing.com/
hearing-loss-overview/high-frequency-hearing-loss/, Decibel Hearing
Services, 2020.
hearing
loss,”
[9] L. Deshotels, “Inaudible sound as a covert channel in mobile devices,” in
8th USENIX Workshop on Offensive Technologies (WOOT 14), 2014.
[10] W. Diao, X. Liu, Z. Zhou, and K. Zhang, “Your voice assistant is mine:
How to abuse speakers to steal information and control your phone,”
in Proceedings of the 4th ACM Workshop on Security and Privacy in
Smartphones & Mobile Devices, 2014, pp. 63–74.
[11] J. D. Durrant and J. H. Lovrinic, “Bases of hearing science: 3rd,” 1995.
[12] M. Egele, T. Scholte, E. Kirda, and C. Kruegel, “A survey on automated
dynamic malware-analysis techniques and tools,” ACM computing
surveys (CSUR), vol. 44, no. 2, p. 6, 2012.
[13] M. D. Fletcher, S. Lloyd Jones, P. R. White, C. N. Dolder, T. G.
Leighton, and B. Lineton, “Effects of very high-frequency sound and
ultrasound on humans. part ii: A double-blind randomized provocation
study of inaudible 20-khz ultrasound,” The Journal of the Acoustical
Society of America, vol. 144, no. 4, pp. 2521–2531, 2018.
[14] “Make reservations with the google assistant,” https://support.google.
com/assistant/answer/9183712?co=GENIE.Platform\%3DAndroid&hl=
en, Google, 2019.
[15] M. Guri, Y. Solewicz, A. Daidakulov, and Y. Elovici, “Acoustic data
exﬁltration from speakerless air-gapped computers via covert hard-
drive noise (‘diskﬁltration’),” in European Symposium on Research in
Computer Security. Springer, 2017, pp. 98–115.
[16] M. Hanspach and M. Goetz, “On covert acoustical mesh networks in
air,” Journal of Communications, vol. 8, no. 11, 2013.
[17] R. Iijima, S. Minami, Y. Zhou, T. Takehisa, T. Takahashi, Y. Oikawa, and
T. Mori, “Audio hotspot attack: An attack on voice assistance systems
using directional sound beams and its feasibility,” IEEE Transactions on
Emerging Topics in Computing, 2019.
[18] Y. Jang, C. Song, S. P. Chung, T. Wang, and W. Lee, “A11y attacks:
Exploiting accessibility in operating systems,” in Proceedings of the
2014 ACM SIGSAC Conference on Computer and Communications
Security, 2014, pp. 103–115.
[19] P. G. Kannan, S. P. Venkatagiri, M. C. Chan, A. L. Ananda, and L.-
S. Peh, “Low cost crowd counting using audio tones,” in Proceedings
of the 10th ACM Conference on Embedded Network Sensor Systems.
ACM, 2012, pp. 155–168.
[20] D. Kumar, R. Paccagnella, P. Murley, E. Hennenfent, J. Mason, A. Bates,
and M. Bailey, “Skill squatting attacks on amazon alexa,” in 27th
USENIX Security Symposium (USENIX Security 18), 2018, pp. 33–
47.
[21] H. Lee, T. H. Kim, J. W. Choi, and S. Choi, “Chirp signal-based aerial
acoustic communication for smart devices,” in 2015 IEEE Conference on
Computer Communications (INFOCOM).
IEEE, 2015, pp. 2407–2415.
than
been
[22] A. Madhavapeddy, R. Sharp, D. Scott, and A. Tse, “Audio networking:
the forgotten wireless technology,” IEEE Pervasive Computing, vol. 4,
no. 3, pp. 55–60, 2005.
[23] M. Marras, P. Korus, N. D. Memon, and G. Fenu, “Adversarial opti-
mization for dictionary attacks on speaker veriﬁcation.” in Interspeech,
2019, pp. 2913–2917.
[24] A. Mason, “Terminology for loudness and level,” 2011.
[25] L. Matney,
100
devices
have
https://techcrunch.com/2019/01/04/
more-than-100-million-alexa-devices-have-been-sold/, Tech Crunch,
2019.
million
“More
sold,”
alexa
[26] R. Nandakumar, K. K. Chintalapudi, V. Padmanabhan, and R. Venkate-
san, “Dhwani: secure peer-to-peer acoustic nfc,” in ACM SIGCOMM
Computer Communication Review, vol. 43, no. 4. ACM, 2013, pp.
63–74.
[27] T. Oohashi, E. Nishina, M. Honda, Y. Yonekura, Y. Fuwamoto,
N. Kawai, T. Maekawa, S. Nakamura, H. Fukuyama, and H. Shibasaki,
“Inaudible high-frequency sounds affect brain activity: hypersonic ef-
fect,” Journal of neurophysiology, 2000.
[28] A. V. Oppenheim and R. W. Schafer, Discrete-time signal processing.
[29] “Sound theory,” https://www.iso.org/standard/34222.html, owyheesound,
Pearson Education, 2014.
2008.
[30] Y. Qin, N. Carlini, G. Cottrell, I. Goodfellow, and C. Raffel, “Imper-
ceptible, robust, and targeted adversarial examples for automatic speech
recognition,” in International Conference on Machine Learning, 2019,
pp. 5231–5240.
[31] B. Reaves, L. Blue, and P. Traynor, “Authloop: End-to-end cryptographic
authentication for telephony over voice channels,” in 25th USENIX
Security Symposium (USENIX Security 16), 2016, pp. 963–978.
[32] ——, “Authloop: End-to-end cryptographic authentication for telephony
over voice channels,” in 25th USENIX Security Symposium (USENIX
Security 16), 2016, pp. 963–978.
[33] V. U. Reddy, “Voice-band modem: A device to transmit data over
telephone networks,” Resonance, vol. 6, no. 6, pp. 60–70, 2001.
[34] N. Roy, S. Shen, H. Hassanieh, and R. R. Choudhury, “Inaudible
voice commands: The long-range attack and defense,” in 15th USENIX
Symposium on Networked Systems Design and Implementation (NSDI
18), 2018, pp. 547–560.
[35] L. Sch¨onherr, K. Kohls, S. Zeiler, T. Holz, and D. Kolossa, “Adversarial
attacks against automatic speech recognition systems via psychoacoustic
hiding,” arXiv preprint arXiv:1808.05665, 2018.
[36] Y. Suzuki, K. Ozawa, and H. Takeshima, “Precise and full-range
determination of two-dimensional equal loudness contours research,”
2003.
[37] T. M. Thompson, From error-correcting codes through sphere packings
to simple groups. Cambridge University Press, 1983, no. 21.
[38] C. Yan, G. Zhang, X. Ji, T. Zhang, T. Zhang, and W. Xu, “The
feasibility of injecting inaudible voice commands to voice assistants,”
IEEE Transactions on Dependable and Secure Computing, 2019.
[39] Q. Yan, K. Liu, Q. Zhou, H. Guo, and N. Zhang, “SurﬁngAttack: Interac-
tive Hidden Attack on Voice Assistants Using Ultrasonic Guided Waves,”
in Network and Distributed System Security Symposium. Reston, VA:
Internet Society, Feb. 2020, pp. 1–18.
[40] X. Yuan, Y. Chen, Y. Zhao, Y. Long, X. Liu, K. Chen, S. Zhang,
H. Huang, X. Wang, and C. A. Gunter, “Commandersong: A systematic
approach for practical adversarial voice recognition,” in 27th USENIX
Security Symposium (USENIX Security 18), 2018, pp. 49–64.
[41] G. Zhang, C. Yan, X. Ji, T. Zhang, T. Zhang, and W. Xu, “Dolphinattack:
Inaudible voice commands,” in Proceedings of the 2017 ACM SIGSAC
Conference on Computer and Communications Security, 2017, pp. 103–
117.
[42] M. Zhou, Z. Qin, X. Lin, S. Hu, Q. Wang, and K. Ren, “Hidden voice
commands: Attacks and defenses on the vcs of autonomous driving
cars,” IEEE Wireless Communications, 2019.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:24:17 UTC from IEEE Xplore.  Restrictions apply. 
530