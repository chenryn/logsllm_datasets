testcase. From an exploitation perspective, a small vulnerability test-
case (VUT) ideally triggers the bug and crashes the target process
in a deterministic way, given that this allows an easier investiga-
tion. A VUT is sometimes also called a crashing input. Based on the
vulnerability type and the affected browser component, there might
already be signs of attacker control. These include bogus register
values or memory content usually provoking the crash. Hence, we
define a VUT to be a user-controlled input which provides a first
and basic control point in the program flow (i. e., CPU registers or
memory contains attacker-controlled content). Our approach starts
with a VUT that provides a control point (also called control source).
This is the beginning of our automation approach.
3) Preparing attacker memory. Before an attacker exercises
the vulnerability via the VUT, she usually prepares regions of mem-
ory which enable an illegitimate action with the bug later on. This
is, for instance, the case for spatial memory errors such as buffer
overflows. An attacker may utilize the browsers scripting engine to
create and place specific JS objects after an object with the buffer
overflow vulnerability on the heap [26]. This serves the purpose of
overwriting the specific object once the bug is triggered. Similarly,
freed memory regions may be reclaimed by attacker-controlled
objects to support temporal memory errors such as use-after-free
bugs [18]. As soon as the vulnerability is triggered, the attacker
operates on the prepared object with the dangling pointer. An-
other bug-class which may need prepared memory is the usage
of uninitialized variables. If the attacker manages to fill the stack
with controlled values, e.g., via stack spraying [16, 23], the unini-
tialized variables are filled with controlled values when the bug
triggers. This extends attacker control beyond the initial control
point. Generally speaking, preparing of attacker memory happens
302ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
B. Garmany et al.
Usually, searching and finding a desired exploitation primitive,
analyzing the corresponding program path, and crafting the data
fields correctly is a cumbersome process, as this is mostly performed
manually and such program paths may consist of many basic blocks.
Our aim is to fully automate all parts of this step, as we explain
in § 3.
5) Finalizing the exploit. Usually after an EPT executed, the
attacker has a higher level of control within the browser process,
either because she has overwritten a security flag and is able to run
high-privileged JS [22], or is performing arbitrary computations
via code-reuse techniques after gaining EIP control. Both are pos-
sible means to exploit a vulnerability in the OS kernel to further
escalate privileges. However, we consider this step as future work
and currently out of scope.
3 DESIGN
In the following, we describe the design and overall architecture
of our approach towards automating and assisting the process of
exploitation in browsers as implemented by PrimGen. An overview
of the architecture is shown in Figure 1. Our prototype is split into
two main phases consisting of several components.
1) Preprocessing. Since we operate on the whole target binary,
our first step is to reconstruct the CFG of each function using off-the-
shelf binary frameworks. Each function is then lifted into an inter-
mediate language (IL) which is, according to its CFG, transformed
into static single assignment (SSA) form. Finally, we collect data
such as function entries, register uses/definitions, memory read-
s/writes, and control-flow information. Furthermore, PrimGen is
able to incorporate trace/control-flow and memory information ob-
tained with dynamic analysis (debugger or tracer). This is achieved
by executing the target program with the VUT in a debugger hav-
ing a breakpoint set at the control point. Hence, a dynamic trace
and memory dump is extracted as soon as the breakpoint is hit. All
information is collected into fact instances that are written into a
knowledge base for postprocessing.
2) Postprocessing. We use a Datalog-based approach to follow
a path of controlled data beyond the control point. This can be seen
as a lightweight static taint analysis. After having determined the
locations of a control point, we start the analysis to find reachable
sinks; based on this information, we form a graph that describes
the flow of control from one basic block to another. With this graph
in place, paths to our intended sinks are symbolically executed and
filtered beforehand if they are not solvable. The remaining paths
lead us to potential exploit primitives and data needs to be crafted
to reach them. In this step, all constraints related to controlled data
are collected and used to build memory maps; these maps provide
an overview on how the objects need to be crafted. Using a memory
dump that is acquired at the time where the control point is hit, we
verify every satisfiable path that has a memory map attached. This
is achieved in a platform-agnostic manner. The process can also be
seen as an additional filtering layer. Finally, given a template (e.g.,
a VUT with a basic heap spray, see § 2.1), our prototype generates
scripts to be fed into the browser (EPT).
Depending on the binary (note that browsers are huge), the first
phase might take up to several hours. Therefore, we extract only
those functions in the binary that are reachable by the control point.
If the analysis reaches a point where further functions are needed,
they are added to the database on demand.
Running Example. During our evaluation of CVE-2016-9079,
a use-after-free in Firefox 50.0.1, our tool generated an input fol-
lowing a path to an indirect call. We think that this specific case
is complex, yet easy enough to clarify the concepts of this work.
Figure 2 illustrates our running example which we constantly refer
to throughout this paper. The figure shows three illustrations which
we cover in the course of the next sections. For now, consider the
assembly code along a path generated by PrimGen. The code runs
from the control point at 0x107a00d4 into an indirect call sink at
0x101c0cb8. The value in ecx at 0x107a00d7 is the memory region
that the attacker controls through a JS object. The interested reader
finds the VUT code leading to the control point in Listings 2 and 3
in Appendix A. It is based on code of the corresponding Mozilla
Bug Report [37].
Datalog. The use of Datalog allows us to express analyses in
a highly declarative manner. Datalog, in its essence, is a query
language based on the logic paradigm. A logic program consists
of facts and rules. Facts describe certain assertions about a closed
world, which, in our case, is a binary application. Facts and rules
are represented as Horn clauses of the form:
P0 : − P1, . . . , Pn
where Pi is a literal of the form p(x1, . . . , xk) such that p is a
predicate and the xj are terms. Each term can be a variable or a
constant. The left hand side of the clause is called head; the right
hand side is called body. A clause is true when each of its literals
in the body are true. A clause can also have an empty body which
makes it a fact.
Conventional Datalog programs distinguish between IDB and
EDB predicates. EDB (extensional database) embodies a collection
of a-priori facts, e.g., those facts that we extract from the binary
and which are listed in Table 1. We also call these EDB predicates
input relations, since they build up the base and are fed into Data-
log before any analysis code runs. IDB (intensional database) are
those predicates that are defined by rules. Rules are basically de-
duced facts of those that are known in the closed world. These
deduced facts again build up the basis for new facts to be deduced.
Datalog programs operate until they are saturated with facts, i.e.,
no new facts are found and a fixpoint is reached. Many program
analyses are based on fixpoint algorithms which utilize worklist
arrangements [3]. With Datalog, we overcome the design of these
arrangements. For a thorough introduction into this field, we refer
the reader to papers by Smaragdakis et al. [33, 34].
3.1 Knowledge Base
The knowledge base is part of PrimGens preprocessing step. Once
the IL is transformed into SSA, we extract properties of interest
into fact databases. For instance, a CallTo fact represents every
call instruction. In Datalog terms, it is expressed by:
CallTo(callee_ctx, callee_entry, section callsite, context_caller).
303Towards Automated Generation of Exploitation Primitives for Web Browsers
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Figure 2: Running example: Path generated from a control point at 0x107a00d4 into an indirect call sink. On the left side, the
assembly code is shown which is executed along the path into the sink at 0x101c0cb8. The arrows indicate the mapping to a
controlled memory region. Each generated path is associated with a memory map. All offsets are relative to the base address.
Each memory map is transformed into a tree structure.
Similarly, there are properties of interest that describe load and
store operations which we express through facts and store them
into their corresponding fact database. Basically each fact database
summarizes the property of interest for each function. All fact
databases together form our knowledge base for the binary. For
brevity, we present a fraction of facts in Table 1, which are used in
our code snippets.
The term context in Table 1 refers to the corresponding name of
the function which is prefixed by “sub” and its entry point address,
when no symbols are present. We utilize so called SSA-maps, an
abstract environment that encapsulates the IL instructions in SSA
form for each basic block. Each IL instruction has an order in these
maps similar to the order of instructions in the basic block. With
address, we, therefore, refer to the basic block address and the
order of the IL expression in the SSA-map. In this manner, we can
precisely identify each expression. We cover the basic functionality
of these maps in § 4.
All of our algorithms operate on the same set of facts stored in
the knowledge base and by defining rules, new facts are deduced
which gives us new insight about properties of interest. Each newly
deduced fact is added to the knowledge base and is transparently
adapted by other algorithms that operate on these facts.
3.2 Propagating Control
With our knowledge base set, we run our Datalog code to search
for specific sinks. These sinks can be seen as enforced taint policies;
we use the term control akin to the idea of a taint. We therefore
use these terms interchangeably. The whole procedure can be seen
as a lightweight static taint analysis as we do not utilize a mem-
ory model. We rather approximate a taint analysis by our Datalog
algorithms. Recall that Datalog is used to conveniently overcome
the complex design of worklist arrangements used in fixpoint algo-
rithms. Another convenient benefit we gain is flexibility. By adding
a new fact to the knowledge base, all algorithms that operate on
the same facts transparently adapt to it. New facts can be added
by a human expert or an algorithm that gives new insight into the
state space of controlled data. To compensate the lack of a mem-
ory model we use an on demand field-,flow-,and context-sensitive
points-to analysis that shares and operates on the same set of facts.
The points-to analysis is needed in some cases where we run into
aliasing issues as we discuss in § 5.2.
Control/Taint is statically propagated from the control point in a
straightforward manner. Whenever a controlled expression, tagged
as a use, is assigned to a register or stored into memory, we collect
that memory or register expression into a set of controlled expres-
sions. For memory, we propagate control if either the memory cell
value or the memory address (base + disp) is controlled.
In Datalog terms this process is achieved by an IDB predicate.
Rules that specify this predicate deduce new facts and the engine
continues until it reaches a fixpoint. In this state the engine can
not derive any new facts until new information is delivered, i.e.,
an unseen fact is added to the knowledge base. The final set of
facts under the IDB predicate summarizes the set of controlled
IL instructions. These IL instructions can be mapped back to their
assembly instructions to pinpoint affected instructions in the binary.
We express the flow of control with the following IDB predicate
that describes the information flow from one expression to another:
Controlled(r eд, {−1, disp}, {′R ′
,
′D ′}, addr , context)
The term reg refers to the deduced register name. The second
term in the predicate can either be −1 or a displacement, depending
304ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
B. Garmany et al.
Table 1: Datalog Input Relations (EDB facts).
CallTo(callee, calleeEntry, section, callsite, caller)
Memory({store,load}, opndType, opndID, disp, addr, context)
Register(id, reg, {d,u}, size, addr, context)
IndCall(id, opndType, opndId, addr, context)
Scope(reg, regSSA, addr, context)
Param(paramID, n, reg, disp, “Stack”, callsite, callerContext)
Describes the interprocedural control-flow from caller to callee.
Describes store and load instructions where opndType can either be a
constant, a register or an equation.
Describes the use or the definition of a register in any expression,
annotated as ’u’ or ’d’ respectively. If a register is used in a memory
expression which is defined, we annotate that register with ’d’ as well.
Describes an indirect call. The type of the operand can either be a
register or a memory expression.
Mapping from a register name to its subscripted register name in SSA
form at a given address.
Describes a stack parameter being passed from a caller context. The
variables reg and disp are unified with the corresponding stack pointer
expression and its displacement. Variable n describes the nth parameter.
on whether the deduced register name is part of a dereference at a
specific address described by the terms addr and context. The third
term can either be ’R’ or ’D’, indicating that we control the register
itself or the value being stored at reg + disp. We express it as
follows as a rule:
Controlled(r eд, −1,
′R ′
, addr , context) : −
mov_rr(c_r eд, r eд, addr , context),
Controlled(c_r eд, −1,
, _, context).
′R ′
This recursive rule says that if a controlled register c_reg is
moved to a register reg, then we control reg. Apparently, a new
fact is deduced which again is used by Datalog to deduce new facts
until a fixpoint is reached. mov_rr is a rule that deduces register
to register moves based on the facts.
Similar to this fashion, we embed all facts for memory move-
ments deduced by their rules into a body of a new Controlled rule.
Interprocedural Propagation. Whenever a controlled variable
flows into a stack parameter, we map the stack expression into the
context of the callee and continue propagating. The following rules
clarify this approach for a parameter pass on x86:
′Stack ′
ControlParam(par amI D, calleeCT X , num,
, _, callerCT X),
′Stack ′
′
.text ′
Controlled(r eд, disp,
Param(par amI D, num, r eд, disp,
CallTo(calleeCT X , calleeEntry,
, callsite , callerCT X),
, callsite , callerCT X).
, callerCT X) : −
′D ′
′D ′
Controlled(r eд, disp,
, calleeEntry, calleeCT X) : −
′Stack ′
ControlParam(par amI D, calleeCT X , num,
Param(par amI D, num, _, _, callsite , f romCT X),
Map(num, r eд, disp, calleeCT X),
CallTo(calleeCT X , calleeEntry,
.text ′
′
, callsite , callerCT X).
, callerCT X),
The first rule states that if we control a value at the memory
location reд + disp, and that location happens to be a parameter
through a stack push, then we have control over the parameter
value that flows from the caller context into the callee context. The
second rule says that if we control a parameter, then we need to
know which stack register and displacement corresponds to that
parameter in the callee context. This is achieved by the Map rule.
The last fact delivers the entry point in the callee context. The
whole rule sets the stage for further propagation of controlled data
in the callee context. If a register is used in a context B that has
no SSA subscription, we know that this register is not defined in
context B at that specific moment. These registers are candidates for
parameters and we refer to them as pass through registers. In order
to track the flow of control into pass through registers, we utilize
Scope facts as described in Table 1. These facts help us to determine
the subscription, i.e., the live definition of a register at the call site
of a context A which calls B. In this manner, we get a mapping of
register expressions between different function invocations.
3.3 Finding Sinks
With our Controlled rules in place, we can define rules to query
for our sinks. We are interested in sinks that have the characteristics
of a WrW / WWW, and EIP primitive. The following simplified rule
shows how we can express an instruction pointer (IP) control:
IPControl(r eд, bb, addr , ctx) : −
IndCall(_, addr , ctx),
Memory(′load ′
′Reд ′
Register(r eдI D, r eд,