sample this random number to simulate the trace.
It turns out that the above example reﬂects the essence of
what is needed to implement oblivious RAM and oblivious
data structures in our source language. We refer the readers to
Sections IV and V-B for details.
Function calls and phantom functions. A straightforward
idea to prevent stack behavior from leaking information is
to enforce function calls in a public context. Then the re-
quirement is that each function’s body must satisfy memory-
and instruction-trace obliviousness. Further, by deﬁning native
functions, ObliVM-lang implicitly assumes that their imple-
mentations satisfy memory- and instruction-trace oblivious-
ness.
Beyond this basic idea, ObliVM-lang makes a step forward
to enabling function calls within a secret
if-statement by
introducing the notion of phantom function. The idea is that
each function can be executed in dual modes, a real mode
and and a phantom mode. In the real mode, all statements are
executed normal with real computation and real side effects.
In the phantom mode, the function execution merely simulates
the memory traces of the real world; no side effects take place;
and the phantom function call returns a secret-shared default
value of the speciﬁed return type. This is similar to padding
ideas used in several previous works [43], [44].
We will illustrate the use of phantom function with the
following prefixSum example. The function prefixSum(n)
accesses a global integer array a, and computes the preﬁx
sum of the ﬁrst n + 1 elements in a. After accessing each
element (Line 3), the element in array a will be set to 0 (Line
4).
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:02 UTC from IEEE Xplore.  Restrictions apply. 
(public int32 n) {
phantom secure int32 prefixSum
secure int32 ret=a[n];
a[n]=0;
if (n != 0) ret = ret+prefixSum(n-1);
return ret;
1
2
3
4
5
6
7
The keyword phantom indicates that the function prefixSum
is a phantom function.
}
Consider the following code to call the phantom functions:
if (s) then x = prefixSum(n);
To ensure security, prefixSum will always be called no
matter s is true or false. When s is false, however, it must be
guaranteed that (1) elements in array a will not be assigned
to be 0; and (2) the function generates traces with the same
probability as when s is true. To this end, the compiler will
generate target code with the following signature:
prefixSum(idx, indicator)
where indicator means whether the function will be called
in the real or phantom mode. To achieve the ﬁrst goal, the
global variable will be modiﬁed only if indicator is false.
The compiler will compile the code in line 4 into the following
pseudo-code:
a[idx]=mux(0, a[idx], indicator);
It is easy to see, that all instructions will be executed, and
thus the generated traces are identical regardless of the value
of indicator. Note, that such a function is not implementable
in any prior loop-unrolling based compiler, since n is provided
at runtime only.
It
is worth noticing that phantom function relaxed the
restriction posed by previous memory trace oblivious type
systems [31], which do not allow looping in the secure
context (i.e. within a secret conditional). The main difﬁculty
in previous systems was to quantify the numbers of loop
iterations in the two branches of an if-statement, and to enforce
the two numbers to be the same. Phantom functions remove
the need of this analysis by executing both branches, with one
branched really executed, and the other executed phantomly.
As long as an adversary is unable to distinguish between a
real execution from a phantom one, the secret guard of the
if-statement will not be leaked, even when loops are virtually
present (i.e. in a phantom function).
IV. USER-FACING OBLIVIOUS PROGRAMMING
ABSTRACTIONS
such as MapReduce
Programming abstractions
and
GraphLab have been popularized in the parallel computing
domain. In particular, programs written for a traditional se-
quential programming paradigm are difﬁcult
to parallelize
automatically by an optimizing compiler. These new paradigms
are not only easy for users to understand and program with,
but also provide insights on the structure of the problem, and
facilitate parallelization in an automated manner.
In this section, we would like to take a similar approach
towards oblivious programming as well. The idea is to de-
velop oblivious programming abstractions that can be easily
365
understood and consumed by non-specialist programmers, and
our compiler can compile programs into efﬁcient oblivious
algorithms. In comparison, if these programs were written
in a traditional imperative-style programming language like
C, compile-time optimizations would have been much more
limited.
A. MapReduce Programming Abstractions
An interesting observation is that “parallelism facilitates
obliviousness” [45], [46]. If a program (or part of a program)
can be efﬁciently expressed in parallel programming paradigms
such as MapReduce and GraphLab [47], [48] (with a few
additional constraints), there is an efﬁcient oblivious algorithm
to compute this task. We stress that in this paper, we con-
sider MapReduce merely as a programming abstraction that
facilitates obliviousness – in reality we compile MapReduce
programs to sequential implementations that runs on a single
thread. Parallelizing the algorithms is outside the scope of this
paper. However, in a subsequent work GraphSC [24] jointly
with our collaborators, we do offer parallel oblivious imple-
mentations of programs written in a GraphLab abstraction –
and doing so requires the design of new, non-trivial parallel
oblivious algorithms detailed in the GraphSC paper [24].
Background: Oblivious algorithms for streaming MapRe-
duce. A streaming MapReduce program consists of two basic
operations, map and reduce.
• The map operation:
takes an array denoted {αi}i∈[n]
where each αi ∈ D for some domain D, and a func-
tion mapper : D → K × V. Now map would apply
(ki, vi) := mapper(αi) to each αi, and output an array
of key-value pairs {(ki, vi)}i∈[n].
• The reduce operation: takes in an array of key-value
pairs denoted {(ki, vi)}i∈[n] and a function reducer :
K × V 2 → V. For every unique key k value in this array,
let (k, vi1 ), (k, vi2 ), . . . (k, vim ) denote all occurrences
with the key k. Now the reduce operation applies the
following operation in a streaming fashion:
Rk := reducer(k, . . . reducer(k, reducer(k, vi1 ,
vi2 ), vi3 ), . . . , vim)
The result of the reduce operation is an array consisting
of a pair (k, Rk) for every unique k value in the input
array.
Goodrich and Mitzenmacher [45] observe that any program
written in a streaming MapReduce abstraction can be converted
to efﬁcient oblivious algorithms, and they leverage this obser-
vation to aid the construction of an ORAM scheme.
done by making a linear scan over the input array.
• The map operation is inherently oblivious, and can be
• The reduce operation can be made oblivious through an
oblivious sorting (denoted o-sort) primitive.
◦ First, o-sort the input array in ascending order of the
key, such that all pairs with the same key are grouped
together.
in a single linear scan, apply the reducer
function: i) If this is the last key-value pair for some
key k, write down the result of the aggregation (k, Rk).
ii) Else, write down a dummy entry ⊥.
◦ Next,
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:02 UTC from IEEE Xplore.  Restrictions apply. 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
Pair[public n] MapReduce@m@n
(I[public m] data,
Pair map(I),
V reduce(K, V, V), V initialVal,
int2 cmp(K, K)) {
public int32 i;
Pair[public m] d2;
for (i=0; i(d2, 1, cmp);
K key = d2[0].k;
V val = initialVal;
Pair>[public m] res;
for (i=0; i+1>
(res, 1, zeroOneCmp);
Pair[public n] top;
for (i=0; i  y) r = 1;
return r;
}
Pair mapper(int32 x) {
return Pair(x, 1);
}
int32 reducer(int32 k, int32 v1, int32 v2) {
return v1 + v2;
}
The top-level program can launch the computation using
c = MapReduce@m@n
(a, mapper, reducer, cmp, 0);
B. Programming Abstractions for Data Structures
We now explain how to provide programming abstractions
for a class of pointer-based oblivious data structures described
by Wang et al. [26]. Figure 2b gives an example, where an
expert programmer provides library support for implementing a
class of pointer-based data structures such that a non-specialist
programmer can implement data structures which will be
compiled to efﬁcient oblivious algorithms that outperform
generic ORAM. We stress that while we give a stack example
for simplicity, this paradigm is also applicable to other pointer-
based data structures, such as AVL tree, heap, and queue.
366
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:02 UTC from IEEE Xplore.  Restrictions apply. 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
struct StackNode@m {
Pointer@m next;
T data;
};
struct Stack@m {
Pointer@m top;
SecStore@m store;
};
phantom void PI:EMAIL(T data) {
StackNode@m node = StackNode@m (
top, data);
this.top = this.store.allocate();
store.add(top.(index, pos), node);
}
phantom T PI:EMAIL() {
StackNode@m res = store
.readAndRemove(top.(index, pos));
top = res.next;
return res.data;
}
1
2
3
4
5
6
7
8
9
10