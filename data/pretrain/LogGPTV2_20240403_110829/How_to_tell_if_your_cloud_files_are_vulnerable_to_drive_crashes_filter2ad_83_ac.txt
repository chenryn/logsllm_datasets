for later, more sophisticated RAFTs.
We consider the following problem instance:
Client model: Unkeyed and layout-speciﬁed.
Adversarial model: The server is cheap-and-lazy.
Drive model: Time to read a block of ﬁxed length ℓ from disk is
constant and denoted by τℓ.
Network model: The latency between client and server (denoted
L) is constant in time and network bandwidth is unlimited.
4.1 Scheme Description
Our RAFT construction encodes the entire m-block ﬁle F with
an erasure code that tolerates a certain fraction of block losses. The
server then spreads the encoded ﬁle blocks evenly over c drives and
speciﬁes a layout. To determine that the server respects this layout,
the client requests c blocks of the ﬁle in a challenge, one from each
drive. The server should be able to access the blocks in parallel
from c drives, and respond to a query in time close to τℓ + L.
If the server answers most queries correctly and promptly, then
blocks are spread out on disks almost evenly. A rigorous formal-
ization of this idea leads to a bound on the fraction of ﬁle blocks
that are stored on any t server drives. If the parameters of the era-
sure code are chosen to tolerate that amount of data loss, then the
scheme is resilient against t drive failures.
To give a formal deﬁnition of the construction, we use a max-
imum distance separable (MDS), i.e., optimal erasure code with
encoding and decoding algorithms (ECEnc, ECDec) and expan-
sion rate 1 + α. ECEnc encodes m-block messages into n-block
codewords, with n = m(1 + α). ECDec can recover the original
message given any αm erasures in the codeword.
The scheme is the following:
• Keygen(1ℓ) outputs φ.
• Encode(κ, F = {fi}m
i=1, t, c) outputs G = {gi}n
i=1 with n
• Verify(G, Q, R, T ) performs two checks. First, it checks
correctness of blocks returned in R using the ﬁle stored lo-
cally by the client6. Second, the client also checks the prompt-
ness of the reply.
If the server replies within an interval
τℓ + L, the client outputs 1.
• Reconstruct(κ, r, {g∗
i=1) outputs the decoding of the ﬁle
blocks retained by S (after a possible drive failure) under the
erasure code: ECDec({g∗
i=1) for r ≥ m, and ⊥ if r < m.
i }r
i }r
The security analysis of the protocol is deferred to the full ver-
sion of the paper [5]. Here we summarize the main result.
THEOREM 1. For ﬁxed system parameters c, t and α such that
α ≥ t/(c − t) and for constant network latency and constant
block read time, the protocol satisﬁes the following properties for a
cheap-and-lazy server S:
1. The protocol is complete: CompRAFT (t)(m, ℓ, t) = 1.
2. If S uses d < c drives, AdvRAFT (t)
3. If S uses d ≥ c drives, AdvRAFT (t)
where B(c, t, α) = α(c−t)−t
(m, ℓ, t) = 0.
(m, ℓ, t) ≤ 1 − B(c, t, α)
S
(1+α)(c−t) .
S
Multiple-step protocols.
We can make use of standard probability ampliﬁcation techniques
to further reduce the advantage of a server. For example, we can
run multiple steps of the protocol. A step for the client involves
sending a c-block challenge, and receiving and verifying the server
response. We need to ensure that queried blocks are different in all
steps, so that the server cannot reuse the result of a previous step in
successfully answering a query.
We deﬁne two queries Q and Q′ to be non-overlapping if Q ∩
Q′ = ∅. To ensure that queries are non-overlapping, the client
running an instance of a multiple-step protocol maintains state and
issues only queries with block indices not used in previous query
steps. We can easily extend the proof of Theorem 1 (3) to show that
a q-step protocol with non-overlapping queries satisﬁes
AdvRAFT (t)
d ≥ c drives.
(m, ℓ, t) ≤ (1 − B(c, t, α))q for a server S using
S
5. NETWORK AND DRIVE TIMING MODEL
In the simple model of Section 4, we assume constant network
latency between the client and server and a constant block-read
time. Consequently, for a given query Q, the response time of the
server (whether honest or adversarial) is deterministic.
In prac-
tice, though, network latencies and block read times are variable.
In this section, we present experiments and protocol-design tech-
niques that can be used to adapt our simple RAFT protocol to more
practical settings.
a multiple of c and G = ECEnc(F ).
5.1 Network model
• Map(n, t, c) outputs a balanced placement {Cj}c
j=1, with
j=1Cj = {1, . . . , n}, so conse-
|Cj| = n/c. In addition ∪c
quently Ci ∩ Cj = φ, ∀i 6= j.
• Challenge(n, G, t, c) outputs Q = {i1, . . . , ic} consisting
of c block indices, each ij chosen uniformly at random from
Cj , for j ∈ {1, . . . , c}. (Here, we omit nonce ν.)
• Response(Q) outputs the response R consisting of the c ﬁle
blocks speciﬁed by Q, and the timing T measured by the
client.
We present some experimental data on network latency between
hosts in different geographical locations based on the Lumezanu
et al. study [24], and quantify the amount of variance it exhibits
over time. We discuss how our RAFT protocol can be made robust
against variability in network latency. We also show how to reduce
the communication complexity of our protocol—thereby eliminat-
ing network-timing variance due to ﬂuctuations in network band-
width.
6Recall we assume a copy of the ﬁle is kept by the client to simplify
veriﬁcation, though this is not necessary.
506Network latency model.
Lumezanu et al. [24] present a study that measures the network
latency between 1715 pairs of hosts at various time intervals within
a two month period. Their goal is to study the occurrence and char-
acteristics of triangle inequality violations in the Internet. In one
of their experiments, they measure the variability of network la-
tency among pairs of hosts over time. Their ﬁndings indicate that
for about 88% of host pairs in their trace, the standard deviation of
network latency is less than 100ms. Another metric of variability
is the inter-quartile range of the latency distribution (deﬁned as the
difference between 75th and 25th percentiles). They show that less
than 10% of the host pairs have inter-quartile higher than 40ms,
suggesting that the variance in network latency is caused by out-
liers farther away from the mean, rather than values closer to the
mean.
For our purposes, we are interested in estimating the maximum
difference between round-trip times observed at various times be-
tween the same pair of hosts. While the study does not give us
directly an estimate for this metric, we can approximate the 99th
percentile of the difference, for instance, by three standard devia-
tions, i.e., 300ms (which for the normal distribution cover 99.7%
of the distribution).
To validate this choice of parameters, we perform our own small-
scale experiments. We pinged two hosts (one in Santa Clara, CA,
USA and one in Shanghai, China) from our Boston, MA, USA lo-
cation during a one week interval in March 2010. We observed that
the ping time distribution is heavy tailed with spikes correlated in
time, most likely due to temporary network congestion.
The ping times to Santa Clara ranged from 86 ms to 463 ms,
with 90th, 99th and 99.9th percentiles at 88ms, 95ms and 102ms,
respectively. Ping times to Shanghai exhibit more variability across
the larger geographical distance and range between 262 ms and 724
ms. While daily spikes in latency raise the average slightly, 90% of
readings are still less than 278 ms. These spikes materially lengthen
the tail of the distribution, however, as the 99% (433 ms) and 99.9%
(530 ms) thresholds are no longer grouped near the 90% mark, but
are instead much more spread out. To summarize, the 99th per-
centile of the difference in network latency is 9 ms for Santa Clara
and 171 ms for Shanghai. The 99.9th percentile results in 16ms
for Santa Clara, and 268ms for Shanghai. We believe therefore
that a choice of three standard deviations (300ms) is a reasonable
maximum variability in network latency we can set in our RAFT
experiments.
In our RAFT protocol, we consider a response valid if it arrives
within the maximum characterized network latency. We then adopt
the bounding assumption that the difference between minimum and
maximum network latency is “free time” for an adversarial server.
That is, during a period of low latency, the adversary might simulate
high latency, using the delay to cheat by prefetching ﬁle blocks
from disk into cache. This strategy would help the server respond
to subsequent protocol queries faster, and help conceal poor ﬁle-
block placement. If the amount of data which can be read during
this “free time” is small compared to the size of the ﬁle, the effect
is insigniﬁcant. We quantify this precisely in the full version of the
paper [5].
Limited network bandwidth.
In the basic protocol from Section 4, challenged blocks are re-
turned to the client as part of the server’s response. To minimize
the bandwidth used in the protocol, the server can simply apply a
cryptographically strong hash to its response blocks together with
a nonce supplied by the client, and return the resulting digest. The
client can still verify the response, by recomputing the hash value
locally and comparing it with the response received from the server.
5.2 Drive model
We now look to build a model for the timing characteristics of
magnetic hard drives. While block read times exhibit high variabil-
ity due to both physical factors and prefetching mechanisms, we
show that for a judicious choice of block size (64KB on a typical
drive), read times adhere to a stable probability distribution. This
observation yields a practical drive model for RAFT.
Drive characteristics.
Magnetic hard drives are complex mechanical devices consisting
of multiple platters rotating on a central spindle at speeds of up to
15,000 RPM for high-end drives today. The data is written and read
from each platter with the help of a disk head sensing magnetic
ﬂux variation on the platter’s surface. Each platter stores data in
a series of concentric circles, called tracks, divided further into a
set of ﬁxed-size (512 byte) sectors. Outer tracks store more sectors
than inner tracks, and have higher associated data transfer rates.
To read or write to a particular disk sector, the drive must ﬁrst
perform a seek, meaning that it positions the head on the right track
and sector within the track. Disk manufacturers report average seek
times on the order of 2 ms to 15 ms in today’s drives. Actual
seek times, however, are highly dependent on patterns of disk head
movement. For instance, to read ﬁle blocks laid out in sequence on
disk, only one seek is required: That for the sector associated with
the ﬁrst block; subsequent reads involve minimal head movement.
In constrast, random block accesses incur a highly variable seek
time, a fact we exploit for our RAFT construction.
After the head is positioned over the desired sector, the data is
read from the platter. The data transfer rate (or throughput) de-
pends on several factors, but is on the order of 300MB per sec-
ond for high-end drives. The disk controller maintains an internal
cache and implements complex caching and prefetching policies.
As drive manufacturers give no clear speciﬁcations of these poli-
cies, it is difﬁcult to build general data access models for drives [30].
The numbers we present in this paper are derived from experi-
ments performed on a number of enterprise class SAS drives, all
connected to a single machine running Red Hat Enterprise Linux
WS v5.3 x86_64. We experimented with drives from Fujitsu, Hi-
tachi, HP7, and Seagate. Complete speciﬁcations for each drive can
be found in Table 1.
Modeling disk-access time.
Our basic RAFT protocol is designed for blocks of ﬁxed-size,
and assumes that block read time is constant.
In reality, though
block read times are highly variable, and depend on both physical
ﬁle layout and drive-read history. Two complications are particu-
larly salient: (1) Throughput is highly dependent on the absolute
physical position of ﬁle blocks on disk; in fact, outer tracks exhibit
up to 30% higher transfer rates than inner tracks [29] and (2) The
transfer rate for a series of ﬁle blocks depends upon their relative
position; reading of sequentially positioned ﬁle blocks requires no
seek, and is hence much faster than for scattered blocks.
We are able, however, to eliminate both of these sources of read-
time variation from our RAFT protocol. The key idea is to render
seek time the dominant factor in a block access time. We accom-
plish this in two ways: (1) We read small blocks, so that seek time
7Upon further inspection, the HP drive is actually manufactured by
Seagate. Nearly all drives available today are in fact made by one
of three manufacturers.
507Manufacturer Model
Capacity Buffer Size Avg. Seek / Full Stroke Seek Latency
Throughput
Hitachi
Seagate
Fujitsu
HP
HUS153014VLS300
ST3146356SS
MBA3073RC
ST3300657SS
147 GB
146 GB
73.5 GB
300 GB
16 MB
16 MB
16 MB
16 MB
3.4 ms./ 6.5 ms.
3.4 ms./6.43 ms.
3.4 ms./8.0 ms.
3.4 ms./6.6 ms.
2.0 ms.
2.0 ms.
2.0 ms.
2.0 ms.
72 - 123 MB/sec
112 - 171 MB/sec
188 MB/sec
122 - 204 MB/sec
Table 1: Drive speciﬁcations
Read Time Distributions
(with 99.9% cutoffs)
Fujitsu HP
Seagate
HP
Seagate
Hitachi
Fujitsu
y
t
i
l
i
b
a
b
o
r
P
 0.1
 0.08
 0.06
 0.04
 0.02
 0
2
4
6
8
10
12
14
16
18
20
Time (ms)
Figure 2: Read time distribution for 64KB blocks
dominates read time and (2) We access a random pattern of ﬁle
blocks, to force the drive to perform a seek of comparable difﬁ-
culty for each block.
Time to Read 50 Random Samples
HP
Seagate
Hitachi
Fujitsu
)
s