datasets. The information is presented as an area plot, where the
distribution for each dataset is plotted as surface of a different color
(i.e., seeds day 1, in blue; real day 2, in red; synthetics, in yellow).
The areas are overlayed on top of one another. Therefore, the distance
between the distribution of two datasets is represented by their non-
overlapping area. For example, the yellow and orange regions repre-
sent areas where the synthetics’ distribution is either non-overlapping
(yellow) or overlaps with the real day 2 dataset’s distribution, but
not with seeds (day 1) dataset. The majority of the colored area is a
region where the real and synthetics distributions overlap (i.e., purple
region). This indicates a high-level of preservation.
distribution for the real and synthetic datasets. Table III shows
the KL-divergence of the real (seed, day 1) dataset to the
synthetic datasets and baselines: real (testing, day 2) dataset;
uniform time allocation (each user spends 1/k proportion of
time at each of the k locations); random time allocation (each
user spends a uniformly random proportion of time at the
location). To visualize those results further, Figure 12 shows
the distribution across all 30 users (for each dataset) for the
most popular location (only). The statistic is highly preserved
in the synthetic traces; sometimes the synthetics’ distribution
is closer to that of the real (seed, day 1) dataset, than the
distribution of the real (testing, day 2) dataset is.
(e) Spatiotemporal mobility features. When constructing
mobility models from location data (4), the overall geographic
and temporal behavior of users’ mobility is used.
To evaluate this, we compare the basic mobility statistics
obtained from the real and synthetic datasets. We compute
the aggregate mobility model for each synthetic dataset, and
compare its geographic similarity with the real (seeds, day 1)
dataset. More precisely, for a synthetic dataset F, we compute
(cid:5)¯pF , ¯πF(cid:6) and compute its similarity to (cid:5)¯p, ¯π(cid:6). The statistical
similarity of ¯pF with ¯p over all synthetic datasets is
[0.8061 (average),
0.8073 (median),
0.0060 (std)],
561561
and the results for the statistical similarity of ¯πF with ¯π is
[0.7856 (average),
0.7867 (median),
0.0152 (std)].
Both these results show a strong correlation between aver-
age/aggregate mobility information of real and fake datasets.
(f) Semantic mobility features.
In contrast to other appli-
cations, identifying areas for new businesses, i.e., task (5)
explicitly takes into account semantic features of the input
location data. Speciﬁcally,
takes into account visits to
semantically similar venues and transitions between different
types of venues. Consequently, it is meaningful to measure
the extent to which semantic features of a real dataset are
preserved in a released fake dataset.
it
To evaluate this, we proceed in two steps. We ﬁrst compute
the semantic similarity of each synthetic trace with its own
seed trace to check if the semantic features of the original
traces are indeed preserved. Figure 8 illustrates the distribution
of this value over all fake traces. Clearly, the distribution is
biased towards higher similarity values. So, the fake traces
considerably preserve the semantic features of the real traces.
In the second step, we look at whether the set of synthetic
traces preserves the inner similarity between the set of traces.
In Figure 9, we present the correlation between two distri-
butions: semantic similarity among real traces, and semantic
similarity among synthetic traces. The Q-Q plot shows a
signiﬁcant correlation between these two distributions; they
are strongly linearly related. This reﬂects that in addition to
maintaining the information about each seed, we also preserve
the statistical relation among the traces.
Overall, the statistics we have identiﬁed are largely pre-
served in the synthetic datasets. Thus, we conclude that our
technique is suitable for the aforementioned geo-data analysis
tasks and those that rely primarily on similar features.
IX. CONCLUSIONS
This is the ﬁrst paper to systematically generate plausi-
ble synthetic location traces based on quantitative metrics.
We propose statistical dissimilarity and plausible deniability
as privacy requirements for synthesizing location traces. By
enforcing these requirements, synthetic traces would not leak
information about real traces from which they are generated
more than what they have in common with any random real
trace. Through extensive privacy and utility evaluations, we
show the application of our mechanism in two mainstream
scenarios: protecting the location privacy of users in LBSs, and
geo-data analysis on synthetic location data. Our synthesized
traces can be of extreme help in protecting location privacy of
LBS users with very low utility cost. We show that inference
attacks cannot identify the true location of mobile users if
our fake traces are used as protection. We also quantitatively
show that our method is superior to all existing methods
of generating fake traces. Our synthetic traces also preserve
useful features of real traces and can be useful in ﬁve popular
geo-data analysis tasks.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:09:44 UTC from IEEE Xplore.  Restrictions apply. 
REFERENCES
[1] G. Acs and C. Castelluccia, “A case study: Privacy preserving release
of spatio-temporal density in paris,” in Proceedings of the 20th ACM
SIGKDD International Conference on Knowledge Discovery and Data
Mining, ser. KDD ’14. New York, NY, USA: ACM, 2014, pp. 1679–
1688. [Online]. Available: http://doi.acm.org/10.1145/2623330.2623361
[2] G. Acs, C. Castelluccia, and R. Chen, “Differentially private histogram
publishing through lossy compression,” in Data Mining (ICDM), 2012
IEEE 12th International Conference on.
IEEE, 2012, pp. 1–10.
[3] M. E. Andr´es, N. E. Bordenabe, K. Chatzikokolakis, and C. Palamidessi,
“Geo-indistinguishability: Differential privacy for location-based sys-
tems,” in Proceedings of the 2013 ACM SIGSAC conference on Com-
puter & communications security. ACM, 2013, pp. 901–914.
[4] C. A. Ardagna, M. Cremonini, S. De Capitani di Vimercati, and
P. Samarati, “An obfuscation-based approach for protecting location
privacy,” Dependable and Secure Computing, IEEE Transactions on,
vol. 8, no. 1, pp. 13–27, 2011.
[5] O. Berthold and H. Langos, “Dummy trafﬁc against long term intersec-
tion attacks,” in Privacy Enhancing Technologies. Springer, 2003, pp.
110–128.
[6] V. Bindschaedler
Shokri,
“Tool:
Plausible
generator.”
[Online].
privacy-
Available:
preserving
https://vbinds.ch/projects/sglt
location
and R.
trace
[7] N. E. Bordenabe, K. Chatzikokolakis, and C. Palamidessi, “Optimal geo-
indistinguishable mechanisms for location privacy,” in Proceedings of
the 2014 ACM SIGSAC Conference on Computer and Communications
Security. ACM, 2014, pp. 251–262.
[8] S. Brooks and B. Morgan, “Optimization using simulated annealing,”
The Statistician, pp. 241–257, 1995.
[9] R. Chen, G. Acs, and C. Castelluccia, “Differentially private sequential
data publication via variable-length n-grams,” in Proceedings of the 2012
ACM conference on Computer and communications security. ACM,
2012, pp. 638–649.
[10] R. Chow and P. Golle, “Faking contextual data for fun, proﬁt, and
privacy,” in WPES ’09: Proceedings of the 8th ACM workshop on
Privacy in the electronic society. New York, NY, USA: ACM, 2009,
pp. 105–108.
[11] T. M. Cover and J. A. Thomas, Elements of information theory.
John
Wiley & Sons, 1994.
[12] C. Diaz and B. Preneel, “Taxonomy of mixes and dummy trafﬁc,” in
Springer,
Information Security Management, Education and Privacy.
2004, pp. 217–232.
[13] T. M. T. Do and D. Gatica-Perez, “The places of our lives: Visiting
patterns and automatic labeling from longitudinal smartphone data,”
Mobile Computing, IEEE Transactions on, vol. 13, no. 3, pp. 638–648,
2014.
[14] C. Dwork, “Differential privacy,” in 33rd International Colloquium on
Automata, Languages and Programming, ICALP 2006, ser. Lecture
Notes in Computer Science, M. Bugliesi, B. Preneel, V. Sassone, and
I. Wegener, Eds., vol. 4052. Springer, 2006, pp. 1–12.
[15] C. Dwork and J. Lei, “Differential privacy and robust statistics,” in
Proceedings of the forty-ﬁrst annual ACM symposium on Theory of
computing. ACM, 2009, pp. 371–380.
[16] J. Gehrke, M. Hay, E. Lui, and R. Pass, “Crowd-blending privacy,” in
Advances in Cryptology–CRYPTO 2012. Springer, 2012, pp. 479–496.
[17] J. Gehrke, E. Lui, and R. Pass, “Towards privacy for social networks: A
zero-knowledge based deﬁnition of privacy,” in Theory of Cryptography.
Springer, 2011, pp. 432–449.
[18] A. Gervais, R. Shokri, A. Singla, S. Capkun, and V. Lenders, “Quan-
tifying web-search privacy,” in Proceedings of the 2014 ACM SIGSAC
Conference on Computer and Communications Security. ACM, 2014,
pp. 966–977.
[19] B. Hoh, M. Gruteser, H. Xiong, and A. Alrabady, “Preserving privacy in
gps traces via uncertainty-aware path cloaking,” in CCS ’07: Proceed-
ings of the 14th ACM conference on Computer and communications
security. New York, NY, USA: ACM, 2007, pp. 161–171.
[20] D. C. Howe and H. Nissenbaum, “TrackMeNot: Resisting surveillance
in web search,” Lessons from the Identity Trail: Anonymity, Privacy, and
Identity in a Networked Society, vol. 23, pp. 417–436, 2009.
[21] A. Juels and R. L. Rivest, “Honeywords: Making password-cracking
detectable,” in Proceedings of the 2013 ACM SIGSAC conference on
Computer & communications security. ACM, 2013, pp. 145–160.
[22] D. Karamshuk, A. Noulas, S. Scellato, V. Nicosia, and C. Mascolo,
“Geo-spotting: Mining online location-based services for optimal retail
store placement,” in Proceedings of the 19th ACM SIGKDD interna-
tional conference on Knowledge discovery and data mining. ACM,
2013, pp. 793–801.
[23] R. Kato, M. Iwata, T. Hara, A. Suzuki, X. Xie, Y. Arase, and S. Nishio,
“A dummy-based anonymization method based on user trajectory with
pauses,” in Proceedings of the 20th International Conference on Ad-
vances in Geographic Information Systems. ACM, 2012, pp. 249–258.
[24] H. Kido, Y. Yanagisawa, and T. Satoh, “An anonymous communication
technique using dummies for location-based services,” in Pervasive
Services, 2005. ICPS ’05. Proceedings. International Conference on,
July 2005, pp. 88–97.
[25] N. Kiukkonen, J. Blom, O. Dousse, D. Gatica-Perez, and J. Laurila, “To-
wards rich mobile phone datasets: Lausanne data collection campaign,”
Proc. ICPS, Berlin, 2010.
[26] J. Krumm, “Realistic driving trips for location privacy,” in Pervasive
the 7th International Conference on Pervasive
’09: Proceedings of
Computing. Berlin, Heidelberg: Springer-Verlag, 2009, pp. 25–41.
[27] E. Levina and P. Bickel, “The Earth Mover’s distance is the Mallows
distance: some insights from statistics,” in Computer Vision, 2001. ICCV
2001. Proceedings. Eighth IEEE International Conference on, vol. 2,
2001, pp. 251 –256 vol.2.
[28] M. Lichman and P. Smyth, “Modeling human location data with mix-
tures of kernel densities,” in Proceedings of the 20th ACM SIGKDD
international conference on Knowledge discovery and data mining.
ACM, 2014, pp. 35–44.
[29] X. Liu, J. Biagioni, J. Eriksson, Y. Wang, G. Forman, and Y. Zhu,
“Mining large-scale, sparse gps traces for map inference: comparison
of approaches,” in Proceedings of the 18th ACM SIGKDD international
conference on Knowledge discovery and data mining. ACM, 2012, pp.
669–677.
[30] H. Lu, C. S. Jensen, and M. L. Yiu, “Pad: privacy-area aware, dummy-
based location privacy in mobile services,” in MobiDE ’08: Proceedings
of the Seventh ACM International Workshop on Data Engineering for
Wireless and Mobile Access. New York, NY, USA: ACM, 2008, pp.
16–23.
[31] E. Lui and R. Pass, “Outlier privacy,” in Theory of Cryptography.
Springer, 2015, pp. 277–305.
[32] C. Y. Ma, D. K. Yau, N. K. Yip, and N. S. Rao, “Privacy vulnerability of
published anonymous mobility traces,” in Proceedings of the sixteenth
annual international conference on Mobile computing and networking,
ser. MobiCom ’10. New York, NY, USA: ACM, 2010, pp. 185–196.
[Online]. Available: http://doi.acm.org/10.1145/1859995.1860017
[33] A. Machanavajjhala, D. Kifer, J. Abowd, J. Gehrke, and L. Vilhuber,
“Privacy: Theory meets practice on the map,” in Data Engineering, 2008.
ICDE 2008. IEEE 24th International Conference on.
IEEE, 2008, pp.
277–286.
[34] D. J. MacKay, Information theory, inference, and learning algorithms.
Citeseer, 2003, vol. 7.
[35] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and
E. Teller, “Equation of state calculations by fast computing machines,”
The journal of chemical physics, vol. 21, no. 6, pp. 1087–1092, 1953.
[36] D. J. Mir, S. Isaacman, R. Caceres, M. Martonosi, and R. N. Wright,
“Dp-where: Differentially private modeling of human mobility,” in Big
Data, 2013 IEEE International Conference on, Oct 2013, pp. 580–588.
[37] J. Munkres, “Algorithms for the assignment and transportation prob-
lems,” Journal of the Society for Industrial & Applied Mathematics,
vol. 5, no. 1, pp. 32–38, 1957.
[38] P. M. Pardalos, H. Wolkowicz et al., Quadratic Assignment and Related
Problems: DIMACS Workshop, May 20-21, 1993. American Mathe-
matical Soc., 1994, vol. 16.
[39] A. Pingley, N. Zhang, X. Fu, H.-A. Choi, S. Subramaniam, and W. Zhao,
“Protection of query privacy for continuous location based services,” in
INFOCOM, 2011 Proceedings IEEE.
IEEE, 2011, pp. 1710–1718.
[40] D. Proserpio, S. Goldberg, and F. McSherry, “Calibrating data to sen-
sitivity in private data analysis,” Proceedings of the VLDB Endowment,
vol. 7, no. 8, 2014.
[41] L. Rabiner, “A tutorial on hidden markov models and selected applica-
tions in speech recognition,” Proceedings of the IEEE, vol. 77, no. 2,
pp. 257–286, 1989.
[42] D. B. Rubin, “Statistical disclosure limitation,” Journal of Ofﬁcial
Statistics, vol. 9, no. 2, pp. 461–468, 1993.
562562
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:09:44 UTC from IEEE Xplore.  Restrictions apply. 
A. Computational Efﬁciency
APPENDIX
The fake generation process, which results in a pool of
fake traces having passed the privacy test, is run ofﬂine on
powerful machines, before the user’s device retrieves and uses
such fakes. Therefore, this computational burden is not placed
on the user’s device. Nevertheless, the generation process is
reasonably efﬁcient. For example, with the experimental setup
described in Section VI, we could generate one fake trace in
less than 2 minutes, per CPU-core, using a regular laptop.
Using a powerful machine, we generated thousands of fakes
in a few hours. Also note that the computation of both the
aggregate mobility and the semantic clustering needs to be
done only once for each input set of real traces. The former’s
computation time is O(SL + (RT )2) where S = |S| is the
number of seed traces, L is the length (i.e., number of events)
of each seed trace. The latter is dominated by S(S − 1)
semantic similarity computations (e.g., each taking O(T R3) in
the zeroth-order case) and one clustering operation. Excluding
the ﬁnal clustering, this step is embarrassingly parallel: the
semantic similarity for any two users u, v can be computed
independently. Also, if a few input traces are added, both the
aggregate statistics and the semantic clustering can be updated
and do not need to be recomputed from scratch. Once the
semantic clustering has been computed, an arbitrarily large
number of fakes for each seed can be generated. This process is
also embarrassingly parallel, since each fake can be generated
independently of other fakes for that seed, and other seeds.
in
with
nyc
the
[43] Y. Rubner, C. Tomasi, and L. Guibas, “A metric for distributions
with applications to image databases,” in Computer Vision, 1998. Sixth
International Conference on, jan 1998, pp. 59 –66.
[44] Y. Rubner, C. Tomasi, and L. J. Guibas, “The Earth Mover’s Distance
as a Metric for Image Retrieval,” International Journal of Computer
Vision, vol. 40, pp. 99–121, 2000, 10.1023/A:1026543900054. [Online].
Available: http://dx.doi.org/10.1023/A:1026543900054
[45] R. Shokri, G. Theodorakopoulos, G. Danezis, J.-P. Hubaux, and
J.-Y. Le Boudec,
case of
sporadic location exposure,” in Proceedings of the 11th international
conference on Privacy enhancing technologies, ser. PETS’11. Berlin,
Heidelberg: Springer-Verlag, 2011, pp. 57–76. [Online]. Available:
http://dl.acm.org/citation.cfm?id=2032162.2032166
“Quantifying location privacy:
[46] R. Shokri, G. Theodorakopoulos, J.-Y. Le Boudec, and J.-P. Hubaux,
“Quantifying location privacy,” in Proceedings of
the 2011 IEEE
Symposium on Security and Privacy, ser. SP ’11. Washington, DC,
USA: IEEE Computer Society, 2011, pp. 247–262. [Online]. Available:
http://dx.doi.org/10.1109/SP.2011.18
[47] R. Shokri, G. Theodorakopoulos, C. Troncoso, J.-P. Hubaux, and J.-Y.
Le Boudec, “Protecting location privacy: optimal strategy against local-
ization attacks,” in ACM Conference on Computer and Communications
Security (CCS’12), T. Yu, G. Danezis, and V. D. Gligor, Eds. ACM,
2012, pp. 617–627.
[48] C. Song, Z. Qu, N. Blumm, and A.-L. Barab´asi, “Limits of predictability
in human mobility,” Science, vol. 327, no. 5968, pp. 1018–1021, 2010.
[49] A. Suzuki, M. Iwata, Y. Arase, T. Hara, X. Xie, and S. Nishio, “A user
location anonymization method for location based services in a real
environment,” in Proceedings of the 18th SIGSPATIAL International
Conference on Advances in Geographic Information Systems, ser. GIS
’10. New York, NY, USA: ACM, 2010, pp. 398–401. [Online].
Available: http://doi.acm.org/10.1145/1869790.1869846
Tockar,
privacy
[50] A.
ger
Available:
passenger-privacy-in-the-nyc-taxicab-dataset/
Passen-
[Online].
http://research.neustar.biz/2014/09/15/riding-with-the-stars-
the
taxicab
stars:
dataset.”
“Riding
the
[51] A. J. Viterbi, “Error bounds for convolutional codes and an asymptot-
ically optimum decoding algorithm,” Information Theory, IEEE Trans-
actions on, vol. 13, no. 2, pp. 260–269, 1967.
[52] Y. Wang, D. Xu, X. He, C. Zhang, F. Li, and D. Xu, “L2p2: Location-
aware location privacy protection for location-based services,” in INFO-
COM, 2012 Proceedings IEEE.
IEEE, 2012, pp. 1996–2004.
[53] R. W. White, A. Hassan, A. Singla, and E. Horvitz, “From devices to
people: Attribution of search activity in multi-user settings,” in Proc.
International World Wide Web Conference (WWW), 2014.
[54] J. Xu, Z. Zhang, X. Xiao, Y. Yang, G. Yu, and M. Winslett,
“Differentially private histogram publication,” The VLDB Journal,
vol. 22, no. 6, pp. 797–822, Dec. 2013.
[Online]. Available:
http://dx.doi.org/10.1007/s00778-013-0309-y
[55] M. Ye, D. Shou, W.-C. Lee, P. Yin, and K. Janowicz, “On the semantic
annotation of places in location-based social networks,” in Proceedings
of
the 17th ACM SIGKDD international conference on Knowledge
discovery and data mining. ACM, 2011, pp. 520–528.
[56] T.-H. You, W.-C. Peng, and W.-C. Lee, “Protecting moving trajecto-
ries with dummies,” in Mobile Data Management, 2007 International
Conference on, May 2007, pp. 278–282.
[57] J. Yuan, Y. Zheng, and X. Xie, “Discovering regions of different
functions in a city using human mobility and pois,” in Proceedings of the
18th ACM SIGKDD international conference on Knowledge discovery
and data mining. ACM, 2012, pp. 186–194.
[58] H. Zang and J. Bolot, “Anonymization of location data does not work:
A large-scale measurement study,” in Proceedings of the 17th annual
international conference on Mobile computing and networking. ACM,
2011, pp. 145–156.
[59] Y. Zheng, L. Zhang, X. Xie, and W.-Y. Ma, “Mining interesting
locations and travel sequences from gps trajectories,” in Proceedings of
the 18th International Conference on World Wide Web, ser. WWW ’09.
New York, NY, USA: ACM, 2009, pp. 791–800. [Online]. Available:
http://doi.acm.org/10.1145/1526709.1526816
563563
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:09:44 UTC from IEEE Xplore.  Restrictions apply.