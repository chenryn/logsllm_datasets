### Data Visualization and Analysis

The information is presented as an area plot, where the distribution for each dataset is represented by a surface of a different color: seeds (day 1) in blue, real (day 2) in red, and synthetics in yellow. The areas are overlaid on top of one another. The distance between the distributions of two datasets is indicated by their non-overlapping areas. For instance, the yellow and orange regions represent areas where the synthetic distribution either does not overlap (yellow) or overlaps with the real day 2 dataset but not with the seeds (day 1) dataset. The majority of the colored area, particularly the purple region, shows where the real and synthetic distributions overlap, indicating a high level of preservation.

### Distribution Comparison

Table III presents the KL-divergence of the real (seed, day 1) dataset to the synthetic datasets and baselines: the real (testing, day 2) dataset, uniform time allocation (each user spends 1/k proportion of time at each of the k locations), and random time allocation (each user spends a uniformly random proportion of time at the location). To further visualize these results, Figure 12 displays the distribution across all 30 users (for each dataset) for the most popular location only. The statistic is highly preserved in the synthetic traces, sometimes more closely resembling the real (seed, day 1) dataset than the real (testing, day 2) dataset.

### Spatiotemporal Mobility Features

When constructing mobility models from location data, the overall geographic and temporal behavior of users' mobility is considered. To evaluate this, we compare the basic mobility statistics obtained from the real and synthetic datasets. We compute the aggregate mobility model for each synthetic dataset and compare its geographic similarity with the real (seeds, day 1) dataset. Specifically, for a synthetic dataset \( F \), we compute \((\bar{p}_F, \bar{\pi}_F)\) and compare it with \((\bar{p}, \bar{\pi})\). The statistical similarity of \(\bar{p}_F\) with \(\bar{p}\) over all synthetic datasets is [0.8061 (average), 0.8073 (median), 0.0060 (std)], and the results for the statistical similarity of \(\bar{\pi}_F\) with \(\bar{\pi}\) are [0.7856 (average), 0.7867 (median), 0.0152 (std)]. These results indicate a strong correlation between the average/aggregate mobility information of the real and synthetic datasets.

### Semantic Mobility Features

In contrast to other applications, identifying areas for new businesses explicitly takes into account semantic features of the input location data, such as visits to semantically similar venues and transitions between different types of venues. Therefore, it is meaningful to measure the extent to which semantic features of a real dataset are preserved in a released synthetic dataset.

To evaluate this, we follow a two-step process. First, we compute the semantic similarity of each synthetic trace with its own seed trace to check if the semantic features of the original traces are preserved. Figure 8 illustrates the distribution of this value over all synthetic traces, showing a bias towards higher similarity values, indicating that the synthetic traces significantly preserve the semantic features of the real traces.

In the second step, we examine whether the set of synthetic traces preserves the inner similarity between the set of traces. Figure 9 presents the correlation between two distributions: semantic similarity among real traces and semantic similarity among synthetic traces. The Q-Q plot shows a significant correlation between these two distributions, indicating they are strongly linearly related. This reflects that, in addition to maintaining the information about each seed, we also preserve the statistical relation among the traces.

Overall, the identified statistics are largely preserved in the synthetic datasets. Thus, we conclude that our technique is suitable for the aforementioned geo-data analysis tasks and those that rely primarily on similar features.

### Conclusions

This paper is the first to systematically generate plausible synthetic location traces based on quantitative metrics. We propose statistical dissimilarity and plausible deniability as privacy requirements for synthesizing location traces. By enforcing these requirements, synthetic traces would not leak information about real traces more than what they have in common with any random real trace. Through extensive privacy and utility evaluations, we demonstrate the application of our mechanism in two mainstream scenarios: protecting the location privacy of users in LBSs and geo-data analysis on synthetic location data. Our synthesized traces can help protect the location privacy of LBS users with very low utility cost. We show that inference attacks cannot identify the true location of mobile users if our synthetic traces are used as protection. We also quantitatively show that our method is superior to all existing methods of generating synthetic traces. Our synthetic traces also preserve useful features of real traces and can be useful in five popular geo-data analysis tasks.

### References

[References listed here, formatted as per the original text]

### Appendix: Computational Efficiency

The fake generation process, which results in a pool of fake traces passing the privacy test, is run offline on powerful machines before the user's device retrieves and uses such fakes. This computational burden is not placed on the user's device. The generation process is reasonably efficient. For example, with the experimental setup described in Section VI, we could generate one fake trace in less than 2 minutes per CPU-core using a regular laptop. Using a powerful machine, we generated thousands of fakes in a few hours.

The computation of both the aggregate mobility and the semantic clustering needs to be done only once for each input set of real traces. The formerâ€™s computation time is \( O(SL + (RT)^2) \) where \( S = |S| \) is the number of seed traces, \( L \) is the length (i.e., number of events) of each seed trace. The latter is dominated by \( S(S - 1) \) semantic similarity computations (e.g., each taking \( O(T R^3) \) in the zeroth-order case) and one clustering operation. Excluding the final clustering, this step is embarrassingly parallel: the semantic similarity for any two users \( u, v \) can be computed independently. If a few input traces are added, both the aggregate statistics and the semantic clustering can be updated without needing to be recomputed from scratch. Once the semantic clustering has been computed, an arbitrarily large number of fakes for each seed can be generated. This process is also embarrassingly parallel, as each fake can be generated independently of other fakes for that seed and other seeds.