title:Spot Me if You Can: Uncovering Spoken Phrases in Encrypted VoIP Conversations
author:Charles V. Wright and
Lucas Ballard and
Scott E. Coull and
Fabian Monrose and
Gerald M. Masson
2008 IEEE Symposium on Security and Privacy
Uncovering spoken phrases in encrypted VoIP conversations
Spot me if you can:
Charles V. Wright Lucas Ballard Scott E. Coull Fabian Monrose Gerald M. Masson
Johns Hopkins University
Department of Computer Science
Baltimore, MD USA 21218
{cvwright,lucas,coulls,fabian,masson}@jhu.edu
Abstract
Despite the rapid adoption of Voice over IP
(VoIP), its security implications are not yet fully un-
derstood. Since VoIP calls may traverse untrusted
networks, packets should be encrypted to ensure
conﬁdentiality. However, we show that when the
audio is encoded using variable bit rate codecs, the
lengths of encrypted VoIP packets can be used to
identify the phrases spoken within a call. Our re-
sults indicate that a passive observer can identify
phrases from a standard speech corpus within en-
crypted calls with an average accuracy of 50%, and
with accuracy greater than 90% for some phrases.
Clearly, such an attack calls into question the efﬁ-
cacy of current VoIP encryption standards. In ad-
dition, we examine the impact of various features of
the underlying audio on our performance and dis-
cuss methods for mitigation.
1
Introduction
Over the past few years, Voice over IP (VoIP)
has become an attractive alternative to more tradi-
tional forms of telephony. Naturally, with its in-
creasing popularity in daily communications, re-
searchers are continually exploring ways to im-
prove both the efﬁciency and security of this new
communication technology. Unfortunately, while
it is well understood that VoIP packets must be en-
crypted to ensure conﬁdentiality [19], it has been
shown that simply encrypting packets may not be
sufﬁcient from a privacy standpoint. For instance,
we recently showed that when VoIP packets are ﬁrst
compressed with variable bit rate (VBR) encod-
ing schemes to save bandwidth, and then encrypted
with a length preserving stream cipher to ensure
conﬁdentiality, it is possible to determine the lan-
guage spoken in the encrypted conversation [41].
As surprising as these ﬁndings may be, one
might argue that
learning the language of the
speaker (e.g., Arabic) only affects privacy in a
marginal way.
If both endpoints of a VoIP call
are known (for example, Mexico City and Madrid),
then one might correctly conclude that the language
of the conversation is Spanish, without performing
any analysis of the trafﬁc. In this work we show
that the information leaked from the combination
of using VBR and length preserving encryption is
indeed far worse than previously thought. Speciﬁ-
cally, we demonstrate that it is possible to spot ar-
bitrary phrases of interest within the encrypted con-
versation. Our techniques achieve far greater preci-
sion than one would expect, thereby rendering the
encryption ineffective.
At a high level, the success of our technique
stems from exploiting the correlation between the
most basic building blocks of speech—namely,
phonemes—and the length of the packets that a
978-0-7695-3168-7 /08 $25.00 © 2008 IEEE
DOI 10.1109/SP.2008.21
35
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:12:02 UTC from IEEE Xplore.  Restrictions apply. 
likely packet
VoIP codec outputs when presented with these
phonemes.
Intuitively, to search for a word or
phrase, we ﬁrst build a model by decomposing
the target phrase into its most likely constituent
phonemes, and then further decomposing those
phonemes into the most
lengths.
Next, given a series of packet lengths that corre-
spond to an encrypted VoIP conversation, we sim-
ply examine the output stream for a subsequence
of packet lengths that match our model. Of course,
speech naturally varies for any number of reasons,
and so two instances of the same word will not
necessarily be encoded the same way. Therefore,
to overcome this, we make use of proﬁle hidden
Markov models [7] to build a speaker-independent
model of the speech we are interested in ﬁnding.
Using these models we are then able to determine
when a series of packets is similar to what we
would expect given a set of phonemes.
As we show later, the approach we explore is
accurate, even in the face of very little information.
In this work we assume that an attacker only has
access to (1) the ciphertext she wishes to search,
(2) knowledge of the spoken language of the con-
versation (e.g., using the techniques in [41] she
may know this is a Spanish conversation), and (3)
statistics deﬁning what phonemes are mapped to
what packet lengths by the VoIP codec. We ar-
gue that even the last assumption is realistic, as this
information can be readily gathered by an adver-
sary who can use the codec as a “black box” to
compress prerecorded speech. For example, in the
case of English, there are relatively few phonemes
and therefore it is plausible to assume that the at-
tacker can ﬁnd sufﬁciently many instances of each
phoneme to generate realistic models. She can then
use these phonemes to construct models even for
words she has not seen before.
Our results show that an eavesdropper who has
access to neither recordings of the speaker’s voice
nor even a single utterance of the target phrase, can
identify instances of the phrase with average accu-
racy of 50%. In some cases, accuracy can exceed
90%. Clearly, any system that is susceptible to such
attacks provides only a false sense of security to
its users. We evaluate the effectiveness of our at-
tack under a variety of conditions to understand its
real-world implications. Additionally, we explore
methods to mitigate the information leaked from
encrypted VoIP.
The remainder of the paper is organized as fol-
lows. In Section 2 we overview how VBR encoding
works in VoIP and provide evidence of why we are
able to infer phonemes from packet lengths. In Sec-
tion 3 we discuss the requisite background for un-
derstanding proﬁle HMMs, and how our search al-
gorithm works. Section 4 presents our experimen-
tal methodology and results, including an analysis
of how one might thwart our attack. We review re-
lated work in Section 5 and conclude in Section 6.
2 Background
In what follows, we brieﬂy review the principles
of speech coding and speech recognition that are
most relevant to Voice over IP and to our attack.
In VoIP, connection setup and the transmission of
voice data are typically performed using separate
connections. The control channel operates using
a standard application-layer protocol like the Ses-
sion Initiation Protocol (SIP) [24], the Extensible
Messaging and Presence Protocol (XMPP) [25], or
an application-speciﬁc control channel like Skype
[30]. The voice data is typically transmitted as
a Real-time Transport protocol (RTP) [28] stream
over UDP, carrying a version of the audio that has
been compressed using a special-purpose speech
codec such as GSM [11], G.728 [34], or several
others.
Generally speaking, the codec takes as input the
audio stream from the user, which is typically sam-
pled at either 8000 or 16000 samples per second
(Hz). At some ﬁxed interval, the codec takes the
n most recent samples from the input, and com-
presses them into a packet for efﬁcient transmission
across the network. To achieve the low latency re-
quired for real-time performance, the length of the
interval between packets is typically ﬁxed between
10 and 50ms, with 20ms being the common case.
Thus for a 16kHz audio source, we have n = 320
samples per packet, or 160 samples per packet for
the 8kHz case.
36
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:12:02 UTC from IEEE Xplore.  Restrictions apply. 
Intuitively, the sizes of CELP packets leak in-
formation because the choice of bit rate is largely
based on the audio encoded in the packet’s payload.
For example, the variable bit-rate Speex codec en-
codes vowel sounds at higher bit rates than frica-
tive sounds like “f” or “s”. In phonetic models of
speech, sounds are broken down into several differ-
ent categories, including the aforementioned vow-
els and fricatives, as well as stops like “b” or “d”,
and affricatives like “ch”. Each of these canonical
sounds is called a phoneme, and the pronunciation
for each word in the language can then be given as
a sequence of phonemes. While there is no con-
sensus on the exact number of phonemes in spo-
ken English, most in the speech community put the
number between 40 and 60.
y
t
i
l
i
b
a
b
o
r
P
0.6
0.5
0.4
0.3
0.2
0.1
0.0
Speex Bit Rate Probability Distribution
Fricative ‘f’
Consonant ‘k’
Vowel ‘aa’
Vowel ‘aw’
13.6
16.6
17.6
20.6
23.8
Bit Rate (kbps)
24.6
27.8
34.2
Figure 2. Distribution of bit rates used
to encode four phonemes with Speex
To demonstrate the relationship between bit rate
and phonemes, we encoded several recordings from
the TIMIT [10] corpus of phonetically-rich English
speech using Speex in wideband variable bit rate
mode, and observed the bit rate used to encode each
phoneme. The probabilities for 8 of the 21 possible
bit rates are shown for a handful of phonemes in
Figure 2. As expected, we see that the two vowel
sounds, “aa” and “aw”, are typically encoded at
signiﬁcantly higher bit rates than the fricative “f”
or the consonant “k”. Moreover, large differences
in the frequencies of certain bit rates (namely, 16.6,
Figure 1. Basic CELP encoder
Many common voice codecs are based on a tech-
nique called code-excited linear prediction (CELP)
[27] (Figure 1). For each packet, a CELP encoder
simply performs a brute-force search over the en-
tries in a codebook of audio vectors to output the
one that most closely reproduces the original audio.
The quality of the compressed sound is therefore
determined by the number of entries in the code-
book. The index of the best-ﬁtting codebook entry,
together with the linear predictive coefﬁcients and
the gain, make up the payload of a CELP packet.
The larger code books used for higher-quality en-
codings require more bits to index, resulting in
higher bit rates and therefore larger packets.
In some CELP variants, such as QCELP [9],
Speex’s [35] variable bit rate mode, or the approach
advocated by Zhang et al. [42], the encoder adap-
tively chooses the bit rate for each packet in order
to achieve a good balance of audio quality and net-
work bandwidth. This approach is appealing be-
cause the decrease in data volume may be substan-
tial, with little or no loss in quality. In a two-way
call, each participant is idle roughly 63% of the
time [4], so the savings may be substantial. Unfor-
tunately, this approach can also cause substantial
leakage of information in encrypted VoIP calls be-
cause, in the standard speciﬁcation for Secure RTP
(SRTP) [2], the cryptographic layer does not pad or
otherwise alter the size of the original RTP payload.
37
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:12:02 UTC from IEEE Xplore.  Restrictions apply. 
Packets for "artificial"
Packets for "intelligence"
)
c
e
s
/
s
t
i
b
(
e
t
a
R
t
i
B
42200
35800
34200
32600
28600
27800
24600
23800
20600
17600
16600
15550
13600
11550
9800
9550
7750
5850
5750
3950
2050
0
5
10
Position in Sequence
15
20
)
c
e
s
/
s
t
i
b
(
e
t
a
R
t
i
B
42200
35800
34200
32600
28600
27800
24600
23800
20600
17600
16600
15550
13600
11550
9800
9550
7750
5850
5750
3950
2050
0
5
25
15
10
25
Position in Sequence
20
30
35
Figure 3. Packets for “artiﬁcial”
Figure 4. Packets for “intelligence”
27.8, and 34.2 kbps), can be used to distinguish aa
from aw and f from k.
In fact, it is these differences in bit rate for
the phonemes that make recognizing words and