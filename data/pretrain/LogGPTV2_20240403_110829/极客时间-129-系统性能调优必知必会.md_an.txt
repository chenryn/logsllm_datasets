# 30 \| 如何权衡关系数据库与NoSQL数据库？你好，我是陶辉。 到了第 4 部分课程的最后一讲，我们来结合前面介绍过的知识点，看看面对NoSQL、关系数据库时该如何选择。 在分布式系统中，我们会同时使用多种数据库。比如，你可能会在 Redis中存放用户 Session 会话，将业务数据拆解为由行、列构成的二维表存储在MySQL 中，将需要全文检索的数据放在 ElasticSearch 中，将知识图谱放在Neo4j 图数据库中，将数据量、访问量很大的数据放在 Cassandra列式数据库或者 MongoDB文档型数据库中，等等。 选择数据库时，我们的依据可能是访问速度，比如基于哈希表的 Redis查询复杂度只有O(1)，也可能从事务的支持程度上选择了关系数据库，甚至从应用层的开发效率上还给它添加了Hibernate 等 ORM 框架，也可能从处理数据的体量上选择了 NoSQL数据库。可是，除了各种实现层面上的差异外，各类 NoSQL与关系数据库之间，有没有最本质的区别？在实际工程中，我们可否从此入手确定大方向，再从细微处选择不同的实现？ 在我看来，答案就在于"关系"这两个字，这也是我权衡数据库时最先考虑的前提。接下来我们就沿着关系数据库的特性，看看NoSQL数据库究竟做了哪些改变，我们又该如何选择它们。 关系数据库的优点关系数据库对业务层开发效率的提升有很大帮助。下面我们先基于一个简单的例子，看看关系数据库有何优点。疫情期间新增了一批能够测量体温的考勤机，通过关系数据库我们新建了用户、考勤机、考勤记录三张表，如下图所示： ![](Images/1f839f3f2c687676103a8a36d28d6e42.png)savepage-src="https://static001.geekbang.org/resource/image/60/25/60870a7eebd59fbcfb87298c3ed31025.jpg"}在关系数据库中，表中的每行数据由多个从属于列的单一值（比如数字、字符串）构成。虽然表中可以存放任意行数据，但列却是预先定义且不变的，因此我们很容易通过行、列交汇处的单一值进行关联操作，进而完成各类业务目的不同的查询。比如，业务开发者可以通过下面这行SQL 语句，找到体温超过 37度的员工，上报其姓名、测量时间以及所在地理位置：     select user.name, record.time, machine.location from user, record, machine where user.id = record.user_id and machine.id = record.machine_id and record.temporature > 37;运营人员则可以通过下面这行 SQL语句，找出各类考勤机的使用频率：     select count(*), machine.id from machine, record where machine.id = record.machine_id group py machine.id;因此，关系数据库**可以通过预定义的关系，由数据库自身完成复杂的逻辑计算，为不同的场景提供数据服务。**由于不同的数据间具有了关系，关系数据库还提供了"Transaction 事务slate-object="inline""，用于保证相关数据间的一致性，这大大释放了应用开发者的生产力。所谓"事务"，会同时具有ACID4 个特性： **Atomicity 原子性**，指多个 SQL语句组成了一个逻辑单位，执行时要么全部成功，要么全部失败。 **Consistency 一致性**，指数据库只能从一个一致性状态转换到另一个一致性状态。即使数据库发生了重启，仍然得维持一致性。 **Isolation 隔离性**，由于数据库可以支持多个连接并发操作，因此并发的事务间必须互相隔离才有意义。SQL标准定义了以下 4 种隔离级别： 1.  READ UNCOMMITTED 未提交读，它表示在事务 A    还未提交时，并发执行的事务 B 已经可以看到事务 A    改变的数据。这种隔离级别会带来很多问题，因此很少使用。        2.  READ COMMITTED 提交读，它表示当事务 A 未提交时，事务 B 看不到事务    A 改变的任何数据，这是 PostgreSQL    数据库的默认隔离级别。        3.  REPEATABLE READ 可重复读，指在 READ COMMITTED    的基础上解决了脏读问题。所谓脏读，是指在一个事务内，多次读取到同一数据时，结果可能不一致。这是    MySQL    数据库的默认隔离级别。        4.  SERIALIZABLE    可串行化，它通过对每一行数据加锁，使得所有事务串行执行，虽然隔离性最好，但也大大降低了数据库的并发性，所以很少使用。        **Durability 持久性**，指一旦事务提交，事务所做的修改必须永久性地保存到数据库中。 可见，事务的 ACID特性简化了本应由应用层完成的流程！这也是关系数据库与 NoSQL数据库之间最大的差别。除事务外，关系数据库还在以下 4点上降低了应用层的开发成本： 1.  无论是商业版的 Oracle，还是开源的    MySQL、PostgreSQL，        **只要是关系数据库就拥有同样的数据模型，因此它们可以通过**        [SQL            **    语言为应用层提供标准化、几乎没有差异的访问接口；**        2.  生产级的数据库对持久化都有良好的支持，全面的冷备、热备方案提供了很高的可用性；        3.  通过索引、缓存等特性，当行数在亿级以下时，关系数据库的性能并不低；        4.  关系数据库支持还不错的并发度，一般可以服务于上千个并发连接。        所以应用层会将许多计算任务放在关系数据库中，在此基础上还诞生了 MVC等将数据层从业务中剥离、以关系数据库为中心的架构。 关系数据库的问题虽然基于单一值的关系映射提供了事务等许多功能，但同时也引入了 3个问题。 首先，内存中的数据结构非常多样，难以直接映射到行列交汇处的单一值上。不过，**这个问题可以通过**ORM（Object-relationalmapping）  slate-object="inline"**框架解决。**比如，Python 中的 Django ORM 框架，可以将上述 3张表映射为内存中的 3 个类：     from django.db import models    class User(models.Model):        name = models.CharField(max_length=20)    class Machine(models.Model):        location = models.CharField(max_length=100)            class Record(models.Model):        time = models.DateTimeField()        temporature = models.FloatField()        user = models.ForeignKey(User)        machine= models.ForeignKey(Machine)ORM 框架会为每张表生成 id 字段，而 Record 表将 User 和 Machine 表中的id 字段作为外键（ForeignKey）互相关联在一起。于是，这 3个类就映射了数据库中的那 3张表，而内存中的对象（即类的实例）则映射为每张表中的一行数据。在 ORM框架下，找到体温大于 37 度员工的那串长 SQL，可以转化为 OOP中的函数调用，如下所示：     #gte表示大于等于    records = Record.objects.filter(temporature__gte = 37)    for r in records:      print(r.user.name, r.machine.location, r.time)相比起 SQL 语句，映射后的 OO编程要简单许多。 其次，为了实现关系映射，每张表中的字段都得预先定义好，一旦在产品迭代过程中数据模型发生了变化，便需要同步完成以下3 件事： 1.  修改表结构；        2.  修改应用层操作数据的代码；        3.  根据新的规则转换、迁移已有数据。        在 ORM 中我们可以把这 3 步放在一个 migration迁移脚本中完成。当然，如果数据迁移成本高、时间长，可以设计更复杂的灰度迁移方案。 **最后是关系数据库固有的可伸缩性问题，这是各类 NoSQL数据库不断诞生的主要原因。**在\[第 21 讲\ 中，我们介绍过沿 AKF X轴扩展的复制型主从结构，然而单点主库无法解决数据持续增长引入的性能问题。 ![](Images/8eea1987f198ff848bf20b49b7c85765.png)savepage-src="https://static001.geekbang.org/resource/image/0c/16/0cf179648bf05bf38fb192c7ca797916.png"}沿 AKF Z轴扩展数据库虽然能够降低数据规模，但分库分表后，单一值关系引申出的 ACID事务不能基于高时延、会抖动的网络传输强行实现，否则会导致性能大幅下降，这样的可用性是分布式系统无法接受的。 ![](Images/3b78b013c5c5bd09528c02319eca2b5b.png)savepage-src="https://static001.geekbang.org/resource/image/44/f4/44c738618f8e947372969be96c525cf4.png"}因此，在单机上设计出的关系数据库，难以处理 PB 级的大数据。而 NoSQL数据库放弃了单一值数据模型，非常适合部署在成千上万个节点的分布式环境中。 NoSQL 数据库是如何解决上述问题的？虽然所有的 NoSQL 数据库都无法实现标准的 SQL 语言接口，但 NoSQL绝不是"No SQL：拒绝 SQL 语言"的意思。当然，NoSQL 也不是"Not OnlySQL：不只是 SQL 语言"的意思，否则 Oracle 也能算 NoSQL数据库了。实际上，没有必要纠结 NoSQL 的字面含义，NoSQL数据库只是放弃了与分布式环境相悖的 ACID事务，提供了另一种聚合数据模型，从而拥有可伸缩性的非关系数据库。 NoSQL 数据库可以分为以下 4类： Key/Value 数据库slate-object="inline"，通常基于哈希表实现（参见\[第 3 讲\），性能非常好。其中 Value的类型通常由应用层代码决定，当然，Redis 这样的 Key/Value 数据库还可以将Value定义为列表、哈希等复合结构。 文档型数据库，在 Key/Value数据库中，由于没有预定义的值结构，所以只能针对 Key执行查询，这大大限制了使用场景。**文档型数据库将 Value 扩展为 XML、JSON（比如MongoDB）等数据结构，于是允许使用者在文档型数据库的内部解析复合型的Value结构，再通过其中的单一值进行查询，这就兼具了部分关系数据库的功能。** 列式数据库slate-object="inline"，比如\[第 22 讲\ 介绍过的 Cassandra。列式数据库基于Key来映射行，再通过列名进行二级映射，同时它基于列来安排存储的拓扑结构，这样当仅读写大量行中某个列时，操作的数据节点、磁盘非常集中，磁盘IO、网络 IO都会少很多。列式数据库的应用场景非常有针对性，比如博客文章标签的行数很多，但在做数据分析时往往只读取标签列，这就很适合使用列式数据库。再比如，**通过倒排索引实现了全文检索的ElasticSearch，就适合使用列式存储存放 DocValues，这样做排序、聚合时非常高效。** 图数据库  slate-object="inline"，在社交关系、知识图谱等场景中，携带各种属性的边可以表示节点间的关系，由于节点的关系数量多，而且非常容易变化，所以关系数据库的实现成本很高，而图数据库既没有固定的数据模型，遍历关系的速度也非常快，很适合处理这类问题。当然，我们日常见到的主要是前3 类 NoSQL 数据库。 相对于关系数据库，NoSQL在性能和易用性上都有明显的优点。 首先我们来看可用性及性能，这是 NoSQL数据库快速发展的核心原因： 1.  NoSQL    数据库的可伸缩性都非常好。虽然许多文档型、列式数据库都提供了类 SQL    语言接口，但这只是为了降低用户的学习成本，它们对跨节点事务的支持极其有限。因此，这些    NoSQL 数据库可以放开手脚，基于 Key/Value 模型沿 AKF Z    轴将系统扩展到上万个节点。        2.  在数据基于 Key    分片后，很容易通过        [\[第 28 讲\             介绍过的 MapReduce    思想，提高系统的计算能力。比如，MongoDB    很自然的就在查询接口中，提供了        [MapReduce                函数。    3.  通过冗余备份，NoSQL    可以提供优秀的容灾能力。比如，Redis、Cassandra    等数据库，都可以基于        [\[第 22 讲\             介绍过的 NWR 算法，灵活地调整    CAP 权重。        4.  如果每个 Key 中 Value 存放的复合数据已经能满足全部业务需求，那么    NoSQL    的单机查询速度也会优于关系数据库。        其次再来看易用性，这主要体现在我们可以低成本地变更 Value 结构。虽然NoSQL 数据库支持复合型 Value结构，但并不限定结构类型。比如，文档型数据库中，同一个表中的两行数据，其值可以是完全不同的JSON结构；同样的，列式数据库中两行数据也可以拥有不同的列数。因此，当数据结构改变时，只需要修改应用层操作数据的代码，并不需要像关系数据库那样同时修改表结构以及迁移数据。 那么，到底该如何选择关系数据库与 NoSQL数据库呢？其实，沿着"单一值关系"这一线索，我们已经找到了各自适用的场景。 如果多个业务数据间互相关联，我们需要从多个不同的角度分析、计算，并保持住相关数据的一致性，那么关系数据库最为适合。一旦数据行数到了亿级别以上，就需要放弃单一值结构，将单行数据聚合为复合结构，放在可以自由伸缩的NoSQL 数据库中。此时，我们无法寄希望于 NoSQL 数据库提供 ACID事务，只能基于二段式提交等算法在应用层代码中自行实现事务。 小结这一讲我们介绍了关系数据库与 NoSQL数据库各自的特点及其适用场景。 关系数据库通过行、列交汇处的单一值，实现了多种数据间的关联。通过统一的SQL接口，用户可以在数据库中实现复杂的计算任务。为了维持关联数据间的一致性，关系数据库提供了拥有ACID特性的事务，提升了应用层的开发效率。 虽然单一值无法映射内存中的复合数据结构，但通过 ORM框架，关系数据库可以将表映射为面向对象编程中的类，将每行数据映射为对象，继续降低开发成本。然而，关系数据库是为单机设计的，一旦将事务延伸到分布式系统中，执行成本就会高到影响基本的可用性。因此，关系数据库的可伸缩性是很差的。 NoSQL 数据库基于 Key/Value数据模型，可以提供几乎无限的可伸缩性。同时，将 Value值进一步设计为复合结构后，既可以增加查询方式的多样性，也可以通过MapReduce 提升系统的计算能力。实际上，关系数据库与每一类 NoSQL数据库都有明显的优缺点，我们可以从数据模型、访问方式、数据容量上观察它们，结合具体的应用场景权衡取舍。 思考题最后，留给你一道讨论题。你在选择 NoSQL与关系数据库时是如何考虑的？欢迎你在留言区与大家一起探讨。 感谢阅读，如果你觉得这节课让你有所收获，也欢迎你把今天的内容分享给身边的朋友。 
# 加餐3｜百万并发下Nginx的优化之道你好，我是专栏编辑冬青。今天的课程有点特别，作为一期加餐，我为你带来了陶辉老师在GOPS 2018 · 上海站的分享，以文字讲解 + PPT的形式向你呈现。今天的内容主要集中在 Nginx的性能方面，希望能给你带来一些系统化的思考，帮助你更有效地去做Nginx。 优化方法论今天的分享重点会看这样两个问题：1.  第一，如何有效使用每个连接分配的内存，以此实现高并发。        2.  第二，在高并发的同时，怎样提高    QPS。    当然，实现这两个目标，既可以从单机中的应用、框架、内核优化入手，也可以使用类似F5 这样的硬件设备，或者通过 DNS等方案实现分布式集群。![](Images/ce2df8f762653a56240e132673040a50.png)savepage-src="https://static001.geekbang.org/resource/image/1a/24/1a69ba079c318c227c9ccff842714424.jpg"}而 Nginx 最大的限制是网络，所以将网卡升级到万兆，比如 10G 或者 40G吞吐量就会有很大提升。作为静态资源、缓存服务时，磁盘也是重点关注对象，比如固态硬盘的IOPS 或者 BPS，要比不超过 1万转每秒的机械磁盘高出许多。![](Images/a09422c875074b31f5581e6d981d09a3.png)savepage-src="https://static001.geekbang.org/resource/image/4a/2c/4aecd5772e4d164dc414d1f473440f2c.jpg"}这里我们重点看下CPU，如果由操作系统切换进程实现并发，代价太大，毕竟每次都有 5微秒左右的切换成本。Nginx 将其改到进程内部，由 epoll 切换ngx_connection_t 连接的处理，成本会非常低。OpenResty 切换 Lua协程，也是基于同样的方式。这样，CPU的计算力会更多地用在业务处理上。从整体上看，只有充分、高效地使用各类 IT 资源，才能减少 RTT时延、提升并发连接。![](Images/944a1fcf618e6df3359df9da08930fa2.png)savepage-src="https://static001.geekbang.org/resource/image/9d/24/9d4721babd048bed55968c4f8bbeaf24.jpg"}请求的"一生"只有熟悉 Nginx 处理 HTTP请求的流程，优化时才能做到有的放矢。首先，我们要搞清楚 Nginx 的模块架构。Nginx是一个极其开放的生态，它允许第三方编写的 C 模块与框架协作，共同处理 1 个HTTP 请求。比如，所有的请求处理模块会构成一个链表，以 PipeAndFilter这种架构依次处理请求。再比如，生成 HTTP响应后，所有过滤模块也会依次加工。![](Images/bbf0564c3d12cd4ddf693a8d6de36fea.png)savepage-src="https://static001.geekbang.org/resource/image/8b/4d/8bb5620111efd7086b3fa89b1b7a3d4d.jpg"}1. 请求到来试想一下，当用户请求到来时，服务器到底会做哪些事呢？首先，操作系统内核会将完成三次握手的连接socket，放入 1 个 ACCEPT 队列（如果打开了 reuseport，内核会选择某个worker 进程对应的队列），某个 Nginx Worker进程事件模块中的代码，需要调用 accept 函数取出socket。 建立好连接并分配 ngx_connection_t 对象后，Nginx 会为它分配 1个内存池，它的默认大小是 512 字节（可以由 connection_pool_size指令修改），只有这个连接关闭的时候才会去释放。接下来 Nginx 会为这个连接添加一个默认 60 秒（client_header_timeout指令可以配置）的定时器，其中，需要将内核的 socket 读缓冲区里的 TCP报文，拷贝到用户态内存中。所以，此时会将连接内存池扩展到1KB（client_header_buffer_size指令可以配置）来拷贝消息内容，如果在这段时间之内没有接收完请求，则返回失败并关闭连接。![](Images/ab2149f4c8aeb234dfc7a8e55bb510da.png)savepage-src="https://static001.geekbang.org/resource/image/17/63/171329643c8f003yy47bcd0d1b5f5963.jpg"}2. 处理请求当接收完 HTTP 请求行和 HEADER后，就清楚了这是一个什么样的请求，此时会再分配另一个默认为4KB（request_pool_size指令可以修改，这里请你思考为什么这个请求内存池比连接内存池的初始字节数多了8 倍？）的内存池。Nginx 会通过协议状态机解析接收到的字符流，如果 1KB内存还没有接收到完整的 HTTP 头部，就会再从请求内存池上分配出32KB，继续接收字符流。其中，这 32KB 默认是分成 4 次分配，每次分配8KB（可以通过 large_client_header_buffers指令修改），这样可以避免为少量的请求浪费过大的内存。![](Images/d7defd897494a46a0923e4a80532c4c9.png)savepage-src="https://static001.geekbang.org/resource/image/f8/64/f8b2e2c3734188c4f00e8002f0966964.jpg"}接下来，各类 HTTP 处理模块登场。当然，它们并不是简单构成 1个链表，而是通过 11 个阶段构成了一个二维链表。其中，第 1 维长度是与 Web业务场景相关的 11 个阶段，第 2 维的长度与每个阶段中注册的 HTTP模块有关。 这 11 个阶段不用刻意死记，你只要掌握 3个关键词，就能够轻松地把他们分解开。首先是 5 个阶段的预处理，包括post_read，以及与 rewrite 重写 URL 相关的 3 个阶段，以及 URL 与 location相匹配的 find_config 阶段。![](Images/4cea04cac067e92373321ea60ba8f043.png)savepage-src="https://static001.geekbang.org/resource/image/a0/86/a048b12f5f79fee43856ecf449387786.jpg"}其次是访问控制，包括限流限速的 preaccess 阶段、控制 IP 访问范围的access 阶段和做完访问控制后的 post_access阶段。 最后则是内容处理，比如执行镜象分流的 precontent 阶段、生成响应的content 阶段、记录处理结果的 log阶段。 每个阶段中的 HTTP 模块，会在 configure脚本执行时就构成链表，顺序地处理 HTTP 请求。其中，HTTP框架允许某个模块跳过其后链接的本阶段模块，直接进入下一个阶段的第 1个模块。 ![](Images/136fef5e246dd5b33f921324f6986465.png)savepage-src="https://static001.geekbang.org/resource/image/0e/fb/0ea57bd24be1fdae15f860b926cc25fb.jpg"}content 阶段会生成 HTTP 响应。当然，其他阶段也有可能生成 HTTP响应返回给客户端，它们通常都是非 200 的错误响应。接下来，会由 HTTP过滤模块加工这些响应的内容，并由 write_filter过滤模块最终发送到网络中。![](Images/8bc542eebf5c2c3c2a7816100ab6e431.png)savepage-src="https://static001.geekbang.org/resource/image/f4/39/f4fc5bc3ef64498ac6882a902f927539.jpg"}3. 请求的反向代理Nginx 由于性能高，常用来做分布式集群的负载均衡服务。由于 Nginx下游通常是公网，网络带宽小、延迟大、抖动大，而上游的企业内网则带宽大、延迟小、非常稳定，因此Nginx需要区别对待这两端的网络，以求尽可能地减轻上游应用的负载。比如，当你配置 proxy_request_buffering on指令（默认就是打开的）后，Nginx 会先试图将完整的 HTTP BODY接收完，当内存不够（默认是 16KB，你可以通过 client_body_buffer_size指令修改）时还会保存到磁盘中。这样，在公网上漫长的接收 BODY流程中，上游应用都不会有任何流量压力。接收完请求后，会向上游应用建立连接。当然，Nginx也会通过定时器来保护自己，比如建立连接的最长超时时间是 60 秒（可以通过proxy_connect_timeout指令修改）。当上游生成 HTTP 响应后，考虑到不同的网络特点，如果你打开了proxy_buffering on（该功能也是默认打开的）功能，Nginx会优先将内网传来的上游响应接收完毕（包括存储到磁盘上），这样就可以关闭与上游之间的TCP连接，减轻上游应用的并发压力。最后再通过缓慢的公网将响应发送给客户端。当然，针对下游客户端与上游应用，还可以通过proxy_limit_rate 与 limit_rate 指令限制传输速度。如果设置proxy_buffering off，Nginx会从上游接收到一点响应，就立刻往下游发一些。![](Images/37364b09c06fc63a7b6ebbf5bf704a39.png)savepage-src="https://static001.geekbang.org/resource/image/9c/90/9c3d5be8ecc6b287a0cb4fc09ab0c690.jpg"}4. 返回响应当生成 HTTP 响应后，会由注册为 HTTP响应的模块依次加工响应。同样，这些模块的顺序也是由 configure脚本决定的。由于 HTTP 响应分为HEADER（包括响应行和头部两部分）、BODY，所以每个过滤模块也可以决定是仅处理HEADER，还是同时处理 HEADER 和BODY。 ![](Images/8ba56efeb294e1dde3a830f7422dc427.png)savepage-src="https://static001.geekbang.org/resource/image/25/e8/2506dfed0c4792a7a1be390c1c7979e8.jpg"}因此，OpenResty 中会提供有 header_filter_by_lua 和 body_filter_by_lua这两个指令。![](Images/656a3530ebbd8242e91b1961abfb936e.png)savepage-src="https://static001.geekbang.org/resource/image/c4/81/c495fb95fed3b010a3fcdd26afd08c81.jpg"}应用层优化1. 协议应用层协议的优化可以带来非常大的收益。比如 HTTP/1 HEADER的编码方式低效，REST 架构又放大了这一点，改为 HTTP/2协议后就大有改善。Nginx 对 HTTP/2 有良好的支持，包括上游、下游，以及基于HTTP/2 的 gRPC 协议。![](Images/5111fbd74c14e7793b4b4c92ca676057.png)savepage-src="https://static001.geekbang.org/resource/image/ee/91/eebe2bcd1349d51ee1d3cb60a238a391.jpg"}2. 压缩对于无损压缩，信息熵越大，压缩效果就越好。对于文本文件的压缩来说，Google的 Brotli 就比 Gzip效果好，你可以通过https://github.com/google/ngx_brotli 模块，让 Nginx 支持 Brotli压缩算法。 对于静态图片通常会采用有损压缩，这里不同压缩算法的效果差距更大。目前Webp 的压缩效果要比 jpeg好不少。对于音频、视频则可以基于关键帧，做动态增量压缩。当然，只要是在Nginx 中做实时压缩，就会大幅降低性能。除了每次压缩对 CPU的消耗外，也不能使用 sendfile零拷贝技术，因为从磁盘中读出资源后，copy_filter过滤模块必须将其拷贝到内存中做压缩，这增加了上下文切换的次数。更好的做法是提前在磁盘中压缩好，然后通过add_header等指令在响应头部中告诉客户端该如何解压。3. 提高内存使用率只在需要时分配恰当的内存，可以提高内存效率。所以下图中 Nginx提供的这些内存相关的指令，需要我们根据业务场景谨慎配置。当然，Nginx的内存池已经将内存碎片、小内存分配次数过多等问题解决了。必要时，通过TcMalloc 可以进一步提升 Nginx申请系统内存的效率。同样，提升 CPU 缓存命中率，也可以提升内存的读取速度。基于 cpu cacheline 来设置哈希表的桶大小，就可以提高多核 CPU下的缓存命中率。![](Images/414df32c8d38e2f38f2e024bc5fe3282.png)savepage-src="https://static001.geekbang.org/resource/image/aa/a7/aa7727a2dbf6a3a22c2bf933327308a7.jpg"}4. 限速作为负载均衡，Nginx 可以通过各类模块提供丰富的限速功能。比如limit_conn 可以限制并发连接，而 limit_req 可以基于 leacky bucket漏斗原理限速。对于向客户端发送 HTTP 响应，可以通过 limit_rate指令限速，而对于 HTTP 上游应用，可以使用 proxy_limit_rate限制发送响应的速度，对于 TCP 上游应用，则可以分别使用 proxy_upload_rate和 proxy_download_rate指令限制上行、下行速度。![](Images/1e77d49ee6878c2861bb193424ff5313.png)savepage-src="https://static001.geekbang.org/resource/image/3e/af/3e7dbd21efc06b6721ea7b0c08cd95af.jpg"}5. Worker 间负载均衡当 Worker 进程通过 epoll_wait 的读事件获取新连接时，就由内核挑选 1 个Worker 进程处理新连接。早期 Linux 内核的挑选算法很糟糕，特别是 1个新连接建立完成时，内核会唤醒所有阻塞在 epoll_wait 函数上的 Worker进程，然而，只有 1 个 Worker 进程，可以通过 accept函数获取到新连接，其他进程获取失败后重新休眠，这就是曾经广为人知的"惊群"现象。同时，这也很容易造成Worker 进程间负载不均衡，由于每个 Worker 进程绑定 1 个 CPU 核心，当部分Worker 进程中的并发 TCP 连接过少时，意味着 CPU的计算力被闲置了，所以这也降低了系统的吞吐量。Nginx 早期解决这一问题，是通过应用层 accept_mutex 锁完成的，在 1.11.3版本前它是默认开启的：accept_mutexon; 其中负载均衡功能，是在连接数达到 worker_connections的八分之七后，进行次数限制实现的。我们还可以通过 accept_mutex_delay配置控制负载均衡的执行频率，它的默认值是 500 毫秒，也就是最多 500毫秒后，并发连接数较少的 Worker 进程会尝试处理新连接：accept_mutex_delay500ms; 当然，在 1.11.3 版本后，Nginx 默认关闭了 accept_mutex锁，这是因为操作系统提供了 reuseport（Linux3.9版本后才提供这一功能）这个更好的解决方案。![](Images/a5ad28e356285031fd17dd46b02d6b70.png)savepage-src="https://static001.geekbang.org/resource/image/5f/7a/5f5f833b51f322ae963bde06c7f66f7a.jpg"}图中，横轴中的 default 项开启了 accept_mutex 锁。我们可以看到，使用reuseport 后，QPS 吞吐量有了 3倍的提高，同时处理时延有明显的下降，特别是时延的波动（蓝色的标准差线）有大幅度的下降。6. 超时Nginx 通过红黑树高效地管理着定时器，这里既有面对 TCP报文层面的配置指令，比如面对下游的 send_timeout 指令，也有面对 UDP报文层面的配置指令，比如proxy_responses，还有面对业务层面的配置指令，比如面对下游 HTTP 协议的client_header_timeout。![](Images/13c88cc2f61c8fc319d34d617b6433bb.png)savepage-src="https://static001.geekbang.org/resource/image/fy/f7/fyyb03d85d4b8312873b476888a1a0f7.jpg"}7. 缓存只要想提升性能必须要在缓存上下工夫。Nginx 对于七层负载均衡，提供各种HTTP 缓存，比如 http_proxy 模块、uwsgi_proxy 模块、fastcgi_proxy模块、scgi_proxy 模块等等。由于 Nginx 中可以通过变量来命名日志文件，因此Nginx 很有可能会并行打开上百个文件，此时通过 open_file_cache，Nginx可以将文件句柄、统计信息等写入缓存中，提升性能。![](Images/848f4c8572ce0b161a4df8dcd1dc97b5.png)savepage-src="https://static001.geekbang.org/resource/image/45/15/452d0ecf0fcd822c69e1df859fdeb115.jpg"}8. 减少磁盘 IONginx虽然读写磁盘远没有数据库等服务要多，但由于它对性能的极致追求，仍然提供了许多优化策略。比如为方便统计和定位错误，每条HTTP 请求的执行结果都会写入 access.log 日志文件。为了减少 access.log日志对写磁盘造成的压力，Nginx提供了批量写入、实时压缩后写入等功能，甚至你可以在另一个服务器上搭建rsyslog 服务，然后配置 Nginx 通过 UDP 协议，将 access.log日志文件从网络写入到 rsyslog 中，这完全移除了日志磁盘IO。 ![](Images/1fe5258e0881375e19c6709c77c8ba56.png)savepage-src="https://static001.geekbang.org/resource/image/d5/da/d55cb817bb727a097ffc4dfe018539da.jpg"}系统优化最后，我们来看看针对操作系统内核的优化。首先是为由内核实现的 OSI 网络层（IP 协议）、传输层（TCP 与 UDP协议）修改影响并发性的配置。毕竟操作系统并不知道自己会作为高并发服务，所以很多配置都需要进一步调整。![](Images/8b2c90f488b5ddf9787af3b34821df99.png)savepage-src="https://static001.geekbang.org/resource/image/d5/15/d58dc3275745603b7525f690479d6615.jpg"}其次，优化 CPU 缓存的亲和性，对于 Numa 架构的服务器，如果 Nginx只使用一半以下的 CPU 核心，那么就让 Worker 进程只绑定一颗 CPU上的核心。 ![](Images/bcce77d89b91c4bc364c7fa444d8a539.png)savepage-src="https://static001.geekbang.org/resource/image/8f/c2/8f073d7222yy8e823ce1a7c16b945fc2.jpg"}再次，调整默认的 TCP网络选项，更快速地发现错误、重试、释放资源。![](Images/361c6a3204bf3699874a67e5581fd913.png)savepage-src="https://static001.geekbang.org/resource/image/32/d3/326cf5a1cb8a8522b89eb19e7ca357d3.jpg"}还可以减少 TCP 报文的往返次数。比如 FastOpen 技术可以减少三次握手中 1个 RTT的时延，而增大初始拥塞窗口可以更快地达到带宽峰值。![](Images/7a0adba3d9496e05c73bceb63460db89.png)savepage-src="https://static001.geekbang.org/resource/image/6f/09/6f0de237bd54cf2edf8cdcfb606c8c09.jpg"}还可以提高硬件资源的利用效率，比如当你在 listen 指令后加入 defer选项后，就使用了 TCP_DEFER_ACCEPT 功能，这样 epoll_wait并不会返回仅完成三次握手的连接，只有连接上接收到的 TCP数据报文后，它才会返回 socket，这样 Worker 进程就将原本 2 次切换就降为 1次了，虽然会牺牲一些即时性，但提高了 CPU的效率。 Linux 为 TCP内存提供了动态调整功能，这样高负载下我们更强调并发性，而低负载下则可以更强调高传输速度。我们还可以将小报文合并后批量发送，通过减少 IP 与 TCP头部的占比，提高网络效率。在 nginx.conf 文件中打开tcp_nopush、tcp_nodelay功能后，都可以实现这些目的。![](Images/e4bbb12d9d47b764e7ffda0a6bd3a7b5.png)savepage-src="https://static001.geekbang.org/resource/image/ac/04/ac69ce7af1abbf4df4bc0b42f288d304.jpg"}为了防止处理系统层网络栈的 CPU过载，还可以通过多队列网卡，将负载分担到多个 CPU中。 ![](Images/7dbbcc4cf5863d067e15eba3a1efd4ee.png)savepage-src="https://static001.geekbang.org/resource/image/6b/82/6bacf6f3cyy3ffd730c6eb2f664fe682.jpg"}为了提高内存、带宽的利用率，我们必须更精确地计算出BDP，也就是通过带宽与 ping 时延算出的带宽时延积，决定 socket读写缓冲区（影响滑动窗口大小）。![](Images/aa38498d0bd0d338b2425ddcbba3fa15.png)savepage-src="https://static001.geekbang.org/resource/image/13/7d/1389fd8fea84cef63e6438de1e18587d.jpg"}Nginx 上多使用小于 256KB 的小内存，而且我们通常会按照 CPU 核数开启Worker 进程，这样一种场景下，TCMalloc 的性能要远高于 Linux 默认的PTMalloc2 内存池。![](Images/872274c36420eb37578b532b91fb595b.png)savepage-src="https://static001.geekbang.org/resource/image/56/a8/56267e1yye31a7af808c8793c894b0a8.jpg"}作为 Web 服务器，Nginx 必须重写 URL以应对网址变化，或者应用的维护，这需要正则表达式的支持。做复杂的 URL或者域名匹配时，也会用到正则表达式。优秀的正则表达式库，可以提供更好的执行性能。![](Images/4ff02fe22c5b17c3bbb870b12c5b4b34.png)savepage-src="https://static001.geekbang.org/resource/image/55/f0/556b3359b43f2a641ef2bc4a13a334f0.jpg"}以上就是今天的加餐分享，有任何问题欢迎在留言区中提出。