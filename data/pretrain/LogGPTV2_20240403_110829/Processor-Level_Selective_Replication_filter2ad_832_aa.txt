title:Processor-Level Selective Replication
author:Nithin Nakka and
Karthik Pattabiraman and
Ravishankar K. Iyer
Processor-level Selective Replication 
Nithin Nakka, Karthik Pattabiraman, Ravishankar Iyer 
Center for Reliable and High Performance Computing 
Coordinated Science Laboratory 
{nakka, pattabir, iyer}@crhc.uiuc.edu 
Abstract 
that  only 
it  can  be  ensured 
We  propose  a  processor-level  technique  called 
Selective  Replication,  by  which  the  application  can 
choose  where  in  its  application  stream  and  to  what 
degree  it  requires  replication.  Recent  work  on  static 
analysis  and 
fault-injection-based  experiments  on 
applications  reveals  that  certain  variables  in  the 
application  are  critical  to  its  crash-  and  hang-free 
execution.  If 
the 
computation  of  these  variables  is  error-free,  then  a 
high  degree  of  crash/hang  coverage  can  be  achieved 
at a low performance overhead to the application. The 
Selective  Replication  technique  provides  an  ideal 
platform  for  validating  this  claim.  The  technique  is 
compared against complete duplication as provided in 
current architecture-level techniques. The results show 
that  with  about  59% 
full 
duplication,  selective  replication  detects  97%  of  the 
data  errors  and  87%  of  the  instruction  errors  that 
were  covered  by  full  duplication.  It  also  reduces  the 
detection of errors benign to the final outcome of the 
application by 17.8% as compared to full duplication. 
less  overhead 
Keywords:  Application-aware,  Error  Detection, 
Redundant Hardware, Critical Variable, Duplication. 
1. Introduction 
than 
The 
System-level  replication  has  been  widely  used  to 
detect  and  possibly  tolerate  transient  errors  in  both 
commercial systems and research prototypes. Recently, 
processor-level  replication  has  emerged  as  a  viable 
technique [1]. 
redundancy  and 
two  basic  approaches  for  processor-level 
replication  are  hardware 
time 
redundancy. (1) Hardware redundancy [3] is achieved 
by  carrying  out  the  same  computation  on  multiple, 
independent hardware at the same time and comparing 
the  redundant  results.  (2)  Time  redundancy  [3][5]  is 
achieved  by  executing  the  same  operation  multiple 
times  on  the  same  or  idle  hardware.  In  both  types  of 
redundancy,  all  instructions  of  the  application  are 
replicated and checked for correct execution. However, 
the application cannot choose to use redundancy for a 
specific code section and run in a normal, unreplicated 
mode  for  the  rest  of  the  code.  In  other  words,  it  is  a 
“one size fits all” approach.  
We propose hardware-based, selective replication to 
replicate only critical portions of the application rather 
than the entire application, thus reducing performance 
overhead.  The  application  chooses  the  portions  that 
need  to  be  replicated  and  the  degree  of  redundancy. 
This  is  done  using  an  extension  of  a  technique 
described  in  [8]  for  identifying  strategic  locations  for 
placement  of  detectors.  Critical  variables  and,  hence, 
critical  code  sections  that  need  to  be  replicated  are 
derived  from  this  analysis.  The  application  is  then 
instrumented with special CHECK instructions, which 
are  an  extension  to  the  instruction  set  architecture 
(ISA),  to  invoke  reconfiguration  of  the  underlying 
hardware and provide the specified level of replication 
to the critical code sections. 
Another  advantage  of  selectively  replicating  an 
application is the reduction in detection of processor-
level errors that do not affect the final outcome of the 
application 
(benign  errors).  Fault-injection-based 
experiments by Wang [6] and Saggese [7] showed that 
80-85% of the errors did not manifest as errors in the 
application  outcome.  Full  replication  at  the  hardware 
level aims at detecting all errors in the processor, even 
those that are benign. This leads to false alarms, which 
are  considered  undesirable  from  a  safety  perspective. 
Selective  replication,  on  the  other  hand,  aims  at 
detecting  only  the  errors  that  result  in  application 
failure. 
This work addresses the following two questions to 
provide selective replication: 
1.  Which  sections  of  the  code  need  to  be 
replicated? 
2.  How  can  we  modify  the  fetch,  renaming,  and 
commit mechanism to handle a specified level 
of redundancy for portions of the code? 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:33 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Processor-level  replication  has  been  implemented 
earlier  [4][5].  However,  it  is  a  non-trivial  task  to 
extend it to support selective replication of portions of 
the application, as it requires a reconfiguration of the 
fetch, rename and commit mechanisms in the processor. 
In  addition,  to  let  the  application  to  select  the 
portions to replicate, the hardware needs to expose an 
API that can be used to trigger the reconfiguration of 
the replication mechanism. 
implementation.  The 
In this paper we detail the mechanism of selective 
replication  in  a  superscalar  processor  and  present  a 
that 
possible 
results  show 
Selective  Replication  detects  about  87%  of 
the 
instruction errors and 97% of the data errors detected 
by  Full  Duplication.  Further,  it  incurs  only  59% 
performance  overhead  compared  to  Full  Duplication. 
Moreover,  the  detection  of  errors  benign  to  the 
application  outcome  is  reduced  by  about  18%  as 
compared to full duplication. 
The  rest  of  the  paper  is  organized  as  follows: 
Section  2  describes  the  analysis  procedure  to  extract 
the  portions  of  the  application  that  need  to  be 
replicated.  The  basic  mechanism  of  Selective 
Replication  has  been  presented  in  Section  3  and  the 
hardware implementation has been detailed in Section 
4. Section 5 presents the results. Some previous work 
has  been  summarized  in  Section  6  and  Section  7 
presents the conclusions and directions for future work. 
2. Application analysis 
In this section, we show how the properties of the 
application  are  leveraged  by  selective  replication  in 
order  to  identify  what  to  replicate  in  the  application. 
This analysis consists of three main steps as shown in 
Figure 1.  
Identification of Critical Variables
Extraction of Critical Code Sections
Code instrumentation with CHECK instructions
Figure 1: Steps in identifying what to replicate 
These steps are carried out at compile-time prior to 
the application being deployed. The first two steps are 
carried  out  by  an  offline  analysis  based  on  the 
Dynamic Dependence Graph (DDG) of the application, 
which represents the dependencies among instructions 
in a real execution of the application. The third step is 
carried out using an enhancement made to the compiler, 
using the information obtained from the first two steps. 
The three steps are explained in more detail as follows:  
1) Identification of Critical Variables. Recent work 
by Pattabiraman et al. [8] has shown that it is feasible 
to  identify  critical  variables  in  an  application,  which 
when  in  error  are  highly  likely  application/system 
failure (crashes1 and fail silence violations). Selective 
replication  leverages  the  results  of  this  study  to 
replicate  only  those  portions  of  the  application  that 
compute the critical variables. In order to identify the 
critical variables we use an approach similar to the one 
described  in  [8].  The  criticality  of  variables  to  error-
free execution of the program has been evaluated using 
metrics  like  lifetime,  and  fanout  (definition).  It  was 
shown that ideal detectors placed at locations with high 
fanout gave higher coverage, where an ideal detector is 
one that is able to detect any data error that propagates 
to the location at which it is placed. The analysis was 
done  on  the  program’s  Dynamic  Dependency  Graph 
(DDG). For multiple inputs, faults are injected into the 
program  variables 
that  are  being  evaluated  for 
criticality  (with  high  fanout,  lifetime  etc.).  For  each 
input, the effect of each fault is traced, using the DDG 
for  that  input,  to  locations  of  the  program  where  the 
program  may  crash.  If  the  error  led  the  program  to  a 
potential crash location, a detector at the critical point 
is said to detect an impending program crash.  
Our claim is that if the computations of the critical 
variables  are  replicated, 
this  can  enhance 
application dependability substantially and at the same 
time incur only a small performance penalty compared 
to that of full replication.   
then 
that 
that  produce  a 
2)  Extraction  of  the  Critical  Code  Sections.  Any 
part of the application that affects the value of a critical 
variable is a critical code section (consisting of critical 
instructions). A critical code section includes: 
•  Instructions that define critical variables. 
•  Instructions 
result 
is 
subsequently consumed by critical instructions (i.e. 
backward  program  slice  of  the  critical  instruction 
[15]). 
A reverse depth-first search algorithm on the DDG 
is  used  for  automated  identification/extraction  of 
instructions that directly or indirectly  affect  the  value 
of  critical  variables.  The  algorithm  extracts 
the 
backward slice of the instruction that defines a critical 
variable  [15].  Backward  slicing  using  static  analysis 
techniques  is  known  to  be  imprecise  [20].  Using  the 
dynamic dependency graph, the precision of backward 
slicing  can  be  improved  [16].  This  is  important  from 
the point of view of selective replication, as imprecise 
1 Program crashes must be detected preemptively to prevent 
error propagation and corruption of program state. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:33 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007slicing  algorithms  can 
instructions that need to be replicated.. 
increase 
the  number  of 
Due  to  space  constraints,  we  do  not  present  the 
details of the algorithm, but these may be found in [13]. 
An  important  point  to  note  is  that  when  using 
multiple critical nodes, there may be an overlap in the 
instructions  that  affect  two  or  more  nodes.  It  is 
sufficient  to  replicate  all  such  instructions  that  affect 
multiple critical nodes once for all nodes. 
Formally, let Θ be the set of critical variables and Ι 
be  the  set  of  all  inputs.  For  an  input  i  ∈  Ι,  let  the 
dynamic dependency graph be Gi = (Vi, Ei) where the 
vertices in Vi correspond to statements in the dynamic 
execution of the program and there is an edge (u, v) in 
Ei if statement u is executed before statement v and u 
produces  a  result  that  is  used  by  v.  For  every  critical 
variable θ ∈ Θ, let Hi,θ = (Vi,θ, Ei,θ) be the sub-graph of 
Gi  which  is  the  backward  slice  of  instructions  that 
affect variable θ. For each dynamic instruction w ∈ Vi,θ 
its  counterpart, s,  in  the  static  code  segment  is  found 
(both  of  them  have  the  same  PC).  The  set  of  static 
instructions corresponding to the dynamic instructions 
in Vi,θ  is the set of critical instructions, Si,θ, that need 
to  be  replicated  for  input  i  and  critical  variable θ.  Si 
SUΘ∈θ
i,θ is the set of critical instructions for input i 
=
and S =
SUIi∈
code segment that need to be replicated for all inputs 
considered. 
i is the set of all instructions in the static 
3) Insertion of CHECK Instructions. The compiler 
places  a  special  CHECK  instruction  before  and  after 
each  duplicated  instruction  to  notify  the  hardware  of 
the change in the level of replication. This is the API 
that  the  hardware  exposes  to  the  application  to  select 
the point and level of replication. Note that the critical 
instructions  can  also  be  consecutive  to  each  other.  In 
such  a  case,  for  each  block  of  contiguous  critical 
instructions,  one  CHECK  instruction  is  placed  before 
and  one  after  the  block  of  instructions  to  notify  the 
replication  module  of  entering  into  and  exiting  from 
replication  mode.  This  reduces 
the  overhead  of 
switching  between  replication  modes  as  well  as  the 
number of CHECK instructions inserted. 
3. Overview of Selective Replication 
This  section  describes  the  selective  replication 
technique  in  detail.  Instructions  are  fetched  as  in  a 
normal  pipeline.  The  dispatch  mechanism,  which 
allocates reorder buffer entries to the currently fetched 
instructions,  broadly  operates  in  two  modes:  the 
unreplicated  mode  and  the  replicated  mode.  In  the 
unreplicated mode, a single copy of each instruction is 
dispatched,  renamed,  and  allocated  to  the  reorder 
buffer (ROB). In the replicated mode, r copies of each 
instruction  are  dispatched,  where  r  is  the  degree  of 
replication. If any instruction, i, in the replicated code 
consumes  a  value  produced  by  a  preceding 
unreplicated instruction, j, then all copies of i receive 
their  input  from  j.  If  a  replicated  instruction  i1  is 
dependent on another replicated instruction i2, then the 
copy of i1 in every replica is dependent on the copy of 
i2  in  the  same  replica.  The  register  operands  of  the 
instructions are renamed accordingly. 
After instruction execution is complete the result is 
stored  in  the  ROB  itself.  When  an  instruction  at  the 
head of the ROB is ready to commit, all copies of the 
instruction  are  checked  to  see  if  they  are  ready  to 
commit.  If  all  copies  are  ready  to  commit,  then  their 
results (stored in their corresponding ROB entries) are 
compared.  If  all  of  them  match  the  instruction  is 
committed.  In  the  case  of  even  a  single  mismatch 
appropriate  recovery  action  is  taken,  such  as  retrying 
the instruction execution. 
3.1.  Mechanism of replication 
An 
the 
mechanism  for  selective  replication  that  allows  the 
application  to  choose  the  extent  and  location  of 
replication it needs.  In this section the implementation 
of selective replication in a modern superscalar out-of-
order  processor  is  described.  Implementing  selective 
replication 
involves 
modifying  the  instruction  fetch  and  dispatch,  register 
renaming, and commit mechanisms of the processor. 
The  block  diagram  in  Figure  2  shows  a  processor 
pipeline  (top  of  the  figure)  with  the  modifications 
required for selective replication (shown at the bottom 
of the figure). 
in  a  superscalar  processor 
important  contribution  of 
this  work 
is 
Before  describing 
the  actual  mechanism  of 
execution  in  the  replicated  mode,  it  is  helpful  to 
describe some key hardware data structures that would 
be used in the execution.  
The  register  alias  table  (RAT)  is  used  in  dynamic 