(10)
(00)
(11)
(00)
Table 2: Information on Scalar Bits from Noise Free Sensitive
Leakage
solute value. We then used unsupervised clustering to classify
these sub-traces into two distinct subsets in order to differen-
tiate the cases ki = 0 and ki = 1. For this step, we used the
Expectation-Maximization algorithm (Scikit-learn Gaus-
sianMixture class8). If the classiﬁcation is successful, the
number of sub-traces in each subsets should match the re-
spective probabilities given by Table 2, i.e. P(ki = 0) = 3/8,
P(ki = 1) = 5/8. This was indeed the case for some T-Test
threshold values. Nonetheless, since we were able to deduce
nonce values from the private key of our experiments on
Rhea, we could precisely evaluate the matching success rate
for ki = 0. Table 3 summarizes the matching success rates for
ki = 0 on the 4000×128 sub-traces of Rhea for various thresh-
old values. For a threshold t, we give the resulting sub-traces
length (# points) after samples selection and signal process-
ing, the probability of success when a sub-trace is sent to the
set ki = 0 and the overall number of sub-traces labeled ki = 0
over the 4000×128 sub-traces. More precisely, the clustering
algorithm will choose two cluster centers (i.e. two multivari-
ate Gaussian distributions) and output, for each sub-trace, the
probability of ﬁtting each cluster. We call conﬁdence level
the probability for a sub-trace to ﬁt the cluster corresponding
to ki = 0. We ran several experiments on Rhea’s traces with
various threshold values. For the second phase of the attack,
we selected the 109714 sub-traces obtained with t = 11 for
which the clustering algorithm’s conﬁdence level is equal or
greater than 95% (highlighted in blue in Table 3). At the end
of this ﬁrst part of the attack, we have thus acquired with very
high probability roughly 109714/4000 ≈ 27.5 bits per nonce
(all located on the upper half of the nonce since they relate
to msb(˜ki)). The second phase of the attack presented in the
next section consists in recovering the unknown part of each
nonce in order to deduce the secret key d.
We proceeded similarly with lsb(˜ki) in the hope to
gather even more knowledge about the nonces. However, as
mentioned before (see Figure 12), the side-channel leakage
related to lsb(˜ki) is signiﬁcantly weaker than the one related
to msb(˜ki) and our matching success rates seemed not
8Exact
parameters
are
covariance_type=’tied’)
GaussianMixture(n_components=2,
USENIX Association
30th USENIX Security Symposium    241
t
10
11
12
13
14
15
sub-trace length
success rate (%)
# sub-traces
697
650
591
554
520
484
99.0
99.0
99.0
99.0
99.1
99.1
110054
109714
108451
106990
106691
105911
Table 3: Results of the clustering algorithm with minimum
conﬁdence level set to 0.95.
good enough. We hence decided to drop this (too) noisy
information.
To summarize, we will target only bits with value 0 (as
value 1 might hide the randomization of a dummy operation)
and only in msb(˜ki) since the sensitive leakage happens to be
stronger there (in comparison to lsb(˜ki)).
5.2 Lattice-based Attack with Partial Knowl-
edge of the Nonces
In [15], Howgrave-Graham and Smart exploited lattice re-
duction algorithms in order to recover (EC)DSA private
keys from the knowledge of only a few bits per nonce.
This work was followed by many others that improved
the understanding of so-called lattice-based attacks and/or
successfully applied variants to practical settings (see e.g.
[1–3, 5, 7, 13, 14, 16, 23, 24, 26–28, 36, 38]). All these attacks
work as follows:
1. Run N ECDSA signatures and record the inputs hi =
h(mi), the outputs (ri,si) and the known information ˆki
on the nonce ki. We denote by ui the unknown part of ki
so that ki = ˆki + ui (warning: contrary to the previous
sections where ki denoted the i-th bit of k, we shall now
use the subscript notation where ki designates the nonce
of the i-th signature, where i = 1, . . . ,N).
2. Rewrite the ECDSA equations si = k−1
(hi + rid) mod q
(see Section 3.1), as linear equations of the form Aiui +
Bid ≡ Ci (mod q), involving the secret key d and the
ui’s for i = 1, . . . ,N.
i
3. Build a lattice L that contains the vector v =
(u1,u2, . . . ,uN) (in practice, this vector often contains
some extra elements).
4. If the known part ˆki of ki is sufﬁciently large, then the
norm of v is small and one can expect to ﬁnd v by solving
an instance of the Shortest Vector Problem (SVP) in L.
As shown in [15], this attack amounts to ﬁnding a solution
to the so-called Hidden Number Problem (HNP) introduced
in [4]. The literature mostly considers the case where the
Following [15], the ECDSA equations si = k−1
known part consists of some of the most signiﬁcant bits of
each nonce. However, a more general setting sometimes re-
ferred to as the Extended Hidden Number Problem (EHNP),
allows the known part to be a sequence of several blocks of
consecutive known bits scattered all over the nonce. In this
case, the unknown ui is a vector whose elements are the un-
known sections of each nonce. We note ui = (ui,1,ui,2, . . . ).
This more general setting did not draw much attention (im-
portant papers are [13–15, 27]) but led to practical attacks
nonetheless, mainly in the speciﬁc case of w-NAF implemen-
tations of the scalar multiplication [7, 23]. Our attack also
relies on this Extended version of the HNP.
(hi +
dri) mod q can be rewritten as ki = Aid − Bi (mod q), with
Ai = s−1
i hi. If the most signiﬁcant bits of
Aid and Bi coincide, or equivalently if Aid − Bi is small,
then one can build a lattice L such that the closest vector to
v = (B1, . . . ,BN,0) in L reveals the nonces k1, . . . ,kN, hence
the private key d. This situation corresponds to the HNP and
the solution is obtained by solving an instance of the Closest
Vector Problem (CVP). A common variant makes it possible
to reduce the problem to an instance of the Shortest Vector
Problem (SVP) in L. In general, this so-called embedding
technique (due to [18]) provides a better probability of suc-
cess.
ri and Bi = −s−1
i
i
In our case, the known part of the nonces does not cor-
respond to the most signiﬁcant bits of ki. Instead, we have
ki = ˆki +
(cid:96)i∑
j=1
ui, j2λi, j ,
(1)
where the bits that form the known part ˆki split the nonces ki
into (cid:96)i unknown parts ui, j.
For the lattice reduction algorithm (LLL or BKZ) to be
successful, the side-channel acquisition phase should provide
enough information on the nonces. Notably, over all recorded
signatures, the number of known bits should be large enough.
It was commonly assumed that this number must be larger
than the bitlength of the secret9. Yet, it is worth mentioning
that very recently, M. Albrecht and N. Heninger managed to
slightly break this so-called information theoretic limit [1]
using a sieve algorithm (and, with less success, an enumer-
ation algorithm). Moreover, and at the price of some rather
expensive computations, they showed that 3 known bits by
nonce are sufﬁcient in practice to solve HNP when most
recent attacks necessitated at least 4 known bits [16, 24].
Based on the above observations and after a few experi-
ments on Rhea, we opted for a strategy that we detail in Sec-
tion 5.3. As explained next, we ﬁltered out the 4000 recorded
signatures in order to keep only those for which the known
part ˆki was a block of 5 consecutive zero bits so that
ki = ui,22λi + 0× 2µi + ui,1
9i.e. the bitlength of the group order: 256 in our case.
(2)
242    30th USENIX Security Symposium
USENIX Association
where λi = µi +5 is the index of the most signiﬁcant unknown
part of ki. The least signiﬁcant part ui,1 has index 0, i.e. it
coincides with the least signiﬁcant bits of ki.
We then used equation 2 to build a lattice that contains
a short vector whose elements include the unknown parts
ui,1,ui,2. Using this information, it was then easy to recon-
struct the nonces ki, notably k1, and therefore the private key
d.
We applied several optimizations to increase both the efﬁ-
ciency and probability of success of the attack. In particular,
we removed the secret key d from the equations, we used the
already mentioned embedding technique, and we adapted the
trick presented in [27] and recalled in [1, 24] that consists of
shifting the interval of the unknown parts ui, j from [0,Ui, j] to
[−Ui, j/2,Ui, j/2] to the case EHNP. The details of our opti-
mization and lattice construction are given in Appendix A.
5.3 Touchdown on Rhea
As seen in Section 5.1, we recorded input and output data
on 4000 ECDSA signatures. Our pruning process and pa-
rameters allowed us to select 109714 sub-traces (iterations)
corresponding to a zero bit with very high probability (99%).
This represents an average of ≈ 27.5 known zero bits per
nonce over the 4000 signatures. We also know that these zero
bits are all located in the upper half of the nonces (see Sec-
tion 4). Unfortunately, the vast majority of this information
is not easily exploitable. Indeed, an elementary, yet rather
conservative equation from [13] tells us that in the case of
EHNP, a known block of less than three consecutive bits is
not helping. In fact, it is deteriorating the success rate by in-
creasing the lattice dimension for no gain. According to [13],
there should be at least three (resp. two) known blocks of 3
bits (resp. 4 bits) per nonce for the attack to be successful.
Thus, after a few experiments, we decided to seek nonces
containing a single block of at least ﬁve consecutive zero bits.
We ended-up with 180 nonces, out of which only 5 included
a wrongly estimated known block.
In simulation, with such a conﬁguration and using LLL for
the lattice reduction, 80 error free signatures are enough to
get about 50% chances to ﬁnd the secret. Based on these sim-
ulations, we completed the attack on Rhea using a brute-force
strategy: we randomly selected 80 nonces among the 180
available to deﬁne the lattice and run the reduction algorithm
until the secret key was found.
Using LLL, each trial attack with 80 signatures took about
100 seconds to complete (on a 3,3GHz Intel Core i7, with
16GB RAM). Eventually, the secret key was recovered after
only a few tens of trials.
In the purpose of completeness, we provide in Appendix B
the attack success rate estimations in simulation with the
BKZ algorithm (for various block sizes). As expected, BKZ
offers much better results than LLL, even allowing us to con-
sider 4-bit known blocks instead of 5-bit blocks, signiﬁcantly
decreasing the overall attack data complexity10.
5.4 Touchdown on Titan
We launched the attack on the Google Titan Security Key
following the exact same trajectory. First, we did our best
to locate the EM probe at the same spatial position and
with the same orientation (see Figure 4). We acquired
6000 side-channel traces during the execution of the U2F
authentication request command (details of the acquisi-
tion campaign are similar to Rhea’s, see Table 1, but for the
number of acquisitions and then for the acquisition time that
took about 6 hours).
Re-alignment, samples selection and signal processing
We applied exactly the same process than for Rhea (the
same four signal peaks were clearly visible). Once re-aligned
around the four signal peaks, we used the T-Test results from
Rhea to select the time samples and we applied the same
signal processing on the sub-traces.11
Unsupervised clustering Again, we applied the same
Expectation-Maximization algorithm than for Rhea. As men-
tioned earlier, we were optimistic about the correctness of the
clustering process since the sizes of the two output clusters
were proportional to the expected ratios (3/8,5/8). We then
brute-forced the T-Test threshold for time samples selection
and eventually selected t = 8 (for Rhea it was t = 11). After
signal processing and samples selection, the sub-trace length
with this threshold was 854.
Pruning and nonces selection We chose the highest con-
ﬁdence level that preserved sufﬁciently many nonces with 5
or more consecutive zeros. Since we had more traces than
for Rhea, we were able to increase the conﬁdence level to
0.98. We ended-up with 156 nonces with a block of at least 5
consecutive zero bits.
Key recovery attack We ran our EHNP solver on random
subsets of size 80 among the 156 selected nonces. The attack
was successful after only a few tens of attempts.
Post analysis From the secret key, we can compute the
values of the nonces and verify that, among the 156 selected
nonces, 7 were erroneous. The attack was then a little more
challenging than for Rhea but still possible. Again, as shown
10The use of a sieve algorithm, as in [1], would certainly improve further
these results.
11By reusing Rhea’s T-Test results for selecting the time samples for
Titan, we assumed that Rhea and Titan share the same clock frequency and
instructions order. These are not strong hypotheses since the clock frequency
can be easily checked and the NXP cryptographic library version seems to
be the same on both devices.
USENIX Association
30th USENIX Security Symposium    243
in Appendix B, the use of BKZ with medium or large block
size would do the work with much fewer nonces.
Time required to replay the attack Once the attacker get
hold of the Titan device, it should take less than 10 hours
to replay the side-channel acquisition: 2 hours for preparing
the device, 1 hour for preparing the side-channel acquisition
setup, 6 hours for the side-channel acquisition and 1 hour
for repackaging the device. After returning the device to the
victim, the key recovery can then be performed ofﬂine in less
than one day.
6 A Crucial Observation
During the post analysis, we ran a lot of simulations on vari-
ous instances of the EHNP. In particular, we observed that the
success rate of the attack, and the minimum number of sig-
natures required to reach a given success rate, differ between
the contexts of Rhea / Titan and that of random instances of
the EHNP.12 We made the following crucial observation:
The success rate of the attack increases when the positions
(bits) covered by the known blocks of the nonces correspond
to positions where the group order is either all-zeros or all-
ones. As a consequence, the number of signatures required to
complete the attack can be greatly reduced in this case.
We realized that the Rhea / Titan implementation of the
scalar multiplication with the comb method, together with the
fact that the observed leakage on the most signiﬁcant bits of