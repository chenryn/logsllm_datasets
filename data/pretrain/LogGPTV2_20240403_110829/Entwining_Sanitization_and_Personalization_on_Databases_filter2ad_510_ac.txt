Nissim [6] can be adapted to show that the absolute error in this def-
inition is the best possible one. In fact, Rastogi, Hong and Suciu [18]
have shown that if there is a powerful adversary whose a priori
information d is at least Ω
, it would be impossible to find
an algorithm to assure the privacy and the utility of the resulting
view of the database. Hence, to obtain a solution, the following
assumption would have to be made:
(cid:18) |DB|
√|D|
(cid:19)
Assumption 3. The a priori information of any adversary has to
be at most d = k
, for some constant k > 0.
If this assumption holds, Rastogi, Hong and Suciu [18] obtains
|DB|
-useful sanitized views of
|D| , γ
γ · ln 2
3 k
ϵ , ϵ
k
a given proprietary database, for any ϵ > 0.
-privacy and
4
|DB|
|D|
(cid:18)
(cid:113)
(cid:17)
(cid:16)
(cid:19)
Session 6: Privacy 1ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea211Security. The security of our solution for the database distribu-
tion problem depends on whether or not the merchant can retrieve
at least one malicious buyer responsible for the redistribution of an
illegitimate copy. As mentioned earlier, the real challenge is to be
able to deal with a collusion of malicious buyers.
Definition 10. Collusion. A c-collusion C is a c-element subset
of B. Each of them gets the views VC = {V1, . . . ,Vc}. By mixing
their views, their objective is to release a counterfeit view V∗ that does
not identify any of them.
In this context, the security requirement can be formulated as:
Definition 11. Traitor-tracing. Given a set of views VC from
potential colluders C and a strategy S, an adversary A from C may
forge a counterfeit view V∗ and releases it. The merchant M running
DBAccuse on V∗ must identify a member of C with probability at
least 1 − ϵ.
Consider the set of the views VC available to an adversary. He
can split the tuples of these views into two disjoint sets:
• the invariant tuples that belong to all views in VC;
• the mutant tuples that belong only to some views of VC.
In the degenerate case of a singleton set VC, all the tuples are
invariant tuples.
his illegal copy V∗:
In our context, an adversary has three distinct strategies to forge
• delete an invariant tuple;
• add (i.e., generate) a tuple that is not in any view;
• select or not mutant tuples according to some criteria (mi-
nority, majority, random selection, ...).
4 SAPDATA: SECURE DISTRIBUTION
Our solution for the problem presented in the introduction in-
tegrates two approaches: the sanitization process to ensure the
privacy of the personal information in a database and the person-
alization process to eventually trace back the malicious buyers
who illegally redistribute their copies of the database. Although
these two processes seem antagonist at first, they must be closely
entwined to present a coherent and secure solution. Hence, the
sanitization step should not deteriorate the personalization. Simi-
larly, the personalization step should not impact the utility of the
resulting database.
Our novel approach is based on an instantiation relying on the
(α, β )-sanitization algorithm [18, 19] and on any binary fingerprint-
ing code. Dual Hamming codes can be particularly efficient when
the size of the collusion is very small (up to three malicious buy-
ers) [7]. For larger collusions, Tardos codes [27] (as improved by
Škorić and his co-authors [23, 24]) may be used. As mentioned
previously, these codes are almost optimal. Nonetheless in both
cases, the fingerprints are simply l-bit vectors. In the remaining of
this section, the underlying codes used to build these fingerprints
are not detailed since any binary fingerprinting code can be used.
DBSetup. The DBSetup algorithm is executed by the merchant
on the following parameters: the database DB, the domain D, as
well as the upper bounds on the number of buyers n, the number
of colluders c and the acceptable error probability ϵ, the size of
the codewords l, and finally the assumed a priori knowledge (d, γ )
Algorithm DBSetup(DB, D, n, c, ϵ, l, d, γ )
Data: The database and appropriate upper bounds
Result: The sanitized view and fingerprinting parameters
// (α,β)-sanitization algorithm
{α, β} ← Initα β (d, γ )
{sR , sF } ← secret seeds of the unpredictable PRNG
V
for all the tuples t in DB in lexicographic order do
← ∅
if PRNG(sR , α ) = 1 then
V = V ∪ {t} // Select with probability α
for all the tuples t in D \ DB in lexicographic order do
V = V ∪ {t} // Select with probability β
if PRNG(sF , β ) = 1 then
// Fingerprinting codes
W ← InitCB(n, c, l, ϵ )
Pos ← a random l-element susbset in D \ DB
// The buyers-codewords association
Rec ← ∅
return the public parameters (α, β )
return the secret parameters (V, sR , sF ,W, Pos, Rec)
Algorithm 1: This algorithm sets the global parameters.
of any adversary on the database DB. This algorithm outputs
the public parameters of the sanitization process consisting of the
variables α and β. It also outputs the secret parameters consisting of
the sanitized viewV, the unpredictable seeds of the pseudo-random
generator (PRNG) used to generate this view, the codebook W and
the marking tuples Pos. This algorithm is described in more details
in Algorithm 1. At first, M generates the public parameters α and β
of the privacy model. To preserve the privacy of the database DB
and to ensure the utility of the sanitized view V, it is sufficient that
α and β respect the following inequalities [18, 19]:
(ρ, ϵ ) − utility
(d, γ ) − privacy
1
2
d
γ
γ
≤ α ≤
≥ β ≥
1 − d
γ
d − dγ
γ − dγ
α
(1)
(2)
Note that these conditions are not necessary but only sufficient.
Inequality 1 would have a solution if d ≤ γ
2 .
Similarly, Inequality 2 would have a solution if
≥ d − dγ
γ − d
γ − dγ
γ
≥ d
d
γ
1 − γ + γ 2
This latter inequality is not as strict on d. Thus, d ≤ γ
sufficient to have solutions for α and β.
2 should be
Rastogi, Hong and Suciu [18] presented an example of their tech-
nique on a US census database commonly used in the literature.
Session 6: Privacy 1ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea212(cid:17)
(cid:16)
|D| , 0.2
10 |DB|
This database has 30,162 tuples with nine attributes while its do-
main is composed of 648,023,040 tuples. The authors were looking
for a
-private solution against tuple-independent ad-
versaries. In practice, this means that the adversaries can roughly
decrease the a priori domain of the database only by a factor of ten
(k = 10), which is relatively small as compared to D
DB . This factor
depends on the data. Indeed if it is too large, it would impact the
utility of the query estimators. On the other hand, the upper bound
on the a posteriori probabilities (γ) has been selected relatively high
as compared to the a priori probabilities to model strong adversaries.
In this scenario, the following bounds can be derived:
0.5 ≤ α ≤ 0.997
0.0023 ≥ β ≥ 0.0019 · α
(3)
(4)
The authors have chosen α = 1
2 and β = 0.00095 in their example
to minimize the number of false tuples added in the resulting views.
This leads to a sanitized view composed of 15,081 true tuples and
615,621 false tuples. Despite this high number of false tuples, they
showed that the view was still useful for any counting query on any
three distinct attributes. Such a result is specific to the database
and can be reached only by limiting the class of queries.
The next step is to construct the sanitized view V of the database
DB. This can be done with the help of a secure and unpredictable
pseudo-random bit generator PRNG(s, p), which produces a deter-
ministic series of bits, once the initial seed s is given. This generator
is such that the probability of having a 1-bit is p. Such a generator
can be easily used to select the (α, β )-sanitized view of DB. Con-
sidering the lexicographic order of the tuples in DB (or D \ DB),
each tuple can be selected with the appropriate probability. Hence,
the seeds sR (for the real tuples) and sF (for the false tuples) can be
used by the merchant M as a proof of ownership. The merchant M
then selects a random l-element subset Pos ⊂ D \DB to insert the
l-bit fingerprints during the watermarking process of the DBBuy al-
gorithm. In parallel, M generates the codebook W containing the n
personalized fingerprints. Depending on the fingerprinting schemes
used, the codewords may not have to be generated beforehand. In
the latter situation, only the parameters of the fingerprinting code
have to be known. For instance, for Tardos code, the upper bound
c on the number of colluders and the upper bound ϵ on the error
probability are sufficient to determine the length of the binary code-
words and the associated probability vector. Once this vector has
been defined, random codewords can be generated upon request.
This means that the merchant does not have to generate and store
useless codewords. Finally, the merchant creates a empty list Rec,
which will be used during the DBBuy algorithm to store all trans-
actional information and in the DBAccuse algorithm to determine
the identity of the potential malicious buyers.
Remark 2 (using quantization to improve robustness). In many
cases, a view of the database could be altered by the adversary
to produce an equivalent (very loosely defined) view. Assume for
instance that a database has numerous real or integer attributes. By
tweaking the least significant bits of these attributes, this would
most likely flip a 1-bit of a codeword (i.e., a given tuple is present
in the representation) into a 0-bit (i.e., a given tuple is absent from
the representation). Nonetheless as only the least significant bits
should be altered, numerous counting queries would still give ap-
proximately the same outputs on the untraceable view. Henceforth,
to improve robustness and without loss of generality we assume
that the database has been quantized beforehand.
Quantization can be defined as the process of mapping a large
set of input values to a (countable) smaller set. For instance, one
way to quantize a continuous attribute is to rely on a discretization
approach converting the continuous attribute (e.g., age) into a dis-
crete attribute (e.g., a set of non-overlapping intervals). Hence, by
tweaking the last bit of the attribute, an individual would be classi-
fied in a totally different age category. Thus even if the produced
view is untraceable, the end result should be useless for any third
party. In such a case, the merchant may accept more easily this fact.
Thus, the quantization process generalizes attributes. Classically,
the generalization is used to guarantee the k-anonymity property.
This step depends on the nature of the database. A trade-off should
be set to ensure that the intervals are small enough to still be useful
but at the same time large enough to make sure that two adjacent
intervals are meaningless with respect to each other. For more
details about possible discretization algorithms, we refer to the
survey of García, Luengo, Sáez, López and Herrera [11].
The example presented earlier can be revisited in this context. For
instance, the age of persons can be discretized into nine categories,
which reduces the domain of the database to 45,001,600 tuples.
Assuming that the adversary knowledge is defined by the same
parameters
, the following bounds on α and β can be
derived
10 |DB|
|D| , 0.2
0.5 ≤ α ≤ 0.967
0.0335 ≥ β ≥ 0.0270 · α
(5)
(6)
The experimentation of Rastogi, Hong and Suciu [18] has been
repeated on this new database. We have chosen the parameters
α = 1
2 and β = 0.015, which lead to a view with 15,007 true tuples
and 673,673 false tuples. All the potential counting queries based on
two or three attributes (among the nine possible ones) have been
used to query both the discretized database and the sanitized one.
Therefore, the queries have either the form (Ai1 = v1, Ai2 = v2), or
the form (Ai1 = v1, Ai2 = v2, Ai3 = v3). In the example, this gives
3,756 and 73,982 queries, respectively.
As presented by Rastogi, Hong and Suciu [18], the buyers have
only access to the sanitized view of the database V and the global
parameters on the solution to estimate the query results on the
database DB. Nevertheless, they can estimate the result of their
queries quite precisely. This is particularly true for counting queries
with large expected values. Let Q be a counting query on D. Then,
Q (DB) can be approximated by a buyer with his personalized view
and the publicly know parameters as:
(cid:16)
(cid:17)
˜Q (DB) =
Q (V ) − βQ (D)
α − β
.
Thus, all the results to these queries Q can be represented by single
points of the form (Q (DB), ˜Q (DB)). The closer a point is to the
diagonal, the better is the estimator, as seen in Figure 1.
Remark 3 (randomization of the fingerprint through one-time pad