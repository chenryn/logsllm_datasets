lines, we also show the percentage of bytes that ﬁnish be-
fore the deadlines in Figure 9(b). Owan outperforms other
approaches more signiﬁcantly on this metric.
It improves
the bytes that ﬁnish before the deadlines by up to 2.03×
than the second best one (Amoeba). Also we can see that
MaxMinFract and Tempus perform better on this metric than
the percentage of transfers that meet their deadlines. This
means they ﬁnish many bytes of a transfer though the entire
transfer does not meet the deadline. This metric is important
to applications that can use the available bytes as they arrive
before the deadlines.
Similar to deadline-unconstrained trafﬁc, we also show
the breakdown of the percentage of transfers that meet dead-
lines in different bins with regard to transfer size. Figure 9(c)
shows the result when the deadline factor is 20. Owan per-
forms better than the other approaches across different bins.
Figure 9(d-f) and (g-i) shows the results of the simulation
results on the ISP and inter-DC topology, respectively. Sim-
ilarly, Owan consistently outperforms other approaches. It
improves the number of transfers that meet their deadlines
by up to 1.13× and 1.08× respectively, and the number of
bytes that ﬁnish before their deadlines by up to 1.46× and
1.33× respectively, as compared to the second best alterna-
tive. Owan also performs well across different transfer sizes.
5.4 Microbenchmarks
We now show some microbenchmarks. All the experi-
ments are performed on the inter-DC topology with deadline-
unconstrained trafﬁc and the load factor being 1 if not other-
wise speciﬁed.
Joint optimization of the optical and network layers: We
show the beneﬁt of jointly optimizing the optical and net-
work layers. For comparison, we develop a greedy algo-
rithm, which ﬁrst builds a network-layer topology based on
trafﬁc demand between every two sites, and then it tries to
ﬁnd a routing conﬁguration that maximizes total throughput
using a similar routine as described in Algorithm 3. In other
words, the greedy algorithm optimizes the optical layer and
the network layer separately. The greediness simpliﬁes the
computation by limiting the search space. Unfortunately as
Figure 10(a) shows, the total throughput is 21% less than the
joint optimization, even if the joint optimization is only an
approximation using simulated annealing. This performance
difference is not incidental: as we have multiple paths for
each ﬂow, the routing conﬁguration is tightly coupled with
the optical conﬁguration. Also, the greedy algorithm does
not try to minimize the number of optical links to change
while the simulated annealing algorithm does.
Consistent network updates: It takes about three to ﬁve
seconds on our testbed to reconﬁgure an optical circuit. Dur-
ing the update of an optical circuit, the circuit goes dark
and cannot carry any trafﬁc. To avoid trafﬁc disruptions,
we use a consistent update scheme in §3.3. To demonstrate
its effectiveness, Figure 10(b) shows the comparison of with
and without the consistent update scheme. Without consis-
tent update, all links are updated simultaneously in one shot
to minimize update completion time. The total throughput
drops 10% during the update, as packets get lost on these
links, affecting the overall TCP performance. With consis-
tent update, we observe no throughput drop during the up-
date process, and we do not observe changes in end-to-end
packet drop rate either.
Breakdown of gains: Owan jointly optimizes network-layer
topology, routing and rate allocation. We use an experiment
to show a breakdown of gains from controlling the three
96
 0 1 2 30.51.01.52.0Factor of ImprovementTraffic Load Factorw.r.t MaxFloww.r.t MaxMinFractw.r.t SWAN 0 1 2 30.51.01.52.0Factor of ImprovementTraffic Load Factorw.r.t MaxFloww.r.t MaxMinFractw.r.t SWAN 0 1 2 30.51.01.52.0Factor of ImprovementTraffic Load Factorw.r.t MaxFloww.r.t MaxMinFractw.r.t SWAN(a) % of transfers that meet deadlines.
(b) % of bytes that meet deadlines.
(c) % of transfers that meet deadlines.
(d) % of transfers that meet deadlines.
(e) % of bytes that meet deadlines.
(f) % of transfers that meet deadlines.
(g) % of transfers that meet deadlines.
(h) % of bytes that meet deadlines.
(i) % of transfers that meet deadlines.
Figure 9: Results for deadline-constrained trafﬁc. (a-c), (d-f), and (g-i) are results of the Internet2 network, ISP net-
work, and inter-DC network, respectively.
parts. Figure 10(c) shows the result of the experiment. In
the experiment, we compare the average transfer comple-
tion time when the system has different levels of control of
the network. All times are normalized by the average trans-
fer completion time when the trafﬁc load factor is 0.5 and
the system has controls of all three parts. In the most basic
scheme, the “rate” line in the ﬁgure, the system only controls
rate allocation. The system cannot reconﬁgure the network-
layer topology, nor can it change routing. It can only adjusts
the sending rates of the transfers. In the second scheme, the
“+rout.” line in the ﬁgure, the system has controls of both
routing and rate allocation. It assigns routing paths and rates
to transfers similar to line 15-25 in Algorithm 3. The third
scheme, the “+topo.” line in the ﬁgure, has controls of all
three parts. As we can see from the ﬁgure, we have lower
average transfer completion time when we have more con-
trol of the network.
Running time and convergence: We use simulated anneal-
ing to ﬁnd a good topology. Since simulated annealing is an
approximation algorithm that performs probabilistic search
for the optimum, the quality of the result is related to its run-
ning time. The longer the algorithm runs, the more states it
can search in the search space and the better the result can
be. In our solution, since we use the current topology as the
initial state of the algorithm, instead of a random topology,
the algorithm starts its search with a reasonable good state.
Since our system runs the algorithm and reconﬁgures the
network every a few minutes, the trafﬁc on the network is un-
likely to change dramatically. Therefore, the algorithm can
quickly ﬁnd a good new topology by starting from the cur-
rent topology and only changing a few links, as compared to
starting from a random topology and spending a lot of time
on ﬁnding a reasonably good topology. Figure 10(d) shows
the performance of our algorithm when we run simulated
annealing for different amounts of time. The performance
is measured by the average transfer completion time. From
the ﬁgure, we can see that the algorithm performs very bad
when the simulated annealing only runs for 20 ms. However,
the algorithm converges quickly, and it only requires about
320 ms to ﬁnd a good topology to signiﬁcantly reduce the
average transfer completion time.
6. RELATED WORK
WAN Trafﬁc Engineering: Trafﬁc engineering is a classic
topic in networking research. Early work focuses on avoid-
ing congestions. Many algorithms are developed to mini-
mize the maximum link utilization under different condi-
tions, such as changing trafﬁc demands and network fail-
ures [25, 26, 27]. There are also efforts on achieving dif-
ferent fairness metrics theoretically and practically [28, 29].
97
 0 20 40 60 80 100 0 10 20 30 40 50% of TransfersDeadline FactorOwanMaxFlow          MaxMinFractSWAN          TempusAmoeba 0 20 40 60 80 100SmallMiddleLargeAll% of TransfersBinsOwanMaxFlowMaxMinFractSWANTempusAmoeba 0 20 40 60 80 100 0 10 20 30 40 50% of TransfersDeadline Factor 0 20 40 60 80 100 0 10 20 30 40 50% of BytesDeadline Factor 0 20 40 60 80 100SmallMiddleLargeAll% of TransfersBins 0 20 40 60 80 100 0 10 20 30 40 50% of TransfersDeadline Factor 0 20 40 60 80 100 0 10 20 30 40 50% of BytesDeadline Factor 0 20 40 60 80 100SmallMiddleLargeAll% of TransfersBins 0 20 40 60 80 100 0 10 20 30 40 50% of TransfersDeadline Factor 0 20 40 60 80 100 0 10 20 30 40 50% of BytesDeadline Factor 0 20 40 60 80 100SmallMiddleLargeAll% of TransfersBins(a) Simulated annealing vs.
the greedy algorithm.
(b) With and without consis-
tent update scheme.
(c) Breakdown of gains.
(d) Impact of running time of
simulated annealing.
Figure 10: Microbenchmark results.
With the emergence of SDN and the ability to direct pro-
gram switches, researchers develop new centralized control
systems, like Google B4 and Microsoft SWAN, to improve
network utilization and its robustness in face of control plane
and data plane failures [1, 2, 30, 31, 32]. Recent work goes
beyond network-wide objectives like network utilization, to
more ﬁne-grained transfer-level objectives, like minimizing
transfer completion time and meeting deadlines [3, 4, 33, 34,
35], and controls not only switches, but also proxies, load
balancers, and DNS servers [36]. Owan follows the trend of
centralized control for WANs. The key feature that differen-
tiates Owan from previous solutions is the joint management
of the optical and network layers, and we show that dynam-
ically reconﬁguring the optical layer can signiﬁcantly.
The routing problem in overlay networks also concerns
two layers [37, 38, 39]. The routing in the underlay net-
work (the network layer in this paper) builds the topology
for the overlay network. However, the overlay and under-
lay networks are usually managed by different parties, and
an overlay network usually traverses multiple ASes and has
unstable end-to-end network performance.
Data-Center Trafﬁc Engineering: Data-center networks
have massive scale in terms of number of switches and hosts.
Most trafﬁc engineering work in data-center networks fo-
cuses on routing elephant ﬂows as it is impractical to deal
with all ﬂows in a centralized manner [40, 41, 42, 43, 44,
45]. To cope with the scalability problem, CONGA designs
a distributed load balancing mechanism and implement it in
switch hardware [46]. Most of these solutions tackle the
routing problem, i.e., choosing a path for a ﬂow or ﬂowlet.
To solve the rate allocation problem, i.e., deciding the rate
for each ﬂow to optimize the ﬂow completion time or the
number of ﬂows that meet deadlines, researchers have de-
veloped a wide range of new ﬂow scheduling and congestion
control algorithms [16, 47, 48, 49, 50, 51, 52, 53]. Some of
them are entirely host-based; others leverage both host and
switch features. There are also works that optimize for a
group of ﬂows, which are important for many big data appli-
cations [20, 21]. Owan has similar objectives as these works,
but the target of Owan is WANs. WANs do not have a struc-
tured topology as FatTree or CLOS in data center networks
(which many algorithms for data-center networks rely on),
and the topology can be changed by reconﬁguring the un-
derlying optical layer.
Besides these works, some solutions propose to provide
bandwidth guarantee to cloud applications and tenants, in
order to provide predictable performance and enforce isola-
tion [54, 55, 56, 57]. In these solutions, requests are formu-
lated as bandwidth reservations between ingress and egress
points. For bulk data transfers, it is more appropriate to for-
mulate requests as volumes of data as in Owan. On the other
hand, bandwidth reservations are also a useful abstraction
for some use cases on the WAN. It is an interesting area of
future work to explore how the reconﬁgurability in the opti-
cal layer can improve bandwidth reservations.
Optical Networks: With the advancements in optical tech-
nology and centralized control, researchers have started to
build centralized production systems to manage the optical
layer on the WAN [14, 15]. Xu et al. [14] present an on-line
system to reconﬁgure the optical circuits given a set of cir-
cuit demands with constraints. Bathula et al. [15] develop
algorithms to compute the minimal set of regenerator con-
centration sites such that any two optical ROADMs have at
least one path available by using the selected sites. In terms
of cross-layer control, early studies present algorithms and
analysis for the joint optimization of the optical and network
layers [58, 59, 60]. They mainly focus on admissible trafﬁc
demand and attempt to optimize for objectives like network
cost and routing hops. Recent work begins to explore build-
ing systems to jointly control the optical and network layers,
such as the DARPA CORONET program [6]. Our work is
built up these efforts and presents the design and implemen-
tation of Owan to jointly control the optical and network lay-
ers and optimize bulk transfers for transfer completion time
and deadlines met.
In terms of data centers, many researchers have proposed
to use optics to boost the network performance. For exam-
ple, Helios, cThrough and OSA use MEMS switches [7, 8,
9]; FireFly uses free-space optics [10]; WaveCube uses WSS
switches [11]. The major objective in these works is to im-
prove the network throughput. By reconﬁguring the topol-
ogy, they can make the network be comparable to a non-
blocking network, while saving on power, cost, and wiring
complexity. Other works use optics to reduce latency [61];
use optics to support multicast [62, 63, 64, 65]; and de-
sign new optical hardware [66, 67, 68]. Differently, Owan
reconﬁgures topologies in the WAN scenario, which uses
ROADMs, regenerators and has the optical reach constraint,
and Owan combines topology reconﬁguration with routing
and rate allocation to optimize transfer-level objectives.
7. CONCLUSION
We present Owan, a new trafﬁc management system that
optimizes bulk transfers on the WAN. Besides controlling
routing and rate allocation, Owan goes one important step
further than prior solutions into the optical layer. It reconﬁg-
98
 0 100 200 300 400 0 2500 5000 7500 10000Throughput (Gbps)Time (s)Simulated AnnealingGreedy 0 5 10 15 20 250246810Throughput (Gbps)Time (second)Consistent UpdateOne Shot Update 0 2 4 6 8 0.5 1 1.5 2Normalized TimeTraffic Load Factorrate+rout.+topo. 1000 1200 1400 1600 18000.020.080.321.285.12Avg. Comp. Time (s)Running Time (s)ures the optical layer in the same time scale as routing and
rate allocation in a centralized manner. We develop efﬁcient
algorithms to compute the optical and routing conﬁgurations
to optimize bulk transfers. Testbed experiments and large-
scale simulations show that Owan completes data transfers
up to 4.45× faster in average and up to 1.36× more ﬂows
meet their deadlines than methods with only network-layer
control. Owan is the ﬁrst step towards software-deﬁned op-
tical WANs. We believe centralized control of the optical
and network layers would have a far-reaching impact on the
theory and practice of network management for WANs.
Acknowledgments We thank our shepherd Hitesh Ballani
and the anonymous reviewers for their feedback. This work