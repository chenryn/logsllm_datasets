AES circuit has depth 50 and thus the online time will not be able
to be less than 3750 ms in this setting.)
we believe that it is clear that our prototype costs several orders of
magnitude less than previous non-massively parallel implementa-
tions, and has the potential to cost much less in the massively paral-
lel setting (since all the expensive steps of the protocol can be done
in parallel). We stress that the ofﬂine/online setting is preferable to
the batch setting since online executions can be run in isolation.
Last, we tested the prototype on a weaker AWS instance, i.e.,
c4.2xlarge, for computation of AES. See Table 7. As expected,
performance is mostly worse than on the stronger instance but for
some parameters they are still very close. This is mainly because of
memory issues, and thus is mostly reﬂected in the ofﬂine stage (our
current implementation of the ofﬂine stage stores many garbled cir-
cuits in memory). Indeed, the online times are almost the same.
Communication in the ofﬂine stage mostly consists of the gar-
bled circuits, whereas the communication in the online stage is
very small. For example, with s = 40, for AES computation with
N = 32, about 260MB are transmitted in the ofﬂine stage and only
about 312KB per online execution; for N = 128, about 698MB are
transmitted in the ofﬂine stage and only about 238 KB per online
execution; for N = 1024, about 3850MB are transmitted in the of-
ﬂine stage and less than 170KB in the online stage. (Recall that
the number of circuits per bucket is larger for N = 32 than for
N = 128,1024, and thus the communication in the online stage is
larger.) For s = 80, these numbers are about double, as expected
since the number of circuits is about double.
Comparison with related work. We focus here on comparing our
results with the ones reported by previous works. We leave the
comprehensive benchmarking of all relevant protocols using simi-
lar hardware, network conﬁguration, and so on to future work.
As discussed in Section 1, the fastest published implementation
of cut-and-choose based 2PC on standard machines (without mas-
sive parallelism) is of [2] which requires more than 6 seconds for a
single secure computation of AES. In, [30, 10], it is shown how to
reduce costs drastically using massive parallelism, requiring only
several tens of ms per 2PC invoked. Note, however, that our pro-
tocol works in the online/ofﬂine setting, while [2, 10] work in the
single-execution setting and [30] works in the batch setting. Still,
Different 2PC protocols, that are not based on the cut-and-choose
technique for garbled circuits, are presented in [26] and [7]. Both
protocols have an ofﬂine stage in which the parties work indepen-
dently of their inputs, and a much shorter online stage in which the
players use their inputs and compute the function of interest. The
cryptographic work required by these protocols during the online
stage is very small (if any), however, both protocols require a num-
ber of interaction rounds that depends on the depth of the circuit
being evaluated.
The overall online stage of [26] costs 4 seconds (for a single
computation) for computing AES, while the ofﬂine is at least 1
second (even when amortized for many computations). For many
computations (135), the total online time is 15 seconds. This gives
a low amortized time, but high latency. The average total running
time (i.e., the sum of the ofﬂine and online timings for a single
AES computation) is at least 1.6 seconds (for all numbers tested in
[26]). In [8], optimizations and improvements were made to [26]
that enables running many AES executions in parallel. The best
results obtained there provide an online time of 9962 ms for 680
AES operations in parallel. This yields a low average cost (about
14 ms per AES), but a high latency. The online time for a single
execution is expected to be similar to [26]. Regarding [7], the cost
of the ofﬂine stage for computing AES is about 156 seconds and
the cost of the online stage (with 50 rounds of communication) is
about 20 ms [31]. However, both [26] and [7] have many rounds
of communication; thus in slower networks (e.g., between different
Amazon regions) they will perform poorly.
We note that in [26] and [7], the ofﬂine stage is independent
of the circuit being evaluated in the online stage, whereas in our
586Number
of buckets
32
128
1024
1 thread
10129
23961
125993
Ofﬂine total
5 threads
6905
15819
82476
9 threads
6310
14539
75879
Number
of buckets
32
128
1024
1 thread
36483
113352
815313
Ofﬂine total
5 threads
35725
111586
778010
9 threads
36039
117650
778235
Table 4: Running times (in ms) of the ofﬂine stage for the AES circuit in LAN conﬁguration for s = 40 in LAN conﬁguration (left)
and WAN conﬁguration (right). The number of circuits per bucket is as in Table 2. (For s = 80, the times are 2-2.5 larger.)
Circuit
Number of buckets
Ofﬂine total Ofﬂine per bucket
AES
SHA-1
32
128
1024
32
128
1024
36039
117650
778235
52463
152509
2936775
1126
919
759
1639
1191
2867
Online time per bucket
9 threads
1 thread
5 threads
171
166
162
194
194
184
164
163
160
185
182
173
163
164
160
176
180
175
Table 5: Running times of AES and SHA-1 in WAN conﬁguration using the parameters of Table 2 (in ms) for s = 40. The roundtrip
between the parties was 75 ms.
protocol, a single circuit is ﬁxed for all computations. Thus, they
are better suited for settings in which the function to be computed
is not known ahead of times. In addition, [7] has two signiﬁcant
advantages over our protocol: (1) it can work with more than two
parties, and (2) it can work with arithmetic circuits, which for some
types of computations is more efﬁcient.
7. CONCLUSION
The ﬁrst evaluation of cut-and-choose based 2PC was presented
in [27] in 2009. It required 1114 seconds for a single computation
of AES. Since then, many algorithmic and engineering improve-
ments have been presented, gradually reducing the cost of AES
computation to 264 seconds [29], to 6 seconds [2], and to even
1.4 seconds [17] and 0.46 seconds [10] when using massive paral-
lelism. This work continues this line of work and shows how the
costs can be further reduced using recent and new algorithmic im-
provements (though in a slightly different, yet very natural setting).
When preprocessing 1024 executions, the average online time is
less than 10 ms and the amortized ofﬂine time is only 74 ms. As
we use most state-of-the-art techniques (e.g., the protocol of [23],
the garbling scheme of [4], and the OT extension of [3]), these tim-
ings are the result of incredible work carried out by the community
on all aspects of the protocol, together with our new consistency
check. We ﬁnd these results to be exciting as they are more than
four orders of magnitude better than the one of [27], carried out just
6 years ago.
We believe that our results can be further improved using better
multithreading, and are currently working on modifying our proto-
type to use multiple cores and even machines in parallel (in a sim-
ilar manner to the work of [17]). We leave the goal of optimizing
and evaluating our protocol for GPUs for future work.
Acknowledgements. We would like to thank Moriya Farbstein,
Meital Levy and Asaf Cohen for the implementation of the protocol
and its extensive performance evaluation.
8. REFERENCES
[1] SCAPI, 2015. http://crypto.biu.ac.il/scapi and
https://github.com/cryptobiu/scapi.
[2] A. Afshar, P. Mohassel, B. Pinkas, and B. Riva.
Non-interactive secure computation based on
cut-and-choose. In EUROCRYPT 2014, Springer (LNCS
8441), pages 387–404, 2014.
[3] G. Asharov, Y. Lindell, T. Schneier, and M. Zohner. More
efﬁcient oblivious transfer extensions with security for
malicious adversaries. In EUROCRYPT 2015, Springer
(LNCS 9056), pages 673–701, 2015.
[4] M. Bellare, V. T. Hoang, S. Keelveedhi, and P. Rogaway.
Efﬁcient garbling from a ﬁxed-key blockcipher. In IEEE
Symposium of Security and Privacy, 2013.
[5] M. Bellare, V. T. Hoang, and P. Rogaway. Adaptively secure
garbling with applications to one-time programs and secure
outsourcing. In ASIACRYPT 2012, Springer (LNCS 7658),
pages 134–153, 2012.
[6] S. G. Choi, J. Katz, R. Kumaresan, and H.-S. Zhou. On the
security of the “free-XOR” technique. In TCC, Springer
(LNCS 7194), pages 39–53, 2012.
[7] I. Damgård, V. Pastro, N. P. Smart, and S. Zakarias.
Multiparty computation from somewhat homomorphic
encryption. In CRYPTO 2012, Springer (LNCS 7417), pages
643–662, 2012.
[8] I. Damgård, R. Lauritsen, and T. Toft. An empirical study
and some improvements of the minimac protocol for secure
computation. In SCN 2014, Springer (LNCS 8642), pages
398–415, 2014.
[9] Y. Ejgenberg, M. Farbstein, M. Levy, and Y. Lindell. SCAPI:
The secure computation application programming interface.
Cryptology ePrint Archive, Report 2012/629, 2012.
http://eprint.iacr.org/.
[10] T. K. Frederiksen, T. P. Jakobsen, and J. B. Nielsen. Faster
maliciously secure two-party computation using the GPU.
Cryptology ePrint Archive, Report 2014/270, 2014.
http://eprint.iacr.org/.
[11] T. K. Frederiksen and J. B. Nielsen. Fast and maliciously
secure two-party computation using the GPU. In ACNS 2013,
Springer (LNCS 7954), pages 339–356, 2013.
[12] O. Goldreich and E. Kushilevitz. A perfect zero-knowledge
proof system for a problem equivalent to the discrete
logarithm. In Journal of Cryptology, 6(2):97–116, 1993.
[13] O. Goldreich, S. Micali, and A. Wigderson. How to play any
mental game. In the 19th ACM STOC, pages 218–229, 1987.
[14] Y. Huang, J. Katz, and D. Evans. Efﬁcient secure two-party
computation using symmetric cut-and-choose. In CRYPTO
2013, Springer (LNCS 8043), pages 18–35, 2013.
587Circuit
Number of buckets
Ofﬂine total Ofﬂine per bucket
AES
SHA-1
32
128
1024
32
128
1024
54467
165239
1102191
89860
314239
1412681
1702
1291
1076
2808
2455
1380
Online time per bucket
1 thread
5 threads
9 threads
204
190
178
268
236
213
180
172
167
227
210
196