acterize clusters of domain names (as opposed to single
domains) related to malicious ﬂux services, and we
introduce some additional new features. We divided our
feature set into two groups, namely “passive” features
and “active” features. We call “passive” those features
that can be directly extracted from the information
collected by passively monitoring the DNS queries
from our RDNS sensors. On the other hand, “active”
features need some additional external information to
be computed (e.g., information extracted from whois
queries, geolocation mapping of IP addresses, BGP
announcement data, etc.). For each cluster of domains
obtained as described in Section II-E, and related to an
epoch Em, we compute the following features:
“Passive” Features:
φ1
φ2
φ3
φ4
φ5
Number of resolved IPs. This is the overall number of
distinct resolved IP addresses ever observed during epoch
Em for all the domains in a cluster.
Number of domains. This is the total number of distinct
domain names in a cluster.
Avg. TTL per domain. Average TTL of the domains in
a cluster.
Network preﬁx diversity This is the ratio between the
number of distinct
/16 network preﬁxes and the total
number of IPs. This feature is used to estimate the degree
of scattering of IP addresses among different networks,
and represents a reasonable approximation of “active”
features φ7 and φ8 (explained below).
Number of domains per network. Number of distinct
domain names that resolved to at least one of the IP
addresses in the considered cluster, during all the previous
epochs E1, E2, ... until the considered epoch Em. In
spite of the high variability of ﬂux domain names, ﬂux
φ6
φ7
φ10
φ11
φ12
networks are rather stable and persistent [7]. Thus, the
same ﬂux agents will be used by many distinct domain
names, during the time. This feature measures how many
domains can be associated to the IPs (i.e., the ﬂux agents)
in a cluster, throughout different epochs.
IP Growth Ratio. This represents the average num-
ber of new IP addresses “discovered” per each DNS
response related to any domain in a cluster. Namely,
1
|Ci| · Pd∈Ci
|R(d)|
Q(d) .
“Active” Features:
Autonomous System (AS) diversity, φ8 BGP preﬁx
diversity, φ9 Organization diversity. We measure the
ratio between the number of distinct ASs where the IPs
of a cluster reside and the total number of resolved IPs.
Also, we compute similar ratios for distinct organization
names and distinct BGP preﬁxes the IPs in the cluster
belong to.
Country Code diversity. For each IP in a cluster, we
map it to its geographical location and compute the ratio
between the number of distinct countries across which the
IPs are scattered and the total number of IPs.
Dynamic IP ratio. The bot-compromised machines that
constitute malicious ﬂux services are mostly home-user
machines. In order to estimate whether an IP is related to
a home-user machine, we perform a reverse (type PTR)
DNS lookup for each IP, and we look for keyworks such
as “dhcp”, “dsl”, “dial-up”, etc., in the DNS response
to identify machines that use a dynamic (as opposed to
static) IP address. We then compute the ratio between the
(estimated) number of dynamic IPs in the cluster and the
total number of IPs.
Average Uptime Index. This feature is obtained by
actively probing each IP in a cluster about six times
a day for a predeﬁned number of days (e.g. 5 days),
and attempting to establish TCP connections on ports
80/53/443, i.e., HTTP/DNS/HTTPS services3. If the host
accepts to establish the TCP connection, it is considered
up, otherwise it is considered down. An estimate of the
uptime of each IP is given by the ratio between number
of times the IP is found to be up versus the total number
of probes. Feature φ12 is computed as the average uptime
for the IPs in a cluster.
After measuring the features described above, we
employ the popular C4.5 decision-tree classiﬁer [10] to
automatically classify a cluster Ci as either malicious
ﬂux service or legitimate/non-ﬂux service. The reasons
for using a decision-tree classiﬁer are as follows: a)
decision-trees are efﬁcient and have been shown to
be accurate in a variety of classiﬁcation tasks; b) the
decision-tree built during training can be easily inter-
preted to determine what are the most discriminant
features that allow us to distinguish between malicious
ﬂux services and legitimate/non-ﬂux services; c) the
C4.5 is able to automatically prune the features that
are not useful, and potentially create noise instead of
increasing classiﬁcation accuracy [10]. We ﬁrst train
the C4.5 classiﬁer on a training dataset containing a
number of labeled clusters related to malicious ﬂux
3We use TCP instead of UDP for DNS probing, because most off-
the-shelf DNS software are designed to listen on port 53 for both TCP
and UDP communications.
316
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:12:17 UTC from IEEE Xplore.  Restrictions apply. 
services and clusters related to legitimate/non-ﬂux ser-
vices. Afterwards, the classiﬁer can be used “online” to
classify the clusters obtained at the end of each epoch E
from the data collected at each RDNS sensor, as shown
in Figure 1. The details of how we obtained the labeled
training dataset of malicious ﬂux and legitimate clusters
and estimated the accuracy of our service classiﬁer are
reported in Section III.
III. EXPERIMENTS
In this Section we present the results obtained with
our malicious ﬂux network detection system. All the
experiments related to the clustering of candidate ﬂux
domains and classiﬁcation of ﬂux service networks were
conducted on a 4-core 3GHz Intel Xeon Machine with
16GB or memory. However, because the machine was
shared with other researchers, we constrained ourselves
to using a maximum of 5GB of RAM for our experi-
ments.
A. Collecting Recursive DNS Trafﬁc
We placed two trafﬁc sensors in front of two different
RDNS servers of a large north American Internet Ser-
vice Provider (ISP). These two sensors monitored the
RDNS trafﬁc coming from users located in the north-
eastern and north-central United States, respectively.
Overall, the sensors monitored the live RDNS trafﬁc
generated by more than 4 million users for a period
of 45 days, between March 1 and April 14, 2009.
During this period, we observed an average of about 1.3
billion DNS queries of type A and CNAME per sensor.
Overall we monitored over 2.5 billion DNS queries per
day related to hundreds of millions of distinct domain
names. The trafﬁc collected at each sensor is reduced
using ﬁlters F1 and F2, as shown in Figure 1 and
described in Section II. We set the epoch E to be one
day. The overwhelming trafﬁc volume monitored by the
RDNS sensors was effectively reduced from more than
109 DNS queries for tens of millions of distinct domain
names, to an average of 4 · 104 to 6 · 104 candidate ﬂux
domain names per day (depending on the sensor we
consider).
B. Clustering Candidate Flux Domains
At the end of each epoch, the candidate ﬂux domains
extracted by the RDNS sensors are transfered to our
Detector machine, where they undergo a clustering
process. Before applying domain clustering we further
narrow down the number of candidate domain names
using a set of ﬁltering rules reported in Appendix.
This further ﬁltering step is optional and we mainly
use it to reduce the amount of memory required by
the clustering algorithm. These ﬁltering rules may be
tuned (or eliminated) to “accept” more domains for
the clustering step if more memory was available. This
additional ﬁlter step reduces the average number of
candidate ﬂux domains to be clustered of almost an
order of magnitude (from 4·104 to 6·104, to about 8·103
domains per sensor). It is worth noting, though, that
similarly to ﬁlter F1 and F2 (see Section II) the ﬁltering
rules reported in Appendix are still very conservative.
In fact, from our experimental results we noticed that
even after this further ﬁltering, the list of candidate
domain names still included all the domain names most
likely related to malicious ﬂux services, along with
domain names related to legitimate CDNs, pools of NTP
servers, and other legitimate services.
Once ﬁltering is completed, we apply a single-linkage
hierarchical clustering algorithm [5, 6] to group together
domains that belong to the same network, as described
in Section II-E. After transfering the data collected from
the RDNS sensors to our detection system, the time
needed for the clustering process was around 30 to
40 minutes per day and per each sensor. The hight of
the dendrogram cut was chosen to be h = 0.6. This
choice is motivated by the fact that we want to cut
the dendrogram at an height within the largest plateau
region (see Section II-E). In particular, by plotting the
cluster analysis graphs similar to the one reported in
Figure 2 for different days, we noticed that the value
h = 0.6 (on the x-axes) was always located around
the end of the largest plateau region and provided high
quality clusters. Using h = 0.6 we obtained an average
of about 4,000 domain clusters per day.
Clustering is a completely unsupervised process [5,
6], and automatically verifying the results is usually
very hard if at all possible. Therefore, with the help of
a graphical interface that we developed, we manually
veriﬁed the quality of the results for a subset of the
clusters obtained every day. In particular, in order to
assess the quality of the domain clusters, we manu-
ally veriﬁed that the domain names in a cluster were
actually related to the same “service” (e.g., the same
CDN, the same malicious ﬂux network, the same NTP
pool, etc.). In many cases this manual evaluation was
straightforward. For example, our clustering algorithm
was able to correctly identify clusters of domain names
belonging to a malicious ﬂux service that was being
used for phishing facebook login credentials. In this
case the domain names advertised by the botmaster all
shared very strong structural similarities because they all
started with “login.facebook”, contained a string of the
form “personalid-RAND”, where “RAND” is a pseudo
317
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:12:17 UTC from IEEE Xplore.  Restrictions apply. 
random string, and ended with “.com”. Also, our IP-
based clustering process (see Section II-E) was able to
correctly group together domain names related to the
NTP server pool in Europe and separate them from the
group of domains related to the NTP pool in North
America, the pool of domains related to Oceania, etc.
The domain names related to the NTP pools in different
regions of the world can visually be distinguished
from each other. Therefore, it was easy to verify that
domains such as 0.europe.pool.ntp.org, uk.pool.ntp.org,
fr.pool.ntp.org were all correctly grouped together, and
separated from the cluster containing au.pool.ntp.org
and oceania.pool.ntp.org, for example. In other cases
we had to conﬁrm the correctness of our clusters by
manually probing the clustered domain names and ﬁnd-
ing relations between the obtained resolved IPs and the
services (e.g., web pages) provided through them.
C. Evaluation of the Service Classiﬁer
In this section we explain the results related to the
classiﬁcation of clusters of domains into either mali-
cious ﬂux services or legitimate/non-ﬂux services. As
described in Section II-F, we use a statistical supervised
learning approach to build a service classiﬁer. In order
to use a supervised learning approach, we ﬁrst need
to generate a dataset of labeled clusters (the “ground-
truth”) which can be used to train our statistical clas-
siﬁer, and evaluate its classiﬁcation accuracy. We ﬁrst
describe how this labeled dataset was generated, and
then motivate why the different statistical features used
by the classiﬁer, and described in detail in Section II-F,
allow us to accurately detect malicious ﬂux service
networks.
In order to construct
the labeled dataset for our
experiments, we manually inspected and labeled a fairly
large number of clusters of domains generated by the
clustering process described in Section II-E. To make
the labeling process less time consuming, we developed
a graphical interface that allows us to rank clusters of
domains according to different features. For example,
our interface allows us to rank all the clusters according
to their network preﬁx diversity (feature φ4), the cu-
mulative number of distinct resolved IPs (feature φ1),
the IP growth ratio (feature φ6), etc. In addition, our
graphical interface allows us to inspect several other
properties of the clusters, such as CNAME entries
collected from DNS responses,
the content of Web
pages obtained by contacting a sample of resolved IPs
from a cluster, information gathered from queries to
whois and search engines, etc.
As we discussed in Section II-F, we use the C4.5
decision tree classiﬁer to automatically classify between
All Features
Passive Features
φ6, φ3, φ5
AUC
0.992 (0.003)
0.993 (0.005)
0.989 (0.006)
DR
99.7% (0.36)
99.4% (0.53)
99.3% (0.49)
FP
0.3% (0.36)
0.6% (0.53)
0.7% (0.49)
Table I: Classiﬁcation performance computed using 5-
fold cross-validation. AUC=Area Under the ROC Curve;
DR=Detection Rate; FP=False Positive Rate. The numbers
between parenthesis represent the standard deviation of
each measure.
clusters of domains related to malicious ﬂux networks
and clusters related to legitimate or non-ﬂux networks.
We discuss the details of how we trained and tested
our classiﬁer later in this section. Here it is important
to notice that one of the reasons we chose the C4.5
classiﬁer is that the decision tree obtained after the
training period is relatively easy to interpret [10]. In
particular, we noticed that when using the “passive” fea-
tures described in Section II-F for training, the classiﬁer
indicated that the IP Growth Ratio (feature φ6) is the
most discriminant feature (i.e., the root of the decision
tree). This conﬁrms the fact
the rapid change
of the resolved IPs of ﬂux domains is a distinctive
characteristic of malicious ﬂux service networks.
that