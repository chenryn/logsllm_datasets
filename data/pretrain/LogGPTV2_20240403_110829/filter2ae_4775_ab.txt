至此 我们的采样数据完成了，接下来是创建一个识别模型
#### 创建识别模型
这里我们不需要自己创建识别模型，因为我们用的就是tensorflow基于COCO数据集提供的几种识别模型
[下载地址](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md
"模型下载地址")
  * ssd_mobilenet_v1_coco
  * ssd_inception_v2_coco
  * faster_rcnn_inception_v2_coco
  * faster_rcnn_resnet50_coco 
  * faster_rcnn_resnet50_lowproposals_coco
  * rfcn_resnet101_coco
  * faster_rcnn_resnet101_coco
  * faster_rcnn_resnet101_lowproposals_coco
  * faster_rcnn_inception_resnet_v2_atrous_coco
  * faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco
  * faster_rcnn_nas 
  * faster_rcnn_nas_lowproposals_coco 
这里我们选择最快的 **ssd_mobilenet_v1_coco**  
下载回来后解压,文件列表如下
    saved_model[dir]
    checkpoint
    frozen_inference_graph.pb
    model.ckpt.data-00000-of-00001
    model.ckpt.index
    model.ckpt.meta
这是一个识别模型最终的输出结果。我们最后训练也会导出同样的文件结构。  
其中 **frozen_inference_graph.pb** 就是训练结果，里面已经包含了多种的识别。
`model.ckpt` 前缀的文件就是训练模型，我们把
  * **model.ckpt.data-00000-of-00001**
  * **model.ckpt.index**
  * **model.ckpt.meta**
三个文件放到 **objectdecting_wechatjump\modle\train_set** 目录下作为我们训练的初始模型。
  * 有网站说 model.ckpt.data-00000-of-00001 要改为 model.ckpt。 这里不需要改。新版的object_detection可以直接读，改了反而出错 
在train_set 新建 **object-detection.pbtxt**  
仿照 **models\research\object_detection\data** 下的pbtxt格式  
写上刚才的物体标签
    item {
      id: 1
      name: 'movtarget'
    }
    item {
      id: 2
      name: 'jumptarget'
    }
保存为 object-detection.pbtxt 也放到 objectdecting_wechatjump\modle\train_set 目录下。
到models\research\object_detection\samples\configs 目录下 把训练配置参数配置文件
**ssd_mobilenet_v1_pets.config** 复制到
**objectdecting_wechatjump\modle\train_set** 下
  * 如果你不是选 ssd_mobilenet_v1_coco 训练模型 那得复制对应的 训练参数文件
修改以下参数
  * num_classes: 37 -> 2 多少个训练物体就有多少个
  * train_input_reader
    * input_path :train_record路径
    * label_map_path pbtxt文件路径
  * eval_input_reader 
    * input_path
    * label_map_path pbtxt文件路径
    * num_readers: 3 有多少个测试参数就写多少个 本来要写34 但是为了稳妥 改成3.慢慢加
本来此处，我们的训练模型已经配置完成，可以进入下一步的训练阶段。  
但实际上，开始训练的时候往往训练一阵子就内存耗光直接奔溃了程序，无法继续。  
查阅了好多资料和源码后，最终发现配置项中需要添加和修改如下参数：  
在 train_config: 中
  * 添加 batch_queue_capacity: 2
  * 添加 prefetch_queue_capacity: 2
  * 修改 batch_size的大小 
  * batch_queue_capacity，prefetch_queue_capacity可以慢慢增加
  * batch_size 原本是24，在我的祖传970的4G显存上只能写12个 
  * 这可能是由于我训练的图片是1080*1920的 
  * SSD原本的训练集好像最大 600*600 。我记得某一篇文档上说过，而且他们训练使用Titan V 
至此，辛苦的活都做完了。接下来就是训练模型阶段。
## 训练模型
我们先来看一下当前目录的情况
我们的识别框架基本成型，训练模型非常简单，直接调用原生的训练文件train.py即可
执行 python models/research/object_detection/train.py
  * 几乎所有参数 需要用--使用，例如 --logtostderr
  * 参数 
    * logtostderr 为空即可 
    * pipeline_config_path : 训练配置文件 
      * objectdecting/modle/train_set/ssd_mobilenet_v1_pets.config 
    * train_dir=objectdecting/modle/train 训练目录
开始后会显示步数和lost信息
使用 tensorboard --logdir="objectdecting_wechatjump/modle/train" 可以看到界面的训练情况
在目录 objectdecting/modle/train 下 我们已经可以看到模型生成了
  * 一开始的数字是 model.ckpt-0000 
  * 训练可以随时停止 
  * 重新开始的话 tensorflow会读取最新的训练模型开始
  * 每隔一段时间会记录一个训练模型，model.ckpt-XXXX 不同就是不同的模型。
  * 我们最终会根据某一个训练模型 model.ckpt-XXXX 导出我们的模型 
在我的970训练了1个多小时后，步数抵达到了24425，来试试导出模型 测试一下
## 导出模型和验证
把 models\research\object_detection\sexport_inference_graph.py的导出文件 拷贝到  
objectdecting_wechatjump目录下 。  
执行 python export_inference_graph.py  
参数
  * input_type:image_tensor 
  * pipeline_config_path 训练模型参数文件
    * objectdecting_wechatjump/modle/train_set/ssd_mobilenet_v1_pets.config 
  * trained_checkpoint_prefix 训练中的模型 这里选一个最大数字就行 :
  * objectdecting_wechatjump\modle\train\model.ckpt-24425" 
  * output_directory 模型导出目录 
    * objectdecting_wechatjump\modle\result
导出完成后，如图，和我们下载的ssd_mobilenet_v1的模型一样的结构
接下来我们写一下验证文档，总体思路是
  * 读取模型
  * 读取设置文件
  * 读取图片
  * 验证 
保存为checkmodel.py 。 具体我就不贴代码了
，稍后会在我的github上同步。[github.com/wstart](github.com/wstart)
测试结果如下
基本上完整识别了所有的目标。只需要取Y轴最高的jumptarget和movtarget的中心点，然后通过时间计算系数，就可以完美的跳了。
最高纪录好像22000，后来就停了，不过微信已经把我加入黑名单了，没办法更新分数。
## 总结
  * 使用tensorflow物体识别可以快速定位移动物体。但是不是最后的一步，定位到物体后还需要检测一下物体是否标准，再去确定中心点的位置。否则很容易因为识别误差问题导致计算中心点识别导致崩盘。
  * 要获取大量的图样，前期需要采集足够多的样本,训练的进度才高。除了一开始的基础框架要跳的足够远以外，起码要500以上，才会出现小圆点，还可以通过破解小程序包，修改源代码来给自己生成奇葩的样本。
  * tensorflow使用的属于 **RCNN** 这种算法还是源于CNN。原理可以参考 [使用TensorFlow自动识别验证码（三）--- CNN模型的基础知识概述以及模型优化](https://xianzhi.aliyun.com/forum/topic/1822)
  * 最新的物体检测算法是YOLO（You only look once），号称实时物体检测，等待测试。环境部署十分简单。 等下一次小游戏上线再测试。
  * 后续代码 测试图 模型等会更新到我的github上， [wechat_AlphaJump](https://github.com/wstart/wechat_AlphaJump "wechat_AlphaJump")