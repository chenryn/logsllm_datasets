: – LocationObject(h),
HEAPPTSTO(h, "reload", h0),
CALLS(i, h0).
: – LocationObject(h),
HEAPPTSTO(h, "replace", h0),
CALLS(i, h0).
Figure 13: Example of a global namespace pollution violation
(Section 4.5.2) in a Live widget.
Function window.open is another form of redirects, as the
following query shows:
Query output: WindowOpen(i : I )
WindowOpen(i)
: – WindowObject(h),
HEAPPTSTO(h, "open", h0),
CALLS(i, h0).
4.5 Host-speciﬁc Policies
The policies we have discussed thus far have been rela-
tively generic. In this section, we give examples of poli-
cies that are speciﬁc to the host site they reside on.
4.5.1 No XMLHttpRequest Use in Live Widgets
The ﬁrst policy of this sort comes directly from the Live
Web Widget Developer Checklist [34]. Among other
rules, they disallow the use of XMLHttpRequest object
in favor of function Web.Network.createRequest. The
latter makes sure that the network requests are properly
proxied so they can work cross-domain:
Query output: XMLHttpRequest(i : I )
XMLHttpRequest(i) : – GlobalSym("XMLHttpRequest", h),
CALLS(i, h).
Query output: ActiveXExecute(i : I )
ActiveXObjectCalls(i)
ShellExecuteCalls(i)
: – GlobalSym("ActiveXObject", h0), CALLS(i, h0).
: –
PTSTO("global", h1), HEAPPTSTO(h1, "System", h2),
HEAPPTSTO(h2, "Shell", h3), HEAPPTSTO(h3, "execute", h4), CALLS(i, h4).
ActiveXExecute(i)
: – ActiveXObjectCalls(i), CALLRET(i, v), PTSTO(v, h),
HEAPPTSTO(h, _, m), CALLS(i?, m), CALLRET(i?, r), PTSTO(r, h?),
ShellExecuteCalls(i0), ACTUAL(i0, _, v0), PTSTO(v0, h?).
Figure 14: Query for ﬁnding information ﬂow violations in Vista Sidebar widgets.
4.5.2 Global Namespace Pollution in Live Widgets
Because web widgets can be deployed on a page with
other widgets running within the same JavaScript inter-
preter, polluting the global namespace, leading to name
clashes and unpredictable behavior. This is why hosting
providers such as Facebook, Yahoo!, Live, etc. strongly
discourage pollution of the global namespace, favoring a
module or a namespace approach instead [11] that avoids
name collision. We can easily prevent stores to the global
scope:
Query output: GlobalStore(h : H )
GlobalStore(h)
: –
PTSTO("global", g),
HEAPPTSTO(g, _, h).
An example of a violation of this policy from a
Live.com widget is shown in Figure 13. Because the
same widget can be deployed twice within the same in-
terpreter scope with different values of SearchTag, this
can lead to a data race on the globally declared variable
SearchTagStr.
Note that our analysis approach is radically different
from proposals that advocate language restrictions such
as AdSafe or Cajita [12, 13, 29] to protect access to the
global object. The difﬁculty those techniques have to
overcome is that the this identiﬁer in the global scope
will point to the global object. However, disallowing
this completely makes object-oriented programming dif-
ﬁcult. With the whole-program analysis GATEKEEPER
implements, we do not have this problem. We are able
to distinguish references to this that point to the global
object (aliased with the global variable) from a local ref-
erence to this within a function.
4.5.3 Tainting Data in Sidebar Widgets
This policy ensures that data from ActiveX controls that
may be instantiated by a Sidebar widget does not get
passed into System.Shell.execute for direct execution on
the user’s machine. This is because it is common for Ac-
tiveX controls to retrieve unsanitized network data, which
is how a published RSS Sidebar exploit operates [27].
There, data obtained from an ActiveX-based RSS control
was assigned directly to the innerHTML ﬁeld withing a
widget, allowing a cross-site scripting exploit. What we
are looking for is demonstrated by the pattern:
var o = new ActiveXObject();
var x = o.m();
System.Shell.Execute(x);
The Datalog query in Figure 14 looks for instances where
the tainted result of a call to method m on an ActiveX ob-
ject is directly passed as an argument to the “sink” func-
tion System.Shell.Execute.
Auxiliary
queries
look for
ActiveXObjectCalls
and
ShellExecuteCalls
source and sink calls
and ShellExecuteCalls ties all the constraints together,
effectively matching the call pattern described above.
As previously shown for the case of Java information
ﬂow [23], similar queries may be used to ﬁnd information
ﬂow violations that involve cookie stealing and location
resetting, as described in Chugh et al. [10].
5 Experimental Results
For our experiments, we have downloaded a large num-
ber of widgets from widget hosting sites’ widget galleries.
As mentioned before, we have experimented with widgets
from Live.com, the Vista Sidebar, and Google. We auto-
mated the download process to save widgets locally for
analysis. Once downloaded, we parsed through each wid-
get’s manifesto to determine where the relevant JavaScript
code resides. This process was slightly different across
the widget hosts. In particular, Google widgets tended to
embed their JavaScript in HTML, which required us to
develop a limited-purpose HTML parser. In the Sidebar
case, we had to extract the relevant JavaScript code out of
an archive. At the end of this process, we ended up with a
total of 8,379 JavaScript ﬁles to analyze.
Figure 15 provides aggregate statistics for the wid-
gets we used as benchmarks. For each widget source,
Avg.
Widget counts
Widget Source LOC Count
2,707
Live.com
4,501
Vista sidebar
Google.com/ig
1,171
105
261
137
JavaScriptGK
97%
2,643
643
65% 1,767
2,946
962
82%
768
JavaScriptSAFE
23%
39%
65%
Figure 15: Aggregate statistics for widgets from Live por-
tal, Windows Sidebar, and Google portal widget repositories
(columns 2–3). Information about widget distribution for dif-
ferent JavaScript language subsets (columns 4–7).
function MM_preloadImages() {
var d=m_Doc;
if(d.images){
if(!d.MM_p) d.MM_p=new Array();
var i,j=d.MM_p.length,
a=MM_preloadImages.arguments;
for(i=0; i<a.length; i++)
if (a[i].indexOf("#")!=0){
d.MM_p[j]=new Image;
d.MM_p[j++].src=a[i];
}
}
}
Figure 18: False positives in common.js from JustMusic.FM.
cells blank. To validate the precision of our analysis, we
have examined all violations reported by our policies. For
examination, GATEKEEPER output was cross-referenced
with widget sources. Luckily for us, most of our query re-
sults were easy to spot-check by looking at one or two
lines of corresponding source code, which made result
checking a relatively quick task. Encouragingly, for most
inputs, GATEKEEPER was quite precise.
5.2 False Positives
We should point out that a conservative analysis such as
GATEKEEPER is inherently imprecise. Two main sources
of false positives in our formulation are prototype han-
dling and arrays. Only two widgets out of over 6,000 ana-
lyzed ﬁles in the JavaScriptGK subset lead to false positives
in our experiments. Almost all false positive reports come
from the Sidebar widget, JustMusic.FM, ﬁle common.js.
Because of our handling of arrays, the analysis conserv-
atively concludes that certain heap-allocated objects can
reach many others by following any element of array a,
as shown in Figure 18. In fact, this example is contains a
number of features that are difﬁcult to analyze statically:
array aliasing, the use of arguments array, as well as ar-
ray element loads and stores, so it is not entirely surprising
that their combination leads to imprecision.
It is common for a single imprecision within static
analysis to create numerous “cascading” false positive
reports. This is the case here as well. Luckily, it is
possible to group cascading reports together in order to
avoid overwhelming the user with false positives caused
by a single imprecision. This imprecision in turn affects
FrozenViolation and LocationAssign queries leading to
many very similar reports. A total of 113 false positives
are reported, but luckily they affect only two widgets.
5.3 Analysis Running Times
Our implementation uses a publicly available declarative
analysis engine provided by bddbddb [32]. This is a
Figure 17: Histogram showing GATEKEEPER processing times.
we specify the total number of widgets we managed
to obtain in column 2. Column 3 shows the average
lines-of-code count for every widget.
In general, Side-
bar widgets tend to be longer and more involved than
their Web counterparts, as reﬂected in the average line
of code metric. Note that in addition to every widget’s
code, at the time of policy checking, we also prepend
the native environment constructed as described in Sec-
tion 3.4. The native environment constitutes 270 lines of
non-comment JavaScript code (127 for specifying the the
browser embedding and 143 for specifying built-in ob-
jects such as Array and Date).
5.1 Result Summary
A summary of our experimental results in presented in
Figure 16. For each policy described in Section 4, we
show the the total number of violations across 8,379
benchmarks, and the number of violating benchmarks.
The latter two may be different because there could be
several violations of a particular query per widget. We
also show the percentage of benchmarks for which we ﬁnd
policy violations. As can be seen from the table, overall,
policy violations are quite uncommon, with only several
percent of widgets affected in each case. Overall, a total
of 1,341 policy violations are reported.
As explained in Section 4.5, we only ran those policies
on the appropriate subset of widgets, leaving other table
p0%10%20%30%40%50%60%70%80%90%100%05001,0001,5002,0002,5003,0003,5004,0004,5001234567891011121314151617181920MoreAnalysis time (seconds)Cumulative %numberof widgetsanalysis time, in secondsLIVE WIDGETS
VISTA SIDEBAR
GOOGLE WIDGETS
Query
Section Viol. Affected % FP Affected Viol. Affected % FP Affected Viol. Affected % FP Affected
AlertCalls(i : I)
FrozenViolation(v : V )
DocumentWrite(i : I)
LocationAssign(v : V )
LocationChange(i : I)
WindowOpen(i : I)
XMLHttpRequest(i : I)
GlobalStore(v : V )
ActiveXExecute(i : I)
4.1
4.2
4.3
4.4
4.4
4.4
4.5
4.5
4.5
54
3
5
3
3
50
1
136
—
0
29 1.1
0
3 0.1
0
1 0.0
2
3 0.1
0
3 0.1
0
22 0.9
0
1 0.0
45 1.7
0
— — —
161
0
143
0
175
0
157
1
21
0
182
0
0 —
0 —
—
0
84 2.9
0
52 1.5 94
0
75 1.7
109 3.8 15
1
20 0.7
87 3.0
1
— — —
— — —
0
0
0
57
0
1
1
158
0
9
1
3
1
19
1
— —
— —
0 —
0
35 3.6
0
1 0.1
0
88 8.1
0
9 0.7
0
3 0.3
0
14 1.5
— — —
— — —
— — —
0
0
0
0
0
0
—
—
—
Figure 16: Experimental result summary for nine policies described in Section 4. Because some policies are host-speciﬁc, we only
run them on a subset of widgets. “—” indicates experiments that are not applicable.
Number of instrumented ﬁles
Instrumentation points per ﬁle
Estimated overhead
Live
2,000
1.74
40%
Sidebar Google
194
5.63
73%
1,179
8.86
65%
Figure 19: Instrumentation statistics.
highly optimized BDD-based solver for Datalog queries
used for static analysis in the past. Because repeatedly
starting bddbddb is inefﬁcient we perform both the points-
to analysis and run our Datalog queries corresponding to
the policies in Section 4 as part of one run for each widget.
Our analysis is quite scalable in practice, as shown in
Figure 17. This histogram shows the distribution of analy-
sis time, in seconds. These results were obtained on a
Pentium Core 2 duo 3 GHz machine with 4 GB of mem-
ory, running Microsoft Vista SP1. Note that the analysis
time includes the JavaScript parsing time, the normaliza-
tion time, the points-to analysis time, and the time to run
all nine policies. For the vast majority of widgets, the
analysis time is under 4 seconds, as shown by the cumula-
tive percentage curve in the ﬁgure. The bddbddb-based
approach has been shown to scale to much larger pro-
grams — up to 500,000 lines of code — in the past [32], so
we are conﬁdent that we should be able to scale to larger
codebases in GATEKEEPER as well.
5.4 Runtime Instrumentation
Programs outside of the JavaScriptSAFE language subset
but within the JavaScriptGK language subset require instru-
mentation. Figure 19 summarizes data on the number of
instrumentation points required, both as an absolute num-
ber and in proportion of the number of widgets that re-
quired instrumentation.