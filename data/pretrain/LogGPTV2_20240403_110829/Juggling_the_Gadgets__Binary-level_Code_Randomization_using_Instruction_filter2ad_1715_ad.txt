Table 1: Data set of PE ﬁles used for randomization coverage analysis.
Figure 5: Randomization coverage of each technique in rela-
tion to each other. Instruction displacement increases the cov-
erage achieved by in-place randomization alone from 84.96%
to 97.23%.
tion of all PE ﬁles in our data set. Although both techniques achieve
comparable coverage, their combination manages to randomize a
greater number of gadgets, and this is true for most executables, as
evident from the slightly steeper curve. Speciﬁcally, as shown in
Table 1, in-place code randomization on average affects 84.96% of
the gadgets, instruction displacement affects 90.04% of the gadgets,
while their combined use randomizes 97.23% of all gadgets in the
properly disassembled code regions.
The Venn diagram in Figure 5 sheds more light into how each of
the two techniques contributes in randomizing gadgets. While a ma-
jority of 77.78% can be randomized by both techniques, instruction
displacement affects an extra 12.27%, increasing signiﬁcantly the
overall randomization coverage. When considering the whole binary,
including the areas that cannot be disassembled, the randomization
coverage is improved from 79.55% to 91.04%.
5.1.2 Gadget Analysis
The achieved randomization coverage of 97.23% leaves only a
remaining 2.77% of gadgets that cannot be randomized by either
of the two techniques. There are several reasons why instruction
displacement cannot affect those gadgets. Among them, 0.83%
are contained within basic blocks smaller than ﬁve bytes, and thus
cannot be displaced due to the restriction of having to use a 5-byte
jmp instruction for patching. Another 0.6% correspond to “basic
block entry” gadgets that remain usable by following the inserted
jmp instruction. The rest 1.34% cannot be displaced due to various
other corner cases related to basic block alignment.
Figure 6: Randomization coverage for different maximum gad-
get lengths.
We also looked speciﬁcally into call-preceded gadgets, as they
can be particularly useful for an attacker that wants to bypass any
deployed coarse-grained CFI protections [16, 21, 28, 47]. The per-
centage of call-preceded among all gadgets, including the areas
that cannot be disassembled, is 5.76%. After randomization using
both techniques, their number is reduced to just 0.16% of all gadgets,
with 0.14% being located in unreachable regions. This means that
the achieved randomization coverage is enough to affect the vast
majority of call-preceded gadgets.
5.1.3 Longer Gadgets
Given that an attacker may be able to use longer gadgets by
spending some additional effort, we explored how the randomization
coverage is affected when considering longer gadgets. To that end,
we repeated our experiments using a maximum gadget length of 10
and 15 instructions. In all cases we follow the same approach as
before, i.e., we ﬁrst apply each diversiﬁcation technique separately,
followed by their combination.
Although the total number of discovered gadgets when consider-
ing a maximum length of 10 instructions increases by about 18%,
the percentage of randomized gadgets using both techniques re-
mains almost the same, at around 97.4%, and so does also for
15-instructions-long gadgets, as shown in Figure 6. As the gadget
size increases, IPR affects a slightly larger percentage of gadgets,
moving from 84.96% to 86.78% and 88.59%, respectively. This
result is expected, as the longer the gadget, the more opportunities
for the different code transformations of IPR to affect some of its
instructions. In contrast, as longer gadgets are more likely to span
consecutive basic blocks, the coverage of instruction displacement
drops slightly from 90.11% for 10 instructions to 87.42% for 15
instructions. It still contributes though an additional 9% in coverage
when combined with IPR.
Disp. − IPRIPR − Disp.Disp. ∩ IPRDisp.  IPR∩DisplacementIn-Place Rand.12.27%(11.49%)7.19%(6.73%)77.78%(72.82%)90.04%(84.31%)84.96%(79.55%)97.23%(91.04%)Unreachable: 6.37%max 5 instr.max 10 instr.max 15 instr.Randomization Coverage (%)020406080100IPRDisp.Both305.2 File Size Increase
Instruction displacement unavoidably incurs an increase in the
size of the randomized PE ﬁles. Based on our experiments, the size
of the .ropf section that hosts the displaced gadgets was veriﬁed
to increase proportionally to the ratio of displaced code regions.
As shown in Table 1 (last column), the average increase over the
original PE ﬁle is minimal, at about 2.35%.
The total size of the displaced code regions is slightly larger than
the original displaced code due to the additional jmp instructions that
sometimes are appended at the end of displaced regions, and more
rarely, due to larger displacement offsets in some operands. From
all displaced regions, only 43.54% require a pair of jumps—in the
rest of the cases, the region ends with an indirect branch instruction
that takes care of transferring control to the appropriate location.
Some additional spaced is also consumed to the random padding at
the beginning of the .ropf section.
5.3 Correctness
Any static binary instrumentation technique should preserve the
original semantics of the instrumented program. To ensure that our
transformations do not break the functionality of complex binaries,
we ﬁrst performed some manual testing with real-world applica-
tions, such as Adobe Reader. After randomization, we veriﬁed that a
variety of PDF documents would open and render properly. Further-
more, when running diversiﬁed versions of the SPEC benchmarks,
as described below, we did not encounter any issues with erroneous
output.
As an attempt to exercise a more signiﬁcant amount of code, we
also used an automated testing approach based on the test suite of
Wine [5], as similarly done by previous works [41, 42]. Wine is
a compatibility layer capable of running Windows applications on
several POSIX-compliant operating systems. To validate that the
ported APIs provided by Wine function as expected, Wine comes
with an extensive test suite that covers the implementations of most
functions exported by the core Windows DLLs. We ported to Win-
dows some of Wine’s test suites for 27 system DLLs, comprising a
total of 10,036 different test cases, and used them repeatedly with
randomized versions of those 27 actual Windows DLLs. By check-
ing the outcome between various inputs and expected outputs, we
could conﬁrm that the randomized versions of the DLLs always
worked correctly.
5.4 Performance Overhead
Finally, our last set of experiments focused on evaluating the
performance overhead of instruction displacement. Since the tech-
nique involves extensive code patching and indirection, we expect
to observe an increase in CPU overhead due to the extra executed
jmp instructions and different code locality patterns. To get a bet-
ter understanding of the performance implications, we performed
two sets of experiments. First, we used a subset of the DLLs and
Wine test cases used for the correctness evaluation, leaving aside
any tests that involved the creation of ﬁles and other operations that
would mask out any CPU overhead. For each DLL, we measured
the overall CPU user time for the completion of all relevant tests
by taking the average time across multiple runs, using both the
original and the randomized versions of the DLL. Second, we used
the Windows-compatible subset of the standard SPEC CPU2006
benchmark suite.
Figures 7 and 8 show the runtime overhead of instruction displace-
ment (when used in conjunction with in-place code randomization)
over native execution for the Wine and SPEC experiments, respec-
tively. The average overhead across all Wine tests is 0.48%, with
a maximum of 1.87%. Surprisingly, some of the test cases exhibit
Figure 7: Runtime overhead over native execution for diver-
siﬁed versions of Windows system DLLs, driven by test cases
ported from Wine’s test suite. The average overhead across all
tests is 0.48%.
Figure 8: Runtime overhead for the SPEC CPU2006 bench-
marks. The average overhead across all benchmarks is 0.36%.
a negative overhead, meaning that the diversiﬁed code ran faster
than the original. We observed the same behavior in a stable and
repeatable way across many iterations of the same experiment, with
different instances of randomized binaries. We attribute this speedup
in better caching behavior due to better code locality in the .ropf
section, as different “hot” basic blocks may now be brought in close
proximity.
For the SPEC benchmarks, the average overhead was 0.36%. The
two benchmarks with the highest overhead are xalancbmk and
perlbench (6.38% and 5.34%, respectively), which is expected
given that they are among the largest and more complex ones. A few
other benchmarks exhibited the same negative overhead behavior
that was also observed before, again in a consistent way across many
repetitions.
We analyzed further the Wine and SPEC test cases that exhibited
negative overheads using statistical hypothesis testing. With the null
hypothesis that the mean CPU times for the original and randomized
binaries are identical, Welch’s two-sample t-test failed to reject it.
advapi32 − credadvapi32 − cryptadvapi32 − crypt_lmhashadvapi32 − crypt_md4advapi32 − crypt_md5advapi32 − crypt_shaadvapi32 − lsaavifil32cabinet − extractcabinet − fdicomcatimagehlpmstask − taskmstask − task_schedulermstask − task_triggermsvfw32ntprintoleaccpsapisnmpapiwinhttp − urlwintrust − asnwldap32Runtime overhead (%)−1.5−1−0.500.511.52400.perlbench401.bzip2403.gcc429.mcf433.milc444.namd445.gobmk450.soplex453.povray456.hmmer458.sjeng464.h264ref470.lbm471.omnetpp473.astar482.sphinx3483.xalancbmkRuntime overhead (%)−2−10123456731That is, the means of the two distributions of CPU times for the
original and randomized binaries in each case are not signiﬁcantly
different from each other with a 95% conﬁdence interval, implying
that these differences fall within the margin of measurement error.
We also explored the overhead of instruction displacement when
used as a standalone technique, without the prior application of
IPR. That is, when all 90.04% of the gadgets that can potentially be
displaced are actually displaced, as opposed to just 12.27% when
used in conjunction with IPR. The average overhead across all
SPEC benchmarks in that case was just 2.06%, denoting that even
extensive but focused patching can still incur a minimal performance
overhead.
6. DISCUSSION AND LIMITATIONS
The two main limiting factors for instruction displacement in
terms of randomization coverage are the precision of code extrac-
tion, and the size of existing basic blocks. Even when using a
state-of-the-art disassembler like IDA Pro, some parts of the code
cannot be extracted, and thus any gadgets in those regions remain
unmodiﬁed. As our experiments have shown (Figure 5), when con-
sidering all available gadgets in a binary, instruction displacement
reduces the number of unmodiﬁable gadgets from 21.45% for stan-
dalone in-place randomization, to 8.96% for the combination of both
techniques. Given that the majority of them are located in unreach-
able regions (6.37%), a more accurate code extraction technique
would allow for improved coverage. On the other hand, only a frac-
tion (0.83%) of all extracted gadgets could not be displaced because
they reside in small basic blocks. For “entry point” gadgets that
still remain available after displacement, we plan to explore further
transformations that can be applied on the displaced instructions, as
discussed in Section 3.2.1.
Given the best-effort nature of our approach, we still cannot
exclude the possibility of an attacker being able to assemble a func-
tional ROP payload using solely the remaining fraction of unmodiﬁ-
able gadgets. An indication about the complexity of ROP payload
construction when working with a limited set of gadgets was pro-
vided by Pappas et al. [41], who showed that two automated ROP
payload construction frameworks were unable to construct a func-
tional payload using only the remaining unmodiﬁable gadgets by
IPR. With the application of instruction displacement on top of IPR,
this set of gadgets is signiﬁcantly reduced even further (from 21.45%
to 8.96%), and thus it is reasonable to assume that automated con-
struction becomes even harder.
Besides the signiﬁcant increase in coverage, instruction displace-
ment also offers an additional beneﬁt over in-place randomization
in terms of the achieved randomization entropy. Although 77.78%
of the gadgets can be randomized by both techniques, the random-
ization achieved through instruction displacement is qualitatively
different. For some gadgets, IPR affects only a few of their instruc-
tions (or even just some of the instructions’ operands), and often
gadgets may exist in one out of just two possible states, leaving
open the possibility of them being still usable after making the
right assumptions. On the other hand, displaced gadgets end up in
random locations that are infeasible to predict. Although in this
work we have restricted the use of instruction displacement only
for gadgets that are not randomized at all by IPR, in the future we
plan to explore more aggressive combinations of the two techniques
to improve randomization entropy even further. As we showed in
Section 5.4, the associated overhead when displacing all possible
gadgets is still modest, at 2.1%, so a small increase in the current
number of displaced regions would have a negligible impact in the
overall overhead.
7. RELATED WORK
The concept of diversiﬁcation has been the basis of a wide range
of software protections against code injection and code reuse at-
tacks [18, 25, 36]. Address space layout randomization (ASLR) [39,
44] is probably one of the most widely deployed protections against
code reuse attacks. Besides frequent weaknesses related to incom-
plete ASLR coverage [26, 32, 43, 59], however, even proper ASLR
can often be bypassed using memory disclosure bugs that leak the
base address of loaded modules [6, 7, 10, 34, 37, 49, 52].
More ﬁne-grained forms of randomization, complementary to
ASLR, aim to diversify even further the layout and structure of
a process’ code. Randomization can be performed at the func-
tion [1, 11, 12, 33], memory page [9], basic block [3, 4, 55], or
instruction level [22, 30, 41], breaking the assumptions of attackers
about the location and structure of gadgets based on the original
code image. From a deployment perspective, most of the techniques
that fully randomize all code segments depend on the availability
of source code [1, 11, 12, 20, 33], debug symbols [3, 4], the use of
heavyweight dynamic binary instrumentation [20,30] or the assump-
tion of accurate code disassembly [9, 55, 58]. In contrast, in-place
code randomization [41], can be applied on stripped binaries even
with partial disassembly coverage.
Another line of compile-time approaches prevent the construction
of ROP code by generating machine code that does not contain
unintended gadgets, and which safeguards any remaining intended
gadgets using additional indirection [38, 40].
Oxymoron [9] applies ﬁne grained code randomization that is
compatible with code sharing. It offers some resistance to JIT-ROP
attacks [20, 52] by replacing direct branches with indirect branches.
This makes it harder for attackers to harvest code pages by following
the ﬂow of control. Other recent research efforts protect against
JIT-ROP attacks by making code executable but not readable. This
can be achieved by relying on page table manipulation [8], split
TLBs [27], hardware virtualization extensions [19, 54, 57], or tech-
niques based on a lightweight form of software fault isolation [14].
The binary-compatible of these approaches [8, 54, 57] can ben-
eﬁt from the improved randomization coverage achieved by our
proposed instruction displacement technique.
8. CONCLUSION AND FUTURE WORK
The emergence of return-oriented programming attacks and the