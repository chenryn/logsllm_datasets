packet. Such an approach to packet marking may at ﬁrst
seem counter-intuitive, for we are apparently wasting a
large amount of “real estate” in the precious b bits. But
the checksum cords make the reconstruction algorithm
much more eﬃcient. The checksum cords serve both as
associative addresses for the router messages and also as
partial integrity validators. They also spread the spec-
trum of possible messages across a large domain, which
signiﬁcantly reduces the ability of the adversary to in-
119terject false messages that collide with legitimate ones.
As we will show, such an approach can easily recon-
struct 8-fragment messages or higher, from hundreds of
routers, even when the adversary is injecting packets
meant to confuse or slow-down our algorithm. In addi-
tion, by including reasonably-large HMAC information
in the message MX , we can achieve unpredictability for
these checksum cords, which makes the adversary’s job
harder, while also providing moderate-to-strong authen-
tication of the routers in the attack tree T . Moreover,
our algorithms do not require any knowledge of the uni-
versal tree U , and we avoid the requirement of having
routers sign individual setup messages by employing au-
thenticated dictionaries [2, 6, 8, 9, 15] for the out-of-
band validations. We describe our methods in the sec-
tions that follow.
2. EFFICIENT PACKET MARKING
Let b denote the number of bits in the IP header that
we can safely use to encode information from a router.
For example, we may wish to use b = 25, as advocated by
Dean et al. [7]. Indeed, we will use b = 25 as a running
example throughout most of this paper. Still, even if
one does not use the 8 type-of-service bits (which are
being advocated for diﬀerentiated services), we would
still have b = 17 (and we give some examples using this
value for b as well). In either case, we may sometimes
upset packet fragmentation2, but the frequency of use
of fragmentation is arguably below typical packet loss
rates [7].
2.1 High-Level View
Our scheme for sending to V the message MX from
each router X in the attack tree is based on using a tech-
nique that we call randomize-and-link. The main idea of
this technique is to perform the following transformation
to MX :
1. Pad MX as needed to make |MX| a multiple of l,
which is a parameter in our algorithm.
2. Compute a reasonably large (and statistically ran-
dom) checksum C = C(MX ) on the sequence MX .
The checksum C(MX ) should utilize randomness
in itself or MX , so that C(MX ) is statistically
random (like a random hash function) and unpre-
dictable to the adversary (but not necessarily con-
ﬁdential).
3. Break MX into a sequence W of non-overlapping
word fragments w0, w1, w2, . . . , wl−1.
4. Create a collection of blocks, which are used to
over-write the b bits, so bi = [i, C, wi].
We use these bi blocks to transmit the message MX to
the victim V . These pieces are not sent in any par-
ticular order, however. We call C = C(MX ) the cord
2We will not completely destroy fragmentation, how-
ever, for our scheme will only overwrite the b seldom
used bits in the IP header with probability p.
for MX , as it will be used as both an associative ad-
dress for MX and a checksum to “link” all the pieces
of MX back together. Moreover, since the cord C is
statistically random and unpredictable to the attacker,
he cannot easily create false cords that would confuse
the reconstruction algorithm. This reconstruction algo-
rithm is therefore quite simple—given a collection of bi’s
with the same cord C, a victim simply tries all possible
ways of putting the bi’s back together in the right order,
using the checksum property of the cord C to eliminate
unintended sequences. Once the victim V has a valid
sequence of bi’s correctly constructed in order, V will
have built the message MX . We give the details below.
2.2 Randomize-and-Link Transmission
As mentioned above, we assume that the IP header al-
lows the reuse of some of its bits for the purpose of infor-
mation marking by routers. We partition the b reusable
bits in the IP header as follows:
• (cid:4)log l(cid:5) bits for the fragment index i
• c bits for the cord, which serves both as an asso-
ciative address and as a checksum
• h = b − c − (cid:4)log l(cid:5) bits for the data word wi.
For example, if b = 25 and l = 8, then we could use
(cid:4)log l(cid:5) = 3 bits for the index i, c = 15 bits for the
checksum C, and h = 7 bits for each data word wi.
As we will show in our analysis, the choices of these
parameters relate to the security and eﬃciency of our
approach.
We assume that either the function C() or MX itself
contain a suﬃcient number of bits that are essentially
random, so that the checksum value C(MX ) is statisti-
cally random and unpredictable to the adversary. That
is, it is as unlikely as a random hash function with sim-
ilar output size for C(MX ) = C(MY ) for two diﬀerent
router messages MX and MY .
In addition, C should
be unpredictable, so that it is diﬃcult for the adversary
to compute C(MX ) prior to its transmission to V . In
particular, we want C(MX ) to be unpredictable to an
adversary who knows only the value of X (we assume
the adversary does not know all of MX ). For example,
if MX does not contain suﬃcient randomness in itself,
we could pad MX with a random nonce, so that its cord
C = C(MX ) has the desired randomness and unpre-
dictability properties.
Given the message MX , we pad to have size that is
a multiple of l. We then compute the c-bit checksum
(cord) C = C(MX ) on MX , and we break MX into a
sequence W of l words w0, w1, w2, . . . , wl−1 of length h
bits each. We deﬁne a set of l blocks b0, b1, . . . , bl−1 so
that bi = [i, C, wi]. Note that the cord C is included
in every block bi. Indeed, it is the inclusion of the cord
C that links the blocks bi together, as it makes C an
associative address for the blocks.
2.3 Packet Marking
Once we have the blocks b0, b1, . . . , bl−1 deﬁned for
a message MX , we proceed with probabilistic packet
120marking in the natural way. Namely, we deﬁne a prob-
ability parameter p (e.g., p = 1/20). With each packet
that X receives, we “ﬂip a coin” with probability p. If
this coin comes up “tails” (an event that occurs with
probability 1 − p), then X simply forwards the packet
on to its destination as usual. Otherwise, if the coin
comes up “heads,” then X chooses one of its blocks bi
at random, inserts bi into the reusable bits of this packet
(updating the header checksum as needed), and forwards
this revised packet on to its destination.
This packet marking process continues until we choose,
for timeliness reasons, to change the message MX . At
such a time that we wish to change to a new MX ,
the router X repeats that above computation for the
bi blocks for the new message. The router then re-
peats the probabilistic packet marking for this new set
of blocks, until we decide yet another change is needed.
Thus, we keep very little state at a router in order
to implement the randomize-and-link packet marking
scheme. A router doesn’t even need to store the blocks
b0, b1, . . . , bl−1, so long as it has a fast way of generating
a bi at random. Moreover, note that the computational
overhead per packet is very small. In the default case,
when the “coin ﬂip” is tails, the router’s work is the
same as when we were doing no packet marking at all;
hence, this scheme can be deployed incrementally. This
property contrasts with most previous packet marking
schemes [7, 19, 21], which require specialized additional
work even when routers are not marking packets.
2.4 Message Reconstruction
The message reconstruction algorithm is based on a
simple combinatorial process. Given a set of packets
received at the victim, we sort their b-bit blocks lexico-
graphically by their (C, i, wi) values, and remove dupli-
cates (interpreting values according to the same format
we used to store blocks in the IP header). This sorting
can be done, for example by a radix sort. Thus, we have,
for each distinct cord C, all the distinct blocks for this
cord ordered by their i-index. We let PC,i denote the set
of distinct packets that have cord C and fragment index
i. We then try all combinatorial combinations of the
blocks in PC,0 · PC,1 ··· PC,l−1, computing a checksum
for each. We keep only those combinations that have a
checksum equal to the cord C. That is, we accept these
strings as being strong candidates as having been sent
from the routers (although we must recognize that some
of these may have been sent by the attacker). The total
running time, then, for this reconstruction algorithm at
the victim is proportional to the following quantity:
l
N +XC
Yi=0
NC,i,
where N is the total number of packets and NC,i is the
number of distinct packets from this set with cord C and
fragment index i. As we show in Section 3, the expected
values of these quantities can be made quite reasonable,
even if there are a large number of routers in the attack
tree. For example, it is easy to observe that the expected
value of NC,i is (N
is the number of
+ nl)/l2c, where N
(cid:3)
(cid:3)
distinct packets received and n is the number of routers
in T .
2.5 Two-Phase Fragmentation
In the above discussion, we argued how fragmenting a
message into small blocks indexed (that is, linked) by a
large statistically-random checksum cord can be an ef-
fective means for sending a message to the victim that
is longer than b bits. In particular, fragmenting a mes-
sage into two, four, or eight word fragments can be an
eﬃcient way to send a moderate-sized message to the
victim (say, on the order of 48 to 96 bits). Unfortu-
nately, if we have a larger-sized message (say, on the
order of 128 or 192 bits), eight fragments may not be
suﬃcient to send the message and still utilize a large
checksum cord (which is needed for both security and
message reconstruction). We can iterate our randomize-
and-link approach, however, to send larger messages. In
this subsection, we describe how to design a two-phase
fragmentation scheme for sending larger messages.
We begin as in our previous method. We take the mes-
sage M and subdivide it into l words, w0, w1, . . . , wl.
This subdivision should be done in such as way as to
preserve in each word wi the same degree of random-
ness as is present globally in the message M . Still, in
many cases where we want M to be reasonably large,
we may observe that each word wi is too big to be
transported with high conﬁdence in a single data block.
So we further subdivide each word wi into m subwords
si,0, si,1, . . . , si,m. Given the value m and the size of the
subwords, we determine the number, c1, of checksum
bits that we can devote to sending the subwords in the
ﬁrst round (given our ﬁxed size of b bits per block). We
devote b− c1 −(cid:4)log m(cid:5) bits to the data in each subword
si,j. Thus, we can compose subwords to form bigger
blocks of m(b− c1 −(cid:4)log m(cid:5)) bits. In order for these big
blocks to have the same security as the smaller blocks,
we should devote c2 = c1 − (cid:4)log m(cid:5) bits to a random
checksum cord for each of them, just as we did in our
single-phase approach. This factor is due to the fact that
the probability of collision between two distinct packets
in the ﬁrst round is 1/m2c1 and this probability in the
second round is 1/lm2c2 , since every round-two word
was comprised of m round-one subwords. In addition,
we must also devote (cid:4)log l(cid:5) bits to a fragment number of
each index i. So, for each word wi we compute a c2-bit
checksum cord we wish to use in order to achieve high
conﬁdence of message transmission for each word.
Data transmission in the two-level scheme is as in the
one-level scheme, except that now when a router decides
to interject a message into a packet it chooses one of its
many subwords, si,j at random and interjects this. Re-
construction of the message, of course, proceeds in two
phases. In the ﬁrst phase we reconstruct all the candi-
date words wi and in the second phase we reconstruct
all the candidate messages. Thus, the running time for
message reconstruction in the two-phase scheme is pro-
portional to the following:
m
l
N +XC
Yi=0
MC,i +XC
Yi=0
NC,i,
121where N is the total number of packets the victim is
using for reconstruction, MC,i is the number of distinct
phase-one blocks from this set with cord C and fragment
index i, and NC,i is the number of distinct phase-two
blocks with cord C and fragment index i. In the analysis
section that follows, we show that these quantities can
be quite reasonable, provided that there are a suﬃcient
number of bits devoted to the checksum cords.
3. ANALYSIS
In this subsection, we analyze the randomize-and-link
approach to probabilistic packet marking. We give this
analysis parameterized by the various values, such as N ,
l, and c, and we also give speciﬁc analyses for various
values assuming we have b = 25 or b = 17 bits that can
be used in an IP header for message transmission.
3.1 Number of Packets Needed
We begin our analysis by estimating the number of
packets that are needed for traceback in our single-phase
method. Let n denote the number of routers in the
attack tree T , and recall that l is the number of words
in the message MX each router X wishes to transmit
to the victim V . Thus, the victim wishes to receive nl
distinct packets if we are to reconstruct the messages
from all the routers in T .
Let p denote the probability that a router injects its
information in a packet. So, p(1−p)d−1 is the probability
that a packet is marked and arrives unchanged from a
router that is d hops away from V . If we conservatively
assume that all routers have their packets successfully
delivered with probability at least that of the farthest
routers, then we can safely estimate that the information
from some router in the attack tree will be contained in
a packet received by the victim with probability at least
dp(1 − p)d−1, where d is the maximum hop-distance for
any such router.
Since every router must successfully send l diﬀerent
blocks for all of its information to arrive at the victim,
the expected number of packets that must be received
before all fragments have been received is an instance
of the coupon collectors problem [14], where the num-
ber of “coupons” is nl and the probability of receiving a
marked packet is dp(1− p)d−1. This observation implies
that the expected number of packets that must arrive
at the victim before it can perform a complete trace-
back of all n routers is nlHnl/dp(1 − p)d−1, where Hn
denotes the n-th Harmonic number. Using an inequality
for Hn from Knuth [11], Hn < ln n + γ + 1/2n, where
γ = 0.5772156649... is Euler’s constant. Thus, the ex-
pected number of packets that must arrive at V before it
can perform a complete traceback of n routers using our
scheme is at most (nl ln(nl) + γnl + 1)/dp(1 − p)d−1. For
example, if p = 1/20, d = 20, n = 1000, and l = 8, then
the expected number of needed packets to do reconstruc-
tion of all the router messages is 76516, not considering
the packet marking probability dp(1 − p)d−1. Dividing
this expectation by the packet marking probability in
this case implies that the expected total number of pack-
ets needed by the victim to do complete reconstruction
of all messages is 202770. Moreover, we can assume that
the attacker’s packets arrive at the victim with proba-
bility (1 − p)d, which is approximately 36% of the time
in this example. Thus, in this example, we could expect
that victim received unchanged from the attacker 72690
the 202770 expected packets the victim needs for attack
tree reconstruction. Note that there are only nl dis-
tinct packets that come from the routers in the attack
tree. Thus, in this example, we should not expect to
have to consider more than 80690 distinct packets during
the message reconstruction phase of the randomize-and-
link algorithm (72690 “noise” packets and 8000 message
packets). Note that this is roughly equal to the expected
number of packets needed without consideration of the
packet marking probability. Contrast this, for example,
with an ICMP messaging solution, which would require
that the victim receive at least 7.5 million attack pack-
ets before it could expect to identify all the participating
routers (assuming d = 20 and the ICMP injection prob-
ability is 1/20000).
The analysis of the two-phase version of the randomize-
and-link algorithm is similar to that given above for
the single-phase version. The main diﬀerence is that in
the two-phase algorithm we wish to receive, from each
router, l words subdivided into m subwords. That is, we
wish to receive lm packets from each router. Thus, the
expected number of packets we have to receive in order
to do complete traceback is nlmHnlm/dp(1 − p)d−1.
3.2 Analysis of Message Reconstruction
Let us address next the expected running time needed
to reconstruct all the messages received by the victim.
We give the analysis ﬁrst for our single-phase algorithm,