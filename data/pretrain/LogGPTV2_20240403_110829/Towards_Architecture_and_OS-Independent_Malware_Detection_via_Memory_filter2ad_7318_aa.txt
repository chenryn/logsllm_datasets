title:Towards Architecture and OS-Independent Malware Detection via Memory
Forensics
author:Rachel Petrik and
Berat Arik and
Jared M. Smith
POSTER: Towards Architecture and OS-Independent Malware
Detection via Memory Forensics
Rachel Petrik*, Berat Arik†, Jared M. Smith† §
*University of Kentucky, †University of Tennessee, Knoxville, §Oak Ridge National Lab
ABSTRACT
In this work, we take a fundamentally different approach to the prob-
lem of analyzing a device for compromises via malware; our approach
is OS and instruction architecture independent and relies only on hav-
ing the raw binary data extracted from the memory dump of a device.
Our system leverages a multi-hundred TB dataset of both compro-
mised host memory dumps extracted from the MalRec dataset [8] and
the first known dataset of benign host memory dumps running nor-
mal, non-compromised software. After an average of 30 to 45 seconds
of pre-processing on a single memory dump, our system leverages
both traditional machine learning and deep learning algorithms to
achieve an average of 98% accuracy of detecting a compromised host.
Finally, we lay out the future work that would form a broader set of
contributions, encapsulating and enhancing the work presented in
this paper.
1 INTRODUCTION AND BACKGROUND
According to a recent 12-month-long study of 477 companies, the
mean time to discover a breach is 197 days, with costs to remediate
these breaches exceeding $3.5 million on average [5]. Having an effec-
tive Digital Forensics and Incident Response (DFIR) capability remains
one of the most effective ways to both prevent and respond to mod-
ern breaches. However, with the proliferation of intrusion detection
systems and security products on the market, DFIR professionals and
security analysts must monitor an increasing amounts of tickets and
alerts from ever-growing infrastructure. To that end, one of the most
effective and widely-used methods to investigate hosts and their op-
erating systems (OS) for breaches relies on memory forensics, or the
examination of a device’s volatile RAM. Among the binary data in RAM
are the names and metadata of running and recently exited processes,
system kernel modules and libraries, executable source code, file infor-
mation, network information, registry keys, and more. Although tools
such as Volatility and Rekall [3, 12] are able to successfully extract
the OS-specific data and potential indicators of compromise (IOCs)
from memory, they require experts to build and maintain the systems,
requiring an addition of new profiles for every new OS and version.
Furthermore, any artifacts found in memory must be verified by an
expert with relevant OS and architecture-specific knowledge, even
when these artifacts may not actually represent a compromise.
By capitalizing on the ongoing breakthroughs in deep learning [9],
as well as more traditional machine learning techniques, we present a
system to detect malware-compromised hosts via captured memory
snapshots alone. By not relying on OS-specific information, we aim to
reduce the amount of time an analyst must focus on a host by flagging
potentially compromised hosts with only a memory snapshot as input.
Most importantly, our system could be deployed in any operational
environment where a memory snapshot can be ingested from con-
nected hosts, without relying on endpoint IDSes that require OS and
domain-specific IOCs. Systems such as Akatosh by Smith et al. [10]
provide the ability to scalably ingest memory images from hosts, as
well as others such as Endcase [2]. Our system utilizes a multi-hundred
TB dataset of both compromised host memory snapshots extracted
from the MalRec dataset [8] and the first known dataset of benign host
memory snapshots running normal, non-compromised software. 1 Af-
ter an average of 30-45 seconds of pre-processing on a single memory
snapshot, our system leverages both traditional machine learning and
deep learning algorithms to achieve an average of 98% accuracy of
detecting a compromised host, with over 3,000 samples for our Con-
volutional Neural Network, and over 9,000 samples for our traditional
machine learning models.
2 DATASETS
2.1 Compromised (Malicious) Snapshots
We employed the MalRec dataset from Severi et al. [8] created by
Georgia Tech over the course of two years. With over 66,000+ mal-
ware recordings from Windows 7 32-bit machines using the QEMU
virtualization software, our infrastructure extracts 1 GB memory snap-
shots at 0% of the QEMU recording, a random percent between 5% and
95%, and finally a snapshot at 99% of the execution of the recording.
Given that the malware for a particular recording executes shortly
after the beginning of the recording, we are able to use the 0% as
a baseline snapshot. In practice, we believe the random percentage
capture models the real-world best, where an operator cannot ensure a
memory snapshot is captured after malware has completely executed
in memory. Finally, these recordings contain traces of memory of nor-
mal programs, depending on what the malware calls into and passes
input to; this could be PDF viewers, the command-line, browsers, and
more pivot points for the malware to infect the machine.
2.2 Benign Snapshots
Next, we created a dataset of benign host memory snapshots running
normal, non-compromised software, including software that executes
in many of the malicious snapshots. We do not claim our dataset is
completely robust, and work remains to build additional representa-
tions of "normal" state represented by volatile RAM. To generate this
dataset, we leverage VirtualBox and Python to instrument a running
VM. After ensuring the VM uses the same size snapshots as MalRec (1
GB), each sample generated includes the execution of between 1 and 9
programs from a list of non-malicious programs that a user might run
such as Google Chrome, PDF Viewers, command-line consoles, Spotify,
Slack, and Skype. Once the programs launched, we waited 20 +(5×np)
seconds, where np is the number of programs ran. After this time, a
benign snapshot is extracted from memory after ample time has passed
for the chosen programs to open. By generating samples in parallel to
the separate malicious environment, we formed our benign memory
snapshot dataset. Additional work should be done to done building
’profiles’ of users in order to have distinct sets of benign snapshots,
centered around different demographics and job functions of users
in practice. Furthermore, the time between program execution and
memory snapshot collection should be varied further, while user input
should be passed automatically to the executed programs to further
simulate real users. Figure 1 below shows the dataset collection phase
of our system, as well as highlights the next phases.
1Our datasets will be published upon acceptance of this paper.
CCS ’18, October 2019, Toronto, CA
Petrik et al.
Geometric, Harmonic, Standard Error, Arithmetic Mean
Skew, Kurtosis, Variance, Standard Deviation
Hamming, Energy, Eucliden, Wasserstein, Bray-Curtis Minkowski* Distance
Jaccard-Needham Dissimilarity
Statistical Features
Min/Max
Entropy
Chi-Square Test
P-adic Valuation*
Shapiro-Wilk Test
Table 1: Total of 43 domain-unaware features extracted from memory snapshots. Starred features were extracted for several differ-
ent parameters.
in a similar manner. Finally, we applied a plethora of statistical and
numerical methods to each snapshot representation to extract 43 fea-
tures, including features for prime-number metrics, distance metrics,
statistical metrics such as variance and standard deviation, and even
probability tests such as the Chi-Squared metric. These features are
shown in Table 1. For all of these feature selection methods and run-
ning on a single core of a Linux-Based machine with a 2.5 GHz Intel
Xeon processor, we show in Figure 2 that the average time to complete
processing of one snapshot is less than 35 seconds for feature vector
extraction. Furthermore, the average time for generating all images or
extracting the byte sequences is less than 10 seconds. These methods
were written in Python with some metrics using Numpy or Scipy;
therefore, so significant speedups could potentially be gained when
implemented all in C or C++.
4 TRADITIONAL MACHINE LEARNING
For our approach to detecting compromises within the snapshots
using traditional machine learning, we employed a C.45 Decision
Tree, a standard Logistic Regression model, a Random Forest model, a
Stochastic Gradient Descent model, and a Support Vector Classifier.
All machine learning methods used Scikit-Learn and an Ubuntu Linux
12-core 2.5 GHz Intel Xeon system with 32 GB of RAM. For each
model, we conducted a probabilistic grid search over all available
hyper-parameters to tune the model, and when testing we used cross-
validation and a non-overlapping 75%/25% train/test split.
Overall, our traditional machine learning methods recorded an
average of 98% accuracy of detecting a compromised host with 9,000
samples. We found the feature vectors generated from the memory
snapshots that had been de-duplicated using MemScrimper performed
the best across all traditional machine learning algorithms. These
results were found both when comparing the benign dataset to the
random, assorted percentage for the malicious memory snapshot and
when comparing the benign dataset to the 99% malicious memory
snapshot. Notably, the false positive rate of this particular setting was
also less than 0.003% on average, indicating that our system would
add only a small fraction of false alerts to an analyst’s dashboard in an
environment with similar hosts and active software. The summary of
results for the best setting of parameters and feature vectors from de-
duplicated snapshots can be found in Table 2. Due to space constraints,
we leave out the results for the full and null-byte-removed snapshots
for both the random or assorted percentage and the 99% snapshots,
though we still found the accuracy was above 95% on average but with
slightly higher false positive rates averaging 0.1%.
5 DEEP LEARNING APPROACH
Our primary deep learning approach was through the use of a Convolu-
tional Neural Network (CNN), trained using various sized images from
the different pre-processing methods outlined earlier. Our model was