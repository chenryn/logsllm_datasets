The topology of our testbed is a BCube(8,1), it has two dimensions
and 8 servers on each dimension connected by an 8-port Ethernet
switch. Each server uses two ports of its dual-port NIC to form a
BCube network. Figure 9 illustrates the physical testbed topology and
its corresponding blueprint graph. Note that we only programmed our
DAC design on servers, and we did not touch switches in this setup
because these switches cannot be programmed. Thus, the blueprint
graph of our testbed observed at any server should have a degree of
14 instead of 2 as there are 7 neighbors for each dimension. This
server-only setup is designed to demonstrate that DAC works in real-
world systems, not its scalability.
In this setup, our DAC application is developed to automatically
assign the BCube ID for all the 64 servers in the testbed. A server
(a)Physical topology and BCube IDs8-port Gigabit Ethernet switchservers0.00.10.71.01.11.77.07.17.7(b)Blueprint graph and BCube IDs0.00.10.71.01.11.77.07.17.7Virtual mesh network46c-int
timeout
T
30
30
50
50
CCB
2.8
26.5
2.9
26.4
Total
184.4
0
211.7
10
245.9
0
275.7
10
Table 2: Time (ms) consumed during autoconﬁguration
TC mapping
0.7
0.4
0.9
0.5
89.6
93.3
90.8
97.6
LD
1.3
1.5
1.3
1.2
90
90
150
150
is selected as DAC manager by setting its level to 0. To inspect the
working process of DAC, we divide DAC into 5 steps and check each
of them: 1) CCB (communication channel building): from DAC man-
ager broadcasts the message with level 0 to the last node in the net-
work gets its level, 2) timeout:
there is no change in neighboring
nodes for 3 ∗ T at leaf nodes, 3) TC (physical topology collection):
from the ﬁrst leaf node sends out its TCM to DAC manager receives
the entire network topology, 4) mapping: device-to-logical ID map-
ping time including the I/O time, 5) LD (logical IDs dissemination):
from DAC manager sends out the mapping information to all the de-
vices get their logical IDs. Table 2 shows the result with different c-int
and T parameters. Note that c-int is to control the number of CBM
messages and T is the timeout value for CBP broadcast, and 3 ∗ T is
for TCM triggering. The experiments show that the total conﬁgura-
tion time is mainly dominated by the mapping time and 3 ∗ T , and
c-int can control and reduce the bustiness of CBM messages. In all
the cases, our autoconﬁguration process can be done within 300ms.
6. PERFORMANCE EVALUATION
In this section, we evaluate DAC via extensive simulations. We ﬁrst
introduce the evaluation methodology and then present the results.
6.1 Evaluation Methodology
Structures for evaluation. We evaluate DAC via experiments on
4 well-known data center structures: BCube [7], FatTree [8], VL2 [9]
and DCell [6]. Among these structures, BCube is the most symmetric,
followed by FatTree, VL2, and DCell. DCell is the most asymmetric.
All the structures can be considered as sparse graphs with different
sparsity. VL2 is the sparsest, followed by FatTree, DCell, and BCube.
For each of them, we vary the size as shown in Table 3. Please refer
to these papers for details. Since BCube is speciﬁcally designed for a
modular data center (MDC) sealed in shipping containers, the number
of devices in BCube should not be very large. We expect them to be in
the thousands, or at most tens of thousands. For FatTree and VL2, we
intentionally make their sizes to be as large as hundreds of thousands
of nodes. DCell is designed for large data centers. One merit of DCell
is that the number of servers in a DCell scales doubly exponentially
as the level increases. For this reason, we check the performance of
DAC on very large DCell graphs. For example, DCell(6,3) has more
than 3.8 million nodes!
Metrics. There are 3 metrics in our evaluation. First, we measure
the speed of O2 on the above structures, which includes both mapping
from scratch (i.e., for brand-new data centers) and mapping for incre-
mental expansion (i.e., for data center expansion). This metric is used
to show how efﬁcient O2 is as a device-to-logical ID mapping engine.
Then, we estimate the total time DAC takes for a complete autocon-
ﬁguration process. Lacking a large testbed, we employ simulations.
Last, we evaluate the accuracy of DAC in detecting malfunctions via
simulations. All the experiments and simulations are performed on
a Linux sever with an Intel 2.5GHz dual-core CPU with 8G DRAM.
The server runs Red-Hat 4.1.2 with Linux kernel 2.6.18.
6.2 Efﬁciency of O2 Mapping Engine
Mapping from scratch. We study the performance of O2 to-
gether with the seminal GI tool proposed in [15] called Nauty and
another algorithm proposed in digital design automation ﬁeld called
Saucy [16]. For Nauty, we use the latest version v2.4. For Saucy,
BCube(n; k)
B(4,4)=2304
B(5,4)=6250
B(6,4)=14256
B(7,4)=28812
B(8,4)=53248
DCell(n; k)
FatTree(n)
D(2,3)=2709
F(20)= 2500
D(3,3)=32656
F(40)=18000
D(4,3)=221025
F(60)=58500
F(80)=136000
D(5,3)=1038996
F(100)= 262500 V(100,100)=252650 D(6,3)=3807349
VL2(nr; np)
V(20,100)= 52650
V(40,100)= 102650
V(60,100)= 152650
V(80,100)= 202650
Table 3: Number of devices in each structure.
it does not calculate the one-to-one mapping nor does the isomor-
phism check between two graphs by default. Instead, it is a tool to
calculate the automorphisms in a graph. We observe that, when in-
putting two graphs as one bigger graph into Saucy, among all the
output automorphisms there exist at least one that maps each node
in one graph to a node in another given that the two graphs are iso-
morphic to each other. To compare with Saucy, we improve its al-
gorithm to check and calculate a one-to-one mapping between two
graphs and call it Saucy+. Essentially, Nauty includes candidate
pruning via orbit, Saucy+ is built on top of Nauty and introduces
selective splitting, and O2 is further built on top of Saucy+ and in-
cludes candidate selection via SPLD, as we show in Table 4.
Figure 10 plots the results for device-to-logical ID mapping. Note
that, we do not include the I=O time for reading graphs into memory.
From the ﬁgure, we can see that the mapping time of O2 scales in
proportion to the total number of devices in the network.
The results in Figure 10 clearly demonstrate that O2 is faster than
both Nauty and Saucy+ on all the evaluated structures. O2 can
perform the mapping for all the structures within 10 seconds. More
speciﬁcally, for BCube(8,4), O2 can ﬁnish the mapping in less than
1.5 seconds; for FatTree(100) and VL2(100, 100), O2 needs 4.16 and
1.07 seconds respectively; for DCell(6,3) with 3.8+ million nodes,
O2 needs only 8.88 seconds. This ﬁnding is not surprising since O2
improves over Saucy+ and Nauty. Note that Nauty does not show
up in the ﬁgures of FatTree, VL2, and DCell, because its run-time for
any graph bigger than DCell(3,3), FatTree(40) and VL2(20,100) is
too long (i.e., days) to ﬁt into the ﬁgures nicely.
To better understand why O2 performs best, we assess the relative
effectiveness of the three heuristics used in the algorithms on popular
data center structures. We make the following three observations.
First, we ﬁnd that candidate pruning via orbit is very efﬁcient
for symmetric structures. For example, Nauty needs only 0.07 for
BCube(4,4) with 2034 devices, whereas it requires 312 seconds for
FatTree(20) with 2500 devices. Another example is that while it only
takes less than 8 seconds to perform the mapping for BCube(8,4) with
53248 devices, it fails to obtain the result for either FatTree(40) with
58500 devices or VL2(20,100) with 52650 devices within 24 hours.
One factor contributing to this effect is that BCube is more symmetric
than either FatTree or VL2 structure.
Second, our experiments suggest that selective splitting introduced
in Saucy should be more efﬁcient for sparse graphs. For exam-
ple, VL2(100,100) and FatTree(100) have similar numbers of devices
(250000+), but VL2 needs only 6.33 seconds whereas FatTree needs
18.50 seconds. This is because VL2(100,100) is sparser than Fat-
Tree(100). We have checked the average node degree of these two
structures. The average degree for VL2(100,100) is approximately
1.03. Compared with VL2(100,100), FatTree(100) has an average
node degree of 2.86, more than 2 times denser.
Finally, when candidate selection via SPLD is further introduced
in O2 to work together with the above two heuristics, it exhibits dif-
ferent performance gains on different structures. SPLD works best
for asymmetric graphs. For example, compared with Saucy+, O2,
which has the SPLD heuristic, improves the time from 2.97 to 1.31
seconds (or 2.27 times) for BCube(8,4), from 18.5 to 4.16 seconds
(or 4.34 times) for FatTree(100), from 6.33 to 1.07 seconds (or 5.92
times) for VL2(100,100), whereas it reduces the time from 44603 to
47Figure 10: The speed of O2 one-to-one mapping on BCube, FatTree, VL2 and DCell structures, and its comparison with Nauty and
Saucy+. Note that we do not include the performance curves of Nauty on DCell, FatTree and VL2 structures because the run-time of
Nauty on all the graphs bigger than DCell(3,3), FatTree(40) and VL2(20,100) respectively is more than one day. Furthermore, we use
log-log scale to clearly show the performance of both O2 and Saucy+ on DCell.
Nauty
√
Candidate pruning via orbit
Selective splitting
Candidate selection via SPLD
Table 4: Heuristics applied in different algorithms.
√
√
Saucy+ O2
√
√
√
Old data center
BCube(8,3)
partial
FatTree(100)
VL2(50,100)
DCell(6,2)
Expanded data center #Increased devices
BCube(8,4)
complete
FatTree(100)
VL2(100,100)
DCell(6,3)
125000
3805242
125000
47104
Time(s)
0.190
0.270
0.240
7.514
8.88 seconds (or 5011 times) for DCell(6,3)! This is because the more
asymmetric a graph is, the more likely that the SPLDs of two nodes
will be different. In our case, BCube is the most symmetric structure
since all the switches are interchangeable, whereas DCell is the most
asymmetric one since there are only two automorphisms for a DCell.
We have also checked other combinations of the heuristics, includ-
ing selective splitting, candidate pruning via orbit plus candidate se-
lection via SPLD, and selective splitting plus candidate selection via
SPLD. We omit the details due to space constraints. The results of
all these combinations conﬁrm the above observations: candidate
pruning via orbit is efﬁcient for symmetric graphs, selective split-
ting works well for sparse graphs, and candidate selection via SPLD
improves both heuristics and has remarkable performance gain for
asymmetric graphs such as DCell.
Mapping for Incremental Expansion. For the evaluation of O2
on incremental expansion, we choose one expansion scenario for each
structure. Since BCube and DCell are recursively deﬁned, we expand
them by increasing the level. For FatTree and VL2, we expand them
by increasing the number of servers in each rack. The results are listed
in Table 5. We ﬁnd that all the mappings can be done efﬁciently. For
Table 5: CPU time of mapping for data center expansion.
BCube, we extend BCube(8,3) to BCube(8,4) and ﬁnish the mapping
in 0.19 second; For FatTree, we expand partial FatTree(100), where
each edge switch connects to 25 servers, to complete FatTree(100),
where each edge switch connects to 50 servers, and take 0.47 second
for mapping; For VL2, we expand VL2(50,100) to VL2(100,100) and
spend 0.24 second; For DCell, we extend DCell(6,2) to DCell(6,3)
and use 7.514 seconds. Finally, we check and verify that O2 keeps
logical IDs for old devices unmodiﬁed.
6.3 Estimated Time Cost on Autoconﬁguration
Recall that, in Section 5, we have evaluated the time cost of DAC
on our BCube(8,1) testbed. In this section, we estimate this time on
large data centers via simulations. We use the same parameters c-int
(checking interval) and T (timeout for CBP broadcast) as in the im-
plementation, and set c-int as 10ms and T 50ms. We estimate the
time cost for each of the ﬁve phases, i.e., CCB, timeout, TC, map-
ping and LD, as described in Section 5. In the simulations, device ID
is a 48-bit MAC address and logical ID is set to 32 bits, like an IP
0123456x 104012345678BCube(n=4...8,k=4)Number of devicesCPU time (s)  O2Saucy+Nauty00.511.522.53x 10505101520FatTree(n=20...100)Number of devicesCPU time (s)  O2Saucy+0.511.522.53x 10501234567VL2(nr=20...100, np=100)Number of devicesCPU time (s)  O2Saucy+10310410510610710−410−2100102104106DCell(n=2...6, k=3)Number of devices (log−scale)CPU time (s) (log−scale)  O2Saucy+48Figure 11: Number of malfunctioning devices detected with increased number(percent) of selected anchor points.
BCube(4,4)