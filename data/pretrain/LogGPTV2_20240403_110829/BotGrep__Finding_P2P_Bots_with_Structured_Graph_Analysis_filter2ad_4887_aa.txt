title:BotGrep: Finding P2P Bots with Structured Graph Analysis
author:Shishir Nagaraja and
Prateek Mittal and
Chi-Yao Hong and
Matthew Caesar and
Nikita Borisov
BotGrep: Finding P2P Bots with Structured Graph Analysis
Shishir Nagaraja, Prateek Mittal, Chi-Yao Hong, Matthew Caesar, Nikita Borisov
{sn275,mittal2,hong78,caesar,nikita}@illinois.edu
University of Illinois at Urbana-Champaign
Abstract
A key feature that distinguishes modern botnets from
earlier counterparts is their increasing use of structured
overlay topologies. This lets them carry out sophisticated
coordinated activities while being resilient to churn, but
it can also be used as a point of detection.
In this
work, we devise techniques to localize botnet mem-
bers based on the unique communication patterns aris-
ing from their overlay topologies used for command and
control. Experimental results on synthetic topologies
embedded within Internet trafﬁc traces from an ISP’s
backbone network indicate that our techniques (i) can lo-
calize the majority of bots with low false positive rate,
and (ii) are resilient to incomplete visibility arising from
partial deployment of monitoring systems and measure-
ment inaccuracies from dynamics of background trafﬁc.
1
Introduction
Malware is an extremely serious threat to modern net-
works. In recent years, a new form of general-purpose
malware known as bots has arisen. Bots are unique in
that they collectively maintain communication structures
across nodes to resiliently distribute commands from a
command and control (C&C) node. The ability to coor-
dinate and upload new commands to bots gives the bot-
net owner vast power when performing criminal activi-
ties, including the ability to orchestrate surveillance at-
tacks, perform DDoS extortion, sending spam for pay,
and phishing. This problem has worsened to a point
where modern botnets control hundreds of thousands of
hosts and generate revenues of millions of dollars per
year for their owners [23, 42].
Early botnets followed a centralized architecture.
However, growing size of botnets, as well as the devel-
opment of mechanisms that detect centralized command-
and-control servers [10, 44, 27, 31, 72, 9, 49, 30, 29, 76],
has motivated the design of decentralized peer-to-peer
botnets. Several recently discovered botnets, such as
Storm, Peacomm, and Conﬁcker, have adopted the use
of structured overlay networks [71, 57, 58]. These net-
works are a product of research into efﬁcient communi-
cation structures and offer a number of beneﬁts. Their
lack of centralization means a botnet herder can join
and control at any place, simplifying ability to evade
discovery. The topologies themselves provide low de-
lay any-to-any communication and low control overhead
to maintain the structure. Further, structured overlay
mechanisms are designed to remain robust in the face of
churn [48, 32], an important concern for botnets, where
individual machines may be frequently disinfected or
simply turned off for the night. Finally, structured over-
lay networks also have protection mechanisms against
active attacks [12].
In this work, we examine the question of whether ISPs
can detect these efﬁcient communication structures of
peer-to-peer (P2P) botnets and use this as a basis for bot-
net defense. ISPs, enterprise networks, and IDSs have
signiﬁcant visibility into these communication patterns
due to the potentially large number of paths between
bots that traverse their routers. Yet the challenge is sep-
arating botnet trafﬁc from background Internet trafﬁc, as
each botnet node combines command-and-control com-
munication with the regular connections made by the ma-
chine’s user. In addition, the massive scale of the com-
munications makes it challenging to perform this task ef-
ﬁciently.
We propose BotGrep, an algorithm that isolates efﬁ-
cient peer-to-peer communication structures solely based
on the information about which pairs of nodes commu-
nicate with one another (communication graph). Our
approach relies on the fast-mixing nature of the struc-
tured P2P botnet C&C graph [26, 11, 6, 79]. The Bot-
Grep algorithm iteratively partitions the communication
graph into a faster-mixing and a slower-mixing piece,
eventually narrowing on to the fast-mixing component.
Although graph analysis has been applied to botnet and
1
P2P detection [15, 36, 78, 35], our approach exploits the
spatial relationships in communication trafﬁc to a sig-
niﬁcantly larger extent than these works. Based on ex-
perimental results, we ﬁnd that under typical workloads
and topologies our techniques localize 93-99% of botnet-
infected hosts with a false positive probability of less
than 0.6%, even when only a partial view of the commu-
nication graph is available. We also develop algorithms
to run BotGrep in a privacy-preserving fashion, such that
each ISP keeps its share of the communication graph pri-
vate, and show that it can still be executed with access to
a moderate amount of computing resources.
The BotGrep algorithm is content agnostic, thus it is
not affected by the choice of ports, encryption, or other
content-based stealth techniques used by bots. However,
BotGrep must be paired with some sort of malware de-
tection scheme, such as anomaly or misuse detection,
to be able to distinguish botnet control structures from
other applications using peer-to-peer communication. A
promising approach starts with a honeynet that “traps” a
number of bots. BotGrep is then able to take this small
seed of bot nodes and recover the rest of the botnet com-
munication structure and nodes.
Roadmap: We start by giving a more detailed prob-
lem description in Section 2. In Section 3, we describe
our overall approach and core algorithms, and describe
privacy-preserving extensions that enable sharing of ob-
servations across ISP boundaries in Section 4. We then
evaluate performance of our algorithms on synthetic bot-
net topologies embedded in real Internet trafﬁc traces in
Section 5. We provide a brief discussion of remaining
challenges in Section 6, and describe related work in Sec-
tion 7. Finally, we conclude in Section 8.
2 System Architecture
In this section we describe several challenges involved in
detecting botnets. We then describe our overall architec-
ture and system design.
Challenges: Over the recent years, botnets have been
adapting in order to evade detection and their activities
have become increasingly stealthy. Botnets use random
ports, encrypt their communication contents, thus defeat-
ing content-based identiﬁcation. Trafﬁc patterns, which
have previously been used for detection [29], could po-
tentially be altered as well, using content padding or
other approaches. However, overall, it seems hard to hide
the fact that two nodes are communicating, and thus we
use this information as the basis for our design.
However, we are faced with several additional chal-
lenges. The background trafﬁc on the Internet is highly
variable and continuously changing, and likely dwarfs
the small amount of control trafﬁc exchanged between
botnet hosts. Further, botnet nodes combine their ma-
licious activity with the regular trafﬁc of the legitimate
users, thus they are deeply embedded inside the back-
ground communication topology. For example, Fig-
ure 1(b) shows a visualization of a synthetic P2P bot-
net graph embedded within a communication graph col-
lected from the Abilene Internet2 ISP. The botnet is
tightly integrated and cannot be separated from the rest
of the nodes by a small cut.
In order to observe a signiﬁcant fraction of botnet
C&C trafﬁc, it is necessary to combine observations from
many vantage points across multiple ISPs. This creates
an extremely large volume of data, since originally the
background trafﬁc will be captured as well. Thus, any
analysis algorithms face a signiﬁcant scaling challenge.
In addition, although ISPs have already demonstrated
their willingness to detect misbehavior in order to better
serve their customers [3] as well as cooperating across
administrative boundaries [4], they may be reluctant to
share trafﬁc observations, as those may reveal conﬁden-
tial information about their business operations or their
customers.
We next propose a botnet defense architecture that ad-
dresses these challenges.
System architecture : As a ﬁrst step, our approach
requires collecting a communication graph, where the
nodes represent Internet hosts and edges represent com-
munication (of any sort) between them. Portions of this
graph are already being collected by various ISPs: the
need to perform efﬁcient accounting, trafﬁc engineer-
ing and load balancing, detection of malicious and dis-
allowed activity, and other factors, have already led net-
work operators to deploy infrastructure to monitor trafﬁc
across multiple vantage points in their networks. Bot-
Grep operates on a graph that is obtained by combin-
ing observations across these points into a single graph,
which offers signiﬁcant,
though incomplete visibility
into the overall communication of Internet hosts 1. Traf-
ﬁc monitoring itself has been studied in previous work
(e.g., [44]), and hence our focus in this work is not on
architectural issues but rather on building scalable botnet
detection algorithms to operate on such an infrastructure.
A second source of input is misuse detection. Since
botnets use communication structures similar to other
P2P networks, the communication graph alone may not
1Tools such as Cisco IOS’s NetFlow [2] are designed to sample
trafﬁc by only processing one out of every 500 packets (by default).
To evaluate the effect of sampling, we replayed packet-level traces col-
lected by the authors of [42] from Storm botnet nodes, and simulated
NetFlow to determine the fraction of botnet links that would be de-
tected. We found that in the worst case (assuming each ﬂow traversed a
different router), after 50 minutes, 100% of botnet links were detected.
Moreover, recent advances in counter architectures [77] may enable
efﬁcient tracking of the entire communication graph without need for
sampling.
2
(a)
(b)
Figure 1: (a) BotGrep architecture and (b) Abilene network with embedded P2P subgraph
be enough to distinguish the two. Some form of indica-
tion of malicious activity, such as botnet nodes trapped in
Honeynets [68] or scanning behavior detected by Dark-
nets [7], is therefore necessary. A list of misbehaving
hosts can act as an initial “seed” to speed up botnet iden-
tiﬁcation, or it can be used later to verify that the detected
network is indeed malicious.
The next step is to isolate a botnet communication sub-
graph. Recently, botnet creators have been turning to
communication graphs provided by structured networks,
both due to their advantages in terms of efﬁciency and
resilience, and due to easy availability of well-tested
implementations of the structured P2P algorithms (e.g.,
Storm bases the C&C structure for its supernodes on the
Overnet implementation of Kademlia [50]). One com-
mon feature of these structured graphs is their fast mix-
ing time, i.e., the convergence time of random walks to a
stationary distribution. Our algorithm exploits this prop-
erty by performing random walks to identify fast-mixing
component(s) and isolate them from the rest of the com-
munication graph.
If sharing of sensitive information
is an issue, it is possible to perform random walks in a
privacy-preserving fashion on a graph that is split among
a collection of ISPs.
Once the botnet C&C structure is identiﬁed and con-
ﬁrmed as malicious, BotGrep outputs a set of suspect
hosts. This list may be used to install blacklists into
routers, to conﬁgure intrusion detection systems, ﬁre-
walls, and trafﬁc shapers; or as “hints” to human oper-
ators regarding which hosts should be investigated. The
list may also be distributed to subscribers of the service,
potentially providing a revenue stream. The overall ar-
chitecture is shown in Figure 1(a).
3
Inference Algorithm
Our inference algorithm starts with a communication
graph G = (V,E) with V representing the set of hosts
3
observed in trafﬁc traces and undirected edges e ∈ E in-
serted between communicating hosts. Embedded within
G is a P2P graph Gp ⊂ G, and the remaining subgraph
Gn = G− Gp containing non-P2P communications. The
goal of our algorithms is to reliably partition the input
graph G into {Gp,Gn} in the presence of dynamic back-
ground trafﬁc and with only partial visibility.
3.1 Approach overview
The main idea behind our approach is that, since most
P2P topologies are much more highly structured than
background Internet trafﬁc, we can partition by detect-
ing subgraphs that exhibit different topological patterns
from each other or the rest of the graph. We do this
by performing random walks, and comparing the relative
mixing rates of the P2P subgraph structure and the rest
of the communication graph. The subgraph correspond-
ing to structured P2P trafﬁc is expected to have a faster
mixing rate than the subgraph corresponding to the rest
of the network trafﬁc. The challenge of the problem is to
partition the graph into these two subgraphs when they
are not separated by a small cut, and to do so efﬁciently
for very large graphs.
Our approach consists of three key steps. Since the
input graph could contain millions of nodes, we ﬁrst ap-
ply a preﬁltering step to extract a smaller set of candi-
date peer-to-peer nodes. This set of nodes contains most
peer-to-peer nodes, as well as false positives. Next, we
use a clustering technique based on the SybilInfer algo-
rithm [21] to cluster only the peer-to-peer nodes, and re-
move false positives. The ﬁnal step involves validating
the result of our algorithms based on fast-mixing charac-
teristics of peer-to-peer networks.
3.2 Preﬁltering Step
The key idea in the preﬁltering step is that for short ran-
dom walks, the state probability mass associated with
nodes in the fast-mixing subgraph is likely to be closer to
the stationary distribution than nodes in the slow-mixing
subgraph. Let P be the transition matrix of the random
walks. P is deﬁned as
if i → j is an edge in G
otherwise
,
(1)
(cid:40) 1
di
0
Pi j =
where di denotes the degree of vertex i in G.
The probability associated with each vertex after the
short random walk of length t, denoted by qt, can be be
used as a metric to compare vertices and guide the ex-
traction of the P2P subgraph. The initial probability dis-
i = 1/|V|, which means that the
tribution q0 is set to q0
walk starts at all nodes with the equal probability. We
can recursively compute qt as follows:
qt = qt−1 · P
(2)
Now, since nodes in the fast-mixing subgraph are
likely to have qt values closer to the stationary distri-
bution than nodes in the slow-mixing subgraph, and be-
cause the stationary distribution is proportional to node
degrees, we can cluster nodes with homogeneous qt
val-
i
di
ues. However, before doing so, we apply a transfor-
mation to dampen the negative effects of high-degree
nodes on structured graph detection. High-degree nodes
or hubs are responsible for speeding up the mixing rate
of the non-structured subgraph Gn and can reduce the
relative mixing rate of Gp as compared to Gn. The trans-
formation ﬁlter is as follows:
(cid:19) 1
r
(cid:18) qt
i
di
si =
,
(3)
where r is the dampening constant. We can now cluster
vertices in the graph by using the k-means algorithm [47]