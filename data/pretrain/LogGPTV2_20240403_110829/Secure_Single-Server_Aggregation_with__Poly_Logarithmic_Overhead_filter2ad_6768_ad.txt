σ = 40 and η = 30, so long as k ≥ 385. Whilst this already saves a
factor of 2500 over the complete graph, even lower requirements
are shown to suffice in Section 5.
4 THE MALICIOUS PROTOCOL
In this section we show how to extend the ideas behind our semi-
honest protocol to withstand an adversary that controls the server
and a fraction γ of the n clients, as before, but where the adversary
can deviate from the protocol execution. This includes, for example,
sending incorrect messages, dropping out, or ignoring certain mes-
sages. Crucially, our protocol retains the computational benefits
of the semi-honest variant: sublinear (polylog) client computation
and communication in n.
Figure 1: Probability mass functions of Xi ∼ HyperGeom(n −
1, γn, k) and Yi ∼ HyperGeom(n − 1,(1 − δ)n, k).
To argue about E2 we will leverage the connectivity properties of
Harary graphs. Consider a graph H = Harary(n, k) and assume that
k is even w.l.o.g. Recall that these graphs can be easily constructed
by putting nodes 1, . . . , n in a circle and connecting each node to
the k/2 nodes to its left and the k/2 nodes to its right (around the
circle). The property that we will use in our argument is that to
disconnect H one needs to remove at least k/2 successive nodes.
To see this consider any way of removing nodes, assume without
loss of generality that node 1 is not removed and assume that some
node is not connected to 1 (and has not been removed). Let m be
such a node of smallest index. Consider nodes m − k/2, . . . , m − 1.
None of these can be 1 otherwise m would be directly connected
to 1. Furthermore none of them can be connected to 1 and present
as otherwise m would be connected to 1 via them, but as m was
minimal none of them can be disconnected from 1 and present.
Therefore they must all be missing, as required.
This property implies that, as G from Algorithm 1, is simply H
but with nodes randomly renamed, we have that Pr[E2(C, D, G′) =
0] ≤ n(γ + δ)k/2, by a union bound across clients and the fact that
(γ +δ)k/2 is an upper bound on the probability that k/2 “successive”
nodes following a particular node in G are in C ∪ D (recall that
|C| ≤ γn and D ≤ δn).
The following lemma captures the three points we have made
so far. Let us remark that it does not tell us immediately how large
k should be. Instead, it states sufficient (efficiently checkable) con-
ditions that would imply that a given k was secure given the rest
of the parameters, and thus it will become central in Section 5.
Lemma 3.7. Let n > 0 be a set of clients, let σ , η be security and
correctness let γ , δ ∈ [0, 1] be the maximum fraction of corrupt and
dropout clients, respectively, and let k, t be natural numbers such that
t ∈ (0, k). Let
Xi ∼ HyperGeom(n − 1, γn, k), Yi ∼ HyperGeom(n − 1,(1 − δ)n, k)
be random variables. If the following two constraints hold then the
distribution D over pairs (G, t) implemented by Algorithm 1 is (σ , η)-
good:
(1) 1 − cdfXi(t − 1) + (δ + γ)k/2
(2) cdfYi(t) < 2−η/n
< 2−σ/n
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA1259Powerful adversary. To illustrate the power of such an adversary,
let us describe a simple attack on the protocol of the previous section
that can be run by a malicious server, by simply giving inconsistent
views of which users dropped out to different clients. The goal of
the server in this attack is to recover the private vector (cid:174)xu from a
target client u. Let N = NG(u) be the set of neighbors chosen by
u in an execution without drop-outs. After collecting all masked
inputs, the server tells all clients in N = [n] \ N that the immediate
neighbors of u, i.e., every client in N , have dropped out. In other
words, the server requests shares that are sufficient to recompute
the pairwise masks of everyone in N . Note that these masks include
values that cancel with all of u’s pairwise masks. Hence, to obtain
u’s private vector, the server can announce to clients in N that u
did not drop out to also recover u’s self mask. Note that the server’s
malicious behavior here is only in notifying everyone in N that
clients in N have dropped out, while simultaneously requesting
shares of u’s self mask from all clients in N . For this reason, this
attack succeeds against any variant of the abstract protocol from
the previous section, regardless of the choice of graph G.
What can the server legitimely learn in a robust protocol? While
clearly the above attack is a problem as the server can learn a single
client’s data, formalizing what constitutes an attack against a proto-
col that aims at being robust against dropouts has some subtleties.
Note that a malicious server can always wait for an execution where
there are no dropouts, and simulate them by ignoring certain mes-
sages. Concretely, if a protocol is robust against a fraction δ of the
clients dropping out, and the adversary controls a fraction γ of the
clients, we cannot hope to prevent the server from learning the
sum of any subset H of honest clients of their choice, as long as
|H| ≥ (1 − δ − γ)n.
Bonawitz et al. [8] show how to modify their protocol so that it
is secure in the presence of such a server by adding a “consistency
check” round at the end of the protocol. This additional round
prevents the server from learning the sum of any subset H of size
|H| ≤ α · n, by ensuring that at least α · n clients, with α = Ω(1),
are given a consistent view of who dropped out. Unfortunately, this
consistency check requires to transmit such a set of size α ·n to each
client, yielding a communication overhead linear in n. Achieving
the analogous goal (ensuring that α is a constant fraction of the
secret sharing degree) in our O(log n)-degree regular graphs from
Section 3 would give α = O(log n/n), which is unsatisfactory from
a security standpoint: the number of values among which an honest
client’s value is hidden is too small, e.g., about 9 for n = 104. Thus,
we require completely new ideas to make α independent of n.
We show that α can in fact be made a constant fraction inde-
pendent of n while retaining polylog communication in n. More
concretely, we show that the server cannot learn the sum of any
subset H of honest clients such that |H| < αn for α = Ω(1).
4.1 Security Definition
Intuitively, we want to define a summation protocol as being α-
secure, for α ∈ [0, 1], if honest clients are guaranteed that their
private value will be aggregated at most once with at least αn other
values from honest clients. Formalizing this requires care. We will
use a simulation-based proof, where we show that any attacker’s
{N1, ..., Nk +1}) and, for each subset Ni it either returns
view of the execution can be simulated in a setting where the at-
tacker (which controls the server and a fraction of the clients) does
not interact with the honest clients but a simulator that does not
have the honest parties’ inputs. Instead, we assume that the simu-
lator can query once an oracle computing an “ideal” functionality
that captures the leakage that we are willing to tolerate. We denote
the functionality by FX,α as it is parameterized by the set X of
the honest parties’ inputs and α ∈ [0, 1]. It takes as input a parti-
tion of the honest clients (a collection of pairwise disjoint subsets
i∈Ni (cid:174)xi if
the subset is “large enough”, namely |Ni| ≥ α · |X|, or answers ⊥.
Definition 4.1 (α-Summation Ideal Functionality). Let n, R, ℓ be
integers, and α ∈ [0, 1]. Let H ⊆ [n] and XH = { (cid:174)xi}i∈H where
(cid:174)xi ∈ Zℓ
The α-summation ideal functionality overXH , denoted by FXH ,α ,
is defined for all partition {H1, . . . , Hκ} ∈ PH as
F(cid:174)x,α({H1, . . . , Hκ}) = {S1, . . . , Sκ} ,
. Let PH be the set of partitions of H.
R
where
∀k ∈ [1, κ],
Sk =
(cid:26) 
⊥
i∈Hk (cid:174)xi
if |Hk| ≥ α · |H|,
otherwise.
Note that the above definition’s only goal is to characterize an
“upper bound” on what an adversary controlling the server could
learn from the protocol, and is unrelated to correctness guarantees.
Let us remark that the prescribed output for the server, as in the
semi-honest case, is the sum of the inputs (cid:174)xi of surviving clients.
Along with our security theorem, we provide a correctness result
that states a guarantee for semi-honest executions in Theorem 4.8,
and discuss the security of our protocol in the (weaker) threat model
where the server is honest in Section 4.6.
4.2 The Malicious Protocol
Our precise protocol is Algorithm 3 in the appendix. Here we discuss
the intuition behind it.
Similarly to Bonawitz et al. [8], we need the assumption that,
roughly speaking, the clients participating in the execution are
“real” clients, and not simulated by the server as part of a Sybil
attack. This could be achieved assuming a Public Key Infrastructure
(PKI) external to the clients and server. It also suffices to assume
that the server behaves semi-honestly during the key collection
phase. Thus below we assume: the server behaves semi-honestly
during Part I of the protocol and commits the public keys of all “real”
clients in a Merkle tree. This limits the power of a malicious server
to interrupting the communication between parties in subsequent
rounds, which is equivalent to making it appear to certain parties
that certain other parties have dropped out.
A first hurdle in extending our efficient semi-honest protocol
from Section 3 to the malicious setting, which does not apply to the
protocol of Bonawitz et al., is that we cannot rely on the server to
generate the communication graph G anymore, as it may deviate
from the prescribed way and assign many malicious neighbors to
an honest client. Hence, the first difference will be that in the pro-
tocol from this section the graph will be generated in a distributed
way (Part II of Algorithm 3). G = (V, E) with V = [n], will now
be a directed graph, and (i, j) ∈ E will mean that client i chose
to trust client j with shares of its secrets; this relationship will
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA1260not be symmetric. We denote by N•→(i) = {j ∈ V : (i, j) ∈ E}
the outgoing neighbors of i. This graph generation algorithm will
enable to prove that no honest client has too many corrupt neigh-
bors with overwhelming probability. In particular, we define the
following event, and will show in Lemma 4.7 that the event holds
with overwhelming probability for the (random) graph generated
in Part II.
Definition 4.2 (Not too many corrupt neighbors (malicious case)).
Let k, t be integers such that k < n and t ∈ (k/2, k), and let C ⊂ [n]
be such that |C| ≤ γn. We define event E4 as
E4(C, G, k, t) = 1 iff ∀i ∈ [n] \ C : |N•→(i) ∩ C| < 2t − k .
Another hurdle, emphasized by the simple attack described at
the beginning of the section, comes as the adversary can give incon-
sistent views to each honest client about which clients dropout. The
first issue is that the adversary must never learn both the shares
of the self-mask and the secret key of a user i that submitted its
masked value. However, even if what precedes holds, this does not
mean that we are satisfying our security definition. As discussed
above, we also want to provide a K-anonymity-style guarantee
that a client input revealed to the server has been combined with
K = α · n clients where α = Ω(1). We show that it suffices to have
a logarithmic number of neighbors and a local consistency check.
Our first issue is solved by the bound 2t − k (instead of t) in
Definition 4.2, and by the fact that a neighbor of i reveals at most
one share from i. Indeed, if mi is the number of malicious neighbors
of i, the adversary needs to learn 2t − 2mi shares from the k − mi
honest neighbors of i to recover both bi and sk
; when the event
in Definition 4.2 holds, i.e. mi < 2t − k, we know the adversary
cannot learn both secret values of i.
As for the second issue, let us describe a way to fix the simple
attack we described, which as we will see leads to a general solution.
Recall that in the attacks, all clients believe that neighbors c1, . . . , ck
of u (the target client) have dropped out, while the ci’s are in fact
alive and report shares from u. Instead, we will make sure each ci
refuses to release any secrets (about u or anybody else) unless the
server can convince them that “enough” of their neighbors know
that they are alive. In particular, the server will have to provide the
ci’s with p = k −t +1 signed messages (assuming that all clients are
honest) from ci’s neighbors stating that they have been informed
that ci is alive, and thus will not release shares of ci’s secret key. To
extend this idea to the setting with corrupted clients it is enough
to note that if we knew that every honest client has no more than
m corrupted neighbors then setting p = k − (t − m) + 1 would
suffice, as we could conservatively assume that the server already
possesses m shares from each client via the corrupted clients. Finally,
to find a value for m that works with overwhelming probability we
will rely on the fact that the number X of corrupted neighbors is
distributed as HyperGeom(n − 1, γn, k) (as in Section 3), and thus an
m ≈ kγ +(cid:112)k + log n suffices.
1
i
Lemma 4.3 (Informal). No honest client i reveals a share and has
more than t shares of their secret key sk
revealed.
1
i
The previous modification prevents the secrets of the ci from
being revealed, but does not yet prevent the attack from going
through. Indeed, if the server told u that all its neighbors have
dropped out, u will mask its input vector only with its self-mask,
which can be recovered from the ci’s by telling them u dropped out.
Henceforth, we will additionally have ci not reveal a secret about u
unless she received a signed message from u that the pairwise mask
between u and ci was included in u’s masked input.
The final challenge therefore consists in proving that the two
countermeasures above prevent the adversary from learning the
sum of the inputs of a “small clique” of clients. Instead, we want
to show that the server needs to aggregate at least α · n clients to
hope to learn anything about their inputs with α = Ω(1). Denote
by S a set of honest clients and assume that every honest client
has no more than m corrupted neighbors; in order to learn the
self-masks of the clients in S, the server needs all of them to have
at least t − m honest clients revealing shares of their self-masks.
However, these honest clients reveal such a share only if they know
the pairwise mask has been included in the sum. Therefore, the
server will also need to include those neighbors in the set S. Now
the server needs that each client in S chooses a fraction ≈ t/k − γ
of their neighbors from S, where γ is the fraction of compromised
clients, and hence we obtain that the server will not learn anything
about a set S unless |S|/n is at least ≈ t/k −γ, which is independent
of n when t is a fraction of k. We define the following event, and
show in Lemma 4.7 that it holds with overwhelming probability for
the random graph generated in Part II.
Definition 4.4 (No small near cliques). Let C ⊂ [n]. We define the
event E5 as E5(C, G, t, α) = 1 iff
∀S ⊂ [n] \ C, |S| < αn,∃i ∈ S, |N•→(i) ∩ (C ∪ S)| < t .
Finally, for the protocol to be correct in the presence of up to δ ·n