### 4. The Malicious Protocol

In this section, we extend the ideas behind our semi-honest protocol to withstand an adversary that controls the server and a fraction \(\gamma\) of the \(n\) clients. The adversary can deviate from the protocol execution by, for example, sending incorrect messages, dropping out, or ignoring certain messages. Importantly, our protocol retains the computational benefits of the semi-honest variant: sublinear (polylog) client computation and communication in \(n\).

#### Probability Mass Functions
Figure 1 illustrates the probability mass functions of \(X_i \sim \text{HyperGeom}(n - 1, \gamma n, k)\) and \(Y_i \sim \text{HyperGeom}(n - 1, (1 - \delta)n, k)\).

#### Connectivity Properties of Harary Graphs
To argue about \(E_2\), we leverage the connectivity properties of Harary graphs. Consider a graph \(H = \text{Harary}(n, k)\) and assume \(k\) is even without loss of generality. These graphs can be constructed by placing nodes \(1, \ldots, n\) in a circle and connecting each node to the \(k/2\) nodes to its left and the \(k/2\) nodes to its right. A key property is that to disconnect \(H\), one needs to remove at least \(k/2\) successive nodes.

To see this, consider any way of removing nodes. Assume without loss of generality that node 1 is not removed and some node is not connected to 1. Let \(m\) be such a node with the smallest index. Nodes \(m - k/2, \ldots, m - 1\) cannot be 1, as this would connect \(m\) to 1. Furthermore, none of these nodes can be connected to 1 and present, as \(m\) would then be connected to 1 via them. Since \(m\) was minimal, none of them can be disconnected from 1 and present. Therefore, they must all be missing.

This property implies that, for \(G\) from Algorithm 1, which is simply \(H\) with nodes randomly renamed, we have \(\Pr[E_2(C, D, G') = 0] \leq n(\gamma + \delta)k/2\). This follows from a union bound across clients and the fact that \((\gamma + \delta)k/2\) is an upper bound on the probability that \(k/2\) "successive" nodes following a particular node in \(G\) are in \(C \cup D\).

#### Lemma 3.7
The following lemma captures the three points we have made so far. It does not immediately tell us how large \(k\) should be but states sufficient (efficiently checkable) conditions that imply a given \(k\) is secure given the rest of the parameters.

**Lemma 3.7.** Let \(n > 0\) be a set of clients, let \(\sigma, \eta\) be security and correctness parameters, let \(\gamma, \delta \in [0, 1]\) be the maximum fractions of corrupt and dropout clients, respectively, and let \(k, t\) be natural numbers such that \(t \in (0, k)\). Let
\[ X_i \sim \text{HyperGeom}(n - 1, \gamma n, k), \quad Y_i \sim \text{HyperGeom}(n - 1, (1 - \delta)n, k) \]
be random variables. If the following two constraints hold, then the distribution \(D\) over pairs \((G, t)\) implemented by Algorithm 1 is \((\sigma, \eta)\)-good:
1. \(1 - \text{cdf}_{X_i}(t - 1) + (\delta + \gamma)k/2 < 2^{-\sigma/n}\)
2. \(\text{cdf}_{Y_i}(t) < 2^{-\eta/n}\)

#### Powerful Adversary
To illustrate the power of such an adversary, consider a simple attack on the protocol of the previous section. A malicious server can give inconsistent views of which users dropped out to different clients. The goal is to recover the private vector \(\mathbf{x}_u\) from a target client \(u\). Let \(N = N_G(u)\) be the set of neighbors chosen by \(u\) in an execution without dropouts. After collecting all masked inputs, the server tells all clients in \(N = [n] \setminus N\) that the immediate neighbors of \(u\) have dropped out. The server requests shares sufficient to recompute the pairwise masks of everyone in \(N\), including values that cancel with all of \(u\)'s pairwise masks. To obtain \(u\)'s private vector, the server can announce to clients in \(N\) that \(u\) did not drop out, thus recovering \(u\)'s self-mask.

#### Security Definition
We define a summation protocol as being \(\alpha\)-secure, for \(\alpha \in [0, 1]\), if honest clients are guaranteed that their private value will be aggregated at most once with at least \(\alpha n\) other values from honest clients. We use a simulation-based proof, where we show that any attacker's view of the execution can be simulated in a setting where the attacker (which controls the server and a fraction of the clients) does not interact with the honest clients but a simulator that does not have the honest parties' inputs. Instead, the simulator can query an oracle computing an "ideal" functionality that captures the leakage we are willing to tolerate.

**Definition 4.1 (Î±-Summation Ideal Functionality).** Let \(n, R, \ell\) be integers, and \(\alpha \in [0, 1]\). Let \(H \subseteq [n]\) and \(X_H = \{\mathbf{x}_i\}_{i \in H}\) where \(\mathbf{x}_i \in \mathbb{Z}^\ell_R\). The \(\alpha\)-summation ideal functionality over \(X_H\), denoted by \(F_{X_H, \alpha}\), is defined for all partitions \(\{H_1, \ldots, H_\kappa\} \in P_H\) as
\[ F_{\mathbf{x}, \alpha}(\{H_1, \ldots, H_\kappa\}) = \{S_1, \ldots, S_\kappa\}, \]
where
\[ \forall k \in [1, \kappa], \quad S_k = \begin{cases} 
\sum_{i \in H_k} \mathbf{x}_i & \text{if } |H_k| \geq \alpha \cdot |H|, \\
\perp & \text{otherwise}.
\end{cases} \]

#### The Malicious Protocol
Our precise protocol is detailed in Algorithm 3 in the appendix. Here, we discuss the intuition behind it.

Similar to Bonawitz et al. [8], we need the assumption that the clients participating in the execution are "real" clients, not simulated by the server as part of a Sybil attack. This can be achieved assuming a Public Key Infrastructure (PKI) external to the clients and server. Alternatively, it suffices to assume that the server behaves semi-honestly during the key collection phase. Thus, we assume the server behaves semi-honestly during Part I of the protocol and commits the public keys of all "real" clients in a Merkle tree.

A first hurdle in extending our efficient semi-honest protocol from Section 3 to the malicious setting is that we cannot rely on the server to generate the communication graph \(G\). Hence, the graph will be generated in a distributed way (Part II of Algorithm 3). \(G = (V, E)\) with \(V = [n]\) will now be a directed graph, and \((i, j) \in E\) means that client \(i\) chose to trust client \(j\) with shares of its secrets; this relationship is not symmetric. We denote by \(N_{\rightarrow(i)} = \{j \in V : (i, j) \in E\}\) the outgoing neighbors of \(i\).

**Definition 4.2 (Not too many corrupt neighbors (malicious case)).** Let \(k, t\) be integers such that \(k < n\) and \(t \in (k/2, k)\), and let \(C \subset [n]\) be such that \(|C| \leq \gamma n\). We define event \(E_4\) as
\[ E_4(C, G, k, t) = 1 \iff \forall i \in [n] \setminus C : |N_{\rightarrow(i)} \cap C| < 2t - k. \]

Another hurdle is that the adversary can give inconsistent views to each honest client about which clients dropped out. The first issue is that the adversary must never learn both the shares of the self-mask and the secret key of a user \(i\) that submitted its masked value. However, even if this holds, it does not mean we satisfy our security definition. We also want to provide a K-anonymity-style guarantee that a client input revealed to the server has been combined with \(K = \alpha \cdot n\) clients where \(\alpha = \Omega(1)\). We show that it suffices to have a logarithmic number of neighbors and a local consistency check.

**Lemma 4.3 (Informal).** No honest client \(i\) reveals a share and has more than \(t\) shares of their secret key \(\text{sk}_i\) revealed.

The final challenge is proving that the two countermeasures above prevent the adversary from learning the sum of the inputs of a "small clique" of clients. Instead, we want to show that the server needs to aggregate at least \(\alpha \cdot n\) clients to hope to learn anything about their inputs with \(\alpha = \Omega(1)\). Denote by \(S\) a set of honest clients and assume every honest client has no more than \(m\) corrupted neighbors. To learn the self-masks of the clients in \(S\), the server needs all of them to have at least \(t - m\) honest clients revealing shares of their self-masks. However, these honest clients reveal such a share only if they know the pairwise mask has been included in the sum. Therefore, the server will also need to include those neighbors in the set \(S\). Now the server needs that each client in \(S\) chooses a fraction \(\approx t/k - \gamma\) of their neighbors from \(S\), where \(\gamma\) is the fraction of compromised clients. Hence, the server will not learn anything about a set \(S\) unless \(|S|/n\) is at least \(\approx t/k - \gamma\), which is independent of \(n\) when \(t\) is a fraction of \(k\).

**Definition 4.4 (No small near cliques).** Let \(C \subset [n]\). We define the event \(E_5\) as
\[ E_5(C, G, t, \alpha) = 1 \iff \forall S \subset [n] \setminus C, |S| < \alpha n, \exists i \in S, |N_{\rightarrow(i)} \cap (C \cup S)| < t. \]

Finally, for the protocol to be correct in the presence of up to \(\delta \cdot n\) dropouts, we need to ensure that the remaining clients can still correctly compute the sum.