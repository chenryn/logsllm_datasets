答：应该以2:1或者5:3的比例部署beaver和其他模块。
二、如果有10台配置完全相同的机器准备部署beaver，此时beaver的三个模块应该怎么
部署？
22
日志学院
答：beaver_datanode需要部署到10台机器上面，每台机器一个实例；beaver_master至
少部署两台机器，为避免脑裂一般3台，每台机器一个实例；beaver_broker至少部署5台
机器，每台机器一个实例。
三、什么是脑裂？
答：集群模块选主时的概念。以MySQL为例，MySQL主模块负责写数据，其他模块从主
模块同步数据。当主节点的MySQL因为某些原因离线后，一般需要根据一定机制选举出
新的MySQL主节点，当超过一半的模块认同该节点为主，则系统将该节点的模块提升为
主模块。但当MySQL集群只有2台主机时，因为是偶数，可能存在两台主机都选自己为
主的情况，这样系统就无法根据过半机制选择真正的主节点，这就是脑裂。（更多内容可
查看https://juejin.im/post/5d36c2f25188257f6a209d37）
本章习题：
1、使用终端连接任一台日志易服务器，你能找到heka、collector、kafka、logriver进程的
进程号吗？需要使用什么命令查找？
2、已知在日志易产品中，编辑agent配置的操作在yottaweb日志中的关键字是
modify_agent_config。不使用manager界面，如何查询到最近一天编辑agent配置的具体
时间？
3、如何查询某Linux服务器上的heka程序同时采集了多少个日志文件？
4、由于客户时间繁忙，部署日志易系统之前，我们需要自己搭建Linux环境。搭建过程中
有什么注意点？请简述具体流程。
5、在自己公司内部环境上部署一个3.0版本的日志易环境吧（单机或集群均可）。
思考：
日志易环境部署完成之后，还需要做些什么才能实现日志分析呢？
23
日志学院
二、日志易产品架构
做日志分析，需要对日志数据进行采集，然后将非结构化的日志数据根据其字段进行结构
化处理，将格式化的数据进行列式存储后，就可以对日志数据进行查询分析了。
日志易作为一款日志分析产品，其产品架构主要由两个数据流转路径组成，一是数据存
储，二是数据查询。
2.1 数据存储
数据存储部分有数据接入、数据缓存、数据处理、数据存储等环节。
数据接入环节主要负责日志数据的采集。通过在日志源上安装采集模块Heka，可实现该日
志源日志数据的采集，Heka会将采集来的日志数据发送到日志易服务器，日志易服务器上
的Collector模块负责接收Heka发送来的数据。
数据缓存环节主要有两个作用，一是对数据流量进行限制，以防日志量大时，因后端数据
处理模块性能瓶颈造成数据堆积，从而造成系统崩溃；二是对日志数据进行缓存，当数据
存储模块发生故障造成日志数据丢失时，可根据此处缓存的数据实现数据恢复。数据缓存
环节由kafka消息队列和Zookeeper协调服务组成。Zookeeper主要负责Kafka节点的管
理。数据经Collector发送给Kafka，由Kafka进行处理后输出给数据处理模块Logriver。
24
日志学院
数据处理环节负责将非结构化的日志数据根据其字段格式进行结构化处理。日志种类不
同，其结构化处理的规则也不相同。这块的工作由Logriver模块负责。
数据存储环节负责将结构化的数据进行存储。这个环节与数据库存储数据类似，不同的
是，日志作为文本数据，其存储更加复杂。数据存储由Beaver模块负责。
Beaver同时又负责日志数据的搜索，这会在下一小节中详细描述。
2.2 数据查询
日志分析一般使用Web页面提供搜索查询服务，用户请求到达日志易服务器时，会先由
Nginx进行代理，并将用户请求进行负载均衡、cookie绑定等处理。
用户请求经Nginx到达日志易服务器后，首先会获取到日志易产品界面。如首次登录日志
易产品界面会弹出登录框。这个动作由Yottweb模块负责提供。
当输入用户名和密码进行登录时，系统会对用户信息进行验证。权限验证部分由Frontend
模块负责。
在日志易系统中，对日志数据进行搜索分析需要使用SPL语句，这些语句需要有一个模块
负责解析，SPLServer模块负责将SPL语句转化为Beaver模块可识别的语句。
然后由Beaver模块负责搜索出用户想要的数据。
之后，数据再经SPLServer、Beaver模块返回，将用户想要的数据呈现给用户。
执行一次数据查询需要经过前端代理、权限验证、数据查询、数据搜索模块。
本章习题：
1、手动绘制日志易产品架构图。
2、根据绘制的产品架构图，向你的小伙伴讲述日志易数据存储及查询的简单逻辑。
思考：
当产品安装成功后，采集的数据不能成功入库，此时该如何定位是哪个模块出现了问题？
25
日志学院
三、日志关键属性
3.1 日志基本概念
在使用日志易之前，需理解并掌握几个最基本的概念。日志的重要属性和这些概念息息相
关，同时这些概念贯穿整个日志易系统。做好相关的规划将对产品的使用带来极大的便
利。
3.1.1 appname
指应用名称，用于标识日志的应用来源，在数据采集时手动指定。
日志易必要属性：系统对日志结构化处理、划分日志分组、快捷搜索、索引路由、数据归
档等功能都和 appname 相关，设置正确将有效帮助您管理您的数据。
3.1.2 tag
标签，标识日志的扩展信息，可定义多个。 在数据采集时手动指定，可指定多个tag，多
个 tag以逗号分隔。
日志易必要属性：系统对日志结构化处理、划分日志分组、快捷搜索等功能都和 tag 相
关，设置正确将有效帮助您管理您的数据。
3.1.3 ip
日志来源IP。 在数据采集时自动指定。
日志易重要属性：标识数据来源的IP。日志易企业版1.10版本支持。日志易日志采集客户
端（heka agent） 1.10.0.11 以上版本支持。
26
日志学院
3.1.4 hostname
日志来源主机名。标识数据来源所在主机。在数据采集时自动指定。
日志易重要属性：默认上报主机名信息，可支持人为修改。
3.1.5 source
日志文件绝对路径。在数据采集时自动指定。
日志易重要属性：日志采集时客户端会上报该信息，rsyslog、syslog数据不含有该字段。
利用source，可提取日志文件路径中的重要信息(应用名称、时间等)，同时配合其他日志
属性，可以缩小查询范围实现快捷搜索。
3.1.6 raw_message
原始日志内容。在数据采集时自动指定。
日志易必要属性：数据进入日志系统，通过该字段可以查看到原始日志内容。
3.1.7 field
日志字段。在数据结构化处理/日志解析时，根据解析规则指定。
日志易重要属性：代表日志中特定位置的内容的含义。通过使用日志易结构化的日志字
段，方便用于检索和统计。日志易支持在查询时提取新的字段，以满足使用的需要。
3.1.8 logtype
日志类型，表示日志被何种解析规则解析。在数据结构化处理时手动指定。
日志易重要属性：用于标识日志的类型。一般情况下，具有相同日志字段的数据，我们将
使用同一个 logtype 做标识，但非强制要求。在日志易系统中，通过 logtype 可以区分数
据是否被正确结构化，使用时，输入 logtype:other 可以查询到未被系统正确结构化的数
据。
3.1.9 timestamp
时间戳贯穿数据的整个生命周期。时间戳是日志易必要属性，用于标识日志的时间信息。
27
日志学院
时间戳的重要性
时间戳与索引存储以及查询关系非常密切，是否正确解析时间戳对后续日志分析有非常大
的影响。日志易建议所有进入系统的数据都做时间戳解析识别。日志实时处理是日志易系
统的一大特点，进入系统的数据，日志易系统默认为数据为实时更新数据，通过日志发送
时间来标识日志的时间。从上述日志发送时间的概念中可以知道，该时间并非和实际日志
产生时间非常吻合，这样就会造成一定的偏差，导致在搜索时时间范围选择有误造成结果
不准确。
举例说明：有一个2016年产生的日志文件，日志内容为2016年标识的数据，该日志需要
进行采集。我们于2017年11月05日采集该离线日志，并在2017年11月05日当天内完
成采集和入库。在未进行时间戳解析识别的情况下，前台搜索选定2016年度的时间段是
不 能搜索出数据的，需要在2017-11-05 00:00:00至2017-11-06 00:00:00时间段可以搜
索出数据。为了解决类似问题，我们需要使用“日志解析时间”来处理，也就是说只有被
日志易系统识别的时间戳，才能在预期时间范围内精确查询。因此对于未能进行时间戳识
别的日志，在使用日志易时需要和采集时间配合使用，即需要人为记住要查询的日志的采
集时间。显然时间一长，就被遗忘。
时间分类
在日志易系统，时间戳又进行了如下区分:
日志内容时间：日志产生的时间。一般情况日志内容里都会记录该时间，会包括年、月、
日、时、分、秒、毫秒。特殊情况下时间会不完全，可能只记录了时、分、秒信息，未记
录年、月、日信息。日志易不建议缺失年月日等基本时间信息，信息缺失将不利于后续的
索引管理和数据查询。在处理这种情况下的时间时，需要多加留意，尽可能将年月日等信
息补全。
日志发送时间：使用日志易日志采集客户端将采集到的数据发送给日志易服务端所记录的
时间。同一批发送的数据将会是相同的日志发送时间。
日志接收时间：日志易服务端接收到日志的时间，同一批接收的数据将会是相同的接收时
间。
日志解析时间：在日志易数据结构化过程中，通过日志易时间戳识别功能所解析的时间。
时间戳识别之后，在查询时通过指定对应的时间查询范围才可以搜索到对应的日志。
从日志内容中抽取时间戳有两种场景：
1、 当该日志时间格式较为标准时，在日志接入时就能识别出该日志内容中的时间戳；
2、 当该日志时间格式不太标准时，需要在日志解析时识别该日志内容中的时间戳，并将
其转换为标准时间戳格式。此时，日志内容时间和日志解析时间为同一时间。
28
日志学院
在日志接入时识别出日志内容中时间戳样例如下：
在日志解析时识别日志时间戳样例如下：
当日志采集时无法提取时间戳，且该日志解析时时间戳没有做识别，或日志原文中没有时
间戳时，日志入库时会使用agent发送日志的时间——即“日志发送”时间作为日志的
timestamp。
29
日志学院
日志接收时间则是日志易系统Collector模块接收到日志的时间，即
collector_recv_timestamp。根据Agent采集日志的时间agent_send_timestamp及Collector
模块接收到日志的时间collector_recv_timestamp可以计算日志入库延时。
针对时间戳识别，我们制作了专题，该专题对于常见的时间戳格式进行枚举，用实例方式
讲解如何识别时间戳，详见本材料字段解析章节的《时间戳解析》小节。
针对以上日志基本概念，我们以实际场景为例来讲解，以便加深大家对术语的理解，详见
下一小节。
3.2 日志关键属性定义实例
在基本了解日志易基本概念之后，我们结合具体的场景来讲解如何将这些日志的关键属性
应用到实际工作中。
3.2.1 场景描述
该场景共 6 台服务器，运行 2 套业务系统，分别为官网系统 (www) 和 客服系统
(icustomer)。
现在我们需要将涉及到的日志接入到日志易系统，以便后续查询检索。那么在接入日志
前，我们需要整体规划如何将这些日志做好区分。
30
日志学院
由于是业务场景，我们可以按照业务系统对所要接入的各主机上的日志进行分类：
业务系统名称 中间件名称 ip Source/要接入的日志
/opt/logs/access.log
nginx 192.168.1.10
/opt/logs/error.log
www 192.168.1.12 /opt/logs/php.log
php
192.168.1.13 /opt/logs/php.log
mysql 192.168.1.14 /opt/logs/mysqld.log
/opt/logs/access.log
nginx 192.168.1.11
/opt/logs/error.log
icustomer
java 192.168.1.12 /opt/logs/java.log
mysql 192.168.1.15 /opt/logs/mysqld.log
3.2.2 日志接入：属性命名
按照业务系统和中间件名称，命名要接入的日志的appname和tag。
业务系统名 中间件名 Source/要接入的日
ip appname tag
称 称 志
nginx_acces
192.168.1.1
nginx /opt/logs/access.log s
0
/opt/logs/error.log nginx_error
192.168.1.1
www 2 /opt/logs/php.log www php
php
192.168.1.1
3 /opt/logs/php.log php
192.168.1.1 /opt/logs/mysqld.lo
mysql
4 g mysql
31
日志学院
nginx_acces
192.168.1.1
nginx /opt/logs/access.log s
1
/opt/logs/error.log nginx_error
icustome