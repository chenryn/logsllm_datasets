only require the minimal number of servers [16] to toler-
ate f faults: 3f + 1. The price for this minimal replication
is that every time new servers are added, the data must be
copied to them.
When more machines are available, it is possible to use
the additional replicas to speed up view changes. We offer
this capability through the new spread parameter. When
the spread parameter m is non-zero, quorum operations
involve more servers than strictly necessary. This mar-
gin allows the quorums to still intersect when a few new
servers are added, allowing these view changes to proceed
quickly. As a result, there are now two different kinds of
view changes: one in which data must be copied and one
in which no copy is necessary. In the second case we say
that the old and new views belong to the same generation.
Each view is tagged with a generation number g that is in-
cremented at each generation change.
These two parameters, m and g, are stored in the view
meta-data alongside with N, f and t.
The additional servers do not necessarily need to be
used to speed up view changes. Using a smaller m with
a given n makes the quorums smaller and reduces the load
on the system. The parameter m therefore allows the ad-
ministrator to trade-off low load and quick view changes.
Intra-Generation: When Quorums Still Intersect When
clients write using the DQ-RPC operation, their message
is received by a quorum of responsive servers. The size
of the quorum depends on the parameters of the current
view t (recall that t is also determined in the course of
a DQ-RPC). The quorum size depends on the failure as-
sumptions made by the protocol. For a U-dissemination
Byzantine protocol that tolerates b faulty servers, the quo-
rum size is q(n, b, m) = (cid:16)(n + b + 1)/2 + m/4(cid:17).
In the absence of view changes, our quorums intersect
in b+1+ m/2 servers. If m new (blank) servers are added
to the system, then our quorums intersect in b + 1 servers,
which is still sufﬁcient for correctness: one of the servers
is correct and the reader will recognize the signature on the
correct data. Thus, up to m servers can be added to the sys-
tem before data must be copied to any of the new servers.
Similarly, if m of the servers that were part of a write
quorum are removed, new quorums will still intersect in
b + 1 servers and the system will behave correctly. Finally,
if b is increased or reduced by up to m (causing the quo-
rums to grow or shrink accordingly), new quorums will
still intersect the old ones in b + 1 servers.
More generally, if after a write a servers are added, d
servers are removed, b is modiﬁed by c, and m is reduced
to mmin then the quorums will still intersect sufﬁciently as
long as a + d + c ≤ mmin. If a view change would break
this inequality then the value must be copied to some of
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:51:11 UTC from IEEE Xplore.  Restrictions apply. 
the new servers before the view change completes: we say
that the old and new views are in different generations.
newView
we are part of
powered off
finished reading
from previous view
joining
or new view is
in same generation
newView we
are part of
limbo
newView
we are not part of
ready
Figure 5: Server transitions for the dissemination protocol
5.3.2. View changes: closing the generation gap The
copying of data across generations is done as part of the
view change protocol. Unlike the view change protocol
that is associated with simpliﬁed DQ-RPC, the full view
change protocol terminates.
View changes are initiated by the administrator when
some machines need to be added, removed or moved, or
when the resilience f or the spread m have to be changed.
The newView method ﬁrst determines whether the new
view will be in the same generation as the previous one,
using the relation in Section 5.3.1. It then computes the
key pairs and certiﬁcates for the new view. Finally the ad-
ministrator encodes the certiﬁcates using the appropriate
shared key and sends them to all servers in t, re-sending
when appropriate and waiting for a quorum of responses.
Servers switch states according to the diagram in Fig-
ure 5. When they receive a new view message for a new
generation (and they are part of that generation), servers
piggyback that message on top of a read they perform on
a quorum from the old view. They then update their value
with what they read (if it is newer than the value they cur-
rently store) and update their view certiﬁcate. If they are
part of the new view but there is no generation change then
the servers just update their view information as per the
forgetting protocol. If they are not part of the new view
then the servers update their certiﬁcates too. In that case
they will not be able to vouch for the new view since they
have no valid view certiﬁcate for it, but they will still be
able to direct clients to the current servers.
Servers are in the limbo state initially and after leaving
the view. They are in the joining state while they copy in-
formation from the older view, and they are in the ready
state otherwise. Servers process client requests in all three
states. Servers in the joining state use the view certiﬁcate
for the old view (if they have it) until they are ready.
The administrator’s newView waits for a quorum of
new servers to acknowledge the view change and then it
posts the new view to the well-known locations and re-
turns. At this point, the administrator knows that the data
stored in the machines that were removed from the view
are not needed anymore and therefore the old machines
can be powered off safely.
There may still be some machines in the joining stage at
this point. These machines do not prevent operations from
completing because DQ-RPC operations only need f + 1
servers in the new generation to complete, and any dis-
semination quorum contains at least f + 1 correct servers.
When newView returns, the old view has ended and
the new view has started and matured, meaning that at
least one correct server is done processing the view change
message for it. This means that reads and writes to the new
view will succeed and reads and writes to the old view will
be redirected to the new view (either by the old servers or
after consultation of the well-known locations).
The protocol as presented here requires the administra-
tor to be correct. If the administrator crashes after send-
ing the new view message to a single faulty new server,
the new server can cause the servers in the old view to
join the limbo state without informing the new servers that
they are supposed to start serving. In the extended techni-
cal report [15] we show a variant that tolerates crashes in
the sense that if the administrator machine crashes at any
point during the view change and never recovers then read
and write operations will still succeed even though it is not
possible to change views anymore.
5.3.3. DQ-RPC satisﬁes transquorums for dissemina-
tion quorums We now prove our ﬁnal theorem:
Theorem 2. U-dissemination, crash and hybrid-d based
on DQ-RPC provide atomic semantics.
The proof is presented in our technical report [15]. The
main lemmas used in the proof are listed below.
Lemma 3. The view t chosen by a DQ-RPC operation is
concurrent with the DQ-RPC operation.
Lemma 4. The DQ-RPC protocol in Figure 4 provides the
transquorum properties for the ordering function o of Fig-
ure 3.
Lemma 5. When using DQ-RPC for the U-dissemination,
crash or hybrid-d protocol, no R operation returns ⊥.
6. Conclusions
We present a methodology that easily transforms sev-
eral existing Byzantine protocols for static quorum sys-
tems [9, 13, 14, 17, 18] into corresponding protocols that
operate correctly when the administrator is allowed to add
or remove servers from the quorum system, as well as
to change its resilience threshold. Performing the trans-
formation does not require extensive changes to the pro-
tocols: all that is required is to replace calls to the Q-
RPC primitive used in static protocols with calls to DQ-
RPC, a new primitive that in the static case behaves like
Q-RPC but can handle operations across quorums that
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:51:11 UTC from IEEE Xplore.  Restrictions apply. 
(meta) ViewTracker.get()
// returns the latest view meta-data
1. return m maxM eta
ViewTracker.consult
// ask well-known servers for the latest meta-data
1. Choose a server j at random from the list of well-
2. Send (CONSULT, m maxM eta) to j
known view publishers
(sender, reply, meta) ViewTracker.receive(nonce)
// used by the Sender object when gathering replies
1. if there is no message waiting, then return false
2. receive (msg, meta) from sender
3. if not validCertiﬁcate(meta) then return false
4. if meta.t > m maxM eta.t then
5.
6. if msg == CONSULT-ACK then goto 1
7. return (sender, msg, meta)
m maxM eta := meta
(messages, view) ViewTracker.consistentQuorum(messageT riples)
// returns a consistent quorum of messages (if any) and the current view
1. msgInQuorun := {m ∈ messageT riples : m.sender ∈ m maxM eta.N}
2. if |msgInQuorun| < q(|m maxM eta.N|, m maxM eta.f , m maxM eta.m) then return (∅,⊥)
3. validM essages := {m ∈ msgInQuorun : validTag(m)}
4. recentM essages := {m ∈ validM essages : m.meta.g == m maxM eta.g}
5. if |recentM essages| < m maxM eta.f + 1 then return (∅,⊥)
6. return (msgInQuorun, m maxM eta)
// fail if there is no consistent quorum of messages
// fail if the view is not mature
ViewTracker.consult
// consults well-known servers for the latest meta-data
1. Choose a server j at random from the list of well-known view publishers
2. Send (CONSULT, m maxM eta) to j
Figure 6: Deﬁnition of the ViewTracker object
may not intersect while still guaranteeing consistency. Our
methodology is based on a novel approach for proving the
correctness of Byzantine quorum protocols: through our
transquorum properties, we specify the characteristics of
quorum-level primitives (such as Q-RPC) that are crucial
to the correctness of Byzantine quorum protocols and pro-
ceed to show that it is possible to design primitives, such as
DQ-RPC, that implement these properties even when quo-
rums don’t intersect. We hope that designers of new quo-
rum protocols will be able to leverage this insight to easily
make their own protocols dynamic.
7. Acknowledgments
The authors would like to thank Eunjin Jung and Jeff
Napper for several interesting conversations and feedback
on the paper presentation.
References
[1] I. Abraham and D. Malkhi. Probabilistic quorums for dynamic sys-
tems. In Proc. 17th Intl. Symp. on Distributed Computing (DISC),
Oct. 2003.
[2] L. Alvisi, D. Malkhi, E. Pierce, M. Reiter, and R. Wright. Dynamic
Byzantine quorum systems. In Proc. of the Intl. Conference on De-
pendable Systems and Networks (DSN), June 2000.
[3] L. Alvisi, D. Malkhi, E. Pierce, and M. K. Reiter. Fault detection
for byzantine quorum systems. IEEE Trans. Parallel Distrib. Syst.,
12(9):996–1007, 2001.
[4] G. V. Chockler, I. Keidar, and R. Vitenberg. Group communica-
tion speciﬁcations: a comprehensive study. ACM Computing Sur-
veys (CSUR), 33(4):427–469, 2001.
[5] S. Davidson, H. Garcia-Molina, and D. Skeen. Consistency in a
partitioned network: a survey. ACM Computing Surveys (CSUR)
Volume 17, Issue 3, pages 341–370, Sept. 1985.
[6] S. Dolev, S. Gilbert, N. Lynch, A. Shvartsman, and J. Welch. Geo-
quorums: Implementing atomic memory in mobile ad hoc net-
March 2002.
[8] S. Gilbert, N. Lynch, and A. Shvartsman. Rambo II: Rapidly re-
conﬁgurable atomic memory for dynamic networks. In Proc. 17th
Intl. Symp. on Distributed Computing (DISC), pages 259–268, June
2003.
[9] G. R. Goodson, J. J. Wylie, G. R. Ganger, and M. K. Reiter. Ef-
ﬁcient consistency for erasure-coded data via versioning servers.
Technical Report CMU-CS-03-127, Carnegie Mellon University,
2003.
[10] L. Kong, A. Subbiah, M. Ahamad, and D.M. Blough. A reconﬁg-
urable byzantine quorum approach for the agile store. In Proc. 22nd
Intl. Symp. on Reliable Distributed Systems (SRDS), Oct. 2003.
[11] L. Lamport. On interprocess communications. Distributed Com-
puting, pages 77–101, 1986.
works. In Proc. 17th Intl. Symp. on Distributed Computing (DISC),
Oct. 2003.
[7] J.R. Douceur. The sybil attack. In Proc. of the IPTPS02 Workshop,
[12] N. Lynch and A. Shvartsman. RAMBO: A reconﬁgurable atomic
memory service for dynamic networks. In Proc. 16th Intl. Symp.
on Distributed Computing (DISC), pages 173–190, Oct. 2002.
[13] D. Malkhi and M. Reiter. Byzantine quorum systems. Distributed
Computing 11/4, pages 203–213, 1998.
[14] D. Malkhi and M. Reiter. Secure and scalable replication in Pha-
lanx. In Proc. 17th IEEE Symp. on Reliable Distributed Systems
(SRDS), Oct 1998.
[15] J-P. Martin and L. Alvisi. A framework for dynamic byzantine stor-
age. Technical Report TR04-08, The University of Texas at Austin,
2004.
[16] J-P. Martin, L. Alvisi, and M. Dahlin. Minimal Byzantine storage.
In Proc. 16th Intl. Symp. on Distributed Computing (DISC), pages
311–325, Oct. 2002.
[17] J-P. Martin, L. Alvisi, and M. Dahlin. Small Byzantine quorum
systems. In Proc. of the Intl. Conference on Dependable Systems
and Networks (DSN), pages 374–383, June 2002.
[18] E. Pierce and L. Alvisi. A framework for semantic reasoning
about byzantine quorum systems. In Brief Announcements, Proc.
20th Symp. on Principles of Distributed Computing (PODC), pages
317–319, Aug. 2001.
[19] R. Rodrigues, B. Liskov, and L. Shrira. The design of a robust peer-
to-peer system. In Tenth ACM SIGOPS European Workshop, Sept.
2002.
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:51:11 UTC from IEEE Xplore.  Restrictions apply.