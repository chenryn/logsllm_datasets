ID. It then modiﬁes the instruction pointer value to point at the original address
of the system-call dispatch routine and re-executes the faulted instruction.
We use a two-step procedure to extract values of OUT parameters at system-
call return. In the ﬁrst step, we record the value present in an OUT parameter at
the beginning of the system call. Since OUT parameters are passed by reference,
the stored value is a pointer. In order to know when a system call’s execution
has completed inside the kernel, we modify the return address of an executing
thread inside the kernel with a new address that is not assigned to the guest
OS. This modiﬁcation occurs when intercepting the entry of the system call. In
the second step, a thread returning to usermode at the completion of a system
call will fault due to our manipulation. As before, the hypervisor receives the
fault. Pyren´ee reads the values of OUT parameters, restores the original return
address, and re-executes the faulting instruction. By the end of the second step,
the host attribution sensor has values for both the IN and OUT system-call
parameters.
5.4 Address Space Construction and Switching
We create isolated address space for untrusted drivers using the Xen hypervisor
and the Windows XP 32-bit guest operating system, though our design is general
and applicable to other operating systems and hypervisors. We allocate memory
for UPT page tables transparent to the guest OS inside the hypervisor. We
then map untrusted driver code pages into the UPT and trusted kernel and
driver code into the TPT. We mark all untrusted driver code pages in TPT as
non-executable and non-writable and mark all trusted code pages in UPT as
non-executable, non-writable, and non-readable.
Pyren´ee switches between the two address spaces depending upon the execu-
tion context. It manipulates the CR3 register: a hardware register that points to
the current page tables used by memory management hardware and inaccessi-
ble to any guest OS. When an untrusted driver invokes a kernel API, execution
faults into the hypervisor due the non-executable kernel code in the UPT. Inside
Automatic Discovery of Parasitic Malware
111
the hypervisor, Pyren´ee veriﬁes the legitimacy of the control ﬂow by checking
whether the entry point into the TPT is valid. If the entry point is valid, it
switches the address space by storing the value of TPT CR3, the trusted page
table base, into CR3. If the entry point is not valid, Pyren´ee records this behav-
ior as an attack and raises an alarm. Similarly, control ﬂow transfers from TPT
to UPT fault because untrusted driver code pages are marked non-executable
inside the TPT. On this fault, Pyren´ee switches the address space by storing the
untrusted page table base, UPT CR3, in the CR3 register.
Pyren´ee identiﬁes the legitimate entry points into the TPT by ﬁnding the
kernel and trusted drivers’ exported functions. These exported functions’ names
and addresses are generated from the PDB ﬁles available from Microsoft’s symbol
server. Pyren´ee keeps this information in the hypervisor for the host-attribution
sensor.
5.5 Interception of Driver Loading
Pyren´ee requires knowledge of drivers’ load addresses to map their code pages
into either the UPT or TPT. Since Windows dynamically allocates memory
for all drivers, these addresses change. Moreover, Windows uses multiple mech-
anisms to load drivers. Pyren´ee intercepts all driver loading mechanisms. It
rewrites the kernel’s binary code on driver loading paths automatically at run-
time. It modiﬁes the direct call instruction to the ObInsertObject kernel func-
tion by changing its target to point to a location in the guest which is not
assigned to the guest VM; it stores the original target. With this design, during
the driver loading process execution faults into the hypervisor. On the fault,
Pyren´ee extracts the driver’s load address securely from the driver object and
resumes the execution at the original target location. This design provides com-
plete interpositioning of driver loading.
6 Evaluation
We tested our prototype implementation of Pyren´ee to evaluate its ability to
appropriately identify malicious software on infected systems, its performance,
and its avoidance of false positives. To generate alerts notifying the correlation
engine of suspicious network activity in our test environment, we ran a network
simulator that acted as a network-based IDS.
6.1 User-Level Malware Identiﬁcation
We tested Pyren´ee’s ability to detect process-to-process parasitic behaviors with
the recent Conficker worm [38]. Conﬁcker employs DLL injection to infect be-
nign processes running on the victim system. We executed Conﬁcker inside a test
VM monitored by Pyren´ee and connected to a network overseen by our NIDS
simulator. When executed, the worm ran as a process called rundll32.exe. The
112
A. Srivastava and J. Giﬃn
host attribution sensor recorded DLL injection behavior from rundll32.exe
targeting speciﬁc svchost processes.
When our NIDS simulator sent the IP addresses and port numbers for out-
bound malicious traﬃc to Pyren´ee’s correlation engine, the engine then deter-
mined what malicious code on the host was responsible. It searched the network
attribution sensor’s data to extract the name of the process bound to the con-
nection’s source port, here svchost.exe. It then searched the host attribution
sensor’s data and found that svchost.exe was the victim of a parasitic DLL
injection from rundll32.exe. The correlation engine also found the names of
other executables infected by the malware, and it generated a complete listing
that could be sent to a security administrator.
We repeated these tests with the Adclicker.BA trojan and successfully de-
tected its parasitic behavior.
6.2 Kernel-Level Malware Identiﬁcation
We evaluated Pyren´ee’s ability to detect kernel-level parasitism by testing it with
the recent Storm worm [23]. Storm is kernel-level malware that exhibits parasitic
behaviors by injecting malicious DLLs into the benign services.exe process,
causing services.exe to launch DDoS attacks. We loaded Storm’s malicious
driver in the test VM. Since the driver is untrusted, Pyren´ee loaded it into the
separate isolated address space. On the execution of the driver’s code, all kernel
APIs invoked by the driver were veriﬁed and logged by Pyren´ee’s host attribution
sensor. The sensor found that the driver was performing injection via APCs, and
it recorded both the parasitic behavior and the victim process.
When our network simulator ﬂagged the traﬃc made by services.exe, the
correlation engine gathered the data collected by the host and network attri-
bution sensors. The network attribution sensor determined services.exe to be
the end-point of the connection, and the host attribution sensor identiﬁed the
parasitism of the malicious driver.
6.3 Performance
We designed Pyren´ee to operate at runtime, so its performance cost on an end
user’s system must remain low. We tested our prototype on an Intel Core 2
Quad 2.66 GHz system. We assigned 1 GB of memory to the untrusted Win-
dows XP SP2 VM and 3 GB combined to the Xen hypervisor and the high-
privilege Fedora Core 9 VM. We carried out CPU and memory experiments
using a Windows benchmark tool called PassMark Performance Test [24]. We
measured networking overheads using IBM Page Detailer [13] and wget. Our
experiments measured Pyren´ee’s overhead during benign operations, during ac-
tive parasitic attacks, and during the isolation of a heavily-used driver in the
UPT. We executed all measurements ﬁve times and present here the median
values.
First, we measured Pyren´ee’s overhead on CPU-bound and memory inten-
sive operations. Tables 3 and 4 list a collection of benchmark measurements for
Automatic Discovery of Parasitic Malware
113
Table 3. Results of CPU performance tests for unmonitored execution and for
Pyren´ee’s monitoring with and without parasitic behaviors present; higher absolute
measurements are better. Percentages indicate performance loss.
Parasitic Behavior
Operations
Integer Math (MOps/sec)
Floating Point Math (MOps/sec)
Compression (KB/sec)
Encryption (MB/sec)
String Sorting (Thousand strings/sec)
Unmonitored Present % Absent %
124.8 1.34
92.5 26.88
6.17
439.5
444.3 5.14
0.41 1496.0 0.32
1494.7
4.20 0.24
2.82 1072.3 2.81
126.5
468.4
1500.9
4.21
1103.3
4.19 0.48
1072.2
Table 4. Results of memory performance tests for unmonitored execution and for
Pyren´ee’s monitoring with and without parasitic behaviors present; higher absolute
measurements are better. Percentages indicate performance loss.
Operations
Allocate Small Block (MB/sec)
Write (MB/sec)
Unmonitored Present % Absent %
2322.3 14.22 2704.1 0.12
1.83 1942.9 1.23
1931
2707.4
1967.0
Parasitic Behavior
execution in a VM with and without Pyren´ee’s monitoring. For executions in-
cluding Pyren´ee, we measured performance both during execution of a DLL
injection attack against an unrelated process and during benign system opera-
tion. Our system’s performance in the absence of parasitic behavior is excellent
and largely reﬂects the cost of system-call tracing. Experiments including the
execution of an injection attack show diminished performance that ranges from
inconsequential to a more substantial performance loss of 27%. The additional
overhead measured during the attack occurred when Pyren´ee’s host sensor identi-
ﬁed injection behavior and harvested state information for its log. This overhead
is infrequent and occurs only when parasitic behaviors actually occur.
that
consisted of many objects
Next, we measured Pyren´ee’s performance during network operations. Us-
ing the IBM Page Detailer, we measured the time to load a complex webpage
spread across
(http://www.cnn.com)
multiple servers. The page load caused the browser to make numerous network
connections—an important test because Pyren´ee’s network attribution sensor
intercepts each packet and performs introspection on SYN packets. The result,
shown in Table 5, demonstrates that the overhead of the network attribution
sensor is low. We next executed a network ﬁle transfer by hosting a 174 MB ﬁle
on a local networked server running thttpd and then downloading the ﬁle over
HTTP using wget from the untrusted VM. Table 5 shows that Pyren´ee incurred
less than 3% overhead on the network transfer; we expect that this strong per-
formance is possible because its packet interception design does not require it to
queue and delay packets.
Finally, we measured the cost of our driver isolation strategy by isolating a
heavily-used driver in the UPT, forcing a high volume of page faults handled
114
A. Srivastava and J. Giﬃn
Table 5. Results of the network performance tests for unmonitored execution and for
Pyren´ee’s monitoring without parasitic behaviors present; smaller measurements are
better. Percentages indicate performance loss.
Operations
Page Loading (sec)
Network File Copy (sec)
Unmonitored Pyren´ee %
3.82 4.95
39.00 2.63
3.64
38.00
Table 6. Eﬀect of isolating the tcpip.sys driver on CPU operations for unmonitored
execution and for Pyren´ee’s monitoring without parasitic behaviors present; higher
measurements are better. Percentages indicate performance loss.
Operations
Integer Math (MOps/sec)
Floating Point Math (MOps/sec)
Compression (KB/sec)
Encryption (MB/sec)
String Sorting (Thousand strings/sec)
Unmonitored Pyren´ee %
122.0 3.55
434.8 7.17
1467.5 2.23
4.11 2.38
1060.8 3.85
126.5
468.4
1500.9
4.21
1103.3
Table 7. Eﬀect of isolating the tcpip.sys driver on memory performance for unmon-
itored execution and for Pyren´ee’s monitoring without parasitic behaviors present;
higher measurements are better. Percentages indicate performance loss.
Operations
Allocate Small Block (MB/sec)
Write (MB/sec)
Unmonitored Pyren´ee %
2649.8 2.12
1922.0 2.29
2707.4
1967.0
Table 8. Eﬀect of isolating the tcpip.sys driver on network performance for unmon-
itored execution and for Pyren´ee’s monitoring without parasitic behaviors present;
smaller measurements are better. Percentages indicate performance loss.
Operations
Unmonitored Pyren´ee %
Network File Copy (sec)
38.00
51.00 34.21
by our hypervisor-level code. We isolated the networking driver tcpip.sys and
repeated our previous CPU, memory, and network performance measurements
in the new setting without active parasitic behaviors. We anticipated that CPU
and memory overheads would remain similar, but that network operations would
experience decreased performance. Tables 6, 7, and 8 provide evidence that our
intuition was correct. Given that the moderate performance cost of isolating a
driver in the UPT is borne only by operations invoking that driver’s functionality,
we believe that it represents a feasible deployment strategy for unknown and
untrusted drivers. The clear performance gain to be had by relocating known-
benign drivers in the TPT provides an incentive for driver authors to produce
veriﬁably-safe drivers acceptable to a driver-signing authority.
Automatic Discovery of Parasitic Malware
115
6.4 False Positive Analysis
Pyren´ee ﬁnds malicious code present on an infected system whenever it receives
an alert from a NIDS; it does not detect attacks directly on its own. Hence, false
positives will be exhibited by Pyren´ee only when it identiﬁes a benign processes’
binary or a driver as malicious. We see two possible reasons for such behavior.
First, a NIDS may have false positives when distinguishing between benign
and malicious traﬃc, and it may mis-characterize benign traﬃc as malicious. In
this case, when the NIDS sends an alert along with the network-related informa-
tion, the network attribution sensor will identify the process that is bound to the
connection, and the correlation engine will mark that process as malicious. Cer-
tainly, this is a false positive. Fortunately, this problem will diminish over time as
NIDS’ false positive rates decrease [11]. Even in the case of such false positives,
Pyren´ee helps an administrator meaningfully look into the actual problem by
locating the endpoint of the network traﬃc. We feel that this design is stronger
than an alternative that stores a whitelist of benign parasitic applications and
considers malicious parasitic behaviors to be those initiated by non-whitelisted
applications. The alternative design requires a whitelist that may not be feasible
to generate.
Second, Pyren´ee could identify a benign process as malicious when a NIDS
correctly generates an alert. Absent implementation bugs, this could only be
possible if the network attribution sensor or the host attribution sensor collect
incorrect information. Benign parasitic behaviors, such as injections caused by
debugging, will not appear to be malicious unless the debugged process is using
the network in a way that appears to the NIDS as an attack.
7 Conclusions
We demonstrated the usefulness of identifying malicious code present on an
infected system during attacks. We presented techniques and a prototype sys-
tem, Pyren´ee, for the automatic discovery of unknown malicious code. Pyren´ee
correlates network-level events to host-level activities with the help of multi-
ple sensors and the correlation engine. When alerted by a NIDS, our system
discovered malicious code, even in the presence of parasitic malware, by corre-
lating information gathered from the host and network attribution sensors. Real
malware samples showed that Pyren´ee correctly identiﬁed malicious code. Our
performance analysis demonstrated that our solution was suitable for real world
deployment.
Acknowledgment of Support and Disclaimer. We thank our shepherd,
Davide Balzarotti, and our anonymous reviewers for their extremely helpful
comments. This material is based upon work supported by National Science
Foundation contract number CNS-0845309. Any opinions, ﬁndings, and conclu-
sions or recommendations expressed in this material are those of the authors
and do not reﬂect the views of the NSF or the U.S. Government.
116
A. Srivastava and J. Giﬃn
References
1. Baliga, A., Ganapathy, V., Iftode, L.: Automatic inference and enforcement of
kernel data structures invariants. In: ACSAC, Anaheim, CA (December 2008)
2. Christodorescu, M., Jha, S., Seshia, S.A., Song, D., Bryant, R.E.: Semantics-aware
malware detection. In: Proceedings of the IEEE Symposium on Security and Pri-
vacy, Oakland, CA (May 2005)
3. Christodorescu, M., Sailer, R., Schales, D., Sgandurra, D., Zamboni, D.: Cloud
security is not (just) virtualization security. In: Cloud Computing Security Work-
shop, Chicago, IL (November 2009)
4. Community Developers. Ebtables, http://ebtables.sourceforge.net/ (last ac-
cessed April 15, 2010)
5. Dinaburg, A., Royal, P., Sharif, M., Lee, W.: Ether: Malware analysis via hardware
virtualization extensions. In: ACM CCS, Alexandria, VA (October 2008)
6. Dunlap, G., King, S., Cinar, S., Basrai, M., Chen, P.: Revirt: Enabling intrusion
analysis through virtual-machine logging and replay. In: OSDI, Boston, MA (De-
cember 2002)
7. Forrest, S., Hofmeyr, S.A., Somayaji, A., Longstaﬀ, T.A.: A sense of self for UNIX
processes. In: IEEE Symposium on Security and Privacy, Oakland, CA (May 1996)
8. Garﬁnkel, T., Rosenblum, M.: A virtual machine introspection based architecture
for intrusion detection. In: NDSS, San Diego, CA (February 2003)
9. Giﬃn, J., Jha, S., Miller, B.: Detecting manipulated remote call streams. In: 11th
USENIX Security Symposium, San Francisco, CA (August 2002)
10. Giﬃn, J.T., Jha, S., Miller, B.P.: Eﬃcient context-sensitive intrusion detection. In:
NDSS, San Diego, CA (February 2004)
11. Gu, G., Porras, P., Yegneswaran, V., Fong, M., Lee, W.: BotHunter: Detecting mal-
ware infection through IDS-driven dialog correlation. In: USENIX Security Sym-
posium, Boston, MA (August 2007)
12. Hofmeyr, S.A., Forrest, S., Somayaji, A.: Intrusion detection using sequences of
system calls. Journal of Computer Security 6(3), 151–180 (1998)
13. IBM. Ibm page detailer,
http://www.alphaworks.ibm.com/tech/pagedetailer/download (last accessed
April 15, 2010)
14. Jiang, X., Wang, X., Xu, D.: Stealthy malware detection through VMM-based
‘out-of-the-box’ semantic view. In: ACM CCS, Alexandria, VA (November 2007)
15. Jones, S.T., Arpaci-Dusseau, A.C., Arpaci-Dusseau, R.H.: VMM-based hidden pro-
cess detection and identiﬁcation using Lycosid. In: ACM VEE, Seattle, WA (March
2008)
16. Kasslin, K.: Evolution of kernel-mode malware,
http://igloo.engineeringforfun.com/malwares/
Kimmo Kasslin Evolution of kernel mode malware v2.pdf (last accessed April
15, 2010)
17. Kephart, J., Arnold, W.: Automatic extraction of computer virus signatures. In:
Virus Bulletin, Jersey, Channel Islands, UK (1994)
18. Kim, G.H., Spaﬀord, E.H.: The design and implementation of tripwire: a ﬁle system
integrity checker. In: ACM CCS, Fairfax, VA (November 1994)