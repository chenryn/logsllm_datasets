far more important than the population.
Our upper bound and lower bound both have a D f
multiplicative term. Given a set U of objects, D f tends to
be inversely proportional to the lifespan but is independent
of the population of the honest identities. For example, if we
assume that each guide votes on y random objects in U , then
D f will be Θ(|U |/y) for any constant f < 1. Increasing the
lifespan y by x times will thus reduce loss by a multiplicative
factor of x.
To see how population may affect the loss, imagine for now
that we ﬁx the voting pattern and the lifespan of all honest
identities. As an example, let us replicate each honest identity
into x distinct new identities where each new identity casts
the same votes as the original identity. Doing so obviously
increases the population by x times. Using similar arguments
as in Theorems 3 and 5 and assuming x < M, one can show
that both the upper bound and the lower bound now become
Θ(D f log(M/x)) = Θ(D f (logM−logx)). In other words, the
loss is reduced only by some additive logarithmic term of x.
7. Loosely Bounding M
The only remaining missing piece of the DSybil defense is
to design a means to loosely bound M, the number of sybil
identities voting on any given object. DSybil uses simple
computational puzzles to bound M; the recommendation
algorithm’s strong guarantees mask the key drawbacks of
computation puzzles, as discussed in this section. Alter-
natively, one could apply sophisticated approaches such
SybilLimit [61] and SumUp [57] (that require a social
network) to better bound M. However, DSybil’s logarithmic
loss implies that the extra beneﬁt gained will likely be limited
in DSybil’s context.
Why computational puzzles sufﬁce. The ﬁrst problem with
computational puzzles is that the adversary can be much more
resourceful than a typical user. DSybil’s logarithmic loss
helps to mitigate this problem. Second, even with recurring
computational puzzles, the adversary can still abandon old
identities, reclaim resources, and create new identities. This
will result in an unlimited number of sybil identities over
293
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:54 UTC from IEEE Xplore.  Restrictions apply. 
time (though they are not simultaneously active). Fortunately,
our algorithm only requires the number of sybil voters on any
given object to be bounded. Notice that an object is likely
to have some limited lifetime. For example, most objects
in p2p ﬁle sharing systems (e.g., Credence) are only active
for a few weeks, and a news story on Digg gets most of its
votes within the ﬁrst few days. We can thus naturally impose
a limited-duration (e.g., a few weeks) voting window for
each object during which votes are permitted on the object.
Given a voting window, computational puzzles can be used
to bound M, as shown next.
Computational puzzles in DSybil. With its logarithmic loss,
DSybil can afford to start actively bounding M only when
the maximum number of votes on individual objects exceeds
some large threshold (e.g., 1 billion). As a comparison point,
the total number of PCs in the world was only around 1
billion in 2007 [50]. Thus, only during rather serious attacks
will such a threshold be exceeded.
After the threshold is exceeded, DSybil periodically (e.g.,
at the beginning of every calendar week) releases a fresh
puzzle seed. For centralized application scenarios such as
Digg, the server can readily release a fresh seed weekly. For
decentralized cases, DSybil simply uses the concatenation
of the weekly closing prices of some common stocks as the
seed [41], which are readily available on the Internet to all
users. The seed, together with an identity’s unique name,
will instantiate a computational puzzle (e.g., of 1 minute)
for the identity. Solving the puzzle will allow the identity
to vote in the next calendar week (on an arbitrary number
of objects), except that solving the very ﬁrst week’s puzzle
enables voting in the ﬁrst two weeks. The puzzle does not
need to be solved online and the solution can be submitted
anytime during the week.
To understand the guarantees, consider an object with
a one-week voting window, which can span at most two
calendar weeks. To cast 10 billion votes for the object, the
adversary needs to solve 5 billion 1-minute puzzles at least
in one of the two weeks. Assuming that an average bot is up
50% of the time, doing so would roughly require a million-
node botnet (i.e., (5× 109)/(0.5× 7× 24× 60) ≈ 106).
In the above design, we chose not to use a one-time
computational puzzle for each identity (e.g., at registration
time), because the adversary could then hoard identities and
M could be unbounded. We did not use a recurring puzzle for
each vote to avoid delays when voting. For similar reasons,
in DSybil solving the puzzle gives voting privileges for the
next week instead of the current week.
DDoS attacks. An adversary controlling a million-node
botnet may be able to launch severe DDoS attacks on
various components of the system. Even simply casting
10 billion votes may already overload the system. Dealing
with such attacks is still an active research area [25] and is
beyond the scope of this paper. DSybil is quite simple at the
implementation level, and it is unlikely to be the bottleneck
component. As future work, we intend to incorporate DSybil
into real-world recommendation systems (e.g., Digg) and
study the system’s robustness against DDoS.
8. Evaluation
We have implemented DSybil as a toolkit in Java. In
this section, we ﬁrst validate DSybil’s key assumption
on small D f , based on a number of real-world datasets
(Sections 8.1 and 8.2). Then, we demonstrate DSybil’s end-
to-end guarantees and its growing defense (Section 8.3).
8.1. Starting Point: Small Dimensions in Digg
DSybil targets applications, such as Digg, where objects
are either good or bad. Thus, our study starts with a crawled
dataset (called digg) of the news stories (together with user
votes) from Aug 2007 to July 2008 on digg.com. This large-
scale dataset has a total of 496,622 users, 36,103 objects, and
44,741,196 votes. All the votes are positive votes, because
Digg does not show the negative votes (i.e., the “buries”). In
any case, DSybil does not use negative votes. Although Digg
is not free of attacks [24], there is evidence that the scale
of the attack is limited (at least before 2009). For example,
researchers [57] found that the fraction of “suspicious objects”
on Digg is only around 0.25%. Thus we expect the dataset
to be “clean enough” for our experiments.
The setting. Consider an imaginary Digg user Alice. Recall
that D f is the smallest number of guides that can cover f
fraction of the good objects in U . For this experiment, we
construct U to contain all the objects in digg. Because the
dataset only contains positive votes, it does not tell us which
objects Alice will consider as bad. We will pessimistically
require the D f guides to cover f fraction of all the objects
in U . Because a guide does not vote on bad objects, doing
so would ensure that the D f guides cover at least f fraction
of the good objects.
To determine D f , we further need to know which users are
guides (i.e., with the same “taste” as Alice). Such information
is not available from digg. To overcome this, let Alice’s
popularity be the fraction of honest users who are guides.
We vary Alice’s popularity and for each popularity value
x, we pick a random x fraction of the users in the dataset
as guides. For example, with a 0.02 popularity, there will
be one user with the same taste as Alice in every 50 users.
In order to be able to beneﬁt from other users’ votes, we
expect Alice to have some minimal level of popularity. In
other words, if Alice has a rather esoteric taste, the help she
can obtain from other users will be minimal. For example in
digg, each object on average has 1239 votes. With lower
than 0.01 popularity, on average fewer than 12 votes out
of these 1239 votes are from users with the same taste as
294
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:54 UTC from IEEE Xplore.  Restrictions apply. 
dataset
dotnetkicks
netflix
movielens
bookcrossing
# users
2,339
480,189
6,040
105,283
# objects
2,252
17,770
3,952
341,133
# votes
45,236
100,480,507
1,000,209
1,149,780
Table 3. Additional supplementary datasets.
increases at most linearly, Alice’s per-round loss will never
increase. Thus, our later per-round loss results are likely to
be upper bounds for any Alice with a lifespan of at least a
year.
8.2. Generalization: Small D f is Fundamental
Supplementary datasets. We are interested in generalizing
our earlier ﬁndings from digg. There are a number of
other Digg-like websites (such as youtube.com, reddit.com,
mixx.com, motorpulse.com, tribalwar.com, dotnetkicks.com)
that involve user voting and recommendation of new stories
or video clips. The websites youtube.com, reddit.com, and
mixx.com only provide the total number of votes on each
object and do not show who the voters are. Thus, we
are unable to use them. The remaining three websites
(motorpulse.com, tribalwar.com, and dotnetkicks.com) have
a rather small numbers of users and objects. Among these
three, we crawled only the largest one, dotnetkicks.com
(a news site for .NET-related techniques), and use it as a
supplementary dataset (Table 3). This dataset is about 2
orders of magnitude smaller than digg. We also use three
publicly available movie/book rating datasets, netflix [48],
movielens [33], and bookcrossing [15] (Table 3).
Finally, while Credence [60] is one of our target applications,
we were not able to obtain Credence’s dataset.
Our thesis. Ideally, one would directly study the dimen-
sions in the supplementary datasets. Unfortunately, as men-
tioned above, dotnetkicks has an overly small number
of users/objects. The other datasets contain ﬁne-grained
scalar/numerical ratings, so their dimension is not even well-
deﬁned. Instead, we use these datasets in the following way.
We will focus on the fundamental cause of small dimen-
sions in digg. Figure 5(a) plots the distribution of the
number of votes cast by individual users in digg. The
ﬁgure shows a rather straight line on log-log scale, indicating
that the distribution is heavy-tail (or more precisely Pareto).
Let T be the number of good objects in U . With a Pareto
vote distribution, an honest user will cast exactly i votes (on
i random objects out of the T objects) with probability a·i−b.
Here a is a normalization factor and is a function of b and
T .
Our thesis is that such heavy-tail distribution is what
fundamentally causes the small dimensions in digg. The
intuition is that a small number of users near the “heavy tail”
can often cover a substantial fraction of all the objects (as
long as these users’ voting patterns, as in those in digg, do
Figure 4. Dimension in digg.
Alice. Thus, we consider popularities of at least 0.01. Finally,
because determining D f is NP-hard, we will use a greedy
heuristic and all our results are thus pessimistic upper bounds
on D f .
Dimension in digg. Figure 4 plots how D f changes with f ,
under different popularity values. Even for a small popularity
of 0.01, the dimension is quite small (below 5) for any
f ≤ 0.6. Section 8.3 later will show that under M = 1010,
such dimension translates to 4%–12% per-round loss in
some speciﬁc scenarios. These small dimension values are
not obvious: If all users in digg were to have cast an
equal number of votes, D0.6 would have been at least
44,741,196/496,622 ≈ 240 instead of below 5. Thus, the small
dimension is due to some users casting signiﬁcantly more
votes than others. Our experiments further show (not included
in Figure 4) that these results are robust: The dimension
remains small (around 5) even after removing the 100 heaviest
voters from the dataset.9 This is easy to understand in
hindsight—with 0.01 popularity, only 1 user out of every
100 users is a guide after all.
0.6×36,103
The dimension increases quickly as f approaches 1.0, even
under 0.1 popularity. This is due to the “coupon collection”
effect. Namely, as f → 1.0, it becomes harder and harder to
cover additional objects because many of the objects covered
are redundant. This also shows why it is critical for DSybil
not to rely on D1.0 being small.
Finally, our digg dataset is one-year long, and one may
wonder how D f will potentially grow for an Alice using Digg
for more than a year. D f can increase due to the “churn” of
the guides, where existing guides leave the system and new
guides are needed to cover objects in later rounds. However,
there are strong reasons to believe that D f will likely increase
at most linearly with Alice’s lifespan. For example, if Alice’s
lifespan reaches two years, the worst case would be for all the
existing guides to leave the system after one year. Assuming
the new guides in the second year have a similar heavy-tail
voting pattern as the old guides, this can at most double
the dimension. On the other hand, as long as the dimension
9. Our notion of “heaviest voters” is different from the notion of “top
Digg users” from http://socialblade.com/digg/topusers.html. “Heaviest voters”
is purely based on vote count, while “top Digg Users” are those who have
submitted many stories that are later promoted by Digg.
295
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:54 UTC from IEEE Xplore.  Restrictions apply. 
 0 5 10 15 20 25 301.00.80.60.40.20f-fractional DimensionFraction f0.01 popularity0.02 popularity0.05 popularity0.1 popularityFigure 5. Pareto ﬁttings. In all ﬁgures, x-axis is the # of votes cast, and y-axis is the fraction of users casting x votes.
dimension of the datasets. In our construction, each guide
votes for a random i objects, with i drawn from the given
Pareto distribution. To allow a direct comparison with digg,
we set T = 36,103 and the total number of honest users to
be 492,622. We again consider different popularity values
for Alice. For space limitations, we only present the results
under f = 0.6 (Figure 6). Obviously, the dimension only
becomes smaller for f < 0.6. We consider b ∈ [1.0,1.8] since
the b values in our ﬁttings fall within such a range. If b is
excessively large, Pareto’s tail is simply not “heavy” any
more for practical purposes. The ﬁgure shows that in all cases,
the dimension remains small. This conﬁrms that a Pareto
vote distribution implies small dimension (with reasonable b
ranges). Independent of these experimental results, we have
also obtained similar results directly via analytical methods.
We omit the details of the analysis due to space limitations.
8.3. Loss under the Worst-case Attack
Even though we have implemented DSybil, we explicitly
choose not to focus on studying DSybil’s loss against individ-
ual attack strategies experimentally (though we provide some
examples in [63]). As emphasized in Section 1, a (human)
attacker will always try to ﬁnd and use the single most
effective strategy, which is dependent on the algorithm being
attacked. It is not meaningful to discuss “typical” attack
strategies. On the other hand, we do not know either how to
construct the worst-case attack against DSybil (otherwise we
could inject such attack experimentally). Thus, we directly
use Equation 8 to (pessimistically) upper bound Alice’s loss
during the worst-case attack, based on the dimension values
in the datasets. Using this upper bound can only make our
results worse (since the upper bound may not be tight).
The setting. We consider the following scenario for a
imaginary Digg user Alice. We pessimistically use 0.01 as
Alice’s popularity. There are 36,103 news stories in digg,