oped to avoid exponential modeling complexity. Another choice is to develop
constrained L-1 approaches (e.g., co-oc [54]), which characterize some aspects of
higher-order relations (e.g., co-occurrence but not order).
Probabilistic models: existing probabilistic approaches, i.e., probabilistic FSA
equivalents, are at precision level L-3. Probabilistic PDA and probabilistic LBA
can be explored to establish L-2 and even L-1 level probabilistic models.
Practicality. In contrast to the extensive research in academia, the security
industry has not widely adopted program anomaly detection technologies. No
products are beyond L-3 level with black-box traces [33]. The main challenges
are eliminating tracing overhead and purifying training dataset.
Tracing Overhead Issue: L-2 and L-1 methods require the exposure of user-
space program activities, which could result in over 100 % tracing overhead on
general computing platforms [3]. However, Szekeres et al. found that the industry
usually tolerates at most 5 % overhead for a security solution [56].
Polluted Training Dataset Issue: most existing program anomaly detection
approaches assume the training set contains only normal traces. Unless the scope
of the norm is deﬁned as legal control ﬂows, which can be extracted from the
binary, the assumption is not very practical for a real-world product. A pol-
luted training dataset prevents a precise learning of the scope of the norm for a
detection model, which results in false negatives in detection.
7 Control-Flow Enforcement Techniques
Control-ﬂow enforcements, e.g., Control-Flow Integrity (CFI) [1] and Code-
Pointer Integrity (CPI) [39], enforce control-ﬂow transfers and prevent illegal
function calls/pointers from executing. They evolve from the perspective of
attack countermeasures [56]. They are equivalent to one category of program
anomaly detection that deﬁnes the scope of the norm as legal control ﬂows [52].
7.1 Control-Flow Enforcement
Control-ﬂow enforcement techniques range from the protection of return
addresses, the protection of indirect control-ﬂow transfers (CFI), to the protec-
tion of all code pointers (CPI). They aim to protect against control-ﬂow hijacks,
e.g., stack attacks [42]. We list milestones in the development of control-ﬂow
enforcement techniques below (with an increasing protection capability).
Return Address Protection: Stack Guard [13], Stack Shield [58].
Indirect Control-ﬂow Transfer Protection: CFI [1], Modular CFI [47].
All Code Pointer Protection: CPI [39].
288
X. Shu et al.
7.2 Legal Control Flows as the Scope of the Norm
In program anomaly detection, one widely adopted deﬁnition of the scope of
the norm SΛ is legal control ﬂows (Sect. 2.3); only basic block transitions that
obey the control ﬂow graphs are recognized as normal. The advantage of such
deﬁnition is that the boundary of SΛ is clear and can be retrieved from the
binary. No labeling is needed to train the detection system. This deﬁnition of
SΛ leads to a fruitful study of constructing automata models through static
program analysis9, e.g., FSA method proposed by Sekar et al. [50] and PDA
method proposed by Feng et al. [18].
7.3 Comparison of the Two Methods
We discuss the connection and the fundamental diﬀerence between control-ﬂow
enforcement and program anomaly detection.
Connection. Modern control-ﬂow enforcement prevents a program from exe-
cuting any illegal control ﬂow. It has the same eﬀect as the category of program
anomaly detection that deﬁnes the scope of the norm as legal control ﬂows. From
the functionality perspective, control-ﬂow enforcement even goes one step fur-
ther; it halts illegal control ﬂows. Program anomaly detection should be paired
with prevention techniques to achieve the same functionality.
Diﬀerence. A system can either learn from attacks or normal behaviors of
a program to secure the program. Control-ﬂow enforcement evolves from the
former perspective while program anomaly detection evolves from the latter.
The speciﬁc type of attacks that control-ﬂow enforcement techniques tackle is
control-ﬂow hijacking. In other words, control-ﬂow enforcement techniques do
not prevent attacks those obey legal control ﬂows, e.g., brute force attacks. Pro-
gram anomaly detection, in contrast, detects attacks, program bugs, anomalous
usage patterns, user group shifts, etc. Various deﬁnitions of the scope of the
norm result in a rich family of program anomaly detection models. One family
has the same detection capability as control-ﬂow enforcement.
8 Conclusion
Program anomaly detection is a powerful paradigm discovering program attacks
without the knowledge of attack signatures. In this paper, we provided a general
model for systematically analyzing (i) the detection capability of any model, (ii)
the evolution of existing solutions, (iii) the theoretical accuracy limit, and (iv)
the possible future paths toward the limit.
Our work ﬁlled a gap in the literature to unify deterministic and probabilis-
tic models with our formal deﬁnition of program anomaly detection. We pre-
sented and proved the theoretical accuracy limit for program anomaly detection.
We developed a uniﬁed framework presenting any existing or future program
9 Dynamically assigned transitions cannot be precisely pinpointed from static analysis.
A Formal Framework for Program Anomaly Detection
289
anomaly detection models and orders them through their detection capabilities.
According to our uniﬁed framework, most existing detection approaches belong
to the regular and the context-free language levels. More accurate context-
sensitive language models can be explored with pragmatic constraints in the
future. Our framework has the potential to serve as a roadmap and help
researchers approach the ultimate program defense without attack signature
speciﬁcation.
Acknowledgments. This work has been supported by ONR grant N00014-13-1-0016.
The authors would like to thank Trent Jaeger, Gang Tan, R. Sekar, David Evans
and Dongyan Xu for their feedback on this work. The authors would like to thank
anonymous reviewers for their comments on stochastic languages.
References
1. Abadi, M., Budiu, M., Erlingsson, U., Ligatti, J.: Control-ﬂow integrity. In: Pro-
ceedings of ACM CCS, pp. 340–353 (2005)
2. Anderson, J.P.: Computer security technology planning study. Technicl report,
DTIC (October (1972)
3. Bach, M., Charney, M., Cohn, R., Demikhovsky, E., Devor, T., Hazelwood, K.,
Jaleel, A., Luk, C.K., Lyons, G., Patil, H., Tal, A.: Analyzing parallel programs
with pin. Computer 43(3), 34–41 (2010)
4. Bhatkar, S., Chaturvedi, A., Sekar, R.: Dataﬂow anomaly detection. In: Proceed-
ings of IEEE S & P, May 2006
5. Bletsch, T., Jiang, X., Freeh, V.W., Liang, Z.: Jump-oriented programming: a new
class of code-reuse attack. In: Proceedings of ASIACCS, pp. 30–40 (2011)
6. Bresnan, J., Bresnan, R.M., Peters, S., Zaenen, A.: Cross-serial dependencies in
Dutch. In: Savitch, W.J., Bach, E., Marsh, W., Safran-Naveh, G. (eds.) The Formal
Complexity of Natural Language, vol. 33, pp. 286–319. Springer, Heidelberg (1987)
7. Canali, D., Lanzi, A., Balzarotti, D., Kruegel, C., Christodorescu, M., Kirda, E.:
A quantitative study of accuracy in system call-based malware detection. In: Pro-
ceedings of ISSTA, pp. 122–132 (2012)
8. Chandola, V., Banerjee, A., Kumar, V.: Anomaly detection for discrete sequences:
a survey. IEEE TKDE 24(5), 823–839 (2012)
9. Chandola, V., Banerjee, A., Kumar, V.: Anomaly detection: a survey. ACM Com-
put. Surv. 41(3), 1–58 (2009)
10. Checkoway, S., Davi, L., Dmitrienko, A., Sadeghi, A.R., Shacham, H., Winandy,
M.: Return-oriented programming without returns. In: Proceedings of ACM CCS,
pp. 559–572 (2010)
11. Chen, S., Xu, J., Sezer, E.C., Gauriar, P., Iyer, R.K.: Non-control-data attacks are
realistic threats. In: Proceedings of USENIX Security, vol. 14, pp. 12–12 (2005)
12. Chomsky, N.: Three models for the description of language. IRE Trans. Inf. Theory
2(3), 113–124 (1956)
13. Cowan, C., Pu, C., Maier, D., Hintony, H., Walpole, J., Bakke, P., Beattie, S.,
Grier, A., Wagle, P., Zhang, Q.: StackGuard: automatic adaptive detection and
prevention of buﬀer-overﬂow attacks. In: Proceedings of USENIX Security, vol. 7,
p. 5 (1998)
290
X. Shu et al.
14. Cox, B., Evans, D., Filipi, A., Rowanhill, J., Hu, W., Davidson, J., Knight, J.,
Nguyen-Tuong, A., Hiser, J.: N-variant systems: a secretless framework for security
through diversity. In: Proceedings of USENIX Security, vol. 15 (2006)
15. Denning, D.E.: An intrusion-detection model. IEEE TSE 13(2), 222–232 (1987)
16. Endler, D.: Intrusion detection: applying machine learning to solaris audit data.
In: Proceedings of ACSAC, pp. 268–279, December 1998
17. Eskin, E., Lee, W., Stolfo, S.: Modeling system calls for intrusion detection with
dynamic window sizes. In: Proceedings of DARPA Information Survivability Con-
ference and Exposition II, vol.1, pp. 165–175 (2001)
18. Feng, H.H., Kolesnikov, O.M., Fogla, P., Lee, W., Gong, W.: Anomaly detection
using call stack information. In: Proceedings of IEEE Security and Privacy (2003)
19. Feng, H., Giﬃn, J., Huang, Y., Jha, S., Lee, W., Miller, B.: Formalizing sensitivity
in static analysis for intrusion detection. In: Proceedings of IEEE Security and
Privacy, pp. 194–208, May 2004
20. Fogla, P., Sharif, M., Perdisci, R., Kolesnikov, O., Lee, W.: Polymorphic blending
attacks. In: Proceedings of USENIX Security, pp. 241–256 (2006)
21. Forrest, S., Hofmeyr, S., Somayaji, A.: The evolution of system-call monitoring.
In: Proceedings of ACSAC, pp. 418–430, December 2008
22. Forrest, S., Perelson, A., Allen, L., Cherukuri, R.: Self-nonself discrimination in a
computer. In: Proceedings of IEEE Security and Privacy, pp. 202–212, May 1994
23. Forrest, S., Hofmeyr, S.A., Somayaji, A., Longstaﬀ, T.A.: A sense of self for unix
processes. In: Proceedings of IEEE Security and Privacy, pp. 120–128 (1996)
24. Gao, D., Reiter, M.K., Song, D.: On gray-box program tracking for anomaly detec-
tion. In: Proceedings of USENIX Security, vol. 13, p. 8 (2004)
25. Gao, D., Reiter, M.K., Song, D.: Behavioral distance for intrusion detection. In:
Proceedings of RAID, pp. 63–81 (2006)
26. Gao, D., Reiter, M.K., Song, D.: Behavioral distance measurement using hidden
Markov models. In: Zamboni, D., Kruegel, C. (eds.) RAID 2006. LNCS, vol. 4219,
pp. 19–40. Springer, Heidelberg (2006)
27. Ghosh, A.K., Schwartzbard, A.: A study in using neural networks for anomaly and
misuse detection. In: Proceedings of USENIX Security, vol. 8, p. 12 (1999)
28. Giﬃn, J.T., Dagon, D., Jha, S., Lee, W., Miller, B.P.: Environment-sensitive intru-
sion detection. In: Proceedings of RAID, pp. 185–206 (2006)
29. Giﬃn, J.T., Jha, S., Miller, B.P.: Detecting manipulated remote call streams. In:
Proceedings of USENIX Security, pp. 61–79 (2002)
30. Giﬃn, J.T., Jha, S., Miller, B.P.: Eﬃcient context-sensitive intrusion detection. In:
Proceedings of NDSS (2004)
31. Gopalakrishna, R., Spaﬀord, E.H., Vitek, J.: Eﬃcient intrusion detection using
automaton inlining. In: Proceedings of IEEE Security and Privacy, pp. 18–31, May
2005
32. Gu, Z., Pei, K., Wang, Q., Si, L., Zhang, X., Xu, D.: Leaps: detecting camouﬂaged
attacks with statistical learning guided by program analysis. In: Processing of DSN,
June 2015
33. Hofmeyr, S.: Primary response technical white paper. http://www.ttivanguard.
com/austinreconn/primaryresponse.pdf. Accessed August 2015
34. Hopcroft, J.E.: Introduction to Automata Theory, Languages, and Computation.
Pearson Education India, New Delhi (1979)
35. Inoue, H., Somayaji, A.: Lookahead pairs and full sequences: a tale of two anomaly
detection methods. In: Proceedings of ASIA, pp. 9–19 (2007)
36. Kosoresow, A., Hofmeyer, S.: Intrusion detection via system call traces. IEEE
Softw. 14(5), 35–42 (1997)
A Formal Framework for Program Anomaly Detection
291
37. Kruegel, C., Mutz, D., Robertson, W., Valeur, F.: Bayesian event classiﬁcation for
intrusion detection. In: Proceedings of ACSAC, pp. 14–23, December 2003
38. Kruegel, C., Kirda, E., Mutz, D., Robertson, W., Vigna, G.: Automating mimicry
attacks using static binary analysis. In: Proceedings of USENIX Security, vol. 14,
p. 11 (2005)
39. Kuznetsov, V., Szekeres, L., Payer, M., Candea, G., Sekar, R., Song, D.: Code-
pointer integrity. In: Proceedings of USENIX OSDI, pp. 147–163 (2014)
40. Lee, W., Stolfo, S.J.: Data mining approaches for intrusion detection. In: Proceed-
ings of USENIX Security, vol. 7, p. 6 (1998)
41. Liao, Y., Vemuri, V.: Use of k-nearest neighbor classiﬁer for intrusion detection.
Comput. Secur. 21(5), 439–448 (2002)
42. Liebchen, C., Negro, M., Larsen, P., Davi, L., Sadeghi, A.R., Crane, S., Qunaibit,
M., Franz, M., Conti, M.: Losing control: on the eﬀectiveness of control-ﬂow
integrity under stack attacks. In: Proceedings of ACM CCS (2015)
43. Liu, Z., Bridges, S.M., Vaughn, R.B.: Combining static analysis and dynamic learn-
ing to build accurate intrusion detection models. In: Proceedings of IWIA, pp.
164–177, March 2005
44. Maggi, F., Matteucci, M., Zanero, S.: Detecting intrusions through system call
sequence and argument analysis. IEEE TDSC 7(4), 381–395 (2010)
45. Marceau, C.: Characterizing the behavior of a program using multiple-length n-
grams. In: Proceedings of NSPW, pp. 101–110 (2000)
46. Mutz, D., Valeur, F., Vigna, G., Kruegel, C.: Anomalous system call detection.
ACM TISSEC 9(1), 61–93 (2006)
47. Niu, B., Tan, G.: Modular control-ﬂow integrity. SIGPLAN Not. 49(6), 577–587
(2014)
48. Papadimitriou, C.H.: Computational Complexity. John Wiley and Sons Ltd., New
York (2003)
49. Pullum, G.K.: Context-freeness and the computer processing of human languages.
In: Proceedings of ACL, Stroudsburg, PA, USA, pp. 1–6 (1983)
50. Sekar, R., Bendre, M., Dhurjati, D., Bollineni, P.: A fast automaton-based method
for detecting anomalous program behaviors. In: Proceedings of IEEE Security and
Privacy, pp. 144–155 (2001)
51. Shacham, H.: The geometry of innocent ﬂesh on the bone: Return-into-libc without
function calls (on the x86). In: Proceedings of ACM CCS, pp. 552–561 (2007)
52. Sharif, M., Singh, K., Giﬃn, J.T., Lee, W.: Understanding precision in host based
intrusion detection. In: Kruegel, C., Lippmann, R., Clark, A. (eds.) RAID 2007.
LNCS, vol. 4637, pp. 21–41. Springer, Heidelberg (2007)
53. Shieber, S.M.: Evidence against the context-freeness of natural language. In: Kulas,
J., Fetzer, J.H., Rankin, T.L. (eds.) The Formal Complexity of Natural Language,
vol. 33, pp. 320–334. Springer, Heidelberg (1987)
54. Shu, X., Yao, D., Ramakrishnan, N.: Unearthing stealthy program attacks buried
in extremely long execution paths. In: Proceedings of ACM CCS (2015)
55. Sufatrio, Yap, R.: Improving host-based IDS with argument abstraction to prevent
mimicry attacks. In: Proceedings of RAID, pp. 146–164 (2006)
56. Szekeres, L., Payer, M., Wei, T., Song, D.: SoK: eternal war in memory. In: Pro-
ceedings of IEEE Security and Privacy, pp. 48–62 (2013)
57. Tandon, G., Chan, P.K.: On the learning of system call attributes for host-based
anomaly detection. IJAIT 15(6), 875–892 (2006)
58. Vendicator: StackShield. http://www.angelﬁre.com/sk/stackshield/. Accessed
August 2015
292
X. Shu et al.
59. Wagner, D., Dean, D.: Intrusion detection via static analysis. In: Proceedings of
IEEE Security and Privacy, pp. 156–168 (2001)
60. Wagner, D., Soto, P.: Mimicry attacks on host-based intrusion detection systems.
In: Proceedings of ACM CCS, pp. 255–264 (2002)
61. Warrender, C., Forrest, S., Pearlmutter, B.: Detecting intrusions using system calls:
alternative data models. In: Proceedings of IEEE S&P, pp. 133–145 (1999)
62. Wee, K., Moon, B.: Automatic generation of ﬁnite state automata for detecting
intrusions using system call sequences. In: Proceedings of MMM-ACNS (2003)
63. Wespi, A., Dacier, M., Debar, H.: Intrusion detection using variable-length audit
trail patterns. In: Debar, H., M´e, L., Wu, S.F. (eds.) RAID 2000. LNCS, vol. 1907,
pp. 110–129. Springer, Heidelberg (2000)
64. Xu, K., Yao, D., Ryder, B.G., Tian, K.: Probabilistic program modeling for high-
precision anomaly classiﬁcation. In: Proceedings of IEEE CSF (2015)