### Avoiding Exponential Modeling Complexity

To avoid exponential modeling complexity, one approach is to develop constrained L-1 methods, such as co-occurrence-based techniques (e.g., co-oc [54]). These methods can capture some aspects of higher-order relations, such as co-occurrence, but not the order.

### Probabilistic Models

Existing probabilistic approaches, which are equivalent to probabilistic Finite State Automata (FSA), operate at the precision level of L-3. To achieve L-2 and even L-1 level probabilistic models, probabilistic Pushdown Automata (PDA) and probabilistic Linear Bounded Automata (LBA) can be explored.

### Practicality in the Security Industry

Despite extensive academic research, the security industry has not widely adopted program anomaly detection technologies. No products currently exceed the L-3 level with black-box traces [33]. The primary challenges include reducing tracing overhead and purifying training datasets.

#### Tracing Overhead Issue

L-2 and L-1 methods require the exposure of user-space program activities, which can result in over 100% tracing overhead on general computing platforms [3]. However, the industry typically tolerates a maximum of 5% overhead for a security solution [56].

#### Polluted Training Dataset Issue

Most existing program anomaly detection approaches assume that the training set contains only normal traces. Unless the scope of "normal" is defined as legal control flows, which can be extracted from the binary, this assumption is impractical for real-world products. A polluted training dataset hinders precise learning of the normal scope, leading to false negatives in detection.

## Control-Flow Enforcement Techniques

Control-flow enforcement techniques, such as Control-Flow Integrity (CFI) [1] and Code-Pointer Integrity (CPI) [39], enforce control-flow transfers and prevent illegal function calls/pointers from executing. These techniques evolve from the perspective of attack countermeasures [56] and are equivalent to a category of program anomaly detection that defines the scope of the norm as legal control flows [52].

### Control-Flow Enforcement

Control-flow enforcement techniques range from protecting return addresses to protecting indirect control-flow transfers (CFI) and all code pointers (CPI). They aim to protect against control-flow hijacks, such as stack attacks [42]. Key milestones in the development of these techniques include:

- **Return Address Protection**: Stack Guard [13], Stack Shield [58]
- **Indirect Control-Flow Transfer Protection**: CFI [1], Modular CFI [47]
- **All Code Pointer Protection**: CPI [39]

### Legal Control Flows as the Scope of the Norm

In program anomaly detection, one widely adopted definition of the scope of the norm \( S_\Lambda \) is legal control flows (Section 2.3). Only basic block transitions that obey the control flow graphs are recognized as normal. This definition provides a clear boundary for \( S_\Lambda \) that can be retrieved from the binary, eliminating the need for labeling during training. This approach has led to significant advancements in constructing automata models through static program analysis, such as the FSA method proposed by Sekar et al. [50] and the PDA method proposed by Feng et al. [18].

### Comparison of Control-Flow Enforcement and Program Anomaly Detection

#### Connection

Modern control-flow enforcement prevents a program from executing any illegal control flow, similar to the category of program anomaly detection that defines the scope of the norm as legal control flows. From a functional perspective, control-flow enforcement goes further by halting illegal control flows. Program anomaly detection should be paired with prevention techniques to achieve the same functionality.

#### Difference

A system can learn from either attacks or normal behaviors to secure a program. Control-flow enforcement evolves from the former perspective, focusing on preventing control-flow hijacking. In contrast, program anomaly detection evolves from the latter, detecting a broader range of issues, including attacks, program bugs, anomalous usage patterns, and user group shifts. Various definitions of the scope of the norm result in a rich family of program anomaly detection models, with one family having the same detection capability as control-flow enforcement.

## Conclusion

Program anomaly detection is a powerful paradigm for discovering program attacks without prior knowledge of attack signatures. This paper provides a general model for systematically analyzing the detection capability of any model, the evolution of existing solutions, the theoretical accuracy limit, and possible future paths toward this limit.

Our work unifies deterministic and probabilistic models with a formal definition of program anomaly detection, presenting and proving the theoretical accuracy limit. We developed a unified framework that orders existing and future program anomaly detection models based on their detection capabilities. According to our framework, most existing detection approaches belong to the regular and context-free language levels. More accurate context-sensitive language models can be explored with pragmatic constraints in the future. Our framework serves as a roadmap, helping researchers approach the ultimate program defense without specifying attack signatures.

## Acknowledgments

This work was supported by ONR grant N00014-13-1-0016. The authors thank Trent Jaeger, Gang Tan, R. Sekar, David Evans, and Dongyan Xu for their feedback. We also thank anonymous reviewers for their comments on stochastic languages.

## References

[References remain unchanged]