EPZ radii permitted by Strava, which enables us to see
the affect of radius size on accuracy.
Fuzz EPZ Intersection Points.
After removing points
from each route that fall within the EPZ, we continue to
remove points up to a random distance ri past the inter-
section (see Figure 8b) where 0 < ri < F. We initially
set F to 80 meters, a value intended to approximate the
size of a city block.
8This technique provides similar operational semantics to Ardagna
et al.’s “shift center” obfuscation [27].
Figure 9: Efﬁcacy of Modify Radius defense – while larger
EPZ radii seem to reduce attack accuracy, the larger radii are
actually just enveloping entire activities.
Spatial Cloaking.
For each user, we choose a random
radius r(cid:48) from the set of permissible EPZ radii on Strava,
a random angle θ ranged from 0 to 355 by factors of 5,
and a random value d where 0 < d < r(cid:48). We then shifted
the center of the EPZ by distance d in the direction of
θ. This ensured that the EPZ still covered the user’s pro-
tected location, but that location was at a random point
within the EPZ instead of the center. d was generated us-
ing a Planar Laplacian mechanism [26] to achieve ε-geo-
indistinguishability. This function takes ε which was set
to 1 and r which was set to r(cid:48). Finally, we truncated all
user activities such that no GPS coordinate fell within the
enhanced EPZ.
6.4 Countermeasure Evaluation
Modify Radius. Against this obfuscation, we deployed
our original EPZ identiﬁcation attack as described in in
Section 3. The results are shown in Figure 9; while our
accuracy is at 99% against 0.125 mile EPZs. our effec-
tiveness plummets to 46% against 0.625 mile EPZs. This
ﬁnding would seem to suggest that a viable and imme-
diately applicable countermeasure against EPZ identiﬁ-
cation is simply to use one of the large radius options
that are already made available by Strava. Unfortunately,
upon further analysis we discovered that this was not the
case. This drop in accuracy is not a result of the increased
distance between endpoints and the protected location,
but simply that the larger radii will often completely en-
velope a posted activity. In other words, the loss of ac-
curacy can be accounted for by a decrease in observable
routes (and their endpoints). At 0.625 miles, the majority
of the activities in our dataset become invisible, dealing
a major blow to the utility of the ﬁtness tracking service.
Fuzz EPZ Intersection Points.
Against this obfusca-
tion, we considered that an attacker may try to account
for the added noise by modifying the distance similar-
ity threshold τd used in the EPZ identiﬁcation algorithm.
We considered a simple extension where τd incorporated
506    27th USENIX Security Symposium
USENIX Association
 40 50 60 70 80 90 1000.1250.2500.3750.5000.625Accuracy (Percentage)Radii of EPZs (Miles)(a) Fixed fuzz value F = 80, variable constant factor c
Figure 11: Activity example that demonstrates an attack
against the Spatial Cloaking defense. If routes are moving in
the direction of the protected location when they cross the EPZ,
linear interpolation of the routes will yield an intersection point
close to the location.
(b) Fixed constant factor c = 1, variable fuzz value F
Figure 10: Efﬁcacy of Fuzz EPZ Intersection Points defense.
Each line charts performance using a different EPZ radii.
the fuzzing value F by some constant factor:
τ(cid:48)
d = τd + cF
(6)
We parameterized c by selecting a random subset of
1,000 athletes and running our algorithm using different
c values but with a ﬁxed F of 80 meters. As shown in
Figure 10a, the optimal value of c turned out to be 1.
Having parameterized the attack, we next set out to
tune our fuzzing parameter in order to identify an accept-
able tradeoff between privacy and usability of the ﬁtness
tracking service. Selecting a different random subset of
1000 users, we applied the enhanced EPZ mechanism.
For each of the 5 permissible Strava radii r, we applied
different values of F ranging from 40 to r, with a ceiling
of 500 meters. Several interesting ﬁndings emerge from
our results, shown in Figure 10b. The ﬁrst is that, while
a protected location can be predicted with 96% accuracy
when r = 0.250 miles, that accuracy drops to 32% with
r = 0.250 miles and F = 40 meters. This is signiﬁcant
because a much larger section of the route is visible in
the latter case in spite of the dramatically improved pri-
vacy level. It is also visible that higher F values quickly
offer diminishing returns on privacy. At F = 200 me-
ters (0.124 miles), accuracy is less than or equal to 15%
against all radii. This validates our theory that injecting a
small amount of noise into EPZ intersection points may
Figure 12: Efﬁcacy of Spatial Cloaking defense (using differ-
ent EPZ radii) against linear interpolation attacks.
lead to dramatic increases in privacy level. However, we
note that there are likely more expressive models for the
attacker to overcome fuzzing noise, which we leave for
future work.
Spatial Cloaking Against this obfuscation, it no longer
makes sense for an attacker to predict the center of the
enhanced EPZ, as the protected location is equally likely
to fall anywhere within the circle. However, we predict
that the direction of an activity route as it enters the EPZ
still leaks signiﬁcant information about the user’s pro-
tected location. To demonstrate this, we propose a new
attack that interpolates the direction of routes as they en-
ter the EPZ. Figure 11 demonstrates the intuition of this
approach. For each user activity, we inspect the last 2
GPS points at the end of the route, then extend the route
through the EPZ with simple linear interpolation. After
doing this for every activity, we tabulate all of the points
in the EPZ at which these lines intersect. We then group
these intersections together to ﬁnd the maximum number
of intersection points that fall within td of one another. If
multiple intersection points were found that fell within td
of each other, we calculated the centroid of these points
and issued a prediction. We considered our prediction
successful if the highest conﬁdence centroid fell within
50 meters of the actual protected location.
USENIX Association
27th USENIX Security Symposium    507
 5 10 15 20 25 30 35 0 1 2 3 4 5 6 7 8 9 10Accuracy (percentage)c Value0.1250.2500.3750.50.625 0 10 20 30 40 50 0 50 100 150 200 250 300 350 400 450 500Accuracy (percentage)F Value (meters)0.1250.2500.3750.50.625xxx 25 30 35 40 45 500.1250.2500.3750.5000.625Accuracy (Percentage)Radii of EPZs (miles)Radii
0.125
0.250
0.375
0.500
0.625
Random Guess
6.178%
1.544%
0.686%
0.386%
0.247%
Prediction
45.0 %
41.3 %
39.1 %
37.6 %
36.2 %
Improvement
7x
27x
57x
98x
147x
Table 2: Success rate of our attack on spatial cloaking com-
pared to randomly guessing. Although the obfuscation re-
duces our identiﬁcation rate, our attack signiﬁcantly outper-
forms chance levels.
Our results can be found in Table 2. Unsettlingly,
this simple interpolation attack is 36.2 % - 45.0 % ac-
curate against geo-indistinguishability techniques. To
demonstrate the signiﬁcance of this result, consider the
likelihood of predicting the protected location by issu-
ing a random guess that falls within the EPZ, as shown
in Table 2. For small privacy zones, our approach of-
fers a 7x improvement over random guess; against large
privacy zones, our approach offers a 147x improvement
over random guessing. We also obtained similar results
when running our fuzzing obfuscation against the inter-
polation attack. While the identiﬁcation rate here is still
low, it is not difﬁcult to imagine that a more sophisticated
version of this attack that leverages more expressive in-
terpolation techniques and incorporates map information
to reduce the search space. These results point to a nat-
ural tension between the desire to publish route infor-
mation while concealing sensitive endpoints; signiﬁcant
amounts of private information is leaked through inspect-
ing the trajectory of the route. At the same time, this
countermeasure signiﬁcantly increases the complexity of
breaking an EPZ, which may prove sufﬁcient to dissuade
attackers in practice.
7 Discussion & Mitigation
7.1 Strava’s Global Heat Map Incident.
The release of Strava’s Global Heatmap published ag-
gregated public usage data for 27 million users [14]. The
motivation for publishing the heatmap was to help pro-
vide a resource for athletes to explore and discover new
places to exercise; in addition, a related Strava Metro
project leveraged this heatmap data to assist departments
of transportation and city planning groups in improving
infrastructure for bicyclists and pedestrians [19]. How-
ever, as a result of the sparsity of background noise in
some regions, the heatmap was observed to leak sensi-
tive and classiﬁed information regarding the locations
of military bases, covert black sites and patrol routes,
to name a few [24]. This information which could be
turned into actionable intelligence, leading to potentially
life-threatening situations [46].
Following the news coverage of privacy leakage in the
global heatmap, we became curious about the privacy
habits of the Strava users that exercised at these facili-
ties. We searched our dataset for activities from three
of the locations identiﬁed in popular media: the United
Kingdom’s Government Communications Headquarters
(GCHQ), Australia’s Pine Gap military facility, and Kan-
dahar Airforce Base in Afghanistan. We found that 1 of 7
athletes in our dataset were using EPZs at GCHQ, 1 of 8
athletes used EPZs at Pine Gap, and 1 of 13 athletes used
EPZs at Kandahar, suggesting that a non-negligible mi-
nority of athletes at these sites were aware of the privacy
risks and were attempting to safeguard their usage.
The ﬁndings presented in this study potentially exac-
erbate the safety risks posed by the global heatmap rev-
elations. Because many of the discovered facilities are
highly secure, their identiﬁcation in the heatmap may
not pose an immediate threat to the safety of personnel.
However, while the identities of speciﬁc athletes were
not directly leaked in the heatmap, a related vulnerability
allows an attacker to upload spoofed GPS data in order
to discover the IDs of Athletes in a given area [25]. They
can then search Strava for off-site areas that the targeted
athlete frequents, making EPZs the last line of defense
for protecting the target’s home. Unfortunately, we have
demonstrated that EPZs (as originally implemented) are
inadequate, meaning that, conceivably, an attacker could
have used our technique to identify an insecure location
associated with military or intelligence personnel. We
note again that such an attack is presently much more
difﬁcult on Strava following updates to their EPZ mech-
anism, which we describe in Section 9.
7.2 Attack Replication.9
The implications of our EPZ Identiﬁcation Attack extend
beyond one single ﬁtness tracking app. To demonstrate,
we replicated our attack on Map My Tracks [18] and
Garmin Connect [12].
Map My Tracks.
Users can set EPZs of radii 500,
1000, or 1500 meters. Map My Tracks also permits users
to export GPS coordinates of the activities of any user
in a CSV format. Like Strava, it is possible to detect
the presence of an EPZ by inspecting the “distance from
start” value of the GPS coordinates, which does not start
from 0 if a route began within an EPZ. We created an ac-
count on Map My Tracks and uploaded 4 activities start-
ing from the same “sensitive” location. Regardless of the
EPZ size used, we successfully identiﬁed the sensitive
location by running our attack, We did not need to repa-
rameterize our algorithm (i.e., τd, τi), indicating that our
values are robust across multiple services.
9Here, we describe an attack replication on companies’ prior EPZ
mechanisms, which were modiﬁed following vulnerability disclosure.
508    27th USENIX Security Symposium
USENIX Association
Garmin Connect.
Garmin Connect is ﬁtness tracking
services that allow users to share activities tracked with
compatible Garmin devices. Garmin Connect provides
EPZs with radii ranging from 100 to 1000 meters in
100 meter increments. Like Map My Tracks, Garmin
Connect allows users to export GPS coordinates of
activities of other users in GPX format (a light-weight
XML data format). Here, discrepancies between the
route information and advertised distance once again
makes it possible to infer when an EPZ is enabled on an
activity. Creating an account on Garmin Connect, we
uploaded 3 activities starting from a “sensitive” location.
When launching our attack against 100, 500, and 1000
meter EPZs, we reliably recovered the protected location.
7.3 Additional Mitigations
In addition to the speciﬁc privacy enhancements pre-
sented above, we also advise ﬁtness tracking services to
adopt the following general countermeasures to order to
increase the difﬁculty of abusing their services:
Randomize Resource IDs.
Strava and Map My Tracks
use sequential resource identiﬁers; data resources identi-
ﬁers should be randomly assigned from a large space of
possible identiﬁers (e.g., 264), as already done by Garmin
Connect, to prevent the bulk enumeration of resources.
Authenticate All Resource Requests.
Strava facilitates
surveillance at scale because it does not require authenti-
cation in order to access resources. To address this con-
cern, we recommend placing ﬁne-grained resources be-
hind an authentication wall so that Strava can monitor or
suspend accounts that issue a high volume of requests.
Server-Side Rendering of Map Resources. We do not
believe that it is necessary to expose raw GPS coordi-
nates to the client in order to provide an enriched user
experience. Instead, activity maps could be rendered at
the server, or at least ﬁltered and fuzzed to frustrate EPZ
location attempts.
Conceal Existence of EPZ. Route information exposed
to clients should be consistent in the claims they make
about the length of routes. The advertised distance of
an activity should be modiﬁed to reﬂect the portion of
the route that is hidden by the EPZ. Had there been con-
sistency of distance claims in our study, we would have
been unable to obtain a ground truth as to whether or not
an EPZ was enabled on the activity. While our method-
ology could still be used to detect likely EPZs in the ab-
sence of ground truth, there would also be a large num-
ber of false positives resulting from attempting to look
for EPZs where they did not exist.
8 Related Work
Prior to this study, the privacy considerations of ﬁtness
apps has received little consideration in the literature.
Williams [11] conducted a detailed study of Strava users
and their behavior towards Strava application. He con-
cluded that the majority of participants had considered
privacy issues when using the application and had taken
some measures to protect themselves, such as setting up
privacy zones or not listing their equipment. However, in
this work we show that only 9% of all the activities we
studied were using privacy zones, calling this result into
question. Further, we demonstrated that the privacy mea-
sures provided by Strava are insufﬁcient to protect user
privacy. The demographics of Strava users [4] indicate
that an attacker would have an ample supply of potential
targets to choose from; as seen in [6, 17], property theft
against Strava users has already been reported in the me-
dia. Our ﬁndings provide a viable explanation for how
these attacks could occur.
8.1 Location Privacy
Geo-indistinguishability has been used previously [30,
55] to provide static location privacy by perturbing the
real location with fake location. Geo-indistinguishability
is derived from differential privacy [35] and ensures that
for any two location that are geographically close it
will produce a pseduo-location with similar probabilities.
Andr´es et al. [26] used Planar Laplace mechanism to
achieve ε geo-indistinguishability by using noise drawn
from a polar Laplacian distribution and added to real lo-
cations. However, these techniques are not directly ap-
plicable to mobility data such as athletes routes that we