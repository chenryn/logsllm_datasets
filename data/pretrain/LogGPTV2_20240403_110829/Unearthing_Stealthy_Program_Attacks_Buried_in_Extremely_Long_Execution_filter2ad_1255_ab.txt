control-ﬂow segments that occur in a large-scale execution
window. We further deduce two practical security goals for
detecting aberrant path attacks. The deduction is based on
the fact that events (e.g., call, jmp, or generic instructions)
in dynamic program traces mark/indicate the control-ﬂow
segment to which they belong.
1. Event co-occurrence analysis examines the patterns of
co-occurred events in a large-scale execution window1.
We illustrate an event co-occurrence analysis in Fig. 2a.
Rules should be learned that events (cid:2)s1, s3(cid:3) or (cid:2)s2, s4(cid:3)
always occur together, but not (cid:2)s1, s4(cid:3) or (cid:2)s2, s3(cid:3).
2. Event occurrence frequency analysis examines the event
occurrence frequencies and the relations among them.
1We deﬁne the co-occurrence of events in the scope of an
execution window, not essentially at the same time.
403For instance, s1, s2 and s3 always occur at the same
frequency in Fig. 2b. Another type of event occurrence
frequency relation is generated utterly due to speciﬁc
usage patterns (mail server example in Sect. 2.2), which
can be only learned from dynamic traces.
2.4 Basic Solutions and Their Inadequacy
There are several straightforward solutions providing event
co-occurrence and occurrence frequency analysis. We point
out their limitations, which help motivate our work.
Basic Solution I: One can utilize a large n in an n-
gram approach (either deterministic approaches, e.g., [11],
or probabilistic approaches, e.g., hidden Markov model [14,
47]). This approach detects aberrant path attacks because
long n-grams are large execution windows. However, it re-
sults in exponential training convergence complexity and
storage complexity. Unless the detection system is trained
with huge number of normal traces, which is exponential to
n, a large portion of normal traces will be detected as anoma-
lous. The exponential convergence complexity explains why
no n-gram approach employs n >40 in practice [10].
Basic Solution II: One can patch existing solutions with
frequency analysis components to detect some aberrant path
attacks, e.g., DoS. The possibility has been explored by Hub-
balli et al. on n-grams [20] and Frossi et al. on automata
state transitions [13]. Their solutions successfully detect
DoS attacks through unusually high frequencies of particular
n-grams and individual automata state transitions. How-
ever, the underlying detection paradigms restrict the solu-
tions from correlating arbitrary events in a long trace. Thus,
their solutions do not detect general aberrant path attacks.
Basic Solution III: One can perform episodes mining
within large-scale execution windows.
It extends existing
frequent episode mining [25, 29] by extracting episodes (fea-
tured subsequences) at all frequencies so that infrequent-
but-normal behaviors can be characterized. In order to an-
alyze all episodes (the power set of events in a large-scale
execution window), this approach faces a similar exponen-
tial complexity of training convergence as Basic Solution I.
3. OVERVIEW OF OUR APPROACH
We present an overview of our approach analyzing event
co-occurrence and event occurrence frequencies in large-scale
execution windows. We develop a constrained agglomera-
tive clustering algorithm to overcome the behavior diversity
challenge. We develop a compact and ﬁxed-length matrix
representation to overcome the scalability problem for stor-
ing variable-length trace segments. We utilize probabilis-
tic methods to estimate normal behaviors in an incomplete
training dataset for overcoming the training scalability issue.
3.1 Proﬁling Program Behaviors
We design our approach to expose user-space program ac-
tivities (executed control ﬂow segments) via call instruc-
2 are responsible for call stack changes
tions. call and ret
and provide a natural boundary for determining execution
windows as discussed in Section 2.2.
2
ret is paired with call, which can be veriﬁed via existing
CFI technique. We do not involve the duplicated correlation
analysis of ret in our model, but we trace ret to mark
function boundaries for execution window partitioning.
We denote the overall activity of a program P within an
execution window W as a behavior instance b. Instance b
recorded in a program trace is proﬁled in two matrices:
Definition 3.1. An event co-occurrence matrix O is an
m × n Boolean matrix recording co-occurred call events in
a behavior instance b. oi,j = True indicates the occurrence
of the call from the i-th row symbol (a routine) to the j-th
column symbol (a routine). Otherwise, oi,j = False.
Definition 3.2. A transition frequency matrix F is an
m× n nonnegative matrix containing occurrence frequencies
of all calls in a behavior instance b. fi,j records the oc-
currence frequency of the call from the i-th row symbol (a
routine) to the j-th column symbol (a routine). fi,j = 0 if
the corresponding call does not occur in W .
For one speciﬁc b, O is a Boolean interpretation of F that
(cid:2)
oi,j =
True
False
if fi,j > 0
if fi,j = 0
(1)
i,j AND o(cid:2)(cid:2)
i,j .
AND O(cid:2)(cid:2)
Bitwise operations, such as AND, OR, andXOR apply to co-
computes a
O and F are succinct representations of the dynamic call
graph of a running program. m and n are total numbers
of possible callers and callees in the program, respectively.
Row/column symbols in O and F are determined through
static analysis. m may not be equal to n, in particular when
calls inside libraries are not counted.
occurrence matrices. For example, O(cid:2)
new O that oi,j = o(cid:2)
Proﬁles at diﬀerent granularities Although designed to
be capable of modeling user-space program activities via
function calls, our approach can also digest coarse level pro-
gram traces for learning program behaviors. For example,
system calls can be traced and proﬁled into O and F to
avoid excessive tracing overheads in performance-sensitive
deployments. The semantics of the matrices changes in this
case; each cell in O and F represents a statistical relation
between two system calls. The detection is not as accurate
as our standard design because system calls are coarse de-
scriptions of program executions.
3.2 Architecture of Our Approach
Our approach consists of two complementary stages of
modeling and detection where montage/frequency anomalies
are detected in the ﬁrst/second stage, respectively.
The ﬁrst stage models the binary representation of event
co-occurrences in a large-scale execution window via event
co-occurrence matrix O.
It performs event co-occurrence
analysis against montage anomalies. It consists of a training
operation Behavior Clustering and a detection operation
Co-occurrence Analysis.
The second stage models the quantitative frequency re-
lation among events in a large-scale execution window via
transition frequency matrix F . It performs event occurrence
frequency analysis against frequency anomalies. It consists
of a training operationIntra-cluster Modeling and a
detection operation Occurrence Frequency Analysis.
We illustrate the architecture of our approach in Fig. 3
and brief the functionalities of each operation below.
1. Behavior Profiling recognizes target execution win-
dows {W1, W2, . . .} in traces and proﬁles b from each
W into O and F . Symbols in F and O are retrieved via
static program analysis or system call table lookup.
404Training Phase
Detecting Phase
Program Traces (Normal)
Program Traces (Unknown)
Behavior Instance Recognition
Behavior Profiling
Behavior Clustering
Co-occu. Analysis
Intra-cluster Modeling
Occu. Freq. Analysis
Normal
i
l
s
s
y
a
n
A
c
i
t
t
a
S
s
e
i
l
a
m
o
n
A
Figure 3: Information ﬂows among operations in two stages
and two phases of our program anomaly detection approach.
2. Behavior Clustering is a training operation. It takes
in all normal behavior instances {b1, b2, . . .} and out-
puts a set of behavior clusters C = {C1, C2, . . .} where
Ci = {bi1 , bi2 , . . .} .
3. Intra-cluster Modeling is a training operation. It is
performed in each cluster. It takes in all normal behav-
ior instances {bi1 , bi2 , . . .} for Ci and constructs one de-
terministic model and one probabilistic model for com-
puting the reﬁned normal boundary in Ci.
4. Co-occurrence Analysis is an inter-cluster detection
operation that analyzes O (of b) against clusters in C to
seek montage anomalies. If behavior instance b is nor-
mal, it reduces the detection problem to subproblems
within a set of behavior clusters Cb = {Cb1 , Cb2 , . . .} ,
in which b closely ﬁts.
5. Occurrence Frequency Analysis is an intra-cluster
detection operation that analyzes F (of b) in eachC b to
seek frequency anomalies. Behavior instance b is normal
if F abides by the rules extracted from Cb and F is
within the normal boundary established in Cb.
4.
INTER-/INTRA-CLUSTER DETECTION
We detail the training/modeling and detection operations
in our two-stage approach. The key to the ﬁrst stage is a
customized clustering algorithm, which diﬀerentiates diverse
program behaviors and divides the detection problem into
subproblems. Based on the clustering, inter-/intra-cluster
detection is performed in the ﬁrst/second stage, respectively.
4.1 Behavior Clustering (Training)
We develop a constrained agglomerative clustering algo-
rithm that addresses two special needs to handle program
behavior instances for anomaly detection: i) long tail elim-
ination, and ii) borderline behavior treatment. Standard
agglomerative clustering algorithms result in a large num-
ber of tiny clusters in a long-tail distribution (shown in Sec-
tion 6.1). Tiny clusters do not provide suﬃcient numbers of
samples for statistical learning of the reﬁned normal bound-
ary inside each cluster. Standard algorithms also do not
Algorithm 1 Constrained agglomerative clustering for
grouping similar program behavior instances.
Require: a set of normal program behavior instances B and a
termination threshold Td. dist() is the distance function be-
tween behaviors/clusters. pen() is the penalty function for
long tail elimination.
continue if vO1  Td
if O1 ∈ V and O2 ∈ V then
Ensure: a set of behavior clusters C.
1: h ← ∅heap
2: v ← ∅hashtable
3: V ← ∅set
4: for all b ∈ B do
O ← Ob
5:
v[O] ← v[O] + 1
6:
for all O(cid:2) ∈ V do
7:
dp ← dist(O, O(cid:2)
8:
push (cid:4)dp, O, v[O], O(cid:2), v[O(cid:2)
9:
10:
11:
12: end for
13: while h (cid:6)= ∅heap do
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
end if
28: end while
29: w[O] ← ∅set for all O ∈ V
30: for all b ∈ B do
O ← Ob
31:
m ← MAXINT
32:
for all O(cid:2) ∈ V do
33:
if O OR O(cid:2)
= O(cid:2)
34:
then
if dist(O, O(cid:2)
) < m then
35:
m ← dist(O, O(cid:2)
36:
V (cid:2) ← {O(cid:2)}
37:
else if dist(O, O(cid:2)
38:
add O(cid:2)
to V (cid:2)
39:
40:
41:
42:
43:
44: end for
45: C ← {w[O] for all O ∈ V }
end for
add b to w[O] for all O ∈ V (cid:2)
end for
add O to V
end if
end if
) × pen(v[O], v[O(cid:2)
])
](cid:5) onto h
)
) = m then
handle borderline behaviors, which could be trained in one
cluster and tested in another, resulting in false alarms.
Our algorithm (Algorithm 1) clusters program behavior
instances based on the co-occurred events shared among in-
stances. To deal with the borderline behavior issue, we alter
the standard process into a two-step process:
i) generate
scopes of clusters in an agglomerative way (line 13-28), and
ii) add behavior instances to generated clusters (line 30-44).
We use a lazily updated heap h in Algorithm 1 to minimize
the calculation and sorting of distances between intermedi-
ate clusters. We perform lazy removal of dead clusters in
h. Dead clusters refer to the clusters that are merged into
others and no longer exist.
The scope of a cluster C = {bi | 0 ≤ i ≤ k} is represented
by its event co-occurrence matrix OC . OC records occurred
events in any behavior instances in C. It is calculated using
405(2) where Obi is the event co-occurrence matrix of bi.
OC = Ob1 OR Ob2 OR . . . OR Obk , 0 ≤ i ≤ k
(2)
The distances between i) two behavior instances, ii) two
clusters, and iii) a behavior instance and a cluster are all
measured by their co-occurrence matrices O1 and O2 in (3)
where |O| counts the number of True in O.
dist(O1, O2) =
Hamming(O1, O2)
min(|O1|,|O2|)
(3)
Hamming distance alone is insuﬃcient to guide the cluster
it loses the semantic meaning of O, and it
agglomeration:
weighs True and False the same. However, in co-occurrence
matrices, only True contributes to the co-occurrence of events.
We explain the unique features of our constrained agglom-
erative clustering algorithm over the standard design:
• Long tail elimination A standard agglomerative cluster-
ing algorithm produces clusters with a long tail distri-
bution of cluster sizes – there are a large number of tiny
clusters, and the unbalanced distribution remains at var-
ious clustering thresholds. Tiny clusters provide insuﬃ-
cient number of behavior instances to train probabilistic
models in Intra-cluster Modeling.
In order to eliminate tiny/small clusters in the long tail,
our algorithm penalizes dist(O1, O2) by (4) before push-
ing it onto h. |Ci| denotes the size of cluster Ci.
pen(|C1|,|C2|) = max(log(|C1|), log(|C2|))
(4)