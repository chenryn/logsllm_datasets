title:Quack: Scalable Remote Measurement of Application-Layer Censorship
author:Benjamin VanderSloot and
Allison McDonald and
Will Scott and
J. Alex Halderman and
Roya Ensafi
Quack: Scalable Remote Measurement of 
Application-Layer Censorship
Benjamin VanderSloot, Allison McDonald, Will Scott, J. Alex Halderman,  
and Roya Ensafi, University of Michigan
https://www.usenix.org/conference/usenixsecurity18/presentation/vandersloot
This paper is included in the Proceedings of the 
27th USENIX Security Symposium.
August 15–17, 2018 • Baltimore, MD, USA
ISBN 978-1-939133-04-5
Open access to the Proceedings of the 27th USENIX Security Symposium is sponsored by USENIX.Quack: Scalable Remote Measurement of Application-Layer Censorship
Benjamin VanderSloot, Allison McDonald, Will Scott, J. Alex Halderman, and Roya Ensaﬁ
University of Michigan
{benvds, amcdon, willscott, jhalderm, ensaﬁ}@umich.edu
Abstract
Remote censorship measurement tools can now detect
DNS- and IP-based blocking at global scale. However,
a major unmonitored form of interference is blocking
triggered by deep packet inspection of application-layer
data. We close this gap by introducing Quack, a scalable,
remote measurement system that can efﬁciently detect
application-layer interference.
We show that Quack can effectively detect application-
layer blocking triggered on HTTP and TLS headers, and
it is ﬂexible enough to support many other diverse pro-
tocols. In experiments, we test for blocking across 4458
autonomous systems, an order of magnitude larger than
provided by country probes used by OONI. We also test
a corpus of 100,000 keywords from vantage points in 40
countries to produce detailed national blocklists. Finally,
we analyze the keywords we ﬁnd blocked to provide in-
sight into the application-layer blocking ecosystem and
compare countries’ behavior. We ﬁnd that the most consis-
tently blocked services are related to circumvention tools,
pornography, and gambling, but that there is signiﬁcant
country-to-country variation.
1
Introduction
Governments often keep speciﬁc targets of censorship se-
cret, in order to avoid public accountability or to increase
fear and uncertainty [24]. We must measure censorship to
gain insights into the deployment of network interference
technologies, policy changes in censoring nations, and the
targets of interference. Making opaque censorship more
transparent illuminates this emerging practice.
Implementing global censorship measurement contin-
ues to be a challenging problem. Today, the most common
way to characterize censorship uses in-country volunteers
to host network probes, such as OONI [19], or to provide
anecdotes about what seems to be blocked to monitoring
organizations. Both are challenging to scale. Moreover,
both rely on human volunteers. For individuals living
under repressive or secretive government controls, coop-
erating with security researchers has substantial risks.
An emerging body of work addresses these problems
by using existing protocols and infrastructure to remotely
measure network interference. Such approaches have
been effective in measuring DNS poisoning [35, 41] and
for detecting interference in TCP/IP-connectivity between
remote machines [17,34]. There has not yet been a global,
remote method for detecting another broadly deployed
censorship technique: application-layer censorship.
Application-layer censorship has become increasingly
important with the rise of content delivery networks
(CDNs). CDNs use a small number of network entry-
points for a large number of customers, resulting in siz-
able collateral damage to IP-based blocking techniques.
When an adversary wishes to block some, but not all, of
these sites, they must look into the content of requests
and understand the HTTP or HTTPS headers to determine
which site is being requested. This form of blocking is
prevalent and effective, but it is not captured by measure-
ments of either DNS or IP connectivity.
In this paper, we introduce Quack, the ﬁrst remote cen-
sorship measurement technique that efﬁciently detects
application-layer blocking. Like other remote measure-
ment approaches, we make use of existing internet infras-
tructure. We rely on servers running protocols that allow
the client to send and reﬂect arbitrary data. This behavior
is present in several common protocols, such as in the
TLS Heartbeat Extension [42], Telnet servers supporting
the “echo” option [38], FTP servers allowing anonymous
read and write [43], and the Echo protocol [37]. After
identifying compatible servers with scanning, we reﬂect
packets that are crafted to trigger DPI policies. We aggre-
gate instances of reliably detected disruption to identify
what and where blocking occurs.
The bulk of our measurements use the RFC 862 Echo
Protocol [37]. Echo was introduced in the early 1980s
as a network testing tool. Servers accept connections on
TCP port 7 and send back the data they receive, making
the protocol easy to scan for and to validate expected
responses. We ﬁnd that the public IPv4 address space
USENIX Association
27th USENIX Security Symposium    187
contains over 50,000 distinct echo servers, providing mea-
surement vantage points in 196 countries and territories.
We design and evaluate an echo-based measurement sys-
tem to test over 500 domain-server pairs per second. The
echo protocol also allows us to understand the importance
of directionality, cases where blocking is only triggered
by messages leaving a region.
The efﬁciency of our technique allows us to measure
application-layer blocking in new detail. We ﬁrst test
1,000 sensitive domains from our 50,000 vantage points
around the world—taking just 28 hours. We ﬁnd anoma-
lously elevated rates of interference in 11 countries. Each
of these countries is reported as restricting web freedoms
by Freedom House [21]. We then consider a larger set of
keywords in the 40 countries with more than 100 vantage
points. We test 100,000 domains, a signiﬁcantly larger
corpus than can be efﬁciently enumerated by previous
techniques. From these experiments, we observe elevated
rates of interference for speciﬁc domains in 7 countries.
These experiments demonstrate the effectiveness of this
technique for gaining a ﬁne-grained view of application-
level blocking policy across time, space, and content.
Application-layer blocking and deep packet inspection
is meant to limit access to targeted content. However,
our measurements show evidence of implementation bugs
introducing collateral damage. For instance, a health and
wellness website is blocked in Iran because it shares part
of its name with a circumvention tool. Other websites
with similar content remain available.
By dynamically and continuously test application-layer
blocking at global scale, Quack can reveal both delib-
erately and incidentally blocked websites that have not
previously been enumerated. The source code is available
online at https://censoredplanet.org/projects/quack.html.
2 Related Work
The phenomenon of network censorship ﬁrst gained no-
toriety in 2002, when Zittrain et al. [49] investigated
keyword-based ﬁltering in China. This initial investi-
gation focused on understanding policy, based off of a
single snapshot of content blocking by a single entity.
Both detection and circumvention of censorship remain
active problems. Many studies are based on in-country
vantage points such as volunteer machines or VPNs, or
are one-time and country-speciﬁc measurement projects
such as studies on Thailand [23], China [9], Iran [4], or
Syria [7]. These direct measurements have shown how
different countries use different censorship mechanisms
such as the injection of fake DNS replies [3], the blocking
of TCP/IP connections [46], and HTTP-level blocking [12,
26]. Our measurements are also one-time; however our
technique considerably reduces the cost of longitudinal
measurement of censorship.
Application-layer Blocking Many measurement systems
measure lists of keywords to test for censorship. In the
context of the web, domain names are commonly used as
a proxy for services, and are typically drawn either from
lists of popular global domains [2], or from curated lists
of potentially sensitive domains [8]. Our system uses both
of these sources to maximize our comparability, and to
test over a sufﬁciently large corpus.
Detection of keywords more broadly has made use of
corpora extracted from observed content deletion, along
with NLP and active probing to reﬁne accuracy [11,22,48].
Previous systems determining such keywords have largely
focused on individual countries and services, especially
related to Chinese social media such as Weibo and TOM-
Skype [10, 27, 28].
Direct Measurement Systems Since censorship policies
change over time, researchers have focused on developing
platforms to run continuous censorship measurements.
One notable platform is Tor project’s Open Observatory
of Network Interference (OONI) [44], which performs
an ongoing set of censorship measurement tests from
the vantage points of volunteer participants [19]. By
running direct measurements, OONI tests are harder for
an adversarial network to speciﬁcally target. However,
these platforms cannot easily certify that it was not the
adversary themselves that contributed measurements in an
effort to confound results. Moreover, OONI has a smaller
number of vantage points, compared to our technique.
Remote Measurement Systems Academic measurement
projects have recently renewed their focus on remote mea-
surement of DNS poisoning [35, 41] and TCP/IP connec-
tivity disruptions [34]. Our system extends this broad
strategy to detect application-layer disruption. Our ap-
proach provides a uniquely detailed view of the trigger
and implementation of interference. We can answer which
direction of which packet or keyword was the trigger, and
whether interference is implemented through packet in-
jection or dropping. This level of detail is not possible in
existing DNS or IP-level side channels.
Investigations of DPI Policies Deep packet inspection
(DPI) and application-level disruption have become stan-
dard practice online [14]. Asghari et al. [5] ﬁnd support
for their hypothesis that nations pursing censorship are
likely to push deployment of DPI technology. OONI re-
ports on DPI-based censorship in 12 countries with iden-
tiﬁed vendors, and the Tor project has faced DPI-based
blocking in at least 7 countries [1].
3 Design and Implementation
Quack is designed to track the use and behavior of deep
packet inspection. We focus on four goals:
188    27th USENIX Security Symposium
USENIX Association
Detection: Since the speciﬁc triggers and behavior of DPI
systems are varied and opaque, Quack focuses on detect-
ing when keywords are blocked and the what technical
methods are employed. It does not focus on uncovering
application-speciﬁc grammars.
Safety: Quack is designed to run from a single vantage
point, with a goal of worldwide coverage without the
need to engage end users to help measure their networks.
Instead, our design focuses on the use of existing network
infrastructure, in this case echo servers, where the existing
protocol reﬂects network interference information while
minimizing risk to end-users.
Robustness: Our system must distinguish unrelated net-
work activity such as sporadic packet loss or other sys-
tematic errors that only become apparent at scale from
network interference. This goal is achieved by retrying
upon indication of failed tests.
Scalability: We aim to accurately measure the phe-
nomenon of keyword blocking on a global scale with
minimal cost. This objective is achieved by daily scans
for active echo servers, which provide us with coverage
of an average of 3,716 autonomous systems daily.
In this section, we discuss our approach to detecting
network interference, describe the speciﬁcs of the system
we designed and built, deﬁne the datasets we acquired
through our ﬁve experiments, and examine the ethical
questions that arise in this work.
3.1 System Design
The Echo Protocol We chose to focus initial measure-
ments on the Echo Protocol. The Echo Protocol, as de-
ﬁned in RFC862 in 1983 by J. Postel, is a network debug-
ging service, predating ICMP Ping. The RFC states, in
its entirety:
A very useful debugging and measurement tool is an
echo service. An echo service simply sends back to
the originating source any data it receives.
TCP Based Echo Service: One echo service is de-
ﬁned as a connection based application on TCP. A
server listens for TCP connections on TCP port 7.
Once a connection is established any data received
is sent back. This continues until the calling user
terminates the connection.
UDP Based Echo Service: Another echo service is
deﬁned as a datagram based application on UDP. A
server listens for UDP datagrams on UDP port 7.
When a datagram is received, the data from it is sent
back in an answering datagram.
There are many active echo servers around the world,
including countries known to use DPI. Our vantage points
are detailed in Section 5.
Figure 1: Echo Protocol—The Echo Protocol, when properly
performed, is a simple exchange between the client and server
where the server’s response is identical to the client’s request. In
the example above, the censoring middlebox ignores the client’s
inbound request, but reacts to the the echo server’s response,
injecting RST packets and terminating the TCP connection.
We use echo servers for their deﬁned purpose: mea-
suring transport reliability. We gain additional informa-
tion about the nature of any unreliability by varying the
transport-layer data and observing differences in the net-
work’s behavior. This affords us insight into the nuanced
network perspectives of remote hosts, contributing to the
exposure of national censorship policies.
We take advantage of three features of echo that lend
themselves to our purposes. First, the protocol has a
well deﬁned response to every request, which makes the
classiﬁcation of abnormal responses trivial. Second, due
to the to send arbitrary binary data, we can test censorship
of any application-layer protocol that utilizes TCP or
UDP as its transport protocol. In this paper, we focus on
HTTP and HTTPS. Finally, because echo servers reﬂect
content back to our measurement machine, we are able
to also detect censorship in the outbound direction, and
differentiate it from censorship triggered by our inbound
request. Direction-sensitive interference is a known
capability of modern DPI boxes. Figure 1 illustrates the
Echo Protocol in the absence of noise.
If, unlike in Figure 1, the middlebox injects a non-RST
response to the echo server, we are still able to observe
the interference. In fact, we are able to see the injected
message because the echo server will echo the content it
observes back to our measurement machine.
We note that echo is not the only protocol that can be
used for this technique. We focus on it here because it
provides a clear signal, but more scale can be achieved by
extending measurements to any other protocol where an
expected response will occur when client probes are sent.
Deﬁning A Trial We call an individual transaction with
a remote server a trial. A trial is conducted with a single
server, using a single keyword, and with a single appli-
cation protocol containing that keyword. For example,
consider example.com as a keyword wrapped within the
format of an HTTP/1.1 request.
During a trial, we initialize a connection to the server
and send it the formatted keyword. We read the response,
and pause for a short period. Finally, we send a short,
innocuous payload to verify that the connection remains
USENIX Association
27th USENIX Security Symposium    189
Echo ServerTargettingTechniqueStatusTCP/IP layerAugur In deploymentDNS layerAletheiaIn deploymentHTTP/TLSEchoIn progressIPv6, Mobile network----BrainstormingTCP HandshakeGET https://google.comGET https://google.comRSTRSTMeasurement MachineFigure 2: Test Control Flow—A single test using an echo
server is performed by following this diagram. The most com-
mon path is also the fastest, in which an echo server responds cor-
rectly to the ﬁrst request and the test is marked as Not Blocked.
If the server never responds correctly, the experiment is consid-
ered a failure and we do not use the test in our evaluation.
Figure 3: Persistent Interference Duration—We use echo
servers in all countries we observe censorship to empirically
measure the length of time interference occurs after a censorship
event has been triggered. Roughly half of the servers responded
correctly to our request within 60 seconds. By 100 seconds,
99.9% responded correctly. We therefore choose two minutes
as a safe delay in the Delay Phase.
active. If the server responds the connection is closed
successfully, we consider the trial a success.
The pause is necessary to allow injected RSTs by inter-
ference technology to reach either host in the connection.
This gives us the ability to directly identify that an inter-
fering network is attempting to exploit a race condition
via a Man-on-the-Side deployment. By verifying that
the connection is still open after the keyword is sent, we
ensure that there is not asymmetric interference occurring,
in which the interfering network closes the connection or
begins dropping packets to our measurement machine.
Test Phases The Echo Protocol enables trivial disam-
biguation between correct and incorrect responses, but
distinguishing noise from network interference requires
additional effort. The Internet is by deﬁnition best-effort,
and therefore even in the face of no interference, there
will be failed connections with echo servers. Addition-
ally, interference technologies are themselves imperfect,
meaning that some trials will be successful even when the
data is typically disallowed, for example when the DPI
boxes are overloaded [18].
Quack is designed to extract meaningful signal from
the noisiness of the network. We think about this as vali-
dating signs of failure through additional measurements,
but there is a trade-off: Not retrying would lead to many