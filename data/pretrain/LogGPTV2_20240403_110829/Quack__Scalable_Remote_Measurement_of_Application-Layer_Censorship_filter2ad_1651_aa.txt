# Quack: Scalable Remote Measurement of Application-Layer Censorship

## Authors
Benjamin VanderSloot, Allison McDonald, Will Scott, J. Alex Halderman, and Roya Ensafi  
University of Michigan  
{benvds, amcdon, willscott, jhalderm, ensafi}@umich.edu

## Publication Details
- **Conference:** 27th USENIX Security Symposium
- **Location:** Baltimore, MD, USA
- **Dates:** August 15–17, 2018
- **ISBN:** 978-1-939133-04-5
- **URL:** [https://www.usenix.org/conference/usenixsecurity18/presentation/vandersloot](https://www.usenix.org/conference/usenixsecurity18/presentation/vandersloot)

## Abstract
Remote censorship measurement tools can now detect DNS- and IP-based blocking at a global scale. However, a significant unmonitored form of interference is blocking triggered by deep packet inspection (DPI) of application-layer data. We address this gap with Quack, a scalable, remote measurement system that efficiently detects application-layer interference.

We demonstrate that Quack can effectively detect application-layer blocking triggered by HTTP and TLS headers and is flexible enough to support many other diverse protocols. In our experiments, we tested for blocking across 4,458 autonomous systems, an order of magnitude larger than the country probes used by OONI. We also tested a corpus of 100,000 keywords from vantage points in 40 countries to produce detailed national blocklists. Our analysis of blocked keywords provides insights into the application-layer blocking ecosystem and compares behavior across countries. We find that the most consistently blocked services are related to circumvention tools, pornography, and gambling, but there is significant variation between countries.

## 1. Introduction
Governments often keep specific targets of censorship secret to avoid public accountability or to increase fear and uncertainty. Measuring censorship is crucial for understanding the deployment of network interference technologies, policy changes in censoring nations, and the targets of interference. Making opaque censorship more transparent illuminates this emerging practice.

Implementing global censorship measurement remains a challenging problem. The most common method currently involves using in-country volunteers to host network probes, such as OONI, or to provide anecdotes about what seems to be blocked. Both methods are difficult to scale and rely on human volunteers, who face substantial risks under repressive or secretive government controls.

Recent work addresses these challenges by using existing protocols and infrastructure to remotely measure network interference. These approaches have been effective in measuring DNS poisoning and detecting TCP/IP connectivity disruptions. However, there has not yet been a global, remote method for detecting another widely deployed censorship technique: application-layer censorship.

Application-layer censorship has become increasingly important with the rise of content delivery networks (CDNs). CDNs use a small number of network entry points for a large number of customers, leading to significant collateral damage from IP-based blocking techniques. When an adversary wishes to block some, but not all, of these sites, they must inspect the content of requests and understand the HTTP or HTTPS headers to determine which site is being requested. This form of blocking is prevalent and effective but is not captured by measurements of DNS or IP connectivity.

In this paper, we introduce Quack, the first remote censorship measurement technique that efficiently detects application-layer blocking. Like other remote measurement approaches, we leverage existing internet infrastructure. We rely on servers running protocols that allow the client to send and reflect arbitrary data, such as the TLS Heartbeat Extension, Telnet servers supporting the "echo" option, FTP servers allowing anonymous read and write, and the Echo protocol. After identifying compatible servers through scanning, we reflect packets crafted to trigger DPI policies. We aggregate instances of reliably detected disruption to identify what and where blocking occurs.

The majority of our measurements use the RFC 862 Echo Protocol. Introduced in the early 1980s as a network testing tool, echo servers accept connections on TCP port 7 and send back the data they receive, making the protocol easy to scan and validate. We found over 50,000 distinct echo servers in the public IPv4 address space, providing measurement vantage points in 196 countries and territories. We designed and evaluated an echo-based measurement system to test over 500 domain-server pairs per second. The echo protocol also allows us to understand the importance of directionality, where blocking is only triggered by messages leaving a region.

The efficiency of our technique enables us to measure application-layer blocking in new detail. We tested 1,000 sensitive domains from our 50,000 vantage points around the world, taking just 28 hours. We found anomalously elevated rates of interference in 11 countries, all reported as restricting web freedoms by Freedom House. We then considered a larger set of keywords in the 40 countries with more than 100 vantage points, testing 100,000 domains. From these experiments, we observed elevated rates of interference for specific domains in 7 countries. These experiments demonstrate the effectiveness of this technique for gaining a fine-grained view of application-level blocking policies across time, space, and content.

Application-layer blocking and deep packet inspection are intended to limit access to targeted content. However, our measurements show evidence of implementation bugs introducing collateral damage. For example, a health and wellness website is blocked in Iran because it shares part of its name with a circumvention tool, while other similar websites remain available.

By dynamically and continuously testing application-layer blocking at a global scale, Quack can reveal both deliberately and incidentally blocked websites that have not previously been enumerated. The source code is available online at [https://censoredplanet.org/projects/quack.html](https://censoredplanet.org/projects/quack.html).

## 2. Related Work
Network censorship gained notoriety in 2002 when Zittrain et al. investigated keyword-based filtering in China. Initial studies focused on understanding policy based on a single snapshot of content blocking by a single entity. Detection and circumvention of censorship remain active research areas. Many studies use in-country vantage points, such as volunteer machines or VPNs, or are one-time, country-specific projects. Direct measurements have shown how different countries use various censorship mechanisms, including fake DNS replies, TCP/IP connection blocking, and HTTP-level blocking. Our measurements are also one-time, but our technique significantly reduces the cost of longitudinal censorship measurement.

### 2.1 Application-Layer Blocking
Many measurement systems test lists of keywords for censorship. Domain names are commonly used as proxies for services, drawn from lists of popular global domains or curated lists of potentially sensitive domains. Our system uses both sources to maximize comparability and test a sufficiently large corpus.

Detection of keywords has utilized corpora extracted from observed content deletion, along with NLP and active probing to refine accuracy. Previous systems have largely focused on individual countries and services, especially related to Chinese social media platforms like Weibo and TOM-Skype.

### 2.2 Direct Measurement Systems
Since censorship policies change over time, researchers have developed platforms for continuous measurements. One notable platform is the Tor project’s Open Observatory of Network Interference (OONI), which performs ongoing tests from volunteer participants. While direct measurements are harder for adversaries to target, these platforms cannot easily certify that the adversary did not contribute measurements to confound results. Additionally, OONI has fewer vantage points compared to our technique.

### 2.3 Remote Measurement Systems
Academic projects have recently focused on remote measurement of DNS poisoning and TCP/IP connectivity disruptions. Our system extends this strategy to detect application-layer disruption, providing a detailed view of the triggers and implementation of interference. We can determine which direction and which packet or keyword was the trigger and whether interference is implemented through packet injection or dropping. This level of detail is not possible with existing DNS or IP-level side channels.

### 2.4 Investigations of DPI Policies
Deep packet inspection (DPI) and application-level disruption have become standard practices online. Asghari et al. found support for their hypothesis that nations pursuing censorship are likely to push the deployment of DPI technology. OONI reports on DPI-based censorship in 12 countries with identified vendors, and the Tor project has faced DPI-based blocking in at least 7 countries.

## 3. Design and Implementation
Quack is designed to track the use and behavior of deep packet inspection. We focus on four goals:

1. **Detection:** Quack focuses on detecting when keywords are blocked and the technical methods employed, rather than uncovering application-specific grammars.
2. **Safety:** Quack is designed to run from a single vantage point, achieving worldwide coverage without engaging end users. It leverages existing network infrastructure, specifically echo servers, to minimize risk to end-users.
3. **Robustness:** Our system must distinguish unrelated network activity, such as sporadic packet loss, from network interference. This is achieved by retrying upon indication of failed tests.
4. **Scalability:** We aim to accurately measure keyword blocking on a global scale with minimal cost. This is achieved by daily scans for active echo servers, providing coverage of an average of 3,716 autonomous systems daily.

### 3.1 System Design
#### 3.1.1 The Echo Protocol
We chose to focus initial measurements on the Echo Protocol, defined in RFC 862 in 1983 by J. Postel. The Echo Protocol is a network debugging service, predating ICMP Ping. It defines two types of echo services: a TCP-based service on port 7 and a UDP-based service on port 7. There are many active echo servers around the world, including in countries known to use DPI. Our vantage points are detailed in Section 5.

**Figure 1:** Echo Protocol—The Echo Protocol, when properly performed, is a simple exchange between the client and server where the server’s response is identical to the client’s request. In the example, the censoring middlebox ignores the client’s inbound request but reacts to the echo server’s response, injecting RST packets and terminating the TCP connection.

We use echo servers for their defined purpose: measuring transport reliability. By varying the transport-layer data and observing differences in the network's behavior, we gain insight into the nuanced network perspectives of remote hosts, contributing to the exposure of national censorship policies.

Echo has three features that make it suitable for our purposes:
1. The protocol has a well-defined response to every request, making the classification of abnormal responses trivial.
2. Due to the ability to send arbitrary binary data, we can test censorship of any application-layer protocol that utilizes TCP or UDP as its transport protocol. In this paper, we focus on HTTP and HTTPS.
3. Because echo servers reflect content back to our measurement machine, we can detect censorship in the outbound direction and differentiate it from censorship triggered by our inbound request. Direction-sensitive interference is a known capability of modern DPI boxes.

If the middlebox injects a non-RST response to the echo server, we can still observe the interference, as the echo server will echo the content back to our measurement machine.

#### 3.1.2 Defining a Trial
We call an individual transaction with a remote server a trial. A trial is conducted with a single server, using a single keyword, and with a single application protocol containing that keyword. For example, consider `example.com` as a keyword wrapped within the format of an HTTP/1.1 request.

During a trial, we initialize a connection to the server and send it the formatted keyword. We read the response, pause for a short period, and finally send a short, innocuous payload to verify that the connection remains active. If the server responds correctly and the connection is closed successfully, we consider the trial a success.

The pause is necessary to allow injected RSTs by interference technology to reach either host in the connection, enabling us to directly identify that an interfering network is attempting to exploit a race condition via a Man-on-the-Side deployment. By verifying that the connection is still open after the keyword is sent, we ensure that there is no asymmetric interference occurring, where the interfering network closes the connection or begins dropping packets to our measurement machine.

#### 3.1.3 Test Phases
The Echo Protocol enables trivial disambiguation between correct and incorrect responses, but distinguishing noise from network interference requires additional effort. The Internet is inherently best-effort, so even in the absence of interference, there will be failed connections with echo servers. Additionally, interference technologies are imperfect, meaning that some trials will be successful even when the data is typically disallowed, for example, when DPI boxes are overloaded.

Quack is designed to extract meaningful signals from the noisiness of the network. We validate signs of failure through additional measurements, but there is a trade-off: not retrying would lead to many false negatives, while excessive retries would waste resources.