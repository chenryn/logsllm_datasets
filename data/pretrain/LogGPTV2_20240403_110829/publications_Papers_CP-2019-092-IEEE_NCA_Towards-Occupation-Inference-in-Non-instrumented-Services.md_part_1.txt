Towards Occupation Inference in Non-instrumented
Services
Ricardo Filipe, Jaime Correia, Filipe Araujo and Jorge Cardoso
CISUC, Department of Informatics Engineering, University of Coimbra
Coimbra, Portugal
Emails: PI:EMAIL, PI:EMAIL, PI:EMAIL and PI:EMAIL
Abstract—Measuring the capacity and modeling the response case, would be extracting information at sub-instrumentation
to load of a real distributed system and its components requires granularityaswellasimprovingthevisibilityoverlegacyparts
painstaking instrumentation. Even though it greatly improves
ofasystemthatarenotorcannotbeadequatelyinstrumented.
observability, instrumentation may not be desirable, due to cost,
Giventhisgoal,weaimtodeterminewhetherwecanperform
or possible due to legacy constraints.
such separation using a neural network.
To model how a component responds to load and estimate its
maximum capacity, and in turn act in time to preserve quality To evaluate this possibility, we created a laboratory exper-
of service, we need a way to measure component occupation. iment, where we use a system with two sequential M/M/1
Hence, recovering the occupation of internal non-instrumented
queues. We opted for Markovian queue systems since request
components is extremely useful for system operators, as they
rates for modern use cases are known to be well modeled
need to ensure responsiveness of each one of these components
and ways to plan resource provisioning. Unfortunately, complex by Poisson processes for large numbers of clients [2]. Fur-
systems will often exhibit non-linear responses that resist any thermore, as it has been shown that any system can be
simple closed-form decomposition. decomposed into an arbitrary number of queues as a result
To achieve this decomposition in small subsets of non-
of the properties of sums of Markovian processes [3], this is
instrumentedcomponents,weproposetraininganeuralnetwork
relativelyrepresentativeofsoftwarecomponents.Theintuition
thatcomputestheirrespectiveoccupations.Weconsiderasubsys-
tem comprised of two simple sequential components and resort behindthisproperty,isthatcomputers,asdiscretesystems,can
tosimulation,toevaluatethe neuralnetworkagainstanoptimal be thought of as a network of buffers.
baseline solution.
We ran a set of several combinations for layer occupations,
Results show that our approach can indeed infer the occupa-
from lightly occupied to heavily busy. For each combination,
tionofthelayerswithhighaccuracy,thusshowingthatthesam-
we collected the response time, for a batch of client requests.
pled distribution preserves enough information about the com-
ponents. Hence, neural networks can improve the observability Using this data, we trained a neural network, which we
of online distributed systems in parts that lack instrumentation. eventually set to three hidden layers of 100 neurons each,
Index Terms—Monitoring, Observability, Black-Box, Analyt- with two outputs representing the level of occupation of each
ics, Neural Networks, Deep Learning, Performance Modeling component of the system. The point is to understand if the
neural network could predict the occupation of each layer
I. INTRODUCTION
without expert understanding of the system. We evaluated
Observability – a metric of how well the internal state a our trained neural network against a baseline optimization
sytem can be determined from its external outputs [1] – is method. To extract the occupation, this method explicitly uses
key to ensure responsiveness of large-scale online systems, underlying knowledge of the components, to fit the observed
comprised of fine-grained distributed components, like mi- datawithatandemqueuemodel.Theaforementionedpremises
croservices. Perfect observability would require extensive in- will be clarified in the following Sections.
strumentationofsourcecodewithagentsdedicatedtosoftware
Our experiments show that the neural network can accu-
and hardware resources. Additionally heavyweight systems,
rately infer the occupation of each layer. With the exception
wouldberequiredtogather,store,processanddisplaydatain
of the case where one of the layers is extremely busy and
dashboards.
dominates the response time of the system, both methods,
Unfortunately, an intrusive monitoring solution may not be the neural network and the tandem queue model, achieve
desirable or possible due to technical constraints. This can satisfactory results. These results show the feasibility of using
happenduetoresourcesinthird-partyproviders(e.g.,Content machine learning to do black-box monitoring of parts of
Delivery Networks), or lack of instrumentation, as this might the system with little or no observability. Furthermore, it
be too complex or too expensive to cover the entire system. reinforces that the measurements contain enough information
Hence,inferringoccupationofindividualcomponentswith- to reason about the structure of the system that generated it.
outhelpfrominstrumentationorexternalagentscanbringcon-
The rest of the paper is organized as follows. Section II
crete benefits for the observability of the system. A clear use
describes the methods we used for the problem we tackle in
978-1-7281-2522-0/19/$31.00©2019IEEE thispaper.SectionIIIdescribesthesettingsforourexperiment.
InSectionIVweshowandevaluatethemeaningoftheresults, time distribution given in Equation 2 as t(λ,µ ,µ ,x) and
1 2
the strengths of this approach and its limitations for both a respective cumulative distribution function (CDF) given
methods. Section V presents the related work. Section VI in Equation 3 as T(λ,µ ,µ ,x). Note that due to space
1 2
concludes the paper and describes future directions. restrictions, the numerator on τ(λ,µ ,µ ,x) is split in two
1 2
lines.
II. SYSTEMANDMACHINELEARNINGAPPROACH
As we want to find the occupations ρ of each layer, and
ρ ∈ ]0,1[, we rewrite the model in terms of occupation, as
In this Section, we describe our approach to infer the
shown in Equation 5.
occupation of each component in the system of two queues
depicted in Figure 1. To fit it to the data, we use optimization to find the values
ρ , ρ that minimize the mean square error (MSE) between
1 2
Θ and the empirical cumulative distribution function (eCDF)
λ µ 1 µ 2 of the samples. We assume λ is known for the time interval
when the samples where taken. Figure 2 shows an example
Fig. 1: Tandem M/M/1 queues.
of how the model Θ fits the eCDF after the optmization
step. This particular sample was generated from a system
Using a sample of response times, we determine the oc-
with a (0.2,0.7) occupation, and the optimization determined
cupation of each component (which we refer to as layer),
parameters (0.16,0.73).
both with model fitting and a deep neural network. While the
model fitting algorithm explores the underlying structure of
the system and serves to prove that it is indeed possible to do
theblack-boxprediction,ourgoalistocreateaneuralnetwork
thatprecludestheneedforanyassumptionorknowledgeabout
the system.
A. Tandem Queue Model Fitting
To determine the occupation of each layer of a tandem,
two-component system, we first need to model their response
to load. In a generic way, this response function is defined
Fig.2:EmpiricalandpredictedCumulativeDistributionFunc-
by the time it takes to service each request and the level of
tions (CDF).
parallelism.Sinceweknowtheresponsetimeisthesumofthe
two random processes representing the service time portions
happeningateachlayer,asanaiveapproach,wecouldattempt B. Machine Learning Approach
to model the data, by fitting the sum of two random variables
We used a neural network that predicts each system layer’s
(exponential for example). This would shed light on the time
occupationfromrawresponsetimes,asclientsorcomponents
spent on each layer, and indirectly their capacity. However,
upstreamobservethem.Sincewewantedtopredicttheoutput
this approach fails to capture the variation in response time in
ofacontinuousvalue,ourneuralnetworkwouldhavetosolve
response to load/occupation, as a result of not considering the
aregressionproblem,i.e.,wewanttopredictouroutputvalue
time spent waiting for the service.
as accurately as possible — contrasting with a classification
Queuing theory gives us a theoretical framework to predict problem.
response time variation in function of occupation. As such,
We made several tests with distinct algorithms and opted
we modelled the system as a network of two tandem single-
for a deep neural network. The rational being that we wanted
server queues (M/M/1), shown in Figure 1. This model
to correlate both layers’ occupation, since the output visible
assumes Markovian properties for both inter-arrival times as
to the client is associated with both layers and has a complex
well as service times. It further assumes no parallelism. We
non-linear relation. Furthermore, current software frameworks
forewent more general models, for which approximate or
makedeploymentandusesimple,aswellasproduction-ready.
numericalsolutionsareknown,astheobjectiveisnotgenerally
In addition, we experimented several setups for the neural
solvingtheproblem,buttoproveitsfeasibilityandestablisha
network — distinct number of layers, nodes (neurons), and
performance baseline for a relatively simple case. Each queue
activation functions. Our final configuration for the neural
is defined by its arrival rate λ and service time µ, and the network consisted of one input layer with 2000 nodes, three
occupation ρ is µλ. The probability density function (PDF) hidden layers, each with 100 nodes, with the activation func-
for the response time distribution is given in Equation 1 by tion being the relu function [4] and, in the final layer, a
r(λ,µ,x) for all values x in its support.
linearactivationfunction.Sincethenetworkissharedbyboth
The model resulting of the composition of two tandem outputs,wewereabletohaveamulti-outputregressionmodel
M/M/1 queues is defined by the arrival rate (λ), and the topredicteachlayer’soccupation.Hence,bothoccupationsare
service rate of each queue (µ ,µ ), and has a response correlated and influence the hidden layers, having an impact
1 2
(1−ρ)µe−x(1−ρ)µ x≥0
r(λ,µ,x)= (1)
0 otherwise
t(λ,µ ,µ ,x)=(r∗r)(x)
1 2
 x
= r(λ,µ ,z)r(λ,µ ,x−z) dz
1 2 (2)
0
 λ  λ  exλ−µ1x exλ−µ2x
=µ µ 1− 1− −
1 2 µ µ µ −µ µ −µ
1 2 2 1 2 1
 x
T(λ,µ ,µ ,x)= t(λ,µ ,µ ,z) dz
1 2 1 2
0
 2 2 1−((µ1−λ)x+1)eλx−µ1x (3)
1− λ µ µ =µ
= µ1 1 µ12−2λµ1+λ2 1 2
τ(λ,µ ,µ ,x) otherwise
1 2
where,
1 − 1λ −µ )e1 µ1− x+µλ x+µ e (− µµ 22x −− µµ1 1x
 (µµ 1 λ1 λ2 2 )eµ1x+(λ−µ 2)eλx eµ2x
τ(λ,µ ,µ ,x)= (4)
1 2 (µ −λ)µ 2+(λ2−µ 2)µ +λµ 2−λ2µ
1 2 1 2 1 1
µ µ
Θ(λ,ρ ,ρ ,x)=T(λ, 1, 2,x) (5)
1 2 λ λ
x 1 is the occupation of the other layer. In the test scenario this
h1 1 h2 1 h3 1 output is not available, serving only to validate the accuracy
. . .
. . of t.he prediction.
x . . .
2
h1 h2 h3
2 2 2 III. EVALUATION
l1
x
3
To validate the tandem queue model fitting method and
h1 h2 h3
3 3 3
the neural network, we used response time data generated
x 4 with a simulated two-component system. We modeled a two
component system as two sequential single server queueing
x l2 components since it elegantly expresses the variation of re-
5
h1 h2 h3 sponse time with occupation. The simulation was made using
n n n
. . the qcomputer [5] package written in R.
.
The occupation levels were defined as all the combinations
of 0.1 increments in the range [0.1,0.9] - e.g., Layer 1 at 0.1
x
z andLayer2at0.5.Thearrivalratewasfixedat30requestsper
unitoftimeandtheservicerateofeachlayervariedtoexpress
Fig. 3: Representation of the network for the two components
the desired occupation. For each combination of occupations,
we collected 150 samples. Since we had 9 occupation levels
on the outcome. Figure 3 illustrates our model. The network per component, we collected 92 ∗150 = 12150 samples of
receiveszinputvalues,whicharetheresponsetimesseenbyz 2,000 request observations each. These observations corre-
clientrequests,andoutputs,l correspondingtotheoccupation spond to overall response times of each request.
i
of the ith layer. To evaluate and create the neural network model, we used
We provide to our network around 10,000 lines of raw Tensorflow with Keras [4]. This framework, allowed us
data from our experiment. Since we are training our neural to rapidly generate and save our model and is a common
network, and therefore using a supervised machine learning standard for the generation of complex networks in the in-
approach, we need labeled data. Each line has 2,002 values: dustry and academy. Of the 150 samples, 80%, or 120 per
2,000 response times as seen by clients and the labels: the occupationcombination,wereusedtotraintheneuralnetwork,
2,001stvalueistheoccupationofonelayer,the2,002ndvalue and the remaining (30 per combination) for the validation of
bothmethods—testset.Furthermore,oftheportionallocated meaning that (0.1,0.5) should be predicted as such, instead
totheneuralnetworktraining,30%(30%ofthe80%portion) of averaging the values to (0.3,0.3). To understand if this
were used for model validation in Tensorflow. relationships exists, we measure the error as the Euclidean
distance between the target and prediction pairs. Figure 4
The neural network treated the 2,000 request observations
shows the error in a way that preserves that relation. We
as its input features and outputted the two occupation values.
WeusedaSequentialmodelandtheMeanAbsoluteError present two visualizations for each method.
— for the optimization score function —, and a total of 100 Firstly, we show the predictions as a cloud of points color
iterations over the dataset — i.e., “epochs”. coded by expected occupation pair (Figures 4a and 4b). The
true occupations have a black circumference; predictions are
Forvalidationandcomparisonofthetwoapproaches(neural
dots with the same color as the disk inside the circumference.
network and model fitting), we calculated the following error