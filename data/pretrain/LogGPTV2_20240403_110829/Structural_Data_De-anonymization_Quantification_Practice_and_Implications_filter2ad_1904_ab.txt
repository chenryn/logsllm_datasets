ond, the k-anonymity scheme is applicable to low-average-
degree datasets. Nevertheless, many datasets, e.g., Google+
[25], Facebook [26], tend to have a large average degree and
still increasing. Finally, the k-anonymity idea lies on data’s
syntactic property, which may not work on protecting data
privacy even if this property is satisﬁed [2].
2.2.2 DA Schemes
Several successful DA attacks on structural data were pro-
posed recently, including structure based schemes [1][2][3]
and semantics based schemes [4]. In [4], Wondracek et al.
designed a DA attack to SN users based on the group mem-
bership information. To implement this attack, the adver-
sary should collect enough group membership information
(semantics information) by “history stealing” on browsers,
and then try to uniquely identify a user.
Instead of leveraging semantic information, we focus on
structure based DA attacks in this paper. In [1], Backstrom
et al.
introduced the structure based DA attacks by de-
signing both active and passive attacks in SNs. Since the
designed attacks in [1] leverage a “sybil” attack before the
actual anonymized data release, they are not scalable as
SNs increase in size [2]. Later, Narayanan and Shmatikov
in [2] designed a two-phase heuristics based DA attack a-
gainst large scale directed SNs. Through experiments on real
datasets, they demonstrated the feasibility of large scale DA
in terms of structure information. In [3], Srivatsa and Hicks
presented three DA attacks to mobility traces, which are all
two-phase schemes. In all the three attacks, to achieve high
DA accuracy, the DA propagation (the second phase) must
be repeated for all k! possible landmark mappings (k is the
number of landmarks), which is very time-consuming. For
instance, to de-anonymize a small dataset having 125 user-
s with 5 landmarks, the three attacks take 6.7 hours, 6.2
hours, and 0.5 hours, respectively. Furthermore, the attacks
in [3] are not suitable for large scale DA since in that sce-
nario more landmarks are required (k > 30, [2]), while when
k ≥ 20, the attacks in [3] are computationally infeasible.
2.2.3 Remarks
In this paper, we study the quantiﬁcation, practice, and
implications of structural data DA. The main aspects dis-
tinguishing this paper from existing works are as follows.
(i) To the best of our knowledge, this is the ﬁrst work that
quantiﬁes structural data DA under a general model. By our
quantiﬁcation, we answered several open questions, e.g., why
can structural data be de-anonymized? what are the condi-
tions for structural data DA? what portion of users can be
de-anonymized? and thus we bridge the gap between struc-
tural data DA practice and theoretical quantiﬁcation. (ii)
Following our theoretical quantiﬁcation, we conduct a large
scale study on 26 real world structural datasets. We also
conduct comprehensive and in-depth analysis on the evalua-
tion results. (iii) Following our quantiﬁcation, we propose a
novel single-phase optimization based DA algorithm (ODA).
ODA is a cold start algorithm without any requirement on
priori knowledge. By conducting experiments on large scale
real datasets, we demonstrate the eﬀectiveness of ODA.
3. SYSTEM MODEL
In this paper, we focus on quantifying the DA attack (vul-
nerability) on anonymized structural data, which could be
social data released by SN operators, (e.g., Google+ [25])
and/or mobility data generated by mobile devices (e.g., clas-
sical longitude-latitude spatiotemporal traces [26][27]).
3.1 Data Model
It is straightforward to model social data using graphs,
where nodes represent users and edges indicate the social
relationships (friendship, contact, following) among users.
Mobility data generated by users (users’ devices) can al-
so be modeled by contact graphs [3][27]. Furthermore, it
has been shown that a contact graph derived from mobili-
ty data has strong correlation with the social graph of the
same group of users that generated them [3][27]. There-
fore, we model the anonymized structural data by a graph
Ga = (V a, Ea), where V a = {i|i is an anonymized user} is
the user set and Ea = {ea
i,j| there is a relationship between
i ∈ V a and j ∈ V a} is the edge/relationship set. In reali-
ty, it is possible that a structural dataset corresponds to a
directed graph, e.g., Twitter. However, for simplicity and
without loss of generality, we assume Ga as an undirected
graph. Note that, the designed algorithm in this paper can
be extended to the directed scenario directly. For i ∈ V a,
i = {j|∃ea
i,j ∈ Ea} and we
its neighborhood is deﬁned as N a
i |, i.e., the degree of i.
i as |N a
denote the cardinality of N a
The auxiliary data is also assumed to be structural da-
ta, e.g., a SN compromising users overlapped with that in
Ga [2][3]. Furthermore, the auxiliary data is easily obtain-
able by multiple means such as academic and government
data mining, advertising, third-party applications, data ag-
gregation, online crawling, etc. Successful examples can be
found in [2][3][4][27]. Consequently, the auxiliary data is al-
so modeled by a graph Gu = (V u, Eu), where V u = {i is a
known user} and Eu = {eu
i,j| there is a relationship between
i ∈ V u and j ∈ V u}. Similarly, the neighborhood of i ∈ V u
i,j ∈ Eu}.
i = {j|∃eu
is deﬁned as N u
3.2 DA Attack
Given Ga and Gu, a DA attack can be formally deﬁned
as a mapping: σ : V a → V u. For ∀i ∈ V a, its mapping
under σ is σ(i) ∈ V u∪{⊥}, where ⊥ is a special not existing
indicator. Similarly, for ∀ea
∈
Eu ∪ {⊥}. Under σ, a successful DA on i ∈ V a is deﬁned as
′ ∈ V u and i and i
′
correspond to the same user;
σ(i) = i
or σ(i) =⊥, otherwise. For other cases, the DA on i fails.
Consequently, the objective of a DA attack is to successfully
de-anonymize as many users in V a as possible.
i,j ∈ Ea, σ(ea
, if i
i,j) = eu
σ(i),σ(j)
′
4. DA QUANTIFICATION
In this section, given Ga and Gu, we quantify a DA attack
under an arbitrary graph distribution in multiple scenarios.
(a) G
(b) Ga
(c) Gu
Figure 1: Edge/relationship projection. Only black
edges appear in Ga/Gu.
Note that, our quantiﬁcation aims to provide a theoretical
foundation for understanding the success of recent heuristic
structure-based DA practices [2][3].
4.1 Preliminaries
To make the quantiﬁcation and proof tractable and conve-
nient, we make some assumptions and deﬁnitions. First, we
assume V a = V u, i.e., the auxiliary data and the anonymized
data are corresponding to the same group of users [2][3][5].
This does not mean that we know any priori correct mapping
from V a to V u. Furthermore, this assumption is reasonable
since one cannot be expected to use Gu to de-anonymize Ga
if they correspond to diﬀerent groups of users. It is possi-
ble that the auxiliary data only has some overlap with the
anonymized data instead of corresponding to the exactly
same group of users. This fact does not limit our theoretical
analysis since we can either (i) apply the quantiﬁcation to
new = V a ∪ (V u \ V a)
the overlapping part, or (ii) redeﬁne V a
new = V u ∪ (V a \ V u), i.e. adding the non-overlapped
and V u
users to V a and V u respectively as isolated users (with de-
gree 0), and apply the analysis to Ga = (V a
new, Ea) and
Gu = (V u
new, Eu). Without of causing any confusion, we
assume V a = V u in the rest of this section.
Second, similar to [5], for the users in V a (or, V u), we
assume that there exists a conceptual underlying graph G =
(V, E) with V = V a = V u and E consisting of the true
relationships among users in V . Consequently, Ga and Gu
can be viewed as the physically observable projections of
G on particular relationships, e.g., “circle” relationship on
Google+, “co-occurrence” relationship in Gowalla. The pro-
jection from G to Ga is characterized by an edge/relationship
projection process [5]: (i) V a = V ; and (ii) ∀ei,j ∈ E, ei,j is
appeared in Ea with probability pa, i.e., Pr(ei,j ∈ Ea|ei,j ∈
E) = pa. Similarly, the projection from G to Gu can be
characterized by another edge/relationship projection pro-
cess with probability pu. For instance, we show a projec-
tion from G to Ga/Gu in Fig. 1. Furthermore, we assume
both projection processes are independent and identically
distributed (i.i.d.). Note that, (i) although the assumption
on the existence of a conceptual underlying graph and the
projection process makes the quantiﬁcation problem theo-
retically tractable, it is still a challenging issue in practice;
and (ii) assuming Ga and Gu are projected from an under-
lying network implies Ga and Gu have a strong structural
correlation. Intuitively, this assumption is reasonable since
they correspond to the same group of users and the em-
pirical results in [2][3] also supports such strong structural
correlation.
Based on the above assumptions, we have n! possible DA
schemes σ : V a → V u to de-anonymize Ga, among which
the only one perfect DA scheme (∀i ∈ V a, i is successfully
de-anonymized) is denoted by σ0.
4.2 Model and Formalization
Now, given G, we denote |V | = n and |E| = m. Let
V = {1, 2,··· , n} and di be the degree of i ∈ V . Then,
we deﬁne D = as the degree sequence of
the nodes (users) in V . Furthermore, let ∆1 and ∆2 (resp.,
δ1 and δ2) be the maximum and second maximum (resp.,
minimum and second minimum) degrees of G, respectively.
In [5], Pedarsani and Grossglauser quantiﬁed the privacy of
G when G is an ER random graph G(n, p) 2. The G(n, p)
model is very useful as a source of insight into the study
of structural data, e.g., SNs [5][21]. However, the degree
distribution of G(n, p) tends to follow the Poisson distribu-
tion, which is quite diﬀerent from the degree distribution-
s of most, if not all, observed real world structural data
(e.g., SNs) [21][22]. Actually, the degree distribution of re-
al world structural data may follow any distribution such
as the power-law distribution, exponential distribution, etc.
[21][22]. Therefore, it is signiﬁcant to understand and quan-
tify a DA attack for structural data under an arbitrary degree
distribution. To this end, we characterize G by a generalized
graph model, the conﬁguration model [21]. Under the con-
ﬁguration model, a graph is speciﬁed by an arbitrary degree
sequence D rather than a particular degree distribution. S-
ince D is an arbitrary degree sequence, D can follow an
arbitrary distribution observed in real world data [21].
Let pi,j be the probability of an edge existing between
i, j ∈ V . Then, we have pi,j = didj
didj
2m−1
2m , which is
a key property of the conﬁguration model [21]. From pi,j, it
is more likely of an existing edge between two users with high
degrees. Based on pi,j, we deﬁne l = min{pi,j|i, j ∈ V, i ̸= j}
and h = max{pi,j|i, j ∈ V, i ̸= j}, i.e., l and h are the
lower and upper bounds of pi,j respectively. Then, given G
with arbitrary degree distribution, we have l ≥ δ1δ2
2m−1 and
h ≤ ∆1∆2
2m−1 .
′ ≤ n, i ∈
′ ∈ V u} ⊆ V a × V u, we deﬁne the DA Error (DE) on
V a, i
i′ \ N a
i |,
a user mapping (i, i
which measures the neighborhoods’ diﬀerence between i in
in Gu under the particular σ. Then, we deﬁne the
Ga and i
ψi,i′ . Taking
overall DE for a particular σ as Ψσ =
Finally, given any DA scheme σ = {(i, i
) ∈ σ as ψi,i′ = |N a
as m→∞
≃
′
)|1 ≤ i, i
i′| + |N u
i \ N u
∑
(i,i′)∈σ