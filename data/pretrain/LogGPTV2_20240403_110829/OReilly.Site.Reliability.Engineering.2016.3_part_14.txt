the mainline will cause failures during the build performed at release time.
During the release process, we re-run the unit tests using the release branch and cre‐
ate an audit trail showing that all the tests passed. This step is important because if a
release involves cherry picks, the release branch may contain a version of the code
that doesn’t exist anywhere on the mainline. We want to guarantee that the tests pass
in the context of what’s actually being released.
To complement the continuous test system, we use an independent testing environ‐
ment that runs system-level tests on packaged build artifacts. These tests can be
launched manually or from Rapid.
Packaging
Software is distributed to our production machines via the Midas Package Manager
(MPM) [McN14c]. MPM assembles packages based on Blaze rules that list the build
artifacts to include, along with their owners and permissions. Packages are named
(e.g., search/shakespeare/frontend), versioned with a unique hash, and signed to
ensure authenticity. MPM supports applying labels to a particular version of a pack‐
age. Rapid applies a label containing the build ID, which guarantees that a package
can be uniquely referenced using the name of the package and this label.
Labels can be applied to an MPM package to indicate a package’s location in the
release process (e.g., dev, canary, or production). If you apply an existing label to a
new package, the label is automatically moved from the old package to the new pack‐
age. For example: if a package is labeled as canary, someone subsequently installing
the canary version of that package will automatically receive the newest version of the
package with the label canary.
Rapid
Figure 8-1 shows the main components of the Rapid system. Rapid is configured with
files called blueprints. Blueprints are written in an internal configuration language
and are used to define build and test targets, rules for deployment, and administrative
information (like project owners). Role-based access control lists determine who can
perform specific actions on a Rapid project.
Continuous Build and Deployment | 91
Figure 8-1. Simplified view of Rapid architecture showing the main components of the
system
Each Rapid project has workflows that define the actions to perform during the
release process. Workflow actions can be performed serially or in parallel, and a
workflow can launch other workflows. Rapid dispatches work requests to tasks run‐
ning as a Borg job on our production servers. Because Rapid uses our production
infrastructure, it can handle thousands of release requests simultaneously.
A typical release process proceeds as follows:
1. Rapid uses the requested integration revision number (often obtained automati‐
cally from our continuous test system) to create a release branch.
2. Rapid uses Blaze to compile all the binaries and execute the unit tests, often per‐
forming these two steps in parallel. Compilation and testing occur in environ‐
ments dedicated to those specific tasks, as opposed to taking place in the Borg job
where the Rapid workflow is executing. This separation allows us to parallelize
work easily.
3. Build artifacts are then available for system testing and canary deployments. A
typical canary deployment involves starting a few jobs in our production envi‐
ronment after the completion of system tests.
4. The results of each step of the process are logged. A report of all changes since
the last release is created.
Rapid allows us to manage our release branches and cherry picks; individual cherry
pick requests can be approved or rejected for inclusion in a release.
92 | Chapter 8: Release Engineering
Deployment
Rapid is often used to drive simple deployments directly. It updates the Borg jobs to
use newly built MPM packages based on deployment definitions in the blueprint files
and specialized task executors.
For more complicated deployments, we use Sisyphus, which is a general-purpose roll‐
out automation framework developed by SRE. A rollout is a logical unit of work that
is composed of one or more individual tasks. Sisyphus provides a set of Python
classes that can be extended to support any deployment process. It has a dashboard
that allows for finer control on how the rollout is performed and provides a way to
monitor the rollout’s progress.
In a typical integration, Rapid creates a rollout in a long-running Sisyphus job. Rapid
knows the build label associated with the MPM package it created, and can specify
that build label when creating the rollout in Sisyphus. Sisyphus uses the build label to
specify which version of the MPM packages should be deployed.
With Sisyphus, the rollout process can be as simple or complicated as necessary. For
example, it can update all the associated jobs immediately or it can roll out a new
binary to successive clusters over a period of several hours.
Our goal is to fit the deployment process to the risk profile of a given service. In
development or pre-production environments, we may build hourly and push relea‐
ses automatically when all tests pass. For large user-facing services, we may push by
starting in one cluster and expand exponentially until all clusters are updated. For
sensitive pieces of infrastructure, we may extend the rollout over several days, inter‐
leaving them across instances in different geographic regions.
Configuration Management
Configuration management is one area of particularly close collaboration between
release engineers and SREs. Although configuration management may initially seem
a deceptively simple problem, configuration changes are a potential source of insta‐
bility. As a result, our approach to releasing and managing system and service config‐
urations has evolved substantially over time. Today we use several models for
distributing configuration files, as described in the following paragraphs. All schemes
involve storing configuration in our primary source code repository and enforcing a
strict code review requirement.
Use the mainline for configuration. This was the first method used to configure serv‐
ices in Borg (and the systems that pre-dated Borg). Using this scheme, developers and
SREs modify configuration files at the head of the main branch. The changes are
reviewed and then applied to the running system. As a result, binary releases and
configuration changes are decoupled. While conceptually and procedurally simple,
Configuration Management | 93
this technique often leads to skew between the checked-in version of the configura‐
tion files and the running version of the configuration file because jobs must be upda‐
ted in order to pick up the changes.
Include configuration files and binaries in the same MPM package. For projects with
few configuration files or projects where the files (or a subset of files) change with
each release cycle, the configuration files can be included in the MPM package with
the binaries. While this strategy limits flexibility by binding the binary and configura‐
tion files tightly, it simplifies deployment, because it only requires installing one
package.
Package configuration files into MPM “configuration packages.” We can apply the her‐
metic principle to configuration management. Binary configurations tend to be
tightly bound to particular versions of binaries, so we leverage the build and packag‐
ing systems to snapshot and release configuration files alongside their binaries. Simi‐
lar to our treatment of binaries, we can use the build ID to reconstruct the
configuration at a specific point in time.
For example, a change that implements a new feature can be released with a flag set‐
ting that configures that feature. By generating two MPM packages, one for the
binary and one for the configuration, we retain the ability to change each package
independently. That is, if the feature was released with a flag setting of first_folio
but we realize it should instead be bad_quarto, we can cherry pick that change onto
the release branch, rebuild the configuration package, and deploy it. This approach
has the advantage of not requiring a new binary build.
We can leverage MPM’s labeling feature to indicate which versions of MPM packages
should be installed together. A label of much_ado can be applied to the MPM packages
described in the previous paragraph, which allows us to fetch both packages using
this label. When a new version of the project is built, the much_ado label will be
applied to the new packages. Because these tags are unique within the namespace for
an MPM package, only the latest package with that tag will be used.
Read configuration files from an external store. Some projects have configuration files
that need to change frequently or dynamically (i.e., while the binary is running).
These files can be stored in Chubby, Bigtable, or our source-based filesystem
[Kem11].
In summary, project owners consider the different options for distributing and man‐
aging configuration files and decide which works best on a case-by-case basis.
94 | Chapter 8: Release Engineering
Conclusions
While this chapter has specifically discussed Google’s approach to release engineering
and the ways in which release engineers work and collaborate with SREs, these practi‐
ces can also be applied more widely.
It’s Not Just for Googlers
When equipped with the right tools, proper automation, and well-defined policies,
developers and SREs shouldn’t have to worry about releasing software. Releases can
be as painless as simply pressing a button.
Most companies deal with the same set of release engineering problems regardless of
their size or the tools they use: How should you handle versioning of your packages?
Should you use a continuous build and deploy model, or perform periodic builds?
How often should you release? What configuration management policies should you
use? What release metrics are of interest?
Google Release Engineers have developed our own tools out of necessity because
open sourced or vendor-supplied tools don’t work at the scale we require. Custom
tools allow us to include functionality to support (and even enforce) release process
policies. However, these policies must first be defined in order to add appropriate fea‐
tures to our tools, and all companies should take the effort to define their release pro‐
cesses whether or not the processes can be automated and/or enforced.
Start Release Engineering at the Beginning
Release engineering has often been an afterthought, and this way of thinking must
change as platforms and services continue to grow in size and complexity.
Teams should budget for release engineering resources at the beginning of the prod‐
uct development cycle. It’s cheaper to put good practices and process in place early,
rather than have to retrofit your system later.
It is essential that the developers, SREs, and release engineers work together. The
release engineer needs to understand the intention of how the code should be built
and deployed. The developers shouldn’t build and “throw the results over the fence”
to be handled by the release engineers.
Individual project teams decide when release engineering becomes involved in a
project. Because release engineering is still a relatively young discipline, managers
don’t always plan and budget for release engineering in the early stages of a project.
Therefore, when considering how to incorporate release engineering practices, be
sure that you consider its role as applied to the entire lifecycle of your product or ser‐
vice—particularly the early stages.
Conclusions | 95
More Information
For more information on release engineering, see the following presentations, each of
which has video available online:
• How Embracing Continuous Release Reduced Change Complexity, USENIX
Release Engineering Summit West 2014, [Dic14]
• Maintaining Consistency in a Massively Parallel Environment, USENIX Configura‐
tion Management Summit 2013, [McN13]
• The 10 Commandments of Release Engineering, 2nd International Workshop on
Release Engineering 2014, [McN14b]
• Distributing Software in a Massively Parallel Environment, LISA 2014, [McN14c]
96 | Chapter 8: Release Engineering
CHAPTER 9
Simplicity
Written by Max Luebbe
Edited by Tim Harvey
The price of reliability is the pursuit of the utmost simplicity.
—C.A.R. Hoare, Turing Award lecture
Software systems are inherently dynamic and unstable.1 A software system can only
be perfectly stable if it exists in a vacuum. If we stop changing the codebase, we stop
introducing bugs. If the underlying hardware or libraries never change, neither of
these components will introduce bugs. If we freeze the current user base, we’ll never
have to scale the system. In fact, a good summary of the SRE approach to managing
systems is: “At the end of the day, our job is to keep agility and stability in balance in
the system.”2
System Stability Versus Agility
It sometimes makes sense to sacrifice stability for the sake of agility. I’ve often
approached an unfamiliar problem domain by conducting what I call exploratory
coding—setting an explicit shelf life for whatever code I write with the understanding
that I’ll need to try and fail once in order to really understand the task I need to
accomplish. Code that comes with an expiration date can be much more liberal with
test coverage and release management because it will never be shipped to production
or be seen by users.
1 This is often true of complex systems in general; see [Per99] and [Coo00].
2 Coined by my former manager, Johan Anderson, around the time I became an SRE.
97
For the majority of production software systems, we want a balanced mix of stability
and agility. SREs work to create procedures, practices, and tools that render software
more reliable. At the same time, SREs ensure that this work has as little impact on
developer agility as possible. In fact, SRE’s experience has found that reliable pro‐
cesses tend to actually increase developer agility: rapid, reliable production rollouts
make changes in production easier to see. As a result, once a bug surfaces, it takes less
time to find and fix that bug. Building reliability into development allows developers
to focus their attention on what we really do care about—the functionality and per‐
formance of their software and systems.
The Virtue of Boring
Unlike just about everything else in life, “boring” is actually a positive attribute when
it comes to software! We don’t want our programs to be spontaneous and interesting;
we want them to stick to the script and predictably accomplish their business goals.
In the words of Google engineer Robert Muth, “Unlike a detective story, the lack of
excitement, suspense, and puzzles is actually a desirable property of source code.”
Surprises in production are the nemeses of SRE.
As Fred Brooks suggests in his “No Silver Bullet” essay [Bro95], it is very important to
consider the difference between essential complexity and accidental complexity.
Essential complexity is the complexity inherent in a given situation that cannot be
removed from a problem definition, whereas accidental complexity is more fluid and
can be resolved with engineering effort. For example, writing a web server entails
dealing with the essential complexity of serving web pages quickly. However, if we
write a web server in Java, we may introduce accidental complexity when trying to
minimize the performance impact of garbage collection.
With an eye towards minimizing accidental complexity, SRE teams should:
• Push back when accidental complexity is introduced into the systems for which
they are responsible
• Constantly strive to eliminate complexity in systems they onboard and for which
they assume operational responsibility
I Won’t Give Up My Code!
Because engineers are human beings who often form an emotional attachment to
their creations, confrontations over large-scale purges of the source tree are not
uncommon. Some might protest, “What if we need that code later?” “Why don’t we
just comment the code out so we can easily add it again later?” or “Why don’t we gate
the code with a flag instead of deleting it?” These are all terrible suggestions. Source
98 | Chapter 9: Simplicity
control systems make it easy to reverse changes, whereas hundreds of lines of com‐
mented code create distractions and confusion (especially as the source files continue
to evolve), and code that is never executed, gated by a flag that is always disabled, is a
metaphorical time bomb waiting to explode, as painfully experienced by Knight Cap‐
ital, for example (see “Order In the Matter of Knight Capital Americas LLC” [Sec13]).
At the risk of sounding extreme, when you consider a web service that’s expected to
be available 24/7, to some extent, every new line of code written is a liability. SRE pro‐
motes practices that make it more likely that all code has an essential purpose, such as
scrutinizing code to make sure that it actually drives business goals, routinely remov‐
ing dead code, and building bloat detection into all levels of testing.
The “Negative Lines of Code” Metric
The term “software bloat” was coined to describe the tendency of software to become
slower and bigger over time as a result of a constant stream of additional features.
While bloated software seems intuitively undesirable, its negative aspects become
even more clear when considered from the SRE perspective: every line of code
changed or added to a project creates the potential for introducing new defects and
bugs. A smaller project is easier to understand, easier to test, and frequently has fewer
defects. Bearing this perspective in mind, we should perhaps entertain reservations
when we have the urge to add new features to a project. Some of the most satisfying
coding I’ve ever done was deleting thousands of lines of code at a time when it was no
longer useful.
Minimal APIs
French poet Antoine de Saint Exupery wrote, “perfection is finally attained not when
there is no longer more to add, but when there is no longer anything to take away”
[Sai39]. This principle is also applicable to the design and construction of software.
APIs are a particularly clear expression of why this rule should be followed.
Writing clear, minimal APIs is an essential aspect of managing simplicity in a soft‐
ware system. The fewer methods and arguments we provide to consumers of the API,
the easier that API will be to understand, and the more effort we can devote to mak‐
ing those methods as good as they can possibly be. Again, a recurring theme appears:
the conscious decision to not take on certain problems allows us to focus on our core
problem and make the solutions we explicitly set out to create substantially better. In
software, less is more! A small, simple API is usually also a hallmark of a well-
understood problem.
The “Negative Lines of Code” Metric | 99
Modularity
Expanding outward from APIs and single binaries, many of the rules of thumb that
apply to object-oriented programming also apply to the design of distributed systems.
The ability to make changes to parts of the system in isolation is essential to creating