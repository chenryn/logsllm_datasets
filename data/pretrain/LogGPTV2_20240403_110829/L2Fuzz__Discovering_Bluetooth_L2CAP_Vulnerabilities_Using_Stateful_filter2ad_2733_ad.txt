related techniques were excluded because they did not support
L2CAP vulnerability detection or were not publicly available.
We compared the mutation efﬁciency and state coverage of
L2FUZZ to the baseline fuzzers using the test device D2 (i.e.,
Google Pixel 3 smartphone, see Table V). We used D2 in the
evaluation because D2 follows the Bluetooth standard with
little customization as a "reference phone" selected by Google.
Therefore, we expected that Bluetooth vulnerabilities would be
most clearly tested in D2.
Evaluation metrics. Because most Bluetooth stacks, ex-
cept for BlueZ and BlueDroid, are closed sources, Bluetooth
fuzzers are close to blackbox fuzzers; evaluation metrics used
in whitebox or greybox fuzzing [20], [26], such as source
code coverage, are difﬁcult to use for evaluation here. Thus,
we suggest two metrics, which can be measured only with
the packet trace, for evaluating Bluetooth fuzzers: mutation
efﬁciency and state coverage, which can be measured even in
an environment where the target device is a black-box:
• Mutation efﬁciency. This refers to the minimum percent-
age of malformed packets transmitted without rejection.
To measure this metric, we calculated the Malformed
Packet Ratio (MP Ratio) and the Packet Rejection Ratio
(PR Ratio), by capturing malformed and rejected packets
through packet snifﬁng tools (e.g., Wireshark [27]).
MP Ratio = #Transmitted Malformed Packets
#Transmitted Packets
PR Ratio = #Received Rejection Packets from Target
#Received Packets from Target
The mutation efﬁciency, which represents the ratio of
malformed packets transmitted without rejection, is cal-
culated as follows.
Mutation efﬁciency = MP Ratio ∗ (1 − PR Ratio)
• State coverage. This metric refers to the number of
L2CAP states to be covered. Because vulnerabilities are
highly likely to occur in the state transition process
and the functions of each state, the more L2CAP states
were covered,
the higher the likelihood of detecting
vulnerabilities. It can be measured by protocol reverse
engineering tool (e.g., PRETT [28]).
B. Vulnerability detection results in real-world devices
We applied L2FUZZ to eight selected test devices for
detecting unknown Bluetooth vulnerabilities. Owing to the
characteristics of Bluetooth, wherein the device and fuzzing
are terminated when a valid vulnerability is found, it is difﬁcult
to measure the number of detected vulnerabilities. Therefore,
we measured (1) whether vulnerabilities were detected and (2)
the elapsed time required to detect vulnerabilities.
In our experiments, we conﬁrmed that L2FUZZ detected ﬁve
zero-day vulnerabilities; the results are shown in Table VI.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:19:38 UTC from IEEE Xplore.  Restrictions apply. 
349
TABLE VI: Vulnerability detection results of L2FUZZ.
Device Vuln? Description Elapsed Time Reported to Vendors?
Yes
Yes
Yes
N/A
Yes
N/A
N/A
D1
D2
D3
D4
D5
D6
D7
D8
Yes
Yes
Yes
No
Yes
No
No
Yes
DoS
DoS
DoS
N/A
Crash
N/A
N/A
Crash
1 m 32 s
1 m 25 s
7 m 11 s
N/A
40 s
N/A
N/A
2 h 40 m
Discussing
* D1, D2, D3: A denial of service was triggered because of a null pointer
dereference by malformed packets. The vendor became aware of
this
vulnerability. (see Section IV-E).
* D5: The device was unexpectedly terminated owing to the malformed
packets. This has been patched by the vendor.
* D8: A crash dump was generated owing to a general protection failure by
malformed packets. We are discussing this issue with the vendor.
L2FUZZ discovered DoS vulnerabilities in three Android
devices (i.e., D1, D2, and D3). The crash was triggered in
the state of device, which allowed malicious commands with
the value CIDP. Additionally, a tombstone ﬁle (i.e., Android
crash dump [29]) was generated in each device, resulting in
Bluetooth termination for all devices (DoS triggered); details
are explained in Section IV-E.
L2FUZZ further detected crashes in two devices (i.e., D5
and D8), a wireless earphone, and a laptop. Regarding D5,
a crash occurred in a state that allowed commands with a
malicious PSM value, resulting in an abnormal phenomenon
(i.e., termination without any control). For D8, a crash dump
ﬁle was created within the target device, and the Bluetooth
communication content and general protection errors were
recorded in the crash dump.
Notably, with the exception of D8, all vulnerabilities were
detected within several minutes. It was infeasible to closely
analyze the direct factors affecting performance, because
the source code of all Bluetooth stacks were not publicly
disclosed. Instead, we conﬁrmed that the vulnerability was
detected within one minute in D5 (supporting six service ports)
while requiring more than two hours on D8 (supporting 13
service ports). Subsequently, we can infer that the elapsed
time was determined based on the number of service ports
provided and the logic complexity of Bluetooth applications.
We responsibly reported all ﬁve detected vulnerabilities to the
corresponding vendors.
Although L2FUZZ discovered ﬁve zero-day vulnerabilities,
it failed to detect vulnerabilities in three devices: D4, D6, and
D7, which used iOS, BTW, and Windows stack, respectively.
Their Bluetooth stack is based on the Bluetooth speciﬁcation
document; however, they also have proprietary protocol layers
and logic. They may have implemented an exception handling
logic for malformed packets generated by L2FUZZ.
C. Mutation efﬁciency measurement
Next, we measured the mutation efﬁciency of L2FUZZ
and compared it with the three existing Bluetooth fuzzing
100000
10000
d
e
t
t
i
s
t
e
k
c
a
P
d
e
m
r
o
f
l
a
M
(log scaled)
m
s
n
a
r
T
#
1000
100
10
1
0
10000
20000
L2Fuzz
Defensics
BFuzz
70000
80000
90000
100000
30000
40000
50000
#Transmitted Packets
60000
Fig. 8: MP Ratio measurement results for the four Bluetooth fuzzing
techniques. BSS did not generate malformed packets, thus it is not
displayed on the graph.
techniques (i.e., Defensics, BSS, and BFuzz). For a fair
comparison, controlled experiments were required. Because
each fuzzer sends a different number of packets per second,
we measured the MP and PR Ratios of each fuzzer based on
100,000 sent packets. We ran the four fuzzers on Google Pixel
3 with Android 11 devices (i.e., D2). Malformed and rejected
packets were captured and analyzed using Wireshark.
MP Ratio measurement. Figure 8 shows the MP Ratio
measurement results for the four fuzzing techniques. Notably,
L2FUZZ can generate up to 46 times more malformed packets
than other techniques. L2FUZZ generated malformed packets
accounting for an average of 33.48% during testing, and
generated a total of 69,966 packets (i.e., 69.96% MP Ratio).
Coversely, Defensics generated malformed packets accounting
for 1.40% on average and generated 2,380 packets in total
(i.e., 2.38% MP Ratio). BFuzz generated malformed packets
accounting for 0.74% on average and generated a total of
1,506 packets (i.e., 1.50% MP Ratio). Notably, the BSS did
not generate any malformed packets (i.e., 0% MP Ratio).
We conﬁrmed that the MP Ratio values of the fuzzing
techniques vary depending on the mutation strategy used for
each technique. Particularly, the existing techniques performed
packet mutation without considering the characteristics of the
L2CAP packet ﬁelds. For examples, BFuzz mutated all ﬁelds
of the packet except for the ﬁxed ﬁelds, and BSS mutated
only one ﬁeld. Therefore, they failed to effectively generate
malformed packets. However, the L2FUZZ approach, which
generates malformed packets with core ﬁeld mutating, showed
much higher MP Ratio than others.
PR Ratio measurement. Figure 9 shows the measured PR
Ratio values for the selected four fuzzing techniques. Based on
100,000 received packets from the target, BFuzz showed the
highest packet rejection ratio (i.e., 91.60% PR Ratio), followed
by L2Fuzz (i.e., 32.49% PR Ratio), and then Defensics (i.e.,
1.73% PR Ratio). Because BSS does not generate malicious
packets, the PR Ratio was also 0%.
Similar to the MP Ratio cases, the PR Ratio values were
different owing to the difference in the mutation strategy of
each fuzzing technique. For example, BFuzz, which showed
the highest PR Ratio, mutated the dependent ﬁelds (D),
resulting in test packets rejected by the target device.
One important observation is that a lower PR Ratio does not
always indicate that a fuzzer is efﬁcient. In the experimental
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:19:38 UTC from IEEE Xplore.  Restrictions apply. 
350
100000
10000
1000
100
10
1
0
10000
n
o
i
t
c
e
j
e
R
d
e
v
i
e
c
e
R
#
t
e
g
r
a
T
m
o
r
f
s
t
e
k
c
a
P
(log scaled)
L2Fuzz
Defensics
BFuzz
90000
20000
30000
40000
50000
60000
#Received Packets from Target
70000
80000
100000
Fig. 9: PR Ratio measurement results for the four Bluetooth fuzzing
techniques. BSS did not receive any rejection packets, thus it is not
displayed on the graph.
results, we conﬁrmed that the PR Ratio of Defensics was
lower than that of L2FUZZ. This is mainly owing to following
two reasons. First, Defensics exhibited a low rejection ratio
because it hardly generated malformed packets. Furthermore,
a Bluetooth application forms as many channels as the number
of supported Bluetooth services. In L2FUZZ, some packets
were rejected because L2FUZZ formed more channels than
the maximum number in one L2CAP state. Because Defensics
only tests one packet per state, there is less chance of being
rejected. In summary, although Defensics showed a low PR
Ratio, it hardly made malformed packets and did not sufﬁ-
ciently inspect each L2CAP state.
In contrast, we conﬁrmed that L2FUZZ showed a relatively
low PR Ratio while generating a sufﬁciently large number
of malicious packets, with the help of core ﬁeld mutating
technique.
TABLE VII: Results of the mutation efﬁciency measurement.
PR Ratio Mutation efﬁciency
Fuzzer
32.49%
L2Fuzz
1.73%
Defensics
91.60%
MP Ratio
69.96%
2.38%
1.50%
47.22%
2.33%
0.12%
BFuzz
BSS
0%
0%
0%
*MP Ratio = Malformed Packet Ratio
*PR Ratio = Packet Rejection Ratio
*Mutation efﬁciency = MP Ratio * (1 - PR Ratio)
Mutation efﬁciency measurement. We then calculated the
mutation efﬁciency for each fuzzer using the measured MP
and PR Ratios. Table VII presents the measurement results.
We conﬁrmed that L2FUZZ was able to transmit the largest
number of malformed packets without rejection; L2FUZZ
showed a mutation efﬁciency of 47.22%. The mutation ef-
ﬁciency value of Defensics, which showed the lowest PR
Ratio, is 2.33% because Defensics hardly generates malformed
packets (i.e., MP Ratio was signiﬁcantly low). Further, the
mutation efﬁciency of BFuzz, which produced few malicious
packets and showed a high rejection ratio, was 0.12%, and
the mutation efﬁciency of BSS, which failed to generate
malicious packets, was 0%. Moreover, L2FUZZ transmitted
524.27 packets per second (pps), allowing more packets to
be tested in a shorter time than Defensics (3.37 pps), BFuzz
(454.54 pps), and BSS (1.95 pps).
From our experimental results, we conﬁrmed that L2FUZZ
outperformed existing Bluetooth fuzzing techniques in terms
of generating more malformed packets that were less likely to
be rejected by the target device.
D. State coverage measurement
Next, we examined the number of L2CAP states that
each fuzzing technique could cover; the more covered states,
the more likely the fuzzing technique to detect a Bluetooth
vulnerability (see Section III-C).
We investigated each fuzzer’s state coverage by analyzing
the packet trace captured using PRETT [28]. For fuzzers with
ﬁxed test times (i.e., Defensics), we analyzed the packet traces
at the end of the test. For the remaining fuzzer with no test
time limit, packet traces were analyzed at the end of a single
test cycle. The results are shown in Figure 10 and Figure 11.
L2Fuzz