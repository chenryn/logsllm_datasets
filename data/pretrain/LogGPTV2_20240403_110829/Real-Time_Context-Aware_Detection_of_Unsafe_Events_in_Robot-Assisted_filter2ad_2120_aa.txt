title:Real-Time Context-Aware Detection of Unsafe Events in Robot-Assisted
Surgery
author:Mohammad Samin Yasar and
Homa Alemzadeh
2020 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)
Real-Time Context-aware Detection of
Unsafe Events in Robot-Assisted Surgery
Mohammad Samin Yasar, Homa Alemzadeh
Abstract— Cyber-physical systems for robotic surgery have
enabled minimally invasive procedures with increased precision
and shorter hospitalization. However, with increasing complex-
ity and connectivity of software and major involvement of
human operators in the supervision of surgical robots, there
remain signiﬁcant challenges in ensuring patient safety. This
paper presents a safety monitoring system that, given the
knowledge of the surgical task being performed by the surgeon,
can detect safety-critical events in real-time. Our approach
integrates a surgical gesture classiﬁer that infers the operational
context from the time-series kinematics data of the robot with
a library of erroneous gesture classiﬁers that given a surgical
gesture can detect unsafe events. Our experiments using data
from two surgical platforms show that the proposed system can
detect unsafe events caused by accidental or malicious faults
within an average reaction time window of 1,693 milliseconds
and F1 score of 0.88 and human errors within an average
reaction time window of 57 milliseconds and F1 score of 0.76.
I. INTRODUCTION
Robot-assisted surgery (RAS) is now a standard procedure
across various surgical specialties,
including gynecology,
urology and general surgeries. During the last two decades,
over 2 million procedures were performed using the Intuitive
Surgical’s daVinci robot in the U.S. [1]. Surgical robots are
complex human-in-the-loop Cyber-Physical Systems (CPS)
that enable 3D visualization of surgical ﬁeld and more
precise manipulation of surgical instruments such as scissors,
graspers, and electro-cautery inside patient’s body. The cur-
rent generation of surgical robots are not fully autonomous
yet. They are in level 0 of autonomy [2], following the
commands provided by the surgeons from a master-side tele-
operation console in real-time (Figure 1a), translating them
into precise movements of robotic arms and instruments,
while scaling surgeon’s motions and ﬁltering out hand-
tremors. By increasing ﬂexibility and precision, surgical
robots have enabled new types of surgical procedures and
have reduced complication rates and procedure times.
Recent studies have shown that safety in robotic surgery
may be compromised by vulnerabilities of the surgical robots
to accidental or maliciously-crafted faults in the cyber or
physical layers of the control system or human errors [3],
[4]. Examples of system faults include disruptions of the
communication between the surgeon console and the robot,
causing packet drops or delays in tele-operation [5], acciden-
tal or malicious faults targeting the robot control software [6],
*This work was partially supported by a grant from the U.S. National
Science Foundation (Award No. 1748737).
*Authors are with the Department of Electrical and Computer Engi-
neering (ECE), University of Virginia, Charlottesville, VA 22904, USA
{msy9an, ha4d}@virginia.edu.
or faulty sensors and actuators [3] (Figure 1b). Those faults
can propagate and manifest as system errors (e.g., unintended
movements, modiﬁcation of surgeon’s intent, and unrespon-
sive robotic system [7]) or cause human errors (e.g., multiple
attempts to suture or end-effector going out of sight [8]–[10])
during surgery and eventually lead to safety-critical events
that negatively impact patients and caregivers. Examples
include causing unexpected cuts, bleeding, or minor injuries
or resulting in long procedure times and other complications
during the procedure or afterwards [3]. Table I provides
examples of common types of human errors during a sample
set of surgical tasks, as reported in the literature.
Our goal is to improve the safety of surgery by enhancing
the robot controller with capabilities for real-time detection
of early signs of adverse events and preventing them by
issuing timely warnings or taking mitigation actions. Previ-
ous works on safety and security monitoring and anomaly
detection in surgical robots and other CPS have mainly
focused on incorporating the information from the cyber
and/or physical layers for modeling and inference of the
system context [11] and distinguishing between safe and
unsafe control commands that could potentially lead to safety
hazards. For example, [6] proposed an anomaly detection
framework for detection of targeted attacks on the robot
control system through modeling robot physical state and
dynamics. They showed that considering the physical context
(e.g., next motor position and velocities to be executed on the
robot) leads to improved detection of unsafe events compared
to ﬁxed safety checks on just the cyber state variables (e.g.,
torque commands calculated in control software). However,
with the major involvement of the human operators in real-
time control and operation of semi-autonomous CPS such
as surgical robots, another important contributing factor to
safety is the operational context that captures human opera-
tors’ preferences, intent, and workﬂow. In this work, we aim
to improve the detection coverage for unsafe events during
surgery by considering a more complete view of system
context
incorporates the knowledge of the surgical
workﬂow, characterized by the surgical tasks or gestures
being performed by the surgeon.
that
This paper presents an online safety monitoring system for
robot-assisted surgery that takes the human operator actions
(surgeon’s commands at the tele-operation console) as input
to infer the operational context (current surgical subtask
or gesture) and performs context-speciﬁc validation of the
kinematics state of the robot to detect erroneous gestures that
could potentially lead to safety-critical events. The proposed
system can be integrated with the existing surgical robots
978-1-7281-5809-9/20/$31.00 ©2020 IEEE
DOI 10.1109/DSN48063.2020.00054
385
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:23:52 UTC from IEEE Xplore.  Restrictions apply. 
(cid:5)(cid:21)(cid:25)(cid:1)(cid:17)(cid:9)(cid:10)(cid:1)(cid:22)(cid:12)(cid:23)(cid:24)(cid:20)(cid:1)(cid:2) (cid:3)(cid:17)(cid:19)(cid:11)(cid:16)(cid:1)(cid:8)(cid:21)(cid:9)(cid:18)(cid:22)(cid:13)(cid:12)(cid:21)(cid:1)(cid:23)(cid:9)(cid:22)(cid:16)
(cid:7)(cid:24)(cid:21)(cid:14)(cid:12)(cid:19)(cid:18)(cid:1)(cid:4)(cid:19)(cid:18)(cid:22)(cid:19)(cid:17)(cid:12)
(cid:7)(cid:24)(cid:21)(cid:14)(cid:15)(cid:11)(cid:9)(cid:17)(cid:1)(cid:6)(cid:19)(cid:10)(cid:19)(cid:23)
Human Surgeon
Master
Console
Control
Software
Control
Hardware
Robotic  Arms and Instruments
(cid:3)(cid:14)(cid:8)(cid:15)(cid:5)(cid:17)(cid:10)(cid:13)(cid:12)(cid:5)(cid:11)(cid:1)(cid:7)(cid:13)(cid:12)(cid:17)(cid:8)(cid:18)(cid:17)
(cid:32) (cid:8)(cid:28)(cid:25)(cid:16)(cid:18)(cid:12)(cid:10)(cid:20)(cid:1)(cid:9)(cid:23)(cid:25)(cid:19)(cid:15)(cid:20)(cid:23)(cid:30)
(cid:3) (cid:8)(cid:28)(cid:25)(cid:16)(cid:18)(cid:12)(cid:10)(cid:20)(cid:1)(cid:27)(cid:10)(cid:26)(cid:19)(cid:2)(cid:1)(cid:26)(cid:28)(cid:11)(cid:27)(cid:10)(cid:26)(cid:19)
(cid:2)(cid:19)(cid:6)(cid:8)(cid:15)(cid:1)(cid:7)(cid:13)(cid:12)(cid:17)(cid:8)(cid:18)(cid:17)
(cid:32) (cid:4)(cid:23)(cid:22)(cid:27)(cid:25)(cid:23)(cid:20)(cid:1)(cid:26)(cid:31)(cid:26)(cid:27)(cid:14)(cid:21)(cid:1)(cid:26)(cid:27)(cid:10)(cid:27)(cid:14)(cid:1)(cid:1)
(cid:3) (cid:7)(cid:23)(cid:11)(cid:23)(cid:27) (cid:24)(cid:23)(cid:26)(cid:18)(cid:27)(cid:18)(cid:23)(cid:22)(cid:2)(cid:1)(cid:23)(cid:25)(cid:18)(cid:14)(cid:22)(cid:27)(cid:10)(cid:27)(cid:18)(cid:23)(cid:22)
(cid:4)(cid:9)(cid:19)(cid:16)(cid:10)(cid:7)(cid:5)(cid:11)(cid:1)(cid:7)(cid:13)(cid:12)(cid:17)(cid:8)(cid:18)(cid:17)
(cid:32) (cid:6)(cid:17)(cid:31)(cid:26)(cid:18)(cid:12)(cid:10)(cid:20)(cid:1)(cid:25)(cid:23)(cid:11)(cid:23)(cid:27)(cid:1)(cid:26)(cid:27)(cid:10)(cid:27)(cid:14)
(cid:3) (cid:5)(cid:23)(cid:27)(cid:23)(cid:25)(cid:1)(cid:14)(cid:22)(cid:12)(cid:23)(cid:13)(cid:14)(cid:25)(cid:1)(cid:29)(cid:10)(cid:20)(cid:28)(cid:14)(cid:26)
(cid:5)(cid:2)
(cid:5)(cid:1)(cid:2)
(cid:5)(cid:4)
(cid:5)(cid:3)
(cid:5)(cid:1)(cid:1)
(a)
(b)
(c)
Fig. 1: (a) Tele-operated surgical robot, adopted from [12], [13], (b) Typical control structure and system context in robotic surgery, (c)
Operational context characterized by surgical gestures in a sample trajectory of Block Transfer task
and simulators to provide real-time feedback to surgeons and
potentially improve the learning curves in simulation training
and prevent adverse events in actual surgery. In summary, the
main contributions of the paper are as follows:
• Demonstrating that across a surgical task, the errors are
context-speciﬁc, i.e., dependent on the current surgical
gesture being performed by the surgeon (Section II).
This suggests the possibility of designing a context-
aware monitoring system that can detect gesture-speciﬁc
errors and can be pervasively applied to any surgical
task that is composed of such atomic gestures.
• Developing a safety monitoring system, consisting of
a surgical gesture classiﬁer and a library of gesture-
speciﬁc classiﬁers that can detect the erroneous gestures
in real-time (Section III). Our proposed system can
detect errors caused by accidental faults or attacks
targeting the software, network or hardware layer or
human errors that affect the kinematic state of the robot.
• Introducing a simulation environment based on ROS
[14] and Gazebo [15] and the Raven II [12] control
software (an open-source surgical robot from Applied
Dexterity Inc.), that enables the experimental evalua-
tion of safety monitoring solutions for robotic surgery
(Section IV-B). Our simulator can model physical inter-
actions between the robot and its environment, generate
synthetic surgical trajectory data, and simulate realistic
robot failure modes using software fault injection with-
out harming the physical robot.
• Evaluating our monitoring system in terms of accuracy
and timeliness in detecting errors using data from two
different surgical platforms, Raven II and daVinci Re-
search Kit [16] (dVRK from Intuitive Surgical Inc.). Our
results in Section V provide evidence for our hypothesis
that a context-aware safety monitor can enable more
accurate detection of anomalies. The proposed monitor
can detect potential adverse events for the surgical tasks
of Block Transfer and Suturing with average F1 scores
of 0.88 and 0.76 within average reaction time windows
of 1,693 and 57 milliseconds, respectively.
II. PRELIMINARIES
Our goal is to enhance the surgical robots with capabilities
for real-time detection of errors and providing just-in-time
386
feedback to surgeons or taking automated mitigation actions
before safety-critical events occur. Our safety monitoring
solution is built upon the main concepts described next.
Operational Context in Surgery: The diverse sources of
faults and involvement of humans in the control of surgical
robots make real-time detection of adverse events particularly
challenging and require understanding of the surgical context
in order to decide on the best safety actions to take.
Previous work [19] has deﬁned context in surgical proce-
dures as a hierarchy, starting from the surgical procedure that
is being executed, to the steps in the procedure, to surgical
tasks, subtasks or gestures, and ﬁnally the speciﬁc motions of
the robot (see Figure 2). Within a speciﬁc procedure (e.g.,
Radical Prostatectomy) for a surgical task (e.g., suturing),
the change in operational context happens in the temporal
domain as a result of the change of the surgeon’s gestures or
the position and orientation of the surgical instruments end-
effectors, leading to the corresponding change in the subtask
(e.g., pull suture through). Other contributing factors to the
change in the operational context in surgery are the state of
the robot software, the type of surgical instrument used, and
the anatomical structures and their interactions within the
surgical workspace. The operational context can be either
observed directly using video data or inferred from the
corresponding kinematics data and other state information
from the robot.
One common approach to modeling of surgical tasks is us-
ing ﬁnite-state Markov chains with each state corresponding
to an atomic surgical gesture [21]. In our work, we consider
tasks from the Fundamentals of Laparoscopic Surgery (FLS)
[22], in particular, Suturing and Block Transfer, which are
commonly observed in both simulation training and actual
surgery. Figure 3a shows the Markov chain representation
of the task of Suturing, which we derived from the analysis
of the dry-lab demonstrations in the JIGSAWS dataset [23].
Surgical Task
Laparoscopic
Cholecystectomy
Laparoscopic
Cholecystectomy
Anastomosis
Faults
Wrong orientation
of end-effector
Too much force
with grasper
Wrong Cartesian
Position
Errors
Liver laceration
with bleeding
Peroration of
gallbladder wall
Needle
overshoots goal
Adverse Events
Hematoma [17]
Subhepatic [17]
Punctures [18]
abcess
Vessel
TABLE I: Common Errors in Surgery
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:23:52 UTC from IEEE Xplore.  Restrictions apply. 
Start
0.74
G1
0.21
0.97
0.01
0.03
G4
0.05
G5
0.01
0.89
0.22
G2
0.62
0.02
0.04
0.96
0.01
0.03
0.03
0.02
0.67
0.76
G3
0.02
0.02
0.01
0.92
0.93
0.50
0.08
0.05
0.08
G6
0.01
0.01
0.01
0.50
0.13
0.08
G8
0.21
G10
G9
0.17
G11
1.00
End
Start
1.00
G2
1.00
G12