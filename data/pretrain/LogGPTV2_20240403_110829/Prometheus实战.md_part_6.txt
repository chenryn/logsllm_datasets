·Exporter
负责不同的业务。
---
## Page 87
本文档使用书栈(BookStack.CN)构建
满足以下格式：
采样数据
文本内容，如果以开头通常表示注释。
注释
被忽略，
Exporter 收集的数据转化的文本内容以行（n）为单位，空行将
文本格式，并提供 http 请求。
格式，因为一个 Exporter 本质上就是将收集的数据，转化为对应的
在讨论 Exporter 之前，有必要先介绍一下 Prometheus 文本数据
文本格式
文本格式
内容如果不以
文本格式
·其他表示一般注释，供阅读使用，将被 Prometheus 忽略。
·文本格式
 metric_name [
gauge
。注释
文本内容最后一行为空行。
采样数据
histogram
#
开头表示定义 metric 类型，包含 
开头表示 metric 帮助说明。
）开头，表示采样数据。它通常紧挨着类型定义行，
summary
counter
---
## Page 88
本文档使用书栈(BookStack.CN)构建
下面是一个完整的例子：
文本格式
乙
2
忆
口
2
6
二
15
切
3
9
O
2
 # TYPE rpc_duration_seconds summary
# HELP rpc_duration_seconds A summary of the RPC duration in
# Finally a summary, which has a complex representation, too:
# A weird metric from before the epoch:
 msdos_file_access_time_seconds{path="C:\\DIR\\FILE.TXT",error="Cannot
 http_requests_total{method="post",code="200"} 1027 1395066363000
# TYPE http_requests_total counter 
 # HELP http_requests_total The total number of HTTP requests.
http_request_duration_seconds_count 144320
http_request_duration_seconds_sum 53423
http_request_duration_seconds_bucket{le="+Inf"} 144320
http_request_duration_seconds_bucket{le="1"} 133988
http_request_duration_seconds_bucket{le="0.2"} 100392
http_request_duration_seconds_bucket{le="0.1"} 33444 
http_request_duration_seconds_bucket{le="0.05"} 24054
# HELP http_request_duration_seconds A histogram of the request
# A histogram, which has a pretty complex representation in the
# Minimalistic line:
# Escaping in label values:
http_requests_total{method="post", code="40o"} 
］ value [ timestamp ］
label_value " }["," ” "}"
seconds.
http_request_duration_seconds_bucket{le="0.5"} 129389
duration.
text format:
metric_without_timestamp_and_labels 12.47
find file:\n\"FILE.TXT\""} 1.458255915e9
3 1395066363000
88
---
## Page 89
本文档使用书栈(BookStack.CN)构建
是
需要特别注意的是，
文本格式
53
2
30.
，采样数据的总和应表示为
顺序排列。
histogram
histogram
采样数据的总量应表示为
rpc_duration_seconds_count 2693
H
 x_bucket{le="y"} 。
x{quantile="y"}。
 summary
histogram
 rpc_duration_seconds_sum 1.7560473e+07
 rpc_duration_seconds{quantile="0.01"} 3102
rpc_duration_seconds{quantile="0.99"} 76656
rpc_duration_seconds{quantile="0.9"} 9001
rpc_duration_seconds{quantile="0.5"} 4773
rpc_duration_seconds{quantile="0.05"} 3272
[x_count]
类型的采样数据的quantile应表示为
类型的采样必须包含
类型的采样分区统计数据将表示为
或
的值。
，假设采样数据 metric 叫做，
summary
类型必需满足以下条件：
x_count。
 X_sum 
x_bucket{le="+Inf"}
必需按从小到大
如果 
它的值等
×
区
---
## Page 90
致为：
http 请求即可，
既然一个 exporter 就是将收集的数据转化为文本格式，并提供
Sample Exporter
 Sample Exporter
本文档使用书栈(BookStack.CN)构建
下面我将用
一个简单的
Sample Exporter
16
15
切
3
11.
6
8
7
6.
4.
· Sample Exporter
 var exportData string = ^# HELP sample_http_requests_total The
 func handler(w http.ResponseWriter, r *http.Request) {
func main(） {
import（
package main
。与 Prometheus 集成
fmt.Fprintf(w, exportData)
一个简单的 exporter
http.ListenAndServe(":8080", nil)
http.HandleFunc("/", handler)
"fmt"
"net/http"
[golang]
 exporter
那很容自己实现一个。
实现一个简单的
sample_exporter”
其代码大
90
---
## Page 91
本文档使用书栈(BookStack.CN)构建
Sample Exporter
6
山
15
3
3
3
5
3
3
2
2
忆
2
乙
21.
20.
19.
 sample_rpc_duration_seconds_sum 1.7560473e+07
 sample_rpc_duration_seconds{quantile="0.05"} 3272
# TYPE sample_rpc_duration_seconds summary 
 # HELP sample_rpc_duration_seconds A summary of the RPC duration in
# Finally a summary, which has a complex representation, too: 
 sample_http_request_duration_seconds_count 144320
 sample_http_request_duration_seconds_sum 53423 
# HELP sample_http_request_duration_seconds A histogram of the
 # A histogram, which has a pretty complex representation in the
 sample_http_requests_total{method="post",code="4oo"} 
 sample_http_requests_total{method="post",code="20o"} 1027
 # TYPE sample_http_requests_total counter 
sample_rpc_duration_seconds{quantile="0.99"} 76656
sample_rpc_duration_seconds{quantile="0.9"} 9001 
sample_rpc_duration_seconds{quantile="0.5"} 4773
sample_rpc_duration_seconds{quantile="0.01"} 3102
seconds.
sample_http_request_duration_seconds_bucket{le="+Inf"} 144320
sample_http_request_duration_seconds_bucket{le="1"} 133988
sample_http_request_duration_seconds_bucket{le="0.5"} 129389
sample_http_request_duration_seconds_bucket{le="0.2"} 100392
sample_http_request_duration_seconds_bucket{le="0.1"} 33444 
sample_http_request_duration_seconds_bucket{le="0.05"} 24054
# TYPE sample_http_request_duration_seconds histogram
request duration.
text format: 
sample_metric_without_timestamp_and_labels 12.47
# Minimalistic line:
sample_msdos_file_access_time_seconds{path="c:\\DIR\\FILE.TXT",error=
find file:\n\"FILE.TXT\""} 1.458255915e9
# Escaping in label values:
1395066363000
1395066363000
total number of HTTP requests.
C
---
## Page 92
本文档使用书栈(BookStack.CN)构建
重启加载配置，然后到PrometheusConsole 查询，你会看到
打开
我们可以利用Prometheus的 static_configs来收集
当运行此程序，你访问
 Sample Exporter
与
smcepingsn labvalutim
的页面：
 simple_exporter 
 sample_exporter
50.
2
 Prometheus 集成
- job_name: "sample"
 sample_rpc_duration_seconds_count 2693
 prometheus.yml
 static_configs:
- targets: ["127.0.0.1:8080"]
seconds
s_comn1 25604
）的数据。
的数据。
conds{path="C:\\DIR\\FILE.TxT",error="Cannot find file:\n\"FILE.TxT\""}1.458255
文件，
http://localhost:8080/metrics,
在
14432
nofthereot fomaton.
 scrape_configs
中添加如下配置：
将看到这样
92
---
## Page 93
本文档使用书栈(BookStack.CN)构建
Sample Exporter
ple
Alerts
Graph
---
## Page 94
本文档使用书栈(BookStack.CN)构建
默认开启的功能
功能对照表
用 Golang 编写。
Node E
NodeExporter安装使用
node_exporter 
Node Exporter 安装使用
exec
entropy
edac
diskstats
cpu
conntrack
arp
·Node Exporter
名称
。数据存储
。程序安装和启动
。功能对照表
Exporter
■Docker 安装
■二进制安装
■将被废弃功能
■默认开启的功能
 execution 统计信息
默认关闭的功能
可用内核熵信息
错误检测与纠正统计信息
收集 cpu 统计信息
主要用于*NIX系统监控，
说明
中收集磁盘
Dragonfly, FreeBSD
Linux 
Linux
 Linux
Linux
Linux
Darwin, Dragonfly, FreeBSD,
Linux
系统
---
## Page 95
本文档使用 书栈(BookStack.CN)构建
默认关闭的功能
Node Exporter 安装使用
buddyinfo
bonding
zfs
xfs
wifi
vmstat
uname
time
textfile
stat
sockstat
netstat
netdev
meminfo
mdadm
loadavg
infiniband
hwmon
filesystem
filefd
名称
收集 
收集×fs 运行时统计信息
收集 wifi 设备相关统计数据
M
通信
系统当前时间
通参本
从息断
从数
网口流量统计信息，单位 bytes 
内存统计信息
从息
收集系统负载信息
从计
从或
刘空
收集系统配置以及激活的绑定网卡数量
过息
过数信
，等
信
M
 InfiniBand
zfs 性能统计信息
/proc/vmstat
包含系启
/proc/mdstat
指息
息
/proc/buddyinfo中收集内存碎片统计信息
uname
定
系统调用，获取系统
启动时间，
0本
netstat -s
中收集各种统计
息
中收集统计信息
1.收
中获取设备统计信
配置中收集网络统
,forks,
收集网络统计
中收集监控器
中收集
中收集文
说明
使用
中
信
Linux
Linux (kernel 4.4+)
Linux
any
any
Linux
Linux
Linux
Darwin, Dragonfly, FreeBSD,
Linux
Linux
Darwin,
Linux
Linux
Darwin, Dragonfly, FreeBSD,
Linux
any
Linux,
Darwin,
Linux, OpenBSD
Linux
 Dragonfly, FreeBSD,
Linux
Linux
FreeBSD,
系统
95
---
## Page 96
本文档使用 书栈(BookStack.CN) 构建
我们可以到下载页面
二进制安装
程序安装和启动
node_exporter 收集的功能模块，
注意：我们可以使用
将被废弃功能
Node Exporter 安装使用
ntp
megacli
gmond 
tcpstat
systemd
supervisord 
runit
qdisc
nfs
meminfo_numa
mountstats
logind
ksmd
ipvs
interrupts
drbd 
devstat
名称
从 NTP 服务器中获取时钟
从 MegaCLI 中收集 RAID 统计信息
收集 Ganglia 统计信息
收集 supervisord 状态信息
收集 runit 状态信息
收集队列推定统计信息
M
M
收集更具体的中断统计信息
收集远程镜像块设备（DRBD）统计信息
M
M
M
收集设备统计信息
/proc/net/ip_vs_stats 
systemd”中收集设备系统状态信息
logind中收集会话统计信息
/proc/net/ip_vs
/proc/meminfo_numa
/sys/kernel/mm/ksm中获取内核和系统统计信息
面选择对应的二进制安装包，
 --collectors.enabled 
中收集 IPVS 状态信息，从
获取统计信息
）中收集内存统计信息
中收集文件系统统计信息，包
说明
如果不指定，将使用默认模块。
运行参数指定
下面我将以
 Linux
Linux
any
any
Linux
Linux
Linux
Linux
Linux
Linux
Linux
OpenBSD
Linux,
Linux 
FreeBSD
Dragonfly,
any
Linux
any
0.14.0
系统
96
---
## Page 97
本文档使用书栈(BookStack.CN)构建
Docker 
运行 Node Exporter，
我们可以使户
作为例子，
Node Exporter 安装使用
2
·启动 Node Exporter
·使用 tar 解压缩 node_exporter-0.14.0.linux-
·使用 wget 下载 Node Exporter
ST
4.
3
2
2
amd64.tar.gz
 INFo[0ooo] Listening on :9100
source="node_exporter.go:186"
source="node_exporter.go:160'
INFo[oooo] Enabled collectors:
collector.textfile.directory source="textfile.go:57"
INFo[oooo] No directory specified, see --  
date=20170321-12:13:32）
INFo[0000] Build context (go=go1.7.5， user=root@bb6d0678e7f3,
source="node_exporter.go:140"
revision=840ba5dcc71a084a3bc63cb6063003c1f94435a6)
INFo[0ooo] Starting node_exporter (version=0.14.0, branch=master,
cd node_exporter-0.14.0.linux-amd64 
tar -xvzf ~/Download/node_exporter-0.14.0.linux-amd64.tar.gz
cd ~/Prometheus
0.14.0.linux-amd64.tar.gz
.....
https://github.com/prometheus/node_exporter/releases/download/v0.14.c
cd ~/Download 
安装