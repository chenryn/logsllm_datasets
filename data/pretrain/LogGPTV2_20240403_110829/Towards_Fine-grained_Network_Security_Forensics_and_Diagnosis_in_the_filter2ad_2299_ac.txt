to the controller model by searching CFG and the paths to the op-
erations. In the meantime, ForenGuard also identifies the state
variables and searches all read/write operations of the variables.
Here, we define the state variables as the class instance variables
of the application. The insight behind is that, except the inputs
(events) from south or north bound interfaces, instance variables
are normally used to store the states of the application and make
forwarding decisions. For example, in the motivating example, all
previously learned information is saved in the MAC/VLAN to port
map data structure. And every output flow rule is generated based
on both the input events and the runtime values of the MAC/VLAN
to port map data structure. Specially, we do not count variables
that are used for logging (log system of the controller itself, not
ForenGuard) or debugging, which are useless for our purpose.
Next, ForenGuard constructs the data dependency graph by
applying the backward data flow tracking technique on the state
variables identified in the previous analysis. To support the above
3We assume the SDN controller and third-party applications should be open source to
the network administrator and operators.
Figure 4: Data Dependency Graph of the Running Example
Figure 5: Challenge of Coarse-granularity
analysis, several challenges are addressed. First, different from regu-
lar programs, an SDN application does not have entry points, since
the main function is missing. To apply data flow tracking as normal,
entry points must be explicitly defined. To this end, our SDN model
in Section 2 is leveraged, which provides sufficient hints. The major
part of each application is multiple event-driven handler functions.
The event handler functions are registered in the Core Services to
subscribe the corresponding events. Therefore, we set the handler
functions as the entry points for the data dependency analysis.
Second, to adapt data flow tracking on a SDN controller, we
define sources and sinks as follows. The data sources we use are
the parameters of the handler functions including the events and
corresponding metadata (e.g., in-port of a new flow) and the state
variables from read operations. The data sinks are state variables
from write operations and generated flow rules (e.g., Line 27 of the
running example).
ForenGuard performs context-sensitive, field-sensitive data
flow analysis on controllers to build the data dependency graph
(DDG). Figure 4 shows the data dependency graph (DDG) of the
running example. The data of the MAC/VLAN to port map could be
from the input parameters (sw and pkt) which are extracted from
the PacketIn event. The generated flow rule msд (if that branch
is triggered) is affected by the input parameters and the map. At
runtime, ForenGuard will generate more concrete and precise
information flows based on the logs of read/write operations of the
state variables.
Technical Challenges: We discuses two technical challenges about
the static analysis: inaccuracy and coarse-granularity. The inac-
curacy of static analysis is well-known since it just explores all
possible data flow paths but cannot track if one certain path is
actually triggered in runtime. Another challenge is that static anal-
ysis can only provide coarse-grained data flow tracking results.
PacketIn EventswpktmacVlanToSw-itchPortMapmsgmacVlanToSwitchPortMapLearningSwitch ApplicationEvent1Event2Event3WriteWriteWriteEvent4ReadNew Flow RuleWhich event other than 4 caused the new flow rule?That is because each state variable may contain many fields, and
it is hard to track which field every event actually accesses. In
our running example, the MAC/VLAN to port mapping data struc-
ture contains multiple key-value pairs/entries/entries. Illustrated
in Figure 5, suppose we already know Event 4 reads the variable
macV lanToSwitchPortMap and then processes a new flow rule
which causes the forwarding problem, however, it is still not clear
which entry of the variable Event 4 reads, and which previous event
adds/modifies this entry. To address them, we instrument the source
code of the controller and applications to profile the detailed field
read/write operations of each state variable.
Instrumentation: Based on the static analysis results, another
sub-module instrumentation starts to instrument the controller ap-
plications at the bytecode level. The target of the instrumentation is
to profile important operations of the control plane at runtime. The
instrumented code will record the source code context (e.g., class
name, line number, thread ID) as the metadata with the involved
heap memory information (the virtual memory address in JVM)
of the operation. Specially, for variable read/write operations, we
do not record the runtime values of the variables for two reasons:
First, recording the runtime values of the variables is too costly.
Second, our purpose is to track the information flows, which has
no need to track the concrete variable values. For example, we aim
to track an information flow starting from a data plane event e1
changing the value of a.x (whose virtual memory address is m1).
Further, another information flow reads this memory location and
finally generates a message msд1 which installs a new flow rule .
Then we can build the the causal relationship from e1 to msд1.
4.3 Activity Logger
After the Preprocessor module, we deploy the instrumented con-
troller in an SDN network. The Activity Logger module works as a
controller component and dynamically collects activities from both
the control plane and the data plane and further builds the causal
dependency relationships. The activities are handled by the three
sub-modules: 1) Data Plane Activity Collector collects the runtime
data plane activities; 2) Control Plane Activity Collector collects
the runtime control plane runtime activities; 3) Causal Dependency
Generator builds the causal dependency relationships between the
collected activities and saves them into a database.
Data Plane Activity Collector: Section 3 defines the activities
of the data plane. The Activity Logger module first keeps tracking
all OpenFlow messages between the control plane and the data
plane. Since we consider switches could be compromised in our
threat model, the Data Plane Activity Collector sub-module does not
directly monitor the states of the data plane switches through some
administering channels (e.g., ovs-ofctl, ovs-dpctl). Instead, to flexibly
track the states and any transitions of the data plane, the Data
Plane Activity Collector sub-module makes use of the OpenFlow
messages to speculate the states of the data plane switches. In the
OpenFlow protocol, any changes in the data plane forwarding tables
(install, modify, delete, expire) should be enforced by or inform the
control plane via OpenFlow messages. Therefore, by tracking and
analyzing all OpenFlow messages, it is already able to understand
the state and changes of the data plane forwarding tables. In our
tracking solution, the Data Plane Activity Collector sub-module
always maintains a data structure that stores the current state of the
data plane forwarding tables. Whenever it observes the OpenFlow
message which shows a change of data plane forwarding table,
the module will generate the new state of the table based on the
meaning of that OpenFlow messages. For example, a FlowRemoved
messages will indicate that a flow entry in one forwarding table
has expired. Thus, the sub-module can delete the flow entry from
its own data structure and log the change. In the future diagnosis
phase, if the stored data plane state does not match the actual data
plane forwarding behaviors, then there could be attacks from the
compromised switches.
Control Plane Activity Collector: The control plane activities
that we aim to collect are shown and explained in Section 3. The
previous Preprocessor module already instruments the source code
with the logic of recording these control plane activities. Thus in
runtime, the instrumented statements will forward the log infor-
mation to the Control Plane Activity Collector sub-module.
Causal Dependency Generator: The Causal Dependency Gen-
erator sub-module collects and processes the activities received
from the Data Plane Activity Collector and Control Plane Activity
Collector sub-modules. It reconstructs event-oriented execution traces
of the control plane and the state transition graphs of the data plane,
and then combines them together. State transition graphs include the
data plane forwarding states and state transitions. Event-oriented
execution traces include the function-level call graphs (function
operations and communication operations) and information flows
(variable operations) of the control plane. Figure 6 shows an exam-
ple of these two types of data structures. In this figure, Sx denotes
data plane forwarding states, ex denotes events, fx denotes func-
tion calls and a.x and b.y denote variables. Using these graphs, we
can reason the causal relationship between activities.
Algorithm 1: Function Call Graph Reconstruction
Input: S = list of function calls in [(thread ID: T , function
name: M), ... ]
Input: G = adjacency list representing the global control flow
graph {node:[adjacency nodes], ...}
call-graphs {thread:[[function calls],...], ...}
Output: L = list of function calls representing dynamic
stack[:] ← ∅ # Initiate the stack as empty only at the first run
of the algorithm
L[:][-1] ← 0;
foreach Si in S do
while stack[Si .T ] (cid:44) ∅ do
R ← stack[Si .T ].top();
if there is a path from R to Si .M in G then
break
stack[Si .T ].pop();
if stack[Si .T ] (cid:44) ∅ then
L[Ti][-1].append(Si)
else
L[Ti].append(new List(Si))
stack[Ti].push(Si .M)
tells the tool what to retrieve from the database and what to output.
For all queries, our tool supports to set up a time filter:
− − a f ter = yyyyMMddHHmmss
− − be f ore = yyyyMMddHHmmss|now
By using the above two options, we can query for activities within a
given time period. Our tool supports both fast querying for forward
issues and querying for detailed activities. In the following we will
explain how to use our tool to fast query for forwarding problems
and how to query detailed activities.
Motivated from networking diagnosis tools, ForenGuard sup-
ports automatically querying for network forwarding problems
including reachability, isolation, routing loop and way-point rout-
ing. Our tool provides an option:
− − problem = routinдloop|routinдpath|waypoint
Figure 6: Execution Traces of the Control Plane and State
Transition Graphs of the Data Plane
We design an algorithm (shown in Algorithm 1) to reconstruct
the dynamic function-level call graphs. The output of the algorithm
is a list of execution traces. Each execution trace is a sequence of
function operations which represents the entire execution from the
start of an event handler function to the end of the handler function.
We build the data dependency relationships of different variables
in each application, in the Activity Logger module, based on the
recorded read/write operations of the fields of the variables. For
example, suppose we have the result that event e has data flow rela-
tionship with the state variable v.a. When we dynamically log there
is a write operation to v.a with its object ID in the heap memory,
and this execution trace is triggered by an event e1, we can build the
information flow from e1 to v.a. In our running example, for every
generated OpenFlow message, we can find the data sources which
cause the messages. When diagnosing some suspicious messages,
we can directly find the data sources of the messages, which could
be the root causes. The Causal Dependency Generator sub-module
maintains a list of all runtime objects which are fields of the state
variables and the current data sources. After each operation, the
Causal Dependency Generator sub-module may update the data
sources of some objects. For example, a write operation will clear
the previous data sources for the object and may build new data
sources for this object.
4.4 Diagnosis
We design a command line tool for the users to query for recorded
activities in the SDN framework. The usage of the tool is shown as
the following:
U saдe : Diaдnosis [options]
The user can set up different options to satisfy their different query
requirements. The option:
− − query = trace|messaдe|event| f unction|variable
The argument routinдloop is to detect routing loops and will output
corresponding activities. The argument routinдpath is to output
the activities which are related to a certain network flow. To use
this argument, the user should also specify the matching conditions
for this network flow. For example, the user can use − − srcip and
− − dstip to specify a flow between two ip addresses. Our tool
currently supports to use the 5-tuple packet header to specify a
network flow. This argument can verify both the conditions of
reachability and isolation. The argument waypoint is to query for
forwarding rules of certain traffic going through certain specific
way_point. To use this argument, the user should specify both the
network flow and the − − dpid of the way_point switch.
Users can also query for detailed activities through our tool. As
shown previously, by using the − − query option, the users specify
what kinds of activities they want to query. The user can use the
argument trace for the corresponding execution traces, messaдe for
communication OpenFlow messages, event for event trigger and
dispatch activities, f unction for function call activities and variable
for variable access activities. The user can also set up several filters
to specify what kinds of activities are needed. For example, to query
for the execution traces that are relevant to a network flow whose
source IP is 10.0.0.2 and destination port is 80, we can write:
− − srcip = 10.0.0.2 − −dstport = 80
For messages, we can specify the application name and message
types (PacketIn, FlowRemoved and etc.). Our tool is independent
of controller types, programming language and hardware specifics.
Many network problems are caused by application crashes in
the SDN control plane [37]. Unlike other types of root causes, the
application crash does not directly output any harmful flow rules
to the data plane. To diagnose this kind of problem, by showing the
execution traces of the control plane, we can locate the crash point
in the program first (e.g., in which function) and then list relevant
activities in the execution trace. For example, many application
crashes are caused by data races at instance variables [44]. From
the execution traces, we can list the recent read/write operations
of variables and check if there is data race happened.
4.5 Flexibility of Tuning Stored Activities
According to the modeling of the SDN activities in Section 3, by
default our forensics function records all types of activities into
S0S1S2S3FlowMod MessageFlowMod MessageFlowRemoved MessageReceive(e1)Init(f1)Read(a.x)Write(b.y)Send(msg1) State Transition GraphsEnd(f1)Thread-1Receive(e2)Init(f2)Init(f3)Dispatch(e3)End(f3)End(f2)Thread-2Event-Oriented Execution TracesInformation FlowData Plane
States
×
28.6%
Functions
Activities
Tunable
Data Size
×
13.2%
Table 2: Options to Tune the Recorded Activities
✓
26.5%
Variables
Control Plane
Events
✓
×
20.2%
11.5%
OF Messages
the database. To provide better flexibility, before deploying our
system, we allow the users to tune their required types of activities
to database storage (instead of all types) to reduce some storage
overhead.
The options to tune the activities to be stored are shown in
Table 2. To build the causal relationship of different activities, some
types of activities are essential. For example, ForenGuard provides
flow-level forensics and diagnosis. Thus the data plane states and
the state transitions (i.e., OpenFlow messages) are necessary. To
build the causal relationship between different modules/apps in the
controller, the event dispatching and receiving information is also
necessary. Other than these, other types of activities are tunable
to be stored or not, because they are only used in the intermediate
stages of building the information flows. According to the recorded
data of several diagnosis cases shown in Section 5, we provide the
rough percentage of data size of each type of activity in Table 2.
5 EVALUATION
In this section, we present the implementation details and the eval-
uation results of ForenGuard.
5.1 Implementation
Controller Module
# of Edges in
the call-graph