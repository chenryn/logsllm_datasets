that  level  once  the  network  reaches  40%  malicious  nodes. 
The  reason  for  this  trend  is  that  the  level  1  nodes  lie  with 
intention  to  keep  them  from  being  detected.  In  effect,  the 
trust index forces the malicious nodes to lie less frequently 
and  therefore  helps  to  improve  the  accuracy  of  the  event 
determination. 
Figure  6  shows  results  for  level  2  malicious  nodes.  It 
shows that these nodes dramatically reduce the accuracy of 
the  network,  although  the  TIBFIT  still  outperforms  the 
baseline model. It is clear from this figure that even the trust 
index  has  trouble  tolerating  level  2  type  faults  due  to  the 
collaborative nature of the nodes. 
Figure  7  shows  level  0  nodes  with  concurrent  events 
compared  to  single  events,  both  simulations  using  TIBFIT. 
The  concurrent  events  occur  with  uniform  distribution 
simultaneously,  although  never  within  rerror  of  each  other. 
7
10
20
30
40
50
55
58
Percentage Network Compromised
Lvl 2 2-6 Baseline
Lvl 2 1.6-6 Baseline
Lvl 2 2-6 TibFit
Lvl 2 1.6-6 TibFit
Figure 6: Experiment 2 – Level 2 faulty nodes 
Level 0 Concurrent vs. Single Events
100
y
c
a
r
u
c
c
A
95
90
85
80
75
70
10
20
30
40
50
Percentage Network Compromised
Lvl 0 1.6-4.25 Single
Lvl 0 2-4.25 Single
Lvl 0 1.6-4.25 Concurrent
Lvl 0 2-4.25 Concurrent
Figure 7. Experiment 2 – Single and Concurrent 
Events 
4.3  Experiment 3 – Decay of Network 
The  next  simulation  increases  the  percentage  of  the 
network compromised by malicious nodes linearly over time. 
The  network 
the  network 
compromised by level 0 faulty nodes. After every 50 events 
5%  more  of  the  network  is  compromised  until  75%  of  the 
network is compromised. 
initialized  with  5%  of 
is 
Figure  8  and  figure  9  show  that  over  time  TIBFIT 
outperforms  the  baseline  model  in  all  cases.  This  occurs 
because  the  trust  indices  of  the  faulty  nodes  decrease  over 
time and the system can then handle the transition of some 
correct nodes to faulty nodes. It is important to compare only 
the  lines  with  the  same  standard  deviation  parameters, 
because  for  some  time  the  baseline  model  with  1.6-4.25 
outperforms the TIBFIT 2-4.25 case, although after a longer 
period of time the TIBFIT line does better, even though it has 
a higher fault rate in its correct nodes.  What is also notable 
is  that  the  TIBFIT  network  maintains  nearly  80%  accuracy 
even with 60% of the network compromised. 
Accuracy with Linear Increase in Faulty Nodes
y
c
a
r
u
c
c
A
1
0.8
0.6
0.4
0.2
50
150
250
350
450
550
650
750
Number of Events that have Occurred
Lvl 0 1.6-6 Baseline
Lvl 0 2-6 TibFit
Lvl 0 2-6 Baseline
Lvl 0 1.6-6 TibFit
Figure 8: Experiment 3 – Linear increase in number 
of faulty nodes 
Accuracy with Linear Increase in Faulty Nodes
y
c
a
r
u
c
c
A
1
0.9
0.8
0.7
0.6
0.5
50
150
250
350
450
550
650
750
Numbers of Events that have Occurred
Lvl 0 2-4.25 Baseline
Lvl 0 1.6-4.25 TibFit
Lvl 0 1.6-4.25 Baseline
Lvl 0 2-4.25 TibFit
Figure 9: Experiment 3 – Linear increase in number 
of faulty nodes 
5  Mathematical analysis 
In this section we analyze the probability associated with 
the  CH  successfully  identifying  a  binary  event  in  the 
presence of faulty nodes.  
Consider a baseline model with no trust indices assigned 
to the nodes. Let us assume that there are N event neighbors, 
of which m are faulty. The probability of a successful report 
N
2
P success
(
P Z
P Z
∑
=
≥
+
=
=
1
)
1
=
/ 2
N
j
from a correct node is p, and the probability of a successful 
report from a faulty node is q. Let X be the random variable 
that is the number of correct reports from correct nodes, and 
Y be the random variable indicating the same for the faulty 
nodes. They are defined: 
P
{
X
=
k
}
=
Y
P
{
=
k
}
=
N m
m
k
−
k
q
k
(
1
k
p
(
1
−
p
)
N m k
− −
m k
−
−
q
)
The  probability  that  the  N-m  correct  nodes  make  k  or 
more correct reports is therefore the sum of the probabilities 
from k to N-m, and from k to m for faulty nodes. Define the 
random variable Z=X+Y. We wish to know the probability 
that Z has a majority of the N votes, which is the probability 
that the event is successfully identified. The expressions are 
shown  in  equations  1,  2,  and  3.  These  expressions  map  to 
Figure 10 with N=10, q=0.5, and p=0.99, 0.95, 0.90, 0.85. 
The accuracy begins to fall off steeply once fifty percent 
of the network is compromised. TIBFIT can tolerate both an 
increase  in  faulty  nodes  over  time  and  more  initial  nodes 
being faulty, and will therefore outperform this baseline case. 
Next we will show how TIBFIT performs over time. 
Consider 
the  TIBFIT  model.  Assume 
the  network 
initializes with N nodes with 1 faulty node and N-1 correct 
nodes.  We  will  corrupt  the  nodes  in  the  network  at  a 
constant rate of one after every k events and show how the 
system still functions with 100% accuracy till N-3 nodes are 
corrupted,  thereby  outperforming  the  baseline  case  which 
drops in accuracy once 50% of the nodes in the system are 
compromised. Without loss of generality, let us assume that 
N  is  odd.  We  also  make  the  simplifying  assumption  that 
correct nodes are always correct and the faulty nodes always 
fail. Let CTIcorrect be the CTI of the set of correct nodes and 
CTIfaulty be the CTI of the set of faulty nodes. 
After every k events a good node is compromised. After 
(N-2)*k  rounds,  total  number  of  correct  nodes  is  3,  and 
faulty nodes is N-3. CTIcorrect is 3 as correct nodes are always 
correct and each has a TI of one. After the first faulty report, 
the TI of a node becomes e(-λ). Therefore after k rounds, the 
TI of the faulty node would be e(-kλ). So, CTIfaulty for (N–3) 
faulty nodes when the newest addition to the faulty set has 
made k errors would be 
e
2
−+
.  
+
e
e
k
λ
k
λ
)2
λ
N
−
−
−
(
k
+K
+
j
, now let 
i
=
N
2
+ −
j
k
                                (1)
N m
−
k
*
k
p
(
1
−
p
)
N m k
− −
*
m
i
i
q
* (1
−
q
)
m i
−
m N m
≤
−
(2)
K
+
j m
,
N
2
∑
min
k
=
N
2
+ −
j N m
−
(
m
k