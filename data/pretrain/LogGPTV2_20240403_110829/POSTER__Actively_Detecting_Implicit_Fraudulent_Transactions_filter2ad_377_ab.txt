partial derivative of the loss:
⃗wt +1 = ⃗wt − α · ∂L1
∂w
(2)
where α is a hyper-parameter by means of learning rate. After
enough iterations of updates, we get the final d-dimensional feature
vector of node w. The procedure is not influenced by unbalanced
labels at all, since only transaction records are needed.
3.3 Training Classifiers from Transaction
Labels
|D|(cid:88)
(cid:18)
дi f (xi ) + 1
(cid:19)
We define D = {(xi , yi )} as the collection of labeled dataset, where
xi is the feature vector of the i-th instance and yi is the label. The
features of an instance are made up of the learned features of the
involved transferor and transferee, as well as the basic information
in the transaction situation. yi = 1 when it is a fraudulent case;
otherwise, yi = 0. ˆyi denotes the predictive fraud score of the i-
th instance by our model, and l (yi , ˆyi ) is a differentiable convex
function of decision tree between yi and ˆyi. Besides, a regularization
term Ω(·) is also added. Inspired by [8], we show the loss as follows:
L2 =
(3)
where L2 is the loss function, дi and hi is the first order and second
order partial derivative of l (yi , ˆyi ):
2hi f 2 (xi )
+ Ω( f )
i =1
дi =
∂l (yi , ˆyi )
∂ ˆyi
hi =
∂2l (yi , ˆyi )
∂ ˆyi ∂ ˆyi
(4)
Although linear classifiers like logistic regression are also widely
applied in supervised learning, we choose the above gradient boost-
ing based models instead as for its high accuracy in the case. When
the training module is finished, the predictor module has the ability
of active detection.
4 EXPERIMENTS
In this section, we will show the effectiveness of the proposed model
versus rule-based approach in the real electronic transactions.
4.1 Benchmark, Baseline and Evaluation
Metrics
We collect the transaction records from December 1, 2016 to Feb-
ruary 20, 2017 in Alipay, from which about 57 million records are
PosterCCS’17, October 30-November 3, 2017, Dallas, TX, USA2476F1
KS
86.18%
41.93%
48.26%
51.77%
57.48%
AUC
61.09%
98.23%
65.22% 88.75% 98.79%
Table 1: The performance comparison between baseline and our model.
REC@100 REC@500 REC@1000
Methods
73.04%
Baseline
Our Model
78.00%
5 CONCLUSION
We propose a novel method for actively detecting implicit fraudu-
lent transactions. From the empirical results, the proposed model
significantly outperforms rule-based baseline. In our future work,
we will investigate more possible solutions to reduce the fraud cases
further.
ACKNOWLEDGEMENT
The authors thank the anonymous reviewers for their valuable
suggestions.
REFERENCES
[1] Emin Aleskerov, Bernd Freisleben, and Bharat Rao. 1997. Cardwatch: A neural
network based database mining system for credit card fraud detection. In CIFEr.
IEEE, 220–226.
sampled, so as to build the transaction network and learn user fea-
tures. We also randomly select 2 million records from February 24,
2017 to April 9, 2017 for training the classifier, and adopt 0.8 million
records from April 10, 2017 to April 20, 2017 as the test dataset.
In order to test the performance of our model, we compare the ex-
perimental results with the rule-based baseline. Inspired by several
guidelines2, dozens of the rules are summarized from the current
transfer environments. For example, if the IP address or telephone
are from a same city, if the transferees has been complained in the
past and so on.
To make a fair comparison, we evaluate using different evalua-
tion metrics. Receiver Operating Characteristic (ROC) curve reflects
the diagnostic capacity of a binary classifier, which is decided by
drawing true positive rate against the false positive rate, while
Area Under a Curve (AUC), as described by its name, is the value
of the area under (the ROC) curve3. Another important metric is
Precision-Recall (PR) plotting curve as the discrimination thresh-
old varies, and the F1 Score is interpreted as harmonic mean of
precision and recall4. Besides, Kolmogorov-Smirnov (KS) test is a
nonparametric test of probability distribution between predictive
results and golden standard5.
4.2 Empirical Results
As described in Table 1, our proposed method can consistently
outperform baseline over different testing metrics. In practice, we
pay more attention on recall at k predictive samples. Specifically,
the value of “REC@100” equals 73.04% means recall value is 73.04%
if we alert only 1 time in 100 transaction records. So the higher value
of “REC@k” is, the more accurate it is. In addition, both AUC values
are close to 100%, as for extremely few fraudulent transactions in
statistics.
(a) PR Curve
(b) ROC Curve
Figure 3: PR Curve and ROC Curve
Figure 3 shows the PR curve and the ROC curve of our model
against baseline. Obviously, in the PR curve, the performance of our
model outperforms baseline consistently. For the other comparison
of the ROC curve, it is easy to observe that the true positive rate is
93.56% of our model when false positive rate is 5%. By contrast, the
value of baseline is only 90.58% with same false positive rate.
2https://www.bluefin.com/merchant-support/identifying-fraudulent-transactions
3https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve
4https://en.wikipedia.org/wiki/F1_score
5https://en.wikipedia.org/wiki/Kolmogorov-Smirnov_test
[2] Gerald Donald Baulier, Michael H Cahill, Virginia Kay Ferrara, and Diane Lambert.
2000. Automated fraud management in transaction-based networks. (Dec. 19
2000). US Patent 6,163,604.
[3] Richard J Bolton and David J Hand. 2002. Statistical fraud detection: A review.
Statistical science (2002), 235–249.
[4] Richard J Bolton, David J Hand, et al. 2001. Unsupervised profiling methods for
fraud detection. Credit Scoring and Credit Control VII (2001), 235–255.
[5] R Brause, T Langsdorf, and Michael Hepp. 1999. Neural data mining for credit
card fraud detection. In ICTAI. IEEE, 103–106.
[6] Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2015. Grarep: Learning graph repre-
sentations with global structural information. In CIKM. ACM, 891–900.
[7] Pedro Casas, Alessandro D’Alconzo, Giuseppe Settanni, Pierdomenico Fiadino,
and Florian Skopik. 2016. POSTER:(Semi)-Supervised Machine Learning Ap-
proaches for Network Security in High-Dimensional Network Data. In CCS. ACM,
1805–1807.
[8] Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system.
In SIGKDD. ACM, 785–794.
[9] William W Cohen. 1995. Fast effective rule induction. In ICML. 115–123.
[10] Sushmito Ghosh and Douglas L Reilly. 1994. Credit card fraud detection with a
neural-network. In System Sciences, Vol. 3. IEEE, 621–630.
[11] David J Hand. 1981. Discrimination and classification. Wiley Series in Probability
and Mathematical Statistics, Chichester: Wiley, 1981 (1981).
[12] Sanjeev Jha, Montserrat Guillen, and J Christopher Westland. 2012. Employing
transaction aggregation strategy to detect credit card fraud. Expert systems with
applications 39, 16 (2012), 12650–12657.
[13] Mark J Nigrini. 1999. I’ve got your number. Journal of accountancy 187, 5 (1999),
79.
[14] Raghavendra Patidar, Lokesh Sharma, et al. 2011. Credit card fraud detection
using neural network. IJSCE 1, 32-38 (2011).
[15] J Ross Quinlan. 1990. Learning logical definitions from relations. Machine learning
5, 3 (1990), 239–266.
[16] Donald Tetro, Edward Lipton, and Andrew Sackheim. 2000. System and method
for enhanced fraud detection in automated electronic credit card processing.
(Aug. 1 2000). US Patent 6,095,413.
[17] Massoud Vadoodparast, Abdul Razak Hamdan, et al. 2015. Fraudulent Electronic
Transaction Detection Using Dynamic KDA Model. IJCSIS 13, 3 (2015), 90.
[18] Christopher Whitrow, David J Hand, Piotr Juszczak, D Weston, and Niall M
Adams. 2009. Transaction aggregation as a strategy for credit card fraud detection.
Data Mining and Knowledge Discovery 18, 1 (2009), 30–55.
Recall00.20.40.60.81Precision00.20.40.60.81BaselineOur ModelFalse Positive Rate00.10.20.30.4Ture Positive Rate0.50.60.70.80.91BaselineOur ModelPosterCCS’17, October 30-November 3, 2017, Dallas, TX, USA2477