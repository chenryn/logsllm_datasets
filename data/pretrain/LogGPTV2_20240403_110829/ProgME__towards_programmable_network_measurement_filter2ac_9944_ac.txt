Identifying heavy hitter is trivial if one maintains a counter
for every single ﬂow. However, this naive approach is not
memory-eﬃcient and does not scale to large number of ﬂows.
We propose Multi-Resolution Tiling (MRT), which exploits
the versatility of FQAE and oﬀers scalable heavy hitter iden-
tiﬁcation. Our key idea is that one can, by observing a
ﬂowset, infer the characteristics of its subsets or objects (the
ﬂows). Therefore, one can selectively zoom into ﬂowsets that
might contain heavy hitters while ignoring others.
4.1 Multi-Resolution Tiling
Algorithm 2 presents the multi-resolution tiling (MRT) al-
gorithm for identifying elephants. MRT starts from a range
R, which is provided through user speciﬁcation as a ﬂowset.
This enables one to only identify elephants belong to a cer-
tain ﬂowset, e.g., elephants that are TCP ﬂows. If no user
speciﬁed R is given, MRT starts its sear set to U.
At each iteration, MRT calls upon FQAE to match a list
of S packets from P . For every ﬂowset F (in D), MRT per-
forms sequential hypothesis test (Section 4.2) to determine
if Fw, the weight of F is larger than θ, the threshold deﬁ-
nition of elephant. MRT uses the following logical inference
rule (Eq. 4) to determine if a ﬂowset can be ruled out the
possibility of having any elephants. The logical inference
rule states: if the weight of a ﬂowset F , which is the sum of
the weight of all ﬂows in it, is smaller than θ, then none of
the ﬂow f in F can possibly be an elephant.
Fw  θ). We propose
to use sequential analysis, more speciﬁcally sequential prob-
ability ratio test (SPRT) proposed by Wald [30], to achieve
this. SPRT has been used successfully by Jung et al. [24] for
port scan detection. Instead of using a ﬁxed sample size to
determine the correctness of a hypothesis, sequential anal-
ysis allows one to determine dynamically whether further
observation is required based on the current observation.
Let H0 be the null hypothesis and H1 be the single alterna-
tive. An ideal test procedure should satisfy user requirement
on false positive rate (α) and false negative rate (β) while
requiring the minimum number of observations. SPRT, for
all practical purposes, can be regarded as such an optimum
sequential test procedure.
Let us denote the result of ith observation as Xi and
the result of a series of n observations as a vector X :. SPRT hinges on ﬁnding Λ(X) — the
probability ratio that this entire observation is produced
when H1 is true as compared to the case when H0 is true.
(5)
Λ(X) =
P{X|H1}
P{X|H0}
.
As described in Eq. 6, we compare Λ(X) against two positive
number A and B.3
If Λ(X) is greater than A (smaller
than B), we consider that there are strong enough statistical
evidence to accept (reject) the null hypothesis and the test
terminates. Otherwise, we continue with more observations.
Intuitively, Λ(X) is an indicator of the likelihood whether
H0 or H1 is true.
8>:reject H0 (accept H1)
accept H0 (reject H1)
continue observation
decision =
if Λ(X) > A
if Λ(X)  θ) is selected so
that false negative rate is smaller or equal to β
and H1 : Fw ≥ θ
(cid:2)
1 : Fw = θ
and H
H0 : Fw . If these n packets are randomly
sampled, then Xi are all independently identically distributed
(i.i.d). Therefore, Λ(X) can be found as the product of the
probability ratio of every single observation (Eq. 11). Eq. 12
deﬁnes Λ(X) in log space, which is easier for computation,
especially if Λ(X) is incrementally updated.
nY
nX
i=1
nY
P{Xi|H1}
P{Xi|H0}
(11)
(12)
Λ(X) =
Λ(Xi) =
i=1
log Λ(X) =
log Λ(Xi)
i=1
Let us denote the scenario that m among the n observed
packets belongs to F as X m
n . The probability of observing
X m
n when H1 or H0 is true can be found as:
P{X
P{X
m
n |H
n |H
1} = (θ
(cid:2)
0} = (θ
(cid:2)
m
(13)
(14)
Therefore, one can determine the probability ratio of X m
n
as:
)
)
)
)
m
n−m
n−m
(1 − θ
(1 − θ
+
−
+
−
m
log Λ(X
m
n ) = m log
3A > B. A and B are determined by the user prescribed
strength (α, β). A ≤ 1 − β
1 − θ+
1 − θ−
(15)
θ+
θ− + (n − m)log
, B ≥ β
1 − α
α
Eq. 15 requires the knowledge of n and m. Our F QAE rou-
tine counts the number of packets matched by each partition
(m). And n is simply the total number of packets observed
so far. The value of log Λ(X) can then be compared with
log A and log B as described in Eq. 6.
4.3 Partition Strategies
(a) C = 4
(b) C = 25
(c) C = 19
(d) G = 2
(e) G = 25
(f) G = 64
Figure 8: Partition Strategies.
After determining that a ﬂowset F might consist of one
or more elephants, we need to choose a partition of F so
that MRT can zoom into this ﬂowset. Note that the num-
ber of partitions of F is huge4, even when the cardinality of
F (|F|) is only marginally large, say 10. Therefore, it is im-
practical to explore every possible partition of F . Choosing
a particular partition presents a tradeoﬀ between memory
consumption and speed in identifying elephants. We deﬁne
the memory cost factor C as the number of subsets gener-
ated and the identiﬁcation gain factor G as the cardinality
of original ﬂowset over the total cardinality of remaining
ﬂowsets that might contain elephants.
One natural strategy is to partition F into equal size sub-
sets. Figure 8a and Figure 8b present two approaches with
diﬀerent memory cost factor and Figure 8d and Figure 8e
present their respective results after one iteration. With a
large memory cost factor, one can partition the ﬂowsets into
more smaller subsets. Consequently, it can exclude more
ﬂowsets in a single iteration and achieves a larger gain fac-
tor. Therefore, the optimal strategy is to use the largest
memory cost factor as long as it satisﬁes the memory con-
straint. The number of iterations (N ) required to identify
the elephants is:
N = logC |U|
(16)
Without a priori knowledge about the elephants, equal-
size partition is the optimal strategy.
In reality, however,
administrators do have knowledge to make educated guesses,
which might further improve the speed of heavy hitter iden-
tiﬁcation. For example, one probably expect the protocol
ﬁeld of elephants to be TCP or UDP in most networks. For
a particular network, certain IP addresses, e.g., Web/FTP
server and certain port numbers e.g., port 21 or 80, are more
likely to appear as elephants than others.
Pn
`
´
4The exact number of possible partitions for a set with n
elements can be found using Bell number recursively with
Bn+1 =
Bk and B0 = B1 = 1.
k=0
n
k
Using ProgME, it is easy to exploit user knowledge to
improve identiﬁcation of elephants. Our approach is to use
preferential partitioning, which allow users to predeﬁne ﬂowsets
with an ampliﬁed memory cost factor C
. This is illustrated
in Figure 8c. The lower left quadrant is assigned a larger
memory cost factor and is therefore partitioned into smaller
subsets. Consequently, even though the memory consump-
tion of the strategy in Figure 8c is lower than the strategy
in Figure 8b, the identiﬁcation gain is larger.
(cid:2)
The eﬀectiveness of preferential partitioning relies heav-
ily on the user to make correct guesses. We believe this
is an reasonable assumption for administrators monitoring
network behavior on a daily base.
5. EVALUATION & DISCUSSION
In this section, we evaluate the proposed ProgME frame-
work, which has two major components — the programmable
engine (FQAE) and the adaptive controller (MRT). We ﬁrst
look at the scalability and accuracy of FQAE and use two
application scenarios to discuss the potential usage of FQAE
in traﬃc engineering and security monitoring. We then dis-
cuss the speed of MRT in identifying heavy hitters.
5.1 Scalability of FQAE
FQAE has unique advantage in its scalability, which is
achieved by keeping per-ﬂowset counters instead of per-ﬂow
counters. We perform empirical evaluation on the scalability
of FQAE by comparing the number of counters one has to
keep for ﬂow-based and ﬂowset-based measurement.
{sip}
53,191
52,762
{dip}
214,411
127,543
{sip, dip}
336,463
293,519
#1
#2
Table 4: Number of Flows in 5-minute Traces.
Conﬁgs
#1
#2
#3
# ﬂowsets
Log-Only (Orig/Disj ) All (Orig/Disj)
19/22
0/0
0/0
40/55
35/38
800/845
Table 5: Size of Queries.
To understand the typical number of ﬂows one should ex-
pect on high speed links, we look at the packet traces col-
lected at OC-48 links by CAIDA [33] on 04/24/2003. We
choose to look at the 5-minute traces since 5-minute is a
typical statistics report interval. As shown in Table 4, these
trace ﬁles have a large number of ﬂows (in the order of
105−106) even when using simple ﬂow deﬁnitions like source
or destination IP address. If we use the two-tuple {sip, dip}
ﬂow deﬁnition, the number of ﬂows are even larger. We
only present two traces but other traces have similarly large
number of ﬂows.