96
617
Facet Total Passed Failed Insufﬁcient Protected Suspended Not Found
0
0
5
1
0
1
1
1,176
983
66
15
2
13
286
66
59
17
1
0
1
58
Most followed (all) 1,000
400
600
Veriﬁed users 1,738 1,531
862
373
489
Trending topics 14,230 13,260
(veriﬁed)
(not veriﬁed)
47
24
6
0
0
0
8
likely reﬂect lower bounds, as we will overlook both low-rate automation (too few
samples to apply the χ2 test) and automation that already employs randomization to
avoid appearing regular.
Public Timeline. The Twitter public timeline provides a sample of the thousands of
tweets being sent via the service each minute. Thus, we can use it to estimate the preva-
lence of automation for public statuses on Twitter overall. The Public timeline accounts
line of Table 1 reﬂects a sample from two days in April 2010. Of the 19,436 accounts
examined during this period, we could test 18,147 using our χ2 method. We ﬁnd that
16% of the accounts publishing tweets exhibit discernible automation.
A study conducted in August 2009 analyzed 11.5 million accounts, classifying those
publishing >150 updates per day as bots [15]. The report concluded that at least 24%
of all tweets were generated by automated bots. Around this time, Twitter began to
focus on reducing spam in the service, and in March 2010 published the claim that the
tweet spam rate had fallen below 1% [5]. To test these claims, we also ran a separate
analysis (on different, somewhat smaller data) of the public timeline weighted by tweet
rather than by account (Public timeline tweets row). We ﬁnd that 14% of public tweets
come from automated sources, suggesting that Twitter has indeed reduced the amount of
unwanted automation on the service (if the methodology used by [15] has an accuracy
comparable to ours). However, unless the vast majority of these automated tweets are
not spam, our results also indicate that the problem of spam is still far from being solved.
Veriﬁed Users. That veriﬁed accounts are often owned by celebrities and popular com-
panies (and Twitter manually approves accounts in the program) argues against these
accounts exhibiting strong automation in their tweets. A heavily automated account
may reﬂect badly on fans and customers, and would likely be harder to have approved
by Twitter. The Veriﬁed users row in Table 1 shows the results of our analysis of these
accounts. We ﬁnd that 6.9% failed our test—the amount of automation seen in veriﬁed
accounts is indeed less than the proportion in the general Twitter population. Among
the veriﬁed accounts that failed were: (1) popular bands reminding fans of concerts
and TV appearances, (2) TV shows reminding their fans of episodes each day, (3) po-
litical ﬁgures and parties publishing links to news articles, (4) journalists publishing
links to their organizations, (5) non-proﬁt organizations sharing links to issues around
the world, and (6) government organizations publishing news and alerts to the public.
Thus, common reasons for veriﬁed accounts failing our test were that they syndicated
news, shared links, or sent reminders to followers in an automated way.
Detecting and Analyzing Automated Activity on Twitter
109
Table 2. Proﬁles of different sources used to publish tweets
Overall Automation Bot
Bot
Organic Organic
Source
Web
Ubertwitter
Twitterfeed
Tweetdeck
REST API
Echofon
Mobile
Tweetie
Txt
Hootsuite
Use
31%
9.4%
7.5%
6.6%
5.9%
4%
2%
1.6%
1.6%
1.4%
Rate
6.4% 11.8%
2.3%
62.0% 27.8%
3.9% 1.5%
60.0% 21.0%
2.1%
1.9%
3.0%
2.6%
51.0% 4.1%
85%
Rate Exclusivity Rate Exclusivity
82%
87%
95%
77%
92%
77%
73%
73%
75%
37%
11.9%
94% 3.7%
76% 8.2%
96%
3%
5%
2.5%
2%
2%
84%
Most Followed Users. Although Twitter does not publish a list of most-followed users,
certain 3rd-party websites do. Using the list provided by TwitterCounter [16], we an-
alyzed the 1,000 most-followed accounts on Twitter. We ﬁnd that 12% of the testable
accounts failed our χ2 test (Most followed (all) row). Only 6.3% of the veriﬁed accounts
(next row) failed, slightly lower than the 6.9% found when analyzing all veriﬁed Twitter
accounts. Of the remaining 600 not-veriﬁed accounts, signiﬁcantly more (16%) were
likely to be automated. Manually examining the 96 non-veriﬁed accounts that failed,
many of them were news websites, blogs, and TV shows that use Twitter to broadcast
new content to followers.
Trending Topics. Twitter publishes a constantly updated list of the 10 most popular
words or phrases at any given time, providing users with a realtime glimpse at the
topics being discussed by the Twitter community. Since many users follow trending
topics by reading the latest tweets that contain those particular terms, it would seem
proﬁtable for automated accounts to target currently trending topic keywords. To test
the trending topics for automation, we performed a search for the ﬁrst trending topic
once per minute, and tested the accounts behind the resulting tweets. As the results
Table 1 show, we found that only 4.7% of accounts participating in the trending topic
discussions on Twitter exhibited strongly automated behavior—signiﬁcantly less than
the 16% automation found in the public timeline.
This lower rate of automation may indicate that Twitter is careful in preventing au-
tomated tweets from polluting the trending topic discussions, since the tweets posted
in response to trending topics are frequently viewed by both members and visitors.
Alternatively, perhaps the number of human users is simply proportionally higher in
searches for trending topics compared to the public timeline, or spammers have not
widely adopted this tactic yet.
Keyword Search Results. Using the Twitter Search API, we evaluated the accounts be-
hind the search results for 24 keywords that we believed might result in varying levels
of automation. (Our aim here is to obtain a qualitative sense of automated-vs.-non-
automated topics, rather than a representative assessment.) Sorted in descending order
by the proportion of testable accounts that appear automated, the words were: mortgage
110
C.M. Zhang and V. Paxson
(48%), jobs, insurance, news, discount, free, money (31%), click, sex, poker, photogra-
phy (24%), video, download, bot, video, viagra (17.5%), porn, school, tv, bieber, jesus
(8.3%), happy, bored, god (5.0%).
Most keywords tested had automation rates higher than the global 16% automation
rate, particularly keywords commonly associated with spam (“discount”, “free”, “sex”,
”poker”, and “download”). Likewise, keywords with lower automation rates often re-
ﬂect terms not commonly associated with spam (“jesus”, “happy”, “bored”, ”god”). It is
surprising though to ﬁnd that “photography” had a higher rate of automation than “via-
gra”. However, manually searching these keywords indeed reveals a signiﬁcant amount
of automated linking to photography-related articles and websites, while “viagra” often
appears in lighthearted messages or jokes posted organically.
A more comprehensive study might directly analyze the frequencies of words that
appear in the updates of automated/organic accounts. We leave this for future work.
Tweet Sources. For each account tested, we also analyzed the source appearing most of-
ten in that account’s tweets. Table 2 summarizes the usage of the most popular sources.
Overall Use is the percentage of tweets we examined that used the given source. Au-
tomation Rate is the proportion of those tweets belonging to accounts that we identiﬁed
as automated. The next two columns reﬂect what proportion of automated accounts
used the given source, and of those, how many used only that source (“Exclusivity”).
The ﬁnal two columns summarize the same information for non-automated accounts.
Empty table entries reﬂect that the given entry corresponded to marginal activity (not
in the top ten sources for either bots or organic activity, respectively).
We see sharp differences in usage patterns depending on the sources employed. Ac-
tivity from Twitterfeed, REST API, and Hootsuite is very often automated, while other
sources exhibited automation rates far below the overall average rate of 16%. Indeed,
many of the services favored by organic users (e.g., UberTwitter [4], TweetDeck [3],
and Echofon [14]) do not offer any scheduling features. This suggests that consider-
ation of publishing source might prove beneﬁcial for identifying unwanted/malicious
Twitter activity. However, just about all of the top sources are also used organically, so
we cannot simply ﬁlter by source without considering other factors.
Based on these ﬁndings, a possible way to improve our testing would be to examine
the publishing times of each of an account’s sources separately. Doing so might readily
identify both hybrid accounts and hijacked accounts for which an attacker usurps use
of what is otherwise a legitimate, organic account.
6 Summary
We have presented a method for detecting instances of automated Twitter accounts us-
ing only the publicly available timestamp associated with each of an account’s tweets.
We ﬁnd that automated accounts exhibit distinct timing patterns that we can not only
observe visually, but also detect in a mechanized fashion using Pearson’s χ2 test.
Testing 19,436 accounts from the public timeline, we ﬁnd 16% exhibit highly auto-
mated behavior, and that 12% of automated accounts spoof their tweet source as ”web,”
apparently to appear organic. (Note that these at best reﬂect evasive postings, because
legitimate automation would presumably use the API rather than a web browser.) We
Detecting and Analyzing Automated Activity on Twitter
111
also ﬁnd that veriﬁed accounts, most-followed accounts, and followers of the most-
followed account all have lower automation rates than the public timeline (6.9%, 12%,
and 4.2%, respectively). Trending topic search results were found to have a lower rate
as well, with 4.7% automation. We also ﬁnd that keywords more associated with spam
generally have higher automation rates than other keywords. We also examined the
apparent source of tweets, ﬁnding that automated sources utilize services that provide
automation and scheduling, while organic users often use Twitter’s web interface or
other non-automated services.
A practical application of our methodology could be to use it in conjunction with
existing spam prevention measures such as community ﬂagging of inappropriate or
abusive accounts. The ability to quickly assess that an account operates in an automated
fashion would allow operators to expedite paying attention to such complaints, allowing
them to more quickly and effectively combat cases of serious spam and other abuse.
References
1. Dr. Phil (DrPhil) on Twitter (2010), http://twitter.com/DrPhil
2. OAuth FAQ 2010, http://apiwiki.twitter.com/OAuth−FAQ
3. TweetDeck (2010), http://www.tweetdeck.com/
4. UberTwitter (2010), http://www.ubertwitter.com/
5. Chowdhury, A.: State of Twitter Spam (2010),
http://blog.twitter.com/2010/03/state−of−twitter−spam.html
6. D’Agostino, R.B., Stephens, M.A. (eds.): Goodness-of-Fit Techniques. Marcel Dekker Inc.,
New York (1986)
7. Grier, C., Thomas, K., Paxson, V., Zhang, M.: @spam: The Underground on 140 Characters
or Less. In: Proc. ACM CCS (2010)
8. Harvey, D.: Trust And Safety (2009),
http://blog.twitter.com/2010/03/trust−and−safety.html
9. Huberman, B.A., Romero, D.M., Wu, F.: Social networks that matter: Twitter under the mi-
croscope. Technical report, Social Coputing Laboratory, HP Labs (2008)
10. Java, A., Song, X., Finin, T., Tseng, B.: Why We Twitter: An Analysis of a Microblogging
Community. In: Zhang, H., Spiliopoulou, M., Mobasher, B., Giles, C.L., McCallum, A.,
Nasraoui, O., Srivastava, J., Yen, J. (eds.) WebKDD 2007. LNCS, vol. 5439, pp. 118–138.
Springer, Heidelberg (2009)
11. Krishnamurthy, B., Gill, P., Arlitt, M.: A few chirps about Twitter. In: Proc. ACM SIGCOMM
Workshop on Online Social Networks (2008)
12. Media, I.: HootSuite (2010), http://hootsuite.com/
13. Miller, C.: Twitter Makes Itself More Useful (2010),
http://bits.blogs.nytimes.com/2010/04/14/
twitter−makes−itself−more−useful/
14. naan studio. Echofon (2010), http://www.echofon.com/
15. Sysomos. Inside Twitter: An In-Depth Look at the 5% of Most Active Users (2009),
http://sysomos.com/insidetwitter/mostactiveusers
16. TwitterCounter.com. The 1000 most popular Twitter users (2010),
http://twittercounter.com/pages/100/
17. Zetter, K.: Trick or Tweet? Malware Abundant in Twitter URLs (2009),
http://www.wired.com/threatlevel/2009/10/twitter_malware/