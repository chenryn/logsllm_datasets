# 检测和分析Twitter上的自动化活动

## 摘要
本文介绍了一种基于公开时间戳数据来检测Twitter上自动化账户的方法。通过使用皮尔逊卡方检验（Pearson's χ² test），我们发现自动化账户表现出独特的发布时间模式，这些模式不仅可以通过可视化观察到，也可以通过机械化手段进行检测。

## 数据集与方法
### 公共时间线
Twitter的公共时间线提供了每分钟数千条推文的样本，因此可以用来估计Twitter整体上的自动化程度。表1中的“公共时间线”行反映了2010年4月两天内的样本。在检查的19,436个账户中，我们能够对其中的18,147个账户使用χ²方法进行测试。结果表明，有16%的账户发布的推文表现出明显的自动化特征。

一项2009年8月的研究分析了1150万个账户，将每天发布超过150条更新的账户分类为机器人 [15]。该报告得出结论，至少24%的推文是由自动化机器人生成的。大约在同一时期，Twitter开始专注于减少服务中的垃圾信息，并于2010年3月声称垃圾推文的比例已降至1%以下 [5]。为了验证这些说法，我们还对公共时间线进行了单独分析（采用不同的、规模较小的数据集），并按推文而非账户进行加权。我们发现，14%的公共推文来自自动化来源，这表明Twitter确实减少了服务中的不必要自动化（如果[15]的方法与我们的准确性相当）。然而，除非这些自动化推文中的绝大多数不是垃圾信息，否则我们的结果也表明垃圾信息问题仍远未解决。

### 验证用户
验证用户的账户通常由名人和知名公司拥有（Twitter会手动批准这些账户），这使得这些账户不太可能表现出强烈的自动化行为。一个高度自动化的账户可能会给粉丝和客户留下不良印象，并且很难获得Twitter的批准。表1中的“验证用户”行显示了我们对这些账户的分析结果。我们发现，只有6.9%的验证用户未能通过我们的测试——验证用户中的自动化程度确实低于普通Twitter用户群体。未能通过测试的验证用户包括：(1) 提醒粉丝参加演唱会和电视节目的流行乐队；(2) 每天提醒粉丝观看节目的电视节目；(3) 发布新闻文章链接的政治人物和政党；(4) 发布组织链接的记者；(5) 分享全球问题链接的非营利组织；(6) 向公众发布新闻和警报的政府机构。因此，验证用户未能通过测试的常见原因是他们以自动化方式分发新闻、分享链接或向关注者发送提醒。

### 最受关注的用户
尽管Twitter没有公布最受关注用户的列表，但某些第三方网站会提供这样的列表。我们使用TwitterCounter [16]提供的列表分析了Twitter上最受关注的1,000个账户。我们发现，可测试的账户中有12%未能通过我们的χ²测试（见表1中的“最受关注（全部）”行）。只有6.3%的验证用户未能通过测试，略低于所有验证Twitter账户中的6.9%。在剩余的600个未验证账户中，显著更多（16%）的账户可能是自动化的。手动检查未通过测试的96个未验证账户，发现许多是新闻网站、博客和电视节目，它们使用Twitter向关注者广播新内容。

### 热门话题
Twitter会不断更新当前最热门的10个词或短语，为用户提供实时了解Twitter社区讨论的话题。由于许多用户通过阅读包含特定关键词的最新推文来关注热门话题，自动化账户似乎会针对这些热门话题关键词。为了测试热门话题中的自动化情况，我们每分钟搜索一次第一个热门话题，并测试相关推文背后的账户。如表1所示，我们发现只有4.7%的参与热门话题讨论的账户表现出强烈的自动化行为——明显低于公共时间线中的16%自动化率。

这种较低的自动化率可能表明Twitter在防止自动化推文污染热门话题讨论方面非常谨慎，因为回应热门话题的推文经常被成员和访客查看。或者，也许在搜索热门话题时，人类用户的比例比公共时间线更高，或者垃圾邮件发送者尚未广泛采用这种策略。

### 关键词搜索结果
我们使用Twitter Search API评估了24个我们认为可能导致不同程度自动化的关键词背后的账户。（我们的目标是获得自动化与非自动化主题的定性感受，而不是代表性的评估。）按照测试账户中自动化比例从高到低排序，这些关键词依次为：抵押贷款 (48%)、工作、保险、新闻、折扣、免费、金钱 (31%)、点击、性、扑克、摄影 (24%)、视频、下载、机器人、视频、伟哥 (17.5%)、色情、学校、电视、比伯、耶稣 (8.3%)、快乐、无聊、上帝 (5.0%)。

大多数测试的关键词的自动化率高于全球平均16%的自动化率，特别是与垃圾信息常见的关键词（如“折扣”、“免费”、“性”、“扑克”和“下载”）。同样，自动化率较低的关键词通常反映的是与垃圾信息无关的术语（如“耶稣”、“快乐”、“无聊”、“上帝”）。令人惊讶的是，“摄影”的自动化率高于“伟哥”。然而，手动搜索这些关键词确实揭示了大量的自动化链接指向摄影相关的文章和网站，而“伟哥”则经常出现在轻松的消息或笑话中，这些消息通常是有机发布的。

更全面的研究可能会直接分析自动化/有机账户更新中出现的词汇频率。我们将此留作未来的工作。

### 推文来源
对于每个测试的账户，我们还分析了其推文中最常见的来源。表2总结了最常用来源的使用情况。“总体使用”是指我们检查的推文中使用给定来源的百分比。“自动化率”是这些推文中属于我们识别为自动化的账户的比例。接下来的两列反映了自动化账户使用给定来源的比例，以及其中有多少只使用该来源（“专一性”）。最后两列总结了相同的信息，但针对非自动化账户。空白表格条目表示相应的活动是边缘性的（不在自动化或有机活动的前十大来源之列）。

我们看到，根据所使用的来源，使用模式存在显著差异。来自Twitterfeed、REST API和Hootsuite的活动非常频繁地是自动化的，而其他来源的自动化率远低于16%的总体平均水平。实际上，许多有机用户偏好的服务（例如UberTwitter [4]、TweetDeck [3] 和Echofon [14]）并不提供任何调度功能。这表明考虑发布来源可能有助于识别不需要的/恶意的Twitter活动。然而，几乎所有顶级来源也都被有机使用，因此我们不能简单地按来源过滤而不考虑其他因素。

基于这些发现，改进测试的一种可能方法是分别检查每个账户来源的发布时间。这样做可以轻易地识别混合账户和被劫持的账户，在这些账户中攻击者接管了一个原本合法、有机的账户。

## 总结
我们提出了一种仅使用公开可用的时间戳来检测Twitter上自动化账户实例的方法。我们发现，自动化账户表现出独特的时间模式，这些模式不仅可以直观观察到，还可以通过皮尔逊卡方检验进行机械化检测。通过对公共时间线上的19,436个账户进行测试，我们发现16%的账户表现出高度自动化行为，并且12%的自动化账户将其推文来源伪造为“Web”，显然为了显得有机。（请注意，这些最多只能反映规避性帖子，因为合法的自动化应该会使用API而不是网络浏览器。）我们还发现，验证用户、最受关注的用户及其追随者的自动化率均低于公共时间线（分别为6.9%、12%和4.2%）。热门话题搜索结果的自动化率也较低，为4.7%。我们还发现，与垃圾信息关联度较高的关键词通常具有更高的自动化率。我们还检查了推文的来源，发现自动化来源使用了提供自动化和调度的服务，而有机用户通常使用Twitter的网页界面或其他非自动化服务。

我们的方法的一个实际应用可能是与现有的垃圾信息预防措施（如社区标记不当或滥用账户）结合使用。快速评估一个账户是否以自动化方式运行的能力可以使运营商更快地处理此类投诉，从而更迅速有效地打击严重的垃圾信息和其他滥用行为。

## 参考文献
1. Dr. Phil (DrPhil) on Twitter (2010), <http://twitter.com/DrPhil>
2. OAuth FAQ 2010, <http://apiwiki.twitter.com/OAuth−FAQ>
3. TweetDeck (2010), <http://www.tweetdeck.com/>
4. UberTwitter (2010), <http://www.ubertwitter.com/>
5. Chowdhury, A.: State of Twitter Spam (2010), <http://blog.twitter.com/2010/03/state−of−twitter−spam.html>
6. D’Agostino, R.B., Stephens, M.A. (eds.): Goodness-of-Fit Techniques. Marcel Dekker Inc., New York (1986)
7. Grier, C., Thomas, K., Paxson, V., Zhang, M.: @spam: The Underground on 140 Characters or Less. In: Proc. ACM CCS (2010)
8. Harvey, D.: Trust And Safety (2009), <http://blog.twitter.com/2010/03/trust−and−safety.html>
9. Huberman, B.A., Romero, D.M., Wu, F.: Social networks that matter: Twitter under the microscope. Technical report, Social Coputing Laboratory, HP Labs (2008)
10. Java, A., Song, X., Finin, T., Tseng, B.: Why We Twitter: An Analysis of a Microblogging Community. In: Zhang, H., Spiliopoulou, M., Mobasher, B., Giles, C.L., McCallum, A., Nasraoui, O., Srivastava, J., Yen, J. (eds.) WebKDD 2007. LNCS, vol. 5439, pp. 118–138. Springer, Heidelberg (2009)
11. Krishnamurthy, B., Gill, P., Arlitt, M.: A few chirps about Twitter. In: Proc. ACM SIGCOMM Workshop on Online Social Networks (2008)
12. Media, I.: HootSuite (2010), <http://hootsuite.com/>
13. Miller, C.: Twitter Makes Itself More Useful (2010), <http://bits.blogs.nytimes.com/2010/04/14/twitter−makes−itself−more−useful/>
14. naan studio. Echofon (2010), <http://www.echofon.com/>
15. Sysomos. Inside Twitter: An In-Depth Look at the 5% of Most Active Users (2009), <http://sysomos.com/insidetwitter/mostactiveusers>
16. TwitterCounter.com. The 1000 most popular Twitter users (2010), <http://twittercounter.com/pages/100/>
17. Zetter, K.: Trick or Tweet? Malware Abundant in Twitter URLs (2009), <http://www.wired.com/threatlevel/2009/10/twitter_malware/>