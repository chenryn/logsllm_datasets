geometry for each user and used two 0.5% percentiles as the 
legitimate boundaries, which is roughly equivalent to 1% false 
rejection rate (rejection rate for legitimate samples). By using 
all  samples  from  the  other  143  subjects  as  the  illegitimate 
samples,  we  achieved  an  average  false  acceptance  rate 
(acceptance rate for illegitimate samples) of 1.08% for each of 
the 144 subjects.  
This result shows that the 12 real features of users’ hand 
geometry exhibit good discernibility to authenticate users. 
2)  Correlation  Analysis  between  Features  of  Hand 
Geometry and TFST Gestures: The 12 physiological features 
of TFST gestures are estimates of the 12 real features of hand 
geometry. However, the correspondence between two sets of 
features  are  sometimes  affected  by  external  factors.  For 
example, small variances in bending and closeness of fingers, 
and  angle  of  touching  may  lead  to  changes  in  the  relative 
positions  of  touching  points  in  TFST  operations,  which  in 
turn  leads  to  changes  of  the  12  physiological  features 
calculated  in  TFST  gestures.  This  induces  errors  in  hand 
geometry  estimation  using  multi-touch  traces  of  TFST 
gestures. 
To  explore  how  much  impact  the  small  behavioral 
variances have on values of physiological features in TFST 
gestures,  we  analyze  the  correlation  between  physiological 
features  in  TFST  and  corresponding  real  features  of  hand 
geometry. 
We  calculated  average  values  of  12  features  of  hand 
geometry for each of 144 subjects from their hand image data. 
Then we used recorded multi-touch traces of 4-finger TFST 
gestures from the 144 subjects to calculate average values of 
12 physiological features of TFST gestures for each subject. 
The  Pearson  Correlation  Coefficients  [22]  between  two 
sets of 12 features for the 144 subjects are shown in Table I. 
We have 144 independent subjects; thus we have 142 degrees 
of freedom (dof). With this dof, if the coefficient is over than 
0.16, the two features are regarded as significantly correlated 
at the significant level 0.05. 
The Pearson Correlation Coefficients of the 12 features are 
all  larger  than  0.16,  which  indicates  there  are  very  strong 
correlations  between  the  two  sets  of  features.  This  may 
suggest that although there exists small behavioral variances, 
the  connection  between  features  in  TFST  gestures  and  real 
features of hand geometry is clear and strong. This provides a 
basis for using TFST gestures to authenticate users. 
B.  Feature Selection 
While  physiological 
features  provide  a  basis 
for 
362
authentication using TFST gesture, behavioral features may 
complement  the  decrease  in  discernibility  of  physiological 
features due to measurement errors resulting from behavioral 
variances.  Via  the  fusion  of  physiological  and  behavioral 
features, we may achieve better performance than only using 
each individual feature set. In this section, we employ feature 
selection  techniques  to  search  for  the  best  combination  of 
physiological and behavioral features for authentication. 
respectively, and can be computed from the data of a single 
Fisher  Score  [23,  24]  is  an  effective  technique  to  find 
discriminant features. The main idea is attempting to find a 
subset of features which maximizes the between class scatter 
and  minimizes  the  within  class  scatter  in  the  data  space 
spanned  by  the  selected  features.  A  simple  form  of  Fisher 
Score is given by, 
(cid:1832)(cid:1861)(cid:1871)(cid:1860)(cid:1857)(cid:1870)(cid:4666)(cid:1863)(cid:4667)(cid:3404)(cid:1845)(cid:4634)(cid:3029)(cid:3038)(cid:1845)(cid:4634)(cid:3047)(cid:3038)(cid:3) 
where (cid:1845)(cid:4634)(cid:3029)(cid:3038) and (cid:1845)(cid:4634)(cid:3047)(cid:3038) are  the  k-th diagonal  element  of (cid:1845)(cid:4634)(cid:3029) and (cid:1845)(cid:4634)(cid:3047) 
feature. (cid:1845)(cid:4634)(cid:3029) is the “between class scatter matrix” and (cid:1845)(cid:4634)(cid:3047) is the 
(cid:1845)(cid:4634)(cid:3029)(cid:3404)(cid:963)
(cid:1842)(cid:3038)(cid:4666)(cid:2020)(cid:3556)(cid:3038)(cid:3398)(cid:2020)(cid:3556)(cid:4667)(cid:4666)(cid:2020)(cid:3556)(cid:3038)(cid:3398)(cid:2020)(cid:3556)(cid:4667)(cid:3021)
(cid:3030)(cid:3038)(cid:2880)(cid:2869)
(cid:1845)(cid:4634)(cid:3047)(cid:3404)(cid:963)
(cid:3030)(cid:3038)(cid:2880)(cid:2869) (cid:963)
(cid:4666)(cid:1876)(cid:3036)(cid:3038)(cid:3398)(cid:2020)(cid:3556)(cid:3038)(cid:4667)(cid:4666)(cid:1876)(cid:3036)(cid:3038)(cid:3398)(cid:2020)(cid:3556)(cid:3038)(cid:4667)(cid:3021). 
(cid:1842)(cid:3038)
(cid:3051)(cid:3284)(cid:3286)(cid:1488)(cid:3030)(cid:3286)
where (cid:2020)(cid:3556)(cid:3038) and (cid:1866)(cid:3038) are the mean vector and size of the k-th class 
respectively in the reduced data space, (cid:2020)(cid:3556) is the overall mean 
vector, (cid:1855)(cid:3038)  is  the  i-th  class,  and (cid:1842)(cid:3038)  refers  to  the  priori 
“within classes scatter matrix”. The definition of the scatter 
matrices are: 
(cid:2869)(cid:3041)(cid:3286)
, 
probability of class i.  
Figure 4 presents the Fisher Score of all features for a 4-
finger  gesture,  including  the  physiological  features  and  the 
behavioral ones. In general, the physiological features have 
larger Fisher Scores than the behavioral ones, which implies 
the discriminability and stability of physiological features are 
better. 
  We use a Fisher Score of 0.5 as a threshold to select better 
features, and list the selected features in Table II. All of the 
physiological features are selected and some of the behavioral 
features are selected. Finally, we get 36 selected features; 12 
are physiological features and 24 are behavioral features. 
V.  ONE-CLASS CLASSIFIERS 
User authentication is a two-class (legitimate user versus 
impostors)  classification  problem  from  the  perspective  of 
pattern-classification.  We  only  have  training  data  from 
legitimate  users  so  we  build  a  model  based  only  on  the 
legitimate user’s data samples, and use that model to detect 
impostors.  This  type  of  problem  is  known  as  one-class 
classification or anomaly detection. 
A.  K-Nearest Neighbor 
K-Nearest  Neighbor  classifier  models  a  user’s  profile 
based on the assumption that new samples from the user will 
be similar to the samples in the training data. In the training 
phase, the classifier computes the Manhattan distance matrix 
between  every  pair  of  training  samples,  and  determines  a 
classification threshold based on the distance matrix. In the 
testing  phase,  the  classifier  calculates  Manhattan  distance 
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:28:02 UTC from IEEE Xplore.  Restrictions apply. 
TABLE III. CONTINGENCY TABLE FOR MCNEMAR’S TEST
# of samples misclassified by 
# of samples misclassified by CA 
n00: 
CA and CB 
n10: 
n01: 
n11: 
but not by CB 
# of samples misclassified by 
# of samples misclassified by 
CB but not by CA 
neither CA and CB 
As  we  have  161  subjects  in  our  evaluation  dataset,  we 
designated one of our subjects as the legitimate user, and the 
rest (160 subjects) as impostors. We trained the classifier and 
tested  its  performance  to  recognize  the  legitimate  user  and 
impostors as follows: 
•  We randomly selected a portion of samples from the 
legitimate  users, and  with  these  samples,  we  trained 
the classifier to build a profile of the legitimate user. 
•  We  tested  the  performance  of  the  classifier  to 
authenticate  the  legitimate  user  with  the  remaining 
samples from the legitimate user. 
•  We tested the performance of the classifier to detect 
impostors with all samples from the 160 impostors.  
This process was then repeated, designating each of the 
subjects as the legitimate user in turn. In the training phase, 
10-fold  cross-validation  [28]  was  employed  to  search  for 
reasonable  parameters  of  the  classifiers.  Since  we  used  a 
random sampling method to divide the data into training and 
testing sets, and we wanted to account for the effect of this 
randomness,  we  repeated  the  procedure  50  times  for  each 
legitimate  user,  each  time  with  independently  selected 
samples from the entire dataset. 
B.  Evaluation of Classifier Performance 
We  employ  the  false-acceptance  rate  (FAR)  and  false-
rejection rate (FRR) as our main evaluation criteria. The FAR 
is defined as the ratio between the number of falsely accepted 
illegitimate samples and the number of all illegitimate testing 
samples; the FRR is defined as the ratio between the number 
of falsely rejected legitimate samples and the number of all 
legitimate  testing  samples.  Via  varying  the  threshold  on 
classification score, we calculate the corresponding FRR and 
FAR pairs, and obtained a performance curve known as the 
receiver  operating  characteristic  (ROC)  curve.  We  also 
calculate  the  equal-error  rate  (EER)  from  the  ROC  curve 
where FAR equals FRR. 
C.  McNemar’s Test 
To  compare  the  performance  of  our  two  different 
classifiers, we employed McNemar’s test [29], a frequently 
used  test  for binary  matched-pair data.  First,  we  divide  our 
available data set S into a training set R and a testing set T. We 
train both of our two classification algorithms on the training 
set R and obtain two classifiers CA and CB. Then we test these 
classifiers  on  the  testing  set T  and  record  the  classification 
results in a contingency table (Table III). 
Under the null hypothesis, the two algorithms should have 
the same error rate, which means n01= n10. So the following 
statistic  is  distributed  as  (cid:70)(cid:2870)  with  1  degree  of  freedom;  it 
fact  that  the  statistic  is  discrete  while  the (cid:70)(cid:2870) distribution  is 
incorporates a continuity correction term to account for the 
Fig. 4. The Fisher Score of the physiological and behavioral features. 
Features # from 1-12 are physiological; 13-64 are behavioral. 
TABLE II. SELECTED FEATURES USING FISHER SCORE 
Category 
Physiological 
Behavioral 
Feature Name 
Point Distance 
Finger Width 
Length Difference 
Length 
Time 
Velocity 
Tool 
Touch 
Selected # 
6 
3 
3 
8 
4 
4 
4 
4 
from the new sample to each of the samples in the training 
data. The average distance calculated between the new sample 
to  the  nearest  k  samples  in  the  training  data  is  used  as  the 
classification  score.  If  the  classification  score  is  below  the 
determined classification threshold, we regard the sample as a 
legitimate one.  
B.  Support Vector Machine 
We also implemented a one-class Support Vector Machine 
(SVM)  classifier.  One-class  SVMs  have  been  successfully 
applied to a number of classification problems, such as mouse 
dynamics, signature verification and keystroke authentication 
[25-27].  SVM  generalizes  the  ideas  of  finding  an  optimal 
hyper-plane  in  a  high-dimensional  space  to  perform  a 
classification. In the training phase, SVM builds models based 
on the training samples of the legitimate user. In the testing 
phase, the testing samples are projected onto the same high-
dimensional space, and the distances between the samples and 
the hyper-plane are computed as the classification scores. If 
the classification  score  is over the  threshold,  we  regard the 
sample as a legitimate one. 
VI.  EVALUATION METHODOLOGY 
In this section, we discuss the evaluation methodology for 
our  proposed  multi-touch  authentication.  The  evaluation  is 
performed on the dataset described in Section III. We present 
the training and testing procedure for one-class classifiers and 
show  the  criterion  to  evaluate  the  performance  of  our 
approach. 
A.  Training and Testing Procedure 
363
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:28:02 UTC from IEEE Xplore.  Restrictions apply. 
)
(
%
R
E
E
Fig. 5. EER curves for 9 types of gestures at varying training set sizes 
continuous: 
(cid:3041)(cid:3116)(cid:3117)(cid:2878)(cid:3041)(cid:3117)(cid:3116) (cid:817)(cid:70)(cid:2870)(cid:4666)(cid:883)(cid:4667), 
(cid:4666)(cid:513)(cid:3041)(cid:3116)(cid:3117)(cid:2879)(cid:3041)(cid:3117)(cid:3116)(cid:513)(cid:2879)(cid:2869)(cid:4667)(cid:3118)
If the null hypothesis is correct, then the possibility that 
this quantity is greater than 3.84 is less than 0.05. So we may 
reject the null hypothesis in favor of the hypothesis that the 
two algorithms have different performance when trained on 
the particular training set R and regard the classifier with low 
error rate as the better one. 
VII. RELIABILITY EVALUATION 
This  section  presents  an  evaluation  of  the  reliability  of 
TFST  gesture  authentication.  We  systematically  investigate 
the accuracy of verifying the legitimacy of a user with respect 
to different TFST gestures, feature sets, classifiers and sizes 
of training sets. We also examined the impact of behavioral 
variability  utilizing  the  long-term  behavioral  data  in  our 
dataset to see whether the performance will deteriorate with 
the elapse of time. 
A.  Comparison of TFST Gestures 
In 
this 
compare 
experiment,  we 
authentication 
performance  when  subjects  are  requested 
to  perform 
horizontal, vertical and L swipes using 2-finger, 3-finger and 
4-finger TFST gestures respectively.  
As  described  in  Section  III,  we  have  52,  39  and  26 
behavioral features, and 12, 7 and 3 physiological features, for 
a 4-finger, 3-finger and 2-finger TFST gesture respectively. 
For L swipe TFST gestures, we separate the trace into two 
sub-gestures:  one  vertical  TFST  swipe  and  one  horizontal 
TFST swipe. So L swipe TFST gestures have twice as many 
features as other TFST gestures. The classifying features are 
selected from combined physiological and behavioral features 
of TFST gestures with the Fisher Score over 0.5. The size of 
the training set ranges from 5 to 100. The classifier is One-
Class KNN with k set to be 3. Figure 5 shows the average 
EERs for the nine gestures. 
Figure  5  shows  that  TFST  gestures  with  more  fingers 
achieve better results. However, the simplest 2-finger gesture 
can achieve an EER of 7.17% with enough training samples. 
Trading off security and convenience, 3-finger swipes can be 
used  as  a promising  authentication  method  on  small  screen 
smartphones  with  EERs  less  than  5%  assuming  enough 
training samples.  
Among all the gestures, the 4-finger L swipe achieves the 
best  performance.  We  speculate  that  the  4-finger  swipe 
contains more biometric information of hand geometry, and 
swipes in both the horizontal and vertical directions make the 
estimates of features of hand geometry more accurate. These 
lead  to  the  better  performance.  We  will  use  the  4-finger  L 
swipe  as  the  evaluation  TFST  gesture  in  the  following 
experiments. 
Figure 5 also exhibits how the authentication performance 
changes  with  size  of  training  data,  which  is  an  important 
perspective of a behavioral authentication technique and will 