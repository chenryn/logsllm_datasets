8.  返回结构化数据structured event
4.1.5 常用方式
针对常见的日志数据，需要采用内置相应的日志解析规则，能够自动识别和解析常见的日志格式，如Linux、Apache、JSON等，对于非常用的日志格式，通过个性化配置日志格式解析规则，抽取自定义字段达到数据的范式化处理。
日志解析的主要作用是抽取重要的字段，则通过字段名称可以进行统计与分析，根据机器数据格式提供常见自定义解析方法：
**字段抽取类**
-   正则解析： 通过配置正则解析出匹配的字段,
    > 支持命名分组、多行正则、grok语法
正则表达式，又称规则表达式（Regular
Expression，常简写为regex、regexp或RE），是计算机科学的一个概念。正则表达式描述了一种字符串匹配的模式（pattern），可以用来检查某一个字符串是否含有某种子串，并将匹配的子串替换或者抽取出来。许多程序设计语言都支持正则表达式。
在日志解析过程中，正则表达式可用于提取符合某种定义模式的字段，尤其是在了解日志相应的语法结构后。
例如这样一条日志：
2014-05-14 23:24:47 15752 \[Note\] InnoDB: 128 rollback segment(s) are
active
希望提取出以下字段：timestamp、pid、loglevel和message，则可以配置如下的表达式：
(?\\\S+\\S+)(?\\\S+)\\\[(?\\\S+\\\](?\.\*)
其中，\\S表示匹配非空格字符，\\S+表示匹配连续的非空格字符，(?\value)表示提取名字为key的字段，其值为value，会解析出如下字段：
-   timestamp：2014-05-14 23:24:47
-   pid：15752
-   loglevel：Note
-   message：InnoDB: 128 rollback segment(s) are active
```{=html}
```
-   KeyValue解析 适用于日志中包含字段名，分隔符比较明确的日志,
    > 配置kv对分隔符和k间的分隔符来抽取字段v之
有的时候，日志会明确给出字段名称和字段值，以key-value的形式展现，能够让人更明确地读懂字段的含义。例如，在有的日志中，192.168.1.1作为字段出现，而key-value形式的日志，可能会以ip=192.168.1.1形式展现该字段。如以下日志示例：
field=tag&filters=&order=desc&page=1&query=\*&size=50&sourcegroup=all&sourcegroupCn=%E6%89%80%E6%9C%89%E6%97%A5%E5%BF%97&time_range=-2d,now&type=fields
这是一个按照\"&\"和\"＝\"来分割的key-value日志。使用字段分隔符为&解析即可，得到key=value样式。
-   KeyValue正则解析 适用于分隔符不确定, kv对不连续的日志, 通过配置key,
    value, 分隔符的正则来抽取字段，
-   Json解析 适用于Json日志格式,
    抽取出来的字段结构和Json中定义的结构一致
-   XML解析 适用于Xml日志解析，抽取出来的字段结构和Xml中定义的结构一致
-   CSV解析 适用于列顺序固定，分隔符固定的日志,
    配置分隔符和列名来解析字段，
-   结构体解析 适用于按固定字节长度写入的日志, 配置字节格式的解析
**字段转换类**
-   UserAgent解析： 从UserAgent抽取出操作系统，浏览器，设备信息
-   geo解析：
    从IP地址中抽取出国家、省、市、互联网服务提供商、经度、经度、纬度信息
-   手机号码解析：
    从手机号码中抽取出国家、省、市、互联网服务提供商、经度、纬度信息
-   固定号码解析： 从手机号码中抽取出国家、省、市、经度、纬度信息
-   自定义字典： 查自定义字典表，从一个字段扩展到多个字段
-   syslog_prio解析： 从syslog的日志抽取出来设备、日志级别
**字段操作类**
-   格式化处理： 用于把多个字段按指定格式, 产生新的字段
-   删除字段： 用于删除不用的字段
-   重命名字段： 用于重命名字段
-   内容替换： 用于替换字段的内容
-   hex转换： 用于把16进制度的hex dump转换成可读度字符格式
-   URL转换： 用于把url转码的字段转换到转码之前的格式
-   ip格式转换： 用于把数值类型的ipv4地址转换成字符串ip地址
-   数值字段转换： 用于把字符串类型的字段转换成数值类型
其他
-   时间戳解析： 配置时间戳抽取格式,
    来抽取日志的时间戳，抽取出来时间戳决定日志的存储位置和搜索时间范围
![截屏2020-06-03%20下午9.43.45.png](media/image8.png){width="5.763888888888889in"
height="2.5972222222222223in"}
图 5 智能划选解析页面
系统提供智能划选的解析规则生成方式，鼠标划过需要解析的字段内容即可自动生成解析正则，配置好规则后，所有的日志会自动按照能匹配到的格式自动匹配，无需人工干预，一键完成字段解析提取。
该方法可以支持常见主流设备的日志自动化解析提取，包括网络、安全、操作系统、中间件、数据库、业务系统、容器等类型，将接收到的各种数据快速按照各种需要的格式进行字段提取、规范化处理、字段清洗过滤等，为智能运维分析打好坚实的数据基础，充分缩短智能运维分析需要的准备工作时间。
## 4.2 跨系统故障智能关联定位的方法
![](media/image9.jpeg){width="5.447222222222222in"
height="3.926388888888889in"}
电力信息系统之间的交互访问涉及到众多网络设备、中间件、数据库、主机的数据，设备节点数量大且分散，出现故障后需要排查时只能各个设备单独查看，不仅效率低下，而且无法收集业务全部链条数据从而快速定位故障环节，提前掌握瓶颈节点，更无法实现运维数据间的关联分析。
各个应用日志之间无法真正定位到是哪个业务系统出现的故障导致最终的业务异常，需要有一套跨系统故障智能关联定位的方法来实现故障的快速定位。本次研究提出两种跨系统故障智能关联定位方法，分别是基于系统间业务逻辑关联分析的方法，通过日志比对实现业务间的关联关联，从而通过实际业务流程梳理业务链条，以及基于自然语言处理技术的日志聚类和日志异常定位的方法实现跨系统故障智能关联定位。两种方法主要依赖以下技术：
### 根因分析
根因分析旨在通过对业务架构或系统架构构建知识图谱，根据合并后的异常来源进行异常定位并给出可能的修复方案，在更理想的情况下，甚至可以自主修复。一个精确的系统拓扑层级结构，是根因分析的关键。在人工构建的成本越来越高的情况下，自动构建拓扑图成为了根因分析中较为重要的探索方向。考虑到指标数据是运维系统中最常见的具象方式，拓扑结构的自动构建同样可以依赖指标数据的信息。
1.  #### 相关性分析 
    相关性分析是指标型数据的一个非常重要的应用领域。对指标之间相关性的挖掘可以间接了解到指标之间的潜在关系，甚至可以协助构建出系统的拓扑结构。相关性较高的指标，大概率同属一个集群或一个服务，因此异常模式也会有所关联。可以粗略的认为，当某一个指标发生异常时，与其相关性较高的指标更容易发生异常。
计算度量相关度最直观的方法是去度量处于同一时间范围内的指标数据的距离，距离越小，则相关度越高。这里的距离函数一般选用欧氏距离。
![IMG_256](media/image10.png){width="2.990972222222222in"
height="0.6902777777777778in"}
某一请求的成功率和失败率两个指标数值上是完全相对的，即变化趋势呈负相关，此时单纯使用欧氏距离度量相关度就变得不是特别合理。实际上，大多数相关的指标数据，我们想去挖掘的"相关性"都是线性相关，而不是简单的数值相等。因此，在使用距离函数之前，我们将原始数据归一化为均值为
0，方差为 1
的标准数据，从而消除了数值的影响，只考虑变化趋势的相关程度。统计学中计算相关度的方法------皮尔森系数，
![IMG_256](media/image11.png){width="5.861805555555556in"
height="0.6090277777777777in"}
即等同于归一化后的欧氏距离，取值 -1 到 1
之间。皮尔森系数的绝对值越接近1，数据越相关；当皮尔森系数等于 0
时，数据完全不相关；当皮尔森系数等于 1
时，数据完全正相关；当皮尔森系数等于 -1
时，数据完全负相关。对一组指标数据两两计算皮尔森系数，最终可以得到一个相关度矩阵。
在实际情况中，两个相关的指标数据可能存在延迟，这一重要的因素在上述计算中是被忽略了的。延迟的产生有很多原因，可能是指标所处层级的不同而产生的传输延迟，可能是数据采样产生的延迟，也可能是业务逻辑上的延迟。在大部分的业务系统中，这种延迟并不会特别长，而且考虑到时效性，智能运维系统对延迟的容忍程度也是有限的，所以一般会给定一个延迟范围，在考虑延迟的基础上计算相关性。
一种方案是改进距离的度量方式，DTW（Dynamic Time
Warping，动态时间归整）算法是一种不规整时间序列的距离度量方法，算法会找到最合适的数据点对应关系（而不是只考虑对应时间点上的数据距离），利用动态规划的思想计算距离。这种方案的缺陷是，它依赖于数据间对应关系的不规整，而实际生产中的数据，在消除延迟后，其实大部分是规整的，不符合算法原理的出发点。因此更简单直接的方案是，在延迟容忍范围内，先对数据进行相移，再计算皮尔森系数。这种方法的好处是符合延迟的特性，缺点是会导致计算时间成倍增长。
一个服务通常由多层模块串联组成。当底层的数据库模块出现异常时，会导致服务端模块异常，进而导致前端显示异常。如果有三个监控项分别监控这三个模块的一项关键指标，这些指标由于监控目标不同，运行环境不同，在正常情况下是不存在线性关系的，它们各自遵循自己的正常模式。当底层模块发生异常时，三项指标由于数据传输关系，都会进入异常模式，异常修复时，三项指标又重回正常模式。很明显，这三项指标是存在相关关系的，但是它们无论处于正常还是异常模式，使用上述挖掘相关性的方法，都无法找到其相关关系。唯一可以表现它们相关性的现象，就是它们各自的异常通常同时发生，也同时消失，我们知道，由于传输延迟的存在，这种相关性也会容忍一些"不同时"。
因此，另一种挖掘相关性的方式，就是利用指标中异常发生的模式的相关性，来表征指标的相关性。在单指标异常检测中，存在很多的方式挖掘异常，可以利用这些机器学习算法或者统计方法，挖掘出每条指标的"异常发生模式"，再对这种"异常发生模式"进行距离计算，从而得到指标间的相关性。更有意义的是，考虑到计算的相似度最高时的相移大概率等于指标间的延迟，我们可以借此粗略地推断出相关指标间的拓扑关系，甚至绘制出整个系统的拓扑关系图，为异常的根因定位提供帮助。
无论使用何种方式计算相关性，最终都会得到一组指标的相关度矩阵（若考虑延迟，也会另外得到一个延迟矩阵）。它类似于一个带权重图的邻接矩阵，因此依据它可以轻易地构造出一个关系图来（若考虑延迟矩阵，则可以构造出有向图）。为了使关系更加的简洁清晰，可以选用一些剪枝策略来去掉不重要的边。对于被监控系统来说，这是一个不需要先验知识的，自动学习到的拓扑关系图。在理想情况下，相对于真实的系统拓扑关系图，学习到的图能够提供更深刻的描述，或挖掘到系统设计的优势点和缺陷，两者相互结合，也能够在根因定位中给出更准确合理的结果。我们仍然可以对这种相关性关系做出进一步的分析，例如把相关度矩阵转化为距离矩阵，应用聚类算法对多指标进行聚类，得到的结果依然具有很大的分析价值。比如尝试挖掘聚类得出的簇的特征并转化为有意义的标签，再比如对簇中的指标应用同种异常检测算法，减少训练的消耗。值得注意的是，虽然拓扑图可以提供很多的信息，但是拓扑图构造的准确性决定了信息的真实性。在实践中，运维人员或开发人员应该更加注重相关性挖掘算法的准确度，它是一切效果的根基所在。
从相关矩阵入手，还可以挖掘更多。例如可以把相关性考虑为"距离"，对指标进行聚类。虽然这种距离未必精准，指标的相似性也不仅仅体现在数据的形状上，但是从聚类的结果中仍然可以挖掘到一些有效的信息。为了使效果更好，通常选择基于距离矩阵的算法来做聚类，如
DB-SCAN (Density-Based Spatial Clustering of Applications with
Noise)等。其实更多的时候，聚类可以作为一种信息挖掘的辅助手段。比如，位于相同簇的指标可以使用同一种异常检测算法，减少了复杂的算法匹配过程；在根因定位时可以根据聚类结果缩小搜索范围，使定位更加快速精准；通过计算相关矩阵的特征值、特征向量、迹等属性，更好地了解和描述数据集。诸如此类的应用，都是相关性分析比较有意义的输出。
高复杂度一直是多指标相关性挖掘中无法避免的问题。因为指标间两两计算相关度是必不可少的，所以无论采用何种算法都至少是平方级别的复杂度。当指标数量过大时，每增加一个指标都会带来巨大的消耗。因此，需要采取一些策略来优化计算速度。首先，两两计算相关性的模式显然是符合并行计算条件的，那么制定多机、多进程、多线程分布式计算的策略是要考虑的第一个问题。通常只需要关心那些相关度较高的指标对，而不关心相关度较低的指标对。在计算准确的相关性之前，可以选用一些方式事先进行一个复杂度较低的粗略计算，从而筛选掉一些不必要计算的指标对，再从需要计算的指标对中挑选两两相关的概率较高的指标对放在同一个
batch 里计算。
同时在相关度计算的算法上做优化，比如制定一个阈值，当明确相似度计算结果一定大于该阈值时即停止计算，这对最终分析的影响较小。