title:Network performance monitoring at small time scales
author:Konstantina Papagiannaki and
Rene L. Cruz and
Christophe Diot
Network Performance Monitoring at Small Time Scales
Konstantina Papagiannaki§, Rene Cruz‡, Christophe Diot†
§
Sprint ATL
Burlingame, CA
PI:EMAIL
‡
Electrical and Computer Engineering Department
University of California San Diego, CA
PI:EMAIL
†
Intel Research
Cambridge, UK
PI:EMAIL
ABSTRACT
SNMP statistics are usually collected over intervals of 5 min-
utes and correspond to average activity of IP links and net-
work elements for the duration of the interval. Nevertheless,
reports of traﬃc performance across periods of minutes can
mask out performance degradation due to short-lived events,
such as micro-congestion episodes, that manifest themselves
at smaller time scales.
In this paper we perform a mea-
surement study of packet traces collected inside the Sprint
IP network to identify the time scales over which micro-
congestion episodes occur. We characterize these episodes
with respect to their amplitude, frequency and duration. We
deﬁne a new performance metric that could be easily com-
puted by a router and reported every 5 minutes through
SNMP to shed light into the micro-behavior of the car-
ried traﬃc. We show that the proposed performance metric
is well suited to track the time scales over which micro-
congestion episodes occur, and may be useful for a variety
of network provisioning tasks.
Categories and Subject Descriptors
C.2.3 [Computer-Communication Networks]: Network Op-
erations - Network Monitoring
General Terms
Algorithms, Management, Measurement, Performance, De-
sign
Keywords
Performance Monitoring, Congestion Detection, Internet mea-
surement
1. MOTIVATION
Large-scale IP networks feature hundreds of routers and
thousands of links. Monitoring of the network-wide state
is usually achieved through the use of the Simple Network
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’03, October 27–29, 2003, Miami Beach, Florida, USA.
Copyright 2003 ACM 1-58113-773-7/03/0010 ...$5.00.
Management Protocol (SNMP)[4]. Routers are conﬁgured
to collect measurements, in the form of counters, that they
report to a speciﬁc location at frequent intervals. Those
intervals are typically set to 5 minutes. Speciﬁc reasons that
guide this decision have to do with the size of the network,
i.e. the interval has to be large enough so that it allows the
polling of the entire network during a single interval. On
the other hand, this interval should not be too small so as
to avoid overloading the polled network elements and the
collection station itself.
Once a network operator decides on the time interval at
which network elements are polled, he/she has to decide on
the actual Management Information Base (MIB) values that
each network element will have to report on. Usually these
MIB values are link utilization, packet drops on a per link
basis, the CPU utilization of the router itself, etc.
In or-
der to avoid router overload and limit the amount of SNMP
traﬃc through the network, network operators usually se-
lect a small number of metrics to be polled by the Network
Management Station and base their network provisioning
decisions on those speciﬁc metrics.
Consequently, it is not uncommon for a network operator
to collect link utilization measurements and infer delay per-
formance based on the collected information. In fact each
network provider usually aims for network-wide link utiliza-
tions that do not exceed the “acceptable utilization levels”.
Those levels are speciﬁc to each network provider and are
frequently set around 50%.
If each link in the network is
utilized less than 50% it is capable of carrying the traﬃc
of any equal-capacity link in its neighborhood in case of
failure. Moreover, it has been shown in previous analytical
work that links utilized less than 50% introduce minimal
queueing delays [1].
However, link utilization is typically reported as a 5-minute
average value. Network operators use this 5-minute average
value as a provisioning tool to ensure that delays through
the network are acceptable.
In this work we show that
traﬃc counters collected every 5 minutes mask out micro-
congestion episodes that occur at time scales of milliseconds.
We deﬁne a micro-congestion episode as a period of time
when packets experience increased delays due to increased
volume of traﬃc on a link.
We perform an empirical study of packet traces collected
inside the Sprint Tier-1 IP backbone network to identify the
time scales over which micro-congestion episodes manifest
themselves. We characterize micro-congestion episodes with
respect to their amplitude, frequency and duration. Our ap-
proach relies on the analysis of link utilization at multiple
time scales simultaneously. We show that this type of anal-
ysis can provide insight into the time scales at which conges-
tion occurs, while oﬀering information that cannot be recov-
ered by similar analysis at a single timescale. We propose
a new performance metric that could be reported through
SNMP every 5 minutes and capture network performance
at small time scales. This type of measurements could have
several applications within an operational setting.
The remainder of the paper is structured as follows. In
Section 2 we describe the data analyzed throughout the pa-
per.
In Sections 3 and 4 we present our methodology for
the characterization of micro-congestion episodes with re-
spect to their amplitude, frequency and duration along with
results obtained for OC-3 and OC-12 link measurements.
We validate our approach in Section 5. This work should
be viewed as a ﬁrst step toward the identiﬁcation of micro-
congestion episodes and their impact. Thus, in Section 6 we
discuss our results and describe the work we intend to carry
out in the future. Conclusions are drawn in Section 7.
2. COLLECTED DATA
Complete characterization of micro-congestion episodes
at small time scales needs to capture their amplitude, fre-
quency and duration. To perform this type of operation we
need detailed packet traces with accurate timing informa-
tion. We install optical splitters on selected links inside the
Sprint IP backbone network and capture the ﬁrst 40 bytes
of each packet seen on each unidirectional IP link. Each
record is GPS timestamped. We call the data sets collected
packet traces.
In this work, we use four packet traces collected inside
the network from OC-3 and OC-12 capacity links on August
9th, 2000 and September 5th, 2001. These packet traces are
selected because they correspond to pairs of monitored links
that attach to the same router inside the network. We call
each pair of packet traces a data set for the remainder of
the paper. We identify those packets that are common to
both incoming and outgoing link and call them matches [3].
In Table 1 we provide information about the packet traces
collected and the resulting matched data sets.
1
Set Link
Speed #pkts
793 ·106
in1
OC-3
567 ·106
out1 OC-3
1,3 ·109
in2
OC-12
1,1 ·109
out2 OC-12
2
Avg. Util. #matches
70 Mbps
60 Mbps
150 Mbps
250 Mbps
3 ·106
18 ·106
Table 1: Details of traces
The routers participating in our measurements are usually
characterized as “virtual output queued switches” and de-
lays experienced by packets through them are not due to out-
put queueing alone. Their architecture is brieﬂy described
in [2]. We compute the “single-hop delay” for the matches as
the diﬀerence between the departure and arrival timestamp
of a packet at the router [3]. These delay measurements
completely characterize the delay performance experienced
by packets on the router path between the monitored in-
put and output link. Nevertheless, the output link receives
traﬃc from other input interfaces, and the input link sends
packets to other non-monitored output links.
In previous
work we have established that the collected single-hop delay
measurements approximate a random sample for the delays
experienced by any packet on the monitored output link [2].
Thus, they are representative with respect to the amount of
time packets need to transit the monitored router and get
transmitted from that speciﬁc output link.
3. AMPLITUDE OF AN EPISODE
The total amount of traﬃc ﬂowing on a link computed
over intervals of diﬀerent duration can exhibit great varia-
tions. Traﬃc burstiness is likely to demonstrate itself through
high throughput values at time scales of milliseconds, while
throughput measurements collected over intervals on the or-
der of minutes are likely to be within the provider’s “accept-
able utilization levels”. In this section we look into the ap-
propriate values for the timescale τ , over which throughput
measurements should be collected in order to reveal perfor-
mance degradation due to traﬃc burstiness at small time
scales.
The decision on the appropriate value of τ is not trivial. If
the value of τ is too small, then high throughput values may
relate to the simple transmission of a small number of pack-
ets back to back. For instance consider the following simple
scenario. A TCP connection sends a full window of packets
that arrive at the router’s incoming interface back to back.
In the absence of crosstraﬃc, these packets will appear back
to back at the output link. If the measurement interval con-
tains those TCP packets alone, the measured throughput is
100% but packets have experienced no queueing delay since
they arrived at an equal-speed link and faced no crosstraﬃc.
Consequently, high output throughput values in this case do
not correspond to increased delays through the router.
On the other hand, if the value of τ is too large, it may
have no relevance to the time scale at which queues are
building up inside the router. The maximum time scale
of relevance for the deﬁnition of micro-congestion episodes
should be related to the total amount of buﬀering available
to packets while transiting the router. This latter time scale
is useful when one wants to analyze the loss characteristics of
the network, but it may be too great when one is interested
in bounding the delay through each node. In reality even a
small queue buildup of 1 ms may be considered prohibitive
if it occurs frequently in space and/or time.
3.1 Methodology
We detect the amplitude of a micro-congestion episode
through its impact on the delay experienced by packets
through a single node. For each interval n of duration τ we
collect the delay measurements for the packets that departed
within that interval {D(n)}, and compute link throughput
B as the total amount of traﬃc transmitted in that same
interval. We associate the link throughput value B with the
set of delay measurements D(B) = {D(n)}. We proceed
for the remainder of the trace. If a later interval n(cid:1)
is char-
acterized by the same throughput value B we augment set
)}. At the
D(B) with the new delay measurements {D(n(cid:1)
end of the trace we have associated each link throughput
level (quantized per 1 Mbps) with a delay distribution.
These results describe the delay behavior experienced by
packets for speciﬁc levels of output link utilization. One
could also consider this relationship as the relationship be-
tween the intensity of an output burst and the probability of
increased delay due to crosstraﬃc. If the link utilization is
high and the delays measured are high then measurements
reveal buildup of queues inside the router. If the link utiliza-
tion if high and the delays experienced are small, then mea-
surements simply reveal packets going through the router at
line rate.
3.2 Results
We perform the analysis described above on our two data
sets. We measure link throughput at intervals of duration
τ equal to 1ms, 10 ms, 100 ms, 1 sec and 5 minutes and
investigate the relationship between the delays experienced
by packets while transiting the monitored router and the
output link utilization.
3.2.1 Results for OC-3 links
In our analysis each level of utilization B is accompanied
by a delay distribution. For the results presented in this
section we characterize the obtained distribution using the
minimum, average, 90th and 99th percentile1. All statistics
are computed for the levels of link utilization that feature at
least 100 delay measurements. Our results are summarized
in Fig. 1 and Fig. 2.
)
s
µ
(
y
a
e
D
l
2500
2000
1500
1000
500
0
0
τ=1ms
minimum
average
90%
99%
50
Throughput (Mbps)
100
150
Figure 1: Output link utilization vs. single-hop de-
lay (τ = 1ms, OC-3).
Fig. 1 presents the delay statistics measured for each level
of output link utilization for set1 when τ is equal to 1ms.
Link throughput measured over intervals of 1 ms duration
approaches the link capacity (155 Mbps) and is accompanied
by delays as large as 2 ms through the monitored router. The
minimum delay reported for each level of output link uti-
lization is approximately the same across the entire range of
possible utilizations. This observation indicates that pack-
ets may experience minimal delays during a highly utilized
interval. Nevertheless, there is a signiﬁcant number of pack-
ets that are likely to spend milliseconds of delay through a
single node.
Consequently, measurements of output link utilization at
1 ms intervals are able to reveal the amplitude of micro-
congestion episodes. In Fig. 2 we investigate whether such a
relationship persists with higher values of τ . Fig. 2 presents