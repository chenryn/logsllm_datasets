54. Yakhchi, S., Ghafari, S.M., Beheshti, A.: CNR: cross-network recommendation
embeddinguser’spersonality.In:Hacid,H.,Sheng,Q.Z.,Yoshida,T.,Sarkheyli,A.,
Zhou,R.(eds.)DataQualityandTrustinBigData-5thInternationalWorkshop,
QUAT2018,HeldinConjunctionwithWISE2018,Dubai,UAE,November12–15,
2018,RevisedSelectedPapers.LectureNotesinComputerScience,vol.11235,pp.
62–77. Springer (2018)
55. Yakhchi, S., Ghafari, S.M., Tjortjis, C., Fazeli, M.: Armica-improved: a new app-
roachforassociationrulemining.In:Li,G.,Ge,Y.,Zhang,Z.,Jin,Z.,Blumenstein,
M.(eds.)ConferenceonKSEM,Australia.LectureNotesinComputerScience,vol.
10412, pp. 296–306. Springer (2017)
56. Yao, Y., Tong, H., Yan, X., Xu, F., Lu, J.: Matri: a multi-aspect and transitive
trust inference model. In: Proceedings of the 22nd International Conference on
World Wide Web, pp. 1467–1476 (2013)
57. Yu, Y., Gao, Y., Wang, H., Wang, R.: Joint user knowledge and matrix factoriza-
tion for recommender systems. In: Conference on WISE, China, pp. 77–91 (2016)
58. Zhang,Y.,Chen,H.,Wu,Z.:Asocialnetwork-basedtrustmodelforthesemantic
web. In: ATC, pp. 183–192 (2006)
Am I Rare? an Intelligent Summarization
Approach for Identifying Hidden
Anomalies
B
Samira Ghodratnama1( ), Mehrdad Zakershahrak2,
and Fariborz Sobhanmanesh1
1
Macquarie University, Sydney, Australia
{samira.ghodratnama,fariborz.sobhanmanesh}@mq.edu.au
2
Arizona State University, Arizona, USA
PI:EMAIL
Abstract. Monitoring network traffic data to detect any hidden pat-
terns of anomalies is a challenging and time-consuming task which
requires high computing resources. To this end, an appropriate summa-
rizationtechniqueisofgreatimportance,whereitcanbeasubstitutefor
the original data. However, the summarized data is under the threat of
removing anomalies. Therefore, it is vital to create a summary that can
reflect the same pattern as the original data. Therefore, in this paper,
weproposeanINtelligentSummarizationapproachforIDENTifyinghid-
denanomalies,calledINSIDENT.Theproposedapproachguaranteesto
keep the original data distribution in summarized data. Our approach
is a clustering-based algorithm that dynamically maps original feature
spacetoanewfeaturespacebylocallyweightingfeaturesineachcluster.
Therefore, in new feature space, similar samples are closer, and conse-
quently, outliers are more detectable. Besides, selecting representatives
based on cluster size keeps the same distribution as the original data
in summarized data. INSIDENT can be used both as the preprocess
approach before performing anomaly detection algorithms and anomaly
detection algorithm. The experimental results on benchmark datasets
proveasummaryofthedatacanbeasubstitutefororiginaldatainthe
anomaly detection task.
· · ·
Keywords: Anomaly detection Summarization Network data
·
Clustering Classification
1 Introduction
MonitoringthefastandlargevolumeofInternettrafficdatathatisbeinggener-
ated is paramount since they may have instances of anomalous network traffic,
whichmakesthesystemvulnerable.However,detectinganomalieswhenweface
big data is computationally expensive and still an open challenge. To this end,
summarization is a practical approach that produces a condensed version of the
(cid:2)c SpringerNatureSwitzerlandAG2021
H.Hacidetal.(Eds.):ICSOC2020Workshops,LNCS12632,pp.309–323,2021.
https://doi.org/10.1007/978-3-030-76352-7_31
310 S. Ghodratnama et al.
original data. Therefore, a summary of the network traffic data helps network
managers quickly assess what is happening in the network. For instance, the
summary should still give insight into most visited websites, frequently used
applications, and incoming traffic patterns. In [23] authors defined three sce-
narios in which summarization can help in traffic data, including: Summariz-
ing network traffic can give an overview of what is going on in the network to
the administrator. Summarized network traffic can be used as input to anomaly
detectionalgorithmstoreducethecost.Asummaryofintrusiondetectionalarms
facilitates the administrator’s duty. In all mentioned scenarios, a concise repre-
sentation of the data helps both the administrator and the analysis algorithms.
Different data summarization techniques are designed for other applications
such as transactional data or stream data [1], which can be applied to traffic
data. However, they have some drawbacks to be used for anomaly detection
purposes, including:
– Clustering is the most used approach for summarization, where centers are
considered as the summarized data. The problem is that the centroids may
not be a part of the original data.
– Detectingfrequentitemsetsisanotherapproachwhichonlycapturesfrequent
items in the summaries. Therefore, they ignore or leave out anomalies that
may be infrequent. Consequently, anomaly detection techniques do not per-
form well on summaries as they do not contain any anomalies.
– Semantics-basedtechniquesdonotkeepthesamesamplesinthesummarized
data.
– Statisticalbasedtechniquessuchassamplingdonotguaranteetherepresenta-
tionofanomaliesinsummarysincetheyuseasampling-basedsummarization
technique.
Therefore, not all summarization approaches are proper for anomaly detection
purposes. Consequently, there is a need for an efficient network traffic sum-
marization technique so that the summary more closely resembles the original
network traffic In this context, summarization aims to create a summary from
originaldatathatincludesinterestingpatterns,especiallyanomalies,andnormal
data for further analysis.
This paper proposes an intelligent summarization approach suitable for
anomaly detection on network traffic datasets, which guarantees the preserva-
tion of original data distribution. We investigate the adaptation of clustering
and KNN algorithms to create a summary. The proposed algorithm is used in
two scenarios: i) as the preprocess approach for performing anomaly detection,
ii) to detect anomalies in supervised problems as it reveals the hidden struc-
ture of data. The proposed summarization technique can also be adapted to
other domains where big data requires being minded for interesting and rele-
vant information. The rest of this paper is organized as follows. Section2 dis-
cusses the state-of-the-art methods. Section3 presents the proposed method,
and Sect.4 explains the experimental results and justifies the obtained results.
Finally, Sect.5 concludes the paper and discusses future work.
INSIDENT 311
2 Related Work
Summarization has been widely explored in many domains and applications,
using a variety of techniques [8,12,33]. When data size increases, the anomaly
detection techniques perform poorly due to increasing false alarms and compu-
tational cost. Detecting anomalies from a summary could address these issues.
However,existingsummarizationtechniquescannotaccuratelyrepresenttherare
anomaliespresentinthedataset.Inthissection,wewillpresentrelatedworkon
trafficdatasummarization,alongwithanomalydetectiontechniques.Itisworth
mentioning although the general goal is to represent an input dataset in a con-
densed version, there is no definition of a good summary since each application
requires a unique technique. For anomaly detection purposes, a good summary
should be representative of all samples in the original dataset.
2.1 Network Analysis Tools
Different network analysis tools summarize network traffic data, such as Traf-
fic Flow Analysis Tool, Flow-tools, Network Visualization Tools, and Network
Monitoring Tools [2]. They produce a graphical report using different mea-
surements, such as network bandwidth or latency. However, they only char-
acterize and aggregate traffic instances based on a single attribute, such as the
source/destination address or protocol. As a result, they are suitable to extract
insights,notforfurtherprocessingtaskssuchasanomalydetection.Besides,the
objective of a summary is to provide an accurate report of the network’s traf-
fic patterns. Consequently, the summarization technique should identify traffic
patterns based on arbitrary combinations of attributes efficiently.
2.2 Statistical Approaches
Statistical approaches aim to estimate the statistical distribution of data that
could approximate the data set pattern. Sampling is a common technique in
this category where a sample is a subset of the dataset. There are different
kinds of sampling in practice, including i) simple random sampling, ii) stratified
random sampling, iii) systematic sampling, iv) cluster random sampling, and v)
multi-stagerandomsampling[15,17].However,summarizeddatausingsampling
is under the threat of removing anomalies. To solve this problem, in a recent
work[2],theauthorproposedasampling-basedsummarizationtechnique,called
SUCh, which integrated the concept of sampling using the modified Chernoff
bound to include anomalous instances in summary. SUCh is computationally
effectivethantheexistingtechniquesandalsoperformsbetterinidentifyingrare
anomalies. However, an essential aspect of the summarization is representing
all different types of traffic behavior. Although SUCh ensures the presence of
anomalies,itignoresothertypesoftrafficastheyfocusonlyonanomalousdata.
312 S. Ghodratnama et al.
2.3 Machine Leaning Approaches
Supervised and unsupervised learning techniques are two widely used knowl-
edge discovery techniques. Two common machine learning algorithms used in
summarizing network traffic data are frequent itemsets and clustering. Frequent
itemsets are a set of items that appears more frequently than the rest of the
samples. Different algorithms are used to detect frequent itemsets [14]. How-
ever, they are proper for detecting frequent items, not rare anomalies. Two
mainclustering-basedalgorithmsfornetworktrafficdatasummarizationinclude
centroid-based and feature-wise intersectin clustering algorithms. In a centroid-
based summarization, after clustering samples, centroids are used to form the
summary. Different variations of the k-means algorithm are widely used due
to its simplicity, which can handle high-dimensional data [20,37]. In a feature-
wiseintersection-basedsummarization,thesummaryiscreatedfromeachcluster
using the feature-wise intersection of the data instances after clustering [14,23].
Consequently,summariesfromalltheclustersarecombinedtoproducethefinal
summary.Thisapproachisbestfittedfordatasetswithidenticalattributevalues
and, therefore, not suitable for detecting rare anomalies.
2.4 Semantic-Based Approaches
Semantic-based approaches are not suitable for anomaly detection since they
do not produce a summary, which is part of the original data. Examples are
linguistic summaries, which are based on the fuzzy. These approaches produce
naturallanguageexpressionsthatdescribeimportantfactsaboutthegivendata
to enhance the human understanding of the network traffic summaries [31].
Attribute Oriented Induction (AOI) is another semantic-based approach aims
to describe data in a concise and general manner [21]. AOI is a generalization
process that abstracts a large dataset from a low conceptual level to a rela-
tively higher conceptual level. Other semantic-based approaches include Fas-
cicles [24], which relies on an extended form of association rules and perform
lossy semantic compression. SPARTAN is another semantic-based summariza-
tion technique [10], which generalizes the fascicles approach.
2.5 Anomaly Detection Techniques
Anomaly detection is an important data analysis task that detects anomalous
or abnormal data from a given dataset. Anomalies are patterns in data that
do not follow the well-defined characteristic of typical patterns. Anomalies are
importantbecausetheyindicatesignificantbutrareeventsthatmayhaveadetri-
mental impact on the system. Therefore, they require prompt critical actions to
betakeninawiderangeofapplicationdomains.Ananomalycanbecategorized
in the following ways [3].
– Point anomaly: When a data instance deviates from the normal pattern of
the dataset, it can be considered a point anomaly.
INSIDENT 313
Table 1. Example of network traffic samples.
Source IP Source port Destination IP Destination port Protocol
192.168.5.10 1234 192.168.1.1 80 TCP
192.168.5.12 4565 192.168.1.2 20 TCP
192.168.5.10 20 192.168.28.80 119 HTTP
192.168.5.10 70 192.168.1.1 50 TCP
211.204.12.10 31 192.168.28.80 119 HTTP
192.168.5.1 3214 192.168.1.2 86 TCP
– Contextualanomaly:Whenadatainstancebehavesanomalouslyinapartic-
ular context, it is called a contextual or conditional anomaly.
– Collective anomaly: When a collection of similar data instances behave
anomalously compared to the entire dataset, the group of data instances is
called a collective anomaly.
Different supervised, unsupervised, and semi-supervised approaches have been
proposed for this purpose. These techniques, including classification based net-
work anomaly detection such as support vector machine [11], Bayesian net-
work [27], neural network [30], and rule-based approaches [38]. Statistical
anomaly detection techniques, including mixture model [16], signal processing
technique [36], and principal component analysis (PCA) [34]. Other category
includes information theory-based and clustering-based [1]. The proposed sum-
marization approach is a general approach used in two scenarios: i) as the pre-
processing approach where results are used as the input for anomaly detection
algorithm, and ii) as an anomaly detection technique in a supervised setting
discussed in the next section.
3 The Proposed Approach (INSIDENT)
Thissectiondiscussesourproposedmethodology.Atfirst,wedefinetheproblem
and then discuss our algorithm.
3.1 Problem Definition
Inthispaper,x iisasamplevectorandX =[x 1,x 2,...,x N]istrafficdataconsists
of N sample where x i ∈ Rd which d denotes the number of features. K is the
number of clusters, and cluster centroids are denoted by c. x is the closest
=
similarsampletox,andx (cid:3)=istheclosestdifferentsample.Anexampleofnetwork
trafficdatawithfewattributesisreportedinTable1.Thegoalistofindacluster
of similar samples and find representatives for each cluster as the summary S
where they keep the same distribution but less in size.
314 S. Ghodratnama et al.
3.2 Methodology
Previousapproachesuseddifferentclusteringorsamplingalgorithmstosumma-
rizedata.However,thereisnoguaranteethatthesummarizeddatahasthesame
distribution as the original data, and therefore as the substitute for the original
data. In this paper, we investigate the adaptation of clustering and the KNN
algorithm to understand the data’s underlying structure. In our previous work,
this structure was used in the context of multi-document summarization [19]
and image retrieval [18], demonstrating promising results. For this reason, the
errorrateofthenearestneighborclassifierineachclusterisminimizedbylocally
weighting features in each cluster. INSIDENT transforms the feature space into
a new feature space by weighting features separately in each cluster, where out-
liers are recognized easier in the new feature space. To this end, the weighted
Euclideandistanceisused.Inourproblem,theseweightsarearrangedinad×K
weight matrix W = {w ij,1 ≤ i ≤ d,1 ≤ j ≤ K} where d is the number of fea-
tures, and is K the number of clusters. To be more specific, for each cluster
we have a vector of weights corresponding to each feature which are representa-
tive of the importance of each feature in each cluster. Our objective function is
designed to minimize the error of 1NN in each cluster by regulating weights of
eachfeature,andconsequentlyclustercenters.Toestimatetheerrorof1NNthe
following approximation function defined in [29] is used:
J(W)= N1 s(cid:2) ∈XSS β(d dw w( (x x, ,x x= (cid:3)=) )) (1)
where the sample x = is the nearest similar sample, and the sample x (cid:3)= is the
closest different sample to the input sample x. Respectively d w is the weighted
Euclidean distance, and S β is the sigmoid function, defined as:
1
S β(z)=( 1+eβ(1−z)) (2)
The objective function of K-means, which aims to minimize the errors of each
cluster, is defined as:
(cid:2)K |(cid:2)NK|
J(W,C)= d2 WK(x i,c K) (3)