### 1. Dataset Summary and Temporal Distribution

The dataset, finalized in December 2016, ensures a high level of confidence in the ground-truth labels for malware. It consists of 129,728 Android applications, including 116,993 goodware and 12,735 malware samples. Figure 1 presents a stacked histogram illustrating the monthly distribution of goodware and malware within the dataset. For clarity, the figure also indicates the number of malware and goodware samples in each bin. The training and testing splits used in Section 3 are detailed in Table 1. All time-aware experiments in this paper involve training on data from 2014 and testing on data from 2015 and 2016, as indicated by the vertical dotted line in Figure 1.

### 2. Sources of Experimental Bias

#### 2.1 Motivational Example

To better illustrate the problem, we consider a motivational example where we vary the sources of experimental bias. Table 1 reports the F1-scores for two algorithms, ALG1 [4] and ALG2 [33], under different experimental configurations. Rows represent different sources of temporal bias, while columns represent different sources of spatial bias. The left part of Table 1 uses squares to indicate the time frames from which training and testing samples are drawn; each square represents a six-month period from January 2014 to December 2016. Black squares denote that samples are taken from that period, while gray squares indicate periods not used. The right part of the table shows different percentages of malware in the training and testing sets.

Table 1 demonstrates that both ALG1 and ALG2 perform significantly worse in realistic settings (bold values with green background in the last row, for 10% malware in testing) compared to settings similar to those in [4, 33] (bold values with red background). This discrepancy is due to inadvertent experimental bias, as discussed below.

**Note:** The cells with red backgrounds in Table 1 refer to settings similar to those in [4, 33]. ALG2 [33] reports an F1-score of up to 99%, which corresponds to a scenario with 86% malware in both training and testing, evaluated using 10-fold cross-validation. We rounded this to 90% for simplicity, and our experiments confirmed that results with 86% and 90% malware-to-benign class ratios are similar. ALG1 [4] uses hold-out validation with 10 random splits (66% training, 33% testing). Since hold-out validation is nearly equivalent to k-fold cross-validation and shares the same spatio-temporal biases, we use k-fold CV for both ALG1 and ALG2 in this section.

#### 2.2 Temporal Experimental Bias

**Concept Drift:** In machine learning, concept drift occurs when a model becomes obsolete because the distribution of incoming test data differs from the training data, violating the assumption of independent and identically distributed (i.i.d.) data [26]. This is also known as dataset shift [50]. Time decay refers to the decrease in model performance over time due to concept drift.

**Impact on Malware Classification:** Concept drift in malware, combined with similarities within malware families, can lead to positively biased performance metrics when using k-fold cross-validation (CV). This is because k-fold CV often includes at least one sample from each malware family in the training set, whereas new families may be unknown during real-world deployment. The all-black squares in Table 1 for 10-fold CV indicate that each training/testing fold contains at least one sample from each time frame. While k-fold CV is widely used in malware classification research [11,12,27,31,34,37,41,49,51,57] to prevent overfitting and estimate classifier performance, its impact on real-world performance with non-stationary data affected by time decay has been unclear. The first row of Table 1 quantifies this performance impact in the Android domain.

**Past Object Detection:** The second row of Table 1 shows an experiment evaluating a classifier's ability to detect past objects. High performance is expected here, as the classifier will likely identify similar variants if it contains at least one variant of a past malware family. However, such experiments can be misleading, and the community should focus on building classifiers robust against time decay.

**Temporal Mismatch:** The third row identifies a novel temporal bias where goodware and malware come from different time periods, often due to different data sources (e.g., [33]). The black and gray squares in Table 1 show that, although malware testing objects are posterior to malware training objects, the goodware/malware time windows do not overlap. This can lead the classifier to learn to distinguish applications from different time periods rather than goodware from malware, resulting in artificially high performance.

**Realistic Setting:** The last row of Table 1 shows that the realistic setting, where training is temporally precedent to testing, generally results in the worst classifier performance. Detailed decay plots and further discussion are provided in Section 4.

#### 2.3 Spatial Experimental Bias

We identify two main types of spatial experimental bias based on assumptions about the percentages of malware in the training and testing sets. All experiments in this section assume temporal consistency, with training on 2014 and testing on 2015 and 2016 (last row of Table 1) to analyze spatial bias without temporal interference.

**Spatial Bias in Testing:** The percentage of malware in the testing distribution must be estimated and cannot be changed if one wants results to be representative of real-world deployment. To illustrate this, we artificially vary the testing distribution. Figure 2 shows the performance (F1-Score, Precision, Recall) for increasing percentages of malware during testing. We downsample goodware to keep the number of malware fixed. The plots exhibit constant Recall and increasing Precision for increasing malware percentages. This is because true positives (TPs) and false negatives (FNs) remain constant, while false positives (FPs) decrease. Since F1-Score is the harmonic mean of Precision and Recall, it increases with Precision. Conversely, Precision for goodware decreases. This example shows how considering an unrealistic testing distribution with more malware than goodware inflates the F1-Score of the malware classifier.

**Spatial Bias in Training:** To understand the impact of altering malware-to-goodware ratios in training, we consider a motivating example with a linear SVM in a 2D feature space. Figure 3 shows three scenarios with 10% malware in testing but 10%, 50%, and 90% malware in training. As the percentage of malware in training increases, the hyperplane moves towards goodware, improving malware Recall but reducing Precision. To minimize the overall error rate (maximize Accuracy), the training distribution should match the expected testing distribution. However, in some cases, one might prioritize finding objects of the minority class (e.g., "more malware") by improving Recall subject to a constraint on maximum FPR.

Figure 4 shows the performance for ALG1 and ALG2 for increasing percentages of malware in training. The plots confirm the trend observed in Figure 3, with increasing Recall but decreasing Precision for malware. For 10% malware in testing, there is a point where the F1-Score for malware is maximized while the error for goodware is within 5%.

### 3. Space-Time Aware Evaluation

We now formalize how to perform an evaluation of an Android malware classifier free from spatio-temporal bias. We define a set of constraints for realistic evaluations (Section 4.1), introduce a time-aware metric, AUT, that captures the impact of time decay (Section 4.2), propose a tuning algorithm to optimize classifier performance subject to a maximum tolerated error (Section 4.3), and introduce TESSERACT, providing counter-intuitive results through unbiased evaluations (Section 4.4). For improved readability, a table of major symbols used in the remainder of the paper is provided in Appendix A.2.

### 4. Evaluation Constraints

[Further content to be added here, following the structure and style of the previous sections.]

This revised version aims to make the text more coherent, clear, and professional, with a logical flow and appropriate headings.