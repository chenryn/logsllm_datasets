    switch(obj->type & 0xFF){ 
        case OBJ_NUM: 
            ret = read_number(sockfd, &(obj->u.num)); 
            break; 
        case OBJ_STR: 
            ret = read_string(sockfd, &(obj->u.str)); 
            break; 
        default: 
            ret = read_opaque(sockfd, &(obj->u.opaque)); 
    } 
    if(ret type){ 
        case OBJ_NUM: 
            break; 
        case OBJ_STR: 
            free_string(obj->u.str); 
            break; 
        default: 
            free_opaque(obj->u.opaque); 
    } 
    free(obj); 
    return 0; 
} 
Listing 7-11 shows an interface for reading objects of some form off the network. 
Notice the small differences between the way objects are initialized and the way they 
are cleaned up. The type variable is a 32-bit integer read in from the network, yet only 
the lower 8 bits are examined during object initialization. When the object is cleaned 
up, all 32 bits are examined. Therefore, if a 32-bit integer type is supplied with the low 
bits equaling OBJ_NUM and the higher bits not all set to zero, a user-controlled integer 
is passed to the free_opaque() function and treated as a memory location, most likely 
resulting in a call to free() on an arbitrary memory location. 
Lists and Tables 
Linked lists and hash tables are often used in applications to keep a collection of data 
elements in a form that's easy to retrieve and manipulate. Some common errors are 
made when implementing routines that add and modify these data structures, and 
these mistakes can lead to inconsistencies in data structures. Attackers could take 
advantage of these inconsistencies to force an application into performing operations 
it wasn't intended to. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
339 
Linked lists are used frequently for storing related data elements that need to be 
looked up or modified later in the program. Linked lists can be singly linked or doubly 
linked. Singly linked lists are those in which elements contain a pointer to the next 
element in the list; doubly linked lists elements contain pointers to both the next 
and previous elements in the list. In addition, linked lists can be circular, meaning 
the last element of the list links back to the first element; for doubly linked lists, the 
previous pointer of the first element links back to the last element. 
When auditing code that makes use of linked lists, you should examine how well the 
algorithm implements the list and how it deals with boundary conditions when 
accessing elements of these lists. Each of these points (discussed in the following 
sections) needs to be addressed: 
Does the algorithm deal correctly with manipulating list elements when the list 
is empty? 
What are the implications of duplicate elements? 
Do previous and next pointers always get updated correctly? 
Are data ranges accounted for correctly? 
Manipulating List Elements in Empty Lists 
Often, list structure members or global variables are used to point to the head of a list 
and potentially the tail of the list. If the code reviewer can find a case where these 
variables aren't updated correctly, there's the possibility for outdated elements or 
undefined data to be references as though they were part of the list. For example, 
consider the code in Listing 7-12. 
Listing 7-12. Empty List Vulnerabilities 
/* head and tail elements of a doubly linked, noncircular 
   list */ 
struct member *head, *tail; 
int delete_element(unsigned int key) 
{ 
    struct member *tmp; 
    for(tmp = head; tmp; tmp = tmp->next){ 
        if(tmp->key == key){ 
           if(tmp->prev) 
               tmp->prev->next = tmp->next; 
           if(tmp->next) 
               tmp->next->prev = tmp->prev; 
          free(tmp); 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
340 
           return 1; 
       } 
   } 
   return 0; 
} 
The deletion code in Listing 7-12 has an obvious omission: If the head or tail elements 
are deleted, this deletion isn't accounted for in the delete_element() function. 
Because the head and tail global variables aren't updated, the first or last element 
can be deleted with this function and then accessed by any code manipulating the 
head or tail pointers. Code that doesn't deal with head and tail elements correctly 
isn't common, but it can occur, particularly when list management is decentralized 
(that is, there's no clean interface for list management, so management happens 
haphazardly at different points in the code). 
Some implementations initialize the list with blank head and/or tail elements, often 
called sentinel nodes (or sentinels). Sentinel nodes are used largely for convenience 
so that code doesn't need to specifically deal with instances of the list being empty, as 
sentinel nodes always have at least one element. If users can add data elements that 
appear to the program to be sentinels or cause sentinels to be deleted, the list 
management code might be susceptible to vulnerabilities stemming from code 
misinterpreting where the head or tail of the list is. 
Duplicate Elements 
Depending on the nature of the data being stored, duplicate elements can cause 
problems. Elements containing identical keys (data values used to characterize the 
structure as unique) could cause the two elements to get confused, resulting in the 
wrong element being selected from the list. This error might have interesting 
consequences; for example, sessions uniquely identified by a cookie could become 
confused if two or more clients supplied identical cookies. This confusion could lead to 
some sort of information leak, elevation of privilege, or other compromise. 
Previous and Next Pointer Updates 
Implementation flaws in deleting and inserting elements may prevent the previous 
and next pointers from being updated correctly. This is especially true if the program 
treats the current member as the head or tail of a list. Listing 7-13 shows a potential 
issue that occurs when updating list elements. 
Listing 7-13. List Pointer Update Error 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
341 
struct member *head, *tail; 
int delete_element(unsigned int key) 
{ 
    struct member *tmp; 
    for(tmp = head; tmp; tmp = tmp->next){ 
        if(tmp->key == key){ 
            if(tmp->prev) 
                tmp->prev->next = tmp->next; 
            if(tmp->next) 
                tmp->next->prev = tmp->prev; 
            if(tmp == head) 
                head = tmp->next; 
            else if(tmp == tail) 
                tail = tmp->prev; 
            free(tmp); 
            return 1; 
       } 
   } 
   return 0; 
} 
The code in Listing 7-13 has a small error when updating the head and tail elements. 
If only one element exists in the list, both the head and the tail element point to it, yet 
you can see in the code that an else statement is used when testing whether the 
element is the head or tail. Therefore, if a single element exists in the list and is 
deleted, the head element is updated correctly to be NULL; however, the tail element 
points to the outdated element. 
Data Ranges 
In ordered lists, the elements are sorted into some type of order based on a data 
member that distinguishes each list element. Often each data element in the list 
represents a range of values, such as part of an IP datagram in an IP fragment queue 
or memory ranges in kernel control structures for processes. The code used to 
implement this seemingly simple data structure can be quite complex, particularly 
when you have to take the following nuances of the data into account: 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
342 
Can overlapping data ranges be supplied? 
Can replacement data ranges (duplicate elements) be supplied? 
Does old or new data take precedence? 
What happens when 0 length data ranges are supplied? 
These details, if not handled correctly, can result in logic flaws in processing data or 
inconsistencies in the list data structures. The most likely result of this oversight is an 
exploitable memory corruption condition. Listing 7-14 is code from the Linux 
kernelthe infamous teardrop bug. It shows how overlapping data ranges can be 
processed incorrectly, resulting in a vulnerability. 
Listing 7-14. Linux Teardrop Vulnerability 
    /* 
     *      We found where to put this one. 
     *      Check for overlap with preceding fragment, 
     *      and, if needed, align things so that any 
     *      overlaps are eliminated. 
     */ 
    if (prev != NULL && offset end) 
    { 
            i = prev->end - offset; 
            offset += i;    /* ptr into datagram */ 
            ptr += i;       /* ptr into fragment data */ 
    } 
     ... 
    /* Fill in the structure. */ 
    fp->offset = offset; 
    fp->end = end; 
     fp->len = end - offset; 
This code processes incoming IP fragments to be placed into a queue with other 
fragments that are part of the same IP datagram. The offset variable represents the 
offset into the complete datagram where the current fragment begins. The end 
variable is the offset into the complete datagram where the current fragment ends, 
calculated by adding the starting offset of the fragment and its length. The IP code 
cycles through a list of fragments and breaks out when it finds the right place in the 
list to insert the incoming IP fragment. If there's any overlap between two fragments, 
the current fragment is shrunk so that only unaccounted for data ranges are added to 
the queue, and the overlapping data is discarded. An "overlap" in this situation means 
that two fragments or more partially or fully supply duplicate data ranges. For 
example, if one fragment supplies data from offset 1030, and another specifies 2040, 
they overlap because both fragments specify data from the offset 2030. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
343 
The vulnerability in this code occurs during the process of shrinking the current 
fragment; the code is written with the assumption that end is greater than or equal to 
prev->end. If this isn't the case, offset is incremented to become larger than end. As 
a result, the fp->len variable is set to a negative value, which is later used as an 
argument to memcpy(), resulting in a buffer overflow. 
Hashing Algorithms 
Hash tables are another popular data structure, typically used for speedy access to 
data elements. A hash table is often implemented as an array of linked lists, so the 
previous discussion on list management is relevant to hash tables as well. Hash tables 
use the list element as input to a hash function (hash functions are discussed in 
Chapter 2(? [????.]), "Design Review"). The resulting hash value is used as an index 
to an array. When dealing with hash tables, code auditors must address these 
additional questions: 
Is the hashing algorithm susceptible to invalid results? Most hashing 
algorithms attempt to guarantee that the result lies within a certain range (the 
array size) by performing an operation and then using the modulus or and 
operator on the result. As discussed in Chapter 6(? [????.]), one potential 
attack vector is forcing the modulus operator to return negative results. This 
result would allow negative indexing into the array used to store elements. 
Additionally, code reviewers must evaluate the consequences if data elements 
can be influenced in such a way that many collisions could occur. Often this 
problem causes a slowdown in lookups, which can be a major problem if the 
application is time critical. 
What are the implications of invalidating elements? Several algorithms that 
store many data elements can invalidate members based on certain conditions, 
such as timeouts or memory threshold limits reached. This pruning can 
sometimes have unexpected consequences. As with lists, code auditors must 
determine whether invalidated elements could be unlinked from the table 
incorrectly, resulting in the application potentially using outdated elements 
later. Invalidating elements in a predictable manner can have other 
interesting consequences, such as causing an application with several session 
data elements to delete valid sessions, resulting in a denial-of-service 
condition. 
7.3.3 Auditing Control Flow 
As you learned in Chapter 4(? [????.]), "Application Review Process," control flow 
refers to the manner in which a processor carries out a certain sequence of 
instructions. Programming languages have several constructs that enable 
programmers to branch to different code paths based on a condition, repeat 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
344 
instructions over a number of iterations, and call subroutines (directly or indirectly). 
These constructs are the basic building blocks of programming languages, and every 
developer is familiar with them. When auditing code, it's interesting to see that these 
constructs often have similar security vulnerabilitiesnot because programmers don't 
know how to implement them, but because the application can enter a specific 
context that isn't accounted for correctly. In this section, you examine loop and 
switch statement constructs, which govern internal control flow. External control flow 
is covered in "Auditing Functions(? [????.])" later in this chapter. For now, you focus 
on how to audit loops and switch-style branches and learn some guidelines on what to 
look for when evaluating their proper use. 
Looping Constructs 
Looping constructs are extremely common and used in every component of 
application processing, whether it's initializing structures, processing input, 
interacting with the file system, or deallocating memory. This section focuses on 
data-processing loops, which are used to interpret user-supplied data and construct 
some form of output based on the data. This output can range from elements 
extracted from user input to data derived from the input. These types of loops pose 
the most immediate security threat to an application. 
A loop can be constructed incorrectly in a number of ways so that it causes a read or 
write outside the bounds of the provided data buffers. The following common errors 
can cause loops to behave in a manner that contradicts the programmer's intentions: 
The terminating conditions don't account for destination buffer sizes or don't 
correctly account for destination sizes in some cases. 
The loop is posttest when it should be pretest. 
A break or continue statement is missing or incorrectly placed. 
Some misplaced punctuation causes the loop to not do what it's supposed to. 
Any of these conditions can have potentially disastrous consequences for application 
security, particularly if the loop performs writes to memory in some way. As discussed 
in Chapter 5(? [????.]), "Memory Corruption," writes stand the most chance of being 
destructive to other variables or program state information and, consequently, 
leading to an exploitable situation. 
Terminating Conditions 
Application developers are often required to construct loops for processing 
user-malleable data. These loops must parse and extract data fields, search for 
occurrences of specific data elements, or store parts of data to a specific destination, 
such as another memory location or a file. When a loop performs a data copy, it is 
necessary to verify whether the copy is performed in a safe mannerthat is, there's no 
way the loop can read or write outside the boundaries of objects being operated on. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
345 
Typically, loops that perform these kinds of copies have multiple terminating 
conditions, which are checks that can cause the loop to exit. A loop might have a 
terminating condition that checks for successful completion of the copy as well as 
several terminating conditions that attempt to account for erroneous conditions that 
might occur during processing. If the set of terminating conditions in a loop don't 
adequately account for all possible error conditions, or the implementation of the 
checks is incorrect, the program might be susceptible to compromise in one form or 
another. When dealing with length calculations, two main problems could occur: 
The loops fail to account for a buffer's size. 
A size check is made, but it's incorrect. 
The first problem is fairly easy; no size check is done on input or output data, so if 
attackers can supply more data than has been allocated for the destination buffer, 
they can trigger a buffer overflow condition and compromise the application. Listing 
7-15 shows a simple example. 
Listing 7-15. Simple Nonterminating Buffer Overflow Loop 
int copy(char *dst, char *src) 
{ 
    char *dst0 = dst; 
    while(*src) 
        *dst++ = *src++; 
    *dst++='\0'; 
    return dst  dst0; 
} 
The code in Listing 7-15 essentially performs the same task as a strcpy() routine: It 
copies data from src into dst until it encounters a NUL byte. These types of loops are 
usually quite easy to spot when auditing code and appear quite often in major 
applications. A notable example is one in the Distributed Component Object Model 
(DCOM) Object Activation RPC interface in Windows operating systems. This interface 
has a tightly contained loop in the GetMachineName() function. Listing 7-16 shows 
approximated C code based on the assembly code. 