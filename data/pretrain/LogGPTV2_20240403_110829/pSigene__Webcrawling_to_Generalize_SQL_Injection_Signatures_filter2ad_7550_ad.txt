incrementally trained. Note that the incremental training is
also an automatic process and therefore, we are spared the
tedium of manually updating prior signatures.
When adding 20% of the SQLmap dataset, we obtained a
TPR = 89.13% and a FPR = 0.039%. After augmenting
the training dataset with 40% of the samples from the
SQLmap set, the TPR increased to 91.15% while the FPR
also increased to 0.044%. In both cases (20% and 40%), we
used sets of 9 signatures.
From the results, the TPR showed an increment of a
bit over 2%, for each round of the experiment. This can
be explained as we ﬁrst randomized the SQLmap set and
then divided it into 20% parts. So one can hypothesize that
pSigene is seeing some similar attack samples in the test
phase.
F. Experiment 3: Comparison to Perdisci’s Approach
We also compared pSigene to the approach presented in
Perdisci et.al. [29] for the automatic generation of signatures
for HTTP-based malware. We selected this approach as (1)
it has as one of its claims the ability to create signatures for
variants of malware that have not yet been seen, (2) it in-
volves the analysis of HTTP traces like in our SQLi scenario,
and (3) is based on the popular token-subsequence technique
used to generate signatures for polymorphic worms [24].
As the current evaluation of pSigene involves a different
type of attacks, SQL injection, two changes were made to
the original technique in Perdisci’s paper 1. First, we did not
implement the ﬁrst step, coarse-grained clustering, as it was
not applicable to our scenario. They clustered malware sam-
ples by looking at structural similarities among sequences
of HTTP requests but in our case, each HTTP request is
considered independently of the rest so the ﬁrst step is
not needed. In the second step, ﬁne-grained clustering, we
1We contacted the authors but no implementation was available to us,
so we re-implemented their technique for this evaluation. We faithfully
followed the method outlined in the paper, with a few specializations which
we outline here.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:01:01 UTC from IEEE Xplore.  Restrictions apply. 
modiﬁed how an HTTP request was evaluated to compute
the distance metric between pairs of requests. We used the
same predeﬁned weights (10 and 8) as in Perdisci, assigning
them to the parameter values and names, respectively, and
disregarded the method and path of a HTTP request. For the
SQLi scenario, the parameter values include the actual SQL
query and therefore represent the most important part of a
URL when detecting this type of attack.
We used the same training set as pSigene to generate
the signature set with the adjusted Perdisci implementation.
Controlling the clustering process by using the DB validity
index (Section 3 of [29]), 145 clusters were produced during
the ﬁne-grained clustering phase. We reduced the cluster set
to 27 after removing clusters according to the presented tech-
nique, i.e., with a single sample or that produce signatures
too short (such as ?id=.*). At the end of phase 3, cluster
merging, 10 signatures were produced. To merge different
clusters, we chose a threshold of 0.1 as this meant that
two signatures would only be merged if they were nearly
identical. At all phases, the DB index was computed to
validate our answers.
We tested the signatures produced with Perdisci’s ap-
proach using the same malicious and benign sets used for
other signature sets. Perdisci’s achieved a TPR of 5.79% and
a FPR of 0%. The FPR is very good as these signatures did
not misclassify a single benign sample as malicious. The
TPR on the other hand is very low. We were not expecting
the TPR to be high as Perdisci’s (and Polygraph) objective
is not to produce generalized signatures but rather to create
a single token subsequence that can represent the set of all
samples previously seen . Still, the TPR shows the limitation
faced from using approaches like this to detect variations of
known attacks. As a counterpoint, when we used the same
samples from the training set for the testing, it showed a
TPR of 76.5%. This indicates that it is more successful in its
objective of automatically creating signatures from already
seen samples.
G. Experiment 4: Performance Evaluation
In this section, we report the overhead of pSigene sig-
natures. Speciﬁcally, we measured the processing-time per
HTTP request for each signature in the SQLmap dataset.
We observe that pSigene reports minimum, average, and
maximum processing times of 390, 995, and 1950 μsec,
respectively. On average, pSigene gives a slowdown of 17X
and 11X against Modsec and Bro signatures respectively.
The increased processing-time in pSigene is majorly attrib-
uted to the count_all() function call, which counts the
number of regex matches for each HTTP request string. We
observe from the data that the signatures with a large number
of invocations of count_all() take a disproportionately
large fraction of the total processing time. Given that we
run these measurements on a relatively resource-starved
machine (700 MHz (CPU), 512 MB (RAM)) and still
the worst case processing time was less than 2 ms, we
would expect that signature matching in pSigene will not
become a bottleneck. Importantly, the signature matching is
completely parallelizable - each parallel thread can match
one signature and this functionality is inbuilt in Bro (Bro’s
cluster mode). But we do not have this obvious performance
optimization implemented yet.
IV. DISCUSSION
This work throws light on the importance of good training
data for creating the clusters and subsequently the signatures.
It is imperative that the training data be representative of
the kinds of attacks that will be seen in operation, though
they do not need to be identical. How far apart can the
attacks in training and test be? This is a perennial question
that is asked of machine learning algorithms in all different
contexts. This answer is probabilistic since our framework
gives a probability value to how likely a sample is to
belong to a cluster. The heartening insight from pSigene’s
evaluation is that the match does not need to be exact and
thus hitherto unseen attacks can also be detected. The ﬂip
side of this is that it suffers from some false positives, which
in some deployments may be completely unacceptable. For
speciﬁcity, consider the following example.
The set of
regex patterns used in signature 4 of
include char, @, information_schema,
pSigene
and ch(a)?r\s*?\(\s*? \d. Looking at
the set of
samples used to train for this signature, one can ﬁnd SQLi
samples similar to ?id=-1+union+ select+1,2,3,
4,concat(database(),char(58), user(),
char(58),version()),6,7,8,9,10, 11, 12,
13, 14, 15, 16,17, where there are two occurrences
of patterns char and two of ch(a)?r\s*?\(\s*?\d.
The testing set on the other hand include samples with
different subsets of the regex patterns for signature 4 and
for pattern char we found samples from zero to thirty
occurrences.
The features should be chosen to be rich enough that
they are likely to capture important characteristics of the
zero-day attacks. Thus, signatures based on such features
will likely be able to match some of the zero-day attacks.
The feature selection process needs to be repeated for each
kind of attack, but not for each attack sample. This makes
this process more feasible in practice. In contrast, manual
signature update is a process that needs to be done for each
attack sample and is therefore not as scalable. Of course, in
practice, a signature update is done in a batch mode after a
certain number of attack samples have been collected.
V. RELATED WORK
The work presented in this paper is related to three
areas of intrusion detection: automatic signature creation,
signature generalization, and the interaction between web
545454
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:01:01 UTC from IEEE Xplore.  Restrictions apply. 
applications and databases. We discuss how previous work
in these two areas relates to our research.
An important work on automatic signature creation is by
Yegneswaran, et al [44]. The authors presented a framework
based on machine learning to produce attack signatures.
A key point by the authors and which we agree with is
that the framework requires protocol knowledge in order
to produce effective signatures and such insight impacts
the resulting detection mechanism. Distinct from our work,
they take a passive approach as HTTP and NetBIOS-based
malware trafﬁc is collected from honeynets. Additionally,
our framework is agnostic to transport- and network-level
information, which is important for their framework. Finally,
we rely heavily on regular expressions, looking to produce
rich, optimized regex signatures. Their approach to regexs
is limited as it only uses simple metacharacters such as *,
+, and ? to express clusters of signatures.
Previous work on signature generalization also includes
[24], [19], and [22]. In [24], a system called Polygraph
generates signatures that consist of multiple disjoint sub-
strings. In doing so, Polygraph leverages our insight that for
a real-world attack to function properly, multiple invariant
substrings are often be present in the payload. Similarly,
[19] applies pattern-matching techniques and protocol con-
formance checks on multiple levels in the protocol hierarchy
to network trafﬁc captured at a honeypot system, to produce
worm signatures. [22] extends this idea to detect zero-day
polymorphic worms on high-speed networks. In both cases,
the goal is to detect worms at the network layer while our
general approach considers protocol information and suited
for other types of attacks.
Robertson et al. [32] present an anomaly generalization
technique to automatically translate suspicious requests to
a web server into anomaly signatures. This approach is
complementary to ours and uses heuristics-based techniques
to infer web-based attacks. For the class of SQL injection
attacks, the technique performs a simple scan for common
SQL language keywords and syntactic elements. This results
in basic signatures to detect SQLi attacks, but no details
were provided on the performance of these signatures.
Other papers that present similar anomaly-based intrusion
detection techniques for SQLi attacks include [17] and [21].
The interaction between web applications and databases
to improve the detection rate of attacks against these re-
sources has been covered in [3], [42], [5], and [31]. [3]
et al. present a novel approach for automatically detecting
potential server-side vulnerabilities of this kind in legacy
web applications through blackbox analysis. [42] proposes
a serially composed system with a web-based anomaly
detection system, a reverse HTTP proxy, and a database
anomaly detection system to increase the detection rate of
web-based attacks.
VI. CONCLUSIONS AND FUTURE WORK
In this work, we presented a system called pSigene, for
the automatic generation and update of intrusion signatures.
The system beneﬁts from mining the vast amount of public
data available on attacks. We tested our architecture for the
prevalent class of SQLi attacks and found our signatures
to perform very well, compared to existing signature sets,
which have been created manually and with a tremendous
amount of security expertise and progressive reﬁnement over
the period of multiple years.
Our framework allows one to generalize existing signa-
tures and the detection of new variations of attacks (i.e.,
some kinds of zero-day attacks) is achieved by using regular
expressions for the generalized signatures. We also rigor-
ously benchmarked our solution with a large set of attack
samples and compare our performance to popular misuse-
based IDS-es. The evaluation also brings out the impact
of a practical use case whereby periodically new attack
samples are fed into our algorithm and consequently the
signatures can be progressively, and automatically, updated.
In contrast, to improve the other signature sets requires the
manual inspection and testing of the signatures, which could
overwhelm a system administrator with limited resources.
Future work will include the implementation of the in-
cremental update operation. This task has some open design
choices in terms of the machine learning technique to use
and empirical evidence is needed to guide our choice. We
will also improve the online performance of the signature
matching process. This will be done ﬁrst by simply paral-
lelizing the process and next by optimizing the code path
within Bro through which our signature matching occurs.
REFERENCES
[1] ARACHNI. Web application security scanner framework.
http://www.arachni-scanner.com, February 2013.
[2] BBC. Royal navy website attacked by romanian hacker.
http://www.bbc.co.uk/news/technology-11711478, November
8, 2010.
[3] P. Bisht, T. Hinrichs, N. Skrupsky, R. Bobrowicz, and V. N.
Venkatakrishnan. Notamper: automatic blackbox detection of
parameter tampering opportunities in web applications.
In
Proc. ACM CCS, 2010.
[4] P. Bisht, A. P. Sistla, and V. Venkatakrishnan. Automatically
In Proc. IFCA Conf. Financial
preparing safe sql queries.
Cryptography, 2010.
[5] R. Chandra, T. Kim, M. Shah, N. Narula, and N. Zeldovich.
Intrusion recovery for database-backed web applications. In
Proc. ACM SOSP, 2011.
[6] J. Clarke. SQL Injection Attacks and Defense. Syngress
Publishing, 1st edition, 2009.
[7] B. Damele and M. Stampar. SQLmap. http://sqlmap.org, July
2012.
555555
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:01:01 UTC from IEEE Xplore.  Restrictions apply. 
[8] DarkReading. Adobe hacker says he used sql injection to
grab database of 150,000 user accounts, November 2012.
[28] V. Paxson. Bro: a system for detecting network intruders in
real-time. Computer Networks, 31(23-24):2435–2463, 1999.
[9] R. Di Pietro and L. V. Mancini. Intrusion Detection Systems.
Springer Publishing Company, Incorporated, 1 edition, 2008.
[10] M. B. Eisen, P. T. Spellman, P. O. Brown, and D. Botstein.
Cluster analysis and display of genome-wide expression pat-
terns. Proc Natl Acad Sci, 95(25):14863–14868, Dec 1998.
[11] S. Eisenstat. Efﬁcient implementation of a class of pre-
conditioned conjugate gradient methods. SIAM Journal on
Scientiﬁc and Statistical Computing, 2(1):1–4, 1981.
[12] O. I. S. Foundation. Suricata intrusion detection and preven-
tion engine. http://www.openinfosecfoundation.org, 2012.
[13] O. S. Foundation. Open source vulnerability database. http:
//www.osvdb.org, 2012.
[14] D. Goodin. New Sony hack exposes more consumer pass-
words. The Register, June 3, 2011.
[15] Google. Google custom search api. https://developers.google.
com/custom-search, 2012.
[29] R. Perdisci, W. Lee, and N. Feamster. Behavioral clustering of
http-based malware and signature generation using malicious
network traces. In Proc. USENIX NSDI, 2010.
[30] A. Prelic, S. Bleuler, P. Zimmermann, A. Wille, P. Buhlmann,
W. Gruissem, L. Hennig, L. Thiele, and E. Zitzler. A
systematic comparison and evaluation of biclustering methods
for gene expression data. Bioinformatics, 22(9):1122–1129,
2006.
[31] W. Robertson, F. Maggi, C. Kruegel, and G. Vigna. Effective
anomaly detection with scarce training data. In Proc. NDSS
Symposium, 2010.
[32] W. Robertson, G. Vigna, C. Kruegel, and R. Kemmerer.
Using Generalization and Characterization Techniques in the
Anomaly-based Detection of Web Attacks.
In Proc. NDSS
Symposium, 2006.
[33] R. Salgado. Websec sql injection pocket reference. http:
//goo.gl/FGAhc, 2011.
[16] IBM.
IBM X-Force 2012 trend and risk report.
//www-03.ibm.com/security/xforce/, March 2013.
http:
[34] O. Security. Exploit database. http://www.exploit-db.com,
2012.
[17] A. Kamra, E. Bertino, and G. Lebanon. Mechanisms for
In Proc. ACM
database intrusion detection and response.
SIGMOD IDAR, 2008.
[18] R. Kaushik and R. Ramamurthy.
Efﬁcient auditing for
complex sql queries. In Proc. ACM SIGMOD, 2011.
[19] C. Kreibich and J. Crowcroft. Honeycomb: creating intrusion
detection signatures using honeypots. SIGCOMM Comput.
Commun. Rev., 34(1):51–56, jan 2004.
[35] SecurityFocus. Bugtraq vulnerability database. http://www.
securityfocus.com/vulnerabilities, 2008.
[36] R. Sekar. An efﬁcient black-box technique for defeating web
application attacks. In NDSS Symposium, 2009.
[37] Sourceﬁre. Snort IDS. http://www.snort.org, 2008.
[38] Z. Su and G. Wassermann. The essence of command injection
attacks in web applications. In Proc. ACM POPL, 2006.
[20] C. Kruegel. Intrusion Detection and Correlation: Challenges
and Solutions. Springer-Verlag TELOS, 2004.
[39] Subgraph. Vega, web application security platform. http:
//www.subgraph.com, February 2013.
[21] S. Y. Lee, W. L. Low, and P. Y. Wong. Learning ﬁngerprints
for a database intrusion detection system. In Proc. ESORICS,
2002.
[22] Z. Li, M. Sanghi, Y. Chen, M.-Y. Kao, and B. Chavez. Hamsa:
fast signature generation for zero-day polymorphic worms
with provable attack resilience. In Proc. IEEE Symp. Security
and Privacy, 2006.
[23] A. Moscaritolo. Oracle’s mysql.com hacked via sql injection,
March 28, 2011.
[24] J. Newsome, B. Karp, and D. Song. Polygraph: automatically
generating signatures for polymorphic worms. In Proc. IEEE
Security and Privacy, 2005.
[25] NIST. National vulnerability database. http://nvd.nist.gov/
nvd.cfm, 2008.
[26] Oracle. Mysql 5.5 reference manual, rev. 31755, August 2012.
[40] S. V. R. Team. Snort rules. http://www.snort.org/snort-rules,
2012.
[41] Trustwave. Modsecurity core rule set. http://www.owasp.
org/index.php/Category:OWASP ModSecurity Core Rule
Set Project, January 2012.
[42] G. Vigna, F. Valeur, D. Balzarotti, W. Robertson, C. Kruegel,
and E. Kirda. Reducing Errors in the Anomaly-based Detec-
tion of Web-Based Attacks through the Combined Analysis
of Web Requests and SQL Queries. J. Comp. Sec., 17(3),
2009.
[43] WAVSEP. Web application vulnerability scanner evaluation
project. https://code.google.com/p/wavsep, July 2012.
[44] V. Yegneswaran, J. T. Gifﬁn, P. Barford, and S. Jha. An
In
architecture for generating semantics-aware signatures.
Proc. USENIX Security, 2005.
[27] PacketStorm.
Packetstorm security portal.
packetstormsecurity.org, 2012.
http://
565656
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:01:01 UTC from IEEE Xplore.  Restrictions apply.