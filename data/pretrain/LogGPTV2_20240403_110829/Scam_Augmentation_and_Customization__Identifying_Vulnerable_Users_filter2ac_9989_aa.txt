title:Scam Augmentation and Customization: Identifying Vulnerable Users
and Arming Defenders
author:Shahryar Baki and
Rakesh M. Verma and
Omprakash Gnawali
Scam Augmentation and Customization: Identifying Vulnerable
Users and Arming Defenders
Shahryar Baki
University of Houston
Houston, Texas
PI:EMAIL
Rakesh M. Verma
University of Houston
Houston, Texas
PI:EMAIL
Omprakash Gnawali
University of Houston
Houston, Texas
PI:EMAIL
ABSTRACT
Why do “classical” attacks such as phishing, IRS scams, etc., still
succeed? How do attackers increase their chances of success? How
do people reason about scams and frauds they face daily? More
research is needed on these questions, which is the focus of this
paper. We take a well-known attack, viz. company representative
fraud, and study several parameters that bear on its effectiveness
with a between-subjects study. We also study the effectiveness of
a coherent language generation technique in producing phishing
emails. We give ample room for the participants to demonstrate
their reasoning and strategies.
Unfortunately, our experiment indicates that participants are
inadequately prepared for dealing with even the company repre-
sentative fraud. Participants also could not differentiate between
offers written by human or generated semi-automatically. Moreover,
our results show attackers can easily increase their success rate
by adding some basic information about the sender, so defenders
should focus more on such attacks. We also observed that partici-
pants who paid attention to more clues were better in distinguishing
legitimate messages from phishing, hence training regimes should
check for reasoning strategies, not just who did not click on a link
or download an attachment. Thus, insights from our work can help
defenders in developing better strategies to evaluate their defenses
and also in devising more effective training strategies.
CCS CONCEPTS
• Security and privacy → Phishing; Usability in security and
privacy; • Human-centered computing → User studies.
KEYWORDS
Phishing, Social Engineering Attack, Usable Security, Personality
Traits, Natural Language Generation
ACM Reference Format:
Shahryar Baki, Rakesh M. Verma, and Omprakash Gnawali. 2020. Scam
Augmentation and Customization: Identifying Vulnerable Users and Arming
Defenders. In Proceedings of the 15th ACM Asia Conference on Computer and
Communications Security (ASIA CCS ’20), October 5–9, 2020, Taipei, Taiwan.
ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3320269.3384753
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ASIA CCS ’20, October 5–9, 2020, Taipei, Taiwan
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6750-9/20/10...$15.00
https://doi.org/10.1145/3320269.3384753
1 INTRODUCTION
So far, security has been addressed as mostly a technological prob-
lem and not enough from the human perspective, although the field
of usable/socio-technical security is trying to address this issue. De-
fenders scramble to produce detectors and patches for new and/or
evolving attacks. However, there is some evidence that phishing
detectors are not working well [24]. Researchers have raced to fill
the gap by proactively finding new attacks or vulnerabilities in soft-
ware, yet Internet users continue to fall prey to “classical” attacks,
such as phishing, spear phishing, and business email compromise,
as reported by the FBI, APWG [29], RSA, etc. For example, based on
Phishlabs 2017-18 reports, even though attacks on email and online
services are the top phishing targets, attacks on social media also in-
creased 70% from the first quarter of 2017 to its second quarter and
are four times the number of attacks during 2016 [48, 49]. Several re-
searchers studied deception and social engineering attacks on social
networks (SN) [56, 57] but none of them investigated the effective-
ness of SNs as a message delivery medium (facade). Researchers
in [7, 8] compared the users’ susceptibility to attacks delivered by
Facebook and email. Authors in [8] showed email-based attacks are
significantly more successful than Fakebook-based attacks, while
results of [7] showed the opposite. We use a professional network,
LinkedIn, as a platform to deliver messages to potential victims and
compare its effect on users’ judgment with the case where messages
are delivered by email.
Despite the emergence of several platforms and tools for elec-
tronic communication (e.g., SMS, collaboration sites and apps, social
media), email continues to be a dominant channel for communica-
tion. Radicati Group estimates that 293 billion emails were sent in
2019 [54]. Email attacks remain one of the most popular ways to
steal user’s information or bring even a well-protected company to
its knees. Almost every user has received phishing and malware
emails. In a more targeted variation of phishing attacks, called
spear-phishing, attackers try to customize the content for a specific
group or person to make it more credible. Spear-phishing attacks’
superior effectiveness (compared to regular phishing) in fooling
Internet users has been studied [13]. But these attacks require some
level of effort by attackers to gather the required information about
the target individual or group, which makes them harder to conduct.
In this work, we seek to answer whether the trouble of generating
spear-phishing attacks is necessary to fool normal users. We show
that some basic customization (e.g., adding fake signature to the
email) is enough to deceive users. Furthermore, we focus on under-
standing how different aspects of an email-based attack contribute
to deception and action by the victim.
Company representation fraud (aka job scam) attacks have in-
creased in recent years [12, 46, 47]. Moreover, phishing detectors
Session 5: Usable Security & Privacy ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan236are not able to catch these frauds without retraining [1]. To gain
an understanding of the parameters contributing to deception and
action by the victim, we conduct a between-subjects study in which
we take a well-known attack, viz., job scam, and parameterize it
with signals such as surrounding context (facade) and customized
content. It helps us understand clues that Internet users rely on to
distinguish legitimate and fraudulent messages. We also consider
semi-automatic generation of such attacks using natural language
generation techniques (NLG) such as those employed in the Dada
tool [10]. This technique previously has been used successfully
for masquerade attack [5] but with short emails. With the recent
advancement of language modeling techniques using neural net-
works (NN) [19, 50, 58], some researchers used NN for generating
emails [18, 55], but could not generate coherent text. Our goal here
is to study whether a semi-automatic generation technique (Re-
cursive Transition Network) is “mature enough” so that it can be
deployed in credible attack generation. If defenders can synthesize
new attacks without too much trouble, then they can test their
techniques on new attacks rather than testing their methods on
classical attacks and always being one step behind the attacker.
To summarize, we make the following contributions:
• Analyzing users’ reasoning to understand the relationship
between their knowledge and their detection ability. Unlike
results in [44], we observe that participants are better at
distinguishing legitimate and phishing attacks as they pay
attention to more clues.
• Effectiveness of Recursive Transition Network as a Natural
Language Generation tool in producing credible company
representative fraud. Our results show that participants did
not notice any difference between human and computer-
generated emails. Surprisingly, the NLG-generated emails
performed better in fooling participants than the human-
generated ones on average.
• Studying the effect of using a professional network such as
LinkedIn on the success rate of phishing attacks. Our results
show an improvement in the success rate of attacks deliv-
ered by LinkedIn compared to attacks delivered by Gmail
although it was not statistically significant. For legitimate
offers, our study shows that participants trust offers received
via LinkedIn more (the difference is significant).
• Studying the effect of basic customization techniques on
perceived email credibility. We show that adding sender’s
contact information to the email’s signature and also putting
receiver’s name in the greeting increases the credibility of
emails (both legit and fraud).
• Our results show that people who use laptops or personal
computers spend more time and are more accurate in detect-
ing legitimate and fake offers (mobile users spend signifi-
cantly lower time reading emails).
Insights from our work can help both security providers and
email users to protect themselves from being a victim. Defenders
can use NLG techniques to create more diverse or even newer at-
tacks. Our results suggest that email training programs need to
focus more on younger adults, mobile users, and on spear phishing
emails. Our observation on participants’ reasoning and its rela-
tionship with their ability in detecting attacks show that users are
capable of detecting attacks if they know the clues. Designing better
training/warning programs to properly prepare users for finding
these clues is one way of using this knowledge.
2 TERMINOLOGY AND HYPOTHESES
Before listing our hypotheses, we explain the terminologies and
tools that we use during this study. We use existing fake and le-
gitimate company representative offers as a basis for our study.
We collect legitimate offers from Glassdoor1 and Indeed,2 online
employment-related search engines. For fake offers, we use the
Joewein Company Representative Scam Dataset.3 In the rest of
this section, we describe the “representative offers” as well as the
natural language generation technique that we use to generate the
offers. Then we present the list of hypotheses.
2.1 Representative Offer
The fake company representative offers (abbr. representative of-
fer) claim to seek representatives in other countries, for collecting
money from customers on behalf of the company they will repre-
sent. The original company representative fraud emails that we got
from the Internet have some typos and grammatical mistakes. We
do not edit them since our goal is to discover whether participants
pay attention to such details and to elicit their inferences.
2.2 Natural Language Generation & Dada
NLG is a challenging research area in which the goal is to gen-
erate coherent, human-like text. The Dada engine [11] has been
previously used to construct short masquerade emails [5] as well
as academic papers on postmodernism [10]. It is a text generation
tool based on the recursive transition network (RTN). RTN is a
schematic representation of grammar with different paths which
leads to different sentences.
The building block of the NLG is a dataset of actual texts from
which we can extract grammar rules. We used the dataset of com-
pany representative scams to create rules for Dada engine. We also
used scams from the dataset directly in our study. One of the au-
thors with some previous experience on RTNs spent 4-5 hours to
review 100 job scams to construct a structure for the generated
text. We split emails into several parts: greeting, sender informa-
tion, company description, job description, closing, and signature.
Separate grammars have been created for each of these parts with
some shared variables among them to keep them consistent (e.g. if
a sender introduces him/herself as a recruiter, the signature should
match it). For the company names, we used GlobalTrade website4
and randomly chose 12 companies and their field of work to use in
our grammar. A total of 100 emails were created and we randomly
chose two of them for this study.
Before describing the experimental design, we briefly mention
our hypotheses and their importance.
1https://www.glassdoor.com/index.htm
2https://www.indeed.com/
3http://www.419scam.org/419representative.htm
4https://www.globaltrade.net/global/Sales-and-Distribution/expert-service-
provider.html
Session 5: Usable Security & Privacy ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan2372.3 Hypotheses
Some social networks like LinkedIn and XING are designed for
professionals. Members may trust messages received in their pro-
fessional network more than an email from a random person. At-
tackers can utilize professional networks as a medium for delivering
their messages to improve the success rate of the attacks. Hence,
understanding the threat posed by these networks requires further
examination to improve both human training and detection systems.
Therefore, this study tests the effect of using professional social
networks as a medium for delivering attacks instead of traditional
email-based phishing attacks by posing the following hypothesis:
H1. Using LinkedIn as an infrastructure for sending phishing
emails improves the effectiveness of the attack compared to
traditional email-based attacks.
A representative offer is mostly a fixed offer which is sent to
a huge number of random recipients. In spear-phishing attacks,
attackers try to customize the message exactly for a specific person,
but this necessitates a sufficient knowledge of the victim and also
lots of time to gather this information. In this study, we want to
test how effective is basic customization, such as adding victims’
name in the email, in increasing their susceptibility. Having some
basic knowledge of the effectiveness of these techniques in fooling
people is an indicator of how much attention should be devoted
to these signals in training programs and also which emails will
require more work in detection. So, in this study we also pose the
following hypotheses:
H2.a. Adding the recipient’s name in the greeting of the email de-
creases the detection rate of a fraudulent representative offer.
H2.b. Adding email signature makes recipients feel the offer comes
from a legitimate source, thus it decreases the detection rate
of a fraudulent representative offer.
Creating phishing emails is a time-consuming task, and repre-
sentative offers are no exception. Using NLG tools can help to speed
it up. This can be helpful for both attacker and defender. Attackers
can generate a variety of emails in a shorter amount of time and
defenders can automatically generate datasets to improve exist-
ing detection systems. On the assumption that this kind of attack
can mimic human writing, new detection techniques should be de-
signed in such a way to detect computer-generated emails as well.
Hence, we pose the following hypothesis to test the effectiveness of
a specific NLG tool called Recurrent Transitional Network (RTN):
H3. The detection rate of fake representative offers generated by
RTN is not significantly different from human-generated offers.
Besides testing these hypotheses, we also ask participants for
their reasoning in making their final decision. This will help us
to have a better understanding of the clues that people typically
use and whether these clues guide them to a safer decision or not.
They may miss an important clue or rely more than they should
on a red herring. For example, the second hypothesis (H2.a) is an
example of both useful and misleading clue. It is misleading in case
of spear-phishing emails in which attackers try to customize the
email for a specific person but useful in random phishing emails
that usually do not address recipients directly.
3 PILOT STUDY
Before running the actual experiment, we conducted a pilot study
with 34 participants [6]. Analysis of the data from the study showed
some unanticipated issues in the pilot study, which resulted in
several improvements to our initial design. Before describing the
final design of the experiment, we briefly discuss the lessons learned
from the pilot study. The detailed result of the pilot study is reported
in [6].