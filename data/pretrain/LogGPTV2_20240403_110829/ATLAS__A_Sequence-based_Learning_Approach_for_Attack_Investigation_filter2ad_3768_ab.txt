3008    30th USENIX Security Symposium
USENIX Association
Non-attack entityAudit LogsABCDEFt6t7t1t4t2t3Bt1ABt2CAt7ECDt3BABCAt7ECDt3t2t1Dt4BBABCAt7ECDt3t2t1Dt4BDt5F……BABCAt7ECDt3t2t1Dt5FEt6FProcesswrite File; ProcessExecute File; ….; t1t2CBCBSequence-based Model Learning12Sequence ConstructionSequence LemmatizationGraph ConstructionProcesswrite File; ProcessExecuteFile; ….; Sequence embedding4Sequence to Numerical vector representationAttack Seq.Non-attack Seq.......LSTM Training5Balanced Sequences........Selective Sequence Sampling3ModelAttack Seq.Normal Seq.Attack entityAttack Symptom Entity(e.g., malicious host)ModelAttack StorySequence Construction and LemmatizationSequence embeddingAttack/non-attack entity inferenceAttack Investigationbasuspicious hostname. Here, ATLAS aims at identifying enti-
ties among many unknown entities that are involved in attack
phases together with the attack symptom entity. To do so,
ATLAS uses the attack symptom entity together with each
unknown entity, constructs sequences, and uses the trained
model to identify whether a sequence is attack or non-attack.
If a sequence is classiﬁed as an attack, ATLAS infers that the
unknown entity is an attack entity. This process helps reduce
the time needed to investigate large causal graphs and accel-
erates the attack investigation by identifying the key attack
entities that make up the attack story.
Design Challenges. Developing ATLAS for effective and scal-
able attack investigation raises a set of unique challenges.
Below we present these challenges and how we address each.
The ﬁrst challenge concerns constructing sequences to
model legitimate and suspicious activities. We aim at ﬁnding
sequences that can better separate benign and malicious ac-
tivities, and generalize sequences extraction across different
audit log types. In traditional sequence problems [15], this
poses two challenges to obtain the sequences from audit logs.
First, there exists a huge number of unique entities in audit
logs, such as different processes with multiple instances, and
each entity set (i.e., combination) maps to a different arbitrary
length sequence. Second, the same attack patterns occurring
in different process executions lead to different sequences
with the same or highly similar sequence contexts. These may
lead to long and repeating entity-based sequences affecting
the model convergence and precision in learning (e.g., van-
ishing and exploding gradients [14]). To address these issues,
ATLAS applies a customized graph-optimization to reduce
graph complexity (see Sec. 4.1). As a result, short yet appro-
priate length sequences are obtained. Additionally, ATLAS
implements a novel technique to extract and learn sequences
that properly represent attack patterns (see Sec. 4.2).
A second challenge concerns the model learning from se-
quences. Attack investigation is historically similar to “ﬁnding
needles in a haystack”, where many activities are monitored,
and only a few of them signal a true attack. This results in
imbalanced datasets consisting of under-represented attack se-
quences and over-represented non-attack sequences. At attack
investigation, the curse of imbalanced sequences substantially
undermines the learning process [38] and tends to bias the
model towards non-attack sequences, leaving a number of
attack sequences undetected. To address this issue, ATLAS
implements under-sampling to reduce the number of non-
attack sequences and over-sampling to generate extra attack
sequences, obtaining an appropriate balancing ratio between
attack and non-attack sequences (see Sec. 4.2.3).
The third challenge is the automated attack investigation
using the trained sequence-based model. Though ATLAS sup-
ports querying arbitrary sequences on the model and reports
whether the sequence is attack or non-attack, the generation
of such sequences by investigators is ad-hoc and may require
the ﬁnding of many sequences with candidate attack entities.
Figure 4: Illustration of graph optimization in ATLAS. P:
Process, S: Session, A: IP Address, D: Domain name.
To address this issue, ATLAS includes an attack investigation
phase, which thoroughly analyzes entities in audit logs to
identify attack entities that form an attack sequence when
paired with an attack symptom entity. Thus, it is able to com-
prehensively recover those attack entities that help build the
attack story more accurately and efﬁciently (see Sec. 4.3).
4 ATLAS
In this section, we detail the ATLAS architecture introduced
in Figure 3. We start with an audit log pre-processing phase
that constructs and optimizes the causal graph for scalable
analysis (Sec. 4.1). We then present a sequence construc-
tion and learning phase that constructs attack and non-attack
sequences for model learning (Sec. 4.2). Lastly, we present
an attack investigation phase that uses the model to identify
attack entities, which helps build the attack story (Sec. 4.3).
4.1 Audit Log Pre-processing
For model learning and attack investigation, ATLAS starts by
transforming audit logs into a platform-independent causal
graph to extract sequences. Here, we build an optimized causal
graph that reduces logs complexity (i.e., reducing the number
of nodes and edges) without sacriﬁcing key semantics for
attack investigation. A less complex graph leads to shorter se-
quences, a crucial metric that guarantees the efﬁcacy and preci-
sion of the sequence-based model learning. ATLAS uses three
techniques for causal graph optimization. First, ATLAS elimi-
nates all nodes and edges which are not reachable from the
attack nodes (in model learning) or the attack symptom node
(in attack investigation). Second, ATLAS constructs the causal
graph from the audit logs with non-repeating edges, thus, we
drop all repeated edges except the edge of the ﬁrst occurrence
of an action (e.g., read or write) between a subject and an
object entity, regardless of how many times an action is re-
peated. As shown in Figure 4, for nodes P1 and A1, among the
two events (P1, connect, A1, T2) and (P1, connect, A1, T9)
which have the same action (connect), ATLAS only considers
the event with the earliest timestamp (T2) for constructing the
causal graph. Third, ATLAS combines certain nodes and edges
if they refer to the same type of events. Turning to Figure 4,
the session nodes S1, S2 and S3 are combined into one node
S1 − S2 − S3, as they share the same incoming-edges (bind)
USENIX Association
30th USENIX Security Symposium    3009
Figure 5: (Middle) An example causal graph to illustrate sequence construction process. (Left) Attack sequence extraction steps.
(Right) Non-attack sequence extraction steps.
and outgoing-edges (send). During this process, ATLAS as-
signs the earliest timestamp of their original edges to the new
edge. While this might break the original temporal order of
events when building the sequence, it does not affect the iden-
tiﬁcation of expected attack patterns, as the temporal order of
events in constructed sequences are consistent between the
model learning and attack investigation phases. Through this
process, ATLAS achieves on average an 81.81% reduction in
terms of the number of the entities, compared to the original
causal graph (see Sec. 6.3).
4.2 Sequence Construction and Learning
ATLAS transforms the causal graph into sequences labeled ei-
ther “attack” or “non-attack” (Sec. 4.2.1), and extends lemma-
tization and selective sampling into the sequence construc-
tion to effectively abstract attack and non-attack patterns
(Sec. 4.2.2-4.2.3). Lastly, it uses word embedding to convert
sequences into vectors of real numbers and learns a sequence-
based model through LSTM (Sec. 4.2.4).
4.2.1 Attack and Non-attack Sequence Extraction
ATLAS uses attack entities as ground-truths to extract attack
and non-attack sequences for model training. The entities
such as a malicious host-name and payload known to us at
attack execution are labeled “attack” and other entities are
labeled “non-attack". The attack entities here are the ones that
can only be associated with attack events. We use this criteria
to distinguish them from non-attack entities. We detail the
sequence extraction process below.
Attack Sequences. The attack sequences include temporally
ordered events of attack entities. ATLAS ﬁrst obtains a set of
all attack entities from a causal graph and constructs their
entity subsets that include two or more entities. For example,
Figure 5 (Middle) shows three attack entities {A, C, F} in a
causal graph, which have the attack subsets of {A, C}, {A, F},
{C, F} and {A, C, F} that include two or more entities. For-
mally, if a causal graph includes k attack entities, the number
of attack entity subsets is ma = ∑k
k is all possi-
ble subsets of choosing i attack entities from k. We note that
the number of attack entity subsets can be exponential when k
k, where Ci
i=2 Ci
(the number of attack entities) is large. However, in practice,
the number of attack entities are usually not large (e.g., less
than 40) as attackers normally try to hide and minimize the
traces of their activities. For instance, it is in an attacker’s best
interest of remaining stealthy to drop one backdoor (repre-
sented as one attack entity) instead of dropping n number of
backdoors (represented as n entities). For each attack entity
subset, ATLAS extracts an attack sequence from the optimized
causal graph through the following steps. First, for each entity
in the attack entity subset, ATLAS extracts its neighborhood
graph (see its deﬁnition in Sec. 2). This step enables ATLAS
to capture all entities which have causal relations with an
attack entity. To illustrate, given an attack entity subset {A, C},
Figure 5 (Left) Step (1) shows neighborhood graphs of A
and C entities in dashed circles. Second, ATLAS obtains the
attack events ordered by timestamps from the constructed
neighborhood graph. An event is labeled attack if the source
or destination node represents an attack entity. For instance,
the extracted attack events for the subset {A, C} are shown
in Figure 5 (Left) Step (2), where attack events represent
timestamp-ordered nodes connected by edges extracted from
the neighborhood graph of the attack entities A and C. Lastly,
ATLAS converts the extracted timestamp-ordered attack events
to a sequence, and labels it as attack if (a) it only consists of
attack events, and (b) it includes all the attack events of the
entity subset. For example, the extracted sequence for the sub-
set {A, C} is labeled attack, since it consists of all the attack
events that contain the attack entities A or C.
Non-attack Sequences. A naive approach to identify non-
attack sequences would be similar to constructing attack se-
quences. That is, obtaining all non-attack entities in a causal
graph and extracting their sequences by following the steps
above. However, this process is complicated due to the ex-
ponential number of non-attack entities. We note that AT-
LAS does not attempt to learn or identify any benign activity
(i.e., non-attack sequences). Instead, it aims to accurately
learn and identify the boundary between malicious and non-
malicious activities. To this end, ATLAS adds a non-attack
entity to each attack subset to extract a non-attack sequence.
The added non-attack entity can potentially add non-attack
events into the sequence, which enables ATLAS to extract
attack-sequence deviations (i.e., non-attack sequences), and
3010    30th USENIX Security Symposium
USENIX Association
Sequence extraction steps given attack entities {A, C}(1) Extract entities neighborhood graphs(2) Extract timestamp-ordered eventsBT2. connectABT3. writeCCT4. executeBCT5. readDCT6. connectFABCDEFT1. writeT2. connectT4. executeT3.writeT5. readT6. connectAttack entityNon-attack entitySequence extraction stepsgiven entity subset {A, B}(1) Extract entitiesneighborhood graph(2) Extract timestamp-ordered eventsBT2. connectABT3. writeCCT4. executeBABCT2. connectT3. writeT4. executeCausal graphacbABCT2. connectT3. writeT4. executeDFT5. readT6. connectTable 1: Abstracted vocabulary set for lemmatization
Type
Vocabulary
process
ﬁle
network
actions
system_process, lib_process, programs_process, user_process
system_ﬁle, lib_ﬁle, programs_ﬁle, user_ﬁle, combined_ﬁles
ip_address, domain, url, connection, session
read, write, delete, execute, invoke, fork, request, refer, bind
receive, send, connect, ip_connect, session_connect, resolve
k
i=1 Ci
to precisely learn the similarities and differences between
attack and non-attack sequences. Formally, if a causal graph
includes k attack entities and k′ non-attack entities, the num-
k.k′, where Ci
ber of non-attack entity subsets is na = ∑k
is all possible subsets of choosing i attack entities from k.
Figure 5 (Middle) shows three attack entities {A, C, F} used
to extract all possible attack subsets {A}, . . . , {A, C, F} that
include one or more attack entities. To generate non-attack
entity subsets, ATLAS appends one entity at a time from the
three non-attack entities {B, D, E} to the extracted attack entity
subsets. For each non-attack entity subset, ATLAS then extracts
non-attack sequences from the causal graph similar to attack-
sequences through the following steps. First, for each entity
in the subset, ATLAS extract the neighborhood graph for the
entity node. For example, for the non-attack entity subset
{A, B}, ATLAS extracts the neighborhood graph for entities A
and B as shown in Figure 5 (Right) Step (1). Second, ATLAS
extracts the ordered events from the neighborhood graph.
Figure 5 (Right) Step (2) shows the extracted events for the
non-attack entity subset {A, B}, which includes ordered events
represented by edges extracted from the neighborhood graph
for entities A and B. Lastly, ATLAS labels a sequence as non-
attack if it does not match any extracted attack sequence,
otherwise, the processed sequence is discarded. For example,
the extracted sequence for the subset {A, B} is labeled as a
non-attack because it does not match any attack sequence.
Sequence Length and Number of Sequences. The sequence
length is the total number of entities and actions in a sequence.
The sequence construction process of ATLAS does not lead
to ﬁxed-length sequences as each sequence may consist of
different number of events obtained from a causal graph. Fur-
ther, the number of attack and non-attack sequences extracted
from a casual graph depends on the size of the causal graph,
which can include different numbers of entities and events
associated with the attack and non-attack entities. Therefore,
ATLAS can extract varying lengths and numbers of attack and
non-attack sequences from a given causal graph.
4.2.2 Sequence Lemmatization
ATLAS uses lemmatization to transform the sequences into a
generalized text representing the sequence patterns for seman-
tic interpretation. Lemmatization is often applied in natural
language processing to group differently inﬂected forms of
a word as a single term [37]. This process retains the orig-
inal semantics of the complete sequences and is conducive
to sequence-based model learning. Table 1 shows the four
different vocabulary types and the vocabulary in each type
that ATLAS uses to abstract entities and actions in a sequence.
The vocabulary includes a total of 30 words, which reduces
inﬂectional forms and derivationally related forms of words
to a common base form. The vocabulary is grouped into
four different types based on ﬁne-grained semantics of the
words: process, ﬁle, network, and actions. The process, ﬁle
and network types are used to lemmatize entities. These types
are sufﬁcient to capture the context of entities in a causal
graph, semantic and syntactic similarity and relation with
other words. ATLAS parses each sequence, ﬁnds the enti-
ties and map each of them to a corresponding vocabulary.
For example,  is transformed to . Overall, the sequences after lemmatiza-
tion process are transformed into a “sentence-like” intermedi-
ate representation which contains the full semantics of gen-
eralized sequence patterns. We note that undesired repeating
of attack and non-attack sequences may occur after lemma-
tizing the sequences. To train the model with non-repeating
sequences, we discard all non-attack sequences that overlap
with an attack sequence before they are passed to the selective
sequence sampling, detailed next.
4.2.3 Selective Sequence Sampling
The number of attack and non-attack sequences constructed
can be imbalanced. The reason is that there are generally
fewer attack entities than non-attack entities in the log entries.
For example, we found in our evaluation by analyzing audit
logs that the average number of attack entities is 61, while the
average number of non-attack entities is around 21K. Train-
ing the classiﬁer using such an extremely imbalanced dataset
would make it either biased in favor of the majority (non-
attack) class or unable to learn the minority (attack) class [14].
To balance the training dataset, ATLAS ﬁrst undersamples non-
attack sequences with a certain similarity threshold. Then, it
uses the oversampling mechanism to randomly mutate those
attack sequences, until their total number reaches the same
number of non-attack sequences. A naive technique to balance
a training dataset would be to either duplicate the sequences
in the minority attack sequences or randomly remove a subset
of the sequences in the majority non-attack sequences. Un-
fortunately, our initial prototype showed that this leads to a
model that over-ﬁt to speciﬁc attack patterns or miss many
important non-attack patterns. To address these issues, ATLAS
uses two mechanisms detailed below.
Undersampling. ATLAS reduces the number of non-attack
sequences through Levenshtein Distance [3] to compute the
similarity among lemmatized sequences. it then ﬁlters out
sequences when their similarities exceed an identiﬁed thresh-
old. While Levenshtein Distance is often applied in NLP to
ﬁnd the similarity between sentences, ATLAS computes the
number of editing steps such as adding or deleting vocabu-
USENIX Association
30th USENIX Security Symposium    3011
lary words in a sequence to transform a sequence to another
lemmatized sequence. The complexity of this process for all
sequences in a training set is O(n2). For each sequence, ATLAS
removes the sequences when their similarity exceeds a certain
threshold. Particularly, through our experiments, we found
that a threshold of 80% similarity between sequences yields a
good undersampling ratio that sufﬁciently ﬁlters out highly
similar and redundant sequences.
Oversampling. ATLAS employs a mutation-based over-
sampling mechanism to include a larger variety of attack
sequences to the training sequences. Recall that ATLAS
deﬁnes different vocabulary words that represent differ-
ent processes and ﬁle types (e.g., system_process and
program_process). Here, for each extracted attack sequence
after lemmatization, ATLAS randomly mutates one vocabulary
word type to another vocabulary word of the same type. This
process does not fundamentally change the mutated sequence.
However, it increases the number of similar sequences not
triggered in the attacks used for model training yet may still
occur in other attacks due to contextual differences.
4.2.4 Sequence Embedding and Model Learning
ATLAS uses word-representations embedding [30] to trans-
form the lemmatized sequences into a generalized text rep-
resenting the sequence patterns for semantic interpretation.
This process retains the original semantics of the complete
sequence and is conducive to sequence-based model learning.
Sequence Embedding. ATLAS integrates word embedding
into model learning to transform the lemmatized sequences
into numerical vectors. Word embeddings such as word-
representations [30] and word2vec [29] have been widely
used in NLP for text representations, since they precisely in-
fer the semantic relations between different words. These
vectors deﬁne a domain-speciﬁc semantic relationship be-
tween the vocabularies and help in highlighting the patterns
of different sequences for model training. The corpus used
for training the word embeddings includes all the lemmatized
attack and non-attack sequences from the audit logs. The em-
bedded sequences improve model learning compared to other
widely used approaches such as one-hot-encoding [40]. We
will present their detailed comparison in Sec. 6.3.
Sequence-based Model Learning. ATLAS uses the Long