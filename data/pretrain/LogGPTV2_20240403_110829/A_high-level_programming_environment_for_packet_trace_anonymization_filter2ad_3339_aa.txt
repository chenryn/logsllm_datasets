title:A high-level programming environment for packet trace anonymization
and transformation
author:Ruoming Pang and
Vern Paxson
A High-level Programming Environment for Packet Trace
Anonymization and Transformation
Ruoming Pang
Department of Computer Science
Princeton University
PI:EMAIL
Vern Paxson
International Computer Science Institute
PI:EMAIL
ABSTRACT
Packet traces of operational Internet trafﬁc are invaluable to net-
work research, but public sharing of such traces is severely lim-
ited by the need to ﬁrst remove all sensitive information. Current
trace anonymization technology leaves only the packet headers in-
tact, completely stripping the contents; to our knowledge, there
are no publicly available traces of any signiﬁcant size that contain
packet payloads. We describe a new approach to transform and
anonymize packet traces. Our tool provides high-level language
support for packet transformation, allowing the user to write short
policy scripts to express sophisticated trace transformations. The
resulting scripts can anonymize both packet headers and payloads,
and can perform application-level transformations such as editing
HTTP or SMTP headers, replacing the content of Web items with
MD5 hashes, or altering ﬁlenames or reply codes that match given
patterns. We discuss the critical issue of verifying that anonymiza-
tions are both correctly applied and correctly speciﬁed, and expe-
riences with anonymizing FTP traces from the Lawrence Berkeley
National Laboratory for public release.
1.
INTRODUCTION
Researchers often use tools such as tcpdump to capture net-
work packet traces. Packet traces recording real-world Internet traf-
ﬁc are especially useful for research on trafﬁc dynamics, protocol
analysis, workload characterization, and network intrusion detec-
tion. However, sharing of Internet packet traces is very limited
because real-world traces contain many kinds of sensitive infor-
mation, such as host addresses, emails, personal web-pages, and
even authentication keys. The traces must be ﬁrst “anonymized”
to eliminate any private information (e.g,, IP addresses, user IDs,
passwords) before they can be shared among researchers.
To date, Internet packet trace anonymization has been limited to
only retaining TCP/IP headers [21, 17], with IP addresses renum-
bered and packet payloads completely removed. To our knowl-
edge, there are no publicly available traces of any signiﬁcant size
that contain TCP payloads. The lack of such traces greatly lim-
its research on application protocols. It is especially crippling for
network intrusion detection research, forcing researchers to devise
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’03, August 25–29, 2003, Karlsruhe, Germany.
Copyright 2003 ACM 1-58113-735-4/03/0008 ...$5.00.
synthetic attack traces that often lack the verisimilitude of actual
trafﬁc in critical ways, resulting in errors such as grossly underes-
timating the false positive rate of “anomaly detection” techniques.
[10, 1]
In this work we develop a new method to allow anonymization
of packet payloads as well as headers. Traces are processed in three
steps:
1. Payloads are reassembled and parsed to generate application-
protocol-level, semantically meaningful data elements.
2. A policy script transforms data elements to remove sensi-
tive information and sends the resulting elements to the com-
poser.
3. The trace composer converts application protocol data ele-
ments back to byte sequences and frames the bytes into pack-
ets, matching the new packets to the originals as much as
possible, in order to preserve the transport protocol dynam-
ics.
Parsing allows the trace transformation policy script to oper-
ate on semantically meaningful data elements, such as usernames,
passwords, or ﬁlenames, making policy scripts more concise and
comprehensible than those operating directly on packets or byte
sequences. Working at a semantic level also gives the opportu-
nity for less draconian anonymization policies. For example, the
added information that the string “root” appears in a ﬁlename
(“/root/.cshrc”) rather than as a username might, depending
on a site’s anonymization policy, allow the string to appear in an
anonymized trace, whereas a purely textual anonymization would
have to excise it, because it could not safely verify that the occur-
rence did not reﬂect a username.
The design of trace composer aims to generate “correct” traces,
for instance, as payload data is modiﬁed, checksums, sequence
numbers, and acknowledgments will be accordingly adjusted. The
output traces just look as if they were collected from the real Inter-
net, except that they do not carry private information. Accordingly,
analysis tools that work on raw traces will likewise work on the
anonymized traces.
In order to make the anonymization process amenable to valida-
tion, we follow a “ﬁlter-in” principle throughout our design of the
anonymizer: instead of focusing on “ﬁltering out” sensitive infor-
mation, the anonymizer focuses on what, explicitly, to retain (or
insert, in a modiﬁed form) in the output trace. With this principle,
it becomes much easier to examine a policy script for privacy holes.
An optional “manual inspection” phase can keep more nonsen-
sitive information in the output trace as the general anonymization
script may have to make conservative judgments for some data el-
ements; for example, whether to allow the command “UUSER” to
appear in a trace of anonymous FTP trafﬁc (the presence of such
a typo can be useful for some forms of analysis, such as anomaly
detection).
We implemented the anonymizer as an extension to Bro [16], a
network intrusion detection system, to take advantage of its appli-
cation parsers and its built-in language support for policy scripts.
Beside anonymization, our tool can also be used for generic trace
transformations, providing a great degree of freedom and conve-
nience for various types transformation. For example, we can take
a trace of FTP trafﬁc and remove from it all the connections for
which the user name was not “anonymous”; or all the ones for
which the FTP authentication was unsuccessful; or those that do
uploads but not downloads. A different type of transformation is
for testing network intrusion detection systems by inserting attacks
into actual background trafﬁc by slightly altering existing, benign
connections present in a trace. Still another type of transformation
is to remove large Web items from HTTP connections (including
persistent sessions with multiple items) in order to save disk space
(see Section 3.4 below).
In a sense, the tool spells the end of traces as being stand-alone
evidence of any sort of activity, since it makes it so easy to modify
what a trace purports to show.
We developed trace transformations for FTP, SMTP, HTTP, Fin-
ger, and Ident. As a test of the approach, we anonymized FTP traces
from the Lawrence Berkeley National Laboratory (LBNL). Besides
testing the technology, one of the important questions behind the
exercise was to explore what sort of anonymizations a site might
require, and being willing to abide, for public release of traces with
contents. To this end, working with the site we devised an anonymi-
zation policy acceptable to the site and approved for public release.
The corresponding traces are available from [6].
The rest of this paper is organized as follows. In the next section
we present our goals. We describe generic packet trace transforma-
tion in Section 3, trace anonymization in Section 4, and unsolved
problems and new directions in Section 5. We discuss related work
in Section 6 and summarize in Section 7.
2. GOALS
We designed the transformation tool with the following goals in
mind:
1. Policy scripts operate on application-protocol-level data val-
ues. This means that instead of operating on packets or TCP
ﬂows, a policy script sees typed and semantically meaning-
ful values (e.g., HTTP method, URI, and version). Likewise,
the trace transformation scripts also specify application-
protocol-level data to the output trace, without needing to
dictate the details of generating the actual packets.
2. The output traces contain well-formed connections: pack-
ets have correct checksums and lengths, TCP ﬂows can
be reassembled from the resulting packets, and application-
protocol data has correct syntax1, so that other programs can
process the transformed traces in the same way that they han-
dle original tcpdump traces.
3. The mechanism supports generic trace transformations be-
sides anonymization.
4. The anonymization is “fail safe” and amenable to veriﬁca-
tion. Fail-safety means that the privacy resulting from the
anonymization does not depend on the tool and the policy
1Or not, if the policy script decides to keep the “dirtiness” of the original
trace.
Figure 1: Data Flow in Trace Transformation
script being completely correct. Being amenable to veriﬁ-
cation means it is easy to examine and validate the policy
script, the anonymization process, and the output trace.
The ﬁrst and third goal dictate where to separate mechanism and
policy: 1) the mechanism part should parse the input trace to expose
all application-protocol semantic elements, e.g., commands, reply
codes, MIME header types; 2) the mechanism should not restrict
how the values will be changed, but leave that to the policy script.
We will discuss mechanism and anonymization policy in the next
two sections, respectively.
3. GENERIC TRACE TRANSFORMATION
Trace transformation consists of three steps: parsing, data trans-
formation, and composition. These are shown as the right-hand
components of Figure 1. The parsing and composition parts do not
depend on the type of trace transformation, and we have imple-
mented them in Bro as built-in mechanisms. The second step (data
transformation) is fully programmable, however, and so is imple-
mented as a Bro policy script.
We will ﬁrst look at the process from the viewpoint of the policy
script, focusing on the trace input/output interface, and then discuss
details of trace parsing and composition.
3.1 Policy Script Programming Environment
The Bro policy script language is procedural, with strong typ-
ing that includes support for several network-speciﬁc types (e.g.,
addresses and ports), as well as relative and absolute time, aggre-
gate types (associative tables, records), regular expression match-
ing, and string manipulation. More details about Bro language can
be found in [16, 15].
From the point of view of a policy script, the parsing part is Bro’s
event engine, and the composer is a family of library functions,
which we call “rewrite functions”.
A policy script for a protocol usually contains several “event han-
dlers”, which are execution entry points of the script. Through
event parameters, each event handler receives protocol-semantic
data elements as well as a record corresponding to the particular
TCP connection. An event handler may call other functions to pro-
cess the data, and writes the transformed data to the output trace
by calling the rewrite functions. When calling a rewrite function,
the policy script speciﬁes a connection, and sometimes also direc-
tion of the ﬂow, to write the data to. The destination connection is
usually the same connection of the event, but can also be any other
connection present in the input trace at the same time.
From:\r\n”
C will generate the event:
“MAIL
connection
an SMTP message
For
example,
arriving
a
line
in
on
smtp_request(
conn: connection = C,
command: string = "MAIL",
argument: string = "From: ")
The policy script receives the command and argument and decides
what to write to the output trace—e.g., it could call:
rewrite_smtp_request(
C,
"MAIL",
"From: ")
to change the sender in the trace from “PI:EMAIL” to
“name123@domain111”.
There is usually a correspondence between protocol events and
rewrite functions: e.g., for event smtp_request, there is func-
tion rewrite_smtp_request, and they have the same or very
similar set of parameters.
Explicit Rewriting: Note that the trace composer API requires ex-
plicit rewrites, i.e., for a data element to get into the output trace, it
must be explicitly placed there by the policy script calling a rewrite
function. Alternatively, another style we could have chosen for the
composer API would be to have the policy script only specify data
elements that should be changed, and pass the rest through unmod-
iﬁed. With this style, we could implement a single generic interface
by which scripts would directly specify the element to change. For
example, the SMTP rewrite above would be speciﬁed as:
modify_element(
smtp_request_arg,
"From: ")
and the composer would alter the location in output trace occu-
pied by the variable smtp_request_arg to contain the new text
rather than the original.
While appealing because a single rewrite function would suf-
ﬁce for all protocols (though the application parsers would have to
annotate each script variable with its location in the connection’s
byte stream), instead of having a family of rewrite functions for
various protocols, we choose the heavier API because it presents
a safer interface for trace anonymization. First, requiring explicit
rewrite forces the policy script writer to put consideration into ev-
ery element, so it will be less likely that they overlook a privacy
hole. Second, it is easier for other people to examine a policy script
for privacy leaks, as the examiner only needs to look at elements
written in the script (rather than having to keep in mind all the pro-
tocol elements that are implicitly not being changed because they
don’t show up in the script). This design choice shows how the
“ﬁlter-in” principle affects our design. Additionally, this interface