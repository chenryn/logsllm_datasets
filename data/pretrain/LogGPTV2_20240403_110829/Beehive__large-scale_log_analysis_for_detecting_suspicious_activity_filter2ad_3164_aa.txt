title:Beehive: large-scale log analysis for detecting suspicious activity
in enterprise networks
author:Ting-Fang Yen and
Alina Oprea and
Kaan Onarlioglu and
Todd Leetham and
William K. Robertson and
Ari Juels and
Engin Kirda
Beehive: Large-Scale Log Analysis for Detecting
Suspicious Activity in Enterprise Networks
Ting-Fang Yen
RSA Laboratories
Cambridge, MA, USA
PI:EMAIL
Alina Oprea
RSA Laboratories
Cambridge, MA, USA
PI:EMAIL
Kaan Onarlioglu
Northeastern University
PI:EMAIL
Boston, MA, USA
Todd Leetham
EMC Corp
Hopkinton, MA, USA
PI:EMAIL
Ari Juels
RSA Laboratories
Cambridge, MA, USA
PI:EMAIL
William Robertson
Northeastern University
PI:EMAIL
Boston, MA, USA
Engin Kirda
Northeastern University
Boston, MA, USA
PI:EMAIL
ABSTRACT
As more and more Internet-based attacks arise, organiza-
tions are responding by deploying an assortment of security
products that generate situational intelligence in the form
of logs. These logs often contain high volumes of inter-
esting and useful information about activities in the net-
work, and are among the ﬁrst data sources that informa-
tion security specialists consult when they suspect that an
attack has taken place. However, security products often
come from a patchwork of vendors, and are inconsistently
installed and administered. They generate logs whose for-
mats diﬀer widely and that are often incomplete, mutually
contradictory, and very large in volume. Hence, although
this collected information is useful, it is often dirty.
We present a novel system, Beehive, that attacks the prob-
lem of automatically mining and extracting knowledge from
the dirty log data produced by a wide variety of security
products in a large enterprise. We improve on signature-
based approaches to detecting security incidents and instead
identify suspicious host behaviors that Beehive reports as
potential security incidents. These incidents can then be
further analyzed by incident response teams to determine
whether a policy violation or attack has occurred. We have
evaluated Beehive on the log data collected in a large enter-
prise, EMC, over a period of two weeks. We compare the
incidents identiﬁed by Beehive against enterprise Security
Operations Center reports, antivirus software alerts, and
feedback from enterprise security specialists. We show that
Beehive is able to identify malicious events and policy viola-
tions which would otherwise go undetected.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ACSAC ’13 Dec. 9-13, 2013, New Orleans, Louisiana, USA
Copyright 2013 ACM 978-1-4503-2015-3/13/12 ...$15.00.
http://dx.doi.org/10.1145/2523649.2523670
1.
INTRODUCTION
Protection of computing infrastructure in large organiza-
tions is a mounting challenge. Both generic malware and
targeted attacks (i.e., Advanced Persistent Threats (APTs))
are growing in sophistication and outstripping the capabil-
ities of traditional defenses such as antivirus software. At
the same time, administrators’ visibility into the posture
and behavior of hosts is eroding as employees increasingly
use personal devices for business applications. The tradi-
tional perimeters of organizations are breaking down, more-
over, due to new complexities in business intelligence shar-
ing, contractor relationships, and geographical distribution.
Many organizations are responding to this challenging land-
scape by deploying an assortment of security products that
enforce policies and generate situational intelligence in the
form of security logs. These products proxy web traﬃc,
detect malware infections, check for policy violations, im-
plement eﬀective authentication mechanisms, and perform
many other useful security functions.
These products yield logs that contain high volumes of
interesting and useful information about activities in the
network, and are among the ﬁrst data sources consulted by
security specialists when an attack is in evidence. For ex-
ample, authentication logs might suggest that an employee’s
account has been compromised because a login has occurred
from a region that the targeted employee has never visited.
As another example, web proxy logs might record which
site a victim visited before being compromised by a drive-
by download attack.
While it is standard practice to examine logs to discover or
conduct forensic analysis of suspicious activity in a network,
such investigation remains a largely manual process and of-
ten relies on signatures of known threats. A major challenge
is that security products often come from a patchwork of
vendors and are inconsistently installed and administered.
They produce log data with widely diﬀering formats, and
logs that are often incomplete, mutually contradictory, very
large in volume (e.g., security-relevant logs in a large enter-
prise grow by terabytes per day), and ﬁlled with non-speciﬁc
199
or spurious event records. Hence, although this collected in-
formation is useful, and is sometimes the only information
at hand, at the same time it is often dirty.
In this paper, we attack the problem of automatically
mining and extracting knowledge from the dirty log data
produced by a wide variety of security products in a large
enterprise. Our aim is to improve on signature-based ap-
proaches to detecting security incidents and instead achieve
behavioral detection of suspicious host activities that sig-
nal potential security incidents. These incidents can then
be further analyzed by incident response teams to deter-
mine whether a policy violation or attack has occurred. A
key insight of our approach is that behaviors observed in
enterprise settings are often signiﬁcantly more constrained
by policy and typical employee behavior than those on the
open Internet. Thus we can eﬀectively identify suspicious
activities by analyzing behaviors in enterprise-speciﬁc ways.
Our automated approach, called Beehive, has three layers:
(1) Functionality to parse, ﬁlter, and normalize log data us-
ing network-speciﬁc conﬁguration information; (2) Feature-
generators that process normalized log data to produce a set
of ﬁfteen distinct features for each host per day; and (3) A
detector that performs clustering over features to identify
outlying, suspicious periods of host activity, which the sys-
tem reports as incidents.
We have evaluated Beehive on the log data collected in
a large enterprise, EMC, over a period of two weeks. We
compare the incidents automatically identiﬁed by Beehive
against enterprise Security Operations Center reports, an-
tivirus software alerts, and feedback received from informa-
tion security specialists in the company. We show that Bee-
hive is able to identify a number of malicious events within
the enterprise network,
including malware infections and
policy violations, that otherwise go unnoticed by existing,
state-of-the-art security tools and personnel.
Our work makes the following contributions:
• We propose a novel automated approach called Bee-
hive that analyzes very large volumes of disparate log
data collected in large organizations to detect mali-
cious activity such as malware infections and policy
violations. Beehive leverages unique features of enter-
prise networks to produce accurate, actionable infor-
mation.
• We have evaluated Beehive on more than 6 terabytes of
log data and have correctly identiﬁed suspicious activ-
ities that went unnoticed by existing state-of-the-art
security tools and personnel.
• To the best of our knowledge, ours is the ﬁrst explo-
ration of the challenges of “big data” security analytics
for large volumes of disparate, real-world log data.
contacting an attack website, communicating with a C&C
server, or exﬁltrating data to a previously unseen external
destination. These behaviors may result from the automated
activities of malware (e.g, zombie machines in a botnet), di-
rect control of hosts by an attacker (e.g., through a remote
access Trojan), or benign users being tricked into dangerous
behavior (e.g., via phishing attacks).
The second scenario concerns host-based user activities
that violate enterprise policies. These activities are not nec-
essarily malicious in intent, but are potentially damaging to
the business, and thus undesirable. Examples include peer-
to-peer ﬁle sharing, instant messaging, multimedia stream-
ing, viewing of adult content, online gaming, and using prox-
ies and tunneling services in an attempt to bypass enterprise
ﬁrewalls and other network-perimeter security mechanisms.
2.2 Data
Beehive uses a wide range of logs generated by various net-
work devices, including web proxies that log every outbound
connection, DHCP servers that log dynamic IP address as-
signments, VPN servers that log remote connections to the
enterprise network, Windows domain controllers that log au-
thentication attempts within the corporate domain, and an-
tivirus software that logs the results of malware scans on
end hosts. These logs are stored in a commercial security
information and event management (SIEM) system.
All of these devices monitor and log the activities of enter-
prise hosts transparently, with the notable exception of the
web proxy. For every external destination, the web proxy
consults a list of domain reputation scores and site categories
maintained by the product vendor, and automatically blocks
the connection if the destination has a low reputation or is in
a prohibited category (e.g., adult-content sites). However,
if the destination is not on this list, the proxy displays to
the user a warning page describing the potential dangers of
connecting to an unknown destination. The user must then
explicitly click on a link to acknowledge agreement to the
company’s network policies, or not visit the site.
Beehive makes heavy use of the web proxy logs, since the
majority of network activity in the enterprise is over HTTP
or HTTPS. In addition, these logs include all ﬁelds in HTTP
headers, making them a particularly useful resource for un-
derstanding users’ browsing behavior, detecting suspicious
connections, and forensic analysis. Table 1 lists a subset of
the ﬁelds included in web proxy logs.
IP Header
Source/destination IP and port,
protocol
Transport Header
domain,
Destination
URL,
HTTP status code, web referer,
domain
domain
category, user-agent string
reputation,
2. PROBLEM AND CHALLENGES
Here we describe the threat model we address, the na-
ture of the log data on which the system operates, and the
challenges that arise in designing and evaluating Beehive.
2.1 Threat Model
Beehive aims to detect threats arising in two diﬀerent sce-
narios. The ﬁrst scenario involves a network host that is
infected or at imminent risk of infection. A host of this
kind may exhibit malicious or dangerous behaviors such as
Connection Attribute
Sent and received bytes, network
policy
Table 1: Fields in web proxy logs.
At EMC, 1.4 billion log messages are generated daily on
average, at a rate of around one terabyte a day. These “raw”
logs contain huge amounts of information about user and
host behaviors. They are also noisy — with non-standardized
timestamps, diﬀerent identiﬁers (i.e., some store a host’s IP
200
address, some the hostname, others the username) — and
can be truncated or arrive out of order. We discuss the
challenges of analyzing such “big data” in the next section.
2.3 Challenges
The massive number of events observed on a real-life en-
terprise network and logged inside the SIEM system poses a
major challenge (a “big data” problem) in log analysis and
detection of security incidents. As noted above, we observed
collection by the SIEM an average of 1.4 billion logs per
day in our case study. Timely detection of critical threats
by Beehive thus requires eﬃcient data-reduction algorithms
and strategies to focus on security-relevant information in
the logs.
A second challenge for Beehive is that of identifying mean-
ingful security incidents in the face of a signiﬁcant semantic
gap between the logs collected by the SIEM system and the
information that security analysts require to identify suspi-
cious host behavior. In our case, Beehive needs to produce
a daily report of suspicious hosts; however, most network
devices only log the IP addresses of network endpoints. As-
sociating IP addresses with speciﬁc hosts requires correla-
tion across diﬀerent logs, which can be especially challenging
when IP addresses are dynamically assigned in the network.
The situation is complicated still more by the fact that the
logging devices may be located in diﬀerent time zones (as is
typical for the infrastructure of a global organization), and
thus the timestamps they produce must be normalized for
accurate temporal correlation.
Finally, a major challenge in designing Beehive is the dif-
ﬁculty of evaluating its eﬀectiveness accurately, due to an
inherent lack of ground truth. Speciﬁcally, an enterprise
network typically has state-of-the-art security technologies
deployed both on the network perimeter and on hosts, and
security analysts actively work toward resolving known in-
cidents. As a result, real-life network data obtained from
such a network often lacks traces of known security threats.
For example, malware on hosts is often cleaned or quaran-
tined before becoming active, and accesses to botnet C&C
servers are often blocked by the ﬁrewall. Such threat reso-
lution prevents automatic testing of Beehive over a ground
truth of known malicious network traﬃc, as none is in ev-
idence. Many of the incidents identiﬁed by Beehive are in
fact unknown to security systems in use in the enterprise.
We therefore must rely on manual evaluation of the security
incidents and suspicious hosts identiﬁed by Beehive.
In designing Beehive, we explore and tackle these chal-
lenges of big data security analytics. Brieﬂy, in a pre-processing
phase, Beehive normalizes the timestamps of all log entries
to UTC, determines statically and dynamically assigned IP
addresses of hosts, and constructs bindings between hosts
and IP addresses, thus attributing every logged event to a
speciﬁc host. Beehive then extracts enterprise-speciﬁc fea-
tures for individual hosts, and clusters hosts with similar
suspicious behaviors. The resulting outlying clusters are
presented as incidents to be examined by security analysts.
To assess the eﬃcacy of Beehive in this study, we manu-
ally investigate its reported incidents with the help of our
enterprise’s Security Operations Center (SOC). Given exist-
ing enterprise resolution of attacks with known signatures,
of particular interest in our study is Beehive’s identiﬁcation
of network policy violations by users and of malware not
detected by current signature-based tools.
201
3. THE BEEHIVE SYSTEM
In this section we describe in detail the operation of the
Beehive system. We start by describing our approach to
remove noise and inconsistencies in the data collected by the
SIEM. We then discuss the selection of features distinctive to
an enterprise setting for detecting misbehavior. Finally, we
describe the unsupervised learning approach we employed
for generating incidents of anomalous host behavior.
3.1 Data Normalization
In order to address the challenges of dirty and inconsis-
tent data explained in the previous sections, Beehive pre-
processes the log data before starting its behavioral-analysis.
We explain diﬀerent stages of this process below.
Timestamp Normalization. In an enterprise running a
global network, devices that produce critical logs are located
in diﬀerent geographies. Moreover, these devices may times-
tamp logs diﬀerently, using their local time zones, UTC, or
other time representations. This results in log entries with
inconsistent timestamps that must be normalized to a stan-
dard representation before any temporal analysis becomes
accurate. While delegating the coordination of time set-
tings to network administrators may be feasible for small
networks, these approaches are unworkable at the scale of a
global enterprise.
Beehive addresses this problem by leveraging the common
use by enterprises of a central SIEM system for log man-
agement that tags each log entry with its own timestamp
tsiem, recording the time at which the log was received by
the SIEM. For each device that sends logs to the SIEM sys-