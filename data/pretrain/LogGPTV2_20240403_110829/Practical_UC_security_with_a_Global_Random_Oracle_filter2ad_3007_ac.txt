In the basic UC framework the environment Z cannot directly access to the ideal setup func-
tionality, but it can do so through the adversary. Namely, any query that Z wishes to make to the
ideal functionality G is observed by the adversary/simulator, who queries the ideal functionality for
Z and forwards the answer. This implicitly means that the setup G is treated as a “private subrou-
tine” of the protocol, and is thus local to the challenge protocol instance. For example, the CRS
functionality in the basic UC model is captured as a trusted setup that gives the reference string
only to the adversary and the parties running the protocol. Technically, this assumption allows the
simulator to program the CRS because the environment has no access to the “real” CRS.
2.2 JUC: UC with Joint State
The basic UC-framework demands that each execution of a protocol ρ is independent and uses
its own local setup functionality. Therefore, if one wants to analyze a protocol π which executes,
say t copies of ρ, one would need t independent instantiations of the setup functionality, e.g., t
independent CRS. However, in practice one wants to use the same setup, e.g., the same CRS, for all
9
executions of ρ. In order to reuse the same CRS in the UC-framework, one has to analyze the entire
system of t executions of ρ as a single unit. Indeed, early works in UC implemented directly the
multi-version of a functionality, e.g., functionality for multiple commitments Fmcom instead of just
functionality for a commitment Fcom, and prove security directly of Fmcom where all commitments
share the same setup.
In [CR03] Canetti and Rabin introduce Universal Composition with Joint State (JUC), and
a new composition theorem that allows to prove composition of protocols that share some state.
Continuing the example of Fmcom and the CRS setup, [CR03] introduces a mechanisms that allows
to do the following. Instead of designing a protocol that directly implements the multi-instance
version Fmcom, it is suﬃcient to provide a protocol that implements Fcom in the standard CRS
model and then “compile” Fcom into Fmcom using the same CRS.
A bit more precisely, functionality Fmcom is a multi-session functionality that has a global sid
and for each sub-session has a a sub-session id ssid. The idea of the compiler of [CR03] is to derive
fresh CRSssid for each ssid starting from a single CRS, and then run each execution of Fcom using
setup CRSssid.
In the JUC model the CRS is locally available to only a speciﬁc set of protocols. It is not a public
setup and cannot be used globally by any protocol. Thus, any protocol which is not pre-speciﬁed
in this set must use a freshly sampled CRS. Technically this means that again the environment Z
has not direct access to the CRS, but it needs to access it through the adversary/simulator, and
therefore the CRS is programmable.
The JUC can be seen more as a proof technique and does not provide a stronger level of security
than basic UC.
2.3 Generalized UC model
In both basic UC and JUC model, the environment is constrained: it does not have access to the
setup functionality. The consequence in practice is that a protocol proved secure in these models
is secure only if the setup is not public. In the CRS example, the CRS must be communicated
privately to the parties participating the protocol.
However this assumption might be too strong or impractical in real life applications where it
is instead more plausible that there is a single CRS published and used by many protocols, or, in
the case of PKI (Public Key Infrastructure), one party uses the same public key in all protocol
executions.
Ideally, one would like to have the nice modularity of the UC composition theorem that works
also in presence of a global setup that is available to all parties/protocol executions. In [CDPW07],
Canetti et al introduce the “Generalized UC model”: they provide the formalism to describe global
functionalities and show that the composition theorem still holds in this setting. The model of
[CDPW07] is very general as it considers general shared functionalities (not necessarily setup func-
tionalities). In the following we restrict our attention to setup functionalities only.
A setup functionality is global if it can be accessed by any protocol running in the system besides
the challenge protocol. To model this, [CDPW07] ﬁrst grants the environment the power of initiating
several sessions besides the challenge session, and second, allows the environment to access to the
setup functionality directly, without going through the simulator/adversary. This indeed captures
the fact that any protocol in the network can use the same setup1. The ﬁrst consequence of this
1 [CDPW07] actually considers also a simpliﬁed deﬁnition called externalized UC model, where the environment
10
modeling is that a global setup functionality must be non-programmable. Too see why, think of the
CRS setup: If the CRS is publicly available then the simulator cannot program it as the environment
Z can create new parties for arbitrary protocols – of which the simulator is not aware of – and
check the CRS.
It is easy to see that GUC security is impossible to achieve in the CRS model as the simulator
has no advantage over the adversary. In fact, as noticed in [CDPW07] it seems that any global
setup that provides only public information is of little help for the simulator as it does not provide
any trapdoor. Thus, achieving security in GUC model seems to require a special publicly available
resource that also “hides” a trapdoor.
Motivated by this intuition [CDPW07] introduces the Augmented CRS (ACRS for short), where
there is a public, global CRS consisting in signature veriﬁcation keys, one for each party participating
in the protocols. Additionally, associated to each veriﬁcation key, there is a secret signing key that
is not revealed to the parties. This is the trapdoor. An honest party never asks for the signing key.
The catch is that a corrupted party can ask for the signing key and this is the trapdoor that allows
the simulator to cheat in the simulation. At the same time, knowledge of her own signing key does
not help the real adversary to break the privacy of other parties.
Note that security in the ACRS model is preserved only for “pid-wise” adversary: Namely it
assumes that a party pid is corrupted in all the sessions that he plays. Also, note that even if
the environment does not instruct the adversary to actually get the private signing key, still the
simulator will ask the key to the ACRS functionality, i.e., a corrupt guy always gets the secret key.
2.4 Our Global Random Oracle Model
In this work we aim to use the random oracle as global setup functionality and achieve the stronger
GUC security using this setup.
Let us ﬁrst consider a simplistic candidate formulation for the global random oracle functionality:
When queried by anyone for a value x, the random oracle functionality simply checks if x was queried
before by anyone. If not, then it returns a freshly chosen random string of some pre-speciﬁed length.
If yes then the previously chosen value is returned again — even if the earlier query was made by
another party. No other information is disclosed to anyone. Let us call this functionality GsRO (where
the s stands for “strict”). While GsRO is natural, it seems to be of little help for proving security of
protocols. For one, GsRO does not allow the simulator to “emulate” the random oracle functionality
to the environment, or in other words to “program” the answers of the random oracle. Indeed, recall
that the environment can create additional parties that query GsRO and report the answer directly
back. More importantly, GsRO is of little help to the simulator for another reason: The environment
can obtain random-oracle values via the auxiliary parties, without having the adversary/simulator be
aware of the queried values or answers. This means that GsRO is essentially useless to the simulator.
Indeed, the impossibility results for UC computation in the plain model (e.g. [CF01, CKL03]) are
easily extendible to the GsRO model.2 And in fact, as mentioned earlier, [CDPW07] already observed
any global setup functionality that provides only public information cannot be useful for achieving
has direct access to the setup functionality but does not initiate any new session except the challenge session. The
access to the setup functionality allows Z to internally mimic the behavior of multiple sessions or more sessions of
the challenge protocol.
2Still, it should be kept in mind that having access to a random oracle such as GsRO is not something that can be
emulated in the standard model using an eﬃciently computable hash function family. In particular, the impossibility
results of [CGH98] still hold even with respect to this model.
11
Functionality GgRO
Parameters: output length (cid:96)(n) and a list ¯F of ideal functionality programs.
1. Upon receiving a query x, from some party P = (pid, sid) or from the adversary S do:
• If there is a pair (x, v) for some v ∈ {0, 1}(cid:96)(n) in the (initially empty) list Q of past
queries, return v to P . Else, choose uniformly v ∈ {0, 1}(cid:96)(n) and store the pair (x, v) in
Q. Return v to P .
• Parse x as (s, x(cid:48)).
If sid (cid:54)= s then add (s, x(cid:48), v) to the (initially empty) list of
illegitimate queries for SID s, that we denote by Q|s.
2. Upon receiving a request from an instance of an ideal functionality in the list ¯F, with SID
s, return to this instance the list Q|s of illegitimate queries for SID s.
Figure 1: GgRO
UC-security as the simulator has no advantage over the real adversary.
We can move forward using the observation that the Random Oracle does keep secret informa-
tion: the queries made by the parties. Such queries are the trapdoor that can allow the simulator
to extract crucial information from the adversary. We want to provide a reasonable formulation of
the global random oracle functionality that allows extractability of the queries.
First note that if we attempt to modify the deﬁnition of GsRO so that it will disclose to the simu-
lator all the queries made by other parties then we will again lose the usefulness of the functionality
altogether, since the adversary too would be able to see the queries made by uncorrupted parties.
Instead, we want to disclose only the queries made by the adversary/environment, while the queries
made by any honest party should be invisible to external entity.
The queries made by the dummy adversary are directly observed by the simulator. The problem
is: how to extract the queries made by the environment?
We propose the following mechanism. Queries are expected to have an explicit session identiﬁer
ﬁeld, namely, a query x is parsed as the pair x = (s, x(cid:48)) where s is the SID. The random oracle
continues to answer the queries as before, namely it answers with a random value. The only
diﬀerence is that some of the queries can be marked as “illegitimate” and potentially disclosed. Let
us explain when a query is illegitimate. Recall that in the UC framework, a party P is identiﬁed by
the unique pair (P ID, SID) where PID is the program identiﬁer and SID is the session identiﬁer.
Illegitimate queries are identiﬁed as follows. If the content of the SID ﬁeld of the query diﬀers from
the content of the SID ﬁeld of the querying party P , then the queries is considered “illegitimate”.
The functionality will record such queries and potentially disclosed to to the instance of F whose
SID is the one in the query.
Therefore, our global random oracle functionality answers the queries just like the strict GsRO,
but additionally it agrees to disclose, to some pre-speciﬁed set of ideal functionalities, the illegitimate
queries. We stress that illegitimate queries are answered as usual; they are just recorded separately
and potentially disclosed. We stress that the random oracle in not programmable. The resulting
random oracle functionality, denoted GgRO, is described in Fig. 1.
The rationale behind this way of deﬁning (il-)legitimate queries is the following. On the one
hand, it allows designing protocols where the legitimate participants make RO queries that are
12
never disclosed (simply preﬁx each query by the SID of the present session). Furthermore, it forces
an ideal functionality to explicitly represent the information that is leaked by ideal functionalities
regarding the oracle queries.
To further exemplify the properties of GgRO, let us consider the case of zero-knowledge protocols
in the presence of GgRO. Recall that the traditional ideal Zero Knowledge functionality, FZK, allows
a prover to convince a veriﬁer (whose identity is determined by the prover) of the correctness
of a statement without revealing any additional information, and without allowing the veriﬁer to
“transfer” the proof to another party. In contrast, as discussed in the Introduction, any proof in the
global ROM is inherently transferable: To transfer a proof to party C, the veriﬁer V simply lets C act
as the veriﬁer, and in particular have C make all the oracle queries herself. Consequently, any formal
modeling of the global ROM should mirror this property of the global ROM. Indeed, it can be seen
that FZK is not realizable if the parties only have access to GsRO. (Intuitively, disclosing the queries
of third parties to the adversary/simulator has the eﬀect that these third parties can no longer use
GgRO to verify claims made by parties that participate in the session under consideration. This, for
instance, means that GgRO can no longer be used, in the model, to “transfer” proofs made within
the session to third parties.) Further discussion on the deﬁnition of transferable Zero-Knowledge in
the gRO model can be found in Appendix A.
We now provide the formal deﬁnition of UC-security in the Global Random oracle model.
Deﬁnition 1. [UC-security in the Global Random Oracle Model.] Let Ft be an ideal m-
party functionality and π be a protocol. We say that Π UC-realizes Ft in the GgRO-hybrid model
if for any hybrid-model PPT adversary A, there exists an ideal process expected PPT adversary S
such that for every PPT environment Z, it holds that:
{IDEAL
GgROFt,S,Z (¯x, n, z)}¯x∈{0,1}∗m,n,z ≈ {REAL
GgRO
π,A,Z (¯x, n, z)}¯x∈{0,1}∗m,n,z
where REAL denotes the outputs of the honest parties and the adversary A after a real execution
of protocol π, where ¯x is the vector of inputs to the parties P1, . . . , Pm, z ∈ {0, 1}∗ is the auxiliary
input for A and n is the security parameter.
IDEAL is the analogous distribution in an ideal
execution with a trusted party that computes Ft for the parties and hands the output to the
designated players. We provide the formal description of the ideal functionalities in the GgRO model
that we implement in this paper: the commitment functionality Fig. 2, the OT functionality Fig. 3
(OT) and the NISC functionality Fig. 4.
2.5 Discussion
Comparison with the JUC model. Our mechanism of illegitimate queries can be seen as a
multiplexing mechanisms where from one global random oracle we derive many independent random
oracles based on the sid. This technique is reminiscent of the multiplexing technique of [CR03] for
the Joint State UC model, where they derive many independent CRS from a shared CRS.
We stress important diﬀerences between our model and the model of [CR03]. First, the shared
CRS in [CR03] is still local to a pre-speciﬁed set of parties. This means that the environment does
not have access to the CRS and that the simulator can program it. Thus, there is no global setup.
In our case the RO is global and can be used by any protocol in the world.
13
Ftcom running in presence of an adversary S proceeds as follows:
Functionality Ftcom
• Commitment Phase: Upon receiving a message (commit, sid, Pi, Pj, m) from Pi where
m ∈ {0, 1}n: Record the tuple (sid, Pi, Pj, m) and send the message (receipt, sid, Pi, Pj) to