placeholder. The placeholder attribute specifies a short hint for the
input box. Often cases, placeholder shows hints for the “username"
and “password" in the phishing pages, e.g., “please enter your pass-
word”, “phone, email or username”. The name attribute specifies
the name of the button. We treat the texts extracted from the form
attributes as features. We also consider the number of forms in the
HTML document as a feature.
Prior works have proposed
Features that We Did Not Use.
other features but most of which are not applicable for our purpose.
For example, researchers of [20, 29, 61] also considered OCR and
lexical features, but the underlying assumption is that phishing
sites share a high level similarity with the real sites (visually or
keyword-wise). However, this assumption is not necessarily true
given the evasion techniques and the large variances of phishing
pages (§3.1). In addition, Cantina [64] and Cantina+ [61] propose
to query search engines (e.g., Google) using the keywords of the
suspicious web pages to match against the real sites. However, these
features are too expensive to obtain given the large scale of our
dataset. To these ends, the features we constructed in this paper (e.g.,
keywords from logos, login forms, and other input fields) are more
generic and light-weighted for modeling the phishing attempts
So far, we haven’t
Discussions on the Feature Robustness.
seen any real-world phishing pages that attempt to evade the OCR
engine. Future attackers may attempt to add adversarial noises
to images to manipulate the OCR output. However, technically
speaking, evading OCR features are difficult in the phishing con-
texts. First, unlike standard image classifiers that can be easily
evaded [25, 32, 34, 43, 48, 54, 62], OCR involves a more complex
segmentation and transformation process on the input images be-
fore the text extraction. These steps make it extremely difficult to
reverse-engineer a blackbox OCR engine to perform adversarial
attacks. A recent work confirms that it is difficult to evade OCR
in a blackbox setting [57]. Second, specifically for phishing, it is
impossible for attackers to add arbitrary adversarial noises to the
whole screenshots. Instead, the only part that attackers can manip-
ulate is the actual images loaded by the HTML. This means texts
of the login forms and buttons can still be extracted by OCR or
from the form attributes. Finally, for phishing, the key is to avoid
alerting users, and thus the adversarial noise needs to be extremely
small. This further increases of the difficulty of evasion. Overall, we
believe the combination of OCR features and other features helps
to increases the performance (and the robustness) of the classifiers.
5.2 Feature Embedding and Training
After the raw features are extracted, we need to first process and
normalize the features before used them for training. Here, we apply
NLP (natural language processing) to extract meaningful keywords
and transform them into training vectors.
Tokenization and Spelling Checking. We first use NLTK [22],
a popular NLP toolkit to tokenize the extracted raw text and then
remove the stopwords [8]. Since the OCR engine itself would make
mistakes, we then apply spell checking to correct certain typos from
OCR. For example, Tesseract sometimes introduces errors such as
“passwod”, which can be easily corrected to “password” by a spell
checker. In this way, we obtain a list of keywords for each page.
Next, we construct the feature vector.
Feature Embedding.
For numeric features (e.g., number of forms in HTML), we directly
append them to the feature vector. For keyword-related features, we
use the frequency of each keyword in the given page as the feature
value. During training, we consider keywords that are frequently
appear in the ground-truth phishing pages as well as the keywords
related to all the 766 brand names. The dimension of feature vector
is 987 and each feature vector is quite sparse.
We tested 3 different machine learning models
Classifiers.
including Naive Bayes, KNN and Random forest. These models are
chosen primarily for efficiency considerations since the classifier
needs to quickly process millions of webpages.
5.3 Ground-Truth Evaluation
We use the ground-truth phishing pages from PhishTank to evalu-
ate the classifier’s performance. The classifier is trained to detect
whether a page is phishing (positive) or not (negative). Recall that
in § 4.1, there is no major difference in the HTML code for web and
mobile pages, we only use the web version to perform the training.
The ground-truth dataset contains 1731 manually verified phish-
ing pages from PhishTank. The benign categories contain 3838
webpages from two sources: the first part of 2273 benign pages
were manually identified from the PhishTank dataset (§4.1); The
Tracking Down Elite Phishing Domains in the Wild
IMC ’18, October 31–November 2, 2018, Boston, MA, USA
Figure 10: False positive rate vs. true pos-
itive rate of different models.
Figure 11: # of verified phishing do-
mains for each brand.
Figure 12: # of squatting phishing do-
mains of different squatting types.
Algorithm
NaiveBayes
KNN
RandomForest
Table 7: Classifiers’ performance on ground-truth data.
False Negative AUC ACC
0.05
0.44
0.86
0.10
0.06
0.90
False Positive
0.50
0.04
0.03
0.64
0.92
0.97
Type
Web
Mobile
Union
Squatting
Domains
657,663
657,663
657,663
Classified
as Phishing
1,224
1,269
1,741
Manually
Confirmed
857 (70.0%)
908 (72.0%)
1175 (67.4%)
Related
Brands
247
255
281
Table 8: Detected and confirmed squatting phishing pages.
second part of benign pages come from the webpages of the 1.6 mil-
lion squatting domains (§3.2). We randomly sampled and manually
verified 1565 benign pages. Due to the time-consuming nature of
manual annotation, we only introduce the most “easy-to-confuse”
benign pages (i.e., those under squatting domains and those incor-
rectly reported as phishing). We did not include the “obviously
benign pages” so that the classifiers can be more focused to distin-
guish the benign pages from the squatting domain set.
Table 7 shows the results of 10-fold cross-validation. We present
the false positive rate, false negative rate, area under curve (AUC)
and accuracy (ACC). We show that Random Forest has the highest
AUC (0.97), with a false positive rate of 0.03 and a false negative rate
0.06. The classifier is highly accurate on the ground-truth dataset.
Figure 10 presents the ROC curve of three algorithms. Random
Forest achieves the best performance, and will be used to detect
squatting phishing domains from the squatting domains.
6 SQUATTING PHISHING IN THE WILD
In this section, we apply our classifier to detect squatting phishing
pages in the wild. We first describe our detection results and manu-
ally the confirm the flagged phishing pages. Then we analyze the
squatting phishing pages to answer the following questions. First,
how prevalent are phishing pages among the squatting domains?
Second, what are the common attacks that squatting phishing pages
are used for, and what types of squatting techniques are used? Third,
are squatting phishing pages more evasive? How quickly can squat-
ting phishing pages be detected or blacklisted?
6.1 Detecting Squatting Phishing Pages
We apply the Random Forest classifier to the collected web and
mobile pages from the squatting domains. As shown in Table 8,
Brand
Manual Verfied
Predicted
Web Mobie Web (%)
105 (94%)
112
18 (86%)
21
8 (40%)
20
16 (84%)
19
16
11 (69%)
4 (25%)
16
7 (50%)
14
8 (80%)
10
5 (63%)
8
7
5 (71%)
4 (57%)
7
3 (60%)
5
5 (83%)
6
3 (50%)
6
1
1 (100%)
Google
Facebook
Apple
BitCoin
Uber
Youtube
PayPal
Citi
Ebay
Microsoft
Twitter
DropBox
GitHub
ADP
Santander
Table 9: 15 example brands and verified phishing pages.
Mobile (%)
89 (92%)
19 (80%)
16 (72%)
16 (94%)
11 (69%)
12 (80%)
7 (41%)
11 (58%)
5 (63%)
2 (100%)
5 (100%)
2 (67%)
2 (50%)
3 (43%)
1 (100%)
Squatting
Domains
6,801
3,837
13,465
1,378
5,963
3,162
2,330
5,123
3,109
3,039
1,378
516
503
3,305
567
97
24
22
17
16
15
17
19
8
2
5
3
4
7
1
the classifier detected 1,224 phishing pages for the web version,
and 1,269 phishing pages for the mobile version. Comparing to the
657,663 squatting domains, the number of squatting phishing pages
are relatively small (0.2%).
After the classification, we manually
Manual Verification.
examined each of the detected phishing pages to further remove
classification errors. During our manual examination, we follow
a simple rule: if the page impersonates the trademarks of the tar-
get brands and if there is a form to trick users to input personal
information, we regard the page as a phishing page. As shown in
Table 8, after manual examination, we confirmed 1,175 domains are
indeed phishing domains. Under these domains, there are 857 web
phishing pages which count for 70.0% of all flagged web pages by
the classifier. In addition, we confirmed even more mobile phishing
pages (908) which count for 72.0% of all flagged mobile pages.
In Table 9, we present 15 example brands and the number of con-
firmed squatting phishing pages. We show the detection accuracy of
the classifier is reasonably high for popular brands such as Google,
Facebook, and Microsoft. However, the classifier is more likely to
make mistakes on brands such as Paypal, Twitter, and Uber. Our
manual analysis shows that the errors largely come from legitimate
pages that contain some submission forms (e.g., survey text boxes
to collect user feedback) or third-party plugins of the target brands
(e.g., plugins for supporting payments via PayPal, Twitter “share”
icons, Facebook “Like” buttons). The results suggest that classifier
trained on the ground-truth dataset is still not perfect. Since the
 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1True Positive RateFalse Positive RateRandomForestKNNNaiveBayes 0 20 40 60 80 100 0 20 40 60 80 100CDF of Brands (%)Verified Phishing Domains per BrandWebMobile 100 200 300 400 500HomographBitsTypoComboWrongTLD# of DomainsWebMobileIMC ’18, October 31–November 2, 2018, Boston, MA, USA
Ke Tian et al.
Figure 13: The top 70 brands targeted by squatting phishing pages.
Squatting Phishing Domains
goog1e.nl
gougle.pl
googl4.nl
gooogle.com.uyl
ggoogle.in
googlw.it
goofle.com.ua
goofle.com.ua