licious samples we took the words with the most attention and
determined to which feature they applied. These results are shown
in Table 5. We see that file operations were most commonly the
most highly paid attention to, followed by API calls, then network
and DLL loads. Interestingly, file operations were also the best per-
forming individual feature. This means that the feature it paid the
most attention to was also the best performing on its own.
Feature
File
API
Network
DLL Loads
Mutex
Registry
Number of times
in top attention
831
305
107
95
72
20
Table 5: This table shows how many times each feature ap-
peared as one of the 10 most important words according to
the attention score for 100 samples.
Answer for RQ2: NLP techniques for document classifica-
tion can be effectively applied on reports to perform malware
detection and show much better results than our Raw Model
neural network.
Answer for RQ4: Neurlux appears to be learning to use
the best combinations of features. Specifically, it pays more
attention to the file operations performed by the malware, as
well as the API calls.
6.5 Robustness
We found that all the approaches had lower accuracies when tested
on a dataset or sandbox report that they were not trained on. The
report format has many differences that should account for the
drop in accuracy. However, the lower accuracy on VendorDataset
implies that we are learning features that do not generalize to all
executables. This could be a problem due to deficiencies in the
training set (not having as wide a breadth of samples as we need).
Also, it could be that the model is still learning some specific features
that do not generalize as well. Neurlux showed the best robustness
to the report formats. Also, the other NLP-based deep learning
approaches (the individual models and Ensemble Model) showed
decent robustness, implying that the NLP techniques give us more
general features than our raw bytes approach.
Answer for RQ3: Neurlux is the most robust of the models
we tried, showing the highest accuracy on another dataset and
on another report format. On the other hand, our raw bytes
model was poor at classification across datasets and reports.
This implies that the features learned using text classification
approaches were more general.
6.6 Unseen Malware Family
Another experiment we performed was to remove one malware
family, train on the remaining data, and then evaluate Neurlux’s
classification accuracy when tested on that family. We removed all
samples that were identified as the family Trojan.Viz.Gen.1, using
VirusTotal. During evaluation Neurlux still correctly classified all
346 samples of that family as malware.
6.7 Performance
We run our experiments on Nvidia Titan RTX and Xeon Gold 6252
processor. Our training process took 19.47 milliseconds/sample
and detection process took 8.21 milliseconds/sample. The data-
cleaning/preprocessing runs at a rate of 6.16 milliseconds/sample.
7 DISCUSSION AND FUTURE WORK
One limitation of Neurlux is that it performs classification based
on behavior seen in dynamic analyses. This means that it is not as
effective as a preventative measure. However, its results still are
useful for identifying malware to generate signatures or catch that
an infection has occurred. Also, Neurlux showed that it was able
to detect a previously unseen family, indicating that it can be used
even on malware that has not been analyzed before. This result
could be further explored to understand the correlations between
different malware families.
Also, Neurlux relies on accurate and broad training data. Future
work would be to try and make it more resilient to the quality of the
training data, as well as exploring different execution environments
to discover if one provides better results for it. Other directions
for future work include exploring different models to improve the
results. For example, image recognition [16], has recently shown
promising results. These models are based on ones that were known
to perform well on image recognition tasks, and can also sometimes
use transfer learning, using the training already done on images.
7.1 Adversarial Learning
Some recent works try to evade the detection of machine learning
based malware classifiers by adversarial learning. Their experi-
ments show that it is possible to generate adversarial samples based
on a trained machine learning classifier. The core of adversarial
sample crafting is to find a small perturbation to feature vectors X
of the original malware sample to change the classification results
F to benign. Formally, they compute the gradient of F with respect
to X to estimate the direction in which a perturbation in X would
maximally change F ′s output. The earliest work of this topic came
from Nguyen et al. [20] who found that a slight change in the image
could trick the image classifier, and then it has been introduced
into computer security in recent years to attack security systems
that rely on machine learning models.
Robustness against adversarial attacks provided is an essential
design characteristic. Our future work will include making our
proposed model more robust against such attacks.
8 RELATED WORK
There has been much work on using machine learning and NLP
models to classify malware, all bringing new strengths and trade-
offs to the table. There were initially many machine learning models
being used, such as Support Vector Machines (SVM), Decision Trees
(DT), Random Forest, and K-Nearest Neighbor (KNN) amongst
others. Recently, neural networks have been prevalent for detecting
and classifying malware.
Saxe et al. [33] proposed a method to distinguish malware from
benign software based on a neural network, deep learning approach.
Their system uses four different types of complementary static
features from benign and malicious binaries. These features are
entropy histogram features, PE import features, string 2D histogram
features, and PE metadata features. However, this work primarily
focused on feature engineering and static analysis. Fan et al. [4]
created a sequence mining algorithm that discovers consecutive
malicious patterns using All-Nearest-Neighbor classifier. They used
feature engineering to extract instruction sequences from the PE
files as the preliminary features. This approach used static features
and required domain knowledge for feature extraction.
Zheng et al. [43] creates a behavior chain that aids in its de-
tection method. The method monitors behavior points based on
API calls and then uses the respective calling sequence at runtime
to construct a behavior chain. The system uses long short-term
memory (LSTM) to detect maliciousness from the created chains.
Salehi et al. [31] used a monitored environment where the argu-
ments and return values of every API call are recorded as (API,
variables, return value) tri-tuples. The authors found a selective
and discriminative set of these features and used SVM algorithm for
classification. Other methods also focused on using API sequence
calls for dynamic malware classification [23, 32, 35]. However, re-
stricting to only one type of feature limits the vast feature space
that can be used to represent different types of malware behaviors.
MalInsight [7] takes a different approach, and profiles malware
based on basic structure, low-level behavior, and high-level behavior.
A feature space is built on three core profiles, namely, the structural
features, how the binary interacts with the OS, and operations on
files, registry, and network. Han et al. pick select features from
the Cuckoo sandbox and train on those. Unlike our experiments
in Section 6.3, they do not use neural networks and they do not
use the whole report as Neurlux does, instead requiring feature
selection.
Another approach is based on early stage recognition [29]. They
implemented a recurrent neural network that takes as input a short
feature set of file activity. They can predict whether or not a file is
malicious using the first few seconds of file execution. Their intu-
ition is that malicious activity surfaces rapidly once the malicious
file begins execution. Their approach differs from ours in that it
only uses file activity, and aims to detect malware in real time. We
use entire dynamic analysis reports which provide a more complete
picture but requires analyzing it in a sandbox.
Zhong et al. [44] suggested that a single deep learning model
was insufficient and created a Multi-Level Deep Learning System.
They first partition the data using static and dynamic features, then
create a convolutional model which learns to classify each cluster,
and combine the clusters to create their final model. They use a
feature extraction phase to extract static and dynamic features,
whereas Neurlux simply learns on the report of dynamic behavior
and not extracted features.
Another approach that performs classification on behavior re-
ports is MalDy, which uses a bag of words approach, with models
combined in an ensemble [11]. A limitation of a bag of words ap-
proach is that it does not take into account the context, just the
frequencies with which words appear [22]. Additionally, BoW pro-
duces feature vectors which are fairly sparse. On the other hand, our
system, which uses word embeddings does not have this limitation,
and produces more dense, low dimensional feature vectors. In our
evaluation (results in Table 3), we show that Neurlux gives a higher
validation accuracy and a much stronger ability to generalize, both
to other datasets and to other report formats than MalDy.
9 CONCLUSIONS
This paper introduced Neurlux, a robust malware detection tool
that can successfully identify malicious files based on their run-time
behavior without feature engineering. It is based on techniques
borrowed from the field of document classification and applied
to dynamic analysis reports. Based on our evaluation results, we
conclude that Neurlux outperforms similar approaches for malware
classification. Our work not only focused on eliminating the need
for feature engineering, but also explains the relation of the classifi-
cation process with respect to different auto-detected features. The
fact that Neurlux can retain a high detection accuracy when tested
on samples from another dataset and on an unknown report format
shows that our model promises robust real-world applicability.
ACKNOWLEDGMENTS
This research is based on research sponsored by a gift from Intel for
the investigation of machine learning for malware analysis, by the
National Science Foundation grant #CNS-1704253, and by DARPA
under agreement number #FA8750-19-C-0003. The U.S. Government
is authorized to reproduce and distribute reprints for Governmental
purposes notwithstanding any copyright notation thereon. The
views and conclusions contained herein are those of the authors
and should not be interpreted as necessarily representing the official
policies or endorsements, either expressed or implied, of DARPA
or the U.S. Government.
We would also like to thank Lastline for providing data that
made this research possible.
REFERENCES
[1] Cuckoo, automated malware analysis. https://cuckoosandbox.org/.
[2] H. S. Anderson and P. Roth. Ember: an open dataset for training static pe malware
machine learning models. arXiv preprint arXiv:1804.04637, 2018.
[3] T. Brosch and M. Morgenstern. Runtime Packers: The Hidden Problem? Black
Hat USA, 2006.
[4] Y. Fan, Y. Ye, and L. Chen. Malicious sequential pattern mining for automatic
malware detection. Expert Systems with Applications, 52:16–25, 2016.
[5] T. Garfinkel, K. Adams, A. Warfield, and J. Franklin. Compatibility is not trans-
parency: Vmm detection myths and realities. In HotOS, 2007.
[6] K. Grosse, N. Papernot, P. Manoharan, M. Backes, and P. McDaniel. Adversarial
examples for malware detection. In European Symposium on Research in Computer
Security, pages 62–79. Springer, 2017.
[7] W. Han, J. Xue, Y. Wang, Z. Liu, and Z. Kong. Malinsight: A systematic pro-
filing based malware detection framework. Journal of Network and Computer
Applications, 125:236–250, 2019.
[8] S. Hochreiter. The vanishing gradient problem during learning recurrent neural
nets and problem solutions. International Journal of Uncertainty, Fuzziness and
Knowledge-Based Systems, 6(02):107–116, 1998.
[9] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation,
9(8):1735–1780, 1997.
[10] Kanchan Sarkar. Recent trends in natural language processing using deep
learning, 2017. https://medium.com/@kanchansarkar/recent-trends-in-natural-
language-processing-using-deep-learning-a1469fbd2ef.
[11] E. B. Karbab and M. Debbabi. Maldy: Portable, data-driven malware detection us-
ing natural language processing and machine learning techniques on behavioral
analysis reports. Digital Investigation, 28:S77–S87, 2019.
[12] A. Kharaz, S. Arshad, C. Mulliner, W. Robertson, and E. Kirda. {UNVEIL}: A
large-scale, automated approach to detecting ransomware. In 25th {USENIX}
Security Symposium ({USENIX} Security 16), pages 757–772, 2016.
[13] C. Kolbitsch, P. M. Comparetti, C. Kruegel, E. Kirda, X.-y. Zhou, and X. Wang.
Effective and efficient malware detection at the end host. In USENIX security
symposium, volume 4, pages 351–366, 2009.
[14] B. Kolosnjaji, A. Zarras, G. Webster, and C. Eckert. Deep learning for classification
of malware system call sequences. In Australasian Joint Conference on Artificial
Intelligence, pages 137–149. Springer, 2016.
[15] M. Lindorfer, C. Kolbitsch, and P. M. Comparetti. Detecting environment-sensitive
malware. In International Workshop on Recent Advances in Intrusion Detection,
[43] H. Zhang, W. Zhang, Z. Lv, A. K. Sangaiah, T. Huang, and N. Chilamkurti. Maldc:
a depth detection method for malware based on behavior chains. World Wide
Web, pages 1–20, 2019.
[44] W. Zhong and F. Gu. A multi-level deep learning system for malware detection.
[45] C. Zhou, C. Sun, Z. Liu, and F. Lau. A c-lstm neural network for text classification.
Expert Systems with Applications, 2019.
arXiv preprint arXiv:1511.08630, 2015.
pages 338–357. Springer, 2011.
[16] M. Long, Y. Cao, J. Wang, and M. I. Jordan. Learning transferable features with
deep adaptation networks. arXiv preprint arXiv:1502.02791, 2015.
[17] L. v. d. Maaten and G. Hinton. Visualizing data using t-sne. Journal of machine
learning research, 9(Nov):2579–2605, 2008.
[18] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed rep-
resentations of words and phrases and their compositionality. In Advances in
neural information processing systems, pages 3111–3119, 2013.
[19] A. Moser, C. Kruegel, and E. Kirda. Limits of static analysis for malware detection.
In Twenty-Third Annual Computer Security Applications Conference (ACSAC 2007),
pages 421–430. IEEE, 2007.
[20] A. Nguyen, J. Yosinski, and J. Clune. Deep neural networks are easily fooled:
High confidence predictions for unrecognizable images. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recognition, pages 427–436, 2015.
[21] D. Oktavianto and I. Muhardianto. Cuckoo malware analysis. Packt Publishing
Ltd, 2013.
[22] G. Paltoglou and M. Thelwall. More than bag-of-words: Sentence-based docu-
ment representation for sentiment analysis. In Proceedings of the International
Conference Recent Advances in Natural Language Processing RANLP 2013, pages
546–552, 2013.
[23] N. Peiravian and X. Zhu. Machine learning for android malware detection using
permission and api calls. In 2013 IEEE 25th international conference on tools with
artificial intelligence, pages 300–305. IEEE, 2013.
[24] R. Perdisci, A. Lanzi, and W. Lee. Mcboost: Boosting scalability in malware
In 2008
collection and analysis using statistical classification of executables.
Annual Computer Security Applications Conference (ACSAC), pages 301–310. IEEE,
2008.
[25] E. Raff, J. Sylvester, and C. Nicholas. Learning the pe header, malware detection
with minimal domain knowledge. In Proceedings of the 10th ACM Workshop on
Artificial Intelligence and Security, pages 121–132. ACM, 2017.
[26] E. Raff, J. Barker, J. Sylvester, R. Brandon, B. Catanzaro, and C. K. Nicholas.
Malware detection by eating a whole exe. In Workshops at the Thirty-Second
AAAI Conference on Artificial Intelligence, 2018.
[27] T. Raffetseder, C. Kruegel, and E. Kirda. Detecting system emulators. In Interna-
tional Conference on Information Security, pages 1–18. Springer, 2007.
[28] B. Rahbarinia, M. Balduzzi, and R. Perdisci. Exploring the long tail of (malicious)
software downloads. In 2017 47th Annual IEEE/IFIP International Conference on
Dependable Systems and Networks (DSN), pages 391–402. IEEE, 2017.
[29] M. Rhode, P. Burnap, and K. Jones. Early-stage malware prediction using recurrent
neural networks. computers & security, 77:578–594, 2018.
[30] C. Rossow, C. J. Dietrich, C. Grier, C. Kreibich, V. Paxson, N. Pohlmann, H. Bos,
and M. Van Steen. Prudent practices for designing malware experiments: Status
quo and outlook. In 2012 IEEE Symposium on Security and Privacy, pages 65–79.
IEEE, 2012.
[31] Z. Salehi, A. Sami, and M. Ghiasi. Maar: Robust features to detect malicious
activity based on api calls, their arguments and return values. Engineering
Applications of Artificial Intelligence, 59:93–102, 2017.
[32] A. Sami, B. Yadegari, H. Rahimi, N. Peiravian, S. Hashemi, and A. Hamze. Malware
detection based on mining api calls. In Proceedings of the 2010 ACM symposium
on applied computing, pages 1020–1025. ACM, 2010.
[33] J. Saxe and K. Berlin. Deep neural network based malware detection using
two dimensional binary program features. In Malicious and Unwanted Software
(MALWARE), 2015 10th International Conference on, pages 11–20. IEEE, 2015.
[34] D. Sgandurra, L. Muñoz-González, R. Mohsen, and E. C. Lupu. Automated
dynamic analysis of ransomware: Benefits, limitations and use for detection.
arXiv preprint arXiv:1609.03020, 2016.
[35] M. K. Shankarapani, S. Ramamoorthy, R. S. Movva, and S. Mukkamala. Malware
detection using assembly and api call sequences. Journal in computer virology, 7
(2):107–119, 2011.
[36] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale
image recognition. arXiv preprint arXiv:1409.1556, 2014.
[37] K. Simonyan, A. Vedaldi, and A. Zisserman. Deep inside convolutional net-
works: Visualising image classification models and saliency maps. arXiv preprint
arXiv:1312.6034, 2013.
[38] D. Ucci, L. Aniello, and R. Baldoni. Survey on the usage of machine learning
techniques for malware analysis. arXiv preprint arXiv:1710.08189, 2017.
[39] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser,
and I. Polosukhin. Attention is all you need. In Advances in neural information
processing systems, pages 5998–6008, 2017.
[40] VirusTotal. Av comparative analyses. https://blog.virustotal.com/2012/08/av-
comparative-analyses-marketing-and.html. (Accessed: 2019-3-31).
[41] Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and E. Hovy. Hierarchical attention
networks for document classification. In Proceedings of the 2016 Conference of the
North American Chapter of the Association for Computational Linguistics: Human
Language Technologies, pages 1480–1489, 2016.
[42] L. Zeltser.
How malware generates mutex names to evade detec-
tion. https://isc.sans.edu/diary/How+Malware+Generates+Mutex+Names+
to+Evade+Detection/19429/. (Accessed: 2019-5-31).