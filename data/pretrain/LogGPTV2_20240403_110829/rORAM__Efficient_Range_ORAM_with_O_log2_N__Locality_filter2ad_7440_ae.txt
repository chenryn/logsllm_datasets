curred on Ri.
• BatchEvict has a deterministic schedule.
10
Algorithm 3 Access(a, r, op, D∗)
1: Let i ∈ [0, ℓ) such that 2i−1  Li · (λ + 1)]  212 (16MB of sequential data).
This is the result of optimizing seeks and reducing overall I/O
since rORAM accesses larger chunks of data with a single
request compared to a large number of requests generated in
case of Path ORAM.
In fact, the reduction in I/O requests makes rORAM faster
than Path ORAM even for SSDs (around 30x) and network
block devices (around 10x). As noted previously [36], ensuring
locality of accesses improves performance on SSDs while the
reduced number of round-trips required to fetch all blocks in
a range makes rORAM faster for network block devices.
12
D. Query Throughput & Application Benchmarks
Although rORAM is primarily designed for range query
applications, the construction can also be used to speedup
applications that have largely sequential access patterns. Logi-
cally sequential blocks can be fetched as a range. Speciﬁcally,
the application, e.g., a ﬁle system generates requests specifying
the total number of bytes/blocks it wants to consecutively
access from the memory. This is translated into a range query
of appropriate size rounding up to a power of 2.
To measure this effect, we assess query throughput for
several real world workloads. Speciﬁcally, similar to [10],
we replay access traces of several applications – sequen-
tial reads, ﬁle server and video server workloads used by
FileBench version 1.4.9.1 – and measure the corresponding
query throughput. To generate the trace, we ﬁrst
log all
requests generated by FileBench and replay these requests to
both Path ORAM and rORAM. Since ﬁle systems typically
break down an access to a large sequential chunk accesses
into smaller sequential chunks not exceeding 1MB in size it
sufﬁces to initialize rORAM with L = 28 blocks.
Sequential reads. The sequential read workload generates
requests for sequential reads of size 8MB over a large (10GB)
ﬁle, interleaving a small number of random reads/writes in
between3. For the local HDD (Figure 7 (a)) and the local SSD
(Figure 7 (b)), rORAM can support up to 10 and 21 queries per
second respectively. This is almost 20x improvement over the
query throughput of Path ORAM. Note that the overall query
throughput of Path ORAM and Path ORAM with batched
evictions remains largely unaffected by sequential accesses