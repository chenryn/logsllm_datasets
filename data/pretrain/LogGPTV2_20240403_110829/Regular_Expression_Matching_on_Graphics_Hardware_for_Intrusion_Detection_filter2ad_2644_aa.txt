title:Regular Expression Matching on Graphics Hardware for Intrusion Detection
author:Giorgos Vasiliadis and
Michalis Polychronakis and
Spyros Antonatos and
Evangelos P. Markatos and
Sotiris Ioannidis
Regular Expression Matching on Graphics
Hardware for Intrusion Detection
Giorgos Vasiliadis, Michalis Polychronakis, Spiros Antonatos,
Evangelos P. Markatos, and Sotiris Ioannidis
Institute of Computer Science, Foundation for Research and Technology – Hellas
{gvasil,mikepo,antonat,markatos,sotiris}@ics.forth.gr
Abstract. The expressive power of regular expressions has been often
exploited in network intrusion detection systems, virus scanners, and
spam ﬁltering applications. However, the ﬂexible pattern matching func-
tionality of regular expressions in these systems comes with signiﬁcant
overheads in terms of both memory and CPU cycles, since every byte of
the inspected input needs to be processed and compared against a large
set of regular expressions.
In this paper we present the design, implementation and evaluation
of a regular expression matching engine running on graphics processing
units (GPUs). The signiﬁcant spare computational power and data par-
allelism capabilities of modern GPUs permits the eﬃcient matching of
multiple inputs at the same time against a large set of regular expressions.
Our evaluation shows that regular expression matching on graphics hard-
ware can result to a 48 times speedup over traditional CPU implemen-
tations and up to 16 Gbit/s in processing throughput. We demonstrate
the feasibility of GPU regular expression matching by implementing it
in the popular Snort intrusion detection system, which results to a 60%
increase in the packet processing throughput.
1 Introduction
Network Intrusion Detection Systems (NIDS) are an eﬃcient mechanism for
detecting and preventing well-known attacks. The typical use of a NIDS is to
passively examine network traﬃc and detect intrusion attempts and other known
threats. Most modern network intrusion detection and prevention systems rely
on deep packet inspection to determine whether a packet contains an attack
vector or not. Traditionally, deep packet inspection has been limited to directly
comparing the packet payload against a set of string literals. One or more string
literals combined into a single rule are used to describe a known attack. By
using raw byte sequences extracted from the attack vector, it is easy to maintain
signature sets that describe a large number of known threats and also make them
easily accessible to the public.
However, the existence of loose signatures [28] can increase the number of
false positives. Signatures that fail to precisely describe a given attack may
increase the number of matches in traﬃc that do not contain an actual attack.
E. Kirda, S. Jha, and D. Balzarotti (Eds.): RAID 2009, LNCS 5758, pp. 265–283, 2009.
c(cid:2) Springer-Verlag Berlin Heidelberg 2009
266
G. Vasiliadis et al.
Moreover, string literals that are shared between two or more rules will probably
conﬂict at the matching phase and increase the number of false positives. Thus, a
large number of well and carefully designed strings may be required for precisely
describing a known attack.
On the other hand, regular expressions are much more expressive and ﬂexible
than simple byte sequences, and therefore can describe a wider variety of payload
signatures. A single regular expression can cover a large number of individual
string representations, and thus regular expressions have become essential for
representing threat signatures for intrusion detection systems. Several NIDSes,
such as Snort [21] and Bro [20] contain a large number of regular expressions to
accomplish more accurate results. Unfortunately, regular expression matching, is
a highly computationally intensive process. This overhead is due to the fact that,
most of the time, every byte of every packet needs to be processed as part of the
detection algorithm that searches for matches among a large set of expressions
from all signatures that apply to a particular packet.
A possible solution is the use of hardware platforms to perform regular expres-
sion matching [9,24,7,18]. Specialized devices, such as ASICs and FPGAs, can be
used to inspect many packets concurrently. Both are very eﬃcient and perform
well, however they are complex to modify and program. Moreover, FPGA-based
architectures have poor ﬂexibility, since most of the approaches are usually tied
to a speciﬁc implementation.
In contrast, commodity graphics processing units (GPUs) have been proven to
be very eﬃcient for accelerating the string searching operations of NIDS [14,30,
10]. Modern GPUs are specialized for computationally-intensive and highly par-
allel operations—mandatory for graphics rendering—and therefore are designed
with more transistors devoted to data processing rather than data caching and
ﬂow control [19]. Moreover, the ever-growing video game industry exerts strong
economic pressure for more powerful and ﬂexible graphics processors.
In this paper we present the design, implementation, and evaluation of a
GPU-based regular expression matching engine tailored to intrusion detection
systems. We have extended the architecture of Gnort [30], which is based on
the Snort IDS [21], such that both pattern matching and regular expressions are
executed on the GPU. Our experimental results show that regular expression
matching on graphics hardware can provide up to 48 times speedup over tradi-
tional CPU implementations and up to 16 Gbit/s of raw processing throughput.
The computational throughput achieved by the graphics processor is worth the
extra communication overhead needed to transfer network packets to the mem-
ory space of the GPU. We show that the overall processing throughput of Snort
can be increased up to eight times compared to the default implementation.
The remainder of the paper is organized as follows. Background information
on regular expressions and graphics processors is presented in Section 2. Section 3
describes our proposed architecture for matching regular expressions on a graphics
processor, while Section 4 presents the details of our implementation in Snort. In
Section 5 we evaluate our prototype system. The paper ends with an outline of
related work in Section 7 and some concluding remarks in Section 8.
Regular Expression Matching on Graphics Hardware
267
2 Background
In this section we brieﬂy describe the architecture of modern graphics cards,
and the general-purpose computing functionality they provide for non-graphics
applications. We also discuss some general aspects of regular expression matching
and how it is applied in network intrusion detection systems.
2.1 Graphics Processors
Graphics Processing Units (GPUs) have become powerful and ubiquitous. Be-
sides accelerating graphics-intensive applications, vendors like NVIDIA1 and
ATI,2 have started to promote the use of GPUs as general-purpose computa-
tional units complementary to the CPU.
In this work, we have chosen to work with the NVIDIA GeForce 9 Series
(G9x) architecture, which oﬀers a rich programming environment and ﬂexible
abstraction models through the Compute Uniﬁed Device Architecture (CUDA)
SDK [19]. The CUDA programming model extends the C programming language
with directives and libraries that abstract the underlying GPU architecture and
make it more suitable for general purpose computing. CUDA also oﬀers highly
optimized data transfer operations to and from the GPU.
The G9x architecture, similarly to the previous G80 architecture, is based on
a set of multiprocessors, each comprising a set of stream processors operating on
SPMD (Single Process, Multiple Data) programs. A unit of work issued by the
host computer to the GPU is called a kernel and is executed on the GPU as many
diﬀerent threads organized in thread blocks. A fast shared memory is managed ex-
plicitly by the programmer among thread blocks. The global, constant, and texture
memory spaces can be read from or written to by the host, are persistent across ker-
nel launched by the same application, and are optimized for diﬀerent memory us-
age [19]. The constant and texture memory accesses are cached, so a read from them
costs much less compared to device memory reads, which are not being cached. The
texture memory space is implemented as a read-only region of device memory.
2.2 Regular Expressions
Regular expressions oﬀer signiﬁcant advantages over exact string matching, pro-
viding ﬂexibility and expressiveness in specifying the context of each match. In
particular, the use of logical operators is very useful for specifying the context
for matching a relevant pattern. Regular expressions can be matched eﬃciently
by compiling the expressions into state machines, in a similar way to some ﬁxed
string pattern matching algorithms [3].
A state machine can be either a deterministic (DFA) or non-deterministic (NFA)
automaton, with each approach having its own advantages and disadvantages. An
NFA can compactly represent multiple signatures but may result to long match-
ing times, because the matching operation needs to explore multiple paths in the
automaton in order to determine whether the input matches any signatures.
1 http://developer.nvidia.com/object/cuda.html
2 http://ati.amd.com/technology/streamcomputing/index.html
268
G. Vasiliadis et al.
A DFA, on the other hand, can be eﬃciently implemented in software—a
sequence of n bytes can be matched with O(n) operations, which is very eﬃcient
in terms of speed. This is achieved because at any state, every possible input
letter leads to at most one new state. An NFA in contrast, may have a set
of alternative states to which it may backtrack when there is a mismatch on
the previously selected path. However, DFAs usually require large amounts of
memory to achieve this performance. In fact, complex regular expressions can
exponentially increase the size of the resulting deterministic automaton [6].
2.3 Regular Expression Matching in Snort
Regular expression matching in Snort is implemented using the PCRE library [1].
The PCRE library uses an NFA structure by default, although it also supports
DFA matching. PCRE provides a rich syntax for creating descriptive expressions,
as well as extra modiﬁers that can enrich the behavior of the whole expression,
such as case-insensitive or multi-line matching. In addition, Snort introduces
its own modiﬁers based on internal information such as the position of the last
pattern match, or the decoded URI. These modiﬁers are very useful in case an
expression should be matched in relation to the end of the previous match.
Each regular expression is compiled into a separate automaton that is used at
the searching phase to match the contents of a packet. Given the large number of
regular expressions contained in Snort’s default rule set, it would be ineﬃcient
to match every captured packet against each compiled automaton separately.
45% of the rules in the latest Snort ruleset perform regular expression matching,
half of which are related to Web server protection.
To reduce the number of packets that need to be matched against a regular
expression, Snort takes advantage of the string matching engine and uses it as
a ﬁrst-level ﬁltering mechanism before proceeding to regular expression match-
ing. Rules that contain a regular expression operation are augmented with a
string searching operation that searches for the most characteristic ﬁxed string
counterpart of the regular expression used in the rule.
The string matching engine consists of a set-wise pattern matching algorithm
that searches in advance for the ﬁxed string subparts of all regular expressions
simultaneously. For a given rule, if the ﬁxed string parts of the regular expressions
are not present in a packet, then the regular expression will never match. Thus,
ﬁxed string pattern matching acts as a pre-ﬁltering mechanism to reduce the
invocation of the regular expression matching engine, as shown in Figure 1.
There are also 24 rules in the latest Snort rule set that do not perform this pre-
ﬁltering, but we believe these are cases of poorly written rules. The matching
procedure for regular expression matching is invoked only when the subparts
have been identiﬁed in the packet. For example, in the following rule:
alert tcp any any -> any 21 (content:"PASS"; pcre:"/^PASS\s*\n/smi";)
the pcre: pattern will be evaluated only if the content: pattern has previously
matched in the packet.
Regular Expression Matching on Graphics Hardware
269
Regular
Expression
Matching
Snort Processing Flow
Decode
Packets
Preprocessors
Content
Scanning
Output
Plug-ins
Fig. 1. Regular expression matching in the Snort IDS
3 Regular Expression Matching on Graphics Processors
We extend the architecture of Snort to make use of the GPU for oﬄoading reg-
ular expression matching from the CPU, and decreasing its overall workload.
Figure 2 depicts the top-level diagram of our regular expression pattern match-
ing engine. Whenever a packet needs to be scanned against a regular expression,
it is transferred to the GPU where the actual matching takes place. The SPMD
operation of the GPU is ideal for creating multiple instantiations of regular ex-
pression state machines that will run on diﬀerent stream processors and operate
on diﬀerent data.
Due to the overhead associated with a data transfer operation to the GPU,
batching many small transfers into a larger one performs much better than
making each transfer separately, as shown in Section 5.3. Thus, we have chosen to
copy the packets to the GPU in batches. We use a separate buﬀer for temporarily
storing the packets that need to be matched against a regular expression. Every
time the buﬀer ﬁlls up, it is transferred to the GPU for execution.
Packets
i
g
n
n
n
a
c
S
t
n
e
t
n
o
C
Texture Memory
Regular Expressions
Global Memory
Packet
Buffer
Regular Expression 1
Regular Expression 2
Regular Expression N
Results
O
u
t
p
u
t
l
P
u
g
-
i
n
s
Fig. 2. Overview of the regular expression matching engine in the GPU
270
G. Vasiliadis et al.
0
4
6
Reg.Ex. ID Length
Reg.Ex. ID Length
Reg.Ex. ID Length
1536
Payload
Payload
Payload
Reg.Ex. ID Length
Payload
Fig. 3. Packet buﬀer format
The content of the packet, as well as an identiﬁer of the regular expression that
needs to be matched against, are stored in the buﬀer as shown in Figure 3. Since
each packet may need to be matched against a diﬀerent expression, each packet
is “marked” so that it can be processed by the appropriate regular expression
at the search phase. Therefore, each row of the buﬀer contains a special ﬁeld
that is used to store a pointer to the state machine of the regular expression the
speciﬁed packet should be scanned against.
Every time the buﬀer is ﬁlled up, it is processed by all the stream processors of
the GPU at once. The matching process is a kernel function capable of scanning
the payload of each network packet for a speciﬁc expression in parallel. The
kernel function is executed simultaneously by many threads in parallel. Using
the identiﬁer of the regular expression, each thread will scan the whole packet in
isolation. The state machines of all regular expressions are stored in the memory
space of the graphics processor, thus they can be accessed directly by the stream
processors and search the contents of the packets concurrently.
A major design decision for GPU regular expression matching is the type of
automaton that will be used for the searching process. As we have discussed in
Section 2, DFAs are far more eﬃcient than the corresponding NFAs in terms
of speed, thus we base our design of a DFA architecture capable of matching
regular expressions on the GPU.
Given the rule set of Snort, all the contained regular expressions are compiled
and converted into DFAs that are copied to the memory space of the GPU. The
compilation process is performed by the CPU oﬀ-line at start-up. Each regular
expression is compiled into a separate state machine table that is transferred to
the memory space of the GPU. During the searching phase, all state machine
tables reside in GPU memory only.
Our regular expression implementation currently does not support a few
PCRE keywords related to some look-around expressions and back references.
Back references use information about previously captured sub-patterns which is
not straightforward to keep track of during searching. Look-around expressions
scan the input data without consuming characters. In the current Snort default
rule set, less than 2% of the rules that use regular expressions make use of these
features. Therefore our regular expression compiler is able to generate automata
for the vast majority of the regular expressions that are currently contained in
Regular Expression Matching on Graphics Hardware
271
the Snort rule set. To preserve both accuracy and precision in attack detection,
we use a hybrid approach in which all regular expressions that fail to compile
into DFAs are matched on the CPU using a corresponding NFA, in the same
way unmodiﬁed Snort does.
4 Implementation
In this section, we present the details of our implementation, which is based
on the NVIDIA G9X platform using the CUDA programming model. First, we
describe how the gathered network packets are collected and transferred to the
memory space of the GPU. The GPU is not able to directly access the captured
packets from the network interface, thus the packets must be copied by the CPU.
Next, we describe how regular expressions are compiled and used directly by the
graphics processor for eﬃciently inspecting the incoming data stream.
4.1 Collecting Packets on the CPU
An important performance factor of our architecture is the data transfers to and
from the GPU. For that purpose, we use page-locked memory, which is substan-
tially faster than non-page-locked memory, since it can be accessed directly by
the GPU through Direct Memory Access (DMA). A limitation of this approach
is that page locked memory is of limited size as it cannot be swapped. In prac-