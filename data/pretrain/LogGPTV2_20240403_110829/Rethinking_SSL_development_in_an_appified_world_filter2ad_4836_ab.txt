apply SSL certiﬁcate validation correctly, they often do not
present sensible feedback when validation fails.
While there are many more details worth discussing in
the context of iOS, for the purpose of this work, the fact
that iOS apps suﬀer from a similar number of SSL prob-
lems shows that these problems must have underlying causes
which are not speciﬁc to a platform or app store model. For
more details on the iOS analysis the reader is referred to
AppendixA.
4. CAUSE ANALYSIS
The iOS study shows that the trouble developers have us-
ing SSL correctly is common to the major platforms and
across all applications and platform paradigms. To develop
an eﬀective countermeasure, we wanted to identify the root
causes of these problems. Therefore, we studied entries
about SSL development for both Android and iOS in on-
line forums and conducted interviews with developers who
had produced broken SSL code.
4.1 Online Forums
We used stackoverflow.com, a popular online forum for
software developers, to search for results that contained text
such as “android/ios allow all certiﬁcates” and “android/ios
trust all certiﬁcates” ﬁrst. These kinds of results were found
in threads where developers asked how they could “work with
self-signed certiﬁcates” or “make ’javax.net.ssl.SSLException’
go away”. Answers to these and similar questions mainly
contained explanations on how to turn oﬀ SSL certiﬁcate
validation or hostname veriﬁcation without mentioning that
this would create serious security issues. Studying these
discussions conﬁrmed our impression that many developers
on both platforms – iOS as well as Android – lack an ade-
quate understanding of how SSL works and were frustrated
with the complexity of customizing SSL code and thus will-
ing to use the quick ﬁxes oﬀered by the forums – potentially
without understanding the consequences. These threads had
more than 30,000 views. To put this number into perspec-
tive, searching for “android ssl pinning” or “ios ssl pinning”
returns only one result for Android and two results for iOS
with less than 600 views in total.
4.2 Interviews
While online forums give a good indication of potential
issues, a more reliable way to conﬁrm whether or not these
issues are the actual reasons causing the problems in the
thousands of real world apps is to talk to developers. We
51contacted 78 developers of the 82 vulnerable apps2 from the
100 Android and 150 iOS apps we studied in detail. We
informed the developers of the discovered vulnerabilities via
email and kindly asked them to contact us for further infor-
mation and assistance in ﬁxing their problems. We received
responses from 39 of the 78 developers. We disclosed the
respective vulnerability, oﬀered further assistance and asked
whether the developers were willing to discuss the details of
the security bug either via telephone or email. We promised
the developers to anonymize all information they provided
and to make neither their names nor the apps’ names pub-
licly available. 14 developers agreed to an interview while
the rest was not willing to discuss the topic in further detail
– often with regard to “constraints” dictated by their legal
departments. The interviews were conducted in German or
English, depending on the developer’s origin. However, not
all developers were native speakers. Statements were trans-
lated by the authors, grammatical errors were not corrected.
4.2.1 Results
One of the main causes for the problems we found, was
that developers wanted to use self-signed certiﬁcates dur-
ing development. 5 of the 14 developers reported that they
needed to turn oﬀ SSL certiﬁcate validation during develop-
ment because they were working with test servers that used
self-signed SSL certiﬁcates. To avoid certiﬁcate validation
exceptions, they implemented their own SSL certiﬁcate val-
idation strategies that accept all certiﬁcates, or copied code
from the online forums mentioned above that promised to
help with getting out of the “self-signed certiﬁcate dilemma”.
While it is understandable that developers turn oﬀ SSL cer-
tiﬁcate validation in the development phase, these develop-
ers basically forgot to remove their accept-all code when they
released their apps. Three of these ﬁve developers realized
that this was a serious security threat and stated that they
should ﬁx this security issue as soon as possible. The other
two did not see the problem and even after our explanations
stated the following:
“You said that an attacker with access to the network
traﬃc can see the data in cleartext. I tried that and I
connected my phone to a Wi-Fi hotspot on my laptop.
When I used Wireshark to look at the traﬃc, Wireshark
said that this is a proper SSL protected data stream and
I could not see any cleartext information when I man-
ually inspected the packets. So I really cannot see what
the problem is here.”
This supports the hypothesis stated by Georgiev et al. [8]
that too little adversarial testing is conducted by app devel-
opers. However, it also raises the issue that there are de-
velopers, who, while being technically adept enough to use
Wireshark to check if their app’s traﬃc is really encrypted,
do not understand the nature of the threat and thus take no
precautions to counter it.
Apart from developers wanting to use self-signed certiﬁ-
cates during development, we also talked to developers who
actually wanted to use them in their production environment
but were unaware of the security implications of accepting
any certiﬁcate:
“I was using a self-signed certiﬁcate for my app because
it is free and CA-signed certiﬁcates cost a lot. But, ac-
2Some developers were responsible for both an Android and
an iOS app; thus there were only 78 developers for 82 apps.
tually, I had no idea that working with self-signed cer-
tiﬁcates could have resulted in such a security issue. I
think the online forum where I found the code snippet
only said that it makes self-signed certiﬁcates work.”
“We added this piece of code because our client uses an
SSL certiﬁcate for his web-service which was signed by a
certiﬁcate authority that is not pre-installed on Android
and actually we did not realize that this would cause
such trouble.”
Sometimes, the broken SSL code was added because de-
velopers had diﬃculties understanding the problem and just
went for the ﬁrst solution that seemingly made the problem
disappear:
“This app was one of our ﬁrst mobile apps and when
we noticed that there were problems with the SSL cer-
tiﬁcate, we just implemented the ﬁrst working solution
we found on the Internet. [. . .] We usually build Java
backend software for large-scale web services.”
However, there were also developers who even after being
informed about the problems and the threat scenario did not
properly understand the problem and their countermeasures
did not address the threat arising from a MITMA:
“We hadn’t realized that it would cause such an issue
by using self-signed certiﬁcates in the past time, and
we just veriﬁed if the certiﬁcate was expired. But after
noticing this issue, we strengthened the security check
like verifying host name. We believe this improvement
can ensure users’ security. So we still stick to trust
self-signed certiﬁcates right now for its smaller size and
lower bandwidth cost.”
So while they added hostname veriﬁcation after we informed
them about the issue, they still accept all self-signed certiﬁ-
cates thus defeating hostname veriﬁcation entirely. In an-
other case, a development company of a vulnerable online
banking app needed two iterations to ﬁx their app correctly,
even though we had sent them the necessary code snippets.
There were also cases where developers thought using broken
SSL was adequate to protect information that they deemed
to be not that valuable:
“We checked into this. Only the [. . .] feature is using
a weak SSL certiﬁcate and that connection only sends
the device models and IMEI, but that’s not a security
concern.”
Some developers knew that their code could cause security
problems but saw no other option but to work with self-
signed certiﬁcates by turning oﬀ certiﬁcate validation en-
tirely, since their customers wanted to use self-signed certiﬁ-
cates.
“This issue exists because many of our customers use
self-signed certiﬁcates for SSO (single sign on). Some
time back, a ﬁx was implemented to allow this to work.”
One of those developers raised the interesting point that An-
droid does not oﬀer any default warning, forcing developers
to provide one for themselves if they wish to inform users
about failed certiﬁcate validations:
“The app accepts all SSL certiﬁcates because some users
wanted to connect to their blogs with self-signed certs
52and [. . . ] because Android does not provide an easy-to-
use SSL certiﬁcate warning message, it was a lot easier
to simply accept all self-signed certiﬁcates.”
The consequence of this design decision was that all users of
this app were at risk because some wanted to use self-signed
certiﬁcates.
The iOS developers in our study tended to rely on frame-
works and libraries during development and were under-
standably startled and upset when told that their apps were
endangered because of faulty code generated by the frame-
work (cf. Appendix A):
“I am using the MKNetworkToolkit as a network wrap-
ping library and its SSL features for HTTPS. After you
informed me of the issue I checked the library’s code
and found that by default SSL certiﬁcate validation is
oﬀ. But, when I used the library in my app, I trusted
it and did not check for the SSL MITMA vulnerability
because it is a widely used library.”
“When I was starting to build apps for iOS, I had a
strong background in coding web applications. When I
came up with the Titanium framework that allows de-
velopers to build native mobile apps by writing HTML
and Javascript, I decided to use this framework just be-
cause it was easier for me. [. . .] I never thought that the
framework would produce broken code for SSL encryp-
tion and [. . .], although we conduct security audits for
our apps, we did not include SSL certiﬁcate validation
checks into the audit process.”
The feedback from app developers conﬁrms that develop-
ers struggle to implement SSL correctly when they have a
need to deviate from the standard use-case. They also rely
on the implementations of frameworks and libraries to pro-
tect their apps without thoroughly testing either the frame-
works’ or their app’s security. However, our investigation
also provides some new insights: developers modiﬁed certiﬁ-
cate validation code for internal testing purposes, e. g. work-
ing with arbitrary self-signed certiﬁcates on test servers, but
forgot about that and thus did not remove the code for the
production environment. So even those developers who un-
derstood the current need for signed and trusted certiﬁcates
put their customers at risk. Also, the developers’ problems
did not only lie in the complexity of the code, but were based
on a lack of understanding of how SSL works. There were
also some cases where developers turned SSL validation oﬀ
because of a customer’s request, either accepting or not real-
izing the implications. Even when we explained what could
go wrong and how to correct it, developers struggled when
trying to ﬁx their app (cf. Section 4.4). Altogether, our
results imply that code-level customization of SSL-handling
is an overwhelming problem for many developers and that
there is a fairly high level of frustration with the complexity
of adapting code to their use-cases.
4.3 Summary
After studying code snippets and advice in developer fo-
rums, as well as talking to app developers that use broken
SSL certiﬁcate validation, we believe that in most cases when
Android and iOS developers deviate from default SSL cer-
tiﬁcate validation strategies – that are secure on both plat-
forms by default – they apply customization features in a
way that weakens security signiﬁcantly (c.f. Section 6.2 for
a quantitative conﬁrmation). Many developers of aﬀected
apps seem to have only a partial understanding of what SSL
does and how it works. Yet, there are also developers who
complain about the bad support for self-signed certiﬁcates
and the lack of easy-to-use SSL warning messages.
One interesting aspect we found in the interviews was that
developers in general seem to be interested in providing a
high level of security for their users. We oﬀered all develop-
ers to help them with their SSL problems and most of them
took the oﬀer. After giving background information on the
security model of SSL and certiﬁcate validation, 10 of the
14 interviewed developers accepted our assitance. 7 of these
10 developers decided to strengthen their app’s security by
implementing SSL pinning. They did this because it gave
them full control over the SSL certiﬁcates trusted by their
app and they found that this was the most secure, ﬂexible
and cheapest way to provide a high level of security. We
provided the developers with code to integrate SSL pinning
based on Moxie Marlinspike’s github page3. All developers
agreed that being able to control exactly which certiﬁcates
their apps trust is a great way to increase security, but that
they would not have known how to do this without our help.
Our results imply that allowing app developers to cus-
tomize SSL handling on source-code level overburdens many
developers and leads to insecure apps. While it is easy to
weaken app security by removing the default SSL certiﬁcate
validation code, it is hard to strengthen it by implementing
pinning or other security-strengthening strategies. Only one
developer stated that using insecure SSL should not be taken
too seriously, which makes us believe that in most cases inse-
cure SSL connections are unintentional and that users must
be protected against careless developers and developers who
usually are no security experts.
4.4 Follow-up Analysis
Our developer study showed that many developers were
unaware of the dangers facing their SSL connections and in-
terested in ﬁxing the issues. Some of the developers who
accepted our help were capable of ﬁxing the SSL problems
in their apps. To analyze how developers cope with this sit-
uation without direct help, we ran a follow-up analysis. All
aﬀected developers (iOS & Android) were informed about
the vulnerabilities and the possible security consequences
for their users at the time of discovery of the vulnerability.
They were given the recommendation that they should ﬁx
the identiﬁed issues as soon as possible. Three months after
the respective notiﬁcations, we downloaded the apps again
to check if they had ﬁxed the SSL vulnerabilities. We found
that 51 of the 78 developers did not ﬁx the SSL issues. Six
apps were not available any more which means we could not
test them a second time. Only 21 (26.9 %) apps were ﬁxed
and implemented correct SSL certiﬁcate validation in their
current versions. Of these 21 apps, 9 belonged to developers
we had helped directly during the interview process. How-
ever, 5 of the 14 developers we interviewed did not ﬁx the
SSL issues in their apps. Furthermore, developers of an app
that included vulnerable SSL certiﬁcate validation on both
Android and iOS only ﬁxed it for Android while the iOS app
was still vulnerable in the second test.
The results of this follow-up analysis indicate that even af-
ter informing and educating developers about vulnerabilities
in their SSL code, problems in correcting these mistakes and
3https://github.com/moxie0/AndroidPinning
53deploying a safe solution still remain. Finding that 73.1 % of
all informed developers did not ﬁx the reported SSL issues
demonstrates even more that the current SSL mechanisms
on appiﬁed platforms need rethinking.
While there are well known usability problems with SSL
warning messages in browsers [16], we believe that allowing
developers to for instance silently ignore SSL errors and put
the user at risk is worse. We thus deﬁne an additional goal:
5. A NEW APPROACH TO SSL SECURITY
ON APPIFIED PLATFORMS
In the previous sections, we showed that incorrect SSL val-
idation is a widespread problem on appiﬁed platforms and
analyzed the causes of these issues. In a follow-up study, we
found that only a small part of previously vulnerable apps
had ﬁxed their app’s SSL vulnerabilities, even after we in-
formed the developers about the problems. In the following,
we propose a major change in how app developers use SSL
to address these issues. While we implemented our ideas