### Applying SSL Certificate Validation Correctly

Many applications fail to apply SSL certificate validation correctly and often do not provide meaningful feedback when validation fails. Although there are numerous additional details worth discussing in the context of iOS, this work highlights that iOS applications suffer from a similar number of SSL issues, indicating that the underlying causes are not specific to a particular platform or app store model. For more detailed information on the iOS analysis, please refer to Appendix A.

### 4. Cause Analysis

The iOS study reveals that the challenges developers face in using SSL correctly are common across major platforms and various application paradigms. To develop an effective countermeasure, we aimed to identify the root causes of these problems. We analyzed online forum discussions and conducted interviews with developers who had produced broken SSL code.

#### 4.1 Online Forums

We used Stack Overflow, a popular online forum for software developers, to search for threads containing phrases like "android/ios allow all certificates" and "android/ios trust all certificates." These threads often involved developers asking how to "work with self-signed certificates" or "make 'javax.net.ssl.SSLException' go away." The answers typically provided instructions on how to disable SSL certificate validation or hostname verification without mentioning the associated security risks. This analysis confirmed that many developers on both iOS and Android lack a proper understanding of SSL and are frustrated by the complexity of customizing SSL code, leading them to use quick fixes suggested in forums. These threads had over 30,000 views. In contrast, searches for "android ssl pinning" or "ios ssl pinning" returned only one result for Android and two for iOS, with fewer than 600 views in total.

#### 4.2 Interviews

While online forums provide valuable insights, a more reliable method to confirm the actual reasons behind the issues is to speak directly with developers. We contacted 78 developers responsible for 82 vulnerable apps out of the 100 Android and 150 iOS apps we studied in detail. We informed the developers about the discovered vulnerabilities via email and requested further communication to assist in fixing the issues. We received responses from 39 out of the 78 developers. We disclosed the vulnerabilities, offered assistance, and asked if they were willing to discuss the details via telephone or email. We assured the developers that their information would be anonymized and not made public. Fourteen developers agreed to an interview, while the rest declined, often citing legal constraints. The interviews were conducted in German or English, depending on the developer's origin. Statements were translated by the authors, and grammatical errors were not corrected.

##### 4.2.1 Results

One of the primary causes of the identified issues was the use of self-signed certificates during development. Five of the 14 developers reported that they needed to disable SSL certificate validation during development because they were working with test servers that used self-signed SSL certificates. To avoid validation exceptions, they implemented custom SSL certificate validation strategies that accepted all certificates or copied code from online forums. While it is understandable to disable SSL certificate validation during development, these developers forgot to remove the accept-all code before releasing their apps. Three of these five developers recognized the security threat and committed to fixing the issue. The other two did not see the problem, even after our explanations:

> "You said that an attacker with access to the network traffic can see the data in cleartext. I tried that and connected my phone to a Wi-Fi hotspot on my laptop. When I used Wireshark to look at the traffic, Wireshark said that this is a proper SSL-protected data stream, and I could not see any cleartext information when I manually inspected the packets. So I really cannot see what the problem is here."

This supports the hypothesis by Georgiev et al. [8] that developers conduct insufficient adversarial testing. However, it also highlights that some technically adept developers, who can use tools like Wireshark, do not fully understand the nature of the threat.

In addition to developers using self-signed certificates during development, some wanted to use them in production but were unaware of the security implications:

> "I was using a self-signed certificate for my app because it is free, and CA-signed certificates cost a lot. But, actually, I had no idea that working with self-signed certificates could have resulted in such a security issue. I think the online forum where I found the code snippet only said that it makes self-signed certificates work."

Sometimes, the broken SSL code was added because developers struggled to understand the problem and opted for the first solution they found:

> "This app was one of our first mobile apps, and when we noticed that there were problems with the SSL certificate, we just implemented the first working solution we found on the Internet. [. . .] We usually build Java backend software for large-scale web services."

Even after being informed about the issues, some developers still did not properly understand the problem and their countermeasures were inadequate:

> "We hadn’t realized that it would cause such an issue by using self-signed certificates in the past time, and we just verified if the certificate was expired. But after noticing this issue, we strengthened the security check like verifying host name. We believe this improvement can ensure users’ security. So we still stick to trust self-signed certificates right now for its smaller size and lower bandwidth cost."

Despite adding hostname verification, they continued to accept all self-signed certificates, rendering the verification ineffective. In another case, a development company of a vulnerable online banking app required two iterations to fix the issue, even with the necessary code snippets provided.

Some developers thought using broken SSL was adequate for protecting less valuable information:

> "We checked into this. Only the [. . .] feature is using a weak SSL certificate, and that connection only sends the device models and IMEI, but that’s not a security concern."

Others knew that their code could cause security problems but saw no other option but to work with self-signed certificates due to customer demands:

> "This issue exists because many of our customers use self-signed certificates for SSO (single sign-on). Some time back, a fix was implemented to allow this to work."

One developer pointed out that Android does not provide a default warning, forcing developers to create their own if they want to inform users about failed certificate validations:

> "The app accepts all SSL certificates because some users wanted to connect to their blogs with self-signed certs, and because Android does not provide an easy-to-use SSL certificate warning message, it was a lot easier to simply accept all self-signed certificates."

iOS developers often relied on frameworks and libraries, which sometimes generated faulty code:

> "I am using the MKNetworkToolkit as a network wrapping library and its SSL features for HTTPS. After you informed me of the issue, I checked the library’s code and found that by default SSL certificate validation is off. But, when I used the library in my app, I trusted it and did not check for the SSL MITMA vulnerability because it is a widely used library."

Feedback from app developers confirms that they struggle to implement SSL correctly when deviating from standard use-cases. They also rely on framework and library implementations without thorough security testing. Our investigation provides new insights: developers modified certificate validation code for internal testing but forgot to remove it for production, putting their customers at risk. Additionally, the problems were not just due to code complexity but also a lack of understanding of SSL. There were cases where developers disabled SSL validation due to customer requests, either accepting or not realizing the implications. Even with our explanations, developers struggled to fix their apps, suggesting that code-level customization of SSL handling is overwhelming and frustrating.

### 4.3 Summary

After studying code snippets and advice in developer forums and interviewing app developers, we conclude that when Android and iOS developers deviate from default SSL certificate validation strategies, they often weaken security significantly. Many affected developers have a partial understanding of SSL. Some complain about poor support for self-signed certificates and the lack of easy-to-use SSL warning messages.

Interestingly, most developers are interested in providing high security for their users. We offered assistance to all developers, and most accepted. After providing background on SSL and certificate validation, 10 out of 14 interviewed developers accepted our help. Seven of these 10 decided to strengthen their app's security by implementing SSL pinning, giving them full control over trusted SSL certificates. We provided them with code based on Moxie Marlinspike’s GitHub page. All developers agreed that controlling which certificates their apps trust is a great way to increase security, but they would not have known how to do this without our help.

Our results imply that allowing app developers to customize SSL handling at the source-code level overburdens many and leads to insecure apps. It is easy to weaken security by removing default SSL certificate validation, but hard to strengthen it by implementing pinning or other strategies. Only one developer stated that insecure SSL should not be taken too seriously, suggesting that most insecure SSL connections are unintentional and that users must be protected against careless or inexperienced developers.

### 4.4 Follow-up Analysis

Our developer study showed that many were unaware of the dangers facing their SSL connections and were interested in fixing the issues. Some developers who accepted our help were capable of fixing the SSL problems. To analyze how developers cope without direct help, we conducted a follow-up analysis. All affected developers (iOS & Android) were informed about the vulnerabilities and given recommendations to fix the issues. Three months later, we re-downloaded the apps to check for fixes. We found that 51 out of 78 developers did not fix the SSL issues. Six apps were no longer available. Only 21 (26.9%) apps were fixed and implemented correct SSL certificate validation. Of these, 9 belonged to developers we helped directly. However, 5 of the 14 interviewed developers did not fix the SSL issues. One developer fixed the issue for Android but not for iOS.

The follow-up analysis indicates that even after informing and educating developers, problems persist in correcting mistakes and deploying safe solutions. Finding that 73.1% of informed developers did not fix the reported SSL issues demonstrates the need to rethink current SSL mechanisms on appified platforms.

While there are known usability issues with SSL warning messages in browsers, allowing developers to silently ignore SSL errors and put users at risk is worse. We thus define an additional goal:

### 5. A New Approach to SSL Security on Appified Platforms

In the previous sections, we demonstrated that incorrect SSL validation is a widespread problem on appified platforms and analyzed the causes. In a follow-up study, we found that only a small portion of previously vulnerable apps had fixed their SSL vulnerabilities, even after we informed the developers. We propose a significant change in how app developers use SSL to address these issues. While we implemented our ideas, the following section outlines our proposed approach.