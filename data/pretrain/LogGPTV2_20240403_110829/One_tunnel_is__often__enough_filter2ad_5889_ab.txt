service, including between which of its peers to provide the ser-
vice, and whether to attach Service Level Agreements (SLAs) to it
that might provide bandwidth and latency guarantees. Other value-
added services might also be offered, such as DoS protection.
The portal should provide at least the following:
• All offered transit paths and services from a speciﬁc ingress
ISP (and optionally, ingress link) to a speciﬁc egress ISP (and
optionally, egress link), including backup ingress router IP ad-
dresses in case of failures,
• the pricing model of the offered transit paths and services, and
• the SLAs provided, such as bandwidth, latency, and maximum
packet loss rate guarantees.
In addition, the portal needs to provide the ability to obtain and
relinquish a path by returning or accepting a corresponding identi-
ﬁcation token, which we call an authenticator. The authenticator is
used in actual ARROW trafﬁc to prove that the endpoint originat-
ing the packet is authorized to use the transit path. The router must
check the authenticator and drop the packet if it does not match. If
the authenticator is compromised, the only penalty is that the cus-
tomer of the service is charged for extra unrelated trafﬁc traversing
the pipe. Techniques to safeguard the authenticator against eaves-
dropping, such as encoding it with the hash of the checksum of the
packet, may be used. Attackers can then only replay entire packets,
but they cannot use snooped authenticators for other packets.
Figure 1: Three example ARROW paths from PowerData to
Amazon: the dotted lines represent the BGP path. The two
dashed lines are ARROW paths.
High Availability: We want endpoints to be able to establish one
or more high quality paths across the Internet, provided a physi-
cal path exists through ISPs willing to be paid for the service. For
availability, endpoints need the ability to route around persistent
reachability problems, as well as to establish multiple paths to min-
imize disruptions due to transient routing loops and blackholes.
Robustness: Because security attacks against the Internet are a
real threat, we need to provide endpoints the means to defend their
routes, both by proactive installation of desirable paths and ﬁlters
and reactive rerouting of trafﬁc in response to degradation in packet
delivery.
In this section, we provide a brief overview of our approach be-
fore describing the key components of our design.
3.1 Overview
We provide an overview of our approach using a simple example
shown in Figure 1. A company called PowerData is using Amazon
cloud services for its day-to-day data storage. Using BGP, trafﬁc
to Amazon would be routed via Comcast (PowerData’s upstream
ISP), Sprint, and either FlakyISP or AT&T. However, FlakyISP of-
ten drops packets and has caused PowerData’s service to be slow
whenever the path through FlakyISP is chosen by Sprint and Com-
cast. Note that, while PowerData can ﬁnd out about the problem
using various available Internet measurement technologies, it has
limited or no control over the paths selected by Sprint (a remote
ISP) and Comcast (the local transit provider).
To remedy this, PowerData buys ARROW transit from AT&T,
which involves provisioning a path through AT&T and establish-
ing the appropriate packet forwarding rules to transmit PowerData
packets along to Amazon and received responses back to Power-
Data. This ensures that PowerData packets to and from Amazon
are routed around FlakyISP since it does not appear on any of the
paths between Comcast and AT&T nor does it appear on the paths
between AT&T and Amazon. Note that PowerData does not have
to provision paths across every ISP on its path to/from Amazon in
order to avoid FlakyISP. Rather, a limited amount of route control
at a remote ISP (AT&T in this example) sufﬁces to achieve the de-
sired paths.
To ensure that reconﬁgurations and temporary outages (for ex-
ample, due to routing loops or misconﬁgurations) at Sprint and
AT&T do not impact PowerData’s service, PowerData also buys
ARROW transit from Level 3 and can fail-over to this path in case
of problems with the original path.
The example illustrates several properties of our proposed ap-
proach. First, the system is incrementally deployable by an ISP,
with incremental incentives to that ISP. An ISP can provide AR-
ROW even if none of its peer, customer or provider ISPs partici-
AT&TSprintComcastAmazonFlakyISPPowerDataARROWARROWLevel 3ARROWARROWFigure 2: Example ARROW transit setup process. Blue routers
in ISPs A and C are ARROW-compatible, gray routers in ISP B
are not. Dashed lines show the path chosen in case (a). Dotted
lines show the detour taken via another ARROW ISP in case
(b). The BGP path in this example is Home-B-Target.
Finally, an RPC interface should be provided that allows clients
to stitch together transit segments of multiple providers into an end-
to-end path. The call may look like this:
chain_path(auth, nextHopAddr, nextHopAuth)
It causes the egress router of an existing ARROW tunnel seg-
ment (identiﬁed by its authenticator auth) to route tunnel trafﬁc
to the IP address nextHopAddr and set the ARROW authentica-
tor of the next hop to nextHopAuth.
An end host contacts one or more of the ARROW ISPs on the
route via this interface and requests provisioned paths through the
individual networks. The ARROW customer then arranges for the
routing of the packet by associating with each hop the address for
each subsequent hop that needs to be traversed. We note that links
within an ISP might run out of excess capacity, but that only pre-
vents future ARROW tunnels from being set up; existing agree-
ments can stay in place. Market prices can then signal a need for
more capacity.
From the ISP-provided lists of ingress and egress points, end-
points are able to compile an atlas, which they can use to determine
a path to a destination. Any shortest path discovery algorithm can
be used on the atlas to determine which ISPs to use to create an
end-to-end circuit. We envision that, eventually, another Internet
webservice maintains the atlas and provides a path query interface,
returning paths according to any of a number of these algorithms.
Most of the information we require ISPs to advertise to potential
customers is already advertised to their direct peers, and much of it
is already publically available.
Figure 2 shows an example of an Internet endpoint arranging an
ARROW circuit with a target endpoint, registering with a number
of ISPs. It also shows how the circuit is maintained by each of the
ISPs. Two cases are considered:
(a) A tier 1 ISP A that is the provider for our home ISP sup-
ports ARROW and a circuit is created via this ISP. Other trafﬁc is
routed via BGP through a non-ARROW supporting ISP B to the
ﬁnal destination. The path in this case is Home-A-B-Target.
(b) An additional ARROW-supporting ISP C is conﬁgured to
avoid the non-ARROW ISP B. In this case, we conﬁgure ISP A
to forward packets to ISP C, via ARROW. The path in this case is
Home-A-C-Target.
In both cases, the endpoint ﬁrst optionally contacts an Internet
atlas service to determine which ISPs to contract for ARROW ser-
vice (1). Then, the home endpoint contacts the portals of the appro-
priate ARROW ISPs on the circuit to create ARROW SLAs. This
typically has to happen in reverse order (2 and then 3), from des-
tination endpoint to source endpoint, so that next-hop information
can be given.
ARROW paths are unidirectional. The reverse path can be pro-
visioned either by the peer, or by the originator of the trafﬁc. This
Figure 3: Relevant ﬁelds of an ARROW packet (in bold). Dst
Addr is the IP address of the ﬁnal destination. Note that the
source endpoint IP address and other IP header ﬁelds are du-
plicated by the envelope IP header.
might depend upon the relationship of the peers. If the source party
is a customer of a cloud service, it makes sense for the source to
provision both paths. A peer-to-peer relationship can be provi-
sioned by either peer individually.
3.3 Data Forwarding
To route trafﬁc via ARROW, the source (or its proxy) encapsu-
lates every IP data packet in a separate IP envelope, as shown in
Figure 3. The envelope also contains the authenticator in a special
ﬁeld (Hop Auth). The envelope’s destination is set to the next AR-
ROW hop’s IP address (Hop Addr) and its next-level protocol ﬁeld
is set to a value identifying ARROW (ARROW Prot).
The source then sends the packet normally through its local net-
work. If the customer has a chain of ARROW providers, then each
modiﬁes the packet with the address and authenticator of the next
hop, according to its local ARROW forwarding table; the last ISP
in the chain removes the IP header encapsulation before forward-
ing. This model requires each ARROW router to have an appropri-
ate entry per ARROW tunnel in its forwarding table, contributing
to the growth of forwarding tables. Modern forwarding and ta-
ble storage techniques [28], however, make routing table scalability
less of a concern.
We do require some level of hardware support in routers, but it is
minimal and similar to the hardware already in place: in many ISPs,
ingress routers demux incoming trafﬁc based on the destination ad-
dress to a speciﬁc MPLS tunnel to route the trafﬁc across their
network. We can leverage similar hardware support in ARROW:
the ingress router must be able to demux on the ARROW address
(and if necessary the ARROW authenticator), route the packet us-
ing MPLS or other means, and then modify the header to insert
the next hop address and authenticator. Alternatively, ISPs can op-
erate high-speed software routers (e.g., RouteBricks [8], Packet-
Shader [11]) at ingress/egress PoPs to perform the necessary tasks
for ARROW trafﬁc.
3.4 Failures and Performance Regressions
Failures. Most failures along an ARROW circuit can be handled
by ISPs directly. Some failures require endpoints to cooperate,
however. Speciﬁcally, in an ARROW circuit, failure can occur at
several different levels:
• failure of a router internal to an ISP,
• failure of a router at the edge of an ISP, or
• failure of a whole ISP.
If an internal router fails, the ISP is responsible for detecting
this failure and routing around it. ISPs today typically have multi-
ple redundant paths between the ingress and egress PoPs, and can
thus use MPLS mechanisms to conﬁgure backup paths and switch
the intradomain paths in a seamless manner. For instance, MPLS
Fast Reroute allows routers inside the ISP to redirect trafﬁc onto a
predetermined backup path when they detect failures in upstream
routers [30].
Home ISPTarget ISPISP BISP AARROWARROWInternet atlasISP CARROWARROW(1)(2)(3)SrcAddrHop Addr…Hop AuthIP envelopeARROWTransportARROWProtSrcAddrDstAddrIP headerSince edge routers correspond to boundaries between ISPs, edge
routers belonging to different ISPs need to cooperatively handle
failover. Thus, we have designed a failover protocol which must be
implemented by each participating ISP. Our implementation does
not perform failure detection, since we believe that in general the
endpoint will be able to do a better job of determining whether its
trafﬁc is actually arriving at the server. Therefore, failover is an
endpoint-driven process in this case.
When the endpoint detects a failure along an ARROW path (i.e.,
it detects that its trafﬁc is not successfully arriving at the desti-
nation), it sends a special probe packet along the same path. Each
ISP’s router is required to respond to the previous hop of the probe
packet and also forward it normally along the path. This is similar
to what happens when an IP packet has reached its end of life, ex-
cept that the packet is also forwarded and the response goes to the
previous hop instead of the source of the packet.
If the endpoint does not receive an acknowledgment from the
ﬁrst ISP, it concludes that the ﬁrst ISP is where the failure exists
and fails over to another edge router in the same ISP. If the ﬁrst ISP
does receive the endpoint’s probe, it ﬁrst acknowledges it so that
the endpoint doesn’t assume it has failed, then forwards the probe
to the second ISP. Thus, the probe is initiated by the endpoint but
is actually performed at each non-failing ISP node in the circuit.
For example, assume a circuit has been established between an
endpoint E, ISP A, ISP B, and a server S. Each ISP has three
routing nodes; we call them A1, A2, A3 and B1, B2, B3. When
the circuit is ﬁrst established, it goes from E to A1 to B1 to S. At
some later time, B1 fails. E detects that S isn’t receiving its mes-
sages and initiates the failover process by sending a probe packet
to A1. A1 receives and acknowledges the probe, then forwards it to
B1. A1 does not receive an acknowledgment within a link-latency-
determined timeout, and concludes (correctly) that B1 has failed.
A1 then forwards the probe to B2, which acknowledges it. In re-
sponse, A1 updates its local state so that packets on the circuit go
to B2 rather than B1. Subsequent trafﬁc is now routed through the
new circuit and E detects that the failover has succeeded.
If the ISP as a whole fails, the endpoint will need to provision an
alternate route. An endpoint can establish multiple ARROW paths
to the destination simultaneously and use them in conjunction with
the original path for fast failover.
Performance regressions. To help endpoints investigate circuit
performance, ISPs should provide a ping service at egress PoPs
to arbitrary IP addresses and ARROW routers need to be able to
respond to ICMP requests. Endpoints then have the ability to in-
dependently gather all required information to analyze the perfor-
mance of each circuit segment.
3.5 Security
The design presented thus far has a few security issues: AR-
ROW paths and their endpoints might be DoS-attacked, the avail-
ability of trusted ARROW ISPs might be spotty and trafﬁc has to
traverse non-ARROW ISPs, and ARROW users themselves might
be malicious. We now address these issues.
DoS attacks. ARROW paths can be set up to resemble swarms
of packet forwarders [7] in order to increase path availability in
the face of DoS attacks. Figure 4 demonstrates how this can be
achieved: multiple ARROW segments are conﬁgured within one
ARROW supporting ISP to mitigate the effects of DoS attacks to
ARROW ingress points. Since ARROW clients can migrate their
trafﬁc to another ingress PoP if their PoP is overloaded, attackers
have to overwhelm all provided ingress points simultaneously in
order to stop trafﬁc to the destination. If the destination endpoint’s
Figure 4: DoS attack prevention using ARROW.
IP address is kept secret, it does not matter whether the ARROW
supporting ISP is the endpoint’s local ISP or an arbitrary remote
ISP. Otherwise, if the provider of the destination endpoint provides
ARROW, the endpoint’s ISP can drop all non-ARROW trafﬁc and
protect the endpoint in this way.
Securing spotty ARROW routes. To ensure that its packets tra-
verse only trusted ISPs, an endpoint can set up ARROW circuits
through each intermediate ISP in an end-to-end path. If some of the
intermediate ISPs don’t provide ARROW support, endpoints have
to resort to normal Internet routing between the ARROW ISPs.
This means that those hops are vulnerable to BGP effects such as
preﬁx hijacking and rerouting of packets through untrusted ISPs.
However, if the AS path lengths of the non-ARROW segments are
small, then only those ASes that are within the local neighborhood
of these segments would be able to mount an effective preﬁx hi-
jacking attack. Additionally, in order to disrupt an ARROW route,
the hijacking entity has to pollute the routing entry at a speciﬁc
egress PoP as opposed to any arbitrary PoP inside the ARROW
supporting ISP. Further, if an ARROW ISP is a provider of the non-
participating ISP (e.g., the ARROW ISP is a tier 1 ISP), then also