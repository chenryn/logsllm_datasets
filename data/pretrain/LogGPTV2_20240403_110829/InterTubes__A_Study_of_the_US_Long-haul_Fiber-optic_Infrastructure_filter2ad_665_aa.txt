title:InterTubes: A Study of the US Long-haul Fiber-optic Infrastructure
author:Ramakrishnan Durairajan and
Paul Barford and
Joel Sommers and
Walter Willinger
InterTubes: A Study of the US Long-haul Fiber-optic
Infrastructure
Ramakrishnan Durairajan†, Paul Barford†*, Joel Sommers+, Walter Willinger‡
{rkrish,pb}@cs.wisc.edu, PI:EMAIL, PI:EMAIL
†University of Wisconsin - Madison
*comScore, Inc.
+Colgate University
‡NIKSUN, Inc.
ABSTRACT
The complexity and enormous costs of installing new long-
haul ﬁber-optic infrastructure has led to a signiﬁcant amount
of infrastructure sharing in previously installed conduits. In
this paper, we study the characteristics and implications of
infrastructure sharing by analyzing the long-haul ﬁber-optic
network in the US.
We start by using ﬁber maps provided by tier-1 ISPs and
major cable providers to construct a map of the long-haul US
ﬁber-optic infrastructure. We also rely on previously under-
utilized data sources in the form of public records from fed-
eral, state, and municipal agencies to improve the ﬁdelity
of our map. We quantify the resulting map’s1 connectivity
characteristics and conﬁrm a clear correspondence between
long-haul ﬁber-optic, roadway, and railway infrastructures.
Next, we examine the prevalence of high-risk links by map-
ping end-to-end paths resulting from large-scale traceroute
campaigns onto our ﬁber-optic infrastructure map. We show
how both risk and latency (i.e., propagation delay) can be
reduced by deploying new links along previously unused
transportation corridors and rights-of-way. In particular, fo-
cusing on a subset of high-risk links is sufﬁcient to improve
the overall robustness of the network to failures. Finally, we
discuss the implications of our ﬁndings on issues related to
performance, net neutrality, and policy decision-making.
CCS Concepts
•Networks → Physical links; Physical topologies;
Keywords
Long-haul ﬁber map; shared risk; risk mitigation
1The constructed long-haul map along with datasets are
openly available to the community through the U.S. DHS
PREDICT portal (www.predict.org).
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than ACM must be honored. Abstracting with credit is per-
mitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
SIGCOMM ’15, August 17–21, 2015, London, United Kingdom
© 2015 ACM. ISBN 978-1-4503-3542-3/15/08. . . $15.00
DOI: http://dx.doi.org/10.1145/2785956.2787499
1 Introduction
The desire to tackle the many challenges posed by novel
designs, technologies and applications such as data cen-
ters, cloud services, software-deﬁned networking (SDN),
network functions virtualization (NFV), mobile communi-
cation and the Internet-of-Things (IoT) has fueled many of
the recent research efforts in networking. The excitement
surrounding the future envisioned by such new architectural
designs, services, and applications is understandable, both
from a research and industry perspective. At the same time,
it is either taken for granted or implicitly assumed that the
physical infrastructure of tomorrow’s Internet will have the
capacity, performance, and resilience required to develop
and support ever more bandwidth-hungry, delay-intolerant,
or QoS-sensitive services and applications. In fact, despite
some 20 years of research efforts that have focused on un-
derstanding aspects of the Internet’s infrastructure such as its
router-level topology or the graph structure resulting from
its inter-connected Autonomous Systems (AS), very little
is known about today’s physical Internet where individual
components such as cell towers, routers or switches, and
ﬁber-optic cables are concrete entities with well-deﬁned ge-
ographic locations (see, e.g., [2, 36, 83]). This general lack
of a basic understanding of the physical Internet is exem-
pliﬁed by the much-ridiculed metaphor used in 2006 by the
late U.S. Senator Ted Stevens (R-Alaska) who referred to the
Internet as “a series of tubes" [65].2
The focus of this paper is the physical Internet. In partic-
ular, we are concerned with the physical aspects of the wired
Internet, ignoring entirely the wireless access portion of the
Internet as well as satellite or any other form of wireless
communication. Moreover, we are exclusively interested in
the long-haul ﬁber-optic portion of the wired Internet in the
US. The detailed metro-level ﬁber maps (with correspond-
ing colocation and data center facilities) and international
undersea cable maps (with corresponding landing stations)
are only accounted for to the extent necessary. In contrast
to short-haul ﬁber routes that are speciﬁcally built for short
distance use and purpose (e.g., to add or drop off network
services in many different places within metro-sized areas),
2Ironically, this infamous metaphor turns out to be not all
that far-fetched when it comes to describing the portion of
the physical Internet considered in this paper.
565long-haul ﬁber routes (including ultra long-haul routes) typ-
ically run between major city pairs and allow for minimal
use of repeaters.
With the US long-haul ﬁber-optic network being the main
focal point of our work, the ﬁrst contribution of this paper
consists of constructing a reproducible map of this basic
component of the physical Internet infrastructure. To that
end, we rely on publicly available ﬁber maps provided by
many of the tier-1 ISPs and major cable providers. While
some of these maps include the precise geographic locations
of all the long-haul routes deployed or used by the corre-
sponding networks, other maps lack such detailed informa-
tion. For the latter, we make extensive use of previously ne-
glected or under-utilized data sources in the form of public
records from federal, state, or municipal agencies or docu-
mentation generated by commercial entities (e.g., commer-
cial ﬁber map providers [34], utility rights-of-way (ROW)
information, environmental impact statements, ﬁber sharing
arrangements by the different states’ DOTs). When com-
bined, the information available in these records is often suf-
ﬁcient to reverse-engineer the geography of the actual long-
haul ﬁber routes of those networks that have decided against
publishing their ﬁber maps. We study the resulting map’s
diverse connectivity characteristics and quantify the ways in
which the observed long-haul ﬁber-optic connectivity is con-
sistent with existing transportation (e.g., roadway and rail-
way) infrastructure. We note that our work can be repeated
by anyone for every other region of the world assuming sim-
ilar source materials.
A striking characteristic of the constructed US long-haul
ﬁber-optic network is a signiﬁcant amount of observed in-
frastructure sharing. A qualitative assessment of the risk in-
herent in this observed sharing of the US long-haul ﬁber-
optic infrastructure forms the second contribution of this pa-
per. Such infrastructure sharing is the result of a common
practice among many of the existing service providers to de-
ploy their ﬁber in jointly-used and previously installed con-
duits and is dictated by simple economics—substantial cost
savings as compared to deploying ﬁber in newly constructed
conduits. By considering different metrics for measuring the
risks associated with infrastructure sharing, we examine the
presence of high-risk links in the existing long-haul infras-
tructure, both from a connectivity and usage perspective. In
the process, we follow prior work [99] and use the popu-
larity of a route on the Internet as an informative proxy for
the volume of trafﬁc that route carries. End-to-end paths de-
rived from large-scale traceroute campaigns are overlaid on
the actual long-haul ﬁber-optic routes traversed by the cor-
responding traceroute probes. The resulting ﬁrst-of-its-kind
map enables the identiﬁcation of those components of the
long-haul ﬁber-optic infrastructure which experience high
levels of infrastructure sharing as well as high volumes of
trafﬁc.
The third and ﬁnal contribution of our work is a de-
tailed analysis of how to improve the existing long-haul
ﬁber-optic infrastructure in the US so as to increase its re-
silience to failures of individual links or entire shared con-
duits, or to achieve better performance in terms of reduced
propagation delay along deployed ﬁber routes. By framing
the issues as appropriately formulated optimization prob-
lems, we show that both robustness and performance can
be improved by deploying new ﬁber routes in just a few
strategically-chosen areas along previously unused trans-
portation corridors and ROW, and we quantify the achiev-
able improvements in terms of reduced risk (i.e., less in-
frastructure sharing) and decreased propagation delay (i.e.,
faster Internet [100]). As actionable items, these technical
solutions often conﬂict with currently-discussed legislation
that favors policies such as “dig once", “joint trenching" or
“shadow conduits" due to the substantial savings that result
when ﬁber builds involve multiple prospective providers or
are coordinated with other infrastructure projects (i.e., utili-
ties) targeting the same ROW [7]. In particular, we discuss
our technical solutions in view of the current net neutral-
ity debate concerning the treatment of broadband Internet
providers as telecommunications services under Title II. We
argue that the current debate would beneﬁt from a quanti-
tative assessment of the unavoidable trade-offs that have to
be made between the substantial cost savings enjoyed by fu-
ture Title II regulated service providers (due to their ensu-
ing rights to gain access to existing essential infrastructure
owned primarily by utilities) and an increasingly vulnerable
national long-haul ﬁber-optic infrastructure (due to legisla-
tion that implicitly reduced overall resilience by explicitly
enabling increased infrastructure sharing).
2 Mapping Core Long-haul Infrastruc-
ture
In this section we describe the process by which we con-
struct a map of the Internet’s long-haul ﬁber infrastructure
in the continental United States. While many dynamic as-
pects of the Internet’s topology have been examined in prior
work, the underlying long-haul ﬁber paths that make up the
Internet are, by deﬁnition, static3, and it is this ﬁxed infras-
tructure which we seek to identify.
Our high-level deﬁnition of a long-haul link4 is one that
connects major city-pairs.
In order to be consistent when
processing existing map data, however, we use the follow-
ing concrete deﬁnition. We deﬁne a long-haul link as one
that spans at least 30 miles, or that connects population cen-
ters of at least 100,000 people, or that is shared by at least 2
providers. These numbers are not proscriptive, rather they
emerged through an iterative process of reﬁning our base
map (details below).
The steps we take in the mapping process are as follows:
(1) we create an initial map by using publicly available ﬁber
maps from tier-1 ISPs and major cable providers which con-
tain explicit geocoded information about long-haul link loca-
tions; (2) we validate these link locations and infer whether
ﬁber conduits are shared by using a variety of public records
3More precisely, installed conduits rarely become defunct,
and deploying new conduits takes considerable time.
4In the rest of the paper, we will use the terms “link"
and “conduit" interchangeably—a “tube" or trench specially
built to house the ﬁber of potentially multiple providers.
566documents such as utility right-of-way information; (3) we
add links from publicly available ISP ﬁber maps (both tier-
1 and major providers) which have geographic information
about link endpoints, but which do not have explicit infor-
mation about geographic pathways of ﬁber links; and (4)
we again employ a variety of public records to infer the
geographic locations of this latter set of links added to the
map. Below, we describe this process in detail, providing
examples to illustrate how we employ different information
sources.
2.1 Step 1: Build an Initial Map
The ﬁrst step in our ﬁber map-building process is to lever-
age maps of ISP ﬁber infrastructure with explicit geocoding
of links from Internet Atlas project [83]. Internet Atlas is
a measurement portal created to investigate and unravel the
structural complexity of the physical Internet. Detailed ge-
ography of ﬁber maps are captured using the procedure de-
scribed, esp. §3.2, in [83]. We start with these maps because
of their potential to provide a signiﬁcant and reliable portion
of the overall map.
Speciﬁcally, we used detailed ﬁber deployment maps5
from 5 tier-1 and 4 major cable providers: AT&T [6],
Comcast [16], Cogent [14], EarthLink [29], Integra [43],
Level3 [48], Suddenlink [63], Verizon [72] and Zayo [73].
For example, the map we used for Comcast’s network [16]
lists all the node information along with the exact geography
of long-haul ﬁber links. Table 1 shows the number of nodes
and links we include in the map for each of the 9 providers
we considered. These ISPs contributed 267 unique nodes,
1258 links, and a total of 512 conduits to the map. Note
that some of these links may follow exactly the same phys-
ical pathway (i.e., using the same conduit). We infer such
conduit sharing in step 2.
2.2 Step 2: Checking the Initial Map
While the link location data gathered as part of the ﬁrst
step are usually reliable due to the stability and static nature
of the underlying ﬁber infrastructure, the second step in the
mapping process is to collect additional information sources
to validate these data. We also use these additional infor-
mation sources to infer whether some links follow the same
physical ROW, which indicates that the ﬁber links either re-
side in the same ﬁber bundle, or in an adjacent conduit.
In this step of the process, we use a variety of public
records to geolocate and validate link endpoints and con-
duits. These records tend to be rich with detail, but have been
under-utilized in prior work that has sought to identify the
physical components that make up the Internet. Our work-
ing assumption is that ISPs, government agencies, and other
relevant parties often archive documents on public-facing
5Although some of the maps date back a number of years,
due to the static nature of ﬁber deployments and especially
due to the reuse of existing conduits for new ﬁber deploy-
ments [58], these maps remain very valuable and provide
detailed information about the physical location of conduits
in current use. Also, due to varying accuracy of the sources,
some maps required manual annotation, georeferencing [35]
and validation/inference (step 2) during the process.
websites, and that these documents can be used to validate
and identify link/conduit locations. Speciﬁcally, we seek
information that can be extracted from government agency
ﬁlings (e.g., [13, 18, 26]), environmental impact statements
(e.g., [71]), documentation released by third-party ﬁber ser-
vices (e.g., [3–5,10]), indefeasible rights of use (IRU) agree-
ments (e.g., [44, 45]), press releases (e.g., [49, 50, 52, 53]),
and other related resources (e.g., [8, 11, 23, 27, 28, 59, 67]).
Public records concerning rights-of-way are of particular
importance to our work since highly-detailed location and
conduit sharing information can be gleaned from these re-
sources. Laws governing rights of way are established on a
state-by-state basis (e.g., see [31]), and which local organi-
zation has jurisdiction varies state-by-state [1]. As a result,
care must be taken when validating or inferring the ROW
used for a particular ﬁber link. Since these state-speciﬁc
laws are public, however, they establish a number of key pa-
rameters to drive a systematic search for government-related
public ﬁlings.
In addition to public records, the fact that a ﬁber-optic
link’s location aligns with a known ROW serves as a type of
validation. Moreover, if link locations for multiple service
providers align along the same geographic path, we consider
those links to be validated.
To continue the example of Comcast’s network, we used,
in part, the following documents to validate the locations of
links and to determine which links run along shared paths
with other networks: (1) a broadband environment study
by the FCC details several conduits shared by Comcast and
other providers in Colorado [12], (2) a franchise agree-
ment [20,21] made by Cox with Fairfax county, VA suggests
the presence of a link running along the ROW with Com-
cast and Verizon, (3) page 4 (utilities section) of a project
document [24] to design services for Wekiva Parkway from
Lake County to the east of Round Lake Road (Orlando,
FL) demonstrates the presence of Comcast’s infrastructure
along a ROW with other entities like CenturyLink, Progress
Energy and TECO/People’s Gas, (4) an Urbana city coun-
cil project update [68] shows pictures [69] of Comcast and
AT&T’s ﬁber deployed in the Urbana, IL area, and (5) doc-
uments from the CASF project [70] in Nevada county, CA
show that Comcast has deployed ﬁber along with AT&T and
Suddenlink.
2.3 Step 3: Build an Augmented Map
The third step of our long-haul ﬁber map construction pro-
cess is to use published maps of tier-1 and large regional
ISPs which do not contain explicit geocoded information.
We tentatively add the ﬁber links from these ISPs to the
map by aligning the logical links indicated in their published
maps along the closest known right-of-way (e.g., road or
rail). We validate and/or correct these tentative placements
in the next step.