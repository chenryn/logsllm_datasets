Session 3C: Inference Attacks CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea876[3] Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Srndic,
Pavel Laskov, Giorgio Giacinto, and Fabio Roli. Evasion Attacks against Machine
Learning at Test Time. In European Conference on Machine Learning and Principles
and Practice of Knowledge Discovery in Databases (ECML/PKDD), pages 387â€“402.
Springer, 2013.
[4] IvÃ¡n Cantador, Peter Brusilovsky, and Tsvi Kuflik. Second Workshop on Infor-
mation Heterogeneity and Fusion in Recommender Systems (HetRec2011). In
ACM Conference on Recommender Systems (RecSys), pages 387â€“388. ACM, 2011.
[5] Nicholas Carlini, Chang Liu, Ãšlfar Erlingsson, Jernej Kos, and Dawn Song. The
Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Net-
works. In USENIX Security Symposium (USENIX Security), pages 267â€“284. USENIX,
2019.
[6] Nicholas Carlini, Florian TramÃ¨r, Eric Wallace, Matthew Jagielski, Ariel Herbert-
Voss, Katherine Lee, Adam Roberts, Tom B. Brown, Dawn Song, Ãšlfar Erlingsson,
Alina Oprea, and Colin Raffel. Extracting Training Data from Large Language
Models. CoRR abs/2012.07805, 2020.
[7] Nicholas Carlini and David Wagner. Towards Evaluating the Robustness of
Neural Networks. In IEEE Symposium on Security and Privacy (S&P), pages 39â€“57.
IEEE, 2017.
[8] Dingfan Chen, Ning Yu, Yang Zhang, and Mario Fritz. GAN-Leaks: A Taxonomy
of Membership Inference Attacks against Generative Models. In ACM SIGSAC
Conference on Computer and Communications Security (CCS), pages 343â€“362.
ACM, 2020.
[9] Wanyu Chen, Fei Cai, Honghui Chen, and Maarten de Rijke. Joint Neural Collab-
orative Filtering for Recommender Systems. ACM Transactions on Information
Systems, 2019.
[10] Christopher A. Choquette Choo, Florian TramÃ¨r, Nicholas Carlini, and Nicolas
Papernot. Label-Only Membership Inference Attacks. CoRR abs/2007.14321, 2020.
[11] Mukund Deshpande and George Karypis. Item-Based Top-N Recommendation
Algorithms. ACM Transactions on Information Systems, 2004.
[12] Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Grag. Badnets: Identifying Vul-
nerabilities in the Machine Learning Model Supply Chain. CoRR abs/1708.06733,
2017.
[13] F. Maxwell Harper and Joseph A Konstan. The MovieLens Datasets: History and
Context. ACM Transactions on Interactive Intelligent Systems, 2015.
[14] Jamie Hayes, Luca Melis, George Danezis, and Emiliano De Cristofaro. LOGAN:
Evaluating Privacy Leakage of Generative Models Using Generative Adversarial
Networks. Symposium on Privacy Enhancing Technologies Symposium, 2019.
[15] Ruining He and Julian McAuley. Ups and Downs: Modeling the Visual Evolution
of Fashion Trends with One-Class Collaborative Filtering. In The Web Conference
(WWW), pages 507â€“517. ACM, 2016.
[16] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng
Chua. Neural Collaborative Filtering. In International Conference on World Wide
Web (WWW), pages 173â€“182. ACM, 2017.
[17] Xiangnan He, Hanwang Zhang, Min-Yen Kan, and Tat-Seng Chua. Fast Matrix
Factorization for Online Recommendation with Implicit Feedback. In International
ACM SIGIR Conference on Research and Development in Information Retrieval
(SIGIR), pages 549â€“558. ACM, 2016.
[18] Xinlei He, Jinyuan Jia, Michael Backes, Neil Zhenqiang Gong, and Yang Zhang.
Stealing Links from Graph Neural Networks. In USENIX Security Symposium
(USENIX Security). USENIX, 2021.
[19] Jonathan L. Herlocker, Joseph A. Konstan, and John Riedl. Explaining Collabo-
rative Filtering Recommendations. In ACM Conference on Computer Supported
Cooperative Work (CSCW), pages 241â€“250. ACM, 2000.
[20] Matthew Jagielski, Nicholas Carlini, David Berthelot, Alex Kurakin, and Nicolas
Papernot. High Accuracy and High Fidelity Extraction of Neural Networks. In
USENIX Security Symposium (USENIX Security), pages 1345â€“1362. USENIX, 2020.
[21] Matthew Jagielski, Alina Oprea, Battista Biggio, Chang Liu, Cristina Nita-Rotaru,
and Bo Li. Manipulating Machine Learning: Poisoning Attacks and Countermea-
sures for Regression Learning. In IEEE Symposium on Security and Privacy (S&P),
pages 19â€“35. IEEE, 2018.
[22] Jinyuan Jia, Ahmed Salem, Michael Backes, Yang Zhang, and Neil Zhenqiang
Gong. MemGuard: Defending against Black-Box Membership Inference At-
tacks via Adversarial Examples. In ACM SIGSAC Conference on Computer and
Communications Security (CCS), pages 259â€“274. ACM, 2019.
[23] George Karypis. Evaluation of Item-Based Top-N Recommendation Algorithms.
In ACM International Conference on Information and Knowledge Management
(CIKM), pages 247â€“254. ACM, 2001.
[24] Yehuda Koren. Factorization Meets the Neighborhood: a Multifaceted Collab-
orative Filtering Model. In ACM Conference on Knowledge Discovery and Data
Mining (KDD), pages 426â€“434. ACM, 2008.
[25] Yehuda Koren. Collaborative Filtering with Temporal Dynamics. In ACM Con-
ference on Knowledge Discovery and Data Mining (KDD), pages 447â€“456. ACM,
2009.
[26] Klas Leino and Matt Fredrikson. Stolen Memories: Leveraging Model Memo-
rization for Calibrated White-Box Membership Inference. In USENIX Security
Symposium (USENIX Security), pages 1605â€“1622. USENIX, 2020.
[27] Zheng Li, Chengyu Hu, Yang Zhang, and Shanqing Guo. How to Prove Your Model
Belongs to You: A Blind-Watermark based Framework to Protect Intellectual
Property of DNN. In Annual Computer Security Applications Conference (ACSAC),
pages 126â€“137. ACM, 2019.
[28] Zheng Li and Yang Zhang. Membership Leakage in Label-Only Exposures. In
ACM SIGSAC Conference on Computer and Communications Security (CCS). ACM,
2021.
[29] Luca Melis, Congzheng Song, Emiliano De Cristofaro, and Vitaly Shmatikov.
In IEEE
Exploiting Unintended Feature Leakage in Collaborative Learning.
Symposium on Security and Privacy (S&P), pages 497â€“512. IEEE, 2019.
[30] Milad Nasr, Reza Shokri, and Amir Houmansadr. Machine Learning with Mem-
bership Privacy using Adversarial Regularization. In ACM SIGSAC Conference on
Computer and Communications Security (CCS), pages 634â€“646. ACM, 2018.
[31] Milad Nasr, Reza Shokri, and Amir Houmansadr. Comprehensive Privacy Analy-
sis of Deep Learning: Passive and Active White-box Inference Attacks against
Centralized and Federated Learning. In IEEE Symposium on Security and Privacy
(S&P), pages 1021â€“1035. IEEE, 2019.
[32] Milad Nasr, Shuang Song, Abhradeep Thakurta, Nicolas Papernot, and Nicholas
Carlini. Adversary Instantiation: Lower Bounds for Differentially Private Machine
Learning. In IEEE Symposium on Security and Privacy (S&P). IEEE, 2021.
[33] Nicolas Papernot, Patrick McDaniel, Arunesh Sinha, and Michael Wellman. SoK:
Towards the Science of Security and Privacy in Machine Learning.
In IEEE
European Symposium on Security and Privacy (Euro S&P), pages 399â€“414. IEEE,
2018.
[34] Nicolas Papernot, Shuang Song, Ilya Mironov, Ananth Raghunathan, Kunal Tal-
war, and Ãšlfar Erlingsson. Scalable Private Learning with PATE. In International
Conference on Learning Representations (ICLR), 2018.
[35] Michael J. Pazzani and Daniel Billsus. Content-Based Recommendation Systems.
In The Adaptive Web, Methods and Strategies of Web Personalization, pages 325â€“341.
Springer, 2007.
[36] Huseyin Polat and Wenliang Du. SVD-based Collaborative Filtering with Privacy.
In ACM Symposium on Applied Computing (SAC), pages 791â€“795. ACM, 2005.
[37] Alexandre Sablayrolles, Matthijs Douze, Cordelia Schmid, Yann Ollivier, and
HervÃ© JÃ©gou. White-box vs Black-box: Bayes Optimal Strategies for Membership
Inference. In International Conference on Machine Learning (ICML), pages 5558â€“
5567. PMLR, 2019.
[38] Ruslan Salakhutdinov and Andriy Mnih. Probabilistic Matrix Factorization. In
Annual Conference on Neural Information Processing Systems (NIPS), pages 1257â€“
1264. NIPS, 2007.
[39] Ahmed Salem, Yang Zhang, Mathias Humbert, Pascal Berrang, Mario Fritz, and
Michael Backes. ML-Leaks: Model and Data Independent Membership Inference
Attacks and Defenses on Machine Learning Models. In Network and Distributed
System Security Symposium (NDSS). Internet Society, 2019.
[40] Badrul Munir Sarwar, George Karypis, Joseph A. Konstan, and John Riedl. Item-
Based Collaborative Filtering Recommendation Algorithms.
In International
Conference on World Wide Web (WWW), pages 285â€“295. ACM, 2001.
[41] J. Ben Schafer, Dan Frankowski, Jon Herlocker, and Shilad Sen. Collaborative
Filtering Recommender Systems. In The Adaptive Web, Methods and Strategies of
Web Personalization, pages 291â€“324. Springer, 2007.
[42] Virat Shejwalkar and Amir Houmansadr. Membership Privacy for Machine
Learning Models Through Knowledge Transfer. In AAAI Conference on Artificial
Intelligence (AAAI). AAAI, 2021.
[43] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. Member-
ship Inference Attacks Against Machine Learning Models. In IEEE Symposium
on Security and Privacy (S&P), pages 3â€“18. IEEE, 2017.
[44] Reza Shokri, Georgios Theodorakopoulos, Jean-Yves Le Boudec, and Jean-Pierre
Hubaux. Quantifying Location Privacy. In IEEE Symposium on Security and
Privacy (S&P), pages 247â€“262. IEEE, 2011.
[45] Congzheng Song and Vitaly Shmatikov. Auditing Data Provenance in Text-
Generation Models. In ACM Conference on Knowledge Discovery and Data Mining
(KDD), pages 196â€“206. ACM, 2019.
[46] Peijie Sun, Le Wu, and Meng Wang. Attentive Recurrent Social Recommenda-
tion. In International ACM SIGIR Conference on Research and Development in
Information Retrieval (SIGIR), pages 185â€“194. ACM, 2018.
[47] Peijie Sun, Le Wu, Kun Zhang, Yanjie Fu, Richang Hong, and Meng Wang. Dual
Learning for Explainable Recommendation: Towards Unifying User Preference
Prediction and Review Generation. In The Web Conference (WWW), pages 837â€“
847. ACM, 2020.
[48] Florian TramÃ¨r, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh,
and Patrick McDaniel. Ensemble Adversarial Training: Attacks and Defenses. In
International Conference on Learning Representations (ICLR), 2017.
Stealing Machine Learning Models via Prediction APIs.
Symposium (USENIX Security), pages 601â€“618. USENIX, 2016.
Journal of Machine Learning Research, 2008.
[49] Florian TramÃ¨r, Fan Zhang, Ari Juels, Michael K. Reiter, and Thomas Ristenpart.
In USENIX Security
[50] Laurens van der Maaten and Geoffrey Hinton. Visualizing Data using t-SNE.
Session 3C: Inference Attacks CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea877[51] Bogdan Walek and Vladimir Fojtik. A Hybrid Recommender System for Rec-
ommending Relevant Movies Using An Expert System. Expert Systems with
Applications, 2020.
[52] Samuel Yeom, Irene Giacomelli, Matt Fredrikson, and Somesh Jha. Privacy Risk
in Machine Learning: Analyzing the Connection to Overfitting. In IEEE Computer
Security Foundations Symposium (CSF), pages 268â€“282. IEEE, 2018.
A DEFENSE
In this section, we demonstrate the defense methodology in detail
(Appendix A.1), discuss about visualization results (Appendix A.2),
and analyze the impacts of Popularity Randomization on original
recommendation performances (Appendix A.3).
A.1 Methodology
In the original setting in Section 2.5, non-members are provided
with the most popular items. However, the most popular items for
different users are the same, resulting in that feature vectors of non-
members are extremely similar and easily distinguished. To address
this problem, an intuitive way is to increase the randomness of non-
membersâ€™ recommendations. In the paper, we propose a defense
mechanism named Popularity Randomization. Specifically, a larger
number of the most popular items are first selected as candidates.
Then, we conduct a random selection, i.e., we randomly pick 10%
of candidates as recommendations for non-members. Note that all
recommendations for non-members are still the most popular items.
In that case, recommendations to different non-members are diverse
and thus the similarities among non-membersâ€™ feature vectors are
decreased. The above defense strategy can be formulated as follows:
First, a recommender system Ağ‘…ğ‘† sorts all items by popularity,
i.e.,
Ağ‘…ğ‘† : Dğ‘œğ‘Ÿğ‘–ğ‘”ğ‘–ğ‘›ğ‘ğ‘™
ğ‘†ğ‘œğ‘Ÿğ‘¡âˆ’â†’ Sğ‘ ğ‘œğ‘Ÿğ‘¡ğ‘’ğ‘‘,
where Dğ‘œğ‘Ÿğ‘–ğ‘”ğ‘–ğ‘›ğ‘ğ‘™ is the original dataset and ğ‘†ğ‘œğ‘Ÿğ‘¡âˆ’â†’ is to sort items by
popularity. And Sğ‘ ğ‘œğ‘Ÿğ‘¡ğ‘’ğ‘‘ is an ordered sequence, including all items
from Dğ‘œğ‘Ÿğ‘–ğ‘”ğ‘–ğ‘›ğ‘ğ‘™. In Sğ‘ ğ‘œğ‘Ÿğ‘¡ğ‘’ğ‘‘, higher items are more popular.
Second, based on the number of recommendations and the pre-
set ratio, the recommender system selects a number of the most
popular items as candidates, which can be defined as the following
functions:
ğ›¼ğ‘ƒğ‘… =
ğ‘ğ‘Ÿğ‘’ğ‘
ğ‘ğ‘ğ‘ğ‘›ğ‘‘
,
Sğ‘ğ‘ğ‘›ğ‘‘ = {ğ‘¥|ğ‘¥ âˆˆ Sğ‘ ğ‘œğ‘Ÿğ‘¡ğ‘’ğ‘‘, ğ¼ğ‘›ğ‘‘ğ‘¥ â‰¤ ğ‘ğ‘ğ‘ğ‘›ğ‘‘},
where ğ›¼ğ‘ƒğ‘… is the ratio of recommendations to candidates. Sğ‘ğ‘ğ‘›ğ‘‘ is
a sequence containing all candidates selected by the recommender
system from Sğ‘ ğ‘œğ‘Ÿğ‘¡ğ‘’ğ‘‘. ğ‘ğ‘Ÿğ‘’ğ‘ and ğ‘ğ‘ğ‘ğ‘›ğ‘‘ are the numbers of the rec-
ommendations and the candidates. And ğ¼ğ‘›ğ‘‘ğ‘¥ is the index of ğ‘¥ in
Sğ‘ ğ‘œğ‘Ÿğ‘¡ğ‘’ğ‘‘.
Finally, non-members are randomly provided with items from
candidates as recommendations, which can be defined as the fol-
lowing function:
ğ‘“ (Sğ‘ğ‘ğ‘›ğ‘‘) = Rğ‘œğ‘¢ğ‘¡
(|Rğ‘œğ‘¢ğ‘¡| = ğ‘ğ‘Ÿğ‘’ğ‘),
where ğ‘“ (Sğ‘ğ‘ğ‘›ğ‘‘) is to randomly select recommendations fromSğ‘ğ‘ğ‘›ğ‘‘.
And |Rğ‘œğ‘¢ğ‘¡|, which is equal to ğ‘ğ‘Ÿğ‘’ğ‘, is the number of recommenda-
tions to non-members.
Figure 13: Comparisons of recommendation performances
before against after deploying the defense mechanism.
A.2 Visualization Results
In this section, we visualize user feature vectors by t-SNE to show
the differences of the distributions between members and non-
members in the shadow and target datasets. In Figure 14, the red
points represent feature vectors of members and the blue points
denote feature vectors of non-members. We conclude from the
comparison between Figure 14a and Figure 14b that Popularity
Randomization can decrease the differences between the feature
vectors of members and non-members, and hinder the attack perfor-
mance considerably. We find a similar phenomenon in Figure 14c
and Figure 14d. These visualization results show the effectiveness
of Popularity Randomization.
Moreover, as Figure 12 shows, with the defense mechanism, the
attack against LFM can only reach comparable performances with
Random Guess. In contrast, when the target algorithm is Item, the
attack achieves strong performances. To explain this, as Figure 14a
and Figure 14c shows, the areas of the red and blue points rarely
overlap when using Item. However, there exist many red points
in the area of the blue points when using LFM, leading to a poor
attack performance.
A.3 Impacts on Recommendation
Performances
We next investigate the impacts on the performance of the target
recommender with Popularity Randomization. In Figure 13, the re-
sults show that the performances of the recommender only slightly
drops. For instance, when the target recommender uses Item on
the ml-1m dataset, Popularity Randomization only achieves a 2%
drop in the recommendation performance. Therefore, our proposed
defense strategy can mitigate the attack risk effectively while pre-
serving the original recommendation performances.
AIALANLILLLNMIMLMN0.00.20.40.60.8HR@100OriginalSettingDefenseMechanismSession 3C: Inference Attacks CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea878(a) ADM_Item_shadow (left) and ADM_Item_target (right) with
the defense mechanism.
(b) ADM_Item_shadow (left) and ADM_Item_target (right) without
the defense mechanism.
(c) ADM_LFM_shadow (left) and ADM_LFM_target (right) with
the defense mechanism.
(d) ADM_LFM_shadow (left) and ADM_LFM_target (right) without
the defense mechanism.
Figure 14: Data distributions by t-SNE, in which red points represent members and blue points denote non-member. (a) Data
points in the shadow and target recommenders using Item on the ADM dataset with the defense mechanism. (b) Data points
in the shadow and target recommenders using Item on the ADM dataset without the defense mechanism. (c) Data points in the
shadow and target recommenders using LFM on the ADM dataset with the defense mechanism. (d) Data points in the shadow
and target recommenders using LFM on the ADM dataset without the defense mechanism.
membersnon-membersmembersnon-membersmembersnon-membersmembersnon-membersmembersnon-membersmembersnon-membersmembersnon-membersmembersnon-membersSession 3C: Inference Attacks CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea879