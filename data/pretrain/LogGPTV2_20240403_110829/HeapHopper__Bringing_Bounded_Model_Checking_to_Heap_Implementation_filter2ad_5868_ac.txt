order to pass the allocator’s checks.
At this stage we do not know, for instance, the correct allo-
cation sizes or the value of overflowing data that is necessary
to reach an exploitation primitive. Therefore, we set these
values to (undefined) C placeholder variables (s1 and s2
in the example in Figure 2). The symbolic execution unit
will consider these placeholder variables, and replace them
with symbolic data. Their values will then be concretized
during the PoC generation.
4.2 Heap Interaction Models
HEAPHOPPER combines the individual transactions de-
scribed before to generate a list of interactions. Each in-
teraction corresponds to a path in our model of the heap.
HEAPHOPPER generates this list of interactions by creating
all possible permutations of transaction sequences.
This step is highly critical for the overall performance
of the system, since every binary created during this step
has to be symbolically executed in the next step. Conse-
quently, the main focus here is to minimize the amount of
sequences, while simultaneously avoiding missing sequences
of transactions that could lead to exploitation primitives.
Therefore, we only consider permutations with at least
one misuse of the heap (direct or indirect), as we assume that
a completely benign usage of the heap will not lead to any
malicious state. Moreover, we dismiss all permutations that
only have an indirect interaction as their last transaction, be-
cause an indirect interaction cannot modify the internal state
of the heap itself, but it requires at least one additional direct
interaction. Furthermore, we avoid generating sequences in
which two actions (e.g., two overflow actions) place sym-
bolic memory in the same location, without any other action
being affected by that memory in between. This is justified
by the fact that the second transaction would just overwrite
symbolic data with symbolic data, having no effect.
After an initial generation of transaction permutations, we
consider the semantics of each action. For instance, in case
of a F transaction, we only generate a sequence for each
possible previous allocation, that can be used as parameter of
free. Similarly, for each UAF and DF action, we only gen-
erate a sequence for each possible previously freed chunk.
With these optimizations we were able to reduce the amount
of sequences significantly. For example, for the experiment
described in Section 7.1, we only generated 5,016 paths, in-
stead of 279,936 (i.e., a reduction of 1.79%) that would be
produced without the aforementioned optimizations.
5 Model Checking
After creating all the sequences out of the interaction model
(represented by source files compiled into binaries), we now
want to find out if any of them can reach an exploitation
primitive. Executing the binaries directly cannot provide
this information, as, at this stage, many of our transactions
are based on undefined (symbolic) placeholder variables.
Therefore, all the sequences are symbolically executed to
determine if they can reach an exploitation primitive and how
(i.e., with which values of their placeholder variables). We
use the angr framework [46] as HEAPHOPPER’s symbolic
execution engine and perform the following analysis for
every sequence of transactions.
5.1 Heap Functions Instrumentation
HEAPHOPPER keeps track of all the direct interactions with
the heap, and analyzes their input and return values in or-
der to keep track of malloced and freed chunks. This
setup allows us to abstract the allocator implementation so
that HEAPHOPPER is totally agnostic of its internal data
handling, but operates through observing and analyzing re-
sults of the direct interactions. This simplifies the analysis
process, and does not require insights into the allocator’s
design. Concretely, HEAPHOPPER stores all the malloced
and freed chunks in two separate dictionaries. The allocat-
ed/freed regions and their sizes can be either a concrete value
or a symbolic expression.
5.2 Identifying Security Violations
HEAPHOPPER checks if a security property has been vio-
lated (and, therefore, the attacker has reached an exploita-
tion primitive), after the execution of any malloc or free
transaction. To check if an exploitation primitive has been
reached, HEAPHOPPER analyzes both the current state of
the symbolic execution and the information about allocated
and freed chunks coming from the dictionaries previously
USENIX Association
27th USENIX Security Symposium    105
described in Section 5.1. We will now describe the exploita-
tion primitives that can be detected by HEAPHOPPER, and
how this detection is performed.
Overlapping Allocation (OA). A common heap exploita-
tion primitive is reached when malloc returns memory that
has already been allocated and not freed. In the simplest
case, this condition can be used in a data-leak attack, by
reading data from the chunk without initializing it first. De-
pending on the contained data, it can be useful to go one
step further and overwrite the existing content, which might
contain pointers or privileged information. Hence, an at-
tacker might be able to perform a privilege escalation, or
modify a code pointer (to ultimately even gain arbitrary code
execution).
Formally, in order to detect an OA when a new memory
chunk is allocated at address A, HEAPHOPPER uses an SMT
solver to check if the following condition is true:
∃B : ((A ≤ B)∧ (A + sizeo f (A) > B))∨ ((A ≥ B)∧ (B + sizeo f (B) > A))
where B is the location of any already-allocated memory
chunk.
Non-Heap Allocation (NHA). Another common exploita-
tion primitive occurs when malloc returns a chunk that
is not inside the heap memory boundaries. The two main
reasons that lead to this condition are the freeing of a fake-
chunk, placed outside the heap (which is later returned by
malloc), and the manipulation of structures holding infor-
mation about unallocated chunks. A NHA can be further
exploited by, for instance, obtaining a malloced region on
the stack and use it to change a saved return pointer, taking
control of the program counter.
To detect this condition, first of all, we detect when the
brk or mmap syscalls (used to ask the kernel to allocate
memory) are called by the heap allocator. The values re-
turned by these syscalls are used to determine where the
heap is legitimately supposed to allocate memory. After-
ward, we check if any allocated chunk resides within this
area, by using an SMT solver to verify if a chunk returned
by malloc could be placed outside the heap’s legitimate
location.
Arbitrary Write (AW and AWC). An arbitrary write de-
scribes a memory write for which an attacker can control
both the destination address (where to write) as well as the
content (what to write). Using an arbitrary write, an attacker
can easily change the value of a function pointer and manip-
ulate code execution. We distinguish the case in which an
attacker has full control over where to write (AW) from the
case in which the attacker can write only to memory loca-
tions where a specific content is present (AWC). This second
scenario is common when it is possible to force the allocator
to perform a write operation, but, in order to bypass the allo-
cator’s checks, the content of the memory where the write
happens needs to satisfy certain constraints (e.g., it needs to
contain data looking like a legitimate chunk’s header).
To detect an arbitrary write exploitation primitive, we
check any write to a symbolic location happening while
executing a malloc or a free. Specifically, we query the
constraint solver to check if it is possible to redirect a write
to a specific memory region as the write’s target (WT). If
this is true, we consider this write as an arbitrary write. To
distinguish between the AW and AWC exploitation primitives,
we check if, before the arbitrary write to WT happens, there
is any constraint on the content of WT. In case WT does
not contain any constraint, we consider this arbitrary write
as AW, otherwise we consider it as AWC.
5.3 Symbolic Heap Pointer Handling
During symbolic execution, transactions can introduce sym-
bolic memory into the allocator’s metadata. When the allo-
cator operates on its internal structures, those symbolic bytes
might then be used directly or as an offset for a memory
access. The location of these memory accesses can have
overwhelmingly many possible solutions. In cases where
the retrieved value ends up in the condition of a branching
instruction, this large solution space can cause a substan-
tial workload for the SMT solver, and ultimately lead to a
state explosion, slowing down the symbolic execution sig-
nificantly. To mitigate this issue, we developed a three-step
procedure, including a new approach designed specifically
for the type of analysis that HEAPHOPPER performs.
In the first step, we filter out symbolic memory accesses
that are in fact well-bounded and need no specific treatment.
Therefore, we ask the SMT solver to check if the number
of solutions for the target of a symbolic access is less or
equal than a threshold T1 (in our experiments, 16). If this
is true, we add proper constraints to the memory locations
where the memory access happened, and we continue with
the symbolic execution.
The second strategy was specifically designed to handle
an allocator’s symbolic metadata, and attempts to concretize
resulting memory accesses to attacker-controlled regions.
If this concretization is possible, we will add proper con-
straints to the attacker-controllable memory locations where
the memory access happens, and resume symbolic execution.
The basic intuition behind this strategy is that if a symbolic
memory access happens to a symbolic location that can be
concretized to more than T1 values, it is likely that an at-
tacker has enough control over it to redirect this access to an
attacker-controlled location. From an attacker point of view,
it is actually convenient to redirect symbolic reads to attacker-
controlled memory to bypass checks that the heap allocator
performs. At the same time, if an attacker can control the
target of a symbolic write, this becomes an arbitrary write
exploitation primitive, as explained before. Empirically, we
found that this strategy is effective in keeping the complexity
of constraints low, while still exploring all the exploitation
possibilities allowed by a specific list of transactions.
106    27th USENIX Security Symposium
USENIX Association
If this second strategy fails, we resort to a third strategy,
which consists of concretizing the memory access to all
possible values, up to a threshold T2, much higher than T1
(in our experiments, 4,096). It is important to notice that
this third strategy is only used as a last resort, as adding so
many concretization possibilities will likely result in having
constraints of an intractable complexity.
5.4 Symbolic Execution Optimizations
A key challenge faced by symbolic execution is scalability,
both in terms of execution time and memory consumption.
We addressed both issues mainly by minimizing the number
of symbolic bytes in memory, thereby keeping state explo-
sion and the complexity of constraints in a feasible range.
Additionally, we decided to use a depth-first instead of
a breadth-first path exploration technique, which led to a
significant speedup. This choice is motivated by the fact that
in our analysis we are interested in finding if there exists any
way in which the execution of a sequence of transactions
can lead to an exploitation primitive, while we are not inter-
ested in finding all the possible states reachable during its
execution.
6 PoC Generation
In the final step, HEAPHOPPER generates a proof-of-concept
program for each sequence that reached an exploitation prim-
itive, based on the interaction sequence’s source code (which
contains placeholder, undefined variables) and the data from
the symbolic execution.
The generated PoC program serves two purposes: First,
it provides a concrete execution example of how a specific
exploitation primitive is reached, supporting the manual anal-
ysis of HEAPHOPPER’s result. Second, it verifies that the
path found by HEAPHOPPER indeed reaches the exploitation
primitive in a concrete execution, and not as a side-effect of
the symbolic execution.
To generate PoCs, HEAPHOPPER first transforms all the
symbolic bytes into corresponding concrete values that make
the concrete execution reaching the same exploitation prim-
itive. This is achieved by solving the symbolic bytes’ con-
straints, collected during the symbolic execution of the con-
sidered sequence of transactions.
After converting the symbolic bytes into concrete values,
HEAPHOPPER transforms the original source as follows.
First, it replaces all the memory locations that contained
symbolic variables during the symbolic execution with their
concrete representation. Then, it replaces the symbolic mem-
ory reads into memory, representing indirect interactions
with the heap, with the values received from concretizing
their symbolic bytes.
The key challenge with this process is that the results
of concretizing symbolic bytes are not just constants, but
often represent pointers containing virtual addresses from the
symbolic execution or specific offsets between two objects in
memory. Therefore, we cannot just use the values as they are,
because they are dependent on the memory layout that is set
by the runtime environment, the output of the compilation,
and the linking of the new PoC binary. In order to solve this
issue, we use our knowledge about the runtime environment
during the symbolic execution to identify pointers and their
offsets with respect to the base of their particular memory
segment.
Additionally, we utilize this knowledge to identify con-
stants that represent offsets between objects in memory. To
detect this, we check if the offset from a constant added to the
address of its memory location and any object in memory is
below a certain threshold (set to 32 bytes in our experiments).
If that is the case, we replace the constant with a dynamic
calculation of the represented offset.
7 Evaluation
We evaluated HEAPHOPPER on 5 different revisions across
3 allocator implementations [1, 2, 31].
The model we use for HEAPHOPPER is based on the heap
as the state. The transitions of the state are defined by a set of
transactions described in Section 4.1. These transactions are
bound to certain parameters. Therefore, the specification of
our model is bound to these parameters as well. The model
specifications for each experiment can be found in Table 1.
We chose these bounds as a tradeoff between the maxi-
mum number of transactions previously known to be nec-
essary to reach exploitation primitives and the cost of the
computing power necessary to run HEAPHOPPER. The
allocation sizes represent three different magnitudes of al-
locations, which potentially fall in three different bin sizes,
and are based on our automatic finding of allocation sizes’
boundaries (see Section 4.1). Furthermore, we chose two
different overflow sizes to simulate a full 64-bit overflow
(which is the register’s size of the architectures targeted by
the analyzed allocators) and a one-byte overflow. We also
had to bound the maximum memory consumption to 32GB,
to keep the computing resources needed within our budget.
For this reason, every instance that took more than 32GB of
memory was killed and marked as failed.
This configuration resulted in 5,016 explored model paths.
Our experiment was run using a cloud with 300 nodes, each
of them having 1 core and 32GB of memory. The average
computing time for each tested allocator was 16 hours with
an average failure rate caused by memory exhaustion of 5%.
7.1 Results Overview
Table 2 summarizes our results. For every allocator, we split
the findings based on the security property violated. We then
parse the types of transactions used in each path and calculate
USENIX Association
27th USENIX Security Symposium    107
Experiment name
Evaluation Section
types of transactions
Depth