Engineering Egress with Edge Fabric
ACM SIGCOMM, August 21–25, 2017, Los Angeles, CA, USA
capacity and utilization. We handle overload on these connections
using the same approach as a regular PNI interface, except we limit
utilization per nexthop.
9 RELATED WORK
CDN traffic engineering. As a result of CDN traffic growth,
researchers and engineers have proposed new traffic engineering
solutions. A common approach in CDN traffic engineering, which
Edge Fabric also employs, is centralized (SDN) control that com-
bines network and traffic information to configure network devices.
Researchers have studied multiple ways to choose where a
client’s request should be directed (e.g., [7, 11, 32]), including using
anycast [11] and DNS extensions [7] as mechanisms to direct
clients over to “nearby” servers. These solutions target a different
set of challenges than those described in §3 and are complementary
to Edge Fabric. Facebook employs solutions to choose where a
client should be directed, but still needs Edge Fabric to choose
which route to use when sending data to the client.
More related to our work are Footprint [16], PECAN [28], Entact
[32], and Espresso [31], which propose choosing which PoP and/or
path a client should be directed to as a function of path performance.
While Footprint focuses on shifting load of long-lived stateful client
sessions between PoPs to avoid congestion and PECAN focuses on
measuring performance and choosing ingress routes (from clients
to servers), Edge Fabric was designed to shift client traffic between
alternate egress routes (from servers to clients) to avoid congestion.
The three proposals are complementary: our techniques could be
applied to Footprint and PECAN, and vice-versa.
Entact and Espresso are most similar. Entact overrides BGP’s
default routing decisions through a well-designed approach that
balances performance, load, and cost, evaluating the approach via
emulation [32]. Similar to AltPath, Entact directs some traffic to
alternate paths to measure their performance. We build on this idea,
working through the details of deploying such a system in produc-
tion, at scale, in a way that applies to all our services and users. For
example, while Entact measured alternate path performance for
individual IP addresses within prefixes, AltPath can assign at ran-
dom or select flows across the address space, guarding against cases
in which different addresses experience different performance and
enabling future use of the same mechanism for application-specific
routing. Entact uses active measurements (pings) to measure path
performance, but is unable to find responsive addresses in many
prefixes so can only make decisions for 26% of MSN traffic. The
need for responsive addresses also limits the number of alternate
paths that Entact can measure in parallel and keeps it from increas-
ing the granularity of its decisions by deaggregating prefixes (both
would require finding more responsive addresses). These atomic
assignments may not be a good approximation of Entact’s optimal
traffic assignments, which assume a provider can split traffic to a
prefix arbitrarily across multiple paths. By applying an approach
similar to Entact’s but based on passive measurement of production
traffic, Edge Fabric uses Facebook’s existing server-side measure-
ment infrastructure to collect measurements that cover and are
representative of our entire user base, can split prefixes to increase
decision granularity, and can use as many paths in parallel as our
peering routers can support. Finally, we expose challenges that
arise in practice (§7.3), including the potential for oscillations, that
do not occur in Entact’s emulated evaluation.
Espresso is Google’s SDN-based system to control egress rout-
ing [31]. Espresso and Edge Fabric are both designed by huge
content providers needing to overcome challenges with BGP and
BGP routers as they expand their PoP and peering footprint in
the face of massive traffic growth. They take a similar top-level
approach, centralizing control of routing while retaining BGP as
the interface to peers. However, the two systems prioritize different
tradeoffs in many other important design decisions, presenting an
interesting case study of how the ranking of priorities can impact a
design. Espresso uses a bespoke architecture to remove the need
for BGP routers that support full Internet routing tables, whereas
Edge Fabric relies on BGP and vendor BGP routers to build on
existing experience and systems. Edge Fabric restricts the size of
its multiple routing tables by isolating PoPs, such that the number
of prefixes carrying user traffic per PoP is low (Figure 3). Whereas
Facebook achieves simplicity by isolating prefix announcements,
ingress, egress, and control to individual PoPs, Espresso uses a
single global controller and can route traffic across the WAN to
egress at distant PoPs, providing flexibility. Edge Fabric’s con-
troller pushes its egress decisions only to peering routers, allowing
us to isolate Facebook’s hosts from network state. Espresso, on the
other hand, pushes routing decisions to hosts, maximizing flexibil-
ity but requiring a more sophisticated controller architecture and
the continuous synchronization of routing state at hosts to prevent
blackholing of traffic. Section 8.1 discusses these tradeoffs (relative
to our goals) in more detail, based on our past experience with
routing egress traffic between PoPs and with host-based routing
(earlier Edge Fabric designs that were more similar to Espresso).
Espresso includes approaches for mitigating some of the challenges
that section describes. Our paper focuses on measurements and
challenges of the BGP interconnectivity of a large content provider,
and on the design and evaluation of a traffic engineering solution
that integrates with existing peering routers.
B4 [14] and SWAN [13] centralize control of inter-datacenter
networks to maximize utilization without hurting performance of
high-priority traffic. Edge Fabric has a similar goal, and it also
uses centralized control. However, the difference in the setting in-
troduces new challenges. In particular, B4 and SWAN operate in
a closed environment in which all hosts and network devices are
under unified administration, and the majority of the traffic can
tolerate delay and loss. In contrast, Edge Fabric controls egress
traffic to networks and users outside its control. Further, much of
the traffic is adaptive bitrate video, and it has soft latency demands
far beyond the elastic traffic on inter-datacenter WANs. Fibbing
centralizes control of legacy OSPF networks, injecting informa-
tion to induce distributed routers to select desired intradomain
routes [29]. Edge Fabric’s controller similarly injects routes, but
our interdomain setting provides much less visibility into or control
over end-to-end paths. Edge Fabric could take advantage of richer
mechanisms for traffic engineering, e.g., iSDX [12].
Performance monitoring. To inform CDN traffic engineering,
existing techniques measure path performance by injecting mea-
surement traffic into the network or by passively monitoring on-
going traffic. Active measurement techniques instrument clients
ACM SIGCOMM, August 21–25, 2017, Los Angeles, CA, USA
B. Schlinker et al.
to collect measurements [4, 21] or dedicated measurement van-
tage points [1, 18, 19]. Passive measurement techniques can require
(often expensive) monitoring functionality in network equipment
[15, 17]. Edge Fabric conducts passive measurements at Face-
book’s servers, which allows (i) monitoring of all paths and services
without the need to instrument millions of clients and (ii) the collec-
tion of richer metrics (e.g., SRTT) compared to on-path devices. Our
finding that a small number of interfaces experience congestion is
similar to previous IXP characterization studies [2, 8, 16].
10 CONCLUSION
Today’s Internet traffic is dominated by a small number of big
content providers. How they interact with other ASes largely shapes
interdomain routing around the world.
This paper provides the first public details of the design, imple-
mentation, and operational experience of Edge Fabric, a system
that steers vast amounts of content to the world. Edge Fabric aug-
ments BGP with measurement and control mechanisms to overcome
BGP’s lack of congestion- or performance-awareness. We designed
it to be simple and scalable, taking advantage of centralized control,
existing support in vendor software and hardware, and server-based
measurements. Our results demonstrate that Edge Fabric success-
fully avoids congesting capacity-constrained interconnections, as
well as show the potential for Edge Fabric’s alternative path mea-
surements to realize performance-aware interdomain routing.
BGP will be the Internet’s interdomain routing standard for the
foreseeable future. By sharing our 4 years of experience engineering
our egress traffic, including a detailed look at opportunities and
challenges presented by the Internet connectivity of today’s large
content providers, we hope that the limitations of BGP can be better
understood and every Internet user’s experience can be improved.
ACKNOWLEDGEMENTS
We thank Facebook colleagues for insights and feedback, includ-
ing Steve Shaw, Manikandan Somasundaram, Lisa Guo, Alexan-
der Kramarov, Bolek Kulbabinski, Vincent Mauge, Jimmy Ottos-
son, Callahan Warlick, Emre Cantimur, Yudong Yang, Martin Lau,
Omar Baldonado, and, especially, Niky Riga and Varghese Vaidhyan.
We thank our shepherd Olaf Maennel and the SIGCOMM review-
ers. We thank the Espresso authors [31], especially K.K. Yap and
Amin Vahdat, for informative exchanges to help highlight similari-
ties/differences between our systems. Brandon Schlinker’s research
has been partially funded by the Facebook Graduate Fellowship.
The PEERING testbed and Ethan Katz-Bassett’s and Harsha Mad-
hyastha’s participation were funded in part by Facebook Faculty
Awards and by the National Science Foundation (CNS-1406042,
CNS-1351100, CNS-1413978, CNS-1563849, and CNS-1564242). Italo
Cunha is funded in part by CNPq and FAPEMIG.
REFERENCES
[1] ThousandEyes: Network Intelligence Software. www.thousandeyes.com.
[2] B. Ager, N. Chatzis, A. Feldmann, N. Sarrar, S. Uhlig, and W. Willinger. Anatomy
of a Large European IXP. In Proc. ACM SIGCOMM, 2012.
[3] M. Calder, X. Fan, Z. Hu, E. Katz-Bassett, J. Heidemann, and R. Govindan. Mapping
the Expansion of Google’s Serving Infrastructure. In Proc. ACM IMC, 2013.
[4] M. Calder, A. Flavel, E. Katz-Bassett, R. Mahajan, and J. Padhye. Analyzing the
Performance of an Anycast CDN. In Proc. ACM IMC, 2015.
[5] Y.-C. Chiu, B. Schlinker, A. B. Radhakrishnan, E. Katz-Bassett, and R. Govindan.
Are We One Hop Away from a Better Internet?. In Proc. ACM IMC, 2015.
[6] F. Dobrian, V. Sekar, A. Awan, I. Stoica, D. Joseph, A. Ganjam, J. Zhan, and H.
Zhang. Understanding the Impact of Video Quality on User Engagement. In Proc.
ACM SIGCOMM, 2011.
[7] M. T. Fangfei Chen, Ramesh K. Sitaraman. End-User Mapping: Next Generation
Request Routing for Content Delivery. In Proc. ACM SIGCOMM, 2015.
[8] N. Feamster. 2016. Revealing Utilization at Internet Interconnection Points. CoRR
abs/1603.03656 (2016).
[9] T. Flach, N. Dukkipati, A. Terzis, B. Raghavan, N. Cardwell, Y. Cheng, A. Jain, S.
Hao, E. Katz-Bassett, and R. Govindan. Reducing Web Latency: The Virtue of
Gentle Aggression. In Proc. ACM SIGCOMM, 2013.
[10] T. Flach, P. Papageorge, A. Terzis, L. D. Pedrosa, Y. Cheng, T. Karim, E. Katz-
Bassett, and R. Govindan. An Internet-Wide Analysis of Traffic Policing. In Proc.
ACM SIGCOMM, 2016.
[11] A. Flavel, P. Mani, D. Maltz, N. Holt, J. Liu, Y. Chen, and O. Surmachev. FastRoute:
A Scalable Load-Aware Anycast Routing Architecture for Modern CDNs. In Proc.
USENIX NSDI, 2015.
[12] A. Gupta, R. MacDavid, R. Birkner, M. Canini, N. Feamster, J. Rexford, and L.
Vanbever. An Industrial-scale Software Defined Internet Exchange Point. In Proc.
USENIX NSDI, 2016.
[13] C.-Y. Hong, S. Kandula, R. Mahajan, M. Zhang, V. Gill, M. Nanduri, and R. Wat-
tenhofer. Achieving High Utilization with Software-driven WAN. In Proc. ACM
SIGCOMM, 2013.
[14] S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski, A. Singh, S. Venkata, J. Wan-
derer, J. Zhou, M. Zhu, J. Zolla, U. Hölzle, S. Stuart, and A. Vahdat. B4: Experience
with a Globally-deployed Software Defined Wan. In Proc. ACM SIGCOMM, 2013.
[15] C. Labovitz, S. Iekel-Johnson, D. McPherson, J. Oberheide, and F. Jahanian. Inter-
net Inter-domain Traffic. In Proc. ACM SIGCOMM, 2010.
[16] H. H. Liu, R. Viswanathan, M. Calder, A. Akella, R. Mahajan, J. Padhye, and M.
Zhang. Efficiently Delivering Online Services over Integrated Infrastructure. In
Proc. USENIX NSDI, 2016.
[17] Z. Liu, A. Manousis, G. Vorsanger, V. Sekar, and V. Braverman. One Sketch to
Rule Them All: Rethinking Network Flow Monitoring with UnivMon. In Proc.
ACM SIGCOMM, 2016.
[18] M. Luckie, B. Huffaker, K. Claffy, A. Dhamdhere, and V. Giotsas. AS Relationships,
Customer Cones, and Validation. In Proc. ACM IMC, 2013.
[19] H. Madhyastha, T. Isdal, M. Piatek, C. Dixon, T. Anderson, A. Krishnamurthy,
and A. Venkataramani. iPlane: an Information Plane for Distributed Services. In
Proc. USENIX OSDI, 2006.
[20] S. Meinders. In RIPE NCC Regional Meeting: Eurasia Network Operators Group
(ENOG 11), 2016.
[21] A. Nikravesh, H. Yao, S. Xu, D. Choffnes, and Z. M. Mao. Mobilyzer: An Open
Platform for Controllable Mobile Network Measurements. In Proc. ACM MobiSys,
2015.
[22] R. Sambasivan, D. Tran-Lam, A. Akella, and P. Steenkiste. Bootstrapping Evolv-
ability for Inter-domain Routing with D-BGP. In Proc. ACM SIGCOMM, 2017.
[23] Sandvine. Global Internet Phenomena Report 2H2016. Available at:
http://www.sandvine.com/trends/global-internet-phenomena.
[24] B. Schlinker, K. Zarifis, I. Cunha, N. Feamster, and E. Katz-Bassett. PEERING: An
[25] J. Scudder, R. Fernando, and S. Stuart. RFC 7854: BGP Monitoring Protocol (BMP).
AS for Us. In Proc. ACM HotNets, 2014.
http://www.ietf.org/rfc/rfc7854.txt.
[26] D. Sommermann and A. Frindell. Introducing Proxygen, Facebook’s C++ HTTP
framework. https://code.facebook.com/posts/1503205539947302.
[27] Y.-W. E. Sung, X. Tie, S. H. Wong, and H. Zeng. Robotron: Top-down Network
Management at Facebook Scale. In Proc. ACM SIGCOMM, 2016.
[28] V. Valancius, B. Ravi, N. Feamster, and A. C. Snoeren. Quantifying the Benefits
of Joint Content and Network Routing. In Proc. ACM SIGMETRICS, 2013.
[29] S. Vissicchio, O. Tilmans, L. Vanbever, and J. Rexford. Central Control Over
Distributed Routing. In Proc. ACM SIGCOMM, 2015.
[30] D. Wing and A. Yourtchenko. RFC 6555 Happy Eyeballs: Success with Dual-Stack
Hosts. http://www.ietf.org/rfc/rfc6555.txt.
[31] K. K. Yap, M. Motiwala, J. Rahe, S. Padgett, M. Holliman, G. Baldus, M. Hines,
T. Kim, A. Narayanan, A. Jain, V. Lin, C. Rice, B. Rogan, A. Singh, B. Tanaka,
M. Verma, P. Sood, M. Tariq, M. Tierney, D. Trumic, V. Valancius, C. Ying, M.
Kallahalla, B. Koley, and A. Vahdat. Taking the Edge off with Espresso: Scale, Reli-
ability and Programmability for Global Internet Peering. In Proc. ACM SIGCOMM,
2017.
[32] Z. Zhang, M. Zhang, A. Greenberg, Y. C. Hu, R. Mahajan, and B. Christian.
Optimizing Cost and Performance in Online Service Provider Networks. In Proc.
USENIX NSDI, 2010.
[33] J. Zhou, M. Tewari, M. Zhu, A. Kabbani, L. Poutievski, A. Singh, and A. Vahdat.
WCMP: Weighted Cost Multipathing for Improved Fairness in Data Centers. In
Proc. ACM EuroSys, 2014.