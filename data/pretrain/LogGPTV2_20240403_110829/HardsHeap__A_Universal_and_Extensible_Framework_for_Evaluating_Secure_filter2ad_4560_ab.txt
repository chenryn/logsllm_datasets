with statically and manually crafted test sets. To overcome this,
HardsHeap employs random testing (i.e., fuzzing) to arbitrarily call
APIs for dynamic memory management and externally observes
security properties of secure allocators in order to evaluate them
(see §5.2).
Quantitative evaluation. We also need to quantitatively evaluate
security properties. Most of the existing security analyses for secure
allocators are binary; they only mark whether a certain allocator
supports a specific security feature (as shown in Table 1) without
further analyzing its quality. However, it is insufficient to evaluate
the security of secure allocators. For example, Silvestro et al. [38]
show that both FreeGuard and DieHarder support random allocation.
However, their mechanisms are relatively weak because FreeGuard’s
entropy is extremely low (i.e., 2 bits) while DieHarder’s is unstable
and varies across object sizes (i.e., larger objects are less randomly
allocated). To address this issue, we require a quantitative analysis.
To this end, HardsHeap performs sampling-based testing; it reports
a security violation with its probability from repeated experiments
(see §5.3).
Explainability. Even though random exploration is effective in
discovering an erroneous case, its findings naturally bring redun-
dancy, which limits further analysis for understanding the issue.
To eliminate this redundancy, delta debugging [49, 51] is widely
used; however, it assumes the reproducibility of failures. To apply
delta debugging in a stochastic environment, which is prevalent
in secure allocators, we devise a new technique called Statistical
Significant Delta Debugging (SSDD). This technique combines a
greedy method with statistical significance (see §5.4) to further
reduce the test case without a loss of reproducibility. According
to our evaluation in §8.2, SSDD successfully reduce test cases by
37.2% while preserving their original probability.
4 THREAT MODEL
In this section, we present our threat model for heap vulnerabil-
ities, which is powerful yet realistic to extensively evaluate the
security of secure allocators. First, an attacker can allocate objects
of an arbitrary size and can deallocate objects in an arbitrary order.
This capability highly depends on applications; however, compli-
cated software such as web browsers is often equipped with it. For
example, in JavaScript, attackers can allocate a heap object of an
arbitrary size using ArrayBuffer, and they can also deallocate it by
nullifying its reference. Second, the attacker can write arbitrary
values to a predefined memory region, which allows them to craft
arbitrary fake chunks for abusing allocators. Third, the attacker can
repeatedly trigger one of heap vulnerabilities in §2.1 (i.e., overflow,
use-after-free, invalid free, or double free). However, it is limited to a
single bug type. This simulates a realistic situation for exploitation;
The attacker attempts to exploit an application by reusing a single
vulnerability multiple times. We also assume that the attacker has
no extremely powerful primitive such as arbitrary writes. This de-
motivates the attacker to launch heap exploitation, enabling easier
attacks. We note that this model assumes the worst-case scenario
for heap exploitation, which is consistent with other studies on
secure allocators [28, 37, 38, 49].
Session 2A: Fuzzing and Bug Finding CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea381deallocation, memory writes, and bug invocation. HardsHeap’s
decoding logic is directly borrowed from ArcHeap’s; therefore, we
briefly explain it, providing further detail in [49]. It is worth noting
that ArcHeap also randomly generates heap actions like HardsHeap;
however, it is limited to evaluating a normal allocator because it
cannot support various yet randomized security properties of secure
allocators.
The following explains each type of heap actions generated by
HardsHeap to evaluate secure allocators.
Allocation. HardsHeap allocates memory with randomized sizes
using malloc. HardsHeap chooses its allocation size carefully to
reduce its search space. It has four types of strategies to select
allocation sizes: 1 random size, 2 other chunk’s size, 3 special
values (e.g., -1 or 0), and 4 offsets between pointers (e.g., heap
pointers or its global buffer to craft fake chunks). The last strategy
is required to discover integer overflow in handling allocations;
others are fairly intuitive strategies for evaluating allocators. For
further analysis, HardsHeap also maintains both the request size
and actual size of an allocated object; HardsHeap achieves the
request size by tracking a malloc’s argument and retrieves the
actual size using malloc_usable_size API.
Deallocation. HardsHeap also randomly picks an object and deal-
locates it. HardsHeap avoids buggy situations (e.g., double free),
which are not controlled by HardsHeap, by tracking an object’s
allocation status. In particular, HardsHeap maintains a bitmap
whose bit represents whether a corresponding object is deallocated
or not. Then, HardsHeap simply ignores the execution of a deallo-
cation action if it tries to deallocate already freed objects.
Memory writes. HardsHeap also writes memory with randomly
generated values. It has two types of memory to write: heap chunks
and a global buffer. HardsHeap uses heap chunks to test whether
an allocator is resilient to modify its internal data in heap objects.
Moreover, HardsHeap uses a global buffer to check whether an
allocator is able to distinguish its heap objects with a fake memory
region in buggy situations (e.g., invalid free or use-after-free). Simi-
lar to ArcHeap, HardsHeap only generates random values that are
related to chunk sizes or pointers instead of purely random values
to reduce its search space.
Bug invocation. HardsHeap also generates buggy actions to
evaluate secure allocators against heap vulnerabilities. HardsHeap
simulates four types of vulnerabilities that are common and widely
adopted: overflow, write-after-free, invalid free, and double free.
Overflow and double free are self-explanatory; write-after-free
allows modifying freed objects, and invalid free allows freeing a
non-heap region, which is a global buffer in HardsHeap.
5.3 Sampling-based Testing
To evaluate various security properties in a secure allocator,
HardsHeap performs sampling-based testing. Because existing
security properties are too diverse to assess them using a single
method, we rely on a manually crafted module for their evaluation.
However, thanks to HardsHeap, we only require hundreds of lines
of code for each property (see Table 2). It is worth noting that we
can reuse heap action generation and test case reduction for any
module; we only need to implement its core logic.
Figure 1: HardsHeap’s overview. Note that gray boxes are dedi-
cated components for each security mechanism, and others are com-
monly used regardless of its evaluating mechanism.
5 DESIGN
In this section, we illustrate the design of HardsHeap to evaluate
various security properties in secure allocators.
5.1 Workflow
Figure 1 shows the high-level design and workflow of HardsHeap.
1 HardsHeap relies on a generic binary-based fuzzer,
(i.e., AFL [50]) to generate random byte stings. Subsequently,
HardsHeap encodes them into heap actions using its decoder [30,
49]. The heap actions consist of four types: allocation, dealloca-
tion, memory writes, and bug invocation. We further discuss how
HardsHeap generates them in §5.2.
2 HardsHeap runs the decoded heap actions with a secure
allocator for analysis (§5.3). HardsHeap uses a standard library
hooking technique (i.e., LD_PRELOAD) to use a secure allocator im-
plementation for its execution. To handle the diversity of security
properties, we implement HardsHeap’s sampling-based testing for
each security property in a special component, referred to as a mod-
ule. This module performs two types of analyses: local and global.
The local analysis installs several hooking functions to heap actions
to control them and gather information. These hooking functions
usually report the occurrence of a security property violation (e.g.,
adjacent chunks) if such a violation is locally checkable. Otherwise,
they gather data and transmit them to the next global analysis.
3 After locally running heap actions multiple times (i.e., sam-
pling), the global analysis calculates the probability of a secu-
rity property violation. HardsHeap calculates the probability in a
straightforward manner — the number of occurrences of security
violations divided by the total number of trials.
4 If the probability is larger than a predefined threshold (0.25
in our prototype), HardsHeap generates Proof-of-concept (PoC)
code. Because of its random nature, HardsHeap’s test case often
contains non-essential actions; therefore, HardsHeap leverages a
technique called Statistical Significance Delta Debugging (SSDD)
(see §5.4) to reduce it. Finally, it produces a PoC code written in the
C language that shows security violations of secure allocators.
5.2 Heap Action Decoding
HardsHeap decodes a random byte string into the corresponding
heap actions. It generates four types of heap actions: allocation,
FuzzerRandom byte stringp1 = malloc(0x100);p2 = malloc(0x200);free(p1);*p1 = 1234;...Secure allocatorimplementations (*.so)Local analysisHeap actionsdecoderLocal resultsGlobalanalysisTestcase minimizer(SSDD)p1 = malloc(0x100);p2 = malloc(0x200);free(p1);*p1 = 1234;...Probability ①②③④ModuleSession 2A: Fuzzing and Bug Finding CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea382With given heap actions, HardsHeap’s module performs two
types of analyses: local and global. In the local analysis, the mod-
ule executes heap actions with a secure heap allocator to test and
records its behavior. For that, HardsHeap allows locating hooking
functions before and after each action (e.g., allocation and deallo-
cation). Moreover, it also allows another hooking functions that
will be called at the module’s initialization and finalization. These
hooking functions can also access the current status of heap objects,
which HardsHeap maintains. For example, in a module that checks
adjacent chunks, we can place a hooking function after allocation
to check whether a returned object is adjacent to current objects.
We detail the modules in §6. HardsHeap also provides a method
for communicating with its global analysis using shared memory.
Therefore, we can transmit the local analysis results to the global
analysis for further analysis.
After obtaining local analysis results, HardsHeap’s module cal-
culates the probability of security violation. In most cases, this
simply counts the number of occurrences of security violations.
However, in certain cases, more complicated analysis is required
to calculate the probability. For example, if we want to evaluate
whether an allocator is resilient to heap spraying, we first need to
compute a recurrent address in multiple executions to count its
occurrences. This recurrent address cannot be calculated in a single
instance; therefore, the global analysis performs this computation
by collecting the results of the local analysis (i.e., sampling).
5.4 Statistical Significance Delta Debugging
If the probability is greater than a pre-defined threshold, which is
set to 0.25 in our prototype, HardsHeap stores a given set of heap
actions and reduces it using Statistical Significance Delta Debug-
ging (SSDD). To reduce test cases, Delta debugging [51] is one of
the most widely used techniques; it re-runs an application with a
more reduced case to check whether the same failure can occur.
By repeating this procedure, delta debugging can reduce the test
case for the same failure. In HardsHeap, the failure corresponds
to a security violation in secure allocators, and the test case is
the set of heap actions. Unfortunately, classical delta debugging is
not directly applicable because it assumes that the failure can be
reliably reproducible; however, in evaluating secure allocators, se-
curity violations only appear stochastically because of their random
mechanisms (e.g., adjacent chunks happen in 30%).
One straw-man design for supporting stochastic events is to
use a greedy algorithm, which is shown in Algorithm 1. In par-
ticular, HardsHeap can compare the probability of a reduced test
case, which eliminates one action, with the original probability;
HardsHeap can measure both probabilities by sampling multiple
events (e.g., 100 in our prototype). If a new probability is greater
than or equal to the old one, we believe that it is safe to eliminate
the corresponding action. (Line 7). However, because of the fickle
nature of probabilities, it is likely to miss opportunities for reducing
a test case. Even if a new probability is insignificantly less than the
old one, a test case cannot be reduced using this greedy method.
To address this issue, we devise Statistical Significance Delta
Debugging (SSDD) by extending the previously mentioned greedy
Algorithm 1: Greedy & SSDD
Input
Input
:actions – actions to minimize
:greedy – use greedy if true, otherwise use SSDD
1 minActions := actions;
2 oldProbs := Sampling(actions);
3 for action ∈ actions do
newProbs := Sampling(minActions - action);
avgDiff = Avg(newProbs) - Avg(oldProbs);
if greedy then
if avgDiff ≥ 0 then
4
5
6
7
8
9
10
11
12
13
14
15
16 end
minActions = minActions - action;
end
else
pValue := StudentTTest(newProbs, oldProbs);
if avgDiff ≥ 0 or pValue ≥ 0.05 then
minActions = minActions - action;
end
end
Output:minActions – minimized actions
method. Unlike the greedy method, SSDD considers statistical sig-
nificance not only differences between average. To measure statisti-
cal significance, we use Student’s t-test [40]; it represents statistical
significance if its p-value is less than the threshold, which is usually
0.05. Even if a new probability is less than the old one, SSDD can
eliminate a corresponding action if the probability difference is
statistically insignificant. It is noteworthy that HardsHeap’s mod-
eling satisfies constraints for using Student’s t-test; we can use t-test
only if an objective distribution follows the normal distribution. In
particular, in evaluating secure allocators, each trial for violating a
security property (e.g., making an adjacent chunk) is a Bernoulli
process, such as coin tossing. Thus, our probability from sampling
follows a binomial distribution, which could be approximated as
a normal distribution. Thus, we are safe to use Student’s t-test to
compute statistical significance in SSDD.
We optimize this test case reduction procedure for a reliably
reproducible case by returning to classical, deterministic delta de-
bugging. Even though a certain security feature is randomized
in theory, its violation can be reliably reproducible. For instance,
Guarder’s allocation is designed to be random; however, it becomes
deterministic if we allocate an extremely large object (> 512 KB). In
such a situation, we can return to classical delta debugging without
SSDD. This is more efficient than SSDD because it requires no re-
peated experiments to compute the probability in delta debugging.
After reducing a test case, HardsHeap returns a C program as
its Proof-of-Concept (PoC) that violates a security property with
high probability. It is trivial to create a C program with heap ac-
tions because each heap action has one-to-one mapping with a C
statement. For example, allocation can be converted into malloc,
and deallocation can be converted into free. In each module, we
also add an assert statement to check whether a security violation
(e.g., adjacent chunks) occurs.
6 MODULES
Session 2A: Fuzzing and Bug Finding CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea383Modules
Adjacent
Reclaim
CheckOnFree
Uninitialized
Spray
SizeCheck
ArcHeap
LoC Mode
135
Small
Cross
Security features
Random allocation,
+ Guard page
119
89
78
64
61
574
Small
Random reuse
Use-after-free prevention
Check-on-free
Segregated metadata
(Resilient to heap spray attack)
(Resilient to integer overflow)
(Resilient to heap vulnerabilities)
Description
Check if chunks can be adjacent
Check if adjacent chunks happen for small objects (< 1K bytes)
Check if adjacent chunks have different object sizes
Check if a dangling chunk is reclaimable
Check if chunk reclaimiation happens for small objects (< 1K bytes)
Check if an allocator terminates when deallocates a corrupted chunk
Check if an allocator leaves metadata in uninitialized memory
Check if subsequent allocations have no recurrent address
Check if an allocated size is greater or equal to requested one
[49]
Table 2: Modules that we implemented using HardsHeap. Modules can have specific modes to discover more interesting cases during their
analyses. In particular, the Small mode focuses on small objects whose sizes are less than 1 KB, and the Cross mode focuses on adjacent chunks
whose sizes are different from each other.
’’’
:param hmgr: A collection of heap chunks
:param index: An index for an allocated object
:param shm: Shared memory for storing local analysis results
’’’
obj = hmgr[index]
for i, other_obj in enumerate(hmgr):
if i == index:
continue
1 capabilities = [ ALLOC, DEALLOC ]
2
3 def post_allocate(shm, hmgr, index):
4
5
6
7
8
9
10
11
12
13
14
15
16
shm.write(index)
shm.write(i)
if is_adjacent(obj, other_obj):
(a) A local analysis of the Adjacent module
i = shm.read()
j = shm.read()
collector[(i,j)] += 1