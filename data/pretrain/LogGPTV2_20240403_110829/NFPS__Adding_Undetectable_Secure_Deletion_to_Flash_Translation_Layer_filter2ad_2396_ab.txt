(cid:2)
(cid:3)
(cid:4)
(cid:1)(cid:5)
(cid:2)(cid:5)
(cid:2)(cid:15)(cid:16)(cid:19)(cid:1)(cid:7)(cid:14)(cid:8)(cid:1)(cid:13)(cid:9)(cid:17)(cid:10)(cid:9)
(cid:6)
(cid:7)
(cid:3)(cid:17)(cid:9)(cid:9)(cid:1)(cid:16)(cid:7)(cid:10)(cid:9)(cid:1)
(cid:4)(cid:14)(cid:18)(cid:7)(cid:12)(cid:11)(cid:8)(cid:1)(cid:16)(cid:7)(cid:10)(cid:9)(cid:1)
(cid:6)(cid:7)(cid:12)(cid:11)(cid:8)(cid:1)(cid:16)(cid:7)(cid:10)(cid:9)(cid:1)
(cid:5)(cid:15)(cid:10)(cid:1)(cid:16)(cid:7)(cid:10)(cid:9)
(cid:7)
(cid:1)(cid:5)
(cid:2)(cid:5)
(cid:3)(cid:5)
(cid:1)
(cid:2)
(cid:3)
(cid:4)
(cid:8)
(cid:1)(cid:5)(cid:5)
(cid:2)(cid:5)
(cid:3)(cid:5)
(cid:4)
(cid:2)(cid:15)(cid:16)(cid:19)(cid:1)(cid:7)(cid:14)(cid:8)(cid:1)(cid:13)(cid:9)(cid:17)(cid:10)(cid:9)
Figure 7.3. Diagram showing two examples of using log pages in the ﬁrst and log
blocks in the second. In the ﬁrst example, the following sequence of data is written: A,
B, C, D, A’, B’, C’. For the ﬁrst 6 writes (steps 1 and 2), due to log pages, even after
the updates of A and B (A’, B’), no erase operation takes place. On the other hand, as
soon as C is modiﬁed (step 3), valid pages have to be copied into a new block. For the
second example, the data sequence written is: A, B, C, D, A’, B’, C’, A”. After the ﬁrst
4 writes the block is full (step 1) and at the ﬁrst additional modiﬁcation a log block is
allocated. The latter can absorb the updates of A, B and C (A’, B’, C’ in step 2). Finally,
when A is updated for a second time (step 3), a merging operation between the data
block and the log block is carried out
The advantage of this version of the FTL is that there is no additional
mapping to maintain between data blocks and log blocks. In FMAX, when an
update operates on a page, this latter is copied to the log block at the ﬁrst
available location and the page number (of the original data block) is copied
into the out-of-band (OOB) area; thus, it becomes possible to update the same
page several times. The merge operation is done when there is no more space
136
Flash Memory Integration
in the log block. The cost of this technique is an additional mapping table in
order to know on which page of the log block a data block page has been last
updated.
7.3.1.3. BAST or Block Associative Sector Translation FTL
BAST [KIM 02] is an FTL similar to FMAX but that limits the number of
blocks used as log. This allows the management of the mapping between data
block and log block pages by means of a page mapping table (instead of the
OOB region). In BAST, a single log block is dedicated to a given data block. A
merge operation is activated when: (1) the log block is full or when (2) a newly
written block page is updated while there are no more log blocks available. In
the latter case, a merge operation between data block and log block is carried
out in order to recycle a block that will be able to be used again as a log block.
7.3.1.4. FAST or Fully Associative Sector Translation FTL
The main problem with BAST is the associativity level of the log blocks,
which is set to 1. This means that every log block is associated with one and
only one data block. However, if a signiﬁcant number (larger than the number
of log blocks) of data blocks undergo updating, the system will generate
several merges with log blocks rarely used. The purpose of FAST is to avoid
this problem by allowing a log block to be associated with several data
blocks. In FAST [LEE 07], log blocks are divided into two regions, each
region containing a block dedicated to sequential updates. In effect, if a block
is completely updated, it is very disadvantageous to distribute the pages over
different log blocks because the cost of merging would be very signiﬁcant.
Therefore, pages sequentially written are placed inside the same block. The
second region contains the rest of log blocks that will absorb random updates
in a completely associative way. This makes it possible to maximize the use
of log blocks by minimizing the number of merging transactions. In FAST,
log blocks are managed by a page mapping table.
7.3.1.5. LAST or Locality Aware Sector Translation FTL
FAST effectively manages to reduce the number of merge operations by
maximizing the usage rate of log blocks. On the other hand, the cost of each
merge operation becomes more signiﬁcant since the log pages from a single
block of data are scattered over several log blocks. When the system has to
recycle a log block, one data block merging operation is thus no longer
sufﬁcient. As a matter of fact, it is necessary that the same number of merge
Flash Translation Layer
137
log blocks. Nonetheless,
operations be performed as there are different block pages in the log block.
For instance, if a log block contains pages originating from two data blocks, 2
merge operations would have to be performed (one for each of the blocks) in
order to recycle a single log block (see Figure 7.4). This is more accentuated
if one takes into account the different access patterns that can be achieved
with the data of different
if we mixed very
infrequently modiﬁed data (cold data) and very frequently modiﬁed data (hot
data), unnecessary data movement would be created. Indeed, cold data would
move from a log block to another without having been modiﬁed. The purpose
of LAST [LEE 08] is precisely to reduce these data movements and thus to
minimize the cost of merge operations. To this end, LAST ﬁrst increases the
number of log blocks for sequential access. It relies on the size of the requests
to send updates to sequential log blocks. Second, LAST partitions the region
of random log blocks into two, one hosting data very frequently modiﬁed
(so-called hot data) and the other, the less frequently modiﬁed data (known as
cold data). This allows the costs of merge operations to be minimized.
(cid:5)(cid:15)(cid:16)(cid:23)(cid:25)(cid:15)(cid:1)(cid:21)(cid:15)(cid:25)(cid:17)(cid:18)(cid:22)(cid:17)
(cid:1)
(cid:2)
(cid:3)
(cid:4)
(cid:9)(cid:15)(cid:25)(cid:17)(cid:15)(cid:1)(cid:2)
(cid:1)(cid:5)
(cid:2)(cid:5)
(cid:6)(cid:5)
(cid:7)(cid:5)
(cid:8)
(cid:9)
(cid:6)
(cid:7)
(cid:9)(cid:15)(cid:25)(cid:17)(cid:15)(cid:1)(cid:3)
(cid:4)(cid:16)(cid:26)(cid:15)(cid:25)(cid:1)(cid:21)(cid:15)(cid:25)(cid:17)(cid:18)(cid:22)(cid:17)
(cid:1)(cid:5)
(cid:2)(cid:5)
(cid:3)
(cid:4)
(cid:8)
(cid:9)
(cid:6)(cid:5)
(cid:7)(cid:5)
(cid:6)(cid:25)(cid:15)(cid:15)(cid:1)(cid:12)(cid:20)(cid:23)(cid:13)(cid:19)
(cid:6)(cid:25)(cid:15)(cid:15)(cid:1)(cid:24)(cid:11)(cid:17)(cid:15)
(cid:7)(cid:22)(cid:27)(cid:11)(cid:20)(cid:18)(cid:14)(cid:1)(cid:24)(cid:11)(cid:17)(cid:15)
(cid:10)(cid:11)(cid:20)(cid:18)(cid:14)(cid:1)(cid:24)(cid:11)(cid:17)(cid:15)
(cid:8)(cid:23)(cid:17)(cid:1)(cid:24)(cid:11)(cid:17)(cid:15)
Figure 7.4. Merging from two data blocks in FAST, two merge
operations are necessary in order to release a single block. For a color
version of this ﬁgure, see www.iste.co.uk/boukhobza/ﬂash.zip
Several FTLs endeavor to address the performance problems of FAST in
addition to those already mentioned. As an example, KAST [CHO 09] for K-
Associative sector mapping FTL is an attempt to reduce the cost of merge
operations by limiting associativity and therefore the number of data blocks
associated with a given log block. HFTL [LEE 09a], for Hybrid FTL, strives to
address the problem of temporal locality in FAST by separating hot and cold
data into different log blocks and by using a page-based mapping scheme for
138
Flash Memory Integration
hot data and block-based for cold data. Several other more recent schemes do
exist, such as BlogFTL [GUA 13] or MNFTL [QIN 11].
7.3.2. Page-level mapping FTL
As previously seen, the implementation of the conventional page-level
mapping scheme is not an option because of the size of the table that has to be
kept in RAM. Several studies attempt to address this problem, we will
mention some of them in this section.
(cid:3)(cid:4)(cid:16)(cid:16)(cid:11)(cid:14)(cid:9)(cid:1)(cid:19)(cid:4)(cid:5)(cid:13)(cid:8)(cid:1)(cid:16)(cid:8)(cid:17)(cid:1)
(cid:16)(cid:4)(cid:9)(cid:8)(cid:1)(cid:11)(cid:14)(cid:1)(cid:6)(cid:4)(cid:6)(cid:10)(cid:8)(cid:1)
(cid:1)(cid:3)(cid:2)
(cid:3)(cid:3)(cid:2)
(cid:1)
(cid:3)
(cid:2)
(cid:4)
(cid:2)(cid:4)(cid:8)
(cid:8)(cid:2)
(cid:6)
(cid:7)(cid:2)(cid:10)
(cid:6)
(cid:8)
(cid:3)(cid:4)(cid:16)(cid:16)(cid:11)(cid:14)(cid:9)(cid:1)(cid:19)(cid:4)(cid:5)(cid:13)(cid:8)
(cid:7)(cid:11)(cid:17)(cid:8)(cid:6)(cid:19)(cid:15)(cid:17)(cid:20)
(cid:5)(cid:4)(cid:3)(cid:2)
(cid:3)(cid:4)(cid:3)(cid:2)
(cid:1)
(cid:2)(cid:1)(cid:1)
(cid:9)(cid:1)(cid:1)
(cid:6)
(cid:1)
(cid:3)
(cid:5)
(cid:6)
(cid:10)(cid:1)(cid:1)(cid:1)
(cid:7)(cid:8)
(cid:1)(cid:2)(cid:3)
(cid:1)(cid:2)(cid:2)
(cid:1)
(cid:3)
(cid:5)
(cid:6)
(cid:8)(cid:9)(cid:9)
(cid:1)(cid:2)(cid:3)
(cid:2)
(cid:1)
(cid:4)
(cid:5)
(cid:6)
(cid:3)(cid:3)
(cid:3)
(cid:5)
(cid:6)
(cid:7)
(cid:3)
(cid:5)
(cid:6)
(cid:7)
(cid:1)(cid:2)(cid:2)
(cid:1)(cid:2)(cid:3)
(cid:2)
(cid:1)
(cid:4)
(cid:5)
(cid:6)
(cid:3)(cid:3)
(cid:2)(cid:4)(cid:19)(cid:4)(cid:1)(cid:5)(cid:13)(cid:15)(cid:6)(cid:12)(cid:18)
(cid:3)(cid:4)(cid:16)(cid:16)(cid:8)(cid:7)(cid:1)(cid:5)(cid:13)(cid:15)(cid:6)(cid:12)(cid:18)
(cid:15)(cid:16)(cid:17)
(cid:18)(cid:11)(cid:13)(cid:12)(cid:14)
(cid:1)(cid:2)(cid:2)
(cid:2)
(cid:4)
(cid:5)
(cid:6)
(cid:3)(cid:3)
Figure 7.5. Structure of the mapping tables in DFTL. The main mapping scheme is
a page-based scheme of which part (the most recently accessed) is stored in RAM
and the rest in ﬂash memory. In addition, a directory of mapping tables in RAM is
maintained in order to be able to ﬁnd the ﬂash block that contains a particular entry
in the mapping table (MVPN and MPPN: the virtual translation page number and the
physical translation page number, respectively). Flash memory is subdivided into two
parts, a small section dedicated to the storage of the mapping table and the rest for the
data
7.3.2.1. DFTL or Demand-based FTL
DFTL is a purely page-based mapping FTL. In order to reduce the size
of the memory storage of the mapping table, part of the latter is stored in
ﬂash memory and the most frequently accessed part of it is kept in RAM (see
Figure 7.5).
Flash Translation Layer
139
CDFTL [QIN 10] proposes a two-level cache mechanism. It improves
DFTL by taking into account
locality of I/O
workloads. Furthermore, only temporal locality is taken into account by
DFTL by using an LRU algorithm for removing parts of the page table in
ﬂash memory.
the temporal and spatial
7.3.2.2. SFTL or Spatial Locality Aware FTL
SFTL [JIA 11] is another page mapping FTL, which makes use of the
sequentiality of I/O workload in order to reduce the size of the mapping table.
If the I/O workload is sequential, it is not necessary to load several different
references of the mapping table into RAM. Only one reference is enough, in
addition to a value specifying the number of the following sequential
references.
7.3.2.3. CFTL or Convertible FTL
CFTL [PAR 10a] focuses on correcting the defects of DFTL, namely poor
performance of read operations due to the latency of the mapping scheme and
to not accounting for spatial locality. CFTL is an adaptive FTL that stores data
using a mapping scheme that depends on the access pattern. Data to which
intensive read requests are applied employ block-wise mapping while very
frequently updated data use page-level mapping. CFTL uses a cache scheme
to store only part of the mapping tables (page and block-based), this scheme
taking into account temporal and spatial locality. Although this type of FTL
makes use of two types of mappings and is therefore hybrid, we have classiﬁed
it among page-based mapping FTL because this latter scheme is thereof the
principal scheme.
7.3.3. FTL with partitioned ﬂash memory
The third family of mapping schemes is hybrid. The objective here is to
partition the memory ﬂash space into two regions, one small region involving
page-based mapping and the other more signiﬁcant region involving block-
based mapping. We will provide two examples of these schemes.
7.3.3.1. WAFTL or Workload Aware FTL
WAFTL [WEI 11] is an adaptive FTL that stores data according to their
I/O access pattern. In this case, ﬂash memory is partitioned into two regions,
140
Flash Memory Integration
one containing the data to be managed page-wise called Page Mapped blocks
(PMB) and the other containing the data to be managed in a block-wise
fashion called Block Mapped Blocks (BMB). WAFTL stores the data