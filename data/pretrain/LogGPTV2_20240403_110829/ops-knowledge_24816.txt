User: I have a django app configured to run behind nginx using uWSGI.  On a separate machine I am running celery, and pushing long running tasks from the webserver to the task machine.  The majority of the task I/O is outbound http requests, which go on for an hour or more.  The task broker is redis.
When the tasks run for more than a minute or two, the webserver becomes unresponsive (503 errors).  
There are no errors raised anywhere within the python app.  The tasks complete normally, after which the webserver continues handling requests. 
Has anyone experienced this before, and if so, how did you deal with it?  Thanks
Assistant: Figured this out after a few days.  We were using a django app called django-health-check.  It has a component called health_check_celery3 that was in the installed apps.  This was having trouble loading while celery was running, and thus causing the whole app to stall.  After removing it, celery runs as it should.