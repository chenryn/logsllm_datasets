ing models with various architectures were proposed. They
take raw traces as input without doing feature engineering [5]–
[7], [19], [20]. We pick the four most effective attacks as our
benchmark in this paper:
• k-ﬁngerprinting (kFP) [4]: kFP uses random forests to
generate a ﬁngerprint for each trace. It compares dis-
tances between ﬁngerprints and selects the k closest
ﬁngerprints to decide the test instance’s label together. Its
k Nearest Neighbor mechanism helps achieve low FPR.
• CUMUL [3]: Panchenko et al. proposed to use a Support
Vector Machine (SVM) with the cumulative summation
of bytes from each direction as input features.
• Deep Fingerprinting (DF) [5]: DF is a deep Convolu-
tional Neural Network specially designed for website
ﬁngerprinting. It takes raw cell sequences as input where
“+1” represents an outgoing cell and “-1” represents an
incoming cell. It is able to achieve higher accuracy than
any previous attack.
• Tik-Tok [7]: Tik-Tok improves upon DF by incorporat-
ing time information into training. It uses directional
timestamps to represent a trace: a positive real number
represents the timestamp of an outgoing cell, and a
negative real number represents that of an incoming cell.
It is currently the state-of-the-art attack.
C. WF Defenses
Existing works can be roughly categorized into three main
classes: Randomization, Regularization, and Adversarial Trace
Crafting. They either function at the network layer or the
application layer.
1) Randomization Defenses: These defenses emphasize
the use of randomness so that different
traces from one
webpage do not have the same pattern [21]–[23]. They focus
on obfuscating (reordering, reshaping, and delaying) HTTP
requests and responses. The most effective defense, ALPaCa,
requires the web server’s cooperation [23], which may hamper
its deployability.
WTF-PAD [8] and FRONT [9] are two lightweight defenses
that introduce no delays to page loads. WTF-PAD tries to
hide distinctive time gaps in traces. It samples time gaps from
several pre-conﬁgured distributions and inserts dummy packets
at those time gaps if no real packets are in the buffer. However,
it was broken by DF [5] before it was ready to be deployed
on Tor. FRONT randomizes the shape of distributions used
for sampling the timing and number of dummy packets added,
and the dummy packets are concentrated near the front of a
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:35:20 UTC from IEEE Xplore.  Restrictions apply. 
1559
EntryMiddleExitAdversarytrace. It only achieves partial effectiveness against DF [5] and
Tik-Tok [7] attack.
Since those defenses do not delay any real packets, their
ability to obfuscate time features is limited. By contrast,
Surakav samples a random time gap for every burst of data,
greatly restricting the time information leakage.
2) Regularization Defenses: This class of defenses aims
at ﬁtting traces into deterministic patterns so that they can
be provably secure under certain assumptions. For example,
the BuFLO family of defenses [11]–[13] suggests using a
ﬁxed sending rate on both sides and maintaining transmission
for some extra time after a page load ﬁnishes. Among them,
Tamaraw [13] achieves a good balance between overhead and
security. Their use of a uniform pattern for all webpages causes
high overhead. Compared to those defenses, Surakav makes
use of diverse sending patterns that are ﬂexibly adjusted in
real time to reduce the overhead.
Two other defenses, Glove [24] and Supersequence [2],
proposed to group webpages into clusters and compute a
super-trace for each group so that visiting a page in this group
will always yield the same trace. But they both require prior
knowledge of the pages to be visited and are too expensive
to use. Walkie-Talkie [10] greatly optimized the overhead by
modifying the browser to talk in half-duplex mode. Still, it
assumes that we can know the burst patterns of each page in
advance, which is hard to achieve in reality. By comparison,
Surakav does not require any prior knowledge of the webpages
to be loaded, making it more realistic to deploy.
3) Adversarial Defenses: Adversarial traces represent a
new direction for WF defense design. These defenses are
based on the fact that deep learning models can be fooled
using small, carefully-crafted perturbations upon the original
inputs [25]–[27]. Mockingbird [28] used an optimization prob-
lem to ﬁnd adversarial perturbations to the network traces.
Hou et al. proposed a GAN model to generate adversarial
traces [29]. However, both works require pre-knowledge of the
full trace to compute noise, which again leads to deployment
issues. Nasr et al. [30] proposed a new method to search for
perturbations without knowing the whole trace. They assumed
that the attack model was trained on undefended traces and
tested on defended traces, which does not ﬁt our model; a
realistic attacker should be able to train on defended traces.
To show their inapplicability, we conducted a brief simula-
tion experiment in the open-world scenario using the same
methodology as our other experiments described in Section V.
We found their defense effectively reduced the TPR of the
attacker by over 94% if the attack model was only trained on
undefended traces, but the attacker’s TPR was reduced by only
4% if it was trained on defended traces.
Note that our defense does not fall
into this category.
Surakav does not try to ﬁnd adversarial perturbations that
can fool a trained classiﬁer. Instead, it tunnels trafﬁc through
various sending patterns generated from a GAN.
4) Other Defenses: Decoy covers each page by randomly
loading another page in the background [16]. Recent research
shows that its overhead is too high (100%) while its security is
not guaranteed due to variant base rates [31]. TrafﬁcSliver [14]
proposed to split trafﬁc over several “sub-circuits” in a highly
random manner. It is meant to defend against a malicious entry
node, which is slightly different from our threat model. Any
local attacker (e.g., someone under the same network) is still
able to see the complete traces, weakening the defense. We
will show how TrafﬁcSliver can be augmented by our defense
in Section VI.
D. Trace Generation
Rigaki and Garcia showed the possibility to make mal-
ware trafﬁc undetectable by mimicking normal trafﬁc with a
GAN [32]. FlowGAN [33] trained a GAN to learn six typical
features of normal network trafﬁc. Then, it dynamically ad-
justed trafﬁc to approach the feature patterns of normal trafﬁc
generated by the GAN to resist censorship. GAN Tunnel [34]
similarly used a GAN to reshape the trafﬁc of an application by
learning the trafﬁc features of a decoy application. However,
they need to train a separate GAN for each decoy application,
which is not scalable for our scenario.
We observed that these works all served the purpose of
evading censorship by changing general trafﬁc features, such
as packet length, packet inter-arrival time, etc. Compared to
our work, none of those works generates burst sequences
directly. To the best of our knowledge, we are the ﬁrst to
show that GANs can be used to create an effective defense
against website ﬁngerprinting attacks.
III. PRELIMINARIES
A. Generative Adversarial Network
A Generative Adversarial Network (GAN) refers to a frame-
work in which two neural networks compete against each
other [35]. In this framework, one player G (Generator) tries
to generate synthesized data to fool its opponent, while the
opponent D (Discriminator) tries to distinguish between real
and synthesized data. Through this adversarial process, G
enhances its ability to generate realistic-looking data using
feedback from an improving D.
Vanilla GAN has several issues in training: the process is
usually unstable, and its loss function does not function well
as a stop condition [36]. Wasserstein GAN (WGAN) was
proposed to solve these limitations [37]–[39]. WGAN-div is
the state-of-the-art variant in the WGAN family and shown to
be stable in training [39]. WGAN-div formulates the model as
a min-max problem
minG maxD
Ex∼Pr [D(x)] − EG(z)∼Pf [D(G(z))]
−kEˆx∼Pu [||∇ˆxD(ˆx)||p],
(1)
where Pf is the distribution of fake data, Pr is the distribution
of real data, and ˆx is a linear interpolation of real and fake data
points (the corresponding distribution is denoted as Pu) [39].
The output of D is the logit of the probability that the input
is real, assigned by the discriminator, which we refer to as
the logit probability. The ﬁrst two terms of (1) show that the
discriminator attempts to maximize the difference of the logit
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:35:20 UTC from IEEE Xplore.  Restrictions apply. 
1560
Fig. 2: Visualization of a burst sequence.
probability between real and fake samples for each potential
generator, who attempts to minimize the same. The third
term of (1) is a regularization term to ensure that D satisﬁes
the Lipschitz constraint [39]. They show that k = 2 and
p = 6 yield the best results. We also use these values in our
implementation.
From (1), we can derive the loss functions of D and G to
minimize as follows,
LD = −Ex∼Pr [D(x)] + EG(z)∼Pf [D(G(z))]
+kEˆx∼Pu [||∇ˆxD(ˆx)||p],
LG = Ex∼Pr [D(x)] − EG(z)∼Pf [D(G(z))].
(2)
(3)
Equation (3) is also known as the estimated Wasserstein
distance between Pf and Pr, providing a good indicator of
when training should stop.
In this work, we build a GAN based on the methodology
of WGAN-div. We train such a generator to generate burst
sequences that look like normal traces and use them to create
a WF defense. We will provide the details of the design in
Section IV.
B. Trace Representation
A trace is usually represented as a sequence of +1’s and -1’s
since a Tor cell is of ﬁxed length [1] and we only need to use
the sign to indicate the direction of the cell. To facilitate the
training of a generator, we transform such cell sequences into
burst sequences. As shown in Figure 2, several consecutive
cells from the same direction form a burst. Then a trace can
be represented as x = (b1,··· , b(cid:96)), where bi represents the
i-th burst of cells. When i is an odd number, bi represents an
outgoing burst; otherwise, it is an incoming burst. b1 is always
an outgoing burst since a loading process is always initiated
by a client request. We use |bi| to denote the size of burst
bi. We denote the time gap between two consecutive outgoing
bursts as to(cid:1)o, deﬁned as the time gap between the ﬁrst cells
of these two bursts. A “trace” refers to a “burst sequence” in
the rest of the paper, unless otherwise stated.
IV. A NEW DEFENSE: SURAKAV
In this section, we introduce our new defense Surakav. We
ﬁrst discuss the motivation and intuition behind the defense.
Then we give an overview of the workﬂow. Finally, we
describe the design for each component of Surakav in detail.
A. Motivation and Intuition
The failure of WTF-PAD [8] against DF [5] indicates that it
is hard for a defense to beat a strong attack with only dummy
packets and no packet delays. Regularization defenses, on the
other hand, provide a simple intuition on why they work: to
load webpages in their predeﬁned sending patterns. Consider
Tamaraw [13], a regularization defense: it constructs a simple
sending pattern for all webpages, making the client and the
server send packets at different constant rates and stop sending
cells when the trace length is a multiple of a predeﬁned integer.
However, since real packets are unevenly distributed during
the loading process, a constant sending strategy cannot fully
utilize the overhead budget. Moreover, Tamaraw users can only
choose to have either fewer delays or less dummy data, at the
cost of increasing the other.
Surakav reduces overhead while maintaining effectiveness
by tunneling packets through different sending patterns rather
than a constant pattern. These patterns capture the general
characteristics of a normal page load (e.g., more incoming
packets than outgoing ones). A naive way to create sending
patterns is to directly use pre-collected real traces. However,
maintaining and distributing real
traces will again burden
the Tor network. Instead, we can use a generative model to
synthesize traces for us as sending patterns and distribute the
trained model directly to users. To distribute a model, we
only need to transfer several megabytes of data, which are
the trained weights of the model.
We choose to use a Generative Adversarial Network (GAN)
for trace generation since it has shown great success in
synthesizing graphics [35], [37], [39]. We design a GAN to
generate realistic sending patterns from various webpages. We
refer to these patterns as “reference traces”. When loading
a webpage, we randomly generate reference traces from the
trained generator and send packets based on them. We wait
for a randomly sampled time gap each time we are about to
send out a burst of data. The size of the defended burst is
determined together by the amount of data currently in the
buffer and the burst size suggested by the reference trace.
Our design leaks minimal time information and allows us to
control how much size information we are willing to sacriﬁce
to lower overhead. By using reference traces derived from a
generator, we ensure the patterns are never repeated, even if
the attacker uses the same generator as the victim.
B. Overview of Surakav
The main components of Surakav are a generator G that
generates reference traces (Section IV-C) and a regulator R
that uses reference traces to decide when and how many
packets should be sent onto the circuit based on two random-
ized mechanisms (Section IV-D). The workﬂow of Surakav is
illustrated in Figure 3.
Surakav ﬁrst uses a GAN to train G on a dataset and samples
reference traces from G. The reference trace is a sequence
of bursts deﬁned in Section III-B. Then, in each round, the
regulator R consumes two bursts from a sampled reference
trace, one for the client and another for the proxy server.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:35:20 UTC from IEEE Xplore.  Restrictions apply. 
1561
IncomingBurstOutgoing BurstTimeOutgoing  cellIncoming cellAAADfnicbVLbbtNAEN0mXIq5NIVHXlakQUgoV1JoeYooDzwWRJtKcRStN5N4Fa/X7I7bRCt/Ca/wUfwNu64rkZaxLB3NbeecmShLhMFe789OrX7v/oOHu4+Cx0+ePttr7D8/NyrXHM64SpS+iJiBRKRwhgITuMg0MBklMI5WJz4+vgRthEq/4yaDqWTLVCwEZ+hcs8YezqwKTaw0oqKqmDWavU6vNHoX9CvQJJWdzvZr43CueC4hRZ4wYyb9XoZTyzQKnkARhLmBjPEVW8LEwZRJMFNbTl7QlvPM6UJp96dIS++/FZZJYzYycpmSYWxux7zzf7FJjoujqRVpliOk/PqhRZ5QR9LLQOdCA8dk4wDjWrhZKY+ZZhydWEHQ8ubGyTZ0oZWkMWJmPna7COuOQfcGrF16uoQOV7L7Iwfj5TTdd8fD46PDrlN80y5FbTOt1VXbc1BJ1dbTLYNUi2WMtEzZYmZQMr3R8y31LGoheSKyIghCyVbA3LbRzRuEn8FJr+GbinKDJ0pKls7tzVYL2wooDb1GGhJbgoyVpdcpI1Shi7B10Qp87xSu+FYPl1BMBtOqzwp0OpC5x36aSK2t7RyGV2Lud9HzX2EPQjnCuNkPLzOnEypp3xZVt5J0ybk4KHzL4oaOwtixaVXmTrF/+/DugvNBp/++M/w6bI4+VUe5S16SV+QN6ZMPZES+kFNyRjjJyU/yi/yuk/rrervevU6t7VQ1L8iW1Y/+Ak+KHI0=to oFig. 3: Workﬂow of Surakav. The defense has two phases: (a) we ﬁrst train a generator that is able to generate various reference
traces; (b) we sample reference traces from the trained generator and send bursts of data based on the reference traces.
a noise vector z as input and outputs a vector representing a
generated burst sequence and a trace length (cid:96). The input vector
is normalized into [0,1] to facilitate the training process. The
key to being able to generate traces of different webpages
is that we include the label information in the input. This is
a trick used by conditional GANs to generate instances of
different classes [40]. Note that the size of different webpages
could vary a lot, leading to different trace lengths, while the
output of the generator is a ﬁxed-length vector. Therefore,
we truncate the output trace in post-processing: we cut the
ﬁxed-length vector at length (cid:96) (i.e., the learnt trace length for
this class) to get the ﬁnal burst sequence. This helps us avoid