## gdb - debug - core dump - How to Analyze a PostgreSQL Crash Dump File   
### 作者        
digoal        
### 日期        
2020-11-17        
### 标签        
PostgreSQL , gdb , debug , core dump , linux         
----        
## 背景     
## 原文     
https://www.highgo.ca/2020/11/07/how-to-analyze-a-postgresql-crash-dump-file  
## 1. Introduction  
In this blog post, I will talk about how to enable the generation of crash dump file (also known as core dump) and some common GDB commands to help a developer troubleshoot a crash-related issues within PostgreSQL and also other applications. Proper analysis of the issue normally will take time and certain degree of knowledge about the application source code. From experience, sometimes it may be better to look at the bigger environment instead of looking at the point of crash.  
## 2. What is a Crash Dump File?  
A crash dump file is a file that consists of the recorded state of the working memory of an application when it crashes. This state is represented by stacks of memory addresses and CPU registers and normally it is extremely difficult to debug with only memory addresses and CPU registers because they tell you no information about the application logic. Considering the core dump contents below, which shows the back trace of memory addresses to the point of crash.  
```  
#1  0x00687a3d in ?? ()  
#2  0x00d37f06 in ?? ()  
#3  0x00bf0ba4 in ?? ()  
#4  0x00d3333b in ?? ()  
#5  0x00d3f682 in ?? ()  
#6  0x00d3407b in ?? ()  
#7  0x00d3f2f7 in ?? ()  
```  
Not very useful is it? So, when we see a crash dump file that looks like this, it means the application is not built with debugging symbols, making this crash dump file useless. If this is the case, you will need to install the debug version of the application or re-build the application with debugging enabled.  
## 3. How to Generate a Useful Crash Dump File  
Before the generation of crash dump file, we need to ensure the application is built with debugging symbols. This can be done by executing the ```./configure``` script like this:  
```  
./configure enable-debug  
```  
This adds the ```-g``` argument to ```CFLAGS``` in ```src/Makefile.global``` with optimization level set to 2 (```-O2```). My preference is to also change the optimization to 0 (```-O0```) so when we are navigating the stack using GDB, the navigation will make much more sense rather than jumping around and we will be able to print out most variables values in memory instead of getting ```optimized out``` error in GDB.  
```  
CFLAGS = -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -g -O0  
```  
Now, we can enable the crash dump generation. This can be done by the user limit command.  
```  
ulimit -c unlimited  
```  
to disable:  
```  
ulimit -c 0  
```  
Make sure there is enough disk space because crash dump file is normally very large as it records all the memory execution states from start to crash, and make sure the ```ulimit``` is set up in the shell before starting PostgreSQL. When PostgreSQL crashes, a core dump file named ```core``` will be generated in ```$PGDATA```  
也可以通过os内核参数设置core dump文件的格式和存放目录  
```  
sysctl:   
kernel.core_pattern = /data01/corefiles/core_%e_%u_%t_%s.%p  
```  
## 4. Analyzing the Dump File using GDB  
GDB (GNU Debugger) is a portable debugger that runs on many Unix-like systems and can work with many programming languages and is my favorite tool to analyze a crash dump file. To demonstrate this, I will intentionally add a line in PostgreSQL source code that will result in ```segmentation fault``` crash type when a ```CREATE TABLE``` command is run.  
也可以使用gcore直接产生core文件   
[《如何查看sshd当前配置 (gcore, gdb 的妙用)》](../201607/20160722_03.md)    
Assuming the PostgreSQL has already crashed and generated a core dump file ```core``` in this location ```~/highgo/git/postgres/postgresdb/core```. I would first use the ```file``` utility to understand more about the core file. Information such as the kernel info, and the program that generated it.  
```  
caryh@HGPC01:~$ file /home/caryh/highgo/git/postgres/postgresdb/core  
postgresdb/core: ELF 64-bit LSB core file x86-64, version 1 (SYSV), SVR4-style, from 'postgres: cary cary [local] CREATE TABLE', real uid: 1000, effective uid: 1000, real gid: 1000, effective gid: 1000, execfn: '/home/caryh/highgo/git/postgres/highgo/bin/postgres', platform: 'x86_64'  
caryh@HGPC01:~$  
```  
The ```file``` utility tells me that the core file is generated by this application ```/home/caryh/highgo/git/postgres/highgo/bin/postgres```, so I would execute ```gdb``` like this:  
```  
gdb /home/caryh/highgo/git/postgres/highgo/bin/postgres -c  /home/caryh/highgo/git/postgres/postgresdb/core  
GNU gdb (Ubuntu 8.1-0ubuntu3) 8.1.0.20180409-git  
Copyright (C) 2018 Free Software Foundation, Inc.  
License GPLv3+: GNU GPL version 3 or later   
This is free software: you are free to change and redistribute it.  
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"  
and "show warranty" for details.  
This GDB was configured as "x86_64-linux-gnu".  
Type "show configuration" for configuration details.  
For bug reporting instructions, please see:  
.  
Find the GDB manual and other documentation resources online at:  
.  
For help, type "help".  
Type "apropos word" to search for commands related to "word"...  
Reading symbols from /home/caryh/highgo/git/postgres/highgo/bin/postgres...done.  
[New LWP 27417]  
[Thread debugging using libthread_db enabled]  
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".  
Core was generated by `postgres: cary cary [local] CREATE TABLE                                 '.  
Program terminated with signal SIGSEGV, Segmentation fault.  
#0  heap_insert (relation=relation@entry=0x7f872f532228, tup=tup@entry=0x55ba8290f778, cid=0, options=options@entry=0,  
    bistate=bistate@entry=0x0) at heapam.c:1840  
1840            ereport(LOG,(errmsg("heap tuple len = %d", heaptup->t_len)));  
(gdb)  
```  
Immediately after running ```gdb``` on the ```core``` file, it shows the location of the crash at ```heapam.c:1840``` and that is exactly the line I have intentionally added to cause a crash.  
## 5. Useful GDB Commands  
With ```gdb```, it is very easy to identify the location of a crash, because it tells you immediately after running ```gdb``` on the ```core``` file. Unfortunately, 95% of the time, the location of the crash is not the real cause of the problem. This is why I mentioned earlier that sometimes it may be better to look at the bigger environment instead of looking at the point of crash. The crash is likely caused by a mistake in the application logic some where else in the application before it hits the point of crash. Even if you fix the crash, the mistake in application logic still exists and most likely, the application will crash somewhere else later or yield unsatisfactory results. Therefore, it is worth awhile to understand some of the powerful GDB commands that could help us understand the call stacks better to identify the real root cause.  
### 5.1 The ```bt``` (Back Trace) command  
The ```bt``` command shows a series of call stacks since the beginning of the application all the way to the point of crash. With full debugging enabled, you will be able to see the function arguments and values being passed in to each function calls as well as the source file and line numbers where they were called. This allows developer to travel backwards to check for any potential application logic mistake in the earlier processing.  
```  
(gdb) bt  
#0  heap_insert (relation=relation@entry=0x7f872f532228, tup=tup@entry=0x55ba8290f778, cid=0, options=options@entry=0,  
    bistate=bistate@entry=0x0) at heapam.c:1840  
#1  0x000055ba81ccde3e in simple_heap_insert (relation=relation@entry=0x7f872f532228, tup=tup@entry=0x55ba8290f778)  
    at heapam.c:2356  
#2  0x000055ba81d7826d in CatalogTupleInsert (heapRel=0x7f872f532228, tup=0x55ba8290f778) at indexing.c:228  
#3  0x000055ba81d946ea in TypeCreate (newTypeOid=newTypeOid@entry=0, typeName=typeName@entry=0x7ffcf56ef820 "test",  
    typeNamespace=typeNamespace@entry=2200, relationOid=relationOid@entry=16392, relationKind=relationKind@entry=114 'r',  
    ownerId=ownerId@entry=16385, internalSize=-1, typeType=99 'c', typeCategory=67 'C', typePreferred=false,  
    typDelim=44 ',', inputProcedure=2290, outputProcedure=2291, receiveProcedure=2402, sendProcedure=2403,  
    typmodinProcedure=0, typmodoutProcedure=0, analyzeProcedure=0, elementType=0, isImplicitArray=false, arrayType=16393,  
    baseType=0, defaultTypeValue=0x0, defaultTypeBin=0x0, passedByValue=false, alignment=100 'd', storage=120 'x',  
    typeMod=-1, typNDims=0, typeNotNull=false, typeCollation=0) at pg_type.c:484  
#4  0x000055ba81d710bc in AddNewRelationType (new_array_type=16393, new_row_type=, ownerid=,  
    new_rel_kind=, new_rel_oid=, typeNamespace=2200, typeName=0x7ffcf56ef820 "test")  
    at heap.c:1033  
#5  heap_create_with_catalog (relname=relname@entry=0x7ffcf56ef820 "test", relnamespace=relnamespace@entry=2200,  
    reltablespace=reltablespace@entry=0, relid=16392, relid@entry=0, reltypeid=reltypeid@entry=0,  
    reloftypeid=reloftypeid@entry=0, ownerid=16385, accessmtd=2, tupdesc=0x55ba8287c620, cooked_constraints=0x0,  
    relkind=114 'r', relpersistence=112 'p', shared_relation=false, mapped_relation=false, oncommit=ONCOMMIT_NOOP,  