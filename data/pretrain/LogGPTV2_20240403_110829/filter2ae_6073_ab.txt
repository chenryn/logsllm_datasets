可以看到少了对于`size`的检查，可能会存在越界读。
再看`nvme_mmio_write`中，该函数调用了`nvme_write_bar`函数。经过对比，题目对`nvme_write_bar`函数中添加了部分代码，添加的代码的内容为：
    default:
          ...
          if ( size == 2 )
          {
            *(_WORD *)((char *)&n->bar.cap + offset) = data;
          }
          else if ( size > 2 )
          {
            if ( size == 4 )
            {
              *(_DWORD *)((char *)&n->bar.cap + offset) = data;
            }
            else if ( size == 8 )
            {
              *(uint64_t *)((char *)&n->bar.cap + offset) = data;
            }
          }
          else if ( size == 1 )
          {
            *((_BYTE *)&n->bar.cap + offset) = data;
          }
          break;
      }
可以看到似乎也存在越界写功能。
再去虚拟机中看mmio空间的大小：
    lspci -vv -s 00:04.0
    00:04.0 Non-Volatile memory controller: Intel Corporation QEMU NVM Express Controller (rev 02) (prog-if 02 [NVM Express])
        Subsystem: Red Hat, Inc. QEMU Virtual Machine
        Physical Slot: 4
        Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR+ FastB2B- DisINTx+
        Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- SERR- bar`大小却只有0x40，结合上面的分析，确定该设备存在越界读写漏洞。
    NvmeCtrl        struc ; (sizeof=0x1C50, align=0x10, copyof_4151)
    00000000 parent_obj      PCIDevice_0 ?
    000008E0 iomem           MemoryRegion_0 ?
    000009D0 ctrl_mem        MemoryRegion_0 ?
    00000AC0 bar             NvmeBar_0 ?
    00000B00 conf            BlockConf_0 ?
    00000B38 page_size       dd ?
    00000B3C page_bits       dw ?
    00000B3E max_prp_ents    dw ?
    00000B40 cqe_size        dw ?
    00000B42 sqe_size        dw ?
    00000B44 reg_size        dd ?
    00000B48 num_namespaces  dd ?
    00000B4C num_queues      dd ?
    00000B50 max_q_ents      dd ?
    00000B54                 db ? ; undefined
    00000B55                 db ? ; undefined
    00000B56                 db ? ; undefined
    00000B57                 db ? ; undefined
    00000B58 ns_size         dq ?
    00000B60 cmb_size_mb     dd ?
    00000B64 cmbsz           dd ?
    00000B68 cmbloc          dd ?
    00000B6C                 db ? ; undefined
    00000B6D                 db ? ; undefined
    00000B6E                 db ? ; undefined
    00000B6F                 db ? ; undefined
    00000B70 cmbuf           dq ?                    ; offset
    00000B78 irq_status      dq ?
    00000B80 serial          dq ?                    ; offset
    00000B88 namespaces      dq ?                    ; offset
    00000B90 sq              dq ?                    ; offset
    00000B98 cq              dq ?                    ; offset
    00000BA0 admin_sq        NvmeSQueue_0 ?
    00000C00 admin_cq        NvmeCQueue_0 ?
    00000C50 id_ctrl         NvmeIdCtrl_0 ?
    00001C50 NvmeCtrl        ends
### 利用
要想成功利用，分为两步：
  1. 利用越界读，泄露程序基址与堆地址。
  2. 利用越界写覆盖`qemu timer`控制程序执行流
因为程序开启了PIE，所以第一步需要先泄露地址。首先是得到`system`地址，在与`bar`地址偏移`0x1ff0`的地方找到了存在程序地址的地方，利用`mmio_read`越界读出来，然后根据偏移计算出`system`地址。其次是得到`NvmeCtrl->bar`地址的空间以实现可以拿到最终传参的地址，在与bar地址偏移`0x1f98`的地方找到了存在堆地址的地方，根据偏移可以计算出`NvmeCtrl->bar`地址。
关键的是如何控制程序执行流，主要原理是利用了`NvmeCtrl`结构体中的`admin_sq`，`admin_sq`中存在一个`timer`结构体，可以利用它来控制程序执行流。
    00000000 NvmeSQueue_0    struc ; (sizeof=0x60, align=0x8, copyof_4154)
    00000000                                         ; XREF: NvmeCtrl_0/r
    00000000                                         ; NvmeCtrl/r
    00000000 ctrl            dq ?                    ; offset
    00000008 sqid            dw ?
    0000000A cqid            dw ?
    0000000C head            dd ?
    00000010 tail            dd ?
    00000014 size            dd ?
    00000018 dma_addr        dq ?
    00000020 timer           dq ?                    ; offset
    00000028 io_req          dq ?                    ; offset
    00000030 req_list        $FE468C6164B384978313660BA47FFEDA ?
    00000040 out_req_list    $FE468C6164B384978313660BA47FFEDA ?
    00000050 entry           $53C797D9CC370671B1F6BB504B4B2727 ?
    00000060 NvmeSQueue_0    ends
    00000000 ; ---------------------------------------------------------------------------    00000000 QEMUTimer       struc ; (sizeof=0x30, align=0x8, copyof_729)
    00000000 expire_time     dq ?
    00000008 timer_list      dq ?                    ; offset
    00000010 cb              dq ?                    ; offset
    00000018 opaque          dq ?                    ; offset
    00000020 next            dq ?                    ; offset
    00000028 attributes      dd ?
    0000002C scale           dd ?
    00000030 QEMUTimer       ends
    00000030
主要有两种方式：
一种是伪造timer，利用虚拟机重启或关机时会触发时钟`timer`，调用`cb(opaque)`控制程序执行流的方法，关键代码如下所示：
    void main_loop_wait(int nonblocking)
    {
        ...
        /* CPU thread can infinitely wait for event after
           missing the warp */
        qemu_start_warp_timer();
        qemu_clock_run_all_timers();
    }
    bool timerlist_run_timers(QEMUTimerList *timer_list)
    {
        ...
            timer_list->active_timers = ts->next;
            ts->next = NULL;
            ts->expire_time = -1;
            cb = ts->cb;
            opaque = ts->opaque;
            /* run the callback (the timer list can be modified) */
            qemu_mutex_unlock(&timer_list->active_timers_lock);
            cb(opaque);   // we can hajack the control flow here
            qemu_mutex_lock(&timer_list->active_timers_lock);
            progress = true;
        }
        ...
        return progress;
    }
可以在堆中伪造好timer结构体，其`cb`为system地址，`opaque`为参数的地址。利用越界将`admin_sq`中的`timer`指针覆盖成该伪造的结构体，当reboot时就可以成功控制程序的执行流。一个关键的点是`timer`结构体中的`timer_list`指针需要正确，因为之前泄露了堆地址，因此可以通过偏移计算得到原来的`timer_list`结构体的值，将它覆盖成原来的就好。但是由于结构体都是堆地址，会导致和泄漏的地址的偏移可能不固定。但是它的地址和堆基址的偏移时一致的，因为我们可以通过计算堆基址来得到`timer_list`的地址，具体可以去看exp中的内容。
另一种方式则是在`nvme_mmio_write`中存在一条调用链：`nvme_mmio_write->nvme_process_db->timer_mod->timer_mod_ns->timerlist_rearm->timerlist_notify->(timer_list->notify_cb)(timer_list->notify_opaque,timer_list->clock->type)`，也可以成功控制程序执行流。
我的exp中使用的是第一种利用方式。
## 小结
qemu ctf pwn题分析到这就暂告一段落，接下来会分析一些qemu cve来进一步了解相关漏洞。
相关脚本以及文件[链接](https://github.com/ray-cp/vm-escape/tree/master/qemu-escape)
* * *