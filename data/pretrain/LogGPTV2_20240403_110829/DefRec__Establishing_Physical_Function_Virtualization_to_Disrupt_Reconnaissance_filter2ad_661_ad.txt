invalid, i.e., they may fail to follow the mathematical model of
a power grid, raising suspicions to adversaries. To solve this
problem, we reﬁne decoy data such that the combination of
decoy and real data becomes valid, which makes them appear
to be measured from a real power grid. In other words, the
combination of decoy and real data raises no alerts in state
estimation.
We use Algorithm 1 to reﬁne decoy data by going through
iterations of two operations: (i) putting decoy and real data
into state estimation (lines 5 and 8), and (ii) using resultant
errors to adjust the value of decoy data while leaving the value
of real data unchanged (line 7). Typically, state estimation
removes data with big measurement errors due to accidents
like misconﬁgurations in sensors [45]. In Algorithm 1, we
use errors differently: modify decoy data instead of removing
them. Using the resultant errors to slightly adjust the values
of decoy data makes them move closer to valid ones, still
achieving the misleading objective (e.g., making Equation (6)
challenging to hold).
B. Discussion: Decoy Data for Other Attacks
In this section, we used a theoretical model of FDIAs
to demonstrate decoy data construction. In Figure 24 in Ap-
pendix B, we further show that by replacing the theoretical
model with ones in other control operations, we can generalize
decoy data construction for other attacks.
Towards Future Smart Grids. DefRec aims at disrupting
adversaries who need global knowledge of a power grid. In
future microgrid infrastructure, distributed energy resources,
such as solar power, decentralize control operations in multiple
regions [36]. Consequently, DefRec may become less effective
against adversaries that restrict their malicious activities in a
region. To solve this problem, we can deploy multiple DefRec
Algorithm 1 Pseudocode of REFINEDECOY that reﬁnes decoy
data such that the combination of decoy and real data is valid
1: Input: zinit = [z zinit
] (cid:46) combination of real and initial
d
(cid:46) the threshold to identify bad data in state
decoy data
2:
τ
estimation
3: procedure REFINEDECOY(zinit)
4:
5:
zd = zinit
[r rd] = SE(zinit) = SE([z zinit
d
(cid:46)
state estimation SE returns measurement errors r and rd
for real and decoy data
])
d
6:
7:
8:
while ||[r rd]|| > τ do
zd = zd − rd
[r rd] = SE([z zd])
return zd
instances independently in concerned regions to disrupt and
mislead adversaries’ preparations relying on knowledge of
those regions.
In future smart grids, we can also experience increased data
acquisition frequency. For example, phasormeasurement units
can collect data at up to 200 times per second [7]. Crafting
decoy data in such frequency can be challenging. However,
those technical advancements are faced by both existing state
estimation application and adversaries, who may down-sample
data to prepare attacks. Consequently, instead of catching up
with advanced data acquisitions, DefRec needs to compete
with adversaries or existing state estimation application, craft-
ing decoy data at a pace quicker than the pace of adversaries’
preparations. Also, based on our evaluation in Figure 17,
the latency of decoy data construction, built on top of state
estimation, is on the same order of magnitude as the latency
of state estimation. As future smart grids introduce advanced
state estimation algorithms, we can increase the efﬁciency of
decoy data construction correspondingly.
VI.
IMPLEMENTATION
To evaluate security policies included in DefRec, we im-
plemented PFV as an SDN application in the ONOS network
operating system and developed a testbed (shown in Figure 7)
that simulates both cyber and physical infrastructures of power
grids.
Communication Networks. The network implementation
follows typical setups for SDN evaluations [78]. Speciﬁcally,
we used ﬁve HP ProCurve 3500yl switches and seven HP
ProLiant DL3600 servers. Each switch has 48 ports, and we
extended each server by deploying four PCI 4-port Ethernet
adapters [26]. By grouping switch ports into different VLANs,
we built six networks of different sizes (up to 124 nodes)
from TopologyZoo dataset [34], which includes topology of
real networks managed by different Internet Service Providers
(ISPs) (see Table I).
Implementation of PFV & DefRec. PFV does not require
a dedicated virtual environment; we implemented PFV as
an SDN application in ONOS [4], including around 1,500
lines of code (LOC). We present storage overhead of PFV in
Appendix C. Based on PFV, we also implemented DefRec’s
disruption policy in ONOS, using less than 200 LOC. For De-
fRec’s attack-misleading policy, we implemented decoy data
construction algorithm by using MATPOWER, an open-source
MATLAB toolbox [79]; the implementation uses around 400
LOC. All implementations were carried out on a 64-bit Ubuntu
18.04, deployed in a workstation with four Intel Xeon 2.8 GHz
processors and 16 GB RAM.
Physical Devices (Seed Devices). We used IEDs from
three different vendors as end devices: Schweitzer Engineering
Laboratories (SEL) 751A feeder protection relay [60], Allen
Bradley (AB) MicroLogix 1400 PLC [1], and Schneider Elec-
tric (SE) ION7550 power meters [58]. To communicate with
those devices, we implemented a DNP3 master by using the
openDNP3 library [49]. For each evaluation case, we used
an DNP3 master to issue requests, including data acquisition
retrieving analog data and control operations opening/closing
breakers, to both real devices and virtual nodes.
9
TABLE I: Evaluation cases. We
include the number of nodes for
each network in parentheses.
Case
1
2
3
4
5
6
Power Grid
Simulation
IEEE 24-bus
IEEE 30-bus
RTS96 73-bus
IEEE 118-bus
Poland 406-bus
Poland 1153-bus
Network (# of
nodes)
Datax (11)
Abilene (22)
Hurricane (30)
Chinanet (56)
Cesnet (78)
Forthnet (124)
Fig. 7: Cyber-physical testbed for evaluation. We set the delay of network links to a normal
distribution with 20 milliseconds (ms) mean and 5 ms jitter, adjusting settings of general-purpose
wide-area networks [31] to meet the requirements of power grids [28].
Power Grid Simulations. To provide physical data for
network trafﬁc, we used MATPOWER to simulate six power
systems [79], shown in Table I. The latter two systems rep-
resent the biggest two areas of Polish 400-, 220-, and 110-
kV national transmission networks. To simulate the normal
variation of operational data, we developed a benchmark
proﬁle based on data from real utilities [16], [52]. We extracted
one month of real data on power generation and calculated
the ratio between actual data value at each timestamp to the
peak value of that month. For each simulated system, we
randomly selected power generators and load units, adjusting
measurements for each unit according to the benchmark.
VII. EVALUATION
In this section, we perform security and performance
evaluation for both PFV and security policies in DefRec.
A. Security Evaluation
Security evaluation focuses on the effectiveness of: (i)
PFV’s virtualization on network ﬂows of real devices, (ii)
disruption policy to delay passive attacks and isolate proactive
attacks (RO1 and RO2 in Section II-B), and (iii) attack-
misleading policy causing adversaries to design ineffective
attacks (RO3).
1) Effectiveness of PFV’s Virtualization: We evaluate
PFV’s effectiveness on actual
implementation of network
stacks, system invariants, and physical state variations of real
devices.
Evaluation of Network Stack Implementation. We used
three outputs from experiments to verify this implementation.
First, outputs in the DNP3 master triggered by responses
from real devices and virtual nodes were always consistent.
Second, network packets showed no errors in common network
analysis tools, such as Wireshark and Zeek runtime network
analyzer [50], [73]. Last, SDN controllers recorded lower-layer
network information of all virtual nodes, e.g., their entries in
ARP caches and corresponding ﬂow entries.
Evaluation of System Invariants. We applied ﬁngerprint-
ing methods proposed for ICSs on both real physical devices
and virtual nodes. As shown in [18], the time to execute
commands in ICS devices, e.g., data acquisition and control
commands, is an effective system invariant to identify device
types and models. Based on the methods presented in [18],
we measured the difference between the timestamp in the
response carrying measurement data and the timestamp in
the corresponding TCP acknowledgment, to accurately reveal
execution times in real devices or virtual nodes.
In Figure 8, we show the estimated execution times based
on responses from three IEDs and from corresponding virtual
nodes. Three IEDs show different characteristics if we consider
the combination of average and variations of execution times.
For example, SE ION 7550 has the largest execution time and
also the biggest variation. The execution times of SEL 751A
and AB MicroLogix 1400 have a close average but different
variations. Outbound packets of virtual nodes, tailored based
on proﬁles of those real devices, follow the communication
patterns, making it challenging for adversaries to distinguish
between real devices and virtual nodes.
In Figure 9, we show the probability density functions
(PDFs) of execution time measured for both data acquisition
and control operations. We can see that PDF patterns vary in
different operation types and devices. In all cases, virtual nodes
can follow the communication patterns of real devices. We
only observe minor differences in the execution time between
them, less than 2 ms, which falls within normal variations
caused by factors like locations and conﬁgurations of devices
and switches.
Evaluation of Physical State Variations. Power grids
use voltages at different locations to represent physical states.
Variation of these values is a critical metric of health condition
of a power grid. In Figure 10, we present the voltage magnitude
measured by the real devices and by the corresponding virtual
nodes, which is normalized to a reference substation (i.e., a
“slack bus”). Based on device proﬁles, virtual nodes can follow
physical state variations of real devices, with less than 1%
differences. Physical states of virtual nodes are not exactly the
same as ones of real devices, which are adjusted by the packet
hooking component according to device proﬁles.
2) Effectiveness of the Disruption Policy: The disruption
policy included in DefRec is to achieve RO1 and RO2, i.e.,
signiﬁcantly delay passive and proactive attacks.
Effectiveness in RO1. We achieve RO1 by randomizing
network requests issued to both real devices and accessible
virtual nodes. Based on the analysis in Section IV, we estimate
the time for adversaries to obtain the identities of real devices
Fig. 8: Comparing the execution time (with 99% conﬁdence
interval) in physical devices and virtual nodes.
10
SEL 751AAB MicroLogix 1400SE ION 75500510Average ExecutionTime (ms)Real DevicesVirtual Nodes(a) SEL 751A
(b) AB MicroLogix 1400
(c) SE ION 7550
Fig. 9: PDF (y-axis) of execution time (x-axis) of data acquisition (at top) and control operations
(at bottom) for three IEDs.
the number of accessible virtual nodes. We make
against
such estimation by assuming that an adversary can passively
monitor up to 200 network packets every second (the most
frequent data acquisition that can be observed in modern power
grids [7]).
Fig. 10: Voltage magnitude measured by
real devices and proﬁled in PFV (with 99%
conﬁdence interval).
throughput can easily trigger alerts in many IDSs, such as
Zeek [50].
In Figure 12, we present the inaccessible-virtual-node to
real-device ratio (shown in y-axis) that is sufﬁcient to delay
adversaries’ acquisition of real measurements for at least 100,
1000, 10,000, and 100,000 years. Even for a small 24-bus
power grid, we need to add a number of inaccessible virtual
nodes equal to 4% of the number of real devices to achieve
RO2. Consequently, when the probabilistic dropping protocol
is used, adversaries must generate a large number of probes
to identify real measurements. If they use the combination of
real and decoy measurements to prepare attacks, the attack-
misleading policy (evaluated in Section VII-A3) can cause
adversaries to design ineffective strategies.
Discussion. Figure 11 and Figure 12 show that DefRec
can delay adversaries for a long latency. In that span of time,
adversaries can face other challenges. For example, operational
environments of power grids can experience changes with
deployment of new generators (see Figure 23 in Appendix A)
to satisfy increasing load demands [27], resulting in changes of
network and physical conﬁgurations. Those changes can make
the previously obtained knowledge of a power grid obsolete,
further increasing adversaries’ difﬁculty in reconnaissance.
3) Effectiveness of
the Attack-Misleading Policy: When
adversaries implement active attacks on FDIAs based on real
data, vulnerable state estimation introduces no alerts.
When adversaries implement FDIAs based on decoy data
(in responses from inaccessible and/or accessible virtual
nodes), misled attacks trigger alerts in state estimation. In
this section, we quantify the effectiveness of decoy data and
conﬁrm the theoretical ﬁndings. Based on the evaluations of
RO1 and RO2, we change the virtual-node to real-device ratio
from 0 to 20%. Also, we change the ratio of compromised
measurements (i.e., the ratio of non-zero entries in vector a;
see Section V-A for its deﬁnition) from 0 to 100%, quantifying
adversaries’ capability in active attacks. As discussed in [42],
more compromised measurements lead to a higher probability
of successful FDIAs, but can become easier to detect.
Deﬁnition 5. RO3 FN: FDIAs prepared based on decoy
data are successful. We consider an FDIA as successful if
compromised measurements determined based on decoy data
introduce no alerts in state estimation, i.e., L2-norm of mea-
surement residual satisﬁes the condition ||z(cid:48)
Deﬁnition 6. RO3 FP: decoy data are not valid, meaning that
the combination of decoy and real data raises alerts in state
estimation without FDIAs. FPs of decoy data do not increase
a − H ˆx(cid:48)
a|| ≤ τ.
As shown in Figure 11, for each power grid, we present
the accessible-virtual-node to real-device ratio (shown in y-
axis) that is sufﬁcient to delay adversaries’ inference of the
identities of real devices for at least 100, 1000, 10,000, and
100,000 years (illustrated in four plots). Even for a small 24-
bus power grid, we can delay passive attacks for 100 years
by adding a number of accessible virtual nodes equal to 15%
of the number of real devices. As the size of a power grid
increases, the ratio decreases exponentially. This is because the
probability that adversaries will make a correct guess about a
real device decreases signiﬁcantly with the size of a power
grid (see Figure 19 in Appendix A).
Fig. 11: Accessible-virtual-node
to real-device ratio sufﬁcient to
delay passive attacks.
Inaccessible-virtual-
Fig. 12:
node to real-device ratio sufﬁ-
cient to delay proactive attacks.