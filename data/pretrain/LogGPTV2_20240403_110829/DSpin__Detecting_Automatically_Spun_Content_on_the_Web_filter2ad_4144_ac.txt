immutables
mutables
Max Synon 3
4th
50.1
31.5
93.5
90.4
3rd
47.5
34.1
92.4
90.0
other
30.5
24.0
94.6
86.0
all
23.2
22.1
80.2
82.3
Max Synon 10
4th
40.9
24.3
97.7
86.0
3rd
31.9
22.9
92.5
83.0
other
25.3
22.3
86.6
79.3
all
21.1
21.0
78.3
77.0
Max Synon 3 Auto-Select
all
4th
54.9
30.3
24.0
36.5
93.4
96.6
91.5
87.6
other
38.0
30.9
93.4
88.7
3rd
40.7
25.1
94.4
89.0
Max Synon 3 Removed Original
4th
60.7
38.8
96.6
93.0
other
35.1
24.2
90.8
87.6
3rd
44.9
26.3
94.5
89.3
all
24.9
20.8
74.9
82.6
Control
control
20.1
20.1
27.8
59.4
TABLE II.
AVERAGE MATCH RATE FOR SHINGLING, PARTS OF SPEECH, AND IMMUTABLES UNDER DIFFERENT SETTINGS FOR TBS.
spun version to another.1 We treat each immutable as unique;
a page has a set of unique immutables instead of a list of
immutables. We differentiate between duplicate immutables by
adding a sufﬁx. With immutables, the Jaccard Coefﬁcient is
deﬁned as:
immutables (A) \ immutables (B)
immutables (A) [ immutables (B)
(4)
Applying the immutable method to the training data set,
Table II shows that using immutables to compute the Jaccard
Coefﬁcient results in ratios well above 90% for most spun
content when using recommended spinning parameters. Under
the most challenging parameters, spinning every word and/or
removing the original mutable words, the immutable method
still produces a similarity score as high as 74.9%. Furthermore,
unlike the previous methods, it scores spun content with a high
value while scoring articles that are different in the control
group with a low coefﬁcient of 27.8%. It thus provides a clear
separation between spun and non-spun content.
The reason this technique does not produce a 100% Jaccard
Coefﬁcient is due to the behavior of spinning in which both
words and phrases can be spun. We use a greedy implementa-
tion that scans the document from beginning to end. For every
word, we see if the word is in the synonym dictionary, and
if it is, we mark it as mutable. If not, we look up the word
combined with zero to ﬁve subsequent words to see if the word
or phrase is present in the synonym dictionary. Due to the
greedy nature of this implementation, we may inadvertently
mark mutable phrases as a series of immutable words. For
example if {a,b,c} is a phrase, and both {a} and {a,b,c} are
in the synonym dictionary, then we mark only {a} as mutable
while marking {b} and {c} as immutable. However, Table II
indicates that this greedy approach still produces very good
results for detecting spun content.
In the control experiment, the synonym dictionary used
to spin content and detect content are the same. In practice,
when examining content on the Web, the synonym dictionaries
may differ between the times of spun content generation
and detection. To gauge the rate of change in the synonym
dictionary over time for TBS, we downloaded two versions
of the synonym dictionary 138 days apart and measured the
overlap between the two. We found that 94% of the words in
the synonym dictionary stayed the same, indicating that the
degree of change in the dictionary is small.
One beneﬁt of using the immutable method is that, in
addition to its accuracy, it also greatly decreases the number of
bytes needed for comparison by reducing the representation of
each article by an order of magnitude. The average ratio of the
number of immutables versus the number of total words in the
1Kolari et al. studied identifying blog spam via examining link based
features [20].
7
1
0.8
0.6
0.4
0.2
F
D
C
0
0
0.2
0.4
Ratio
0.6
0.8
1
Fig. 5. Ratio of original document word count versus immutable word count
original document is 6%. We disregard content that has one
immutable or less, as one immutable would not provide enough
conﬁdence to determine whether two articles are related via
spinning. The reduction in size of our data (Section V-A) is
illustrated in Figure 5. The ﬁgure shows that more that 90%
of pages we evaluate have an 80% reduction in the number
of words that needs to be compared versus the original. More
than 65% of the content has a 90% reduction. We ﬁnd similar
ratios in our GoArticles data set.
C. Veriﬁcation Process
To further test the immutable method, we generated a 600-
article test data set. We select ﬁve articles from ﬁve different
popular article directories, and one directory containing ﬁve
articles randomly selected from Google news. We spin each
article 20 times using the bulk spin option in TBS. We selected
the word replacement frequency of one out of every three
words as suggested by the TBS spinning tutorial [3]. We apply
the immutable method on this data set, and all the spun content
is identiﬁed and correctly matched together with the original
source.
Although the immutable method produces very accurate
classiﬁcation of spun content in our experimental data set, it is
agnostic towards analyzing mutable content. Since the mutable
words can account for 80% or more of the text on a page,
ignoring them completely can cause false positives in cases
where foreign text or symbols will bias two otherwise different
pages to be identiﬁed as spun. To address this concern, we
add another layer of veriﬁcation to the immutable technique,
which we call the mutable veriﬁer. At a high level, the mutable
veriﬁer cross-references the mutable words, words that appear
in the synonym dictionary, among two pages.
The mutable veriﬁer computes the overlap of the mutables
in the following steps:
•
•
•
First, it sums all the words that are common between
the two pages, and adds it to the total overlap count.
Second, it compares the ﬁrst level synonyms. It com-
putes the synonyms of the remaining words from one
page and determines if they match the words of the
other page, and vice versa. Matches are added to the
overlap count.
Third,
it computes the second level synonyms by
taking the synonyms of the synonyms of the remaining
words and comparing them in a similar fashion to step
two.
As with immutables, the score the mutable veriﬁer pro-
duces is the overlap over the union of the mutable words. We
use a overlap threshold of 70%.
The mutable veriﬁer rates spun content in our training data
set as detailed in Table II. It produces a high rate for spun
content with scores between 77% to 93% for spun pages, and
a similarity score of 59.4% for non-spun pages. We do not
employ the mutable veriﬁer on the entire data set because it
has a much higher overhead, as the algorithm compares all the
words in the documents for two levels of synonyms. Instead,
we rely on this to verify content which our immutable method
identiﬁes as spun to ﬁlter out false positives. Since the mutable
veriﬁer only runs in the veriﬁcation phase, it only needs to take
two documents at a time, enabling easy parallelization.
V. METHODOLOGY
Given a means of detecting the similarity of two potentially
spun articles, we implement the immutable method in the
Hadoop framework. We ﬁrst discuss how we acquire two
data sets from domains that are known to have spam. We
then sanitize the data sets sanitized for the purpose or article
comparison, removing foreign text, link spam, invisible text,
and exact duplicates. Then we optimize duplicate detection to
better scale to larger data set sizes.
A. Data Sets
We evaluate the immutable method on two data sets.
The ﬁrst is a set of crawled wiki pages actively targeted by
spammers. The second is a popular article directory, GoArti-
cles.com, which spammers use as both a source of articles for
spinning as well as a target for spamming.
1) Spammed Wikis: The wiki data set is a collection of wiki
article spam that we collected over a month between December
1, 2012 through December 31, 2012. The wikis themselves are
benign, but their permissions leave them open for abuse by
spammers. Figure 1 shows a typical example of spam posted
as a wiki article.
To populate the wiki data set, we use a set of wikis
discovered to have article spam. We identiﬁed this set of wikis
by purchasing a Fiverr job offering to create 15K+ legitimate
backlinks.2 At the end of the job, the seller returned a list of
URLs (not as legitimate as advertised) pointing to wiki article
spam for inspection. From this list, we identiﬁed 797 distinct
wikis apparently targeted by a wide range of spammers.
On an hourly basis, we then crawled the recent posts on
each of the wikis, the majority of which are spam articles.
Because the wikis all use the MediaWiki [24] platform, we
use the following URL:
http://mediawikiexample/&Special:
RecentChanges&limit=500&hideminor=0
to fetch links for the 500 most-recent changes to the wiki. Note
that we ignore any recent changes that do not occur within
the hour to avoid fetching content that overlaps with previous
crawls. We crawl 55K pages on average per hour, and in total
we crawl 37M pages for December 2012.
2) GoArticles: The GoArticles data set is a collection of
articles from GoArticles.com, a large article directory with
over 4.6M articles. An article directory is a Web site in which
users post articles on various topics, e.g., business, health and
law. Some high quality article directories even pay authors
for their contributions. In general, article directories forbid
duplicate and spun content. The goal of the article directory is
to attract readers and to make money from advertising. These
directories enable users to submit unique articles and embed
links to other relevant Web sites. Authors may use these pages
to generate backlinks to their own personal sites.
We select this article directory for several reasons. First,
GoArticles.com is one of the top search results returned by
Google for the query “article directory”. Furthermore, we
observe that the site is targeted by members of the black hat
SEO forums [1], who are lured by the fact that the site allows
users to build backlinks as “dofollow” that can affect search
engine page rankings. Often, sites that allow users to create
backlinks in the form of HTML anchors can specify that all
links created by users should be labeled “nofollow”, indicating
to search engines that they should disregard the link when
ranking the linked page. The use of “nofollow” therefore acts
as a deterrent to spamming a site with SEO backlinks. In the
SEO vernacular, links not labeled as “nofollow” are considered
“dofollow” and, as such, sites that allow them are highly prized
by article spammers.
We populate the GoArticles data set by ﬁrst enumerating
1M unique URLs pointing to articles on the site, and then
crawling each article pointed to by the URL. To enumerate
URLs, we take advantage of the URL format followed by the
site, shown below, in which title refers to the title of the article
and id refers to a seven-digit unique identiﬁer for the article:
http://goarticles.com///
We found that the site ignores the title ﬁeld and returns
the article that matches the id. As a result, crawlers can fetch
articles between id ranges while using random strings for the
title. In addition, the site assigns ids to articles in chronological
order. Thus, we can fetch all articles for a time period if we