50
60
Stream Sorted By Optimistic Resource Index
(c) Video streams, Degree Cap 10
x
e
d
n
I
e
c
r
u
o
s
e
R
x
e
d
n
I
e
c
r
u
o
s
e
R
5
4
3
2
1
0
8
7
6
5
4
3
2
1
0
Optimistic
Distribution
Pessimistic
0
10
20
30
40
50
60
Stream Sorted By Optimistic Resource Index
(b) Video streams, Degree Cap 6
Optimistic
Distribution
Pessimistic
0
10
20
30
40
50
60
Stream Sorted By Optimistic Resource Index
(d) Video streams, Degree Cap 20
Figure 6: Average Resource Index for each stream.
ple policies, such as capping the degree bound to a static amount
to make sure that no person contributes more than what is consid-
ered to be “reasonable.” There could be more complex policies to
allow users to individually determine how much they are willing to
contribute in return for some level of performance [6].
While there are resources in the common scenarios, in 10% of
the cases there were not enough resources (or close to not enough)
to allow all participants to receive at the full encoding rate. In such
scenarios, there are three generic classes of alternatives to consider.
The ﬁrst alternative is to enforce admission control and reject in-
coming free-riders when the Resource Index dips below one. A
second alternative is to dynamically adapt the streaming bit-rate,
either in the form of scalable coding [15], MDC [11], or multiple
encoding rates [7]. This has the advantage that the system can still
be fully supported using an application end-point architecture with
a reduction in the perceived quality of the stream. Lastly, a third al-
ternative is to add resources into the system. These resources can be
statically allocated from infrastructure services such as content de-
livery networks (CDNs) with the advantage that the resources only
need to complement the already existing resources provided by the
application end-points. Another solution is to allocate resources in
a more on-demand nature using a dynamic pool of resources, for
example, using a waypoint architecture [7].
3.4 Impact of NATs and Firewalls
One factor that can negatively impact our results is the presence
of participating hosts that have connectivity restrictions behind Net-
work Address Translators (NATs) and ﬁrewalls. Such hosts cannot
communicate with other connectivity restricted hosts and thus re-
duce the number of usable pair-wise overlay links. Recently, several
x
e
d
n
I
e
c
r
u
o
s
e
R
 2.5
 2
 1.5
 1
 0.5
 0
 0
0% NAT
20% NAT
30% NAT
40% NAT
50% NAT
 10
 50
Stream Sorted By Optimistic Resource Index
 20
 30
 40
 60
Figure 7: Resource Index for video streams when considering
NATs.
solutions have been developed to allow hosts behind NATs and ﬁre-
walls to participate in overlay multicast [10]. Such solutions enable
all hosts except for hosts behind symmetric NATs [23] and certain
ﬁrewalls to have universal connectivity. For the purpose of this pa-
per, we assume that these solutions are implemented. Thus, our con-
cern is with symmetric NATs and ﬁrewalls that still are connectivity
restricted. Note that the connectivity semantics of a symmetric NAT
is that it cannot communicate with other symmetric NATs. Fire-
walls, on the other hand, can have arbitrary connectivity semantics.
For this paper, we assume that ﬁrewalls have the most restrictive se-
mantics – the same as symmetric NATs in they cannot communicate
with other symmetric NATs or ﬁrewalls. Thus, links between two
Single Tree
Single Tree + Residual Bandwidth
3
2.5
2
1.5
1
0.5
x
e
d
n
I
e
c
r
u
o
s
e
R
0
0
10
20
30
Stream
40
50
60
Figure 8: Resource Index for multiple trees.
different symmetric NATs or ﬁrewalls cannot be used in the overlay.
To simplify the discussion, we will refer to both symmetric NATs
and ﬁrewalls that have the same connectivity semantics as symmet-
ric NATs for the rest of this section.
To understand how our results change in the presence of sym-
metric NATs, we consider the Resource Index as a function of the
percentage of symmetric NATs in the system. We refer the readers
to [10] for the details on how to implement the optimizations and
compute the Resource Index with connectivity restrictions.
Figure 7 depicts the Resource Index for the same video streams
as those depicted in Figure 6(b) with a degree cap of 6 and a distribution-
based estimate of unknowns. Each line represents a scenario where
there are 0% to 50% of restricted hosts (symmetric NATs) in the
system. There is little or no difference between the 0%, 20% and
30% cases (the curves overlap). We start to see a drop in the Re-
source Index when more than 40-50% of the hosts are connectivity
restricted. However, the drop is not that signiﬁcant as the Resource
Index is still above 1 for 67% of the streams even when half of the
hosts are connectivity restricted. This is similar to when there are
no connectivity restricted hosts in the system (Figure 6(b)). Further-
more, from operational experience with End System Multicast [10],
the percentage of symmetric NATs is usually much lower (10%-
30%). In such regimes, the Resource Index is the same as when
there are no symmetric NATs given that all NAT-based optimiza-
tions are implemented in the protocol.
To summarize, for the large-scale streams in our traces, the
presence of 40% or more connectivity restricted hosts in the sys-
tem reduces the Resource Index. However, such reductions are not
signiﬁcant enough to make the Resource Index drop below one un-
less it was already below one without connectivity restricted hosts
in the system. In addition, for realistic percentages of NATs (10%-
30%), the Resource Index is unchanged compared to when there are
no NATs in the system.
3.5 Multiple-Tree Protocols
In the previous section, we analyzed the amount of resources
for single-tree protocols. More recently, multiple-tree protocols [4,
18, 13] have been proposed to increase the overall resilience of the
system. Such protocols are tightly coupled with specialized video
encodings, such as multiple description coding (MDC). The video
stream is encoded into k independent descriptions (or sub-streams)
and distributed across k independent trees.
The implication of multiple trees and MDC on resources is that
the amount of resources in the system may increase as the residual
bandwidth that was previously unused in the single-tree protocol
may now be used. For example, if a host has an outgoing bandwidth
of 300 kbps, and the stream is encoded at 250 kbps for a single tree,
then the host has a residual bandwidth of 50 kbps that is unused.
On the other hand, if the stream is encoded using MDC into many
descriptions each at 50 kbps, then the host can contribute all of its
outgoing bandwidth to the system to transmit up to 6 descriptions.
Overall, the use of MDC and multiple trees should always re-
sult in an increase in the supply of resources compared to a single
tree. To quantify the increase, we modify the Resource Index com-
putation as follows. We allow fractional supply (where the frac-
tion corresponds to the residual bandwidth) to be used. For exam-
ple, the supply for the host in the previous example is computed as
300=250 = 1:2. We assume the demand remains the same as in the
single-tree case – this is simplistic in that we are assuming no over-
head and no redundancy in the encoding. A host needs to collect
at least 5 descriptions in this example (5x50 kb = 250 kb), to
have good quality video. The intuition behind this is that a stream
that is originally encoded at 250 kbps, say a tennis match, is jerky
and not watch-able at 50 kbps, or even at 200 kbps. If it were per-
fectly watch-able, then the stream would have already been encoded
at the lower rate for the single-tree protocol.
Figure 8 depicts the Resource Index for the multiple-tree pro-
tocol for the same video streams presented earlier in Figure 6(b).
Also depicted is the Resource Index for the single-tree protocol.
The conﬁguration shown here is for degree cap 6 (or the equivalent
in kbps) and the distribution-based assignment for unknowns. To
have sufﬁcient resources, a Resource Index higher than 1 is needed
for both the single-tree and multiple-tree protocol. We ﬁnd that for
the streams that had sufﬁcient resources using a single-tree protocol,
using a multiple-tree protocol can increase the bandwidth resources
up to 20-25%. More interestingly, for the remaining streams that
did not have sufﬁcient resources using a single-tree protocol, the
Resource Index increases from below 1 to above 1 for all but one
stream when using a multiple-tree protocol. The value of the Re-
source Index determines how much encoding overhead the system
can support. For example, a Resource Index of 1.1 means that 10%
of overhead may be added.
To summarize, using multiple trees and MDC can increase the
amount of resources in the system. With a degree cap of 6, 1/3 of
the streams had a Resource Index of below 1 using a single-tree
protocol. Using a multiple tree protocol, in all but one case, the
Resource Index is above 1. Thus, multiple-tree protocols increase
the feasibility of overlay multicast especially for those streams that
do not have abundant resources.
3.6 Resources Summary
Our results indicate promise for application end-point architec-
tures. Using a single-tree protocol and a single encoding rate, all
audio streams have abundant resources and most video streams have
enough inherent resources. With realistic percentages of NATs and
ﬁrewalls in the system, the resource characteristics is the same as if
there were no NATs and ﬁrewalls. Lastly, in resource constrained
environments, using multiple-tree protocols can increase the supply
of resources in the system and improve the situation.
4.
IS THERE ANY STABILITY?
In this section, we look at feasibility of maintaining a stable and
connected tree in the presence of group dynamics. In addition, we
evaluate mechanisms that can be used to increase the stability of the
overlay.
4.1 Extreme Group Dynamics
Figure 9 depicts the session duration characteristics for the 660
large-scale streams. The x-axis is the session duration in minutes.
F
D
C
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0.01
5th Percentile
25th Percentile
50th Percentile
95th Percentile
0.1
1
10
100
1000
Session Duration (minutes)
Figure 9: Incarnation session duration in minutes.
The y-axis is the cumulative distribution of the number of streams.
The ﬁrst curve on the left depicts the cumulative distribution of the
observed 5th percentile session duration in all 660 streams. For
example, 5% of incarnations in 30% of the streams had durations
of shorter than 1 second. The next 3 curves are for the 25th, 50th
and 95th percentile. Note that the same value on the y-axis does not
necessarily correspond to the same stream on all the curves.
Based on this ﬁgure, we make two observations. First, there
is a signiﬁcant number of very short sessions. Looking at the 25th
percentile curve, we ﬁnd that for most streams, 25% of sessions are
under 2 minutes. Furthermore, the most disastrous is that in the 50th
percentile curve, 20% of the streams have extremely dynamic group
membership with half of the sessions shorter than 5 minutes. With
such short session durations, it seems very unlikely that there could
be any stability.
Our second observation is that there is a heavy tail, where a
small number of incarnations have very long sessions. The 95th
percentile curve in Figure 9 shows that for most streams, the 95th
percentile session duration is longer than 30 minutes. Perhaps the
tail can help add some stability to the tree. Note that these observa-
tions are consistent with the session duration analysis of the largest
event in Section 2.
4.2 Stability Metrics
When an incarnation leaves, it causes all of its descendants to
become disconnected from the overlay and stop receiving data. Dis-
connects are perceived as glitches in the stream, resulting in poor
performance. Disconnected descendants will need to ﬁnd new par-
ents and reconnect to continue receiving the stream. Therefore, a
desirable tree is one in which when an incarnation leaves, no one
is affected. Incarnations that will stay for a long time should be at
the top of the tree, and incarnations that will stay for short durations
should be leaf nodes at the bottom of the tree. To capture stability
of the overlay we look at two metrics:
(cid:15)Mean interval between ancestor change for each incarnation.
This metric captures the typical performance of each incarnation.
An ancestor change is caused by an ancestor leaving the group, typ-
ically resulting in a glitch in the stream. Frequent glitches may be
annoying. Therefore, the longer the interval, the better the perfor-
mance. If a host sees only one ancestor change during its session,
the time between ancestor change is computed as its session dura-
tion.
If a host sees no ancestor changes at all, the time between
ancestor change is inﬁnite.
(cid:15)Number of descendants of a departing incarnation. This metric
captures overall stability of the system. If many hosts are affected
by one host leaving, then the overall stability of the system is poor.
However, assuming a balanced tree, most hosts will be leaf nodes
and will not have children. Therefore, we hope to see that a large
percentage of hosts will not have children when they leave.
4.3 Overlay Protocol
We simulate the effect of group dynamics on the overlay proto-
col using a trace-driven event-based simulator. The simulator takes
the group dynamics trace from the real event and the degree assign-
ments based on the techniques in the previous section, and simulates
the overlay tree at each instant in time. Hosts in the simulator run
a fully distributed self-organizing protocol to build a single con-
nected tree rooted at the source. The protocol is a simpliﬁed version
of the one used in the End System Multicast project [7]. Note that
we do not simulate any network dynamics or adaptation to network
dynamics. The following protocol functions of the simpliﬁed proto-
col are also common across many of the existing overlay multicast
protocols.
Host Join: When a host joins, it contacts the source to get a random
list of  current group members. In our simulations,  is set to
100.
It then picks one of these members as its parent using the
parent selection algorithm described below.
Host Leave: When a host leaves, all of its descendants are dis-
connected from the overlay tree. For each of its descendants, this
is counted as an ancestor change. Descendants then connect back
to the tree by independently ﬁnding a new parent using the parent
selection algorithm. Note that we prioritize reconnections by al-
lowing descendants that contribute resources to connect back ﬁrst,
before free-riders. This prevents free-riders from saturating the tree
before all descendants are able to reconnect. This is implemented
by having hosts that contribute fewer resources wait longer before
trying to reconnect.
Parent Selection: When a host needs to ﬁnd a parent, it selects a
set of  random hosts that are currently in the system, probes them
to see if they are currently connected to the tree and have enough re-
sources to support a new incoming child, and then ranks them based
on the parent selection criteria described in the next section. In our
simulations,  is set to 100. We do not simulate the mechanisms
for learning about hosts currently participating in the system, but
assume that such mechanisms provide random knowledge. In a real
implementation, Gossip-based mechanisms [22] may be used.
4.4 Parent Selection Algorithms