sensitive data and code against malicious code that manage to
run in a same process context.
B. In-process Private Memory: Requirements and Intuitions
A direct solution to in-process abuse is to enable private
memory in individual processes and allow application devel-
opers to protect their sensitive code and data against malicious
code that manages to enter the same processes. We identify
four basic requirements for such a solution to be useful,
practical, and secure:
R1 - Flexible granularity: A solution needs to recognize
accessing entities at various granularities, from compilation
modules, to functions, and even to sub-routines. This is neces-
sary for developers to deﬁne the minimum entities that should
be permitted to access the private memory (i.e., minimizing
the exposure of protected memory). It also narrows the scope
of code that developers need to change when adopting the
solution.
R2 - Easy adoption and deployment: A solution must cover
not only newly developed software but also legacy ones. It
needs to be easily adoptable by developers and practically
deployable in real-world. This requirement boils down to
simple APIs, minimal required code changes, and realistic
deployment restrictions.
5858
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:20 UTC from IEEE Xplore.  Restrictions apply. 
R3 - Robustness against attacks: Accessing entities, even
when minimally deﬁned, may still contain vulnerable or faulty
code, which can lead to data leakage from private memory
or code injection into the accessing entities. A solution must
consider and prevent such vulnerabilities or attacks.
R4 - Low overhead: Memory content that need protection
may be frequently used throughout a program’s execution.
Therefore, a solution providing in-process private memory
must not incur high overhead. It should be independent from,
and more efﬁcient than, the conventional paging-based mem-
ory protection.
C. Existing Solutions
Several existing security methods and mechanisms can be
used to mitigate in-process memory abuse. However, they fail
to meet some or all of the above requirements, and therefore,
cannot fully or effectively prevent in-process memory abuse.
Employing privilege separation [8]–[10], developers can
protect the sensitive memory content by executing code of
different levels of privileges in isolated processes. If OS is
not trusted, stronger isolation can be achieved with hardware
support, such as virtualization [11] and SGX [12]. However,
needless to say virtual machines or enclaves, processes are
often too coarse and too restrictive for protecting sensitive
code and data that are tightly integrated and frequently used
in applications. Software fault isolation (SFI) [13] and sim-
ilar techniques can conﬁne untrusted code inside a memory
region and prevent it from adversely impacting the rest of
an application. However, it requires potentially offensive code
to be instrumented and veriﬁed during compilation, which is
unrealistic for stealthily injected malicious code that performs
in-process abuse. Some recent works [3] have enabled thread-
level memory isolation. Although taking an important step
towards mitigating in-process memory abuse, the approach still
relies on the scheduling units (e.g., threads and processes) for
memory isolation, which makes the solutions coarse-grained,
cumbersome to adopt, and inefﬁcient. More detailed discussion
about the related works is in § VI.
Motivated by the need for in-process private memory that
meets R1-R4, we design and build the shred system.
III. SYSTEM DESIGN
A. Overview
We introduce a new OS primitive, namely shred, for se-
curely executing certain (sensitive) pieces of application code
against
in-process attacks. Shreds are thread segments of
various sizes (Figure 1), which are deﬁned by application
developers. Code running inside a shred can store and access
secrets in an assigned memory pool (s-pool), which is inac-
cessible to the rest of the thread or other threads in the same
process, despite that they all share the same virtual memory
space. By running sensitive code pieces in individual shreds
and storing secrets in associated s-pools, developers prevent
malicious or erroneous code running in the same thread or
process from retrieving the secrets, and in turn, defend against
in-process abuse attacks.
Shreds’ security is guaranteed by three properties:
• P1 - Exclusive access to s-pool: An s-pool is solely ac-
cessible to its associated shreds. Other shreds or threads,
even when running concurrently with the associated
shreds, cannot access the s-pool.
• P2 - Non-leaky entry and exit: Data loaded into s-pools
cannot have copies elsewhere in memory or be exported
without sanitization.
• P3 - Untampered execution: Shred execution cannot be
altered or diverted outside of the shred.
P 1 enables the very protection of a shred’s sensitive mem-
ory against other unrelated shreds or out-shred code that run
in the same address space. P 2 avoids secret
leaks when
data are being loaded into or exported out of s-pools (e.g.,
ensuring that no secret is buffered in unprotected memory as a
result of standard I/O). P 3 prevents in-process malicious code
from manipulating shreds’ control ﬂow. Such manipulation can
cause, for instance, ROP that forces a shred to execute out-
shred code and expose its s-pool.
We design and implement a system that enables shreds and
the aforementioned properties for Linux/ARM platforms. Our
system consists of a compilation toolchain (S-compiler) and a
dynamic loadable kernel extension (S-driver). Developers can
adopt shreds in their programs using a set of simple APIs: two
APIs for entering and exiting a shred; two APIs for allocating
and freeing memory in an s-pool. S-compiler is needed to build
programs that contain shreds. S-compiler performs the code
analysis and instrumentation that are necessary to ensure P 2
and P 3. During runtime, S-driver handles shred creations and
terminations. It manages and protects s-pools in accordance
to P 1. Our design makes a novel use of memory domains, an
under-exploited feature in ARM CPUs, to efﬁciently protect
s-pools and shred executions.
The rest of the section explains the detailed designs of shred
APIs, S-compiler, and S-driver. It then examines the designs
against the requirements (R1-R4).
B. Shred APIs and Usages
Application developers use shreds and s-pools via the fol-
lowing intuitive APIs:
err t shred enter(int pool desc);
err t shred exit();
void * spool alloc(size t size);
void spool free(void *ptr);
These APIs internally make requests to S-driver via ioctl
for managing shreds and s-pools. To explain the API usage,
we use the lightweight open-source web server, Lighttpd, as
an example, where we employ shreds to protect the HTTP
authentication password in Lighttpd’s virtual memory. By
wrapping the code that receives and checks the password
in two shreds and storing the password in an s-pool, the
5959
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:20 UTC from IEEE Xplore.  Restrictions apply. 
modiﬁed Lighttpd prevents out-shred code, including third-
party and injected code, from accessing the password in
memory. Listings 1-3 show the code snippets that contain the
modiﬁcations (lines marked with “+”).
A successful call to shred enter starts a shred execution
on the current thread. It also causes a switch to a secure
execution stack allocated in s-pool, which prevents potential
secret leaks via local variables after the shred exits. The thread
then is given exclusive access to the associated s-pool, which
is speciﬁed by the developer using the pool desc parameter
of shred enter. Our design allows developers to associate
an s-pool with multiple shreds by using the same descriptor
at shred creations (e.g., an encryption shred and a decryption
shred may need to share the same s-pool storing keys). The
two shreds in Lighttpd, created on Line 9 in Listing 1 and
Line 3 in Listing 3, share the same s-pool. However, as
a security restriction, shreds in different compilation units
cannot share s-pools. Therefore, even if shreds from different
origins happen to use the same descriptor value, their s-pools
are kept separate.
The shred exit API stops the calling shred, revokes the
current thread’s access to the s-pool, and recovers the original
execution stack. It is called immediately after a self-contained
operation or computation on the s-pool ﬁnishes, as shown
on Line 22 in Listing 1 and Line 8 in Listing 3. The shred
enter and exit APIs must be used in pairs without nesting. To
facilitate veriﬁcation, an enter-exit pair must be called inside a
same function. In principle, a shred should contain a minimum
body of code that corresponds to a single undividable task
requiring access to an s-pool. In the example, since Lighttpd
separates the parsing and processing of HTTP requests, we
naturally used two small shreds, rather than one big shred, to
respectively read the password from network and checks if the
hash value of the password matches with the local hash.
To allocate memory from its associated s-pool, in-shred
code calls spool alloc, in a same way as using libc’s mal-
loc. Similar to regular heap-backed memory regions, buffers
allocated in s-pools are persistent and do not change as code
execution enters or exits shreds. They are erased and reclaimed
by S-driver when in-shred code calls spool free. In the
Lighttpd example, an s-pool named AUTH PASSWD POOL is
used for storing the password that the server receives via
HTTP authentication requests. The password enters the s-pool
immediately after being read from the network stream and
stays there till being erased at the end of its lifecycle.
connection *con) {
/* current parsing offset */
/* inside the request parsing loop */
char *cur;
char auth_str[] = "Authorization";
int auth_str_len = strlen(auth_str);
if (strncmp(cur, auth_str, auth_str_len)==0){
1 int http_request_parse(server *srv,
2
3 ...
4
5
6 +
7 +
8 +
9 +
10 +
11 +
12 +
13 +
14 +
shred_enter(AUTH_PASSWD_POOL);
/* object holding passwd in spool */
data_string *ds = s_ds_init();
int pw_len = get_passwd_length(cur);
cur += auth_str_len + 1;
buffer_copy_string_len(ds->key, auth_str,
auth_str_len);
buffer_copy_string_len(ds->value, cur, pw_len)
;
/* add ds to header pointer array */
array_insert_unique(parsed_headers, ds);
/* only related shreds can deref ds */
/* wipe out passwd from input stream */
memset(cur, 0, pw_len);
cur += pw_len;
shred_exit();
15 +
16 +
17 +
18 +
19 +
20 +
21 +
22 +
23 +
24 ...
25 }
}
Listing 1: lighttpd/src/request.c – The HTTP request
parser specially handles the AUTH request inside a shred:
it allocates a data string object in the s-pool (Line 11),
copies the input password from the network stream to the
object (Line 12-15), saves the object pointer to the array of
parsed headers (Line 17), and ﬁnally erases the password
from the input buffer before exiting the shred.
data_string *ds;
ds = spool_alloc(sizeof(*ds));
ds->key = spool_alloc(sizeof(buffer));
ds->value = spool_alloc(sizeof(buffer));
return ds;
1 /* called inside a shred */
2 data_string *s_ds_init(void) {
3
4 +
5 +
6 +
7 ...
8
9 }
10
11 /* called inside a shred */
12 void s_ds_free(data_string *ds) {
13 ...
14 +
15 +
16 +
17
18 }
spool_free(ds->key);
spool_free(ds->value);
spool_free(ds);
return;
Listing 2: lighttpd/src/data string.c – We added s-
pool support to the data string type in Lighttpd, which
allows the HTTP parser to save the AUTH password, among
other things, in s-pools and erase them when needed.
1 ...
2 /* inside HTTP auth module */
3 +
4
5
6
7 +
8 +
9 ...
shred_enter(AUTH_PASSWD_POOL);
/* ds points passwd obj in spool */
http_authorization = ds->value->ptr;
... // hash passwd and compare with local copy
s_ds_free(ds);
shred_exit();
Listing 3: lighttpd/src/mod auth.c – When the
authentication module receives the parsed headers, it enters
a shred, associated to the same s-pool as the parser shred.
It retrieves the password by dereferencing ds, as if the
password resided in a regular memory region (Line 5)
Code included in a shred need to follow two rules. First,
it cannot copy data from an s-pool to unprotected memory
6060
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:20 UTC from IEEE Xplore.  Restrictions apply. 
without applying any transformation (e.g., encryption). This
rule prevents unexpected secret leaks from s-pools and is
needed for achieving P 2. Second, in-shred code can only
use libraries built using S-compiler. This rule allows all code
inside shreds to be checked and instrumented for P 3. Although
seemingly restrictive, the second rule is not impractical: the
commonly used libraries, such as libc and libm, can be pre-
compiled and installed along with S-driver as part of system
deployment; the uncommon libraries required in shreds for
processing sensitive data are usually in-house developed or
open source, and therefore, can be recompiled by developers.
Both rules are enforced by S-compiler.
C. S-compiler: automatic toolchain for shred veriﬁcation and
instrumentation
Developers use S-compiler to build programs that use
shreds. In addition to regular compilation, S-compiler per-
forms a series of analysis and instrumentation to verify pro-
grams’ use of shreds and prepare the executables so that S-
driver can enforce the security properties (P 1-P 2) during run-