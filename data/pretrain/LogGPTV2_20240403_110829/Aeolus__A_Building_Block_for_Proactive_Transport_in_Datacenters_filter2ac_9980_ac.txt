### SIGCOMM '20, August 10–14, 2020, Virtual Event, NY, USA
**S. Hu et al.**

### 3.3 Loss Recovery in Aeolus

In the Aeolus system, scheduled packets are less likely to be dropped due to their protected status. However, unscheduled packets may be dropped under the selective dropping mechanism. Therefore, a fast and efficient loss recovery for unscheduled packets is essential. Given that scheduled packets are safeguarded, our approach is to retransmit lost unscheduled packets using subsequent scheduled packets, whose delivery is guaranteed by the proactive transport property. Consequently, loss recovery in Aeolus primarily reduces to loss detection.

#### Loss Detection

Aeolus enables per-packet ACKs at the receiver to quickly notify the sender of the arrival of unscheduled packets. We use selective ACKs (SACK) instead of cumulative ACKs for loss detection in the middle, and leverage a simple probing mechanism to detect tail losses of unscheduled packets. Specifically, the Aeolus sender transmits a probe packet immediately after the last unscheduled packet. This probe packet carries the sequence number of the last unscheduled packet and is of minimal Ethernet packet size, e.g., 64 bytes. When the receiver receives the probe packet, it returns an ACK carrying the sequence number of the probe packet. Once the sender receives this probe ACK, it can immediately infer all the losses of unscheduled packets, including the last one. It is important to note that to ensure the delivery of the probe packet and all ACKs, they are treated as scheduled in the network.

#### Retransmission

As previously introduced, Aeolus retransmits lost unscheduled packets using subsequent scheduled packets. Upon receiving credits, the sender can either retransmit old packets or transmit new packets. Specifically, the sender has three types of packets to transmit: sent but unacknowledged unscheduled packets, loss-detected unscheduled packets, and unsent scheduled packets. These are prioritized in the following order: loss-detected unscheduled packets, unsent scheduled packets, and sent but unacknowledged unscheduled packets. The highest priority is given to loss-detected unscheduled packets to fill the gap as soon as possible, minimizing the memory footprint of the resequencing buffer. Unscheduled packets that have been sent but not acknowledged are prioritized lower than unsent scheduled packets to avoid redundant retransmissions.

### 3.4 Why This Works

The key to Aeolus's effectiveness is its simple yet effective selective dropping mechanism, which not only delivers good performance but also significantly simplifies both rate control and loss recovery designs. With selective dropping, new flows can start at line-rate to fully utilize spare bandwidth without affecting scheduled packets. For pre-credit unscheduled packets, the combination of line-rate start and selective dropping maximizes their potential benefits (e.g., utilizing spare bandwidth) while minimizing their side effects (e.g., impacting scheduled packets). Furthermore, by selectively dropping only unscheduled packets, loss recovery becomes relatively simple because packet losses only occur in the pre-credit stage (or first batch), and the deliveries of subsequent scheduled packets are guaranteed. We only need to locate the losses in the first batch and efficiently retransmit them once using scheduled packets. Unlike TCP, which has many complex loss recovery mechanisms for different scenarios, Aeolus's loss recovery is extremely simple yet more efficient.

### 4 Implementation

#### 4.1 Switch Implementation

The Aeolus switch selectively drops unscheduled packets while preserving scheduled packets in a single switch queue. We propose two implementation options to achieve this:

**WRED (Weighted Random Early Detection):**
WRED is an extension of RED (Random Early Detection) where a single queue has several different sets of queue dropping/marking thresholds. WRED typically supports three packet colors: red, yellow, and green, each with its own dropping thresholds in a switch queue. WRED is widely supported by commodity switching chips.

To implement selective dropping using WRED, we mark scheduled and unscheduled packets with different DSCP values at the end host. At the switch, we configure the access control list (ACL) table to set the arriving packet's color based on its DSCP field. Thus, scheduled and unscheduled packets can be marked with different colors in the switch pipeline. For unscheduled packets, we set both the high and low dropping thresholds to the desired selective dropping threshold. For scheduled packets, we set the high/low dropping threshold to a very large value (e.g., total buffer size) so that scheduled packets will not be dropped by WRED.

**RED/ECN (Explicit Congestion Notification):**
While WRED is widely supported by switching chips, it may not be exposed by all switch operating systems. Some switch OSes (e.g., Arista EOS) provide a simple RED/ECN configuration interface where a switch queue has a single set of dropping/marking thresholds.

To realize selective dropping using only the RED/ECN feature, we reinterpret the ECN mechanism. At the sender, we set the ECN fields of unscheduled packets and scheduled packets to Non-ECT and ECT(0), respectively. At the switch, we enable ECN marking and configure both the high and low RED thresholds to the selective dropping threshold. In this way, any unscheduled packets exceeding this threshold will be selectively dropped by the switch. At the receiver, we simply ignore the ECN marks of the arriving packets.

#### 4.2 Host Implementation

To evaluate the benefits of Aeolus in augmenting proactive solutions, we implemented a prototype of Aeolus with two recent proactive transports, ExpressPass [14] and Homa [29]. Our implementation is based on DPDK 18.05 [2], which allows the network stack to bypass the kernel and communicate directly with the NIC.

**Figure 7: Aeolus Software Implementation Architecture on Top of Proactive Solutions**

- **Packet Sending Pipeline:**
  As shown in Figure 7(a), the application starts data transmission by calling the `send()` function. The flow classification module tracks the per-flow state using a table. Each flow is identified using the 5-tuple (source/destination IPs, source/destination ports, and protocol ID) and initially classified as a pre-credit flow. The flow enters the credit-induced state once it finishes its first-RTT packet transmission. Pre-credit and credit-induced flows are processed separately by the Aeolus control logic and the proactive control logic.
  
  The Aeolus control logic checks the sender buffers of its belonging flows iteratively in a round-robin fashion, reads the data, segments it into unscheduled packets, constructs request, probe, and ACK packets, and forwards these to the next-stage processing module. The proactive control logic follows its original processing logic without modification.

- **Packet Receiving Pipeline:**
  We use the DPDK poll mode driver to periodically poll the RX Ring buffer of the NIC. Once a batch of packets is received, the packet dispatch module distributes them to the corresponding control logic. The Aeolus control logic performs three main operations upon receiving a packet:
  1. Notify the flow classification module to change the state of a flow if an ACK for the flow is received for the first time.
  2. Notify the proactive control logic of the arrival of a new flow when a request is received.
  3. Perform loss detection based on received ACKs and notify the proactive control logic to perform loss retransmission with scheduled packets.

### 5 Evaluation

We evaluated Aeolus using a combination of large-scale simulations and testbed experiments. The key findings are:

- **ExpressPass [14]:** Aeolus improves the normal-case FCT, with the mean FCT reduced by up to 56%.
- **Homa [29]:** Aeolus improves the tail FCT, with the 99th percentile FCT reduced by up to 1400×.
- **NDP [18]:** Aeolus preserves the superior performance of NDP without requiring switch modifications.

#### 5.1 Evaluation Setup

- **Baseline Proactive Transports:** We chose three recent proactive transport solutions: ExpressPass [14], Homa [29], and NDP [18], to represent different design choices of proactive transport. ExpressPass forbids data transmissions in the first RTT, while Homa and NDP send unscheduled packets in the first RTT.
- **Testbed:** We built a small testbed consisting of 8 servers connected to a Mellanox SN2000 switch using 10Gbps links. The switch supports ECN and strict priority queueing with 8 queues. Each server is equipped with an Intel 82599EB 10GbE NIC that supports DPDK. We enabled RED/ECN at the switch to implement selective dropping. The base RTT is around 14 μs.
- **Simulator:** For all three schemes, we used the simulators provided by the authors with their recommended configuration options. For ExpressPass, we implemented Aeolus on top of ExpressPass’s open-source code [3] with ns-2 simulator. For Homa, we implemented Aeolus on top of Homa’s open-source code [6] with OMNeT++ simulator. Homa assumes infinite switch buffer in its simulations and lacks a loss recovery mechanism, so we extended Homa’s simulator to include a timeout-based loss recovery.

**Figure 8: Message Completion Times (MCT) of 7-to-1 Incast**
- **(a) MCT with 30KB message size**
- **(b) Mean MCT with different message sizes**

**Table 2: Flow Size Distributions of Realistic Workloads**
- **Web Server [31]:** 81% 0-100KB, 19% 100KB-1MB, 0% >1MB, Average flow size: 64KB
- **Cache Follower [31]:** 53% 0-100KB, 18% 100KB-1MB, 29% >1MB, Average flow size: 701KB
- **Web Data Search [9]:** 83% 0-100KB, 8% 100KB-1MB, 9% >1MB, Average flow size: 7.41MB
- **Data Mining [17]:** 52% 0-100KB, 18% 100KB-1MB, 20% >1MB, Average flow size: 1.6MB

This optimized version of the text aims to improve clarity, coherence, and professionalism, making it easier to read and understand.