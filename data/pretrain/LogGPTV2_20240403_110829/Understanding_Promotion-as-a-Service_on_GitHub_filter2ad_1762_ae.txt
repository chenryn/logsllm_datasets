### Promised to Pass Our Request on to the Appropriate Team for Consideration

#### Limitations
We developed our detection method by analyzing behavior patterns and then applied this method to perform large-scale detection. However, if adversaries were aware of our detection algorithms in advance, they could adjust their behavior patterns to evade detection. For example, they might engage in more common activities such as committing, pushing, and pulling, similar to normal users. These actions would increase the cost of maintaining these promotion accounts. An alternative evasion method is to reduce the frequency of starring and forking, but this would also increase the cost for promotion service providers and significantly decrease their profits. Another evasion tactic may involve forking or starring other popular repositories during their promotion service. This can confuse our detection due to the addition of more actions that cannot be accurately identified. In future work, we will investigate possible evasion methods and improve our detection by making it more adaptive.

#### Recommendations to GitHub
We recommend that GitHub take action to regulate existing promotion services. One possible action is to send emails with confirmed information to suspected accounts and request an active response. The inquiries should be based on the actual activities that have occurred on the GitHub repositories, and the responses should be relevant to the inquiries. Based on our observations, most suspected promotion accounts are acquired through buying and selling. Therefore, they are likely to ignore emails received in their GitHub accounts or auto-reply to the inquiries. In such cases, GitHub can flag these accounts. Industry recruiters will notice the flagged accounts and may reject applications from repositories that have stars or forks from these flagged accounts, thereby mitigating the negative impacts of promotion services. Another action could be to require suspected promotion accounts to complete a more complex CAPTCHA, which can prevent automatic logins and automated actions like forking and starring.

### 7. Related Works

#### Collaboration on GitHub
GitHub is a cloud-based service that facilitates collaboration on various projects. Collaboration plays a vital role on GitHub. Researchers have conducted extensive studies on this platform [27, 35, 37, 39, 44]. Developers make contributions [29, 40, 45] to enhance their reputation. While developers and their communities can benefit from the legitimate use of bots [47], the misuse of bots in promotion services can harm the community, although this has not yet been widely recognized.

#### Manipulating Reputation
Reputation manipulation has become a serious security issue in recent years. In online e-commerce markets, dishonest sellers have been reported to manipulate reputation systems by faking transaction histories. Xu et al. [49] investigated five underground markets for reputation manipulation in Taobao, referred to as Seller-Reputation-Escalation (SRE) markets. Within the SRE underground market, sellers can easily hire human labor to conduct fake transactions to improve their store's reputation. Cai et al. [25] employed reinforcement learning methods to detect reputation manipulation in online e-commerce markets. Xie et al. [48] examined the underground market where mobile app developers can illegally misuse positive reviews to boost their reputation. Chen et al. [26] exploited unusual ranking change patterns of apps to identify promoted apps and detect collusive promotion groups involved in reputation manipulation.

#### Promotion Services in Online Social Networks
Stringhini et al. [42] inspected Twitter follower markets, which provide promotion services to help users gain a large number of followers. Similarly, an underground market for boosting page likes has emerged on Facebook and has attracted considerable attention [24, 28, 33]. Zheng et al. [52] demonstrated the presence of collusive promoters who generate seemingly trustworthy reviews on Dianping, a user-review social network. Jiang et al. [34] proposed a graph-mining approach to catch synchronized behaviors in large networks. Several studies have also been conducted to detect crowdturfing [41, 46] and suspicious accounts [31, 43]. Song et al. [41] detected crowdturfing by identifying target objects such as post content, pages, and URLs. Wang et al. [46] performed detection in the context of malicious crowdsourcing systems, where sites connect both paying users and promoters. However, these detection approaches are ineffective on GitHub. GitHub promotion service providers do not need to post content for promotion. Many of them use instant messaging tools to gain profits, and there is no valid site yet. Additionally, GitHub promotion service providers employ two main tactics to conceal their characteristics:
1. They actively forge retroactive commits in their own accounts, making the account appear as a normal one with more complex action patterns, including forking, starring, and issuing.
2. They mix their promotion actions with normal actions. For example, during our infiltration described in Section 3.3, we observed that promotion accounts performed star and fork operations on well-known repositories as a disguise.

### 8. Conclusion
In this paper, we conducted the first comprehensive investigation into a new promotion service on GitHub called "Promotion-as-a-Service," which helps developers increase the number of stars and forks on a repository to improve their social status and career prospects. We developed a behavior pattern model by purchasing services from actual GitHub promotion service providers and performed a large-scale scan on all accounts with star and fork operations from 2015 to 2019. We detected that 63,872 accounts are promotion accounts that star and fork for profit. Furthermore, we conducted a large-scale measurement of these suspected promotion accounts and the repositories they starred or forked. We believe our findings will help the security community pay more attention to various fraudulent promotion methods. More importantly, our work will contribute to achieving fair and objective recruitment in the IT industry.

### 9. Acknowledgements
We thank our shepherd Ting-Fang Yen and anonymous reviewers for their insightful feedback, which helped us improve the quality of this paper. This work was supported in part by the National Natural Science Foundation of China (U1836213, U1636204) and the BNRist Network and Software Security Research Program (Grant No. BNR2019TD01004).

### References
[References listed here]

### Appendix A: Forging Retroactive Commits
Figure 11 illustrates the abuse of forging retroactive commits, allowing adversaries to pretend to be active developers.

- **Before the promotion:** The honeypot repository had only two contributions in 2016.
- **After the promotion:** The honeypot repository had 190 contributions in 2016.

**Figure 11: Forging historical commits**

Figure 12 shows how adversaries forge retroactive commits and pretend to be skillful and hardworking developers. In this process, they must first change historical records stored separately in two local files, “pack-*.idx” and “pack-*.pack.” Then, they forge a temporary file and tamper with it to add, modify, or delete characters. By uploading these files back to GitHub, adversaries can change historical records at will.

- **The content of retroactive commits is simple.**

**Figure 12: The process of forging historical commits.**