2m−k + α.
any k > 0, it is also a (k, ε)-extractor for ε = 1
2
See Theorem 8.37 in [19] for a nicely explained proof of
the above lemma.
Pseudorandom Generators. We say that a function G :
{0, 1}m → {0, 1}n is a (deterministic) (t, ε)-pseudorandom
generator (PRG) if CDt(G(Um),Un) ≤ ε.
Game Playing Framework. For our security deﬁnitions
and proofs we use the code-based game playing framework of
[3]. A game GAME has an initialize procedure, procedures to
respond to adversary oracle queries, and a ﬁnalize procedure.
A game GAME is executed with an adversary A as follows.
First, initialize executes, and its outputs are the inputs to A.
Then A executes, its oracle queries being answered by the
corresponding procedures of GAME. When A terminates,
its output becomes the input to the ﬁnalize procedure. The
output of the latter is called the output of the game, and
we let GAMEA ⇒ y denote the event that this game out-
In the next section, for all GAME ∈
put takes value y.
{RES, FWD, BWD, ROB, SROB}, AGAME denotes the output
= 2×Pr[GAMEA ⇒ 1]−1.
of the adversary. We let AdvGAMEA
Our convention is that Boolean ﬂags are assumed initialized
to false and that the running time of the adversary A is de-
ﬁned as the total running time of the game with the adver-
sary in expectation, including the procedures of the game.
3. PRNG WITH INPUT: MODELING AND
SECURITY
Definition (PRNG with input) A PRNG with input is
a triple of algorithms G = (setup, refresh, next) and a triple
(n, (cid:96), p) ∈ N3 where:
• setup: it is a probabilistic algorithm that outputs some
public parameters seed for the generator.
• refresh: it is a deterministic algorithm that, given seed,
a state S ∈ {0, 1}n and an input I ∈ {0, 1}p, outputs
a new state S(cid:48) = refresh(S, I) = refresh(seed, S, I) ∈
{0, 1}n.
• next:
it is a deterministic algorithm that, given seed
and a state S ∈ {0, 1}n, outputs a pair (S(cid:48), R) =
next(S, I) = next(seed, S, I) where S(cid:48) ∈ {0, 1}n is the
new state and R ∈ {0, 1}(cid:96) is the output.
The integer n is the state length, (cid:96) is the output length and
p is the input length of G.
Before moving to deﬁning our security notions, we no-
tice that there are two adversarial entities we need to worry
about: the adversary A whose task is (intuitively) to distin-
guish the outputs of the PRNG from random, and the distri-
bution sampler D whose task is to produce inputs I1, I2, . . .,
which have high entropy collectively, but somehow help A
in breaking the security of the PRNG. In other words, the
distribution sampler models potentially adversarial environ-
ment (or “nature”) where our PRNG is forced to operate.
Unlike prior work, we model the distribution sampler explic-
itly, and believe that such modeling is one of the important
technical and conceptual contributions of our work.
3.1 Distribution Sampler
The distribution sampler D is a stateful and probabilistic
algorithm which, given the current state σ, outputs a tuple
(σ(cid:48), I, γ, z) where: (a) σ(cid:48) is the new state for D; (b) I ∈
{0, 1}p is the next input for the refresh algorithm; (c) γ is
some fresh entropy estimation of I, as discussed below; and
(d) z is the leakage about I given to the attacker A.
We denote by qD the upper bound on number of execu-
tions of D in our security games, and say that D is legitimate
if:1
H∞(Ij | I1, . . . , Ij−1, Ij+1, . . . , IqD ,
z1, . . . , zqD , γ1, . . . , γqD ) ≥ γj
(3)
for all j ∈ {1, . . . , qD} where (σi, Ii, γi, zi) = D(σi−1) for
i ∈ {1, . . . , qD} and σ0 = 0.
We now explain the reason for explicitly requiring D to
output the entropy estimate γj used in (3). Most complex
PRNGs, including the Linux PRNG, are worried about the
situation where the system might enter a prolonged state
where no new entropy is inserted in the system. Correspond-
ingly, such PRNGs typically include some ad hoc entropy
estimation procedure E whose goal is to block the PRNG
from outputting output value Rj until the state has not ac-
cumulated enough entropy γ∗ (for some entropy threshold
γ∗). Unfortunately, it is well-known that even approximat-
ing the entropy of a given distribution is a computation-
ally hard problem [18]. This means that if we require our
PRNG G to explicitly come up with such a procedure E, we
are bound to either place some signiﬁcant restrictions (or
assumptions) on D, or rely on some hoc and non standard
assumptions. Indeed, as part of these work we will demon-
strate some attacks on the entropy estimation of the Linux
PRNG, illustrating how hard (or, perhaps, impossible?) it
is to design a sound entropy estimation procedure E. Fi-
nally, we observe that the design of E is anyway completely
independent of the mathematics of the actual refresh and
next procedures, meaning that the latter can and should be
evaluated independently of the “accuracy” of E.
Motivated by these considerations, we do not insist on
any “entropy estimation” procedure as a mandatory part
1Since conditional min-entropy is deﬁned in the worst-case
manner in (1), the value γj in the bound below should not
be viewed as a random variable, but rather as an arbitrary
ﬁxing of this random variable.
649of the PRNG design, allowing us to elegantly side-step the
practical and theoretical impossibility of sound entropy es-
timation. Instead, we chose to place the burden of entropy
estimations on D itself, which allows us to concentrate on
the provable security of the refresh and next procedures. In
particular, in our security deﬁnition we will not attempt
to verify if D’s claims are accurate (as we said, this ap-
pears hopeless without some kind of heuristics), but will
only require security when D is legitimate, as deﬁned in (3).
Equivalently, we can think that the entropy estimations γj
come from the entropy estimation procedure E (which is
now “merged” with D), but only provide security assuming
that E is correct in this estimation (which we know is hard
in practice, and motivates future work in this direction).
However, we stress that: (a) the entropy estimates γj will
only be used in our security deﬁnitions, but not in any of
the actual PRNG operations (which will only use the “input
part” I returned by D); (b) we do not insist that a legitimate
D can perfectly estimate the fresh entropy of its next sample
Ij, but only provide a lower bound γj that D is “comfortable”
with. For example, D is free to set γj = 0 as many times
as it wants and, in this case, can even choose to leak the
entire Ij to A via the leakage zj!2 More generally, we allow
D to inject new entropy γj as slowly (and maliciously!) as
it wants, but will only require security when the counter c
keeping track of the current “fresh” entropy in the system3
crosses some entropy threshold γ∗ (since otherwise D gave
us “no reason” to expect any security).
3.2 Security Notions
In the literature, four security notions for a PRNG with
input have been proposed: resilience (RES), forward security
(FWD), backward security (BWD) and robustness (ROB),
with the latter being the strongest notion among them. We
now deﬁne the analogs of this notions in our stronger adver-
sarial model, later comparing our modeling with the prior
modeling of [1]. Each of the games below is parametrized by
some parameter γ∗ which is part of the claimed PRNG se-
curity, and intuitively measures the minimal “fresh” entropy
in the system when security should be expected. In partic-
ular, minimizing the value of γ∗ corresponds to a stronger
security guarantee.
All four security games (RES(γ∗), FWD(γ∗), BWD(γ∗),
ROB(γ∗)) are described using the game playing framework
discussed earlier, and share the same initialize and ﬁnalize
procedures in Figure 1 below. As we mentioned, our overall
adversary is modeled via a pair of adversaries (A,D), where
A is the actual attacker and D is a stateful distribution
sampler. We already discussed the distribution sampler D,
so we turn to the attacker A, whose goal is to guess the
correct value b picked in the initialize procedure, which also
returns to A the public value seed, and initializes several
important variables: corruption ﬂag corrupt, “fresh entropy
counter” c, state S and sampler’s D initial state σ.4 In each
of the games (RES, FWD, BWD, ROB), A has access to
2Jumping ahead,
setting γj = 0 corresponds to the
bad-refresh(Ij) oracle in the earlier modeling of [1], which
is not explicitly provided in our model.
3Intuitively, “fresh” refers to the new entropy in the system
since the last state compromise.
4With a slight loss of generality, we assume that when S is
random it is safe to set the corruption ﬂag corrupt to false.
several oracles depicted in depicted in Figure 2. We brieﬂy
discuss these oracles:
D-refresh. This is the key procedure where the distribution
sampler D is run, and where its output I is used to refreshed
the current state S. Additionally, one adds the amount of
fresh entropy γ to the entropy counter c, and resets the
corrupt ﬂag to false when c crosses the threshold γ∗. The
values of γ and the leakage z are also returned to A. We
denote by qD the number of times A calls D-refresh (and,
hence, D), and notice that by our convention (of including
oracle calls into run-time calculations) the total run-time of
D is implicitly upper bounded by the run-time of A.
next-ror/get-next. These procedures provide A with either
the real-or-random challenge (provided corrupt = false) or
the true PRNG output. As a small subtlety, a “premature”
call to get-next before corrupt = false resets the counter c to
0, since then A might learn something non-trivial about the
(low-entropy) state S in this case.5 We denote by qR the
total number of calls to next-ror and get-next.
get-state/set-state. These procedures provide A with the
ability to either learn the current state S, or set it to any
value S∗. In either case c is reset to 0 and corrupt is set to
true. We denote by qS the total number of calls to get-state
and set-state.
We can now deﬁne the corresponding security notions for
PRNGs with input. For convenience, in the sequel we some-
time denote the “resources” of A by T = (t, qD, qR, qS).
Definition (Security of PRNG with input) A pseudo-
random number generator with input G = (setup, refresh,
next) is called (T = (t, qD, qR, qS), γ∗, ε)-robust (resp. re-
silient, forward-secure, backward-secure), if for any adver-
sary A running in time at most t, making at most qD calls
to D-refresh, qR calls to next-ror/get-next and qS calls to
get-state/set-state, and any legitimate distribution sampler
D inside the D-refresh procedure, the advantage of A in game
ROB(γ∗) (resp. RES(γ∗), FWD(γ∗), BWD(γ∗)) is at most ε,
where:
to make the above calls.
to get-state/set-state (i.e., qS = 0).
• ROB(γ∗) is the unrestricted game where A is allowed
• RES(γ∗) is the restricted game where A makes no calls
• FWD(γ∗) is the restricted game where A makes no calls
to set-state and a single call to get-state (i.e., qS = 1)
which is the very last oracle call A is allowed to make.
• BWD(γ∗) is the restricted game where A makes no
calls to get-state and a single call to set-state (i.e., qS =
1) which is the very ﬁrst oracle call A is allowed to
make.
Intuitively, (a) resilience protects the security of the PRNG
when not corrupted against arbitrary distribution samplers
D, (b) forward security protects past PRNG outputs in case
the state S gets compromised, (c) backward security secu-
rity ensures that the PRNG can successfully recover from
state compromise, provided enough fresh entropy is injected
into the system, (d) robustness ensures arbitrary combina-
tion of the above. Hence, robustness is the strongest and
5We could slightly strengthen our deﬁnition, by only reduc-
ing c by (cid:96) bits in this case, but chose to go for a more con-
servative notion.
650proc. initialize
seed $← setup; σ ← 0; S $← {0, 1}n; c ← n; corrupt ← false; b $← {0, 1}
OUTPUT seed
proc. ﬁnalize(b∗)
IF b = b∗
ELSE RETURN 0
RETURN 1
Figure 1: Procedures initialize and ﬁnalize for G = (setup, refresh, next)
proc. D-refresh
(σ, I, γ, z) $← D(σ)
S ← refresh(S, I)
c ← c + γ
IF c ≥ γ∗,
corrupt ← false
OUTPUT (γ, z)
proc. next-ror
(S, R0) ← next(S)
R1
IF corrupt = true,
$← {0, 1}(cid:96)
c ← 0
RETURN R0
ELSE OUTPUT Rb
proc. get-next
(S, R) ← next(S)
IF corrupt = true,
c ← 0
OUTPUT R
proc. get-state
c ← 0, corrupt ← true
OUTPUT S
proc. set-state(S∗)
c ← 0, corrupt ← true
S ← S∗
Figure 2: Procedures in games RES(γ∗), FWD(γ∗), BWD(γ∗), ROB(γ∗) for G = (setup, refresh, next)
the resilience is the weakest of the above four notions. In
particular, all our provable constructions will satisfy the ro-
bustness notion, but we will use the weaker notions to better
pinpoint some of our attacks.
3.3 Comparison to Barak-Halevi Model
Barak-Halevi Construction. We brieﬂy recall the ele-
gant construction of PRNG with input due to Barak and
Halevi [1], since it will help us illustrate the key new elements
(and some of the deﬁnitional choices) of our new model.