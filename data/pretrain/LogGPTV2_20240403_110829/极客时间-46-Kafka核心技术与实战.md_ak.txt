## 何时创建 TCP 连接？要回答上面这个问题，我们首先要弄明白生产者代码是什么时候创建 TCP连接的。就上面的那段代码而言，可能创建 TCP 连接的地方有两处：Producerproducer = new KafkaProducer(props) 和 producer.send(msg,callback)。你觉得连向 Broker 端的 TCP连接会是哪里创建的呢？前者还是后者，抑或是两者都有？请先思考 5秒钟，然后我给出我的答案。首先，生产者应用在创建 KafkaProducer 实例时是会建立与 Broker 的 TCP连接的。其实这种表述也不是很准确，应该这样说：**在创建 KafkaProducer实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender线程开始运行时首先会创建与 Broker的连接**。我截取了一段测试环境中的日志来说明这一点：> \[2018-12-09 09:35:45,620\] DEBUG \[Producer clientId=producer-1\> Initialize connection to node [localhost:9093 (id: -2 rack: null)> ]{.orange}for sending metadata request> (org.apache.kafka.clients.NetworkClient:1084)> \[2018-12-09 09:35:45,622\] DEBUG \[Producer clientId=producer-1\> Initiating connection to node [localhost:9093 (id: -2 rack: null)> ]{.orange}using address localhost/127.0.0.1> (org.apache.kafka.clients.NetworkClient:914)> \[2018-12-09 09:35:45,814\] DEBUG \[Producer clientId=producer-1\> Initialize connection to node [localhost:9092 (id: -1 rack:> null)]{.orange} for sending metadata request> (org.apache.kafka.clients.NetworkClient:1084)> \[2018-12-09 09:35:45,815\] DEBUG \[Producer clientId=producer-1\> Initiating connection to node [localhost:9092 (id: -1 rack: null)> ]{.orange}using address localhost/127.0.0.1> (org.apache.kafka.clients.NetworkClient:914)> \[2018-12-09 09:35:45,828\] DEBUG \[Producer clientId=producer-1\> Sending metadata request (type=MetadataRequest, topics=) to node> localhost:9093 (id: -2 rack: null)> (org.apache.kafka.clients.NetworkClient:1068)你也许会问：怎么可能是这样？如果不调用 send 方法，这个 Producer都不知道给哪个主题发消息，它又怎么能知道连接哪个 Broker呢？难不成它会连接 bootstrap.servers 参数指定的所有 Broker吗？嗯，是的，Java Producer 目前还真是这样设计的。我在这里稍微解释一下 bootstrap.servers 参数。它是 Producer的核心参数之一，指定了这个 Producer 启动时要连接的 Broker地址。请注意，这里的"启动时"，代表的是 Producer 启动时会发起与这些Broker 的连接。因此，如果你为这个参数指定了 1000 个 Broker连接信息，那么很遗憾，你的 Producer 启动时会首先创建与这 1000 个 Broker的 TCP 连接。在实际使用过程中，我并不建议把集群中所有的 Broker 信息都配置到bootstrap.servers 中，通常你指定 3～4 台就足以了。因为 Producer一旦连接到集群中的任一台 Broker，就能拿到整个集群的 Broker信息，故没必要为 bootstrap.servers 指定所有的 Broker。让我们回顾一下上面的日志输出，请注意我标为橙色的内容。从这段日志中，我们可以发现，在KafkaProducer 实例被创建后以及消息被发送前，Producer应用就开始创建与两台 Broker 的 TCP连接了。当然了，在我的测试环境中，我为 bootstrap.servers 配置了localhost:9092、localhost:9093 来模拟不同的Broker，但是这并不影响后面的讨论。另外，日志输出中的最后一行也很关键：它表明Producer 向某一台 Broker 发送了 METADATA请求，尝试获取集群的元数据信息------这就是前面提到的 Producer能够获取集群所有信息的方法。讲到这里，我有一些个人的看法想跟你分享一下。通常情况下，我都不认为社区写的代码或做的设计就一定是对的，因此，很多类似的这种"质疑"会时不时地在我脑子里冒出来。拿今天的这个 KafkaProducer 创建实例来说，社区的官方文档中提及KafkaProducer 类是线程安全的。我本人并没有详尽地去验证过它是否真的就是thread-safe 的，但是大致浏览一下源码可以得出这样的结论：KafkaProducer实例创建的线程和前面提到的 Sender 线程共享的可变数据结构只有RecordAccumulator 类，故维护了 RecordAccumulator类的线程安全，也就实现了 KafkaProducer 类的线程安全。你不需要了解 RecordAccumulator类是做什么的，你只要知道它主要的数据结构是一个ConcurrentMap\。TopicPartition 是 Kafka用来表示主题分区的 Java 对象，本身是不可变对象。而 RecordAccumulator代码中用到 Deque 的地方都有锁的保护，所以基本上可以认定RecordAccumulator 类是线程安全的。说了这么多，我其实是想说，纵然 KafkaProducer是线程安全的，我也不赞同创建 KafkaProducer 实例时启动 Sender线程的做法。写了《Java 并发编程实践》的那位布赖恩·格茨（BrianGoetz）大神，明确指出了这样做的风险：在对象构造器中启动线程会造成 this指针的逃逸。理论上，Sender 线程完全能够观测到一个尚未构造完成的KafkaProducer实例。当然，在构造对象时创建线程没有任何问题，但最好是不要同时启动它。好了，我们言归正传。针对 TCP连接何时创建的问题，目前我们的结论是这样的：**TCP 连接是在创建KafkaProducer实例时建立的**。那么，我们想问的是，它只会在这个时候被创建吗？当然不是！**TCP连接还可能在两个地方被创建：一个是在更新元数据后，另一个是在消息发送时**。为什么说是可能？因为这两个地方并非总是创建TCP 连接。当 Producer 更新了集群的元数据信息之后，如果发现与某些 Broker当前没有连接，那么它就会创建一个 TCP连接。同样地，当要发送消息时，Producer 发现尚不存在与目标 Broker的连接，也会创建一个。接下来，我们来看看 Producer 更新集群元数据信息的两个场景。场景一：当 Producer 尝试给一个不存在的主题发送消息时，Broker 会告诉Producer 说这个主题不存在。此时 Producer 会发送 METADATA 请求给 Kafka集群，去尝试获取最新的元数据信息。场景二：Producer 通过 metadata.max.age.ms参数定期地去更新元数据信息。该参数的默认值是 300000，即 5分钟，也就是说不管集群那边是否有变化，Producer 每 5分钟都会强制刷新一次元数据以保证它是最及时的数据。讲到这里，我们可以"挑战"一下社区对 Producer的这种设计的合理性。目前来看，一个 Producer 默认会向集群的所有 Broker都创建 TCP 连接，不管是否真的需要传输请求。这显然是没有必要的。再加上Kafka 还支持强制将空闲的 TCP 连接资源关闭，这就更显得多此一举了。试想一下，在一个有着 1000 台 Broker 的集群中，你的 Producer可能只会与其中的 3～5 台 Broker 长期通信，但是 Producer启动后依次创建与这 1000 台 Broker 的 TCP 连接。一段时间之后，大约有 995个 TCP连接又被强制关闭。这难道不是一种资源浪费吗？很显然，这里是有改善和优化的空间的。
## 何时关闭 TCP 连接？说完了 TCP 连接的创建，我们来说说它们何时被关闭。Producer 端关闭 TCP 连接的方式有两种：**一种是用户主动关闭；一种是 Kafka自动关闭**。我们先说第一种。这里的主动关闭实际上是广义的主动关闭，甚至包括用户调用kill -9 主动"杀掉"Producer 应用。当然最推荐的方式还是调用producer.close() 方法来关闭。第二种是 Kafka 帮你关闭，这与 Producer 端参数 connections.max.idle.ms的值有关。默认情况下该参数值是 9 分钟，即如果在 9分钟内没有任何请求"流过"某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP连接关闭。用户可以在 Producer 端设置 connections.max.idle.ms=-1禁掉这种机制。一旦被设置成 -1，TCP连接将成为永久长连接。当然这只是软件层面的"长连接"机制，由于 Kafka创建的这些 Socket 连接都开启了 keepalive，因此 keepalive探活机制还是会遵守的。值得注意的是，在第二种方式中，TCP 连接是在 Broker 端被关闭的，但其实这个TCP 连接的发起方是客户端，因此在 TCP 看来，这属于被动关闭的场景，即passive close。被动关闭的后果就是会产生大量的 CLOSE_WAIT 连接，因此Producer 端或 Client 端没有机会显式地观测到此连接已被中断。
## 小结我们来简单总结一下今天的内容。对最新版本的 Kafka（2.1.0）而言，JavaProducer 端管理 TCP 连接的方式是：1.  KafkaProducer 实例创建时启动 Sender 线程，从而创建与    bootstrap.servers 中所有 Broker 的 TCP 连接。2.  KafkaProducer 实例首次更新元数据信息之后，还会再次创建与集群中所有    Broker 的 TCP 连接。3.  如果 Producer 端发送消息到某台 Broker 时发现没有与该 Broker 的 TCP    连接，那么也会立即创建连接。4.  如果设置 Producer 端 connections.max.idle.ms 参数大于 0，则步骤 1    中创建的 TCP 连接会被自动关闭；如果设置该参数 =-1，那么步骤 1    中创建的 TCP 连接将无法被关闭，从而成为"僵尸"连接。
## 开放讨论对于今天我们"挑战"的社区设计，你有什么改进的想法吗？欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。![](Images/a7d15815f9efb5693db5b2d278244658.png){savepage-src="https://static001.geekbang.org/resource/image/c8/bf/c89da43deab85fe7cb06acec867aa5bf.jpg"}
# 14 \| 幂等生产者和事务生产者是一回事吗？你好，我是胡夕。今天我要和你分享的主题是：Kafka消息交付可靠性保障以及精确处理一次语义的实现。所谓的消息交付可靠性保障，是指 Kafka 对 Producer 和 Consumer要处理的消息提供什么样的承诺。常见的承诺有以下三种：-   最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。-   至少一次（at least once）：消息不会丢失，但有可能被重复发送。-   精确一次（exactly once）：消息不会丢失，也不会被重复发送。目前，Kafka 默认提供的交付可靠性保障是第二种，即至少一次。在专栏[第 11期](https://time.geekbang.org/column/article/102931)中，我们说过消息"已提交"的含义，即只有Broker 成功"提交"消息且 Producer 接到 Broker的应答才会认为该消息成功发送。不过倘若消息成功"提交"，但 Broker的应答没有成功发送回 Producer 端（比如网络出现瞬时抖动），那么 Producer就无法确定消息是否真的提交成功了。因此，它只能选择重试，也就是再次发送相同的消息。这就是Kafka 默认提供至少一次可靠性保障的原因，不过这会导致消息重复发送。Kafka 也可以提供最多一次交付保障，只需要让 Producer禁止重试即可。这样一来，消息要么写入成功，要么写入失败，但绝不会重复发送。我们通常不会希望出现消息丢失的情况，但一些场景里偶发的消息丢失其实是被允许的，相反，消息重复是绝对要避免的。此时，使用最多一次交付保障就是最恰当的。``{=html}无论是至少一次还是最多一次，都不如精确一次来得有吸引力。大部分用户还是希望消息只会被交付一次，这样的话，消息既不会丢失，也不会被重复处理。或者说，即使Producer 端重复发送了相同的消息，Broker 端也能做到自动去重。在下游Consumer 看来，消息依然只有一条。那么问题来了，Kafka是怎么做到精确一次的呢？简单来说，这是通过两种机制：幂等性（Idempotence）和事务（Transaction）。它们分别是什么机制？两者是一回事吗？要回答这些问题，我们首先来说说什么是幂等性。
## 什么是幂等性（Idempotence）？"幂等"这个词原是数学领域中的概念，指的是某些操作或函数能够被执行多次，但每次得到的结果都是不变的。我来举几个简单的例子说明一下。比如在乘法运算中，让数字乘以1就是一个幂等操作，因为不管你执行多少次这样的运算，结果都是相同的。再比如，取整函数（floor和 ceiling）是幂等函数，那么运行 1 次 floor(3.4) 和 100 次floor(3.4)，结果是一样的，都是 3。相反地，让一个数加 1这个操作就不是幂等的，因为执行一次和执行多次的结果必然不同。在计算机领域中，幂等性的含义稍微有一些不同：-   在命令式编程语言（比如    C）中，若一个子程序是幂等的，那它必然不能修改系统状态。这样不管运行这个子程序多少次，与该子程序关联的那部分系统状态保持不变。-   在函数式编程语言（比如 Scala 或 Haskell）中，很多纯函数（pure    function）天然就是幂等的，它们不执行任何的 side effect。幂等性有很多好处，**其最大的优势在于我们可以安全地重试任何幂等性操作，反正它们也不会破坏我们的系统状态**。如果是非幂等性操作，我们还需要担心某些操作执行多次对状态的影响，但对于幂等性操作而言，我们根本无需担心此事。
## 幂等性 Producer在 Kafka 中，Producer 默认不是幂等性的，但我们可以创建幂等性Producer。它其实是 0.11.0.0 版本引入的新功能。在此之前，Kafka向分区发送数据时，可能会出现同一条消息被发送了多次，导致消息重复的情况。在0.11 之后，指定 Producer 幂等性的方法很简单，仅需要设置一个参数即可，即props.put("enable.idempotence", ture)，或props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)。enable.idempotence 被设置成 true 后，Producer 自动升级成幂等性Producer，其他所有的代码逻辑都不需要改变。Kafka自动帮你做消息的重复去重。底层具体的原理很简单，就是经典的用空间去换时间的优化思路，即在Broker 端多保存一些字段。当 Producer发送了具有相同字段值的消息后，Broker能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们"丢弃"掉。当然，实际的实现原理并没有这么简单，但你大致可以这么理解。看上去，幂等性 Producer的功能很酷，使用起来也很简单，仅仅设置一个参数就能保证消息不重复了，但实际上，我们必须要了解幂等性Producer 的作用范围。首先，它只能保证单分区上的幂等性，即一个幂等性 Producer能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。这里的会话，你可以理解为Producer 进程的一次运行。当你重启了 Producer进程之后，这种幂等性保证就丧失了。那么你可能会问，如果我想实现多分区以及多会话上的消息无重复，应该怎么做呢？答案就是事务（transaction）或者依赖事务型Producer。这也是幂等性 Producer 和事务型 Producer 的最大区别！