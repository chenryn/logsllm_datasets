            x = self.embedding(x)  # (batch_size, target_seq_len, d_model)
            x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
            x += self.pos_encoding[:, :seq_len, :]
            x = self.dropout(x, training=training)
            for i in range(self.num_layers):
                x, block1, block2 = self.dec_layers[i](x, enc_output, training,
                                                       look_ahead_mask, padding_mask)
                attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1
                attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2
            # x.shape == (batch_size, target_seq_len, d_model)
            return x, attention_weights
    """## Create the Transformer
    Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned.
    """
    class Transformer(tf.keras.Model):
        def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,
                     target_vocab_size, rate=0.1):
            super(Transformer, self).__init__()
            self.encoder = Encoder(num_layers, d_model, num_heads, dff,
                                   input_vocab_size, rate)
            self.decoder = Decoder(num_layers, d_model, num_heads, dff,
                                   target_vocab_size, rate)
            self.final_layer = tf.keras.layers.Dense(target_vocab_size)
        def call(self, inp, tar, training, enc_padding_mask,
                 look_ahead_mask, dec_padding_mask):
            enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)
            # dec_output.shape == (batch_size, tar_seq_len, d_model)
            dec_output, attention_weights = self.decoder(
                tar, enc_output, training, look_ahead_mask, dec_padding_mask)
            final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)
            return final_output, attention_weights
    num_layers = 4
    d_model = 128
    dff = 512
    num_heads = 8
    input_vocab_size = tokenizer_pt.vocab_size + 2
    target_vocab_size = tokenizer_en.vocab_size + 2
    dropout_rate = 0.1
    class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
        def __init__(self, d_model, warmup_steps=4000):
            super(CustomSchedule, self).__init__()
            self.d_model = d_model
            self.d_model = tf.cast(self.d_model, tf.float32)
            self.warmup_steps = warmup_steps
        def __call__(self, step):
            arg1 = tf.math.rsqrt(step)
            arg2 = step * (self.warmup_steps ** -1.5)
            return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)
    learning_rate = CustomSchedule(d_model)
    optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,
                                         epsilon=1e-9)
    temp_learning_rate_schedule = CustomSchedule(d_model)
    plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))
    plt.ylabel("Learning Rate")
    plt.xlabel("Train Step")
    """## Loss and metrics
    Since the target sequences are padded, it is important to apply a padding mask when calculating the loss.
    """
    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
        from_logits=True, reduction='none')
    def loss_function(real, pred):
        mask = tf.math.logical_not(tf.math.equal(real, 0))
        loss_ = loss_object(real, pred)
        mask = tf.cast(mask, dtype=loss_.dtype)
        loss_ *= mask
        return tf.reduce_mean(loss_)
    train_loss = tf.keras.metrics.Mean(name='train_loss')
    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')
    val_loss = tf.keras.metrics.Mean(name='val_loss')
    val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')
    """## Training and checkpointing"""
    transformer = Transformer(num_layers, d_model, num_heads, dff,
                              input_vocab_size, target_vocab_size, dropout_rate)
    def create_masks(inp, tar):
        # Encoder padding mask
        enc_padding_mask = create_padding_mask(inp)
        # Used in the 2nd attention block in the decoder.
        # This padding mask is used to mask the encoder outputs.
        dec_padding_mask = create_padding_mask(inp)
        # Used in the 1st attention block in the decoder.
        # It is used to pad and mask future tokens in the input received by
        # the decoder.
        look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])
        dec_target_padding_mask = create_padding_mask(tar)
        combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)
        return enc_padding_mask, combined_mask, dec_padding_mask
    """Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."""
    checkpoint_path = "./checkpoints/train"
    ckpt = tf.train.Checkpoint(transformer=transformer,
                               optimizer=optimizer)
    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)
    # if a checkpoint exists, restore the latest checkpoint.
    if ckpt_manager.latest_checkpoint:
        ckpt.restore(ckpt_manager.latest_checkpoint)
        print('Latest checkpoint restored!!')
    EPOCHS = 200
    train_num = len([1 for _, _ in train_dataset])
    @tf.function
    def train_step(inp, tar):
        tar_inp = tar[:, :-1]
        tar_real = tar[:, 1:]
        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)
        with tf.GradientTape() as tape:
            predictions, _ = transformer(inp, tar_inp,
                                         True,
                                         enc_padding_mask,
                                         combined_mask,
                                         dec_padding_mask)
            loss = loss_function(tar_real, predictions)
        gradients = tape.gradient(loss, transformer.trainable_variables)
        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))
        train_loss(loss)
        train_accuracy(tar_real, predictions)
    @tf.function
    def val_step(inp, tar):
        tar_inp = tar[:, :-1]
        tar_real = tar[:, 1:]
        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)
        predictions, _ = transformer(inp,tar_inp,
                                    enc_padding_mask=enc_padding_mask,
                                    look_ahead_mask=combined_mask,
                                    dec_padding_mask=dec_padding_mask,
                                    training=False)
        loss = loss_function(tar_real, predictions)
        ppl = tf.exp(loss)
        val_loss(ppl)
        val_accuracy(tar_real, predictions)
    print("(3):Traning model......")
    """Portuguese is used as the input language and English is the target language."""
    for epoch in range(EPOCHS):
        train_loss.reset_states()
        train_accuracy.reset_states()
        val_loss.reset_states()
        val_accuracy.reset_states()
        print('Epoch {}'.format(epoch + 1))
        start = time.time()
        # inp -> portuguese, tar -> english
        with tqdm(total=train_num * BATCH_SIZE) as pbar:
            for inp, tar in train_dataset:
                train_step(inp, tar)
                pbar.update(BATCH_SIZE)
        for inp, tar in val_dataset:
            val_step(inp, tar)
        end = time.time()
        print('train_loss {:.4f}\ttrain_acc {:.2f}\t'
              'val_loss {:.4f}\tval_acc {:.2f}\t'
              'time {:.2f}s'.format(train_loss.result(),
                                    train_accuracy.result() * 100,
                                    val_loss.result(),
                                    val_accuracy.result() * 100,
                                    end - start,
                                    ))
    def evaluate(inp_sentence):
        start_token = [tokenizer_pt.vocab_size]
        end_token = [tokenizer_pt.vocab_size + 1]
        # inp sentence is portuguese, hence adding the start and end token
        inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token
        encoder_input = tf.expand_dims(inp_sentence, 0)
        # as the target is english, the first word to the transformer should be the
        # english start token.
        decoder_input = [tokenizer_en.vocab_size]
        output = tf.expand_dims(decoder_input, 0)
        for i in range(MAX_LENGTH):
            enc_padding_mask, combined_mask, dec_padding_mask = create_masks(
                encoder_input, output)
            # predictions.shape == (batch_size, seq_len, vocab_size)
            predictions, attention_weights = transformer(encoder_input,
                                                         output,
                                                         False,
                                                         enc_padding_mask,
                                                         combined_mask,
                                                         dec_padding_mask)
            # select the last word from the seq_len dimension
            predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)
            predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)
            # return the result if the predicted_id is equal to the end token
            if tf.equal(predicted_id, tokenizer_en.vocab_size + 1):
                return tf.squeeze(output, axis=0), attention_weights
            # concatentate the predicted_id to the output which is given to the decoder
            # as its input.
            output = tf.concat([output, predicted_id], axis=-1)
        return tf.squeeze(output, axis=0), attention_weights
    def plot_attention_weights(attention, sentence, result, layer):
        fig = plt.figure(figsize=(16, 8))
        sentence = tokenizer_pt.encode(sentence)
        attention = tf.squeeze(attention[layer], axis=0)
        for head in range(attention.shape[0]):
            ax = fig.add_subplot(2, 4, head + 1)
            # plot the attention weights
            ax.matshow(attention[head][:-1, :], cmap='viridis')
            fontdict = {'fontsize': 10}
            ax.set_xticks(range(len(sentence) + 2))
            ax.set_yticks(range(len(result)))
            ax.set_ylim(len(result) - 1.5, -0.5)
            ax.set_xticklabels(
                [''] + [tokenizer_pt.decode([i]) for i in sentence] + [''],
                fontdict=fontdict, rotation=90)
            ax.set_yticklabels([tokenizer_en.decode([i]) for i in result
                                if i < tokenizer_en.vocab_size],
                               fontdict=fontdict)
            ax.set_xlabel('Head {}'.format(head + 1))
        plt.tight_layout()
        plt.show()
    def translate(sentence, plot=''):
        result, attention_weights = evaluate(sentence)
        predicted_sentence = tokenizer_en.decode([i for i in result
                                                  if i < tokenizer_en.vocab_size])
        print('Input: {}'.format(sentence))
        print('Predicted translation: {}'.format(predicted_sentence))
        if plot:
            plot_attention_weights(attention_weights, sentence, result, plot)
    print("(4):Evaluate model......")
    translate("este é um problema que temos que resolver.")
    print("Real translation: this is a problem we have to solve .")
    translate("os meus vizinhos ouviram sobre esta ideia.")
    print("Real translation: and my neighboring homes heard about this idea .")
    translate("vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.")
    print(
        "Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .")
    """You can pass different layers and attention blocks of the decoder to the `plot` parameter."""
    translate("este é o primeiro livro que eu fiz.", plot='decoder_layer4_block2')
    print("Real translation: this is the first book i've ever done.")