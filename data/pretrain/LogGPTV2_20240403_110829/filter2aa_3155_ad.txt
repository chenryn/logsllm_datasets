be vulnerable and could lead to a SSRF vulnerability, so in order to remedy this possible vulnerability, the website performs 
a validation on the URL, disallowing URLs with a specific hostname in order to block requests to those hosts.
As we’ve seen before, because urlsplit does not ignore extra slashes, it will parse this URL as a URL with an empty authority 
(netloc), thus passing the security check comparing the netloc (an empty string in this case) to google.com. However, since 
cURL ignores the extra slash, it will fetch the URL as if it had only two slashes, thus bypassing the attempted validation and 
resulting in a SSRF vulnerability.
BACKSLASH CONFUSION
Another interesting interaction between URL parsers and malformed URLs involves URLs that use a backslash (\) instead of 
a slash (/). According to RFC 3986, a backslash is an entirely different character from a slash, and should not be interpreted 
as one. This means the URL https://google.com and https:\\google.com are different and should be parsed differently.
And true to the RFC, most programmatic URL parsers do not treat a slash and a backslash interchangeably:
An example code implementing the security checks described above.
An example code implementing the security checks described above. 
As we’ve seen before, because urlsplit does not ignore extra slashes, it will parse this URL as a 
URL with an empty authority (netloc), thus passing the security check comparing the netloc (an 
empty string in this case) to google.com. However, since cURL ignores the extra slash, it will 
fetch the URL as if it had only two slashes, thus bypassing the attempted validation and 
resulting in a SSRF vulnerability. 
Backslash Confusion 
Another interesting interaction between URL parsers and malformed URLs involves URLs that 
use a backslash (\) instead of a slash (/). According to RFC 3986, a backslash is an entirely 
different character from a slash, and should not be interpreted as one. This means the URL 
https://google.com and https:\\google.com are different and should be parsed differently. 
And true to the RFC, most programmatic URL parsers do not treat a slash and a backslash 
interchangeably: 
claroty.com
18
Copyright © 2021 Claroty Ltd. All rights reserved
However, when supplied to the Chrome browser (this result is replicated in most browsers), Chrome chooses to interpret  
the backslash as if it was a regular slash.
And indeed, the browser treats this malformed URL as if the backslashes were slashes.
Furthermore, to take matters into the extreme, in case both slashes and backslashes are used, the browser still accepts the 
URL and treats it as a valid URL, as can be seen in the picture below.
The parsing result of the URL http:\\google.com. 
However, when supplied to the Chrome browser (this result is replicated in most browsers), 
Chrome chooses to interpret the backslash as if it was a regular slash. 
A HTTP response telling the browser to redirect the user to https:\\www.google.com through the Location HTTP header, 
using backslashes instead of slashes. 
And indeed, the browser treats this malformed URL as if the backslashes were slashes. 
Furthermore, to take matters into the extreme, in case both slashes and backslashes are used, 
the browser still accepts the URL and treats it as a valid URL, as can be seen in the picture 
below. 
A HTTP response telling the browser to redirect the user to https:◌ֿ /\www.google.com through the Location HTTP header, 
using both backslashes and slashes. 
This uncanny behavior happens because most browsers actually follow the WHATWG URL 
specification (TWUS), which states backslashes should be treated the same as front slashes. 
The parsing result of the URL http:\\google.com. 
However, when supplied to the Chrome browser (this result is replicated in most browsers), 
Chrome chooses to interpret the backslash as if it was a regular slash. 
A HTTP response telling the browser to redirect the user to https:\\www.google.com through the Location HTTP header, 
using backslashes instead of slashes. 
And indeed, the browser treats this malformed URL as if the backslashes were slashes. 
Furthermore, to take matters into the extreme, in case both slashes and backslashes are used, 
the browser still accepts the URL and treats it as a valid URL, as can be seen in the picture 
below. 
A HTTP response telling the browser to redirect the user to https:◌ֿ /\www.google.com through the Location HTTP header, 
using both backslashes and slashes. 
This uncanny behavior happens because most browsers actually follow the WHATWG URL 
specification (TWUS), which states backslashes should be treated the same as front slashes. 
The parsing result of the URL http:\\google.com. 
However, when supplied to the Chrome browser (this result is replicated in most browsers), 
Chrome chooses to interpret the backslash as if it was a regular slash. 
A HTTP response telling the browser to redirect the user to https:\\www.google.com through the Location HTTP header, 
using backslashes instead of slashes. 
And indeed, the browser treats this malformed URL as if the backslashes were slashes. 
Furthermore, to take matters into the extreme, in case both slashes and backslashes are used, 
the browser still accepts the URL and treats it as a valid URL, as can be seen in the picture 
below. 
A HTTP response telling the browser to redirect the user to https:◌ֿ /\www.google.com through the Location HTTP header, 
using both backslashes and slashes. 
This uncanny behavior happens because most browsers actually follow the WHATWG URL 
specification (TWUS), which states backslashes should be treated the same as front slashes. 
A HTTP response telling the browser to redirect the user to https:\\www.google.com through the Location 
HTTP header, using backslashes instead of slashes.
A HTTP response telling the browser to redirect the user to https:ֿ/\www.google.com through the Location 
HTTP header, using both backslashes and slashes.
The parsing result of the URL http:\\google.com.
claroty.com
19
Copyright © 2021 Claroty Ltd. All rights reserved
This uncanny behavior happens because most browsers actually follow the WHATWG URL specification (TWUS), which 
states backslashes should be treated the same as front slashes. 
Another interesting example of URL parsers treating backslashes as slashes can be seen inside the regular expressions used 
by urllib3 to parse a given URL to its different components.
As we can see, urllib3 uses a backslash as a delimiter to its authority component. This means that if an authority contains 
a backslash in it, urllib3 would split it and use only the prefix to the backslash as the authority, instead concatenating the 
postfix to the path.
This creates a wide range of attack scenarios, in which a malicious attacker abuses this parsing primitive by using a 
backslash inside a URL in order to confuse different parsers and achieve unexpected results.
One example of such a confusion could be seen when giving the following URL to different parsers:
http://evil.com\@google.com/
If we follow the latest URL RFC, specifying that a backslash has no special meaning inside a URL authority, we reach the 
simple conclusion that this URL has the following authority:
Authority = [ userinfo “@” ] host [ “:” port ]
Authority = [ evil.com\ “@” ] google.com
Meaning our host is google.com, while evil.com\ is simply the given userinfo, and when we look into how most parsers parse 
this URL, we get a confirmation for our hypothesized authority.
The source code of the regex used to parse URLs by urllib3, using a backslash as a delimiter to the 
authority URL component (marked in red).
Another interesting example of URL parsers treating backslashes as slashes can be seen inside 
the regular expressions used by urllib3 to parse a given URL to its different components. 
The source code of the regex used to parse URLs by urllib3, using a backslash as a delimiter to the authority URL 
component (marked in red). 
As we can see, urllib3 uses a backslash as a delimiter to its authority component. This means 
that if an authority contains a backslash in it, urllib3 would split it and use only the prefix to the 
backslash as the authority, instead concatenating the postfix to the path. 
This creates a wide range of attack scenarios, in which a malicious attacker abuses this parsing 
primitive by using a backslash inside a URL in order to confuse different parsers and achieve 
unexpected results. 
One example of such a confusion could be seen when giving the following URL to different 
parsers: 
http://evil.com\@google.com/ 
If we follow the latest URL RFC, specifying that a backslash has no special meaning inside a 
URL authority, we reach the simple conclusion that this URL has the following authority: 
Authority = [ userinfo "@" ] host [ ":" port ] 
Authority = [ evil.com\ "@" ] google.com 
Meaning our host is google.com, while evil.com\ is simply the given userinfo, and when we look 
into how most parsers parse this URL, we get a confirmation for our hypothesized authority. 
However, since we’ve seen that urllib3 treats a backslash as a delimiter to the authority 
component, we know its result will not be the same. And since the requests Python module 
claroty.com
20
Copyright © 2021 Claroty Ltd. All rights reserved
However, since we’ve seen that urllib3 treats a backslash as a delimiter to the authority component, we know its result will 
not be the same. And since the requests Python module uses urllib3 as its main parser (while still using urllib’s urlparse 
and urlsplit in other cases), this gets even more interesting.
As we can see, in both cases the URL parser concluded that evil.com is the correct authority/host for this URL, since the 
parser accepts a backslash as a valid delimiter. 
ing this discrepancy between parsers, a malicious attacker could easily bypass many different validatio
By abus 
ns being 
performed, thus opening a wide range of possible attack vectors.
URL-ENCODED DATA CONFUSION
Lastly, another interesting URL interaction we’ve discovered is one involving URLs containing URL-encoded characters. 
URL encoding is a method in which any non-printable characters are instead converted to a hex representation, with a 
percent sign (%) as a suffix. This method allows non-printable characters to be sent inside a URL without sending the actual 
value of the character, keeping the request completely textual even if it would contain non-printable characters. This also 
doubles down as a protection from many attacks, such as a CRLF injection or a NULL byte injection. However, technically 
speaking, printable characters could also be URL-encoded, and our confusion involves just that. 
According to the URL RFC (RFC 3986), all URL components except the scheme can be represented using URL encoded 
characters, and when parsed should be URL decoded. While it’s common for URL parsers to decode the path component, 
many parsers are not decoding the host although the RFC 3896 clearly states that. For example, we have tested this 
scenario with cURL which did not decode the host component. We reported this behaviour to cURL maintainer Daniel 
Stenberg who considered it a bug and fixed it in the latest cURL version.
When we supplied our parsers with a URL that has URL-encoded printable characters, most parsers did not URL-decode the 
URL (the opposite operation of URL-encoding), instead returning a result containing URL-encoded data.
Our malicious URL is parsed by urllib3’s parse_url, returning evil.com as the host, as well as being used in a 
GET request by the requests library, resulting in evil.com being fetched.
uses urllib3 as its main parser (while still using urllib’s urlparse and urlsplit in other cases), this
gets even more interesting.
Our malicious URL is parsed by urllib3’s parse_url, returning evil.com as the host, as well as being used in a GET request
by the requests library, resulting in evil.com being fetched.
As we can see, in both cases the URL parser concluded that evil.com is the correct 
authority/host for this URL, since the parser accepts a backslash as a valid delimiter. 
By abusing this discrepancy between parsers, a malicious attacker could easily bypass many 
different validations being performed, thus opening a wide range of possible attack vectors.
claroty.com
21
Copyright © 2021 Claroty Ltd. All rights reserved
While this seems like the expected result (and it might actually be the expected result), an interesting interaction happens 
whenever we try to fetch this URL. In order to fetch this URL, we’ve used both urllib’s urlopen and requests, Python’s most 
prominent URL fetchers. When we fetched this URL, we discovered that both parsers were actually decoding the URL, and 
managed to fetch the URL.
URL parsers parsing a URL-encoded form of http://google.com, returning a URL-encoded result
A fetch request using both urllib and requests, fetching the URL-encoded URL of  
http://127.0.0.1.Both requests were fulfilled, fetching the requested resource.
URL parsers parsing a URL-encoded form of http://google.com, returning a URL-encoded result 
While this seems like the expected result (and it might actually be the expected result), an 
interesting interaction happens whenever we try to fetch this URL. In order to fetch this URL, 
we’ve used both urllib’s urlopen and requests, Python’s most prominent URL fetchers. 
When we fetched this URL, we discovered that both parsers were actually decoding the URL, 
and managed to fetch the URL. 
A fetch request using both urllib and requests, fetching the URL-encoded URL of http://127.0.0.1. Both requests 
were fulfilled, fetching the requested resource. 
URL parsers parsing a URL-encoded form of http://google.com, returning a URL-encoded result 
While this seems like the expected result (and it might actually be the expected result), an 
interesting interaction happens whenever we try to fetch this URL. In order to fetch this URL, 
we’ve used both urllib’s urlopen and requests, Python’s most prominent URL fetchers. 
When we fetched this URL, we discovered that both parsers were actually decoding the URL, 
and managed to fetch the URL. 
A fetch request using both urllib and requests, fetching the URL-encoded URL of http://127.0.0.1. Both requests 
were fulfilled, fetching the requested resource. 
claroty.com
22
Copyright © 2021 Claroty Ltd. All rights reserved
And indeed, when we checked if the request was performed, we found that both parsers decoded the URL-encoded 
characters and successfully fulfilled the request.
This dissonance in which one time the parser decodes the URL and another it does not opens a huge range of possible 
vulnerabilities in which an attacker could bypass validations being performed by URL-decoding the URL he wants to 
retrieve. Furthermore, because this confusion could happen when using only one URL parsing library, for example urllib’s 
urlsplit and urlopen, the attack becomes even more prominent in web applications. 
SCHEME MIXUP
The last confusion type we’ve named Scheme Mixup, and it refers to a mixup between multiple URL Schemes. As we’ve 
explained before, the scheme component of a URL dictates the exact URL protocol which should be used in order to 
parse the URL. Currently, many URL schemes exist, the most popular one (and the one which we’ve talked about in this 
paper the most) being the HTTP/HTTPS URL protocol. However, URLs support many other protocols, including FTP, FILE, 
SIP, LDAP  and many more.
While all of the above URL protocols are still considered a URL, and share very similarities to the basic URL, some 
differences still exist, and there is no guarantee that a general URL parser will be able to correctly parse URLs of a 
different protocol.
For example, let’s take a look back into the log4j bypass vulnerability (CVE-2021-45046) which we’ve explained before. 
In this example, we’ve showcased the following LDAP URL:
ldap://127.0.0.1#.evilhost.com:1389/a
As it turns out, this specific URL is parsed differently whether it is parsed as a LDAP URL or a HTTP URL. Let’s take a look at 
the LDAP URL specification (taken from RFC 2255):
As we can see, the LDAP URL has some different components, however one component in particular is missing - the 
Fragment. This means that if we were to parse this URL as a regular URL, the Authority component would end after the 
# character (which is a reserved character signaling the start of a Fragment), leaving 127.0.0.1 as the Authority, 
while a LDAP URL parser would assign the whole 127.0.0.1#.evilhost.com:1389 as the Authority, since in LDAP 
RFC the # character has no special meaning.
While this example is taken from a real-life vulnerability which exploited this exact mixup, it showcases how different some 
URL schemes can be, and the importance of using the correct, protocol specific URL parsers whenever parsing a URL of a 
none-default scheme.
ldap://127.0.0.1#.evilhost.com:1389/a
As it turns out, this specific URL is parsed differently whether it is parsed as a LDAP URL or a 
HTTP URL. Let's take a look at the LDAP URL specification (taken from RFC 2255):
      ldapurl    = scheme "://" [hostport] ["/" 
[dn ["?" [attributes] ["?" [scope] 
["?" [filter] ["?" extensions]]]]]] 
As we can see, the LDAP URL has some different components, however one component in
particular is missing - the Fragment. This means that if we were to parse this URL as a regular
URL, the Authority component would end after the # character (which is a reserved 
character signaling the start of a Fragment), leaving 127.0.0.1 as the Authority, while a 
LDAP URL parser would assign the whole 127.0.0.1#.evilhost.com:1389 as the 
Authority, since in LDAP RFC the # character has no special meaning.
While this example is taken from a real-life vulnerability which exploited this exact mix up, it 
showcases how different some URL schemes can be, and the importance of using the correct,
protocol specific URL parsers whenever parsing a URL of a none-default Scheme.
Summary
Scheme 
Confusion
Slash 
Confusion
Backslash 
Confusion
URL-Encoded 
Confusion
claroty.com
23
Copyright © 2021 Claroty Ltd. All rights reserved
Lang
Python
Python
Python
Python
Python
Python
curl
wget
Browser
.NET 
Java 
Java 
PHP