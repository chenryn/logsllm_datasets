### Feature request
ðŸ¤— Accelerate has a wrapper to help with distributed metric calculation (a
tough problem!), and the `no_trainer` scripts should be updated to include it!
An example can be seen here, below is an example diff of what the integration
would look like:
    -             predictions, references = accelerator.gather((predictions, batch["labels"]))
    -             # If we are in a multiprocess environment, the last batch has duplicates
    -             if accelerator.num_processes > 1:
    -                 if step == len(eval_dataloader) - 1:
    -                     predictions = predictions[: len(eval_dataloader.dataset) - samples_seen]
    -                     references = references[: len(eval_dataloader.dataset) - samples_seen]
    -                 else:
    -                     samples_seen += references.shape[0]
    +             predictions, references = accelerator.gather_for_metrics((predictions, batch["labels"])) 
The list of available scripts to update include:
  * examples/pytorch/image-classification/run_image_classification_no_trainer.py
  * examples/pytorch/language-modeling/run_clm_no_trainer.py
  * examples/pytorch/language-modeling/run_mlm_no_trainer.py
  * examples/pytorch/multiple-choice/run_swag_no_trainer.py
  * examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py
  * examples/pytorch/question_answering/run_qa_no_trainer.py
  * examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py
  * examples/pytorch/speech-pretraining/run_wav2vec2_pretraining_no_trainer.py
  * examples/pytorch/summarization/run_summarization_no_trainer.py
### Motivation
This is a great first issue for someone who wants to learn how to use some of
the latest bits in Accelerate and get an easy beginner contribution to the
library ðŸ¤—
### Your contribution
If you decide to pick up this issue, feel free to ping myself (@muellerzr),
@sgugger, or @pacman100 to review ðŸ¤—