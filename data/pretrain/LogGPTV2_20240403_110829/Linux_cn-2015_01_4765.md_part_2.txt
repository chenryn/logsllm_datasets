上面的配置是当 HAProxy 为 HTTP 负载均衡时建议使用的，但是并不一定是你的环境的最优方案。你可以自己研究 HAProxy 的手册并配置它。
### 3. Web 集群配置
Web 集群配置定义了一组可用的 HTTP 服务器。我们的负载均衡中的大多数设置都在这里。现在我们会创建一些基本配置，定义我们的节点。将配置文件中从 frontend 段开始的内容全部替换为下面的：
```
listen webfarm *:80 
       mode http 
       stats enable 
       stats uri /haproxy?stats 
       stats realm Haproxy\ Statistics 
       stats auth haproxy:stats 
       balance roundrobin 
       cookie LBN insert indirect nocache 
       option httpclose 
       option forwardfor 
       server web01 192.168.100.2:80 cookie node1 check 
       server web02 192.168.100.3:80 cookie node2 check 
```
"listen webfarm \*:80" 定义了负载均衡器监听的地址和端口。为了教程的需要，我设置为 "\*" 表示监听在所有接口上。在真实的场景汇总，这样设置可能不太合适，应该替换为可以从 internet 访问的那个网卡接口。
```
stats enable 
stats uri /haproxy?stats 
stats realm Haproxy\ Statistics 
stats auth haproxy:stats 
```
上面的设置定义了，负载均衡器的状态统计信息可以通过 http:///haproxy?stats 访问。访问需要简单的 HTTP 认证，用户名为 "haproxy" 密码为 "stats"。这些设置可以替换为你自己的认证方式。如果你不需要状态统计信息，可以完全禁用掉。
下面是一个 HAProxy 统计信息的例子
![](/data/attachment/album/201501/27/221130jkj3bc5000v0jp0j.jpg)
"balance roundrobin" 这一行表明我们使用的负载均衡类型。这个教程中，我们使用简单的轮询算法，可以完全满足 HTTP 负载均衡的需要。HAProxy 还提供其他的负载均衡类型：
* **leastconn**：将请求调度至连接数最少的服务器­
* **source**：对请求的客户端 IP 地址进行哈希计算，根据哈希值和服务器的权重将请求调度至后端服务器。
* **uri**：对 URI 的左半部分（问号之前的部分）进行哈希，根据哈希结果和服务器的权重对请求进行调度
* **url\_param**：根据每个 HTTP GET 请求的 URL 查询参数进行调度，使用固定的请求参数将会被调度至指定的服务器上
* **hdr(name**)：根据 HTTP 首部中的  字段来进行调度
"cookie LBN insert indirect nocache" 这一行表示我们的负载均衡器会存储 cookie 信息，可以将后端服务器池中的节点与某个特定会话绑定。节点的 cookie 存储为一个自定义的名字。这里，我们使用的是 "LBN"，你可以指定其他的名称。后端节点会保存这个 cookie 的会话。
```
server web01 192.168.100.2:80 cookie node1 check 
server web02 192.168.100.3:80 cookie node2 check 
```
上面是我们的 Web 服务器节点的定义。服务器有由内部名称（如web01，web02），IP 地址和唯一的 cookie 字符串表示。cookie 字符串可以自定义，我这里使用的是简单的 node1，node2 ... node(n)
启动 HAProxy
----------
如果你完成了配置，现在启动 HAProxy 并验证是否运行正常。
### 在 Centos/RHEL 中启动 HAProxy
让 HAProxy 开机自启，使用下面的命令
```
# chkconfig haproxy on
# service haproxy start 
```
当然，防火墙需要开放 80 端口，像下面这样
#### CentOS/RHEL 7 的防火墙
```
# firewall­cmd ­­permanent ­­zone=public ­­add­port=80/tcp
# firewall­cmd ­­reload 
```
#### CentOS/RHEL 6 的防火墙
把下面内容加至 /etc/sysconfig/iptables 中的 ":OUTPUT ACCEPT" 段中
```
­A INPUT ­m state ­­state NEW ­m tcp ­p tcp ­­dport 80 ­j ACCEPT 
```
重启**iptables**：
```
# service iptables restart 
```
### 在 Debian 中启动 HAProxy
启动 HAProxy
```
# service haproxy start 
```
不要忘了防火墙开放 80 端口，在 /etc/iptables.up.rules 中加入：
```
­A INPUT ­p tcp ­­dport 80 ­j ACCEPT 
```
### 在 Ubuntu 中启动HAProxy
让 HAProxy 开机自动启动在 /etc/default/haproxy 中配置
```
ENABLED=1 
```
启动 HAProxy：
```
# service haproxy start 
```
防火墙开放 80 端口：
```
# ufw allow 80 
```
测试 HAProxy
----------
检查 HAProxy 是否工作正常，我们可以这样做
首先准备一个 test.php 文件，文件内容如下
```
```
这个 PHP 文件会告诉我们哪台服务器（如负载均衡）转发了请求，哪台后端 Web 服务器实际处理了请求。
将这个 PHP 文件放到两个后端 Web 服务器的 Web 根目录中。然后用 curl 命令通过负载均衡器（192.168.100.4）访问这个文件
```
$ curl http://192.168.100.4/test.php 
```
我们多次运行这个命令此时，会发现交替的输出下面的内容（因为使用了轮询算法）：
```
Server IP: 192.168.100.2
X-Forwarded-for: 192.168.100.4
```
---
```
Server IP: 192.168.100.3
X-Forwarded-for: 192.168.100.4
```
如果我们停掉一台后端 Web 服务，curl 命令仍然正常工作，请求被分发至另一台可用的 Web 服务器。
总结
--
现在你有了一个完全可用的负载均衡器，以轮询的模式对你的 Web 节点进行负载均衡。还可以去实验其他的配置选项以适应你的环境。希望这个教程可以帮助你们的 Web 项目有更好的可用性。
你可能已经发现了，这个教程只包含单台负载均衡的设置。这意味着我们仍然有单点故障的问题。在真实场景中，你应该至少部署 2 台或者 3 台负载均衡以防止意外发生，但这不是本教程的范围。
如果你有任何问题或建议，请在评论中提出，我会尽我的努力回答。
---
via: 
作者：[Jaroslav Štěpánek](http://xmodulo.com/author/jaroslav) 译者：[Liao](https://github.com/liaoishere) 校对：[wxy](https://github.com/wxy)
本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创翻译，[Linux中国](http://linux.cn/) 荣誉推出