four sub-metrics:
• Conﬁdence: How conﬁdent the user was that they could
implement this advice.
• Time Consumption: How time consuming the respondent
thought it would be to implement this piece of advice.
• Disruption: How disruptive the user thought it would be
to implement this advice.
• Diﬃculty: How diﬃcult the user thought it would be to
implement this advice.
each evaluated on a 4-point Likert scale from “Not at All” to
“Very.” The full questionnaire, which included an example to
help respondents distinguish among the diﬀerent sub-metrics,
is included in Appendix C. Each imperative was evaluated
by three respondents, and each respondent evaluated ﬁve ran-
domly drawn imperatives.
These four sub-metrics align with theoretical foundations
relevant to security behavior. The conﬁdence sub-metric is
drawn from Protection Motivation Theory [52], which identi-
ﬁes perceived ability to protect oneself as a key component
of protective behavior implementation, and from the Human
in the Loop model [12], which identiﬁes knowledge acquisi-
tion—knowing what to do with information—as a key com-
ponent of security behavior change. The time-consumption
and disruption sub-metrics are created to align with the “cost”
of the behavior, which has been found to be an important
decision-making factor in economic frameworks of secure
behavior [3, 23, 47, 48]. Finally, the diﬃculty sub-metric is
used to align with the capabilities component of the Human
in the Loop model [12].
Perceived eﬃcacy. We also use human-generated data to
measure the perceived eﬃcacy of the advice imperatives. We
asked professional security experts (see qualiﬁcation criteria
below) to answer an evaluation questionnaire for each piece of
security advice. Each advice imperative was again evaluated
by three respondents. The eﬃcacy questionnaire evaluated, for
each advice imperative, Perceived eﬃcacy: whether the expert
believed that a typical end user following this advice would
experience an improvement in, no eﬀect on, or harm to their
92    29th USENIX Security Symposium
USENIX Association
USENIX Association
29th USENIX Security Symposium    93
four randomly drawn documents.
4.2 Human Subjects Recruitment
For measurements conducted with the general population
(measurements of actionability and comprehensibility), we
recruited users from the survey research ﬁrm Cint’s6 survey
panel, which allows for the use of quota sampling to ensure
our respondents’ demographics were representative of the
U.S. population within 5% on age, gender, race, education
and income. We recruited a total of 1,586 users in June 2019
to evaluate the actionability and comprehensibility of our
security advice. Participants were compensated in accordance
with their agreement with Cint.
The eﬃcacy measurements were conducted with profes-
sional security experts. We recruited experts during May and
June 2019. We did so by tweeting from the lead author’s
Twitter account, asking well-known security Twitter accounts
to retweet, and leveraging our personal networks. We also
posted in multiple professional LinkedIn groups and con-
tacted authors of security blogs. All recruited individuals
completed a screening questionnaire to assess their security
credentials, including what security certiﬁcations they held,
whether they had ever participated in a CTF, what security
blogs or publications they read, whether they had ever had
to write a program that required them to consider security
implications, whether they had ever penetration-tested a sys-
tem, and their current job title. We also asked them to upload
their resume or link to their personal website so that we could
verify their credentials. We considered anyone who had done
two or more of: participating in a CTF, penetration testing a
system, and writing programs that required them to consider
security implications, OR who held security certiﬁcations
(including computer security professors) to be an expert. Ul-
timately, 41 qualiﬁed experts evaluated our security advice.
The majority of our experts were practitioners; only three
were academics. Our experts have diverse workplace con-
texts: engineer through director-level information security
professionals for large corporations and government agen-
cies, red team/pen testers, independent security consultants,
and privacy-focused professionals at large and well-known
non-proﬁt/advocacy organizations. Experts were paid $1 for
each piece of advice they evaluated. Advice was evaluated
in batches of 10; experts were allowed to complete as many
batches as desired and were able to skip previously-evaluated
pieces of advice. On average, experts evaluated 38 pieces of
advice each.
4.3 Measurement Validity
We evaluate the validity of our measurements in two ways:
(1) we check the reliability of ratings provided by our user
6https://www.cint.com/reach-survey-respondents/
and expert evaluators, again using the ICC metric (see Sec-
tion 3) and (2) we examine whether these quality measures are
discriminant, whether they correlate with behavior adoption
(the ultimate goal of security advice), and, where possible,
whether we reproduce results of prior work on security advice.
We report on (1) here and point the reader to Section 9 for the
results of (2).
Overall, all of our evaluators achieved at least “good” relia-
bility in evaluating our three metrics of advice quality [27].
For actionability, reliability was ”very good”: ICC = 0.896,
0.854, 0.868, and 0.868 for conﬁdence, time consumption,
disruption, and diﬃculty, respectively. For eﬃcacy, the ex-
perts achieved “very good” reliability, with an ICC of 0.876,
and for comprehensibility, our Cloze raters had “excellent”
reliability (ICC=0.989), while our ease raters achieved “good”
reliability (ICC = 0.757).
4.4 Limitations
As with all measurement and user studies, our work has cer-
tain inherent limitations. First, it is possible that our security
advice corpus is not fully representative of the ecosystem of
security advice. We used multiple techniques — soliciting
advice recommendations from experts, two methods for col-
lecting search queries from users — to ensure broad coverage
of advice in order to mitigate this potential limitation. Sec-
ond, it is possible that our manual annotation process was
inaccurate. We conducted a double annotation of over 10% of
our documents, achieving “suﬃcient” inter-annotator agree-
ment before proceeding to annotate independently, to mitigate
this risk; further, both coders conducted a full review of each
other’s taxonomies once annotation was ﬁnished, and reached
a ﬁnal, cohesive taxonomy that was applied to all documents.
Third, we cannot capture all possible types of relevant exper-
tise. To minimize data collection, we screened our experts
for expertise but explicitly did not collect demographic data;
examining how experts’ sociodemographic backgrounds may
aﬀect how experts prioritize advice may be an exciting direc-
tion for future work.
Fourth, due to the volume of advice, experts and users eval-
uated advice in the abstract and did not evaluate all advice.
We ﬁnd, through a X2 proportion test, that there is not a sta-
tistically signiﬁcant diﬀerence between the priority ratings of
the 26 experts who rated less than 30 pieces of advice and the
15 who rated more advice; however, lack of a full sense of the
dataset may still have aﬀected prioritization.
Fifth, our instantiations of our metrics may not provide a
full picture of the comprehensibility, perceived eﬃcacy, and
perceived actionability of our documents. To mitigate this
limitation, we relied upon established, validated tools from li-
brary science and NLP [49,65] and constructed questionnaires
that we robustly pre-tested using techniques such as cognitive
interviewing, following survey methodology best practice for
mitigating self-report biases such as social desirability [44].
94    29th USENIX Security Symposium
USENIX Association
USENIX Association
29th USENIX Security Symposium    95
Advice
Apply the highest level of security that’s practical
Be wary of emails from trusted institutions
Beware of free VPN programs
Change your MAC address
Change your username regularly
Consider opening a credit card for online use only
Cover your camera
Create a network demilitarization zone (DMZ)
Create keyboard patterns to help remember passwords
Create separate networks for devices
Disable automatic download of email attachments
Disable Autorun to prevent malicious code from running
Disconnect from the Internet
Do online banking on a separate computer
Encourage others to use Tor
Encrypt cloud data
Encrypt your hard drive
Isolate IoT devices on their own network
Keep sensitive information on removable storage media
Leave unsafe websites
Limit personal info being collected about you online
Lock your SIM card in your smartphone
Not blindly trust HTTPS
Not change passwords unless they become compromised
Not identify yourself to websites
Not let computers or browsers remember passwords
Not overwrite SSDs
Not send executable programs with macros
Not store data if you don’t need to
Not use credit or debit cards online
Not use encryption when sending e-mail to a listserv
Not use extensions or plugins
Not use Facebook
Not use your real name online
Not write down passwords
Remove unsafe devices from the network
Run a virus scan on new devices
Set up auto-lock timers for your smartphone
Turn oﬀ Bluetooth
Understand who to trust online
Unmount encrypted disks
Use a password manager
Use an air gap
Use an unbranded smartphone
Use diﬀerent computers for work and home use
Use encryption
Use incognito mode
Use single sign-on SSO
Use unique passwords
Not
Conﬁdent
✗
Very Time
Consuming
✗
Very
Disruptive
Very
Diﬃcult
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
Eﬃcacy
All Accurate
All Accurate
All Accurate
Majority Accurate
Majority Useless
All Useless
Majority Accurate
Majority Accurate
Majority Useless
Majority Accurate
All Accurate
All Accurate
All Accurate
All Accurate
Majority Accurate
Majority Accurate
All Accurate
Majority Accurate
Majority Accurate
Majority Accurate
Majority Accurate
No Consensus
Majority Accurate
All Harmful
Majority Accurate
Majority Accurate
All Accurate
All Accurate
All Accurate
Majority Useless
Majority Useless
Majority Accurate
Majority Accurate
All Accurate
Majority Accurate
All Accurate
All Accurate
All Accurate
All Accurate
All Accurate
All Accurate
All Accurate
Majority Accurate
All Useless
All Accurate
All Accurate
Majority Accurate
All Accurate
All Accurate
Risk
Reduced
50%
25%
30%
32.5%
NA
NA
30%
27.5%
NA
40%
40%
50%
25%
32.5%
25%
45%
5%
20%
22.5%
22.5%
15%
NA
20%
-30%
30%
45%
45%
20%
40%