among the images and texts.
Table 5: Various image-to-image and image-to-text dis-
tances.
Distance
(1) dist(I1, I2) (img-to-img)
(2) dist({I1, I2}, {IDecoy}) (img-to-decoy)
(3) dist({I1, I2}, {IT1,T2}) (img-to-txt)
(4) dist(T1,T2) (txt-to-txt)
Avg. (std.)
0.240 (0.113)
0.480 (0.021)
0.000 (0.000)
0.003 (0.003)
Table 5 shows that the average correlation between the two
user-provided images that are used as passwords was 0.240, and the
standard deviation was 0.113. Therefore, we can observe that users
provided two images have fairly low correlation and users seem to
submit dissimilar images. While correlations between images and
decoy images are higher with 0.480. This shows that close to half
of decoy images (about 20 images) are in the same category and
make it difficult to guess.
The average distance between first user-provided image and first
text password and second user-provided image and second text
password was 0. Therefore, PassTag generates highly uncorrelated
adversarial images, which can mitigate the machine learning attack-
ers. Additionally, the average distance between the text passwords
Session 2: Authentication ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan67was 0.00 and the standard deviation was 0.003 as shown in Table 5.
This clearly confirms that users do not provide the related textual
passwords.
9.1 Error Analysis on User Inputs
Image Input Errors: The overall success rate of image selection
was 97.1% as shown in Table. 4. To understand the reasons for
failures to recall images, Fig. 7 shows the percentage of the types
of image input errors made during authentication, where we show
them as red bars. 72% of the errors (“Left Empty") were due to users
not selecting an image when their image was displayed. 21% of the
errors (“Incorrect Image”) were due to users selecting an incorrect
image when their image was displayed alongside it. Lastly, 7% of
the errors (“Unnecessary Selection”) were due to users selecting
an incorrect (decoy) image when no correct image was displayed.
We can conclude from the results that valid users rarely select the
decoy images set by PassTag. Majority of the errors were made
when a correct image was presented to the users (94%). We observed
that users were able to more accurately discern decoy images than
recognizing their correct image. We also noticed that users made
more errors during the 1st and 2nd attempts which may be due to
being initially unfamiliar with the system design. Additional reason
for the high error rate of users not selecting an image when it was
displayed could be due to the display scheme of PassTag which
presents 40 images in 150x150 pixels. A different quantity and
quality of images and sizes in which they are displayed could allow
users to better recognize they images and improve the error rate.
We leave this study for future work.
Textual Password Errors: We initially categorized textual er-
rors into two categories as easily fixable errors (e.g. spacing) shown
in blue bars and complex errors (e.g. unnecessary input) in purple
bars as shown in Fig. 7. The “complex error” criterion is for when
users’ inputs are completely different from their original passwords
(colored in purple bar), and the “fixable error” means it matches the
entire strings but misses capitalization, spacing between words or
similar words (colored in blue bar). As shown in Fig. 7, only 35%
of textual errors were complex errors. The 65% fixable errors rate
leads us to believe that users were able to get an idea of what the
text password was but not the exact text itself. We further catego-
rized the types of textual errors users made in PassTag as shown in
as shown in Fig. 7 we categorized the errors into 7 categories: 1)
Spacing (e.g., favoritememory vs. favorite memory); 2) totally incor-
rect submission; 3) similar word was provided (e.g., hungry4food
vs. starving4food); 4) capitalization errors (e.g., 9312happytimes vs.
9312Happytimes); 5) unnecessary input as wrong image to text com-
bination (I1 + T1) vs. (I1 + T2); 6) spelling errors (e.g., b4nn4nap0p vs
bannanapop); or 7) additional words were added (e.g., workSunday
vs myworkSunday). Our analysis showed that the types of textual
errors users made by the users appear to be minor and show that
majority of the user seem to recall the gist of what their original
password was.
User Sentiment: At the end of the authentication study, we
asked participants to provide feedback through a survey created
about the usability and memorability of PassTag. We asked each
participant to answer questions shown in Table 2 regarding their
experience in 1 to 7 scale. The score 1 being strongly disagree, 4
Figure 7: Histogram of textual and image input errors.
being neither agree or disagree, and 7 being strongly agree. The
results are summarized in Fig. 8.
For Q1. “whether the solving time was reasonable”, the average
score was 6.11, median was 6. And for Q2, “if successfully logging in
with the authentication system was reasonable”, the average score
was 6.24, median was 6, and standard deviation was .95. Lastly
for Q3, “if it was easy to use the authentication system”, the av-
erage score was 6.09, median was 6, and standard deviation was
1.04. Therefore, most participants agreed that PassTag was quite
usable and found the time it took to complete registration and
authentication to be reasonable.
For memorability, when Q4 was asked “if it was easier to remem-
ber the images than the text passwords”, the average score was 6.17,
median was 6.15. Conversely, when asked question Q5, “if it was
easier to remember the text passwords than the images”, the average
score was 3.19, and median was 3. Hence, we confirm the effective-
ness of the picture superiority as users found images to be easier
to recall than textual passwords. For question Q6, “if looking at the
images helped users remember the text passwords”, the average
score was 5.35, and median was 6. Therefore, we can demonstrate
the effectiveness of and level-of-processing effect, where the images
are viable to be used as cues to remember text passwords. Lastly,
when asked question Q7, “if the images that were generated by the
authentication system was similar to the user-provided images”,
the average score was 5.76, and median was 6. This suggests that
the decoy images generated by PassTag are similar to user-provided
images. This allows for an even and consistent distribution of im-
ages to be displayed making it difficult for attackers to specifically
distinguish a specific single image.
10 STUDY 3: LONG TERM MEMORABILITY
COMPARISON WITH SECURITY
QUESTIONS
Our initial motivation for designing PassTag with decoy images was
to create a memorable and secure fallback authentication scheme.
To evaluate PassTag against this motivation, we experimentally
evaluated PassTag against another comparable baseline security
questions, for three key performance measures: 1) long-term mem-
orability with infrequent authentication, 2) resilience to close ad-
versary attacks, and 3) authentication speed. Long-term memo-
rability after extended disuse was our key measure of interest,
Session 2: Authentication ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan68Table 6: Security Questions used by the top four webmail ser-
vice providers
Security Question
What is your favorite food?
What is your pet’s name?
Where were you born?
What is your favorite restaurant?
What is the name of your school?
Who is your favorite singer?
What is your favorite song?
What is your favorite film?
What is your favorite book?
What was your first job?
What was your first teacher’s name?
What is your first phone number?
Where was your mother’s birthplace?
Who was your best childhood friend?
Who was your favorite teacher?
Who is your favorite historical person?
What was the name of your first school?
Who was your childhood hero?
What is your favorite sports team?
What is your father’s middle name?
Selected by User
7.5%
5%
10%
17.5%
0%
0%
10%
15%
0%
5%
12.5%
0%
7.5%
5%
0%
0%
0%
5%
0%
0%
within three attempts. Another memorability test was conducted
in a third session that took place one month after the second one
(i.e. two months after the first session). Users were instructed to
perform the same tasks as they had for the second session.
Final Session: One month after the third session, we invited
users to a long-term evaluation in attempt to simulate a realistic
fallback authentication scenario in which length time between en-
rollment and required fallback authentication had passed. Users
performed the same procedure as similar to the second and third
session. At the end of the sessions, we asked users to provide feed-
back through a survey created about the usability and memorability
of each authentication scheme.
11 RESULTS OF STUDY 3
Demographics: We recruited 80 participants (53 men 27 women)
from our campus. The age of the participants varied between 18 and
over 65. The age group of 20 to 29 was most represented with 58
participants. The relationship between the users and their close ad-
versaries was as follows: 16 participants brought their close friend,
7 brought their partner, 5 brought their spouse, and 2 brought their
sibling. They received $10 gift vouchers for their participation.
Memorability: We first tested the hypothesis that graphical se-
crets in PassTag should be more memorable than security questions.
We found strong evidence in support of this hypothesis. Table 7
shows the percentage of participants successfully authenticated
in each scheme within three attempts. Overall, 95.0% of our par-
ticipants (19/20) could recall the secrets in PassTag within three
attempts even after the third month, compared to just 55.0% (11/20)
who could recall the security questions, showing statistical signifi-
cance (FET test with one tailed, p=0.04 < 0.05).
Figure 8: Participant ratings (Q1. Authentication time
was reasonable, Q2. Successfully authenticating using
PassTag was reasonable, Q3. It was easy to use PassTag, Q4. It
was easier to remember the images than the text passwords,
Q5. It was easier to remember the text passwords than the
images, Q6. The images that were generated by PassTag were
similar to my images, and Q7. Looking at the images helped
me remember my password in Table 2).
because PassTag is designed for fallback authentication, where se-
crets should be easily memorable for long-term without a lot of
repetitions. Next, we tested for resilience against close adversaries
such as close friends, sibling, and spouse to measure the strength of
decoy images and as security questions come with shortcomings in
this aspect [33]. Lastly, we selected authentication speed because
of its importance in usability and deployability.
First Session: We conducted a between-subject user study with
80 participants in our lab. While users (40 participants) had to par-
take in all four time-separated sessions in creating and authenticat-
ing with one of the three authentication scheme, close adversaries
(40 participants) only had to come for the first session. 40 partic-
ipants were instructed to create an authentication secret on one
of the authentication scheme (20 participants per scheme). Each
scheme was randomly assigned for each participant and the com-
plexity of the secrets were selected to be very similar on average –
our security questions scheme used questions which are provided
by popular webmail providers [35] and contained identical set of
questions in relation to the images deployed by PassTag. The secu-
rity questions and participant selections are provided in Table 6.
Close adversaries were asked to leave the lab and wait, while
users created authentication secrets for their assigned authentica-
tion scheme. Identical to creation in PassTag, users in all authenti-
cation schemes were given three attempts to correctly select and
create authentication secrets. Once users completed creating their
authentication secrets, we asked users to leave the lab and invited
the close adversaries in. Close adversaries had five attempts to cor-
rectly choose the images and the security questions, along with the
corresponding answers. Close adversaries were allowed to use the
Internet and their phones for research.
Second and Third Session: One month after the first session,
we invited users back to perform another memorability test. Again,
users had to answer their three questions from the first session
Session 2: Authentication ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan69Table 7: Participants that successfully remembered their au-
thentication secrets.
Scheme
PassTag
Security Questions
One Month Two Month Three Month
95.0%
65.0%
95.0%
60.0%
95.0%
55.0%
Figure 9: Box plot of the authentication time distributions
for PassTag and security questions.
Resilience to Close Adversaries: We next tested the hypoth-
esis that PassTag should be more resilient to shoulder surfing at-
tack than security questions authentication. We also found strong
evidence in support of this hypothesis. None (0/20) of the close
adversaries were able to correctly authenticate PassTag compared
to 30.0% (6/20) who were able to correctly answer the security ques-
tions. This result also shows statistical significance (FET test with
one-tailed, p=0.04 < 0.05), demonstrating it is significantly harder
for close adversaries to guess PassTags than security questions.
Authentication Speed: Lastly, we measured the authentication
speeds of PassTag and security questions. Fig.9 shows the distribu-
tions of how long it took participants to authenticate in PassTag,
and security questions. while the average authentication time of
PassTag was 53.9 secs on average users were able to authenticate
quicker for security questions with 38.2 secs on average (t-test, p
≪ 0.001).