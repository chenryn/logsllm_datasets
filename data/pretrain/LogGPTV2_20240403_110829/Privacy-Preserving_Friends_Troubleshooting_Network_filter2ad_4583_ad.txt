average.) We have: E(Nc) =
where
Pown is the percent of users that own the application under
troubleshooting, i denotes the cluster size, P (G = i) is the
percent of clusters with size i, and Ph,i is the probability to
help according to cluster size i for a given innocence level.
With the common friends’ statistics from our MSN IM friends
network topology (Section V-B), we estimate P (G = i) · i
as P (F = i) · i · (1 − Poverlap), where P (F = i) denotes
the percentage of users with i friends, and Poverlap is the
percentage of the cluster entrance’s friends that have already
seen the request (and hence will not join its cluster). According
to overlapping friends distribution, neighboring nodes have
14.15% of common friends in average, and since neighboring
cluster entrances are two hops away, one can estimate the
l=2(0.1415)l = 2.33%, where
upper bound of Poverlap as
(0.1415)l approximates the percentage of common friends
between the current cluster entrance and a previous cluster
entrance that is l hops away.
(cid:80)∞
2) Innocence Level Vs. Number of Clusters: Now, we use
the MSN IM friendship topology to evaluate the trade-off
between privacy (I) and average number of clusters (E(Nc))
involved in a troubleshooting event. We assume that Pown = 1
(e.g., the application under troubleshooting is very popular).
We impose an upper bound on the cluster size to 36 for limit-
ing the intra-cluster communication overhead. This reduces the
average number of nodes in a cluster to 14 based on our MSN
IM data. Table I shows the expected number of clusters and
nodes needed to obtain 10 samples (with which PeerPressure is
already effective [17]) using the static IM friendship topology
(Figure 3) for achieving nine different innocence levels. We
00.050.10.150.20.250.30.350.40.454681012141618202224262830323436Cluster SizeProbability to Help (Ph)I = 1I = 2I = 3I = 4I = 5I = 6I = 7I = 8I = 9Innocence Level
Expected # Clusters
Expected # Nodes Involved
Avg # Clusters in Simulation
Avg # Nodes Involved in Simulation
1
2.02
28
2
27.6
2
2.82
39.4
3.1
44.5
3
3.67
51.4
3.59
47.47
4
4.62
64.69
4.55
69.2
5
5.68
79.55
5.78
85.9
6
6.91
96.8
6.75
92.5
7
8.3
116.2
8.18
120.35
8
9.84
137.82
9.49
140.4
9
11.65
163.11
11.27
162.3
AVERAGE NUMBER OF CLUSTERS AND NODES INVOLVED TO OBTAIN 10 SAMPLES
TABLE I
Fig. 5. The average number of clusters required to obtain 10 samples for
different threshold helping strategies.
Fig. 7. The estimated average response time for enterprise users (5 Mbps
available bandwidth) and home users (100 Kbps available bandwidth)
hash function. If we use six 16-valued hash function, and
we reserve 1 byte for the count, the troubleshooting request
message is about 100 KB. If we choose the 20 top-ranking
entries as the root-cause candidates, and reserve 1024 bytes
to aggregate the sum of the most popular value, the second
round query message is approximately 20 KB. (Of course, the
requests can be compressed to save network bandwidth.)
During the process of cluster aggregation, each participant
has to transmit M ∗ G KB information, where M KB is the
troubleshooting message size. Each node on the return path
only needs to transmit M KB information. The number of
clusters involved on the forwarding path is E(Nc) on average.
The return path has 2E(Nc) nodes, since the entrance and exit
nodes of each cluster on the forwarding path are both involved
to propagate the reply back along the return path. Figure 7
depicts the estimated average response time for an enterprise
user with 5 Mbps available bandwidth for troubleshooting, and
a broadband home user with bandwidth of 100 Kbps, when
cardinality is unknown, to achieve nine different innocence
levels.
Also, we can estimate the timeout
that a node on the
forwarding path should set. The average hop length to obtain
10 samples under innocence level 6 is AvgHopLen = 1/(1−
¯Pf ) = 6.9, where ¯Pf = 0.855 is the average probability
of forwarding the request from one cluster to another. The
variance of the hop length is var = ( ¯Pf )/((1− ¯Pf )2). Hence,
we have AvgHopLen + 3 · √
var = 26. The cumulative
(L−1)(1 −
probability of all hop lengths ≥ 26 is
¯Pf ) = ¯Pf
¯Pf
L = ¯Pf
44 = 0.001. Therefore,
we choose 26 to estimate the upper limit of the hop length,
and set the timeout to be 1.6 minutes for an enterprise user
with 5 Mbps bandwidth, and 67 minutes for a home user with
100 Kbps bandwidth.
44(1 − ¯Pf )
(cid:80)∞
(cid:80)∞
L=0
¯Pf
L=45
Fig. 6. Local Processing Time Vs. Number of Suspects for 20 Real-world
Troubleshooting Cases.
VI. PROTOTYPE IMPLEMENTATION AND PERFORMANCE
We have prototyped an FTN system in C#. In our im-
plementation, aside from Ph, we also set a help budget, in
the unit of “requests per friend per day”, for FTN nodes to
control the rate of conﬁguration state exposure. In addition, a
disk budget is conﬁgured by an FTN user to set aside for
maintaining FTN protocol state such as previous and next
hops for respective ReqID’s that have been traversing the
node. The disk budget is fair-shared among the node’s active
troubleshooting friends. Figure 6 shows the local processing
times for the 20 troubleshooting cases under study [17]. The
processing time grows with the number of suspect entries.
In terms of bandwidth overhead, for the troubleshooting
cases [17] we evaluated with, there is a median of 1171 suspect
entries. When cardinality is unknown, the size of the value
distribution ﬁeld depends on the range of the small-valued
051015202530354045123456789Innocence LevelAverage Number of Clusters Required toObtain 10 SamplesT=0T=1T=2T=300.511.522.538591052137179451303233729754371Number of SuspectsLocal Processing Time (Second)051015202530354045123456789Innocence LevelEstimated Response TimeEnterprise User (sec)Home User (min)VII. RELATED WORK
There is much related work in the area of anonymization.
The random walk approach is also those used in FreeNet [5]
and Crowds [14]. FreeNet is a distributed anonymous infor-
mation storage and retrieval system. Crowds provides anony-
mous web transactions. Other anonymization system are based
on Chaum’s mixes [4], which serve as proxies to provide
sender-receiver unlinkability through trafﬁc mixing. Onion
routing [10] extends the mixes with layers of onion-style pre-
encryptions. Tarzan [7] implements the mix idea using a peer-
to-peer overlay and provides sender anonymity and robustness
to the mix entry point.
All of the above anonymization techniques address point-to-
point communications. However, our protocol in FTN involves
one-to-many communication, in the form of broadcasting a
troubleshooting request to peers. This broadcast should be
limited according to the friend relationships, which is more
naturally implemented using a peer-to-peer overlay. Further, as
discussed in Section III, our recursive trust model requires that
the conﬁguration data be transmitted between friends. Fully
anonymous conﬁguration data arriving over a mix network
could not be trusted to be authentic, as only friends can
be trusted not
to contribue false and potentially harmful
information about their conﬁgurations.
Canny [3] proposed a collaborative ﬁltering algorithm to
allow a community of users to compute a public aggregate
of their data without exposing individual users’ data. In his
scheme, homomorphic encryption[2] is used to anonymously
aggregate encrypted user data and the decryption key is not
held by any single person but instead secret-shared among
all the clients. The FTN targets a highly dynamic friends
community where users join and leave all the time. The key
share generation process would incur a high cost since new
shares would have to be generated every time a user joins.
Furthermore, the collaborative ﬁltering algorithm is designed
for a known, ﬁxed set of items, while the set of values for
conﬁguration entries relevant to troubleshooting requests is not
known ahead of time.
Similarly, the well known secure multiparty sum protocol
enables aggregation without revealing individual private con-
tributions; however, this protocol only supports aggregations
of ﬁxed-length vectors. We use the secure sum protocol as
a building block, but we extend it to support counting the
number of distinct values in a set, as well revealing the
most popular value, while keeping the individual contributions
private. We also make sure to send the results of the aggregate
to a single node, different than the cluster entrance, such that
collusion between at least two nodes is required to ﬁnd out
the cluster-wide sum.
Another technique for privacy-preserving data aggregation
is to introduce random perturbations [1] at each input. The
idea is that these perturbations would not signiﬁcantly affect
the aggregate, while hiding individual contributions. However,
this is only true when a large number of samples are collected;
with only 10 samples needed for PeerPressure, the random
noise would signiﬁcantly impact ranking accuracy. Increasing
the number of samples for effective noise ﬁltering would un-
acceptably increase the overhead of troubleshooting requests.
Our problem of privacy-preserving parameter aggregation
shares much similarity to the problem of secure and privacy-
preserving voting [8], [2] with three distinctions. First, voting
requires voters to be authenticated by a centralized authority,
such as the government. Second, our protocol has an additional
requirement of participation privacy; otherwise, the privacy of
the application ownership is compromised. Lastly, most voting
scenarios involve a ﬁxed, limited number of voting chances,
while our troubleshooting problem does not.
The authors of SIA[13] presented a set of techniques for
secure information aggregation in sensor networks with the
presence of malicious sensors and aggregators. The integrity
of information aggregation is achieved essentially through
authentication which is identity-revealing. In FTN, we cannot
do the same because of the privacy concerns.
VIII. CONCLUSIONS
In this paper, we have presented the design, implementation,
and the evaluation of the Friends Troubleshooting Network, a
peer-to-peer overlay network that aggregates privacy-sensitive
conﬁguration data from peers to carry out PeerPressure-based
misconﬁguration root-cause diagnosis. The links between FTN
nodes reﬂect the friendship of their owners. The FTN man-
ifests recursive trust rather than transitive trust. In FTN, we
use a historyless and futureless random walk for integrated
search and cluster-based parameter aggregation to achieve pri-
vacy. We further introduce a cluster-based secure aggregation
protocol to ﬁnd the cardinality and mode of a collection of
values while preserving the privacy of individual contributions.
Many of our design decisions are guided by a real-world
friends network topology obtained from the MSN IM network.
FTN poses interesting tradeoffs between privacy and protocol
efﬁciency which we have analyzed in detail with the real-
world friends network data. The performance of our current
prototype allows enterprise users to diagnose misconﬁgura-
tions in a minute with a high privacy guarantee. We believe
our techniques can be applied to other application scenarios
that require privacy-preserving information aggregation.
IX. ACKNOWLEDGMENTS
Luis von Ahn, Josh Benaloh, David Brumley, John Duna-
gan, Yih-Chun Hu, David Jao, and Dan Simon have given us
invaluable discussions and critiques on the technical content,
as well as the presentation of this paper. We are grateful for
their help. We also thank the anonymous reviewers for their
insightful comments and suggestions.
REFERENCES
[1] Rakesh Agrawal and Ramakrishnan Srikant. Privacy Perserving Data
Mining. In Proceedings of SIGMOD, 2000.
[2] Benaloh. Veriﬁable Secret-Ballot Elections. PhD thesis, Yale University,
Sept. 1987.
[3] John Canny. Collaborative Filtering with Privacy. In IEEE Security and
Privacy, 2002.
[4] D. L. Chaum. Untraceable Electronic Mail, Return Addresses and
Digital Pseudonyms. In CACM, 1981.
[5] Ian Clarke, Oskar Sandberg, Brandon Wiley, and Theodore W. Hong.
Freenet: A distributed anonymous information storage and retrieval
system. In Proc. International Workshop on Design Issues in Anonymity
and Unobservability.
In Proceedings of International Workshop on
Design Issues in Anonymity and Unobservability, 2001. Lecture Notes
Computer Science Volume 2009.
[6] John R. Douceur.
The Sybil Attack.
In Proceedings of
the 1st
International Workshop on Peer-to-Peer Systems (IPTPS), 2002.
[7] Michael J. Freedman, Emil Sit, Josh Gates, and Robert Morris. Intro-
ducing Tarzan, a Peer-to-Peer Anonymizing Network Layer. In IPTPS,
2002.
[8] T. Fujioka, T. Okamoto, and K. Ohta. A Practical Secret Voting Scheme
for Large Scale Elections. In Proceedings of Auscrypt, Dec. 1992.
[9] The Gnutella v0.6 Protocol, Gnutella Development Forum, 2001.
[10] D. M. Goldschlag, M. G. Reed, and P. F. Syverson. Onion Routing for
Anonymous and Private Internet Connections. In CACM, Feb 1999.
[11] KaZaa. http://www.kazaa.com.
[12] Moni Naor. Bit Commitment Using Pseudo-Randomness. In Advanced
in Cryptology — CRYPTO ’89, pages 128–136, 1989.
[13] Bartosz Przydatek, Dawn Song, and Adrian Perrig.
SIA: Secure
Information Aggregation in Sensor Networks. In Proceedings of ACM
SenSys, Nov 2003.
[14] Michael K. Reiter and Aviel D. Rubin. Crowds: Anonymity for Web
Transactions. In ACM Transactions on Information and System Security,
Nov 1998.
[15] M Silver and L Fiering. Desktop and Notebook TCO Updated for the
21st Century, September 2003.
[16] Web-to-Host: Reducing the Total Cost of Ownership, The Tolly Group,
May 2000.
[17] Helen J. Wang, Yu Chen, John Platt, Ruyun Zhang, and Y. M. Wang.
PeerPressure, A Statistical Method towards Automatic Troubleshooting.
Technical Report MSR-TR-2003-80, Microsoft Research, Redmond,
WA, Nov 2003.
[18] Helen J. Wang, Yih-Chun Hu, Chun Yuan, Zheng Zhang, and Yi-Min
Wang. Friends Troubleshooting Network: Towards Privacy-Preserving,
Automatic Troubleshooting.
In Proceedings of the 3rd International
Workshop on Peer-to-Peer Systems (IPTPS), 2004.
[19] Yi-Min Wang, Chad Verbowski, John Dunagan, Yu Chen, Helen J.
Wang, Chun Yuan, and Zheng Zhang. STRIDER: A Black-box, State-
based Approach to Change and Conﬁguration Management and Support.
In Proceedings of LISA, 2003.