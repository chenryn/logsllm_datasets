### 1. Introduction to Expected Number of Clusters (E(Nc))

The expected number of clusters \( E(N_c) \) can be defined as:
\[ E(N_c) = \sum_{i} P(G = i) \cdot i \cdot P_{h,i} \]
where:
- \( P_{\text{own}} \) is the percentage of users who own the application under troubleshooting.
- \( i \) denotes the cluster size.
- \( P(G = i) \) is the percentage of clusters with size \( i \).
- \( P_{h,i} \) is the probability of a user helping, given the cluster size \( i \) and a specific innocence level.

### 2. Estimation of Cluster Size and Overlap

Using the common friends' statistics from the MSN IM friends network topology (Section V-B), we estimate \( P(G = i) \cdot i \) as:
\[ P(F = i) \cdot i \cdot (1 - P_{\text{overlap}}) \]
where:
- \( P(F = i) \) denotes the percentage of users with \( i \) friends.
- \( P_{\text{overlap}} \) is the percentage of the cluster entrance's friends who have already seen the request and will not join its cluster.

According to the overlapping friends distribution, neighboring nodes have an average of 14.15% common friends. Since neighboring cluster entrances are two hops away, the upper bound of \( P_{\text{overlap}} \) can be estimated as:
\[ P_{\text{overlap}} \approx 2 \times (0.1415)^2 = 2.33\% \]

### 3. Trade-off Between Privacy and Average Number of Clusters

We use the MSN IM friendship topology to evaluate the trade-off between privacy (I) and the average number of clusters \( E(N_c) \) involved in a troubleshooting event. We assume \( P_{\text{own}} = 1 \) (e.g., the application is very popular). We impose an upper bound on the cluster size of 36 to limit the intra-cluster communication overhead, reducing the average number of nodes in a cluster to 14 based on our MSN IM data.

Table I shows the expected number of clusters and nodes needed to obtain 10 samples for achieving nine different innocence levels using the static IM friendship topology (Figure 3).

| Innocence Level | Expected # Clusters | Expected # Nodes Involved | Avg # Clusters in Simulation | Avg # Nodes Involved in Simulation |
|-----------------|---------------------|---------------------------|--------------------------------|------------------------------------|
| 1               | 2.02                | 28                        | 2                              | 27.6                               |
| 2               | 2.82                | 39.4                      | 3.1                            | 44.5                               |
| 3               | 3.67                | 51.4                      | 3.59                           | 47.47                              |
| 4               | 4.62                | 64.69                     | 4.55                           | 69.2                               |
| 5               | 5.68                | 79.55                     | 5.78                           | 85.9                               |
| 6               | 6.91                | 96.8                      | 6.75                           | 92.5                               |
| 7               | 8.3                 | 116.2                     | 8.18                           | 120.35                             |
| 8               | 9.84                | 137.82                    | 9.49                           | 140.4                              |
| 9               | 11.65               | 163.11                    | 11.27                          | 162.3                              |

### 4. Network Overhead and Response Time

During the process of cluster aggregation, each participant transmits \( M \cdot G \) KB of information, where \( M \) KB is the troubleshooting message size. Each node on the return path transmits \( M \) KB of information. The number of clusters involved on the forwarding path is \( E(N_c) \) on average. The return path has \( 2E(N_c) \) nodes, as both the entrance and exit nodes of each cluster on the forwarding path are involved in propagating the reply back along the return path.

Figure 7 depicts the estimated average response time for an enterprise user with 5 Mbps available bandwidth and a home user with 100 Kbps bandwidth, to achieve nine different innocence levels.

### 5. Timeout Estimation

The timeout that a node on the forwarding path should set can be estimated. For example, under innocence level 6, the average hop length to obtain 10 samples is:
\[ \text{AvgHopLen} = \frac{1}{1 - \bar{P_f}} = 6.9 \]
where \( \bar{P_f} = 0.855 \) is the average probability of forwarding the request from one cluster to another. The variance of the hop length is:
\[ \text{var} = \frac{\bar{P_f}}{(1 - \bar{P_f})^2} \]
Thus, the upper limit of the hop length is:
\[ \text{AvgHopLen} + 3 \cdot \sqrt{\text{var}} = 26 \]
The cumulative probability of all hop lengths ≥ 26 is:
\[ \sum_{L=45}^{\infty} \bar{P_f}^L (1 - \bar{P_f}) = \bar{P_f}^{44} = 0.001 \]
Therefore, we choose 26 to estimate the upper limit of the hop length and set the timeout to be 1.6 minutes for an enterprise user with 5 Mbps bandwidth and 67 minutes for a home user with 100 Kbps bandwidth.

### 6. Prototype Implementation and Performance

We have prototyped an FTN system in C#. In our implementation, aside from \( P_h \), we also set a help budget in the unit of "requests per friend per day" to control the rate of configuration state exposure. Additionally, a disk budget is configured by an FTN user to set aside space for maintaining FTN protocol state such as previous and next hops for respective ReqID’s that have been traversing the node. The disk budget is fair-shared among the node’s active troubleshooting friends.

Figure 6 shows the local processing times for the 20 troubleshooting cases under study. The processing time grows with the number of suspect entries.

### 7. Related Work

There is extensive related work in the area of anonymization. The random walk approach is used in systems like FreeNet [5] and Crowds [14]. Other anonymization systems are based on Chaum’s mixes [4], which provide sender-receiver unlinkability through traffic mixing. Onion routing [10] extends the mixes with layers of onion-style pre-encryptions. Tarzan [7] implements the mix idea using a peer-to-peer overlay and provides sender anonymity and robustness to the mix entry point.

However, these anonymization techniques address point-to-point communications, while our protocol in FTN involves one-to-many communication in the form of broadcasting a troubleshooting request to peers. This broadcast should be limited according to the friend relationships, which is more naturally implemented using a peer-to-peer overlay.

Canny [3] proposed a collaborative filtering algorithm to allow a community of users to compute a public aggregate of their data without exposing individual users’ data. In his scheme, homomorphic encryption [2] is used to anonymously aggregate encrypted user data, and the decryption key is secret-shared among all clients. The FTN targets a highly dynamic friends community where users join and leave frequently, making the key share generation process costly.

Similarly, the secure multiparty sum protocol enables aggregation without revealing individual private contributions but only supports aggregations of fixed-length vectors. We extend this protocol to support counting the number of distinct values and revealing the most popular value while keeping individual contributions private.

Another technique for privacy-preserving data aggregation is to introduce random perturbations [1] at each input. However, this is only effective when a large number of samples are collected; with only 10 samples needed for PeerPressure, the random noise would significantly impact ranking accuracy.

Our problem of privacy-preserving parameter aggregation shares similarities with secure and privacy-preserving voting [8], [2] but has additional requirements such as participation privacy and no fixed number of voting chances.

### 8. Conclusions

In this paper, we presented the design, implementation, and evaluation of the Friends Troubleshooting Network (FTN), a peer-to-peer overlay network that aggregates privacy-sensitive configuration data from peers to carry out PeerPressure-based misconfiguration root-cause diagnosis. The links between FTN nodes reflect the friendship of their owners, and FTN manifests recursive trust rather than transitive trust. We use a historyless and futureless random walk for integrated search and cluster-based parameter aggregation to achieve privacy. Our prototype allows enterprise users to diagnose misconfigurations in a minute with a high privacy guarantee.

### 9. Acknowledgments

We thank Luis von Ahn, Josh Benaloh, David Brumley, John Dungan, Yih-Chun Hu, David Jao, and Dan Simon for invaluable discussions and critiques. We also thank the anonymous reviewers for their insightful comments and suggestions.

### 10. References

[1] Rakesh Agrawal and Ramakrishnan Srikant. Privacy-Preserving Data Mining. In Proceedings of SIGMOD, 2000.
[2] Benaloh. Verifiable Secret-Ballot Elections. PhD thesis, Yale University, Sept. 1987.
[3] John Canny. Collaborative Filtering with Privacy. In IEEE Security and Privacy, 2002.
[4] D. L. Chaum. Untraceable Electronic Mail, Return Addresses and Digital Pseudonyms. In CACM, 1981.
[5] Ian Clarke, Oskar Sandberg, Brandon Wiley, and Theodore W. Hong. Freenet: A distributed anonymous information storage and retrieval system. In Proc. International Workshop on Design Issues in Anonymity and Unobservability, 2001. Lecture Notes Computer Science Volume 2009.
[6] John R. Douceur. The Sybil Attack. In Proceedings of the 1st International Workshop on Peer-to-Peer Systems (IPTPS), 2002.
[7] Michael J. Freedman, Emil Sit, Josh Gates, and Robert Morris. Introducing Tarzan, a Peer-to-Peer Anonymizing Network Layer. In IPTPS, 2002.
[8] T. Fujioka, T. Okamoto, and K. Ohta. A Practical Secret Voting Scheme for Large Scale Elections. In Proceedings of Auscrypt, Dec. 1992.
[9] The Gnutella v0.6 Protocol, Gnutella Development Forum, 2001.
[10] D. M. Goldschlag, M. G. Reed, and P. F. Syverson. Onion Routing for Anonymous and Private Internet Connections. In CACM, Feb 1999.
[11] KaZaa. http://www.kazaa.com.
[12] Moni Naor. Bit Commitment Using Pseudo-Randomness. In Advanced in Cryptology — CRYPTO ’89, pages 128–136, 1989.
[13] Bartosz Przydatek, Dawn Song, and Adrian Perrig. SIA: Secure Information Aggregation in Sensor Networks. In Proceedings of ACM SenSys, Nov 2003.
[14] Michael K. Reiter and Aviel D. Rubin. Crowds: Anonymity for Web Transactions. In ACM Transactions on Information and System Security, Nov 1998.
[15] M Silver and L Fiering. Desktop and Notebook TCO Updated for the 21st Century, September 2003.
[16] Web-to-Host: Reducing the Total Cost of Ownership, The Tolly Group, May 2000.
[17] Helen J. Wang, Yu Chen, John Platt, Ruyun Zhang, and Y. M. Wang. PeerPressure, A Statistical Method towards Automatic Troubleshooting. Technical Report MSR-TR-2003-80, Microsoft Research, Redmond, WA, Nov 2003.
[18] Helen J. Wang, Yih-Chun Hu, Chun Yuan, Zheng Zhang, and Yi-Min Wang. Friends Troubleshooting Network: Towards Privacy-Preserving, Automatic Troubleshooting. In Proceedings of the 3rd International Workshop on Peer-to-Peer Systems (IPTPS), 2004.
[19] Yi-Min Wang, Chad Verbowski, John Dunagan, Yu Chen, Helen J. Wang, Chun Yuan, and Zheng Zhang. STRIDER: A Black-box, State-based Approach to Change and Configuration Management and Support. In Proceedings of LISA, 2003.