lacks this information for most schemes. The burden on
the end-user in migrating from passwords (distinct from
the deployability costs of modifying browser and server
infrastructure) is another important cost—both the one-time
initial setup and per-account transition costs. While ease
of resetting and revoking credentials falls within Easy-
Recovery-from-Loss, the beneﬁt does not include user and
system aspects related to ease of renewing credentials that
expire within normal operations (excluding loss). Other
missing cost-related beneﬁts are low cost for initial setup
(including infrastructure changes by all stakeholders); low
cost for ongoing administration, support and maintenance;
and low overall complexity (how many inter-related “moving
parts" a system has). We don’t capture continued availabil-
ity under denial-of-service attack, ease of use on mobile
devices, nor the broad category of economic and business
effects—e.g., the lack of incentive to be a relying party is
cited as a main reason for OpenID’s lack of adoption [28].
We have not attempted to capture these and other beneﬁts
in the present paper, though all ﬁt into the framework and
could be chosen by others using this methodology. Alas,
many of these raise a difﬁculty: assigning ratings might be
even more subjective than for existing beneﬁts.
C. Additional nuanced ratings
We considered, but did not use, a “fatal” rating to indicate
that a scheme’s performance on a beneﬁt is so poor that the
scheme should be eliminated from serious consideration. For
example, the 2–3 minutes required for authentication using
the Weinshall or Hopper-Blum schemes may make them
“fatally-non-Efﬁcient-to-Use”, likely preventing widespread
adoption even if virtually all other beneﬁts were provided.
564
We decided against this because for many properties, it isn’t
clear what level of failure to declare as fatal.
We also considered a “power” rating to indicate that
a scheme optionally enables a beneﬁt for power users—
e.g., OpenID could be rated “amenable-to-No-Trusted-Third-
Party” as users can run their own identity servers, in contrast
to Facebook Connect or Microsoft Passport. The popularity
of webmail-based password reset indicates most users ac-
cede to a heavily-trusted third party for their online identities
already, so “amenable-to” may sufﬁce for adoption. OpenID
is arguably amenable to every security beneﬁt for power
users, but doesn’t provide them for common users who
use text passwords to authenticate to their identity provider.
However, as one could argue for an amenable-to rating for
many properties of many schemes, we maintained focus on
properties provided by default to all users.
D. Weights and ﬁner-grained scoring
We reiterate a caution sounded at the end of Section II: the
beneﬁts chosen as metrics are not all of equal weight. The
importance of any particular beneﬁt depends on target use
and threat environment. While one could assign weights to
each column to compute numerical scores for each scheme,
providing exact weights is problematic and no ﬁxed values
would suit all scenarios; nonetheless, our framework allows
such an endeavour. For ﬁner-grained evaluation, table cell
scores like partially could also be allowed beyond our very
coarse {no, almost, yes} quantization, to further delineate
similar schemes. This has merit but brings the danger of
being “precisely wrong”, and too ﬁne a granularity adds to
the difﬁculty of scoring schemes consistently. There will be
the temptation to be unrealistically precise (“If scheme X
gets 0.9 for this beneﬁt, then scheme Y should get at most
0.6”), but this demands the ability to maintain a constant
level of precision repeatably across all cells.
We have resisted the temptation to produce an aggregate
score for each scheme (e.g., by counting the number of
beneﬁts achieved), or to rank the schemes. As discussed
above, fatal failure of a single beneﬁt or combined failure
of a pair of beneﬁts (e.g., not being Resilient-to-Internal-
Observation and fatally failing Easy-Recovery-from-Loss for
biometrics) may eliminate a scheme from consideration.
Thus, seeking schemes purely based on high numbers of
beneﬁts could well prove but a distraction.
Beyond divergences of judgement, there will no doubt be
errors in judgement in scoring. The table scoring methodol-
ogy must include redundancy and cross-checks sufﬁcient to
catch most such errors. (Our exercise involved one author
initially scoring a scheme row, co-authors verifying the
scores, and independently, cross-checks within columns to
calibrate individual beneﬁt ratings across schemes; useful
clariﬁcations of beneﬁt deﬁnitions often resulted.) Another
danger in being “too precise” arises from scoring on second-
hand data inferred from papers. Coarsely-quantized but self-
consistent scores are likely better than inconsistent ones.
On one hand, it could be argued that different appli-
cation domains (e.g., banking vs. gaming) have different
requirements and that therefore they ought to assign different
weights to the beneﬁts, resulting in a different choice of
optimal scheme for each domain. However on the other
hand,
to users, a proliferation of schemes is in itself a
failure: the meta-scheme of “use the best scheme for each
application” will score rather poorly on Scalable-for-Users,
Easy-to-Learn and perhaps a few other usability beneﬁts.
E. Combining schemes
it
is optimistic to assume that
Pairs of schemes that complement each other well in a
two-factor arrangement might be those where both achieve
good scores in usability and deployability and at least one
does so in security—so a combined scheme might be viewed
as having the AND of the usability-deployability scores
(i.e., the combination does not have a particular usability
or deployability beneﬁt unless both of the schemes do) and
the OR of the security scores (i.e., the combination has the
security beneﬁt if either of the schemes do). An exception
would appear to be the usability beneﬁt Scalable-for-Users
which a combination might inherit from either component.
However, this is necessarily just a starting point for the
two-component
analysis:
schemes always inherit beneﬁts in this way. Wimberly and
Liebrock [65] observed that the presence of a second factor
caused users to pick much weaker passwords than if pass-
words alone were used to protect an account—as predicted
by Adams’s “risk thermostat” model [66]. Thus, especially
where user choice is involved, there can be an erosion of the
efﬁcacy of one protection when a second factor is known to
be in place. Equally, defeating one security mechanism may
also make it materially easier to defeat another. We rated,
e.g., Phoolproof Quasi-Resilient-to-Internal-Observation be-
cause it requires an attacker to compromise both a PC and a
mobile device. However, malware has already been observed
in the wild which leverages a compromised PC to download
further malware onto mobile devices plugged into the PC
for a software update [67].
See O’Gorman [9] for suggested two-factor combinations
of biometrics, passwords, and tokens, for various applica-
tions (e.g., combining a hardware token with a biometric).
Another common suggestion is pairing a federated scheme
with a higher-security scheme, e.g., a hardware token.
VI. CONCLUDING REMARKS
The concise overview offered by Table I allows us to see
high level patterns that might otherwise be missed. We could
at this stage draw a variety of conclusions and note, for
example, that graphical and cognitive schemes offer only
minor improvements over passwords and thus have little
hope of displacing them. Or we could note that most of
565
the schemes with substantial improvements in both usability
and security can be seen as incarnations of Single-Sign-
On (including in this broad deﬁnition not only federated
schemes but also “local SSO” systems [26] such as password
managers or Pico). Having said that, we expect the long-
term scientiﬁc value of our contribution will lie not as much
in the raw data distilled herein, as in the methodology by
which it was assembled. A carefully crafted beneﬁts list
and coherent methodology for scoring table entries, despite
inevitable (albeit instructive) disagreements over ﬁne points
of speciﬁc scores, allows principled discussions about high
level conclusions.
That a Table I scheme (the CAP reader) scored full marks
in security does not at all suggest that its real-world security
is perfect—indeed, major issues have been found [55]. This
is a loud warning that it would be unwise to read absolute
verdicts into these scores. Our ratings are useful and we
stand by them, but they are not a substitute for independent
critical analysis or for considering aspects we didn’t rate,
such as vulnerability to active man-in-the-middle attacks.
We note that the ratings implied by scheme authors in
original publications are often not only optimistic, but also
incomplete. Proponents, perhaps subconsciously, often have
a biased and narrow view of what beneﬁts are relevant. Our
framework allows a more objective assessment.
In closing we observe that, looking at the green (vertical)
and red (horizontal) patterns in Table I, most schemes
do better than passwords on security—as expected, given
that inventors of alternatives to passwords tend to come
from the security community. Some schemes do better and
some worse on usability—suggesting that the community
needs to work harder there. But every scheme does worse
than passwords on deployability. This was to be expected
given that the ﬁrst four deployability beneﬁts are deﬁned
with explicit reference to what passwords achieve and the
remaining two are natural beneﬁts of a long-term incum-
bent, but this uneven playing ﬁeld reﬂects the reality of a
decentralized system like the Internet. Marginal gains are
often not sufﬁcient to reach the activation energy necessary
to overcome signiﬁcant transition costs, which may provide
the best explanation of why we are likely to live considerably
longer before seeing the funeral procession for passwords
arrive at the cemetery.
ACKNOWLEDGMENTS
The authors thank the anonymous reviewers whose com-
ments helped improve the paper greatly. Joseph Bonneau
is supported by the Gates Cambridge Trust. Paul C. van
Oorschot is Canada Research Chair in Authentication and
Computer Security, and acknowledges NSERC for funding
the chair and a Discovery Grant; partial funding from
NSERC ISSNet is also acknowledged. This work grew out
of the Related Work section of Pico [8].
REFERENCES
[1] J. Bonneau, C. Herley, P. C. van Oorschot, and F. Stajano,
“The quest to replace passwords: A framework for compar-
ative evaluation of web authentication schemes,” University
of Cambridge Computer Laboratory, Tech Report 817, 2012,
www.cl.cam.ac.uk/techreports/UCAM-CL-TR-817.html.
[2] R. Morris and K. Thompson, “Password security: a case
history,” Commun. ACM, vol. 22, no. 11, pp. 594–597, 1979.
[3] A. Adams and M. Sasse, “Users Are Not The Enemy,”
Commun. ACM, vol. 42, no. 12, pp. 41–46, 1999.
[4] C. Herley and P. C. van Oorschot, “A research agenda
acknowledging the persistence of passwords,” IEEE Security
& Privacy, vol. 10, no. 1, pp. 28–36, 2012.
[5] D. Florêncio and C. Herley, “One-Time Password Access to
Any Server Without Changing the Server,” ISC 2008, Taipei.
[6] M. Mannan and P. C. van Oorschot, “Leveraging personal
devices for stronger password authentication from untrusted
computers,” Journal of Computer Security, vol. 19, no. 4, pp.
703–750, 2011.
[7] S. Chiasson, E. Stobert, A. Forget, R. Biddle, and P. C. van
Oorschot, “Persuasive cued click-points: Design, implemen-
tation, and evaluation of a knowledge-based authentication
mechanism,” IEEE Trans. on Dependable and Secure Com-
puting, vol. 9, no. 2, pp. 222–235, 2012.
[8] F. Stajano, “Pico: No more passwords!” in Proc. Sec. Proto-
cols Workshop 2011, ser. LNCS, vol. 7114. Springer.
[9] L. O’Gorman, “Comparing passwords, tokens, and biometrics
for user authentication,” Proceedings of the IEEE, vol. 91,
no. 12, pp. 2019–2040, December 2003.
[10] K. Renaud, “Quantiﬁcation of authentication mechanisms: a
usability perspective,” J. Web Eng., vol. 3, no. 2, pp. 95–123,
2004.
[11] R. Biddle, S. Chiasson, and P. C. van Oorschot, “Graphical
Passwords: Learning from the First Twelve Years,” ACM
Computing Surveys, vol. 44, no. 4, 2012.
[12] J. Nielsen and R. Mack, Usability Inspection Methods.
Wiley & Sons, Inc, 1994.
John
[13] J. Bonneau and S. Preibusch, “The password thicket: technical
and market failures in human authentication on the web,” in
Proc. WEIS 2010, 2010.
[14] J. Bonneau, “The science of guessing: analyzing an
anonymized corpus of 70 million passwords,” IEEE Symp.
Security and Privacy, May 2012.
[15] K. Fu, E. Sit, K. Smith, and N. Feamster, “Dos and don’ts of
client authentication on the web,” in Proc. USENIX Security
Symposium, 2001.
[16] D. Florêncio and C. Herley, “Where Do Security Policies
Come From?” in ACM SOUPS 2010: Proc. 6th Symp. on
Usable Privacy and Security.
[17] L. Falk, A. Prakash, and K. Borders, “Analyzing websites for
user-visible security design ﬂaws,” in ACM SOUPS 2008, pp.
117–126.
[18] S. Gaw and E. W. Felten, “Password Management Strategies
for Online Accounts,” in ACM SOUPS 2006: Proc. 2nd Symp.
on Usable Privacy and Security, pp. 44–55.
[19] D. Florêncio and C. Herley, “A large-scale study of web
password habits,” in WWW ’07: Proc. 16th International Conf.
on the World Wide Web. ACM, 2007, pp. 657–666.
[20] D. Balzarotti, M. Cova, and G. Vigna, “ClearShot: Eavesdrop-
ping on Keyboard Input from Video,” in IEEE Symp. Security
and Privacy, 2008, pp. 170–183.
566
[21] B. Kaliski, RFC 2898: PKCS #5: Password-Based Cryptog-
raphy Speciﬁcation Version 2.0, IETF, September 2000.
[22] Mozilla Firefox, ver. 10.0.2, www.mozilla.org/.
[23] A. Pashalidis and C. J. Mitchell, “Impostor: A single sign-
on system for use from untrusted devices,” Proc. IEEE
Globecom, 2004.
[24] R. M. Needham and M. D. Schroeder, “Using encryption
for authentication in large networks of computers,” Commun.
ACM, vol. 21, pp. 993–999, December 1978.
[25] J. Kohl and C. Neuman, “The Kerberos Network Authentica-
tion Service (V5),” United States, 1993.
[26] A. Pashalidis and C. J. Mitchell, “A Taxonomy of Single
Sign-On Systems,” in Proc. ACISP 2003, Information Se-
curity and Privacy, 8th Australasian Conference.
Springer
LNCS 2727, 2003, pp. 249–264.
[27] D. Recordon and D. Reed, “OpenID 2.0: a platform for user-
centric identity management,” in DIM ’06: Proc. 2nd ACM
Workshop on Digital Identity Management, 2006, pp. 11–16.
[28] S.-T. Sun, Y. Boshmaf, K. Hawkey, and K. Beznosov, “A
billion keys, but few locks: the crisis of web single sign-on,”
Proc. NSPW 2010, pp. 61–72.
[29] B. Laurie, “OpenID: Phishing Heaven,” January 2007, www.
links.org/?p=187.
[30] R. Jhawar, P. Inglesant, N. Courtois, and M. A. Sasse, “Make
mine a quadruple: Strengthening the security of graphical
one-time pin authentication,” in Proc. NSS 2011, pp. 81–88.
[31] L. Lamport, “Password authentication with insecure commu-
nication,” Commun. ACM, vol. 24, no. 11, pp. 770–772, 1981.
[32] N. Haller and C. Metz, “RFC 1938: A One-Time Password
System,” 1998.
[33] M. Kuhn, “OTPW — a one-time password login package,”
1998, www.cl.cam.ac.uk/~mgk25/otpw.html.
[34] RSA, “RSA SecurID Two-factor Authentication,” 2011, www.
rsa.com/products/securid/sb/10695_SIDTFA_SB_0210.pdf.
[35] P. Bright, “RSA ﬁnally comes clean: SecurID is compro-
mised,” Jun. 2011, arstechnica.com/security/news/2011/06/
rsa-ﬁnally-comes-clean-securid-is-compromised.ars.
[36] B. Parno, C. Kuo, and A. Perrig, “Phoolproof Phishing
Prevention,” in Proc. Fin. Crypt. 2006, pp. 1–19.
[37] A. K. Jain, A. Ross, and S. Pankanti, “Biometrics: a tool
for information security,” IEEE Transactions on Information
Forensics and Security, vol. 1, no. 2, pp. 125–143, 2006.
[38] A. Ross, J. Shah, and A. K. Jain, “From Template to Image:
Reconstructing Fingerprints from Minutiae Points,” IEEE
Trans. Pattern Anal. Mach. Intell., vol. 29, no. 4, pp. 544–560,
2007.
[39] J. Daugman, “How iris recognition works,” IEEE Trans.
Circuits Syst. Video Techn., vol. 14, no. 1, pp. 21–30, 2004.
[40] P. S. Aleksic and A. K. Katsaggelos, “Audio-Visual Biomet-
rics,” Proc. of the IEEE, vol. 94, no. 11, pp. 2025–2044, 2006.
[41] T. Matsumoto, H. Matsumoto, K. Yamada, and S. Hoshino,
“Impact of artiﬁcial “gummy” ﬁngers on ﬁngerprint systems,”
in SPIE Conf. Series, vol. 4677, Apr. 2002, pp. 275–289.
[42] LastPass, www.lastpass.com/.
[43] D. P. Kormann and A. D. Rubin, “Risks of the Passport single
signon protocol,” Computer Networks, vol. 33, no. 1–6, 2000.
[44] “Facebook Connect,” 2011, www.facebook.com/advertising/
?connect.
[45] M. Hanson, D. Mills, and B. Adida, “Federated Browser-
Based Identity using Email Addresses,” W3C Workshop on
Identity in the Browser, May 2011.
567
[46] T. W. van der Horst and K. E. Seamons, “Simple Authenti-
cation for the Web,” in Intl. Conf. on Security and Privacy in
Communications Networks, 2007, pp. 473–482.
[47] H. Tao, “Pass-Go, a New Graphical Password Scheme,”
Master’s thesis, School of Information Technology and Engi-
neering, University of Ottawa, June 2006.
[48] D. Weinshall, “Cognitive Authentication Schemes Safe
Against Spyware (Short Paper),” in IEEE Symposium on
Security and Privacy, May 2006.
[49] N. Hopper and M. Blum, “Secure human identiﬁcation pro-
tocols,” ASIACRYPT 2001, pp. 52–66, 2001.
[50] S. Smith, “Authenticating users by word association,” Com-
puters & Security, vol. 6, no. 6, pp. 464–470, 1987.
[51] A. Wiesmaier, M. Fischer, E. G. Karatsiolis, and M. Lip-
pert, “Outﬂanking and securely using the PIN/TAN-System,”
CoRR, vol. cs.CR/0410025, 2004.
[52] “PassWindow,” 2011, www.passwindow.com.
[53] Yubico, “The YubiKey Manual, v. 2.0,” 2009, static.yubico.
com/var/uploads/YubiKey_manual-2.0.pdf.
[54] Ironkey, www.ironkey.com/internet-authentication.
[55] S. Drimer, S. J. Murdoch, and R. Anderson, “Optimised
to Fail: Card Readers for Online Banking,” in Financial
Cryptography and Data Security, 2009, pp. 184–200.
[56] Cronto, www.cronto.com/.
[57] Google Inc., “2-step veriﬁcation: how it works,” 2012, www.
google.com/accounts.
[58] S. Schechter, A. J. B. Brush, and S. Egelman, “It’s no secret:
Measuring the security and reliability of authentication via
‘secret’ questions,” in IEEE Symp. Security and Privacy,
2009, pp. 375–390.
[59] M. Jakobsson, L. Yang, and S. Wetzel, “Quantifying the
Security of Preference-based Authentication,” in ACM DIM
2008: 4th Workshop on Digital Identity Management.
[60] J. Brainard, A. Juels, R. L. Rivest, M. Szydlo, and M. Yung,
“Fourth-factor authentication: somebody you know,” in ACM
CCS 2006, pp. 168–178.
[61] D. Weinshall, “Cognitive Authentication Schemes Safe
Against Spyware,” IEEE Symp. Security and Privacy, 2006.
[62] P. Golle and D. Wagner, “Cryptanalysis of a Cognitive
Authentication Scheme,” IEEE Symp. Security and Privacy,
2007.
[63] B. Coskun and C. Herley, “Can “Something You Know” be
Saved?” ISC 2008, Taipei.
[64] Q. Yan, J. Han, Y. Li, and H. Deng, “On limitations of
designing usable leakage-resilient password systems: Attacks,
principles and usability.” Proc. NDSS, 2012.
[65] H. Wimberly and L. M. Liebrock, “Using Fingerprint Authen-
tication to Reduce System Security: An Empirical Study,” in
IEEE Symp. Security and Privacy, 2011, pp. 32–46.
[66] J. Adams, “Risk and morality: three framing devices,” in Risk
and Morality, R. Ericson and A. Doyle, Eds. University of
Toronto Press, 2003.
[67] A. P. Felt, M. Finifter, E. Chin, S. Hanna, and D. Wagner,
“A survey of mobile malware in the wild,” in ACM SPSM
2011: 1st Workshop on Security and Privacy in Smartphones
and Mobile Devices, pp. 3–14.