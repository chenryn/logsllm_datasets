the ﬂow of information about themselves, which features
deﬁnitively in certain theories, is merely one transmission
principle—albeit an important one—among many. There is
probably no end to the variation in transmission principles.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:00 UTC from IEEE Xplore.  Restrictions apply. 
3 A Formal Model of Contextual Integrity
In this section, we formalize a fragment of contextual
integrity. Our model consists of communicating agents
who take on various roles in contexts and send each other
messages containing attributes of other agents. The evo-
lution of the knowledge of individual agents depends on
messages they receive and computation rules that enable
agents to infer further attributes. Agent interactions give
rise to execution histories, or traces. In our speciﬁc model,
norms of transmission are expressed using Linear Tempo-
ral Logic (LTL) formulas interpreted over these traces, al-
though the choice of linear time over other temporal logics
may not be highly signiﬁcant.
3.1 Agents, Attributes, and Messages
We begin by modeling communicating agents. Associ-
ated with each agent is a collection of the attributes that
agent knows. Let P be a set of agents, and let T be a set
of attributes. For example, Alice and Bob are agents, and
“postal address” and “height” are attributes. A knowledge
state κ is a subset of P × P × T . If (p, q, t) ∈ κ, we say
agent p knows the value of attribute t of agent q. For exam-
ple, Alice knows Bob’s height. We omit “group” attributes,
for example the average height of Alice, Bob, and Charlie.
Data Model. To structure attributes, we include compu-
tation rules. Our computation rules provide an abstract pre-
sentation of possible inferences, enabling agents to compute
the attribute “postal code” from the attribute “postal ad-
dress”. Formally, a computation rule is a pair (T, t), where
T ⊆ T and t ∈ T . Intuitively, if Alice knows the value
of each attribute in T for Bob, then Alice can compute the
value of attribute t for Bob. We express this formally as a
relation on knowledge states:
∀κ.∀p, q ∈ P.if {p} × {q} × T ⊆ κ, then κ
(T,t)−−−→ κ(cid:2)
where κ(cid:2) = κ ∪ {(p, q, t)}. That is, agent p learns attribute
t about agent q. Let I be a set of computation rules. The
relation I−→ is the transitive closure of
(T,t)−−−→ for (T, t) ∈ I.
Communication Model. An agent can send a message to
another agent provided the sending agent knows all the at-
tributes communicated by the message. For example, Al-
ice can send a message to Bob containing Charlie’s height
just in case Alice herself knows Charlie’s height. After re-
ceiving such a message, Bob learns Charlie’s height. Mes-
sages m are drawn from a set M. Associated with each
message m is a (possibly empty) set of attributes which the
message contains, content(m) ⊆ P × T , which is closed
under computation rules. For example, a message that con-
tains a postal address necessarily contains the correspond-
ing postal code. We refer to the act of sending a message
as a communication action and represent such actions as
triples (p1, p2, m), where agent p1 is the sender, agent p2 is
the recipient, and m is the message being sent. A commu-
nication action transforms knowledge states as follows:
∀κ, ˆκ.∀p1, p2 ∈ P.∀m ∈ M.
if κ I−→ ˆκ and {p1} × content(m) ⊆ ˆκ,
(p1,p2,m)
−−−−−−→ κ(cid:2),
then κ
where κ(cid:2) = ˆκ ∪ {p2} × content(m). The contents of the
message are ﬁrst computed by the sender (at ˆκ) and then
learned by the recipient (at κ(cid:2)).
3.2 Roles, Contexts, and Traces
In order to model contextual integrity, we impose addi-
tional structure that associates agents with roles as part of
contexts. Let R be a set of roles and C be a partition of
R. We refer to elements c ∈ C as contexts and the roles
r ∈ c as the roles of context c. For example, “teller” is a
role in a banking context and “doctor” is a role in a health
care context. The roles are structured by a partial order ≤R.
If r1 ≤R r2, then r1 is a specialization of role r2 and, sym-
metrically, r2 is a generalization of r1. For example, a psy-
chiatrist is a specialization of a doctor, which in turn is a
specialization of a health care provider.
Agents can be active in multiple roles simultaneously.
For example, Alice can be at once a doctor in a health care
context and a customer in a banking context. A role state ρ
is a subset of P × R. If (p, r) ∈ ρ, we say agent p is active
in, or plays, role r. For example, if (Alice, psychiatrist) ∈
ρ, then Alice is active in the role of psychiatrist. We re-
quire role states to be closed under role generalization, that
is if r1 ≤R r2 and (p, r1) ∈ ρ, then (p, r2) ∈ ρ. Return-
ing to our example, if (Alice, psychiatrist) ∈ ρ, Alice must
be active in the role of doctor in addition to that of psy-
chiatrist. There are many instances of each context (many
banks, many hospitals), but for clarity we omit instances.
The history of the agent world is an (inﬁnite) trace: a
sequence of triples (κ, ρ, a), where κ is a knowledge state,
ρ is a role state, a is a communication action, and
an+1−−−→ κn+1, for all n ∈ N.
κn
The role state can change freely from one state to the next.
We view the role state as an input to the model. For exam-
ple, a hospital provides as input to the policy mechanism a
record of which of its employees are nurses, which are doc-
tors, etc. The knowledge state, however, evolves in concert
with the communication actions. This prevents Alice from
spontaneously learning Charlie’s birthday.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:00 UTC from IEEE Xplore.  Restrictions apply. 
σ |= ∀p1, p2, q : P.∀m : M.∀t : T.
incontext(p1, c) ∧ send(p1, p2, m) ∧ contains(m, q, t) →
(cid:2)
ϕ+ ∧
(cid:3)
ϕ+∈norms+(c)
ϕ−∈norms−(c)
ϕ−
(1)
positive norm:
negative norm:
inrole(p1, ˆr1) ∧ inrole(p2, ˆr2) ∧ inrole(q, ˆr) ∧ (t ∈ ˆt) ∧ θ ∧ ψ
inrole(p1, ˆr1) ∧ inrole(p2, ˆr2) ∧ inrole(q, ˆr) ∧ (t ∈ ˆt) ∧ θ → ψ
Figure 1. Norms of Transmission Represented as a Temporal Formula
3.3 Temporal Logic
We employ a standard temporal logic for expressing
properties of traces of agent actions (e.g., [29]). The tem-
poral operators are used to capture the principles of trans-
mission. For example, if Alice tells Bob her age under
the principle of conﬁdentiality, then, in the future, Bob
must not disclose Alice’s age. The past operators are also
useful for capturing “opt-in” and other similar privacy id-
ioms. Several temporal logics are appropriate for formaliz-
ing contextual integrity, including linear temporal logic and
branching-time temporal logic. We employ linear temporal
logic, in particular multi-sorted, ﬁrst-order LTL. The inter-
ested reader can ﬁnd the details in Appendix A. We use
formulas generated by the following grammar:
ϕ ::= send(p1, p2, m) | contains(m, q, t) |
inrole(p, r) | incontext(p, c) | t ∈ t(cid:2) |
ϕ ∧ ϕ | ¬ϕ | ϕUϕ | ϕSϕ |
ϕ | ∃x : τ.ϕ
Intuitively, send(p1, p2, m) holds in a state if agent p1 just
sent message m to agent p2, contains(m, q, t) holds if mes-
sage m contains attribute t of agent q, inrole(p, r) holds in
a state if agent p is active in role r, incontext(p, c) holds in
a state if agent p is active in a role of context c, t ∈ t(cid:2) holds
if attribute t can be computed from (is a component of) at-
tribute t(cid:2), and ϕUψ holds just in case ϕ holds until ψ holds
(ψ must eventually hold). The modality “since,” written S
is the past version of U.
ϕ holds iff ϕ holds in the next
state. Finally, ∃ is rigid existential quantiﬁcation.
To simplify notation, we use the following standard sym-
bols:
, respectively, and W for
for the past versions of
“wait for.” The formula ϕWψ holds if either ϕ holds or
ϕUψ holds.
for “henceforth,”
and
for “eventually,”
and
3.4 Norms of Transmission
Norms of transmissions are expressed as temporal for-
mulas. Each norm is either positive or negative. A positive
norm might state that doctor Alice can send patient Char-
lie’s test results to researcher Bob if Bob keeps the records
in conﬁdence. Negative norms are dual: they state commu-
nication can occur only if the temporal condition is satis-
ﬁed. For example, doctor Alice can send patient Charlie’s
test results to researcher Bob only if Bob keeps the records
in conﬁdence. In the positive case, some other norm could
authorize the communication and Bob would not be obliged
to keep the results conﬁdential, whereas in the negative case
Bob must keep the results conﬁdential regardless of how he
obtained them from Alice.
We say a trace σ satisﬁes the norms of context c if For-
mula (1) of Fig. 1 holds. Formula (1) takes a disjunc-
tion over the positive norms of transmission for context c,
denoted norms+(c), and a conjunction over the negative
norms of transmission for context c, denoted norms−(c).
Thus, in order to satisfy the norms, a communication must
be allowed by at least one of the positive norms and it must
respect all of the negative norms.
The syntactic forms of positive and negative norms are
depicted in Fig. 1, where p1, p2, and q are variables of sort
P , ˆr1, ˆr2, and ˆr are terms of sort R, t is a variable of sort T ,
ˆt is a term of sort T , θ is an agent constraint, and ψ is a tem-
poral condition. An agent constraint θ is a formula free of
temporal operators with free variables among p1, p2, and q.
It expresses a relation among the sender, the recipient, and
the subject, for example, that the sender and the subject are
one and the same agent. A temporal condition ψ formalizes
the notion of a principle of transmission and is a temporal
formula with free variables among p1, p2, q, m, and t. It
requires certain future actions to occur and certain past ac-
tions to have occurred (see Sect. 5 for concrete examples of
norms).
One subtle consequence of the construction of For-
mula (1) is the treatment of attributes. Each individual norm
applies to a downwardly closed set of attributes (downward
in the information ordering on attributes induced by the
computation rules). This captures the usual implication that
the statement “allow disclosure of postal address” also al-
lows the disclosure of postal codes. The formula univer-
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:00 UTC from IEEE Xplore.  Restrictions apply. 
sally quantiﬁes over attributes because each communicated
attribute must have a normative basis. The usual “upwards”
inheritance of deny rules arises naturally here from the uni-
versal quantiﬁcation over attributes and the downward clo-
sure of message contents. Suppose, for example, a norm
denies the disclosure of postal codes. If one agent attempts
to send a message containing a postal address, that mes-
sage must also contain a postal code and when the attribute
“postal code” is considered by the universal quantiﬁer, the
formula will forbid the disclosure.
4 Policies, Combination, and Compliance
A privacy policy regulates what ﬂows of information are
permitted between agents in various roles. A policy is a
conjunction of contexts, requiring the norms of each context
to be respected. For example, if Alice plays roles in both a
bank and a hospital, she must act in accordance with the
informational norms of both contexts.
Def. A privacy policy is a conjunction of formulas of the
form (1) in Fig. 1.
We deﬁne below methods for evaluating privacy policies,
both independently and in comparison with other policies.
In addition, we deﬁne a notion of privacy compliance for an
action. These problems can be solved using standard tools
because they are formulated in LTL.
4.1 Consistency
A policy is consistent if it is possible for communicat-
ing agents to respect the policy. Inconsistent policies are
not useful because they prescribe norms that agents cannot
possibly satisfy. As deﬁned, privacy policies can be sat-
isﬁed trivially by agents who refrain from communicating
any attributes. To focus on substantive consistency, we use
a temporal formula, a purpose, to compel communication,
requiring, for example, that eventually a bank customer re-
ceives his account balance.
Def. A privacy policy θ is consistent with a purpose α if
there exists a trace σ such that σ |= θ ∧ α.
Because the satisﬁability of LTL formulas is a well-studied
problem, we can apply a set of known algorithmic re-
sults [39, 18, 29] to evaluate consistency of privacy poli-
cies. By assuming our carrier sets are ﬁnite, we are able
to rewrite universal and existential quantiﬁers as ﬁnite con-
junctions and disjunctions in Propositional LTL (PLTL).
Theorem 1. Policy consistency can be decided in PSPACE.
Let β be an LTL formula expressing the knowledge evo-
lution constraints on traces. The proof idea is to proposi-
tionalize θ ∧ α ∧ β and decide its satisﬁability in PSPACE
(with respect to formula length and the size of the carrier
sets). Although the worst-case complexity of satisﬁability
is PSPACE, there are efﬁcient algorithms for several syn-
tactic classes of formulas [18]. Furthermore, there are tools
that work well in practice, such as the widely used SPIN
model-checker [24].
4.2 Entailment
Another metric for evaluating a privacy policy is to com-
pare it against another policy. For example, a hospital’s pri-
vacy policy should not allow information ﬂows prohibited
by HIPAA.
Def. A privacy policy θ1 entails a policy θ2 if the LTL for-
mula θ1 → θ2 is valid over traces.
A hospital’s privacy policy should entail HIPAA (which in
turn should entail the norms of the societal health care con-
text). Entailment generalizes the notion of policy reﬁnement
deﬁned for EPAL in [7, 9]. These previous deﬁnitions are
lattice-theoretic and require direct reasoning about upwards
and downwards inheritance. Our simpler model-theoretic
deﬁnition is made possible by representing policies as log-
ical formulas that properly quantify over attributes. Here,
policy entailment reduces to standard logical implication.
Theorem 2. Policy entailment can be decided in PSPACE.
This theorem is proved by observing that the formula
θ1 → θ2 is valid over traces just in case ¬(θ1 → θ2) ∧ β
is not satisﬁable, where β is an LTL formula for knowledge
constraints. Deciding policy entailment for our policies is
more difﬁcult than for other privacy languages because we
directly model temporal constraints instead of abstracting
them into uninterpreted “obligations” (see Sect. 6.3).
Policy entailment also leads to notions of policy com-
bination, as in [10, 6]. Entailment as implication gives
rise to combination as logical conjunction and disjunction.
This replaces the previous complex lattice-based deﬁnitions
of other privacy languages. Policy combination is simpler
in this framework because we represent policies by care-
fully constructed logical formulas and not by functions, as
in XACML and EPAL. Representing policies as functions
loses essential information about whether a requirement
was inherited from another attribute. Representing policies
as logical formulas retains the inheritance information, sim-
plifying combination.
4.3 Compliance
Finally, we address the issue of compliance: given the
sequence of past communications, does the policy permit
a contemplated communication and, if so, what future re-
quirements are incurred? This question has both a weak
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:00 UTC from IEEE Xplore.  Restrictions apply. 
and a strong formulation. The weak formulation requires
the contemplated action to satisfy all the necessary present
conditions imposed by the policy. These necessary condi-