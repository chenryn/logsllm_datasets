sidered in the evaluation. The user’s only task is to
rate whether the shown ﬁngerprints match by clicking on
Match or Doesn’t Match on the phone. Based on the con-
dition assignment, participants see different approaches
in a randomized order. We measure whether their an-
swer was correct and their speed, i. e., the amount of time
spent on the comparison. The experiment is concluded
with a survey collecting feedback on the used approaches
and the tasks and demographic information discussed in
the “Results” section.
4.3.1 Variables and Conditions
In the main experiment, the used representation scheme
is our controlled independent variable whereas its val-
ues deﬁne our experiment conditions. In our additional
chunking experiment, the chunking size is our controlled
independent variable instead of the representation algo-
rithm. During all tasks, we measure how fast participants
perform with their given conditions and whether they are
able to detect attacks by rating “incorrect” (speed and
accuracy as our measured dependent variables).
In both experiments, each user had to perform 46 com-
parisons in total. To detect users clicking randomly, 2
obviously distinct comparisons were added to test a par-
ticipant’s attention. Training comparisons and attention
tests are not included in the evaluation. Based on the
feedback in our pre-study, we added tooltips during the
training comparisons giving hints for language-based ap-
proaches telling the user that spelling attacks would not
occur. We set the number of attacks to six: two obvious
attacks where all bits are altered serving as control ques-
tions and 4 actual attacks with partial 80-bit preimages
(one for each representation scheme). Participants failing
at the control attacks are not considered in the evaluation
but still received a payment if ﬁnishing all tasks. The
major challenge in the study design is a high attack de-
tection rate in general: most users perform comparisons
correctly for the given attacker strength.
To avoid side effects, we chose ﬁxed font size, color
200  25th USENIX Security Symposium 
USENIX Association
8
Figure 4: A screenshot showing a statement rating in the post-experiment survey. Since the participants might
not distinguish the different types, we have provided an example from their previous task.
and style, i. e., the same typeface for all ﬁngerprint rep-
resentations. In addition, we set ﬁxed line breaks for sen-
tences and word lists. In the main experiment, the same
chunking style was used for all representations: For (al-
pha)numeric approaches a chunk consists of four charac-
ters separated by spaces. For word lists, we opted for a
line break every four words. In the generated sentences
representation, one sentence per line is displayed. We are
aware that all these design decisions can have an effect
on the comparison of the representations. However, our
pre-study results show a signiﬁcantly lower effect size.
More importantly, we are mainly interested in compar-
ing the concepts, therefore we did not vary any of the
visual attributes like font size or style. In particular, dif-
ferences resulting from the font’s typeface have not been
evaluated. Lund showed in his meta-analysis that there
are no signiﬁcant legibility differences between serif and
sans serif typefaces [25].
Chunk-Size Testing A question was raised whether
the chunking of a hexadecimal string plays a greater role
in comparison to the different approaches. Thus, in addi-
tion to the main experiment testing different representa-
tion types, we conducted a second experiment with new
participants testing different chunk sizes for the hexadec-
imal representation. Here, we used chunk-sizes ranging
from 2 to 8 in addition to “zero-chunk size” (8 cases).
The zero-chunk size means that no spaces have been in-
cluded. To make the results more comparable, we opted
for a similar design as done in the major experiment, i. e.,
we required the same amount of comparisons, used the
same font settings, and had the same amount of attacks.
For each participant, we assigned 4 out of 8 different
chunk-sized randomly. Same as in the major experiment,
all participants had to compare 46 ﬁngerprints whereas
the ﬁrst 4 are considered as training comparisons, 4 at-
tacks (one for each chunk size), and 2 control attacks
with obviously distinct ﬁngerprints.
The major experiment is followed by a survey fo-
cusing on self-reported user perception and opinions
about the different approaches. This is the main reason
we opted to compare as much as possible in a within-
groups fashion and only selected a small number of con-
ditions in total. Since users might not notice the dif-
ference between the various dictionary or alphabet ap-
proaches, we designed a mixed factorial design where
the users would only get one of the alphabets/dictionar-
ies (between-subjects) but they would test all different
high-level systems (within-group) as depicted in Table 2.
The between-group conditions have been assigned ran-
domly with a uniform distribution. Since participants
from our pre-study had difﬁculties to distinguish the dif-
ferent chunking approaches, we skipped the survey part
in the chunk-size experiment.
4.3.2 Online Survey
The experiment was followed by an online survey gath-
ering self-reported data and demographics from partic-
ipants. To measure perception, we asked the partici-
pants whether they agreed with statements discussed in
subsection 5.2 on a 5 point Likert scale: from strongly
disagree to neural strongly agree as shown in Figure 4.
Participants had to rate each representation type for all
statements. Since users might not distinguish the differ-
ent representation schemes, we provide an example from
their previously ﬁnished task.
4.3.3 Statistical Testing
We opted for the common signiﬁcance level of α = 0.05.
To counteract the multiple comparisons problem, we use
the Holm-Bonferronicorrection for our statistical signif-
icance tests [18]. Consequently, all our p-values are re-
ported in the corrected version.
We test
the comparison duration with the Mann-
Whitney-Wilcoxon (MWW) test (two-tailed). We opt for
this signiﬁcance test due to a few outliers, consequently a
USENIX Association  
25th USENIX Security Symposium  201
9
Scheme
Hexadecimal
Hexadecimal – Base32
Hexadecimal – Numeric
Hexadecimal – PGP
Hexadecimal – Peerio
Hexadecimal – Sentences
Base32
Base32 – Hexadecimal
Base32 – Numeric
Base32 – PGP
Base32 – Peerio
Base32 – Sentences
Numeric
Numeric – Hexadecimal
Numeric – Base32
Numeric – PGP
Numeric – Peerio
Numeric – Sentences
PGP
PGP – Hexadecimal
PGP – Base32
PGP – Numeric
PGP – Peerio
PGP – Sentences
Peerio
Peerio – Hexadecimal
Peerio – Base32
Peerio – Numeric
Peerio – PGP
Peerio – Sentences
Sentences
Sentences – Hexadecimal
Sentences – Base32
Sentences – Numeric
Sentences – PGP
Sentences – Peerio
Speed
mean [s] med [s]
10.0
1.1
0.5
−1.2
2.7
−0.7
8.9
−1.1
−0.6
−2.3
1.6
−1.8
9.5
−0.5
0.6
−1.7
2.2
−1.2
11.2
1.2
2.3
1.7
3.9
0.5
7.3
−2.7
−1.6
−2.2
−3.9
−3.4
10.7
0.7
1.8
1.2
−0.5
3.4
11.2
1.0
0.6
−1.8
2.5
−1.1
10.2
−1.0
−0.4
−2.8
1.5
−2.1
10.6
−0.6
0.4
−2.4
1.9
−1.7
13.0
1.8
2.8
2.4
4.3
0.7
8.7
−2.5
−1.5
−1.9
−4.3
−3.6
12.3
1.1
2.1
1.7
−0.7
3.6
p-val
stdev
6.4
0.0 <0.001
0.6 <0.001
−1.0 <0.001
0.8 <0.001
−0.6 <0.001
6.4
−0.0 <0.001
0.6 <0.001
−1.0 <0.001
0.8 <0.001
−0.6 <0.001
5.8
−0.6 <0.001
−0.6 <0.001
−1.6 <0.001
0.2 <0.001
−1.2 <0.001
7.4
1.0 <0.001
1.0 <0.001
1.6 <0.001
1.8 <0.001
0.4 <0.001
5.6
−0.8 <0.001
−0.8 <0.001
−0.2 <0.001
−1.8 <0.001
−1.4 <0.001
7.0
0.6 <0.001
0.6 <0.001
1.2 <0.001
−0.4 <0.001
1.4 <0.001
Accuracy
p-val
f-pos
fail-rate
0.49
10.44
0.690 −2.09
−1.94
0.21
0.048
−4.10
−1.65
0.690 −0.01
0.08
0.048
−4.69
−7.45 <0.001 −0.99
2.58
8.50
2.09
1.94
0.690
−2.16
2.30
0.404
2.08
0.28
0.714
2.17
−2.75
0.404
1.10
−5.51 <0.001
6.34
0.28
0.048 −0.21
4.10
0.404 −2.30
2.16
2.45
0.404 −0.22
0.714 −0.13
−0.59
0.004 −1.20
−3.35
0.50
8.78
0.690
0.01
1.65
−0.28
0.714 −2.08
0.22
0.404
−2.45
0.337
−3.03
0.09
−5.79 <0.001 −0.98
5.75
0.41
0.048 −0.08
4.69
2.75
0.404 −2.17
0.13
0.714
0.59
0.337 −0.09
3.03
0.075 −1.07
−2.76
1.48
2.99
7.45 <0.001
0.99
5.51 <0.001 −1.10
1.20
3.35
0.004
0.98
5.79 <0.001
2.76
0.075
1.07
fails
50
12
−9
11
22
22
38
−12
−21
−1
10
10
59
9
21
20
31
31
39
−11
1
−20
11
11
28
−22
−10
−31
−11
0
28
−22
−10
−31