```
postgres=# insert into tbl values (1,'info') on conflict on constraint tbl_pkey do update set info=excluded.info;  
INSERT 0 1  
```
【推荐】如果用户经常需要访问一张大表的某些数据，为了提升效率可以使用索引，但是如果这个数据还需要被用于更复杂的与其他表的JOIN操作，则可以使用物化视图来提升性能。    
同时物化视图还可以被用于OLAP场景，例如统计后的数据可以固化到物化视图中，以便快速的检索。    
例如  
```
CREATE MATERIALIZED VIEW mv_tbl as select xx,xx,xx from tbl where xxx with data;  
```
增量刷新物化视图  
```
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_tbl with data;  
```
【推荐】不建议对宽表频繁的更新，原因是PG目前的引擎是多版本的，更新后会产生新的版本，如果对宽表的某几个少量的字段频繁更新，其实是存在写放大的。   
建议将此类宽表的不更新或更新不频繁的列与频繁更新的列拆分成两张表，通过PK进行关联。  
查询是通过PK关联查询出结果即可。    
【推荐】使用窗口查询减少数据库和应用的交互次数。  
例如    
有一个这样的表，记录如下:    
```
id | company | product 
----+---------+---------
1 | c1      | p1
1 | c1      | p2
1 | b1      | p2
1 | c2      | p2
1 | c1      | p1
2 | c3      | p3
```
需要找出某个产品，这个产品只有一个公司生产。    
```
select distinct product from (select min(company) over(partition by product) m1,max(company) over(partition by product) m2, product from tbl) t where m2<>m1; 
```
又如，根据指定窗口，查询当前行与以窗口为范围取其avg,max,min,sum,count,offset,rank,dist等，同时输出当前行。例如与第一名的差距，与前一名的差距，与全国第一名的差距，与全班第一名的差距，同时还输出当前记录的详情。    
【推荐】应该尽量在业务层面避免死锁的产生，例如一个用户的数据，尽量在一个线程内处理，而不要跨线程（即跨数据库会话处理）。    
【推荐】OLTP系统不要频繁的使用聚合操作，聚合操作消耗较大的CPU与IO资源。例如实时的COUNT操作，如果并发很高，可能导致CPU资源撑爆。    
对于实时性要求不高的场景，可以使用定期操作COUNT，并将COUNT数据缓存在缓存系统中的方式。    
【推荐】数据去重的方法，当没有UK或PK时，如果数据出现了重复，有什么好的方法去重。或者某个列没有加唯一约束，但是业务层没有保证唯一，如何去重？  
行级别去重  
```
delete from tbl where ctid not in (select min(ctid) from tbl group by tbl::text);  
```
带PK的列col级别去重  
```
delete from tbl where pk in (select pk from (select pk,row_number() over(partition by col order by pk) rn from tbl) t where t.rn>1);  
```
不带PK的列级别去重(以业务逻辑为准，可以选择其他的条件删除)  
```
delete from tbl where ctid not in (select min(ctid) from tbl group by col);  
```
【推荐】快速读取随机记录的方法
利用索引列进行优化的方法。  
方法    1.  随机取出n条记录,以下取出5条随机记录  
```
digoal=> select * from tbl_user
digoal->  where id in
digoal->         (select floor(random() * (max_id - min_id))::int
digoal(>                 + min_id
digoal(>            from generate_series(1,5),
digoal(>                 (select max(id) as max_id,
digoal(>                         min(id) as min_id
digoal(>                    from tbl_user) s1
digoal(>         )
digoal-> limit 5;
   id   | firstname | lastname |   corp   | age 
--------+-----------+----------+----------+-----
 965638 | zhou      | digoal   | sky-mobi |  27
 193491 | zhou      | digoal   | sky-mobi |  27
 294286 | zhou      | digoal   | sky-mobi |  27
 726263 | zhou      | digoal   | sky-mobi |  27
 470713 | zhou      | digoal   | sky-mobi |  27
(5 rows)
Time: 0.670 ms
```
方法   2. 取出N条连续的随机记录.(此处用到函数)  
```
digoal=> create or replace function f_get_random (i_range int) returns setof record as $BODY$
digoal$> declare
digoal$> v_result record;
digoal$> v_max_id int;
digoal$> v_min_id int;
digoal$> v_random numeric;
digoal$> begin
digoal$> select random() into v_random;
digoal$> select max(id),min(id) into v_max_id,v_min_id from tbl_user;
digoal$> for v_result in select * from tbl_user where id between (v_min_id+(v_random*(v_max_id-v_min_id))::int) and (v_min_id+(v_random*(v_max_id-v_min_id))::int+i_range)
digoal$> loop
digoal$> return next v_result;
digoal$> end loop;
digoal$> return;
digoal$> end
digoal$> $BODY$ language plpgsql;
CREATE FUNCTION
```
以下举例取出10条连续的随机记录  
```
digoal=> select * from f_get_random(9) as (id bigint,firstname varchar(32),lastname varchar(32),corp varchar(32),age smallint);
   id   | firstname | lastname |   corp   | age 
--------+-----------+----------+----------+-----
 694686 | zhou      | digoal   | sky-mobi |  27
 694687 | zhou      | digoal   | sky-mobi |  27
 694688 | zhou      | digoal   | sky-mobi |  27
 694689 | zhou      | digoal   | sky-mobi |  27
 694690 | zhou      | digoal   | sky-mobi |  27
 694691 | zhou      | digoal   | sky-mobi |  27
 694692 | zhou      | digoal   | sky-mobi |  27
 694693 | zhou      | digoal   | sky-mobi |  27
 694694 | zhou      | digoal   | sky-mobi |  27
 694695 | zhou      | digoal   | sky-mobi |  27
(10 rows)
Time: 0.418 ms
```
【推荐】线上表结构的变更包括添加字段，索引操作在业务低峰期进行。  
【推荐】OLTP系统，在高峰期或高并发期间 拒绝 长SQL，大事务，大批量。  
说明：  
(1). 长SQL占用大量的数据库时间和资源，占用连接，可能影响正常业务运行。  
(2). 大事务，或长事务，可能导致长时间持锁，与其他事务产生锁冲突。  
(3). 大批量，大批量在并发事务中增加锁等待的几率。  
【推荐】查询条件要和索引匹配，例如查询条件是表达式时，索引也要是表达式索引，查询条件为列时，索引就是列索引。  
【推荐】如何判断两个值是不是不一样（并且将NULL视为一样的值），使用col1 IS DISTINCT FROM col2    
例如   
```
postgres=# select null is distinct from null;
 ?column? 
----------
 f
(1 row)
postgres=# select null is distinct from 1;
 ?column? 
----------
 t
(1 row)
```
另外还有IS NOT DISTINCT FROM的用法 。    
【推荐】如果在UDF或online code逻辑中有数据的处理需求时，建议使用游标进行处理。  
例如  
```
do language plpgsql $$
declare
  cur refcursor;
  rec record;
begin
  open cur for select * from tbl where id>1; 
  loop
    fetch cur into rec; 
    if found then  
      raise notice '%', rec; 
      update tbl set info='ab' where current of cur;
      -- other query
    else 
      close cur;
      exit; 
    end if;
  end loop;
end;
$$;
```
【推荐】应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。    
如果业务确实有这种需求的查询，可以有几种优化方法  
1\. partial index  
这个是最有效的方法，可以使用到索引扫描，如果有其他条件，也可以在其他条件的索引上建立partial index.  
```
create index idx1 on tbl (id) where cond1 <> xx;
```
2\. 分区表  
使用分区表，如果有!=的查询条件，PostgreSQL会根据分区约束，避免扫描不需要扫描的表。  
3\. 约束  
```
set constraint_exclusion=on;
exec query;
```
在查询列上有约束的情况下，如果!=或<>与约束违背，则可以提前返回查询，不会扫描表。  
【推荐】对于经常变更，或者新增，删除记录的表，应该尽量加快这种表的统计信息采样频率，获得较实时的采样，输出较好的执行计划。  
例如  
当垃圾达到表的千分之五时，自动触发垃圾回收。  
当数据变化达到表的百分之一时，自动触发统计信息的采集。  
当执行垃圾回收时，不等待，当IOPS较好时可以这么设置。  
```
postgres=# create table t21(id int, info text) with (
autovacuum_enabled=on, toast.autovacuum_enabled=on, 
autovacuum_vacuum_scale_factor=0.005, toast.autovacuum_vacuum_scale_factor=0.005, 
autovacuum_analyze_scale_factor=0.01, autovacuum_vacuum_cost_delay=0, 
toast.autovacuum_vacuum_cost_delay=0);
CREATE TABLE
```
【推荐】PostgreSQL 对or的查询条件，会使用bitmap or进行索引的过滤，所以不需要改SQL语句，可以直接使用。  
例如  
以下查询都可以走索引  
```
select * from tbl where col1 =1 or col1=2 or col2=1 or ...;
select * from tbl where col1 in (1,2);
```
【推荐】很多时候用 exists 代替 in 是一个好的选择：  
```
select num from a where num in (select num from b);
```
用下面的语句替换：  
```
select num from a where exists(select 1 from b where num=a.num)
```
【推荐】尽量使用数组变量来代替临时表。如果临时表有非常庞大的数据时，才考虑使用临时表。    
【推荐】对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。  
使用explain可以查看执行计划，如果发现执行计划不优，可以通过索引或者调整QUERY的写法解决。  
例如  
```
begin;
explain (verbose,costs,timing,buffers,analyze) query;
rollback;
......
```
【推荐】PG优化器可以动态调整JOIN的顺序，获取更好的执行计划，但是如何强制优化器的显示JOIN顺序呢？   
首先PG根据join_collapse_limit的设置，当需要关联的表的个数超过这个设置时，超出的JOIN数部分不会继续动态调整JOIN顺序。  
另外需要注意，如果开启了GEQO，当JOIN的表(含隐式JOIN,以及子查询) (full outer join 只算1)数量超过了geqo_threshold设置的值，则会触发遗传算法，可能无法得到最佳的JOIN顺序。   
要让优化器固定JOIN顺序，首先必须使用显示的JOIN，其次将join_collapse_limit设置为1，显示的JOIN顺序将被固定，固定JOIN顺序可以减少优化器的编排时间，降低频繁执行多表JOIN带来的优化阶段的CPU开销。    
显示的JOIN例子  
```
t1 join t2 on (xxx)  
```
隐式的JOIN例子  
```
t1, t2 where xxx
```
例如  
```
begin;
set local join_collapse_limit=1;
set local geqo=off;
postgres=# create table t1(id int, info text);
CREATE TABLE
postgres=# create table t2(id int, info text);
CREATE TABLE