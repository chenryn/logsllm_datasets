28, all honest replicas lock on a chain certificate lockv +1 such that
tip(CC) extends Bk before entering a new view. After entering a
new view, honest replicas send their locked CC to the new leader
in status message. The new leader extends on the tip of a highest
ranked chain certificate (say, lock′) in a status certificate S. Even
if some honest replicas are locked on chain certificates (say, CC”)
that rank higher than lock′), by Corollary 30 it is safe to unlock
on CC”). Hence, honest replicas will vote for blocks that extend
tip(lock′). After that, the honest leader can propose at least one
block in 2∆ time and keep making progress. Moreover, the honest
leader doesn’t equivocate. This ensures all honest replicas keep
committing new blocks.
□
7 EVALUATION
In this section, we evaluate the performance of the protocol with
optimal optimistic responsiveness with 2∆ synchronous latency
and > 3n/4 sized quorum (Section 4). Here after, we call the protocol
OptSync for brevity. We first evaluate the throughput and latency of
OptSync under varying batch sizes and payload. We then compare
OptSync with Sync HotStuff [2] and HotStuff [27] at optimal batch
size under different payloads and system size.
7.1 Implementation Details and Methodology
Our implementation is an adaption of the open-source implemen-
tation of Sync HotStuff. We modify the core consensus logic to
replace the core Sync HotStuff code to OptSync.
In our implementation, each block consists of a batch of client
commands. Each command contains a unique command identifier
and an associated payload. The number of commands in a block
determines its batch size. The throughput and latency results were
measured from the perspective of external clients that run on sep-
arate machines from that of the replicas. The clients broadcast a
configurable outstanding number of commands to every replica.
Clients issue more commands when the issued commands have
been committed. In all of our experiments, we ensure that the per-
formance of replicas are not limited by lack of client commands.
Experimental Setup. All our replicas and clients were installed on
Amazon EC2 c5.4xlarge instances. Each instance has 16 vCPUs
supported by Intel Xeon Platinum 8000 processors with maximum
network bandwidth of upto 10Gbps. The network latency between
two machines is measured to be less than 1ms. We used secp256k1
for digital signatures in votes and quorum certificate consists of an
array of secp256k1 signatures.
Baselines. We make comparisons with two state-of-the-art proto-
cols: (i) HotStuff, a partially synchronous protocol, and (ii) Sync Hot-
Stuff, a synchronous protocol. OptSync shares the same codebase
with HotStuff and Sync HotStuff, and thus enables a fair comparison
between the protocols. Although, HotStuff has a revolving leader
policy, for fair comparison we chose to compare with HotStuff un-
der stable leader policy as both OptSync and Sync HotStuff have a
stable leader in the steady state. In all of the experiments, the curves
represented by OptSync show the protocol’s performance when the
optimistic conditions are met. When the optimistic conditions are
not met, our protocol behaves identically to Sync HotStuff (without
responsiveness) and the curves marked as Sync HotStuff describe
the protocol’s performance.
7.2 Basic Performance
We first evaluate the basic performance of OptSync when the toler-
ating f = 1 fault with a synchronous delay ∆ = 50ms. We measure
the observed throughput (i.e., number of committed commands per
second) and the end-to-end latency for clients. In our first experi-
ment (Figure 7a), each command has a zero-byte payload and we
vary batch size at different values, 100, 400, and 800 as represented
by the three lines in the graph. Each point in the graph represents
the measured throughput and latency for a run with a given load
sent by clients. Basically, clients maintain an outstanding number of
commands at any moment and issue more commands immediately
when previous commands have been committed. We vary the size
of outstanding commands to simulate different loads. As seen in
the graph, the throughput increases with increasing load without
increasing latency upto a certain point before reaching saturation.
After saturation, the latency increases while the throughput ei-
ther remains consistent or slightly degrades. We observe that the
throughput is maximum at around 280 Kops/sec when the batch
size is 400 with a good latency of around 3ms. We set the batch size
to be 400 for our following experiments.
In our second experiment (Figure 7b), we vary the command
request/response payload at different values in bytes 0/0, 128/128
and 1024/1024 with a fixed batch size of 400. Not surprisingly, as the
payload size increases, each command requires a higher bandwidth
and the throughput, measured in number of commands, decreases.
We also observe a marginal drop in latency with increasing payload.
7.3 Scalability and Comparison with Prior
Work
Next, we study how OptSync scales as the number of replicas in-
crease. We also compare with HotStuff and Sync HotStuff. First, we
study how the protocols perform with zero-payload commands to
understand the raw overhead incurred by the underlying consensus
mechanism at different values of f (Figure 8). Then, we study how
the protocols perform at a higher payload of 1024/2024 (Figure 9).
We use a batch size of 400 and a synchronous delay ∆ of 50ms for
both these experiments. Each data point in the graphs represent the
throughput and latency at the saturation point without overloading
the replicas. We note that we are using 2f + 1 replicas for OptSync
and Sync HotStuff, and 3f + 1 replicas for HotStuff.
Comparison with HotStuff. The throughput of OptSync is slightly
less than HotStuff for smaller system sizes (Figures 8a, 9a). But at
higher faults, OptSync performs better than HotStuff for all pay-
loads. This is because in both cases the system is bottlenecked by
a leader communicating with all other replicas and since OptSync
requires fewer replicas to tolerate f faults, its performance scales
better than HotStuff.
In terms of latency (Figures 8b, 9b), OptSync performs much
better than HotStuff. OptSync commits in a single round of votes
wherease HotStuff requires 3 rounds.
Comparison with Sync HotStuff. OptSync is identical to Sync Hot-
Stuff except for the responsive commit-path. The throughput of
OptSync is consistently better than Sync HotStuff (Figures 8a, 9a).
This is because Sync HotStuff, due to the synchronous wait time,
needs to maintain a higher load of blocks at any time. In terms
of latency, since the optimistic commit in OptSync does not incur
O(∆) delays, it’s latency is far superior. We note that Sync Hot-
Stuff [2] work does describe an optimistically responsive protocol
(that was not implemented). However, since they explicitly need
to know whether optimistic conditions are met, they will always
incur at least a 2∆ delay to switch paths, and hence will have a
worse latency.
(a) Varying batch sizes.
(b) Varying payload.
Figure 7: Throughput vs. latency at varying batch sizes and payload at ∆ = 50ms and f = 1.
(a) f vs. throughput.
Figure 8: Performance as function of faults at ∆ = 50ms, optimal batch size, and 0/0 payload.
(b) f vs. latency.
(a) f vs throughput.
Figure 9: Performance as function of faults at ∆ = 50ms, optimal batch size, and 1024/1024 payload.
(b) f vs latency.
Figure 10: Throughput and latency vs time with two commit rules triggered intermittently at ∆ = 50ms and f = 1.
Performance under changing conditions. We further evaluate
the performance of OptSync when the optimistic conditions are
triggered intermittently and replicas commit using different com-
mit rules. To simulate adversarial behavior where some replicas
intermittently do not vote, we have f replicas who only intermit-
tently vote and switch their behavior every 5s. The other f + 1
replicas always vote for all the proposed blocks. Figure 10 shows
the throughput and latency for the commands across execution
time. For latency, each point refers to the average latency for com-
mands that were committed in the past 50ms. The commit latency
switches between 3ms when optimistic conditions are met and
104ms when optimistic conditions are not met. The throughput re-
mains consistent at around 200Kops/sec irrespective of the commit
rules triggered. In comparison, protocols such as Sync HotStuff that
follow the fast-path–slow-path paradigm will require an explicit
view-change if sufficient replicas do not vote in the fast path, and
hence require a view-change to commit.
8 RELATED WORK
There has been a long line of work on Byzantine agreement start-
ing at the Byzantine Generals Problem [18]. Dolev and Strong [9]
presented a deterministic solution to the Byzantine Broadcast prob-
lem in the synchronous model tolerating f < n − 1 faults with a
f + 1 round complexity. Several other works [1, 4, 10, 11, 14, 15, 24]
have been proposed to improve the round complexity. We review
the most recent and closely related works below. In particular, we
4090140190240290Throughput(Kops/sec)1357Latency(ms)OptSync-b100OptSync-b400OptSync-b800130180230280Throughput(Kops/sec)13579Latency(ms)OptSync-p0OptSync-p128OptSync-p102414816FaultyReplicas(f)050100150200250300Throughput(Kops/sec)Sync-HS-p0HotStuff-p0OptSync-p014816FaultyReplicas(f)0306090120Latency(ms)Sync-HS-p0HotStuff-p0OptSync-p014816FaultyReplicas(f)050100150200Throughput(Kops/sec)Sync-HS-p1024HotStuff-p1024OptSync-p102414816FaultyReplicas(f)04080120160200240Latency(ms)Sync-HS-p1024HotStuff-p1024OptSync-p1024010203040506070Time(s)050100150200Throughput(Kops/sec)05101520253035404550556065Time(s)050100Latency(ms)[9] Danny Dolev and H. Raymond Strong. 1983. Authenticated algorithms for
[6] T-H Hubert Chan, Rafael Pass, and Elaine Shi. 2018. PaLa: A Simple Partially
[10] Pesech Feldman and Silvio Micali. 1997. An optimal probabilistic protocol for
[4] Michael Ben-Or. 1983. Another advantage of free choice (Extended Abstract)
Completely asynchronous agreement protocols. In Proceedings of the second
annual ACM symposium on Principles of distributed computing. 27–30.
[5] Miguel Castro, Barbara Liskov, et al. 1999. Practical Byzantine Fault Tolerance.
In OSDI, Vol. 99. 173–186.
Synchronous Blockchain. IACR Cryptology ePrint Archive 2018 (2018), 981.
Synchronous Blockchain. IACR Cryptology ePrint Archive 2018 (2018), 980.
in Byzantine agreement. Journal of the ACM (JACM) 37, 4 (1990), 720–741.
Byzantine agreement. SIAM J. Comput. 12, 4 (1983), 656–666.
synchronous Byzantine agreement. SIAM J. Comput. 26, 4 (1997), 873–933.
[11] Matthias Fitzi and Juan A Garay. 2003. Efficient player-optimal protocols for
strong and differential consensus. In Proceedings of the twenty-second annual
symposium on Principles of distributed computing. 211–220.
[12] Yossi Gilad, Rotem Hemo, Silvio Micali, Georgios Vlachos, and Nickolai Zel-
dovich. 2017. Algorand: Scaling byzantine agreements for cryptocurrencies. In
Proceedings of the 26th Symposium on Operating Systems Principles. 51–68.
[13] Guy Golan Gueta, Ittai Abraham, Shelly Grossman, Dahlia Malkhi, Benny Pinkas,
Michael K Reiter, Dragos-Adrian Seredinschi, Orr Tamir, and Alin Tomescu. 2018.
SBFT: a scalable decentralized trust infrastructure for blockchains. arXiv preprint
arXiv:1804.01626 (2018).
[14] Timo Hanke, Mahnush Movahedi, and Dominic Williams. 2018. Dfinity technol-
ogy overview series, consensus system. arXiv preprint arXiv:1805.04548 (2018).
[15] Jonathan Katz and Chiu-Yuen Koo. 2006. On expected constant-round protocols
for Byzantine agreement. In Annual International Cryptology Conference. Springer,
445–462.
[16] Ramakrishna Kotla, Lorenzo Alvisi, Mike Dahlin, Allen Clement, and Edmund
Wong. 2007. Zyzzyva: speculative byzantine fault tolerance. ACM SIGOPS
Operating Systems Review 41, 6 (2007), 45–58.
[17] Jae Kwon. 2014. Tendermint: Consensus without mining. Draft v. 0.6, fall 1, 11
(2014).
[18] Leslie Lamport, Robert Shostak, and Marshall Pease. 1982. The byzantine generals
problem. ACM Transactions on Programming Languages and Systems 4, 3 (1982),
382–401.
[19] J-P Martin and Lorenzo Alvisi. 2006. Fast byzantine consensus. IEEE Transactions
on Dependable and Secure Computing 3, 3 (2006), 202–215.
[20] Atsuki Momose, Jason Paul Cruz, and Yuichi Kaji. 2020. Hybrid-BFT: Optimisti-
cally Responsive Synchronous Consensus with Optimal Latency or Resilience.
(2020).
[7] T-H Hubert Chan, Rafael Pass, and Elaine Shi. 2018. PiLi: An Extremely Simple
[8] Danny Dolev, Ruediger Reischuk, and H Raymond Strong. 1990. Early stopping
Report. Manubot.
[21] Satoshi Nakamoto. 2009. Bitcoin: A peer-to-peer electronic cash system. Technical
[22] Rafael Pass and Elaine Shi. 2017. Hybrid consensus: Efficient consensus in the
permissionless model. In 31st International Symposium on Distributed Computing
(DISC 2017). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik.
[23] Rafael Pass and Elaine Shi. 2018. Thunderella: Blockchains with optimistic instant
confirmation. In Annual International Conference on the Theory and Applications
of Cryptographic Techniques. Springer, 3–33.
[24] Michael O Rabin. 1983. Randomized byzantine generals. In 24th Annual Sympo-
sium on Foundations of Computer Science (sfcs 1983). IEEE, 403–409.
[25] Fred B Schneider. 1990. Implementing fault-tolerant services using the state
machine approach: A tutorial. ACM Computing Surveys (CSUR) 22, 4 (1990),
299–319.
[26] Elaine Shi. 2019. Streamlined Blockchains: A Simple and Elegant Approach (A
Tutorial and Survey). In International Conference on the Theory and Application
of Cryptology and Information Security. Springer, 3–17.
[27] Maofan Yin, Dahlia Malkhi, Michael K Reiter, Guy Golan Gueta, and Ittai Abra-
ham. 2019. Hotstuff: Bft consensus with linearity and responsiveness. In Pro-
ceedings of the 2019 ACM Symposium on Principles of Distributed Computing.
347–356.
make comparisons with synchronous BFT protocols with the notion
of optimistic and synchronous commit paths. Compared to all of
these protocols, our responsive commit incurs an optimal latency
of 2δ and synchronous commit incurs a latency of 2∆ time while
tolerating the same number of faults.
Thunderella. The idea of optimistic responsiveness in a back-and-
forth slow-path–fast-path paradigm was first introduced in Thun-
derella [23]. They commit a decision in a single round under opti-
mistic executions. Their path switching time and the synchronous
latency is O(κ∆) or O(n∆), where κ is a security parameter.
Sync HotStuff. Like Thunderella, Sync HotStuff [2] is presented
in a back-and-forth slow-path–fast-path paradigm. If started in
the wrong path, their responsive commit will incur a latency of
2∆ + O(δ) time and synchronous commit incurs 4∆ + O(δ) time.
Compared to them, our protocol in Section 6 can also perform an
optimistically responsive view change, while their view change
always incurs a 2∆ delay.
Comparison with works having simultaneity in commits. Our
upper bound results are not the first results to use simultaneous
paths. There are works such as Zyzzyva [16], SBFT [13] and FaB [19]
which have considered the notion of simultaneous paths under par-
tial synchrony. Similarly, a recent work called PiLi [7] achieves
simultaneity under a synchronous assumption. Ours is the first
work that achieves simultaneity under a synchrony assumption
while obtaining optimal latency.
PiLi. PiLi [7] presents a BFT SMR protocol that progresses through
a series of epochs. The protocol assumes lock-step execution in
epochs. Each epoch lasts for O(δ) (resp. 5∆) under optimistic (resp.
synchronous) conditions or O(δ). The protocol commits 5 blocks af-
ter 13 consecutive epochs. PiLi has a responsive (resp. synchronous)
latency of at least 16δ-26δ (resp. 40∆-65∆).
Hybrid-BFT. Hybrid-BFT [20] is an independent and concurrent
work. They propose an optimistically responsive protocol with
both responsive and synchronous commit paths existing simulta-
neously. However, after a responsive commit, their protocol waits
for 7∆ time before starting the next block. From the perspective
of a client, if a command is sent to replicas just after processing
some command, the replicas will not process them for 7∆ time;
though after that, it will immediately commit within O(δ) time. In
comparison, our protocols will commit within O(δ) time without
waiting for a synchronous delay. Their synchronous commits also
incur a similar 7∆ delay after starting a block. They also introduce a
responsive view-change; however, a synchronous wait of 7∆ before
the view-change makes it not responsive in essence.
REFERENCES
[1] Ittai Abraham, Srinivas Devadas, Danny Dolev, Kartik Nayak, and Ling Ren.
2019. Synchronous Byzantine Agreement with Expected O(1) Rounds, Expected
O(n2) Communication, and Optimal Resilience. In International Conference on
Financial Cryptography and Data Security. Springer, 320–334.
[2] Ittai Abraham, Dahlia Malkhi, Kartik Nayak, Ling Ren, and Maofan Yin. 2020.
Sync HotStuff: simple and practical synchronous state machine replication. In
IEEE Security and Privacy.
[3] Ittai Abraham, Kartik Nayak, Ling Ren, and Zhuolun Xiang. 2020. Optimal Good-
case Latency for Byzantine Broadcast and State Machine Replication. arXiv
preprint arXiv:2003.13155 (2020).