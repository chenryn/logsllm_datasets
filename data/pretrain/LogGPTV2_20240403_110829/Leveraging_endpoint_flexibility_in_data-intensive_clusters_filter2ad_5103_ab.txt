Cosmos [19]
256 MB
Thousands
Hundreds
Lower (i.e., Better)
want Sinbad to be usable in public cloud offerings with little or
no access to in-network measurement counters. Sinbad can inter-
act nicely with existing network-level load balancers (e.g., Hed-
era [8], MicroTE [13], or ECMP [28]). This is because network-
level techniques balance load among paths given source-destination
pairs, whereas Sinbad dictates destinations without enforcing spe-
ciﬁc paths.
Fault Tolerance and Scalability Since Sinbad agents are collo-
cated with that of the parent CFS, host failures that can take Sinbad
slaves ofﬂine will take down corresponding CFS agents as well.
If Sinbad master dies, the CFS master can always fall back to the
default placement policy. Because most CFSes already have a cen-
tralized master with slaves periodically reporting to it – Sinbad does
not introduce new scalability concerns. Furthermore, piggybacked
measurement updates from Sinbad slaves introduce little overhead.
4 Measurements and Implications
In this section, we analyze traces from two production data-parallel
clusters – Facebook’s Hadoop-HDFS cluster and Microsoft Bing’s
SCOPE-Cosmos cluster. Table 1 lists the relevant details. In both
clusters, core-to-rack links are the most likely locations for network
bottlenecks.
Our goal behind analyzing these traces is to highlight character-
istics – the volume of distributed writes, the impact of writes on job
performance, and the nature of imbalance in bottleneck link utiliza-
tions – that motivate us to focus on distributed writes and enable us
to make realistic assumptions in our analysis and evaluation.
4.1 Network Footprint of Distributed Writes
Available data points indicate a growing trend of the volume of data
ingested into data-intensive clusters. Recent data from Facebook
• Static Information!• Network topology!• Link, disk capacities!• Dynamic distributions of !• loads in links!• popularity of ﬁles!Info (from slaves)!Sinbad Master!Where to put block B?!{ Locations }!• At least r replicas!• In f fault domains!• Collocate with block B’!• …!Constraints & Hints!Sinbad Master!CFS Master!CFS Slave!Sinbad Slave!CFS Slave!Sinbad Slave!CFS Slave!Sinbad Slave!Where to put block B?!Machine!233Table 2: Sources of Cross-Rack Trafﬁc
Facebook
Microsoft
Reads
14%
31%
Inter.
46%
15%
Job Writes Other Writes
30%
49%
10%
5%
Figure 4: Weighted CDF of the fraction of task durations spent in writing
to HDFS by tasks with write phases.
claims that it ingests more than 500 TB every day (Aug. 2012) [5].
To provide fresh ads and content recommendations, ingestion hap-
pens at regular intervals including peak hours [16, 41]. The inges-
tion engine of Windows Azure Storage (WAS) keeps around 350
TB of Facebook and Twitter data to provide near-realtime search
results within 15 seconds [17]. Finally, Amazon S3 has experi-
enced a sharp rise in the number of objects it stores since 2006; it
currently stores more than 1:3 trillion objects (Jan. 2013) [6], many
of which are likely to be large blobs due to S3’s performance and
pricing models.3
The impact of the increasing volume of writes was evident in
our traces. Although intermediate transfers are known to have sig-
niﬁcant impact on application performance [20], they are far from
being the dominant source of cross-rack trafﬁc! We found that in-
termediate transfers account for 46% and 15% of all cross-rack
trafﬁc in Facebook and Microsoft clusters (Table 2). As expected,
both clusters achieved good data locality – only 10% of all tasks
read input from non-local machines [10, 34, 44].
Contrary to our expectations, however, we observed that cross-
rack replication due to distributed writes accounted for 40% and
54% of the network trafﬁc in the two clusters. In addition to the
ﬁnal output that jobs write to the CFS, we identiﬁed two additional
sources of writes:
1. Data ingestion or the process of loading new data into the clus-
ter amounted for close to 50% of all cross-rack bytes in the
Microsoft cluster.
2. Preprocessor outputs. Preprocessing jobs only have map tasks.
They read data, apply ﬁlters and other user-deﬁned functions
(UDFs) to the data, and write what remains for later consump-
tion by other jobs. Combined with data ingestion, they con-
tributed 30% of all cross-rack bytes in the Facebook cluster.
4.2 Impact of Writes on Job Performance
To understand the impact of writes on task durations, we compare
the duration of the write phase with the runtime of each writer.
For a reduce task, we deﬁne its “write phase” as the time from
the completion of shufﬂe (reading its input from map outputs over
the network) until the completion of the task. For other writers,
we deﬁne the write phase as the timespan between a task ﬁnishing
reading its entire input (from local disk) and its completion time.
(a) Facebook
(b) Microsoft Bing
Figure 5: Imbalance in 10s average utilizations of up and downlinks be-
tween the core and racks in Facebook and Microsoft clusters due to CFS
and non-CFS trafﬁc.
We found that 37% of all tasks write to the CFS. A third of these
are reducers; the rest are other writers. We observed that 42% of
the reduce tasks and 91% of other writers spent at least half their
durations in the write phase (Figure 4). This suggests that faster
writes can help many tasks to complete earlier.
4.3 Characteristics of Network Imbalance
We found that the cumulative trafﬁc from intermediate transfers,
distributed writes, cluster management workload, and the trafﬁc
from collocated services can be substantially imbalanced across the
bottleneck links in the short term (e.g., tens of seconds). Causes
of imbalance include skew in application communication patterns
[14, 35], imbalance in the number of mappers and reducers, and
cluster management events such as rolling updates.
We measured network imbalance using the coefﬁcient of varia-
tion4 (Cv) of the average link utilization in each 10s interval across
up and downlinks (Figure 5). With perfect balance, these values
would be zero. However, in both traces, we found that the down-
links had Cv > 1 for almost half the time. Uplinks were equally
imbalanced in the Facebook trace, but the imbalance was somewhat
lower in the Bing trace. We do not yet know the reason for this.
Although skewed, link utilizations remained stable over short
intervals. Such stability is important to enable predictable online
placement decisions for relatively short block transfers. To analyze
the stability of link utilizations, we calculated average utilization
over different time intervals in all core-to-rack links in the Face-
book cluster. We consider a link’s utilization Ut(l) at time t to be
stable for the duration T if the difference between Ut(l) and the
average value of Ut(l) over the interval [t; t + T ) remains within
StableCap% of Ut(l). We observed that average link utilizations
remained stable for smaller durations with very high probabilities.
For the most unpredictable link, the probabilities that its current
utilization from any instant will not change by more than 5% for
the next 5, 10, 20, and 40 seconds were 0:94, 0:89, 0:80, and
0:66, respectively. Compare these with the 256 MB blocks used
in these clusters. It will take around 5s to write such a block at a
disk throughput of 50 MBps, which is small enough to exploit uti-
lization stability periods. We found that 81% of all bytes written to
the CFS come from 32% of the blocks that are 256 MB in size.
Imbalance without congestion may not impact performance. We
observed in the Facebook trace that the 95th percentile load across
bottleneck links was more than 75% of link capacity 25% of the
time. However, the effect of congested links is magniﬁed – a single
3S3 charges for individual PUT requests, and PUT response times
are empirically better for larger objects.
4Coefﬁcient of variation, Cv = (cid:27)
in relation to the mean of the population.
(cid:22) , shows the extent of variability
!"#$!"#%!"#&!"#'!"#(!")!")*!")#!"))!")+!")$!")%!")&!")'!")(!"+!"+*0!0.25!0.5!0.75!1!0!0.25!0.5!0.75!1!CDF!(Weighted by Bytes Written)!Fraction of Task Duration in Write!Preproc./Ingest!Reducers!Combined!0!0.25!0.5!0.75!1!0!1!2!3!4!5!6!Fraction of Time!Coeff. of Var. of Load Across Core-Rack Links!Down Links!Up Links!0!0.25!0.5!0.75!1!0!1!2!3!4!Fraction of Time!Coeff. of Var. of Load Across Core-Rack Links!Down Links!Up Links!234bottleneck link can impact a large number of jobs if they have tasks
communicating through that congested link.
Finally, despite signiﬁcant short-term imbalance, link usages be-
come more balanced over longer intervals (e.g., over hours). Dur-
ing normal operation (i.e., in absence of failures), we observed that
each bottleneck link is almost equally likely to become a hotspot.
4.4 Summary
We make the following observations in this section.
(cid:15) Replication account for almost half the cross-rack trafﬁc in
data-intensive clusters, and its magnitude is rapidly increasing.
(cid:15) Network congestion in such clusters has signiﬁcant skew across
bottleneck links in the short term, but the skew is minimal over
longer durations.
(cid:15) Durations of write tasks (e.g.,
ingestion and preprocessing
(cid:15) Most bytes written to the CFS belong to the maximum sized
tasks) are dominated by time spent in writing.
(256 MB) blocks.
5 Analytical Results
In this section, we
The distributed writing problem is NP-hard.
provide insights into the complexity of this problem, consider as-
sumptions that make the problem tractable, and present two opti-
mal algorithms under the simplifying setting. We also discuss the
potential for improvements using a network-aware solution.
Detailed analysis and proofs can be found in the appendix.
5.1 Optimizing Block Writes
The primary objective of a CFS is to minimize the average block
write time, which also results in maximizing the system utiliza-
tion of the CFS. The optimal placement algorithm must select the
best destinations (through suitable bottleneck links) for all block
requests as they arrive.
Complexity Optimizing for block writes is NP-hard, even when
all block requests and link capacities are known beforehand. This
can be proven by a reduction from the NP-hard job-shop scheduling
problem (Theorem A.1).
The online distributed writing problem is even harder because of
the following reasons:
1. Links have different available capacities.
2. Lack of future knowledge about
(a) bottleneck link utilizations throughout the duration of repli-
cation, and
(b) new replica placement requests (sizes and arrival times) to
arrive while a block is being replicated.
Variations of job shop scheduling with one or more of the above-
mentioned characteristics are known to be NP-hard and hard to ap-
proximate as well [9, 36, 37].
Simpliﬁed Model For the ease of analysis, we make the following
assumptions based on our observations in Section 4.
1. Blocks have a ﬁxed size. The size of each block is already
bounded. Additionally, we assume all blocks to have the same
size (i.e., blocks are padded). Because most bytes are generated
by a third of all blocks written, we ignore the impact of the rest
during analysis.
2. Link utilization is ﬁxed while a block is being written. Since
link utilizations remain reasonably stable in the short term, we
assume that changes in bottleneck links are precisely known
throughout the duration of writing a block. Changes are ex-
pected only due to trafﬁc introduced by replication.
3. Potential bottleneck links are easily discernible. Given the
oversubscribed (logical) tree-based topologies of data-intensive
clusters, links leading in and out of the racks are likely to be the
bottlenecks. We assume that the potential network bottlenecks
are known, which allows us to abstract away the topology.5
′
4. Decision intervals are independent. We assume that block re-
quests arrive at the beginning of decision intervals, and they
are small enough so that their replication ﬁnish within the same
interval. All decision intervals have the same length, q.
Given the aforementioned assumptions, greedy assignment of
blocks to the least-loaded link ﬁrst is optimal for minimizing the
average block write time (see Theorem A.2). We refer to this algo-
rithm as OP T . OP T ’s improvements over the uniform placement
policy increases with the increasing imbalance in the network and
as the number of off-rack replicas increases (§A.2).
5.2 Optimizing File Writes
CFSes store data by dividing it into ﬁxed-sized blocks. Hence, a
request to write a large ﬁle/object generates a sequence of block
write requests. For a writer, the objective then to minimize the
average ﬁle write time. Optimizing the average ﬁle write time is
no easier than optimizing the average block write time, and, it is
NP-hard as well.
OP T is optimal when all blocks have the same size. However,
ﬁles can have different sizes, which can result in different numbers
of equal-sized blocks. Using a simple counter-example it can be
shown that OP T is not optimal in this case (Lemma B.1).
Given the assumptions in Section 5.1 and with OP T in place,
greedy assignment of blocks through links in the least-remaining-
blocks-ﬁrst order is optimal for minimizing the average ﬁle write
time (see Theorem B.2). We refer to this algorithm as OP T
.
′
′
′
OP T
favors smaller ﬁles. However, larger ﬁles will not com-
pletely starve as long as the arrival rate of block requests does not
exceed the simultaneous serving capacity of the system.
OP T
requires the decision interval to be longer than zero (i.e.,
q > 0) so that it can order blocks from different ﬁles by the num-
ber of blocks remaining in their parent ﬁles. In contrast, q = 0
refers to a pure online solution, where OP T
reduces to OP T . The
length of the decision interval (q) presents a tradeoff. A larger q po-
tentially provides better opportunities for OP T
, but it introduces
additional delay to the write time of each block in that interval.
6 Design Details
This section discusses the expected operating environment of Sin-
bad (§6.1), how Sinbad estimates bottleneck link utilizations across
the cluster (§6.2), and how it incorporates (§6.3) the algorithms in-
troduced in Section 5.
6.1 Operating Environment
We make the following assumptions about the characteristics of
write requests and on the availability of certain pieces of informa-
tion (e.g., oversubscription in the topology).
Because most bytes are generated by a third of all blocks writ-
ten, we consider only ﬁxed-sized blocks in Sinbad. This allows
Sinbad to ignore the arrival order of block requests when making
a decision for the current block request. In a sense, this problem
is akin to an online load balancing problem. A frequent stream of
roughly evenly-sized entities is quite easy to balance. Contrast this
with the case when block sizes are unbounded; whether or not large
blocks will arrive in the future crucially impacts placement, since
5Generalizing to arbitrary topologies adds overhead. For example,
we would have to run max-ﬂow/min-cut to determine which of the
many bottlenecks are tight given a placement.
′
235▷ Ignore small blocks
▷ Terminating condition
end if
if B.size < THRESHOLD then
return Default.getReplicaLocations(B)
Pseudocode 1 Request Dispatching Algorithm
1: procedure GETREPLICALOCATIONS(Request B)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11: end procedure
end if