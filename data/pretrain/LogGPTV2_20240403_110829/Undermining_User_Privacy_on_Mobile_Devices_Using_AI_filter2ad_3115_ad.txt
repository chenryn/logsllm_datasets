### 6.1 Website and Application Inference

In the literature, various methods have been explored to infer visited websites and running applications. Vila et al. [47] utilize shared event loops to infer opened websites from the server side. Panchenko et al. [37] employ traffic analysis to detect visited websites in the Tor network. Zhang et al. [51] exploit iOS APIs to infer both visited websites and running applications. Spreitzer et al. [42, 43] extract distinct features from the `procfs` filesystem and use Android APIs to infer opened web pages and applications. Lee et al. [27] leverage uninitialized GPU memory pages to detect websites, while Naghibijouybari et al. [35] use OpenGL APIs and GPU performance counters for the same purpose. Gulmezoglu et al. [20] monitor hardware performance events of modern processors to infer visited websites. Diao et al. [6] infer applications through system interrupts. Jana and Shmatikov [26] demonstrate that websites leave a distinct memory footprint in the browser application. Oren et al. [36] and Gruss et al. [13] show that opened websites and their individual elements can be inferred from cache observations using malicious JavaScript applets. Shusterman et al. [41] extend this work by inferring websites from JavaScript with simple last-level cache profiles, classified by convolutional neural networks (CNNs) and long short-term memory (LSTM) networks. As this is concurrent work, we provide a detailed comparison later in this section. Gulmezoglu et al. [19] use cache observations to detect running applications in co-located virtual machines. In our work, we also use measurements of cache activity to infer running applications, visited websites, and streamed videos.

**Table 1: Related Website and Application Inference Attacks**

| Attack Vector                | Acc. (%) | Classes |
|-----------------------------|----------|---------|
| Last-level Cache (LLC)       | 85.8     | 70      |
| LLC                          | 82.1     | 8       |
| CPU Performance Events       | 86.1     | 100     |
| GPU Performance Events       | 84.0     | 30      |
| Uninitialized GPU Memory     | 93.0     | 200     |
| Scheduling Statistics        | 95.4     | 100     |
| Shared Event Loops           | 78.0     | 100     |
| Traffic Analysis             | 76.7     | 500     |
| iOS APIs                     | 92.5     | 100     |
| Java-based Android API       | 68.5     | 20      |
| ProcFS Leaks                 | 89.4     | 20      |
| LLC                          | 94.0     | 70      |
| LLC                          | 97.8     | 40      |
| iOS APIs                     | 78.5     | 120     |
| Java-based Android API       | 89.0     | 20      |
| Interrupt Handling           | 85.6     | 100     |
| ProcFS Leaks                 | 87.0     | 100     |
| LLC                          | 96.0     | 70      |

Our results are compared with other attacks in Table 1. It shows that GPU-, network traffic-, and operating system-based attacks achieve higher success rates for website classification than our inference attack. However, our attack does not require access to GPU, network, or OS APIs, which can be restricted or easily monitored. We rely on simple memory accesses and coarse-grained timing measurements, which are difficult to restrict and monitor. Compared to the LLC-based attack by Oren et al. [36], our success rates are higher, even though we classify significantly more websites. Compared to the results by Shusterman et al. [41], we achieve similar classification rates. At the same time, we relax the attacker model by compensating for imprecise timing sources and random cache replacement policies. For application detection, our approach achieves, to the best of our knowledge, the highest success rate in the literature.

#### Comparison with Shusterman et al. [41]

Shusterman et al. present a similar inference attack to the one proposed in this work. Their LLC profiling is based on traces of cache activity (called memorygrams) obtained from repeatedly accessing a buffer as large as the LLC. The time to access the entire buffer relates to the activity in the LLC, which is used to infer websites. In contrast, we build eviction sets to profile individual parts of the LLC, providing a more fine-grained view of the cache activity. Shusterman et al. profile the LLC for 30 seconds, while our profiling phase is only 1.5 seconds. The authors choose their CNN parameters based on the success rate, while we select parameters based on validation loss, making the trained model more robust. This leads to differences in parameter selection, particularly regarding the number of convolution layers, kernel size, and pooling size. While Shusterman et al. use 3 convolution layers, a varying kernel size for each layer, and a pooling size of 4, we train our model with 2 convolution layers, a constant kernel size per layer, and a pooling size of 2. Furthermore, we incorporate the CNN design guidelines by Prouff et al. [38]. In summary, both works share a common goal but differ in approach and attack environment. Shusterman et al. launch their attack from JavaScript on Intel CPUs, while we conduct our attack on Android and ARM. The achieved classification rates for Google Chrome are comparable in both environments, emphasizing that such inference attacks are a practical, cross-platform threat.

### 6.2 Cache Attacks on ARM

Most known cache attacks either use dedicated flush instructions [16, 18, 49] or targeted thrashing of cache sets [9, 17, 24, 45] to observe cache activity. While many techniques have been proposed for x86 processors, Lipp et al. [29] demonstrated the feasibility of attacks on ARM processors, which complicate attacks with random replacement policies, exclusive and non-inclusive cache hierarchies, and internal line locking mechanisms [12]. In this work, we show that despite these challenges, simple LLC observations are sufficient to infer user activity on ARM-based mobile devices. Unlike previous work, we pair these simple observations with advanced machine learning techniques, thereby alleviating attack difficulties on ARM processors.

#### Comparison with Lipp et al. [29]

Lipp et al. perform multiple cache attacks on ARM devices, including Prime+Probe [45], the attack technique employed in this work. We compare the Prime+Probe technique by Lipp et al. to ours. Specifically, we set up an experiment to classify the first 20 websites from Table 4 in Appendix A. We obtain the Prime+Probe code from the GitHub repository [30] by Lipp et al. and run the eviction strategy evaluator on the ARM Cortex-A57. The strategy 22-1-6 yields the highest eviction rate of 98%. The code by Lipp et al. uses pagemap entries to find eviction sets (thus requiring root privileges), while we employ algorithms 1 and 2 that work without elevated privileges. The profiling phase for the website classification is 1.5 seconds. We collect 800 LLC profiles for each website, using 90% as training data and the rest as test data. We then derive the ordered and FFT feature vectors, as described in Section 3.3. We omit the unordered feature vector, as it yielded lower accuracies in our experiments. While the approach by Lipp et al. achieves classification rates of 90% and 85% (ordered and FFT), our approach yields 93% and 94%. Thus, our profiling technique achieves higher classification rates while requiring no root privileges to find eviction sets.

### 6.3 Machine Learning and SCAs

Side-channel attacks (SCAs) typically rely on signal processing and statistics to infer information from observations. Since 2011, advanced machine learning approaches have been introduced to side-channel literature. Lerman et al. [28] use random forests (RFs), SVMs, and self-organizing maps (SOMs) to compare the effectiveness of machine learning techniques against template attacks. Later, Gulmezoglu et al. [19] showed that SVM-based approaches can be used to extract features from FFT components obtained from cache traces. Martinasek et al. [33, 34] showed that basic neural network techniques can recover AES keys with a 96% success rate. With the increasing popularity of deep learning, corresponding techniques were also studied for SCAs. In 2016, Maghrebi et al. [32] compared four deep learning techniques with template attacks while attacking an unprotected AES implementation using power consumption. In 2017, Schuster et al. [39] showed that encrypted streams can be used to classify videos with CNNs. Gulmezoglu et al. [20] used hardware performance events to classify websites visited on a personal computer using SVM and CNN.

#### Comparison with Prouff et al. [38]

It is important to follow a systematic approach when choosing parameters of CNNs. Prouff et al. studied the parameter selection of MLP and CNN in the context of side-channel attacks. According to their work, there are four rules to follow:
1. Consecutive convolution layers should have the same parameters.
2. Pooling layers should have a dimension of 2.
3. The number of filters in a convolution layer should be higher than the one of the previous layer.
4. All convolution layers should have the same kernel size.

While we implement rules 1, 2, and 4, rule number 3 does not apply to our experiments. Instead, the number of filters decreases for each convolution layer. Additionally, we do not exhaustively explore batch sizes and optimization methods, as they do not significantly affect the validation loss in our case.

### 7 Conclusion

Inference attacks undermine privacy by revealing our most secret interests, preferences, and attitudes. Unfortunately, modern processors, which form the core of our digital infrastructure, are particularly vulnerable to these attacks. Footprints in the processor cache allow the inference of running applications, visited websites, and streaming videos. The advances in machine learning, especially the concepts behind deep learning, significantly lower the bar for successfully implementing inference attacks. Our work demonstrates that it is possible to execute an inference attack without privileges, permissions, or access to special programming interfaces and peripherals. The simple nature of the attack code makes comprehensive defense extremely difficult. This simplicity is paired with the careful application of deep learning, which conveniently compensates for interferences such as measurement noise, misalignment, or unfavorable processor features. The comparison with concurrent work indicates that inference attacks of this kind are ubiquitous and succeed across runtime environments and processing hardware. For applications that value the privacy of their users, protection against inference attacks is of utmost importance. A comprehensive solution, however, seems to require closer collaboration between hardware manufacturers, operating system designers, and application developers.

### Acknowledgments

We would like to thank our shepherd Martina Lindorfer and the anonymous reviewers for their valuable feedback. This work is supported by the National Science Foundation, under grants CNS-1618837 and CNS-1814406. Berk Gulmezoglu is also supported by the WPI PhD Global Research Award 2017.

### References

[References listed here as in the original text.]

This version of the text is more structured, coherent, and professional, with clear headings and subheadings, and a more polished writing style.