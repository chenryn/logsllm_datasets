               Output: .................................................  
               Index Cond: ((refund.refund_digoal_rid_id = 35018) AND (refund.refund_type = 3))  
               Buffers: shared hit=32  
         ->  Index Scan using idx_digoal_tbl_task_2 on public.digoal_tbl_task task  (cost=0.56..8.53 rows=1 width=271) (actual time=0.014..0.014 rows=1 loops=30)  
               Output: .........................................................  
               Index Cond: ((task.digoal_dealid = 2997380888::bigint) AND (task.task_type = 300) AND (task.status = 8) AND (task.biz_id = refund.id))  
               Buffers: shared hit=151  
 Planning time: 0.419 ms  
 Execution time: 0.756 ms  
(16 rows)  
```  
内表扫描30次，扫描151个BLOCK。(每次访问5个PAGE，root+branch1+branch2+leaf+heap)   
```  
create extension pageinspect;  
postgres=# select * from bt_metap('idx_digoal_tbl_task_2');  
 magic  | version | root  | level | fastroot | fastlevel   
--------+---------+-------+-------+----------+-----------  
 340322 |       2 | 25447 |     3 |    25447 |         3  
(1 row)  
```  
响应也从7毫秒，降低到了0.7毫秒。  
重新压测，性能达到 2万tps。   
性能：  
```  
tps = 19932.917811 (including connections establishing)  
tps = 19934.054737 (excluding connections establishing)  
```  
## 八、索引深度  
接着第七个问题，内表每次访问，都是索引访问，那么每次的索引访问需要访问多少个数据块呢？和索引深度有关：  
```  
meta page, root page, branch page(optional), leaf page, heap page(optional).  
```  
这里索引的深度决定了要访问多少个索引页，有命中时，则需要访问到heap page。  
索引深度由索引页内记录数以及整个HEAP表被索引的记录的记录数决定。  
原理详见：  
[《深入浅出PostgreSQL B-Tree索引结构》](../201605/20160528_01.md)    
[《PostgreSQL 9种索引的原理和应用场景》](../201706/20170627_01.md)    
[《自动选择正确索引访问接口(btree,hash,gin,gist,sp-gist,brin,bitmap...)的方法》](../201706/20170617_01.md)    
## 九、partial index  
partial index实际上是部分索引，可用来降低索引深度，例如1000万条记录，如果每个索引 BLOCK 可以存放260个ITEM (ctid即行号固定8字节，加上字段本身内容的长度，占一个IDX ITEM的长度)，那么需要3层。    
```  
root page(260), branch page(260/root), leaf page(260/branch).  
postgres=# select 260*260*260;  
 ?column?   
----------  
 17576000  
(1 row)  
```  
3层树刚好满足1千多万条记录。                                                                                                                                                                                       
通过降低索引树的层级，在大量LOOP时，可以减少扫描的BLOCK数量。怎么降低层级呢？partial index是一种方法，另一种方法是减少索引字段个数。  
比如  
```  
Index Cond: ((task.digoal_dealid = 2997380888::bigint) AND (task.task_type = 300) AND (task.status = 8) AND (task.biz_id = refund.id))  
```  
原来是多字段复合索引，改成partial index   
```  
create index idx on task (biz_id) where digoal_dealid = 2997380888 and task_type = 300 and status = 8;  
```  
这样的话被索引的记录变少了，可以直接影响索引层级。  
同时索引也从4个字段降到了1个字段，每个IDX ITEM也变短了，一个PAGE可以存储更多的ITEM，因此索引层级再次压缩。  
性能再次提升：  
```  
 Limit  (cost=37641.76..37641.76 rows=1 width=784) (actual time=0.174..0.226 rows=10 loops=1)  
   Output: ..................................  
   Buffers: shared hit=122  
   ->  Nested Loop  (cost=0.86..37641.76 rows=11 width=784) (actual time=0.031..0.222 rows=30 loops=1)  
         Output: ........................................................  
         Buffers: shared hit=122  
         ->  Index Scan using idx_digoal_rid_idtype_1 on public.digoal_tbl_refund refund  (cost=0.56..10839.91 rows=5945 width=513) (actual time=0.020..0.056 rows=30 loops=1)  
               Output: ................................................  
               Index Cond: ((refund.refund_digoal_rid_id = 35018) AND (refund.refund_type = 3))  
               Buffers: shared hit=32  
         ->  Index Scan using idx on public.digoal_tbl_task task  (cost=0.29..4.50 rows=1 width=271) (actual time=0.004..0.004 rows=1 loops=30)  
               Output: ................................................  
               Index Cond: (task.biz_id = refund.id)  
               Buffers: shared hit=90  
 Planning time: 0.423 ms  
 Execution time: 0.303 ms  
(16 rows)  
```  
因为记录数降了，索引层级直接变2级，每次访问3个PAGE(root, leaf, heap)，循环30次仅仅访问了90个BLOCK，达到了极限。     
```  
postgres=# select * from bt_metap('idx');  
 magic  | version | root | level | fastroot | fastlevel   
--------+---------+------+-------+----------+-----------  
 340322 |       2 |    3 |     1 |        3 |         1  
(1 row)  
```  
性能：  
```  
tps = 20261.781186 (including connections establishing)  
tps = 20263.110009 (excluding connections establishing)  
```  
## 小结  
本文通过一个OUTER JOIN的例子，展示了JOIN相关的知识点，涉及内存带宽 , JOIN算法 , FILTER亲和力 , TSP , HINT , 索引扫描顺序与命中率 , 语义转换 , 扫描顺序 , 存储顺序 , 命中率 , 索引深度 , partial index   。    
最后通过提高内表命中率，降低索引层级等方法，减少内存访问消耗，性能从300多TPS，提升到了2万多TPS。  
更智能的方法是关联分区、TSP算法与数据分区的结合。解决JOIN过滤与亲和, limit的问题。    
## 参考  
[《关键时刻HINT出彩 - PG优化器的参数优化、执行计划固化CASE》](../201607/20160723_02.md)    
[《深入浅出PostgreSQL B-Tree索引结构》](../201605/20160528_01.md)    
[《PostgreSQL 9种索引的原理和应用场景》](../201706/20170627_01.md)    
[《自动选择正确索引访问接口(btree,hash,gin,gist,sp-gist,brin,bitmap...)的方法》](../201706/20170617_01.md)    
[《PostgreSQL nestloop/hash/merge join讲解》](../201205/20120521_02.md)    
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")