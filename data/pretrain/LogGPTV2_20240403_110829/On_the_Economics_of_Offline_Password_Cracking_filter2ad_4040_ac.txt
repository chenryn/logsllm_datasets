following question: Does this noise, however small, affect
our CDF-Zipf ﬁtting process in any signiﬁcant way? We
claim that the answer is no, and we offer strong empirical
evidence in support of this claim. In particular, we took the
RockYou dataset (N ≈ 32.6 million users) and generated
30 different perturbed versions of the frequency list by
running the (, δ)-differentially private algorithm of Blocki
et al. [13]. We set  = 0.25, the same value that was
used to collect the Yahoo! dataset that we analyze. For
each of these perturbed frequency lists we compute a CDF-
Zipf law ﬁt using linear least squares regression. To apply
Linear Least Squares regression we apply logarithms to the
858
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:33:59 UTC from IEEE Xplore.  Restrictions apply. 
Sample Size
(Millions)
15
30
45
60
Full
y
r
0.00949
0.01321
0.01592
0.01810
0.02112
0.2843
0.2544
0.2384
0.2277
0.2166
2
R
0.9542
0.9531
0.9529
0.9530
0.9544
TABLE 2: Yahoo! CDF-Zipf with Sub-sampling
CDF-Zipf equation λt = y · t
log λt = log y + r log t.
r to obtain a linear equation
impact
Our results, shown in Table 1, strongly suggest that
the
the differential privacy mechanism does not
parameters y and r in a CDF-Zipf ﬁtting in any signiﬁcant
way. In particular, the parameters y and r we obtain from
ﬁtting the original data with a CDF-Zipf model are virtually
indistinguishable from the parameters we obtain by ﬁtting on
one of the perturbed datasets. Similarly, differential privacy
2
2 value of the CDF-Zipf ﬁt. Here, R
does not affect the R
measures how well the linear regression models the data
2 values closer to 1 indicate better ﬁttings). Thus, one
(R
can compute CDF-Zipf’s law parameters for the Yahoo!
data collected by [13] and [12] without worrying about the
impact of the (, δ)-differentially private algorithm used to
perturb this dataset. We also veriﬁed that the noise added to
the Yahoo! dataset will also have a negligible affect on the
parameters s and z in a PDF-Zipf ﬁtting.
3.3. Testing Stability of CDF-Zipf Fit via Subsam-
pling
There are two primary ways to ﬁnd a CDF-Zipf ﬁt:
Golden Section Search (GSS) and Linear Least Squares
(LLS). Wang et al. [11] previously found that CDF-Zipf ﬁts
stabilize more quickly with GSS than with LLS. This was
particularly important because the largest dataset they tested
had size ≈ 3 × 10
7. In this section we test the stability of
LLS by subsampling from the much larger Yahoo! dataset.
In particular, we subsample (without replacement) datasets
of size 15 million, 30 million, 45 million and 60 million and
use LLS to compute the CDF-Zipf parameters y and r for
each subsampled dataset. Our results are shown in table 2
graphically in Figure 1. While the CDF-Zipf ﬁt returned by
LLS does take longer to stabilize our results indicate that
it does eventually stabilize at larger (sub)sample sizes (e.g.,
the Yahoo! dataset).
stabilize before N = 7 × 10
We also found that the PDF-Zipf parameters s and z
7 samples.
3.4. Fitting the Yahoo! data set with CDF-Zipf
We used both LLS regression and GSS to obtain separate
CDF-Zipf ﬁttings for the Yahoo! dataset. The results, shown
in table 3 and graphically in Figure 6 showed that both
methods produce high quality ﬁttings. In addition to the
859
Fig. 1: Yahoo! CDF-Zipf Subsampling
Method
LLS
GSS
y
0.0211
0.03315
r
0.2166
0.1811
2
R
KS
0.9544
0.9498
0.0094328
0.022282
TABLE 3: Yahoo! CDF-Zipf Test Results
2 values and Kolmogorov-
parameters y and r we report R
Smirnov (KS) distance. The KS test can be thought of as
the largest distance between the observed discrete distribu-
tion Fn (x) and the proposed theoretical distribution F (x).
Formally,
DKS = sup |Fn(x) − F(x)|
Intuitively, smaller DKS values (resp.
indicates better ﬁts.
larger R
2 values)
3.4.1. Discussion. Both LLS and GSS produce high quality
2 = 0.9544) for the Yahoo! dataset.
CDF-Zipf ﬁttings (e.g., R
LLS regression outperforms the golden section search under
2 and Kolmogorov-Smirnov (KS) tests. Wang and
both R
Wang [11] had previously adopted golden section search
because the results stabilized quickly. While this was most
likely the right choice for smaller password datasets like
RockYou, our analysis in the previous section suggest that
LLS eventually produces stable solutions when the sample
size is large (e.g., N ≥ 60 million samples) as it is in the
Yahoo! dataset. Thus, in the remainder of the paper we use
the CDF-Zipf parameters y = 0.0211 and = 0.2166 from
LLS regression. We stress that the decision to use the CDF-
Zipf parameters from LLS instead of the parameters returned
by GSS does not affect our ﬁndings in any signiﬁcant way.
We remark that LLS is also more efﬁcient computation-
ally. While we were able to run GSS to ﬁnd a CDF-Zipf
ﬁt for the Yahoo! dataset (N ≈ 7 × 10
7), running GSS on
a dataset of N = 1 billion passwords (e.g., the size of the
most recent Yahoo! breach [34]) would be difﬁcult if not
intractable. By contrast, LLS could still be used to ﬁnd a
CDF-Zipf ﬁtting and our analysis suggests that the ﬁt would
be superior.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:33:59 UTC from IEEE Xplore.  Restrictions apply. 
Dataset
RockYou
000webhost
Battleﬁeld
Tianya
Dodonew
CSDN
Mail.ru
Gmail
Flirtlife.de
Yahoo!
y
0.0374
0.0059
0.0103
0.0622
0.0194
0.0588
0.0252
0.0210
0.0346
0.0211
r
0.1872
0.2816
0.2949
0.1555
0.2119
0.1486
0.2182
0.2257
0.2916
0.2166
7
6
7
T (y, r, 1)
1.70 × 10
7
3.67 × 10
2.37 × 10
2.28 × 10
4.92 × 10
7.63 × 10
8.75 × 10
1.14 × 10
4.44 × 10
2.25 × 10
7
7
6
7
4
7
7
6
7
T (y, r, 0.8)
2.04 × 10
7
4.27 × 10
2.77 × 10
2.76 × 10
5.87 × 10
9.24 × 10
1.04 × 10
1.36 × 10
5.19 × 10
2.69 × 10
7
7
7
7
4
7
TABLE 4: CDF-Zipf threshold T (y, r, a) < v/k at which
adversary cracks 100% of passwords for a ∈ {1, 0.8}.
4. Analysis of Rational Adversary Model for
Zipf’s Law
In this section, we show that there is a ﬁnite threshold
T (y, r, a) which characterizes the behavior of a rational
ofﬂine adversary when user passwords follow CDF-Zipf’s
r. In particular,
law with parameters y and r i.e., λi = yi
Theorem 1 gives a precise formula for computing this
threshold T (y, r, a)7. If v/k ≥ T (y, r, a) then a rational
value v adversary will proceed to crack all user passwords
as marginal guessing rewards will always exceed marginal
guessing costs for a rational attacker. In Table 4 we use
this formula to explicitly compute T (y, r, a) for the Yahoo!
dataset as well as for nine other password datasets analyzed
by Wang and Wang [11].
We note that we choose to focus on CDF-Zipf’s law
in this section as it is believed to be better than PDF-
Zipf models. However, we stress that similar bounds can be
derived using PDF-Zipf’s law though we omit these results
from the submission for lack of space.
Theorem 1. Let k denote the cost of attempting a password
guess. If
v
k
where
(cid:6)
≥ T (y, r, a) = max
t≤Z
(cid:7)1/r
(cid:8)(cid:6)
(cid:9)
(cid:7)
1 − y(t − 1)r
ya(ra)tra−1
Z =
1
y
+ 1
then a value v rational attacker will crack 100% of
passwords chosen from a Zipf’s law distribution with
parameters y and s.
Proof :
Suppose a password frequency distribution fol-
lows Zipf’s Law, for some parameters 0 < r < 1 and
r. Since the marginal revenue is
y, so that λn = yn
a
a
t−1) and the marginal cost is MC(n) =
MR(n) = v(λ
t − λ
, a rational adversary can be assumed to
k
(cid:2)t
n=1 pn
1 −
(cid:11)
(cid:10)
7. We remark that when a = 1 it is possible to derive a closed form
expressing for the threshold T (y, r, a).
continue attacking as long as MR(n) ≥ MC(n). Therefore,
the attacker will not quit as long as
t−1) ≥ k
t(cid:4)
(cid:12)
(cid:13)
pn
a
a
v(λ
t − λ
a(t − 1)ra) ≥ k(1 − y(t − 1)r)
1 −
n=1
a
v(y
ra − y
t
In particular, the attacker will not quit as long as
≥
v
k
1 − y(t − 1)r
(cid:11)
(cid:10)
yatra − ya(t − 1)ra .
max
t
≥ maxt
1−y(t−1)r
yatra−ya(t−1)ra
Notably, if v
for all t, then
k
a rational adversary will eventually crack all passwords.
ar−1 dx we have
a
Since y
a(ra)(t − 1)ar−1 ≤ y
ra−1
y
and
t−1 y
a(t − 1)ra ≤ y
a(t−1)ra =
(cid:5)t
(cid:7)
ra − y
t
a(ra)x
ra −y
t
a(ra)t
(cid:6)
(cid:6)
(cid:7)
a
1 − y(t − 1)r
yatra − ya(t − 1)ra
(cid:10)
(cid:11)
≥ max
1 − y(t − 1)r
ya(ra)tra−1
. We note that if, ∀t ≥ Z, f
t
1−y(t−1)r
ya(ra)tra−1
(cid:4)(t) ≤
Let f(t) =
0 then for any value of t exceeding Z it will always be true
≥ 0, and thus an adversary will be expected to crack
that v
k
all passwords. Then it follows that
1−ar
(t − 1)r−1
t
a
−ar
(cid:4)(t) =
1−a
y
f
.
a(1 − (t − 1)r
y
ar
y)
,