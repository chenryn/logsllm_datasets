title:Protecting location privacy against inference attacks
author:Kazuhiro Minami and
Nikita Borisov
Protecting Location Privacy against Inference Attacks
Kazuhiro Minami
National Institute of Informatics
Tokyo, Japan
PI:EMAIL
Nikita Borisov
University of Illinois at Urbana-Champaign
Urbana, IL 61801–2307
PI:EMAIL
ABSTRACT
GPS-enabled mobile devices are a quickly growing market
and users are starting to share their location information
with each other through services such as Google Latitude.
Location information, however, is very privacy-sensitive, since
it can be used to infer activities, preferences, relationships,
and other personal information, and thus access to it must
be carefully protected. We provide a formal deﬁnition of
location privacy that incorporates an adversary’s ability to
predict location and discuss possible implementation of ac-
cess control mechanisms that satisfy this deﬁnition. To sup-
port our reasoning, we analyze a preliminary data set to
evaluate the accuracy of location prediction.
Categories and Subject Descriptors: C.2.4 [Distributed
Systems]: Distributed applications; K.6.5 [Management of
Computing and Information Systems]: Security and Protec-
tion
General Terms: Security
Keywords: Location privacy, access control, the Markov
model
1.
INTRODUCTION
Soon the vast majority of mobile devices will be equipped
with some form of localization capability; already, most smart
phones include a GPS receiver. This has led to the rise of
location-based services on a number of mobile platforms, in-
cluding Symbian, iPhone, and Android. Novel applications,
such as Google Latitude [3] have opened up the possibilities
of sharing location information with other users [2, 3, 5].
Location sharing raises signiﬁcant privacy concerns [1],
since a location, such as a bar or a hospital, can be used to
infer a user’s personal activities. Therefore, location-sharing
services (LSSs) have introduced access controls that allow
the user to specify what location data may be shared with
whom. For example, Google Latitude allows a user to au-
thorize others’ access to his or her location; it also allows
a user to enter a decoy location manually. Glympse [2]
speciﬁes a time duration during which location informa-
tion is shared. These interfaces provide coarse-grained con-
trols. Researchers in pervasive computing have proposed
more ﬁne-grained access control schemes [4, 6, 8] that make
use of context information such as location, time of day, and
so on. These rules both better represent the users’ actual
Copyright is held by the author/owner(s).
CCS’10, October 4–8, 2010, Chicago, Illinois, USA.
ACM 978-1-4503-0244-9/10/10.
Figure 1: Example safe disclosure of location infor-
mation. The solid line represents an actual path of a
user visiting a hospital. We assume that the hospital
is a private place and the library is a public place.
A safe LSS would disclose location points denoted
by black nodes.
sharing desires and at least partially automate the decisions
to provide seamless integration of location sharing into peo-
ple’s daily lives.
One additional danger of sharing location information,
however, is that it can lead to inference of previous or past
locations. For example, a person traveling along a trajec-
tory is likely to remain along that path. Things get signiﬁ-
cantly more complex as more background data is introduced.
For example, walking and driving paths follow a predictable
pattern, following streets and sidewalks; furthermore, each
person exhibits more speciﬁc patterns in their activities. For
example, Figure 1 shows two potential walking paths leading
to a hospital and a library. Given background knowledge, it
is possible to infer that a user traveling towards the intersec-
tion (black circles) is likely to visit one of these two places.
A user who turns left at the intersection (white circles) may
then be assumed to be going to the hospital. Therefore, if
the user wishes to hide visits to the hospital, it is important
to stop revealing his or her location earlier as well.
We, therefore, propose to develop a new access-control
scheme that prevents such inference attacks. Our basic ap-
proach is to model an adversary as a location predictor that
predicts future movements of a target user from his previous
movements with certain probabilities. Intuitively, our access
control scheme discloses a user’s location information only
!"#$%&'((cid:3))%*+'+,(cid:3)-./(cid:3)-./(cid:3)711if an unauthorized user cannot predict that the user moves
to some private location with a suﬃciently high probabil-
ity. To model outside knowledge, we conservatively assume
that the adversary has access to a complete history of the
previous movements of the target user. We base our predic-
tions on higher-order Markov models, which have shown to
be very good at predicting user location movements [9]. Our
preliminary results with actual GPS traces of a single user
show that we can predict the user’s next movement with the
accuracy of 60% using a ﬁrst-order Markov model, and we
can improve the accuracy by 10% by considering multiple
previous movements with a higher-order Markov model.
The rest of the paper is organized as follows. Section 2
introduces our system model for LSSs in this paper, and
Section 3 describes a location predictor based on the Markov
model. We present our preliminary results of experiments in
Section 4. We cover related work in Section 5 and conclude
in Section 6.
2. SYSTEM MODEL
Figure 2 shows our system model for LSSs. We assume
that a Alice is interested in receiving Bob’s location move-
ments. Bob, carrying a GPS-enabled mobile devices period-
ically sends location-timestamp pairs (lock, tk) to the LSS
for k ∈ N . In our model, the LSS is completely trusted and
receives all of the pairs:
L = {(lock, tk) | k ∈ N}.
Bob also deﬁnes an access-control policy to protect his lo-
cation information, with the LSS implementing the policy.
We represent access control policies by the function
acl : P × W → 2
P
where P is a set of all users and W is a ﬁnite set of all
locations. The function acl takes a user identity X and a
location name l as inputs and outputs a set of users who
are authorized to learn that “Bob is at location l.” In other
words, the LSS releases Bob’s location movement (lk, tk) to
principal X only if X belongs to set acl (Bob, lk), and thus
user X receives a subset of events L0(X) ⊆ L
0
(X) = {(lock, tk) | X ∈ acl (Bob, lock)}.
L
To simplify the presentation, we consider access policies that
depend on location only, but it would be easy to incorporate
other pieces of context, such as the timestamp tk.
We next provide an informal deﬁnition of privacy that
incorporates inference. In short, if Alice is not authorized
to see when Bob is in a certain location, then she should not
be able to infer this fact from other information released by
the LSS.
Definition 1
(Preservation of location privacy.).
We say that a LSS preserves a user X’s location privacy
against another user Y if Y cannot infer X’s movement
(l, t) for any l such that Y /∈ acl (Bob, l) from the released
location-timestamp pairs L0(Y ).
In next section, we describe how we model Alice’s infer-
ences by a location predictor based on the Markov model,
and give a more precise deﬁnition of privacy metrics based
on probabilistic inference.
Figure 2: System model.
3. LOCATION PRIVACY AGAINST INFER-
ENCE ATTACKS
We can represent Bob’s potential locations with random
variables
X1, X2, X3, . . .
where each Xi has a value drawn from the ﬁnite set of loca-
tions W. For simplicity, we assume that location informa-
tion is updated at regular intervals and dispense with the
timestamp tk. We will use Markov models to predict the lo-
cation, which assumes that a location depends only on the
last k states. So, for example, for a Markov chain of order
1,
P r(Xn+1|X1, . . . , Xn) = P r(Xn+1|Xn)
We can represent this Markov chain as a |W|×|W| transi-
tion matrix, indexed by locations in W. Each matrix entry
represents the probability of moving from location li to lj:
Mi,j = P r(Xn+1 = li|Xn = lj)
for every pair of li and lj in set W. The probability of moving
from location li to lj in n time steps can be computed by
multiplying the transition matrix M n times as follows:
P r(Xn+1 = li|X1 = lj) = M n
i,j.
Since it is likely that we can improve the accuracy of location
predictions by considering multiple previous movements, we
also consider a location predictor based on a Markov model
of a higher order. If we use a second-order Markov model,
the transition matrix becomes a |W|2 × |W| matrix, where:
M(j−1)∗|W|+k,i = P r(Xn+1 = li|Xn = lj, Xn−1 = lk)
To create the transition matrix, we compute the proba-
bilities based on the past history of a user, as stored by the
LSS. Note that we include in the history locations that are
not part of L0(X) to be conservative: even though these lo-
cations are not released through the LSS, the adversary may
have some external knowledge of a user’s locations that can
be factored in as well.
!""(cid:3)#$%&'(()**+($,-.$/&0$/1(1)*(cid:3)'/1()&L={(lock,tk)|k=1,2,...}Alice∈acl(Bob,lk)Ask if  L={(lock,tk)|Alice∈acl(Bob,lk)}7125. RELATED WORK
Location privacy has been studied heavily in the context of
the anonymization and obfuscation of location data (See [7]
for a comprehensive survey). The focus of research in this
area is to ensure that no anonymized and/or obfuscated
data is associated with an individual. This inference prob-
lem concerning location privacy is diﬀerent from ours since
we consider the inference problem in access-control systems
for LSSs, which release identiﬁable location data of mobile
users.
6. CONCLUSIONS
We study an issue of inference attacks on GPS traces when
we support mobile users’ privacy policies for LBSs. We dis-
cuss that a traditional access-control mechanism that hides
only the private locations of a user is not suﬃcient since
an unauthorized user might be able to infer the user’s fu-
ture movements to private locations from her previous move-
ments. We deﬁne an adversary who has access to a mobile
user’s previous location data as a location predictor based on
the Markov model, and then gives location privacy metrics
under the presence of such inference attacks. Our prelimi-
nary experimental results show that it is possible to predict
a mobile user’s future location with high accuracy.
Acknowledgments
This research is in part supported by grant from the Pro-
motion program for Reducing global Environmental loaD
through ICT innovation (PREDICT) of the Ministry of In-
ternal Aﬀairs and Communications in Japan.
7. REFERENCES
[1] Denise Anthony, Tristan Henderson, and David Kotz.
Privacy in location-aware computing environments.
IEEE Pervasive Computing, 6(4):64–72, 2007.
[2] Glympse. http://www.glympse.com.
[3] Google latitude. http://www.google.com/latitude.
[4] Urs Hengartner and Peter Steenkiste. Access control to
people location information. ACM Transactions on
Information and System Security (TISSEC),
8(4):424–456, 2005.
[5] Instamapper. http://www.instamapper.com.
[6] Apu Kapadia, Tristan Henderson, Jeﬀrey J. Fielding,
and David Kotz. Virtual Walls: Protecting Digital
Privacy in Pervasive Environments. In Proceedings of
the Fifth International Conference on Pervasive
Computing (Pervasive), volume 4480 of LNCS, pages
162–179. Springer-Verlag, May 2007.
[7] John Krumm. A survey of computational location
privacy. Personal and Ubiquitous Computing,
13(6):391–399, 2009.
[8] Ginger Myles, Adrian Friday, and Nigel Davies.
Preserving privacy in environments with location-based
applications. IEEE Pervasive Computing, 2(1):56–64,
January-March 2003.
[9] Libo Song, David Kotz, Ravi Jain, and Xiaoning He.
Evaluating next cell predictors with extensive Wi-Fi
mobility data. IEEE Transactions on Mobile
Computing, 5(12):1633–1649, December 2006.
Figure 3: Accuracy of location predictions.
Definition 2
((M, δ)-location privacy.). Given a tran-
sition matrix M corresponding to the ﬁrst order Markov
model, and a probability threshold δ > 0, we say that a LSS
preserves a user X’s (M, δ)-location privacy with respect to
a user Y if, whenever a pair (li, t) is released from the LSS
to Y , for every lj such that Y /∈ acl (X, lj),
i,j ≤ δ for all n = 1, 2, . . .
M n
Intuitively speaking, the above deﬁnition requires that user
Y cannot predict that the target user X is at some private
location lj in some future time with probability p, which is
greater than the threshold value δ.
4. EXPERIMENTAL RESULTS
We conducted experiments with actual GPS traces to study
how accurately we can predict future location movements us-
ing location predictors based on the Markov model. One of
the authors collected GPS traces by carrying a GPS device
over a period of 50 days.
We consider GPS data whose data points reside within a
rectangular region, which covers the campus of University
of Illinois and its surrounding oﬀ-campus areas. The dimen-
sion of the region is 4.8 kilometers times 4.0 kilometers. We
divide each coordinate into 40 units and deﬁne 1,600 rect-
angular location regions.
We used half of the data to construct a state transition
matrix M and used the other half to compute the accuracy
of the predictions with matrix M . When we construct M ,
we do not consider movements within the same location.
Figure 3 shows our experimental results. The X-axis shows
how many steps we predict ahead, and the Y-axis shows
the accuracy of our predictions. We computed the accu-
racy of predicting every next location and took its average.
When we predict a next location in a single time step with a
1-order Markov model, our predictions are about 60% accu-
rate. However, as we try to predict a location reachable in
greater number of steps, the prediction accuracy decreases.
We compare the results of Markov models of three diﬀerent
orders. As we can see, when we predict locations reachable
in a fewer number of time steps, we can improve the accu-
racy by 10% by using a higher-order Markov model, which
considers multiple previous movements. Thus, we believe
that the threat of an adversary with a location prediction is
real considering these preliminary results.
 0.1 0.2 0.3 0.4 0.5 0.6 0.7 1 2 3 4 5 6 7 8 9 10Prediction accuracyLength of a path to predictNumber of geographical coordinate units = 40, Freq. = 3 secOrder 1Order 2Order 3713