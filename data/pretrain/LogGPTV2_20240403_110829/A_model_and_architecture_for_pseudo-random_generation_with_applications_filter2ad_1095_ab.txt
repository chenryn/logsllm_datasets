We would like to say that a necessary condition for D to
be “good” is that the attacker cannot distinguish the value
Fs(x) in this game from a truly random string.
In prac-
tice, in many cases people use a construction such as (say)
Fs(x) = HMAC-SHA1s(x). Moreover, it seems that people
make the assumption that any distribution with enough en-
tropy is “good” for such constructions. We stress, however,
that this assumption is in fact false. Indeed, it is easy to see
that for every deterministic function Fs(x) there exists an
(eﬃciently sampleable) distribution Ds (depending on Fs)
with roughly |x| − 1 bits of entropy, such that Fs(x ←R D)
can be easily distinguished from the uniform distribution.
(For example, let Ds be the uniform distribution over all
the strings x for which the ﬁrst bit of Fs(x) is zero.)
It follows that no single construction can “work” for all
the high-entropy distributions (in the sense of the game from
above). Of course, we only care about the construction
“working” for distributions that are likely to arise in prac-
tice, but it is not at all clear how to formally deﬁne such
distributions. Moreover, recall that we are interested in the
distribution of refresh data from the attacker’s perspective,
on which we know very little.
To make the task of constructing, modeling and proving
such generators more tractable, we therefore propose the
following approach: We introduce a parameter H which is
supposed to capture a family of “good distributions”, and
formally deﬁne what it means for a generator be secure with
respect to a given family H (cf. Deﬁnition 3.1 in Section 3).3
We then advocate splitting the construction of the generator
into two orthogonal components:
• One component is a procedure for processing the re-
fresh data x, trying to distill from it a nearly-uniform
string d of length m (where m is the security parame-
ter). Such procedures are commonly called extractors
(cf., [14] and references therein). In Deﬁnition 2.1 we
formalize what it means for a procedure extract(x) to
“work” for a given distribution family H.
3The notation H is meant to suggest High-entropy.
• The other component takes the (hopefully random)
string d and uses it in the operation of the genera-
tor. We give one simple example of how it can be
constructed (using non-robust cryptographic PRG) in
Section 4.
The randomness extraction component of a generator needs
to distill (something close to) true randomness from the fam-
ily H of distributions that are likely to arise in the system
under “normal working conditions”. Its design and analysis
must therefore take into account at least some of the speciﬁcs
of the target system(s). For the design of this component
we defer to previous works such as [1, 5] (which work for es-
sentially as general families H as possible) and the extensive
research on randomness extractors as surveyed in [14].
We note that extractors can be built using combinator-
ial and statistical tools, and in principle need not use any
cryptography at all (although there may be eﬃciency gains
in using cryptographic components for this task). We de-
scribe some of these previous works in the appendix, and
we also give some hints on concrete implementations in Sec-
tion 4. Formally, we make the following requirements from
a randomness extraction function:
Definition 2.1
(Extraction functions). Let m be
an integer, and let H be a family of distributions over {0, 1}≥m
(i.e., the set of strings of length at least m). A function
extract : {0, 1}≥m → {0, 1}m is an H-extractor if for every
D ∈ H and every y ∈ {0, 1}m,
−m(1 − 2
2
−m) ≤ Pr
x←RD[extract(x) = y] ≤ 2
−m(1 + 2
−m)
2.2 Back to our model
As we explained above, our formal model is parameterized
with a family H of distributions that the system uses under
“normal” conditions. The attacker in our model is given
the two interfaces good-refresh and bad-refresh. In principle,
when using the interface good-refresh the attacker is required
to specify a distribution D ∈ H, and when using bad-refresh
it can specify an arbitrary distribution. We slightly simplify
things by letting the attacker specify the actual input for
the refresh algorithm in the “dysfunctional” case, instead
of the distribution from which this input is taken. (These
two formulations are equivalent as long as the distributions
are eﬃciently sampleable.) Hence the attacker has the in-
terfaces good-refresh(D) that speciﬁes a distribution D ∈ H
and bad-refresh(x) that speciﬁes a single bit string x.
3. ROBUST PSEUDORANDOM
GENERATORS
A robust pseudorandom generator consists of two func-
tions:
(r, s0) ← next(s), where s is the current internal state. Re-
turns (say) an m-bit string r, where m is the security
parameter of the generator,4 and replaces the internal
state by the new state s0.
s0 ← refresh(s, x), with x a string of length at least m and s
the current internal state. Updates the internal state
using the data x.
4We assume for simplicity that the generator always output
exactly m bits, but both the deﬁnition and the construction
generalize easily to the case of variable-length output.
The security requirements from a robust generator are for-
mulated via probabilistic games between two players: one
player is the system that implements the generator, and the
other is the attacker that tries to attack the system. In the
introduction we discussed several diﬀerent properties that
we expect from a robust pseudo-random generator. Instead
of formulating each one via a separate formal deﬁnition, we
choose to deﬁne security via the ideal-world/real-world par-
adigm (cf.
[10]). Namely, we have a real-world game that
is meant to describe a real attacker that interacts with the
robust generator, and we have an ideal-world game that is
meant to capture “the most secure process that you could
possibly get”. A construction is then deemed secure if no
attacker can distinguish between interacting with the gen-
erator in the real world and interacting with the “secure
process” in the ideal world. After presenting the formal de-
ﬁnition, we brieﬂy explain why it implies all the properties
that we described in the introduction.
The real-world game. We model an attacker on the gen-
erator in the “real world” as an eﬃcient procedure A that
has four interfaces to the generator, namely good-refresh(·),
bad-refresh(·), set-state(·) and next-bits(). Formally, the real-
world game is parameterized by a security parameter m and
a family of distribution H (as described in Section 2 above).
The game begins with the system player initializing the in-
ternal state of the generator to null, (i.e., s ← 0m), and
then the attacker interacts with the system using the fol-
lowing interfaces:
good-refresh(D) with D a distribution in H. The system
draws x ←R D, sets s0 ← refresh(s, x), and updates
the internal state to s0.
bad-refresh(x) with a bit string x. The system sets s0 ←
refresh(s, x) and updates the internal state to s0.
set-state(s0) with an m-bit string s0. The system returns
to the attacker the current internal state s and then
changes it to s0.
next-bits(). The system runs (r, s0) ← next(s), replaces the
internal state s by s0 and returns to the attacker the
m-bit string r.
The game continues in this fashion until the attacker decides
to halt with some output in {0, 1}. For a particular construc-
tion PRG = (next, refresh), we let Pr[A(m,H)R(PRG) → 1] de-
note the probability that A outputs the bit “1” after inter-
acting as above with the system that implements the gener-
ator PRG and with parameters m,H. (Here R(PRG) stands
for the “real-world process” from above.)
The ideal-world game. The ideal-world game proceeds
similarly to the real-world game, except that the calls that A
makes to its interfaces are handled diﬀerently. Speciﬁcally,
whenever A “expects to learn something new” from a next-bits()
or set-state(·) call, the ideal process would return to A a new
random m-bit string, independent of everything else.
The exception, of course, is that if A already knows the in-
ternal state due to a previous set-state call, then everything
that it later sees until the next good-refresh call should be
consistent with that internal state. This is done by having
the system maintains a ﬂag compromised that is set on a
set-state call and reset on a good-refresh call, and the sys-
tem behaves according to the prescribed robust generator
when compromised = true and returns random strings when
compromised = false.
Formally, the ideal-world game is parametrized by the
same security parameter m and family of distribution H
as before. The game begins with the system player initializ-
ing s ← 0m and compromised ← true and then the attacker
interacts with the system using the following interfaces:
good-refresh(D) with D a distribution in H. The system
resets compromised ← false.
bad-refresh(x) with a bit string x.
If compromised = true
then the system sets s0 ← refresh(s, x) and updates the
internal state to s0. Otherwise (if compromised = false)
it does nothing.
set-state(s0) with an m-bit string s0. If compromised = true
then the system returns to the attacker the current
internal state s, and if compromised = false then it
chooses a new random string s ←R {0, 1}m and returns
it to the attacker.
Either way, the system also sets compromised ← true
and sets the new internal state to s0.
next-bits(). If compromised = true then the system runs (r, s0) ←
next(s), replaces the internal state s by s0 and returns
to the attacker the m-bit string r. If compromised =
false then the system chooses a new random string
r ←R {0, 1}m and returns it to the attacker.
The game continues in this fashion until the attacker de-
cides to halt with some output in {0, 1}. For a particular
construction PRG = (next, refresh), we let Pr[A(m,H)I(PRG) →
1] denote the probability that A outputs the bit “1” after
interacting as above with the system. (Here I(PRG) stands
for the “ideal process” from above and note that we only
use PRG in this game to answer queries that are made while
the compromised ﬂag is set to true.)
As we explained above, we say that a construction PRG
is secure if no attacker can tell the diﬀerence between inter-
acting with the system implementing PRG in the real world
and interacting with the “ideal process”. Formally, we have
the following:
Definition 3.1. We say that PRG = (next, refresh) is a
robust pseudorandom generator (with respect to a family
H of distributions) if for every probabilistic polynomial-time
attacker algorithm A, the diﬀerence
Pr[A(m,H)R(PRG) → 1] − Pr[A(m,H)I(PRG) → 1]
is negligible in the security parameter m.
4. A CONSTRUCTION
Now that we deﬁned our formal model, we turn to present-
ing a simple construction that can be rigorously proven to
satisfy our deﬁnition of a robust pseudorandom generator.
The two components of our construction are the extrac-
tion function extract(·) and a simple (non-robust) crypto-
graphic PRG G(·). A cryptographic PRG is a stateless func-
tion G : {0, 1}m → {0, 1}2m such that G(Um) is computa-
tionally indistinguishable from U2m (where m is a security
parameter and Ui is the uniform distribution on {0, 1}i).
Such a generator can be built from symmetric ciphers and
hash functions (e.g., either AES or HMAC-SHA1 in counter
mode), the factoring problem [3], or even any arbitrary one
way function [9, 12].
Below we write (r, s0) ← G(s) to denote that r is the ﬁrst
m bits in the output of G(s) and s0 is the last m bits. Also,
we denote by G0 the function that on input s ∈ {0, 1}m
outputs only the ﬁrst m bits of G(s). Our pseudorandom
generators operates as follows:
Operation of PRG. For security parameter m, given an H-
extractor extract : {0, 1}≥m → {0, 1}m and a cryptographic
non-robust PRG G : {0, 1}m → {0, 1}2m, our robust PRG
behaves as follows: It has a state s ∈ {0, 1}m, and the func-
tions refresh and next are deﬁned as:
• refresh(s, x) returns s0 ← G0(s ⊕ extract(x)).
• next(s) returns (r, s0) ← G(s).
Our main theorem regarding this pseudorandom generator
is the following:
Theorem 4.1. Let m be a security parameter, let extract :
{0, 1}≥m → {0, 1}m and let H be a family of distributions
over bit strings, such that extract is an H-extractor. Also,
let G be a cryptographic PRG. Then the construction from
above is a robust pseudorandom generator with respect to the
family H.
Proof. Let us ﬁx some eﬃcient attacking algorithm A.
We consider the following two experiments:
Expr. R A interacts with the real system R(PRG).
Expr. I A interacts with the ideal process I(PRG).
We want to prove that A outputs “1” in both experiments
with almost the same probability. To this end, we consider
another experiment, denoted Expr. H (for Hybrid). This is
similar to Expr. R, except that it uses a truly random m-bit
string to refresh the state in the good refresh calls (instead
of the output of extract(x) for x ←R D ∈ H). Namely, in
Expr. H the attacker A interacts with a modiﬁed process
that works as follows:
good-refresh(D) with D a distribution in H. The system
draws d ←R {0, 1}m, sets s0 ← G0(s ⊕ d), and updates
the internal state to s0.
bad-refresh(x) with a bit string x. The system sets s0 ←
refresh(s ⊕ extract(x)) and updates the internal state
to s0.
set-state(s0) with an m-bit string s0. The system returns
to the attacker the current internal state s and then
changes it to s0.
next-bits(). The system runs (r, s0) ← next(s), replaces the
internal state s by s0 and returns to the attacker the
m-bit string r.
On one hand, we show that the view of A in Expr. H
is statistically close to its view in Expr. R. On the other
hand, we show that to distinguish between Expr. H and
Expr. I the attacker A would have to break the underlying
cryptographic PRG.
Proving the ﬁrst claim is fairly straightforward. Let qr be
a (polynomial) upper-bound on the number of good-refresh(·)
calls that A makes during the attack, and notice that the
view of A is a deterministic function of the (qr or less) m-bit
strings that are the result of extract(·) in these good-refresh(·)
calls. In Expr. H the distribution over these strings is the
uniform distribution, whereas in Expr. R each of these
string is set to extract(x) where x is chosen from (a con-
vex combination of) the distribution in H.5 But since the
statistical distance between the uniform distribution and
extract(D) is bounded by 2−n for every D ∈ H, it follows
that the statistical distance between the view of A in the
two games Expr. H and Expr. R cannot exceed qr/2n.
To prove the second claim, we show that distinguishing
Expr. H from Expr. I implies breaking the underlying
cryptographic PRG. Let pH be the probability that A out-
puts one in Expr. H, and similarly let pI be the probability
that A outputs one in Expr. I. We show a procedure B that
breaks the cryptographic PRG G with advantage of at least
(pH − pI )/q, where q is a polynomial bound on the total
number of calls made by A to all of its interfaces. The pro-
cedure B gets as input two m-bit string r∗, s∗, and it tries to
determine if they were chosen at random and independently
from {0, 1}m, or were set as (r∗, s∗) ← G(s) for a random
s ←R {0, 1}m.
The procedure B(r∗, s∗) uses the attacker A as a subrou-
It begins by choos-
tine, implementing for it the system.
ing at random an index i∗ ←R {1, 2, . . . , q}, and also set-
ting s ← 0m and compromised ← true, and then it runs A,
roughly answering the ﬁrst i∗ − 1 calls of A with random
bit-strings, answering the i∗’th call using the input (r∗, s∗),
and answering calls i∗ + 1 and on as is done in Expr. H.
More speciﬁcally, the i’th call of A is answered as follows: