also valid/non-trivial. Thus, the overall false positive rate for
security context was (323-209)/323=35%.
As a dynamic analysis, FLOWDIST cannot discover
vulnerabilities that are not covered by the executions it
analyzes, which naturally causes false negatives. Since the
entire set of true vulnerabilities is unknown for our subject
systems, we could not quantify the false negative rate of
FLOWDIST for security context with respect to our dataset.
6.3.6 RQ6: Baseline Comparisons
Our baseline PHOSPHOR instruments a standard JVM such
that taint tags set and retrieved in (unit) test cases can be
propagated during the execution of a given application on the
instrumented JVM [47]. This requires sources and sinks to
be in the test code. Thus, we needed to write a dedicated unit
test for each source-sink pair per subject—the original test
cases (e.g., system tests) associated with our subjects do not
contain the sources/sinks considered in our comparisons.
In each of these dedicated tests, we ﬁrst tainted the source
data (variable) at the test entry, then triggered the original
subject execution, and ﬁnally checked the taint-tag at the
sink upon the test exit. We realized these taint tagging
and checking operations using PHOSPHOR APIs as per the
variable type. These test cases are in [65]/PhosphorTest. We
spent 4 to 10 hours to develop such dedicated tests for each of
our subjects. By design, PHOSPHOR does not compute taint
ﬂow paths. Thus, for each source-sink pair, we considered
that PHOSPHOR found a taint ﬂow between the pair if the sink
contained the taint tag set at the source.
The other baseline JOANA [75] identiﬁes vulnerabilities
(e.g., sensitive information leaks) in a given Java program
through a static dependence analysis. It requires entry points,
sources, and sinks explicitly speciﬁed by users through
annotations in the program. We spent 1 to 3 hours to set
such annotations for each of our subjects. JOANA does not
report ﬂow paths either, but only the sinks reachable from any
annotated sources. To enable comparison, we considered that
it found an information ﬂow path between a source and a sink
if it reports the sink when we annotated the source.
We note that a few cross-process DIFA/DTA tools do exist,
yet to the best of our knowledge no such tools working
for common distributed Java software like our subjects
are available: For example, Kakute [79] works only with
data-intensive applications based on a particular framework
Spark while Taint-Exchange [124] (like Cloudfence [103] and
Cloudopsy [123]) only works for C/C++ software. And all
such tools are not purely application-level like ours.
Effectiveness. Figure 10 contrasts FLOWDIST with the
baselines in terms of effectiveness for all the source/sink
pairs in Thrift, Voldemort-Load, and Netty—we only considered
these executions as we were able to (manually) produce
the ground truth only for them (as for RQ1). Both baselines
captured all the true intraprocess paths found by FLOWDIST
but missed all the interprocess ones. Thus, they had the
same but low (37.5%) recall; for the same reason, none of
them found any of the known and new vulnerabilities (which
were all on interprocess paths) as FLOWDIST did. JOANA
reported many additional paths that were not covered in
the executions considered. With respect to the ground-truth
paths (all being dynamic), those additional paths were false
positives, leading to very low (30%) precision of JOANA. As
a result, FLOWDIST had a much higher F1 accuracy (100%)
than PHOSPHOR (54.6%) and JOANA (33.3%).
It should also be noted that many of the vulnerabilities
found by FLOWDIST were conﬁrmed not just according to
the source-sink reachability but by checking the complete,
detailed ﬂow paths as offered by a DIFA. DTA techniques
like JOANA and PHOSPHOR would not sufﬁciently support
such conﬁrmations (even when working across processes to
address interprocess ﬂows), because they do not provide the
path details needed. This helps justify using DIFA over DTA.
Efﬁciency. For the above effectiveness results, PHOSPHOR
and JOANA took 1.38 and 0.43 seconds on average,
respectively,
than
FLOWDIST’s querying cost (13 seconds on average).
FLOWDIST also incurred a higher average storage cost
(293.4MB) than PHOSPHOR (21.2MB) and JOANA (35.2MB).
The reason is that FLOWDIST performed more, heavier
analyses (e.g., probing, building the dependence graph,
source/sink
each
for
pair,
lower
USENIX Association
30th USENIX Security Symposium    2105
0%50%100%150%PrecisionRecallF1FLOWDIST   PHOSPHOR   JOANAFigure 11: The total time costs (in seconds) of FLOWDISTmul and
FLOWDISTsim against FLOWDIST for all subject executions.
Figure 12: The storage costs (in MB) of FLOWDISTmul and
FLOWDISTsim against FLOWDIST for all subject executions.
proﬁling instance-level method events) than the baselines
(e.g., JOANA only statically checked the source code). These
extra costs of FLOWDIST were moderate and should be paid
off by its much higher effectiveness. Critically, it did not
incur the substantial manual (e.g., test case development or
source annotation) effort as the baselines require.
Discussion. Our goal with FLOWDIST is to achieve practical
applicability, portability, scalability, and cost-effectiveness
together for DIFA of distributed software instead of
just better DTA efﬁciency for single-process programs.
In addition, FLOWDIST works at an application level
and computes full information ﬂow paths (as opposed
to taint checking only as by our baselines). Thus, we
expected it to incur higher overheads than system-level DTA
approaches (e.g., PHOSPHOR). The baselines need platform
customization and/or substantial manual (test development
or source annotation) effort that FLOWDIST avoids. The full
information ﬂow paths, which the baselines do not provide,
are valuable for detailed security diagnoses. FLOWDIST thus
complements the baselines by making different tradeoffs (e.g.,
portability versus efﬁciency).
FLOWDIST achieved much higher effectiveness at
reasonable costs over two state-of-the-art peer tools, yet
without manual setup effort. None of the baselines found
any of the known and new vulnerability as FLOWDIST did
due to their failure to analyze interprocess ﬂows.
6.3.7 RQ7: Alternative Design Comparisons
To compare FLOWDIST to the two alternative designs,
we repeated the experiments for RQ1 and RQ2 with
FLOWDISTsim and FLOWDISTmul. We conﬁrmed that these
three tools produced the same information ﬂow paths, hence
their equivalence in effectiveness—while FLOWDISTmul
generally suffers from non-determinism in the analyzed
executions, it was not affected by such issues in our study.
Also as expected, the best performer among the three
varied for different systems in terms of efﬁciency. Figure 11
shows the contrasts in the total analysis time of each tool
for each of the 18 executions studied. For relatively large
systems (ZooKeeper and larger), FLOWDIST was constantly
the most efﬁcient. For these systems the time saved due
to the reduced instrumentation and proﬁling scope in the
pre-analysis noticeably outweighed the time cost of the static
Table 6: Recommendations on DIFA/DTA tool selection
System type
Distributed
(multi-process)
With non-deterministic executions?
Yes
No
FLOWDISTsim
or FLOWDISTmul
Common Small FLOWDISTsim
Large FLOWDIST
FLOWDIST
Kakute [79] (for Spark [122])
Pileus [116] (for OpenStack [110]),...
Specialized
Single-process
PHOSPHOR [47], JOANA [75],...
analysis itself that enabled the reduction—thus, FLOWDIST
won over FLOWDISTsim. Meanwhile, the time saved due to
the reduced scope of proﬁling instance-level method events
was outweighed by the extra time incurred by additional
executions (with tracing) of the subject (in the intermediate
phase)—thus, FLOWDIST won over FLOWDISTmul.
These outweighing contrasts were reversed for small
systems (those smaller than ZooKeeper), which explains why
for those systems the alternative designs won (albeit the
difference between FLOWDISTsim and FLOWDISTmul was
small). Here we differentiate systems as small and large not
only by code size but also trace size.
Comparison on storage costs revealed insigniﬁcant
differences, as shown in Figure 12. FLOWDISTsim needed
the most storage spaces while FLOWDISTmul had the least
storage requirements. And the storage costs incurred by
FLOWDIST (default design) were in between. The reason
is that FLOWDISTsim traces all instance-level method and
branch events in the subject execution during the pre-analysis
phase. In contrast, FLOWDIST traces relevant methods and
branches only. On the other hand, FLOWDISTmul just records
the ﬁrst entry and last returned-into events in the pre-analysis
phase, and then only traces methods on the method-level ﬂow
paths found in the pre-analysis and branches in those methods.
These ﬁndings led us to the recommendations on
choosing the right tool for a particular system, as shown in
Table 6. Overall, FLOWDIST best suits large-scale common
distributed systems, regardless of the executions analyzed
being non-deterministic or not. For small common distributed
systems, either FLOWDISTsim or FLOWDISTmul may be
a great choice if the target execution is known to be
deterministic; otherwise, FLOWDISTmul would be opted
out. We also put in a few peer tools that suite other types
of (specialized distributed or single-process) systems, to
highlight again that our work complements them.
2106    30th USENIX Security Symposium
USENIX Association
01,0002,0003,0004,0005,0006,000FLOWDISTmulFLOWDISTsimFLOWDIST02004006008001,0001,2001,4001,600FLOWDISTmulFLOWDISTsimFLOWDISTThe two alternative designs can complement FLOWDIST
in suiting smaller systems, while the three together
complement existing DIFA/DTA tools in dealing with
common distributed systems.
6.4 Regarding the Vulnerabilities Discovered
The previously known vulnerabilities discovered by
FLOWDIST have been documented in detail on respective
CVE pages as seen in Table 4. The documentations include
how the vulnerabilities have been disclosed and addressed.
Regarding each of the 24 new vulnerabilities discovered by
FLOWDIST, we have contacted the developers of respective
systems. By the time of this paper submission, all of these
have been reported to the system vendors, although some
of them have not been conﬁrmed yet (i.e., for HSQLDB,
Raining Sockets, Voldemort, and xSocket), possibly because
the developers have not been active recently. Others have
all been conﬁrmed, among which two have been ﬁxed. The
details on each of these 24 vulnerabilities are documented
in [65]/newVulnerabilities/Vulnerabilities.docx.
7 Related Work
Most previous information ﬂow analyses are purely static
(e.g., [50, 75, 99, 117]), including well-known works for
Android (e.g., FlowDroid [41], IccTA [88], Amandroid [118],
DroidSafe [73], and HornDroid [54]). These approaches
suffer from imprecision issues common to purely static
analysis, which is also commonly unsound due to dynamic
constructs (e.g., reﬂection and dynamic code loading) in
modern languages [91]. With distributed programs, these
issues are exacerbated due to implicit dependencies among
distributed (decoupled) components. Next, we discuss prior
works closely related to ours (i.e., relevant to DIFA/DTA),
which are dynamic in nature and target speciﬁc program
executions by design (hence orthogonal to common problems
like run-time input quality and limited coverage).
Conventional DIFA/DTA.
[64],
TaintMan [120] customizes the Android OS to track
whole-system information ﬂow at runtime. Panorama [119]
performs system-side dynamic information ﬂow tracking for
Windows malware analysis, through dynamic instrumentation
as Dytan [60] and TaintEraser [125]. In [76], a dynamic
taint analysis was used for intrusion detection via a custom
Linux security module. Juturna [92] employs bytecode
augmentation and modiﬁed Java API classes, similar to
PHOSPHOR instrumenting JVM, for taint tracking. These
approaches require customized run-time platforms, like
a few others [59, 62, 115] using specialized hardware, to
perform DTA. In [43, 44, 82], the authors proposed language
semantics for dynamic taint analysis of JavaScript code.
LabelFlow [58] works as an extension of PHP to implement
security policies in web applications. Like many other DTA
TaintDroid
Like
tools [35, 42, 45, 57, 96, 101, 106, 113], these approaches do
not work with common distributed software as they only
track information ﬂows in single threads/processes.
In contrast, FLOWDIST is a purely application-level DIFA.
It does not require modifying original run-time platforms nor
speciﬁc frameworks/emulators. Importantly, it tracks dynamic
information ﬂow (across processes), which is out of the
applicability scope of most peer approaches.
Cross-process DIFA/DTA. Only a few existing techniques
address information ﬂows across processes. Kakute [79]
tracks ﬁeld-level data ﬂow with uniﬁed APIs for reference
propagation and tag sharing. Based on PHOSPHOR, it needs to
customize (instrument) its runtime platform (i.e., JVM). And
it focuses on Spark [122] applications only, not working with
common distributed software. Similarly, Pileus [116] targets
the applications on a special cloud platform OpenStack [110].
Taint-Exchange [124] is a framework for cross-host taint
tracking, using libdft [83] to transfer taint information
through sockets and pipes. Like Cloudfence [103] and
Cloudopsy [123], Taint-Exchange relies on a customized
platform (Pin) and targets C/C++ software.
In contrast, FLOWDIST works generally with common
distributed systems, without any change to the original
run-time platform while offering full information ﬂow paths.
We are not aware of a prior DIFA working for common
distributed software: Kakute [79] and Pileus [116] are DTA
and work only for specialized distributed systems—DTA is
conceptually differentiated from DIFA (§2); other relevant
approaches are either DTA or not working with common
distributed systems. The key conceptual differences between
FLOWDIST and peer approaches lie in our multi-staged,
reﬁnement-based methodology for DIFA and in FLOWDIST
explicitly addressing interprocess information ﬂow.
Dynamic dependence analysis for distributed programs.
A number of dynamic slicing algorithms [46, 55, 63, 69,
74, 80, 85, 97] have been developed. In particular, prior
work [46] deﬁnes varied kinds of dependencies induced by
interprocess communication. However, the approach was
not implemented to work on real-world distributed software,
and its algorithmic nature implies scalability barriers. A
major focus of FLOWDIST is to deal with the overhead of
ﬁne-grained dynamic dependence analysis so as to scale
to large real-world distributed systems. The method-level
dependence analysis in the pre-analysis of FLOWDIST was
inspired by DISTIA [53]. In comparison, FLOWDIST targets
a ﬁner-grained and much more precise data-ﬂow analysis at
statement level with high efﬁciency and scalability.
Reasoning about happens-before relations by addressing
global timing via partial ordering based on logic clocks is
a standard technique in concurrent program analysis. This
technique has been used in testing concurrent programs and
distributed systems [89, 102, 121]. For example, DCatch [89]
detects concurrency bugs by checking a distributed execution
USENIX Association
30th USENIX Security Symposium    2107
against a set of happens-before relation rules. FLOWDIST
also leverages happens-before relations, but among method
execution events partially ordered through message-passing
events and for inferring interprocess dependencies.
Language-based information ﬂow control. Jif
[105]
extends Java to address information ﬂow security via
augmenting the language with features that are related
to security.
It supports security labels to help users
specify conﬁdentiality/integrity policies. Furthermore, as a
platform and language for building secure distributed systems,
Fabric [90] extends Jif to support distributed transactions
and programming. It has several mechanisms, such as access
control and information ﬂow control, to prevent untrusted
nodes from violating integrity and conﬁdentiality. Other
language-based information ﬂow control approaches [56, 86,
108] have also been proposed.
In essence, these approaches offer ways of constructing
an information-ﬂow-secure system. Thus, to beneﬁt from
them, developers need to build the system in a specialized
manner (e.g., using the Fabric language). Also, the security
capabilities they offer depend on the accuracy of the policies
speciﬁed. In contrast, FLOWDIST does not impose these
burdens to developers and it analyzes existing distributed
systems already built without any knowledge about itself. It
also provides detailed code-level information ﬂow paths that
those language-based tools typically do not offer. Finally, the
core of FLOWDIST is a dynamic data ﬂow analysis, which can
empower applications beyond those on security (e.g., testing,
debugging, program understanding, performance analysis)
that the language-based approaches do not readily support.
8 Conclusion