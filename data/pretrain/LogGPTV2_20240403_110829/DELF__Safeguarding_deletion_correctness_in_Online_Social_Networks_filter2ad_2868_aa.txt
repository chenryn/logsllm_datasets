title:DELF: Safeguarding deletion correctness in Online Social Networks
author:Katriel Cohn-Gordon and
Georgios Damaskinos and
Divino Neto and
Joshi Cordova and
Benoît Reitz and
Benjamin Strahs and
Daniel Obenshain and
Paul Pearce and
Ioannis Papagiannis and
Available Media
DelF: Safeguarding deletion correctness in 
Online Social Networks
Katriel Cohn-Gordon, Facebook; Georgios Damaskinos, Facebook, EPFL; Divino 
Neto, Joshi Cordova, Benoît Reitz, Benjamin Strahs, and Daniel Obenshain, 
Facebook; Paul Pearce, Facebook, Georgia Tech; Ioannis Papagiannis, Facebook
https://www.usenix.org/conference/usenixsecurity20/presentation/cohn-gordon
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.DELF: Safeguarding deletion correctness in Online Social Networks
Katriel Cohn-Gordon
Facebook
Georgios Damaskinos
Facebook, EPFL
Benjamin Strahs
Facebook
Daniel Obenshain
Facebook
Abstract
Deletion is a core facet of Online Social Networks (OSNs).
For users, deletion is a tool to remove what they have shared
and control their data. For OSNs, robust deletion is both an
obligation to their users and a risk when developer mistakes
inevitably occur. While developers are effective at identify-
ing high-level deletion requirements in products (e.g., users
should be able to delete posted photos), they are less effective
at mapping high-level requirements into concrete operations
(e.g., deleting all relevant items in data stores). Without frame-
work support, developer mistakes lead to violations of users’
privacy, such as retaining data that should be deleted, deleting
the wrong data, and exploitable vulnerabilities.
We propose DELF, a deletion framework for modern OSNs.
In DELF, developers specify deletion annotations on data type
deﬁnitions, which the framework maps into asynchronous,
reliable and temporarily reversible operations on backing
data stores. DELF validates annotations both statically and
dynamically, proactively ﬂagging errors and suggesting ﬁxes.
We deployed DELF in three distinct OSNs, showing the
feasibility of our approach. DELF detected, surfaced, and
helped developers correct thousands of omissions and dozens
of mistakes, while also enabling timely recovery in tens of
incidents where user data was inadvertently deleted.
1 Introduction
The ability to delete data is a core privacy expectation for
users entrusting Online Social Networks (OSNs) with their
personal information [1, 2]. Users make use of deletion to
retract posts shared with their friends, to avoid future conﬂicts,
to forget past experiences, to remove content they shared by
accident, to comply with policies of their organization, and
to address perceived privacy or security concerns regarding
providers they do not trust [3–6]. Deletion empowers users
to safeguard their privacy in a straightforward way.
It is
increasingly enshrined worldwide as a user privacy right [7,8].
Providing robust deletion infrastructure is important for
service providers. On one hand, bugs in deletion undermine
Divino Neto
Facebook
Paul Pearce
Joshi Cordova
Facebook
Benoît Reitz
Facebook
Facebook, Georgia Tech
Ioannis Papagiannis
Facebook
the integrity of the service when the wrong data is deleted;
and may also manifest as exploitable vulnerabilities that allow
users to delete arbitrary data. On the other hand, failing to
delete user data undermines user trust and can trigger substan-
tial regulatory ﬁnes [7, 8]. Both types of issues are common,
affect numerous services, and are reported widely [9–16].
OSNs are particularly challenging applications in regards
to identifying what to delete and when. In traditional commu-
nication services, such as email or messaging, data ownership
is clear and limited to the items in a user’s inbox. Instead, the
data model of OSNs is much more complex and changes fre-
quently to support novel features. Billions of users interact on
shared containers (e.g., proﬁles, groups, events, live videos,
marketplace items, and stories) where they perform many dif-
ferent actions (e.g., comment, share, retweet, react, link, paint
over, buy, watch, and upvote). Deleting a shared container
(e.g., a group) should delete all of its subcontainers (e.g., all
posts and photos in the group), and recursively delete all ac-
tions for each leaf container (e.g., all reactions, shares and
upvotes of each photo) independently of who created the data.
However, deleting a subcontainer (e.g., a retweet) should not
delete the original container (e.g., the original tweet), in par-
ticular if this would allow malicious users to delete content
they do not control. Identifying what to delete and when is a
challenge [3, 17, 18], and is cited as an important reason not
to trust that services delete data correctly [19, 20].
Our insight is that both developer input and control in the
deletion process can and should be minimized. Rather than
expecting developers to delete data correctly on their own, the
process should be facilitated by a framework which executes
all deletions in an application. Having centralized control
of all deletions enables us to provide at the framework level
three important features to safeguard correctness: (a) we can
enforce that all developers specify how user data should be
deleted before any data is collected, (b) we can validate de-
veloper speciﬁcations to surface mistakes early, and (c) when
undetected mistakes inevitably occur we can recover any in-
advertently deleted data with minimal engineering effort.
We demonstrate these ideas in DELF. DELF is a deletion
USENIX Association
29th USENIX Security Symposium    1057
framework that exposes a simple declarative API to specify
deletion behavior, supporting OSNs’ complex data models
and abstracting away heterogeneous storage infrastructure.
It validates deletion speciﬁcations via static and dynamic
analysis, helps developers correct mistakes, and executes all
deletions to completion, despite any transient infrastructure
errors. To our knowledge, DELF is the ﬁrst framework that
helps developers delete data correctly at scale.
We deploy DELF at FACEBOOK—a large OSN service
provider—and explore its effectiveness. Via a case study of
developer actions, we measure that even when forced to spec-
ify how data should be deleted during product development—
a scenario that occurs about a hundred times every day at this
service provider—developer precision is limited to 97.6%.
DELF detects the majority of the resulting mistakes with
high conﬁdence. DELF independently validates developer
data models for deletion correctness and when it detects mis-
matches it raises these to developers for consideration. In
our deployment we observe that due to DELF static valida-
tion developers change how 62.2% of the object types they
create are deleted, while dynamic validation of edge types
achieves 95.0% precision at 74.8% recall, i.e., DELF discov-
ers how three quarters of all edge types should be deleted, and
is correct 95% of the time, showing that it can independently
pinpoint most developer mistakes when annotating edge types.
In practice, DELF surfaced thousands of historical omissions
and dozens of mistakes which developers corrected. When
undetected mistakes lead to inadvertent data deletion DELF
enables recovery with signiﬁcantly less engineering effort.
The main contributions of this paper are:
1. We perform a case study of developer actions at FACE-
BOOK, quantifying the rate of mistakes developers intro-
duce when asked to specify how data should be deleted
in OSNs spanning tens of thousands of data types and
hundreds of millions of lines of code.
2. We design DELF, an application-agnostic and robust
framework for controlling deletion with restoration ca-
pabilities. We show how DELF simpliﬁes and uniﬁes
the deletion process on top of distinct data store types,
including a relational database, a graph database, a key-
value store, and a blob store.
3. We demonstrate how DELF detects and helps developers
correct common types of mistakes.
4. We deploy DELF at FACEBOOK. DELF detected thou-
sands of omissions and dozens of mistakes which would
have otherwise undermined deletion correctness result-
ing in privacy violations or vulnerabilities.
The rest of this paper is organized as follows. §2 introduces
common types of data stores used to persist user data and lays
out the deletion policy of one popular OSN service provider.
§3 establishes our baseline in regards to observed frequency
of developer mistakes in a large-scale codebase demanding
complicated data models. §4 introduces the high level techni-
cal design of DELF and §5 discusses topics pertaining to its
implementation. §6 assesses the effectiveness of our system
in production. We close with a discussion of related work in
§7, areas for future work in §8, our conclusions in §9, and we
acknowledge contributions to our work in §10.
2 Background
Modern large-scale OSNs are supported by a variety of scal-
able persistent data stores [21–27]. Data stores expose dif-
ferent data models to optimize for the workloads required
by the speciﬁc applications they target. It is common for a
modern OSN to leverage multiple data stores simultaneously.
For example, photos and videos may be persisted in a blob
store, while social interactions, such as like or follow, may be
persisted in a graph database.
We refer to application-level delete operations as subgraph
deletions or just deletions. This is in contrast to row-level or
object-level delete operations permitted by most data store
APIs; we refer to those as point deletes.
2.1 Data Models
Scaling relational databases to handle large numbers of read
and writes is non-trivial [24, 28]. Product workloads in mod-
ern OSNs are read-heavy [21], their scale requires sharding
user data across thousands of servers, and even data a single
user creates is sharded across multiple servers to facilitate
reads. For example, all comments on a post are typically
stored on the same shard as the post for faster loading. In
a sharded deployment multiple database servers follow the
same database schema but each server stores only a subset of
rows from each logical table [21, 29].
Many scalable data stores trade off advanced querying ca-
pabilities, support for transactions, or consistency of the full
relational data model in favor of throughput, availability, and
latency improvements possible with more constrained data
models [23, 24, 26, 27]. Under a key-value model, data is
indexed by arbitrary strings [22, 29]. Keys may be gener-
ated automatically [22] or chosen by the application [22, 29].
Values may be structured [27, 30] or unstructured [22, 25].
Under a graph model, data forms a graph [21,31] whose main
entities are objects and associations.
There are domain-speciﬁc data stores that empower spe-
cialized functionality within OSNs. Sets approximated by
Bloom ﬁlters [32] or stream processing systems leveraging
HyperLogLog [33, 34] store aggregate hashes of input and
have applications in security, abuse prevention, analytics,
and performance optimization [35, 36]. Data warehouse sys-
tems [37–39] store large amounts of logs and shard based on
time to facilitate daily batch processing for analytics and ma-
chine learning. In such domain-speciﬁc data stores, indexes
1058    29th USENIX Security Symposium
USENIX Association
to enable point queries may be prohibitively demanding—
frequently they are not available at all. Suggested techniques
to address deletion when point deletes are not feasible are
storing all data with short retention, anonymization, and en-
cryption at write time with a key that can be deleted sepa-
rately [40,41]. The rest of this paper focuses on deletion from
relational, key-value, and graph data stores where indexes to
perform point deletes are available.
1
2
3
4
5
6
7
8
9
10
object_type:
name: photo
storage:
type: TAO
deletion: directly
id:
photo_id: integer_autoincr
attributes:
created_on: datetime
caption: string
11
12
13
14
15
16
17
18
19
20
edge_types:
handle:
to: photo_blob
deletion: deep
created_by:
to: user
deletion: shallow
inverse:
created_photo:
deletion: deep
2.2 Dangling Data
We describe a reference to a deleted object and the correspond-
ing object storing such a reference as dangling. Dangling data
conveys information about deleted objects, e.g., a key-value
entry linking a phone number to a deleted account may retain
how to contact the account and a graph association from an
account to a deleted video may retain who watched the video.
For correct deletion no dangling data should remain.
Relational databases rely on integrity constraints [42, 43]
to achieve referential integrity and identify what should be
deleted once a row is deleted. With foreign key declara-
tions and appropriate indexes in place, a relational database
propagates point deletes for rows on the parent table to cas-
cade and delete dangling rows in child tables. Developers
control this process via referential actions on foreign key
declarations, such as ON DELETE CASCADE and ON DELETE
SET NULL. There is no guarantee that developers deﬁne ei-
ther foreign keys or referential actions correctly. There is no
mechanism to detect omissions. Modern popular sharded data
stores such as MongoDB [44], Dynamo [29], and Redis [30]
ofﬂoad enforcing referential integrity to applications [45].
2.3 Recovery via Backups
Data store backups enable service providers to recover from
hardware failures, system crashes, and application-level bugs.
In a typical conﬁguration a full database snapshot is sched-
uled periodically [46]. The data store is separately conﬁgured
to log incremental mutations [47]. To recover the data store
to any point in time a full snapshot is restored and any sub-
sequent incremental mutations are replayed. Reverting only
speciﬁc deletions is not practical without additional informa-
tion, since incremental mutations do not store metadata about
application-level actions [48]. We illustrate these challenges
in the context of a data loss incident in our case study (§3).
2.4 FACEBOOK
FACEBOOK is a service provider in the space of social net-
working. Its products collectively have approximately 3 bil-
lion monthly active users [49]. FACEBOOK products in-
clude multiple distinct consumer OSNs, such as Facebook
(the OSN), Instagram, and Dating, with a variety of features
Figure 1: A Photo object type deﬁnition for storing photo
metadata in TAO (line 4) with an edge type to the photo blob
object in Everstore (line 13). DELF object type (line 5) and
edge type (lines 14, 17, 20) annotations specify how data
should be deleted when the data type is deﬁned.
spanning—amongst others—private and public media sharing,
messaging, groups, video streaming, and a marketplace.
Infrastructure. In the backend FACEBOOK products deﬁne
tens of thousands of distinct data types to empower external-
facing features across existing products, new products un-
dergoing testing, and internal tools. Major data stores are
TAO [21], Everstore [22], MySQL [50] and ZippyDB [26]; a
graph, blob, relational, and key-value data store, respectively.
None of these data stores enforces referential integrity for
references across shards and across data stores. Objects of
several popular data types, such as photos, videos, and group
posts, may get deleted as a result of dozens of actions.
FACEBOOK infrastructure requires developers across most
products to deﬁne their data types before they are used in
a structured format, at minimum exposing object types con-
nected via edge types. Figure 1 presents an example in pseu-
docode of such a deﬁnition. The implementation depends
on the backing data store. For example, MySQL maps an
object type to a table and an edge type to a different table
with columns to store the primary keys of the referenced ta-
bles; TAO maps objects and edges to objects and associations
directly. A subsequent code generation step creates imple-
mentation classes with strongly-typed read, write and delete
methods for common languages used to develop applications.
This intermediate abstraction layer for deﬁning and manipulat-
ing data types is similar to object-relational mapping [51]. It
facilitates access control [52] and improves performance [26].
Deletion Policy. FACEBOOK’s deletion policy prescribes that