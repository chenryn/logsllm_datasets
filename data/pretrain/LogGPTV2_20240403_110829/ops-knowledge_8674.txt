User: 如何使用Python编写一个简单的网络爬虫，用于抓取网站上的数据？
Assistant: 编写Python网络爬虫的步骤如下：

1. 导入所需的库。

```
import urllib.request
from bs4 import BeautifulSoup
```

2. 利用 `urllib` 库将网页下载到本地。

```
url = 'https://www.example.com'
html = urllib.request.urlopen(url).read()
```

3. 使用 `BeautifulSoup` 库对网页进行解析。

```
soup = BeautifulSoup(html, 'html.parser')
```

4. 找到需要抓取的数据所在的标签，使用 `find` 或 `find_all` 方法。

```
data = soup.find_all('div', {'class': 'example-class'})
```

5. 遍历获取到的数据，对每一个数据进行处理。

```
for d in data:
    print(d.text)
```

6. 将获取到的数据保存到本地文件中（可选）。

```
with open('data.txt', 'a') as f:
    for d in data:
        f.write(d.text + '\n')
```

一个完整的Python网络爬虫示例代码如下：

```
import urllib.request
from bs4 import BeautifulSoup

url = 'https://www.example.com'
html = urllib.request.urlopen(url).read()

soup = BeautifulSoup(html, 'html.parser')

data = soup.find_all('div', {'class': 'example-class'})

with open('data.txt', 'a') as f:
    for d in data:
        f.write(d.text + '\n')

for d in data:
    print(d.text)
```