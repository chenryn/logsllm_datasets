title:Identifying and Characterizing Sybils in the Tor Network
author:Philipp Winter and
Roya Ensafi and
Karsten Loesing and
Nick Feamster
Identifying and Characterizing Sybils  
in the Tor Network
Philipp Winter, Princeton University and Karlstad University; Roya Ensafi, Princeton 
University; Karsten Loesing, The Tor Project; Nick Feamster, Princeton University
 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/winter
This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX Identifying and characterizing Sybils in the Tor network
Philipp Winter∗†
Roya Ensaﬁ∗
Karsten Loesing‡
Nick Feamster∗
∗Princeton University
†Karlstad University
‡The Tor Project
Abstract
Being a volunteer-run, distributed anonymity network,
Tor is vulnerable to Sybil attacks. Little is known about
real-world Sybils in the Tor network, and we lack practi-
cal tools and methods to expose Sybil attacks.
In this
work, we develop sybilhunter, a system for detecting
Sybil relays based on their appearance, such as conﬁg-
uration; and behavior, such as uptime sequences. We
used sybilhunter’s diverse analysis techniques to analyze
nine years of archived Tor network data, providing us
with new insights into the operation of real-world attack-
ers. Our ﬁndings include diverse Sybils, ranging from
botnets, to academic research, and relays that hijacked
Bitcoin transactions. Our work shows that existing Sybil
defenses do not apply to Tor, it delivers insights into real-
world attacks, and provides practical tools to uncover
and characterize Sybils, making the network safer for its
users.
1
Introduction
In a Sybil attack, an attacker controls many virtual iden-
tities to obtain disproportionately large inﬂuence in a net-
work. These attacks take many shapes, such as sockpup-
pets hijacking online discourse [34]; the manipulation of
BitTorrent’s distributed hash table [35]; and, most rele-
vant to our work, relays in the Tor network that seek to
deanonymize users [8]. In addition to coining the term
“Sybil,”1 Douceur showed that practical Sybil defenses
are challenging, arguing that Sybil attacks are always
possible without a central authority [11]. In this work,
we focus on Sybils in Tor—relays that are controlled by
a single operator. But what harm can Sybils do?
The effectiveness of many attacks on Tor depends on
how large a fraction of the network’s trafﬁc—called the
1The term is a reference to a book in which the female protagonist,
Sybil, suffers from dissociative identity disorder [29].
consensus weight—an attacker can observe. As the at-
tacker’s consensus weight grows, the following attacks
become easier.
Exit trafﬁc tampering: When leaving the Tor network,
a Tor user’s trafﬁc traverses exit relays, the last hop
in a Tor circuit. Controlling exit relays, an attacker
can eavesdrop on trafﬁc to collect unencrypted cre-
dentials, break into TLS-protected connections, or
inject malicious content [37, § 5.2].
Website ﬁngerprinting: Tor’s
encryption
prevents
guard relays (the ﬁrst hop in a Tor circuit) from
learning their user’s online activity.
Ignoring the
encrypted payload, an attacker can still take ad-
vantage of ﬂow information such as packet lengths
and timings to infer what websites Tor users are
visiting [16].
Bridge address harvesting: Users behind censorship
systems use private Tor relays—typically called
bridges—as hidden stepping stones into the Tor net-
work. It is important that censors cannot obtain all
bridge addresses, which is why The Tor Project rate-
limits bridge distribution. However, an attacker can
harvest bridge addresses by running a middle relay
and looking for incoming connections that do not
originate from any of the publicly known guard re-
lays [22, § 3.4].
End-to-end correlation: By running both entry guards
and exit relays, an attacker can use timing analysis
to link a Tor user’s identity to her activity, e.g., learn
that Alice is visiting Facebook. For this attack to
work, an attacker must run at least two Tor relays, or
be able to eavesdrop on at least two networks [14].
Conﬁguring a relay to forward more trafﬁc allows an
attacker to increase her consensus weight. However, the
capacity of a single relay is limited by its link band-
width and, because of the computational cost of cryptog-
raphy, by CPU. Ultimately, increasing consensus weight
USENIX Association  
25th USENIX Security Symposium  1169
requires an adversary to add relays to the network; we
call these additional relays Sybils.
In addition to the above attacks, an adversary needs
Sybil relays to manipulate onion services, which are TCP
servers whose IP address is hidden by Tor. In the current
onion service protocol, six Sybil relays are sufﬁcient to
take ofﬂine an onion service because of a weakness in
the design of the distributed hash table (DHT) that pow-
ers onion services [4, § V]. Finally, instead of being a
direct means to an end, Sybil relays can be a side effect
of another issue. In Section 5.1, we provide evidence for
what appears to be botnets whose zombies are running
Tor relays, perhaps because of a misguided attempt to
help the Tor network grow.
Motivated by the lack of practical Sybil detection
tools, we design and implement heuristics,
leverag-
ing our observations that Sybils (i) frequently go on-
line and ofﬂine simultaneously, (ii) share similarities in
their conﬁguration, and (iii) may change their identity
ﬁngerprint—a relay’s ﬁngerprint is the hash over its pub-
lic key—frequently, to manipulate Tor’s DHT. Three of
our four heuristics are automated and designed to run
autonomously while one assists in manual analysis by
ranking what relays in the network are the most similar
to a given reference relay. Our evaluation suggests that
our heuristics differ in their effectiveness; one method
detected only a small number of incidents, but some of
them no other method could detect. Other heuristics pro-
duced a large number of results, and seem well-suited
to spot the “low hanging fruit.” We implemented these
heuristics in a tool, sybilhunter, which we subsequently
used to analyze 100 GiB worth of archived network data,
consisting of millions of ﬁles, and dating back to 2007.
Finally, we characterize the Sybil groups we discovered.
To sum up, we make the following key contributions:
• We design and implement sybilhunter, a tool to an-
alyze past and future Tor network data. While we
designed it speciﬁcally for the use in Tor, our tech-
niques are general in nature and can easily be ap-
plied to other distributed systems such as I2P [31].
• We characterize Sybil groups and publish our ﬁnd-
ings as datasets to stimulate future research.2 We
ﬁnd that Sybils run MitM attacks, DoS attacks, and
are used for research projects.
The rest of this paper is structured as follows. We
begin by discussing related work in Section 2 and give
some background on Tor in Section 3. Section 4 presents
the design of our analysis tools, which is then followed
by experimental results in Section 5. We discuss our re-
sults in Section 6 and conclude the paper in Section 7.
2The datasets are available online at
https://nymity.ch/sybilhunting/.
2 Related work
In his seminal 2002 paper, Douceur showed that only a
central authority that veriﬁes new nodes as they join the
distributed system is guaranteed to prevent Sybils [11].
This approach conﬂicts with Tor’s design philosophy that
seeks to distribute trust and eliminate central points of
control. In addition, a major factor contributing to Tor’s
network growth is the low barrier of entry, allowing op-
erators to set up relays both quickly and anonymously.
An identity-verifying authority would raise that barrier,
alienate privacy-conscious relay operators, and impede
Tor’s growth. Barring a central authority, researchers
have proposed techniques that leverage a resource that is
difﬁcult for an attacker to scale. Two categories of Sybil-
resistant schemes turned out to be particularly popular,
schemes that build on social constraints and schemes
that build on computational constraints. For a broad
overview of alternative Sybil defenses, refer to Levine
et al. [19].
Social constraints rely on the assumption that it is difﬁ-
cult for an attacker to form trust relationships with honest
users, e.g., befriend many strangers on online social net-
works. Past work leveraged this assumption in systems
such as SybilGuard [39], SybilLimit [38], and Sybil-
Infer [6]. Unfortunately, social graph-based defenses
do not work in our setting because there is no existing
trust relationship between relay operators.3 Note that we
could create such a relationship by, e.g., linking relays to
their operator’s social networking account, or by creat-
ing a “relay operator web of trust,” but again, we believe
that such an effort would alienate relay operators and see
limited adoption.
Orthogonal to social constraints, computational re-
source constraints guarantee that an attacker seeking to
operate 100 Sybils needs 100 times the computational re-
sources she would have needed for a single virtual iden-
tity. Both Borisov [5] and Li et al. [21] used compu-
tational puzzles for that purpose. Computational con-
straints work well in distributed systems where the cost
of joining the network is low. For example, a lightweight
client is sufﬁcient to use BitTorrent, allowing even low-
end consumer devices to participate. However, this is not
the case in Tor because relay operations require constant
use of bandwidth and CPU. Unlike in many other dis-
tributed systems, it is impossible to run 100 Tor relays
while not spending the resources for 100 relays. Compu-
tational constraints are inherently tied to running a relay.
In summary, we believe that existing Sybil defenses
are ill-suited for application in the Tor network; its dis-
tinctive features call for customized solutions that con-
3Relay operators can express in their conﬁguration that their relays
are run by the same operator, but this denotes an intra-person and not
an inter-person trust relationship.
1170  25th USENIX Security Symposium 
USENIX Association
2
sider the nature of Tor relays. There has already been
some progress towards that direction; namely, The Tor
Project has incorporated a number of both implicit and
explicit Sybil defenses that are in place as of June 2016.
First, directory authorities—the “gatekeepers” of the Tor
network—accept at most two relays per IP address to
prevent low-resource Sybil attacks [3, 2]. Similarly,
Tor’s path selection algorithm ensures that Tor clients
never select two relays in the same /16 network [9]. Sec-
ond, directory authorities automatically assign ﬂags to
relays, indicating their status and quality of service. The
Tor Project has recently increased the minimal time until
relays obtain the Stable ﬂag (seven days) and the HSDir
ﬂag (96 hours). This change increases the cost of Sybil
attacks and gives Tor developers more time to discover
and block suspicious relays before they get in a posi-
tion to run an attack. Finally, the operation of a Tor re-
lay causes recurring costs—most notably bandwidth and
electricity—which can further restrain an adversary.
3 Background
We now provide necessary background on the Tor net-
work [10]. Tor consists of several thousand volunteer-run
relays that are summarized in the network consensus that
is voted on and published each hour by nine distributed
directory authorities. The authorities assign a variety of
ﬂags to relays:
Valid: The relay is valid, i.e., not known to be broken.
HSDir: The relay is an onion service directory, i.e., it
participates in the DHT that powers Tor onion ser-
vices.
Exit: The relay is an exit relay.
BadExit: The relay is an exit relay, but is either mis-
conﬁgured or malicious, and should therefore not
be used by Tor clients.
Stable: Relays are stable if their mean time between
failure is at least the median of all relays, or at least
seven days.
Guard: Guard relays are the rarely-changing ﬁrst hop
for Tor clients.
Running: A relay is running if the directory authorities
could connect to it in the last 45 minutes.
Figure 1: Sybilhunter’s architecture. Two datasets serve
as input to sybilhunter; consensuses and server descrip-
tors, and malicious relays gathered with exitmap [37,
§ 3.1].
of a relay family. Families are used to express that a set
of relays is controlled by a single operator. Tor clients
never use more than one family member in their path
to prevent correlation attacks. In February 2016, there
were approximately 400 relay families among all 7,000
relays.
4 Data and design
We deﬁne Sybils in the Tor network as two or more re-
lays that are controlled by a single person or group of
people. Sybils per se do not have to be malicious; a relay
operator could simply have forgotten to conﬁgure her re-
lays as a relay family. Such Sybils are no threat to the Tor
network, which is why we refer to them as benign Sybils.
What we are interested in is malicious Sybils whose pur-
pose is to deanonymize or otherwise harm Tor users.
To uncover malicious Sybils, we draw on two
datasets—one publicly available and one created by us.