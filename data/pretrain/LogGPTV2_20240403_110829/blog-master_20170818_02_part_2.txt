-----------------------------------------------------------------------------------------------------------------------------------------------  
 Gather Motion 48:1  (slice2; segments: 48)  (cost=124755.04..124755.07 rows=1 width=96)  
   Rows out:  1 rows at destination with 149 ms to end, start offset by 1.890 ms.  
   ->  HashAggregate  (cost=124755.04..124755.07 rows=1 width=96)  
         Group By: tbl_ao_row.c2  
         Rows out:  1 rows (seg42) with 0.004 ms to first row, 55 ms to end, start offset by 64 ms.  
         ->  Redistribute Motion 48:48  (slice1; segments: 48)  (cost=124755.00..124755.02 rows=1 width=96)  
               Hash Key: tbl_ao_row.c2  
               Rows out:  48 rows at destination (seg42) with 32 ms to end, start offset by 64 ms.  
               ->  HashAggregate  (cost=124755.00..124755.00 rows=1 width=96)  
                     Group By: tbl_ao_row.c2  
                     Rows out:  Avg 1.0 rows x 48 workers.  Max 1 rows (seg0) with 0.001 ms to first row, 46 ms to end, start offset by 59 ms.  
                     ->  Append-only Scan on tbl_ao_row  (cost=0.00..109755.00 rows=20834 width=16)  
                           Rows out:  Avg 20833.3 rows x 48 workers.  Max 20854 rows (seg42) with 24 ms to end, start offset by 59 ms.  
 Slice statistics:  
   (slice0)    Executor memory: 345K bytes.  
   (slice1)    Executor memory: 770K bytes avg x 48 workers, 770K bytes max (seg0).  
   (slice2)    Executor memory: 359K bytes avg x 48 workers, 374K bytes max (seg42).  
 Statement statistics:  
   Memory used: 128000K bytes  
 Settings:  optimizer=off  
 Optimizer status: legacy query optimizer  
 Total runtime: 152.386 ms  
(22 rows)  
```  
12、行存AO表，末尾几个字段的统计  
```  
postgres=# explain analyze select c398,count(*),sum(c399),avg(c399),min(c399),max(c399) from tbl_ao_row group by c398;  
                                                                     QUERY PLAN                                                                        
-----------------------------------------------------------------------------------------------------------------------------------------------------  
 Gather Motion 48:1  (slice2; segments: 48)  (cost=125186.01..125401.52 rows=9578 width=96)  
   Rows out:  10001 rows at destination with 183 ms to end, start offset by 1.846 ms.  
   ->  HashAggregate  (cost=125186.01..125401.52 rows=200 width=96)  
         Group By: tbl_ao_row.c398  
         Rows out:  Avg 208.4 rows x 48 workers.  Max 223 rows (seg17) with 0.003 ms to first row, 97 ms to end, start offset by 22 ms.  
         ->  Redistribute Motion 48:48  (slice1; segments: 48)  (cost=124755.00..124946.56 rows=200 width=96)  
               Hash Key: tbl_ao_row.c398  
               Rows out:  Avg 8762.2 rows x 48 workers at destination.  Max 9422 rows (seg46) with 32 ms to end, start offset by 68 ms.  
               ->  HashAggregate  (cost=124755.00..124755.00 rows=200 width=96)  
                     Group By: tbl_ao_row.c398  
                     Rows out:  Avg 8762.2 rows x 48 workers.  Max 8835 rows (seg2) with 0.013 ms to first row, 48 ms to end, start offset by 22 ms.  
                     ->  Append-only Scan on tbl_ao_row  (cost=0.00..109755.00 rows=20834 width=16)  
                           Rows out:  Avg 20833.3 rows x 48 workers.  Max 20854 rows (seg42) with 22 ms to end, start offset by 71 ms.  
 Slice statistics:  
   (slice0)    Executor memory: 377K bytes.  
   (slice1)    Executor memory: 1144K bytes avg x 48 workers, 1144K bytes max (seg0).  
   (slice2)    Executor memory: 414K bytes avg x 48 workers, 414K bytes max (seg0).  
 Statement statistics:  
   Memory used: 128000K bytes  
 Settings:  optimizer=off  
 Optimizer status: legacy query optimizer  
 Total runtime: 184.723 ms  
(22 rows)  
```  
13、列存AO表，前面几个字段的统计  
```  
postgres=# explain analyze select c2,count(*),sum(c3),avg(c3),min(c3),max(c3) from tbl_ao_col group by c2;  
                                                                    QUERY PLAN                                                                      
--------------------------------------------------------------------------------------------------------------------------------------------------  
 Gather Motion 48:1  (slice2; segments: 48)  (cost=122928.04..122928.07 rows=1 width=96)  
   Rows out:  1 rows at destination with 104 ms to end, start offset by 1.878 ms.  
   ->  HashAggregate  (cost=122928.04..122928.07 rows=1 width=96)  
         Group By: tbl_ao_col.c2  
         Rows out:  1 rows (seg42) with 0.003 ms to first row, 18 ms to end, start offset by 55 ms.  
         ->  Redistribute Motion 48:48  (slice1; segments: 48)  (cost=122928.00..122928.02 rows=1 width=96)  
               Hash Key: tbl_ao_col.c2  
               Rows out:  48 rows at destination (seg42) with 30 ms to end, start offset by 55 ms.  
               ->  HashAggregate  (cost=122928.00..122928.00 rows=1 width=96)  
                     Group By: tbl_ao_col.c2  
                     Rows out:  Avg 1.0 rows x 48 workers.  Max 1 rows (seg0) with 0.007 ms to first row, 3.991 ms to end, start offset by 54 ms.  
                     ->  Append-only Columnar Scan on tbl_ao_col  (cost=0.00..107928.00 rows=20834 width=16)  
                           Rows out:  0 rows (seg0) with 40 ms to end, start offset by 56 ms.  
 Slice statistics:  
   (slice0)    Executor memory: 345K bytes.  
   (slice1)    Executor memory: 903K bytes avg x 48 workers, 903K bytes max (seg0).  
   (slice2)    Executor memory: 359K bytes avg x 48 workers, 374K bytes max (seg42).  
 Statement statistics:  
   Memory used: 128000K bytes  
 Settings:  optimizer=off  
 Optimizer status: legacy query optimizer  
 Total runtime: 106.859 ms  
(22 rows)  
```  
14、列存AO表，末尾几个字段的统计  
```  
postgres=# explain analyze select c398,count(*),sum(c399),avg(c399),min(c399),max(c399) from tbl_ao_col group by c398;  
                                                                       QUERY PLAN                                                                         
--------------------------------------------------------------------------------------------------------------------------------------------------------  
 Gather Motion 48:1  (slice2; segments: 48)  (cost=123364.18..123582.28 rows=9693 width=96)  
   Rows out:  10001 rows at destination with 120 ms to end, start offset by 1.921 ms.  
   ->  HashAggregate  (cost=123364.18..123582.28 rows=202 width=96)  
         Group By: tbl_ao_col.c398  
         Rows out:  Avg 208.4 rows x 48 workers.  Max 223 rows (seg17) with 0.001 ms to first row, 54 ms to end, start offset by 35 ms.  
         ->  Redistribute Motion 48:48  (slice1; segments: 48)  (cost=122928.00..123121.86 rows=202 width=96)  
               Hash Key: tbl_ao_col.c398  
               Rows out:  Avg 8762.2 rows x 48 workers at destination.  Max 9422 rows (seg46) with 31 ms to end, start offset by 63 ms.  
               ->  HashAggregate  (cost=122928.00..122928.00 rows=202 width=96)  
                     Group By: tbl_ao_col.c398  
                     Rows out:  Avg 8762.2 rows x 48 workers.  Max 8835 rows (seg2) with 0.004 ms to first row, 8.004 ms to end, start offset by 82 ms.  
                     ->  Append-only Columnar Scan on tbl_ao_col  (cost=0.00..107928.00 rows=20834 width=16)  
                           Rows out:  0 rows (seg0) with 28 ms to end, start offset by 64 ms.  
 Slice statistics:  
   (slice0)    Executor memory: 377K bytes.  
   (slice1)    Executor memory: 1272K bytes avg x 48 workers, 1272K bytes max (seg0).  
   (slice2)    Executor memory: 414K bytes avg x 48 workers, 414K bytes max (seg0).  
 Statement statistics:  
   Memory used: 128000K bytes  
 Settings:  optimizer=off  
 Optimizer status: legacy query optimizer  
 Total runtime: 122.173 ms  
(22 rows)  
```  
对于非分布键的分组聚合请求，Greenplum采用了多阶段聚合如下：  
第一阶段，在SEGMENT本地聚合。（需要扫描所有数据，这里不同存储，前面的列和后面的列的差别就体现出来了，行存储的deform开销，在对后面的列进行统计时性能影响很明显。）  Greenplum会根据字段的distinct值的比例，考虑是直接重分布数据，还是先在本地聚合后再重分布数据（减少重分布的数据量）。  
第二阶段，根据分组字段，将结果数据重分布。（重分布需要用到的字段，此时结果很小。）  
第三阶段，再次在SEGMENT本地聚合。（需要对重分布后的数据进行聚合。）  
第四阶段，返回结果给master，有必要的话master节点调用聚合函数的final func（已经是很少的记录数和运算量）。  
## 如何查看表的存储结构  
pg_class.relstorage表示这个对象是什么存储：  
```  
postgres=# select distinct relstorage from pg_class ;    
 relstorage     
------------    
 a  -- 行存储AO表    
 h  -- heap堆表、索引    
 x  -- 外部表(external table)    
 v  -- 视图    
 c  -- 列存储AO表    
(5 rows)    
```  
查询当前数据库有哪些AO表：  
```  
postgres=# select t2.nspname, t1.relname from pg_class t1, pg_namespace t2 where t1.relnamespace=t2.oid and relstorage in ('c', 'a');    
 nspname  |      relname          
----------+-------------------    
 postgres | tbl_tag    
 postgres | tbl_pos_1_prt_p1    
 postgres | tbl_pos_1_prt_p2    
 postgres | tbl_pos_1_prt_p3    
 postgres | tbl_pos_1_prt_p4    
 postgres | tbl_pos_1_prt_p5    
 postgres | tbl_pos_1_prt_p6    
 postgres | tbl_pos_1_prt_p7    
 postgres | tbl_pos_1_prt_p8    
 postgres | tbl_pos_1_prt_p9    
 postgres | tbl_pos_1_prt_p10    
 postgres | tbl_pos    
 postgres | xx_czrk_qm_col    
 postgres | ao1    
(14 rows)    
```  
查询当前数据库有哪些堆表：  
```  
select t2.nspname, t1.relname from pg_class t1, pg_namespace t2 where t1.relnamespace=t2.oid and relstorage in ('h') and relkind='r';    
```  
## 参考  
[《PostgreSQL 向量化执行插件(瓦片式实现) 10x提速OLAP》](../201702/20170225_01.md)    
http://greenplum.org/docs/best_practices/schema.html  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")