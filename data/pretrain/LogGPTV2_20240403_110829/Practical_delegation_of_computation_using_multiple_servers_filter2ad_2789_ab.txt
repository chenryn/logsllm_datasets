ware that allow almost any type of computation (e.g. [22, 18]). In
the latter one, the client trusts some small tamper-resistant hard-
ware (e.g. a tamper-proof coprocessor) that the server has, and
using this hardware the server can prove the correctness of its com-
putation. We note that using tamper-resistant hardware is concep-
tually similar to trusting another weak third-party (in this case,
the hardware manufacturer). Nonetheless, this direction is very
promising by means of practicality and generality.
There are works that consider veriﬁcation of peers in distributed
computations (e.g., [14] for verifying peers that are state machines)
but usually these works assume the different players (i.e. the servers
in our model) communicate among themselves or through a trusted
server. In the model of cloud computing, we prefer that all commu-
nication will be held only between the client and the servers. That
way, the servers do not know whom they are “playing” against (or
even against how many) and the client does not have to trust any
third party servers.
Our construction is not based on probabilistically checkable proofs
or Fully Homomorphic Encryption, which are not practical yet, nor
does it rely on trusted hardware. Furthermore, it does not require
the arguably complex transformation of a Turing Machine program
to a boolean circuit.
1.3 Organization
In Section 2 we deﬁne the model of Refereed Delegation of
Computation (RDoC) and show how to extend RDoC with two
servers to N servers. In Section 3.3 we present in detail our RDoC
protocol. In Section 4 we describe the difﬁculties of implementing
the protocol, our design choices, the adaptation of the protocol for
X86 CPU and the architecture of Quin. In Section 4.4 we show
experimental results of Quin on live clouds and in Section 4.5 we
outline several future improvements.
2. REFEREED DELEGATION
OF COMPUTATION
A refereed delegation of computation for a function f is a proto-
col between a client (or a referee) R and N servers P1, P2, . . . , PN .
All parties may use local randomness. The client and the servers
receive an input x. The servers claim different results for the com-
putation of f (x) and the client should be able to determine the cor-
rect answer with high probability. We assume that at least one of
the servers is honest.
DEFINITION 1
(REFEREED DELEGATION OF COMPUTATION).
Let (P1, P2, . . . , PN , R) be an ε-RDoC with N servers for a func-
tion f if the following holds:
• For any input x and for all i ∈ {1, . . . , N}, if server Pi is
N the output
honest then for any P ∗
1 , . . . , P ∗
of R is f (x) w.p. at least 1 − ε.
i+1, . . . , P ∗
i−1, P ∗
• The complexity of the client is at most quasi-linear in |x| and
the complexity of the (honest) servers is polynomial in the
complexity of evaluating f.
447If soundness holds only for polynomially bounded (in |x|) servers
then we say that it is a computationally sound RDoC. Furthermore,
if the client starts by sending all its local random choices to all
servers, and if all the communication between the client and the
servers is public, we call it a full-information RDoC.
For completeness of the description, we brieﬂy review the model
of Refereed Games [10]. A refereed game (RG) for a language L
is a protocol between a referee R and two competing unbounded
servers P1 and P2. All three parties may use local randomness.
The referee and the servers receive x ∈ {0, 1}∗. Without loss of
generality we can assume P1 claims that x ∈ L and P2 claims
that x /∈ L, and the referee should be able to determine the correct
answer with probability at least 2/3.
From Two Servers to N Servers. In the next sections we only
discuss the case where there are two servers. Here we show how,
given any RDoC with two servers and negligible error probabil-
ity, one can construct a RDoC with N servers and negligible error
probability, where we only need to assume that at least one of them
is honest.
The idea is to execute the RDoC with two servers between each
pair of servers. By the soundness of the RDoC with two servers,
with high probability there exists an honest server Pi that convinces
the client in all of his “games”. The client outputs the claimed
result of Pi.
This solution can be executed in parallel for all pairs, and there-
fore keeps the number of rounds the same. However, it requires
N·(N−1)
different executions of the protocol.
2
3. PROTOCOL FOR TURING MACHINES
3.1 Preliminaries: Merkle Hash Tree
Merkle Hash Tree (MHT) [19] is a common primitive that allows
one to hash a long string of n characters in a where the hash can
later be used to reveal any part of the string and supply a short
proof of consistency. Given a collision-resistant hash function H
and a string str of length n, the tree has n leaf nodes where leaf
node i has the value of H(str[i]). The next level has the values of
H(H(str[i]) ◦ H(str[i + 1])) for i = 1, 3, . . . n − 1, and so on
for the other levels. The highest level, the root, is the hash for the
full string str. The proof of consistency for character i is the hash
values along the path from the root to H(str[i]) and their siblings.
Given a Merkle Hash Tree of string str, denote by MH root(str)
the value of the root, by MH proof (str, i) the proof of consistency
for i-th character, and by VerifyMHProof(root, i, stri, p) the veri-
ﬁcation function that given a claimed p = MH proof (str, i) outputs
True if p is a valid proof of consistency, and False otherwise. Note
that the size of MH root(str) depends on the output length of the
hash function and the size of MH proof (str, i) is logarithmic in the
length of str.
Denote by str[i]=x the string that equals to str except for the i-
th character that is x. We observe the following property of Merkle
Hash Trees: Given a proof of consistency p for the i-th character of
str, anyone can efﬁciently (i.e. in logarithmic time in the length of
str) compute MH root(str[i]=x). This can be done by computing
the hash of x and then iteratively computing the hashes along the
path from i to the root.
3.2 Reduced Turing Machine Conﬁguration
Given a Turing Machine conﬁguration (state, head, tape), let
the reduced-conﬁguration of (state, head, tape) be the tuple
( state, head, tape[head], MH root(tape) ).
For simplicity of the description, we denote by k the maximal
length of the tape during the execution of the Turing Machine. Note
that the size of the reduced-conﬁguration is logarithmic in k, and
therefore for computation of size T , it is at most logarithmic in T .
Given two reduced Turing Machine conﬁgurations rc1 = (s1, h1,
v1, r1) and rc2 = (s2, h2, v2, r2) that are claimed to be consec-
utive, and a proof of consistency of the ﬁrst conﬁguration p1 =
MH proof (t, h1) where t is the tape of conﬁguration rc1, one can
efﬁciently verify this claim by checking the following:
1. Verify that VerifyMHProof(r1, h1, v1, p1) is True.
2. Simulate a single step of the Turing Machine on s1, h1, v1
and get the next state s(cid:48), new head position h(cid:48) and the written
character v(cid:48)
3. Verify that s(cid:48) == s2 and h(cid:48) == h2.
4. Using p1 and v(cid:48), compute r(cid:48) = MH root(t[h1]=v(cid:48) ). (This can
be done without knowing t using the previous observation.)
5. Verify that r(cid:48) == r2.
If one of the above checks fail, then the claim is false.
Denote by VerifyReducedStep(rc1, rc2, p1) the function that given
two reduced conﬁgurations rc1, rc2 and proof of consistency p1
outputs False if any of the above checks fails, and True otherwise.
3.3 The Protocol
We base our protocol on the work of Feige and Kilian [10] where
they present a refereed game with polynomial number of rounds
and private communication channels (therefore not full informa-
tion) for any EXPTIME language. Their protocol uses arithmetiza-
tion for consistency checks and then takes advantage of the locality
property of a single Turing Machine step (each Turing Machine
transition uses only O(1) local information: the current state, the
current head position and the current character). In their protocol
for languages in EXPTIME, the referee is polynomial in the length
of the input x.
Their construction can be directly scaled-down for languages in
P , yielding a protocol where the servers are polynomial in the in-
put size and the referee is quasi-linear. Correctness remains un-
conditional. However, the protocol requires private communication
channels between the referee and the two servers.
We modify their scaled-down protocol (for P languages) by re-
placing the use of arithmetization with Merkle Hash Trees. Al-
though it gives only computational soundness, it greatly simpliﬁes
the protocol and gives us a negligible error probability for even one
execution of the protocol. Since the main overhead of the protocol
would be retrieving different states of the execution, this property
is highly important. Our protocol is full-information and in par-
ticular does not require private communication channels. In a set-
ting where messages between the players are digitally signed, the
client can obtain a publicly veriﬁable proof that a server is cheat-
ing. (Note that in case of private channels/private-information, and
speciﬁcally in the protocol of [10], colluding referee and server
can forge together a transcript that incriminates an honest server of
cheating. In the full-information model it is not possible.)
Given a Collision-Resistant Hash Function, our protocol is the
following. The client requests each server to execute the Turing
Machine that computes f (x). In case they answer the same, by
the assumption that one of them is honest, the answer is the correct
one. Else, the client continues to a binary-search phase. The client
asks the servers to send him the number of steps it takes to compute
f (x)), takes the smaller answer as the current bad row variable, nb,
and sets to 1 the current good row variable, ng. The client also asks
448for the maximal length of their stored conﬁgurations and takes the
bigger answer to be k. Now, the client asks for the reduced con-
ﬁguration of the (nb − ng)/2 + ng conﬁguration. If one of the
answers is not a valid reduced conﬁguration, the client outputs the
value of f (x) of the other server (this is the honest server). If an-
swers match, he sets ng = (nb − ng)/2 + ng, otherwise, he sets
nb = (nb − ng)/2 + ng. The client continues the binary search
in that way till he gets ng + 1 = nb. Note that the servers do not
have to remember all the conﬁgurations, instead, they can remem-
ber only two conﬁgurations, one for the last ng and one for the last
(nb − ng)/2 + ng. Then, when asked for the next conﬁguration,
the server can continue the TM execution from one of those con-
ﬁgurations. Overall, in worst case scenario, the servers execution
time is not much more than executing the program twice.
Now, the client asks Server 1 for the consistency proof for con-
ﬁguration ng, i.e. p = MH proof (tng , hng ). Denote by rcng and
rcnb the reduced conﬁguration that Server 1 sent to the client. If
VerifyReducedStep(rcng , rcnb , p) is True, the client outputs the
value of f (x) of Server 1. Otherwise, he outputs the value of f (x)
of Server 2.
Overall we have:
THEOREM 1. Assume the hash function in use is collision re-
sistant. Then the above protocol is a computationally sound, full-
information, RDoC with two servers and with negligible soundness
ε for any function computable in polynomial time. For functions
that can be computed by TMs taking T (n) steps and S(n) space
on input x with |x| = n, the protocol takes log T (n) + 3 rounds,
the client runs in time O(n + κ log T (n) + κ log S(n)) and the
servers run in time O(T (n) + κS(n) log T (n)), where κ is a se-
curity parameter.
Note that in case both servers are honest, there is no overheads.
PROOF (SKETCH). By the speciﬁcation of the protocol, if Server
1 is honest then it always successfully convinces the client (no mat-
ter what a malicious Server 2 does).
A malicious Server 1 can deceive the client to output a false value
only if it can generate a fake consistency proof p that has the same
root of the Merkle Hash Tree as in the correct reduced conﬁgu-
ration ng. Let π be the above protocol, and let π(cid:48) be the above
protocol with the following change: in the last step the client asks
for the consistency proof from both servers and outputs the value of
the server that was honest (i.e., its consistency proof was consistent
with its reduced conﬁgurations ng and nb) or the output of Server
1 if they were both “honest” (i.e., both proofs were valid). Let  be
the probability that Server 1 cheats in π and let (cid:48) be the probability
Server 1 cheats in π(cid:48). Since a malicious Server 1 from protocol π
can also cheat in protocol π(cid:48) then  ≤ (cid:48). Now, assuming Server 1
in π(cid:48) is malicious, then the client in protocol π(cid:48) receives two differ-
ent consistency proofs with the same root, thus, he gets a collision
in some node along the path to index hng . By the security of the
collision resistant hash function, this can only happen with a negli-
gible probability. Therefore,  is negligible.
3.4 Extensions
Reducing the number of rounds. In some scenarios, the number
of rounds might still be the bottle-neck of the protocol. We can
reduce the number of rounds by permitting larger messages and
longer running time of the servers.
For any constant number t we can reduce the number of rounds
to logt+1 T (n) (but slightly increase the communication size, by a
factor of t) using the following idea. Instead of asking the servers
for only one reduced conﬁguration in each round, the client asks
for t reduced conﬁgurations. Speciﬁcally, the client asks for the
t steps that are equally spread between ng and nb.
I.e., given
ng = 100, nb = 200, t = 4, the client asks for 120, 140, 160
and 180. Similar to the protocol from Section 3.3, the client up-
dates ng and nb according to the servers’ answers and continues to
the next iteration of the binary (or (t + 1)-ary) search.
More than two servers. In addition to the general method for ex-
tending the protocol to N servers from Section 2, we can extend
this speciﬁc protocol also in the following way. The client executes
a Playoff between all servers.
In the ﬁrst round, the client exe-
cutes the protocol from Section 3.3 with all servers (he can do that
because the protocol uses only public communication), where he
marks a row as a good row only if all answers for this row match.
At the end of the binary search, the client checks if the reduced
conﬁgurations are consecutive for each one of the servers. After
the execution of this protocol, at least one malicious server will be
caught lying and will be declared as a cheater. The client continues
to the next round with the other servers, again, executes the pro-
tocol to ﬁnd at least one cheater and then excludes him (or them)
from the next rounds. The protocol ends when all the remaining
servers agree on the output.
Since the client excludes at least one malicious server in each
round of the playoff, the number of rounds is bounded by the num-
ber of malicious servers.
Supporting large datasets. In order to support computations which
use large datasets (e.g. Databases), we can use the Merkle Hash
Trees again. We assume the client knows the root of the MHT of
the data (either because he delegated the data in the past, or by
keeping track of changes of the root). We modify the protocol from
Section 3.3 to work with another tape that includes the dataset and
we add to the reduced conﬁguration also the root of the MHT of
this tape, the current head position and the MHT proof for its cur-
rent character. The rest of the protocol is the same. Note that the
client has to know the root of the MHT at the beginning of the
computation in order to be able to verify the initial conﬁguration.
Reducing the server’s overhead. In the worst case, the execution
time of the servers in the protocol from Section 3.3 is not much
more than executing the program twice. The server “pays” one
execution time only for counting the number of instructions and
then half execution time for getting to the middle conﬁguration.
If we allow the servers to store more conﬁgurations then we can
reduce the computation time for getting the middle conﬁguration.
Instead of just counting the number of instructions, the server also
stores intermediate conﬁgurations. Let i be the current step of the
execution. During the count of instructions, the server remembers
the last three conﬁgurations for steps i3 = 2(cid:98)log(i)(cid:99), i1 = i3/2 and
i2 = (i3−i1)/2+i1. Note that these values are changed only when
i = 2 ∗ i3, and by storing also conﬁguration i3 + i1, the server can
compute them efﬁciently on-the-ﬂy. In other words, the server al-
ways remembers at most four conﬁgurations and updates them dur-
ing the counting (without rewinding the computation). Now, when
requested for the middle conﬁguration, the server takes the nearest
stored conﬁguration (either for i1 or i2) and continues the execution
from that conﬁguration. Overall, it reduces the computation of the
middle conﬁguration from half to one sixth in the worst case (re-
6 instead of 2). Repeating this method can
sulting in overhead of 1 4
reduce this overhead even more but with the price of larger storage.
4. QUIN: ADAPTATION AND IMPLEMEN-
TATION OF THE PROTOCOL FOR X86
We show how to adapt the protocol from Section 3.3 for X86
CPU, and we present a prototype implementation that enables del-
449egation of X86 executables for the Windows environment. Note
that Windows is a closed-source OS, and our implementation does
not require any changes to the OS. Everything runs in User-Mode.
See [4] for the source code of the prototype.
4.1 The Difﬁculties and Design Choices
Although the protocol in Section 3.3 seems easy to describe with
Turing Machines, its adaptation for real-world use is quite delicate.
An implementation of it must have the following key properties:
• Determinism: The protocol highly depends on the determin-