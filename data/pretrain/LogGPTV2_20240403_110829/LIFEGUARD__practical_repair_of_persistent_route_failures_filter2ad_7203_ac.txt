D2, whereas selective poisoning forces only A to change. In §5.2
we ﬁnd that selective poisoning lets LIFEGUARD avoid 73% of the
links we test.
4. APPLYING FAILURE AVOIDANCE
In the previous section, we described how LIFEGUARD uses BGP
poisoning to approximate AVOID_PROBLEM(X,P). This allows us
to experiment with failure avoidance today, and it gives ASes a way
to deploy failure avoidance unilaterally. In this section, we describe
how LIFEGUARD decides when to poison and which AS to poison,
as well as how it decides when to stop poisoning an AS.
4.1 Locating a Failure
An important step towards ﬁxing a reachability problem is to
identify the network or router responsible for it. To be widely ap-
plicable and effective, we require our fault isolation technique to:
• be effective even if the system has control over only one of the
endpoints experiencing a reachability problem.
• be accurate even if measurement probes to reachable targets
appear to fail due to rate-limiting, chronic unresponsiveness,
and/or being dropped on the reverse direction.
• integrate information from multiple measurement nodes, each
with only partial visibility into routing behavior.
We assume that a routing failure between a pair of endpoints can
be explained by a single problem. While addressing multiple fail-
ures is an interesting direction for future work, this paper focuses
on single failures.
4.1.1 Overview of Failure Isolation
The failure isolation component of LIFEGUARD is a distributed
system, using geographically distributed PlanetLab hosts to make
data plane measurements to a set of monitored destinations. Be-
cause many outages are partial, LIFEGUARD uses vantage points
with working routes to send and receive probes on behalf of those
with failing paths. Because many failures are unidirectional [20],
it adapts techniques from reverse traceroute [19] to provide reverse
path visibility. In the current deployment, vantage points send pings
to monitor destinations, and a vantage point triggers failure isola-
tion when it experiences repeated failed pings to a destination.
LIFEGUARD uses historical measurements to identify candidates
that could potentially be causing a failure, then systematically prunes
the candidate set with additional measurements. We outline these
steps ﬁrst before describing them in greater detail.
1. Maintain background atlas: LIFEGUARD maintains an atlas
of the round-trip paths between its sources and the monitored
Figure 3: A case in which LIFEGUARD can use selective poisoning. By
selectively poisoning A on announcements to D2 and not on announce-
ments to D1, O can cause trafﬁc to avoid the link from A to B2, without
disrupting how C3 routes to A or how C[1,2,4] route to O.
options, converging instantly. We will show in a measurement
study in §5.2 that this prepending smooths convergence, helping
ease concerns that an automated response to outages might intro-
duce needless routing instability. This approach is orthogonal to ef-
forts to reduce convergence effects [18, 22, 24], which LIFEGUARD
would beneﬁt from.
3.1.2 Partially Poisoning ASes
LIFEGUARD tries to avoid cutting off an entire AS A and all ASes
that lack routes that avoid A. We have three goals: (1) ASes cut off
by poisoning should be able to use routes through A to reach O as
soon as they work again; (2) if some paths through A work while
others have failed, ASes using the working routes should be able
to continue to if they lack alternatives; and (3) when possible, we
should steer trafﬁc from failed to working paths within A.
Advertising a less-speciﬁc sentinel preﬁx. While O is poisoning
A, ASes like F that are “captive” behind A will lack a route [7].
To ensure that F and A have a route that covers P, LIFEGUARD an-
nounces a less-speciﬁc sentinel preﬁx that contains P (and can also
contain other production preﬁxes). When P experiences problems,
the system continues to advertise the sentinel with the baseline (un-
poisoned) path. As seen in Fig. 2(b), ASes that do not learn of the
poisoned path, because they are “captive” behind A, will receive the
less speciﬁc preﬁx and can continue to try routing to the production
preﬁx on it, through A, instead of being cut off. This effect is the
Backup Property desired from AVOID_PROBLEM(A,P) and helps
achieve goals (1) and (2).
Selectively poisoning to avoid AS links. Although most failures in
a previous study were conﬁned to a single AS, 38% occurred on an
inter-AS link [13]. We use a technique we call selective poisoning
to allow LIFEGUARD, under certain circumstances, to implement
AVOID_PROBLEM(A-B,P). Poisoning does not provide a general
solution to AS link avoidance, but, given certain topologies, selec-
tive poisoning can shift trafﬁc within A onto working routes.
Speciﬁcally, under certain circumstances, O may be able to steer
trafﬁc away from a particular AS link without forcing it completely
away from the ASes that form the link. Suppose O has multiple
providers that connect to A via disjoint AS paths. Then O can
poison A in advertisements to one provider, but announce an un-
poisoned path through the other provider. Because the paths are
disjoint, A will receive the poisoned path from one of its neighbors
and the unpoisoned path from another, and it will only accept the
unpoisoned path. So, A will route all trafﬁc to O’s preﬁx to egress
via the neighbor with the unpoisoned path. This selective poison-
ing shifts routes away from A’s link to the other neighbor, as well
as possibly affecting which links and PoPs are used inside A.
OB1B2AC1C2C3C4D1D2OB1B2AC1C2C3C4D1D2Network linkTransitive linkPre-poison pathPost-poison path(a) Before poisoning(b) After poisoning A via D2Figure 4: Isolation measurements conducted for an actual outage. With
traceroute alone, the problem appears to be between TransTelecom and
ZSTTK. Using spoofed traceroute, reverse traceroute, and historical
path information, LIFEGUARD determines that the forward path is
ﬁne, but that Rostelecom no longer has a working path back to GMU.
targets to discern changes during failures and generate candi-
dates for failure locations.
2. Isolate direction of failure and measure working direction:
After detecting a failure, LIFEGUARD isolates the direction of
failure to identify what measurements to use for isolation. Fur-
ther, if the failure is unidirectional, it measures the path in the
working direction using one of two measurement techniques.
3. Test atlas paths in failing direction: LIFEGUARD tests which
subpaths still work in the failing direction by probing routers on
historical atlas paths between the source and destination. It then
remeasures the paths for responsive hops, thereby identifying
other working routers.
4. Prune candidate failure locations: Routers with working paths
in the previous step are eliminated. Then, LIFEGUARD blames
routers that border the “horizon of reachability.” This horizon
divides routers that have connectivity to the source from those
that lack that connectivity.
4.1.2 Description of Fault Isolation
We illustrate the steps that LIFEGUARD uses to isolate failures
using an actual example of a failure diagnosed on February 24,
2011. At the left of Fig. 4 is one of LIFEGUARD’s vantage points,
a PlanetLab host at George Mason University (labeled GMU). The
destination, belonging to Smartkom in Russia, at the right, became
unreachable from the source. For simplicity, the ﬁgure depicts hops
at the AS granularity.
Maintain background atlas: In the steady state, LIFEGUARD uses
traceroute and reverse traceroute to regularly map the forward and
reverse paths between its vantage points and the destinations it is
monitoring. During failures, this path atlas yields both a view of
what recent paths looked like before the failure, as well as a histor-
ical view of path changes over time. These paths provide likely can-
didates for failure locations and serve as the basis for some of the
isolation measurements we discuss below. Because some routers
are conﬁgured to ignore ICMP pings, LIFEGUARD also maintains a
database of historical ping responsiveness, allowing it to later dis-
tinguish between connectivity problems and routers conﬁgured to
not respond to ICMP probes.
The ﬁgure depicts historical forward and reverse traceroutes with
the dotted black and red lines, respectively. The thick, solid black
line in Fig. 4 depicts the traceroute from GMU during the failure.
Traceroute can provide misleading information in the presence of
failures. In this case, the last hop is a TransTelecom router, sug-
gesting that the failure may be adjacent to this hop, between Trans-
Telecom and ZSTTK. However, without further information, oper-
ators cannot be sure, since the probes may have been dropped on
the reverse paths back from hops beyond TransTelecom.
Isolate direction of failure and measure working direction: LIFE-
GUARD tries to isolate the direction of the failure using spoofed
pings [20].
In the example, spoofed probes sent from GMU to
Smartkom reached other vantage points, but no probes reached
GMU, implying a reverse path failure. When the failure is unidirec-
tional, LIFEGUARD measures the complete path in the working di-
rection. Extending the spoofed ping technique, LIFEGUARD sends
spoofed probes to identify hops in the working direction while avoid-
ing the failing direction. For a reverse failure, LIFEGUARD ﬁnds a
vantage point with a working path back from D, then has S send
a spoofed traceroute to D, spooﬁng as the working vantage point.
In the example, GMU issued a spoofed traceroute, and a vantage
point received responses from ZSTTK and the destination. The
blue dashed edges in Fig. 4 show the spoofed traceroute.
If the failure had been on the forward path, the system instead
would have measured the working reverse path with a spoofed re-
verse traceroute from D back to S.
It is useful to measure the working direction of the path for two
reasons. First, since the path is likely a valid policy-compliant path
in the failing direction, it may provide a working alternative for
avoiding the failure. Second, knowledge of the path in the working
direction can guide isolation of the problem in the failing direction,
as we discuss below.
Test atlas paths in failing direction: Once it has measured the
working path, LIFEGUARD measures the responsive portion of the
path. For forward and bidirectional failures, the source can simply
issue a traceroute towards the destination.
For reverse failures, LIFEGUARD cannot measure a reverse tracer-
oute from D, as such a measurement requires a response from D to
Instead, LIFEGUARD has its vantage
determine the initial hops.
points, including S, ping: (1) all hops on the forward path from S to
D and (2) all hops on historical forward and reverse paths between
S and D in its path atlas. These probes test which locations can
reach S, which cannot reach S but respond to other vantage points,
and which are completely unreachable. LIFEGUARD uses its at-
las to exclude hops conﬁgured never to respond. For all hops still
pingable from S, LIFEGUARD measures a reverse traceroute to S.
In the example, LIFEGUARD found that NTT still used the same
path towards GMU that it had before the failure and that Rostele-
com no longer had a working path. We omit the reverse paths from
most forward hops to simplify the ﬁgure. In this case, LIFEGUARD
found that all hops before Rostelecom were reachable (denoted
with blue clouds with solid boundaries), while all in Rostelecom
or beyond were not (denoted with light-gray clouds with dashed
boundaries), although they had responded to pings in the past.
Prune candidate failure locations: Finally, LIFEGUARD removes
any reachable hops from the suspect set and applies heuristics to
identify the responsible hop within the remaining suspects. For
forward outages, the failure is likely between the last responsive
hop in a traceroute and the next hop along the path towards the des-
tination. LIFEGUARD’s historical atlas often contains paths through
the last hop, providing hints about where it is trying to route.
For a reverse failure, LIFEGUARD considers reverse paths from D
back to S that are in its atlas prior to the failure. For the most recent
path, it determines the farthest hop H along that path that can still
reach S, as well as the ﬁrst hop H’ past H that cannot. Given that
H’ no longer has a working path to S, contacting the AS containing
H’ or rerouting around it may resolve the problem.
If the failure is not in H’, one explanation is that, because H’
lacked a route, D switched to another path which also did not work.
In these cases, LIFEGUARD performs similar analysis on older his-
torical paths from D, expanding the initial suspect set and repeating
Level3TeliaZSTTKRostelecomNTTTransTelecomTarget:SmartkomSource:GMUTraceRoute     Historical TR     Spoofed TR     Hist. Reverse TRDeciding when to unpoison: Once LIFEGUARD accurately identi-
ﬁes the AS A responsible for a problem, BGP poisoning can target
it and cause other ASes to route around A. However, A will even-
tually resolve the underlying issue, at which point we would like
to be able to revert to the unpoisoned path, allowing ASes to use
paths through A, if preferred. When the poisoned announcement is
in place, however, A will not have a path to the preﬁx in question.
LIFEGUARD uses a sentinel preﬁx to test reachability. Concerns
such as aggregation and address availability inﬂuence the choice of
sentinel. In our current deployment, the sentinel is a less speciﬁc
preﬁx containing both the production preﬁx and a preﬁx that is not
otherwise used. Responses to pings from the unused portion of
the sentinel will route via the sentinel preﬁx, regardless of whether
the hops also have the poisoned more-speciﬁc preﬁx. By sending
active ping measurements from this preﬁx to destinations that had
been unable to reach the production preﬁx prior to poisoning (e.g.,
E in Fig. 2), the system can detect when to unpoison the production
preﬁx. If the sentinel is a less-speciﬁc without any unused preﬁxes,
LIFEGUARD can instead ping the destinations within the poisoned
AS (e.g., A) or within captives of the poisoned AS (e.g., F).
5. LIFEGUARD EVALUATION
To preview the results of our evaluation, we ﬁnd that LIFEGUARD’s
poisoning ﬁnds routes around the vast majority of potential prob-
lems, its approach is minimally disruptive to paths that are not ex-
periencing problems, and its failure isolation can correctly identify
the AS needing to be poisoned. Table 1 summarizes our key results;
the following sections provide more details.
We deployed LIFEGUARD’s path poisoning using the BGP-Mux
testbed [5], using its AS number and preﬁxes. LIFEGUARD con-
nected to a BGP-Mux instance at Georgia Tech, which served as
the Internet provider for the BGP-Mux AS (and hence for LIFE-
GUARD). For the poisoning experiments in this section, LIFEGUARD
announced preﬁxes via Georgia Tech into the commercial Internet.
We assessed the effects of poisoning in the absence of failures.
To obtain ASes to poison, we announced a preﬁx and harvested all
ASes on BGP paths towards the preﬁx from route collectors [26,
31]. We excluded all Tier-1 networks, as well as Cogent, as it is