title:Information Flow in the Peer-Reviewing Process
author:Michael Backes and
Markus D&quot;urmuth and
Dominique Unruh
Information Flow in the Peer-Reviewing Process (Extended Abstract)
Michael Backes, Markus D¨urmuth, Dominique Unruh
Saarland University
{backes,duermuth,unruh}@cs.uni-sb.de
Abstract
1.1. The Electronic Publishing Process
We investigate a new type of information ﬂow in the
electronic publishing process. We show that the use of
PostScript in this process introduces serious conﬁdential-
ity issues.
In particular, we explain how the reviewer’s
anonymity in the peer-reviewing process can be compro-
mised by maliciously prepared PostScript documents. A
demonstration of this attack is available. We brieﬂy discuss
how this attack can be extended to other document formats
as well.
To elaborate on our attack, let us ﬁrst consider the infor-
mation ﬂow that naturally appears in the electronic publish-
ing process. Usually, the user Alice prepares a document
on computer A. Then this document is transferred, e.g., by
email, to the computer B of user Bob. Finally, Bob reads
the document as rendered by computer B (on screen or by
printing it). The information ﬂow of this process is depicted
by the solid arrows in Figure 1 (a).
1. Introduction
The PostScript language [12] and its successor PDF
(Portable Document Format) are the de-facto standards for
electronic publishing. Despite PostScript being the older
standard, its availability on virtually any platform and its
support on a number of printers makes it still widely de-
ployed, in particular in scientiﬁc publishing.
It is well-
known that PostScript is a Turing-complete programming
language, and it also comprises commands to access the ﬁle
system. Some enthusiasts have even implemented a web
server [14] or an HTML renderer [6] in PostScript.
In 1992 the community involved in developing the
GhostScript interpreter realized that this comprehensive
set of commands rises security issues when processing
PostScript documents from untrusted sources. This led to
the introduction of a conﬁguration option, which prevents
the document to access ﬁles on the local machine, i.e., to
read, write, and delete ﬁles. This option is nowadays ac-
tivated by default.
It is commonly believed that this is
sufﬁcient to ensure security against malicious documents.
(Barring, of course, implementation glitches which tend to
appear in and threaten the security of most complex appli-
cations.) In the following we argue that this belief is not
justiﬁed.
It can be seen as an example of an incomplete
modeling of the information ﬂow occurring in the publish-
ing process which in turn gives rise to natural exploits of the
weaknesses of the PostScript language.
Alice
Bob
Author
Referee
back-channel
referee report
A
reads
B
private
information
A
submission
reads
B
referee’s 
identity
(a)
(b)
Figure 1. Information ﬂow of electronic pub-
lishing, (a) in the general case, (b) in the spe-
cial case of peer-reviewing.
However, for PostScript documents this description is
not complete. Since PostScript is a Turing-complete pro-
gramming language, the rendered document may depend in
arbitrary manner on the data accessible to the PostScript
code. This data may—depending on the particular imple-
mentation of the PostScript interpreter—contain some of
Bob’s private information stored on computer B. We will
see below that this is indeed the case for common PostScript
implementations. In this light, it is necessary to extend the
information ﬂow diagram by another arrow (depicted by a
dashed arrow below computer B in Figure 1 (a)).
It is this idea of information ﬂow that often underlies—
although not explicitly stated—the security considerations
concerning PostScript code, and it is this idea that governs
the design decisions whether language features have to be
disabled or whether they may be available to untrusted docu-
ments. In this model, Bob’s private information only ﬂows
to Bob, but not back to Alice. This is usually considered
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:53:55 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007to be harmless. As a consequence, in common implemen-
tations the access to the private information is not—so we
will show—as restricted as it should be.
The ﬂow of information that is usually overlooked in
this setting is the human communication between Alice and
Bob, in particular, information ﬂowing from Bob to Alice.
So a complete diagram should at least contain an additional
arrow from Bob to Alice. (In order to make the presentation
more concise, we do not include arrows that are not relevant
to our discussion.) Including this back-channel, we ﬁnally
get the situation depicted in Figure 1 (a). Presented in this
form, one immediately sees that Bob’s private information
might in fact ﬂow to Alice.
At this point, one might object that this back-channel is
not a security threat since it is not under Alice’s control and
since the human being Bob will not tell Alice any conﬁden-
tial information even if that information are contained in the
rendered document. This, however, is not entirely correct,
as Bob may talk to Alice about seemingly harmless informa-
tion, which may convey the private information through a
subliminal channel. So the task of a malicious Alice would
be threefold: First, identify some interesting private infor-
mation available to the PostScript code. Second, devise a
dynamic document such that Bob’s response will depend
on the dynamic details of the document. And third, Alice
has to devise an encoding that hides the private information
in the dynamic content of the document such that the private
information can be reconstructed from Bob’s response.
The remainder of this paper is devoted to demonstrating
the feasibility and relevance of the above approach. This
will be done by analysing and exploiting the information
ﬂow in a setting in which PostScript is very popular: the
scientiﬁc peer-reviewing process.
1.2. The Peer Reviewing Process
The reviewing process in scientiﬁc publishing is usu-
ally implemented as a peer-reviewing process, the main rea-
son being that reviewing scientiﬁc papers requires in-depth
knowledge of the subject to judge on its correctness, nov-
elty, and quality. However, judging the work of colleagues
potentially bears the danger of decisions being inﬂuenced
by political considerations, especially if the author who’s
work is being refereed is aware of the identity of the referee.
In particular younger researchers might be afraid to openly
contradict established and inﬂuential members of the com-
munity. For this reason, during a peer-review, the identity
of the referee (and often also of the author) is kept secret.
In this light, the identity of the referee, which is usually
known to the referee’s computer, can be considered as pri-
vate information whose conﬁdentiality must be ensured. So
by applying the considerations of the preceding section to
the peer-reviewing process, we see that the information ﬂow
is as depicted in Figure 1 (b). It turns out that the identity of
the referee is indeed accessible to untrusted documents in
many PostScript implementations.
The back-channel is also naturally present in the review-
ing process. Since the author usually gets a referee report
listing suggestions and mistakes, the author can implement
a back-channel by creating a document that dynamically in-
troduces mistakes depending on the identity of the referee.
Even if the referee does only report part of these errors,
using a suitable error-correcting code one can easily trans-
mit enough information to be able to identify the referee in
many situations. So the anonymity of the peer-reviewing
process is indeed in danger when using PostScript.
1.3. Related Work
The back-channel we are using can be seen as a novel
form of a covert channel [15]. Traditional covert chan-
nels typically transmit data on an electronic link, usually a
network connection, e.g., by exploiting different execution
times resulting in observably different behaviors [17, 1, 7],
or by employing steganographic techniques to hide data
within other data, see [2] for a survey. In our scenario the
PostScript document takes the part of the sender of the data,
while the author is the receiver. In contrast to the common
setting, the channel we are investigating is not an electronic
one but constitutes a socially-engineered back-channel.
Our approach furthermore has similarities to the notion
of watermarking schemes [9, 11]. While robust watermark-
ing schemes provide measures that prevent the watermark
from being removed from the document, fragile watermark-
ing schemes aim to detect if a document was tampered with.
Thus they do not precisely ﬁt our setting as we rather rely
on the usual behavior of a reviewer and are not primarily
interested in whether an existing document was modiﬁed.
Another related concept is traitor tracing [8, 4, 3], which al-
lows for detecting a party who leaked a secret, e.g., a secret
decryption key. While there are again similarities at the sur-
face, the exact setting as well as the technical realization of
our work is quite different since the reviewer does not inten-
tionally leak its secret key but is rather pushed into leaking
it without noticing.
Some other surprising PostScript hacks include a Web-
server [14] as well as an HTML-renderer [6]. A virus-
like program written in LATEX is described in [16]. Weak-
nesses of PostScript and the process that led to the current
(insufﬁcient) sandboxing model which is implemented on
GhostView can be found at the GhostScript homepage [10].
2. Encoding Data in Errors
We will now discuss how the private information can ac-
tually be encoded into errors. We will concentrate on the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:53:55 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007case of binary errors, i.e., errors that either occur or do not
occur. Of course, one could also use errors with higher en-
tropy. As an extreme example, one could insert a random-
looking word which is a one-time-pad encryption of the user
name or other conﬁdential information. If the referee sends
that word back, decoding is easy. In the binary case, the
situation is more involved.
We will use errors that are either letter-level or word-
level errors (e.g., substituting letters or words by other let-
ters or words), since these seem to be easily detectable.
Furthermore, if the errorneous word has the same length
as the correct one, these errors can be easily implemented
(cf. Section 3). Furthermore, we believe that the errors
should be contained in abstract or introduction, since other
parts might be read with already lessened concentration.
Also, the number of errors should be kept small, and one
should avoid errors that are too extreme (like the above-
mentioned random word), since otherwise the referee might
simply recommend a detailed proof reading instead of list-
ing individual errors.
So in order to encode the username (or whatever informa-
tion we want to transmit), we ﬁrst transform the username
into a natural number. There are different possibilities how
to do this. If the set of potential referees is manageable (e.g.,
a several dozen or even a few hundreds), one might hard-
code the list of referees into the document. Then the user-
name is matched against each referee and the index of the
matching referee is used. Of course, the matching routine
should be smart enough to match variations of the referee’s
full name, such as smith, john, jsmith, johnsmith,
john smith, john.smith. Such a limited referee list
exists in many conferences where the submissions are re-
viewed by the program committee. (If the document hap-
pens to be reviewed by a subreferee, we choose a special
index to indicate failure.) If no such list is available, we
probably will be able to transmit only part of the username,
e.g., the ﬁrst two letters or the initials, from which the au-
thor has to guess the identity of the referee.
When an encoding of the username as a natural number
u ∈ {1, . . . , N } has been ﬁxed, we have to ﬁnd a suitable
code. To encode the username u, this code needs to have N
codewords. Assuming that we have n possible distinguish-
able positions where errors may occur, each codeword has
to have length n. Each bit that is set in the codeword corre-
sponds to an error that will occur in the document. Assume
that we choose to have w errors in our document. Note that
the choice of w is crucial. Too small numbers will make
the encoding more difﬁcult, but too large numbers might
have the result that the referee will not list individual errors
any more. If we ﬁxed a w, this is the Hamming weight of
each codeword, so the code is a constant-weight code. Fi-
nally, we cannot assume that the referee ﬁnds all errors. We
should be able to decode given only some of the errors. Let
n w e
3
24
24
4
5
5
n w e
4
24
24
5
7
7
N
168
1895
N
253
1368
n w e