is around 1700 bytes (this is relatively large spam email size
likely in HTML format). It is possible that some messages
are larger such as image spam and some spam messages are
smaller — many spam messages only contain a few words
then a link to a scam Web site or a messenger contact. For
cases where spam messages are smaller, it is a clear beneﬁt
in bandwidth usage reduction.
Note that the above is somewhat an ideal case, there are
some minor issues at the TCP layer that need to be ﬁxed.
First, from the mail server’s perspective, it may not receive
any TCP ACK messages for its response packets since
the high-bandwidth bot never gets them in the ﬁrst place.
But in reality, the mail server’s initial congestion window
is large enough to hold all the outgoing packets without
receiving any ACK (although it may cause the mail server
to unnecessarily retransmit the response packets). One pos-
sibility is to let the relay bot to ACK mail server’s response
packets directly without burdening the high-bandwidth bot.
Similarly, at the sender side, although the initial congestion
window at the high-bandwidth bot is also typically large
enough to hold all outgoing packets without getting any
ACK. It would again cause unnecessary retransmissions that
waste bandwidth resources. In order to mitigate this issue,
we have two options: 1) let the relay bot relay the ACK
packets from the mail server to the high-bandwidth bot or
2) spoof the ACK packets locally at the high-bandwidth
bot. The second option has the potential problem of not
able to detect packet loss (since we always spoof the ACK
without knowing whether it is received by the mail server),
although this may rarely happen. The ﬁrst option will use
some bandwidth to relay the ACK packets but the size of
ACK packets should be relatively small and it is simpler. We
have successfully implemented the ﬁrst option and veriﬁed
that the emails can be successfully received by mail servers.
Technique 2. Aggressive pipelining.
The SMTP protocol is interactive and I/O bound as each
SMTP session typically involves many round trips limiting
the aggregated throughput. Thus, SMTP has incorporated
the pipeline support as introduced in RFC2920 [15] in 2000
to pipeline the commands to reduce the overall session
time. In the extreme case, one may send all commands in
a single batch to the server. However, as speciﬁed in RFC,
the EHLO, DATA, VRFY, EXPN, TURN, QUIT, and NOOP
commands can only appear as the last command in a group
since their success or failure produces a change of state
that the SMTP client must accommodate. In order to test
the pipelining support in today’s mail server, we pick a set
of popular mail servers (both open source and commercial)
including: sendmail, Java Apache Mail Enterprise Server
(JAMES), Gmail, Hotmail, Yahoo mail, and AOL mail.
Interestingly, only two mail servers, Gmail and AOL mail,
strictly enforce the RFC. All other mail servers allow full
pipelining (sending all commands in a single batch). For
Gmail and AOL mail, we have to wait after the server
processes each ‘critical’ command such as EHLO before we
can issue the next set of commands. Normally we know that
the server has ﬁnished processing a command by observing
its response. However, if RTT is large, spammers will have
to wait for very long before they can move on to the next set
of commands. But based on our experiments on a variety of
mail servers that we tested, the next set of commands will
be accepted as long as the server has ﬁnished processing the
previous ‘critical’ command. This means that it is possible
to aggressively pipeline the commands such that the next set
of commands arrive just after the server ﬁnishes processing
the previous ‘critical’ command. Typically, the processing
time of the ‘critical’ command should be smaller than the
wide area RTT which can be hundreds of milliseconds.
Algorithm 2 and 3 have the pseudo-code that illustrates
different pipelining approaches. In Algorithm 3, when t1 =
t2 = 0, it becomes full pipelining.
Algorithm 2 Normal pipelining
send(“EHLO [hostname]”);
recv and process(response);
send(“MAIL FROM: \r\nRCPT TO:
\r\nDATA\r\n”);
recv and process(response);
send(“[actual data]\r\nQUIT\r\n”);
Algorithm 3 Aggressive pipelining
send(“EHLO [hostname]”);
sleep(t1);
send(“MAIL FROM: \r\nRCPT TO:
\r\nDATA\r\n”);
sleep(t2);
send(“[actual data]\r\nQUIT\r\n”);
Here, since the EHLO command is relatively simple to
process, the processing time is usually very small. However,
for the next set of commands (MAIL FROM to DATA),
there are three commands combined together, which may
take the mail server longer to process. By carefully choosing
delay t1 and t2 in Algorithm 3, one can potentially increase
the throughput for every single connection and possibly the
overall spamming throughput.
150
100
50
)
s
p
b
M
(
t
u
p
h
g
u
o
r
h
T
0
0
Delay = 0ms
Delay = 50ms
Delay = 100ms
5
20
Number of receiving mail servers
10
15
25
Figure 7.
Impact of delays on the spamming throughput
Next, we try to quantitatively study the impact of delay
t1 and t2 on the throughput. We conduct the throughput
experiment on Emulab where 25 pc3000 machines with
1Gbps network interface are used. Each machine has a
single 3GHz core. We pick one machine as the sender and
the rest of the machines as potential receiving mail servers
running the open source mail server JAMES. We spawn a
large number of threads for concurrent connections for each
mail server. Each thread continuously sends emails with a
new TCP connection. As shown in Figure 7, the throughput
increases as the number of mail servers increases, indicating
that the initial bottleneck is at the mail server side. In the
experiment, we choose the delay t1 and t2 to be 0ms,
50ms and 100ms respectively and draw the throughput
curve accordingly. Figure 7 shows that it is difﬁcult to gain
higher throughput when the corresponding delay is large.
Without aggressive pipelining, to achieve high throughput,
spammers may need to pick a large number of concurrent
mail servers (which could be possible). With aggressive
pipelining, one may be able to achieve signiﬁcant through-
put improvement with the same number of mail servers by
reducing the delay t1 and t2. For the case of 100ms and
50ms delay, the throughput improvement is about 1.5X –
2X with the same number of mail servers.
In reality, on the high-bandwidth bot, two of the fol-
lowing can happen: 1. Network bandwidth is the limiting
factor (network bandwidth can be fully utilized). 2. CPU is
the limiting factor (too many concurrent connections may
cause context switches to occur too frequently such that
the bandwidth may not be fully utilized). The throughput
saturates or grows slowly as the number of concurrent
connections increases.
Technique 1 applies to case 1 given that it can reduce
unnecessary messages received at the high-bandwidth bot.
At the high-bandwidth bot, it is likely that the uplink and
the downlink are shared (Ethernet rather than ADSL). If
the network bandwidth is the bottleneck, this technique can
free up additional bandwidth to deliver spam messages.
Technique 2 applies to case 2 as shortening each in-
dividual RTT can help improve the overall throughput.
Intuitively, t1 and t2 have to be at least greater than the
server processing time for the corresponding commands.
To get an idea of this value, we empirically vary t1 and
t2 and target at one Gmail server which does not allow
full pipelining. We perform the measurement on both peak
hours (noon) and off-peak hours (mid-night). We found
that during peak hours, t1 = 400ms and t2 = 800ms are
often large enough to ensure successful email delivery. For
off-peak, t1 = 20ms and t2 = 40ms are large enough.
The difﬁcult question is what delay value for t1 and t2
to pick in practice. Without triangular spamming, since
each bot can only send one or two spam messages (to
avoid being blacklisted), there is no easy way for them
to reuse the learned processing time. One possibility is
to let bots coordinate the learned processing time, but this
can be inefﬁcient. Another possibility, offered by triangular
spamming, is to use the measured processing time from one
or more previous connections.
it
The reason that
it can work under triangular spam-
ming setting is that
is easy to share the measured
processing time information across multiple connections (all
with different spoofed IPs) given all connections happen
on the same physical machine (the high-bandwidth bot).
More speciﬁcally, when triangular spamming starts, we
open multiple connections for each target server. There
are some bots that relay packets back earlier than others.
We can use the RTT values observed from quick bots as
an approximation for the processing time. One potential
problem to consider is that we should avoid making too
many concurrent connections to the same server because
it will likely overload the server and inﬂate the processing
time. So it is a good idea to spread the connections across
multiple mail servers. A simple way to do so is to spread the
connections across multiple IP addresses/machines exposed
by a single mail provider, or sometimes even a single IP
address may also correspond to multiple servers internally.
To study the feasibility of the second technique, we again
use the Planetlab to measure how diverse RTT values can
be, i.e., quick bots vs. slow bots, in a globally distributed
environment simulating a botnet. We use a machine in
a university to act as the original sender, as university
networks are typically well-provisioned. The idea is that
if there are indeed many slow bots, we can use the second
technique to reduce RTT and increase throughput.
Figures 8 through 11 show the RTT distribution for dif-
ferent target mail servers. We can see that for Hotmail and
Gmail servers, the RTT distribution is quite diverse ranging
from 50ms to 300ms. If we assume that we only need a
single connection to compute the approximate processing
time, it can improve the throughput signiﬁcantly.
For the local mail server experiment, we simulate the
scenario where triangular spamming is carried out within
the same ISP or organization as the victim mail server.
In this case, although the direct RTT between our original
sender and the local mail server is only 0.4ms, the RTTs ob-
served are much larger due to triangular routing. However,
the increased stealthiness achieved by triangular spamming
has the cost of affecting throughput due to large RTTs.
Aggressive pipelining could help to improve the throughput
of each individual connection signiﬁcantly.
For the Indian mail server experiment, we simulate the
scenario where spammers are targeting a mail server far
away from the original sender. We can see that the RTT is
clustered at around 200 – 300ms, for 82% of IPs studied,
which is mostly bounded by the RTT between the original
sender and the target mail server. In fact, the smallest RTT is
227ms, indicating that it could be effective to use aggressive
pipelining. But some initial measurement of the processing
time has to be done rather than in parallel (where the
processing time measured from quick bots can be used for
slow bots).
D. Implication on detection
We observe that although the IP address can be spoofed,
some properties exhibited by the original sender may not
be easily imitated. For instance, they may run different
operating system and resulting in different OS ﬁngerprints.
Also, the network delay between the target mail server and
the original sender can be different from the delay between
the target mail server and the spoofed host. If we can probe
the spoofed host in real time to detect deviations in such
properties, we may be able to discover triangular spam-
ming. In this section, we brieﬂy discuss several properties
promising for detection. Detailed detection results will be
shown in §V.
1) Round Trip Time difference: As we have shown in
Figures 8 through 10, RTT can differ widely across relay
bots. However, from the target mail server’s perspective,
it does not know the original sender’s IP address and
can only observe two other RTTs. One is active RTT
between itself and the relay bot by direct probing. The
second is passive RTT observed locally by observing the
delay between sending SYN and receiving SYN-ACK. If
no triangular spamming is involved, the two RTT values
should be comparable.
2 where t′
However, in the presence of triangular spamming, the
passive RTT is calculated as t1 + t2 + t3 where t1 to t3
correspond to the network delays of the three steps shown
in Figure 1. The active probed RTT can be calculated as
t2 + t′
2 is the reverse path network delay of step
2. For simplicity, we assume t′
2 to be roughly the same
as t2 (similarly for t1 and t3 as well) which allows us to
calculate the likelihood of detecting RTT differences. If we
compare the passive RTT with the active RTT, the difference
is (t1 + t2 + t3)−2× t2 = (t1 + t3 − t2). Although triangular
inequality is shown to be invalid sometimes [40], we show
that the chances that t1 + t3 − t2 is close to 0 would still
be small.
To understand how likely we can observe large values for
t1 + t3 − t2, we again conduct experiments on Planetlab.
First, we measure t1 + t2 + t3 as previously described.
Second, we measure 2 × t1 by probing from the original
sender to the target mail server. Last, we measure 2 × t3 by
probing from the original sender to the Planetlab nodes. The
distribution of the value t1 + t3 − t2 is shown in Figures 12
through 15.
1
s
e
s
s
e
r
d
d
a
P
I
f
o
n
o
i
t
c
a
r
F
0.8
0.6
0.4
0.2
1
s
e
s
s
e
r
d
d
a
P
I
f
o
n
o
i
t
c
a
r
F
0.8
0.6
0.4
0.2
0
0   100 200 300 400 500 600 700 800
RTT (ms)
0
0  
100
200
300
RTT (ms)
400
500
600
1
s
e
s
s
e
r
d
d
a
P
I
f
o
n
o
i
t
c
a
r
F
0.8
0.6
0.4
0.2
0
0
1
s
e
s
s
e
r
d
d
a
P
I
f
o
n
o
i
t
c
a
r
F