title:Efficient Private Statistics with Succinct Sketches
author:Luca Melis and
George Danezis and
Emiliano De Cristofaro
Efﬁcient Private Statistics with Succinct Sketches
Luca Melis, George Danezis, and Emiliano De Cristofaro
Department of Computer Science, University College London
{luca.melis.14, g.danezis, e.decristofaro}@ucl.ac.uk
6
1
0
2
n
a
J
6
]
R
C
.
s
c
[
3
v
0
1
1
6
0
.
8
0
5
1
:
v
i
X
r
a
Abstract—Large-scale collection of contextual information is
often essential in order to gather statistics, train machine learning
models, and extract knowledge from data. The ability to do
so in a privacy-preserving way – i.e., without collecting ﬁne-
grained user data – enables a number of additional compu-
tational scenarios that would be hard, or outright impossible,
to realize without strong privacy guarantees. In this paper, we
present the design and implementation of practical techniques
for privately gathering statistics from large data streams. We
build on efﬁcient cryptographic protocols for private aggregation
and on data structures for succinct data representation, namely,
Count-Min Sketch and Count Sketch. These allow us to reduce
the communication and computation complexity incurred by each
data source (e.g., end-users) from linear to logarithmic in the size
of their input, while introducing a parametrized upper-bounded
error that does not compromise the quality of the statistics. We
then show how to use our techniques, efﬁciently, to instantiate
real-world privacy-friendly systems, supporting recommendations
for media streaming services, prediction of user locations, and
computation of median statistics for Tor hidden services.
I.
INTRODUCTION
The increasing amount of contextual information collected
by multitudes of always-on, always-connected devices makes
it increasingly possible to extract value and knowledge from
statistical data. For instance, Google analyzes GPS locations
reported by mobile devices to calculate the speed along a road
and generate live trafﬁc maps (Google Trafﬁc), and search data
to estimate and predict ﬂu activity (Google Flu Trends). Alas,
the large-scale collection of user data raises serious privacy,
conﬁdentiality, and liability concerns. This motivates the need
for efﬁcient and scalable techniques allowing providers to
privately gather statistics, and to use such statistics to train
models and facilitate predictions. Our work is actually inspired
by a few real-world problems:
P1 Online streaming services routinely collect statistics about
videos watched by their users, and provide them with
personalized suggestions, typically, using recommender
systems. In particular, we will focus on recommendations
for BBC’s iPlayer [1], an online platform offering free
streaming of TV programs.
P2 Urban planning committees, as well as mass transport op-
erators, are keen on gathering statistics about movements
and commuting paths, aiming to improve transportation
services and predict future trends, e.g., to respond to
anomalies and disruptions on short notice [57, 60].
P3 The Tor network [28] needs to collect trafﬁc statistics
such as the number of, and trafﬁc generated by, hidden
services, in order to ﬁne tune design decisions and con-
vince their funders of the value of the network [32].
In general, we are interested in scenarios where providers
need to train models based on aggregate statistics gathered
from many data sources, and our goal is to do so without
disclosing ﬁne-grained information about single sources. In
theory, we could turn to existing cryptographic protocols for
privacy-friendly aggregation: using homomorphic encryption
or secret sharing untrusted aggregators can collect encrypted
readings but only decrypt the sum [9, 13, 15, 33, 47, 61].
However, these tools require each data source to perform a
number of cryptographic operations, and transmit a number
of ciphertexts, linear in the size of their input, which makes
them impractical when sources contribute large streams. For
instance, in scenario P1, we need to collect distributions of “co-
views” (i.e., pairs of videos watched by the same user) in order
to perform recommendations based on K-Nearest Neighbor
(KNN) algorithms [25]: even when only hundreds of programs
are available, each user would have to encrypt and transmit a
matrix of hundreds of thousands of values.
Also, differential privacy could be used to let aggregators
add noise to datasets so that other parties may perform
statistical queries while the probability of identifying single
records is minimized [23]. However, differential privacy alone
would not protect the privacy of single data sources w.r.t.
the aggregators themselves. Although recent work such as
RAPPOR [34] supports, via input perturbation, differentially-
private statistics collection with an untrusted aggregator, it
actually requires millions of users in order to obtain reasonably
accurate answers.
Our insight is to combine privacy-preserving aggregation
with data structures supporting succinct data representation,
namely, Count-Min Sketch [22] and Count Sketch [16] (intro-
duced in Section II-B). Private aggregation is performed over
the sketches, rather than the raw inputs. Despite an upper-
bounded error in the aggregate is introduced, this allows us to
reduce communication and computational complexity (for the
cryptographic operations) from linear to logarithmic in the size
of the inputs. We then use the resulting private statistics tools to
instantiate protocols and build systems addressing applications
P1–P3 discussed above, where the error does not affect the
overall quality of the computation.
More precisely,
in Section III, we present a privacy-
preserving recommender system allowing online streaming ser-
vices like BBC’s iPlayer to support recommendations without
tracking their users. Users’ browsers encrypt and transmit a
succinct representation of the co-view matrix (i.e., pairs of
videos they have watched) so that the BBC can only decrypt
the aggregate matrix (i.e., how many users have watched a
given pair). This is broadcast back to the users and used to
derive recommendations. Next, in Section IV, we introduce
an Android application enabling users to report to a service
provider their locations over time, in a privacy-preserving way,
i.e., so that only aggregate statistics are disclosed. We then
show that these can be used to train a model geared to predict
future movements. Finally, in Section V, we build a system for
privately computing statistics of Tor hidden services, aiming
to address the conﬂict between the importance to collect (and
publish) such statistics and the risk of harming the privacy of
individual Tor users. This addresses an open problem raised
by the Tor Project [39]. We show how to estimate median
statistics by collecting an encrypted frequency distribution of
the statistics across all Hidden Services Directories (HSDir).
We also discuss real-world deployment and present full-
blown implementations of our techniques, in JavaScript, An-
droid, and/or Python. Our design makes it extremely easy for
anyone to integrate our techniques – as simple as installing
a package from a public repository. User-side deployment is
transparent too, as client-side code can run in the browser
(in JavaScript), thus requiring no additional software to be
installed or technical understanding of the cryptographic layer.
Our techniques are not limited to one particular model:
on the contrary, we can support different trust, robustness, and
deployment models. Although our three applications all gather
statistics via private sketch aggregation, they do differ in a few
key characteristics. The privacy-friendly recommendation and
location prediction systems (cf. Section III–IV) build atop a
privacy-preserving aggregation scheme where private keys sum
up to zero [47, 61], and use the aggregator itself as a bulletin
board to distribute users’ public keys. We implement them
in JavaScript to support seamless web application deployment
and portability to multiple browsers as well as Android.
On the other hand, our ﬁrst-of-its-kind protocol for median
statistics of Tor hidden services (cf. Section V) uses additively
homomorphic threshold decryption, relying on a set of non-
colluding authorities. It is developed in Python so that it can
be integrated on Tor Hidden Service Directories. We also show
how to integrate differential privacy guarantees by adding noise
to leaked intermediate values during the median estimation
process which does not involve non-linear operations.
Paper organization. The rest of the paper is organized as
follows. Next section introduces relevant background informa-
tion, then, Section III and Section IV present, respectively, a
privacy-preserving recommender system for online broadcast-
ers and an Android-based private location prediction service.
Section V introduces a system for privately computing the me-
dian statistics of Tor hidden services. After reviewing related
work in Section VI, the paper concludes with Section VII.
II. PRELIMINARIES
A. Cryptographic Background
Computational Difﬁe Hellman Assumption. Let G be a
cyclic group of order q (|q| = τ, for security parameter τ), with
generator g. We say that the Computational Difﬁe Hellman
(CDH) problem is hard if, for any probabilistic polynomial-
time algorithm A and random x, y drawn from Zq:
Pr [A(G, q, g, gx, gy) = gxy]
is negligible in the security parameter τ.
Decisional Difﬁe Hellman Assumption. Let G be a cyclic
group of order q (|q| = τ), with generator g. We say that the
2
Decisional Difﬁe Hellman (DDH) problem is hard if, for any
probabilistic polynomial-time algorithm A(cid:48) and random x, y, z
drawn from Zq:
(cid:12)(cid:12)(cid:12) Pr [A(cid:48)(G, q, g, gx, gy, gz) = 1] − Pr [A(cid:48)(G, q, g, gx, gy, gxy) = 1]
(cid:12)(cid:12)(cid:12)
is negligible in the security parameter τ.
Pairwise Independent Hash Functions. Let H be a family of
random-looking hash functions mapping values from a domain
[D] to a range [R]. H is pairwise independent iff ∀x (cid:54)= y ∈ [D]
and ∀a1, a2 ∈ [R]: Prh∈H [h(x) = a1 ∧ h(y) = a2] = 1
R2 .
B. Count-Min Sketch and Count Sketch
Count-Min Sketch [22] is a data structure that can be used to
provide a succinct sublinear-space representation of multi-sets.
An interesting property is that they enable aggregation of the
multi-sets represented by two or more sketches using a linear
operation on the sketches themselves. Prior uses of Count-
Min Sketch include summarizing large amounts of frequency
data for sensing, networking, natural language processing, and
database applications [2].
Deﬁnition 1 (Count-Min Sketch). A Count-Min Sketch with
parameters (, δ) is a two-dimensional array (table) X, with
width w and depth d. Given parameters (, δ), set d = (cid:100)ln T /δ(cid:101)
and w = (cid:100)e/(cid:101), where T is the number of items to be counted.
Each entry of the table is initialized to zero. Then, d hash
functions hj : {0, 1}∗ → {0, 1}w, are chosen uniformly at
random from a pairwise-independent family H.
Update Procedure. To update item i by a quantity ci, ci is
added to one element in each row, where the element in row j
is determined by the hash function hj. The update is denoted
as (i, ci). More precisely, to update the count for item i to
ci ∈ N, for each row j of X, set:
X[j, hj(i)] ← X[j, hj(i)] + ci
Estimation Procedure. To estimate the count ˆci for item i, we
take the minimum of the estimates of ci from every row of X:
ˆci ← min
j
X[j, hj(i)]
Error Upper Bound. Given estimate ˆci, it holds:
1) ci ≤ ˆci
2) ˆci ≤ ci + (cid:80)T
j=1 |cj| with probability 1 − δ.
(where ci is the true counter).
Count Sketch [16] is a data structure which provides an
estimate for an item’s frequency in a stream. Count Sketch has
the same update procedure as Count-Min Sketch, but differs
in the estimation. Speciﬁcally, given the table X built on the
stream, the row estimate of ci (which is the counter of item i)
for row j is computed based on two buckets: X[i, hj(i)] and
X[i, h(cid:48)
j(i)], where h(cid:48)
h(cid:48)
j(i) :=
j(i) is deﬁned as:
(cid:26)hj(i) − 1
(cid:0)X[j, hj(i)] − X[j, h(cid:48)
j(i)](cid:1)
hj(i) + 1
if hj(i) mod 2 = 0
if hj(i) mod 2 = 1
The estimate of ci for row j is then
To estimate the count ˆci for item i, we take the median of the
estimates of ci from every row of X:
(cid:0)X[j, hj(i)] − X[j, h(cid:48)
j(i)](cid:1)
ˆci ← median
j
Both Count-Min and Count Sketch are linear: the element-
wise sum of the sketches representing two multi-sets yields
the sketch of their union.
C. Differential Privacy
Differentially private mechanisms allow a party publishing
a dataset to make sure that only a bounded amount of infor-
mation is leaked. Output perturbation mechanisms modify a
statistic on a dataset D, prior to its release, using a randomized
algorithm A, so that the output of A does not reveal too much
information about any particular row in D.
Deﬁnition 2 (-Differential privacy [30]). A randomized algo-
rithm A satisﬁes -differential privacy, if for any two neighbor
datasets D1 and D2 that differ only in one row, and for any
possible output R of A, it holds:
Pr [A(D1) = R] ≤ e · Pr [A(D2) = R]
Note that  here is used differently than in the Count-
Min Sketch’s deﬁnition. Although this somewhat overloads the
notation for , it is actually clear from the context if it relates
to the data structure or to the differential privacy setting.
Laplace Mechanism. In Section V, we use the differentially
private Laplace mechanism [31], which perturbs the output of
a function F . Given F , the Laplace mechanism transforms F
into a differentially private algorithm, by adding independent
and identically distributed (i.i.d.) noise (denoted as η) into each
output value of F . The noise η is sampled from a Laplace
distribution Lap(λ) with the following probability density
2λ e|x|λ. Dwork [30] proves that the
function: P r[η = x] = 1
Laplace mechanism ensures -differential privacy if λ ≥ S(F )
,
with S(F ) denoting the sensitivity of F , deﬁned as:

S(F ) = max
D1,D2
||F (D1) − F (D2)||1
where || · ||1 denotes the L1 norm, and D1 and D2 are any two
neighbor datasets. Intuitively, S(F ) measures the maximum
possible change in F ’s output when we modify one arbitrary
row in F ’s input.
D. ItemKNN-based Recommender Systems
Recommender systems are used to predict the utility of
a certain item for a particular user, based on their previous
ratings as well as those of other “similar” users [58]. Consider
a set of N users and a list of M items: for each user, a
rating can be associated to each item, based, e.g., on the
user’s explicit opinion about the item (e.g., 1 to 5 stars) or by
implicitly deriving it from purchase records or browser history.
Machine learning can be used to predict the expected rating
of an unrated item for a given user. The K-Nearest Neighbor
(KNN) classiﬁcation algorithm ﬁnds the top-K nearest neigh-
bors for a given item, so that ratings associated with these are
combined to predict unknown ratings. In this paper, we use a
variant called ItemKNN [59]. The algorithm is trained using an
item-to-item similarity matrix (correlation matrix), where each
3