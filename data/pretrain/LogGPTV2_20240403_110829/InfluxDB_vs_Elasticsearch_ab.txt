| Dataset duration(s)  |24h  |
| Total values in dataset  |87,264,000  |6​​/  14
This is only a subset of the entire benchmark suite, but it’s a representative example. At the end of this paper we will discuss other variables and their impacts on performance. If you’re interested in additional details, you can read more about the testing methodology on ​​. 
Test methodology 
Write performanceTo test write performance, we concurrently batch loaded the 24-hour dataset with 16 worker threads. We found that the average throughput of Elasticsearch was 458,728 values per second (using the aggregation template, more details below) . The same dataset loaded into InfluxDB at a rate of 2,800,990 values per second, which corresponds to approximately 6.1x faster ingestion by InfluxDB. (Remember: the concurrency for this test was 16 with 100 hosts reporting.)This write throughput stays relatively consistent across larger datasets (i.e. 48 hours, 72 hours, 96 hours). 
C O N C L U S I O N : 
 7​​/  14
InfluxDB outperformed Elasticsearch by 6.1x when examining 
data ingestion performance. 
Query performanceQuery performance 
To test query performance, we chose a query that aggregates data for a single server over a random 1-hour period of time, grouped into one-minute intervals, potentially representing a single line on a visualization, a common DevOps monitoring and metrics function. Querying an individual time series is common for many IoT use cases as well.To reduce variability, the query times were averaged over 1,000 runs. With 1 worker thread, we found that the mean query response time for Elasticsearch was 8.73ms (114 queries/sec). The same query took an average of 1.07ms (934 queries/sec)  on InfluxDB, demonstrating approximately 8.2x faster query performance than Elasticsearch. 
C O N C L U S I O N : 
|  |  |
|---|---|
|  |8​​/  14 ||  |  |
|---|---|
|  |8​​/  14 |
On-disk storage requirements 
As mentioned above, we chose to utilize Elasticsearch in the recommended configuration for time series data. However, we also wanted to give some insight into how the storage requirements compared against the default Elasticsearch configuration as well.For the same 24-hour dataset outlined above, we looked at the amount of disk space used after writing all values and allowing each database’s native compaction process to finish. We found that the dataset required 449 MB for Elasticsearch with the aggregate schema and 1.9 GB forElasticsearch with the default schema. The same dataset required only 178 MB for InfluxDB, corresponding to 2.5x and 10x better compression by InfluxDB, respectively. This results in approximately 2,15 bytes per value for InfluxDB and 5.39 bytes per value for Elasticsearch (23.4 for the default schema).Largely, the additional storage requirement for Elasticsearch with the default configuration comes from the persistence of the ​_source​ data, which is a byproduct of full-text search features such as highlighting, where the original source document is required. However, even with that data discarded, the Lucene-based DocValues storage format provided by Elasticsearch givessub-optimal compression when compared to InfluxDB for time series workloads. 
 9​​/  14
C O N C L U S I O N : 
InfluxDB outperformed Elasticsearch by delivering 2.5x better 
on-disk compression. 
Testing hardwareAll of the tests performed were conducted on two virtual machines in AWS, running Ubuntu 16.04 LTS. We used the instance type r4.4xlarge (Intel Xeon E5-2686 v4 2.3GHz, 16 vCPU, 122 GB RAM, 1x EBS Provisioned 6000 IOPS SSD 250GB) for a database server and c4.xlarge instance type (Intel Xeon E5-2666v3 2.9GHz, 4 vCPU, 7.5GB RAM) for a client host with the data load and query clients. 
User experience comparisonUser experience comparison 
The user experiences of InfluxDB and Elasticsearch differ in two key ways: syntax and 
convenience, and mental models. Elastic was designed for full-text search while InfluxDB was designed with time series as a first-class citizen. This section of the paper is largely subjective so your mileage may vary. 
Syntax and convenienceSyntax and convenience 
Elasticsearch’s query language is JSON. This can be both good and bad: while it’s immediately readable for most developers, hand-writing queries in JSON might feel awkward. For example, remembering to skip final commas when writing JSON arrays could be frustrating.Additionally, the Elasticsearch HTTP API allows many syntactically-valid JSON requests regardless of the intended semantics. This means that if a mistake is made in an index template declaration (by incorrectly nesting an aggregation clause), the server would readily accept the input. For example, in Elasticsearch 5.6.3 and later, the ​minimum_should_match​ parameter is no longer recognized in certain contexts. However, Elasticsearch would still silently allow it to be included in a query.10​​/  14
InfluxDB’s query language, InfluxQL, provides a relatively concise way to work with time series. For 
example, compare these two logically-equivalent queries:
InfluxDB 
SELECT mean(usage_user) from cpu where time >= 
'2018-01-12T04:29:14-08:00' and time < '2018-01-13T04:29:14-08:00' group by time(1h) 
Elasticsearch 
{ 
	 "size" : 0, 
	 "aggs": { 
	 "result": { 
	 "filter": { 
	 "range": {"filter": { 
	 "range": { 
	 "timestamp": { 
	 "gte": "2018-01-12T04:29:14-08:00", 
	 "lt": "2018-01-13T04:29:14-08:00" 
	 } 
	 } 
	 }, 
	 "aggs": { 
	 "result2": { 
	 "date_histogram": { 
	 "field": "timestamp", 
	 "interval": "1h", 
	 "format": "yyyy-MM-dd-HH" 
	 }, 
	 "aggs": { 
	 "avg_of_field": { 
	 "avg": { 
	 "field": "usage_user" 
	 } 
	 } 
	 } 
	 } 
	 } 
	 } 
	 } 
}
 11​​/  14} 
	 } 
	 } 
	 } 
	 } 
}
 11​​/  14
Queries in Elasticsearch are more verbose, even for relatively simple tasks. 
Another difference between the two databases is type inference. Both databases have fields that are strongly-typed, and that type is inferred from the first value they see for that field.In Elasticsearch, for example, if a user creates a document with field ​foo​ set to ​bar​, it will correctly infer that field foo is a variable-length string field. If another document is then inserted with field foo set, the database will reject any value that is not a string.In Elasticsearch, this type inference can cause unexpected errors. If a document is created with field ​bar​ set to 1, Elasticsearch can’t know what kind of number it is — is it an integer, float, bignum, or some other type? Elasticsearch assumes that numbers without decimal points are integers by default. This can be especially problematic when a value changes from an ambiguous whole number, such as 0, to a nearby floating point value, such as 0.1. In this case, the solution is to always print the decimal point, but it requires more user intervention to avoid this confusion.In contrast, InfluxDB requires values to conform to a small set of types, each with their own syntax: 
Boolean: true, false 
Integer: 0i, 123i 
Float: 0, 0.0, 123.0 
String: “foo” 
Because integers are suffixed with an ​i​, there is no ambiguity when dealing with numerical values, and no type inference problems. All other values are stored natively as 64-bit floating point numbers. 
Mental modelsMental models 
As noted already, Elasticsearch is a full-text search server which also happens to have a datastore that can be used for time series data. On the other hand, InfluxDB is purpose-built to support time series data. 
Elasticsearch’s flexibility comes at a price: any particular use case needs to be modeled to correctly utilize the primitives Elasticsearch provides. 
 12​​/  14For example, while evaluating the differences between Elasticsearch’s default indexing template and the recommended configuration for time series data, it was necessary to know all about the details of how Elasticsearch and Lucene store data on disk. The result was a set of design decisions that took into account how Elasticsearch works, the shape of the data, and the expected queries. This end-to-end thinking is needed when configuring any generalized datastore: using it optimally requires knowing how the internal mechanisms work and requires a much steeper learning curve.InfluxDB requires fewer decisions from the user because it is purpose-built for the time series use case. It makes it easier to think directly in terms of the data, with the concepts of “measurements”, “tags”, and “fields”. 
In conclusion, we highly encourage developers and architects to run these benchmarksthemselves to independently verify the results on their hardware and datasets of choice. However, for those looking for a valid starting point on which technology will give better time series data ingestion, compression and query performance “out-of-the-box”, InfluxDB is the clear winner across all these dimensions, especially when the datasets become larger and the system runs over a longer period of time.About InfluxData 
InfluxData is the creator of InfluxDB, the open source time series database. Our technology is purpose-built to handle the massive volumes of time-stamped data produced by IoT devices, applications, networks, containers and computers. We are on a mission to help developers and organizations, such as Cisco, IBM, PayPal, and Tesla, store and analyze real-time data, empowering them to build transformative monitoring, analytics, and IoT applications quicker and to scale. InfluxData is headquartered in San Francisco with a workforce distributed throughout the U.S. and across Europe.​. 
InfluxDB documentation, downloads & guides 
	13​​/  14
What is time series data? 
Time series data is nothing more than a sequence of values, typically consisting of successive measurements made from the same source over a time interval. Put another way, if you were to plot your values on a graph, one of your axes would always be time.Time series databases are optimized for the collection, storage, retrieval and processing of time series data; nothing more, nothing less. Compare this to document databases optimized for storing JSON documents, search databases optimized for full-text searches or traditional relational databases optimized for the tabular storage of related data in rows and columns. 
What is a time series database?What is a time series database?
​​some of the typical characteristics of a purpose-built time series database. These include: 
●	90+% of the database’s workload is a high volume of high-frequency writes. 
●	Writes are typically appends to existing measurements over time. 
●	These writes are typically done in a sequential order, for example: every second or every 	minute.If a time series database gets constrained for resources, it is typically because it is I/O ●
bound. 
●	Updates to correct or modify individual values already written are rare. 
●	Deleting data is almost always done across large time ranges (days, months or years) 	rarely if ever to a specific point. 
Queries issued to the database are typically sequential per-series, in some form of sort ●order with perhaps a time-based operator or function applied. 
●	Issuing queries that perform concurrent reads or reads of multiple series are common. 
799 Market Street 
San Francisco, CA 94103 
(415) 295-1901 
Twitter: ​
Facebook: ​
	14​​/  14