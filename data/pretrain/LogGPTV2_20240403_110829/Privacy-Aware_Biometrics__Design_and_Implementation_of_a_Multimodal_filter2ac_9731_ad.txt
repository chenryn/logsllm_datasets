best-of-ﬁve for the ﬁngerprint system). Figures 5(A)-(C)
present the frequency distributions for different values of
the match-threshold for the single-trait biometric system
and for our method. Moreover, Receiver Operating Char-
acteristic (ROC) curves are reported in Figure 5(D). The
single iris system showed a Equal Error Rate (EER), (i.e.,
the value of the threshold used in the discriminating proce-
dure at which FMR and FNMR are identical) of 0.9%, while
the ﬁngerprint system and the proposed scheme achieved a
127137
00.20.40.60.810102030(A) Iris System: 9600 bitsMatch scoreFreq.00.20.40.60.8105101520(B) Nist Fingerbit system: 1920 bitsMatch scoreFreq.00.20.40.60.8105101520(C) Proposed SchemeMatch scoreFreq.00.0020.0040.0060.0080.0100.10.2FMRFNMR(D) ROC comparison   Iris system 9600 bitsNIST 1920 bitsProposed schemeEER=0%. As expected for multimodal systems, the scheme
we suggested, while improving the protection of the biomet-
ric inputs, showed a performance which is equivalent to the
one of the single-trait ﬁngerprint system (which is the best
performer in our practical implementation).
By using commercial iris-code segmentation libraries,
we are sure that better absolute rates could be obtained.
Also, larger datasets could be employed to have more re-
alistic estimates of the EER. However, the implementation
of our method was developed mainly to verify the practical
feasibility itself and it fulﬁlls such goal.
6. Conclusions
In this paper, we have proposed a method combining
standard cryptographic techniques and biometrics to pro-
vide an effective and easily deployable identity veriﬁcation
system. The system is privacy-aware since the information
contained in the identiﬁer is not sufﬁcient to recover the bio-
metric traits of the users and further biometric inputs are
required. Any abuse of biometric information is then pre-
vented. With respect to the requirements discussed in Sec-
tion 3, it is easy to see that Requirement 1 was completely
fulﬁlled. The method is multimodal (Requirement 2) need-
ing at least two biometric traits. Moreover, the method is
composed of two basic modules, that can then be combined
to build more complex systems (Requirement 3) and it does
not depend on the particular feature extraction algorithms
selected (Requirement 4).
The method we propose enables the biometric veriﬁca-
tion of persons by using ofﬂine secure documents, in which
neither biometrics traits nor other sensible data are stored in
a central database (Requirement 5). To ensure its validity,
the identiﬁer produced during the enrollment phase could
be signed using the private key of the issuer. Then, at veri-
ﬁcation, the signature on the ID could be veriﬁed using the
issuer’s public key.
Finally, we suggested an actual implementation of our
method based on real biometrics. The implementation
shows the feasibility of the scheme (Requirement 6) and of-
fers an idea of the performances one might obtain from the
application on real datasets. Indeed, the resulting error rate
is acceptable and it is not worse than the best error rate of
the single-trait biometric systems on which it is based. The
work paves the way for large scale applicability of privacy-
aware biometric systems.
7. Acknowledgments
The authors acknowledge helpful conversations with
Sabrina De Capitani di Vimercati while writing the paper.
The research leading to these results has received funding
128138
from the European Community’s Seventh Framework Pro-
gramme (FP7/2007-2013) under grant agreement n 216483.
References
[1] X. Boyen. Reusable cryptographic fuzzy extractors. In Proc.
of the 11th ACM Conference on Computer and Communica-
tion Security (CCS 2004), volume 3027, pages 82–91. ACM,
2004.
[2] X. Boyen, Y. Dodis, J. Katz, R. Ostrovsky, and A. Smith.
Secure remote authentication using biometric data.
In
R. Cramer, editor, Advances in Cryptology (EUROCRYPT
2005), volume 3494 of Lecture Notes in Computer Science.
Springer-Verlag, 2005.
[3] J. Bringer, H. Chabanne, G. Cohen, B. Kindari, and G. Ze-
mor. An application of the goldwasser-micali cryptosys-
tem to biometric authentication. In Proc. of the 12th Aus-
tralasian Conference on Information Security and Privacy
(ACISP’07), volume 4586 of Lecture Notes in Computer Sci-
ence, pages 96–106. Springer-Verlag, 2007.
[4] J. Bringer, H. Chabanne, G. Cohen, B. Kindarji, and
G. Z´emor. Optimal iris fuzzy sketches. The Computing Re-
search Repository, abs/0705.3740, 2007.
[5] Chinese Academy of Sciences. Database of 756 greyscale
eye images; Version 1.0, 2003.
[6] J. G. Daugman. High conﬁdence visual recognition of
IEEE
persons by a test of statistical
Transactions on Pattern Analysis and Machine Intelligence,
15:1148–1161, 1993.
indenpendence.
[7] Y. Dodis, R. Ostrovsky, L. Reyzin, and A. Smith. Fuzzy
extractors: How to generate strong keys from biometrics and
other noisy data. Technical Report 2006/235, Cryptology
Eprint Archive, 2006.
[8] Y. Dodis, L. Reyzin, and A. Smith. Fuzzy extractors: How to
generate strong keys from biometrics and other noisy data.
In C. Cachin and J. Camenisch, editors, Advances in Cryp-
tology (EUROCRYPT 2004), volume 3027 of Lecture Notes
in Computer Science. Springer-Verlag, 2004.
[9] Y. Dodis, L. Reyzin, and A. Smith. Fuzzy extractors.
In
P. Tuyls and J. Goseling, editors, Security with Noisy Data,
chapter 5, pages 93–111. Springer-Verlag, 2007.
[10] Y. Dodis and A. Smith. Correcting errors without leaking
partial information. In Proceedings of the thirty-seventh an-
nual ACM symposium on Theory of computing, pages 654–
663, 2005.
[11] W. J. Gross, F. R. Kschischang, R. Koetter, and P. G. Gu-
lak. Towards a VLSI architecture for interpolation-based
soft-decision Reed-Solomon decoders. The Journal of VLSI
Signal Processing, 39(1-2):93–111, 2005.
[12] V. Guruswami and M. Sudan. Improved decoding of Reed-
IEEE Trans. Inf.
Solomon and algebraic-geometry codes.
Theory, 45(6):1757–1767, 1999.
[13] F. Hao, R. Anderson, and J. Daugman. Combining cryptog-
raphy with biometrics effectively. Technical Report UCAM-
CL-TR-640, University of Cambridge, Computer Labora-
tory, United Kingdom, July 2005.
[14] A. K. Jain, A. Ross, and S. Pankanti. Biometrics: A tool
for information security. IEEE transactions on information
forensics and security, 1(2):125–143, June 2006.
[15] A. Juels and M. Sudan. A fuzzy vault scheme. In A. Lapi-
doth and E. Teletar, editors, Proceedings of the IEEE In-
ternational Symposium on Information Theory, 2002, page
408. IEEE Press, 2002.
[16] A. Juels and M. Wattenberg. A fuzzy commitment scheme.
In Proceedings of the 6th ACM conference on Computer
and communications security (CCS ’99), pages 28–36, New
York, NY, USA, 1999. ACM Press.
[17] P. Karn. Reed-solomon encoding and decoding code, 2002.
[18] R. Koetter and A. Vardy. Algebraic soft-decision decod-
IEEE Trans. Inf. Theory,
ing of Reed-Solomon codes.
49(11):2809–2825, 2003.
[19] A. W.-K. Kong, K. H. Cheung, D. Zhang, M. S. Kamel, and
J. You. An analysis of biohashing and its variants. Pattern
Recognition, 39(7):1359–1368, 2006.
[20] A. Lumini and L. Nanni. An improved biohashing for hu-
man authentication. Pattern Recognition, 40(3):1057–1065,
2007.
[21] D. Maio, D. Maltoni, R. Cappelli, J. L. Wayman, and A. K.
Jain. FVC2000: Fingerprint veriﬁcation competition. IEEE
Transactions on Pattern Analysis and Machine Intelligence,
24(3):402–412, 2002.
[22] L. Masek and P. Kovesi. MATLAB source code for a bio-
metric identiﬁcation system based on iris patterns. The
School of Computer Science and Software Engineering, The
University of Western Australia, 2003.
[23] A. Ross, K. Nandakumar, and A. K. Jain. Handbook
of Multibiometrics (International Series on Biometrics).
Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006.
[24] B. Schneier. Biometrics: uses and abuses. Commun. ACM,
42(8):136, Aug. 1999.
[25] D. Schonberg and D. Kirovski. Eyecerts.
IEEE Trans-
actions on Information Forensics and Security, 1:144–153,
June 2006.
[26] Y. Sutcu, Q. Li, and N. Memon. Protecting biometric tem-
plates with sketch: Theory and practice. IEEE Transaction
on Information Forensics and Security, 2(3), 2007.
[27] U. Uludag, S. Pankanti, S. Prabhakar, and A. Jain. Biometric
In Proceedings of
cryptosystems: Issues and challenges.
the IEEE, Special Issue on Enabling Security Technologies
for Digital Rights Management, volume 92, pages 948–960,
June 2004.
[28] C. I. Watson, M. D. Garris, E. Tabassi, C. L. Wilson, R. M.
McCabe, S. Janet, and K. Ko. User’s Guide to NIST Bio-
metric Image Software (NBIS).
(formerly NISTIR 6813),
2007.
Appendices
A. A short discussion on the ECC code em-
ployed
The selection of the error correcting code needs further
discussion. Given the large inter-subject variability of iris
templates, for which typically e1 > 0.25, the fraction of
errors the code must be able to withstand is larger than in
129139
usual ECC applications. Common ECC code, like BCH,
are capable of correcting a fraction of errors strictly less
than n/4, thus seems ruled out. Others binary codes might
get closer to the Singleton bound but at the price of a small
rate k/n.
In fact, as several authors pointed out [9], the
Plotkin bound from coding theory implies that a binary code
can correct more than n/4 errors only at the expenses of
reducing the number of codeword to about log n.
This is the route we pursued by deriving a binary code
from a Reed-Solomon one;
the latter is Maximum Dis-
tance Separable (MDS) and reaches the Singleton bound.
The concatenation of the shortened Reed-Solomon code
[9600, 1920, 7681]214 and the [14, 1, 1]2 mapping leads on
average to a [14 × 9600, 1920, 7681]2 binary code. The
correction rate is de facto increased only as we can decide
which part of the codeword affect with errors and which
not. And this is different than what happen in actual digital
transmissions.
The idea is made clearer if instead of using a Reed-
Solomon code, we generalize the construction to BCH
codes. The software we employed for computing the iris
code had e1 = 0.4 and injecting errors in a restricted part of
a longer codeword we might manage to use also this fam-
ily of code. For example, let us use for the case at hand a
[32767, 2279, 7679]2 code that can correct up to t = 3839
errors. Performing c⊕I1 on the 9600 upper bit at enrollment
and s⊕ I(cid:48)
1 on the same substring at veriﬁcation does not in-
troduce any further error on the remaining 32767 − 9600
bits. But now having gathered all the possible errors on a
smaller part of the codeword, we also obtained a larger local
correction ratio that is actually about 3839/9600 ≈ 40%, as
desired.
A second issue is that in the scheme described, the de-
coding procedure was successful when the number of dif-
ferent bits between the two iris codes was smaller than the
error correcting capacity of the code. For Reed-Solomon
codes, the classical Berkelekamp-Welch decoder can cor-
rect up to t = (cid:100) n−k
2 (cid:101) errors. But in [12] the authors
showed that it is feasible to list all the codewords at a
Hamming distance t(cid:48) > t (list decoding problem), with
t(cid:48) ≤ (cid:100)n −(cid:112)n(k − 1) − 1(cid:101). Proceeding further in this di-
rection, in [18] the authors managed to exploit the statistical
characteristics of the channel and to solve the list decoding
problem with even larger t(cid:48). While a larger number of errors
corrected by an ECC decoder means more reliable trans-
missions and storage of information, here it implies that
the user biometrics might be uncovered simply exploiting
a more capable decoder. The solution is obvious: either a
code for which list decoding algorithms are not available
should be used, or the Reed-Solomon code should be tuned
on the larger capacity decoder. The latter solution brings
a wider computational burden (even if recent works show
clear progress in reducing the computational time [11]).