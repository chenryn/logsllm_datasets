dummy execution abstraction opaque to the attacker;
(2) Data Flow Linearization (DFL): we transform every secret-
dependent data access (including those performed by dummy
execution) into an oblivious operation that touches all the
locations such program point can possibly reference, leaving
the attacker unable to guess the intended target.
CFL and DFL add a level of indirection around value computations.
The CFL dummy execution abstraction uses it to implicitly nullify
the effects of instructions that presently execute as decoy paths.
DFL instead wraps load and store operations to induce memory
Session 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea717accesses for the program that are secret-invariant, also ensuring
real and decoy paths access the same collections of objects.
Linearizing control and data flows represents a radical design
point with obvious scalability challenges. To address them, Con-
stantine relies on carefully designed optimizations. For control
flows, we rely on a M/o/Vfuscator-inspired indirect memory address-
ing scheme to legalize decoy paths while allowing the optimizer to
see through our construction and generate efficient code. We also
propose just-in-time loop linearization to efficiently support arbi-
trary loops in real-world programs and automatically bound their
execution based on the behavior of the original program (i.e., auto-
matically padding the number of iterations based on the maximum
value observed on real paths).
For data flows, we devise aggressive function cloning to substan-
tially boost the precision of static memory access analysis and min-
imize the extra accesses required by DFL. To further optimize DFL,
we rely on an efficient object metadata management scheme and on
hardware-optimized code sequences (e.g., AVX-512) to efficiently
touch all the necessary memory locations at each secret-dependent
data access. We also exploit synergies between control-flow and
data-flow handling to (i) eliminate the need for shadow accesses
on decoy paths (boosting performance and eradicating problematic
decoy data flows altogether); (ii) handle challenging indirect control
flows such as indirect function calls in real-world programs.
To automatically identify secret-dependent code and data ac-
cesses, we rely on profiling information obtained via dynamic infor-
mation flow tracking and propagate the dependencies along the call
graph. To analyze memory accesses, we consider a state-of-the-art
Andersen-style points-to analysis implementation [68] and show
how aggressive function cloning can greatly boost its precision
thanks to newly added full context sensitivity.
From a security perspective, CFL ensures PC-security for all the
instructions that operate on secret data or whose execution depends
on it; in the process it also replaces variable-latency instructions
with safe software implementations. DFL provides analogous guar-
antees for data: at each secret-dependent load or store operation,
the transformed program obliviously accesses every potentially
referenced location in the execution for that program point and is
no longer susceptible to microarchitectural leaks by design.
Figure 1 provides a high-level view of the CFL, DFL, and support
program analysis components behind Constantine. Our tech-
niques are general and we implement them as analyses and trans-
formation passes for the intermediate representation (IR) of LLVM.
4.2 Control Flow Linearization
With control flow linearization (CFL) we turn secret-dependent con-
trol flows into straight-line regions that meet PC-security require-
ments by construction [50], proposing just-in-time linearization
for looping sequences. We also make provisions for instructions
that may throw an exception because of rogue values along decoy
paths, or yield variable latencies because of operand values.
CFL: The sequence of secret-dependent instructions that the CPU
executes is constant for any initial input (PC-security) and data
values do not affect the latency of each such instruction.
With this invariant, only data access patterns can then influence
execution time, and DFL will make them insensitive to secret in-
put values. We assume that an oracle (the taint analysis of §4.4.1)
enucleates which control-flow transfer decisions depend on secret
data. Such information comprises if-else and loop constructs and
indirect-call targets. For each involved code region, we push the lin-
earization process in a recursive fashion to any nested control flows
(i.e., if-else branches, loops, and function calls), visiting control-flow
graphs (CFGs) and call graph edges in a post-order depth-first fash-
ion. By doing so we avoid leaks from decoy paths when executing
secret-independent inner branches in a protected region.
4.2.1 Dummy Execution. Each linearized region holds a “taken”
predicate instance that determines if the original program would
execute it (real path) or not (decoy path) under the current program
state. We incrementally update the predicate with a new instance
at every control-flow decision that guards the region in the original
program, and let the compiler use the previous incoming instance
upon leaving the region. The predicate backs a dummy execution
indirection abstraction where we let decoy paths execute together
with real paths, and use the taken predicate to prevent that visible
effects from decoy paths may pollute the program state.
The key to correctness is that we can safely allow decoy paths
to make local computations (i.e., assign to virtual registers in the
IR), as long as their values do not flow into memory. For memory
operations, each pointer expression computation selects an artificial
⊥ value when in dummy execution. DFL primitives wrap every load
and store instruction and make both real and decoy paths stride
the same objects thanks to points-to metadata associated with the
memory operation. Upon leaving a region, local values that the
program may use later (i.e. live virtual registers) undergo a selection
step to pick values from real paths at merge points.
The key to efficiency is using a selection primitive that is trans-
parent for the optimizer thanks to indirection. As we observed in
§2, the cmov selector typical of predicated execution constrains the
behavior of the optimizer during code generation. We leverage the
indirection on taken to design selection primitives based on arith-
metic and logic operations that can instead favor optimizations.
Let us consider the pointer assignment ptr = taken ? p : ⊥ of
Figure 1. By modeling taken as an integer being 1 on real paths
and 0 on decoy ones, and by using NULL to represent ⊥ for DFL,
the selection becomes ptr = taken ∗ p. DFL helpers will prevent
NULL accesses and deem them as from decoy paths: those can-
not happen on real paths since, like prior literature [53], we work
on error-free programs. This constant-time multiplication-based
scheme unleashes many arithmetic optimizations (e.g., global value
numbering [56], peephole [7]) at the IR and backend level, bring-
ing a net CFL speedup of 32.9% in wolfSSL over using the cmov
approach. Appendix B details other primitives that we evaluated.
Selection may be needed for (ϕ) compiler temporaries too, as
we will detail in §4.2.3. Unlike memory addresses, both incoming
values may be arbitrary, allowing for more limited optimization:
for them we use the select IR instruction and let LLVM lower it
branchlessly as it sees fit (including an x86 cmov).
Hereafter, we use ct_select to refer to a constant-time selection
of any values, but we inline the logic in the IR in the implementation.
Session 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea718Figure 1: Architecture of Constantine: code analyses, CFL & DFL transformations, and run-time object metadata.
4.2.2 Compiler IR Normalization. Constantine takes as input the
intermediate representation (IR) produced for the program by the
language-specific compiler frontend. We assume that the IR comes
in static single assignment (SSA) form [56] and that the CFG of
every function containing regions to transform is reducible. The
code can come in already-optimized form (e.g., -O2, -O3 settings).
We apply a number of normalization passes that simplify later
transformations with the ultimate goal of having single-entry, single-
exit regions as unit of transformation, similarly to [80].
We use existing LLVM passes to lower switch constructs into
if-else sequences, and to unify multiple function exit points into
a single one (for abort-like sequences that do not fall through, we
add artificial CFG edges to the exit node). As we work on error-free
programs, we replace exception-aware invoke statements with
normal calls. We also turn indirect calls into if-else sequences of
direct calls using points-to information (§4.4.2), guarding each direct
call with a pointer comparison on the target.
We then massage the CFG using standard compiler techniques [7]
so that it results into a graph composed only of single-entry, single-
exit regions: this will hold for all branches and loop constructs in
the IR. This normalized IR is the input for the taint oracle of §4.4.1.
4.2.3 Branch Linearization. We can now detail how branch lin-
earization operates and its orchestration with dummy execution.
Under the single-entry, single-exit structural assumption from IR
normalization, for a conditional construct of the likes if (cond) then
{A} else {B}, we note that its exit CFG node post-dominates both the
“then” and “else” regions of the branch, and is dominated by the
entry node by construction. In SSA form, ϕ-nodes select incoming
path-sensitive values. To linearize a conditional construct we:
(1) remove the conditional branch, unlinking blocks A and B;
(2) replace in A every pointer expression computation with a
conditional assignment ct_select(cond, ptr,⊥);
(3) replace similarly in B, using the condition negated (!cond);
(4) wrap memory accesses with DFL ct_{load, store} primi-
tives, supplying the DFL metadata for the operation (§4.3);
(5) replace each ϕ-node v0 = ϕ(vA, vB) in the exit block (which
assigns virtual register v0 according to whether A or B exe-
cuted) with a conditional assignment ct_select(cond, vA, vB);
(6) merge ⟨entry, A, B, exit⟩ to form a single block, in this order.
We thus “sink” cond to conditionally assign pointers (⊥ for decoy
paths) and virtual registers that outlive the region. Our transforma-
tion preserves the SSA form and can always be applied locally.
We can now add the dummy execution idea to the picture. With-
out loss of generality, let us consider two nested if-else statements
that possibly take part in a larger linearized region as in Figure 2.
if (couter ) {
b1 = v [2]
} else {
if (cinner ) {
b2 = v [0]
} else {
b3 = 0
}
binner = ϕ (b2 ,b3 )
}
b4 = ϕ (b1 ,binner )
v [1] = b4
(a) Original code
t0 = 
t1 = couter && t0
ptr1 = ct_select (t1 , &v [2] , ⊥)
b1 = ct_load ( ptr1 , DFLb1
)
t1−else = !couter && t0
t2 = cinner && t1−else
binner = ct_select (cinner , b2 , b3 )
b4 = ct_select (couter , b1 , binner )
ptr3 = ct_select (t0 , &v [1] , ⊥)
ct_store ( ptr3 , b4 , DFLstore1
)
(b) After linearization
ptr2 = ct_select (t2 , &v [0] , ⊥)
b2 = ct_load ( ptr2 , DFLb2
)
t2−else = !cinner && t1−else // unused
b3 = 0
Figure 2: Linearization and dummy execution.
When reaching the outer if construct, the program sees a taken pred-
icate instance t0 that determines whether the execution reached
the construct as part of a real (taken = true) or decoy computation.
Inside a region, IR instructions that assign virtual registers do not
need to know t0. Path-sensitive assignments of live-out values from
a region, such as binner, check the linearized conditions (cinner in
this case). Memory-related instructions see instead their pointer
expressions conditionally assigned according to some ti taken in-
stance. Those instances are updated upon entering the enclosing
code block in the (original) program to reflect the combination of
control-flow conditions with the incoming taken predicate.
Loop Linearization. To cope with the practical requirements
4.2.4
of real-world code, with Constantine we explore a just-in-time
approach for the linearization of loops. Let us consider the follow-
ing secret-sensitive fragment, taken from a wolfSSL function that
computes x/R == x (mod N) using a Montgomery reduction:
= c + pa ;
_c
tmpm = a -> dp ;
for (x = 0; x < pa +1; x ++)
* tmpm ++ = * _c ++;
for (; x < oldused ; x ++)
// zero any excess digits on
// destination that we didn 't write to
* tmpm ++ = 0;
The induction variable x depends on secret data pa, outlives
the first loop, and dictates the trip count of the second loop. Prior
solutions struggle with each of these aspects, as well as with contin-
ue/break statements we found in wolfSSL. For the secret-dependent
trip count issue, some [80] try to infer a bound and pad the loop
with decoy iterations, then unroll the loop completely. However,
high trip counts seen at run time or inaccurate bound predictions
make unrolling immediately impractical due to code bloat.
In Constantine we design a new approach to handle loops that
avoids unrolling and supports full expressivity for the construct.
secret dataINFORMATION FLOW TRACKINGPOINTS-TO ANALYSISCODE ANALYSESNORMALIZED LLVM IRif (cond)y = ...x = load(p)V = alloc()free(V)sensitive region inﬂuenced byallocation site AS2Control Flow Linearization (CFL)if (cond)taken ⬅ old_taken && condptr = taken ? p : ⊥x = CT_load(ptr, DFLx)y = ...taken ⬅ old_takenIR-LEVEL CODE TRANSFORMATIONSCODE GENERATIONPROGRAM EXECUTIONLLVMLeak-freebinaryglobal g...Fast stridingload/store codepoints-to info for allocation sitesAS2: V = malloc()AS1: global gV1V2V3program maintains run-time information on object instances from allocation site AS2 (dynamic)allocation site AS1Data Flow Linearization (DFL)Session 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea719base :
ibase = 0
body :
icur = ϕ ( base : ibase ,
body : ibody )
[...]
ibody = icur +1
[...]
cond = ... // exit loop ?
br cond , out , body
base :
ibase = 0
body :
icur = ϕ ( base : ibase , body : ibody )
ireal = ϕ ( base : undef , body : iout )
ibody = icur +1
iout = ct_select ( taken , ibody , ireal )
[...]
cond = ... // exit loop ?
cfl_cond = ... // CFL override
br cfl_cond , out , body
out :
x = ibody
out :
x = iout
(a) Original code
(b) After linearization
Figure 3: Linearization with local variables outliving loops.
The key idea is to flank the normal trip count of a loop with an own
CFL induction variable—dubbed c_idx next—and let such variable
dictate just-in-time how many times that loop should execute.
After IR normalization, a loop is a single-entry, single-exit region:
its exit block checks some condition cond for whether the program
should leave the loop or take the back-edge to the loop body. Note
that break/continue statements are just branches to the exit node
and we linearize them as in §4.2.3. Before entering the loop we
set c_idx := 0, and modify the exit block in such a way that the
program still makes the original cond computation, but uses instead
the current c_idx value to decide whether to leave the loop.
wishes to take the back-edge to the body: we allow it;
Say that we expect the program to execute the loop no more
than k times (we address loop profiling in §4.4.1). At every iteration
our exiting decision procedure increments c_idx by 1 and faces:
(1) taken = true∧ cond = false. The program is on a real path and
(2) taken = true∧ cond = true. The program is on a real path and
wishes to exit the loop: if c_idx = k we allow it, otherwise
we enter dummy mode (taken := false) and the program will
perform next k − c_idx dummy iterations for PC-security;
(3) taken = false. We make the program leave the loop when
c_idx = k, and take the back-edge otherwise.
Note that for (3) we do not use the value of cond, as it can go rogue
along decoy paths, but we still read it for the sake of linearization.
Additionally, during (1) we validate the prediction of the oracle:
whenever real program paths wish to iterate more than k times, we
adaptively update k allowing the loop to continue, and use the k′
seen on loop exit as the new bound when the program reaches the
loop again. The handling of this comparison is also linearized.
Nested loops or linearized branches in loop bodies pose no chal-
lenge: we incrementally update the taken predicate and restore it
across regions as we did for nested branches in §4.2.3 and Figure 2.
Let us resume the discussion of the code fragment. As variable x
outlives the first loop, we should prevent decoy paths from updating
it for the sake of correctness. If the compiler places x in memory,
the IR will manipulate it using load and store instructions, and the
dummy execution abstraction guarantees that only real paths can
modify it. If instead it uses a virtual register v for performance, we
flank it with another register v′ conditionally assigned according to
taken, and replace all the uses of v as operand in the remainder of
the CFG with v′. Figure 3 shows this transformation with ibody and
iout: decoy paths keep modifying ibody for the sake of PC-security,
but do not pollute the program state. Thanks to this design, we do
not demote v to memory storage, which could harm performance
especially for tight loops, nor we constrain the optimizer.
4.2.5 Operand Sanitization. As last step, we safeguard computa-
tions that could cause termination leaks from rogue values along
decoy paths. In our design, this may happen only with divisions
instructions receiving zero as divisor value. In §2 we noted that x86
integer division is also subject to variable latencies from operand
values. We address both issues via software emulation, replacing
*div and *rem LLVM instructions with subroutines that execute in
constant-time, and for *div are also insensitive to rogue values.
4.2.6 Code Generation. Our CFL design poses no restrictions on
code optimization as well as code generation operated in the back-
end. The optimizer can transform CFL-generated indirect memory
references by means of optimizations such as common subexpres-
sion elimination and the code generator can lower such references
using the most efficient patterns for the target architecture (includ-
ing cmov instructions on occasion). However, we need to prevent
the code generation process from inadvertently adding branches
in branchless IR-level code. Indeed, this is not uncommon [21, 50]:
luckily, modern compilers offer explicit support to preserve our
constant-time invariants. In more detail, we use LLVM backend
options (e.g., -x86-cmov-converter=0 for branchless lowering on
x86) to control this behavior. As discussed later, we have also exper-
imentally validated Constantine-instrumented binaries preserve
our security invariants by means of a dedicated verifier.
4.3 Data Flow Linearization