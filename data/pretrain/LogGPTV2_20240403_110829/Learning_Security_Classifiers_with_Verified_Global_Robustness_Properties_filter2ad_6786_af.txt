4
4
8
8
8
8
8
8
4
8
8
8
8
4
8
8
4
4
4
4
8
8
8
8
4
8
8
8
8
8
8
8
8
8
8
?
8
8
8
8
8
4
4
4
4
4
8
8
8
8
8
8
8
8
8
8
8
4
4
8
8
8
8
8
8
8
8
8
8
?
8
8
8
8
4
4
8
4
8
8
8
8
8
8
8
8
8
8
8
8
4
8
Redundancy
8
8
8
8
8
8
8
8
8
8
8
8
8
8
8
4
8
4
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
Small
Neighborhood
8
8
8
4
8
8
8
8
8
8
8
?
8
8
8
8
4
4
8
8
8
8
8
8
8
8
8
8
8
4
8
4
Table 8: Results for training Twitter account classier and Twitter spam URL classier with global robustness properties,
compared to baseline models. N/A: property not specied. 4: veried to satisfy the property. 8: veried to not satisfy the
property. ?: unknown.
detection datasets. Monotonic XGB outperforms our Logic Ensem-
ble Monotonic models, but we still have comparable performance.
For example, for the Twitter spam account detection, our Logic
Ensemble Monotonicity model has 3.5% lower true positive rate
(TPR), and 0.5% higher false positive rate (FPR) than the Monotonic
XGB model.
Result 5: Our models have moderate performance drop
to obtain an individual property. For cryptojacking detection,
enforcing each property does not decrease TPR at all, and only
increases FPR by 0.1% compared to the baseline neural network
model (Table 6). For Twitter spam account detection, logic ensemble
models that satisfy one global robustness property decrease the TPR
by at most 3.8%, and increase the FPR by at most 0.9%, compared to
the baseline XGB model (Table 8). For Twitter spam URL detection,
within monotonicity, stability, and small neighborhood properties,
enforcing one property for the classier can maintain high TPR
(from 92.9% to 97.6%) and low FPR (from 2.8% to 5.4%, Table 8). For
example, the Logic Ensemble High Condence model decreases the
TPR by 1.4% and increases the FPR by 3.9%, compared to the baseline
XGB model. This model utilizes the low-cost features to improve the
Session 2C: Defenses for ML Robustness  CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea488prediction accuracy. If we only use high-cost features to train a tree
ensemble with the same capacity (10 rounds of boosting), we can
only achieve 79.9% TPR and 0.96075 AUC. In comparison, our Logic
Ensemble High Condence model has 97.6% TPR and 0.98646 AUC.
Results regarding hyperparameters are discussed in Appendix F.
Result 6: Training a classier with one property some-
times obtains another property. Table 6 shows that all crypto-
jacking Logic Ensemble classiers that were enforced with only one
property, have obtained at least one other property. For example, the
Logic Ensemble Stability model has obtained small neighborhood
property, and vice versa. Since we specify all features to be stable
for this dataset, the stability property is equivalent to the global Lip-
schitz property under L0 distance. On the other hand, we dene the
small neighborhood property with a new distance. This shows that
enforcing robustness for one property can generalize the robustness
to a dierent property. More results are discussed in Appendix G.
Result 7: We can train classiers to satisfy multiple global
robustness properties at the same time. We train a cryptojack-
ing classier with four properties, and a Twitter spam account clas-
sier with ve properties. For cryptojacking detection, the Logic
Ensemble Combined model maintains the same high TPR, and only
increases the FPR by 3% compared to the baseline neural network
model (Table 6). For Twitter spam account detection, the Logic En-
semble Combined model that satises all properties only decreases
the TPR by 5.4% and increases the FPR by 0.1%, compared to the
baseline XGB model with no property (Table 8). More results are
discussed in Appendix H.
7 RELATED WORK
Program Synthesis. Solar-Lezama et al. [80] proposed counterex-
ample guided inductive synthesis (CEGIS) to synthesize nite pro-
grams according to specications of desired functionalities. The key
idea is to iteratively generate a proposal of the program and check
the correctness of the program, where the checker should be able
to generate counterexamples of correctness to guide the program
generation process. The general idea of CEGIS has also been used to
learn recursive logic programs (e.g., as static analysis rules) [2, 15,
69, 75]. We design our xer following the general form of CEGIS.
Local Robustness. Many techniques have been proposed to ver-
ify local robustness (e.g., `p robustness) of neural networks, in-
cluding customized solvers [34, 38, 39, 83] and bound propaga-
tion based verication methods [6, 8, 53, 63, 64, 71, 74, 76–78, 86–
88, 90, 92, 94, 98]. Bound propagation veriers can also be ap-
plied in robust optimization to train the models with certied lo-
cal robustness [9, 11, 54, 62, 85, 93, 97, 99]. Randomized smooth-
ing [14, 36, 45, 52, 73, 95] is another technique to provide probabilis-
tic local robustness guarantee. Several methods have been proposed
to utilize the local Lipshitz constant of neural networks for veri-
cation [33, 90, 91], and constrain or use the local Lipshitz bounds
to train robust networks [4, 12, 13, 22, 24, 30, 49, 65, 68, 79, 81].
Global Robustness. Fischer et al. [25] and Melacci et al. [60] pro-
posed global robustness properties for image classiers using uni-
versally quantied statements. Both of their techniques smooth the
logic expression of the property into a dierentiable loss function,
and then use PGD attacks [42] to minimize the loss. They can train
neural networks to obtain local robustness, but cannot obtain veri-
ed global robustness. ART [56] proposed an abstraction renement
strategy to train provably correct neural networks. The model satis-
es global robustness properties when the correctness loss reaches
zero. However, in practice their correctness loss did not converge
to zero. Leino et al. [50] proposed to minimize global Lipschitz con-
stant to train globally-robust neural networks, but they can only
verify one global property that abstains on non-robust predictions.
Monotonic Classiers. Many methods have been proposed to
train monotonic classiers [5, 7, 16, 17, 23, 32, 35, 40, 89]. Recently,
Wehenkel et al. [89] proposed unconstrained monotonic neural net-
works, based on the key idea that a function is monotonic as long as
its derivative is nonnegative. This has increased the performance of
monotonic neural network signicantly compared to enforcing non-
negative weights. Incer et al. [35] used monotone constraints from
XGBoost to train monotonic malware classiers. XGBoost enforces
monotone constraints for the left child weight to be always smaller
(or greater) than the right child, which is a specialized method and
does not generalize to other global robustness properties.
Discrete Classier and Smoothing. Friedman et al. [27] pro-
posed rule ensemble, where the each rule is a path in the decision
tree, and they used regression to learn how to combine rules. Our
logic ensemble is more general such that the clauses do not have to
form a tree structure. We only take rules from trees as the starting
classier to x the properties. Kantchelian et al. [37] proposed the
mixed integer linear program attack to evade tree ensembles by per-
turbing a concrete input. In comparison, our integer linear program
verier has only integer variables, and represents all inputs symbol-
ically. Continuous Logic Networks was proposed to smooth SMT
formulas to learn loop invariants [72, 96]. In this paper, we apply
the smoothing techniques to train machine learning classiers.
8 CONCLUSION
In this paper, we have presented a novel booster-xer training
framework to enforce new global robustness properties for security
classiers. We have formally dened six global robustness proper-
ties, of which ve are new. Our training technique is general, and
can handle a large class of properties. We have used experiments
to show that we can train dierent security classiers to satisfy
multiple global robustness properties at the same time.
9 ACKNOWLEDGEMENTS
We thank the anonymous reviewers for their constructive and valu-
able feedback. This work is supported in part by NSF grants CNS-
18-50725, CCF-21-24225; generous gifts from Open Philanthropy,
two Google Faculty Fellowships, Berkeley Articial Intelligence Re-
search (BAIR), a Capital One Research Grant, a J.P. Morgan Faculty
Award; and Institute of Information & communications Technology
Planning & Evaluation (IITP) grant funded by the Korea govern-
ment(MSIT) (No.2020-0-00153). Any opinions, ndings, conclusions,
or recommendations expressed herein are those of the authors, and
do not necessarily reect those of the US Government, NSF, Google,
Capital One, J.P. Morgan, or the Korea government.
REFERENCES
[1] [n.d.]. Gurobi Optimization. https://www.gurobi.com/.
Session 2C: Defenses for ML Robustness  CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea489[2] Aws Albarghouthi, Paraschos Koutris, Mayur Naik, and Calvin Smith. 2017.
Constraint-based synthesis of Datalog programs. In International Conference
on Principles and Practice of Constraint Programming. Springer, 689–706.
[3] Kevin Allix, Tegawendé F Bissyandé, Jacques Klein, and Yves Le Traon. 2015. Are
your training datasets yet relevant?. In International Symposium on Engineering
Secure Software and Systems. Springer, 51–67.
[4] Cem Anil, James Lucas, and Roger Grosse. 2019. Sorting out Lipschitz function
approximation. In International Conference on Machine Learning. PMLR, 291–301.
[5] Norman P Archer and Shouhong Wang. 1993. Application of the back
propagation neural network algorithm with monotonicity constraints for
two-group classication problems. Decision Sciences 24, 1 (1993), 60–75.
[6] Mislav Balunović, Maximilian Baader, Gagandeep Singh, Timon Gehr, and
Martin Vechev. 2019. Certifying geometric robustness of neural networks.
Advances in Neural Information Processing Systems (NeurIPS) (2019).
[7] Arie Ben-David. 1995. Monotonicity maintenance in information-theoretic
machine learning algorithms. Machine Learning 19, 1 (1995), 29–43.
[8] Akhilan Boopathy, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, and Luca Daniel. 2019.
Cnn-cert: An ecient framework for certifying robustness of convolutional
neural networks. In AAAI Conference on Articial Intelligence (AAAI).
[9] Akhilan Boopathy, Tsui-Wei Weng, Sijia Liu, Pin-Yu Chen, Gaoyuan Zhang,
and Luca Daniel. 2021. Fast Training of Provably Robust Neural Networks by
SingleProp. AAAI Conference on Articial Intelligence (AAAI) (2021).
[10] Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system.
In Proceedings of the 22nd acm sigkdd international conference on knowledge
discovery and data mining. ACM, 785–794.
[11] Yizheng Chen, Shiqi Wang, Dongdong She, and Suman Jana. 2020. On Training
Robust PDF Malware Classiers. In USENIX Security Symposium.
[12] Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas
Usunier. 2017. Parseval networks: Improving robustness to adversarial examples.
In International Conference on Machine Learning. PMLR, 854–863.
[13] Jeremy EJ Cohen, Todd Huster, and Ra Cohen. 2019. Universal lipschitz approxi-
mation in bounded depth neural networks. arXiv preprint arXiv:1904.04861 (2019).
[14] Jeremy M Cohen, Elan Rosenfeld, and J Zico Kolter. 2019. Certied adversarial
International Conference on Machine
robustness via randomized smoothing.
Learning (2019).
[15] Andrew Cropper, Sebastijan Dumančić, and Stephen H Muggleton. 2020. Turning
30: New ideas in inductive logic programming. In International Joint Conferences
on Artical Intelligence (IJCAI).
[16] Hennie Daniels and Marina Velikova. 2010. Monotone and partially monotone