title:Trusted Display on Untrusted Commodity Platforms
author:Miao Yu and
Virgil D. Gligor and
Zongwei Zhou
Trusted Display on Untrusted Commodity Platforms
Miao Yu
ECE Department and CyLab
Carnegie Mellon University
PI:EMAIL
Virgil D. Gligor
ECE Department and CyLab
Carnegie Mellon University
PI:EMAIL
Zongwei Zhou
∗
ECE Department and CyLab
Carnegie Mellon University
PI:EMAIL
ABSTRACT
A trusted display service assures the conﬁdentiality and au-
thenticity of content output by a security-sensitive applica-
tion and thus prevents a compromised commodity operating
system or application from surreptitiously reading or mod-
ifying the displayed output. Past approaches have failed
to provide trusted display on commodity platforms that use
modern graphics processing units (GPUs). For example, full
GPU virtualization encourages the sharing of GPU address
space with multiple virtual machines without providing ade-
quate hardware protection mechanisms; e.g., address-space
separation and instruction execution control. This paper
proposes a new trusted display service that has a minimal
trusted code base and maintains full compatibility with com-
modity computing platforms. The service relies on a GPU
separation kernel that (1) deﬁnes diﬀerent types of GPU
objects, (2) mediates access to security-sensitive objects,
and (3) emulates object whenever required by commodity-
platform compatibility. The separation kernel employs a
new address-space separation mechanism that avoids the
challenging problem of GPU instruction veriﬁcation with-
out adequate hardware support. The implementation of the
trusted-display service has a code base that is two orders of
magnitude smaller than other similar services, such as those
based on full GPU virtualization. Performance measure-
ments show that the trusted-display overhead added over
and above that of the underlying trusted system is fairly
modest.
Categories and Subject Descriptors
D.4.6 [OPERATING SYSTEMS]: Security and Protec-
tion—Security kernels
∗Current aﬃliation: VMware Inc, 3401 Hillview Ave, Palo
Alto, CA 94304.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813719.
Keywords
GPU separation kernel; Trusted display
1.
INTRODUCTION
A trusted display service provides a protected channel
that assures the conﬁdentiality and authenticity of content
output on selected screen areas. With it users can rely
on the information output by a security-sensitive applica-
tion (SecApp) without worrying about undetectable screen
“scrapping” or “painting” by malicious software on commod-
ity systems; i.e., the display output is surreptitiously read
or modiﬁed by a compromised commodity operating systems
(OSes) or applications (Apps).
Security architectures that isolate entire SecApps from un-
trusted commodity OSes and Applications (Apps) [35] im-
plement trusted display functions via trusted path [55, 56].
That is, a user’s explicit activation of the trusted-path ef-
fectively removes all untrusted OS and Apps access to the
display device and assigns the device to a SecApp for the
entire duration of a session. Unfortunately, the exclusive
use of display devices via trusted path does not allow both
untrusted OS/Apps and SecApps to output content concur-
rently on a user’s screen; i.e., untrusted output cannot be
displayed until after the trusted path releases the screen at
the end of the SecApp session. As a consequence, it would
not be possible to maintain the typical multi-window user
experience for applications that comprise both trusted and
untrusted components and use the same display screen.
Problem. Some past approaches that allow trusted dis-
play of output with diﬀerent sensitivity on the same screen
concurrently have been based on encapsulating and protect-
ing graphics cards within high-assurance security kernels [14,
42, 17]. In addition to requiring changes of commodity OSes,
adopting such an approach for the entire graphics processing
unit (GPU) would not work since the complexity of modern
GPU functionality1 would rule out maintaining a small and
simple code base for the security kernel, which is a prerequi-
site for high assurance. For example, the size of Intel’s GPU
driver for Linux 3.2.0 - 36.57 has over 57K SLoC, which is
more than twice the size of a typical security kernel [54]. Fur-
thermore, GPU functions operate asynchronously from the
CPUs [46, 53] to improve graphics performance and intro-
duce concurrency control for multi-threading in the trusted
1Modern GPUs include graphics/computation accelera-
tors [39, 16]. They are equipped with hundreds of proces-
sors [32] to provide complex functions of 2D/3D hardware
rendering, general-purpose computing on GPU (GPGPU),
and hardware video encoding/decoding.
989code base. This would invalidate all correctness proofs that
assume single-thread operation [27, 47].
Full GPU virtualization [46, 45] can be used to enable con-
current display of both trusted and untrusted output on a
user’s screen without requiring commodity OSes/Apps mod-
iﬁcation. However, full GPU virtualization, which is largely
motivated by improved performance, relies on address-space
sharing between diﬀerent virtual machines (VMs) and the
GPU without providing adequate hardware mechanisms for
protecting diﬀerent VMs’ code and data within the GPU;
e.g., address-space separation and instruction execution con-
trol. As a concrete example, we illustrate a class of new
attacks that exploit the inadequacy of address-space separa-
tion on fully virtualized GPUs; viz., Section 2.2. Moreover,
full GPU virtualization intrinsically requires a large trusted
code base; e.g.
supporting native GPU drivers/Apps re-
quires emulating all accesses to all GPU conﬁguration regis-
ters for the VMs scheduled to access the GPU. Thus, adopt-
ing full GPU virtualization for high-assurance trusted dis-
play would be impractical.
Solution. The trusted display design presented in this
paper satisﬁes the following four requirements.
• it allows the conﬁdentiality and authenticity of dis-
play contents to be assured to whatever degree of rigor
deemed necessary by minimizing and simplifying the
trusted-display code base.
• it avoids redesign and modiﬁcation of underlying trusted-
system components, and preserves their correctness
properties; e.g., proofs of high-assurance micro-kernels
and micro-hypervisors [27, 47].
• it preserves full compatibility with commodity plat-
forms; i.e., it does not require any modiﬁcation of com-
modity OS/Apps code and GPU hardware or reduce
their functionality.
• it maintains a typical user’s perception and use of ap-
plication output and relies on easily identiﬁable screen
geometry; e.g., it uses diﬀerent windows for trusted
and untrusted screen areas.
The central component of our trusted display design is a
GPU Separation Kernel (GSK) that (1) distinguishes diﬀer-
ent types of GPU objects, (2) mediates access to security-
sensitive objects, and (3) emulates object access whenever
required by commodity-platform compatibility. The GSK
employs a new address-space separation mechanism that
avoids the challenging problem of GPU instructions veriﬁ-
cation without adequate hardware support. The implemen-
tation of the trusted display service has a code base that is
two orders of magnitude smaller than other similar services,
such as those based on full GPU virtualization.
Outline.
In Section 2, we provide a brief overview of
GPU functions to enable the reader understand the vul-
nerabilities of GPU virtualization to adversary attacks, and
challenges of trusted display on commodity platforms.
In
Section 3, we deﬁne the adversary threats, security secu-
rity properties that counter them, and an informal security
model that satisﬁes these properties. In Section 4, we de-
scribe the detailed design and implementation of the trusted
display system, and in Section 5, we evaluate our implemen-
tation. The related work in this area is presented in Section
6, common use of trusted display is brieﬂy discussed in Sec-
tion 7, and conclusions are provided in Section 8.
Figure 1: Overview of a modern GPU architecture.
2. COMMODITY GPU ARCHITECTURE
AND SECURITY VULNERABILITIES
In this section, we present an overview of common archi-
tecture features of modern GPUs to enable an unfamiliar
reader understand their vulnerability to attacks. The GPU
architecture described herein is common to widely avail-
able commodity devices from vendors such as Intel [23, 2],
AMD [6], Nvidia [4], and ARM [3, 10].
2.1 GPU Architecture Overview
CPU programs (e.g. GPU drivers and Apps) control GPU
execution via four types of objects, namely data, page tables,
commands, and instructions that are stored in GPU mem-
ory, and GPU conﬁguration registers; viz., Figure 1.
CPU programs produce the instructions and commands
that are executed by GPU hardware. For example, instruc-
tions are executed on GPU processor cores, process input
data, and produce results that are used by display engines.
In contrast, commands are executed by dedicated command
processors and are used to conﬁgure the GPU with correct
parameters; e.g., specify stack base address used by instruc-
tions. Groups of commands are submitted for processing
in dedicated command buﬀers; e.g., they are received in in-
put (ring) buﬀers from drivers and (batch) buﬀers from both
applications and drivers.
As shown in Figure 1, a GPU also contains several en-
gines [46, 23, 7], such as the processing engine and display
engine. The processing engine executes instructions on mul-
tiple GPU cores for computation acceleration. It references
memory regions known as the GPU local address space via
the GPU local page tables. The display engine parses screen
pixel data stored in frame buﬀers according to the engine’s
conﬁgurations, and outputs images for display. Other en-
gines perform a variety of functions such as device-wide per-
formance monitoring and power management.
The display engine deﬁnes several basic conﬁgurations for
frame buﬀer presentation; e.g. geometry and pixel formats.
Furthermore, it provides the data paths from frame buﬀers
to external monitors. For example, the screen output may
comprise a combination of multiple screen layers, each of
GPU Configuration Registers Commands Instructions Local Page Tables Global Page Table Display Engine Graphic Output Processing Engine Legend: Objects  GPU Access CPU CPU Access Programs (e.g., GPU drivers, Apps) Data Other  Engines GPU Address Spaces 990which contains a separate frame buﬀer. In this case, GPUs
support a hardware cursor as the front layer of the screen and
display it over the primary image. Since a single GPU may
be connected to multiple screen monitors, a monitor may
consume the same frame buﬀers as another monitor, which
implies that GPU memory protection requires a controlled-
sharing mechanism. Furthermore, an image presented on
a screen may be torn as the result of frame-buﬀer updates
by CPU programs during screen refreshing. To address this
synchronization problem, display engines of modern GPUs
also provides a V-Sync interrupt to notify CPU programs of
the time when it is safe to update a frame buﬀer [49].
Although the GPU architecture illustrated in Figure 1 is
common to many commodity GPUs, some of these GPUs
diﬀer in how memory is accessed and managed. For ex-
ample, Intel’s GPUs use a global page table (GGTT) for
memory access in addition to local page tables. The GGTT
maps the memory region referred as the GPU global address
space, which includes frame buﬀers, command buﬀers, and
GPU memory aperture, which is shared between CPU and
GPU. In contrast, AMD and Nvidia GPUs do not have a
GGTT and allow direct access to GPU physical memory
address space2. This implies that GPU memory access may
also diﬀer in diﬀerent GPUs; e.g., the processing engine of
Nvidia’s GPU can access only the local address space [45,
26], whereas the Intel and AMD’s3 can also access the global
address space [23, 6, 2].
2.2 Address Space Separation Attacks
A fully virtualized GPU shares its global address space
with multiple virtual machines (VMs) to support concurrent
accesses to its memory [46]. For example, while the GPU’s
display engine fetches a VM’s frame buﬀer to display its
content, the GPU’s processing engine generates content for
other VMs’ frame buﬀers. Furthermore, the hardware design
of the GPU’s processing engines (e.g. Intel, AMD) allows
instructions to access the global address space. Because full
GPU virtualization supports native drivers, any malicious
VMs can submit GPU instructions that access another VM’s
GPU data for screen output.
Figure 2(a) illustrates this simple attack. Here, a mali-
cious VM2 submits valid GPU instructions that ostensibly
address GPU memory inside VM2’s address space but in fact
access victim VM1’s GPU memory. For example, VM2 can
submit malicious instructions that contain large address oﬀ-
sets which fall into VM1’s GPU address space4. Unless an
additional “base-and-bound” mechanism for address space
protection is supported by GPU address translation, the
GPU’s processing engine would allow the malicious VM2
to access victim VM1’s GPU output data thereby violating
conﬁdentiality and authenticity.
We note that some fully virtualized GPUs support a single
“base-and-bound” pair of registers for address space protec-
tion; e.g., Intel GPUs limit memory access range of GPU
2To simplify presentation, we consider that these GPUs use
a GGTTs with ﬂat mappings (e.g. virtual addresses are
identical with physical addresses) even though the GGTT
does not exist in these GPUs.
3Although this feature is undocumented by AMD’s GPUs,
it is supported in the open source GPU driver provided by
AMD [6].
4Other full GPU virtualization approaches [45] are also sub-
ject to such attacks.
(a) Simple
(b) General
Figure 2: GPU address-space separation attacks.
instructions by correct setting of the “base-and-bound” reg-
ister pair for GPU command execution [23]. These GPUs
can mediate memory accesses and deny address-space vio-
lations by GPU instructions and commands issued by mali-
cious VMs [46].
Unfortunately, a single pair of base and bound registers is
insuﬃcient to counter all address-space separation attacks
mounted by malicious VMs. These attacks are enabled by
another important performance optimization of full GPU
virtualization. That is, address space “ballooning” [46] al-
lows the GPU to directly access virtual memory at addresses
provided by guest VMs. This optimization improves GPU
memory-access performance and greatly reduces complexity
of GPU programming. Without it, trusted code would have
to translate the referenced GPU virtual addresses for every
object, and even recompile GPU instructions on the ﬂy. For
example, AMD’s GPU instructions perform register-indirect
memory accesses, and hence would require such recompila-
tion for address translation.
However, address space ballooning allows the GPU mem-
ory of a guest VM to be mapped into two or more non-
contiguous blocks in GPU global address space; e.g., one in