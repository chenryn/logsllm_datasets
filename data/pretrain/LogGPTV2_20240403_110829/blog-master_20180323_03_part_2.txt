                     Output: skip.id    
                     Buffers: shared hit=11    
                     CTE skip    
                       ->  Recursive Union  (cost=0.46..51.29 rows=101 width=4) (actual time=0.050..0.099 rows=3 loops=1)    
                             Buffers: shared hit=11    
                             ->  Result  (cost=0.46..0.47 rows=1 width=4) (actual time=0.049..0.049 rows=1 loops=1)    
                                   Output: $1    
                                   Buffers: shared hit=4    
                                   InitPlan 3 (returns $1)    
                                     ->  Limit  (cost=0.43..0.46 rows=1 width=4) (actual time=0.045..0.046 rows=1 loops=1)    
                                           Output: t_3.id    
                                           Buffers: shared hit=4    
                                           ->  Index Only Scan using idx_t on public.t t_3  (cost=0.43..205165.21 rows=10000033 width=4) (actual time=0.045..0.045 rows=1 loops=1)    
                                                 Output: t_3.id    
                                                 Index Cond: (t_3.id IS NOT NULL)    
                                                 Heap Fetches: 0    
                                                 Buffers: shared hit=4    
                             ->  WorkTable Scan on skip s  (cost=0.00..4.88 rows=10 width=4) (actual time=0.015..0.015 rows=1 loops=3)    
                                   Output: (SubPlan 2)    
                                   Filter: (s.id IS NOT NULL)    
                                   Rows Removed by Filter: 0    
                                   Buffers: shared hit=7    
                                   SubPlan 2    
                                     ->  Result  (cost=0.46..0.47 rows=1 width=4) (actual time=0.018..0.019 rows=1 loops=2)    
                                           Output: $3    
                                           Buffers: shared hit=7    
                                           InitPlan 1 (returns $3)    
                                             ->  Limit  (cost=0.43..0.46 rows=1 width=4) (actual time=0.018..0.018 rows=0 loops=2)    
                                                   Output: t_2.id    
                                                   Buffers: shared hit=7    
                                                   ->  Index Only Scan using idx_t on public.t t_2  (cost=0.43..76722.42 rows=3333344 width=4) (actual time=0.017..0.017 rows=0 loops=2)    
                                                         Output: t_2.id    
                                                         Index Cond: ((t_2.id > s.id) AND (t_2.id IS NOT NULL))    
                                                         Heap Fetches: 0    
                                                         Buffers: shared hit=7    
         ->  Index Only Scan using idx_t on public.t  (cost=0.43..1.56 rows=1 width=8) (actual time=0.005..0.005 rows=0 loops=3)    
               Output: t.id, t.c1    
               Index Cond: ((t.id = skip.id) AND (t.c1 = 1))    
               Heap Fetches: 0    
               Buffers: shared hit=7    
   ->  Index Only Scan using idx_t on public.t t_1  (cost=0.43..1.56 rows=1 width=8) (actual time=0.010..0.010 rows=0 loops=1)    
         Output: t_1.id, t_1.c1    
         Index Cond: ((t_1.id IS NULL) AND (t_1.c1 = 1))    
         Heap Fetches: 0    
         Buffers: shared hit=3    
 Execution time: 0.256 ms    
(56 rows)    
```    
从150多毫秒，降低到了0.256毫秒    
## 数据结构设计优化  
因为通常来说这种数据在关系上来说，我们可以使用外键把这个驱动列剥离出来。     
例如驱动列为分组ID，我们再设计一个以分组ID为PK的表。     
```  
create table tbl_grp (  
  id int primary key,   
  info text,  
  crt_time timestamp  
);  
create table tbl_feedlog (  
  id int8 primary key,  
  gid int references tbl_grp(id),  
  c1 int,  
  info text,  
  crt_time timestamp  
);  
```  
创建了一个复合索引，驱动列为GID  
```  
create index idx_tbl_feedlog_1 on tbl_feedlog (gid,c1);  
```  
非驱动列查询c1，用前面的方法，我们需要写CTE，很长。  
现在有了foreign table，我们可以直接用它，遍历驱动列。  
```  
select * from tbl_feedlog where c1=100 and gid=any(array(select id from tbl_grp))  
union all  
select * from tbl_feedlog where c1=100 and gid is null;  
```  
```  
postgres=# explain select * from tbl_feedlog where c1=100 and gid=any(array(select id from tbl_grp))  
union all  
select * from tbl_feedlog where c1=100 and gid is null;  
                                                QUERY PLAN                                                  
----------------------------------------------------------------------------------------------------------  
 Append  (cost=28.63..34.69 rows=2 width=56)  
   ->  Index Scan using idx_tbl_feedlog_1 on tbl_feedlog  (cost=28.63..32.30 rows=1 width=56)  
         Index Cond: ((gid = ANY ($0)) AND (c1 = 100))  
         InitPlan 1 (returns $0)  
           ->  Bitmap Heap Scan on tbl_grp  (cost=7.18..28.48 rows=1130 width=4)  
                 ->  Bitmap Index Scan on tbl_grp_pkey  (cost=0.00..6.90 rows=1130 width=0)  
   ->  Index Scan using idx_tbl_feedlog_1 on tbl_feedlog tbl_feedlog_1  (cost=0.15..2.37 rows=1 width=56)  
         Index Cond: ((gid IS NULL) AND (c1 = 100))  
(8 rows)  
```  
性能验证，完美：  
```  
postgres=# insert into tbl_grp select generate_series(0,999);  
INSERT 0 1000  
postgres=# insert into tbl_feedlog select id, random()*999, id, 'test', now() from generate_series(1,10000000) t(id);  
postgres=# insert into tbl_feedlog select id, null, id, 'test', now() from generate_series(10000001,10100000) t(id);  
```  
4毫秒 vs 200毫秒  
```  
优化方法  
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from tbl_feedlog where c1=100 and gid=any(array(select id from tbl_grp))  
union all  
select * from tbl_feedlog where c1=100 and gid is null;  
                                                                        QUERY PLAN                                                                           
-----------------------------------------------------------------------------------------------------------------------------------------------------------  
 Append  (cost=26.31..45.11 rows=2 width=29) (actual time=2.239..3.767 rows=1 loops=1)  
   Buffers: shared hit=3035  
   ->  Index Scan using idx_tbl_feedlog_1 on public.tbl_feedlog  (cost=26.31..42.44 rows=1 width=29) (actual time=2.239..3.760 rows=1 loops=1)  
         Output: tbl_feedlog.id, tbl_feedlog.gid, tbl_feedlog.c1, tbl_feedlog.info, tbl_feedlog.crt_time  
         Index Cond: ((tbl_feedlog.gid = ANY ($0)) AND (tbl_feedlog.c1 = 100))  
         Buffers: shared hit=3032  
         InitPlan 1 (returns $0)  
           ->  Index Only Scan using tbl_grp_pkey on public.tbl_grp  (cost=0.28..25.88 rows=1000 width=4) (actual time=0.026..0.245 rows=1000 loops=1)  
                 Output: tbl_grp.id  
                 Heap Fetches: 1000  
                 Buffers: shared hit=9  
   ->  Index Scan using idx_tbl_feedlog_1 on public.tbl_feedlog tbl_feedlog_1  (cost=0.43..2.65 rows=1 width=29) (actual time=0.006..0.006 rows=0 loops=1)  
         Output: tbl_feedlog_1.id, tbl_feedlog_1.gid, tbl_feedlog_1.c1, tbl_feedlog_1.info, tbl_feedlog_1.crt_time  
         Index Cond: ((tbl_feedlog_1.gid IS NULL) AND (tbl_feedlog_1.c1 = 100))  
         Buffers: shared hit=3  
 Planning time: 0.195 ms  
 Execution time: 3.805 ms  
(17 rows)  
传统方法  
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from tbl_feedlog where c1=100;  
                                                                   QUERY PLAN                                                                     
------------------------------------------------------------------------------------------------------------------------------------------------  
 Index Scan using idx_tbl_feedlog_1 on public.tbl_feedlog  (cost=0.43..133248.85 rows=1 width=29) (actual time=107.331..199.335 rows=1 loops=1)  
   Output: id, gid, c1, info, crt_time  
   Index Cond: (tbl_feedlog.c1 = 100)  
   Buffers: shared hit=52088  
 Planning time: 0.164 ms  
 Execution time: 199.366 ms  
(6 rows)  
```  
## 内核层面优化    
与Oracle做法类似，或者说与递归的做法类似。    
使用这种方法来改进优化器，可以达到index skip scan的效果，而且不用改写SQL。    
## 参考    
[《distinct xx和count(distinct xx)的变态递归优化方法 - 索引收敛(skip scan)扫描》](../201611/20161128_02.md)      
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")