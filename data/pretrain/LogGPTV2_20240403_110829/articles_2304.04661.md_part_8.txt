towards their own application and cannot be easily adopted troubleshooting processes of engineers and SREs. And trace
even by other similar systems. This alludes towards need for RCAcanbetriggeredinamoread-hocwayinsteadofrunning
more generalizable architectures for modeling the RCA task continuously.Thisdifferentiatesthepotentialtechniquestobe
which in turn needs more robust generalizable log analysis adopted from trace anomaly detection.
models that can handle hetergenous kinds of log data coming TraceEntityGraph.Fromthetechnicalpointofview,trace
fromdifferentsystems. Continual learning framework:One RCA and trace anomaly detection share similar perspectives.
of the challenging aspects of RCA in the distributed cloud To our best knowledge, there are not too many existing works
setting is the agile environment, leading to new kinds of talking about trace RCA alone. Instead, trace RCA serves
incidents and evolving causation factors. This kind of non- as an additional feature or side benefit for trace anomaly
stationary learning setting poses non-trivial challenges for detection in either empirical approaches [121] [196] or deep
RCA but is indeed a crucial aspect of all practical industrial learning approaches [120] [197]. In trace anomaly detection,
applications. Human-in-the-loop framework: While neither the constructed trace entity graph (TEG) after offline training
provides a clean relationship between each component in the
completely supervised or unsupervised settings is practical
application systems. Thus, besides anomaly detection, [122]
for this task, there is need for supporting human-in-the-loop
implemented a real-time RCA algorithm that discovers the
framework which can incorporate feedbacks from domain
deepest root of the issues via relative importance analysis
experts to improve the system, especially in the agile settings
aftercomparingthecurrentabnormaltracepatternwithnormal
wherecausationfactorscanevolveovertime.Realisticpublic
tracepatterns.Theirexperimentintheproductionenvironment
benchmarks: Majority of the literature in this area is focused demonstratedthisRCAalgorithmcanachievehigherprecision
on industrial applications with in-house evaluation setting. In and recall compared to naive fixed threshold methods. The
some cases, they curate their internal testbed by injecting effectiveness of leverage trace entity graph for root cause
failures or faults or anomalies in their internal simulation analysis is also proven in deep learning based trace anomaly
environment (for e.g. injecting CPU, memory, network and detection approaches. Liu et al. [198] proposed a multimodal
Disk anomalies in Spark platforms) or in popular testing LSTM model for trace anomaly detection. Then the RCA
settings (like Grid5000 testbed or open-source microservice algorithm can check every anomalous trace with the model
applications based on online shopping platform or train ticket training traces and discover root cause by localizing the next
booking or open source cloud operating system OpenStack). calledmicroservicewhichisnotinthenormalcallpaths.This
Other works evaluate by deploying their solution in real- algorithmperformswellforbothsyntheticdatasetandproduc-
world setting in their in-house cloud-native application, for tiondatasetsoffourlargeproductionservices,accordingtothe
e.g. on IBM Bluemix platform, or for Facebook applications evaluation of this work.
20
Online Learning. An alternative approach is using data Future Trends
mining and statistical learning techniques to run dynamic More Efficient Trace Platform. Currently there are very
analysis without constructing the offline trace graph. Tra- limitedstudiesintracerelatedtopics.Afundamentalchallenge
ditional trace management systems usually provides basic isaboutthetraceplatforms.Therearebottlenecksincollection,
analytical capabilities to diagnose issues and discover root storage, query and management of trace data. Traces are
causes [199]. Such analysis can be performed online without usually at a much larger scale than logs and metrics. How
costly model training process. Chen et al.proposed Pinpoint tomoreefficientlycollect,storeandretrievetracedataisvery
[124], a framework for root cause analysis that using coarse- critical to the success of trace root cause analysis.
grained tagging data of real client requests at real-time when Online Learning. Compared to trace anomaly detection,
these requests traverse through the system, with data mining online learning plays a more important role for trace RCA,
techniques.Pinpointdiscoversthecorrelationbetweensuccess especiallyforlargecloudsystems.AnRCAtoolusuallyneeds
/ failure status of these requests and fault components. The to analyze the evidence on the fly and correlate the most
entire approach processes the traces on-the-fly and does not suspicious evidence to the ongoing incidents, this approach is
leverage any static dependency graph models. Another related very time sensitive. For example, we know trace entity graph
area is using trouble-shooting guide data, where [200] rec- (TEG) can achieve accurate trace RCA but the preassumpiton
ommends troubleshooting guide based on semantic similarity is the TEG is reflecting the current status of the system. If
with incident description while [201] focuses on automation offline training is the only way to get TEG, the performance
oftroubleshootingguidestoexecutionworkflows,asawayto of such approaches in real-world production environments is
remediate the incident. always questionable. Thus, using online learning to obtain the
TEG is a much better way to guarantee high performance in
RCA on Incident Reports this situation.
Another notable direction in AIOps literature has been Causality Graphs on Multimodal Telemetries. The most
mining useful knowledge from domain-expert curated data precious information conveyed by trace data is the complex
(incident report, incident investigation data, bug report etc) topologicalorderoflargesystems.Withouttraces,causalanal-
towards enabling the final goals of root cause analysis and ysis for system operations relies on temporal and geometrical
automatedremediationofincidents.Thisisanopenendedtask correlations to infer causal relationships, and practically very
which can serve various purposes - structuring and parsing few existing causal inference can be adopted in real-world
unstructured or semi-structured data and extracting targeted systems. However, with traces, it is very convenient to obtain
information or topics from them (using topic modeling or in- the ground truth of how requests flow through the entire
formation extraction) and mining and aggregating knowledge system. Thus, we believe higher quality causal graphs will
into a structured form. be much easier achievable if it can be learned by multimodel
telemetry data.
The end-goal of these tasks is majorly root cause analysis,
while some are also focused on recommending remediation Complete Knowledge Graph of Systems. Currently
to mitigate the incident. Especially since in most cloud- knowledge mining has been tried for single data type. How-
based settings, there is an increasing number of incidents that ever, to reflect the full picture of a complex system, the AI
occur repeatedly over time showing similar symptoms and models need to mining knowledge from any kind of data
having similar root causes. This makes mining and curating types,includingmetrics,logs,traces,incidentreportsandother
knowledgefromvariousdatasources,verycrucial,inorderto systemactivityrecords,thenconstructaknowledgegraphwith
be consumed by data-driven AI models or by domain experts complete system information.
for better knowledge reuse.
Causality Graph. [202] extracts and mines causality graph
VII. AUTOMATEDACTIONS
from historical incident data and uses human-in-the-loop su-
pervision and feedback to further refine the causality graph. While both incident detection and RCA capabilities of
[203]constructsananomalycorrelationgraph,FacGraphusing AIOps help provide information about ongoing issues, tak-
a distributed frequent pattern mining algorithm. [204] recom- ing the right actions is the step that solve the problems.
mends appropriate healing actions by adapting remediations Without automation to take actions, human operators will
retrievedfromsimilarhistoricalincidents.Thoughtheendtask still be needed in every single ops task. Thus, automated
involves remediation recommendation, the system still needs actions is critical to build fully-automated end-to-end AIOps
to understand the nature of incident and root cause in order systems. Automated actions contributes to both short-term
to retrieve meaningful past incidents. actions and longer-term actions: 1) short-term remediation:
Knowledge Mining. [205], [206] mines knowledge graph immediate actions to quickly remediate the issue, including
from named entity and relations extracted from incident re- server rebooting, live migration, automated scaling, etc.; and
ports using LSTM based CRF models. [207] extracts symp- 2) longer-term resolutions: actions or guidance for tasks such
toms, root causes and remediations from past incident inves- as code bug fixing, software updating, hard build-out and re-
tigations and builds a neural search and knowledge graph sourceallocationoptimization.Inthissection,wediscussthree
to facilitate a retrieval based root cause and remediation common types of automated actions: automated remediation,
recommendation for recurring incidents. auto-scaling and resource management.
21
A. Automated Remediation scenario, or an end-to-end auto-remediation solution for very
specificusecasessuchasvirtualmachineinterruptions.Below
Problem Definition are a few topics that can significantly improve the quality of
Besides continuously monitoring the IT infrastructure, de- auto-remediation systems.
tecting issues and discovering root causes, remediating issues System Integration Now there is still no unified platform
with minimum, or even no human intervention, is the path that can perform all the issue analysis, learn the context
towards the next generation of fully automated AIOps. Auto- knowledge, make decisions and execute the actions.
mated issue remediation (Auto-remediation) is taking a series LearntogenerateandupdateknowledgegraphsQuality
of actions to resolve issues by leveraging known information, of auto-remediation decision making strongly depends on
existing workflows and domain knowledge. Auto-remediation domain knowledge. Currently humans collect most of the
is a concept already adopted in many IT operation scenarios, domain knowledge. In the future, it is valuable to explore
including cloud computing, edge computing, SaaS, etc. approaches that learn and maintain knowledge graphs of the
Traditional auto-remediation processes are based on a vari- systems in a more reliable way.
ety of well-defined policies and rules to get which workflows AI driven decision making and execution Currently most
to use for a given issue. While machine learning driven of the decision making and action execution are rule-based or
auto-remediation means utilizing machine learning models to statistical learning based. With more powerful AI techniques,
decide the best action workflows to mitigate or resolve the theremediationenginecanthenconsumerichinformationand
issue. ML based auto-remediation is exceptionally useful in make more complex decisions.
large scale cloud systems or edge-computing systems where
it’s impossible to manually create workflows for all issue B. Auto-scaling
categories.
Problem Definition
Existing Work
The cloud native technologies are becoming the de facto
End-to-endauto-remediationsolutionsusuallycontainthree
standard for building scalable applications in public or private
maincomponents:anomalyorissuedetection,rootcauseanal-
clouds, enabling loosely coupled systems that are resilient,
ysisandremediationengine[208].Thismeanssuccessfulauto- manageable,andobservable†.ThecloudsystemssuchasGCP
remediationsolutionshighlyrelyonthequalityofanomalyde-
and AWS provide users on-demand resources including CPU,
tectionandrootcauseanalysis,whichwe’vealreadydiscussed
storage,memoryanddatabases.Usersneedstospecifyalimit
in the above sections. Besides, the remediation engine should
of these resources to provision for the workloads of their
be able to learn from the analysis results, make decisions and
applications.Ifaserviceinanapplicationexceedsthelimitof
execute.
a particular resource, end-users will experience request delays
Knowledge learning. The knowledge here refers to a va- or timeouts, so that system operators will request a larger
rietyofcategories.Anomalydetectionandrootcauseanalysis limit of this resource to avoid degraded performance. But
forthisspecificissuecontributestoamajorityofthelearnable if hundreds of services are running, such large limit results
knowledge [208]. Remediation engine uses these information in massive resource wastage. Auto-scaling aims to resolve
to locate and categorize the issue. Besides, the human activity thisissuewithouthumanintervention,whichenablesdynamic
records(suchastickets,bugfixinglogs)ofpastissuesarealso provisioning of resources to applications based on workload
significant for the remediation to learn the full picture of how behavior patterns to minimize resource wastage without loss
issues were handled in history. In Sections VI-A VI-B VI-C of quality of service (QoS) to end-users.
we discussed about mining knowledge graphs from system Auto-scaling approaches can be categorized into two types:
metrics, logs and human-in-the-loop records. A high quality reactiveauto-scalingandproactive(orpredictive)auto-scaling.
knowledge graph which clearly describes the relationship of Reactive auto-scaling monitors the services in a application,
system components. and brings them up and down in reaction to changes in
Decision making and execution. Levy et al. [209] workloads.
proposed Narya, a system to handle failure remediation for Reactive auto-scaling. Reactive auto-scaling is very effec-
running virtual machines in cloud systems. For a given issue tive and supported by most cloud platforms. But it has one
where the host is predicted to fail, the remediation engine potential disadvantage, i.e., it won’t scale up resources until
needs to decide what is the best action to take from a few workloads increase so that there is a short period in which
optionssuchaslivemigration,softreboot,servicehealing,etc. more capacity is not yet available but workloads becomes
ThedecisiononwhichactionstotakearemadeviaA/Btesting higher. Therefore, end-users can experience response delays
andreinforcementlearning.Withadoptingmachinelearningin in this short period. Proactive auto-scaling aims to solve this
their remediation engine, they see significant virtual machine problem by predicting future workloads based on historical
interruptionsavingscomparedtothepreviousstaticstrategies. data. In this paper, we mainly discuss proactive auto-scaling
algorithms based on machine learning.
Future Trends
Proactive Auto-scaling. Typically, proactive auto-scaling
Auto-remediation research and development is still in very
involves three steps, i.e., predicting workloads, estimating
early stages. The existing work mainly focuses on an inter-
mediate step such as constructing a causal graph for a given †https://github.com/cncf/foundation/blob/main/charter.md
22
capacities and scaling out. Machine learning techniques are andschedulingtenants’tasks.Howtoprovisionresourcescan
usually applied to predict future workloads and estimate the be determined in a reactive manner, e.g., creating static rules
suitablecapacitiesforthemonitoredservices,andthenadjust- manually based on domain knowledge. But similar to auto-
mentscanbedoneaccordinglytoavoiddegradedperformance. scaling, reactive approaches result in response delays and ex-
One type of proactive auto-scaling approaches applies re- cessiveoverheads.Toresolvethisissue,ML-basedapproaches
gression models (e.g., ARIMA [210], SARIMA [211], MLP, forresourcemanagementhavegainedmuchattentionrecently.
LSTM [212]). Given the historical metrics of a monitored
service, this type of approaches trains a particular regression ML-based Resource Management
model to learn the workload behavior patterns. For example, Many ML-based resource management approaches have
[213] investigated the ARIMA model for workload prediction been developed in recent years. Due to space limitation, we
and showed that the model improves efficiency in resource will not discuss them in details. We recommend readers who
utilization with minimal impact in QoS. [214] applied a time are interested in this research topic to read the following nice
window MLP to predict phases in containers with different reviewpapers:[218],[219],[220],[221],[222].Mostofthese
types of workloads and proposed a predictive vertical auto- approaches apply ML techniques to forecast future resource