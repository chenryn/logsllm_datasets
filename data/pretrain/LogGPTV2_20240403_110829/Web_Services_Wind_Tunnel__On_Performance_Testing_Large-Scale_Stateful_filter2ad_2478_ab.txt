### 37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)
**Authorized licensed use limited to: Tsinghua University. Downloaded on March 20, 2021 at 12:30:40 UTC from IEEE Xplore. Restrictions apply.**
**0-7695-2855-4/07 $20.00 © 2007**

#### Markov Transition Matrix
The transition matrix \( P \) for a Markov chain with \( n+1 \) states is given by:

\[
P = 
\begin{pmatrix}
p_{00} & p_{01} & p_{02} & \cdots & p_{0n} \\
p_{10} & p_{11} & p_{12} & \cdots & p_{1n} \\
p_{20} & p_{21} & p_{22} & \cdots & p_{2n} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
p_{n0} & p_{n1} & p_{n2} & \cdots & p_{nn}
\end{pmatrix}
\]

where:
- \( p_{ij} \) represents the transition probability from state \( i \) to state \( j \).
- \( 0 \leq p_{ij} \leq 1 \) for all \( i, j \).
- \( \sum_{j=0}^{n} p_{ij} = 1 \) for all \( i \).

#### Knowledge Exercise Step
In the knowledge exercise step, our objective is to generate load patterns that closely mimic those observed in production. This is achieved using the Markov Transition Matrix created during the Knowledge Retriever step.

An important aspect of this methodology is that the transition matrix reflects only the average behavior over a certain period. To reproduce the exact same pattern observed in production (e.g., CPU utilization, memory utilization, disk utilization), the matrix must be periodically updated.

#### Workflow Diagram
**Figure 3. Markov Chain Workflow**

1. **Aggregation of Production Activity Logs**: The first step involves aggregating production activity logs by session and ordering them by timestamps.
2. **Data Mining**: Through data mining, we extract:
   - The Markov Transition Matrix over the APIs.
   - The interval between each API transaction (referred to as "Thinking Time" [10]).
   - Parameter calling patterns for each API.
3. **Knowledge Retriever Step**: At this point, we have completed the knowledge retriever step.

#### Stress Testing Environment
The next step is to exercise the collected knowledge in the stress testing environment. We found it more challenging to recover and mimic the parameter patterns of each API call than to produce the Markov transition matrix. This is because most input parameters are user-specific information with a high degree of randomness (e.g., user's first name).

For user-specific information, we developed tools or methods to generate valid parameter values by creating or retrieving them from our data store and depositing them in parameter pools.

- **Client Representation**: A thread represents a client, calling APIs one by one based on the Markov Transition Matrix.
- **Sleep Interval**: A sleep interval is introduced between two consecutive API calls to make the simulation more realistic.
- **Parameter Fetching**: The model fetches needed parameters from the parameter pool for each API call.
- **Scalability**: The model is scalable, allowing for the generation of stress loads. The parameter generator and threads can be distributed across machines via configurable parameters.

**Figure 4. Load Profiles in Production and Test Environments**

- **CPU Utilization**: The figure shows the CPU utilization in both production and test environments over a 3-hour run. The load profile in the test clusters was very similar to that observed in production.

#### Insights from the Markov Chain Model
The Markov chain model not only simulates production-like stress loads on test environments but also provides insights into system behavior, particularly the correlation among APIs and their parameters. For example:
- Highly correlated APIs might benefit from improved locality.
- Unexpected correlations may indicate potential areas needing further inspection.

### Cache-based Load Simulation Tools

#### Methods for Load Simulation
The methods described in previous sections provide a large dataset resembling production and a practical way to analyze and simulate real-user behaviors. However, performance tuning of stateful systems often requires executing a particular API numerous times in isolation to determine system bottlenecks.

Web services are generally modeled after finite state machines, where most APIs expect the invoking entity to be in a certain state before an operation [11]. The conventional approach is to generate an entity and induce it into the required state before the actual API invocation. This on-the-fly data generation and entity state inducement can hide actual system bottlenecks.

#### Solution: Cache-based Load Simulation
Our solution is cache-based load simulation, which requires pre-determination of individual API calls to the states in which the entity must be. Each defined state is represented as a bucket, and the bucket definitions are collections of Boolean conditions. An entity matches the predefined set of conditions and belongs to the corresponding bucket.

**Process Steps**:
1. Determine the matching bucket for the API.
2. Extract an entity from the bucket.
3. Invoke the API with the selected entity.
4. Re-evaluate the state post API invocation.
5. Re-insert the entity in the new bucket(s). If the entity is no longer usable, discard it.

**Implementation**:
- **Entity Cache**: Uses a SQL database to prevent data loss and allow easy data sharing across multiple instances of the tool.
- **Abstraction Layer**: Introduces a layer of abstraction to wrap database calls, exposing methods to modify entities and buckets.

**Table 3. DB Access Methods for Cache-based Simulation**

| Method Type       | Method               |
|-------------------|----------------------|
| Initialization     | InitializeCache      |
| Bucket Access     | LoadBuckets, Clear, AddBucket, GetBucketList, GetCountPerBucket |
| Entity Access     | AddEntity, GetEntityFromBucket, RemoveEntity, GetPreExistingEntity |

**Entity State Management**:
- Entities are treated like critical sections; only one thread can act on an entity at a time.
- To avoid corruption, entities are removed from their matching buckets just prior to API invocation and re-evaluated post-execution.

**Cache Population**:
- During the cache-population stage, we use the "GetPreExistingEntity" method to pick random entities from the existing dataset and place them in the appropriate buckets.
- Specific buckets may require executing predefined steps, resulting in a combination of sanitized and synthetic data.

**State Determination**:
- Entity state is usually determined by parsing results from "state-retrieving" API calls (e.g., Get calls).
- Custom data access methods are constructed if the state-retrieving API calls do not provide sufficient information.

**Generalization**:
- This cache-based approach can be implemented in any commercial application for load generation, focusing on interactions with the underlying system rather than load volume.

### Results and Future Work

#### Techniques for Performance Testing
We have described techniques for building proper environments and performance test tools to accurately simulate the same conditions observed in production. These techniques include Data Sanitization, Markov Chain Stress Model, and Cache-based Load Simulation Tools.

**Application**:
- Successfully used for benchmarking, capacity planning, and scalability tests for three major distributed web services: Subscription and Commerce Web Services, Identity Services Web Services, and Customer Assistance Web Services, all part of the Microsoft Member Platform Group.
- Accuracy of performance numbers collected in test laboratories increased to a deviation of less than 5% from production environments (compared to ~9% with synthesized data).
- The number of real performance and functional issues found during the quality assurance process increased by 15%.

**Future Work**:
- Extend data sanitization to other data sources beyond relational databases.
- Implement real-time data sanitization.
- Generalize the Markov Chain Stress Model to different log sources.
- Generalize Cache-based load simulation tools to automatically identify potential matching buckets based on the Finite State Machine for the system being tested.

### References
[1] “Privacy in e-commerce: examining user scenarios and privacy preferences,” Proceedings of the 1st ACM conference on Electronic commerce, ACM, 1999.
[2] W.E. Howden, “Reliability of the path analysis testing strategy,” IEEE Trans. Software Engineering, vol SE-2, 1976 Sep.
[3] Y. Saito, B.N. Bershad, H.M. Levy, "Manageability, availability, and performance in porcupine: a highly scalable, cluster-based mail service," ACM Transactions on Computer Systems, 2000.
[4] J. Edvardsson, "A survey on automatic test data generation," Proceedings of the Second Conference on Computer Science and Engineering, ECSEL, October 1999.
[5] SRM Oliveira, OR Zaıane, “Protecting Sensitive Knowledge By Data Sanitization,” Third IEEE International Conference on Data Mining, ICDM 2003.
[6] O.C. McDonald, X. Wang, M. De Barros, R.K. Bonilla, Q. Ke, “Strategies for Sanitizing Data Items,” US Patent Application (patent pending), 2004.
[7] S. Abiteboul, P. Buneman, D. Suciu, "Data on the Web: From Relational to Semistructured Data and XML," SIGMOD Record, Vol. 32, No. 4, December 2003.
[8] Stuart J. Russell, Peter Norvig, Artificial Intelligence: A Modern Approach (2nd Edition), Prentice Hall, Upper Saddle River, NJ, Dec, 2003.
[9] W.R. Gilks, S. Richardson, D.J. Spiegelhalter, Markov Chain Monte Carlo in Practice, Chapman & Hall/CRC, Dec, 1995.
[10] J.D. Meier, Srinath Vasireddy, Ashish Babbar, and Alex Mackman, Improving .NET Application Performance and Scalability, Microsoft Corp., Redmond, WA, April 2004.
[11] B. Benatallah, F. Casati and F. Toumani, “Web service conversation modeling: A corner-stone for e-business automation,” IEEE Internet Computing, 2004.