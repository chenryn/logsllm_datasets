title:The Doppelg&quot;anger Bot Attack: Exploring Identity Impersonation
in Online Social Networks
author:Oana Goga and
Giridhari Venkatadri and
Krishna P. Gummadi
Exploring Identity Impersonation in Online Social Networks
The Doppelgänger Bot Attack:
Oana Goga
MPI-SWS
Giridhari Venkatadri
MPI-SWS
Krishna P. Gummadi
MPI-SWS
ABSTRACT
People have long been aware of malicious users that imper-
sonate celebrities or launch identity theft attacks in social
networks. However, beyond anecdotal evidence, there have
been no in-depth studies of impersonation attacks in today’s
social networks. One reason for the lack of studies in this
space is the absence of datasets about impersonation at-
tacks. To this end, we propose a technique to build extensive
datasets of impersonation attacks in current social networks
and we gather 16,572 cases of impersonation attacks in the
Twitter social network. Our analysis reveals that most iden-
tity impersonation attacks are not targeting celebrities or
identity theft. Instead, we uncover a new class of imperson-
ation attacks that clone the proﬁles of ordinary people on
Twitter to create real-looking fake identities and use them
in malicious activities such as follower fraud. We refer to
these as the doppelg¨anger bot attacks. Our ﬁndings show (i)
that identity impersonation attacks are much broader than
believed and can impact any user, not just celebrities and
(ii) that attackers are evolving and create real-looking ac-
counts that are harder to detect by current systems. We
also propose and evaluate methods to automatically detect
impersonation attacks sooner than they are being detected
in today’s Twitter social network.
INTRODUCTION
1.
Today, users sign on to most online social networks like Face-
book and Twitter via weak identities, i.e., unveriﬁed identi-
ties (accounts) that do not require users to prove that their
online identities match their oﬄine, real world, personali-
ties. Weak identities lower the sign-on barriers for users,
oﬀer users a certain level of anonymity, but they leave the
sites vulnerable to a variety of fake identities or Sybil at-
tacks. Malicious attackers are known to use Sybil identities
to post spam content [31] and to tamper with the popular-
ity of content on these sites [33]. Consequently, a number of
prior works have focussed on understanding and detecting
Sybil attacks in online social networks [20, 25, 21, 14].
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
IMC’15, October 28–30, 2015, Tokyo, Japan.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3848-6/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2815675.2815699.
In this paper, we focus on a special class of Sybil (fake
identity) attacks known as identity impersonation attacks,
where the attacker spoofs or assumes the identity of another
real-world user, the victim. As more and more personal data
about users becomes publicly available on the Web, imper-
sonation attacks become easier to carry out. For instance,
an attacker can easily copy public proﬁle data of a Facebook
user to create an identity on Twitter or Google+.
There are many diﬀerent types of impersonation attacks
based on the attacker’s motivation. (i) In a celebrity imper-
sonation attack, the attacker exploits or maligns the public
reputation of the victim, whose identity she impersonated.
Popular and celebrity users are often targets for such imper-
sonation attacks [19, 26]. (ii) In a social engineering attack,
the attacker abuses victim’s identity to trick the victim’s
friends into revealing sensitive information or providing ser-
vices (e.g., transfer money to the attacker) [30, 22]. (iii) In
a doppelg¨anger bot attack, the attacker is simply interested
in evading detection by the Sybil or Spam defenses deployed
by site operators. As Sybil detectors are often trained to
detect non-real-looking identities (e.g., lacking proﬁle pho-
tos or location information or bio), attackers could create
more real-looking fake identities by copying the attributes
of a real user.
Regardless of the attacker’s motivation, identity imper-
sonation attacks could seriously damage the victim’s online
reputation. As people’s online data is increasingly aggre-
gated by people’s search engines [28] and used for a variety
of purposes including evaluating their suitability for employ-
ment [27], impersonation attacks, particularly those that go
undetected, can have serious adverse consequences for the
victims, even in the oﬄine world.
Despite the serious threat posed by impersonation attacks,
few studies, to date, have systematically studied imperson-
ation attacks in online social networks. Beyond a few anec-
dotal examples that are reported in the popular press, we
lack large datasets about real-world impersonation attacks.
Perhaps, not surprisingly, most social networking sites to-
day lack frameworks to automatically detect impersonators.
Instead, they rely on manual reports from victims about ac-
counts that are impersonating them [32], which can be risky
as victims usually become aware of their attackers after their
online reputation has already been damaged.
Against this background, this paper presents, to the best
of our knowledge, the ﬁrst extensive study of real-world im-
personation attacks in online social networks. Speciﬁcally,
it makes the following contributions:
1411. Methodology for gathering data about imper-
sonation attacks. We identify the fundamental challenges
associated with gathering data about impersonation attacks
and propose practical methods to circumvent the challenges.
Our method, as described in §2, consists of two steps: (1)
identify doppelg¨anger accounts in a social network that por-
tray the same person/entity; and (2) out of the doppel-
g¨anger accounts that portray the same entity, label which
accounts are legitimate and which accounts are imperson-
ators.
The second step is complicated by the fact that people
can maintain multiple legitimate accounts in a social net-
work. We applied our method to gather data on Twitter.
We identiﬁed 54,304 doppelg¨anger pairs of Twitter identi-
ties that portray the same person. We successfully labelled
16,572 of the doppelg¨anger pairs as resulting from imper-
sonation attacks and 3,639 pairs as cases when a person
maintains two legitimate accounts in the Twitter network.
2. Characterizing impersonation attacks. Our anal-
ysis of the data we gathered reveals many interesting facts
about identity impersonation attacks, including some that
contradicted our expectations.
(1) Contrary to our expectation that most impersonation
attacks would largely target celebrity / popular user identi-
ties, we discovered that many impersonation attacks target
ordinary users.
(2) Additionally, many impersonation at-
tacks do not seem to attempt social engineering attacks or
even try to exploit the public reputation of their victims.
They appear to have been created by attackers looking to
create real looking fake accounts that could pass undetected
by current Sybil detection systems. We call these attacks
as the doppelg¨anger bot attacks. Despite their motivation,
doppelg¨anger bot attacks can still harm the online repu-
tation of the victim identity.
(3) We found that it takes
Twitter on average 287 days to suspend the impersonating
accounts from our dataset. The long delay in detecting the
attacks call for developing methods to detect such attacks
sooner.
3. Methods to automatically detect impersonation
attacks. Our analysis characterizing impersonation attacks
yield novel insights for detecting impersonation attacks. First,
given a pair of doppelg¨anger identities, we could determine
whether the identity-pair is managed by the same person or
whether it is the result of an impersonation attack, by com-
paring the social network neighborhood and interests of the
user. In the former scenario, the pair of doppelg¨anger iden-
tities share considerable overlap in network neighborhood
and interests, while in the latter, they are considerably more
dissimilar. Furthermore, we ﬁnd that we can infer which of
the pair of doppelg¨anger identities is legitimate (victim) and
which is the impersonator (attacker), by comparing various
reputation metrics, such as creation date, number of follow-
ers etc. We ﬁnd that victim identities almost always have
higher reputation and older creation dates than imperson-
ating identities.
We leverage these insights to propose automatic methods
(based on machine learning techniques) to detect imperson-
ation attacks in §4. We detect 10,894 more cases of imper-
sonation attacks and 9,354 cases of accounts managed by the
same person when we test the scheme on the 34,091 unla-
beled pairs of accounts that portray the same person. More
than half of the impersonating accounts detected by our
method were subsequently suspended by Twitter (over a 6
month period), which shows the eﬀectiveness of our method
at detecting impersonating accounts sooner than Twitter.
In summary, our paper proposes methods to gather data
about a large number of real-world impersonation attacks in
online social networks. Although our method does not cap-
ture all impersonation attacks, the resulting dataset allows
us to do an insightful exploration of impersonation attacks,
and to build an automatic detector that is not only able
to detect more such attacks, but also detect them sooner.
Our work represents a useful step towards enabling users to
better protect their online reputation from identity imper-
sonation attacks.
2. DATA GATHERING METHODOLOGY
In this section, we ﬁrst propose a methodology for gather-
ing data about impersonation attacks in real-world social
networks. Later, we apply our methodology to gather data
about impersonation attacks on Twitter.
Intuitively, an identity impersonation attack involves an
attacker creating an account (identity) pretending to be some
other real-world user (victim), i.e., the attacker’s identity
mimics or copies the features of the victim’s identity. How-
ever, gathering data about such attacks is surprisingly diﬃ-
cult in practice (which might explain why few prior studies,
if any, have successfully analyzed real-world impersonation
attacks).
2.1 Challenges
To understand why identifying impersonation attacks is hard,
consider the real-world example attack shown in Fig. 1. We
discovered this attack on “Nick Feamster”, a computer sci-
ence researcher, during the course of our study. We alerted
Nick, who conﬁrmed the attack, and the impersonating ac-
count has since been suspended by Twitter. We realized
three challenges in the process:
Figure 1: Example of impersonation attack.
1. How do we determine which identities are attempting
to portray or represent the same user? For instance,
there are many Twitter identities with the same user
name “Nick Feamster”, but we felt that only the ac-
count that shared similar bio and photo as Nick’s orig-
inal account,
is attempting to pretend to be Nick.
Our intuitive decision raises the question: how simi-
lar should the proﬁles of two identities be to qualify as
portraying the same user?
2. After determining that a pair of identities portray the
same user, how do we determine whether the identity-
pair is the result of an impersonation attack or the
142result of a user simply creating multiple (duplicate)
accounts for herself? For instance, users on Twitter
are permitted to create multiple identities, including
pseudonymous identities. To determine the shared
ownership of identities, we would need to contact and
obtain conﬁrmation from the identities’ owners them-
selves (e.g., by sending messages to the identities).
However, such conﬁrmations are not only hard to ob-
tain for a large-scale study, but also when we attempted
it on Twitter, the Twitter identity we created to con-
tact other Twitter users for the study got suspended
for attempting to contact too many unrelated Twitter
identities.
3. After determining that a pair of identities portraying
the same user is the result of an impersonation attack
(i.e., they are not duplicate accounts owned by the
same user), how do we determine which identity is le-
gitimate and which is the impersonating identity? In
our attack example, we were lucky to know the person
portrayed, Nick Feamster, in the oﬄine world. This
knowledge enabled us to diﬀerentiate the legitimate
identity from the attacker’s identity. But, in practice,
the oﬄine user portrayed by the online identities is
often unknown, i.e., it is unclear how to contact the
oﬄine user.
In these scenarios, it is unclear how to
diﬀerentiate the legitimate identity from the imperson-
ating identity, as both may claim to be the legitimate
identity.
Below we propose a practical methodology that tackles
some of these fundamental challenges and circumvents oth-
ers. We applied it on Twitter to gather data about several
hundreds to thousands of real-world impersonation attacks.
Our methodology does not guarantee that we would discover
all or even a representative sample of all impersonation at-
tacks occurring in Twitter. Nevertheless, given the inherent
diﬃculty in collecting any data about impersonation attacks,
we feel that our work represents a ﬁrst step in the direction
of addressing these challenges.
2.2 Terminology
We introduce some terminology to both simplify and clar-
ify our discussion in the rest of the paper.
(i) doppel-
g¨anger identities: We refer to identities as doppelg¨anger iden-
tities when they are determined to be portraying or repre-
senting the same user. (ii) avatar-avatar pair: A pair of
doppelg¨anger identities is referred to as an avatar-avatar pair
when both identities are managed by the same owner. (iii)
victim-impersonator pair: A pair of doppelg¨anger iden-
tities is referred to as a victim-impersonator pair when one
of the identities is legitimate (victim identity) and the other
is created by an attacker (impersonating identity). Using
our terminology, the above challenges can be rephrased as
follows:
1. How do we identify doppelg¨anger identities?
2. How do we determine that a pair of doppelg¨anger iden-
tities is an avatar-avatar pair or a victim-impersonator
pair?
3. How do we determine which of the victim-impersonator
identity-pair is the victim and which is the imperson-
ator?
2.3 Data gathering strategy
In this section, we discuss our strategy to tackle the above
challenges when gathering data. We defer a detailed discus-
sion of the collected data to the next section. At a high-level,
our strategy involves ﬁrst automatically identifying a large
number of pairs of doppelg¨anger identities and then diﬀer-
entiating them into avatar-avatar and victim-impersonator
pairs.