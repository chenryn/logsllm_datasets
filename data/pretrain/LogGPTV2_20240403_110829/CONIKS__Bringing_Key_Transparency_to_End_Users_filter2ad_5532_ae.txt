assume her “lost identity”.
In practice, this could be prevented by allowing the
provider to place a “tombstone” on a name with its own
signature, regardless of the user’s key policy. The provider
would use some speciﬁc out-of-band authorization steps
to authorize such an action. Unlike allowing providers to
issue key change operations, though, a permanent account
deactivation does not require much additional trust in
the provider, because a malicious provider could already
render an account unusable through denial of service.
6.3 Protocol Extensions
Limiting the effects of denied service. Sufﬁciently pow-
erful identity providers may refuse to distribute STRs to
providers with which they do not collude. In these cases,
clients who query these honest providers will be unable to
obtain explicit proof of equivocation. Fortunately, clients
may help circumvent this by submitting observed STRs to
these honest identity providers. The honest identity pro-
viders can verify the other identity provider’s signature,
and then store and redistribute the STR.
Similarly, any identity provider might ignore requests
about individual bindings in order to prevent clients from
performing consistency checks or key changes. In these
cases, clients may be able to circumvent this attack by
using other providers to proxy their requests, with the
caveat that a malicious provider may ignore all requests
for a name. This renders this binding unusable for as
long as the provider denies service. However, this only
allows the provider to deny service, any modiﬁcation to
the binding during this attack would become evident as
soon as the service is restored.
Obfuscating the social graph. As an additional privacy
requirement, users may want to conceal with whom they
are in communication, or providers may want to offer
anonymized communication. In principle, users could use
Tor to anonymize their communications. However, if only
few users in CONIKS use Tor, it is possible for providers
to distinguish clients connecting through Tor from those
connecting to the directly.
USENIX Association  
11
24th USENIX Security Symposium  393
CONIKS could leverage the proxying mechanism de-
scribed in §6.3 for obfuscating the social graph. If Alice
would like to conceal with whom she communicates, she
could require her client to use other providers to proxy
any requests for her contacts’ bindings or consistency
proofs. Clients could choose these proxying providers
uniformly at random to minimize the amount of infor-
mation any single provider has about a particular user’s
contacts. This can be further improved the more pro-
viders agree to act as proxies. Thus, the only way for
providers to gain information about whom a given user is
contacting would be to aggregate collected requests. For
system-wide Tor-like anonymization, CONIKS providers
could form a mixnet [13], which would provide much
higher privacy guarantees but would likely hamper the
deployability of the system.
Randomizing the order of directory entries. Once a
user learns the lookup index of a name, this position in
the tree is known for the rest of time because the index is
a deterministic value. If a user has an authentication path
for two users PI:EMAIL and PI:EMAIL which
share a common preﬁx in the tree, the Bob’s authentica-
tion path will leak any changes to Alice’s binding if his
key has not changed, and vice-versa. foo.com can prevent
this information leakage by randomizing the ordering of
entries periodically by including additional data when
computing their lookup indices. However, such random-
ized reordering of all directory entries would require a
complete reconstruction of the tree. Thus, if done every
epoch, the identity provider would be able to provide en-
hanced privacy guarantees at the expense of efﬁciency.
The shorter the epochs, the greater the tradeoff between
efﬁciency and privacy. An alternative would be to reorder
all entries every n epochs to obtain better efﬁciency.
Key Expiration. To reduce the time frame during which
a compromised key can be used by an attacker, users may
want to enforce key expiration. This would entail includ-
ing the epoch in which the public key is to expire as part
of the directory entry, and clients would need to ensure
that such keys are not expired when checking the consis-
tency of bindings. Furthermore, CONIKS could allow
users to choose whether to enforce key expiration on their
binding, and provide multiple security options allowing
users to set shorter or longer expiration periods. When the
key expires, clients can automatically change the expired
key and specify the new expiration date according to the
user’s policies.
Support for Multiple Devices. Any modern communi-
cation system must support users communicating from
multiple devices. CONIKS easily allows users to bind
multiple keys to their username. Unfortunately, device
pairing has proved cumbersome and error-prone for users
in practice [32, 67]. As a result, most widely-deployed
chat applications allow users to simply install software to
a new device which will automatically create a new key
and add it to the directory via password authentication.
The tradeoffs for supporting multiple devices are the
same as for key change. Following this easy enrollment
procedure requires that Alice enforce the cautious key
change policy, and her client will no longer be able to
automatically determine if a newly observed key has been
maliciously inserted by the server or represents the addi-
tion of a new device. Users can deal with this issue by
requiring that any new device key is authenticated with
a previously-registered key for a different device. This
means that clients can automatically detect if new bind-
ings are inconsistent, but will require users to execute a
manual pairing procedure to sign the new keys as part of
the paranoid key change policy discussed above.
7 Related Work
Certiﬁcate validation systems. Several proposals for
validating SSL/TLS certiﬁcates seek to detect fraudulent
certiﬁcates via transparency logs [4, 34, 38, 39, 53], or
observatories from different points in the network [4, 34,
54, 58, 68]. Certiﬁcate Transparency (CT) [39] publicly
logs all certiﬁcates as they are issued in a signed append-
only log. This log is implemented as a chronologically-
ordered Merkle binary search tree. Auditors check that
each signed tree head represents an extension of the pre-
vious version of the log and gossip to ensure that the log
server is not equivocating.
This design only maintains a set of issued certiﬁcates,
so domain administrators must scan the entire list of is-
sued certiﬁcates (or use a third-party monitor) in order
to detect any newly-logged, suspicious certiﬁcates issued
for their domain. We consider this a major limitation for
user communication as independent, trustworthy moni-
tors may not exist for small identity providers. CT is also
not privacy-preserving; indeed it was designed with the
opposite goal of making all certiﬁcates publicly visible.
Enhanced Certiﬁcate Transparency (ECT) [60], which
was developed concurrently [46] extends the basic CT
design to support efﬁcient queries of the current set of
valid certiﬁcates for a domain, enabling built-in revoca-
tion. Since ECT adds a second Merkle tree of currently
valid certiﬁcates organized as a binary search tree sorted
lexicographically by domain name, third-party auditors
must verify that no certiﬁcate appears in only one of the
trees by mirroring the entire structure and verifying all
insertions and deletions.
Because of this additional consistency check, audit-
ing in ECT requires effort linear in the total number of
changes to the logs, unlike in CT or CONIKS, which only
394  24th USENIX Security Symposium 
12
USENIX Association
require auditors to verify a small number of signed tree
roots. ECT also does not provide privacy: the proposal
suggests storing users in the lexicographic tree by a hash
of their name, but this provides only weak privacy as most
usernames are predictable and their hash can easily be
determined by a dictionary attack.
Other proposals include public certiﬁcate observato-
ries such as Perspectives [54, 58, 68], and more com-
plex designs such as Sovereign Keys [53] and AK-
I/ARPKI [4, 34] which combine append-only logs with
policy speciﬁcations to require multiple parties to sign
key changes and revocations to provide proactive as well
as reactive security.
All of these systems are designed for TLS certiﬁcates,
which differ from CONIKS in a few important ways. First,
TLS has many certiﬁcate authorities sharing a single,
global namespace. It is not required that the different
CAs offer only certiﬁcates that are consistent or non-
overlapping. Second, there is no notion of certiﬁcate or
name privacy in the TLS setting,11 and as a result, they use
data structures making the entire name-space public. Fi-
nally, stronger assumptions, such as maintaining a private
key forever or designating multiple parties to authorize
key changes, might be feasible for web administrators but
are not practical for end users.
Key pinning. An alternative to auditable certiﬁcate sys-
tems are schemes which limit the set of certiﬁcate au-
thorities capable of signing for a given name, such as
certiﬁcate pinning [16] or TACK [44]. These approaches
are brittle, with the possibility of losing access to a do-
main if an overly strict pinning policy is set. Deployment
of pinning has been limited due to this fear and most web
administrators have set very loose policies [35]. This dif-
ﬁculty of managing keys, experienced even by technically
savvy administrators, highlights how important it is to
require no key management by end users.
Identity and key services. As end users are accustomed
to interacting with a multitude of identities at various
online services, recent proposals for online identity ver-
iﬁcation have focused on providing a secure means for
consolidating these identities, including encryption keys.
Keybase [37] allows users to consolidate their online
account information while also providing semi-automated
consistency checking of name-to-key bindings by verify-
ing control of third-party accounts. This system’s primary
function is to provide an easy means to consolidate online
identity information in a publicly auditable log. It is not
designed for automated key veriﬁcation and it does not
integrate seamlessly into existing applications.
11Some organizations use “private CAs” which members manually
install in their browsers. Certiﬁcate transparency speciﬁcally exempts
these certiﬁcates and cannot detect if private CAs misbehave.
Nicknym [56] is designed to be purely an end-user key
veriﬁcation service, which allows users to register existing
third-party usernames with public keys. These bindings
are publicly auditable by allowing clients to query any
Nicknym provider for individual bindings they observe.
While equivocation about bindings can be detected in
this manner in principle, Nicknym does not maintain an
authenticated history of published bindings which would
provide more robust consistency checking as in CONIKS.
Cryptographically accountable authorities. Identity-
based encryption inherently requires a trusted private-key
generator (PKG). Goyal [28] proposed the accountable-
authority model, in which the PKG and a user cooperate
to generate the user’s private key in such a way that the
PKG does not know what private key the user has chosen.
If the PKG ever runs this protocol with another party
to generate a second private key, the existence of two
private keys would be proof of misbehavior. This concept
was later extended to the black-box accountable-authority
model [29, 61], in which even issuing a black-box decoder
algorithm is enough to prove misbehavior. These schemes
have somewhat different security goals than CONIKS in
that they require discovering two private keys to prove
misbehavior (and provide no built-in mechanism for such
discovery). By contrast, CONIKS is designed to provide
a mechanism to discover if two distinct public keys have
been issued for a single name.
VUFs and dictionary attacks. DNSSEC [15] provides a
hierarchical mapping between domains and signing keys
via an authenticated linked list. Because each domain
references its immediate neighbors lexicographically in
this design, it is possible for an adversary to enumerate
the entire set of domains in a given zone via zone walking
(repeatedly querying neighboring domains). In response,
the NSEC3 extension [40] was added; while it prevents
trivial enumeration, it suffers a similar vulnerability to
ECT in that likely domain names can be found via a dic-
tionary attack because records are sorted by the hash of
their domain name. Concurrent with our work on CON-
IKS, [27] proposed NSEC5, effectively using a veriﬁable
unpredictable function (also in the form of a deterministic
RSA signature) to prevent zone enumeration.
8 Conclusion
We have presented CONIKS, a key veriﬁcation system for
end users that provides consistency and privacy for users’
name-to-key bindings, all without requiring explicit key
management by users. CONIKS allows clients to efﬁ-
ciently monitor their own bindings and quickly detect
equivocation with high probability. CONIKS is highly
scalable and is backward compatible with existing se-
cure communication protocols. We have built a prototype
USENIX Association  
13
24th USENIX Security Symposium  395
CONIKS system which is application-agnostic and sup-
ports millions of users on a single commodity server.
As of this writing, several major providers are im-
plementing CONIKS-based key servers to bolster their
end-to-end encrypted communications tools. While au-
tomatic, decentralized key management without least a
semi-trusted key directory remains an open challenge, we
believe CONIKS provides a reasonable baseline of secu-
rity that any key directory should support to reduce user’s
exposure to mass surveillance.
Acknowledgments
We thank Gary Belvin, Yan Zhu, Arpit Gupta, Josh Kroll,
David Gil, Ian Miers, Henry Corrigan-Gibbs, Trevor Per-
rin, and the anonymous USENIX reviewers for their feed-
back. This research was supported by NSF Award TC-
1111734. Joseph Bonneau is supported by a Secure Us-
ability Fellowship from OTF and Simply Secure.
References
[1] Pidgin. http://pidgin.im, Retr. Apr. 2014.
[2] Protocol Buffers.
https://code.google.com/p/
protobuf, Retr. Apr. 2014.
[3] E. Barker, W. Barker, W. Burr, W. Polk, and M. Smid.
Special Publication 800-57 rev. 3. NIST, 2012.
[4] D. Basin, C. Cremers, T. H.-J. Kim, A. Perrig, R. Sasse,
and P. Szalachowski. ARPKI: attack resilient public-key
infrastructure. ACM CCS, 2014.
[5] D. J. Bernstein, N. Duif, T. Lange, P. Schwabe, and B.-Y.
Yang. High-speed high-security signatures. Journal of
Cryptographic Engineering, 2(2), 2012.
[6] D. J. Bernstein, M. Hamburg, A. Krasnova, and T. Lange.
Elligator: Elliptic-curve points indistinguishable from uni-
form random strings. ACM CCS, 2013.
[7] D. Boneh, B. Lynn, and H. Shacham. Short signatures
from the weil pairing. ASIACRYPT, 2001.
[8] N. Borisov, I. Goldberg, and E. Brewer. Off-the-record
communication, or, why not to use PGP. WPES, 2004.
[9] S. Braun, A. Flaherty, J. Gillum, and M. Apuzzo. Secret
to Prism program: Even bigger data seizure. Associated
Press, Jun. 2013.
[10] P. Bright. Another fraudulent certiﬁcate raises the same