User: 请解答这个和日志有关的问题Expert quote on entropy for uncrackable password Could anyone point to a quote in a published work - or suggest a recognised expert who might provide a quote - which answers the following question 


  How much entropy in a password would guarantee that it is secure against an offline guessing attack even if the attacker has the most powerful hardware in the world?


I am writing an article about creating a secure password based on true randomness and I would like to include a figure for guaranteed security but I would rather not offer my own opinions and arguments, I would like to quote a recognised expert or published work.

In more detail what is meant above by these terms is as follows.

If a password has enough entropy then presumably it is uncrackable in our current threat model, which is the one where the attacker has a cryptographic hash of the password and is repeatedly making a password guess, hashing the guess and comparing the hash.

By entropy I mean that the password creator has chosen randomly, with equal probability for each choice, a password from N possible passwords.
The entropy in bits is then log₂(N)

So quote needs to cover how much entropy in bits (or how big is N) to guarantee that the password is secure against this kind of attack, even if the attacker has the most powerful hardware in the world.

Assistant: There's a quote for you in this crypto.SE answer, by Bruce Schneier in Applied Cryptography (1996), pp. 157–8.

You can also find Bruce Schneier citing himself in his blog (2009), if you want an online citation.

Here is the full quote, in case of the links breaking:


  One of the consequences of the second law of thermodynamics is that a
  certain amount of energy is necessary to represent information. To
  record a single bit by changing the state of a system requires an
  amount of energy no less than kT, where T is the absolute temperature
  of the system and k is the Boltzman constant. (Stick with me; the
  physics lesson is almost over.)  
  
  Given that k = 1.38×10-16erg/°Kelvin,
  and that the ambient temperature of the universe is 3.2°Kelvin, an ideal
  computer running at 3.2°K would consume 4.4×10-16 ergs every time it
  set or cleared a bit. To run a computer any colder than the cosmic
  background radiation would require extra energy to run a heat pump.  
  
  Now, the annual energy output of our sun is about 1.21×1041 ergs. This
  is enough to power about
  2.7×1056 single bit changes on our ideal computer; enough state changes to put a 187-bit counter through all its values. If we built a
  Dyson sphere around the sun and captured all of its energy for 32
  years, without any loss, we could power a computer to count up to
  2192. Of course, it wouldn’t have the energy left over to perform any useful calculations with this counter.   
  
  But that’s just one star, and a
  measly one at that. A typical supernova releases something like 1051
  ergs. (About a hundred times as much energy would be released in the
  form of neutrinos, but let them go for now.) If all of this energy
  could be channeled into a single orgy of computation, a 219-bit
  counter could be cycled through all of its states.  
  
  These numbers have
  nothing to do with the technology of the devices; they are the
  maximums that thermodynamics will allow. And they strongly imply that
  brute-force attacks against 256-bit keys will be infeasible until
  computers are built from something other than matter and occupy
  something other than space.


Update: If you want a citation to assess the strength of a randomly generated password, you can use this website that is regularly updated with recommendations made by different institutes. A random password is equivalent to a symmetric key, so this is the value you are looking for. (Here is a wayback machine link, if this website were to close.)