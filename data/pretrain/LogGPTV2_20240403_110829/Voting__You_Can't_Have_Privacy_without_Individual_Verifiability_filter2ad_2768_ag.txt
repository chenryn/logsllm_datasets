National recommendation on e-voting.
[2] 2013. Ordonnance de la ChF sur le vote électronique (OVotE) du 13 décembre
2013 (Etat le 15 janvier 2014). Chancellerie fédérale ChF. Swiss recommendation
on e-voting.
[3] Martín Abadi and Cédric Fournet. 2001. Mobile Values, New Names, and Secure
Communication. In 28th ACM SIGPLAN-SIGACT Symposium on Principles of
Programming Languages (POPL’01). ACM, 104–115. https://doi.org/10.1145/
360204.360213
[4] Ben Adida. 2008. Helios: Web-based Open-Audit Voting. In 17th USENIX Security
Symposium (Usenix’08). 335–348.
[5] Michael Backes, Catalin Hritcu, and Matteo Maffei. 2008. Automated Verification
of Remote Electronic Voting Protocols in the Applied Pi-Calculus. In 21st IEEE
Computer Security Foundations Symposium, (CSF 2008). 195–209.
[6] J. Benaloh. 1987. Verifiable secret-ballot elections. Ph.D. Dissertation. Yale Univer-
sity.
[7] David Bernhard, Veronique Cortier, David Galindo, Olivier Pereira, and Bogdan
Warinschi. 2015. A comprehensive analysis of game-based ballot privacy defini-
tions. In Proceedings of the 36th IEEE Symposium on Security and Privacy (S&P’15).
IEEE Computer Society Press, 499–516.
[8] David Bernhard, Olivier Pereira, and Bogdan Warinschi. 2012. How Not to Prove
Yourself: Pitfalls of the Fiat-Shamir Heuristic and Applications to Helios. In
Advances in Cryptology - ASIACRYPT 2012 (LNCS), Vol. 7658. Springer, 626–643.
[9] David Bernhard and Ben Smyth. 2014. Ballot secrecy with malicious bulletin
boards. Cryptology ePrint Archive, Report 2014/822.
[10] Bruno Blanchet. 2016. Modeling and Verifying Security Protocols with the
Applied Pi Calculus and ProVerif. Foundations and Trends in Privacy and Security
1, 1–2 (Oct. 2016), 1–135.
[11] Ian Brightwell, Jordi Cucurull, David Galindo, and Sandra Guasch. 2015. An
overview of the iVote 2015 voting system. Available at https://www.elections.
nsw.gov.au.
[12] Pyrros Chaidos, Véronique Cortier, Georg Fuchsbauer, and David Galindo. 2016.
BeleniosRF: A Non-interactive Receipt-Free Electronic Voting Scheme. In 23rd
ACM Conference on Computer and Communications Security (CCS’16). Vienna,
Austria, 1614–1625.
[13] Benoît Chevallier-Mames, Pierre-Alain Fouque, David Pointcheval, Julien Stern,
and Jacques Traoré. 2010. On Some Incompatible Properties of Voting Schemes.
In Towards Trustworthy Elections 2010. 191–199.
[14] M. R. Clarkson, S. Chong, and A. C. Myers. 2008. Civitas: Toward a Secure Voting
System. In IEEE Symposium on Security and Privacy (S&P’08). IEEE Computer
Society, 354–368.
[15] Véronique Cortier, David Galindo, Stéphane Glondu, and Malika Izabachene.
2014. Election Verifiability for Helios under Weaker Trust Assumptions. In 19th
European Symposium on Research in Computer Security (ESORICS’14) (LNCS),
Vol. 8713. Springer, 327–344.
[16] Véronique Cortier, David Galindo, Ralf Küsters, Johannes Müller, and Tomasz
Truderung. 2016. SoK: Verifiability Notions for E-Voting Protocols. In 36th IEEE
Symposium on Security and Privacy (S&P’16). San Jose, USA, 779–798.
[17] Véronique Cortier, Niklas Grimm, Joseph Lallemand, and Matteo Maffei. 2017.
A type system for privacy properties. In 24th ACM Conference on Computer and
Communications Security (CCS’17). ACM, Dallas, USA, 409–423.
[18] Véronique Cortier and Ben Smyth. 2013. Attacking and fixing Helios: An analysis
[23] Rop Gonggrijp and Willem-Jan Hengeveld. 2007.
of ballot secrecy. Journal of Computer Security 21, 1 (2013), 89–148.
[19] Véronique Cortier and Cyrille Wiedling. 2012. A formal analysis of the Norwegian
E-voting protocol. In Proceedings of the 1st International Conference on Principles
of Security and Trust (POST’12) (Lecture Notes in Computer Science), Vol. 7215.
Springer, 109–128.
[20] Stéphanie Delaune, Steve Kremer, and Mark D. Ryan. 2006. Coercion-Resistance
and Receipt-Freeness in Electronic Voting. In 19th IEEE Computer Security Foun-
dations Workshop (CSFW’06). IEEE Computer Society Press, Venice, Italy, 28–39.
[21] Stéphanie Delaune, Steve Kremer, and Mark D. Ryan. 2009. Verifying Privacy-
type Properties of Electronic Voting Protocols. Journal of Computer Security 17,
4 (2009), 435–487. https://doi.org/10.3233/JCS-2009-0340
[22] David Galindo, Sandra Guasch, and Jordi Puiggali. 2015. 2015 Neuchâtel’s Cast-
as-Intended Verification Mechanism. In 5th International Conference on E-Voting
and Identity, (VoteID’15). 3–18.
Studying the
Nedap/Groenendaal ES3B Voting Computer: A Computer Security Per-
spective.
In USENIX Workshop on Accurate Electronic Voting Technology
(EVT’07).
[24] Sven Heiberg, Tarvi Martens, Priit Vinkel, and Jan Willemson. 2017. Improving
the Verifiability of the Estonian Internet Voting Scheme. In E-Vote-ID 2016 (LNCS),
Vol. 10141. Springer, 92–107.
[25] Steve Kremer, Mark D. Ryan, and Ben Smyth. 2010. Election verifiability in
electronic voting protocols. In 15th European Symposium on Research in Com-
puter Security (ESORICS’10) (LNCS), Vol. 6345. Springer. https://doi.org/10.1007/
978-3-642-15497-3_24
[26] Ralf Küsters, Tomasz Truderung, and Andreas Vogt. 2010. Accountabiliy: Defini-
tion and Relationship to Verifiability. In 17th ACM Conference on Computer and
Communications Security (CCS’10). 526–535.
[27] Ralf Küsters, Tomasz Truderung, and Andreas Vogt. 2011. Verifiability, Privacy,
and Coercion-Resistance: New Insights from a Case Study. In 32nd IEEE Sympo-
sium on Security and Privacy (S&P 2011). IEEE Computer Society, 538–553.
[28] R. L. Rivest and W. D. Smith. 2007. Three Voting Protocols: ThreeBallot, VAV and
Twin. In USENIX/ACCURATE Electronic Voting Technology (EVT 2007).
discovered by Peter Roenne and then described in the paper [17].
[29] Peter Roenne. [n. d.]. Private communication. ([n. d.]). The attack has been
[30] Peter Ryan. 2008. Prêt à Voter with Paillier encryption. Mathematical and
Computer Modelling 48, 9–10 (2008), 1646–1662.
[31] Drew Springall, Travis Finkenauer, Zakir Durumeric, Jason Kitcat, Harri Hursti,
Margaret MacAlpine, and J. Alex Halderman. 2014. Security Analysis of the
Estonian Internet Voting System. In 2014 ACM SIGSAC Conference on Computer
and Communications Security, Gail-Joon Ahn, Moti Yung, and Ninghui Li (Eds.).
ACM, 703–715.
[32] Scott Wolchok, Eric Wustrow, J. Alex Halderman, Hari K. Prasad, Arun Kankipati,
Sai Krishna Sakhamuri, Vasavya Yagati, and Rop Gonggrijp. 2010. Security
Analysis of India’s Electronic Voting Machines. In 17th ACM Conference on
Computer and Communications Security (CCS’10). Chicago, IL.
[33] Scott Wolchok, Eric Wustrow, Dawn Isabel, and J. Alex Halderman. 2012. Attack-
ing the Washington, D.C. Internet Voting System. In Financial Cryptography and
Data Security (FC’12).
14
Appendix A SYMBOLIC PROOF
A.1 Assumptions summary
We simply recall here the assumptions described in the core of the paper (Sections 2 and 3.4). The numbers will be useful to refer to the
assumptions in the proofs. We also formally define alternative assumptions only sketched in the core of the paper, like the possibility to
assume a special “independent” vote instead of a neutral vote.
Notations: if k ∈ N and v ∈ V, k · v denotes the multiset containing k instances of v. If V is a multiset of votes, and v a vote, we denote
V(v) the number of instances of v in V .
(1) The tallying process is assumed to output terms representing the result of the election on a channel cr , i.e.
∀α . ∀(tr , ϕ) ∈ trace(Pα). out(cr , r) ∈ tr ⇒ ∃V . ϕ(r) ∈ R(ρ(V)).
(2) The representation function is assumed to be injective: ∀r (cid:44) r′. R(r) ∩ R(r′) = ∅.
(3) The counting function is assumed to have the partial tally property: ∀V , V ′. ρ(V ⊎V ′) = ρ(V)∗ ρ(V ′). ∗ is an associative, commutative
(4) The voting processes must be election determinate, i.e. satisfy
operation.
′
, ϕ, ϕ
, x, V .
∀α, t, t
′
(t =τ t
ϕ(x) ∈ R(ρ(V))) ⇒ ϕ
′(x) ∈ R(ρ(V))
′ ∧ (t .out(cr , x), ϕ) ∈ trace(Pα) ∧ (t
′
.out(cr , x), ϕ
′) ∈ trace(Pα) ∧
(5) The voting processes are assumed to be voting friendly, i.e. we assume that for all voter a ∈ A, there exists t′′ such that for all α
satisfying a (cid:60) dom(α),
• for all (t, ϕ) ∈ trace(Pα), such that t = t′.out(cr , x) for some t′, x, for all v, there exists tr, ψ such that tr =τ t′′, Voted(a, v) ∈ tr,
(t′.tr .out(cr , x),ψ) ∈ trace(Pα∪{a(cid:55)→v }), and ∀V . ϕ(x) ∈ R(ρ(V)) ⇒ ψ(x) ∈ R(ρ(V ⊎ {|v|})).
• and for all t′, x such that blocking(t′.out(cr , x), Pα), for all v, tr, ψ such that tr =τ t′′, blocking(t′.tr .out(cr , x), Pα∪{a(cid:55)→v }).
Our result holds provided one of the two following assumptions is true:
(6) There exists a neutral vote vneutral ∈ V, such that ρ({|vneutral|}) is neutral for ∗.
(7) There exists a special vote vspecial ∈ V, which is counted separately in the result, as briefly sketched in the core of the paper. Formally,
vspecial must enjoy the following properties.
• the result associated with a multiset determines the number of instances of vspecial in it
′(vspecial).
′) =⇒ V(vspecial) = V
. ρ(V) = ρ(V
∀V , V
• the count of vspecial can be simplified
′
∀V , V
′
, k. ρ(V ⊎ k · vspecial) = ρ(V
′ ⊎ k · vspecial) =⇒ ρ(V) = ρ(V
′).
For example, for ρhom, all the votes are special, therefore this property always holds. For ρmix , it depends on the set of valid votes. In
the standard case where a vote is a selection of candidates (for example between k1 and k2 candidates), then a special vote is, for
instance, a vote that includes the selection of an extra candidate, not used before.
A.1.1 Properties. We recall here the definitions of the individual verifiability and privacy properties (presented in 3.3), and we define two
properties used as pivots in the proof.
• Individual verifiability:
V1(t, ϕ) def= ∀t
′
, x . (t = t
′
.out(cr , x)) ⇒ ∃Vc . ϕ(x) ∈ R(ρ({|v | ∃a. Voted(a, v) ∈ t|} ⊎ Vc))
def= ∀α . ∀(t, ϕ) ∈ trace(Pα). V1(t, ϕ).
V
• Privacy:
• First pivot property:
P = ∀α . ∀a, b ∈ A\dom(α). ∀v1, v2. Pα∪{a(cid:55)→v1,b(cid:55)→v2} ≈t Pα∪{a(cid:55)→v2,b(cid:55)→v1}
def= ∀α . ∀a ∈ A\dom(α). ∀v1, v2 ∈ V. ∀t, t′, ϕ, ϕ′, V , V ′.
F
[ t =τ t′ ∧
(t, ϕ) ∈ trace(Pα∪{a(cid:55)→v1}) ∧
(t′, ϕ′) ∈ trace(Pα∪{a(cid:55)→v2}) ∧
result(t, ϕ, V) ∧ result(t′, ϕ′, V ′) ]
ρ(V ′ ⊎ {|v1|}) = ρ(V ⊎ {|v2|}).
15
=⇒
• Second pivot property:
F F
def= ∀α . ∀(t, ϕ) ∈ trace(Pα). ∀V , Vchange. ∀Vwanted ⊆ {|v | ∃a. Voted(a, v) ∈ t|}.
result(t, ϕ, V) ⇒
|Vchange| = |Vwanted| ⇒
∃Vc . ρ(V) ∗ ρ(Vchange) = ρ(Vwanted) ∗ ρ(Vc)
A.2 Theorem
Lemma A.1 (Privacy implies F). Under assumptions 1, 2, 3, 4, and 5,
P ⇒ F
Proof. We prove this by contradiction: assuming F does not hold, we construct an attack on privacy.
Assume F is false. Hence there exists a scenario where changing the vote of one agent does not change the result by one. That is to say,
there exist an affectation of votes α, an agent a (cid:60) dom(α), votes v1, v2 ∈ V, traces (t, ϕ) ∈ trace(Pα∪{a(cid:55)→v1}) and (t′, ϕ′) ∈ trace(Pα∪{a(cid:55)→v2}),
such that t =τ t′,and two multisets V , V ′, such that result(t, ϕ, V), result(t′, ϕ′, V ′), and ρ(V ′ ⊎ {|v1|}) (cid:44) ρ(V ⊎ {|v2|}).
Since result(t, ϕ, V), there exist x, t1 such that t = t1.out(cr , x) and ϕ(x) ∈ R(ρ(V)). Similarly, there exist y, t′
1.out(cr , y)
and ϕ′(y) ∈ R(ρ(V ′)). Since t =τ t′, x = y.
Note that we necessarily have v1 (cid:44) v2: indeed, if v1 = v2 then (t, ϕ) and (t, ϕ′) are traces of the same process. Since ϕ(x) ∈ R(ρ(V)), by
assumption 4, this implies that ϕ′(x) ∈ R(ρ(V)). Since we already know that ϕ′(x) ∈ R(ρ(V ′)), by assumption 2, we have ρ(V) = ρ(V ′). Thus,
as v1 = v2, we have ρ(V) ∗ ρ({|v2|}) = ρ(V ′) ∗ ρ({|v1|}), which is contradictory. Hence v1 (cid:44) v2.
1 such that t′ = t′
The attack on privacy consists in the fact that, since changing a’s vote does not produce a change of exactly one in the result, even in
Formally, let b (cid:60) dom(α) ∪ {a}. By assumption 5, there exist sequences of actions tb, t′
presence of another agent b whose vote is the opposite of a’s, the result will be different depending on the vote of a.
, and frames ψ, ψ ′, such that
(t1.tb .out(cr , x),ψ) ∈ trace(Pα∪{a(cid:55)→v1,b(cid:55)→v2}),
′
′) ∈ trace(Pα∪{a(cid:55)→v2,b(cid:55)→v1}),
(t
1.t
′
Voted(b, v2) ∈ tb , Voted(b, v1) ∈ t
b ,
Since ρ(V ′ ⊎ {|v1|}) (cid:44) ρ(V ⊎ {|v2|}), by assumption 2, we have ψ(x) (cid:44) ψ ′(x).
We have constructed two frames, obtained by the same actions in Pα∪{a(cid:55)→v1,b(cid:55)→v2} and Pα∪{a(cid:55)→v2,b(cid:55)→v1}, which yield different results
2 ,ψ ′′) ∈
Indeed, let us denote t2 def= t1.tb .out(cr , x) and t′
2
2, then by assumption 4 we have ψ ′′(x) ∈ R(ρ(V ′⊎{|v1|})). Hence, by assumption 2 as ρ(V ⊎{|v2|}) (cid:44)
□
for the election. Using assumption 4, this lets us prove that these two processes are not ≈t -equivalent.
trace(Pα∪{a(cid:55)→v2,b(cid:55)→v1}), if t′′
ρ(V ′ ⊎ {|v1|}), we have ψ ′′(x) (cid:60) R(ρ(V ⊎ {|v2|})), which implies that ψ, ψ ′′ are not statically equivalent.
1.t′
b .out(cr , x). We have (t2,ψ) ∈ trace(Pα∪{a(cid:55)→v1,b(cid:55)→v2}). For any trace (t′′
ψ(x) ∈ R(ρ(V ⊎ {|v2|})), and ψ
′
b .out(cr , x),ψ
2 =τ t2 =τ t′
def= t′
′
b , tb =τ t
′(x) ∈ R(ρ(V
′ ⊎ {|v1|})).
b
Thus, Pα∪{a(cid:55)→v1,b(cid:55)→v2} ̸≈t Pα∪{a(cid:55)→v2,b(cid:55)→v1}. This violates P, which concludes the proof.
Lemma A.2 (Privacy and F imply F F). Under assumptions 1, 2, 3, 4, and 5,
(P ∧ F) ⇒ F F
Proof. Assume that both P and F hold. Let α be an affectation of votes, let (t, ϕ) ∈ trace(Pα), let V be such that result(t, ϕ, V), i.e. there
exist t′, x such that t = t′.out(cr , x) and ϕ(x) ∈ R(ρ(V)). Let Vwanted ⊆ {|v | ∃a. Voted(a, v) ∈ t|}, and Vchange such that |Vchange| = |Vwanted|.
To prove F F, we need to show that the result in this trace augmented with Vchange contains at least the subset Vwanted of the (intended)
votes of the honest voters. That is to say, we must show that there exists Vc such that ρ(V) ∗ ρ(Vchange) = ρ(Vwanted) ∗ ρ(Vc).
The idea of the proof is to compare ρ(V) to the result ρ(V ′) obtained by turning, one by one, all votes from Vwanted into the votes from
Vchange, and performing the same sequence of actions. As we will see, this is possible, otherwise P would break; and V ⊎ Vchange contains
more instances of the honest votes than V ′ ⊎ Vwanted, since F holds.
Let us denote the Voted events appearing in t by
Voted(a1, v1), . . . , Voted(al , vl)
for some pairwise distinct agents a1, . . . , al ∈ Voters(t), and some l ∈ N.
By definition, each element of Vwanted is associated with one of these Voted events. Let m
assume that Vwanted = {|v1, . . . , vm|}.
def= {|v′
Note that |Vchange| is also equal to m by assumption. Let us then denote Vchange
Since, by assumption on the form of the processes, the Voted(a, v) event can only be emitted by the process Voter(a, v, c) for some
credential c, we have α(ai) = vi for all i ∈(cid:74)1, m(cid:75).
def= |Vwanted|. Without loss of generality, we may
1, . . . , v′
m|}.
16
For i ∈(cid:74)0, m(cid:75), let αi denote the affectation of votes obtained from α by turning the first i votes from Vwanted to Vchange, i.e.
if j ∈(cid:74)1, i(cid:75);
• αi(aj) = v′
• αi(aj) = vj if j ∈(cid:74)i + 1, m(cid:75);
• αi(a) = α(a) if a ∈ dom(α) is not one of the aj, j ∈(cid:74)1, m(cid:75).
j
Let β
def= αm. Note that α0 = α, and that all the αi have the same domain.
Let us show that for all i, the same actions as t can be performed in Pαi
with the same agents emitting Voted events, i.e. that
∀i ∈(cid:74)0, k1(cid:75). ∃ti . ti =τ t ∧ ¬blocking(ti , Pαi).
By contradiction, assume this property does not hold, and let i be the smallest index that falsifies it. Hence,
∀ti . ti =τ t ⇒ blocking(ti , Pαi).