protection is required. Each server’s work can be divided
into two parts: processing clients and communicating
with other servers. Most expensive interactions are with
the clients (including verifying the ZKPs etc.), which can
be performed on a single server and is independent of κ.
The interaction among servers is simply data exchange
and there is no complex computation involved.
Data exchange among the servers serves two purposes:
x 109
Ratio of Running Times
ElGamal
Paillier
7
6
5
4
3
2
1
0
Enron
EM
RAND
Figure 2: Running time ratios between homomorphic en-
cryption based solutions and P4P.
reconstructing shared secrets when necessary (the ﬁnal
sum in the end of each iteration and the commitments
during the veriﬁcation) and reaching agreement regard-
ing a user’s status (each server needs to verify that the
user computes a share of the commitments correctly).
And since each server is semi-honest, for the second part
they only need pass the ﬁnal conclusion, veriﬁcation of
the ZKPs can be done on only one of the servers.
For constructing the ﬁnal sum, all servers must send
their shares to the server hosting ARPACK. The later
will receive a total of 8κm bytes (assuming data is en-
coded using double precision) which is about 8κ MB if
m = 106. For the consistency check, during each it-
eration, one server is selected as the “master”. All other
servers sends their shares of the commitments to the mas-
ter. This includes 3n large integers in Zq (3 for each
user) from each server.
In addition, each non-master
server also sends to the master an n-bit bitmap, encod-
ing whether each user computes the commitments to the
shares correctly. The master will reconstruct the com-
plete commitments and verify the ZKPs. It then broad-
casts an n-bit bitmap encoding whether each user passes
the consistency check to all other servers. For the mas-
ter, the total communication cost is receiving 3n(κ − 1)
integers in Zq and κn-bit strings and sending (κ − 1)n
bits. With n = 106 and |q| = 1024, these amount to
12
384 (κ − 1) MB and approximately 0.1 (κ − 1) MB, re-
spectively. For other servers, the sending and receiving
costs are approximately 384 MB and 0.1 MB, respec-
tively. We believe such cost is practical for small κ (e.g.,
3 or 4). Note that the master does not have to be collo-
cated with the ARPACK engine so the servers can take
turns to serve as the master to share the load.
As for the computation associated with using κ servers
(the part that is independent of κ has been discussed
earlier and omitted here), the master needs to perform
3n(κ − 1) multiplications in Z∗
q. Using our benchmark,
this amounts to 0.186(κ− 1) seconds for n = 106 users.
Again we believe this is practical for small κ. The other
servers do not need to do any extra work.
7.3 Scalability
We also experimented with a few very large matrices,
with dimensionality ranging from tens of thousands to
over a hundred million. They are document-term or user-
query matrices that are used for latent semantic analysis.
To facilitate the tests, we did not include the data ver-
iﬁcation ZKPs, as our previous benchmarks show they
amount to an insigniﬁcant fraction of the cost. Due to
space and resource limit we did not test how performance
varies with dimensionality and other parameters. Rather,
these results are meant to demonstrate the capability of
our system, which we have shown to maintain privacy at
very low cost, to handle large data sets at various conﬁg-
urations.
Table 3 summarizes some of the results. The running
time measures the time of a complete run, i.e., from the
start of the job till the results are safely written to disk.
It includes both the computation time of the server (in-
cluding the time spent on invoking the ARPACK engine)
and the clients (which are running in parallel), and the
communication time. In the table, frontend processors
refer to the machines that interact with the users directly.
Large-scale systems usually use multiple frontend ma-
chines, each serving a subset of the users. This is also a
straightforward way to parallelize the aggregation pro-
cess, i.e., each frontend machine receives data from a
subset of users and aggregates them before forwarding
to the server. On one hand, the more frontend machines
the faster the sub-aggregates can be computed. On the
other hand, the server’s communication cost is linear in
the number of frontend processors. The optimal solution
must strike a balance between the two. Due to resource
limitation, we were not able to use the optimal conﬁgu-
ration for all our tests. The results are feasible even in
these sub-optimal cases.
8 Conclusion
In this paper we present a new framework for privacy-
preserving distributed data mining. Our protocol is based
on secret sharing over small ﬁeld, achieving orders of
magnitude reduction in running time over alternative so-
lutions with large-scale data. The framework also admits
very efﬁcient zero-knowledge tools that can be used to
verify user data. They provide practical solutions for
handling cheating users. P4P demonstrates that cryp-
tographic building blocks can work harmoniously with
existing tools, providing privacy without degrading their
efﬁciency. Most components described in this paper
have been implemented and the source code is avail-
able at http://bid.berkeley.edu/projects/p4p/. Our goal is
to make it a useful tool for developers in data mining
and others to build privacy preserving real-world appli-
cations.
References
[1] ALDERMAN, E., AND KENNEDY, C. The Right to Privacy. DI-
ANE Publishing Co., 1995.
[2] BEAVER, D., AND GOLDWASSER, S. Multiparty computation
with faulty majority. In CRYPTO ’89.
[3] BEERLIOV ´A-TRUB´INIOV ´A, Z., AND HIRT, M. Perfectly-secure
mpc with linear communication complexity. In TCC 2008 (2008),
Springer-Verlag, pp. 213–230.
[4] BEIMEL, A., NISSIM1, K., AND OMRI, E. Distributed private
data analysis: Simultaneously solving how and what. In CRYPTO
2008.
[5] BEN-DAVID, A., NISAN, N., AND PINKAS, B. Fairplaymp: a
system for secure multi-party computation. In CCS ’08 (2008),
ACM, pp. 257–266.
[6] BEN-OR, M., GOLDWASSER, S., AND WIGDERSON, A.
Completeness theorems for non-cryptographic fault-tolerant dis-
tributed computation. In STOC’88 (1988), ACM, pp. 1–10.
[7] BLUM, A., DWORK, C., MCSHERRY, F., AND NISSIM, K.
In PODS ’05 (2005),
the SuLQ framework.
Practical privacy:
ACM Press, pp. 128–138.
[8] BLUM, A., LIGETT, K., AND ROTH, A. A learning theory ap-
proach to non-interactive database privacy. In STOC 08.
[9] BOAZ BARAK, E. A. Privacy, accuracy, and consistency too: a
holistic solution to contingency table release. In PODS ’07.
[10] CANNY, J. Collaborative ﬁltering with privacy via factor analy-
sis. In SIGIR ’02.
[11] CANNY, J. Collaborative ﬁltering with privacy. In IEEE Sympo-
sium on Security and Privacy (2002), pp. 45–57.
[12] CHEN, H., AND CRAMER, R. Algebraic geometric secret shar-
ing schemes and secure multi-party computations over small
ﬁelds. In CRYPTO 2006.
[13] CHU, C.-T., KIM, S. K., LIN, Y.-A., YU, Y., BRADSKI, G.,
NG, A. Y., AND OLUKOTUN, K. Map-reduce for machine learn-
ing on multicore. In NIPS 2006 (2006).
[14] COHEN, W. W.
Enron email dataset.
http://www-
2.cs.cmu.edu/˜enron/.
[15] CRAMER, R., AND DAMG ˚ARD, I. Zero-knowledge proof for
In
ﬁnite ﬁeld arithmetic, or: Can zero-knowledge be for free?
CRYPTO ’98 (1998), Springer-Verlag.
13
Table 3: SVD of Large Matrices
n
100,443
12,046,488
149,519,201
37,389,030
1,363,716
33,193,487
m k
200
200
250
300
200
200
176,573
440,208
478,967
366,881
2,611,186
1,949,789
No. Frontend Processors Time (hours)
1.4
6.0
8.3
9.1
14.8
28.0
32
128
128
128
1
128
Iterations
1287
354
1579
1839
1260
1470
[16] DAMG ˚ARD, I., ISHAI, Y., KRØIGAARD, M., NIELSEN, J. B.,
AND SMITH, A. Scalable multiparty computation with nearly op-
timal work and resilience. In CRYPTO 2008 (Berlin, Heidelberg,
2008), Springer-Verlag, pp. 241–261.
[17] DAS, A. S., DATAR, M., GARG, A., AND RAJARAM, S. Google
news personalization: scalable online collaborative ﬁltering. In
WWW ’07 (2007), ACM Press, pp. 271–280.
[18] DHANJANI, N.
Initial
[ec2]:
http://www.dhanjani.com/archives/2008/04/.
thoughts
security
Amazon’s
on
elastic
compute
cloud
implications.
[33] GOLDWASSER, S., AND LEVIN, L. Fair computation of gen-
eral functions in presence of immoral majority. In CRYPTO ’90
(1991), Springer-Verlag, pp. 77–93.
[34] HIRT, M., AND MAURER, U. Complete characterization of ad-
versaries tolerable in secure multi-party computation (extended
abstract). In PODC ’97.
[35] HIRT, M., AND MAURER, U. Player simulation and general
adversary structures in perfect multiparty computation. Journal
of Cryptology 13, 1 (2000), 31–60.
[36] KEARNS, M. Efﬁcient noise-tolerant learning from statistical
[19] DINUR, I., AND NISSIM, K. Revealing information while pre-
queries. In STOC ’93 (1993), pp. 392–401.
serving privacy. In PODS ’03 (2003), pp. 202–210.
[20] DUAN, Y. Privacy without noise. In CIKM ’09.
[21] DUAN, Y., AND CANNY, J.
Practical private computation
and zero-knowledge tools for privacy-preserving distributed data
mining. In SDM ’08 (2008).
[22] DUAN, Y., WANG, J., KAM, M., AND CANNY, J. A secure
online algorithm for link analysis on weighted graph. In Proc. of
the Workshop on Link Analysis, Counterterrorism and Security,
SDM 05, pp. 71–81.
[23] DWORK, C. Ask a better question, get a better answer a new
approach to private data analysis. In ICDT 2007 (2007), Springer,
pp. 18–27.
[24] DWORK, C., KENTHAPADI, K., MCSHERRY, F., MIRONOV, I.,
AND NAOR, M. Our data, ourselves: Privacy via distributed noise
generation. In EUROCRYPT 2006 (2006), Springer.
[25] DWORK, C., MCSHERRY, F., NISSIM, K., AND SMITH, A. Cal-
ibrating noise to sensitivity in private data analysis. In TCC 2006
(2006), Springer, pp. 265–284.
[26] FEIGENBAUM, J., NISAN, N., RAMACHANDRAN, V., SAMI,
R., AND SHENKER, S. Agents’ privacy in distributed algorithmic
mechanisms. In Workshop on Economics and Information Securit
(Berkeley, CA, May 2002).
[27] FIAT, A., AND SHAMIR, A. How to prove yourself: Practical
solutions to identiﬁcation and signature problems. In CRYPTO
86.
[28] FITZI, M., HIRT, M., AND MAURER, U. General adversaries in
unconditional multi-party computation. In ASIACRYPT ’ 99.
[29] GENNARO, R., RABIN, M. O., AND RABIN, T. Simpliﬁed
vss and fast-track multiparty computations with applications to
threshold cryptography. In PODC ’98, pp. 101–111.
[30] GOLDREICH, O. Foundations of Cryptography: Volume 2 – Ba-
sic Applications. Cambridge University Press, 2004.
[37] LEHOUCQ, R. B., SORENSEN, D. C., AND YANG, C. ARPACK
Users’ Guide: Solution of Large-Scale Eigenvalue Problems with
Implicitly Restarted Arnoldi Methods. SIAM, 1998.
[38] LINDELL, Y., AND PINKAS, B. Privacy preserving data mining.
Journal of cryptology 15, 3 (2002), 177–206.
[39] LINDELL, Y., PINKAS, B., AND SMART, N. P. Implementing
two-party computation efﬁciently with security against malicious
adversaries. In SCN ’08.
[40] MALKHI, D., NISAN, N., PINKAS, B., AND SELLA, Y.
Fairplay—a secure two-party computation system. In SSYM’04:
Proceedings of the 13th conference on USENIX Security Sympo-
sium (Berkeley, CA, USA, 2004), USENIX Association, pp. 20–
20.
[41] MCSHERRY, F., AND MIRONOV, I. Differentially private rec-
ommender systems: Building privacy into the netﬂix prize con-
tenders. In KDD ’09.
[42] MCSHERRY, F., AND TALWAR, K. Mechanism design via dif-
ferential privacy. In FOCS ’07.
[43] NISSIM, K., RASKHODNIKOVA, S., AND SMITH, A. Smooth
In STOC ’07
sensitivity and sampling in private data analysis.
(2007), ACM, pp. 75–84.
[44] PAILLIER, P. Trapdooring discrete logarithms on elliptic curves
over rings. In ASIACRYPT ’00.
[45] PEDERSEN, T. Non-interactive and information-theoretic secure
veriﬁable secret sharing. In CRYPTO ’91.
[46] PINKAS, B., SCHNEIDER, T., SMART, N., AND WILLIAMS,
S. Secure two-party computation is practical. Cryptology ePrint
Archive, Report 2009/314, 2009.
[47] STEWART, G. W., AND SUN, J.-G. Matrix Perturbation Theory.
Academic Press, 1990.
[48] TREFETHEN, L. N., AND III, D. B. Numerical Linear Algebra.
SIAM, 1997.
[31] GOLDREICH, O., MICALI, S., AND WIGDERSON, A. How to
[49] VAIDYA, J., AND CLIFTON, C. Privacy-preserving k-means
play any mental game. In STOC ’87.
clustering over vertically partitioned data. In KDD ’03.
[32] GOLDREICH, O., AND OREN, Y. Deﬁnitions and properties
of zero-knowledge proof systems. Journal of Cryptology 7, 1
(1994), 1–32.
[50] WRIGHT, R., AND YANG, Z. Privacy-preserving bayesian net-
work structure computation on distributed heterogeneous data. In
KDD ’04 (2004), pp. 713–718.
14
[51] YANG, Z., ZHONG, S., AND WRIGHT, R. N. Privacy-preserving
classiﬁcation of customer data without loss of accuracy. In SDM
2005 (2005).
[52] YAO, A. C.-C. Protocols for secure computations. In FOCS ’82
(1982), IEEE, pp. 160–164.
Notes
1Most mining algorithms need to bound the amount of noise in the
data to produce meaningful results. This means that the fraction of
cheating users is usually below a much lower threshold (e.g. α <
20%).
15