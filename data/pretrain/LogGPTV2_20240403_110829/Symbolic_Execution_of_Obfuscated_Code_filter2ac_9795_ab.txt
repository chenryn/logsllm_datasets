VM’s dispatch point is equal to the number of opcodes in
the VM’s instruction set. The resulting search space con-
tains all the programs the interpreter is capable of running
and exploring it exhaustively is impractical even for small
interpreters. Furthermore, even if we hypothesize a success-
ful exploration of the search space, i.e., discovering all of
the interpreted programs executable by the interpreter, it
is only the interpreter whose execution paths are fully ex-
plored, not the interpreted byte-code. Note that this is a
more general situation than handling of symbolic memory
addresses although the issue with symbolic addresses is still
a problem with symbolic execution engines [9, 33].
It is not diﬃcult to cause the VIP to become symbolic: all
that is needed is to make the VIP input dependent at some
point, e.g., by transforming control dependencies into di-
rect data dependencies. Moreover, this attack against sym-
bolic execution can be used with arbitrary predicates, which
makes it more ﬂexible than that of Sharif et al. [36], which
is restricted to equality predicates.
3.2 Conditional Jump to Conditional Jump
Transformation
The previous section discussed how an obfuscator could
use explicit arithmetic on the condition code ﬂags to turn
conditional jumps into indirect jumps that are harder to
analyze symbolically. Here we discuss how similar arithmetic
operations can be used to transform the predicate associated
with a conditional jump to a completely diﬀerent predicate,
as illustrated by the following example.
Example 3.2. Consider the following code fragment:
1
2
3
4
5
6
7
8
r0 := input();
FLAGS := test(r0)
push(FLAGS)
r1 := pop()
r2 := r1 >> 4
push(r2)
FLAGS := pop()
jpe L
/* x86: test */
/* x86: pushf */
/* x86: shr */
/* x86: popf */
/* jpe: jump if parity even */
Instructions 2–4 above check the input value and move the
condition code ﬂags into register r1. This register is then
right-shifted by four bits (instruction 5) and the resulting
value is moved back into the condition code ﬂags (instruc-
tions 6, 7), which is used to perform a conditional jump
(instruction 8). The conditional branch instruction, jpe, is
not a very common one: it stands for “jump if parity is even”
and is taken if the parity ﬂag is set. In reality, however, the
bit that is actually being tested is not the parity ﬂag, but
rather the bit that was shifted into the parity ﬂag’s position
by instruction 5—namely, the zero ﬂag. In other words, the
the condition that is really being tested is whether the input
value read into r0 by instruction 1 is zero or not; however
this is being done using a very diﬀerent predicate.2
The approach illustrated above can also be used to con-
struct opaque predicates, i.e., conditional jumps that are
either always taken or always not taken.
The issue described here is orthogonal to that of trans-
forming an input value to a diﬀerent value and applying
a diﬀerent predicate to the transformed value [36], since it
involves using architecture-speciﬁc knowledge to transform
meta-information. The commercial obfuscation tool EXE-
Cryptor [38] uses this approach to produce long sequences
of this kind of bit-shuﬄing operations to hamper analysis.
Note that while concolic analyses have to map conditional
jump instructions to predicates on values, reasoning about
such bit-level manipulations of condition code ﬂags addition-
ally requires ﬁne-grained taint-tracking. Conventional byte-
or word-level taint tracking can lead to signiﬁcant overtaint-
ing in the presence of the sorts of bit manipulation illustrated
above. Overtainting occurs when imprecision in taint prop-
agation causes the taint analysis to determine values to be
tainted, and deemed to be symbolic, when that are in fact
independent of the inputs appear to be dependent on them.
Conditional branches on expressions involving such spurious
symbolic variables are then treated as candidates for gener-
ating inputs that can lead to alternative execution paths,
resulting in additional computational load on the constraint
solver and degrading the overall performance of the system.
In the worst case, a very large number of such spurious sym-
bolic variables and associated conditional branches can use
up so much resources that the system crashes or is unable to
make progress on identifying inputs that would in fact cause
the program to take alternative paths.
3.3 Symbolic Code
Symbolic code can be seen as an extension of a code obfus-
cation technique commonly used in malware, where the pro-
gram modiﬁes the code region ahead of the program counter,
such that execution then falls into the modiﬁed code. Sym-
bolic code extends this idea to carry out the code modiﬁca-
tion using an input-derived value. The idea is that, if the
input meets some appropriate condition, the modiﬁed bytes
encode a jump instruction to some desired address; other-
wise, the modiﬁed bytes encode some non-jump instructions.
The eﬀect is that execution branches to the target of the
jump if and only if the input satisﬁes that condition. The
key characteristic of symbolic code is that this is done with-
out executing an explicit comparison or conditional jump
2We use the relatively uncommon and unstealthy jpe in-
struction in this example to highlight how diﬀerent the pred-
icate of the jump instruction can be from the actual condi-
tion on the input value. In practice one would expect the
obfuscated code to use more common instructions.
735call
cmp
jz
call
L: call
get_input()
eax, TRIGGER
L
abort()
payload()
get_input()
eax, TRIGGER
al, 0xEB
ebx, L1
ecx, L2
ecx, ebx
ah, cl
word [L1], ax
call
sub
add
lea
lea
sub
mov
mov
nop
nop
L1: call
L2: call
abort()
payload()
call
sub
add
lea
lea
sub
mov
mov
pc→ jmp
L1: call
L2: call
get_input()
eax, trigger
al, 0xEB
ebx, L1
ecx, L2
ecx, ebx
ah, cl
word [L1], ax
L2
abort()
payload()
(a) Original code
(b) Obfuscated code executed with
(c) Obfuscated code executed with
non-trigger input
trigger input
Figure 3: An example of symbolic code
on an input-derived symbolic value, which means that if the
input condition is not satisﬁed, standard concolic analysis
does not see a conditional jump in the instruction stream
and therefore does not consider the possibility of an alter-
nate execution path.
Figure 3 shows an example of this approach. Figure 3(a)
shows the original code where the behavior of the code is
based on an input value. The code in 3(b) shows the ob-
fuscated code statically where the obfuscation tries to hide
the control transfer based on some trigger value. The code
uses the input value to overwrite an instruction in the code
in such a way that the execution results in the control being
transferred to a code when the value of the input is the de-
sired one. For other inputs either the instruction constructed
is an illegal instruction or the control does not reach the hid-
den code. 3(c) shows the code where the input triggers the
execution of the hidden code. With the input value being
the desired value, the computed instruction is a jump which
transfers the control to the label L2.
Symbolic code is a straightforward variation on an ob-
fuscation technique that has long been used in malware:
namely, to modify a few bytes ahead of the execution and
have execution fall into the modiﬁed bytes. This is illus-
trated in Figure 4, which shows instructions from the Net-
Sky.aa worm (ﬁrst encountered in 2004). Figure 4(a) shows
the ﬁrst few instructions from a static disassembly of the
code. When this code is executed, the add instructions at
addresses 0x403e64 and 0x403e68 modify ﬁve bytes at ad-
dress 0x403e6e; execution then falls into the newly created
instructions, thereby installing an exception handler at ad-
dress 0x5cbc32, which is then used to ﬁeld the exception
raised via a (deliberate) null-pointer dereference by the mov
instruction at address 00403e84. The main diﬀerence that
the symbolic code technique brings to bear is that the bytes
used to create the modiﬁed code are input-dependent.
Symbolic code can be used to conceal trigger-based behav-
iors, i.e., behaviors that are exhibited only under speciﬁc
external or environmental triggers [3]. Existing proposals
for detecting such latent behaviors using symbolic execution
assume that the control transfers associated with these trig-
gers rely on conditional branches [3, 13]. Symbolic code can
evade such approaches by conditionally creating an uncondi-
tional jump instruction, e.g., by using input values to create
the modiﬁed instruction(s) in such a way that only the de-
sired input (trigger) will result in the desired (malicious)
execution, but for the rest of values the malicious part does
not get exposed to the analysis. Since the resulting con-
trol transfer does not use a conditional branch instruction,
existing approaches will not consider it as a candidate for
symbolic analysis to identify inputs that can trigger alter-
native execution paths.
4. HANDLING OBFUSCATIONS
Since the primary focus of this work is to improve con-
colic analysis of obfuscated code, we do not address other
potential problems with concolic analyses, e.g., path selec-
tion or dealing with system calls. The key idea behind our
approach is to use a combination of bit-level architecture-
aware taint analysis, bit-level constraints on symbolic values
derived from condition-code ﬂags, and architecture-aware
constraint generation, to reason about and identify inputs
that can cause diﬀerent control ﬂow paths to be taken.
4.1 Bit-Level Dynamic Taint Analysis
This section considers dynamic taint analysis, where taint
is propagated through the instructions in an execution trace.
The same static instruction can give rise to many diﬀerent
instruction instances at runtime, with diﬀerent operands, re-
sults, and condition code ﬂags; dynamic taint analysis treats
these diﬀerent runtime instances diﬀerently. To avoid unnec-
essary repetition, we use the term “instruction” to refer to
these dynamic instances of instructions: i.e., diﬀerent run-
time instances of the same static instruction are referred to
as diﬀerent instructions.
Taint propagation algorithms generally propagate taint
information at the byte- or word-level, i.e., maintain a taint
bit for each byte or word of data. However, this turns out to
be too imprecise for our needs: our experiences with obfus-
cations, e.g., those that use bit manipulations to obfuscate
conditional jumps, as discussed in Sections 3.1 and 3.2, indi-
cate that the ability to track taint at the level of individual
bits can be crucial for dealing with obfuscated code. We
therefore carry out taint propagation at bit level granular-
ity. Additionally, since concolic analysis involves reasoning
about the conditions under which diﬀerent execution paths
may be taken, we keep track of taint sources arising from
73600403e5f
00403e64
00403e67
00403e68
00403e6e
00403e6f
00403e70
00403e72
00403e74
00403e7b
00403e82
00403e84
mov eax, 0x403e6e
add byte [eax], 0x28
inc eax
add dword [eax], 0x1234567
nop
retf
jbe 0x4c
call dword near [eax+0x64]
push dword [0x0]
mov [fs:0x0], esp
xor eax, eax
mov [eax], ecx
00403e5f
00403e64
00403e67
00403e68
00403e6e
00403e73
00403e74
00403e7b
00403e82
00403e84
mov eax, 0x403e6e
add byte [eax], 0x28
inc eax
add dword [eax], 0x1234567
mov eax, 0x5cbc32
push eax
push dword [fs:0x0]
mov [fs:0x0], esp
xor eax, eax
mov [eax], ecx
(a) Static disassembly
(b) Runtime code sequence
Figure 4: Self-modifying code in the NetSky.aa worm
condition code ﬂags. This is done using taint tags or mark-
ings. Taint markings can be of two kinds:
• Otherwise, for each destination bit dst[j] of I (includ-
ing condition code ﬂags):
1. A ‘generic taint’ marking that indicates that the taint
originated from an input value rather than a condition
code ﬂag.
2. A triple (cid:104)ins, ﬂag, polarity(cid:105) where ins refers to (a par-
ticular dynamic instance of) an instruction in an ex-
ecution trace; ﬂag encodes a condition code ﬂag; and
polarity indicates whether the bit that the taint mark-
ing refers to has the same value as that of the original
ﬂag value it was derived from or whether it has been
inverted.
Taint analysis takes as input an execution trace and pro-
cesses the instructions in order, propagating taint bits and
taint markings. For each instruction I, taint is propagated
from its inputs to its outputs using a taint mapping func-
tion that is based on the semantics of I. Values obtained
as inputs (e.g., set by system calls) are considered to have
all of their bits tainted. For instructions that set condition
code ﬂags (which include most arithmetic and logical opera-
tions as well as the test and cmp instructions), if any input
operands are tainted then taint is propagated to the ﬂags
along with the appropriate taint markings. Let (cid:96)[i] denote
the ith bit position of an operand (i.e., location or value) (cid:96).
Taint propagation for an instruction I in the trace is done
as follows:
• If none of the source operands of I are tainted, or if the
value of a destination bit dst[i] is ﬁxed and indepen-
dent of the values of the source operands, then dst[i]
is marked ‘not tainted’. (In general, it is necessary to
take implicit ﬂows into account in order to avoid un-
dertainting [8]. Existing approaches to incorporating
implicit information ﬂows into taint analyses [11, 21]
can be adapted to our purposes. Since this is not the
focus of our work, we do not discuss it further here.)
• Otherwise, if all of the source operands of I have the
marking ‘generic taint’ then:
– each non-condition-code destination operand of I
gets the taint marking ‘generic taint’;
– each condition code ﬂag f aﬀected by I gets the
taint marking (cid:104)I, f, 1(cid:105).
– if the value of dst[j] can be determined from some
particular source operand bit src[k], then:
∗ if dst[j] has the same value as src[k] then
dst[j] gets the same taint marking as src[k];
∗ otherwise dst[j] gets the same taint marking
as src[k] but with the polarity reversed.
– Otherwise: dst[j] is marked tainted and its taint
mark is determined as follows:
∗ Each condition code ﬂag f gets a new tag
∗ Each non-condition-code bit gets the mark
marking (cid:104)I, f, 1(cid:105).
‘generic taint’.
We keep track of taint markings in terms of bit values—
namely, a condition code ﬂag along with its polarity—to
simplify reasoning about code obfuscations that manipulate
these bits. However, a taint marking (cid:104)I, ﬂag, polarity(cid:105) also
corresponds to a predicate on one or more values in the com-
putation. Since a particular ﬂag may be set diﬀerently by
diﬀerent instruction operations, the speciﬁcs of the predicate
will depend on the instruction I that set the ﬂag. For exam-
ple, the cmp (compare) and sub (subtract) instructions set
CF if there is a borrow in the result; some forms of the integer
multiply instruction imul set CF if the result of multiplica-
tion has been truncated; and some bit-rotate instructions
(e.g., rcl, rcr) include CF in the rotation and so set it de-
pending on the bit that is moved into it due to the rotation.
Given a taint marking t ≡ (cid:104)I, f, p(cid:105), we can use the semantics
of the instruction I, together with the ﬂag f and the polar-
ity p, to determine the predicate associated with the taint
marking t. We refer to this predicate as the ﬂag condition
for t, written FlagCond(t).
Taint markings allow us to improve the precision of the
taint analysis by identifying operations on bits that originate
from the same value. As an example, consider the following
instruction sequence:
1
2
3
4
5
6
r0 := input();
FLAGS := test(r0)
push(FLAGS)
r1 := pop()
r2 := !r1
r3 := r1 ^ r2
/* x86: test */
/* x86: pushf */
/* x86: neg */
/* x86: xor */
737In this example, instructions 2–4 check the input value and
move the condition code ﬂags into register r1 (in a real-life
example the input might be the result of timing the execu-
tion of a fragment of code, and the check might determine
whether the value falls within a range indicating that the
program is not running within an emulator). Instructions
5–7 then carry out a variety of bit manipulations on the ﬂag
bits, e.g., as performed in obfuscation tools such as VMPro-
tect and EXECryptor. In this example, our taint analysis
will determine that the bitwise negation operation in instruc-
tion 5 ﬂips the bits of r1 into r2, which means that, after
instruction 5, the low bit of r2 is diﬀerent from that of r1,
and therefore that the low bit of r3 after the xor operation