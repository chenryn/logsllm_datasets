over the measurements s in the density function for the recent window (s ∈ Ri),
we have ai =
s Ri(s) log Ri(s)
Si(s) .
This computation can be updated incrementally in constant time as one mea-
surement leaves the recent window and another enters it. To prevent division by
(cid:3)
Community Epidemic Detection Using Time-Correlated Anomalies
369
)
C
(
e
r
o
c
S
y
t
i
n
u
m
m
o
C
x
a
M
0
5
.
0
6
4
.
0
2
4
.
0
DoS (1%)
DoS (10%)
Content Spoof (i)
Content Spoof (ii)
Content Spoof (iii)
Privilege Escalation
Memory Thief
CPU Thief
y
t
i
s
n
e
D
5
1
0
1
5
0
Client Scores
Community Scores
Epidemic Threshold (V)
0
5
10
15
20
25
30
Infected Clients (d)
0.30
0.35
0.40
0.45
0.50
0.55
Client or Community Score
Fig. 3. Syzygy detected all of the attacks
once the infection size was suﬃciently
large. The horizontal line is the epidemic
threshold V .
Fig. 4. Our client model
is incomplete
and noisy; anomalous behavior is com-
mon. The community scores, however, are
extremely steady.
zero, the measurements in the recent window are included in the distribution
Si. By default, each client reports this score whenever there is new information
available to the model (e.g., a request or hiaton), but it is straightforward to add
feedback or batching to the client-server protocol to curb communication traﬃc
(we do so in Section 5.3).
4.2 Results
Figure 3 shows the results of our detection experiments; there were no false
positives in these experiments and detection latency was never more than a
couple of seconds. Although some attacks are diﬃcult to detect when only a few
machines are infected (low d), Syzygy is able to correctly detect each attack once
a suﬃciently large number of clients are infected. In the case of the third (iii)
content spoof attack, the behavior is anomalous enough on even a single client
for our simple response time model to detect it; this is not true for most of the
other attacks, meaning the community was crucial.
We achieved these high detection rates despite the fact that our behav-
ior model was incomplete and noisy. Figure 4 shows part of the distribution
of anomaly scores reported by individual healthy clients. In fact, these values
ranged as high as 0.8 but we have truncated the graph for readability. In con-
trast, however, note that the healthy community scores stayed within a very
small range (the dashed red line is actually a very slim Gaussian). The epidemic
threshold V is the dotted line to the right of the cluster of community scores.
Because the community scores are such a stable signal, they enable Syzygy both
to reliably provide a low false positive rate and to be sensitive to minor—but
not isolated—changes in client behavior.
In the subsequent sections, we discuss the beneﬁts of distributed training, the
eﬀects of heterogenous hardware and user behavior, performance and overhead
on a real network deployment, predicting and setting the false positive rate,
performance in communities with thousands of clients, and Syzygy’s robustness
against tainted training data and advanced exploit behavior (like mimicry).
370
A.J. Oliner, A.V. Kulkarni, and A. Aiken
5 Deployment Experiments
For practical use, our method assumes that (i) a real deployment can scale to
large numbers of clients across a realistic network topology and (ii) despite mi-
nor client variations, such as hardware and conﬁguration diﬀerences, healthy
anomaly score distributions are similar across clients. We verify that these as-
sumptions hold in practice by deploying Syzygy on several dozen Linux work-
stations on a university campus. Most of these machines were 3.0 GHz Intel
Core2 Duos with 2 GB RAM and the CentOS 5 operating system; exceptions
include two laptops and (brieﬂy) the Syzygy server, itself. Syzygy monitored the
Firefox web browser via strace on Linux. Over the course of these two weeks
of experiments, Syzygy reported no false positives.
5.1 Model
In the next two sections, we use a model of client behavior (diﬀerent from Sec-
tion 4) that uses short sequences of a program’s system calls. This information
can be gathered with low overhead and has been shown to be useful [9, 14]. We
use sequences of six system calls to be consistent with previous work [7, 14, 22],
but instead of using one of the existing stide or t-stide algorithms [33], the
model uses an information theoretic approach with several additional modiﬁca-
tions. During training, Syzygy computes a frequency distribution of system call
sequences of length six and the maximum observed time between consecutive sys-
tem call invocations. The computations are extremely similar to Section 4.1, but
use system call sequences as measurements, instead of request response times.
Whenever a system call is invoked, the model concatenates the name of the
call onto a sequence consisting of the previous ﬁve and increments the counter
associated with that sequence. For example, on Mac OS X, while executing the
command echo hi, we generate the following period-delimited sequence:
s = sigaction.writev.read.select.select.exit.
Even when idle, many applications will continue to invoke system calls (e.g.,
polling for new work or user input). This behavior acts as a kind of heartbeat
for the program, and its absence indicates unusual behavior just as much as
the presence of, say, unusual system call sequences. For example, during one
such execution of echo hi, the maximum time between system call invocations,
according to dtrace, was 375 μs.
Using this kind of information about call sequences and timing, we construct
a model analogous to the one for request response times in Section 4.1. The
only diﬀerences are that the tables used to construct Si and Ri are indexed by
sequences and the recent window Wi has units of sequences. The anomaly signal
is computed as described in Section 4.1.
5.2 Distributed Training
Over a period of roughly two weeks, we collected normal usage traces from 35
active clients. During the day, a median of 8 clients were active at a time. The
Community Epidemic Detection Using Time-Correlated Anomalies
371
s
e
c
n
e
u
q
e
S
e
u
q
n
U
i
f
o
n
o
i
t
c
a
r
F
0
.
1
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
)
)
C
(
d
s
(
n
o
i
t
i
a
v
e
D
d
r
a
d
n
a
S
t
0
.
3
0
.
2
0
1
.
0
0
.
Community Makeup:
Actual
Outliers Removed
High SD Removed
Homogeneous
Homogeneous (High SD)
0.0
0.2
0.4
0.6
0.8
1.0
0
5
10
15
20
25
30
35
Fraction of Training Set
Community Size (n)
Fig. 5. Distributed training happens
quickly: 25% of the data exhibits 90% of
the unique sequences. Retraining a model
(e.g., after a software upgrade) is eﬃcient
Fig. 6. Community scores converge in
real data; variance comes from client vari-
ance, not system conﬁguration or work-
load heterogeneity
ﬁrst week of these traces is our training data and contains more than 2.2 billion
sequences, of which approximately 180,000 are unique. As shown in Figure 5,
most of the sequences were seen quickly (90% within the ﬁrst 25% of the trace).
The fact that training speeds up with community size is consistent with pre-
vious work [21]; Syzygy’s distinctive use of the community occurs during the
monitoring phase (Section 5.3).
During this training period, while the clients were reporting both the complete
sequences and timestamps at an average of 100 KB/s, the average bandwidth
usage at the server was 1160 KB/s (the peak was 3240 KB/s). The clients re-
quired less than 1% CPU each for the strace process and Syzygy script. With
all 35 clients active, the server-side script was using 13% of the processor, on
average, with peaks as high as 32%.
Even though the training data includes machines that are unlike most of the
cluster, such as two laptops, we still ﬁnd that the distribution of community
anomaly scores within the training community converges toward a tight normal
distribution. Figure 6 shows the standard deviation of the community score for
increasing numbers of clients; in the ﬁgure, the clients “join” the community
in reverse order of average anomaly score (so n = 1 represents the client with
the highest average anomaly score). To evaluate the impact of heterogeneity,
we also plot four hypothetical communities: “Outliers Removed,” where the two
laptops and the Syzygy server were replaced with the client with the lowest
standard deviation, “High SD Removed,” where the ﬁve clients with the high-
est standard deviations were replaced with ﬁve clones of the machine with the
lowest standard deviation, and “Homogeneous” and “Homogeneous (High SD),”
which are communities of n clones of the client with the lowest average anomaly
score and highest standard deviation, respectively. The results show that vari-
ance in the community score comes not from client heterogeneity (the client in
“Homogeneous (High SD)” was a normal cluster machine) but from client vari-
ance. The results also show that a larger community can compensate for client
variance.
Section 3.3 shows how to compute the threshold V , given a desired false
positive rate and the training data; these analytical results correspond well with
what we observe experimentally. Using the data from our deployment, Figure 7
plots the appropriate choice of V for a desired false positive rate (note the log
scale) and community size (n). The units of the false positive rate, for this
372
A.J. Oliner, A.V. Kulkarni, and A. Aiken
)
V
l
(
d
o
h
s
e
r
h
T
5
4
3
2
1
0
n=
1
2
4
8
16
35
e
t