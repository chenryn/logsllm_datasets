whose URL was clicked, and anonymized information
about the email and the URL, as shown in Table 1.
3.3 LDAP Logs
LBNL uses corporate Gmail to manage its employees’
emails.2 Each time an employee successfully logs in,
Gmail logs the user’s corporate email address, the time
when the login occurred, and the IP address from which
the user authenticated. From these LDAP logs, we
received anonymized information about login sessions
where (1) the login IP address had never been used by the
user during any previous successful login, (2) the user
had more than 25 prior logins, and (3) the login IP ad-
dress did not belong to LBNL’s network. The last row of
Table 1 shows the anonymized data in each entry of the
LDAP logs.
4 Challenge: Diversity of Benign Behavior
Prior work has used machine learning to identify
spearphishing attacks, based on suspicious content in
email headers and bodies [8,19]. While that work detects
several spearphishing attacks, their optimal false positive
1Shortened URLs are expanded to their ﬁnal destination URLs.
2Email between two employees also ﬂows through corporate
Gmail, which allows our detector to scan “internal” emails for lateral
spearphishing attacks.
Time span
Total emails
Unique sender names
(names in From)
Unique sender addresses
(email addresses in From)
Emails with clicked URLs
Unique sender names
(names in From)
Unique sender addresses
(email addresses in From)
# total clicks on embedded URLs
Unique URLs
Unique hostnames
Logins from new IP address
# geolocated cities among all
new IP addresses
# of emails sent during sessions
where employee logged in from
new IP address
Mar 1, 2013– Jan 14, 2017
372,530,595
3,415,471
4,791,624
2,032,921
246,505
227,869
30,011,810
4,014,412
220,932
219,027
7,937
2,225,050
Table 2: Summary of data in the three logs. Note that some
emails contain multiple URLs, some or all of which may be
visited multiple times by multiple recipients (thus, there are
more clicked-URLs than emails that contain clicked-URLs).
rates (FPR) are 1% or higher, which is far too high for
our setting: a FPR of 1% would lead to 3.7 million false
alarms on our dataset of nearly 370 million.
In this section, we identify several issues that make
spearphishing detection a particularly difﬁcult challenge.
Speciﬁcally, when operating on a real-world volume of
millions of emails per week, the diversity of benign be-
havior produces an untenable number of false positives
for detectors that merely look for anomalous header val-
ues.
4.1 Challenge 1: Senders with Limited
Prior History
A natural detection strategy is to compare the headers
of the current email under analysis against all histor-
ical email headers from the current email’s purported
sender. For example, consider a name spoofer who at-
tempts to spearphish one of Alice’s team members by
sending an email with a From header of Alice Good
. An anomaly-based detector
could identify this attack by comparing the email’s From
address () against all From ad-
dresses in prior email with a From name of Alice
Good.
However,
this approach will not detect a different
spearphishing attack where neither the name nor the
address of the From header have ever been seen be-
fore: Alice  or HR Team
In this previ-
.
ously unseen attacker setting, there is no prior history
to determine whether the From address is anomalous.
472    26th USENIX Security Symposium
USENIX Association
Figure 2: Distribution of the number of emails sent per From
name. Nearly 40% of all From names appear in only one
email and over 60% of all From names appear in three or fewer
emails.
To address this gap, one might ﬂag all emails with a
new or previously unknown From name (e.g., any email
where the From name has been seen in two or fewer
emails leads to an alert). Unfortunately, this approach
generates an overwhelming number of alerts in practice
because millions of From names are only ever seen in a
few emails. Figure 2 shows the distribution of the num-
ber of emails per From name in our dataset. In particu-
lar, we ﬁnd that over 60% of From names sent three or
fewer emails and over 40% of From names sent exactly
one email. Thus, even if one ran a detector retrospec-
tively to alert on every email with a From name that had
never been seen before and did not eventually become
an active and engaged sender, it would produce over 1.1
million alerts: a false positive rate of less than 1% on
our dataset of nearly 370 million emails, but still orders
of magnitude more than our target. Even though spam
might account for a proportion of these emails with new
From names, LBNL’s security staff investigated a ran-
dom sample of these emails and found a spectrum of be-
nign behavior: event/conference invitations, mailing list
management notices, trial software advertisements, and
help support emails. Thus, a detector that only lever-
ages the traditional approach of searching for anomalies
in header values faces a stiﬂing range of anomalous but
benign behavior.
4.2 Challenge 2: Churn in Header Values
Even if we were to give up on detecting attacks that
come from previously unseen From names or addresses,
a detector based on header anomalies still runs into yet
another spectrum of diverse, benign behavior. Namely,
header values for a sender often change for a variety of
benign reasons. To illustrate this, we consider all From
Figure 3: Distribution of the total number of From addresses
per From name (who send over 100 emails) across all emails
sent by the From name. Over half (52%) of these From names
sent email from two or more From addresses (i.e., have at least
one new From address).
names that appear in at least 100 emails (our dataset con-
tains 125,172 of them) and assess the frequency at which
these names use a new From email address when send-
ing email.
Figure 3 shows the cumulative distribution of the to-
tal number of From email addresses per From name.
From this graph, we see that even among From names
with substantial history (sent over 100 emails), there is
considerable variability in header values: 52% of these
From names send email from more than one From email
address. We ﬁnd that 1,347,744 emails contain a new
From email address which has never been used in any
of the From name’s prior emails. Generating an alert for
each of these emails would far exceed our target of 10
alerts per day.
This large number of new email addresses per From
name stems from a variety of different sources: work
vs. personal email addresses for a user, popular hu-
man names where each email address represents a
different person in real
life (e.g., multiple people
named John Smith), professional society surveys,
and functionality-speciﬁc email addresses (e.g. Foo
, Foo ,
Foo ). While it might be
tempting to leverage domain reputation or domain simi-
larity between a new From address and the From name’s
prior addresses to ﬁlter out false positives, this fails in
a number of different cases. For example, consider the
case where Alice suddenly sends email from a new
email address, whose domain is a large email hosting
provider; this could either correspond to Alice sending
email from her personal email account, or it might rep-
USENIX Association
26th USENIX Security Symposium    473
100101102103104105106107108Total number of emails sent per From: name0.00.20.40.60.81.0Cumul fraction of From: names110100100010000Total number of From: addresses per name0.00.20.40.60.81.0Cumul frac of From: names w/ > 100 emailsresent a name spoofer using a Gmail account with a
spoofed From name.
Given the prevalence of emails with anomalous, yet
benign, header values, a practical detector clearly needs
to leverage additional signals beyond an email’s header
values. Some prior academic work has attempted to
incorporate stylometry features from an email’s body
to identify spearphishing attacks [19]; however, as dis-
cussed earlier, these systems have false positive rates
of 1% or higher, which would lead to millions of false
alarms, a prohibitively high number for practical usage.
In the following section, we present a novel approach that
leverages a different set of signals based on the underly-
ing nature of spearphishing attacks.
5 Detector Design
At a high level, our detector consists of three stages il-
lustrated in Figure 4 and described below: a feature ex-
traction stage (§ 5.1 and § 5.2), a nightly scoring stage
(§ 5.4), and a real-time alert generation stage (§ 5.5).
Conceptually, our work introduces two key ideas that en-
able our detector to detect a wide range of attacks, while
achieving a practical volume of false positives that is over
200 times lower than prior work. First, our detector ex-
tracts two sets of reputation-based features that indepen-
dently target the two key stages of a spearphishing attack
identiﬁed in our attack taxonomy. Second, we introduce
a novel, unsupervised anomaly detection technique that
enables our detector to automatically rank a set of unla-
beled events and select the most suspicious events for the
security team to review. We ﬁrst discuss each of these
elements and then show how to combine them for our
real-time detector.
5.1 Features per Attack Stage
Fundamentally, spearphishing attacks aim to trick their
recipients into performing a dangerous action described
in the email.
If the attacker fails to persuade the vic-
tim into taking the action, the attack fails. For credential
spearphishing, the dangerous action is clicking on a link
in an email that leads the victim to a credential phish-
ing website.3 Thus, we analyze every email that contains
a link that a user clicked on; we call this clicked link a
click-in-email event.
As discussed in our taxonomy (§ 2.1), spearphishing
attacks consist of two necessary stages: the lure stage,
where the attacker persuades the victim to trust him, and
the exploit stage, where the victim performs a dangerous
3While an adversary could attempt to spearphish an employee’s cre-
dentials by fooling them into including the credentials in an email re-
sponse, this attack variant is likely more difﬁcult to successfully exe-
cute given employee awareness from security training and education.
Based on their multi-year incident database, LBNL has not observed
such attacks succeed in practice.
action for the attacker. This insight leads to the ﬁrst core
idea in our approach: we craft two sets of features to tar-
get both of these stages of a spearphishing attack. Prior
work has often used features that capture only the lure
or the exploit; our insight is that we can do signiﬁcantly
better by using both types of features.
Accordingly, we have two classes of features: domain
reputation features, and sender reputation features.
In
order to steal the victim’s credentials, the attacker must
link to a site under her control. Because spearphish-
ing attacks are so tightly targeted, visits to this mali-
cious website will presumably be rare among the histor-
ical network trafﬁc from the organization’s employees.
Therefore, for each click-in-email event, the domain rep-
utation features characterize the likelihood that an em-
ployee would visit that URL, based on its (fully quali-
ﬁed) domain. The sender reputation features character-
ize whether the sender of that email falls under one of the
impersonation models outlined in our taxonomy. Effec-
tively, the sender reputation features capture elements of
the lure (by recognizing different types of spooﬁng that
the attacker might use to gain the victim’s trust), and the
domain reputation features capture characteristics of the
exploit.
Because the sender reputation features differ for each
impersonation model (§ 5.2.2), our detector actually con-
sists of three sub-detectors, one for each impersonation
model. As discussed below (§ 5.5), if any of the sub-
detectors ﬂags an email as spearphishing, the detector
treats it as an attack and generates an alert for the se-
curity team.
5.2 Features
Each sub-detector uses a feature vector containing four
scalar values, two for domain reputation and two for
sender reputation; Appendix A contains a summary ta-
ble of these features, which we discuss below. As we
show later (§ 6), these compact feature vectors sufﬁce to
detect a wide-range of attacks while achieving a practical
volume of false positives.
5.2.1 Domain Reputation Features
All sub-detectors use the same two features to character-
ize the reputation of a link that the user clicked on. Intu-
itively, if few employees from the enterprise have visited
URLs from the link’s domain, then we would like to treat
a visit to the email’s link as suspicious. Additionally, if
employees have never visited URLs from a domain until
very recently, then we would also like to treat visits to
the domain’s URLs as risky. Based on these two ideas,
the ﬁrst feature counts the number of prior visits to any
URL with the same fully qualiﬁed domain name (FQDN)
as the clicked URL; this is a global count across all em-
ployees’ visits, from the NIDS logs. The second fea-
474    26th USENIX Security Symposium
USENIX Association
Figure 4: Overview of our real-time detector, which leverages output from a nightly batch job during its real-time analysis, as
described in § 5.4 and § 5.5. As emails arrive, our detector leverages historical logs to extract and save three feature vectors (one FV
per impersonation model) for each URL in the email (§ 5.1). Using the network trafﬁc logs, our detector logs all clicks on URLs
embedded in emails. Each night, our detector runs our anomaly scoring algorithm on the FVs from a sliding window over the
past month’s clicked URLs and stores a ComparisonSet of the month’s most suspicious FVs for each impersonation model (§ 5.4).
Observing real-time network trafﬁc, our detector sees clicked email URLs, compares the real-time click’s feature vector for each
impersonation model against the ComparisonSet, and generates an alert for the security team if needed (§ 5.5).
ture counts the number of days between the ﬁrst visit by
any employee to a URL on the clicked link’s FQDN and
the time when the clicked link’s email initially arrived at
LBNL.
We chose to characterize a clicked link’s reputation
in terms of its FQDN, rather than the full URL, be-
cause over half of the clicked URLs in our dataset had
never been visited prior to a click-in-email event. Con-
sequently, operating at the granularity of the full URL
would render the URL reputation features ineffective be-
cause the majority of URLs would have the lowest possi-
ble feature values (i.e., never been visited prior to the
email recipient). Additionally, using a coarser granu-
larity such as the URL’s registered domain name or its
effective second-level domain could allow attackers to
acquire high reputation attack URLs by hosting their
phishing webpages on popular hosting sites (e.g., at-
tacker.blogspot.com). By deﬁning a URL’s reputation in
terms of its FQDN, we mitigate this risk.
5.2.2 Sender Reputation Features
Name Spoofer: As discussed earlier (§ 2.1.1), in this at-
tacker model Mallory masquerades as a trusted entity by
spooﬁng the name in the From header, but she does not
spoof the name’s true email address. Because the trusted
user that Mallory impersonates does not send email from
Mallory’s spoofed address, the spearphishing email will
have a From email address that does not match any of
the historical email addresses for its From name. There-
fore, the ﬁrst sender reputation feature counts the number
of previous days where we saw an email whose From
header contains the same name and address as the email
being scored.
Also, in this attacker model, the adversary spoofs the
From name because the name corresponds to someone
known and trusted. If that name did not correspond to
someone trustworthy or authoritative, there would be no
point in spooﬁng it, or it would manifest itself under our
previously unseen attacker threat model. Thus, the sec-
ond sender reputation feature for a clicked email reﬂects
the trustworthiness of the name in its From header. We
measure the trustworthiness of a name by counting the
total number of weeks where this name sent at least one
email for every weekday of the week. Intuitively, the idea
is that From names that frequently and consistently send
emails will be perceived as familiar and trustworthy.
Previously Unseen Attacker:
In this threat model
(§ 2.1.1), Mallory chooses a name and email address