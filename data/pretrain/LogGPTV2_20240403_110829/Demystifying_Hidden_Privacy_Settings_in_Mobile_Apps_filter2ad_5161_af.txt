in Baidu map (see Section V-B). In its new version 10.1.0
published in Feb. 2th, 2018, developers put the setting into a
newly created view titled Track Setting and add an indicator
(cid:22)(cid:25)(cid:17)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:53:00 UTC from IEEE Xplore.  Restrictions apply. 
TABLE VIII: Privacy leakage in different languages
# of privacy settings
# of privacy settings that leak privacy by default
# of hidden privacy settings
# of hidden privacy settings that leak privacy by default
English
329
110
Chinese
270
75
Total
599
185
260 (79.03%)
209 (77.41%)
469 (78.30%)
93 (84.55%)
59 (78.67%)
152 (82.16%)
TABLE IX: Privacy leakage in different categories
Privacy settings
Opt-in
to leak
Total
Hidden privacy settings
Total
Opt-in
to leak
Category
On-device data
Users’ personal proﬁle
Users’ social connections
Users’ behaviors
Users’ posted content
76
84
61
80
70
Anti-spam
228
52
69
61
64
46
(68.42%)
(82.14%)
(100.00%)
(80.00%)
(65.71%)
177
(77.63%)
22
50
20
28
27
38
16
44
20
22
19
31
(72.73%)
(88.00%)
(100.00%)
(78.57%)
(70.37%)
(81.58%)
pointing to the view under the Privacy Settings view, which
is easy for users to ﬁnd. Another example is BMW Motorrad
Connected (an app for BMW bike) which has a privacy setting
“Help us improve the range of products from BMW Motorrad”.
The setting lets users control whether or not to allow the
app to collect user location, trace and other usage data in the
background. In the old version (1.3), it was put in the view
titled Legal notices and the UI-path does not even include the
Settings view. In the new version (1.4.2), developers move the
privacy setting into the view titled Data privacy which is much
easier to locate. Similar changes happen on popular apps (e.g.,
KingsChat with 500,000+ downloads and Web Browser with
10 million downloads). We ﬁnd that among the 132 apps, 98
have been downloaded more than 100 thousand times and 54
installed over 1 million times. Therefore, it appears to us that
the developers of popular apps attach more importance to the
designs of privacy settings and are likely making more efforts
to improve their usability.
D. Privacy Leakage by Default
The problem will be even more severe when hidden privacy
settings are set to leak users’ private information by default.
Taking Facebook as an example, 22 out of 34 privacy settings
are set to leak privacy by default, among which 12 are hidden.
To further understand this problem, we randomly selected 100
English apps from Google Play and 100 Chinese apps from
Baidu market, and checked 599 privacy settings manually. The
results are astonishing: 469 (78.30%) privacy settings are set to
leak privacy by default (79.03% for English apps and 77.41%
for Chinese apps, see Table VIII). Among the hidden privacy
settings, 82.16% are set to leak by default, which means that
users cannot quickly ﬁnd them and stop the leakage of their
privacy. Such privacy includes all the six categories in Table I.
We further counted the number of privacy settings and hidden
ones in each category for the 200 apps. The results are shown
in Table IX. To our surprise, 100% of users’ social connections
are exposed by default. Also in this category, about one-third
of the settings are hidden, which makes it very hard for users
to switch them off.
Further, our participants reported that the texts of some
privacy settings are confusing. Especially, some texts look like
protecting users’ privacy (e.g., the setting “Hide location”), but
the setting is switched off by default, which means the location
is not hidden. Maybe developers want such description to let
users feel that the app is protecting users’ privacy. Similar texts
include “Do not show people I follow and groups I’ve joined”
(in the social app Blued with over 14 million downloads)
and “Do not show my listening history to friends” (in the top
popular music app QQ music with over 550 million downloads
in China). We manually analyzed 599 privacy settings in the
200 apps, and found 21.87% of the privacy settings have this
problem (20.05% for English apps and 24.07% for Chinese
apps). Most users just leave the settings there without changing
the default status, unintentionally leaking their privacy.
VI. SUGGESTIONS FOR DEVELOPERS
Based on our measurement, we ﬁnd that
the problem
of hidden privacy settings is severe and pervasive. A good
guidance on how to design privacy settings for developers is
in urgent need. One may think of the UI design principles
from big companies like Google and Apple [18], [28], [29].
However, they only give very rough suggestions such as
“keeping an app consistent by using system-provided interface
elements, standard text styles, uniform terminology”, and more
importantly, they do not focus on privacy settings. GSMA [30],
an originally-European trade body that represents the interests
of mobile network operators worldwide, makes “Privacy Design
Guidelines for Mobile Application Development” [3] that
requires developers to ensure that defaulting settings are privacy
protective and give users control of their personal information
in the ways which are easy to understand and use. However,
still they fail to provide enough detailed suggestions. To help
developers better design their privacy settings, we summarize
some suggestions for them based on the human subject studies
and measurement.
• For all privacy settings, let Settings→Privacy Settings
starts their UI-paths. Most users get used to locating a privacy
setting using the two views. In this way, developers can avoid
the categorization problems such as placing a privacy setting
into an inappropriate view which users may never visit for
searching privacy settings. However, for some privacy settings
that are also reasonable to show up in other places, we suggest
the developers to use multiple entries to connect to the settings
from these places. For example, for the setting “share location”,
(cid:22)(cid:25)(cid:18)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:53:00 UTC from IEEE Xplore.  Restrictions apply. 
in addition to the entry under Privacy Settings, we suggest the
developers to add another entry in Location Settings.
• Never put too many UI elements in a view. Instead, use
nested views when necessary. A view containing too many
UI elements is one of the root causes of hidden privacy settings
(see Section II-B). Therefore, we suggest developers to ensure
that all the UI elements in the same view can be displayed in
one screen. When too many privacy settings have to be put
into a view, developers should consider group them according
to their functionalities and create a nested view for the group.
• Keep the text of a privacy setting short and concise;
separate descriptions of the setting from the text. Some
developers like to provide detailed descriptions for a privacy
setting, explaining more on the privacy been used. However,
users may not read them due to the complexity. Developers
should use a short text to describe the basic functionalities of
the setting and separate the long description from the text.
• Use typical icons as indicators and add text descriptions
to every icon. According to the second user study, users are
often confused by non-typical icons. What they like are concise
text descriptions.
• Design a privacy setting as follows: switch on for sharing
privacy; switch off for stopping sharing. Users get used to
this manner for a privacy setting. Otherwise, some users may
leak privacy unintentionally (See Section V-D).
Besides the suggestions, we will also support our tool
Hound for developers to identify hidden privacy settings
before releasing their apps. Once a hidden setting is identiﬁed,
developers can refer to our suggestions to improve their UI
design.
VII. LIMITATIONS
User study. The ﬁrst limitation of the user study is that the
difﬁculty level of each privacy setting is quantiﬁed by the
average score given from 5 participants. And the results might
be subject to a lack of representativeness due to the relatively
small number of participants for each setting. However, the
average Fleiss’s kappa of our results is as high as 71.93%,
indicating a substantial agreement among the responses of
the participants. Therefore, the results of our user study are
a legitimate evaluation of the hiddenness of privacy settings.
Another limitation is that 57.26% of the participants from
China are working in computer science or related ﬁelds. These
participants have better skills for using apps comparing to the
general public so that they tend to view a privacy setting more
easy-to-ﬁnd. Thus, having more users with different background
will make the result more general. Furthermore, it would be
ideal if we can ﬁnd users that have used all the mobile apps
we evaluate. However, it is difﬁcult to recruit such users with
the less popular apps. Alternatively, we require participants to
use mobile for at least one year to have experienced users. And
in our user study, we also ask our participants whether they
have used the app before. According to our research, whether
using the app or not doesn’t have much impact on their ability
to set the privacy settings (t-test, p>0.8).
Technique. Although the technique semantics-based UI tracing
is based on the static analysis which cannot handle obfuscation,
Hound can still identify the indicator texts and the title of views
to extract the UI-paths if an obfuscated app leaves semantics in
the resources ﬁles such as .layout ﬁle. We randomly selected
200 apps in our dataset, and only one app (0.5%) is obfuscated
entirely without any semantic information in the app. Hound
cannot identify privacy settings which are loaded from the
Internet dynamically. In our randomly selected 200 apps, only
nine (4.5%) apps load their privacy settings from servers each
time. This situation is not considered in our research.
VIII. RELATED WORK
Mobile privacy protection. Android system provides a
permission-based security model that restricts an app’s access
to user private data [6], [31], [32], [33]. A lot of previous
work [34], [35], [36], [37] focus on how to conﬁgure permission
preferences to avoid unnecessary permissions application and
the privilege escalation issue. Other works [38], [39], [40], [41]
provide various approaches to enhance Android permission
system for better protection. However, system permissions
only protect limited personal data (i.e., the privacy in the ﬁrst
category in Table I such as contacts and location). Our research
studies on much broader privacy settings touched by mobile
apps beyond the protection by system permissions (i.e., the
other ﬁve categories in Table I).
Mobile app usability. The usability is essential in app design.
Lots of researches [42], [43], [44], [45], [46], [47], [48] work
on how to achieve the goal by studying the UI design principles
such as considering screen size, text font, data entry methods,
etc. But most of them focus on the general UI design for an app,
and only very few studies concentrate on the usability of mobile
privacy settings [49], [50], [51]. In addition to applying general
UI design rules on privacy settings [49], some studies[51],
[50] focus on the accuracy of privacy setting text, such as
discussing the consistency between the text and the desire
of privacy settings [51], and providing the suggestions for
designing a better understanding of privacy setting text for
users [50]. Different from them, our research is studying the
difﬁculties in locating a privacy setting, which is the ﬁrst step
when considering the usability of privacy settings.
UI-paths analysis. Hidden feature extractor in HPSI is sup-
ported by the UI-path tracer, which extracts the UI-paths that
link an app’s home view to a given privacy setting. Previous
studies [52], [53], [54] extract UI-paths by searching Android
API startActivity to recover the connections among views. But
they cannot ﬁnd the indicator that triggers one view to another.
To solve the problem, Hound uses semantics-based UI tracing
to correlate an indicator with a view according to the semantic
information of the indicator and title of the views.
(cid:22)(cid:25)(cid:19)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:53:00 UTC from IEEE Xplore.  Restrictions apply. 
IX. CONCLUSION
In this paper, we report the ﬁrst large-scale measurement
study on privacy settings that are difﬁcult for users to ﬁnd.
More speciﬁcally, we did two user studies to understand users’
perceptions of data exposure controlled by privacy settings and
found whether these settings are presented to them in the right
way. From participants’ feedback, we summarized six root
causes for the trouble and converted them into 14 features for
further detect them. We build a tool called Hound with a high
accuracy of 93.54% to recover privacy settings and identify
those problematic ones, which uses a novel technique named
semantics-based UI tracing to extract features for training the
classiﬁer. Running the Hound on 100,000 apps from Google
Play and third-party markets, we ﬁnd that over one-third
(36.29%) of the privacy settings from these apps are hidden
and 82.16% of them by default leak out user private data. We
observed that the problem of hidden privacy settings becomes
more serious from the year 2017 to 2018, possibly due to the
fundamental causes of privacy settings’ problematic designs.
Finally, we provide ﬁve suggestions for developers to design
privacy settings.