inaudibly injects malicious Skill S’s invocation name from a pre-
recorded and modulated audio file.
To handle the recorded user command D sends it to a speech-to-
text Service STT which transcribes it and returns the most probable
transcriptions as text. We are using the Bing Speech API18. If the
transcription contains a command or invocation name that D wants
to hijack, it sends an instruction to the state server to mimic this
specific Skill and command. Otherwise D sends the recorded audio
to AVS. The AVS backend will then process the command and
return a JSON payload containing a Speak Directive with a binary
attachment containing MP3 encoded audio. To get the response in
textual form this audio has to be transcribed by STT as well. After
D gets the transcription its sends it as an instruction to the state
server telling S to return the transcribed audio text via AVS to the
user. If the genuine Skill expects a response from the user, the Skill’s
reply will prompt the user to provide this response. In this case D
will proceed to recording the user’s response, send it response to
STT for transcription, forward this to the genuine Skill through
AVS and, receive the response, transcribe it again through STT and
finally send the transcription as an instruction to S for playback to
the user. In this way the adversary is are able to conduct a complete
MITM attack on the user’s genuine Alexa-enabled device and the
requested genuine Skill.
5 EVALUATION
The evaluation of our attack was carried out in an isolated office
room measuring about 4 times 6 meters. The background noise was
around 50 dB. The ultrasonic speaker was placed about 30 cm above
an Amazon Echo Dot, our Alexa device, to avoid coupling effects.
5.1 Attack Components’ Performance
5.1.1 Adversarial Skill invocation. First we needed to find the car-
rier wave frequency on which Amazon Echo Dot demodulates the
strongest signal. We injected the command “start Evil”, where Evil
is our uncertified Skill’s invocation name. Our evaluation in App. C
shows that using carrier wave frequencies from 22 kHz to 23 kHz
provides the best performance in terms that AVS is able to optimally
understand the injected voice command.
5.1.2 What to jam. To test how AVS and the Alexa-enabled device
(e.g. Echo Dot) react to jamming, we used white noise to jam parts
of a command in order to find the best jamming strategy.
Setup. To evaluate what we have to jam and how AVS reacts to
it we used the (syntactically incorrect) command: “Alexa, Ask X
for Y, ask Evil for Z”, with the invocation names X and Evil and
utterances Y and Z. For testing purposes we used audible white
noise and added it to parts of the command audio sample recorded
from a male person. We experimented with jamming different parts
of the command in order to see which parts of the command needed
to be jammed to make AVS not understand the benign command
anymore and instead understand our injected command. The results
are shown in Tab. 1.
Jamming benign Skill name. Jamming the benign Skill’s invoca-
tion name “X”, resulted in the effective command “Alexa, Ask for
Y, ask Evil for Z”. AVS started “Z” unreliably (in < 50% of trials) if
it was also a built-in functionality like “tell me a joke”. If “Z” was
only an utterance for “Evil” we were not even able to make AVS
launch ”Evil” with the utterance “Z”.
17https://www.mathworks.com/help/signal/ref/equiripple.html
18https://azure.microsoft.com/en-us/services/cognitive-services/speech/
Session 6A: IoT SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand471Table 1: Results of jamming different parts of the command.
Part to jam
Only X
Result
Alexa starts unreliably Z if it is
also a built-in function
Ask and first part of X Alexa starts unreliably Evil with Z
Ask X for Y
Command: “Alexa, Ask X for Y, ask Evil for Z”
Alexa starts reliably Evil with Z
]
%
[
g
n
i
m
m
a
j
l
u
f
s
s
e
c
c
u
S
100
80
60
40
20
0
Sawtooth at 22
Sinewave at 22
Sawtooth at 23
Sinewave at 23
Wave type and carrier frequency [kHz]
50
55
60
Figure 7: Results of jamming the voice sample “tell me a
joke” recorded from a male person, arriving with an air pres-
sure of 73 dB at the Amazon Echo Dot, with a sawtooth and
sine wave signal at 1000 Hz, modulated with different carrier
waves, from 30 cm distance, at different volume levels (50-
60/100)
Jamming Ask and first part of X. We only jammed “Ask” and first
part of “X” leaving the recognizable part of the command as “for
Y, ask Evil for Z”. If the added noise was loud enough so that AVS
was not able to understand the jammed part correctly it interprets
it as “ask Evil for Z” unreliably (in < 50% of trials). This shows that
the leftover utterance “for Y” is still confusing AVS.
Jamming the whole benign command. Finally we added noise to
the complete benign command “Ask X for Y”. AVS was now able
to understand “ask Evil for Z” reliably, and therefore started our
malicious Skill (Evil) with the utterance “Z”.
Result. The results show that jamming has to start immediately
after the wake-word and last just until the inaudible command
injection starts (i.e., the entire benign command has to be jammed).
This means that jamming needs to start before the attacker knows
which command the user will issue, otherwise Alexa will recog-
nize the genuine Skill name and will ignore the redirection to the
malicious Skill S or will be confused by those parts of the benign
command that have not been jammed.
5.1.3 User command jamming. To evaluate command jamming,
we recorded a human male saying “tell me a joke”. This command
starts the built-in functionality of Alexa to tell a joke and therefore
should be easy for Alexa to understand correctly, because it uses
no arbitrary Skill names. This sample was played with a sound
pressure of 73 dB at the Echo Dot. We modulated a 1000 Hz saw-
tooth and a 1000 Hz sine wave signal with a carrier wave with a
frequency of 22 kHz and 23 kHz to induce a noise signal in Echo
Dot’s microphone. The results of jamming with 10 trials each are
shown in Fig. 7. At volume level 60 all signal types are able to
jam the voice sample successfully. The sawtooth signal was barely
audible whereas the sine wave-based signal was even less audible.
5.1.4 Attack performance. We evaluated injection and jamming
at a distance of 30 cm. The greater the distance between D and E,
the higher sound pressure [14, 25] is required. With our setup the
maximum distance for reliable injection and jamming we could
achieve was 140 cm between the ultrasonic speaker and Echo Dot
with a success rate of 100% at a volume level of 70/100 for injection
and 60% for jamming with 10 trials each.
We evaluated the Skill redirection attack on 10 “top skills” of
the US Alexa Skill store and two smart home security Skills “Nuki”
and “Homematic IP” in an isolated room. We invoked each Skill
using the 1-3 example utterances displayed on each Skill’s store
page. Every Skill was invoked 10 times by two different persons.
Each attack was executed as described in Sect. 4.4, i.e., by jamming
the user command after the wake-word and injecting a command
to invoke the malicious Skill after the user stopped speaking. This
results in an attack success rate of 75 %. Tab. 2 shows the percentage
of failure for each module (jamming, injection and STT). The most
prevalent reason for the attack to fail was due to a failure in the
injection of the malicious Skill’s invocation name. We observed that
even when the recorded audio of the injected invocation-name was
very good (the audio captured by AVS can be inspected through
the “history” tab in the Alexa Apps settings), AVS still sometimes
misheard the command, resulting in a failure to start the malicious
skill. Jamming and speech-to-text translation (STT) of the command
were almost always successful. An asterisk next to the STT value in
Tab. 2 indicates minor transcription errors (e.g. “new key” instead
of “Nuki”, or “jurassic park” instead of “jurassic bark”) which were
systematic and can therefore easily be corrected by malicious device
D using an extended keyword list to capture desired utterances.
They were thus not counted as STT module failures.
We also tested how accurately Skills are triggered without ad-
versarial influence by invoking each Skill ten times, as described
above. In the benign setting the requested Skill was successfully
started with the correct command in 87 % of the trials. An invoca-
tion trial was considered successful, if the command was correctly
transcribed by AVS as displayed by the “history” tab in the Alexa
app and the correct Skill was started. As can be seen, the attack
deteriorates the accuracy of Alexa’s responses from a user point of
view, but only slightly (from 87 % to 75 %). It is therefore question-
able whether a user would be able to notice the presence of attacks
only based on the changed behavior of AVS.
To evaluate whether different room layouts or interiors affect
the attack we carried out tests in a conference room, different office
rooms with up to 6 persons in it and even a crowded exhibition hall.
We found no degradation of the attack success rate based on these
factors, however, a large enough background noise pressure like in
the crowded exhibition hall can cause our attack to fail (when the
injected command sound level is less than the background noise
Session 6A: IoT SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand472Table 2: Results of attacking the 10 “top skills” from the US
Skill store (Nov. 2018) and two smart home security Skills,
using example commands (1-3) listed on the store page
Skill Name
Flash Briefing Skills
Reuters TV (U.S.)
Fox News
NPR News Now
Custom Skills
Jeopardy!
Find My Phone
Jurassic Bark
Question of the Day
Sleep Sounds:
Ocean Sounds
Sleep Sounds:
White Noise
Sleep and Relaxation
Sounds
Nuki
Smart Home Skills
Homematic IP
Jamming
Injection
STT
7 %
10 %
0 %*
5 %
0 %
0 %
0 %
5 %
25 %
0 %
5 %
0 %
0 %
22 %
22 %
15 %
20 %
25 %
11 %
20 %
15 %
15 %
6 %
0 %*
0 %*
0 %
0 %*
6 %
0 %*
5 %*
level) but such noise levels are not common in private homes where
Alexa devices are typically deployed.
5.2 Proof-of-Concept Attack
We implemented two proof-of-concept implementations of our at-
tack for two Alexa-controlled smart-home devices, the Homematic
IP Security System 19 and the Nuki smart lock20. Both security
Skills can be activated or locked through Alexa. The goal of the at-
tack is to prevent the user from locking his smart lock or arming of
the smart home security system while simultaneously leaving him
believing Alexa has armed or locked it properly. The Homematic
IP Security System uses a Smart Home Skill for arming the home
security system. When the Skill-redirection attack is run and the
user says “Turn on absence mode”, the command is redirected to
the malicious Skill which will return a reply that is identical with
that of the benign Skill, requesting further information on what
device is to be armed: “Sorry what device?”. The user can reply to
this anything, the malicious Skill will always just return “Okay.”
without notifying or contacting the genuine Skill at any stage. The
result of the attack is that the security system remains disarmed,
even though the user thinks it is armed, because the exact same
wording is used by the malicious Skill than what the genuine Skill
would use. The Nuki Smart Lock uses a Custom Skill. If a user wants
to close a lock and says “Ask Nuki to lock front door.”, where front
door is the name of the lock to be locked, the malicious Skill will
directly return “Smart lock front door is locking.”, again using a
wording that is identical with the benign Skill’s reply.
19https://www.homematic-ip.com/
20https://nuki.io/en/smart-lock/
In a Skill-in-the-middle scenario if the user wants to hear recent
stock prices for a company using a popular stock market Skill called
Stock Prices by Opening Bell21 and asks “Ask Opening Bell for the
price of Amazon”, malicious device D forwards this command to
Alexa’s backend, and gets a response which is formed like “Amazon
is trading at 1599.01. Down 1.97%.”. Device D can modify these
values at will and return this forged response with the help of
malicious Skill S. Again the adversary used the exact wording of
the genuine Skill to make the user believe the provided information
is real because it comes from his trusted stock Skill.
Feasibility on IoT Hardware. To evaluate the susceptibility
5.2.1
of smart home devices to the Lyexa attack, we examined its feasi-
blity given the typical hardware set-up of IoT devices. The used
malicious device could be a cheap two-way security camera like
the Apexis J011-WS. The J011-WS is equipped with a generic 1 W,
8 Ω small loudspeaker and the Cirrus WM8731 driver22, which is
able to process PCM audio with a sampling rate of up to 96 kHz.
We tested the speaker and were able to inaudibly inject commands
into the Echo Dot from a distance of up to ≈ 30 cm and inaudibly
jam commands from up to ≈ 15 cm, with an AM carrier frequency
of up to 25 kHz even though the speaker is not rated for frequen-
cies beyond 20 kHz (this is the maximum we could safely achieve
without overheating the speaker, for a one time attack, even more