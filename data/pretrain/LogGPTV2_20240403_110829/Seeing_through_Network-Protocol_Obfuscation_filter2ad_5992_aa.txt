title:Seeing through Network-Protocol Obfuscation
author:Liang Wang and
Kevin P. Dyer and
Aditya Akella and
Thomas Ristenpart and
Thomas Shrimpton
Seeing through Network-Protocol Obfuscation
Liang Wang
University of Wisconsin
PI:EMAIL
Kevin P. Dyer
Portland State University
PI:EMAIL
Aditya Akella
University of Wisconsin
PI:EMAIL
Thomas Ristenpart
Cornell Tech
PI:EMAIL
ABSTRACT
Censorship-circumvention systems are designed to help users by-
pass Internet censorship. As more sophisticated deep-packet-
inspection (DPI) mechanisms have been deployed by censors to de-
tect circumvention tools, activists and researchers have responded
by developing network protocol obfuscation tools. These have
proved to be effective in practice against existing DPI and are now
distributed with systems such as Tor.
In this work, we provide the ﬁrst in-depth investigation of the
detectability of in-use protocol obfuscators by DPI. We build a
framework for evaluation that uses real network trafﬁc captures to
evaluate detectability, based on metrics such as the false-positive
rate against background (i.e., non obfuscated) trafﬁc. We ﬁrst
exercise our framework to show that some previously proposed
attacks from the literature are not as effective as a censor might
like. We go on to develop new attacks against ﬁve obfuscation
tools as they are conﬁgured in Tor, including:
two variants of
obfsproxy, FTE, and two variants of meek. We conclude by using
our framework to show that all of these obfuscation mechanisms
could be reliably detected by a determined censor with sufﬁciently
low false-positive rates for use in many censorship settings.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—Secu-
rity and protection
Keywords
Censorship-resistance; network obfuscation; Tor
1.
INTRODUCTION
Nation-states and other Internet censors use deep-packet inspec-
tion (DPI) to detect and block use of circumvention tools. They do
so by recognizing the tools’ protocol headers or other telltale ﬁnger-
prints contained in application-layer content of network packets. In
response, researchers and activists have proposed a large number of
approaches for obfuscating the network protocol being used. These
obfuscation tools can be loosely categorized as either attempting to
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813715.
Thomas Shrimpton
University of Florida
teshrim@cise.uﬂ.edu
randomize all bytes sent on the wire [39, 40, 48, 52], attempting to
look like (or mimic) an unblocked protocol such as HTTP [12, 26,
45,46], or tunneling trafﬁc over an implementation of an unblocked
protocol [42]. Examples of network obfuscators from each of these
three classes are now deployed as Tor pluggable transports [3] and
with other anti-censorship tools [44, 48]. Currently, the available
evidence indicates that existing DPI systems are easily subverted
by these tools [12], and that nation-state censors are not currently
blocking their use via DPI [43]. Thus these systems provide
signiﬁcant value against today’s censors.
Can censors easily adapt and deploy new DPI algorithms that
accurately detect these protocol obfuscators? Houmansadr et
al. [16] proposed a number of attacks for detection of mimicry
obfuscators, but they do not measure false-positive rates. It may
be that their attacks are undeployable in practical settings, due to
labeling too many “legitimate” connections as emanating from an
anti-censorship tool. What’s more, the randomizing and tunneling
obfuscators, which are the most widely used at present [43],
have not been evaluated for detectability at all. (Despite folklore
concerns about possible approaches [42].) In short, no one knows
whether these obfuscators will work against tomorrow’s censors.
In this work, we provide the ﬁrst in-depth, empirical investiga-
tion of the detectability of modern network protocol obfuscators,
and of the collateral damage to real network trafﬁc due to false
positives. Our results suggest that all of the in-use protocol
obfuscation mechanisms can be reliably detected by methods
that require surprisingly little in the way of payload parsing
or DPI state. See Figure 1 for a summary of our best-performing
attacks against Tor’s pluggable transport obfuscators.
To obtain these results, we built a trace analysis framework and
exercised it with a variety of datasets. Prior attack evaluations [12,
16] have focused primarily on small, synthetic datasets generated
by a researcher running a target tool in a speciﬁc environment, and
evaluating true-positive and false-negative rates of a certain attack.
As mentioned above, this may lead to over-estimation of tool
efﬁcacy in practice: actual false-positive rates may be prohibitively
large, and the synthetic traces used in the lab evaluations may be
unlike the network traces seen in real environments. We address
both of these issues by employing an experimental methodology
that more closely reﬂects the setting of nation-state level DPI.
We collected nearly a terabyte of packet traces from routers
associated to various networks at our university campus. Together
these have about 14 million TCP ﬂows. Given the size of the
covered networks (ﬁve /16 networks and three /24 networks), this
represents a large, diverse dataset suitable for assessing false posi-
tives. We supplement with researcher-driven traces of obfuscation
tools (which do not appear in the traces already), collected across a
number of client environments.
57Type
Attack
Obfuscator
obfsproxy3 Randomizer entropy + length
obfsproxy4 Randomizer entropy + length
FTE
meek-amazon Tunneling
meek-google Tunneling
Mimicry URI entropy/length 1.0 0.00003
0.98 0.0002
0.98 0.00006
TPR FPR
1.0 0.002
1.0 0.002
decision tree
decision tree
Figure 1: Summary of best-found attacks against the network
obfuscators deployed as Tor pluggable transports. TPR is the true-
positive rate; FPR is the false-positive rate as measured using real
network traces from a university campus.
Using these datasets, we explore previously proposed DPI-based
attacks against obfuscation systems and develop new ones. To
begin, we evaluate a collection of semantics-based attacks, which
attempt to detect a mimicry obfuscator by looking for deviations
from expected behavior of the cover protocol. This type of attack
was recently introduced by Housmansadr et al. [16]. Next, we
explore entropy-based attacks, which seek to detect when network
packet contents (in whole, or in part) appear to be encrypted.
encryption may be in whole, or in speciﬁc parts where non-
obfuscated ﬂows would not be. Finally, we examine machine-
learning-based attacks. These use decision trees that are trained
from traces of both obfuscated and non-obfuscated trafﬁc. Some
of the features used were inspired by suggestions by the meek
designers [42], but we are the ﬁrst to build full attacks and evaluate
them. Our investigations reveal that:
•
Semantics-based attacks can sometimes have prohibitive false-
positive rates (up to 37% in the case discussed in §4.1). False
positives here arise because many non-censorship tools devi-
ate from standards in ways similar to mimicry protocols. In
these cases they are unlikely to be useful by censors. We also
show that other semantics attacks, including one suggested
in [16], have relatively low false-positive rates (0.03% as in
§4.2).
•
• Randomizers such as obfsproxy [40], which only emit ran-
dom payload bytes, are reliably detected by a combination of
entropy-based tests and simple heuristics (e.g. length checks).
In particular, these tests are applied only to the beginning of
the ﬁrst packet payload. This attack abuses the distinction
between conventional protocols’ plaintext headers and the
lack of same in randomizing obfuscators.
In short, having
“no ﬁngerprint” is itself a ﬁngerprint (§5.1).
Format-transforming encryption (FTE), as currently deployed
in Tor, is reliably detected by simple tests on the entropy
and length of the URI appearing in the ﬁrst FTE-produced
packet (§5.2).
• Tunneling protocols such as meek [42], broadly considered
the most secure current proposal for protocol obfuscation,
are reliably detected by classiﬁers trained on trafﬁc-analysis
and entropy features (§6). The trained classiﬁers are simple
decision trees, and do require the DPI to maintain state for the
ﬁrst part of a ﬂow.
In summary, our analyses show how to reliably detect all of the
currently deployed Tor pluggable transports. For example, our
testing reveals that we can detect 100% of obfsproxy3/obfsproxy4
traces using just the ﬁrst packet in the ﬂow, and with false-positive
rate of 0.2%.
A false-positive rate of 0.2% is likely to still be considered
prohibitively high for some censors. In particular, since the base-
rate of obfuscator-produced trafﬁc is dominated by that of non-
obfuscated trafﬁc, the vast majority of ﬂows that are tagged as
obfuscated will in fact be false positives.
In the near term,
false positive rates could be improved via white-listing of speciﬁc
protocols. In addition, more robust and expensive tests on tagged
trafﬁc such as the active probing techniques used by the Great
Firewall [51] could be used to achieve a false positive rate of
essentially zero. Using our network trace data sets, we give a
preliminary analysis of the expected burden such secondary checks
would impose on a censor’s infrastructure (§6.2). Nevertheless,
evidencing negligible false positive rates in realistic deployment
settings remains an important challenge for future work.
Summary and discussion. We are the ﬁrst to provide an in-depth
analysis of attacks against modern network protocol obfuscation.
We quantify, for the ﬁrst time, the false-positive rates of previously
proposed attacks, as well as ones that we introduce. To do so we
use real network trafﬁc like what censors would see in practice.
The framework for this analysis, while built mostly off existing
open-source tools (e.g., Bro, MySQL, etc.)
required signiﬁcant
engineering effort to handle the scale of our analyses. We will open
source and make public the framework for other researchers to use.
The university network captures cannot be released.
Our results suggest that censors can easily adapt their current
tools to efﬁciently detect state-of-the-art network obfuscators. New
obfuscators could, in turn, easily defeat the speciﬁc tests that we
propose. Under current knowledge, whichever of the censor or
protocol obfuscator can adapt to the other will have the upper
hand in protocol (mis)classiﬁcation. Developing practical, network
obfuscation mechanisms that are robust to adaptation by the DPI
remains a compelling open problem of practical import.
2. BACKGROUND
Censorship. Nation-states and other organizations assert control
over Internet communications by blocking connections to websites
based on IP address, application-layer content of packets, active
probing of remote servers, or some combination of the preceding.
For a more ﬁne-grained taxonomy of attacks see [16].
IP ﬁltering is a commonly-used censorship technique. Here
the censors monitor a list of IPs and block all communications
whose source or destination IP that belongs to the list. IP ﬁltering
can be deployed in border ASes or local ISPs by nation-states
censors [53]. To bypass IP ﬁltering, a simple method is to use
anonymous proxies. By deploying proxies outside the censored
network, users within the censored network can submit trafﬁc
past censors to the (unﬁltered) proxy IP. Various proxy-based
censorship circumvention systems have been developed such as
freegate, Ultrasurf and JonDo. Tor [11], an onion routing system,
helps circumvent IP-based ﬁltering due to its use of a large number
of proxies (and bridges). A more recent proposal is to use domain
fronting, in which one sends trafﬁc through an unwitting reverse
proxy [42].
In addition to ﬁltering by IPs, and partly because of the bur-
den of maintaining an exhaustive and accurate list of proxy IP
addresses, censors have increasingly also deployed deep packet
inspection (DPI) techniques. This enables censors to attempt
protocol identiﬁcation: inspecting the application-layer content of
packets (e.g., application-layer headers) as well as packet size or
timing information, in order to classify the trafﬁc as generated by
communication protocols associated with an anti-censorship tool.
In the past, Tor trafﬁc itself contained unique application-layer
ﬁngerprints patterns that can be recognized by DPIs [51]. In this
work we focus primarily on DPI-based censorship.
A ﬁnal class of protocol identiﬁcation attacks uses active probing
of a remote server. The Great Firewall of China, for example, is
known to attempt Tor handshakes with destination IP addresses
58should a DPI test ﬂag a ﬂow to that IP as possibly emanating from
a Tor client [51]. We will consider an active attack brieﬂy in §4.2,
and also in consideration of ﬁltering out a (passive) DPI test’s false
positives (§6.2).
Network protocol obfuscation.
In response censors’ efforts to
carry out protocol identiﬁcation, researchers have developed a
number of approaches to protocol obfuscation. In large part, the
goals have been to force DPI to misidentify ﬂows of a censored
protocol as those of a protocol that is not blocked, or to prevent
DPI from recognizing the ﬂows’ protocol at all. The latter helps
in the case that censors do not block unidentiﬁed ﬂows. Suggested
obfuscation techniques roughly fall into three categories:
• Randomizers: A randomizing obfuscator aims to hide all
application-layer static ﬁngerprints, usually by post-processing
trafﬁc with an obfuscation step that emits only bits that are
indistinguishable from random ones. Examples are Dust [48],
ScrambleSuit [52], and the various versions of obfsproxy [40,
54]. The last are currently deployed with Tor.
• Protocol mimicry: A mimicry obfuscator attempts to produce
trafﬁc that looks to DPI as if it were generated by some
“benign” protocol, also called the cover protocol. One
example of light-weight mimicry is format-transforming en-
cryption (FTE) [12, 24], now deployed with Tor and imple-
mented elsewhere [44].
It encrypts messages to produce
ciphertexts that match regular expressions commonly used
by DPI for identifying protocols. Less efﬁcient obfuscators
like Stegotorus [46], SkypeMorph [26], CensorSpoofer [45]
and Marionette [13] use heavier steganographic techniques to
produce messages that look like a cover protocol. Marionette
also provides mechanisms to mimic higher-level protocol
behaviors, to perform trafﬁc shaping, and to protect against
some forms of active attacks.
Tunneling: A logical extreme of mimicry is to simply tunnel
data over a (typically encrypted) cover protocol. Intuitively
this should provide best-possible mimicry as one is, in fact,
using an existing implementation of the cover protocol. An
example now deployed with Tor is meek, which uses domain
fronting and tunnels trafﬁc over HTTPS connections to popu-
lar cloud load balancers such as Google (we will refer to this
as meekG) and Amazon (meekA).
•
As mentioned, several of these are now in-use with Tor as pluggable
transports (PTs). A PT is just Tor’s terminology for an obfuscator