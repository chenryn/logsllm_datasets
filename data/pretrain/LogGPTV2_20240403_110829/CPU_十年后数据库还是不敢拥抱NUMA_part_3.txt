![undefined](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/十年后数据库还是不敢拥抱NUMA/d653f2b25e16c008-1620956524069-85ec2c06-ff55-48e9-8c26-96e738456ed4.png)
![undefined](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/十年后数据库还是不敢拥抱NUMA/8c797b537fc7dac4-1620956551990-6e376a3d-de40-4180-a05b-b21a9cbf33bc.png)
关键是上图红框中的代码，node distance比较大（也就是开启了NUMA的话），强制将 zone_reclaim_mode设为1，这是2014年提交的代码，将这个强制设为1的逻辑去掉了。
这也就是为什么之前大佬们碰到NUMA问题后尝试修改 zone_reclaim_mode 没有效果，**也就是2014年前只要开启了NUMA就强制线回收PageCache，即使设置zone_reclaim_mode也没有意义，真是个可怕的Bug。**
### 验证一下zone_reclaim_mode 0是生效的
内核版本：3.10.0-327.ali2017.alios7.x86_64
#### [测试方法](https://github.com/torvalds/linux/commit/e02dc017c3032dcdce1b993af0db135462e1b4b7)
先将一个160G的文件加载到内存里，然后再用代码分配64G的内存出来使用。
单个NUMA node的内存为256G，本身用掉了60G，加上这次的160G的PageCache，和之前的一些其他PageCache,总的 PageCache用了179G，那么这个node总内存还剩256G-60G-179G，
如果这个时候再分配64G内存的话，本node肯定不够了，我们来看在 zone_reclaim_mode=0 的时候是优先回收PageCache还是分配了到另外一个NUMA node(这个NUMA node 有240G以上的内存空闲）
#### 测试过程
分配64G内存
```
#taskset -c 0 ./alloc 64
To allocate 64GB memory
Used time: 39 seconds
```
![undefined](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/十年后数据库还是不敢拥抱NUMA/689e47eb1c7cf6e7-1620966121309-a264fd7f-fe50-4fc6-940f-4cb603ec7874.png)
从如上截图来看，再分配64G内存的时候即使node0不够了也没有回收node0上的PageCache，而是将内存跨NUMA分配到了node1上，符合预期！
释放这64G内存后，如下图可以看到node0回收了25G，剩下的39G都是在node1上：
![undefined](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/十年后数据库还是不敢拥抱NUMA/2bad7da356c6e69a-1620967573650-b8400c2f-7b48-4502-b7d5-6c050e557126.png)
### 将 /proc/sys/vm/zone_reclaim_mode 改成 1 继续同样的测试
可以看到zone_reclaim_mode 改成 1，node0内存不够了也没有分配node1上的内存，而是从PageCache回收了40G内存，整个分配64G内存的过程也比不回收PageCache慢了12秒，这12秒就是额外的卡顿
![undefined](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/十年后数据库还是不敢拥抱NUMA/7bc694ba82e6dc6e-1620977108922-a2f67827-cf00-43a0-bba1-4ba105a33201.png)
测试结论：**从这个测试可以看到NUMA 在内存使用上不会优先回收 PageCache 了**
### innodb_numa_interleave
从5.7开始，mysql增加了对NUMA的无感知：[innodb_numa_interleave](https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_numa_interleave)，也就是在开了NUMA的机器上，使用内错交错来分配内存，相当于使用上关掉 NUMA
> For the [`innodb_numa_interleave`](https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_numa_interleave) option to be available, MySQL must be compiled on a NUMA-enabled Linux system.
当开启了 innodb_numa_interleave 的话在为innodb buffer pool分配内存的时候将 [NUMA memory policy](https://linux.die.net/man/2/set_mempolicy) 设置为 MPOL_INTERLEAVE 分配完后再设置回 MPOL_DEFAULT（OS默认内存分配行为，也就是zone_reclaim_mode指定的行为)。
innodb_numa_interleave参数是为innodb更精细化地分配innodb buffer pool 而增加的。很典型地innodb_numa_interleave为on只是更好地规避了前面所说的zone_reclaim_mode的kernel bug，**修复后这个参数没有意义了**。
### [AUTOMATIC NUMA BALANCING](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/virtualization_tuning_and_optimization_guide/sect-virtualization_tuning_optimization_guide-numa-auto_numa_balancing)
RedHat 7默认会自动让内存或者进程就近迁移，让内存和CPU距离更近以达到最好的效果
> Automatic NUMA balancing improves the performance of applications running on NUMA hardware systems. It is enabled by default on Red Hat Enterprise Linux 7 systems.
> 
> An application will generally perform best when the threads of its processes are accessing memory on the same NUMA node as the threads are scheduled. Automatic NUMA balancing moves tasks (which can be threads or processes) closer to the memory they are accessing. It also moves application data to memory closer to the tasks that reference it. This is all done automatically by the kernel when automatic NUMA balancing is active.
对应参数
```
cat /proc/sys/kernel/numa_balancing shows 1
```
### 监控
查找相应的内存和调度器事件
```shell
#perf stat -e sched:sched_stick_numa,sched:sched_move_numa,sched:sched_swap_numa,migrate:mm_migrate_pages,minor-faults -p 7191
 Performance counter stats for process id '7191':
                 0      sched:sched_stick_numa                                        (100.00%)
                 1      sched:sched_move_numa                                         (100.00%)
                 0      sched:sched_swap_numa
                 0      migrate:mm_migrate_pages
               286      minor-faults
# perf stat -e sched:sched_stick_numa,sched:sched_move_numa,sched:sched_swap_numa,migrate:mm_migrate_pages,minor-faults -p PID
...
                 1      sched:sched_stick_numa
                 3      sched:sched_move_numa
                41      sched:sched_swap_numa
             5,239      migrate:mm_migrate_pages
            50,161      minor-faults
#perf stat -e sched:sched_stick_numa,sched:sched_move_numa,sched:sched_swap_numa,migrate:mm_migrate_pages,minor-faults -p 676322
 Performance counter stats for process id '676322':
                 0      sched:sched_stick_numa
                16      sched:sched_move_numa
                 0      sched:sched_swap_numa
                24      migrate:mm_migrate_pages
             2,079      minor-faults               
```
## 总结
-   放弃对NUMA的偏见吧，优先回收 PageCache 这个Bug早已修复了
-   按NUMA绑定core收益巨大，即使只有两个NUMA的intel芯片，也有一倍以上的性能提升，在飞腾等其他芯片上收益更大
-   没必要自欺欺人关掉NUMA了
-   RDS这样独占物理机的服务可以做到按NUMA来绑定core，收益可观
-   ECS售卖如果能够精确地按NUMA绑核的话性能，超卖比能高很多
-   在刷tpcc数据的时候更应该开NUMA和正确绑核
我个人一直对集团所有机器默认关闭NUMA耿耿于怀，因为定制的物理机（BIOS也是定制的）BIOS默认就是关闭NUMA的，装机还得一台台手工打开（跪了，几十万台啊），算是理清了来龙去脉。因为一个kernel的bug让大家对NUMA一直有偏见，即使14年已经修复了，大家还是以讹传讹，没必要。
关于cpu为什么高但是没有产出的原因是因为CPU流水线长期stall，导致很低的IPC，所以性能自然上不去，可以看[这篇文章](http://www.brendangregg.com/blog/2017-05-09/cpu-utilization-is-wrong.html)
其他同学测试的结论：
-   Hadoop离线作业在 Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz 24 cores/socket * 2, Turbo Off 下打开NUMA后性能提升8%
一些其它不好解释的现象：
1.  增加少量跨NUMA 的core进来时能增加QPS的，但是随着跨NUMA core越来越多（总core也越来越多）QPS反而会达到一个峰值后下降---效率低的core多了，抢走任务，执行得慢
1.  压12-19和8-15同样8core，不跨NUMA的8-15性能只好5%左右(87873 VS 92801) --- 难以解释
1.  由1、2所知在测试少量core的时候跨NUMA性能下降体现不出来
1.  在压0-31core的时候，如果运行 perf这个时候QPS反而会增加（13万上升到15万）--- 抢走了一些CPU资源，让某个地方竞争反而减小了
1.  综上在我个人理解是core越多的时候UPI压力到了瓶颈，才会出现加core性能反而下降
## 系列文章
[CPU的制造和概念](/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/)
[CPU 性能和Cache Line](/2021/05/16/CPU Cache Line 和性能/)
[Perf IPC以及CPU性能](/2021/05/16/Perf IPC以及CPU利用率/)
[Intel、海光、鲲鹏920、飞腾2500 CPU性能对比](/2021/06/18/%E5%87%A0%E6%AC%BECPU%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/)
[飞腾ARM芯片(FT2500)的性能测试](/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87(FT2500)%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/)
[十年后数据库还是不敢拥抱NUMA？](/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/)
[一次海光物理机资源竞争压测的记录](/2021/03/07/%E4%B8%80%E6%AC%A1%E6%B5%B7%E5%85%89%E7%89%A9%E7%90%86%E6%9C%BA%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%E5%8E%8B%E6%B5%8B%E7%9A%84%E8%AE%B0%E5%BD%95/)
[Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的](/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/)
## 参考资料
https://www.redhat.com/files/summit/session-assets/2018/Performance-analysis-and-tuning-of-Red-Hat-Enterprise-Linux-Part-1.pdf
https://informixdba.wordpress.com/2015/10/16/zone-reclaim-mode/
https://queue.acm.org/detail.cfm?id=2513149
[NUMA DEEP DIVE PART 1: FROM UMA TO NUMA](https://frankdenneman.nl/2016/07/07/numa-deep-dive-part-1-uma-numa/) 这是一个系列，都很干货，值得推荐
https://15721.courses.cs.cmu.edu/spring2016/papers/p743-leis.pdf Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework for the Many-Core Age 论文给出了很多numa-aware下的bandwidth、latency数据，以及对THC-H的影响
Reference: