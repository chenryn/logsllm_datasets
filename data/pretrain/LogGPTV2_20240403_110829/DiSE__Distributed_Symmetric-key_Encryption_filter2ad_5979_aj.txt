Vault by HashiCorp. https://www.vaultproject.io/.
[vauc]
Vault Docs, Basic Concepts, Seal-Unseal.
docs/concepts/seal.html.
https://www.vaultproject.io/
A Cryptographic Primitives
A.1 Authenticated Encryption
Deﬁnition A.1 (Symmetric encryption) A symmetric encryption scheme is a triple of
polynomial-time algorithms (Kgen, Encrypt, Decrypt) that satisfy a correctness requirement.
− Kgen(1κ) → sk : On input the security parameter, Kgen outputs a secret key sk.
− Encrypt(sk, m) → c : On input the secret key sk and a message m, Encrypt outputs a
ciphertext c.
− Decrypt(sk, c) =: m/⊥ : On input the secret key sk and a ciphertext c, Decrypt outputs
a message m or a failure symbol ⊥.
Correctness. For all κ ∈ N, sk output by Kgen(1κ), and any message m, there exists a
negligible function negl such that
Pr [m := Decrypt(sk, c) : c ← Encrypt(sk, m)] ≥ 1 − negl(κ),
where the probability is over the randomness of Encrypt.
Chosen-plaintext attack. A symmetric encryption scheme Π = (Kgen, Encrypt, Decrypt)
is secure against chosen-plaintext attacks (CPA) if for all PPT adversary A, there exists a
negligible function negl such that
(cid:12)(cid:12)Pr(cid:2)SymCPAΠ,A(1κ) = 1(cid:3) − 1/2(cid:12)(cid:12) ≤ negl(κ),
where SymCPA is deﬁned as follows:
1. Initialize. Run Kgen to get a key sk.
2. Pre-challenge encryption queries. On receiving (Encrypt, m) from A, return c ← Encrypt(sk, m).
This step can be repeated any number of times.
3. Challenge. When A sends (Challenge, (m0, m1)) such that |m0| = |m1|, choose a ran-
dom bit b←${0, 1} and return c(cid:63) ← Encrypt(sk, mb).
4. Post-challenge encryption queries. Same as Step 2.
5. Guess. Finally, receive a guess b(cid:48) from A and output 1 if and only if b(cid:48) = b.
37
Authenticity [BN00, KY01, RS06]. A symmetric encryption scheme Π = (Kgen, Encrypt,
Decrypt) satisﬁes authenticity if for all PPT adversary A, there exists a negligible function
negl such that
Pr(cid:2)SymAUTHΠ,A(1κ) = 1(cid:3) ≤ negl(κ),
where SymAUTH is deﬁned as follows:
1. Initialize. Run Kgen to get a key sk.
2. Encryption queries. On receiving (Encrypt, m) from A, return c ← Encrypt(sk, m). This
step can be repeated any number of times.
3. Forgery. A produces a ciphertext c(cid:63). Output 1 if and only if Decrypt(sk, c(cid:63)) (cid:54)= ⊥.
In the following, we use Encryptsk(·) and Decryptsk(·) to mean Encrypt(sk,·) and Decrypt(sk,·),
respectively.
A.2 Commitment
Deﬁnition A.2 A (non-interactive) commitment scheme Σ consists of two PPT algorithms
(Setupcom, Com) which satisfy hiding and binding properties:
− Setupcom(1κ) → ppcom : It takes the security parameter as input, and outputs some public
parameters.
− Com(m, ppcom; r) =: α : It takes a message m, public parameters ppcom and randomness
r as inputs, and outputs a commitment α.
Hiding. A commitment scheme Σ = (Setupcom, Com) is hiding if for all PPT adversaries
A, all messages m0, m1, there exists a negligible function negl such that for ppcom ←
Setupcom(1κ),
|Pr[A(ppcom, Com(m0, ppcom; r0)) = 1] − Pr[A(ppcom, Com(m1, ppcom; r1)) = 1]| ≤ negl(κ),
where the probability is over the randomness of Setupcom, random choice of r0 and r1, and
the coin tosses of A.
Binding. A commitment scheme Σ = (Setupcom, Com) is binding if for all PPT adversaries
A, if A outputs m0, m1, r0 and r1 ((m0, r0) (cid:54)= (m1, r1)) given ppcom ← Setupcom(1κ), then
there exists a negligible function negl such that
Pr[Com(m0, ppcom; r0) = Com(m1, ppcom; r1)] ≤ negl(κ),
where the probability is over the randomness of Setupcom and the coin tosses of A.
Deﬁnition A.3 (Trapdoor (Non-interactive) Commitments.) Let Com = (Setupcom, Com)
be a (non-interactive) commitment scheme. A trapdoor commitment scheme has two more
PPT algorithms SimSetup and SimOpen:
− SimSetup(1κ) → (ppcom, τcom) : It takes the security parameter as input, and outputs
public parameters ppcom and a trapdoor τcom.
38
− SimOpen(ppcom, τcom, m(cid:48), (m, r)) =: r(cid:48) : It takes parameters ppcom, trapdoor τcom, a mes-
sage m(cid:48) and a message-randomness pair (m, r) as inputs, and outputs a randomness
r(cid:48).
For every (m, r) and m(cid:48), there exists a negligible function negl such that
ppcom ≈stat pp(cid:48)
com
where ppcom ← Setupcom(1κ) and (pp(cid:48)
com, τcom) ← SimSetup(1κ)
and
(pp(cid:48)
com, τcom) ← SimSetup(1κ);
r(cid:48) := SimOpen(pp(cid:48)
(cid:21)
com, τcom, m(cid:48), (m, r))
≥ 1−negl(κ).
(cid:20)
Pr
Com(m, pp(cid:48)
com; r) = Com(m(cid:48), pp(cid:48)
com; r(cid:48)) |
Remark A.4 Clearly, a trapdoor commitment can be binding against PPT adversaries only.
A.2.1 Concrete instantiations.
Practical commitment schemes can be instantiated under various settings:
Random oracle.
In the random oracle model, a commitment to a message m is simply
the hash of m together with a randomly chosen string of length r of an appropriate length.
DLOG assumption. A popular commitment scheme secure under DLOG is Pedersen
commitment. Here, Setupcom(1κ) outputs the description of a (multiplicative) group G of
prime order p = Θ(κ) (in which DLOG holds) and two randomly and independently chosen
generators g, h. If H : {0, 1}∗ → Zp is a collision-resistant hash function, then a commitment
to a message m is given by gH(m)· hr, where r ←$ Zp. A trapdoor is simply the discrete log of
h with respect to g. In other words, SimSetup picks a random generator g, a random integer a
p and sets h to be ga. Given (m, r), m(cid:48) and a, SimOpen outputs [(H(m)−H(m(cid:48)))/a] + r.
in Z(cid:63)
It is easy to check that commitment to m with randomness r is equal to the commitment to
m(cid:48) with randomness r(cid:48).
Pseudo-random generators. Naor proposed a simple and eﬃcient commitment scheme
based on the existence of PRGs [Nao91]. We brieﬂy describe here a non-interactive variant
of the scheme for commitment to n-bit strings. Setupcom outputs a randomly chosen string
crs of length 4n. Let pad : {0, 1}n → {0, 1}4n be the function that prepends 3n zeroes to
its argument, H : {0, 1}∗ → {0, 1}n be a collision-resistant hash function, and G : {0, 1}n →
{0, 1}4n be a pseudo-random generator. Then, a commitment to a message m is given by
G(r) + crs · pad(H(x)) with arithmetic in GF (24n), where r ←$ {0, 1}n. We skip rest of the
details.
A.3 Secret Sharing
Deﬁnition A.5 (Shamir’s Secret Sharing) Let p be a prime. An (n, t, p, s)-Shamir’s se-
cret sharing scheme is a randomized algorithm SSS that on input four integers n, t, p, s, where
0 < t ≤ n < p and s ∈ Zp, outputs n shares s1, . . . , sn ∈ Zp such that the following two con-
ditions hold for any set {i1, . . . , i(cid:96)}:
− if (cid:96) ≥ t, there exists ﬁxed (i.e., independent of s) integers λ1, . . . , λ(cid:96) ∈ Zp (a.k.a. Lagrange
coeﬃcients) such that(cid:80)(cid:96)
j=1 λjsij = s mod p;
39
− if (cid:96) < t, the distribution of (si1, . . . , si(cid:96)) is uniformly random.
Concretely, Shamir’s secret sharing works as follows. Pick a1, . . ., at−1 ←$ Zp. Let f (x)
be the polynomial s + a1 · x + a2 · x2 + . . . + at−1 · xt−1. Then si is set to be f (i) for all i ∈ [n].
A.4 Non-interactive Zero-knowledge
Let R be an eﬃciently computable binary relation. For pairs (s, w) ∈ R, we refer to s
as the statement and w as the witness. Let L be the language of statements in R, i.e.
L = {s : ∃w such that R(s, w) = 1}. We deﬁne non-interactive zero-knowledge arguments of
knowledge in the random oracle model based on the work of Faust et al. [FKMV12].
Deﬁnition A.6 (Non-interactive Zero-knowledge Argument of Knowledge) Let H :
{0, 1}∗ → {0, 1}poly(κ) be a hash function modeled as a random oracle. A NIZK for a binary
relation R consists of two PPT algorithms Prove and Verify with oracle access to H deﬁned
as follows:
− ProveH(s, w) takes as input a statement s and a witness w, and outputs a proof π if
(s, w) ∈ R and ⊥ otherwise.
− VerifyH(s, π) takes as input a statement s and a candidate proof π, and outputs a bit
b ∈ {0, 1} denoting acceptance or rejection.
These two algorithms must satisfy the following properties:
− Perfect completeness: For any (s, w) ∈ R,
Pr(cid:2)VerifyH(s, π) = 1 | π ← ProveH(s, w)(cid:3) = 1.
− Zero-knowledge: There must exist a pair of PPT simulators (S1,S2) such that for all
PPT adversary A,
(cid:12)(cid:12)(cid:12)Pr[AH,ProveH
(1κ) = 1] − Pr[AS1(·),S(cid:48)
2(·,·)(1κ) = 1]
(cid:12)(cid:12)(cid:12) ≤ negl(κ)
for some negligible function negl, where
− S1 simulates the random oracle H;
− S(cid:48)
− S1 and S2 share states.
2 returns a simulated proof π ← S2(s) on input (s, w) if (s, w) ∈ R and ⊥ other-
wise;
− Argument of knowledge: There must exist a PPT simulator S1 such that for all PPT
adversary A, there exists a PPT extractor EA such that
(cid:104)
(s, w) /∈ R and VerifyH(s, π) = 1 |
Pr
(s, π) ← AS1(·)(1κ); w ← EA(s, π, Q)
(cid:105) ≤ negl(κ)
for some negligible function negl, where
− S1 is like above;
− Q is the list of (query, response) pairs obtained from S1.
40
Fiat-Shamir transform. Let (Prove, Verify) be a three-round public-coin honest-veriﬁer
zero-knowledge interactive proof system (a sigma protocol) with unique responses. Let H be
a function with range equal to the space of the veriﬁer’s coins. In the random oracle model,
the proof system (ProveH, VerifyH) derived from (Prove, Verify) by applying the Fiat-Shamir
transform satisﬁes the zero-knowledge and argument of knowledge properties deﬁned above.
See Deﬁnition 1, 2 and Theorem 1, 3 in Faust et al. [FKMV12] for more details.
(They
actually show that these properties hold even when adversary can ask for proofs of false
statements.)
B A few failed attempts in detail
B.1 Attempt 1: Distributed Encryption Scheme proposed by Naor et al.
The work of Naor et al. [NPR99], which puts forward the DPRF constructions we use in this
paper, also proposes the only distributed symmetric-key encryption proposal we are aware
of. Their proposal appeared before any formal treatment of threshold symmetric-key existed,
and in fact even prior to the introduction of authenticated encryption in the non-distributed
setting. Hence, it is only natural that their scheme does not meet the strong security notions
we introduce here. We review their protocol in Figure 11 and argue why it fails to meet the
security deﬁnitions introduced in this paper.10
(In)-security of ΠNPR. The protocol ΠNPR is CPA-secure against malicious adversaries if
the underlying DPRF satisﬁes weak-malicious security. The formal proof is similar to the
proof of the CPA-security of our protocol (c.f. Theorem 7.4) and hence we omit it. However,
we argue that ΠNPR does not satisfy authenticity (c.f. Deﬁnition 6.8) even when the corrupt
parties follow the protocol. To see this, ﬁrst observe that a ciphertext in this protocol is a
tuple c := (j, k, e) where k = y ⊕ w, y := DP(j(cid:107)e) and e ← sENC.Encryptw(m) for some
message m. After obtaining this ciphertext, an adversary can go “oﬀ-line” and compute
another ciphertext c(cid:48) = (j, k(cid:48), e) which now decrypts to m(cid:48)
:= sENC.Decryptw(cid:48)(e) where
w(cid:48) = k(cid:48) ⊕ y. This is possible since CPA-security does not guarantee that a ciphertext c
can not be decrypted with another secret-key w(cid:48) (although the message m(cid:48) will not reveal
any information about m by CPA-security). So the adversary could produce many valid
ciphertexts by running just one encryption session, and thus win the authenticity game. (If
we consider adversaries that choose their own w, then it becomes even harder to make the
scheme secure.)
The authors also mention that “in order [to] combat changes to the stored information
one should use parts of y as an authentication key to e and w” (symbols in the quote have
been replaced with the equivalent ones here). As we interpret, one can additionally use a
message-authentication code (MAC) so that the ciphertext would look like c := (j, k, e, t)
where k := w ⊕ y1, t = MACy2(e||w) and (y1||y2) := DP(j(cid:107)e). However, the modiﬁed
construction still does not satisfy the authenticity requirement (c.f. Def. 6.8) because once
an adversary gets the MAC key y2 through an encryption session, it can re-launch the same
attack, this time attaching a correct MAC computed with y2.
10We present a slightly diﬀerent version here that does not use a collision-resistant hash function or a
decryption policy, but incorporates the identity of the initiating party in computing the ciphertext. This does
not interfere in any way with the security analysis we carry out.
41
Ingredients:
− An (n, t)-DPRF protocol DP := (DP.Setup, DP.Eval, DP.Combine).
− A CPA secure symmetric-key encryption scheme:
sENC := (sENC.Kgen, sENC.Encrypt,
sENC.Decrypt).
Setup(1κ, n, t) →(cid:16)(cid:74)sk(cid:75)[n], pp
(cid:17)
DistEnc((cid:74)sk(cid:75)[n], [j : m, S], pp) → [j : c/⊥]: To encrypt a message m with the help of parties in S:
− Party j samples w ← sENC.Keygen(1κ) and computes e ← sENC.Encryptw(m). Then it sends e
: Run DP.Setup(1κ, n, t) to get ((rk1, . . . , rkn), pp(cid:48)). Set ski := rki for
i ∈ [n] and pp := pp(cid:48).
to all parties in S.
− For every i ∈ S, party i runs DP.Eval(ski, j(cid:107)e, pp) to get yi, and sends it to party j.
− Party j runs Combine({(i, yi)}i∈S, pp) to get y or ⊥. In the latter case, it outputs ⊥. Otherwise,
it outputs c := (j, k, e) where k := y ⊕ w.
DistDec((cid:74)sk(cid:75)[n], [j(cid:48) : c, S], pp) → [j(cid:48) : m/⊥]: To decrypt a ciphertext c with the help of parties in S:
− Party j(cid:48) ﬁrst parses c into (j, k, e). Then it sends j(cid:107)e to all the parties in S.
− For i ∈ S, party i receives x and checks if it is of the form j(cid:63)(cid:107)e(cid:63) for some j(cid:63) ∈ [n]. If not, then
it sends ⊥ to party j(cid:48). Else, it runs DP.Eval(ski, x, pp) to get yi, and sends it to party j(cid:48).
− Party j(cid:48) runs Combine({(i, yi)}i∈S, pp) to get y or ⊥. In the latter case, it outputs ⊥. Otherwise,
it computes w := k ⊕ y and outputs m := sENC.Decryptw(e).
Figure 11: Description of the protocol ΠNPR
B.2 Attempt 2: DPRF + Authenticated Encryption
Another natural proposal for encryption is to generate a fresh pseudorandom key using a
DPRF and use it to encrypt the message via a symmetric-key authenticated encryption
scheme. This was our ﬁrst attempt for a secure construction. It is helpful to review this
construction (Fig. 12) and show why it fails to meet our notion of authenticity, even when
the corrupt parties do not deviate from the protocol.
To see why the above scheme does not meet our authenticity notion, consider an attacker
who runs a single distributed encryption session to learn an encryption key w and uses it to
encrypt many messages “oﬀ-line”, thereby generating many new valid ciphertexts.
C Missing Proofs
C.1 Proof of Theorem 7.4
We use a sequence of hybrids to prove security, with the ﬁrst hybrid being the message privacy
game MsgPriv. We ﬁrst write down the challenge phase of MsgPriv in detail:
1. A outputs (Challenge, j(cid:63), m0, m1, S(cid:63)) where j ∈ S(cid:63) \ C and |S(cid:63)| ≥ t.
2. Compute α(cid:63) := Com(mb, ppcom; ρ(cid:63)) by picking ρ(cid:63) at random, and zi ← DP.Eval(ski, (j(cid:63)(cid:107)α(cid:63)), pp)
for every i ∈ S(cid:63) \ C.
3. Send α(cid:63) to A and get back ˆzi for every i ∈ S(cid:63) ∩ C.