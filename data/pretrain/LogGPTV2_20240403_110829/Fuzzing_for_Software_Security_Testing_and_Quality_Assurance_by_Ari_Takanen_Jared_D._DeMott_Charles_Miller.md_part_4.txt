analyzed with all possible metrics selected for use. A test lab may contain expensive,
dedicated tools for load and performance testing, as well as fuzzing. Indeed, some
commercial fuzzers have been implemented as fixed test appliances for traditional
test lab environments.
In operations, various post-deployment techniques are used to increase soft-
ware security. Vulnerability scanners or security scanners such as Nessus2 are most
commonly used in a live environment. An important criterion for test tools in an
operational environment is that they should not disrupt the operation of critical
services. Still, penetration testing services are often conducted against live systems,
as they need to validate the real environment from real threats. This is because not
all problems can be caught in the controlled confines of a test lab. Similarly, fuzz-
ing should be carefully considered for operational environments. It may be able to
find more flaws than when compared to a test lab, but it is likely to also disrupt
critical services.
2 The Nessus Security scanner is provided by Tenable Security and is available at www.nessus.org.
6760 Book.indb 3 12/22/17 10:50 AM
4 Introduction
Never forget that there is no silver bullet solution for security: Not even fuzzing
can guarantee that there are no flaws left in the software. The fast-paced world of
technology is changing, growing, and constantly evolving, for better or worse. This
is good news for testers: People will be writing new software for the foreseeable
future. And new software inevitably brings new bugs with it. Your future careers
are secured. Software continues to become more complex, and the number of bugs
is thought to be directly proportional to lines of code. The security testing tools
you have will also improve and, as you will see, fuzzing tools certainly have evolved
during the past 20 years.
1.1.1 Security Incident
The main motivation for software security is to avoid security incidents: events where
someone can compromise the security of a system through and active attack, and
where data can be disclosed or destroyed through mistakes made by people, or due
to natural disasters such as floods or tornadoes. Active compromises are the more
significant factor for discussions related to fuzzing. Accidental incidents may arise
when software is misconfigured or a single bit among massive amounts of data flips
due to the infamous alpha-particles, cosmic rays, or other mysterious reasons and
result in the crash of a critical service. Accidental incidents are still quite rare events,
and probably only concern service providers requiring extremely high availability,
handling massive amounts of data such as telecommunication, storage or cloud.
The related threat is minimal, as the probability of such an incident is insignificant.
The threat related to active attacks is much more severe.
Software security boasts a mixture of terms related to security incidents. Threats
are typically related to risks of loss for an asset (money, data, reputation). In a secu-
rity compromise, this threat becomes realized. The means of conducting the com-
promise is typically done through an attack, a script or malicious code that misuses
the system, causing the failure, or potentially even resulting in the attacker’s taking
control of the system. An attack is used to exploit a weakness in the system. These
weaknesses when verified to be exploitable are called software vulnerabilities, but
can also be called defects, or flaws in the system.
Example threats to assets include:
• Availability of critical infrastructure components;
• Data theft using various technical means.
Example attacks are the actual exploitation tools or means:
• Viruses and worms that take advantage of zero-day flaws;
• Distributed denial of service (DDoS) attacks.
Weaknesses can be, for example,
• Openness of wireless networks;
• Processing of untrusted data received over the network;
• Mishandling of malicious content received over the network.
6760 Book.indb 4 12/22/17 10:50 AM
1.1 Software Security 5
Even casual security hackers are typically one step ahead of the system admin-
istrators who try to defend their critical networks. One reason for that is the easy
availability of vulnerability details and attack tools. You do not need to keep track
of all available hacking tools if you know where you can find them when you need
them. However, now that computer crime has gone professional, all the tools used
by hackers might not be available to the good guys. Securing assets is becoming
more challenging, as white-hat hacking is becoming more difficult.
1.1.2 Disclosure processes
There are thousands of software flaws just waiting to be found and, given enough
time, they will be found.3 It is just a matter of who finds them first and what they
do with the findings. In the worst case, each found security issue could result in a
patch and penetrate race: A malicious user tries to infiltrate the security of the ser-
vices before the administrators can close the gaping holes, or a security researcher
keeps reporting issues to a product vendor one by one over the course of many
months or years, forcing the vendor to undergo a resource-intensive patch testing,
potential recertification, and worldwide rollout process for each new reported issue.
Three different models are commonly used in vulnerability disclosure processes:
1. No disclosure: No details of the vulnerability, nor even the existence of the
vulnerability, are disclosed publicly. This is often the case when vulner-
abilities are found internally, and they can be fixed with adequate time and
prioritization. The same can also happen if the disclosing organization is a
trusted customer or a security expert who is not interested in gaining fame
for the findings. People who do not like the no-disclosure model often argue
that it is difficult for the end users to prioritize the deployment of updates
if they do not know whether they are security-related and that companies
may not bother to fix even critical issues quickly unless there is direct pres-
sure from customers to do so.
2. Partial disclosure: This is the most common means of disclosure in the
industry. The vendor can disclose the nature of the correction and even a
workaround when a proper correction is not yet available. The problem
with partial disclosure is that hackers can reverse-engineer the corrections
even when limited information is given. Most partial disclosures end up
becoming fully known by those who are interested in the details and have
the expertise to understand them.
3. Full disclosure: All details of the vulnerability, including possible exploitation
techniques, are disclosed publicly. In this model, each reader with enough
skill can analyze the problem and prioritize it accordingly. Sometimes users
decide to deploy the vendor-provided patches, but they can also build other
means of protecting against attacks targeting the vulnerability, including
deploying intrusion detection systems or firewalls. Full disclosure is the
3 For example, according to CVE details database, top 10 vendors had total of 4,600 vulnerabilities
found in 2016; www.cvedetails.com.
6760 Book.indb 5 12/22/17 10:50 AM
6 Introduction
default for open source projects as code commits, comments and discus-
sions are usually public.
From an end-user perspective, there are several worrisome questions: Will an
update from the vendor appear on time, before attackers start exploiting a reported
vulnerability? Can we deploy that update immediately when it becomes available?
Will the update break some other functionality? What is the total cost of the repair
process for our organization?
As a person conducting fuzzing, you may discover many critical vulnerabilities
that can affect both vendors and end users. You may want to consider the conse-
quences before deciding what to do with the vulnerabilities you find. Before blowing
the whistle, we suggest you familiarize yourself with the works done on vulnerability
disclosure at Oulu University Secure Programming Group (OUSPG).4
1.1.3 Attack Surfaces and Attack Vectors
The most important aspect of software vulnerabilities is the accessibility of the vul-
nerability. Software vulnerabilities have security implications only when they are
accessible through external interfaces. Such vulnerabilities also must have triggers
that can be identified and are repeatable.
Fuzzing enables software testers, developers, and researchers to find vulner-
abilities that can be triggered by malformed or malicious inputs via standard inter-
faces. This means that fuzzing is able to cover the most exposed and critical attack
surfaces in a system relatively well. Attack surface has several meanings, depending
on what is analyzed. To some, attack surface means the source code fingerprint
that can be accessed through externally accessible interfaces. This is where either
remote or local users interact with applications, like loading a document into a
word processor, or checking email from a remote mail server. From a system testing
standpoint, the total attack surface of a system can comprise all of the individual
external interfaces it provides. It can consist of various network components, vari-
ous operating systems and platforms running on those devices, and finally, all client
applications and services.
Interfaces where privilege changes occur are of particular interest. For example,
network data is unprivileged, but the code that parses the network traffic on a
server always runs with some privilege on its host computer. If an attack is possible
through that network-enabled interface—for example, due to a vulnerability in mes-
sage parsing code—an unprivileged remote user could gain access to the computer
doing the parsing. As a result, the attacker will elevate its privileges into those of
the compromised process. Privilege elevation can also happen from lower privileges
to higher privileges on the same host without involving any network interfaces.
An example of fuzzing remote network-enabled attack surfaces would be to
send malformed Web requests to a Web server, or to create malformed video files
for viewing in a media player application. Currently, dozens of commercial and
free fuzz testing frameworks and fuzz-data generators of highly varying testing
4 Vulnerability disclosure publications and discussion tracking, maintained by University of Oulu since
2001. Available at https://www.ee.oulu.fi/research/ouspg/Disclosure_tracking.
6760 Book.indb 6 12/22/17 10:50 AM
1.1 Software Security 7
capability exist. Some are oriented toward testing only one or a few interfaces with
a specialized and predefined rule set, while others are open frameworks for creat-
ing fuzz tests for any structured data. The quality of tests can vary depending on
the complexity of the interface and the fuzzing algorithms used. Simple tools can
prove very good at testing simple interfaces, for which complex tools could be too
time-consuming or expensive. On the other hand, a complex interface can only be
tested thoroughly with a more capable fuzzing system.
The various routes into a system, whether they are remote or local, are called
attack vectors. A local vector means that an attacker already has access to the system
to be able to launch the attack. For instance, the attacker may possess a user-name
and password, with which he or she can log into the system locally or remotely.
Another option is to have access to the local user interface of the system. Note that
some user interfaces are realized over the network, meaning that they are not local.
The attacker can also have access to a physical device interface such as a USB port.
As examples a local attack vector can consist of any of the following:
1. Graphical user interface (GUI);
2. Command line user interface (CLI);
3. Programming interfaces (API);
4. Files;
5. Local network loops (RPC, Unix sockets or pipes, etc.);
6. Physical hardware access.
Much more interesting interfaces are those that are accessible remotely. Those are
the ones on which fuzzing has traditionally focused. Note that many local interfaces
can also be accessed remotely through active content (ActiveX, JavaScript, Flash)
and by fooling people into activating malicious content (media files, executables).
Most common categories of remote interfaces that fuzzers test are displayed
in Figure 1.2.
1. Web applications: Web forms are still the most common attack vector. Prob-
ably half of all publicly reported vulnerabilities are related to various pack-
aged or tailored Web applications, often unique to a specific Web service or
application. Almost all of those vulnerabilities have been discovered using
various forms of fuzzing although today there are more static analysis tools
that understand Web application vulnerabilities.
Figure 1.2 Categories of remote attack vectors in most network-enabled systems.
6760 Book.indb 7 12/22/17 10:50 AM
8 Introduction
2. Digital media: File formats are transferred as payloads over the network (e.g.,
downloaded over the Web or sent via email). There are both open source and
commercial fuzzers available for almost any imaginable file format. Many
fuzzers include simple Web servers or other tools to automatically send the
malicious payloads over the network, whereas other file fuzzers are com-
pletely local. Interesting targets for file fuzzers are various media gateways
that cache, proxy, or convert various media formats, antivirus software that
has to be able to separate valid file contents from malware, and, of course,
various widely used operating system components such as graphics libraries
or metadata indexing services.
3. Network protocols: Standardization organizations such as IETF and 3GPP
have specified hundreds of communication protocols that are used every-
where in the world. A network protocol fuzzer can be made to test both
client- and server-side implementations of the protocol. A simple router on
the network can depend on dozens of publicly open protocol interfaces, all
of which are extremely security-critical due to the requirement of the router
being available for any remote requests or responses.
4. Wireless infrastructure: All wireless networks are always open. Fuzzing has
been used to discover critical flaws in Bluetooth and 802.11 WLAN (WiFi)
implementations, for example, with these discoveries later emerging as sophis-
ticated attack tools capable of exploiting wireless devices several miles away.
Wireless devices are almost always embedded, and a flaw found in a wireless
device has the potential of resulting in a total corruption of the device. For
example, a flaw in an embedded device such as a Bluetooth-enabled phone
can totally corrupt the memory of the device with no means of recovery.
Fuzzers are already available for well over one hundred different attack vectors,
and more are emerging constantly. The hottest trends in fuzzing seem to be related
to communication interfaces that have just recently been developed. One reason for
that is that those technologies are most immature, and therefore security flaws are
easy to find in them. Some very interesting technologies for fuzzers include
• Next Generation Networks (Triple-Play) such as VoIP and IPTV;
• Data/video streaming protocols such as MPEG2-TS (DVB-C/S/T);
• IPv6 and related protocols;
• Wireless technologies such as WiFi, 6LoPAN, Zigbee, Bluetooth, NFC,
and RFID;
• Industrial networks (SCADA);
• Vehicle area networks such as CAN and MOST.
We will not list all the various protocols related to these technologies here,
but if you are interested in finding out which protocols are the most critical ones
for you, we recommend running a port scanner5 against your systems, and using
5 One good free port scanner is NMAP. Available at http://insecure.org/nmap.
6760 Book.indb 8 12/22/17 10:50 AM
1.1 Software Security 9
network analyzers6 to monitor the actual data being sent between various devices
in your network.
1.1.4 reasons Behind Security Mistakes
Clearly, having security vulnerabilities in software is a bad thing. If we can define
the attack surface and places where privilege can be elevated, why can’t we simply
make the code secure? The core reason is that the fast evolution of communications
technologies has made software overwhelmingly complex. Even the developers of
the software may not understand all of the dependencies in the communication
infrastructure. Integration into off-the-shelf frameworks, third-party libraries, com-
ponents and operating systems brings along with it unnecessary network services
that should be shut down or secured before deploying the products and services.
Past experience has shown that all complex communication software is vulnerable
to security incidents: The more complex a device is, the more vulnerable it usually
proves in practice. For example, some security solutions are brought in to increase
security, but they may instead enable new vulnerabilities due to their complexity.
If a thousand lines of code have on average between two to ten critical defects, a
product with millions of lines of code can easily contain thousands of flaws just
waiting to be found. For secure solutions, look for simple solutions over complex
ones, and minimize the feature sets instead of adding anything unnecessary. Every-
thing that is not used by majority of the users can probably be removed completely
or shut down by default. If you cannot do that or do not want to do that, you have
to test (fuzz) that particular feature thoroughly.
Standardization and harmonization of communications have their benefits, but
there is also a downside to them. A standardized homogeneous infrastructure can
be secure if all possible best practices are in place. But when security deployment is
lacking in any way, such an environment can be disrupted with one single flaw in
one single standard communication interface. Viruses and worms often target widely
deployed homogeneous infrastructures. Examples of such environments include
email, Web, and VoIP. A unified infrastructure is good from a security point of
view only if it is deployed and maintained correctly. Most people never update the
software in their wireless home routers and printers. Think about it! Some people do
not even know if they can update the software on their cars, or worse, have to pay
for the updates. If you do not want to update all those devices every week, it might
be beneficial to try to fuzz them, and maybe fix several flaws in one fell swoop.
Open, interconnected wireless networks pose new opportunities for vulner-
abilities. In a wireless environment, anyone can attack anyone or anything. Wire-
less is by definition always open, no matter what authentication and encryption
mechanisms are in place. For most flaws that are found with fuzzing in the wireless
domain, authentication is only done after the attack has already succeeded. This is
because in order to attempt authentication or encryption, input from an untrusted
source must be processed. In most cases the first message being sent or received in
wireless communications is completely anonymous and unauthenticated. If you do
6 One popular network analyzer is Wireshark. Available at www.wireshark.org.
6760 Book.indb 9 12/22/17 10:50 AM
10 Introduction
not need wireless, do not use it. If you need to have it open, review the real opera-
tion of that wireless device and at minimum test the handling of preauthentication
messages using fuzzing.
Mobility will increase the probability of vulnerabilities, but also will make it
easier to attack those devices. Mobile devices with complex communication software
are everywhere, and they often exist in an untrusted environment. Mobility will also
enable anonymity of users and devices. Persons behind security attacks cannot be
tracked reliably. If you have a critical service, it might be safer to ask everyone to
authenticate himself or herself in a secure fashion. At minimum, anything that can
be accessed anonymously has to be thoroughly tested for vulnerabilities.
1.1.5 proactive Security
For an enterprise user, there are typically two different measures available for protect-
ing against security incidents: reactive and proactive. The main difference between
reactive security measures and proactive security measures is who is in control of