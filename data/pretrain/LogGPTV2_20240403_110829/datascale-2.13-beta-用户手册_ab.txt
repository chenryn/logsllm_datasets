• 将 source 组件的输出连接到 sink 组件的输入，并点击 “保存” 按钮
通过 过配置文件配置 dataflow通过 过配置文件配置 dataflow
• 在安装目录的 ./config/group/default/dataflow/ 路径下创建 dataflow 配置文件
{ 
	"name": "my_first_dataflow", 
	"sources": [ 
	{ 
	"name": "file_source", 
	"type": "file", 
	"conf": { 
	"include": [ "/tmp/my_file.log" ] 	} 
	} 
	], 
	"pipelines": [],
• 重新启动 DataScale 服务
信息
• 关于 dataflow 配置文件的格式，参见文档 Dataflow 配置
• 关于 source / sink 组件的类型和配置参数，参见文档 Source 组件，Sink 组件
导入数据 
将数据写入数据源文件：导入数据 
将数据写入数据源文件：
$ echo "this is event 1" >> /tmp/my_file.log $ echo "this is event 2" >> /tmp/my_file.log $ echo "this is event 3" >> /tmp/my_file.log
查询数据 
在炎凰数据平台的数据集 my_event_set 中查询采集到的数据：
	版本：2.13.0-beta 
更多 dataflow 实 实例
使用 DataScale 采集数据的更多例子。
📄采集 Nginx 访问 访问日志
Nginx 是一种流行的 HTTP 服务器和反向代理服务器。
	版本：2.13.0-beta 
采集 Nginx 访问 访问日志版本：2.13.0-beta 
采集 Nginx 访问 访问日志
 是一种流行的 HTTP 服务器和反向代理服务器。作为 HTTP 服务器，Nginx 可以非常有效和 可靠地提供静态内容；作为反向代理，它可以用作多个后端服务器或其他应用程序（例如缓存和负载 平衡）的单个访问入口。 Nginx 同时提供了免费的开源版本，以及更能更全面的商业发行版本 Nginx
Plus。
目标
配置 dataflow 从文件中采集 Nginx 访问日志，导入炎凰数据平台。并通过使用炎凰数据平台内置的 数据源类型 nginx.access_log 自动完成 Nginx 访问日志的字段解析。
信息
关于炎凰数据平台的数据源类型的功能介绍以及可用的内置数据源类型，参见炎凰数据平台相 关文档。
步骤
创建数据集
在炎凰数据平台中为 Nginx 访问日志创建数据集（在本例中将使用数据集在炎凰数据平台中为 Nginx 访问日志创建数据集（在本例中将使用数据集
my_nginx_access_log）。
	信息 
如果你使用的是鸿鹄，需要在 Vector input 允许的数据集范围中加入数据集 my_nginx_access_log
配置 dataflow
通过 过 Web UI 配置 dataflow
• 在 default 群组中创建 dataflow my_nginx_access_log
• 添加 dataflow 的 source 组件 nginx_access_log_source 、pipeline 组件 	nginx_access_log_pipeline和 sink 组件nginx_access_log_sink
• 将 source 组件的输出连接到 pipeline 组件的输入，将 pipeline 组件的输出连接到 sink 组件 	的输入，并点击 “保存” 按钮通过 过配置文件配置 dataflow
• 在安装目录的 ./config/group/default/dataflow/ 路径下创建 dataflow 配置文件
{ 
	"name": "my_nginx_access_log", 
	"sources": [ 
	{ 
	"name": "nginx_access_log_source", 
	"type": "file", 
	"conf": { 
	"include": [ "/usr/local/var/log/nginx/access.log" ] 	} 
	} 
	], 
	"pipelines": [ 
	{ 
	"name": "nginx_access_log_pipeline", 
	"inputs": [ "nginx_access_log_source" ], 
	"conf": { 
	"transforms": ["conf": { 
	"transforms": [ 
	{ 
	"type": "datatype", 
	"conf": { 
	"datatype": "nginx.access_log" 
	} 
	} 
	] 
	} 
	} 
	], 
	"sinks": [ 
	{ 
	"name": "nginx_access_log_sink",
• 重新启动 DataScale 服务
	信息
• 本例中的 Nginx 访问日志文件的路径为 /usr/local/var/log/nginx/ 	access.log，请根据实际情况修改此路径。
• 数据源类型 nginx.access_log 适用于解析使用默认格式的 Nginx 访问日志• 关于 Pipeline 组件以及 transform 方法的类型和配置参数，参见文档 Pipeline 组件
导入数据导入数据 
确认日志文件 /usr/local/var/log/nginx/access.log 中已经存有日志（如果日志文件为 空，可以通过访问 Nginx 服务使之生成新访问日志）。
查询数据 
在炎凰数据平台的数据集 my_nginx_access_log 中查看采集到的日志 event 的内容和自动解析 出的字段
信息
每个 event 的数据源类型是由 _datatype 字段指定。
版本：2.13.0-beta 
基础 础指南
基础的 DataScale 的使用指南。
📄配置 DataScale 服务
DataScale Web UI 提供了一部分常用的服务配置参数的配置页面。但对于其他的配置参数，你需要参考 DataScale 服务的配置文件，文件路径为安装目录下的 config/datascale.toml。
📄配置 Group📄配置 Group
通过 Web UI 配置 group
🗃配置 Dataflow
| 3 个项目 |
|---|
| 📄监 监控 DataScale 服务 |
DataScale 服务运行过程中产生的日志和指标数据可以用于监控服务的运行状态，以及诊断服务的异常状态。
📄命令行工具
可执行文件 ./bin/datascale 位于 DataScale 的安装路径下。
📄 Restful API
关于 DataScale 服务的 Restful API 完整列表，参见 DataScale Swagger UI。
版本：2.13.0-beta
配置 DataScale 服务
DataScale Web UI 提供了一部分常用的服务配置参数的配置页面。但对于其他的配置参数，你需要参考 DataScale 服务的配置文件，文件路径为安装目录下的 config/datascale.toml 。你可以修改此配置 文件中的参数，或者设置参数相对应的环境变量来调整服务运行时的行为和状态。信息 
如果你直接修改配置文件，需要重启 DataScale 服务才能使改动生效。
配置文件 
config/datascale.toml文件中对于每个参数的作用都有注释加以说明，在这里仅对其中部分参数的 用法做更详细的描述。
Service 配置 
service.address参数用于设置 DataScale 服务的监听地址，默认为0.0.0.0:7881（API 服务 监听地址）。当默认地址在实际部署环境中有冲突时，可以修改此参数的值，使用新的监听地址。
service.mode参数用于设置 DataScale 服务运行时的模式，可以为worker或者manager。
当 DataScale 服务运行在 worker 模式时，可以选择配置该 worker 是否接受某个 manager 的管理：• 如果该 worker 不需要接受任何 manager 的管理，可以将 service.worker.manager_address 	的值为空，那么它的所有 dataflow 相关配置都将使用本地配置。
假设 worker 所属的 group 为 default ，配置如下：
[service] 
mode = "worker"
• 如果该 worker 需要接受某个 manager 的管理，则需要将 service.worker.manager_address 的值设置为该 manager 的地址，并需要指定自己所属的 group，那么它将会从 manager 接收所有 指定的 group 的 dataflow 相关配置。
假设 manager 的 API 服务地址为 http://172.16.0.1:7881 ，worker 所属的 group 为 default，则配置如下：[service] 
mode = "worker" 
[service.worker] 
	manager_address = "http://172.16.0.1:7881" 	groups = "default"
当 DataScale 服务运行在 manager 模式时，它将不再负责任何 dataflow 的执行，而只负责 group 和 dataflow 相关配置的管理，并负责将 dataflow 相关配置推送到所有连接到它的 worker。
配置如下：
[service] 
mode = "manager"
信息
• 当 worker 同时属于多个 group 时，使用逗号分隔 service.worker.groups 参数中的多 	个 group 名称。
• 当 worker 接受 manager 的管理时，任何本地的 dataflow 配置都会被来自 manager 的配置覆盖。
• 关于 group 的介绍，参见 DataScale 基础。
Backend 配置
backend.type参数用于设置 DataScale 服务将 event 发送到炎凰数据平台的方式。
如果你使用的是 YHP（炎凰数据平台商业 业版），发送方式应该设置为 yh_kafka ，并设置目标炎凰数据平 台的 Kafka 服务的信息。
假设 YHP 的 Kafka 地址为 172.16.0.1:30000 ，数据集对应的 Kafka topic 名称的前缀为 yh ，YHP 部署所在的 Kubernetes namespace 为 yanhuang ，则配置如下：
type = "yh_kafka" 
[backend.yh_kafka] 
	bootstrap_servers = "172.16.0.1:30000" 	topic_prefix = "yh"k8s_namespace = "yanhuang"
如果你使用的是 鸿鹄 鸿鹄（炎凰数据平台社区版），发送方式应该设置为 yh_vector ，并设置目标炎凰数据 平台的 Vector 服务的信息。
假设鸿鹄的 Vector 服务的地址为 172.16.0.1:20000 ，则配置如下：
type = "yh_vector" 
[backend.yh_vector] 
	address = "172.16.0.1:20000"
Metastore 配置
metastore.type参数用于设置 DataScale 服务保存配置的方式，可以是file或者sqlite。
当使用 file 类型的 metastore 时，DataScale 服务的配置保存在安装目录下的 config/ 目录下的文
件中，主要包括：
•	config/extension/collector/存放内置以及自定义 collector 的配置（参见文档 自定义采集器）
•	config/group/存放 group 信息以及该 group 范围内的配置（参见文档 配置 Group）
•	config/group//dataflow/存放该 group 内的 dataflow 的配置（参见文档 配
置 Dataflow）
•	config/instance_info/存放当前 DataScale 服务的安装标识信息（参见文档 Instance ID）
•	config/dataflow/存放 dataflow 中可以使用的 source / pipeline / sink 组件的配置模版
•	config/vector/存放内置数据采集器 Vector 的全局配置
当使用 sqlite 类型的 metastore 时，DataScale 服务会将上述配置项保存在 SQLite 文件中。
信息信息
目前 sqlite 类型的 metastore 仍处于 Beta 测试阶段。
环境变 变量
配置文件 config/datascale.toml 中每个参数都有对应的环境变量，你可以通过设置环境变量，覆盖 配置文件中对应的参数的值。
环境变量的名字的格式为：
DATASCALE_
• 变量名的前半部分为 DATASCALE_
• 变量名的后半部分为参数的路径，其中所有的字母为大写形式，并使用下划线作为分隔符
例如：
• 环境变量 DATASCALE_SERVICE_ADDRESS 可以覆盖参数 service.address
• 环境变量 DATASCALE_SERVICE_WORKER_GROUPS 可以覆盖参数 service.worker.groups• 环境变量 DATASCALE_BACKEND_YH_KAFKA_BOOTSTRAP_SERVERS 可以覆盖参数版本：2.13.0-beta
配置 Group
通过 过 Web UI 配置 group
DataScale Web UI 提供了创建、修改、启停、删除等 group 管理功能：
通过 过 Restful API 配置 group
DataScale 服务提供了创建、修改以及删除 group 的 Restful API，参见文档 Restful API
通过 过文件配置 group
当使用 file 类型的 metastore 时（参见 Metastore 配置），可以直接通过配置文件配置
group。
创建 group
• 在 DataScale 安装路径下创建目录 config/group/my_group/ ，目录名 my_group 即 	是 group 名称。
• 在 group 目录下创建 meta 文件 config/group/my_group/meta.json ，文件内容如下：
{ 
	"name": "my_group", 
	"description": "Description of my_group" }
重命名 group
• 重命名 group 目录 config/group/my_group/ ：
$ mv config/group/my_group config/group/my_new_group
• 修改 meta 文件 config/group/my_new_group/meta.json 中的 group 信息：