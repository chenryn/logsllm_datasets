tended to be done together (e.g., checking for viruses in
attachments from both known and unknown sources and
changing passwords frequently as well as checking for
viruses in attachments from known sources). Hence, likely
these students were more attuned to particular risks and
willing to take action against them, an approach that may
arise out of the primary sources of information being their
own or friends’ experiences with security problems.
Faculty in medicine and electrical engineering who used
university supplied (but not maintained) laptops were likely
to have security software (anti-virus, anti-spyware, spam
ﬁlter or ﬁrewall) installed, but were lax about backups
[11]. More than 92% of those surveyed had some security
software installed with anti-virus software being the most
common (87% of subjects) and spam ﬁlter the least (31%
of subjects). These users were highly educated and motivated
to protect their portable, employer owned machines.
From a behavioral viewpoint, perhaps the most written
about approach to security is password protection. The
problems with passwords have been addressed by empirical
studies (e.g., [40], [41], [42], [19], [43], [44], [45]), position
pieces on the need for alternative approaches (e.g., [46],
[47]) and even the popular press (e.g., [48]). The scope of the
literature is beyond that of this paper. The primary ﬁnding
is that while users do understand the merits of strong pass-
words, current procedures impose too hard a burden on users
which in turn has them undermining the safeguards (e.g., re-
using passwords, writing or storing passwords in unsecured
locations, sharing passwords). Following the rules suggested
by some security experts would require the average user to
remember a large number of different passwords (estimates
of accounts requiring passwords vary from tens to hundreds
per user) that may have to conform to different constraints
depending on the site (constraints that are designed to make
them harder to type and remember). Human memory and
patience does not appear to be up to this challenge.
users either don’t see the need and/or are not willing to incur
the cost of security measures (too much time or money or
loss of access to desired beneﬁts). In [5], 19% of respondents
indicated that security software was too expensive.
Downloading software applications is a major source of
security breaches because of software bundling. Installation
includes notices such as End User Licensing Agreements
(EULAs), software agreements and Terms of Service (TOS).
Anecdotal evidence supports the observation that users do
not read such notices. As a famous case in point, PC Pitstop
included a clause in one of its EULAs that offered “special
consideration which may include ﬁnancial compensation”
to anyone who contacted them at a particular email address;
it took more than 3,000 downloads before anyone sent an
email [49].
A study of 31 undergraduates examined the effect of
installation notices on decisions to download software [50].
The study presented the participants with the scenario that
they were helping a friend set up a new computer and
had been asked to install “appropriate” applications from
a set of ﬁve that had been recommended: Google Toolbar,
Webshots, Weatherscope, KaZaA and Edonkey. As part of
the installation process, one-third of the participants were
presented with the standard EULA, one-third with the EULA
plus a Microsoft Windows XP Service Pack 2 warning, and
one-third with the EULA plus a customized short notice. The
customized notice answered four questions (constructed by
the study authors carefully reading the agreements provided
with the software): what information is collected, how is this
information collected, how is this information used, and how
does this program affect your computer. Data were collected
about the installations done, and post-study interviews were
conducted with each participant. The most important factor
inﬂuencing download decisions was whether the software
was perceived to be “useful”. For example, many partici-
pants considered ﬁle sharing software to be essential and
were willing to incur risk for it; although given that they
were offered a choice of two in the study, they tended to
select the one they perceived incurred the least risk. Brand
name trust and prior experience did appear to factor in as
93% installed the Google Toolbar and only 47% installed
KaZaA; many participants stated that they had previously
had a negative experience with it. The additional notices did
appear to improve understanding of the risks (11 out of 21
participants stated that the additional notices had affected
their decision to install), but the effect was not signiﬁcant
between the customized notice and the Windows warning.
This study suggests that simply improving the notiﬁcations is
not enough; users may need to be presented with alternatives
that satisfy the same utility with less risk.
B. Attitudes to Security Interventions
VI. RECOMMENDATIONS FOR FUTURE WORK
Security countermeasures require time and sometimes
cost. The evidence of studies (e.g., [6], [8]) suggests that
The studies support a set of recommendations about future
research and development of security tools for home users.
219
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:21 UTC from IEEE Xplore.  Restrictions apply. 
In particular, we identify six distinct areas that we believe
require particular attention.
Choosing a proper methodology for user study: We believe
that the methodologies for home user studies need to be
broadened. Most of the studies involved self-report surveys.
Yet, self reports of taking security and privacy precautions,
e.g., downloading patches, protecting passwords, can vary
widely between studies. Studies that have been able to verify
user’s reports on their computers have uncovered lower
actual than reported rates of some behaviors [33], [7]. As
[37] showed, peer perception does inﬂuence how people
respond; so some of the responses may reﬂect more of
what the respondent thinks they should be doing than what
they actually are (e.g., respondent bias, socially desirable
responding). In addition, people are not very good at pre-
dicting what they would do in a particular situation. These
factors help explain why some of the survey results are
contradictory and do not match actual behavior. Whenever
possible, self-reporting surveys need to be conﬁrmed by
checking intention versus actual behavior.
Another approach is experiments based on simulation
– where the participant is put in the actual situation and
monitored. The simulation can support a set of user and
computer actions that trigger threats of interest. For example,
user actions may include emailing, Web browsing, online
shopping, social networking, online banking and peer-to-
peer activities. Computer actions may include pop-ups ask-
ing to download a program, asking for registration at a site in
order to proceed, or asking for the user to agree to licensing
terms for use of a site. At the end, the participant can be
asked about beneﬁts such as convenience, time, access to a
greater selection, access to the site, access to the program,
overcoming geographic and time boundaries, ease of access,
and connecting with multiple people at one time.
A simulation based study can also help us assess the
emotional reactions of users to interventions and warnings.
The purpose of this assessment is to bypass a participant’s
responses that may be driven by ego-protection (e.g., “I don’t
want them to think I’m afraid”), demand characteristics (i.e.,
participant gives what they think is an expected response),
or experimenter bias (i.e., experimenter inadvertently treats
participants in a leading manner due to his or her expecta-
tions for the study).
Assessing the impact of demographics: A few studies
showed differences due to demographics (e.g., [8], [14],
[9], [15]). Additionally, some studies hint at effects due to
age, interests, location, socioeconomics and education. For
example, the majority of studies have been conducted with
undergraduate subjects. Given hints from existing studies
and intuition about this subject group, one would expect to
see signiﬁcant differences between this group and others.
One study [50] indicated that undergraduates consider P2P
software to be indispensable, which is probably not the case
with older adults. Undergraduates have a level of education,
experience with computers and economic stability that is
not true of all groups. Another study [9] suggested that
socioeconomic factors, such as income, may inﬂuence the
view of vulnerability. We believe that new studies should
cover a broader range of society and identify the common-
alities and differences between them in their perceptions of
risk, threats, and adaptive behaviors. As a starting point,
we suggest studying college age individuals (18–29 years
of age) and adults aged 50–64 years. Both these groups
are considered vulnerable populations for security threats;
studies suggest that seniors are among the most vulnerable
demographics for spyware [51].
Assessing the users’ understanding of threat and potential
consequences of each threat: According to Fox [52] users
may not always understand the various security threats
and their magnitude as they engage in online behavior.
Considerable research has been done on usability of security
tools; not enough has been done to elucidate how users
understand privacy and security threats, and their potential
consequences. Users who lack an understanding of both
threat and its consequence may exhibit inappropriate defen-
sive strategies when engaging in online behavior. We believe
that a qualitative methodology for assessing user understand-
ing of threat and consequence associated with each threat
is most appropriate for this investigation. Qualitative data,
which are in the form of words provided by subjects under
study, provide rich explanations and descriptions of subjects’
perceptions and choices. By asking subjects to provide their
own words to answer a question, researchers avoid priming
participants, or providing them hints from which to create
answers that they believe the researcher wants rather than
their own answers [53].
Assessing the factors that inﬂuence decision making about
security: Security knowledge and high self-efﬁcacy are im-
portant determinants of secure behavior. For example, stud-
ies such as [24], [35] show that users with high knowledge of
computer skills tend to practice safer behaviors and employ
more security strategies. Users with a better understanding
of computers in general also had a better appreciation of the
consequences of risky action [15].
Some studies (e.g., [16], [26]) suggest that many users
have incomplete and partially incorrect mental models of
security threats, risks and consequences of actions. Even
when users have some idea of what they should do, they
are often unwilling to incur the costs (cognitive, opportunity
and ﬁnancial) to do so. For example, studies such as [50],
[33] show that users are willing to incur higher risk of
negative consequences when they really want the service
(e.g., Facebook, P2P software). Users are more willing to
divulge more personal information when they perceive a
positive gain from that information exchange [54]. However,
previous studies have not identiﬁed levels of gain associated
with levels of risk. Such a study will be needed to develop
a formula for risk-taking decision-making that can then be
220
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:21 UTC from IEEE Xplore.  Restrictions apply. 
used by an appropriate security tool. To understand risk
relative to beneﬁt decision-making, we opine that a scale
for assessing perceptions be formulated. Currently no such
scale exists for determining which risk computer users are
willing to make and for what gain. Hence, the development
of such a scale will make a signiﬁcant contribution to the
development of security and privacy protection solutions.
Such information informs the decisions that users make
about behaviors online and actions to mitigate security
threats. More studies are needed to identify where poor
mental models produce poor decisions. What exact data
to collect depends on the goal of the study; however, the
signiﬁcant factors found in [14], [24], [35], [32], [37], [39]
provide good starting points. Also, research should explore
how security tools might allow the user to take calculated
risks, while minimizing the damage.
Identifying factors and approaches for improved design
of security and privacy software and policies: Education
certainly should play a role in encouraging home users to
take security precautions, but there is evidence that users are
not willing to take the time to do so. For example, a study
of 206 undergraduates found that by making most students
more aware that online safety was their responsibility, the
intention to practice safety online increased (over suggesting
it was not their responsibility) except for those not interested
in safety issues and who were not conﬁdent in their abilities
to protect themselves [55]. In light of some of such ﬁndings,
education may need to be tailored to an individual. In
fact,
the authors [55] suggested that security education
websites might pre-screen visitors and then route them to
tailored messages (e.g., utilize computer-adaptive training).
Similarly, Davinson and Sillence [36] concluded from their
study that participants may have changed their behavior
because they believed that the security information they were
given had been tailored based on their risk level.
Software and approaches for security and privacy protec-
tion need to be better designed to address both current and
future needs of home users. Current practice does not appear
to be adequate. Home user studies suggest incorporating
factors that matter to people (e.g., ease of use, control of
personal ﬁles); such information should be leveraged to
produce approaches that are easily manageable by users and
appeal to their abilities and concerns. West [25] suggests
having default software settings be more secure and making
the activities of security protections more obvious to the user
so that they can gain an appreciation of the protection they
are producing.
A more ambitious approach is to broaden and integrate
the activities of security tools to be more comprehensive
in their protection and to reduce the incremental overhead
of the current suite of necessary actions. Having to employ
different tools for different threats (e.g., installing antivirus
software, disabling ﬂash, creating strong passwords) imposes
a high burden on home computer users. To the extent possi-
ble, protections should be automated and straightforward to
understand; safer behavior has been identiﬁed in users with
automated software updates and habits of safe behavior [24].
Conducting longitudinal studies: Given the rate of change
and inﬂuence of the Internet, it is difﬁcult to know whether
results from 10 years ago still apply. Longitudinal stud-
ies could identify the inﬂuence of ongoing education (as
computer training becomes more common in schools), new
technologies (e.g., rise of Twitter), news events (e.g., recent
press on the Stop Online Piracy Act) and ongoing efforts
to inform the public (e.g., Google’s recent email and media
notiﬁcation of its new privacy policy).
VII. CONCLUSIONS
Generally, home computer users view others as being
more at risk. When they are aware of the threats, home
computer users do care about security and view it as their
responsibility. However, many studies suggest
that users
often do not understand the threats and sometimes are not
willing or able to incur the costs to defend against them.
At least three studies [24], [50], [32] found that users still
want the beneﬁts of potentially unsafe behavior. Herley [47]
argues that rejection of security advice might actually be
a rational choice when the security measures and costs are
carefully assessed.
The challenge of user-centered security [56] clearly sub-
sumes some of the issues discussed in this paper; a great deal
more needs to be done both in terms of facilitating models of
the user and suitable approaches to security that conform to
these models. As we recommend in Section VI, user studies