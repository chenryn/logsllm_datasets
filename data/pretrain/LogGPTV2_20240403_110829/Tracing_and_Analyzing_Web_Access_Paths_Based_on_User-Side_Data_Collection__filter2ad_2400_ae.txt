data analysis will not reﬂect the behavior of global web users.
Second, depending on the purpose of analysis, the method
used to label malicious URLs needs to be reviewed, . We
used GSB entries to ﬂag malicious URLs; however, this is
not always desirable. Depending on the policies, users may
implement different blacklists.
Third, the scale of the dataset is limited. Although the
number of browser extension users was sufﬁcient for the
analysis in this paper, it is very small considering the number
of web users in general. In particular, the number of victims
is too small. When conducting other types of analysis, such as
user classiﬁcation, the scale of the data can be insufﬁcient, and
one such example is discussed in Section 6.4. To cope with
this issue, measures such as effective campaigns to attract
e.g., users’ navigation information, which enables us
to analyze users in detail. Indeed, our browser extension
can collect data that are not listed in Section 2.1, such
as the list of installed browser extensions and process
information.
This paper demonstrated the usability of our data collection
and analysis approach, and we hope this paper will encourage
per-user data analysis to better protect users.
6.2 Attracting and Motivating Users
In this work, the primary is the number of users who install
our browser extension and continue using it. The browser
extension collects user’s privacy-related information, which
may reveal information they do not want anybody to know.
Although the terms and conditions state that we do not link
the data and the user’s identity, this may discourage people
from installing the browser extension.
To motivate users to install our browser extension, we
implemented a campaign in the past, where a user can obtain
a JPY 2,000 Amazon gift card. The campaign was successful
from the standpoint of encouraging users to install the browser
extension; however, over half of the users stopped using the
browser extension within three months, indicating that the
campaign was unable to motivate users to continue using the
software.
Rather than asking people to install and use the browser
extension, we redesigned the browser extension so that people
would be interested in installing and continuing to use it
by using a popular character, called Tachikoma, a popular
character in the Ghost in the Shell universe [9]. By continuing
to activate the browser extension, users can see Tachikoma in
their browser. People who like the story or the character are
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    103
more users should be devised and deployed. Future works
could consider these limitations of the dataset.
6.4 Further Analyses
This paper demonstrated the usefulness of analyzing user-side
data collected through browsers. Further analyses are
encouraged to deepen the understanding of user behaviors,
including the analysis of access records before session
reconstruction as discussed in Section 3.2. In this section,
two more analysis directions are shown below.
We may use data that was unused in this paper
to reconstruct hazardous paths in detail. For example,
transition qualiﬁers, which can be collected through the
chrome.webNavigation API, could be used to deepen the
understanding of user behaviors. The API provides four
transition qualiﬁers: "client_redirect," "server_redirect,"
"forward_back," and "from_address_bar." Their usability is
demonstrated in a case, where a user browses pages in the
following manner. (1) A user visits a search engine result page
(whose transition type is set to "form_submit"). (2) The user
clicks on one of the links on the page. (3) The user pushes the
"back" button on the browser. In this case, the access record
of the access (1) is used as the access record for the access
(3), meaning that its transition type is "start_page" and the
referer does not comply with access (2). In this study, the
access path reconstruction scheme judges that the access (3)
is the path entry point; however, we could trace back further
by considering transition qualiﬁer information.
Moreover, user behaviors can be analysed at a ﬁner
granularity. For example, user behaviors can be analyzed
for each type of detected threats rather than using a
binary label, i.e., malicious or not malicious. Indeed GSB
provides types of detected threats, e.g., "MALWARE" and
"SOCIAL_ENGINEERING"; however, we could not use
these in this paper because our dataset did not have a sufﬁcient
amount of access records for each type of the threats detected
by GSB. As discussed in Section 6.3, our dataset was too
small to analyze accesses based on these types.
Various other analyses can be conducted for different
purposes. These analyses will aid in building efﬁcient
schemes to improve user protection.
7 Related Work
Various studies have been reported in the area of malicious
URL analysis. They take different approaches with different
datasets. This section introduces major such works.
Previous studies have analyzed web page content to identify
malicious sites [10–17]. A JavaScript code analysis at a
bytecode level has been proposed [11] to cope with the
obfuscation. Another study proposed a link structure analysis
technique [12] to detect compromised websites by identifying
structural anomalies. In addition, a cascading style sheets
analysis technique has been proposed [13] to detect pages
leading to malware downloads.
Lexical analysis has also been proposed to extract features
from URL strings and identify malicious sites [18–23].
Among studies that apply lexical analysis, one study [19]
attempts to achieve online learning; thus it does not use
information that requires time to obtain. That study uses
the URL string and host-related information, i.e., host name,
primary domain, TLD, whois information, AS number, and
geographical information, as features.
In addition, several studies have focused on building
and analyzing redirection chains [24–29], which are often
observed when users reach malicious URLs. For example, the
SpiderWeb system [28] analyzes HTTP redirection chains. It
uses ﬁve types of features, i.e., client, referer, landing page,
ﬁnal page, and redirection graph, to distinguish chains that
correspond to malicious activity and those that are legitimate.
WarningBird [29] detects malicious URLs posted on Twitter
by analyzing the correlations of redirection chains, while
Surf [25] identiﬁes redirects to malicious URLs that are
originated from search engine results.
Access paths followed by users who eventually fall
victim to different types of malware download attacks, called
malware download paths, have also been analyzed [30]. In
that study, the authors proposed a download path traceback
technique as well as a technique to determine whether the
path is social engineering or drive-by, using various features,
such as domain ages and the number of hops to exploit pages.
Another study focuses on social engineering URLs [31].
That study uses a random forest algorithm to determine the
occurrence of a social engineering attack from ad-related sites
by learning about such past attacks using features extracted
from the download paths. In addition, research focusing on
identifying malicious exploit kits has also been reported [32].
Other studies have focused on user behavior [33–37]. A
study analyzes trafﬁc on a mobile cellular network to predict
whether a user will visit a malicious URL within a month
based on past browsing activities and a questionnaire [34].
The study also predicts whether a user would access a
malicious URL within a session based on information from
past records in the same session.
Various other studies have been reported in this area,
including domain reputation systems [38–40] and signature
generation techniques
[41, 42]. Contrary to these, we
collected data at the user side, which enabled us to analyze
the user activities in detail by discerning users and browser
tabs. We also proposed a preemptive domain ﬁltering scheme
that identiﬁed hazardous domains that were not included in
blacklists.
8 Conclusion
Our user-side web access record collection approach enabled
us to access to a wide range of data, such as user IDs, browser
104    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
tab IDs, and user navigation information, which facilitated
efﬁcient and detailed analysis of user behavior. We have
reconstructed hazardous paths from the collected data by
continuously tracing previous access records until we identify
entry points of the paths. The hazardous path reconstruction
was efﬁcient because it was able to discern users and
browser tabs. Then, we analyzed the reconstructed hazardous
paths to deepen the understanding of users’ web browsing
activities and revealed several analysis results, including that
bookmarks are the major entry points of hazardous paths. It
indicated that sanitizing bookmark entries will minimize the
risk of accessing malicious URLs. Furthermore, we proposed
a preemptive domain ﬁltering scheme that identiﬁes and
ﬁlters domains that lead to malicious URLs. The effectiveness
of the proposed scheme was demonstrated by revealing
non-blacklisted domains that ultimately led users to malicious
URLs. We hope that our work in this paper will contribute to
the security of the web.
Acknowledgment
This study has been supported by WarpDrive project [2]. We
thank all the colleagues of the project. We would like to extend
our gratitude to our paper shepherd, Amin Kharraz, and the
anonymous reviewers for their feedback and assistance.
References
[1] Google Safe Browsing.
https://safebrowsing.
google.com/. Accessed: June 1, 2020.
[2] WarpDrive.
https://warpdrive-project.jp/.
Accessed: June 1, 2020.
[3] Chrome: developer.
https://developer.chrome.
com/home. Accessed: June 1, 2020.
[4] chrome.webRequest. https://developer.chrome.
com/extensions/webRequest. Accessed: June 1,
2020.
[5] chrome.webNavigation.
https://developer.
chrome.com/extensions/webNavigation.
Accessed: June 1, 2020.
[6] chrome.history. https://developer.chrome.com/
extensions/history. Accessed: June 1, 2020.
[7] Alexa top sites. https://www.alexa.com/topsites.
Accessed: June 1, 2020.
[8] VirusTotal.
https://www.virustotal.com/.
Accessed: June 1, 2020.
[9] Ghost in the Shell.
http://www.production-ig.
com/contents/works_sp/16_/index.html.
Accessed: June 1, 2020.
[10] D. Canali, M. Cova, G. Vigna, and C. Kruegel. Prophiler:
A fast ﬁlter for the large-scale detection of malicious
web pages. In Proceedings of the 20th International
Conference on World Wide Web, 2011.
[11] Y. Fang, C. Huang, L. Liu, and M. Xue. Research on
malicious javascript detection technology based on lstm.
IEEE Access, 6, 2018.
[12] P. Ravi Kumar, P. Herbert Raj, and P. Jelciana. A
framework to detect compromised websites using link
structure anomalies. In Computational Intelligence in
Information Systems, 2019.
[13] B. Chen, and Y. Shi. Malicious hidden redirect attack
In 2018
web page detection based on css features.
IEEE 4th International Conference on Computer and
Communications, 2018.
[14] B. Altay, T. Dokeroglu, and A. Cosar. Context-sensitive
and keyword density-based supervised machine learning
Soft
techniques for malicious webpage detection.
Comput., 23, 2019.
[15] A. Fass, R. P. Krawczyk, M. Backes, and B. Stock.
Jast: Fully syntactic detection of malicious (obfuscated)
javascript. In Detection of Intrusions and Malware, and
Vulnerability Assessment, 2018.
[16] M. Cova, C. Kruegel, and G. Vigna. Detection and
analysis of drive-by-download attacks and malicious
javascript code. In Proceedings of the 19th International
Conference on World Wide Web, 2010.
[17] K. Rieck, T. Krueger, and A. Dewald. Cujo: Efﬁcient
detection and prevention of drive-by-download attacks.
In Proceedings of the 26th Annual Computer Security
Applications Conference, 2010.
[18] M. Darling, G. Heileman, G. Gressel, A. Ashok, and
P. Poornachandran. A lexical approach for classifying
malicious urls. In 2015 International Conference on
High Performance Computing Simulation, 2015.
[19] J. Ma, L. K. Saul, S. Savage, and G. M. Voelker.
Learning to detect malicious urls. ACM Trans. Intell.
Syst. Technol., 2, 2011.
[20] R. Verma, and K. Dyer. On the character of phishing
urls: Accurate and robust statistical learning classiﬁers.
In Proceedings of the 5th ACM Conference on Data and
Application Security and Privacy, 2015.
[21] A. Le, A. Markopoulou, and M. Faloutsos. Phishdef: Url
names say it all. In 2011 Proceedings IEEE INFOCOM,
2011.
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    105
[22] D. Huang, K. Xu, and J. Pei. Malicious url detection
by dynamically mining patterns without pre-deﬁned
elements. World Wide Web, 17, 2014.
[23] G. Tan, P. Zhang, Q. Liu, X. Liu, C. Zhu, and L. Guo.
Malﬁlter: A lightweight real-time malicious url ﬁltering
system in large-scale networks. In 2018 IEEE Intl Conf
on Parallel Distributed Processing with Applications,
Ubiquitous Computing Communications, Big Data
Cloud Computing, Social Computing Networking,
Sustainable Computing Communications, 2018.
[24] Z. Li, S. Alrwais, Y. Xie, F. Yu, and X. Wang. Finding
the linchpins of the dark web: a study on topologically
dedicated hosts on malicious web infrastructures. In
2013 IEEE Symposium on Security and Privacy, 2013.
[25] L. Lu, R. Perdisci, and W. Lee. Surf: Detecting and
measuring search poisoning. In Proceedings of the 18th
ACM Conference on Computer and Communications
Security, 2011.
[26] H. Mekky, R. Torres, Z. Zhang, S. Saha, and A. Nucci.
Detecting malicious http redirections using trees of user
browsing activity. In IEEE Conference on Computer
Communications, 2014.
[27] Z. Li, K. Zhang, Y. Xie, F. Yu, and X. Wang. Knowing
your enemy: Understanding and detecting malicious
In Proceedings of the 2012 ACM
web advertising.
Conference on Computer and Communications Security,
2012.
[28] G. Stringhini, C. Kruegel, and G. Vigna. Shady paths:
Leveraging surﬁng crowds to detect malicious web
In Proceedings of the 2013 ACM SIGSAC
pages.
Conference on Computer & Communications Security,
2013.
[29] S. Lee, and J. Kim. Warningbird: A near real-time
in twitter
detection system for suspicious urls
stream. IEEE Transactions on Dependable and Secure
Computing, 10, 2013.
[30] T. Nelms, R. Perdisci, M. Antonakakis, and M. Ahamad.
Webwitness: Investigating, categorizing, and mitigating
In 24th USENIX Security
malware download paths.
Symposium, 2015.
[31] T. Nelms, R. Perdisci, M. Antonakakis, and M. Ahamad.
Towards measuring and mitigating social engineering
software download attacks. In 25th USENIX Security
Symposium, 2016.
[32] T. Taylor, X. Hu, T. Wang, J. Jang, M. P. Stoecklin,
F. Monrose, and R. Sailer. Detecting malicious exploit
kits using tree-based similarity searches. In Proceedings
of the Sixth ACM Conference on Data and Application
Security and Privacy, 2016.
[33] D. Canali, L. Bilge, and D. Balzarotti.
On the
effectiveness of risk prediction based on users browsing
behavior. In Proceedings of the 9th ACM Symposium on
Information, Computer and Communications Security,
2014.
[34] M. Sharif, J. Urakawa, N. Christin, A. Kubota, and
A. Yamada. Predicting impending exposure to malicious
In Proceedings of the
content from user behavior.
2018 ACM SIGSAC Conference on Computer and
Communications Security, 2018.
[35] F. L. Lévesque, J. M. Fernandez, and A. Somayaji.
Risk prediction of malware victimization based on
user behavior. In 2014 9th International Conference
on Malicious and Unwanted Software: The Americas
(MALWARE), 2014.
[36] M. Ovelgönne, T. Dumitra¸s, B. A. Prakash, V. S.
Subrahmanian, and B. Wang. Understanding the
relationship between human behavior and susceptibility
to cyber attacks: A data-driven approach. ACM Trans.
Intell. Syst. Technol., 8, 2017.
[37] Y. Carlinet, L. Mé, H. Debar, and Y. Gourhant. Analysis
of computer infection risk factors based on customer
In 2008 Second International
network usage.
Conference on Emerging Security Information, Systems
and Technologies, 2008.
[38] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and
N. Feamster. Building a dynamic reputation system for
dns. In Proceedings of the 19th USENIX Conference on
Security, 2010.
[39] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and
D. Dagon. Detecting malware domains at the upper
In Proceedings of the 20th USENIX
dns hierarchy.
Conference on Security, 2011.
[40] M. A. Rajab, L. Ballard, N. Lutz, P. Mavrommatis, and
N. Provos. CAMP: content-agnostic malware protection.
In 20th Annual Network and Distributed System Security
Symposium, 2013.
[41] J. Zhang, C. Seifert, J. W. Stokes, and W. Lee. Arrow:
Generating signatures to detect drive-by downloads. In
Proceedings of the 20th International Conference on
World Wide Web, 2011.
[42] J. Newsome, B. Karp, and D. Song.
Polygraph:
Automatically generating signatures for polymorphic
worms. In Proceedings of the 2005 IEEE Symposium
on Security and Privacy, 2005.
106    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association