security than what is necessary in our context because
they assume that the details of f remain hidden from the
owner of the data. Regardless, their method (and others
requiring interaction [8, 9, 36]) requires much more server-
participant interaction than is practical for a volunteer
distributed computation. Sander, Young, and Yung [31]
develop a non-interactive protocol called Symmetrically-
secure CryptoComputing (SYC), which provides a variant
of secure circuit evaluation, hiding the input x and reveal-
ing only a bound on the depth of the circuit f. Their solu-
tion, however, is limited to log-depth circuits, and is thus
impractical in our context.
Rivest, Adleman, and Dertouzos [29] formally intro-
duced the notion of privacy homomorphism, whose exis-
tence in theory allows computing with encrypted functions.
They conclude that these homomorphisms are inherently
limited in their capabilities since comparisons cannot be
included in the possible set of operations without creating
a vulnerability to ciphertext-only attacks. They also raise
the (still open) question of the existence of highly secure
privacy homomorphisms that use large sets of operations.
Ahituv, Lapid, and Neumann [5] show that if a privacy ho-
momorphism allows the addition operation, then it is inse-
cure under chosen plaintext attacks. Brickell and Yacobi
[12] introduce R-additive privacy homomorphisms, which
are secure under addition, but place constraints on the num-
ber of ciphertexts that can be added.
In general, secure
privacy homomorphisms that preserve more than one oper-
ation are difﬁcult to ﬁnd. An exception is a homomorphism
developed by Ferrer [15] that preserves addition and mul-
tiplication while resisting known plaintext attacks. Though
elegant, these homomorphisms have far too limited opera-
tion sets to be of practical use in volunteer distributed com-
putations.
The problem of multiparty function computation in-
volves players Pi, 1 ≤ i ≤ n, with private inputs xi who
wish to evaluate a function f (x1, . . . , xn) without reveal-
ing any more information about the xi than is implicitly
contained in the output value. Yao [38] introduces this
problem and develops a protocol for the two player case.
Goldreich, Micali, and Wigderson [20] extend this result
to several parties, developing a protocol that leaks no input
information provided a majority of honest players. Both
of these results are based on assumptions of intractability
of certain functions (the cryptographic approach). Results
based on the information-theoretic approach, which does
not assume limits on processor computation power, include
work of Ben-Or, Goldwasser, and Wigderson [10], who
present a protocol that achieves a tight bound on the size of
the group of colluding players that can disrupt the compu-
tation, and Chaum, Cr´epeau, and Damgard [14], who show
that any “reasonable” multiparty protocol can be achieved
if at least 2/3 of the players are honest. Goldreich [19] pro-
vides a survey of results in this area. As with the secure cir-
cuit evaluation work above, these protocols have communi-
cation and computation complexity that precludes their use
in the current context.
8. Conclusions
Via a speciﬁc application, we have introduced a strategy
for enhancing data privacy in some distributed volunteer
computations. The strategy is based on the observation that
the requirements for computing with obscured data can be
much less restrictive in some of these computations than in
traditional execution models because of the ﬁltering nature
of certain volunteer computations. In particular, because
the identiﬁcation of important data, rather than the output
associated with this data, is the goal of these computations,
there can be considerable ﬂexibility in task procedure def-
initions. This ﬂexibility can be leveraged to provide data
privacy by allowing transformations to data and procedures
that retain sufﬁcient information for ﬁltering, while simul-
taneously obscuring data details so that identiﬁcation is dif-
ﬁcult, if not impossible.
We illustrated the potential of this strategy by describ-
ing a scheme for enhancing data privacy in the Smith-
Waterman local sequence comparison algorithm. Our mod-
iﬁcations are a promising ﬁrst step, in that they provide rea-
sonable, though not rigorously provable, data privacy while
preserving sufﬁcient information for distinguishing well-
matching sequences. In addition, by presenting a practi-
cal, important, and non-trivial real-world application that
requires privacy and is efﬁciently parallelizable, we have
begun to populate a potential benchmark suite of applica-
tions for privacy study.
Acknowledgments
We would like to thank biologists Rafael De Sa, Laura
Runyen-Janecky, and Joe Gindhart, all from the University
of Richmond, for their patient and thorough treatment of
our questions. We would also like to thank the anonymous
reviewers and Tadayoshi Kohno for many valuable com-
ments that helped make this a better paper than it otherwise
would have been.
References
[1] M. Abadi and J. Feigenbaum. Secure circuit evaluation: A
protocol based on hiding information from an oracle. Jour-
nal of Cryptology, 2(1):1–12, 1990.
[2] M. Abadi, J. Feigenbaum, and J. Kilian. On hiding infor-
mation from an oracle.
In Proceedings of the 19th ACM
Symposium on the Theory of Computing, pages 195–203,
1987.
[3] M. Abadi, J. Feigenbaum, and J. Kilian. On hiding infor-
mation from an oracle. Journal of Computer and System
Sciences, 39(1):21–50, August 1989.
[4] M. Abdalla, M. Bellare, D. Catalano, E. Kiltz, T. Kohno,
T. Lange, J. Malone-Lee, G. Neven, P. Paillier, and H. Shi.
Searchable encryption revisited: Consistency properties, re-
lation to anonymous ibe, and extensions. Cryptology ePrint
Archive, Report 2005/254, 2005. http://eprint.
iacr.org/.
[5] N. Ahituv, Y. Lapid, and S. Neumann. Processing encrypted
data. Commun. ACM, 30(9):777–780, 1987.
[6] M. Ajtai and C. Dwork. A public-key cryptosystem with
worst-case/average-case equivalence. In Proceedings of the
29th Annual ACM Symposium on Theory of Computing,
pages 284–293, El Paso, Texas, May 1997.
[7] S. Altschul and W. Gish. Local alignment statistics. Meth-
ods Enzymol, 266:460–480, 1996.
[8] J. Bar-Ilan and D. Beaver. Non-cryptographic fault-tolerant
computing in a constant number of rounds of interaction. In
Proceedings of 8th ACM SIGACT-SIGOPS Symposium on
Principles of Distributed Computing, pages 201–209, 1989.
[9] D. Beaver, S. Micali, and P. Rogaway. The round com-
plexity of secure protocols. In Proceedings of the Twenty-
second Annual ACM Symposium on Theory of Computing,
pages 503–513. ACM Press, 1990.
[10] M. Ben-Or and A. Wigderson. Completeness theorems
for non-cryptographic fault-tolerant distributed computa-
tion.
In Proceedings of the Twentieth Annual ACM Sym-
posium on Theory of Computing, pages 1–10, 1988.
[11] M. Bishop. Computer Security: Art and Science. Addison-
Wesley, 2003.
[12] E. Brickell and Y. Yacobi. On privacy homomorphisms (ex-
tended abstract). In D. Chaum and W. Price, editors, Ad-
vances in Cryptology—EUROCRYPT ‘87, volume 304 of
Lecture Notes in Computer Science, pages 117–126, Berlin,
1987. Springer-Verlag.
[13] E. Chargaff. Structure and function of nucleic acids as cell
constituents. Fed. Proc, 10:654–659, 1951.
11
[14] D. Chaum, C. Cr´epeau, and I. Damgard. Multiparty uncon-
ditionally secure protocols. In Proceedings of the Twentieth
Annual ACM Symposium on Theory of Computing, pages
11–19, 1988.
[15] J. Domingo-Ferrer. A new privacy homomorphism and ap-
plications. Information Processing Letters, 60(5):277–282,
December 1996.
[16] C. Dwork, M. Naor, and O. Reingold.
Immunizing en-
cryption schemes from decryption errors.
In C. Cachin
and J. Camenisch, editors, Advances in Cryptology – EU-
ROCRYPT 2004, volume 3027 of Lecture Notes in Com-
puter Science, pages 342–360, Interlaken, Switzerland,
May 2004. Springer-Verlag.
[17] J. Feigenbaum. Encrypted problem instances, or... Can you
take advantage of someone without having to trust him?
In Proceedings of Crypto’ 85, pages 477–488. Springer-
Verlag, 1986.
[18] Genbank.
http://www.ncbi.nlm.nih.gov/
GenBank/GenBankOverview.html.
[19] O. Goldreich. Secure multi-party computation. Working
Draft, 2000.
[20] O. Goldreich, S. Micali, and A. Wigderson. How to play
any mental game. In Proceedings of the Nineteenth Annual
ACM Conference on Theory of Computing, pages 218–229,
1987.
[21] P. Golle and I. Mironov. Uncheatable distributed com-
putations.
In Proceedings of the RSA Conference 2001,
Cryptographers’ Track, pages 425–441, San Francisco, CA,
2001. Springer.
[22] P. Golle and S. Stubblebine. Secure distributed computing
in a commercial environment. In P. Syverson, editor, Proc.
of Financial Crypto 2001, volume 2339 of Lecture Notes in
Computer Science, pages 289–304. Springer-Verlag, 2001.
[23] S. Karlin and S. Altschul. Methods for assessing the sta-
tistical signiﬁcance of molecular sequence features by us-
ing general scoring schemes. Proceedings of the National
Academy of Sciences (USA), 87:2264–2268, March 1990.
[24] S. Karlin and S. Altschul. Applications and statistics for
multiple high-scoring segments in molecular sequences.
Proceedings of the National Academy of Sciences (USA),
90:5873–5877, June 1993.
[25] F. Monrose, P. Wyckoff, and A. Rubin. Distributed ex-
ecution with remote audit.
In Proceedings of the 1999
ISOC Network and Distributed System Security Symposium,
pages 103–113, 1999.
[26] S. Needleman and C. Wunsch. A general method applicable
to the search for similarities in the amino acid sequence of
two proteins. Journal of Molecular Biology, 48:443–453,
1970.
[27] W. Pearson. Empirical statistical estimates for sequence
similariy searches. Journal of Molecular Biology, 276:71–
84, 1998.
[28] T. Phan, L. Huang, and C. Dulan. Challenge: Integrating
mobile wireless devices into the computational grid. In Pro-
ceedings of the Eight International Conference on Mobile
Computing and Networking (MobiCom 2002), pages 271–
278, Atlanta, GA, September 2002.
[29] R. Rivest, L. Adleman, and M. Dertouzos. On data banks
and privacy homomorphisms. In R. D. Millo, D. Dobkin,
A. Jones, and R. Lipton, editors, Foundations of Secure
Computation, pages 169–179. Academic Press, New York,
1978.
[30] R. D. Sa, L. Runyen-Janecky, and J. Gindhart, July 2005.
Personal conversations.
[31] T. Sander, A. Young, and M. Yung. Non-interactive crypto-
computing for N C 1. In IEEE Symposium on Foundations
of Computer Science, pages 554–567, 1999.
[32] L. Sarmenta. Sabotage-tolerance mechanisms for volunteer
computing systems. Future Generation Computer Systems,
18(4):561–572, March 2002.
[33] T. Smith and M. Waterman.
Identiﬁcation of common
Journal of Molecular Biology,
molecular subsequences.
147:195–197, 1981.
[34] D. Szajda, B. Lawson, and J. Owen. Hardening functions
for large-scale distributed computations. In Proceedings of
the 2003 IEEE Symposium on Security and Privacy, pages
216–224, Berkeley, CA, May 2003.
[35] D. Szajda, B. Lawson, and J. Owen. Toward an optimal
redundancy strategy for distributed computations. In Pro-
ceedings of the 2005 IEEE International Conference on
Cluster Computing (Cluster 2005), Boston, MA, Septem-
ber 2005.
[36] S. Tate and K. Xu. On garbled circuits and constant round
secure function evaluation. Technical Report TR 2003-02,
University of North Texas, Computer Privacy and Security
(CoPS) Lab, 2003.
[37] M. Waterman.
Introduction to Computational Biology:
Interdisciplinary Statis-
Maps, Sequences, and Genomes.
tics. Chapman & Hall, 1995.
[38] A. Yao. How to generate and exchange secrets.
In Pro-
ceedings of the 27th Annual Symposium on Foundations of
Computer Science, pages 162–167, Toronto, Canada, Octo-
ber 1986.
A. Sequence Comparison Algorithm Details
The details of the Smith-Waterman global sequence
alignment algorithm follow. We assume here, for simplic-
ity of notation, that length n sequences begin at index 1
and end at index n. Recall that S denotes the similarity
score of a sequence pair, s denotes the similarity function
for symbols, and g denotes the gap penalty.
Theorem. [37]. If U = u1u2 . . . un and V = v1v2 . . . vm,
deﬁne
Si,j = S(u1u2 . . . ui, v1v2 . . . vj).
Also, set
S0,0 = 0, S0,j =
j
Xk=1
g(vk), and Si,0 =
i
Xk=1
g(uk).
Then
Si,j = max{Si−1,j + g(ui), Si−1,j−1 + s(ui, vj),
Si,j−1 + g(vj)}.
12
set of integers between 1 and 4N inclusive.) The entropy
[11], H(X), of X is easily shown to be 2N, which is to be
expected, since in effect each nucleotide contains two bits
of uncertainty. Now let us consider the conditional entropy
H(X|Y ) of X given that the adversary has received off-
set sequence Y = F (U, δ). Let Cδ denote the number of
occurrences of literal δ in U. Then
H(X|Y ) =
Xi=1
−
4
N
P (X = Si|Y = F (U, δ))
×
log(P (X = Si|Y = F (U, δ))).
Since, however, the positions of literal δ are revealed by
F (U, δ), and δ is known to the adversary, thus there are
3N −Cδ sequences in S that could be the preimage of U.
Let k1, k2, . . . , k3N−Cδ be the indices (over the set S of
these possible preimages). Thus,
N−CA
3
1
−
H(X|Y ) =
Xi=1
P (X = Ski|Y = F (U, δ))
log(P (X = Ski|Y = F (U, δ)))
3N −CA(cid:19)
= −3N −CA
= (N − CA) log 3.
log(cid:18) 1
3N −CA
×
Proving the validity of the dynamic programming ap-
proach in this context is straightforward. One need only
observe that an alignment ending with indices i and j must
end with one of the choices below.
··· ui
···−
··· ui
··· vj
···−
··· vj
Thus the best alignment ending with indices i and j must
be the best alignment ending with indices i and j − 1 plus
the gap penalty, or the best alignment ending with indices
i − 1 and j − 1 plus s(ui, vj), or the best alignment ending
with indices i − 1 and j plus the gap penalty.
For local sequence comparison, deﬁne for (i, j) pair the
function H by
Hi,j = max{0;
S(uxux+1 . . . ui−1ui, vyvy+1 . . . vj−1vj) :
1 ≤ x ≤ i, 1 ≤ y ≤ j}.
Then H can be computed using the following two re-
sults from [37].
Theorem. Assume that the gap function g is a function of
gap length. Set H0,0 = 0, and set Hi,0 = H0,j = 0 for
1 ≤ i ≤ n and 1 ≤ j ≤ m. Then
Hi,j = max(cid:20)0, max
1≤k≤i{Hi−k,j − g(k)},
Hi−1,j−1 + s(ui, vj), max
1≤l≤j{Hi,j−l − g(l)}(cid:21) .
The proof is similar to that of the global alignment algo-
rithm.
Finally, we have the following
Corollary.
H(U, V ) = max{Hk,l : 1 ≤ k ≤ n, 1 ≤ l ≤ m}.
B. Entropy Calculation
Given that the adversary has determined the location of
all instances of a single nucleotide, we can measure con-
ditional entropy. Assume that our original sequence U has
length N, and that the adversary has been provided with
F (U, δ) for some ﬁxed literal δ ∈ Σ. There are 4N possi-
ble length N sequences over Σ, and we may assume that
these are enumerated such that each has a unique integer
index in the range 1 to 4N inclusive. That is, all possible
length N sequences over Σ occur exactly once among the
set S = {S1, S2, . . . , S4N}. Let X be the random variable
that has a uniform distribution over S. (Technically, X is
the random variable that has a uniform distribution over the
13