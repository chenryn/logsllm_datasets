inputLength+=splits[i].getInputDataLength（）；
maps[i]=new TaskInProgress（jobId, jobFile, splits[i]，jobtracker, conf，
this, i，numSlotsPerMap）；}
if（numMapTasks＞0）{
//map task放入nonRunningMapCache，其将在JobTracker向
//TaskTracker分配Map Task的时候使用
nonRunningMapCache=createCache（splits, maxLevel）；
}
//创建Reduce Task
this.reduces=new TaskInProgress[numReduceTasks]；
for（int i=0；i＜numReduceTasks；i++）{
reduces[i]=new TaskInProgress（jobId, jobFile, numMapTasks, i，jobtracker，
conf, this, numSlotsPerReduce）；
//Reduce Task放入nonRunningReduces，其将在JobTracker向
//TaskTracker分配Reduce Task的时候使用
nonRunningReduces.add（reduces[i]）；
}
//清理Map和Reduce
cleanup=new TaskInProgress[2]；
TaskSplitMetaInfo emptySplit=JobSplit.EMPTY_TASK_SPLIT；
cleanup[0]=new TaskInProgress（jobId, jobFile, emptySplit, jobtracker, conf，
this, numMapTasks）；
cleanup[0].setJobCleanupTask（）；
cleanup[1]=new TaskInProgress（jobId, jobFile, numMapTasks, numReduceTasks，
jobtracker, conf, this，1）；
cleanup[1].setJobCleanupTask（）；
//创建两个初始化Task，一个初始化Map，一个初始化Reduce
setup=new TaskInProgress[2]；
setup[0]=new TaskInProgress（jobId, jobFile, emptySplit, jobtracker, conf，
this, numMapTasks+1，1）；
setup[0].setJobSetupTask（）；
setup[1]=new TaskInProgress（jobId, jobFile, numMapTasks, numReduceTasks+1，
jobtracker, conf, this，1）；
setup[1].setJobSetupTask（）；
tasksInited=true；//初始化完毕
……
}
从上面的代码可以看出初始化过程主要有以下步骤：
1）从HDFS中读取作业对应的job.split（见图6-1的步骤⑥）。JobTracker从HDFS中作业对应的路径获取JobClient在步骤③中写入的job.split文件，得到输入数据的划分信息，为后面初始化过程中Map任务的分配做好准备。
2）创建并初始化Map任务和Reduce任务。initTasks先根据输入数据划分信息中的个数设定Map Task的个数，然后为每个Map Task生成一个TaskInProgress来处理input split，并将Map Task放入nonRunningMapCache，以便在JobTracker向TaskTracker分配Map Task的时候使用。接下来根据JobConf中的mapred.reduce.tasks属性利用setNumReduceTasks（）方法来设置reduce task的个数，然后采用类似Map Task的方式将Reduce Task放入nonRunningReduces中，以便向TaskTracker分配Reduce Task时使用。
3）最后就是创建两个初始化Task，根据个数和输入划分已经配置的信息，并分别初始化Map和Reduce。
6.1.4 分配任务
在前面的介绍中我们已经知道，TaskTracker和JobTracker之间的通信和任务的分配是通过心跳机制完成的。TaskTracker作为一个单独的JVM执行一个简单的循环，主要实现每隔一段时间向JobTracker发送心跳（Heartbeat）：告诉JobTracker此TaskTracker是否存活，是否准备执行新的任务。JobTracker接收到心跳信息，如果有待分配任务，它就会为TaskTracker分配一个任务，并将分配信息封装在心跳通信的返回值中返回给TaskTracker。TaskTracker从心跳方法的Response中得知此TaskTracker需要做的事情，如果是一个新的Task则将它加入本机的任务队列中（见图6-1的步骤⑦）。
下面从TaskTracker中的transmitHeartBeat（）方法和JobTracker中的heartbeat（）方法的主要代码出发，介绍任务分配的详细过程，以及在此过程中TaskTracker和JobTracker的通信。
TaskTracker中transmitHeartBeat（）方法的主要代码：
//向JobTracker报告TaskTracker的当前状态
if（status==null）{
synchronized（this）{
status=new TaskTrackerStatus（taskTrackerName, localHostname, httpPort, cloneAndRe
setRunningTaskStatuses（sendCounters），failures, maxMapSlots, maxReduceSlots）；
}
}
……
//根据条件是否满足来确定此TaskTracker是否请求JobTracker
//为其分配新的Task
boolean askForNewTask；
long localMinSpaceStart；
synchronized（this）{
askForNewTask=（status.countMapTasks（）＜maxCurrentMapTasks||
status.countReduceTasks（）＜maxCurrentReduceTasks）＆＆acceptNewTasks；
localMinSpaceStart=minSpaceStart；
}
……
//向JobTracker发送heartbeat
HeartbeatResponse heartbeatResponse=jobClient.heartbeat（status, justStarted，
justInited, askForNewTask, heartbeatResponseId）；
……
JobTracker中heartbeat（）方法的主要代码：
……
String trackerName=status.getTrackerName（）；
……
//如果TaskTracker向JobTracker请求一个Task运行
if（recoveryManager.shouldSchedule（）＆＆acceptNewTasks＆＆！isBlacklisted）{
TaskTrackerStatus taskTrackerStatus=getTaskTracker（trackerName）；
if（taskTrackerStatus==null）{
LOG.warn（"Unknown task tracker polling；ignoring："+trackerName）；
}else{
List＜Task＞tasks=getSetupAndCleanupTasks（taskTrackerStatus）；
if（tasks==null）{
//任务调度器分配任务
tasks=taskScheduler.assignTasks（taskTrackers.get（trackerName））；
}
if（tasks！=null）{
for（Task task：tasks）{
//将任务返回给TaskTracker
expireLaunchingTasks.addNewTask（task.getTaskID（））；
actions.add（new LaunchTaskAction（task））；
}}}}……
上面两段代码展示了TaskTracker和JobTracker之间通过心跳通信汇报状态与分配任务的详细过程。TaskTracker首先发送自己的状态（主要是Map任务和Reduce任务的个数是否小于上限），并根据自身条件选择是否向JobTracker请求新的Task，最后发送心跳。JobTracker接收到TaskTracker的心跳后首先分析心跳信息，如果发现TaskTracker在请求一个Task，那么任务调度器就会将任务和任务信息封装起来返回给TaskTracker。
针对Map任务和Reduce任务，TaskTracker有固定数量的任务槽（Map任务和Reduce任务的个数都有上限）。当TaskTracker从JobTracker返回的心跳信息中获取新的任务信息时，它会将Map任务或者Reduce任务加入对应的任务槽中。需要注意的是，在JobTracker为TaskTracker分配Map任务时，为了减小网络带宽，会考虑将map任务数据本地化。它会根据TaskTracker的网络位置，选取一个距离此TaskTracker map任务最近的输入划分文件分配给此TaskTracker。最好的情况是，划分文件就在TaskTracker本地（TaskTracker往往是运行在HDFS的DataNode中，所以这种情况是存在的）。
6.1.5 执行任务
TaskTracker申请到新的任务之后，就要在本地运行任务了。运行任务的第一步是将任务本地化（将任务运行所必需的数据、配置信息、程序代码从HDFS复制到TaskTracker本地，见图6-1的步骤⑧）。这主要是通过调用localizeJob（）方法来完成的（此方法的具体代码并不复杂，不再列出）。这个方法主要通过下面几个步骤来完成任务的本地化：
1）将job.split复制到本地；
2）将job.jar复制到本地；
3）将job的配置信息写入job.xml；
4）创建本地任务目录，解压job.jar；
5）调用launchTaskForJob（）方法发布任务（见图6-1的步骤⑨）。
任务本地化之后，就可以通过调用launchTaskForJob（）真正启动起来。接下来launchTaskForJob（）又会调用launchTask（）方法启动任务。launchTask（）方法的主要代码如下：
……
//创建Task本地运行目录
localizeTask（task）；
if（this.taskStatus.getRunState（）==TaskStatus.State.UNASSIGNED）{
this.taskStatus.setRunState（TaskStatus.State.RUNNING）；
}
//创建并启动TaskRunner
this.runner=task.createRunner（TaskTracker.this, this）；
this.runner.start（）；
this.taskStatus.setStartTime（System.currentTimeMillis（））；
……
从代码中可以看出launchTask（）方法会先为任务创建本地目录，然后启动TaskRunner。在启动TaskRunner后，对于Map任务，会启动MapTaskRunner；对于Reduce任务则启动ReduceTaskRunner。
之后，TaskRunner又会启动新的Java虚拟机来运行每个任务（见图6-1的步骤⑩）。以Map任务为例，任务执行的简单流程是：
1）配置任务执行参数（获取Java程序的执行环境和配置参数等）；
2）在Child临时文件表中添加Map任务信息（运行Map和Reduce任务的主进程是Child类）；
3）配置log文件夹，然后配置Map任务的通信和输出参数；
4）读取input split，生成RecordReader读取数据；
5）为Map任务生成MapRunnable，依次从RecordReader中接收数据，并调用Mapper的Map函数进行处理；
6）最后将Map函数的输出调用collect收集到MapOutputBuffer中（见图6-1的步骤11）。
6.1.6 更新任务执行进度和状态
在本章的作业提交过程中我们曾介绍：一个MapReduce作业在提交到Hadoop上之后，会进入完全地自动化执行过程，用户只能监控程序的执行状态和强制中止作业。但是MapReduce作业是一个长时间运行的批量作业，有时候可能需要运行数小时。所以对于用户而言，能够得知作业的运行状态是非常重要的。在Linux终端运行MapReduce作业时，可以看到在作业执行过程中有一些简单的作业执行状态报告，这能让用户大致了解作业的运行情况，并通过与预期运行情况的对比来确定作业是否按照预定方式运行。
在MapReduce作业中，作业的进度主要由一些可衡量可计数的小操作组成。比如在Map任务中，其任务进度就是已处理输入的百分比，如果完成100条记录中的50条，那么Map任务的进度就是50%（这里只是针对一个Map任务举例，并不是在Linux终端中执行MapReduce任务时出现的Map 50%，在终端中出现的50%是总体Map任务的进度，这是将所有Map任务的进度组合起来的结果）。总体来讲，MapReduce作业的进度由下面几项组成：Mapper（或Reducer）读入或写出一条记录，在报告中设置状态描述，增加计数器，调用Reporter对象的progess（）方法。
由MapReduce作业分割成的每个任务中都有一组计数器，它们对任务执行过程中的进度组成事件进行计数。如果任务要报告进度，它便会设置一个标志以表明状态变化将会发送到TaskTracker上。另一个监听线程检查到这标志后，会告知TaskTracker当前的任务状态。具体代码如下（这是Map Task中run函数的部分代码）：
//同TaskTracker通信，汇报任务执行进度
TaskReporter reporter=new TaskReporter（getProgress（），umbilical, jvmContext）；
startCommunicationThread（umbilical）；
initialize（job, getJobID（），reporter, useNewApi）；
同时，TaskTracker在每隔5秒发送给JobTracker的心跳中封装任务状态，报告自己的任务执行状态。具体代码如下（这是TaskTracker中transmitHeartBeat（）方法的部分代码）：
//每隔一段时间，向JobTracker返回一些统计信息
boolean sendCounters；
if（now＞（previousUpdate+COUNTER_UPDATE_INTERVAL））{
sendCounters=true；previousUpdate=now；
}
else{
sendCounters=false；
}
通过心跳通信机制，所有TaskTracker的统计信息都会汇总到JobTracker处。JobTracker将这些统计信息合并起来，产生一个全局作业进度统计信息，用来表明正在运行的所有作业，以及其中所含任务的状态。最后，JobClient通过每秒查看JobTracker来接收作业进度的最新状态。具体代码如下（这是JobClient中用来提交作业的runJob（）方法的部分代码）：
//首先生成一个JobClient对象
JobClient jc=new JobClient（job）；
//调用submitJob来提交一个任务
running=jc.submitJob（job）；
……
//使用monitorAndPrintJob方法不断监控作业进度
if（！jc.monitorAndPrintJob（job, rj））{
LOG.info（"Job Failed："+rj.getFailureInfo（））；
throw new IOException（"Job failed！"）；