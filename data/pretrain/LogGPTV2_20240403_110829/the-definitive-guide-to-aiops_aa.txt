The Definitive Guide to AIOps
Copyright © 2018-2019 
All rights reserved. 
Second revision, May 2019 
 The Definitive Guide to AIOps 1 
Introduction: 
The Definitive Guide to AIOps 
A bare-metal software environments, virtualization created a new 	sophisticated and useful, they also tend to grow more 	complex. For example, when virtual machines replaced 	s hardware and software systems become more efficient,layer of complexity that IT teams had to plan for and manage. 
The shift in recent years toward microservices and containers similarly increased the number of components that go into a single application, as well as the challenge of orchestrating all of them. 
Traditionally, the ability of IT Ops teams to handle ever-
increasing complexity has been limited. Hiring more staff is the most obvious response, but that is not a cost-effective solution, or one that can scale well.Automation tools can also help handle added complexity. However, because traditional automation tools require humans to configure, deploy and manage them, the ability to simplify increasingly complex IT environments is also limited. 
 The Definitive Guide to AIOps 2 
AIOps as the Answer to Complexity 
In recent years, Artificial Intelligence for IT Operations (AIOps) has emerged as a better solution to the challenge of ever-increasing complexity in IT. AIOps leverages Big Data, data analytics and machine learning to provide insight and enable a higher level of automation (one that does not depend 
extensively on human operators) for the management tasks that modern infrastructure and software require.For this reason, AIOps holds tremendous value. Going forward, AIOps will play a key role in enabling new efficiencies for IT teams. It will also make practical the adoption of complex next-generation technologies that cannot be managed successfully using traditional solutions. 
In short, businesses of the future won’t survive without the assistance of AIOps. If your business has not yet begun adopting AIOps-powered solutions, now is the time for assessing,planning and implementing AIOps tools that can drive business value. 
This guide is designed to help you in making the migration toward AIOps. It defines AIOps and assesses the current state of AIOps within the IT industry. It also identifies and explains the core components that drive AIOps, as well as the main use cases for AIOps-powered tools. 
 The Definitive Guide to AIOps 3 
Chapter 1:Chapter 1: 
What Is AIOps? 
Defining AIOps 
AIOps is the use of machine learning, Big Data and automated decision-making to complete IT tasks. AIOps makes it possible to automate processes that would traditionally require 
significant manual intervention by humans. 
AIOps, which is short for “algorithmic IT operations” or “artificial intelligence for IT operations,” entered the IT lexicon in 2016, when Gartner coined the term as part of an effort to understand how data analytics was enabling new efficiencies for IT Ops teams.Why is AIOps Innovative? 
The use of data analytics and machine learning by businesses has been widespread for years—It did not arise alongside AIOps. IT operations, or IT Ops, also existed as a distinct discipline long before the concept of AIOps appeared. 
However, what makes AIOps innovative is that it brings data-driven insights and IT Ops together. Previously, data analytics was used primarily to drive business insights, not to help ITThe Definitive Guide to AIOps 4 
teams do their jobs. To the extent that data and machine learning played a role in IT Ops, they were limited mostly to basic security and infrastructure monitoring tools. IT Ops teams made use of automated tools to help make their work more efficient, but those tools were not typically capable of making complex automated decisions based on data, and they required significant manual effort to use.AIOps changes this by providing IT Ops teams with access to tools that can make advanced decisions and perform automated actions by collecting and analyzing data. It represents a much more refined, sophisticated way of integrating data analytics into IT Ops. In addition, it helps traditional IT Ops admins transition into Site Reliability Engineer (SRE) roles and support morescalable workflows that align with business needs. 
The State of AIOps 
While precise data about current AIOps adoption rates is not available, Gartner  in 2017 that “25% of global 
enterprises will have strategically implemented an AIOps 
platform supporting two or more major IT operations functions” by 2019. In addition, recent research by TechValidate found that 97% of surveyed IT organizations agreed that AIOps-enabled solutions that deliver actionable insights will help automate and enhance overall IT Operations functions.AIOps is already seeing early adoption by enterprises, although it will likely take some time before a majority of businesses have deployed AIOps platforms. 
The major hurdles currently standing in the way of greater AIOps adoption include a lack of certainty among businesses over whether AIOps reflects true innovation or mere hype. That doubt will likely disappear as more enterprises adopt AIOps and theThe Definitive Guide to AIOps 5 
value of AIOps becomes clearer. In a 2018  NewVantage Partners  97.2% of executives are investing in building or 
launching Big Data and AI initiatives. 
Low confidence among businesses in their ability to collect high-quality data (combined with uncertainty over how best toimplement AIOps-enabled solutions that will deliver broad, long-term value) are also holding back AIOps adoption in some organizations. These challenges, however, can be overcome with sufficient research and planning. 
AIOps Components 
Such planning begins by identifying the core components that make AIOps possible and assessing your business’s ability to implement them effectively.The chief components of AIOps include: 
● Data collection. Collecting data is the first step in enabling AIOps. Successful AIOps and Big Data technologies are used to collect data from disparate sources, to transform and aggregate the data as needed, and backup and retain data effectively and maintain data quality sufficient for powering data analytics and machine learning.● Data analytics. Once data has been appropriately collected and transformed, statistical  analytics are performed to draw out insights from the data. 
● Machine learning. Machine learning is the process of using the insights gleaned from data analytics to make automated decisions. Machine learning is implemented through 
algorithms that allow software to react automatically to information revealed by data.The Definitive Guide to AIOps 6 
● Artificial intelligence (AI). AI refers to the broader category of automated decision-making, of which machine learning is one component.
We will explore each of these components below within the context of discussing AIOps use cases and practices. 
AIOps Use Cases 
By combining data collection, data analytics and machine learning to form a complete AIOps solution, IT Ops teams can support several key use cases:● Anomaly detection. Perhaps the most basic use case for AIOps is detecting anomalies within data, then reacting to them as needed. 
● Causal analysis. AIOps also helps IT Ops teams automate root 	cause analysis so that issues can be resolved quickly. 
● Prediction. AIOps allows tools to make automated predictions about the future, such as how user traffic is likely to change at a given point in time, then react accordingly.● Alarm  management. AIOps plays an increasingly important role in helping IT Ops teams to contend with the deluge of alerts that they must handle in order to support operations. 
● Intelligent remediation. AIOps drives closed loop remediation through automation tools without relying on human 
operators. 
The following chapters dive deeper into each of these cases by explaining in detail what they involve and how to support them successfully.The Definitive Guide to AIOps 7 
Chapter 2: 
Data Collection and Normalization 
D AIOps-enabled solution. 	implementing effective processes for collecting and 	normalizing data is an essential first step in creating an 	ata forms the foundation for AIOps. For this reason, 
Data collection refers to the task of moving data from the sources where data originates, which are usually of a diverse nature, to a location where it can be processed and analyzed.Data normalization is the process of preparing data for analysis. 
Normalization involves converting data from one format to another so that it is compatible with data analytics tools. It also often entails integrating diverse datasets so that they can be analyzed efficiently from a single location. 
To perform data collection and normalization effectively, organizations should keep the following challenges and best practices in mind.The Definitive Guide to AIOps 8 
Disparate and Diverse Data Sources 
In most cases, the data that powers AIOps platforms is not “born” in a single location or a single format. It instead originates in many different formats and is spread across multiple locations.For example, some of the data that your business collects for AIOps might originate from web server logs that are available in plain text. At the same time, you might collect other data from operating system logs that are stored as compressed files and need to be unpacked before they can be analyzed. Similarchallenges arise when collecting data from different types of databases. For instance, data inside MySQL databases is typically formatted differently from data within so-called NoSQL 
databases. Time-series datasets also pose data collection 
challenges because they require data that was collected at different times to be normalized before it can be analyzed.The diverse nature of data sources and formats creates two distinct challenges: 
● Organizations must be able to collect and aggregate data from multiple locations. The amount of effort and 
complexity required to perform this task will vary depending on how many data sources you have and how widely 
distributed they are. In most cases, data collection willrequire running agents on your various systems that can collect the data they generate and send it to a central location for storage and processing. 
● Normalizing data by translating it into formats that are compatible with analytics tools. Normalization doesn’t necessarily require transforming all of your data into a single 
 The Definitive Guide to AIOps 9The Definitive Guide to AIOps 9 
format. It does, however, typically involve performing at least some dataset transformations, as well as taking advantage of Big Data tools like Apache Hive, HBase and Elasticsearch, which provide an interface for integrating data inside 
conventional databases with Big Data analytics tools such as Hadoop. 
Real-Time Data OperationsReal-Time Data Operations 
When planning and implementing an AIOps solution, it is important to strive for real-time data collection and 
normalization. Real-time data operations mean that you can collect and analyze data as quickly as it is generated and gain instant or near-instant insights as a result. 
Real-time data processing is essential for most AIOps use cases.If your goal is to use AIOps to detect anomalies that could indicate a security breach, for example, being able to gain that insight as soon as the breach occurs will drive a much greater deal of business value than discovering the problem after attackers are already exploiting your data and infrastructure. 
Similarly, when you use AIOps for root-cause analysis of asoftware or infrastructure problem, you want to be able to get to the root of the issue as quickly as possible so that you can 
resolve it before it impacts end users. In both of these examples, delays of even just a few minutes in collecting and normalizing the data that you depend on for your AIOps processes could undercut your ability to achieve your business goals.Achieving data collection and normalization in real time requires full automation of these processes. The agents that help you collect data, and the tools that help you transform or access it for analytics purposes, must be able to operate without the assistance of humans. Otherwise, if you rely on admins to help 
 The Definitive Guide to AIOps 10The Definitive Guide to AIOps 10 
collect data or perform data transformations manually, you won’t be able to achieve real-time insights. 
Data Retention and Backup 
Although real-time data processing is an important part of AIOps, keeping data available after AIOps processes are complete is also valuable. You may be required to retain data for a certain period for compliance reasons, and even if you are not, being able to perform retrospective analysis of data can be useful.This is why your AIOps planning should include assessment of how long your business will retain data after it has been 
collected and normalized, as well as how data will be backed up in order to protect it against unexpected disruptions. While data retention and backup policies vary widely depending on business needs, a common means of deciding which policies are the best fit for your organization involves analyzing two factors:● Recovery Point Objective, or RPO. RPO is the amount of data that your business can afford to lose permanently without serious consequences. If you have high RPO needs, it is essential to back up data on a constant, routine basis. 
● Recovery Time Objective, or RTO. RTO refers to the amount of time that your business can wait for data to be madeavailable again following a disruption. High RTO requirements necessitate backup processes that allow you to restore data very quickly, as well as period tests of recovery time to ensure that you are able to meet recovery goals. 
In order to reduce data storage and backup costs, businesses can take advantage of discounted data storage services available from public cloud providers. These services, which are typically referred to as “cold storage,” provide low-cost data storage, withThe Definitive Guide to AIOps 11 
the caveat that accessing the data often entails a delay. For data that is no longer in active use for AIOps, that delay is typically acceptable. 
Openness 
A final key factor to consider when preparing data collection and normalization solutions for AIOps is the issue of closed versus open source-based solutions.In general, choosing open solutions is better than adopting proprietary, closed-source tools. The latter can lead to lock-in and restrict your business’s ability to modify its AIOps toolset and processes in the future. 
For this reason, it is a best practice to adopt open source data collection and normalization tools. Examples include: 
● Apache Kafka 
● Apache Hive 
● Apache HBase 
● CloverETL● Apache HBase 
● CloverETL 
● KETL 
● Rsyslog 
● Logstash 
● Elasticsearch 
Keep in mind that many proprietary data collection and 
normalization tools are built on top of these open source 
solutions. Some such platforms are more “open” and compatible with third-party tools than others. If you consider commercial tools for data collection and normalization, assess how suitable they are for integration with third-party options in order to avoid lock-in regrets. Similarly, when considering an open sourceThe Definitive Guide to AIOps 12 
solution, be sure to assess whether the effort required to set up 
and maintain the tool offsets the cost savings of using open 
source.
 The Definitive Guide to AIOps 13 
Chapter 3: 
Detection 
D both recognize behavior that is out of the ordinary (such as a 	understand trends within infrastructure and applications 	is a key use case for AIOps. Detection allows tools to 	etecting anomalies in order to locate problems andserver that is responding more slowly than usual, or uncommon network activity generated by a breach) and react accordingly. 
What is an Anomaly? 
An anomaly is a data point or event that is consistent with normal operating conditions. In other words, it is an outlier. 
Dynamic BaseliningWhile understanding the concept of an anomaly is easy enough, what makes anomaly detection particularly challenging for AIOps in modern software environments is that, in many cases, there is no consistent means of defining “normal” operating conditions. The amount of network traffic, memory and storage space that a given environment consumes might fluctuate widely throughout the day, for example. So could the number of active users or application instances.Effective detection under these circumstances requires AIOps tools that are intelligent enough to set dynamic baselines. 
 The Definitive Guide to AIOps 14 