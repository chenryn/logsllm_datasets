title:MUTE: bringing IoT to noise cancellation
author:Sheng Shen and
Nirupam Roy and
Junfeng Guan and
Haitham Hassanieh and
Romit Roy Choudhury
MUTE: Bringing IoT to Noise Cancellation
Sheng Shen, Nirupam Roy, Junfeng Guan, Haitham Hassanieh, Romit Roy Choudhury
University of Illinois at Urbana-Champaign
{sshen19, nroy8, jguan8, haitham, croy}@illinois.edu
ABSTRACT
Active Noise Cancellation (ANC) is a classical area where
noise in the environment is canceled by producing anti-noise
signals near the human ears (e.g., in Bose’s noise cancellation
headphones). This paper brings IoT to active noise cancella-
tion by combining wireless communication with acoustics.
The core idea is to place an IoT device in the environment
that listens to ambient sounds and forwards the sound over
its wireless radio. Since wireless signals travel much faster
than sound, our ear-device receives the sound in advance
of its actual arrival. This serves as a glimpse into the future,
that we call lookahead, and proves crucial for real-time noise
cancellation, especially for unpredictable, wide-band sounds
like music and speech. Using custom IoT hardware, as well as
lookahead-aware cancellation algorithms, we demonstrate
MUTE, a fully functional noise cancellation prototype that
outperforms Bose’s latest ANC headphone. Importantly, our
design does not need to block the ear – the ear canal remains
open, making it comfortable (and healthier) for continuous
use.
CCS CONCEPTS
• Networks → Sensor networks; • Human-centered com-
puting → Ubiquitous and mobile devices;
KEYWORDS
Noise Cancellation, Acoustics, Internet of Things, Wearables,
Edge Computing, Adaptive Filter, Smart Home, Earphone
ACM Reference Format:
Sheng Shen, Nirupam Roy, Junfeng Guan, Haitham Hassanieh,
Romit Roy Choudhury. 2018. MUTE: Bringing IoT to Noise Cancel-
lation. In SIGCOMM ’18: ACM SIGCOMM 2018 Conference, August
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from permissions@acm.org.
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5567-4/18/08...$15.00
https://doi.org/10.1145/3230543.3230550
Figure 1: MUTE leverages the difference between wire-
less and acoustic propagation delay to provide future
lookahead into the incoming sound signals.
20–25, 2018, Budapest, Hungary. ACM, New York, NY, USA, 15 pages.
https://doi.org/10.1145/3230543.3230550
1 INTRODUCTION
Ambient sound can be a source of interference. Loud conver-
sations or phone calls in office corridors can be disturbing
to others around. Working or napping at airports may be
difficult due to continuous overhead announcements. In de-
veloping regions, the problem is probably most pronounced.
Loud music or chants from public speakers, sound pollution
from road traffic, or just general urban cacophony can make
simple reading or sleeping difficult. The accepted solution
has been to wear ear-plugs or ear-blocking headphones, both
of which are uncomfortable for continuous use [22, 31, 41].
This paper considers breaking away from convention and
aims to cancel complex sounds without blocking the ear. We
introduce our idea next with a simple example.
Consider Alice getting disturbed in her office due to frequent
corridor conversations (Figure 1). Imagine a small IoT device
– equipped with a microphone and wireless radio – pasted
on the door in Alice’s office. The IoT device listens to the
ambient sounds (via the microphone) and forwards the exact
sound waveform over the wireless radio. Now, given that
wireless signals travel much faster than sound, Alice’s noise
cancellation device receives the wireless signal first, extracts
the sound waveform from it, and gains a “future lookahead”
into the actual sound that will arrive later. When the ac-
tual sound arrives, Alice’s ear-device is already aware of
the signal and has had the time to compute the appropriate
anti-noise signal. In fact, this lead time opens various other
3. Wireless arrives atear-device earlier4. Sound arrives later1. Sound starts2. IoT relay forwards sound over wirelessAliceSIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
S. Shen, N. Roy, J. Guan, H. Hassanieh, and R. Roy Choudhury
Figure 2: MUTE’s experimental platform: The center figure (b) shows the full system with the wireless IoT relay
taped on the room’s inside wall and the (crude) ear-device on the table (composed of a microphone on the human
head model, an anti-noise speaker, and a DSP board). The left figure (a) shows our vision of the hollow ear-device,
not covering the ear. The right figure (c) zooms into the relay hardware.
algorithmic and architectural opportunities, as will become
clear in the subsequent discussions.
In contrast, consider today’s noise cancellation headphones
from Bose [9, 10], SONY [15], Philips [18], etc. These head-
phones essentially contain a microphone, a DSP processor,
and a speaker. The processor’s job is to process the sound
received by the microphone, compute the anti-noise signal,
and play it through the speaker. This sequence of operations
starts when the sound has arrived at the microphone, how-
ever, must complete before the same sound has reached the
human’s ear-drum. Given the small distance between the
headphone and the ear-drum, this is an extremely tight dead-
line (≈ 30 µs [13]). The penalty of missing this deadline is a
phase error, i.e., the anti-noise signal is not a perfect “oppo-
site” of the actual sound, but lags behind. The lag increases
at higher frequencies, since phase changes faster at such
frequencies. This is one of the key reasons why current head-
phones are designed to only cancel low-frequency sounds
below 1 kHz [5, 46], such as periodic machine noise. For high-
frequency signals (e.g., speech and music), the headphones
must use sound-absorbing materials. These materials cover
the ear tightly and attenuate the sounds as best as possible
[10, 33].
Meeting the tight deadline is not the only hurdle to real-time
noise cancellation. As discussed later, canceling a sound also
requires estimating the inverse of the channel from the sound
source to the headphone’s microphone. Inverse–channel es-
timation is a non-causal operation, requiring access to future
sound samples. Since very few future samples are available
to today’s headphones, the anti-noise signal is not accurate,
affecting cancellation quality.
With this background in mind, let us now return to our pro-
posal of forwarding sound over wireless links. The forwarded
sound is available to our cancellation device several millisec-
onds in advance of its physical arrival (as opposed to tens
of microseconds in conventional systems). This presents 3
opportunities:
(1) Timing: The DSP processor in our system can complete the
anti-noise computation before the deadline, enabling noise
cancellation for even higher frequencies. Hence, sound-
absorbing materials are not necessary to block the ear.
(2) Profiling: Lookahead allows the DSP processor to fore-
see macro changes in sound profiles, such as when Bob
and Eve are alternating in a conversation. This allows for
quicker multiplexing between filtering modes, leading to
faster convergence at transitions.
(3) Channel Estimation: Finally, much longer lookahead im-
proves anti-noise computation due to better inverse-channel
estimation, improving the core of noise cancellation.
Of course, translating these intuitive opportunities into con-
crete gains entails challenges. From an algorithmic perspec-
tive, the adaptive filtering techniques for classical noise can-
cellation need to be delicately redesigned to fully harness
the advantages of lookahead. From an engineering perspec-
tive, the wireless relay needs to be custom-made so that
forwarding can be executed in real-time (to maximize looka-
head), and without storing any sound samples (to ensure
privacy). This paper addresses all these questions through
a lookahead-aware noise cancellation (LANC) algorithm, fol-
lowed by a custom-designed IoT transceiver at the 900MHz
ISM band. The wireless devices use frequency modulation
(FM) to cope with challenges such as carrier frequency offset,
non-linearities, and amplitude distortion.
Figure 2(b) shows the overall experimentation platform for
our wireless noise cancellation system (MUTE). The custom-
designed wireless relay is pasted on the wall, while the
Hollow Ear Device(for visualization)Wireless Relay (Tx)Reference Mic.Anti-Noise SpeakerRxDSPError Mic.Ear Mic.Noise SourceMUTE: Bringing IoT to Noise Cancellation
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
(crude) ear-device is laid out on the table. The ear-device
has not been packaged into a wearable form factor, however,
is complete in functionality, i.e., it receives the wireless sig-
nals from the relay, extracts the audio waveform, and feeds
it into a TI TMS320 DSP board running the LANC algorithm.
Figure 2(a) visualizes the potential form-factor for such a
wearable device (sketched in AutoDesk), while Figure 2(c)
zooms into the relay hardware. To compare performance,
we insert a “measurement microphone” into the ear position
of the human head model – this serves as a virtual human
ear. We place Bose’s latest ANC headphone (QC35 [10]) over
the head model and compare its cancellation quality against
MUTE, for different types of sounds, multipath environments,
and lookahead times. Finally, we bring in 5 human volun-
teers to experience and rate the performance difference in
noise cancellation. Our results reveal the following:
• MUTE achieves cancellation across [0, 4] kHz, while Bose
cancels only up to 1 kHz. Within 1 kHz, MUTE outperforms
Bose by 6.7 dB on average.
• Compared to Bose’s full headphone (i.e., ANC at [0, 1] kHz
+ sound-absorbing material for [1, 4] kHz), our cancellation
is 0.9 dB worse. We view this as a non ear-blocking de-
vice with a slight compromise. With ear-blocking, MUTE
outperforms Bose by 8.9 dB.
• MUTE exhibits greater agility for fast changing, intermittent
sounds. The average cancellation error is reduced by 3 dB,
and human volunteers consistently rate MUTE better than
Bose for both speech and music.
• Finally, Bose is advantaged with specialized microphones
and speakers (with significantly less hardware noise); our
systems are built on cheap microphone chips ($9) and off-
the-shelf speakers ($19). Also, we have designed a mock
ear-device to suggest how future earphones need not block
the ear (Figure 2(a)). However, we leave the real packaging
(and manufacturing) of such a device to future work.
In closing, we make the following contributions:
• Introduce MUTE, a wireless noise cancellation system archi-
tecture that harnesses the difference in propagation delay
between radio frequency (RF) and sound to provide a valu-
able “lookahead” opportunity for noise cancellation.
• Present a Lookahead Aware Noise Cancellation (LANC) al-
gorithm that exploits lookahead for efficient cancellation
of unpredictable high frequency signals like human speech.
Our prototype compares well with today’s ANC headphones,
but does not need to block the user’s ears.
We expand on each of these contributions next, beginning
with a brief primer on active noise cancellation (ANC), and
followed by our algorithm, architecture, and evaluation.
2 NOISE CANCELLATION PRIMER
An active noise cancellation (ANC) system has at least two
microphones and one speaker (see Figure 3). The microphone
placed closer to the ear-drum is called the error microphone
Me, while the one away from the ear is called the reference
microphone, Mr . The speaker is positioned close to Me and
is called the anti-noise speaker. Ambient noise first arrives
at Mr , then at Me, and finally at the ear-drum. The DSP
processor’s goal is to extract the sound from Mr , compute
the anti-noise, and play it through the speaker such that the
anti-noise cancels the ambient noise at Me.
Figure 3: Basic architecture of an ANC headphone, cur-
rently designed for a single noise source.
Given that received sound is a combination of current and
past sound samples (due to multipath), the DSP processor
cannot simply reverse the sound samples from Mr . Instead,
the various channels (through which the sound travels) need
to be estimated correctly to construct the anti-noise signal.
For this, the DSP processor uses the cancellation error from
Me as feedback and updates its channel estimates to converge
to a better anti-noise in the next time step. Once converged,
cancellation is possible at Me regardless of the sound sample.
So long as the ear-drum is close enough to Me, the human
also experiences similar cancellation as Me.
(cid:4) The ANC Algorithm: Figure 4 redraws Figure 3 but from
an algorithmic perspective. Observe that the error micro-
phone Me receives two signals, one directly from the noise
source, say a(t), and the other from the headphone’s anti-
noise speaker, say b(t). The output of this microphone can
be expressed as e(t) = a(t) + b(t). For perfect cancellation,
e(t) would be zero.
Now, a(t) can be modeled as a(t) = hne(t) ∗ n(t), where hne
is the air channel from the noise source to Me, n(t) is the
noise signal, and ∗ denotes convolution. Similarly, b(t) can
be modeled as:
hnr(t) ∗ n(t)(cid:17)(cid:17)
b(t) = hse(t) ∗(cid:16)
hAF(t) ∗(cid:16)
(1)
𝑀𝑟: Ref. Mic.𝑀𝑒: Error Mic.DSPAnti-NoiseSpeaker(Error Feedback)NoiseSIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
S. Shen, N. Roy, J. Guan, H. Hassanieh, and R. Roy Choudhury
the noise source, and replace the wired connection between
Mr and the DSP processor with a wireless (RF) link. This sep-
aration significantly increases the lead time (or lookahead),