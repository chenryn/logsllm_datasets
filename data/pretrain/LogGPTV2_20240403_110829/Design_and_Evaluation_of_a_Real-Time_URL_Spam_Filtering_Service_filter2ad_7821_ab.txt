Web browser
URL features for each link, number of links, ratio of internal domains to external domains
Web browser
Number of user prompts, tokens of prompts, onbeforeunload event present?
Web browser
URL features for each window URL, number of windows, behavior that caused new window
Web browser
URL features for each plugin URL, number of plugins, application type of plugin
Web browser
Tokens of all ﬁeld names and values; time-based ﬁelds are ignored
IP of each host, mailserver domains and IPs, nameserver domains and IPs, reverse IP to host match?
DNS resolver
IP analysis
Country code, city code (if available) for each IP encountered
ASN/BGP preﬁx for each IP encountered
IP analysis
TABLE 1: List of features collected by Monarch
[26], our system employs an instrumented version of Firefox
with JavaScript enabled and plugin applications installed in-
cluding Flash and Java. As a URL loads in the browser, we
monitor a multitude of details, including redirects, domains
contacted while constructing a page, HTML content, pop-up
windows, HTTP headers, and JavaScript and plugin execution.
We now explain the motivation behind each of these raw
features and the particulars of how we collect them.
Initial URL and Landing URL. As identiﬁed by earlier
research [16], [23], the lexical features surrounding a URL
provide insight
into whether it reﬂects spam. The length
of a URL, the number of subdomains, and terms that ap-
pear in a URL all allow a classiﬁer to discern between
get.cheap.greatpills.com and google.com. However, given the
potential for nested URLs and the frequent use of shortening
services, simply analyzing a URL presented to our service
does not sufﬁce. Instead, we fetch each URL provided to the
browser, allowing the browser to log both the initial URL
provided as well as the URL of the ﬁnal landing page that
results after executing any redirects.
landing URL,
Redirects. Beyond the initial and ﬁnal
the
redirect chain that occurs in between can provide insight into
whether a ﬁnal page is spam. Suspiciously long redirect chains,
redirects that travel through previously known spam domains,
and redirects generated by JavaScript and plugins that would
otherwise prevent a lightweight browser from proceeding all
offer insight into whether the ﬁnal landing page reﬂects spam.
To capture each of these behaviors, the web browser monitors
each redirect that occurs from an initial URL to its ﬁnal
landing page. This monitoring also includes identifying the
root cause of each redirect; whether it was generated by a
server 30X HTTP response, meta refresh tag, JavaScript event,
or plugin (e.g., Flash).
Sources and Frames. In the case of mashup pages with spam
content embedded within a non-spam page, the URL of a ﬁnal
page masks the presence of spam content. This is particularly
a problem with URL shortening services, including ht.ly and
ow.ly, which embed shortened URLs as IFrames. To recover
information about embedded content, the web browser mon-
itors and logs all frames, images, and ad URLs it contacts
during the construction of a page. The browser also collects
a list of all outgoing network requests for URLs, regardless
whether the URL is for a top level window or frame, and
applies a generic label called sources.
HTML Content. Beyond features associated with URLs, the
content of a page often proves indicative of the presence of
spam [24], [27], [28]. This includes the terms appearing on
a page and similar layout across spam webpages. To capture
page content, the web browser saves a ﬁnal landing page’s
HTML in addition to the HTML of all subframes on the page.
Naturally, we cannot collect HTML features for image-based
spam or for media content such as PDFs.
Page Links. The links appearing on a ﬁnal landing page offer
some insight into spam. While the web browser only follows
URLs that automatically load (it does not crawl embedded
links such as HREFs), if a page contains a URL to a known
spam page, then that can help to classify the ﬁnal landing page.
Similarly, search engine optimization techniques where a page
comes stuffed with thousands of URLs to an external domain
also suggests misbehavior. To capture both of these features,
the web browser parses all links on a ﬁnal landing page. Each
link is subjected to the same analysis as frames and redirects.
Afterwards, we compute the ratio of links pointing at internal
pages versus external domains.
JavaScript Events. In addition to the content of a page,
observing an attempt
to force the user to interact with a
page—such as pop-up boxes and prompts that launch before a
user navigates away from a page—strongly indicates spam. To
identify this behavior, the web browser instruments all dialog
messages that would normally require some user action to
dismiss, including alerts, input boxes, and onbeforeunload
events. When a dialog box occurs, the browser silently returns
from the event, logging the text embedded in the dialog. If a
return value is expected such as with an input box, the browser
provides a random string as a response. The browser saves
450
as features the number of dialogs that occur, the text of the
dialogs, and the presence of an onbeforeunload event.
Pop-up Windows. As with pop-up dialogs, pop-up windows
are a common feature of spam. Whenever a pop-up window
occurs, the browser allows the window to open, instrumenting
the new page to collect all the same features as if the URL had
originated from the dispatch queue. It records the parent URL
that spawned the pop-up window, along with whether the page
was launched via JavaScript or a plugin. After all windows
have ﬁnished loading (or upon a timeout), the browser saves
the total number of pop-up windows spawned and the features
of each window and associates them with the parent URL.
Plugins. Previous reports have shown that spammers abuse
plugins as a means to redirect victims to a ﬁnal
landing
page [26], [29]. To capture such plugin behavior, our browser
monitors all plugins instantiated by a page, the application type
of each plugin (e.g., Java, Flash), and ﬁnally whether a plugin
makes any request to the browser that leads to an outgoing
HTTP request, causes a page to redirect, or launches a new
window.
HTTP Headers. The HTTP headers that result as the browser
loads a landing page provide a ﬁnal source of information.
Header data offers insight into the servers, languages, and
versions of spam hosts,
in addition to cookie values and
custom header ﬁelds. We ignore HTTP ﬁelds and values
associated with timestamps to remove any bias that results
from crawling at particular times.
3.2. DNS Resolver
While spammers rapidly work through individual domain
names during the course of a campaign, they often reuse
their underlying hosting infrastructure for signiﬁcant peri-
ods [17], [18], [20], [23]. To capture this information, once the
web browser ﬁnishes processing a page, the crawler instance
manager forwards the initial, ﬁnal, and redirect URLs to a
DNS resolver. For each URL, the resolver collects hostnames,
nameservers, mailservers, and IP addresses associated with
each domain. In addition, we examine whether a reverse
lookup of the IP addresses reported match the domain they
originated from. Each of these features provides a means for
potentially identifying common hosting infrastructure across
spam.
3.3. IP Address Analysis
Geolocation and routing information can provide a means
for identifying portions of the Internet with a higher prevalence
of spam [17]. To extract these features, we subject each IP
address identiﬁed by the DNS resolver to further analysis in
order to extract geolocation and routing data. This includes
identifying the city, country, ASN, and BGP preﬁx associated
with each address.
3.4. Proxy and Whitelist
To reduce network delay, Monarch proxies all outgoing
network requests from a crawling instance through a single
cache containing previous HTTP and DNS results. In addition,
we employ a whitelist of known good domains and refrain
from crawling them further if they appear during a redirect
chain as a top-level window; their presence in IFrames or pop-
up windows does not halt the surrounding collection process.
Whitelists require manual construction and include trusted,
high-frequency domains that do not support arbitrary user
content. Our current whitelist contains 200 domains, examples
of which include nytimes.com, ﬂickr.com, and youtube.com.
Whitelisted content accounts for 32% of URLs visited by
our crawlers. The remaining content falls into a long tail
distribution of random hostnames, 67% of which appear once
and 95% of which appear at most 10 times in our system.
While we could expand the whitelist, in practice this proves
unnecessary and provides little performance improvement.
3.5. Feature Extraction
In preparation for classiﬁcation, we transform the un-
processed features gathered during feature collection into a
meaningful feature vector. We ﬁrst canonicalize URLs to
remove obfuscation, domain capitalization, and text encod-
ing. Obfuscation includes presenting IP addresses in hex or
octet format, or embedding path-traversal operations in the
URL path. By reducing URLs to a canonical form, we can
assure that common URL features match consistently across
occurrences and cannot be masked by lexical transformations
that would otherwise result in the same browser behavior. To
compensate for potential lost information, we also include a
boolean feature reﬂecting the presence of an obfuscated URL.
Once canonicalized, we split a URL into its basic compo-
nents of domain, path, and query parameters, each of which
we tokenize by splitting on non-alphanumeric characters. We
apply a similar process to HTML and any text strings such
as HTTP headers, where we tokenize the text corpus into
individual terms and treat them as an unsorted bag of words.
We then convert
the results of tokenization into a binary
feature vector, with a ﬂag set for each term present. Rather
than obscuring the origin of each token, we construct separate
feature groups to indicate that a feature appeared in a redirect
versus HTML content. Given the potential for millions of
features, we represent feature vectors as sparse hash maps,
which only indicate the presence of a feature. Finally, we
provide these sparse maps to the classiﬁer for training and
decision making.
4. Distributed Classiﬁer Design
For Monarch, we want a classiﬁer that we can train
quickly over large sets of data. Our ﬁrst design decision
along these lines was to use linear classiﬁcation, where the
output classiﬁcation model is a weight vector (cid:126)w that describes
451
a hyperplane that separates data points placed in a high-
dimensional space. We choose linear classiﬁcation because
of its simplicity, scalability and interpretability — for these
reasons, linear classiﬁers have become common-place for web
service providers interested in large-scale anti-phishing and
anti-spam classiﬁcation [24], [30].
In addition to quick training, we want the classiﬁer to ﬁt
in memory. With these goals in mind, we design our training
algorithm as a parallel online learner with regularization to
yield a sparse weight vector. In particular, we combine the
strategies of iterative parameter mixing [31] and subgradient
L1-regularization [32]. Although more sophisticated algo-
rithms exist that could yield higher accuracy classiﬁers at the
expense of more training time, we favor a design that can yield
favorable classiﬁcation accuracies with less training time.
4.1. Notation
The problem of identifying spam URLs is an instance of
binary classiﬁcation. For a given URL, the data point (cid:126)x ∈ Rd
represents its feature vector in a high-dimensional space with
d features. Because (cid:126)x is sparse (typically 1,000–1,500 nonzero
entries out of an extremely large feature space of d > 107),
we represent the feature vector as a hash map. We label the
data point with an accompanying class label y ∈ {−1, +1}.
y = −1 represents a non-spam site, and a y = +1 represents
a malicious site.
To predict the class label of a previously unseen example
(cid:126)x (representing the URL’s feature vector), we train a linear
classiﬁer characterized by weight vector (cid:126)w trained ofﬂine on
a labeled set of training data. During testing or deployment,
we compute a predicted label as the sign of the dot product
between the weight vector and the example: ˆy = sign((cid:126)x · (cid:126)w).
If the predicted label ˆy = +1 but the actual label y = −1,
then the error is a false positive. If ˆy = −1 but y = +1, then
the error is a false negative.
4.2. Logistic Regression with L1-regularization
n(cid:88)
For training the weight vector (cid:126)w, we use logistic regression
(LR) with L1-regularization [33]. Given a set of n labeled
training points {((cid:126)xi, yi)}n
i=1, the goal of the training process
is to ﬁnd (cid:126)w that minimizes the following objective function:
f( (cid:126)w) =
log(1 + exp[−yi((cid:126)xi · (cid:126)wi)]) + λ(cid:107) (cid:126)w(cid:107)1.
(1)
i=1
The ﬁrst component of the objective constitutes the log-
likelihood of the training data as a function of the weight
vector—it is an upper bound on the number of mistakes made
during training, and solving this proxy objective is a tractable
alternative to directly minimizing the training error. For a
single example ((cid:126)xi, yi), we can minimize the value of log(1+
exp[−yi((cid:126)xi · (cid:126)wi)]) if the classiﬁcation margin yi((cid:126)xi · (cid:126)wi) is a
large positive value. (The margin is proportional to the distance
between (cid:126)xi and the classiﬁer’s decision boundary—a positive
Algorithm 1 Distributed LR with L1-regularization
Input: Data D with m shards
Parameters: λ (regularization factor), I (no. of iterations)
Initialize:
(cid:126)w = (cid:126)0
for i = 1 to I do
(gradient) (cid:126)g(j) = LRsgd( (cid:126)w, Dj) for j = 1..m
(average) (cid:126)w = (cid:126)w − 1
(shrink) wα = sign(wα) · max(0,|wα| − λ) for α = 1..d
j=1 (cid:126)g(j)
m
(cid:80)m
end for
Algorithm 2 Stochastic gradient descent for LR (LRsgd)
Input: (cid:126)w (weight vector), Dj (data shard)
Parameters: η (learning rate)
Initialize:
(cid:126)g0 = (cid:126)w
for t = 1 to |Dj| do
Get data point (xt, yt) from Dj
Compute margin z = yt((cid:126)xt · ( (cid:126)w − (cid:126)gt−1))
Compute partial gradient (cid:126)h = yt([1 + e−z]−1 − 1)(cid:126)xt
(cid:126)gt = (cid:126)gt−1 + η(cid:126)h
end for
Return: (cid:126)g|Dj|
The second component
value means it is on the correct side of the boundary, and
a negative value means it is on the incorrect side.) Thus, a
solution that minimizes f( (cid:126)w) would ideally yield a positive
classiﬁcation margin for as many examples as possible.
of (cid:126)w is large ((cid:107) (cid:126)w(cid:107)1 = (cid:80)d
is the regularization—it adds a
penalty to the objective function for values where the L1 norm
j=1 wj). L1-regularization tends
to yield sparse weight vectors—where there are relatively
few nonzero feature weights. This is useful for applications
that may be memory-constrained and require sparse solutions.
(By contrast, using the L2 norm, another popular form of
regularization, would yield solutions whose weights have small
magnitudes but that tend to be non-sparse.) The parameter λ
governs the amount of regularization: a higher λ gives the
second component of Equation 1 more weight relative to the
ﬁrst component and will yield a more sparse solution.
Many optimization strategies exist for minimizing the ob-
jective in Equation 1. We had particular interest in a strategy
amenable to learning over large-scale data sets in a short
amount of time. We settled on a combination of recently-
developed distributed learning and regularization techniques,
which we describe in the next section.
4.3. Training Algorithm
We ﬁrst divide the training data into m shards (which occurs
by default storing data on certain distributed ﬁle systems
such as the Hadoop Distributed File System [34]). Then,
we distribute the initial model weight vector (cid:126)w to the m
shards for training by stochastic gradient descent (Algorithm 1,
“gradient” step).
Within each shard, we update the weight vector using
452
a stochastic gradient descent for logistic regression (Algo-
rithm 2). We update the weight vector one example at a time
as we read through the shard’s data (this is also known as