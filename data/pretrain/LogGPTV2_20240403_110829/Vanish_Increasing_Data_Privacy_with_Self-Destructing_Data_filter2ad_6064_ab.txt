keys. Under our model, though, we assume that the at-
tacker will be able to obtain access to the decryption
keys, e.g., through a court order or subpoena.2
A potential alternative to standard encryption might be
to use forward-secure encryption [6, 13], yet our goal
is strictly stronger than forward secrecy. Forward se-
crecy means that if an attacker learns the state of the
user’s cryptographic keys at some point in time, they
should not be able to decrypt data encrypted at an earlier
time. However, due to caching, backup archives, and the
threat of subpoenas or other court orders, we allow the at-
tacker to either view past cryptographic state or force the
user to decrypt his data, thereby violating the model for
forward-secure encryption. For similar reasons, plus our
desire to avoid introducing new trusted agents or secure
hardware, we do not use other cryptographic approaches
like key-insulated [5, 23] and intrusion-resilient [21, 22]
cryptography. Finally, while exposure-resilient cryptog-
raphy [11, 24, 25] allows an attacker to view parts of a
key, we must allow an attacker to view all of the key.
Another approach might be to use steganography [48],
deniable encryption [12], or a deniable ﬁle system [17].
The idea is that one could hide, deny the contents of, or
deny the existence of private historical data, rather than
destroying it. These approaches are also attractive but
hard to scale and automate for many applications, e.g.,
generating plausible cover texts for emails and photos. In
addition to the problems observed with deniable ﬁle sys-
tems in [17] and [38], deniable ﬁle systems would also
create additional user hassles for a trash bin application,
whereas our approach could be made invisible to the user.
For online, interactive communications systems, an
ephemeral key exchange process can protect derived
symmetric keys from future disclosures of asymmetric
private keys. A system like OTR [1, 10] is particularly at-
2U.S. courts are debating whether citizens are required to disclose
private keys, although the ultimate verdict is unclear. We thus target
technologies robust against a verdict in either direction [29, 40]. Other
countries such as the U.K. [43] require release of keys, and coercion or
force may be an issue in yet other countries.
tractive, but as the original OTR paper observes, this ap-
proach is not directly suited for less-interactive email ap-
plications, and similar arguments can be made for OTR’s
unsuitability for the other above-mentioned applications
as well.
An approach with goals similar to ours (except for
the goal of allowing users to create self-destructing ob-
jects without having to establish asymmetric keys or
passphrases) is the Ephemerizer family of solutions [39,
46, 47]. These approaches require the introduction of
one or more (possibly thresholded) trusted third parties
which (informally) escrow information necessary to ac-
cess the protected contents. These third parties destroy
this extra data after a speciﬁed timeout. The biggest risks
with such centralized solutions are that they may either
not be trustworthy, or that even if they are trustworthy,
users may still not trust them, hence limiting their adop-
tion. Indeed, many users may be wary to the use of dedi-
cated, centralized trusted third-party services after it was
revealed that the Hushmail email encryption service was
offering the cleartext contents of encrypted messages to
the federal government [59]. This challenge calls for
a decentralized approach with fewer real risks and per-
ceived risks.
A second lesson can be learned from the Ephemer-
izer solutions in that, despite their introduction several
years ago, these approaches have yet to see widespread
adoption. This may in part be due to the perceived trust
issues mentioned above, but an additional issue is that
these solutions require the creation of new, supported and
maintained services. We theorize that solutions that re-
quire new infrastructures have a greater barrier to adop-
tion than solutions that can “parasitically” leverage exist-
ing infrastructures. A variant of this observation leads us
to pursue approaches that do not require secure hardware
or other dedicated services.
3 Goals and Assumptions
To support our
target applications (self-destructing
emails, Facebook messages, text messages, trash bins,
etc.), we introduce the notion of a vanishing data ob-
ject (VDO). A VDO encapsulates the user’s data (such
as a ﬁle or message) and prevents its contents from per-
sisting indeﬁnitely and becoming a source of retroactive
information leakage. Regardless of whether the VDO is
copied, transmitted, or stored in the Internet, it becomes
unreadable after a predeﬁned period of time even if an
attacker retroactively obtains both a pristine copy of the
VDO from before its expiration, and all of the user’s
past persistent cryptographic keys and passwords. Fig-
ure 2 illustrates the above properties of VDOs by show-
ing the timeline for a typical usage of and attack against
a VDO. We crystallize the assumptions underlying our
4. No secure hardware. The system must not require
the use of dedicated secure hardware.
5. No new privacy risks. The system should not intro-
duce new privacy risks to the users.
Figure 2: Timeline for VDO usage and attack.
VDO model and the central aspects of the threat model
below.
Assumptions. Our VDO abstraction and Vanish system
make several key assumptions:
1. Time-limited value. The VDO will be used to en-
capsulate data that is only of value to the user for a
limited period of time.
2. Known timeout. When a user encapsulates data in a
VDO, she knows the approximate lifetime that she
wants for her VDO.
3. Internet connectivity. Users are connected to the In-
ternet when interacting with VDOs.
4. Dispensability under attack. Rather than risk expo-
sure to an adversary, the user prefers the VDO to be
destroyed, even if prematurely.
We consider encapsulation of data that only needs to
be available for hours or days; e.g., certain emails, Web
objects, SMSs, trash bin ﬁles, and others fall into this
category. Internet connectivity is obviously required for
many of our applications already, such as sending and
receiving emails. More generally, the promise of ubiqui-
tous connectivity makes this assumption reasonable for
many other applications as well. Internet connectivity is
not required for deletion, i.e., a VDO will become un-
readable even if connectivity is removed from its storage
site (or if that storage site is ofﬂine). Finally, Vanish is
designed for use with data that is private, but whose per-
sistence is not critical. That is, while the user prefers that
the data remain accessible until the speciﬁed timeout, its
premature destruction is preferable to its disclosure.
Goals. Having stated these assumptions, we target the
following functional goals and properties for Vanish:
1. Destruction after timeout. A VDO must expire au-
tomatically and without any explicit action on the
part of its users or any party storing a copy of the
VDO. Once expired, the VDO must also be inac-
cessible to any party who obtains a pristine copy of
the VDO from prior to its expiration.
2. Accessible until timeout. During its lifetime, a
VDO’s contents should be available to legitimate
users.
3. Leverage existing infrastructures. The system must
leverage existing infrastructures. It must not rely on
external, special-purpose dedicated services.
A corollary of goal (1) is that the VDO will become
unavailable to the legitimate users after the timeout,
which is compatible with our applications and assump-
tion of time-limited value.
Our desire to leverage existing infrastructure (goal (3))
stems from our belief that special-purpose services may
hinder adoption. As noted previously, Hushmail’s dis-
closure of the contents of users’ encrypted emails to the
federal government [59] suggests that, even if the cen-
tralized service or a threshold subset of a collection of
centralized services is trustworthy, users may still be un-
willing to trust them.
As an example of goal (5), assume that Ann sends
Carla an email without using Vanish, and then another
email using Vanish. If an attacker cannot compromise
the privacy of the ﬁrst email, then we require that the
same attacker — regardless of how powerful — cannot
compromise the privacy of the second email.
In addition to these goals, we also seek to keep the
VDO abstraction as generic as possible. In Vanish, the
process of encapsulating data in a VDO does not require
users to set or remember passwords or manage crypto-
graphic keys. However, to ensure privacy under stronger
threat models, Vanish applications may compose VDOs
with traditional encryption systems like PGP and GPG.
In this case, the user will naturally need to manipulate
the PGP/GPG keys and passphrases.
Threat Models. The above list enumerates the intended
properties of the system without the presence of an ad-
versary. We now consider the various classes of poten-
tial adversaries against the Vanish system, as well as the
desired behavior of our system in the presence of such
adversaries.
The central security goal of Vanish is to ensure the
destruction of data after a timeout, despite potential ad-
versaries who might attempt to access that data after its
timeout. Obviously, care must be taken in deﬁning what
a plausible adversary is, and we do that below and in Sec-
tion 6. But we also stress that we explicitly do not seek
to preserve goal (2) — accessible prior to a timeout —
in the presence of adversaries. As previously noted, we
believe that users would prefer to sacriﬁce availability
pre-timeout in favor of assured destruction for the types
of data we are protecting. For example, we do not defend
against denial of service attacks that could prevent read-
ing of the data during its lifetime. Making this assump-
tion allows us to focus on the primary novel insights in
this work: methods for leveraging decentralized, large-
scale P2P networks in order to make data vanish over
time.
  AttackerServiceUserBegins attackall VDO copies expireTimeT1T1T5T5Obtains VDOT2T2T3T3T4T4T1:   User creates VDO;T2:   Service archives a pristine           copy of the VDO;T3:   All copies of VDO expire;T4:   Attacker decides to attack          this VDO;T5:   Attacker obtains pristine         VDO copy from service or          user; copy is unreadableWe therefore focus our threat model and subsequent
analyses on attackers who wish to compromise data pri-
vacy. Two key properties of our threat model are:
1. Trusted data owners. Users with legitimate access
to the same VDOs trust each other.
2. Retroactive attacks on privacy. Attackers do not
know which VDOs they wish to access until after
the VDOs expire.
The former aspect of the threat model is straightforward,
and in fact is a shared assumption with traditional en-
cryption schemes: it would be impossible for our sys-
tem to protect against a user who chooses to leak or
permanently preserve the cleartext contents of a VDO-
encapsulated ﬁle through out-of-band means. For exam-
ple, if Ann sends Carla a VDO-encapsulated email, Ann
must trust Carla not to print and store a hard-copy of the
email in cleartext.
The latter aspect of the threat model — that the at-
tacker does not know the identity of a speciﬁc VDO of
interest until after its expiration — was discussed brieﬂy
in Section 1. For example, email or SMS subpoenas typi-
cally come long after the user sends a particular sensitive
email. Therefore, our system defends the user against
future attacks against old copies of private data.
Given the retroactive restriction, an adversary would
have to do some precomputation prior to the VDO’s ex-
piration. The precise form of precomputation will de-
pend on the adversary in question. The classes of ad-
versaries we consider include: the user’s employer, the
user’s ISP, the user’s web mail provider, and unrelated
malicious nodes on the Internet. For example, foreshad-
owing to Section 6, we consider an ISP that might spy
on the connections a user makes to the Vuze DHT on
the off chance that the ISP will later be asked to assist
in the retroactive decapsulation of the user’s VDO. Sim-
ilarly, we consider the potential for an email service to
proactively try to violate the privacy of VDOs prior to
expiration, for the same reason. Although we deem both
situations unlikely because of public perception issues
and lack of incentives, respectively, we can also provide
defenses against such adversaries.
Finally, we stress that we do not seek to provide pri-
vacy against an adversary who gets a warrant to intercept
future emails. Indeed, such an attacker would have an ar-
senal of attack vectors at his disposal, including not only
a priori access to sensitive emails but also keyloggers
and other forensic tools [37].
4 The Vanish Architecture
We designed and implemented Vanish, a system capa-
ble of satisfying all of the goals listed in Section 3. A
key contribution of our work is to leverage existing, de-
centralized, large-scale Distributed Hash Tables (DHTs).
After providing a brief overview of DHTs and introduc-
ing the insights that underlie our solution, we present our
system’s architecture and components.
Overview of DHTs. A DHT is a distributed, peer-to-
peer (P2P) storage network consisting of multiple partic-
ipating nodes [35, 56, 64]. The design of DHTs varies,
but DHTs like Vuze generally exhibit a put/get interface
for reading and storing data, which is implemented inter-
nally by three operations: lookup, get, and store. The
data itself consists of an (index,value) pair. Each node in
the DHT manages a part of an astronomically large index
name space (e.g., 2160 values for Vuze). To store data,
a client ﬁrst performs a lookup to determine the nodes
responsible for the index; it then issues a store to the re-
sponsible node, who saves that (index,value) pair in its
local DHT database. To retrieve the value at a particular
index, the client would lookup the nodes responsible for
the index and then issue get requests to those nodes. In-
ternally, a DHT may replicate data on multiple nodes to
increase availability.
Numerous DHTs exist
including
Vuze, Mainline, and KAD. These DHTs are commu-
nal, i.e., any client can join, although DHTs such as
OpenDHT [54] only allow authorized nodes to join.
in the Internet,
Key DHT-related Insights. Three key properties of
DHTs make them extremely appealing for use in the con-
text of a self-destructing data system:
1. Availability. Years of research in availability in
DHTs have resulted in relatively robust properties
of today’s systems, which typically provide good
availability of data prior to a speciﬁc timeout. Time-
outs vary, e.g., Vuze has a ﬁxed 8-hour timeout,
while OpenDHT allows clients to choose a per-data-
item timeout of up to one week.
2. Scale, geographic distribution, and decentraliza-
tion. Measurement studies of the Vuze and Main-
line DHTs estimate in excess of one million si-
multaneously active nodes in each of the two net-