and database – all of these layers produce valuable logs for forensic
investigation. Collecting logs from these multiple servers and layers
and providing it to investigators in a secure way is extremely chal-
lenging.
Accessibility of Logs. The logs generated in different layers are
required to be accessible to different stakeholders of the system, e.g.,
system administrator, forensic investigator, and developer. System
administrators need relevant log to troubleshoot the system; devel-
opers need the required log to ﬁx the bug of the application; forensic
investigators need logs, which can help in their investigation. Hence,
there should be some access control mechanism, so that everybody
will get what they need exactly – nothing more, nothing less and
obviously, in a secure way. We should not expect that a malicious
cloud employee, who can violate the privacy of the users gets access
to users’ log information.
Multi-tenancy:
In cloud computing, multiple virtual machines
Network Servers OS Data Application Access Control Network Servers OS Data Application Access Control Network Servers OS Data Application Access Control SaaS PaaS IaaS Customers have control Customers do not have control (VM) can share the same physical infrastructure, i.e., log for multi-
ple customers may be co-located. The nature of this infrastructure is
different from the traditional single owner computer system. Hence,
while collecting logs for one user, other users’ data can be mingled
with the log evidence. An alleged user can claim that the log con-
tains information of other users, not her. The investigator then needs
to prove it to the court that the provided logs indeed belongs to the
malicious user. Moreover, we need to preserve the privacy of the
other tenants. For both of these issues, collecting and providing logs
to the investigator is challenging in cloud paradigm.
Chain of custody: The chain of custody is one of the most vital
issues in traditional digital forensic investigation. The chain of cus-
tody should clearly depict how the evidence was collected, analyzed,
and preserved in order to be presented as admissible evidence in
court [29]. In traditional forensic procedure, it starts with gaining
the physical control of the evidence, e.g., computer, hard disk. How-
ever, in cloud forensics, this step is not possible due to the multi
jurisdictional laws, procedures, and proprietary technology in cloud
environment [27, 14]. Collecting logs from cloud infrastructure,
analyzing, and presenting the proof of logs need to follow this chain
of custody. We must clarify certain things to maintain the chain of
custody, e.g., how the logs were generated and stored, and who had
the access to the logs.
Presentation: The ﬁnal step of digital forensic investigation is
presentation, where an investigator accumulates his ﬁndings and
presents to the court as the evidence of a case. Challenges also
lie in this step of cloud forensics [22]. Proving the integrity of
network and process logs in front of jury for traditional computer
forensics is relatively easy, compared to the complex structure of
cloud computing. Presenting the logs and the proofs of integrity of
the logs to the court in an admissible way is challenging for cloud
computing.
3. THREAT MODEL
In this section, we describe the attacker’s capability, possible
attacks on logs, and properties of our proposed system. Before
describing the threat model, we ﬁrst deﬁne the important terms to
clarify the threat model.
3.1 Deﬁnition of terms
• User: A user is a customer of the cloud service provider
(CSP), who uses the CSP’s storage service. A user can be
malicious or honest.
• Log: A log can be the network log, process log, operating
system logs, or any other logs generated in cloud for a VM.
• Proof of Past Logs (PPL): The PPL contains the proof of logs
to verify whether some logs belong to a particular user or not.
• Investigator: An investigator is a professional forensic in-
vestigator, who needs to collect necessary logs from cloud
infrastructure in case of any malicious incident.
• CSP: The Cloud Service Provider (CSP) will generate the
PPL and give access to the logs to users and investigators
through an API or management console.
• Log Chain (LC): The LC maintains the correct order of the
logs. From the LC, it can be veriﬁed that the CSP or the
investigators provide logs in the actual order of log generation.
• Auditor: Most likely, the auditor will be the court authority
that will verify the correctness of the logs from the PPL and
LC.
• Intruder: An intruder can be any malicious person including
a employee of the CSP, who wants to reveal user’s activity
from the PPL or from the log storage.
3.2 Attacker’s Capability
In our threat model, we assume that the users and the investigators
do not trust the CSPs, and both of them can be malicious. We
assume that a CSP is honest at the time of publishing the PPL and
LC. However, during the investigation, CSP can collude with a user
or an investigator and provide tampered logs, for which the PPL and
LC have already been published. User, investigator, and CSP can
collude with each other to provide fake logs to the auditor. A user
cannot modify the logs by him, but he can collude with CSP to alter
the logs. An investigator can present false log information to the
court to frame an honest user or can collude with a malicious user to
save her from accusation. The CSP can also repudiate any published
PPL. An intruder can acquire the PPL of a user to learn the user’s
activity. A malicious cloud employee can also be an intruder.
3.3 Possible Attacks
There can be different types of attacks on providing log API. CSP
can remove some crucial logs or can reorder the logs. A user can
deny the ownership of any logs. Even an investigator can present
invalid logs to the court. Below we mention some of the possible
attacks:
• Privacy violation: If the CSP published the PPL publicly on
the web, any malicious person can acquire the published PPL
and try to learn about the logs from the proof. Even if logs are
kept unpublished, an otherwise honest employee of the CSP
who has access to the log storage can identify the activity of
the user from the stored logs.
• Log modiﬁcation: A dishonest CSP, while colluding with
user or investigator can modify the logs, either to save a
malicious user or to frame a honest user. If an investigator
is not trustworthy, he can also tamper with the logs before
presenting the logs to the court. There can be three types of
contamination of logs:
1. Removal of crucial logs
2. Planting of false logs
3. Modiﬁcation of the order of the logs
• Repudiation by CSP: An otherwise honest CSP can deny a
published PPL/LC after-the-fact.
• Repudiation by User: As data are co-mingled in the cloud, a
malicious user can claim that the logs contain another cloud
user’s data.
3.4 System Property
In designing SecLaaS, our goal is to ensure the secure preserva-
tion of cloud users’ logs in a persistent storage. Our mechanism
should prevent any malicious party to produce a false proof of past
logs PPL. A false PPL attests the presence of a log record for a
user, which the user does not actually own. Once the proof has been
published, the CSP can neither modify the proof nor repudiate any
published proof. Additionally, we must prevent false implications
by malicious forensic investigators. Based on our analysis, a secure
log service for clouds should possess the following integrity and
conﬁdentiality properties:
• I1: The CSP cannot remove a log entry from the storage after
publishing the PPL.
• I2: The CSP cannot change the order of a log from its actual
order of generation.
• I3: The CSP cannot plant false log after-the-fact.
• I4: An investigator cannot hide or remove a log entry at the
time of presenting logs to court.
• I5: An investigator cannot change the actual order of a log
entry at the time of presenting evidences to court.
• I6: An Investigator cannot present phony log to the court.
• I7: The CSP cannot repudiate any previously published proof
of logs.
• C1: From the published proof of log, no adversaries can
recover any log.
• C2: A malicious cloud employee will not be able to recover
logs from the log storage.
4. THE SecLaaS SCHEME
In this section, we present SecLaaS – our system for secure
retrieval of logs and storage of the proof of past logs. Initially, we
provide an overview of the mechanism, followed by the schematic
and the protocol speciﬁc description of the system.
4.1 Overview
A VM in the cloud can attack other VMs inside the cloud or can
attack a computing device outside the VM. The attacker VM can
also attack the Node Controller (NC) to launch a side channel attack
[23]. Figure 2 presents an overview of storing the logs in a secured
way and making it available to forensic investigators in case of such
attacks. Malicious activity of a VM can be found from various logs
generated in the NC, on which the VM is running. For each running
VM, our system ﬁrst extracts various kinds of logs from the NC and
will store in a persistent log database. Hence, terminating the VM
will not prevent SecLaaS to provide useful logs during investigation.
While saving logs in log database, SecLaaS ensures the integrity
and conﬁdentiality of the logs. After saving a log entry in the log
database, the system will additionally store the proof of this entry in
the proof database. When an investigator wants logs of a particular
IP to investigate an incident, he can get the necessary logs by an
API call or from the cloud management plane. In order to prove the
logs as admissible evidence, the investigator can provide the proof
of the logs along with the logs.
4.2 Schematic Description
In this section, we present the schematic description of our system.
SecLaaS extracts log information from different log sources and
generates a Log Entry LE. A Log Entry LE for network log is deﬁned
as follows:
LE =
(1)
To ensure the conﬁdentiality of users’ log, some information of the
LE can be encrypted using a common public key of the security
agencies. The Encrypted Log Entry ELE is prepared as follows:
ELE = (2)
where PKa is the common public key of all the agencies. We cannot
encrypt all the ﬁelds of the LE as the CSP needs to search the storage
Figure 2: Overview of SecLaaS
by some ﬁelds. To preserve the correct order of the log entry, we
will use a hash-chain scheme. We refer the hash-chain as Log Chain
(LC), which will be generated as follows:
LC =
(3)
where LCPrev is the Log Chain LC of the previous entry of the
persistent storage. Each entry for the persistent log database DBLE
is constituted of ELE and LC,
DBLE =
(4)
The proof of this DBLE will be inserted into a accumulator. We
denote this as Accumulator Entry AE. At the end of each day, CSP
retrieves the AED of that day and generates the Proof of Past Log
PPL as follows:
P P L =
(5)
where H(AE) is the hash of AE, t represents the proof generation
time, and SPKc(AE) is the signature over AE using the private key of
the CSP, PKc.
4.3 System Details
In this section, we present how the log insertion, proof generation,
and veriﬁcation of SecLaaS work. We consider the network log to
describe the entire system. After generating the Log Entry LE the
system will work for any type of logs.
VM	
VM	
VM	
Web Server	
Investigator	
Attack	
Communication	
Ext	
Attacker	
API	
NC	
Log DB	
Proof DB	
(g) After creating the database entry DBLE, the logger module
communicates with the proof storage to retrieve the latest
accumulator entry.
(h) In this step, the logger generates the proof of the database
entry DBLE, i.e., the logger creates a new entry for the accu-
mulator AE and updates the last retrieved accumulator entry
with the newly generated AE.
(i) The logger module sends the updated accumulator entry to
the accumulator storage to store the proof.
(j) At the end of each day, the logger retrieves the last accumula-
tor entry of each static IP, which we denote as AED.
(k) According to equation 5, the logger then creates the Proof of
Past Log PPL using the AED.
(l) After computing the Proof of Past Log PPL, the logger will
publish the PPL and the public key of CSP on the web. These
information can also be available by RSS feed to protect it
from manipulation by the CSP after publishing the proof.
We can also build a trust model by engaging other CSPs in
the proof publication process. Whenever one CSP publishes
a PPL, that PPL will also be shared between other CSPs.
Therefore, we can get a valid proof as long as one CSP is
honest.
4.3.2 Veriﬁcation
When an investigator wants to investigate an incident, he will ﬁrst
gather the required log either by calling log API or from the cloud
management console. While presenting the evidence to the court,
he needs to provide the collected logs and also the proof of the logs.
There will be two steps to verify the provided logs. In the ﬁrst step,
the auditor will verify the integrity of the proof and the individual
log entry. In the next step, he will verify the order of the log.
Integrity Veriﬁcation: Figure 4 shows the the process ﬂow of
individual log entry veriﬁcation.
4.3.1 Log and Proof Insertion
Figure 3 illustrates the detail ﬂow of log retrieval, secured log
insertion, and PPL generation and below is the details of the system.
Figure 3: Process Flow of Retrieving Log and Storing the PPL
(a) The parser module ﬁrst communicates with the log sources to
collects different types of logs. For example, to store network
log the parser listens the Snort 1.
(b) After acquiring logs from different sources, the parser then
parses the collected log and generates the Log Entry LE.
(c) The parser module sends the Log Entry LE to the logger
module to further process the LE.
(d) The logger module, upon receiving the LE from the parser,
encrypts some conﬁdential information using the public key
of the security agencies and generates the Encrypted Log
Entry ELE. The private key to decrypt the log can be shared
among the security agencies. For the network log, some
crucial information that we can encrypt includes: destination
IP, port, and user information.
(e) After generating the ELE, the logger module then creates the
Log Chain LC by using equation 3. In section 5, we will
discuss how this can prevent reordering and deletion of logs.
(f) The logger module then prepares the entry for the log storage
DBLE using the Encrypted Log Entry ELE and the Log Chain
LC, and sends the DBLE to the log storage to add the new
entry.
9 1http://www.snort.org
Figure 4: Log Veriﬁcation Process Flow
Snort	
Parser	
Web	
(a)	
(b)	
(c)	
(f)	
(g)	
Logger	
Log	
Storage	
(h)	
(j)	
(d)	
(e)	
Proof 	
Accumulator	
(l)	
(k)	
(i)	
Published Proof (PPL)	
Result from API Call	
DBLE- 0	
Exists?	
No	
Sequence veriﬁcation	
Yes	
Reject	
DBLE- 1	
Valid?	
No	