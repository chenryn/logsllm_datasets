title:Pythia: Remote Oracles for the Masses
author:Shin-Yeh Tsai and
Mathias Payer and
Yiying Zhang
Pythia: Remote Oracles for the Masses
Shin-Yeh Tsai, Purdue University; Mathias Payer, EPFL; Yiying Zhang, Purdue University
https://www.usenix.org/conference/usenixsecurity19/presentation/tsai
This paper is included in the Proceedings of the 28th USENIX Security Symposium.August 14–16, 2019 • Santa Clara, CA, USA978-1-939133-06-9Open access to the Proceedings of the 28th USENIX Security Symposium is sponsored by USENIX.Pythia: Remote Oracles for the Masses
Shin-Yeh Tsai
Purdue University
Mathias Payer
EPFL
Yiying Zhang
Purdue University
Abstract
Remote Direct Memory Access (RDMA) is a technology
that allows direct access from the network to a machine’s
main memory without involving its CPU. RDMA offers low-
latency, high-bandwidth performance and low CPU utilization.
While RDMA provides massive performance boosts and has
thus been adopted by several major cloud providers, security
concerns have so far been neglected.
The need for RDMA NICs to bypass CPU and directly
access memory results in them storing various metadata like
page table entries in their on-board SRAM. When the SRAM
is full, RNICs swap metadata to main memory across the PCIe
bus. We exploit the resulting timing difference to establish
side channels and demonstrate that these side channels can
leak access patterns of victim nodes to other nodes.
We design Pythia, a set of RDMA-based remote side-
channel attacks that allow an attacker on one client machine
to learn how victims on other client machines access data
a server exports as an in-memory data service. We reverse
engineer the memory architecture of the most widely used
RDMA NIC and use this knowledge to improve the efﬁciency
of Pythia. We further extend Pythia to build side-channel
attacks on Crail, a real RDMA-based key-value store applica-
tion. We evaluated Pythia on four different RDMA NICs both
in a laboratory and in a public cloud setting. Pythia is fast
(57 µs), accurate (97% accuracy), and can hide all its traces
from the victim or the server.
1 Introduction
Direct Memory Access (DMA) allows a machine’s peripher-
als like storage and network devices to access its main mem-
ory directly without involving CPU, vastly increasing I/O
performance and reducing CPU utilization. Inspired by DMA,
Remote Direct Memory Access, or RDMA, is a technology
that allows remote hosts to directly access (exported) mem-
ory of a node without having to go through its CPU. RDMA
enables high throughput and low latency data transfers and
largely reduces CPU utilization in clusters.
In recent years, major cloud vendors like Microsoft
Azure [73] and Alibaba Cloud [6] have adopted RDMA in
their datacenters to speed up processing and to reduce cost
of accessing large amounts of data. As the underlying proto-
cols prosper [32], more and more servers leverage the RDMA
protocol to speed up processing. The use of RDMA has rev-
olutionized data sharing in cloud environments with imple-
mentations for efﬁcient key-value stores [24, 25, 40, 56, 57],
in-memory databases and transactional systems [19, 83, 88],
and graph processing systems [68, 85].
There is a plethora of research work on RDMA, but the
focus so far was all on performance, usability, and network
protocols. Security has been largely overlooked in RDMA
research and production1. With the rise of information leaks
through memory-based side-channels [17,26,39,41,42,86,87],
we have set out to evaluate the side-channel resistance of
existing RDMA implementations.
In a scenario where multiple nodes connect to a server that
provides remote access to its local memory through RDMA
(e.g., for a key-value store), a malicious node may want to
learn what data was accessed by benign nodes. We assume
that the server is trusted and that the attacker tries to learn
what data was accessed by the victim nodes through a remote
side channel which leaks access patterns. Figure 1 illustrates
this environment.
We discovered a new side channel that prevails across
all RDMA hardware that we know of. NICs that support
RDMA, or RNICs, cache metadata such as page table entries
in their on-board SRAM so that they can perform all opera-
tions needed to access main memory on their own without
involving CPU. However, the on-board SRAM size is limited
and the RNIC can only cache hot metadata while leaving the
rest in main memory. When an RDMA request’s metadata is
not cached, the RNIC takes extra time to fetch the metadata
from main memory to its SRAM. We observe and characterize
different side channels that can lead to this timing difference
1We made an initial exploration of security issues and opportunities in
one-sided communication in a recent workshop [77].
USENIX Association
28th USENIX Security Symposium    693
on three generations of RNIC devices.
Based on our ﬁndings, we designed Pythia, a set of side-
channel attacks that can be launched completely from the
network through RDMA. The basic idea is to issue RDMA
network requests to the server to ﬁll its RNIC SRAM, eventu-
ally evicting the metadata of the target data. Then the attacker
reloads the target data with an RDMA request and based on
the time it takes, predict if the victim has accessed the data.
Although the basic idea is similar to the EVICT+RELOAD
CPU cache side-channel attack [30], designing Pythia
presents many new challenges. The ﬁrst challenge is the difﬁ-
culty in achieving good eviction performance. Existing CPU-
cache based side-channel attacks leverage cache associativity
to reduce the eviction set size, thereby improving eviction
performance. However, RNICs are vendor owned and are
complete black boxes to public knowledge. To confront this
challenge, we reverse engineered the memory architecture
of the Mellanox ConnectX-4 RNIC [48], the type of RNIC
that is used in all major datacenter RDMA deployment. We
successfully discovered the internal architectural organiza-
tion of RNIC SRAM and leverage this knowledge to achieve
low-latency eviction.
The second challenge is in the reload and prediction pro-
cess. Because of our environment of being in a shared dat-
acenter network, the latency of an RDMA request can vary
with different network state. The traditional approach of using
a static threshold to differentiate cache hit from cache miss
is not a good ﬁt for our environment. We take an adaptive
approach to dynamically train a hit/miss classiﬁer based on
RDMA access latency at the time of attack and use the trained
classiﬁer to statistically predict victim accesses [22, 28].
We evaluated Pythia in our lab environment and in a public
cloud [65] with four different types of RNICs. Pythia com-
pletes one EVICT+RELOAD cycle (across the network) in as
low as 57 µs with 97% accuracy2 Moreover, Pythia effectively
hides its traces from the server and victims because it per-
forms all its attack using RDMA operations from a separate
machine.
We further built three variations of Pythia to attack a real
RDMA-based system, the Apache Crail key-value store sys-
tem [7,70]. On a real application like Crail, it is more challeng-
ing to establish a strong side-channel attack because of limited
application interface and noise coming from application per-
formance overhead. After improving Pythia to accommodate
these difﬁculties, we successfully launched a side-channel
attack solely from a separate client machine using the unmod-
iﬁed Crail client interface. This attack is efﬁcient and can
accurately learn a victim’s key-value pair access patterns.
The contributions of this paper are:
1. Discovery of new side channels in RDMA-based systems
that leak client RDMA access patterns;
2The deﬁnition of accuracy throughout the paper is the percentage of
successful guesses over total guesses.
Figure 1: Attack Environment and RNIC Architecture.
The attacker and the victim are both clients that can access data in
the server machine’s memory throuth RDMA.
2. Reverse engineering of the most widely used RNIC hard-
ware architecture, which can be leveraged in designing
efﬁcient side channels;
3. Design, implementation, and evaluation of a set of Pythia
side-channel attacks, which are fast, accurate, and can
be launched solely from a separate machine across the
network;
4. A case study of Pythia in a real-world setting;
5. Discussion of possible mitigations, most of which are
uniquely applicable to RDMA systems.
Pythia is the ﬁrst work that explores side-channel vulnera-
bilities in RDMA and exploits the vulnerabilities to launch
attacks on RDMA-based datacenter systems. With today’s
datacenters all having robust defenses against direct snifﬁng
or hijacking of network trafﬁc, side channels are more feasible
attack mechanisms and we believe that our work raises seri-
ous security concerns in a young but already widely-adopted
network technology.
We have responsibly disclosed the weaknesses to Mellanox
and Crail. Our implementation of Pythia is publicly available
at https://github.com/Wuklab/Pythia.
2 Background on RDMA
2.1 RDMA Basics
Remote Direct Memory Access, or RDMA, is a network
technology designed to offer remote low-latency, low-CPU-
utilization access to exported memory regions. RDMA sup-
ports both one-sided and two-sided communication. One-
sided RDMA operations directly access memory at a re-
mote node without involving the remote node’s CPU, simi-
lar to DMA on a single machine. Two-sided RDMA opera-
tions involve both sender and receiver processing, similar to
send/recv in traditional network messaging.
694    28th USENIX Security Symposium
USENIX Association
Server MachineRDMA Network RNICSRAM Main MemoryCPUClient MachineAttackerClient MachineVictimQPMRPTEPCIePTEMRDataRDMA improves performance along several dimensions.
First, one-sided RDMA requests bypass the CPU of the re-
ceiver. Second, applications issue RDMA requests directly
from user space, bypassing kernel and avoiding kernel trap
cost. Third, RDMA avoids memory copying (a technique
called zero-copy). As a result, RDMA achieves low-latency,
high-throughput performance.
There are three implementations of RDMA: InﬁniBand
(IB) [10, 11], RoCE [8, 9], and iWARP [63]. All implemen-
tations follow the standard RDMA protocol [64]. Among
them, RoCE, or RDMA over Converged Ethernet, implements
the RDMA protocol over standard Ethernet (RoCEv1) and
UDP (RoCEv2), and is the preferred technology in existing
datacenters [32].
One-sided RDMA is the key area where signiﬁcant perfor-
mance and CPU utilization improvements over other network
technologies happen. Thus, we focus on one-sided RDMA. To
perform a one-sided RDMA operation, an application process
at a receiver node needs to ﬁrst allocate a consecutive virtual
memory space and then use the virtual memory address range
to register a memory region, or MR, with the RNIC. An appli-
cation can register multiple MRs over the same or different
memory spaces. The RNIC will assign a pair of local and re-
mote protection keys (called lkey and rkey) to each MR. This
application then conveys the virtual address of the MR and
its rkey to processes running on other nodes. After building
connections between these other nodes (senders) and the node
that the MR-registering application runs on (receiver), these
processes can use 1) a virtual memory address that falls in the
MR’s virtual memory address range, 2) a size, and 3) the rkey
of the MR to perform one-sided RDMA read and write. In
RDMA’s term, a connection is called a Queue Pair, or QP.
2.2 RDMA NICs
RDMA NICs, or RNICs, are where most RDMA functionali-
ties are implemented. They usually contain complex hardware
logic that implements the RDMA protocol and some SRAM
to store metadata, and they are often connected to the host’s
PCIe bus (allowing the card access to main memory through
DMA). Because of the need to bypass the kernel and re-
ceiver’s CPU, most RDMA functionalities and data structures
have to be ofﬂoaded to the RNIC hardware.
An RNIC’s on-board SRAM stores three types of metadata.
First, it stores metadata for each QP in its memory. Second,
it stores lkeys, rkeys, and virtual memory addresses for all
registered MRs. Third, it caches page table entries (PTEs) for
MRs to obtain the DMA address of an RDMA request from
its virtual memory address. RNICs have a limited amount
of on-board SRAM which can only hold metadata for hot
data. When the SRAM is full, an RNIC will evict its cached
metadata to the main memory on the host machine, and on a
future access, fetch the evicted metadata from the host main
memory back through the PCIe bus. The timing difference
between an RDMA access whose metadata is in RNIC SRAM
and one that is not is what we exploit in our side-channel
attack. The SRAM architecture is vendor-speciﬁc and not
disclosed or speciﬁed in the RDMA standard. We reverse
engineer the SRAM architecture of the state-of-the-art RNIC
in Section 4.4.
2.3 RDMA-Based Applications
RDMA was originally designed for high-performance com-
puting environments, and it has been a popular choice of
network system in these environments for the past two
decades [34, 44, 54]. In recent years, major datacenters and
public clouds adopted RDMA for its low CPU utilization and
superior performance. For example, Microsoft Azure [73]
and Alibaba [6] have deployed RDMA with RoCE at large,
production scale.
Many datacenter systems and applications have been ported
to or rebuilt with RDMA. These include in-memory key-
value stores [7, 24, 25, 40, 56, 57, 70], in-memory databases
and transactional systems [19, 83, 88], graph processing sys-
tems [68, 85], distributed machine learning systems [15],
consensus implementations [60, 80], distributed non-volatile
memory systems [45,67,93], and remote swap systems [5,31].
Most of these applications use both one-sided and two-sided
RDMA operations, with some being pure one-sided [14, 88].
Our work is applicable to all RDMA-based applications that
use one-sided RDMA (but not necessary purely one-sided).
3 Threat Model
In our attack, there are three parties: the server which hosts
data in its main memory for other client machines to ac-
cess (e.g., an in-memory database or an in-memory key-value
store), the victim who accesses the server’s in-memory data
through RDMA, and the attacker who tries to infer the vic-
tim’s accesses and access patterns. The attacker and the victim
are both normal clients that can access the data store service
the server provides, and they run on separate machines. Fol-
lowing the threat models of related work that introduces and
evaluates side channels, we assume that the attacker does not
have direct control over the victim. As victim and attacker ex-
ecute on different machines and communication to the server
happens through the network, we assume that the attacker
cannot observe the victim’s network packets (as otherwise,
the attacker could directly infer the accessed addresses and
values as RDMA is currently not encrypted). This assumption
is reasonable as snifﬁng victim’s packets would require an
attacker to have root access on either the victim’s machine
or the server’s machine [52, 72, 74] or to launch man-in-the-
middle attack to the network, both of which are well defended
in cloud datacenters. We also assume that the server can-
not directly observe memory accesses of either the victim
or the attacker as both victim and attacker interact with the
server through one-sided RDMA operations, not involving
the server’s CPU.
USENIX Association
28th USENIX Security Symposium    695
4 Side-Channel Attacks on RDMA
counters.
RDMA exposes node-internal memory to external hosts. Due
to best practices of optimizing accesses and caching, cur-
rent RDMA hardware is vulnerable to a variety of timing