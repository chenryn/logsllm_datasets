## 恭迎万亿级营销(圈人)潇洒的迈入毫秒时代 - 万亿user_tags级实时推荐系统数据库设计   
##### [TAG 15](../class/15.md)
### 作者                                                                       
digoal                                                                        
### 日期                                                                      
2016-12-25                                                                        
### 标签                                                                      
PostgreSQL , 标签 , 推荐系统 , 实时圈人 , 数组 , gin , gist , 索引 , rum , tsvector , tsquery , 万亿 , user , tag , 淘宝     
----                                                                      
## 背景    
**我们仅用了PostgreSQL的两个小特性，却解决了业务困扰已久的大问题。**    
推荐系统是广告营销平台的奶牛，其核心是精准、实时、高效。     
这么多广告平台，到底谁家强？谁的核心牛逼？      
1\. 精准，指对用户的描述精准，通常需要基于大量的用户行为数据，经历深度学习后形成的用户画像，或称之为标签系统。 标签的准确性关系到推荐的精准度，比如你可能不会对一个正常的年轻人推荐老花眼镜（当然如果有其他购买意向的标签来指出他有购买老花眼镜的欲望除外）。     
2\. 实时，指标签的更新实时性，很多标签是具有非常强的时效性的，比如一次营销的目标人群，又或者用户最近浏览的一些商品可能是有潜在购买欲望的商品，都具备时效性。如果你的标签生成是隔天，或者个很多天的，那么可能已经错过了推荐时机。因此实时性在推荐系统中是非常重要的。     
3\. 高效，指基于标签圈人的动作的效率与并发能力，作为购买广告的金主，当然是期望他们拿到数据的速度越快越好。并且会有很多人向你的平台购买广告，这考验的是并发能力。      
做到以上三点，这样的广告平台才具备一定的竞争力。     
除此之外还需要关注的是平台的成本，包括硬件的成本，开发成本，维护成本等。     
下面将以电商的推荐系统为例，介绍推荐系统的数据库设计与优化技巧。     
**以及如何让营销潇洒 (低成本，高并发，高效率) 的迈入毫秒时代**。   
## 电商推荐系统 部分需求介绍  
比如一家店铺，如何找到它的目标消费群体？     
要回答这个问题，首先我们需要收集一些数据，比如：      
1\. 这家店铺以及其他的同类店铺的浏览、购买群体。      
我们在逛电商时，会产生一些行为的记录，比如在什么时间，逛了哪些店铺，看了哪些商品，最后在哪家店铺购买了什么商品。       
然后，对于单个商店来说，有哪些用户逛过他们的商店，购买过哪些商品，可以抽取出一部分人群。      
2\. 得到这些用户群体后，筛选出有同类消费欲望、或者具备相同属性的群体。      
对这部分人群的属性进行分析，可以获得一个更大范围的群体，从而可以对这部分群体进行营销。       
以上是对电商推荐系统的两个简单的推理。     
![pic](20161225_01_pic_001.png)      
### 量级  
电商的用户量级，放眼全球，可能会达到几十亿的级别。      
店铺数量，放眼全球，可能会达到千万级别。      
商品数量（细分种类，比如条形码），放眼全球，可能会达到亿级。      
店铺标签数量，针对单个用户而言，逛了哪些店，多少次，看了哪些商品，多少次，买了哪些商品等。通常一个人，在一定的时间范围内，会产生上千的这样的标签。           
用户标签，画像，10万级别，这个量级可以描述清楚人的属性。     
根据以上的估算，user_tags可能达到万亿（user几十亿, 店铺\商品浏览相关的标签数千级别）的级别。      
## 高效设计  
## 数据库设计  
我们首先整理一下关键因素    
用户ID、浏览过的店铺 以及浏览次数、浏览过的商品 以及浏览次数、购买的商品 以及购买数量。(次数\数量 可以根据区间，设置为枚举类型，比如0表示100次以下，1表示100到500次，。。。)         
这几个要素很容易从用户的行为数据中生成，从而当某家店铺需要做推广，或者针对某个产品做推广时，可以结合这些因素，产生一批目标人群。     
比如1周内浏览护手霜相关商品超过10次的人群。     
### 表结构设计  
1\. 店铺、商品编成ID     
2\. 浏览过多少次、购买了多少某个商品        
由于每个用户在某个时间段内，都可能浏览或者购买多个店铺或商品。如果每个商店，每个商品都使用一条记录来存储，会产生很多很多的记录。浪费空间，并且影响查询效率。      
PostgreSQL 支持数组类型，可以很好的完成这样的任务，减少存储，同时支持数组索引，提高查询效率。     
3\. 表结构如下     
3\.1 范围表，约几十或上百条记录  
字段和描述  
```  
class int,    -- 维度,对应用户标签表的s1,s2,s3,s4
id int,       -- 偏移量(或者叫枚举值)    
description   -- 描述(例如 1-10000,10001-100000，。。。。。)    
```  
3\.2 用户标签表  
```  
uid int primary key,  -- 用户ID  
s1 int[],  -- 浏览过的店铺以及次数范围(店铺ID哈希 + 范围表id)     
s2 int[],  -- 浏览过的商品以及次数范围(商品ID哈希 + 范围表id)  
s3 int[],  -- 购买的商品以及数量范围(商品ID哈希 + 范围表id)
s4 int[],   -- ....其他维度以此类推 
时间区间1,   -- 比如按天, 每天统计一次，写入该表
```  
3\.3 次数阶梯化   
浏览次数，购买个数都是连续值，为了更好的进行挖掘，建议将其阶梯化。  
对应3\.1的设计，例如1-10000一个阶级，10001-100000又一个阶级。  
例子  
```
轨迹 s1 对应的阶梯
1 -> 0
2 -> 1-10
3 -> 11-100
4 -> 101-500
5 -> 501-
...
9 -> 10000+
```
3\.4 将（商品、店铺ID）与阶梯组合成一个新的值 - 方法1          
使用text[]例如 店铺ID:OFFSET 表示。text[]数组效率可能不如整型数组INT[]，空间也比INT[]要大一点。     
如果业务方可以容忍，使用text[]开发工作量小点。    
例子  
userid|s1|s2|s3   
1|{'1:2', '109:9'}|{'2:2', '88:19'}|{'2:1', '88:2'}
含义解释:  
- 用户ID：1，   
- 浏览了店铺1（次数阶梯=2）、店铺109（次数阶梯9），  
- 浏览了商品2（次数阶梯=2）、商品88（次数阶梯19），  
- 购买了商品2（次数阶梯=1）、商品88（次数阶梯2）。   
3\.5 将（商品、店铺ID）与阶梯组合成一个新的值 - 方法2       
方法1用了text数组，方法2将使用int/int8数组，效率更高。    
要使用一个int/int8新值表达两层含义(原始店铺、商品ID，以及阶梯)，需要公式支持。   
公式设计如下，(公式、常量)。    
以流量店铺次数(s1)字段为例：   
```
新值起始ID = new_start_val = 1                  -- 常量，用户可以自由指定，但是固定下来了就不要变它
对应维度步长(比如流量店铺的阶梯数) = step = 9   -- 常量，用户可以自由指定(每个维度的阶数可以不一样)，但是固定下来了就不要变它
店铺ID = dp_id                                  -- 指原来的店铺ID
int/int8新值 = new_val                          -- 生成的，带有两层含义（店铺ID，阶数）的新值
已知店铺ID求new_val(写入、查询过程):
$new_val = new_start_val + (step+1)*(dp_id-1)
已知new_val求店铺ID(翻译过程):
$dp_id = 1 + (new_val-new_start_val)/(step+1)
```
例子(step=19阶, new_start_val=1)  
```
浏览店铺ID=1，1阶
浏览店铺ID=192，15阶
根据以上信息、常量、公式 生成new_val数组:  
{1, 3821}
根据以上数组、常量、公式 翻译出店铺ID:  
{1, 192}
```
4\. 分区    
例如，建议每500万或1000万一个分区，查询时，可以并行查询，提高效率。     
如果要快速圈得所有的用户，建议使用并行查询（plproxy，每个分区一个连接，并行查询）。     
如果要快速的得到用户，流式返回，建议使用继承（如果是多节点，可以使用postgres_fdw+pg_pathman，或者postgres_fdw+继承），使用游标返回。     
### 性能指标  
几十亿用户，每个用户将时间区间的浏览过的店铺、商品、购买过的商品以及数量级聚合成标签化的数组，产生万亿级别的user_tags组合。     
根据tags从几十亿的用户群体中圈选人群，能达到什么样的性能呢？     
由于使用了索引，如果使用流式返回的话可以控制在10毫秒左右。      
是不是顿时觉得分析型的业务进入了毫秒时代？      
如果你对PostgreSQL接触不多，可能会感到很惊奇，接触多了就习惯了，PostgreSQL有很多功能会帮你解决很多问题，有时候甚至给你大开脑洞的。    