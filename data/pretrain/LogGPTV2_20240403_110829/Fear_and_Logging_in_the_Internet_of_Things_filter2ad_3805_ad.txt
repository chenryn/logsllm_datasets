IPC [54]
Ground Truth
nodes
edges
ProvSave
nodes
edges
7
23
19
14
173
34
10
6
7
18
7
7
15
6
14
13
12
29
9
28
61
14
19
29
29
91
8
27
17
13
168
31
10
5
5
29
5
5
15
5
11
13
13
31
8
31
59
14
16
25
33
81
7
23
19
14
173
34
10
6
7
18
7
7
15
6
14
13
12
29
9
28
61
14
19
29
29
91
8
27
17
13
168
31
10
5
5
29
5
5
15
5
11
13
13
31
8
31
59
14
16
25
33
81
Cov.
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
TABLE V: Average code instrumentation overhead for SmartApps
and Device Handlers. Performance improvement of ProvSave is
shown in parenthesis.
Type
SmartApp
Device Handler
34
27
Inst. Time (ms)
ProvFull
ProvSave
31 (91%)
25 (93%)
LoC Added
ProvFull
108
85
ProvSave
24 (22%)
16 (19%)
LoC
Vanilla
280
200
B. Instrumentation Performance
We benchmarked our instrumentation tool
in terms of
analysis time and Lines of Code (LoC) overhead. We applied
our tool to a corpus of 236 SmartApps averaging 280 LoC
each, and 132 Device Handlers averaging 200 LoC each. Our
evaluation results are shown in Table V. ProvFull has larger
instrumentation time and introduces more LoC as compared
to ProvSave, with ProvSave reducing the invasiveness of
instrumentation by 78% and 81% for SmartApps and Device
Handlers, respectively. This is because ProvFull instruments
extraneous instructions that do not relate to sources or
sinks. We note that the instrumentation is a one-time effort,
and also that in addition to the above LoC our tool appends
200 LoC for the Groovy Library that provides helper functions
for provenance generation and transmission (xV).
C. Runtime Performance
We next measured the cost imposed by provenance col-
lection on end-to-end event handling latency, which is the
time between an event handler receiving an event and reaching
the sink execution. For example, for an event handler which
sends a text message if motion is detected by a motion sensor,
the end-to-end event handling latency is the time between the
motion event is received and the time the message is delivered
to the user. We further divide end-to-end latency into SmartApp
computation (the time taken in executing the SmartApp event
handler code), Device Handler computation (time taken to
9
generate the command message to be sent to the physical
device), and sink execution (time taken to send the command
message from SmartThings cloud backend and for the physical
device to execute the command).
The SmartThings cloud IDE provides a simulator which
can model the behavior of physical devices with virtual de-
vices. In the experiment, we run our corpus of 236 Smar-
tApps within the simulator. To automate the test, we build
an automatic testing framework using Selenium [22] which
automatically install a SmartApp, set the preferences for the
SmartApp and generate all types of events (such as device
events and timer events). For each SmartApp, our testing
framework uses the fuzz testing approach to randomly feed
user inputs and generate all types of events in different order
to trigger all the event handling logic in the SmartApp. For
example, for the SmartApp in Figure 2, we generate both
lock and unlock event to trigger the eventHandler. Our
results are shown in Figure 9a. On average, ProvSave imposes
20.6% overhead on event handling (68 ms additional SmartApp
computation, 7 ms additional Device Handler computation)
compared to ProvFull’s 40.4% overhead. In addition to bench-
marking SmartApps on the simulator, we also evaluated two
events using physical devices: a SmartApp which strobes an
Aeon Labs Z-Wave Siren [12] if the gun case is moved, and a
SmartApp that sends an SMS to the user’s phone when power
consumption exceeds a threshold.5 We trigger both events 50
times and observe 5.3% and 4.5% total respective overhead for
ProvSave, compared to 13.8% and 8.7% overhead for ProvFull.
We conclude that our prototype already meets the efﬁcient
demands of real world deployment.
Storage Overhead. We determine the storage costs of
provenance collection by measuring log growth during our
runtime performance tests, shown in Figure 9b. At 168,000
events, ProvFull generated 219 MB of raw provenance, while
ProvSave generated just 89 MB of provenance, a 59% reduc-
tion. As a baseline, we compare these values to the event log
from the SmartThings IDE, which is in the format of “Date,
Source, Type, Name, Value, Displayed Text”. For the same
events, SmartThings event log took 29 MB raw data; while
ProvSave’s log is 3 times larger, the SmartThings log does not
track the causal relationships necessary to reconstruct attacks
and perform impact analysis. Moreover, a highly active IoT
user may generate just 500 events each day [3], which would
translate to just 260 KB storage cost for ProvSave. We thus
conclude that ProvThings imposes negligible storage costs.
D. Query Performance
Finally, we consider the speed with which ProvThings can
be queried. The ability to quickly query the provenance graph
is of critical importance when using ProvThings for online
monitoring of certain sequence of events. We evaluated query
performance using the Neo4j database. In the evaluation, we
issued a series of queries to the Provenance Recorder using
the query API deﬁned in xIV. For each node, we request
the ancestry of it to produce a provenance graph. The query
performance is shown in Figure 9c. For graphs with 2 million
nodes generated by ProvSave, the average query time for all
5Note that there are no Device Handlers for the SMS tests as SMS support
is provided by the SmartThings API.
)
s
m
(
y
c
n
e
d
t
a
n
L
e
-
o
t
-
d
n
E
g
n
i
l
d
n
a
H
t
n
e
v
E
  2 0 0 0
  1 5 0 0
  1 0 0 0
  5 0 0
  0
Si n k  e x e c.
S m art A p p  c o m p.
D e vi c e  H a n dl er  c o m p.
ProvFull
Save
Vanilla
Prov
2 3 6  S m art A p p s
ProvFull
Save
Vanilla
Prov
T h e  Sir e n  A p p
ProvFull
Save
Vanilla
Prov
T h e  S M S  A p p
( a)
E n d-t o- e n d e v e nt h a n dli n g l at e n c y o v er h e a d
( b)
Fi g. 9:
R u nti m e
O v er h e a ds f or
R a w  D at a ( P F)
R a w  D at a ( P S)
R a w  D at a ( A p p l o g)
  2 5 0
  2 0 0
  1 5 0
  1 0 0
  5 0
  0
)
B
M
(
t
s
o
C
e
g
a
r
o
t
S
  1
  0. 8
  0. 6
  0. 4
  0. 2
  0
y
t
i
s
n
e
D
e
v
i
t
a
l
u
m
u
C
All  N o d e s ( P F)
Si n k  N o d e s ( P F)
All  N o d e s ( P S)
Si n k  N o d e s ( P S)
  0
  2 0
  4 0
  6 0
  8 0
  1 0 0
  1 2 0
  1 4 0
  1 6 0