### Table V: Average Code Instrumentation Overhead for SmartApps and Device Handlers

| Type          | Inst. Time (ms) | LoC Added | LoC Vanilla |
|---------------|-----------------|-----------|-------------|
| **SmartApp**  |                 |           | 280         |
| ProvFull      | 34 (91%)        | 108       |             |
| ProvSave      | 31 (93%)        | 24 (22%)  |             |
| **Device Handler** |              |           | 200         |
| ProvFull      | 27 (91%)        | 85        |             |
| ProvSave      | 25 (93%)        | 16 (19%)  |             |

### B. Instrumentation Performance

We benchmarked our instrumentation tool in terms of analysis time and Lines of Code (LoC) overhead. Our evaluation was conducted on a corpus of 236 SmartApps, each averaging 280 LoC, and 132 Device Handlers, each averaging 200 LoC. The results are summarized in Table V.

- **ProvFull** has a larger instrumentation time and introduces more LoC compared to **ProvSave**.
- **ProvSave** reduces the invasiveness of instrumentation by 78% for SmartApps and 81% for Device Handlers.
- This is because **ProvFull** instruments extraneous instructions that do not relate to sources or sinks.
- The instrumentation is a one-time effort, and in addition to the above LoC, our tool appends 200 LoC for the Groovy Library, which provides helper functions for provenance generation and transmission.

### C. Runtime Performance

We measured the cost imposed by provenance collection on end-to-end event handling latency. This is the time between an event handler receiving an event and reaching the sink execution. For example, for an event handler that sends a text message if motion is detected by a motion sensor, the end-to-end event handling latency is the time between the motion event being received and the message being delivered to the user.

- **End-to-End Latency** is divided into:
  - **SmartApp Computation**: Time taken to execute the SmartApp event handler code.
  - **Device Handler Computation**: Time taken to generate the command message to be sent to the physical device.
  - **Sink Execution**: Time taken to send the command message from the SmartThings cloud backend and for the physical device to execute the command.

**Experiment Setup:**

- The SmartThings cloud IDE provides a simulator that models the behavior of physical devices with virtual devices.
- We ran our corpus of 236 SmartApps within the simulator.
- An automatic testing framework using Selenium was built to automate the test, which installs a SmartApp, sets preferences, and generates all types of events (e.g., device events and timer events).
- For each SmartApp, the testing framework uses a fuzz testing approach to randomly feed user inputs and generate all types of events in different orders to trigger all the event handling logic.

**Results:**

- On average, **ProvSave** imposes a 20.6% overhead on event handling (68 ms additional SmartApp computation, 7 ms additional Device Handler computation) compared to **ProvFull**'s 40.4% overhead.
- In addition to benchmarking SmartApps on the simulator, we evaluated two events using physical devices:
  - A SmartApp that strobes an Aeon Labs Z-Wave Siren if the gun case is moved.
  - A SmartApp that sends an SMS to the userâ€™s phone when power consumption exceeds a threshold.
- For these events, **ProvSave** had a 5.3% and 4.5% total respective overhead, compared to 13.8% and 8.7% for **ProvFull**.
- We conclude that our prototype meets the efficient demands of real-world deployment.

**Storage Overhead:**

- We determined the storage costs of provenance collection by measuring log growth during our runtime performance tests.
- At 168,000 events, **ProvFull** generated 219 MB of raw provenance, while **ProvSave** generated just 89 MB, a 59% reduction.
- As a baseline, the SmartThings event log, which does not track causal relationships, took 29 MB for the same events.
- A highly active IoT user may generate just 500 events each day, translating to only 260 KB storage cost for **ProvSave**.
- We conclude that **ProvThings** imposes negligible storage costs.

### D. Query Performance

Finally, we considered the speed with which **ProvThings** can be queried. The ability to quickly query the provenance graph is crucial for online monitoring of certain sequences of events.

- We evaluated query performance using the Neo4j database.
- In the evaluation, we issued a series of queries to the Provenance Recorder using the query API defined in xIV.
- For each node, we requested the ancestry to produce a provenance graph.
- The query performance is shown in Figure 9c.
- For graphs with 2 million nodes generated by **ProvSave**, the average query time was [insert specific values here].

**Note:** There are no Device Handlers for the SMS tests as SMS support is provided by the SmartThings API.

### Figures

**Figure 9:**
- **(a)** End-to-end event handling latency overhead
- **(b)** Storage overhead
- **(c)** Query performance

[Insert figures here]

This revised version aims to provide a clear, coherent, and professional presentation of the data and results.