Semantics detection. Since the general problem of de-
ciding whether one program is an obfuscated form of another
program is closely related to the halting problem, which in
general is undecidable [16], the presented algorithm uses the
following strategy to match the program to the template:
The algorithm tries to match (unify) each template node
to a node in the program. In case two matching nodes are
found, the def-use relationships in the template are evalu-
ated with respect to the program code.
If they hold true
in the actual program, the program fragment matches the
template.
Value preservation and NOP detection. The goal
of this analysis step lies in the detection of NOP operations,
i.e., program fragments that do not change the values of
the watched variables. The following strategies were im-
plemented by the authors in [3]: (i) Matching instructions
against a library of known NOP commands and NOP frag-
ments, (ii) symbolic execution of the code sequence with
randomized initial states, as well as (iii) two diﬀerent theo-
rem provers.
Resilience against the approach. As outlined by the
authors, the semantic-aware malware detection approach is
532Figure 2: Resilience against semantic-aware malware detection.
able to detect instruction reordering and register reassign-
ment as well as a garbage insertion. Furthermore, with re-
spect to the underlying instruction replacement engine, a
limited set of replaced instructions can be detected. How-
ever, this approach is not able to detect obfuscation tech-
niques using equivalent functionality or reordered memory
access. In Figure 2 we give an example of a code fragment
(left) that is matched to a template (center) and an obfus-
cated form (right) of the same fragment. The obfuscation
steps applied are ﬂagged with the letters (A) and (B). Note
that for reasons of simplicity, JMP instructions have been
omitted from the illustration.
Since our obfuscation technique does not work by insert-
ing NOP fragments, the direct detection and removal of NOP
elements has no impact on our approach. Nevertheless, we
use these mechanisms in the course of the matching algo-
rithm in order to check for value preservation. The seman-
tic detection relies heavily on the algorithm applying local
uniﬁcation by trying to ﬁnd bindings of program nodes to
template nodes. It is important to note that the bindings
may diﬀer at diﬀerent program points, i.e., one variable in
the template may be bound to diﬀerent registers in the pro-
gram, and the binding is therefore not consistent. The idea
behind this approach lies in the possibility to detect register
reassignments.
In order to eliminate inconsistent matches
that cannot be solved using register reassignment, a mecha-
nism based on def-use chains and value-preservation (using
NOP detection) is applied.
The local uniﬁcation used to generate the set of candidate
matches that is then reduced using def-use chains and value
preservation is limited by several restrictions. The following
two are the most important ones with respect to our obfus-
cation method: (i) If operators are used in a template node,
the node can only be uniﬁed with program nodes containing
the same operators and (ii) symbolic constants in template
nodes can only be uniﬁed with program constants. The ob-
fuscation pattern (B) in Figure 2 violates restrictions (i) and
(ii) as, e.g., the simple “+”-function is replaced by a MOV in-
struction followed by looping an XCHG instruction. The same
holds true for obfuscation pattern (C). In case of obfusca-
tion pattern (A) even the control ﬂow graph was changed as
the explicit jump instruction following the condition as well
as the condition itself are replaced by an assignment and a
LOOP instruction. Thus, the local uniﬁcation engine is not
able to match these program fragments to the respective
template fragments. In order to generate the set of match
candidates, the local uniﬁcation procedure must be able to
match program nodes with template nodes, relying on the
IR-engine to detect semantically identical program nodes
and to convert them into the same intermediate represen-
tation. However, authors state that “[...] same operation
[...] has to appear in the program for that node to match.”.
For example, an arithmetic left shift (eax = eax << 1)
would not match a multiplication by 2 (x = x ∗ 2) despite
these instructions being semantically equivalent. Therefore,
we can safely conclude that replacements with side eﬀects
as proposed in our concept would not match in the local
uniﬁcation as they do not use the same operations as the
original code for implementing a speciﬁc functionality.
One could argue that once the concept of covert compu-
tation is publicly known, malware detectors could simply
improve the hardware models on which the instruction re-
placement engine is based to be able to identify malicious
behaviors implemented in side eﬀects. While in theory, ev-
ery single aspect of the hardware could be mapped to the
machine model, we strongly believe that this is an unrealistic
assumption as increasing the level of detail and completeness
of the model is costly and reduces its practical applicability
A = const_addr1B = const_addr2condition(A) ?mem[B] = f(mem[A])A = A - cB = B + dC = 2TemplatetruefalseExample Instanceeax = 0x403000ebx = 0x400000edx = eax + 3eax != 0 ?mem[ebx] = mem[edx-3] << 2 + 1eax = eax - 4ebx = ebx + 1ecx = 2trueObfuscated Instanceeax = 0x403000ebx = 0x400000edx = eax + 3mem[ebx] = mem[edx-3] << 2 + 1ecx = 2xchg eax, esilodsxchg eax, esiecx = 4xchg eax, ecxloop -1falseBCecx = eaxloop 8A533in real-life malware detection scenarios, where the decision
on maliciousness has to be made in real time. A more com-
plex model also increases the complexity of the evaluation,
so the model has to be kept as general as possible, preventing
completeness in semantic-aware program analysis. Today’s
virus scanners as well as semantic-aware malware detection
concepts are not even able to cover the entire semantics of
side eﬀects-free code. Following the original argument of the
possibility of a complete model, mapping these semantics
should have been even more trivial. The second important
aspect is diversity. Christodorescu et al. [3] argue that a
malware author would have to “devise multiple equivalent,
yet distinct, implementations of the same computation, to
evade detection”. With covert computation we have shown
that side eﬀects in the microprocessor can be used to achieve
exactly this requirement.
5. CONCLUSION
In this paper, we have shown that the complexity of to-
day’s microprocessors, which support a myriad of diﬀerent
instructions, can be exploited to hide functionality in a pro-
gram’s code as small code portions. In the context of mal-
ware, we demonstrated that existing concepts for semantic-
aware malware detection systems are not able to analyze
the semantics of code that is implemented in side eﬀects
and argue that the indirectly shown incompleteness of ma-
chine models for semantic-aware malware detection raises
the threat of malware that exploits exactly this knowledge
gap. A successful implementation of the obvious mitigation
strategy – improving the models – is doubtful, as, while it
might be possible to map the side eﬀects of a speciﬁc in-
struction in the model, it would complex to evaluate the
impact of the side eﬀects of an entire sequence of instruc-
tions. Models are abstract representations of the real world,
which implies that some information is lost in its develop-
ment. The increasing complexity of the real world makes
it hard to design models that are strong enough to entirely
simulate the eﬀects of the code running on real hardware.
The obfuscator has an important advantage over code an-
alysts as he or she can make the code arbitrarily complex.
In contrast, analysts have to keep their models simple to
avoid an impractical level of complexity for testing whether
a given code matches a model for malicious behavior. Thus,
the feasibility of implementing a complete hardware model
for malware detection is an unrealistic assumption.
Acknowledgments
The research was funded under Grant 826461 (FIT-IT) and
COMET K1 by the FFG – Austrian Research Promotion
Agency.
6. REFERENCES
[1] B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich,
A. Sahai, S. Vadhan, and K. Yang. On the (im)
possibility of obfuscating programs. In Advances in
Cryptology—Crypto 2001, pages 1–18. Springer, 2001.
[2] M. Christodorescu and S. Jha. Testing malware
detectors. ACM SIGSOFT Software Engineering
Notes, 29(4):34–44, 2004.
[3] M. Christodorescu, S. Jha, S. Seshia, D. Song, and
R. Bryant. Semantics-aware malware detection. In
Security and Privacy, 2005 IEEE Symposium on,
pages 32–46. IEEE, 2005.
[4] C. Collberg and C. Thomborson. Watermarking,
tamper-prooﬁng, and obfuscation-tools for software
protection. Software Engineering, IEEE Transactions
on, 28(8):735–746, 2002.
[5] C. Collberg, C. Thomborson, and D. Low. A
taxonomy of obfuscating transformations. Technical
report, Department of Computer Science, The
University of Auckland, New Zealand, 1997.
[6] J. Crandall, Z. Su, S. Wu, and F. Chong. On deriving
unknown vulnerabilities from zero-day polymorphic
and metamorphic worm exploits. In Proceedings of the
12th ACM conference on Computer and
communications security, pages 235–248. ACM, 2005.
[7] B. De Sutter, B. Anckaert, J. Geiregat, D. Chanet,
and K. De Bosschere. Instruction set limitation in
support of software diversity. Information Security
and Cryptology–ICISC 2008, pages 152–165, 2009.
[8] R. Giacobazzi. Hiding information in completeness
holes: New perspectives in code obfuscation and
watermarking. In Software Engineering and Formal
Methods, 2008. SEFM’08. Sixth IEEE International
Conference on, pages 7–18. IEEE, 2008.
[9] K. Griﬃn, S. Schneider, X. Hu, and T. Chiueh.
Automatic generation of string signatures for malware
detection. In Recent Advances in Intrusion Detection,
pages 101–120. Springer, 2009.
[10] N. Idika and A. Mathur. A survey of malware
detection techniques. Purdue University, page 48,
2007.
[11] J. Kinder, S. Katzenbeisser, C. Schallhart, and
H. Veith. Detecting malicious code by model checking.
Detection of Intrusions and Malware, and
Vulnerability Assessment, pages 514–515, 2005.
[12] A. Moser, C. Kruegel, and E. Kirda. Limits of static
analysis for malware detection. In Computer Security
Applications Conference, 2007. ACSAC 2007.
Twenty-Third Annual, pages 421–430. IEEE, 2007.
[13] C. Nachenberg. Computer virus-coevolution.
Communications of the ACM, 50(1):46–51, 1997.
[14] M. Preda, M. Christodorescu, S. Jha, and S. Debray.
A semantics-based approach to malware detection. In
ACM SIGPLAN Notices, volume 42, pages 377–388.
ACM, 2007.
[15] M. Preda, M. Christodorescu, S. Jha, and S. Debray.
A semantics-based approach to malware detection.
ACM Transactions on Programming Languages and
Systems (TOPLAS), 30(5):25:1–25:53, 2008.
[16] A. Turing. On computable numbers, with an
application to the entscheidungsproblem. In
Proceedings of the London Mathematical Society,
volume 42, pages 230–265, 1936.
[17] S. Udupa, S. Debray, and M. Madou. Deobfuscation:
Reverse engineering obfuscated code. In Reverse
Engineering, 12th Working Conference on, pages
10–pp. IEEE, 2005.
[18] Z. Wu, S. Gianvecchio, M. Xie, and H. Wang.
Mimimorphism: a new approach to binary code
obfuscation. In Proceedings of the 17th ACM
conference on Computer and communications security,
pages 536–546. ACM, 2010.
534