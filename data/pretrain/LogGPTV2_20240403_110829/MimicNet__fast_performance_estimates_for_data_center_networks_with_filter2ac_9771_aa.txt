# Title: MimicNet: Fast Performance Estimates for Data Center Networks with Machine Learning

## Authors:
- Qizhen Zhang
- Kelvin K. W. Ng
- Charles W. Kazer
- Shen Yan
- João Sedoc
- Vincent Liu

### Affiliations:
- University of Pennsylvania
- Swarthmore College
- Peking University
- New York University

### Abstract:
Evaluating new innovations in data center networks at scale has become increasingly challenging, both in testbeds and simulations. This paper introduces MimicNet, a system that provides fast and accurate performance estimates for large data center networks. MimicNet combines the abstraction of packet-level simulation for a portion of the network with machine learning to approximate the behavior of the remaining, non-visible parts. This approach can provide over two orders of magnitude speedup compared to traditional simulations, while maintaining high accuracy (within 5% of true results) for key metrics such as tail FCT, throughput, and RTT.

### CCS Concepts:
- **Networks**: Network simulations, Network performance modeling, Network experimentation
- **Computing Methodologies**: Massively parallel and high-performance simulations

### Keywords:
- Network simulation
- Data center networks
- Approximation
- Machine learning
- Network modeling

### ACM Reference Format:
Qizhen Zhang, Kelvin K.W. Ng, Charles W. Kazer, Shen Yan, João Sedoc, and Vincent Liu. 2021. MimicNet: Fast Performance Estimates for Data Center Networks with Machine Learning. In *ACM SIGCOMM 2021 Conference (SIGCOMM '21)*, August 23–27, 2021, Virtual Event, USA. ACM, New York, NY, USA, 18 pages. https://doi.org/10.1145/3452296.3472926

## 1. Introduction
Over the years, numerous protocols and systems have been proposed to enhance the performance of data center networks [5–7, 12, 19, 33, 39]. While these proposals are innovative and promising, they face a common challenge: the difficulty of evaluating their performance at scale. Data center networks, which are highly interconnected and filled with dependencies, make it particularly challenging to assess the impact of small changes on overall performance.

Full-scale testbeds are prohibitively expensive to build and maintain. As a result, pre-production performance evaluation often relies on smaller, less representative setups, including:
- **Hardware testbeds** [47]: Provide full control but at a high cost.
- **Emulated testbeds** [43, 54, 56]: Model the network but struggle with scale and network effects.
- **Small regions of the production network**: Offer in-vivo accuracy but require a trade-off between scale and safety [48, 59].

Simulation was intended to address these issues by providing an approximation of network behavior at any scale. However, modern simulators struggle to handle large networks efficiently. For example, even for relatively small networks, packet-level simulation can be 3–4 orders of magnitude slower than real-time (e.g., 5 minutes of simulated time taking ∼3.2 days). Larger networks can take months or longer to simulate.

In this paper, we present MimicNet, a tool for fast performance estimation of large data center networks. MimicNet presents users with the familiar abstraction of a packet-level simulator but only simulates traffic to and from a single "observable" cluster. For the remaining clusters and traffic, MimicNet uses deep learning models and flow approximation techniques to estimate their effects.

### Key Contributions:
- **Architecture for composing Mimics**: A generative model of a full-scale data center network that can match ground-truth results much faster than traditional methods.
- **Customizable hyperparameter tuning**: Ensures optimality in both generalization and user-defined objectives.
- **Implementations and case studies**: Demonstrates the effectiveness of MimicNet across a variety of network protocols.

The framework is available at: https://github.com/eniac/MimicNet.

## 2. Motivation
Modern data center networks connect up to hundreds of thousands of machines, capable of processing hundreds of billions of packets per second. These networks achieve this through scale-out architectures, particularly FatTree topologies [4, 18, 50]. The size and complexity of these networks make testing and evaluating new ideas and architectures challenging.

Researchers have explored various approaches, including verification [15, 26, 27, 35, 57], emulation [52, 54, 56], phased rollouts [48, 59], and runtime monitoring [20, 58]. However, in this paper, we focus on pre-deployment performance estimation using simulation.

### 2.1 Background on Network Simulation
Popular simulation frameworks like OMNeT++ [34], ns-3 [42], and OPNET [1] operate at a packet level and use an event-driven model. These simulators offer several advantages:
- **Arbitrary scale**: Decoupling from hardware and timing constraints allows simulations of any number of devices.
- **Arbitrary extensions**: Full control over simulated behavior enables modeling of any protocol, topology, design, or configuration.
- **Arbitrary instrumentation**: Collection of any information at any granularity without impacting system behavior.

However, these simulators trade off varying levels of accuracy compared to bare-metal deployments. Despite this, prior work has shown their value in approximating real behavior [5, 6, 33, 46, 55].

### 2.2 Scalability of Today’s Simulators
Packet-level simulation is easy to reason about and extend, but simulating large and complex networks is often prohibitively slow. Discrete-event simulators serialize a distributed system into a single event queue, leading to poor performance as the network size increases.

**Parallelization** is a natural approach to improve simulation speed, but it is often inefficient for highly interconnected data center networks. Synchronization requirements and the need for frequent communication between processes can lead to decreased performance (see Figure 2).

## 3. Evaluation
Figure 1 shows the accuracy of MimicNet's Flow-Completion Time (FCT) predictions for various data center sizes, compared to flow-level simulation and small-scale simulation. MimicNet is 4.1× more accurate and up to two orders of magnitude faster than these alternatives.

MimicNet imposes a few carefully chosen restrictions on the system being modeled:
- **FatTree topology**
- **Predictable per-host network demand**
- **Congestion primarily on fan-in**
- **Independently managed host connections**

These assumptions allow for efficient simulation and accurate estimation while still being applicable to a broad class of data center networking proposals.

### 3.1 Operation
MimicNet operates as follows:
1. **Small-scale simulation**: Runs a simulation of a small subset of the larger data center network.
2. **Model training/tuning**: Uses the generated data to train a Mimic, which approximates the internal and cross-cluster behavior of the non-observable clusters.
3. **Full-scale approximation**: Composes a single observable cluster with \(N-1\) Mimic'ed clusters to form a packet-level generative model of a full-scale data center.

A hyperparameter tuning stage ensures optimality in both generalization and user-defined objectives, using metrics like FCT, RTT, and average throughput.

### 3.2 Results
For a network of a thousand hosts, MimicNet's steps take 1h3m, 7h10m, and 25m, respectively, while full simulation takes over a week. These results hold across a wide range of network configurations and conditions extracted from the literature.

### 3.3 Contributions
- **Techniques for modeling cluster behavior**: Using deep learning and flow-level approximation.
- **Scalability of accuracy**: Ensuring the ability to generalize to larger networks in a zero-shot fashion.

Compared to other evaluation techniques, MimicNet offers a significant speedup with minimal loss of accuracy, making it a valuable tool for pre-deployment performance estimation in data center networks.