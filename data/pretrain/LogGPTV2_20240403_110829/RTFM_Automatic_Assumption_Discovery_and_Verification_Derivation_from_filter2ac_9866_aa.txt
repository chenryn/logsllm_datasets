title:RTFM! Automatic Assumption Discovery and Verification Derivation from
Library Document for API Misuse Detection
author:Tao Lv and
Ruishi Li and
Yi Yang and
Kai Chen and
Xiaojing Liao and
XiaoFeng Wang and
Peiwei Hu and
Luyi Xing
RTFM! Automatic Assumption Discovery and Verification
Derivation from Library Document for API Misuse Detection
Tao Lv1,2, Ruishi Li1,2, Yi Yang1,2, Kai Chen1,2,∗
Xiaojing Liao3, XiaoFeng Wang3, Peiwei Hu1,2, Luyi Xing3
1SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China
2School of Cyber Security, University of Chinese Academy of Sciences, China
3Luddy School of Informatics, Computing and Engineering, Indiana University Bloomington
{lvtao,liruishi,yangyi,chenkai,hupeiwei}@iie.ac.cn,{xliao,xw7,luyixing}@indiana.edu
Abstract
To use library APIs, a developer is supposed to follow guidance
and respect some constraints, which we call integration assump-
tions (IAs). Violations of these assumptions can have serious conse-
quences, introducing security-critical flaws such as use-after-free,
NULL-dereference, and authentication errors. Analyzing a program
for compliance with IAs involves significant effort and needs to be
automated. A promising direction is to automatically recover IAs
from a library document using Natural Language Processing (NLP)
and then verify their consistency with the ways APIs are used in a
program through code analysis. However, a practical solution along
this line needs to overcome several key challenges, particularly the
discovery of IAs from loosely formatted documents and interpre-
tation of their informal descriptions to identify complicated con-
straints (e.g., data-/control-flow relations between different APIs).
In this paper, we present a new technique for automated assump-
tion discovery and verification derivation from library documents.
Our approach, called Advance, utilizes a suite of innovations to
address those challenges. More specifically, we leverage the obser-
vation that IAs tend to express a strong sentiment in emphasizing
the importance of a constraint, particularly those security-critical,
and utilize a new sentiment analysis model to accurately recover
them from loosely formatted documents. These IAs are further
processed to identify hidden references to APIs and parameters,
through an embedding model, to identify the information-flow re-
lations expected to be followed. Then our approach runs frequent
subtree mining to discover the grammatical units in IA sentences
that tend to indicate some categories of constraints that could have
security implications. These components are mapped to verification
code snippets organized in line with the IA sentence’s grammatical
structure, and can be assembled into verification code executed
through CodeQL to discover misuses inside a program. We imple-
mented this design and evaluated it on 5 popular libraries (OpenSSL,
SQLite, libpcap, libdbus and libxml2) and 39 real-world applications.
∗Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’20, November 9–13, 2020, Virtual Event, USA
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-7089-9/20/11...$15.00
https://doi.org/10.1145/3372297.3423360
Our analysis discovered 193 API misuses, including 139 flaws never
reported before.
CCS Concepts
• Security and privacy → Vulnerability scanners; • Software
and its engineering → Software safety.
Keywords
API misuse; Integration assumption; Verification code generation;
Documentation analysis
ACM Reference Format:
Tao Lv, Ruishi Li, Yi Yang, Kai Chen, Xiaojing Liao, XiaoFeng Wang, Pei-
wei Hu, Luyi Xing. 2020. RTFM! Automatic Assumption Discovery and
Verification Derivation from Library Document for API Misuse Detec-
tion. In Proceedings of the 2020 ACM SIGSAC Conference on Computer and
Communications Security (CCS ’20). ACM, New York, NY, USA, 16 pages.
https://doi.org/10.1145/3372297.3423360
1 Introduction
Today’s software is more composed than built, with existing pro-
gram components, even online services, being extensively reused,
often through integration of their Application Programming In-
terfaces (APIs). These APIs may only operate as expected under
some constraints (referred to as integration assumptions or IA in
our research), on their inputs (called pre-conditions, like a limit on
parameter lengths), outputs (called post-conditions, e.g., “return 1 or
0”) and invocation context (called context conditions, such as “must
be called from the same thread”), which their users should be aware
of. Although these IAs are typically elaborated in library documen-
tation, they may not be strictly followed by software developers,
as reported by prior studies [42, 44]. This affects the functionality
of the software using these APIs, and often comes with serious
security or privacy implications. As an example, setuid, which
temporarily carries a high privilege, is expected to drop its privilege
when its task is done, and failing to do so needs to be checked, as
indicated in the libstdc documentation “it is a grave security error
to omit to check for a failure return from setuid()”; this instruction,
however, has not been respected by PulseAudio 0.9.8, leading to a
local privilege escalation risk (CVE-2008-0008).
The fundamental cause of API misuse is that developers do not
follow the IAs of APIs in documents, which therefore becomes the
key sources for API misuse discovery. Prior research on API misuse
detection and API specification discovery [21, 30, 37, 41, 52] rely on
analyzing a set of code to infer putative IAs, so as to identify API
misuses. However, these IAs are often less accurate, introducing
significant false positives. In the meantime, the limited coverage
of the code set can also cause many real-world misuse cases to fall
through the cracks (Section 5.3).
Finding misuse from doc: challenges. Alternatively, one can
recover their IAs from documentation for a compliance check on
the software integrating them, which leverages more semantic in-
formation and therefore can be more accurate. Given the size of
today’s library documents (e.g., 327 pages for OpenSSL), manual
inspection becomes less realistic. Prior research seeks to automate
this process by inferring these assumptions using natural language
processing (NLP) [42, 44, 47]. Particularly, it has been shown that
for the well-formatted C# documents, a set of templates that specify
the relations between subject and object are adequate in recovering
IAs. This simple approach, however, no longer works well on less or-
ganized documents, like those for most C libraries, such as OpenSSL,
where IA descriptions can be hard to fit into any fixed templates:
as an example, we ran the code released by the prior research on
OpenSSL and only observed accuracy of 49% (Section 5.3). How to
effectively identify the API constraints from such documents turns
out to be nontrivial.
Also the challenge is to automatically analyze each IA and de-
termine a program’s compliance with the assumption. The prior
research maps a set of predicates on pre- and post-conditions to
formal expressions (e.g., “greater” to “>”) [44]. Less known is how
these predicates are selected and whether they are representative.
Most concerning is the missing of semantic analysis on context
conditions (except on API order [42, 54]), which can describe the
information flow relations (between calls or between the caller
and the callee) that must be established to avoid security or pri-
vacy fallouts. For example, the libpcap document describes how a
program should use two APIs pcap_close and pcap_geterr: “you
must use or copy the string before closing the pcap_t”. Here, the
references to pcap_geterr and pcap_close are implicit, through
natural language description (“close” and “pcap_t”), which spec-
ifies information-flow connections: one needs to use the output
of pcap_geterr (“string” in the IA) – a data flow, before running
pcap_close to terminate the handler pcap_t – a control flow. Viola-
tion of this IA could lead to a use-after-free bug (Figure 2). Discovery
and interpretation of such relations are by no means trivial.
Given the challenges in automatic IA discovery and semantic anal-
ysis on loosely organized library documents for the API compliance
check, so far we are not aware of any end-to-end solution that has been
applied to real-world software and led to the discovery of security-
critical bugs, particularly those never reported before.
Advance. Recent years have witnessed significant progress made
in machine learning and NLP (e.g., Gated recurrent unit (GRU) and
Attention) techniques, in terms of performance and effectiveness,
which potentially offers new means to address the challenges in
API misuse detection from library documentation. In this paper,
we report a new attempt to innovate over these new techniques,
which moves the state-of-the-art of IA discovery and compliance
check a step forward, enabling detection of security-critical API
misuse from real-world applications. Our technique, dubbed Ad-
vance (assumption discovery and verification derivation from the
document), is capable of automatically analyzing less organized C
library documentation to recover and interpret IAs and then trans-
lating them into verification code executed by CodeQL [4] to find
the API misuses in a program’s API integration. For this purpose,
Advance is designed to overcome the technical barriers mentioned
earlier, based upon several key observations. More specifically, we
found that with the diversity in the ways IAs are described, the
related sentences are characterized by a strong sentiment to empha-
size the constraints that API users are expected to follow: e.g., “the
application must finalize every prepared statement”; “make sure that
you explicitly check for PCAP_ERROR”; “it is the job of the callback
to store information about the state of the last call”. Such sentiments
cannot be easily described by templates but can be captured using
semantic analysis. In our research, we utilized a Hierarchical Atten-
tion Network (HAN) [51] to capture the sentences carrying such
a sentiment when the entities (API names, parameters) under the
constraint (as expressed by the sentiment) can be controlled by the
API caller (Section 3.2). This has been done by training a classifier
named S-HAN on 5,186 annotated data items, which is shown to
work effectively in inferring IA sentences from library documents.
Also discovered in our research is the pervasiveness of similar IA
components within a document and in some cases, across different
libraries. These components imply common assumption (constraint)
types for certain kinds of operations, which are often among the
most important and can be security critical. For example, “... is
not threadsafe”, an expression describing thread safety; “... must be
freed by...”, an IA asking for resource release – an operation with a
significant security implication. Leveraging this observation, our
approach automatically parses IA sentences into dependency trees
and runs frequent subtree mining [53] to discover the components
(called Code Descriptions or CDs, which are the smallest textual
description units that can be mapped to verification code snippets.)
for such common assumption types. Each of such assumptions is
then mapped to a verification code snippet (VCS) for building up the
complete verification code (VC), which may contain multiple VCSes
(Section 3.4). Our research shows that the discovered assumption
types cover 75% of CDs in the IAs (the column “CD-Cov” in Table 2).
To discover the context condition from an IA sentence, we cap-
italize on the observation that although the reference to an API
or its parameters can be implicit, its semantics must come close
to the description of its functionalities. For example, “closing the
pcap_t” represents the API pcap_close and pcap_t is from the
first parameter of pcap_geterr. Therefore, we trained a sentence
embedding model in our research to convert the components of
each IA sentence, as identified through shadow parsing, into vec-
tors, so as to compare their similarity with those generated from
the descriptions of different APIs (Section 3.2). In this way, not
only can we discover the implicit reference to APIs and parameters,
but we can also find out the data-flow (through parameters) and
control-flow (through invocations) relations among APIs that form
assumption types.
Discoveries. In our research, we implemented Advance on Stan-
fordCoreNLP [38], AllenNLP [26], TREEMINER [53] and CodeQL [4],
and further evaluated our prototype on the documentations of 5
popular libraries, including OpenSSL, SQLite, libpcap, libdbus and
libxml2. Our study shows that Advance can effectively identify IA
sentences, achieving an accuracy of 88% (on labeled dataset). Also,
our prototype successfully recovered over 69% of IAs.
Further running our prototype on 39 applications integrating
these libraries, including popular programs like wireshark, open-
vpn and ettercap (Section 5.4), our approach detected 193 instances
of API misuse, including 139 problems never reported before. So
far 16 of them have already been confirmed by the application
developers. Many of these cases are security-relevant, with 6 of
them documented by CVEs. These newly discovered API misuses
can lead to system crash (NULL-dereference), DoS attacks or in-
formation leakage (improper resource shutdown or release) . As
far as we know, this is the first time that an NLP-based end-to-end
API misuse system automatically captures new security bugs by
analyzing loosely organized documents. We will release the first
version of Advance through Github later1.
Contributions. The contributions of this paper are summarized
as follows:
• New technique. We developed a novel technique for automatic, end-
to-end IA discovery and verification code derivation. Our approach
addresses several key technical barriers that prior research fails
to overcome, including the use of sentiment analysis to recover
assumptions from loosely organized library documents, subtree
mining to identify the common operations related to the integration
assumption, and sentence embedding to detect implicit description
of information flows. These innovations enable a new end-to-end,
document-to-code analysis capability and contribute to the advance
of scientific research in this area.
• Implementation and discoveries. We implemented our technique
and open-sourced our prototype. The evaluation of our prototype
on popular libraries and real-world applications leads to the discov-
ery of 193 API misuses (most with significant security or privacy
implications), including 139 bugs never reported before. Such dis-
coveries have never been made automatically on loosely organized
API documents before, up to our knowledge.
2 Background
2.1 API Misuse
Software libraries often come with documentation that describes
how to use their APIs properly, under constraints. Failure to follow
such guidance can lead to API misuses, breaking the constraints
on API inputs (e.g., overlong input parameters), the usage of out-
puts (e.g., unchecked return value), and the context for API invo-
cations (e.g., inverse invocation sequence). Such misuses can have
serious consequences, affecting the functionality of the software
integrating these APIs, often with security or privacy implications,
such as memory leaks, denial of service through application crash,
etc. For example, most libraries require the application integrat-
ing their APIs to free allocated variables after its whole lifetime,
which is usually specified in the API documentation. If the appli-
cation fails to do so, a bug can be introduced (CWE-401: Missing
Release of Memory after Effective Lifetime), which will cause mem-
ory over-consumption, resulting in a denial of service (by crashing
or hanging the program). Despite the fact that such security-critical
1The release information is available at: http://kaichen.org/tools/Advance.html
constraints are described in the documentation, API misuse is still
one prevalent cause of software bugs [35].
2.2 NLP primitives
To analyze the library documentations, we leveraged a set of NLP
techniques in our research. They are briefly introduced here.
Dependency parsing. Dependency parsing is an NLP technique
to analyze the grammatical relations between the linguistic units
(words) in one sentence and extract the syntactic structure of this
sentence. As illustrated in Figure 4(a), in a dependency tree, the
verb of a clause structure is the root and the other linguistic units
are nodes linked by grammatical relations to the root. According
to the Stanford Parser manual [1], there exist approximately 50
grammatical relations. In our research, we utilize the AllenNLP
parser [26] to generate dependency trees for mining CDs.
Word embedding. A word embedding 𝑊 : 𝑤𝑜𝑟𝑑𝑠 → 𝑉 𝑛 is a pa-
rameterized function mapping words to vectors (200 to 500 dimen-
sions), e.g., 𝑊 (“𝑒𝑑𝑢𝑐𝑎𝑡𝑖𝑜𝑛”) = (0.2,−0.4, 0.7, ...), which captures a
word’s relation with other words in its context. Among the word
embedding methods, word2vec [40] is a state-of-the-art and com-
putationally efficient technique. Such a mapping can be done in
different ways, e.g., using the continual bag-of-words model and
the skip-gram technique to analyze the context in which the words
show up. Such a vector representation ensures that synonyms are
given similar vectors and antonyms are mapped to dissimilar vec-
tors. In our study, we utilized word2vec to generate semantic word
vectors from library documentation for the sentiment analysis.
Sentiment analysis. Sentiment analysis, also known as opinion
mining, is a technique using NLP and text analysis to identify, ex-
tract, and study the opinion and subjective information. One of its
main tasks is sentiment classification, which aims to classify the po-
larity of the text into positive or negative opinions. Recent research
focuses on leveraging Deep Learning (DL) classifiers for sentiment
classification. Popular off-the-shelf models include Text-CNN [32],
RCNN [34], and HAN [51]. In our research, we compared the effec-
tiveness of the aforementioned models and utilized a variance of
HAN in discovering the sentences with IA (Section 3.2).
3 Advance: Design
In this section, we elaborate on the design and implementation of
Advance – our technique for automatic assumption discovery and
verification code derivation. We first give an overview of the whole
design, its architecture and an example that shows how it works,
and then move onto its individual components.
3.1 Overview
Architecture. Figure 1 illustrates the architecture of Advance, in-
cluding three key components: IA discovery, IA dereference and
Figure 1: Architecture of Advance
LibraryDocumentApplicationCodeVC generationSatisfy?VCsIA discovery1MisusesIAsIA dereference 2IAs3VC generation, together with its workflow. Specifically, at step 1 ,
IAs are automatically discovered from the loosely structured API
descriptions in the documents, through an S-HAN-based classifier
that identifies IAs from the sentiments in the text. Then for each IA,
Advance replaces its implicit references to APIs or their parameters
with explicit ones (called IA dereference, step 2 ). For this purpose,