  * python3
  * sklearn
  * keras2.2.4
  * pands 0.22
  * numpy 1.15
###  0x01 DGA域名识别
首先将提供的pcap数据包进行处理，使其比较方便进行下一步的操作，这里进行的操作是选取数据包中有用的数据，将其保存为csv文件。采用和题目一类似的方式将数据提取出来。
在进行DGA域名识别时，从两个方面进行考虑：特征分类和先验经验。
**特征分类**
确定区分DGA域名与正常域名的原则：
DGA域名的特点是是大部分是随机生成的字符串，所以其可读性非常差，为了确定其可读性，我们这采用元音或辅音字母比例，在正常的单词中，为了更好的发音，元音和辅音存在配合关系，不会出现非常多的连续辅音或元音的情况；隐马尔科夫模型（HMM）计算字符串的转移概率；香农熵计算字符串的混乱程度。
考虑到域名避免与现有域名产生较多的碰撞，DGA域名选取的长度较长。
从DGA解析的角度出发，当感染主机运行DGA算法，并且尝试连接DAG域名时，其解析流量中会出现大量的`NXDomain`的解析响应，因为大部分的DGA域名都不会被解析到，之后攻击者在展开攻击后注册了某个域名，才会出现解析成功的响应。所以这里从解析主机和域名解析关联两方面入手分析，对于解析主机的解析行为特征，从主机解析的域名分布及解析类型考虑。对于域名解析关联，出发点是考虑该域名的解析情况，关注域名解析总数，解析该域名的ip总数，对应每个IP解析的数量，在解析过程中的响应类型，还包括流量中的transaction
id的数量，用于判断是否是重传。这里计算域名解析失败率，记录该域名在解析中失败的比例。
从上面的原则中最终确定的特征包括
特征名 | 含义  
---|---  
domain_len | 域名长度  
domain_entropy | 域名香农熵  
domain_consonants_ratio | 域名辅音比例  
domain_number_ratio | 域名数字比例  
hmm | 域名中字符的转移概率  
r_code | 响应类型  
domain_tld | 域名顶级域  
domain_ip_dal | 解析该域名的IP地址解析域名的平均长度  
number_qry | 解析该域名的IP解析域名总数  
number_res_a | 该IP解析请求中记录A的数量比例  
domain_ip_more | 该IP地址解析域名中大于平均长度的数量比例  
failed_ratio | 域名解析失败率  
max_consonants_ratio | 最长连续辅音比例  
vowel_ratio | 域名中元音比例  
hyphen_ratio | 域名中连字符比例  
unique_char | 域名唯一字符数  
ngrams_statics | 域名 n-gram 频率分布的统计特征，包括 均值，标准差，中位数，25% percentile，75%
percentile，最小值，最大值，n 取 1，2，3，故该特征最终为长度为21的向量  
在获取特征后，使用机器学习算法进行识别，这里采用`kmeans`聚类算法。
**先验经验**
对实验数据进行人工分析，利用已有知识进行数据筛选。
在对未响应域名的分析过程中，发现在未响应中存在一部分非DGA域名。如果存在一台主机反复请求一个域名，但该域名解析不成功，但从行为上看，其并不是DGA域名。另外还存在一些域名，在形式上与DGA域名非常相似，但其解析模式令人费解。如
`xmbdgkqvlbnrx.co.uk`,怀疑其并非是DGA域名，而是某IOT设备的域名。
对分类结果进行查看，发现其中存在一部分仅仅是字符串而不存在顶级域的解析域名，这明显并非是DGA域名。
根据观察发现和已有经验对识别结果做进一步的筛选。
###  0x02 DGA域名家族聚类
在通过第一步的识别获得DGA域名后，对其进行家族分类。
对于家族聚类，思路是利用主机关联性和域名特征相似性两方面综合考虑。
如果利用主机相似性进行聚类，不得不考虑的问题是：`在获得数据中，一台主机仅仅产生一种DGA还是会产生多中DGA`，这会影响到后面的聚类效果。
**域名字符串特征聚类**
仅利用域名本身存在的字符串特征进行聚类。
**基本思路** ：
>   * 同一家族的DGA域名在字符串特征上存在一定的相似性
>   * 直接聚类可能导致类内方差太大
>
考虑到如果直接聚合成大类效果可能不好，方法考虑先聚合成小类，再根据一些指标进行小类间的聚合，指标在下面介绍。
聚类算法采用的是`kmeans`算法，采用了47个特征。这里还利用`Xmeans`进行实验，以获得较好的初步聚类。
在合并指标的选择上首先考虑经常作为聚类评判标准的`silhouette_score`和`calinski_harabaz_score`,但是其是从数据的角度上进行考虑，可能对特定的问题的表现并不好。
考虑自定义的指标，首先对单个类别的评价，计算每类的方差，类内的IP重合度[对类内的每个ip计算其解析的域名，计算n个IP的解析重合度]，IP聚合程度[主要IP所占比例]。
考虑类合并的指标，两类的重合IP重要度[两类中重合IP部分在各自类比中所占的比重]，IP重合度[两种中重合IP的比重]，合并方差波动率[先考虑将两类进行合并，查看合并前和合并后的方差波动水平]。
缺乏实验依据，在类别合并方面没有找到可以有效表示其效果的显著性指标。
计算两类IP重合度，示例代码
    # 计算两类之间的相关程度
    def correlation_ip_cluster(c1,c2):
        #两类的ip重合度：
        # 重合ip域名重合度：从重合ip中其解析的域名数量，计算比例
        # 输入c1,c2为两个类别的数据
        # 输出为c1，c2中重合ip与ip并集的比例
        c1_ip_list = ip_list[c1.index]
        c1_list =  [i for inner in c1_ip_list.values for i in inner if type(i) != list]
        c1_list_sup =  [j for inner in c1_ip_list.values for i in inner if type(i) == list for j in i]
        c1_list.extend(c1_list_sup)
        c2_ip_list = ip_list[c2.index]
        c2_list =  [i for inner in c2_ip_list.values for i in inner if type(i) != list]
        c2_list_sup =  [j for inner in c2_ip_list.values for i in inner if type(i) == list for j in i]
        c2_list.extend(c2_list_sup)
        corr_ip = len(set(c1_list).intersection(set(c2_list)))/len((set(c1_list).union(set(c2_list))))
        return corr_ip
**基于主机关联性聚类**
**基本思路：**
>   * 不同主机请求相同的可疑域名，说明主机产生同类型的 DGA
>   * 一个域名集 被 一个主机集所共同查询，说明域名集属于同一类的可能性大  
>  **步骤：**
>
  1. 生成无响应域名 NXDomains 和产生无响应域名主机 NXHosts 的关联矩阵 M，矩阵行表示主机，列表示域名，矩阵的值 M _i,j_ 计算如下：  
  2. 计算相似矩阵 S
  3. 使用 PCA 对相似矩阵，进行降维
  4. 基于相似性矩阵，使用 KMeans，XMeans 算法进行聚类
**结果分析：**
使用 XMeans 算法，分成了40个类，很多类别数目过少，和仅使用域名字符特征进行 XMeans
算法进行聚类的结果一样，结果并不理想。因此进一步，考虑结合两种方法。
**强主机关联性聚类**
本方法考虑的首要因素是主机之间的关联性，假设一台主机只产生一种DGA，那么可以将某一台主机产生的域名分为同一个家族，同时在出现一个域名被多个主机解析的情况下，那么将另一台主机解析的域名同样归入此家族。
首先计算获得所有有关联的主机及其解析的域名，发现存在大部分主机之间是没有关联的，即没有与其他主机的域名产生重合。这种情况需要利用其他手段对单个主机的类别进行合并。
**利用`kmeans`聚类计算类别相似性**
在仅仅利用主机关联进行家族分类后，得到37个类别，其中大部分是单个主机的类别，需要将其合并至其他类别中。本方法利用`kmeans`产生的域名相似性进行二次聚类。
利用`kmeans`算法，使用域名字符串特征，对DGA域名进行不同类别数的多次聚类，这里选取的类别数是[3,20]。这样可以获得18个聚类结果，然后将之前进行主机关联获得的37个类别与18个分类结果中的每一个类别进行对比，计算每个类别的域名重合度，选取最大的域名重合定义为相关类别，然后将相关类别中的IP取出，得出相关IP。
例如：当n
取5时，`kmeans`得到5类，将主机关联获得的37个类别中的域名分别与5类中的域名进行比较，如果前者的第一类与后者的第三类的域名重合度最高，则将后者第三类的ip与前者第一类的ip记作为相关ip。
在获得了37类的每类的相关ip集合后，利用相关ip集合与原有类别的ip集合的重合度，将重合度高的类别聚合在一起。
例如，A类的相关ip集合为{1，2，3，4}，B类的ip集合为{3，4，5，6}，C类的ip集合为{2，3，4，8}，则A类和C类的重合度更高，则将A类和C类进行合并。
    # 计算主机ip关联类别和聚类类别的关联性，输出中具有主机关联类别之间的关联关系
    def ip_cluster_kmeans_k():
        connected_df = pd.read_hdf('./input/connected_df_2.h5')
        connected_df.drop(330,axis = 1,inplace = True)
        ip_set_list,ip_cluster = ip_cluster_func(connected_df)
        corr_ip_2_ip_pd = pd.DataFrame(np.array(ip_set_list).reshape([37,1]),columns=["iplist"])
        for i in tqdm(range(3,22)):
            feat_cluster = feat_cluster_func(i,connected_df)
            corr_ip_2_ip = ip_corr(ip_cluster,feat_cluster)
            corr_ip_2_ip_pd["cluster_{num}".format(num =i)] = corr_ip_2_ip
        com_c_list = []
        max_corr_list = []
        for i in corr_ip_2_ip_pd.values[:,1:]:
            max_corr = 0
            com_c = 0
            ip_c = pd.Series([k for j in i for k in j])
            ip_ser = ip_c.value_counts()
            ip_c_corr = set(ip_ser.index[ip_ser == ip_ser.max()])
            for j,ip_c_list in enumerate(ip_set_list):
                re_corr = len(ip_c_corr.intersection(ip_c_list)) / len(ip_c_list)
                if re_corr > max_corr:
                    max_corr = re_corr
                    com_c = j
            com_c_list.append(com_c)
            max_corr_list.append(max_corr)
        corr_ip_2_ip_pd["combination"] = com_c_list
        corr_ip_2_ip_pd.to_csv("combination_ip_feat_more_cluster.csv")
        return corr_ip_2_ip_pd
方向二最终得分：75
## 赛后反思
整体开来，能力建设团队专业性非常强，真正的做到应用数据说话，从数据中确定异常，而THUteam1和DeepDeer及我们本身都是利用足够的知识，针对性的对局部数据进行分析。
赛后看了前三名的writeup后，发现在大赛中的不足之处：
  * 某些点的分析不够透彻  
> 比赛中为脱敏数据可能对字符分布、语义、信息熵等造成影响
>
> 题目一和二中的攻击流量为人为构造，是纯净的攻击流量，在第二题的解题过程中忽视了这一点，导致开始方向出错
  * 对数据流量的整体认识不足  
> 在获得数据后，总是有主观的考虑，在这一点上，阿里云团队展现了非常强的专业性，从数据本身出发的方法更具泛化性
  * 对机器学习的认识太浅薄  
> 机器学习是一个工具，但并不是某个算法就可以解决全部问题，还需要增加对算法本质和广度的认识
  * 利用现有资源能力不足  
> 在题目二中，由于前期方向错误，浪费时间。但最大的问题其实是没有利用找到的公开数据。