vnode/object
vm_page
vm_page
encrypted
vm_page
vm_object
vm_page
vm_page
encrypted
vm_page
Fig. 5. Virtual memory structures for a process. Dark rectangles mark the possible
placements for EncExec.
table5. This essentially replaces all the reserved pages in the kernel map with
non-reserved pages. The kernel then switches to the new page table and continues
the booting process. To make sure that no reserved pages exist in this new page
table (except the DMAP area), we write a small kernel function to scan the new
page table for reserved pages. No reserved page was found in the new page table.
Eventually, the kernel adds the left-over physical pages to the run-time page
allocator (vm page startup in sys/vm/vm page.c). We hook into this function
and reserve pages as they are being added to the allocator. We also hook into
the kernel’s whole-cache ﬂushing function (wbinvd). By doing so, we can encrypt
the plaintext pages ﬁrst to prevent the unencrypted data from being leaked to
the memory. The CPU may temporarily power down a part of its caches in some
power management states. In our implementation, we disable the CPU power
management when EncExec is active and re-enable it otherwise.
3.2 Secure In-Cache Execution
With EncExec, the protected data remain encrypted in the memory; they are
loaded and decrypted into the reserved cache on demand. This essentially adds
another layer to the kernel’s demand paging: the memory serves as the backing
store for plaintext pages, while the swap partition services as the backing store
for the memory. EncExec manipulates the page table to desynchronize the cache
and the plaintext pages. FreeBSD’s virtual memory management has a unique
design that provides two alternative choices in the placement of EncExec.
Figure 5 shows the kernel data structures that manage the process address
space in FreeBSD. The top level structure, vmspace, represents the whole address
space. It is a container for other related structures. Two notable such structures
are vm map and pmap. FreeBSD separates the address space layout (vm map) from
the page table management (pmap). vm map describes the process’ virtual address
space layout using a list of vm map entry structures. Each vm map entry spec-
iﬁes a continuous block of the process’ address space, including its start and
5 The kernel uses 2 MB large pages to map its data. We break them down into 4 KB
pages ﬁrst.
Secure In-Cache Execution
393
end addresses and its permissions (read/write/execute). Each vm map entry is
backed by a chain of vm objects. A vm object describes the origin of the data
for this entry and the backing store to swap in and out the data. There are three
types of vm objects. Named vm objects represent ﬁles. Program sections like
the code and data sections use named vm objects because their initial contents
are loaded from the program binary. Anonymous vm objects represent sections
that are zero-ﬁlled on the ﬁrst use, such as uninitialized data sections and heap
sections. Shadow vm objects hold a private copy of the locally modiﬁed pages
(represented by vm pages). Every vm object has an associated pager interface
that decides how to swap in and swap out the object’s associated data. For
example, anonymous vm objects use the swap pager to store data in the swap
partition. The pmap structure consists of architecture-speciﬁc data and func-
tions to manage the process’ page table. Every CPU architecture deﬁnes its own
pmap structure but implements the common pmap API. As such, other kernel
modules do not need to be concerned with the details of page tables. Pmap can
decide when and how to map a page. For example, it can unmap a page from
the process’ address space as long as the page is not pinned by the upper vm
layers.
This design enables two feasible ways to implement EncExec in the FreeBSD
kernel: it can either be implemented as a shadow object or in the pmap module.
We chose the latter because it is simpler and more likely to be applicable to
other OSes (e.g., Linux). Speciﬁcally, a vm map entry can be backed by a chain
of vm objects. Objects ahead in the chain precede over these later in the chain.
When a page fault happens, the page fault handler searches for the faulting page
along the chain of vm objects. It returns the ﬁrst located page without checking
the rest of the chain. This chain of objects is essential to many features of
FreeBSD’s virtual memory design, such as copy-on-write where the kernel creates
a shadow object of the original one for both the parent and the child and marks
the original object read-only. If either process tries to modify a shared page, the
kernel makes a copy of the page and gives it to the corresponding shadow object.
This new copy overshadows the original shared page. EncExec can be similarly
implemented as a shadow object by using plaintext pages to store the data and
the original (non-reserved) memory as the backing store. However, this design
introduces additional complexity to the kernel’s already tangled virtual memory
system [20]. For example, EncExec’s shadow object should always be the ﬁrst
object in the chain, otherwise plaintext pages could be copied to vm objects
earlier in the chain and leaked to the memory. EncExec thus has to monitor any
changes to the object chain. If a new object is inserted before EncExec’s shadow
object, EncExec must move its object to the head of the chain. Reordering
objects is not supported by FreeBSD. Additionally, it is hard to apply this design
to other kernels that do not have a similar structure (e.g., Linux).
The pmap module also has the needed support for EncExec: by design, pmap
is allowed to unmap a page from the process’ address space as long as the
page is not pinned. The page fault handler will ask pmap to remap that page
if it is later accessed. Moreover, pmap maintains a reverse mapping for each
394
Y. Chen et al.
physical page, which keeps track of all the processes and virtual addresses a
physical page is mapped. EncExec uses reverse mapping to completely disconnect
a shared page from all the processes, otherwise some processes might incorrectly
access the encrypted data. Pmap also tracks the page usage information for page
replacement. EncExec can leverage this information to optimize its own page
replacement.
EncExec ﬁrst picks 15 reserved pages as the plaintext pages and unmaps all
the protected data from the process’ address space. If a page is shared by multiple
processes, EncExec removes it from other processes as well. EncExec then returns
to the user space to resume the process. When the process accesses its protected
data, a page fault will be triggered. The page fault handler searches its data
structures and asks pmap to map in the data (pmap map in pmap.c). EncExec
intercepts this request, allocates a plaintext page, decrypts the target page into
it, and maps it into the process. At any time, no more than 15 plaintext pages
can be used by the protected process. If more are needed, EncExec will pick a
plaintext page in use for replacement. In addition, the FreeBSD kernel might
proactively map-in (also called pre-fault) a page, expecting the process to access
it in the near future. No page fault will be triggered when the process accesses
this page later. In our prototype, we disable pre-faulting for the protected data
sections to save the limited plaintext pages. The process may also perform ﬁle
I/O with the protected memory. For correctness, we temporarily restore the
aﬀected pages and unmap them from the process’ address space. When these
pages are accessed by the user space again, page faults will be triggered. This
signals the end of the ﬁle I/O operation. We then re-enable the protection for
these pages.
4 Evaluation
In this section, we evaluate the security and performance of our EncExec pro-
totype. All the experiments were conducted on a desktop with a 3.6 GHz Intel
Core i7-4790 CPU and 16 GB of memory. The system runs 64-bit FreeBSD for
x86-64, version 10.2. To test its performance, we run various benchmarks in
the FreeBSD ports and the benchmarks of mbed TLS [2]. Mbed TLS, formerly
known as PolarSSL, is a popular, portable, open-source TLS library developed
by ARM.
4.1 Validation
We ﬁrst validate that we can actually desynchronize the cache and plaintext
pages. Theoretically, updates to the plaintext pages should be conﬁned to the
reserved cache because neither the kernel nor other processes can cause cache
conﬂicts with EncExec, and we never use more plaintext pages than the size of
the reserved cache. Consequently, the CPU should not evict the cached plaintext
pages. However, x86 does not provide instructions to directly query the cache
line status. To address that, we ﬁrst validate that none of the reserved pages are
Secure In-Cache Execution
395
used by the kernel or unprotected processes. Speciﬁcally, we write a simple kernel
function that scans a page table for reserved pages. We apply this function to all
the active page tables in the system. No reserved pages are found to be mapped
in these page tables, except plaintext pages in the kernel’s direct map area.
As mentioned before, we use direct map to encrypt/decrypt plaintext pages.
We also unmap plaintext pages from the direct map when EncExec is not in
use. If the kernel accesses any of these pages, a page fault will be triggered
and the kernel will crash itself. None of these happen during our experiment.
Moreover, we conduct an experiment to validate de-synchronization of the cache
and the plaintext pages. Speciﬁcally, we write all zeros to a plaintext page and
then execute the wbinvd instruction, which writes back the modiﬁed cache lines
and invalidates the internal caches. Now, the cache and the page have been
synchronized and the memory of this page is guaranteed to contain all zeros.
Next, we modify the plaintext page. Any changes should remain in the cache. To
check that, we discard the modiﬁed cache lines by executing the invd instruction
and read the plaintext page again. The plaintext page should contain all zeros.
This is indeed the case. It shows that the plaintext page and the cache have been
desynchronized.
Fig. 6. Overhead of common crypto-
graphic algorithms.
Fig. 7. Overhead of RSA and DH
handshakes.
Fig. 8. Overhead of Elliptic Curve
algorithms.
Fig. 9. Performance of Bonnie. The unit
on Y-axis is MB/sec and thousand-
seeks/sec (for RandomSeeks only).
396
Y. Chen et al.
4.2 Performance Evaluation
EncExec uses the hardware-accelerated AES (AES-NI) to encrypt and decrypt
data. Our measurements show that it takes about 3 µs on average to
encrypt/decrypt 4 KB data using 128-bit AES algorithm. Therefore, there is
an extra 3 µs or so delay to load a data page and 6 µs if it’s necessary to replace
an existing page. This delay is the most signiﬁcant source of EncExec’s overhead,
but it is hard to reduce this delay.
We use the oﬃcial benchmarks from mbed TLS to measure the performance
overhead of EncExec. These benchmarks consist of a wide range of cryptographic
algorithms. The results are presented in Figs. 6, 7, and 8. The overhead is cal-
culated relative to the baseline performance, i.e., the performance of mbed TLS
on the original FreeBSD system. The “mode 1” bars give the overhead of mbed
TLS protected by the ﬁrst mode of EncExec. Speciﬁcally, we modiﬁed the source
code of mbed TLS to allocate the session data and the stack from the secure
memory. The “mode 2” bars give the overhead of mbed TLS protected by the
second mode of EncExec, i.e., we protect all its data sections with EncExec. We
experimented with both 15 and 31 plaintext pages. In the latter, we changed our
prototype to double the reserved cache (32 pages, or 128 KB). This set of exper-
iments represents the most practical use cases of EncExec, given the limited size
of the reserved cache.
For simple algorithms like SHA-512 and AES, EncExec incurs virtually no
overhead (Fig. 6) because neither CPU nor the memory is a performance bot-
tleneck. Earlier systems like TRESOR [22] have similar or even slightly better
performance for AES. However, EncExec can support more complex algorithms,
such as RSA and Diﬃe-Hellman, due to its larger secure storage. For those algo-
rithms, mbed TLS in mode 1 and mode 2/31 pages only slightly lags behind the
baseline (about 2% slower), but its performance under mode 2/15 pages is sig-
niﬁcantly slower than the baseline. For example, it can only achieve about 8.4%
of the baseline performance for RSA-2048 public key encryption and 16.7% for
RSA-2048 private key encryption. This can be explained with the working set
model [25]. Clearly, the working set of these benchmarks is larger than 15 pages
but less than (or around) 31 pages. With only 15 plaintext pages, thrashing is
guaranteed, leading to poor performance. Mode 1 is not aﬀected by the large
working set because it only needs to protect the selected data, instead of all the
data sections. Nevertheless, many real-world programs have very large working
set. EncExec’s second mode is thus more suitable for compact programs, such
as an encryption/decryption service program.
We also measured the impact of EncExec on other concurrently running
processes. Speciﬁcally, we run bonnie, a ﬁle system benchmark, twice, once alone
and once while the mbed TLS benchmark is running (mode 2/15 pages). The
results are shown in Fig. 9. These two runs have almost identical performance
for most of the six tests except the third one: the concurrent run is about 43%
slower. This overhead likely is not caused by EncExec but instead the result of
the kernel’s scheduling algorithm: both benchmarks have very low initial CPU
usage. It is likely that they will be scheduled to run on the same CPU core.
Secure In-Cache Execution
397
When bonnie is running its third test, the mbed TLS benchmark starts to run
the RSA-related tests and uses more than 80% of the CPU. Temporarily, the
mbed TLS benchmark preempts bonnie and degrades its performance. This is
supported by the fact that bonnie uses 19.9% of the CPU time in the single
run for this test, but it only receives 11.1% of the CPU time in the concurrent
run. In the following tests, bonnie uses more than 100% of the CPU time and
will be scheduled to a diﬀerent CPU core than the mbed TLS benchmark. The
performance of the mbed TLS benchmark remains mostly the same. To verify
this hypothesis, we simultaneously run bonnie and the mbed TLS benchmark
without EncExec. The similar results are observed a little bit earlier than the
concurrent run with EncExec. This is because the mbed TLS benchmark runs
faster this time. Overall, this result is not surprising: a process protected by
EncExec and other processes cannot interfere with each other through the L3
cache, but they can still interact through the L1 and L2 caches if they are
scheduled to the same core. Meanwhile, there is no interference through the
cache if they are scheduled to diﬀerent cores because each core has its own
L1 and L2 caches. This strong performance isolation makes EncExec a more
practical defense against cold boot attacks.
5 Discussion
In this section, we discuss some potential improvements to EncExec and related
issues.
Impact on L1 and L2 Caches: EncExec controls all the physical pages cached
by the reserved cache. This allows EncExec to precisely control the replacement
of the reserved cache. These pages are also cached by the L1 and L2 cache. This
naturally raises the question of whether EncExec reserves some of the L1 and
L2 cache, as an side eﬀect. L1 and L2 caches are critical to the overall system
performance as they are smaller, faster, and closer to CPU cores. Reserving