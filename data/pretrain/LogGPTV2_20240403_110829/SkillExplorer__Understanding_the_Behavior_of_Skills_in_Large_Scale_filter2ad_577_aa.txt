title:SkillExplorer: Understanding the Behavior of Skills in Large Scale
author:Zhixiu Guo and
Zijin Lin and
Pan Li and
Kai Chen
SkillExplorer: Understanding the Behavior of 
Skills in Large Scale
Zhixiu Guo, Zijin Lin, Pan Li, and Kai Chen, SKLOIS, Institute of Information 
Engineering, Chinese Academy of Sciences, China; School of Cyber Security, 
University of Chinese Academy of Sciences, China
https://www.usenix.org/conference/usenixsecurity20/presentation/guo
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.SkillExplorer: Understanding the Behavior of Skills in Large Scale
Zhixiu Guo1,2, Zijin Lin1,2, Pan Li1,2, and Kai Chen∗1,2
1SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China
2School of Cyber Security, University of Chinese Academy of Sciences, China
Abstract
Smart speakers have been popularly used around the world
recently, mainly due to the convenience brought from the vir-
tual personal assistant (VPA) which offers interactive actions
through the convenient voice commands from users. Besides
the built-in capabilities, VPA services can be further extended
by third-party developers through skills. Similar to smart-
phone applications on Android and iOS markets, skills are
also available on markets (e.g., Amazon, Google), attracting
users together with malicious developers. Recent researches
discover that malicious developers are able to route users’
requests to malicious skills without users’ consent by creating
skills with similar names of legitimate ones. However, to the
best of our knowledge, there is no prior research that system-
atically explores the interaction behaviors of skills, mainly
due to the challenges in handling skills’ inputs/outputs which
are in the form of natural languages. In this paper, we pro-
pose the ﬁrst systematic study on behaviors of skills, which is
achieved by a suite of new grammar-based techniques includ-
ing utterance extraction, question understanding, and answer
generation speciﬁcally designed for skills. We build an inter-
active system called SkillExplorer and analyze 28,904 skills
from the Amazon market and 1,897 actions from the Google
market. Among these skills, we ﬁnd that 1,141 skills request
users’ private information without following developer speci-
ﬁcations, which are actually demanded by markets. 68 skills
continue to eavesdrop users’ private conversations, even after
users have sent the command to stop them.
1 Introduction
Smart speakers have been widely used around the world re-
cently, mainly due to the convenience brought from the inte-
grated virtual personal assistant (VPA) that offers interactive
actions. Merely through voice commands of users, the VPA
can be activated and respond to users’ commands such as
∗Corresponding author.
providing information like weather and news, playing music,
making phone calls, and even controlling other smart devices
such as smart lights and thermostats. Besides the built-in capa-
bilities, VPA services can be further enhanced through ecosys-
tems offered by their providers, where third-party developers
can teach VPAs new abilities (called skills by Amazon or ac-
tions by Google1). Through such skills, users’ activities can
be extended such as placing orders, communicating in social
networks, and playing games, which attract tens of millions
of users, and in turn attract more developers. According to a
recent report [1], over 100,000 skills are on the Amazon mar-
ket, which is 20,000 more than the number at the beginning of
2019; and over 19,000 actions are on the Google market [2].
However, with the rapid development of skills, dangerous
skills also appear. According to recent studies [26, 35, 36],
some skills can route users’ requests to malicious applications
without their consent by creating skills with similar names of
legitimate ones (e.g., the same or similar pronunciation but
different spellings of skill names, like “Full Moon” v.s. “Four
Moon”).
Although the invocation of skills is recently studied to lo-
cate dangerous skills, less is understood about the contents
provided by skills, or the behaviors of a skill. Actually, dan-
gerous skills may eavesdrop users’ privacy or even monitor
users’ conversations inﬁnitely [26]. For example, according
to a recent report [3], an attacker can create a malicious skill
to read an unpronounceable sequence. During this period,
the speaker remains silent but still active, which allows the
malicious skill to fully capture users’ conversations. Even
more, the malicious skill can pass through the strict vetting
process of Amazon and Google, and is ready on the store
waiting for victim users. To the best of our knowledge, there
is no prior research to systematically explore the behaviors of
skills, mainly due to the following challenges.
Challenges. C1: Fully black-box. Different from exploring
behaviors of an application (e.g., an x86 binary with or with-
1In this paper, we use skills to describe the abilities including Google’s
actions.
USENIX Association
29th USENIX Security Symposium    2649
out source code, or an Android application), a skill is a kind of
web services, which is fully black-box to the analyzer. What
the analyzer can only do is to send inputs to the skill and
observe its responses. No inner states of the skill could be
gained to facilitate the analysis process. As a result, it is hard
to determine whether the behaviors of a skill have been fully
explored. Sometimes, even if an input is accepted by a skill
and a valid answer is given, it seems difﬁcult to tell whether
another input can trigger different behaviors of the skill. Also,
without the complete understanding of the inner states of
a skill (e.g., branches), it seems impossible to optimize the
strategy to explore a skill’s behaviors.
C2: Inputs/outputs of skills are in the form of natural lan-
guages. To explore the behaviors of a skill, the analyzer should
understand the questions from skills and sort out certain an-
swers in natural languages. The validity of inputs (i.e., an-
swers in natural languages) is self-designed by various de-
velopers, which means that the generated inputs should be
consistent with the designs of speciﬁc skills. Even for similar
questions from different skills, the generated answers may be
quite diverse. A conversational system (e.g., a chatbot) could
be one of solutions to explore the behaviors of skills. How-
ever, the questions may not be well understood by existing
conversational systems. For example, “To check out our new
features, try saying what’s new or help.”, the famous chatbot
Mitsuku [4] will answer “The obvious one”. Besides the prob-
lem of understanding questions, generating valid answers is
also highly challenging.
Our approach. To understand the skills in the markets, we
develop a novel technique called SkillExplorer to explore the
behaviors of a given skill and identify the suspicious ones.
A suite of grammar-based approaches are designed to solve
the unique problems encountered where natural language is
the sole way for communication, including generating the
initial input, understanding the questions (i.e., outputs) from
skills, and generating the valid inputs. Besides, to make the
inputs be able to trigger various behaviors of skills, we build a
knowledge database containing multiple personal proﬁles that
are automatically collected from the Internet. The full process
of exploration is recorded and further utilized to increase
efﬁciency.
Speciﬁcally, to initialize the dialog with a given skill, the
ﬁrst input should be carefully chosen. Based on the observa-
tion that the developer usually gives sample inputs (called
sample utterances) on the introduction page of the skill in
the market, hoping her skill to be easy to use, SkillExplorer
analyzes the introduction page and extracts suitable inputs
to initialize the dialog. After the target skill receives the ini-
tial input and gives the outputs, SkillExplorer will parse the
outputs (questions) and further classify them into ﬁve ba-
sic types including Yes/No questions, Instruction questions,
Selection questions, Wh questions and Mix questions. For
some types (e.g., the question like “To check out our new fea-
tures, try saying what’s new.”), the afterward valid responses
can be extracted directly from the questions (referred to as
explicit questions); while for other questions like “What’s
your phone number?” (referred to as implicit questions), the
answers cannot be directly extracted. In particular, for the
explicit questions, SkillExplorer enumerates all the valid an-
swers from the corresponding questions and feeds them to
the skill; for the implicit questions, SkillExplorer identiﬁes
those related to privacy and chooses suitable answers from a
knowledge database which is pre-built by collecting different
users’ proﬁles from the Internet. In this way, by continuously
repeating the procedures of parsing questions and answering,
SkillExplorer can communicate with the target skill, and fur-
ther to explore its behaviors. After the behaviors are explored,
we will further check whether the questions from the target
skill can impact users’ privacy. Note that, to increase the efﬁ-
ciency of behavior exploration, we design an i-tree to record
the status of exploration and let SkillExplorer quickly execute
a branch question.
Findings. Beneﬁt from the automatic exploration, we are
able to analyze the behaviors of 30,801 skills (28,904 from
the Amazon market in America and 1,897 actions from the
Google market), whose scale has never been achieved be-
fore. Such a large-scale analysis gives us a unique chance
to understand the behaviors of skills and their developers.
From the results, we ﬁnd 1,141 skills request users to provide
personal information (e.g., mobile phone number, name, ad-
dress, etc.) without following developer speciﬁcations (e.g.,
different from their claims in privacy policy pages or without
conﬁguring permissions, etc.). We also ﬁnd that 68 skills
continue to eavesdrop user’s private conversations after users
send commands to stop them.
Contributions. The contributions of the paper are as follows:
• A systematic study on skills’ behaviors on a large scale. We
propose the ﬁrst systematic study on the behaviors of skills,
which is achieved by a suite of new grammar-based tech-
niques including utterances extraction, question understand-
ing, and answer generation speciﬁcally designed for skills.
The techniques have evaluated 28,904 skills from the Ama-
zon market and 1,897 actions from the Google market, a
scale that has never been achieved before for analyzing skills’
behaviors.
• New ﬁndings. Besides a good number of suspicious skills
found in our study, we also have the unique chance to observe
the suspicious behaviors of skills on a large scale, and together
with the understanding of their developers. Such understand-
ings could not only help the administrators of the markets for
better vetting skills but also shed new lights to develop new
techniques to efﬁciently detect malicious skills2.
2We have sent our veriﬁed ﬁndings to the markets and are waiting for
their response.
2650    29th USENIX Security Symposium
USENIX Association
2 Background
2.1 Skill and Restrictions in Development
Skill and the ecosystem. The VPA is a software agent that
provides services for a human individual by following his
voice commands. Especially, with the rapid development of
IoT devices such as smart speakers (e.g., Alexa Echo, Google
Home), VPAs are popularly integrated into these devices for
better user experience in controlling. Besides the built-in func-
tionalities offered by the VPAs, the capabilities can be further
extended through the ecosystem offered by their providers,
which are called skills by Amazon (or actions by Google).
Actually, the providers encourage third-party developers to
build their own skills, serving as add-on functionalities to
VPAs, just like the ecosystem of mobile applications (e.g.,
Android markets and the Apple market). Similarly, developers
publish their skills on the market, including the invocation
names, authors, descriptions, etc. For users, they ask their
smart speakers to request services from skills. For example,
as shown in Figure 1, a user asks “Alexa, ask Plan My Trip
to plan a trip from Seattle to Portland on Friday”. Alexa
will send the audio stream to its cloud server Amazon Web
Services (AWS) to parse the audio and determine the most
suitable skill to respond to the request. In this case, the skill
“Plan My Trip” is explicitly invoked and will receive the user’s
request in texts parsed by AWS. Then it generates the answer
and sends it back to Alexa, which will speak out the answer at
the user’s side. The user can also request services from skills
in an implicit way. For example, he can say something like
“Alexa, i want to visit Portland” and Alexa will choose the
most suitable skill that fulﬁlls the request.
Although skills are very close to mobile applications, they
have essential differences. One main difference is the way
to request the services: voice commands for skills and click
operations for mobile apps. The second difference is that users
do not need to install skills on smart speakers (instead, they
use a combination of phrases and invocation name supported
by the Alexa service such as saying “Alexa, open XXX” to
automatically enable a skill).
Figure 1: Overall workﬂow of interacting with skills
Restrictions in development. When a developer publishes a
skill, he must follow the rules provided by the markets (e.g.,
Amazon or Google), which is also similar to publishing mo-
bile applications. For Amazon, the basic information which
he should provide includes invocation name, a cloud-based
service, intents, and sample utterances. Details are shown in
Appendix A. For example, the skill “Plan My Trip” has an in-
vocation name “plan my trip”. It uses the AWS Lambda cloud
to execute the user’s requests. Intent “PlanMyTrip” is used to
fulﬁll requests such as the utterance“Alexa, ask Plan My Trip
to plan a trip from Seattle to Portland on Friday”. Besides
the basic information, the developer must also follow some
restrictions from the markets. Especially, if a skill requests
personal information, it should provide the privacy policy
link to Amazon [5]. The markets have their requirements for
privacy policies which describe the outline of collected infor-
mation from users and ways to use and share them. During
the developing process, Amazon stipulates that if a skill wants
to obtain users’ information such as the name, phone number,
email, home address, and so on, it must include a link to the
privacy policy that applies to the skill. It also needs to con-
ﬁgure permissions so that when users enable this skill, they
can agree or deny authorization to provide such information
to the skill [6]. Such fulﬁllment will be carefully checked by
the markets before releasing the skill to the public.
2.2 Researches on the Security of Skill
Until very recently, only a few researches have been carried
on skills, which are mainly limited to the invocation mech-
anism of skills. KUMAR et al. [26] and Zhang et al. [35]
ﬁnd that a malicious skill could be mistakenly invoked by
a user without her consent due to similar pronunciations be-
tween the skill and the legitimate ones (e.g., “Boil an Egg”
v.s. “Boyle an Egg”). Zhang et al. [36] ﬁnd that the natural
language understanding’s classiﬁer of a VPA could divert a
user’s request to a malicious skill due to improper semantic
interpretation of the request. In October 2019, researchers
from SR Labs implement two attacks on VPAs [3]. One is to
develop a malicious skill to camouﬂage as the VPA, asking for
users’ private information such as their password. The other
attack is to let a malicious skill eavesdrop users’ conversation,
even if it has received users’ voice command to exit. We also
identify such a situation and ﬁnd that 68 skills having similar
behaviors are still alive in the Amazon market, which has not
been discovered before.
2.3 Conversational System
To explore the behaviors of a skill, one may consider using
conversational AI systems. However, current conversational
AI systems are not suitable for this task. According to a recent
survey [25], there are three types of existing conversational
systems. QA agents are often used to answer domain-speciﬁc
questions or to search for answers from open knowledge sys-
tems (e.g., Wikipedia). Task-oriented dialogue agents are used
to perform a series of tasks or services for users such as busi-
ness trip planning whose input content needs to meet a cer-
tain format to be understood. A chatbot’s response content
is usually a combination of statistical methods and manual