[8]G. F.Cret¸u-Ciocˆarlie, M.Budiu, and M.Goldszmidt.Hunting for problems with Artemis.In First USENIX Workshop on Analysis of System Logs（WASL’08），San Diego, CA, December 2008.
[9]Y. Yu, M.Isard, D.Fetterly, M.Budiu, U.Erlingsson, P.Gunda, and J.Currey.DryadLINQ：A system for general-purpose distributed data-parallel computing using a high-level language.In 8thUSENIX Symposium on Operating Systems Design and Implementation（OSDI'08），San Diego, CA, December 2008.
[10]R. Van Renesse, K.Birman, and W.Vogels.Astrolabe：A Robust and Scalable Technology for Distributed System Monitoring, Management, and Data Mining.ACM TOCS，21（2）：164-206，2003.
[11]R. Huebsch, J.Hellerstein, N.Lanham, B.Loo, S.Shenker, and I.Stoica.Querying the Internet with PIER.Proceedings of 19th International Conference on Very Large Databases（VLDB），pages 321-332，2003.
[12]M. Massie, B.Chun, and D.Culler.The Ganglia Distributed Monitoring System：Design, Implementation, and Experience.Parallel Computing，30（7）：817-840，2004.
第18章 Hadoop的常用插件与开发
本章内容
Hadoop Studio的介绍和使用
Hadoop Eclipse的介绍和使用
Hadoop Streaming的介绍和使用
Hadoop Libhdfs的介绍和使用
本章小结
18.1 Hadoop Studio的介绍和使用
 18.1.1 Hadoop Studio的介绍
Hadoop Studio是一个加快Hadoop开发进程的可视化开发环境。Hadoop Studio通过降低Hadoop的使用复杂度，让用户在更少的步骤内完成更多的事情以提高效率。Studio有专业版和大众版两个版本，大众版仅需要注册就可以获得，本章介绍的Studio都指大众版Studio。用户可以通过Hadoop Studio强大的GUI部署Hadoop任务，并监控Hadoop任务的实时信息。它主要有以下优点：
简化并加快了Hadoop任务模型建立、开发和调试的进程。
能够实时地定义、管理、可视化和监视作业、集群和文件系统等；能够查看任务的实时工作情况；能够让用户通过观察输入输出和中间结果的工作流程图来管理任务的执行时间。
具有很强的移植性，能够被部署在任何操作系统和任何版本的私有或公有Hadoop云系统上，且服务能通过代理服务器和防火墙而不受影响。
Hadoop Studio的优点决定了无论用户是只有极少MapReduce或Hadoop开发经验的Java程序员，还是熟练的并行程序开发者，它都能简化用户的工作，提高其工作效率。而这主要是从设计、部署、调试和可视化四个方面来实现的。
1）设计：由于Studio能够仿真Hadoop系统，所以用户初期建立MapReduce任务模型时就不需要真正的集群，这可以帮助用户迅速上手。
2）部署：无论用户使用的是私有网络内的集群还是公共网络上的集群，Studio都能简化用户任务的部署而且不受服务器和防火墙的影响。在Hadoop Studio环境下，用户只需要简单几步便可以启动计算任务：首先在Hadoop Jobs中添加生成好的JAR包，然后选择要执行的主类，添加依赖项，并选择执行任务的目标Cluster节点和目标Filesystems即可完成启动。
3）调试：MapReduce编程中最具挑战性的领域之一就是在集群上调试MapReduce任务。Studio提供了可视化工具和任务实时监控，并支持图表化Hadoop任务执行状态（包括作业类型、完成情况、执行状态、起止时间、报错信息、输出结果等）和查看任务计数器，这都使得调试MapReduce变得容易起来。
4）可视化：强大的图形用户界面能够使用户不用关注分布式平台的细节就可以编写程序、调试程序、管理集群和文件系统、配置任务信息和日志文件等，这都为用户节省了时间。同时图形界面还能让用户通过实时查看输入输出和中间结果的流程图等其他任务信息来管理任务的执行情况。
Hadoop Studio是一个强大的Hadoop插件，它具有众多优点，能够简化用户Hadoop开发过程，提高用户的效率。
18.1.2 Hadoop Studio的安装配置
Hadoop Studio专注于简化数据处理。为满足其广泛的可用性，Hadoop Studio开发和部署环境的要求都设计得很简单。表18-1是它的开发和部署环境要求：
从这个表中可以看出Studio的开发可以基于Eclipse。下面，我们以基于Eclipse（安装在Linux系统上）的大众版Hadoop Studio为例介绍其安装和使用方法。
基于Eclipse安装Hadoop Studio需要一个集成开发环境（IDE）、Java平台和Java SE，并且首先需要有以下软件的支持，如表18-2所示。
安装JDK和Eclipse的过程不再赘述，重点介绍安装好JDK和Eclipse之后如何安装基于Eclipse的大众版Hadoop Studio。
Hadoop Studio是Eclipse的一个插件，在启动Eclipse之后依次点击Help菜单下的Install New Software→弹出的Install窗口→Add，然后在弹出的Add Repository窗口中填入以下信息：
Name：Karmasphere Studio Plugin
Location：http：//updates. karmasphere.com/dist/＜＜serial_key＞＞/Eclipse/site.xml
填完之后点击OK。接下来在Install窗口下会出现可能需要安装的插件，选择Karmasphere Studio Community Edition或者Karmasphere Studio Professional Edition，之后一直点击Next并选择I accept the terms of the license agreements。接下来Hadoop Studio插件将会自动下载并安装。中途如果出现Security Warning窗口，选择OK安装就会继续。安装结束后重启Eclipse即能正常使用。现在最新版本的Studio是1.11。
18.1.3 Hadoop Studio的使用举例
下面以本地MapReduce任务的开发、调试和部署及远程部署为例，介绍Hadoop Studio的使用情况。
1.本地开发、调试和部署
（1）本地的开发和调试
Hadoop Studio的任务开发工具允许用户开发并调试MapReduce任务。Hadoop Studio可以降低MapReduce编程的入门门槛，因为有了它，用户可以在不需要集群支持的情况下，不断开发和调试自己的任务以避免延误整个工程的开发周期。接下来我们介绍两个工作流程并说明如何在本地部署它们，让大家熟悉Hadoop Studio开发工具的使用方法，这两个工作流程中一个使用MapReduce预定义类（WordCount Workflow），另一个使用MapReduce自定义类（Pi Project Workflow）。
WordCount工作流
1）创建一个名为WordCountProject的Java工程（详细过程略）；
2）创建一个MapReduce工程。
为了使用Hadoop Studio，我们需要引用Karmasphere和Hadoop libraries，右键点击步骤1）中创建的Java工程，选择Build Path＞Add Libraries，接着选择弹出窗口中的Hadoop Libraries from Karmasphere并点击Next，在弹出的窗口中选择Karmasphere Client for Hadoop并点击finish。然后右键点击WordCountProject工程，选择New＞Other，接着选择Hadoop Jobs下的Hadoop Map-Reduce Job（Karmasphere API）并点击finish。再然后展开Eclipse工作区面板中的WordCountProject，双击src下的HadoopJob.wordfolw。出现下面的界面（如图18-1所示）：
图 18-1 Hadoop Studio工程配置图
点击窗口界面中第一行的Bootstrap按钮，再点击相应页面中的Browse按钮，打开文件系统上的一个文件，然后保存工程。这样Studio就会为你的工程生成所有的代码并且进行编译。在图18-1的窗口中有很多选项卡，点击各个选项卡用户可以查看自己工程所处的状态和输入数据在各个时间点对工程的影响。用户也可以点击选项卡设置对应的工程配置参数。
现在先点击Input选项卡，在Class name一栏中输入org.apache.Hadoop.mapred.TextInputFormat，将输入文件的格式设定为TextInputFormat。再点击Mapper选项卡，在Class name一栏输入org.apache.Hadoop.mapred.lib.TOKenCountMapper，为Mapper的计数令牌设定类的格式。接着点击Partitioner选项卡，在Class name一栏输入org.apache.Hadoop.mapred.lib.HashPartitioner，以设定Partitioner的类。随后点击Comparator选项卡，在Class name一栏输入org.apache.Hadoop.io.Text.Comparator选定Text Comparator。然后点击Combiner，在Classname一栏输入org.apache.Hadoop.mapred.lib.IdentityReducer，选定Identity Reduce。再然后点击Reducer，在Class name一栏输入org.apache.Hadoop.mapred.lib.LongSumReducer，选定Long Sum Reducer。最后点击Output选项卡，在Class name中输入org.apache.Hadoop.mapred.TextOutputFormat，以设定output的数据类型。
Pi Project工作流
1）创建新的Java工程，按照上面WordCountProject中添加工作流的步骤添加一个工作流。如图18-2所示。
图 18-2 Hadoop Studio新创建的工程图
2）右键点击PiProject，选择New→Other。选择New窗口中Hadoop Types下的Hadoop Mapper，然后点击finish。Package Explorer中的PiProject工程下会出现HadoopMapper.java，按照同样的步骤添加HadoopReducer.java。双击HadoopMapper.java打开界面，输入下面的代码：
package cn.edu.ruc.cloudcomputing.book.chapter18；
import java.util.Random；
import java.io.IOException；
import org.apache.Hadoop.mapred.MapReduceBase；
import org.apache.Hadoop.mapred.Mapper；
import org.apache.Hadoop.mapred.OutputCollector；
import org.apache.Hadoop.mapred.Reporter；
import org.apache.Hadoop.io.Text；
import org.apache.Hadoop.io.LongWritable；
/**
*
*/
public class HadoopMapper extends MapReduceBase implements Mapper＜Text, Text, Text，
LongWritable＞{
public void map（Text key, Text value, OutputCollector＜Text, LongWritable＞output，
Reporter reporter）
throws IOException{
Random generator=new Random（）；
int i；
final int iter=100000；
for（i=0；i＜iter；i++）
{
double x=generator.nextDouble（）；
double y=generator.nextDouble（）；
double z；
z=x*x+y*y；
if（z＜=1）
output.collect（new Text（"VALUE"），new LongWritable（1））；
else
output.collect（new Text（"VALUE"），new LongWritable（0））；
}
}
}
}
再双击HadoopReducer.java打开界面，输入下面代码：
package cn.edu.ruc.cloudcomputing.book.chapter18；
import java.io.IOException；
import java.util.Iterator；
import org.apache.Hadoop.mapred.MapReduceBase；
import org.apache.Hadoop.mapred.OutputCollector；
import org.apache.Hadoop.mapred.Reducer；
import org.apache.Hadoop.mapred.Reporter；
import org.apache.Hadoop.io.Text；
import org.apache.Hadoop.io.LongWritable；
import org.apache.Hadoop.io.DoubleWritable；
public class HadoopReducer extends MapReduceBase implements Reducer＜Text, LongWrit-
able, Text, DoubleWritable＞{
p u b l i c v o i d r e d u c e（T e x t k e y, I t e r a t o r＜L o n g W r i t a b l e＞v a l u e，
OutputCollector＜Text, DoubleWritable＞output, Reporter reporter）
throws IOException{
double pi=0；
double inside=0；
double outside=0；
while（value.hasNext（））
{
if（value.next（）.get（）==（long）1）
inside++；
else
outside++；
}
pi=（4*inside）/（inside+outside）；
output.collect（new Text（"pi"），new DoubleWritable（pi））；
}
}
右键点击Eclipse菜单栏中的Project选项卡，查看Build Automatically项是否选中，如果没有选中，就点击Project下的Build Project。需要注意的是，Build Automatically对于Studio生成的Hadoop Job默认是选中的。之后点击HadoopJob.wordflow下的Bootstrap，接着点击Browse选择输入文件，并点击input选项卡设定输入格式为org.apache.Hadoop.mapred.KeyValueTextInputFormat。然后点击mapper选项卡输入HadoopMapper选定HadoopMapper。点击Partitioner选项卡输入org.apache.Hadoop.mapred.lib.HashPartitioner选定Hash Partitioner。点击Comparator选项卡，输入org.apache.Hadoop.io.TextComparator选定Text Comparator。点击Reducer选项卡，输入HadoopReducer选定Hadoop Reducer。最后点击Output选项卡输入org.apache.Hadoop.mapred.TextOutputFormat选定输出数据格式。
（2）本地任务部署
Hadoop Studio使用户能够将自己的本地任务部署成线程模式。这里我们介绍将本地工作流任务和JAR包任务部署成线程模式的详细步骤，包括工作流和JAR文件。需要注意的是如果读者使用的是Windows系统，则需要先安装Cygwin模拟Linux环境。
部署工作流
打开上面已经创建的PiProject工程中的工作流，点击Eclipse工具栏中最后一个Deploy按钮，设定Deployment窗口中Target Cluster和Data Filesystem的参数值，分别为In-Process Thread（0.20.2）和Local Filesystem C：\，然后点击OK。当工作流在本地部署完成时，在Output窗口下就可以看到实时执行状态了。
部署JAR包
首先还是打开上面已经创建的PiProject工程中的工作流，然后选择Eclipse→window→Open Perspective→Other→Hadoop，点击OK之后会打开Hadoop视图。在Jobs上右键点击选择New Job，输入Job Name，选择Job Type为Hadoop Job from pre-existing JAR file，点击Next，然后选择要部署的JAR文件并点击Next。接着选择Default Cluster为In-Process Thread（0.19.3），设定Default Arguments为pi 10 10000。最后右键点击新建的Job，选择Execute Job。到此JAR文件的部署已经完成。同样在JAR文件部署完成之后，就可以在Output窗口中查看Job的实时执行状态了。
2.集群部署
（1）新建Hadoop HDFS
为了使用HDFS，我们首先需要在Hadoop视图下创建一个文件系统。Hadoop Studio允许用户通过Socket或SSH连接、浏览、读写一个HDFS。它有一个内置的用来展示本地文件系统的选项。
首先，让我们打开Hadoop视图创建一个文件系统选项。右键点击Filesystem选择New Filesystem，在打开的窗口中输入文件系统的名字并设定Filesystem Type为Hadoop HDFS Filesystem。接下来配置运行HDFS的NameNode。如果计划通过SSH连接，那么需要将NameNode Host配置成localhost，然后再配置NameNode Port、Hadoop Version、Username、Group并点击finish，接下来将连接类型配置成DIRECT，之后点击finish完成文件系统选项的创建。右键点击创建的文件系统选项，选择Open Filesystem可以浏览文件系统项目，Studio将会创建同文件系统的连接，并打开Filesystem Browser窗口以便于用户查看管理文件系统。
（2）监控HDFS
Hadoop Studio可以图形化地描述HDFS文件系统的状态，在需要查看的文件系统上点击右键选择Monitor status就可以查看。当然前提是用户已经创建了文件系统。
（3）创建Hadoop集群
要在分布式Hadoop集群上部署、调试、监控，需要先在Hadoop视图下创建集群选项。Hadoop Studio允许用户在集群上运行自己的任务并通过图表监控集群的状态。
Hadoop Studio有一个内置模拟集群的选项。用户可以用它来运行任务，在测试小数据量上任务的运行时显得尤其有用。在这里将创建一个Hadoop集群，首先需要添加一个新的JobTracker集群。打开Hadoop视图右键点击Hadoop Clusters并选择New Cluster，在出现的窗口输入Cluster Name，选择Cluster Type为Hadoop Cluster（JobTracker），再设定正确的Hadoop Version和Default Filesystem。点击Next之后再配置集群，输入JobTracker Host、JobTracker Port和Username，之后点击Next。接下来配置Hadoop集群的通信机制，有直接通信、Socket和可选SSH。我们这里设置为直接通信。然后点击finish完成Hadoop集群的创建。
（4）监控正在运行的任务
Hadoop Studio可以解释并显示用户Hadoop集群在运行任务时保存的日志文件和错误诊断信息。这个功能使用户可以监控自己任务的执行情况，并且分析任务的执行结果。当MapReduce Job运行时，Hadoop Studio会切换到Job Monitor视图，在这个视图上用户可以看到任务的执行信息。Job Monitor视图列出了集群上所有任务的信息，选择一个任务并点击Task Monitor按钮，就可以看到这个任务的Summary、Timeline、Logs、Tasks和Config等信息。如果需要监控集群的状态，可以右键点击对应集群并选择Monitor Status, Monitor Status窗口就会列出Map Attempts、Reduce Attempts、Task Trackers和User Accounting的统计表格。
（5）部署运行任务
Hadoop Studio允许用户部署三种类型的任务：工作流、JAR文件和流任务。这里我们将介绍部署这三种类型任务的步骤。需要注意的是，如果集群通过SSH连接，那么部署的Job必须是通过Hadoop Client创建的（具体过程参考本章相关内容）。另一个需要注意的是保证Hadoop的版本与集群的Hadoop版本一致。
工作流
创建一个工作流（过程略）然后点击deploy，在弹出的Deployment窗口中输入Job Name，选择Target Cluster和Data Filesystem，键入输入和输出的参数，然后点击OK。需要注意的是，输入参数的时候需要每个参数都要占一行或者同行参数之间需要空格隔开，并且输出目录应为空或不存在。接下来点击OK，之后工作流就会部署运行了，在Output窗口里可以查看运行情况。
流任务
打开Hadoop视图，右键点击Jobs选择New Job。输入Job Name，选择Job Type为Hadoop Streaming Job，点击Next。再输入Input Location和Output Location，点击Next。接着选择Mapper和Reducer的types为Raw Command，在Mapper和Reducer中输入/bin/cat，然后点击finish，如果是自己编写的代码那么就需要在设置Mapper和Reducer时选择Upload。接下来右键点击新建的Job选择Execute Job，在确认各项参数无误之后点击OK，这样，任务就会部署运行，同样可以在Output中查看状态。
JAR文件
在集群上部署Jar文件需要用到Hadoop Services。具体步骤是打开Hadoop视图，右键点击Jobs，选择New Job，输入Job Name，选择Job Type为Hadoop Job from pre-existing JAR file，点击Next。在弹出的窗口中浏览文件系统选择Primary Jar file，并输入Main Class，点击Next。接下来需要选择默认集群和默认参数，配置完成之后点击finish。参数输入格式的要求和Job Worflow中相同，然后右键点击新创建的Job，选择Execute Job，确认参数无误之后点击OK，这样，任务就会部署运行，同样可以在Output中查看状态。
到这里Hadoop Studio的使用方法已经介绍完毕，我们从本机和集群两个角度分别介绍了不同任务的部署和运行，同时还介绍了如何使用Hadoop Studio监控用户任务，以及利用其用户界面简化Hadoop任务的创建、调试、监控和执行。Hadoop Studio的可视化设计和全面的功能大大降低了基于Hadoop项目的开发难度，值得所有Hadoop使用者和开发者使用。
18.2 Hadoop Eclipse的介绍和使用
 18.2.1 Hadoop Eclipse的介绍
Hadoop是一个强大的并行框架，它允许任务在其分布式集群上并行处理。但是编写、调试Hadoop程序都有很大的难度。正因为如此，Hadoop的开发者开发出了Hadoop Eclipse插件，它在Hadoop的开发环境中嵌入Eclipse，从而实现了开发环境的图形化，降低了编程难度。在安装插件、配置Hadoop的相关信息之后，如果用户创建Hadoop程序，插件会自动导入Hadoop编程接口的JAR文件，这样用户就可以在Eclipse的图形化界面中编写、调试、运行Hadoop程序（包括单机程序和分布式程序），也可以在其中查看自己程序的实时状态、错误信息和运行结果，还可以查看、管理HDFS及其文件。总的来说，Hadoop Eclipse插件安装简单，使用方便，功能强大，尤其是在Hadoop编程方面，是Hadoop入门和Hadoop编程必不可少的工具。
18.2.2 Hadoop Eclipse的安装配置