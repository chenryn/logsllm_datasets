title:Thinning akamai
author:Ao-Jan Su and
Aleksandar Kuzmanovic
Thinning Akamai
Ao-Jan Su and Aleksandar Kuzmanovic
Department of Electrical Engineering & Computer Science
Northwestern University, Evanston, IL 60208, USA
PI:EMAIL, PI:EMAIL
ABSTRACT
Global-scale Content Distribution Networks (CDNs), such
as Akamai, distribute thousands of servers worldwide pro-
viding a highly reliable service to their customers. Not only
has reliability been one of the main design goals for such
systems — they are engineered to operate under severe and
constantly changing number of server failures occurring at
all times. Consequently, in addition to being resilient to
component or network outages, CDNs are inherently con-
sidered resilient to denial-of-service (DoS) attacks as well.
In this paper, we focus on Akamai’s (audio and video)
streaming service and demonstrate that the current system
design is highly vulnerable to intentional service degrada-
tions. We show that (i) the discrepancy among streaming
ﬂows’ lifetimes and DNS redirection timescales, (ii) the lack
of isolation among customers and services, (e.g., video on
demand vs. live streaming), (iii) a highly transparent sys-
tem design, (iv) a strong bias in the stream popularity, and
(v) minimal clients’ tolerance for low-quality viewing expe-
riences, are all factors that make intentional service degra-
dations highly feasible. We demonstrate that it is possi-
ble to impact arbitrary customers’ streams in arbitrary net-
work regions: not only by targeting appropriate points at
the streaming network’s edge, but by eﬀectively provoking
resource bottlenecks at a much higher level in Akamai’s mul-
ticast hierarchy. We provide countermeasures to help avoid
such vulnerabilities and discuss how lessons learned from
this research could be applied to improve DoS-resiliency of
large-scale distributed and networked systems in general.
Categories and Subject Descriptors
C.2.2 [Computer-Communication Networks]: Internet
C.4
[Performance of Systems]: Reliability, availability,
and serviceability
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’08, October 20–22, 2008, Vouliagmeni, Greece.
Copyright 2008 ACM 978-1-60558-334-1/08/10 ...$5.00.
General Terms
Security, Measurement, Experimentation
Keywords
Streaming, Akamai, CDN, Denial of service
1.
INTRODUCTION
Streaming is thriving in the Internet. A recent study
shows that as a result of streaming audio and video in web
downloads, HTTP took back the leading position from peer-
to-peer (p2p) applications for the ﬁrst time in the last four
years [19]. Streaming alone accounts for more than 20% of
the total Internet traﬃc [19], and it is expected that new
applications, such as Internet video and TV (e.g., [5, 7, 10]),
will further accelerate this trend over the coming years.
One of the key driving forces standing behind the suc-
cess of streaming applications in the Internet is certainly
their quality. Due to penetration of high-speed broadband
access technologies and improved streaming dissemination
techniques, the quality bars have been raised quite high. In-
deed, a recent study conducted by Akamai Technologies ex-
plored fundamental elements related to the future success of
online video: consumer preferences around video consump-
tion and consumer reaction to low-quality viewing experi-
ences. The most compelling results reveal that, having ex-
perienced poor video performance at an Internet site, more
than half of online video users would seek content from a
competing website, and a quarter would leave with a more
negative brand perception and be less likely to return to the
poorly performing site [13].
This apparently opens the doors for denial-of-service (DoS)
attacks against streaming services. Indeed, generating even
short server or network outages, or reducing the encoding
rate can cause a stream’s quality to degrade, producing
“glitches,”“slide-shows,” and “freeze ups” as the user watches
the stream. This, in turn, can dramatically impact clients’
perception and can cause them to switch the channel or sim-
ply give up [13].
Incentives for conducting such misbehaviors are manifold.
In addition to the rough competition among streaming con-
tent providers, other scenarios are possible as well. For
example, many political and sport events are frequently
streamed over the Internet nowadays, and opposing parties
might be tempted to disrupt such broadcasts on the Inter-
net, e.g., interrupt the broadcast of a political speech on
CNN’s web site to clients on the East Coast, or disrupt the
broadcast of a basketball game on NBA’s pay-per-view site
on the West Coast. Unfortunately, such scenarios are not
the matter of a distant future; we demonstrate that such
sophisticated attacks could be launched today.
In this paper, we focus on Akamai’s streaming architecture
and its resilience to DoS attacks. While our experiments
and evaluations are necessarily tied to Akamai’s stream-
ing infrastructure, the lessons learned from our study can
be generalized not only to other DNS-driven and multicast
streaming services, but can have important impact on the
design and security of distributed and networked systems in
general, as we discuss later in the paper. Akamai’s stream-
ing network is one of the largest streaming infrastructures in
the world, capable of serving close to a million streams con-
currently [3].1 In addition to the built-in resilience to net-
work and server failures [14], the architecture is character-
ized by several other desirable properties. Unlike p2p-based
streaming architectures (e.g., ESM [4]), which are vulnerable
to misbehaving peers (e.g., [28]), no clients are directly in-
volved in distributing content in Akamai’s case [22]. Unlike
data-center-oriented systems (e.g., YouTube [9]) that have a
single point of failure (a data center itself), Akamai’s stream-
ing network aggressively distributes content all around the
world; hence, no single point of failure exists.
Contrary to the common belief, we ﬁnd that it is highly
feasible to degrade service quality to arbitrary ﬂows in ar-
bitrary parts of the Akamai’s streaming network. The key
issue is that the redirection time-scales used for load balanc-
ing by DNS-driven systems are fundamentally inappropriate
for live streaming. In particular, when a server (or the net-
work access link) experiences increased load, the redirection
might help the newly arriving clients to avoid the problem,
but not the clients that are already fetching their streams
from the given server.2 Thus, contrary to the web case,
where DNS redirections at time scales of tens of seconds can
eﬀectively help reduce the load from the troubled server,
such an approach does not work for streaming, particularly
when the system is under attack. This is because the ﬂow
lifetimes are fundamentally diﬀerent for streaming and the
web. Moreover, clients’ tolerance for the former is dramati-
cally thinner [13].
Unfortunately, other problems exist as well. In particu-
lar, streams belonging to diﬀerent customers, channels, and
services (e.g., live audio, live video, or video on demand) all
share the same infrastructure, and we show that no strong
spatial nor temporal isolation among them exists, neither at
the server nor at the network level. The combination of this
problem and the above slow load balancing problem causes
additional security implications. Because both popular and
unpopular streams overlap at the same servers, it is possible
to generate traﬃc surges by requesting unpopular streams,
thus dramatically impacting the popular ones.
A related issue is that global-scale streaming services dis-
tribute streaming servers to edge regions which typically
have limited, often moderate bandwith (e.g., 100 Mbps or
less), shared by the rest of the ISPs’ traﬃc. As a result, only
moderate attacker resources are needed to generate traﬃc
surges and impact a streaming service at a particular edge
1Monthly peak 974,296 streams on May 17, 2007 [3].
2Even the newly arriving ﬂows might end up redirected to
a distant backup server, e.g., to a diﬀerent continent, with
increased probability to experience poorer viewing quality.
region. Even though these attacks may not “melt down” the
entire streaming service globally, they can dramatically en-
danger the reputation of a streaming service by targeting
a desired customer’s stream (e.g., broadcast of a popular
event) at a given network region.
In an attempt to verify the above hypotheses, while tak-
ing enormous care not to cause any problems to Akamai’s
clients, we perform Internet experiments. To excite Aka-
mai’s bottlenecks, we carefully and gradually increase the
request rate for unique unpopular streams from appropri-
ate Akamai servers. Whenever the bottleneck reaches its
limit, we instantly abort the experiment. We verify the slow
load balancing problem, and demonstrate that a stream’s
throughput can get thinned (e.g., from 1.4 Mbps to 200 kbps)
when the bottleneck reaches its capacity. Moreover, a highly
transparent system design that feeds important internal in-
formation to the public (via URLs), opens the doors to ad-
ditional unforeseen problems. We show that it is feasible
to eﬀectively exploit the transparent system design and ex-
cite resource bottlenecks not only at the streaming network’s
edge, but at a much higher level in the Akamai’s multicast
hierarchy: at reﬂectors or even at content providers’ origin
servers.
Providing a single comprehensive solution to the above
problems is challenging for a number of reasons. Hence, we
provide a set of countermeasures with the goal to signiﬁ-
cantly increase the bar for potential attackers rather than
provide a “bullet-proof” solution. First, we argue that
resource-based or graphic-puzzles based admission control
schemes are either inappropriate or incapable of solving the
problem. Second, we argue that location-aware admission
control can dramatically raise the bar for the attackers:
force them to use botnets, instead of a few high-bandwidth
machines as we did. Third, we argue that a more care-
ful edge cluster conﬁguration, and most importantly, a less-
transparent system design that is capable of hiding impor-
tant internal information from the public, can dramatically
raise the system’s resilience to even botnet-equipped attack-
ers. Finally, we discuss the tradeoﬀs between security and
system transparency in networked and distributed systems
in general.
This paper is structured as follows. In Section 2, we sum-
marize a DNS-driven streaming architecture and illucidate
the key vulnerabilities of this system. In Section 3 we per-
form a measurement study that reveals the security impli-
cations of this architecture, and we show how they can be
exploited in Section 4. We provide design guidelines to avoid
these exploits in Section 5. Finally, we conclude in Section
6.
2. DNS-BASED STREAMING SERVICES:
BACKGROUND AND VULNERABILITIES
Here, we provide the necessary background on Akamai’s
DNS-driven streaming infrastructure. Then, we outline the
main vulnerabilities characterstic not only for this particular
infrastructure, but for large-scale DNS-driven and multicast
streaming systems in general.
2.1 Background
In order to serve millions of audio, video, on-demand,
and live streaming clients globally, Akamai designed and de-
ployed an overlay streaming multicast network [14].
servers and between edge servers and reﬂectors are done via
DNS. Below, we exemplify the ﬁrst scenario — DNS-driven
mapping between clients and edge servers.
Figure 1: Akamai’s overlay multicast streaming net-
work
Figure 1 illustrates an abstract view of this streaming ar-
chitecture. At the source, content providers (e.g., a radio
or a TV station) encode their streams and transfer them
to the so-called entry points of the Akamai’s streaming net-
work. To distribute streams to a large number of regions
in a scalable manner (e.g., [26]), the streams are then repli-
cated to multiple set reﬂectors [22]. Set reﬂectors in turn
propagate the streams to edge servers. Finally, edge servers
stream content to clients (not shown in the Figure).
Data in the multicast network is transferred via UDP. To
tolerate network transfer errors, reﬂectors and edge servers
may receive multiple copies of each packet and reassemble
the data streams by pruning duplicate packets. Still, repli-
cating each of the streams to each of the reﬂectors and edge
servers is simply not feasible. This is because such an ap-
proach would overload set reﬂectors. Moreover, replicating
all streams to all reﬂectors and edge servers is really not
needed, because not all streams are equally popular [22].
Subscription system. To address this problem, the
streaming CDN adopts a reﬂector subscription system. It al-
lows set reﬂectors to propagate streams upon requests from
downstream edge servers. Indeed, the subscription approach
ensures that only watched streams get propagated to edge
regions [22]. Still, even the development of a subscription
system does not fully remove the potential to overload set
reﬂectors. For example, if all popular edge regions subscribe
to the same set reﬂector, they could overload that machine
or a set of machines, even though the set reﬂector subsystem
as a whole has plenty of spare capacity [22].
Portsets. To further address the problem, the approach
is to group streams into buckets called portsets.3 Then, it as-
signs portsets to diﬀerent set reﬂectors to ensure the load is
distributed appropriately. Indeed, a portset is no more than
a collection of streams that is supposed to be transported
through the same set reﬂectors [22]. Akamai groups popular
and unpopular streams in the same portsets. Such an ap-
proach provides good load balancing capabilities. Likewise,
when the load in a given portset starts growing, the system
can adapt to the growth.
DNS-driven system. Following the successful design
applied in the case of web,4 all the mappings in the Akamai’s
streaming architecture, i.e., those between clients and edge
3In this paper, we interchangeably use terms ’portset’ and
’channel.’
4Akamai routinely delivers between ten and twenty percent
of all web traﬃc, at times reaching more than 650 Gigabits
per second [3].
Figure 2: DNS-based load balancing
Figure 2 illustrates the DNS load balancing approach.
When the monitoring infrastructure observes network or
server overloading conditions of an edge server (E1), it up-
dates appropriate DNS entry to redirect new clients to an-
other edge server (E2).
In this way, the system reduces
the load placed on edge server E1 and helps newly arriving
clients get better service from the server (E2). The criti-
cal issue, however, is the timescale at which the redirection