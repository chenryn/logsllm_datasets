The result does require some assumptions about the exis-
tence of records having certain values in the database, namely
hypotheses h2 and h3. Hypothesis h2 requires that there exist
two records with values a and b such that a, b ∈ [N/4, 3N/4],
and b − a ≥ N/3 (what really matters for the proof to go
through is that a, b should be Ω(N ) away from 1, N and
each other); and additionally that there exist at least three
records with values within [N, N + 1 − N ] that are more
than N away from each other (note that a and b can be two
of these values). Hypothesis h3 requires that a strict majority
of all records have a value within [N, N + 1 − N ], and
that no range of length N contains the values of a (strict)
majority of all records. On the face of it, h2 and h3 seem
like they are restrictive in that they make several requirements
on the database. But those requirements are quite mild. Both
hypotheses essentially ask that the database should not be too
concentrated over a few values. We have not encountered a
real-world dataset that failed to satisfy those requirements.
Further, only h2 is actually required for the T node to exist and
leak sacriﬁcial -approximate order as claimed. The only point
of hypothesis h3, which is more demanding, is to ensure that
that node is the deepest node covering a majority of records, so
that it can be easily located. But that is a theoretical concern:
in our experiments, the desired T node was usually in the ﬁrst
two levels of the tree. Thus, the practically relevant hypothesis
is h2, which only requires that the database should not be
entirely concentrated near the endpoints.
In the full verison, we prove that the query complexity
of our algorithm is optimal within a constant factor. More
precisely, any (unbounded) adversary achieving sacriﬁcial -
AOR for all databases must require Ω(−1 log −1) queries.
C. Experimental Results
Assuming uniform queries, the ApproxOrder attack suc-
ceeds within O(−1 log −1) queries (for any given constant
probability of success η < 1). We experimentally evaluate
the tightness of this bound for a ﬁxed number of records
R, and various numbers of possible values, N, so that we
1074
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:08 UTC from IEEE Xplore.  Restrictions apply. 
be interpreted in this way.
Although our theoretical analysis for the ApproxOrder
attack assumes a uniform query distribution, this assumption
was only for the analysis and the attacker does not need
to know the query distribution to carry out the attack. We
consider now another more realistic distribution on queries,
namely ﬁxed-width range queries. Such queries are widespread
in practice: for example, the industry-standard TPC-H contains
six explicit ﬁxed-width range queries. For a given number of
possible values N and width W ≤ N, there are N + 1 − W
[1, W ], [2, W + 1], . . . , [N + 1 − W, N ]. We
such ranges:
experimentally evaluate how well the ApproxOrder attack
performs for a dataset of R = 1000 records, N = 10000
possible values, and range queries of different widths. The
results are in Figure 4. Unlike the case of uniform range
queries, the limiting factor here in attaining -AOR is initially
the too-high symmetric values of the sacriﬁced records. For
small range widths (relative to the domain size, N), these
results are to be expected: when only a few queries have
been observed, the total number of possible values that have
matched any query so far is limited, and thus the maximum
symmetric value of a record that is not in a bucket may be
high. After this initial period, the attack’s performance follows
the results of the uniform range query case and reﬂects the
behaviour of −1 log −1 .
D. From AOR to ADR
We now show how our approximate ordering attack can
be combined with a model of the database distribution π
(commonly called an auxiliary distribution) to mount powerful
-ADR attacks. That is, we leverage our approximate ordering
attack above to achieve approximate database recovery. Our
attack is somewhat reminiscent of the LMP auxiliary distribu-
tion attack, with two major differences: (1) it does not require
the additional rank leakage used by LMP, and (2) we can study
its performance analytically.
We implemented the resulting -ADR attack and conducted
experiments with several datasets representative of practical
use cases of encrypted databases. As in the analysis of
approximate order reconstruction, we will assume here that
the query distribution is uniform only to make the exposition
simpler—no part of our attack requires queries to be uni-
formly distributed. Our attack takes as input the output of
any algorithm achieving -AOR. It also takes a model of the
database distribution π (which needs only to approximate the
true database distribution), the query distribution πq, and the
domain size N. It outputs an estimate for the underlying value
of every record in the database. The pseudocode for the attack
is given in Algorithm 4 in Appendix D.
Attack intuition. Brieﬂy, the attack uses the observation that,
for every disjoint subset of records Ai (i ∈ [1, . . . , k]) given
by -AOR, some information about the ranks of the records
(i.e. their positions in a sorted list of all records) in the subset
is revealed. Because each sacriﬁced record could be before A1
or after Ak the exact ranks are unknown, but lower and upper
bounds can be computed.
Fig. 3. Maximum symmetric values of records not in buckets and maximum
bucket diameters. Results averaged over 500 databases for each value of N.
generate both dense and sparse databases. Record values are
sampled uniformly at random, so hypotheses h2 and h3 were
satisﬁed with high probability. Our results are averaged over
500 databases, each with 500 randomly sampled queries. We
measured the results after every 10 queries, and therefore
sometimes needed a heuristic to identify a likely candidate
for the Q node when the number of queries is very small.
When the root node was not a Q node, our experiments chose
the ﬁrst child Q node that contained at least a third of the
records. As our results indicate, this node usually contained
an overwhelming majority of the records.
The bottom group of lines in Figure 3 shows the maximum
symmetric value (as a fraction of N) of any record that
was not in one of the Q node’s children buckets. When the
ApproxOrder attack succeeds, the only records that are
not necessarily in buckets are those with values in [1, N [ or
]N + 1− N, N ]. If all records have been placed into buckets
below the Q node, the maximum excluded symmetric value is
set to 0. These results show that the theoretical upper bound
holds, even when taking it with all constants set to 1, like in
Section III-D. The attack also behaves in the predicted scale-
free way: changing N has little effect on empirical results.
The upper group of lines in Figure 3 shows the maximum
diameter (as a fraction of N) of the Q node’s child buckets. We
compare this to the expected maximum diameter dictated by
the -net bound, and see that convergence happens as quickly
as predicted by the bound taken with all constants set to 1, as
in the previous case. Again, results are scale-free.
Another way of interpreting these results is to ask, after a
certain number of queries, for what  have we achieved sacri-
ﬁcial -approximate order reconstruction? Our results indicate
that the bottleneck is the maximum bucket diameter, not the
sacriﬁced values, so the upper group of lines in Figure 3 could
1075
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:08 UTC from IEEE Xplore.  Restrictions apply. 
0100200300400500Numberofqueries0.000.020.040.060.080.100.12Symmetricvalue/bucketdiameter(asafractionofN)Max.sacriﬁcedsymmetricvalueN=100N=1000N=10000N=100000Max.bucketdiameterN=100N=1000N=10000N=100000−1log−1−1log−1ApproxOrderexperimentalresultsR=1000,comparedtotheoretical-netboundthe expected value of the order statistic with that rank. The
third step is database estimation, which estimates a value for
each record in a group given a range of values for that group.
Our estimate for each record is the median of the range.
Experiment setup and data. We implemented Algorithm 4
in Python 2.7 and ran all our experiments on an Ubuntu 16.04
desktop with an Intel Core i7-6700 CPU, clocked at 3.4GHz.
We used an existing C++ implementation [14] of the PQ-tree
data structure and used SWIG [15] to call it from Python.
We evaluate the attack on two datasets. The ﬁrst
is a
database of registered pilots from the US government Federal
Aviation Administration (FAA) [16]. It contains the ZIP code
of residence for over 61,000 pilots nationwide. ZIP codes are
ﬁve-decimal-digit numbers. The most signiﬁcant digits reveal
increasingly precise information about location—for example,
the ﬁrst three digits identify a neighborhood in large cities.
For more information see [17]. For this experiment we use US
Census data about ZIP code population as an auxiliary model
of the distribution. Though there are some high-probability
ZIP codes, the distribution is overall fairly uniform. Further,
the FAA ZIP codes are not well-modeled by the census data
- their statistical distance is about 0.51.
The second is a database of California (CA) state public
employee salaries from 2016. Salary data is sensitive both for
cultural reasons and because of the possibility of blackmail.
The database contains over 248,000 numbers between 0 and
762,000 US dollars. Most are salaries (i.e. at least 25,000 US
dollars), but a sizeable fraction are in the low hundreds of
dollars. We did not remove the low dollar amounts (as doing
so could bias experiments in our favor) but we did truncate the
few outliers over 500,000 US dollars. We used a database of
around 120,000 New York (NY) state public employee salaries
from the same year as auxiliary data for this experiment. Both
NY and CA salary datasets are roughly Gaussian with means
73,000 and 67,000 respectively. Their statistical distance is
about 0.19. Rather than use the full CA salary database, in
this experiment we subsampled random databases of 10,000
salaries and averaged the results to better understand how the
attack performs on smaller databases.
Results and discussion. Our attacks will measure accuracy
as percent error, that is, if the true value of a record is u and
the attack guesses v, (for u, v ∈ [N ] the error for that record
is |u − v|/N. The baseline guessing attack for this accuracy
measure is predicting the median of the database distribution
for every record. Figure 5 shows the results of the ZIP code ex-
periment averaged over 20 randomly-generated transcripts and
the salary experiments averaged over 10 randomly subsampled
databases each with 10 randomly-generated transcripts. We
also show the baseline guessing accuracy. The variance was
low in all our experiments with 25 or more queries. With
only ten queries, the variance for the 75th percentile error is
quite high, which we intuitively expect—with so few queries
many groups of records will be large. The results in that
table assume the Ai have been oriented correctly. Because
ZIP codes have a fairly ﬂat distribution our heuristic procedure
(Top) Maximum symmetric values of records not in buckets. (Bottom)
Fig. 4.
Maximum bucket diameters. Results for ﬁxed-width queries averaged over 500
databases for each value of range query width.
There are three main questions to answer in building an
attack from this observation. (1) How should the attack orient
the Ai? (2) How many sacriﬁced records should go before A1?
(3) How should record values be estimated? We will describe
the steps of the attack at a high level here; a full description
of the attack steps appears in Appendix C.
The ﬁrst step is record rank estimation. This step has three
tasks: choosing an orientation of the Ai, guessing how many
of the sacriﬁced records are less than the ﬁrst sorted group
A1, and computing a range of possible ranks for the records
in each Ai. The attack uses a heuristic to orient the Ai that
looks at the number of records above and below the median
group. To estimate the number of sacriﬁced records to put
below A1, we model the number of sacriﬁced records to the
left of A1 as successes in a binomial distribution and use it to
estimate the smallest rank of an element in A1. After that, the
range of ranks for each Ai can be computed as a running sum
of the smallest rank and number of records in each group.
The second step is partition estimation. This step estimates a
range of possible values for each group Ai, given the range of
ranks for the group. We estimate the value for each rank using
1076
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:08 UTC from IEEE Xplore.  Restrictions apply. 
0100200300400500Numberofqueries0.000.020.040.060.080.10Symmetricvalue(asafractionofN)Rangequerywidth1002505001000200050000.000.020.040.060.080.10−1log−1MaximumsacriﬁcedvaluesforApproxOrder,N=10000,R=1000records,ﬁxed-widthrangequeries0100200300400500Numberofqueries0.0000.0250.0500.0750.1000.1250.1500.1750.200Bucketdiameter(asafractionofN)Rangequerywidth1002505001000200050000.0000.0250.0500.0750.1000.1250.1500.1750.200−1log−1MaximumbucketdiametersforApproxOrder,N=10000,R=1000records,ﬁxed-widthrangequeriesPercent Error
25%
50%
75%
# Queries ZC SAL ZC SAL ZC SAL
10
25
50
100
BL
4
2
1
1
15
2
1
1
1
2
7
4
3
2
27
4
2
2
2
5
11
7
6
5
37
7
4
3
3
9
Fig. 5. Accuracy of Algorithm 4 on FAA ZIP codes (‘ZC”, N = 9, 999)
and CAL salaries (‘SAL”, N = 500, 000): percentage of records recovered
with error at most the listed percent of N. ‘BL” refers to baseline guessing.
Error is computed as |(actual) − (guessed)|/N).
OrientSubsets chose the wrong orientation in about half of the
experiments. The Ai were oriented correctly in all runs of the
salary experiment. Since there are only two ways to orient
the Ai an incorrect guess is mostly inconsequential. We do
not include trials for which the PQ tree does not have a Q
node at the ﬁrst level. This happened only a few times in all
experiments for ZIP codes. For salary experiments with 10
queries about one-quarter of the trials did not have a Q node
at the ﬁrst level. With 100 queries, about one-tenth of the trials
did not. (The attacker can tell when there is no Q node and
choose to see more queries before running the attack.)
The attack on ZIP codes performed extremely well. With
only ten queries, we are able to guess the ﬁrst digit correctly
for over half the records on average. Concretely, about half the
database records would have their state of residence partially
revealed with only ten queries. With only one hundred queries,
we recover the ﬁrst two digits (or a small window with only a
few possibilities) for a majority of the records in the database.
For the attack on salaries, the accuracy of the baseline
guessing attack is artiﬁcially low because of the skew of the
distribution—the max value (which we use as the denominator
to compute percent error) is much larger than all but a tiny
fraction of salaries. Thus, the baseline guessing attack having
5% error translates to 25,000 USD, but most salaries are within
25,000 USD of the median, so baseline guessing performs
very poorly on most salaries. In contrast, our attack predicts a
majority of the records in the database to within 2% error
(10,000 USD) with only ﬁfty queries, and with only 100
queries predicts a quarter with 1% error (5,000 USD).
V. GENERALIZING APPROXIMATE RECONSTRUCTION
We have seen how -nets and -samples can be used to
build and analyze approximate reconstruction attacks on range
queries. In this section, we abstract a core technical idea from