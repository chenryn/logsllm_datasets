title:De-anonymizing Programmers via Code Stylometry
author:Aylin Caliskan Islam and
Richard E. Harang and
Andrew Liu and
Arvind Narayanan and
Clare R. Voss and
Fabian Yamaguchi and
Rachel Greenstadt
De-anonymizing Programmers 
via Code Stylometry
Aylin Caliskan-Islam, Drexel University; Richard Harang, U.S. Army Research Laboratory; 
Andrew Liu, University of Maryland; Arvind Narayanan, Princeton University;  
Clare Voss, U.S. Army Research Laboratory; Fabian Yamaguchi, University of Goettingen; 
Rachel Greenstadt, Drexel University
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/caliskan-islam
This paper is included in the Proceedings of the 
24th USENIX Security Symposium
August 12–14, 2015 • Washington, D.C.
ISBN  978-1-939133-11-3
Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXDe-anonymizing Programmers via Code Stylometry
Aylin Caliskan-Islam
Drexel University
Arvind Narayanan
Princeton University
Richard Harang
U.S. Army Research Laboratory
Clare Voss
U.S. Army Research Laboratory
Andrew Liu
University of Maryland
Fabian Yamaguchi
University of Goettingen
Rachel Greenstadt
Drexel University
Abstract
Source code authorship attribution is a signiﬁcant pri-
vacy threat to anonymous code contributors. However,
it may also enable attribution of successful attacks from
code left behind on an infected system, or aid in resolv-
ing copyright, copyleft, and plagiarism issues in the pro-
gramming ﬁelds. In this work, we investigate machine
learning methods to de-anonymize source code authors
of C/C++ using coding style. Our Code Stylometry Fea-
ture Set is a novel representation of coding style found
in source code that reﬂects coding style from properties
derived from abstract syntax trees.
Our random forest and abstract syntax tree-based ap-
proach attributes more authors (1,600 and 250) with sig-
niﬁcantly higher accuracy (94% and 98%) on a larger
data set (Google Code Jam) than has been previously
achieved. Furthermore, these novel features are robust,
difﬁcult to obfuscate, and can be used in other program-
ming languages, such as Python. We also ﬁnd that (i) the
code resulting from difﬁcult programming tasks is easier
to attribute than easier tasks and (ii) skilled programmers
(who can complete the more difﬁcult tasks) are easier to
attribute than less skilled programmers.
1
Introduction
Do programmers leave ﬁngerprints in their source code?
That is, does each programmer have a distinctive “cod-
ing style”? Perhaps a programmer has a preference for
spaces over tabs, or while loops over for loops, or,
more subtly, modular rather than monolithic code.
These questions have strong privacy and security im-
plications. Contributors to open-source projects may
hide their identity whether they are Bitcoin’s creator or
just a programmer who does not want her employer to
know about her side activities. They may live in a regime
that prohibits certain types of software, such as censor-
ship circumvention tools. For example, an Iranian pro-
grammer was sentenced to death in 2012 for developing
photo sharing software that was used on pornographic
websites [31].
The ﬂip side of this scenario is that code attribution
may be helpful in a forensic context, such as detection of
ghostwriting, a form of plagiarism, and investigation of
copyright disputes. It might also give us clues about the
identity of malware authors. A careful adversary may
only leave binaries, but others may leave behind code
written in a scripting language or source code down-
loaded into the breached system for compilation.
While this problem has been studied previously, our
work represents a qualitative advance over the state of the
art by showing that Abstract Syntax Trees (ASTs) carry
authorial ‘ﬁngerprints.’ The highest accuracy achieved
in the literature is 97%, but this is achieved on a set of
only 30 programmers and furthermore relies on using
programmer comments and larger amounts of training
data [12, 14]. We match this accuracy on small program-
mer sets without this limitation. The largest scale exper-
iments in the literature use 46 programmers and achieve
67.2% accuracy [10]. We are able to handle orders of
magnitude more programmers (1,600) while using less
training data with 92.83% accuracy. Furthermore, the
features we are using are not trivial to obfuscate. We are
able to maintain high accuracy while using commercial
obfuscators. While abstract syntax trees can be obfus-
cated to an extent, doing so incurs signiﬁcant overhead
and maintenance costs.
Contributions. First, we use syntactic features for
code stylometry. Extracting such features requires pars-
ing of incomplete source code using a fuzzy parser to
generate an abstract syntax tree. These features add a
component to code stylometry that has so far remained
almost completely unexplored. We provide evidence that
these features are more fundamental and harder to ob-
fuscate. Our complete feature set consists of a compre-
hensive set of around 120,000 layout-based, lexical, and
syntactic features. With this complete feature set we are
USENIX Association  
24th USENIX Security Symposium  255
able to achieve a signiﬁcant increase in accuracy com-
pared to previous work. Second, we show that we can
scale our method to 1,600 programmers without losing
much accuracy. Third, this method is not speciﬁc to C or
C++, and can be applied to any programming language.
We collected C++ source of thousands of contestants
from the annual international competition “Google Code
Jam”. A bagging (portmanteau of “bootstrap aggregat-
ing”) classiﬁer - random forest was used to attribute pro-
grammers to source code. Our classiﬁers reach 98% ac-
curacy in a 250-class closed world task, 93% accuracy in
a 1,600-class closed world task, 100% accuracy on av-
erage in a two-class task. Finally, we analyze various
attributes of programmers, types of programming tasks,
and types of features that appear to inﬂuence the success
of attribution. We identiﬁed the most important 928 fea-
tures out of 120,000; 44% of them are syntactic, 1% are
layout-based and the rest of the features are lexical. 8
training ﬁles with an average of 70 lines of code is sufﬁ-
cient for training when using the lexical, layout and syn-
tactic features. We also observe that programmers with
a greater skill set are more easily identiﬁable compared
to less advanced programmers and that a programmer’s
coding style is more distinctive in implementations of
difﬁcult tasks as opposed to easier tasks.
The remainder of this paper is structured as follows.
We begin by introducing applications of source code au-
thorship attribution considered throughout this paper in
Section 2, and present our AST-based approach in Sec-
tion 3. We proceed to give a detailed overview of the ex-
periments conducted to evaluate our method in Section 4
and discuss the insights they provide in Section 5. Sec-
tion 6 presents related work, and Section 7 concludes.
2 Motivation
Throughout this work, we consider an analyst interested
in determining the programmer of an anonymous frag-
ment of source code purely based on its style. To do so,
the analyst only has access to labeled samples from a set
of candidate programmers, as well as from zero or more
unrelated programmers.
The analyst addresses this problem by converting each
labeled sample into a numerical feature vector, in order to
train a machine learning classiﬁer, that can subsequently
be used to determine the code’s programmer. In partic-
ular, this abstract problem formulation captures the fol-
lowing ﬁve settings and corresponding applications (see
Table 1). The experimental formulations are presented in
Section 4.2.
We emphasize that while these applications motivate
our work, we have not directly studied them. Rather, we
formulate them as variants of a machine-learning (classi-
ﬁcation) problem. Our data comes from the Google Code
Jam competition, as we discuss in Section 4.1. Doubt-
less there will be additional challenges in using our tech-
niques for digital forensics or any of the other real-world
applications. We describe some known limitations in
Section 5.
Programmer De-anonymization.
In this scenario,
the analyst is interested in determining the identity of an
anonymous programmer. For example, if she has a set of
programmers who she suspects might be Bitcoin’s cre-
ator, Satoshi, and samples of source code from each of
these programmers, she could use the initial versions of
Bitcoin’s source code to try to determine Satoshi’s iden-
tity. Of course, this assumes that Satoshi did not make
any attempts to obfuscate his or her coding style. Given a
set of probable programmers, this is considered a closed-
world machine learning task with multiple classes where
anonymous source code is attributed to a programmer.
This is a threat to privacy for open source contributors
who wish to remain anonymous.
Ghostwriting Detection. Ghostwriting detection is
related to but different from traditional plagiarism detec-
tion. We are given a suspicious piece of code and one or
more candidate pieces of code that the suspicious code
may have been plagiarized from. This is a well-studied
problem, typically solved using code similarity metrics,
as implemented by widely used tools such as MOSS [6],
JPlag [25], and Sherlock [24].
For example, a professor may want
to determine
whether a student’s programming assignment has been
written by a student who has previously taken the class.
Unfortunately, even though submissions of the previous
year are available, the assignments may have changed
considerably, rendering code-similarity based methods
ineffective. Luckily, stylometry can be applied in this
setting—we ﬁnd the most stylistically similar piece of
code from the previous year’s corpus and bring both stu-
dents in for gentle questioning. Given the limited set of
students, this can be considered a closed-world machine
learning problem.
Software Forensics. In software forensics, the analyst
assembles a set of candidate programmers based on pre-
viously collected malware samples or online code repos-
itories. Unfortunately, she cannot be sure that the anony-
mous programmer is one of the candidates, making this
an open world classiﬁcation problem as the test sample
might not belong to any known category.
Copyright Investigation. Theft of code often leads to
copyright disputes. Informal arrangements of hired pro-
gramming labor are very common, and in the absence of
a written contract, someone might claim a piece of code
was her own after it was developed for hire and delivered.
A dispute between two parties is thus a two-class classi-
ﬁcation problem; we assume that labeled code from both
programmers is available to the forensic expert.
256  24th USENIX Security Symposium 
USENIX Association
2
Authorship Veriﬁcation. Finally, we may suspect
that a piece of code was not written by the claimed pro-
grammer, but have no leads on who the actual program-
mer might be. This is the authorship veriﬁcation prob-
lem. In this work, we take the textbook approach and
model it as a two-class problem where positive examples
come from previous works of the claimed programmer
and negative examples come from randomly selected un-
related programmers. Alternatively, anomaly detection
could be employed in this setting, e.g., using a one-class
support vector machine [see 30].
As an example, a recent investigation conducted by
Verizon [17] on a US company’s anomalous virtual pri-
vate network trafﬁc, revealed an employee who was out-
sourcing her work to programmers in China.
In such
cases, training a classiﬁer on employee’s original code
and that of random programmers, and subsequently test-
ing pieces of recent code, could demonstrate if the em-
ployee was the actual programmer.
In each of these applications, the adversary may try to
actively modify the program’s coding style. In the soft-
ware forensics application, the adversary tries to modify
code written by her to hide her style. In the copyright and
authorship veriﬁcation applications, the adversary mod-
iﬁes code written by another programmer to match his
own style. Finally, in the ghostwriting application, two
of the parties may collaborate to modify the style of code
written by one to match the other’s style.
Application
De-anonymization
Ghostwriting detection
Software forensics
Copyright investigation
Authorship veriﬁcation
Learner
Multiclass
Multiclass
Multiclass
Two-class
Two/One-class
Comments
Closed world
Closed world
Open world
Closed world
Open world
Evaluation
Section 4.2.1
Section 4.2.1
Section 4.2.2
Section 4.2.3
Section 4.2.4
Table 1: Overview of Applications for Code Stylometry
We emphasize that code stylometry that is robust to
adversarial manipulation is largely left to future work.
However, we hope that our demonstration of the power
of features based on the abstract syntax tree will serve as
the starting point for such research.
3 De-anonymizing Programmers
One of the goals of our research is to create a classiﬁer
that automatically determines the most likely author of
a source ﬁle. Machine learning methods are an obvious
choice to tackle this problem, however, their success cru-
cially depends on the choice of a feature set that clearly
represents programming style. To this end, we begin by
parsing source code, thereby obtaining access to a wide
range of possible features that reﬂect programming lan-
guage use (Section 3.1). We then deﬁne a number of
different features to represent both syntax and structure
of program code (Section 3.2) and ﬁnally, we train a ran-
dom forest classiﬁer for classiﬁcation of previously un-
seen source ﬁles (Section 3.3). In the following sections,
we will discuss each of these steps in detail and outline
design decisions along the way. The code for our ap-
proach is made available as open-source to allow other
researchers to reproduce our results1.
3.1 Fuzzy Abstract Syntax Trees
To date, methods for source code authorship attribu-
tion focus mostly on sequential feature representations of
code such as byte-level and feature level n-grams [8, 13].
While these models are well suited to capture naming
conventions and preference of keywords, they are en-
tirely language agnostic and thus cannot model author
characteristics that become apparent only in the compo-