1.虚假的节点利用率(这让我怎么抄作业? 脚本小子第一个不服)
2.缺乏简易安装的节点安装功能,考虑设置好mongodb的权限为只读,防止子节点控制核心数据库，这个设计需要考量安全性。
3.celery天然支持优先级调度,这个工具不支持,参考 
4.任务细粒度依然是一个目标->一个worker处理->产生大量的request请求,很容易被BanIP
other issue:
**优点:**
代码写的很规范, 注释也很清晰, 整体架构也简单，让人很容易读懂整个程序，不至于出现一些比较低级的语句(给人胶水的感觉)。
没有复杂的大型结构, 非常适合新手作为入门工具去学习分布式。
使用了优秀的celery框架, 处理了繁琐的信息交互(下发任务,竞争处理...),提高了整体的稳定性。
## 0x5 分析reNgine
这个工具属于的设计思想虽然并不少见, 但是能维护好一个类似pipe line的功能，而且提供了
官方文档:, 一键化，定时维护，定时更新，有自己的社区,我认为是一个成功吃螃蟹的作品。
虽然这个工具并没有说明自己具备分布式能力,但是从它的设计上来看,就是采用了celery框架来写的实现的单机分布式,改改就能变成真正意义上的分布式了。
下面是笔者对该工具的分析过程。
* * *
目录结构:
    ├── CHANGELOG.md
    ├── CONTRIBUTORS.md
    ├── Dockerfile
    ├── LICENSE
    ├── Makefile
    ├── README.md
    ├── _config.yml
    ├── certs
    │   ├── Dockerfile
    │   └── entrypoint.sh
    ├── config
    │   └── nginx
    ├── dashboard
    │   ├── __init__.py
    │   ├── admin.py
    │   ├── apps.py
    │   ├── models.py
    │   ├── templates
    │   ├── tests.py
    │   ├── urls.py
    │   └── views.py
    ├── docker-compose.dev.yml
    ├── docker-compose.setup.yml
    ├── docker-compose.yml
    ├── docker-entrypoint.sh
    ├── fixtures
    │   └── default_scan_engines.yaml
    ├── make.bat
    ├── manage.py
    ├── notification
    │   ├── __init__.py
    │   ├── admin.py
    │   ├── apps.py
    │   ├── forms.py
    │   ├── migrations
    │   ├── models.py
    │   ├── static
    │   ├── templates
    │   ├── tests.py
    │   ├── urls.py
    │   └── views.py
    ├── reNgine
    │   ├── __init__.py
    │   ├── celery.py
    │   ├── definitions.py
    │   ├── init.py
    │   ├── settings.py
    │   ├── tasks.py
    │   ├── urls.py
    │   ├── validators.py
    │   └── wsgi.py
    ├── requirements.txt
    ├── scanEngine
    │   ├── __init__.py
    │   ├── admin.py
    │   ├── apps.py
    │   ├── forms.py
    │   ├── migrations
    │   ├── models.py
    │   ├── static
    │   ├── templates
    │   ├── tests.py
    │   ├── urls.py
    │   └── views.py
    ├── secret
    ├── secrets
    │   └── certs
    ├── startScan
    │   ├── __init__.py
    │   ├── admin.py
    │   ├── api
    │   ├── apps.py
    │   ├── migrations
    │   ├── models.py
    │   ├── static
    │   ├── templates
    │   ├── templatetags
    │   ├── tests.py
    │   ├── urls.py
    │   └── views.py
    ├── static
    │   ├── assets
    │   ├── bootstrap
    │   ├── custom
    │   ├── img
    │   └── plugins
    ├── staticfiles
    ├── targetApp
    │   ├── __init__.py
    │   ├── admin.py
    │   ├── apps.py
    │   ├── forms.py
    │   ├── migrations
    │   ├── models.py
    │   ├── static
    │   ├── templates
    │   ├── tests.py
    │   ├── urls.py
    │   └── views.py
    ├── templates
    │   └── base
    └── tools
        ├── OneForAll
        ├── Sublist3r
        ├── amass
        ├── aquatone
        ├── config
        ├── default_settings.yaml
        ├── dirsearch
        ├── get_dirs.sh
        ├── get_urls.sh
        ├── massdns
        ├── scan_results
        ├── subjack_fingerprint.json
        ├── takeover.sh
        └── wordlist
这里其实目录结构不是很复杂,前端的一个大功能其实就是对应了一个文件夹。
我关注的主要是带有scan字样的文件夹。
### 0x5.1 分析流程
`startScan/views.py` 91line:
`start_scan_ui`扫描开始
我们这里跟进`doScan`函数,这里代码很长,分块来分析:
接着解析yaml的配置,来加载对应的工具,挺暴力的。
比如下面这个子域名扫描模块部分中代码中调用amass工具:
加载对应工具，让其自身输出结果文件到结果文件夹。
> 这个else设计导致了没办法复用之前的域名扫描结果了。
>
>
> 这里主要联系是根据taskid来的而不是根据domain来的,也就是说,你不能执行完一个task之后,在执行其他扫描，复用这个task，要么你必须一个task包括你想要两个task完成的功能
>
> 要不然你在插入的数据库的时候就会导致因为缺乏对应的字段导致失败的
获取子域名存储完之后,httpx读取获取到的子域名txt进行存活性判断。
接着就是截图之类的...完成了subdomain的模块,如果我们还同时选中了目录扫描模块的话。
最终扫描完成走到最后:
### 0x5.2 实现扫描进度
这个工具前端能够实时展示当前的扫描进度，我当时写的x7scan为了写这个进度可是折腾了好久,所以这里分出来一节,用来学习别人是怎么实现更新进度的。
根据状态应用不同的button样式。
可以看到这里的进度的动态显示,主要就是利用
    {% widthratio scan_history.scanactivity_set.all|length scan_history.scan_type.get_number_ofs_steps|add:4  100 %}
django的模本运算,扫描的结果集长度/(步骤+4) *100 得到当前的进度
`scan_history.scanactivity_set.all`反向查询获取`scanactivity`的条数
程序的话,默认会创建4个属于表示状态的Activity,这就是为什么+4。
步骤其实就是扫描器的核心5个调用功能点:
### 0x5.3 优缺点分析
由于笔者对django一窍不通,所以很多代码欣赏不来, 整个项目的变量统一采用蛇形格式,
但注释比较少，笔者读起来还是非常吃力，而且这种celery的框架要是想调试也很麻烦,所以这里不对代码作评价。
作为一个用户的角度来简单说说:
**缺点:**
比较明显一点就是结果不能复用，还有就是如果同时有太多扫描(产生大量子域名)，文件读取(txt)也就是读写I/O会占用非常多的内存,系统很容易出现崩溃的情况,还有就是细粒度还是比较大的问题(它本来就不是分布式扫描工具,没必要苛求这个,但是想提高速度的话,可以自己多开一个worker
docker,数目和你CPU差不多就行了)
还有很多issue(xss漏洞之类的):
...
**优点:**
界面写的很用心,系统调低线程的话整体运行还是很稳定的,再者有人不断维护,会越来越优秀的。
还有支持yaml配置各个tools的具体参数配置,看作者写的代码,可以看出来作者写的蛮疲惫的。
...
## 0x6 总结与展望
本文简单地分析了几款的主流工具的工作流程,明白了工具作者的基本思想，其实与我心目中架构的思想还是不太一致的,特别是细粒度这一方面,我会针对细粒度的划分做一些性能的小测试。
> 保佑自己毕设在开始code之前,能够把这个小工具作为前胃菜完结吧,真的是太忙了Orz.
## 0x7 参考链接
[Python 使用VS Code进行调试](https://zhuanlan.zhihu.com/p/95863891)