ity of the system. For example, even if an application runs in an
isolated memory space and no other process (e.g., virus) can mod-
ify it, spyware can invoke its functions by providing some fake/junk
input, thus compromise the integrity of the process’s data. If a pro-
cess takes input from the network, the input can be eavesdropped
or even modiﬁed by malicious processes at the OS layer.
Several approaches have been proposed to enhance the security at
the OS level, such as security-enhanced Linux (SELinux) [19] and
TrustedBSD [5]. In these systems, the OS kernel is extended to in-
clude authorization modules which enforce access control policies.
With an increasing number of attacks launched at the OS kernel
level, such as malicious device drivers and rootkits [8, 18], these
systems cannot provide high assurance for trusted computing ser-
vices.
Similar to enforcing isolation between processes with a secure ker-
nel (e.g., with Nexus in NGSCB), an intuitive approach to address
the above problems is to use a secure kernel as an intermediary for
inter-process communications, i.e., it forwards messages between
processes. While this is applicable for some simple cases, it would
be very complex for the kernel to implement all kinds of commu-
nication mechanisms, since most of them need involvement of the
OS, for example to access the local ﬁle system or the network stack.
Therefore it is difﬁcult for a secure kernel to enforce effective and
ﬂexible access control between processes. Even if it is possible,
with these functionalities, the trust of the secure kernel is difﬁcult
to maintain, because an important consideration to achieve its trust-
worthy status is to make it as simple and small as possible.
3. OVERVIEW OF SECUREBUS DESIGN
Figure 1 shows the architecture of a SecureBus-enhanced platform.
On this platform, the hardware layer (comprising a TCG-compliant
TPM and other necessary hardware such as LT-enabled CPU and
chipset) provides the root of trust for TC. The secure kernel (SK)
provides a protected runtime environment for SB.
SB is the middle layer between kernel space and user space. SB
allocates isolated memory space for each process before the pro-
cess starts to run. With SB, all interactions between a process and
the OS are conducted through SB. Interactions between two iso-
lated processes are monitored by a reference monitor in SB and are
controlled according to pre-deﬁned policies (see Section 5). Other
related services can be in user space for the security management
purpose, such as policy deﬁnition and administration.
One of SB’s design goals is that it should be transparent to applica-
tions and OS, which enables most existing legacy software to run
on commodity OS without changes. This requires that SB should
provide the same interface as a normal OS does. When a process
uses the interface, it is transparent to the process that now the inter-
face is provided by SB instead of the OS. For each access request
from one process to another, SB validates the access by querying
pre-deﬁned access control policies. If this access is allowable, SB
forwards it to the OS silently. If this access is denied, an excep-
tion is returned to the requesting process. Thus SB works like a
middleware such as Java Virtual Machine (JVM), which provides
a transparent interface to applications and controls their accesses
to underlying OS resources. However, since SB does not provide
other complex functionalities such as a platform-independent run-
time environment, its properties and behaviors can have high assur-
ance and possibly even be formally veriﬁed.
Note that for platform management, there are applications and sys-
tem services that run in user space without the involvement of SB.
Typically, these applications, such as installing/updating system
software and patching the system kernel, are “trusted” by the plat-
form administrator such that they have administrative privileges.
Under this architecture, we now present our trust model and the
primitive functions of SB.
3.1 The Trust Model
The integrity of SK is measured by TPM when the system starts.
Also, SK is protected in memory space by hardware so that its in-
tegrity is guaranteed at runtime.
For local applications, before SB is started, SK measures SB’s in-
tegrity and stores its hash value locally. In turn, when a program is
119
3.2 Primitive Functions of SB
To provide transparent services to processes, SB implements an
identical interface that a legacy OS provides to applications. When
SB receives a system call from an application process, the call is
checked by SB according to pre-deﬁned policies based on the at-
tributes of the caller and callee processes, the calling method, as
well as possible context information (see Section 5 for more de-
tails). If the call is allowed, SB forwards it to the underlying OS. To
provide a protected runtime environment for a process and enable
trust veriﬁcation by other components, SB provides the following
primitive functions.
• SB allocates and maintains isolated memory space before
launching a process, by utilizing the memory management
functions provided by SK. This prevents interference between
processes at runtime.
• SB provides integrity check and veriﬁcation by measuring
a process code’s hash value and combining it with the hash
value of any output data that it generates. This enables data
and process authenticity veriﬁcation on a local platform.
• SB enables process-based remote attestation by digitally sign-
ing the hash value of a process as well as its input. The re-
mote attestation enables data and process authenticity veriﬁ-
cation across platforms.
• SB enforces ﬂexible access control and information ﬂow poli-
cies between processes on local platforms or between remote
platforms based on the authenticity veriﬁcation of data and
processes.
Based on this trust model and primitive functions, in the following
sections, we focus on the mechanisms of integrity measurement
and authenticity veriﬁcation in SB in Section 4 and access control
through SB in Section 5.
4. PROCESS AND DATA AUTHENTICITY
The isolation provided by the hardware and SK can prevent ma-
licious modiﬁcation to the binary code of a running process. But
protecting the integrity of the running code is not sufﬁcient. At-
tacks can be mounted via other approaches, such as through input
to a process. For example, a malicious entity can easily send or
inject fake or erroneous data to a process and compromise its run-
time integrity via buffer overﬂow. For a collaborative computing
task like SETI@Home [2], a fraud peer can report fake results to
the server without really performing the computation and get cred-
its. Thus, it is essential to guarantee the authenticity of a process at
runtime and the data it generates.
In our proposed architecture, the authenticity of a process and its
generated data is achieved through a hash chain signed by SB. Fig-
ure 2 shows an example. Suppose process P1 takes primitive input
D0 and generates output D1, which is the input of process P2. The
output (D2) of P2 can be the input of another process, or it can be
returned to P1. Without loss of generality, we assume that interac-
tions between P1 and P2 are on two different platforms, enhanced
with SB1 and SB2, respectively. To ensure the authenticity of the
process and its data, the following protocol is enforced.
Figure 1: Platform architecture with SB
loaded, SB measures the integrity of the program (binary code) and
allocates some separate memory space for it by utilizing functions
of SK. The separation is enforced by SK during the entire running
period of the application.
For remote attestations, a hash chain is constructed to establish the
trust of SB and the upper level applications based on the root of
trust provided by the hardware. Speciﬁcally, SK has a public-
private key pair generated by TPM when the platform is initial-
ized, where the public key is certiﬁed by the attestation identity key
(AIK) of TPM. SK also generates a public-private key pair for SB,
where the public key is certiﬁed by SK by signing with its private
key and the private key is protected by SB with the sealed stor-
age function of TPM. The key pair for SB is generated at the ﬁrst
time when SB is installed on the platform. For the attestation of
a running process state, TPM signs a set of platform conﬁguration
register (PCR) values with its AIK key,1 and SK signs the integrity
value of SB with its private key, while SB signs the integrity value
of the application code. These three signatures are then sent to the
attestation challenger. The challenger veriﬁes all these signatures
and the public key certiﬁcates of AIK, SK, and SB, respectively.
If all are valid and the integrity values match, the application is
trusted.
Note that the “trust” of an application does not imply any extra
privileges. The trust veriﬁcation provides high assurance that it be-
haves as expected, but does not make any decision as to whether it
is guaranteed to be safe. This is why access control mechanisms are
needed to conﬁne application activities, as illustrated in Section 5.
To support the remote attestation and sealed storage, a basic au-
thentication infrastructure is needed to support our trust model.
For simplicity we assume that necessary components for TC, such
as privacy certiﬁcate authority (PCA) (to certify the AIKs of each
platform), are available.
1We do not explicitly specify what PCR values are included in an
attestation, since the required properties of a platform (including
hardware, BIOS, and OS conﬁgurations) are application-speciﬁc.
1. P1 takes primitive input D0 and generates output D1 and
sends it to the local SB (SB1). Note that SB1 has veriﬁed
120
TPM(cid:13)Device(cid:13)Device(cid:13)Hardware(cid:13)OS(cid:13)Secure Kernel(cid:13)Secure(cid:13)Bus(cid:13)Reference(cid:13)Monitor(cid:13)Operating System(cid:13)Security(cid:13)Services(cid:13)Process(cid:13)1(cid:13)...(cid:13)Process(cid:13)2(cid:13)...(cid:13)Figure 2: Integrity chain and veriﬁcation
P1 → SB1:
1
2
SB1:
3 SB1 → SB2:
4
SB2:
5
SB2 → P2: D1
(D0, D1)
V1 = {H(H(D0)||H(P1)||H(D1))}Kpr1 , where Kpr1 is the private key of SB1.
(D1, V1,H(D0),H(P1))
verify the signature and integrity of D0||P1||D1 with Kpb1 (SB1’s public key).
Figure 3: Integrity measurements and veriﬁcation
the source and integrity of D0, either from local platform or
from network resources.
2. SB1 generates individual hash values for D1, and concate-
nates with the hash value of D0 and P1 (measured when P1
is launched), hashes the total and signs it with its private key.
The result is V1 as shown in Figure 2.
3. After SB1 and SB2 build a secure communication channel
following remote attestation, SB1 sends D1 and V1 to SB2.2
4. SB2 veriﬁes the signature and the hash values, and makes
decisions on the integrity and authenticity of P1 and D1.
5. Upon successful veriﬁcation, SB2 sends D1 to P2.
With the sealed signature capability of TC, SB can generate a valid
digital signature only if it is loaded without modiﬁcation, i.e., its in-
tegrity value matches what is sealed with its private key or any other
key that protects the private key. Thus, the digital signature can be
trusted by the applications on the local platform. Furthermore, with
the remote attestation capability of underlying TC hardware, the
trust of SBs on different platforms can be built, which enables the
digital signature veriﬁcation between applications across different
platforms. Ideally, the remote attestation between SB1 and SB2
(required for step 3 in Figure 3) is a one-time operation between
platforms whenever both of them are active can be reused.
As the above example demonstrates, from the process’ viewpoint,
only input/output data are transferred along the dashed lines shown
in Figure 2. Thereby SB enforces the security mechanisms trans-
parently to applications.
Note that SB does not detect attacks according to software vulnera-
bilities in the process code, such as buffer overﬂow with malicious
inputs. Typically, “trusted computing cannot guarantee that soft-
ware executed on a computer system is free of programming errors
(vulnerabilities) that could be exploited” [22]. However, when the
input of a process can be trusted (e.g., signed by a trusted party),
SB can verify the execution status of the running code and the in-
tegrity of the output. For example, with a SB-enabled client, a
SETI@Home server can verify the trust of the computed result
from the client since the input of the client is generated by the
server itself or trusted parties for task assignments.
The combined integrity veriﬁcation of input/output data and pro-
cess code can be used in many traditional communication mech-
anisms on a single platform or between platforms, such as pipe,
signal, and remote procedure call (RPC). For process communi-
cations through shared memory and ﬁles, shared components also
need to be protected by SB when loaded or created, and similar
mechanisms can be used for secure communications between pro-
cesses. Providing details of these mechanisms is beyond the scope
of this paper.
5. ACCESS CONTROL ENFORCEMENT
The goal of access control through SB is to control the information
ﬂow between isolated processes. Information can ﬂow during inter-
actions between processes (e.g., call interfaces and return results),
or accessing shared resources on the computing platform (e.g., read
or write local ﬁles, network resources).3 As aforementioned, with
the runtime process integrity and the authenticity of process com-
munications and input/output, we still cannot guarantee overall se-
curity. To ensure the overall security of a process, it is also es-
sential to control information ﬂow between processes according to
application or organization speciﬁc policies. Beyond preserving a
binary code’s integrity with runtime space isolation and integrity
veriﬁcation with a hash chain, our architecture integrates applica-
tion semantics into the integrity consideration, by introducing an
application context-aware access control model enforced by SB.
Figure 4 sketches the access control architecture with SB, where
the policy manager is launched whenever SB is loaded, with which
the platform owner or system administrator deﬁne access control
policies. The policy manager mainly consists of a policy decision
point (PDP) and a policy database, of which the integrity can be
veriﬁed by SB before any access control decision is made. When-
ever a process needs to access another one (e.g., read data from or
2The remote attestation is either challenged by SB1 or SB2, or
both depending on application and trust requirements.
3Note that we do not address the covert channel problem, which is
generally considered to be beyond the scope of TC technologies.
121
P(cid:13)1(cid:13)D(cid:13)0(cid:13)P(cid:13)2(cid:13)D(cid:13)2(cid:13)...(cid:13)D(cid:13)2(cid:13)SB(cid:13)1(cid:13)SB(cid:13)2(cid:13)D(cid:13)1(cid:13), V(cid:13)1(cid:13)D(cid:13)1(cid:13)D(cid:13)2(cid:13), V(cid:13)2(cid:13)1(cid:13)2(cid:13)3(cid:13)4(cid:13)5(cid:13)write data to this process), the reference monitor evaluates the re-
quest by querying the policy manager, which in turn queries a pol-
icy database or another decision point (e.g., a higher level PDP in
an organization). If the access is allowed, SB forwards the request
to the destination process and returns the result to the requesting
process. That is, SB acts as both a policy enforcement point (PEP)
and a communication proxy for access control between applica-
tions. This makes it transparent to upper layer applications.
The additional advantage of this architecture is the separation of
policy management and enforcement, which is a general require-
ment for modern complex computing systems. This feature makes