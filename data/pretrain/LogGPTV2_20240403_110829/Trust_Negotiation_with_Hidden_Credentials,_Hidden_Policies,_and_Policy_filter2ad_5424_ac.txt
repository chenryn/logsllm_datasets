set of credentials relevant to policy pc.)
We claim that a credential c /∈ C(X) is removed after
at most level(c) iterations, i.e., that for some i ≤ level(c)
we have c ∈ CX,i−1 and c /∈ CX,i. This is established by
a straightforward induction on level(c), whose details we
omit. (cid:3)
5 Review of Cryptographic Tools and Hidden
5.3 Scrambled Circuit Evaluation
Credentials System
5.1
Identity-based encryption
The concept of Identity-Base Encryption (IBE) was ﬁrst
proposed by Shamir [26] in 1984, however the ﬁrst usable
IBE systems were discovered only recently [5, 9]. An IBE
scheme is speciﬁed by following four algorithms:
1. Setup: A Private Key Generator (PKG) takes a security
parameter k and generates system parameters params
and a master secret s. params is public, whereas s is
private to PKG.
2. Extract: Given any arbitrary ID ∈ {0, 1}∗, PKG uses
params, s, and ID to compute the corresponding pri-
vate key dID.
3. Encrypt: It takes params, ID and plaintext M as input
and returns ciphertext C.
4. Decrypt: It takes params, dID and ciphertext C as input
and returns the corresponding plaintext M.
An IBE scheme enables Bob to encrypt a message using
Alice’s ID as the public key, and thus avoids obtaining the
public key from Alice or a directory. Boneh and Franklin
proposed an IBE scheme from the Weil pairing [5]. Their
scheme is secure against adaptive chosen ciphertext attacks.
5.2 Homomorphic Encryption
A homomorphic encryption scheme [23, 24, 10, 11] is an
encryption scheme in which the plaintexts are taken from a
group G, and given the encryptions of two group elements
one can efﬁciently compute a encryption of their sum. Usu-
ally this computation involves a modular multiplication of
the encryptions, let G = ZM where M is a large integer,
we have E(a) · E(b) = E(a + b mod M ). It is easy to see
that E(a)c = E(c · a mod M ).
Damg˚ard and Jurik [11] recently proposed a homomor-
phic encryption scheme in which all users can use the same
RSA modulus N when generating key pairs. Under the
Decisional Composite Residuosity assumption and Deci-
sion Difﬁe-Hellman assumption, the Damg˚ard-Jurik cryp-
tosystem [11] is semantically secure. The semantic secu-
rity property guarantees that an eavesdropper cannot learn
any information about a from E(a). More precisely, given
two arbitrary message m0 and m1, the random variables
representing the two homomorphic encryptions E(m0) and
E(m1) are computationally indistinguishable.
The scrambled circuit evaluation protocol was developed
by Yao [31]. This protocol involves a generator and an
evaluator, in which the evaluator has private input x and
the generator has private input y, and they want to jointly
compute f (x, y) without revealing their private inputs to the
other party.
In the scrambled circuit evaluation protocol, the gener-
ator builds a circuit for computing f, constructs a scram-
bled version of the circuit, and then sends the scrambled
circuit to the evaluator for evaluation. In a scrambled cir-
cuit, each wire is associated with two random numbers, one
corresponds to 0 and the other to 1. Before the evaluation,
the evaluator uses oblivious transfer to obtain the random
values for the input wires corresponding to each bit of her
private input x. During the evaluation, the evaluator learns
exactly one random value for each internal wire, yet she
doesn’t know whether it corresponds to 0 or 1. Finally the
evaluator sends the outcome of the evaluation to the gener-
ator, who recovers the ﬁnal result.
The scrambled circuit evaluation protocol
is secure
against semi-honest adversaries and has been implemented
by Malkhi et al. in [22]. Let γ be a security parameter, ρ
be the cost of a 1-out-of-2 oblivious transfer, assuming the
circuit to compute f is an s-input, t-gate Boolean 2-ary cir-
cuit, the cost of the scramble circuit protocol is O(ρs + γt).
When the size of the circuit is linear to the size of the input,
the cost of the protocol is O(ρs).
5.4 Review of hidden credentials system
The hidden credentials system was proposed by Holt et
[17, 6].
In that system, there is a trusted Credential
al.
Authority (CA) who issues credentials for users in the sys-
tem3. Each user in the system is assigned a unique nym,
where nym could be either a real name or a pseudonym. A
hidden credential is a digitally signed assertion about an at-
tribute of a credential holder by the CA. Roughly speaking,
given an IBE scheme, a hidden credential cred for username
nym and attribute attr is the private key corresponding to
the string nym||attr.
We now give a simple example of how Alice accesses
Bob’s resource using the hidden credentials. Suppose Bob’s
resource M has an access policy which states that M should
only be accessed by students. Alice has a student credential
cred, i.e., cred.nym = Alice and cred.attr = student.
To access M, Alice sends her username Alice to Bob. Bob
responds with I(M, Alice||student), the IBE encryption of
M using identity Alice||student. Alice uses her credential
cred to decrypt I(M, Alice||student) and obtains M. Note
3It is possible to support multiple CAs in the hidden credentials sys-
tem [17]. For simplicity, we assume there is only one CA.
that Bob does not learn whether Alice possesses a student
credential from the above interaction.
6 Protocol for Privacy-Preserving Trust Ne-
gotiation
6.1 Building Blocks
We now describe two building blocks, one for blinded
policy evaluation, the other for equality test for array ele-
ments. These building blocks will later be used in the secure
RE strategy protocol.
6.1.1 Blinded policy evaluation
The goal of the blinded policy evaluation is for Bob to
evaluate Alice’s policy without learning her policy. Alice
should learn nothing about Bob’s input nor the output of the
evaluation. We deﬁne the input and output for this blinded
policy evaluation in Figure 3.
Input: Alice has a private policy function φ :
{0, 1}k → {0, 1}, two random numbers t0 and t1,
and k pairs of values {r1[0], r1[1]}, . . . , {rk[0], rk[1]}.
Bob has k values r1, . . . , rk where ri ∈ {ri[0], ri[1]}.
Output: Bob learns t
. Alice
learns nothing.
=r1[1],...,rk
φ(r1
?
?
=rk[1])
Figure 3. Input and output of blinded policy
evaluation
The protocol for blinded policy evaluation was given
in [14], for details see Appendix B. In most cases, it re-
quires a polynomial amount of communication, and works
for a family of policy functions.
6.1.2 Equality test for array elements
In an equality test for array elements, Alice has a private ar-
ray hx1, . . . , xni and Bob has a private array hy1, . . . , yni.
They want to learn whether there exists an index i such that
xi = yi. The result of the equality test is known to nei-
ther Alice nor Bob. We deﬁne the input and output for this
protocol in Figure 4.
This equality test can be implemented by a scrambled
circuit evaluation protocol [31, 22]. The protocol requires
O(ρ2n) communication and computation, where ρ is the
maximum bit-length of each xi and yi or the security para-
mater (whichever is larger). We give an efﬁciency improve-
ment that reduces that communication and computation re-
Input: Bob has n values hy1, y2, . . . , yni. Alice has n
values hx1, x2, . . . , xni and has two random numbers
t0 and t1.
Output: Bob learns t1 if and only if there ∃ i ∈ [1..n]
such that xi = yi, and learns t0 otherwise. Alice learns
nothing.
Figure 4. Input and output of equality test for
array elements
quirement to O(ρn) (that is of independent interest) in Sec-
tion 7.
6.2 Secure RE Strategy Protocol
The goal of the secure RE strategy protocol is to se-
curely implement the RE strategy in Figure 1. We denote
the participants of this protocol by Alice and Bob, where
Alice is either the client or the server and Bob is the oppo-
site role. In this section, we introduce a protocol to com-
pute secure-reverse-eager-strategy(CA, PA, CB, UB) (the
items subscripted by A are Alice’s values and those sub-
scripted by B are Bob’s values), where the output is UA
in the split-form described earlier. The careful reader may
notice a discrepancy between this and the RE strategy de-
ﬁned earlier. Note that in this case UB represents an array
of Boolean values marking which credentials are usable,
whereas in the previous case it represented the actual cre-
dentials. A credentials c of Alice’s is not usable if Bob’s
usable credentials do not satisfy Alice’s usability policy for
c. Figure 5 describes this protocol.
Intuiton of Correctness/Security: In Step 1 of the proto-
col, Bob will learn ti[1] if he has credential ci and he can use
it, and otherwise he learns ti[0]. Note that these values were
generated by Alice. The ﬁrst part of this (i.e., Bob has ci)
is captured by the value x; that is, Bob is able to obtain x if
and only if he has ci. Furthermore, if Bob’s credential bj is
ci, then dj = x in Step 1b. The second part of this (i.e., Bob
can use ci) is captured by the set UB; that is, Alice will have
i [0] otherwise.
i [1] if Bob can use ci can she will have rB
rB
Putting these pieces together implies that ”bj equals ci and
Bob can use bj” if and only if x + rB
j [1].
Thus the equality test for arrary elements protocol computes
the desired value.
j ] = dj + rB
j [dB
In Step 2 of the protocol Alice and Bob learn their shares
of UA, that is Alice will learn a pair (rA
i [1]) and Bob
i [1] if and only if Alice can use credential ai and
will learn rA
i [0] otherwise. Note that Alice can use cre-
he will learn rA
dential ai only if Bob’s usable credential (computed in Step
1) satisﬁes Alice’s policy for ai. However, this is exactly
i [0], rA
Input: Bob inputs: (1) a set of credentials, CB, which we denote by b1, . . . , bn and (2) his share of UB, which
n [1]). Alice inputs: (1) a set of credentials, CA, which
we denote by ordered pairs (rB
we denote by a1, . . . , am, (2) a set of policies for these credentials, PA, which we denote by p1, . . . , pm, and (3)
her share of UB, which we denote by rB
is 1 if Bob can use bi and is 0 otherwise).
1 [1]), . . . , (rB
1 [0], rB
n [0], rB
n ] (note dB
1 ], . . . , rB
n [dB
i
the updated UA which is denoted by ordered pairs
the updated UA which is denoted by
Bob learns his share of
1 [dB
share of
1 [1]), . . . , (rA
Alice
Output:
(rA
1 [0], rA
1 [dA
1 ], . . . , rA
rA
Protocol Steps:
learns her
m[0], rA
m], where dA
m[1]).
i = pi(UB).
m[dA
1. Determine which credentials in Alice’s policies Bob has and can use: Suppose that the credentials in R(PA)
are c1, . . . , ck. Alice randomly generates k ordered pairs: (t1[0], t1[1]), . . . , (tk[0], tk[1]). For each creden-
tial ci, Alice and Bob engage in the following steps:
(a) Alice picks a random number x, and sends m = I(x, ci) (the IBE encryption of x based on the hidden
credential ci) to Bob.
(b) Bob decrypts m using each of his hidden credentials, and obtains d1, . . . , dn, where di = I −1(m, bi).
(c) Alice creates a vector ~a1 = hx + rB
n ]i and Bob creates a vector ~a2 = hd1 +
n [1]i. Alice and Bob engage in an equality test protocol for array elements where
1 [1], . . . , dn + rB
rB
they each input their own array and Alice inputs ti[0] and ti[1]. At the end of the protocol, Bob obtains
ti[xi]. Note that xi is 1 if and only if ci ∈ UB and Bob has ci (that is Bob can use the credential and
he actually has it) and is 0 otherwise.
1 ], . . . , x + rB
1 [dB
n [dB
2. Compute UA: For each credential ai, Alice and Bob engage in the following steps:
(a) Alice randomly generates an ordered pair (rA
(b) Alice
i [0], rA
i [1]).
and Bob securely evaluate pi using blinded policy evaluation.
inputs
i [1]), {(t1[0], t1[1]), . . . , (tk[0], tk[1])} and Bob inputs {t1[x1], . . . , tk[xk]}. At the end
Alice
i [0], rA
pi, (rA
of the protocol Bob obtains rA
3. Alice and Bob produce UA:
1 [dA
rA
1 ], . . . , rA
m[dA
m]
1 ].
1 [dA
Alice learns
(rA
1 [0], rA
1 [1]), . . . , (rA
m[0], rA
m[1]) and Bob learns
Figure 5. Secure RE strategy protocol secure-reverse-eager-strategy(CA, PA, CB, UB)
what the blinded policy evaluation in Step 2 does.
scribe the protocol in Figure 6.
Proof of Correctness/Security: A more detailed proof
sketch is given in Section 8.
Cost analysis Steps 1(a)-1(c) are performed k times. Step
1(c) requires O(nρ2) (where ρ is a security parameter) com-
munication. Thus Step 1 requires O(knρ2) communication,
but this can be reduced to O(knρ) if the protocol in Section
7.1 is used for Step 1(c). Assuming that the policies can be
computed with circuits that are linear in the number of cre-
dentials, Step 2 requires O(mkρ) communication. Now k
is mA, n is nB, and m is nA, and so this protocol requires