imately 5.5 TOPS in total. Spatial demultiplexing adds another
1.5 TOPS. If we assume a 2 ms frame transmission time, channel
inversion needs another 269 GOPS. Adding them up, the AP will
need a processing capability to support as many as 7.27 TOPS! The
downlink is less demanding, but the estimate is still 1.7 TOPS.
These numbers are simply astronomical, far beyond the capabil-
ity of a single piece of processing hardware today (or even in the
near future given existing technology trends). As one data point for
reference, state-of-the-art multi-core CPUs or DSPs on the market
can only process on the order of 50 GOPS per chip. To build a MU-
MIMO system to handle this kind of computation load and possibly
scale up further, it will require serious thinking in the signal pro-
cessing architecture and the system design, as well as non-trivial
engineering efforts.
3. DESIGN PRINCIPLES
Our goal is to build a scalable AP architecture that can support a
large number of MIMO antennas, say tens or hundreds. Our strat-
egy to scale is to parallelize the MU-MIMO processing into many
small pieces, each of which can ﬁt into an available computing de-
vice (or a processing unit). As far as our architecture is concerned,
such a computing device can be a general purpose processor (i.e.,
CPU), DSP, FPGA, or even a custom-designed ASIC. However, as
we will show later, the speciﬁc properties of MU-MIMO and wire-
less communications have placed fundamental constraints on how
we can parallelize the processing. In this section, we start with a set
of principles that guide our practical system design.
Distributed pipeline. One simple idea for parallelization is to par-
tition the sample streams into blocks and send each block to a dif-
Figure 2: A typical frame format for MU-MIMO transmis-
sions. Each transmitter will send an orthogonal pilot symbol
for wireless channel measurement. After that, all data symbols
are transmitted together.
In the downlink direction, the M AP antennas will simultane-
ously transmit to the N antennas at the clients. Similar to the
uplink operations but reversed, the AP ﬁrst encodes the informa-
tion bits with a forward error correction (FEC) code (channel en-
coding). It also computes a pseudo-inverse of the channel matrix
H, H + = H∗(HH∗)−1. Then, for every outgoing symbol (after
channel encoding), the AP performs precoding by multiplying the
symbol with the channel inverse,
(cid:48)
X
(t) = H +X(t).
and transmits the precoded symbols instead. This way, the N re-
ceiving antennas will just receive the data symbols targeted at them-
selves, while the interference is canceled out as
Y (t) = HX
(cid:48)
(t) = HH +X(t) = X(t).
This decoding and precoding method is called zero-forcing, as it ef-
fectively removes the mutual interference among concurrent trans-
missions.
In a practical MU-MIMO system, transmissions are grouped into
frames, as shown in Figure 2. Each frame has a preamble before the
data symbols. During this preamble portion, each sender can trans-
mit a known pilot symbol orthogonally for the receivers to learn the
wireless channel H.
Although MU-MIMO is well-understood in information theory,
only small-scale MU-MIMO (i.e., M 
1000. With spatial stream partitioning, each decoding module may
only handle one spatial stream. Even with a 160 MHz wide chan-
nel, the required bandwidth (∼ 5 Gbps) may also be accommodated
easily. Accordingly, the computational requirement is reduced by
up to a factor of W for each CI or SD module and a factor of N for
each CD module.
5.2 Computation partitioning inside a server
Today’s high-end PC servers are predominantly built on shared-
memory multi-core architecture. Therefore, we can further explore
parallelism across multiple cores to speed up MU-MIMO signal
processing. In this subsection, we study the three core signal pro-
cessing algorithms used in a MU-MIMO system: 1) matrix multi-
plication, 2) matrix inversion, and 3) channel decoding, e.g., Viterbi.
Matrix multiplication. The basic idea to parallelize matrix multi-
plication is to divide the matrices into a group of small blocks, and
assign the multiplication of each block to a distinct CPU core. For
example, to compute H∗H (an intermediate step in the channel in-
version, see §2.1) with two cores, we can divide H = (H1H2)T .
Figure 4: The parallelized Viterbi decoder.
Then, the result matrix
∗
R = H
H = (H
∗
1 H
∗
2 )
(cid:19)
(cid:18) H1
H2
= (H
∗
1 H1 + H
∗
2 H2) .
Each H∗
i Hi operation can be assigned to a different CPU core and
is much less complex compared to the original matrix multiplica-
tion.
Matrix inversion. The direct way to invert a square matrix is to
use the Gauss-Jordan method. Its complexity grows with O(N 3),
where N is the size of each dimension of the matrix. Again, we
can partition the computation by assigning different sets of rows to
different CPU cores. Each core can perform Gaussian elimination
on these rows independently [7]. With N units, the computational
complexity can be reduced to O(N 2).