memory is ﬁxed at 10MB. Initially, only two virtual ma-
chines are launched and they collude with each other to
construct the covert channel. In this ﬁrst case, the stable
sleeping time is 145s and the bit rate is 17.66bps. In the
second case, we boot another two virtual machines (we call
them the irrelevant VMs) with the same conﬁguration and
keep them idle. Now the stable sleeping time is increased
to 180s and thus the bit rate is reduced to 14.44bps. To
further increase system workload, in the third case, we run
CPU intensive benchmark Cuadro [11] on the two irrelevant
VMs. Again, the bit rate drops to 11.64bps. Then we also run
the benchmark on the sender, i.e. the victim VM. This fourth
scenario is close to a real world one: the victim machine and
other co-resident machines are busy running services while
the attacker-controlled receiver can keep idle. Such a system
conﬁguration in the fourth case yields the stable sleeping
time of 225s with the bit rate of 11.38bps. In the ﬁfth case,
when we also run the benchmark on the receiver, the bit rate
drops a little again to 11.13bps. These results agree with
our assumption: increasing system workload will result in a
longer stable sleeping time and a lower bit rate. This is due
to the competition between KSM and other processes of the
0501001502002503000102030Write Access Time(microsecond)050100150200250300010203005010015020025030001020300501001502002503000102030PageFigure 3. The relationship between memory size and bit rate. The stable
sleeping time is also marked.
Figure 5. The relationship between system memory pressure and bit rate.
The stable sleeping time is also marked.
the experiments with different memory pressure. At
the
beginning, the memory usage of all virtual machines remain
medium. From Figure 5 we can see under medium memory
pressure, the achievable bit rate is decent. Then, we launch
a memory intensive benchmark LMBench [12] on those two
irrelevant VMs. The benchmark makes the virtual machines
under high memory pressure. Since our system is conﬁgured
as over-committed, the entire system suffers from a high
memory pressure. Due to the high memory pressure, the bit
rate of the channel decreases. After we run the benchmark
on the sender side as well, the stable sleeping time rises and
the bit rate drops again. Such results are expected: under
high memory pressure KSM has many more pages to scan,
which takes more time. Moreover, over-committing memory
could cause swapping, which might affect the deduplication
as well. However, even in the extreme scenario where the
system is under a memory pressure as high as in our
experiments, a 100MB memory deduplication covert channel
can still achieve a bit rate above 40bps, which is acceptable.
B. Virtualization Detection
To evaluate the effectiveness of the proposed virtualization
detection method, we conduct four groups of experiments to
cover the following four scenarios: (1) run the experiment
on the guest OS, while memory deduplication is enabled on
the host OS; (2) run the experiment on the guest OS, while
memory deduplication is disabled on the host OS; (3) run
the experiment on the host OS, while memory deduplication
is enabled on the host OS; and (4) run the experiment on
the host OS, while memory deduplication is disabled on the
host OS. On current Linux systems, we can enable KSM by
writing 1 to /sys/kernel/mm/ksm/run and disable it
by writing 0 to the same ﬁle. The KSM in the guest OS is
always turned off so as not to interfere with the KSM at the
host level.
the experiment
For each group,
is conducted in two
separate rounds. First, we load the ELF binary for apache
into memory, write to each page, and record the access
time for each page. Second, we load the same ELF binary
Figure 4.
The stable sleeping time is also marked.
The relationship between computation workload and bit rate.
system on CPU resources. The more CPU resources used
by guests, the fewer CPU cycles left for KSM to perform
deduplication.
However, from Figure 4, we can also see that the perfor-
mance of the covert channel is not severely inﬂuenced by
system workload. When the system workload increases, the
bit rate only drops slightly. Moreover, in the experiments
of the sixth case, all the virtual machines are busy running
benchmarks and we leverage 100MB memory to construct
the covert channel. Since the stable sleeping time is no more
than 320s, we can still achieve a bit rate above 80bps. This
indicates that even in a close-to-real-world scenario where
multiple users run different services on different VMs above
a single physical machine, our covert channel is still able
to transfer information in a decent rate. According to the
analysis of
[10], a real world L2 cache channel can only
achieve a bit rate around 11bps with some errors. Thus,
it is clear that our memory deduplication covert channels
outperform L2 cache covert channels.
Finally, we evaluate the performance of our covert channel
under high memory pressure. Figure 5 illustrates the dynam-
ics of the bit rate under different system memory pressure.
In this series of experiments, we boot 4 VMs and all of them
run the CPU benchmark except for the receiver. We perform
0204060801000102030405060708090100Memory Size(MB)Bit Rate (b/s)205s230s280s260s230s220s275s205s2 Idle4 Idle2Idle 2Busy   1Idle 3Busy 4 Busy        4Busy, 100MB size0102030405060708090System WorkloadBit Rate (b/s)145s180s220s225s320s230sMedium Pressure2 VMs under High Pressure   3 VMs under High Pressure0102030405060708090100System Memory PressureBit Rate (b/s)  50MB70MB90MB100MB245s555s500s570s260s480s305s270s470s600s605s505sFigure 6. Write access to apache pages on guest OS with memory
deduplication enabled on host
Figure 8. Write access to apache pages on host OS with memory
deduplication enabled
Figure 7. Write access to apache pages on guest OS with memory
deduplication disabled on host
Figure 9. Write access to apache pages on host OS with memory
deduplication disabled
into two memory regions, wait for ﬁve minutes, allowing
memory deduplication to take effect, and then for one of the
two regions, we write to each page and record the access
time.
Figures 6, 7, 8, and 9 show the results for the four
groups of experiments, respectively. In all the four ﬁgures,
the red squares represent the write access time when we
load the binary once, while the green asterisks represent the
write access time when we load the same binary twice into
memory (at two different memory regions). The size of the
apache ELF ﬁle is 468,560 bytes, indicating that it occupies
about 114 pages in memory.
In the ﬁrst scenario, the write access in the second round
should take longer time than the ﬁrst round, because of
the extra copy operation. As shown in Figure 6, the green
asterisks are clearly on top of the red squares, indicating
that our experimental results match with the analysis above.
In the other three scenarios,
the write accesses of the
two rounds should have no signiﬁcant difference. From
Figures 7, 8, and 9, we can see that in these scenarios,
there is no signiﬁcant difference between the red squares and
the green asterisks, indicating that the write access times at
different rounds are no longer distinguishable.
The third scenario deserves more explanation. We run our
program on the host OS, and Linux KSM is enabled on the
host OS. However, Linux KSM has no performance impact
upon write access, as shown in Figure 8. This is because
in the current Linux KSM implementation, page sharing is
not transparent to applications. The applications that want
to beneﬁt from Linux KSM have to explicitly invoke a
system call function madvise() to inform the kernel that their
memory can be shared. But madvise() is not called in our
experiment, and thus Linux KSM will not merge the pages
owned by the application. In other words, although Linux
KSM is on, it is not utilized by the application and thereby
producing zero impact on the application’s write accesses.
C. Kernel Integrity Monitoring
The purpose of this experiment is to demonstrate how we
utilize memory deduplication and smaps to detect rootkits
that modify kernel read-only data. We run our monitoring
program on the physical machine (host OS) and we monitor
the runtime integrity of a guest OS that is running Fedora
16.
On Linux systems, after kernel compilation, an ELF ﬁle
called vmlinux will be generated. Generally, this ﬁle includes
.text section, .data section, .rodata section, .bss section, etc.
Among these sections, the .rodata section is the one that
stores read only data such as the system call table. In fact,
the system call table is a commonly modiﬁed data structure
targeted by kernel module rootkits [13], [14], [15], [16].
By redirecting system calls from standard system call code
to malicious code, attackers can hide ﬁles, processes, and
02040608010012005101520PageWrite Access Time(microsecond)  load onceload twice02040608010012000.511.52PageWrite Access Time(microsecond)  load onceload twice02040608010012000.511.52PageWrite Access Time (microsecond)  load onceload twice02040608010012000.511.52PageWrite Access Time(microsecond)  load onceload twiceFigure 10. Kernel Read-Only Data Pages Monitoring
network connections. So, it is critical to ensure the integrity
of the system call table. We achieve this by monitoring the
.rodata section.
First, we use objcopy command to dump the .rodata
section from the vmlinux (of Fedora 16) into a small ﬁle.
We call
this ﬁle rodata ﬁle below. In our experiments,
the size of the vmlinux is 151MB; while the size of the
rodata ﬁle is 1.8MB, including 457 pages plus 1 incomplete
page in our system whose page size is 4KB. And then
we launch the virtual machine. On the host OS, we also
load the rodata ﬁle into memory (using the C program
we mentioned before). Since the rodata ﬁle is relatively
small (1.8MB), it usually takes less than one minute to
merge its identical pages. After that, we read the PSS value
corresponding to the ﬁle. As Figure 10 shows, the PSS is
918KB, i.e., PSS=(457/2+1)*4KB=918KB, where ‘1’ means
the incomplete page that will not be shared.
Later on, we port a well-known real world rootkit called
override [17], [18], [19] that hijacks several system calls by
modifying the system call table. The system calls being hi-
jacked include sys getuid(), sys geteuid(), sys getdents64(),
sys chdir(), and sys read(). After we successfully load the
rootkit as a loadable kernel module into the target Linux
kernel,
table
should become unshared 4. From Figure 10, we can see that
PSS is now 920KB, i.e., PSS=(456/2+1+1)*4KB=920KB,
the page corresponding to the system call
4In standard Fedora 16 (32-bit) kernel, there are 347 entries in the system
call table. Given the fact that one entry corresponds to 4 bytes, the whole
table occupies less than one page.
and the number of shared pages decreases from 457 to 456.
Therefore, we can infer the kernel read only data has been
modiﬁed.
Based on the experimental result above, it is evident that
our solution can effectively detect the malicious modiﬁca-
tions on the system call table. We believe that the same
mechanism will work for any kernel pages that are not
supposed to be changed during runtime.
V. DISCUSSION
When page sharing mechanism is initially proposed, it is
for the sake of saving memory. Thus, it is understandable
that
the developers might have overlooked some hidden
security issues. Based on our study, we observe that current
page sharing mechanism is practically not secure, and there-
fore we suggest to improve the page sharing mechanism for
striking a better balance between performance and security.
In the following, we ﬁrst discuss potential countermeasures
to thwart the disclosed attacks, and then discuss an issue
related to the kernel integrity monitoring technique.
A. Potential Countermeasures
To defeat covert channels, we propose to use a random
sharing scheme - merge identical pages randomly. In doing
so, in the covert channel attack scenario, the receiver will
not be able to reliably decide which pages are written by the
sender, and hence it cannot decode the information being
transferred.
In order to prevent virtualization detection, we can modify
the page sharing system so that identical pages from the
same virtual machine or the same process are not merged,
unless they are zero pages. In this manner, the attacker will
not see the write access time difference between loading
two copies of the same ﬁle into memory and just loading
one copy, because neither can induce page sharing. One
might argue that this strategy may reduce the beneﬁt of
page sharing, however, given the fact that there are already
existing mechanisms for sharing same-content pages within
a virtual machine, for example, shared libraries, we believe
the opportunities lost due to not merging (non-zero) identical
pages within a virtual machine would be minor.
B. KSM Off
As to our kernel integrity monitoring technique, one might
argue that, to eliminate false positives, when the read only
data pages have been merged, we need to turn off KSM,
which might cause a performance loss. However, this is not
necessarily true. First of all, we propose to turn off KSM
only because, from security’s perspective,
it’s the safest
way to eliminate a false positive theoretically. In practice,
whether or not turning off the KSM would not affect the
detection results. In our experiments, we never encounter
any false positives no matter whether KSM is turned off
or not. Also, in reality, since the kernel read-only data just
occupies one page, it’s easy to determine if any PSS changes
is caused by data modiﬁcation or by false positives, because
they would incur different PSS changes. Last but not least,
although KSM reduces memory usage, it increases CPU
usage. Whether KSM improves performance depends on the
type of workload; and system administrators are expected to
keep KSM on or turn it off based on their environments [20].
VI. RELATED WORK
This section brieﬂy summarizes previous work related to
covert channel construction in a virtualized environment,
virtualization detection, and kernel
integrity monitoring,
respectively.
A. Covert Channel
Ristenpart et. al [8] have succeeded in identifying co-
resident virtual machines and then launching L2-cache based
side channel attacks in a real cloud environment, i.e., Ama-
zon EC2. In fact, L2 cache channel is one of the most
widely studied covert channels. Compared with L2 cache
channel, our memory deduplication channel can achieve
higher reliability as well as higher bit rate. According to
the work done by Xu et al. [10], the optimal bit rate of
L2 cache covert channel can be around 262bps and the
achievable bit rate in EC2 is around 11bps. Our memory
deduplication covert channel can achieve 1,000bps in an