b) Feature analysis: By using gradient boosted trees, we
can measure how important individual features are to the overall
performance. As we want to make an accurate assessment for
Fig. 3. Performance metrics (mean and standard deviation) for the extended
a priori ensemble model, trained on the 2017 and a varying part of the 2018
ground truth.
Fig. 4. FNR and FPR as a function of the fraction of domains with a score
below a certain value. By choosing the maximum error rate, we determine the
fraction of domains that can be automatically classiﬁed.
to be manually classiﬁed and added to the training set at 15%, as
it represents the best trade-off between improved performance
and limited additional effort. We repeat this random selection
ten times and report average results. Table VI shows that this
extended a priori ensemble model improves on the base model.
However, some misclassiﬁcations still occur in this extended
a priori model. The gradient boosted tree model outputs a score
that reﬂects its conﬁdence in its prediction. We can leverage
these scores to develop a directed semi-automated approach:
uncertain domains are manually investigated in more detail a
posteriori. We examine how effective this approach is in further
improving performance while still reducing investigative effort.
10
010203040747678808284868890%AccuracyF1 score0102030400.00.51.01.52.02.53.03.54.0%FNRFPR0.00.20.40.60.81.0% of 2018 domains added to training set0.00.20.40.60.81.00.020.040.080.0100.055.572.9Fraction of domains (%)0.11.010.0100.00.52.0Error rate (%)Equal error rateAbove equal error rate: fully rely on automated classificationFalse negative rateFalse positive rateTABLE VII.
IMPORTANCE SCORES OF THE TOP 10 FEATURES IN THE
FULL FEATURE SET FOR THE EXTENDED A PRIORI ENSEMBLE MODEL.
TABLE VIII.
AVERAGE COVARIANCE BETWEEN FEATURES OF ONE SET,
FOR THE DOMAINS FROM THE 2017 AND 2018 ITERATIONS.
Set
WHOIS
WHOIS
WHOIS
WHOIS
WHOIS
Passive DNS Time between ﬁrst passive DNS query and takedown
Passive DNS Time between ﬁrst and last seen passive DNS query
Feature
Time between WHOIS creation and expiration date
Time between WHOIS creation and takedown date
#
14
13
21
20
11
15
34 Active DNS Days DNS record was seen for resource record MX
15
31 Active DNS
3
Popularity
Renewal of domain seen in WHOIS data (False)
Time between ﬁrst seen DNS record and AGD validity
Number of pages found in Wayback Machine
Time between WHOIS creation date and AGD validity
Renewal of domain seen in WHOIS data (Unknown)
Score
0.230
0.219
0.057
0.049
0.041
0.040
0.040
0.037
0.029
0.028
patterns, but it remains necessary for domains that lack any other
data set (but these are likely candidates for manual veriﬁcation).
Missing passive or active DNS data has a less pronounced
effect. We ﬁnd some degree of redundancy between passive
and active DNS data, as their time-based features in partic-
ular represent similar concepts and are therefore intuitively
dependent. We conﬁrm this effect with the covariance between
feature sets shown in Table VIII: passive and active DNS data
are relatively highly correlated with each other.
This effect means that passive and active DNS (as well as
WHOIS) data all capture important and hard-to-evade time-
based patterns, but that one missing data set can be substituted
by the others without a signiﬁcant loss in performance. This
becomes important when considering that data sets such as
WHOIS that lead to better performance may come with a
signiﬁcant cost to acquire. In Section VI-B, we elaborate on
the implications of our ﬁndings on future takedown operations.
d) Conclusion: We ﬁnd that an approach combining
primarily automated classiﬁcation and targeted manual investi-
gation across multiple iterations achieves the best compromise
of high accuracy and low manual effort, with less than 3%
mistakes. This reduces investigative effort by up to 76.9%,
depending on the tolerated error rate, freeing up time to focus
on those domains that are the hardest to classify.
Our analysis of features and data sets shows that time-
based features are the most important ones, which at the same
time increases the cost and difﬁculty of evading our classiﬁer.
However, our performance depends on data sources with a high
cost of acquisition, in particular WHOIS data. We continue our
discussion of these aspects in the next section.
VI. DISCUSSION
In this section, we elaborate on the factors that may
inﬂuence the applicability of our approach to future takedowns.
We ﬁrst explain how a high cost and effort for attackers
complicates the evasion of our classiﬁer and may therefore
discourage malicious actors. We then highlight how recent
developments in the availability of data sets may have a negative
impact on the performance of our approach.
A. Evasion
Previous work [38], [60] pointed out that attackers may
develop bypasses to mislead a classiﬁer like ours and therefore
evade detection and subsequent takedown of their malicious
domains, especially as we cannot rely on detecting the malicious
activity that would be required for the correct functioning of the
botnet. We discuss potential evasion strategies and how difﬁcult
Fig. 5. Cumulative distribution function of the values of benign, malicious,
false positive, and false negative domains for the time between WHOIS creation
and expiration date.
the full feature set, we calculate importance scores for the
extended model on domains where all data sets are available.
We show the ten most important features in Table VII and
ﬁnd that they primarily capture the age and activity period of
a domain. When malware creators want to evade our classiﬁer,
they would primarily want to inﬂuence these features. Figure 5
shows how the distributions of values for the most impactful
feature (time between WHOIS creation and expiration date) are
clearly distinct for benign and malicious domains. Misclassiﬁed
benign domains (false positives) actually show a ‘malicious’
character, i.e. they are young; the malicious domains in our test
set (from 2018) are never old, so other (but less expressive)
features impact whether they are classiﬁed correctly.
Consistent with our second insight from Section IV-B, time-
based features are costly and difﬁcult to evade: attackers have
to register a domain name for a longer period of time, which
translates into a higher monetary cost, and register it earlier,
which is hard to achieve retroactively. In an extreme case, the
domain name would have to be registered before the malware
family becomes active.
c) Data set comparison: We assess the impact of the
availability of each data source on our performance starting
from the extended a priori ensemble model, after which we
retrain models with one feature set omitted each time. We join
lexical, popularity-based, and Certiﬁcate Transparency features
into a joint feature set, as they are the easiest to acquire and
are always available, which leaves us with four feature sets:
joint, WHOIS, passive DNS, and active DNS.
Figure 6 illustrates the performance of the models where
one data set is discarded. We observe that missing WHOIS data
has the most severe impact, signiﬁcantly harming performance.
Discarding the joint data set may actually improve performance,
as its non-time-based features may lack sufﬁciently distinctive
11
0200040006000800010000Value in days0.00.20.40.60.81.0Fraction of domainsTruly benign 2017Truly malicious 2017Truly benign 2018Truly malicious 2018False positives 2018False negatives 2018JointPassiveDNSWHOISActiveDNSJointPassive DNSWHOISActive DNS0.220.0480.0790.0970.0480.130.050.110.0790.050.260.110.0970.110.110.430.060.090.120.150.18(a) Accuracy.
(b) F1 score.
(c) Precision.
(d) Recall.
(e) Equal error rate.
(f) Reduction in effort
(for 2% error rate).
Fig. 6. Performance metrics (mean and standard deviation, in percent) of extended a priori ensemble models where one data set is omitted.
they are for malicious actors to deploy. This proactive analysis
allows for anticipating changes in attacker behavior, developing
additional features that are even harder to circumvent and
implementing infrastructural measures that complicate evasion.
Features that leverage the properties of the DGA itself, such
as lexical features, can be evaded by redesigning DGAs. While
it is feasible to carefully engineer DGAs to be more resilient
against detection [85], such a DGA should generate domains
that appear very similar to benign domains (e.g., only short
domains). This yields a higher risk of collisions and fewer
domains available for registration, endangering uninterrupted
control of the botnet.
Popularity-based features require setting up a website for
discovery by web crawlers, and generating trafﬁc, or at least
the appearance thereof. Website popularity rankings can easily
be manipulated at scale [56], allowing attackers to insert their
domains and appear as benign. If malicious actors can have
a presence within the networks where passive DNS data is
collected, they could also insert DNS trafﬁc that makes the
domain appear regularly visited. Given that the attackers control
their infected machines, the botnet itself could be leveraged
for this purpose. However, as the trafﬁc of infected machines
can be monitored, these queries can be detected, revealing
those domains that the malicious actors have registered upfront.
Finally, the presence of certain DNS resource records can be
forged by inserting fake records, but as some records require
values of a speciﬁc format, their validity could be veriﬁed, as
maintaining valid records requires more effort.
Given recent efforts to increase the ubiquity of TLS
encryption by making free and automated TLS certiﬁcates
available [11], malicious actors can relatively easily obtain
them for malicious domains and therefore appear in Certiﬁcate
Transparency logs. However, such a process still requires
additional effort that is not strictly necessary for the correct
operation of the C&C server. While the choice to obtain a paid
certiﬁcate indicates a willingness to invest in the domain (and
therefore suggests benignness), the use of a free certiﬁcate does
not necessarily imply maliciousness.
Features that consider the age of a domain can be thwarted
by registering malicious domains (long) before they become
valid. However, it requires prolonged registrations and the
corresponding payment of registration fees, which runs counter
to minimizing the cost of the malicious campaign. Moreover,
the longer a domain with malicious intent has been registered,
whether active or dormant, the more susceptible it is to being
blacklisted/taken down or to the attackers being identiﬁed.
Acquiring and managing domains may incur a signiﬁcant
(manual) effort. If the process is automated, certain registration
patterns can emerge that make it easier to identify the mali-
ciously registered domains [86], [93]. Malicious actors might
attempt to compromise existing or reuse expired domains to
exploit the (residual) trust in these domains [57] (for example
their age). However, it would require even more effort, as they
would need to ﬁnd eligible domains, attempt to compromise
them or monitor their expiration status to take them over at
the right time, and ﬁnally deploy the malicious operation. As
domains are randomly generated by a DGA and often have a
short validity, the likelihood of success is low.
To circumvent features that use WHOIS registrant records,
malicious actors could insert forged yet realistically-looking
data. However, if these records are automatically generated,
detection becomes feasible and accurate [86], [93]. Manual
effort in creating fake records quickly becomes infeasible given
the need to keep registering domains as they become (in)valid.
In summary, while the publication of features allows for
an attacker to develop techniques to evade them, many of
these would go against the goal of malware operators to set
up these domains with low effort and at low cost. Moreover,
if the attacker behavior would signiﬁcantly shift, other evasion
countermeasures and detection strategies remain available,
although they might require increased effort and involvement
by relevant stakeholders. Finally, we ﬁnd time-based features
to be the most important ones: they are particularly costly and
hard to evade.
B. Availability of data sets
Our features come from different data sources that each
present their own issues in terms of acquisition, affecting not
only law enforcement but also adversaries seeking to evade the
model. Moreover, our evaluation of the importance of different
data sources for correctly classifying domains shows that the
data sets that contribute the most to our model’s performance
have a signiﬁcant cost in terms of money and effort.
WHOIS data in particular provides the highest accuracy, but
obtaining it may be challenging. From a technical standpoint,
WHOIS data is not machine-readable nor has a standard for-
mat [27], so it requires (sometimes manual) parsing. Moreover,
access is rate limited [59].
Public availability of WHOIS data is also affected by privacy
concerns [74] as well as strict limitations on the collection and
dissemination of personal data due to privacy regulations. This
triggered ICANN to adopt the “Temporary Speciﬁcation for
12
NoneJointPassiveDNSWHOISActiveDNSData set removed020406080100NoneJointPassiveDNSWHOISActiveDNSData set removed020406080100NoneJointPassiveDNSWHOISActiveDNSData set removed020406080100NoneJointPassiveDNSWHOISActiveDNSData set removed020406080100NoneJointPassiveDNSWHOISActiveDNSData set removed0510152025NoneJointPassiveDNSWHOISActiveDNSData set removed020406080100gTLD Registration Data”, which allows generic TLD registries
to redact personal data in WHOIS records, while having the
intent to provide vetted partners such as law enforcement
agencies with privileged access [45]. As a result of the European
General Data Protection Regulation, European country-code
TLD registries have also started to withhold personal data [29].
Security researchers have voiced concerns that the unavailability
of such data to them could signiﬁcantly hamper efforts to
identify and track malicious actors [34], [70].
Passive DNS data collection may also have privacy im-
plications [52], and requires sufﬁcient storage and processing
resources. Active DNS data collection has similar storage and
resource needs, especially to ensure that records are updated
sufﬁciently frequently. The coverage of both data sets also
depends on cooperation of third parties: passive DNS requires
access to recursive resolvers ideally deployed all over the world,
and active DNS collection often relies on zone ﬁles that must
then be shared by registries. Although law enforcement may
gain more extensive access, they may be more limited in terms
of resources, and delays in procedures to obtain data may
hamper swift action. Conversely, commercial providers that
can deploy more extensive resources may not be able to access
more sensitive information. Finally, from a cost perspective,
these commercial providers may charge signiﬁcant amounts,
especially for historical data.
We see that our approach becomes less effective if certain
data sets would be unavailable, and our discussion shows
that comprehensive coverage of data sets comes at great cost.
However, we can still achieve reasonable performance even
with missing data, and we see that data sets are partially
correlated. The continued availability of these data sets is
therefore important to counter future malicious operations, but
not to such an extent that their absence would be disrupting
the effectiveness of takedowns.
VII. RELATED WORK
a) Classiﬁers for detecting malicious domains: Numer-
ous works have addressed the problem of designing classiﬁers
to distinguish benign from malicious web pages and domains.
Ma et al. [60] classiﬁed malicious URLs based on lexical
and host-based features, comparing multiple feature sets and
classiﬁers. Felegyhazi et al. [33] designed a classiﬁer seeded
with known malicious domains that uses DNS and WHOIS
data. Antonakakis et al. [15] proposed Notos, which outputs a
reputation score based on the determination of the reputation
of domain clusters obtained from network properties, DNS
data, and the ground truth on benign and malicious domains.
Bilge et al. [19], [20] proposed Exposure, which uses DNS-
based and domain name features to detect domains contacted by
infected machines within passive DNS trafﬁc. Frosch et al. [36]
proposed Predentiﬁer, which combines passive DNS, WHOIS,
and geolocation data to detect botnet command and control
servers. Hao et al. [38] proposed PREDATOR, a classiﬁer for
malicious domains based on features available at the time of
registration and the identiﬁcation of batch registrations. Spooren
et al. [86] developed Premadoma, a model to detect malicious
domains at the time of registration, leveraging features based on
infrastructural reputation and registrant similarity, and discussed
the challenges and tactics for deploying the model in an
operational setting. Machlica et al. [61] created a model that
uses two levels of classiﬁers to improve detecting malicious
domains using lexical and trafﬁc-based features. Kidmose
et al. [48] and Zhauniarovich et al. [102] surveyed approaches
to detecting malicious domains from (enriched) DNS data.
b) Classiﬁers for detecting algorithmically generated
domains: Earlier work in detecting algorithmically generated
domains (AGDs) identiﬁed clusters of likely candidates. Yadav
et al. [99], [100] evaluated several statistical measures for
classifying groups of domains as algorithmically generated
or not based on character distributions within the domain
names and the IP addresses to which they resolve. Yadav and
Reddy [98] applied similar statistical measures on successful
and failed domain resolutions. Antonakakis et al. [16] proposed