### Fork and Similarity

If there are millions of blocks within the execution, the similarity will be much lower than 0.1. In this scenario, if the tracer incorrectly guesses the destination basic block of a control transfer, subsequent guesses will also be incorrect. This is because the branching instructions under analysis differ from the actual execution, leading to incorrect subsequent branches. This problem is not analogous to guessing a sequence of binary bits at a fixed juncture of execution. The results in Table V show that Catcher's output is actually close to the real execution.

**Table V: Similarity Measures**

| Target              | Similarity |
|---------------------|------------|
| Spyrix              | 0.51       |
| Blackbox Express    | 0.25       |
| kidlogger           | 0.74       |
| Revealer keylogger  | 0.53       |
| MyDoom              | 0.54       |
| Ratos               | 0.44       |
| HIV                 | 0.49       |
| Armadillo           | 0.70       |
| Themida             | 0.16       |
| WinUpack            | 0.61       |
| UPX                 | 0.53       |

### Evaluation of Heuristics

To evaluate the contributions of each of the five heuristics described in Section III-B, we conducted experiments to measure the accuracy of Catcher without applying one of them at a time. According to the results in Figure 7, on average, all heuristics improve precision, except for Heuristic 5 (Lost Trace Handling). Heuristics 1 and 3 might cause a slight drop in recall, but they still lead to a better F-score.

**Figure 7: Average Precisions, Recalls, and F-scores Without Different Heuristics**

Heuristic 5 is designed to re-synchronize Catcher with the target execution by leveraging the stack. It is more beneficial for recall enhancement, meaning that more executed code blocks can be traced by Catcher. The average recall in Figure 7 shows that, although Heuristic 5 causes a 0.4% drop in precision, the recall increases by nearly 20.7%.

### Performance

**Table VI: Time Cost of Different Operations**

| Operation          | Time (µs)  |
|--------------------|------------|
| CR3 fetching       | 3.9        |
| Agent switching    | 6.9/0.7    |
| Memory reading     | 1.7        |
| Block probing      | 0.8        |

1. **Overhead**: Table VI lists the tasks performed by the analyzers and agents in three phases of Catcher. In the prologue phase, the analyzer fetches the target’s CR3 by PID, which takes around 3.9 µs on average. Reading 512 bytes of memory costs around 5500 CPU cycles. The key to agent switching is modifying the CR3. When launching the agent for the first time and switching it to the target’s memory address space, we need to use the obtained CR3 to load the corresponding EPT, which takes more than 22,000 CPU cycles (6.9 µs in our experiment). We do not need to reload EPT every time in the trace phase; an agent switch without reloading EPT costs less than 0.7 µs. One probing on a basic block costs 0.8 µs.

2. **System**: We measured the slowdown caused by Catcher on SPEC2006 benchmarks [5]. We compared the performance overheads with the baseline, which refers to SPEC CPU2006 benchmarks with no Catcher running. The normalized performance cost on average is 2.89%, as shown in Figure 8.

   **Figure 8: Normalized Benchmark Run Times When Catcher is Running**

We also measured its influence on memory and cache using Cachebench [27]. It incorporates benchmarks for different cache operations like cache read, cache write, and cache read/write/modify. It also tests `memset()` and `memcpy()` from the C library. Figure 9 shows that the performance of the cache drops by about 8.16% when Catcher is introspecting a process.

   **Figure 9: Performance Decline in CacheBench**

### Discussions

#### Multithreading

Multithreading allows a process to create several threads that work in the same memory space. Shared memory address space and non-sequential execution can cause inconsistencies in cache states. Even with the same code and input, the cache states obtained vary from time to time, making it difficult to infer the control flow.

Fortunately, there is no real multithreading in Linux. The Linux kernel creates Lightweight Processes (LWPs) to simulate threads. A process containing multiple LWPs is known as a multi-threaded process. Each thread is an independent LWP with its own process identifier and can be scheduled by the kernel like a normal process. To locate a thread, we get its LWP through `PS -Lf pid`. Catcher can switch to the CR3 related to this LWP to analyze the thread.

### Conclusion

In summary, we propose a novel out-of-VM introspection technique called Catcher to trace a target process from scratch. It utilizes CPU cache to reveal the execution situation of the target without interrupting its execution. Due to its non-intrusiveness and transparency, it introduces no side effects into the system and can be applied to anti-analysis malware. Although it is not as accurate as other intrusive analysis tools, Catcher still provides practical results. Its passive monitoring mode makes the overhead negligible, and it gains an advantage in analyzing malware with anti-debugging techniques by introducing no environmental variability.

### Acknowledgment

We thank all the reviewers for their valuable suggestions. This article is partially supported by the Singapore National Research Foundation under NCR Award Number NRF2018NCR-NSOE004-0001 and the National NSF of China under Grant Nos. 61772266, 61431008.

### References

[References listed as provided, with proper formatting and citation style]

---

This optimized version improves the clarity, coherence, and professionalism of the original text.