• Managing self-presentation includes disclosing personal
information to build trust, self-censorship, audience se-
lection tools on social media, context collapse, curating
public proﬁles, and reckoning with institutional proﬁling.
• Inﬂuencing others’ S&P behaviors includes consulting
close friends and family for advice, sharing stories about
S&P events with others, nudges with social proof to in-
ﬂuence S&P behaviors, and cross-cultural considerations
for appropriate S&P advice and support.
We further segmented the social S&P these behavioral
domains into different interactive social distances, i.e., how
frequently and intensely people interact with each other [24].
Work predating the modern computing era suggests that,
across social distances, users have different levels of disclosure
and privacy preferences [25]. Across intimacy levels, there are
distinct types of interpersonal relationships, jointly construed
threat models, resources shared, social norms, collaborative
capabilities, desired access control policies, and strategies for
securing shared digital resources.
To select pertinent levels of social distance, we loosely
adapted the four “interpersonal distances of man” proposed
by Hall in his formulation of proxemics theory [18], or how
people non-verbally communicate their level of intimacy with
each other by arranging themselves in a physical environment.
Hall describes four different scales of social interaction that
are revealed through physical proximity: the intimate space
(romantic partners),
the personal space (like families and
households), the social space (e.g., acquaintances, coworkers),
and the public space. This seminal innovation continues to in-
ﬂuence work in anthropology [26] and communication theory
[27]; it is a canonical reference for work on the relationship
between social relations and interpersonal distances, even
within computing, where these scales extend beyond physical
proximity [28], [29]. For S&P behaviors speciﬁcally, as we
unpack in the sections to come, the ways romantic partners,
families and households, social acquaintances, and the public
share resources, credentials, advice, and about themselves with
each other are all distinct from one other.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:32 UTC from IEEE Xplore.  Restrictions apply. 
21864
IV. NEGOTIATING ACCESS TO SHARED RESOURCES
In this section, we consider the sharing of digital services
(Netﬂix, banking, work accounts), physical devices, and phys-
ical environments. Since many existing solutions for securing
shared resources poorly map onto ideal social access control
policies, we also discuss situations in which direct account /
password sharing is used in place of formal access control as
a means of sharing access to a protected digital resource. We
also cover work that presents design implications or entirely
new technologies focused around supporting socially nuanced
access control for jointly owned and shared digital resources.
A. Intimate relationships
Intimate partners commonly share a variety of digital de-
vices, accounts and resources, ranging from bank accounts,
media subscription services, calendars, and smart devices.
However, prior work suggests that existing models for sharing
and access control can often complicate these behaviors,
resulting in social friction, breaches of desired access control
policies, or cumbersome practices to work around technologies
designed for single-person use.
1) Content, device, and resource sharing: A number of
formative studies have examined how social practices impact
sharing among intimate partners. Jacobs et al. [30] identiﬁed
four patterns in the sharing behaviors of couples. One, in-
tentional sharing, usually occurs for practical reasons, e.g., a
shared calendar or saving money on subscriptions to media
accounts. The second, an explicit
lack of sharing, occurs
around personal laptops, search histories, and bank accounts,
usually motivated as a way for users to maintain personal
privacy and identity.2 The third, unintentional access, occurs
when participants sometimes accidentally see messages on
co-located partners’ devices. Finally, the fourth, unintentional
inhibiting of access, occurs when one partner forgets to share
a password with the other.
Alternately, Park et al. [32] presents a temporal analysis of
sharing and security behaviors across the phases of romantic
relationships. In the beginning of a relationship, partners are
uncertain about sharing, but as trust grows throughout a
relationship, partners share more with each other, including
passwords and devices. At a relationship’s end, however, revo-
cation or disabling of access to shared resources might grow to
be non-trivially tedious. Lin et al. [33] add an environmental
dimension to this timeline, ﬁnding that speciﬁcally deﬁned
relationship statuses and environments (e.g., relationship for-
mation, cohabitation, engagement/marriage) exhibit sharing
behaviors with progressive levels of risk in exposing personal
information. For example, before cohabitation, couples share
entertainment subscriptions early on. During cohabitation,
couples start sharing utilities and shopping accounts, and,
through high levels of face-to-face interactions, trust grows
(conversely, couples in long-distance relationships are less
2As a counterpoint, more recent work on smart speaker use has found that
some users who share devices with their partners feel that they had nothing
to hide, and that checking up on one another’s information via the devices is
par for the course in their relationships [31].
willing to share resources). Finally, the authors found that
engagement or marriage was associated with sharing the most
personal accounts such as ﬁnance and insurance.
On the other hand, when a relationship ends, account shar-
ing does not terminate so cleanly. Obada-Obieh [34] identiﬁed
abundant psychosocial burdens related to S&P when users
end online account sharing with others: uncertainty about
whether the sharing had actually stopped, annoyance at having
to migrate to a new account (including either possibly losing
personal content or not being able to delete all content), and
the risk of being hijacked by a sharee. And, to avoid awkward
conversation with sharees, users often fail at ending account
sharing even when the desire for such sharing had long passed.
2) Passwords: There is often a necessary conﬂation be-
tween sharing content, and sharing the authentication infor-
mation that facilitates access to the content. Even though
passwords and PINs generally come with the advice to “never
be shared”, partners do so anyway. Couples frequently share
devices, media, and ﬁnances, via password sharing, creating
joint accounts, and leaving devices unlocked on purpose [30].
Couples in Australia, for example, frequently share banking
PINs and passwords, even though banking systems ask their
customers not
to do so: married couples often have joint
accounts, for which there are only individual passwords [35].
Still, when ending account sharing, users often struggle with
password-speciﬁc issues: having to remember all the shared
users of an account, changing passwords, and remembering
which passwords were reused across accounts [34].
In other words, end users appropriate authentication meth-
ods like usernames and passwords as a simple, socially fric-
tionless form of access control. Some digital platforms directly
build this into their designs: Netﬂix accounts, among other
streaming services, are tied to an individual username and
password, but allow for multiple viewers and proﬁles.
3) Intimate partner violence: Not all intimate partners
have equal control over S&P policies and practices; indeed,
there are unfortunate cases in which one partner abuses S&P
conﬁgurations to control or stalk the other. Survivors of
intimate partner violence (IPV) often share cell phone plans
with their abusers, which allows abusers to track devices,
activate/deactivate services, and view account activity [36].
The conﬂation of trust with password sharing can also exac-
erbate IPV situations. Due to the intimacy and in-person nature
of relationships characterized by IPV, abusers can easily access
the survivor’s devices and accounts. This access is not always
seized by brute force: when the relationship is still positive,
survivors often willingly share passwords and devices, along
with information that could answer account security questions,
with their abusers because they trust them [36]. To better
organize these social-technical complexities, Matthews et al.
[37] describe a three-phase framework for organizing how
survivors of IPV make S&P decisions. Initially, survivors must
cope with regular physical access by the abuser, who may
monitor their devices and accounts or install spyware on their
devices; some survivors used alternative devices or accounts in
response. When trying to escape, some survivors deactivated
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:32 UTC from IEEE Xplore.  Restrictions apply. 
31865
accounts and destroyed their devices to hide themselves from
their abusers, making a trade-off between online privacy and
access to social support. Once they left, survivors monitored
and restricted the activities of their kids and other social
networks, blocking contacts if they might threaten their safety.
deviations from household social norms might be more to
blame than simple inﬂexibility in access control. For one, an
increase in ﬂexibility also means an increase in UI complexity;
users also relied more on existing household norms to quell
S&P conﬂicts than directly interacting with the UI controls.
B. Families and households
C. Social acquaintances
Families and households exhibit complex practices around
sharing. Past work has explored the implications of both
intended and unintended sharing within the household. Re-
garding intended sharing, Mazurek et al. [38] found that across
diverse household types (couples, roommates, families), users
have distinct ideas of what they classiﬁed as sensitive, and used
a variety of access control mechanisms to combat violations
of this sensitivity. However, users often iteratively adapt their
ideal access control policies rather than settle on the initial
ones they reported, suggesting that a priori access control
policies may be insufﬁcient within the household context [38].
Generally, device sharing is common in households, even
for personal devices like mobile phones. Household device
sharing is often characterized by a trust in sharees, i.e., not
requiring supervision over the sharee’s usage of a device or
account; if a trusted person broke expectations, they would
become less trusted and would have less access [39]. Con-
venience also inﬂuenced security behaviors; devices within
closer proximity tended to be shared more. Device type and
location within the home also inﬂuence the degree of sharing
within the household: families with more laptops tended
toward more individual usage and ownership, while desktop
computers, often placed in common areas, were shared across
the household [40]. And, as with romantic partners, households
frequently share passwords for paid resource accounts to save
money. Even users who typically do not share other passwords
still share wi-ﬁ passwords with home visitors [41].
Some technical work at this scale has explored how to
better support these social practices around intended sharing.
For example, Family Accounts, a model for user accounts
on shared home computers, proposed making documents and
settings shared by default, but allowing individual proﬁles to
personalize settings by making speciﬁc folders and documents
private to just themselves [42].
The consequences of unintended sharing afforded by shared
devices are also well-documented. Users of smart speaker de-
vices, often shared within a household, tend to have imperfect
understandings of who else in the household can access their
data [31]. Even though they are concerned about unauthorized
access to personal information via the devices, users’ mitiga-
tion strategies often either prevent them from making full use
of the speaker’s capabilities or resign themselves to exposing
their private information. These problems are exacerbated by
the fact that they tend to be purchased and associated with
one family member, but shared by the entire home [43].
Unintended access scenarios range diversely from malicious
family member access to inadvertent guest access. To address
this, Zeng and Roesner [44] designed and deployed a smart
home user interface in an in-home user study, ﬁnding that
This scale includes sharing resources within social friend
groups, but is primarily focused on workplace sharing. Within
social groups, prior work has identiﬁed social sharing of re-
sources in a variety of settings, such as digital media accounts,
physical items, computing devices, and group messages [45].
Members of social groups individually employ their per-
sonal S&P practices to combat insider and outsider threats,
trusting in other group members to protect shared resources;
however, they are also frustrated with the inefﬁcient patch-
work nature of such a strategy to represent collective S&P
preferences, especially given how diverse the aforementioned
resources are [45]. Moju-Igbene et al. [46] try to bridge this in-
efﬁciency by engaging groups of users in participatory design
workshops to envision social solutions to the access and S&P
problems they face as groups. Through these “design jams”,
the authors and groups recommend four design dimensions
to consider in future work: social transparency, or the ability
for the group to keep track of individual behaviors; stakes
and responsibility, or the distribution of responsibility and
ownership in the S&P of the shared resources; structures of
governance, i.e., the collective decision-making process; and
motivating pro-group S&P behaviors.
Beyond general social sharing of resources, we speciﬁcally
identiﬁed two domains in the workplace: sharing of digital
resources like ﬁles, mailing lists, and enterprise services; and
access control for physical environments.
1) Workplace digital resource sharing: Once again, pass-
word sharing is utilized as an easy workaround for users
to share access to resources needed for their work; the role
of passwords in these situations is similar to access sharing
behaviors found in intimate relationships and households. For
example, colleagues frequently share passwords for shared
work resources like mailing lists and digital access to journals
[41]. Users share passwords with coworkers in a number of
ways: by telling others directly, through email or Slack; writing
on a board or post-it note shared in common work areas;
using enterprise password managers; or logging into their own
accounts for others to use [47]. This sharing not only makes
it easier for coworkers to share ofﬁcial work information in a
secured environment, but also helps workplaces save money
by having fewer accounts for paid services. The practical
considerations of sharing access costs blurs the line between
common authentication methods and access control.
Some work has focused speciﬁcally on novel technologies
for workplace sharing, and presented new approaches intended
to support more ﬂexible work resource sharing. For example,
Voida et al. [48] explored a tool called the Sharing Palette,
which attempted to provide the simplicity of email, coupled
with greater visibility and control over the sharing process.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:32 UTC from IEEE Xplore.  Restrictions apply. 
41866
2) Access control for physical environments: Another
group of work at this scale has focused on physical access
control policies, and in particular, the ways that static policies
may break down with social groups. For example, adminis-
trators in an ofﬁce environment who manage access control
policies for a physical space (via swipe cards and physical
keys) have several requirements not addressed by currently
technology: (1) policies being made by multiple people, (2)
policy makers being different from policy implementers, and
(3) access control systems being unable to implement desired
policies [8]. Bauer et al. [7] compared how well physical
keys achieved users’ ideal access control policies in an ofﬁce
environment compared to a distributed smartphone system.
The smartphone system was able to meet logging, notiﬁcation,
and real-time approval conditions desired by users (which are
not supported by physical keys). As such, resource owners
have more control and ﬂexibility over access control.
Logas et al. [49] also found that when administrators of
makerspaces construct static access control polices for the
spaces, they are constrained by four dynamic factors: safety,