title:GraphSC: Parallel Secure Computation Made Easy
author:Kartik Nayak and
Xiao Shaun Wang and
Stratis Ioannidis and
Udi Weinsberg and
Nina Taft and
Elaine Shi
2015 IEEE Symposium on Security and Privacy
2015 IEEE Symposium on Security and Privacy
GraphSC: Parallel Secure Computation Made Easy
Kartik Nayak∗, Xiao Shaun Wang∗, Stratis Ioannidis†, Udi Weinsberg‡, Nina Taft◦ and Elaine Shi∗
∗University of Maryland, †Yahoo!, ‡Facebook and ◦Google
Abstract—We propose introducing modern parallel program-
ming paradigms to secure computation, enabling their secure
execution on large datasets. To address this challenge, we
present GraphSC, a framework that (i) provides a programming
paradigm that allows non-cryptography experts to write secure
code; (ii) brings parallelism to such secure implementations; and
(iii) meets the needs for obliviousness, thereby not leaking any
private information. Using GraphSC, developers can efﬁciently
implement an oblivious version of graph-based algorithms (in-
cluding sophisticated data mining and machine learning algo-
rithms) that execute in parallel with minimal communication
overhead. Importantly, our secure version of graph-based al-
gorithms incurs a small
logarithmic overhead in comparison
with the non-secure parallel version. We build GraphSC and
demonstrate, using several algorithms as examples, that secure
computation can be brought into the realm of practicality for big
data analysis. Our secure matrix factorization implementation
can process 1 million ratings in 13 hours, which is a multiple
order-of-magnitude improvement over the only other existing
attempt, which requires 3 hours to process 16K ratings.
I.
INTRODUCTION
Through their interactions with many web services, and
numerous apps, users leave behind a dizzying array of data
across the web ecosystem. The privacy threats due to the
creation and spread of personal data are by now well known.
The proliferation of data across the ecosystem is so complex
and daunting to users, that encrypting data at all times appears
as an attractive approach to privacy. However, this hinders
all beneﬁts derived from mining user data, both by online
companies and the society at
through opinion
statistics, ad campaigns, road trafﬁc and disease monitoring,
etc). Secure computation allows two or more parties to evaluate
any desirable polynomial-time function over their private data,
while revealing only the answer and nothing else about each
party’s data. Although it was ﬁrst proposed about three decades
ago [1], it is only in the last few years that the research
community has made enormous progress at improving the
efﬁciency of secure computation [2]–[6]. As such, secure
computation offers a better alternative, as it enables data
mining while simultaneously protecting user privacy.
large (e.g.,
The need to analyze data on a massive scale has led
to modern architectures that support parallelism, as well as
higher level programming abstractions to take advantage of
the underlying architecture. Examples include MapReduce [7],
Pregel [8], GraphLab [9], and Spark [10]. These provide
software developers interfaces handling inputs and parallel
data-ﬂow in a relatively intuitive and expressive way. These
programming paradigms are also extremely powerful, encom-
passing a broad class of machine learning, data mining and
graph algorithms. Even though these paradigms enable devel-
opers to efﬁciently write and execute complex parallel tasks on
†‡◦This work was done when the authors were working at Technicolor, Los
Altos.
very large datasets, they do not support secure computation.
Our goal is to bring secure computation to such frameworks in
a way that does not require programmers to have cryptographic
expertise.
The beneﬁts of integrating secure computation into such
frameworks are numerous. The potential to carry out data
analysis tasks while simultaneously not leaking private data
could change the privacy landscape. Consider a few examples.
A very common use of MapReduce is to compute histograms
that summarize data. This has been done for all kinds of
data, such as counting word frequencies in documents, sum-
marizing online browsing behavior, online medicine purchases,
YouTube viewing behavior, and so on, to name just a few.
Another common use of the graph parallelization models (e.g.,
GraphLab) is to compute inﬂuence in a social graph through,
for example, the PageRank algorithm. Today, joint inﬂuence
over multiple social graphs belonging to different companies
(such as Facebook and LinkedIn), cannot be computed because
companies do not share such data. For this to be feasible,
the companies need to be able to perform an oblivious secure
computation on their joint graph in a highly efﬁcient way that
supports their massive datasets and completes in a reasonable
time. A privacy requirement for such an application is to
ensure that the graph structure, and any associated data, is
not leaked; the performance requirements for scalability and
efﬁciency demand the application to be highly parallelizable.
A third example application is recommender systems based on
the matrix factorization (MF) algorithm. It was shown in [3]
that it is possible to carry out secure MF, enabling users to
receive recommendations without ever revealing records of
past behavior (e.g., movies watched or rated) in the clear to the
recommender system. But this previous work did not grace-
fully incorporate parallelism to scale to millions of records.
This paper addresses the following key question: can we
build an efﬁcient secure computation framework that uses
familiar parallelization programming paradigms? By creating
such a framework, we can bring secure computation to the
practical realm for modern massive datasets. Furthermore, we
can make it accessible to a wide audience of developers that are
already familiar with modern parallel programming paradigms,
and are not necessarily cryptography experts.
One naïve approach to obtain high parallelization is the
following: (a) programmers write programs using a program-
ming language speciﬁcally designed for (sequential) secure
computation such as the SCVM source language [2] or the
ObliVM source language [11]; (b) apply an existing program-
to-circuits compiler1; and (c) exploit parallelism that occurs at
the circuit level – in particular, all the gates within the same
layer (circuit depth) can be evaluated in parallel. Henceforth,
1RAM-model compilers such as SCVM [2] and ObliVM [11] effectively
compile a program to a sequence of circuits as well. In particular, dynamic
memory accesses are compiled into ORAM circuits.
© 2015, Kartik Nayak. Under license to IEEE.
© 2015, Kartik Nayak. Under license to IEEE.
DOI 10.1109/SP.2015.30
DOI 10.1109/SP.2015.30
377
377
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:55 UTC from IEEE Xplore.  Restrictions apply. 
we use the term circuit-level parallelism to refer to this baseline
approach.
While intuitive, this baseline approach is far from ideal.
The circuit derived by a sequential program-to-circuits com-
piler can also be sequential in nature, and many opportunities
to extract parallelism may remain undiscovered. We know from
experience, in the insecure environment, that generally trying
to produce parallel algorithms requires careful attention. Two
approaches have been intensely pursued (for the case of non-
secure computation): (a) Design of parallel algorithms: an
entire cottage industry has focused on designing parallel ver-
sions of speciﬁc algorithms that seek to express computation
tasks with shallow depth and without signiﬁcantly increasing
the total amount of work in comparison with the sequential
setting; and (b) Programming abstractions for parallel com-
putation: the alternative to ﬁnding point solutions for particular
algorithms, is to develop programming frameworks that help
programmers to easily extract and express parallelism. The
frameworks mentioned above fall into this category. These
two approaches can also be followed for solutions in secure
computation; examples of point solutions include [3], [4]. In
this work, we follow the second approach to enable parallel
oblivious versions for a range of data mining algorithms.
is the need to provide a solution that
There are two fundamental challenges to solve our prob-
lem. The ﬁrst
is
data oblivious, in order to prevent any information leakage
and to prevent unnecessary circuit explosion. The second is
that of migrating secure computation models to the parallel
environment in an efﬁcient way. Because our solution focuses
on graph-based parallel algorithms, we need to ensure that the
graph structure itself is not revealed.
In this paper, we focus on 2-party computation in the semi-
honest model. Our two parties could be two non-colluding
cloud providers (such as Google and Amazon) where both par-
ties have parallel computing architectures (multiple machines
with multiple cores). In this case, the data is outsourced to the
cloud providers, and within each cloud the secret data could
be distributed across multiple machines. In a second scenario,
a single cloud provider splits up the data to achieve resilience
against insider attacks or APT threats. To realize these, we
make the following novel contributions.
A. Our Contributions
We design and implement a parallel secure computation
framework called GraphSC. With GraphSC, developers can
write programs using programming abstractions similar to
Pregel and GraphLab [8], [9], [12]. GraphSC executes the
program with a parallel secure computation backend. Adopting
this programming abstraction allows GraphSC to naturally
support a broad class of data mining algorithms.
New parallel oblivious algorithms. To the best of our
knowledge, our work is the ﬁrst to design non-trivial par-
allel oblivious algorithms that outperform generic Oblivious
Parallel RAM [13]. The feasibility of the latter was recently
demonstrated by Boyle et al. [13]; however, their constructions
are of a theoretical nature, with computational costs that
would be prohibitive in a practical implementation. Analo-
gously, in the sequential literature, a line of research focuses
on designing efﬁcient oblivious algorithms that outperform
generic ORAM [14]–[17]. Many of these works focus on
speciﬁc functionalities of interest. However, such a one-at-a-
time approach is unlikely to gain traction in practice, since
real-life programmers likely do not possess the expertise
to design customized oblivious algorithms for each task at
hand; moreover, they should not be entrusted to carry out
cryptographic design tasks.
While we focus on designing efﬁcient parallel oblivious
algorithms, we take a departure from such a one-at-a-time
design approach. Speciﬁcally, we design parallel oblivious
algorithms for GraphSC’s programming abstractions, which
in turn captures a broad class of interesting data mining and
machine learning tasks. We will demonstrate this capability
for four such algorithms. Moreover, our parallel oblivious
algorithms can also be immediately made accessible to non-
expert programmers. Our parallel oblivious algorithms achieve
logarithmic overhead in comparison with the high poly-
logarithmic overhead of generic OPRAM [13]. In particular,
for a graph containing |E| edges and |V| vertices, GraphSC
just has an overhead of O(log |V|) when compared with the
parallel insecure version.
System implementation. ObliVM-GC (http://www.oblivm.
com) is a programming language that allows a programmer
to write a program that can be compiled into a garbled circuit,
so that the programmer need not worry about the underlying
cryptographic framework. In this paper, we architect and
implement GraphSC, a parallel secure computation frame-
work that supports graph-parallel programming abstractions
resembling GraphLab [9]. Such graph-parallel abstractions are
expressive and easy-to-program, and have been a popular
approach for developing parallel data mining and machine
learning algorithms. GraphSC is suitable for both multi-core
and cluster-based computing architectures. The source code of
GraphSC is available at http://www.oblivm.com.
Evaluation. To evaluate the performance of our design, we im-
plement four classic data analysis algorithms: (1) a histogram
function assuming an underlying MapReduce paradigm; (2)
PageRank for large graphs; and two versions of matrix fac-
torization, namely, (3) MF using gradient descent, and (4)
MF using alternating least squares (ALS). We study numerous
metrics, such as how the time scales with input size, with an
increasing number of processors, as well as communication
costs and accuracy. We deploy our experiments in a realistic
setting, both on a controlled testbed and on Amazon Web
Services (AWS). We show that we can achieve practical speeds
for our 4 example algorithms, and that the performance scales
gracefully with input size and the number of processors. We
achieve these gains with minimal communication overhead,
and an insigniﬁcant impact on accuracy. For example, we
were able to run matrix factorization on a real-world dataset
consisting of 1 million ratings in less than 13 hours on a
small 7-machine lab cluster. As far as we know, this is the
ﬁrst application of a complicated secure computation algorithm
on large real-world dataset; previous work [3] managed to
complete a similar task on only 17K ratings, with no ability
to scale beyond a single machine. This demonstrates that our
work can bring secure computation into the realm of practical
large-scale parallel applications.
The rest of the paper is structured as follows. Following
378378
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:55 UTC from IEEE Xplore.  Restrictions apply. 
in Section II we present GraphSC, our
the related work,
framework for parallel computation on large-scale graphs. In
Section III we detail how GraphSC can support parallel data
oblivious algorithms. Then, in Section IV, we discuss how such
parallel oblivious algorithms can be converted into parallel
secure algorithms. Section V discusses the implementation of
GraphSC and detailed evaluation of its performance on several
real-world applications. We conclude the paper in Section VI.
sequential (e.g., a narrow and deep circuit), their technique
may not be able to exploit massive degrees of parallelism. Our
design ensures GraphSC primitives are implemented as low-
depth circuits. Though our design currently works on a multi-
core processor architecture or a compute cluster, however,
conceivably, the same programming abstraction and parallel
oblivious algorithms can be directly ported to a GPU-based
backend; our work thus is complementary to Husted et al. [33].
B. Model and Terminology
Our main deployment scenario is the following parallel
secure two-party computation setting. Consider a client that
wishes to outsource computation to two non-colluding, semi-
honest cloud providers. Since we adopt Yao’s Garbled Cir-
cuits [18], one cloud provider acts as the garbler, and the other
acts as the evaluator. Each cloud provider can have multiple
processors performing the garbling or evaluation.
We adopt
the standard security notion of semi-honest
model secure computation. The two clouds do not see the
client’s private data during the course of computation. We
assume that the size information |V| + |E| is public, where
|V| is the total number of vertices and |E| is the total number
of edges. Not only can the client hide the data from the two
cloud providers, it can also hide the computation outcome –
simply by masking the computation outcome with a one-time
random secret known only to the client.
To keep terminology simple, our main algorithms in Sec-
tion III-D refers to parallel oblivious algorithms – assuming
a model where multiple processors have a shared random-
access memory. It
that once we derive parallel
oblivious algorithms, it is easy to translate them into parallel
secure computation protocols. Section IV and Figure 5 later
in the paper will elaborate on the details of our models and
terminology.
turns out
C. Related Work
Secure computation has been studied for decades, starting
from theory [18]–[22] to implementations [2], [3], [5], [6],
[23]–[29].
Parallel secure computation frameworks. Most existing
implementations are sequential. However, parallel secure com-
putation has naturally attracted attention due to the wide
adoption of multi-core processors and cloud-based compute
clusters. Note that in Yao’s Garbled Circuits [18], the garbler’s
garbling operations are trivially parallelizable: garbling is input
data independent, and essentially involves evaluating four
AES encryptions or hash functions per AND gate using free
XOR techniques [30]–[32]. However, evaluation of the garbled
circuit must be done layer by layer, and therefore, the depth
of the circuit(s) determine the degree to which evaluation can
be parallelized.
Most research on parallel secure computation just ex-
ploits the natural parallelism within each circuit or in be-
tween circuits (for performing cut-and-choose in the malicious
model). For example, Husted et al. [33] propose using a
GPU-based backend for parallelizing garbled circuit generation
and evaluation. Their work exploits the natural circuit-level
parallelism – however, in cases where the program is inherently
Kreuter et al. [6] exploit parallelism to parallel cut-and-
choose in malicious-model secure computation. In particular,
cut-and-choose techniques require the garbled evaluation of
multiple circuits, such that one can assign each circuit to a
different processor. In comparison, we focus on parallelizing
the semi-honest model. If we were to move to the malicious
model, we would also beneﬁt from the additional parallelism
natural in cut-and-choose, like Kreuter et al. [6]. Our approach
is closest to, and inspired by, the privacy-preserving matrix
factorization (MF) framework by Nikolaenko et al. [3] that
implements gradient-descent MF as a garbled circuit. As in
our design, the authors rely on oblivious sorting that, as they
note, is parallelizable. Though Nikolaenko et al. exploit this to
parallelize parts of their MF computation, their overall design
is not trivially parallelizable: it results in a Ω(|V | + |E|)-
depth circuit, containing serial passes over the data. In fact, the
algorithm in [3] is equivalent to the serial algorithm presented
in Algorithm 2, restricted to MF. Crucially, beyond extending
our implementation to any algorithm expressed by GraphSC,
not just gradient-descent MF, our design also parallelizes these
serial passes (cf. Figure 4), leading to a circuit of logarithmic
depth. Finally, as discussed in Section V, the garbled circuit
implementation in [3] can only be run on a single machine,
contrary to GraphSC.
Automated frameworks for sequential secure computation.
In the sequential setting, numerous automated frameworks for
secure computation have been explored, some of which [28],
[29] build on (a subset of) a standard language such as C;
others deﬁne customized languages [2], [23], [24], [26]. As
mentioned earlier, the circuits generated by these sequential
compilers may not necessarily have low depth. For general-
purpose secure computation backends, several protocols have
been investigated and implemented, including those based on
garbled circuits [1], [18], GMW [34], somewhat or fully homo-
morphic encryption [35], and others [36], [37]. In this paper,
we focus on a garbled circuits backend for the semi-honest
setting, but our framework and programming abstractions can
readily be extended to other backends as well.
Oblivious RAM and oblivious algorithms. Since Oblivi-
ous RAM (ORAM) was initially formulated by Goldreich
and Ostrovsky [38], numerous subsequent works [39]–[54]
improved their construction,
including the new tree-based
constructions [51]–[54] that have been widely adoped due
to their simplicity and efﬁciency. Further, efﬁcient oblivious
algorithms were studied for speciﬁc functionalities [14]–[17],
[55], [56] providing point solutions that outperform generic
ORAM. As recent works point out [2], Oblivious RAM and
oblivious algorithms are key to transforming programs into
379379
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:55 UTC from IEEE Xplore.  Restrictions apply. 
compact circuits2 – and circuits represent the computation
model for almost all known secure computation protocols.
Broadly speaking, any data oblivious algorithm admits an
efﬁcient circuit
implementation whose size is proportional
to the algorithm’s runtime. Generic RAM programs can be
compiled into an oblivious counterpart with polylogarithmic
blowup [38], [41], [47], [51], [53].
In a similar manner, Oblivious Parallel RAM (OPRAM),
proposed by Boyle et al.. [13], essentially transforms PRAM
programs into low-depth circuits, also incurring a polylogarith-
mic blowup [13]. As mentioned earlier, their work is more of a
theoretical nature and expensive in practice. In comparison, our
work proposes efﬁcient oblivious algorithms for a restricted
(but sufﬁciently broad) class of PRAM algorithms, as captured
by our GraphSC programming abstractions. As in [13], our
design tackles blowups both due to obliviousness and due to
parallelism: our secure, parallel implementation incurs only
logarithmic blowup, and is easy to implement in practice.
Parallel programming paradigms. The past decade has
given rise to parallelization techniques that are suitable to
cheap modern hardware architecture. MapReduce [7] is a
seminal work that presented a simple programming model for
processing massive datasets on large cluster of commodity
computers. This model resulted on a plethora of system-
level implementations [58] and improvements [10]. A second
advancement was made with Pregel [8], a simple programming
model for developing efﬁcient parallel algorithms on large-
scale graphs. This also resulted in several implementations,
including GraphLab [9], [12] and Giraph [59]. The simplicity
of interfaces exposed by these paradigms (like the scatter,
gather, and apply operations of Pregel) led to their widespread
adoption, as well as to the proliferation of algorithms imple-
mented in these frameworks. We introduce similar program-
ming paradigms to secure computation, in the hope that it
can revolutionize the ﬁeld like it did to non-secure parallel
programming models, thus making secure computation easily
accessible to non-experts, and easily deployable over large,
cheap clusters.
Apply(G(V, E, D), fA)
for each v in V
v.data := fA(v.data)
Scatter(G(V, E, D), fS, b)
for each e(u, v) in E
if b = “in”
e.data := fS(e.data, v.data)
else
e.data := fS(e.data, u.data)
Gather(G(V, E, D),⊕, b)
for each v in V
if b = “in”
v.data := v.data || (cid:2)
v.data := v.data || (cid:2)