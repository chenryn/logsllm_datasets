flag 产生时间差异，使用 Timeless Timing 攻击完成 XS-Leaks 。
#### 题目
题目主要有两个对象：
  * User 对象：拥有 username/password/webstie/date 属性
  * Paste 对象：拥有 pastedid/username/title/content/date 属性
题目主要功能：
  * 基础的用户注册登录功能
  * 用户可以自行创建 Paste ；用户可以自定义自己的 website 属性
  * 搜索功能：通过模糊匹配实现，但是用户传入的数据会被 escape-string-regexp 过滤。用户可以执行搜索自己的文章内容；Admin 用户则可以搜索所有用户的文章内容。
其中 admin 用户的搜索功能实现为：
    const searchRgx = new RegExp(escapeStringRegexp(word), "gi");
    // No time to implemente the pagination. So only show 5 results first.
    let paste = await Pastes.find({
        content: searchRgx,
    })
        .sort({ date: "asc" })
        .limit(5);
    if (paste && paste.length > 0) {
        let data = [];
        await Promise.all(
            paste.map(async (p) => {
                let user = await User.findOne({ username: p.username });
                data.push({
                    pasteid: p.pasteid,
                    title: p.title,
                    content: p.content,
                    date: p.date,
                    username: user.username,
                    website: user.website,
                });
            })
        );
        return res.json({ status: "success", data: data });
    } else {
        return res.json({ status: "fail", data: [] });
    }
也就是说 admin 用户搜索到对应的文章内容后，还会进一步找到对应的用户信息。
可以看到 admin 的搜索接口其实就比较符合这个背景。因为 admin 搜索接口在搜索到相关内容时，会进一步去查询 MongoDB
当中的用户信息，如果搜不到就会立马返回响应，这里就是 Timeless Timing 所需要测量的时间差值。并且我们知道 flag 就在 admin
的文章当中，所以我们只需要让 admin 查自己的文章是否包含我们查询的字符串，比如 `flag{a` 就能通过是否有时间延迟来测量出来了。
但是此时我们所处的背景环境是在浏览器当中，我们无法直接控制到报文的生成发送，这是进行 Timeless Timing
比较困难的地方。没办法控制报文同时发送就会让发出去的请求会因为各种网络抖动因素导致时间侧信道失效，所以怎么在浏览器的背景下利用 Timeless
Timing 成了我们这个题目的最大的难点。
这里我们需要用到 TCP 拥塞控制，其实应该指的是 [Nagle
算法](https://baike.baidu.com/item/Nagle算法/5645172) :
>
> Nagle算法于1984年定义为福特航空和通信公司IP/[TCP拥塞控制](https://baike.baidu.com/item/TCP拥塞控制/22718027)方法，这是福特经营的最早的专用[TCP/IP](https://baike.baidu.com/item/TCP%2FIP/214077)网络减少拥塞[控制](https://baike.baidu.com/item/控制/10102496)，从那以后这一方法得到了广泛应用。Nagle的文档里定义了处理他所谓的小包问题的方法，这种问题指的是应用程序一次产生一字节数据，这样会导致网络由于太多的包而过载（一个常见的情况是发送端的"
> **糊涂窗口综合症(Silly Window Syndrome)**
> "）。从[键盘](https://baike.baidu.com/item/键盘/208749)输入的一个字符，占用一个字节，可能在传输上造成41字节的包，其中包括1字节的有用信息和40字节的首部数据。这种情况转变成了4000%的消耗，这样的情况对于轻负载的网络来说还是可以接受的，但是重负载的福特网络就受不了了，它没有必要在经过节点和网关的时候重发，导致包丢失和妨碍传输速度。吞吐量可能会妨碍甚至在一定程度上会导致连接失败。Nagle的算法通常会在TCP程序里添加两行代码，在未确认数据发送的时候让发送器把数据送到[缓存](https://baike.baidu.com/item/缓存/100710)里。任何数据随后继续直到得到明显的数据确认或者直到攒到了一定数量的数据了再发包。尽管Nagle的算法解决的问题只是局限于福特网络，然而同样的问题也可能出现在ARPANet。这种方法在包括因特网在内的整个网络里得到了推广，成为了默认的执行方式，尽管在高互动环境下有些时候是不必要的，例如在客户/服务器情形下。在这种情况下，nagling可以通过使用TCP_NODELAY
> [套接字](https://baike.baidu.com/item/套接字/9637606)选项[关闭](https://baike.baidu.com/item/关闭/2901526)。
简单来说，在 TCP 拥堵的情况下，数据报文会被暂时放到缓存区里，然后等后续数据到了一定程度才会被发送出去。按照这个理论，只要我们能够把 TCP
阻塞到一定程度即可让我们的报文放到缓存区中从而使得我们的两个搜索请求放到一个 TCP 报文当中了。
如何让 TCP 产生拥堵呢？在浏览器里我们能进行的操作并不多，最简单最直接的就是直接发送 POST 一个过大 body 的 HTTP 请求即可。
所以，到这里我们基本可以知道怎么去解题了。只需要提交一个页面链接，该页面会进行使用 JavaScript 进行以下操作：
  1. Post 过大的 body 到任意接受 POST 的路由进而阻塞整个 TCP 信道
  2. 使用两个`fetch`向搜索接口发送我们需要探测的字符串，此时系统检测到 TCP 信道存在阻塞，会将这两个请求放入到缓冲区，从而放入到一个 TCP 报文当中
  3. 使用`Promise.all`或者其他方法检测这两个 fetch 哪一个先被返回
  4. 重复以上步骤，每对字符串请求以 10 次或 20 次为一轮，统计每轮请求中对应字符的返回顺序优先关系得到概率，进行多轮（最好大于等于 4 轮）探测
  5. 根据我们得到的结果频率为依据判断我们探测的字符
#### 解题
    from flask import Flask,render_template,request,
    app = Flask(__name__)
    @app.route('/')
    def index():
        word = request.args.get('word')
        return render_template('index.html',word="TQLCTF{%s"%word)
    @app.route('/result',methods=['GET'])
    def check():
        word = request.args.get('word')
        ms = request.args.get('ms')
        print('%s,%s'%(word,ms))
        return "asd"
    if __name__ == '__main__':
        app.run(host="0.0.0.0",port=5001)
        Document
将flask服务器架设起来接收结果。
打开burp用测试器爆破，提交架设的页面让bot去访问，Payload选择小写字母和数字(因为flag只有八位小写字母和数字)，爆破完一位往flask代码里再加一位就好了。
## 5 总结
  * Timeless timing攻击不受网络抖动因素的影响
  * 远程的计时攻击具有与本地系统上的攻击者相当的性能
  * 可以针对具有多路复用功能的协议发起攻击或利用启用封装的传输协议
  * 所有符合标准的协议都可能受到Timeless timing attck：在实际场景下我们创建了针对 HTTP/2 和 EAP-pwd (Wi-Fi) 的攻击
## 6 拓展与延申
论文中提到，在HTTP/2协议的情况下，我们可以利用多路封装协议来完成timeless timing
attck；但目前主流网络环境仍使用HTTP/1.1，所以出了论文中提到的基于报文封装的限制性较大的方法，还有没有办法能够在HTTP/1.1协议下完成Timeless
timing attck呢？
我们可以考虑HTTP/1.1的pipeline，这是HTTP持续连接的工作方式之一，其特点是客户在收到HTTP的响应报文之前就能够接着发送新的请求报文。于是一个接一个的请求报文到达服务器后，服务器就可持续发回响应报文。
总结一下特点：
  1. 由于pipeline是强制顺序响应的，那么其请求和响应的顺序是强制固定的
  2. 服务端在接受pipeline的请求时以单一线程对其进行分割并进行处理，只有请求1处理完成后才会处理请求2
pipeline是单线程顺序处理，那么就算时间有延迟我们也难以发现，这种情况下可以考虑放大。
**既然pipeline是单线程，那么我就利用pipeline单线程不断的处理同一个请求，假如请求A和请求B的执行时间差异1ms，那么请求A*1000和请求B*1000的整个时间差异就可以达到1秒！**
但实际情况下我们并不能进行无限制的放大。在实际的场景里，pipeline的最大处理请求数受到服务器中间件的配置影响，比如apache里默认在启用keepalive的情况下会设置pipeline最大支持请求为100个。
当然，如果响应里keepalive只有一个timeout并没有max的情况下则意味着其没有对pipeline数量进行限制，那么也就是说我们的放大场景是存在的这时候只要无限的构造pipeline请求就可以无限叠加倍率。
这样我们就可以在HTTP/1.1的场景下使用，虽然这样的站点不是很多但也算是另辟蹊径。
参考