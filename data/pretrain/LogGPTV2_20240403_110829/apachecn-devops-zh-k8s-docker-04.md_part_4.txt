要指出的主要是输出的`Spec`部分。这列出了可能安装以支持后端存储系统的任何驱动程序的详细信息。由于我们没有后端存储系统，因此不需要在群集上安装额外的驱动程序。
为了展示节点将列出的内容，下面是安装了两个驱动程序的集群的输出，支持两种不同的供应商存储解决方案:
![Figure 4.10 – Multiple driver example ](img/Fig_4.10_B15514.jpg)
图 4.10–多驱动示例
如果你查看这个节点的`spec.drivers`部分，你会看到两个不同的名称部分。第一个显示我们安装了支持 NetApp SolidFire 的驱动程序，而第二个是支持 Reduxio 的 stora ge 解决方案的驱动程序。
## 存储驱动程序
正如我们已经提到的，您的 KinD 集群没有安装任何额外的存储驱动程序。如果执行`kubectl get csidrivers`，应用编程接口将不会列出的任何资源。
## KinD 存储类
要将附加到任何群集提供的存储，群集需要一个`StorageClass`对象。Rancher 的提供程序创建了一个名为 standard 的默认存储类。它还将类设置为默认的`StorageClass`，因此您不需要在您的聚氯乙烯请求中提供`StorageClass`名称。如果没有设置默认的`StorageClass`，每个聚氯乙烯请求都需要一个`StorageClass`的名字。如果未启用默认类，并且聚氯乙烯请求未能设置`StorageClass`名称，聚氯乙烯分配将失败，因为应用编程接口服务器将无法将请求链接到`StorageClass`。
注意
在生产集群上，省略分配默认`StorageClass`被认为是一种好的做法。根据您的用户，您可能有忘记设置类别的部署，默认存储系统可能不适合部署需求。这个问题可能不会发生，直到它成为一个生产问题，这可能会影响业务收入或公司的声誉。如果您不分配默认类，开发人员将有一个失败的聚氯乙烯请求，这个问题将在业务受到任何损害之前被发现。
要列出集群上的存储类，请执行`kubectl get storageclasses`，或者使用缩短版本，用`sc`代替`storageclasses`:
![Figure 4.11 – Default storage class ](img/Fig_4.11_B15514.jpg)
图 4.11–默认存储类别
接下来，让我们学习如何使用置备程序。
## 使用 KinD 的存储供应程序
使用附带的置备程序非常简单。由于它可以自动调配存储并被设置为默认类，任何进入的聚氯乙烯请求都会被调配窗格看到，然后创建`PersistentVolume`和`PersistentVolumeClaim`。
为了展示这个过程，让我们通过必要的步骤。以下是在基本 KinD 集群上运行`get pv`和`get pvc`的输出:
![Figure 4.12 – PV and PVC example ](img/Fig_4.12_B15514.jpg)
图 4.12–光伏和聚氯乙烯示例
请记住`PersistentVolume`不是命名空间对象，因此我们不需要在命令中添加命名空间选项。PVC 是命名空间对象，所以我告诉 Kubernetes 向我展示所有命名空间中可用的 PVC。由于这是一个新群集，并且没有默认工作负载需要持久磁盘，因此没有 PV 或 PVC 对象。
如果没有自动资源调配器，我们需要先创建一个 PV，然后 PVC 才能申请卷。由于我们的集群中运行了 Rancher provisioner，因此我们可以通过部署一个带有 PVC 请求的 pod 来测试创建过程，如下所示:
```
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: test-claim
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Mi
---
kind: Pod
apiVersion: v1
metadata:
  name: test-pvc-claim
spec:
  containers:
  - name: test-pod
    image: busybox
    command:
      - "/bin/sh"
    args:
      - "-c"
      - "touch /mnt/test && exit 0 || exit 1"
    volumeMounts:
      - name: test-pvc
        mountPath: "/mnt"
  restartPolicy: "Never"
  volumes:
    - name: test-pvc
      persistentVolumeClaim:
        claimName: test-claim
```
这个聚氯乙烯请求将在默认命名空间中被命名为`test-claim`，并且它正在请求一个 1 MB 的卷。我们确实需要包含`StorageClass`选项，因为 KinD 已经为集群设置了默认的`StorageClass`。
要创建 PVC，我们可以使用 kubectl 执行一个`create`命令，比如`kubectl create -f pvctest.yaml`–Kubernetes 将返回，说明 PVC 已经创建，但需要注意的是，这并不意味着 PVC 已经完全工作。聚氯乙烯对象已经创建，但如果聚氯乙烯请求中缺少任何依赖项，它仍将创建该对象，尽管它将无法完全创建聚氯乙烯请求。
创建聚氯乙烯后，您可以使用两个选项之一来检查真实状态。第一个是简单的`get`命令；也就是`kubectl get pvc`。因为我的请求在默认的名称空间中，所以我不需要在`get`命令中包含名称空间值(注意，我们必须缩短卷的名称，以便它适合页面):
```
NAME         STATUS          VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
test-claim   Bound    pvc-9c56cf65-d661-49e3-         1Mi            RWO          standard     2s
```
我们知道我们在清单中创建了一个 PVC 请求，但是我们没有创建 PV 请求。如果我们现在查看 PV，我们会看到单个 PV 是根据我们的 PVC 请求创建的。同样，我们缩短了 PV 名称，以便将输出放在一行中:
```
NAME                   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM
pvc-9c56cf65-d661-49e3-   1Mi          RWO           Delete       Bound    default/test-claim
```
这就完成了 KinD 存储部分。
由于如此多的工作负载需要持久磁盘，了解 Kubernetes 工作负载如何与存储系统集成非常重要。在本节中，您学习了 KinD 如何向群集添加自动资源调配器。我们将在下一章 [*第五章*](05.html#_idTextAnchor150) *，库本 etes Bootcamp* 中强化我们对这些 Kubernetes 存储对象的了解。
# 为入口添加自定义负载平衡器
注意
这一节是一个复杂的主题涉及添加一个自定义的 HAProxy 容器，您可以使用它来负载平衡 KinD 集群中的工作节点。*您不应该将这些步骤部署在我们将在其余章节中使用的 KinD 集群上。*
我们添加了这一部分，供任何想了解更多关于如何在多个工作节点之间进行负载平衡的人使用。
KinD 不包括工作节点的负载平衡器。包含的 HAProxy 容器只为 API 服务器创建一个配置文件；该团队不正式支持对默认映像或配置的任何修改。由于您将在日常工作中与负载平衡器进行交互，我们希望添加一节，介绍如何配置自己的 HAProxy 容器，以便在三个 KinD 节点之间实现负载平衡。
首先，我们不会在本书的任何章节中使用这种配置。我们希望每个人都可以使用这些练习，因此为了限制所需的资源，我们将始终使用我们在本章前面创建的双节点集群。如果你想用负载均衡器测试 KinD 节点，我们建议使用不同的 Docker 主机，或者等到你读完这本书，删除你的 KinD 集群。
## 安装先决条件
我们假设您有一个基于以下配置的 KinD 集群:
*   任意数量的控制平面节点
*   三个工作节点
*   集群名为`cluster01`
*   **金网或印花布** ( **CNI** )的工作版本
*   NGINX 入口控制器已安装–已打补丁监听主机上的端口 80 和 443
## 创建 KinD 集群配置
由于您将使用在 Docker 主机的端口 80 和 443 上公开的 HAProxy 容器，因此您不需要公开集群`config`文件中的任何端口。
为了使测试部署更容易，您可以使用这里显示的示例集群配置，它将创建一个简单的六节点集群，并禁用 Kindnet:
```
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
  apiServerAddress: "0.0.0.0"
  disableDefaultCNI: true
kubeadmConfigPatches:
- |
  apiVersion: kubeadm.k8s.io/v1beta2
  kind: ClusterConfiguration
  metadata:
    name: config
  networking:
    serviceSubnet: "10.96.0.1/12"
    podSubnet: "192.168.0.0/16"
nodes:
- role: control-plane
- role: control-plane
- role: control-plane
- role: worker
- role: worker
- role: worker
```
您需要使用我们在本章前面使用的相同清单来安装 Calico。安装 Calico 后，需要按照本章前面提供的步骤安装 NGINX 入口控制器。
一旦您部署了 Calico 和 NGINX，您应该有一个工作的基础集群。现在，您可以继续部署 custo m HAProxy 容器了。
## 部署定制的 HAProxy 容器
HAProxy 在 Docker Hub 上提供了一个易于部署的容器，只需要一个配置文件就可以启动容器。
要创建配置文件，您需要知道集群中每个工作节点的 IP 地址。在本书的 GitHub 存储库中，我们包含了一个脚本文件，它将为您找到这些信息，创建配置文件，并启动 HAProxy 容器。它位于`HAProxy`目录下，叫做`HAProxy-ingress.sh`。
为了帮助您更好地理解这个脚本，我们将分解脚本的各个部分，并详细说明每个部分正在执行什么。首先，下面的代码块获取集群中每个工作节点的 IP 地址，并将结果保存在一个变量中。后端服务器列表需要这些信息:
```
 #!/bin/bash
worker1=$(docker inspect --format '{{ .NetworkSettings.IPAddress }}' cluster01-worker)
worker2=$(docker inspect --format '{{ .NetworkSettings.IPAddress }}' cluster01-worker2)
worker3=$(docker inspect --format '{{ .NetworkSettings.IPAddress }}' cluster01-worker3)
```
接下来，因为我们将在启动容器时使用绑定挂载，所以我们需要将配置文件放在一个已知的位置。我们选择将其存储在当前用户的个人文件夹中，位于名为`HAProxy`的目录下:
```
# Create an HAProxy directory in the current users home folder
mkdir ~/HAProxy
```
接下来，脚本的以下部分将创建`HAProxy`目录:
```
# Create the HAProxy.cfg file for the worker nodes
tee ~/HAProxy/HAProxy.cfg <<EOF
```
配置的`global`部分设置整个流程的安全性和性能设置:
```
global
  log /dev/log local0
  log /dev/log local1 notice
  daemon
```
`defaults`部分用于配置将应用于配置值中所有前端和后端部分的值: