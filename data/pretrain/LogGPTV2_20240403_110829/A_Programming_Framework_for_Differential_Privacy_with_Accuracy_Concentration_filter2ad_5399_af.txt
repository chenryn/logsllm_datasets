differential privacy for SQL queries,” PVLDB, vol. 11, no. 5,
2018.
[12] D. Zhang, R. McKenna, I. Kotsogiannis, M. Hay, A. Machanava-
jjhala, and G. Miklau, “EKTELO: A framework for deﬁning
differentially-private computations,” in Proc. International Con-
ference on Management of Data, 2018.
[13] H. Zhang, E. Roth, A. Haeberlen, B. C. Pierce, and A. Roth,
“Fuzzi: A three-level logic for differential privacy,” in Proc. ACM
SIGPLAN International Conference on Functional Programming
(ICFP’19), 2019.
[14] A. Machanavajjhala, D. Kifer, J. M. Abowd, J. Gehrke, and
L. Vilhuber, “Privacy: Theory meets practice on the map,” in
Proc. International Conference on Data Engineering, ICDE,
2008.
[15] P. Mohan, A. Thakurta, E. Shi, D. Song, and D. E. Culler,
“GUPT: privacy preserving data analysis made easy,” in Proc.
ACM SIGMOD International Conference on Management of
Data, SIGMOD, 2012.
[16] D. J. Mir, S. Isaacman, R. C´aceres, M. Martonosi, and R. N.
Wright, “DP-WHERE: differentially private modeling of human
mobility,” in Proc. IEEE International Conference on Big Data,
2013.
[17] M. Gaboardi, J. Honaker, G. King, K. Nissim, J. Ullman, and
S. P. Vadhan, “PSI (Ψ): a private data sharing interface,” CoRR,
vol. abs/1609.04340, 2016.
[18] C. Ge, X. He, I. F. Ilyas, and A. Machanavajjhala, “APEx:
Accuracy-aware differentially private data exploration,” in Proc.
International Conference on Management of Data, 2019.
[19] D. P. Dubhashi and A. Panconesi, Concentration of measure for
the analysis of randomized algorithms. Cambridge University
Press, 2009.
[20] C. Dwork and A. Roth, “The algorithmic foundations of
differential privacy,” Foundations and Trends in Theoretical
Computer Science, vol. 9, no. 3-4, pp. 211–407, 2014.
[21] C. Dwork, G. N. Rothblum, and S. P. Vadhan, “Boosting
and differential privacy,” in 51th Annual IEEE Symposium on
Foundations of Computer Science, FOCS, 2010, pp. 51–60.
[22] G. Barthe, M. Gaboardi, B. Gr´egoire, J. Hsu, and P. Strub, “A
program logic for union bounds,” in International Colloquium
on Automata, Languages, and Programming, ICALP, ser. LIPIcs,
vol. 55. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik,
2016.
[23] A. Sabelfeld and A. C. Myers, “Language-Based Information-
Flow Security,” IEEE J. Selected Areas in Communications,
vol. 21, no. 1, pp. 5–19, Jan. 2003.
[24] D. Schoepe, M. Balliu, B. C. Pierce, and A. Sabelfeld, “Ex-
plicit secrecy: A policy for taint tracking,” in IEEE European
Symposium on Security and Privacy, 2016, pp. 15–30.
[25] P. Li and S. Zdancewic, “Arrows for secure information ﬂow,”
Theoretical Computer Science, vol. 411, no. 19, pp. 1974–1994,
2010.
[26] A. Russo, K. Claessen, and J. Hughes, “A library for light-weight
information-ﬂow security in Haskell,” in Proc. ACM SIGPLAN
Symp. on Haskell. ACM Press, 2008.
[27] C. Smith, J. Hsu, and A. Albarghouthi, “Trace abstraction modulo
probability,” PACMPL, vol. 3, no. POPL, 2019.
[28] F. McSherry and R. Mahajan, “Differentially-private network
trace analysis,” ACM SIGCOMM Computer Communication
Review, vol. 41, no. 4, pp. 123–134, 2011.
[29] G. Barthe, M. Gaboardi, E. J. G. Arias, J. Hsu, C. Kunz, and
P. Strub, “Proving differential privacy in Hoare logic,” in Proc.
IEEE Computer Security Foundations Symposium, 2014.
[30] C. Li, G. Miklau, M. Hay, A. McGregor, and V. Rastogi, “The
matrix mechanism: optimizing linear counting queries under
differential privacy,” VLDB J., vol. 24, no. 6, 2015.
[31] M. Hay, V. Rastogi, G. Miklau, and D. Suciu, “Boosting the
accuracy of differentially private histograms through consistency,”
PVLDB, vol. 3, no. 1, 2010.
[32] X. Xiao, G. Wang, and J. Gehrke, “Differential privacy via
wavelet transforms,” IEEE Trans. Knowl. Data Eng., vol. 23,
no. 8, 2011.
[33] M. Hay, A. Machanavajjhala, G. Miklau, Y. Chen, and D. Zhang,
“Principled evaluation of differentially private algorithms using
DPBench,” in Proceedings of the 2016 International Conference
on Management of Data, SIGMOD Conference 2016, San
Francisco, CA, USA, June 26 - July 01, 2016, 2016.
[34] H. Ebadi and D. Sands, “Featherweight PINQ,” Privacy and
Conﬁdentiality, vol. 7, no. 2, 2017.
[35] E. Moggi, “Notions of computation and monads,” Inf. Comput.,
vol. 93, no. 1, pp. 55–92, 1991.
[36] D. Terei, S. Marlow, S. L. Peyton Jones, and D. Mazi`eres, “Safe
Haskell,” in Proceedings of the 5th ACM SIGPLAN Symposium
on Haskell, Haskell 2012, Copenhagen, Denmark, 13 September
2012, 2012, pp. 137–148.
[37] R. A. Eisenberg, D. Vytiniotis, S. L. Peyton Jones, and
S. Weirich, “Closed type families with overlapping equations,”
in The ACM SIGPLAN-SIGACT Symposium on Principles of
Programming Languages, 2014.
[38] A. Narayan and A. Haeberlen, “DJoin: Differentially private
join queries over distributed databases,” in 10th USENIX
Symposium on Operating Systems Design and Implementation,
OSDI. USENIX Association, 2012.
[39] J. Blocki, A. Blum, A. Datta, and O. Sheffet, “Differentially
private data analysis of social networks via restricted sensitivity,”
in Innovations in Theoretical Computer Science, ITCS, 2013.
[40] N. M. Johnson, J. P. Near, and D. Song, “Towards practical
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
424
differential privacy for SQL queries,” PVLDB, vol. 11, no. 5,
2018.
[41] A. Russo, “Functional Pearl: Two Can Keep a Secret,
if
One of Them Uses Haskell,” in Proc. of the ACM SIGPLAN
International Conference on Functional Programming. ACM,
2015.
[42] T.-H. H. Chan, E. Shi, and D. Song, “Private and continual
release of statistics,” ACM Transactions on Information and
System Security (TISSEC), vol. 14, no. 3, p. 26, 2011.
[43] G. Barthe, M. Gaboardi, B. Gr´egoire, J. Hsu, and P. Strub,
“Proving differential privacy via probabilistic couplings,” in Proc.
ACM/IEEE Symposium on Logic in Computer Science, 2016.
[44] M. Hardt, K. Ligett, and F. McSherry, “A simple and practical
algorithm for differentially private data release,” in Advances
in Neural Information Processing Systems 25: 26th Annual
Conference on Neural Information Processing Systems, 2012.
[45] M. Hardt and K. Talwar, “On the geometry of differential privacy,”
in Proc. of the 42nd ACM Symposium on Theory of Computing,
STOC, 2010.
[46] A. Nikolov, K. Talwar, and L. Zhang, “The geometry of
differential privacy:
the sparse and approximate cases,” in
Symposium on Theory of Computing Conference, STOC’13, 2013.
[47] D. Proserpio, S. Goldberg, and F. McSherry, “Calibrating data
to sensitivity in private data analysis,” PVLDB, vol. 7, no. 8,
2014.
[48] I. Kotsogiannis, Y. Tao, X. He, M. Fanaeepour, A. Machanava-
jjhala, M. Hay, and G. Miklau, “PrivateSQL: A differentially
private SQL query engine,” Proc. VLDB Endow., vol. 12, no. 11,
pp. 1371–1384, Jul. 2019.
[49] K. Nissim, S. Raskhodnikova, and A. D. Smith, “Smooth
sensitivity and sampling in private data analysis,” in Proc. Annual
ACM Symposium on Theory of Computing, 2007.
[50] J. P. Near, D. Darais, C. Abuah, T. Stevens, P. Gaddamadugu,
L. Wang, N. Somani, M. Zhang, N. Sharma, A. Shan, and
D. Song, “Duet: An expressive higher-order language and linear
type system for statically enforcing differential privacy,” Proc.
ACM Program. Lang., vol. 3, no. OOPSLA, Oct. 2019.
[51] A. Albarghouthi and J. Hsu, “Synthesizing coupling proofs of
differential privacy,” PACMPL, vol. 2, no. POPL, 2018.
[52] Y. Wang, Z. Ding, G. Wang, D. Kifer, and D. Zhang, “Proving
differential privacy with shadow execution,” in Proc. ACM
SIGPLAN Conference on Programming Language Design and
Implementation, 2019.
[53] G. Barthe, N. Fong, M. Gaboardi, B. Gr´egoire, J. Hsu, and
P. Strub, “Advanced probabilistic couplings for differential
privacy,” in Proc. ACM SIGSAC Conference on Computer and
Communications Security, 2016.
[54] K. Ligett, S. Neel, A. Roth, B. Waggoner, and Z. S. Wu,
“Accuracy ﬁrst: Selecting a differential privacy level for accuracy-
constrained ERM,” CoRR, vol. abs/1705.10829, 2017.
[55] I. Mironov, “R´enyi differential privacy,” in 2017 IEEE 30th
IEEE, 2017.
[56] C. Dwork and G. N. Rothblum, “Concentrated differential
Computer Security Foundations Symposium (CSF).
privacy,” arXiv preprint arXiv:1603.01887, 2016.
[57] M. Bun and T. Steinke, “Concentrated differential privacy:
Simpliﬁcations, extensions, and lower bounds,” in Theory of
Cryptography Conference. Springer, 2016.
[58] M. Bun, C. Dwork, G. N. Rothblum, and T. Steinke, “Compos-
able and versatile privacy via truncated cdp,” in Proceedings
of the 50th Annual ACM SIGACT Symposium on Theory of
Computing. ACM, 2018, pp. 74–86.
[59] B. Balle and Y.-X. Wang, “Improving the gaussian mechanism
for differential privacy: Analytical calibration and optimal
denoising,” arXiv preprint arXiv:1805.06530, 2018.
[60] J. Thaler, J. Ullman, and S. P. Vadhan, “Faster algorithms for
privately releasing marginals,” in Automata, Languages, and
Programming - 39th International Colloquium, ICALP, 2012,
pp. 810–821.
[61] M. Gaboardi, E. J. G. Arias, J. Hsu, A. Roth, and Z. S. Wu,
“Dual query: Practical private query release for high dimensional
data,” in Proc. International Conference on Machine Learning,
ICML, 2014.
[62] G. Cormode, T. Kulkarni, and D. Srivastava, “Marginal release
under local differential privacy,” in Proc. of International
Conference on Management of Data, SIGMOD, 2018, pp. 131–
146.
A. Primitive dpPart and disjoint datasets
APPENDIX
1 q ::  → [Color] → Data 1 Double
2 → Query (Map Color Double)
3 q eps bins dataset = dpPart id dataset dps
4 where dps = fromList [(c, λds → dpCount eps dataset)
5
6
-- dps = fromList [(c, λds → dpCount eps ds
| c ← bins]
Fig. 10: DP-histograms by using dpPart
We present the code in Figure 10. Query q produces a -
DP histogram of the colors found in the argument dataset,
which rows are of type Color and variable bins enumerates
all the possible values of such type. The code partitions the
dataset by using the function id:: Color → Color (line 2) and
executes the aggregation counting query (dpCount) in each
partition (line 3)—function fromList creates a map from a
list of pairs. The attentive reader could notice that dpCount
is applied to the original dataset rather than the partitions.
This type of errors could lead to break privacy as well as
inconsistencies when estimating the required privacy budget.
A correct implementation consists on executing dpCount on
the corresponding partition as shown in the commented line 4.
The IFC analysis assigns the provenance of dataset in
q to the top-level fragment of the query rather than to sub-
queries executed in each partition—and DPella will raise an
error at compile time when ds is accessed by the sub-queries!
Instead, if we comment line 3 and uncomment line 4, the
query q is successfully run by DPella (when there is enough
privacy budget) since every partition is only accessing their
own partitioned data (denoted by variable ds).
B. Taint analysis example
Figure 11 presents the query plan totalCount which
adds the results of hundred dpCount queries over different
datasets, namely ds1, ds2, . . . , ds100. (The ... denotes code
intentionally left unspeciﬁed.) The code calls the primitive add
with the results of calling dpCount. (We use [x1, x2, x3 ] to
denote the list with elements x1, x2, and x3.) What would it
be then the theoretical error of totalCount? The accuracy
calculation depends on whether all the values are untainted
in line 7. When no dependencies are detected between v1, v2,
. . . , v100, namely all the values are untainted, DPella applies
Chernoff bound in order to give a tighter error estimation.
Instead, for instance, if v3 were computed as an aggregation
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
425
1 totalCount :: Query (Value Double)
2 totalCount = do
3
4
5
6
7
v1 ← dpCount 0.3 ds1
v2 ← dpCount 0.25 ds2
v100 ← dpCount 0.5 ds100
return (add [v1, v2, . . , v100 ])
...
Fig. 11: Combination of sub-queries results
NORM-INF
vj = S[iCDFj, sj, tsj]
n )|}j=1...n
iCDF = λβ → max {|iCDFj(
norm∞ [v1, v2, ..., vn ] (cid:6) S[iCDFM, 0,∅]
β
NORM-1
vj = S[iCDFj, sj, tsj]
iCDF = λβ → n(cid:2)
norm1 [v1, v2, ..., vn ] (cid:6) S[iCDF, 0,∅]
j=1
|iCDFj(
β
n )|
Fig. 12: Calculation of norms
of v1 and v2, e.g., let v3 = add [v1, v2 ], then line 7 applies
union bound since v3 is a tainted value. With taint analysis,
DPella is capable to detect dependencies among terms of
type Value Double, and leverages that information to apply
different concentrations bounds.
C. Norms calculation
Figure 12 shows our static analysis when computing norm∞
and norm1, respectively. There is nothing special about the
rules except to note that the results are symbolic values which
are tainted. The reason for that is that norms are designed to
condense (in one measure) the error of the list of the arguments.
By doing so, it is hard to assign an speciﬁc Laplace distribution
with sensitivity s to the overall given vector. We simply say
that the return symbolic values are tainted—thus they can only
be aggregated by ADD-UNION in Figure 7.
D. Accuracy for dpMax
Figure 13 shows the iCDF computed by dpMax, which aligns
with the one appearing in [22]. Observe that the return value
is tainted. The reason for that relies in the fact that the result,
which is one of the responses in res, contains no noise—it is
rather the process that lead to determining the winning response
which has been “noisy.” In this light, no scale of noise nor
distribution can be associated to the response—as we did, for
instance, with dpCount.
DPCOUNT
ds :: Data 1 r
iCDF = λβ → 4

· log(
length res
)
β
dpMax  res vote ds (cid:5) S[iCDF, 0,∅]
Fig. 13: iCDF implemented by dpMax
(cid:6)
DPCOUNT
ds :: Data s r
iCDF = λβ → σ ·
σ = s · 1 ·
(cid:6)
2 · log(2/β)
2 · log(1.25/δ)/
t fresh
dpCount  ds (cid:5) S[iCDF, σ2,{t}]
Fig. 14: Accuracy analysis for aggregations
CHERNOFF-BOUND
(cid:3)
iCDF = λβ →
vj = S[iCDFj, sj, tsj]
2 · (cid:4)n
j=1 sj · log (1/β)
cb [v1, v2, ..., vn ] (cid:6) iCDF
(cid:5)
ADD-CHERNOFF-UNION
j=1...n tsj = ∅
vj = S[iCDFj, sj, tsj]
iCDF = λβ → min (ub [v1, v2, ..., vn ] β) (cb [v1, v2, ..., vn ] β)
(cid:7)
(∀j · tsj (cid:10)= ∅)
(cid:4)
add [v1, v2, ..., vn ] (cid:6) S[iCDF,
j=1...n tsj]
n
j=1 sj,
Fig. 15: Calculation of concentration bounds
E. Accuracy of Gaussian mechanism
For Q : db → R an arbitrary function with sensitivity ΔQ
as deﬁned in II.2, the Gaussian mechanism with parameter σ
add noise scaled to N (0, σ2) to its output.
Theorem A.1 (Gaussian Mechanism [59]). For any , δ ∈
(0, 1), the Gaussian output perturbation mechanism with stan-
dard deviation σ = ΔQ
δ )/ is (, δ)-differentially
private
Deﬁnition A.1 (Accuracy for the Gaussian mechanism). Given
a randomized query ˜Q(·) : db → R implemented with the
Gaussian mechanism as previously described, we have that
2 log( 1.25
(cid:5)