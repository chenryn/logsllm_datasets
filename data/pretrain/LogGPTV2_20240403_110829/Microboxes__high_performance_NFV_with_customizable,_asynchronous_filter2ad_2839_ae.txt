For the first configuration, both modules register for the
PKT_IN event of the TCP Monitor Stack, causing events
about all packets to go through both NFs. This configuration
gets the lowest throughput since both NFs receive and pro-
cess two events for each packet: one when the stack updates
the client-side state and one when it updates the server-side
state. For the second configuration, we deregister events for
server side flows and only allow events related to the client’s
packets to pass through, effectively reducing the number of
events by about half. For the third configuration, we deregis-
ter the events generated by the client stack and only observe
events related to server stack updates caused by packets from
the client, and this reduces another half of events. For most
IDS deployments, this would be sufficient: the IDS only needs
to monitor traffic entering from untrusted clients, and it does
not need to separately track TCP state for both the client
and server sides. From Figure 7c, we can see 1.2x and 2.6x
throughput improvements shown in the second and third
bar due to narrowing the subscribed events when compared
with the first configuration.
Next we enable dynamic subscriptions. For the fourth con-
figuration, DPI subscribes to PKT/TCP events for the server
stack, as in case 3 above. However, we now have the DPI pub-
lish events based on the type of protocol identified, and the
Signature_Match NF subscribes for EVENT/DPI_DETECT
messages. Thus when DPI identifies a flow as HTTP, it
triggers the event and then uses dynamic subscriptions to
unsubscribe from PKT/TCP events for that flow (since it
has already been identified). At the same time, the Signa-
ture_Match NF begins to subscribe to the PKT/TCP events
so that it can perform its analysis (e.g., scanning for SQL injec-
tion attacks). If a specific signature is found, Signature_Match
will publish a new EVENT/IDS_ALERT event and deregis-
ter the current flow. By using dynamic filtering, we reduce
the number of processed events by more than 50%, and pro-
vide nearly 5x throughput increase compared to the static
filtering in case 3. For the last configuration, we enable flow
reassembly so that DPI and Signature_Match can subscribe
and publish DATA_RDY events. This allows the NFs to detect
patterns that span multiple packets, at the expense of about
15% overhead to reassemble the packet payload and create
the bytestream.
This experiment shows the value of enabling NFs to tune
their subscriptions and to be able to use events to communi-
cate information. Prior systems would send far more packets
to each NF for processing (similar to cases 1-3), while our
approach allows NFs to be directly alerted of information
they need and tune their subscriptions accordingly.
7.4 IDS+Mon: Dynamic, Parallel Events
We now evaluate a more complex group of NFs and show how
dynamic subscriptions and parallel processing can improve
performance under different configurations. Our setup is
based on the real world services evaluated in NFP [28].
We first configure the five NFs as a sequential or paral-
lel chain as shown at the top of Figure 8. In the "Default"
configuration, all NFs in the chain subscribe to PKT/TCP
events; however, since the Signature_Match and Logger mod-
ules are much more expensive than the others they are
the performance bottlenecks. To tune the chain, we next
Microboxes: High Performance NFV with Customizable,
Asynchronous TCP Stacks and Dynamic Subscriptions
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
Framework Architecture
Microboxes
mOS [12]
Comb [26]
Bro [22]
FlowOS [6]
pipelined
monolithic
pipelined
/monolithic
monolithic
monolithic
high
high
low
medium
medium
Flexibility Events Chain
yes
yes
no
yes
no
yes
no
yes
no
yes
Table 4: A comparison with other middlebox frame-
works that support TCP protocol processing.
flow-level programming model for middleboxes. It hides the
low-level packet process but it relies on Linux kernel stack
which is not optimized for middleboxes.
Microboxes provides a shared customizable TCP stack
for each group of NFs which is designed to remove redun-
dant stack processing while maintaining consistency require-
ments. Our event system is inspired by the user-defined
events in mOS and Bro, but we extend these with a meaning-
ful type hierarchy and support for cross NF coordination.
Modularity and Parallelism: Click has been a popular
platform to build network functions due to its modularity
and extensibility. A set of individual elements are connected
via pull or push connections to build a more complex ap-
plication. Click also inspired a series of other modular NFV
architectures [4, 8, 17, 26]. However, without native TCP sup-
port in Click, these platforms are restricted to L2 or L3 NFs.
NFP and Parabox [28, 30] focus on NF level parallelism, they
can automatically analyze NF dependencies and reconstruct
a service graph with parallel NFs to improve performance.
P4 [7] is a configuration language for packet processors and
it enables parallelism by identifying table dependencies.
Microboxes works along both directions and is compli-
mentary to these works. By decomposing a stack into several
customizable building blocks, Microboxes promotes paral-
lelism. We mainly focus on asynchronous processing that
allows parallelism between NFs and the protocol stack.
9 CONCLUSIONS
Existing NFV frameworks focus on efficient packet move-
ment and layer 2/3 processing, yet many key middlebox
applications require higher level protocol processing. The
Microboxes architecture balances the goals of consolidating
protocol processing and supporting a customizable stack that
can be tailored to the needs of individual flows. We achieve
this by designing a modular, asynchronous TCP stack and
efficient, event-based communication mechanisms to link
together NFs into complex applications. We introduce op-
timizations such as stack snapshots to ensure stack consis-
tency while maintaining high performance. We believe that
Microboxes will provide a valuable framework for NF devel-
opers to deploy transport-layer-and-above middleboxes or
end-services.
Figure 8: Parallelizing a long chain and using dynamic
event filtering provides substantial latency benefits
setup the DPI_DETECT event described in the prior section
which causes the DPI and Signature_Match NFs to dynami-
cally tune their subscriptions. This reduces the load on the
first two NFs, improving the average latency as shown by
the “DPI_DETECT” bars in Figure 8. Next we consider cus-
tom events for the Flow_Stats and Logger NFs. We define a
LONG_FLOW event published by Flow_Stats once the aver-
age packet length of a flow is larger than a threshold. The
Logger subscribes to this event, and adjusts its subscription
so that it only logs events about long running flows. Finally,
we consider the combination of both of these custom events,
which provides a further improvement in performance. Com-
pared to the sequential chain, the parallel configuration pro-
vides between a 3%-13% latency reduction.
8 RELATED WORK
TCP Stacks: There are several research efforts on high per-
formance networking stacks [5, 13, 15, 20, 21, 23] but most
are specific to end-host applications. We present a compar-
ison of NFV frameworks [6, 12, 22, 26] that support TCP
protocol processing in Table 4. mOS [12] provides a reusable
TCP stack to facilitate L4-L7 NF development for monolithic
architecture, however it focuses on a single NF, not a chain.
Simply replacing each NF’s stack with mOS and hooking
them together will incur multiple copies and cause perfor-
mance issues. Comb [26] could support both pipelined and
monolithic applications and has focused on consolidating
applications and managing resources at the network-wide,
without addressing the stack or NF configurability at the
application level. Bro [22] presents a stack and event man-
agement framework specific to Intrusion Detection System.
However its modules are tightly-coupled which makes it
hard to extend into other applications. FlowOS [6] presents a
TCPDPISIG_MatchFlow_StatsLoggerLBTCPDPISIG_MatchFlow_StatsLoggerLBSequentialParallel 0 40 80 120 160 200 240SequentialParallelLatency (us)DefaultDPI_DETECTLONG_FLOWBothSIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
G. Liu et al.
Acknowledgements: We would like to thank our shepherd
KyoungSoo Park, the anonymous reviewers, and Jean Tour-
rilhes and Puneet Sharma from HPE for their detailed com-
ments and valuable feedback. This work was supported in
part by NSF grants CNS-1422362 and CNS-1522546.
REFERENCES
[1] Data plane development kit (dpdk). http://www.dpdk.org/.
[2] Haproxy. http://haproxy.1wt.eu/.
[3] ndpi | ntop. http://www.ntop.org/products/ndpi/.
[4] B. Anwer, T. Benson, N. Feamster, and D. Levin. Programming slick
network functions. In Proceedings of the 1st ACM SIGCOMM Sympo-
sium on Software Defined Networking Research, SOSR ’15, Santa Clara,
California, USA, June 17-18, 2015, 2015.
[5] A. Belay, G. Prekas, A. Klimovic, S. Grossman, C. Kozyrakis, and
E. Bugnion.
IX: A protected dataplane operating system for high
throughput and low latency. In 11th USENIX Symposium on Operating
Systems Design and Implementation (OSDI 14). USENIX Association,
2014.
[6] M. Bezahaf, A. Alim, and L. Mathy. Flowos: A flow-based platform
for middleboxes. In Proceedings of the 2013 Workshop on Hot Topics in
Middleboxes and Network Function Virtualization, HotMiddlebox ’13,
pages 19–24, New York, NY, USA, 2013. ACM.
[7] P. Bosshart, D. Daly, G. Gibb, M. Izzard, N. McKeown, J. Rexford,
C. Schlesinger, D. Talayco, A. Vahdat, G. Varghese, and D. Walker. P4:
Programming protocol-independent packet processors. SIGCOMM
Comput. Commun. Rev., 44(3):87–95, July 2014.
[8] A. Bremler-Barr, Y. Harchol, and D. Hay. Openbox: A software-defined
framework for developing, deploying, and managing network func-
tions. In Proceedings of the 2016 conference on ACM SIGCOMM 2016
Conference, Florianopolis, Brazil, August 22-26, 2016, 2016.
[9] A. Cohen, S. Rangarajan, and H. Slye. On the Performance of TCP
Splicing for URL-aware Redirection. In Proceedings of the 2Nd Con-
ference on USENIX Symposium on Internet Technologies and Systems -
Volume 2, USITS’99, pages 11–11, Berkeley, CA, USA, 1999. USENIX
Association.
[10] N. Dragoni, S. Giallorenzo, A. L. Lafuente, M. Mazzar, F. Montesi,
R. Mustafin, and L. Safina. Microservices: Yesterday, today, and tomor-
row. Present and Ulterior Software Engineering, 2017.
[11] S. Han, K. Jang, A. Panda, S. Palkar, D. Han, and S. Ratnasamy. Softnic:
A software nic to augment hardware. Technical Report UCB/EECS-
2015-155, EECS Department, University of California, Berkeley, May
2015.
[12] M. A. Jamshed, Y. Moon, D. Kim, D. Han, and K. Park. mos: A reusable
networking stack for flow monitoring middleboxes. In 14th USENIX
Symposium on Networked Systems Design and Implementation, NSDI
2017, Boston, MA, USA, March 27-29, 2017, 2017.
[13] E. Jeong, S. Woo, M. A. Jamshed, H. Jeong, S. Ihm, D. Han, and K. Park.
mtcp: a highly scalable user-level TCP stack for multicore systems.
In Proceedings of the 11th USENIX Symposium on Networked Systems
Design and Implementation, NSDI 2014, Seattle, WA, USA, April 2-4, 2014,
2014.
[14] E. Kohler, R. Morris, B. Chen, J. Jannotti, and M. F. Kaashoek. The click
modular router. ACM Trans. Comput. Syst., 18(3):263–297, 2000.
[15] R. Laufer, M. Gallo, D. Perino, and A. Nandugudi. Climb: Enabling
network function composition with click middleboxes. In Proceedings
of the 2016 Workshop on Hot Topics in Middleboxes and Network Function
Virtualization, HotMIddlebox ’16, New York, NY, USA, 2016. ACM.
[16] F. Le, E. Nahum, V. Pappas, M. Touma, and D. Verma. Experiences
Deploying a Transparent Split TCP Middlebox and the Implications for
NFV. In Proceedings of the 2015 ACM SIGCOMM Workshop on Hot Topics
in Middleboxes and Network Function Virtualization, HotMiddlebox ’15,
pages 31–36, New York, NY, USA, 2015. ACM.
[17] B. Li, K. Tan, L. L. Luo, Y. Peng, R. Luo, N. Xu, Y. Xiong, and P. Cheng.
Clicknp: Highly flexible and high-performance network processing
with reconfigurable hardware. In Proceedings of the ACM SIGCOMM
2016 Conference, Florianopolis, Brazil, August 22-26, 2016, 2016.
[18] D. A. Maltz and P. Bhagwat. MSOCKS: an architecture for transport
layer mobility. In IEEE INFOCOM ’98. Seventeenth Annual Joint Confer-
ence of the IEEE Computer and Communications Societies. Proceedings,
volume 3, pages 1037–1045 vol.3, Mar. 1998.
[19] J. Martins, M. Ahmed, C. Raiciu, V. Olteanu, M. Honda, et al. ClickOS
and the art of network function virtualization. In USENIX NSDI, 2014.
[20] Z. Niu, H. Xu, D. Han, P. Cheng, Y. Xiong, G. Chen, and K. Winstein.
Network stack as a service in the cloud. In Proceedings of the 16th ACM
Workshop on Hot Topics in Networks, HotNets-XVI, pages 65–71, New
York, NY, USA, 2017. ACM.
[21] S. Pathak and V. S. Pai. Modnet: A modular approach to network stack
extension. In 12th USENIX Symposium on Networked Systems Design
and Implementation, NSDI 15, Oakland, CA, USA, May 4-6, 2015, 2015.
[22] V. Paxson. Bro: a system for detecting network intruders in real-time.
Computer Networks, 31(23-24):2435–2463, 1999.
[23] S. Peter, J. Li, I. Zhang, D. R. K. Ports, D. Woos, A. Krishnamurthy,
T. Anderson, and T. Roscoe. Arrakis: The operating system is the con-
trol plane. In Proceedings of the 11th USENIX Conference on Operating
Systems Design and Implementation, OSDI’14, Berkeley, CA, USA, 2014.
USENIX Association.
[24] R. Ricci, E. Eide, and C. Team. Introducing CloudLab: Scientific infras-
tructure for advancing cloud architectures and applications. ; login::
the magazine of USENIX & SAGE, 39(6):36–38, 2014.
[25] L. Rizzo. netmap: A novel framework for fast packet i/o. In USENIX
ATC, 2012.
[26] V. Sekar, N. Egi, S. Ratnasamy, M. K. Reiter, and G. Shi. Design and
implementation of a consolidated middlebox architecture. In Proceed-
ings of the 9th USENIX Symposium on Networked Systems Design and
Implementation, NSDI 2012, San Jose, CA, USA, April 25-27, 2012, 2012.
[27] J. Sherry, S. Hasan, C. Scott, A. Krishnamurthy, S. Ratnasamy, and
V. Sekar. Making Middleboxes Someone else’s Problem: Network Pro-
cessing As a Cloud Service. In Proceedings of the ACM SIGCOMM 2012
Conference on Applications, Technologies, Architectures, and Protocols
for Computer Communication, SIGCOMM ’12, pages 13–24, New York,
NY, USA, 2012. ACM.
[28] C. Sun, J. Bi, Z. Zheng, H. Yu, and H. Hu. NFP: enabling network
function parallelism in NFV. In Proceedings of the Conference of the
ACM Special Interest Group on Data Communication, SIGCOMM 2017,
Los Angeles, CA, USA, August 21-25, 2017, 2017.
[29] W. Zhang, G. Liu, W. Zhang, N. Shah, P. Lopreiato, G. Todeschi, K. Ra-
makrishnan, and T. Wood. OpenNetVM: A platform for high perfor-
mance network service chains. In HotMiddlebox. ACM, 2016.
[30] Y. Zhang, B. Anwer, V. Gopalakrishnan, B. Han, J. Reich, A. Shaikh,
and Z. Zhang. Parabox: Exploiting parallelism for virtual network
functions in service chaining. In Proceedings of the Symposium on SDN
Research, SOSR 2017, Santa Clara, CA, USA, April 3-4, 2017, 2017.