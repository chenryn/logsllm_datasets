if f (x1, . . . , xm) = y then P else Q. We naturally gener-
alize this construct to let N = M in P else Q where N is
built from poly-injective functions and variables.
1 (y) in . . . let xm : Tm = f −1
j
Let us introduce two cryptographic primitives that we
use in the following.
Deﬁnition 1 Let Tmr, Tmk, and Tms be types that corre-
spond intuitively to random seeds, keys, and message au-
thentication codes, respectively; Tmr is a ﬁxed-length type.
A message authentication code [14] consists of three func-
tion symbols:
• mkgen : Tmr → Tmk where Iη(mkgen) = mkgen η is
the key generation algorithm taking as argument a ran-
dom bitstring, and returning a key. (Usually, mkgen
is a randomized algorithm; here, since we separate the
choice of random numbers from computation, mkgen
takes an additional argument representing the random
coins.)
• mac : bitstring × Tmk → Tms where Iη(mac) =
macη is the mac algorithm taking as argument a mes-
sage and a key, and returning the corresponding tag.
(We assume here that mac is deterministic; we could
easily encode a randomized mac by adding an addi-
tional argument as for mkgen.)
• check : bitstring × Tmk × Tms → bool where
Iη(check ) = check η is a checking algorithm such that
check η(m, k, t) = 1 if and only if t is a valid mac of
message m under key k. (Since mac is deterministic,
check η(m, k, t) is typically macη(m, k) = t.)
We have ∀m ∈ Bitstring, ∀r ∈ Iη(Tmr), check η(m,
mkgen η(r), macη(m, mkgen η(r))) = 1.
A mac is secure against existential forgery under chosen
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
message attack if and only if for all polynomials q,
A
max
Pr[r R← Iη(Tmr); k ← mkgen η(r);
(m, t) ← Amacη(.,k),check η(.,k,.) : check η(m, k, t)]
is negligible, where the adversary A is any probabilistic
Turing machine, running in time q(η), with oracle access
to macη(., k) and check η(., k, .), and A has not called
macη(., k) on message m.
Deﬁnition 2 Let Tr and T (cid:2)
r be ﬁxed-length types; let Tk
and Te be types. A symmetric encryption scheme [12]
(stream cipher) consists of three function symbols kgen :
Tr → Tk, enc : bitstring × Tk × T (cid:2)
r → Te, and
dec : Te × Tk → bitstring ⊥, with Iη(kgen) = kgen η,
Iη(enc) = encη, Iη(dec) = decη, such that for all
m ∈ Bitstring, r ∈ Iη(Tr), and r(cid:2) ∈ Iη(T (cid:2)
r),
decη(encη(m, kgen η(r), r(cid:2)), kgen η(r)) = m.
Let LR(x, y, b) = x if b = 0 and LR(x, y, b) = y
if b = 1, deﬁned only when x and y are bitstrings of the
same length. A stream cipher is IND-CPA (satisﬁes indis-
tinguishability under chosen plaintext attacks) if and only if
for all polynomials q,
max
A
2 Pr[b R←{0, 1}; r R← Iη(Tr); k ← kgen η(r);
b(cid:2) ← Ar(cid:2)
R← Iη(T (cid:2)
r);encη(LR(.,.,b),k,r(cid:2)) : b(cid:2) = b] − 1
is negligible, where the adversary A is any probabilis-
tic Turing machine, running in time q(η), with oracle ac-
cess to the left-right encryption algorithm which given
two bitstrings a0 and a1 of the same length,
returns
r(cid:2) R← Iη(T (cid:2)
r); encη(LR(a0, a1, b), k, r(cid:2)), that is, encrypts a0
when b = 0 and a1 when b = 1.
Example 1 Let us consider the following trivial protocol:
k, xk, x(cid:2)(cid:2)
r )
k are fresh random numbers
A → B : e, mac(e, xmk) where e = enc(x(cid:2)
and x(cid:2)(cid:2)
r , x(cid:2)
A and B are assumed to share a key xk for a stream cipher
and a key xmk for a message authentication code. A creates
a fresh key x(cid:2)
k, and sends it encrypted under xk to B. A mac
is appended to the message, in order to guarantee integrity.
The goal of the protocol is that x(cid:2)
k should be a secret key
shared between A and B. This protocol can be modeled in
our calculus by the following process Q0:
Q0 = start(); new xr : Tr; let xk : Tk = kgen(xr) in
r) in
r : Tmr; let xmk : Tmk = mkgen(x(cid:2)
new x(cid:2)
c(cid:5)(cid:6); (QA | QB)
QA = !i≤ncA[i](); new x(cid:2)
k : Tk; new x(cid:2)(cid:2)
let xm : bitstring = enc(k2b(x(cid:2)
cA[i](cid:5)xm, mac(xm, xmk)(cid:6)
r : T (cid:2)
r;
k), xk, x(cid:2)(cid:2)
r ) in
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
QB = !i(cid:2)≤ncB[i(cid:2)](x(cid:2)
m, xma); if check (x(cid:2)
then let i⊥(k2b(x(cid:2)(cid:2)
k)) = dec(x(cid:2)
m, xmk, xma)
m, xk) in cB[i(cid:2)](cid:5)(cid:6)
When Q0 receives a message on channel start, it begins
execution: it generates the keys xk and xmk by choosing
random coins xr and xr(cid:2) and applying the appropriate key
generation algorithms. Then it yields control to the context
(the adversary), by outputting on channel c. After this out-
put, n copies of processes for A and B are ready to be ex-
ecuted, when the context outputs on channels cA[i] or cB[i]
respectively. In a session that runs as expected, the context
ﬁrst sends a message on cA[i]. Then QA creates a fresh
key x(cid:2)
k (Tk is assumed to be a ﬁxed-length type), encrypts
it under xk with random coins x(cid:2)(cid:2)
r , computes the mac of the
encryption under xmk, and sends the ciphertext and the mac
on cA[i]. The function k2b : Tk → bitstring is the natural
injection Iη(k2b)(x) = x; it is needed only for type con-
version. The context is then expected to forward this mes-
sage on cB[i]. When QB receives this message, it checks
the mac, decrypts, and stores the obtained key in x(cid:2)(cid:2)
k. (The
function i⊥ : bitstring → bitstring ⊥ is the natural injec-
tion; it is useful to check that decryption succeeded.) This
key x(cid:2)(cid:2)
k should be secret.
The context is responsible for forwarding messages from
A to B. It can send messages in unexpected ways in order
to mount an attack.
Although we use a trivial running example due to length
constraints, this example is sufﬁcient to illustrate the main
features of our prover. Section 6 presents results obtained
on more realistic protocols.
We denote by var(P ) the set of variables that occur in P ,
and by fc(P ) the set of free channels of P . (We use similar
notations for input processes.)
2.2 Type System
We use a type system to check that bitstrings of the
proper type are passed to each function, and that array in-
dexes are used correctly.
To be able to type variable accesses used not under their
deﬁnition (such accesses are guarded by a ﬁnd construct),
the type-checking algorithm proceeds in two passes. In the
ﬁrst pass, we build a type environment E, which maps vari-
able names x to types [1, n1] × . . . × [1, nm] → T , where
the deﬁnition of x[i1, . . . , im] of type T occurs under repli-
cations !i1≤n1, . . . , !im≤nm. We require that all deﬁnitions
of the same variable x yield the same value of E(x), so that
E is properly deﬁned.
In the second pass, the process is typechecked in the type
environment E by a simple type system. This type system
is detailed in [17]. It deﬁnes the judgment E (cid:15) Q which
means that the process Q is well-typed in environment E.
Invariant 3 (Typing) The process Q0 satisﬁes Invariant 3
if and only the type environment E for Q0 is well-deﬁned,
and E (cid:15) Q0.
We require the adversary to be well-typed. This require-
ment does not restrict its computing power, because it can
always deﬁne type-cast functions f : T → T (cid:2) to bypass the
type system. Similarly, the type system does not restrict the
class of protocols that we consider, since the protocol may
contain type-cast functions. The type system just makes ex-
plicit which set of bitstrings may appear at each point of the
protocol.
2.3 Formal Semantics
The semantics is deﬁned by a probabilistic reduction re-
lation formally detailed in [17]. The notation E, M ⇓ a
means that the term M evaluates to the bitstring a in envi-
ronment E. We denote by Pr[Q (cid:2)η c(cid:5)a(cid:6)] the probability
that Q outputs the bitstring a on channel c after some reduc-
tions.
Our semantics is such that, for each process Q, there
exists a probabilistic polynomial time Turing machine that
simulates Q. (Processes run in polynomial time since the
number of processes created by a replication and the length
of messages sent on channels are bounded by polynomi-
als.) Conversely, our calculus can simulate a probabilistic
polynomial-time Turing machine, simply by choosing coins
by new and by applying a function symbol deﬁned to per-
form the same computations as the Turing machine.
2.4 Observational Equivalence
A context is a process containing a hole [ ]. An evaluation
context C is a context built from [ ], newChannel c; C, Q |
C, and C | Q. We use an evaluation context to represent
the adversary. We denote by C[Q] the process obtained by
replacing the hole [ ] in the context C with the process Q.
Deﬁnition 3 (Observational equivalence) Let Q and Q(cid:2)
be two processes, and V a set of variables. Assume that
Q and Q(cid:2) satisfy Invariants 1, 2, and 3 and the variables of
V are deﬁned in Q and Q(cid:2), with the same types.
An evaluation context is said to be acceptable for Q, Q(cid:2),
V if and only if var(C)∩(var(Q)∪var(Q(cid:2))) ⊆ V and C[Q]
satisﬁes Invariants 1, 2, and 3. (Then C[Q(cid:2)] also satisﬁes
these invariants.)
We say that Q and Q(cid:2) are observationally equivalent
with public variables V , written Q ≈V Q(cid:2), when for all
evaluation contexts C acceptable for Q, Q(cid:2), V , for all chan-
nels c and bitstrings a, | Pr[C[Q] (cid:2)η c(cid:5)a(cid:6)] − Pr[C[Q(cid:2)] (cid:2)η
c(cid:5)a(cid:6)]| is negligible.
Intuitively, the goal of the adversary represented by con-
text C is to distinguish Q from Q(cid:2). When it succeeds, it
performs a different output, for example c(cid:5)0(cid:6) when it has
recognized Q and c(cid:5)1(cid:6) when it has recognized Q(cid:2). When
Q ≈V Q(cid:2), the context has negligible probability of distin-
guishing Q from Q(cid:2).
The unusual requirement on variables of C comes from
the presence of arrays and of the associated ﬁnd construct
which gives C direct access to variables of Q and Q(cid:2): the
context C is allowed to access variables of Q and Q(cid:2) only
when they are in V . (In more standard settings, the calculus
does not have constructs that allow the context to access
variables of Q and Q(cid:2).) The following result is not difﬁcult
to prove:
Lemma 1 ≈V is an equivalence relation, and Q ≈V Q(cid:2)
implies that C[Q] ≈V (cid:2) C[Q(cid:2)] for all evaluation contexts
C acceptable for Q, Q(cid:2), V and all V (cid:2) ⊆ V ∪ (var(C) \
(var(Q) ∪ var(Q(cid:2)))).
0 Q(cid:2) the particular case in which for all
We denote by Q ≈V
evaluation contexts C acceptable for Q, Q(cid:2), V , for all chan-
nels c and bitstrings a, Pr[C[Q] (cid:2)η c(cid:5)a(cid:6)] = Pr[C[Q(cid:2)] (cid:2)η
c(cid:5)a(cid:6)]. When V is empty, we write Q ≈ Q(cid:2) instead of
Q ≈V Q(cid:2) and Q ≈0 Q(cid:2) instead of Q ≈V
0 Q(cid:2).
3 Game Transformations
In this section, we describe the game transformations
that allow us to transform the process that represents the
initial protocol into a process on which the desired security
property can be proved directly, by criteria given in Sec-
tion 4. These transformations are parametrized by the set V
of variables that the context can access. As we shall see in
Section 4, V contains variables that we would like to prove
secret. These transformations transform a process Q0 into a
process Q(cid:2)
0 such that Q0 ≈V Q(cid:2)
0.
3.1 Syntactic Transformations
RemoveAssign(x): When x is deﬁned by an assignment
let x[i1, . . . , il] : T = M in P , we replace x with its
value. Precisely, the transformation is performed only when
x does not occur in M (non-cyclic assignment). When
x has several deﬁnitions, we simply replace x[i1, . . . , il]
with M in P . (For accesses to x guarded by ﬁnd, we do
not know which deﬁnition of x is actually used.) When
x has a single deﬁnition, we replace everywhere in the
game x[M1, . . . , Ml] with M {M1/i1, . . . , Ml/il}. We ad-
ditionally update the deﬁned conditions of ﬁnd to pre-
serve Invariant 2, and to maintain the requirement that
x[M1, . . . , Ml] is deﬁned when it was required in the ini-
tial game. When x ∈ V , its deﬁnition is kept unchanged.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 