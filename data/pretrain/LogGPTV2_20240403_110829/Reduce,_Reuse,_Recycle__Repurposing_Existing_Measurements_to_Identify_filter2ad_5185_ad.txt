Local Preference values than public peers [64]. We do generate a
signal in the case of routing through a private peer if such changes
were observed in public traceroute feeds, which allows us to infer
that ASi assigns equal BGP Local Preference values to public and
private peers.
4.3 Using Staleness Prediction Signals
Depending on the goals and constraints of a system, the system
may use staleness prediction signals to decide which traceroutes
to refresh, to prune stale traceroutes, or to treat inferences made
with stale traceroutes with lower confidence. This section discusses
general approaches to using signals in real systems.
4.3.1 Refreshing Stale Traceroutes and Signal Calibration. Once
stale traceroutes are detected in a corpus, in many scenarios it is
desirable to issue new traceroutes to refresh them. However, the
number of traceroutes signalled as stale can exceed the measure-
ment budget, particularly in systems that require monitoring a large
corpus (e.g., [18, 46, 50, 83]).
Each corpus traceroute crosses some set of borders between ASes.
Each border may be monitored by zero or more of our techniques
depending on the visibility provided by available vantage points.
Some of the techniques monitor the use of the border(s) on the way
to particular destinations (§4.1), whereas others monitor the use of
the border along a subpath independent of destination (§4.2). We
say a technique provides a potential staleness prediction signal for
a border (and associated destination or subpath) that it monitors.
We say a potential signal and a corpus traceroute are related if
the potential signal monitors a border and destination/subpath of
the traceroute. At any point in time, some of the potential signals
related to a traceroute may indicate that it is stale (i.e., the technique
generated a staleness prediction signal since the traceroute was
issued). Any related potential signal for which a staleness prediction
signal has not been generated implicitly indicates that the technique
has not detected a change at that border.
To prioritize which traceroutes to reissue, we monitor the effec-
tiveness of each potential signal over time and prioritize those that
are effective. To capture effectiveness, every time we remeasure
a traceroute, we evaluate the correctness of each potential signal
related to the (old) traceroute. A signal that indicated a change
in a portion of the old traceroute is considered a True Positive
(TP) if that portion of the path has actually changed, or a False
Positive (FP) if that portion of the path remains unchanged. A po-
tential signal that (implicitly) indicated that a portion of a path
had not changed is a True Negative (TN) if that portion remains
in the new traceroute, or a False Negative (FN) if that portion is
not in the new traceroute. For the vantage point v that issued the
traceroute and each related potential signal s, we maintain running
tallies TPv,s, FPv,s, TNv,s, and FNv,s over a sliding window of
the last l = 30 (by default) signal generation windows to allow
for changes over time. We use these tallies to maintain the true
positive rate TPRv,s = TPv,s/(TPv,s +FNv,s) and the true negative
rate TNRv,s = TNv,s/(TNv,s + FPv,s). Before the initial sliding
window is “full” of l windows, we consider TPRv,s and TNRv,s to
be uninitialized.
We refresh a number of measurements at the end of each staleness
prediction signal generation window wi according to the probing
budget available for refreshing the corpus. Let Si be the set of
staleness signals that predict a change at the end of window wi,
and ¯Si be the set of potential signals that do not predict a change.
i ⊆ Si and ¯Sv
i ⊆ ¯Si be the subsets related to a traceroute
Let Sv
from vantage point v.
We decide which measurement to issue using the following steps:
(1) We first choose the traceroute VP v with the highest relative
TPR across all VPs v′ with signals in Si. More precisely, we
choose v = argmaxv
. This
selection prioritizes VPs whose measurements more often
detect changes, increasing efficacy of the refreshing process.
(2) For simplicity, we calculate a single probability for the se-
lected VP v to refresh each of its traceroutes that a related
TPRs,v/(cid:16)
TPRs,v′(cid:17)


s∈Sv′
s∈Sv
i
v′
i
IMC ’20, October 27–29, 2020, Virtual Event, USA
Vasileios Giotsas et al.
=
s∈Sv
i

refresh
v,i

TPRs,v +
staleness prediction signal indicates is stale. The potential sig-
nals may not agree on which traceroutes have changed. We
combine their “opinions” to decide a probability of refreshing
a traceroute, as follows: P
TNRs,v
This calculation potentially considers TPR and TNR inferred
across multiple traceroutes, multiple borders per traceroute,
and multiple potential signals per border. The potential sig-
nals may “disagree” on whether or not their monitored por-
tions of traceroutes need to be refreshed. The TPR of signals
that indicate staleness will drive up the likelihood of refresh-
ing a traceroute, and the TNR of potential signals that do not
indicate staleness will drive down the likelihood.
TPRs,v
s∈ ¯Sv
i
s∈Sv
i
.
(3) For every signal in Sv
i
we iterate over all related corpus trace-
routes from v–that is, the set that the signal monitors and
hence now suggests are stale–and, if measurement budget
remains, we issue a remapping traceroute with probabil-
ity P
(4) If after executing step 3 there is still measurement budget
available, we remove v from the set of VPs that can be se-
lected and we repeat the process from step 1.
refresh
v,i
(5) While budget remains after the following process, which
in particular happens during bootstrapping while TPRv,s
and TNRv,s remain uninitialized for many vantage points
and signals, we order the signals according to the attributes
in Table 1, ordered by their priority from highest to lowest.
The first 5 attributes compare the overlap of the traceroutes
inferred as stale and the public traceroutes or BGP feed that
triggered the inference. When two signals are tied for one
attribute, before moving to the next attribute we use the
number of VPs as a tie-breaker for BGP-based signals or the
deviation from the staleness detection z-score for traceroute-
based signals. We use this technique instead of random signal
selection to bootstrap our TPR calculations using the best
possible signals for each vantage point, so that we avoid
building low scores for signals that can be potentially useful
for a vantage point but may not be selected due to a bad
start.
4.3.2 Revoking stale signals. Paths often change from a preferred
prevalent route to a less-preferred route temporarily during disrup-
tions, before changing back to the preferred prevalent route after
the disruption is solved [19]. Some of our techniques provide not
just a signal of when a corpus traceroute has gone stale but also
if it later reverts to its original route. When all AS path (§4.1.2),
community (§4.1.3), IP-level subpath (§4.2.1), and inter-city border
router (§4.2.2) staleness prediction signals associated with a particu-
lar corpus traceroute revert to the value they had when the corpus
traceroute was issued, we discard the staleness prediction signals
and consider the corpus traceroute fresh again without reissuing a
traceroute.
5 EVALUATION OF PRECISION AND
COVERAGE
This section evaluates our techniques in the following scenarios:
(1) Section 5.1 presents a retrospective evaluation to evaluate the
coverage and precision of our staleness prediction signals. We
Table 1: Ordered list of signal attributes used to sort signals
by priority when choosing measurements to refresh stale
traceroutes during the bootstrap period.
.
Priority
1
2
3
4
5
6
7
Signal Attribute
Longest IP-level path overlap
Longest AS-level path overlap
VPs in the same AS and city
VPs in the same AS
VPs in the same city
AS-level change
Border-level or IXP change
compare traceroutes across consecutive rounds of periodic
measurements and assess the relationship between changes
and signals that occur between the measurement rounds.
(2) Section 5.2 presents a live evaluation, in which we use our
techniques to maintain a traceroute corpus for two months.
We compare the efficacy of issuing refresh traceroutes using
our techniques and random choices.
(3) Section 5.3 compares our techniques with earlier approaches.
Metrics. We evaluate the precision and coverage of our tech-
niques in detecting path changes. We define precision as the fraction
of signals that identify a path change in our dataset, and coverage
as the fraction of path changes for which our techniques generate
signals. Precision is the ratio between the number of correct signals
(true positives) and the number of signals (positives). Coverage is
the ratio between the number of correct signals and the number of
path changes (true positives plus false negatives).2
Public BGP, traceroute feeds, and traceroute processing. We collect
all the available RouteViews and RIPE RIS data from BGPStream
to compute signals using our BGP-based techniques, starting two
days prior to the initialization of the corpus of traceroutes. During
our measurement period, RouteViews and RIS offered 710 IPv4
VPs in 485 ASes, 84% of which advertised their full BGP table to
the collectors. The public traceroutes we use for each scenario are
explained in their respective subsections. Appendix A describes
standard approaches we use to process traceroutes.
5.1 Retrospective Evaluation
5.1.1 Traceroute corpus. We use the RIPE Atlas anchoring mea-
surements, which issue two types of traceroutes every 900 seconds:
(1) A traceroute to every Atlas Anchor (a device with more CPU,
memory, and network bandwidth than regular Probes) from
approximately 400 Atlas Probes. The set of Probes can differ
across Anchors but is kept stable across rounds for each
particular Anchor. If a Probe becomes inactive, it is replaced.
(2) A mesh of traceroutes between all Anchors.
We start collecting anchoring measurements to 497 Anchors on
t0 = 2019-02-15. Every 900-second round, the anchoring measure-
ments produce about 446K traceroutes, 199K traceroutes between
Probes and Anchors, and 247K traceroutes between Anchors.
Figure 1 shows the fraction of border-level and AS-level paths
that are different from their initial t0 traceroute over a period of
2We use the term coverage rather than recall (calculated the same way) because false
negatives (undetected changes) are mainly caused by a lack of vantage points in the
proper locations.
Repurposing Existing Measurements to Identify Stale Traceroutes
IMC ’20, October 27–29, 2020, Virtual Event, USA
Table 2: Precision and coverage for each path staleness prediction technique for the retrospective evaluation. Each technique
has high precision, and combining all techniques is necessary to achieve high coverage.
Coverage
Border-level changes
Individual Unique
AS or border changes
Precision Individual Unique
AS-level changes
Individual Unique
0.82
0.80
0.72
0.74
0.85
0.81
0.83
0.82
0.80
0.13
0.09
0.11
0.27
0.13
0.51
0.11
0.69
0.81
0.07
0.05
0.03
0.08
0.35
0.07
0.28
0.03
0.04
0.29
0.12
0.42
0.19
0.70
0.86
0.16