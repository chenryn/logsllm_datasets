Let’s try to understand how identity provider mix-up works (see Figure 14-1):
 1. This attack happens with an OAuth 2.0 client application, which 
provides multiple identity provider (IdP) options for login. Let’s 
say foo.idp and evil.idp. We assume that the client application 
does not know that evil.idp is evil. Also it can be a case where evil.
idp is a genuine identity provider, which could possibly be under 
an attack itself.
 2. The victim picks foo.idp from the browser and the attacker 
intercepts the request and changes the selection to evil.idp. Here 
we assume the communication between the browser and the 
client application is not protected with Transport Layer Security 
(TLS). The OAuth 2.0 specification does not talk about it, and it’s 
purely up to the web application developers. Since there is no 
confidential data passed in this flow, most of the time the web 
application developers may not worry about using TLS. At the 
same time, there were few vulnerabilities discovered over the past 
on TLS implementations (mostly openssl). So, the attacker could 
possibly use such vulnerabilities to intercept the communication 
between the browser and the client application (web server), even 
if TLS is used.
Chapter 14  Oauth 2.0 SeCurity
289
 3. Since the attacker changed the identity provider selection of the 
user, the client application thinks it’s evil.idp (even though the 
user picked foo.idp) and redirects the user to evil.idp. The client 
application only gets the modified request from the attacker, who 
intercepted the communication.
 4. The attacker intercepts the redirection and modifies the 
redirection to go to the foo.idp. The way redirection works is 
the web server (in this case, the client application) sends back 
a response to the browser with a 302 status code—and with 
an HTTP Location header. If the communication between 
the browser and the client application is not on TLS, then this 
response is not protected, even if the HTTP Location header 
contains an HTTPS URL. Since we assumed already, the 
communication between the browser and the client application 
can be intercepted by the attacker, then the attacker can modify 
the Location header in the response to go to the foo.idp—which is 
the original selection—and no surprise to the user.
Figure 14-1. Identity provider mix-up attack
Chapter 14  Oauth 2.0 SeCurity
290
 5. The client application gets either the code or the token (based on 
the grant type) and now will talk to the evil.idp to validate it. The 
authorization server (or the identity provider) will send back the 
authorization code (if the code grant type is used) to the callback 
URL, which is under the client application. Just looking at the 
authorization code, the client application cannot decide to which 
identity provider the code belongs to. So we assume it tracks the 
identity provider by some session variable—so as per step 3, the 
client application thinks it’s the evil.idp and talks to the evil.idp to 
validate the token.
 6. The evil.idp gets hold of the user’s access token or the authorization 
code from the foo.idp. If it’s the implicit grant type, then it would 
be the access token, otherwise the authorization code. In mobile 
apps, most of the time, people used to embed the same client id 
and the client secret into all the instances—so an attacker having 
root access to his own phone can figure it out what the keys are and 
then, with the authorization code, can get the access token.
There is no record that the preceding attack is being carried out in practice—but at 
the same time, we cannot totally rule it out. There are a couple of options to prevent such 
attacks, and our recommendation is to use the option 1 as it is quite straightforward and 
solves the problem without much hassle.
 1. Have separate callback URLs by each identity provider. With 
this the client application knows to which identity provider the 
response belongs to. The legitimate identity provider will always 
respect the callback URL associated with the client application 
and will use that. The client application will also attach the value 
of the callback URL to the browser session and, once the user got 
redirected back, will see whether it’s on the right place (or the 
right callback URL) by matching with the value of the callback 
URL from the browser session.
 2. Follow the mitigation steps defined in the IETF draft specification: 
OAuth 2.0 IdP Mix-Up Mitigation (https://tools.ietf.
org/html/draft-ietf-oauth-mix-up-mitigation-01). This 
specification proposes to send a set of mitigation data from 
Chapter 14  Oauth 2.0 SeCurity
291
the authorization server back to the client, along with the 
authorization response. The mitigation data provided by the 
authorization server to the client includes an issuer identifier, 
which is used to identify the authorization server, and a client 
id, which is used to verify that the response is from the correct 
authorization server and is intended for the given client. This way 
the OAuth 2.0 client can verify from which authorization server 
it got the response back and based on that identify the token 
endpoint or the endpoint to validate the token.
 Cross-Site Request Forgery (CSRF)
In general, Cross-Site Request Forgery (CSRF) attack forces a logged-in victim’s browser 
to send a forged HTTP request, including the victim’s session cookie and any other 
automatically included authentication information to a vulnerable web application. 
Such an attack allows the attacker to force a victim’s browser to generate requests, where 
the vulnerable application thinks are legitimate requests from the victim. OWASP (Open 
Web Application Security Project) identifies this as one of the key security risks in web 
applications in its 2017 report.2
Let’s see how CSRF can be used with OAuth 2.0 to exploit a vulnerable web 
application (see Figure 14-2):
 1. The attacker tries to log in to the target web site (OAuth 2.0 client) 
with his account at the corresponding identity provider. Here we 
assume the attacker has a valid account at the identity provider, 
trusted by the corresponding OAuth 2.0 client application.
 2. The attacker blocks the redirection to the target web site and 
captures the authorization code. The target web site never sees the 
code. In OAuth 2.0, the authorization code is only good enough for 
one-time use. In case the OAuth 2.0 client application sees it and 
then exchanges it to an access token, then it’s no more valid—so 
the attacker has to make sure that the authorization code never 
reaches the client application. Since the authorization code flows 
through the attacker’s browser to the client, it can be easily blocked.
2 OWASP Top 10 2017, www.owasp.org/images/7/72/OWASP_Top_10-2017_%28en%29.pdf.pdf
Chapter 14  Oauth 2.0 SeCurity
292
 3. The attacker constructs the callback URL for the target site—and 
makes the victim clicks on it. In fact, it would be the same callback 
URL the attacker can copy from step 2. Here the attacker can send the 
link to the victim’s email or somehow fool him to click on the link.
 4. The victim clicks on the link and logs in to the target web site, 
with the account attached to the attacker—and adds his/her credit 
card information. Since the authorization code belongs to the 
attacker, the victim logs in to the target web site with the attacker’s 
account. This is a pattern many web sites follow to authenticate 
users with OAuth 2.0. Login with Facebook works in the same way. 
Once the web site gets the authorization code, it will talk to the 
authorization server and exchanges it to an access token. Then 
using that access token, the web site talks to another endpoint 
in the authorization server to find user information. In this case, 
since the code belongs to the attacker, the user information 
returned back from the authorization server will be related to 
Figure 14-2. Cross-Site Request Forgery (CSRF) attack in the OAuth 2.0 code 
flow
Chapter 14  Oauth 2.0 SeCurity
293
him—so the victim now logs in to the target web site with the 
attacker’s account.
 5. The attacker too logs in to the target web site with his/her valid 
credentials and uses victim’s credit card to purchase goods.
The preceding attack can be mitigated by following these best practices:
• 
Use a short-lived authorization code. Making the authorization code 
expires soon gives very little time for the attacker to plant an attack. 
For example, the authorization code issued by LinkedIn expires in 30 
seconds. Ideally, the lifetime of the authorization code should be in 
seconds.
• 
Use the state parameter as defined in the OAuth 2.0 specification. 
This is one of the key parameters to use to mitigate CSRF attacks in 
general. The client application has to generate a random number 
(or a string) and passes it to the authorization server along with the 
grant request. Further, the client application has to add the generated 
value of the state to the current user session (browser session) before 
redirecting the user to the authorization server. According to the 
OAuth 2.0 specification, the authorization server has to return back 
the same state value with the authorization code to the redirect_uri 
(to the client application). The client must validate the state value 
returned from the authorization server with the value stored in the 
user’s current session—if it mismatches, it rejects moving forward. 
Going back to the attack, when the user clicks the crafted link sent 
to the victim by the attacker, it won’t carry the same state value 
generated before and attached to the victim’s session (or most 
probably victim’s session has no state value), or the attacker does not 
know how to generate the exact same state value. So, the attack won’t 
be successful, and the client application will reject the request.
• 
Use PKCE (Proof Key for Code Exchange). PKCE (RFC 7636) was 
introduced to protect OAuth 2.0 client applications from the 
authorization code interception attack, mostly targeting native 
mobile apps. The use of PKCE will also protect users from CSRF 
attacks, once the code_verifier is attached to the user’s browser 
session. We talked about PKCE in detail in Chapter 10.
Chapter 14  Oauth 2.0 SeCurity
294
 Token Reuse
OAuth 2.0 tokens are issued by the authorization server to a client application to access 
a resource on behalf of the resource owner. This token is to be used by the client—and 
the resource server will make sure it’s a valid one. What if the resource server is under 
the control of an attacker and wants to reuse the token sent to it to access another 
resource, impersonating the original client? Here the basic assumption is there are 
multiple resource servers, which trust the same authorization server. For example, in a 
microservices deployment, there can be multiple microservices protected with OAuth 
2.0, which trust the same authorization server.
How do we make sure at the resource server side that the provided token is only good 
enough to access it? One approach is to have properly scoped access tokens. The scopes 
are defined by the resource server—and update the authorization server. If we qualify 
each scope with a Uniform Resource Name (URN) specific to the corresponding resource 
server, then there cannot be any overlapping scopes across all the resource servers—and 
each resource server knows how to uniquely identify a scope corresponding to it. Before 
accepting a token, it should check whether the token is issued with a scope known to it.
This does not completely solve the problem. If the client decides to get a single 
access token (with all the scopes) to access all the resources, then still a malicious client 
can use that access token to access another resource by impersonating the original 
client. To overcome this, the client can first get an access token with all the scopes, then 
it can exchange the access token to get multiple access tokens with different scopes, 
following the OAuth 2.0 Token Exchange specification (which we discussed in Chapter 
9). A given resource server will only see an access token having scopes only related to 
that particular resource server.
Let’s see another example of token reuse. Here assume that you log in to an OAuth 
2.0 client application with Facebook. Now the client has an access token, which is 
good enough to access the user info endpoint (https://graph.facebook.com/me) of 
Facebook and find who the user is. This client application is under an attacker, and now 
the attacker tries to access another client application, which uses the implicit grant type, 
with the same access token, as shown in the following.
https://target-app/callback?access_token=
Chapter 14  Oauth 2.0 SeCurity
295
The preceding URL will let the attacker log in to the client application as the original 
user unless the target client application has proper security checks in place. How do we 
overcome this?
There are multiple options:
• 
Avoid using OAuth 2.0 for authentication—instead use OpenID 
Connect. The ID token issued by the authorization server (via 
OpenID Connect) has an element called aud (audience)—and its 
value is the client id corresponding to the client application. Each 
application should make sure that the value of the aud is known to it 
before accepting the user. If the attacker tries to replay the ID token, 
it will not work since the audience validation will fail at the second 
client application (as the second application expects a different aud 
value).
• 
Facebook login is not using OpenID Connect—and the preceding 
attack can be carried out against a Facebook application which 
does not have the proper implementation. There are few options 
introduced by Facebook to overcome the preceding threat. One way 
is to use the undocumented API, https://graph.facebook.com/
app?access_token=, to get access token metadata. 
This will return back in a JSON message the details of the application 
which the corresponding access token is issued to. If it’s not yours, 
reject the request.
• 
Use the standard token introspection endpoint of the authorization 
server to find the token metadata. The response will have the client_
id corresponding to the OAuth 2.0 application—and if it does not 
belong to you, reject the login request.
There is another flavor of token reuse—rather we call it token misuse. When implicit 
grant type is used with a single-page application (SPA), the access token is visible to the 
end user—as it’s on the browser. It’s the legitimate user—so the user seeing the access 
token is no big deal. But the issue is the user would probably take the access token out of 
the browser (or the app) and automate or script some API calls, which would generate 
more load on the server that would not expect in a normal scenario. Also, there is a cost 
Chapter 14  Oauth 2.0 SeCurity
296
of making API calls. Most of the client applications are given a throttle limit—meaning 
a given application can only do n number of calls during a minute or some fixed time 
period. If one user tries to invoke APIs with a script, that could possibly eat out the 
complete throttle limit of the application—making an undesirable impact on the other 
users of the same application. To overcome such scenarios, the recommended approach 
is to introduce throttle limits by user by application—not just by the application. In that 
way, if a user wants to eat out his own throttle limit, go out and do it! The other solution is 
to use Token Binding, which we discussed in Chapter 11. With token binding, the access 
token is bound to the underlying Transport Layer Security (TLS) connection, and the 
user won’t be able to export it and use it from somewhere else.
 Token Leakage/Export
More than 90% of the OAuth 2.0 deployments are based on bearer tokens—not just the 
public/Internet scale ones but also at the enterprise level. The use of a bearer token is 
just like using cash. When you buy a cup of coffee from Starbucks, paying by cash, no 
one will bother how you got that ten-dollar note—or if you’re the real owner of it. OAuth 
2.0 bearer tokens are similar to that. If someone takes the token out of the wire (just like 
stealing a ten-dollar note from your pocket), he/she can use it just as the original owner 
of it—no questions asked!
Whenever you use OAuth 2.0, it’s not just recommended but a must to use TLS. Even 
though TLS is used, still a man-in-the-middle attack can be carried out with various 
techniques. Most of the time, the vulnerabilities in TLS implementations are used to 
intercept the TLS-protected communication channels. The Logjam attack discovered 
in May 2015 allowed a man-in-the-middle attacker to downgrade vulnerable TLS 
connections to 512-bit export-grade cryptography. This allowed the attacker to read and 
modify any data passed over the connection.
There are few things we need to worry about as precautions to keep the attacker 
away from having access to the tokens:
• 
Always be on TLS (use TLS 1.2 or later).
• 
Address all the TLS-level vulnerabilities at the client, authorization 
server, and the resource server.
Chapter 14  Oauth 2.0 SeCurity
297
• 
The token value should be >=128 bits long and constructed from 
a cryptographically strong random or pseudorandom number 
sequence.
• 
Never store tokens in cleartext—but the salted hash.
• 
Never write access/refresh tokens into logs.
• 
Use TLS tunneling over TLS bridging.
• 
Decide the lifetime of each token based on the risk associated with 
token leakage, duration of the underlying access grant (SAML grant 
(RFC 7522) or JWT grant (RFC 7523)), and the time required for an 
attacker to guess or produce a valid token.
• 
Prevent reuse of the authorization code—just once.
• 
Use one-time access tokens. Under the OAuth 2.0 implicit grant 
type, access token comes as a URI fragment—which will be in the 
browser history. In such cases, it can be immediately invalidated 
by exchanging it to a new access token from the client application 
(which is an SPA).
• 
Use strong client credentials. Most of the applications just use client 
id and client secret to authenticate the client application to the 
authorization server. Rather than passing credentials over the wire, 