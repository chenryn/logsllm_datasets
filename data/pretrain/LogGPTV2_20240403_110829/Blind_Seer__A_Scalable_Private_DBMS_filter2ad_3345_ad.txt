For 1 ≤ x ≤ α − 1, PrD[x] = 1/α.
For x ≥ α, PrD[x] = (1/α) · 1/2x−α+1.
Here, α is a tunable parameter. The client chooses x←D,
and then it also chooses x random indices (j1, . . . , jx)← [n]x.
When handling the query, the client superimposes the basic
search procedure above with these random paths. Our system
is 1/α zero-one indistinguishable and  one-case indistinguish-
able with  = 1. Intuitively, the leakage to the index server is
the tree traversal pattern, and these additional random paths
make the 0-case look like 1-case with a reasonably good
probability. We give more detail in Appendix B.
If we slightly relax the deﬁnition and ignore views tak-
−20, we can even
ing place with a tiny probability, say 2
achieve both 1-case and 0-case indistinguishability at the same
time; the probability of the number x of fake paths is now
|x−α|+2 with a parametrized center α, say α = 20 (except
1/2
when x = 0, i.e., Pr[x = 0] = 1/2α+1).
Against the server. One-case indistinguishability against the
server is easily achieved by generating a sufﬁcient number of
dummy record decryption keys in the preprocessing phase; the
index server will let the client know the (permuted) positions
of the dummy keys. When zero records are returned from a
query, the client asks for a dummy decryption key from the
server. For brevity, we omit the details here, and exclude this
feature in the security analysis.
C. Delete, Insert, and Update from the Server
Our system supports a basic form of dynamic deletion,
insertion, and update of a record which is only available
to the server. If it would like to delete a record Ri, then
the server sends i to the index server, which will mark
the encrypted correspondent as deleted. For newly inserted
(encrypted) records, the index server keeps a separate list for
them with no permutation involved. In addition, it also keeps
a temporary list of their Bloom ﬁlters. During search, the
temporary list is also scanned linearly, after the tree. When
the length of the temporary Bloom ﬁlter list reaches a certain
threshold, all the current data is re-indexed and a new Bloom
ﬁlter tree is constructed. The frequency of rebuilding the tree
is of course related to the frequency of the modiﬁcations and
also the threshold we choose for the temporary list’s size. Our
tree building takes one hour/100M records. Finally, update is
simply handled by atomically issuing a delete and an insert
command.
365
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:22 UTC from IEEE Xplore.  Restrictions apply. 
Functionality Fdb
Parameter: Leakage proﬁle.
Init: Given input (D, P ) from S, do the following:
1) Store the database records D and the policy P . Let
n be the number records in D. Shufﬂe D and let
(R1, . . . , Rn) be the shufﬂed records. Choose a random
permutation π : [n]→[n]. Construct a BF-search tree for
(R1, . . . , Rn) using the hash functions H.
2) To handle the client’s queries, it chooses hash functions
H = {hi
i=1 for Bloom ﬁlters with
parameters (η, (cid:3)) to maintain false positive rate of 10−6.
3) Finally, return a DONEinit and the leakage to all parties.
: {0, 1}∗→[(cid:3)]}η
Query: Given input q from C, do the following:
1) Check if q is allowed by P . If the check fails, then
disallow the query by setting y = ∅. Otherwise, for each
i ∈ [n], let Bi ∈ {0, 1}(cid:3)(cid:2)
be the Bloom ﬁlter associated
with the ith leaf in the BF tree. For i = 1, . . . , n, check
if the query passes according to the ﬁlter Bi (refer to
Section II); if so, add (i, Ri) to the result set Y .
2) Return Y to C and return a DONEquery message and
leakage to all parties.
Figure 4. The Ideal Functionality Fdb
We note that updates is not our core contribution; we
implement and report it here, but don’t focus on its design
and performance. A more scalable update system would use
a BF tree rather than a list; its implementation is a simple
modiﬁcation to our system.
VI. SECURITY ANALYSIS
In this section, we present an overview of the security of our
system. A full analysis with formal deﬁnitions and extensive
proofs is completed and written separately.
We consider static security against a semi-honest adversary
that controls at most one participant. We ﬁrst describe an
ideal functionality Fdb parameterized with a leakage proﬁle
in Figure 4, and then show that our system securely realizes
the functionality where the leakage is essentially the search
tree traversal pattern and the pattern of accessed BF indices.
For the sake of simplicity, we only consider security where
there are no insert/delete/update operations,2and unify the
server and the query checker into one entity. We also assume
that all the records have the same length.
We use the DDH assumption (for ElGamal encryption and
Naor-Pinkas OT), and our protocols are in the random oracle
model (for Naor-Pinkas OT and OT extension). We also use
PRGs and PRFs, and those primitives are implemented with
AES.
2 As access patterns are revealed, additional
in-
serted/deleted/updated records is leaked. For example, C or IS may learn
whether a returned record was recently inserted; they also may get advantage
in estimating whether the query matched a recently deleted record. We stress
that this additional leakage can be removed by re-running the setup of the
search structure.
information for
A. Security of Our System
With empty leakage proﬁle, the ideal functionality Fdb in
Figure 4 captures the privacy requirement of a database
management system in which each query is handled deter-
ministically. The client obtains only the query results, but
nothing more. The index server and the server learn nothing.
Realizing such a functionality incurs a performance hit. Our
system realizes the functionality Fdb with the leakage proﬁle
described below. The security of our system can be proved
from the security of the secure computation component, and
is deferred to the full version.
Leakage in Init. Since the server has all the input, the leakage
to S is none. The leakage to C is n, that is, the total number
of records. The leakage to IS is n and |R1|.
Leakage to S in each query. We ﬁrst consider the leakage
to the server. The server is involved only when the record is
retrieved. Let ((i1, Ri1 ), . . . , (ij, Rij )) be the query results.
Then, the leakage to the server is (π(i1), π(i2), . . . , π(ij)).
Leakage to C in each query. The leakage to the client is
the BF-search tree traversal paths, that is, all the nodes v in
which the query passes according to the ﬁlter Bv.
Leakage to IS in each query. The leakage to the index
server is a little more than that to the client. In particular,
the nodes in the faked paths that the client generates due
to one-case indistinguishability are added to the tree search
pattern. Also, the topology of the query circuit and of the
policy circuit is leaked to IS as well. Finally, the BF indices are
also revealed to IS (although not the BF content), but assuming
that the hash functions are random, those indices reveal little
information about the query. However, based on this, after
observing multiple queries, IS can infer some correlations a
C’s queries’ keywords.
B. Discussion
Leakage to the server. We could wholly remove the leakage
to the server by modifying the protocol as follows:
Remove the decryption key preparation (and blinded
keys) in the preprocessing; instead, the client re-
ceives the secret key sk from the server. The client
(as the receiver) and the index server (as the sender)
execute oblivious transfer at each leaf of the search
tree. The choice bit of the client is whether the
output of the query circuit
is success. The two
messages of the index server is the encrypted record
and a string of zeros.
However, we believe that it is important for the server to be
able to upper-bound the number of retrieved records. Without
such control, misconﬁguration on the query checker side may
allow overly general queries to be executed, causing too many
rows to be returned to the client; in contrast, in our approach,
S releases record decryption keys at the end, and therefore
it is easy to enforce the sanity check of the total number of
returned records. Moreover, if S has a commercial DB, it may
366
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:22 UTC from IEEE Xplore.  Restrictions apply. 
be convenient to implement payment mechanism in association
with key release by S.
OR queries. For OR queries passing the policy, our system
leaks extremely small information. In particular, the leakage
to the client is minimal, as the tree traversal pattern can be
reconstructed from the returned records. As a consequence, if
the client retrieves only document ids, the client learns nothing
about the results for individual terms in his query. The leakage
to the index server is similar. We believe that the topology
of the SQL formula and the policy circuit reveals small
information about the query and the policy. If desired, we can
even hide those information using universal circuits [37] with
a circuit size blow-up of a logarithmic multiplicative factor.
AND queries. For AND queries, the tree traversal pattern
consists of two kinds of paths. The ﬁrst are, of course, the
paths reaching the leaves (query results). The second stop
at some internal nodes due to our BF approach3; although
the leakage from this pattern reveals more information about
which node don’t contain a given keyword, we still believe
this leakage is acceptable in many use cases.
We stress that the second leakage is related to the fact that
a large linear running time seems to be inherent for some
AND queries, irrespective of privacy, but depending only on
the underlying database (see Section VIII-C for more detail).
Therefore, if we aim at running most AND queries in sublinear
time, the running time will inherently leak information on the
underlying DB.
VII. IMPLEMENTATION
We built a prototype of the proposed system to evaluate
its practicality in terms of performance. The prototype was
developed from scratch in C++ (a more than a year effort,
almost two years including designing) and consists of about
10KLOC. In this section, we describe several interesting parts
of the implementation that are mostly related to the scalability
of the system.
Crypto building blocks. We developed custom implemen-
tations for all the cryptographic building blocks that were
previously described in Section II. More speciﬁcally, we
used the GNU Multiple Precision (GMP) library to im-
plement oblivious transfers, garbled circuits and the semi-
homomorphic key management protocol. The choice of GMP
was mostly based on thread-safety. As for AES-based PRF, we
used the OpenSSL implementation because it takes advantage
of the AES-NI hardware instructions, thus delivering better
performance.
Parallelization. The current implementation of Blind Seer
supports parallel preprocessing and per-query threading when
searching. For all the multi-threading features we used Intel’s
Threading Building Blocks (TBB) library. To enable multi-
threaded execution of the preprocessing phase we created
3 For example, consider a query q that looks for two keywords, say, q =
α∧β. Let v be some node and c1, . . . , cb be the children of v in the search
tree. If c1 contains only α, and c2 contains only β, then v will contain both
α and β, and so the node v will pass the query; however, neither c1 nor c2
would.
a 3-stage pipeline. The ﬁrst stage is single-threaded and it
is responsible for reading the input data. The second stage
handles record preprocessing. This stage is executed in parallel
by a pool of threads. Finally, the last stage is again single-
threaded and is responsible for handling the encrypted records.
Concurrently supporting multiple queries was straightforward
as all the data structures are read-only. To avoid accessing the
Bloom ﬁlter tree while it is being updated by a modiﬁcation
command, we added a global writer lock (which does not
block reads). Since we only currently support paralleliza-
tion on a one-thread-per-query basis, it only beneﬁts query
throughput, not latency. However, long-running queries involve
a large amount of interaction between querier and server
that is independent and thus amenable to parallelization. The
improvement we see in throughput is a good indicator for how
much we could improve latency of slow queries by applying
parallelization to these interactions.
Bloom ﬁlter tree.
This is the main index structure of
our system which grows by the number of records and the
supported features (e.g., range). For this reason, the space
efﬁciency of the Bloom ﬁlter tree is directly related to the
scalability of the system. In the current version of our system
we have implemented two space optimizations: one on the
representation of the tree and another on the size of Bloom
ﬁlter in each tree node.
Firstly, we avoided storing pointers for the tree represen-
tation, which would result in wasting almost 1G of memory
for 100M records. This is achieved by using a ﬂat array with
ﬁxed size allocations per record.
Secondly, we observed that naively calculating the number
of items stored in the inner nodes by summing the items of
their children is inefﬁcient. For example, consider the case
of storing the ‘Sex’ ﬁeld in the database, which has only
two possible values. Each Bloom ﬁlter in the bottom layer
of the tree (leaves) will store either the value sex:male or
sex:female. However, their parent nodes will keep space for
10 items, although the Sex ﬁeld can have only two possible
values. Thus, we estimate the number of items that need to be
stored in a given level as the minimum between the cardinality
of the ﬁeld and the number of leaf-nodes of the current subtree.
This optimization alone reduced the total space of the tree by
more than 50% for the database we used in our evaluation.
Keyword search and stemming. Although we focus on
supporting database search on structured data, our underlying
system works with collections of keywords. Thus,
it can
trivially handle other forms of data,
like keyword search
over text documents, or even keyword search on text ﬁelds
of a database. We actually do support the latter – in our
system we provide this functionality using the special oper-
ator CONTAINED_IN(column, keyword). Also, we support
stemming over keyword search by using the Porter stemming
algorithm [2].
VIII. EVALUATION
In this section, we evaluate our system. We ﬁrst evaluate our
system as a comparison with MySQL as a baseline, to establish
367
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:22 UTC from IEEE Xplore.  Restrictions apply. 
)
c
e
s
(
e
m
i
t
y
r
e
u
q
l
a
t