• Radio Resource Control (RRC) — is a layer 3 protocol for the
• GPRS Tunnelling Protocol (GTP) — is an IP-based commu-
nication protocol used for carrying the GPRS packets, e.g.,
user data withing an LTE network
connection between UE and eNB
2.2 LTE Procedures
The LTE network is an end-to-end all IP network which means all
traffic flows from a User Equipment (UE) to a Packet Data Network
(PDN) are transferred based on IP protocol.
In order for a UE to connect to an LTE network, first, a mutual
authentication between the UE and the MME is performed using
the information stored in the HHS. Second, the UE sends a Service
Request to the MME. After receiving the request, the MME sends
GTP tunnel creation request to the SGW. Finally, after GTP tunnel
setup, the UE can send uplink data and receive downlink data. If
a UE is connected to the network but not using any services for a
pre-set amount of time, it will go to an idle mode. If a UE is in idle
mode and has a downlink data, the SGW sends a donwlink data
notification to the MME after receiving the data from PGW. The
MME then pages the UE to reconnect to the network.
3 FRAMEWORK
In this section, first, we briefly describe the overall DistAppGaurd
framework (Fig. 2). Then, we explain its different modules and the
key differences between this paper and [14].
First, the OS layer system calls that originate from the virtual
layer, i.e. Docker containers, are collected from the hosts (step 1, fig.
2). Second, system calls that are part of the same communication
are aggregated (step 2, fig. 2). Third, microservices are subject to
a role identification procedure in order to establish a consistent
view of each microservice and its containing processes (step 3,
fig. 2). Fourth, after generating this consistent view of the virtual
application, the graph generator module maps various system calls
into these new microservice role IDs to create a microservice data
exchange graph (step 4, fig. 2). Finally, the weight of the edges of
the graph calculated from the previous step are used to train an
ML model representing the virtual application’s normal behaviour
(step 4, fig. 2). The trained model is then used to perform runtime
anomaly detection using graph feature vectors computed from
running virtual applications (step 5, fig. 2). As soon as there is a
divergence between the learned model and the virtual application’s
current behaviour greater than a pre-set threshold, DistAppGaurd
sends security alerts to the security management system.
3.1 System Call Collection and Aggregation
System calls are the primary source of input for many application
behaviour profiling approaches. However, classical approach of
collecting all the system calls made by the application will produce
significant overhead on the CPU. On the other hand, DistAppGaurd
only needs to capture data exchange related system calls (e.g., read,
mmap2, and recvmsg) to represent the behaviour of an application
which reduces the overhead significantly.
The collected system calls are then streamed out to the central
server for further analysis. However, streaming out the collected
system calls adds another overhead on the CPU. Specially, in cloud
based environments, where the system calls are needed to be col-
lected from several hosts and processed together, it becomes a real
bottleneck. For example, when two microservices communicate
with each other over the TCP protocol, a simple data exchange leads
to many packets being exchanged between them, which produces
a large number of corresponding system calls.
839ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Ghorbani et al.
Figure 2: An overview of DistAppGaurd framework
To minimize this extra overhead, in DistAppGaurd, the system
calls related to the same data flow are aggregated together and
replaced with two pairs of aggregated system calls which represent
the total amount of data exchanged. This means all network-related
system calls are aggregated and mapped to pairs of data exchanges
between two sockets, showing the amount of data exchanged be-
tween them in a time window. For file accesses, read and write
system calls that are called between an open and a close system
calls are aggregated together. For memory accesses, we only collect
mmap2 and munmap system calls which are used to allocate and
release memory pages. The continuously allocated or deallocated
memory pages are then aggregated to calculate pairs of memory
addresses showing the start and the end of each memory section.
3.2 Microservice and Process Role
Identification
In order to find a permanent and consistent solution for the problem
of the arbitrary and temporary process IDs, we use the concept
of identifying a role ID for each process which will be permanent
and consistent similar to [14]. However, the algorithm proposed
in [14] is subject to inconsistency when processes are created in
a different order since they are calculated based on the position
in the inheritance tree. This happens when different functionality
of the microservices are called in different order when they are
spawned in the data center. Also, different instantiation of the same
microservice (i.e. docker image) can be used for different purposes
in an application. To address these issues, in this paper we propose
a new method to identify the role of each process and microser-
vice (see Algorithm 1). The inheritance tree (i.e., pstree) is used to
compute the role IDs. The virtual layer portion of the inheritance
tree represents a specified functionality of the microservice and is
consistent in representing that functionality in the data center.
As it is described in Algorithm 1, first, we initialize the role ID
of each process with its binary hash (line 4-6). Then, by traversing
the tree from the leaves to the root (line 7), we concatenate each
process’ role ID with the concatenation of its children’s role IDs
(line 10). Finally, we concatenate each process’ role IDs with its
parent’s role ID from the root to the leaves (line 16). This algorithm
ensures that each process’ role ID is defined based on its own func-
tionality and all the other processes present in that microservice
functionality. Furthermore, we introduce thread role id by concate-
nating each thread’s name with its parent’s role ID (line 19). This is
vital for microservices that have a thread-based design to increase
performance and concurrency. At the end, we define the role ID of a
microservice by concatenating the process role IDs of all processes
running in that microservice (line 23).
The microservice role identification is used for the abstraction
of the service delivery components. This process’ main reason is to
decouple these components from their constantly changing imple-
mentation in the data center due to virtual environments’ dynamic
nature, such as migration, redundancy, microservice restarting, and
scaling; see Fig. 3 as an example.
In Fig. 3, each node represents a virtual entity (such as a process
or a file), whereas each edge represents a data flow between two
entities. In this example, there are two microservice types (i.e.,
two docker images) in which five instances (i.e., container) of one
type (colored black) with three instances of the other one (colored
gray) are running on three hosts. As we can see, regardless of
the quantity or physical location of the containers, DistAppGaurd
returns a single representation for the behaviour of the running
application.
Figure 3: DistAppGaurd’s single representation of a
microservice-based application regardless of the quantity
or physical location of the containers
The system calls gathered in the previous phase will be aggre-
gated and allocated to the identified roles rather than process IDs,
  System Call Collector MicroserviceRole IdentifierMicroserviceData ExchangeGraph Generator ML ModuleAutoencoder Training Detection ModuleTrained ModelReal-time DetectionDistAppGaurdAlertHost 1Host 2Host 3Step 1System Call Aggregator Step 2Step 3Step 4Step 5Step 6  Container 1Host 1 Container 2Container 3Container 7Host 3 Role IdentificationContainer 4Host 2 Container 3Container 8Intra-container data transferInter-container data transferContainer 5Container 6PID-187PID-132PID-412PID-13PID-112PID-104PID-67PID-323PID-256PID-201PID-453PID-212PID-554PID-78PID-325VirtFile-17VirtMem-7VirtFile-21VirtMem-63VirtFile-52VirtMem-12TID-47TID-10TID-85TID-41TID-96RID-11Role ID (RID)Process ID (PID)Thread ID (TID)RID-12RID-13RID-14RID-15RID-16RID-19RID-18RID-17RID-20RID-21RID-22840DistAppGaurd: Distributed Application Behaviour Profiling in Cloud-Based Environment
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
which can change at any time. As a result, since the role ID is de-
signed to be consistent, a restarted microservice’s activities can be
seen as a continuation of the previous microservice’s activities with
the same role. Furthermore, since the role ID is the same regardless
of where the microservice is instantiated or migrated in the data
center, we can monitor its activities as it moves or reappears. Finally,
in the case of redundancy and scaling out or in, the operations of
several microservices with the same role are easily aggregated since
they all share the same role ID.
data exchanges among virtual process role IDs and various virtual
resources in the data center over a specified time span (a sliding
window approach). Virtual process roles, I/O entities, and memory
sections are the vertices in this graph, while data exchanges are the
edges, with the direction of the data exchange preserved and the
amount of data that is exchanged is the weight of the graph.
end for
end for
11:
12:
13: end for
14: for i = 2 to d do
15:
16:
for process in li do
process[role_id] ← concat(process[role_id],
process[parent][role_id])
end for
17:
18: end for
19: for thread in pstree do
20:
thread[role_id] ← concat(thread[name],
thread[parent][role_id])
Initialisation :
Algorithm 1 Microservice and Process Role Identification
Input: MS_pstree
Output: MS_role_id
1: d ← depth of the pstree
2: li ← processes in the ith layer of the pstree
3: MS_role_id ← ””
4: for process in pstree do
5:
6: end for
7: for i = d − 1 to 1 do
for process in li do
8:
9:
10:
process[role_id] ← process[binary_hash]
for child in process[children] do
process[role_id] ← concat(process[role_id],
child[role_id])
Process Role Identification :
21: end for
Microservice Role Identification :
22: for process in pstree do
23: MS_role_id ← concat(MS_role_id, process[role_id])
24: end for
25: return MS_role_id
3.3 Microservice Data Exchange Graph
Generation
The microservice data exchange graph generation is almost iden-
tical to that of Malchain; thus, we only describe its overview and
refer the reader to the original paper [14] for details.
Malchain introduced the microservice data exchange graph (MS-
DEG), a concept for representing the behaviour of virtual applica-
tions that involves any data exchange between at least one virtual
process role and another virtual entity (e.g., virtual memory). The
MSDEG generator module creates a directed graph based on all
Figure 4: Microservice data exchange graph for user attach
procedure in LTE
In this paper, we increase the granularity of the MSDEG graph by
adding the threads of a process in the graph. For memory resources,
instead of presenting each memory page as a node that change
over time, we connect a new node through a bidirectional edge
to each process that represent the memory of that process. The
weight of edges towards the process and memory are allocated and
deallocated memory size, respectively. Fig. 4 shows the MSDEG
graph of an attach procedure in a distributed OpenAirInterface
implementation of LTE. During this procedure, the SPGWU and
the SPGWC allocate memory and the eNB reads from /online file.
3.4 ML Model Training and Anomaly Detection
Following the construction of a MSDEG for a virtual application in
each time interval, a vector of features reflecting the virtual appli-
cation’s behaviour is generated from the graph. To build this vector,
in [14], first, each node is vectorized (i.e, node embedding) using
graph feature functions (e.g., Betweenness Centrality). Then, by
aggregating these vectors, the graph is vectorized. However, during
this process some graph information will be lost. To tackle this issue,
we use the weight of the edges of the graph directly as our input
feature vector to feed our machine learning model by leveraging
neural networks, more precisely, Autoencoders [16]. In the follow-
ing, we first describe the Autoencoder model, then, we introduce
our microservice-aware Autoencoder model for microservice-based
virtual application profiling.
3.4.1 Anomaly Detection Using Autoencoders. Autoencoders are a
type of artificial neural networks which aim to produce an output
similar to the input in an unsupervised manner. They consists
of two parts, namely encoder and decoder as illustrated in Fig. 5.
Autoencoders compress the input data into a lower-dimensional
code (encoding), which is used to rebuild the output (decoding). By
  |  EMZNAHE Mengyuan Zhang  |  2020-11-24  |  Ericsson Internal  |  Page 10 of 19OAI containerization—Modify—Build in ERDC—7 VMsOAI containerization  Modified OAI test bed to containerization  Need some legend Small video, Join system, UE attach the system and explain how the system work, make a simple call from a container (1-3m) SPGWCSPGWUMMEHSSeNBRU threadData transferSPGWU MEMSPGWC MEMUE/onlineITTI 14MemoryFileThreadRoleHostProcessRoles841ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Ghorbani et al.
doing so, they learn a compressed representation of the input since
the number of neurons in the code are very smaller than the input.
The idea behind the anomaly detection with Autoencoders is
that if we feed the algorithm with only normal data, the model will
learn the pattern of the normal data and will be able to reproduce
the input data on the output with a low reconstruction error. On
the other hand, if we give an abnormal data that is generated by a
different pattern, the reconstruction error will be high. Therefore,
the reconstruction error can be compared with a preset threshold
to determine whether the data is anomaly or not.
Fig. 5 demonstrates an example of using Autoencoders for graph
anomaly detection. Each neuron in the input layer of the neural
network represents the value of the weight of a specific edge of the
graph. The root-mean-square error (RMSE) is then used to compare
the input and the output to decide if the input is an attack or not. In
our use case, Autoencoders present important advantages compared
to other unsupervised ML models: 1) They can learn from very long
input vectors 2) The training and detection are fast since they are
done by backpropagation and feeding forward 3) Online learning
is possible 4) They are capable of learning non-linear relationship.
of the same microserivce role id; i.e., their edges with the other
nodes of the first layer are dropped. The connections between the
fourth and fifth layer follow the same approach. The third layer
(i.e., code) is fully connected to the second and forth layer.
The idea behind this design is that since each microservice has a
set of specific functions, we first represent the behaviour of each