#一阶差分
ax1=
fig = plt.figure(figsize=(12,8))
fig.add_subplot(111)
disk_used
8
我们需要使用差分的方法来使该序列变为平稳序列。
机器学习－磁盘容量预测与处理机制103
---
## Page 109
本节使用LB 统计量的方法进行白噪声检验，代码如下：
验。如果为白噪声，则有用的信息已经被提取完毕，剩下的随机扰动，无法进行预测和使用。
104磁盘容量预测与处理机制－机器学习
第一种方法：人工识别根据自相关图和偏自相关图来确定 p 和α 的值。
确定 p 和 q 的值，建立 ARIMA (p,1,q)模型。
为了验证系列中是否还存在有用的信息，是否已经被提取完毕，需要对序列进行白噪声检
白噪声检验
else:
[[lb],[p]]=acirr_ljungbox(
else:
from statsmodels.stats.diagnostic import acorr_ljungbox 
print(u'原始序列经过%s阶差分后归于平稳,p值为%s’%(diff，adf[1]))
[1b], [p]]=acirr_ljungbox(dta,lag=1)
while adf[1]>=0.05:
#原始序列
#adf[1]为p值，
adf=ADF(dta)
#平稳性检测函数ADF
diff=0
from statsmodels.tsa.stattools i
print(u'一阶差分序列为
print(u'一阶差分序列为非日
print(u'原始序列为比
print(u'原始序列为非白
adf=ADF(dta)
diff=diff+1
字列
如果p值小于0.05则认为该序列是平稳的。
噪
山
(dta
声
噪声
序列
E
噪声
a.diff()
序列
序列，
 import adfuller as ADF
序列
对应的p值为%s',%)
对应的p值为%s',%p)
对应的p值为%s',%p)
) .dropna(),lag=1)
对应的p值为%s',%p)
---
## Page 110
个概念来说明效果：
平稳性检测
定值的所有组合的 BIC 信息量，去其中 BIC 信息量达到最小的模型阶数。
·报警减少率：预测覆盖率=预测报警且真正报警的机器数／报警的机器数
·预测准确率：预测准确率=预测报警且具有报警趋势的机器数／预测报警的机器数
有人可能会问这个系统可能依赖于预测模型的准确率。为了验证模型的准确率，我们提出来两
后图可以看出预测结果能够真实的反映出历史数据的走势，能够真实的预测出未来的数据值。
预测未来一段时间的值。
预测未来趋势
从7中获得了 p，q值，从 5 中获得d的值后我们就可以建立 ARIMA 模型了。
所以p 为 O，q为 O 第二种方法：相对最优模型识别计算 ARIMA(p,q)，当 p和q 均小于一
print predict_outcome[0] 
#我们可以从predict_outcome[0]获取到预测的结果
predict_outcome = model.forecast(24)
#predict_outcome中保存了预测结果、标准误差以及置信区间
model = ARIMA(dta, (p,d,q), freq='H').fit(trend='nc')
P,q = bic_matrix.stack().idxmin() 
#从中找到p和q的最小值
bic_matrix = []
qmax = int(len(dta)/10)
pmax=int（len（dta)/10)
#一般阶数不超过length/10
#迭代的阶数
bic_matrix.append(tmp)
for
try:
#存在部分p和q建模不成功
q in range(qmax):
except: 
tmp.append(None)
model_tmp = ARIMA(dta, (p,1,q), freq='H')
except:
try:
tmp.append(None) 
tmp.append(model_tmp.fit().bic)
机器学习－磁盘容量预测与处理机制105
---
## Page 111
通过这种预测与处理机制，能够尽可能减少磁盘报警，真正解放人力资源。
息发送给用户，由用户自己去处理。
定的风险，所以我们还有一种是通知邮件，我们会定期将扫描出来的占用空间比较大的文件信
写的不规范，业务访问量的增长，还是会有磁盘被写满的情况，所以单纯依靠自动清理会有一
及一些归档的日志文件。虽然我们有一定的目录规范和定期的日志轮转，但是因为有些程序编
以根据自己的意愿选择处理类型：一种是自动处理，一种是通知邮件。
智能处理
我们的模型能够获得比较好的效果。
果。可以发现我们的模型预测准确率能够达到100%，报警减少率能够达到70%左右，这说明
106磁盘容量预测与处理机制－机器学习
上面介绍的磁盘智能预测与处理机制已经在我们线上进行使用，并取得了比较好的效果。
如果是自动处理类型，我们会清理 100%可以确定删除的日志文件，比如 allweb 文件以
接下来将重点介绍在预测磁盘使用率将要达到阈值后，我们如何自动处理的过程。用户可
我们对线上的20000+台机器未来 24小时的走势进行预测，跟踪了将近一个月的预测结
disk_used
8
B
1
Jan142017
time(s)
---
## Page 112
本文链接：https://opsdev.cn/post/disk-predict.html
A：准确率接近100%，报警减少率接近70%.
Q：你们采用 AR 模型，效果怎么样？
我们可以将占比比较高的文件信息发送给用户，由用户来自己处理。
一种是自动清理，我们会处理一些日志文件（绝大部分的磁盘空间是因此导致的），当然如果觉得不稳妥，
A：比如磁盘空间使用率，在有比较好的预测模型后，预测出将要发生故障的机器后，会有两种处理策略：
Q：第一部分预测后自动处理能举一个例子吗？
面对面：
机器学习－磁盘容量预测与处理机制107
口
1一扫查看文章详
H
---
## Page 113
模型：
般为输输入层个数乘以2再加1，所以输出层为 49，输出层的个数为1，我们根据此规则建立
模型使用
具有隐患的故障扼杀在摇篮中，提高系统的可靠性和可用性。
输入的是非线性方程，可以处理更复杂的时间序列。
的 CPU的走势。在预测情况比较复杂的监控项时候，传统的 ARIMA 或者指数平滑的方法很
的方法来确保服务的可靠性和可用性。甚至有学者使用时间序列的预测模型来提前预测服务器
■智能预测之CPU预测
难达到比较好的效果，因为他们很难捕捉到以前从未出现过的情况。相反，神经网络模型由于
108智能预测之CPU预测－机器学习
由于我们的线上业务具有天的周期性，所以我们将输出层的个数设为 24，隐藏层的个数一
建立神经网络模型，首先要确定输入、
建立神经网络模型
我们采集过去7天的数据，采集间隔是1小时，使用下面代码得到历史的数据。
获取数据
本文采用神经网络模型去预测 CPU 的走势，提前预测出将要发生报警的机器，尽可能将
CPU是服务器正常运行的比较重要的指标之一。为了保证其性能，业界通常为其设定阈值
Jan. 19th 2017 BY 籍鑫璞
 :( .yuasuad pasn., epep .dueasaut.. Jezep)dtz
#将.csv数据读入Pandas数据帧
#将数据保存在mydata中
time_series =
data = pd.read_csv("cpu_idle_data.csv")
mydata
#从csv文件中读取时间和对应的数据
import datetime 
importdate
import csv 
#导入需要的模块
mydata.append(used_percent)
隐藏和输出层的神经元个数。
---
## Page 114
trainer.trainUntilConvergence(maxEpochs=1000)
#maxEpochs即你需要的最大收敛迭代次数，这里采用的方法是训练至收敛，此
训练时候采用 BP 神经网络：
from pybrain.supervised.trainers import BackpropTrainer
训练神经网络
from pybrain.datasets import SupervisedDataSet 
构造数据集
处设为1000
learningrate=0.01)
trainer = BackpropTrainer(fnn, ds, verbose = True,
fnn.sortModules()
#让神经网络可用
fnn.addconnection(hidden_to_out)
fnn.addconnection(in_to_hidden)
#将连接加入神经网络
hidden_to_out = Fullconnection(hiddenLayer, outLayer)
in_to_hidden = Fullconnection(inLayer, hidenLayer) 
#建立三层之间的连接
fnn.addoutputModule(outLayer)
fnn.addModule(hiddenLayer)
fnn.addInputModule(inLayer)
#将三层都加入神经网络(即加入神经元)
outLayer = LinearLayer(1, name="outLayer")
输出层
#设立三层，
fnn = FeedForwardNetwork()
from pybrain.structure import
xTest, yTest = dataTest["input"], dataTest["target"] 
xTrain, yTrain = dataTrain["input"],
dataTrain,dataTest = ds.splitWithProportion(0.8)
#把数据集切分成训练集和测试集，
for i in range(24,
ds = SupervisedDataSet(24, 1) 
output=data[i+1]
sample = data[i-24:i]
一层输入层（3个神经元，别名为inLayer），
len(data)-1):
训练集：测试集=8:2
机器学习－智能预测之CPU预测109
一层隐藏层，一层
---
## Page 115
本文链接：https://opsdev.cn/post/cpu-predict.html
一篇论文：PRACTISE: Robust Prediction of Data Center Time Series 
道了，而隐藏层一般是输入层跟输出层的综合考虑得到的一个数，输出层是你想要预测的时间窗口。推荐你看
Q：神经网络模型的输入，隐藏层，输出层具体使用哪些参数数据？
A：我们使用 Python里面的 pybrain 这个算法包去搭建的模型。
Q：请问你们采用的什么技术、语言进行的神经网络模型搭建？
面对面：
平稳性检测
A：输入层是跟踪自相关系数得到的，比如通过求1,2………，7得到7天的自相关系数最高，那么输入层就可以知
110智能预测之CPU预测－机器学习
如果普通的 BP 神经网络的效果不理想，可以尝试深度神经网络中的 RNN 模型。
上面输出层含有一个神经元，如果想预测多个时间点的数据，可以修改输出层的个数。
我们可以挑选出测试集中的任意一个数据来验证模型的好坏
验证与分析
print("true number is: " + str(yTest[c]),
#可以将其打印出来
prediction = fnn.activate(x2)
# activate函数即神经网络训练后,
X2 = xTest[c,:] 
#X2为xTest的一个随机样本点
C = random.randint(0, xTest.shape[0])
#c为从o到xTest的长度（包括o，不包括长度）
import random
"prediction number is:"
"error:"
 + str((prediction-yTest[c])/yTest[c]))
+ str(prediction),
预测的X2的输出值
之间的随机值
扫
一扫查看文章详情
口
25
1
---
## Page 116