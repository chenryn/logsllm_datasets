title:SOTER: A Runtime Assurance Framework for Programming Safe Robotics
Systems
author:Ankush Desai and
Shromona Ghosh and
Sanjit A. Seshia and
Natarajan Shankar and
Ashish Tiwari
SOTER: A Runtime Assurance Framework for
Programming Safe Robotics Systems
Ankush Desai‡, Shromona Ghosh‡, Sanjit A. Seshia‡, Natarajan Shankar∗, Ashish Tiwari∗†
‡University of California at Berkeley, CA, USA, ∗SRI International, Menlo Park, CA, USA, †Microsoft, Redmond, WA, USA
9
1
0
2
r
p
A
9
1
]
O
R
.
s
c
[
3
v
1
2
9
7
0
.
8
0
8
1
:
v
i
X
r
a
Abstract—The recent drive towards achieving greater au-
tonomy and intelligence in robotics has led to high levels of
complexity. Autonomous robots increasingly depend on third-
party off-the-shelf components and complex machine-learning
techniques. This trend makes it challenging to provide strong
design-time certiﬁcation of correct operation.
To address these challenges, we present SOTER, a robotics pro-
gramming framework with two key components: (1) a program-
ming language for implementing and testing high-level reactive
robotics software, and (2) an integrated runtime assurance (RTA)
system that helps enable the use of uncertiﬁed components,
while still providing safety guarantees. SOTER provides language
primitives to declaratively construct a RTA module consisting of
an advanced, high-performance controller (uncertiﬁed), a safe,
lower-performance controller (certiﬁed), and the desired safety
speciﬁcation. The framework provides a formal guarantee that a
well-formed RTA module always satisﬁes the safety speciﬁcation,
without completely sacriﬁcing performance by using higher per-
formance uncertiﬁed components whenever safe. SOTER allows
the complex robotics software stack to be constructed as a
composition of RTA modules, where each uncertiﬁed component
is protected using a RTA module.
To demonstrate the efﬁcacy of our framework, we consider
a real-world case-study of building a safe drone surveillance
system. Our experiments both in simulation and on actual drones
show that the SOTER-enabled RTA ensures the safety of the
system, including when untrusted third-party components have
bugs or deviate from the desired behavior.
I. INTRODUCTION
Robotic systems are increasingly playing diverse and safety-
critical roles in society, including delivery systems, surveil-
lance, and personal
transportation. This drive towards au-
tonomy is also leading to ever-increasing levels of software
complexity,
including integration of advanced data-driven,
machine-learning components. This complexity comes on top
of the existing challenge of designing safe event-driven, real-
time, concurrent software required for robotics applications.
However, advances in formal veriﬁcation and systematic test-
ing have yet to catch up with this increased complexity [1].
Moreover, the dependence of robotic systems on third-party
off-the-shelf components and machine-learning techniques is
predicted to increase. This has resulted in a widening gap
between the complexity of systems being deployed and those
that can be certiﬁed for safety and correctness.
One approach to bridging this gap is to leverage tech-
niques for run-time assurance, where the results of design-
time veriﬁcation are used to build a system that monitors
itself and its environment at run time; and, when needed,
1
switches to a provably-safe operating mode, potentially at
lower performance and sacriﬁcing certain non-critical objec-
tives. A prominent example of a Run-Time Assurance (RTA)
framework is the Simplex Architecture [2], which has been
used for building provably-correct safety-critical avionics [3],
[4], robotics [5] and cyber-physical systems [6], [7], [8].
The typical RTA architecture based on Simplex [2] (see
Figure 1) comprises three sub-components: (1) The advanced
controller (AC) that controls the robot under nominal operat-
ing conditions, and is designed to achieve high-performance
with respect to specialized metrics (e.g., fuel economy, time),
but it is not provably safe, (2) The safe controller (SC) that
can be pre-certiﬁed to keep the robot within a region of safe
operation for the plant/robot, usually at the cost of lower
performance, and (3) The decision module (DM) which is
pre-certiﬁed (or automatically synthesized to be correct) to
periodically monitor the state of the plant and the environment
to determine when to switch from AC to SC so that the system
is guaranteed to stay within the safe region. When AC is in
control of the system, DM monitors (samples) the system state
every ∆ period to check whether the system can violate the
desired safety speciﬁcation (φ) in time ∆. If so, then DM
switches control to SC.
Fig. 1. RTA Architecture
This Simplex-based
RTA architecture is a
very useful high-level
there
framework, but
are several
limitations
of its existing instan-
tiations. First, existing
techniques either apply
RTA [9], [10], [3] to a
single untrusted compo-
nent
in the system or
wrap the large monolithic system into a single instance of
Simplex which makes the design and veriﬁcation of the
corresponding SC and DM difﬁcult or infeasible. Second,
most prior applications of RTA do not provide high-level
programming language support for constructing provably-safe
RTA systems in a modular fashion while designing for timing
and communication behavior of such systems. In order to ease
the construction of RTA systems, there is a need for a general
programming framework for building provably-safe robotic
software systems with run-time assurance that also considers
implementation aspects such as timing and communication.
Finally, existing techniques do not provide a principled and
safe way for DM to switch back from SC to AC so as to keep
performance penalties to a minimum while retaining strong
safety guarantees.
In this paper, we seek to address these limitations by
developing SOTER, a programming framework for building safe
robotics systems using runtime assurance. A SOTER program is
a collection of periodic processes, termed nodes, that interact
with each other using a publish-subscribe model of communi-
cation (which is popular in robotics, e.g., in Robot Operating
System, ROS [11]). An RTA module in SOTER consists of an
advanced controller node, a safe controller node and a safety
speciﬁcation; if the module is well-formed then the framework
provides a guarantee that the system satisﬁes the safety speci-
ﬁcation. SOTER allows programmers to declaratively construct
an RTA module with speciﬁed timing behavior, combining
provably-safe operation with the feature of using AC whenever
safe so as to achieve good performance. SOTER provides a
provably-safe way for DM to switch back from SC to AC,
thus extending the traditional RTA framework and providing
higher performance. Our evaluation demonstrates that SOTER
is effective at achieving this blend of safety and performance.
Crucially, SOTER supports compositional construction of the
overall RTA system. The SOTER language includes constructs
for decomposing the design and veriﬁcation of the overall
RTA system into that for individual RTA modules while
retaining guarantees of safety for the overall composite system.
SOTER includes a compiler that generates the DM node that
implements the switching logic, and which also generates C
code to be executed on common robotics software platforms
such as ROS [11] and MavLink [12].
We evaluate the efﬁcacy of the SOTER framework by build-
ing a safe autonomous drone surveillance system. We show
that SOTER can be used to build a complex robotics software
stack consisting of both third-party untrusted components
and complex machine learning modules, and still provide
system-wide correctness guarantees. The generated code for
the robotics software has been tested both on an actual
drone platform (the 3DR [13] drone) and in simulation (using
the ROS/Gazebo [14] and OpenAI Gym [15]). Our results
demonstrate that the RTA-protected software stack built using
SOTER can ensure the safety of the drone both when using
unsafe third-party controllers and in the presence of bugs
introduced using fault injection in the advanced controller.
In summary, we make the following novel contributions:
1. A programming framework for a Simplex-based run-time
assurance system that provides language primitives for the
modular design of safe robotics systems (Sec. III);
2. A theoretical formalism based on computing reachable sets
that keeps the system provably safe while maintaining
smooth switching behavior from advanced to a safe con-
troller and vice-versa (Sec. III-C);
3. A framework for the modular design of run-time assurance
(Sec. IV), and
4. Experimental results in simulation and on real drone plat-
Fig. 2. Case Study: A Drone Surveillance System
forms demonstrating how SOTER can be used for guarantee-
ing correctness of a system even in the presence of untrusted
or unveriﬁed components (Sec. V).
II. OVERVIEW
We illustrate the SOTER framework for programming safe
robotics systems by using our case study of an autonomous
drone surveillance system.
A. Case Study: Drone Surveillance System
In this paper, we consider the problem of building a
surveillance system where an autonomous drone must safely
patrol a city. Figure 2 (left) presents a snapshot of the city
workspace from the ROS/Gazebo simulator [14] and Figure 2
(right) presents the corresponding obstacle map.
For our case study, we consider a simpliﬁed setting where
all the obstacles (houses, cars, etc.) are static, known a priori,
and that there are no environment uncertainties like wind. Even
for such a simpliﬁed setup the software stack (Figure 3) is
complex: consisting of multiple components interacting with
each other and uses uncertiﬁed components (red blocks).
Drone software stack. The application layer implements
the surveillance protocol that ensures the application speciﬁc
property, e.g., all surveillance points must be visited inﬁnitely
often. The generic components of the software stack consists
of the motion planner and the motion primitives.
For surveillance, the ap-
plication generates the next
target location for the drone.
The motion planner com-
putes a sequence of way-
points from the current lo-
cation to the target location
– a motion plan. The way-
points w1 . . . w6 in Figure 2
represent one such motion
plan generated by the plan-
ner and the dotted lines rep-
resent the reference trajec-
tory for the drone. Once the
motion primitive library re-
ceives the next waypoint, it generates the required low-level
controls necessary to closely follow the reference trajectory.
The solid trajectory in Figure 2 represents the actual trajectory
of the drone, which deviates from the reference trajectory be-
cause of the underlying dynamics. Programming such robotics
Fig. 3. Drone Software Stack
2
software stack is challenging as it is composed of individual
components, each implementing a complicated protocol, and
continuously interacting with each other for accomplishing the
mission safely.
In our drone surveillance case study, we would like the
system to satisfy two safety invariants: (1) Obstacle Avoidance
(φobs): The drone must never collide with any obstacle. (2)
Battery Safety (φbat): The drone must never crash because of
low battery. Instead, when the battery is low it must prioritize
landing safely (e.g., in Figure 2 (right), low battery is detected
at w6 and the mission is aborted to land safely). φobs can be
further decomposed into two parts φobs := φplan ∧ φmpr; (a)
Safe Motion Planner (φplan): The motion planner must always
generate a motion-plan such that the reference trajectory does
not collide with any obstacle, (b) Safe Motion Primitives
(φmpr): When tracking the reference trajectory between any
two waypoints generated by the motion planner, the controls
generated by the motion primitives must ensure that the drone
closely follows the trajectory and avoids collisions.
In practice, when implementing the software stack, the pro-
grammer may use several uncertiﬁed components (red blocks
in Figure 3). For example, implementing an on-the-ﬂy motion
planner may involve solving an optimization problem or using
an efﬁcient search technique that relies on a solver or a third-
party library (e.g., OMPL [16]). Similarly, motion primitives
are either designed using machine-learning techniques like
Reinforcement Learning [17], or optimized for speciﬁc tasks
without considering safety, or are off-the-shelf controllers
provided by third parties [12]. Ultimately, in the presence of
such uncertiﬁed or hard to verify components, it is difﬁcult to
provide formal guarantees of safety at design time. We assume
the state-estimators (green blocks) in Figure 3 are trusted and
accurately provide the system state within bounds.
Challenges and motivation: The robotics software (Figure 3)
must react to events (inputs) from the physical world as well
as other components in the software stack. These components
must
therefore be implemented as concurrent event-driven
software which can be notoriously tricky to test and debug
due to nondeterministic interactions with the environment and
interleaving of the event handlers. In SOTER, we provide a
language framework for both implementing and systematic
testing of such event-driven software. In practice, for complex
systems, it can be extremely difﬁcult to design a controller
that is both safe and high-performance. The AC, in general,
is any program or component designed for high-performance
under nominal conditions using either third-party libraries or
machine-learning techniques. We treat them as unsafe since
they often exhibit unsafe behavior in off-nominal conditions
and uncertain environments, and even when they do not, it
is hard to be sure since their complexity makes veriﬁcation
or exhaustive testing prohibitively expensive. Furthermore, the