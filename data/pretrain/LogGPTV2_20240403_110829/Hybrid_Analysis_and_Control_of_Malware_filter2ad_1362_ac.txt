7 Signal- and Exception-Handler Analysis
Analysis-resistant programs are often obfuscated by signal- and exception-based
control ﬂow. Static analyses cannot reliably determine which instructions will
raise signals or exceptions, and have diﬃculty ﬁnding signal and exception han-
dlers, as they are usually registered (and often unpacked) at run-time. Current
dynamic instrumentation tools do not analyze signal and exception handlers
[27,29], whereas we analyze them and provide analysis-based instrumentation on
them. This ability to analyze and control the handlers is important on analysis-
resistant binaries because the handlers may perform tasks that are unrelated to
signal and exception handling (e.g., PECompact overwrites existing code).
Signal and exception handlers can further obfuscate the program by redirect-
ing control ﬂow [38]. When a signal or exception is raised, the operating system
gives the handler context information about the fault, including the program
counter value. The handler can modify this saved PC value to cause the OS to
resume the program’s execution at a diﬀerent address. As shown in step 3 of
Figure 4, this technique is used by the “Yoda’s Protector” packer to obfuscate
330
K.A. Roundy and B.P. Miller
1:A store to address 0 causes an access vio-
lation and the OS saves the fault’s PC on
the call stack.
1a: The OS informs the attached SD-
Dyninst process of the exception.
1b: SD-Dyninst analyzes the registered
instruments its
exception handler,
exit points, and returns to the OS.
2:The OS calls the program’s exception
handler.
3:The handler overwrites the saved PC with
the address of the program’s original en-
try point.
3a: Instrumentation at the handler’s exit
point invokes SD-Dyninst.
3b: SD-Dyninst detects the modiﬁed PC
value, analyzes the code at that ad-
dress, and resumes the handler’s ex-
ecution.
4:The handler returns to the OS.
5:The OS resumes the program’s execution
at the modiﬁed PC value, which is the
program’s original entry point.
Fig. 4. The normal behavior of an exception-based control transfer used by Yoda’s
Protector is illustrated in steps 1-5. Steps 1a-1b and 3a-3b illustrate SD-Dyninst’s
analysis of the control transfer through its attached debugger process.
its control transfer to the program’s original entry point (OEP) [16]. Yoda’s Pro-
tector raises an exception, causing the OS to invoke Yoda’s exception handler.
The handler overwrites the saved PC value with the address of the program’s
OEP, causing the OS to resume the program’s execution at its OEP.
Analyzing Signal- and Exception-Based Control Flow. We ﬁnd and ana-
lyze handlers by intercepting signals and exceptions at run-time. Signal and ex-
ception interception is possible whether we observe the malware’s execution from
a debugger process or virtual machine monitor (VMM). In our current implemen-
tation, SD-Dyninst is apprised of raised signals and exceptions through standard
use of the debugger interface. A VMM-based implementation would automat-
ically be apprised of signals and exceptions, and would use VM-introspection
techniques to detect which of them originate from malicious processes [19].
As shown in Figure 4, upon notiﬁcation of the signal or exception, we analyze
and instrument the program’s registered handlers. We ﬁnd handlers in Windows
programs by traversing the linked list of structured exception handlers that is
on the call stack of the faulting thread. Finding handlers is even easier in Unix-
based systems because only one handler can be registered to each signal type.
We analyze the handler as we would any other function, and mark the faulting
instruction as an invocation of the handler.
We guard against the possibility that the handler will redirect control ﬂow
by instrumenting it at its exit points. After analyzing the handler, but before
it executes, we insert our exit-point instrumentation (step 1b of Figure 4). We
inform the analyst’s tool of the signal or exception and of the newly discovered
handler code so that it can add its own instrumentation. We then return control
Hybrid Analysis and Control of Malware
331
to the OS, which invokes the program’s exception handler. When the handler is
done executing, our exit-point instrumentation triggers a callback to our anal-
ysis engine (steps 3a-3b of Figure 4), where we check for modiﬁcations to the
saved PC value. If we detect a change, we analyze the code at the new address,
instrument it, and allow the analyst to insert additional instrumentation.
8 Experimental Results
We evaluated our techniques by implementing them in SD-Dyninst and applying
it to real and synthetic malware samples. We show that we can eﬃciently ana-
lyze obfuscated, packed, and self-modifying code by applying our techniques to
the binary packer tools that are most heavily used by malware authors, compar-
ing these results to two of the most eﬃcient existing tools. We demonstrate the
usefulness of our techniques by using SD-Dyninst to create a malware analysis
factory that we apply to a large batch of recent malware samples. Our analy-
sis factory uses instrumentation to construct annotated program CFG’s and a
stackwalk at the program’s ﬁrst socket communication.
8.1 Analysis of Packer Tools
Packed binaries begin their execution in highly obfuscated metacode that is often
self-modifying and usually unpacks itself in stages. The metacode decompresses
or decrypts the original program’s payload into memory and transfers control to
the payload code at the original program’s entry point.
Table 1 shows the results of applying our techniques to the packer tools that
are most often used to obfuscate malicious binaries, as determined by Panda
Research for the months of March and April 2008, the latest dates for which
such packer statistics were available [10]. We do not report results on some of
these packers because they incorporate anti-tampering techniques such as self-
checksumming, and SD-Dyninst does not yet incorporate techniques for hiding
its use of dynamic instrumentation from anti-tampering. We excluded NullSoft’s
installer tool (with 3.58% market share) from this list because it can be used to
create binaries with custom code-unpacking algorithms; though we can handle
the analysis-resistance techniques contained in most NullSoft-based packers, we
cannot claim success on all of them based on successful analysis of particular
packer instances. We also excluded the teLock (0.63% market share) and the
Petite (0.25% market share) packer tools, with which we were unable to produce
working binaries. The total market share of the packer tools listed by Panda
Research is less than 40% of all malware, while at least 75% of malware uses some
packing method [8,50]. This discrepancy is a reﬂection both of the increasing
prevalence of custom packing methods and a limitation of the study, which
relied on a signature-based tool to recognize packer metacode [11]; most custom
packers are derivatives of existing packer tools, which are often modiﬁed with
the express purpose of breaking signature-based detection.
In Table 1 we divide the execution time of the program into pre- and post-
payload execution times, representing the time it takes to execute the binaries’
332
K.A. Roundy and B.P. Miller
Table 1. Our analysis techniques applied to the most prevalent packer tools used to
obfuscate malware. We analyzed all of the packed binaries that do not employ anti-
tampering techniques.
code
ing
Time (seconds)
Pre-payload
instr. uninstr.
0.02
0.50
1.24
0.02
Post-payload
instr. uninstr.
0.02
0.02
2.80
2.81
yes
yes
yes
PolyEnE
EXECryptor
Themida
PECompact
Packer
UPX
Malware Over- Anti
market writes tamper- Pre-
exec’n
share
23.44
9.45%
6.21%
22.55
4.06%
2.95%
2.59%
2.08%
1.74%
1.29%
1.26%
0.89%
0.43%
0.37%
Yoda’s Protector 0.33%
0.17%
0.13%
UPack
nPack
ASPack
ASProtect
Armadillo
yes
yes
yes
yes
FSG
Nspack
yes
yes
yes
yes
yes
yes
yes
yes
WinUPack
MEW
22.81
3.16
22.56 23.50
23.21
1.54
4.42
22.58
1.38
22.53
22.52
2.69
22.44 23.60
22.56
3.87
0.02
0.03
0.02
0.02
0.03
0.03
2.81
4.08
2.80
2.81
2.78
2.78
0.02
0.02
0.02
0.02
0.02
0.02
0.03
0.03
4.10
2.80
0.02
0.02
metacode and payload code, respectively. In the uninstrumented case, we deter-
mine the proper time split by using a priori knowledge of the packed program to
breakpoint its execution at the moment that control transfers from its metacode
to its payload code. In the instrumented case, our code-discovery instrumenta-
tion automatically identiﬁes this transition by capturing the control transfer to
the payload code. We report on SD-Dyninst’s pre-execution cost separately, as
one of the major beneﬁts of incorporating static analysis techniques into our
approach is that we are able to frontload much of the analysis of the program
so that it does not aﬀect the program’s execution time.
The most striking diﬀerences in Table 1 are in the pre-payload cost incurred
by SD-Dyninst from one packer to the next. These diﬀerences are proportional
to the number of occasions in which we discover and analyze new code in the
metacode of these binaries. Our instrumentation of the UPX, PolyEnE, nPack,
and Nspack packers caused little slowdown in their execution, as their metacode
is static and not obfuscated in ways that substantially limit our ability to parse
them prior to their execution, while the FSG, MEW, ASPack, UPack, and Win-
Upack packers are more heavily obfuscated and unpack in stages, requiring that
we analyze their code incrementally. The largest contributor to the incremental
analysis cost is SD-Dyninst’s current inability to resolve the targets of indirect
control transfers at parse time, coupled with a simplifying implementation
decision to instrument whole functions at a time, meaning that discovery of
a new basic block currently causes its entire function to be re-instrumented.
SD-Dyninst’s performance will improve signiﬁcantly in the near future through
Hybrid Analysis and Control of Malware
333
Table 2. A comparison of pre-payload execution times and instrumented program
locations in SD-Dyninst, Renovo, Saﬀron, and EtherUnpack on packed executables.
Pre-payload time
Packer
UPX
ASPack
FSG
WinUpack
MEW
SD-D. Ren.
5
5
8
8
6
0.5
4.4
1.6
23.6
4.0
Saﬀ. Ether
7.6
2.7
18.7
fail
31.1
1.4
23.5
67.8
150.5
fail
Instrumented locations
SD-D.