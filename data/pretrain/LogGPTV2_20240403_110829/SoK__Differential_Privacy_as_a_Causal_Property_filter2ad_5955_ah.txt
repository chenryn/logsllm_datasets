guarantees provided by the existing DP mechanisms are valid
only under the assumption that the data tuples forming the
database are pairwise independent” [33, p. 2].
A somewhat different tack is taken in a 2016 paper by
Cuff and Yu, which instead focuses on the strong adversary
assumption [8, p. 2]:
The deﬁnition of (, δ)-DP involves a notion of
neighboring database instances. Upon examination
one realizes that this has the affect of assuming that
the adversary has already learned about all but one
entry in the database and is only trying to gather
additional information about the remaining entry.
We refer to this as the strong adversary assumption,
which is implicit
in the deﬁnition of differential
privacy.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:36:11 UTC from IEEE Xplore.  Restrictions apply. 
369
Yang et al.’s 2015 paper allows either assumption [49, §1.2]:
C. Details of Causation
Differential privacy is designed to preserve the
privacy in the face of intrusions by the strongest
adversary who exactly knows everything about all
individual entities except the object of its attack. [. . .]
In fact, as we will show in Section 3, differential
privacy does guarantee privacy against intrusion by
any adversary when all the entities in the database
are independent.
4) Responses: In addition to the aforementioned blog post
by McSherry [35], other works by those promoting the original
view of DP have also re-asserted that DP was never intended
to prevent all inferential privacy threats and that doing so is
impossible [3], [25], [36]. In a different blog post, McSherry
goes the furthest, questioning whether wholesale inferential
privacy is the normal meaning of “privacy” or even an ap-
pealing concept [36]. He calls it “forgettability”, invoking the
European Union’s right to be forgotten, and points out that
preventing inferences prevents people from using data and
scientiﬁc progress. He suggests that perhaps people should
only have an expectation to the privacy of data they own, as
provided by DP, and not to the privacy of data about them. He
challenges the line of research questioning DP (Appendix A3)
to justify the view that forgettability is a form of privacy.
We know no works explicitly responding to this challenge.
B. Counterexample Involving Zero Probability for Strong Ad-
versary D.P.
Consider Deﬁnition 2 modiﬁed to look at one distribution
P, which represents the actual distribution of the world.
Deﬁnition 10. A randomized algorithm A is said to be -
Strong Adversary Differentially Private for One Distribution
P if for all databases d, d(cid:48) ∈ Dn at Hamming distance at
most 1, and for all output values o, if Pr[D=d] > 0 and
Pr[D=d(cid:48)] > 0 then
PrP,A[O=o | D=d] ≤ e ∗ PrP,A[O=o | D=d(cid:48)]
(8)
where O = A(D) and D = (cid:104)D1, ..., Dn(cid:105).
To prove that this does not imply Deﬁnition 1, consider the
case of a database holding a single data point whose value
could be 0, 1, or 2. Suppose the population P is such that
PrP [D1=2] = 0. Consider an algorithm A such that for the
given population P,
PrA[A(0)=1] = 1/2
PrA[A(1)=1] = 1/2
PrA[A(2)=1] = 0
PrA[A(0)=0] = 1/2
PrA[A(1)=0] = 1/2
PrA[A(2)=0] = 1
(9)
(10)
(11)
The algorithm does not satisfy Deﬁnition 1 due to its behavior
on the input 2. However, using (3),
PrP,A[O=0 | D1=0] = 1/2 PrP,A[O=1 | D1=0] = 1/2
PrP,A[O=0 | D1=1] = 1/2 PrP,A[O=1 | D1=1] = 1/2
While (3) says nothing about D1=2 since that has zero
probability, this is sufﬁcient to show that the algorithm satisﬁes
Deﬁnition 10 since it only applies to data points of non-zero
probability. Thus, the algorithm satisﬁes Deﬁnition 10 but not
Deﬁnition 1.
We use a slight modiﬁcation of Pearl’s models. The models
we use are suggested by Pearl for handling “inherent” ran-
domness [42, p. 220] and differs from the model he typically
uses (his Deﬁnition 7.1.6) by allowing randomization in the
structural equations FV . We ﬁnd this randomization helpful
for modeling the randomization within the algorithm A.
Formally, let(cid:74)M(cid:75)((cid:126)x).(cid:126)Y be the joint distribution over values
ordering). That is,(cid:74)M(cid:75)((cid:126)x).(cid:126)Y ((cid:126)y) represents the probability of
for the variables (cid:126)Y that results from the background variables
(cid:126)X taking on the values (cid:126)x (where these vectors use the same
(cid:126)Y = (cid:126)y given that the background variables had values (cid:126)X = (cid:126)x.
Since the SEM is non-recursive this can be calculated in a
bottom up fashion. We show this for the model MA with
Di := Ri for all i, D := (cid:104)D1, ..., Dn(cid:105), and O := A(D):
(cid:74)MA(cid:75)(r1, ..., rn).Ri(ri) = 1
(cid:74)MA(cid:75)(r1, ..., rn).Di(ri)
(cid:74)MA(cid:75)(r1, ..., rn).D((cid:104)r1, ..., rn(cid:105))
= PrFDi
[FDi(Ri)=ri] = PrFDi
[Ri=ri] = 1
= PrFD [FD(D1, ..., Dn)=(cid:104)r1, ..., rn(cid:105)]
= PrFD [FD(FD1(R1), ..., FDn (Rn))=(cid:104)r1, ..., rn(cid:105)]
= PrFD [FD(R1, ..., Rn)=(cid:104)r1, ..., rn(cid:105)]
= PrFD [(cid:104)R1, ..., Rn(cid:105)=(cid:104)r1, ..., rn(cid:105)] = 1
and (cid:74)MA(cid:75)(r1, ..., rn).O(o) = PrFO [FO(D)=o]
= PrA[A((cid:104)r1, ..., rn(cid:105))=o]
We can raise the calculations above to work over P instead
of a concrete assignment of values (cid:126)x. Intuitively, the only
needed change is that, for background variables (cid:126)X,
(cid:88)
(cid:126)x∈ (cid:126)X
PrPA[ (cid:126)X=(cid:126)x] ∗(cid:74)MA(cid:75)((cid:126)x).(cid:126)Y ((cid:126)y)
PrMA,P [(cid:126)Y =(cid:126)y] =
where (cid:126)X are all the background variables.1
The following lemma will not only be useful, but will
illustrate the above general points on the model MA that
concerns us.
Lemma 1. For all algorithms A, P, all o, and all d1, ..., dn,
PrMA,P [O=o | do(D1:=d1, ..., Dn:=dn)]
= PrA[A(d1, ..., dn)=o]
Proof. Let Fdi() represent
the constant function with no
arguments that always returns di. The structural equation
for Di is Fdi in MA[D1:=d1]··· [Dn:=dn]. As before, we
compute bottom up, but this time on the modiﬁed SEM:
(cid:74)MA[D1:=d1]··· [Dn:=dn](cid:75)(r1, ..., rn).Ri(ri) = 1
1This is Pearl’s equation (7.2) raised to work on probabilistic structural
equations FV [42, p. 205].
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:36:11 UTC from IEEE Xplore.  Restrictions apply. 
370
and(cid:74)MA[D1:=d(cid:48)
1](cid:75)(r1, ..., rn).O(o)
= PrFO [FO(D)=o] = PrA[A((cid:104)d(cid:48)
1, r2, ..., rn(cid:105))=o]
Thus,
PrMA,P [O=o | do(D1:=d(cid:48)
1)]
1],P [O=o]
= PrMA[D1:=d(cid:48)
PrP [R1=r1, ..., Rn=rn]
=
r1,. . . ,rn∈Rn
PrP [R1=r1, ..., Rn=rn]
∗(cid:74)MA[D1:=d(cid:48)
1](cid:75)(r1, ..., rn).O(o)
1, r2, ..., rn(cid:105))=o]
PrP [R1=r1 | R2=r2, ..., Rn=rn]
∗ PrA[A((cid:104)d(cid:48)
1, r2, ..., rn(cid:105))=o]
∗ PrP [R2=r2, ..., Rn=rn]
∗ PrA[A((cid:104)d(cid:48)
PrP [R1=r1 | R2=r2, ..., Rn=rn]
∗ PrP [R2=r2, ..., Rn=rn]
∗ PrA[A((cid:104)d(cid:48)
1, r2, ..., rn(cid:105))=o]
r1,. . . ,rn∈Rn
r1,. . . ,rn∈Rn
(cid:88)
(cid:88)
r1∈R
r2,. . . ,rn∈Rn
(cid:88)
r2,. . . ,rn∈Rn
PrP [R2=r2, ..., Rn=rn]
∗ PrA[A((cid:104)d(cid:48)
1, r2, ..., rn(cid:105))=o]
PrP [R1=r1 | R2=r2, ..., Rn=rn]
∗ (cid:88)
r1∈R
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
=
=
=
=
=
=
=
(cid:74)MA[D1:=d1]··· [Dn:=dn](cid:75)(r1, ..., rn).Di(di)
(cid:74)MA[D1:=d1]··· [Dn:=dn](cid:75)(r1, ..., rn).D((cid:104)d1, ..., dn(cid:105))
= PrFD [FD(D1, ..., Dn)=(cid:104)d1, ..., dn(cid:105)]
= PrFD [FD(FD1 (), ..., FDn())=(cid:104)d1, ..., dn(cid:105)]
= PrFD [FD(d1, ..., dn)=(cid:104)d1, ..., dn(cid:105)]
= PrFD [(cid:104)d1, ..., dn(cid:105)=(cid:104)d1, ..., dn(cid:105)] = 1
[Fdi()=di] = 1
= PrFdi
(cid:74)MA[D1:=d1]··· [Dn:=dn](cid:75)(r1, ..., rn).O(o)
= PrFO [FO(D)=o] = PrA[A((cid:104)d1, ..., dn(cid:105))=o]
Thus,
PrMA,P [O=o | do(D1:=d1, ..., Dn:=dn)]
(cid:88)
= PrMA[D1:=d1]···[Dn:=dn],P [O=o]
(cid:88)
=
= PrA[A((cid:104)d1, ..., dn(cid:105))=o] ∗(cid:80)
PrP [ (cid:126)R=(cid:126)r] ∗ PrA[A((cid:104)d1, ..., dn(cid:105))=o]
PrP [ (cid:126)R=(cid:126)r] ∗(cid:74)MA[D1:=d1]··· [Dn:=dn](cid:75)((cid:126)r).O(o)
(cid:126)r∈Rn PrP [ (cid:126)R=(cid:126)r]
(cid:126)r∈Rn
(cid:126)r∈Rn
=
= PrA[A((cid:104)d1, ..., dn(cid:105))=o] ∗ 1
= PrA[A((cid:104)d1, ..., dn(cid:105))=o]
Lemma 2. For all algorithms A, P, o, j, and d(cid:48)
j,
(cid:88)
PrMA,P [O=o | do(Dj=d(cid:48)
j)]
=
(cid:88)
(cid:3)
PrP(cid:2)∧i∈{1,. . . ,j−1,j+1,. . . ,n}Ri=ri
PrMA,P(cid:2)∧i∈{1,. . . ,j−1,j+1,. . . ,n}Di=di
∗ PrA[A(r1, ..., rj−1, d(cid:48)
(cid:104)r1,. . . ,rj−1,rj+1,. . . ,rn(cid:105)∈Rn−1
=
(cid:3)
(cid:104)d1,. . . ,dj−1,dj+1,. . . ,dn(cid:105)∈Dn−1
∗ PrA[A(d1, ..., dj−1, d(cid:48)
j, dj+1, ..., dn)=o]
Proof. With out loss of generality, assume j is 1. Let Fd(cid:48)
()
represent the constant function with no arguments that al-
ways returns d(cid:48)
in
MA[D1:=d(cid:48)
1]. As before, we compute bottom up, but this
time on the modiﬁed SEM:
1. The structural equation for D1 is Fd(cid:48)
1
1
holds as before. The behavior of Di varies based on whether
i = 1:
[Fd(cid:48)
1) = PrFd(cid:48)
1](cid:75)(r1, ..., rn).Ri(ri) = 1
(cid:74)MA[D1:=d(cid:48)
1](cid:75)(r1, ..., rn).D1(d(cid:48)
(cid:74)MA[D1:=d(cid:48)
1](cid:75)(r1, ..., rn).Di(ri) = PrFDi
(cid:74)MA[D1:=d(cid:48)
1](cid:75)(r1, ..., rn).D((cid:104)d(cid:48)
(cid:74)MA[D1:=d(cid:48)
= PrFD [FD(D1, D2..., Dn)=(cid:104)d(cid:48)
(), FD2 (R2), ..., FDn(Rn))=(cid:104)d(cid:48)
= PrFD [FD(Fd(cid:48)
1, r2, ..., rn)=(cid:104)d(cid:48)
= PrFD [FD(d(cid:48)
= PrFD [(cid:104)d(cid:48)
1, r2, ..., rn(cid:105)]
1, r2, ..., rn(cid:105)] = 1
1, r2, ..., rn(cid:105))
1, r2, ..., rn(cid:105)]
for all i (cid:54)= 1. Thus,
1, r2, ..., dn(cid:105)=(cid:104)d(cid:48)
= PrFDi
1
1
1
()=d(cid:48)
1] = 1
[FDi(Ri)=ri]
[Ri=ri] = 1
1, r2, ..., rn(cid:105)]
j, rj+1, ..., rn)=o]
r2,. . . ,rn∈Rn
PrP [R2=r2, ..., Rn=rn]
∗ PrA[A((cid:104)d(cid:48)
1, r2, ..., rn(cid:105))=o] ∗ 1
r2,. . . ,rn∈Rn
d2,. . . ,dn∈Dn
PrP [R2=r2, ..., Rn=rn]
∗ PrA[A((cid:104)d(cid:48)
1, r2, ..., rn(cid:105))=o]
PrP [D2=d2, ..., Dn=dn]
∗ PrA[A((cid:104)d(cid:48)
1, d2, ..., dn(cid:105))=o]
where the last line follows since Di = Ri for i (cid:54)= 1.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:36:11 UTC from IEEE Xplore.  Restrictions apply. 
371