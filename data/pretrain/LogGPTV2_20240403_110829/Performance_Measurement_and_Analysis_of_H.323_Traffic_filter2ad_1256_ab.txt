### Legend:
- Research Network Link
- Satellite Network Link
- Commodity Network Link
- Cable Modem Network Link
- DSL Modem Network Link

### Figure 3: World Map Showing the Test Sites Involved in Each Path Under Test

Spirent SmartBits [18] technology was utilized to validate whether NISTnet accurately introduced the delay, jitter, and loss settings. The primary difference between the LAN and Internet tests in terms of NISTnet settings is that, in a LAN environment, the end-to-end delay, jitter, and loss are entirely controlled by NISTnet; whereas, in the Internet, the network paths already have inherent values of delay, jitter, and loss. Therefore, a pre-determination step for each test site's network path characteristics was required before configuring additional end-to-end delay, jitter, and loss on NISTnet. To accurately obtain these inherent network path characteristics, data from OARnet H.323 Beacon, NLANR Iperf, and appareNet (developed by Apparent Networks) were used. The end-to-end delay, jitter, and loss values configured on NISTnet for the Internet tests were determined by subtracting the inherent path characteristics values from the LAN NISTnet settings.

### 4. Analysis of Performance Bounds

Sites with research network connections traversing Abilene and GEANT backbones exhibited more consistent network path characteristics and overall results. This aligns with the popular opinion about the superior performance levels of these backbones, attributed to limited cross-traffic and low utilization levels. In contrast, sites with commodity Internet connections, cable modem, and DSL modem last-mile connections, as well as academic sites in Brazil and Korea, showed significant variations in network path characteristics, contributing the most to the variance in the overall results.

Figures 4-6 illustrate the subjective and objective Mean Opinion Score (MOS) rankings obtained during the testing for different scenarios of delay, jitter, and loss. The observed variance in the results is well within the performance bounds values of delay, loss, and jitter stated in Section 2.3. This clearly demonstrates that our LAN results are scalable to the Internet. Additionally, the MOS values plotted in Figures 4-6 include those obtained from tasks involving the H.323 Beacon, highlighting its utility in determining user-perceived audiovisual quality in H.323 production systems without remote end-user intervention.

#### Figure 4: Subjective and Objective MOS vs. Delay
#### Figure 5: Subjective and Objective MOS vs. Jitter
#### Figure 6: Subjective and Objective MOS vs. Loss

The correlation between objective and subjective scores was found to be in the above-average to strong range, with Pearson correlation coefficients for delay, jitter, and loss being 0.827, 0.737, and 0.712, respectively. The reasons for not all correlations being strong include the use of Emodel objective scores modeled after only audio traffic streams, diverse participant backgrounds (Videoconferencing Coordinators, Network Engineers, Graduate Students, Instructors, and IT Managers), and various types of hardware and software codec H.323 endpoints. The observed audio codecs at the endpoints were GSM, G.711, and G.722, while the video codecs were H.261, H.262, and H.263.

### Table 1: Results of Quality Grade Assessments for LAN/Internet Tests

| S6 | S7 | S8 | S9 |
|----|----|----|----|
| P  | G  | G  | A  |
| Delay | G  | A  | P  | G  |
| Jitter | G  | A  | P  | G  |
| Loss   | G  | A  | P  | P  |
| Result | G  | A/P| P  | A/P| A/P| G*/A| A  | A*/P| G  |

Legend:
- G → Good
- A → Acceptable
- P → Poor
- (S1-S9) → Scenarios 1-9

In the pursuit of identifying the most dominant factor among delay, jitter, and loss affecting end-user perception of audiovisual quality, we normalized the scales of these factors and plotted them against both the subjective and objective MOS assessments, as shown in Figures 7 and 8. Each unit in the normalized scale corresponds to a delay of 150ms, jitter of 20ms, and loss of 0.5%.

#### Figure 7: Effects of Normalized Delay, Jitter, and Loss Variations on Subjective MOS
#### Figure 8: Effects of Normalized Delay, Jitter, and Loss Variations on Objective MOS

We observed that end-user perception of audiovisual quality is more sensitive to changes in jitter than to changes in delay and loss. In fact, changes in delay have a low impact on the end-user’s perception of audiovisual quality, although delay values exceeding 3 units on the normalized scale are deemed unsuitable for interactive communications [14].

### 5. Conclusion and Future Work

In this paper, we determined the performance bounds for network metrics such as delay, jitter, and loss. We used these bounds to assess the impact of network health on end-user perception of audiovisual quality in H.323 applications. By emulating various network health scenarios in both LAN and Internet environments and using realistic Videoconferencing tasks, we demonstrated that end-user perception of audiovisual quality is more sensitive to variations in end-to-end jitter than to variations in delay or loss. In the Internet tests, considering almost every possible last-mile connection, we showed that the results obtained in LAN tests scaled consistently to the Internet.

Using valuable network traces obtained from one-on-one testing with various sites worldwide, we are currently studying the effects of jitter buffer sizes on packet discards under various network conditions using popular audio and video codecs. We are also investigating the effects of various packet sizes on the end-user perception of audiovisual quality in H.323 applications. The results of our studies could serve as troubleshooting information during periods of suspected network trouble affecting H.323 audio and video conferences. They can also foster a broader understanding of the behavior of audio and video traffic over the Internet, leading to better-designed networks in the future.

### References
1. ITU-T Recommendation H.323, Infrastructure of audiovisual services- Systems and terminal equipment for audiovisual services, Series H: Audiovisual and multimedia systems. (1999)
2. Markopoulou, A., Tobagi, F., Karam, M.: Assessment of VoIP quality over Internet backbones. In: Proceedings of IEEE Infocom. (2002)
3. Marsh, I., Li, F.: Wide area measurements of Voice Over IP Quality. SICS Technical Report T2003:08 (2003)
4. Eurescom reports of Europe-wide experimentation of multimedia services (1999)
5. ITU-T Recommendation G.107, The Emodel, a computational model for use in transmission planning. (1998)
6. ITU-T Recommendation P.911, Subjective audiovisual quality assessment methods for multimedia applications. (1998)
7. Mullin, J., Smallwood, L., Watson, A., Wilson, G.: New techniques for assessing audio and video quality in real-time interactive communications. IHM-HCI Tutorial (2001)
8. OARnet H.323 Beacon: a tool to troubleshoot end-to-end h.323 application performance problems. (http://www.itecohio.org/beacon)
9. Schopis, P., Calyam, P.: H.323 traffic characterization study. OARnet Technical Report submitted to American Distance Education Consortium (2001)
10. ITU-T Recommendation P.800, Methods for subjective determination of transmission quality. (1996)
11. ITU-T Recommendation P.862, An objective method for end-to-end speech quality assessment of narrowband telephone networks and speech codecs. (2001)
12. Clark, A.: Modeling the effects of burst packet loss and recency on subjective voice quality. (2001)
13. Schulzrinne, H., Casner, S., Frederick, R., Jacobson, V.: RTP: A transport protocol for real-time applications. RFC 1889 (1996)
14. ITU-T Recommendation G.114, One Way Transmission Time. (1996)
15. Kelly, B.: Quality of service in internet protocol (IP) networks (2002)
16. Indraji, A., Pearson, D.: The network: Internet2 commons site coordinator training (2003)
17. NISTnet network emulation package. (http://snad.ncsl.nist.gov/itg/nistnet/)
18. Spirent SmartBits network measurement suite. (http://www.spirentcom.com)