varies significantly on the value spaces of behaviors. In fact, both
IP address and client version are segmented. Two IP addresses that
share the same long prefix, i.e., 24 bits, belong to the same subnet
and hence they are highly correlated. Similarly, the client version
follows a similar pattern. Yuan et al. [37] map each IP address to its
highest 24 bits to aggregate those in the same class subnet. They
successfully correlate malicious accounts dispersing in a small sub-
net but also create massive groups on popular IP address segments.
Thus, we develop a dynamic segmentation method to group IP
addresses. It starts from the highest bit and separates the accounts
into two sets with the highest bit as 0 and 1. It recursively divides
these two account sets using the next highest bit until the size of
the account set drops below a given threshold fip or all the bits in
the IP address are set. Each of these account sets corresponds to
an IP address prefix. These IP address prefixes make up the new
behavior value set and form a denser bigraph. Similarly, we use
the dynamic segmentation technique to construct account-version
bigraphs.
Exponential segmentation. According to Section 3, the account’s
action counts range from 0 to 10k+. Therefore, it is costly to record
all distinct action counts as nodes. Intuitively, if two accounts have
close action counts, then the two accounts tend to behave similarly
and the action counts can be merged into a single one. Based on
this intuition, we divide the action counts into action groups, where
each group includes a range of action counts. Here, we design an
exponential segmentation mechanism. Specifically, if an account
has the action count in a range [2n + 1, 2n+1], where n = 0, 1, 2,· · · ,
then we map this action count to the (n + 2)-th action group. Note
that, we consider the number of actions for each action type, rather
than the total number of actions. In the account-action bigraph, an
attribute node is the action count set for a certain action type, e.g.,
we can use the set [9,16] and [33,64] to indicate “joining chatrooms"
and “commenting on other posts", respectively. Since the range is
[2, 2] when n = 0, the first group is empty and we set it as [0, 1],
which is consistent with the settings of other action groups.
Account-Behavior Bigraph ConstructionAccount-Account Graph ConstructionUnsupervised Maliciousness AssessmentGrowing-Up Account Detection.........Detected Growing-Up AccountsMusesUser Behaviors UUID XXXXXXX Action Login Time 158******* IP *.*.*.* Version *.*.* Other Behaviors… 302On Detecting Growing-Up Behaviors of Malicious Accounts in Privacy-Centric Mobile Social Networks
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
4.3 Account-Account Graph Construction
In the constructed bigraphs, the relationship between accounts is
not directly presented since there are no edges between accounts
in the account-behavior bigraph. To address this, we utilize Ran-
dom Walk with Restart (RWR) [18], an efficient graph learning
method that can capture semantic relationships between entities,
to construct an account-account graph that models the relationship
between accounts for each behavior. In particular, we construct an
account-account transition matrix from the bigraph, which effec-
tively addresses the issue that popular attributes of benign accounts
dominate unpopular attributes of growing-up accounts.
We take the IP address as an example to illustrate the process of
RWR. Suppose we already have the account-IP bigraph G = (V , E)
and aim to construct the account-account graph for IP address to
obtain the correlation between accounts. We can apply random walk
with restart, which gives the affinity between nodes in a graph, and
(t)
use the tth step probability distribution p
u as an approximation,
which can be iteratively computed as follows:
+ αeu ,
(t−1)
u
(t)
u = (1 − α)(S · T)p
p
(1)
(t)
u is the steady-state probability vector starting from node
where p
u in the tth iteration, α is the restart probability, S is the transition
matrix from account nodes to IP address nodes, T is that from IP
address nodes to account nodes and eu is the starting vector with
all elements 0 except for the entry that corresponds to node u to be
(t)
u represents the probability that a random
set 1. Each element in p
walker starting from node u find himself at the node corresponding
(0)
to that element. We set the initial probability distribution p
u equals
to the starting vector eu.
Base on the observation in Section 3, we know that behavior val-
ues have various popularities. Thus, we assign each attribute-value
node v a weight Hv = loд2|Γv|, where Γv is the set of the neighbors
of v. We use the logarithm to prevent prevalent behavior values
from dominating the transition matrix S, which can be written as:
(cid:40) Hv
Cu
0
Su,v =
v ∈ Γu
others
(2)
where Γu is the set of neighbors of u, Cu is the sum of the weight
of the neighbors of u.
Since we have no assumption on the maliciousness of accounts,
we assign equal weight to account nodes. Hence we construct a
behavior to account transition matrix T as:
u ∈ Γv
others
1
|Γu |
0
Tv,u =
(cid:26)
(3)
(k)
u1
(k)
p
u2
A(k) = [p
The account-account transition matrix A is then computed by:
(4)
where n is the number of accounts and k is the number of iterations
of RWR.
Based on results of random walk, we construct a weighted normal
graph G = (U , E), where U is the set of account nodes and E is the
set of edges:
(k)
un ]
p
· · ·
E = {(u1, u2, w)|u1 ∈ U , u2 ∈ U , w = A
(k)
u1u2 + A
(k)
u2u1}.
(5)
4.4 Unsupervised Maliciousness Assessment
After constructing the account-account graph for each behavior,
we can perform community detection to group accounts into com-
munities. Specifically, we adopt the typical community detection
algorithm, i.e., the Louvain method [2], which is effective and ef-
ficient to extract communities from large-scale networks. After
community detection, accounts in each community show high simi-
larities among each other, so that we can evaluate the maliciousness
of each account according to the communities. Existing methods
detect malicious accounts by identifying the communities whose
sizes are larger than a threshold to be malicious accounts. However,
as we discussed in Section 3, growing-up accounts pretend to be
benign and share similar behavior patterns with benign accounts.
As a result, growing-up accounts and benign accounts are very
likely to be mixed in the same community. Therefore, we can not
predict accounts to be growing-up ones simply based on the com-
munity size. To address this issue, we design a metric to evaluate
the maliciousness of each community in an unsupervised fashion
and identify growing-up accounts by evaluating the metric.
We note that malicious accounts are controlled by automated
scripts to boost efficiency and thus naturally share similar behav-
ior patterns, while benign accounts have diverse behavior patterns
since they are owned by different people. If all accounts in a commu-
nity have the same behavior attributes, e.g., if all accounts use the
same set of IP addresses, then all these accounts are very likely to
be malicious. In contrast, if accounts in a community have diverse
behavior attributes, e.g., if each account uses a different IP address,
then these accounts are very likely to be benign. Based on these in-
tuitions, we design a metric that can capture the similarity/diversity
of accounts’ behavior attributes. Specifically, given a behavior (IP
address, client version, action type) and a detected community, we
first calculate the number of attributes of each account in the com-
munity, i.e., account node degree in the account-behavior bigraph.
Then, we use the standard deviation of all accounts’ degrees to
compute the diversity of the community. However, in the account-
action bigraph, the number of edges for each account is equal to
the number of action types because each account has exactly one
action count for each action type. As a result, the standard deviation
of the account node degree is 0. Thus, we use the degree of the
action node rather than that of the account node to compute the
deviation. Specifically, we map accounts in each community to the
account-action bigraph and obtain a sub-bigraph, and then use the
standard deviation of the action node degree in the sub-bigraph to
represent the standard deviation of the community.
Suppose we have a set of |C| communities C = {c1, c2, ..., cn}. We
denote σ(ci) as the standard deviation of accounts’ degrees of com-
munity ci. Then, we define the malicious score s(ci) of community
ci as follows:
s(ci) = cmax − σ(ci)
cmax − cmin
,
(6)
where cmax = maxcj ∈C σ(cj) and cmin = mincj ∈C σ(cj). That is, if
a community has the minimum standard deviation, i.e., accounts in
this community have the most similar behavior patterns, then the
community has the largest malicious score of 1; if a community has
the maximum standard deviation, i.e., accounts in this community
303ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Zijie Yang1, Binghui Wang2, Haoran Li1, Dong Yuan1, Zhuotao Liu1, Neil Zhenqiang Gong3
Chang Liu4, Qi Li1, Xiao Liang5, Shaofeng Hu5
have the least similar behavior patterns, then the community has
the smallest malicious score of 0.
Furthermore, we set the malicious score of all accounts in a
community as the community malicious score. Note that one can
design new ways to assign different malicious scores for different
accounts in each community. However, our experimental results
demonstrate that this score assignment method is effective and has
already achieved promising performance. Finally, since we perform
community detection on the account-account graph constructed
based on each behavior, we have three malicious scores for each
account. For an account u, we denote its three malicious scores as
sI P(u), sV ER(u), and sACT (u), with respect to the IP address, client
version, and action count, respectively.
Recall that the growing-up accounts pretend to be benign and
share similar behavior patterns with benign accounts. However, we
find that malicious accounts in each community share similar be-
havior patterns and benign accounts have diverse behavior patterns.
Suppose there are two communities of IP addresses, i.e., malicious
and benign communities. The overall distribution of the number of
IP addresses associated with each type of accounts is similar to that
shown in Figure 1a, where growing-up and benign accounts have a
similar trend. However, we find that each benign community has
diverse IP addresses because different WeChat users are with differ-
ent locations, while the malicious community is with less diverse
IP addresses as they are probably controlled by the same group in
similar locations.
4.5 Growing-up Account Detection
Using the account’s malicious score from one single behavior do-
main is inadequate to detect growing-up accounts, as some behav-
ior attributes are shared by both benign and growing-up accounts.
Therefore, we propose to combine the account’s three malicious
scores into a single one. We also note that such a combination en-
hances the robustness of Muses against evasion attacks, as demon-
strated in Appendix A. Specifically, for each account u, we calculate
its final malicious score s(u) as the Root Mean Square (RMS) of
sI P(u), sV ER(u) and sACT (u) to measure the magnitude of the three
malicious scores. The final malicious score s(u) is defined as:
(cid:114)
sI P(u)2 + sV ER(u)2 + sACT (u)2
.
s(u) =
3
(7)
Note that, by applying RMS that considers three behavior do-
mains, we ensure that any manipulations in these domains cannot
interfere with the detection (see Appendix A). We find that benign
accounts suspicious in a single behavior domain will be ruled out
of the malicious list if they are benign in other domains, and vice
versa, thus achieving a high precision by Muses. These three mali-
cious scores contribute equally to the final malicious score of an
account. If an account is a growing-up account, all three malicious
scores should be higher than benign accounts. Actually, in order to
lower final malicious scores, the attacker has to lower at least two
malicious scores in two domains, which incurs significant costs.
The final malicious score s(u) can then be used for growing-up
account detection. For instance, we predict an account u to be a
growing-up account if s(u) > 0.5, and benign account, otherwise. In
practice, an administrator can choose a threshold value to balance
between precision and recall.
5 EVALUATION
In this section, we evaluate Muses using a real-world user behavior
dataset from WeChat. Particularly, we evaluate the effectiveness of
Muses, measure the generalizability of Muses, and demonstrate the
robustness of Muses against various evasion attacks.
5.1 Experimental Setup
Dataset: We obtain an anonymized dataset from WeChat, which
contains the first-week action records after registration of 440k
accounts including 300k malicious accounts and 140k benign ac-
counts. The labels of these accounts are provided and verified by the
WeChat security team. Among the malicious accounts, 24k accounts
perform the same actions frequently showing obvious malicious
intends. The remaining 276k malicious accounts are growing-up
accounts that show no particular malicious intends during the first
week but are labeled for their later malicious campaigns.
Parameter setting: As shown in Figure 1b, more than 99% of the
IP addresses are shared by less than 100 accounts, hence we set
the fip to 100 in the dynamic segmentation method. We use the
default setting of the random walk [14] and the Louvain method [2].
Notations and default values of key parameters are in Table 1.
Evaluation metrics: We draw the Precision-Recall curve to com-
pare the performance of Muses with other baseline methods. Besides,
we use AUC PR, the area under the PR curve, to quantify the ability
of Muses in detecting growing-up accounts.
Compared methods: We compare Muses with three state-of-the-
art malicious account detection methods, i.e., Clickstream [29],
SynchroTrap [6], and EvilCohort [21].
• Clickstream. Clickstream is the first work to detect malicious ac-
counts based on action patterns. It constructs an account-account
graph using action count distance as edge weights and performs
graph partition on the graph. It needs a small set of labeled ac-
counts to determine malicious communities.
• SynchroTrap. SynchroTrap takes action time into consideration
and builds an account-account graph using consistent action
proportion as edge weights. It filters out less similar edges and
extracts connected components as communities. The malicious
accounts are expected to group into large dense communities.
• EvilCohort. EvilCohort uses the number of shared IP addresses
between accounts as edge weights to build an account-account