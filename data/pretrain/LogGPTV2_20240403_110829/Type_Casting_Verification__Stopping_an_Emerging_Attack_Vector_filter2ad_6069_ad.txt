### Table 1: List of Vulnerabilities Newly Discovered by CAVER

All security vulnerabilities listed here have been confirmed and fixed by the corresponding development teams. The "Types" column indicates the classes causing bad-castings, including allocation, source, and destination classes. The "Security Implication" column details the security impacts of each vulnerability, such as C++ ABI incompatibility issues (ABI), memory corruption (Mem), and the actual security assessment ratings assigned by the vendor (Rating). Note that GNU libstdc++ members did not provide security ratings.

### Evaluation of CAVER on Known Bad-Casting Vulnerabilities

Table 2 shows our testing results for five known bad-casting vulnerabilities. CAVER successfully detected all vulnerabilities. These vulnerabilities were backported due to limited support for the LLVM/clang compiler in older Chromium versions, except for CVE-2013-0912.

### Comprehensive Testing with Test Cases

In addition to real vulnerabilities, we thoroughly evaluated CAVER using test cases designed based on all possible combinations of bad-casting vulnerabilities:
1. Whether an object is polymorphic or non-polymorphic.
2. The three object types: allocation, source, and destination.

This resulted in eight different unit tests, as shown in Table 3. CAVER's design handles both polymorphic and non-polymorphic classes, allowing it to successfully detect all cases. In contrast, UBSAN failed six cases, primarily due to its dependency on RTTI. More severely, UBSAN crashed in two cases when attempting to parse RTTI for non-polymorphic class objects, indicating the difficulty of using UBSAN without manual blacklists. Given that Firefox contains over 60,000 downcasts (see Table 4), creating such a blacklist would require significant manual engineering efforts.

### Protection Coverage

Table 4 summarizes our evaluation of CAVER’s protection coverage during instrumentation, including the number of protected types/classes (left half) and the number of protected type castings (right half). In our evaluation with C++ applications in SPEC CPU 2006, Firefox, and Chromium, CAVER covers 241% more types and protects 199% more type castings compared to UBSAN.

### Instrumentation Overheads

Table 5 details the increase in binary size due to various factors, including:
1. Inserted functions for tracing objects' type and verifying type castings.
2. Type hierarchy tables (THTable) for each class.
3. CAVER’s runtime library.

Although CAVER did not perform much instrumentation for most SPEC CPU 2006 applications, the file size increase was noticeable, mainly due to the statically linked runtime library (245 KB). The CAVER-hardened Chromium requires 6× more storage than Firefox because Chromium has more classes. The additional THTable overhead is the primary contributor to the file size increase. UBSAN increased the file size by 64% and 49% for Chromium and Firefox, respectively, indicating that THTable is a more efficient representation of type information compared to RTTI.

### Runtime Performance Overheads

We measured the runtime overheads of CAVER using SPEC CPU 2006’s C++ benchmarks and various browser benchmarks for Chromium and Firefox. For comparison, we also measured the original, non-instrumented version (compiled with clang) and the UBSAN-hardened version.

#### Microbenchmarks

To understand the performance characteristics of CAVER-hardened applications, we profiled micro-scaled runtime behaviors related to CAVER’s operations (Table 6). We used the built-in input for the two C++ applications of SPEC CPU 2006 and loaded the default start page of the Chromium and Firefox browsers. Overall, CAVER traced a considerable number of objects, especially for the browsers: 783k in Chromium and 15,506k in Firefox. Firefox performed 710% more castings than Chromium, indicating that the total number of verified castings and the corresponding performance overheads depend significantly on the application's implementation and usage patterns.

#### SPEC CPU 2006

With these application characteristics in mind, we measured the runtime performance impacts of CAVER on two SPEC CPU 2006 programs, xalancbmk and soplex. CAVER slowed down the execution of xalancbmk and soplex by 29.6% and 20.0%, respectively. CAVER-NAIVE (before applying the optimization techniques described in §4.4) slowed down xalancbmk and soplex by 32.7% and 20.8%, respectively. UBSAN caused xalancbmk to crash due to RTTI limitations in handling non-polymorphic types, and soplex became 21.1% slower.

#### Browser Benchmarks (Chromium)

To evaluate the end-to-end performance of CAVER, we measured the performance overhead of web benchmarks. We tested four browser benchmarks: Octane, SunSpider, Dromaeo-JS, and Dromaeo-DOM, each evaluating either the JavaScript engine or page rendering. Figure 4 shows the benchmark results for the Chromium browser. On average, CAVER showed a 7.6% overhead, while CAVER-NAIVE showed a 30.7% overhead, highlighting the effectiveness of the optimization techniques. UBSAN exhibited a 16.9% overhead on average.

### Summary

CAVER effectively detects and mitigates bad-casting vulnerabilities, providing comprehensive protection with minimal overhead. The tool outperforms UBSAN in terms of detection accuracy and efficiency, making it a valuable asset for enhancing the security of C++ applications.