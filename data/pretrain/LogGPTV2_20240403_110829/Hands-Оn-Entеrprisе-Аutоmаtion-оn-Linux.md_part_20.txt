- name: Copy MariaDB configuration files to host
template:
src: {{ item.src }}
dest: {{ item.dest }}
owner: root
group: root
mode: 0644
loop:
- { src: 'templates/mariadb.cnf.j2', dest: '/etc/mysql/mariadb.cnf' }
- { src: 'templates/50-server.cnf.j2', dest:
'/etc/mysql/mariadb.conf.d/50-server.cnf' }
notify:
- Restart MariaDB Server
[ 200 ]
Configuration Management with Ansible Chapter 7
Finally, we define a handler to restart MariaDB if the configuration has changed, as follows:
---
- name: Restart MariaDB Server
service:
name: mariadb
state: restarted
Now, before we run this, a word on variables. In Ansible, variables can be defined at a wide
number of levels. In a case such as this, where we are applying a different configuration to
different hosts with differing purposes, it makes sense to define the variables at the host or
hostgroup level. However, what happens if someone were to forget to put these in the
inventory, or in another appropriate location? Fortunately, we can leverage the variable
precedence order of Ansible to our advantage here and define default variables for our role.
These are second lowest on the order of precedence, so are almost always overridden by
another setting elsewhere, yet they provide a safety net, should they be missed accidentally.
As our preceding templates have been written, if the variables are not defined anywhere,
the configuration file will be invalid and the MariaDB server will refuse to start—a case we
would definitely like to avoid.
Let's define the default values for these variables in our role now under
defaults/main.yml, as follows:
---
mariadb_bind_address: "127.0.0.1"
mariadb_port: "3306"
mariadb_max_binlog_size: "100M"
With this complete, our role structure should look like this:
roles/
└── configuremariadb
├── defaults
│ └── main.yml
├── handlers
│ └── main.yml
├── tasks
│ └── main.yml
└── templates
├── 50-server.conf.j2
└── mariadb.cnf.j2
[ 201 ]
Configuration Management with Ansible Chapter 7
Naturally, we want to override the default values, so we will define these in our inventory
grouping—this is a good use case for inventory groups. All MariaDB servers that serve the
same function would go in one inventory group, and then have a common set of inventory
variables assigned to them, such that they all receive the same configuration. However, the
use of templates in our role means that we can reuse this role in a number of situations,
simply by providing differing configurations through variable definition. We will create an
inventory for our test host that looks like this:
[dbservers]
ubuntu-testhost
[dbservers:vars]
mariadb_port=3307
mariadb_bind_address=0.0.0.0
mariadb_max_binlog_size=250M
With this complete, we can finally run our playbook and observe what happens. The result
is shown in the following screenshot:
With this successfully run, we have shown a complete end-to-end example of how to
manage configuration on an enterprise scale, all while avoiding the pitfalls of regular
expression substitutions and multi-part configurations. Although these examples are
simple, they should serve as the basis for any well-thought-out enterprise automation
strategy where a configuration is required.
[ 202 ]
Configuration Management with Ansible Chapter 7
Summary
Managing configuration across an enterprise Linux estate is filled with pitfalls and the
potential for configuration drift. This can be caused by people with good intentions, even in
break-fix scenarios where changes have to be made in a hurry. However, it can also be
caused by those with malicious intent, seeking to circumvent security requirements. Good
use of Ansible, especially templating, enables the construction of easy-to-read, concise
playbooks that make it easy to ensure configuration management is reliable, repeatable,
auditable, and version-controlled—all the basic tenets we set out earlier in this book for
good enterprise automation practice.
In this chapter, you gained practical experience in extending a Linux machine with new
software packages. You then learned how to apply simple, static configuration changes to
those packages, and the potential pitfalls associated with this. Finally, you learned best
practices for managing configuration across an enterprise using Ansible. In the next
chapter, we proceed to look at internal repository management with Pulp.
Questions
1. What are the different Ansible modules commonly used for making changes to
configuration files?
2. How does templating work in Ansible?
3. Why must you consider configuration file structure when making changes with
Ansible?
4. What are the pitfalls of using regular expressions when making file
modifications?
5. How does a template behave if there are no variables in it?
6. How can you check that a configuration template you have deployed is valid
before committing it to disk?
7. How can you quickly audit the configuration of 100 machines against a known
template with Ansible?
Further reading
For an in-depth understanding of Ansible, please refer to Mastering Ansible, Third
Edition, by James Freeman and Jesse Keating (https:/​/​www.​packtpub.​com/​gb/
virtualization-​and-​cloud/​mastering-​ansible-​third-​edition).
[ 203 ]
3
Section 3: Day-to-Day
Management
This section covers how the management of Linux servers in the Enterprise does not end
with good build processes—it is vital that ongoing management is effective and efficient. In
this section, we will explore the use of Ansible and other tools to achieve these goals.
This section comprises the following chapters:
Chapter 8, Enterprise Repository Management with Pulp
Chapter 9, Patching with Katello
Chapter 10, Managing Users on Linux
Chapter 11, Database Management
Chapter 12, Performing Routine Maintenance with Ansible
8
Enterprise Repository
Management with Pulp
So far in this book, we have covered several tasks related to the build and configuration of
Linux servers for deployment in an Enterprise environment. While much of the work we
have completed scales well to cover most scenarios, it must be noted that so far we have
only installed packages from one of two sources—either the upstream public package
repositories corresponding to each Linux distribution we are using or, in the case of our
PXE booting chapter, from an ISO image we downloaded.
Needless to say, this presents several challenges, especially when it comes to creating
repeatable, manageable builds of Linux. We will explore these in greater depth in the
section titled Installing Pulp for patch management, but suffice to say, using the publicly
available repositories means that two builds being performed on two different weekdays
could be different! The ISO installation method presents the other end of the spectrum and
always produces consistent builds regardless of when they are performed, but in this case,
no security (or other) updates are received! What is required is a compromise between
these two extremes, and thankfully, one exists in the form of a software package called
Pulp.
We shall explore Pulp in this chapter, specifically covering the following:
Installing Pulp for patch management
Building repositories in Pulp
Patching processes with Pulp
Enterprise Repository Management with Pulp Chapter 8
Technical requirements
This chapter includes examples based on the following technologies:
Ubuntu Server 18.04 LTS
CentOS 7.6
Ansible 2.8
To run through these examples, you will need access to two servers or virtual machines
running one of each of the operating systems listed previously and Ansible. Note that the
examples provided in this chapter may be destructive in nature and if run as-is are only
intended to be run in an isolated test environment.
All example code discussed in this chapter is available on GitHub at the following URL:
https://github.com/PacktPublishing/Hands-On-Enterprise-Automation-on-Linux/tree
/master/chapter08.
Installing Pulp for patch management
Before we delve into the practical aspects of installing Pulp, let's take a more in-depth look
at why you would use it. Throughout this book, we have advocated building a Linux
environment that is standardized and features high degrees of repeatability, audibility, and
predictability. These are important not just as a foundation for automation, but also serves
as good practice in the enterprise.
Let's assume that you build a server and deploy a new service to it with Ansible, as we
have set out earlier in this book. So far, so good—the Ansible playbooks provide
documentation on the build standard and ensure the build can be accurately repeated at a
later date. There is a catch, however. Let's say that, a few months later, you return to create
another server—perhaps to scale an application or for a Disaster Recovery (DR) scenario.
Depending on the source for your packages, one of two things will happen:
If you install from the public internet-facing repositories, both builds will have
the latest versions of all the packages that were installed on the date they were
built. This difference may be significant, and if time has been put into testing and
qualifying software on a given build of Linux, you may not be able to guarantee
this with different package versions. Sure, everything is up to date, and you will
have all of the latest security patches and bug fixes, but every time you perform
this build on a different day, you are prone to getting different package versions.
This causes problems with repeatability, especially when ensuring that code that
has been tested in one environment works in another.
[ 206 ]
Enterprise Repository Management with Pulp Chapter 8
At the other end of the scale is the ISO build repositories that we used in Chapter
6, Custom Builds with PXE Booting. These never change (unless someone
downloads a newer ISO and extracts it over the old one), and so while it
produces builds that are of a completely known quantity (and hence support our
repeatability goal), they never receive any security updates. This in itself may be
a problem.
The compromise is, of course, to find a middle ground between these two extremes. What if
it were possible to create our own repositories of packages that were a snapshot of a given
point in time of a public repository? Hence, they remain static when we need them to (thus
ensuring consistent builds), and yet can be updated on demand if an important security fix
comes out. The Pulp project comes to our rescue here and is capable of doing exactly these
things. It is also a component in some of the more complex infrastructure management
solutions such as Katello, as we shall see in the next chapter.
However, for installations where a Graphical User Interface (GUI) is not a requirement,
Pulp meets our needs perfectly. Let's take a look at how we might install it.
Installing Pulp
As we discussed in Chapter 1, Building a Standard Operating Environment on Linux, in this
book, there will be times when even though you may have built a standardized operating
environment around a given Linux distribution such as Ubuntu Server, you have to create
an exception. Pulp is such a case, for although it can manage both .rpm and .deb packages
(hence handling repository requirements for a wide variety of Linux distributions), it is
only packaged for (and therefore is easiest to install) on CentOS, Fedora, and RHEL-based
operating systems. You can still manage your Ubuntu Server estate with Pulp—you just
need to install it on CentOS (or your preferred Red Hat variant).
There are several facets to the Pulp installation. For example, Pulp relies
on a MongoDB installation, which may be external if desired. Similarly, it
also relies on a message bus, and it is possible to use either RabbitMQ or
Qpid as preferred. Most organizations will have their own standards for
these things, and so it is left as an exercise to you to define the architecture
best suited to your enterprise. In this chapter, we will perform a very
simple installation of Pulp on a single server to demonstrate the steps
involved.
[ 207 ]
Enterprise Repository Management with Pulp Chapter 8
Given the relative complexity of installing Pulp, it is recommended that you create an
Ansible Playbook for your Pulp installation. However, in this chapter, we will complete the
installation manually to demonstrate the work involved—there is no one-size-fits-all Pulp
installation:
1. Before we can begin the installation, we must build a virtual (or physical) server
to host our Pulp repositories. For our example, we will base this on CentOS 7.6,
which is the latest supported version for Pulp at the time of writing. Also, note
the following filesystem requirements:
/var/lib/mongodb: We will build our example Pulp server with
MongoDB on the same host. The MongoDB database can grow to over
10 GB in size, and it is recommended to mount this path on a
dedicated LVM backed filesystem so that it can be easily grown if
required, and so that if it ever does fill up, it doesn't halt the rest of the
system.
/var/lib/pulp: This directory is where the Pulp repositories are
housed, and again it should be on a dedicated LVM backed filesystem.
The size will be determined by the repositories you wish to create—for
example, if you want to mirror a 20 GB upstream repository,
then /var/lib/pulp needs to be a minimum of 20 GB in size. This
filesystem also must be XFS-based—if created on ext4, you run the
risk of running out of inodes.
2. Once these requirements are met, we must install the EPEL repository as the
Pulp install will draw packages from here:
$ sudo yum install epel-release
3. We then need to install the Pulp repository file:
$ sudo wget -O /etc/yum.repos.d/rhel-pulp.repo
https://repos.fedorapeople.org/repos/pulp/pulp/rhel-pulp.repo
4. Next, we set up the MongoDB server—this must be completed before we proceed
with the Pulp installation. It is expected that most enterprises will have some
internal standards for the database servers that they will follow—here, we will
suffice with a default installation with SSL encryption:
$ sudo yum install mongodb-server
[ 208 ]
Enterprise Repository Management with Pulp Chapter 8
5. Again, it is fair to say that most enterprises will have their own certificate
authority, be it internal or otherwise. For our example server, we will generate a
simple self-signed certificate with the following command:
$ sudo openssl req -x509 -nodes -newkey rsa:4096 -keyout
/etc/ssl/mongodb-cert.key -out /etc/ssl/mongodb-cert.crt -days 3650
-subj "/C=GB/CN=pulp.example.com"
6. We then need to concatenate the private key and certificate into one file for
MongoDB to pick up:
$ sudo cat /etc/ssl/mongodb-cert.key /etc/ssl/mongodb-cert.crt |
sudo tee /etc/ssl/mongodb.pem > /dev/null
7. With this complete, we must reconfigure MongoDB to pick up the newly created
certificate file and enable SSL. Edit the /etc/mongod.conf file and configure the
following parameters (any other parameters in the file can be left at their
defaults):
# Use ssl on configured ports
sslOnNormalPorts = true
# PEM file for ssl
sslPEMKeyFile = /etc/ssl/mongodb.pem
8. At this stage, we can now enable the MongoDB service to start on boot and start
it:
$ sudo systemctl enable mongod.service
$ sudo systemctl restart mongod.service
9. With our Mongo database server running, we now need to install the message
bus. Again, most enterprises will have corporate standards for this and it is
recommended to adhere to these where they are defined. The following example
is the minimum required set of steps for a functional demo—it should not be
considered fully secured, but it is functional for the sake of testing and evaluating
pulp. Here, we simply install the required packages and then enable and start the
services:
$ sudo yum install qpid-cpp-server qpid-cpp-server-linearstore
$ sudo systemctl enable qpidd.service
$ sudo systemctl start qpidd.service
[ 209 ]
Enterprise Repository Management with Pulp Chapter 8
10. With our underlying infrastructure completed, we can now install Pulp itself.
The initial steps are to install the base packages:
$ sudo yum install pulp-server python-gofer-qpid python2-qpid qpid-
tools
Pulp uses a plugin-based architecture to host the various repositories it is capable
of serving. At the time of writing, Pulp is capable of hosting the following:
RPM-based repositories (for example, CentOS, RHEL, and Fedora)
DEB-based repositories (for example, Debian and Ubuntu)
Python modules (for example, for mirroring PyPI content)
Puppet manifests
Docker images
OSTree content
Unfortunately, this chapter does not allow us space to go into all of these modules
in detail—however, it is safe to say that, at a high-level, Pulp operates in the same
manner across all these different technologies. Whether working with Python
modules, Docker images, or RPM packages, you can create a central repository
that is stable and can be version controlled to ensure an up-to-date environment
can be maintained without losing control of what that environment contains.
As our use case is Pulp for serving out Linux packages, we will install the RPM-
and DEB-based plugins:
$ sudo yum install pulp-deb-plugins pulp-rpm-plugins
11. With Pulp installed, we must configure the core services. This is performed by
editing /etc/pulp/server.conf—most of the default settings are fine for a
simple demo such as ours—however, as we enabled SSL support on our
MongoDB backend, we must tell the Pulp server we have done this and disable
SSL verification as we are using self-signed certificates. The [database] section