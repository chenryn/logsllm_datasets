in benign documents presents a quite different pattern. From
the dotted line in Figure 6, we can clearly see that about
90% of benign documents have a ratio smaller than 0.2 and
almost no document has a ratio over 0.6. The results indicate
that this feature can effectively distinguish between benign
and malicious documents.
The statistical results of the other static features in ma-
licious documents are shown in Table VI. For boolean
features, “False” is denoted as 0 and “True” as 1. We found
that while empty objects can be found in malicious samples,
no benign documents contain empty object. This complies
with our intuition that people rarely have incentive to include
these junk objects in documents and normally they tend to
use automatic tools like this.addscript() and [43] to
insert Javascript. These tools rarely generate empty objects.
Unlike previous two features, more malicious samples use
header obfuscation and hex code. As a comparison, we only
found three benign documents with header obfuscation and
no benign document contains hex code. We believe this
is because usually PDF documents are created from other
formats like Microsoft Word and LaTeX using automatic
107107107
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:29:18 UTC from IEEE Xplore.  Restrictions apply. 
Figure 6: Ratio of PDF Objects on
Javascript Chain in Malicious and Benign
Documents
Figure 7: Memory Consumption of
Malicious and Benign Javascripts
Figure 8: Memory Consumption of PDF
Reader When Opening Many Documents
conversion tools. Such tools do not obfuscate document
header or structure. Finally, only about 1% of malicious
samples use multiple levels of encoding, and surprisingly
about 3% of them do not use any encoding. In benign
documents, we found that all of them use either zero or one
level of encoding. Overall, these ﬁve features complement
with the ﬁrst feature and enable us to more accurately
distinguish between benign and malicious documents.
Table VI: Statistics of Static Features of Malicious Documents.
XXXXXXXX
Feature
Header Obfuscation
Value
Hex Code
Empty Objects
Encoding Level
0/False
6792
6827
7357
233
1/True
578
543
5
7065
2
-
-
4
40
3
-
-
3
31
6
-
-
1
0
Memory Consumption: We randomly sampled 30 docu-
ments from each of two categories, “Known Benign” and
“Known Malicious”, respectively. All of the 30 selected
benign documents contain Javascript. Then, we measured
the memory consumption of the sampled 60 documents
in JS-context and the results are shown in Figure 7. As
we can see, one malicious sample can consume more than
1700 MB memory. On average, malicious samples consume
about 336.4 MB memory while benign documents consume
merely 7.1 MB. Moreover, the minimal memory consumed
by malicious samples is 103 MB but
the maximum by
benign samples is only 21 MB. These results indicate that
our context-aware monitoring of memory consumption could
be an effective feature to differentiate between benign and
malicious documents.
Context-aware v.s. Context-free. However, only if the
monitoring is conducted in JS-context, will memory con-
sumption be an effective feature. The context-free mon-
itoring could be inaccurate. In order to demonstrate the
deﬁciency of the context-free monitoring, we measure the
memory consumption of a PDF reader when different
number of documents are opened at the same time. Note
that opening many documents simultaneously is a common
practice in daily life. In our evaluation, we used Adobe
Acrobat 9.0 and four documents with various size from our
reference list, including [3] [5] [20] [29]. For each document,
we made 20 copies and recorded the memory consumption
of Acrobat when different number of copies were opened
simultaneously. The results are shown in Figure 8. In most
108108108
cases, the memory consumption increases linearly with the
inceasing number of opened documents and it can grow up
to 1600 MB. An exception is [3]. When the 15th copy is
opened, the memory consumption drops to a lower level
and then increases linearly again. We tested many times and
this effect appeared in every test. Our speculation is that
this speciﬁc document triggers some memory optimization
mechanisms in Acrobat. From these results, we can see that
it is almost impossible to set an appropriate threshold in the
context-free monitoring. A high value could miss a large
fraction of malicious documents while a low value may
generate many false positives. Besides, as shown in Figure
8, the memory increase of [29] is also very large. Thus, in
the context-free monitoring, the memory increase of a PDF
reader is not a good feature either. By contrast, our context-
aware monitoring is much more effective and accurate.
C. Detection Accuracy
We evaluate the detection accuracy of our prototype, in
terms of false positive rate and false negative rate. We tested
the malicious samples in VMware Workstation hosting Win
XP SP1 with Adobe Acrobat 8.0/9.0 installed. We ﬁrst
describe the parameter conﬁguration of our detector and then
present the detection results.
1) Parameter Conﬁguration
First, we normalize non-binary features, including F1, F4,
F5, and F8. The normalization rules are listed in Table VII.
According to Figures 6 and 7, we set F1 as 1 when the ratio
≥ 0.2 and F9 as 1 when the memory consumption ≥ 100
MB. Similarly, the values of F5 and F6 are set according to
Table VI. In this way, all 13 features can be represented in
binary values.
To set the weights and threshold, we need to meet the
criterion that a document is tagged as malicious iff at least
one JS-context feature and any other features have positive
values. The basic idea is that if no suspicious behavior is
detected in JS-context, the document contains no malicious
Javascript and thus it is out of the scope of our detection.
According to the criterion, we set w1 as 1, w2 as 9, and the
threshold as 10, respectively.
2) Detection Results
We measured the false positive and false negative rates
of the tuned detector over all benign documents with
Javascript (994) and one thousand randomly selected mali-
cious samples. The malicious samples cover vulnerabilities
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:29:18 UTC from IEEE Xplore.  Restrictions apply. 
Table VII: Parameter Conﬁgurations in Our System.
Table IX: Comparison With Existing Methods
Parameter
F1
F4
F5
F8
w1
w2
Threshold
Value
If ratio ≥ 0.2, F1 = 1; else F1 = 0;
If # of empty objects ≥ 1, F4 = 1; else F4 = 0;
If encoding level ≥ 2, F5 = 1; else F5 = 0;
If mem consumption ≥ 100 MB, F8 = 1; else F8 = 0;
1
9
10
Table VIII: Detection Results
Category
Benign Samples
Malicious Samples
Detected
Malicious
0
917
Detected
Benign
994
25
Noise
0
58
Total
994
1000
in Javascript interpreter, Flash, U3D (Universal 3D), TIFF
and JBIG2 image, etc. The detection results are shown in
Table VIII.
It can be seen that no benign sample is misclassiﬁed as
malicious, achieving zero false positive. There is only one
sample with suspicious behavior in JS-context. However,
since there is no other feature with positive value,
this
sample is still classiﬁed as benign. Afterwards, we checked
the sample and conﬁrmed that the script uses SOAP for
network access. The rest 993 samples are tagged as benign
simply because no suspicious JS-context behavior is moni-
tored, although some samples have positive values in other
features. Even though Javascript methods like SOAP and
ADBC can generate network accesses, we are reluctant to
white list them since we cannot decide the maliciousness of
the target server.
During the test, 58 (∼6%) of the malicious samples did
nothing when opened. Inspecting those samples, we found
that these samples exploited either CVE-2009-1492 [44] or
CVE-2013-0640 [45] which do not work on Adobe Acrobat
8.0/9.0. As these samples failed to exploit, we excluded
them when computing false negative rate. For the rest 942
samples, we successfully detected 917, with a detection rate
of 97.3%. We examined the 25 undetected samples and we
found two reasons that cause the misses. First, although
malicious Javascripts in these samples spray the heap, the
PDF reader process crashes when the scripts attempt to
hijack the control ﬂow. Second, the 25 undetected samples
use no obfuscation and thus no static feature contributes
to detection. Actually there are more than 25 samples that
crash the PDF reader process, but the others are detected
by our system via suspicious memory consumption and
static features. Although false negatives are unavoidable
when malicious PDF fails to exploit, it does not violate
our primary goal, i.e., protecting users from damages of
malicious PDF.
Table IX compares our method with previous countermea-
sures in terms of false positive rate and true positive rate. It is
clear that our method is comparable with the best fully static
methods [4] [5]. Since the malicious samples in our dataset
are not the most recent (the latest was captured in Feb. 2013),
we cannot fully demonstrate the superiority of our system
over the fully static methods. Thus, we further compare our
Method
N-grams [17]
PJScan [7]
PDFRate [4]
Structural [5]
MDScan [9]
Wepawet [18]
Ours
31%
16%
2%
0.05%
N/A
N/A
0
False Positive
True Positive
84%
85%
99%
99%
89%
68% [9]
97%
system with other methods by analyzing possible advanced
attacks.
• Our approach v.s. Structural methods: The mimicry
attacks proposed in [8] can effectively bypass these
structural methods [4] [5] [6] [7]. However, our ap-
proach is immune to the proposed attacks in that we
detect the malicious attempts from Javascript rather
than how malicious Javascript is stored in PDF.
• Our approach v.s. Anti-virus Software: There are a
whole bunch of tricks available in the wild to evade
anti-virus software [30] [46] [47]. Attackers can easily
generate variants using these tricks to defeat anti-
virus software. Compared with anti-virus software, our
method can effectively detect new variants and zero-
day malicious PDF in time because we use the incon-
cealable system-level behaviors of malicious PDF for
detection.
• Our approach v.s. Dynamic Analysis Tools: At-
tackers can subvert existing dynamic analysis tools
like CWSandbox [13] using event-triggering and
environment-sensitive malcode. Our method does not
suffer this limitation since we detect as real users
operate on malicious documents.
Based on the analysis of potential advanced attacks, we
can see that our method is more robust than existing defense
against malicious PDF.
D. System Performance
To measure the runtime overhead of our method, we run
our prototype on 32-bit Windows 7. We performed the tests
on a laptop with a 2.53 GHz Intel Core 2 Duo CPU processor
and 2 GB of RAM. The performance of each component in
our system is presented below.
1) Static Analysis and Instrumentation
Overall, it took about 297.7 seconds to process all 7370
malicious samples, i.e., 0.04 seconds on average for each
sample. We also measured the overhead when processing
the ﬁles with various sizes. We randomly selected three
benign and malicious documents, respectively. The sizes of
these documents are shown in Table X. One of the malicious
samples contains two scripts and the rest of ﬁve documents
contain only one script.
The execution time of each step in static analysis and
instrumentation is shown in Table X. We can see that the
overhead is minor for both large and small documents. In
particular, it took only about 5.5 seconds to process a 20
MB document. Considering that it could take 20 seconds to
download the document (in case of 1 MB/s), the additional
delay of 5.5 seconds for processing it is acceptable.
109109109
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:29:18 UTC from IEEE Xplore.  Restrictions apply. 
Table X: Execution Time (in seconds) of Static Analysis &
Instrumentation.
PDF
Size
2 KB
9 KB
24 KB
325 KB
7.0 MB
19.7 MB