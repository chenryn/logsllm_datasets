title:Next stop, the cloud: understanding modern web service deployment
in EC2 and azure
author:Keqiang He and
Alexis Fisher and
Liang Wang and
Aaron Gember and
Aditya Akella and
Thomas Ristenpart
Next Stop, the Cloud: Understanding Modern
Web Service Deployment in EC2 and Azure
Keqiang He, Alexis Fisher, Liang Wang, Aaron Gember, Aditya Akella, Thomas Ristenpart
{keqhe,aﬁsher,liangw,agember,akella,rist}@cs.wisc.edu
University of Wisconsin – Madison
ABSTRACT
An increasingly large fraction of Internet services are hosted on a
cloud computing system such as Amazon EC2 or Windows Azure.
But to date, no in-depth studies about cloud usage by Internet ser-
vices has been performed. We provide a detailed measurement
study to shed light on how modern web service deployments use
the cloud and to identify ways in which cloud-using services might
improve these deployments. Our results show that: 4% of the
Alexa top million use EC2/Azure; there exist several common de-
ployment patterns for cloud-using web service front ends; and ser-
vices can signiﬁcantly improve their wide-area performance and
failure tolerance by making better use of existing regional diversity
in EC2. Driving these analyses are several new datasets, includ-
ing one with over 34 million DNS records for Alexa websites and
a packet capture from a large university network.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Network]: General; C.4 [Perfo-
rmance of Systems]: Metrics—performance measures
General Terms
Measurement
Keywords
Web Service, Cloud Computing, EC2, Azure, DNS, trace analysis
1.
INTRODUCTION
Up until a few years ago, web services were hosted in heteroge-
neous server clusters or co-location centers that were widely dis-
tributed across different network providers and geographic regions.
Today, web services are increasingly being deployed in infrastruc-
ture-as-a-service (IaaS) clouds such as Amazon EC2, Windows
Azure, and Rackspace. Industry and the media claim that over 1%
of Internet trafﬁc goes to EC2 [31] and that outages in EC2 are
reputed to hamper a huge variety of services [4, 6, 24, 35].
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
IMC’13, October 23–25, 2013, Barcelona, Spain.
Copyright 2013 ACM 978-1-4503-1953-9/13/10 ...$15.00.
http://dx.doi.org/10.1145/2504730.2504740.
Despite the popularity of public IaaS clouds, we are unaware of
any in-depth measurement study exploring the current usage pat-
terns of these environments. Prior measurement studies have quan-
tiﬁed the compute, storage, and network performance these clouds
deliver [29, 30], evaluated the performance and usage patterns of
speciﬁc services that are hosted in these clouds, e.g., Dropbox [23],
or examined cloud usage solely in terms of trafﬁc volume [28].
We present the ﬁrst in-depth empirical study of modern IaaS
clouds that examines IaaS cloud usage patterns and identiﬁes ways
in which cloud tenants could better leverage IaaS clouds. We focus
speciﬁcally on web services hosted within IaaS clouds, which our
study (unsurprisingly) indicates is a large and important use case
for IaaS.
We ﬁrst examine who is using public IaaS clouds. We generate
a dataset of cloud-using domains using extensive DNS probing in
order to compare the IPs associated with websites on Alexa’s top
1 million list [1] against published lists of cloud IP ranges. This
identiﬁes that ≈40K popular domains (4% of the Alexa top mil-
lion) have a subdomain running atop Amazon EC2 or Windows
Azure, two of the largest public clouds. We extract an additional
≈13K cloud-using domains from a one week packet capture from
a large university network, and we use this capture to characterize
the network trafﬁc patterns of cloud-hosted web services. These
results indicate that a large fraction of important web services are
already hosted within public IaaS clouds.
We proceed to dissect how these services are using the cloud.
EC2 and Azure both have a veritable potpourri of features, includ-
ing virtual machines, load balancers, platform-as-a-service (PaaS)
environments, content-distribution networks (CDNs), and domain
name services. They also give tenants the choice of deploying
their services in several different regions (i.e., geographically dis-
tinct data centers), and EC2 provides several different “availability
zones” within each region. We couple analysis of DNS records with
two different cloud cartography techniques [34] to identify which
features, regions and zones web services use. We identify several
common front end deployment patterns and report estimates of the
percentages of Alexa subdomains using each of the patterns. In par-
ticular, we ﬁnd that about 4% of EC2-using web services use load
balancers and 8% of them leverage PaaS. Only 5% of the DNS
servers used by cloud-using subdomains run on VMs inside EC2
or Azure. We also show that 97% of the subdomains hosted on
EC2 and 92% of the subdomains hosted on Azure are deployed
in only a single region. Counted among these are the subdomains
of most of the top 10 (by Alexa rank) cloud-using domains. Ser-
vices deployed in EC2 also appear to make limited use of different
availability zones: our measurements estimate that only 66% of
subdomains use more than one zone and only 22% use more than
two. This lack of redundancy means that many (even highly ranked
(a) P1: VM front end
(b) P2: Load balancer front end
(c) P3: PaaS front end
(d) P4: Leverage CDN
Figure 1: Deployment patterns for web services.
Alexa) services will not tolerate single-region or even single-zone
failures.
Finally, we use a series of PlanetLab-based [17] active measure-
ments and simulations to estimate the impact of wide-area route
outages and the potential for wide-area performance improvement.
We ﬁnd that expanding a deployment from one region to three
could yield 33% lower average latency for globally distributed cli-
ents, while also substantially reducing the risk of service downtime
due to downstream Internet routing failures.
The remainder of our paper is organized as follows. We ﬁrst pro-
vide background on Amazon EC2 and Windows Azure and discuss
the primary datasets we use in our study (§2). We then examine
who is using the cloud (§3), and which cloud features, regions, and
zones are used by the cloud-using web services we identiﬁed (§4).
Based on these observations, we proceed to estimate the wide-area-
failure tolerance of current web service deployments and the poten-
tial for performance improvement (§5). Finally, we discuss related
work (§6) before concluding (§7).
2. MEASUREMENT SCOPE & DATASETS
Public IaaS clouds, such as Amazon EC2, Windows Azure, and
Rackspace, allow tenants to dynamically rent virtual machine (VM)
instances with varying CPU, network, and storage capacity. Cloud
tenants have the option of renting VMs in one or more geographi-
cally distinct data centers, or regions. Some clouds, such as EC2,
further divide these regions into multiple distinct availability zones.
Each zone has separate compute and power infrastructure to make
certain failure modes zone-speciﬁc and to allow cloud tenants to
replicate their deployments across multiple zones for smooth fail-
over.
Beyond simple VMs, IaaS providers, as well as third parties,
offer a wide-range of value-added features: load balancers (e.g.,
Amazon Elastic Load Balancer and Azure Trafﬁc Manager), plat-
form-as-a-service environments (e.g., Amazon Elastic Beanstalk,
Heroku, and Azure Cloud Services), content-distribution networks
(e.g., Amazon CloudFront and Azure Media Services), DNS host-
ing (e.g., Amazon route53), etc. The result is a complex ecosystem
of interdependent systems operating at multiple layers of abstrac-
tion, and, in turn, a large variety of possible deployment patterns
for cloud tenants. In this paper, we study four popular deployment
patterns. We describe these using a series of examples.
In Figure 1, we show the steps involved in a client accessing an
EC2-hosted web service that is using one or more of the aforemen-
tioned features. When a client wants to access a web service, it
ﬁrst performs a DNS lookup of the service’s domain name. The
response may contain an IP address associated with a VM (deploy-
ment pattern P1), a load balancer (P2), or a platform-as-a-service
(PaaS) node (P3). With P2, the client request is subsequently di-
rected to a VM1. Tenants using P1–P3 may also rely on additional
VMs or systems (dashed lines) to handle a client’s request; these
additional components may or may not be in the same region or
availability zone (indicated by the gray boxes). An object returned
to a client (e.g., a web page) may sometimes require the client to
obtain additional objects (e.g., a video) from a content-distribution
network (P4).
We focus on studying the front end portions of web service de-
ployments within the above four deployment patterns (indicated
by the thicker lines in Figure 1). These portions are encountered
within the initial few steps of a client making a request. We leave an
exploration of deployment/usage patterns covering the later steps
(e.g. back-end processing) for future work.
2.1 Datasets
We use two primary datasets: (i) a list of cloud-using subdo-
mains derived from Alexa’s list of the top 1 million websites, and
(ii) packet traces captured at the border of the UW-Madison cam-
pus network. Both datasets leverage the fact that EC2 [12] and
Azure [8] publish a list of the public IPv4 address ranges associ-
ated with their IaaS cloud offerings. Below, we provide details on
our Alexa subdomains and packet capture datasets. We augment
these data sets with additional traces and active measurements to
aid speciﬁc analyses; we describe these at the appropriate places in
subsequent sections.
Top Cloud-Using Subdomains Dataset. Our ﬁrst dataset is a list
of subdomains which use EC2 or Azure and are associated with do-
mains on Alexa’s list of the top 1 million websites [1]. We consider
a subdomain to use EC2 or Azure if a DNS record for that subdo-
main contains an IP address that falls within EC2 or Azure’s public
IP address ranges.
To construct this dataset, we ﬁrst identiﬁed the subdomains as-
sociated with each domain on Alexa’s list of the top 1 million web-
sites. We started with Alexa’s top 1 million list from Feburary 6,
2013 and attempted to issue a DNS zone transfer (i.e., a DNS query
of type AXFR) for each domain on the list. The query was suc-
cessful for only about 80K of the domains. For the remaining do-
mains, we used dnsmap [16] to identify subdomains by brute-force.
Dnsmap uses a pre-deﬁned word list, which we augmented with
the word list from knock [15], to construct potential subdomain
names. Dnsmap then runs DNS queries to check if the potential
subdomains actually exist. This brute-force approach misses some
subdomains, but it allows us to provide a lower bound on the num-
ber of subdomains which use public IaaS clouds and explore the
deployment patterns of these known cloud-using subdomains. We
distributed this task to 150 globally-distributed PlanetLab nodes,
producing a list of 34 million valid subdomains.
To limit the list of subdomains to cloud-using subdomains, we
performed a series of DNS lookups using the UNIX dig utility.
We ﬁrst performed a single DNS lookup from one PlanetLab node
(chosen from our set of 150 nodes) for each subdomain.
If the
DNS record contained an IP address within EC2 or Azure’s public
IP ranges2, we included it on our list of the top cloud-using subdo-
mains. This resulted in a list of 713K cloud-using subdomains. We
then performed a DNS lookup for each of the cloud-using subdo-
mains on every node in a set of 200 globally-distributed PlanetLab
nodes. Figure 2 shows the geographic location of these PlanetLab
1Or PaaS nodes, as is done by Amazon Elastic Beanstalk and Azure
Trafﬁc Manager.
2We assume the IP address ranges published by EC2 and Azure are
relatively complete.
Cloud
EC2
Azure
Total
Bytes
81.73
18.27
100
Flows
80.70
19.30
100
Table 1: Percent of trafﬁc volume and percent of ﬂows associated
with each cloud in the packet capture.
Protocol
ICMP
HTTP (TCP)
HTTPS (TCP)
DNS (UDP)
Other (TCP)
Other (UDP)
Total
EC2
Azure
Overall
Bytes
0.01
16.26
80.90
0.11
2.40
0.28
100
Flows
0.03
70.45
6.52
10.33
0.40
0.19
100
Bytes
0.01
59.97
37.20
0.10
2.41
0.31
100
Flows
0.18
65.41
6.92
11.59
1.10
14.77
100
Bytes
0.01
24.24
72.94
0.11
2.40
0.28
100
Flows
0.06
69.48
6.60
10.58
0.60
3.00
100
Table 2: Percent of trafﬁc volume and percent of ﬂows associated
with each protocol in the packet capture.
3.1 Protocols and Services
We ﬁrst examine the fraction of bytes and ﬂows in the packet
capture that are associated with each cloud (Table 1). We only
consider ﬂows that were initiated within the university and destined
for EC2 or Azure. We observe that the majority of cloud trafﬁc,
both as measured by volume and number of ﬂows, is EC2-related:
81.73% of bytes (80.70% of ﬂows) are associated with EC2, while
Azure accounts for 18.27% of bytes (19.30% of ﬂows).
Next, we use the packet capture to study the application-layer
protocols used by cloud tenants. Table 2 shows the percentage of
bytes (and ﬂows) using a speciﬁc protocol relative to the total num-
ber of bytes (and ﬂows) for EC2, Azure, and the capture as a whole.
We observe that more than 99% of bytes in the packet capture are
sent and received using TCP, with less than 1% of bytes associated
with UDP or ICMP. The vast majority of this TCP trafﬁc is HTTP
and HTTPS. The proportion of HTTPS trafﬁc is far higher than
that seen for general web services in the past (roughly 6% [18]);
as we will show later, HTTPS trafﬁc is dominated by cloud stor-
age services. Interestingly, the majority of Azure’s TCP trafﬁc is
HTTP (59.97%) while the majority of EC2’s TCP trafﬁc is HTTPS
(80.90%)
The breakdown by ﬂow count is less skewed towards TCP, with
UDP ﬂows accounting for 14% of ﬂows in the packet capture. This
is largely due to DNS queries, which account for 11% of ﬂows but
carry few bytes.
As one would expect, public IaaS clouds are also used for non-
web-based services. In the packet capture, we ﬁnd a small fraction
of non-HTTP(S) TCP trafﬁc and non-DNS UDP trafﬁc going to
both EC2 and Azure. This trafﬁc includes SMTP, FTP, IPv6-in-
IPv4, SSH, IRC, and other trafﬁc that Bro could not classify.
Summary and implications. While we analyze a single vantage
point, our measurements suggest that web services using HTTP(S)
represent an important set of WAN-intensive cloud tenants. The
extent to which compute-intensive workloads (that may not result
in a large impact on network trafﬁc) are prevalent as cloud tenants
remains an interesting open question. In the following sections we
dig into what tenants are hosting web services on public clouds as
well as diving deeper into their trafﬁc patterns.
3.2 Popular Cloud-Using (Sub)Domains
Cloud-using Alexa domains. We now consider what subset of the
Alexa top 1 million websites use the cloud to (partly) host their
services. Recall that Alexa provides an estimate of the most pop-
Figure 2: PlanetLab nodes used for DNS lookups
nodes, which are spread across North America, South America,
Europe, Asia, and Australia. The queries were performed March
27-29, 2013. These distributed DNS queries help ensure that we
gather a comprehensive set of DNS records for each cloud-using
subdomain and capture any geo-location-speciﬁc cloud usage.
We refer to the list of cloud-using subdomains, and their associ-
ated DNS records, as the Alexa subdomains dataset.
Packet Capture Dataset. Our second primary dataset is a se-
ries of packet traces captured at the border of the University of
Wisconsin-Madison campus network3. We captured full IP packets
whose source or destination IP address fell within the public ad-
dress ranges published by EC2 and Azure. The capture was per-
formed from Tuesday, June 26 to Monday, July 2, 2012 giving
us a full week of trafﬁc and a total of 1.4TB of data. The total
Internet trafﬁc averaged approximately 7Gbps during the capture,
with about 1% of the trafﬁc going to/coming from EC2 or Azure.
Due to the relatively low rate of trafﬁc being captured, no loss oc-
curred during the capture process (according to tcpdump and coun-
ters reported by the border router). To protect user privacy, we
anonymized the IP addresses of clients within the university net-
work, and we only report aggregate statistics.
Since our traces contain full packets, we were able to perform an
in-depth analysis of network and transport layer information (e.g.,
IP addresses, protocols, ports), application layer information (e.g.,
HTTP hostnames, HTTP content-type, HTTPS certiﬁcates), and
packet payloads. We extracted relevant information from the traces
using Bro [33], a network monitoring and trafﬁc analysis tool. We
refer to these traces as the packet capture dataset.
We recognize that a packet trace from a single campus vantage
point may not reﬂect the “typically” usage patterns of services de-
ployed in IaaS clouds. Correspondingly, we only leverage the pack-
et capture for analysis which cannot be conducted using our Alexa
subdomains dataset—namely, protocol usage (§3.1), popularity es-
timates based on trafﬁc volume and ﬂow counts (§3.2), and ﬂow
characteristics (§3.3).
3. WEB-FACING CLOUD TENANTS
In this section, we explore what applications are being hosted
on public IaaS clouds. We start by analyzing the packet capture
to identify the types of applications being hosted. This analysis
suggests (unsurprisingly) that web applications represent a large,
important set of cloud tenants. We then turn to examining which
of the most popular websites are using clouds. We view popularity
both globally, via the Alexa top website rankings, and locally, via
the volume of trafﬁc associated with each domain in the packet cap-
ture. We also analyze the trafﬁc patterns of cloud-using services,
including ﬂow characteristics and content types served.