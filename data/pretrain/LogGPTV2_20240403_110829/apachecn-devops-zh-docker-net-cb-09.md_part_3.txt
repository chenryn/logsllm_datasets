user@net1:~$ sudo ip link add macvlan1 link eth0 type macvlan
```
接下来，我们将接口移动到新创建的网络命名空间中:
```
user@net1:~$ sudo ip link set macvlan1 netns namespace1
```
最后，从命名空间中，我们为它分配一个 IP 地址，并将其调出:
```
user@net1:~$ sudo ip netns exec namespace1 ip address \
add 172.16.10.5/24 dev macvlan1
user@net1:~$ sudo ip netns exec namespace1 ip link set \
dev macvlan1 up
```
为了测试的目的，让我们在第二个命名空间中创建第二个接口:
```
user@net1:~$ sudo ip netns add namespace2
user@net1:~$ sudo ip link add macvlan2 link eth0 type macvlan
user@net1:~$ sudo ip link set macvlan2 netns namespace2
user@net1:~$ sudo ip netns exec namespace2 ip address \
add 172.16.10.6/24 dev macvlan2
user@net1:~$ sudo ip netns exec namespace2 ip link set \
dev macvlan2 up
```
### 注
当您使用不同的配置时，创建和删除同一个界面很多次是很常见的。这样做，您可能会生成具有相同 IP 地址但不同 MAC 地址的接口。因为我们将这些媒体访问控制地址呈现给上游物理网络，所以一定要确保上游设备或网关拥有您试图到达的 IP 的最新 ARP 条目。许多交换机和路由器通常会有很长的 ARP 超时值，在此期间，它们不会为较新的 MAC 条目进行 ARP。
此时，我们有一个拓扑，看起来像这样:
![How to do it…](img/5453_09_04.jpg)
父接口(`eth0`)和以前一样有一个 IP 地址，但这次，MacVLAN 接口位于它们自己唯一的名称空间内。尽管位于不同的命名空间中，但它们仍然共享同一个父级，因为这是在将它们移入命名空间之前完成的。
此时你应该注意到外部主机不再能 ping 通所有的 IP 地址。而是只能到达`172.16.10.2`的`eth0` IP 地址。原因很简单。大家会记得，名称空间相当于一个**虚拟路由和转发** ( **VRF** )并且有自己的路由表。如果您检查这两个名称空间的路由表，您会发现它们都没有默认路由:
```
user@net1:~$ sudo ip netns exec namespace1 ip route
172.16.10.0/24 dev macvlan1  proto kernel  scope link  src 172.16.10.5
user@net1:~$ sudo ip netns exec namespace2 ip route
172.16.10.0/24 dev macvlan2  proto kernel  scope link  src 172.16.10.6
user@net1:~$
```
为了使这些接口可以通过网络到达，我们需要给每个名称空间一个指向该子网中网关的默认路由(`172.16.10.1`)。同样，这也是寻址与父接口位于同一子网中的 MacVLAN 接口的好处。路由已经在物理网络上了。添加路线并再次测试:
```
user@net1:~$ sudo ip netns exec namespace1 ip route \
add 0.0.0.0/0 via 172.16.10.1
user@net1:~$ sudo ip netns exec namespace2 ip route \
add 0.0.0.0/0 via 172.16.10.1
```
从外部测试主机(为简洁起见，删除了一些输出):
```
user@test_server:~$ ping 172.16.10.2 -c 2
PING 172.16.10.2 (172.16.10.2) 56(84) bytes of data.
64 bytes from 172.16.10.2: icmp_seq=1 ttl=63 time=0.459 ms
64 bytes from 172.16.10.2: icmp_seq=2 ttl=63 time=0.441 ms
user@test_server:~$ ping 172.16.10.5 -c 2
PING 172.16.10.5 (172.16.10.5) 56(84) bytes of data.
64 bytes from 172.16.10.5: icmp_seq=1 ttl=63 time=0.521 ms
64 bytes from 172.16.10.5: icmp_seq=2 ttl=63 time=0.528 ms
user@test_server:~$ ping 172.16.10.6 -c 2
PING 172.16.10.6 (172.16.10.6) 56(84) bytes of data.
64 bytes from 172.16.10.6: icmp_seq=1 ttl=63 time=0.524 ms
64 bytes from 172.16.10.6: icmp_seq=2 ttl=63 time=0.551 ms
```
因此，虽然外部连接看起来像预期的那样工作，但您会注意到没有一个接口可以相互通信:
```
user@net1:~$ sudo ip netns exec namespace2 ping 172.16.10.5
PING 172.16.10.5 (172.16.10.5) 56(84) bytes of data.
--- 172.16.10.5 ping statistics ---
5 packets transmitted, 0 received, 100% packet loss, time 0ms
user@net1:~$ sudo ip netns exec namespace2 ping 172.16.10.2 
PING 172.16.10.2 (172.16.10.2) 56(84) bytes of data.
--- 172.16.10.2 ping statistics ---
5 packets transmitted, 0 received, 100% packet loss, time 0ms
user@net1:~$
```
这似乎很奇怪，因为它们都共享同一个父接口。问题在于 MacVLAN 接口是如何配置的。MacVLAN 接口类型支持四种不同的模式:
*   **VEPA**:**虚拟以太网端口聚合器** ( **VEPA** )模式会强制所有来源于 MacVLAN 接口的流量离开父接口，而不考虑目的地。即使是发往共享同一父接口的另一个 MacVLAN 接口的流量也要遵守此政策。在第 2 层场景中，由于标准的生成树规则，两个 MacVLAN 接口之间的通信可能会被阻塞。您可以在上游路由器上在两者之间进行路由。
*   **网桥**:MAC VLAN 网桥模式模仿标准的 Linux 网桥。允许同一父接口上的两个 MacVLAN 接口之间的通信直接发生，而无需将父接口从主机上转移出去。这对于您期望高级接口在同一父接口上进行接口通信的场景非常有用。
*   **Private** :这个模式类似于 VEPA 模式，增加了完全阻断同一父接口上接口之间通信的能力。即使您允许流量通过父节点，然后再重新进入主机，通信也会中断。
*   **直通**:意在作为直接将父接口绑定到 MacVLAN 接口的手段。在这种模式下，每个父节点只允许有一个 MacVLAN 接口，并且 MacVLAN 接口从父节点继承 MAC 地址。
虽然不知道从哪里看不容易辨别，但我们的 MacVLAN 接口碰巧是 VEPA 类型的，这恰好是默认的。我们可以通过将详细信息(`-d`)标志传递给`ip`命令来看到这一点:
```
user@net1:~$ sudo ip netns exec namespace1 ip -d link show
1: lo:  mtu 65536 qdisc noop state DOWN mode DEFAULT group default
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 promiscuity 0
20: macvlan1@if2:  mtu 1500 qdisc noqueue state UNKNOWN mode DEFAULT group default
    link/ether 36:90:37:f6:08:cc brd ff:ff:ff:ff:ff:ff promiscuity 0
 macvlan  mode vepa
user@net1:~$
```
在我们的例子中，VEPA 模式阻止了两个名称空间接口直接对话。更常见的是，MacVLAN 接口被定义为类型`bridge`，以允许同一父接口上的接口之间的通信。然而，即使在这种模式下，子接口也不允许直接与直接分配给父接口的 IP 地址通信(在这种情况下为`172.16.10.2`)。这应该是一个单独的段落。
```
user@net1:~$ sudo ip netns del namespace1
user@net1:~$ sudo ip netns del namespace2
```
现在我们可以重新创建两个接口，为每个 MacVLAN 接口指定`bridge`模式:
```
user@net1:~$ sudo ip netns add namespace1
user@net1:~$ sudo ip link add macvlan1 link eth0 type \
macvlan mode bridge
user@net1:~$ sudo ip link set macvlan1 netns namespace1
user@net1:~$ sudo ip netns exec namespace1 ip address \
add 172.16.10.5/24 dev macvlan1
user@net1:~$ sudo ip netns exec namespace1 ip link set \
dev macvlan1 up
user@net1:~$ sudo ip netns add namespace2
user@net1:~$ sudo ip link add macvlan2 link eth0 type \
macvlan mode bridge
user@net1:~$ sudo ip link set macvlan2 netns namespace2
user@net1:~$ sudo ip netns exec namespace2 sudo ip address \
add 172.16.10.6/24 dev macvlan2
user@net1:~$ sudo ip netns exec namespace2 ip link set \
dev macvlan2 up
```
指定`bridge`模式后，我们可以验证两个接口可以直接相互连接:
```
user@net1:~$ sudo ip netns exec namespace1 ping 172.16.10.6 -c 2
PING 172.16.10.6 (172.16.10.6) 56(84) bytes of data.
64 bytes from 172.16.10.6: icmp_seq=1 ttl=64 time=0.041 ms
64 bytes from 172.16.10.6: icmp_seq=2 ttl=64 time=0.030 ms
--- 172.16.10.6 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 999ms
rtt min/avg/max/mdev = 0.030/0.035/0.041/0.008 ms
user@net1:~$
```
但是，我们也注意到，我们仍然无法到达在父接口(`eth0`)上定义的主机 IP 地址:
```
user@net1:~$ sudo ip netns exec namespace1 ping 172.16.10.2 -c 2
PING 172.16.10.2 (172.16.10.2) 56(84) bytes of data.
--- 172.16.10.2 ping statistics ---
2 packets transmitted, 0 received, 100% packet loss, time 1008ms
user@net1:~$
```
# 使用 Docker MacVLAN 网络驱动程序
当我开始写这本书的时候，Docker 的当前版本是 1.10，那个时候 MacVLAN 功能已经包含在 Docker 的发布候选版本中。此后 1.12 版本发布，将 MacVLAN 推入软件的发布版本。也就是说，使用 MacVLAN 驱动程序的唯一要求是确保您安装了 1.12 或更新版本的 Docker。在本章中，我们将回顾如何为 Docker 提供的容器使用 MacVLAN 网络驱动程序。
## 做好准备
在这个食谱中，我们将使用两个运行 Docker 的 Linux 主机。我们的实验室拓扑将由位于同一网络上的两台 Docker 主机组成。它看起来像这样: