title:Time-Window Based Group-Behavior Supported Method for Accurate Detection
of Anomalous Users
author:Lun-Pin Yuan and
Euijin Choo and
Ting Yu and
Issa Khalil and
Sencun Zhu
8
3
0
0
0
.
1
2
0
2
.
7
8
9
8
4
N
S
D
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
1
2
0
2
©
0
0
.
1
3
$
/
1
2
/
7
-
2
7
5
3
-
4
5
6
6
-
1
-
8
7
9
|
)
N
S
D
(
s
k
r
o
w
t
e
N
d
n
a
s
m
e
t
s
y
S
e
l
b
a
d
n
e
p
e
D
n
o
e
c
n
e
r
e
f
n
o
C
l
a
n
o
i
t
a
n
r
e
t
n
I
P
I
F
I
/
E
E
E
I
l
a
u
n
n
A
t
s
1
5
1
2
0
2
2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)
Time-Window Based Group-Behavior Supported Method for Accurate Detection of
Anomalous Users
Lun-Pin Yuan
Euijin Choo
Ting Yu
Pennsylvania State University
Qatar Computing Research Institute
Qatar Computing Research Institute
PI:EMAIL
PI:EMAIL
PI:EMAIL
Issa Khalil
Qatar Computing Research Institute
PI:EMAIL
Sencun Zhu
Pennsylvania State University
PI:EMAIL
Abstract—Autoencoder-based anomaly detection methods
have been used in identifying anomalous users from large-
scale enterprise logs with the assumption that adversarial
activities do not follow past habitual patterns. Most existing
approaches typically build models by reconstructing single-
day and individual-user behaviors. However, without capturing
long-term signals and group-correlation signals, the models
cannot identify low-signal yet long-lasting threats, and will
wrongly report many normal users as anomalies on busy
days, which, in turn, lead to high false positive rate. In this
paper, we propose ACOBE, anAnomaly detection method
based on COmpound BEhavior, which takes into consideration
long-term patterns and group behaviors. ACOBE leverages
a novel behavior representation and an ensemble of deep
autoencoders and produces an ordered investigation list. Our
evaluation shows that ACOBE outperforms prior work by a
large margin in terms of precision and recall, and our case
study demonstrates that ACOBE is applicable in practice for
cyberattack detection.
Keywords-Computer Security, Anomaly Detection, Machine
Learning
I. INTRODUCTION
Emerging cyber threats such as data breaches, data exﬁl-
tration, botnets, and ransomware have caused serious con-
cerns in the security of enterprise infrastructures [1], [2]. The
root cause of a cyber threat could be a disgruntled insider or
a newly-developed malware. What is worse, emerging cyber
threats are more difﬁcult to be identiﬁed by signature-based
detection methods, because more and more evasive tech-
niques are available to adversaries. To identify the emerg-
ing cyber threats before they can cause greater damage,
anomaly detection upon user behaviors has attracted focuses
from large-scale enterprises [3]–[9], as anomaly detection
enables security analysts to ﬁnd suspicious activities that
could be aftermath of cyber threats (including cyberattacks
and insider threats). Adversarial activities often manifest
themselves in abnormal behavioral changes compared to
past habitual patterns. Our goal is to ﬁnd such abnormal
behavioral changes by learning past habitual patterns from
organizational audit logs.
Autoencoders are one of the most well-known anomaly
detection techniques [10]–[12]. They are attractive to secu-
rity analysts because of their robustness to domain knowl-
edge. Brieﬂy speaking, an autoencoder-based anomaly de-
tection model only learns how to reconstruct normal data;
hence, in events of poor reconstruction, the input data is
highly likely to be abnormal. Detailed domain knowledge is
no longer required, because the complex correlation among
different activities is captured by learning the normal dis-
tribution from normal activities. Furthermore, autoencoder
learns features from unlabeled data in an unsupervised
manner, where human interference is reduced.
to other
However, similar
typical anomaly detection
methodologies, the autoencoder-based approaches also suf-
fer from the overwhelming number of false positive cases.
The challenge is that, while an anomaly detection model is
required to be sensitive to abnormal events in order to raise
anomaly alerts, the model can also be so sensitive to normal
behavioral deviation that it often wrongly reports normal
deviations as anomalies (hence a false positives). This chal-
lenge leads to the question: how to further differentiate
abnormal events from normal events. While prior approaches
work with data that meets the data-quality requirements
(e.g., completeness, availability, consistency) for cybersecu-
rity applications [13], important factors such as misconduct
timeliness and institutional environment are not considered.
To reduce false positives, we argue that it is important to also
examine long-term signals and group-correlation signals,
as opposed to typical autoencoder approaches that examine
only single-day and individual-user signals.
The
limitation of only examining single-day
and
individual-user signals is twofold. First, without capturing
long-term signals, a model cannot identify low-signal yet
long-lasting threats. Certain cyber-threat scenarios do not
cause immediate behavioral deviation, but progressively
cause small yet long-lasting behavioral deviation; for ex-
ample, an insider threat is a scenario where a disgruntled
employee stealthily leaks sensitive data piece-by-piece over
978-1-6654-3572-7/21/$31.00 ©2021 IEEE
DOI 10.1109/DSN48987.2021.00038
250
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:27 UTC from IEEE Xplore.  Restrictions apply. 
time [14], [15]. What is worse, without long-term signals,
a model will
likely wrongly report many normal users
as anomalies on busy days (e.g., working Mondays after
holidays) due to the massive burst of events in a short term.
This further leads to the second limitation: without capturing
group-correlation signals, a model cannot reduce its false
positive rate in occasions (e.g., environmental change) where
many users have common burst of events. For example,
common trafﬁc bursts occur among many users when there is
a new service or a service outage. By examining behavioral
group-correlation, a model may ﬁgure out that the common
behavioral burst is indeed normal, assuming the more behav-
ioral correlation a user has with the group, the less likely
the user is abnormal.
To address these fundamental limitations, we propose a
different methodology, which involves a novel behavioral
representation. We refer to this representation as a compound
behavioral deviation matrix. Each matrix encloses individual
behaviors and group behaviors across multiple days. Having
compound behaviors, we then apply our anomaly detec-
tion method, which is implemented with an ensemble of
deep fully-connected autoencoders. We propose ACOBE, an
Anomaly detection method based on COmpound BEhavior.
ACOBE has three steps in its workﬂow (Figure 1):
it
ﬁrst derives compound behavioral deviation matrices from
organizational audit logs; then, for each user, it calculates
anomaly scores in different behavioral aspects using an
ensemble of autoencoders; lastly, having anomaly scores,
ACOBE produces an ordered list of the most anomalous
users that need further investigation. In summary, we make
the following contributions.
1) We propose a novel behavioral representation which
we refer to as the compound behavioral deviation
matrix. It proﬁles individual and group behavior over
a time window (e.g., several days). We further apply
deep fully-connected autoencoders upon such repre-
sentation in order to ﬁnd anomalous users. Our model
outputs an ordered list of anomalous users that need
to be orderly investigated.
2) We evaluate ACOBE upon a synthesized and labeled
dataset which illustrates insider threats. With four
abnormal users out of 929 users, ACOBE achieves
99.99% area under the ROC curve; that is, ACOBE
effectively puts abnormal users on top of the investiga-
tion list ahead of normal users. Furthermore, ACOBE