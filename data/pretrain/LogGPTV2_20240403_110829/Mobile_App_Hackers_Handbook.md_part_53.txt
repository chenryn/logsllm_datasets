is a much better way to check for the existence of an application on a device rather than checking for the
existence of its APK file in a certain directory. The APK may be renamed by developers of the application or
be installed in a different place to the commonly checked /system/app/ directory. The installed package
names of these applications could also be searched; for example, 'com.noshufou.android.su'and
'eu.chainfire.supersu'. This check is the least reliable because the user could have just installed a root
manager application from the Play Store without actually having root access. However, if the user managed
to install the root manager's APK somewhere inside the /system folder, then this indicates that he had
privileged access to the device at some point.
Debugger Detection
A reverse engineer who needs to manipulate code inside your application can do so by using a debugger attached
to the device. However, this technique can only be used if your application is marked as debuggable. A reverse
engineer may have modified the application's manifest to include android:debuggable=”true” or used a runtime
manipulation tool that makes the process debuggable in order to achieve this.
You can perform a check to make sure that the application is not set as debuggable by implementing the
following code:
boolean debuggable = (getApplicationInfo().flags &
ApplicationInfo.FLAG_DEBUGGABLE) != 0;
Another measure that you could implement is to periodically check whether an application has a debugger
attached to it by using the isDebuggerConnected() method provided in the android.os.Debug class.
These approaches do not provide an infallible way of preventing application debugging but will certainly slow
down a reverse engineer who has not taken the time to defeat these checks.
Tamper Detection
An application can be designed to fail to run if it detects signs of modification of its APK file. This technique is
commonly known as tamper detection. The following code snippet shows how an application can check whether
its APK has been changed and resigned. Specifically, it checks the signature of the signing certificate used
against a known good value.
public boolean applicationTampered(Context con)
{
PackageManager pm = con.getPackageManager();
try
{
PackageInfo myPackageInfo = pm.getPackageInfo(con.getPackageName(),
PackageManager.GET_SIGNATURES);
String mySig = myPackageInfo.signatures[0].toCharsString();
//Compare against known value
return !mySig.equals("3082...");
}
catch (NameNotFoundException e)
{
e.printStackTrace();
}
return false;
}
A reverse engineer could certainly patch these checks or defeat them in some other way; however, it is an
annoyance. Upon failing the tamper detection check, the app could also transmit information about the device
to the application developer so that he is aware that someone is attempting to modify the application, possibly
in an attempt to crack it and make it available on the Internet. Paid products that provide code obfuscation also
often provide tamper detection. If paying for tamper detection code is a better option, refer to the “Obfuscation”
section earlier in this chapter for some options.
Summary
When creating an Android application, you must consider many security aspects. However, the security
functionality provided by the Android platform is rich and strong security mechanisms can be created using
built-in features. The following is a list of security checks provided in this chapter that you can use as input to a
security assessment of your application. The items on this checklist are most of the time not fully attainable but
should be seen as an ideal to strive toward.
Check that all code paths into application components expose only the functionality that is intended.
Minimize the storage of user data down to the essentials.
Limit interaction with untrusted sources and scrutinize any outside interaction.
Verify that the minimum possible set of permissions have been requested by the application.
Ensure that no unintended files are bundled inside the APK.
Assign permissions to all exported application components.
Define a protection level of signature to all custom permissions.
Ensure that tapjacking attacks cannot be performed on any sensitive View within the application.
Ensure that sensitive inputs do not store any typed-in words into the Android dictionary.
Ensure that activities that extend PreferenceActivity correctly verify the requested fragment.
Ensure that login activities do not contain a way for a user to open authenticated activities prior to passing
authentication checks.
Ensure that all inputs for user passwords are appropriately masked.
Ensure that BROWSABLE activities do not expose any way for a malicious website to misuse functionality
within the activity.
Ensure that content providers that do not intend to be exported have this explicitly set in their manifest
declarations.
Ensure that content providers do not have SQL injection vulnerabilities.
Ensure that file-backed content providers do not provide access to unintended files.
Ensure that pattern-matching flaws do not exist on any paths protected by permissions.
Ensure that secret codes have been removed and if they have not that they only provide intended
functionality.
Set restrictive file permissions on files stored inside the private data directory.
Pay attention to the sensitivity of files stored on the SD card.
Ensure that sensitive files stored anywhere on the filesystem are encrypted.
Ensure that encryption keys are not hard-coded in the source or stored insecurely.
Ensure that encryption keys were generated using best practices.
Ensure that files that have to be shared with other applications do not expose these files in an insecure way
and make use of a content provider and the Grant URI permission functionality.
Ensure Grant URI functionality makes use of an explicit intent when allowing access to another application.
Encrypt all communications to the Internet using well-known standards.
Add an additional transport layer security mechanism such as SSL certificate pinning on all communications
to the Internet.
Ensure that no certificate checking bypass code has been used to allow invalid SSL certificates.
Use only standard IPC mechanisms provided by Android.
Ensure that WebViews are not loading any cleartext content.
Use targetSdKVersion and minSdkVersion of 17 or higher when making use of a WebView with a
JavaScriptInterface.
Lock each WebView down to its tightest possible configuration with features that affect security being disabled
wherever possible.
Ensure that backing up the application content using ADB backup functionality is not possible.
Ensure that the application is not marked as debuggable.
Use the highest possible API version in targetSdKVersion and minSdkVersion in the manifest as well as in
APP_PLATFORM for native code.
Ensure that the application does not log sensitive data.
Inspect the quality of the native code for memory corruption flaws.
Scrutinize all entry points into native code and reduce them where possible.
Ensure that all possible exploit mitigations are present on compiled native code.
Implement protection level downgrade detections.
Ensure that non-exported application components cannot be invoked by a privileged user because of the
implemented token system.
Rigorously obfuscate all code.
Implement root detection checks.
Implement debugger detection checks.
Implement tamper protection checks.
CHAPTER 10
Analyzing Windows Phone Applications
Windows Phone (WP) 8 and 8.1 are arguably two of the most secure mobile operating systems on the market at
the time of this writing. Indeed, in contrast to other mobile operating systems such as iOS and Android, WP8
and 8.1 and their Original Equipment Manufacturer (OEM) devices have not been publicly vulnerable to a long
string of jailbreaking and security vulnerabilities.
Windows Phone 8 and 8.1 are built on top of the NT kernel technology. The older Windows Phone OSes, 7.x
(and the even older Windows Mobile OSes) differ from Windows Phone 8.x in that their cores were made up of
the CE kernel instead.
The market has shifted recently. Whereas Windows Phones previously seemed quite far behind the rest of the
mobile arena, their market share increase now places them in third place, one place higher than BlackBerry
devices. This makes Windows Phone devices very viable options for Windows Phone development, and as a
consequence, application security research.
In this book we stick to the more recent Windows Phone operating systems, WP8 and WP8.1, though much of
the content we discuss in the following four chapters may be relevant when assessing legacy WP7 applications
as well.
Before delving into attacking and code auditing Windows Phone 8 and 8.1 applications in Chapter 11, this
chapter first explores Windows Phone 8 and 8.1’s various security features, and then covers how to build an
environment suitable for carrying out security reviews and exploration activities on Windows Phone 8 and 8.1
apps.
Understanding the Security Model
It’s important to understand the host’s OS security model before carrying out application security assessments
to gain an appreciation for how apps are able to interact with each other and with the OS at large. Windows
Phone is not just Windows on a phone. It is a much more closed operating system than standard Windows, and
apps are much more restricted.
This section introduces Windows Phone’s security model and other security-related aspects of the OS so that
you become aware of how exposed an app and its data is to attacks by other apps (consider malicious apps on a
device) and exploit attempts in general. Other security features are also introduced, including device encryption
and exploit mitigation technologies.
Code Signing and Digital Rights Management (DRM)
Windows Phone 8, by default, is a closed computing platform. On locked devices (that is, non-developer
unlocked) all code must first be signed by Microsoft in order to run, much the way Apple requires that code have
a signed a binary for it to run on non-jailbroken iOS devices.
The majority of applications consumed by Windows Phone 8 users are obtained via the Windows Phone Store.
All applications submitted to the Store are subject to a Microsoft-defined submission process (more on this
later), before being accepted and code signed with a certificate issued by the aptly named Certification Authority,
Microsoft Marketplace CA. Signed apps are then made available for purchase or free download to the general
public who own Windows Phone 8 devices.
In addition to being code signed, applications from the Store are protected using the FairPlay DRM technology.
Tampering with the XAP or APPX files being installed results in the installation being halted.
Note that not all applications have to be Microsoft signed to run on WP8 or 8.1 devices. When developer mode is
unlocked on a device, applications can be sideloaded, but in the context of Store applications running on the
device of a standard consumer, all apps must be signed. (More on sideloading and its applicability to penetration
testing appears later in this chapter.)
Application Sandboxing
In line with Windows Phone 8.x’s closed architecture, applications are sandboxed to control their access to
system resources and to prevent them from accessing other applications’ data. In Windows Phone 8.x realm, all
third-party applications from the Store run in AppContainers. This section briefly discusses what an
AppContainer is and what it means for standard applications in terms of privileges, security, and segregation of
applications.
AppContainer
The AppContainer at a high level can be considered a process-isolation mechanism that offers fine-grained
security permissions governing which operating system resources, such as files, the registry, and other
resources, that contained applications can access and interact with.
Because all third-party WP8 and WP8.1 applications run inside an AppContainer, each app can access only its
own private file sandbox; any attempts to read or write outside of it, including into another application’s data
sandbox, fail. Similarly, any attempts to write into the registry also fail, though some of the registry is readable
by standard third-party apps.
Chambers and Capabilities
The ability of an application to access functionality offered by the OS and its services, such as the camera or
networking, is controlled by that app’s capabilities. The Windows Phone 8 security model is based on the
concept of least privilege, and as such, every application on a device is running inside one of two distinct
security chambers.
In the Windows Phone 8 and 8.1 security architecture, the two chambers are the Least Privilege Chamber (LPC)
and the Trusted Computing Base (TCB). All applications run in the notional LPC chamber, whether they are
Microsoft-written services, OEM services, or just third-party Store applications. Even some device drivers run in
the LPC. The only code that runs in the TCB chamber are kernel components. Figure 10.1 represents this
chamber architecture graphically.
Figure 10.1 Windows Phone 8.x chamber architecture
Windows Phone 8 and 8.1 implement the principle of least privilege by quite severely restricting the freedom of
applications running in the LPC, by default. By least privileges enforcement, so few permissions are granted to
apps by default that tasks such as networking, camera use and access to user contacts (for example) are not
possible. For an application to be able to undertake serious tasks that are expected of modern smartphone apps,
privileges have to be granted to it. At install time, applications “ask” for additional privileges by requesting
capabilities.
When developers create WP8 applications, they must specify which capabilities their application requires in
order to carry out its tasks and provide its functionality. For example, here are several typical capabilities that
Store Windows Phone apps commonly request:
ID_CAP_NETWORKING—Outbound and inbound network access
ID_CAP_PHONEDIALER—Access to the dialer functionality
ID_CAP_MICROPHONE—Access to the microphone API
ID_CAP_LOCATION—Access to geolocation data
ID_CAP_ISV_CAMERA—Access to device’s built-in camera
In the context of a Windows Phone 8.1 app, you can specify capabilities in its Package.appxmanifest file and use
different names; for example, internetClient in APPX manifests provides similar capabilities as
ID_CAP_NETWORKING. Developers specify capabilities to be requested at install either via the Manifest Designer
interface or by manually editing the application manifest XML files—WMAppManifest.xml or
Package.appxmanifest. (You can find more information about these files, in the “Application Manifests” section
of this chapter).
At install time for an application, its manifest file is parsed for capabilities. Certain privileges, such as
ID_CAP_LOCATION, result in the user’s being prompted for permission to grant the capability to the app, since
geolocation data can be considered sensitive information. Other permissions such as ID_CAP_NETWORKING, on the
other hand, are granted automatically, thus any third-party may use the OS’ networking APIs without the device
user having to specifically authorize it via an install time prompt. Requests for powerful capabilities that are
only meant for Microsoft and OEM software, such as ID_CAP_INTEROPSERVICES, are denied by the OS, and third-
party apps requesting such capabilities will not install.
Once the capabilities have been parsed out from the manifest and granted or denied (either automatically or by
the user’s acceptance or denial), the application’s chamber is then provisioned with these granted capabilities.
The app is then accordingly restricted by the security boundary the chamber presents, and it cannot go beyond
that container by attempting to access APIs that it does not have the capabilities for. This summarizes the least
privileges principle; if an app does not have the correct capabilities to access a particular API, the OS will deny
access to it if the app attempts to use it.
Each time the application runs, its process executes in an AppContainer whose privileges reflect those of the
capabilities granted to it.
The access controls enforced by WP8.x’s security model have been implemented using NT kernel’s security
primitives: tokens and Security IDs (SIDs), where every AppContainer has its own capability SID, which is used
to check with Access Control Lists (ACLs) whether or not the process has permission to carry out the action
requested.
Data Encryption ‘At Rest’
When you are reviewing apps from a security standpoint it’s helpful to understand the current state of data
encryption for the data stored on a Windows Phone 8.x device or on an accompanying SD card.
Chiefly, it’s important to know how well protected application data is if a device is lost or stolen, and an attacker
extracts the flash storage module in an attempt to extract and use data on the device.
The current status quo for encryption on standalone (non-corporate) and even some corporate-enrolled devices
may surprise some readers.
We’ll discuss the general status of device and SD card encryption in the following two short sections.
Internal Storage Volume
At the time of this writing, data on devices running both Windows Phone 8 and Windows Phone 8.1 is not
encrypted by default. Moreover, at present, no public API is available to enable full device encryption on
unmanaged devices, such as those used by non-business consumers. This is true even when a device has a
password set on it; this does not mean that any whole storage encryption has been enabled.
The only documented method of encrypting the internal storage volume (i.e., the entire flash storage—the disk)
is via corporate enrollment and correct configuration of Exchange ActiveSync policies. In particular, the policy
setting of interest is RequireDeviceEncryption, as documented in Microsoft’s WP ActiveSync overview
(http://go.microsoft.com/fwlink/?LinkId=270085).
When encryption is enabled via ActiveSync policy, device encryption in Windows Phone 8 and 8.1 is carried out
by Microsoft’s BitLocker technology. According to Microsoft documentation, BitLocker uses Advanced
Encryption Standard (AES) encryption in Chained Block Cipher (CBC) mode, using either a 128- or 256-bit key,
in combination with the “Elephant” diffuser for security aspects that are particular to disk encryption. The full
technical specifications of BitLocker’s encryption are available athttp://www.microsoft.com/en-
us/download/confirmation.aspx?id=13866.
Given the lack of out-of-the-box storage volume encryption even when a password is applied to Windows Phone
8 and 8.1 devices, non-enterprise WP8.x phone users at the time of this writing are vulnerable to data theft in
the event that their device is lost or stolen, assuming the would-be attacker is able to extract filesystem data
from the flash drive.
Secure Digital Card Encryption
When BitLocker is enabled on Windows Phone 8 and 8.1, it does not encrypt Secure Digital (SD) card contents.
In terms of applications themselves writing encrypted or unencrypted data to the SD card, the conclusion to the
matter is quite simple. In Windows Phone 8, Store applications are not capable of writing to SD cards; they only
have read-access to the device. Only OEM and Microsoft applications have read- and write-access to SD cards.
This has changed, however, in Windows Phone 8.1. Apps in WP8.1 with the removableStorage capability are
afforded read- and write-access to the SD card.
SD cards—as data entry points into applications—are discussed in more detail in Chapter 11.
Windows Phone Store Submission Process
As stressed previously, Windows Phone 8 is a closed computing platform. It therefore makes sense that in
addition to enforcing a strict security model to sandbox apps, Microsoft also reviews all app submissions to the
Store to ensure that they comply with certain security-related dos and don’ts that Microsoft defines.
Most obviously the Store submission screening process involves a certain degree of analysis to ensure that
submitted apps are not malware. In this sense submitted applications are vetted for malicious code, and any
code that Microsoft considers to be malicious leads to the app’s rejection.
Still, even if a submitted application is not coded to carry out blatantly malicious actions, certain questionable
behaviors may be disallowed and lead to the app’s being rejected. For example, if an application attempted to
read a file outside of its sandbox for seemingly innocuous purposes, the app would most likely be refused, even
though the action would in the vast majority of cases fail anyway. Similarly, accessing registry keys that are
readable may also be considered questionable, and could lead to rejection of the app submission. Exact patterns
of behavior that are prohibited by Microsoft are not available to the general public, but even accidental or
innocuous naïve attempts to breach the sandbox model would most likely be considered inappropriate and
would be a reason for rejection.
Another pattern of behavior that could be implemented by a well-meaning developer but is prohibited includes
“altering” an application’s behavior after the application has been accepted and certified by the Store. This may