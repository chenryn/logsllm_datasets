# Adaptive Software Rejuvenation: Degradation Model and Rejuvenation Scheme

**Authors:**
- Yujuan Bao
- Xiaobai Sun
- Kishor S. Trivedi

**Affiliations:**
- Department of Computer Science, Duke University, Durham, NC 27708
- Department of Electrical and Computer Engineering, Duke University, Durham, NC 27708

**Contact:**
- {byj, xiaobai}@cs.duke.edu
- PI:EMAIL

## Abstract
This paper presents a framework for the adaptive estimation and rejuvenation of software system performance in the presence of aging sources. The framework specifies a degradation model that not only describes an aging process but also enables the adaptation of model-based performance estimates to online measurements. Adaptive estimation combines a priori model-based estimates with posteriori estimates derived from data measurements. The rejuvenation policy determines the timing for data collection and rejuvenation based on system dynamics. In the context of resource leaks, we introduce a non-homogeneous Markov model to establish a connection between resource leaks and failure rates, demonstrating an increasing failure rate in the presence of resource leaks.

## 1. Introduction: The Adaptation Problem
We present a framework for adaptive estimation and rejuvenation of software system performance in the presence of aging sources, particularly focusing on memory leakage. Memory is essential in computer and communication systems, and memory leakage is a common aging source due to software bugs in client applications. Our framework consists of three components: a degradation model, an adaptive estimation scheme, and an adaptive rejuvenation scheduling policy. The degradation model allows the adaptation of model-based performance estimates to online measurements. The adaptive estimation scheme uses a priori model-based estimates and obtains posteriori estimates based on measurements. The rejuvenation scheduling policy then determines the timing for data collection and rejuvenation.

The concept and framework of adaptive software rejuvenation (ASR) have evolved from earlier software rejuvenation efforts. Since Huang et al. introduced software rejuvenation in 1995, degradation analysis and rejuvenation techniques have advanced rapidly and are widely used in various applications, such as spacecraft systems, transaction processing systems, and telecommunications systems. Software rejuvenation is often framed as an optimization problem, aiming to minimize both the risk of preventable failures and the cost of rejuvenation. However, the optimization process has evolved with improvements in modeling, degradation estimation, and rejuvenation scheduling.

Huang et al. [9] presented a continuous-time Markov chain (CTMC) model for the degradation-rejuvenation process, which includes four states: healthy, degraded, failed-and-recovered, and rejuvenated. Garg et al. [6] used a Markov regenerative stochastic Petri net (MRSPN) to handle deterministic intervals between rejuvenations. Dohi et al. [4] introduced a semi-Markov process model for determining the optimal rejuvenation schedule. Bobbio et al. [2] refined the description of the degradation state using a discrete degradation index. Most of these models assume the availability of a failure profile, separating this relationship from the profiling process. For long-term, steady-running systems, a failure profile can be obtained through monitoring and learning.

In measurement-based approaches, dynamic changes in a system are captured by monitoring certain data related to performance degradation. For example, an SNMP-based resource monitoring tool can monitor resource usage at regular intervals, and statistical trend detection techniques can analyze the collected data to estimate the time to resource exhaustion. However, these approaches face challenges, such as making rejuvenation decisions difficult and being overly sensitive to local temporary changes. Our ASR framework integrates model construction, model-based estimates, and online inspection, adapting model-based estimates to measured data, particularly for memory leakage.

## 2. Degradation Model and Analysis
We develop a model for performance degradation due to the gradual loss of system resources, especially memory. In a client-server system, each client process issues memory requests at varying points in time. If the allocated memory is not fully released, a memory leak occurs, reducing the available memory over time. This can lead to resource requests being denied when the system suffers from memory leaks. Our model accommodates performance analysis for both leak-less and leak-present cases and can adapt performance estimates to online data measurements.

### Leak-Free Model
Consider the ideal, leak-less case modeled as a CTMC (Figure 1). Let \( M \) be the initial total amount of available memory. The system is in workload state \( k \) when there are \( k \) independent processes holding a portion of the resource. Memory requests arrive from a Poisson process with rate \( \lambda \). A request is granted if sufficient memory is available; otherwise, the system fails. The conditional probability that the system fails in state \( k \) upon the arrival of a new request is denoted by \( \xi[k] \). The amount of each memory request is modeled as a continuous random variable with density function \( g(x) \). The allocated resource is held for a random period of time, exponentially distributed with rate \( \mu \), and the release rate \( \mu_k \) at state \( k \) is \( k\mu \).

Given the specifications of the request arrival rate \( \lambda \), service rates \( \mu_k \), and the conditional probabilities \( \xi[k] \), the failure rate of the system can be obtained via the transient solution to the Kolmogorov equations for the CTMC:
\[
\frac{d\pi_{\text{sink}}(t)}{dt} = \sum_{k} \xi[k] \pi_k(t),
\]
\[
\frac{d\pi_0(t)}{dt} = -\lambda \pi_0(t) + \mu_1 \pi_1(t),
\]
\[
\frac{d\pi_k(t)}{dt} = \lambda (1 - \xi[k-1]) \pi_{k-1}(t) - (\lambda + \mu_k) \pi_k(t) + \mu_{k+1} \pi_{k+1}(t), \quad k > 0.
\]

### Leak-Present Model
For a leak-present system, we use a non-homogeneous CTMC (Figure 2). The conditional probabilities \( \xi[k, l(t)] \) now depend on the current state and the accumulated leak \( l(t) \). The failure rate increases as the leaked resource accumulates over time, confirming that memory leakage is indeed an aging source.

By integrating these models, our ASR framework provides a comprehensive approach to adaptive estimation and rejuvenation, ensuring that software systems maintain optimal performance in the presence of aging sources.