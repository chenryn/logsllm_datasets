2. Start VM
3. Execute malware to infect system (and wait 2 seconds)
4. Start Internet Explorer
5. Analyze IE for hooks until hooks are found or timeout occurs
The decision for suitable timeout is diﬃcult. It is closely related to the halting
problem. By only observing a program it can never be known whether a program
will inject itself into a browser or not. When monitoring a falsely classiﬁed sam-
ple, it may never modify a browser. A lot of specimen of malware are known to
wait a certain amount of time before they conduct their malicious actions. Zeus
is an example for these. We conducted preliminary tests and found that 96% of
the specimen became active in the ﬁrst 110 seconds whereas only 41% injected
the mitb-component within the ﬁrst 30 seconds. A timeout of 130 seconds was
used for the ﬁnal evaluation.
Sample Pool. A set of 881 Zeus samples from Zeus-tracker was used. In addi-
tion to that 164 SpyEye samples were obtained from the SpyEye-Tracker. Each
sample was run and broken samples discarded. Each malware without a detected
browser hook was manually veriﬁed for crashes.
272
A. Buescher, F. Leder, and T. Siebert
There are a lot of reasons for broken malware samples. Samples can get broken
during the infection because of incomplete downloads. Another reason for broken
samples is that some variants bind themselves to the ﬁrst system the sample
infects and crash on all other. This helps to evade the analysis in sandboxes at
a later stage. Other malware crashes after detecting a virtual environment.
Out of the 881 Zeus samples, 75 crashed. Out of the 164 SpyEye samples only
4 crashed.
Results for Zeus. After the removal of all samples that crashed, a set of 12
diﬀerent hooking ﬁngerprints was found for the remaining 806 samples. The
distribution of the ﬁngerprints including timeouts and the crashed samples are
shown in ﬁgure 1. More than 75% (607) of all have a unique ﬁngerprint. A
manual veriﬁcation showed that this includes specimen of Zeus versions 1 and
2, which illustrates that the browser hooking is not the major reason for the
version change. The second largest group of samples of 12.4% (100) are old Zeus
versions. All of the remaining groups, with between 1 and 20 samples each,
were investigated manually. We were able to identify a group of 20 samples as
a component of a Fake AV software called Kingsoft Antivirus that steals all
kinds of information from the user using mitb techniques. Unfortunately, this
breaks our assumption about a clean reference classiﬁcation. So do three groups
of two samples that each belong to the SpyEye family. The six remaining groups
contained custom variants of Zeus. It is known that customized versions of Zeus
exist with enhanced functionality. These six underline this.
Thus, a total of 8 Zeus hooking ﬁngerprints were discovered, with more than
96% of the Zeus samples having one of the two most common ﬁngerprints. This
shows that Zeus can be very reliably detected and that only minor variations
from the standard hook ﬁngerprints exist.
Since our Zeus sample set proved to contain specimen from other families a
veriﬁcation was performed on the remaining samples to ensure that the infections
are Zeus. This was conducted using a combination of known system modiﬁca-
tions that are unique for Zeus. No false positives were encountered for the Zeus
sampleset.
Results for SpyEye. Out of the 164 samples that we obtained as being SpyEye
specimen, only 4 crashed. A possible explanation for the low rate of crashes
compared to Zeus may be that SpyEye does not include machine binding. 23
samples timed out and did not perform any system modiﬁcations. Either our
timeout of 130 seconds is too short or the samples detected our tools and the
virtual machine. It is unclear whether these samples are really of this family or
are classiﬁed incorrectly by other tools. The remaining 137 samples split into
13 groups with diﬀerent ﬁngerprints. This is illustrated in ﬁgure 2. The largest
group consisted of more than 30% of the samples. The top three ﬁngerprints
were found in 80% of the samples. The remaining groups consisted of only one
to seven samples. Four ﬁngerprints were unique to one sample each.
The amount of ﬁngerprints illustrates the progress in development of the
SpyEye construction kit. Compared to Zeus, which is very established as a
Banksafe Information Stealer Detection Inside the Web Browser
273
ĞƵƐϭĂŶĚϮ
ĞƵƐϭ
&ĂŬĞs
ĞƵƐϭsĂƌŝĂŶƚ
ĞƵƐϮsĂƌŝĂŶƚ
ĞƵƐϭsĂƌŝĂŶƚ
ĞƵƐϭsĂƌŝĂŶƚ
^ƉǇĞǇĞ
^ƉǇĞǇĞ
^ƉǇĞǇĞ
ĞƵƐϭsĂƌŝĂŶƚ
ĞƵƐϮsĂƌŝĂŶƚ
ƚŝŵĞŽƵƚ
ĐƌĂƐŚ
Fig. 1. Fingerprints and classiﬁcation results for Zeus
^ƉǇǇĞ͘
^ƉǇǇĞ͘
^ƉǇǇĞ͘
^ƉǇǇĞ͘ ^ƉǇǇĞ͘
^ƉǇǇĞ͘&
^ƉǇǇĞ͘' ^ƉǇǇĞ͘, ^ƉǇǇĞ͘/
^ƉǇǇĞ͘:
^ƉǇǇĞ͘
^ƉǇǇĞ͘D ƚŝŵĞŽƵƚ
ĐƌĂƐŚ
Fig. 2. Fingerprints and classiﬁcation results for SpyEye
construction kit, SpyEye is rather new in the market and under heavy devel-
opment. We observed that the basic root-kit component is constant for all of the
ﬁngerprints, just the amount and type of information that is collected changes.
The amount of samples that produce the four most common ﬁngerprints (85%)
274
A. Buescher, F. Leder, and T. Siebert
shows that stable versions exist that are distributed more widely. The six speci-
men of SpyEye that were accidently contained in the Zeus sample set contained
ﬁngerprints from those top four.
All in all, the classiﬁcation of the SpyEye sampleset is not as reliable as the
one for Zeus. We expect that a ﬁx-point for the hooked functions will exist for
new specimen in the near future, when the development of the root-kit reaches
a stable state. This will increase the reliability of our approach. Already, the
classiﬁcation works perfectly when taking hooks in DLLs other than wininet.dll
into consideration.
5.2 AV Signature Detection
To estimate the detection rates of antivirus software against information stealers
we queried the database of the VirusTotal service [3] using the VT API to check
our Zeus and Spyeye samplesets. VirusTotal scans uploaded samples using more
than 40 antivirus engines. All of these scans are based on signature detection.
Since Zeus- and Spyeye-Tracker sends all samples to Virustotal, we could get
information on AV detection by simply requesting the samples MD5 hashes. By
default the VT API responds with the latest scan results when queried with
the MD5 of a sample but it is possible to also request the results of the ﬁrst
scan. The overall detection rate of Zeus samples was 86.8% for the latest scans
while the rate of the initial scans was signiﬁcantly lower with 27.1%. For the
SpyEye sampleset detection rates were 81.7% and 26.5% respectively. Figure 3
depicts the corresponding detection rates of Zeus and Spyeye samplesets using 12
renown antivirus engines. These numbers clearly point out the main problem of
signature based detection with automated builder tools for malware executables.
While antivirus vendors oﬀer an acceptable detection rate after having some
time to issue new signatures, the detection of fresh malware samples is poor. If
a botmaster updates the bot executable regularly he has a good chance to evade
signature detection.
Fig. 3. AV detection rates of Zeus and Spyeye samplesets
Banksafe Information Stealer Detection Inside the Web Browser
275
The VirusTotal results for the samplesets also included the virusnames as-
signed to the detected signatures. We used this data to evaluate how well AV
vendors could classify the respective trojans. 30.6 percent of the Zeus samples
were detected as Zeus or Zbot by the AV engines of the same 12 vendors as
before. Microsoft was the best AV engine with 87.1% Zeus samples classiﬁed
correctly. The classiﬁcation of Spyeye was even worse with 17.8% with also Mi-
crosoft topping the list with 36.4%.
5.3 Comparison to Behavior Blockers
In order to compare our proposed detection method to common proactive de-
tection solutions we installed eight popular AV security suites on VirtualBox
machine instances of Microsoft Windows XP SP2:
– Panda Internet Security 2011
– Avast Internet Security 5
– Norton Internet Security 2011
– G Data Internet Security 2011
– F-Secure Internet Security 2011
– McAfee Internet Security
– Kaspersky Internet Security 2011
– TrendMicro Internet Security 2011
Over the course of two weeks all new in-the-wild samples provided by Zeus-
and Spyeye-Tracker [6][5] that had a zero signature detection rate by the afore-
mentioned products were used to evaluate the abilities of the AV suites built-in
proactive detections. The zero signature detection was a requirement in order to
ensure that new samples are really unknown. All in all, 22 Zeus samples and 16
Spyeye samples were tested.
All trojan samples were manually executed ﬁrst with the security solution
already installed and then in the opposite order to test retrospective detection.
In the retrospective evaluation none of the eight solutions was able to detect
any of the Zeus or Spyeye samples that had already infested the system. With
the security suite already installed only one product was able to detect the Zeus
installation process while two products prevented Spyeye infections proactively.
Another security suite detected the Zeus infections and showed a warning to the
user but did not eﬀectively prevent them.
All of the samples were successfully detected by Banksafe. All of the ﬁnger-
prints could also be found in the bigger sample set of the ﬁrst experiment. Thus
a perfect classiﬁcation was achieved in this smaller experiment.
5.4 Other Information Stealers
Although Zeus and Spyeye were by far the most prevalent information steal-
ers measured by the 1,045 samples, we also tested Banksafes detection abilities
against other popular information stealing crimeware with smaller samplesets of
276
A. Buescher, F. Leder, and T. Siebert
trojans Patcher, Carberp, Silentbanker, Bebloh, Gozi and Katusha. The samples
were identiﬁed by searching for their names in the comments of the VirusTotal
[3] database and matching the resulting samples with AV signature names. The
samplesets were manually veriﬁed using known features of the respective trojan
like install directory or registry keys modiﬁed.
With the exception of Katusha, which uses a malicious browser plugin, all
trojans hook API functions inside the web browser to enable form-grabbing
abilities and were reliably detected by Banksafe. Table 1 shows an overview of the
evaluation results of all samplesets tested against Banksafe. Our implementation
was not able to detect the browser helper object of Katusha since the trojan uses
standard interfaces oﬀered by Microsofts Internet Explorer. This technique is on
one hand very easy to detect but lies outside the scope of our proposed detection
method.
Table 1. Detection results and ﬁngerprint count for diﬀerent information stealers
# samples crashed detected ﬁngerprints detection rate
family
855
Zeus
170
Spyeye
45
Patcher
7
Carberp
Silentbanker 5
4
Bebloh
3
Gozi
Katusha
4
1093
total
100%
100%
100%
100%
100%
100%
100%
0%
99.6%
125
27
4
1
3
1