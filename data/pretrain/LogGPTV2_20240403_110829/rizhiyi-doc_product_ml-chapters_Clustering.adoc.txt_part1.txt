==== BIRCH
关于BIRCH (balanced iterative reducing and clustering using hierarchies)的wiki：
算法特点：
1. BIRCH试图利用可用的资源来生成最好的聚类结果，给定有限的主存，一个重要的考虑是最小化I/O时间。
2. BIRCH采用了一种多阶段聚类技术：数据集的单边扫描产生了一个基本的聚类，一或多遍的额外扫描可以进一步改进聚类质量。
3. BIRCH是一种增量的聚类方法，因为它对每一个数据点的聚类的决策都是基于当前已经处理过的数据点，而不是基于全局的数据点。
4. 如果簇不是球形的，BIRCH不能很好的工作，因为它用了半径或直径的概念来控制聚类的边界。
5. 能够比较好的处理动态增加和变化中的数据集的聚类问题，大多数情况下只需要对数据集进行一边扫描，时间和资源消耗控制比较理想
BIRCH算法中引入了两个概念：聚类特征（CF）和聚类特征树（CF Tree）
聚类特征：
CF是BIRCH增量聚类算法的核心，CF树中得节点都是由CF组成，一个CF是一个三元组，这个三元组就代表了簇的所有信息。给定N个d维的数据点{x1,x2,....,xn}，CF定义如下：
 CF=（N，LS，SS）
其中，N是子类中节点的数目，LS是N个节点的线性和，SS是N个节点的平方和。
CF有个特性，即可以求和，具体说明如下：
 CF1=（n1,LS1,SS1）
 CF2=（n2,LS2,SS2）
则
 CF1+CF2=（n1+n2, LS1+LS2, SS1+SS2）。
例如：
假设簇C1中有三个数据点：（2,3），（4,5），（5,6），则CF1={3，（2+4+5,3+5+6），（2^2+4^2+5^2,3^2+5^2+6^2）}={3，（11,14），（45,70）}，同样的，簇C2的CF2={4，（40,42），（100,101）}，那么，由簇C1和簇C2合并而来的簇C3的聚类特征CF3计算如下：
 CF3={3+4,（11+40,14+42），（45+100,70+101）}={7，（51,56），（145,171）}
另外两个概念：簇的质心和簇的半径。假如一个簇中包含n个数据点：{X~i~}，i=1,2,3...n.，则质心C和半径R计算公式如下：
 C=(X1+X2+...+X~n~)/n，（这里X1+X2+...+X~n~是向量加）
 R=(|X1-C|^2+|X2-C|^2+...+|X~n~-C|^2)/n
其中，簇半径表示簇中所有点到簇质心的平均距离。CF中存储的是簇中所有数据点的特性的统计和，所以当我们把一个数据点加入某个簇的时候，那么这个数据点的详细特征，例如属性值，就丢失了，由于这个特征，BIRCH聚类可以在很大程度上对数据集进行压缩。
聚类特征树：
CF tree的结构类似于一棵B-树，它有两个参数：内部节点平衡因子B，叶节点平衡因子L，簇半径阈值T。树中每个节点最多包含B个孩子节点，记为（CFi，CHILDi），1 [into model_name]
Parameters:
*  ：使用这些特征字段对目标字段进行聚簇和预测的训练，字段个数须>=1
* [into model_name]：保存下来的模型名称，可选，若不填将不做保存
* [algo_params]：针对BIRCH模型的参数设置，可选，不填时用默认参数设置
** threshold : float, default 0.5
+
The radius of the subcluster obtained by merging a new sample and the closest subcluster should be lesser than the threshold. Otherwise a new subcluster is started.
** branching_factor : int, default 50
+
Maximum number of CF subclusters in each node. If a new samples enters such that the number of subclusters exceed the branching_factor then the node has to be split. The corresponding parent also has to be split and if the number of subclusters in the parent is greater than the branching factor, then it has to be split recursively.
** n_clusters : int, instance of sklearn.cluster model, default 3
+
Number of clusters after the final clustering step, which treats the subclusters from the leaves as new samples. If None, this final clustering step is not performed and the subclusters are returned as they are. If a model is provided, the model is fit treating the subclusters as new samples and the initial data is mapped to the label of the closest subcluster. If an int is provided, the model fit is AgglomerativeClustering with n_clusters set to the int.
** compute_labels : bool, default True
+
Whether or not to compute labels for each fit.
** copy : bool, default True
+
Whether or not to make a copy of the given data. If set to False, the initial data will be overwritten.
以热那亚大学某年工程学专业115名大一新生的在线测试成绩为例，样本数据字段如下:
1. Student ID 学生id
2. ES1.1 在线测试session1 question1 得分
3. ES1.2 在线测试session1 question2 得分
4. ES2.1 在线测试session2 question1 得分
5. ES2.2 在线测试session2 question2 得分
6. ES3.1 在线测试session3 question1 得分
7. ES3.2 在线测试session3 question2 得分
8. ES3.3 在线测试session3 question3 得分
9. ES3.4 在线测试session3 question4 得分
10. ES3.5 在线测试session3 question5 得分
11. ES4.1 在线测试session4 question1 得分
12. ES4.2 在线测试session4 question2 得分
13. ES5.1 在线测试session5 question1 得分
14. ES5.2 在线测试session5 question2 得分
15. ES5.3 在线测试session5 question3 得分
16. ES6.1 在线测试session6 question1 得分
17. ES6.2 在线测试session6 question2 得分
18. TOTAL 在线测试总得分
由于聚簇分析中没有目标feature，所以这里我们用前70条数据的所有的feature进行训练和预测
  appname:ml_spl AND tag:cluster_ly | limit 70 | fit Birch threshold=0.8,branching_factor=60,n_clusters=5,compute_labels=true,copy=false from json.ES1.1,json.ES1.2,json.ES2.1,json.ES2.2,json.ES3.1,json.ES3.2,json.ES3.3,json.ES3.4,json.ES3.5,json.ES4.1,json.ES4.2,json.ES5.1,json.ES5.2,json.ES5.3,json.ES6.1,json.ES6.2,json.TOTAL, json.Student_ID into _test | table json.Student_ID, cluster
image::images/ml-birch-fit.png[]
用剩余数据的所有feature进行apply
  appname:ml_spl AND tag:cluster_ly | sort by +timestamp | limit 45 | apply _test | table json.Student_ID, cluster
image::images/ml-birch-apply.png[]