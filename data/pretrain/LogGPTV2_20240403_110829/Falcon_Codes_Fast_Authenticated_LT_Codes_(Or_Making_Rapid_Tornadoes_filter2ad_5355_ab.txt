Proof: Let us ﬁrst analyze n1,
the value of n that
initiates the ﬁrst f b1. Since before the ﬁrst f b1 no distribution
k−1 ln k.
shifting occurs we have Ω(cid:2)
k,0(1) = k
k,n0 (1) =Ω (cid:2)
(cid:9)
(cid:11)
ni =
(cid:10)
k − n1 = − W−1(−A1(k))
(cid:10)
A1(k)
(cid:9)
W−1(−A1(k))
,
.
n1 =
A1(k)
k +
√
(cid:9)
(8)
(9)
Further, we can easily see that n2 can be obtained from
k,n2 (1) − Ω(cid:2)
k,n1 (1) =
Ω(cid:2)
ln k that in the same way gives
W−1(−A2(k))
n2 =
k +
k,ni(1)−Ω(cid:2)
A2(k)
k,ni−1 (1) =
Finally, we have Ω(cid:2)
the lemma.
(cid:10)
.
√
ln k that proves
(10)
Lemma 2 gives the value of n for which f b1’s are generated.
, i ∈ {1, 2, . . . , 5} versus k.
In Figure 1, we have depicted ni
From Figure 1, we can see that ni
k decreases as k increases.
As an example, we can see that at k = 102 the ﬁrst and the
second f b1’s are issued at n ≥ 39 and n ≥ 58, respectively.
Further, for k = 104 the ﬁrst and the second f b1’s are issued
at n ≥ 2740 and n ≥ 4346, respectively.
k
i
n
k
0.8
0.7
0.6
0.5
0.4
0.3
102
n1
k
n2
k
n3
k
n4
k
n5
k
104
103
k
Fig. 1. Values of ni
k
, i ∈ {1, 2, . . . , 5} versus k.
B. Generating f b2
Since in LT-AF coding no degree-one output symbol is
generated, no decoding is performed and we have n = 0
until some degree-one output symbols are requested employing
f b2’s. The idea to generate f b2 is to smartly and greedily
choose and request an input symbol that makes the largest
2648
2013 IEEE International Symposium on Information Theory
progress toward decoding completion. It is well-known that
LT codes have all-or-nothing decoding property (also called
waterfall phenomenon) [1], where an abrupt jump in the ratio
of decoded input symbols occurs at a γ close to γsucc > 1.
Therefore, transmission of f b2’s before γ = 1 does not
considerably contribute to decoding progress. Therefore, we
propose to generate f b2’s only when γ surpasses 1. To have
uniformly distributed f b2’s and to avoid feedback channel
congestion, an LT-AF decoder issues a f b2 on the reception
of every (ln k)th output symbol.
Let us ﬁrst describe the structure of input and output
symbols in the buffer of a decoder. Input and received output
symbols of an LT code at a decoder can be viewed as vertices
of a bipartite graph G. The input symbols are the variable
nodes vi, i ∈ {1, . . . k} and the output symbols are the check
nodes cj, j ∈ {1, 2, . . . , γ k} [3, 14], and they are connected
to their neighbors denoted by N (vi) and N (cj ), respectively,
with undirected edges.
During data transmission some variable nodes vi, i ∈
{1, . . . k} are decoded and some check nodes cj, j ∈
{1, 2, . . . , γ k} are reduced to degree zero and are both re-
moved from the decoding graph G. Let us refer to the set of
remaining undecoded variable nodes by Vun and the set of
buffered check nodes with a degree higher than one by Cbuf f .
We remind that the check nodes with degree 1 are called the
ripple. Figure 2 illustrates such a graph G at a decoder at
γ = 1 for k = 7. Note that we interchangeably employ the
terms variable and check nodes for input and output symbols,
respectively, in the rest of the paper.
v1
v2
v3
v4
v5
v6
v7
c1
c2
c3
c4
c5
c6
c7
Fig. 2. The bipartite graph representing the input and the output symbols of
an LT-AF code at the buffer of a decoder.
It is important to note that the design of f b2 is to greedily
decode as many input symbols as possible so the decoding
succeeds at a smaller γsucc. However, as discussed earlier as
n increases closer to the end of decoding the average degree
of check nodes should be increased to decrease the probability
that they become redundant due to earlier recovery of all their
neighboring variable nodes. This is the rationale to employ
the distribution shifting and f b1 along with f b2. In the next
sections, we devise three algorithms to analyze the graph G at
decoder and greedily select suitable variable nodes to generate
f b2’s.
1) Generating f b2 Based on Variable Node with Maximum
Degree (VMD): One insight into choosing a suitable variable
node is requesting the variable node vi ∈ Vun with the max-
imum degree. Such a selection greedily removes the highest
number of edges in the ﬁrst step of decoding after the delivery
of the respective input symbol. Based on this idea we propose
an algorithm called “Variable Node with Maximum Degree”
(VMD), where the decoder requests the variable node with the
highest degree in its current decoding graph to issue a f b2. For
instance, in Figure 2 VMD would request v5. On the arrival
of c8 containing only v5, the value of v5 will become known.
This removes all the edges emanating from v5 to all other
check nodes and reduces some to degree 1 (they are added
to the ripple). For instance, c7 is added to the ripple, which
recovers v7 in the next decoding iteration. Note that at this
step the ripple becomes empty and decoding stalls; hence we
have Cbuf f = {c1, c2, . . . , c6} and Vun = {v1, v2, v3, v4, v6}.
We can see that VMD greedily removes the largest possible
number of edges from G and decreases the degree of many
check nodes.
2) Generating f b2 Based on Full Variable Node Decoding
(FVD): A more complex method to generate f b2 is to run
a dummy decoding for all unrecovered input symbols. Next,
the single input symbol whose delivery results in the highest
number of decoded input symbols is requested by a f b2. We
refer to this method by “Full Variable Node Decoding” (FVD),
which has a much higher complexity than VMD.
V. PERFORMANCE EVALUATION
In this section, we evaluate the performance of LT-AF codes
employing numerical simulations. Our results are obtained
employing Monte-Carlo method by averaging over the results
of at least 107 numerical simulations.
A. LT-AF Decoding Error Rate and Runtime
100
10−2
R
E
B
10−4
10−6
10−8
1
1
0.8
0.6
0.4
0.2
s
g
n
i
d
o
c
e
d
l
u
f
s
s
e
c
c
u
s
f
o
o
i
t
a
R
0
1
LT-AF, VMD
LT-AF, FVD
SLT
LT codes
1.05
1.1
1.15
γ
1.2
1.25
1.3
1.35
Fig. 3. Decoding error rate comparison for k = 1000.
LT-AF, VMD
LT-AF, FVD
SLT
1.05
1.1
1.15
γ
1.2
1.25
Fig. 4. Decoding success rate comparison for k = 1000.
We plot the decoding bit-error-rate (BER) (average ratio of
unrecovered input symbols to total number of input symbols
1−E[ n
k ]) and the ratio of successful decodings versus received
overhead γ in Figures 3 and 4, respectively, for k = 1000.
Note that we set c = 0.9 and δ = 0.1 for SLT and LT codes
as proposed in [6].
2649
2013 IEEE International Symposium on Information Theory
Figures 3 and 4 show that LT-AF codes signiﬁcantly surpass
SLT codes. Figure 3 shows that SLT codes require γsucc =
1.31 for decoding completion (BER≤ 10−8), which has been
reduced to γsucc = 1.14 and γsucc = 1.09 using FVD and
VMD. However, we should note that in LT-AF coding the
average degree of output symbols is much higher than that of
regular LT codes, which causes a higher encoding/decoding
complexity.
B. Number of Feedbacks
In this section, we compare the total number of feedbacks
issued by LT-AF codes and compare it to that of SLT codes.
We emphasize that other proposed LT codes with feedback
cannot achieve the performance of SLT and LT-AF codes. The
expected number of feedbacks for LT-AF and SLT codes are
summarized in Table I. From Table I, we can interestingly
observe that not only LT-AF codes decrease the required
coding overhead for a successful decoding γsucc, but also
they need slightly smaller number of feedbacks compared to
SLT codes. Further, we should note that the total number of
feedbacks is much smaller than γsucck.
THE AVERAGE NUMBER OF FEEDBACKS ISSUED IN LT-AF AND SLT
CODES FOR FULL DECODING OF DATA BLOCK.
TABLE I
Algorithm
LT-AF,VMD
LT-AF,FVD
SLT
N = 1000
f b1
2.68
3.58
-
f b2
9.29
6.92
-
total
11.97
10.5
12.27
C. Robustness to Erasure in Feedback Channel
We evaluate the effect of feedback loss on the performance
of LT-AF and SLT codes. Assume that the loss rate of the
is εf b = 0.9 (which is not known to
feedback channel
encoder and decoder), hence 90% of the feedbacks are lost
in transmission. Note, that in a lossy forward channel the
degree-one acknowledgements may also be dropped while f b1
or f b2 may have already been delivered. In the case of f b2
loss, the retransmission compensates this loss. However, in
case of f b1 loss, the encoder shifts the degree distribution
accordingly while the decoder remains unaware of this shift.
In this case, feedback retransmission is not even required since
the degree distribution shift has already occurred. Therefore,
we consider the worst case in our simulations and assume that
if an acknowledgement is lost the distribution shifting does not
occur as well. Figure 5 shows the performance of LT-AF and
SLT codes for k = 1000 and εf b = 0.9.
Figure 5 shows the excellent resilience of LT-AF codes to
feedback loss in contrast to SLT codes. In practice, the perfor-
mance of SLT codes approach that of regular LT codes as the
feedback loss ratio increases. To the best of our knowledge
robustness against feedback loss had not been considered in
any existing work and this signiﬁcantly distinguishes LT-AF
codes.
VI. CONCLUSION
In this paper, we proposed LT-AF codes that are LT codes
with two types of feedback, which alleviate the low perfor-
mance of LT codes for short data-block lengths. In LT-AF
codes, the decoder may inform the encoder with the total
100
10−2
R
E
B
10−4
10−6
10−8
1
LT-AF, εf b = 0.9
LT-AF, εf b = 0
SLT, εf b = 0.9
SLT, εf b = 0
1.05
1.1
1.15
1.2
1.25
γ
1.3
1.35
1.4
1.45
Effect of 90% feedback loss on the performance of SLT and LT-
Fig. 5.
AF codes employing VMD. Note that the curves representing LT-AF codes’
performance for εf b = 0.9 and εf b = 0.9 fully overlap for all γ.
number of decoded input symbols by the ﬁrst type of feedback
or request a certain input symbol from the encoder employing
second type of feedback. We showed that LT-AF codes require
lower coding overhead for successful decoding and lower
number of feedback compared to existing work. Finally and
most importantly, LT-AF codes’ performance does not consid-
erably degrade at large loss rates in the feedback channel. On
the other hand, LT-AF codes generate output symbols with a
higher average degree resulting in coding/decong with higher
complexity.
VII. ACKNOWLEDGEMENT
This material is based upon work supported by the National
Science Foundation under Grants ECCS-1056065 and CCF-
0915994.
REFERENCES
[1] M. Luby, “LT codes,” The 43rd Annual IEEE Symposium on Foundations
of Computer Science, 2002. Proceedings., pp. 271–280, 2002.
[2] A. Shokrollahi, “Raptor codes,” IEEE Transactions on Information
Theory, vol. 52, pp. 2551–2567, June 2006.
[3] P. Maymounkov, “Online codes,” NYU Technical Report TR2003-883,
2002.
[4] E. Bodine and M. Cheng, “Characterization of Luby transform codes
with small message size for low-latency decoding,” IEEE International
Conference on Communications, ICC, pp. 1195 –1199, may 2008.
[5] E. Hyytia, T. Tirronen, and J. Virtamo, “Optimal degree distribution for
LT codes with small message length,” INFOCOM, pp. 2576 –2580, may
2007.
[6] A. Hagedorn, S. Agarwal, D. Starobinski, and A. Trachtenberg, “Rate-
less coding with feedback,” INFOCOM 2009, pp. 1791 –1799, 2009.
[7] A. Kamra, V. Misra, J. Feldman, and D. Rubenstein, “Growth codes:
Maximizing sensor network data persistence,” SIGCOMM Comput.
Commun. Rev., vol. 36, no. 4, pp. 255–266, 2006.
[8] A. Beimel, S. Dolev, and N. Singer, “RT oblivious erasure correcting,”
IEEE/ACM Transactions on Networking, vol. 15, pp. 1321 –1332, dec.
2007.
[9] S. Kokalj-Filipovic, P. Spasojevic, E. Soljanin, and R. Yates, “ARQ with
doped fountain decoding,” ISSSTA, pp. 780 –784, aug. 2008.
[10] J. Sørensen, P. Popovski, and J. Østergaard, “On the Role of Feedback
in LT Codes,” Arxiv preprint arXiv:1012.2673, 2010.
[11] J. H. Sorensen, T. Koike-Akino, and P. Orlik, “Rateless feedback codes,”
in ISIT, pp. 1767–1771, IEEE, 2012.
[12] S. Ahmad, R. Hamzaoui, and M. Al-Akaidi, “Adaptive unicast video
streaming with rateless codes and feedback,” IEEE Transactions on
Circuits and Systems for Video Technology, vol. 20, no. 2, pp. 275–285.
[13] R. Corless, G. Gonnet, D. Hare, D. Jeffrey, and D. Knuth, “On the
lambert W function,” Advances in Computational mathematics, vol. 5,
no. 1, pp. 329–359, 1996.
[14] M. G. Luby, M. Mitzenmacher, M. A. Shokrollahi, D. A. Spielman, and
V. Stemann, “Practical loss-resilient codes,” Proceedings of the 29th
annual ACM symposium on Theory of computing, pp. 150–159, 1997.
2650