100+
100+
1,000+
100+
100+
Category
Operating System
Secure Messenger
Virtualization/Containers
JavaScript Libraries
Code Editor
JavaScript Libraries
.NET Libraries
Operating System
Version Control System
GUI Tool
Orchestration
Network Security Monitor
Scientific Computing
Cryptocurrency Exchange
Operating System
Code Analysis
JavaScript Libraries
Scientific Computing
Scientific Computing
Network Protocol
Virtualization/Containers
Data Format
Virtualization/Containers
Orchestration
Operating System
Scientific Computing
Scientific Computing
1 If multiple projects: largest project covered in the interview.
2 Total number of codes assigned to the interview after resolving conflicts.
GitHub. See also Table I for an overview of interviewed
participants and corresponding recruitment channel.
Aside from our professional network and well-known open
source projects, we utilized GitHub as a platform for selecting
and contacting open source projects. We focused on GitHub,
as it is widely used in the open source community and provides
relevant metrics for gauging the activity as well as popularity
of a project. We created our initial dataset based on data
from July 2021, consisting of code repositories that received
at least 40 commits from at least 20 distinct committers in
the previous six months and gained new committers in July
2021. Our intent was to exclude inactive projects or small
projects without contributors, for which our inquiry would
either not reach active contributors or in which trust processes
are irrelevant. The detailed selection process and criteria are
described in the replication package (cf. Section I-A) and
Appendix (cf. Appendix A). We then joined popularity and
activity indicators to a combined ranking and divided the set of
projects into quartiles, from which we then iteratively selected
and contacted projects until we reached interview saturation:
1) Communication Channel. If the project provided a public
communication channel such as a Slack workspace, Dis-
cord server, or Gitter chat, we asked the administrators
for permission to post a call for participants.
2) Contact Email. Otherwise, we either contacted the
project’s contact email or the project’s top contributor
by number of commits in the past year via their public
email address.
In addition to these channels, we asked our participants for
their recommendations of interesting or unique open source
projects, which we then contacted via the approaches described
above.
Due to the previous filtering, we did not require any addi-
tional eligibility criteria from our participants beyond stating
that we were looking for people involved in OSS. In total,
we recruited 27 participants from equally as many distinct
projects.
Interview Procedure: We conducted the 27 interviews in
a lead/backup interviewer configuration between July and
November 2021. To afford our participants a high level of
comfort during the interview, we offered them the choice to
conduct the interview either in English or German, as all
interviewing researchers were proficient in both languages. We
conducted the majority of interviews via our self-hosted Jitsi
instance, though a few interviews were conducted via Zoom or
the participant’s service of choice. Interviews were advertised
as lasting between 30–45 minutes in total, with the interview
part lasting a median of 00:37:52 minutes.
The different interview sections were introduced with an
open, non-leading question, allowing participants to elicit their
own thoughts and reactions on their terms. Only if specific
points were not addressed, we followed up with a more spe-
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:27 UTC from IEEE Xplore.  Restrictions apply. 
1883
Intro
Introduction to the interview and obtaining verbal consent.
1. Project Demographics
Establish project context and role of participant.
2. Security Challenges
Explore security challenges the project faced in the past.
3. Guidance and Policies
Identify guidance and best practices available to contributors,
content and applicability of security and disclosure policies.
Establish practices around (security) testing and reviews.
4. Project Structure
Establish repository setup, build process and control, and
supply chain handling.
5. Releases and Updates
Establish release and update processes and responsibilities,
explore handling of security-relevant updates.
6. Roles and Responsibilities
Identify the maintainer and contributor hierarchy of the
project.
7. Trust Processes
Establish trust models and explore past trust incidents and
trust strategies of the project.
8. Opinions and Improvements
Explore participants’ views of problems and potential
improvements.
Outro
Debrief and collect feedback for the interview.
Fig. 1: Illustration of the flow of topics in the semi-structured
interviews. In each section, participants were presented with
general questions and corresponding follow-ups, but were
generally free to diverge from this flow at will.
cific, non-leading sub-question. Interviewers were specifically
instructed not to impart a sense that the project’s security or
insecurity was being judged and to not prime participants’
answers in other ways.
B. Interview Structure
We outline our semi-structured interview structure below
and in Figure 1. For reporting, we group the interview into
eight sections, each consisting of 1–4 opening questions, cor-
responding follow-up questions, and in some cases additional
nudges.
Before the actual
interview part, we gave a short
in-
troduction of involved institutions and our motivations. We
specifically highlighted to participants that our goal is not to
judge the security of their projects, that it is okay not to be
aware of all aspects of a project, and that we are explicitly
interested in their personal thoughts and opinions. We went
over how we intend to collect and handle the interview data
and obtained the participant’s consent for recording and data
handling.
1. Project Demographics: The interview opens with a general
question section about the project and our participant’s relation
to it. This section is intended both to ease nervous participants
into the interview as well as establish some initial context
to later combine with actual repository data. We report the
demographics and combined data in Section IV-A and Table I.
2. Security Challenges: The “Security Challenges” sec-
tion explores past security challenges encountered by our
participants, as well as their opinion of a recent research
conflict. To open this section with an example of a recent
incident and to ease participants into this sensitive topic, we
queried them about, and if necessary introduced them to, the
“hypocrite commits” incident from early 2021 [10], [98], [99].
The incident is a recent, widely publicized example of well-
intentioned actions resulting in potentially adverse outcomes.
We selected this incident because we suspected that projects
are more familiar with well-intentioned commits turning sour,
compared to straight-up malicious attacks. We report these
results in Section IV-B.
3. Guidance and Policies: The “Guidance and Policies”
section establishes guidance provided for and policies enforced
by participants’ projects. Follow-ups for guidance included
specific guidance for infrastructure, programming style, and
cryptography usage. Follow-ups for policies included the (co-
ordinated) disclosure approach of the project, potential poli-
cies for handling security incidents, and policies for security
aspects such as enforced (security) reviews. We report these
results in Section IV-C.
4. Project Structure: The “Project Structure” section in-
vestigates behind-the-scenes structures and processes in the
project. Specifically, we were interested in structures that are
often not directly visible from repository artifacts, such as
how build and deploy steps are set up, who controls them,
and how the related secrets are managed. We also included
follow-ups for supply chain handling such as selection criteria
and vulnerability checks for dependencies. Lastly, we asked
participants about additional
infrastructure such as project
websites and communication tools, as well as who controls
these resources. We report these results in Section IV-D.
5. Releases and Updates: The “Releases and Updates”
section explores release mechanisms within the project as
well as how end users or downstream dependencies receive
updates to the latest version, with a special focus on security-
relevant fixes. In particular, we were interested in release
schedules, whether there were guidelines in place regarding
the deprecation of older (insecure) versions, as well as if and
how release binaries are secured. We report these results in
Section IV-E.
6. Roles and Responsibilities: The “Roles and Responsibili-
ties” section establishes the contributor hierarchy and security
roles of the project. We were especially interested in how
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:27 UTC from IEEE Xplore.  Restrictions apply. 
1884
decisions are formed and whether security-specific roles are
assigned. We report these results in Section IV-F.
7. Trust Processes: The “Trust Processes” section considers
established trust models in the project and how recently
onboarded contributors can become trusted members. Follow-
ups included questions about identity checks or the mandatory
signing of Contributor License Agreements (CLAs). Addition-
ally, we asked the participants about past trust incidents and, if
applicable, what their mitigation strategy looked like. In cases
without such an incident, we asked participants about their
opinion on what would happen if an incident occurred. We
report these results in Section IV-G.
8. Opinions and Improvements: The “Opinions and
Improvements” section aims to elicit participants’ personal
opinions and beliefs about current open source practices
regarding security and trust and how they would personally
approach improving the status quo. We report these results in
Section IV-H.
After the interview part, we debriefed the participants and
collected additional feedback regarding covered topics and
suggestions for interesting or unique open source projects to
contact.
C. Coding and Analysis
For our study with interviews and repository artifacts,
we evaluated both qualitative and quantitative data points.
We recorded the interviews digitally, transcribed them via
a GDPR-compliant service, and manually reviewed all tran-
scripts for potential mistakes.
We analyzed all interview answers in an iterative open-
coding approach [100]–[102]. All researchers together es-
tablished an initial codebook based on the interview guide
and interview impressions. Three researchers then iteratively
coded the interviews in multiple rounds, resolving conflicts
by consensus decision or by introducing new (sub)codes
after each iteration. We continued with our iterative coding
approach until no new codes or themes emerged [103], [104].
This approach does not necessitate the reporting of inter-
coder agreement, as each conflict is resolved when it emerges
(resulting in a hypothetical final agreement of 100%). In total,
we assigned 1618 codes after resolving, resulting in a median
of 59 codes per interview. The final codebook is included in
our replication package described in Section I-A.
D. Ethical Considerations and Data Protection
This experiment was approved by the human subjects re-
view board (IRB equiv.) of our institution. Research plan,
study procedure, and all involved parties adhered to the strict
German data and privacy protection laws, as well as the EU
General Data Protection Regulation (GDPR). In addition, we
modeled our study to follow the ethical principles of the Menlo
report for research involving information and communications
technologies [105]. All documents with personally identifiable
data according to the GDPR were stored in a secure cloud
collaboration software suite and were encrypted at rest and
in transit. The transcription service we leveraged is based
in the EU and fully complies with the GDPR. Our research
approach agrees with the Researcher Guidelines for the Linux
developer community introduced in response to the “hypocrite
commits” incident in late March 2022, after the conclusion of
our work [106].
We encouraged potential participants to familiarize them-
selves with consent and data handling information on a study
website before agreeing to any interview participation. We ob-
tained informed consent from all participants for participation
in the study and having their interview’s audio recorded. We
contacted participants with a preprint and gave them an oppor-
tunity to suggest changes or veto this work in its current form.
Before, during, and after the interview, (potential) participants
were able to contact us at listed contact addresses for any
questions or additional information. We consider the interview
questions regarding certain security incidents to be of sensitive
nature and explicitly highlighted to the participants that they
could skip questions or terminate the interview at any time.
Our participants did not receive any compensation, since we
surmised that open source contributors likely would be more
inclined to volunteer their time to research if they act out of
intrinsic motivation.
E. Limitations
Our work includes a number of limitations typical for this
type of interview study and should be interpreted in context.
In general, self-report studies may suffer from several biases,
including over- and under-reporting, sample bias, and social-
desirability bias. We do note that our sample is a convenience
sample and that our participants are not necessarily representa-
tive of contributors in the open source ecosystem. It is possible
that contributors who agreed to speak with us are more (or
less) security-conscious than those who declined.
During sampling, we focused on projects providing an En-
glish Readme document. We also offered and conducted seven
interviews in German for participants’ convenience. Thus,
we can offer no direct insight regarding the generalizability
of our results w.r.t. non-English and non-German speaking
open source contributors. During modelling of our study, we
decided that this was an agreeable trade-off, with English
serving as the “working language” of the international open
source community, likely allowing us to communicate with a
meaningful set of contributors.
Certain questions, e. g., about security and trust incidents,
can be considered to be of sensitive nature. To reduce social-
desirability bias in answers, we specifically highlighted to
participants that we were only interested in information about
their projects and not judging their security approaches and
processes in any way. We also instructed participants that they
were able to skip questions or to terminate the interview for
any reason at any time.
IV. RESULTS
In the following section, we report and discuss results for
27 semi-structured interviews with open source contributors,
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:27 UTC from IEEE Xplore.  Restrictions apply. 
1885
maintainers, and owners. In our reporting, we mostly adhere to
the structure of the interview guide described in Section III-A
and summarize our key findings after each question block.
We report participants’ quotes as transcribed, with minor
grammatical corrections and omissions marked by brackets
(“[. . .]”). Quotes from German interviews were translated to
English by native German speakers.
A. Project Demographics
In total, we interviewed 27 valid participants. In addition
to this section, we report general interview and project de-
mographics in Table I. As it is common in the open source
community to be involved in multiple projects, we encouraged
our participants to talk about the projects they considered most
relevant during the interview. For the collected quantitative
data, we considered the largest project mentioned during
the interview, as a trade-off between concise reporting and