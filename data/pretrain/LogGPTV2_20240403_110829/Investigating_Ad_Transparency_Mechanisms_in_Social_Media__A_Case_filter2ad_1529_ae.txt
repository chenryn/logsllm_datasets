Interest
Interest
Interest
PII-Based
PII-Based
Experiments
3
4
1
3
3
2
3
2
26
10
3
1
that received the ad do not have the same attributes). Thus,
we have no evidence that Facebook ad explanations are not
consistent.
d) Correctness: We observed that in some of our con-
trolled experiments the ad explanations provided by Facebook
contain,
in the second part of the explanations, potential
attributes that we never speciﬁed in our targeting, namely
location-related attributes.
To explore this, we performed 65 controlled experiments
where we did not specify any location and the audiences were
created using custom lists: Ai = (Custom List AND ai), or
Ai = (Custom List AND ai AND aj), where ai, aj are various
attributes. Despite the fact that we selected no location, all of
the corresponding ad explanations contained the following text
in the second part:
There may be other reasons why you’re seeing this
ad, including that [advertiser] wants to reach people
ages 18 and older who live [in/near] [location].
where [location] included “Germany”, “Saarbr¨ucken, Saar-
ˆIle-de-France”, “Nice, Provence-Alpes-Cˆote
land”, “Paris,
d’Azur”, “Ay´ıa Paraskev´ı, Attiki, Attica (region)”, depend-
ing on the user. This shows that Facebook adds potential
attributes to ad explanations that advertisers never speciﬁed
in their targeting, which makes them misleading. In all of
our experiments,
the location listed in the ad explanation
corresponded to the current location of the user receiving the
ad. Our intuition is that when the location is not speciﬁed by
the advertiser, Facebook is automatically adding the current
location of the user receiving the ad as a potential attribute
to the ad explanation (and not the location of the advertiser).
We do not believe that Facebook is intentionally constructing
misleading ad explanations, but our ﬁnding underscores the
importance of ensuring that ad explanations accurately capture
the reasons why a user was targeted.
e) Determinism:
In the AD-DATASET, we observed
that 12,144 ads were seen multiple times by the same user.
Of these, we found that 3% of the ads had at
two
different explanations given to the same user. For 55% of
these cases the change is in the second part of the explanation,
and corresponds to the explanation having different targeting
least
locations in each ad (potentially because the user was in a
different places when he received the ad). Thus, Facebook’s
ad explanations do not appear to always be deterministic.
3) Data-broker targeting: In the AD-DATASET, we col-
lected 78 ad explanations that mentioned data brokers. In these
cases, the actual targeted attribute is not given; instead, the user
is told they were part of an audience based on data provided by
a speciﬁc data broker (see Table III). This is in contrast with the
ﬁne-grained attributes that advertisers can choose from in the
Facebook advertiser interface (e.g., income level, see Table II).
To verify this, we conducted three controlled experiments
where A = (ai), with ai being an attribute provided by
Acxiom. As before, we observed that
the explanation did
not mention the actual attribute, but instead simply said it
was “based on data provided by Acxiom.” This indicates that
when advertisers use data-broker-provided targeting attributes,
Facebook provides incomplete explanations to users.
4) Advertiser-PII targeting: Finally, we examine how Face-
book’s explanations change when advertisers use PII-based
targeting (e.g., uploading the user’s PII to add them to an
audience, using a custom list). Across all explanations we
found when using PII-based targeting, Facebook provides
explanations like “you’re on their customer list” or “you’ve
provided them with your contact information off of Facebook.”
Unfortunately, Facebook does not reveal to the user which
PII the advertiser provided (e.g., their email address, phone
number, etc). Yet again, we ﬁnd that the explanations provided
by Facebook are incomplete; this issue is especially acute when
the advertisers are targeting users directly with their PII.
E. Summary
Across all of our experiments, we consistently found that
Facebook’s explanations are incomplete and sometime mis-
leading, often omitting key details that would allow users to
understand and potentially control the way they are targeted.
Many times, the ways in which the explanations are incomplete
make it difﬁcult for users to understand whether sensitive
information was used: by appearing to pick the most common
attribute to show, by not providing the actual attribute when
advertisers use data-broker-provided attributes, and by not
revealing the PII that advertisers provided when using PII-
based targeting.
IV. DATA INFERENCE EXPLANATIONS
We now turn to examine the data inference process, and
Facebook’s explanations that attempt to answer the question
what data about me is Facebook inferring and making avail-
able to advertisers to target me with ads? We call
these
answers data explanations. Similar to the previous section, we
ﬁrst discuss key properties of data explanations and then test
whether the explanations provided by Facebook satisfy these
properties.
A. What is a data explanation?
As mentioned in Section II-A, data explanations can pro-
vide information about the inputs, the outputs, or the map-
ping function of the data inference process. For example, an
explanation for outputs could simply list all
the attributes
the advertising platform has inferred about
the user or it
could provide additional information such as the platform’s
conﬁdence that the user actually has the given attribute, or
whether the attribute has an expiration date. An explanation
for the mapping function could simply say “We inferred that
you like Pizza from your activity on Facebook” or could give
a more ﬁne grained answer such as “We inferred that you like
Pizza because you checked in to Joe’s Pizza on 27 June 2017”.
An explanation for the mapping function could additionally
say how it is inferring an attribute such as “We use DBpedia
to infer attributes from your Facebook likes”, or even specify
when the platform usually updates the proﬁle of a user.
The amount of information that can be presented in an ex-
planation is therefore large. However, the advertising platform
might not wish for their “formula” to be revealed to the users,
as it might be considered intellectual property by the platform.
Facebook provides an Ad Preferences Page [5] that shows
users the advertising attributes it has inferred about
them
(i.e., the outputs). Facebook also gives explanations about the
actions that led to the inference of a particular attribute (i.e.,
Facebook provides information about the mapping function of
the data inference system), see Figure 3. We next discuss what
are some key properties for such explanations.
B. Properties of data explanations
Let us suppose that a user U performed a set of actions in
on Facebook (i.e., the inputs), and that Facebook inferred a set
of attributes on about the user from these activities (i.e., the
outputs). And let us suppose the mapping function for inputs
to outputs had the rule
(i1 AND i2) OR i3
=⇒ o1, o2, o3
We next describe the types of data explanations a platform
could provide.
a) Speciﬁcity: A data explanation is precise if it shows
the precise activities that were used to infer an attribute about
a user. A precise explanation for o1 might be “we inferred
o1 because you took the actions i1 and i2”, while a vague
explanation might be “we inferred o1 because of what you do
on Facebook.” We say that an explanation is precise enough
when it is reproducible. Precise explanations are preferable
over vague explanations as they provide actionable information
that users can use to control what the advertising platform is
inferring about them.
b) Snapshot completeness: A data explanation is snap-
shot complete if the explanation shows all the inferred at-
tributes about
the user that Facebook makes available. A
complete data explanation for a user who took action i3 would
be {o1, o2, o3}, while an incomplete data explanation would be
{o1}.
The number of attributes the advertising platform has
inferred about a user can sometimes be large. Thus, it might
be desirable to list the attributes by their importance, for some
measure of importance (e.g., how rare/uniquely identifying is
the attribute, how many ads received by the user were shown
because of the particular attribute, etc). We leave a more in-
depth exploration of the best design choices to future work.
11
c) Temporal completeness: In our experimental results,
we observe that the attributes inferred about users change
quite often. Hence, for a system that
is highly dynamic,
snapshot completeness is not enough and it is important for
the explanation to be temporally complete and show all the
attributes inferred about a user over a period of time. Moreover,
it may be equally important to learn that the platform removed
an attribute as it is to learn that it inferred it in the ﬁrst place.
Thus, a temporally complete explanation is one where the
platform shows all inferred attributes over a speciﬁed period
of time.
d) Correctness: A correct explanation is one that only
shows the activities that actually lead to the inference of the
attributes. Correct explanations for o1 would include {i1 AND
i2}, or {i3}. An incorrect explanation would be {i4 AND
i2}. It is important, when analyzing the properties of a data
explanation, not to confuse the properties of the explanations
with the properties of the inference algorithm. For example,
an explanation might be correct, even if the attributes inferred
are incorrect (i.e., the user is not interested in a particular
attribute).
Note that, while speciﬁcity and correctness are properties
of explanations of the mapping function, snapshot and tempo-
ral completeness are properties of explanations of the outputs.
C. Measurement methodology
To study what data explanations Facebook provides, we
crawl the information on the Ad Preferences Page daily over
a 5 month period for the 35 monitored users.
The Ad Preferences Page provides insights on three as-
pects: interests: the interests Facebook inferred about the user
from his activity on Facebook such as the pages he liked;
advertisers: the advertisers connected to the user (advertisers
whose ads the user clicked on, advertisers whose webpages
he visited, and advertisers who have the user’s contact in-
formation); and categories: the demographic and behavioral
information Facebook has collected or has inferred about the
user based on data inside or outside of Facebook (see Figure 3).
To analyze this information, our Chrome extension collects all
the attributes present on the Ad Preferences Page on a daily
basis. For interests alone, Facebook provides explanations of
why they inferred the particular interest; we collect
these
explanations as well.
D. Evaluation of Facebook’s data explanations
We now examine the data we collected from our 35
users to better understand the properties of Facebook’s data
explanations.
1) Overview: We ﬁrst examine the number of attributes
that Facebook reports to each user. We ﬁnd that the number
of reported attributes varies widely by user, ranging from 4 to
893 attributes, with an average of 247 and a median of 153.
Across all users, we ﬁnd that most reported attributes were
interest-based (93%), followed by behavior-based (5%) and
demographic-based (2%).
We also examine how often these reported attributes change
(recall that we collect the reported attributes daily for each
Fig. 3: Example of information provided in the Ad Preferences
Page.
user). We measure changes using divergence, which is simply
|Setday1 ⊕ Setday2|
where ⊕ denotes the disjunctive union of the sets. Thus,
the divergence is simply the number of attributes added or
removed. Across all users, we ﬁnd that the average daily
divergence ranges from 0 to 82, with an average of 10.7. Thus,
we see that the inferred attributes change somewhat rapidly (on
average, 4.3% of attributes change per day).
Next, we turn to examine whether the explanations meet the
properties we outlined in Section IV-B. Recall that Facebook
only provides data explanations for interest attributes; thus,
these are the explanations we examine for the remainder of
this section.
2) Speciﬁcity: Out of the 9,929 different data explana-
tions we collected, we extracted ﬁve distinct patterns; these
are shown in Table V. The explanations are usually short,
generic, and they mostly refer to ad clicks, page likes or app
installations. While explanations that refer to app installs, as
well as explanations that refer to preferences that the users
added themselves, are precise, the majority (97%) of data
explanations are not. For example, the vast majority of interest
explanations are due to liked pages and ad clicks, but Facebook
does not specify which page or ad led to the interest attribute.
3) Snapshot completeness: To evaluate the snapshot com-
pleteness, we test whether Facebook allows advertisers to
target users based on attributes that do not appear in their
Ad Preferences Page. Thus, for each user, we check whether
there are attributes that appear in their ad explanations but
12
TABLE V: Overview of data explanations we observed.
Pattern
You have this preference because you liked a page related to [interest]
You have this preference because you clicked on an ad related to [interest]
You have this preference because we think it may be relevant to you
based on what you do on Facebook, such as pages you’ve liked or ads
you’ve clicked
You have this preference because you installed the app [app]
This is a preference you added
Explanations
4,518
4,352
785
249
25
which never appeared in their Ad Preferences Page, we call
them these hidden attributes. In our dataset, we found a total
of 205 hidden attributes for 24 distinct users, 55 of these are
proﬁle attributes such as schools, languages, or relationship
status, and the rest are interest-, behavior-, or demographic-
based attributes. It is important to note that this does not mean
explanations are deﬁnitely incomplete, as we may have missed
some attributes that only appeared brieﬂy in the Ad Preferences
Page (i.e., for less than one day).
To verify whether we can target people with attributes
that do not appear in their Ad Preferences Page, we launched
several controlled experiments targeting an audience with dif-
ferent attributes that are not present in a user’s Ad Preferences
Page. If the monitored user receives an ad from one of these
campaigns with an ad explanation containing the attribute, it
means that Facebook allows advertisers to target him with
attributes that are not shown in the Ad Preferences Page.9
We tested six data broker attributes, out of which two
resulted in successful campaigns with a data broker expla-
nation for a monitored user; we also tested four proﬁle data
and language attributes, out of which two were observed in
a data explanation for at least one monitored user. While
we observed that most of the proﬁle data attributes appear
in some form in the “About Page”, or “Facebook Settings”
of a user, we observed that no data broker attributes appear
in the Ad Preferences Page (or other places) of any of our
monitored users. According to a statement by a Facebook
representative [15], the absence of data broker attributes from
the Ad Preferences Page is a deliberate choice, motivated by
the fact that the data was not collected by Facebook. Due to
this decision, Facebook’s data explanations are not complete,
as no data broker attributes are ever shown to users.