title:GuardSpark++: Fine-Grained Purpose-Aware Access Control for Secure
Data Sharing and Analysis in Spark
author:Tao Xue and
Yu Wen and
Bo Luo and
Boyang Zhang and
Yang Zheng and
Yanfei Hu and
Yingjiu Li and
Gang Li and
Dan Meng
GuardSpark++: Fine-Grained Purpose-Aware Access Control for
Secure Data Sharing and Analysis in Spark
Tao Xue
Institute of Information Engineering,
Chinese Academy of Sciences
Institute of Information Engineering,
Chinese Academy of Sciences
Yu Wen∗
Beijing, China
PI:EMAIL
The University of Kansas
Bo Luo
Kansas, USA
PI:EMAIL
Beijing, China
School of Cyber Security, University
of Chinese Academy of Sciences
Beijing, China
PI:EMAIL
Boyang Zhang
Institute of Information Engineering,
Chinese Academy of Sciences
Institute of Information Engineering,
Chinese Academy of Sciences
Institute of Information Engineering,
Chinese Academy of Sciences
Yang Zheng
Yanfei Hu
Beijing, China
PI:EMAIL
Beijing, China
PI:EMAIL
Beijing, China
School of Cyber Security, University
of Chinese Academy of Sciences
Beijing, China
PI:EMAIL
Dan Meng
Beijing, China
PI:EMAIL
Department of Computer and
Information Science, University of
Centre for Cyber Security Research
and Innovation, Deakin University
Institute of Information Engineering,
Chinese Academy of Sciences
Yingjiu Li
Oregon
Oregon, USA
PI:EMAIL
Gang Li
Geelong, Australia
PI:EMAIL
ABSTRACT
With the development of computing and communication technolo-
gies, extremely large amount of data has been collected, stored,
utilized, and shared, while new security and privacy challenges
arise. Existing platforms do not provide flexible and practical access
control mechanisms for big data analytics applications. In this paper,
we present GuardSpark++, a fine-grained access control mecha-
nism for secure data sharing and analysis in Spark. In particular, we
first propose a purpose-aware access control (PAAC) model, which
introduces new concepts of data processing/operation purposes
to conventional purpose-based access control. An automatic pur-
pose analysis algorithm is developed to identify purposes from data
analytics operations and queries, so that access control could be
enforced accordingly. Moreover, we develop an access control mech-
anism in Spark Catalyst, which provides unified PAAC enforcement
∗Corresponding Author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ACSAC 2020, December 7–11, 2020, Austin, USA
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-8858-0/20/12...$15.00
https://doi.org/10.1145/3427228.3427640
for heterogeneous data sources and upper-layer applications. We
evaluate GuardSpark++ with five data sources and four structured
data analytics engines in Spark. The experimental results show that
GuardSpark++ provides effective access control functionalities with
a very small performance overhead (average 3.97%).
CCS CONCEPTS
• Security and privacy → Access control.
KEYWORDS
Spark, big data, access control, data sharing, data protection, pur-
pose
ACM Reference Format:
Tao Xue, Yu Wen, Bo Luo, Boyang Zhang, Yang Zheng, Yanfei Hu, Yingjiu Li,
Gang Li, and Dan Meng. 2020. GuardSpark++: Fine-Grained Purpose-Aware
Access Control for Secure Data Sharing and Analysis in Spark. In Annual
Computer Security Applications Conference (ACSAC 2020), December 7–11,
2020, Austin, USA. ACM, New York, NY, USA, 14 pages. https://doi.org/10.
1145/3427228.3427640
1 INTRODUCTION
In the big data era, tremendous amount of data is being collected,
stored, and utilized in various platforms and applications [29]. The
big data processing platforms have been developed to harness data,
to facilitate data analytics functions, and to discover intrinsic value
ACSAC 2020, December 7–11, 2020, Austin, USA
Tao Xue, et al.
from data [2, 28, 33, 43, 74]. They were designed to access various
data sources, support hybrid data analytics engines (e.g., advanced
SQL, machine learning, and graph) and efficiently process a very
large volume of data. However, data security and privacy were not
sufficiently considered when these platforms were designed. As a
result, very limited data protection functions are provided, so that
data owners and administrators are unable to specify fine-grained or
complex access control intentions. For example, users often get full
access to sensitive raw data when they are supposed to only execute
aggregate or statistical queries. Moreover, data gets more vulnerable
in the context of large-scale cross-organizational data sharing [10,
20], where curious users may correlate data/attributes from multiple
sources or platforms to further extract sensitive information.
algorithms could be employed, including regression analysis, time
series analysis, stochastic models, etc. It is almost impossible to
specify a static set of database operations to be allowed under this
purpose. Meanwhile, the same operation may be a building block in
satisfying different data usage purposes. It could be difficult for the
database engine to automatically identify the right purpose for an
operation, and to allow or deny the operation based on the purpose.
To tackle the challenges, we propose GuardSpark++, a fine-
grained access control mechanism for big data sharing and analy-
sis. We first design a purpose-aware access control (PAAC) model,
which introduces data processing purposes and data operation pur-
poses to conventional PBAC. With PAAC, GuardSpark++ could auto-
matically recognize the data processing purposes from data process-
ing logics, and then make access decisions accordingly. Moreover,
we enforce the PAAC model in the Catalyst optimizer of Spark [26].
We add an access control enforcement stage between the analysis
and optimization stages of Spark’s optimization pipeline. The ac-
cess control stage generates secure logical query plans according
to the specified PAAC policies, so that sensitive data objects are
only used in data operations that are consistent with the authorized
purposes. To demonstrate the effectiveness of GuardSpark++, we
evaluate it with five data sources: network streaming, LFS, HDFS,
MySQL and Kafka, and four structured data analytics engines: SQL,
ML Pipeline, GraphFrame, and Structured Streaming. Last, we eval-
uate the efficiency of GuardSpark++ using the TPC-DS benchmark
[11], and show that GuardSpark++ only introduces 3.97% average
overhead on top of the original Spark.
To our best knowledge, GuardSpark++ is the first effort towards a
practical purpose-aware access control solution for big data security
in Spark. In particular, our main contributions are:
• We have designed a fine-grained purpose-aware access control
(PAAC) model with the newly defined data processing purposes and
data operation purposes for big data analytics. We further develop
analysis algorithm to support automatic purpose recognition, which
is the core component for enforcing PAAC. (Section 4)
• We developed a PAAC enforcement mechanism, which provides
unified access control support for the heterogeneous data sources
(at lower layer) and the higher-layer data analytics engines in Spark.
• We further evaluated GuardSpark++’s effectiveness and efficiency
with five data sources (network streaming, LFS, HDFS, MySQL,
and Kafka) and four data analytics engines (SQL, ML Pipelines,
GraphFrame and Structured Streaming). Experiment results show
that GuardSpark++ provides expected security guarantees with a
very small computation overhead.
The rest of the paper is organized as follows: we introduce Apache
Spark and articulate our motivation in Section 2. We present the
threat model and an overview of GuardSpark++ in Section 3, fol-
lowed by the technical details of the PAAC model and the purpose
analysis algorithm in Section 4, and the PAAC enforcement mech-
anism in Section 5. We then present the experimental results and
security analysis in Sections 6 and 7. Finally, we briefly survey the
literature in Section 8 and conclude the paper in Section 9.
In data management and sharing applications, access control is
the essential protection mechanism to defend against unauthorized
access to sensitive data [40, 41, 44, 70]. A baseline solution for the
big data platforms is to directly employ access control functionali-
ties provided by the underneath data source or OS. However, this
simple solution is usually insufficient in supporting users’ access
control needs: 1) those mechanisms often fall short in providing
fine-grained (attribute-, record-, or cell-level) access control capa-
bilities, which is the de facto granularity standard for state-of-art
data management applications [68]. For instance, the Hadoop Dis-
tributed File System (HDFS) only provides access control capability
at the file level, which could be too coarse-grained for users’ ex-
pectations. And 2) the heterogeneity of the security models and
mechanisms from various data sources may cause incompatible
access control features and inconsistent capabilities. For instance,
if the user aggregates data from multiple sources that all contain
sensitive attributes, the security guarantee is only as good as the
weakest link among all data providers.
Security middlewares, such as Apache Sentry [5] and Apache
Ranger [4], have been developed to provide fine-grained role-based
access control solutions for heterogeneous data sources. However,
they do not support access policies that control data usage, such
as “user could run statistical functions on sensitive data but could
not see the raw data.” Unfortunately, such operations are often the
purpose of many big data analysis applications, and the correspond-
ing policies are the primary access control intentions of the data
owners in big data sharing scenarios [51]. For example, when e-
commerce platforms collaborate with retailers and advertisers, they
would allow the collaborators to run data analytics algorithms or
issue aggregate queries on the transaction database, so that the col-
laborators may analyze the market, discover sales trends/patterns,
and optimize their business strategies. Meanwhile, the e-commerce
platforms also need to ensure that the collaborators’ queries could
never access the raw data, which is sensitive and private.
The purpose-based access control (PBAC) model [32, 37, 38] was
proposed for privacy-preserving access control. PBAC was initially
designed for conventional RDBMS, in which specific purposes of
data usage were defined and translated to a set of SQL queries
to be authorized. For example, the purpose of “shipping” allows
querying the shipping addresses of active orders [32]. However,
in big data analytics applications, it could be difficult to directly
associate the abstract-level data usage purposes to system-level data
processing logic and database operations. For instance, to achieve
the data usage purpose “analyzing sales trends”, many different
GuardSpark++: Fine-Grained Purpose-Aware Access Control for Secure Data Sharing and Analysis in Spark
ACSAC 2020, December 7–11, 2020, Austin, USA
Figure 1: A medical data sharing scenario: example tables
and an example application based on DataFrame APIs.
2 BACKGROUND AND MOTIVATION
2.1 Introduction to Apache Spark
Apache Spark is a unified computing engine in big data ecosystem,
and its layout contains three layers: application layer, optimization
layer and execution layer [35].
At application layer, Spark supports structured data analytics
engines/APIs based on data types DataFrame and Dataset[35]. An