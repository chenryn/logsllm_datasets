above requires O(Ct) CPU and memory if it does not expire any state, while the FTP
session analyzer only requires CPU and memory in proportion to the number of FTP
client connections). However, in our experience it is rare that such analyzers exceed
CPU or memory demands of O(Ct), since such analysis quickly becomes intractable
on any high-volume link. Moreover, while it is possible that such inter-connection an-
alyzer may depend on the results of other analyzers, we ﬁnd that such analyzers tend
to be well modular and decoupled (e.g., the scan detector needs the same amount of
memory independent of whether the NIDS performs HTTP URL extraction or enables
FTP session-tracking).
3.2 Principle Contributors to Resource Usage
Overall, it appears reasonable to assume that for a typical analyzer, resource usage
is (i) linear with either the number of input packets or the number of connections it
processes, and (ii) independent of other analyzers. In this light, we can frame two main
contributors to the resource usage of a NIDS:
1. The speciﬁc analyzers enabled by the operator for the system’s analysis. That these
contribute to resource usage is obvious, but the key point we want to make is that
most NIDSs provide options to enable/disable certain analyzers in order to trade off
resource requirements. Yet NIDSs give the operators almost no concrete guidance
regarding the trade-offs, so it can be extremely hard to predict the performance of
a NIDS when enabling different sets of analyzers. This difﬁculty motivated us to
build our tool nidsconf (per §5.2) that provides an understanding of resource
usage trade-offs to support conﬁguration decisions.
Predicting the Resource Consumption of NIDSs
141
2. The trafﬁc mix of the input stream—i.e., the prevalence of different types of appli-
cation sessions—as this affects the number of connections examined by each type
of analyzers.
The above reasoning need not hold universally. However, we examined the architec-
ture of two popular open source NIDS, Snort and Bro, and found that their resource
consumption indeed appears consistent with the model discussed above. We hypothe-
size that we can characterize most operational NIDSs in this fashion, and thus they will
lend themselves well to the kind of performance prediction we outline in §5. To support
our claims, we now explore the resource usage of the Bro NIDS in more depth.
4 Example NIDS Resource Usage
To assess our approach of modeling a NIDS’s resource demands as the sum of the
requirements of its individual analyzers, and scaling linearly with the number of ap-
plication sessions, we now examine an example NIDS. Among the two predominant
open-source NIDSs, Snort and Bro, we chose to examine Bro for two reasons: (i) Bro
provides a superset of Snort’s functionality, since it includes both a signature-matching
engine and an application-analysis scripting language; and (ii) it provides extensive,
ﬁne-grained instrumentation of its internal resource consumption; see [3] for the
speciﬁcs of how the system measures CPU and memory consumption in real-time. Snort
does not provide similar capabilities. For our examination we have to delve into details
of the Bro system, and we note that some of the speciﬁcs of our modeling are neces-
sarily tied to Bro’s implementation. While this is unavoidable, as discussed above we
believe that similar results will hold for Snort and other modern NIDSs.
For our analysis we captured a 24-hour full trace at the border router of the
M¨unchener Wissenschaftsnetz (MWN). This facility provides 10 Gbps upstream ca-
pacity to roughly 50,000 hosts at two major universities, along with additional research
institutes, totaling 2-4 TB a day. To avoid packet drops, we captured the trace with a
high-performance Endace DAG card. The trace encompasses 3.2 TB of data in 6.3 bil-
lion packets and 137 million connections. 76% of all packets are TCP. In the remainder
of this paper, we refer to this trace as MWN-full.
4.1 Decomposition of Resource Usage
We ﬁrst assess our hypothesis that we can consider the resource consumption of the
NIDS’s analyzers as independent of one another. We then check if resource usage gen-
erally scales linearly with the number of connections on the monitored network link.
Independence of Analyzer Resource Usage. For our analysis we use Bro version
1.1, focusing on 13 analyzers: ﬁnger, frag, ftp, http-request, ident, irc, login, pop3,
portmapper, smtp, ssh, ssl, and tftp. To keep the analyzed data volume tractable, we use
a 20-minute, TCP-only excerpt of MWN-full, which we refer to as Trace-20m,
We run 15 different experiments. First, we establish a base case (BROBASE), which
only performs generic connection processing. In this conﬁguration, Bro only analyzes
connection control packets, i.e., all packets with any of the TCP ﬂags SYN, FIN or
142
H. Dreger et al.
sum of analyzer workloads
sum of normalized analyzer workloads
no error
+0.2s absolute error
p
u
d
e
m
m
u
s
s
r
e
z
y
a
n
a
l
l
l
a
,
]
s
[
e
m
i
t
U
P
C
6
.
1
4
.
1
2
.
1
0
.
1
8
.
0
6
.
0
4
.
0
0.4
0.6
0.8
1.0
1.2
1.4
1.6
CPU time [s], all analyzers loaded
Fig. 2. Scatter plot of accumulated CPU usages vs. measured CPU usage
RST set. This sufﬁces for generating one-line summaries of each TCP connection in
the trace. BROBASE thus reﬂects a minimal level of still-meaningful analysis. Next,
we run a fully loaded analysis, BROALL, which enables all analyzers listed above, and
by far exceeds the available resources. Finally, we perform 13 additional runs where we
enable a single one of the analyzers on top of the BROBASE conﬁguration. For each test,
Bro is supplied with a trace preﬁltered for the packets the conﬁguration examines. This
mimics live operation, where this ﬁltering is usually done in the kernel and therefore
not accounted to the Bro process.
We start with examining CPU usage. For each of the 13 runs using BROBASE plus
one additional analyzer, we calculate the contribution of the analyzer as the difference
in CPU usage between the run and that for the BROBASE conﬁguration. We then form
an estimate of the time of the BROALL conﬁguration as the sum of the contributions
of the individual analyzers plus the usage of the BROBASE conﬁguration. We term this
estimate BROAGG.
Figure 2 shows a scatter plot of the measured CPU times. Each point in the plot
corresponds to the CPU time required for one second of network input. The circles
reﬂect BROAGG (Y-axis) versus BROALL (X-axis), with ﬁve samples between 1.7s and
2.6s omitted from the plot for legibility. We observe that there is quite some variance
in the matching of the samples: The mean relative error is 9.2% (median 8.6%) and
for some samples the absolute error of BROAGG’s CPU time exceeds 0.2s (20% CPU
load). There is also a systematic bias towards slight underestimation by BROAGG, with
about 64% of its one-second intervals being somewhat lower than the value measured
during that interval for BROALL.
To understand the origin of these differences, we examine the relative contribution
of the individual analyzers. We ﬁnd that there are a number of analyzers that do not
add signiﬁcantly to the workload, primarily due to those that examine connections that
are not prevalent in the analyzed network trace (e.g., ﬁnger). The resource consumption
with these analyzers enabled is very close to that for plain BROBASE. Furthermore, due
to the imprecision of the operating system’s resource accounting, two measurements
of the same workload are never exactly the same; in fact, when running the BROBASE
conﬁguration ten times, the per-second samples differ by MR = 18 msec on aver-
age. This means that if an analyzer contributes very little workload, we cannot soundly
Predicting the Resource Consumption of NIDSs
143
distinguish its contribution to CPU usage from simple measurement variation. The
ﬂuctuations of all individual runs with just one additional analyzer may well accumulate
to the total variation seen in Figure 2.
To compensate for these measurement artifacts, we introduce a normalization of
CPU times, as follows. For each single-analyzer conﬁguration, we ﬁrst calculate the dif-
ferences of all its CPU samples with respect to the corresponding samples of BROBASE.
If the mean of these differences is less than the previously measured value of MR then
we instead predict its load based on aggregation across 10-second bins rather than 1-
second bins. The ’+’ symbols in Figure 2 show the result: we both reduce overall ﬂuc-
tuation considerably, and no sample of BROAGG exceeds BROALL by more than 0.2s.
The mean relative error drops to 3.5% (median 2.8%), indicating a good match. As in
the non-normalized measurements, for most samples (71%) the CPU usage is extrapo-
lated to slightly lower values than in the actual BROALL measurement. The key point
is we achieve these gains solely by aggregating the analyzers that introduce very light
additional processing. Thus, we conclude that (i) these account for the majority of the
inaccuracy, (ii) correcting them via normalization does not diminish the soundness of
the prediction, and (iii) otherwise, analyzer CPU times do in fact sum as expected.
Turning to memory usage, we use the same approach for assessing the additivity of
the analyzers. We compute the difference in memory allocation between the instance
with the additional analyzer enabled versus that of BROBASE. As expected, summing
these differences and adding the memory consumption of BROBASE yields 465 MB,
closely matching the memory usage of BROALL (461 MB).
Overall, we conclude that we can indeed consider the resource consumption of the
analyzers as independent of one another.
Linear Scaling with Number of Connections. We now assess our second hypothesis:
that a NIDS resource consumption scales linearly with the number of processed connec-
tions. For this evaluation, we run Bro with identical conﬁgurations on traces that differ
mainly in the number of connections that they contain at any given time. To construct
such traces, we randomly subsample an input trace using per-connection sampling with
different sampling factors, run Bro on the subtrace, and compare the resulting resource
usage in terms of both CPU and memory. To then extrapolate the resource usage on the
full trace, we multiply by the sample factor.
To sample a trace with a sample factor P , we hash the IP addresses and port num-
bers of each packet into a range [0; P − 1] and pick all connections that fall into a
particular bucket. We choose a prime for the sample factor to ensure we avoid aliasing;
this approach distributes connections across all buckets in a close to uniform fashion as
shown in [11]. For our analysis we sampled Trace-20m with sampling factors P = 7
(resulting in STRACE7) and P = 31 (resulting in STRACE31).
CPU Usage. Figure 3 shows a scatter plot of the CPU times for BROBASE on
Trace-20m without sampling, vs. extrapolating BROBASE on STRACE7 (circles) and
STRACE31 (triangles). We notice that in general the extrapolations match well, but are
a bit low (the mean is 0.02 sec lower). Unsurprisingly, the ﬂuctuation in the deviation
from the originally measured values grows with the sampling factor (further measure-
ments not included in Figure 3 with sampling factors between 7 and 31 conﬁrm this).
144
H. Dreger et al.
sampling factor 7
sampling factor 31
s
e
c
a
r
t
d
e
p
m
a
s
e
m
l
i
t
r
e
s
u
5
.
0
4
.
0
3
.
0
2
.
0
0.2
0.3
0.4
0.5
user time for analyzing unsampled trace
Fig. 3. Scatter plot of BROBASE conﬁguration on sampled traces vs. non-sampled trace
4
3
2
1
g
n
i
l
p
m
a
s
.
n
n
o
c
/
w
s
e
u
a
v
l
e
l
i
t
n
a
u
Q
80%
95%
sampling factor 7
sampling factor 11