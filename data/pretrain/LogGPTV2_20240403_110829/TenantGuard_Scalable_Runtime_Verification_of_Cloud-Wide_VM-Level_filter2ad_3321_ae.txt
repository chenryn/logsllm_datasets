In this step as well, we rely on state-of-the-art ﬁrst-match
algorithm applied on ﬁrewall rules at each VM-side against
the header of the symbolic packet. Therefore, the correctness
of our approach follows from the correctness of those well-
established algorithms in a straightforward manner.
5) Incremental Veriﬁcation: The dynamic nature of cloud
leads to frequent changes in the conﬁgurations of virtual
networks. The veriﬁcation result may be invalidated even after
a single change, such as the deletion of a security group
rule from a group of VMs, or the addition of a routing
rule to a router. However, verifying the cloud-wide network
isolation again after each such event is obviously costly and
unnecessary.
To cope with the effect of each event at run-time, Ten-
antGuard adopts an incremental event-driven veriﬁcation ap-
proach. This approach ﬁrst identiﬁes the set of events that
potentially impact the isolation results. Then, the impact of
each such event is identiﬁed. Finally, only those parts of the
veriﬁcation that are affected by the event will be re-evaluated.
Table II lists an excerpt of events that may require updating
the veriﬁcation results along with their impact. Note that G
should be updated for all these events and the symbol ∗ in the
table indicates the network elements impacted by the event.
To illustrate how such events may be handled via incre-
mental veriﬁcation, Algorithm 3 sketches the steps for partially
updating the veriﬁcation results upon deleting a security group
rule and upon adding a new routing rule, respectively, as
explained in the following (detailed algorithms for other events
are omitted due to space limitations).
- Creating a VM: The creation of a new VM (denoted
as VM*) does not affect the veriﬁcation process unless
it gets connected to one or more subnets through virtual
ports, which naturally leads to the update of our graph
model by creating the corresponding virtual port nodes.
Furthermore, when the VM is ﬁrst created, it is attached to
9
Event
Creating a VM*
Deleting a VM*
Creating a subnet SN*
Deleting a subnet SN*
Creating a router R*
Deleting a router R*
Veriﬁcation Tasks
• Invoke VM-to-VM for VM* once as source and once as destination
• Remove the results related to VM-to-VM for VM*
• Initialize a radix trie for the host routes
• Create new preﬁx-to-preﬁx binary tries where SN* is source or destination
• Invoke preﬁx-to-preﬁx for subnets in the C* related to SN*
• Invoke preﬁx-to-preﬁx (Step 2.a and Step 2.b) for SN*
• Delete the preﬁx-to-preﬁx tries where SN* is source or destination
• Update VM-level isolation for all VMs having private IPs within the preﬁx of SN* either as source or destination
• Initialize the corresponding radix trie
• Recalculate all the preﬁx-to-preﬁx tries for the component C* related to R*
• Partially perform VM-level isolation for all VMs belonging to C* considered as source and as destination
TABLE II.
AN EXCERPT OF EVENTS AND THEIR CORRESPONDING INCREMENTAL VERIFICATION TASKS. THE SYMBOL * INDICATES THE NETWORK
ELEMENTS THAT ARE IMPACTED BY THE EVENT
the default security group. At this level, the results of step
1 and step 2 of our methodology remain unchanged and
the veriﬁcation update is conﬁned to step 3 by invoking
the function VM-to-VM.
- Deleting a VM: After deleting a VM, the graph model is
updated by removing the associated virtual ports, then the
last result is updated by removing all VM pairs where the
deleted VM appears either as a source or as a destination.
- Creating a subnet: When a subnet (denoted as SN*) is
newly created, it is speciﬁed with a gateway, which is a
router interface, and an IP preﬁx. Our graph model is up-
dated with a new subnet node with an edge to the gateway
interface and the corresponding radix tree is initialized.
This event will create new preﬁx-to-preﬁx binary tries
for which SN* is either a source or a destination. This
would result in re-calculating step 1 for C*, the maximally
connected component SN* belongs to, then step 2-a and
step 2-b for SN*. As long as no VM has been attached
to SN*, the VM-to-VM reachability veriﬁcation (step 3)
does not require updates.
- Deleting a subnet: The deletion of a subnet (denoted as
SN*) will lead to deleting the preﬁx-to-preﬁx tries where
SN* appears either as a source or as a destination. This
will obviously reduce the number of possible forwarding
paths. As such, VM-to-VM reachability also needs to
be updated accordingly for all VMs having their private
IPs within the preﬁx of SN* either as a source or as a
destination.
- Creating a router: The event of adding a router (denoted
as R*) would result only in adding a router node in
the graph model and initializing the corresponding radix
tree. The veriﬁcation result is affected when the router’s
interfaces are connected either to the tenant’s network or
to the external network, and the routing rules are added.
- Deleting a router: Deleting a router R* requires recal-
culating all the Btries for the component C* the router
belongs to. VM-to-VM reachability analysis should also
be partially performed in this situation for all VMs
belonging to C* either considered as a source or as a
destination.
- Deleting a security group rule: Whenever an ingress (or
egress) rule is deleted from a security group, the action is
propagated into all VMs, denoted as VMs*, this security
group is attached to. Consequently, the corresponding
ingress (or egress) radix trie is updated accordingly. Let
VM* be a member of VMs*. For the deletion of an egress
(resp. ingress) rule, security groups veriﬁcation result is
updated for all pairs where VM* appears as a source VM
(resp. destination VM).
- Adding a routing rule: Whenever a new routing rule
is added to a router, denoted as R*, belonging to a
component C*, this would result in updating the cor-
responding radix trie with the decision of the newly
inserted rule. Then, for each preﬁx-to-preﬁx binary trie
built for subnets belonging to the component C*, the
variable HR of the binary trie (holding the history of
visited nodes) is consulted. If the ID of R* appears in the
history of traversed nodes, then the corresponding binary
trie needs to be updated. Then VM-level isolation needs
to be checked for couples of VMs if the source and/or
destination belong to C*. Routing rules and host routes
deletion and addition events are handled similarly.
if r* is an egress rule then
V erif ySecGroups(V M ∗, V Mdest)
if r* is an ingress rule then
V erif ySecGroups(V Msrc, V M ∗)
for each pair (V Msrc, V Mdst) where (V Msrc = V M ∗ do
Algorithm 3 Rules addition/deletion
1: On the creation/deletion of a security group rule r* for a set of VMs* do:
2: update RadixTrie(r*)
3: for each VM* in VMs* do
4:
5:
6:
7:
8:
9:
10: On the creation/deletion of a routing rule r* at router R* belonging to C* do:
11: update RadixTrie(r*)
12: for each pref ix-to-pref ix binary trie btrie built for subnets of C ∗ do
13:
14:
15: for each pair (V Msrc, V Mdst) where V MsrcinC ∗ and/or V MdstinC ∗ do
16:
for each pair (V Msrc, V Mdst) where (V Mdst = V M ∗ do
if R∗isinbtrie.leaves.HR then
pref ix-to-pref ix(btrie)
V M-to-V M(V Msrc, V Mdst)
To facilitate the veriﬁcation update, we leverage caches that
store intermediary and previous preﬁx-level isolation results,
such as X-fast binary tries. We also utilize the radix tries,
which store the routing rules and the security groups.
As discussed in Section IV-C3, the complexity of Algo-
rithm 3 (basically updating the Radix tree) is constant because
it is linear in the length of a key, which is bounded by 32. In
contrast, the complexity of a full veriﬁcation is O(M 2) where
M is the number of VMs, can be as large as millions for a real
cloud. Therefore, the overhead of our incremental veriﬁcation
is negligible in comparison to a full veriﬁcation.
V. APPLICATION TO OPENSTACK
We have implemented the proposed system design as a
prototype system based on OpenStack [12]. In this section, we
brieﬂy discuss implementation details about data collection,
preprocessing, and parallel veriﬁcation. In OpenStack, VMs
are managed by the compute service Nova, while networking
service Neutron manages virtual networking resources in the
10
cloud. Data related to these services is stored in databases
containing over one hundred tables.
Data Collection and Preprocessing. TenantGuard allows both
on-demand and on regular basis incremental auditing. To build
a snapshot of the virtual networking infrastructure for audit-
ing, we collect data from OpenStack databases. Additionally,
we leverage the notiﬁcation service from PyCADF [44] and
Ceilometer [12] services to intercept operational events that
result in a conﬁguration change. Thus, our data collection
module starts by collecting an initial snapshot of the virtual
networking infrastructure. Then, at each detected event, the
changed conﬁguration is gathered and the snapshot of the vir-
tual networking infrastructure is updated to enable incremental
veriﬁcation.
Once the data is collected, we perform several prepro-
cessing steps, such as building and initializing different data
structures to be used in the veriﬁcation step. For instance, from
the list of all subnets, routers, and gateways of all tenants,
we correlate the information to determine which subnets can
actually communicate through public IPs. We also determine
the lists of subnets involved in the preﬁx-level veriﬁcation
using public IP preﬁxes, and subnets per maximally connected
subgraphs as explained in Section IV-C1. Additionally, we
ﬁlter all ‘orphan’ subnets, as they are not connected to any
other subnets or external networks.
In OpenStack, VMs and virtual networking resources are
respectively managed by Nova and Neutron services. The
corresponding conﬁguration data is then stored in Nova and
Neutron databases. Therefore, we mainly used SQL queries
to retrieve data for different tables in those databases. For
instance, VM ports, router interfaces, router gateways and
other virtual ports are collected from table ports in Neutron
database. Therein, we use both device owner and device id
ﬁelds to infer the type and afﬁliation relationship between
the virtual ports and their corresponding devices. The packet
ﬁltering and forwarding rules are stored in neutron.routerrules,
subnetroutes, and securitygrouprules tables, where rules are
represented by destination-nexthop data pairs.
Parallelization of Reachability Veriﬁcation. In addition to
the single machine-based implementation, we have also ex-
tended TenantGuard to a parallel environment. The paralleliza-
tion is based on building groups of preﬁxes such that there is
no common path in the graph. This allows us to cache the
temporary binary tries to store results for routers matching,
which can be reused in other paths. Thus, we divide the list
of all preﬁxes into groups of preﬁxes that would be used as
destination preﬁxes and we create the same number of threads
as the groups, where each thread considers all possible preﬁxes
as sources.
The analysis controller is responsible for data collection,
graph construction, veriﬁcation tasks scheduling and distri-
bution. The controller obtains the topological view of the
compute worker cluster, its computation capacity and metrics,
such as the number of cores with CPU loads. Based on such
proﬁles, the task scheduler dynamically divides the veriﬁcation
computation into Java runnables, which will be distributed and
executed individually across the worker clusters through data
streaming in such a way that all the tasks are performed in
memory and no disk IO is involved. To avoid interference, the
divided runnable is not executed at the controller. The compute
worker cluster consists of nodes for performing tasks assigned
by the controller. The nodes discover each other automatically
through the conﬁguration in the same LAN. The result could
be returned directly to the caller, or written into the data
cache cluster in such a way that the data can be in-memory
distributed among the nodes. The latter is especially useful
when the size of data exceeds the capacity of single-machine
memory.
Integration to OpenStack Congress. We further integrate
TenantGuard into OpenStack Congress service [17]. Congress
implements policy as a service in OpenStack in order to pro-
vide governance and compliance for dynamic infrastructures.
Congress can integrate third party veriﬁcation tools using a
data source driver mechanism [17]. Using Congress policy
language that is based on Datalog, we deﬁne several tenant
speciﬁc security policies. We then use TenantGuard to detect
network isolation breaches between multiple tenants. Tenant-
Guard’s results are in turn provided as input for Congress
to be asserted by the policy engine. This allows integrating
compliance status for some policies whose veriﬁcation is
not supported by Congress (e.g., reachability veriﬁcation as
mentioned in Section II). TenantGuard can successfully verify
VM reachability results against security policies deﬁned inside
the same tenant and among different tenants. TenantGuard can
also detect breaches to network isolation. For example, we
test an attack in which, through unauthorized access to the
OpenStack management interface, the attacker authorizes some
malicious VMs to have access to the virtual networks from
other tenants. TenantGuard can successfully detect all such
injected security breaches providing the list of rules in the
routers that caused the breach.
VI. EXPERIMENTS
This section presents experimental results for performance
evaluation of TenantGuard on a single machine, on Amazon
EC2 [45] and using data collected from a real cloud. We also
perform a quantitative comparison with our baseline algorithm
and with NoD [27], which is the closest work to ours (as
detailed in Section II, most of the other works are either
designed for physical networks and not suitable for large
scale virtual networks, or they do not support the veriﬁcation
of all-pair reachability at the VM-level as targeted by our
solution). Note that, in our experiments, the baseline algorithm
is not brute force but already an optimized algorithm that uses
efﬁcient data structures, mainly radix tries (although it lacks
the other optimization mechanisms of our ﬁnal solution, e.g.,
the three-step preﬁx-to-preﬁx approach detailed in Section IV).
A. Experimental Settings
Our test cloud is based on OpenStack version Kilo with
Neutron network driver, implemented by ML2 OpenVSwitch
and L3 agent plugins, which are popular networking deploy-
ments [12]. There are one controller node integrated with
networking service, and up to 80 compute nodes. Tenants’
VMs are initiated from the Tiny CirrOS image [12], separated
by VLAN inside the compute nodes, while VxLAN tunnels are
used for the VM communications across the compute nodes.
We generate two series of datasets (i.e., SNET and LNET)
to
for the evaluation. The SNET datasets represent small
11
Prefix−to−Prefix
Baseline Algo
NoD
8
6
4
2
)
s
(
e
m
T
i
12
9
6
3
)
s
(
e
m
T
i
0
100
300
200
400
# of VMs/Subnet
500
0
0
2,000
# of Rules/Router
4,000
6,000
(a)
(b)
)
s
(
e
m
T
i
50
40
30
20
10
0
0
5
10
15
19
# of Hops