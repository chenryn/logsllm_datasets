Condition
Sex
M Heart Disease
M Viral Infection
Middle M
F
Middle
F
Middle
F
Middle
Middle
F
F
Middle
F
Young
Young
F
Cancer
Cancer
Flu
Ulcer
Gastritis
Pneumonia
Gastritis
Pneumonia
Table 5: Patient Information 2
Disclose Nothing
  (*, *, *)
(*, *, Sex)
(*, Age, *)
(Marital, *, *)
(*, Age, Sex)
(Marital, *, Sex)
(Marital, Age, *)
(Marital, Age, Sex)
Figure 10: Traversing the Generalization Lattice
Note that at T1, which corresponds to the node (M arital,
∗, ∗), the rotation set of the original table contains one pos-
sible database state, i.e., the table given in Table 7. This
table does not satisfy the entropy l-diversity.
As a result, we will generate the ﬁnal disclosure table
based on T2, which corresponds to the generalization node
(M arital, ∗, ∗) as shown in Table 8. This delayed output
schema indeed protects the database state shown in Table
7.
5. RELATED WORK
The initial works [1, 3, 11, 16, 17] were concerned with
conducting data census, while protecting the privacy of sen-
sitive information in disclosed tables. Two approaches, data
swapping [10, 22, 27] and data suppression [18] were sug-
gested to protect data, but could not quantify how well the
data is protected. The work [9] gave a formal analysis of
the information disclosure in data exchange. The work [24,
4] showed that publishing data sets even without identi-
fying attributes can cause privacy breaches and suggested
a new notion of privacy called k-anonymity. Achieving k-
anonymity with the best data utility was proved to be NP-
hard [20]. A similar measure, called blending in a crowd
was proposed by [26]. The work [28] proposed a new gen-
eralization framework based on the concept of “personalized
anonymity.” In addition, many works, e.g., [8, 23, 24, 19,
25, 15], proposed eﬃcient algorithms for k-anonymity. The
work [2] discussed deﬁciency of k-anonymity as a measure of
privacy, and proposed an alternative property of l-diversity
to ensure privacy protection in the microdata disclosure, and
demonstrated that algorithms developed for k-anonymity
G; //a generalization lattice
x; //a current database state
l; //the l of Entropy l-diversity
01.Input: B; //a set of all sensitive attributes
02.
03.
04.
02.Output: T ; //the output disclosure schema for x
03.Var: D′,D∗,C; //subset of D
04.
05.Begin
06. Traverse G using the original sequence T to ﬁnd g1 ∈ G that satisﬁes l-anonymity;
07.
08.
Select a new sequence (g1, g2, . . . , gn′ ) from g1 up to the top point of G;
Let T ′ = (T1, T2, . . . , Tn), (n = n′ + 1) where
T ′; //element of T
(T1, T2, . . . , Tn−1) represents schema sequence based on
(g1, g2, . . . , gn′ ) and Tn represents that nothing is disclosed
If Ti = Tn Return Tn;
For every j from n down to i + 1;
09. Traverse T ′ to ﬁnd the ﬁrst Ti such that t(Ti, x) satisﬁes entropy l-diversity;
10.
11.
12.
13.
14.
15. Return Ti;
16.End
Return Tj;
End For;
If for every generalized group g in Tj, rs(g) does not satisfy Entropy l-diversity on Tj−1
Figure 9: Algorithm 5
Marital Age Sex
Condition
M
M
M
M
M
M
S
S
S
S
O
O
M
M
M
M
M
M
Y
Y
*
*
*
*
*
*
*
*
*
*
Viral Infection
Heart Disease
Cancer
Cancer
Flu
Ulcer
Gastritis
Pneumonia
Gastritis
Pneumonia
Name Marital Age
Alan
Old
Bob
Old
Clark
Diana
Ellen
Fen
Sex
M
M
Middle M
F
Middle
F
Middle
Middle
F
F
Middle
F
Middle
F
Young
Young
F
Condition
Cancer
Cancer
Flu
Ulcer
Viral Infection
Heart Disease
Gastritis
Pneumonia
Gastritis
Pneumonia
Grace
Helen
Grace
Helen
M
M
M
M
M
M
S
S
S
S
Table 6: Table for node (Marital, Age, *)
Table 7: Patient Information 2
can also be used for l-diversity. The prior work on l-diversity,
however, did not take into account that the disclosure algo-
rithm and sequence may be known to the adversary. As a
result, under such an assumption, the property of l-diversity
is no longer guaranteed, as we illustrated in Section 1.
In statistical databases (e.g., [21, 11, 13]) a typical prob-
lem is how to “safely” answer aggregation queries so that
sensitive data on individuals would not be disclosed. The
works [7, 6] addressed this problem by auditing and deciding
whether a new query can be answered based on the database
state and on previously answered queries. The works [7, 12,
14] considered the same problem in more speciﬁc settings of
oﬀ-line auditing and online auditing respectively. The work
[14] considered the knowledge contained in the decision al-
gorithm itself. However, the techniques suggested in [14]
are only applicable to a limited case of aggregation queries.
Furthermore, when deciding whether to answer a new query,
it only considers previously answered queries, but not the
database state itself. We believe that an extension of the
techniques developed in this paper can relax some of the
limitation in [14].
6. CONCLUSIONS AND FUTURE WORK
To the best of our knowledge, this is the ﬁrst paper that
studies the problem of maximal data utility while guaran-
teeing safety under the assumption that the adversary may
know the disclosure algorithm and sequence.
Many interesting research questions remain open. One
research question is how to extend the “local optimality”
property used in this paper to “global optimality”. This
includes ﬁnding good measures of data utility that would
deﬁne total (rather than partial) ordering on possible ways
to disclose data. Another research direction is using proba-
bilistic, rather than deterministic disclosure algorithms, and
the related extended notions of safety. We conjecture that
some of the complexity hurdles may be eliminated. For the
case of microdata disclosure and l-diversity in particular, a
question remains whether we can deﬁne conditions less re-
strictive than the notions of conservative p-safety and weak
optimality. Finally, extending our techniques to more gen-
eral settings beyond the setting of generalization sequences
is an interesting question that may be applicable to statis-
tical databases.
Marital Age Sex
Condition
M
M
M
M
M
M
S
S
S
S
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
Cancer
Viral Infection
Heart Disease
Ulcer
Cancer
Flu
Pneumonia
Gastritis
Pneumonia
Gastritis
Table 8: Final Disclosure Table
7. ACKNOWLEDGMENTS
This work is supported by NSF grants CT-0716567, CT-
0627493, IIS-0242237, and IIS-0430402 and by ARO grant
W911NF-07-1-0383. Jajodia was also supported by MITRE
Technology Program project 07MSR204. We thank the anony-
mous reviewers for their comments and kind suggestions.
8. REFERENCES
[1] A.Dobra and S.E.Feinberg. Bounding entries in
multi-way contingency tables given a set of marginal
totals. In Foundations of Statistical Inference:
Proceedings of the Shoresh Conference 2000. Springer
Verlag, 2003.
[2] A.Machanavajjhala, J.Gehrke, D.Kifer, and
M.Venkitasubramaniam. l-diversity: Privacy beyond
k-anonymity. In Proceedings of the 22nd IEEE
International Conference on Data Engineering (ICDE
2006), 2006.
[3] A.Slavkovic and S.E.Feinberg. Bounds for cell entries
in two-way tables given conditional relative
frequencies. Privacy in Statistical Databases, 2004.
[4] V. Ciriani, S. D. C. di Vimercati, S. Foresti, and
P. Samarati. k-anonymity. In Secure Data
Management in Decentralized Systems (edited by T.Yu
and S.Jajodia). Springer-Verlag, 2007.
[5] D.Kifer and J.Gehrke. Injecting utility into
anonymized datasets. In SIGMOD, 2006.
[6] D.P.Dobkin, A.K.Jones, and R.J.Lipton. Secure
databases: Protection against user inﬂuence. ACM:
Transactions on Database Systems (TODS),
4(1):76–96, 1979.
[7] F.Chin. Security problems on inference control for
sum, max, and min queries. J.ACM, 33(3):451–464,
1986.
[8] G.Aggarwal, T.Feder, K.Kenthapadi, R.Motwani,
R.Panigrahy, D.Thomas, and A.Zhu. k-anonymity:
Algorithms and hardness. Technical report, Stanford
University, 2004.
[9] G.Miklau and D.Suciu. A formal analysis of
information disclosure in data exchange. In SIGMOD,
2004.
[10] G.T.Duncan and S.E.Feinberg. Obtaining information
while preserving privacy: A markov perturbation
method for tabular data. In Joint Statistical Meetings.
Anaheim,CA, 1997.
[11] I.P.Fellegi. On the question of statistical
conﬁdentiality. Journal of the American Statistical
Association, 67(337):7–18, 1993.
[12] J.Kleinberg, C.Papadimitriou, and P.Raghavan.
Auditing boolean attributes. In PODS, 2000.
[13] J.Schlorer. Identiﬁcation and retrieval of personal
records from a statistical bank. In Methods Info. Med.,
1975.
[14] K.Kenthapadi, N.Mishra, and K.Nissim. Simulatable
auditing. In PODS, 2005.
[15] K.LeFevre, D.DeWitt, and R.Ramakrishnan.
Incognito: Eﬃcient fulldomain k-anonymity. In
SIGMOD, 2005.
[16] L.H.Cox. Solving conﬁdentiality protection problems
in tabulations using network optimization: A network
model for cell suppression in the u.s. economic
censuses. In Proceedings of the Internatinal Seminar
on Statistical Conﬁdentiality, pages 229–245.
International Statistical Institute, Dublin, 1982.
[17] L.H.Cox. New results in disclosure avoidance for
tabulations. In International Statistical Institute
Proceedings of the 46th Session, pages 83–84. Tokyo,
1987.
[18] L.H.Cox. Suppression, methodology and statistical
disclosure control. Journal of the American Statistical
Association, 90:1453–1462, 1995.
[19] L.Sweeney. k-anonymity: a model for protecting
privacy. International Journal on Uncertainty,
Fuzziness and Knowledge-based Systems,
10(5):557–570, 2002.
[20] A. Meyerson and R. Williams. On the complexity of
optimal k-anonymity. In ACM Symposium on
Principles of Database Systems (PODS), 2004.
[21] N.R.Adam and J.C.Wortmann. Security-control
methods for statistical databases: A comparative
study. ACM Comput. Surv., 21(4):515–556, 1989.
[22] P.Diaconis and B.Sturmfels. Algebraic algorithms for
sampling from conditional distributions. Annals of
Statistics, 1:363–397, 1998.
[23] P.Samarati. Protecting respondents’ identities in
microdata release. In IEEE Transactions on
Knowledge and Data Engineering, pages 1010–1027,
2001.
[24] P.Samarati and L.Sweeney. Protecting privacy when
disclosing information: k-anonymity and its
enforcement through generalization and suppression.
Technical report, CMU, SRI, 1998.
[25] R.J.Bayardo and R.Agrawal. Data privacy through
optimal k-anonymization. In ICDE-2005, 2005.
[26] S.Chawla, C.Dwork, F.McSherry, A.Smith, and
H.Wee. Toward privacy in public databases. In Theory
of Cryptography Conference, 2005.
[27] T.Dalenius and S.Reiss. Data swapping: A technique
for disclosure control. Journal of Statistical Planning
and Inference, 6:73–85, 1982.
[28] X.Xiao and Y.Tao. Personalized privacy preservation.
In SIGMOD, 2006.