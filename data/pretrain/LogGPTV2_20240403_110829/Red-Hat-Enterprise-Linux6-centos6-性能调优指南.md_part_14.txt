有关 tuned-adm 的详情请查看其 man page（man tuned-adm），或者《电源管理指南》，网址为
http://access.redhat.com/site/documentation/Red_Hat_Enterprise_Linux/。
7.3. 文文件件系系统统
7.3.1. Ext4 文文件件系系统统
ext4 文件系统是红帽企业版 Linux 5 中默认的 ext3 文件系统的扩展。现在最红帽企业版 Linux 6 中默认黑色
用 Ext4，同时支持到最大文件系统为 16TB，单一文件最大值为 16TB。它还去除了 ext3 中最多只能有
32000 个子系统的限制。
54
第 7 章 文件系统
注注意意
对于超过 16TB 到文件系统，我们建议您使用弹性高容量文件系统，比如 XFS。详情请查看
第 7.3.2 节 “XFS 文件系统”。
ext4 文件系统默认是大多数负载的最佳系统，但如果性能分析显示文件系统行为影响到性能，则可以使用以
下几个调节选项：
内内节节点点表表初初始始化化
对于超大文件系统，mkfs.ext4 进程要花很长时间初始化文件系统中到所有内节点表。可使用 -E
lazy_itable_init=1 选项延迟这个进程。如果使用这个选项，内核进程将在挂载文件系统后继续初始化
该文件它。可使用 mount 命令的 -o init_itable=n 选项控制发生初始化到比例，其中执行这个后台初始
化的时间约为 1/n。n 的默认值为 10。
Auto-fsync 行行为为
因为在重命名、截取或者重新写入某个现有文件后，有些应用程序不总是可以正确执行 fsync()，在重命
名和截取操作后，ext4 默认自动同步文件。这个行为与原有到 ext3 文件系统行为大致相同。但 fsync()
操作可能会很耗时，因此如果不需要这个自动行为，请在 mount 命令后使用 -o noauto_da_alloc 选项
禁用它。这意味着该程序必须明确使用 fsync() 以保证数据一致。
日日志志 I/O 优优先先权权
默认情况下，日志注释 I/O 比普通 I/O 的优先权稍高。这个优先权可使用 mount 命令的
journal_ioprio=n 选项控制。默认值为 3。有效值范围为 0-7，其中 0 时最高优先权 I/O。
其他 mkfs 和调节选项详情请参考 mkfs.ext4(8) 和 mount(8) man page，同时 kernel-doc 软件包的
Documentation/filesystems/ext4.txt 文件也有它到信息。
7.3.2. XFS 文文件件系系统统
XFS 是一个鲁棒、高度弹性单一主机 64 位日志文件系统。它完全基于扩展，因此可支持超大文件和文件系
统。XFS 系统可拥有的文件数量只受该文件系统中可用空间的限制。
XFS 支持元数据日志，这样可从崩溃中迅速恢复。XFS 文件系统还可以最挂载和激活时去除并放大碎片。另
外，红帽企业版 Linux 6 支持专门用于 XFS 到备份和恢复工具。
XFS 使用基于扩展到分配，并有大量分配方案可用，比如延迟分配和直接预分配。基于扩展到分配可提供更
多简洁、有效到方法跟踪文件系统中使用到空间，并通过减少碎片化和元数据使用到空间提高大文件性能。
延迟分配可提高将文件写入连续块组到机会，减少碎片化，提高性能。预分配可用于在程序事先知道它需要
写入的数据量到情况下完全防止碎片化。
XFS 提供卓越的 I/O 灵活性，方法是使用 b-tree 检索所有用户数据和元数据。检索中所有操作的对象计数增
长都继承基础 b-tree 的对数伸缩特性。有些 XFS 调节选项提供 mkfs 时的各种 b-tree 宽度，这样就可以改
变不同子系统的伸缩特性。
7.3.2.1. XFS 到到基基本本调调节节
通常默认的 XFS 格式和挂载选项对大多数负载都是最佳选择。红帽建议使用默认值除非具体配置更改可以对
文件系统负载有帮助。如果使用软件 RAID，mkfs.xfs 命令可自动使用正确到条单位和宽度自行配置以便
与硬件对应。如果使用硬件 RAID 就需要手动进行配置。
在大容量（多 TB）文件系统中建议使用 inode64 挂载选项，除非是使用 NFS 和传统 32 位 NFS 客户端
55
红帽企业版 Linux 6 性能调节指南
导出到文件系统需要对该文件系统到访问。
建议在经常修改或者迅速增长的文件系统中使用 logbsize 选项。默认值为 MAX（32 KB，日志条单位），
同时最大值为 256 KB。建议最有大量修改的文件系统中使用 256 KB。
7.3.2.2. XFS 的的高高级级调调节节
更改 XFS 参数前，您需要理解为什么默认 XFS 参数会造成性能问题。这包括理解您的程序在做什么，以及
该文件系统如何应对那些操作。
可观察到的性能问题可以通过一般由文件碎片或者文件系统中到资源限制造成的调整修正或者减少。处理这
些问题有不同的方法，但在有些情况下修复问题需要修改程序配置，而不是修改文件系统配置。
如果您以前没有处理过这个进程，建议您咨询您到本地红帽支持工程师。
优优化化大大量量文文件件
XFS 引入文件系统可以拥有的文件数随机限制。通常这个限制会高到根本无法达到的高度。如果您知道默认
限制无法满足未来的需要，您可以使用 mkfs.xfs 命令增加可使用的内节点文件系统空间的百分比。如果您
在创建文件系统后达到文件限制（通常在尝试创建文件或者目录时出现 ENOSPC 错误信息，即使有可用空
间），您可以使用 xfs_growfs 命令调整该限制。
最最单单一一目目录录中中优优化化大大量量文文件件
文件系统的目录块是固定的，且无法更改，除非最初使用 mkfs 格式化。最小目录块时文件系统块大小，默
认为 MAX（4 KB，文件系统块大小）。通常没有理由减少目录块大小。
因为该目录结构是基于 b-tree，更改块大小影响每个物理 I/O 可检索或者修改的命令信息量。目录越大，在
给定块大小的每个操作需要的 I/O 就更多。
但当使用较大的目录块时，相比使用较小目录块到文件系统，同样的修改操作可能要消耗更多的 CPU。就是
说相比小目录，大目录块的修改性能较差。当目录达到 I/O 的性能-限制因数，大块目录性能更佳。
默认配置的 4 KB 文件系统块大小和 4 KB 目录块大小是最多有 1-2 百万条目，每个条目名称最 20-40 字节
之间到目录到最佳选择。如果您的文件系统需要更多条目，更大的目录块以便有更佳性能，则 16 KB 块大小
时有 1-10 百万目录条目文件系统的最佳选择，64 KB 块大小是超过 1 千万目录条目到文件系统的最佳选
择。
如果负载使用随机目录查询而不是修改（即目录读取比目录写入更常用或者重要），那么以上增加块大小的
幅度就要减少一个数量级。
并并行行优优化化
与其他文件系统不同，XFS 可以最非共享对象中同时执行很多种类的分配和取消分配操作。扩展的分配或者
取消分配可同时进行，即可在不同的分配组中同时进行。同样，内节点的分配和取消分配也可以同时进行，
即同时进行的操作影响不同的分配组。
使用有多个 CPU 的机器以及多线程程序尝试同时执行操作时分配组的数量就变得很重要。如果只有 4 个分
配组，那么可持续的、平行元数据操作将只限于那四个 CPU（该系统提供的并发性限制）。对小文件系统，
请确保该系统提供的并发性支持分配组的数量。对于大文件系统（10TB 以上），默认格式化选项通常可生
成足够多的分配组以避免限制并发性。
应用程序必须意识到限制点以便使用 XFS 文件系统结构中固有的并行性。不可能同时进行修改，因此创建和
删除大量文件的应用程序应避免最一个目录中保存所有文件。应将每个创建的目录放在不同的分配组，这样
类似哈希文件的计数就可以最多个子目录中提供比使用单一大目录更灵活的存储形式。
使使用用扩扩展展的的属属性性优优化化程程序序
56
第 7 章 文件系统
如果内节点中有可用空间，则 XFS 可以直接在内节点中保存小属性。如果该属性符合该内节点的要求，那么
可以最不需要额外 I/O 检索独立属性块的情况下检索并修改它。内嵌属性和外部属性之间的性能差异可以简
单归结为外部属性的数量级要低。
对于默认的 256 字节内节点，约有 100 字节属性空间可用，具体要看也保存最内节点中的数据扩展指针
数。默认内节点大小只在保存少量小属性时有用。
在执行 mkfs 时增加内节点的大小可以增大用来保存内嵌属性的可用空间量。512 字节的内节点约可增加用
于保存属性的空间 350 字节，2 KB 的内节点约有 1900 字节的空间可用。
但对于每个独立可以保存到内嵌书香则有一个大小限制：即属性名称和值占用空间最多为 254 字节（即如果
属性的名称长度和值长度都在 254 字节以内则为内嵌属性）。超过这个限制则会将属性强制保存为外部属
性，即使在该内节点中有足够到空间保存所有属性。
持持续续元元数数据据修修改改优优化化
日志的大小时决定可持续元数据修改等级的主要因素。日志设备是循环使用的，因此最可以覆盖 tail 命令的
结果钱，必须将日志中的所有修改写入磁盘的实际位置中。这可能会涉及大量寻求写入所有脏元数据的操
作。默认配置会让日志大小与文件系统总体大小成比例，因此在大多数情况下不需要调整日志大小。
小日志设备可导致非常频繁的元数据写回操作，即日志会一直从结尾写入以便释放空间，会经常将如此频繁
修改的元数据写入磁盘，导致操作变缓。
增加日志大小会增加从结尾处 push 事件的间隔。这样可以更好地聚合脏元数据，形成更好的元数据写回模
式，减少频繁修改的元数据的写回。代价是较大的日志需要更多内存方可跟踪所有内存中突出的修改。
如果您的机器内存有限，大日志就没有好处，因为内存限制可导致元数据写回延长抵消了释放大日志带来的
好处。在这些情况下，通常较小的日志比较大的日志性能更好，因为缺少空间的日志元数据写回比内存重新
回收形成的写回更有效。
您应该永远都保持将日志与包含该文件系统的设备底层条单位同步。mkfs 命令可自动为 MD 或者 DM 设备
完成此功能，但如果是硬件 RAID 则需要手动指定。设定这个功能目前可以避免在磁盘写入修改时所有可能
的由于未同步 I/O 以及后续读取-修改-写入操作造成的日志 I/O。
通过编辑挂载选项可进一步提高日志操作性能。增大内存嵌入的日志缓存（logbsize）的大小可增加写入
日志的更改速度。默认日志缓存大小为 MAX（32 KB，日志条单元），且最高可达 256 KB。通常该数值越大
性能越快。但如果是在 fsync 负载较重的环境中，小日志缓存比使用大条单元的大缓存速度明显快很多。
delaylog 挂载选项也可以改进不变的元数据修改性能，方法是减少日志更改次数。它通过在将其写入日志
前整合每个内存更改：频繁修改的元数据是阶段性写入日志，而不是每次修改时都写入。这个选项增加了跟
踪脏元数据的内存用量，同时也增加了崩溃发生时可能损失的操作量，但可以将元数据修改速度和延展性提
高一个等级。使用这个选项不会在使用 fsync, fdatasync 或者 sync 时减少数据或者元数据完整性，从
而保证可以将数据和元数据写入磁盘。
7.4. 集集群群
集群的存储可为集群中的所有服务器提供一致的文件系统映像，让服务读取和写入单一文件或者共享的文件
系统。这样可以通过限制类似在一个文件系统中安装和为程序打补丁的方法简化集群管理。集群范围内的文
件系统还不需要程序数据的冗余副本，这样也简化了备份和系统恢复的过程。
红帽高可用性附加组件除提供红帽全局文件系统 2（单行存储附加组件）外还提供集群的存储。
7.4.1. 全全局局文文件件系系统统 2
全局文件系统 2 是自带的文件系统，可直接与 Linux 内核文件系统互动。它可允许多台计算机（节点）同时
分享集群中的同一存储设备。GFS2 文件系统一般采用自我调节，但也可以手动调整。本小节列出了尝试手
57
红帽企业版 Linux 6 性能调节指南
动调节性能时应注意的事项。
红帽企业版 Linux 6.4 引进了 GFS2 中改进文件系统碎片管理的方法。在红帽企业版 Linux 6.3 或者之前的版
本中生成文件时，多个进程同时写入多个文件很容易造成碎片化。这个碎片化可让系统运行缓慢，特别是在
有超大文件的负载时。而使用红帽企业版 Linux 6.4，同时写入的结果是产生较少的文件碎片，并籍此获得更
好的性能。
虽然红帽企业版 Linux 中没有用于 GFS2 的碎片清除工具，您可以使用 filefrag 工具，通过文件碎片工具识
别它们，将其复制到临时文件中，并重新命名该临时文件以替换原始文件，这样就可以清除碎片。（只要写
入是按顺序进行的，这个步骤还可以用于红帽企业版 Linux 6.4 以前的版本。）
因为 GFS2 使用全局锁定机制，可能会需要集群中节点间的通讯，当将您的系统设计成可避免这些节点间文
件和目录竞争时即可获得最佳性能。这些可避免竞争的方法为：