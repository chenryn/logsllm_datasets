browser proﬁling
methods can be used to learn whether a particular
extension is installed [29]. However, measuring these
effects is out of scope of this work.
6.3 Malicious mix and CoverUp server
The bi-directional channel, hence the chat, in our proto-
type requires to trusts the mix server and the CoverUp
server. For efﬁciency reasons, the mix server directly
learns the intended recipient of a chat message. This
trust assumption can be removed by introducing a bi-
directional broadcast:
the requests of all participants
(voluntary and involuntary) would be broadcast to all
other participants,
letting the involuntary participants
send garbage. Such a bi-directional broadcast would,
however, reduce the uplink rate by a factor of 1/n2, with
n being the number of participants.
A malicious CoverUp server could serve involuntary
participants malicious JavaScript code, which opens var-
ious attack vectors. Against attackers that do not have
physical access to the CoverUp server, one could in
principle defend by utilizing trusted components on the
server side (e.g., Intel SGX or ARM Trustzone) to ensure
that the correct JavaScript code is served even if the rest
of the server is compromised. Alternatively, the exten-
sion could check byte for byte whether all messages from
the CoverUp server are as expected and, if not, the ex-
tension would not do anything. We decided not to imple-
ment this variant, as it incurs high delays and increases
the timing leakage.
7 Timing leakage experiments
This section experimentally evaluates the timing leak-
age of CoverUp. For the evaluation we used 26 systems
running Windows Server 2012 operating system. Sec-
tion 7.1 describes the experimental set-up. Section 7.2
inspects the effects of adding any noise after the mea-
surement is done. Section 7.4 proves an upper bound
for distinguishability and Section 7.5 discuss CoverUp
privacy evaluation under circumstances such as noise vs.
leakage and noise vs. observations. Section 7.6 draws
conclusive remarks of the timing leakage experiment.
7.1 The experimental set-up
The goal of the experiments is to measure the leakage
from the timing delays of CoverUp. To simulate realistic
scenarios, we set up the involuntary and both kind of vol-
untary participants on 26 identical systems running Win-
dows Server 2012 equipped with Intel Xeon E3-1245 3.4
GHz CPU and 16 GB of main memory. All the systems
also run Apache tomcat server with the CoverUp and mix
server deployed. The involuntary version of the test set-
up only has running Mozilla Firefox browser while for
the ﬁrst scenario the later one executes identical browser
and CoverUp’s external application to receive the feed.
To simulate the second scenario (the chat) the voluntary
participant’s browser additionally runs our extension and
a python script in background which sends automated
chat data to the browser extension utilizing native mes-
saging (via STDIO). All of the communications between
the server and the browser are executed on loop-back net-
work network interface. We use tshark [10] to capture all
such network trafﬁc on loop-back interface. We compare
the distributions of timing traces produced by a volun-
tary participant (both chat and feed) to the distribution
produced by an involuntary participant. All the experi-
ments are conducted on these 3 set-ups to investigate the
timing leakage from the browser due to the browser ex-
tension and the external application.
Reﬂecting the attacker model. The attacker model
(see Section 3) is reﬂected in our experiments by taking
timing traces from the perspective of the attacker who
has access to all network trafﬁc. Therefore, we cap-
tured the trafﬁc on a corresponding network interface.
As a network-level attacker can change the TCP ﬂag for
timestamps and compel the victim’s operating system to
add timestamps to the TCP headers [9], we conduct all
measurements in the settings where the browser, the en-
try server, the CoverUp server, and the mix server resides
on a same system. The network trafﬁc dump contains
reliable timestamps with a resolution of less than 1 mi-
croseconds. Our attacker model also assumed that the
attacker has no control over the operating system hence
can not determine the existence of the CoverUp external
application or the browser extension.
Types of measurements. We have proﬁled the execu-
tion time of the browser extracted from the TCP time
stamp of the network packets dispatched by the browser
in two separate measurements: the initial loading time
measurement and the periodic execution measurement.
The loading time measurement simulates the case
where the browser requests CoverUp’s iframe and the
browser performance in composing its context internally.
We simulate this case by forcing the iframe to refresh on
the entry server page in the browser. Before CoverUp’s
snippet is refreshed,
it already has requested a feed
packet from the mix server and has received an answer.
In the corresponding network trafﬁc dump, we compute
the timing difference between the response of the initial
iframe html source request to its ﬁrst droplet request to
the mix server, because waiting for the ﬁrst droplet re-
quest after the iframe request enables loading the exten-
sion’s content script. This timing difference captures any
distinguishing feature produced by the extension.
The periodic measurement models the scenario where
the voluntary and involuntary participant load the iframe
once, followed by one feed request to the server and
one response from the mix server. In the network trafﬁc
dump, we look for the timing difference for two contigu-
ous feed requests from the browser.
Evaluation details. All the experiments are performed
on 26 identical system running Windows Server 2012
standard edition. The systems are equipped with In-
tel Xeon E3-1245 3.4 GHz CPU and 16 GigaByte of
main memory. We deployed CoverUp and mix server
on Apache Tomcat web server. We also prepare a cus-
tom SSL certiﬁcate and conﬁgure Tomcat to use SSL all
the time (strict transport layer security). All of the com-
munications between the server and the browser are ex-
ecuted on loop-back network network interface. We use
tshark [10] to capture all such network trafﬁc on loop-
back interface. To obtain the time differences between
subsequent requests, we use the time stamp of the ﬁrst
TCP packet (carrying TLS application data) for each re-
quest and answer and simply subtract them. To avoid
any caching artifacts, we disable the support for HTTP
request caching on the server side completely.
7.2 The timing without additional noise
CoverUp does not send the droplet requests at ﬁxed time
but rather draws delay noise from a gaussian distribution
and accordingly noises the time at which the requests are
11
Figure 4: Distribution of timing traces (without additional
noise) of 26 windows server systems running periodic and load-
ing testing. Periodic test consists of around 12.9 million timing
traces while the loading test around 600K (voluntary chat and
involuntary both).
sent. To simplify and accelerate testing, however, the ex-
periments do not draw this noise. We added the noise
artiﬁcially afterwards. We measured the independence
of generating noise inside the experiment and adding it
after the experiment. Section 7.3 elaborates on this inde-
pendence.
For the sake of illustration, we brieﬂy describe the his-
tograms of the timing traces without the additional noise.
Figure 4 depicts the differences in the measurements of
our implementations on all the systems. The loading
process invokes much more computational power and
is therefore more noisy, as opposed to sending and re-
ceiving a simple network packet as in the periodic case,
the distribution in the loading one have a wider range.
Remarkable here is that in the periodic case the distri-
butions for interactive and non-interactive requests look
very similar. The mean and median differ less than a mi-
crosecond.
7.3
Independence of additional noise
In the analysis of the timing leakage, we simulated the
additional noise by adding it to the measurement result.
To justify this procedure, we conducted separate exper-
iments, similar to the periodic scenario, but instead of
waiting 1000ms for the next droplet request, we drew in
JavaScript a uniformly distributed random number (using
Math.random()) and expanded it in an afﬁne way such
that an interval ranges from 200ms to 1800ms. Addi-
tionally, we stored each of the drawn random numbers
together with an epoch time stamp. Later in the analysis
Figure 5: Statistical Independence using uniform noise: Dis-
tance: 1.8%
Figure 6: Attacker’s accuracy vs the width of the noise distri-
bution, for 20’000 periodic and 1’000 loading observations if
only feed is enabled and 10’000 periodic and 1’000 loading ob-
servations if chat is enabled. The noise distributions are half-
gaussian distributions with mean 0 and a very high standard
deviation (10 times the width of the noise).
step, we subtracted the corresponding random number
from the network dump measurement. This procedure
produced measurements artifacts, caused by the time res-
olution of our system (which lies slightly under 1us).
As we are only interested in the fact whether artiﬁcially
adding the noise after the experiment is independent of
directly adding the additional noise in the experiments,
we clustered close histogram bars that are not separated
by a signiﬁcant gap.
Figure 5 shows the resulting distribution. The statisti-
cal distance of these two distributions is 1.8% which is
an acceptable value.
12
Periodic test1000 time (ms)Density9989991001100202468Voluntary InvoluntaryLoading test2020Density20002010203020400.00.20.40.60.8Voluntary Involuntarytime (ms)0.300.240.180.120.060.000.060.120.180.24ms0.00.10.20.30.40.50.6DensityNo Noise added0.300.240.180.120.060.000.060.120.180.24ms0.00.10.20.30.40.50.6DensityNoise added in JavaScript subtracted113612244688166316600widthofthenoisedistribution[s](log-scale)0.50.520.540.560.580.60.620.640.660.680.7attacker’saccuracyLoadingFeedChatPeriodicFeedChatof 100 microseconds.
7.5 Evaluating privacy
We evaluate the privacy that different noise distribu-
tions of request delays yield against various amounts
of attacker observations. The timing leakage is up-
per bounded by the sum of the leakage caused by
loading of the JavaScript (up to requesting the ﬁrst
droplet) and by subsequent periodic requests. Because
our two experiments take place at two different stages
of CoverUp’s procedure, we can capture these leak-
ages separately and quantify them separately, as well.
We call the accuracy of an attacker that can distin-
guish the two loading experiments the loading accu-
racy and the accuracy of an attacker that can distinguish
the two periodic experiments as periodic accuracy. The
bound for the attacker’s accuracy = loading accuracy +
periodic accuracy− 0.5.
Leakage vs. noise. Figure 6 plots the attacker’s accu-
racies vs width of the noise distribution, with a log-scale
x-axis. As noise distribution, we use a very wide half-
Gaussian distribution with mean 0 which we truncate af-
ter n seconds. This width n of the noise distribution (x-
axis on Figure 6) also determines the standard deviation
that we use: we use 10n as standard deviation. In this
way, we effectively obtain almost a uniform distribution.
Figure 6 shows that the width of the noise is inverse
proportional to the accuracy of the attacker. Moreover,
it shows for feed-only deployment of the system the at-
tacker’s accuracies for up to 20’000 observations and, for
the system with chat the attacker’s accuracies to 10’000
observations. For the sake of illustration, we will se-
lect a few numbers that yield strong privacy. The ﬁgure
indicates that if only the feed application is deployed,
for a width of the noise of 40s the loading accuracy is
≤ 50.2% and with a width of 60s the periodic accuracy
is ≤ 50.9%. If the chat is additionally enabled and with
a noise width of 600 seconds, the loading accuracy is
≤ 53.2% and, with a width of 60 seconds the periodic
accuracy is ≤ 53.1%.
The ﬁgure shows that even less noise would achieve
reasonable privacy guarantees. For the chat case, 200s
and 1’000 loading observations would yield a loading
accuracy of less than 60%, and even the periodic noise
could be reduced 30s while having for 10’000 periodic
observations a periodic accuracy of ≤ 55%.
For feed + chat, a loading noise of 10 minutes (5 min-
utes expected time) is still practical for a high-latency
chat, as the average visiting time of an e-commerce user
around 10.3 minutes [1, 3]. With 10 minutes of load-
ing noise (i.e., 5 minutes expected initial request time),
Figure 7: The accuracy of an attacker for periodic and loading
leakage, with the following noise widths (with expected request
time): feed periodic 60s (30s), chat periodic 60s (30s), feed
loading 40s (20s), chat loading 10 min (5 min).
7.4 Attacker accuracy upper bound
Estimating the attacker’s pre-knowledge about the de-
lays of a user is challenging.
In principle, we cannot
exclude that a very strong (e.g., state-funded) attacker
runs measurement experiments on many combinations
of hardware, browsers, and operating systems. These
measurements might be usable by a malicious website
to ﬁngerprint the operating system and the hardware, as
indicated shown in a recent work [29]. Therefore, our
analysis includes a minimal privacy bound against an
overly strong attacker that extensively measured the tim-
ing leakage for the system of the eavesdropped partici-
pant (in the sense of Deﬁnition 1). We then compute the
accuracy of the optimal attacker with this pre-knowledge
as the statistical distance (also called the total variance).
Lemma 3 in Appendix 15 recalls the textbook-proof that
the statistical distance is an upper bound on the advan-
tage (= 2∗ (accuracy− 0.5)) of any (i.e., also potentially
unbounded) attacker.
We over-approximate the attacker’s advantage δi af-
ter i subsequent runs of CoverUp as follows: δ0 =
statistical distance after adding noise,δi = δi−1 + (1 −
δi−1) · δ0,. Appendix 16 proves this over-approximates
the attacker’s advantage. Recall that all our graphs
show the attacker’s accuracy, which can be computed as
advantage/2 + 0.5. Moreover, for computing this accu-
racy, we use 100 microseconds instead of 1 microsecond,
since it turns out that after convolution with the noise dis-
tribution there is virtually no advantage to use 1 instead
13
0.00.20.40.60.81.0numberofobservations0.00.20.40.60.81.0attacker’saccuracy0400080001200016000200002400028000320000.500.520.540.560.580.60PeriodicFeedChat050010001500200025003000350040000.500.520.540.560.580.600.62LoadingFeedChatour high-latency chat would still be able to send 10 re-
quests in the expected case. The size of the payload can
be increased without violating the privacy of the volun-
tary participants; a single request and response can be
used to send and receive high amount of new messages.
Leakage vs. number of observations. Figure 7 shows
the development of the upper bound on the attacker’ ac-
curacy if the number of observations increases. For these
graphs, we assumed the following request delay noise
widths (with expected request time): feed periodic 60s
(30s), chat periodic 60s (30s), feed loading 40s (20s),
chat loading 10min (5min). The leakage increases lin-
early with an increasing number of observations. The
ﬁgure shows that with these widths even a 3 times more
active voluntary chat participant with 30’000 observa-
tions could still count on ≤ 60% periodic accuracy and
≤ 60% loading accuracy.
7.6 Privacy conclusion
Recall that the usage pattern of a voluntary participant is
restricted to the visiting behavior of involuntary partici-
pants, as discussed in Section 6.2. While this usage pat-
tern depends on the speciﬁc service that the entry server
provides, we assume the usage pattern for a popular e-
commerce site. As shown in [1, 3] each visit should not
be longer than 10.3 minutes. We stress that this usage
pattern can be controlled and recommended or even en-
forced by the extension or the external application. Ad-
ditionally, we envision a button to set the extension ac-
tive only when required by the user. This justiﬁes our
assumptions of a voluntary participants that visits and
utilizes the entry server 4 times per working day, stays
each time 10 minutes, and has 4 weeks of holidays per
year. In a deployment of feed-only application with noise
widths as above (loading = 40s, periodic = 60s), a year
worth of observations correspond to around 20’000 pe-
riodic observations and 1’000 loading observations (see
Section 6.2). These parameters results in an attacker’s
accuracy of ≤ 51.1%, which is only 1.1% better than
pure guessing. In a deployment of the full system (in-
cluding the chat) with widths as above (loading = 600s,
periodic = 60s), a year worth of observations correspond
to around 10’000 periodic and 1’000 loading observa-