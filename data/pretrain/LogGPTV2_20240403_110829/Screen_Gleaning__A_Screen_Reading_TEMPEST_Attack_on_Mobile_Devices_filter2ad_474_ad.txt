contrast between the background and the text. Reducing the
contrast leads to a less easily readable screen for the human
eye, but does not necessarily result in an emage that is more
difﬁcult to interpret. Exploratory experiments conﬁrmed that
our choice of background represents a challenging setting,
and that, if the attacker is lucky, the contrast between the
background and the message on the display of the phone might
actually make the attack easier.
VI. TESTBED
So far, we have introduced the screen gleaning attack and
shown its effectiveness in recovering a security code displayed
as a push message on the screen of a mobile phone. The attack
was carried out with technology representative of the current
state of the art. However, with time, we expect the quality of
the antenna and SDR to improve. Also, additional training data
and algorithmic advances will increase the accuracy of the deep
learning classiﬁer. These advances mean that screen gleaning
attacks can be expected to become increasingly dangerous,
and future work will be necessary to understand them and
develop countermeasures. To support this future work, we
have developed a testbed that enables the systematic test of
screen gleaning attacks under incrementally more challenging
attacker models. In this section, we describe the testbed, which
has also been released so that can be directly used by the
scientiﬁc community. The testbed consists of two parts, ﬁrst, a
deﬁnition of a set of images and a set of scales, and, second,
a speciﬁcation of the attacker model, in terms of the model
dimensions and the parameterization of the dimensions. We
also report the results of experiments validating the testbed.
A. Testbed Images
We base our testbed on the eye chart used by eye doctors to
test vision acuity [14], and for this reason, we call it the eye
chart testbed. Most people are familiar with the experience
of a vision test. The eye chart measures someone’s vision
by determining the minimum level of detail that the person’s
eyes can distinguish at a given distance. Likewise, our testbed
uses eye chart
letters to determine the minimum level of
visual detail that a screen gleaning attack can recover given a
particular attack setup.
The testbed is deployed by ﬁrst specifying an attacker
model and creating an attack setup based on that model. Then,
different scales are tested until it is possible to determine at
which scale the identity of the letter can no longer be recovered
by the attack.
The testbed deﬁnes 11 different scales. For the largest scale
(20×), the size of the letter is the maximum size that can be
ﬁt on the screen, with still leaving 10% of the letter width as
margins on the side. For the smallest scale, the letter appears
with a width of 1/20 of the largest scale. The relative sizes of
the testbed scales are illustrated on the top line of Figure 12,
using the letter C as an example. The font is the Sloan font
used for eye charts. We used the Creative Commons licensed
version, which is available on Github.2 The full letter set in
the testbed release is C, D, E, F, L, N, O, P, T, Z. The full set
of letters is tested as each scale.
The letters in an eye chart are chosen so that all the letters
in the set are equally easy to read. This ensures that for each
scale, the ability of the person to read the letters is related
to the scale, and not to the speciﬁc letters. By choosing to
use eye chart letters, we extend this property to our test set.
Different eye charts use different fonts and different letter
2https://github.com/denispelli/Eye-Chart-Fonts/blob/master/README.md
10
CCCCCCCCCCCDimension
Message
Message
appearance
Attack
hardware
Device
proﬁling
Computational
resources
Description
The symbol set (e.g., 0-9, a-z) must be
deﬁned. If the symbols are not all
equiprobable, the prior probability of each
symbol must be deﬁned.
Any constraints that will be imposed on the
scale of the message or on font types must be
deﬁned. Assumptions about the pattern of the
background and the brightness of the screen
must be deﬁned.
The antenna and the SDR must be speciﬁed.
Any assumptions on the position of the
antenna must be deﬁned (positions range from
touching the phone, to under the table, to
across the room).
The conditions on device access must be
deﬁned (attacker has access to the device to be
attacked, to devices of an identical model, to
devices of the same make). The ability of the
attacker to cause a certain image to appear on
the accessible devices must be deﬁned, along
with the amount of time that the attacker can
count on having access. After the number and
nature of devices at the attackers disposal is
deﬁned, the number and length of the sessions
that the attacker can record on each device
must also be speciﬁed.
Deﬁne the amount of time and computational
resources available for training, and also for
the attack itself (i.e., after the model is trained
recovering the message from the emage).
TABLE VII: Five-dimensional attacker model: Parameter set-
tings to specify when designing an attacker model for testing
with the testbed.
sets. We choose our testbed based on the fact that this set
is currently in widespread use.
It is natural to wonder why we use the limited set of
characters used in an eye chart instead of using a larger set
of alphanumeric characters. The answer is that the testbed
is designed to detect the ability of an attack to discriminate
and recover visual detail. Using eye-chart characters means
that the results of the testbed reﬂect the discernability and
interpretability of other forms of visual information as well,
for example, symbols or images displayed on the phone screen,
and not just text.
Figure 12 depicts emages that were captured with the setup
described in Section IV. It can be seen that they move from
being uninterpretable to the human eye on the left to inter-
pretable on the right. This property of the testbed has the goal
of ensuring that the testbed can measure interpretability with
other attack setups. We are especially interested in supporting
the investigation of attack setups where the signal might be
very weak, for example, as the antenna is moved further from
the phone. For a very weak signal, the larger letters will
become uninterpretable to the human eye. This will allow
researchers to quantify the effectiveness of a machine-learning
attack under the conditions of a weak signal. If researchers
adopt the same standard testbed, the measurements made can
be more easily compared in a fair manner.
Again, it is important to note that although our testbed
consists of letters, it does not speciﬁcally assess the ability of
an attack to recover written text consisting of letters. Instead,
it assesses the ability of the attack to recover a message that
has a certain level of visual detail. Just like the eye chart tests
general visual acuity, and not just reading, our testbed tests
the acuity of a particular attack to recover information in the
visual form displayed on the phone screen, and not just letters.
B. Parameterization of the Attacker Model
Here, we describe the parameterized attacker model. It
contains ﬁve dimensions, message, message appearance, attack
hardware, device proﬁling, and computational resources. Each
of these dimensions has several parameters. In order to have
a fully speciﬁed attack mode, speciﬁcations must be made for
each of the parameters. The parameters can be considered to
correspond to the values of design decisions. The ﬁve dimen-
sional model along with the parameters for each dimension are
described in Table VII. Note that in the security code attack
we present in Section III, we use the same ﬁve dimensions in
the attacker model (Table I).
This parameterized attacker model forms the basis for the
attack setup. It has two purposes. First, it ensures that when
the testbed is being applied, the attacker model that is being
assumed is fully described, i.e., no detail is left out. Second, it
allows researchers to systematically make the attack stronger.
The attack strength can be increased by increasing the values
of any or all the parameters. In this way, the attacker model
guides researchers in discovering increasingly strong attacks.
The dimensions of the attacker model can be also used to guide
the development of countermeasures.
C. Validating the Eye Chart Testbed
In this section, we validate the eye chart testbed with
the demonstration of an attack. The attack uses the same
Attack hardware and Computational resources as the Security
Code attack demonstrated in Section III. The Message and the
Message appearance are derived from the eye chart testbed.
The Device Proﬁling is also the same, and the speciﬁcs of
data collection are explained in the next section.
1) Data Collection: We collect a total of 12 sessions,
among which two sessions (sessions 1 and 2) have 50 samples
for each of 11 classes of letters at each of 10 scales, and the
rest 10 sessions have 15 per class per scale. For inter-session
evaluation, we use sessions 11 and 12 as testing sets for all the
experiments. Session 1 plus 2 are used as the initial training
set, and are gradually enlarged by including two more sessions
each time, resulting in ﬁve different training sets with increased
size, denoted as Training 1, 2, 3, 4 and 5, as illustrated in
Figure 13. Training 5 has the most data with 24200 samples.
2) Experiments: Similar to the security code attack, we use
the following partitions: 80% training, 10% validation and 10%
testing. We use the ResNet-18 model [35] as our classiﬁcation
model, and we train on ﬁve training sets individually until
convergence. Figure 14 shows that including more training ses-
sions generally lead to performance improvement in the inter-
session case. For the second session, we notice an accuracy
11
Fig. 13: Train/test splits speciﬁed in the inter-session case of
our eye chart letter classiﬁcation task, where the training set
is gradually enlarged by including more sessions, and the test
set is ﬁxed with two sessions.
Fig. 14: Inter-session accuracy in our eye chart letter classiﬁ-
cation task. The two bars for each training set represent two
different test sessions.
drop when including more data from Training 2 to Training 3,
which can also be explained by the fact that the data quality
of different sessions of data could impact the performance.
Figure 15 shows the confusion matrix of the classiﬁcation
accuracy with respect to different classes. We can observe
that accuracy differs for different letters. Table VIII shows
the results at 11 different scales. We could observe that the
accuracy of the letters at moderate scales (e.g, 7, 8 and 9)
is comparatively higher than the others. Without surprise, the
smallest scale has the lowest accuracy. However, what we
found also interesting is that accuracy with respect to scale
1 is also low. We suspect that it is because of the receptive
ﬁeld of the model we chose. More detailed results per class
per scale can be found in Figure 16.
VII. COUNTERMEASURES
In our setup, the target device has no extra protection
beyond the common design features of commercial devices.
12
Fig. 15: Confusion matrix of the classiﬁcation in our eye chart
letter task.
Fig. 16: Classiﬁcation results of our eye chart letter task with
respect to different classes and scales.
As a step towards improving the protection of the device, we
discuss possible countermeasures that could possibly mitigate
the danger of a potential screen gleaning attack.
A. Hardware-Based Approaches
Screen gleaning attacks would be made difﬁcult by using
a shielding technique. Shielding a cable consists of wrapping
the center core of the cable that transmits an electric signal by
a common conductive layer. The shield acts as a Faraday cage
inside the cable, blocking electromagnetic waves. The resulting
electromagnetic leakage is lowered, decreasing the SNR of the
signal. Several standard cables (e.g., coaxial cable, twisted pair
cable) are shielded to reduce its electromagnetic perturbations
and emanations. However, this technique comes at an extra
cost and increases the cable dimension. For this reason, ﬂexible
ﬂat cables inside small electronics with a display often lack a
protective shield, and it is not trivial to add one.
A metallic protective case would also act as a shield
for electromagnetic radiation, preventing attacks that measure
the signal emitted from the back of the phone, but every
telecommunication signal would also be perturbed.
B. Communication-Based Approaches
Another countermeasure against screen gleaning, similar
to the method used for pay-TV, could be to encrypt the signal
between the graphical unit and the screen. The core idea is
to share a cryptographic key between the two entities and
encode the video stream using a cipher. As a result,
the
leaked information by the transmitted signal will become more
difﬁcult to interpret by the attacker, who does not have the
(S9, S10)(S7, S8)Training 4(S5, S6)(S3, S4)(S1, S2)Training 1Training 2Training 3Training 5CCCCCCCCD...CCC......CCDCCCCCCCCD...CCC......CCDCCCCCCCCD...CCC......CCDTEST(S11, S12)CCCCCCCCD...CCC......CCDTraining 1Training 2Training 3Training 4Training 5Training set020406080100Accuracy (%)10.022.828.540.579.410.526.211.317.361.3Scale
1
Acc. (%)
66.7
1.2
48.7
1.5
82.0
2
87.3
2.5
86.7
3
4
5
7
82.0
88.7
89.3
97.3
10
98.7
20
46.0
TABLE VIII: Accuracy with respect to 11 different scales in our eye chart letter classiﬁcation task.
key. This solution comes at a cost. Although some stream
ciphers could meet requirements for throughput and latency,
both the screen and the graphical unit would need extra logic
for encryption and decryption of the cipher and implement a
key establishment protocol to create a shared key when paired
together. Moreover, this countermeasure would be ineffective
against an attack targeting the screen itself during the rendering
(although this is a different attack, see [27]).
C. Graphics-Based Approaches
M. G. Kuhn in [47] introduces a cheap and efﬁcient coun-
termeasure against electromagnetic TEMPEST that consists of
a special font where the transmitted signal has been ﬁltered to
reduce the strength of the top peaks of its Fourier transform.
The resulting font appears visually quite blurry for a high-
resolution representation rendered on the screen but makes the
side-channel silent.
Another method that can be used as a countermeasure is
obfuscation. This obfuscation can either be introduced into the
background of the image using confusing patterns and colors
behind the text or by using a font with visually difﬁcult to
differentiate letters. However, obfuscation is often ineffective
against distinguishing methods based on machine learning and
may introduce difﬁculties for humans to read the original
image from the screen.
VIII. FROM TEXT TO IMAGE
it
Here we return to the discussion of different formulations
of the screen gleaning problem. As we stated earlier, in the
discrimination scenario,
the attacker knows a ﬁnite set of
messages that are possible and attempts to determine which
one actually occurred on the phone screen. The security code
recovery attack belongs to the discrimination scenario.
As the work on screen gleaning moves forward,
is
interesting to look at problems beyond recovering messages
built from symbol sets, such as security codes and written
words, but also at images. Screen gleaning of images can be
addressed within the reconstruction scenario, mentioned above.
In this scenario, the attacker has no prior knowledge of the
screen contents and attempts to reconstruct the screen exactly
as it appears to the human eye. The following is an example
of the reconstruction scenario: If the screen was displaying a
photo of a person, the goal of the attack would be to recover
that photo completely. Complete recovery requires that the
features of the person in the photo are clear, as needed for a
human viewer to identify the person, but also that the recovered
photo looks exactly like the original one including details of
the background and the lighting and coloring of the photo.
Screen gleaning of images can also be addressed within
a more general classiﬁcation scenario than the discrimination
scenario. The discrimination scenario is a type of classiﬁcation
scenario in which the attacker has access to information about
13
the complete set of possible messages. There exists another