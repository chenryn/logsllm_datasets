These subjects are observed with normal and justiﬁed ac-
cess patterns as grey edges with right-side objects. How-
ever, they are also allowed to access critical system ﬁles,
which are unjustiﬁed and over-permissive. Attackers can
exploit vulnerabilities in these subjects to compromise crit-
ical ﬁles via these access patterns.
In particular, without
prior knowledge of any vulnerabilities or attacks, SPOKE
identiﬁes mediaserver, which is the subject that was previ-
ously found having the notorious libstagefright vulnera-
bility [5] (CVE-2015-1538). Attackers can ﬁrst compromise
mediaserver with this vulnerability as a step stone, and
then use the over-permissive access patterns deﬁned by a
rule allow mediaserver ANONYMIZED_LABEL : file {ioctl
read write create getattr setattr append unlink link
rename open} to modify critical system ﬁles and eventually
control the enterprise device. This risky rule with other ones
have been conﬁrmed and removed by policy engineers.
6. DISCUSSION
Native functional tests and other knowledge inputs:
Currently, SPOKE mainly focuses on Android functional
3
Since the analyzed policy is currently used in real-world Android
devices, we are requested by the vendor to anonymize some speciﬁc
ﬁle names.
10
tests for applications and framework. However, functional
tests for native executable binaries can also be used to ex-
tract domain knowledge for pure native functionality in an
Android system. SPOKE can be enhanced with techniques
such as ptrace/ltrace and native library hooking to achieve
this feature, which we leave as future work. Other dynamic
analysis techniques can provide useful domain knowledge
as well. For example, dynamic taint analysis [18] can pro-
vide detailed information ﬂow of a series of access patterns.
Static analysis such as symbolic execution [33, 45] can iden-
tify code-level functionality and access patterns and provide
extra knowledge of how access patterns and control ﬂow are
aﬀected by speciﬁc inputs.
Data mining and machine learning possibilities: We
design an analysis engine in SPOKE to leverage the knowl-
edge base for policy rule justiﬁcation and attack surface
analysis. Apart from these, other data mining and machine
learning techniques can also be applied within the analy-
sis engine. For example, outlier/anomaly detection [22] can
ﬁnd suspicious or mistakenly deﬁned access patterns from
certain subjects or objects that are diﬀerent from the ma-
jority of the access patterns in the knowledge base. Bayesian
networks [19, 20] can also be applied for learning the rela-
tionship between access patterns and inferring whether a
new access pattern deﬁned by a new rule is likely to be jus-
tiﬁed or over-permissive.
User-based access pattern collection: As the SEAn-
droid policy is eventually deployed to user devices for ac-
cess control enforcement, human users can also be asked
to involve the testing and reﬁnement process of SEAndroid
policy development. With the user agreement of data col-
lection during testing (e.g., private data anonymization and
no deliberate malicious usage), access patterns representing
device’s daily use can be collected to help synthesize and
reﬁne policy rules. Existing user-based testing is already
available for pre-released Android applications (e.g., Google
Play Store Beta Testing [4]). We envision that SEAndroid
policy development can also beneﬁt from similar user beta
testings.
7. RELATED WORK
In general, SPOKE’s knowledge extraction platform is a
dynamic analysis system for Android. Plenty of research ef-
forts have been made in this ﬁeld. DroidScope [44] proposed
an emulation-based inspection to analyze both Java and na-
tive components of Android applications. CopperDroid [39]
also used QEMU and focused on system call analysis of An-
droid malware. TaintDroid [18] provided a dynamic taint
tracking system for information ﬂow analysis in Android. In
our case, we require the domain knowledge from real devices
since some security functionalities require hardware features,
and thus cannot use virtualization-based approach. Besides,
it is non-trivial and insuﬃcient to port previous techniques,
as we focus on a fundamental new problem of collecting do-
main knowledge for SEAndroid policy, which requires new
techniques speciﬁc for knowledge extraction.
Although SEAndroid is relatively new, SELinux has been
researched for years, such as SELinux policy analysis and
veriﬁcation [12, 21, 26, 36], policy comparison [15], policy vi-
sualization [43], policy information ﬂow integrity measure-
ment [24, 25, 40]. These work mainly analyzed SELinux ref-
erence policy itself, which has been reﬁned by the commu-
nity for years. In contrast, SEAndroid policy is fairly new
and under active development by vendors. It is necessary
to analyze SEAndroid policy together with the original do-
main knowledge to ensure the labels and rules deﬁned in the
policy are consistent with the real case. In addition, by col-
lecting and leveraging domain knowledge, SPOKE creates a
new dimension to policy development and analysis.
EASEAndroid [42] is a recent work that applied machine
learning to analyze large-volume access events collected from
user device logs to reﬁne SEAndroid policy. SPOKE is or-
thogonal to EASEAndroid. EASEAndroid focuses on the
post-deployment policy analysis to reﬁne the policy against
attacks in the wild. SPOKE focuses on the pre-deployment
analysis of the policy to bridge the knowledge gap for policy
engineers during policy development and analysis. SPOKE
can help policy engineers have better understanding and
analysis of the developed policy in the ﬁrst place before the
policy is deployed to user devices. Nevertheless, the knowl-
edge from both SPOKE and EASEAndroid can be shared
with each other to provide better analysis results.
8. CONCLUSION
SEAndroid policy development and analysis require do-
main knowledge.
In this paper, we presented SPOKE, a
knowledge engine that collects domain knowledge from func-
tional tests, and provides attack surface analysis through
policy rule justiﬁcation. We evaluated SPOKE using real-
world functional tests. SPOKE successfully collected de-
tailed domain knowledge.
It also revealed over-permissive
rules, helping policy engineers analyze and revise the policy.
Acknowledgements We would like to thank colleagues in
Samsung Research America for their valuable input and re-
source. We also like to thank anonymous reviewers for their
support to publish this paper. William Enck’s work in this
paper was supported in part by NSF grant CNS-1253346 and
ARO grant W911NF-16-1-0299. Ninghui Li’s work was sup-
ported by NSF grant No. 1314688 and ARO grant W911NF-
16-1-0127. Any opinions, ﬁndings, and conclusions or recom-
mendations expressed in this paper are those of the authors
and do not necessarily reﬂect the views of Samsung or the
funding agencies.
9. REFERENCES
[1] Android Testing. http:
//developer.android.com/tools/testing/index.html.
[2] AWS Device Farm of Mobile App Testing.
https://aws.amazon.com/device-farm/.
[3] EMMA: a free Java code coverage tool.
http://emma.sourceforge.net.
[4] Google Play Store Beta Testing.
http://developer.android.com/distribute/googleplay/
developer-console.html.
[5] Joshua Drake, Stagefright: Scary Code in the Heart of
Android. https://www.blackhat.com/us-15/brieﬁngs.
[6] Proﬁling with Traceview. http://developer.android.
com/tools/debugging/debugging-tracing.html.
[7] Security-Enhanced Linux in Android.
https://source.android.com/security/selinux.
[8] SELinux Access Vector Rules.
http://selinuxproject.org/page/AVCRules.
[9] SELinux Policy Analysis Tools.
https://github.com/TresysTechnology/setools.
11
[10] SELinux Type Statements.
http://selinuxproject.org/page/TypeStatements.
[11] Testdroid. http://testdroid.com/.
[12] M. Alam, J.-P. Seifert, Q. Li, and X. Zhang. Usage
Control Platformization via Trustworthy SELinux. In
ASIACCS ’08, pages 245–248. ACM, 2008.
[13] K. Beck. Test-driven development: by example.
Addison-Wesley Professional, 2003.
[14] K. Burr and W. Young. Combinatorial test
techniques: Table-based automation, test generation
and code coverage. In Proc. of the Intl. Conf. on
Software Testing Analysis & Review. San Diego, 1998.
[15] H. Chen, N. Li, and Z. Mao. Analyzing and
Comparing the Protection Quality of Security
Enhanced Operating Systems. In NDSS ’09, 2009.
[16] W. Choi, G. Necula, and K. Sen. Guided GUI Testing
of Android Apps with Minimal Restart and
Approximate Learning. In OOPSLA ’13, pages
623–640, New York, NY, USA, 2013. ACM.
[17] R. DeMilli and A. J. Oﬀutt. Constraint-based
automatic test data generation. Software Engineering,
IEEE Transactions on, 17(9):900–910, 1991.
[18] W. Enck, P. Gilbert, S. Han, V. Tendulkar, B.-G.
Chun, L. P. Cox, J. Jung, P. McDaniel, and A. N.
Sheth. TaintDroid: An Information-Flow Tracking
System for Realtime Privacy Monitoring on
Smartphones. ACM Trans. Comput. Syst.,
32(2):5:1–5:29, June 2014.
[19] N. Friedman, D. Geiger, and M. Goldszmidt. Bayesian
network classiﬁers. Machine Learning, 29(2):131–163.
[20] N. Friedman, I. Nachman, and D. Pe´er. Learning
Bayesian Network Structure from Massive Datasets:
The Sparse Candidate Algorithm. In UAI’99, pages
206–215. Morgan Kaufmann Publishers Inc., 1999.
An Input Generation System for Android Apps. In
ESEC/FSE ’13, pages 224–234, 2013.
[30] P. K. Manadhata and J. M. Wing. An attack surface
metric. IEEE Transactions on Software Engineering,
37(3):371–386, 2011.
[31] D. McCullough. Speciﬁcations for multi-level security
and a hook-up. In Security and Privacy, 1987 IEEE
Symposium on, pages 161–161. IEEE, 1987.
[32] P. McMinn. Search-based software test data
generation: A survey. Software Testing Veriﬁcation
and Reliability, 14(2):105–156, 2004.
[33] N. Mirzaei, S. Malek, C. S. P˘as˘areanu, N. Esfahani,
and R. Mahmood. Testing android apps through
symbolic execution. SIGSOFT Softw. Eng. Notes,
37(6):1–5, Nov. 2012.
[34] E. Reshetova, F. Bonazzi, T. Nyman, R. Borgaonkar,
and N. Asokan. Characterizing SEAndroid Policies in
the Wild. ArXiv e-prints arXiv:1510.05497, Oct. 2015.
[35] J. Saltzer and M. Schroeder. The Protection of
Information in Computer Systems. Proceedings of the
IEEE, 63(9), Sept. 1975.
[36] A. Sasturkar, S. D. Stoller, C. R. Ramakrishnan,
C. Science, and S. Brook. Policy Analysis for
Administrative Role Based Access Control. In CSFW
’06, 2006.
[37] S. Smalley and R. Craig. Security Enhanced (SE)
Android: Bringing Flexible MAC to Android. In
NDSS ’13, 2013.
[38] S. Smalley, C. Vance, and W. Salamon. Implementing
selinux as a linux security module. NAI Labs Report,
1(43):139, 2001.
[39] K. Tam, S. J. Khan, A. Fattori, and L. Cavallaro.
Copperdroid: Automatic reconstruction of android
malware behaviors. In NDSS ’15, 2015.
[21] B. Hicks, S. Rueda, and L. S. Clair. A logical
[40] H. Vijayakumar, G. Jakka, S. Rueda, J. Schiﬀman,
speciﬁcation and analysis for SELinux MLS policy.
ACM Transactions on Information and System
Security (TISSEC), 13(3):1–31, 2010.
[22] V. J. Hodge and J. Austin. A survey of outlier
detection methodologies. Artiﬁcial Intelligence Review,
22(2):85–126.
[23] M. Howard, J. Pincus, and J. M. Wing. Measuring
relative attack surfaces. Springer, 2005.
[24] T. Jaeger, R. Sailer, and U. Shankar. PRIMA:
Policy-reduced Integrity Measurement Architecture. In
SACMAT ’06, pages 19–28, 2006.
[25] T. Jaeger, R. Sailer, and X. Zhang. Analyzing
Integrity Protection in the SELinux Example Policy.
In USENIX Security ’03, 2003.
[26] T. Jaeger, R. Sailer, and X. Zhang. Resolving
constraint conﬂicts. In SACMAT ’04, pages 105–114,
New York, New York, USA, 2004. ACM Press.
[27] C. S. Jensen, M. R. Prasad, and A. Møller.
Automated testing with targeted event sequence
generation. In ISSTA ’13, pages 67–77. ACM, 2013.
[28] P. Loscocco and S. Smalley. Integrating Flexible
Support for Security Policies into the Linux Operating
System. In USENIX Annual Technical Conference ’01,
number February, pages 29–42, 2001.
[29] A. Machiry, R. Tahiliani, and M. Naik. Dynodroid:
and T. Jaeger. Integrity Walls: Finding Attack
Surfaces from Mandatory Access Control Policies. In
ASIACCS ’12, pages 75–76, 2012.
[41] W. Visser, S. Corina, and S. Khurshid. Test input
generation with java pathﬁnder. ACM SIGSOFT
Software Engineering Notes, 29(4):97–107, 2004.
[42] R. Wang, W. Enck, D. Reeves, X. Zhang, P. Ning,
D. Xu, W. Zhou, and A. M. Azab. EASEAndroid:
Automatic Policy Analysis and Reﬁnement for
Security Enhanced Android via Large-Scale
Semi-Supervised Learning. In In USENIX Security
’15, pages 351–366, Aug. 2015.
[43] W. Xu, M. Shehab, and G.-J. J. Ahn. Visualization
based policy analysis: case study in SELinux. In
Proceedings of the 13th ACM Symposium on Access
control models and technologies, pages 165–174, 2008.
[44] L. K. Yan and H. Yin. DroidScope: Seamlessly
Reconstructing the OS and Dalvik Semantic Views for
Dynamic Android Malware Analysis. In USENIX
Security ’12, pages 29–29, 2012.
[45] Z. Yang, M. Yang, Y. Zhang, G. Gu, P. Ning, and
X. S. Wang. AppIntent: analyzing sensitive data
transmission in android for privacy leakage detection.
In CCS ’13, pages 1043–1054, 2013.
12
APPENDIX
Figure 5: The representative bipartite result of attack surface analysis generated by SPOKE. Subjects are red nodes in left. Objects are blue
nodes in right. Justiﬁed access patterns are in grey. Over-permissive access patterns in red allow unjustiﬁed subjects to access anonymized
critical ﬁles, which have been conﬁrmed and revoked by policy engineers. With the help of SPOKE, policy rules in new releases are more strict
than the old ones.
13
read,writeread,writeread,writeioctl,read,writeread,writeread,writeread,writeread,writeread,writeread,writereadread,writereadread,writeread,writeread,writeread,writeioctl,readread,writeread,writereadread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeioctl,read,writeread,writeread,writeread,write,executeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeread,writeexecuteread,writeread,writeread,writeread,writeread,writeread,writedebuggerdaudiodauditdsdcarddsurfaceflingerwpagpsdvoldmediaserverkeyboard_input_appsystem_server/proc/pid/system/usr/share/timezonedata/dev/sound_trigger_boost/data/misc/audit/log/storage/emulated/legacy/dev/video50/data/misc/wifi/blacklist.conf/data/misc/wifi/p2p_supplicant.conf/data/misc/location/dev/device-mapper/system/vendor/lib/mediadrm/data/data/keyboard_input_app/*anonymized_file5anonymized_file4anonymized_file3anonymized_file2anonymized_file1