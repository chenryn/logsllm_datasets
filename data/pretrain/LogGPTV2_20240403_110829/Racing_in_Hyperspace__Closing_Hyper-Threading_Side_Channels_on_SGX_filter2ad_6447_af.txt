requests a co-location test. If the co-location test fails, the
enclave program reacts according to a pre-deﬁned policy, e.g.,
retries r times and, if all fail, terminates.
VII. PERFORMANCE EVALUATION
In this section, we evaluate the performance overhead of
HYPERRACE. All experiments were conducted on a Dell
Optiplex 7040 machine with an Intel Core i7-6700 processor
and 32GB memory. The processor has four physical cores (8
logical cores). The parameter α of the co-location tests was
set to 1e−6; p0, p1, and n were the same as in Sec. V.
A. nbench
We ported nbench [36], a lightweight benchmark application
for CPU and memory performance testing,
to run inside
SGX and applied HYPERRACE to defend it against Hyper-
Threading side-channel attacks.
Contention due to Hyper-Threading itself. Before evaluating
the performance overhead of HYPERRACE, we measured the
execution slowdown of nbench due to contention from the
co-located logical core. This slowdown is not regarded as
an overhead of HYPERRACE, because the performance of
an enclave program is expected to be affected by resource
contention from other programs; a co-located thread running
a completely unrelated program is normal.
We set up two experiments: In the ﬁrst experiment, we
run nbench applications with a shadow thread (busy looping)
executing on a co-located logical core; in the other experiment,
190
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:38:29 UTC from IEEE Xplore.  Restrictions apply. 
 1
 0.8
0.944 0.952
0.897 0.900
0.981
0.874
0.839
0.752
s
n
o
i
t
a
r
e
t
i
f
o
#
d
e
z
i
l
d
n
o
c
e
s
r
e
p
 0.6
 0.4
0.748
0.671
a
m
r
o
N
 0.2
 0
lu decomposition
       numeric sort
           string sort
       fp emulation
                bit(cid:1)eld
        assignment
                fourier
          neural net
             hu(cid:2)man
                   idea
q = Inf
q = 20
q = 15
q = 10
q =   5
d
a
e
h
r
e
v
o
d
e
z
i
l
a
m
r
o
N
2.5×
2×
1.5×
1×
0.5×
0×
lu decomposition
       numeric sort
           string sort
       fp emulation
                bit(cid:1)eld
        assignment
                fourier
          neural net
             hu(cid:2)man
                   idea
Fig. 8. Normalized number of iterations of nbench applications when running
with a busy looping program on the co-located logical core.
Fig. 9. Runtime overhead due to AEX detection; q = Inf means one AEX
detection per basic block; q = 20/15/10/5 means one additional AEX
detection every q instructions within a basic block.
we run nbench with the co-located logical core unused. In
both cases, the nbench applications were complied without
HYPERRACE instrumentation. In Fig. 8, we show the nor-
malized number of iterations per second for each benchmark
application when a shadow thread causes resource contention;
the normalization was performed by dividing the number
of iterations per second when the benchmark occupies the
physical core by itself.
instance,
As shown in Fig. 8, the normalized number of iterations
ranges from 67% to 98%. For
the benchmark
numeric sort runs 1544.1 iterations per second with a
shadow thread while 1635.2 iterations per second without it,
which leads to a normalized value of 1544.1/1635.2 = 0.944.
The following evaluations do not include the performance
degradation due to the Hyper-Threading contention.
Overhead due to frequent AEX detection. The performance
overhead of the HYPERRACE consists of two parts: AEX
detection and co-location tests. We evaluated these two parts
separately because the frequency of AEX detection depends
on the program structure (e.g., control-ﬂow graph) while
the frequency of the co-location tests depends on the num-
ber of AEXs detected. We use the execution time of non-
instrumented nbench applications (still compiled using LLVM)
with a shadow thread running on the co-located logical core
as the baseline in this evaluation.
To evaluate the overhead of AEX detection, we short-
circuited the co-location tests even when AEXs were detected
in HYPERRACE. Hence no co-location tests were performed.
Fig. 9 shows the overhead of AEX detection. Note that
q = Inf means that there is only one AEX detection at
the beginning of every basic block; q = 5 suggests that if
there are more than 5 instructions per basic block, a second
AEX detection is inserted; q = 20, q = 15, and q = 10
are deﬁned similarly. Since each instrumentation for AEX
detection (by checking SSA) consists of two memory loads
(one SSA marker for each thread) and two comparisons, when
the basic blocks are small, the overhead tends to be large. For
example, the basic blocks in the main loop of assignment
benchmark application containing only 3 or 4 instructions per
TABLE VII
MEMORY OVERHEAD (NBENCH).
Bytes
Overhead
Original
207, 904
-
q = 20
242, 464
16.6%
q = 15
246, 048
18.3%
q = 10
257, 320
23.7%
q = 5
286, 448
37.7%
basic block, the overhead of HYPERRACE on assignment is
large (i.e., 1.29×) even with q = Inf. Generally, the overhead
increases as more instrumentations are added. With q = Inf,
the overhead ranges from 0.8% to 129.3%, with a geometric
mean of 42.8%; when q = 5, the overhead ranges from 3.5%
to 223.7%, with geometric mean of 101.8%.
Overhead due to co-location tests. The overhead of co-
location tests must be evaluated when the number of AEX
is known. HYPERRACE triggers a co-location test when an
AEX happens in one of the two threads or both. By default,
the operating system generates timer interrupts and other types
interrupts to each logical core. As such, we observe around
250 AEXs on either of these two threads per second. To
evaluate the overhead with increased numbers of AEXs, we
used a High-Resolution Timers in the kernel (i.e., hrtimer)
to induce interrupts to cause more AEXs. The overhead is
calculated by measuring the overall execution time of one
iteration of the nbench applications, which includes the time
to perform co-location tests when AEXs are detected.
We ﬁxed the instrumentation parameters as q = 20 in
the tests. The evaluation results are shown in Fig. 10. The
overhead of AEX detection has been subtracted from the
results. From the ﬁgure, we can tell that the overhead of co-
location tests is small compared to that of AEX detection. With
250 AEXs per second, the geometric mean of the overhead is
only 3.5%; with 1000 AEXs per second, the geometric mean
of the overhead is 16.6%. The overhead grows almost linear
in the number of AEXs.
Memory overhead. The memory overhead of the enclave code
is shown in Table VII. We compared the code size without
instrumentation and that with instrumentation under different
q values. The memory overhead ranges from 16.6% to 37.7%.
191
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:38:29 UTC from IEEE Xplore.  Restrictions apply. 
lu decomposition
       numeric sort
           string sort
       fp emulation
                bit(cid:1)eld
        assignment
                fourier
          neural net
             hu(cid:2)man
                   idea
Fig. 10. Runtime overhead of performing co-location tests when q = 20.
250 AEXs per second
427 AEXs per second
611 AEXs per second
1000 AEXs per second
d
a
e
h
r
e
v
o
d
e
z
i
l
a
m
r
o
N
0.3×
0.25×
0.2×
0.15×
0.1×
0.05×
0×
d
a
e
h
r
e
v
o
d
e
z
i
l
a
m
r
o
N
1.2×
1×
0.8×
0.6×
0.4×
0.2×
0×
1.021
0.838
0.240
0.228
0.022
0.496
0.210
0.146
              ECDSAsign
    EVP Digest (sha1)
EVP Digest (sha256)
             AESdecrypt
      DH computekey
RSAprivatedecrypt
   DESncbcencrypt
ECDH computekey
Fig. 11. Overhead of crypto algorithms.
B. Cryptographic Libraries
We also applied HYPERRACE to the Intel SGX SSL crypto-
graphic library [37] and measured the performance overhead of
eight popular cryptographic algorithms. We run each algorithm
repeatedly for 10 seconds and calculated the average execution
time for one iteration. Fig. 11 gives the overhead (for both
AEX detection and co-location test) when instrumented every
q = 20 instructions per basic block, and no extra AEXs
introduced (the default 250 AEXs per second).
The overhead for AES_decrypt algorithm is small
(around 2%) compared to other algorithms since its dominat-
ing basic blocks are relative large. In contrast, the overhead for
ECDH_compute_key and ECDSA_sign are relatively large
(i.e., 102.1% and 83.8%) because elliptic curve algorithms
consist of many small basic blocks. The overhead for other
evaluated algorithms ranges from 14.6% to 49.6%. The geo-
metric mean is 36.4%.The size of the complied static trusted
library libsgx_tsgxssl_crypto.a grew from 4.4 MB
to 6.6 MB, resulting in an memory overhead of 50%.
VIII. RELATED WORK
Related to our work is a large volume of literature on
micro-architectural side-channel attacks. Many of these attacks
leverage various shared resources on Hyper-Threading, such
as the L1 D-cache [20], [21],
the L1 I-cache [22], [23],
[27], branch target buffers [18] and ﬂoating-point unit [19], to
perform same-core attacks against co-located victim processes.
These attacks also work on SGX-enabled processors.
Countermeasures to Hyper-Threading side-channel attacks
are less explored. The only known solution is to disable
Hyper-Threading. However, because the OS is not trusted
by the enclave programs,
it cannot be trusted to disable
Hyper-Threading. Gruss et al. [30] brieﬂy touched upon this
problem in their exploration of using TSX to mitigate cache
side channels. As the TSX-based solutions do not address
Hyper-Threading enabled attacks, they proposed to launch
two threads to occupy both logical cores of the physical
core, and construct a timing-less covert channel using TSX
transactions to verify that the two threads are indeed scheduled
on the same core. However, as discussed in Sec. IV-A, covert-
channel solutions are vulnerable to man-in-the-middle attacks.
As a countermeasure, Gruss et al. proposed to randomly
choose “a different L1 cache set (out of the 64 available)
for each bit to transmit”. However, because the adversary can
perform a PRIME-PROBE analysis on the entire L1 cache to
learn which cache set is used for the covert channel (and at
the same time extract the signals), man-in-the-middle attacks
are still feasible. In contrast, our scheme does not rely on
cache-contention based covert channels; even with the system
capability, the adversary cannot simulate the data races that
take place inside the enclave, fundamentally addressing the
man-in-the-middle threats.
HYPERRACE has been inspired by HomeAlone [38], which
utilizes cache side-channel analysis techniques to identify un-
known VMs in public clouds. HYPERRACE is different in that
it faces a stronger adversary who controls the entire system
software. The idea of using covert channels for co-location
detection has been applied in prior works to achieve VM co-
location in public clouds [39], [40], [41], [29]. Our method
of detecting AEX follows Gruss et al. [30]. A very similar
technique (i.e., placing markers in control data structures) has
been explored by Zhang et al. for detecting hypervisor context
switches from guest VMs [42].
IX. CONCLUSION
In conclusion, HYPERRACE is a tool for protecting SGX en-
claves from Hyper-Threading side-channel attacks. The main