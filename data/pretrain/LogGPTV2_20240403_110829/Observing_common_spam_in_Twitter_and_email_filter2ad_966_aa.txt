title:Observing common spam in Twitter and email
author:Cristian Lumezanu and
Nick Feamster
Observing Common Spam in Tweets and Email
Cristian Lumezanu
NEC Laboratories America
Princeton, NJ
PI:EMAIL
Nick Feamster
University of Maryland
College Park, MD
PI:EMAIL
ABSTRACT
Spam is pervasive across many types of electronic commu-
nication, including email, instant messaging, and social net-
works. To reach more users and increase ﬁnancial gain,
many spammers now use multiple content-sharing platforms—
including online social networks—to disseminate spam. In
this paper, we perform a joint analysis of spam in email and
social networks. We use spam data from Yahoo’s web-based
email service and from Twitter to characterize the pub-
lishing behavior and eﬀectiveness of spam advertised across
both platforms. We show that email spammers that also ad-
vertise on Twitter tend to send more email spam than those
advertising exclusively through email. Further, we use DNS
lookup information to show that sending spam on both email
and Twitter correlates with a signiﬁcant increase in cover-
age: spam domains appearing on both platforms are looked
up by an order of magnitude more networks than domains
using just one of the two platforms.
Categories and Subject Descriptors
C.2.3 [Computer-communication networks]: Network
Operations; K.4.2 [Computers and society]: Social is-
sues; H.0 [Information systems]: General
General Terms
Measurement, Security
Keywords
Twitter, email, spam, DNS, multiple platform spam
1.
INTRODUCTION
Spam is an unwanted yet continual scourge in electronic
communication; it inﬁltrates basic conversation tools, such
as email and instant messaging, as well social-based content
sharing platforms, such as OSNs and forums. A recent study
shows that 89% of the 107 trillion emails sent in 2010 were
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’12, November 14–16, 2012, Boston, Massachusetts, USA.
Copyright 2012 ACM 978-1-4503-1705-4/12/11 ...$15.00.
spam [15]. Further, emerging social-based applications such
as social networks, blogs, or video sharing websites, are also
subject to abuse: 8% of the URLs shared on Twitter lead
to malicious websites that host malware or scams [6].
To reach more users and maximize their ﬁnancial gains,
spammers are increasingly using multiple content-sharing
platforms to disseminate the same malicious content. For
example, several malware and phishing campaigns are car-
ried over email, to target as many users as possible, but also
over social networking platforms, where the trust-based so-
cial graph enables spammers to target those users who are
more likely to click on their links [8,9]. In our analysis (§ 4),
we discover over 700 scam, malware, and phishing domains
that are advertised using both email and tweets over the
course of a month.
In this paper, we take an initial step towards understand-
ing the properties of spam across multiple platforms. We
present a joint measurement study of spam across two pop-
ular content sharing platforms: email and social networking.
We consider spam to be any message containing an URL
that leads to a website that hosts malicious content such
as malware, phishing, or scams. Using two message data
sets, of emails to Yahoo accounts and tweets from Twitter,
gathered for one month in March 2011, we provide a parallel
view of the properties of spam and behavior of spammers.
An important characteristic of our study is that it focuses
on both emails and tweets sent during the same time period.
We characterize email and tweet spam from two diﬀerent
perspectives. First, we investigate the presence of spam on
the two dissemination platforms (Section 4). We discover
that 55% of all spam emails advertise scam domains that
also appear on Twitter. Email spammers that advertise at
least one domain on Twitter are likely to send more email
spam overall during our measurement than those that send
only email-exclusive spam.
Second, we seek to understand the eﬀect of advertising
spam on multiple platforms (Section 5). To the best of our
knowledge, our study oﬀers the ﬁrst large-scale analysis on
the behavior and eﬀectiveness of spam sent during the same
time period on both email and Twitter. Using DNS lookup
data to estimate the number of clicks for each domain, we
ﬁnd that domains common to both emails and tweets receive
an order of magnitude more clicks than domains exclusive
to one platform.
Because the email data set is unﬁltered while the tweets
have already passed through Twitter’s spam ﬁlters, our study
has a few limitations. We cannot oﬀer a complete compar-
ison between email and tweet spam or establish a causal
461relationship between the presence of spam in tweets and in
emails and its eﬀectiveness. Notwithstanding, our results
show that there is a positive correlation between publishing
spam on multiple platforms and both the volume of email
spam send by these publishers and the eﬀectiveness of the
spam being sent. This leads to a most important ﬁnding
of our study: incorporating information about Twitter spam
publishing behavior into email spam ﬁlters (or vice versa)
could increase their eﬀectiveness in quickly identifying viru-
lent spammers.
Although we do not pursue the positive implications of our
ﬁndings in this paper, we believe that the overlap between
spam that appears in both email messages and tweets ulti-
mately presents new opportunities for improving both the
accuracy and speed of spam detection. Spam ﬁlters could
leverage information about publishing behavior of spam across
platforms to build better defenses. For example, discovering
that spam URLs are consistently published on Twitter be-
fore email could help develop more accurate email blacklists.
Further, understanding how and when spammers send com-
mon spam could reveal their strategies and how to counter
them. Finally, understanding the presence and behavior of
common spam would help existing spam ﬁghting solutions
developed for individual platforms [1, 2, 5–7, 10, 12, 16, 19]
interact better with each other.
2. RELATED WORK
Most analyses of spam have focused exclusively on email
[1, 11, 12, 19]. They characterize spam from various aspects
such as the behavior of spammers [11, 12], the email con-
tents [14], or the properties of spam hosting infrastructures
[1]. More recently, several studies characterize spam in fo-
rums [10, 13], or in social networking applications such as
Facebook and Twitter [2, 5–7]. Unlike previous work, we
focus on spam that is sent on multiple platforms (e.g., both
email and Twitter) at the same time. Such a joint analysis
provides a new perspective on spam and allows us to better
understand how spammers work and coordinate to increase
their impact.
To ﬁght spam sent across web services such as social net-
working or video sharing sites, Thomas et al. proposed
Monarch, a spam URL ﬁltering service [16]. Monarch com-
pared email and tweet spam and found few features in com-
mon across the two platforms. This means that one would
need to learn speciﬁc sets of rules to detect spam on each
platform. We share a similar philosophy to Monarch, that
generalizing spam ﬁghting across multiple platforms can lead
to faster and more eﬃcient detection. However, unlike Thomas
et al., we focus on the spam that is common across platforms
and characterize its prevalence, publishing behavior, and ef-
fectiveness.
3. DATA AND METHODS
In this section, we present the data sets used in our anal-
ysis and discuss how we identify spam messages. We use
Twitter and Yahoo! Mail as representative applications for
online social networks (OSNs) and email, respectively.
3.1 Data sets
To compare spam in tweets and email, we start with two
sets of public messages, Twitter and Yahoo, both collected
in March 2011. The Twitter data set contains public tweets
gathered using the public Twitter streaming API. For each
tweet we retrieve the publishing time, details on its author
(e.g., id, screen name, numbers of followers, friends, and sta-
tuses posted), as well as the text of the tweet. The Yahoo
data set represents a snapshot of all incoming emails to Ya-
hoo! Mail accounts as received by Yahoo’s mail servers and
it was privately shared by Yahoo!. The information available
is the connecting IP, the time of the message, and the URLs
contained in the message. Both data sets capture around
1%, extracted uniformly at random, of all messages sent on
each platform in March 2011.
3.2 Spam identiﬁcation
Because URLs are the primary method that spammers use
to attract users to websites that host malicious content, we
restrict our analysis on the tweets and emails that contain
URLs. To identify spam messages, we take the following
three steps. (1) We parse the text of each tweet and extract
all URLs. (2) We ﬁnd the ﬁnal landing page for all links
from tweets and emails that are hidden with URL shorten-
ing services or behind chains or redirections. (3) We use two
sources to determine whether a URL leads to malicious con-
tent by comparing the URL of the ﬁnal landing page with
public URL blacklists and spamtrap emails. We describe
below this ﬁnal step in more detail.
URL blacklists contain domains and websites that are
known to host malicious content such as scams and malware
or participate in phishing campaigns. We check the domains
in our data sets against several public URL blacklists in the
ﬁrst week of May 2011. URIBL and SURBL are DNS-based
blacklists with domain names found in the body of spam
emails, but generally not in legitimate emails. PhishTank
lists phishing URLs voted by users. To detect malware,
we use the list published by malwaredomains.com. Finally,
for both malware and phishing domains, we use the Google
Safebrowsing API to check against Google’s constantly up-
dated blacklists.
Blacklists are not always eﬀective in detecting recently ad-
vertised spam domains or domains that are not frequently
reused. Previous studies show that information about many
spam domains and spammers fails to show up in blacklists
even more than a month after the domain was ﬁrst adver-
tised [6, 12]. To improve the completeness of our study and
detect even recently published spam domains, we use data
from the spamtrap set up by Ramachandran and Feam-
ster [11]. Because the spamtrap is associated with a DNS
Mail Exchange (MX) record with no legitimate email ad-
dresses, all email that it receives is spam. For our measure-
ment, we collect all URLs found in over 11 million emails
received by the spamtrap between January and March 2011.
Although all emails received at the spamtrap are from
spammers, the spam emails might still contain legitimate
URLs to subvert anti-spam ﬁlters. We use the following
simple heuristic to select the spamtrap URLs (and domains)
that are more likely to be malicious. First, we whitelist all
URLs with domains present in the Alexa top 10,000 most
popular domains, under the assumption that popular do-
mains rarely host spam. Second, we consider only domains
that appear in more than 1,000 spamtrap emails. This is
based on the assumption that, for spam to be eﬀective, it
must be distributed at scale [20].
462Data set
All
Yahoo
- Yahoo only
- Yahoo, common
Twitter
- Twitter only
- Twitter, common
290,355,683
135,740,285 (47%)
186,552,390 (64%)
5,569,940
496,303 (1%)
5,159,890 (99%)
Data set
All
Yahoo
- Yahoo only
- Yahoo, common
Twitter
- Twitter only
- Twitter, common
14,860,901
14,699,376 (>99%)
161,535 (99%)
Spam
spamtrap
13,134,298
8,012,716 (61%)
8,881,790 (68%)
18,404
0 (0%)
18,404 (100%)
total
49,142,499
34,159,814 (69%)
27,009,682 (55%)
198,887
29 (99%)
Domains
blacklist
81,567
80,897 (99%)
670 (99%)
Spam
spamtrap
3,681
3,601 (89%)
80(2%)
80
0 (0%)
80 (100%)
total
82,233
81,493 (99%)
740 (1%)
746
6 (99%)
Table 1: Data sets used in our study. We collect the main data sets, Yahoo and Twitter in March 2011.
The secondary data sets contain the messages with domains that appear only on Yahoo, only on Twitter,
and on both. Percentages are computed of the values for the main data sets. Not all percentages add to
100% because there are messages with more than one URL where some URLs are unique to one platform
and others are common to both. We also separate the messages and domains according to whether they are
spam or not and to the method used to identify them as spam (blacklists or spamtrap).
3.3 Spam characterization
We use the methods described above to identify spam mes-
sages in the Twitter and Yahoo data sets. Table 1 shows
the statistics with respect to spam domains and messages
(tweets or emails) that contain spam URLs (focus on the
data sets labeled “Yahoo” and “Twitter”). There are around
two orders of magnitude more spam emails than tweets. This
could be explained by the relative diﬀerence between the
number of messages in the two data sets but it could also
be due to the Twitter data being collected after ﬁltering,
as we explain below. The gap becomes smaller when we
consider the amount of spam relative to the total number
of messages on each platform: 17% of all emails are spam
while, even after ﬁltering, 4% of all tweets are spam. These
numbers suggest that although Yahoo! Mail has many more
users and daily messages than Twitter [4, 18], Twitter is be-
coming a signiﬁcant infrastructure for disseminating spam.
3.4 Limitations
Data sampling. Due to the large volume of tweets and
emails, we analyze only 1% of the emails received by Yahoo
servers and of the tweets sent in March 2011. Sampling can
misrepresent the properties of the original message popula-
tion, but we are conﬁdent that it has not distorted general
trends: for example, the statistics about the prevalence of
spam that we report are comparable to what previous stud-
ies have shown [6, 17, 20].
Spam ﬁltering. The Yahoo data set contains informa-
tion about emails captured before any spam ﬁltering was
performed, while the tweets in our data set have already
passed through Twitter’s spam ﬁlters. This can aﬀect our
results as follows:
1. It can underestimate the amount of Twitter spam,
which in turn underestimates the common spam sent
on both Twitter and email. However, even after ﬁl-
tering, we ﬁnd a signiﬁcant amount of tweets that are
spam.
2. Twitter’s ﬁltering may skew the ratio between the amount
of “common with Yahoo” and “exclusive to Twitter”
spam (if exclusive domains are ﬁltered more or less
than common domains). We believe that, because
Twitter uses email blacklists to ﬁght spam [6], it is
more likely that common domains are ﬁltered more
than exclusive domains, making our results in Sec-
tion 4 an underestimation of reality.
3. Finally, while distorting the absolute view on common
spam, the ﬁltered tweets in our data sets can oﬀer a
more realistic perspective on the amount of common
spam that an email spam ﬁlter would see if it had ac-
cess to the publicly available Twitter stream. Our re-
sults in Section 4 suggest that email ﬁlters could be
more eﬀective if they incorporated Twitter spam pub-
lishing behavior in their analysis.
Spam identiﬁcation. We use both blacklists and spam-
trap emails to ensure that our knowledge about which do-
mains host malicious content is as complete as possible.
However, even then, we may still miss many spam domains.
For example, neither blacklists nor spamtrap emails help
us identify several Twitter-speciﬁc spam campaigns (e.g.,
phishing for followers, buying retweets [6]). Because the fo-
cus of our paper is on common spam in email and Twitter,
missing the Twitter-speciﬁc spam does not aﬀect our results.
4. PRESENCE OF COMMON SPAM
We now study the presence of spam and the behavior of
spammers across Twitter and email from two perspectives:
How is common spam published across platforms?, and How
do we identify it? Unsurprisingly, we ﬁnd that the networks
4631.0
0.8
s
k
r