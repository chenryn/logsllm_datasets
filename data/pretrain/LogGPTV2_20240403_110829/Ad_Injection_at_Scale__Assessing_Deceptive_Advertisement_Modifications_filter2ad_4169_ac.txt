●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
aggregate form; never tracking or analyzing the behavior of
individual users; never sharing raw data outside of Google; and
setting a short lifetime on the data collected after which only
aggregates could be stored. We also veriﬁed that our system
is compatible for all clients that we collect data from (e.g.,
there is no degradation in the client’s user experience due to
crashing) and that our system never interferes with ad injectors
or tampers with the client’s DOM, but only provides a passive
measure of ad injection in the wild.
●
B. Identifying Distribution Vectors
●
●●●
●●●●●●●●●●●●●●●●●●
●
●●●●●●●●●●●●●●●●●
●●●●●●
●●●●●●
●●●●●
●●●●●●●●●●
●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●
●●●●●●●●●
●●●●●●●●
●●●
●●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●●●
●
●●●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●
●●●●
●●●●●●●●●●●●
●●
●●●●●●●●●●●
●●
●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●
●●●●●●●●●●●●
●●●●●●●●
●●●●●●●●
●●
●●
●●●●●
●
●●
●●
●
●●●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●●●
●●
●
●
●
●●
●
●
●
●
●●●
●●
●
●
●
●
●
●●●
●
●●
●●●●
●
●●●
●●●●
●
●
●●
●●●
●
●
●
●●
●●●
●
●●●
●
●●
●
●●●●●
●●●●
●●●
●●
●●
●●●
●●
●
●●
●
●●
●
●●
●●
●●●
●●●●
●
●●●
●●●●●●●●
●
●
●●
●●●●●●●●●
●●●
●
●
●●●●●●●●
●
●●
●●●●●●●●●●●
●
●●●●
●
●●●
●●●●●●●●●●●●●●●●●●
●●
●●●●
●●●●
●●●
●●●●●●●●●●●●
●●●
●●
●
●●●●●●
●●
●●
●●
●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●
●●●●●●●
●●●●●●●
●
●●●●●●●●●●●●●●●●●●●●●●●
●
●●●●●●●
●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●●●
●●●●●
●
●●●
●●●●
●
●●●●●
●●●●●●
●●●●●●●●●●●
●●
●
●●●●●
●
●
●
●●●●●●●
●
●
●●●●●●
●●
●●●●●●
●
●●
●
●●
●
●●●●
●
●
●
●
●●
●
●●
●
●●
●●●●
●●●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
101
103
105
107
Number of pages with script
Figure 3: Zipf-like distribution of script popularity in tampered DOM
clients. The top 10 and top 100 scripts appear in 56% and 74% of
tampered DOMs respectively.
Design Decisions & Related Approaches: When we designed
our client-side detection, we opted to whitelist rather than
blacklist page elements as the former requires no knowledge
of active threats and is more robust to changes in ad injection
techniques over time. Our strategy is similar to “web tripwires”
used to detect in-ﬂight page changes [29]. We expand on
the core idea of web tripwires and identify speciﬁc injected
elements, rather than simply reporting a binary determination
of whether tampering occurred.
Our system is also similar to Content Security Policies
(CSP) supported by modern browsers [36], which rely on
server-speciﬁed whitelists for preventing or reporting when a
client’s browser requests cross-origin scripts, iframes, or data
(typically to prevent cross-site scripting attacks). We opted
to rely on a JavaScript payload as it is simpler to deploy as
an experiment, allows ﬁner-grain reporting detail compared
to CSP (e.g., page elements, not just cross-origin requests),
and does not rely on browser compatibility beyond JavaScript.
At the time of writing, CSP is only supported in Chrome,
Firefox, and Safari; enforcement in Internet Explorer remains
in development. A second motivation for JavaScript over CSP
is that there is an existing incentive for extensions, binaries,
and networks to tamper with CSP headers2 due to enforcement
policies that might otherwise prevent ad injection. Despite
these shortcomings, we believe that CSP is a viable fallback
for detecting ad injection in the absence of a more robust
experimentation framework.
Ethics and Privacy: Our data collection technique is anal-
ogous to Content Security Policies, which modern browsers
use to report client-side telemetry of page integrity to website
operators. Prior to deploying our system, Google’s internal
privacy review board (similar to an IRB) vetted and approved
our architecture and the data it collects. Part of the restrictions
placed on our system include never analyzing data in non-
2Web servers specify a CSP policy in HTTP headers for pages served to a
client. Any intermediary with sufﬁcient network control can strip or modify
these values.
We correlated the ad injectors we observed in client trafﬁc
with potential installation vectors, including extensions, bi-
naries, and network tampering. To this end, we cast a wide
net and dynamically analyzed over 1 million extensions and
25 million binaries in search of ad injectors. We used a
secondary technique for identifying network-based injectors.
1) Browser Extensions: To analyze ad injection conducted
via browser extensions, we relied on WebEval—Google’s
internal system for reviewing Chrome extensions which we de-
scribe below—and Hulk [18]—an independent system for de-
tecting malicious Chrome extensions. We obtained extensions
from three sources: crawling the web; extensions installed or
side-loaded by binaries provided by Safe Browsing (described
shortly); and all extensions in the Chrome Web Store. We
used WebEval to evaluate all three sources—totaling over
1 million extensions created between March, 2011–October,
2014—while Hulk’s analysis focused on 91,660 extensions it
crawled from the Web Store.
We outline WebEval’s analysis pipeline in Figure 4. An
extension’s evaluation consists of two phases: (1) a static
scan of the extension’s HTML, JavaScript, and manifest per-
missions; and (2) a dynamic evaluation, which loads a fresh
copy of Chrome with the extension installed and subjects the
extension to a barrage of behavioral suites. The full details of
WebEval’s architecture are beyond the scope of this paper, but
we highlight the features relevant to our ad injection study.
Static Analysis: WebEval’s static analysis module identiﬁes
the use of sensitive manifest permissions such as intercepting
web requests (e.g., modifying incoming and outgoing network
trafﬁc to the browser), unrestricted access to cookies, or the
ability to prevent uninstalling an extension. It also heuristi-
cally scans for code obfuscation, the inclusion of JavaScript
eval(), and embedded URLs for remote resources (e.g.,
scripts, images). Static signals also include reputation data
surrounding the extension developer, the age of the extension,
the timeline of installs for the extension, and whether installs
originate organically from the Web Store. Our install statistics
are limited to aggregate counts (we have no details on which
clients install an extension).
During dynamic analysis, WebEval
Dynamic Analysis:
launches a virtualized Windows environment and installs
the extension under evaluation in an instrumented Chrome
browser. The testing environment captures all Chrome API
calls, DOM method calls, and network requests made by the
154154
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:21 UTC from IEEE Xplore.  Restrictions apply. 
process, actively man-in-the-middling any HTTPS connections
to introspect on packet contents. Similar to our extension
analysis pipeline, we detect binary-based ad injectors by scan-
ning the network logs related to visiting Google websites for
outgoing requests to injection libraries. In total, Safe Browsing
dynamically evaluated over 25 million unique binaries from
February–October, 2014. Of these, we categorize 34,407 as
ad injectors.
3) Network: We use the data produced by our client-side
measurements to detect network-based ad injectors. Mechan-
ically, these actors intercept page content in transit to either
inject scripts or directly inject ad-based DOM elements. We
detect the possibility of such tampering by comparing the
fraction of tampered DOMs that were served over HTTP
versus HTTPS. This approach assumes that a network attacker
does not have a valid certiﬁcate to man-in-the-middle HTTPS
connections (and that certiﬁcate pinning is not present
to
prevent this attack). This approach cannot determine which
network element in particular is responsible for tampering with
a client’s connection.
C. Pinpointing Advertisers and Intermediaries
The ad injection ecosystem hinges on the willingness of
advertisers to pay for trafﬁc from injectors. This involves a tan-
gled web of intermediaries that ultimately connect advertisers
with injection libraries. We unravel this graph by automatically
visiting creatives (e.g., ad text, images, and objects) served by
ad injectors and enumerating all of the parties involved.
As a ﬁrst step, we need to acquire creatives from ad injec-
tors. One strategy would be to reverse engineer the ad request
protocol for each of the ad injectors we encounter. While semi-
automated approaches exist for extracting gadgets to replay
malware C&C protocols [5], the security community relies
on these techniques to overcome event-based triggers (e.g.,
timing, user interaction) that cause the malware to activate.
In our case, we know the triggers that cause ad injectors to
activate—it is as simple as visiting a web page.
To this end, we dynamically execute Chrome in a vir-
tualized environment with an ad injector installed and then
automatically visit a suite of pages that trigger ad insertion.
This approach elides any complexities surrounding reversing
the protocol of each injection library, executing JavaScript,
priming cookies, or satisfying environment variables or pa-
rameters expected by the ad injector to operate. We select
ad injectors from our feed of extensions, omitting binaries
from the process. As we will discuss in Section V, extensions
provide a better coverage of ad injectors in the wild.
1) Identifying Potential Trigger Pages: In order to generate
a suite of trigger pages that reliably induce ad injection scripts
to fetch rogue creatives, we manually scan the Alexa Top
100 in Chrome, cycling through 14 different ad injection
extensions. This set of extensions provides non-overlapping
coverage of the top injection libraries we observe in the
wild, absent those not contacted by any of the extensions
(or binaries) in our dataset. We speciﬁcally choose extensions
Figure 4: WebEval’s analysis pipeline for scanning Chrome Web
Store extensions.
browser during execution. WebEval then subjects the browser
to behavioral suites that include querying Google Search and
visiting dummy pages laden with advertisements to determine
whether the extension alters the browser’s DOM (e.g., injects
new elements or replaces existing ads). WebEval specially
constructs behavioral suites to replay network requests from
a cached network trace previously produced by loading web
pages in the same environment, but without the extension
installed; any new network requests made by the extension
are allowed to access the external Internet. This technique—
similar to recording and replaying virtual machine system
calls [13]—allows WebEval to identify all network requests
made speciﬁcally by an extension rather than a web page.
Furthermore,
it prevents page dynamism from introducing
false positives when detecting DOM-level alterations. As
pages become stale over time WebEval periodically updates
its test suites to keep up with content drift.
We combine WebEval’s ad analysis suite and network traces