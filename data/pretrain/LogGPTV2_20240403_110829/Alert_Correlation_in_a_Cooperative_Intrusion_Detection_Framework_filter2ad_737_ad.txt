### 6. Limitations of the Approach

Our approach is not applicable to scenarios where the detection field of attacks corresponds to combined events. It is limited to detection scenarios that involve single, isolated events.

### 7. Optimization of Correlation Rules

While it is possible to define an algorithm to optimize correlation rules, the overhead due to the lack of such optimization is minimal. Therefore, we do not consider this optimization a high priority.

### Example of Ontological Rule

```prolog
use_service(System_address, 'NetBios').
use_os(System_address, windows).
```

**Figure 4: Example of ontological rule**

From a syntactical perspective, we assume that the restrictions applied to the representation of pre- and post-conditions in an ontological rule are similar to those for the pre- and post-conditions of an attack (i.e., they do not include disjunctions).

### Generalization of Definition 2

The next step is to generalize Definition 2 when ontological rules are used for correlation. This generalization is performed in two steps:

1. **Generalize Definition 2**: We extend Definition 2 to apply to the correlation of two ontological rules, an attack with an ontological rule, or an ontological rule with an attack. Given that the syntactical format of the pre- and post-conditions of an attack is similar to that of an ontological rule, this generalization is straightforward.

2. **Introduce Indirect Correlation**: We introduce the concept of indirect correlation, defined as follows:

   **Definition 3: Indirect Correlation**
   
   We say that attack A and attack B are indirectly correlated through ontological rules R1, …, Rn if the following conditions are satisfied:
   - Attack A is directly correlated with rule R1 through a most general unifier θ0.
   - For each j in [1, n-1], rule Rj is directly correlated with rule Rj+1 through a most general unifier θj.
   - Rule Rn is directly correlated with attack B through a most general unifier θn.

Using Definition 3, we can conclude that attack "MIR-0073" (TCPScan) is indirectly correlated with attack "MIR-0036" (Winnuke). This is because the post-condition of "MIR-0073" is `knows(Source_user, use_service(Target_address, Target_service))`. The pre-condition of "RULE-0001" is `use_service(System_address, 'NetBios')`, so "MIR-0073" is directly correlated to "RULE-0001" through the mgu:
- `Target_address = System_address, Target_service = 'NetBios'`.

Similarly, the post-condition of "RULE-0001" is `use_os(System_address, windows)`. Since this predicate matches the pre-condition of "MIR-0036", the indirect correlation is established.

### Automatic Generation of Correlation Rules

All correlation rules are automatically generated by analyzing the descriptions in LAMBDA of the set of attacks. This process is performed offline, making it non-time-consuming for online intrusion detection.

### Applying Correlation Rules

After generating all correlation rules offline, the online correlation process can begin. When a new alert `Alert1` is received, the process proceeds as follows:

1. **Check for Existing Alerts**: Let `Attack1` be the classification associated with `Alert1`. We first check if there are other alerts already stored in the database with a classification `Attack2` such that `attack_correlation(Attack1, Attack2)` or `attack_correlation(Attack2, Attack1)` is stored in the correlation base. This step is for optimization, as it filters on the `attack_correlation` predicate to identify potentially correlated alerts.

2. **Apply Correlation Rules**: If there are alerts `Alert2` that are potentially correlated with `Alert1`, the corresponding correlation rules are applied to check if the correlation conditions are satisfied. The result is a set of pairs of alerts that are correlated, one member of these pairs being `Alert1`.

3. **Aggregation or New Scenario**: For each pair in this set, we apply an algorithm to check if the pair can be aggregated into an existing scenario. If not, a new scenario starting with this pair of alerts is generated.

For example, if there is already a scenario with three alerts (`alert1, alert2, alert3`), and a new alert `alert4` is received, and the online correlation process generates a pair `(alert3, alert4)`, a longer scenario `(alert1, alert2, alert3, alert4)` is generated.

### Handling Complex Scenarios

A complex scenario with several branches is decomposed into multiple sequential scenarios, each corresponding to a branch. The graphic interface will aggregate these sequential scenarios. For each sequential scenario, the online correlation process generates a special alert called a "scenario alert," which is fully compliant with the IDMEF format.

### Abductive Correlation

There are still some challenges in applying our online correlation process. For instance, consider the attack scenario presented in Figure 7, which we call "illegal NFS mount." This attack enables the intruder to gain root access by exploiting a misconfiguration in the security policy. There are six different steps in this attack, and both Snort and e-Trust did not detect step 5 ("MIR-0164": `attack_rhost`).

To address this, our approach is to abduce a new (virtual) alert corresponding to `attack_rhost`. The classification field of this virtual alert is initialized to "MIR-0164," and other fields are initialized using Skolem constants. The detect time field must satisfy the constraint that it is after the alert corresponding to `attack_mount` and before the alert corresponding to `attack_rlogin`.

### Example of Attack Scenario

**Figure 6: Example of attack scenario**

The "Correlationalert" field of this alert corresponds to the list of correlated alerts (the order in this list is important). Other fields of this alert are generated by merging data from the correlated alerts.

### Intrusion Scenario and Detection Results

**Figure 7: "Illegal NFS Mount" scenario**

These six steps are specified in LAMBDA, and when the offline correlation process is applied, six correlation rules are obtained, as shown in Figure 8. `cond1, …, cond6` correspond to the six correlation conditions associated with these rules.

**Figure 8: Results of correlation process on attack "illegal NFS mount"**

By e-Trust, our clustering function gives five clusters. Both Snort and e-Trust did not detect step 5. The results are provided to the correlation function for further analysis, with the objective of correlating these five clusters to recognize a single complex attack.

This structured and detailed approach ensures clarity and coherence in explaining the system's functionality and limitations.