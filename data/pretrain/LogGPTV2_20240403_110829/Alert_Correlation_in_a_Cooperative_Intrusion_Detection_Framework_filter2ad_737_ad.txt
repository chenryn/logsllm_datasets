6  Notice  that  our  approach  does  not  apply  to  the  case  where  the
detection field of attacks corresponds to combined events. It is restricted
to detection scenarios that are single events.
7 Defining an algorithm to optimize correlation rules might be done.
But, the overhead due to this lack of optimization is marginal so that we
do not find that such an optimization is a priority.
use_service(System_address,’NetBios’)
use_os(System_address,windows)
Figure 4: Example of ontological rule
From  a  syntactical  point  of  view,  we  assume  that
restrictions that apply to the representation of pre and post
conditions in an ontological rule are similar to the one for
pre and post conditions of an attack (that is, they do not
include disjunction).
Next  step  is  then  to  generalize  definition  2  when
ontological  rule  are  used  to  perform  correlation.  This
generalization  is  done  in  two  steps.  We  first  generalize
definition 2 so that it applies to correlate two ontological
rules  or  an  attack  with  an  ontological  rule  or  an
ontological rule with an attack. Since we assume that the
syntactical  format  of  the  pre  and  post  conditions  of  an
attack  is  similar  to  the  one  of  an  ontological  rule,  this
generalization is straightforward.
We then introduce the notion of indirect correlation. It
is defined as follows:
Definition 3: Indirect correlation
We  say  that  attack  A  and  attack  B  are  indirectly
correlated  through  ontological  rules  R1,  …,  Rn  if  the
following conditions are satisfied:
•  Attack A is directly correlated with rule  R1 through a
most general unifier θ0,
•  For each j in [1,n-1], rule Rj is directly correlated with
rule Rj+1 through a most general unifier θj,
•  Rule Rn is directly correlated with attack B through a
most general unifier θn.
of 
attack 
Using  definition  3,  we  can  now  conclude  that  attack
“MIR-0073”  (TCPScan)  is  indirectly  correlated  with
attack “MIR-0036” (Winnuke). This is because the post-
condition 
to
knows(Source_user,use_service(Target_address,Target_s
ervice)).  Then,  since  the  pre-condition  of  “RULE-0001”
is 
to  use_service(System_address,’NetBios’),
“MIR-0073”  is  directly  correlated  to  “RULE-0001”
through the mgu:
•  Target_address  =  System_address,  Target_service  =
“MIR-0073” 
equal 
is 
equal 
‘NetBios’
Similarly, the post-condition of “RULE-0001” is equal
to use_os(System_address,windows). Since this predicate
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
  correlation_rule(Alert1,Alert2) :-
cond_detection(Attack1),
cond_detection(Attack2),
θ0, …, θn.
For  example,  figure  5.b  presents  the  correlation  rule
corresponding  to  attacks  “MIR-0073”  (TCPScan)  and
“MIR-0036” (Winnuke).
Notice  that  all  the  correlation  rules  are  automatically
generated  by  analyzing  the  descriptions  in  LAMBDA  of
the  set  of  attacks.  This  process  is  performed  offline  and
therefore,  it  is  not  time  consuming  for  online  intrusion
detection.
4.5. Applying correlation rules
After all the correlation rules are generated offline, the
online  correlation  process  can  start.  When  this  process
receives a new alert Alert1, it proceeds as follows.
Let  Attack1  be  the  classification  associated  with
Alert1.  In  a  first  step,  we  check  if  there  are  other  alerts
already stored in the database and whose classification is
Attack2 such that the fact attack_correlation(Attack1,Attack2)
or  attack_correlation(Attack2,Attack1)  is  stored  in  the
correlation  base.  Notice  that  this  first  step  is  only  for
optimization  since the correlation  rules  might  be  applied
directly.  However  it  is  more  efficient  to  first  filter  on
predicate  attack_correlation  to  check  if  there  are  alerts
that  are  potentially  correlated  to  Alert1.  Notice  that  we
both  look  for  facts  attack_correlation(Attack1,Attack2)
and  attack_correlation(Attack2,Attack1)  because  we  do
not assume that the alerts are received in the  same order
as their order of occurrence.
If there are alerts Alert2 that are potentially correlated
with  Alert1,  then  the  corresponding  correlation  rules
apply to check if the correlation  conditions  are  satisfied.
The result is a set of pairs of alerts that are correlated, one
member of these pairs being Alert1.
For each pair in this set, we then apply an algorithm to
check  if  this  pair  might  be  aggregated  to  an  existing
scenario.  Else,  a  new  scenario  starting  with  this  pair  of
alerts is generated. For instance, let us assume that there
is  already  a  scenario  with  three  alerts  (alert1,  alert2,
alert3). Let us assume that alert4 is received and that the
online correlation process generates a pair (alert3, alert4).
In  this  case,  a  “longer”  scenario  (alert1,  alert2,  alert3,
alert4) is generated.
Notice that  a  complex  scenario  with  several  branches
is  actually  decomposed  into  several  sequential  scenarios
corresponding  to  each  branch.  For  instance,  let  us
consider  the  scenario  presented 
is
represented  by  two  sequential  scenarios  (alert1,  alert2,
alert3,  alert4)  and  (alert2,alert5,alert6,alert4).  It  will  be
the role of the graphic interface to “aggregate” these two
sequential scenarios as presented in figure 6 (see annex 1
for a short presentation of this interface).
in  figure  6.  It 
For  each  sequential  scenario,  the  online  correlation
process  generates  a  special  alert  called  “scenario  alert”.
This  alert  is  fully  compliant  with  the  IDMEF  format.
alert_correlation(Alert1,Alert2) :-
alert_correlation(Alert1,Alert2) :-
  alert(Alert1),
  source(Alert1,Source1),
  source_user(Source1,Source_user1),
  target(Alert1,Target1),
  target_node(Target1,Target_node1),
  address(Target_node1,Target_address1),
  classification(Alert1,"MIR-0163"),
  alert(Alert2),
  source(Alert2,Source2),
  source_user(Source2,Source_user2),
  target(Alert2,Target2),
  target_node(Target2,Target_node2),
  address(Target_node2,Target_address2),
  target_user(Target2,Target_user2),
  classification(Alert2,"MIR-0164"),
  Source_user1 = Source_user2,
  Partition1 = Partition2.
  alert(Alert1),
  source(Alert1,Source1),
  source_node(Source1,Source_node1),
  address(Source_node1,Source_address1),
  source_user(Source1,Source_user1),
  target(Alert1,Target1),
  target_node(Target1,Target_node1),
  address(Target_node1,Target_address1),
  target_service(Target1,Target_service1),
  classification(Alert1,"MIR-0073”),
  alert(Alert2),
  source(Alert2,Source2),
  source_node(Source2,Source_node2),
  address(Source_node2,Source_address2),
  target(Alert2,Target2),
  target_node(Target2,Target_node2),
  address(Target_node2,Target_address2),
  classification(Alert2,"MIR-0036"),
  Target_address1 = System_address3,
  Target_service1 = ‘NetBios’,
  System_address3 = Target_address2.
Figure 5.a: Correlation rule for “MIR-0163”
Figure 5.b: Correlation rule for
NFSMount) and “MIR-0164” (Modification of .rhost)
“MIR-0073” (TCPScan) and “MIR-0036” (Winnuke)
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
alert1
alert2
alert3
alert4
attack-rpcinfo
cond1
attack-showmount
cond3
alert5
alert6
attack-finger
cond2
attack-mount
cond4
cond5
attack-rhost
cond6
attack-rlogin
Figure 8: results of correlation process on attack
“illegal NFS mount”
by  e-Trust.  Our  clustering  function  gives  5  clusters.
Actually, both Snort and e-Trust did not detect step 5.
This result is then provided to the correlation function
for further analysis, the objective being to correlate these
5 clusters in order to recognize one single complex attack.
The  main  difficulty  to  fully  recognize  multiple  steps
attack “illegal NFS mount” comes from the fact that step
5  (“MIR-0164”:  attack_rhost)  is  not  detected  by  both
Snort and e-Trust. Our approach to solve this problem is
the following.
one 
to 
receives 
one 
The 
correlation 
function 
corresponding 
alert
corresponding to attack  “MIR-0163”  (attack_mount)  and
another 
“MIR-0165”
(attack_rlogin). Since the correlation function knows that
it is possible to correlate attack_mount  with attack_rhost
and  then  attack_rhost  with  attack_rlogin,  the  correlation
function  makes  the  hypothesis  that  it  is  possible  to
transitively correlate attack_mount with attack_rlogin8. In
this case, the approach is to abduce9 a new alert that is to
create a new (virtual) alert corresponding to attack_rhost.
When  this  virtual  alert  is  generated,  its  classification
field  is  initialized  to  “MIR-0164”  (corresponding  to
attack_rhost). All the other fields are initialized by using
Skolem  constants10.  For  instance,  the  target  field  is
initialized  to  “target(1)”  meaning  that  the  target  of  this
alert exists but is  currently  unknown.  The  case  of  detect
time field is slightly more complex. It is partly unknown
but must satisfy the following constraint: it must be after
the  alert  corresponding  to  attack_mount  and  before  the
alert corresponding  to  attack_rlogin.  The  solution  in  this
8  Similar  reasoning  applies  to  transitively  correlate  attack_finger
with attack_rlogin.
9 Abduction consists is making new hypotheses and to use them to
derive new facts. Typically, this kind of reasoning is used when facts are
missing to complete a diagnostic.
10 Skolemization is a process used to replace expressions having the
form ∃ x, p(x) by p(α) where α is a Skolem constant.
Figure 6: Example of attack scenario
The “Correlationalert” field of this alert corresponds to
the  list  of  correlated  alerts  (the  order  in  this  list  is
important!). The other fields of this alert are generated by
using the merging function to merge data contained in the
correlated  alerts  (see  [3]  for  more  details  about  the
merging function).
5. Abductive correlation
There are still some problems that arise when we apply
our  online  correlation  process.  For  instance,  let  us
consider the attack scenario presented in figure 7. We call
this  attack  “illegal  nfs  mount”.  This  attack  scenario
enables  the  intruder  to  get  a  root  access  by  exploiting  a
misconfiguration  in  the  security  policy,  namely  the
intruder can mount a partition corresponding to the home
directory of root. There are 6 different steps in this attack.
Intrusion scenario
Detection results
Step 1 : attack_finger
finger root
Step 2 : attack_rpcinfo
rpcinfo 
Step 3 : attack_showmount
showmount 
Step 4 : attack_mount
mount directory
Step 5 : attack_rhost
cat “++” > .rhost
Step 6 : attack_rlogin
rlogin 
Snort
eTrust
Snort 
eTrust 
Snort 
eTrust 
Snort 
eTrust 
: 3 alerts
: 0 alert
: 1 alert
: 1 alert
: 1 alert
: 0 alert
: 1 alert
: 0 alert
Not detected
Snort 
eTrust 
: 1 alert
: 1 alert
Fusion
results
CRIM : 1 alert
CRIM : 1 alert
CRIM : 1 alert
CRIM : 1 alert
CRIM : 1 alert
Figure 7: “Illegal NFS Mount” scenario
These 6 steps are specified in Lambda so that when we
apply  the  offline  correlation  process,  we  obtain  6
correlation  rules  as  shown  in  Figure  8.  cond1,  …  cond6
correspond to the 6 correlation conditions associated with
these correlation rules.