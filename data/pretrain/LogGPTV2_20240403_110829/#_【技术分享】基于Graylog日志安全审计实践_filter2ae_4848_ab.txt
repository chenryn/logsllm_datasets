        @getRequest:(req_url) =>
            body, status_code, headers = http.simple {
                url: req_url 
                method: "GET"
                headers: self.headers_info 
            }
            return body
        @checkParam:(s_type, s_param) =>
            --检查配置信息
            if type(self.url) == "nil"
                return 'auth info err.'
            --检查端末类型
            info = self.endpoints[s_type]
            chk_flg = type(info)
            if chk_flg == "nil"
                return "Input parameter error,unknow type."
            key = ''
            for k,v in pairs info
                key = k 
            --检查查询参数有效性
            str = ''
            for k,v in pairs info[key]
                if type(s_param[v]) == 'nil'
                    return info[key][k]..":is nil"
                str = str..s_param[v]
            return "OK", str
        @call: (s_type, s_param) =>
            key = ''
            for k,v in pairs self.endpoints[s_type]
                key = k 
            --参数打包成URL
            url_data = ngx.encode_args(s_param)
            tmp_url = self.url..key.."?"
            req_url = tmp_url..url_data
            --转发用户HTTP请求给GraylogRest服务。
            ret = selfgetRequest req_url
            return ret
        @dealStream: (s_type, s_param) =>
            ret = ''
            status, param_list = GMoonSDKcheckParam s_type, s_param
            if status == "OK"
                ret = GMoonSDKcall s_type, s_param
            else 
                ret = status 
            return ret
SDK完成后，我们在Nginx+Lua上用Lapis创建一个WEB服务，做REST API数据请求转发。
    class App extends lapis.Application
      "/testcase": =>
        --准备对应REST的输入参数，如果相应该有的项目没有设定会输出NG原因。
        param_data= {
            fields:'username',
            limit:3,
            query:'*',
            from: '2017-01-05 00:00:00',
            to:'2017-01-06 00:00:00',
            filter:'streams'..':'..'673b1666ca624a6231a460fa'
        }
        --进行鉴权信息设定
        url  = GMoonSDKauth 'supervisor', 'password', '127.0.0.1', '12600'
        --调用对应'TYPE'相对应的REST服务，返回结果。
        ret = GMoonSDKdealStream 's_ua', param_data
        ret
上文提到 ‘TYPE’， 其实就是对Endpoints的一种编号，基本上和GrayLog REST API是一对一关系。
    endpoints: {
            's_uat':{'/search/universal/absolute/terms':{'field', 'query', 'from', 'to', 'limit'} }
            's_ua':{'/search/universal/absolute':{'fields', 'query', 'from', 'to', 'limit'} }
            's_urt':{'/search/universal/relative/terms':{'field', 'query', 'range'} }
            's_ut':{'/search/universal/relative':{'fields', 'query', 'range'} }
        }
理论上说，可以个修改以上的数据结构，对应各种REST API的服封装(GET),只要知道对应URL与可接收的参数列表。
**4-2. Dashboard的Widget数据更新**
Graylog数据管理概念图
Graylog抽象出Input、Stream、Dashboard这些自己原生的日志管理概念，是基于对日志数据一种新的组织化分，我们通过Graylog中一个叫Dashboard方法，对某一类日志数据，进行Top10排序，
例如：对5分钟之内端口访问量最多的10个用户进行排序。
     rglog = require "GRestySDK"
      data = '{
       "description": "scan-port",
       "type": "QUICKVALUES",
       "config": {
         "timerange": {
           "type": "relative",
           "range": 123
         },
         "field": "port",
         "stream_id": "56e7ab11fd624ca91defeb11",
         "query": "username: graylog",
         "show_data_table": true,
         "show_pie_chart": true
       },
       "cache_time": 3000
     }
     '
      url  = rglogauth 'admin', 'password', '0.0.0.0', '12345'
      rglogupdateWidget('57a7bc60be624b691feab6f','019bca13-50cf-481e-a123-a0d2e649b41a',data)
Graylog在收到这个请求后，会数某日志数据，进行快速统计排序， 把Top10的统计数据，用饼图的形式画出来。
**4-3.REST API定制新审计后台与可视化展示**
如果你不想用Kibanna、Grayglog
Dashboard，想实现自己的一套审计工具后台，或是情态感知的可视化大屏幕，可通过基于自己习某用开发的语言，开发一套SDK进行接功能扩展，实现自己定制的可视化感知系统。
**五. 反扫检查**
威胁情报可视化，一直以来对安全人员分析安全事件起着有益的作用，
可视化是对分析的结果一种图形化的映射，是威胁行为的一种图形具象化。针对蜜罐日志分析的流程来讲，溯源和展示攻击行为本身也是很重要的，我们可以结合Graylog可视化与REST
API自动检测，与honeypot和扫描器结果结合分析，发现来至内部的扫描形为。
蜜罐向类似mysql这种库中写入被访问的IP地址和Port，启动定时任 务读取数据库，取出数据库当条目总数，与之前本地保存的最大数进行比较 发现，数据库
中的日志记录变多了，就将这些数据取出，进行分析和报警。这是一种基于Mysql存储和蜜罐威胁事件结合的方式。
另一种方式是依赖ips,ids这种设备，对网段内的所有蜜罐的流量进行监控，发现有任何 触发蜜罐的访问就进行数据的报警分析，不好的地方是，除了要依赖这些设备
，ids和ids 本身对蜜罐被访问策略控制比较单一,另外如果想进一步的想取得访问的payload也需要与ids
，ips再次交互取，不同产商的设备特点不统一。
所以产生了，第三种Graylog与Honeypot结合反扫检查的方案，通过Graylog提供RESTAPI，自动化统计日志数据，通过Graylog
Dashboard功能统计端口访问量大的ID、IP，将Honepot日志与Graylog数据进行对撞分析，再与扫描器记录下每台服务器的开放的端口指纹做比较，如果访问了端口指纹里没有开放的端口，并且还有触发蜜罐的历史，可以加强定位为是威胁。
上图就是通过Graylog
Dashboard返回的端口访问量前三的用户的可视化图。User1明显为描扫行为，User2是可以行为，User3是正常访问行为。
**6.总结**
我们将Graylog作为一个可扩展的数据容器来使用，因为Graylog
REST的这个基础功能，让他从一个数据管理工具升级为数据平台。日志千变万化，行为迥异不同，Graylog只是众多日志数据管理产品中的一个，Graylog依靠开源免费表现优异的特点，越来越被人们接受。Graylog可能会在一次次产品升级过程中升级完善，也可能被更好的新产品夺走注意力，但是我们基于某种工具上实践思路是可以延续的，名词术语变了，应用模式依然有生命力，开放的思路，更益于工具的使用，借这篇向大家介绍Graylog一点实践应用思路。