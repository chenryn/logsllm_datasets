### Multi-class Classifier Accuracy under Different ε Settings

**Figure 1: Multi-class Classifier Accuracy under Different ε Settings**

- **(a) Keystroke Timing Attack**
- **(b) Website Inference Attack**

The dashed horizontal lines in the figure represent the accuracy of blind guesses based on the likelihood of each class. For keystroke timings, the most likely class occurred approximately 44% of the time. As shown in the graph, setting ε ∈ [1, 3] is sufficient to reduce the classifier's accuracy to this baseline. In contrast, the classifier achieved perfect accuracy (1.0) when no noise was added.

### 6.1.2 Mitigating Website Inference

The memory footprint of a browser can reveal the website it visits, as discussed in Section 3.1. In this experiment, we instrumented the Google Chrome browser with a script to visit a target website, chosen uniformly from the Alexa top-10 websites. During this process, an attacker repeatedly sampled the data resident size field (drs), calculated as totalVM - sharedVM, by reading the `/proc/<pid>/statm` of the browser process every 500 µs. To support this sampling rate, `dpprocfs` employed the heuristic method of invariant reestablishment (Section 5.3), which returned results in approximately 50 µs (compared to 8 ms for the nearest solution). The sampling period lasted for 3 seconds, during which the attack process recorded all the drs field values read.

The attacker estimated the true (unnoised) drs value corresponding to the j-th read value in each 3-second interval using an empirical distribution observed for these j-th values gathered by accessing each of the 10 websites an equal number of times. The attacker then constructed a histogram of these estimated drs values, binned into seven equal-width bins, and used the vector of bin counts (in N7) as a feature vector for classification. Each of the Alexa top-10 websites was visited 100 times; 70% of the data were used for training and 30% for testing the SVM classifier (with m = 10 classes).

**Figure 1(b):** The resulting accuracy of the classifier is shown in Figure 1(b). The key difference from Figure 1(a) is that the values of ε needed to interfere with the website inference attack are much smaller, indicating that more noise was added. This is primarily due to the larger differences between drs readings from the m classes compared to the differences between the readings of the voluntary context switch counter (nvcsw) with and without a keystroke. In terms of d*, the distances between the classes in the website inference attack were much greater than those in the keystroke attack. This implies that the settings of ε needed for privacy will vary per-field and per-application and, to some extent, need to be informed by known attacks. Several tested values of ε significantly reduced classification accuracy; with no noise added, the classifier reached 0.915 accuracy.

### 6.2 Utility Evaluation

We evaluate the utility of `dpprocfs` in two ways:

1. **Relative Error:** We measure the relative error of selected `procfs` outputs that are calculated using fields protected by `dpprocfs`, under the two methods discussed in Section 5.3 for enforcing invariants: producing a heuristic solution and a nearest solution to the invariants.
2. **Impact on Process Ranking by `top`:** We report the impact of `dpprocfs` on the ranking of processes according to certain features by `top`, a common utility for monitoring and diagnosis. Here, we focus on `dpprocfs` outputs such as memory and CPU usage, as these are generally useful system diagnostics.

#### 6.2.1 Relative Error

To evaluate the relative error of the drs field, we preserved access to an unprotected version of `procfs` alongside the protected version. We extended our setup to simultaneously query both the protected and unprotected versions of the drs field while the browser process was running. The browser was instrumented to repeatedly visit `https://www.youtube.com`, and the drs field was queried every 50 ms for a total of 500 queries. This experiment was repeated 200 times.

**Figure 2:** Comparison between nearest and heuristic invariant reestablishment for the drs field; ε = 0.005. The figure shows the distribution of relative error for both the nearest and heuristic solutions for reestablishment, computed on the same noised values ˜x produced by `privfs`. Each query range on the horizontal axis has two box-and-whiskers plots, one for nearest and one for heuristic. The three horizontal lines forming each box indicate the first, second (median), and third quartiles, and the whiskers extend to cover all points within 1.5× the interquartile range. Outliers are indicated using plus ("+") symbols. A different box-and-whiskers plot is shown per 100-query block across the 200 runs (i.e., each boxplot represents 20,000 points) because the noise increases as the number of queries grows. The differences between the nearest and heuristic distributions are nearly imperceptible, and this trend holds for other parameter and `procfs` fields we have explored. However, the heuristic solution relies on hand-tuned algorithms and provides no guarantees. In cases where the speed of computing the nearest solution is acceptable (the nearest solution took an average of 8 ms to return, whereas our heuristic approach completed in an average of 50 µs), it might be preferable.

**Figures 3 and 4:** These figures represent the relative error in readings of the drs field and the utime field from the `/proc/<pid>/stat` file, respectively, for various values of ε. The values of ε in Figure 3 were chosen to overlap those used in the security evaluation depicted in Figure 1(b). The ε values tested in Figure 4 were chosen based on our simulation of the software-keyboard side-channel attack of Lin et al. [28], conducted on a Nexus 4 smartphone running Android 5.1 with kernel 3.4.0. Based on this simulation, we estimated that ranging ε over 1/2 ≤ ε ≤ 5 would result in a curve similar to or better (with lower accuracy) than that in Figure 1(a). In the tests in Figure 4, the utime field was queried every 50 ms while a video game was running. These graphs suggest that the relative error is typically modest, e.g., with a third quartile of < 15% in Figure 3 and < 30% in Figure 4, though outliers can be large.

#### 6.2.2 Rank Accuracy of `top`

`top` is a utility used by Linux administrators for performance monitoring and diagnosis. By reading `procfs`, `top` displays system information like memory and CPU usage of running processes. The processes are ranked by `top` according to a chosen field. In this section, we evaluate the utility of `dpprocfs` by measuring the rank accuracy of `top` when run using `dpprocfs` in place of the original `procfs`.

To measure the rank accuracy, we ran two `top` processes on one computer. These two `top` processes were started at the same time and updated information with the same frequency (every two seconds in our tests). The only difference was that one `top` process read from `dpprocfs` (with heuristic invariant reestablishment), and the other read from `procfs` in its original form. To control the test workload in each experiment, we ran a set of ten processes performing floating-point operations.

**Figure 5:** The figure shows the rank accuracy of `top` for different numbers of queries. The x-axis represents the number of queries, and the y-axis represents the accuracy of the top ranks (Top 1, Top 3, Top 5, and Top 10).