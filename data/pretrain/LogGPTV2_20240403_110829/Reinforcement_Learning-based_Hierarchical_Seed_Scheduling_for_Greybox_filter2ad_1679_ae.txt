overhead is lower than 10%. On AFL++-based prototype, we
observed lower performance overhead, as shown in Figure 9.
Next, we measured the throughput of AFL-HIER versus
AFL and AFLFAST on CGC benchmarks. Figure 6 shows the
ratio of AFL-HIER’s throughput over AFL and AFLFAST in an
ascending order. The x-axis represents different CGC binaries
while the y-axis shows the ratio within a 95% conﬁdence
in logarithmic scale. Surprisingly, AFL-HIER only leads to
a lower throughput for about a quarter of the binaries; and
for another quarter of the binaries, AFL-HIER’s throughput is
at least twice as AFLFAST’s. This indicates that the speciﬁc
optimizations for AFL-HIER act very well. A similar trend
is also observed on the AFL++-based prototype, as shown
in Figure 8.
E. RQ 4. Performance Boost via Hierarchical Seed Scheduling
(cid:63) Experiment results on CGC and FuzzBench bench-
marks demonstrate that our hierarchical seed scheduler
dramatically reduces the number of candidates to be
examined.
Previous experiments already show that our hierarchical
seed scheduler is more suitable for highly sensitive coverage
metrics, as AFL-HIER can achieve higher coverage faster
than AFL-FLAT and ﬁnd more bugs. In this evaluation, we
12
0.00.20.40.60.81.0time0.00.20.40.60.81.0number of edges15m30m1h2h4h6h7500100001250015000175000.72  0.50freetype2-201715m30m1h2h4h6h5000600070008000*0.22  *0.00harfbuzz-1.3.215m30m1h2h4h6h100015002000*0.25  *0.86lcms-2017-03-2115m30m1h2h4h6h26002800300032003400*0.18  0.22libjpeg-turbo-07-201715m30m1h2h4h6h145015001550160016500.51  *0.93libpng-1.2.5615m30m1h2h4h6h3000400050006000*0.11  *0.00libxml2-v2.9.215m30m1h2h4h6h800010000120001400016000*0.72  *0.93openssl_x50915m30m1h2h4h6h50005200540056005800*0.97  *0.94openthread-2019-12-2315m30m1h2h4h6h18000200002200024000260000.69  *1.00sqlite3_ossfuzz15m30m1h2h4h6h1900200021000.39  0.39vorbis-2017-12-1115m30m1h2h4h6h5000550060006500*0.00  *0.83bloaty_fuzz_target15m30m1h2h4h6h15000155001600016500170000.44  0.19curl_curl_fuzzer_http15m30m1h2h4h6h3004005006000.50  0.50jsoncpp_jsoncpp_fuzzer15m30m1h2h4h6h01000200030000.58  *0.72libpcap_fuzz_both15m30m1h2h4h6h760078008000*0.79  0.56mbedtls_fuzz_dtlsclient15m30m1h2h4h6h10002000300040005000*0.94  *0.89proj4-2017-08-1415m30m1h2h4h6h2000250030003500*0.00  *0.00re2-2014-12-0915m30m1h2h4h6h625630635640*0.92  0.50systemd_fuzz-link-parser15m30m1h2h4h6h80010001200140016001800*0.78  0.35woff2-2016-05-0615m30m1h2h4h6h6008001000*1.00  *0.89zlib_zlib_uncompress_fuzzerafl++afl++-flatafl++-hierTABLE II: Unique edge coverage between aﬂ++ (Qemu) and
aﬂ++-hier (Hier) on FuzzBench benchmarks. The coverage is
union over different runs.
Benchmark
bloaty_fuzz_target
curl_curl_fuzzer_http
freetype2-2017
harfbuzz-1.3.2
jsoncpp_jsoncpp_fuzzer
lcms-2017-03-21
libjpeg-turbo-07-2017
libpcap_fuzz_both
libpng-1.2.56
libxml2-v2.9.2
mbedtls_fuzz_dtlsclient
openssl_x509
openthread-2019-12-23
proj4-2017-08-14
re2-2014-12-09
sqlite3_ossfuzz
systemd_fuzz-link-parser
vorbis-2017-12-11
woff2-2016-05-06
zlib_zlib_uncompress
Total Hier - Qemu Qemu - Hier
102417
143182
56114
13073
2583
12817
18486
11800
5944
89852
32046
115381
42901
10434
5904
48181
4167
6372
6401
1664
674
114
1227
124
0
33
237
195
54
210
102
14
0
67
100
965
0
4
8
0
1880
24
203
774
58
0
36
0
141
6
52
142
26
344
109
2
0
8
54
24
Fig. 7: Overhead of AFL-HIER Scheduler on CGC bench-
marks.
Fig. 6: Comparison between Throughput of AFL-HIER, AFL,
AFLFAST and AFL-FLAT on CGC benchmarks.
investigate the number of seeds generated by each fuzzer
to validate that such improvement is indeed caused by the
scheduler. Figure 10 shows the number of seeds generated by
each fuzzer on the left side, as well as the number of nodes
at different levels of the tree in AFL-HIER on the right side.
The y-axis is in logarithmic scale. We can observe that due
to the increased sensitivity of distance metric CD, both AFL-
HIER and AFL-FLAT selected one magnitude more seeds than
AFL and AFLFAST, which uses edge coverage with hit count.
However, by clustering the seeds in a hierarchical structure,
AFL-HIER dramatically reduced the number of candidates to
examine when scheduling. Speciﬁcally, on average there are
about 21 + 1102/21 + 2350/1102 + 2608/2350 ≈ 77 exami-
nations to perform for each scheduling, which is signiﬁcantly
less than examining 2608 seeds. As a result, even with the
most number of seeds (more than AFL-FLAT), AFL-HIER can
still balance exploration and exploitation and achieve better
Fig. 8: Comparison between Throughput of AFL++-HIER,
AFL++, and AFL++-FLAT on FuzzBench benchmarks.
fuzzing performance (in terms of coverage and detected bugs)
than baseline fuzzers.
On FuzzBench benchmarks, we also observed a similar
level of reduction, as shown in Figure 11. More importantly,
we can see that our scheduling algorithm can scale to larger
programs with signiﬁcantly more edges and more saved seeds.
As shown in Table II, all
least
thousands of edges in total, and some even contain more than
one hundred thousand edges.
the benchmarks have at
F. RQ 5. Hyper-parameters
(cid:63) Experiment results on CGC benchmarks demonstrate
that the hyper-parameters will affect the performance in
terms of crashes and edge coverage.
As discussed in §IV-B, the seed scoring involves two hyper-
parameters. One is w in Equation 4 that determines how much
13
binaries10%20%50%100%200%500%1000%throughput ratioafl-hier vs aflafl-hier vs aflfastafl-hier vs afl-flatruns0%2%4%6%8%10%12%14%overhead proportionbinaries20%50%100%200%500%throughput ratioafl++-hier vs afl++afl++-hier vs afl++-flatFig. 9: Overhead of AFL++-HIER Scheduler on FuzzBench
benchmarks.
Fig. 10: Number of Seeds and Nodes on CGC benchmarks.
we will decrease weights to old rewards when calculating the
mean reward. The other one is C in Equation 5 that controls
the trade-off between seed exploration and exploitation. In
this evaluation, we investigate when they are set to different
values, how the fuzzing performance will vary. Table III
and Table V show the average number of crashed binaries and
covered edges with different values of C and w, respectively.
In addition, we also investigate the number of binaries uniquely
crashed as shown in Table IV and Table VI, where each cell
represents the number of binaries that have been crashed by
the setting of the row once but never by the setting of the
column. We can observe that different settings will lead to
different results.
Notably, when C is set to 0, which extremely encourages
it uniquely crashes the most binaries, but on
exploitation,
average,
it crashes the least. This indicates that although
keeping exploitation may help to trigger a crash at the end of a
14
Fig. 11: Number of Seeds and Nodes on FuzzBech bench-
marks.
TABLE III: Average number of crashed CGC binaries and
mean edge coverage with different values of hyper-parameter
C.
Value of C
Crash
Edge Cov
0
74
776
0.014
75
667
0.14
75
748
1.4
76
727
14
75
746
seed chain in one run, it also takes the risk of being trapped in
fuzzing other seeds that previously have led to rarely explored
coverage, thus missing the crash in other runs. In other words,
high exploitation may do better in crash triggering than crash
reproducing. Meanwhile, the result of edge coverage indicates
that exploring more coverage may not be closely related to
bug detection as expected when under different conﬁgurations
of the relative strength of exploration and exploitation. For
example, setting C to 0.014 will lead to signiﬁcantly less
coverage, but it crashes almost the same number of binaries
as others.
In terms of the hyper-parameter w, note that a larger w
makes old rewards more weighted, thus encourages seed ex-
ploitation rather than exploration. We can observe that setting
w either too high (as 1.0) or too low (as 0.5) will lead to worse
coverage, while setting w to 0.5 will lead to signiﬁcantly more
unique crashes.
Overall, we can observe that when setting C to 1.4, w to
0.5, they perform reasonably well in average crashes, unique
crashes, and mean edge coverage. Thus we adapt these settings
in our current implementation.
G. RQ 6. Ability to Support other Coverage Metrics
(cid:63) Experiment results on the maze problem show that
our hierarchical scheduler can also improve the fuzzing
performance when using other sensitive coverage metrics.
As discussed in §III-A, it is very hard, if not impossible, to
use edge or even distance coverage to solve the maze problem
runs0%0.5%1%1.5%2%overhead proportionaflaflfastafl-flatafl-hier102050100200500100020005000100002000050000number of seeds & nodes18117824802608l1l2l32111022350afl++afl++-flatafl++-hier102050100200500100020005000100002000050000number of seeds & nodes20161450113199l1l2l3731933213191TABLE IV: Pairwise comparisons (row vs. column) of
uniquely crashed on CGC benchmarks with different values
of hyper-parameter C.
Value of C 0
-
0
3
0.014
0.14
4
1.4
3
14
3
0.014
0.14
8
-
4
7
3
7
2
-
7
2
1.4
4
3
5
-
4
14
9
4
5
9
-
TABLE V: Average number of crashed CGC binaries and mean
edge coverage with different values of hyper-parameter W.
Value of W 0.10
Crash
74
Edge Cov
698
0.25
73
758
0.50
76
727
0.75
72
666
0.90
75
739
1.00
75
660
(Listing 1). However, it is possible to solve it using memory
sensitivity CA (see §III-D2 for details). In this experiment, we
investigate whether our hierarchical scheduler can also boost
the performance of coverage metrics other than code-related
coverage. Speciﬁcally, we conﬁgured AFL-FLAT and AFL-
HIER to use memory access metric CA instead of distance
metric CD and evaluate the two fuzzers on the maze problem.
Table VII shows the results. As we can see, compared to the
power scheduler used by AFL-FLAT, our hierarchical scheduler
allows AFL-HIER to solve the maze problem much faster.
This empirical result suggests that our scheduler is ﬂexible
to support different coverage metrics.
VI. RELATED WORK
A. Coverage Guided Greybox Fuzzing
Greybox fuzzing was introduced as early as in 2016 by
Sidewinder [16]. Since then it has been extensively used in
practice with the popularity of AFL [55] and LIBFUZZER [1].
Meanwhile, it has gained tremendous academic interest in var-
ious areas. On the one hand, various techniques including taint
tracking [12], [37], [46], symbolic execution [4], [41], program
transformation [23], [33], and deep learning [36], [40], are
incorporated into greybox fuzzing to boost its performance.
TABLE VI: Pairwise comparisons (row vs. column) of
uniquely crashed on CGC benchmarks with different values
of hyper-parameter W.
Value of W 0.10
0.10
0.25
0.50
0.75
0.90
1.00
-
1
8
2
4
4
0.25
5
-
11
4
5
6
0.50
2
1