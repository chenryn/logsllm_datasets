Attackers in our model submit malicious inputs (HTTP
requests) intended to probe and exploit known vulnerabilities
on victim web servers. Our system does not defend against
exploits of previously unknown (i.e., zero-day) vulnerabilities;
such protection is outside our scope.
Although the exploited vulnerabilities are known, we assume
that the attack payloads might be completely unique and
therefore unknown to defenders. Such payloads might elude
network-level monitors, and are therefore best detected at the
software level at the point of exploit. We also assume that
attackers might use one payload for reconnaissance but reserve
another for the ﬁnal attack. Misleading the attacker into
launching the ﬁnal attack is therefore useful for discovering
the ﬁnal attack payload, which can divulge attacker strategies
and goals not discernible from the reconnaissance payload
alone.
Attacker requests are processed by a server possessing
strictly user-level privileges, and must therefore leverage web
server bugs and kernel-supplied services to perform malicious
actions, such as corrupting the ﬁle system or accessing other
users’ memory to access conﬁdential data. The defender’s
ability to thwart these and future attacks stems from his
ability to deﬂect attackers to fully isolated decoys and perform
counterreconnaissance (e.g., attack attribution and information
gathering).
2.4 Background
Apache HTTP has been the most popular web server since
April 1996 [4]. Its market share includes 54.5% of all active
websites (the second, Nginx, has 11.97%) and 55.45% of the
top-million websites (against Nginx with 15.91%) [42]. It is a
robust, commercial-grade, feature-rich open-source software
product comprised of 2.27M SLOC mostly in C [44], and
has been tested on millions of web servers around the world.
These characteristics make it a highly challenging, interesting,
and practical ﬂagship case study to test our approach.
Process Checkpoint-restart. Process migration through
checkpoint-restart is the act of transferring a running process
between two nodes by dumping its state on the source and
resuming its execution on the destination. (A mechanism to
transfer the state between nodes is assumed.) Recently, there
has been growing interest in this problem, especially for high-
performance computing [27, 57]. As a result, several emerging
tools have been developed to support performance-critical
process checkpoint-restart (e.g., BLCR [20], DMTCP [3], and
CRIU [18]). Process checkpoint-restart plays a pivotal role
in making the honey-patch concept viable. In this work, we
have extended CRIU (Checkpoint/Restore In Userspace) [18]
with memory redaction and transparent relocation of TCP
connections to restore active attacker sessions in decoys without
disrupting the source web server.
Linux Containers. OS-level virtualization allows multiple
guest nodes (containers) to share the kernel of their control-
ling host. Linux containers (LXC) [39] implement OS-level
virtualization, with resource management via process control
groups and full resource isolation via Linux namespaces. This
ensures that each container’s processes, ﬁle system, network,
and users remain mutually isolated.
For our purposes, LXC oﬀers a lightweight sandbox that we
leverage for attacker session isolation. For eﬃcient container
management, we use the overlay ﬁle system to deploy con-
tainers backed by a regular directory (the template) to clone
new overlayfs containers (decoys), mounting the template’s
root ﬁle system as a read-only lower mount and a new private
delta directory as a read-write upper mount. The template
used to clone decoys is a copy of the target container in which
all sensitive ﬁles are replaced with disinformation.
3. ARCHITECTURE
The architecture of RedHerring is shown in Fig. 1. Central
to the system is a reverse proxy that acts as a transparent
proxy between users and internal servers deployed as LXC
containers. The target container hosts the honey-patched web
server instance, and the n decoys form the pool of ephemeral
containers managed by the LXC Controller. The decoys
serve as temporary environments for attacker sessions. Each
container runs a CR-Service (Checkpoint/Restore) daemon,
which exposes an interface controlled by the CR-Controller
for remote checkpoint and restore.
Honey-patch. The honey-patch mechanism is encapsulated
in a tiny C library, allowing for low-coupling between target
application and honey-patching logic. The library exposes
three API functions:
Listing 3: hp_fork function
1 void hp fork()
2 {
3
4
5
6
7
8
9 }
read context();
if (decoy) return;
register handler();
request fork();
wait();
save context();
//read context (target/decoy)
//if in decoy, do nothing
//register signal handler
//fork session to decoy
//wait until fork process has ﬁnished
//save context and resume
to the proxy: acquire (to acquire a container from the pool),
and release (to release back a container to the pool).
Each container follows the life cycle depicted in Fig. 2. Upon
receiving a fork request, the proxy acquires the ﬁrst available
container from the pool. The acquired container holds an
attacker session until (1) the session is deliberately closed by
the attacker, (2) the connection’s keep-alive timeout expires,
(3) the ephemeral container crashes, or (4) a session timeout
is reached. The last two conditions are common outcomes
of successful exploits. In any of these cases, the container is
released back to the pool and undergoes a recycling process
before becoming available again.
Recycling a container encompasses three sequential opera-
tions: destroy, clone (which creates a new container from a
template in which legitimate ﬁles are replaced with honeyﬁles),
and start. These steps happen swiftly for two main reasons.
First, the lightweight virtualization implemented by LXC
allows containers to be destroyed and started similarly to how
OS processes are terminated and created. Second, we deploy
our ephemeral containers as overlayfs-based clones, making
the cloning step almost instantaneous.
CR-Service. The Reverse Proxy uses the CR-Controller
module to communicate with CR-Service daemons running in
the background of each container. Each CR-Service implements
a fa¸cade that exposes CR operations to the proxy’s CR-
Controller through a simple RPC protocol based on Protocol
Buﬀers [28]. To enable fast, OS-local RPC communication,
we use IPC sockets (a.k.a., Unix domain sockets).
The CR-Service uses an extended version of CRIU to
checkpoint attacker sessions on the target and restore them
on decoys. It is also responsible for sanitizing process image
ﬁles (dump ﬁles), which are written to disk during checkpoint,
as well as managing attacker session signaling.
Reverse Proxy. The proxy plays a dual role in the honey-
patching system, acting as (1) a transport layer transparent
proxy, and (2) an orchestrator for attacker session forking.
As a transparent proxy, its main purpose is to hide the
backend web servers and route client requests. To serve each
client’s request, the proxy server accepts a downstream socket
connection from the client and binds an upstream socket
connection to the backend HTTP server, allowing HTTP
sessions to be processed transparently between the client and
the backend server. To keep its size small, the proxy neither
manipulates message payloads, nor implements any rules for
Figure 2: Linux containers pool and decoys life cycle
Figure 1: RedHerring system architecture overview
• hp_init(pgid, pid, tid, sk ): initialize honey-patch with
the process group pgid , process pid , thread tid , and
socket descriptor sk of the session.
• hp_fork(): initiate the attacker session remote forking
process, implementing the honey-patching core logic.
• hp_skip(c): skip over block c if in a decoy.
Function hp_init initializes the honey-patch with the neces-
sary information to handle subsequent session termination
and resurrection. It is invoked once per HTTP connection, at
the start of the session life cycle. In Apache, this immediately
follows acceptance of an HTTP request and handing the
newly created session oﬀ to a child process or worker thread;
in Lighttpd and Nginx, it follows the accept event for new
connections.
Listing 3 details the basic steps of hp_fork. Line 3 deter-
mines the application context, which can be either target
(denoting the target container) or decoy. In a decoy, the
function does nothing, allowing multiple attacks within a
single attacker session to continue within the same decoy.
In the target, a fork is initiated, consisting of four steps:
(1) Line 5 registers the signal handler for session termination
and resurrection. (2) Line 6 sends a fork request containing
the attacker session’s pgid , pid , and tid to the proxy’s CR-
Controller. (3) Line 7 synchronizes checkpoint and restore of
the attacker session in the target and decoy, respectively, and
guarantees that sensitive data is redacted from memory before
the clone is allowed to resume. (4) Once forking is complete
and the attacker session has been resurrected, the honey-patch
context is saved and the attacker session resumes in the decoy.
The fork request (step 2) achieves high eﬃciency by ﬁrst
issuing a system fork to create a shallow, local clone of the
web server process. This allows event-driven web servers
to continue while attacker sessions are forked onto decoys,
without interrupting the main event-loop. It also lifts the
burden of synchronizing concurrent checkpoint operations,
since CRIU injects a Binary, Large OBject (BLOB) into the
target process memory space to extract state data during
checkpoint (see §4).
The context-sensitivity of this framework allows the honey-
patch code to exhibit context-speciﬁc behavior: In decoy
contexts, hp_skip elides the execution of the code block
passed as an argument to the macro, elegantly simulating the
unpatched application code. In a target context, it is usually
never reached due to the fork. However, if forking silently fails
(e.g., due to resource exhaustion), it abandons the deception
and conservatively executes the original patch’s corrective
action for safety.
LXC Pool. The decoys into which attacker sessions are
forked are managed as a pool of Linux containers controlled
by the LXC Controller. The controller exposes two operations
Honey-patchedBinaryApply.Patch.&CompileReverse.Proxytargetdecoy.1decoy.2decoy.nLXC...UserAttackerCR-ControllerLXC.Controllerephemeral containersSourceCodeHoney-patch...acquiredecoy 1runningdecoy 2runningdecoy nrunningreleasedecoy 1runningdecoy 1recyclingrecycledcontainers poolavailableunavailableFigure 3: Attacker session forking. Numbers indicate the sequential steps taken to fork an attacker session.
detecting attacks. There is also no session caching. This makes
it extremely innocuous and lightweight. We implemented the
proxy as a transport-layer reverse proxy to reduce routing
overhead and support the variety of protocols operating above
TCP, including SSL/TLS.
As an orchestrator, the proxy listens for fork requests and
coordinates the attacker session forking as shown in Fig. 3.
Under legitimate load, the proxy simply routes user requests
to the target and routes server responses to users. However,
attack inputs elicit the following alternate workﬂow:
Step 1: The attacker probes the server with a crafted request
(denoted by GET /malicious in Fig. 3).
Step 2: The reverse proxy transparently routes the request
to the backend target web server.
Step 3: The request triggers the honey-patch (i.e., when the
honey-patch detects an attempted exploit of the patched
vulnerability) and issues a fork request to the reverse proxy.
Step 4: The proxy’s CR-Controller processes the request,
acquires a decoy from the LXC Pool, and issues a checkpoint
RPC request to the target’s CR-Service. The CR-Service
4.1: checkpoints the running web server instance to the
/imgs directory; and
4.2: signals the attacker session with a termination code,
gracefully terminating it.
Step 5: Upon checkpoint completion, the CR-Controller
commands the decoy’s CR-Service to restore the dumped
web server images on the decoy. The CR-Service then
5.1: restores a clone of the web server from the dump
images located in the /imgs directory; and
5.2: signals the attacker session with a resume code, and
cleans the dump data from /imgs.
Step 6: The attacker session resumes on the decoy, and a
response is sent back to the reverse proxy.
Step 7: The reverse proxy routes the response to the attacker.
Throughout this workﬂow, the attacker’s session forking
is completely transparent to the attacker. To avoid any
substantial overhead for transferring ﬁles between target and
decoys, we adopt the strategy of bind-mounting each decoy’s
/imgs folder to the target’s /imgs directory. After the session
has been forked to the decoy, it behaves like an unpatched
server, making it appear that no redirection has taken place
and the original probed server is vulnerable.
4. SESSION REMOTE FORKING
At the core of our architecture is the capability of remote
forking an attacker session to a decoy through checkpoint and
restore of the target server. To this end, we have extended
CRIU [18] with a memory redaction procedure performed
during checkpoint to protect sensitive data of legitimate users,
and a transparent connection relocation mechanism to restore
TCP connections in the destination decoy without stopping
the target server. We name this extended version CRIUm.
4.1 Checkpoint
The checkpoint procedure takes place in the target container
and is initiated when the CR-Service receives a checkpoint
request. The request includes the process group leader $pgid,
attacker process $pid, and attacker thread $tid.
The CR-Service passes this information to our CRIUm
checkpoint interface, which in turn: (1) uses the /proc
ﬁle system to collect ﬁle descriptors (/proc/$pgid/fd and
/proc/$pgid/fdinfo), pipe parameters, and memory maps
(/proc/$pgid/maps) for the process group; (2) walks through
/proc/$pgid/task/ and gathers child processes recursively to
build the process tree; (3) locks the network by adding netﬁlter
rules and collecting socket information; (4) uses ptrace (with
PTRACE_SEIZE) to attach to each child (without stopping it)
and collect VMA areas, the task’s ﬁle descriptor numbers, and
core parameters such as registers; (5) injects a BLOB code
into the child address space to collect state information such as
memory pages; (6) performs memory redaction using $pid and
$tid; (7) uses ptrace to remove the injected code from the
child process and continues until all children have been traced;
(8) unlocks network using netﬁlter, and ﬁnishes the procedure
by writing the process tree image ﬁles to /imgs/$tid/.
At this point, CRIUm returns to the caller, the web server
is running, and the attacker thread waits to be signaled. The
CR-Service then sends a termination signal to the attacker