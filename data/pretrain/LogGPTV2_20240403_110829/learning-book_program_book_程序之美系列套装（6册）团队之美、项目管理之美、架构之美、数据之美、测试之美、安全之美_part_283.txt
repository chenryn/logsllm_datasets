---
## Page 1606
mispelings 3937
语料库中使用的misspellings一词，拼写错误的概率达到了7%。可以
有三种方式来解决这个问题。第一种，我们可以获得一个字典单词
列表，并且只对字典中的单词纠正错误。但是字典没有列出最新发
明的单词和名字。（一种折中方案是把单词变成小写放到字典词汇
中，但是允许全部大写的单词不在字典库中。）第二种，我们可以
获得一个已经仔细校验过的语料库，可能是来自于高品质的出版社
的书籍和期刊。第三种，我们可以纠正语料库中的错误。在使用语
料库进行拼写检查之前，先对语料库拼写检查，这看起来就像是
“循环论证"(crcularreasoning)，但是可以实现。对于这个应用，我
们把编辑距离很小的单词聚在一起。针对每组相似单词，我们检查
是否有某个单词的出现频率要远远高于其他单词。如果存在这个单
词，我们将检查二元模型（或者三元模型）计数来观察这两个单词
和相邻的单词是否有相似的分布。例如，以下是“mispellings"和
“misspellings”的四个二元文法模型计数：
mispellings allowed 99
misspellings allowed 2410
mispellings as 50
misspellings as 749
mispellings for 122
misspellings for 11600
mispe1lings of 7360
misspellings of 16943
这两个单词共享很多相同的二元文法相邻的单词，对于这些单词组
合中，总是“misspellings"的出现频率更高，因此很有可能
“mispellings"是拼写错误。初级测试表示这种方法效果不错——但
是存在一个问题：它需要CPU计算好几百个小时。因此，这种方法
适合于在一个工作组上执行计算，而不适合于单机。
1605
---
## Page 1607
这种数据驱动的方法与更传统的软件开发过程相比如何？对于后
者，程序员在编码中制定了一些显示规则。为了回答这个问题，我
们一起来看ht：/Dig项目的拼写纠正代码，Dig是一款优秀的开源企
业内网搜索引擎。给定一个单词，ht：/Dig项目的metaphone算法可
以生成一个关键字来表示这个词的发声。举个例子，“tough"和"tuff”
都映射到关键字"TF”，因此可以作为互相拼写错误的候选。以下是
对于字母"G"的metaphone算法的代码：
case'G':
/ *
*F if in-GH and not B--GH, D--GH,
*-H--GH, -H---GH else dropped if
--*‘-
*else J if in-GE-, -GI-, -GY-and
*not GG else K
*/
if（（*(n+1)!=*G*I1vowel（*(n+2)))&&
(*(n+1)!=*N*I1(*(n+1) &&
(*(n+2) ! =*E*I 1
*（n+3）！='D*)））&&
(*(n-1)!='D*I1! frontv(*(n+1)) ))
if (frontv(*(n+1)) &&*(n+2)!='G*)
key<<'J';
else
key<<'K';
else if(*(n+1) ==*H*&&! noghf (*(n-3)) &&
*(n-4) != *H*)
1606
---
## Page 1608
key<<'F'
break;
这块代码正确地把"TOUGH"中的"GH"映射为"F”，但是不会把
“BOUGH"中的"GH"映射为"F”。但是这些规则是否正确地捕获了所
以编写测试样例来验证代码的每个分支，但是即使如此，我们还是
无法知道哪些方面没有覆盖全。当引入新的单词如"iPhone”，结果
会如何呢？显然，手工制定的规则很难扩展和维护。数据驱动方法
的很大优势是在数据中包含了很多信息，可以简单地通过增加更多
的数据来增加新的知识。另一个优点是，虽然数据是海量的，但代
码却很简洁——函数correct只包含50行左右的代码，而ht：//Dig的
拼写代码超过1500行。正如伟大的Bil1Gate所言：“通过代码行数来
衡量编程进展正如通过重量来衡量飞机建造过程。"Gates认为代码
行数是一种负担，而不是财富。概率性的数据驱动方法是敏捷开发
的终极。
该算法的另一个问题是可移植性。如果我们想要一个拉脱维亚语
（Ltvian）的拼写纠正器，该英语metaphone规则几乎毫无用处。把数
据驱动的纠正算法移植到另一种语言上，我们需要的是一个大的拉
脱维亚语的语料库，而不需要改动代码。
其他任务
以下是通过概率性语言模型处理的一些其他任务。
语言识别
存在Web协议来声明网页的编码语言。实际上至少存在两种协议，
一种在HTML，另一种在HTTP。但是有时这两种协议不一致，它们
都不表示真实的信息，因此搜索引擎在搜集了一些已知语言的样本
页面后，通常通过基于实际页面内容对页面进行分类。任务是写一
个这样的分类器。该技术的前沿水平是语言识别的准确率超过
99% 。
垃圾邮件检测和其他分类任务
1607
---
## Page 1609
据估计，每天发送的垃圾邮件有1000亿封。给定垃圾邮件和非垃圾
邮件两个语料库，任务是对未来的消息进行分类。最佳的垃圾邮件
分类器包含N元单词模型（包含"10000000.00willbereleased”和"our
countryNigeria"的消息很可能是垃圾邮件）以及N元字符模型
（"vlagra"可能是垃圾邮件）等特征。该任务的前沿技术是通过垃
圾邮件拦截方式，其准确率超过99%。一旦你可以对文档分类为垃
圾邮件/非垃圾邮件，那么你就可以很容易地进行其他方式的分类，
比如紧道/非紧道邮件消息，或者对新闻文章的分类，如政治/商业
体育/其他，或者产品反馈的分类如“喜欢/一般/不喜欢”。
作者识别（文体学Stylometry)
语言模型已经被用于识别《FederalistPapers》、莎士比亚的诗和
《圣经》的有争议的作者。相似的技术还被用于追踪恐怖组织，在
刑法中，用于识别和找到罪犯。该领域还不太成熟，我们还不太确
定什么是最佳实践，或者期望概率是多少，虽然2004年竞赛的胜出
者的准确率达到71%。竞赛的最佳实践在语言上很简单，但是在统
计上非常复杂。
记录文档重组和DNA序列化
在VernorVinge的科幻小说《RainbowsEnd》（TrBooks出版），
Librareome项目通过把所有书籍扔到树碎纸机、对碎片拍照和使用
计算机算法重新组合这些图片的方式数字记录整个图书馆的信息。
在实际生活中，德国政府的E-Puzzler项目正在重新构建4500万页面
的记录文档，它们被民主德国秘密警察Stasis所破坏。这两个项目都
依赖复杂的计算机视觉技术。但是一旦把图像转化为字符，即可使
用语言模型和爬山算法来重新组合那些碎片。可以采用类似的技术
来解读生命之语：人类基于组项目使用了称为shotgun序列化技术来
重新组合DNA碎片。因此，所谓的“下一代序列化"把更多的负担从
Web实验室转移到大规模的并行重组算法。
机器翻译
G公司的N元语料是由机器翻译组的研究人员创建的。把外语（翻
译成英语(e和纠正拼写错误的单词很相似。最佳的英语翻译建模如
下：
best=argmaxe P(e|f) =argmaxe P(fle）P(e)
1608
---
## Page 1610
其中，P(e)是英语的语言模型，通过N元语法模型数据进行估计，
而P（fe）是翻译模型，通过双语语料库进行学习：在双语语料库
中，一对文档被标记为相互的翻译。虽然高端系统利用了语言学特
征，包括很多句子的一部分词和语义解析，但是结果发现翻译需要
的绝大部分知识来自于n元文法模型数据。
讨论和结论
我们显示了软件开发方法的力量，它使用大量的数据来解决不确定
环境中提出的不确定问题。本章中探讨的是语言数据，但是很多相
同的经验也适合于其他数据。
在我们所探索的样例中，程序简洁明了，这是因为使用的概率模型
简单。这些样例模型忽略了人类所知道的很多知识一一显然，对
“choosespain.com"进行分段，我们需要了解很多关于旅游业如何工
作以及其他因素的专业知识，但是奇怪的结果在于程序不需要显式
表示所有的知识：它隐式地从N元语法模型中获取知识，它表示其
他人选择了探讨的方面。在过去，概率模型更复杂，因为它们依赖
于更少的数据。
需要强调的是，当缺失数据时的统计复杂的平滑策略。既然有非常
大的语料库，那么我们可以使用类似“愚蠢回退”的方法，而不再过
于担心平滑模型。
我们在本章研究的程序中的绝大多数复杂性是由于搜索策略。我们
看到了三类搜索策略：
穷举式(Ehaustive)
对于移位密码，只有26个候选项，我们可以全部一一测试它们。
保证式（Garanteed)
对于分段策略，存在2种候选方式，但是很多方式可以被证明是非
最优的（在独立假设前提下），不需要对它们进行检查。
启发式(Huristic)
对于全部的替换密码，我们无法保证已经发现了最佳的候选，但是
我们可以搜索一个代表子集，使我们可以有较大的机会找到最佳候
1609
---
## Page 1611
选。对于很多问题，其绝大部分工作是选择正确的函数进行优化，
理解搜索空间的拓扑，发现好的顺序来枚举相邻节点。
如果我们是基于大量的数据构建模型，那么就需要获取“在各种情
况下"ithewild可能的数据。N元文法计数具备这个属性：我们可
以很容易地从Web中收集1万亿条自然文本数据。然而，标签化的拼
写纠正不是自然产生的，因此我们在这些数据中只找到了4万个，
两种最成功的自然语言应用——机器翻译和语言识别——可以得到
大量的语料样例，这绝非偶然。相反，句子的语义解析任务依然大
部分还未实现，一部分是由于在解析后的句子中不存在自然存在的
大量的语料库。
值得一提的是，我们的概率性数据驱动模型方法一—最大化了所有
候选项的概率——是合理的数据驱动方法的一个特例——最大化所
有候选项的期望效益。举个例子，合理性的拼写纠正程序需要知道
存在一些禁忌语，而当用户并不想使用这些禁忌语时，提示这些禁
忌语会给用户带来难堪，其负面影响比拼写一个错误单词要严重得
多。合理性的程序会考虑一个单词正确或错误的概率，以及提示每
个单词所带来的正面或负面价值。不确定问题需要在校验和测试上
有很好的纪律约束。为了评估一个不确定问题的解决方案，人们需
要把数据分为三个集合：1）训练集合，用于构建概率模型。2）校
验集合，并发人员用于评估一些不同的方法，观察哪一种方法打分
更高，从新的算法中获取思想。3）测试集合，用于在并发介素时
准确地判断该算法对于新的、未访问的数据效果如何。当使用完一
次测试集合后，理想情况是抛弃该集合，正如一个老师不能给一个
班级的学生进行两次相同的测试。但是在实践中，数据很昂贵，而
且在通过支付方式获取新数据和通过某种不会导致模型过度拟合数
据的方式重用旧数据之间存在一个折中。注意对独立测试集合的需