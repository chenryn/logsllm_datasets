title:Android Permissions Remystified: A Field Study on Contextual Integrity
author:Primal Wijesekera and
Arjun Baokar and
Ashkan Hosseini and
Serge Egelman and
David A. Wagner and
Konstantin Beznosov
Android Permissions Remystified:  
A Field Study on Contextual Integrity
Primal Wijesekera, University of British Columbia; Arjun Baokar, Ashkan Hosseini,  
Serge Egelman, and David Wagner, University of California, Berkeley;  
Konstantin Beznosov, University of British Columbia
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/wijesekera
This paper is included in the Proceedings of the 
24th USENIX Security Symposium
August 12–14, 2015 • Washington, D.C.
ISBN  978-1-939133-11-3
Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXAndroid Permissions Remystiﬁed:
A Field Study on Contextual Integrity
Primal Wijesekera1, Arjun Baokar2, Ashkan Hosseini2, Serge Egelman2,
David Wagner2, and Konstantin Beznosov1
1University of British Columbia, Vancouver, Canada,
{primal,beznosov}@ece.ubc.ca
2University of California, Berkeley, Berkeley, USA,
{arjunbaokar,ashkan}@berkeley.edu, {egelman,daw}@cs.berkeley.edu
Abstract
We instrumented the Android platform to collect data re-
garding how often and under what circumstances smart-
phone applications access protected resources regulated
by permissions. We performed a 36-person ﬁeld study
to explore the notion of “contextual integrity,” i.e., how
often applications access protected resources when users
are not expecting it. Based on our collection of 27M data
points and exit interviews with participants, we exam-
ine the situations in which users would like the ability to
deny applications access to protected resources. At least
80% of our participants would have preferred to prevent
at least one permission request, and overall, they stated a
desire to block over a third of all requests. Our ﬁndings
pave the way for future systems to automatically deter-
mine the situations in which users would want to be con-
fronted with security decisions.
Introduction
1
Mobile platform permission models regulate how appli-
cations access certain resources, such as users’ personal
information or sensor data (e.g., camera, GPS, etc.). For
instance, previous versions of Android prompt the user
during application installation with a list of all the per-
missions that the application may use in the future; if the
user is uncomfortable granting any of these requests, her
only option is to discontinue installation [3]. On iOS and
Android M, the user is prompted at runtime the ﬁrst time
an application requests any of a handful of data types,
such as location, address book contacts, or photos [34].
Research has shown that few people read the Android
install-time permission requests and even fewer compre-
hend them [16]. Another problem is habituation: on av-
erage, Android applications present the user with four
permission requests during the installation process [13].
While iOS users are likely to see fewer permission re-
quests than Android users, because there are fewer pos-
sible permissions and they are only displayed the ﬁrst
time the data is actually requested, it is not clear whether
or not users are being prompted about access to data that
they actually ﬁnd concerning, or whether they would ap-
prove of subsequent requests [15].
Nissenbaum posited that the reason why most privacy
models fail to predict violations is that they fail to con-
sider contextual integrity [32]. That is, privacy violations
occur when personal information is used in ways that
defy users’ expectations. We believe that this notion of
“privacy as contextual integrity” can be applied to smart-
phone permission systems to yield more effective per-
missions by only prompting users when an application’s
access to sensitive data is likely to defy expectations. As
a ﬁrst step down this path, we examined how applica-
tions are currently accessing this data and then examined
whether or not it complied with users’ expectations.
We modiﬁed Android to log whenever an application
accessed a permission-protected resource and then gave
these modiﬁed smartphones to 36 participants who used
them as their primary phones for one week. The pur-
pose of this was to perform dynamic analysis to deter-
mine how often various applications are actually access-
ing protected resources under realistic circumstances.
Afterwards, subjects returned the phones to our labora-
tory and completed exit surveys. We showed them vari-
ous instances over the past week where applications had
accessed certain types of data and asked whether those
instances were expected, and whether they would have
wanted to deny access. Participants wanted to block a
third of the requests. Their decisions were governed pri-
marily by two factors: whether they had privacy concerns
surrounding the speciﬁc data type and whether they un-
derstood why the application needed it.
We contribute the following:
• To our knowledge, we performed the ﬁrst ﬁeld study
to quantify the permission usage by third-party ap-
plications under realistic circumstances.
USENIX Association  
24th USENIX Security Symposium  499
1
• We show that our participants wanted to block ac-
cess to protected resources a third of the time. This
suggests that some requests should be granted by
runtime consent dialogs, rather than Android’s pre-
vious all-or-nothing install-time approval approach.
• We show that the visibility of the requesting appli-
cation and the frequency at which requests occur are
two important factors which need to be taken into
account in designing a runtime consent platform.
2 Related Work
While users are required to approve Android application
permission requests during installation, most do not pay
attention and fewer comprehend these requests [16, 26].
In fact, even developers are not fully knowledgeable
about permissions [40], and are given a lot of free-
dom when posting an application to the Google Play
Store [7]. Applications often do not follow the principle
of least privilege, intentionally or unintentionally [44].
Other work has suggested improving the Android per-
mission model with better deﬁnitions and hierarchical
breakdowns [8]. Some researchers have experimented
with adding ﬁne-grained access control to the Android
model [11]. Providing users with more privacy informa-
tion and personal examples has been shown to help users
in choosing applications with fewer permissions [21,27].
Previous work has examined the overuse of permissions
by applications [13, 20], and attempted to identify mali-
cious applications through their permission requests [36]
or through natural language processing of application de-
scriptions [35]. Researchers have also developed static
analysis tools to analyze Android permission speciﬁca-
tions [6, 9, 13]. Our work complements this static anal-
ysis by applying dynamic analysis to permission us-
age. Other researchers have applied dynamic analysis to
native (non-Java) APIs among third-party mobile mar-
kets [39]; we apply it to the Java APIs available to devel-
opers in the Google Play Store.
Researchers examined user privacy expectations sur-
rounding application permissions, and found that users
were often surprised by the abilities of background ap-
plications to collect data [25, 42]. Their level of con-
cern varied from annoyance to seeking retribution when
presented with possible risks associated with permis-
sions [15]. Some studies employed crowdsourcing to
create a privacy model based on user expectations [30].
Researchers have designed systems to track or reduce
privacy violations by recommending applications based
on users’ security concerns [2, 12, 19, 24, 28, 46–48].
Other tools dynamically block runtime permission re-
quests [37]. Enck et al. found that a considerable number
of applications transmitted location or other user data to
third parties without requiring user consent [12]. Horny-
ack et al.’s AppFence system gave users the ability to
deny data to applications or substitute fake data [24].
However, this broke application functionality for one-
third of the applications tested.
Reducing the number of security decisions a user must
make is likely to decrease habituation, and therefore, it is
critical to identify which security decisions users should
be asked to make. Based on this theory, Felt et al. created
a decision tree to aid platform designers in determining
the most appropriate permission-granting mechanism for
a given resource (e.g., access to benign resources should
be granted automatically, whereas access to dangerous
resources should require approval) [14]. They concluded
that the majority of Android permissions can be automat-
ically granted, but 16% (corresponding to the 12 permis-
sions in Table 1) should be granted via runtime dialogs.
Nissenbaum’s theory of contextual integrity can help us
to analyze “the appropriateness of a ﬂow” in the con-
text of permissions granted to Android applications [32].
There is ambiguity in deﬁning when an application actu-
ally needs access to user data to run properly. It is quite
easy to see why a location-sharing application would
need access to GPS data, whereas that same request com-
ing from a game like Angry Birds is less obvious. “Con-
textual integrity is preserved if information ﬂows accord-
ing to contextual norms” [32], however, the lack of thor-
ough documentation on the Android permission model
makes it easier for programmers to neglect these norms,
whether intentionally or accidentally [38]. Deciding on
whether an application is violating users’ privacy can be
quite complicated since “the scope of privacy is wide-
ranging” [32]. To that end, we performed dynamic analy-
sis to measure how often (and under what circumstances)
applications were accessing protected resources, whether
this complied with users’ expectations, as well as how
often they might be prompted if we adopt Felt et al.’s
proposal to require runtime user conﬁrmation before ac-
cessing a subset of these resources [14]. Finally, we show
how it is possible to develop a classiﬁer to automatically
determine whether or not to prompt the user based on
varying contextual factors.
3 Methodology
Our long-term research goal is to minimize habituation
by only confronting users with necessary security de-
cisions and avoiding showing them permission requests
that are either expected, reversible, or unconcerning. Se-
lecting which permissions to ask about requires under-
standing how often users would be confronted with each
type of request (to assess the risk of habituation) and user
reactions to these requests (to assess the beneﬁt to users).
In this study, we explored the problem space in two parts:
500  24th USENIX Security Symposium 
USENIX Association
2
we instrumented Android so that we could collect actual
usage data to understand how often access to various pro-
tected resources is requested by applications in practice,
and then we surveyed our participants to understand the
requests that they would not have granted, if given the
option. This ﬁeld study involved 36 participants over the
course of one week of normal smartphone usage. In this
section, we describe the log data that we collected, our
recruitment procedure, and then our exit survey.
3.1 Tracking Access to Sensitive Data
In Android, when applications attempt to access pro-
tected resources (e.g., personal information, sensor data,
etc.)
at runtime, the operating system checks to see
whether or not the requesting application was previously
granted access during installation. We modiﬁed the An-
droid platform to add a logging framework so that we
could determine every time one of these resources was
accessed by an application at runtime. Because our target
device was a Samsung Nexus S smartphone, we modiﬁed
Android 4.1.1 (Jellybean), which was the newest version
of Android supported by our hardware.
3.1.1 Data Collection Architecture
Our goal was to collect as much data as possible about
each applications’ access to protected resources, while
minimizing our impact on system performance. Our
data collection framework consisted of two main com-
ponents: a series of “producers” that hooked various An-
droid API calls and a “consumer” embedded in the main
Android framework service that wrote the data to a log
ﬁle and uploaded it to our collection server.
We logged three kinds of permission requests. First, we
logged function calls checked by checkPermission()
in the Android Context implementation.
Instru-
menting the Context implementation, instead of the
ActivityManagerService or PackageManager, al-
lowed us to also log the function name invoked by the
user-space application. Next, we logged access to the
ContentProvider class, which veriﬁes the read and
write permissions of an application prior to it accessing
structured data (e.g., contacts or calendars) [5]. Finally,
we tracked permission checks during Intent transmis-
sion by instrumenting the ActivityManagerService
and BroadcastQueue. Intents allow an application to
pass messages to another application when an activity is
to be performed in that other application (e.g., opening a
URL in the web browser) [4].
We created a component called Producer that fetches
the data from the above instrumented points and sends it
back to the Consumer, which is responsible for logging
everything reported. Producers are scattered across
the Android Platform, since permission checks occur in
multiple places. The Producer that logged the most
data was in system server and recorded direct func-
tion calls to Android’s Java API. For a majority of priv-
ileged function calls, when a user application invokes
the function, it sends the request to system server
via Binder. Binder is the most prominent IPC mech-
anism implemented to communicate with the Android
Platform (whereas Intents communicate between ap-
plications). For requests that do not make IPC calls to the
system server, a Producer is placed in the user appli-
cation context (e.g., in the case of ContentProviders).
The Consumer class is responsible for logging data pro-
duced by each Producer. Additionally, the Consumer
also stores contextual information, which we describe in
Section 3.1.2. The Consumer syncs data with the ﬁlesys-
tem periodically to minimize impact on system perfor-
mance. All log data is written to the internal storage of
the device because the Android kernel is not allowed to
write to external storage for security reasons. Although
this protects our data from curious or careless users, it
also limits our storage capacity. Thus, we compressed
the log ﬁles once every two hours and upload them to
our collection servers whenever the phone had an active
Internet connection (the average uploaded and zipped log
ﬁle was around 108KB and contained 9,000 events).
Due to the high volume of permission checks we en-
countered and our goal of keeping system performance
at acceptable levels, we added rate-limiting logic to the
Consumer. Speciﬁcally,
if it has logged permission
checks for a particular application/permission combina-
tion more than 10,000 times, it examines whether it did
so while exceeding an average rate of 1 permission check
every 2 seconds. If so, the Consumer will only record
10% of all future requests for this application/permission
combination. When this rate-limiting is enabled, the
Consumer tracks these application/permission combina-
tions and updates all the Producers so that they start
dropping these log entries. Finally, the Consumer makes
a note of whenever this occurs so that we can extrapolate
the true number of permission checks that occurred.
3.1.2 Data Collection
We hooked the permission-checking APIs so that every
time the system checked whether an application had been
granted a particular permission, we logged the name of
the permission, the name of the application, and the API
method that resulted in the check. In addition to times-
tamps, we collected the following contextual data:
• Visibility—We categorized whether the requesting
application was visible to the user, using four cate-
gories: running (a) as a service with no user inter-
action; (b) as a service, but with user interaction via
USENIX Association  
24th USENIX Security Symposium  501
3
notiﬁcations or sounds; (c) as a foreground process,
but in the background due to multitasking; or (d) as
a foreground process with direct user interaction.
• Screen Status—Whether the screen was on/off.
• Connectivity—The phone’s WiFi connection state.
• Location—The user’s last known coordinates. In
order to preserve battery life, we collected cached
location data, rather than directly querying the GPS.
• View—The UI elements in the requesting applica-
tion that were exposed to the user at the time that a
protected resource was accessed. Speciﬁcally, since
the UI is built from an XML ﬁle, we recorded the
name of the screen as deﬁned in the DOM.
interacted prior to the requesting application.
• History—A list of applications with which the user
• Path—When access to a ContentProvider object
was requested, the path to the speciﬁc content.
Felt et al. proposed granting most Android permissions
without a priori user approval and granting 12 permis-
sions (Table 1) at runtime so that users have contextual
information to infer why the data might be needed [14].
The idea is that, if the user is asked to grant a permission
while using an application, she may have some under-
standing of why the application needs that permission
based on what she was doing. We initially wanted to
perform experience sampling by probabilistically ques-
tioning participants whenever any of these 12 permis-
sions were checked [29]. Our goal was to survey par-
ticipants about whether access to these resources was ex-
pected and whether it should proceed, but we were con-
cerned that this would prime them to the security focus
of our experiment, biasing their subsequent behaviors.
Instead, we instrumented the phones to probabilistically
take screenshots of what participants were doing when
these 12 permissions were checked so that we could ask
them about it during the exit survey. We used reservoir
sampling to minimize storage and performance impacts,
while also ensuring that the screenshots covered a broad
set of applications and permissions [43].
Figure 1 shows a screenshot captured during the study
along with its corresponding log entry. The user was
playing the Solitaire game while Spotify requested a
WiFi scan. Since this permission was of interest (Table
1), our instrumentation took a screenshot. Since Spotify
was not the application the participant was interacting
with, its visibility was set to false. The history shows that
prior to Spotify calling getScanResults(), the user
had viewed Solitaire, the call screen, the launcher, and
the list of MMS conversations.
Permission Type
WRITE SYNC
SETTINGS
ACCESS WIFI
STATE
INTERNET
NFC
READ HISTORY
BOOKMARKS
ACCESS FINE
LOCATION
ACCESS COARSE
LOCATION
LOCATION
HARDWARE
READ CALL LOG