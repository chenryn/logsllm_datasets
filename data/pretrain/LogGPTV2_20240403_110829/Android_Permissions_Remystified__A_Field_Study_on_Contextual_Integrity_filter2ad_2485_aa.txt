# Title: Android Permissions Remystified: A Field Study on Contextual Integrity

## Authors:
- Primal Wijesekera, University of British Columbia
- Arjun Baokar, University of California, Berkeley
- Ashkan Hosseini, University of California, Berkeley
- Serge Egelman, University of California, Berkeley
- David Wagner, University of California, Berkeley
- Konstantin Beznosov, University of British Columbia

## Abstract
We instrumented the Android platform to collect data on how frequently and under what circumstances smartphone applications access protected resources regulated by permissions. Our 36-person field study explored the concept of "contextual integrity," specifically how often applications access these resources when users do not expect it. Based on 27 million data points and exit interviews with participants, we examined situations in which users would prefer to deny applications access to protected resources. At least 80% of our participants would have preferred to prevent at least one permission request, and overall, they expressed a desire to block over a third of all requests. Our findings provide insights for future systems to automatically determine when users should be prompted with security decisions.

## Introduction
Mobile platform permission models regulate how applications access certain resources, such as personal information or sensor data (e.g., camera, GPS, etc.). For instance, previous versions of Android prompt users during application installation with a list of all permissions the application may use in the future; if the user is uncomfortable granting any of these, their only option is to discontinue installation [3]. On iOS and Android M, users are prompted at runtime the first time an application requests specific data types, such as location, address book contacts, or photos [34].

Research has shown that few people read Android install-time permission requests, and even fewer comprehend them [16]. Another issue is habituation: on average, Android applications present users with four permission requests during installation [13]. While iOS users see fewer permission requests due to fewer possible permissions and runtime prompts, it is unclear whether users are being prompted about data access they find concerning or whether they would approve of subsequent requests [15].

Nissenbaum posited that most privacy models fail to predict violations because they do not consider contextual integrity [32]. Privacy violations occur when personal information is used in ways that defy users' expectations. We believe this notion of "privacy as contextual integrity" can be applied to smartphone permission systems to make them more effective by only prompting users when an application's access to sensitive data is likely to defy expectations. As a first step, we examined how applications currently access this data and whether it complies with users' expectations.

We modified Android to log whenever an application accessed a permission-protected resource and then gave these modified smartphones to 36 participants who used them as their primary phones for one week. The purpose was to perform dynamic analysis to determine how often various applications access protected resources under realistic conditions. Afterward, participants returned the phones and completed exit surveys. We showed them instances where applications had accessed certain types of data and asked whether those instances were expected and whether they would have wanted to deny access. Participants wanted to block a third of the requests, primarily based on privacy concerns and understanding why the application needed the data.

Our contributions include:
- To our knowledge, we performed the first field study to quantify permission usage by third-party applications under realistic circumstances.
- We show that participants wanted to block access to protected resources a third of the time, suggesting some requests should be granted via runtime consent dialogs rather than Android’s all-or-nothing install-time approval approach.
- We highlight the importance of the visibility of the requesting application and the frequency of requests in designing a runtime consent platform.

## Related Work
While users must approve Android application permission requests during installation, most do not pay attention and fewer comprehend these requests [16, 26]. Even developers are not fully knowledgeable about permissions [40] and have significant freedom when posting applications to the Google Play Store [7]. Applications often do not follow the principle of least privilege, intentionally or unintentionally [44]. Other work has suggested improving the Android permission model with better definitions and hierarchical breakdowns [8], and some researchers have experimented with adding fine-grained access control [11]. Providing users with more privacy information and personal examples has been shown to help them choose applications with fewer permissions [21, 27].

Previous work has examined the overuse of permissions by applications [13, 20] and attempted to identify malicious applications through their permission requests [36] or natural language processing of application descriptions [35]. Researchers have developed static analysis tools to analyze Android permission specifications [6, 9, 13]. Our work complements this static analysis by applying dynamic analysis to permission usage. Other researchers have applied dynamic analysis to native (non-Java) APIs among third-party mobile markets [39]; we apply it to the Java APIs available to developers in the Google Play Store.

Researchers have examined user privacy expectations surrounding application permissions and found that users are often surprised by the abilities of background applications to collect data [25, 42]. Their level of concern varies from annoyance to seeking retribution when presented with possible risks associated with permissions [15]. Some studies have employed crowdsourcing to create privacy models based on user expectations [30]. Researchers have designed systems to track or reduce privacy violations by recommending applications based on users’ security concerns [2, 12, 19, 24, 28, 46–48]. Other tools dynamically block runtime permission requests [37]. Enck et al. found that many applications transmit location or other user data to third parties without requiring user consent [12]. Hornyack et al.’s AppFence system allowed users to deny data to applications or substitute fake data, but this broke functionality for one-third of the applications tested [24].

Reducing the number of security decisions a user must make is likely to decrease habituation, making it critical to identify which security decisions users should be asked to make. Felt et al. created a decision tree to aid platform designers in determining the most appropriate permission-granting mechanism for a given resource [14]. They concluded that most Android permissions can be automatically granted, but 16% (corresponding to the 12 permissions in Table 1) should be granted via runtime dialogs. Nissenbaum’s theory of contextual integrity can help analyze the appropriateness of data flows in the context of permissions granted to Android applications [32]. There is ambiguity in defining when an application needs access to user data to run properly. It is clear why a location-sharing application needs GPS data, whereas the same request from a game like Angry Birds is less obvious. Contextual integrity is preserved if information flows according to contextual norms [32], but the lack of thorough documentation on the Android permission model makes it easier for programmers to neglect these norms, whether intentionally or accidentally [38]. Deciding whether an application violates users’ privacy can be complicated since the scope of privacy is wide-ranging [32]. We performed dynamic analysis to measure how often and under what circumstances applications access protected resources, whether this complies with users’ expectations, and how often they might be prompted if we adopt Felt et al.’s proposal [14]. Finally, we show how it is possible to develop a classifier to automatically determine whether to prompt the user based on varying contextual factors.

## Methodology
Our long-term research goal is to minimize habituation by only confronting users with necessary security decisions and avoiding showing them permission requests that are either expected, reversible, or unconcerning. Selecting which permissions to ask about requires understanding how often users would be confronted with each type of request and their reactions to these requests. In this study, we explored the problem space in two parts: we instrumented Android to collect actual usage data to understand how often applications request access to various protected resources, and we surveyed participants to understand the requests they would not have granted, if given the option. This field study involved 36 participants over one week of normal smartphone usage. In this section, we describe the log data collected, our recruitment procedure, and the exit survey.

### 3.1 Tracking Access to Sensitive Data
In Android, when applications attempt to access protected resources (e.g., personal information, sensor data, etc.) at runtime, the operating system checks whether the requesting application was previously granted access during installation. We modified the Android platform to add a logging framework to determine every time one of these resources was accessed by an application at runtime. Since our target device was a Samsung Nexus S smartphone, we modified Android 4.1.1 (Jellybean), the newest version supported by our hardware.

#### 3.1.1 Data Collection Architecture
Our goal was to collect as much data as possible about each application's access to protected resources while minimizing the impact on system performance. Our data collection framework consisted of two main components: a series of "producers" that hooked various Android API calls and a "consumer" embedded in the main Android framework service that wrote the data to a log file and uploaded it to our collection server.

We logged three kinds of permission requests:
1. Function calls checked by `checkPermission()` in the Android Context implementation. Instrumenting the Context implementation, rather than the `ActivityManagerService` or `PackageManager`, allowed us to log the function name invoked by the user-space application.
2. Access to the `ContentProvider` class, which verifies the read and write permissions of an application before it accesses structured data (e.g., contacts or calendars) [5].
3. Permission checks during Intent transmission by instrumenting the `ActivityManagerService` and `BroadcastQueue`. Intents allow an application to pass messages to another application when an activity is to be performed (e.g., opening a URL in the web browser) [4].

We created a component called "Producer" that fetches data from the above instrumented points and sends it back to the "Consumer," responsible for logging everything reported. Producers are scattered across the Android Platform, as permission checks occur in multiple places. The Producer that logged the most data was in the system server and recorded direct function calls to Android’s Java API. For most privileged function calls, when a user application invokes the function, it sends the request to the system server via Binder, the most prominent IPC mechanism in Android. For requests that do not make IPC calls to the system server, a Producer is placed in the user application context (e.g., in the case of `ContentProviders`).

The Consumer class is responsible for logging data produced by each Producer and storing contextual information. The Consumer syncs data with the filesystem periodically to minimize performance impact. All log data is written to the internal storage of the device for security reasons. Although this protects our data from curious or careless users, it also limits our storage capacity. Thus, we compressed the log files every two hours and uploaded them to our collection servers whenever the phone had an active Internet connection (the average uploaded and zipped log file was around 108KB and contained 9,000 events).

Due to the high volume of permission checks and our goal of maintaining acceptable system performance, we added rate-limiting logic to the Consumer. Specifically, if it has logged permission checks for a particular application/permission combination more than 10,000 times, it examines whether it did so while exceeding an average rate of one permission check every two seconds. If so, the Consumer will only record 10% of all future requests for this application/permission combination. When this rate-limiting is enabled, the Consumer tracks these combinations and updates all the Producers to start dropping these log entries. Finally, the Consumer notes whenever this occurs to extrapolate the true number of permission checks.

#### 3.1.2 Data Collection
We hooked the permission-checking APIs so that every time the system checked whether an application had been granted a particular permission, we logged the name of the permission, the name of the application, and the API method that resulted in the check. In addition to timestamps, we collected the following contextual data:
- **Visibility**: Categorized whether the requesting application was visible to the user, using four categories: (a) running as a service with no user interaction; (b) running as a service, but with user interaction via notifications or sounds; (c) running as a foreground process, but in the background due to multitasking; or (d) running as a foreground process with direct user interaction.
- **Screen Status**: Whether the screen was on or off.
- **Connectivity**: The phone’s WiFi connection state.
- **Location**: The user’s last known coordinates. To preserve battery life, we collected cached location data rather than directly querying the GPS.
- **View**: The UI elements in the requesting application exposed to the user at the time a protected resource was accessed. Specifically, we recorded the name of the screen as defined in the DOM.
- **History**: A list of applications with which the user interacted prior to the requesting application.
- **Path**: When access to a `ContentProvider` object was requested, the path to the specific content.

Felt et al. proposed granting most Android permissions without a priori user approval and granting 12 permissions (Table 1) at runtime so that users have contextual information to infer why the data might be needed [14]. The idea is that, if the user is asked to grant a permission while using an application, they may have some understanding of why the application needs that permission based on what they were doing. Initially, we wanted to perform experience sampling by probabilistically questioning participants whenever any of these 12 permissions were checked [29]. However, we were concerned that this would prime them to the security focus of our experiment, biasing their subsequent behaviors. Instead, we instrumented the phones to probabilistically take screenshots of what participants were doing when these 12 permissions were checked, allowing us to ask them about it during the exit survey. We used reservoir sampling to minimize storage and performance impacts while ensuring the screenshots covered a broad set of applications and permissions [43].

**Figure 1** shows a screenshot captured during the study along with its corresponding log entry. The user was playing Solitaire while Spotify requested a WiFi scan. Since this permission was of interest (Table 1), our instrumentation took a screenshot. Since Spotify was not the application the participant was interacting with, its visibility was set to false. The history shows that prior to Spotify calling `getScanResults()`, the user had viewed Solitaire, the call screen, the launcher, and the list of MMS conversations.

| Permission Type | WRITE SYNC SETTINGS | ACCESS WIFI STATE | INTERNET | NFC | READ HISTORY BOOKMARKS | ACCESS FINE LOCATION | ACCESS COARSE LOCATION | LOCATION HARDWARE | READ CALL LOG |
|-----------------|---------------------|-------------------|----------|-----|-------------------------|----------------------|------------------------|--------------------|---------------|
|                 |                     |                   |          |     |                         |                      |                        |                    |               |

This comprehensive approach allowed us to gather detailed and meaningful data on how and when applications access protected resources, providing valuable insights into user expectations and preferences.