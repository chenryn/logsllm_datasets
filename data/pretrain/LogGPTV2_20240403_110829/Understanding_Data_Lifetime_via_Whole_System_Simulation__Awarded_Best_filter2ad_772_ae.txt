the garbage collector to collect unreferenced strings.
The existing code zeroed the ﬁrst 4 bytes (8 bytes, on
64-bit architectures) of strings as a side effect. We mod-
iﬁed it to zero all bytes of unreferenced strings.
We reran the experiment with these modiﬁcations,
01020304050607080050100150200250timebytes01020304050607080OriginalModifiedas in systems like TaintBochs or Perl’s tainting or may
simply be an intuitive metaphor for understanding the
results of a static analysis.
In Perl,
Perl [20] provides the most well known example
if “tainting” is enabled, data
of tainting.
read by built-in functions from potentially untrusted
sources, i.e. network sockets, environment variables, etc.
is tagged as tainted. Regular expression matching clears
taint bits and is taken to mean that the programmer is has
checked that the input is “safe.” Sensitive built-in func-
tions (e.g. exec) will generate a runtime error if they
receive tainted arguments.
Static taint analysis has been applied by a variety
of groups with signiﬁcant success. Shankar et al. [24]
used their static analysis tool Percent-S to detect format
string vulnerabilities based on a tainting style analysis
using type qualiﬁer inference and programmer annota-
tions. Scrash [6], infers which data in a system is sensi-
tive based on programmer annotations to facilitate spe-
cial handling of that data to allow secure crash dumps,
i.e. crash dumps which can be shipped to the application
developer without revealing users sensitive data. This
work is probably the most similar to ours in spirit as its
focus is on making a feature with signiﬁcant impact on
sensitive data lifetime safe. The heart of both of these
systems is the CQual [23], a powerful system for sup-
porting user extensible type inference.
Ashcraft et al. [2] successfully applied a tainting style
static analysis in the context of their meta-compilation
system with extremely notable success. In the context
of this work they were able to discover a large number
of new bugs in the Linux and OpenBSD kernels. Their
system works on a more ad-hoc basis, effectively and
efﬁciently combining programmer written compiler ex-
tensions with statistical techniques.
Static analysis and whole system simulation both
have signiﬁcant strengths and can be used in a comple-
mentary fashion. Both also present a variety of practical
trade-offs. Static analysis can examine all paths in a pro-
gram. As it need not execute every path in the program
to glean information about its properties, this allows it
to avoid an exponential “blow up” in possible execution
paths. This can be achieved through a variety of means,
most commonly by making the analysis insensitive to
control ﬂow. On the other hand, simulation is basically
program testing with a very good view of the action. As
such, it examines only execution paths that are exercised.
Static analysis is typically performed at the source
code level, thus all code is required to perform the anal-
ysis, and the analysis typically cannot span multiple pro-
grams. Further, most but not all static analysis tools re-
quire some program annotation to function. Whole sys-
tem simulation can be easily used to perform analysis of
properties that span the entire software stack and can be
essentially language independent. Possession of source
code is not even required for an analysis to include a
component, although it is helpful for interpreting results.
One clear advantage of dynamic analysis in general
is that it actually allows the program to be run to deter-
mine its properties. Because many program properties
are formally undecidable they cannot be discovered via
static analysis alone. Also, because lower level analysis
works at the architectural level, it makes no assumptions
about the correctness of implementations of higher level
semantics. Thus, higher level bugs or misfeatures (such
as a compiler optimizing away memset() as described
in section 2) are not overlooked.
6 Future Work
Many questions remain to be answered about data
lifetime. There is no current empirical work on how
long data persists in different memory region types
(e.g. stack, heap, etc.) under different workloads. As dis-
cussed in Appendix A allocation policies are quite com-
plicated and vary widely, making it difﬁcult to deduce
their impact from ﬁrst principles. This problem also
holds for virtual memory subsystems. While our frame-
work identiﬁes potential weaknesses well, we would like
a more complete solution for gaining quantitative infor-
mation about data lifetime in the long term (over hours,
and even days) under different workloads both in mem-
ory and on persistent storage.
One direction for similar inquiries might be to exam-
ine data lifetime with a more accurate simulation, such
as one that would reﬂect the physical characteristics of
the underlying devices `a la work by Gutmann [11, 12].
Another area for future work is improving our sim-
ulation platform. Speed is a fundamental limitation
of TaintBochs’ current incarnation because of the ﬁne-
grained tainting and detailed logging that it does. Taint-
Bochs can run as much as 2 to 10 times slower than
Bochs itself. The enormity of the logging done by Taint-
Bochs also presents a problem for our postmortem anal-
ysis tools, since it can easily take minutes or hours to
replay a memory log to an interesting point in time.
We have several ideas for optimizing our system. By
reducing the volume of data we log, or simply doing
away with our dependency on logging altogether, we
could vastly improve TaintBochs overheads. The whole-
system logging technique used in ReVirt [9], for exam-
ple, only had a 0-8% performance cost.
Reduced logging overhead also opens up the pos-
sibility of moving TaintBochs functionality onto faster
whole-system simulation environments like those dis-
cussed in section 5. The right trade-offs could allow us
to do TaintBochs-like analysis in production scenarios.
7 Conclusion
Minimizing data lifetime greatly decreases the
chances of sensitive data exposure. The need for min-
imizing the lifetime of sensitive data is supported by a
signiﬁcant body of literature and experience, as is the
recognition of how difﬁcult it can be in practice.
We explored how whole system simulation can pro-
vide a practical solution to the problem of understanding
data lifetime in very large and complex software systems
through the use of hardware level taint analysis.
We demonstrated the effectiveness of this solution by
implementing a whole system simulation environment
called TaintBochs and applying it to analyze sensitive
data lifetime in a variety of large real world applications.
We used TaintBochs to study sensitive data lifetime
in real world systems by examining password handing
in Mozilla, Apache, Perl, and Emacs. We found that
these systems and the components that they rely on han-
dle data carelessly, resulting in sensitive data being prop-
agated widely across memory with no provisions made
to purge it. This is especially disturbing given the huge
volume of sensitive data handled by these applications
on a daily basis. We further demonstrated that a few
practical changes could drastically reduce the amount of
long lived sensitive data in these systems.
8 Acknowledgments
This work was supported in part by the National Sci-
ence Foundation under Grant No. 0121481 and a Stan-
ford Graduate Fellowship.
References
[1] Apache Software Foundation. The Apache HTTP Server project.
http://httpd.apache.org.
[2] K. Ashcraft and D. Engler. Using programmer-written compiler
extensions to catch security holes. In IEEE Symposium on Secu-
rity and Privacy, May 2002.
[3] V. Bala, E. Duesterwald, and S. Banerjia. Dynamo: a transparent
dynamic optimization system. ACM SIGPLAN Notices, 35(5):1–
12, 2000.
[4] M. Blaze. A cryptographic ﬁle system for UNIX. In ACM Con-
ference on Computer and Communications Security, pages 9–16,
1993.
[9] G. W. Dunlap, S. T. King, S. Cinar, M. A. Basrai, and P. M.
Chen. ReVirt: enabling intrusion analysis through virtual-
machine logging and replay. SIGOPS Operating Systems Review,
36(SI):211–224, 2002.
[10] Gentoo Linux. http://www.gentoo.org.
[11] P. Gutmann. Secure deletion of data from magnetic and solid-
state memory. In Proceedings of the 6th USENIX Security Sym-
posium, july 1996.
[12] P. Gutmann. Data remanence in semiconductor devices. In Pro-
ceedings of the 7th USENIX Security Symposium, Jan. 1998.
[13] P. Gutmann. Software generation of practically strong random
In Proceedings of the 8th USENIX Security Sympo-
numbers.
sium, August 1999.
[14] M. Howard.
Some bad news and some good news.
http://msdn.microsoft.com/library/default.
asp?url=/library/en-us/dncode%/html/
secure10102002.asp, October 2002.
[15] IBM Rational software. IBM Rational Purify. http://www.
rational.com.
[16] V. Kiriansky, D. Bruening, and S. Amarasinghe. Secure exe-
In Proceedings of the 11th
cution via program shepherding.
USENIX Security Symposium, August 2002.
[17] D. Lea. A memory allocator. http://gee.cs.oswego.
edu/dl/html/malloc.html.
[18] P. S. Magnusson, M. Christensson, J. Eskilson, D. Forsgren,
G. Hallberg, J. Hogberg, F. Larsson, A. Moestedt, and B. Werner.
Simics: A full system simulation platform.
IEEE Computer,
35(2):50–58, February 2002.
[19] N. Nethercote and J. Seward. Valgrind: A program supervision
framework. In O. Sokolsky and M. Viswanathan, editors, Elec-
tronic Notes in Theoretical Computer Science, volume 89. Else-
vier, 2003.
[20] Perl security manual page. http://www.perldoc.com/
perl5.6/pod/perlsec.html.
[21] N. Provos. Encrypting virtual memory. In Proceedings of the
10th USENIX Security Symposium, pages 35–44, August 2000.
[22] M. Rosenblum, S. A. Herrod, E. Witchel, and A. Gupta. Com-
plete computer system simulation: The SimOS approach. IEEE
Parallel and Distributed Technology: Systems and Applications,
3(4):34–43, Winter 1995.
[23] J. S. Type Qualiﬁers: Lightweight Speciﬁcations to Improve Soft-
ware Quality. PhD thesis, University of California, Berkeley,
December 2002.
[24] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner. Detecting
format string vulnerabilities with type qualiﬁers. In Proc. 10th
USENIX Security Symposium, August 2001.
[25] D. A. Solomon and M. Russinovich. Inside Microsoft Windows
2000. Microsoft Press, 2000.
[26] R. Stallman et al. GNU Emacs. ftp://ftp.gnu.org/pub/
gnu/emacs.
[5] Bochs: The cross platform IA-32 emulator. http://bochs.
[27] The Mozilla Organization. Home of the mozilla, ﬁrebird, and
sourceforge.net/.
camino web browsers. http://www.mozilla.org/.
[6] P. Broadwell, M. Harren, and N. Sastry. Scrash: A system for
generating secure crash information. In Proceedings of the 11th
USENIX Security Symposium, August 2003.
[7] M. Burrows, S. N. Freund, and J. Wiener. Run-time type check-
ing for binary programs. International Conference on Compiler
Construction, April 2003.
[8] B. Cmelik and D. Keppel. Shade: a fast instruction-set simulator
for execution proﬁling. In Proceedings of the 1994 ACM SIG-
METRICS conference on Measurement and modeling of com-
puter systems, pages 128–137. ACM Press, 1994.
[28] J. Viega.
Protecting sensitive data in memory.
http:
//www-106.ibm.com/developerworks/security/
library/s-data.html?dwzo%ne=security.
[29] J. Viega and G. McGraw. Building Secure Software. Addison-
Wesley, 2002.
[30] VMware, Inc. VMware virtual machine technology. http:
//www.vmware.com/.
[31] E. Witchel and M. Rosenblum. Embra: Fast and ﬂexible machine
simulation. In Measurement and Modeling of Computer Systems,
pages 68–79, 1996.
A Data Lifetime by Memory Region Type
Most data in software can be classiﬁed in terms of
its allocation discipline as static, dynamic, or stack data.
Allocation and release of each kind of data occurs in a
different way: static data is allocated at compile and link
time, dynamic data is allocated explicitly at runtime, and
stack data is allocated and released at runtime accord-
ing to an implicit stack discipline. Similarly, taints in
each kind of data are likely to persist for different lengths
of time according to its allocation class. The allocators
used in various operating systems vary greatly, so the de-
tails will vary from one system to another. To show the
complexity of determining when freed memory is likely
to be reallocated, we describe the reallocation behavior
of Linux and the GNU C library typically used on it:
• Static data. Static data persists at least as long as the
process itself. How much longer depends on the op-
erating system and the system’s activity level. The
Linux kernel in particular takes a very “lazy” ap-
proach to clearing pages. As with most kernels, pages
are not zeroed when they are freed, but unlike some
others (such as Windows NT [25] and descendants)
pages are not zeroed in a background thread either.
Pages are not zeroed when memory is requested by
a process, either. Only when a process ﬁrst tries to
access an allocated page will Linux actually allocate
and zero a physical page for its use. Therefore, under
Linux static data persists after a process’s termination
as long as it takes the kernel to reassign its page to
another process. (Pages reclaimed from user process
may also be allocated by the kernel for its own use,
but in that case they may not be zeroed immediately
or even upon ﬁrst write.)
When allocation and zeroing does become neces-
sary, the Linux kernel’s “buddy allocator” for pages
is biased toward returning recently freed pages. How-
ever, its actual behavior is difﬁcult to predict, because
it depends on the system’s memory allocation pattern.
When single free pages are coalesced into larger free
blocks by the buddy allocator, they are less likely
to be returned by new allocation requests for single
pages. They are correspondingly more likely to be
returned for multi-page allocations of the proper size,
but those are far rarer than single-page allocations.
• Dynamic data. Dynamic data only needs to per-
sist until it is freed, but it often survives signiﬁ-
cantly longer. Few dynamic memory allocators clear
memory when it is freed; neither the Linux kernel
dynamic memory allocator (kmalloc()) nor the
glibc 2.x dynamic memory allocator (malloc())
zeroes freed (or reallocated) memory. The question
then becomes how soon the memory is reassigned on
a new allocation. This is of course system-dependent.
In the case of Linux, the answer differs between the
kernel and user-level memory allocators, so we treat
those separately.
The Linux kernel “slab” memory allocator draws
each allocation from one of several “pools” of ﬁxed-
size blocks. Some commonly allocated types, such
as ﬁle structures, have their own dedicated pools;
memory for other types is drawn from generic pools
chosen based on the allocation size. Within each
pool, memory is allocated in LIFO order, that is, the
most recently freed block is always the ﬁrst one to be
reused for the next allocation.
The GNU C library, version 2.x, uses Doug Lea’s
implementation of malloc() [17], which also pools
blocks based on size. However, its behavior is far
more complex. When small blocks (less than 512
bytes each) are freed, they will be reused if allo-
cations of identical size are requested immediately.
However, any allocation of a large block (512 bytes
or larger) causes freed small blocks to be coalesced
into larger blocks where possible. Otherwise, allo-
cation happens largely on a “best ﬁt” basis. Ties are
broken on a FIFO basis, that is, less recently freed
blocks are preferred. In short, it is difﬁcult to predict
when any given free block will be reused. Dynamic
data that is never freed behaves in a manner essen-
tially equivalent to static data.
• Stack data. Data on a process’s stack changes con-
stantly as functions are called and return. As a result,
an actively executing program should tend to clear
out data in its stack fairly quickly. There are some im-
portant exceptions. Many programs have some kind
of “main loop” below which they descend rarely, of-
ten only to terminate execution. Data on the stack
below that point tends to remain for long periods.
Second, some programs occasionally allocate large
amounts of stack space e.g. for input or output buffers
(see 4.1.2). Such data may only be fully cleared out
by later calls to the same routine, because other rou-
tines are unlikely to grow the stack to the point that
much of the buffer is cleared. If data read into large
buffers on the stack is sensitive, then it may be long-
lived. Data that remains on the stack at program ter-
mination behaves the same way as static data.
Most of the accounts above only describe when memory
tends to reallocated, not when it is cleared. These are not
the same because in most cases, reallocated memory is
not necessarily cleared by its new owner. Memory used
as an input or output buffer or as a circular queue may
only be cleared as it is used and perhaps not at all (by
this owner) if it is larger than necessary. Padding bytes
in C structures, inserted by the programmer manually or
the compiler automatically, may not be cleared either.