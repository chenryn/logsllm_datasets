I am currently facing a use case where I need to control the timing and method by which Celery workers dequeue tasks from RabbitMQ. The task dequeuing needs to be synchronized with an external event that occurs outside the Celery context. My primary concern is whether Celery provides the necessary flexibility to manage this process.

After some research, I have identified a few potential approaches:

1. **Use `basic.get` Instead of `basic.consume`:** 
   - By default, Celery uses `basic.consume` (push semantics) for task retrieval. However, I would like to trigger `basic.get` based on an external event. Is it possible to override the default behavior without modifying the core Celery code?

2. **Custom Remote Control of Workers:**
   - Another approach is to remotely control the workers when the external event is triggered. However, the documentation does not clearly explain how remote control commands can be used to manage task dequeuing.

I prefer to continue using Celery and avoid writing a custom queue processing solution on top of AMQP. 

Additionally, there are two more advanced options to consider:

1. **Define a Custom Exchange Type in RabbitMQ:**
   - This allows you to create custom routing rules that control which tasks are sent to which queues. This could provide more granular control over the task distribution.

2. **Define a Custom Celery Mediator:**
   - A custom mediator can be implemented to control the movement of tasks from queues to worker pools. This would give you more control over the task processing flow.

These options might offer the flexibility I need to synchronize task dequeuing with external events.