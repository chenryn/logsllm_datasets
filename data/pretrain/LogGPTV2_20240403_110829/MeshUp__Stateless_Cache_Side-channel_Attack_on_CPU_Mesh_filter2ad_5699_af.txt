Table IX shows the results (columns with “N”), and fewer
pattern traces are observed (dropped from 56 to 40), mainly
because the noises interfere with the probe and make the delay
traces be ﬁltered out by our script. Yet, ACC1 is similar
(97.1% vs. 97.2% in Table VIII). Hence, we expect the attack
can be successful in the noisy environment when more delay
traces are collected.
Pattern
A
B
C
All
#
N, CR
2, 3
14, 11
24, 18
40, 32
Acc1
N, CR
96.2%, 99.5%
98.5%, 99.0%
96.3%, 95.1%
97.1%, 96.9%
Perfect
N, CR
0, 2
4, 5
1, 1
5, 8
Acc3
N, CR
21.0%, 30.1%
22.8%, 26.7%
20.8%, 19.7%
21.5%, 23.1%
TABLE IX: Results with background workload (columns “N”)
and core-remapping (columns “CR”).
Core Remapping. In the previous evaluation, we ﬁxed the
victim at a core when RSA encryption is executed. On cloud
13
platforms, neither the attacker nor the victim has control over
core allocation, as the OS or hypervisor may remap tasks to
other cores silently [72]. The core remapping process may
introduce noises, and we evaluate the impact here.
First, we try to estimate the frequency of core remapping.
We ran the attack of Section VII-B in a VM hosted by QEMU,
and observed that core remapping has happened 23 times in
10,395 seconds, meaning that core remapping happens every
7.5 minutes on average, which is far longer than a round of
RSA encryption. Therefore, most delay traces would not be
impacted. Then, we estimate how many bits can be recovered
from the traces when core remapping is happening. Initially,
we tried to force the OS to remap the victim task to another
core with taskset, but found Linux does not remap a task
under this instruction. Then, we tried to launch a large number
(e.g., 72) of dummy threads, which forces OS to schedule
tasks among cores. We found core remapping happens 52
times during the 1,000 runs of RSA, which means 52 traces
are directly polluted by core remapping while the rest are
indirectly interfered. In Table IX (columns with “CR”), we
can see that the results are similar as the case with background
workload. The number of pattern traces is 32, while ACC1 is
96.9%.
Another OS factor that can impact MESHUP is memory
swapping. During evaluation, we did not prevent memory
swapping, so noises introduced by it have been taken into
consideration.
C. App Fingerprinting
We tested the coherence-based probe for app ﬁngerprinting,
with the 40 apps in Phoronix Test Suite used by [70]. Our
testbed has two CPUs, so we let the attacker’s code runs on
two different CPUs and a random core is occupied in each
CPU. The victim’s app runs on a random core on one of the
two CPUs. When collecting delay traces, the attacker probes
the UPI bus in a 10ms interval, so 30,000 samples can be
collected for each app run (i.e., 5 min). In the pre-processing
phase, we remove the abnormal samples (or noises) that are
out of the normal range (30000, 600000) and smooth the trace
with a window size of 80 samples. We train an RNN classiﬁer
with the processed training traces and classify the traces in the
testing data. To further reduce the length of the traces sent to
the RNN model, we split a trace by window of 120 samples,
and each window is convoluted to a 16-dimension vector.
Therefore a trace will be compressed to 250 (30000/120) 16-
dimension vectors. Compressing the time-series has also been
adopted by other works in intrusion detection [73].
In our evaluation, we employ Bi-directional LSTM with
Attention (AttBLSTM) [74], which has been broadly used to
classify time-series, to classify a test trace to an app. Table X
shows the model hyper-parameters.
Results. MESHUP has 82.27% classiﬁcation accuracy. In
comparison, the PRIME-PROBE method leveraged by [70]
yields 78% accuracy. We conclude coherence-based probe
can achieve satisfactory attack accuracy under the cross-CPU
setting. Admittedly, the accuracy is not high enough, mainly
batch size
64
hidden layer size
384
drop out
0.1
attention layer size
512
TABLE X: Hyper-parameters of the AttBLSTM model used
for app ﬁngerprinting.
because the execution of those apps comes with a lot of
random factors, like random core location and random input.
Yet, it is surprising the coarse-grained coherence-based probe
has better accuracy than the ﬁne-grained probe
[70]. We
speculate the rise is resulting from better coverage of cache
transactions: our attack can probe transactions from all cache
sets of a CPU, while a stateful cache attack can only probe
one cache set at a time. The overall cache accessing frequency
derived under our probe characterizes an app better.
Website Fingerprinting. We have also tested the coherence-
based probe on website ﬁngerprinting. The details are elabo-
rated in Appendix H.
VIII. DISCUSSION
Limitations. 1) To evaluate the eviction-based probe, we use
RSA as the victim application, whose mesh trafﬁc mainly
belongs to T1-T2. Other applications may show different pat-
terns: e.g., I/O intensive applications could introduce promi-
nent mesh trafﬁc between PCIe stop and LLC slices. We
plan to test such applications in the future. 2) MESHUP
bypasses the existing defenses at the cost of obtaining coarse-
grained information about cache activities. In stateful cache
attacks like PRIME+PROBE, the attacker can precisely evict a
cache set shared with a victim and learn the which memory
address/range accessed by the victim. However, MESHUP at
most tells which LLC slice the victim accesses. As such, we
choose the Java-based RSA implementations which leak more
information. 3) We chose Intel CAT as the defense following
recent cache side-channel attacks like Xlate [3]. The other
stronger defenses like DAWG [75] and temporal isolation [5]
are not tested because we cannot ﬁnd their implementation
on Intel CPU (e.g., DAWG requires hardware modiﬁcation)
or the mainstream OSes (e.g., temporal isolation builds on
seL4). However, as MESHUP is based on the stateless channel,
which admittedly is out of the mitigation scope of stateful
protections [5], we expect MESHUP to be effective under these
defenses. 4) For the attack against RSA encryption, we used
a script to ﬁlter the useful traces with hard-coded parameters,
but we expect these parameters can be replaced with a learned
classiﬁer, e.g., an LSTM model. 5) Our evaluation is done
on Intel CPUs. In the future, we plan to test other CPUs
with mesh interconnects like ARM Neoverse [18]. 6) For
the core remapping experiment, the measurements are not
isolating the cases where core mappings change, which might
underestimate its impact.
Implications and Defenses. The key takeaway message from
our study is that the mesh interconnect on server-grade CPUs
introduces stateless cache side-channels. This is counter-
intuitive at ﬁrst sight, but the new interconnect design inter-
twines the cache lines on the move from different applications,
introducing new types of resource contention. Together with
LoR [8], MESHUP draws a comprehensive picture about the
contention side-channel of CPU interconnect, and we hope
more attention can be spared on this class of issues.
For defenses, in Section VI-E, we proposed a simple so-
lution that isolates LLC to reduce the SNR for T1-T2 trafﬁc
exploited by MESHUP. Yet, the other types of trafﬁc still leak
information. On the other hand, if spatial isolation can go
a step further to partition interconnect bandwidth, MESHUP
might be thwarted. However, as mentioned in [5], “no support
for bandwidth partition exists on contemporary mainstream
hardware”. Though Intel recently proposed a technique named
Memory Bandwidth Allocation (MBA) [76], which limits
the bandwidth a core can issue to memory, the limit is an
approximation and insufﬁcient for threat mitigation [5].
Instead of strong mitigation based on isolation, we believe
mechanisms that increase the aggression difﬁculty is more
likely to be adopted. One example is cache randomization. By
forcing the mapping between physical addresses and cache set
index dynamic and unpredictable, ﬁnding the right eviction
sets is expected to be more difﬁcult, which could make the
probes of MESHUP unstable. However, recent studies [77],
[78], [79] have shown the previous approaches like CEASER-
S [80] and ScatterCache [81] are broken under new attack
methods. Following these discoveries, Song et al. proposed to
ﬁx the ﬂaws of the existing mechanisms [77] and Saileshwar et
al. proposed fully associative cache [82]. We plan to evaluate
whether the new methods are effective against MESHUP.
IX. CONCLUSION
is different from previous cache side-channels,
In this work, we show stateless cache side-channel on the
mesh interconnect, or MESHUP, that can leak memory access
patterns of a victim program on server-grade CPUs. The side-
channel
in
that it does not rely on stateful micro-architectural changes
made by the victim. Therefore it can bypass the existing
defenses based on spatial and temporal isolation. To reveal
the consequences of MESHUP, we analyzed RSA encryption
and application ﬁngerprinting. The results show that MESHUP
is very effective. We believe mesh interconnect opens up new
opportunities for security research, and its implications should
be further examined.
ACKNOWLEDGEMENT
We thank the valuable feedback from the anonymous re-
viewers, which help us signiﬁcantly improve this paper. The
Fudan authors are supported by NSFC 61802068. The UCI
author is partially supported by gift from Microsoft and Cisco.
REFERENCES
[1] Y. Yarom and K. Falkner, “Flush+ reload: a high resolution, low noise,
l3 cache side-channel attack,” in 23rd {USENIX} Security Symposium
({USENIX} Security 14), 2014, pp. 719–732.
[2] C. Disselkoen, D. Kohlbrenner, L. Porter, and D. Tullsen, “Prime+ abort:
A timer-free high-precision l3 cache attack using intel {TSX},” in 26th
{USENIX} Security Symposium ({USENIX} Security 17), 2017, pp. 51–
67.
14
[3] S. Van Schaik, C. Giuffrida, H. Bos, and K. Razavi, “Malicious
management unit: Why stopping cache attacks in software is harder
than you think,” in 27th {USENIX} Security Symposium ({USENIX}
Security 18), 2018, pp. 937–954.
[4] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee, “Last-level cache
side-channel attacks are practical,” in 2015 IEEE symposium on security
and privacy.
IEEE, 2015, pp. 605–622.
[5] Q. Ge, Y. Yarom, T. Chothia, and G. Heiser, “Time protection: the
the Fourteenth EuroSys
missing os abstraction,” in Proceedings of
Conference 2019, 2019, pp. 1–17.
[6] K. T. Nguyen, “Introduction to Cache Allocation Technology in the
Intel Xeon Processor E5 v4 Family,” https://software.intel.com/content
/www/us/en/develop/articles/introduction-to-cache-allocation-technolog
y.html, 2016, [Online; accessed 10-August-2020].
[7] F. Liu, Q. Ge, Y. Yarom, F. Mckeen, C. Rozas, G. Heiser, and
R. B. Lee, “Catalyst: Defeating last-level cache side channel attacks
in cloud computing,” in 2016 IEEE international symposium on high
performance computer architecture (HPCA).
IEEE, 2016, pp. 406–
418.
[8] R. Paccagnella, L. Luo, and C. W. Fletcher, “Lord of the ring (s): Side
channel attacks on the {CPU} on-chip ring interconnect are practical,”
in 30th {USENIX} Security Symposium ({USENIX} Security 21), 2021.
[9] Intel, “Intel Xeon Scalable Processors,” https://www.intel.com/conten
t/www/us/en/products/processors/xeon/scalable.html, 2020, [Online; ac-
cessed 10-August-2020].
[10] S. Bell, B. Edwards, J. Amann, R. Conlin, K. Joyce, V. Leung,
J. MacKay, M. Reif, L. Bao, J. Brown et al., “Tile64-processor: A 64-
core soc with mesh interconnect,” in 2008 IEEE International Solid-
State Circuits Conference-Digest of Technical Papers.
IEEE, 2008, pp.
88–598.
[11] S. Vangal, J. Howard, G. Ruhl, S. Dighe, H. Wilson, J. Tschanz,
D. Finan, P. Iyer, A. Singh, T. Jacob et al., “An 80-tile 1.28 tﬂops
network-on-chip in 65nm cmos,” in 2007 IEEE International Solid-State
Circuits Conference. Digest of Technical Papers.
IEEE, 2007, pp. 98–
589.
[12] D. J. Bernstein, J. Breitner, D. Genkin, L. G. Bruinderink, N. Heninger,
T. Lange, C. van Vredendaal, and Y. Yarom, “Sliding right into disaster:
Left-to-right sliding windows leak,” in International Conference on
Cryptographic Hardware and Embedded Systems. Springer, 2017, pp.
555–576.
[13] T. T. Kevin Fogarty, “Chasing proﬁts and Intel, AMD sets sights on
data centers,” https://www.spglobal.com/marketintelligence/en/news-ins
ights/latest-news-headlines/chasing-proﬁts-and-intel-amd-sets-sights-o
n-data-centers-57996772, 2020.
[14] J. Gilbert and M. Rowland, “The intel® xeon® processor e5 family
architecture, power efﬁciency, and performance,” in 2012 IEEE Hot
Chips 24 Symposium (HCS).
IEEE, 2012, pp. 1–25.
[15] Unknown, “Mesh Interconnect Architecture - Intel,” https://en.wikichip.
org/wiki/intel/mesh interconnect architecture, 2020, [Online; accessed
5-August-2020].
[16] ——, “Intel Unveils 3rd Gen Ice Lake-SP Xeon CPU Fam-
ily,” https://wccftech.com/intel-unveils-ice-lake-sp-xeon-cpu-family-1
0nm-sunny-cove-cores-28-core-die/, 2020,
accessed 18-
August-2020].
[Online;
[17] M. B. Taylor, J. Kim, J. Miller, D. Wentzlaff, F. Ghodrat, B. Greenwald,
H. Hoffman, P. Johnson, W. Lee, A. Saraf et al., “A 16-issue multiple-
program-counter microprocessor with point-to-point scalar operand net-
work,” in 2003 IEEE International Solid-State Circuits Conference,
2003. Digest of Technical Papers. ISSCC.
IEEE, 2003, pp. 170–171.
[18] J. D. Gelas, “New ARM IP Launched: CMN-600 Interconnect for 128
Cores and DMC-620, an 8Ch DDR4 IMC,” https://www.anandtech.com/
show/10711/arm-cmn-600-dmc-620-128-cores-8-channel-ddr4, 2020,
[Online; accessed 18-August-2020].
[19] D. Wentzlaff, P. Grifﬁn, H. Hoffmann, L. Bao, B. Edwards, C. Ramey,
M. Mattina, C.-C. Miao, J. F. Brown III, and A. Agarwal, “On-chip
interconnection architecture of the tile processor,” IEEE micro, vol. 27,
no. 5, pp. 15–31, 2007.
[20] Unknown, “Intel Ultra Path Interconnect,” https://en.wikipedia.org/wiki/
Intel Ultra Path Interconnect, 2021, [Online; accessed 13-April-2021].
[21] A. Farshin, A. Roozbeh, G. Q. Maguire Jr, and D. Kosti´c, “Make the
most out of last level cache in intel processors,” in Proceedings of the
Fourteenth EuroSys Conference 2019, 2019, pp. 1–17.
[22] M. Yan, R. Sprabery, B. Gopireddy, C. Fletcher, R. Campbell, and
J. Torrellas, “Attack directories, not caches: Side channel attacks in a
non-inclusive world,” in 2019 IEEE Symposium on Security and Privacy
(SP).
IEEE, 2019, pp. 888–904.
[23] R. Sch¨one, T. Ilsche, M. Bielert, A. Gocht, and D. Hackenberg, “Energy
efﬁciency features of the intel skylake-sp processor and their impact on
performance,” in 2019 International Conference on High Performance
Computing & Simulation (HPCS).
IEEE, 2019, pp. 399–406.
[24] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart, “Cross-tenant
side-channel attacks in paas clouds,” in Proceedings of the 2014 ACM
SIGSAC Conference on Computer and Communications Security, 2014,
pp. 990–1003.
[25] G. Irazoqui, T. Eisenbarth, and B. Sunar, “S $ a: A shared cache attack