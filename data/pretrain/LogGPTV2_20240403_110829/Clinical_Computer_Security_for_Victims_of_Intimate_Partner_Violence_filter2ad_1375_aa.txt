title:Clinical Computer Security for Victims of Intimate Partner Violence
author:Sam Havron and
Diana Freed and
Rahul Chatterjee and
Damon McCoy and
Nicola Dell and
Thomas Ristenpart
Clinical Computer Security for Victims of 
Intimate Partner Violence
Sam Havron, Diana Freed, and Rahul Chatterjee, Cornell Tech; Damon McCoy, 
New York University; Nicola Dell and Thomas Ristenpart, Cornell Tech
https://www.usenix.org/conference/usenixsecurity19/presentation/havron
This paper is included in the Proceedings of the 28th USENIX Security Symposium.August 14–16, 2019 • Santa Clara, CA, USA978-1-939133-06-9Open access to the Proceedings of the 28th USENIX Security Symposium is sponsored by USENIX.Clinical Computer Security for Victims of Intimate Partner Violence
Sam Havron∗,1
Diana Freed∗,1
Nicola Dell1
1 Cornell Tech
Abstract
Digital insecurity in the face of targeted, persistent at-
tacks increasingly leaves victims in debilitating or even life-
threatening situations. We propose an approach to helping
victims, what we call clinical computer security, and explore
it in the context of intimate partner violence (IPV). IPV is
widespread and abusers exploit technology to track, harass,
intimidate, and otherwise harm their victims. We report on the
iterative design, reﬁnement, and deployment of a consultation
service that we created to help IPV victims obtain in-person
security help from a trained technologist. To do so we created
and tested a range of new technical and non-technical tools
that systematize the discovery and investigation of the compli-
cated, multimodal digital attacks seen in IPV. An initial ﬁeld
study with 44 IPV survivors showed how our procedures and
tools help victims discover account compromise, exploitable
misconﬁgurations, and potential spyware.
1 Introduction
As computers and other digital technologies take an increas-
ingly central role in people’s lives, computer insecurity has
for some people become debilitating and even life-threatening.
Activists and other dissidents are monitored [7, 23, 25, 26],
journalists are harassed and doxed [10], gamers are subjected
to bullying [9], and abusers are exploiting technology to
surveil and harass their intimate partners [35]. Traditional se-
curity mechanisms most often fail in the face of such targeted,
personalized, and persistent attacks.
A different approach for helping targeted individuals is
what we call clinical computer security. The idea is to provide
victims of dangerous attacks the opportunity to obtain person-
alized help from a trained technologist. Just like people visit
doctors for health problems, seek out lawyers when suffering
legal troubles, or hire accountants for complex tax situations,
so too should victims of dangerous digital attacks have experts
to assist them. But while these other examples of professional
∗These authors contributed equally to the paper.
Rahul Chatterjee1
Damon McCoy2
Thomas Ristenpart1
2 New York University
services have a long history leading to today’s best practices,
for computer security we are essentially starting from scratch:
existing technology support services are ill-suited for helping
victims in dangerous situations. The research challenge is
therefore to develop rigorous, evidence-based best practices
for clinical approaches to computer security, as well as design
the supporting tools needed to help victims.
In this paper we explore clinical computer security in the
important context of intimate partner violence (IPV)1. IPV
is widespread, affecting one out of three women and one out
of six men over the course of their lives [32]. Prior work has
shown how abusers exploit technology to harass, imperson-
ate, threaten, monitor, intimidate, and otherwise harm their
victims [8, 14, 19, 20, 27, 35, 43]. Prevalent attacks include
account compromise, installation of spyware, and harassment
on social media [20,27]. In many cases digital attacks can lead
to physical violence, including even murder [34]. Unfortu-
nately, victims currently have little recourse, relying on social
workers or other professionals who report having insufﬁcient
computer security knowledge to aid victims [19].
Working in collaboration with the New York City
Mayor’s Ofﬁce to End Domestic and Gender-Based Violence
(ENDGBV), we designed, prototyped, and deployed a clin-
ical computer security service for IPV survivors.2 Doing so
required not only developing ﬁrst-of-their-kind protocols for
how to handle face-to-face consultations while ensuring safety
for both clients (the term we use for IPV victims in this con-
text) and technology consultants, but also the design and
implementation of new technical and non-technical instru-
ments that help to tease apart the complicated, multifaceted
digital insecurities that clients often face.
We designed a ﬁrst-of-its-kind consultation procedure via
a careful, stakeholder-advised process that made client safety
paramount. Initial designs were reﬁned over two months via
14 focus groups with a total of 56 IPV professionals, including
1A full version of this paper and materials is available at: https://www.
ipvtechresearch.org
2Our initial and reﬁned research protocols were approved by our institu-
tion’s IRB and the ENDGBV leadership.
USENIX Association
28th USENIX Security Symposium    105
social workers, police, lawyers, mental health professionals,
and more. This led to substantive feedback and reﬁnements,
culminating in a consultation design that appropriately takes
into account the socio-technical complexity of IPV and the
unique risks that clients face.
Our consultation procedure starts with a referral from an
IPV professional, and then proceeds through a face-to-face
discussion where we seek to understand the client’s technol-
ogy issues, investigate their digital assets via programmatic
and manual inspections, and advise them and the referring
professional on potential steps forward. This last step, impor-
tantly, involves procedures for clearly communicating new
found information about technology abuse so that profession-
als can help clients with safety planning. Supporting this
understand-investigate-advise framework are a number of
tools that we created, including: a standardized technology
assessment questionnaire (the TAQ); a diagrammatic method
for summarizing a client’s digital assets called a technograph;
succinct guides for helping consultants and clients manu-
ally check important security conﬁgurations; and a new spy-
ware scanning tool, called ISDi, that programmatically detects
whether apps dangerous in IPV contexts are installed on a
client’s mobile devices.
After completing our design process, we received permis-
sion to meet with clients in order to both help them and ﬁeld
test our consultation procedures and tools. Thus far, we have
met with 44 clients and our consultations have discovered
potential spyware, account compromise, or exploitable mis-
conﬁgurations for 23 of these clients. The tools we developed
proved critical to these discoveries, and without them our con-
sultations would have been signiﬁcantly less effective. For
clients with discovered issues, we provided advice about im-
proving security, in parallel with appropriate safety planning
guided by case managers knowledgeable about their abuse
history and current situation. Many other clients expressed
relief that our consultations did not discover any problems.
Professionals at the FJCs have uniformly responded posi-
tively to our ﬁeld study, and reported that the consultations
are helpful to their clients. Demand for consultations has
increased and we are performing them on an ongoing basis.
More broadly, our tools, including ISDi, will be made open-
source and publicly available, providing a suite of resources
for testing the replicability of our clinical approach in other
locations. Whether our approaches and methods can be useful
for other targeted attack contexts beyond IPV is an interesting
open question raised by our work. We discuss this question,
and others, at the end of the paper.
2 Towards Clinical Computer Security
This paper considers targeted attacks in the context of intimate
partner violence (IPV). Prior work indicates that IPV victims
are frequently subject to technology abuse [8, 14, 19, 20, 27,
35, 43], and a taxonomy by Freed et al. [20] includes four
broad categories: (1) ownership-based attacks in which the
abuser owns the victim’s digital accounts or devices, giving
them access and control; (2) account or device compromise;
(3) harmful messages or posts (e.g., on social media); and (4)
exposure of private information online. Abusers use access to
victim devices or accounts to setup dangerous conﬁgurations,
such as adding their ﬁngerprints to be accepted for device
login, conﬁguring devices to synchronize data with an abuser-
controlled cloud account, or setting up tools such as Find My
Phone to send location updates to an abuser’s email address.
Another avenue is installation of spyware apps that provide
powerful features for monitoring devices [8].
Technology abuse in IPV is certainly complex in the ag-
gregate, but even speciﬁc individuals suffer from complex,
multifaceted threats. To concretize this, we give an exam-
ple. For privacy reasons it is not any particular person’s story.
However, it is representative of many of the actual client
situations we have encountered in our work.
Example scenario, Carol’s experience: Carol’s now ex-
husband subjected her to several years of increasing physical,
emotional, and technology abuse before she obtained an or-
der of protection, physically moved out, and ﬁled for divorce.
They are in a custody battle over their two children, ages four
and ten, who live with the ex-husband part of the time.
Carol knows that he installed spyware on at least one of
her devices, because she found the purchase of mSpy on their
joint credit card statement. Additionally, he had access to her
private photos that he then posted on Facebook. He would
also routinely, over the period of a year, “hack” into her
online accounts, posing as her in efforts to further alienate
her from her friends and family. He even locked her out of her
GMail account by changing the recovery emails and phone
number to his, which was devastating to her career in sales
because it contained her business contacts.
Carol currently has ﬁve devices: a new Apple iPhone that
is her primary device, two Android phones used by her chil-
dren, an Apple iPad tablet bought for her children by her
ex-husband, and a several-year-old Apple iPhone originally
bought for her by her ex-husband. She routinely uses Face-
book, a new GMail account (since her old one was stolen by
her ex-husband), and a variety of other social media apps
that are important for her work in sales.
This representative example highlights the complexities
faced by IPV victims. Carol has a complicated digital foot-
print that includes a wide variety of devices and online ac-
counts, some of which may be linked (e.g., different devices
may have stored authentication credentials for different online
accounts). She has complicating entanglements, meaning dig-
ital or personal relationships that may enable or complicate
tech abuse, or render its mitigation more difﬁcult. In Carol’s
case, the abuser has access to the children’s devices, owns
some of the devices in her digital footprint, and her need to
use social media for her career limits options for preventing
106    28th USENIX Security Symposium
USENIX Association
harassment via it. The complex timeline of events, such as
when she physically moved out and when the children visit
the abuser, may be directly relevant to the tech problems she
is facing. Finally, there is also the risk that blocking digi-
tal attacks causes an escalation of abuse, such as triggering
physical violence as the abuser seeks to regain his control.
One avenue for improving on the status quo is pursuit
of new technology designs that better resist such targeted
attacks. While doing so is very important, future designs will
not help IPV victims in the near term. More pessimistically,
it may in fact never be possible to rule out damaging attacks
by highly resourced, determined adversaries against lower-
resource victims. We therefore need complementary socio-
technical approaches to helping victims.
Unfortunately, existing victim support services struggle
to help with complicated tech abuse situations [19, 27]. The
case workers, lawyers, police, and other professionals that
work with victims report having insufﬁcient tech expertise to
help victims with digital threats [19]. There currently are no
best practices for how to discover, assess, and mitigate tech
issues [19]. Existing tools for programmatically detecting
spyware are ineffective [8], and the state-of-the-art in practice
is that professionals assume spyware on phones if a victim
reports that the phone is acting strangely [20].
Commercial tech support services (e.g., Geek Squad [36]
or phone stores) are unfortunately not a ready solution for
addressing tech abuse. Prior work reports that victims occa-
sionally use these services [19, 27], but that even when used
they often fail to effectively diagnose problems [20]. We
believe this is because commercial IT support professionals
do not have context-speciﬁc training needed to identify and
handle complex tech abuse situations prevalent in IPV. In the
worst case, they put victims into more danger due to a lack
of appropriate safety planning. Finally, victims with lower
socio-economic status may ﬁnd such services hard to access.
Clinical computer security. We target new approaches for
victims to obtain personalized and appropriately contextual-
ized support from a trained technologist. There are a handful
of existing efforts from which we drew some inspiration. The
Citizen Lab [13] and related Citizen Clinic [1] have been
working for several years with targets of government persecu-
tion, a recent Technology-Enabled Coercive Control (TECC)
clinic was established for IPV victims in Seattle [2], and in-
dividual computer security experts have long informally vol-
unteered to aid those suffering attacks [24]. However, there
has been little research into how such personalized security
services should be systematically designed and deployed.
We propose an approach that we call clinical computer
security. The goal is to develop, in a rigorous, evidence-based
way, a set of best practices for how a technology consultant
can assist a victim — called the client in such a service con-
text — with digital insecurity. Best practices will need to
encompass a range of issues, including how to setup and run
clinics, recruit and train volunteers or paid professionals to
staff them, deal with the many legal issues that will inevitably
arise, and how consultations with clients should proceed. In
this initial work we focus on designing and prototyping con-
sultations, the fundamental element of any clinical approach.
We discuss other aspects of running a clinic in Section 8.
The challenges faced in client consultations. As seen in
Carol’s example, individual IPV victims often experience a
wide range of tech problems. They have a complex digital
footprint, including multiple devices and online accounts,
each of which can be a vector for abuse. They often have many
nuanced entanglements. Existing tools for detecting spyware
have a high false negative rate [8]. To improve outcomes for
IPV victims, we need to design a protocol for face-to-face
consultations that can integrate into existing victim support
infrastructure, help us understand the client’s problems from
their point of view, discover tech risks they may not be aware
of, and safely advise them about what steps they could take
to improve their computer security.
Of course, we can look to other disciplines that use clinical
interventions for guidance, including medicine, social work,
mental health counseling, and even legal practice. These
areas have long histories leading to today’s best practices,
including common interview procedures such as standards for
psychiatric assessments [28] or client-centered advocacy [31].
However, none of these disciplines speak to procedures for
computer security, so while we incorporate ideas from them
when useful, overall, we need new approaches.
3 Methods, Client Safety, and Ethics
We designed a client consultation protocol and associated
instruments to improve computer security outcomes for IPV
victims via face-to-face discussions and both programmatic
and manual investigations of their digital assets (i.e., their
computing devices and online accounts). Here we discuss our
iterative design methods that optimized for client safety.
IPV victims can be in dangerous and even life-threatening
situations, and we made client safety and well-being central
to our methodological approach. No consultation process will
ever be perfect, in the sense that one could guarantee that
all of the client’s technology problems will be discovered,
accurately assessed, and successfully mitigated. Indeed, the