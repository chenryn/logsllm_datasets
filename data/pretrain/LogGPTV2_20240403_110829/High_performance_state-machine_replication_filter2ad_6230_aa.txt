# High-Performance State-Machine Replication

**Authors:**
- Parisa Jalili Marandi, University of Lugano (USI), Switzerland
- Marco Primi, University of Lugano (USI), Switzerland
- Fernando Pedone, University of Lugano (USI), Switzerland

## Abstract
State-machine replication is a well-established approach to achieving fault tolerance by replicating a service across multiple servers. This ensures the service remains available even if one or more servers fail. However, state-machine replication has two primary performance limitations: it introduces overhead in service response time due to the requirement for total command ordering, and it does not allow for increased throughput by adding more replicas. In this paper, we address these issues by employing speculative execution to reduce response time and state partitioning to increase throughput. We demonstrate these techniques using a highly available parallel B-tree service.

## 1. Introduction
Computer systems often achieve fault tolerance through replication. By replicating a service on multiple servers, clients are guaranteed that the service will remain available even if some replicas fail. However, maintaining consistency among the replicas is crucial. State-machine replication is a well-known method for ensuring strong consistency by regulating how client commands are propagated and executed by the replicas. This involves two key requirements: (i) every non-faulty replica must receive every command, and (ii) no two replicas can disagree on the order of received and executed commands. Command execution must be deterministic, meaning that if two replicas execute the same sequence of commands in the same order, they must reach the same state and produce the same output.

While state-machine replication improves service availability, it has two significant performance limitations. First, it introduces overhead in service response time compared to a client-server implementation. Second, service throughput is limited by the throughput of a single replica, as adding more replicas does not significantly improve overall throughput. The increased response time is due to the need to order client commands before execution, which is inherently more costly than sending them directly to a server. The throughput limitation arises because each replica stores a full copy of the service state and handles every command.

In this paper, we address these issues. To reduce the response time overhead, we use speculative (or optimistic) execution, a technique previously applied in replicated databases. Speculative execution allows servers to process commands before their final order is established, overlapping the command execution with the ordering protocol. If the order is confirmed, the command's execution is finalized; otherwise, the commands are rolled back and re-executed in the correct order. We integrate this technique into Ring Paxos, a high-throughput consensus protocol, and show that it is more advantageous than previous proposals because it does not depend on network conditions.

To address the throughput limitation, we propose a state partitioning strategy. This allows applications to decompose their state into sub-states and replicate each sub-state individually. Commands are directed to and executed by the relevant partitions only. By partitioning the state, we enable parallel processing of commands, which is particularly effective for services with perfect state partitioning, where each command accesses only one sub-state. Commands that access multiple sub-states must be carefully ordered to avoid inconsistencies. We discuss how to efficiently integrate this technique into Ring Paxos.

To illustrate our approach, we implement and evaluate a highly available parallel B-tree service. Our service supports three B-tree operations: inserts, deletes, and range queries. We show that speculative execution can reduce response time by up to 16.2%. State partitioning allows service throughput to increase by adding replicas, resulting in throughput nearly four times greater than classic state-machine replication. In our largest configuration, up to 750,000 B-tree commands can be executed per second with a response time below 4 milliseconds.

**Contributions:**
1. Integration of speculative execution into Ring Paxos to reduce the response time of state-machine replication.
2. Presentation of state partitioning in the context of state-machine replication.
3. Illustration of these techniques with a B-tree service capable of efficient command execution.
4. Detailed discussion and experimental assessment of the implementation.

## 2. Background

### 2.1 System Model
We assume a distributed system composed of interconnected nodes within a single geographical location, such as a data center. Nodes may fail by crashing and subsequently recover, but they do not experience arbitrary behavior (i.e., no Byzantine failures). The network is mostly reliable and subject to small latencies, although load unbalances may cause variations in processing and transmission delays. Communication can be one-to-one or one-to-many, and messages can be lost but not corrupted.

Our protocols ensure safety under both asynchronous and synchronous execution periods. The FLP impossibility result states that under asynchronous assumptions, consensus cannot be both safe and live. Therefore, we assume the system is partially synchronous, initially asynchronous, and eventually becomes synchronous at an unknown Global Stabilization Time (GST). Before GST, there are no bounds on message transmission and action execution times. After GST, such bounds exist but are unknown. After GST, nodes are either correct or faulty. A correct node is operational "forever" and can reliably exchange messages with other correct nodes. This assumption is needed to prove liveness properties about the system.

### 2.2 State-Machine Replication
State-machine replication is a fundamental approach to implementing a fault-tolerant service by replicating servers and coordinating client commands among server replicas. The specific implementation depends on the targeted consistency criteria, which in this paper, we assume to be linearizability.

An execution is linearizable if there is a way to reorder its commands in a sequence that respects the semantics of the commands and the order of non-overlapping commands across all clients. Linearizability can be contrasted with sequential consistency, a weaker form of consistency, where the reordering respects the semantics of the commands and the ordering of commands issued by the same client.

Figure 1 illustrates the difference between linearizability and sequential consistency. In the top execution, client C2 modifies the state of a read-write object x, and then client C1 reads a state of x that precedes C2’s update. This execution is sequentially consistent but not linearizable. The bottom execution is both linearizable and sequentially consistent, as C1 is allowed to see a value of x that precedes C2’s update since the two commands overlap in time.

State-machine replication can be implemented as a series of consensus instances. The i-th consensus instance decides on the i-th command (or batch of commands) to be executed by the servers. Consensus guarantees that (i) if a server decides v, then some client proposed v; (ii) no two servers decide different values; and (iii) if one (or more) non-faulty client proposes a value, then eventually some value is decided by all non-faulty servers.

With respect to performance, state-machine replication suffers from two limitations: (i) totally ordering commands delays their execution, increasing the response time experienced by clients compared to a non-replicated client-server setup, and (ii) since every replica contains a full copy of the service state and must receive every command, adding replicas does not significantly improve performance. Some performance improvement can be obtained from optimizations, such as having only one server execute read commands and return the results to the client. Figure 2 compares the performance of a replicated system to a non-replicated client-server system with a workload composed of read-only commands. The graph on the left shows the response time as the number of clients increases, while the graph on the right shows the throughput as replicas are added. Since the workload is composed of read operations only, replication can improve throughput up to four replicas; with eight replicas, the overhead of delivering and discarding read commands prevents further scaling.

We claim that these are fundamental performance limitations, not specific to any particular implementation. In the next section, we describe two mechanisms that address these problems.