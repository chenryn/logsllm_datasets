title:Randomized Intrusion-Tolerant Asynchronous Services
author:Henrique Moniz and
Nuno Ferreira Neves and
Miguel Correia and
Paulo Ver&apos;ıssimo
Randomized Intrusion-Tolerant Asynchronous Services∗
Henrique Moniz, Nuno Ferreira Neves, Miguel Correia, and Paulo Ver´ıssimo
University of Lisboa, Portugal
{hmoniz, nuno, mpc, pjv}@di.fc.ul.pt
Abstract
Randomized agreement protocols have been around for
more than two decades. Often assumed to be inefﬁcient
due to their high expected communication and time com-
plexities, they have remained largely overlooked by the
community-at-large as a valid solution for the deployment
of fault-tolerant distributed systems. This paper aims to
demonstrate that randomization can be a very competi-
tive approach even in hostile environments where arbitrary
faults can occur. A stack of randomized intrusion-tolerant
protocols is described and its performance evaluated un-
der different faultloads. The stack provides a set of relevant
services ranging from basic communication primitives up to
atomic broadcast. The experimental evaluation shows that
the protocols are efﬁcient and no performance reduction is
observed under certain Byzantine faults.
1. Introduction
With the increasing need of our society to deal with
computer- and network-based attacks, the area of intrusion
tolerance has been gaining momentum over the past few
years [25]. Arising from the intersection of two classical
areas of computer science, fault tolerance and security, its
objective is to guarantee the correct behavior of a system
even if some of its components are compromised and con-
trolled by an intelligent adversary.
A pivotal problem in fault- and intrusion-tolerant dis-
tributed systems is consensus. This problem has been spec-
iﬁed in different ways, but basically it aims to ensure that n
processes are able to propose some values and then all agree
on one of these values. The relevance of consensus is con-
siderable because it has been shown equivalent to several
other distributed problems, such as state machine replica-
tion [23] and atomic broadcast [9]. Consensus, however,
cannot be solved deterministically in asynchronous systems
∗
This work was partially supported by the EU through NoE IST-4-
026764-NOE (RESIST) and project IST-4-027513-STP (CRUTIAL), and
by the FCT through project POSI/EIA/60334/2004 (RITAS) and the Large-
Scale Informatic Systems Laboratory (LASIGE).
if a single processe can crash (also known as the FLP impos-
sibility result [12]). This is a signiﬁcant result, in particular
for intrusion-tolerant systems, because they usually assume
an asynchronous model in order to avoid time dependen-
cies. Time assumptions can often be broken, for example,
with denial of service attacks.
Throughout the years, several techniques have been pro-
posed to circumvent the FLP result. Most of these solutions,
however, require changes to the basic system model, with
the explicit inclusion of stronger time assumptions (e.g.,
partial synchrony models [10]), or by augmenting the sys-
tem with devices that hide in their implementation these as-
sumptions (e.g., failure detectors [7] or wormholes [19]).
Randomization is another technique that has been around
for more than two decades [2, 20]. One important advantage
of this technique is that no time assumptions are needed –
to circumvent FLP, it uses a probabilistic approach where
the termination of consensus is ensured with probability 1.
Although this line of research produced a number of impor-
tant theoretical achievements, including many algorithms,
in what pertains to the implementation of practical appli-
cations, randomization has been historically overlooked be-
cause it has usually been considered to be too inefﬁcient.
The reasons for the assertion that “randomization is in-
efﬁcient in practice” are simple to summarize. Randomized
consensus algorithms, which are the most common form
of these algorithms, usually have a large expected num-
ber of communication steps, i.e., a large time-complexity.
Even when this complexity is constant, the expected num-
ber of communication steps is traditionally signiﬁcant even
for small numbers of processes, when compared, for in-
stance, with solutions based on failure detectors. Many of
these algorithms also rely heavily on public-key cryptogra-
phy, which increases the performance costs, especially for
LANs or MANs in which the time to compute a digital sig-
nature is usually much higher than the network delay.
Nevertheless, two important points have been chroni-
cally ignored. First, consensus algorithms are not usually
executed in oblivion, they are run in the context of a higher-
level problem (e.g., atomic broadcast) that can provide a
friendly environment for the “lucky” event needed for faster
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Vector Consensus
Atomic Broadcast
Multi-valued Consensus
Binary Consensus
Protocols
implemented
in RITAS
Reliable Broadcast
Echo Broadcast
TCP
IPSec AH
Standard
Internet
services
Figure 1. The RITAS protocol stack.
termination (e.g., many processes proposing the same value
can lead to a quicker conclusion). Second, for the sake
of theoretical interest, the proposed adversary models usu-
ally assume a strong adversary that completely controls the
scheduling of the network and decides which processes re-
ceive which messages and in what order. In practice, a real
adversary does not possess this ability, but if it does, it will
probably perform attacks in a distinct (and much more sim-
pler) manner to prevent the conclusion of the algorithm – for
example, it could block the communication entirely. There-
fore, in practice, the network scheduling can be “nice” and
lead to a speedy termination.
The paper describes the implementation of a stack of
randomized intrusion-tolerant protocols and evaluates their
performance under different faultloads. One of the main
purposes is to show that randomization can be efﬁcient
and should be regarded as a valid solution for practical
intrusion-tolerant distributed systems.
This implementation is called RITAS which stands for
Randomized Intrusion-Tolerant Asynchronous Services. At
the lowest level of the stack (see Figure 1) there are two
broadcast primitives: reliable broadcast and echo broad-
cast. On top of these primitives, the most basic form of
consensus is available, binary consensus. This protocol lets
processes decide on a single bit and is, in fact, the only
randomized algorithm of the stack. The rest of the proto-
cols are built on the top of this one. Building on the binary
consensus layer is the multi-valued consensus, allowing the
agrement on values of arbitrary range. At the highest level
there is vector consensus, which lets processes decide on a
vector with values proposed by a subset of the processes,
and atomic broadcast, which ensures total order. The pro-
tocol stack is executed over a reliable channel abstraction
provided by standard Internet protocols – TCP ensures re-
liability, and IPSec guarantees cryptographic message in-
tegrity [13]. All these protocols have been previously de-
scribed in the literature [3, 22, 9]. The implemented proto-
cols are, in most cases, optimized versions of the original
proposals that have signiﬁcantly improved the overall per-
formance (see Section 2 for a description of some of these
optimizations).
The protocols of RITAS share a set of important struc-
tural properties. They are asynchronous in the sense that no
assumptions are made on the processes’s relative execution
and communication times, thus preventing attacks against
assumptions in the domain of time (a known problem in
some protocols that have been presented in the past). They
3 (cid:3) mali-
attain optimal resilience, tolerating up to f = (cid:2) n−1
cious processes out of a total of n processes, which is impor-
tant since the cost of each additional replica has a signiﬁcant
impact in a real-world application. They are signature-free,
meaning that no expensive public-key cryptography is used
anywhere in the protocol stack, which is relevant in terms
of performance since this type of cryptography is several
orders of magnitude lower than symmetric cryptography.
They take decisions in a distributed way (there is no leader),
thus avoiding the costly operation of detecting the failure of
a leader, an event that can considerably delay the execution.
The paper has two main contributions: 1) it presents the
implementation of a stack of randomized intrusion-tolerant
protocols discussing several optimizations – to the best of
our knowledge, the implementation of a stack with the four
above properties is novel; 2) it provides a detailed evalu-
ation of RITAS in a LAN setting, showing that it has in-
teresting latency and throughput values; for example, the
binary consensus protocol always runs in only one round
(three communication steps) with realistic faultloads, and
the atomic broadcast has a very low ordering overhead (only
2.4%) when the rate of transmitted messages is high; more-
over, some experimental results show that realistic Byzan-
tine faults do not reduce the performance of the protocols.
2. System Model and Protocol Deﬁnitions
The system is composed by a group of n processes
P = {p0, p1, ..., pn−1}. Processes are said to be correct
if they do not fail, i.e., if they follow their protocol until
termination. Processes that fail are said to be corrupt. No
assumptions are made about the behavior of corrupt pro-
cesses – they can, for instance, stop executing, omit mes-
sages, send invalid messages either alone or in collusion
with other corrupt processes. This class of unconstrained
faults is usually called arbitrary or Byzantine. It is assumed
3 (cid:3) processes can be corrupt, which
that at most f = (cid:2) n−1
implies that n ≥ 3f + 1. The system is asynchronous in the
sense that there are no assumptions about bounds on pro-
cessing times or communication delays.
The processes are assumed to be fully-connected. Each
pair of processes (pi, pj) shares a secret key sij. It is out
of the scope of the paper to present a solution for distribut-
ing these keys, but it may require a trusted dealer or some
kind of key distribution protocol based on public-key cryp-
tography. Nevertheless, this is normally performed before
the execution of the protocols and does not interfere with
their performance. Each process has access to a random bit
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
generator that returns unbiased bits observable only by the
process (if the process is correct).
Some protocols use a cryptographic hash function H(m)
that maps an arbitrarily length input m into a ﬁxed length
output. We assume that it is impossible (1) to ﬁnd two val-
ues m (cid:5)= m(cid:1)
such that H(m) = H(m(cid:1)), and, (2) given
a certain output, to ﬁnd an input that produces that output.
The output of the function is often called a hash.
The rest of the section brieﬂy describes the function of
each protocol and how it works. Since all protocols have
already been described in the literature, no formal speciﬁ-
cations are given, and some details are only provided to ex-
plain the optimizations. We have developed formal proofs
showing that the optimized protocols behave according to
their speciﬁcation, but we could not present them in the pa-
per due to lack of space.
2.1. Reliable Channel
The two layers at the bottom of the stack implement a
reliable channel (see Figure 1). This abstraction provides
a point-to-point communication channel between a pair of
correct processes with two properties: reliability and in-
tegrity. Reliability means that messages are eventually re-
ceived, and integrity says that messages are not modiﬁed in
the channel. In practical terms, these properties can be en-
forced using standard Internet protocols: reliability is pro-
vided by TCP, and integrity by the IPSec Authentication
Header (AH) protocol [13].
2.2. Reliable Broadcast
The reliable broadcast primitive ensures two properties:
(1) all correct processes deliver the same messages; (2) if
the sender is correct then the message is delivered. The im-
plemented reliable broadcast protocol was originally pro-
posed by Bracha [3]. The protocol starts with the sender
broadcasting a message (INIT, m) to all processes. Upon
receiving this message a process sends a (ECHO, m) mes-
2 (cid:3) + 1
sage to all processes. It then waits for at least (cid:2) n+f
(ECHO, m) messages or f + 1 (READY, m) messages, and
then it transmits a (READY, m) message to all processes.
Finally, a process waits for 2f + 1 (READY, m) messages
to deliver m. Figure 2 illustrates the three communication
steps of the protocol.
2.3. Echo Broadcast
The echo broadcast primitive is a weaker and more
efﬁcient version of the reliable broadcast.
Its properties
are somewhat similar, however, it does not guarantee that
all correct processes deliver a broadcasted message if the
sender is corrupt [24]. In this case, the protocol only en-
sures that the subset of correct processes that deliver will do
it for the same message.
Figure 2. Overview of
changed in each protocol.
the messages ex-
The implemented protocol – that we call matrix echo
broadcast – is based on the echo multicast proposed by Re-
iter [22], in which digital signatures are replaced by vectors