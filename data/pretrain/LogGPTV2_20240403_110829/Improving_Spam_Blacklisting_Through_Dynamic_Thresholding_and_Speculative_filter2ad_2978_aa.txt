# Improving Spam Blacklisting Through Dynamic Thresholding and Speculative Aggregation

**Authors:**
- Sushant Sinha
- Michael Bailey
- Farnam Jahanian

**Affiliation:**
University of Michigan, Ann Arbor, MI 48109, USA  
Email: {sushant, mibailey, farnam} @umich.edu

## Abstract

Unsolicited bulk e-mail (UBE), commonly known as spam, constitutes a significant portion of all email traffic, frustrating users, consuming resources, and serving as a vector for malicious software. To effectively and scalably mitigate the impact of spam, email system designers have increasingly adopted blacklisting. Blacklisting is a form of coarse-grained, reputation-based, dynamic policy enforcement where real-time feeds of spam-sending hosts are sent to networks to reject or specially mark emails from these hosts. However, current spam blacklist services are highly inaccurate, with both false positives and significant false negatives. In this paper, we investigate the root causes of blacklist inaccuracy and demonstrate that the trend towards more stealthy spam exacerbates the existing tension between false positives and false negatives in assigning spamming IP reputations. We argue that global aggregation and reputation assignment should be replaced with local aggregation and reputation assignment, leveraging pre-existing global spam collection along with local usage, policy, and reachability information. We propose two specific techniques, dynamic thresholding and speculative aggregation, aimed at improving the accuracy of blacklist generation. We evaluate the performance and accuracy of these solutions using a dataset of 2.5 million production emails and 14 million emails from spamtraps deployed across 11 domains over a one-month period. Our results show that the proposed approaches significantly reduce false positive and false negative rates compared to existing methods.

## 1. Introduction

Recent estimates suggest that up to 94% of all Internet email is unsolicited bulk email (UBE) or spam [24]. This spam negatively impacts user productivity [21], consumes network resources [14], and serves as an infection vector for malicious software [15]. To combat these issues, two primary anti-spam approaches have emerged: content-based filtering and blacklisting. Content-based filtering methods, such as [22, 10], use classification algorithms to differentiate between legitimate (ham) and unsolicited (spam) emails. However, these methods are easily evaded [27] and can even block legitimate emails [16]. Therefore, email system designers have increasingly turned to blacklisting. Blacklisting is a form of coarse-grained, reputation-based, dynamic policy enforcement where real-time feeds of spam-sending hosts are sent to networks to reject or specially mark emails from these hosts. Many organizations provide these services, including NJABL [1], SORBS [3], SpamHaus [5], and SpamCop [4].

Unfortunately, current spam blacklist services are highly inaccurate, exhibiting both false positives and significant false negatives. For example, a previous study of four prominent blacklists (SORBS, SpamHaus, SpamCop, and NJABL) found false positive rates ranging from 0.2% to 9.5% and false negative rates ranging from 35% to 98.4% [23]. To address these limitations, blacklists are often used in conjunction with content-based filters to improve effectiveness [13]. However, the accuracy of spam blacklist services remains crucial, as they reduce the cost of executing more expensive content-based filters and often successfully blacklist emails that content filters fail to capture. While several novel blacklisting systems have been developed (e.g., [20, 11]), little work has focused on understanding why existing methods fail and how they might be directly improved.

In this paper, we explore the factors affecting the accuracy of traditional blacklisting techniques. We evaluate both factors inherent to the evolution of spammer behavior (e.g., targeted spam, low-rate or "snowshoe" spam) and those integral to the approach itself (e.g., detection delay, overly aggressive or conservative blacklisting). Our evaluation shows that many false negatives come from IP addresses that send limited numbers of emails to each domain and very few domains overall, limiting the available information for reputation assignments. Additionally, many false positives are due to the blocking of high-volume, multi-user domains (e.g., webmail) or the lack of appropriate whitelisting. We believe that the fundamental tension between the small number of events available to assign reputation to an individual IP and the accuracy of the reputation result must be overcome to improve these methods.

To address this tension, we propose two novel techniques: dynamic thresholding and speculative aggregation. These techniques supplement spam events with local policy, usage, and routing data, shifting the blacklist aggregation and decision-making from global collection infrastructure providers to the local network enforcing the policy decision.

- **Dynamic Thresholding:** This technique bases the decision to blacklist a spamming IP on the relative importance of a remote IP address to the local network, rather than on a static threshold and whitelist combination. Local, customized blacklists are created by tracking the ratio of spam events for a remote IP to the number of outbound emails from the local network to that remote IP. This allows for more aggressive threshold selection for remote domains not frequently used by the local network, alleviates the need for manual and sometimes arbitrary whitelisting, and enables unique, dynamic thresholds and whitelists for each organization.

- **Speculative Aggregation:** This approach uses global information from spamtraps and BGP reachability data to determine the ratio of good (and active) IP addresses within a block to the number of spamming IP addresses. Based on the notion that spamming IPs are clustered [11, 26], the ratio of spamming to non-spamming hosts in a network block is a good predictor of future spamming activity. To mitigate the risk of blocking entire prefixes, we layer dynamic thresholding on top of speculative aggregation, allowing emails from bad neighborhoods if they are important to the local network.

To validate our techniques, we collected headers from both a production email system of a large academic department, which received 2.5 million emails, and our own separate spamtrap deployment, which received 14 million emails, during February-March 2009. We built blacklists based on emails received on the spamtrap and the production network, evaluating them using a combination of SpamAssassin and manual examination. Our evaluation shows that these approaches perform significantly better than existing methods, with the dynamic thresholding approach achieving three times the detection rate for a false positive rate below 0.5%, and the speculative aggregation approach providing five times the detection rate for a false positive rate below 0.5%.

The main contributions of this paper are:
- An examination of the root causes of blacklist ineffectiveness, arguing that the decreasing number of observable spam events for a given IP severely hampers the accuracy of these techniques.
- The proposal of two techniques, dynamic thresholding and speculative aggregation, to address these root causes. We argue that blacklist generation should incorporate both local usage, policy, and reachability information, as well as global reputation data, and that policy decisions should be made locally rather than globally.
- An evaluation of these techniques using data from a large academic departmental email server, demonstrating significant improvements over existing methods.

The remainder of this paper is structured as follows: Section 2 explores the root causes of existing blacklist failure. Section 3 introduces the speculative aggregation and dynamic thresholding techniques. Section 4 evaluates these approaches in our production deployment. Section 5 provides an overview of related work. Section 6 discusses the limitations and future directions of this work.

## 2. Exploring the Inaccuracy of Blacklists

Spam blacklists play a crucial role in blocking unwanted email traffic. In this section, we examine the factors that limit the accuracy of existing spam blacklists to understand how to improve them. We begin by describing existing methods for blacklist creation and then discuss the experimental setup used throughout this analysis, including the oracle, the production email network, and our spamtrap deployment. By creating our own blacklist and analyzing its effectiveness in the context of our production email system, we explore the factors (e.g., low-rate, low-volume spam, detection delay) that may impact the accuracy of existing blacklist creation methods. We conclude that trends in spammer behavior limit the number of events used to assign IP reputation, thereby impacting the accuracy of these methods.

### 2.1 Background

Several organizations generate dynamic blacklists for spam, including SORBS [3], SpamHaus [5], and SpamCop [4]. These spam blacklist providers deploy and monitor unused email addresses called spamtraps. There are two general approaches to spamtrap deployment:
1. Configuring an email server for an unused domain. For example, Project Honeypot [25] monitors emails to unused sub-domains within legitimate domains.
2. Monitoring unused users within a legitimate domain. In this model, the email server delivers emails to existing users but directs emails to nonexistent users to a separate account.

Emails sent to spamtraps are aggregated by a blacklist provider, as shown in Figure 1. The emails are aggregated by source IP, and those IP addresses exceeding a threshold number of spamtrap hits within a given time window are blacklisted [7]. Since legitimate email servers, such as yahoo.com, can also be used by spammers, a threshold-based approach can blacklist legitimate email servers, causing widespread email disruption. Therefore, commercial blacklist providers maintain whitelists of popular email services and use "Received" headers added by these legitimate servers to determine the sender's IP. Unfortunately, this scheme does not work universally. For example, it does not work with Gmail because Gmail does not add the source IP of the client if the web interface is used for sending the email [23]. Additionally, SpamCop uses a sample of DNS lookups to determine if IP addresses should avoid being blacklisted, but this may not be a reliable estimate of actual emails delivered (e.g., due to DNS caching).

### 2.2 Experimental Setup

We evaluate the effectiveness of spam blacklists and other results in this paper by observing emails to and from a large academic institution. During a month-long period from February 10, 2009, to March 10, 2009, we monitored over 7,000 local hosts. We used a traffic tap (i.e., span port) to the gateway router to observe all traffic exchanged between the network and the rest of the Internet. TCP streams on port 25 were reassembled using libnids [28], and full SMTP formatted emails were available for evaluation. During the measurement period, we observed a total of 3,999,367 SMTP connections, of which 2,575,634 emails were successfully delivered. The remaining SMTP connections failed or were aborted, primarily due to non-existent users on the target domain.

#### 2.2.1 Oracle Selection

To evaluate blacklist accuracy, we need to determine whether an email on the production network is ham (legitimate email) or spam. Given the scale of the measurement, hand-classification was infeasible, so we used SpamAssassin [13] as our oracle. SpamAssassin uses multiple spam detectors and assigns scores for each detector. The total score for a message is computed by adding the scores of all detectors that classified the message as spam. If the total score exceeds the default threshold of 5.0, the message is classified as spam. We used the default SpamAssassin configuration from the Gentoo Linux distribution and configured it with additional detection modules, Pyzor [2] and Razor [6], to improve accuracy. We discuss the issue of oracle accuracy and our manual examination to cover oracle limitations in Section 4.5.

#### 2.2.2 Characterizing the Email Seen on the Network

Our month-long observation shows that approximately 75% of the delivered email (both ham and spam, excluding failed connections) was spam. This number rises to 84% when including failed SMTP connections (due to nonexistent users or domains). We observed 764,248 unique IP addresses during this period, spread across 35,390 distinct BGP prefixes, announced by 85 unique autonomous systems. Most spam messages (1,448,680) came from external sources. However, we also had a sizable number of internal spams (392,192), which was roughly four times the number of spam messages (98,679) from internal hosts to the rest of the Internet. Ham messages were dominated by internal-to-internal emails (369,431), followed by internal-to-external (151,860), and then by external-to-internal (114,792). The top five external senders of spam observed during this period at our network were Turk Telekom (69,278), Verizon (34,819), Telecomunicacoes Brazil (34,175), TELESC Brazil (27,360), and Comcast (25,576). The top five destinations for legitimate email from our network were Google (87,373), Inktomi (4,559), Microsoft (3,466), Inktomi-II (2,052), and Merit Networks (1,793). The average message size for all emails was 5,301 bytes, with averages of 4,555 bytes, 15,152 bytes, and 1,916 bytes for spam, ham, and failed connections, respectively.

#### 2.2.3 Characterizing the Spamtrap Deployment

To understand the root causes of false positives and false negatives produced by existing blacklist aggregation algorithms, we deployed our own spamtrap covering 11 domains during the measurement period. The email server in these domains copied emails sent to non-existent users to a separate account for post-analysis. In total, we observed 13,903,240 emails from 1,919,911 unique sources between February 10, 2009, and March 10, 2009. Table 1 shows the number of emails received and the number of unique sources observed on each domain. Over 14 million spam emails were captured and analyzed.

| Top Level Domain | E-Mails Received | % of Total Spamtrap Emails | Unique Sources |
|------------------|------------------|---------------------------|----------------|
| .org             | 289,991          | 2.1%                      | 137,725        |
| .org             | 449,803          | 3.2%                      | 216,291        |
| .org             | 571,856          | 4.1%                      | 253,777        |
| .com             | 1,090,611        | 7.8%                      | 407,838        |
| .net             | 1,159,353        | 8.3%                      | 439,152        |
| .net             | 1,306,411        | 9.4%                      | 473,686        |
| .net†            | 1,321,232        | 9.5%                      | 18             |
| .com             | 1,458,865        | 10.5%                     | 486,675        |
| .com             | 1,552,240        | 11.2%                     | 521,321        |
| .net             | 1,698,295        | 12.2%                     | 513,057        |
| .net             | 3,004,583        | 21.6%                     | 689,633        |

†This domain received between 28,244-58,597 spam emails from 2-11 unique source addresses per day. Interestingly, the total number of distinct source IP addresses was small (18) and all belonged to Gmail. We conjecture that the domain was being spammed using numerous compromised Gmail accounts.

### 2.3 Factors That May Influence Blacklist Accuracy

In this section, we explore the factors that may influence the accuracy of traditional blacklisting techniques. We evaluate both factors inherent to the evolution of spammer behavior (e.g., targeted spam, low-rate or "snowshoe" spam) and those integral to the approach itself (e.g., detection delay, overly aggressive or conservative blacklisting). Our evaluation shows that many false negatives come from IP addresses that send limited numbers of emails to each domain and very few domains overall, limiting the available information for reputation assignments. Additionally, many false positives are due to the blocking of high-volume, multi-user domains (e.g., webmail) or the lack of appropriate whitelisting. We believe that the fundamental tension between the small number of events available to assign reputation to an individual IP and the accuracy of the reputation result must be overcome to improve these methods.