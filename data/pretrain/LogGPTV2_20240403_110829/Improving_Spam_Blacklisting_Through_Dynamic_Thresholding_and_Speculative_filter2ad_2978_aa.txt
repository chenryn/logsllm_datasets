title:Improving Spam Blacklisting Through Dynamic Thresholding and Speculative
Aggregation
author:Sushant Sinha and
Michael Bailey and
Farnam Jahanian
Improving Spam Blacklisting Through Dynamic Thresholding and
Speculative Aggregation
Sushant Sinha, Michael Bailey, and Farnam Jahanian
University of Michigan, Ann Arbor, MI 48109, USA
{sushant, mibailey, farnam} @umich.edu
Abstract
Unsolicited bulk e-mail (UBE) or spam constitutes a sig-
niﬁcant fraction of all e-mail connection attempts and rou-
tinely frustrates users, consumes resources, and serves as
an infection vector for malicious software. In an effort to
scalably and effectively reduce the impact of these e-mails,
e-mail system designers have increasingly turned to black-
listing. Blacklisting (blackholing, block listing) is a form of
course-grained, reputation-based, dynamic policy enforce-
ment in which real-time feeds of spam sending hosts are sent
to networks so that the e-mail from these hosts may be re-
jected. Unfortunately, current spam blacklist services are
highly inaccurate and exhibit both false positives and sig-
niﬁcant false negatives. In this paper, we explore the root
causes of blacklist inaccuracy and show that the trend to-
ward stealthier spam exacerbates the existing tension be-
tween false positives and false negatives when assigning
spamming IP reputation. We argue that to relieve this ten-
sion, global aggregation and reputation assignment should
be replaced with local aggregation and reputation assign-
ment, utilizing preexisting global spam collection, with the
addition of local usage, policy, and reachability informa-
tion. We propose two speciﬁc techniques based on this
premise, dynamic thresholding and speculative aggregation,
whose goal is to improve the accuracy of blacklist genera-
tion. We evaluate the performance and accuracy of these
solutions in the context of our own deployment consisting of
2.5 million production e-mails and 14 million e-mails from
spamtraps deployed in 11 domains over a month-long pe-
riod. We show that the proposed approaches signiﬁcantly
improve the false positive and false negative rates when
compared to existing approaches.
1
Introduction
Recent estimates indicate that as much as 94% of all In-
ternet e-mail is unsolicited bulk e-mail (UBE) or spam [24].
This spam routinely impacts user productivity [21], con-
sumes resources [14], and serves as an infection vector
for malicious software [15].
In an effort to reduce these
impacts, two major classes of anti-spam approaches have
emerged: content-based ﬁltering and blacklisting. Content-
based ﬁltering methods (e.g., [22, 10]) rely on classiﬁcation
algorithms to examine the contents of e-mails (i.e., head-
ers, body) and to differentiate legitimate (or ham) and un-
solicited (or spam) e-mail. Unfortunately, these methods
are easy to evade [27] and can even be co-opted to block
legitimate e-mail [16]. In an effort to scalably and effec-
tively reduce the impact of these e-mails, e-mail system
designers have increasingly turned to blacklisting. Black-
listing (blackholing, block listing) is a form of course-
grained, reputation-based, dynamic policy enforcement in
which real-time feeds of spam sending hosts are sent to net-
works so that the e-mail from these hosts can be rejected
or specially marked. Currently, a large number of orga-
nizations provide these services for spam detection (e.g.,
NJABL [1], SORBS [3], SpamHaus [5], and SpamCop [4]).
Unfortunately, current spam blacklist services are highly
inaccurate and exhibit both false positives and signiﬁcant
false negatives. For example, in a previous study of four
prominent blacklists including SORBS, SpamHaus, Spam-
Cop, and NJABL, false positives ranged from 0.2% to 9.5%
and false negatives ranged from 35% to 98.4% [23]. To
compensate for these limitations, blacklists are often used
in conjunction with content-base techniques to further im-
prove effectiveness [13]. However, the accuracy of spam
blacklist services remains important as they are used reduce
the cost of executing the more expensive content-based ﬁl-
ters and often successfully blacklist e-mail that the content-
ﬁlters fail to capture. While numerous novel blacklisting
systems have been created (e.g., [20, 11]) to address this
need, little work has focused on understanding why exist-
ing methods fail and how these methods might be directly
improved.
In this paper, we explore the factors that affect the ac-
curacy of traditional blacklisting techniques. We evaluate
both factors that are inherent to the evolution of spammer
behavior (e.g., targeted spam, low rate or “snow shoe”), as
well as those integral to the approach itself (e.g., detection
delay, over or under aggressive blacklisting).
In evaluat-
ing these factors, we show that the vast number of false
negatives come from IP addresses that have sent limited
numbers of e-mail to each domain and very few domains
overall, limiting the amount of information available with
which to make reputation assignments. Furthermore, many
of the false positives are attributable to the blocking of high
volume, multi-user domains (e.g., web-mail) or to the lack
of appropriate whitelisting to avoid such problems. We
believe this fundamental tension between the increasingly
small number of events with which to assign reputation to
an individual IP and the accuracy of the reputation result
must be overcome if these methods are to be improved.
In order to address this tension, we propose two novel
techniques: dynamic thresholding and speculative aggrega-
tion. Fundamentally, these techniques work by supplement-
ing spam events with local policy, usage, and routing data
and by moving the blacklist aggregation and decision mak-
ing away from the global collection infrastructure providers
to the local network that is enforcing the policy decision.
In dynamic thresholding, the determination to blacklist a
spamming IP is neither global, nor based on a static thresh-
old and whitelist combination, but rather based on the rela-
tive importance of a remote IP address to the local network.
These local, customized blacklists are created by tracking
the ratio of spam events for a remote IP to the number of
outbound e-mails from the local network to that remote IP.
The value of this technique is that: (i) it allows more ag-
gressive threshold selection for remote domains that are not
used often by the local network (ii) it alleviates the need
for manual (and sometimes arbitrary or punitive) whitelist
selection, as important remote IPs and domains will not be
blacklisted unless they become “more trouble than they are
worth,” and (iii) policies are now local to the networks in
which they are applied, allowing unique, dynamic thresh-
olds and whitelists for each and every organization.
In the second approach, speculative aggregation, we use
global information provided by spamtraps and BGP reacha-
bility information to determine the ratio of good (and active)
IP addresses within a block to the number of spamming IP
addresses within a block. Based on the prevalent notion that
spamming IPs are clustered [11, 26], the ratio of spamming
to non-spamming hosts in a network block is a good predic-
tor of future spamming activity for a variety of reasons, in-
cluding shared administrative and security policies, and dy-
namic hosts. The danger of such an approach, obviously, is
that it may block entire preﬁxes, some of which send legiti-
mate e-mail to the local network. To ameliorate this effect,
we layer dynamic thresholding techniques on top of spec-
ulative execution to allow e-mail from bad neighborhoods
if these neighborhoods are important to the local network.
This technique improves the accuracy of generation by: (i)
predicting potential new sources of spamming before they
hit spam collectors and (ii) limiting the chance that these
predicted hosts or networks are of use to the local network.
To validate our techniques, we collected headers from
both a production e-mail system of a large academic de-
partment, which received 2.5 million e-mails, and our own
separate spamtrap deployment, which received 14 million e-
mails, during the month-long evaluation period of February-
March, 2009. We built blacklists based on e-mails re-
ceived on the spamtrap and on the e-mails received on
the production network. We evaluated the blacklists us-
ing a combination of SpamAssassin and manual examina-
tion.
In our evaluation, we found that these approaches
performed signiﬁcantly better than our implementation of
existing approaches—the detection rate for the dynamic
thresholding approach is three times that of the existing ap-
proaches for a false positive rate below 0.5%, and the spec-
ulative aggregation approach provides ﬁve times the detec-
tion rate when compared to the existing approach for a false
positive rate below 0.5%.
To summarize, the main contributions of this paper are:
• An examination of the root causes of blacklist ineffec-
tiveness. We argue that the decreasing number of ob-
servable spam events for a given IP severely hampers
the accuracy of these techniques.
• We propose two techniques that address these root
causes: dynamic thresholding and speculative aggre-
gation. We argue that blacklist generation techniques
should take into account both local usage, policy, and
reachability information as well as global reputation
data when making policy decisions and that these pol-
icy decisions should be made locally rather than glob-
ally. By shifting the location of these decisions and
adding local context, we argue that we improve the ac-
curacy of the reputation assignment.
• An evaluation of these techniques on data collected
from a large academic departmental e-mail server and
a demonstration of these two techniques that shows
signiﬁcant improvement over existing methods.
The remainder of this paper is structured as follows: We
begin in Section 2 by exploring the root causes of existing
blacklist failure. The architecture section, Section 3, intro-
duces the speculative aggregation and dynamic thresholding
techniques that make up our system and Section 4 evaluates
these approaches in our production deployment. Section 5
provides a brief overview of related work. We conclude in
Section 6 by discussing the limitations of and future of this
work.
BlACKLIST
Provider
Deny All Bot1
Deny All Bot2 
Bot1
Trap1
User2
Trap2
Spammer
User1
User3
Bot2
User4
Figure 1: In existing approaches to blacklist generation, spam is sent to both legitimate users as well as unused accounts and do-
mains (spamtraps). Spam is aggregated by a blacklisting provider and global provider conﬁguration (inclusion threshold, whitelist-
ing) is applied to determine blacklist contents. Customer networks may choose to locally implement the published blacklist policy
(i.e., block or specially mark e-mail from those IPs).
2 Exploring the Inaccuracy of Blacklists
Spam blacklists serve an important role in blocking un-
wanted e-mail trafﬁc. In this section, we examine the factors
that limit existing spam blacklist accuracy in an effort to un-
derstand how to improve them. We begin by describing ex-
isting methods for blacklist creation and proceed to discuss
the experimental setup used throughout this analysis (and
the remainder of this paper) including the oracle we used,
the production e-mail network, and our spamtrap deploy-
ment. By creating our own blacklist and analyzing its effec-
tiveness in the context of our production e-mail system, we
explore the factors (e.g., low-rate, low-volume spam, detec-
tion delay) that may impact the accuracy of existing black-
list creation methods. We conclude that trends in spammer
behavior limit the number of events used to assign IP repu-
tation and therefore impact the accuracy of these methods.
2.1 Background
A number of organizations generate dynamic blacklists
for spam including: SORBS [3], SpamHaus [5] and Spam-
Cop [4]. These spam blacklist providers deploy and moni-
tor a number of unused e-mail addresses called spamtraps.
There are two general approaches to spamtrap deployment.
The ﬁrst approach is to conﬁgure an e-mail server for an
unused domain. For example, Project Honeypot [25] takes
unused sub-domains, like mail1.umich.edu, within legiti-
mate domains, like umich.edu, and monitors all e-mails to
these domains. The second approach is to monitor unused
users within a legitimate domain. In this deployment model,
the e-mail server delivers all e-mails directed to existing
users to their respective folders, but any e-mail directed to a
nonexistent user is delivered to a separate account.
E-mails sent to spamtraps are then aggregated by a
blacklist provider, as shown in Figure 1. The e-mails are
aggregated by source IP and those IP addresses that ex-
ceed a threshold number of spamtrap hits within a given
time window are blacklisted [7]. Since legitimate e-mail
servers, such as yahoo.com, can also be used by spam-
mers, the danger of a threshold-based approach is that it can
blacklist legitimate e-mail servers causing widespread e-
mail disruption. Therefore, commercial blacklist providers
maintain whitelists of popular e-mail services and then use
“Received” headers added by those legitimate servers to
determine the IP addresses of the sender. Unfortunately,
this scheme does not work universally. For example, this
scheme does not work with Gmail because Gmail does not
add the source IP of the client, if the web interface is used
for sending the e-mail [23]. In addition, SpamCop uses a
sample of DNS lookups to determine if IP addresses should
avoid being blacklisted. However, this may not be a reliable
estimate of actual e-mails delivered (e.g., DNS caching).
2.2 Experimental Setup
We evaluate the effectiveness of spam blacklists, as well
as the other results in this paper, by observing e-mails to
and from a large academic institution. In our experiments,
we observed over 7,000 local hosts during a month-long
period from February 10, 2009 to March 10, 2009. We
monitored trafﬁc using a trafﬁc tap (i.e., span port) to the
gateway router that provides visibility into all of the trafﬁc
exchanged between the network and the rest of the Inter-
net. The TCP streams on port 25 were reassembled us-
ing libnids [28], and full SMTP formatted e-mails were
available for evaluation. During the measurement period
we observed a total of 3,999,367 SMTP connections, out
of which 2,575,634 e-mails were successfully delivered.
The remaining SMTP connections failed or were aborted
in large part due to non-existent users on the target domain.
2.2.1 Oracle Selection
In order to evaluate blacklist accuracy, we need to deter-
mine whether an e-mail on the production network is ham
(legitimate e-mail) or spam. At the scale of the above mea-
surement, a hand classiﬁcation of e-mails was infeasible and
so we used SpamAssassin [13] as our oracle classiﬁcation.
SpamAssassin uses a number of spam detectors and assigns
scores for each detector. The total score for a message is
computed by adding the score of all the detectors that clas-
siﬁed the message as spam. If the total score exceeds the
default threshold of 5.0, then the message is classiﬁed as
spam. We used the default SpamAssassin conﬁguration that
came with the Gentoo Linux distribution. We conﬁgured
SpamAssassin with two additional detection modules, Py-
zor [2] and Razor [6], for improving SpamAssassin accu-
racy. We discuss the issue of oracle accuracy and our man-
ual examination to cover the oracle limitation in Section 4.5.
2.2.2 Characterizing the E-mail Seen on the Network
Our month-long observation shows that roughly 75% of
the delivered e-mail (i.e., ham and spam, but not failed
connections) was spam. This number rises to 84% when
failed SMTP connections (due to nonexistent users or do-
mains) are included. We observed 764,248 unique IP ad-
dresses during this period in 35,390 distinct BGP preﬁxes,
announced by 85 unique autonomous systems. Most of
the spam messages (1,448,680) came from sources exter-
nal to our network. However, we had a sizable number
of spams (392,192) from within the network, which was
roughly four times the number of spam messages (98,679)
from hosts within the network to the rest of the Inter-
net (we send much more spam to ourselves than to the
rest of the Internet). Ham messages were dominated by
internal to internal e-mails (369,431), followed by inter-
nal to external (151,860), and then by external to internal
(114,792). The top ﬁve external senders (i.e., autonomous
systems) of spam observed during this period at our net-
work were Turk Telekom (69,278), Verizon (34,819), Tele-
comunicacoes Brazil (34,175), TELESC Brazil (27,360),
Top level
domain
.org
.org
.org
.com
.net
.net
.net†
.com
.com
.net
.net
E-Mails
received
289,991
449,803
571,856
1,090,611
1,159,353
1,306,411
1,321,232
1,458,865
1,552,240
1,698,295
3,004,583
The % of total
spamtrap e-mails
2.1
3.2
4.1
7.8
8.3
9.4
9.5
10.5
11.2
12.2
21.6
Unique
sources
137,725
216,291
253,777
407,838
439,152
473,686
18
486,675
521,321
513,057
689,633
Table 1: Our spamtrap deployment by top level domains,
number of e-mails received, and number of unique sources.
Over 14 million spam e-mails were captured and analyzed.
†This domain received between 28,244-58,597 spam e-mails
from 2-11 unique source addresses per day. Interestingly, the
total number of distinct source IP addresses was small (18) and
all of them belong to Gmail. We conjecture the domain was be-
ing spammed using numerous compromised Gmail accounts.
and Comcast (25,576). The top ﬁve destinations (i.e., au-
tonomous systems) for legitimate e-mail from our network
were Google (87,373), Inktomi (4,559), Microsoft (3,466),
Inktomi-II (2,052), and Merit Networks (1,793). The av-
erage message size for all e-mails was 5,301 bytes, with
averages of 4,555 bytes, 15,152 bytes, and 1,916 bytes for
spam, ham, and failed connections respectively.
2.2.3 Characterizing the Spamtrap Deployment
In order to understand the issues effecting the root causes
of the false positives and false negatives produced by exist-
ing blacklist aggregation algorithms, we deployed our own
spamtrap deployment covering 11 domains during the mea-
surement period. The e-mail server in these domains copied
e-mails sent to non-existent users to a separate account for
post analysis.
In total, we observed 13,903,240 e-mails
from 1,919,911 unique sources between February 10, 2009
to March 10, 2009. Table 1 shows the number of e-mails re-
ceived and the number of unique sources observed on each
of these domains. Over 14 million spam e-mails were cap-
tured and analyzed.
2.3 Factors that May Inﬂuence Blacklist Accu-