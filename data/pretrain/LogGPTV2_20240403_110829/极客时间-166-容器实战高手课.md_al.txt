# echo iomap_file_buffered_write >> set_ftrace_filter    
# echo pagecache_get_page >> set_ftrace_filter    
# echo try_to_free_mem_cgroup_pages >> set_ftrace_filter    
# echo try_charge >> set_ftrace_filter    
# echo mem_cgroup_try_charge >> set_ftrace_filter    
# echo function_graph > current_tracer    
# echo 1 > tracing_on这些设置完成之后，我们再运行一下容器中的写磁盘程序，同时从 ftrace 的trace_pipe中读取出追踪到的这些函数。这时我们可以看到，当需要申请 Page Cache 页面的时候，write()系统调用会反复地调用 mem_cgroup_try_charge()，并且在释放页面的时候，函数do_try_to_free_pages() 花费的时间特别长，有50+us（时间单位，micro-seconds）这么多。      1)               |  vfs_write() {      1)               |    xfs_file_write_iter [xfs]() {      1)               |      xfs_file_buffered_aio_write [xfs]() {      1)               |        iomap_file_buffered_write() {      1)               |          pagecache_get_page() {      1)               |            mem_cgroup_try_charge() {      1)   0.338 us    |              try_charge();      1)   0.791 us    |            }      1)   4.127 us    |          }    …      1)               |          pagecache_get_page() {      1)               |            mem_cgroup_try_charge() {      1)               |              try_charge() {      1)               |                try_to_free_mem_cgroup_pages() {      1) + 52.798 us   |                  do_try_to_free_pages();      1) + 53.958 us   |                }      1) + 54.751 us   |              }      1) + 55.188 us   |            }      1) + 56.742 us   |          }    …      1) ! 109.925 us  |        }      1) ! 110.558 us  |      }      1) ! 110.984 us  |    }      1) ! 111.515 us  |  }看到这个 ftrace的结果，你是不是会想到，我们在容器内存那一讲中提到的 Page Cahe呢？ 是的，这个问题的确和 Page Cache 有关，Linux会把所有的空闲内存利用起来，一旦有 Buffered I/O，这些内存都会被用作 PageCache。 当容器加了 Memory Cgroup 限制了内存之后，对于容器里的 BufferedI/O，就只能使用容器中允许使用的最大内存来做 PageCache。 **那么如果容器在做内存限制的时候，Cgroup 中 memory.limit_in_bytes设置得比较小，而容器中的进程又有很大量的 I/O，这样申请新的 Page Cache内存的时候，又会不断释放老的内存页面，这些操作就会带来额外的系统开销了。**重点总结我们今天讨论的问题是在容器中用 Buffered I/O方式写文件的时候，会出现写入时间波动的问题。由于这是 Buffered I/O 方式，对于写入文件会先写到内存里，这样就产生了dirty pages，所以我们先研究了一下 Linux 对 dirty pages的回收机制是否会影响到容器中写入数据的波动。在这里我们最主要的是理解这两个参数，**dirty_background_ratio 和dirty_ratio**，这两个值都是相对于节点可用内存的百分比值。**当 dirty pages 数量超过 dirty_background_ratio对应的内存量的时候，内核 flush 线程就会开始把 dirty pages 写入磁盘 ; 当dirty pages 数量超过 dirty_ratio对应的内存量，这时候程序写文件的函数调用 write()就会被阻塞住，直到这次调用的 dirty pages全部写入到磁盘。**在节点是大内存容量，并且 dirty_ratio 为系统缺省值20%，dirty_background_ratio 是系统缺省值 10% 的情况下，我们通过观察/proc/vmstat 中的 nr_dirty 数值可以发现，dirty pages 不会阻塞进程的Buffered I/O 写文件操作。所以我们做了另一种尝试，使用 perf 和 ftrace工具对容器中的写文件进程进行 profile。我们用 perf 得到了系统调用 write()在内核中的一系列子函数调用，再用 ftrace来查看这些子函数的调用时间。**根据 ftrace 的结果，我们发现写数据到 Page Cache的时候，需要不断地去释放原有的页面，这个时间开销是最大的。造成容器中Buffered I/O write() 不稳定的原因，正是容器在限制内存之后，Page Cache的数量较小并且不断申请释放。**其实这个问题也提醒了我们：在对容器做 Memory Cgroup限制内存大小的时候，不仅要考虑容器中进程实际使用的内存量，还要考虑容器中程序I/O 的量，合理预留足够的内存作为 Buffered I/O 的 PageCache。 比如，如果知道需要反复读写文件的大小，并且在内存足够的情况下，那么Memory Cgroup的内存限制可以超过这个文件的大小。还有一个解决思路是，我们在程序中自己管理文件的 cache 并且调用 DirectI/O来读写文件，这样才会对应用程序的性能有一个更好的预期。思考题我们对 dirty_bytes 和 dirty_background_bytes做下面的设置：    -bash-4.2
# echo 8192 > /proc/sys/vm/dirty_bytes    -bash-4.2
# echo 4096 > /proc/sys/vm/dirty_background_bytes然后再运行下面的 fio 测试，得到的结果和缺省 dirty\_\*配置的时候会有差别吗？    
# fio -direct=1 -iodepth=64 -rw=write -ioengine=libaio -bs=4k -size=10G -numjobs=1  -name=./fio.test欢迎你在留言区提出你的思考或是疑问。如果这篇文章对你有帮助的话，也欢迎你分享给你的朋友、同事，一起学习进步。
# 15 \| 容器网络：我修改了/proc/sys/net下的参数，为什么在容器中不起效？你好，我是程远。从这一讲开始，我们进入到了容器网络这个模块。容器网络最明显的一个特征就是它有自己的Network Namespace了。你还记得，在我们这个课程的第一讲里，我们就提到过 Network Namespace负责管理网络环境的隔离。今天呢，我们更深入地讨论一下和 Network Namespace相关的一个问题------容器中的网络参数。和之前的思路一样，我们先来看一个问题。然后在解决问题的过程中，更深入地理解容器的网络参数配置。问题再现在容器中运行的应用程序，如果需要用到 tcp/ip协议栈的话，常常需要修改一些网络参数（内核中网络协议栈的参数）。很大一部分网络参数都在 /proc文件系统下的/proc/sys/net/slate-object="inline"目录里。**修改这些参数主要有两种方法：一种方法是直接到 /proc文件系统下的\"/proc/sys/net/\"目录里对参数做修改；还有一种方法是使用****sysctl**slate-object="inline"**这个工具来修改。**在启动容器之前呢，根据我们的需要我们在宿主机上已经修改过了几个参数，也就是说这些参数的值已经不是内核里原来的缺省值了.比如我们改了下面的几个参数：    
# 