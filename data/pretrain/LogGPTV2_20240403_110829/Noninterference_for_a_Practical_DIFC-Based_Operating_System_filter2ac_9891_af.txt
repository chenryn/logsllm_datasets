− ∈ ˆO and t
+
VII. RELATED WORK
Information ﬂow control (IFC) at the operating system level dates
back to the centralized military systems of the 70s, and 80s [30],
[15], [31]. Several systems like IX [11] and SELinux [32] integrated
information-ﬂow ideas with Unix-like operating systems in 90s.
Denning ﬁrst pointed out that dynamically-adjusted security labels
could leak data [12] and suggested instead static checking, which later
found fruition as type-analysis [33]. Decentralized declassiﬁcation
and endorsement proved a key relaxation, making IFC practical for
language-based systems [4], and eventual spurring a revitalization
of the idea in operating systems and web-serving settings with the
Asbestos [1], HiStar [2] and Flume [3] systems. HiStar introduced
the idea of “self-tainting,” solving the wide covert channel described
in Section III. Flume later adopted a similar strategy, but within a
streamlined label system.
Taint-tracking is another technique for tracking information ﬂow
through legacy software written in arbitrary languages [34], [35].
Such systems run a target application as rewritten binary, without the
cooperation or recognition of the application in question, meaning
they must infer label changes. Therefore taint-tracking systems are
susceptible to the covert channel attacks described in Section III, and
cannot uphold noninterference.
Goguen and Meseguer introduced the idea of noninterference
for security protocols [17], while Volpano et al. ﬁrst showed that
type systems could provably uphold the idea [36]. More recently,
Zheng and Myers [37] and also Tse and Zdancewic [38] proved
that statically-typed systems with runtime principles could still obey
noninterference. Relative to Flume, information ﬂow is monitored at
a ﬁner granularity. On the other hand, the Flume model provides more
ﬂexibility as to how the various user processes Ui behave: it restricts
these processes from accessing all but one communication channel,
but otherwise they can act arbitrarily and need not be type-checked.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:18:50 UTC from IEEE Xplore.  Restrictions apply. 
The proofs offered here are manual. In future work, we hope to
investigate shaping the Flume model used in the proof to a form that
is amenable to automated analysis. Lowe ﬁrst used an automated
checker to break protocol previous assumed secure [39]. Ryan and
Schneider also describe how the FDR automated checker can verify
standard security protocols [40],
VIII. CONCLUSION
This paper presented the ﬁrst formal security argument for a DIFC-
based operating system. It modelled Flume using the CSP formalism,
and proved that the model fulﬁlls noninterference—an end-to-end
property that protects secrecy and integrity even against subtle
covert channel attacks. The model and proof are not substantially
weakened by the reﬁnement paradox, since the proof holds for many
reﬁnements of the model. Future work calls for further investigation
of timing-based covert and side channels, and automation of the proof
techniques, for both the model and its implementation.
ACKNOWLEDGMENTS
Maxwell Krohn was supported at MIT CSAIL by the joint NSF
CyberTrust/DARPA grant CNS-0430425, Nokia, and an NSF Grad-
uate Student Fellowship. This research was supported in part by
CyLab at Carnegie Mellon under grant DAAD19-02-1-0389 from
the Army Research Ofﬁce. Eran Tromer was supported by NSF
CyberTrust grant CNS-0808907 and AFRL grant FA8750-08-1-0088.
Views and conclusions contained here are those of the authors and
should not be interpreted as necessarily representing the ofﬁcial
policies or endorsements, either express or implied, of ARO, CMU,
AFRL, or the U.S. Government or any of its agencies. Much of the
material in this paper appeared in Maxwell Krohn’s doctoral thesis,
advised by Frans Kaashoek, Robert Morris and Eddie Kohler, and
read by Butler Lampson. We thank them all for their advise, careful
reading and comments. Thanks to Greg Morrisett, Andrew Myers,
Nickolai Zeldovich, Alex Yip, Micah Brodsky, Adrian Perrig, and
Anupam Datta for their ideas and guidance. We thank the anonymous
reviewers for their detailed comments and suggestions.
REFERENCES
[1] P. Efstathopoulos, M. Krohn, S. VanDeBogart, C. Frey, D. Ziegler,
E. Kohler, D. Mazi`eres, F. Kaashoek, and R. Morris, “Labels and event
processes in the Asbestos operating system,” in Proceedings of the 20th
ACM Symposium on Operating Systems Principles (SOSP), Brighton,
UK, October 2005.
[2] N. B. Zeldovich, S. Boyd-Wickizer, E. Kohler, and D. Mazi`eres,
“Making information ﬂow explicit in HiStar,” in Proceedings of the 5th
Symposium on Operating Systems Design and Implementation (OSDI),
Seattle, WA, Nov. 2006.
[3] M. Krohn, A. Yip, M. Brodsky, N. Cliffer, M. F. Kaashoek, E. Kohler,
and R. Morris, “Information ﬂow control for standard OS abstractions,”
in Proceedings of
the 21st ACM Symposium on Operating Systems
Principles (SOSP), Stevenson, WA, October 2007.
[4] A. C. Myers and B. Liskov, “A decentralized model for information
ﬂow control,” in Proceedings of the 16th ACM Symposium on Operating
Systems Principles (SOSP), Saint-Malˆo, France, Oct. 1997, pp. 129–142.
[5] J. Fielding, “UN website is defaced via SQL injection,” Tech Re-
public, Aug. 2007, http://blogs.techrepublic.com.com/
networking/?p=312.
[6] R. Lemos, “Payroll site closes on security worries,” Cnet News.com, Feb.
2005, http://news.com.com/2102-1029_3-5587859.html.
data ﬁles
http://www.news10.net/
[7] News10,
thousands
at CSU Chico,” Mar.
display_story.aspx?storyid=9784.
2005,
of
personal
“Hacker
accesses
[8] K. Poulsen, “Car shoppers’ credit details exposed in bulk,” Securi-
tyFocus, Sept. 2003, http://www.securityfocus.com/news/
7067.
[9] ——, “FTC investigates petco.com security hole,” SecurityFocus, Dec.
2003, http://www.securityfocus.com/news/7581.
71
[10] R. Trounson, “Major breach of UCLA’s computer ﬁles,” Los Angeles
Times, Dec. 12 2006.
[11] M. D. McIlroy and J. A. Reeds, “Multilevel security in the UNIX
tradition,” Software—Practice and Experience, vol. 22, no. 8, pp. 673–
694, 1992.
[12] D. E. Denning, “A lattice model of secure information ﬂow,” Commu-
nications of the ACM, vol. 19, no. 5, pp. 236–243, May 1976.
[13] T. Fraser, “LOMAC: Low water-mark integrity protection for COTS
environments,” in Proceedings of the IEEE Symposium on Security and
Privacy, Oakland, CA, May 2000, pp. 230–245.
[14] D. E. Bell and L. J. LaPadula, “Secure computer system: Uniﬁed
exposition and Multics interpretation,” MITRE Corparation, Bedford,
MA, Tech. Rep. MTR-2997, Rev. 1, March 1976.
[15] K. J. Biba, “Integrity considerations for secure computer systems,”
MITRE Corp., Bedford, MA, Tech. Rep. MTR-3153, Rev. 1, 1976.
[16] C. A. R. Hoare, Communicating Sequential Processes.
Englewood
Cliffs, New Jersey: Prentice/Hall International, 1985.
[17] J. A. Goguen and J. Meseguer, “Security policies and security models,”
in Proceedings of the IEEE Symposium on Research in Security and
Privacy, 1982.
[18] P. A. Ryan and S. A. Schneider, “Process algebra and non-interference,”
Journal of Computer Security, no. 9, pp. 75–103, 2001.
[19] A. W. Roscoe, A Theory and Practice of Concurrency. London, UK:
Prentice Hall, 1998.
[20] S. Schneider, Concurrent and Real-Time Systems: The CSP Approach.
Chichester, UK: John Wiley & Sons, LTD, 2000.
[21] A. Roscoe and M. H. Goldsmith, “What is intransitive noninterference?”
in Proceedings of the 12th IEEE Computer Security Foundations Work-
shop (CSFW).
IEEE Computer Society Press, 1999.
[22] A. Bossi, C. Piazza, and S. Rossi, “Modelling downgrading in informa-
tion ﬂow security,” in Proceedings of the 17th IEEE Computer Security
Foundations Workshop (CSFW), June 2004.
[23] J. Jacob, “On the derivation of secure components,” in Proceedings of
the the IEEE Symposium on Security and Privacy, Oakland, CA, 1989.
[24] G. Lowe, “On information ﬂow and reﬁnement-closure,” in Proceedings
of the Workshop on Issues in the Theory of Security (WITS07), 2007.
[25] H. Mantel, “Preserving Information Flow Properties under Reﬁnement,”
in Proceedings of the 2001 IEEE Symposium on Security and Privacy,
May 2001.
[26] D. R. Engler, M. F. Kaashoek, and J. O’Toole, “Exokernel: An operating
system architecture for application-level resource management,” in Pro-
ceedings of the 15th ACM Symposium on Operating Systems Principles
(SOSP), Copper Mountain Resort, Colorado, Dec. 1995, pp. 251–266.
[27] A. C. Arpaci-Dusseau, R. H. Arpaci-Dusseau, N. C. Burnett, T. E.
Denehy, T. J. Engle, H. S. Gunawi, J. A. Nugent, and F. I. Popovici,
“Transforming policies into mechanisms with infokernel,” in Proceed-
ings of the 19th ACM Symposium on Operating Systems Principles
(SOSP), Bolton Landing, Lake George, New York, Oct. 2003, pp. 90–
105.
[28] M. Bellare, R. Canetti, and H. Krawczyk, “Keying hash functions for
message authentication,” in Proceedings of the 16th Annual International
Cryptology Conference on Advances in Cryptology (CRYPTO), Aug.
1996, pp. 1–15.
[29] FIPS 180-2, Secure Hash Standard, U.S. Department of Com-
merce/N.I.S.T., National Technical Information Service, Springﬁeld, VA,
Aug. 2002.
[30] D. E. Bell and L. J. LaPadula, “Secure computer systems: Mathematical
foundations,” MITRE Corparation, Bedford, MA, Tech. Rep. Technical
Report 2547, Volume I, Mar. 1973.
[31] Trusted Computer System Evaluation Criteria (Orange Book), DoD
5200.28-STD ed., Department of Defense, December 1985.
[32] P. Loscocco and S. Smalley, “Integrating ﬂexible support for security
policies into the Linux operating system,” in Proceedings of the 2001
USENIX Annual Technical Conference, San Diego, CA, June 2001,
FREENIX track.
[33] J. Palsberg and P. Ørbæk, “Trust in the λ-Calculus,” in Proceedings of
the 2nd International Symposium on Static Analysis, Sept. 1995.
[34] J. Newsome and D. Song, “Dynamic taint analysis for automatic
detection, analysis, and signature generation of exploits on commodity
software,” in Network and Distributed System Security Symposium
(NDSS), Feb. 2005.
[35] S. McCamant and M. Ernst, “Quantitative Information Flow as Network
Flow Capacity,” in Proceedings of the ACM SIGPLAN Conference on
Programming Language Design and Implementation, 2008.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:18:50 UTC from IEEE Xplore.  Restrictions apply. 
[36] D. Volpano, C. Irvine, and G. Smith, “A sound type system for secure
ﬂow analysis,” vol. 4, no. 2-3, 1996, pp. 167–187.
[37] L. Zheng and A. C. Myers, “Dynamic security labels and noninterfer-
ence,” in Proceedings of the 2nd International Workshop on Formal
Aspects in Security and Trust (FAST), Aug. 2004.
[38] S. Tse and S. Zdancewic, “Run-time principals in information-ﬂow
type systems,” ACM Transactions on Programming Language Systems,
vol. 30, no. 1, 2007.
[39] G. Lowe, “Some new attacks upon security protocols,” in Proceedings of
the 9th IEEE Computer Security Foundations Workshop (CSFW), 1996.
[40] P. Ryan and S. Schneider, The Modelling and Analysis of Security
Protocols: The CSP Approach. Addison-Wesley Professional, 2001.
[41] J. Ouaknine, “A framework for model-checking timed CSP,” Oxford
University, Tech. Rep., 1999.
A. Review of CSP
APPENDIX
Communicating Sequential Processes (CSP) is a process algebra
useful in specifying systems as a set of parallel state machines that
sometimes synchronize on events. We offer a brief review of it here,
borrowing heavily from Hoare’s book [16].
1) CSP Processes: Among the most basic CSP examples is
Hoare’s vending machine:
VMS = in25 → choc → VMS
This vending machine waits for the event in25, which corresponds
to the input of a quarter into the machine. Next, it accepts the event
choc, which corresponds to a chocolate falling out of the machine.
Then it returns to the original state, with a recursive call to itself. The
basic operator at use here is the preﬁx operator. If x is an event, and
P is a process, then (x → P ), pronounced “x then P ,” represents
a process that engages in event x and then behaves like process P .
For a process P , the notation αP describes the “alphabet” of P . It
is a set of all of the events that P is ever willing to engage in. For
example, αVMS = {in25, choc}.
For any CSP process P , we can discuss a trace of events that P
may accept. For the VMS example, various traces include:
(cid:10)(cid:11)
(cid:10)in25(cid:11)
(cid:10)in25, choc(cid:11)
(cid:10)in25, choc, in25, choc, in25(cid:11)
For two traces tr and tr(cid:2), deﬁne tr (cid:4) tr(cid:2) to be their concatenation.
The next important operator is “choice,” denoted by “|”. If x and
y are distinct events, then:
(x → P | y → Q)
denotes a process that accepts x and then behaves like P or accepts
y and then behaves like Q. For example, a new vending machine
can accept either a coin and output a chocolate, or accept a bill and
output an ice cream cone:
VMS2 = (bill → cone → VMS2 | in25 → choc → VMS2)
CSP offers a more general choice function (for choosing between
many inputs succinctly), but the Flume model only requires simple
choice.
A related operator is internal (nondeterministic) choice, is denoted
“(cid:15)”. In simple choice, the machine reacts exactly to events it ﬁelds
from the machine’s user. In nondeterministic choice, the machine be-
haves unpredictably from the perspective of the user, maybe because
the machine’s description is underspeciﬁed, or maybe because the
machine is picking from a random number generator. For instance, a
change machine might return coins in any order, depending on how
the machine was last serviced:
CHNG = (in25 → (out10 → out10 → out5 → CHNG (cid:15)
out10 → out5 → out10 → CHNG))
That is, the machine takes as input a quarter, and returns two dimes
and a nickel in one of two orderings. Another standard operator,
“external choice” denoted “(cid:5)”, has different semantics but does not
appear in Flume’s model.
CSP provides useful predeﬁned processes like STOP, the process
that accepts no events, and SKIP, the process that shows a successful
termination and then behaves like STOP. Other processes like DIV,
RUN and CHAOS are standard in the literature, but are not required
here.
The next class of operators relate to parallelism. The notation:
P (cid:7)
Q
A
denotes P running in parallel with Q, synchronizing on events in A.6
This means a stream of incoming events can be arbitrarily assigned
to either P or Q, assuming those events are not in A. However,
for events in A, both P and Q must accept them in synchrony. As
an example, consider the vending machine and the change machine
running in parallel, synchronizing on the event in25:
FREELUNCH = VMS
(cid:7)
CHNG
{in25}
Possible traces for this new process are the various interleavings of
the traces for the two component machines that agree on the event
in25. For instance:
(cid:10)in25, choc, out10, out10, out5, . . .(cid:11)
(cid:10)in25, out10, choc, out10, out5, . . .(cid:11)
(cid:10)in25, out10, out10, choc, out5, . . .(cid:11)
(cid:10)in25, choc, out10, out5, out10, . . .(cid:11)
(cid:10)in25, out10, out5, out10, choc, . . .(cid:11)
are possible execution paths for FREELUNCH.
Another variation on parallel composition is arbitrary interleaving,
denoted: P (cid:3) Q. In interleaving, P and Q never synchronize,
operating independently of one another. P (cid:3)Q is therefore equivalent
to P (cid:7){} Q, which means P and Q run in parallel and synchronize
on the empty set.
Processes that run in parallel can communicate with one another
over channels. A typical channel c can carry various values v, denoted
c.v.7 This is represented as the sending process accepting the event
c!v while the receiving process accepts the event c?x (where x is
thus far unbound) and sets x to v. Communication on a channel
is possible only when the sender and receiver processes are in the
respective states simultaneously. If one process is at the suitable state
and the other is not, the ready process waits until its partner becomes
ready. In a slight deviation from Hoare’s semantics, channels here are
bidirectional: messages can travel independently in either direction
across a channel. The Flume model uses channels extensively.
The next important CSP feature is concealment or hiding. For a
process P and a set of symbols C, the process P \C is P with
symbols in C hidden or concealed. The events in C become internal
6Parallelism differs between Hoare’s original CSP formulation and more