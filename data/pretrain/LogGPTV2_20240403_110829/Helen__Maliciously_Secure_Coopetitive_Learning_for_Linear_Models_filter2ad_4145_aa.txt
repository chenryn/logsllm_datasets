title:Helen: Maliciously Secure Coopetitive Learning for Linear Models
author:Wenting Zheng and
Raluca Ada Popa and
Joseph E. Gonzalez and
Ion Stoica
(cid:19)(cid:17)(cid:18)(cid:26)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:1)(cid:52)(cid:90)(cid:78)(cid:81)(cid:80)(cid:84)(cid:74)(cid:86)(cid:78)(cid:1)(cid:80)(cid:79)(cid:1)(cid:52)(cid:70)(cid:68)(cid:86)(cid:83)(cid:74)(cid:85)(cid:90)(cid:1)(cid:66)(cid:79)(cid:69)(cid:1)(cid:49)(cid:83)(cid:74)(cid:87)(cid:66)(cid:68)(cid:90)
Helen: Maliciously Secure Coopetitive Learning for Linear Models
Wenting Zheng, Raluca Ada Popa, Joseph E. Gonzalez, and Ion Stoica
UC Berkeley
Abstract—Many organizations wish to collaboratively train
machine learning models on their combined datasets for a
common beneﬁt (e.g., better medical research, or fraud detection).
However, they often cannot share their plaintext datasets due to
privacy concerns and/or business competition. In this paper, we
design and build Helen, a system that allows multiple parties
to train a linear model without revealing their data, a setting
we call coopetitive learning. Compared to prior secure training
systems, Helen protects against a much stronger adversary who
is malicious and can compromise m − 1 out of m parties.
Our evaluation shows that Helen can achieve up to ﬁve orders
of magnitude of performance improvement when compared to
training using an existing state-of-the-art secure multi-party
computation framework.
I. INTRODUCTION
Today, many organizations are interested in training machine
learning models over their aggregate sensitive data. The parties
also agree to release the model to every participant so that
everyone can beneﬁt from the training process. In many existing
applications, collaboration is advantageous because training on
more data tends to yield higher quality models [40]. Even more
exciting is the potential of enabling new applications that are
not possible to compute using a single party’s data because they
require training on complementary data from multiple parties
(e.g., geographically diverse data). However, the challenge is
that these organizations cannot share their sensitive data in
plaintext due to privacy policies and regulations [3] or due to
business competition [67]. We denote this setting using the term
coopetitive learning1, where the word “coopetition” [30] is a
portmanteau of “cooperative” and “competitive”. To illustrate
coopetitive learning’s potential impact as well as its challenges,
we summarize two concrete use cases.
A banking use case. The ﬁrst use case was shared with us by
two large banks in North America. Many banks want to use
machine learning to detect money laundering more effectively.
Since criminals often hide their traces by moving assets across
different ﬁnancial institutions, an accurate model would require
training on data from different banks. Even though such a model
would beneﬁt all participating banks, these banks cannot share
their customers’ data in plaintext because of privacy regulations
and business competition.
A medical use case. The second use case was shared with us by
a major healthcare provider who needs to distribute vaccines
during the annual ﬂu cycle. In order to launch an effective
vaccination campaign (i.e., sending vans to vaccinate people in
1We note that Google uses the term federated learning [67] for a different
but related setting: a semi-trusted cloud trains a model over the data of millions
of user devices, which are intermittently online.
participant 2
  . . .
participant 1
coopetitive 
learning
participant m
model
Fig. 1: The setting of coopetitive learning.
remote areas), this organization would like to identify areas that
have high probabilities of ﬂu outbreaks using machine learning.
More speciﬁcally, this organization wants to train a linear
model over data from seven geographically diverse medical
organizations. Unfortunately, such training is impossible at this
moment because the seven organizations cannot share their
patient data with each other due to privacy regulations.
The general setup of coopetitive learning ﬁts within the
cryptographic framework of secure multi-party computation
(MPC) [8, 37, 70]. Unfortunately, implementing training using
generic MPC frameworks is extremely inefﬁcient, so recent
training systems [56, 41, 54, 34, 20, 35, 5] opt for tailored
protocols instead. However, many of these systems rely on
outsourcing to non-colluding servers, and all assume a passive
attacker who never deviates from the protocol. In practice, these
assumptions are often not realistic because they essentially
require an organization to base the conﬁdentiality of its data on
the correct behavior of other organizations. In fact, the banks
from the aforementioned use case informed us that they are
not comfortable with trusting the behavior of their competitors
when it comes to sensitive business data.
Hence, we need a much stronger security guarantee: each
itself. This goal calls for
organization should only trust
maliciously secure MPC in the setting where m − 1 out of m
parties can fully misbehave.
In this paper, we design and build Helen, a platform for mali-
ciously secure coopetitive learning. Helen supports a signiﬁcant
slice of machine learning and statistics problems: regularized
linear models. This family of models includes ordinary least
squares regression, ridge regression, and LASSO. Because
these models are statistically robust and easily interpretable,
they are widely used in cancer research [48], genomics [28, 59],
(cid:165)(cid:1)(cid:19)(cid:17)(cid:18)(cid:26)(cid:13)(cid:1)(cid:56)(cid:70)(cid:79)(cid:85)(cid:74)(cid:79)(cid:72)(cid:1)(cid:59)(cid:73)(cid:70)(cid:79)(cid:72)(cid:15)(cid:1)(cid:54)(cid:79)(cid:69)(cid:70)(cid:83)(cid:1)(cid:77)(cid:74)(cid:68)(cid:70)(cid:79)(cid:84)(cid:70)(cid:1)(cid:85)(cid:80)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:15)
(cid:37)(cid:48)(cid:42)(cid:1)(cid:18)(cid:17)(cid:15)(cid:18)(cid:18)(cid:17)(cid:26)(cid:16)(cid:52)(cid:49)(cid:15)(cid:19)(cid:17)(cid:18)(cid:26)(cid:15)(cid:17)(cid:17)(cid:17)(cid:21)(cid:22)
(cid:24)(cid:19)(cid:21)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply. 
ﬁnancial risk analysis [63, 17], and are the foundation of basis
pursuit techniques in signals processing.
The setup we envision for Helen is similar to the use cases
above: a few organizations (usually less than 10) have large
amounts of data (on the order of hundreds of thousands or
millions of records) with a smaller number of features (on the
order of tens or hundreds).
While it is possible to build such a system by implementing
a standard training algorithm like Stochastic Gradient Descent
(SGD) [61] using a generic maliciously secure MPC proto-
col, the result is very inefﬁcient. To evaluate the practical
performance difference, we implemented SGD using SPDZ, a
maliciously secure MPC library [1]. For a conﬁguration of 4
parties, and a real dataset of 100K data points per party and
90 features, such a baseline can take an estimated time of 3
months to train a linear regression model. Using a series of
techniques explained in the next section, Helen can train the
same model in less than 3 hours.
A. Overview of techniques
To solve such a challenging problem, Helen combines
insights from cryptography, systems, and machine learning.
This synergy enables an efﬁcient and scalable solution under
a strong threat model. One recurring theme in our techniques
is that, while the overall training process needs to scale
linearly with the total number of training samples, the more
expensive cryptographic computation can be reformulated to
be independent of the number of samples.
Our ﬁrst insight is to leverage a classic but under-utilized
technique in distributed convex optimization called Alternating
Direction Method of Multipliers (ADMM) [15]. The standard
algorithm for training models today is SGD, which optimizes
an objective function by iterating over the input dataset. With
SGD, the number of iterations scales at least linearly with the
number of data samples. Therefore, na¨ıvely implementing SGD
using a generic MPC framework would require an expensive
MPC synchronization protocol for every iteration. Even though
ADMM is less popular for training on plaintext data, we show
that it is much more efﬁcient for cryptographic training than
SGD. One advantage of ADMM is that it converges in very few
iterations (e.g., a few tens) because each party repeatedly solves
local optimization problems. Therefore, utilizing ADMM allows
us to dramatically reduce the number of MPC synchronization
operations. Moreover, ADMM is very efﬁcient in the context of
linear models because the local optimization problems can be
solved by closed form solutions. These solutions are also easily
expressible in cryptographic computation and are especially
efﬁcient because they operate on small summaries of the input
data that only scale with the dimension of the dataset.
However, merely expressing ADMM in MPC does not solve
an inherent scalability problem. As mentioned before, Helen
addresses a strong threat model in which an attacker can deviate
from the protocol. This malicious setting requires the protocol
to ensure that the users’ behavior is correct. To do so, the
parties need to commit to their input datasets and prove that
they are consistently using the same datasets throughout the
computation. A na¨ıve way of solving this problem is to have
each party commit to the entire input dataset and calculate
the summaries using MPC. This is problematic because 1) the
cryptographic computation will scale linearly in the number of
samples, and 2) calculating the summaries would also require
Helen to calculate complex matrix inversions within MPC
(similar to [57]). Instead, we make a second observation that
each party can use singular value decomposition (SVD) [38] to
decompose its input summaries into small matrices that scale
only in the number of features. Each party commits to these
decomposed matrices and proves their properties using matrix
multiplication to avoid explicit matrix inversions.
Finally, one important aspect of ADMM is that it enables
decentralized computation. Each optimization iteration consists
of two phases:
local optimization and coordination. The
local optimization phase requires each party to solve a local
sub-problem. The coordination phase requires all parties to
synchronize their local results into a single set of global
weights. Expressing both phases in MPC would encode local
optimization into a computation that is done by every party,
thus losing the decentralization aspect of the original protocol.
Instead, we observe that the local operations are all linear
matrix operations between the committed summaries and the
global weights. Each party knows the encrypted global weights,
as well as its own committed summaries in plaintext. Therefore,
Helen uses partially homomorphic encryption to encrypt the
global weights so that each party can solve the local problems
in a decentralized manner, and enables each party to efﬁciently
prove in zero-knowledge that it computed the local optimization
problem correctly.
II. BACKGROUND
A. Preliminaries
In this section, we describe the notation we use for the rest
of the paper. Let P1, ..., Pm denote the m parties. Let ZN
denote the set of integers modulo N, and Zp denote the set
of integers modulo a prime p. Similarly, we use Z∗
N to denote
the multiplicative group modulo N.
We use z to denote a scalar, z to denote a vector, and Z to
denote a matrix. We use EncPK(x) to denote an encryption
of x under a public key PK. Similarly, DecSK(y) denotes a
decryption of y under the secret key SK.
Each party Pi has a feature matrix Xi ∈ Rn×d, where
n is the number of samples per party and d is the feature
dimension. yi ∈ Rn×1 is the labels vector. The machine
learning datasets use ﬂoating point representation, while our
cryptographic primitives use groups and ﬁelds. Therefore, we
represent the dataset using ﬁxed point integer representation.
B. Cryptographic building blocks
In this section, we provide a brief overview of the crypto-
graphic primitives used in Helen.
1) Threshold partially homomorphic encryption: A partially
homomorphic encryption scheme is a public key encryption
scheme that allows limited computation over the ciphertexts.
(cid:24)(cid:19)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply. 
For example, Paillier [58] is an additive homomorphic encryp-
tion scheme: multiplying two ciphertexts together (in a certain
group) generates a new ciphertext such that its decryption yields
the sum of the two original plaintexts. Anyone with the public
key can encrypt and manipulate the ciphertexts based on their
homomorphic property. This encryption scheme also acts as
a perfectly binding and computationally hiding homomorphic
commitment scheme [39], another property we use in Helen.
A threshold variant of such a scheme has some additional
properties. While the public key is known to everyone, the
secret key is split across a set of parties such that a subset of
them must participate together to decrypt a ciphertext. If not
enough members participate, the ciphertext cannot be decrypted.
The threshold structure can be altered based on the adversarial
assumption. In Helen, we use a threshold structure where all
parties must participate in order to decrypt a ciphertext.
2) Zero knowledge proofs:
Informally, zero knowledge
proofs are proofs that prove that a certain statement is true
without revealing the prover’s secret for this statement. For
example, a prover can prove that there is a solution to a Sudoku
puzzle without revealing the actual solution. Zero knowledge
proofs of knowledge additionally prove that the prover indeed
knows the secret. Helen uses modiﬁed Σ-protocols [25] to prove
properties of a party’s local computation. The main building
blocks we use are ciphertext proof of plaintext knowledge,
plaintext-ciphertext multiplication, and ciphertext interval proof
of plaintext knowledge [23, 14], as we further explain in
Section IV. Note that Σ-protocols are honest veriﬁer zero
knowledge, but can be transformed into full zero-knowledge
using existing techniques [24, 32, 33]. In our paper, we present
our protocol using the Σ-protocol notation.
3) Malicious MPC: We utilize SPDZ [27], a state-of-the-art
malicious MPC protocol, for both Helen and the secure baseline
we evaluate against. Another recent malicious MPC protocol
is authenticated garbled circuits [69], which supports boolean
circuits. We decided to use SPDZ for our baseline because
the majority of the computation in SGD is spent doing matrix
operations, which is not efﬁciently represented in boolean
circuits. For the rest of this section we give an overview of
the properties of SPDZ.
An input a ∈ Fpk to SPDZ is represented as (cid:3)a(cid:4) =
(δ, (a1, . . . , an), (γ(a)1, . . . , γ(a)n)), where ai is a share of
a and γ(a)i is the MAC share authenticating a under a SPDZ
global key α. Player i holds ai, γ(a)i, and δ is public. During
a correct SPDZ execution, the following property must hold:
a =
i γ(a)i. The global key α is not
revealed until the end of the protocol; otherwise the malicious
parties can use α to construct new MACs.
i ai and α(a + δ) =
(cid:2)
(cid:2)
SPDZ has two phases: an ofﬂine phase and an online phase.
The ofﬂine phase is independent of the function and generates
precomputed values that can be used during the online phase,
while the online phase executes the designated function.
C. Learning and Convex Optimization
Much of contemporary machine learning can be framed in
the context of minimizing the cumulative error (or loss) of
a model over the training data. While there is considerable
excitement around deep neural networks, the vast majority of
real-world machine learning applications still rely on robust
linear models because they are well understood and can
be efﬁciently and reliably learned using established convex
optimization procedures.
In this work, we focus on linear models with squared error
and various forms of regularization resulting in the following
set of multi-party optimization problems:
(cid:5)Xiw − yi(cid:5)2
2 + λR(w),
m(cid:3)
(1)
ˆw = arg min
w
1
2
i=1
n×d and yi ∈ R
where Xi ∈ R
n are the training data
(features and labels) from party i. The regularization function
R and regularization tuning parameter λ are used to improve
prediction accuracy on high-dimensional data. Typically, the
regularization function takes one of the following forms:
d(cid:3)
j=1
w2
j
RL1 (w) =
|wj|,
RL2 (w) =
1
2
d(cid:3)
j=1
m(cid:3)
1
2
corresponding to Lasso (L1) and Ridge (L2) regression re-
spectively. The estimated model ˆw ∈ R
d can then be used
to render a new prediction ˆy∗ = ˆwT x∗ at a query point x∗.
It is worth noting that in some applications of LASSO (e.g.,
genomics [28]) the dimension d can be larger than n. However,
in this work we focus on settings where d is smaller than n,