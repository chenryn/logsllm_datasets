==== 使用KafkaMessageEncoder发送日志原文到Kafka
本节介绍如何只将raw_message的日志原文按照appname回写到不同的topic。
版本：
linux 64bit Heka 3.2.0.3以上，包括3.2.0.3
配置说明：
首先，从 Agent 层面就发送原文也就意味着不用发给日志易后端，所以打开高级配置，找到RzyHttpOutput，将其中的message_matcher值改为FALSE，跳过发送日志易步骤：如下：
  [RzyHttpOutput]
    message_matcher = "FALSE"
    address = "http://192.168.1.82:5180/proto/?compressed=true"  
    use_buffering = true
    encoder = "RzyProtobufEncoder"
    [RzyHttpOutput.Buffering]
      max_file_size = 268435456
      max_buffer_size = 1073741824
      full_action = "block"
      cursor_update_count = 1000
然后，在Other下添加下面内容：
  [CKafkaOutput]
    message_matcher = 'TRUE'
    addrs = ["10.211.55.2:9092"]
    # 使用KafkaMessageEncoder时该项配置不生效，配置为test即可
    topic = "test"
    # encoder，此处使用KafkaMessageEncoder
    encoder = 'KafkaMessageEncoder'
    use_buffering = true
    # 新建TOPIC的partition和replication，只有在kafka version >= 0.10.2.0才生效
    num_partitions = 1
    replication_factor = 1
    [CKafkaOutput.Buffering]
      max_file_size = 268435456
      max_buffer_size = 1073741824
      full_action = "block"
      cursor_update_count = 1000
  [KafkaMessageEncoder]
    # 需要输出到kafka的数据的规则
    payload_extractor = ":$str(.payload)"
    # 需要输出到的topic的规则
    topic_extractor = ":$str(.appname)"
payload_extractor和topic_extractor的配置说明：
假设raw_message数据如下：
  {"uuid":"QVhCQ3RGVTgwMXB5V2p6YlBKY2YAAAAA","timestamp":1581667079484215000,"type":"kafka","logger":"2315c25a2bfa73fb0b99442de16e5a66_kafka_input","severity":7,"payload":"testPayload","hostname":"ylhost2","appname":"testAppName","tag":"testTag","contextID":1581667079000000000,"source":"testSource","ip":"127.0.0.1","logTimestamp":1581667079000}
如果通过heka采集该数据后，根据input配置会给本条数据打上相应的appname、payload、source、hostname、tag等（其中payload表示采集的源数据本身)，由于本条数据本身也有appname、payload、source、hostname、tag字段，所以为了方便后面解释，称本条数据的这些字段为源数据的对应字段。
第一种情况：
配置为appname、payload、source、hostname、tag 中的一种，表示提取heka本次采集打上的对应字段
如：
  [KafkaMessageEncoder]
  payload_extractor = "payload"
  topic_extractor = "appname"
表示将本次采集的源数据输出到kafka，topic为本次打上的appname字段
第二种情况：
配置为以:开头的string，表示提取源数据的对应字段，具体规则参考KafkaInput使用说明中的映射规则
如：
  [KafkaMessageEncoder]
  payload_extractor = ":$str(.payload)"
  topic_extractor = ":$str(.appname)"
表示将源数据中的payload字段输出到kafka，topic为源数据中的appname字段，即testAppName。
注意：不要照写对应的配置，payload_extractor字段具体应该参考你实际的数据里面的字段名字，如果是采集的日志易的raw_message topic，往往需要的原文字段名字是叫raw_message，而不是payload。