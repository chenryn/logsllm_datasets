HW is that is describes the ideal functionality or oracle that models
the real (physical) world assumptions about the hardware security
properties of Intel SGX), and that an adversary shouldn’t be able to
distinguish between interacting with the real world hardware and
the ideal functionality. This allows us to simulate the adversary’s
interaction with HW in a proof of security, but it is a very strong
assumption on the secure hardware being used, particularly since
the adversary has access to the physical hardware and can closely
monitor its behavior. A weaker assumption, stated informally, is
simply that the adversary gains no more “useful" information from
querying the real hardware on some input beyond the outputs
specified by HW, without requiring that an adversary’s physical
interactions with HW cannot be simulated. Our security proof of
the main system/construction we have presented assumes the first
model. In Appendix D we explore the second model, though it turns
out that we cannot achieve the standard non-interactive notion of
functional encryption in this stronger security model.
Related models. Barbosa et. al. [7] define a similar interface/ideal
functionality to represent systems like SGX that perform attested
computation. Compared to their model, our model sacrifices some
generality for a simpler syntax that more closely models SGX. Their
security model uses a game-based definition of attested computa-
tion, similar to the second security model we discuss in the Appen-
dix.
Pass, Shi, and Tramer [48] also define an ideal functionality for
attested computation in the Universal Composability framework
[14]. The goal of their model is to explore composable security for
protocols using secure processors performing attested computation.
Similar to [7] their syntax is more abstract that ours, e.g. does
not distinguish between local and remote attestation. However,
their hardware security model is more similar in that it allows the
hardware functionality to be simulated. A key difference is that their
simulator does not possess the hardware’s secret signing key(s) used
to generate attestations. Our simulator will be given the hardware’s
secret keys, similar to trapdoor information in CRS-model proofs.
Bahmani et al [6] adapts the SGX model of [7] to deal with
sequences of SGX computations that may be stateful, asynchronous,
and interleaved with other computations. Their model is called
labelled attested computation, which refers to labels being appended
to every enclave input/output in order to track state. This capability
is implicitly captured in our model as well.
5.2 Functional Encryption
We adapt the definition of functional encryption to fit the com-
putational model of our system. Interaction with local enclaves is
modeled as calls to the HW functionality defined in Definition 5.1.
Communication with the remote KME is modeled with a sepa-
rate oracle KM(·). We allow for a preprocessing phase which runs
the setup for all HW instances. A functional encryption scheme
ℱℰ for a family of programs 𝒫 and message space ℳ consists
of algorithms ℱℰ = (FE.Setup, FE.Keygen, FE.Enc, FE.DecSetup,
FE.Dec) defined as follows.
• FE.Setup(1λ ): On input security parameter λ (in unary), out-
put the master public key mpk and the master secret key
msk.
• FE.Keygen(msk, P ): On input the master secret key msk and
a program P ∈ 𝒫, output the secret key skP for P.
• FE.Enc(mpk, msg): On input the master public key mpk and
an input message msg ∈ ℳ, output a ciphertext ct.
• FE.DecSetupKM(·),HW(·) (mpk): The decryption node setup
algorithm has access to the KM oracle and the HW oracles.
On input the master public key mpk, output a handle hdl to
be used by the actual decryption algorithm.
• FE.DecHW(·) (hdl, skP , ct): On input a handle hdl for an en-
clave, a secret key skP and a ciphertext ct and outputs P (msg)
or ⊥. This algorithm has access to the interface for all the
algorithms of the secure hardware HW.
(cid:17)
all P ∈ 𝒫 and all msg ∈ ℳ, the probability for FE.DecHW(·)(cid:16)
Correctness. A functional encryption scheme ℱℰ is correct if for
hdl,
to be not equal to P (msg) is negl(λ), where (mpk, msk) ←
skP , ct
FE.Setup(1λ ), skP ← FE.Keygen(msk, P ), ct ← FE.Enc(mpk, msg)
and hdl ← FE.DecSetupKM(·),HW(·) (mpk) and the probability is
taken over the random coins of the probabilistic algorithms FE.Setup,
FE.Keygen, FE.Enc, FE.DecSetup.
Session D1:  Functional Encryption and ObfuscationCCS’17, October 30-November 3, 2017, Dallas, TX, USA772Non-interaction. Non-interaction is central to the standard no-
tion of functional encryption. Our construction of hardware assisted
FE requires a one-time setup operation where the decryptor’s hard-
ware contacts the KME to receive a secret key. However, this in-
teraction only occurs once in the setup of a decryption node, and
thereafter decryption is non-interactive. To capture this restriction
on interaction we add to the standard FE algorithms an additional
algorithm FE.DecSetup, which is given oracle access to a Key Man-
ager KM(·). The decryption algorithm FE.Dec is only given access
to HW.
Security definition. Here, we define a strong simulation-based
security of F E similar to [2, 11, 26]. In this security model, a polyno-
mial time adversary will try to distinguish between the real world
and a “simulated” world. In the real world, algorithms work as
defined in the construction. In the simulated world, we will have
to construct a polynomial time simulator which has to do the ex-
periment given only the program queries P made by the adversary
and the corresponding results P (msg).
Definition 5.2 (SimSecurity-FE). Consider a stateful simulator 𝒮
and a stateful adversary 𝒜. Let Umsg (·) denote a universal oracle,
such that Umsg (P ) = P (msg).
Both games begin with a pre-processing phase executed by the
environment. In the ideal game, pre-processing is simulated by 𝒮.
Now, consider the following experiments.
ℱℰ (1λ ) :
Expreal
(mpk, msk) ← FE.Setup(1λ )
(msg) ← 𝒜FE.Keygen(msk,·) (mpk)
ct ← FE.Enc(mpk, msg)
α ← 𝒜FE.Keygen(msk,·),HW,KM(·) (mpk, ct)
Output (msg, α )
Expideal
ℱℰ (1λ ) :
mpk ← 𝒮 (1λ )
msg ← 𝒜𝒮 (·) (mpk)
ct ← 𝒮Umsg (·) (1λ, 1|msg| )
α ← 𝒜𝒮Umsg (·) (·) (mpk, ct)
Output (msg, α )
In the above experiment, oracle calls by 𝒜 to the key-generation,
HW and KM oracles are all simulated by the simulator 𝒮Umsg (·) (·).
An F E scheme is simulation-secure against adaptive adversaries if
there is a stateful probabilistic polynomial time simulator 𝒮 that
on each FE.Keygen query P queries its oracle Umsg (·) only on the
same P (and hence learn just P (msg)), such that for every proba-
bilistic polynomial time adversary 𝒜 the following distributions
are computationally indistinguishable.
Exprealℱℰ (1λ )
c≈ Expidealℱℰ (1λ )
Note that the above definition handles one message only. This
can be extended to a definition of security for many messages by
allowing the adversary to adaptively output many messages while
providing him the ciphertext for a message whenever he outputs
one. Here, the simulator will have an oracle Umsgi (·) for every msgi
output by the adversary.
Simulating HW. As previously discussed, we let the simulator
intercept all the adversary’s queries to HW and return simulated
responses, just as in [19]. If we do not allow simulation of HW, it
is impossible to achieve Definition 5.2. In Appendix D we provide
a modified FE definition to allow minimal interaction8 with an effi-
cient KM oracle during every run of FE.Dec, and give a construction
that realizes this modified FE in the stronger security model.
6 FORMAL CONSTRUCTION
We present here the formal description of our FE system using the
syntax of the HW model from Definition 5.1. The trusted authority
platform T A and decryption node platform DN each have access to
instances of HW. Let PKE denote an IND-CCA2 secure public key
encryption scheme (Definition B.3) and let S denote an existentially
unforgeable signature scheme (Definition B.2).
Pre-processing phase. T A and DN run HW.Setup(1λ ) for their
HW instances and record the output params.
FE.SetupHW(1λ ). The key manager enclave program QK ME
is defined as follows. The value tagDE, the measurement of the
program QDE, is hardcoded in the static data of QK ME. Let state
denote an internal state variable.
QK ME:
• On input (“init", 1λ ):
(1) Run (pkpke, skpke) ← PKE.KeyGen(1λ ) and (vksign, sksign) ←
S.KeyGen(1λ )
(cid:17)
(cid:16)
mdhdl, tagQ, in, out, σ
(2) Update state to (skpke, sksign, vksign) and output (pkpke, vksign)
• On input (“provision", quote, params):
(1) Parse quote =
(2) Parse in = (“init setup”, vksign) and check if vksign matches with
(3) Parse out = (sid, pk) and run b ← HW.QuoteVerify(params,
tagDE. If not, output ⊥.
the one in state. If not, output ⊥.
quote) on quote. If b = 0 output ⊥.
, check that tagQ =
(4) Retrieve skpke from state and compute ctsk = PKE.Enc(pk,
skpke) and σsk = S.Sign(sksign, (sid, ctsk )) and output (sid,
ctsk, σsk ).
• On input (“sign", msg):
Compute sig ← S.Sign(sksign, msg) and output sig.
Run hdlK ME ← HW.Load(params, QK ME ) and (pkpke, vksign) ←
HW.Run(hdlK ME , (“init", 1λ )). Output the master public key mpk :=
(pkpke, vksign) and the master secret key msk := hdlK ME.
FE.KeygenHW (msk, P ). Parse msk = hdlK ME as a handle to
HW.Run. Derive tagP and call sig ← HW.Run(hdlK ME , (“sign",
tagP )). Output skp := sig.
FE.Enc(mpk, msg). Parse mpk = (pk, vk). Compute ct ←
PKE.Enc(pk, msg) and output ct.
FE.DecSetupHW,KM(·) (skP , ct). The decryption enclave program
QDE is defined as follows. The security parameter λ is hardcoded
into the program.
QDE:
• On input (“init setup", vksign):
(1) Run (pkra, skra) ← PKE.KeyGen(1λ ).
(2) Generate a session ID, sid ← {0, 1}λ.
(3) Update state to (sid, skra, vksign), and output (sid, pkra).
8Allowing unbounded interaction would lead to trivial constructions where KM simply
decrypts the ciphertext and returns the function of the message.
Session D1:  Functional Encryption and ObfuscationCCS’17, October 30-November 3, 2017, Dallas, TX, USA773exists for sid, output ⊥.
0, output ⊥.
• On input (“complete setup", sid, ctsk, σsk ):
(1) Look up the state to obtain the entry (sid, skra, vksign). If no entry
(2) Verify the signature b ← S.Verify(vksign, σsk, (sid, ctsk )). If b =
(3) Run m ← PKE.dec(skra, ctsk ) and parse m = (skpke).
(4) Add the tuple (skpke, vksign) to state9.
• On input (“provision", report, sig):
(1) Check to see that the setup has been completed, i.e. that state
(cid:16)
(3) Parse report =
mdhdl, tagQ, in, out, mac
(2) Check to see that the report has been verified, i.e. that state
and compute b ←
contains the tuple (skpke, vksign). If not, output ⊥.
(cid:17)
contains the tuple (1, report). If not, output ⊥.
S.Verify(vksign, sig, tagQ ). If b = 0, output ⊥.
Else, output ⊥.
(4) Parse out as (sid, pk). If b = 1 output (sid, PKE.Enc(pk, skpke)).
Run hdlDE ← HW.Load(params, QDE ). Parse mpk = (skpke,
vksign) and call quote ← HW.Run&QuoteskHW (hdlDE , “init setup",
vksign). Query KM(quote), which internally runs (sid, ctsk , σsk ) ←
HW.Run(hdlK ME , (“provision", quote, params))10. And now, call
HW.Run(hdlDE , (“complete setup", sid, ctsk , σsk )). Output hdlDE.
FE.DecHW(·) (hdl, skP , ct). Define a function enclave program
parameterized by P.
QF E (P ):
• On input (“init"):
(1) Run (pkla, skla) ← PKE.KeyGen(1λ ).
(2) Generate a session ID, sid ← {0, 1}λ.
(3) Update state to (sid, skla), and output (sid, pkla).
• On input (“run", reportsk, ctmsд ):
(1) Check to see that the report has been verified, i.e. that state
(cid:17)
contains the tuple (1, reportsk ). If not, output ⊥.
(cid:16)
(2) Parse reportsk =
mdhdl, tagQ, in, out, mac
. Parse out as (sid,
ctkey ).
for sid, output ⊥.
x ← PKE.dec(skpke, ctmsд ).
(3) Look up the state to obtain the entry (sid, skla). If no entry exists
(4) Compute skpke ← PKE.dec(skra, ctkey ) and use it to decrypt
(5) Run P on x and record the output out := P (x ). Output out.
Run hdlP ← HW.Load(params, QF E (P )) and call report ←
HW.Run&Reportskreport (hdlP , “init"). Run HW.ReportVerifyskreport
(hdlDE , report) with hdlDE = hdl and then call reportsk ←
HW.Run&Report(hdlDE , (“provision", report, sig)) with sig = skP .
Finally, run HW.ReportVerifyskreport (hdlP , reportsk ) and call out ←
HW.Run(hdlP , “run", reportsk , ctmsд ) with ctmsд = ct. Output
out.
7 SECURITY
We first explain the crux of our security proof here. More details
will follow.
We construct a simulator 𝒮 which can simulate FE.Keygen, HW,
KM oracles and simulate the challenge ciphertext for the challenge
message msg∗ provided by the adversary 𝒜. The only information
9vksign is already in state as part of the outputs of the previous “init setup” phase, but
it is useful store and use this tuple as result of a successfully completed setup.
10We could use HW.Run&Quote here instead of explicitly creating the signature σk .
If we do that, the verification step in DE would involve using the Intel Attestation
Service.
that 𝒮 will get about msg∗ other than its length is the access to
the Umsg∗ oracle which reveals P (msg∗) for the P’s queried by 𝒜
to FE.Keygen. At a high level, the proof idea is simple: 𝒮 encrypts
zeros as the the challenge ciphertext ct∗ and FE.Keygen is simu-
lated honestly. In the ideal experiment, 𝒮 intercepts 𝒜’s queries to
HW and provides simulated responses. It can use its Umsg∗ oracle
to get P (msg∗) and simply send this back to 𝒜 as the simulated
HW output. If 𝒜 queries HW on any ciphertexts that do not match
the challenge ciphertext ct∗, 𝒮 can decrypt them honestly since it
possesses msk. Since 𝒮 has to modify the program descriptions in
enclaves, we provide 𝒮 access to the HW keys skreport and skquote
to produce reports and quotes.
Despite the apparent simplicity, the following subtleties make
the proof of security more challenging than on first sight:
(1) The simple proof sketch does not account for all of 𝒜’s
interaction with HW between sending ct∗ and receiving
back P (msg∗). HW communicates through 𝒜 as a proxy. 𝒜
might even tamper with these intermediate messages and