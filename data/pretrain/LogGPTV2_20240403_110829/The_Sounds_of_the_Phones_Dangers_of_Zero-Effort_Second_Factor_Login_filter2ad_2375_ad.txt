get applications for Sound-Danger. Table 2 summarizes the frac-
tion of participants who use a given app and the default ringtone
popularity among the participants who use the app.
We asked the participants about the kind of sounds they use for
each application on their smartphone. The more predictable the
ringtone is, the more successful the active ringtone attack would be
in Sound-Danger. For the phone calls and text messaging, vibra-
tion and default ringtone are the most popular settings, silent and
custom ringtone being less popular. It seems people tend to set the
vibration at work, and set the default ringtone while at home. While
still some participants tend to set custom ringtone for their phone
calls and text messaging, custom ringtone is not that popular for
instant messaging applications. More than half of the participants
set the default ringtone for the instant messaging applications. Vi-
bration is the second most popular setting for the instant messaging
applications. The participants said that during a day they keep their
phone on ringing mode or on vibrate mode about half the time,
while they set it on silent mode only once in a while. These mea-
sures show that the Sound-Danger active attacks that target users by
calling them on some popular instant messaging applications have a
higher chance to succeed. Apart from the instant messaging appli-
cation, launching a passive attack by playing the default alarm tone
seems quite feasible. About half of the participants set the default
alarm tone that the attacker can play locally at certain time of the
day to mimic the sounds of the victim’s phone. Table 3 summarizes
the popular ringing setting of the two most popular phone brands,
namely iPhone and Samsung among the participants, in three com-
mon situations: at home, at work and while asleep.
6. REAL-WORLD ATTACK STRATEGIES
The survey results in Section 5 help us devise real-world attack
strategies and estimate the corresponding attack success rates. The
915Table 4: Sound-Danger Attack Strategy (Tc = 0.1524): The percentage of compromised users at the beginning of each attack round i is denoted as
CNi. Effective attack success rate (Ef fi) of the attack at each round i depends upon the particular type of device victim is using (device), the particular
state of the device the attack is targeting (state), the iterative success rate for a number of login attempts (k) the attack will be repeated for (Itt), and the
percentage of currently uncompromised users the attack is targeted towards (U Ni), as shown in Equation 3. In our calculations, k = 3 all throughout. The
last column (CNi = 1 − U Ni) shows the percentage of compromised users (CN) after each attack round. Before the start of the attack, i.e., at round 0,
CN0 = 0% (U N0 = 100%). When the attack applies to all devices (e.g., vibrational attacks), the device probability (device) is 100%, and when it applies
to speciﬁc device types, iPhone and Samsung, the device probabilities are 39% and 27%, respectively. The highlighted cell represents the percentage of user
accounts successfully compromised in eight rounds, which may ﬁnish in less than a day.
Attack Round (i)
Attack Description
1
2
3
4
5
6
7
8
Vibration at work
iPhone call at work
Samsung call at work
Vibrate at night
iPhone call at night
Samsung call at night
iPhone alarm
Samsung alarm
Probabilities
x
state
device
100.00% 57.00% 85.40%
39.00% 16.00% 81.80%
27.00% 13.00% 81.80%
100.00% 30.00% 85.40%
39.00% 30.00% 81.80%
27.00% 37.00% 81.80%
39.00% 50.00% 100.00%
27.00% 50.00% 100.00%
Itt(k = 3)
Ef fi(k = 3)
Compromised User Accounts
(CNi = 1 − U Ni)
99.69%
99.40%
99.40%
99.69%
99.40%
99.40%
100.00%
100.00%
56.82%
2.68%
1.41%
11.69%
3.19%
2.40%
3.19%
1.88%
56.82%
59.50%
60.19%
72.60%
75.79%
78.19%
81.38%
83.27%
strategies to maximize the impact of the attack based on the target
user population under question.
effective success rate of the attack, for an adversary who does not
know (but can guess) the user’s behavior and their habits of using
the phone, can be calculated by multiplying the usage probabilities
we obtained from the survey by the success rates reported in our
correlation analysis of the attacks (Section 4).
Preliminaries: Let us call the success rate of the correlation-
based attack, as we presented in Table 1, as x (e.g., success rate
of a ringing attack for an attacker who knows the victim’s ring-
tone). Then, such attack would succeed with the probability p =
device×state×x, where device denotes the probability of owning
a speciﬁc type of device (e.g., Apple’s iPhone) and state denotes
the probability of the phone being in a particular state (e.g., default
ringtone at home). Note that the attacker can make multiple login
attempts at a given point of time to increase the chances of success.
In this case, for k iterations of login, the “Iterative success rate”
(termed Itt(k)), for a particular attack (with success rate x) can be
calculated as:
Itt(k) = 1 − (1 − x)k
(2)
The attacker repeats the above attack, with different attack vari-
ations, in multiple rounds. During each attack round i, the attacker
performs the attack with k iterations targeting the remaining un-
compromised users from round i − 1 (i.e., U Ni−1). Initially, no
users have been compromised (i.e., U N0 = 100%). Thus, the “Ef-
fective attack success rate” Ef fi(k), in round i with k iterations,
which represents the fraction of users the attacker has compromised
in round i, is given by:
Ef fi(k) = device × state × Itt(k) × U Ni−1
(3)
Note that device, state and Itt(k) do not depend on the at-
tack round per se, but rather they depend on the type of attack per-
formed, i.e., these values remain the same even when the order in
which the attack rounds are executed is changed. In contrast, Ef f
and U N depend upon the attack round.
A Concrete Sample Strategy: The attacker can devise a strategy
to compromise the maximum number of victims by choosing any
subset of the attack variations discussed in Section 3 and launch-
ing them in a particular order. In the rest of this section, we show
a sample attack strategy based on our online survey results (Sec-
tion 5) and a subset of our attacks (Table 1) in a speciﬁc order to
compromise about 83% of user accounts in a total period of less
than a day. Our attack strategy is summarized in Table 4. This is
only a sample strategy for demonstrating the overall effectiveness
of our attack. In practice, a real-world attacker can devise other
As in our Sound-Danger attack model, we start with the assump-
tion that the attacker has already obtained username, password,
phone number and timezone of each of the target users by compro-
mising a server and is trying to login to the victim user’s account
by: (1) entering the ﬁrst authentication factor (username and the
password), and (2) attacking the Sound-Proof application to prove
the possession of the second factor (the phone). We also assume
that the server throttles login attempt after three login trials to pre-
vent a login brute force attack (a common practice employed by
many web services). Therefore, we limit the attacker’s login at-
tempts to three, setting k = 3 in our attack strategy throughout.
We test our attack strategy against our implementation of Sound-
Proof with the threshold Tc = 0.1524.
We start with U N0 equal to 100.00% of the user accounts (no
account has yet been compromised). Since many of the users in
our survey indicated that they keep their phones in vibration mode
at work and this attack works irrespective of the device type, we
attack such users in the ﬁrst round. We know that 57.00% of
the users have their device in vibration mode at work (Table 3),
and the attack success rate x for the vibration attack is 85.42%
(Table 1). This yields the iterative attack success rate (Itt) in
this round to be 99.69%. Hence, the effective attack success
rate (Ef f1) for this attack is device × state × Itt × U N0 =
100.00% × 57.00% × 99.69% × 100.00% = 56.82%. This means
that we can compromise 56.82% of the users with the vibration
attack by just making three phone calls during work hours. The
calculations and success rates for this round of the attack are sum-
marized in Table 4, row 1. Compromising about 57% accounts in
just one round, for example, right after the password database was
leaked, would be a signiﬁcant threat. The attacker may stop here,
or continue to the next round to compromise more user accounts.
To attack the rest of the uncompromised users, U N1 = 43.18%,
after the ﬁrst round, we choose the next popular device and state
combination based on Table 3. Through our survey, we observed
that 39.00% of the users have iPhone. From Table 3, we know
that 16.00% of the users keep their device under default ringtone
at work. Therefore, in our strategy, the second attack round would
involve the default ringtone call for the “iPhone at work” users,
since we can have the maximum impact with this approach. From
Table 1, the attack success rate for default ringtone x is 81.80%,
which amounts to Itt equal to 99.40%. The effective attack suc-
cess rate (Ef f2) for this round of the attack is device × state ×
916Itt × U N1 = 39.00% × 50.00% × 16.00% × 43.18% = 2.68%.
Hence, after the second round of the attack, we have successfully
compromised 59.50% of the user population (56.82% in the ﬁrst
round plus 2.68% in the second round). This attack round is sum-
marized in Table 4, row 2. The attacker may continue for the
next few rounds in a similar fashion, as shown in Table 4.
In
case of alarm attack (round 7 and 8), the attacker needs to guess
when the alarm normally goes off at the victim’s end. Our user
survey reports that all of the users use alarm; however only 50%
of them use default alarm ringtone. Now, for a morning alarm,
we assume that users set their alarms at 5am, 6am, 7am, and
8am. For three attempts, the probability that the attacker plays
the alarm simultaneously with the victim’s alarm is 75% (3 out of
4). Hence, Ef f7 is calculated as device × state × x × U N6 =
39.00%×50.00%×100.00%×21.81%×75% = 3.19%. Similarly,
we calculate Ef f8 using the same alarm guessing probability. As
we can see, after the eighth round, our Sound-Danger system will
have compromised a total of over 83% of the user accounts.
Since we started the attack “at work”, and end it in the morning
time (with the alarm attack), it is fair to say that all the rounds
of the attacks will have ﬁnished over a period of less than a day.
A persistent attacker may continue further the next day, perhaps
trying other attacks at different points of time, and may gradually
compromise almost all user accounts in few days.
Finally, we re-calculated the success rate for the above attack
strategy against our implementation of Sound-Proof with threshold
values higher than Tc = 0.1524. We found that even when we in-
crease Tc, our attack strategy is still successful, by compromising
82.60% of the users with Tc = 0.18, and 81.52% with Tc = 0.2.
Hence, our attack strategy remains robust to increased thresholdiza-
tion, highlighting the overall vulnerability of Sound-Proof.
7. POTENTIAL MITIGATION
A natural defense against our attacks would be to disable the 2FA
system in the scenario when a call or a notiﬁcation is received (and
the corresponding sounds are played by the phone), or when an
alarm is triggered. Alternatively, the calls, notiﬁcations or alarms
could be disabled when the 2FA login takes place. This approach
is in line with the conﬁgurable feature of the iOS system to mute
the device when an app is recording, or block recording when the
device is playing sounds. However, such mitigation will prevent
the user from receiving calls/notiﬁcations or setting alarms while
logging into Sound-Proof enabled accounts, and could possibly de-
grade the usability of the phone system.
Another possible defense is to reduce the probability of guessing
the phone sounds. This defense relies on the user to prevent the at-
tack by picking ringtones that are difﬁcult for the attacker to predict
and possibly changing them frequently in order to stop the attacker
from attempting an exhaustive search. The analysis of the user sur-
vey in Section 5 shows that many users set the default ringtone for
the instant messaging applications (e.g., Skype or Facebook) that
makes it easier for an active attacker to predict the sound.
Similar to the custom ringtone, combination of sounds and/or
vibration is a possible defense mechanism. During our attack anal-
ysis, we noticed that the correlation reduces to below the thresh-
old value when the notiﬁcation sound is mixed with vibration and
the attacker plays only the notiﬁcation ringtone at its side. Simply
combining the ringtone and the vibration at the attacker’s side to
mimic the audio at the victim’s side does not work for the attacker
as we noticed that the vibration started at different point when the
ringtone starts playing at the victim’s phone. Hence, for a success-
ful attack, the combination should be precisely synced with the one
at the victim’s side (with the occurrence of vibration at the exact
position in the audio), which seems unlikely.
Our user survey shows that many users reuse their username over
multiple accounts. The security issues rising from reusing the pass-
word have been demonstrated previously (reuse of the password
helps the attacker, who compromises one service, to compromise
other accounts with the same password). In light of our attacks, the
reuse of the username raises a similar issue as that of the password
reuse. For example, an attacker who has compromised the web-
service and knows the username of the victim might successfully
perform the ringing attack on an application (e.g., Skype) with the
same username. Picking a different username for each account pre-
vents the attacker who has already compromised the server from
trying to launch our active attacks.
Any of the above defenses possibly introduce certain usability is-
sues. For example, users might prefer default notiﬁcation tone over
custom ringtone. Or reusing the username requires the user to re-
member multiple usernames associated with each account. Further
study is required to understand how these possible usability issues
may impact the user experience of the phone system while strength-
ening the security of Sound-Proof in the face of Sound-Danger.
8. DISCUSSION AND FUTURE WORK
Sound-Proof Demo Analysis: Karapanos et al. [17] have deployed
Sound-Proof demo app and released apps for Android4 and Apple5.
We set forth to analyze how the demo app (version 1.6 on Android)
performs against our attacks compared to our implementation of
Sound-Proof. We observed that the demo app uses higher value of
correlation threshold (Tc = 0.2) than the one reported in the paper
[17] (Tc = 0.13). As we only had access to the app binary (and not
source code), we could not directly ﬁgure out the values for other
parameters deployed in the demo app.
Our evaluation showed that FNR of the demo app (benign set-
ting) when the phone was kept beside the computer was quite high,
at 27.91%. When the phone was kept inside a bag/purse, FNR in-
creased to 50%. Compared to the results reported in [17], the higher
FNR might have been due to the use of higher value of correlation
threshold (and possibly other tighter parameters) than that reported
in the paper.
We then attacked the demo app with one active attack and one
passive attack. In the active attack trials, we made calls to the vic-
tim using WhatsApp.
In the passive attack trials, we tested the
demo app against alarm audio using two different devices (victim
uses Samsung Galaxy S5 while attacker uses LG G3). FPR for the
active attacks was found to be 38.46% while that for the passive
attacks was 64.71%. The attack success rate on the demo app is
less than that on our implementation of Sound-Proof. This may
again be due to the fact that the demo app uses higher value of
Tc (and possibly other stricter parameters). As shown in Table 1,
the success rate for different attacks against our implementation of
Sound-Proof decreased when T c was increased. Moreover, we no-
ticed that the average correlation provided by the demo app was
relatively high (e.g., the average correlation for the alarm clock is
0.29 with 0.16 as minimum correlation). Hence, if the demo app
had used the Tc reported in the paper [17] (Tc = 0.13), the alarm
attacks would have been 100.00% successful.
Furthermore, we analyzed for which parameters in our imple-
mentation of Sound-Proof will produce similar results to that by
Sound-Proof demo app. To this end, we recorded audio from two
devices simultaneously using both apps. We collected 30 audio
4https://play.google.com/store/apps/details?id=ch.soundproof
5https://itunes.apple.com/us/app/sound-proof/id1069858990
917instances and logged the correlation score from the demo app.
We calculated the correlation results for different length of audio
recorded (3s, 4s, 5s, and 6s) and for different threshold values
(0.1524, 0.18 and 0.2). We found that when we compared 6 sec-
ond long audio with Tc = 0.2, the scores from our app and the
demo app had the maximum correlation (we used the alternative
computation formula for Pearson’s r [18] to calculate the correla-