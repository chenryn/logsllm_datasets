4.4.1 Collecting the English Dataset
As a proof of concept, we focus on the category of porn-
related defacements without considering other types. Fol-
lowing the same data acquisition approach described in Sec-
tion 3.1.1, we ﬁrst collect a list of adult-content websites.
We then crawl their web pages and extract illicit keywords
from the titles. This is based on the observation that titles
of adult-content pages typically contain a large portion of
illicit keywords. By manually examining these candidates, we
ﬁnally collect 10,656 English illicit keywords related to adult
content.
To collect defaced pages, we develop two approaches as
follows:
d
• As discussed in Section 3.1.1, we query search engines
with illicit keywords and crawl returned web pages. After
manual checking of crawled pages, we collect 5,928 de-
faced pages among 22 websites. We refer to this dataset
as Dreal
.
• We carefully craft a list of defaced pages by following
defacers’ procedures. Speciﬁcally, we notice that defac-
ers typically utilize off-the-shelf tools [18] to generate
defaced pages based on a list of illicit keywords. Lever-
aging these tools, we generate two datasets with different
amounts of defacements. Each dataset includes 12,817
defaced pages. The ﬁrst one is the stealthy defacement
dataset (Dcra f tS
), where each page contains 3 to 7 illicit
keywords. The second one has more defacements with
more than 20 illicit keywords in each page, which we
refer to as Dcra f tL
d
.
d
The legitimate web pages are collected from top interna-
tional websites including education, news and government
d
d
d
websites. In total, we collect 31,946 web pages, which we
refer to as Dl. We use 80% of the defacement dataset (i.e.,
Dreal
) and Dl for training. We then use the
remaining 20% of defacement dataset and Dl for testing.
or Dcra f tL
, Dcra f tS
To facilitate further research and reproducibility, we have
released a subset of the English defacement dataset at [17],
which includes 500 real defaced web pages, over 25,000
crafted web pages with defacements, and over 1,400 illicit key-
words. Interestingly, during collection of real defaced pages,
we identiﬁed defacements in some well-known institutional
domains including nyu.edu, mit.edu and cuhk.edu.hk. We in-
cluded all of them in our real testing set, and the detection
accuracy is reported in the ﬁrst column in Table 5. Their snap-
shots are also available in our released dataset. Most of the
defacements in the affected websites had been removed by
their administrators over the course of our experiments.
4.4.2 Detecting Defaced English Web Pages
The training procedure is similar except for the following
differences:
• We do not notice the usage of obfuscated jargons in En-
glish defacements. If any, interested readers can directly
apply the language-speciﬁc jargon normalization algo-
rithms. Therefore, we only make Lemmatization with
NTLK to map words with similar meaning into one word
(e.g., better → good, doing → do).
• Similar to the Chinese scenario, we then train the HTML
classiﬁcation model (DMOS/DMOS_V2). Here we use
word2vec as the initial embedding.
The experiment results for the three datasets are shown
in Table 5. It shows our proposed tag-aware method can im-
prove the performance of HAN and BERT under the English
scenario as well. This demonstrates the applicability of our
approach to other languages.
A closer examination reveals that our approach brings
more improvements for the detection of stealthy defacements.
Speciﬁcally, the improvement over HAN is: 4.22% (stealthy
defacements) vs 1.18% (large defacements) in precision, and
1.51% (stealthy defacements) vs 0.12% (large defacements)
in recall. The improvement over BERT is: 3.88% (stealthy
defacements) vs 0.52% (large defacements) in precision, and
1.70% (stealthy defacements) vs 0.69% (large defacements)
in recall. These results are consistent with our previous ﬁnd-
ings on Chinese defacement detection.
USENIX Association
30th USENIX Security Symposium    3715
Figure 10: Relative Frequency of Infected HTML Tags. Du-
plicated tags in one web page are not counted to avoid bias.
Figure 11: Distribution of Jargon Occurrences
5 New Discoveries and Measurements
Based on the detection results of DMOS on Chinese dataset,
we have performed a measurement study to better understand
the preferences of website defacement techniques. This study
has led to a set of surprising ﬁndings and new insights.
5.1 Prevalence of Stealthy Defacements
Our study conﬁrms that most defacers tend to keep the de-
facements to a minimum. By counting the injected/altered
tags in each defaced web page, we ﬁnd that 26% of defaced
web pages are injected with only one tag. 70% of defaced
web pages contain fewer than 10 injected tags. Only 5% of
web pages contain more than 50 injected tags. This can ex-
plain why THAN outperforms the standard HAN model: it
focuses more on the suspicious tags while avoiding the noise
introduced by the majority of normal regions.
Analyzing the frequency distribution of HTML tags in de-
faced web pages, we ﬁnd that while 44 different tags are used
to inject illicit promotional text, marquee, a, title, meta are the
most preferred tags. Together, they comprise 67% of the data.
Figure 10 reports the corresponding statistics. The marquee
tag is widely used because it is convenient to visually hide
its content with the scrollamount and scrolldelay properties.
While some other styling techniques are also used for cloak-
ing, e.g., tiny font or white color, they have been known to
and detected by most search engines for a long time [35]. The
prevalence of the a tag is simply because hackers need to put
links to lead users or search engine crawlers to their promoted
websites. Lastly, title and meta tags are preferred as they have
higher priority when search engines index the web page.
Jargon Normalization Results
5.2
Our proposed Jargon Normalization Algorithm (JNA) has
achieved a high precision. To compute the precision, we man-
ually review the jargons identiﬁed by JNA in the ofﬂine test-
ing dataset. JNA identiﬁes 50,848 obfuscated jargons among
3,147 pages out of 20,958 defaced pages. We manually check
these jargons and do not ﬁnd false positives. For the 40,426
legitimate pages, JNA recognizes 7 obfuscated jargons across
4 pages. Particularly, 2 jargons are, in fact, typos within orig-
inal content. The other 5 jargons are false positives of JNA.
Notice that, even in the cases where JNA has made a mistake,
the corresponding pages can still be correctly classiﬁed by
DMOS.
Figure 11 shows the distribution of the number of jargons
found in defaced pages. Although most defaced pages contain
fewer than 50 obfuscated jargons, some pages surprisingly
include hundreds of them. Table 6 lists an example keyword
of MARK SIX (i.e., “六合彩”) as well as the frequency of
its Top-8 transformed jargons. The Equivalence in English
column explains the Chinese jargon obfuscation through sim-
ilar representations in English6. Usually, the initial keyword
is widely used by defacers, and the ones that evolved from it
also receive attention, albeit less than the initial one. Given
the large volume of obfuscated jargons, we need to revert the
jargons to their base forms so that THAN can understand
their semantics to enhance the correct classiﬁcation of de-
faced pages. As shown in Table 2, the jargon normalization
algorithm improves DMOS by 3.60% in precision and 0.51%
in recall.
5.3 Differences in Search Engines
Search engines have different policies regarding black hat
SEO. Leveraging this observation, defacers sometimes per-
form website defacements targeting some speciﬁc search
engines. As observed, a signiﬁcant portion of defaced web
pages that DMOS detected applies the cloaking techniques,
by checking the User-Agent and Referer header, to return
illicit content to certain search engine bots only. More illicit
content appearing in search results indicates weaker black hat
SEO tackling of the corresponding search engine.
To improve user experience, most modern search engines
display warnings next to defaced or malicious websites in
their search results so that users will not visit these poten-
tially dangerous websites. Figure 12 illustrates one example
6These English equivalent jargons are for illustration purpose only. They
have not been used by defacers in practice.
3716    30th USENIX Security Symposium
USENIX Association
Table 6: Top 8 Transformed Jargons Related to “MARK SIX”
No. Keywords
六合彩
1
六和彩
2
6和彩
3
六合采
4
六合财
5
六台彩
6
7
liuhecai
六盒彩
8
Equivalence in English
Frequency
MARK SIX
MARC SIX
MARK 6
MARK SYX
MARK SIKS
M4RK SIX
N.A.
MARCK SIX
620356
145759
48991
26509
4852
3378
3357
3181
Table 7: Search Result Warnings and Defaced Pages Statistics
Figure 13: Depth of Defaced Pages from Site Landing Page
Search Engines Defaced Pages With Warning Tips
baidu.com
m.baidu.com
so.com
m.so.com
sogou.com
m.sogou.com
4451
231
10300
8770
5499
3430
29.8%
31.1%
11.3%
7.7%
17.9%
21.4%
of such warning tips. The higher percentage of warnings in-
dicates that the search engine has more powerful mitigation
against black hat SEO. During defaced dataset collection for
ofﬂine testing (Section 3.1.1), one batch of data (22,939 web
pages over 2,563 domains) is collected simultaneously from
three major Chinese search engines: Baidu (baidu.com), 360
Search (so.com), and Sogou (sogou.com), together with their
mobile versions (m.baidu.com, m.so.com, and m.sogou.com).
By comparing the proportion of defaced web pages and the
number of search engine warnings, we can deduce which
search engine is preferred by defacers and has less effective
black hat SEO mitigation techniques. Table 7 presents our
ﬁndings. It shows that 360 Search is a preferred target for
defacers, as it has a signiﬁcantly higher portion of defaced
pages with the least warnings. Meanwhile, given a large num-
ber of defaced pages from mobile search results (especially
for 360 Search and Sogou), it seems the mobile versions of
search engines have already attracted defacers’ attention for
exploitation.
Figure 12: A Warning Generated by the Search Engine.
5.4 Hijacking of Expired DNS Domains
We have observed a recent trend of attackers abusing expired
DNS domains during our manual post-detection analysis, es-
pecially for those domains previously held by government
agencies. It is easy to understand the attackers’ motivation:
these privileged domains usually rank high in search engines.
After the domain expired, its ranking retains for some pe-
riod before search engines adjust it. Furthermore, it is easier
for defacers to take over the expired domains (e.g., by direct
purchase or exploiting vulnerabilities in outdated, no-longer-
maintained websites). Attackers can thus promote their illicit
content more effectively. An interesting note: at the beginning
of 2019, we observed a burst of abuse on expired domains
initially owned by the Chinese government. Upon further
investigations, we learned that the Central Ofﬁce of China
had issued a document requiring government organizations
to start using the .gov.cn domain in September 2018 [3]. As
a result, many government websites that were not under the
.gov.cn domain had to migrate to the new domains and thus
released the control of their previous domains.
5.5 Path Depth of Defaced Web Pages
We are interested in whether the web pages within a shallower
depth of a site are more likely to be defaced. Here, the depth
means the number of hops from the landing page to the de-
faced page, and zero-depth means the landing page itself. To
this end, we examine the defaced web pages discovered by
DMOS. Although we limit the depth of our crawler to be 12,
as presented in Figure 13, most defacements occur within 4
hops from the landing page, and the overall percentage for
page-depth greater than 8 is negligible. Knowing the depth
distribution of the defaced pages, we can reduce the depth of
our crawler without sacriﬁcing the recall of DMOS.
USENIX Association
30th USENIX Security Symposium    3717
6 Discussions
7 Related Work
Our research shows that DMOS offers a highly effective solu-
tion to the threat of promotional defacement. In this section,
we discuss its limitations and future research directions.
6.1 Robustness under Incomplete Keyword
List
It is difﬁcult, if not impossible, to collect a complete list of
illicit keywords. Fortunately, our approach has performed
effectively even under an incomplete illicit keyword list due
to the following reasons:
• Promotional defacements mainly aim at SEO. By lever-
aging the “related keyword” support by search engines,
our method can already harvest the majority of illicit
keywords used by defacements.
• Although the set of jargons is extensive, their original
forms are limited. For example, all the obfuscated jar-
gons listed in Table 6 are evolved from a single initial
jargon, i.e., Mark Six. Given the Jargon Normalization
algorithm, we can map unknown obfuscated jargons to
the limited set of original jargons.
• As shown in Section 5.1, adversaries can deface multi-
ple HTML tags in one page. Therefore, we may miss
multiple keywords/tags, but can still have a good chance
to catch others.
• THAN takes word embeddings as the input. Words can