11.50 ± 0.80
31.18 ± 0.57
P1/P2 Comp.
1.60 ± 0.59
5.85 ± 0.66
7.65 ± 0.89
21.09 ± 1.90
Table 2: Half-gates and hashing technique enabled;
times in milliseconds.
Circuit
AES-128
MD-5
SHA-1
SHA-256
P3 (KB) P1/P2 (KB)
1.19
2.05
2.78
6.11
752.37
1276.16
1732.75
3752.25
Table 3: Communication sizes for experiments of
Table 2.
gate technique has a major eﬀect on reducing the total run-
ning time as well the bandwidth of the protocol. The size
of communication increases by 50% which is expected since
garbled tabled sizes increase from 2 two 3.
Circuit
AES-128
% diﬀ
MD-5
% diﬀ
SHA-1
% diﬀ
SHA-256
% diﬀ
Network
17.80 ± 1.45
+34.57%
41.19 ± 2.20
+65.66%
51.74 ± 3.04
+64.90%
116.10 ± 4.00
+67.96%
P3 Comp.
3.10 ± 0.30
+34.78%
15.45 ± 0.80
+70.71%
19.85 ± 0.79
+72.61%
50.10 ± 1.22
+60.68%
P1/P2 Comp.
2.20 ± 0.41
+37.50%
12.93 ± 0.53
+121.02%
16.48 ± 1.13
+115.42%
44.40 ± 2.01
+110.53%
Table 4: Half-gates disabled; times in milliseconds.
Percentages show diﬀerence from Table 2.
Circuit
AES-128
% diﬀ
MD-5
% diﬀ
SHA-1
% diﬀ
1.77
+48.74%
3.05
+48.78%
4.16
+49.64%
SHA-256
9.17
% diﬀ
+50.08%
P3 (KB) P1/P2 (KB)
1104.74
+46.83%
1885.66
+47.76%
2561.82
+47.85%
5618.85
+49.75%
Table 5: Communication sizes for experiments of
Table 4. Percentages show diﬀerence from Table 2
Next, we turn the half-gate technique back on and turn-
oﬀ the hash technique and re-run the experiments. Results
are shown in Tables 6 and 7. Again, this reconﬁrms the
signiﬁcant eﬀect of the hashing technique on both the total
running time and the communication size. Note that the
computation times reduces when we turn oﬀ the hash tech-
nique which is natural since we avoid the extra hashing by
all parties. But given that serializing and sending/receiving
messages is the bottleneck, the net eﬀect of the hashing op-
timization is positive.
598Circuit
AES-128
% diﬀ
MD-5
% diﬀ
SHA-1
% diﬀ
SHA-256
% diﬀ
Network
20.89 ± 1.24
+27.39%
45.15 ± 0.97
+12.55%
57.50 ± 1.68
+14.03%
125.93 ± 2.35
+10.30%
P3 Comp.
1.30 ± 0.46
-43.48%
4.20 ± 0.40
-53.59%
5.50 ± 0.59
-52.17%
15.72 ± 0.75
-49.58%
-45%
P1/P2 Comp.
0.88 ± 0.40
3.35 ± 0.58
-42.74%
4.65 ± 0.70
-39.22%
12.90 ± 0.68
-38.83%
Table 6: Hash technique disable. times in millisec-
onds. Percentages show diﬀerence from Table 2
P3 (KB) P1/P2 (KB)
1447.58
+92.40%
2485.63
+94.77%
3380.84
+95.11%
7437.82
+98.22%
Circuit
AES-128
% diﬀ
MD-5
% diﬀ
SHA-1
% diﬀ
2.33
+95.80%
4.03
+96.59%
5.50
+97.84%
SHA-256
12.15
% diﬀ
+98.85%
Table 7: Communication size for experiments of Ta-
ble 6. Percentages show diﬀerence from Table 2
4.3 Comparison
3PC with one corruption.
As mentioned earlier, the most relevant protocols to ours
are those designed in the same setting of 3PC with one cor-
ruption, or honest majority in general. The MPC construc-
tions based on veriﬁable secret sharing [BOGW88, RBO89]
achieve the same security as our construction (malicious se-
curity), and are asymptotically very eﬃcient, as they require
O(poly(n)) bits of communication per multiplication gate
where n is number of parties, and the polynomial is rela-
tively small, and these protocols also avoid cryptographic
operations. However, to the best of our knowledge, no im-
plementation of these constructions exists, so it is hard to
provide a concrete comparison.
It is a very valuable di-
rection to explore practical eﬃciency of these constructions
even in the three-party setting, and compare their eﬃciency
and scalability with our construction in various scenarios.
The 3PC constructions with experimental results reported
include VIFF [Gei07], Sharemind [BLW08], PICCO [ZSB13],
ShareMonad [LDDAM12, LADM14], and [IKHC14]. With
the exception of [IKHC14], these protocols only provide se-
curity against semi-honest adversaries. In contrast, our pro-
tocol is secure against malicious adversaries in the same set-
ting, but demonstrates eﬃciency that is comparable to these
semi-honest counterparts.
Admittedly, an accurate/fair comparison is not possible,
given that each implementation runs in a diﬀerent envi-
ronment, using diﬀerent language/libraries and networking,
memory, and CPU speciﬁcations. For example, our ma-
chines’ memory/CPU speciﬁcations seems fairly modest com-
pared to the prior work and we do not take advantage of any
parallelism. But to demonstrate that eﬃciency of our con-
struction (for boolean circuits) is comparable to other im-
plemented constructions with only semi-honest security, a
single execution of an AES block requires 232 ms in Share-
mind [LTW13], 14.3 ms in ShareMonad [LDDAM12], and
18 ms in our implementation (See Table 2). The construc-
tion of [IKHC14] which achieves malicious security (similar
to ours) did not include an implementation of any boolean
circuits circuit but based on the provided experimental num-
bers, their construction requires a factor of k (the security
parameter) more communication and a factor of 3 more com-
putation compared to secret-sharing-based semi-honest 3PC
implementations.
Protocols with Dishonest Majority.
The bulk of other existing implementations with mali-
cious security are focused on the dishonest majority set-
ting. For example, there is large body of work on mak-
ing Yao’s two-party protocol secure against malicious adver-
saries with several implementations available [LPS08, KS12,
FN13, AMPR14]. When considering a single execution,
these protocols are at least a multiplicative factor of secu-
rity parameter (80) more expensive than semi-honest Yao’s
protocol. But as seen earlier, our protocol has complexity
that is fairly comparable to a single run of semi-honest and
hence outperforms single-execution malicious 2PC protocols
by a wide margin.
Note that when running many instances of malicious 2PC
for the same function, there are recent results [LR14, HKK+14]
that noticeably reduce the amortized multiplicative factor.
In general, our comparisons are only for a single execution
of the constructions. It is interesting to compare eﬃciency
of the existing implementations in batch execution of the
same of diﬀerent setting, and to introduce new techniques
for better batch 3PC.
We also emphasize that the above comparison is only
fair for Boolean circuits, as secret-sharing-based protocols
are often superior to garbled-circuit based ones for arith-
metic circuits given that they directly implement multipli-
cation/addition gates.
Another line of work [DKL+12, DKL+13] consider multi-
party computation with dishonest majority in the pre-processing
model where the goal is to implement a very fast online phase
after a relatively expensive pre-prceossing stage for generat-
ing authenticated triplets. Similar to malicious 2PC, the
total cost (oﬄine + online) of these protocols signiﬁcantly
higher than ours (several seconds), but a direct comparison
is not warranted give the diﬀerence in security guarantees
and their focus on a fast online phase. We discuss this line of
work again when considering the credential encryption ser-
vice application where online/oﬄine separation is natural.
5. APPLICATION: DISTRIBUTED CREDEN-
TIAL ENCRYPTION SERVICE
An interesting application of our work and an initial mo-
tivation for it was the design of a distributed credential en-
cryption service. The goal of this service is to keep creden-
tials such as hashed passwords encrypted at rest, in order
to prevent oﬄine dictionary attacks when user databases are
compromised. At the same time, the service should be easily
retroﬁtted into existing authentication systems, in which an
authentication server computes or receives a hashed pass-
word in the clear. Hence, the goal is not to use crypto to
protect the computation of a hashed password, but to simply
protect the static database of hashed passwords.
599A (non-distributed) credential encryption service receives
a hashed password from the authentication server as input,
which it encrypts to return a ciphertext that is stored in a
database. To authenticate a user, the authentication server
sends to the encryption service the hash of the purported
password along with the correct ciphertext obtained from
the database. The encryption service authenticates the user
by decrypting the ciphertext and checking whether the re-
sult matches the hashed password that is given. Overall,
the encryption service stores a secret encryption key and
provides encryption/decryption functionality. The authen-
tication server’s database remains encrypted; authenticating
a user requires interaction with the encryption service and
hence cannot be done oﬄine in a dictionary attack in the
event that the authentication database is compromised.
In order to distribute trust and avoid a single point of at-
tack we replace the encryption service by three servers run-
ning our 3PC protocol. P1 and P2 each hold a 128-bit ran-
dom strings K1 and K2, while P3 receives h(passwd) from a
log-in service to encrypt using the key K = K1 ⊕ K2, i.e. to
compute AESK (h(passwd)). Our 3PC construction guar-
antees that even if the encrypted database is compromised,
and one of the servers is compromised and even controlled
by the adversary, the encryption key is not compromised
and user credentials are not susceptible to oﬄine dictionary
attacks.
Note that unlike the general 3PC scenario, in the creden-
tial encryption service we can consider further optimizations.
For example, since the computation involves the same circuit
(e.g., AES) each time, we can in an oﬄine phase (i.e. in the
background or through a diﬀerent channel without a latency
restriction) have P1 and P2 garble many circuits separately
using randomness they agree on and transmit them to P3.
Furthermore, given that P1, P2’s inputs remain the same
across multiple executions, they can also incorporate their
garbled inputs to those circuits. A subtle issue is that for
this approach to work, we have to assume that the garbling
scheme is adaptively secure [BHR12a], a stronger assump-
tion than we need for our main protocol.
The online phase then consists of P3 obtaining the la-
bels for his input h(passwd), taking a pair of garbled cir-
cuits/commitments that are the same from a pile computed
earlier and evaluating it. Our experiments show that the on-
line running time of the protocol is on average 1.34 ± 0.47
ms, making the protocol feasible for real-world deployment.
The SPDZ protocols and followup works [DKL+12, DKL+13],
also focus on optimizing the online case at the cost of the of-
ﬂine phase, and achieve fast online performance in the order
of milliseconds for AES circuit (though higher than ours),
but have a much slower oﬄine phase compared to us. Given
than the oﬄine phase is not reusable in either ours or SPDZ
construction and has to repeated on a regular basis, our
protocol seems more suitable for this application given the
faster oﬄine phase. On the other hand, the SPDZ protocols