word embeddings,” in NIPS, 2016.
[15] I. Chalkidis, M. Fergadiotis, P. Malakasiotis, and I. Androutsopoulos,
“Large-scale multi-label text classiﬁcation on eu legislation,” in ACL,
2019.
[16] Z. Dai, Z. Yang, Y. Yang, J. G. Carbonell, Q. V. Le, and R. Salakhutdi-
nov, “Transformer-xl: Attentive language models beyond a ﬁxed-length
context,” in ACL, 2019.
[17] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of
deep bidirectional transformers for language understanding,” in NAACL-
HLT, 2018.
[18] A. Dosovitskiy and T. Brox, “Inverting visual representations with
convolutional networks,” CVPR, pp. 4829–4837, 2016.
[19] V. Duddu, D. Samanta, D. V. Rao, and V. E. Balas, “Stealing neural
networks via timing side channels,” ArXiv, vol. abs/1812.11720, 2018.
[20] C. Dwork and A. Roth, “The algorithmic foundations of differential
privacy,” Foundations and Trends in Theoretical Computer Science,
vol. 9, pp. 211–407, 2014.
[21] M. Fredrikson, S. Jha, and T. Ristenpart, “Model inversion attacks that
exploit conﬁdence information and basic countermeasures,” in CCS,
2015.
[22] M. Fredrikson, E. Lantz, S. Jha, S. Lin, D. Page, and T. Ristenpart,
“Privacy in pharmacogenetics: An end-to-end case study of personalized
warfarin dosing,” vol. 2014, pp. 17–32, 2014.
[23] K. Ganju, Q. Wang, W. Yang, C. A. Gunter, and N. Borisov, “Property
inference attacks on fully connected neural networks using permutation
invariant representations,” in CCS, 2018.
[24] R. Gilad-Bachrach, N. Dowlin, K. Laine, K. E. Lauter, M. Naehrig, and
J. R. Wernsing, “Cryptonets: Applying neural networks to encrypted
data with high throughput and accuracy,” in ICML, 2016.
[25] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. MIT Press,
2016, http://www.deeplearningbook.org.
[26] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
S. Ozair, A. C. Courville, and Y. Bengio, “Generative adversarial nets,”
in NIPS, 2014.
[27] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing
adversarial examples,” ArXiv, vol. abs/1412.6572, 2014.
[28] W. Guo, J. Shao, R. Lu, Y. Liu, and A. A. Ghorbani, “A privacy-
preserving online medical prediagnosis scheme for cloud environment,”
IEEE Access, vol. 6, pp. 48 946–48 957, 2018.
[29] M. Hardt, E. Price, and N. Srebro, “Equality of opportunity in supervised
learning,” in NIPS, 2016.
[30] M. Humbert, E. Ayday, J.-P. Hubaux, and A. Telenti, “Addressing the
concerns of the lacks family: quantiﬁcation of kin genomic privacy,” in
CCS, 2013.
[31] ——, “Quantifying interdependent risks in genomic privacy,” ACM
Trans. Priv. Secur., vol. 20, pp. 3:1–3:31, 2017.
[32] S. Ioffe and C. Szegedy, “Batch normalization: Accelerating deep
network training by reducing internal covariate shift,” ArXiv, vol.
abs/1502.03167, 2015.
[33] N. Japkowicz and S. Stephen, “The class imbalance problem: A system-
atic study,” Intell. Data Anal., vol. 6, pp. 429–449, 2002.
[34] Y. Ji, X. Zhang, S. Ji, X. Luo, and T. Wang, “Model-reuse attacks on
deep learning systems,” in CCS, 2018.
[35] J. Jia and N. Z. Gong, “Attriguard: A practical defense against at-
tribute inference attacks via adversarial machine learning,” ArXiv, vol.
abs/1805.04810, 2018.
[36] A. Jochems, T. Deist, I. E. Naqa, M. L. Kessler, C. Mayo, J. Reeves,
S. Jolly, M. Matuszak, R. T. Haken, J. van Soest, C. J. G. Oberije,
C. Faivre-Finn, G. J. Price, D. K. M. D. Ruysscher, P. Lambin, and
A. Dekker, “Developing and validating a survival prediction model
for nsclc patients through distributed learning across 3 countries,” in
International journal of radiation oncology, biology, physics, 2017.
[37] A. Jochems, T. Deist, J. van Soest, M. J. Eble, P. Bulens, P. A. Coucke,
W. J. F. Dries, P. Lambin, and A. Dekker, “Distributed learning: Devel-
oping a predictive model based on data from multiple hospitals without
data leaving the hospital - a real life proof of concept.” Radiotherapy and
oncology : journal of the European Society for Therapeutic Radiology
and Oncology, vol. 121 3, pp. 459–467, 2016.
[38] D. Jurafsky, “Speech and language processing,” 2006.
[39] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
ArXiv, vol. abs/1412.6980, 2014.
[40] R. Kiros, Y. Zhu, R. Salakhutdinov, R. S. Zemel, R. Urtasun, A. Torralba,
and S. Fidler, “Skip-thought vectors,” in NIPS, 2015.
[41] G. Lample and A. Conneau, “Cross-lingual language model pretraining,”
ArXiv, vol. abs/1901.07291, 2019.
[42] Q. V. Le and T. Mikolov, “Distributed representations of sentences and
documents,” ArXiv, vol. abs/1405.4053, 2014.
[43] B. Lee, T. Lee, B. Na, and S. Yoon, “Dna-level splice junction prediction
using deep recurrent neural networks,” ArXiv, vol. abs/1512.05135,
2015.
[44] Y. Liu, M. Ott, N. Goyal, J. Du, M. S. Joshi, D. Chen, O. Levy, M. Lewis,
L. S. Zettlemoyer, and V. Stoyanov, “Roberta: A robustly optimized bert
pretraining approach,” ArXiv, vol. abs/1907.11692, 2019.
[45] F. MASTEROPPGAVE and Ø. Johansen, “Gene splice site prediction
using artiﬁcial neural networks,” 2008.
[46] H. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efﬁcient learning of deep networks from decentralized
data,” in AISTATS, 2016.
[47] L. Melis, C. Song, E. D. Cristofaro, and V. Shmatikov, “Exploiting
unintended feature leakage in collaborative learning,” in Security &
Privacy, 2019.
[48] E. M. E. Mhamdi, R. Guerraoui, and S. Rouault, “The hidden vulnera-
bility of distributed learning in byzantium,” in ICML, 2018.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:19:28 UTC from IEEE Xplore.  Restrictions apply. 
1327
[49] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,
“Distributed representations of words and phrases and their composi-
tionality,” in NIPS, 2013.
[50] M. Nasr, R. Shokri, and A. Houmansadr, “Machine learning with
membership privacy using adversarial regularization,” in CCS, 2018.
[51] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin,
A. Desmaison, L. Antiga, and A. Lerer, “Automatic differentiation in
pytorch,” 2017.
[52] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and
L. S. Zettlemoyer, “Deep contextualized word representations,” ArXiv,
vol. abs/1802.05365, 2018.
[53] P. Pollastro and S. Rampone, “Hs3d: Homo sapiens splice site data set,”
[54] A. Radford, “Improving language understanding by generative pre-
2002.
training,” 2018.
[55] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever,
“Language models are unsupervised multitask learners,” 2019.
[56] H. E. Robbins, “A stochastic approximation method,” 2007.
[57] S. Salamatian, A. Zhang, F. du Pin Calmon, S. Bhamidipati, N. Fawaz,
B. Kveton, P. Oliveira, and N. Taft, “Managing your private and public
data: Bringing down inference attacks against your privacy,” IEEE
Journal of Selected Topics in Signal Processing, vol. 9, pp. 1240–1255,
2015.
[58] A. Salem, A. Bhattacharyya, M. Backes, M. Fritz, and Y. Zhang,
“Updates-leak: Data set inference and reconstruction attacks in online
learning,” ArXiv, vol. abs/1904.01067, 2019.
[59] A. Salem, Y. Zhang, M. Humbert, P. Berrang, M. Fritz, and M. Backes,
“Ml-leaks: Model and data independent membership inference attacks
and defenses on machine learning models,” ArXiv, vol. abs/1806.01246,
2018.
[60] G. Salton and C. Buckley, “Term-weighting approaches in automatic
text retrieval,” Inf. Process. Manage., vol. 24, pp. 513–523, 1988.
[61] G. Shen, K. Dwivedi, K. Majima, T. Horikawa, and Y. Kamitani, “End-
to-end deep image reconstruction from human brain activity,” in Front.
Comput. Neurosci., 2019.
[62] R. Shetty, B. Schiele, and M. Fritz, “A4nt: Author attribute anonymity by
adversarial training of neural machine translation,” in USENIX Security
Symposium, 2017.
[63] R. Shokri, M. Stronati, C. Song, and V. Shmatikov, “Membership
inference attacks against machine learning models,” Security & Privacy,
pp. 3–18, 2017.
[64] R. Shokri, G. Theodorakopoulos, J.-Y. L. Boudec, and J.-P. Hubaux,
“Quantifying location privacy,” Security & Privacy, pp. 247–262, 2011.
[65] S. S. Shringarpure and C. D. Bustamante, “Privacy risks from genomic
data-sharing beacons.” American journal of human genetics, vol. 97 5,
pp. 631–46, 2015.
[66] L. Song, R. Shokri, and P. Mittal, “Privacy risks of securing ma-
chine learning models against adversarial examples,” ArXiv, vol.
abs/1905.10291, 2019.
[67] Y. Sun, S. Wang, Y. Li, S. Feng, H. Tian, H. Wu, and H. Wang, “Ernie
2.0: A continual pre-training framework for language understanding,”
ArXiv, vol. abs/1907.12412, 2019.
[68] I. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to sequence learning
with neural networks,” in NIPS, 2014.
[69] D. Tang, Y. Zhao, and T. Liu, “Document modeling with gated recurrent
neural network for sentiment classiﬁcation,” in EMNLP, 2015.
[70] F. Tram`er, F. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart,
“Stealing machine learning models via prediction apis,” ArXiv, vol.
abs/1609.02943, 2016.
[71] V. N. Vapnik, “The nature of statistical learning theory,” in Statistics for
Engineering and Information Science, 1995.
[72] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
L. Kaiser, and I. Polosukhin, “Attention is all you need,” pp. 5998–6008,
2017.
[73] B. Wang and N. Z. Gong, “Stealing hyperparameters in machine
learning,” Security & Privacy, pp. 36–52, 2018.
[74] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi,
P. Cistac, T. Rault, R. Louf, M. Funtowicz, and J. Brew, “Huggingface’s
transformers: State-of-the-art natural language processing,” ArXiv, vol.
abs/1910.03771, 2019.
[75] Y. Wu and M. S. et al., “Google’s neural machine translation system:
Bridging the gap between human and machine translation,” ArXiv, vol.
abs/1609.08144, 2016.
[76] Z. Yang, Z. Dai, Y. Yang, J. G. Carbonell, R. Salakhutdinov, and
Q. V. Le, “Xlnet: Generalized autoregressive pretraining for language
understanding,” ArXiv, vol. abs/1906.08237, 2019.
[77] Z. Yang, J. Zhang, E.-C. Chang, and Z. Liang, “Neural network inversion
in adversarial setting via background knowledge alignment,” in CCS,
2019.
[78] S. Yeom, I. Giacomelli, M. Fredrikson, and S. Jha, “Privacy risk in
machine learning: Analyzing the connection to overﬁtting,” CSF, pp.
268–282, 2017.
[79] L. Yu, W. Zhang, J. Wang, and Y. Yu, “Seqgan: Sequence generative
adversarial nets with policy gradient,” ArXiv, vol. abs/1609.05473, 2016.
[80] Y. Zhang, M. Humbert, T. A. Rahman, C.-T. Li, J. Pang, and M. Backes,
“Tagvisor: A privacy advisor for sharing hashtags,” WWW, 2018.
[81] Y. Zhang, X. Liu, J. N. MacLeod, and J. Liu, “Discerning novel splice
junctions derived from rna-seq alignment: a deep learning approach,” in
BMC Genomics, 2018.
[82] L. Zhu, Z. Liu, and S. Han, “Deep leakage from gradients,” in NeurIPS,
2019.
APPENDIX
A. Implementation of Utility Models
Fig. 8. Utility of benchmark systems on (a) Genome and (b) Medical.
1) Genome: We implemented eight genome classiﬁcation
systems for splice site prediction based on a public genome
dataset called HS3D (Homo Sapiens Splice Sites Dataset) 2.
Roughly speaking, splice site prediction is a binary classiﬁca-
tion task in computational genetics which determines whether
the target nucleotide sequence contains certain functional unit.
To build the benchmark systems, we ﬁrst prepared a dataset
from HS3D that consists 28800 (2880) negative (positive)
samples for training and 1000 (1000) samples for testing.
All the genome sequences are of length 20. Each system
is composed with a pretrained language model for feature
extraction and a three-layer MLP of 200 hidden units with
sigmoid activation for classiﬁcation. Fig. 8(a) reports the utility
(in accuracy) of our benchmark system when incorporating
different language models, where the non-trivial margin over
the random guess demonstrates their effectiveness.
2) Medical: We implemented eight pre-diagnosis systems
based on the CMS public healthcare records 3. These sys-
tems are designed to guide patients to the proper department
according to the textual description of their decease. The pre-
processed dataset contains 120, 000 decease descriptions from
10 medical departments (e.g., Orthopedic Surgery, Anesthesi-
ology, Dermatology and so on). We model the pre-diagnosis
task as 10-class classiﬁcation, and implemented the systems as
a combination of the pretrained language models for feature
extraction and a three-layer MLP of 200 hidden units with
sigmoid activation for classiﬁcation. First, the classiﬁcation
2http://www.sci.unisannio.it/docenti/rampone/
3https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-
Trends-and-Reports/Medicare-Provider-Charge-Data/Physician-and-Other-
Supplier2016.html
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:19:28 UTC from IEEE Xplore.  Restrictions apply. 
1328
accuracy in Fig. 8(b) highly demonstrates the utility of our
benchmark systems.
B. Implementation Details of Attack Model on Genome
In practice, we ﬁnd training an attack model targeted on
the i-th nucleotide is ineffective if we only use the pairs
of embeddings and the corresponding nucleotide types. We
speculate it is probably because the training sample itself
contains insufﬁcient
information. Consider the example of
sequence ACGT AACT and the attacker targeted at the fourth
nucleotide. If we only supply the learning model with its
embedding and the type T , the attack model has actually
no idea of whether the learning objective is to infer the T
at
the tail. To solve this
problem, we propose to augment the training pair (z, wi) with
auxiliary information regarding the target position, in the form
of positional for the target position i.
the target position, or the T at
Basically, we concatenate the embedding z of the generated
sample with the positional embedding pi for position i. For-
mally, we use the sinusoidal positional embedding as in [72],
which is deﬁned by pi,2k = sin (i/100002k/dpos), pi,2k+1 =
cos (i/10000(2k+1)/dpos), where pi,2k denotes the 2k-th coor-
dinate of pi and dpos is its dimension. In our implementation,
we set dpos equal to the dimension of z. Corresponding to
this modiﬁcation, we implement one single attack model
for inferring the nucleotide type at any speciﬁed position.
Different from the Citizen case, this modiﬁcation will not
increase the parameter number as the class number is still 4.
The attack model is implemented as a three-layer MLP which
takes input z ⊕ pi of dimension 2d and has 200 hidden units
with sigmoid activation and intermediate batch normalization
layers [32] for faster convergence. For training, we generate
mini-batches of size 128 that consist of tuples (z, pi, wi),
where the positional embedding i is randomly sampled from
the interval of possible positions (i.e. 1, . . . , 20). For inference,
the attacker inputs the victim’s embedding and the targeted
position and the model outputs the predicted nucleotide type.
C. Omitted Details on Defenses
Laplace Mechanism. For the second defense, we leverage
a differential privacy approach for mitigation. Speciﬁcally,
we apply the Laplace mechanism introduced in [20] to pro-
tect the original embedding from privacy breaching. Roughly
speaking,
the Laplace mechanism perturbs the embedding
coordinate-wise with samples from a Laplace distribution
whose parameters are determined by the (cid:2)1-sensitivity of the
language models (denoted as f). Formally, we propose the DP-
based defense as ˆz = Dlap,f,(z) .= z+(Y1, . . . , Yd) , where Yi
are i.i.d. random samples drawn from Lap(Δf /), the Laplace
distribution with location 0 and scale Δf /. Here Δf denotes
the (cid:2)1-sensitivity of the language model, which is deﬁned
)(cid:10)1 where
as Δf = max
(cid:2)
, x are sentences that are different only in one position.
x
Intuitively, the Laplace mechanism makes it harder for the
adversary to distinguish from the embeddings the difference
caused by alteration of one word, which thus defends both
(cid:2)(cid:3)1=1 (cid:10)f (x) − f (x
(cid:2)∈N|V|,(cid:3)x−x
x,x
(cid:2)
the pattern reconstruction attack and keyword inference attack
in a straightforward way. In theory, it can be proved that
the language model with protection, i.e. Dlap,f, ◦ f is (, 0)-
differential private. In practice, we estimate the (cid:2)1-sensitivity
(cid:2)
)
of each language model by generating 10, 000 pairs of (x, x
by word substitution, querying the language models and cal-
culating Δf according to the deﬁnition. The numeric value
is provided in Table IV. However, there still exists many
theoretical challenges in bounding the errors of the estimated
L1 sensitivity, which will be a meaningful direction to pursue
in the future.
ESTIMATED (cid:2)1-SENSITIVITY OF EACH LANGUAGE MODEL & TIME COST
FOR QUERYING ONE TRAINING BATCH
TABLE IV
Name
Bert
Transformer-XL
XLNet
GPT
GPT-2
RoBERTa
XLM
Ernie 2.0
Estimated Δf
Query Time (sec.)
81.82
17.09
601.5
73.19
110.2
4.15
219.4
28.20
0.577