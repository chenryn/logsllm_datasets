ϵ (cid:17) instead of Lap (cid:16) 6
ϵ(cid:17) to each cell. Note
that even if any set of 3 attributes is covered, answering 4-way
marginals will still have Reconstruction Errors.
Analysis in [29] shows that the choice of optimal ℓ (size of each
marginal) is independent from parameters such as dataset size n,
privacy parameter ϵ, and dimensionality d. In particular, setting
ℓ to be around 8 works well. The optimal choice of m (number
of marginals), however, depends on n, ϵ, d, and the nature of the
average of these estimates are therefore
NE(n, d, ϵ, ℓ) =
Var1
m ·ℓ
= min (cid:18)
= min (cid:18)
4eϵ
(eϵ − 1)2
4eϵ
(eϵ − 1)2
,
,
d
L − 2 + eϵ
(eϵ − 1)2 (cid:19) ·
(eϵ − 1)2 (cid:19) ·
L − 2 + eϵ
m
n
L
ℓ
· L ·
d
m · ℓ
·
d
n
(7)
The key observation here is that the magnitude of Noise Errors
does not depend on m, which is different from PriView. It does
depend on ℓ and ϵ, where ϵ affects the first term, which is the
variance of the FO protocol. The parameter ℓ affects both the term
L
ℓ and the variance for the FO protocol.
Also note that when we estimate k-way marginals based on the
estimation of marginals of the k attributes, the estimation is affected
by the errors for each of the k attributes, we thus use k ·NE(n, d, ϵ, ℓ)
as the Noise Errors when we optimize for a particular k value.
Reconstruction Errors. Reconstruction Errors occur when a k-
way marginal is not covered by any of the chosen marginal. The
magnitude of Reconstruction Errors depends on to what extent
attributes are correlated. If all attributes are mutually independent,
then Reconstruction Errors do not exist. When attributes are de-
pendent, the general trend is that larger m and larger ℓ will cover
more combination of attributes, reducing reconstruction errors. The
reduction effect of Reconstruction Errors diminishes as m increases.
For example, if all k-ways marginals are already fully covered, Re-
construction Errors are already 0 and cannot be further decreased.
Even if not all k-ways marginals are fully covered, increasing m
beyond some reasonably large number will only cause diminishing
return. Since Reconstruction Errors are dataset dependent, there is
no formula for estimating them.
Sampling Errors. Sampling Errors occur when a marginal in a
group of users deviates from the marginal in the whole population.
The parameter ℓ has no impact on Sampling Errors. However, in-
creasing m would cause each group size n
m to be smaller, raising
Sampling Errors. When computing a marginal from a group of
s = n/m users, each cell in the marginal can be viewed as the sum
of s independent Bernoulli random variables, divided by s. In other
words, each cell is a binomial random variable divided by s. Thus
each cell has variance MA(v )(1−MA(v ))
, where MA(v) is the fraction
of users with value v in the whole population. The Sampling Errors
for an ℓ-way marginal A are thus
s
MA(v)(1 − MA(v))
s
=
m ×c ∈VA MA(v)(1 − MA(v))
n
v ∈VA
Since v ∈VA MA(v) = 1, we have v ∈VA MA(v)(1 − MA(v))  k and CoverDesign(d, k, ℓb − 1) ≤ mu do
Decrement ℓb ← ℓb − 1
if ℓb == ℓu then
return min(mu , (cid:0) d
ℓu(cid:1)), ℓu
Assign E ← 1, m ← mu , ℓ ← ℓu
for ℓt in [ℓb , ℓu ] do
Assign mt ← CoverDesign(d, k, ℓt )
if max(SE(n, mt ), k · NE(n, d, ϵ, ℓt )) < E then
Update E ← max(SE(n, mt ), k · NE(n, d, ϵ, ℓt ))
Update m ← mt , ℓ ← ℓt
return m, ℓ
Algorithm 1 gives the pesudocode for determining m and ℓ. The
algorithm uses the formula to calculate Noise Errors NE from (7),
and Sampling Errors SE as in (8). CoverDesign is an external pro-
cedure to calculate the number of ℓ-way marginals that can fully
include all k-way marginals. Note that NE is for a single attribute;
one can multiply NE by k to approximate the Noise Errors for the
k-way marginals.
For example, Figure 3 gives the Noise Errors times k (i.e., k · NE)
for n = 216, d = 8, and k = 3 when ϵ ranges from 0.2 to 2.0. If
we fix θ = 10−3, we can read from the figure that when ϵ ≤ 1.4,
only ℓ = 2 can be used. Because larger ℓ will make NE even larger;
and we choose to allow some RE to exist. When ϵ is larger, e.g.,
5.1 Experimental Setup
Our experimental setup is largely influenced by that in [11], which
introduced the Fourier Transformation method and ran extensive
comparisons of several methods for this problem.
Environment. All algorithms are implemented in Python 3.5 and
all the experiments are conducted on a PC with Intel Core i7-4790
3.60GHz and 16GB memory.
Datasets. We run experiments on the following four datasets.
• POS [43]: A dataset containing merchant transactions of half
a million users.
• Kosarak [2]: A dataset of click streams on a Hungarian web-
site that contains around one million users.
• Adult [4]: A dataset from the UCI machine learning repos-
itory. After removing missing values, the dataset contains
around 50 thousands records. The numerical attributes are
bucketized into categorical attributes.
• US [32]: A dataset from the Integrated Public Use Microdata
Series (IPUMS). It has around 40k records of the United States
census in 2010.
The first two are transactional datasets where each record con-
tains some items. We treat each item as a binary attribute. Thus
these two datasets are binary. When running experiments with k
binary attributes, we pre-process a dataset to include only the top
d most frequent items. The later two are non-binary datasets, i.e.,
each attribute contains more than two categories.
Evaluation Methodology. To evaluate the performance of dif-
ferent methods, the Sum of Squared Error (SSE) of the marginals
is reported. That is, we compute the ground truth and calculate
the sum of squared difference in each cell. For each dataset and
each method, we choose 50 random k-way marginal queries and
measure their SSE. This procedure is repeated 20 times, with result
mean and standard deviation reported.
Competitors. The FC, AM, and EM methods can be directly ap-
plied. For a fair comparison, the FO used in those methods are also
chosen adaptively.
The FT method is unable to deal with the non-binary attributes.
Therefore, we implement the non-binary version of FT by encoding
each non-binary attribute into several binary attributes.
As a baseline comparison, we also plot the SSE of the Uniform
method (Uni in the figures), which always returns a uniform dis-
tribution for any marginal tables. Clearly, if the performance of
one method is worse than the Uniform method, the marginal con-
structed from that method is meaningless.
Experimental Settings. Different methods scale differently with
respect to d, the number of attributes, and k, the size of marginals.
Also, the error depends on n, the size of the dataset. We use three
values of d: 8, 16, and 32. We consider k = 3 for all three settings
of d. We consider k = 6 only for d ∈ {16, 32}, and k = 8 only for
d = 32. This is because a larger k value makes more sense with a
larger d value.
We consider two dataset sizes n = 216 and n = 218, which were
used in [11]. Since all methods benefit similarly when n increases,
the comparison results remain valid for other n sizes.
The settings for m and ℓ are given in Table 2 in the appendix.
5.2 SSE on Binary Datasets
Figure 4 illustrates the results for comparing CALM against existing
methods we discussed in Section 3 on two binary datasets Kosarak
and POS.
In all settings, CALM significantly outperforms all existing algo-
rithms, and the advantage of CALM increases for larger d and larger
k values, and for smaller ϵ values. For most settings, the difference
between CALM and FT, the closest competitor, is between one and
two orders of magnitude. When ϵ is small, e.g., when ϵ = 0.2, all
existing algorithms perform close to the Uniform baseline, meaning
they can provide very little information when the privacy budget is
small. Whereas CALM can still provide enough information even
for very small ϵ. Furthermore, many methods simply do not scale
to the case of d = 32.
EM performs poorly, in fact it is often worse than the Uniform
baseline. This is because EM requires each user to report informa-
tion on all d attributes, in order to perform inference. This means
dividing the privacy budget by d, which results in large pertur-
bation. The other methods can split the population into groups,
instead of splitting privacy budget, thus performing better. Also,
when k is larger than 5, the computation time for EM method is
too long to run efficiently (about 20 minutes each query). We thus
do not plot EM for the k = 6, 8 cases.
Among the competitors, FT performs the best. When d = 8, k = 3,
we can compute the variance for FC, AM and FT using Formulas (4),
(5), and (6). The results are 256 · Var0 for FC, 448 · Var0 for AM,
and 93 · Var0 for FT. From Figures 4a and 4g, we can see that the
experimental results match the analytical comparison.
For d = 16, CALM’s performance is similar to the case of d =
8. Other methods, however, have significantly larger error. For
example, in Figure 4b, when ϵ = 0.2, the squared error of CALM is
0.0055, which is 41 times better than the state-of-the-art method,
i.e., FT with squared error of 0.2266.
The performance of FC does not depends on k, since it constructs
a full contingency table.
When d = 32, most of the existing methods are unable to scale,
especially when k = 8. For the AM method, the number of possible
marginals are (cid:0)32
8(cid:1) = 10518300. As a result, the average number
of users that contribute information to each marginal is less than
one when we choose n = 216 and 218. Similarly, the number of
Fourier coefficients required to reconstruct 8-way marginals are
s =1 (cid:0)32
8
s (cid:1) = 15033173, resulting less than one user contributes to
each coefficient.
5.3 SSE on Non-binary Datasets
The experimental results for non-binary datasets, i.e., Adult and
US, are shown in Figure 5. To reduce computational complexity, we
pre-process all attributes to contain at most 3 categories.
The experimental results show the superiority of CALM, which
achieves around 1 to 2 orders magnitude of improvement over
existing methods.
By comparing the d = 8 and k = 3 setting in Figure 4 with
Figure 5, we observe that FT performs better than FC and AM in
the binary datasets, whereas performs worse in the non-binary
datasets. The bad performance in the non-binary datasets is due
to the binary encoding process, which dramatically increases the
[23] H. W. Kuhn and A. W. Tucker. Nonlinear programming. In Traces and emergence
of nonlinear programming, pages 247ś258. Springer, 2014.
[24] N. Li, M. Lyu, D. Su, and W. Yang. Differential Privacy: From Theory to Practice.
Synthesis Lectures on Information Security, Privacy, and Trust. Morgan Claypool,
2016.
[25] N. Mishra and M. Sandler. Privacy via pseudorandom sketches. In Proceedings of
PODS, pages 143ś152. ACM, 2006.
[26] T. T. Nguyên, X. Xiao, Y. Yang, S. C. Hui, H. Shin, and J. Shin. Collecting and analyz-
ing data from smart device users with local differential privacy. arXiv:1606.05053,
2016.
[27] N. Papernot, M. Abadi, Ú. Erlingsson, I. Goodfellow, and K. Talwar. Semi-
supervised knowledge transfer for deep learning from private training data.
arXiv:1610.05755, 2016.
[28] N. Papernot, S. Song, I. Mironov, A. Raghunathan, K. Talwar, and Ú. Erlingsson.
Scalable private learning with pate. In ICLR, 2018.
[29] W. Qardaji, W. Yang, and N. Li. Priview: practical differentially private release of
marginal contingency tables. In Proceedings of SIGMOD, pages 1435ś1446. ACM,
2014.
[30] Z. Qin, Y. Yang, T. Yu, I. Khalil, X. Xiao, and K. Ren. Heavy hitter estimation
over set-valued data with local differential privacy. In Proceedings of CCS, pages
192ś203. ACM, 2016.
[31] X. Ren, C.-M. Yu, W. Yu, S. Yang, X. Yang, J. A. McCann, and S. Y. Philip. Lopub:
High-dimensional crowdsourced data publication with local differential privacy.
IEEE Transactions on Information Forensics and Security, 13(9):2151ś2166, 2018.
[32] S. Ruggles, J. T. Alexander, K. Genadek, R. Goeken, M. B. Schroeder, and M. Sobek.
Integrated public use microdata series: Version 5.0 [machine-readable database],
2010.
[33] A. Smith, A. Thakurta, and J. Upadhyay. Is interaction necessary for distributed
private learning? In Proceedings of Symposium on Security and Privacy (SP), pages
58ś77. IEEE, 2017.
[34] A. G. Thakurta, A. H. Vyrros, U. S. Vaishampayan, G. Kapoor, J. Freudiger, V. R.
Sridhar, and D. Davidson. Learning new words, Mar. 14 2017. US Patent 9,594,741.
[35] S. Vadhan. The complexity of differential privacy. In Tutorials on the Foundations
of Cryptography, pages 347ś450. Springer, 2017.
[36] D. Wang, M. Gaboardi, and J. Xu.
Efficient empirical risk minimiza-
tion with smooth loss functions in non-interactive local differential privacy.
arXiv:1802.04085, 2018.
[37] T. Wang, J. Blocki, N. Li, and S. Jha. Locally differentially private protocols for