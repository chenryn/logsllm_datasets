=== 利用日志易进行日志自审计
日志易支持对系统自身用户行为进行日志自审计。
在日志易 Agent 管理列表页上, 点击类型为 Server 的服务器地址, 进入 Agent 详情页, 页面顶部点击"高级", 打开 Agent 采集配置。
在高级配置中, 找到如下配置段落:
[source,]
----
[internal_file_splitter]
type = 'RegexSplitter'
delimiter = '\n(\d|\[)'
delimiter_eol = false
keep_truncated = true
deliver_incomplete_final = true
deliver_interval = '5s'
[internal_file_decoder]
type = 'PathDecoder'
[internal_file_input]
type = 'LogstreamerInput'
log_directory = '/data/rizhiyi/logs'
file_match = '(?P[^/]+)/(?P.*)\.(?Plog|stdout|stderr)'
differentiator = ['ModuleName', '_', 'FileName', '_', 'Suffix', '..rizhiyi_internal..padding']
oldest_duration = '24h'
exclude = '.*yottasearch.*'
splitter = 'internal_file_splitter'
decoder = 'internal_file_decoder'
disabled = true
----
将最后一行的 `disabled = true` 修改为 `disabled = false`, 即可采集日志易内部日志进入专属的 yottaself 域内。
此外，日志易还可以自监控作为 Syslog 服务器时，接收的每台远端数据源的数据发送、黑白名单过滤处理情况。同样在 Server Heka 的高级配置中，找到如下配置段落：
[source,]
----
[metrics_prometheus_scrape_input]
appname = 'server_heka_metrics'
disabled = false
rescan_interval = '1m'
tag = 'rizhiyi_internal'
targets = '["http://unix/getMetrics"]'
type = 'PrometheusScrapeInput'
worker = 1
----
修改其中 `disabled = false` 即可。
重启生效后, 您可以登录 `http://yottaweb-ip:7180`, 通过搜索统计等手段, 具体进行针对日志易审计信息的查询可视化甚至监控告警。
=== 利用日志易进行日志自追踪
==== 简介
日志易的每个内部模块,都会逐步添加相应的trace功能,方便对每个服务调用进行追踪。
注意：调用链日志和模块日志不甚相同,二者共用一个traceid,但调用链主要在追踪一次请求的调用过程，注重模块间的交互，而模块日志,则是记录在模块内部的运行过程。当在调用链图中发现了故障，可以通过traceid在模块内部日志进行查找，从而更具体地分析问题。
==== 详情
每个内部模块都包含一份trace.log日志,以JSON的形式展示调用详情。需要采集、配置字段解析以及创建调用链趋势图进行查看。下面是JSON内容：
----
{
      "traceid" "d7182724a89c4a6b90d52285b635bd1e",        //（必填）STRING  整个请求发起方生成的UUID。
      "spanid": "e13732ed-3264-4691-afa9-dfc6a0e201e9",    //（必填）STRING  每发送一次请求，就生成一个新的spanid，也是UUID。
      "parent_spanid": "825d02a78c3a4460b3bf99e260de5e0b", //（必填）STRING  上游的父spanid，初始为空字符串。
      "display": "SS INVOKE searchFuture",             //（必填）STRING  current_module.name details.method details.path拼接而来。
      "start_timestamp":1599809546985000,              //（必填）LONG    起始时间戳，单位微妙，客户端发送请求前或服务端接收请求后的时间戳。
      "timestamp": 1599809557865,                      //（必填）LONG    打印日志的时间戳，单位毫秒，用于logriver入库使用。
      "duration": 10628000,                            //（必填）LONG    执行的时长，单位微秒，由下方record_timestamps两个时间戳相减而来。
      "kind": "client",                                //（必填）STRING  标记客户端还是服务端，调用链图只使用客户端日志。
      "current_module": {                              //（必填）OBJECT  当前模块的信息
        "name": "SS",                                  //（必填）STRING  当前模块名标识。
        "ip": "192.168.1.142",                         //（可选）STRING  SS和YW目前都没有，因为采集的日志会自带ip。
        "port": 9400                                   //（可选）INTEGER 同上，都没有。
      },
      "target_module": {                               //（可选）OBJECT  目标模块的信息（如果是服务端可不填）
        "name": "BEAVER",                              //（必填）STRING  目标模块标识。
        "ip": "192.168.1.142",                         //（可选）STRING  目标模块IP，能拿到就有。（BEAVER目前只有SearchResponse类型的接口能拿到，YW和SS的Mysql都拿不到）
        "port": 9400                                   //（可选）INTEGER 目标模块port，同上。
      },
      "record_timestamps": [                           //（必填）OBJECT  记录两个时间戳，客户端是CS，CR，服务端是SS，SR。（S是send，R是receive）。
        {
          "timestamp": 1599809546985000,    
          "value": "CS"
        },
        {
          "timestamp": 1599809557613000,
          "value": "CR"
        }
      ],
      "details": {                                                      //（必填）OBJECT  详情，有模块共同的内容，也有模块特殊内容。
        "db_sql": "SELECT `id`,`name`,`create_time` FROM `Domain`",     //（可选）STRING  Mysql或Mongodb的SQL语句，Mongodb目前好像没有获取到，在method和path中体现即可。
        "error_code": 1,                                                //（必填）INTEGER 错误码，正常为0，如果错误，客户端透传下游返回的错误码，服务端返回自己的错误码。
        "error_message": "错误 roleIds is null",                         //（可选）STRING  错误信息，如果错误码不为0，则有，其余同上。
        "path": "searchFuture",                                         //（必填）STRING  请求路径，服务端写自己被请求的路径，客户端写向下游模块请求的路径。rpc调用写方法名,Mysql写表名，Mongodb写DB名或表名。
        "method": "INVOKE",                                             //（必填）STRING  请求方法，比如http有GET，POST等，Mysql有SELECT，UPDATE等，Mongodb有FIND等，RPC调用使用INVOKE等。
        "trace_rate": 0.25,                                             //（可选）INTEGER 采样率，源头发送方记录，经由模块不记录。当不是上游传来的带有采样率的请求，而是本地自动执行的，比如后台任务等需要使用自己模块的采样率。
        "trace_tag": "abc",                                             //（可选）STRING  trace标记，正常都没有，手动调用接口时，可以在请求中加个标记，方便筛选日志。
      }
}
----
说明：
1、采样率：
每个内部模块有自己的采样率。采样率是打印trace日志的比率，以免打印太多日志信息，造成压力。对于一次请求而言，如果初始发送方确定要打印本次请求的trace日志，则调用下游的每个模块都需要打印。作为初始发送方的模块，需要根据自己模块的采样配置，判断本次请求是否打印。
2、请求角色：
每次调用都有两种角色：客户端和服务端。客户端是发起请求的一端，服务端是接收请求的一端。发起和接收都需要打印trace日志，调用链图只筛选并展示客户端日志，即kind字段为client的日志。服务端日志可通过搜索进行查询，从而计算获得网络延迟等信息。
3、内外模块：
追踪包含内部模块和外部模块。内部模块是日志易自己的模块，比如Yottaweb，Spl等，外部模块是第三方模块，比如Mysql，Mongodb等。目前外部模块都不打印作为服务端的接收日志，只在内部模块调用他们时打印客户端的发送日志。
4、时间戳：
* start_timestamp：客户端的起始时间是发送请求的时间，服务端的起始时间是接收到请求的时间。
* timestamp：trace日志打印的时间，Logriver入库时间戳。
* record_timestamps：trace日志记录的时间，每条日志包含两个记录时间。
** CS：Client Send，客户端发起请求的时间。
** CC：Client Receive，客户端收到响应结果的时间。
** SS：Server Send，服务端返回结果的时间。
** SC：Server Receive，服务端接收到请求的时间。
5、接口调用:
接口调用，是手动拼写url，通过curl等方式请求各模块的接口。经常是为了调查问题或复现问题使用。在url中，需要拼写四个参数：
----
traceid:  整个请求发起方生成的UUID。
spanid:  每次发送生成一个新的spanid，也是UUID。
should_trace:  是否打印调用链日志。
trace_tag:  透传打印标签。
----
* 如果想打印本次请求整个生命周期的所有trace日志，则需将should_trace参数置为true。
* 如果想筛选出本次请求途经的所有trace日志，需自定义trace_tag参数，这个标记会透传到每个下游模块。
* 如果想查看请求在模块内部的执行过程,可以使用调用链日志中的traceid在模块日志中进行查询。
* 如果想在调用链图中看到手动进行的接口调用，则需要在url中将parent_spanid置空，在调用链图的语句中不过滤kind字段。但是，手动调用接口的调用链图与正常有所不同，可能会显示出接收方日志，即kind是server的日志。
== 管理数据完整性
日志易依赖底层搜索引擎实现和保证接入数据的完整性。
Beaver 引擎在写入每个数据文件的时候会在文件头和文件末尾加上指定的魔数(Magic Number)，引擎访问数据的时候会先验证这个魔数来确认文件的完整性。
Beaver 引擎在索引层面，还可以开启 `write_hash_for_block` 配置：
image::images/index-hash.png[]
该索引从下一次切分时间开始，每次新数据刷盘、合并，都会对磁盘上的分块进行数据哈希计算，并保存到对应的 self.ds 自描述文件中。在后续管理工作中，可以通过日志易提供的 `block_hash` 命令行二进制工具，即时计算索引数据，与自描述文件对比，确认数据完整性无恙。
image::images/write-hash-for-block.png[]
`write_hash_for_block` 配置支持 MD5 和 SM3 两种不同算法，默认采用国密 SM3 算法。