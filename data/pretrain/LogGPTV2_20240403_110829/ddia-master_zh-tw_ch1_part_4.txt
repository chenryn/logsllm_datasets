[^iii]: 理想情况下，批次作业的执行时间是资料集的大小除以吞吐量。在实践中由于资料倾斜（资料不是均匀分布在每个工作程序中），需要等待最慢的任务完成，所以执行时间往往更长。
> #### 延迟和响应时间
>
> **延迟（latency）** 和 **响应时间（response time）** 经常用作同义词，但实际上它们并不一样。响应时间是客户所看到的，除了实际处理请求的时间（ **服务时间（service time）** ）之外，还包括网路延迟和排队延迟。延迟是某个请求等待处理的 **持续时长**，在此期间它处于 **休眠（latent）** 状态，并等待服务【17】。
即使不断重复传送同样的请求，每次得到的响应时间也都会略有不同。现实世界的系统会处理各式各样的请求，响应时间可能会有很大差异。因此我们需要将响应时间视为一个可以测量的数值 **分布（distribution）**，而不是单个数值。
在 [图 1-4](../img/fig1-4.png) 中，每个灰条代表一次对服务的请求，其高度表示请求花费了多长时间。大多数请求是相当快的，但偶尔会出现需要更长的时间的异常值。这也许是因为缓慢的请求实质上开销更大，例如它们可能会处理更多的资料。但即使（你认为）所有请求都花费相同时间的情况下，随机的附加延迟也会导致结果变化，例如：上下文切换到后台程序，网路资料包丢失与 TCP 重传，垃圾收集暂停，强制从磁碟读取的页面错误，伺服器机架中的震动【18】，还有很多其他原因。
![](../img/fig1-4.png)
**图 1-4 展示了一个服务 100 次请求响应时间的均值与百分位数**
通常报表都会展示服务的平均响应时间。（严格来讲 “平均” 一词并不指代任何特定公式，但实际上它通常被理解为 **算术平均值（arithmetic mean）**：给定 n 个值，加起来除以 n ）。然而如果你想知道 “**典型（typical）**” 响应时间，那么平均值并不是一个非常好的指标，因为它不能告诉你有多少使用者实际上经历了这个延迟。
通常使用 **百分位点（percentiles）** 会更好。如果将响应时间列表按最快到最慢排序，那么 **中位数（median）** 就在正中间：举个例子，如果你的响应时间中位数是 200 毫秒，这意味著一半请求的返回时间少于 200 毫秒，另一半比这个要长。
如果想知道典型场景下使用者需要等待多长时间，那么中位数是一个好的度量标准：一半使用者请求的响应时间少于响应时间的中位数，另一半服务时间比中位数长。中位数也被称为第 50 百分位点，有时缩写为 p50。注意中位数是关于单个请求的；如果使用者同时发出几个请求（在一个会话过程中，或者由于一个页面中包含了多个资源），则至少一个请求比中位数慢的机率远大于 50%。
为了弄清异常值有多糟糕，可以看看更高的百分位点，例如第 95、99 和 99.9 百分位点（缩写为 p95，p99 和 p999）。它们意味著 95%、99% 或 99.9% 的请求响应时间要比该阈值快，例如：如果第 95 百分位点响应时间是 1.5 秒，则意味著 100 个请求中的 95 个响应时间快于 1.5 秒，而 100 个请求中的 5 个响应时间超过 1.5 秒。如 [图 1-4](../img/fig1-4.png) 所示。
响应时间的高百分位点（也称为 **尾部延迟**，即 **tail latencies**）非常重要，因为它们直接影响使用者的服务体验。例如亚马逊在描述内部服务的响应时间要求时是以 99.9 百分位点为准，即使它只影响一千个请求中的一个。这是因为请求响应最慢的客户往往也是资料最多的客户，也可以说是最有价值的客户 —— 因为他们掏钱了【19】。保证网站响应迅速对于保持客户的满意度非常重要，亚马逊观察到：响应时间增加 100 毫秒，销售量就减少 1%【20】；而另一些报告说：慢 1 秒钟会让客户满意度指标减少 16%【21，22】。
另一方面，最佳化第 99.99 百分位点（一万个请求中最慢的一个）被认为太昂贵了，不能为亚马逊的目标带来足够好处。减小高百分位点处的响应时间相当困难，因为它很容易受到随机事件的影响，这超出了控制范围，而且效益也很小。
百分位点通常用于 **服务级别目标（SLO, service level objectives）** 和 **服务级别协议（SLA, service level agreements）**，即定义服务预期效能和可用性的合同。SLA 可能会宣告，如果服务响应时间的中位数小于 200 毫秒，且 99.9 百分位点低于 1 秒，则认为服务工作正常（如果响应时间更长，就认为服务不达标）。这些指标为客户设定了期望值，并允许客户在 SLA 未达标的情况下要求退款。
**排队延迟（queueing delay）** 通常占了高百分位点处响应时间的很大一部分。由于伺服器只能并行处理少量的事务（如受其 CPU 核数的限制），所以只要有少量缓慢的请求就能阻碍后续请求的处理，这种效应有时被称为 **头部阻塞（head-of-line blocking）** 。即使后续请求在伺服器上处理的非常迅速，由于需要等待先前请求完成，客户端最终看到的是缓慢的总体响应时间。因为存在这种效应，测量客户端的响应时间非常重要。
为测试系统的可伸缩性而人为产生负载时，产生负载的客户端要独立于响应时间不断传送请求。如果客户端在传送下一个请求之前等待先前的请求完成，这种行为会产生人为排队的效果，使得测试时的伫列比现实情况更短，使测量结果产生偏差【23】。
> #### 实践中的百分位点
>
> 在多重呼叫的后端服务里，高百分位数变得特别重要。即使并行呼叫，终端使用者请求仍然需要等待最慢的并行呼叫完成。如 [图 1-5](../img/fig1-5.png) 所示，只需要一个缓慢的呼叫就可以使整个终端使用者请求变慢。即使只有一小部分后端呼叫速度较慢，如果终端使用者请求需要多个后端呼叫，则获得较慢呼叫的机会也会增加，因此较高比例的终端使用者请求速度会变慢（该效果称为尾部延迟放大，即 tail latency amplification【24】）。
>
> 如果你想将响应时间百分点新增到你的服务的监视仪表板，则需要持续有效地计算它们。例如，你可以使用滑动视窗来跟踪连续10分钟内的请求响应时间。每一分钟，你都会计算出该视窗中的响应时间中值和各种百分数，并将这些度量值绘制在图上。
>
> 简单的实现是在时间视窗内储存所有请求的响应时间列表，并且每分钟对列表进行排序。如果对你来说效率太低，那么有一些演算法能够以最小的 CPU 和记忆体成本（如前向衰减【25】、t-digest【26】或 HdrHistogram 【27】）来计算百分位数的近似值。请注意，平均百分比（例如，减少时间解析度或合并来自多台机器的资料）在数学上没有意义 - 聚合响应时间资料的正确方法是新增直方图【28】。
![](../img/fig1-5.png)
**图 1-5 当一个请求需要多个后端请求时，单个后端慢请求就会拖慢整个终端使用者的请求**
### 应对负载的方法
现在我们已经讨论了用于描述负载的引数和用于衡量效能的指标。可以开始认真讨论可伸缩性了：当负载引数增加时，如何保持良好的效能？
适应某个级别负载的架构不太可能应付 10 倍于此的负载。如果你正在开发一个快速增长的服务，那么每次负载发生数量级的增长时，你可能都需要重新考虑架构 —— 或者更频繁。
人们经常讨论 **纵向伸缩**（scaling up，也称为垂直伸缩，即 vertical scaling，转向更强大的机器）和 **横向伸缩**（scaling out，也称为水平伸缩，即 horizontal scaling，将负载分布到多台小机器上）之间的对立。跨多台机器分配负载也称为 “**无共享（shared-nothing）**” 架构。可以在单台机器上执行的系统通常更简单，但高阶机器可能非常贵，所以非常密集的负载通常无法避免地需要横向伸缩。现实世界中的优秀架构需要将这两种方法务实地结合，因为使用几台足够强大的机器可能比使用大量的小型虚拟机器更简单也更便宜。
有些系统是 **弹性（elastic）** 的，这意味著可以在检测到负载增加时自动增加计算资源，而其他系统则是手动伸缩（人工分析容量并决定向系统新增更多的机器）。如果负载 **极难预测（highly unpredictable）**，则弹性系统可能很有用，但手动伸缩系统更简单，并且意外操作可能会更少（请参阅 “[分割槽再平衡](ch6.md#分割槽再平衡)”）。
跨多台机器部署 **无状态服务（stateless services）** 非常简单，但将带状态的资料系统从单节点变为分散式配置则可能引入许多额外复杂度。出于这个原因，常识告诉我们应该将资料库放在单个节点上（纵向伸缩），直到伸缩成本或可用性需求迫使其改为分散式。
随著分散式系统的工具和抽象越来越好，至少对于某些型别的应用而言，这种常识可能会改变。可以预见分散式资料系统将成为未来的预设设定，即使对不处理大量资料或流量的场景也如此。本书的其余部分将介绍多种分散式资料系统，不仅讨论它们在可伸缩性方面的表现，还包括易用性和可维护性。
大规模的系统架构通常是应用特定的 —— 没有一招鲜吃遍天的通用可伸缩架构（不正式的叫法：**万金油（magic scaling sauce）** ）。应用的问题可能是读取量、写入量、要储存的资料量、资料的复杂度、响应时间要求、访问模式或者所有问题的大杂烩。
举个例子，用于处理每秒十万个请求（每个大小为 1 kB）的系统与用于处理每分钟 3 个请求（每个大小为 2GB）的系统看上去会非常不一样，尽管两个系统有同样的资料吞吐量。
一个良好适配应用的可伸缩架构，是围绕著 **假设（assumption）** 建立的：哪些操作是常见的？哪些操作是罕见的？这就是所谓负载引数。如果假设最终是错误的，那么为伸缩所做的工程投入就白费了，最糟糕的是适得其反。在早期创业公司或非正式产品中，通常支援产品快速迭代的能力，要比可伸缩至未来的假想负载要重要的多。
尽管这些架构是应用程式特定的，但可伸缩的架构通常也是从通用的积木块搭建而成的，并以常见的模式排列。在本书中，我们将讨论这些构件和模式。
## 可维护性