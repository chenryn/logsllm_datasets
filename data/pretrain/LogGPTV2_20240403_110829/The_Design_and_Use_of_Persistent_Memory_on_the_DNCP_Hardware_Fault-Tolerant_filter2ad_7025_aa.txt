title:The Design and Use of Persistent Memory on the DNCP Hardware Fault-Tolerant
Platform
author:Thomas C. Bressoud and
Tom Clark and
Ti Kan
The Design and Use of Persistent Memory on the DNCP Hardware Fault-Tolerant 
Platform 
Thomas C. Bressoud 
Bell Laboratories 
Lucent Technologies 
Tom Clark, Ti Kan 
Lucent San Jose Labs 
Lucent Technologies 
600 Mountain Ave. Murray Hill, NJ 07974 
2065 Hamilton Ave. San Jose, CA 95 125 
bressoud @research. bell-labs.com 
{dogbert, ti} @lucent.com 
Abstract 
Systems that are designed to recover from system failure 
due  to sofhvare faults of  the operating  system  and/or ap- 
plication typically require a means of persistently storing a 
subset of the state of the application.  Disk drives are most 
often used  as this persistent storage,  but at a performance 
cost incurred repeatedly during normal execution as well as 
again at recovery time. 
Academic work has pioneered the concept of using a re- 
gion of  conventional memory, protecting  it, and making  it 
persist  across  operating  system  crashes and  reboots,  and 
making it as reliable as disk.  This can be used  in place of 
disk  to alleviate the performance penalties noted above. 
This paper describes a project to take these concepts and 
apply  them in  a  RAM  disk  based  realization  of persistent 
memory (PM) as part of the Lucent DNCP hardware fault- 
tolerant platform and implemented for the HP-UX operat- 
ing system, focusing on its use by a main-memory database 
system (MMDB). While we found  that the reduction in re- 
covery time was small  relative to reboot time, we achieved 
a  nearly  40%  reduction  in  execution  time for an MMDB 
benchmark run on PM as opposed to its normal use of disk 
f o r  achieving recoverability. 
Keywords: 
database, Performability, RAM disk 
Reliable Memory,  Recovery,  Main  memory 
1. Introduction 
Systems must continually strive to  strike an  achievable 
balance between  performance and availability.  Techniques 
used  to  increase availability  in  the  face of  operating sys- 
tem  and application  faults typically  have an adverse affect 
on  performance.  Likewise,  providing  for  faster applica- 
tion  start-up  times  for planned  outages  use  performance- 
decreasing disk storage of application state to achieve their 
ends. 
These  solutions  for  achieving  high  availability  in  the 
presence of software faults exhibit a common pattern of ex- 
ecution. Given that a fault may occur that results in a system 
failure, the goal becomes the expeditious recovery of the ap- 
plication  to a consistent state following a failure. The basic 
mechanism for achieving  this goal  is to write some subset 
of the application state to disk.  The steps of this execution 
pattern include: 
1. 
2. 
3. 
4. 
5. 
6. 
state-write: During normal execution, an application 
writes  a  critical  subset  of  its  state synchronously to 
disk storage.  This state-write may  be triggered  by  an 
event or on a periodic basis. 
outage: A failure occurs, or the system is taken  out of 
service for a planned  outage.  The period  of  unavail- 
ability begins at the onset of this step. 
restart:  Following  the  outage,  the  application  is 
restarted or a backup instance of the application is pro- 
moted to primary.  For some types of outage (and fail- 
ure),  an  operating system reboot  may  be  required as 
well. 
state-read: The latest complete application state writ- 
ten  during  the  state-write step prior  to  the  outage  is 
read back in from disk. 
validation: As a protection  measure, the stored appli- 
cation state may be validated. 
construction:  To reduce the performance penalty  of 
the repeated state-write step, the application state sub- 
set may be in  some reduced data form.  This must be 
used as input to a construction step that brings the state 
into an execution usable form. 
7. 
consistency-resolution:  Since time has elapsed rela- 
tive to the last state-write and events have occurred in 
0-7695-1101-5/01 $iO.OO  0 2001 IEEE 
487 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:59:04 UTC from IEEE Xplore.  Restrictions apply. 
the  environment, the  state of  the application must be 
resolved with  the state of the environment before exe- 
cution can continue.  Note that the steps of validation, 
construction, and consistency resolution may occur to- 
gether as opposed to in separate steps. 
Providing for faster recovery  following planned outages 
follows a  similar  pattern,  although typically  state-write is 
synchronized with  the  planned  outage  and  validation  and 
consistency resolution  is minimized. 
Solutions  following  this  pattern  incur  two  significant 
costs.  First, during  normal  execution, the  cost of  repeat- 
edly writing  synchronously to disk reduces the capacity of 
the  system  to  do other  useful  work.  Second, during  re- 
covery, the recovery  is  slowed through disk operations re- 
quired  to  reinstate  the  ability  to  execute.  Both  of  these 
costs are dependent on  (i) the  amount of  application state 
stored/recovered, (ii) the frequency of the store operation, 
and (iii) the tradeoff  of size vs.  recovery  for the construc- 
tion step. The first cost affects performance/capacity of the 
application and  system, while the  second cost impacts  its 
availability. 
This execution pattern  is  exhibited by  general-purpose 
fault  tolerance mechanisms  as well  as by  application spe- 
cific methods.  Two important examples of this pattern are 
in checkpointing facilities  [ 101, [6], [ 141, [I71 and in trans- 
action  based  database  systems  [9], [8].  In  checkpointing 
systems, the checkpoints themselves are the content of the 
state-write. In database systems, the transaction logs form 
the content of the state-write. Note that the described execu- 
tion pattern fails to hold when state is shared in the memory 
of elements of a distributed system or implicitly through ac- 
tive replication  techniques [ 151, [2]. 
Of particular interest to the authors (and the authors' em- 
ployer) are the class of applications employing a main mem- 
ory database (MMDB) [5], [7],  [3] to  support fast  queries 
and  updates of memory  resident records used  in  telecom- 
munications applications.  The MMDB stores its database 
in main memory in the image store. To provide recoverabil- 
ity  on  a  system failure, the  MMDB supports a durability 
mode. When executing in durability mode, the MMDB pe- 
riodically  writes  a snapshot of the image store to disk. For 
any transactions not committed to an image store snapshot, 
the MMDB maintains a transaction log so that, on recov- 
ery  following an  outage,  the  combination of  one or more 
image store snapshots and the transaction  log are sufficient 
to resolve all committed transactions and to abort any non- 
committed transactions at the time of failure. 
Breaking the performance penalty of synchronous writes 
to disk and improving recovery time has been the subject of 
academic research.  In common to this body of work is the 
fundamental concept of  defining a region of conventional 
memory, protecting it, and making it persist across operat- 
ing system crashes and reboots. It has been shown that this 
I 
persistent memory can be made as reliable as disk, but with 
the performance attributes of memory. When applied to the 
execution steps identified  above, persistent memory can be 
used as the target of the statelwrite and state-read to address 
the performance hits both during normal execution and dur- 
ing recovery. 
The Recovery Box  work  by  Baker  [ I ]   defines a  region 
of memory in the kernel and, preserves it across crashes.  It 
is protected from inadvertant modification directly by faults 
in application software as kernel memory, and modification 
is through a well-checked inJerface. The recovery box em- 
ploy's checksums to detect corruption of the memory region. 
Thle RAM  I10 (RIO) work  by  Chen  [4] and  its  exten- 
sions [ 1 I],  [ 121, and [ 131 focus on a more general-purpose 
utility  that breaks the perceived  trade-off  between the reli- 
ability  of a write-through file system with the performance 
of a write-back file system.  Their persistent memory is re- 
alized through the file buffer cache. Again application level 
faults are protected by having the persistent memory in ker- 
nel buffers, but they go further and use virtual memory pro- 
tectic'n  techniques, to protect the  buffer cache from many 
classes of operating system faults as well. 
The  goal  we  set  ourselves to  in  the  current  work  was 
to take these innovative concepts and to apply them to our 
own rndustry-specific  domain and to architect a realization 
targeted  at a commercial operating system. 
The  Lucent  Distributed  Network  Control  Platform 
(DNCP) is the current evolution of the pair and spare archi- 
tectuiie born of Stratus Computer [ 161 and then  aquired by 
Ascend Communications, which  was then acquired by  Lu- 
cent 'Technologies. The current platform is based on the HP 
PA-R.ISC 8500 processor and, as a hardware fault-tolerant 
platform, protects against any single point of failure of the 
proccssor(s),  memory,  bus,  and  I/O subsystems.  Note  in 
particular that  both  memory  and power  supply  are dupli- 
cated. 
Although the  DNCP handles hardware  faults  both  effi- 
ciently and transparently, faults of the operating system and 
of applications can still result in  system failure and outage. 
To maximize availability,  hybrid  approaches are employed 
using hardware fault-tolerance to mask the hardware faults 
and using more expensive (in performance impact as well 
as in unavailability) software techniques when necessary  to 
prov:ide coverage of software faults. Thus the performance 
and recovery-time impact of the execution pattern described 
above are applicable to the DNCP platform' as well. 
The  DNCP  platform  makes  an  excellent  platform  for 
applying  the  persistent  memory  concept.  The redundant 
power supply satisfies memory's vulnerability to power out- 
ages of concern to many critics of persistent memory tech- 
niques [4].  Further, with redundant memory, the persistent 
memory is itself duplicated. 
We have designed and implemented Persistent Memory 
488 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:59:04 UTC from IEEE Xplore.  Restrictions apply. 
(PM) on the  DNCP platform.  It  is  available  as a  layered 
product for the HP-UX operating system and, to the best of 
our knowledge, is the first commercial realization embody- 
ing the ideas of RIO and Recovery Box, bringing the impact 
of that work to bear on the industry. 
The remainder of this paper is organized as follows.  In 
Section  2  we  discuss the  alternative  realizations that  PM 
might take.  Section  3  then  describes the  PM architecture. 
In  Section  4 we  present some performance results and we 
conclude in Section 5. 
2. Architectural Choices 
In this section, we discuss and evaluate a set of architec- 
tural realizations of persistent memory. 
In  common to  all the  realization  is the requirement for 
a mechanism at system boot time to detect the existence of 
persistent memory in the system and to preserve that area of 
memory and avoid any operating system action to attempt 
to zero that memory and/or to use it for other purposes. 
2.1. Memory-Based Realizations 
The first realization of persistent memory that one might 
consider  is  to  make  it  appear,  in  terms  of  interface  and 
operations,  like  conventional  memory.  An  application  or 
MMDB  desirous  of  using  persistent  memory  would  per- 
form  an  attach/associate  operation  analagous  to  the  Unix 
shmat or m a p  that would identify the persistent memory 
and map it into the process’s virtual address space.  Appli- 
cation state requiring  persistence  would  then  be located  in 
persistent  memory  and  accessed  through  traditional  loads 
and stores. 
The obvious advantage to this realization  is the simplic- 
ity of the interface presented to the application  or MMDB. 
For the MMDB, the image store itself could  be located in 
PM and obviate the need to use durable mode at all, since 
the image store would already be persistent. 
When one thinks further about this realization, however, 
one discovers a number of difficult issues: 
0  PointedAddress  Usage.  With  a  load/store  interface, 
the  question  arises  of  whether or  not  it  can  contain 
pointers.  If  PM  always maps to the  same virtual ad- 
dress, it could contain pointers within  the PM region, 
but not pointers to addresses outside PM. Such restric- 
tions would be difficult to enforce. 
tity  would  have to be  provided,  or the  responsibility 
for such consistency would be left to the application. 
Application  Impact. The application would have to be 
made aware of PM to allow the approriate attach call as 
well as to adequately address the previous two issues. 
This would require significant work on the application 
set. 
Although  the  lack  of  transparency  to  the  application 
would make it difficult to justify this realization in general, 
we  believe  that  it  could be justified  for the MMDB case. 
The pointer/address issue should be satisfied for the MMDB 
image store.  Further, the MMDB already has mechanisms 
to group operations into transactions and to detect inconsis- 
tency.  Although not transparent, the MMDB modifications 
may well be manageable and would then leverage the ben- 
efits to all applications utilizing the target MMDB. 
2.2. Disk / Storage Realizations 
File Buffer Cache  Another realization of persistent mem- 
ory  to  consider  is  to  make the memory blocks  of  the  file 
buffer cache persistent, as was done in RIO. This realization 
is attractive as it provides a transparent interface to all file 
accesses. Any application performing a state-write or state- 
read  to/from  disk  will  place  the  data in  the  persistent  file 
buffer cache and return immediatey. In addition, because of 
the natural block level interface it is simpler to implement 
an atomic interface.  Each write of a block to the file buffer 
would constitute an atomic operation. 
An  important drawback of this solution, however, is that 
it dedicates physical memory in support of persistent buffer 
cache  for all  files  in  the  system,  including  transient  files. 
This broad  cast  of  the  net  may  not  be an  effective  use  of 
resources. 
More  pragmatically,  the  solution  requires  modification 
to key  portions of the operating system  in  order to be im- 
plemented.  The subsystems affected  must include the  file 
buffer management, and may  also include parts of the vir- 
tual memory subsystem, especially if the system uses a uni- 
fied buffer cache.  In  commercial operating systems, these 
portions of  the  code are  proprietary  and  not  available  for 
modification.  Even  if the source were available and could 
be modified,  such alteration by  independent software ven- 
dors would result in a perceived “difference” and could re- 
sult in the non-acceptance of the operating system “brand’. 
0  Operation Granularity and Atomicity.  When  a failure 
occurs,  operations  on  data  structures or  higher  level 
abstractions could  leave  such structures in  a partially 
updated  state.  Either  library  functions  to  group re- 
lated  load/store  operations into  a  transaction-like en- 
File System / Disk Interface  A  final alternative to  con- 
sider is to  realize  persistent  memory through  a filesystem 
or disk interface.  Like a RAM disk, conventional memory 
would be dedicated to the storage of disk data blocks as well 
as disk metadata.  This “disk” memory would be made per- 
489 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:59:04 UTC from IEEE Xplore.  Restrictions apply. 