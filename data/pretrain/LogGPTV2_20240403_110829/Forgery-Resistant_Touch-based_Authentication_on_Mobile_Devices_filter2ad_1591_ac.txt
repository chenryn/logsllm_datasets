Creative Commons Attribution-Share Alike 3.0 license from
the Wikipedia website. (b) The game used in the task 2;
the user must swipe vertically. We produced this image and
release it under the Creative Commons Attribution Share-
Alike 3.0 license.
Table 2: The number of strokes per subject and per second
in the ﬁve screen settings for the 25 subjects.
Strokes per subject
sa sb
se
sc sd
sa
sb
se
Horizontal 51 52 48 49 52 0.35 0.30 0.19 0.17 0.17
83 77 74 78 75 0.71 0.47 0.31 0.30 0.27
Vertical
sd
sc
Strokes per second
Task 1, horizontal strokes:
In the ﬁrst game the user
must identify diﬀerences between two images. The applica-
tion shows two versions of one image in a horizontal gallery
with a black image in between. The user must swipe hori-
zontally between the images. Figure 5a shows a screenshot
of this game. We shuﬄe the ﬁve screen settings along the
X axis at the beginning of the game, and change a setting
every 30s.
In the second game the user
Task 2, vertical strokes:
must identify pairs of images. The application shows ﬁve
(statically pre-shuﬄed) pairs of vertically aligned images of
diﬀerent patterns, shapes, and colors. At one given time
only one image is visible and the user must move the screen
to other images along the Y axis. The static shuﬄing allows
us to compare the same task across diﬀerent users. Figure 5b
shows a screenshot of this game. We shuﬄe the ﬁve screen
settings along the Y axis at the beginning of the game, and
change a setting every 30s.
We used a HTC One smartphone to collect data from 25
subjects. These subjects age between 25 and 35; and 11 of
them are female. Table 2 summarizes our dataset.
Smooth transition between screen settings: Our au-
thentication system automatically transits from one setting
to another in diﬀerent time intervals. One natural ques-
tion is that if users notice such transitions. To answer this
question, we ask each subject the question “Did you notice
anything abnormal?” when he/she ﬁnishes the tasks.
We ﬁnd that no subject noticed these transitions, which
means that users subconsciously adapt their behavior to dif-
ferent screen settings and transitions between settings do not
interrupt users nor inﬂuence user experiences.
Notation
C-Baseline-x
C-ATCA-x
S-Baseline-x
S-Baseline-improved
S-ATCA
Table 3: Approaches we compare.
Description
Baseline classiﬁer only using touch strokes in the setting sx, where x ∈ {a, b, c, d, e}
Our classiﬁer for the setting sx, where x ∈ {a, b, c, d, e}; strokes in other settings are also used
Baseline authentication system using C-Baseline-x with the ﬁxed universal setting sx, where x ∈ {a, b, c, d, e}
Our improved Baseline authentication system whose setting is randomly selected
Our authentication system using C-ATCA-x, where x ∈ {a, b, c, d, e};
settings are randomly selected in each time interval
6.2 Experimental setups
We evaluate both random attacks (RA) and targeted at-
tacks (TA) against previous approaches [12, 13, 19] and ours;
we explore the impact of the number of screen settings on
the performance of our approach; and we study the time
required to collect training strokes in the registration phase.
6.2.1 Compared approaches
We distinguish classiﬁers and authentication systems. Clas-
siﬁers are key components of a touch-based authentication
system, but an authentication system also requires to con-
sider screen settings. We name approaches to train classi-
ﬁers with a preﬁx ’C’ and approaches to implement authen-
tication systems with a preﬁx ’S’. Table 3 summarizes the
approaches we compare.
Classiﬁers: We compare the following classiﬁers:
• C-Baseline [12, 13, 19]: This approach considers
one setting. To train a classiﬁer for a user u, they take
the touch strokes of u in a setting as positive examples
and those of all other users in the same setting as neg-
ative examples. We use C-Baseline-x to denote their
approach in the setting sx, where x ∈ {a, b, c, d, e}.
• C-ATCA: Our adaptive touch-based continuous au-
thentication (ATCA) considers multiple settings when
training classiﬁers. Speciﬁcally, for a user u, we train
classiﬁers for all the ﬁve screen settings. We denote
them as C-ATCA-a, C-ATCA-b, C-ATCA-c, C-ATCA-
d, and C-ATCA-e, respectively. To train C-ATCA-x,
we take strokes of u in the setting sx as positive ex-
amples, and strokes of u in the other four settings and
strokes of other users in all the ﬁve settings as negative
examples, where x ∈ {a, b, c, d, e}.
We adopt Support Vector Machine (SVM) [7] as the clas-
siﬁer [7] in all compared approaches since it was shown to
perform well by previous work [12, 13].
Authentication systems: Other than using diﬀerent clas-
siﬁers, authentication systems might also have diﬀerent ways
to use screen settings.
• S-Baseline [12, 13, 19]: Their approach uses an uni-
versal setting (e.g., the default setting of the smart-
phone system) for all users. In this case, the attacker
can obtain the universal setting, e.g., via reading the
code of the authentication system. We further use S-
Baseline-x to denote the authentication system with
the universal setting sx, where x ∈ {a, b, c, d, e}. Note
that S-Baseline-x uses the classiﬁer C-Baseline-x.
• S-Baseline-improved: We improve S-Baseline via se-
lecting a setting from {sa, sb, sc, sd, se} uniformly at
random in the registration phase and ﬁxing it in the
authentication phase for each user. The S-Baseline-
improved system makes the attacker unaware of the
setting used for a targeted user.
• S-ATCA: Our adaptive touch-based continuous au-
thentication (ATCA) selects a setting sx from the con-
sidered ﬁve settings uniformly at random in each time
interval and uses the classiﬁer C-ATCA-x to authenti-
cate users, where x ∈ {a, b, c, d, e}.
6.2.2 Training and testing
We evaluate the approaches via 5-fold cross-validation.
Next, we take horizontal strokes as an example to illustrate
the details. The vertical strokes are treated in the same way.
The set of our subjects is denoted as Ud.
We evenly split horizontal strokes of each user in each set-
ting into 5 folds uniformly at random. Let F = {1, 2, 3, 4, 5}
denote the IDs of the 5 folds. Moreover, we denote by
f (u, s, i) the ith fold of horizontal strokes of the user u in
the setting s, where i ∈ F and s ∈ {sa, sb, sc, sd, se}.
For each user u, we iterate over i. For each i, we train
classiﬁers as follows:
Training C-Baseline classiﬁers: To train C-Baseline-x,
we use u’s horizontal strokes in the setting sx (i.e., ∪j∈F−{i}
f (u, sx, j) as positive examples and other users’ horizontal
strokes in the setting sx (i.e., ∪v∈Ud−{u}∪j∈F−{i} f (u, sx, j))
as negative examples, where x ∈ {a, b, c, d, e}.
Training C-ATCA classiﬁers: To train a C-ATCA-x
classiﬁer, we use u’s horizontal strokes in the setting sx
(i.e., ∪j∈F−{i}f (u, sx, j)) as positive examples. However,
we treat u’s horizontal strokes in the other four settings
(i.e., ∪j∈F−{i}f (u, sy, j), where y ∈ {a, b, c, d, e}/ {x}) and
other users’ horizontal strokes in all the ﬁve settings (i.e.,
∪v∈Ud−{u} ∪j∈F−{i} f (u, sz, j), where z ∈ {a, b, c, d, e}) as
negative examples, where x ∈ {a, b, c, d, e}.
We adopt a Gaussian kernel for SVM and use the LibSVM
library [6] to learn the corresponding hyper-parameters via
grid search. Each feature is re-scaled to be between -1 and
1. Note that training features and testing features are nor-
malized separately.
Testing: In the test phase, we use u’s horizontal strokes in
a setting (i.e., f (u, sx, i)) as legitimate (or positive) exam-
ples for the classiﬁers trained for the same setting (i.e., C-
Baseline-x and C-ATCA-x), where x ∈ {a, b, c, d, e}. More-
over, we treat other users’ horizontal strokes in all the ﬁve
settings (i.e., ∪v∈Ud−{u}f (v, sz, i), where z ∈ {a, b, c, d, e})
as strokes to perform random attacks; and we treat the tar-
get user’s horizontal strokes in the ﬁve settings (i.e., f (u, sz, i),
where z ∈ {a, b, c, d, e}) as strokes to perform targeted at-
tacks. For each user, training and testing are performed with
5 trials since we have 5 folds, and the results are averaged
over them.
Table 4: Mean EERs over all subjects for each classiﬁer and attack dataset for horizontal strokes. Numbers in parentheses
are standard deviations.
(a) Horizontal strokes, random attacks
sa
sb
sc
sd
se
C-Baseline-a
C-Baseline-b
C-Baseline-c
C-Baseline-d
C-Baseline-e
C-ATCA-a
C-ATCA-b
C-ATCA-c
C-ATCA-d
C-ATCA-e
0.06(0.0543)
0.04(0.0461)
0.07(0.0590)
0.10(0.0817)
0.09(0.0891)
0.04(0.0736)
0.02(0.0554)
0.06(0.0782)
0.06(0.0771)
0.03(0.0719)
0.06(0.0485)
0.04(0.0462)
0.07(0.0518)
0.09(0.0818)
0.10(0.0966)
0.02(0.0534)
0.04(0.0681)
0.07(0.0822)
0.06(0.0823)
0.04(0.0743)
0.06(0.0472)
0.05(0.0423)
0.06(0.0498)
0.09(0.0742)
0.10(0.0942)
0.02(0.0437)
0.02(0.0572)
0.08(0.0778)
0.06(0.0787)
0.04(0.0703)
0.07(0.0530)
0.05(0.0447)
0.06(0.0463)
0.09(0.0792)
0.10(0.0973)
0.01(0.0355)
0.02(0.0437)
0.06(0.0634)
0.09(0.0857)
0.05(0.0755)
0.07(0.0547)
0.05(0.0472)
0.06(0.0541)
0.09(0.0757)
0.09(0.0991)
0.01(0.0291)
0.02(0.0544)
0.06(0.0675)
0.07(0.0811)
0.06(0.0864)
(b) Horizontal strokes, targeted attacks
sa
sb
sc
sd
se
C-Baseline-a
C-Baseline-b
C-Baseline-c
C-Baseline-d
C-Baseline-e
C-ATCA-a
C-ATCA-b
C-ATCA-c
C-ATCA-d
C-ATCA-e
0.50(0.0000)
0.46(0.1142)
0.49(0.1442)
0.43(0.1926)
0.39(0.2480)
0.50(0.0000)
0.33(0.1475)
0.37(0.1569)
0.27(0.1390)
0.21(0.1780)
0.49(0.1142)
0.50(0.0000)
0.49(0.1181)
0.44(0.1866)
0.40(0.2210)
0.27(0.1563)
0.50(0.0000)
0.35(0.1340)
0.29(0.1353)
0.22(0.1729)
0.44(0.1586)
0.47(0.1388)
0.50(0.0000)
0.46(0.1376)
0.41(0.1852)
0.23(0.1384)
0.30(0.1166)
0.50(0.0000)
0.33(0.1311)
0.24(0.1721)
0.38(0.2023)
0.35(0.1602)
0.46(0.1397)
0.50(0.0000)
0.42(0.1752)
0.16(0.1684)
0.25(0.1185)
0.32(0.1100)
0.50(0.0000)
0.25(0.1516)
0.37(0.2051)
0.35(0.1710)
0.41(0.1876)
0.47(0.1129)
0.50(0.0000)
0.16(0.1515)
0.23(0.1437)
0.35(0.1370)
0.35(0.1019)
0.50(0.0000)
6.2.3 Evaluation metrics
Our evaluation metric involves the false-acceptance rate
(FAR), the false rejection rate (FRR), and the mean time T