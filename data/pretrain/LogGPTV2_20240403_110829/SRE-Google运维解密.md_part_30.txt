探针程序希望得到一个HTTP200返回值，以及一个JSON结果集，精确匹配为：
个HTTPGET请求：
使用Bug中的黑盒监控系统结果链接，你会发现探针程序给/api/search发送了一
作的。日志记录系统最好能够按需、快速、有选择启用。
过10ms的，
的范围很广，例如过滤SetRPC中内容长度小于1024字节的，或者是操作时间超
更进一步，你可能需要在日志系统中支持过滤条件一
记录会更好，例如每1000次操作记录一次。
当系统正常运行时，将系统日志级别还原。
'search_text':'the forms of thingsunknown'
"speaker":"Theseus"
"Line":2526,
"scene":1,
"act":5,
"work":"A Midsummer Night's Dream"，
：或者是调用了rpc_handler.py中doSomethingInteresting（）函数的操
调试莎士比亚搜索服务
。根据服务的流量大小，有可能采用采样
一记录所有满足X的操作。X
实践
121
139
---
## Page 164
140
注10在很多情况下，这和著名的“FiveWhys”理论很像，可参见文献[Ohn88]。
122
做这些操作，以及系统的资源都被用在了“哪里”
行的操作。那么找出系统目前正在执行“什么”，然后通过询问该系统“为什么”正在
在一个异常系统中，该系统经常还正在执行某种操作，只是这些操作不是你想让系统执
“什么”“哪里”和“为什么”
再重复进行。
逐个检查可能太慢了，可以采用对分法（bisection）将系统分为两部分，确认问题所在
每一个组件，直到系统最底层。这样的策略非常适用于数据处理流水线。在大型系统中，
整套系统需要多层组件共同协作完成。最好的办法通常是从系统的一端开始，逐个检查
问题分解（Divide&Conquer）也是一个非常有用的通用解决方案。在一个多层系统中，
境，非生产环境通常可以执行更具有侵入性和危害性的操作。
统有配套的测试用例，那么调试起来就会很容易。甚至这套测试用例可以用于非生产环
试的一种），是非常有帮助的。尤其是使用针对某种错误情况的专门测试数据。如果系
件是否正常工作。将已知的测试数据输入到系统中，检查输出是否正确（这就是黑盒测
的结果）。我们就可以通过检查组件之间的链接，或者是中间传输的数据来判断某个组
则将输入转化为输出（在我们的例子中，该组件接收搜索文字请求，并且返回符合条件
理想情况下，系统中的每个组件都应该有明确定义的接口，并且每个接口都按照固定规
简化和缩略
这里有一些通用的手段可以在没有领域知识的情况下提供帮助。
对系统设计的详细了解，是针对目前系统出现的问题提出合理猜想的主要帮助。但是，
诊断
后端服务器是否工作正常。
Trace，其中写明了处理请求的后端服务器地址。利用这个信息，可以仔细检查这些
Gateway)，也没有任何结果信息。同时，结果中包含了一个HTTP头，X-Request-
使用curl，你手动发送了一个请求，
时，具体返回了什么结果，所以你将这个问题记录了下来，以便日后修复。
第12章有效的故障排查手段
获得了一个失败回复：HTTP502（Bad
可以帮助你了解系统为什么出错。
注10
---
## Page 165
图12-2：错误率图表以及部署开始时间和结束时间
如图12-2所示。
页面上，你可以将系统的错误率图表和新版本的部署起始时间和结束时间标记在一起，
过将系统的环境改变与系统性能和行为进行对比，可能比较有用。例如，在服务的监控
新。这包括从处理用户请求的服务进程，一直到集群中每个节点的安装的版本信息。通
设计良好的系统应该有详尽的生产日志，记录整个架构中新版本部署或者配置文件的更
可能对查找问题根源很有帮助。注12
外力因素出现，例如一个配置文件的修改，用户流量的改变等。
计算机系统有惯性存在：我们发现，
最后一个修改
2
关系。
的问题。考虑使用RE2，该类库保证不使用回溯，同时保障运行时间与输入呈线性
解决方案：重写该正则表达式，避免使用回溯（backtracking）。在代码中寻找类似
哪里：这段排序代码中的哪部分在消耗资源？是在一段正则表达式的计算过程中
在将日志记录排序，写入磁盘。
哪里：Spanner服务器的CPU消耗在了哪里？通过采样（profiling）得知该任务正
为什么：Spanner服务器的任务实例把CPU占满了，无法处理用户发来的请求。
现象：一个Spariner集群出现延迟过高的情况，RPC请求超时。
文献[A115]中提到这是一个在解决问题中经常被使用的手段。
PCRE在计算某些正则表达式的时候可能需要指数型时间。RE2可在htps://github.com/google/re2下载。
注目
ErrorRate%
0.1-
0.2+
0.3+
0.4+
对问题现象的解析
6:00
一个正常工作的计算机系统会维持工作，直到某种
12:00
Deploy #7214
18:00
Acepte LO
。检查最近对系统的修改
+
实践
123
141
---
## Page 166
143
124
争问题。）
复杂的测试，例如将用户流量导出一个集群，同时使用特殊构造的请求试图发现资源竞
在设计测试时，有一些考量必须时刻记住。（这些测试可能是简单的ping测试，或者是
里出现了错误。
拓扑环境、防火墙配置等。通过查看源代码，并且试图模拟源代码执行，也可以看出哪
证第二个假设。通过ping数据库服务器可以测试第一个假设，但是这取决于具体的网络
于数据库拒绝连接导致的。通过测试应用服务器的用户名和密码实际链接数据库可以验
果认为一个错误是由于应用逻辑服务器和数据库之间的网络连接问题导致的，或者是由
源问题。通过执行一些具体的试验，可以确认和推翻我们所列举的假设。举例来说，如
有了一个相对较短的可能原因列表，接下来就应该试着找出具体哪个原因才是真正的根
测试和修复
某个特定系统，但是在不同的团队和系统之间应该寻找共同点，以减少重复劳动。
和诊断系统会更有用。Google SRE花费了很多时间开发这样的工具。很多工具只适用于
有针对性地进行诊断
发送测试请求来测试，同时检查后端服务的监控指标。
那么就不会带有这个信息。现在你可以将精力集中在后端服务器上，通过分析日志
前端服务器和负载均衡服务出现问题的几率：因为如果请求没有到达后端服务器
材料），并且观察到错误回复中包含处理请求的后端服务器，可以让你排除掉API
·某项测试可能产生有误导性的结果。例如：防火墙规则可能只允许某些特定IP
·先测试最可能的情况：按照可能发生的顺序执行测试，
执行测试可能会带来副作用。举例说明：让一个进程使用更多CPU可能会让某
ping数据库可能是成功的。
些操作更快，也可能会导致数据竞争问题更容易发生（单线程与多线程运行）。
访问，所以在你的工作机上ping 数据库可能会失败，而实际从应用服务器上
问某机器可能更合理。
危险性。先测试网络连通性，再检查是否是最近的配置文件改变导致用户无法访
时确认另外一组假设。在实际执行中，这比较难。
同样的，在运行中开启详细日志可能会使延迟问题变得更糟，同时也让你的测试
一个理想的测试应该具有互斥性，通过执行这个测试，可以将一组假设推翻，同
第12章有效的故障排查手段
，同时考虑该测试对系统的
---
## Page 167
因为一个可靠的、应用广泛的负面结果对其他人更有帮助。
的事后报告都属于这个范畴。我们在设计实验的时候应该将可能的负面结果考虑在内，
新的试验，或者避免之前设计中的问题。微型性能测试、文档化的反模式，以及某项目
就算该负面结果无法被其他人直接利用，这项试验收集到的数据也可以帮助其他人选择
发团队想要评测Web服务器时，他们可以直接利用之前的负面结果判断而不是从头开始。
试验和设计是否值得一试。举例来说，某个研发团队可能决定不使用某个Web服务器
负面结果不应该被忽略，或者被轻视。意识到自己的错误通常意义更大：一个明确的负
广义范围的，包括新的系统设计、启发性算法或工作流程没有改进他们试图取代的旧系
“负面结果”指一项试验中预期结果没有出现，也就是该试验没有成功。这里的试验是
神奇的负面结果
助于将系统还原到测试前的状态，而不是一直运行在这种未知状态下。
如果你修改了线上系统，例如给某个进程增加了可用资源。系统化和文档化这些改变有
处理更加复杂的问题时，良好的文档可以让你记住曾经发生过什么，可避免重复执行。注14
注14
注13使用实时聊天或者共享文档可以记录你具体操作的时间点，
否使用。
他们可以根据（a）需要的并发连接数少于800个（b）锁竞争问题已经被解决了来决定是
因为由于锁竞争的缘故只能处理800个并发连接，而不是需要的8000个。当下一个研
息、设计理念对错或者现有系统的性能极限。这些负面结果能够帮助其他人决定他们的
一项试验中出现的负面结果是确凿的。这些结果确切地告诉了我们有关生产环境中的信
问题通常是模糊而抽象的。
计方向可供选择，选择任意一个方向都需要回答有关是否另外一个方向更好的问题。该
面结果可以给某些最难的设计问题画上句号。一个团队经常同时有两个看起来可行的设
将你的想法明确地记录下来，包括你执行了哪些测试，以及结果是什么。注13尤其是当你
统
·某些测试无法得出准确的结论，只是建议性的。死锁和数据竞争问题可能是非常
参见本章后面“神奇的负面结果”
也共享给了其他人，
难以重现的，所以有的时候你并不能找到非常确切的证据。
结果难以理解：是问题变得更加严重了，还是因为开启详细日志的原因？
他们可以了解目前事态的进展，就不需要打断你来了解情况。
一节。
在事后总结时非常有用。同时这个信息
神奇的负面结果
作者：Randall Bosetti
编辑：JoanWendt
125
144
---
## Page 168
注15关于如何对系统建模可参看文献[Mea08]，
因是很困难的。因为如下几个原因，我们经常只能发现可能的原因。
明这就是问题根源。在生产环境中试图通过重现一个原因而明确地证明它就是问题的原
治愈
最后，公开你自己觉得意外的结果会让其他人一
过度筛选，也可能因为作者的方法不是那么严谨。
没有提到失败的设计文档、性能评估文档以及短文保持怀疑，因为这篇文章可能经过了
意识到，负面结果是有计划的冒险行为，每个设计良好的试验都是有价值的。应对任何
每个人都应该主动公布自己已经排除的设计、算法和团队工作流程等。鼓励你的同行们