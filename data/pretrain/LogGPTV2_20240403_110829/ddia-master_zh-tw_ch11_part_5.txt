#### 变更资料捕获的实现
我们可以将日志消费者叫做 **衍生资料系统**，正如在 [第三部分](part-iii.md) 的介绍中所讨论的：储存在搜寻索引和资料仓库中的资料，只是 **记录系统** 资料的额外检视。变更资料捕获是一种机制，可确保对记录系统所做的所有更改都反映在衍生资料系统中，以便衍生系统具有资料的准确副本。
从本质上说，变更资料捕获使得一个数据库成为领导者（被捕获变化的资料库），并将其他元件变为追随者。基于日志的讯息代理非常适合从源资料库传输变更事件，因为它保留了讯息的顺序（避免了 [图 11-2](../img/fig11-2.png) 的重新排序问题）。
资料库触发器可用来实现变更资料捕获（请参阅 “[基于触发器的复制](ch5.md#基于触发器的复制)”），透过注册观察所有变更的触发器，并将相应的变更项写入变更日志表中。但是它们往往是脆弱的，而且有显著的效能开销。解析复制日志可能是一种更稳健的方法，但它也很有挑战，例如如何应对模式变更。
LinkedIn 的 Databus【25】，Facebook 的 Wormhole【26】和 Yahoo! 的 Sherpa【27】大规模地应用这个思路。Bottled Water 使用解码 WAL 的 API 实现了 PostgreSQL 的 CDC【28】，Maxwell 和 Debezium 透过解析 binlog 对 MySQL 做了类似的事情【29,30,31】，Mongoriver 读取 MongoDB oplog【32,33】，而 GoldenGate 为 Oracle 提供类似的功能【34,35】。
类似于讯息代理，变更资料捕获通常是非同步的：记录资料库系统在提交变更之前不会等待消费者应用变更。这种设计具有的运维优势是，新增缓慢的消费者不会过度影响记录系统。不过，所有复制延迟可能有的问题在这里都可能出现（请参阅 “[复制延迟问题](ch5.md#复制延迟问题)”）。
#### 初始快照
如果你拥有 **所有** 对资料库进行变更的日志，则可以透过重播该日志，来重建资料库的完整状态。但是在许多情况下，永远保留所有更改会耗费太多磁碟空间，且重播过于费时，因此日志需要被截断。
例如，构建新的全文索引需要整个资料库的完整副本 —— 仅仅应用最近变更的日志是不够的，因为这样会丢失最近未曾更新的专案。因此，如果你没有完整的历史日志，则需要从一个一致的快照开始，如先前的 “[设定新从库](ch5.md#设定新从库)” 中所述。
资料库的快照必须与变更日志中的已知位置或偏移量相对应，以便在处理完快照后知道从哪里开始应用变更。一些 CDC 工具集成了这种快照功能，而其他工具则把它留给你手动执行。
#### 日志压缩
如果你只能保留有限的历史日志，则每次要新增新的衍生资料系统时，都需要做一次快照。但 **日志压缩（log compaction）** 提供了一个很好的备选方案。
我们之前在 “[杂凑索引](ch3.md#杂凑索引)” 中关于日志结构储存引擎的上下文中讨论了日志压缩（请参阅 [图 3-2](../img/fig3-2.png) 的示例）。原理很简单：储存引擎定期在日志中查询具有相同键的记录，丢掉所有重复的内容，并只保留每个键的最新更新。这个压缩与合并过程在后台执行。
在日志结构储存引擎中，具有特殊值 NULL（**墓碑**，即 tombstone）的更新表示该键被删除，并会在日志压缩过程中被移除。但只要键不被覆盖或删除，它就会永远留在日志中。这种压缩日志所需的磁碟空间仅取决于资料库的当前内容，而不取决于资料库中曾经发生的写入次数。如果相同的键经常被覆盖写入，则先前的值将最终将被垃圾回收，只有最新的值会保留下来。
在基于日志的讯息代理与变更资料捕获的上下文中也适用相同的想法。如果 CDC 系统被配置为，每个变更都包含一个主键，且每个键的更新都替换了该键以前的值，那么只需要保留对键的最新写入就足够了。
现在，无论何时需要重建衍生资料系统（如搜寻索引），你可以从压缩日志主题的零偏移量处启动新的消费者，然后依次扫描日志中的所有讯息。日志能保证包含资料库中每个键的最新值（也可能是一些较旧的值）—— 换句话说，你可以使用它来获取资料库内容的完整副本，而无需从 CDC 源资料库取一个快照。
Apache Kafka 支援这种日志压缩功能。正如我们将在本章后面看到的，它允许讯息代理被当成永续性储存使用，而不仅仅是用于临时讯息。
#### 变更流的API支援
越来越多的资料库开始将变更流作为第一等的介面，而不像传统上要去做加装改造，或者费工夫逆向工程一个 CDC。例如，RethinkDB 允许查询订阅通知，当查询结果变更时获得通知【36】，Firebase 【37】和 CouchDB 【38】基于变更流进行同步，该变更流同样可用于应用。而 Meteor 使用 MongoDB oplog 订阅资料变更，并改变了使用者介面【39】。
VoltDB 允许事务以流的形式连续地从资料库中汇出资料【40】。资料库将关系资料模型中的输出流表示为一个表，事务可以向其中插入元组，但不能查询。已提交事务按照提交顺序写入这个特殊表，而流则由该表中的元组日志构成。外部消费者可以非同步消费该日志，并使用它来更新衍生资料系统。
Kafka Connect【41】致力于将广泛的资料库系统的变更资料捕获工具与 Kafka 整合。一旦变更事件进入 Kafka 中，它就可以用于更新衍生资料系统，比如搜寻索引，也可以用于本章稍后讨论的流处理系统。
### 事件溯源
我们在这里讨论的想法和 **事件溯源（Event Sourcing）** 之间有一些相似之处，这是一个在 **领域驱动设计（domain-driven design, DDD）** 社群中折腾出来的技术。我们将简要讨论事件溯源，因为它包含了一些关于流处理系统的有用想法。
与变更资料捕获类似，事件溯源涉及到 **将所有对应用状态的变更** 储存为变更事件日志。最大的区别是事件溯源将这一想法应用到了一个不同的抽象层次上：
* 在变更资料捕获中，应用以 **可变方式（mutable way）** 使用资料库，可以任意更新和删除记录。变更日志是从资料库的底层提取的（例如，透过解析复制日志），从而确保从资料库中提取的写入顺序与实际写入的顺序相匹配，从而避免 [图 11-4](../img/fig11-4.png) 中的竞态条件。写入资料库的应用不需要知道 CDC 的存在。
* 在事件溯源中，应用逻辑显式构建在写入事件日志的不可变事件之上。在这种情况下，事件储存是仅追加写入的，更新与删除是不鼓励的或禁止的。事件被设计为旨在反映应用层面发生的事情，而不是底层的状态变更。
事件溯源是一种强大的资料建模技术：从应用的角度来看，将使用者的行为记录为不可变的事件更有意义，而不是在可变资料库中记录这些行为的影响。事件溯源使得应用随时间演化更为容易，透过更容易理解事情发生的原因来帮助除错的进行，并有利于防止应用 Bug（请参阅 “[不可变事件的优点](#不可变事件的优点)”）。
例如，储存 “学生取消选课” 事件以中性的方式清楚地表达了单个行为的意图，而其副作用 “从登记表中删除了一个条目，而一条取消原因的记录被新增到学生反馈表” 则嵌入了很多有关稍后对资料的使用方式的假设。如果引入一个新的应用功能，例如 “将位置留给等待列表中的下一个人” —— 事件溯源方法允许将新的副作用轻松地从现有事件中脱开。
事件溯源类似于 **编年史（chronicle）** 资料模型【45】，事件日志与星型模式中的事实表之间也存在相似之处（请参阅 “[星型和雪花型：分析的模式](ch3.md#星型和雪花型：分析的模式)”） 。
诸如 Event Store【46】这样的专业资料库已经被开发出来，供使用事件溯源的应用使用，但总的来说，这种方法独立于任何特定的工具。传统的资料库或基于日志的讯息代理也可以用来构建这种风格的应用。
#### 从事件日志中派生出当前状态
事件日志本身并不是很有用，因为使用者通常期望看到的是系统的当前状态，而不是变更历史。例如，在购物网站上，使用者期望能看到他们购物车里的当前内容，而不是他们购物车所有变更的一个仅追加列表。