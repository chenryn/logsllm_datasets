# Round-Trip Latencies During Link Failure

The following data points represent the round-trip latencies (in seconds) experienced by packets through a diamond topology during a link failure:

- 0.5 seconds
- 1 second
- 1.5 seconds
- 2 seconds
- 2.5 seconds
- 3 seconds
- 3.5 seconds

The number of flows is as follows:
- 100 flows
- 200 flows
- 400 flows
- 800 flows
- 1600 flows

**Figure 10: Round-trip latencies experienced by packets through a diamond topology during link failure.**

To ensure network resilience, we configured multiple disjoint paths for each flow. This setup allows the network to withstand a link failure. The latencies experienced by packets were measured by physically unplugging a link. As shown in Figure 10, the path reconverges within 40 milliseconds. However, a packet could be delayed up to one second while the Controller handles the surge of requests.

Our network policy allows the Controller to set up multiple disjoint paths when a flow is created. This enables faster convergence during failures, especially if the Switches detect a failure and switch to the backup flow entry. Although this feature has not been implemented in our prototype, it is planned for future development.

## Flow Table Sizing

We also explored the required size of the flow table in the Switch. Ideally, the Switch should be able to hold all currently active flows. In our Ethane deployment, the number of active flows never exceeded 500. With a table of 8,192 entries and a two-function hash table, we did not encounter any collisions. As shown in Figure 7, the LBL network, with 8,000 hosts, did not exceed 1,200 flows.

In practice, the number of ongoing flows depends on the Switch's position in the network. Edge Switches, which connect to a small number of hosts, will see a number of flows proportional to their fanout. Our deployed Switches, with a fanout of four, saw no more than 500 flows. A Switch with a fanout of 64 might see a few thousand active flows. Central Switches, on the other hand, are likely to see more active flows and may need to handle all active flows.

Based on these observations, we conclude that a Switch in a university-sized network should have a flow table capable of holding 8K–16K entries. If each entry is 64 bytes, such a table requires about 1MB of storage, or up to 4MB if a two-way hashing scheme is used. In comparison, a typical commercial enterprise Ethernet switch holds 1 million Ethernet addresses (6MB), 1 million IP addresses (4MB of TCAM), 1-2 million counters (8MB of fast SRAM), and several thousand ACLs (more TCAM). Thus, the memory requirements of an Ethane Switch are relatively modest.

To further explore the scalability of the Controller, we tested its performance with simulated inputs. The Controller was configured with a policy file of 50 rules and 100 registered principles, with routes precalculated and cached. Under these conditions, the system could handle 650,845 bind events per second and 16,972,600 permission checks per second. The complexity of these operations grows linearly with the number of rules.

## Ethane’s Shortcomings

Deploying a new architecture into legacy networks without changing the end-hosts presents several challenges:

### Broadcast and Service Discovery
Broadcast discovery protocols (e.g., ARP, OSPF neighbor discovery) generate significant overhead traffic, constituting over 90% of the flows in our network. VLANs are often used to control broadcast traffic, but unless Ethane can interpret the protocol and respond, it must broadcast the request to all potential responders, leading to high traffic and potential security risks. A standard way to register services, as proposed by SANE [12], would eliminate this issue.

### Application-layer Routing
Ethane relies on end-hosts to follow network policies, but it cannot prevent higher-layer communications from violating these policies. For example, if A is allowed to talk to B but not C, and B can relay messages from A to C, the policy is compromised. This problem is difficult to solve and may require changes to the operating system and virtual machines.

### Transport Port Numbers
Ethane assumes that transport port numbers indicate user activity, but malicious users can use non-standard ports or tunnel applications over common ports like 80. While this is a persistent issue, application proxies can be inserted along the path using Ethane’s waypoint mechanism.

### Spoofing Ethernet Addresses
Ethane Switches rely on the binding between a user and Ethernet addresses. If a user spoofs a MAC address, they might trick Ethane into delivering packets to an unauthorized host. This can be prevented by ensuring each Switch port connects to only one host or by using 802.1X and link-level encryption mechanisms.

## Related Work

Ethane aligns with the 4D philosophy of simplifying the data-plane and centralizing the control-plane. Unlike 4D, Ethane supports fine-grained policy management based on flows. By moving all flow decisions to the Controller, Ethane can add new functions and features through software updates.

Ipsilon Networks proposed caching IP routing decisions as flows, similar to Ethane’s use of flows for forwarding. However, Ethane extends this to include security features like address swapping and enforcing outgoing initiated flows.

Distributed firewalls declare policy centrally and enforce it at each end-host. Ethane differs by not trusting end-hosts to enforce filtering, providing maximal defense in depth and network-level guarantees.

Pol-Eth, Ethane’s policy language, is inspired by predicate routing (PR) and extends it by making users first-class objects and supporting group declarations and multiple connectivity constraints.

VLANs are commonly used for segmentation and isolation but are difficult to manage. Ethane aims to replace VLANs with simpler control over isolation, connectivity, and diagnostics.

Identity-Based Networking (IBN) custom switches and secure AAA servers allow high-level policy declaration but generally lack control over the network data-path and rely on end-host enforcement.

## Conclusions

Building and deploying Ethane provided valuable insights. We found it easier to manage the network than expected, with the ability to add new Switches, users, and protocols quickly. Centralized policy management and journaling of registrations and bindings enabled us to identify and address network issues and malicious flows.

Adding new features, such as extending the policy language, introducing new routing algorithms, and adding application proxies, was straightforward. Ethane’s simplicity and ease of innovation make it a promising solution for network management. The Controller can scale to support large networks, and Switches can be built in various ways, from software to custom ASICs.

Future innovations in Switch design, such as multiple queues, could enhance functionality. Overall, Ethane’s simplicity, scalability, and ease of innovation make it a compelling solution for modern network management.

**Acknowledgments**
We thank Tal Garfinkel, Greg Watson, Dan Boneh, Lew Glendenning, John Lockwood, and Aditya Akella for their valuable input. David Mazières, Nickolai Zeldovich, Jennifer Rexford, Sharon Goldberg, and Changoon Kim provided helpful feedback on early drafts. We also thank Anja Feldman for her guidance. This work was supported by the National Science Foundation under Grant No. CNS-0627112 (The 100x100 Clean Slate Program), from the FIND program with funding from DTO, and the Stanford Clean Slate program. Martín Casado was funded by a DHS graduate fellowship.

**References**
[References listed as in the original text]