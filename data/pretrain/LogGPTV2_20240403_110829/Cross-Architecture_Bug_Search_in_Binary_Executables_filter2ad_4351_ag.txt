### Inlined Functions and Instruction Reordering

Even when target programs do not exhibit inlining, our approach can still identify multiple counterparts in non-inlined target programs by leveraging the multiple initial basic block matches in our BHB (Best-Hit-Broadening) algorithm.

#### Instruction Reordering
Compilers may reorder independent computations to enhance data locality. This reordering changes the syntactic assignment formulas in the intermediate representation (IR). However, the input/output (I/O) pairs remain the same, as altering them would change the semantics of the basic block. By comparing code semantics, our system effectively handles instruction reordering without additional overhead.

### Semantics vs. Syntax

Our approach focuses on semantics rather than syntax. For example, calling conventions are largely irrelevant to our method. We abstract from specific register names, making it unimportant which registers or memory addresses are used to pass parameters or return results. While comparing the syntax of IR representations would be problematic, hashing sampled I/O pairs allows us to ignore register names entirely.

### Compiler Idiosyncrasies

This list of compiler idiosyncrasies is not exhaustive, but covering all of them is beyond the scope of this discussion. Some optimizations, such as loop unrolling and dead code elimination, modify the control flow graph (CFG) and can be problematic if they affect the bug signature. However, our evaluation shows that our system performs well in realistic settings and implicitly covers many optimization cases. Most of the experiments in Section IV were based on real-world binaries compiled by various vendors, demonstrating the robustness of our approach in heterogeneous build environments.

### Scalability

All experiments were conducted in a single process/thread without parallel computing. The k-MinHash algorithm, which yields the best results, significantly degrades performance, which can be problematic when searching for multiple signatures in a large database of binaries. A potential solution is to use computationally cheaper algorithms (e.g., Single-MinHash) first and then re-process high-ranking results with k-MinHash. Additionally, most computations can be parallelized at the basic block level, reducing runtime by orders of magnitude on commodity servers. Notably, the most compute-intensive parts, such as translating binaries, sampling, and hashing, need to be performed only once per binary. The matching phase, which must be run once per search, can also be parallelized.

### Related Work

To the best of our knowledge, we are the first to propose a strategy for comparing binary code across different architectures. Our work differs from other similar use cases (e.g., bug finding) because we operate under more challenging conditions (e.g., without source code or across multiple architectures).

#### Code Similarity
- **CCFINDER** [22] finds equal suffix chains of source code tokens.
- **DECKARD** [18] uses abstract syntax trees and local sensitive hashes to find similar subtrees.
- **Yamaguchi et al.** [42] extend this concept with text mining to extrapolate vulnerabilities and detect missing checks.
- **REDEBUG** [17] is a scalable system to find unpatched code clones in many programming languages.

These approaches require source code and thus cannot aid in comparing binary software, especially closed-source software.

#### Binary Code Similarity
- **BINHUNT** [13] and **IBINHUNT** [29] use symbolic execution and theorem proving to show semantic equivalence but are limited to x86.
- **BINJUICE** [24] translates basic blocks into syntactic equations and hashes them, but fails across CPU architectures.
- **BINHASH** [20] relies on I/O behavior but does not support multiple architectures and lacks sub-function granularity.
- **EXPOSÃ‰** [32] uses a theorem prover for function-level matching but assumes a single calling convention.

Concurrently, **BLEX** [11] matches functions by executing them with a low number of contexts, but it is limited to x64 and function-level matching.

#### Identifying Previously-Unknown Bugs
- **AEG** [2] and **COVERITY** [4] use symbolic execution and static analysis to find vulnerabilities but have limitations.
- **Shankar et al.** [35] and **Johnson and Wagner** [21] use type inference to detect format string vulnerabilities.
- **Miller et al.** [28] and **Livshits and Lam** [25] use blackbox fuzzing and tainting to find vulnerabilities.
- **MAYHEM** [6] is an efficient symbolic execution engine for finding previously-unseen bugs at the binary level.

These tools often require an operational environment and are tailored to specific bug classes, whereas our approach is focused on re-finding known bugs in different binary software.

### Conclusions

We have demonstrated that semantic binary code matching is feasible across CPU architectures under practical assumptions. This advances prior research, which was limited to single-architecture comparisons. Our novel metric allows for fine-grained code comparison and has been successfully applied to identify real-world vulnerabilities in closed-source software. With the rise of closed-source software on various architectures, our approach can greatly assist in finding future vulnerabilities in binaries compiled for any architecture.

### Acknowledgment

This work was supported by ERC Starting Grant No. 640110 (BASTION) and the German Research Foundation (DFG) research training group UbiCrypt (GRK 1817).

### References

[References listed here, formatted as in the original text]

---

This revised version aims to improve clarity, coherence, and professionalism while maintaining the technical depth and accuracy of the original content.