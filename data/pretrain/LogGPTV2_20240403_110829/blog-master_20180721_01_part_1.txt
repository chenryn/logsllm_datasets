## PostgreSQL 批量SQL before/after for each row trigger的触发时机、性能差异分析、建议 - 含9.4 , 10版本    
### 作者                                                               
digoal                                                               
### 日期                                                               
2018-07-21                                                             
### 标签                                                               
PostgreSQL , trigger , row , statement , before , after , s_lock         
----                                                               
## 背景        
数据库触发器的触发时机，性能，高并发批量导入时，触发器的性能如何？    
批量导入时，before, after触发器在for each row模式下，触发机制如何，什么时候开始条到触发器指定的function中进行运算？      
1、before for each row，在数据落目标表前，被触发，同时返回的内容（TUPLE）被REPLACE到对应的数据文件存储。触发器必须明确返回```NEW```。       
```    
以insert为例    
insert request to HEAP table -> 每一row立即generate NEW -> before trigger(s) -> return NEW -> write tuple to HEAP table    
```    
2、after for each row，在数据落到目标表之后，再被触发(如果是批量写入，那么会等批量写入结束后，才开始触发after trigger procedure)。after tirgger procedure返回什么值都无所谓，因为用不上。after for each row建议触发器返回null。    
```    
以insert为例    
insert request to HEAP table -> write tuple to HEAP table -> 所有row一次性generate NEW -> after trigger(s) -> return NULL    
```    
到底哪个性能好？    
## 测试    
测试场景参考    
[《PostgreSQL 流式处理应用实践 - 二手商品实时归类(异步消息notify/listen、阅后即焚)》](../201807/20180713_03.md)      
[《PostgreSQL 批量SQL before/after for each row trigger的触发时机、性能差异》](../201807/20180721_01.md)    
1、建表    
```    
create table a (          
  id int8 primary key,   -- 商品ID          
  att jsonb   -- 商品属性          
);    
```    
2、建结果表    
```      
create table t_result(id serial8 primary key, class text, content text);        
```     
3、建merge json函数    
```    
create or replace function merge_json(jsonb, jsonb) returns jsonb as $$        
  -- select json_object_agg(key,value)::jsonb from (     -- 9.4   
  select jsonb_object_agg(key,value) from (        
  select         
    coalesce(a.key, b.key) as key,         
    case         
    when         
    coalesce(jsonb_array_element(a.value,1)::text::timestamp, '1970-01-01'::timestamp)         
    >         
    coalesce(jsonb_array_element(b.value,1)::text::timestamp, '1970-01-01'::timestamp)         
    then a.value        
    else b.value        
    end        
  from jsonb_each($1) a full outer join jsonb_each($2) b using (key)        
  ) t;          
$$ language sql strict ;        
```    
## 批量，并发数据写入性能对比(before, after, no trigger)    
1、创建dblink插件    
```    
create extension dblink;    
```    
2、建立断开连接的函数，目的是不抛异常。    
```    
create or replace function dis_conn(name) returns void as $$    
declare    
begin    
  perform dblink_disconnect($1);    
  return;    
exception when others then    
  return;    
end;    
$$ language plpgsql strict;    
```    
3、创建连接函数接口    
```    
CREATE OR REPLACE FUNCTION public.conn(name, text)    
 RETURNS void    
 LANGUAGE plpgsql    
 STRICT    
AS $function$                
declare                
begin                
  perform dis_conn($1);      
  perform dblink_connect($1, $2);               
  return;                
exception when others then                
  return;                
end;                
$function$;    
```    
4、创建并行，批量加载函数。 56个并行，每一批写入200万条数据。总共写入1.12亿行。    
```    
CREATE OR REPLACE FUNCTION public.get_res()    
 RETURNS SETOF record    
 LANGUAGE plpgsql    
 STRICT    
AS $function$          
declare          
  start_time timestamptz := clock_timestamp();    
  loops int := 55;    
  batchs int := 2000000;    
  -- 总数据量1.12亿    
begin          
  for i in 0..loops loop                 
    perform conn('link'||i,  'hostaddr=127.0.0.1 port='||current_setting('port')||' user=postgres dbname=postgres application_name=digoal_loader');               
    perform '1' from dblink_get_result('link'||i) as t(res text);                
    perform dblink_send_query('link'||i, format($_$    
    insert into a select         
    id, '{"price":[10000, "2018-01-01 10:10:11"]}'    
    from generate_series(%s,%s) t(id)    
    on conflict (id)        -- 9.4 注释掉 这行  
    do update set           -- 9.4 注释掉 这行  
    att = merge_json(a.att, excluded.att)      -- 9.4 注释掉 这行  
    $_$, i*batchs, (i+1)*batchs-1));                
  end loop;             
  for i in 0..loops loop          
    return query select extract(epoch from clock_timestamp()-start_time)::text from dblink_get_result('link'||i) as t(res text);    
  end loop;          
end;          
$function$;    
```    
### after trigger for each row    
当一条SQL写入a完成后，触发after触发器，开始处理每行。      
1、建触发器函数，用于处理每一行原始数据，包括50个处理逻辑.    
```          
CREATE OR REPLACE FUNCTION notify1() returns trigger          
AS $function$          
declare          
begin          
  if jsonb_array_element(NEW.att->'price', 0)::text::float8 > 100 then   -- 规则1， 价格大于100，写入结果表          
     insert into t_result(class,content) values (        
       'a',    -- 归类        
       format('CLASS:high price, ID:%s, ATT:%s', NEW.id, NEW.att)   -- 消息内容          
     );          
  end if;         
  -- 模拟多轮判断    
  for i in 1..49 loop    
    if jsonb_array_element(NEW.att->'price', 0)::text::float8 > 100 then   -- 规则xx        
      null;         
    end if;        
  end loop;    
  return null;    -- aster 触发器    
  -- return NEW;  -- BEFORE 触发器    
end;          
$function$ language plpgsql strict;          
```          
2、创建after insert or update触发器          
```          
create trigger tg1 after insert or update on a for each row execute procedure notify1();     
```          
3、写入单条，测试    
```    
insert into a values           
  (1, '{"price":[10000, "2018-01-01 10:10:11"]}')           
  on conflict (id)           
  do update set           
  att = merge_json(a.att, excluded.att)     -- 合并新属性，保留老属性，需要使用一个UDF来合并          
;      
```    
4、调用并行接口，批量并发写入    
```    
select * from get_res() as t(id text);      
```    
5、你会发现，数据是在写入完成后，才开始逐行处理触发器内部逻辑。    
目标表在写入，但是trigger并没有处理，因此结果表还没有看到任何记录    
```    
以insert为例    
insert request to HEAP table -> write tuple to HEAP table -> 所有row一次性generate NEW -> after trigger(s) -> return NULL    
```    
```    
postgres=# \dt+ a|t_result    
                    List of relations    
 Schema | Name | Type  |  Owner   |  Size   | Description     
--------+------+-------+----------+---------+-------------    
 public | a    | table | postgres | 3560 MB |     
 public | t_result | table | postgres | 8192 bytes |     
postgres=# \dt+ a    
                    List of relations    
 Schema | Name | Type  |  Owner   |  Size   | Description     
--------+------+-------+----------+---------+-------------    
 public | a    | table | postgres | 3603 MB |     
 public | t_result | table | postgres | 8192 bytes |     
```    
6、数据量：1.12亿条    
总耗时：    
(主要慢在trigger内部的逻辑处理)    
1367 秒。      
### before trigger for each row    
before触发器，在数据落盘前，触发before trigger function    
1、建触发器函数，用于处理每一行原始数据，包括50个处理逻辑.    
```          
CREATE OR REPLACE FUNCTION notify1() returns trigger          
AS $function$          
declare          
begin          
  if jsonb_array_element(NEW.att->'price', 0)::text::float8 > 100 then   -- 规则1， 价格大于100，写入结果表          
     insert into t_result(class,content) values (        
       'a',    -- 归类        
       format('CLASS:high price, ID:%s, ATT:%s', NEW.id, NEW.att)   -- 消息内容          
     );          
  end if;         
  -- 模拟多轮判断    
  for i in 1..49 loop    
    if jsonb_array_element(NEW.att->'price', 0)::text::float8 > 100 then   -- 规则xx        
      null;         
    end if;        
  end loop;    
  -- return null;    -- aster 触发器    
  return NEW;  -- BEFORE 触发器    
end;          
$function$ language plpgsql strict;          
```          
2、创建before insert or update触发器          
```          
drop trigger tg1 on a;    
create trigger tg1 before insert or update on a for each row execute procedure notify1();     
```          
3、调用并行接口，批量并发写入    
```    
truncate a;  
truncate t_result;  
select * from get_res() as t(id text);      
```    
4、写入过程中查看    
你会发现，目标表和结果表同时在增长，因为    
```    
以insert为例    
insert request to HEAP table -> 每一row立即generate NEW -> before trigger(s) -> return NEW -> write tuple to HEAP table    
```    
```    
postgres=# \dt+ a|t_res*    
                      List of relations    
 Schema |   Name   | Type  |  Owner   |  Size  | Description     
--------+----------+-------+----------+--------+-------------    
 public | a        | table | postgres | 335 MB |     
 public | t_result | table | postgres | 387 MB |     
(2 rows)    
```    