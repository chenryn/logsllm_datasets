conﬁdentiality policy if it acts for a reader or owner of the
policy; it is trusted to enforce an integrity policy if it acts for
a writer or an owner of the policy.
3.5. Orderings on labels
The acts-for relation (cid:60) gives rise to an information-
ﬂow ordering ordering on labels. The ordering (cid:96)1 (cid:118) (cid:96)2
captures when ﬂow from label (cid:96)1 to label (cid:96)2 is secure.
We say “(cid:96)1 can ﬂow to (cid:96)2” or “(cid:96)1 is less restrictive
than (cid:96)2”. For example,
if Bob acts for Alice.friends,
then Alice → Alice.friends (cid:118) Alice → Bob be-
cause
can learn information labeled
fewer principals
Alice → Bob than could have learned information labeled
Alice → Alice.friends.
The ordering (cid:96)1 (cid:118) (cid:96)2 is used when checking information
ﬂow within Fabric programs, both at compile time and at run
time. For example, when assigning from a variable with label
(cid:96)1 to one with label (cid:96)2, this ordering must hold.
3.6. Declassiﬁcation and endorsement
In general, the ordering (cid:118) only approximates the true infor-
mation security requirements of an application, so sometimes
it prevents ﬂows that applications need. DIFC systems such
as Fabric allow these ﬂows using downgrading operations.
Declassiﬁcation is a downgrading operation which removes
conﬁdentiality policies; endorsement is one that adds integrity
policies.
Fabric programs must explicitly specify declassiﬁcation
and endorsement. Additionally, all policy-downgrading code
is marked with an authority clause that speciﬁes the principal
authorizing the downgrade. This principal must act for the
Fig. 2: Trust relationships in the FriendMap example.
separate principal (e.g., Alice.friends and Bob.friends)
representing the group of their friends, and that principal
delegates to each friend’s principal. Similarly, each user has a
principal (e.g., Alice.locGrp and Bob.locGrp) represent-
ing the group of principals who can learn the user’s location.
The acts-for relation is transitive: if p (cid:60) q and q (cid:60) r then
p (cid:60) r. This allows policy changes to be implemented using
small changes in the acts-for hierarchy. For example, Bob
might decide that all of his friends should be able to read
his location. He can implement this by making Bob.locGrp
delegate to Bob.friends, as depicted in Figure 2. Since
Alice (cid:60) Bob.friends, this immediately implies that Alice
(cid:60) Bob.locGrp, allowing Alice to read Bob’s location.
The acts-for relationship is also used to express trust
in Fabric nodes. The roots of trust
in Fabric are X.509
certiﬁcates [13] published by nodes. These certiﬁcates include
the node’s hostname and the oid of its principal object.
The set of principals generates a lattice ordered by (cid:60). The
top principal (cid:62) acts for all other principals, and all principals
act for the bottom principal ⊥.
3.4. Labels
Fabric programs express security policies using labels.
Labels are drawn from the decentralized label model
(DLM) [25], and express policies in terms of principals.
Every object in Fabric has an object label describing the
conﬁdentiality and integrity of its contents. This label is stored
persistently with the object, and constrains how information
can ﬂow via the object. Information whose conﬁdentiality is
too high or whose integrity is too low cannot be stored in
the object, and information from the object cannot ﬂow to a
location whose conﬁdentiality is too low or whose integrity
is too high. Labels are part of types, and compile-time label
checking controls information ﬂow within programs with ﬁne
granularity.
To support the decentralization of information-ﬂow poli-
cies, each policy in a label is owned by a principal. A label
is a set of such owned policies. For example, Bob might
protect information about his location by the conﬁdentiality
policy Bob→Bob.locGrp. This policy states that Bob owns
194
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:46:49 UTC from IEEE Xplore.  Restrictions apply. 
SnappAliceBobAlice.friendsBob.friendsAlice.locGrpBob.locGrpMapServFriendMapincreasing trustowner of any policy that is weakened. Further, declassiﬁcation
and endorsement may only happen in code whose control ﬂow
is unaffected by low-integrity information. This rule enforces
robust downgrading [2], which prevents the adversary from
causing these operations to be misused.
The program-counter label, pc [23],
identiﬁes the in-
formation that
inﬂuences whether a given program point
is reached. The Fabric type system requires that the left-
hand sides of assignments have labels higher than pc in
the information-ﬂow ordering. For conﬁdentiality, this rule
prevents information from leaking through implicit ﬂows [8].
It is also crucial for integrity, where it prevents untrusted data
from indirectly inﬂuencing trusted data.
3.7. Adversaries
Every Fabric principal views every untrusted principal as
a potential adversary, so who the adversary is depends on
whom you ask. In the FriendMap example, the FriendMap
application provider is treated as an adversary since no one
trusts it. Similarly, Snapp and MapServ do not delegate to
anyone, so they consider everyone to be adversaries. For
simplicity, we assume that Alice and Bob delegate to Snapp,
so Snapp is not an adversary for them.
Fabric’s goal is to ensure that the security of a principal
does not depend on any part of the system that it considers
to be an adversary. This is called the decentralized security
principle. More precisely, the security of an object, expressed
by the policies in its label, should only depend on system
components that are trusted to enforce those policies. Thus,
the integrity of an object with label (cid:96) should be unaffected
by an adversary A unless A (cid:60) I((cid:96)), and its conﬁdentiality
should be unaffected unless A (cid:60) C((cid:96)).
In a decentralized system, there is no single trusted comput-
ing base (TCB). In fact, the decentralized security principle
generalizes TCBs, because each label (cid:96) has its own trusted
computing base, consisting of the enforcement mechanisms
on nodes n where n (cid:60) (cid:96). The decentralized security principle
is also more precise than TCBs, since it deﬁnes which security
policies (cid:96) may be violated if some set of components is
compromised.
4. An architecture for secure mobile code
The challenge of Mobile Fabric is to maintain the strong
yet decentralized security guarantees of Fabric while giving
adversaries the power to upload and execute mobile code. To
address this challenge, we add several new components to the
system architecture, depicted in Figure 4. As in Fabric, infor-
mation is stored in persistent objects that can refer to each
other. Unlike in Fabric, code can also be stored persistently
at stores, and downloaded and executed by workers. We will
call code stored in Fabric class objects (not to be confused
with Java class objects). Each object contains a reference to
a class object, which deﬁnes its structure and behavior.
Fig. 4: Compiling, linking and loading mobile code
4.1. Producing mobile code
These new class objects are created and loaded onto stores
by Fabric workers. In particular, the Mobile Fabric compiler
and linker are themselves Fabric programs that code providers
can invoke to turn source code into Fabric objects. This
process is depicted in the “Developer” portion of Figure 4.
A novel feature of this design is placing information-ﬂow
policies on class objects. Like other objects stored in Fabric,
class objects are given labels. These labels are essential for
preventing adversaries from using mobile code to compromise
integrity and conﬁdentiality.
The code for a class can mention other classes, hence
it
the meaning of a class depends on other classes that
names. Unlike in many other mobile-code platforms such as
JavaScript and Java, the binding between names and classes is
deﬁned by the code developer when the class is published. We
call this linkage speciﬁcation a codebase. Each class object
speciﬁes its codebase.
Mobile Fabric extends the Fabric language to enable both
compile-time and run-time reasoning about the trust that can
be placed in code. Class source can explicitly refer to the
provider label of any class, including its own, using the name
provider. The provider label can appear in label annotations
checked at compile time, and can also be compared to other
labels at run time. Code is label-checked without making
any assumptions about the provider label. This forces all
assumptions about the code’s provider to be made explicit in
the source code so that the same source code can be securely
reused, relinked, or provided by different principals.
4.2. Executing mobile code
Code is executed at worker nodes. In the original Fabric
system, workers stored all code locally and implicitly trusted
195
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:46:49 UTC from IEEE Xplore.  Restrictions apply. 
DeveloperUsercheckernew classsourcecodeveriﬁerclassobjectexecutablecodepersistentdistributed objectsclassobjectnew classobjectscodelinkerloaderit. In Mobile Fabric, workers may also fetch code from class
objects that are themselves stored in Fabric, as shown in the
“User” portion of Figure 4.
Workers load the code for a class when an instance of
that class is ﬁrst fetched from a store or when the class is a
dependency of another class being loaded. The worker fetches
the class object and veriﬁes the information ﬂows within
the class’s code. Finally, it converts the class into executable
bytecode, thus allowing methods on the class to be invoked.
4.3. Threat model
An important component of any security architecture is
the threat model, which deﬁnes the power of the adversary.
Mobile Fabric allows a powerful adversary—one that is even
more powerful than in Fabric. Therefore, security assurance
is in some ways stronger than in the prior system.
As discussed in Section 3, any principal may be considered
an adversary, so we deﬁne the power of adversaries in terms
of untrustworthy principals. Since the system should be secure
from the viewpoint of every participating principal p, the
adversary is some principal A where A (cid:54)(cid:60) p. Therefore, we
can analyze security assuming an arbitrary but unspeciﬁed
principal A. All of the security mechanisms are designed
to enforce security regardless of the particular choice of
adversary.
From the viewpoint of principal p, a node n might be
controlled by the adversary if n (cid:54)(cid:60) p. This untrusted node
need not be running the Mobile Fabric implementation and
can therefore violate its rules. The node might participate
incorrectly in the low-level protocols that
the
system. It might view or leak any keys or messages that
adversary-controlled nodes receive, and it can read and update
any state on any other node it acts for. We do assume
that the adversary cannot fabricate cryptographic signatures
or decrypt messages without the appropriate private keys;
therefore, trustworthy nodes can communicate with each other
over authenticated private channels.
implement
Our goal is to allow secure interaction despite distrust, so
adversaries are able to read and update certain objects stored
at trustworthy nodes. In particular, a node n allows a node
a to read an object with low-conﬁdentiality labels (cid:96); that is,
if a (cid:60) C((cid:96)). This read is allowed even if n considers a an
adversary. Similarly, n allows a to update objects with low-
integrity labels (a (cid:60) I((cid:96))).
Class objects containing mobile code are particularly im-
portant examples of objects adversaries can affect. Adver-
saries can provide mobile code to trustworthy nodes, as long
as the code has a low integrity label. The challenge is to
prevent this code from compromising security.
Adversaries can also try to use remote calls to invoke
methods on trustworthy nodes. These calls are allowed only
if the initial pc label of the method is low-integrity.
Fabric uses SSL for communication, providing some pro-
tection against network adversaries. We therefore assume that
adversaries cannot tamper with network messages and that
they do not learn anything about the contents of network
messages unless they control the intended recipient. Because
network destinations are visible in network packets,
the
adversary might be able to learn something from the existence
of a message, its source and destination, its size, or its timing.
We ignore these trafﬁc analysis channels, as do most systems.
Fake trafﬁc might mitigate these channels, though at a cost.
As in most work on distributed system security, timing,
termination [31], and progress channels [1] are largely ig-
nored. Termination and progress channels might be justiﬁ-
ably ignored because they have low bandwidth, but timing
channels can have high bandwidth. There are two kinds of
timing channels: external and internal [32]. We do not attempt
to control covert external timing channels in this work; in
other words, adversarial nodes are assumed not to time when
messages arrive. Run-time mitigation methods (e.g., [15, 39]),
might be useful for limiting the bandwidth of these channels.
Internal
timing channels arise when code running within
the system measures time, either explicitly or implicitly by
constructing a race among concurrent threads. Fabric does
not support ﬁne-grained concurrency; a top-level transaction
must be sequential. Races between threads therefore involve
external communication with a store, and can be considered
external timing channels.
5. Securing mobile code
In the original Fabric system, workers trust all code they
execute. Since adversaries can provide code to workers in
Mobile Fabric, two key assumptions about code are inval-
idated: that all code goes through type checking and label
checking to ensure its information ﬂows are secure, and that
code is provided by a trusted entity. Fabric also assumes
certain vulnerabilities arising from inconsistent objects and
read channels can be ignored safely because they are hard to
exploit without the complicity of trusted nodes.
In this section, we analyze the vulnerabilities inherent in
systems supporting mobile code and present our solutions for
preserving the security of Mobile Fabric using information
ﬂow control. These solutions are summarized in Figure 5,
which also serves as a roadmap to the remainder of this
section.
5.1. Label-checking mobile code
We cannot be sure that code dynamically loaded by workers
respects information-ﬂow policies. Therefore, at load time,
workers perform static label checking of all dynamically
loaded mobile code. Because type checking and label check-
ing are modular, this analysis can be performed whenever a
new class is encountered.
Code must be stored by Mobile Fabric in a form that
permits accurate static analysis. In the current prototype, code
is stored and loaded as source—like JavaScript but unlike
Java. Storing code as source is not essential to the design, and
other code formats such as abstract syntax trees or annotated
bytecode are possible.
196
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:46:49 UTC from IEEE Xplore.  Restrictions apply. 
• Mobile-code label checking (§5.1).
– adversary-provided code creates no insecure informa-
tion ﬂows within trustworthy nodes
• Provider-bounded label checking (§5.2)
– untrusted code cannot corrupt high-integrity informa-
tion or downgrading decisions
– conﬁdential code cannot affect public output
• Type ﬁngerprint checking for remote calls (§5.4)
integrity and conﬁdentiality restrictions
– information ﬂows caused by remote calls comply with
• Type ﬁngerprint checking when objects are loaded (§5.5)
– the dynamic types (including information-ﬂow labels)
of objects are consistent with the static type.
• Access label checking (§5.6)
– information ﬂows caused by fetching objects comply
with conﬁdentiality restrictions
Fig. 5: Summary of the novel dynamic checks that trustworthy nodes
perform, and the invariants they preserve. These invariants enforce
the decentralized security requirements of Mobile Fabric.
1 String{user←user} password;
2 void initialize_password{user←user}() {
3
4 }
password = "init";
Fig. 6: Mobile code creating a vulnerability
Code is trusted if the user completely trusts the code
provider. According to the decentralized security principle,
the user can load such code without analyzing it. To accelerate
loading and execution, trusted code can be loaded as bytecode
or even as machine code.
5.2. Provider-bounded label checking
Label checking ensures all ﬂows in code obey the
information-ﬂow ordering, but this is not enough to stop
adversary-provided code from introducing vulnerabilities. For
example, a method like that in Figure 6 type-checks, because
only high-integrity information appears to inﬂuence the high-
integrity variable password: the literal init, and the fact that
the method was called, which is captured by the pc label at
the call site. The literal init is considered trusted because
the code is trusted, whereas pc at the call site is constrained
by the initial pc label of the method (the “begin label” [23]),
which in this case is trusted: {user←user}.
However, if the adversary convinces a trusted worker node
to use this code, it might be used to change the password, a
clear security vulnerability.
To solve this problem, we extend the program-counter (pc)
mechanism. With respect to a given adversary A, a high-
conﬁdentiality context is a part of the program about whose
execution the adversary is not trusted to learn: A (cid:54)(cid:60) C(pc). A
low-integrity context is a part of the program whose execution
the adversary can affect: A (cid:60) I(pc). In either case, security
197
requires restricting how information ﬂows out of the context,
so we refer to either sort of context as a high context.
The key to preventing attacks like that in Figure 6 is to
treat the code itself as information that affects the results
it produces. Therefore code is stored with an information-
ﬂow label (the provider label) that bounds the inﬂuence of
the adversary on the code. In fact, this label is precisely the
object label of the class object.
To constrain untrusted code, we join the provider label into
the pc label. This makes sense because the code provider
affects the statements that are executed. If the code of Figure 6
is provided by an adversary, its low-integrity provider label
will effectively make the pc label low-integrity, preventing
any assignments to high-integrity variables such as the pass-
word. We refer to this analysis as provider-bounded label
checking.
The provider label also enforces robust downgrading, be-
cause it prevents the adversary from exploiting downgrading
to affect conﬁdentiality and integrity. A provider label with
low integrity prevents the adversary from using declassiﬁ-