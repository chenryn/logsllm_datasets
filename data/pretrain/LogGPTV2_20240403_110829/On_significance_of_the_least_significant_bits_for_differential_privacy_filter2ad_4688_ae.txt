nation of user-provided and trusted codebase, such as Aira-
vat’s user-speciﬁed mappers and system reducers. For both
codebases, subtleties of ﬂoating-point arithmetic may dra-
matically increase sensitivity of the outcome, beyond what
mathematical analysis of the underlying mathematical ab-
straction would suggest.
Consider the following natural example of an aggregation
operator: f (x1, . . . , xn) ,
n
i=1 xi. If the sensitivity of in-
put is 1, i.e., a single user may change at most one input
variable xi by at most 1, then the sensitivity of f is obvi-
ously at most 1. However, f ’s implementation in ﬂoating-
point arithmetic, denoted by f
, has much higher sensitivity
as demonstrated by the following example:
∑
∗
−23, . . . , xn = −2
−23.
Not surprisingly,
∗
f
(x1, . . . , xn) =
xi = 230 − 230 · 2
−23 = 230 − 128.
n = 230 + 1,
x1 = 230,
x2 = −2
n∑
i=1
Let x
1 ⊕ x2
′
′
′
1 = x1 + 1. Since ulp(x
1) = 2
1⊕x2)⊕x3 will again produce
′
′
will result in x
1, computing (x
′
x
1, etc. In this case
−22, computing x
∗
′
′
1 = 230 + 1.
1, x2, . . . , xn) = x
f
(x
∗
The sensitivity of f
—a ﬂoating-point realization of f —on
this pair of inputs is 129 rather than 1. This is a manifes-
tation of the accumulated error phenomenon, which can be
counteracted by application of the Kahan summation algo-
rithm [22, 20]. More complex mechanisms are likely to ex-
hibit similar behavior on adversarially-chosen inputs, com-
plicating the task of validating their privacy claims.
7. RELATED WORK
Modulating the lower order bits of transmitted data is a
well-documented covert channel mechanism, whose primary
use is to enable communication between processes which are
otherwise not allowed to exchange information [25, 16].
The main diﬀerence between our attack and well-known
covert channels is in the intent of the transmitting party. All
platforms surveyed in Section 3 accept untrusted code and
have to confront the threat of covert communications. An
example of a timing attack, to which PINQ and Airavat are
vulnerable, and Fuzz and GUPT explicitly address, involves
a query that takes inordinate amount of time when it is
evaluated on some particular record. Measuring timing of
the response leaks information about the input.
The attack described in this paper does not require ad-
versarial code, or any active malicious intent. Any textbook
implementation of the ﬂoating-point Laplacian mechanism
is potentially vulnerable.
Fixed-point or integer-valued algorithms are immune to
our attack. Examples of such mechanisms include diﬀer-
entially private computations in a distributed setting [11],
privacy-preserving billing and aggregation [5, 24].
The snapping mechanism is closely related to the mecha-
nism proposed by Dodis et al. [7], which defends against an
adversary who exerts some control over the source of ran-
domness. The adversary in this model is capable of introduc-
ing arbitrary bias into the source, as long as each subsequent
bit has some constant entropy conditioned on all previously
output bits. In particular, the bias may depend on the previ-
ous bits and the description of the mechanism. The model is
known as the Santha-Vazirani source [40], and was shown to
imply negative results for existence of certain cryptographic
tasks [29, 8].
In contrast with Dodis et al., we assume a
perfect source of randomness but model inaccuracies due to
use of ﬂoating-point arithmetic.
8. CONCLUSIONS
Floating-point arithmetic is a notoriously leaky abstrac-
tion, which is diﬃcult to argue about formally and hard
to get right in applications. Non-associativity of basic arith-
metic operations, compounding errors, rounding rules, signed
zeros, denormals, NaNs, inﬁnities, CPU ﬂags, and hardware
bug are complicated enough even in the absence of security
concerns.
We initiate study of adapting ﬂoating-point algorithms
to applications in diﬀerential privacy. We describe a prac-
tical, eﬃcient attack on a textbook implementation of the
Laplacian mechanism that underlies all existing platforms
for general purpose diﬀerentially private computations.
We describe and prove a post-processing snapping proce-
dure, which does not perceptible increase the error intro-
duced by the Laplacian mechanism. The snapping mech-
anism is also known to preserve diﬀerential privacy when
instantiated with a class of weak sources of randomness.
In conclusion we observe that ﬂoating-point arithmetic
presents a unique security challenge to developers of real-
world applications.
It is diﬀerent from convenient math-
ematical abstractions in ways that are, on the one hand,
complex and riddled with many corner- and special cases.
On the other hand, its common implementations are stan-
dard, predictable, and deterministic, so that these problem-
atic cases can be forced and exploited by the adversary.
9. ACKNOWLEDGMENTS
The author thanks Yevgeniy Dodis, Frank McSherry, Ben-
jamin Pierce, and Indrajit Roy for their support and valu-
able comments.
10. REFERENCES
[1] R. Bhaskar, A. Bhowmick, V. Goyal, S. Laxman, and
A. Thakurta. Noiseless database privacy. In D. H. Lee
and X. Wang, editors, Advances in
Cryptology—ASIACRYPT 2011, volume 7073 of
Lecture Notes in Computer Science, pages 215–232.
Springer, 2011.
[2] J. Blocki, A. Blum, A. Datta, and O. Sheﬀet. The
Johnson-Lindenstrauss transform itself preserves
diﬀerential privacy. In 53rd Symposium on
659Foundations of Computer Science (FOCS 2012). IEEE
Computer Society, 2012. To appear.
[3] K. Chaudhuri and C. Monteleoni. Privacy-preserving
logistic regression. In D. Koller, D. Schuurmans,
Y. Bengio, and L. Bottou, editors, Advances in Neural
Information Processing Systems 21 (NIPS), pages
289–296. Curran Associates, Inc., 2008.
[4] Correctly rounded mathematical library.
http://lipforge.ens-lyon.fr/www/crlibm/.
[5] G. Danezis, M. Kohlweiss, and A. Rial. Diﬀerentially
private billing with rebates. In Proceedings of the 13th
international conference on Information hiding, IH’11,
pages 148–162, Berlin, Heidelberg, 2011.
Springer-Verlag.
[6] F. de Dinechin, C. Q. Lauter, and J.-M. Muller. Fast
and correctly rounded logarithms in double-precision.
Theoretical Informatics and Applications,
41(1):85–102, 2007.
[7] Y. Dodis, A. L´opez-Alt, I. Mironov, and S. Vadhan.
Diﬀerential privacy with imperfect randomness. In
Advances in Cryptology—CRYPTO 2012, 2012. To
appear. Full
version http://eprint.iacr.org/2012/435.
[8] Y. Dodis, S. J. Ong, M. Prabhakaran, and A. Sahai.
On the (im)possibility of cryptography with imperfect
randomness. In FOCS ’04, pages 196–205. IEEE
Computer Society, 2004.
[9] C. Dwork. Diﬀerential privacy. Invited talk. In
M. Bugliesi, B. Preneel, V. Sassone, and I. Wegener,
editors, Automata, Languages and
Programming—ICALP (2), volume 4052 of Lecture
Notes in Computer Science, pages 1–12. Springer,
2006.
[10] C. Dwork. A ﬁrm foundation for private data analysis.
Commun. ACM, 54(1):86–95, 2011.
[11] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov,
and M. Naor. Our data, ourselves: Privacy via
distributed noise generation. In S. Vaudenay, editor,
Advances in Cryptology—EUROCRYPT 2006, volume
4004 of Lecture Notes in Computer Science, pages
486–503. Springer, 2006.
[12] C. Dwork, F. McSherry, K. Nissim, and A. Smith.
Calibrating noise to sensitivity in private data
analysis. In S. Halevi and T. Rabin, editors, Theory of
Cryptography Conference—TCC 2006, volume 3876 of
Lecture Notes in Computer Science, pages 265–284.
Springer, 2006.
[13] C. Dwork and K. Nissim. Privacy-preserving
datamining on vertically partitioned databases. In
M. K. Franklin, editor, Advances in
Cryptology—CRYPTO 2004, volume 3152 of Lecture
Notes in Computer Science, pages 528–544. Springer,
2004.
[14] T. Evans, L. Zayatz, and J. Slanta. Using noise for
disclosure limitation of establishment tabular data. J.
of Oﬃcial Statistics, 14(4):537–551, 1998.
[15] A. Ghosh, T. Roughgarden, and M. Sundararajan.
Universally utility-maximizing privacy mechanisms. In
M. Mitzenmacher, editor, Proceedings of the 41st
Annual ACM Symposium on Theory of Computing,
STOC 2009, pages 351–360. ACM, 2009.
[16] V. D. Gligor. A guide to understanding covert channel
analysis of trusted systems. Technical Report
NCSC-TG-030, National Computer Security Center,
Nov. 1993.
[17] D. Goldberg. What every computer scientist should
know about ﬂoating-point arithmetic. ACM
Computing Surveys, 23(1):5–48, Mar. 1991.
[18] A. Haeberlen, B. C. Pierce, and A. Narayan.
Diﬀerential privacy under ﬁre. In USENIX Security
Symposium. USENIX Association, 2011.
[19] M. Hardt, K. Ligett, and F. McSherry. A simple and
practical algorithm for diﬀerentially private data
release. CoRR, abs/1012.4763, 2010.
[20] N. J. Higham. Accuracy and Stability of Numerical
Algorithms. SIAM: Society for Industrial and Applied
Mathematics, 2nd edition, Aug. 2002.
[21] IEEE standard for ﬂoating-point arithmetic. Technical
report, Microprocessor Standards Committee of the
IEEE Computer Society, 3 Park Avenue, New York,
NY 10016-5997, USA, Aug. 2008.
[22] W. Kahan. Pracniques: further remarks on reducing
truncation errors. Commun. ACM, 8(1):40, Jan. 1965.
[23] D. E. Knuth. Seminumerical Algorithms, volume 2 of
The Art of Computer Programming. Addison-Wesley,
third edition, 1997.
[24] K. Kursawe, G. Danezis, and M. Kohlweiss.
Privacy-friendly aggregation for the smart-grid. In
S. Fischer-H¨ubner and N. Hopper, editors, PETS,
volume 6794 of Lecture Notes in Computer Science,
pages 175–191. Springer, 2011.
[25] B. W. Lampson. A note on the conﬁnement problem.
Communications of the ACM, 16(10):613–615, Oct.
1973.
[26] P. L’Ecuyer. SSJ: Stochastic simulation in Java.
http://www.iro.umontreal.ca/~simardr/ssj/
indexe.html.
[27] C. Li, M. Hay, V. Rastogi, G. Miklau, and
A. McGregor. Optimizing linear counting queries
under diﬀerential privacy. In J. Paredaens and D. V.
Gucht, editors, Symposium on Principles of Database
Systems, PODS 2010, pages 123–134. ACM, 2010.
[28] A. Machanavajjhala, D. Kifer, J. M. Abowd,
J. Gehrke, and L. Vilhuber. Privacy: Theory meets
practice on the map. In G. Alonso, J. A. Blakeley, and
A. L. P. Chen, editors, Proceedings of the 24th
International Conference on Data Engineering, ICDE
2008, pages 277–286. IEEE Computer Society, 2008.
[29] J. L. McInnes and B. Pinkas. On the impossibility of
private key cryptography with weakly random keys. In
A. Menezes and S. A. Vanstone, editors, Advances in
Cryptology—CRYPTO ’90, volume 537 of Lecture
Notes in Computer Science, pages 421–435. Springer,
1991.
[30] F. McSherry. Privacy integrated queries: an extensible
platform for privacy-preserving data analysis. In
U. ¸Cetintemel, S. B. Zdonik, D. Kossmann, and
N. Tatbul, editors, Proceedings of the ACM SIGMOD
International Conference on Management of Data,
SIGMOD 2009, pages 19–30. ACM, 2009.
[31] F. McSherry. Privacy integrated queries: an extensible
platform for privacy-preserving data analysis.
Commun. ACM, 53(9):89–97, 2010.
660[32] F. McSherry and R. Mahajan. Diﬀerentially-private
[37] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and
network trace analysis. In S. Kalyanaraman, V. N.
Padmanabhan, K. K. Ramakrishnan, R. Shorey, and
G. M. Voelker, editors, SIGCOMM, pages 123–134.
ACM, 2010.
[33] F. McSherry and I. Mironov. Diﬀerentially private
recommender systems: Building privacy into the
Netﬂix Prize contenders. In J. F. Elder, IV,
F. Fogelman-Souli´e, P. A. Flach, and M. J. Zaki,
editors, Proceedings of the 15th ACM SIGKDD
International Conference on Knowledge Discovery and
Data Mining—KDD 2009, pages 627–636. ACM, June
2009.
[34] P. Mohan, A. G. Thakurta, E. Shi, D. Song, and D. E.
Culler. GUPT: Privacy preserving data analysis made
easy. In Proceedings of the 38th SIGMOD
international conference on Management of data,
SIGMOD ’12, New York, NY, USA, 2012. ACM.
[35] J.-M. Muller, N. Brisebarre, F. de Dinechin, C.-P.
Jeannerod, V. Lef`evre, G. Melquiond, N. Revol,
D. Stehl´e, and S. Torres. Handbook of Floating-Point
Arithmetic. Birkh¨auser Boston, 2010.
[36] K. Nissim, S. Raskhodnikova, and A. Smith. Smooth
sensitivity and sampling in private data analysis. In
D. S. Johnson and U. Feige, editors, Proceedings of the
39th Annual ACM Symposium on Theory of
Computing (STOC), pages 75–84. ACM, 2007.
B. P. Flannery. Numerical Recipes: The Art of
Scientiﬁc Computing. Cambridge University Press,
New York, NY, USA, third edition, 2007.
[38] J. Reed and B. C. Pierce. Distance makes the types
grow stronger: a calculus for diﬀerential privacy. In
P. Hudak and S. Weirich, editors, Proceeding of the
15th ACM SIGPLAN international conference on
Functional programming, ICFP 2010, pages 157–168.
ACM, 2010.
[39] I. Roy, S. T. V. Setty, A. Kilzer, V. Shmatikov, and
E. Witchel. Airavat: Security and privacy for
MapReduce. In Proceedings of the 7th USENIX
Symposium on Networked Systems Design and
Implementation, NSDI 2010, pages 297–312. USENIX
Association, 2010.
[40] M. Santha and U. V. Vazirani. Generating
quasi-random sequences from semi-random sources. J.
Comput. Syst. Sci., 33(1):75–87, 1986.
661