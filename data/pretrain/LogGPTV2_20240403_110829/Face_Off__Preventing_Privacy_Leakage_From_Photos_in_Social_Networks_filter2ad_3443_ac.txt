of tags for the users at the 1%, 5%, 10% and 20% positions.
stranger scenario, and explore how many photos of strangers
they are able to view, if the uploader had selected the “friends
only” setting. Speciﬁcally, for each participant, we calcu-
late the number of photos that have been uploaded by that
user or his/her friends, and contain the tag of a user not in
his/her friendlist (we refer to them as strangers). Figure 6
presents the results, with 92% of the participants having
access to photos where strangers have been tagged. On av-
erage, these users can view 647 photos of 169 diﬀerent users
to which they are not connected, regardless of the privacy
settings those users have set. One user can view 1,866 pho-
tos depicting 1,073 diﬀerent strangers, while each of the top
10% users can view photos of at least 358 strangers. As such,
even if the OSN opts for a more privacy-oriented approach,
where the default setting for photos is “viewable by friends
only”, users’ faces will remain viewable by many strangers.
Overall, our study conﬁrms concerns regarding the privacy
risks that emerge from shared photos and threaten users,
and demonstrates the necessity for a ﬁne-grained access con-
trol mechanism, as the one we propose.
 0 0.2 0.4 0.6 0.8 1101102103104105106Cumulative fraction of Photos(CDF)User’s and friends’ photos (log)#Photos 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 50000 100000 150000 200000 200 400 600 800 1000 1200 1400CDFTotal TagsUnique Tagged UserIDsTagsUserIDs 0.86 0.88 0.9 0.92 0.94 0.96 0.98 1 1 2 4 8 16 32CDFTags per Photo (log)Full Set2000 Set 0 500 1000 1500 2000 2500 3000 0 5000 10000 15000 20000 25000 30000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9Number of TagsUserIDsUserIDs (%)895500363239User TagsFigure 6: For each user study participant’s clique, we plot
the total number of tags, the tags that belong to users not
associated with that participant (i.e., strangers), and how
many (unique) UIDs belong to strangers.
4. ACCESS CONTROL MODEL
The key concept of our approach is to reﬁne the object
of the access control model, switching from photos (coarse-
grained) to faces (ﬁne-grained). As summarized in Figure 7,
the objects in our access control model are the faces, the sub-
jects are the users, whereas the photos are modeled as object
groups. This allows us to deﬁne the concept of ﬁne-grained,
content-based, multi-owner control policy for photos.
The photo owner has a write-only right for publishing the
photo. Read rights are enforced by the users whose faces are
depicted in the photo. For example, in Figure 7, the user
U2 owns the photo P2 (solid dot), which depicts U1, U3, and
U5’s faces (empty dot, or solid dots on the diagonal axis).
This model could be implemented with a simple 2D sparse
matrix, replacing any existing access control model, or as
an extension, by adding an additional list containing the
permission bits as necessary. By choosing to visualize it as
a 3D matrix, we highlight that our model is an extension
of the current model and does not interferes with it. As a
matter of fact, this model can provide the exact functionality
of the current one, simply by enabling the permission bits on
all the objects. This model is implemented in the following.
4.1 System Design
Here we describe how our system resolves conﬂicting cases
in requested photos. We design the system by assuming the
availability of the existing functionalities of OSNs, namely
face recognition (as in Facebook and Google+), image pro-
cessing, and access control policy enforcement based on user
preferences. Figure 8 provides an overview of the work-ﬂow
of our approach, which is further detailed in the following.
Step 1: Face recognition. We rely on face recognition
to detect faces of known users, which become objects in
the access control model. This process takes place once a
user uploads a photo in the OSN. Each detected face is ﬁrst
compared to the classiﬁers of the uploader’s contacts, as
there is a high possibility that the depicted users will be
friends with the uploader. Previous work [41] has also shown
that social relationships can be used to further improve face
recognition results. Detected faces that do not match any of
the uploader’s contacts, will subsequently be compared to
the contacts of the other depicted users. Depending on the
computational resources available, this step can be extended
to include an arbitrarily larger portion of users.
Figure 7: Visualization of our revised access control model.
Auto tagging and suggestion. Auto-suggestions of the iden-
tiﬁed faces are displayed to the user to verify the subjects’
identity, if necessary. Moreover, we request the uploader to
tag any unidentiﬁed users. The auto-suggestion mechanism
is already implemented in modern OSNs.
Step 2: Template generation. The depicted (recog-
nized) users are notiﬁed about the photo and everyone sets
its own permissions. If a default setting has been already
set by a user, the system can enforce it automatically and
allow adjustments on a per-photo basis. Then, a template
of the processed photo is generated.
User notiﬁcation. Every user identiﬁed in the photo is
automatically notiﬁed that a photo with his/her face has
been uploaded. Users will be asked to verify the validity of
the face (if its actually him/her) and set the access control
for the speciﬁc photo. Until the depicted user has processed
the speciﬁc face, even if tagged by other users, the face will
remain hidden and no tag will appear. The mechanism for
allowing a tag is already implemented by Facebook, in the
form of tag review [4], and users have grown accustomed
to such requests. However, diﬀerently from our approach,
the user’s selection is reﬂected solely on the visibility of the
entire photo within the user’s albums.
The output of this phase is a template photo, which is
composed by the uploaded photo and a set of F layers, where
F is the number of faces recognized. Each layer represents a
face f appearing in the original photo p and has the size of
the patch corresponding to the associated face area. Each
tuple (cid:104)p, f(cid:105) in the template is processed: the face patch f is
pixelized/blurred, or set to a solid color.
Step 3: Template rendering. When a photo is to
be viewed by a subject, we select the corresponding row in
the access control matrix (see Figure 7). This allows us to
determine, in constant time, the faces (objects), f1, f2, . . .,
that the subject is allowed to view (read) according to each
face’s owner’s privacy setting for that photo, p. Based on
this information, we create a photo “on the ﬂy” and serve
it to the user. Thanks to the template photo, this can be
performed eﬃciently, by simply superimposing the required
layers (cid:104)p, fi(cid:105) on the original photo.
User lists. Each user has a personalized set of lists and
populates them with certain contacts. Every list may repre-
sent a group of friends with a common characteristic (e.g.,
coworkers, family, close friends). These lists are used for as-
signing permissions to groups of contacts for our ﬁne-grained
access control mechanism. The user can create a new list at
100101102103104105106107 10 20 30 40 50 60 70 80 90 100 110 120Number of Tags (log)UsersTotal TagsTotal Stranger TagsUnique Stranger UIDsuser U1user U2user U3user U4user U5. . .Subjectsphoto P1photo P2photo P3photo P4photo P5. . .Object groupsface F1face F2face F3face F4face F5. . .Objectspublished byofFigure 8: Overview of our approach. In Step 1 we identify the depicted faces and associate them to the users’ identities. In
Step 2 we create a template of multiple layers, each containing a single hidden face from the original photo. In Step 3 we
create a “processed” photo by superimposing the template layers on the original photo, according to users’ permissions.
where i = j + k
Algorithm 4.1: ViewPhotos(U, V )
P ← ListOfPhotos(U )
F ← Tag Present(U, P )
N ← Tag Not Present(U, P )
comment: {P1, ..., Pi} = {F1, ..., Fj} ∪ {N1, ..., Nk},
for each x ∈ N
do
for each x ∈ F
(cid:26)photo ← FaceOff(x, V )
Show(photo)
access f lag ← TagAccess(x, U, V )
if access f lag = 1
(cid:26)photo ← FaceOff(x, V )
do
then
Show(photo)
Figure 9: Pseudo-code of photo selection and access control
enforcement mechanism.
any time or remove an existing one. Access permission is not
irrevocable or permanent, as the user can modify his friend-
lists by adding new friends or removing some of the existing
ones, to revoke their permissions. Lists can be managed
(create/modify) during the permission assignment phase, as
the user may wish to create a new list for the speciﬁc photo
(e.g., friends that attended event X). Note that the custom
friend-list functionality is already provided by most OSNs.
Access control. Our goal is to provide an eﬃcient face-
level, ﬁne-grained access control mechanism that smoothly
operates on top of the traditional photo-level mechanisms.
Thus, the existing photo-level access mechanism used to
populate the photo albums a user is attempting to view,
remains as is. After the set of photos is identiﬁed, our face-
level granularity access mechanism is employed, for deter-
mining which depicted faces can be viewed and which must
be hidden from the user. Thus, if our model is adopted by
an OSN it can extend the existing mechanisms.
The procedure of selecting the photos of user U that will
be shown to the viewer V is presented in Figure 9. Using the
existing photo-level mechanism, we create the set of photos
P that the viewer is allowed to access. This set can be
broken down to two subsets, F where U ’s face is present,
and N where the U is absent. For every photo in N , we
check the permissions for every individual user depicted and
hide any faces, that should not be viewable. For photos in F ,
we only present photos where the viewer has the permission
to view U ’s tag, and once again, we check the permissions
of every individual face.
The reason for using our ﬁned-grained access control mech-
anism in conjunction with the existing mechanism can be
highlighted with the following scenario, as it demonstrates
how we achieve stronger privacy in certain cases. Consider
the case where Alice is trying to view Bob’s photos. For a
speciﬁc photo where Bob is depicted along with Marjorie,
who is also a friend of Alice, Bob has set a privacy setting
that prohibits Alice from viewing her face. However, Mar-
jorie has a less restrictive setting. If Alice was able to view
the photo, where Bob’s face would be blurred, she would
be able to argue that the hidden face most likely belongs
to Bob, as she is accessing Bob’s photo album. One could
state that this precaution may be redundant because Al-
ice can view the speciﬁc photo through Marjorie’s albums.
However, in an extreme case where Bob, Alice and Marjorie
have the exact set of users as online friends, Alice could
reveal that Bob’s face is hidden, by accessing the photo al-
bums of all of her friends. Since the photo will be presented
only in Bob’s and Marjorie’s albums, she can infer without
a doubt that Bob is depicted in the photo. While this exam-
ple may present a very extreme case, even in normal cases
Alice is inclined to consider Bob as the most plausible can-
didate. Thus, we choose to hide such photos from Alice, so
when viewing the photo through Marjorie, any other user is
equally possible to be hidden beneath the blurred section.
5.
IMPLEMENTATION DETAILS
In this section we describe the proof-of-concept implemen-
tation of our mechanism. We built our prototype as a third-
party Facebook app that is hosted on our web server, which
is also used for storing the uploaded photos, user informa-
tion and users’ permission matrices. We store all users’ data
locally, as our intention is not to provide another tool for al-
tering the current access control mechanisms, but to demon-
strate the functionality of our approach and to verify that it
can be easily integrated into existing OSNs. The fact that
we were able to implement our approach as an external ap-
plication, without any modiﬁcation in the backend, indicates
the unobtrusiveness of our mechanism.
Step 2: Template preparationStep 3: TemplaterenderingOriginal photosStep 1: Face recognitionUser graphObjects (faces)Object groups (photo templates)Privacy preservingphotos{F1 @ (x1,y1), F2 @ (x2,y2), ...}the blurred layers of the template on top of the photo, and
we populate it into the user’s album, as shown in Figure 10b.
In our prototype we implement the functionality of the
ﬁne-grained access control mechanism, but do not replicate
the existing photo-level mechanism. We follow a simpliﬁed
approach by considering that all the photos can be accessed
by the friends of the uploader and the friends of each tagged
user. However, our implementation takes into consideration
the case where the uploader’s face should remain hidden, as
described in Section 4.1, and does not populate these photos
in the uploader’s photo album.
6. EVALUATION
In this section we evaluate several aspects of our approach.
First, we measure the overhead introduced by our system.
Next, we conduct a user study to evaluate the eﬀectiveness
of our approach in preserving the privacy of users. Finally,
we explore the willingness of users to adopt our ﬁne-grained
access control mechanism for protecting their privacy.
6.1 Performance Evaluation
Regarding the performance overhead imposed by our ap-
proach, one must take into account that several OSNs al-
ready have the infrastructure available for performing real-
time face recognition on uploaded photos. This functionality
has already been implemented by Facebook and Google+
for supporting their tagging suggestion mechanism. Here,
we measure the processing overhead of our mechanism; we
do not measure the time required for the face detection pro-
cess, as we focus on the overhead incurred by actions that
are not already performed by the service. All experiments
were conducted on a commodity desktop machine.
Overhead: First, we measure the overhead presented by
the photo preparation phase, which takes place after a photo
has been uploaded and faces have been identiﬁed. This in-
cludes cropping detected faces and creating a blurred layer
of each face. We select 100 random photos from our user
study and process them. This phase takes 0.0023 seconds
on average per tag, and is performed before the photo is
added to the uploader’s albums. This overhead is negligi-
ble, especially when considering that OSNs already perform
transformations to uploaded photos (e.g., resizing).
Figure 11 presents the results from the experiment re-
garding the access control enforcement and photo transfor-
mation. Again, we upload 100 photos to our app, and tag
one of the faces. We then access the photos from an account
that does not have permission to view that tag, and measure
the total time required for creating the processed photo “on
the ﬂy”. This includes retrieving the access control lists for
the photo, selecting the faces to be blurred, overlaying the
blurred sections, and saving the transformed image. Over-
laying the blurred layer for a single tag requires merely 0.001
on average (0.022 seconds in the worst case) which is neg-