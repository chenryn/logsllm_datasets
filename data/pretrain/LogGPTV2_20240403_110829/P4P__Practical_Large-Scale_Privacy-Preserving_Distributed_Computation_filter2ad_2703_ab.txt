tems came close to providing satisfactory solutions for
most large-scale real-world applications. Table 1 shows
some representative benchmarks obtained by these im-
plementations. Using FairplayMP [5] as an example,
adding two 64-bit integers is compiled into a circuit of
628 gates and 756 wires using its SFDL compiler. Ac-
cording to [5]’s benchmark, evaluating such a circuit
between two players takes about 7 seconds. With this
performance, adding 106 vectors of dimensionality 106
each, which constitutes one iteration in our framework,
takes 7 × 1012 seconds, or 221,969 years.
ECC and a single server: It has been shown that con-
ventional client-server paradigm can be augmented with
homomorphic encryption to perform some computations
with privacy (e.g., [11, 22, 51]). Still, such schemes are
only marginally feasible for small to medium scale prob-
lems due to the need to perform at least linear number of
large ﬁeld operations even in purely semi-honest model.
Using elliptic curve cryptography (ECC) can mitigate the
problem as ECC can reduce the size of the cryptographic
ﬁeld (e.g., a 160-bit ECC key provides the same level
of security as a 1024-bit RSA key). ECC cryptosystems
such as [44] are (+, +)-homomorphic which is ideal for
private computation. However, ECC point addition re-
quires 1 ﬁeld inversion and several ﬁeld multiplications.
The operation is still orders of magnitude slower than
adding 64-bit or 32-bit integers directly. According to
our benchmark, inversion and multiplication in a 160-bit
ﬁeld take 0.0224 and 0.001 milliseconds, respectively.
Adding 1 million 106-element vectors takes 260 days.
Lesson learned: For large-scale problems, privacy and
security must be added with negligible cost. In particular,
those steps that dominate the computation should not be
burdened with public-key cryptographic operations (even
those “efﬁcient” ones such as ECC) simply because they
have to be performed so many times. This is the major
principle that guides our design. In our scheme, the main
computation is always performed in small ﬁeld, while
veriﬁcations are done via random projection techniques
to reduce the number of cryptographic operations. As
our experiments show, this approach is effective. When
the number of cryptographic operations are insigniﬁcant,
even using the traditional ElGamal encryption (or com-
mitment) with 1024-bit key the performance is adequate
for large scale problems.
4 P4P’s Architecture
Our approach is called Peers for Privacy, or P4P. The
name comes from the feature that, during the computa-
tion, certain aggregate information is released. This is a
very important technique that allows the private protocol
to have high efﬁciency. We show that publishing such
aggregate information does not harm privacy: individual
traits are masked out in the aggregates and releasing them
is safe. In other words, peers data mutually protects each
other within the aggregates.
there
service providers
Let κ > 1 be a small
are κ servers
integer. We assume
belonging to
differ-
that
(e.g., Amazon’s EC2 ser-
ent
and Microsoft’s Azure Services Platform,
vice
http://www.microsoft.com/azure/default.mspx).
We
deﬁne a server as all the computation units under the
control of a single entity. It can be a cluster of thousands
of machines so that it has the capability to support a
large number of users.
Threat Model Let α ∈ [0, 0.5) be the upper bound on
the fraction of the dishonest users in the system. 1 Our
scheme is robust against a computationally bounded ad-
versary whose capability of corrupting parties is mod-
eled as follows:
1. The adversary may actively corrupt at most ⌊αn⌋
users where n is the number of users.
2. In addition to 1, we also allow the same adversary
to passively corrupt κ − 1 server(s).
4
Table 1: Performance Comparison of Existing MPC Implementations
System
Fairplay [40]
FairplayMP [5]
PSSW [46]
LPS [39]
Adversary Model
Semi-honest
Semi-honest
Semi-honest
Malicious
Benchmark
Billionaires
Binary Tree Circuit (512 Gates)
AES Encryption of 128-bit block
16-bit Integer Comparison
Run Time (sec)
1.25
6.25
7
135
This model was proposed in [21] and is a special
case of the general adversary structure introduced in
[28, 34, 35] in that some of the participants are actively
corrupted while some others are passively corrupted by
the same adversary at the same time. Our model does not
satisfy the feasibility requirements of [34, 35] and [28].
We avoid the impossibility by considering addition only
computation.
The model models realistic threats in our target appli-
cations. In general, users are not trustworthy. Some may
be incentivized to bias the computation, some may have
their machines corrupted. So we model them as active
adversaries and our protocol ensures that active cheat-
ing of a small number of users will not exert large in-
ﬂuence on the computation. This greatly improves over
existing privacy-preserving data mining solutions (e.g.
[38, 51, 49]) and many current MPC implementations
which handle only purely passive adversary. The servers,
on the other hand, are selling CPU cycles and disk space,
something that is not related to user’s computation or
data. Deviating from the protocol causes them penalty
(e.g., loss of revenue for incorrect results) but little ben-
eﬁt. Their threat is therefore passive. (Corrupted servers
are allowed to share data with corrupted users)
Treating “large institutional” servers as semi-honest,
non-colluding has already been established by various
previous work [38, 51, 50, 49]. However, in most of
the models, the servers are not only semi-honest, but
also “trusted”, in that some user data is exposed to at
least one of the servers (vertical or horizontal partitioned
database). Our model does not have this type of trust re-
quirement as each server only holds a random share of
the user data. This further reduces the server’s incentive
to try to beneﬁt from user data (e.g., reselling it) because
the information it has are just random numbers without
the other shares. A compromise requires the collusion
of all servers which is a much more difﬁcult endeavor.
This also works for the servers’ beneﬁt: they are relieved
of the liability of hosting secret or illegal computation,
a problem that someone [18] envisions cloud providers
will be facing.
5 The P4P Framework
Let n be the number of users. Let φ be a small (e.g., 32-
or 64-bit) integer. We write Zφ for the additive group
of integers modulo φ. Let ai be private user data for
user i and I be public information. Both can be matri-
ces of arbitrary dimensions with elements from arbitrary
domains. Our scheme supports any iterative algorithms
whose (t + 1)-th update can be expressed as
n
d(t)
i
, I (t))
I (t+1) = f (
Xi=1
i = g(ai, I (t)) ∈ Zm
where d(t)
φ is an m-dimensional
data vector for user i computed locally. Typical values
for both m and n can range from thousands to millions.
Both f and g are in general non-linear. In the SVD ex-
ample that we will present, I (t) is the vector returned by
ARPACK, g is matrix-vector product, and f is the inter-
nal computation performed by ARPACK.
This simple primitive is a surprisingly powerful model
supporting a large number of popular data mining and
machine learning algorithms, including Linear Regres-
sion, Naive Bayes, PCA, k-means, ID3, and EM etc.,
as has been demonstrated by numerous previous work
such as [11, 13, 17, 10, 22]. It has been shown that all
algorithms in the statistical query model [36] can be ex-
pressed in this form. Moreover, addition is extremely
easy to parallelize so aggregating a large amount of num-
bers on a cluster is straightforward.
5.1 Private Computation
In the following we only describe the protocol for one
iteration since the entire algorithm is simply a sequen-
tial invocations of the same protocol. The superscript is
thus dropped from the notation. For simplicity, we only
describe the protocol for the case of κ = 2. It is straight-
forward to extend it to support κ > 2 servers (by sub-
stituting the (2, 2)-threshold secret sharing scheme with
a (κ, κ) one). Using more servers strengthens the pri-
vacy protection but also incurs additional cost. We do
not expect the scheme will be used with a large number
of servers. This arrangement simpliﬁes matters such as
synchronization and agreement. Let S1 and S2 denote
5
the two servers. Leaving out validity and consistency
check which will be illustrated using the SVD example,
the basic computation is carried out as follows:
function f , which is summation in our case, deﬁned as
[25]:
S(f ) = max
D,D′ kf (D) − f (D′)k1
1. User i generates a uniformly random vector ui ∈
φ and computes vi = di − ui mod φ. She sends
Zm
ui to S1 and vi to S2.
where D and D′ are two data sets differing by a sin-
gle record and k · k1 denotes the L1-norm of a vector.
Cauchy’s Inequality states that
2. S1 computes µ = Pn
putes ν =Pn
3. S1 updates I with f ((µ + ν) mod φ, I).
i=1 ui mod φ and S2 com-
i=1 vi mod φ. S2 sends ν to S1.
It is straightforward to verify that if both servers follow
the protocol, then the ﬁnal result is indeed the sum of the
user data vectors mod φ. This result will be correct if
every user’s vector lies in the speciﬁed bounds for L2-
norm, which is checked by the ZKP in [21].
5.2 Provable Privacy
Theorem 1 P4P’s computation protocol leaks no infor-
mation beyond the intermediate and ﬁnal aggregates, if
no more than κ − 1 servers are corrupted.
The proof follows easily the fact that both the secret shar-
ing scheme (for the computation) and the Pedersen com-
mitment scheme [45, 15] used in the ZK protocols are
information-theoretic private, as the adversary’s view of
the protocol is uniformly random and contains no infor-
mation about user data. We refer the readers to [30] for
details and formal deﬁnition of information-theoretic pri-
vacy.
As for the leakage caused by the released sums, ﬁrst,
for SVD, and some other algorithms, we are able to show
the sums can be approximated from the ﬁnal result so
they do not leak more information. For general compu-
tation, we draw on the works on differential privacy. [20]
has shown that, using well-established results from sta-
tistical database privacy [7, 19, 25], under certain condi-
tions, releasing the vector sums still maintains differen-
tial privacy.
In some situations verifying the conditions of [20] pri-
vately is non-trivial but this difﬁculty is not essential in
our scheme. There are well-established results that prove
that differential privacy, as well as adequate accuracy,
can be maintained as long as the sums are perturbed by
independent noise with variance calibrated to the number
of iterations and the sensitivity of the function [7, 19, 25].
In our settings, it is trivial to introduce noise into our
framework – each server, which is semi-honest, can add
the appropriate amount of noise to their partial sums af-
ter all the vectors from users are aggregated. Calibrating
noise level is also easy: All one needs are the parameters
ǫ, δ, the total number of queries (mT in our case where
T is the number of iterations), and the sensitivity of the
m
m
m
(
Xi=1
Xi=1
xiyi)2 ≤ (
x2
i )(
Xi=1
y2
i )
For a user vector a = [a1, . . . , am], let xi = |ai|, yi = 1,
we have
m
m
kak2
1 = (
Xi=1
Xi=1
|ai|)2 ≤ (
a2
i )m = kak2
2m
Since our framework bounds the L2-norm of a user’s
vector to below L, this means the sensitivity of the com-
putation is at most √mT L.
Note that the perturbation does not interfere with our
ZK veriﬁcation protocols in any way, as the latter is per-
formed between each user and the servers on the original
data. Whether noise is necessary or not is dependent on
the algorithm. For simplicity we will not describe the
noise process in our protocol explicitly. We stress again
that the SVD example we will present next does not need
any noise at all. See section 6.6.
6 Private Large-Scale SVD
In the following we use a concrete example, a private
SVD scheme, to demonstrate how the P4P framework
can be used to support private computation of popular
algorithms.
6.1 Basics
Recall that for a matrix A ∈ Rn×m, there exists a factor-
ization of the form
A = U ΣV T
(1)
where U and V are n × n and m × m, respectively, and
both have orthonormal columns. Σ is n×m with nonneg-
ative real numbers on the diagonal sorted in descending
order and zeros off the diagonal. Such a factorization is
called a singular value decomposition of A. The diago-
nal entries of Σ are called the the singular values of A.
The columns of U and V are left- resp. right-singular
vectors for the corresponding singular values.
SVD is a very powerful technique that forms the core
of many data mining and machine learning algorithms.
Let r = rank(A) and ui, vi be the column vectors of
U and V , respectively. Equation 1 can be rewritten as
6
i=1 σiuivT
k =Pk
A = U ΣV T = Pr
i where σi is the ith singu-
lar value of A. Let k ≤ r be an integer parameter, we
i .
can approximate A by Ak = UkΣkV T
i=1 σiuivT
It is known that of all rank-k approximations, Ak is op-
timal in Frobenius norm sense. The k columns of Uk
(resp. Vk) give the optimal k-dimensional approxima-
tion to the columnspace (resp.
rowspace) of A. This
dimensionality reduction preserves the structure of orig-
inal data while considers only essential components of
the matrix. It usually ﬁlters out noise and improves the
performance of data mining tasks.
Our
implementation uses a popular eigensolver,
ARPACK [37] (ARnoldi PACKage), and its parallel