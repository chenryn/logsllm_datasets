These observations suggest a publish-subscribe [3] archi-
tecture for managing state updates. Speci(cid:12)cally, a game
node registers a \subscription" describing the objects which
it wishes to keep updated. Also, whenever a node changes
the state of a game object, the node creates a \publica-
tion" which is delivered to the other nodes interested in that
object. Note that the subscription essentially implements
\area-of-interest" (cid:12)ltering (which we describe in further de-
tail in Section 6.4).
A key requirement of this design is a (cid:13)exible subscrip-
tion language which allows the game to express its object-
subscriptions precisely. If the language is coarse, the game
may end up receiving a large number of irrelevant updates
which will have to be (cid:12)ltered locally. But a language may
also be so (cid:13)exible as to preclude scalable routing of object
updates. Fortunately, we can use the multi-attribute range
query primitive, which Mercury implements scalably, as the
subscription language for distributed games.
In the remainder of this section, we describe the publish-
subscribe system we have built on top of the Mercury rout-
ing layer; describe Caduceus, our simple multiplayer dis-
tributed game; compare publish-subscribe to other possi-
ble solutions, and present some basic performance measure-
ments.
6.2
Implementing Publish›Subscribe with
Mercury
face. We then explain how Mercury is used to implement
this API.
The publish-subscribe system exposes a simple interface
for applications. This API has three basic calls: send_
publication, register_interest, and unregister_interest.
The send_publication call is used to disseminate an ob-
ject update via Mercury. The call takes the updated ob-
ject as its argument. When an application invokes this call,
the publish-subscribe system assumes responsibility for de-
livering the object update to other interested nodes. The
register_interest is used to subscribe to updates. This
call takes a multi-attribute range query as its argument.
After an application invokes this call, the publish-subscribe
system is responsible for delivering an update to the appli-
cation whenever an object matching the query is added or
modi(cid:12)ed. The unregister_interest call simply cancels a
subscription.
Our implementation of publish-subscribe using Mercury
is relatively straightforward. Publications are routed as reg-
ular data items in Mercury. Subscriptions are similar to
Mercury queries, but with one important di(cid:11)erence. Mer-
cury queries can be discarded immediately after they are
answered. Subscriptions, however, must match not only ob-
jects currently existing in the system, but must return fu-
ture matching objects as well. Thus, subscriptions must be
retained at the nodes which receive them.
In our current
implementation, subscriptions are hard state: they are re-
tained until they are cancelled by the querying node. To
provide robustness in the face of node failures, however, we
plan to implement subscriptions as soft state.
6.3 Caduceus
Caduceus is a two-dimensional, multi-player, shooter game.
Each player in the game has a ship and a supply of mis-
siles. Players pursue each other around the two-dimensional
space, and (cid:12)re missiles when their opponents are in range.
The goal is simply to kill as many opponents are possible.
Figure 10(a) presents a screenshot of the game. At any given
time, a player sees the other ships in her immediate vicinity,
as de(cid:12)ned by the game window. The virtual game world is
larger than the window. Thus, there might, for example,
be opponents located beyond any of the edges of the game
window.
The state of the game is represented using two kinds of
objects: ships and missiles. A ship consists of a location, ve-
locity, and ancillary information such as fuel level. A missile
is created whenever a ship (cid:12)res shots. A missile consists of a
location, velocity, and owner information.12 The main loop
of Caduceus, shown in Figure 10(b), is relatively simple.
6.4 Alternative Update Routing Architectures
As stated previously, a central problem in distributed mul-
tiplayer gaming is ensuring that all nodes have (weakly) con-
sistent views of the game state. To provide this (weak) con-
sistency, nodes send updates to other nodes whenever the
game state has changed. To date, most games have used
either broadcast messaging, or a centralized server, to de-
liver these updates. Unfortunately, both these designs scale
poorly to a large number of nodes.
To improve scalability, researchers have proposed area-of-
interest (cid:12)ltering [17,24] schemes, which divide the world into
To explain the implementation of publish-subscribe with
Mercury, we begin with the application programmer’s inter-
12The owner is used to credit the appropriate player when
an opponent is killed.
void GameApp::timerEvent(QTimerEvent *) f
m Renderer(cid:0)>Render();
m GameEngine(cid:0)>RunFrame(); // read keyboard events,
// run physics
updateSubs();
m StateManager(cid:0)>UpdateState(); // publish dirty objects,
// receive pubs
m StateManager(cid:0)>CollectGarbage(); // delete useless objects
g
(a)
(b)
Player 1
(200, 60)
int
int
int
int
x >= 150
x = 10
y = 225
x = 75
y <= 175
Game
World
Figure 10: a) Screenshot of Caduceus b) Caduceus main loop c) Example subscriptions
a (cid:12)xed set of regions and map them to IP multicast groups.
However, the (cid:12)xed regions result either in the delivery of
a large number of irrelevant updates to clients, or in the
maintenance of a large number of IP multicast groups at
routers.
In contrast, Mercury’s subscription language is ideal for
implementing area-of-interest (cid:12)ltering.
In particular, the
subscription language makes it easy to describe arbitrary
physical regions. As an example, Figure 10(c) shows two
nodes expressing their interests in the rectangular regions
near them. Of interest is the fact that the regions do not,
for example, need to (cid:12)t a pre-de(cid:12)ned tiling of the space.
Note that while tiling the space, and assigning these tiles
to di(cid:11)erent channels, would be possible for a simple two-
dimensional game, it becomes far more di(cid:14)cult in games
with irregular spaces, such as corridors, or which have to
deal with visibility constraints such as horizons. It is also
di(cid:14)cult for multicast group-based schemes to support arbi-
trary interests such as \the location of all my teammates".
As shown in Figure 6(b), Mercury is able to handle 10000
nodes while keeping the number of routing hops below 8. As-
suming that the average-case, one-way delay between nodes
is about 20ms (e.g., they are all well connected and within
the U.S. west coast), this results in an end-to-end delay of
less than 160ms. We believe that game-speci(cid:12)c caching algo-
rithms could further improve the routing performance, mak-
ing Mercury-based games scalable to thousands of nodes.
6.5 Performance Evaluation
We evaluate the performance of our system with two met-
rics: hop count, and message count. We run a varying
number of players. The players move through the world
according to a random waypoint model, with a motion time
chosen uniformly at random from (1, 10) seconds, a des-
tination chosen uniformly at random, and a speed chosen
uniformly at random from (0, 360) pixels per second. The
size of the game world is scaled according to the number of
players. The dimensions are 640n (cid:2) 480n, where n is the
number of players. All results are based on the average of 3
experiments, with each experiment lasting 60 seconds. The
experiments include the bene(cid:12)t of a log n sized LRU cache
at each node, but do not include the bene(cid:12)ts of any long
pointers. 13
Table 1 summarizes the results. With respect to hop
count, we (cid:12)nd that the hop count increases only slightly
13We did not implement long-distance links because we were
primarily interested in assessing the suitability of the Mer-
cury service for distributed games. However, we were curi-
ous about performance.
as we double the number of nodes. To evaluate Mercury’s
messaging e(cid:14)ciency, we compare it to two alternatives. In
the \broadcast messages" column of the table, we report
the number of messages that would have been transmitted
if every update were sent to every node (as was done in
(cid:12)rst-generation distributed games).
In the \optimal mes-
sages" column, we report the number of messages required
to exactly satisfy each node’s interests, without any control
message overhead. We (cid:12)nd that Mercury performs substan-
tially better than a broadcast scheme (43% as many mes-
sages transmitted for 20 nodes), and that this performance
di(cid:11)erence increases when we increase the number of nodes,
with Mercury using only 29% as many messages as broad-
cast for 40 nodes.
# of
Players
20
40
Average
Hops
4.44
4.61
Broadcast
Messages
170000
695240
Mercury
Messages
74295
199076
Optimal
Messages
28154
58644
Table 1: Routing overheads for Caduceus, without
long pointers.
7. CONCLUSION
In this paper, we have described the design and imple-
mentation of Mercury, a scalable protocol for routing multi-
attribute range-based queries. Our contributions as com-
pared to previous systems include support for multiple at-
tributes and explicit load balancing. Mercury incorporates
novel techniques to support random sampling of nodes within
the system. Random sampling enables a number of light-
weight approaches to performing load-balancing, node count
estimation and query selectivity estimation. Our evaluation
clearly shows that Mercury scales well, has low lookup la-
tency and provides good load balancing properties.
In addition to providing high query-routing performance,
Mercury provides a (cid:13)exible range-based query primitive.
Using this primitive, we are able to build an easy-to-use
publish-subscribe facility for the maintenance of weakly con-
sistent distributed state. We (cid:12)nd that this facility is well
suited for distributed state maintenance in distributed games.
While we have only directly shown the suitability of Mercury
for distributed games, we believe that the classes of applica-
tions that will bene(cid:12)t from our system include collaborative
applications, such as shared whiteboards, distributed inven-
tories and possibly sensing applications as well.
8. ACKNOWLEDGEMENTS
We thank Justin Weisz for his initial work on adapting
Caduceus to work with Mercury.
9. REFERENCES
[1] Byers, J., Considine, J., and Mitzenmacher, M.
Simple load balancing for distributed hash tables.
Second International Workshop on Peer-to-Peer
Systems (2003).
[2] Cabrera, L. F., Jones, M. B., and Theimer, M.
Herald: Achieving a Global Event Noti(cid:12)cation
Service. In Proceedings of the 8th IEEE Workshop on
Hot Topics in Operating Systems (Elmau, Germany,
May 2001).
[3] Carzaniga, A., Rosenblum, D. S., and Wolf,
A. L. Design and Evaluation of a Wide-Area Event
Noti(cid:12)cation Service. ACM Transactions on Computer
Systems 19, 3 (Aug. 2001), 332{383.
[4] Castro, M., Druschel, P., Hu, Y. C., and
Rowstron, A. Exploiting network proximity in
distributed hash tables. In International Workshop on
Future Directions in Distributed Computing (FuDiCo)
(June 2002), O. Babaoglu, K. Birman, and
K. Marzullo, Eds., pp. 52{55.
[5] Castro, M., Druschel, P., Kermarrec, A. M.,
Nandi, A., Rowstron, A., and A., S. Splitstream:
High-bandwidth multicast in a cooperative
environment. In Proceedings of the 19th Symposium on
Operating System Principles (Oct. 2003).
[6] Castro M., et. al. SCRIBE: A large-scale and
decentralized application-level multicast
infrastructure. IEEE Journal on Selected Areas in
Communications (JSAC) 20, 8 (Oct. 2002).
[7] Dabek, F., Kaashoek, M. F., Karger, D.,
Morris, R., and Stoica, I. Wide-area cooperative
storage with CFS. In Proceedings of the 18th
Symposium on Operating System Principles (Chateau
Lake Louise, Ban(cid:11), Canada, Oct. 2001).
[8] Ganeshan, P., Bawa, M., and Garcia-Molina, H.
Online Balancing of Range-Partitioned Data with
Applications to Peer-to-Peer Systems. In Conference
on Very Large Databases (VLDB) (2004). To appear.
[9] Ghosh, B., Leighton, F. T., Maggs, B. M.,
Muthukrishnan, S., Plaxton, C. G., Rajaraman,
R., Richa, A. W., Tarjan, R. E., and
Zuckerman, D. Tight analyses of two local load
balancing algorithms. In Proceedings of the 27th ACM
STOC (1995), pp. 548{558.
[10] Gummadi, K., Gummadi, R., Ratnasamy, S.,
Gribble, S., Shenker, S., and Stoica, I. The
Impact of DHT Routing Geometry on Resilience and
Proximity. In Proceedings of the ACM SIGCOMM ’03
(Aug. 2003).
[11] Harvey, N. J. A., Jones, M. B., Saroiu, S.,
Theimer, M., and Wolman, A. Skipnet: A scalable
overlay network with practical locality properties. In
Proceedings of the 4th USENIX Symposium on
Internet Technologies and Systems (Seattle, WA, Mar.
2003).
[12] Heubsch, R., Hellerstein, J., Lanhan, N., Loo,
B. T., Shenker, S., and Stoica, I. Querying the
Internet with PIER. In Proceedings of the 29th
International Conference on Very Large DataBases
(Sept. 2003).
[13] Karger, D., and Ruhl, M. Simple e(cid:14)cient
load-balancing algorithms for peer-to-peer systems.
Third International Workshop on Peer-to-Peer
Systems (2004).
[14] Kleinberg, J. The Small-World Phenomenon: An
Algorithmic Perspective. In Proceedings of the 32th
ACM STOC (2000).
[15] Kostic, D., Rodriguez, A., Albrecht, J.,
Bhirud, A., and Vahdat, A. Using random subsets
to build scalable network services. In Proceedings of
the 4th USENIX Symposium on Internet Technologies
and Systems (Seattle, WA, Mar. 2003).
[16] Li, X., Kim, Y.-J., Govindan, R., and Hong, W.
Multi-dimensional range queries in sensor networks. In
Proceedings of the ACM Sensys 2003 (Nov. 2003).
[17] Macedonia, M. R., Zyda, M. J., Pratt, D. R.,
Brutzman, D. P., and Braham, P. T. Exploiting
reality with multicast groups: A network architecture
for large-scale virtual environments. In Proc. of the
1995 IEEE Virtual Reality Symposium (VRAIS95)
(Mar. 1995).
[18] Manku, G., Bawa, M., and Raghavan, P.
Symphony: Distributed hashing in a small world. In
Proceedings of the 4th USENIX Symposium on
Internet Technologies and Systems (Seattle, WA, Mar.
2003).
[19] Motwani, R., and Raghavan, P. Randomized
Algorithms. Cambridge University Press, 1995.
[20] Randall, D. Math 8213A - Rapidly Mixing Markov
Chains.
http://www.math.gatech.edu/(cid:24)randall/Course/lewis1.ps,
2003.
[21] Rao, A., Lakshminarayanan, K., Surana, S.,
Karp, R., and Stoica, I. Load Balancing in
Structured P2P Systems. Second International
Workshop on Peer-to-Peer Systems (2003).
[22] Ratnasamy, S., Francis, P., Handley, M., Karp,
R., and Shenker, S. A Scalable Content-Addressable
Network . In Proceedings of the SIGCOMM ’01
Symposium on Communications Architectures and
Protocols (San Diego, California, Aug. 2001).
[23] Rowstron, A., and Druschel, P. Pastry: Scalable,
distributed object location and routing for large-scale
peer-to-peer systems. In IFIP/ACM International
Conference on Distributed Systems Platforms
(Middleware) (Nov. 2001), pp. 329{350.
[24] Singhal, S., and Cheriton, D. Using projection
aggregations to support scalability in distributed
simulation. In Proceedings of the 16th International
Conference on Distributed Computing Systems (1996).
[25] Stoica, I., Morris, R., Karger, D., Kaashoek,
F., and Balakrishnan, H. Chord: A scalable
peer-to-peer lookup service for internet applications.
In Proceedings of the SIGCOMM ’01 Symposium on
Communications Architectures and Protocols (2001).