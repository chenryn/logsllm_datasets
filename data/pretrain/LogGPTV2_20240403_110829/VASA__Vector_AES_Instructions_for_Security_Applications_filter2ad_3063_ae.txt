### 5.3 EMP-OT

For oblivious transfers, we evaluated the EMP-OT library [90] (cf. § 4.3.2). We ran it single-threaded with 100 million OT operations on localhost. For the one-time base OT operations, which use public-key cryptography, the default number of OT operations was used, and these times were excluded from the throughput results. As base OT protocols, we used the Naor and Pinkas protocol [74] for passive security assumptions and SimplestOT [23] for active security, except for FERRET OT [93], which uses its own base OT protocol. The library employs fixed-key AES for its pseudorandom generator (PRG) [13], the optimized version of Ishai et al.'s protocol [8, 57] for passive security, and the variant by Asharov et al. [9] for active security.

Additionally, we measured the performance of FERRET-OT [93], as it is a protocol with minimal communication after the initial base OTs. EMP-OT was compiled with Clang. The results are shown in Table 5. We observed performance improvements ranging from 14.8% to 30.1% when using VAES. Notably, the performance increase was particularly high for random OTs (R-OTs), which can be attributed to reduced system interaction due to lower communication requirements for R-OTs.

**Table 5: Run-times in seconds of 10 million OTs for EMP-OT [90] before "Ref" and after implementation of VAES support.**
- **Functionality**: General OT (OT), Correlated OT (C-OT), and Random OT (R-OT).
- **Improv%**: Performance improvement of VAES over AES-NI.
- **Higher throughput is better.**

| Functionality | Security | Library | Implementation | OT (s) | C-OT (s) | R-OT (s) | Improv% |
|---------------|----------|---------|----------------|--------|----------|----------|---------|
| EMP-OT IKNP [8, 57] | Ref [8, 57, 90] | 0.35 | 0.20 | 0.33 | - |
| EMP-OT IKNP [8, 57] | VAES | 0.28 | 0.16 | 0.25 | 20.0% | 20.0% | 24.2% |
| EMP-OT FERRET [93] | Ref [90, 93] | 1.33 | 1.14 | 1.32 | - |
| EMP-OT FERRET [93] | VAES | 1.13 | 0.99 | 1.09 | 15.0% | 10.4% | 17.4% |
| EMP-OT ALSZ [9] | Ref [9, 90] | 0.39 | 0.24 | 0.38 | - |
| EMP-OT ALSZ [9] | VAES | 0.32 | 0.19 | 0.29 | 17.9% | 20.8% | 23.7% |
| EMP-OT FERRET [93] | Ref [90, 93] | 1.38 | 1.2 | 1.37 | - |
| EMP-OT FERRET [93] | VAES | 1.21 | 1.04 | 1.16 | 12.3% | 13.3% | 15.3% |
| +Random Choice | Ref [90, 93] | - | 0.94 | - | - |
| +Random Choice | VAES | - | 0.80 | - | - | 14.8% | - |

**Discussion.** From the OT performance data in Table 5, we see that AVX512 and VAES significantly improve performance by 20-30% for the traditional OT implementation in the EMP libraries, which use VAES for the PRG and AVX512 for bit transposition. Additionally, we observe mild performance improvements of 16.6% for the FERRET protocols, mainly using AES to generate the random matrices in the core matrix-vector multiplication.

### 5.4 EMP-AGMPC

For EMP-AGMPC [90, 92] (cf. § 4.3.3), we ran SHA256 with three parties on localhost, using binaries compiled with Clang. The runs were performed 11 times and then averaged. After the initial measurements, we decided to benchmark with batching applied and using only a VAES-enabled library implementation of AES-ECB, the PRG, and the OT functionalities. The resulting performance numbers are shown in Table 6. In this table, the computation backend indicates the implementation strategy used, with the numbers in parenthesis showing the performance improvements over the previous row.

**Table 6: Run-times in milliseconds for the evaluation of various parts of SHA256 in EMP-AGMPC [90, 92] (§ 5.4).**
- **Computation Backend (Comp. Backend)**: Indicates the implementation strategy used.
- **Evaluated Parts**: One-time setup, function-independent preprocessing, function-dependent preprocessing, and input-dependent online phase.
- **Values in parenthesis show the performance improvement in percent over the reference.**
- **Lower run-times are better.**

| Operation | Comp. Backend | Setup (ms) | Function-Independent (ms) | Function-Dependent (ms) | Online (ms) |
|-----------|---------------|------------|---------------------------|-------------------------|-------------|
| Ref [90, 92] | 45.0 | 564.5 | 247.0 | 7.0 | - |
| VAES | 45.9 (-2.1%) | 580.7 (-2.8%) | 250.6 (-1.4%) | 6.7 (5.0%) | - |
| Batched + VAES | 45.4 (-0.9%) | 453.0 (24.6%) | 250.7 (-1.5%) | 7.0 (0.7%) | - |

**Discussion.** The AGMPC performance data (in Table 6) shows substantial performance differences. The performance increase from VAES in the online phase stems from the OT used with extra batching, moving values out of registers again due to the gap between successive accesses. The most notable improvement is the 25% performance increase through batching in the function-independent preprocessing phase combined with VAES. This is because the garbling operations used in that phase benefit sufficiently from the batching, and there are not too many XORs sparsing out the AND gates and their memory.

### 5.5 CrypTFlow2

As CrypTFlow2 [82] (cf. § 4.3.4) uses EMP-OT internally, it is a natural target to investigate how the internal improvements benefit the overall performance of a more end-to-end application. As benchmarks, we ran inference for the SqueezeNetImgNet, SqueezeNetCIFAR, ResNet50, and DenseNet121 networks. Each network has its dedicated driver executable, compiled using GCC, and run via localhost with both parties on the same machine, focusing on computational performance. The default settings utilized multiple load-intensive threads for both the client and the server, but had no noticeable impact on performance consistency.

A summary of the results using the geometric mean is given in Table 7, and the details are shown in Table 9 in Appendix B. Times below 1 second were omitted from the table.

**Table 7: Geometric mean of run-times in seconds for CrypTFlow2 [82] inference (§ 5.5) using the SqueezeNetImgNet, SqueezeNetCIFAR, ResNet50, and DenseNet121 networks.**
- **Ring32-OT**: Denotes the 32-bit ring-based implementation using OT.
- **Ref**: Reference implementation using AES-NI.
- **VAES**: Our version using VAES.
- **Improv%**: Performance improvement of VAES over AES-NI.
- **Lower run-times are better.**

| Sub-Operation Type | Implementation | Convolution (s) | Truncation (s) | ReLU (s) | Matrix Multiplication (s) | Batch Normalization (s) | MaxPool (s) | Total (s) | Improv% |
|--------------------|----------------|-----------------|----------------|----------|---------------------------|-------------------------|-------------|-----------|---------|
| Ref [82] | 96.5 | 30.7 | 9.6 | 94.0 | 15.6 | 3.7 | 126.8 | - |
| VAES | 97.0 | 21.0 | 6.8 | 94.5 | 13.5 | 2.5 | 119.1 | -0.5% | 46.5% | 40.4% | -0.5% | 15.9% | 47.1% | 6.5% |

**Discussion.** Table 7 shows that the VAES-based speed-up for the OT-based Ring32 implementation is 6.5% in total. The non-linear layers, particularly the ReLU and MaxPool layers, have contributed significantly to this improvement, with both improving by over 40%. We observe no performance changes for the linear convolution and matrix multiplication steps for the Ring32 implementation. This is because these are primarily bound by the speed of the operating system interaction. We can also conceive that the performance improvement for the Ring32 implementation stems from the relatively short focus on VAES during the operations.

### 6. CONCLUSION AND FUTURE WORK

In this work, we have demonstrated how AES-NI and VAES can be used to speed up MPC protocols and applications, especially in cases where operations are not known a priori.

**Summary.** We started by discussing how dynamic batching and its extensions and optimizations use deferred execution to provide better batches of AES calls to the hardware units. Next, we discussed how more explicit measures in the code, such as SIMD gates and layering, find batches of tasks with more invasive code modifications. Furthermore, we discussed how to compute the batched calls using abstract pre- and post-processing and platform-specific AES computation in our memory-oriented computation strategy. Our alternative register-oriented strategy accepted code duplication for a low-level, register-value-oriented code description that the compiler and processor can execute more easily. We applied these techniques to ABY [13, 25, 97], EMP-OT [90], EMP-AGMPC [90, 92], and Microsoft CrypTFlow2 [82]. For ABY, we implemented additional garbled circuit variants [40, 41, 97] for comparison. We then evaluated the performance impact of the use of VAES and batching techniques. In ABY, these batching techniques significantly increased performance without changing the hardware requirements. The use of VAES yielded further significant performance improvements in ABY, EMP-OT, Microsoft CrypTFlow2, and some parts of EMP-AGMPC.

**Future Work.** Our research can be extended in multiple directions:

- **Improved Modelization.** The techniques presented in § 4.1 and § 4.2 could be further improved. A more theoretical modelization and a more detailed analysis of the interaction with cache effects could yield valuable insights for future implementations.
- **Merging Register- and Memory-oriented Computation.** Our computation techniques from § 4.2 require making a manual choice between low code duplication, high performance, and clarity to the compiler. Further research could find techniques to automatically achieve low code duplication, high performance, and clarity. Techniques from programming language and compiler research might be useful.
- **Further Applications in MPC.** VAES and other AVX512 extensions can be used to improve performance in further applications in MPC, such as the most recent garbling schemes [10, 43, 85] that reduce communication (the main bottleneck in MPC) at the cost of more computation.

### AVAILABILITY

The open-source code of our changed VAES implementations is freely available under the permissive Apache license at https://encrypto.de/code/VASA.

### ACKNOWLEDGMENTS

We sincerely thank Nir Drucker and Shay Gueron for their very helpful comments and pointers to the history of VAES, which helped us substantially improve our paper. Shay Gueron was the inventor of the concept, perceived usages and motivation, architecture, and microarchitectural implementation for vectorized AES in Intel processors when he was with Intel.

This project received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation program (grant agreement No. 850990 PSOTI). It was co-funded by the Deutsche Forschungsgemeinschaft (DFG) — SFB 1119 CROSSING/236615297 and GRK 2050 Privacy & Trust/251805230, and by the German Federal Ministry of Education and Research and the Hessen State Ministry for Higher Education, Research, and the Arts within ATHENE.