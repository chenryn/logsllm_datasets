(d1, f1)
(d2, f2)
. . .
image-hash
(ds, fs)
where di is a domain on which this image was found,
and frequency fi is the number of times the user visited
the page. The plug-in either maintains the frequency
value itself (adding one every time the page is loaded)
or uses the browser’s history ﬁle to compute it. Only
13
images referenced with the SPOOFGUARD attribute are
stored in the database.
When the browser downloads a login page containing
an image whose hash is in the database it does the fol-
lowing:
• Check to see if the page’s domain is in the list of
domains associated with the image. If so, let F be
the frequency for the domain. If not, set F to 0.
• Let M be the maximum frequency in the image’s
record. The test return the value p = 1 − F/M.
To see how this works, consider the eBay login page
and consider an image marked with SPOOFGUARD on
that page. Now, consider the record in the plug-in’s im-
age database corresponding to this image. Most likely,
the eBay login page will have the highest frequency in
the image record. Consequently, the eBay login page
will have p = 0 indicating that it is not likely to be a
spoof. Other pages containing this image with a SPOOF-
GUARD attribute (either set up by an attacker or by
someone attempting to DoS eBay) will have a much
lower frequency and therefore result in a p value close
to 1. This technique prevents abuse of this test for denial
of service.
6.3 Password hashing and site-speciﬁc salt
Users often use the same password at many different
sites. For example, the same password may be used
for an E*Trade account as for a newspaper site. We
can combat this problem using site-speciﬁc password
salt. Password salt, or other improvements of the stan-
dard password mechanism, also help with other secu-
rity problems. In particular, when attackers break into
a low security site they often try the recovered user-
name/password combinations at various ﬁnancial sites.
As a result, a web site implementing proper security
policies suffers when other sites do not apply recent
patches and store passwords in the clear.
Passwords at one site can be made independent of
passwords at other sites by adding a new SALT attribute
to the html  element. This attribute lets a site
specify per-server salt; per-user salt is not possible since
it is supplied before the user is identiﬁed. With this new
attribute, password ﬁelds would look like:
where the site developers ensure that their salt is unique
to their site. For example, one could use the domain-
name as a salt.
When processing a password ﬁeld the browser ﬁrst
computes Epwd[salt], where E is block cipher, pwd is
the password entered by the user, and salt is the salt
from input html element. The browser transmits the
resulting value rather than the user’s password. If the
salt attribute is not present in the html page, the browser
uses 0 as the salt. The main point is that with the block
cipher, it is hard to compute Epwd[X] from Epwd[Y ]
for X (cid:54)= Y . Consequently, a newspaper break-in will
not compromise an E*Trade password. Note that this is
similar to challenge-response authentication, except that
each site uses a ﬁxed and unique challenge rather than
a random challenge. This way the site need only store
in its database a hash of the submitted password value
rather than the plaintext submitted password.
One difﬁculty in deploying site-speciﬁc salt is that all
browsers must be simultaneously modiﬁed and web sites
must re-authenticate their users after this mechanism is
deployed. Another problem is that this mechanism it-
self is susceptible to spooﬁng. As presented, a spoof
site need only contact the honest site to obtain the site-
speciﬁc salt, then pass the same salt on to the victim.
This will cause the victim’s browser to send the spoof
site the exact password needed to gain access to the hon-
est site. Although we have not done a thorough study,
site-speciﬁc salt may still be useful when the request
comes over https and the certiﬁcate check establishes
a reliable association between the salt and the request-
ing domain. With this limitation, site-speciﬁc salt will
produce distinct passwords for distinct sites, and pre-
vent a phisher who sets up an insecure (i.e., non-https)
site from obtaining a password associated with a more
secure (https) site.
7 More Speculative Techniques
We describe a few techniques that might be useful in
combating spoof sites. We did not experiment with these
since we consider them to be more speculative at the
moment.
Collaborative Methods. Several projects [Bri03] use
collaborative methods to identify spam email. A similar
mechanism might apply to blocking spoof sites. Con-
sider a user who uses our plug-in, but ignores the warn-
ing issued by the plug-in when visiting a site. The user
enters his identifying information, submits the data, and
then realizes that he just entered private information on
a spoof site. At that point the user might want to alert
the authorities as well as alert other users to avoid the
site. By providing a “send alert” button in our browser
plug-in the user could notify a central server that the cur-
rent page is a spoof. If enough users identify the page
as a spoof the server could alert all plug-ins to block
the page. This might dramatically reduce the number of
users who get duped by the spoof site.
We consider this method to be speculative for two rea-
sons. First, user’s who are duped by spoof sites are also
likely to be unaware of the “send alert” button and its
function. Second, this mechanism could potentially be
used to launch a denial of service attack against an hon-
est site.
Search engines to the rescue. Spoof sites are often
direct copies of pages on the honest site. Therefore,
when viewing a sensitive page (a page that requests a
user password), our browser plug-in could do a Google
search on some key phrases or links on the page. If a
page similar to the current page is found at a different
domain, the plug-in would increase the page’s spoof-
score.
We consider this method to be speculative since pages
are often cached at various sites on the web and it would
be difﬁcult to distinguish a spoof from a cached page.
In addition, if every browser in the world automatically
issued a Google query for every password page it en-
counters, the resulting trafﬁc would likely overwhelm
Google. There is also no business incentive for Google
to support such a service.
Forensics. Suppose internal tests at E*Trade indicate
that a user’s password has been compromised. E*Trade
suspects that this is the result of a spoof E*Trade site.
They wish to quickly determine where the site is. One
option is to examine the user’s history ﬁle since it con-
tains all the sites the user visited recently, including the
spoof site. However, a well-minded user would likely
refuse to hand over the browser’s history ﬁle due to pri-
vacy concerns. To reduce the user’s exposure, Spoof-
Guard could keep track of sites where the user entered a
password identical to his E*Trade password. Only those
sites would be handed over to E*Trade.
We consider this method to be speculative since most
spoof sites are active for only a few days. Most likely the
process required for obtaining data from the user would
take more time than that. Nevertheless, the problem of
quickly locating spoof sites is important and deserves
attention. We may experiment with using web crawlers
for this task in the future.
8 Conclusion
Most of the $37 million increase in losses from In-
ternet fraud observed between 2001 to 2002 has been
attributed to web spooﬁng [Von03]. While web spoof-
ing (or phishing) may become more sophisticated in the
future, we propose a set of methods that appear effective
for the kind of simple attacks observed by law enforce-
ment and affected companies. SpoofGuard uses a com-
bination of stateless page evaluation, stateful page evalu-
ation, and examination of outgoing post data to compute
a spoof index. When a user enters a username and pass-
word on a spoof site that contains some combination of
14
suspicious url, misleading domain name, images from
an honest site, other measures discussed in section 3,
and a username and password that have previously been
used at an honest site, SpoofGuard will intercept the post
and warn the user with a pop-up that foils the attack. We
have tested SpoofGuard with actual attacks found in the
wild and found the mechanisms generally unobtrusive
and effective. While technically savvy Internet profes-
sionals probably do not need SpoofGuard themselves,
there are many less sophisticated users who may beneﬁt
from this tool.
In order to effectively reduce the impact of Internet
fraud based on web spooﬁng, SpoofGuard must be dis-
tributed and deployed, or the mechanisms tested here
must be adopted by browser companies and integrated
into standard browser security mechanisms. While the
initial tests from our research effort are promising, we
expect to continue to reﬁne SpoofGuard and subject
the components of our method to more rigorous sta-
tistical testing. Especially if some of the server-side
methods described in section 6 are adopted by compa-
nies subject to web spooﬁng fraud, such as EarthLink,
Citibank, Morgan Stanley’s Discover unit, eBay, Pay-
Pal, banks and state lotteries [Ber03], we believe that
SpoofGuard methods will reduce fraud. In addition to
reducing the direct loss ﬁgure mentioned above, good
protection against web spooﬁng would signiﬁcantly re-
duce customer support costs.
A second consequence of deploying the methods de-
scribed in this paper is that phishers will have to work
harder to spoof web users into revealing sensitive infor-
mation. As discussed in section 5.3 and elsewhere, many
of our tests can be circumvented by relatively simple
modiﬁcations to spoof pages. Like virus detection and
spam ﬁltering, we expect that any serious effort to com-
bat web spooﬁng will lead to more sophisticated spoofs
and the need for more sophisticated defenses. As men-
tioned throughout the paper, the methods currently im-
plemented in SpoofGuard can be improved. Individual
page tests can be improved, more page test can be added,
and the formula for computing the spoof index can be
reﬁned. Furthermore, if e-commerce sites act on their
concern about the problem, server-side techniques offer
signiﬁcant promise for combating web spooﬁng.
From a broader perspective, web spooﬁng takes ad-
vantage of the unauthenticated email and weak web-site
authentication. As a Tumbleweed Communications web
site regarding phishing [Tum03] points out, one counter-
measure is “the use of digitally signed email to protect
against phishing hacker attacks and spam email.” While
this is certainly true, digitally signed email has been
technically feasible for many years, yet the adoption rate
remains small. Strong web site authentication could also
eliminate web spooﬁng. If challenge-response methods,
for example, were widely deployed, then a spoof site
authenticating a user would not have any way to imper-
sonate the user on the honest site. In this sense, Spoof-
Guard helps patch over a weakness in current web prac-
tices that could be solved more effectively by stronger
known technology. However, the history of the Internet
suggests that once a convention is widely adopted, it is
very difﬁcult to introduce new standards.
Acknowledgments
Thanks to Dan Boneh, Alissa Cooper, Greg Crabb,
Tom Pageler, Robert Rodriguez, and Chris Von Holt.
References
[Ber03]
[Bri03]
[CNN03]
in
18,
used
identity-theft
Tara Siegel Bernard.
logo
SmartMoney.com, August
http://www.smartmoney.
com/bn/ON/index.cfm?story=
ON-20030818-000809-1407%.
Citigroup’s
attempt.
2003.
Brightmail
brightmail.com, 2003.
inc.
http://www.
reel
iden-
scams
http://www3.cnn.com/
‘phishing’
tity.
2003/TECH/internet/07/21/
phishing.scam/, July 22, 2003.
in your
[Cox03] Mike Cox.
Fraudulent emails - thieves
informa-
Posting from the
http:
intend to steal your personal
tion 6/2003, 2003.
Michigan Attorney General,
//www.michigan.gov/ag/0,
1607,7-164--70494--,00.html.
[Din03]
[EY01]
Theo Van Dinter.
http://useast.spamassassin.
org/.
Spamassassin, 2003.
S.W. Smith E.Z. Ye, Y. Yuan. Web
spooﬁng revisited: Ssl and beyond, 2001.
http://www.cs.dartmouth.edu/
˜pkilab/demos/spoofing/.
[FBDW97] Edward W. Felten, Dirk Balfanz, Drew
Dean, and Dan S. Wallach. Web spooﬁng:
An internet con game.
In Proceedings of
20th National Information Systems Security
Conference, 1997.
[FBI03]
spooﬁng warning,
FBI web
2003.
http://www.fbi.gov/pressrel/
pressrel03/spoofing072103.
htm.
15
[HF03]
[Pax99]
[Sno03]
[Tum03]
Katie Hafner and Laurie J. Flynn. E-mail
swindle uses false report about a swindle.
NY Times, June 21, 2003.
Vern Paxson. Bro: a system for detect-
ing network intruders in real-time. Com-
puter Networks (Amsterdam, Netherlands:
1999), 31(23–24):2435–2463, 1999.
Snort: The open source network intrusion
detection system, 2003. http://www.
snort.org/.
Tumbleweed Communications.
itally signed email
phishing
http://www.tumbleweed.com/
en/solutions/phishing.html.
Dig-
to protect against
2003.
attacks,
hacker
[VKJM00] R. Venkatesan, S.-M. Koon, M. H.
Jakubowski, and P. Moulin. Robust im-
age hashing.
In Proceedings of the Inter-
national Conference on Image Processing,
2000.
[Von03]
C. T. Von Holt. Resident Agent In Charge,
US Secret Service, San Jose, CA. Private
communication, 2003.
16