### Image Hashing and Frequency Tracking

The image database stores entries in the following format:
- (d1, f1)
- (d2, f2)
- ...
- image-hash
- (ds, fs)

Here, \( d_i \) represents the domain where the image was found, and \( f_i \) is the frequency of user visits to that page. The plug-in either maintains the frequency value itself (incrementing by one each time the page is loaded) or uses the browser’s history file to compute it. Only images referenced with the SPOOFGUARD attribute are stored in the database.

When the browser downloads a login page containing an image whose hash is in the database, it performs the following steps:
1. **Domain Check**: It checks if the page’s domain is in the list of domains associated with the image. If so, let \( F \) be the frequency for the domain. If not, set \( F \) to 0.
2. **Frequency Calculation**: Let \( M \) be the maximum frequency in the image’s record. The test returns the value \( p = 1 - \frac{F}{M} \).

To illustrate, consider the eBay login page with an image marked with SPOOFGUARD. The record in the plug-in’s image database for this image will likely show the highest frequency for the eBay login page. Therefore, the eBay login page will have \( p = 0 \), indicating it is not likely to be a spoof. Other pages containing this image with a SPOOFGUARD attribute (either set up by an attacker or as part of a DoS attack) will have a much lower frequency, resulting in a \( p \) value close to 1. This technique helps prevent abuse of the test for denial of service attacks.

### Password Hashing and Site-Specific Salt

Users often use the same password across multiple sites. For example, the same password might be used for both an E*Trade account and a newspaper site. To combat this, we can use site-specific password salt. This approach also addresses other security issues, such as when attackers break into a low-security site and try the recovered username/password combinations at financial sites. As a result, a web site implementing proper security policies can suffer due to other sites' lack of recent patches and clear-text password storage.

To make passwords at one site independent of those at other sites, a new SALT attribute can be added to the HTML `<input>` element. This attribute allows a site to specify per-server salt, which must be unique to the site. For example, the domain name can be used as a salt.

When processing a password field, the browser computes \( E_{\text{pwd}}[\text{salt}] \), where \( E \) is a block cipher, `pwd` is the user-entered password, and `salt` is from the input HTML element. The browser transmits the resulting value rather than the user’s password. If the `salt` attribute is not present in the HTML page, the browser uses 0 as the salt. The key point is that with the block cipher, it is difficult to compute \( E_{\text{pwd}}[X] \) from \( E_{\text{pwd}}[Y] \) for \( X \neq Y \). Consequently, a newspaper site break-in will not compromise an E*Trade password. This method is similar to challenge-response authentication, except that each site uses a fixed and unique challenge rather than a random one. This way, the site only needs to store a hash of the submitted password value rather than the plaintext password.

**Challenges in Deployment:**
- All browsers must be simultaneously modified.
- Web sites must re-authenticate their users after this mechanism is deployed.
- The mechanism itself is susceptible to spoofing. A spoof site could contact the honest site to obtain the site-specific salt and pass it on to the victim, causing the victim’s browser to send the exact password needed to access the honest site.

However, if the request comes over HTTPS and the certificate check establishes a reliable association between the salt and the requesting domain, site-specific salt can still be useful. This ensures distinct passwords for distinct sites and prevents a phisher who sets up an insecure (non-HTTPS) site from obtaining a password associated with a more secure (HTTPS) site.

### More Speculative Techniques

We describe a few speculative techniques that might be useful in combating spoof sites. These methods have not been experimentally tested yet.

#### Collaborative Methods

Several projects use collaborative methods to identify spam email. A similar mechanism could be applied to blocking spoof sites. For example, a user who ignores a warning from the plug-in and enters private information on a spoof site might want to alert authorities and other users. By providing a “send alert” button in the browser plug-in, the user could notify a central server. If enough users identify the page as a spoof, the server could alert all plug-ins to block the page. This could significantly reduce the number of users duped by the spoof site.

**Challenges:**
- Users who are duped by spoof sites may be unaware of the “send alert” button and its function.
- This mechanism could potentially be used to launch a denial of service attack against an honest site.

#### Search Engines to the Rescue

Spoof sites are often direct copies of pages on the honest site. When viewing a sensitive page, the browser plug-in could perform a Google search on key phrases or links on the page. If a similar page is found at a different domain, the plug-in would increase the page’s spoof score.

**Challenges:**
- Pages are often cached at various sites, making it difficult to distinguish a spoof from a cached page.
- Automatic Google queries for every password page could overwhelm Google.
- There is no business incentive for Google to support such a service.

#### Forensics

Suppose internal tests at E*Trade indicate that a user’s password has been compromised. E*Trade suspects a spoof site and wishes to quickly determine its location. One option is to examine the user’s history file, but a privacy-conscious user might refuse to hand over the file. To reduce the user’s exposure, SpoofGuard could track sites where the user entered a password identical to their E*Trade password. Only those sites would be handed over to E*Trade.

**Challenges:**
- Most spoof sites are active for only a few days, and the process of obtaining data from the user might take longer.
- However, the problem of quickly locating spoof sites is important and deserves attention. We may experiment with using web crawlers for this task in the future.

### Conclusion

Most of the $37 million increase in losses from Internet fraud between 2001 and 2002 has been attributed to web spoofing. While web spoofing (or phishing) may become more sophisticated, we propose a set of methods effective against simple attacks. SpoofGuard uses a combination of stateless and stateful page evaluation and examination of outgoing POST data to compute a spoof index. When a user enters a username and password on a suspicious site, SpoofGuard intercepts the POST and warns the user, foiling the attack. Our tests with actual attacks have shown the mechanisms to be generally unobtrusive and effective.

To effectively reduce the impact of Internet fraud, SpoofGuard must be widely distributed and deployed, or the mechanisms must be adopted by browser companies and integrated into standard browser security. While our initial tests are promising, we expect to continue refining SpoofGuard and subjecting its components to more rigorous statistical testing. If some of the server-side methods described in section 6 are adopted by companies, we believe that SpoofGuard methods will reduce fraud, reducing both direct losses and customer support costs.

Deploying these methods will force phishers to work harder to spoof web users. As with virus detection and spam filtering, any serious effort to combat web spoofing will lead to more sophisticated spoofs and the need for more sophisticated defenses. The methods currently implemented in SpoofGuard can be improved, and individual page tests can be refined. If e-commerce sites act on their concerns, server-side techniques offer significant promise for combating web spoofing.

From a broader perspective, web spoofing exploits unauthenticated email and weak web-site authentication. While digitally signed email and strong web site authentication could eliminate web spoofing, the adoption rate remains small. In this sense, SpoofGuard helps patch over a weakness in current web practices that could be solved more effectively by stronger known technology. However, the history of the Internet suggests that once a convention is widely adopted, it is very difficult to introduce new standards.

### Acknowledgments

Thanks to Dan Boneh, Alissa Cooper, Greg Crabb, Tom Pageler, Robert Rodriguez, and Chris Von Holt.

### References

[Ber03] Tara Siegel Bernard. "Citigroup’s logo attempt." SmartMoney.com, August 18, 2003. http://www.smartmoney.com/bn/ON/index.cfm?story=ON-20030818-000809-1407%.

[Bri03] Brightmail Inc. http://www.brightmail.com, 2003.

[CNN03] "‘Phishing’ scams in your inbox." CNN, July 22, 2003. http://www3.cnn.com/TECH/internet/07/21/phishing.scam/.

[Cox03] Mike Cox. "Fraudulent emails - thieves intend to steal your personal information." Michigan Attorney General, June 2003. http://www.michigan.gov/ag/0,1607,7-164--70494--,00.html.

[Din03] Theo Van Dinter. Spamassassin, 2003. http://useast.spamassassin.org/.

[EY01] S.W. Smith, E.Z. Ye, Y. Yuan. "Web spoofing revisited: SSL and beyond," 2001. http://www.cs.dartmouth.edu/~pkilab/demos/spoofing/.

[FBDW97] Edward W. Felten, Dirk Balfanz, Drew Dean, and Dan S. Wallach. "Web spoofing: An internet con game." In Proceedings of 20th National Information Systems Security Conference, 1997.

[FBI03] FBI web spoofing warning, 2003. http://www.fbi.gov/pressrel/pressrel03/spoofing072103.htm.

[HF03] Katie Hafner and Laurie J. Flynn. "E-mail swindle uses false report about a swindle." NY Times, June 21, 2003.

[Pax99] Vern Paxson. "Bro: a system for detecting network intruders in real-time." Computer Networks (Amsterdam, Netherlands: 1999), 31(23–24):2435–2463, 1999.

[Sno03] Snort: The open source network intrusion detection system, 2003. http://www.snort.org/.

[Tum03] Tumbleweed Communications. "Digitally signed email to protect against phishing hacker attacks and spam email." 2003. http://www.tumbleweed.com/en/solutions/phishing.html.

[VKJM00] R. Venkatesan, S.-M. Koon, M. H. Jakubowski, and P. Moulin. "Robust image hashing." In Proceedings of the International Conference on Image Processing, 2000.

[Von03] C. T. Von Holt. Resident Agent In Charge, US Secret Service, San Jose, CA. Private communication, 2003.