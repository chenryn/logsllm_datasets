# Title: ConfErr: A Tool for Assessing Resilience to Human Configuration Errors

## Authors
Lorenzo Keller, Prasang Upadhyaya, George Candea  
École Polytechnique Fédérale de Lausanne (EPFL), Switzerland

## Abstract
We introduce ConfErr, a tool designed to test and quantify the resilience of software systems to human-induced configuration errors. ConfErr leverages error models grounded in psychology and linguistics to generate realistic configuration mistakes, which are then injected into the system. The tool measures the impact of these errors, producing a resilience profile that succinctly captures the sensitivity of the target software to different classes of configuration errors. This profile can be used to improve the software or to compare the resilience of functionally equivalent systems. ConfErr is highly portable, as all mutations are performed on abstract representations of the configuration files. Using ConfErr, we identified several serious flaws in popular software systems such as MySQL, PostgreSQL, Apache, BIND, and djbdns, and were able to directly compare the resilience of functionally equivalent systems like MySQL and PostgreSQL.

## 1. Introduction
Human error has long been a significant cause of downtime in computer systems, particularly in mission-critical infrastructures. Over two decades ago, 42% of incidents in high-end mainframe installations were attributed to human operators [4]. More recent studies have found that human errors account for 33% of failures at a major Internet portal and 36% at a global content hosting service [9]. A recent study attributed 58% of reported problems in database systems to mistakes made by database administrators [8].

Configuration errors represent a substantial portion of human administrator mistakes. Studies show that more than 55% of human-induced errors observed in Internet services are configuration errors [7, 9]. A field study found that 24% of Microsoft Windows NT downtime was caused by system configuration and maintenance errors [19]. These errors are particularly pernicious because they are often difficult to detect and fix, leading to extended repair times and wide-ranging effects. For example, a DNS misconfiguration once rendered Microsoft's MSN hosting services unavailable worldwide for 24 hours [12].

While better operator training can help, it often has limited benefits. Even highly trained individuals working on well-studied tasks with clear life-safety implications face significant error rates. For instance, nuclear plant operators, who undergo extensive training, were responsible for 44%-52% of all significant reactor problems [13]. Additionally, large software systems, with their complex behaviors and numerous configuration parameters, can overwhelm even the best administrators. For example, the Oracle 10g DBMS has 220 initialization parameters and 1,477 tables of system parameters [11], along with an 875-page "Administrator's Guide" [10].

Therefore, it is crucial that critical software systems be resilient to configuration mistakes. Redundancy and replication, while useful, do not significantly improve availability in the face of operator errors [9]. Better user interfaces can help but cannot transform a system vulnerable to configuration errors into a resilient one (e.g., graphical interfaces do not prevent errors in firewall configuration [16]).

To design systems that are less vulnerable to configuration errors, software engineers need tools that quantitatively measure the benefits of different techniques and implementations. A suitable, objective benchmark can also encourage system designers to compete on resilience to configuration errors. Previous benchmarking methodologies have involved manually porting system-specific errors to different systems [15, 7] or using real human operators [3], which can be expensive and may not yield objective results.

Automating configuration error testing is key to making such benchmarks uniform, economical, and comprehensive. In this paper, we present ConfErr, a tool that embodies these goals. ConfErr converts the understanding of human errors developed by psychologists and linguists [13, 14] into an automated benchmark for measuring systems' resilience to configuration errors. To our knowledge, this is the first error injection tool to do so.

ConfErr automatically generates and injects realistic errors into a system's configuration files, assesses the target's resilience to the injected errors, and computes the system's resilience profile. This profile can provide prompt feedback during development (e.g., to quantify the impact of a new feature/design on the ultimate reliability of the system) or serve as a benchmark to compare different functionally-equivalent systems (e.g., databases from different vendors).

Despite the emergence of configuration wizards and graphical user interfaces, configuration files remain the primary means of communicating the desired configuration to programs. Moreover, configuration files typically have a predefined syntactic structure, making them amenable to systematic, quantitative evaluation. We designed ConfErr to be extensible and accommodate arbitrary error generation plugins, enabling a wide array of configuration error types while preserving both the complete automation and efficiency of testing and benchmarking.

This paper makes three contributions:
1. We demonstrate how models of human error can be turned into practical, realistic error injection tools.
2. We show that using simple abstract representations of configuration files enables these models to be applied portably across different systems.
3. We show that, after running for less than one hour, ConfErr reveals serious design flaws in systems that are critical components of many computing infrastructures today.

In the rest of the paper, we describe the human error models used by ConfErr (Section 2), present the design of the tool (Section 3), and describe three error generator plugins for ConfErr (Section 4). We then present case studies of using ConfErr to find weaknesses in MySQL, PostgreSQL, Apache, BIND, and djbdns, as well as to compare the error resilience of MySQL to that of PostgreSQL (Section 5). We review related work (Section 6) and conclude (Section 7).

## 2. Configuration Error Models
Psychology offers insights into why human mistakes occur. Several researchers have studied the psychological underpinnings of human error, with one of the most succinct presentations being the Generic Error-Modeling System (GEMS) framework [13].

GEMS identifies multiple cognitive levels at which humans solve problems. The lowest skill-based level is used for common, repetitive tasks. Simple slips and lapses at this level account for about 60% of general human errors; typos and mistakes in digit recognition are examples of such slips. The next level up is the rule-based level of cognitive processing, where reasoning and problem-solving are performed by pattern-matching the situation at hand with previously-seen situations and applying the solutions discovered in those previous instances (e.g., applying the configuration principles of one database system to another). Mistakes caused by misapplying such rules account for roughly another 30% of human errors. Finally, the highest cognitive level is the knowledge-based level, where tasks are approached by reasoning from first principles, without the direct use of previously-formed rules or skills (e.g., configuring a piece of functionality that was previously never encountered). Mistakes at this level account for the remaining 10% of human errors.

Training and experience move task processing from higher cognitive levels to lower ones: a knowledge-based task may move over time to the rule-based level, as it becomes familiar and encoded into mental rules. Similarly, tasks performed on the rule-based level may move to the skill-based level if they become so familiar as to be "second nature."

ConfErr's error generators embody three error models that span all these cognitive levels: one models mistakes at the level of individual words in configuration files (Section 2.1), one models mistakes in the structure of configuration files (Section 2.2), and another one models semantic errors (Section 2.3).

### 2.1. Spelling Mistakes
Typographical errors (typos) occur during the process of typing. Highly disciplined individuals will proofread just-edited configuration files before applying them to the corresponding systems; others rely on the system to identify such problems upon startup. As computers become faster, this latter approach becomes increasingly widespread, similar to how programmers type up programs and invoke the compiler without re-reading their code.

Adapting the classification in [14], we divide one-letter typos into the following categories:
- **Omissions**: One character in a word is missing, corresponding to characters being missed during hurried typing. Single-letter omissions are more likely in practice than multi-letter omissions because more than one missing character is generally easier to notice.
- **Insertions**: A spurious letter is introduced in a word.
- **Substitutions**: A letter is replaced with another (incorrect) letter. We use the keyboard layout to produce realistic single-letter substitutions based on the model of operators accidentally pressing nearby keys.
- **Case alterations**: This is a special substitution error in which the case of adjacent letters is swapped due to a miscoordination in pressing the Shift key.
- **Transpositions**: Two adjacent letters in a word are swapped. Letters in different words are rarely swapped because humans automatically place cognitive boundaries between words.

### 2.2. Structural Errors
Configuration files generally have a well-specified structure; mistakes related to this structure trace their roots to all three cognitive levels. We reflect this in our model of structural mistakes.

At the skill-based level, we capture mistaken repetitions of configuration directives and misplacement of directives in sections of the configuration file, as might result from copy-paste operations. Another type of error is omission on account of configuration complexity: while editing a configuration with many parameters required in a section (or many sections required overall), one of these may be simply forgotten.

At the rule-based level, we model operator mistakes resulting from the use of a configuration format that is similar but incorrect. An example of such a mistake would be the "borrowing" of a configuration directive or section from another program configured by the same operator.

Mistakes at the knowledge-based level tend to result from a mismatch between the mental model the operator has of the system and the actual operation of the system [13]. For example, reverting a non-functioning configuration to the default configuration "just to get the system started" may omit critical directives without the operator realizing it.

Structural configuration errors abound in practice. For example, numerous cases for the Apache web server can be found in [1]: a common mistake is the omission of a directive that has to be present in each subsection (e.g., the `ServerName` directive in `VirtualHosts` sections) or the duplication of a directive (such as `Listen` or `NameVirtualHost`), with the final replica overriding all previous ones. Other common mistakes include the addition of wrong directives or entire sections of directives via copy-paste or moving directives to similar kinds of sections (e.g., access restrictions in `Directory` sections, index options for a `ScriptAlias` directory).

### 2.3. Semantic Errors
In addition to mistakes in syntax and structure, configuration errors can take on a semantic nature, resulting from the administrator's wrong understanding of how the system works. Semantic errors are introduced solely when operating at the highest cognitive level.

In our model, we capture two classes of semantic errors. The first class is inconsistent configurations, in which required constraints are not satisfied. For example, the value of one parameter (e.g., shared memory pool) may be related in a specific way to that of another (e.g., maximum number of client connections), and an ignorant operator may generate a configuration that does not satisfy this relation. A properly configured domain name service (DNS), for example, should provide both forward and reverse mappings for a given name-IP pair, but an operator might forget to set up one of the two mappings.

The second type of semantic errors occurs when the operator does not know exactly the meaning of a given parameter and uses it to configure a similar but different aspect of the system. For instance, DNS provides multiple record types, and an inexperienced administrator may associate an address to a domain via a CNAME record (normally used to declare aliases, not to assign addresses); this results in all other records associated with the domain name becoming inaccessible, since the unaliased domain name is necessary for correct name resolution.

## 3. The ConfErr Framework
The goal of ConfErr is to turn error models, such as the ones described above, into practical tools. ConfErr allows error models to be encoded in generator plugins and integrated into an end-to-end injection and measurement system. ConfErr automatically drives all parsing of initial configuration files, generation of errors, injection, startup and shutdown of the system under test (SUT), and measurement of the impact of each error on the system; none of these require human intervention.

After a brief overview of ConfErr's design (Section 3.1), we describe how it creates and uses abstract representations of configuration files (Section 3.2) and how error generation models are described (Section 3.3). Complete source code and documentation can be found at http://conferr.epfl.ch/.

### 3.1. Overview of ConfErr's Design
[Detailed description of ConfErr's design]

### 3.2. Abstract Representations of Configuration Files
[Detailed description of how ConfErr creates and uses abstract representations of configuration files]

### 3.3. Error Generation Models
[Detailed description of how error generation models are described and implemented in ConfErr]

---

This revised version aims to make the text more coherent, professional, and easier to read. It includes clearer headings, improved sentence structure, and a more logical flow of information.