with performance anomalies, and to differentiate among appli(cid:173)
cation performance changes and workload-related changes as
transactions are accumulated over time.
Prerequisite to applying regression is that a service provider
collects the application server access log that reflects all pro(cid:173)
cessed client transactions (i.e., client web page accesses), and
the CPU utilization ofthe application server(s) in the evaluated
system.
4.1 Regression-Based Transaction Model
To capture the site behavior across time we observe a num(cid:173)
ber of different client transactions over a monitoring window t
of fixed length L. We use the terms "monitoring window t" or
"time epoch t" interchangeably in the paper. The transaction
mix and system utilization are recorded at the end ofeach mon(cid:173)
itoring window. Assuming that there are totally n transaction
types processed by the server, we use the following notation:
• Tm denotes the time segment for monitored site behavior
and ITm I denotes the cardinality of the time segment T m,
i.e., the number of time epochs in T m;
• Ni,t is the number of transactions of the i-th type in the
monitoring window t, where 1 ::; i ::; n;
• UCPU,t
is the average CPU utilization of application
server during this monitoring window t E T m;
• D i is the average CPU demand of transactions of the i-th
type at application server, where 1 ~ i ~ n;
• Do is the average CPU overhead related to activities that
"keep the system up". There are operating system pro(cid:173)
cesses or background jobs that consume CPU time even
when there are no transactions in the system.
From the utilization law, one can easily obtain Eq. (1) for each
monitoring window t:
Do +L Ni,t . D i = UCPU,t . L.
i=l
(1 )
Let Ci,m denote the approximated CPU cost of D i for 0 ~ i ~
n in the time segment T m' Then, an approximated utilization
Ubpu,t can be calculated as
U'
CPU,t -
- C
+ L....."i=l
",n N· t
L
1"
. C·
1"m
.
(2)
O,m
To solve for Ci,m, one can choose a regression method from
a variety of known methods in the literature. A typical objec(cid:173)
tive for a regression method is to minimize either the absolute
error or the squared error. In all experiments, we use the Non(cid:173)
negative Least Squares Regression (Non-negative LSQ) pro(cid:173)
vided by MATLAB to obtain Ci,m. This non-negative LSQ
regression minimizes the error
Ern = L (Ubpu,t - UCPU,t)2
tETTn
1-4244-2398-9/08/$20.00 ©2008 IEEE
454
DSN 2008: Cherkasova et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:22:14 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
such that Ci,m ~ O.
When solving a large set of equations with collected moni(cid:173)
toring data over a large period of time, a direct (naive) lin(cid:173)
ear regression approach would attempt to set non-zero values
for as many transactions as it can to minimize the error when
the model is applied to the training set. However, this may
lead to poor prediction accuracy when the model is later ap(cid:173)
plied to other data sets, as the model may have become too
finely tuned to the training set alone. In statistical terms, the
model may "overfit" the data if it sets values to some coeffi(cid:173)
cients to minimize the random noise in the training data rather
than to correlate with the actual CPU utilization.
In order to
create a model which utilizes only the statistically significant
transactions, we use stepwise linear regression [10] to deter(cid:173)
mine which set of transactions are the best predictors for the
observed CPU utilization. To determine the set of significant
transactions, the stepwise regression algorithm initializes with
an "empty" model which includes none of the transactions. At
each following iteration, a new transaction is considered for in(cid:173)
clusion in the model. The best transaction is chosen by adding
the transaction which results in the lowest mean squared error
when it is included. Before the new transaction is included in
the model, it must pass an F-test which determines if includ(cid:173)
ing the extra transaction results in a statistically significant im(cid:173)
provement in the model's accuracy. If the F-test fails, then the
algorithm terminates since including any further transactions
cannot provide a significant benefit. The coefficients for the
selected transactions are calculated using the linear regression
technique described above. The coefficient for the transactions
not included in the model is set to zero.
Typically, for an application with n transactions, one needs
at least n + 1 samples to do regression using all n transactions.
However, since we do transaction selection using a stepwise
linear regression and an F-test, we can do regression by in(cid:173)
cluding only a subset ofn transactions in the regression model.
This allows us to apply regression without having to wait all
n + 1 samples.
4.2 Algorithm Outline
Using statistical regression, we can build a model that ap(cid:173)
proximates the overall resource cost (CPU demand) of appli(cid:173)
cation transactions on a given hardware configuration. How(cid:173)
ever, an accuracy of the modeling results critically depends on
the quality of monitoring data used in the regression analysis:
if the collected data contain periods of performance anoma(cid:173)
lies or periods when an updated application exhibits very dif(cid:173)
ferent performance characteristics, then this can significantly
impact the derived transaction cost and can lead to an inac(cid:173)
curate approximation model. The challenge is to design an
on-line method that alarms service providers ofmodel changes
related to performance anomalies and application updates. Our
method has the following three phases:
• Finding the optimal segmentation. This stage of the
algorithm identifies the time points when the transac(cid:173)
tion cost model exhibits a change.
For example, as
shown in Figure 3, the CPU costs of the transactions
(TTl, TT2, ... , TT n ) during the time interval (To, T1 ) are
defined by a model (Co, C1 , C2 , ... , Cn). After that, for
a time interval (T1 , T2 ) there was no a single regression
model that provides the transaction costs within a spec(cid:173)
ified error bound. This time period is signaled as hav-
'1
T~
To
Figure 3. Finding optimal segmentation and detecting
anomalies.
~ dme
ing anomalous behavior. As for time interval (T2, T 3 ),
the transaction cost function is defined by a new model
(Cb, Cf, C~, ... , C~).
• Filtering out the anomalous segments. Our goal is to con(cid:173)
tinuously maintain the model that reflects a normal appli(cid:173)
cation resource consumption behavior. At this stage, we
filter out anomalous measurements identified in the col(cid:173)
lected data set, e.g., the time period (T1 , T2 ) that corre(cid:173)
sponds to anomalous time fragment a shown in Figure 3.
• Model reconciliation. After anomalies have been filtered
out, one would like to unify the time segments with no
application change/update/modification by using a single
regression model: we attempt to "reconcile" two differ(cid:173)
ent segments (models) by using a new common model as
shown in Figure 4.
•••• '3
Figure 4. Model reconciliation.
time
We try to find a new solution (new model) for con1bined
transaction data in (To, T1 ) and (T2,T3 ) with a given
(predefined) error. If two models can be reconciled then
an observed model change is indicative of the workload
change and not of an application change. We use the
reconciled model to represent application behavior across
different workload mixes.
If the model reconciliation does not work then it means these
models indeed describe different consumption models of ap(cid:173)
plication over time, and it is indicative of an actual application
performance change.
4.3 On-Line Algorithm Description
This section describes the three phases of the on-line model
change and anomaly detection algorithm in more detail.
1) Finding the optimal segmentation
This stage of the algorithm identifies the time points where
the transaction cost model exhibits a change. In other words,
we aim to divide a given time interval T into time segments
Tm (T = UTm) such that within each time segment T m the
application resource consumption model and the transaction
costs are similar. We use a cost-based statisticalleaming algo(cid:173)
rithm to divide the time into segments with a similar regression
model. The algorithm is composed of two steps:
• construction of weights for each time segment T m;
• dynamic programming to find the optimum segmentation
(that covers a given period T) with respect to the weights.
The algorithm constructs an edge with a weight, W m , for each
possible time segment T m ~ T. This weight represents the
cost of forming the segment T m' Intuitively, we would like the
weight W m to be small if the resource cost of transactions in
1-4244-2398-9/08/$20.00 ©2008 IEEE
455
DSN 2008: Cherkasova et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:22:14 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
Tm can be accurately approximated with the same regression
model, and to be large ifthe regression model has a poor fit for
approximating the resource cost of all the transactions in T m'
The weight function, W m is selected as a Lagrangian sum of
two cost functions: WI,m and W2,m, where
• the function WI,m is the total regression error over T m:
WI,m == L (UcPU,t - UCPU,t)2
tETrn
• the function W2,m is a length penalty function. A length
penalty function penalizes shorter time intervals over
longer time intervals to avoid dynamic programming to
break the time into segments of very short length (since
the regression error can be significantly smaller for a
shorter time segments). It is a function that decreases as
the length of the interval T m increases. We set it to a
function of the entropy of segment length as
W2,m == -(ITm\) 'log(ITml/ITI)
Our goal is to divide a given time interval T into time segments
Tm (T == UTm) that minimize the Lagrangian sum OfWI,m
and W2,m over the considered segments, i.e., the segmentation
that minimizes:
(3)
where the parameter A is the Lagrangian constant that is used
to control the average regression error E allow (averaged over
T) allowed in the model, and
m
m
Let us consider an example to explain the intuition for how the
equation (3) works. Let us first consider the time interval T
with no application updates or changes. Let time interval T be
divided into two consecutive time segments T I and T2 .
First of all, WI (TI ) + WI (T2) :S W(T), hence there are
two possibilities:
• One possibility is that a regression model constructed over
T is also a good fit over time segments T I and T2, and the
combined regression error of this model over time seg(cid:173)
ments T I and T2 is approximately equal to the total re(cid:173)
gression error over the original time interval T.
• The other possibility is that there could be different re(cid:173)
gression models that are constructed over shorter time
segments T I and T2 with the sum of regression errors
smaller than a regression error obtained when a single re(cid:173)
gression model is constructed over T.
For the second possibility, the question is whether the differ(cid:173)
ence is due to a noise or small outliers in T, or do segments T I
and T2 indeed represent different application behaviors, i.e.,
"before" and "after" the application modification and update.
This is where the W2 function in equation (3) comes into
play. The term log( ITmI/IT I) is a convex function of ITmi·
Therefore, each time a segment is split into multiple segments,
W 2 increases. This way, the original segment T results in the
smallest W2 compared to any subset of its segments, and A can
be viewed as a parameter that controls the amount of regres(cid:173)
sion error allowed in a segment. By increasing the value of A,
we allow a larger WI, regression error, in the segment. This
help in reconciling T I and T2 into a single segment represen(cid:173)
tation T. In such a way, by increasing the value of A one can
avoid the incorrect segmentations due to noise or small out(cid:173)
liers in the data T. When an average regression error over a
single segment T is within the allowable error E allow (fallow is
set by a service provider), the overall function (3) results in the
smallest value for the single time segment T compared to the
values computed to any of its sub-segments, e.g., T I and T2 .
Therefore, our approach groups all time segments defined by
the same CPU transaction cost (or the same regression model)
into a single segment. By decreasing the value of A, one can
prefer the regression models with a smaller total regression er(cid:173)
ror on the data, while possibly increasing the number of seg(cid:173)
ments over the data.
There is a trade-off between the allowable regression error
(it is a given parameter for our algorithm) and the algorithm
outcome. If the allowable regression error is set too low then
the algorithm may result in a high number of segments over
data, with many segments being neither anomalies or applica(cid:173)
tion changes (these are the false alarms, typically caused by
significant workload changes). From the other side, by setting
the allowable regression error too high, one can miss a number
of performance anomalies and application changes that hap(cid:173)
pened in these data and masked by the high allowable error. 1
2) Filtering out the anomalous segments
An anomalous time segment is one where observed CPU uti(cid:173)
lization cannot be explained by an application workload, i.e.,
measured CPU utilization can not be accounted for by the
transaction CPU cost function. This may happen if an un(cid:173)
known background process(es) is using the CPU resource ei(cid:173)
ther at a constant rate (e.g., using 40% ofthe CPU at every time
epoch during some time interval) or randomly (e.g., the CPU is
consumed by the background process at different rates at every
It is important to be able to detect and filter out the
epoch).
segments with anomalous behavior as otherwise the anoma(cid:173)
lous time epochs will corrupt the regression estimations of the
time segments with normal behavior. Furthermore, detecting
anomalous time segments provides an insight into the service
problems and a possibility to correct the problems before they
cause major service failure.
We consider a time segment Tm as anomalous if one of the
following conditions take place:
• The constant coefficient, Co, m, is large.
Typically, CO,m is used in the regression model to repre(cid:173)
sent the average CPU overhead related to "idle system"
activities. There are operating system processes or sys(cid:173)
tem backgroundjobs that consume CPU time even when
there is no transaction in the system. The estimate for the
"idle system" CPU overhead over a time epoch is set by
the service provider. When CO,m exceeds this threshold a
time segment Tm is considered as anomalous.
• The segment length ofTm is short, indicating that a model
does not get fit to ensure the allowed error threshold.
Intuitively, the same regression model should persist over
the whole time segment between the application up(cid:173)
dates/modifications unless something else, anomalous,
happens to the application consumption model and it
manifests itself via the model changes.
1Appendix provides a formal description of the algorithm.
1-4244-2398-9/08/$20.00 ©2008 IEEE
456
DSN 2008: Cherkasova et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:22:14 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
3) Model reconciliation
been
filtered
out,
time
anomalies have
one would
After
like to unify the
segments with no application
change/update/modification by using a single regression
model. This way, it is possible to differentiate between the
segments with application changes from the segments which
are the parts of the same application behavior and were
segmented out by the anomalies in between.
In such cases,
the consecutive segments can be reconciled into a single
segment after the anomalies in the data are removed. If there
is an application change, on the other hand, the segments will
not be reconciled, since the regression model that fits to the
individual segments will not fit to the overall single segment
without exceeding the allowable error (unless the application
performance change is so small that it still fits within the
allowable regression error).
4.4 Algorithm Complexity
The complexity of the algorithm is O(M 2
), where M is the
number of time samples collected so far. This is problematic
since the complexity is quadratic in a term that increases as