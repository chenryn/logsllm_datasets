matches some preconditions, then veriﬁes if an entry for the con-
nection originator exists in its state table. If so, and the detection
state associated with the originator is in the WAIT_HTTP state, the
handler advances the detection state to WAIT_FTP.
Figure 4: Flow-insensitive algorithm. Dashed arrows represent control dependencies; shaded nodes represent table accesses.
Step 1 in Algorithm 1 computes the PDG. The algorithm only
considers data dependencies, so the result is really a data depen-
dency graph (DDG). Figure 4(b) shows the full PDG for the pro-
gram; dashed lines represent conditional dependencies (ignored in
this phase). Note that the original program has been converted
to the intermediate assembly-like representation of HILTI ([38];
see §6.2), where each node corresponds to an atomic instruction
(conditional statements correspond to if.else branch instructions).
Step 2 computes the set C of table accesses (shaded nodes in the
graph). Step 3 performs backward slicing as described in §4.1, re-
turning the slice S which contains all program statements relevant
for the scheduling function A. Figure 4(c) describes the output of
this step for our example. Step 4 (Figure 4(d)) ﬁlters redundant
table accesses, i.e., accesses that use the same index variable such
as v3, (which corresponds to the high-level variable c.src in Fig-
ure 4(a)). These are easily identiﬁable since as part of the PDG
construction we transform the code into SSA form [20]. Finally,
during code generation (Step 5) the slice is translated to a straight-
line code sequence, and each table access is replaced by an instruc-
tion returning the corresponding index. The scheduling function A
for our example is reported in Figure 4(e).
Due to the simplicity of the example, the description above does
not account for the situation where some index value depends on
control ﬂow, or where the application accesses multiple indices.
The algorithm transparently deals with these occurrences by return-
ing all possible indices that the execution may generate.
Discussion: We ﬁnd that the algorithm described in this section
works well in a variety of use cases (see §6.4). Its main limitations
are that (i) being ﬂow-insensitive, it cannot soundly analyze pro-
grams that have loops in the index computation; and (ii) when table
indices depend on conditional instructions, the resulting schedul-
ing function is imprecise. In the next section we present a slicing
algorithm that overcomes these limitations.
4.3 Flow-sensitive Algorithm
Certain analyses contain conditional constructs, such as branches
and loops, in their index computation. These are typically the anal-
yses for which the scope cannot be deﬁned simply in terms of pro-
tocol units. One such example is the ProtocolConﬁrmation han-
dler in our multistep example, described in §3.1. To be effective, a
scheduling function A for such a program P should keep as much
as possible of the original control ﬂow. To do so, the backward
slice S on P must include both control and data edges.
We note, however, that even with this approach it is not possible
to preserve all control ﬂow. In fact, the slice S may retain branch
instructions whose outcome depends on the content of the table,
such as for example .
Such an expression cannot be executed in a scheduling function,
which “lives” in the scheduler and does not have access to the table.
We deal with this situation by pruning such branch instructions (), thus causing the instructions that depend on them
() to be executed unconditionally.
Algorithm 2: Flow-sensitive A generation
Compute PDG G from program P
1
Find the set of table accesses C in G
2
Compute the backward slice S from C
3
Remove from S branch conditions that are
4
data-dependent on statements in C
Remove superﬂuous branch conditions from S
Remove redundant table accesses from S
Recompute the slice S
Emit code for S
5
6
7
8
Algorithm 2 describes the high-level steps through which ﬂow-
sensitive scheduling function generation is performed. We discuss
each step using a simpliﬁed version of the ProtocolConﬁrmation
event handler from multistep (§3.1). Pseudocode is given in Fig-
ure 5(a). The program receives as inputs a connection ID and a
protocol ID. If the protocol is SSH and the destination port is 2222,
the handler creates a new entry for the connection responder in its
state table. If the protocol is IRC, the handler checks if the table
has an entry for the connection originator; if yes, it emits an alert.
Steps 1-3 of Algorithm 2 correspond to the same steps in Algo-
rithm 1, with the difference that in Algorithm 2 the analysis builds
the full program dependency graph. Therefore, the slice S returned
by Step 3 contains both control and data dependencies (Figure 5(b),
with control edges represented as dashed arrows). Steps 4-7 further
prune the subgraph. In Figure 5(a) and (b), nodes removed dur-
ing each step (and the corresponding lines in the high-level pseu-
docode) are marked with the step number. Step 4 removes branch
map hosts;  void HttpRequest(connection c,                  string method,                  string uri) {   if ( method == "GET" &&        "dl.html" in uri)   {     if ( c.src in hosts) {       if ( hosts[c.src] == WAIT_HTTP )             hosts[c.src] == WAIT_FTP;       }     } }       (a) Program text (pseudocode)  addr SF_HTTPRequest(connection c) {   addr v3 = struct.get c (cid:361)src(cid:362)   return.result v3 }      (e) Scheduling function (assembly)   method uri v0 = equal method “GET” v1 = string.find uri “dl.html” if.else v2 v2 = bool.and v0 v1 c v3 = struct.get c “src” v4 = map.exists hosts v3 if.else v4 v5 = map.get hosts v3 v6 = equal v5 WAIT_HTTP if.else v6 map.put hosts v3 WAIT_FTP (b) Original PDG (assembly) c v3 = struct.get c src v4 = map.exists hosts v3 v5 = map.get hosts v3 map.put hosts v3 WAIT_FTP (c) Slicing output c v3 = struct.get c src v4 = map.exists host v3 (d) Output after filtering Figure 5: Flow-sensitive algorithm (multistep example)
instructions that cannot be decided at run-time, as discussed above.
In Step 5, we also heuristically remove two classes of superﬂuous
branches: redundant ones, i.e., branches that would lead to the same
set of indices Ind(i) regardless of whether they are taken or not,
and branches for which one side would not lead to any table access.
Step 6 removes redundant table accesses, similar to Step 4 in Al-
gorithm 1. Finally, since the pruning performed in Steps 4-6 may
have disconnected further nodes from the rest of the graph, in Step
7 the program slice S is recomputed to ﬁlter them out. The result-
ing graph, and the scheduling function emitted by code generation
(Step 8) are reported respectively in Figure 5(c) and 5(d).
Discussion: By preserving part of the original control ﬂow Algo-
rithm 2 supports loops within scheduling functions, and can gener-
ate more precise results than Algorithm 1.
4.4 Soundness of Scheduling Functions
We deﬁne a scheduling function A to be sound if Ind(i) ⊆
A(i), i.e., if A returns, for every input i, a superset of the in-
dices the program P will access on that input. A relevant issue
is whether the algorithms described in this section generate sound
scheduling functions, because this guarantees that each detector in-
stance receives all the inputs relevant for its task. A program P is
transformed into a scheduling function A through two operations:
a slicing procedure, that extracts a slice S from P , and the pruning
step, that further removes various statements from S and restruc-
tures control ﬂow. Intuitively, both transformations must preserve
soundness.
We ﬁrst observe that, as our slicing procedure is correct, it pre-
serves all statements in P relevant to compute Ind(i). There-
fore executing S on any input i generates a set of indices S(i) s.t.
Ind(i) ⊆ S(i). We then need to show that S(i) ⊆ A(i).
For a slice S, we deﬁne πS(i) as the program path on input i,
i.e., the sequence of instructions executed by S when run on input
i. We then deﬁne the set of all possible paths executed by S as ΠS.
Both Algorithms 1 and 2 create an overapproximation A of S by
removing some (or all) branches and executing the dependent in-
struction unconditionally. Therefore, for each input i, A will gen-
erate a ﬁnite set of paths ΠA(i) ⊆ ΠS. The set ΠA(i) has the
following property. For every input i, let πS(i) be the path gener-
ated by the slice S. Then there exists a path πA(i) ∈ ΠA(i), that
executes the data-ﬂow instructions in πS(i). Note that if πA(i) ex-
ecutes the same data-ﬂow instructions as πS(i), it will generate the
same table indices. Informally, the property implies that for each
possible input i, A generates a superset of the indices returned by
S on the same input. Therefore Ind(i) ⊆ S(i) ⊆ A(i), and A is
sound.
4.5 Running Multiple Scheduling Functions
A full-ﬂedged IDS is expected to run several different analyses
on the same trafﬁc. In general, each analysis can have a different
scope, and a different scheduling function. When an event is gen-
erated, the IDS must therefore run the scheduling functions for all
analyses registered for that event. However, the number of possible
scopes will be substantially smaller than the number of analyses in
the system. Indeed, a 2009 analysis of Bro’s script corpus showed
that the majority of event handlers could be mapped to one of only
four scopes [37]. If two scheduling functions have equal scope only
one needs to be executed, reducing the amount of computation re-
quired. Furthermore, it may be possible to merge two schedul-
ing functions with different scopes, as long as one subsumes the
other. For example, the scope  subsumes the scope
. Scheduling according
to the former scope is safe even if the application uses the latter,
more speciﬁc scope.
5. SCHEDULING ALGORITHMS
Scheduling functions can infer scope for each program execu-
tion, but they do not imply any concrete scheduling algorithm. An
issue is therefore how to perform scheduling efﬁciently. This sec-
tion formalizes the scheduling problem as an invariant, and dis-
cusses how scheduling algorithms can maintain this invariant.
An IDS analysis within our model can be formalized as a pro-
gram P that executes in an event-driven fashion, updating its state
every time a new input is received. Given such a program, let I be
the space of inputs and S be the state space of the program. The
type of P is I → (S → S), i.e, given an input i ∈ I and a state
s ∈ S the new state of the program is given by P (i)(s). Without
loss of generality, assume that the state space of the program is a
set hosts;  void ProtocolConfirmation(connection c,                           int proto) {     if (proto == SSH &&          c.port == 2222) {         if ( c.dst !in hosts )             add(hosts, c.dst);     } else if ( proto == IRC ) {         if ( c.src in hosts )             report_host(c.src);     }}           (a) Program text (pseudocode) c v1 = struct.get c port v2 = equal v1 2222/tcp v0 = equal proto SSH proto v3 = bool.and v0 v2 if.else v3 v4 = struct.get c dst v6 = equal proto IRC v5 = set.exists hosts, v4 if.else v6 if.else v5 v7 = struct.get c src v8 = set.exists hosts v7 set.insert host v4 c v1 = struct.get c port v2 = equal v1 2222/tcp proto v0 = equal proto SSH v3 = bool.and v0 v2 if.else v3 v4 = struct.get c dst v7 = struct.get c src v5 = set.exists hosts v4 v8 = set.exists hosts v7 (c) Output after filtering (assembly) addr SF_ProtocolConfirmation(connection c,                              int proto {        v0 = equal proto SSH        v1 = struct.get c port        v2 = equal v1 2222/tcp        v3 = bool.and v0 v2        if.else v3 @L0 @L1 L0: v4 = struct.get c dst        return.result v4 L1: v7 = struct.get c src         return.result v7 }            (d) Scheduling function (assembly) (b) Slicing output (assembly) 4 4 6 6 5 5 7 7 5/7 5/7 4 4 6 6 possibly unbounded array or table T [0··· k] of bytes. Given the
program P , let Ind (i) be the set of indices of the table T that are
read by or written to when executing the program P with input i.
Furthermore, we stipulate that P runs within a multi-threaded sys-
tem, where each execution of P is in general scheduled to a differ-
ent thread. Each thread maintains its own private copy of the table
T holding program P ’s state. Throughout the rest of the discus-
sion assume that the program P is ﬁxed (i.e., everything implicitly
corresponds to the program P ).
A scheduler (denoted by Sch) takes a stream of inputs from
I and maps them to threads. Let mSch (i) be a positive integer
that denotes the ID of the thread to which Sch maps the input i.
Assume that the scheduler Sch, having already scheduled inputs
i1,··· , ik, receives a new input ik+1, and assigns it to the thread
ID mSch (ik+1). For a program P we want the scheduler Sch to
maintain the following invariant Inv:
mSch (ix) (cid:54)= mSch (iy) ⇒ Ind (ix) ∩ Ind (iy) = ∅
thus enforcing that inputs are mapped to different threads only if
the corresponding executions of P do not share state.
5.1 A General Scheduler
To maintain the invariant, a scheduler has to evaluate Ind (i1) ∩
Ind (i2) for every two inputs i1 and i2. In our approach we do not
compute Ind (i) directly; rather we assume to have a scheduling
function A such that for all i ∈ I, Ind (i) ⊆ A(i).
We will now consider a scheduler SchA which makes use of
the scheduling function A. Assume that the scheduler SchA has
already scheduled the inputs i1,··· , ik. Let mA(ij) be the thread
ID corresponding to the input ij (for 1 ≤ j ≤ k). We assume
that the schedule so far satisﬁes the invariant Inv. Suppose the
scheduler receives a new input ik+1. There are three cases:
Case 1: ik+1 is equal to ij for some j ∈ [1,··· , k].
In this case, schedule ik+1 on the same thread as ij.
Case 2: A(ik+1) ∩ Ind (ij) = ∅ for all j ∈ [1,··· , k].
In this case, ik+1 is scheduled on an arbitrary thread and mA(ik+1)
is assigned the ID of this thread.
Case 3: A(ik+1) ∩ Ind (ij) (cid:54)= ∅ for one or more j ∈ [1,··· , k].
In this case, the set A(ik+1) may overlap with multiple past Ind (ij),
where each ij was scheduled to a different thread. Therefore, it
is in general not possible to pick a thread ID mA(ik+1) that di-
rectly maintains the invariant. It is however still possible to ensure
that computation remains consistent, by transferring state across
threads. For each index x ∈ A(ik+1), we locate the thread holding
the respective table entry T [x]. We then consolidate all said table
entries on the private state of a single thread. Finally, we schedule
ik+1 on the same thread, and mA is updated accordingly.
5.2 Practical Event Scheduling
The scheduler outlined above has two main drawbacks. First, it
needs to keep track of past decisions, to ensure consistent schedul-
ing of future events. Also, it may pause computation and move data
across threads, in order to ensure that each program run has access
to all necessary state. Both issues generate overhead.
We note however that, for many relevant analyses, Ind (i) is a
singleton set for all i ∈ I. In other words, for every input i the
program P only reads or writes from a single index in the table T
(i.e., |Ind (i)| = 1). In particular, this applies to all analyses that
do not correlate information across contexts.
As singleton sets cannot partially overlap, case (3) from §5.1
cannot happen, and data movements are never necessary. More-
Application
Flowbytes
Httpvol
Scandetect
Multistep [1]
Dnstunnel [19]
Sidejack [19]
Approach/Key data structures
Counts the amount of per-ﬂow trafﬁc and generates
an event for each ﬂow crossing a given threshold.
Tracks the amount of trafﬁc generated by external
HTTP hosts, returns aggregate data sorted by host.
Detects horizontal and vertical port scans,
inte-
grating information from connection attempts and
HTTP requests.
Proof-of concept worm detector, inspired by a di-
dactic policy script for the Bro IDS. Detects worm
activity by tracking hosts that generate a speciﬁc se-
quence of events.
Simple DNS tunnel detector, tracking hosts that gen-
erate a large number of DNS requests without con-
tacting the resolved addresses.
HTTP sidejacking detector. Locates reuses of the
same authentication cookie by unrelated users.
Table 1: Summary of applications used in the evaluation.
over, scheduling can be performed statelessly, i.e., without keeping
track of past decisions. Let H be a hash function from table indices
to positive integers. The scheduler can then simply schedule an in-
put i on the thread with ID H(Ind (i)). Since H is a function, the
scheduler clearly satisﬁes the invariant Inv.
In practice, for most relevant detection analyses it is possible to
derive a scheduling function A that returns a singleton set, enabling
the use of this simple hash-based scheduler. If a system includes
limited number of analyses that do not satisfy this condition (i.e.,
each run of the analysis may access multiple indices), a possible
solution is to run them on a dedicated thread/core.