curacy of our power model by running two real-world applica-
tions: (1) video streaming over YouTube app; (2) web browsing
over Google Chrome Browser app. For video experiments, we play
a video [4] at 2K resolution, in both online mode (over cellular ra-
dio) and offline mode (downloaded to SD card). To get the network
energy consumption, we subtract the total offline energy which
contains energy consumed by decoding and rendering of video
from the total energy measured when running online. Similarly
for web experiments, we download the whole website to SD card
and open the locally stored homepage (.html) file on Chrome to
load the website in offline mode and then compare the same when
loaded in online mode. We compare the energy consumption esti-
mated by our model with the actual energy consumption measured
by Monsoon power monitor. The average relative errors are 3.7%
for video streaming and 2.1% for web browsing.
4.6 Software power monitor calibration
Although hardware power monitors such as Monsoon [17] pro-
vides highly accurate power readings of mobile devices by di-
rectly supplying power to them, it will be extremely inconvenient
for users to retrieves such information in daily use. In particu-
lar, it requires non-trivial hardware engineering efforts on cur-
rent COTS smartphones (e.g., remove the non-removable back
cover and battery). Android exposes battery status such as current
(/sys/class/power_supply/battery/current_now) and voltage
(/sys/class/power_supply/battery/voltage_now) which can
be used to measure the device power. Thus, besides different im-
pacting factors for power model construction, we also study the
accuracy of battery status (current, voltage) readings and whether
it can be calibrated and further used to report the device power.
First, we run different activities and collect battery status using the
software (API) and hardware (Monsoon) and calculate the average
relative errors. The software approach always underestimate the
power (Table 9 in Appendix A.5). A higher sampling rate may help
provide better estimation, but this will incur higher energy over-
head (Table 3). Next, we use DTR to calibrate the software power
values. Fig. 15 shows the calibration performance (SW) together
with our TH+SS model results. After calibration, the software-based
approach can achieve comparable performance. A higher sampling
rate (e.g., 10Hz) can even lead to better performance (i.e., lower
MAPE). However, we argue that a higher sampling rate will incur
higher overhead which is less energy-efficient.
To summarize, we empirically characterize several impacting
factors such as signal strength and throughput over power consump-
tion by smartphones using 5G services. We propose an ML-based
data-driven approach to construct power models for 5G networks.
We demonstrate that our models help increase accuracy in predict-
ing device power consumption. We show that the software power
monitor can achieve comparable accuracy after calibration.
Next, we take a closer look at two popular mobile applications,
video streaming and web browsing, both combined are expected to
cover more than 80% of the mobile traffic share by 2025 [8]. We look
at them from the perspective of both application QoE and energy
efficiency. We believe the proposed power models can be useful to
aid developers in making their application more energy-efficient.
For the following sections, we focus on mmWave 5G which are
considered key to mainstream 5G and have not been studied before
in the context of mobile applications.
5 VIDEO STREAMING OVER 5G
Adaptive bitrate (ABR) algorithms are the primary tools used to op-
timize video quality of experience (QoE). The research community
 0 5 10 15S10/VZ/NSA-HBS20/VZ/NSA-HBS20/VZ/NSA-LBS20/TM/NSA-LBS20/TM/SA-LBMAPE (%)Device/Carrier/NetworkTH+SSTHSS 0 2 4 6 8 10S10/VZ/NSA-HBS20/VZ/NSA-HBS20/VZ/NSA-LBS20/TM/NSA-LBS20/TM/SA-LBMAPE (%)Device/Carrier/NetworkTH+SSSW-1HzSW-10HzA Variegated Look at 5G in the Wild: Performance, Power, and QoE Implications
SIGCOMM ‚Äô21, August 23‚Äì28, 2021, Virtual Event, USA
has proposed a plethora of ABR algorithms for video streaming
in recent years [33, 38, 61, 62]. In this section, we demystify 5G‚Äôs
implication on video streaming by conducting the first in-depth
investigation of ABR streaming QoE over 5G with mmWave. We
aim to answer the following questions:
‚Ä¢ What‚Äôs the performance footprint of the current state-of-the-art
ABR algorithms under 5G and how does it compare with 4G?
‚Ä¢ What are the major factors that impact ABR streaming perfor-
mance over 5G?
‚Ä¢ What new mechanisms are needed to make future ABR algorithms
5G-aware and further improve the QoE?
5.1 Evaluation Methodology
Our testbed consists of an Apache server hosting the videos and a
DASH.js [15] video client. We use trace-driven emulation to ensure
that all algorithms experience the same set of network conditions.
We use the Lumos5G dataset [40] which contains 121 5G and 175
4G throughput traces, collected at 1-second granularity. We fo-
cus on traces collected with mmWave coverage as 5G‚Äôs high-band
frequency range is considered key to support UHD and beyond
video streaming [49]. We use a custom 4K video [3] and encode
it using FFmpeg [6] with libx264 into 6 tracks (or qualities) with
different bitrates. 4K (or even 16K) video streaming usually requires
25-120 Mbps (246-328 Mbps) bandwidth [11, 18, 19, 66] which can
be easily met by 5G. Thus, to identify rate adaptation challenges
in 5G which has a mean throughput value that is 10√ó of 4G, we
scale the video bitrate of 5G tracks used to match its throughput
range. This ensures avoiding any trivial bitrate selection. We set
the bitrate of the top track (i.e., highest video quality) to match
the median throughput of 5G/4G network traces. In this study, the
maximum bitrate track for 5G is 160 Mbps, and 20 Mbps for 4G.
We then decide the bitrates for lower-quality tracks by keeping
the encoded bitrate ratio as ‚àº1.5 [45] between two adjacent tracks.
Note, our goal here is not to understand whether video streaming
is better over 5G or 4G. Rather, we focus on studying whether ex-
isting ABR algorithms can work well over mmWave 5G. Using the
throughput traces, we use Linux tc on the client side and control
the instantaneous bandwidth. For showing results, we normalize
the video bitrates by the bitrate of the top track.
We study the following 7 state-of-the-art ABR algorithms cover-
ing 4 different categories. (1) Buffer-based: BBA [32] and BOLA [56]
make bitrate decisions based on the buffer occupancy. (2) Throughput-
based: simple rate-based (RB) and FESTIVE [33] use information of
past chunks to estimate future throughput and decide the bitrate
of the next chunk to download. (3) Control theoretic: FastMPC and
RobustMPC [62] make bitrate decisions by solving an optimization
problem of the QoE for the next ùëõ chunks (e.g., ùëõ = 5). (4) Machine
learning-based: Pensieve [38] adopts a deep neural-network to learn
bitrate decisions that maximize a QoE reward7.
5.2 Performance of Existing ABR Schemes
Overall, we find that multiple ABR algorithms that work well un-
der 4G do not maintain the high performance under 5G. Fig. 17
summarizes the bitrate and the video stall time for different ABR
7We show the results of the Pensieve model trained with real Lumos5G [40] network
traces. We also verify that the performance observed by using models trained with
synthetic traces (as suggested in their paper [38]) and Lumos5G traces are similar.
algorithms. The top-right rectangular region marked using maroon-
colored dashed lines represents ABR algorithms with better QoE.
Here, better QoE refers to ABR algorithms that achieve less than 5%
video stall and over 0.8 normalized bitrate across different traces.
For 5G, only one algorithm (robustMPC) provides better QoE while
for 4G there are 3 more algorithms.
Although most of the ABR algorithms under 5G can achieve
similar normalized bitrates as they are in 4G (i.e., similar Y-axis
values in Figs. 17a and 17b, with an average drop of only 3.5%),
the concerning problem for video streaming over 5G lies in the
video stalls. For RB, BOLA, MPC, and Pensieve, we observe a sig-
nificant increase (58.2% on average) of video stall. Fig. 17c shows
that except for BBA all other ABR algorithms suffer an increase in
video stalls when running over 5G. For instance, the mean video
stall time for fastMPC and Pensieve has increased by 82.0% and
259.5%, respectively. Pensieve outperforms all other algorithms in
4G but incurs the highest video stall time under 5G setting. Since
Pensieve makes bitrate selection to optimize its QoE reward, we
also compare its QoE reward with that of fastMPC and robustMPC.
Pensieve‚Äôs QoE reward improvement is also marginal compared
to other algorithms (0.66% improvement over fastMPC and 5.93%
over robustMPC), which is 3√ó lower than the results in the original
Pensieve paper. A possible explanation is that for 5G networks, a
larger dataset is needed for training the model to learn 5G specific
characteristics and make better decisions, which deserves further
study. After taking a closer look at the bitrate decisions taken by
Pensieve and fastMPC, we find that they sometimes choose the
highest bitrate chunk only to regret that it was a wrong decision
that is difficult to undo, resulting in a very high stall time. This is not
happening in 4G scenarios with the same optimization metric used.
Based on this phenomenon, next we dig further to quantitatively
understand the challenges involved in running ABR algorithms for
video streaming over 5G networks (¬ß5.3).
5.3 Challenges in ABR Streaming under 5G
Throughput prediction. Many ABR algorithms incorporate net-
work throughput into its decision by leveraging a throughput pre-
dictor and their performance heavily depends on prediction accu-
racy. To study the impact of throughput prediction on 5G video
streaming, we fix other parts in an ABR algorithm and plug in dif-
ferent throughput predictors and compare the incurred QoE. Con-
sidered as one of the state-of-the-art ABR algorithms, we choose
fastMPC as the baseline since it explicitly incorporates a throughput
predictor while Fugu [61] and Pensieve use throughput informa-
tion implicitly. We compare three different throughput predictors:
(1) hmMPC: the original throughput predictor used by fastMPC
uses harmonic mean of past throughput values to predict future
throughput, (2) MPC_GDBT: a state-of-the-art mmWave 5G-specific
throughput predictor [40] that adopts a ML based approach called
Gradient Boosted Decision Tree (GDBT), and (3) truthMPC: ground-
truth throughput trace to represent the optimal online through-
put prediction scheme. Since MPC‚Äôs goal is to maximize its QoE
function [62], we use the QoE function as the metric to evaluate
the effectiveness of applying the 5G-specific throughput predictor.
Fig. 18a indicates that using the GDBT throughput predictor can
achieve 31.98% higher normalized QoE compared to the default har-
monic mean predictor. Compared to truthMPC though, adopting the
SIGCOMM ‚Äô21, August 23‚Äì28, 2021, Virtual Event, USA
Arvind Narayanan‚àó, Xumiao Zhang‚àó, Ruiyang Zhu, Ahmad Hassan, Shuowei Jin, et al.
(a) Two dimensional QoE for 5G.
(b) Two dimensional QoE for 4G.
(c) 4G & 5G video stall time.
Figure 17: QoE of different ABR algorithms in (a) 5G (b) 4G, and (c) comparison of video stall.
Table 4: Energy consumption for different
interface selection schemes.
Interface selection scheme
5G-only MPC
5G-aware MPC
5G-aware MPC NO*
(*NO = No Overhead)
Energy (J)
495.0¬±55.1
474.4¬±59.1
475.0¬±58.9
Figure 18: QoE impact of: (a) throughput predictors (b) chunk length, and (c) inter-
face selection schemes.
GDBT predictor only provides 1.3% less QoE. Therefore, improving
throughput prediction accuracy in ABR algorithms can significantly
enhance video streaming QoE and provide opportunities to build
better 5G-aware throughput-predictors. Since 5G now spans across
many different bands and its network performance variation is
large (¬ß3), building better throughput prediction schemes is not
only vital to make ABRs work well over 5G but also to improve our
understanding of the 5G ecosystem in general.
Decision making granularity. An ABR algorithm‚Äôs decisions are
coarse-grained in that it has to do chunk selection on chunk bound-
aries, and once made, such decisions cannot be rolled back. Specif-
ically in our 5G video streaming results, we find that just one or
two bad chunk selections can significantly affect QoE of the entire
stream. This one chunk download decision indeed quickly drains
the playback buffer or even causes 5‚Äì10 seconds of rebuffering.
One fix is to reduce the video chunk length to support fine-grained
selections. We study the effect of different chunk lengths (1/2/4s)
on 5G video streaming (with fastMPC). Fig. 18b shows that using
1s chunks provides 21.5% (35.9%) higher bitrate and 33.6% (29.8%)
less video stalls compared to 2s (4s) chunks. Therefore, although 2s
and 4s chunks are typically suggested for ABR [2], we argue video
content providers should consider shorter length chunks (e.g., 1s)
so that ABR algorithms can make finer-grained decisions and adapt
better to the highly fluctuating 5G network conditions.
Table 5: Factors considered for analyzing their impact on
page load time and energy consumption.
Factor
Abbr
DNO
Size of dynamic objs / total page size (in bytes) DSO
NO
# of dynamic/total objs
# of objects
Factor
Abbr
# of images (videos) NI (NV)
Total Page Size
Avg. Object Size
PS
AOS
video stall time by 26.9% compared to always using 5G interface
during the entire video. Compared to the 5G-aware MPC with no
overhead version (where we remove the interface switch delay,
assuming the UE can instantly switch between 4G and 5G), our
realistic interface selection model only incurs 4.0% more stall time.
Table 4 shows the corresponding energy consumption, measured by
feeding the collected video packet traces into our 5G power model
(¬ß4). As shown, the proposed 5G-aware schemes consumes 4.2% less
energy than always using 5G. It‚Äôs also slightly ‚Äúgreener‚Äù than the no
overhead version by trading a little bit of video quality: downloading
higher quality chunks and consuming more energy. Figure 18c
and Table 4 conclude that carefully selecting between 4G and 5G
interfaces can both improve adaptive video streaming performance
(26.9% fewer stalls) as well as reduce the energy consumption (by
4.2%, comparative to the 4.7% saving achieved in [59]).
6 QoE IMPLICATIONS OF WEB BROWSING
5.4 Improving 5G ABR Streaming
Based on our observation that 5G consumes more power than 4G
when the throughput is low (¬ß4) and 5G throughput fluctuates a
lot, we propose 5G-aware video streaming. The idea is switch
to 4G when ABR algorithms predict that 5G throughput is low
(i.e., <4G‚Äôs average throughput), given that 4G provides relatively
stable bandwidth, and switch back to 5G when the video buffer
level has reached over some threshold (empirically set to 10s). We
also take into account the switching overhead between 4G and
5G (¬ß4) and emulate the switching delay using Linux tc. Similarly,
we use fastMPC as the baseline ABR algorithm. Figure 18c depicts