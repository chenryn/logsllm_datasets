such, the pr for cluster ts1 is 0.50. In Table II for f7, there
are only two unique cluster pairs, i.e., (cid:104)tc1, ts1(cid:105) and (cid:104)ts2, tc2(cid:105).
Therefore, all clusters have their pr = 1, suggesting better
clustering quality than using f1.
Structure Coherence Constraints. Structure coherence con-
straints state that messages of the same type share similar ﬁeld
structure. For messages of different types, they may share some
common ﬁelds, separated by their unique ﬁelds. When aligning
these messages, alignment gaps are formed due to these type-
speciﬁc ﬁelds. For example in Figure 9, the two messages
are of different types with different ﬁeld structure. If they are
wrongly put into a cluster, a lot of gaps (‘-’) will be inserted
to make their common ﬁelds aligned. Although gaps also exist
in the alignment for messages of the same type (due to data
variation), the former case usually results in more gaps. Hence,
8
ThresholdErrorRateEERFNMRFMRfield1field2field3field3field1!"!#----after clustering with the candidate ﬁeld, we align messages
in the same cluster again and count the average number of
alignment gaps. The proportion of gaps is used as the prior
probability of coherence constraints.
ps = 1 − Average number of gaps in a message
Total length of an (aligned) message
For example, there are 4 messages mc0, mc2, mc3, and mc4
in cluster tc1 of ﬁeld f7 in Figure 7b. Based on the MSA
results shown in Figure 4a, messages mc0 and mc4 have 11
gaps after alignment, denoted by the symbols ‘-’ inserted at
the tail after alignment. In contrast, mc2 and mc3 have no
gap. After alignment (and gap insertion), all the four messages
have the length of 28. Hence the average number of gaps is
(11 + 0 + 0 + 11)/4 = 5.5 for tc1 and ps for the cluster is
computed as 1 − 5.5/28.
Dimension Constraints. We consider two metrics in dimen-
sion constraints: the total number of clusters and the number
of single-message clusters, in which there is only a single
message.
The ﬁrst metric is deﬁned as follows.
rdistinct value =
Number of distinct ﬁeld values
Number of messages
We compare it with a threshold tvalue, which is conservatively
set
to 0.5 in this paper. If the metric is greater than the
threshold, it means that the candidate ﬁeld generates too many
clusters, which is less likely to be a true keyword. Note that
a true keyword usually has only a small number of distinct
values. Thus 0.5 is a very conservative value to make sure
the true keyword will not be ignored and it doesn’t affect the
number of generated clusters.
The second metric is the proportion of single-message
clusters over the total number of clusters.
rsingle cluster =
Number of single-message clusters
Number of clusters
It is also compared against a threshold tsingle, which is 0.5
as well in this paper. If both values are smaller than their
thresholds, the dimension constraint is given a high probability,
e.g., 0.95. Otherwise it is set a low probability, e.g., 0.1.
0.95,
0.1,
pd =
if rdistinct value < tvalue
and rsingle cluster < tsingle
otherwise
From the clustering results shown in Figure 7, we can decide
that rsingle cluster for ﬁeld f1 is 5/8, thus its pd is 0.1, whereas
f7 satisﬁes both conditions and its pd is 0.95.
Normalization. As discussed above, the four observation
constraints are represented by different metrics, which do not
mean general probabilities and may have different distribu-
tions. For example, EER is usually in range [0.3, 0.6], while
the computed pr for remote coupling constraints could be as
high as 1. If probabilities of one type of observation constraint
are limited in a small range, this type of observation constraint
may play a less important role compared with others. To
avoid this issue, we normalize probabilities of the same type
of constraints for all candidate ﬁelds to the same range, e.g.,
[0.1, 0.95], before further probabilistic inference.
9
C. Probabilistic Inference
In this stage, all the constraints are considered together to
form a joint distribution. Let boolean variable k denote the
keyword predicate and xi denote the observation predicates in
Table I. Then all constraints can be represented as probabilistic
functions with boolean variables. Speciﬁcally, an observation
constraint xi = 1(p) is translated as follows.
if xi is true
f (xi) =
1 − p, otherwise
And an inference constraint k
p→−−→ xi is translated as follows.
(cid:26)p,
(cid:26)p→,
if k → xi is true
(cid:88)
f (k, xi) =
1 − p→, otherwise
p←←−− xi is similarly transformed. Then
Inference constraint k
the conjunction of all the constraints can be denoted as the
product of all the corresponding probabilistic functions:
f (k, x1, x2, . . . , xn) = f1 × f2 × ··· × fm
The joint probability function is deﬁned as follows [53].
(cid:80)
f1 × f2 × ··· × fm
(f1 × f2 × ··· × fm)
k,x1,...,xn
p(k, x1, x2, . . . , xn) =
Our interest is the marginal probability of the assumption
k, which is the sum over all observation variables. This
value represents the probability that the candidate ﬁeld is the
keyword.
p(k) =
p(k, x1, x2, . . . , xn)
x1,...,xn
Factor Graph. Due to the large number of constraints, the
computation of the marginal probability is very expensive.
We use a graphical model, factor graph [86], to represent
all probabilistic functions and conduct efﬁcient computation.
A factor graph is a bipartite graph with two kinds of nodes,
i.e., factor nodes and variable nodes. Factor nodes represent
probabilistic functions. Variable nodes represent the variables
used in probabilistic functions with edges connected to the
corresponding factor nodes. Then the sum-product belief
propagation algorithm [53] is used to compute the marginal
probability of a node by iterative message passing in an
efﬁcient way. Intuitively, one can consider this as a rumor
spreading procedure. The observations are initial rumors. In
each iteration, each variable (think of it as a person) collects
all the rumors about itself from its neighbors, aggregates them,
and passes the aggregated rumor on to the connected factors.
Each factor (involving multiple variables) collects the rumors
of its variables and computes marginal probabilities based on
the conditional probabilities denoted by the factor and then
propagates the computed probabilities to its variables. The
process repeats until convergence. We are using an off-the-
shelf factor graph engine [17]. The details are hence elided.
V. EVALUATION
A few protocol reverse engineering works have been pro-
posed to cluster messages based on network traces. However,
their evaluation studies are inadequate in a number of places.
Most works only conduct experiments on a small number of
protocols with the focus on text protocols. As discussed earlier,
it is usually more difﬁcult to cluster binary protocols. Most
works rely on sensitive parameters which need to be adjusted
for different protocols. Hence,
to be evaluated
against more protocols to illustrate effectiveness and generality.
Another common issue is that most existing works do not
make their systems publicly available, nor do they use public
datasets. This makes it hard to validate these methods or
conduct comparative studies.
they ought
As binary analysis and network trace based techniques have
different application scenarios and none of binary analysis
techniques is publicly available, it is difﬁcult to compare NET-
PLIER with binary analysis techniques. Hence, our compara-
tive studies focus on existing network trace based techniques.
In this section, we compare NETPLIER with two state-of-the-
art methods, Netzob and Discoverer, and show the advantage
of NETPLIER with experiments on clustering of different
protocols and datasets of different sizes, format inference, and
state machine inference (Section V-A - Section V-D).
Internet of Things (IoT) devices are increasingly popular
today. The evaluation of existing protocol reverse engineering
works usually focus on well-known application layer protocols,
while IoT devices often have customized or self-deﬁned pro-
tocols for wireless communication. To validate the generality
of NETPLIER, we also compare with AWRE [69], a recent
work for the physical layer of proprietary wireless protocols
(Section V-E), and conduct evaluation with multiple unknown
protocols used in real IoT devices (Section V-F).
A. Experiment Setup
Datasets. We construct our datasets from several publicly
available traces [66], [41], [9], [5], [11], [14]. We ﬁlter
messages of 10 common protocols from these traces with focus
on binary protocols. Note that we cover most protocols tested
by existing works, while each existing work usually only tested
a small part of these protocols. For each protocol, we ﬁlter at
least 1000 messages except TFTP due to the lack of enough
messages. Table III shows the statistical information of the
datasets. These protocols represent different categories. FTP is
a common text protocol. DHCP has complex ﬁeld structures
which lead to low message similarities. ICMP and NTP are
simple in structure but may contain broadcast messages, which
leads to fewer coupling constraints. SMB and SMB2 are two
versions with different ﬁeld structures and both have many
message types, as shown in Table III. TFTP is used for ﬁle
transfer and its messages may vary a lot in length. ZeroAccess
is a P2P botnet protocol, which is a representative of command
and control protocols. DNP3 and Modbus are two commonly
used protocols in industrial control systems. The variety of
these protocols shows the generality of our method.
Implementation. In NETPLIER, we use MAFFT [46] for
multiple sequence alignment and pgmpy [17] for probabilistic
inference. As mentioned before, most existing works are not
open-sourced. Hence we re-implement
the two representa-
tive clustering methods discussed in Section II, Netzob and
Discoverer, for comparative studies. We implement Netzob
on its underlying framework [7] and implement Discoverer
based on a through study of its paper. The parameters are
chosen following Bossert’s work [25] and trained on small
10
TABLE III: Dataset information
# Message Types # Session
Server
Protocol
DHCP
DNP3
FTP
ICMP
Modbus
NTP
SMB
SMB2
TFTP
ZeroAccess
# Message
Client Server Total Client
523
460
458
492
494
678
454
510
225
577
1000
1000
1000
1000
1000
1000
1000
1000
453
1000
477
540
542
508
506
322
546
490
228
433
3
3
14
1
4
3
9
14
4
1
2
3
15
2
4
1
10
15
1
1
100
40
30
73
13
83
89
242
34
278
datasets with 100 messages. As only partial data of Netzob
are public and Discoverer used proprietary datasets,
is
hard to compare with original works. However, we test our
implementations on the datasets used in Netzob and achieve
similar results, which provides validation of the correctness of
our re-implementation.
it
B. Evaluation of Clustering
Evaluation Metrics. Some non-keyword ﬁelds may play the
same role as a keyword and also generate correct clusters.
Thus, the evaluation is focused on the clustering results instead
of the keyword identiﬁcation. Existing works use different
metrics in their experiments to evaluate clustering results and
most of them have similar meanings. In this paper, we use com-
mon objectives for clustering performance evaluation, which
are called homogeneity and completeness [71]. Homogeneity
means that each cluster contains only messages of a single
message type, while completeness means all messages of a
given type are assigned to the same cluster. We use two scores
to measure homogeneity and completeness, denoted as h and