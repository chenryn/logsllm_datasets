t
A
f
o
r
e
b
m
u
N
e
v
i
t
l
a
e
R
1
0.1
0.01
0.001
0.0001
0
Google
UCSB
TU Vienna
0.2
0.4
0.6
0.8
1
Probability Values
Figure 4: Attribute Character Distribution
proach to reduce the number of false positives is to modify the
training and detection thresholds to account for the higher
variability in the Google traﬃc. Nearly half of the number of
false positives are caused by anomalous search strings that
contain instances of non-printable characters (probably re-
quests issued by users with incompatible character sets) or
extremely long strings (such as URLs directly pasted into the
search ﬁeld). Another approach is to perform post-processing
of the output, maybe using a signature-based intrusion de-
tection system to discard anomalous queries with known de-
viations. In addition, it is not completely impossible to deal
with this amount of alerts manually. One or two full-time
employees could browse the list of alerts, quickly discarding
obviously incorrect instances and concentrating on the few
suspicious ones.
When analyzing the output for the two university log ﬁles,
we encountered several anomalous queries with attributes
that were not malicious, even though they could not be in-
terpreted as correct in any way. For example, our tool re-
ported a character string in a ﬁeld used by the application
to transmit an index. By discussing these queries with the
administrators of the corresponding sites, it was concluded
that some of the mistakes may have been introduced by users
that were testing the system for purposes other than security.
After estimating the false alarm rates, the detection ca-
pabilities of our tool were analyzed. For this experiment, a
number of attacks were introduced into the data set of TU
Vienna. We have chosen this data set to insert attacks for two
reasons. First, we had access to the log ﬁle and could inject
queries; something that was impossible for the Google data
set. Second, the vulnerable programs that were attacked had
already been installed at this site and were regularly used.
This allowed us to base the evaluation on real-world training
data.
We used eleven real-world exploits downloaded from popu-
lar security sites [6, 27, 29] for our experiment. The set of at-
tacks consisted of a buﬀer overﬂow against phorum [26], a php
message board, and three directory traversal attacks against
htmlscript [24]. Two XSS (cross-site scripting) exploits
were launched against imp [15], a web-based email client,
and two XSS exploits against csSearch [8], a search utility.
Webwho [9], a web-based directory service was compromised
using three variations of input validation errors. We also
wanted to assess the ability of our system to detect worms
such as Nimda or Code Red. However, as mentioned above,
all log ﬁles were created by Apache web servers. Apache
is not vulnerable against the attacks, as both worms exploit
vulnerabilities in Microsoft’s Internet Information Server (IIS).
We solved the problem by installing a Microsoft IIS server
and, after manually creating training data for the vulnerable
program, injecting the signature of a Code Red attack [5].
Then, we transformed the log ﬁle into Apache format and
run our system on it.
All eleven attacks and the Code Red worm have been re-
liably detected by our anomaly detection system, using the
same thresholds and training data that were used to evaluate
the false alarm rate for this data set. Although the attacks
were known to us, all are based on existing code that was
used unmodiﬁed. In addition, the malicious queries were in-
jected into the log ﬁles for this experiment after the model
algorithms were designed and the false alarm rate was as-
sessed. No manual tuning or adjustment was necessary.
Data Set
Google
UCSB
TU Vienna
Number of Alerts Number of Queries False Positive Rate Alarms per Day
4,944
0.01
1.89
0.000419
0.000650
0.000212
206
3
151
490,704
4617
713,500
Table 4: False Positive Rates
Attack Class
Buﬀer Overﬂow
Directory Traversal
XSS (Cross-Site Scripting)
Input Validation
Code Red
Length Char. Distr.
Structure Token Presence Order
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
Table 5: Detection Capabilities
Table 5 shows the models that reported an anomalous
query or an anomalous attribute for each class of attacks.
It is evident that there is no model that raises an alert for
all attacks. This underlines the importance of choosing and
combining diﬀerent properties of queries and attributes to
cover a large number of possible attack venues.
The length model, the character distribution model, and
the structural model are very eﬀective against a broad range
of attacks that inject a substantial amount of malicious pay-
load into an attribute string. Attacks such as buﬀer over-
ﬂow exploits (including the Code Red worm, which bases
its spreading mechanism on a buﬀer overﬂow in Microsoft’s
IIS) and cross-site scripting attempts require a substantial
amount of characters, thereby increasing the attribute length
noticeably. Also, a human operator can easily tell that a ma-
liciously modiﬁed attribute does not ‘look right’. This ob-
servation is reﬂected in its anomalous character distribution
and a structure that diﬀers from the previously established
proﬁle.
Input validation errors, including directory traversal at-
tempts, are harder to detect. The required number of charac-
ters is smaller than the number needed for buﬀer overﬂow or
XSS exploits, often in the range of the legitimate attribute.
Directory traversal attempts stand out because of the un-
usual structure of the attribute string (repetitions of slashes
and dots). Unfortunately, this is not true for input valida-
tion attacks in general. The three attacks that exploit an
error in Webwho did not result in an anomalous attribute for
the character distribution model or the structural model. In
this particular case, however, the token ﬁnder raised an alert,
because only a few diﬀerent values of the involved attribute
were encountered during the training phase.
The presence/absence and the parameter order model can
be evaded without much eﬀort by an adversary that has suﬃ-
cient knowledge of the structure of a legitimate query. Note,
however, that the available exploits used in our experiments
resulted in reported anomalies from at least one of the two
models in 8 out of 11 cases (one buﬀer overﬂow, four directory
traversal, and three input validation attacks). We therefore
decided to include these models into our IDS, especially be-
cause of the low number of false alarms they produce.
The results presented in this section show that our sys-
tem is able to detect a high percentage of attacks with a
very limited number of false positives (all attacks, with less
than 0.2% false alarms in our experiments). Some of the at-
tacks are also detectable by signature-based intrusion detec-
tion systems such as Snort, because they represent variations
of known attacks (e.g., Code Red, buﬀer overﬂows). Other
attacks use malicious manipulation of the query parameters,
which signature-based system do not notice. These attacks
are correctly ﬂagged by our anomaly detection system.
A limitation of the system is its reliance on web access logs.
Attacks that compromise the security of a web server before
the logging is performed may not be detected. The approach
described in [1] advocates the direct instrumentation of web
servers in order to perform timely detection of attacks, even
before a query is processed. This approach may introduce
some unwanted delay in certain cases, but if this delay is
acceptable then the system described here could be easily
modiﬁed to ﬁt that model.
6. CONCLUSIONS
Web-based attacks should be addressed by tools and tech-
niques that compose the precision of signature-based detec-
tion with the ﬂexibility of anomaly-based intrusion detection
system.
This paper introduces a novel approach to perform anomaly
detection, using as input HTTP queries containing param-
eters. The work presented here is novel in several ways.
First of all, to the best of our knowledge, this is the ﬁrst
anomaly detection system speciﬁcally tailored to the detec-
tion of web-based attacks. Second, the system takes advan-
tage of application-speciﬁc correlation between server-side
programs and parameters used in their invocation. Third,
the parameter characteristics (e.g., length and structure) are
learned from input data.
Ideally, the system will not re-
quire any installation-speciﬁc conﬁguration, even though the
level of sensitivity to anomalous data can be conﬁgured via
thresholds to suit diﬀerent site policies.
The system has been tested on data gathered at Google,
Inc. and two universities in the United States and Europe.
Future work will focus on further decreasing the number of
false positives by reﬁning the algorithms developed so far,
and by looking at additional features. The ultimate goal is
to be able to perform anomaly detection in real-time for web
sites that process millions of queries per day with virtually
no false alarms.
Acknowledgments
We would like to thank Urs Hoelzle from Google, Inc. who
made it possible to test our system on log ﬁles from one of
the world’s most popular web sites.
This research was supported by the Army Research Oﬃce,
under agreement DAAD19-01-1-0484. The views and conclu-
sions contained herein are those of the authors and should not
be interpreted as necessarily representing the oﬃcial policies
or endorsements, either expressed or implied, of the Army
Research Oﬃce, or the U.S. Government.
7. REFERENCES
[1] M. Almgren and U. Lindqvist. Application-Integrated
Data Collection for Security Monitoring. In Proceedings
of Recent Advances in Intrusion Detection (RAID),
LNCS, pages 22–36, Davis,CA, October 2001. Springer.
[2] Apache 2.0 Documentation, 2002.
http://www.apache.org/.
[3] D. Barbara, R. Goel, and S. Jajodia. Mining Malicious
Data Corruption with Hidden Markov Models. In 16th
Annual IFIP WG 11.3 Working Conference on Data
and Application Security, Cambridge, England, July
2002.
[4] Patrick Billingsley. Probability and Measure.
Wiley-Interscience, 3 edition, April 1995.
[5] CERT/CC. “Code Red Worm” Exploiting Buﬀer
Overﬂow In IIS Indexing Service DLL. Advisory
CA-2001-19, July 2001.
[6] CGI Security Homepage.
http://www.cgisecurity.com/, 2002.
[7] K. Coar and D. Robinson. The WWW Common
Gateway Interface, Version 1.1. Internet Draft, June
1999.
[8] csSearch. http://www.cgiscript.net/.
[9] Cyberstrider WebWho. http://www.webwho.co.uk/.
[10] D.E. Denning. An Intrusion Detection Model. IEEE
Transactions on Software Engineering, 13(2):222–232,
February 1987.
[11] R. Fielding et al. Hypertext Transfer Protocol –
HTTP/1.1. RFC 2616, June 1999.
[12] S. Forrest. A Sense of Self for UNIX Processes. In
Proceedings of the IEEE Symposium on Security and
Privacy, pages 120–128, Oakland, CA, May 1996.
[13] A.K. Ghosh, J. Wanken, and F. Charron. Detecting
Anomalous and Unknown Intrusions Against
Programs. In Proceedings of the Annual Computer
Security Applications Conference (ACSAC’98), pages
259–267, Scottsdale, AZ, December 1998.
[14] K. Ilgun, R.A. Kemmerer, and P.A. Porras. State
Transition Analysis: A Rule-Based Intrusion Detection
System. IEEE Transactions on Software Engineering,
21(3):181–199, March 1995.
[15] IMP Webmail Client. http://www.horde.org/imp/.
[16] H. S. Javitz and A. Valdes. The SRI IDES Statistical
Anomaly Detector. In Proceedings of the IEEE
Symposium on Security and Privacy, May 1991.
[17] C. Ko, M. Ruschitzka, and K. Levitt. Execution
Monitoring of Security-Critical Programs in
Distributed Systems: A Speciﬁcation-based Approach.
In Proceedings of the 1997 IEEE Symposium on
Security and Privacy, pages 175–187, May 1997.
[18] C. Kruegel, T. Toth, and E. Kirda. Service Speciﬁc
Anomaly Detection for Network Intrusion Detection.
In Symposium on Applied Computing (SAC). ACM
Scientiﬁc Press, March 2002.
[19] T. Lane and C.E. Brodley. Temporal sequence learning
and data reduction for anomaly detection. In
Proceedings of the 5th ACM conference on Computer
and communications security, pages 150–158. ACM
Press, 1998.
[20] W. Lee and S. Stolfo. A Framework for Constructing
Features and Models for Intrusion Detection Systems.
ACM Transactions on Information and System
Security, 3(4), November 2000.
[21] W. Lee, S. Stolfo, and K. Mok. Mining in a Data-ﬂow
Environment: Experience in Network Intrusion
Detection. In Proceedings of the 5th ACM SIGKDD
International Conference on Knowledge Discovery &
Data Mining (KDD ’99), San Diego, CA, August 1999.
[22] J. Liberty and D. Hurwitz. Programming ASP.NET.
O’REILLY, February 2002.
[23] U. Lindqvist and P.A. Porras. Detecting Computer and
Network Misuse with the Production-Based Expert
System Toolset (P-BEST). In IEEE Symposium on
Security and Privacy, pages 146–161, Oakland,
California, May 1999.
[24] Miva HtmlScript. http://www.htmlscript.com/.
[25] V. Paxson. Bro: A System for Detecting Network
Intruders in Real-Time. In Proceedings of the 7th
USENIX Security Symposium, San Antonio, TX,
January 1998.
[26] Phorum: PHP Message Board.
http://www.phorum.org/.
[27] PHP Advisory Homepage.
http://www.phpadvisory.com/, 2002.
[28] M. Roesch. Snort - Lightweight Intrusion Detection for
Networks. In Proceedings of the USENIX LISA ’99
Conference, November 1999.
[29] Security Focus Homepage.
http://www.securityfocus.com/, 2002.
[30] Andreas Stolcke and Stephen Omohundro. Hidden
Markov Model Induction by Bayesian Model Merging.
Advances in Neural Information Processing Systems,
1993.
[31] Andreas Stolcke and Stephen Omohundro. Inducing
Probabilistic Grammars by Bayesian Model Merging.
In Conference on Grammatical Inference, 1994.
[32] K. Tan and R. Maxion. ”Why 6?” Deﬁning the
Operational Limits of Stide, an Anomaly-Based
Intrusion Detector. In Proceedings of the IEEE
Symposium on Security and Privacy, pages 188–202,
Oakland, CA, May 2002.
[33] Robert Tarjan. Depth-First Search and Linear Graph
Algorithms. SIAM Journal of Computing, 1(2):10–20,
June 1972.
[34] Security Tracker. Vulnerability statistics April
2001-march 2002. http://www.securitytracker.com/
learn/statistics.html, April 2002.
[35] N. Ye, Y. Zhang, and C. M. Borror. Robustness of the
Markov chain model for cyber attack detection. IEEE
Transactions on Reliability, 52(3), September 2003.