that the ovals do not represent the states of the system at any 
particular time. The submodels are organized into four  mod-
ules:  computing  &  checkpointing,  failure  and  recovery,  cor-
related failure, and useful work computation.
Computing  and  checkpointing  module.  The  com-
pute_nodes  submodel  depicts  the  computation  and  check-
pointing  behavior  of  the  compute  nodes  in  the  failure-free 
mode. While the compute nodes are in execution, the applica-
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
tion may be performing either computation or I/O operations, 
and  this  is  represented  in  the  app_workload  submodel.  The 
master  submodel  represents  the  master  node  in  the coordi-
nated  checkpointing  protocol.  It  triggers  and  coordinates  the 
checkpointing,  as  modeled  in  the  compute_nodes  submodel. 
The coordination among the compute nodes is modeled in the 
coordination submodel. The io_nodes submodel captures the 
I/O operations conducted by I/O nodes. It receives data from 
the  compute_nodes  submodel, writes/reads  checkpoints 
to/from  the  file-system,  and  writes  data  on  behalf  of  the  ap-
plication in the app_workload submodel. These five submod-
els form the computing and checkpointing module of the sys-
tem model and are further described in Section 5. 
Table 1: Submodel List 
Module 
Computing 
& check-
pointing 
Submodel 
app_workload 
compute_nodes 
coordination 
io_nodes 
master 
in 
state 
Comments 
Application  state:  performing  compu-
tation or I/O operations 
Compute  processor 
the 
checkpoint cycle: executing (including 
both  application’s  computation  and 
I/O  operations),  quiescing,  or  check-
point dumping 
Coordination  procedure  for  check-
pointing 
I/O  processor  state:  idling  (including 
data  transmission  between  compute 
nodes),  writing  application  data,  writ-
ing checkpoint, or reading checkpoint; 
if checkpoint is locally buffered 
System  checkpointing  state:  if  check-
pointing is started or not 
Failure behavior of compute nodes 
Failure & 
recovery 
Correlated 
failure 
Useful 
work 
Recovery behavior of compute nodes 
comp_node_fail-
ure 
comp_node_recov
ery 
io_node_failure 
io_node_recovery 
system_reboot 
correlated_failures  Correlated failure behavior 
Failure behavior of I/O nodes 
Recovery behavior of I/O nodes 
System reboot operation 
useful_work 
Useful work computation 
Failure  and  recovery  module.  A  compute  node  or  I/O 
node may fail in any of its states. The occurrence of failures 
in compute nodes is  modeled in the comp_node_failure sub-
model.  Recovery  is  initiated  following  the  detection  of  the 
failure  and  modeled  in  the  comp_node_recovery  submodel. 
As  failures  may  also  occur  during  recovery,  compute  nodes 
may  experience  multiple  failures  and  subsequent  recoveries 
in  the  comp_node_recovery  submodel  before  the  final  suc-
cessful recovery, after  which  the system resumes the  normal 
execution  and  checkpointing  cycle.  Failures  of  compute 
nodes  do  not  affect  the  I/O  nodes  if  error propagation  is  not 
considered. The behavior of I/O nodes is similar, except that 
when  an  I/O  node  fails  while  writing  application  data  to  the 
file  system,  the  application  results  are  lost  and  the  system 
rolls back to the last checkpoint. This is represented in Figure 
1  by  an  arrow  from  the  io_node_failure  submodel  to  the 
comp_node_failure submodel.   
The  recovery  process  occurs  in  two  stages.  First,  the  I/O 
nodes  read  the  checkpoint  from  the  file  system  and  buffer  it 
in  their  local  memories.  Then  the  compute  nodes  read  the 
checkpoint  from  the  I/O  nodes  and  complete  the  recovery. 
The  compute  nodes  then  go  back  to  the  execution  state,  the 
master process gets reset, and the system exits the correlated 
failure window if there was one. If the checkpoint is already 
locally buffered in the I/O nodes when a compute node fails, 
the  first  stage  is  skipped.  If  an  I/O  node  fails  while  writing 
out a checkpoint, the checkpoint is aborted and the I/O nodes 
get restarted, but the compute nodes are not affected.   
If 
in 
(“severe 
recoveries 
the  number  of  unsuccessful 
the 
comp_node_recovery  and/or  io_node_recovery  submodel(s) 
exceeds  a  predefined  threshold,  the  whole  system,  including 
the  compute  nodes  and  I/O  nodes,  is  rebooted  in  sys-
tem_reboot 
from 
comp_node_recovery and io_node_recovery to system_reboot 
in  Figure  1).  When  the  reboot  completes,  I/O  processors  are 
ready for execution, but compute nodes still need to read the 
last  checkpoint  and  recover.  So  the  arrows  of  “reboot  com-
pletes”  from  the  system_reboot  submodel  point  to  the 
io_nodes  and  comp_node_failure  submodels, instead  of  the 
compute_nodes submodel in Figure 1.   
transitions 
failures” 
computing & checkpointing
useful work 
computation
useful_work
useful
work
master
app_workload
checkpointing control
detail
expansion
coordination
compute_nodes
detail
expansion
checkpoint
dump/
read
I/O operation
io_nodes
useful work 
computation useful work 
computation
recovery completes
failure
failure
useful work 
computation
comp_node_failure
useful work 
computation
reboot
completes
system_reboot
severe failures
failure & 
recovery
comp_node
_recovery
recovery 
starts
comp_node_failure
I/O 
failure
severe failures
reboot
completes
recovery 
completes
recovery 
starts
io_node_failure
io_node_recovery
failure rate 
control
failure rate 
control
failure rate 
control
correlated_failures
failure rate control
correlated 
failure
Figure 1: The overall composition of the model
Correlated  failure  module.  The  correlated_failures 
submodel  models  the  semantics  of  correlated  failures  sepa-
rately from the compute and I/O nodes’ failure and recovery 
submodels.  It  controls  the  rates  of  all  failures  in  the  system. 
When  a  correlated  failure  occurs,  the  system  enters  a  corre-
lated  failure  window,  in  which  it  experiences  failures  with  a 
higher  rate  than  the  independent  failure  rate.  Note  that  inde-
pendent  failures  can  continue  to  occur  when  the  system  is 
within a correlated failure window. 
Useful  work  module.  The  useful_work  submodel  calcu-
lates  the  useful  work  completed  by  the  system.  A  positive 
reward is accumulated  when the compute nodes perform job 
computation or I/O operations, and a negative reward equal to 
the amount of the lost work is applied when a compute node 
fails. 
5.  Modeling  Computing  and  Coordinated 
Checkpointing 
In  this  section,  we  describe  the  details  of  modeling  the 
computing  and  coordinated  checkpointing  module  using 
SANs. Due to space limitations, detailed SAN models of the 
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
other  three  modules  are  not  described  in  this  paper.  The 
reader may refer to the technical report [25] for these. 
Figure 2 shows the SAN submodels for the computing and 
coordinated  checkpointing  module.  States  are  shared  among 
the  submodels  with  the  same  names.  Selected  shared  states 
are numbered in Figure 2 to help identify them.   
1
When the application is started in the system, the compute 
nodes start out in the execution state and the master is in the 
master_sleep  state.  We  assume  the  application  starts  doing 
computation  and  the  app_workload  is  in  the  compute  state. 
The  I/O  nodes  are  in  the  ionode_idle  state.  Initially,  each  of 
these states has a token, indicated by block arrows in Figure 
2.  In  our  model,  the  non-random  events  are  modeled  as  de-
terministic activities, and exponential distribution is assumed 
for random events. To simplify the model, message transmis-
sions  are  not  explicitly  modeled  in  SAN,  but  the  parameters 
of  the  corresponding  events  are  appropriately  set  to  include 
the message transmission latency. Also, the ‘done’ and ‘pro-
ceed’  message  exchanges  are  not  modeled  in  the  interest  of 
simplicity.  The  following  steps  detail  the  behavior  of  the 
model. 
• First, assume that the checkpoint interval expires and the 
checkpoint  activity  is  enabled.  The  master  moves  from  the 
master_sleep  state  to  the  master_checkpointing  state  and 
starts a timer as shown by the start_timer gate. (Figure 2d) 
• The  compute  nodes  are  initially  in  the  state  execution.
When  the  master  moves  to  master_checkpointing,  the  com-
pute  nodes  move  to  the  quiescing  state  after  a  latency  of 
recv_quiesce_bcast _time (broadcast overhead). (Figure 2a)
•   Henceforth,  the  behavior  depends  on  whether  the  ap-
plication  workload  is  performing  computation  or  I/O.  If  the 
app_workload  is  in  the  compute  state,  the  coordination  for 
checkpointing  is  started,  as  shown  in  the  to_coordination 
activity.  If  the  app_workload  is  in  the  IO state,  the  compute 
nodes wait till the I/O completes before starting the coordina-
tion activity. (Figure 2c)
•   After the coordination activity (coord) completes, a to-
ken is placed in the complete_coordination state, enabling the 
activity coordinate in compute_nodes, and the compute nodes 
move from quiescing to checkpointing. (Figure 2e, 2a)
• If  the  timer  expires  before  the  coordination  is  complete, 
it  places  a  token  in  the  timedout  state.  This  activates  the 
skip_chkpt2  activity  in  compute_nodes,  causing  the  compute 
nodes 
the 
back_to_execution state. (Figure 2d, 2a, 2e) 
the  checkpointing  and  move 
• When the compute node is in the state checkpointing and 
the  I/O  node  is  in  the  state  ionode_idle,  the  dump_chkpt  ac-
tivity  is  enabled.  The  checkpoint  dump  time  depends  on  the 
checkpoint  size  and  the  bandwidth  between  the  compute 
nodes and the I/O nodes. (Figure 2a) 
•   After  storing  the  checkpoint,  the  compute  nodes  go 
back  to  the  execution state.  The  completion  of  this  activity 
also places tokens in the enable_chkpt state. (Figure 2a) 
• When the I/O node is in ionode_idle, it sees the token in 
the  enable_chkpt  state  and  goes  to  the  writing_chkpt  state. 
This enables the write_chkpt activity, which models the writ-
ing  of  the  checkpoint  to  the  file  system.  The  latency  of  the 
write  depends  on  the  checkpoint  size  and  the  bandwidth  be-
tween the I/O node and the file system. (Figure 2b) 
to  abort 
to 
6
2
5
3
9
8
2
9
(a) compute_nodes
7
8
7
(b) io_nodes
9
(c) app_workload
4
1
2
(d) master
3
4
6
5
(e) coordination
Figure 2: Submodels for computing and checkpointing 
• If  the  I/O  node  is  not  in  ionode_idle,  the  compute  node 
has to wait for the I/O node to come to the ionode_idle state 
before  sending  the  checkpoint  to  it.  This  prerequisite  is  en-
forced by the ionode_is_idle input gate. (Figure 2a) 
• When the checkpointing is completed or aborted, tokens 
are placed in the two states chkpt_completed_or_aborted and 
to_reset_processor_state.  The  tokens  cause  the  master  to 
move back to the master_sleep state and the app_workload to 
reset at the compute state. (Figure 2c) 
Since the model considers all the compute nodes as a sin-
gle  unit,  it  does  not  reflect  the  discrepancy  in  the  quiesce 
times among the compute nodes and does not show how the 
variation in the quiesce time  among the  nodes can cause  the 
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
master to timeout. This behavior is modeled separately in the 
coordination  submodel  (Figure  2e).  It  is  assumed  that  each 
node  has  an  identical,  exponentially  distributed  quiesce  time 
with the mean of MTTQ. We use a random variable Y, repre-
senting  the  maximum  of  all  the  quiesce  times,  to  model  the 
coordination time as follows: 
Let n and Xi denote the number of compute nodes and the 
ith node’s quiesce time, respectively, and Y = max{Xi} (1 (cid:148) i 
(cid:148) n). Then, the CDF of Y is FY(y)=(FX(y))n=(1-e-(cid:540)y)n where (cid:540)
is the quiesce rate of a single compute node. Y can be gener-
ated from a uniform random variable U between 0 and 1 by Y
= -1/(cid:540)·log(1-U1/n). The value of Y is used as the latency in the 
coord  activity  in  the  coordination  submodel  to  represent  the 
coordination process. 
Generic correlated failures. The system may suffer from 
generic correlated failures at any instant of the system life. A 
correlated  failure  coefficient  (cid:545)  is  assumed  to  model  generic 
correlated failures, which is the unconditional probability of a 
correlated failure occurring at any time. Table 2 lists the pa-
rameters used for modeling generic correlated failures. Then, 
the failure rate of generic correlated failures is given by, 
(cid:540)s = (cid:540)si + (cid:545)(cid:540)sc = n(cid:540) + (cid:545)rn(cid:540) = n(cid:540)(1 + (cid:545)r).   
Note that (cid:540)si, (cid:540)sc, and (cid:545) are not the same as the (cid:540)i, (cid:540)c, and (cid:545)e
in  the  discussion  of  correlated  failures  due  to  error  propaga-
tion, because they model different probabilities. The symbols 
n, (cid:540) and r have the same meanings in both models. 
Table 2: Parameters for modeling generic correlated failures 
6. Modeling Correlated Failures   
Two  categories  of  correlated  failures  are  modeled  in  the 
paper: (i) correlated failures due to error propagation and (ii) 
generic  correlated  failures.  Both  are  modeled  by  appropri-
ately increasing the node/processor failure rates. This section 
describes how these increased rates are derived. 