### System Model and Submodels

The ovals in the model do not represent the states of the system at any particular time. The submodels are organized into four modules: Computing & Checkpointing, Failure and Recovery, Correlated Failure, and Useful Work Computation.

#### 1. Computing and Checkpointing Module

- **Submodels:**
  - **app_workload:** Represents the application's state, whether it is performing computation or I/O operations.
  - **compute_nodes:** Models the behavior of compute nodes during normal execution and checkpointing. It includes the checkpoint cycle, which consists of executing (both computation and I/O), quiescing, and dumping checkpoints.
  - **coordination:** Models the coordination procedure for checkpointing among the compute nodes.
  - **io_nodes:** Captures the I/O operations conducted by I/O nodes, including data transmission between compute nodes, writing/reading checkpoints to/from the file system, and writing data on behalf of the application.
  - **master:** Represents the master node in the coordinated checkpointing protocol, responsible for triggering and coordinating the checkpointing process.

These five submodels form the computing and checkpointing module, which is further detailed in Section 5.

#### 2. Failure and Recovery Module

- **Submodels:**
  - **comp_node_failure:** Models the failure behavior of compute nodes.
  - **comp_node_recovery:** Models the recovery behavior of compute nodes.
  - **io_node_failure:** Models the failure behavior of I/O nodes.
  - **io_node_recovery:** Models the recovery behavior of I/O nodes.
  - **system_reboot:** Models the system reboot operation.

When a compute node or I/O node fails, the system initiates the recovery process. Compute nodes may experience multiple failures and recoveries before the final successful recovery, after which the system resumes normal execution and checkpointing. Failures of compute nodes do not affect I/O nodes if error propagation is not considered. If an I/O node fails while writing application data to the file system, the application results are lost, and the system rolls back to the last checkpoint.

The recovery process occurs in two stages:
1. I/O nodes read the checkpoint from the file system and buffer it in their local memories.
2. Compute nodes read the checkpoint from the I/O nodes and complete the recovery.

If the number of unsuccessful recoveries exceeds a predefined threshold, the entire system, including compute and I/O nodes, is rebooted.

#### 3. Correlated Failure Module

- **Submodel:**
  - **correlated_failures:** Models the semantics of correlated failures separately from the compute and I/O nodes' failure and recovery submodels. It controls the rates of all failures in the system.

When a correlated failure occurs, the system enters a correlated failure window, experiencing failures at a higher rate than the independent failure rate. Independent failures can still occur within this window.

#### 4. Useful Work Computation Module

- **Submodel:**
  - **useful_work:** Calculates the useful work completed by the system. A positive reward is accumulated when compute nodes perform job computation or I/O operations, and a negative reward equal to the amount of lost work is applied when a compute node fails.

### Detailed Modeling of Computing and Coordinated Checkpointing

This section describes the details of modeling the computing and coordinated checkpointing module using Stochastic Activity Networks (SANs). Due to space limitations, detailed SAN models of the other three modules are not described here. Readers may refer to the technical report [25] for these.

**Figure 2** shows the SAN submodels for the computing and coordinated checkpointing module. States are shared among the submodels with the same names, and selected shared states are numbered to help identify them.

- **Initial State:**
  - When the application starts, compute nodes begin in the execution state, the master is in the `master_sleep` state, and I/O nodes are in the `ionode_idle` state. The `app_workload` is in the `compute` state. Each of these states has a token, indicated by block arrows in Figure 2.

- **Model Behavior:**
  - **Checkpoint Interval Expiration:**
    - The master moves from the `master_sleep` state to the `master_checkpointing` state and starts a timer.
  - **Compute Nodes Quiescing:**
    - Compute nodes move to the `quiescing` state after a latency.
  - **Coordination for Checkpointing:**
    - If `app_workload` is in the `compute` state, the coordination for checkpointing is started. If `app_workload` is in the `IO` state, compute nodes wait until I/O completes.
  - **Checkpointing:**
    - After coordination, compute nodes move to the `checkpointing` state. If the timer expires before coordination is complete, the checkpointing is skipped.
  - **Checkpoint Dump:**
    - When the compute node is in the `checkpointing` state and the I/O node is in the `ionode_idle` state, the `dump_chkpt` activity is enabled.
  - **Completion:**
    - After storing the checkpoint, compute nodes return to the `execution` state. The completion also places tokens in the `enable_chkpt` state.
  - **I/O Node Writing:**
    - The I/O node sees the token in the `enable_chkpt` state and goes to the `writing_chkpt` state, enabling the `write_chkpt` activity.

**Figure 2** illustrates the submodels for computing and checkpointing, with the following key points:
- **Coordination Time:**
  - The model assumes each node has an identical, exponentially distributed quiesce time. The coordination time is modeled using a random variable representing the maximum of all quiesce times.

### Generic Correlated Failures

The system may suffer from generic correlated failures at any time. A correlated failure coefficient \(\alpha\) is assumed to model these failures, which is the unconditional probability of a correlated failure occurring at any time. Table 2 lists the parameters used for modeling generic correlated failures. The failure rate of generic correlated failures is given by:

\[
\lambda_s = \lambda_{si} + \alpha \lambda_{sc} = n\lambda + \alpha r n\lambda = n\lambda(1 + \alpha r)
\]

Note that \(\lambda_{si}\), \(\lambda_{sc}\), and \(\alpha\) are different from \(\lambda_i\), \(\lambda_c\), and \(\alpha_e\) in the discussion of correlated failures due to error propagation, as they model different probabilities.

### Conclusion

This document provides a detailed overview of the system model and its submodels, focusing on the computing and checkpointing module. The failure and recovery, correlated failure, and useful work computation modules are also briefly described. For more detailed information on the other modules, readers are referred to the technical report [25].