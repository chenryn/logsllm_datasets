name of the library may be obfuscated in an app, thus
directly using the package name is not accurate. Con-
sidering the fact that not all apps obfuscate their code,
we can use non-obfuscated package name of the same
library (which has similar SIG). In this way, most of the
obfuscated package names are recovered for libraries.
Currently, for each manipulation point, we can extract
its Web principal and app principal. The next step is to
determine whether APmp and W Pmp represent the same
security principal.
3.5 XPMClassﬁer
According to our deﬁnition in Equation (1), cross-
principal manipulation of Web resources is recognized
by judging whether a Web principal and an app principal
are the same. However, it is hard to automatically make
such decisions. For example, if the app principal is “fb”
and the Web principal is “facebook”, it is obvious to
recognize them as same principal by manual inspection
while there is no straightforward way to automatically
give the same result.
As it is difﬁcult to strictly tell whether two princi-
pals are the same, we perform some relaxation on this
problem. Speciﬁcally, we transform the strict deﬁnition
of cross-principal manipulation in Equation (1) into the
following deﬁnition where Sim is the similarity of the
two principals.
If the similarity proceeds a predeﬁned
threshold θ, we think the two principals are the same.
Otherwise, the two principals are thought to be different.
IS XPM(mp) := Sim(APmp,W Pmp) ≥ θ
(2)
The key to recognize cross-principal manipulation
turns to calculate the similarity of two principals. Our
idea is to take advantage of search engine knowledge.
The insight is that more similar are the two princi-
pals, more similar results should be searched for them.
Thus, we search the two principals in the search engine,
and calculate the similarity between the search results.
Speciﬁcally, the classiﬁcation of XPM is performed in
the following steps. Note that in rare cases where search
engine returns no results, we use literal edit distance
between Web principal and app principal to calculate the
similarity.
1. Firstly, we remove noise words in 
such as sufﬁxes [5] and stop words [6] (e.g. remove
“com” and “get” from “get.appdog.com”), since
they make little contribution to XPM classiﬁcation.
After that, we get AP(cid:48)
2. Secondly, we use AP(cid:48)
mp and W P(cid:48)
mp.
mp and W P(cid:48)
mp as search key-
words to query Google search engine and get search
results as Rap and Rwp respectively. All the results
are translated into English using Google Translate.
3. Thirdly, we segment the words in the Rap and Rwp
using the bag-of-words model. Speciﬁcally, we
only keep the multiplicity and ignore grammar and
word order. We normalize each word (term) and
transform their term frequencies into two vectors:
A and W .
4. Fourthly, we calculate the similarity of the two
principals as cosine similarity between the two
vectors using the following equation.
Sim(APmp,W Pmp) =
(cid:114) n
∑
i=1
AiWi
(cid:114) n
n
∑
i=1
A2
i
∑
i=1
(3)
W 2
i
5. Finally, we compare the calculated similarity with
a threshold θ.
If the similarity does not exceed
the threshold, we regard the Web principal and app
principal are from different parties and classify the
manipulation point (mp) as XPM.
4 Empirical Study
Our empirical study is performed on a large dataset
of apps collected from Google Play during July 2017.
These apps were selected with at least 5,000 installations
across 48 categories, and 84,712 (out of 108,477) apps
were successfully downloaded.
To the best of our
knowledge, this study is the ﬁrst to understand the Web
resource manipulation behaviors with large-scale real-
world apps.
Analysis Statistics. We use XPMChecker to analyze
these apps on a CentOS 7.4 64-bit server with 64 CPU
cores (2GHz) and 188 GB memory. We start 9 processes
to parallel the analysis and set timeout of 20 minutes for
each app. In all, the analysis takes 233 hours to process
the whole dataset, that is about 10 seconds per app. The
static analyzer module of XPMChecker successfully pro-
cesses 80,694 (95.3%) apps, and the rest apps either run
out of time or fail to be analyzed by Soot or FlowDroid.
For the successfully analyzed apps, XPMChecker ﬁnds
13,599 apps with 29,448 manipulation points, and 3,858
of the apps contain 14,476 XPM points. The detailed
data is showed in Table 3.
4.1 Evaluation of XPMChecker
Evaluation of Static Analyzer. The static analyzer
module is used to ﬁnd all manipulation points and
extract manipulation information (i.e. manipulated Web
URL and manipulating context) for further principal
1190    27th USENIX Security Symposium
USENIX Association
Table 3: Overall result of our study.
#
Category
All Apps
Finished Apps
Apps with Manipulation Points
Apps with XPM Behaviors
1 The number
in the bracket
manipulation points.
84,712
80,694
13,599 (29,448)1
3,858 (14,476)
represents the number of
identiﬁcation. To evaluate the effectiveness of static
analyzer, we randomly select 50 successfully analyzed
apps and manually label all the manipulation points
for these apps including manipulation information.
In
total, we manually ﬁnd 36 manipulated points, while
XPMChecker correctly labels 33 of them. The left 3
cases are failed to extract the manipulating Web URLs
due to complex string encoding and deep inter-procedure
call. As a result, the static analyzer module successfully
recall 91.7% of all manipulation points with correctly
labeled manipulating information. Further improvement
can be achieved by enhancing the string analysis which
is a orthogonal research direction [18, 29].
Evaluation of Principal Identiﬁer and XPMClassi-
ﬁer. For each Web resource manipulation point, Prin-
cipal Identiﬁer extracts the Web principal and app prin-
cipal, then XPMClassiﬁer judges whether this is XPM
by leveraging search engine knowledge. To evaluate the
performance of the two modules, we randomly select
1,200 manipulation points identiﬁed by the static ana-
lyzer, and manually label them as XPM or not. The
performance of XPMClassﬁer depends on the threshold
θ. To set θ, we select 1,000 labeled manipulation points
from our ground truth and draw the receiver operating
characteristic (ROC) curve by trying different thresholds
(as shown in Figure 4). Our aim is to gain the balance
between false positive rate (FPR) and false negative rate
(FNR), so we choose the threshold at the equal error rate
(EER) point, that is 0.3134.
We use the left 200 manipulation points to test the per-
formance of Principal Identiﬁer and XPMClassiﬁer. As
showed in Table 4, our tool ﬁnds 94 XPM points, while
93 of them are true positive. Therefore, the precision
and recall of Principal Identiﬁer and XPMClassiﬁer are
98.9% and 97.9% respectively.
We further manually inspect the false positives and
false negatives. The cause for the false positives is the
lack of search result for some Web principals from small
websites. Since these Web sites are not popular, these
false positives do not affect the overall result and ﬁnding.
The false negatives are caused by unofﬁcial apps whose
app principals are highly related to those of the ofﬁcial
ones. For these cases we need to use more complex
Figure 4: ROC curve for varied θ in XPMClassﬁer with
1000 manipulation points.
Table 4: Precision and recall of Principal Identiﬁer and
XPMClassiﬁer.
# of Manually Labeled XPM
# of Detected XPM
# of True Positive
Precision
Recall
95
94
93
98.9%
97.9%
techniques to extract app principal. Considering the
recall rate is relatively high, we argue current design is
quite acceptable to perform a large-scale study.
4.2 Prevalence of XPM Behaviors
This section measures the prevalence of XPM behavior
in real-world apps. Our results consist of the following
ﬁndings.
Finding 1: 49.2% of manipulation points are cross-
principal. As shown in Table 3, XPMChecker ﬁnds
29,448 manipulation points, while 14,476 of them is
crossing principal, which means 49.2% of manipulation
points are cross-principal.
Finding 2: 16.9% of apps manipulate Web re-
sources, and 4.8% of apps have XPM behaviors. As
shown in Table 3, in all the successfully analyzed 80,964
apps, XPMChecker ﬁnds 13,599 apps that contain at
least one manipulation points, that is 16.9% of all apps.
Further more, XPMChecker ﬁnds 3,858 apps have XPM
behaviors, which is 4.8% of all apps.
Finding 3: 63.6% of cross-principal manipulation
points originate from libraries. As shown in Table 5,
our results show that 63.6% of cross-principal manipu-
lation points are from 88 libraries, covering 2,545 apps.
Meanwhile, 36.4% of the cross-principal manipulation
points belong to 1,414 apps. Note some apps may have
USENIX Association
27th USENIX Security Symposium    1191
0.00.20.40.60.81.0False Positive Rate0.00.20.40.60.81.0True Positive RateEER pointROCEqual Error RateTable 5: XPM point distribution according to its location.
XPM Location
# of XPM Points (%)
# of Apps
Library
App
All
9,201 (63.6%)
5,275 (36.4%)
14,476
2,545
1,414
3,858
Table 6: Top 10 Web hosts that are cross-principal
manipulated.
rank
1
2
3
4
5
manipulated host
play.google.com
market.android.com
facebook.com
youtube.com
docs.google.com
rank manipulated host
player.vimeo.com
maps.google.com
google.com
drive.google.com
twitter.com
6
7
8
9
10
XPM behaviors in both its app code and library code.
Finding 4: More than 70% of XPM points ma-
nipulate top popular Web services. We collect the
manipulated Web host for all the XPM points and ﬁnd
that more than 70% of them belong to top Web services,
such as Google, Facebook and Twitter. We list the top 10
manipulated Web hosts in Table 6.
Finding 5: Web contents and Web addresses are
the most commonly manipulated and cross-principal
manipulated Web resources. We count the manipula-
tion APIs used for all the discovered manipulation points
and present the result in Figure 5. We can see that load-
UrlJs and evaluateJavascript are the most frequently
used, which support JavaScript injection into Web pages.
Besides, APIs that can manipulate Web addresses, such
as shouldOverrideUrlLoading, onPageStarted are also
widely used, rendering that Web addresses are of high
interest for manipulating. We ﬁnd getCookie API is quite
exceptional because it is widely used in manipulation
points but few are cross-principal.
Figure 5: Manipulation API Usage.
4.3 Breakdown of XPM Behaviors
To further understand what XPM behaviors do in real-
world apps, we select some apps to study.
In all, we
manually study all the 88 libraries in Table 5 which
cover 63.6% of all XPM behaviors, and randomly select
100 apps from the 1,414 apps. We classify these XPM
behaviors and present the results in Table 7.
Table 7: XPM behaviors in 88 libraries and 100
randomly selected apps.
Behavior
% in libraries % in apps
Customizing Web services
Invoking local apps
Obtaining OAuth tokens
Malicious behaviors
Other behaviors
False positive
56.8%
30.7%
2.3%
0
5.7 %
4.5%
67.0%
16.1%
4.6%
0.9%
8.2%
3.2%
1 Note that one app may have several XPM behaviors.
We ﬁnd that the most popular XPM behaviors we
found are customizing Web services and invoking local
apps.
Furthermore, we ﬁnd several apps exhibiting
obvious malicious behaviors, and it is the ﬁrst time that
we can conﬁrm the threat of Web resource manipulation
in real-world apps. In the following, we further present
our ﬁndings in dissecting these XPM behaviors.
4.3.1 Necessary XPM Behaviors
Finding 6: Most of XPM behaviors are necessary to
improve the usability for mobile users. Our manual
analysis ﬁnds that about 90% of the XPM behaviors
provide new functionalities. Here we give some ex-
amples.
Since Android WebView does not support
navigation control [2], we ﬁnd many XPM behaviors
inject JavaScript code to add this feature. We also
ﬁnd a library called “Android-MuPDF” which injects
JavaScript code into the Google cloud print page to help
users reduce the steps in using cloud print. Another
common use case of XPM behavior is to invoke local
apps. For example, the “org.nexage.sourcekit.mraid”
library uses shouldOverrideUrlLoading API to mon-
itor the loaded URLs. If the URLs are ads about apps, it
will invoke the local “Google Play” app to display the
advertised apps.
4.3.2 Unsafe XPM Behaviors
Finding 7: Some XPM behaviors implement OAuth
implicit grant ﬂow in an unsafe way. We ﬁnd some
XPM behaviors in 2 libraries and 10 apps implement
1192    27th USENIX Security Symposium
USENIX Association
 !   "    "!   #$%&’()*+,*(*-#$%&’()*+,.(/012.34(*$/567)*),860,8(9.0:;622)0612.6,(92=6,8(9.0?*+62=6’+>6@96,+56+A((B)6,8(9.0:;622)0612.6,(92=6F,8(9.0?*+62=6’+>6@96,+CD6E>6,(92=6FOAuth implicit grant ﬂow, but in an unsafe way. Fig-
ure 6(a) shows the standard and secure OAuth 2.0 im-
plicit grant ﬂow, where an external user-agent is used and
third-party app can only access data in step 1 and step 7.
However, we ﬁnd XPM behaviors are used to implement
OAuth implicit ﬂow as depicted in Figure 6(b). Instead
of using an external user-agent,
the third-party app
uses an internal user-agent, i.e. a WebView to do the
OAuth implicit grant. Then the third-party app uses
Web resource manipulation APIs to intercept the access
token from the WebView in step 5 in Figure 6(b). For
example, we ﬁnd a library called “com.magzter” that
uses onPageFinished API to intercept access token
when doing OAuth on Twitter.
According to previous research on OAuth security [41,
16, 43] and RFC OAuth 2.0 speciﬁcation [4], it is unsafe
to use internal user-agent. Speciﬁcally, the OAuth 2.0
speciﬁcation [4] says “native apps MUST NOT use