### Interrupts and No-Wake Timers

The following log entries illustrate various interrupts, primarily involving No-Wake (NW) enhanced timers. These timers are used to manage the minimum due time for certain tasks. Some timers are periodic (P), meaning they will be reinserted at their expiration time. A few timers also have a maximum due time, indicating a tolerance for when they might expire. Additionally, one of the timers is associated with a callback function managed by the Windows Driver Foundation (WDF) framework.

#### Log Entries
- **Entry 1:**
  - **Timestamp:** 11/30/2020 20:50:16.326
  - **Interrupt ID:** 1825dd19e8
  - **Type:** NWF
  - **Due Time:** 11/30/2020 20:50:21.326

- **Entry 2:**
  - **Timestamp:** 11/30/2020 20:50:16.364
  - **Interrupt ID:** 1825e2d9c6
  - **Type:** NW P
  - **Periodic Timer:** 27ef6380

- **Entry 3:**
  - **Timestamp:** 11/30/2020 20:50:16.391
  - **Interrupt ID:** 1825e6f8c4
  - **Type:** NW P
  - **Periodic Timer:** 27ef6380

- **Entry 4:**
  - **Timestamp:** 11/30/2020 20:50:16.426
  - **Interrupt ID:** 1825ec5ae8
  - **Type:** NWF
  - **Due Time:** 11/30/2020 20:50:21.426

- **Entry 5:**
  - **Timestamp:** 11/30/2020 20:50:16.543
  - **Interrupt ID:** 1825fe1d10
  - **Type:** NWF
  - **Due Time:** 11/30/2020 20:50:18.543

- **Entry 6:**
  - **Timestamp:** 11/30/2020 20:50:16.703
  - **Interrupt ID:** 18261691e3
  - **Type:** NW P
  - **Periodic Timer:** 11e1a300

- **Entry 7:**
  - **Timestamp:** 11/30/2020 20:50:16.706
  - **Interrupt ID:** 18261707d3
  - **Type:** NWF
  - **Due Time:** 11/30/2020 20:50:17.157

- **Entry 8:**
  - **Timestamp:** 11/30/2020 20:50:16.725
  - **Interrupt ID:** 182619f439
  - **Type:** NWF
  - **Due Time:** 11/30/2020 20:50:21.725

- **Entry 9:**
  - **Timestamp:** 11/30/2020 20:50:18.691
  - **Interrupt ID:** 182745de01
  - **Type:** NW P
  - **Periodic Timer:** 11e1a300

- **Entry 10:**
  - **Timestamp:** 11/30/2020 20:50:18.897
  - **Interrupt ID:** 18276567a9
  - **Type:** NWF
  - **Callback:** Wdf01000!FxTimer::_FxTimerExtCallbackThunk
  - **Context:** ffffa483f3db7360
  - **Due Time:** 11/30/2020 20:50:19.897
  - **Periodic Timer:** 02faf080

- **Entry 11:**
  - **Timestamp:** 11/30/2020 20:50:18.943
  - **Interrupt ID:** 18276c5890
  - **Type:** NW P
  - **Periodic Timer:** 27ef6380

- **Entry 12:**
  - **Timestamp:** 11/30/2020 20:50:19.288
  - **Interrupt ID:** 1827a0f6b5
  - **Type:** NWF
  - **Due Time:** 11/30/2020 20:50:34.288

- **Entry 13:**
  - **Timestamp:** 11/30/2020 20:50:19.628
  - **Interrupt ID:** 1827d4fcb5
  - **Type:** NWF
  - **Due Time:** 11/30/2020 20:50:21.628

### System Worker Threads

During system initialization, Windows creates several threads in the System process, known as system worker threads. These threads are dedicated to performing work on behalf of other threads. In many cases, threads executing at DPC/dispatch level need to execute functions that can only be performed at a lower IRQL. For example, a DPC routine, which executes at DPC/dispatch level IRQL, might need to access paged pool or wait for a dispatcher object used to synchronize execution with an application thread. Since a DPC routine cannot lower the IRQL, it must pass such processing to a thread that executes at a lower IRQL.

Some device drivers and executive components create their own threads dedicated to processing work at passive level; however, most use system worker threads instead, which avoids the unnecessary scheduling and memory overhead associated with having additional threads in the system. An executive component requests a system worker thread’s services by calling the executive functions `ExQueueWorkItem` or `IoQueueWorkItem`. Device drivers should use only the latter, as it associates the work item with a Device object, allowing for greater accountability and handling scenarios where a driver unloads while its work item is active.

These functions place a work item on a queue dispatcher object where the threads look for work. The `IoQueueWorkItemEx`, `IoSizeofWorkItem`, `IoInitializeWorkItem`, and `IoUninitializeWorkItem` APIs act similarly but create an association with a driver’s Driver object or one of its Device objects.

Work items include a pointer to a routine and a parameter that the thread passes to the routine when it processes the work item. The device driver or executive component that requires passive-level execution implements the routine. For example, a DPC routine that must wait for a dispatcher object can initialize a work item that points to the routine in the driver that waits for the dispatcher object. At some stage, a system worker thread will remove the work item from its queue and execute the driver’s routine. When the driver’s routine finishes, the system worker thread checks to see if there are more work items to process. If not, the system worker thread blocks until a work item is placed on the queue.

There are several types of system worker threads, each with different priorities and behaviors:
- **Normal Worker Threads:** Execute at priority 8.
- **Background Worker Threads:** Execute at priority 7.
- **Delayed Worker Threads:** Execute at priority 12 and process non-time-critical work items.
- **Critical Worker Threads:** Execute at priority 13 and process time-critical work items.
- **Super-Critical Worker Threads:** Execute at priority 14.
- **Hyper-Critical Worker Threads:** Execute at priority 15.
- **Real-Time Worker Threads:** Execute at priority 18, operating in the real-time scheduling range.

Recent versions of Windows introduced custom priority worker threads, which are now recommended for all driver developers and allow the driver to specify its own priority level.

A special kernel function, `ExpLegacyWorkerInitialization`, sets an initial number of delayed and critical worker queue threads during the boot process. However, these variables are no longer utilized by the kernel on modern Windows 10 systems and later. Instead, recent kernels use a new kernel dispatcher object, the priority queue (KPRIQUEUE), coupled with a fully dynamic number of kernel worker threads, and split what used to be a single queue of worker threads into per-NUMA node worker threads.

On Windows 10 and later, the kernel dynamically creates additional worker threads as needed, with a default maximum limit of 4096. This limit can be configured through the registry up to a maximum of 16,384 threads and down to a minimum of 32. The `MaximumKernelWorkerThreads` value can be set under the registry key `HKLM\SYSTEM\CurrentControlSet\Control\SessionManager\Executive`.

Each partition object contains an executive partition, which includes a data structure tracking the work queue manager for each NUMA node part of the partition. It also contains an array of pointers to each of the eight possible work queues (EX_WORK_QUEUE). These queues are associated with an individual index and track the number of minimum (guaranteed) and maximum threads, as well as how many work items have been processed so far.

Every system includes two default work queues: the ExPool queue and the IoPool queue. The former is used by drivers and system components using the `ExQueueWorkItem` API, whereas the latter is meant for `IoAllocateWorkItem`-type APIs. Up to six more queues are defined for internal system use, leveraging the `ExQueueWorkItemToPrivatePool` API.

The executive tries to match the number of critical worker threads with changing workloads. Whenever work items are being processed or queued, a check is made to see if a new worker thread might be needed. If so, an event is signaled, waking up the `ExpWorkQueueManagerThread` for the associated NUMA node and partition. An additional worker thread is created under certain conditions, such as when there are fewer threads than the minimum number of threads for this queue, or when the maximum thread count hasn’t been reached and all worker threads are busy.

Additionally, once every second, the `ExpWorkQueueManagerThread` can determine whether a deadlock may have occurred. If a deadlock is detected, an additional worker thread will be created, regardless of any maximum thread limits, to clear out the potential deadlock. This detection is then disabled until it is deemed necessary to check again.

Finally, once every double the worker thread timeout minutes (by default 10, so once every 20 minutes), the thread checks if it should destroy any system worker threads. This ensures that system worker thread counts do not get out of control. A system worker thread is reaped if it has been waiting for a long time and no further work items are waiting to be processed.

### Experiment: Listing System Worker Threads

Unfortunately, the kernel debugger’s `!exqueue` command can no longer be used to see a listing of system worker threads classified by their type due to the per-partition reshuffling of the system worker thread functionality. However, the `EPARTITION`, `EX_PARTITION`, and `EX_WORK_QUEUE` data structures are available in the public symbols, and the debugger data model can be used to explore the queues and their managers.

For example, to look at the NUMA Node 0 worker thread manager for the main (default) system partition:

```shell
lkd> dx ((nt!_EX_PARTITION*)(*(nt!_EPARTITION**)&nt!PspSystemPartition)->ExPartition)->WorkQueueManagers[0]
```

This will display the details of the worker thread manager, including the partition, node, events, timers, and thread handle.

Alternatively, to look at the ExPool for NUMA Node 0:

```shell
lkd> dx ((nt!_EX_PARTITION*)(*(nt!_EPARTITION**)&nt!PspSystemPartition)->ExPartition)->WorkQueues[0][0],d
```

This will show the details of the ExPool, including the number of threads and the number of work items processed.

You can also enumerate the worker threads associated with this queue:

```shell
lkd> dx -r0 @$queue = ((nt!_EX_PARTITION*)(*(nt!_EPARTITION**)&nt!PspSystemPartition)->ExPartition)->WorkQueues[0][0]
lkd> dx Debugger.Utility.Collections.FromListEntry(@$queue->WorkPriQueue.ThreadListHead, "nt!_KTHREAD", "QueueListEntry")
```

This will list the worker threads associated with the ExPool.

Similarly, you can look at the IoPool and private pools, such as the Store Manager’s pool.

### Exception Dispatching

In contrast to interrupts, which can occur at any time, exceptions are conditions that result directly from the execution of the program that is running. Windows uses structured exception handling, which allows applications to gain control when exceptions occur. The application can then fix the condition and return to the place the exception occurred, unwind the stack, or declare that the exception isn’t recognized, and the system should continue searching for an exception handler.

On x86 and x64 processors, all exceptions have predefined interrupt numbers that correspond to the entry in the Interrupt Descriptor Table (IDT) that points to the trap handler for a particular exception. The following table shows x86-defined exceptions and their assigned interrupt numbers:

| Interrupt Number | Exception              | Mnemonic |
|------------------|------------------------|----------|
| 0                | Divide Error           | #DE      |
| 1                | Debug (Single Step)    | #DB      |
| 2                | Non-Maskable Interrupt | -        |
| 3                | Breakpoint             | #BP      |
| 4                | Overflow               | #OF      |
| 5                | Bounds Check (Range Exceeded) | #BR |
| 6                | Invalid Opcode         | #UD      |
| 7                | NPX Not Available      | #NM      |
| 8                | Double Fault           | #DF      |
| 9                | NPX Segment Overrun    | -        |
| 10               | Invalid Task State     | -        |

Understanding these concepts is crucial for developing robust and reliable software on the Windows platform.