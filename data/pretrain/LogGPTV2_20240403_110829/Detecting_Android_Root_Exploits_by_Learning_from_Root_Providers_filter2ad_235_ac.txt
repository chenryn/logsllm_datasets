symbolic formulas of such input arguments also specify
how they are depend on each other. Based on this obser-
vation, we extract the data dependencies between system
calls by simply naming the symbolic values returned by
system calls according to the system call names and their
sequence in the feasible path (e.g., read2 buf).
Extracting control dependencies: Symbolic execu-
tion does not directly provide control dependencies. To
extract such information, we simply conduct a backward
analysis. In particular, when outputting the feasible path
discovered via symbolic execution, we also mark each
control point that directly depends on the symbolic value
with the system calls that introduced that value. Using
the path, we start from the end point and traverse the
trace backwards to look for system call invocations (e.g.,
BL mmap). Once we ﬁnd a system call invocation, we
can extract its control dependencies over previous sys-
tem calls by searching for the closest “tainted” branch
that precedes this syscall invocation. Alternatively, we
could have used static binary taint analysis to extract both
data and control dependencies.
Modeling of libc functions: The exploit binaries in
our training set do not generally call the system calls di-
rectly (as typical with most native code). Instead, they
call the libc functions (in Android, it is called Bionic).
Fortunately, most are simply wrappers of system calls
and have the same exact semantics. In cases they are not
exactly the same, for example, fopen() vs. open(), we
model the Bionic version fopen() by mapping its ar-
guments and return values to open(). Furthermore, we
leverage function summaries to model most encountered
libc functions that need to be analyzed by symbolic exe-
cution.
5.2 Examples
Device Driver Exploit: To illustrate our behavior graph
analysis, we consider a popular device driver exploit
that targets the vulnerable Qualcomm camera driver,
“camera-isp”. This example is taken directly from our
training data set from a popular one click root app. In
1134    26th USENIX Security Symposium
USENIX Association
and invoking multiple connect() calls on the same
ICMP socket (we omit the complete behavior graph for
brevity). In addition, One or more child processes are
created as helpers to construct as many ICMP sockets as
possible for padding. Since the fork() occurs in a loop
(up to 1024 iterations), it is necessary for symbolic exe-
cution to identify and choose one feasible path. Speciﬁ-
cally, the analysis output is that as long as the loop is ex-
ecuted once, a feasible exploit path can be constructed.
This means that we can simply unroll the loop once and
have a new behavior graph constructed for the child pro-
cess (which is connected to the parent behavior graph via
a fork() edge). Note that unrolling the fork loop more
times is also feasible which will cause identical behav-
ior graphs to be constructed. In this case, all behavior
graphs will need to be matched so that we can claim an
exploit is detected. It is worthwhile mentioning that the
precondition analysis (which will be described in more
detail in the next section) is conducted jointly, and will
ensure that the ﬁrst fork() will succeed at runtime, thus
causing the exploit to match the behavior graph with one
child process only.
5.3 Using Behavior Graphs in Detection
Once the behavior graphs for different root exploits are
generated ofﬂine, we are able to use them for detection in
a scanner (similar to Google Bouncer). More precisely,
by monitoring system call invocations (and arguments),
our dynamic analysis environment determines if the be-
havior of the program under analysis matches any of the
learned behavior graphs. The matching algorithm is sim-
ilar to that in [49]. We only brieﬂy describe the procedure
below and the design decisions that were made.
To ﬁnd a match in the behavior graph, it is necessary to
ensure the following: (1) The order of system calls con-
forms to the dependencies represented in the learned be-
havior graph. In addition, the dependencies in the behav-
ior graph need to be maintained at runtime as well. This
can be checked using dynamic taint analysis [14, 49]. (2)
The exact values of the arguments for system calls match
(e.g., a ﬁle opened with read/write permission). For those
arguments whose values cannot be determined statically
during training, they will simply be considered as wild-
card values that can match any value at runtime. (3) A
system call’s status (either success or failure) matches
with the one in the learned behavior graph.
We observe that the root exploits typically have unique
inputs to the system via system call arguments, which
makes them easy to distinguish from legitimate pro-
grams. We therefore relax requirement (1) by only veri-
fying simple dependencies at runtime (e.g., a ﬁle read()
depends on the output of open()). Such cases can be
checked through the OS objects monitored in the ker-
Figure 2: Behavior graph for the “camera-isp” exploit.
brief, the vulnerable device driver allows any program to
map any part of the physical address space into the user
space, which can subsequently allow the disabling of the
permission check in setresuid() system call. This al-
lows an attacker to change the running process into a root
process.
Figure 2 represents the behavior graph. The exploit
needs to open two separate ﬁles, the vulnerable device
ﬁle /dev/camera-isp and the helper ﬁle /proc/iomem
which has the information about where the kernel code
is located in the physical address space. Both ﬁles are
checked with the open() system call to ensure that they
can be successfully opened. The device ﬁle is checked
once more in the beginning, via a stat() system call,
for existence. The exploit then attempts to mmap()
the kernel code region into the user address space with
read/write permissions; however, the exact offset (argu-
ment in mmap()) is retrieved from the read result of the
/proc/iomem. After the mmap() is successful, the ex-
ploit searches for a particular sequence of bytes in the
mapped memory that corresponds to the code blocks for
setresuid(). Upon locating the code block, it patches
the code block by writing to a speciﬁc offset, which ef-
fectively eliminates the security check in setresuid()
(the above two steps are invisible in the behavior graph).
Then the exploit simply calls setresuid(0,0,0) to
change the uid of itself to root. Finally, as mentioned
earlier, all exploit binaries in our training set, end the ex-
ecution with a check through getuid() to verify that the
exploit process has obtained root.
Note that due to space constraints, we do not annotate
the graph with the exact arguments (e.g., ﬁle open with
a read/write permission or read-only). We also do not
label whether the system call succeeded or not. In most
exploits, all system calls need to be successful in order
to compromise the system and typically the failure of a
system call will immediately result in an abort.
Kernel Exploit: As a second example, we consider
Pingpong root [77], one of the most recent generic root
exploits that can target almost all Android devices re-
leased prior to mid-2015. The case also reﬂects one
where the exploit creates multiple processes.
In par-
ticular, the key exploit logic [35] is conducted in the
main process, including mmap() at a speciﬁc address,
USENIX Association
26th USENIX Security Symposium    1135
open/dev/camera-ispopen/proc/iomemfdmmapreadfdaddrsetresuidcontrolstatcontrolnel, without conducting an expensive taint analysis. For
more complex dependencies such as the values obtained
through read() affecting a system call mmap() as shown
in Figure 2, we only require that the order is the same as
constrained on the graph, i.e., read() happens before
mmap(). We plan to implement the dynamic taint anal-
ysis for stricter dependency enforcement in future work.
Alternatively to improve efﬁciency, we could also apply
the optimization proposed by Kolbitsch et al. [49].
6 Satisfying Exploit Preconditions
It is crucial to build an environment that can satisfy the
preconditions expected by root exploits. More impor-
tantly, because our behavior graph is constructed over
one successful path, if an analyzed app contains root ex-
ploits, our dynamic analysis environment must determin-
istically coerce the app to follow that path, i.e., the app
must be made to reveal the same set of malicious behav-
iors that match the learned signature. This means that
whenever the exploit asks the environment for certain re-
sults, we must return them as expected.
The problem naturally maps on to the common debug-
ging and testing problem of generating the proper inputs
to a program, so that it will reach a particular target state-
ment [53, 26, 22]. Here the target statement is the end
point of the root exploit, e.g., the getuid() call. The
“inputs” are the system call results, including (1) system
call return values and, (2) other return results through ar-
guments (e.g., a buffer ﬁlled in read()). Our solution
to this problem is symbolic execution. Speciﬁcally, we
symbolize all the “inputs” from system calls and lever-
age symbolic execution to ﬁnd the shortest feasible path
that can reach the target instruction from the entry point.
Once we ﬁnd such a path, we then ask the SMT solver to
generate a concrete instance of the inputs which will be
“replayed” during dynamic analysis.
With respect to the system call return values, we con-
sider two types of system calls: (1) Those that return a
reference to kernel object, e.g., open() and socket()
return a ﬁle descriptor; and mmap() returns the address of
the “memory-mapping object”. (2) The remaining ones
(e.g., stat()) that return either 0 (indicating success)
or an error code. For type (1), since ﬁle descriptors and
mapped addresses are determined dynamically by the OS
and the constraints are typically simple (just != 0), we
symbolize their return values as a Boolean during anal-
ysis and do not force a speciﬁc value during runtime.
Instead, we simply choose to force a success or failure
based on the Boolean and let the OS assign the concrete
return value. To allow expected interactions with the cor-
responding kernel objects, we use “decoy objects” (ex-
plained later) instead of tracking those references. For
type (2), we just symbolize their returned values nor-
Figure 3: Pseudo code of proc/iomem read
mally as bit-vectors and ask the solver to generate a sat-
isfying value.
For system calls that return results through arguments,
they are always pointers passed in user programs (e.g.,
read buffer). We use these input pointers to symbolize
the corresponding memory content. Going back to the
ﬁrst example exploit in §5.2, after reading from the ﬁle
/proc/iomem, the exploit attempts to read the starting
physical address of the kernel code. This procedure is
illustrated in Figure 3. As we can see, the exploit reads
the ﬁle line by line to look for the constant string “Ker-
nel code”. Once the line is located, it retrieves the kernel
code base address (through the getAddress() call) at
the -20 offset relative to the returned buffer of strstr().
There are effectively two loops in the program. The ﬁrst
is the while loop; the second is inside strstr(). In this
particular case, the discovered feasible path says that the
while loop can iterate just once, indicating that we can
return the string containing “Kernel code” when the ﬁrst
line is retrieved using the read() system call. However,
the feasible path also says that the loop in strstr()
needs to iterate at least 20 times1; in other words, “Ker-
nel code” needs to start at line [20]. This is because the
getAddress() call reads the location at buf-20. If buf
is at the beginning of line, then buf-20 would be reading
something out of bound.
In this case, the address returned from getAddress()
is not
further constrained later, which means that
line[0] to line[19] are unconstrained and can take
any value. Therefore, the constraint solver will gener-
ate an output for line with something like “abcdefghi-
jklmnopqrstKernel code”. Further, since the read() sys-
tem call only reads one line, we will place the single line
content into the expected ﬁle object. There is a similar
case later on involving a search through the memory for
constants after mmap(), which can be resolved similarly.
Decoy Objects: During dynamic analysis, we can
provide the preconditions we learned by forcing/faking
1In our real implementation, we use function summary to handle all
encountered external library calls.
1136    26th USENIX Security Symposium
USENIX Association
fdIo = open("/proc/iomem");// locate the kernel code offset in physical memorywhile ((line = readline(fdIo)) > 0} {    if((buf = strstr(line, "Kernel code")) != NULL) {        addr = getAddress(buf);          break;    }}int getAddress(buf) {    return atoi[buf-20];}Figure 4: Operational model of the detection system
all syscall results. However, to improve the robustness
of our environment (i.e., making it more real), we de-
cided to use decoy objects to provide expected results
for operations over certain type of kernel objects. Doing
so would allow us to “tolerate” certain operations (e.g.,
stats() that are not observed during our ofﬂine learn-
ing phase.
Currently we only support three types of decoy ob-
jects: ﬁles, socket, and device drivers. These are created
in two ways.
If the target objects (such as a vulnera-
ble device driver) do not exist in our analysis environ-
ment, we simply create decoys. If the objects (such as
/proc/iomem) already exist in our environment, instead
of opening the real ﬁle, we “redirect” the ﬁle open oper-
ation to the alternative decoy object so that we can return
the expected content.
7 Detecting Root Exploits
Thus far, we have described the training phase, where we
generate both the behavior graph and the environment
constraints.
In this section, we provide details about
the components of our detection system (testing phase).
We ﬁrst present an overview of our system’s operational
model and then describe its components in detail.
7.1 Operational Model
As mentioned earlier, we envision RootExplorer to be
used as an app vetting tool for Android markets. When
a developer submits an app to the market via a web ser-
vice, we envision the market pushing it to RootExplorer,
as depicted in Figure 4. First, we employ a static ana-
lyzer (different from the static analysis during the train-
ing phase), which performs several checks to ﬁlter apps
that are unlikely to contain root exploits (details later).
Subsequently, it determines “with which kind of mobile
device(s) or emulator(s),” the dynamic analysis will be
performed. Upon completion of the dynamic analysis,
the detector collects the results and determines if the app
contains a root exploit and if so what exploit it is. If the
app does have root exploits, it informs the Android mar-
ket and saves the hash of the app to the central database;
otherwise the app is moved either to a different malware
scanner (e.g., Bouncer) that is orthogonal to our system
Figure 5: Static analyzer
or for publication in the Android market. The dynamic
analyzer can be run on either real phones or Android em-
ulators (or a mix of both), and can be easily integrated
into various malware analysis environments as needed.
7.2 Static Analyzer
The static analyzer consists of three components as
shown in Figure 5. The ﬁrst component is the native code
detector. Since almost all root exploits are written in na-
tive code (certainly the case for the one-click root app we