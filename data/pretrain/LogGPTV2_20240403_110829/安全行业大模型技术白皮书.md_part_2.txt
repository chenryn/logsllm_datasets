FLAN
TO
LaMDA
nspurYuan1.0
Anthropic
AI
HyperCLOVA NAVER
AlphaCode
WebGPT
1-12
Falcon
S
CodeGeeX
Ernie3.0Titan
InstructGPT
2022
C
UL2
Sparrow
Gopher
CodeGer
Pythia
G
PaLM
Flan-T5
GLaM
MT-NLG
OPT
8
Vicun
YaLM
Flan-PaLM
GPT-NeoX-20B
PanGu-E
BLOOM
GLM
Tk-Instruct
Ai2
C
Bard
mTo
8
NLLB
a
Cohere
AlexaTM
OLLaMA
BLOOMZ
WeLM
2023
Galatica
8
OPT-IML0
ChatGPT
图1大语言模型发展历程[1]
随着模型参数规模和训练数据规模的爆炸式增长，通用大语言模型LLM的涌现能力
6
# Page 11
新趋势：ChatGPT技术加速安全革命
（EmergentAbility）凸显。相对于经典规模尺度较小的机器学习或深度学习模型，LLM在上
下文学习（In-ContextLearning）、复杂推理、知识容量、泛化性等方面的能力大幅提升。那么，
这些提升的能力是否能够成为LLM在安全行业的应用潜能呢？具体包括：
·知识语义增强：通过在大规模通用文本数据上进行训练，LLM得以掌握广泛的语言
知识和语义理解能力。相较于小模型，LLM能够更全面地理解词汇、句法和语用，
生成的文本更加准确、连贯，同时保留了语义特征。在安全行业中，知识语义增强有
助于理解和分析安全领域特定的数据内容，如安全威胁、漏洞、攻击技术等相关知识
和安全语义，从而更为准确地识别风险、提供建议或生成报告。
·逻辑分析增强：LLM可以理解和应用逻辑原则来推理和分析输入文本中的信息。相
较于小模型，LLM经过训练可以更好地理解和应用逻辑规则，能够产生更为合乎逻
辑的输出结果。在安全行业中，逻辑分析增强可以更好地分析不同事件之间的关系、
理解上下文相关性、挖掘潜在的威胁情报等，进一步推断可能的攻击路径和攻击团伙，
并分析推荐可采取的安全措施。
·交互决策增强：LLM在与用户的交互过程中表现出更高水平的决策能力和响应性能。
相较于小模型，LLM可以更好地根据输入的上下文和目标指令，综合利用所学习到
的语言知识、语义理解能力以及可能的逻辑推理和决策策略，生成更智能和个性化的
回复，这使得LLM在对话系统、问答系统中具备更强的交互决策能力。在安全行业中，
交互决策增强提供与安全专家、分析师等不同角色进行智能交互，更好地理解不同需
求并提供个性化的安全指导和辅助决策，协助安全团队开展应急响应和威胁管理等工
作。
LLM的通用知识语义、逻辑分析和交互决策这三个增强能力在安全行业中具有重要作用，
有助于提升安全系统的感知、分析和决策能力。通过从特殊的安全数据中提取关键信息、识
别潜在威胁，并能够提供恰当处理建议，LLM可以进一步提高安全系统的效率和准确性，使
其能更好地应对不断演变的安全威胁。随着LLM技术的不断创新发展，有望推动安全行业向
智能化和自动化的方向发展，从而提升网络空间的安全性和可信度。
7
# Page 12
02
新范式：
安全行业大模型
核心框架
# Page 13
新范式：安全行业大模型核心框架
本章首先介绍安全模型的发展困境和研究新范式，接下来阐述安全行业大模型的必要性
和创新价值，并深入分析安全行业大模型的升级技术和分层框架。
2.1安全模型发展面临困境
安全模型发展面临多重困境，其中包括威胁演化速度快、数据量和复杂性增加、数据偏
差和不均衡，隐私和合规性问题、自适应能力缺乏，以及对抗攻击挑战等。克服这些困境对
于推动安全行业的发展具有重要意义。
意。《Dos and Don'ts of Machine Learning in Computer Security》[2] 总结了安全行业的机器
学习模型的十大陷阱，这些陷阱普遍存在于恶意样本识别、网络入侵检测、漏洞分析挖掘、
网站攻击监测、社交网络滥用、二进制代码分析和代码归因等安全场景中，导致关键结果出
现严重偏差、一系列的性能劣化和不可解释性难题，进而影响安全模型在安全行业的应用推
广。
ChatGPT一经推出便引I起轰动，安全行业研究员和工作者也纷纷就ChatGPT在安全行业
的应用潜力和影响展开探索，尝试应用于情报分析、运营辅助、攻击预测、网络钓鱼内容生成、
恶意代码编写等攻防场景中。从探索的实际效果来看，ChatGPT背后的LLM大模型技术在
安全行业可能会面临如下挑战：
·安全专业数据和知识缺乏：LLM模型使用广泛的通用语料库进行训练，同时安全行
业的数据通常是特殊且有限的。这导致LLM缺乏安全相关数据和专业知识，缺乏对
特定安全问题的理解能力，无法提供准确或深入的专业解释。
·零日攻击和新型威胁挑战：LLM的训练数据只能基于过去的安全事件和攻击行为。
然而，威胁攻击是不断演变和改变的，面对零日攻击和新型威胁等未知的威胁，LLM
很可能无法准确地识别和防御。
·模型低成本和实时性难题：安全行业需要对威胁事件进行及时响应，因此模型最好能
够本地部署和学习，具备实时性能。然而，由于LLM的计算复杂性，推理过程需要
高性能的计算资源和较长的时间，这可能无法满足安全实时检测和及时响应的需求。
·数据隐私和安全性问题：LLM在训练过程中使用的大量数据可能包含敏感信息，同
时处理和存储用户交互数据也存在威胁用户隐私和安全性的风险。因此，在安全行业
中应用LLM时，必须采取相应的数据保护措施，以确保用户隐私和敏感数据不被泄露，
9
# Page 14
NSFOCUS|安全行业大模型SecLLM技术白皮书
遵守相关的隐私保护法规和标准。
·可解释和可信限制：LLM往往被视为黑盒模型，其决策过程和判断依据难以解释。
在安全行业中，可解释和可信度对于分析和决策的重要性不容忽视。因此，在应用
LLM时，需要考虑如何增强安全行业对LLM模型的信任度，并使分析和决策过程更
加可靠和可解释。
为了有效应对上述LLM大模型技术在安全行业应用中的挑战，有必要探索新的方法和
技术来提高模型对特定安全问题的理解能力和专业解释能力。因此，构建一个专用于安全
行业的大模型（SecurityLargeLanguage Model，缩写为SecLLM）是非常有必要的。期望
SecLLM能够更好地理解解释和协助解决与网络安全相关的特定问题。它将具备对网络威胁、
攻击技术、漏洞利用等方面的更深入理解，从而提供更准确的威胁分析和安全决策的智能化
支持。
2.2安全模型的研究新范式
由上文分析可以看出，传统安全模型和LLM技术在安全行业应用中都面临一系列困境，
解决这些困境有必要构建安全行业专用的大模型SeCLLM。
传统安全模型的构建通常采用有监督学习范式。有监督学习模型训练前，需要依赖人工，
针对输入网络流量、系统日志不同数据开展数据标注、特征构建和算法选择等工作；接看分
别训练小模型；训练完毕后，不同小模型各自只能预测单一的入侵行为或恶意攻击。如图2
因此，传统安全模型的研究思路会限制其学习和泛化能力，所以并不适用于SeCLLM的构建。
不同于传统安全模型，通用的大语言模型LLM采用“预训练－微调”的研究新范式，该
范式已成为NLP任务的主流范式。在该范式下，LLM在大规模无监督学习的基础上预训练，
然后通过有监督学习或强化学习进行特定任务的精细调整和优化，提升了模型的泛化和学习
能力。那么是否可以借鉴LLM的“预训练-微调”新范式来构建SeCLLM？
T/0
可分类编号
恶意样本监测
加密
Web
加密流量分类
击
安全大模型
Web攻击分析
Web
下游任务·
payload
预训练
微调
图2安全模型研究范式的变化
10
# Page 15
新范式：安全行业大模型核心框架
在这个新范式下开展SeCLLM的研究，如图2右侧所示，安全大模型是利用大规模无标
注安全数据通过无监督学习预训练安全模型的基座，然后在基座模型上利用下游不同安全任
务的有标注数据进行有监督学习微调，实现下游任务的适配。
·无监督预训练：通过大规模的无监督预训练来学习安全领域的专业知识和编码。这一
阶段通常使用Transformer架构，在海量多源异构安全数据上进行预训练，使模型具
备对安全词汇、攻击上下文和威胁语义的理解能力。通过在海量安全语料上的预训练
增强，补充记忆大量的安全专业知识。
·下游任务微调：无监督预训练完成后进入微调阶段。微调是在特定下游安全任务上使
用有监督学习或强化学习方法，将预训练模型的参数进行微调。微调的目的是根据下
游安全任务需求和特定数据集中的标注信息，使模型适应特定任务的要求。经过指令
微调对齐安全专家的威胁处置后，安全模型在各种攻防处理任务中展现出了强大的通
用能力，能够解决许多未知或复杂攻防新问题的零样本或小样本任务。
了手工构建特征的需要，提高传统安全模型的准确性和适应性。当有新型威胁出现时，只需
要微调模型而不是重新训练。在SeCLLM的构建过程中，“预训练-微调”范式将使模型更
具适应性和智能性，具有应对不同新型攻击和未知威胁的处理能力，以确保在实际安全行业
应用中取得成功。
2.3安全行业大模型的升级技术
基于“预训练-微调”的研究新范式，SeCLLM的目标是构建易用、高效、准确和可信的
“快”、“准”、“安”四方面开展技术升级（如图3所示），为安全行业提供智能化的威
胁应对和安全防御能力，提供更强大可信的解决方案。
“易”
“快”
简单LUI替代GUI
快速接入提供及时
SecLLM
“准”