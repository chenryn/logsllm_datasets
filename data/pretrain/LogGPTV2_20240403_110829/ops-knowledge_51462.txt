User: 请解答这个和日志有关的问题Need to make a storage that keeps growing in size First, due to security reasons and others I wont be able to make use of S3, or other similar solution.

I have a a storage server in which I have a 1TB had disk. I have a Mysql server running in it. Data is contentiously begin added to the database by our computers about a GB per hour. So in about a month I would run out of storage. 

I want to be able to add new hard disks and connect other systems to the network and link the storage. eg: If i link one more 1TB system I want the available storage for MySQL db to be 2TB.  ie: distributed over the two systems.

Load balancing option too would be great. Ie. MySQL server on  Both the system should be able to access the database. 

How can I  achieve this (Open source solutions preferred).

Assistant: Start a new MySQL server every time you are close to full.  Rewrite the client software to access the right MySQL server depending on the date of the information they need.

Of course, you need to have data that can be partitioned by datestamp.  Queries that need to span servers will have to query each one and combine the results.  Joins will be difficult.  However, considering that you want infinite storage, you have to compromise elsewhere.  You can't have infinite storage and still use MySQL.

This works great for any database that is storing logs or other archive data that accumulates but doesn't change.  Such data is also easy to partition by datestamp.

This is the scheme that Twitter used initially.  They had one MySQL server to archive old tweets; when it filled up they started a new server.   Searches for "Everything user X ever tweeted" sent the query to each server starting with the newest and ending with the server that stored the archive when the account was created.  All the old servers were set up with read-only replicas; as many needed to fulfill the amount of queries they had to handle.  Therefore the system can scale in both directions: scale up (moving to the next server for more space) and scale out (adding more replicas for more load).

However what you will eventually find is that a relational database is a terrible choice for storing logs or other archive data that accumulates but doesn't change.  Inserting many rows at a time involves locking that slows down the process and is wasteful if you can guarantee that all the data is "write once".

Twitter eventually moved to other storage technology and you will find that you want to do the same.  You will want to select a system that is built to grow infinitely by adding more machines.  The system then tracks which machines hold which data and even though you send your queries to a master node, it does the right thing to find the results.  Such systems include: MongoDB, Hbase, CouchDB, and I think Riak.

If you data can not be partitioned easily, this answer won't help you.  In that case you'll need to look at adding more and more storage to the existing system.  Adding a lot of disk to a SAN and connecting that to the machine is one solution.