107
104
101
Networks from Topology Zoo
79
Figure 9: Optimizing soft specification comes at the cost of
exploring roughly x
2 states as opposed to x.
random baseline in 60% of the cases each. In 4% of the topologies for
LPx2, however, Snowcap incurs 13% higher cost than the random
approach. “Most important first” outperforms “most important last”
in scenario IGPx2, while it is the other way around in scenario
LPx2, highlighting the benefits of using an adaptive approach like
Snowcap’s to accommodate the different scenarios.
Optimization overhead. While Snowcap effectively finds recon-
figuration orderings with low costs, it also matters what overhead
this incurs. Therefore, we measure the number of states explored by
the random baseline and Snowcap with and without soft specifica-
tion. To this end, we consider the scenario FM2RR and measure the
median number of states, along with the 25th and 75th percentile,
over 10 000 runs on 79 different topologies from Topology Zoo.
Fig. 9 shows the number of explored states for all three ap-
proaches on a logarithmic scale. The topologies are ordered by
number of explored states of Snowcap’s “hard spec. only” approach.
The figure clearly shows that the soft specification comes at a cost:
2 states compared to x without opti-
Snowcap explores roughly x
mization, which is expected as Snowcap has to explore all possible
commands at every step to find the optimal one. Nevertheless,
Snowcap outperforms the random approach for some topologies
by orders of magnitude while finding better solutions.
6.3 Accuracy of Snowcap
Snowcap relies on a sufficient, but not necessary condition (cf. §5.2)
to provide guarantees on the network state during convergence.
Since it is “only” sufficient, it can be overly careful and deem a safe
convergence process to be unsafe. In the following, we analyze the
accuracy of these guarantees.
Methodology. We use the Switch network from Topology Zoo, a
topology with 30 routers and 61 edges. We select three route reflec-
tors and choose 1000 different IGP configurations. The network has
three neighbors ex , e1, and e2, which all advertise the same FEC.
The route from ex is the least preferred. During reconfiguration,
we remove the eBGP session towards e2. As hard specification, we
require all routers to forward traffic either towards e1 or e2 during
convergence. To evaluate the accuracy, we check the convergence
guarantees (prediction) and simulate 10 000 different, random con-
vergence sequences to see if any sequence violates the requirement
(simulation), resulting in 28 000 data points.
The results show that our prediction matches the simulation
in 78.5% of the scenarios: for 57.6% of them Snowcap correctly
assesses their safety; for 20.9% of them Snowcap correctly detects
a violation. For the remaining 21.5% scenarios, Snowcap is too
conservative: it sees a potential violation, even though no simulated
convergence procedure violates the condition. This experiment
shows that our condition is effective and most importantly, never
considers a convergence process to be safe, when it is not.
7 CASE STUDY
We demonstrate Snowcap’s practicality using an end-to-end imple-
mentation interfacing with a virtualized network using GNS3 [14]
and FRRouting [41]. We use the Hibernia Ireland topology from
Topology Zoo, a network with six routers. The reconfiguration in-
volves moving from an iBGP full mesh to a route reflector topology
(FM2RR), involving 15 commands.
For this case study, every router has a client connected to it,
which continually sends packets towards all five external networks.
We measure the number of packets lost during the reconfiguration.
As a baseline, we apply all commands in random order and wait
two seconds between each command, regardless of convergence.
In total, around 50% of the traffic is lost during the 40 seconds it
takes to apply all 15 commands. In comparison, when using the full
pipeline of Snowcap without human intervention (i.e., Snowcap’s
runtime controller applies the sequence synthesized by our search
tactics), the reconfiguration takes around 80 seconds, dropping
only around 2% of the total traffic. These blackholes are caused by
a specific behavior of FRR routers, which close a BGP session upon
tagging a neighbor as a route reflector client. Without additional
temporary safeguards (e.g., static routes), these problems cannot
be avoided on FRRouting.
8 DISCUSSION
We now discuss some operational aspects of Snowcap including
its complexity and completeness; and how to deal with impossible
scenarios or failures during the reconfiguration.
Complete exploration. Snowcap is able to quickly find a valid
solution for the vast majority of reconfiguration scenarios. This
is achieved by aggressively pruning the search space using the
counter-example-guided approach (§4.2). In few cases though, this
approach might rule out valid solutions, potentially requiring Snow-
cap to exhaustively explore the search space (§4.1) instead. One
example in which exhaustive exploration happens is when the con-
figuration exhibits more than one stable state (i.e., the network
contains one or more “BGP Wedgies” [21]); and (ii) any invalid
ordering produces exactly the same error, preventing the Reduce
phase (Alg. 2) to remove any commands.
While possible (we provide a theoretical example of the situa-
tion in App. F), we argue that these conditions are not practical—
especially because they entail an incorrect BGP configuration to
start with—and also did not manifest themselves in any of the prac-
tical reconfiguration scenarios we considered. Also, we stress that
SIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
Tibor Schneider, Rüdiger Birkner, and Laurent Vanbever
Network configuration repair. CPR [15] and AED [1] synthesize
configuration repairs for a given configuration such that it meets
the operator’s specification. AED can also take management and
operational objectives into account, such as minimizing the number
of devices affected by the repair or the total number of configura-
tion changes. Snowcap complements these systems as it can apply
their repairs without violating the specification during the recon-
figuration. Concretely, one could use AED to synthesize the final
configuration, and then Snowcap to safely transition to it.
Abstract control plane representation. Tiramisu [2] and ARC [16]
use an abstract graph representation of the control plane to ana-
lyze network configurations. Snowcap’s convergence guarantees
(§5.2) rely on a similar approach using a graph representation of
the transient forwarding state. Its accuracy might be improved by
incorporating control plane information like ARC does.
10 CONCLUSION
We presented Snowcap, the first protocol-agnostic system to syn-
thesize safe network-wide configuration updates in distributed
control planes by phrasing the problem as an optimization problem
under constraints. We introduced a precise and dynamic specifi-
cation language based on LTL to allow operators to specify the
transition from the old to the new high-level policy. We further
proposed search tactics which leverage counter-examples to isolate
command dependencies and resolve them independently. Finally,
we demonstrated Snowcap’s scalability and effectiveness: Snowcap
finds good reconfiguration plans for realistic network topologies
and reconfiguration scenarios in few seconds.
Ethical issues. This work does not raise any ethical issues
ACKNOWLEDGEMENTS
We thank our shepherd Lixin Gao and the anonymous reviewers
for their insightful comments and helpful feedback. The research
leading to these results was supported by an ERC Starting Grant
(SyNET) 851809.
even in these unlikely scenarios, Snowcap works (it is complete)—
albeit more slowly.
Impossible reconfigurations. It may be impossible to directly tran-
sition from the initial to the final configuration without violating
the hard specification. In such situations, Snowcap is not able to
find a safe ordering. To overcome the critical steps during the re-
configuration, one can introduce temporary configurations such
as static routes. Finding the right temporary configurations is a
difficult problem as one also needs to keep the network’s resiliency
(e.g., link failures) in mind. We plan to address this in future work.
Outages during reconfiguration. Networks are constantly faced
with the possibility of unexpected outages, which can also happen
during reconfiguration. Our specification language allows operators
to express redundancy, i.e., that conditions still apply even if links
in the network fail. This inherently solves the problem, without the
need for control.
9 RELATED WORK
Network management automation. To reduce operator-induced
downtimes, several systems have been proposed to automate net-
work management [29, 38, 40]. These systems automate configura-
tion generation and deployment for network operators. In addition,
they monitor the network state during updates to react upon anom-
alies. Snowcap can extend these systems by providing a safe recon-
figuration ordering, eliminating potential anomalies and human
interventions during the updates.
Network migrations. Researchers have put extensive focus on the
special case of IGP migrations. Francois et al. [11, 13] have shown
how to avoid transient forwarding loops in link-state protocols,
such as OSPF or IS-IS, by updating the routers in a specific order and
progressively changing the link weights. Raza et al. [34] extended
this approach by allowing to optimize for certain metrics during
the reconfiguration (e.g., minimize link utilization).
Several systems build upon the technique known as Ships-In-
The-Night [3, 25, 42–45], where each router is running two separate
configurations in parallel. The new configuration runs in the back-
ground and the transition happens once it has converged. All these
approaches pose particular requirements to the hard- and software
of network devices as they need to support multiple routing and
forwarding tables at the same time.
SDN updates. Several works looked at safe transitions from one
configuration to another in the context of SDN [24, 31, 32]. While
the problem is similar, the solution differs vastly as reconfiguration
in SDN means updating the forwarding state directly. The work of
McClurg et al. [32] takes a similar approach as Snowcap: it finds
an ordering of data plane updates using counter-examples.
The Routing Control Platform (RCP) [7] combines ideas from
SDN with traditional, distributed networking to solve the problem
of network-wide configuration updates. It does so by logically-
centralizing the routing information and performing the route se-
lection on behalf of the routers. Approaches like RCP require drastic
changes to the network-wide configuration and topology, and have
several side-effects. Snowcap, however, can be used with traditional
networks without the need for any adaptation of the network.
Synthesizing Network-Wide Configuration Updates
SIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
[34] Saqib Raza, Yuanbo Zhu, and Chen-Nee Chuah. 2011. Graceful Network State
[33] Bruno Quoitin and Steve Uhlig. 2005. Modeling the Routing of an Autonomous
[32] Jedidiah McClurg, Hossein Hojjat, Pavol Čern`y, and Nate Foster. 2015. Efficient
Network Configurations. In ACM SelfDN. Budapest, Hungary.
[30] Hongqiang Harry Liu, Yibo Zhu, Jitu Padhye, Jiaxin Cao, Sri Tallapragada, Nuno P
Lopes, Andrey Rybalchenko, Guohan Lu, and Lihua Yuan. 2017. Crystalnet:
Faithfully Emulating Large Production Networks. In ACM SOSP. Shanghai, China.
[31] Ratul Mahajan and Roger Wattenhofer. 2013. On Consistent Updates in Software
Defined Networks. In ACM HotNets. College Park, MD, USA.
Synthesis of Network Updates. In ACM PLDI. Portland, OR, USA.
System with C-BGP. IEEE Network 19, 6 (2005), 12–19.
Migrations. IEEE/ACM Transactions on Networking 19, 4 (2011), 1097–1110.
[35] John Regehr, Yang Chen, Pascal Cuoq, Eric Eide, Chucky Ellison, and Xuejun
Yang. 2012. Test-Case Reduction for C Compiler Bugs. In ACM PLDI. Beijing,
China.
[36] Arjun Singh, Joon Ong, Amit Agarwal, Glen Anderson, Ashby Armistead, Roy
Bannon, Seb Boving, Gaurav Desai, Bob Felderman, Paulie Germano, Anand
Kanagala, Jeff Provost, Jason Simmons, Eiichi Tanda, Jim Wanderer, Urs Höl-
zle, Stephen Stuart, and Amin Vahdat. 2015. Jupiter Rising: A Decade of Clos
Topologies and Centralized Control in Google’s Datacenter Network. In ACM
SIGCOMM. London, United Kingdom.
[37] P. Smith. 2010. BGP Techniques for Internet Service Providers. NANOG50
Presentation. (2010).
cessed: 2021-01-23.
[38] Peng Sun, Ratul Mahajan, Jennifer Rexford, Lihua Yuan, Ming Zhang, and Ahsan
Arefin. 2014. A Network-State Management Service. In ACM SIGCOMM. Chicago,
IL, USA.
[39] Yu-Wei Eric Sung, Sanjay Rao, Subhabrata Sen, and Stephen Leggett. 2009. Ex-
tracting Network-wide Correlated Changes from Longitudinal Configuration
Data. In PAM. Seoul, Korea.
[40] Yu-Wei Eric Sung, Xiaozheng Tie, Starsky HY Wong, and Hongyi Zeng. 2016.
Robotron: Top-down Network Management at Facebook Scale. In ACM SIGCOMM.
Florianopolis, Brazil.
[41] The Linux Foundation. [n. d.]. FRRouting. https://frrouting.org/. ([n. d.]). Ac-
[42] Laurent Vanbever, Stefano Vissicchio, Luca Cittadini, and Olivier Bonaventure.
2013. When the Cure is Worse than the Disease: The Impact of Graceful IGP
Operations on BGP. In IEEE INFOCOM. Turin, Italy.
[43] Laurent Vanbever, Stefano Vissicchio, Cristel Pelsser, Pierre Francois, and Olivier
Bonaventure. 2011. Seamless Network-Wide IGP Migrations. In ACM SIGCOMM.
Toronto, Ontario, Canada.
[44] Laurent Vanbever, Stefano Vissicchio, Cristel Pelsser, Pierre Francois, and Olivier
Bonaventure. 2012. Lossless Migrations of Link-State IGPs. IEEE/ACM Transac-
tions on Networking 20, 6 (2012), 1842–1855.
[45] Stefano Vissicchio, Laurent Vanbever, Cristel Pelsser, Luca Cittadini, Pierre Fran-
cois, and Olivier Bonaventure. 2012. Improving Network Agility with Seam-
less BGP Reconfigurations. IEEE/ACM Transactions on Networking 21, 3 (2012),
990–1002.
[46] Andreas Zeller and Ralf Hildebrandt. 2002. Simplifying and Isolating Failure-
Inducing Input. IEEE Transactions on Software Engineering 28, 2 (2002), 183–200.
REFERENCES
[1] Anubhavnidhi Abhashkumar, Aaron Gember-Jacobson, and Aditya Akella. 2020.
AED: Incrementally Synthesizing Policy-Compliant and Manageable Configura-
tions. In ACM CoNEXT. Barcelona, Spain.
[2] Anubhavnidhi Abhashkumar, Aaron Gember-Jacobson, and Aditya Akella. 2020.
Tiramisu: Fast Multilayer Network Verification. In USENIX NSDI. Santa Clara,
CA.
[3] Richard Alimi, Ye Wang, and Y. Richard Yang. 2008. Shadow Configuration as a
Network Management Primitive. In ACM SIGCOMM. Seattle, WA, USA.
[4] T. Bates, E. Chen, and R. Chandra. 2006. RFC 4456: BGP Route Reflection: An
Alternative to Full Mesh Internal BGP (IBGP). Technical Report.
[5] Ryan Beckett, Aarti Gupta, Ratul Mahajan, and David Walker. 2017. A General
Approach to Network Configuration Verification. In ACM SIGCOMM. Los Angeles,
CA, USA.
[6] Ryan Beckett, Ratul Mahajan, Todd Millstein, Jitendra Padhye, and David Walker.
2019. Don’t Mind the Gap: Bridging Network-Wide Objectives and Device-Level
Configurations: Brief Reflections on Abstractions for Network Programming.
ACM SIGCOMM CCR 49, 5 (2019), 104–106.
[7] Matthew Caesar, Donald Caldwell, Nick Feamster, Jennifer Rexford, Aman Shaikh,
and Jacobus van der Merwe. 2005. Design and Implementation of a Routing
Control Platform. In USENIX NSDI. Boston, MA, USA.
[8] Cindy Eisner, Dana Fisman, John Havlicek, Yoad Lustig, Anthony McIsaac, and
David Van Campenhout. 2003. Reasoning with Temporal Logic on Truncated
Paths. In CAV. Boulder, CO, USA.
[9] Klaus-Tycho Foerster, Stefan Schmid, and Stefano Vissicchio. 2018. Survey of
Consistent Software-Defined Network Updates. IEEE Communications Surveys &
Tutorials 21, 2 (2018), 1435–1461.
[10] Ari Fogel, Stanley Fung, Luis Pedrosa, Meg Walraed-Sullivan, Ramesh Govindan,
Ratul Mahajan, and Todd D Millstein. 2015. A General Approach to Network
Configuration Analysis.. In USENIX NSDI. Oakland, CA, USA.
[11] Pierre Francois and Olivier Bonaventure. 2007. Avoiding Transient Loops During
the Convergence of Link-State Routing Protocols. IEEE/ACM Transactions on
Networking 15, 6 (2007), 1280–1292.
[12] P. Francois, O. Bonaventure, B. Decraene, and P. Coste. 2007. Avoiding Disrup-
tions during Maintenance Operations on BGP Sessions. IEEE Transactions on
Network and Service Management 4, 3 (2007), 1–11.
[13] Pierre Francois, Mike Shand, and Olivier Bonaventure. 2007. Disruption Free
Topology Reconfiguration in OSPF Networks. In IEEE INFOCOM. Barcelona,
Spain.
[14] Galaxy Technologies, LLC. [n. d.]. GNS3 | The software that empowers network
professionals. https://www.gns3.com/. ([n. d.]). Accessed: 2021-01-23.
[15] Aaron Gember-Jacobson, Aditya Akella, Ratul Mahajan, and Hongqiang Harry
Liu. 2017. Automatically Repairing Network Control Planes Using an Abstract
Representation. In ACM SOSP. Shanghai, China.
[16] Aaron Gember-Jacobson, Raajay Viswanathan, Aditya Akella, and Ratul Mahajan.
2016. Fast Control Plane Analysis Using an Abstract Representation. In ACM
SIGCOMM. Florianopolis, Brazil.
[17] Aaron Gember-Jacobson, Wenfei Wu, Xiujun Li, Aditya Akella, and Ratul Maha-
jan. 2015. Management Plane Analytics. In ACM IMC. Tokyo, Japan.
[18] Nick Giannarakis, Devon Loehr, Ryan Beckett, and David Walker. 2020. NV: An
Intermediate Language for Verification of Network Control Planes. In ACM PLDI.
London, UK.
[19] V. Gill and J. Mitchell. 2003. AOL Backbone OSPF-ISIS Migration. NANOG29
[20] Barry Raveendran Greene and Philip Smith. 2002. Cisco ISP Essentials. Cisco
[21] T. Griffin and G. Huston. 2005. RFC 4264: BGP Wedgies. Technical Report.
[22] Timothy G Griffin and Gordon Wilfong. 2002. On the Correctness of IBGP
Configuration. In ACM SIGCOMM. Pittsburgh, PA, USA.
[23] Gonzalo Gomez Herrero and Jan Antón Bernal Van der Ven. 2011. Network
Mergers and Migrations: Junos Design and Implementation. Vol. 45. John Wiley &
Sons.
[24] Xin Jin, Hongqiang Harry Liu, Rohan Gandhi, Srikanth Kandula, Ratul Mahajan,
Ming Zhang, Jennifer Rexford, and Roger Wattenhofer. 2014. Dynamic Scheduling
of Network Updates. In ACM SIGCOMM. Chicago, IL, USA.
[25] John P John, Ethan Katz-Bassett, Arvind Krishnamurthy, Thomas Anderson, and
Arun Venkataramani. 2008. Consensus Routing: The Internet as a Distributed
System. In USENIX NSDI. San Francisco, CA, USA.
Analysis: Static Checking for Networks. In USENIX NSDI. San Jose, CA, USA.
[27] Hyojoon Kim, Theophilus Benson, Aditya Akella, and Nick Feamster. 2011. The
Evolution of Network Configuration: A Tale of Two Campuses. In ACM IMC.
Berlin, Germany.
[28] S. Knight, H.X. Nguyen, N. Falkner, R. Bowden, and M. Roughan. 2011. The
[26] Peyman Kazemian, George Varghese, and Nick McKeown. 2012. Header Space
Internet Topology Zoo. IEEE JSAC 29, 9 (2011), 1765 –1775.
[29] Hongqiang Harry Liu, Xin Wu, Wei Zhou, Weiguo Chen, Tao Wang, Hui Xu, Lei
Zhou, Qing Ma, and Ming Zhang. 2018. Automatic Life Cycle Management of
Presentation. (2003).
Press.
SIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
Tibor Schneider, Rüdiger Birkner, and Laurent Vanbever
APPENDIX
Appendices are supporting material that has not been peer-reviewed.
A NETWORK ACQUISITION CASE STUDY
To study the impact of different reconfiguration plans on the recon-
figuration costs and to evaluate Snowcap, we studied the network
acquisition scenario [23], in which two networks are merged. For
this scenario, we automatically and randomly partition the network
into two distinct connected components, where both are connected
to at least one external device. For each of these components, we
choose a single route reflector based on the router with the highest
degree, and choose all link weights randomly. All external routers