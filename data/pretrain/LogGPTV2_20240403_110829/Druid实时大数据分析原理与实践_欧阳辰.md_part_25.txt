aggs=concurrentGet(prev);
//Welostarace
agg.aggregate();
if（reportParseExceptions)
//"aggregate" can throw ParseExceptions if a selector expects something but
}else{
thrownewParseException(e,
log.debug(e, "Encountered parse error, skipping aggregator[%s].", agg.
gets something else.
agg.getName(）);
getName(）);
199
---
## Page 224
dex对象；其大部分实现由DefaultIndexIOHandler完成。IndexIO实现类图如图8-4所示。
rowContainer.set(null);
...//Aggregaterow;
rowContainer.set(row);
ThreadLocalrowContainer,
访问的并发度。
它为每一个线程分别创建一个独立的变量副本，而不会影响其他线程所对应的副本，提高了
public interface Aggregator
ByteBuffer，效率会更高一些。
以由 AggregatorFactory 创建对象。BufferAggregator 是类似的聚合器，它将 Metric 直接聚合成
的内部实现使用了FloatColumnSelector和Offset。
带任何参数，这里假设所有的参数都已经在环境中设置好，或者已经在构造函数中创建。它
4
200
void aggregate();
long getLong();
void close(）;
String getName();
float getFloat(）;
Object get();
void reset();
基本类图关系，IndexIO提供装载索引文件功能：LoadIndex(FileDIR)，返回QueryableIn-
装载索引文件
另外，在聚合过程中使用了ThreadLocal技术，它为row数据创建了ThreadLocal变量：
Aggregator是非常有意思的对象，用于聚合Metric，提供了aggregateO和get()方法，
Druid实时大数据分析原理与实践
不
---
## Page 225
5
第8章
持久化索引
IndexMerger负责索引的持久化，整个过程如图8-6所示。
装载索引文件的过程如图8-5所示。
核心源代码探析
wferserialzereao
图8-5装载索引文件的过程
图8-4
IndexIO实现类图
Data
201
---
## Page 226
开始支持直接生产V9格式的索引文件，提高了性能。
的实现都是先生产V8格式，最后一步转化成V9格式。2016年6月发布的Druid0.9.1版本，
202
由于Druid0.9版本发布时，直接生成V9格式的代码未经全面测试，因此在0.9版本中
v8OutDir,outDir,indexSpec)
indexiO.getDefaultlindexIOHandler().convertV8toV9(
writer.write(
IterabletheRows=makeRowiterable(
indexSpec.gelBitmapSerdeFactory()
datalnterval,
v8OutDir.
rowMergerFn
dimCo
mergedMetrics,
bitmapSerdeFactory.getBitmapFactory().makelmmutableBitmap（bitset)
indexes
Walkthrough datasetsandmerge them
Create Inverted Indexes(Bitmap.Spatial)
图8-6
Create Forward Indexes
ConvertfleformatfromV8toV9.
Create IndexDrdFile
持久化索引的过程
下面是开发中的一些性能数据。
Druid实时大数据分析原理与实践
---
## Page 227
方法，可以在遍历过程中中断，它会保存执行的状态，下次执行时再从中断处开始。但Yielder
了解决这个问题，可以将Sequence转换成Yielder对象。Yielder的功能类似于Python的yield
方法完成对资源的关闭操作。控制反转的缺点是不能把迭代器中的数据暴露给用户使用。为
进行回调即可。
在Sequence内部完成迭代遍历，调用方只需要提供一个实现操作符逻辑的函数，在遍历过程
2.Sequence实现
扫描遍历多次。
得到的结果集传递给后续的聚集操作，如果结果集很大会带来很大的内存开销，同时会造成
成操作，使用迭代器可以实现不同操作符之间的流式处理。试想使用List存储扫描索引以后
什么不直接使用选代器而且对其进行封装。高效的选代器设计可以实现只扫描一次表就能完
级封装，其底层还是依赖于Iterator（迭代器）。这里先讲为什么要使用迭代器，后续再讲为
1.Sequence
8.6.1
8.6
MergerV9.java。
第8章核心源代码探析
这样设计的好处是Sequence能够对资源进行管理，它可以在遍历完成以后强制调用close
选代器最典型的应用场景是迭代遍历进行操作符运算。Sequence采用控制反转的方式，
Druid设计了一种可选代的序列叫作Sequence，Sequence其实是对Iterator通用操作的高
直接生产V9格式代码可以查看$\druid\processinglsrc\mainVjavalio\druid\segment\Index-
·性能提升37.3%（（101.3+89.2-65.6-53.8)/(101.3+89.2)=37.3%）
·新方法（直接创建V9格式）
·旧方法（创建V8格式，然后转化成V9格式）
来自开发者KurtYoung的一些数据。
基础组件
Query模块
。Merge时间：53.8秒
。Merge时间：89.2秒
总时间：101.3秒（10个文件）
。总时间：65.6秒
203
---
## Page 228
new Accumulator(）
码如下：
逻辑的Accumulator，in这个参数必须是Integer类型，accumulated也设置为 Integer类型。代
明。假设有一个计算所有元素的总和的场景，我们采用Sequence来实现。首先实现执行求和
while（!accumulator.yielded(）&& iter.hasNext(））{
OutType retVal= initValue;
迭代时作为参数传入，循环执行直到迭代结束。具体过程请参考如下代码。
合运算的结果，在调用时作为参数传入，计算完成以后将该参数作为结果返回，并在下一次
public interface Accumulator
合运算的逻辑抽取到accumulate方法中回调执行。
个Accmulator（累积器）。Accumulator是封装回调函数的接口，把原来在选代过程中进行聚
public OutType accumulate(OutType initValue,
它只提供了如下两个方法。
Yielder的功能看起来很神奇，接下来从代码层面剖析其是如何实现的。先看 Sequence接口，
不会提供类似于 Sequence的资源管理功能，需要调用方显式地调用close方法。Sequence和
204
retVal=accumulator.accumulate(retVal，iter.next(）);
public AccumulatedType accumulate(AccumulatedType accumulated,
public Integer accumulate(Integer accumulated,Integer in)
@Override
return accumulated+in;
第二个参数in是选代器的下一个元素的值。听起来比较抽象，下面通过一个示例来说
该方法接收两个参数，参数类型通过泛型的方式设定。第一个参数accumulated保存聚
accumulate方法的功能是通过控制反转的方式完成聚合运算。调用该方法时需要传入一
InType in):
Accumulator accumulator);
YieldingAccumulator accumulator);
Druid实时大数据分析原理与实践
---
## Page 229
些常用方法。
Sequences 是一个工具类，提供了一些对常用Sequence的封装。我们来看一下 Sequences的一
及销毁Iterator背后的资源，并在其基础上采用装饰器模式衍生出很多不同功能的 Sequence。
构建BaseSequence需要传入自定义的IteratorMaker对象，IteratorMaker用来创建Iterator以
回当前值一次，就实现了类似于Iterator的 next方法。BaseSequence是Sequence的基本实现。
new YieldingAccumulator(）{
整数元素，通过Yielder的接口来实现Iterator的next方法。
器中的值赋给当前Yielder。下面实现一个YieldingAccumulator，目标是获取 Sequence的每个
调用yield方法以后将该标志设置为true，它的作用是退出当前的遍历迭代过程，并将累积
语言中的中断/延续执行。YieldingAccumulator添加了yield标志，yield标志的初始值为false，
对象。在toYielder方法中需要传入一个YieldingAccumulator，它和Yielder协同工作实现Java
个链表，调用Yielder的 get方法获取当前头元素的值，通过调用next方法获取下一个Yielder
第8章核心源代码探析
publicInteger accumulate(Integer accumulated,Integer in){
@Override
奥秘就在第4行yield方法的调用上，退出当前的迭代，这样每执行一次迭代就退出并返
yield(）;
第二个方法toYielder的功能是将Sequence转换成一个Yielder。Yielder对象可以看作是一
·concat方法，用于把多个Sequence合并成一个，为了减少内存的使用，并不会把多
·simple方法，传入一个实现iterable接口的对象，返回BaseSequence。
return in;
·map方法，最常见的方法，类似函数式编程中的map函数，在执行accumulate方法时，
Function fn = new Function()
下面代码来实现。
一个Sequence对象保存学生的成绩，现在需要将每个学生的成绩提高5分，可以通过
在调用转换函数以后再进行聚合操作。下面我们通过示例讲解具体使用方法。假设有
个Sequence的累积结果合并在一起。
个 Sequence 中的元素复制到一个新的 Sequence，而是在执行 accumulate方法时将多
public Integer apply(Integer input)
205
---
## Page 230
8.6.2内存池管理
206
·MMap在Java中通过调用ByteBuffer的get/put接口来实现文件的读写，它也是依赖于
·使用临时文件，在索引创建和合并过程中，中间临时结果会占用大量的内存。为了减
为了减轻JVM垃圾回收带来的性能波动，Druid尽量使用堆外内存和系统内存。
·sort方法，将Sequence中的元素按照指定的规则排序。需要注意的是，该方法会先将
·toList方法，转换成List，将 Sequence中的元素物化到List中。
·filter方法，其功能是在执行accumulate方法时根据传入的Predicate过滤，如果Predicate
内核的PageCache。它最大的优势是直接操作内核的内存，减少一次内存复制。
Kakfa也正是利用了文件IO的这种特性。
盘的页刷到磁盘中，但并不会删除相应的PageCache，以便读取时快速访问。Apache
Cache（页面缓存）。为了提升IO的性能，Linux操作系统增加了PageCache，文件IO
少IVM内存的使用，采用临时文件，通过文件IO的方式，巧妙地利用内核的Page
需要物化到List中，如果Sequence很大的话，需要注意内存的使用。
Sequence 中的元素物化到List中，然后排序List 中的元素，再转换成 Sequence。因为
进行缓存操作。
ner 中异步地将 Sequence中的元素收集到一个List中，待 accumulate方法执行完成再
withEffect方法，在执行accumulate方法时异步执行某些逻辑，例如在CachingQueryRun
不再关心资源管理，避免调用方忘记释放资源造成泄漏。
调用close方法时，同时调用Closable的close方法实现主动管理资源，优点是调用方
池申请的内存。可以自定义Closable在其close方法中实现资源的释放。在Sequence
功能是Sequence主动管理在使用过程中除底层选代器以外的其他资源，例如从内存
现的。
返回true 则进行累积，返回false则抛弃。Group By查询的 Having就是用filter方法实
Sequences.map(source,fn);
returninput+5;
Druid实时大数据分析原理与实践
---
## Page 231
8.6.3
置大一些。这样处理较小的Segment分片就会造成内存浪费。
只处理一个Segment分片，为了兼顾处理较大的Segment分片，我们一般将内存块的大小设
buffer.sizeBytes设置。Group By查询采用固定大小的内存，会造成内存浪费。处理线程每次
时计算结果集中聚合。Druid会给每个处理线程从内存池中申请一块内存，
对象，Druid设计了临时计算结果集，采用固定大小的堆外内存存储Metric的值，先在临
然后在内存中进行聚合操作。默认的内存增量索引使用IVM内存。为了减少大量创建临时
按块操作的，所以固定分区非常切合这种场景。Group By查询需要根据维度拉取原始数据
定大小的内存，容易造成内存碎片。但根据上述的使用场景，编码/解码、压缩/解压缩都是
第8章核心源代码探析
QueryResouce
Druid查询的整体流程如图8-7所示。
Druid采用固定分区的内存池。固定分区的优点是足够简单，缺点是每次申请分配固
·DirectBuffer，在Druid中DirectBuffer的使用场景如下。
查询流程概览
在查询过程中存放中间结果集。
。在索引查询过程中按块解压缩/解码，存放解压缩以后的数据，默认块大小为
。在索引创建过程中按块压缩/编码，LZF压缩除外，默认块大小为64KB。
GroupBy查询在上下文中设置“userOffHeap=true”，
算结果集。
64KB。
Query
QueryRunner
图8-7Druid查询整体流程图
mentWalker
QueryRunnerFactory
，则使用DirectBuffer存放计
QueryToolChest
，内存大小通过
QueryEngine
207
---
## Page 232
public QueryRunnermergeRunners(ExecutorService queryExecutor,
执行给定的Segment查询，并返回一个Sequence存储返回的结果。
public QueryRunner createRunner(Segment segment);
的结果。该接口提供了两个方法。
ule中添加了Yielder与 Sequence的序列化和反序列化的定制。
方便序列化。
208
该方法接收一个参数Segment，基于给定的 Segment创建QueryRunner。QueryRunner会
QueryRunnerFactory的功能是创建底层查询的QueryRunner，以及合并多个QueryRunner
QueryRunnerFactory
（4）利用JsonWriter将Yielder序列化写人到Response中。在DruidDefaultSerializersMod-
（3）将Sequence转换成Yielder，这个Yielder每执行一次返回一个元素，类似于选代器，
（2）调用相应的QuerySegmentWalker构建QueryRunner，然后执行返回Sequence。
（1）通过Jackson Json的ObjectMapper把参数反序列化成Query对象。
其执行流程如下：
QueryResource是查询的人口，Druid启动时将“druid/v2”的URL绑定在QueryResource
QueryResource
·QueryEngine，查询引擎，查询逻辑的核心实现类。每种类型的查询都有一个相应的
.QueryRunner,
·QueryRunnerFactory，负责构建底层查询的QueryRunner，以及并发执行QueryRunner，
·QuerySegmentWalker，根据查询的interval或者Segment 构建QueryRunner。
·QueryResource，查询人口。
下面是Druid查询过程中的关键组件。
·QueryToolChest，辅助创建QueryRunner，用于合并结果以及后处理等。
引擎。
执行查询链的一段逻辑。
、
然后合并。
QueryRunner采用调用链和装饰器模式实现，每个QueryRunner负责
Iterable>queryRunners);
Druid实时大数据分析原理与实践
---
## Page 233
图8-8所示，并介绍重要的QueryRunner实现。
共同的功能交给QueryRunner构建职责链处理。接下来我们看一下QueryRunner的类图，如
上层还是有很多共同之处的，例如Metric性能指标收集、缓存的使用、多线程执行等，这些
有查询执行计划，而是采用固定的查询模式。每种不同类型的查询采用不同的模式，但是其
JDKIO包中的OutputStream/InputStream的实现，通过嵌套组合的方式实现职责链。Druid没
3.QueryRunner
前缀的QueryRunnerFactory。
return new ChainedExecutionQueryRunner>(queryExecutor
代码所示。
GroupBy查询和SegmentMetadata查询以外，其他所有查询的mergeRunners方法实现如下面
最后合并其返回结果。Druid设计了ChainedExecutionQueryRunner封装了上述逻辑。除了
QueryRunner，mergeRunners 方法会将这些QueryRunner提交给ExecutorService并发执行，
第8章核心源代码探析
QueryRunner是封装执行查询的高级接口。QueryRunner采用装饰器设计模式，类似于
GroupByQueryRunnerFactory
后面会介绍ChainedExecutionQueryRunner的具体实现。不同类型的查询设计了其名称
·BySegmentQueryRunner，用于调试，在结果集中添上Segment的信息。
·FinalizeResultsQueryRunner，将复杂对象的Metric转换成数值类型。
·CPUTimeMetricQueryRunner，在执行过程中收集CPU的执行时间，并且发送到配置
.MetricsEmittingQueryRunner,
（1）通用的QueryRunner
.TimeBoundaryQueryRunnerFactory
.SelectQueryRunnerFactory
SearchQueryRunnerFactory
TopNQueryRunnerFactory
TimeseriesQueryRunnerFactory
的Emitter。
，在执行过程中收集Metric，并且发送到配置的Emitter。
queryRunners);
queryWatcher,
209
---
## Page 234
210
·CachingQueryRunner，添加缓存功能。
·GroupByParallelQueryRunner,其功能类似于ChainedExecutionQueryRunner。因为Group
·ChainedExecutionQueryRunner，并发执行的核心类，
·IntervalChunkingQueryRunner，会将大跨度的查询按照chunkPeriod拆分成多个小段
·UnionQueryRunner，它的功能是处理Union查询。
·DirectDruidClient，使用NettyHttpClient发起对历史节点或者实时节点（或者索引服
·CachingClusteredClient，它是Broker查询的核心类，根据时间线路由，分发查询请求
SelectQueryRunner,
（3）实时节点或历史节点用到的QueryRunner
（2）Broker用到的QueryRunner
部类中。
这个类来实现。