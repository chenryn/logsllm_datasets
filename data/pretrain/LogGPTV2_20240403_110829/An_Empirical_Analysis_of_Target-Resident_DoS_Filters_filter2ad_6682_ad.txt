v
i
t
a
g
e
N
e
s
a
F
l
 90
 80
 70
 60
 50
 40
 30
 20
 10
 0
-5
NAC
24 bit SC
16 bit SC
 0
 5
 10
 15
 20
 25
False Positive Percentage
Figure 7. NAC, 16-bit SC, and 24-bit SC (at-
tacker learning)
hypothesis that larger clusters (16-bit preﬁxes) tended to ac-
count for the largest portions of normal trafﬁc in NAC, and
as x was increased, smaller clusters (of preﬁx length greater
than 16 bits) became common according to deﬁnition (1). In
16-bit SC, however, these clusters were represented more
coarsely (still by 16-bit preﬁxes), thus permitting more traf-
ﬁc and a higher false negative rate. Presumably with a more
precise set of routing tables, this difference would become
more pronounced.
As discussed in Section 3, other approaches, notably PI,
have been proposed for use with attacker learning. As a
point of comparison, we also tested NAC, 16-bit SC and
24-bit SC under an attacker learning scenario. In this case,
we utilized attacker and normal trafﬁc (as in Section 5.2)
to train the NAC and SC ﬁlters, with attack packets labeled
as such. Now, for a ﬁxed percentage x, we say that an at-
tribute value (cluster) v(cid:1) is corrupt if the smallest set of at-
tribute values that account for a total of x% of the attacker
packets contains value v(cid:1), or more precisely, if (cid:2) satisﬁes
(1) where %(vi) now is the percentage of attacker packets
seen during training that bear attribute value vi. During ﬁl-
tering (for a ﬁxed percentage x), each packet bearing a cor-
rupt attribute value is rejected; others are admitted.
The results of this test are shown in Figure 7. In this
case, NAC performs slightly better than 16-bit SC in rea-
sonable ranges for both false positives and false negatives.
In addition, the availability of attacker learning induces a
far smaller false positive rate for both NAC and SC than
did normalcy learning. In the case of 24-bit SC, this differ-
ence is extreme. The performance of 24-bit SC is presum-
ably due to the fact that, with ﬁltering attributes of this level
of granularity, attacker addresses almost never overlapped
normal addresses for the server.
An alternative form of ﬁltering after attacker learning
would be to utilize a threshold as in PI. That is, a packet with
a certain ﬁlter attribute value is kept only if attack pack-
ets bearing the same ﬁlter attribute value constitute below a
threshold percentage of all trafﬁc bearing that ﬁlter attribute
value. We will report on this evaluation in the full paper.
6. Discussion
In the course of Section 5, several observations about
factors that affect the performance of these various ﬁlters
became apparent. A factor of some signiﬁcance was the
learning time afforded to each ﬁlter. For example, for the
scenario we studied, a learning period adequate to support
HCF was far longer than predicted by the authors of that
technique. Another signiﬁcant factor was the type of learn-
ing permitted, i.e., attacker learning as assumed by PI, or
merely normalcy learning as assumed by other techniques.
A comparison of the various techniques is summarized
in Figure 8, which is obtained by merging selected re-
sults from Section 5. For readability, we have omitted er-
ror bars from Figure 8, though we caution the reader that
these error bars are important in determining whether there
is a statistically signiﬁcant difference between various ap-
proaches. Figure 8(i) summarizes ﬁlter effectiveness against
spoofed attacks, and Figure 8(ii) summarizes ﬁlter effec-
tiveness against non-spoofed attacks.
We ﬁrst discuss Figure 8(i). Though HCF yielded very
low false negative rates in our evaluations as shown in Fig-
ure 3, we remind the reader that our analysis there was
performed under the optimistic assumption that the true
hop count of each packet could be reliably determined; see
Section 5.1. As already noted in [13], however, corrupted
computers conducting spoofed attacks can manipulate hop
count measurement (by manipulating initial TTL values)
and thereby achieve roughly a 10% false negative rate. As
such, in Figure 8(i) we have shifted the HCF curve upward
to account for this attack. In light of this, the PI and 16-bit
SC curves reach closest to the origin. For PI, this can be ex-
plained since PI marks are immune to spooﬁng. The success
of 16-bit SC (and the similar performance of NAC) can pre-
sumably be attributed to the fact that spoofed addresses in-
duce a very different address distribution from normalcy,
and thus can be ﬁltered relatively easily based on address
alone.
The dramatic impact of attacker learning (versus nor-
malcy learning) is a central conclusion from Figure 8(ii).
The plot demonstrates that attacker learning in the case of
non-spoofed attacks yields vastly superior performance for
each of NAC and SC.
Finally, we again caution the reader from concluding too
much from Figure 8. Though we believe these graphs con-
Proceedings of the 2004 IEEE Symposium on Security and Privacy (S&P’04)  
1081-6011/04 $ 20.00 © 2004 IEEE 
e
g
a
t
n
e
c
r
e
P
e
v
i
t
a
g
e
N
e
s
a
F
l
t
e
g
a
n
e
c
r
e
P
e
v
i
t
a
g
e
N
e
s
a
F
l
 60
 50
 40
 30
 20
 10
 0
 0
 90
 80
 70
 60
 50
 40
 30
 20
 10
 0
 0
NAC
16 Bit SC
24 bit SC
PI
Hop Count Filtering
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100
False Positive Percentage
(i) Spoofed attacks
NAC
16 bit SC
24 bit SC
PI
NAC (Attacker Learning)
16 bit SC (Attacker Learning)
24 bit SC (Attacker Learning)
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100
False Positive Percentage
(ii) Non-spoofed attacks
Figure 8. Summary
tain useful commentary on the relative performance of these
ﬁltering techniques, our results are obviously dependent on
the situation in which our data was recorded and on the par-
ticulars of our methodology. Further studies are required to
conﬁrm these results.
7. Future Work
We recognize that as an initial study of target-resident
ﬁltering techniques, our evaluation has several limitations.
One is the small degree to which attacker addresses and nor-
mal addresses were represented in the network maps that
we were able to gather for evaluating path-based ﬁlters; see
Section 4.3.1. A second is the fact that our evaluation is
based on a single attack event. Improving these aspects of
Proceedings of the 2004 IEEE Symposium on Security and Privacy (S&P’04)  
1081-6011/04 $ 20.00 © 2004 IEEE 
our analysis are topics of ongoing work.
We have also left several parameters for future study. For
example, for path based schemes, it is important to consider
changes in network topology and their effect on the perfor-
mance of these schemes. Speciﬁcally, as the network adapts
to outages and load—possibly DoS-induced—the resulting
changes to paths will affect ﬁlters such as HCF and PI.
Another topic for future study is motivated by Fig-
ure 1(iii), which shows the variation over time with which
compromised computers entered this attack. A more pro-
nounced variation was recently employed by the My-
Doom viruses, each copy of which launched its DoS at-
tack (against a web server) according to the local time on
the computer on which it was residing. As such, comput-
ers in different time zones entered the attack at different
global times. Such a prolonged, staged entry of attack-
ers could pose challenges to learning algorithms.
The changes to routers that PI requires suggests another
topic of work, namely evaluating the relative performance
of this technique when only partially deployed. Our analy-
sis here utilized the assumption of total deployment.
Finally, we intend to systematically evaluate combina-
tions of ﬁlters that we have studied here. An example of
such a combination is described in [32].
Acknowledgements
We are deeply grateful to Abraham Yaar for useful tech-
nical discussions.
References
[1] M. Adler. Tradeoffs in probabilistic packet marking. In Pro-
ceedings of the 34th ACM Symposium on Theory of Comput-
ing, pages 407–418, May 2002.
[2] P. Barford and D. Plonka. Characteristics of network trafﬁc
ﬂow anomalies. In Proceedings of the 1st ACM SIGCOMM
Internet Measurement Workshop, November 2001.
[3] P. Barford, J. Kline, D. Plonka and A. Ron. A signal analy-
sis of network trafﬁc anomalies. In Proceedings of the 2nd
ACM SIGCOMM Internet Measurement Workshop, Novem-
ber 2002.
[4] S. M. Bellovin, M. Leech, and T. Taylor. ICMP trace-
back messages. Internet-draft: draft-ietf-itrace-01.txt, work
in progress, October 2001.
[5] R. C´aceres. Measurement of wide-area internet trafﬁc. Tech-
nical Report UCB/CSD 89/550, Computer Science Depart-
ment, University fo California, Berkeley, 1989.
[6] K. C. Claffy, H.-W. Braun and G. C. Polyzos. A parameter-
izable methodology for internet trafﬁc ﬂow proﬁling. IEEE
Journal on Selected Areas in Communications 13(8):1481–
1494, 1995.
[7] D. Dean, M. Franklin and A. Stubbleﬁeld. An algebraic ap-
proach to IP traceback. ACM Transactions on Information
and System Security 5(2):119–137, May 2002.
[8] S. Dietrich, N. Long, D. Dittrich. Analyzing Distributed De-
nial of Service Attack Tools: The Shaft Case. In Proceedings
14th Systems Administration Conference, LISA 2000.
[9] P. Ferguson and D. Senie. Network ingress ﬁltering: Defeat-
ing denial of service attacks which employ IP source address
spooﬁng. Request for Comments: 2267, the Internet Society,
January 1998.
[10] C. Hood and C. Ji. Proactive network fault detection. In Pro-
ceedings of IEEE INFOCOM ’97, April 1997.
[11] A. Hussain, J. Heidemann and C. Papadopoulos. A frame-
work for classifying denial of service attacks. In Proceedings
of the 2003 ACM Conference on Applications, Technologies,
Architectures, and Protocols for Computer Communications
(SIGCOMM), August 2003.
[12] J. Ioannidis and S. M. Bellovin. Implementing pushback:
Router-based defense against DDoS attacks. In Proceedings
of the 2002 ISOC Symposium on Network and Distributed
Security, February 2002.
[13] C. Jin, H. Wang and K. G. Shin. Hop-count ﬁltering: An ef-
fective defense against spoofed DDoS trafﬁc. In Proceedings
of the 10th ACM Conference on Computer and Communica-
tions Security, October 2003.
[14] J. Jung, B. Krishnamurthy and M. Rabinovich. Flash crowds
and denial of service attacks: Characterization and implica-
tions for CDNs and web sites. In Proceedings of the 11th In-
ternational World Wide Web Conference, May 2002.
[15] I. Katzela and M. Schwartz. Schemes for fault identiﬁca-
tion in communications networks. IEEE/ACM Transactions
on Networking 3(6):753–764, December 1995.
[16] B. Krishnamurthy and J. Wang. On network-aware cluster-
ing of web clients. In Proceedings of the 2000 ACM Confer-
ence on Applications, Technologies, Architectures, and Pro-
tocols for Computer Communications (SIGCOMM), August
2000.
[17] A. Mankin, D. Massey, C. L. Wu, S. F. Wu, and L. Zhang.
On design and evaluation of intention-driven ICMP trace-
back. In Proceedings of the 2001 IEEE International Con-
ference on Computer Communication and Networks, Octo-
ber 2001.
[18] J. Mirkovic, G. Prier and P. Reiher. Attacking DDoS at the
source. In Proceedings of the 10th IEEE International Con-
ference on Network Protocols, November 2002.
[23] C. Papadopoulos, R. Lindell, J. Mehringer, A. Hussain, and
R. Govindan. COSSACK: Coordinated suppression of si-
multaneous attacks. In Proceedings of the 3rd DARPA Infor-
mation Security Conference and Expo (DISCEX III), April
2003.
[24] S. Romig, M. Fullmer and S. Ramachandran. Cisco ﬂow
logs and intrusion detection at
the Ohio State Univer-
sity. ;login: – The Magazine of the USENIX Association,
September 1999. Available at http://www.usenix.
org/publications/login/1999-9/osu.html.
[25] S. Savage, D. Wetherall, A. Karlin and T. Anderson. Net-
work support for IP traceback. IEEE/ACM Transactions on
Networking 9(3), June 2001.
[26] A. C. Snoeren, C. Partridge, L. A. Sanchez, C. E. Jones,
F. Tchakountio, B. Schwartz, S. T. Kent, and W. T. Strayer.
Single-packet IP traceback. IEEE/ACM Transactions on Net-
working 10(6), December 2002.
[27] M. Sung and J. Xu. IP traceback-based intelligent packet
ﬁltering: A novel technique for defending against internet
DDoS attacks. In Proceedings of the 10th IEEE International
Conference on Network Protocols, November 2002.
[28] J. Toelle and O. Niggemann. Supporting intrusion detection
by graph clustering and graph drawing. In Proceedings of the
3rd International Workshop on Recent Advances in Intrusion
Detection, October 2000.
[29] A. Ward, P. Glynn and K. Richardson. Internet service per-
formance failure detection. Performance Evaluation Review,
August 1998.
[30] W. Willinger, M. Taqqu, R. Sherman, and D. Wilson. Self-
similarity through high-variability: Statistical analysis of
Ethernet LAN trafﬁc ant the source level. IEEE/ACM Trans-
actions on Networking 5(1):71–86, February 1997.
[31] A. Yaar, A. Perrig and D. Song. Pi: A path identiﬁcation
mechanism to defend against DDoS attacks. In Proceedings
of the 2003 IEEE Symposium on Security and Privacy, May
2003.
[32] A. Yaar, A. Perrig and D. Song. StackPi: A new defensive
mechanism against IP spooﬁng and DDoS attacks. Techni-
cal Report CMU-CS-02-208, Carnegie Mellon University,
February 2003.
[33] N. Ye. A markov chain model of temporal behavior for
anomaly detection. In Proceedings of the Workshop on In-
formation Assurance and Security, June 2000.
[19] J. Mirkovic and P. Reiher. A taxonomy of DDoS
defense mechanisms. Available
http://www.cs.ucla.edu/˜sunshine/
attack
at
publications/ccr.pdf.
and DDoS
[20] D. Moore, G. Voelker and S. Savage. Inferring inter-
net denial-of-service activity. In Proceedings of the 10th
USENIX Security Symposium, August 2001.
[21] V. Paxson. Fast, approximate synthesis of fractional gaus-
sian noise for generating self-similar network trafﬁc. Com-
puter Communications Review 27(5):5–18, October 1997.
[22] V. Paxson. Measurements and Analysis of End-to-End In-
ternet Dynamics. Ph.D. thesis, University of California–
Berkeley, 1997.
Proceedings of the 2004 IEEE Symposium on Security and Privacy (S&P’04)  
1081-6011/04 $ 20.00 © 2004 IEEE