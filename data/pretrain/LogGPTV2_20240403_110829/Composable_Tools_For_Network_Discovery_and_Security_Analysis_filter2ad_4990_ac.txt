Interface
Normalize
Ipsetup
Ipaddr: 111.222.3.4
Netmask: 255.255.255.0
CS
Ipsetup
Ipaddr: 222.111.127.1
Netmask: 255.255.0.0
Figure 5. Example of the complete set constraint.
table. Note that the Query Processor allows the NetDB to
be in a semi-inconsistent state, where more than one entity
instance may have the same unique attribute value. This
inconsistency is resolved during the normalization of the
database, when all instances that have the same unique at-
tribute value are merged.
The cardinality constraints on the relations in the net-
work model can also be used when resolving ghost entries.
Consider a relation that has a 1:N constraint.
If the data
stored in the NetDB actually implements an M:N relation,
then the Query Processor can infer that all the entity in-
stances on the left side of the relation are ghost entries. This
inconsistency can then be resolved by merging all instances
on the left side of the relation.
Another useful constraint is the “complete set” con-
straint. A relation instance is marked as a complete set if it
is known that no more entity instances can take part in that
relation. If other related entities exist, then they are ghost
entities and should be merged with the complete set. As an
example of the use of a complete set constraint, consider
the interface and ipsetup entities from the NetDB
schema of Figure 2. Figure 5 shows a graphical represen-
tation of an example input to the normalization algorithm
and the result. The dashed line between the two interface
elements symbolizes that the two interface instances shown
are the same. The “CS” next to two of the relations denotes
that the relation is a complete set. The normalization algo-
rithm detects that there exists one ipsetup instance that
is not part of the complete set. Because of the complete
set constraint, the ipsetup entity must be a ghost entry
of one of the ipsetups in the complete set. The net-
mask attribute of the ghost entry and the ﬁrst ipsetup in
the complete set differ. This means they cannot represent
the same object. The only possible solution is that the ghost
entry and the second ipsetup are the same and should be
merged. The result of the algorithm is shown in the right
side of Figure 5.
5.2. Network Security Analysis
After the NetDB database is populated with up-to-date
network information, a comprehensive security analysis can
be performed. The output of the analysis may either be a
report of the current state of the network or conﬁguration
data to be used with some security component, such as a
ﬁrewall or an intrusion detection system.
Currently, two prototype analyzers have been developed.
The ﬁrst, a ﬁrewall conﬁgurator, uses the client-server rela-
tionship expressed in the network model to create a list of
valid clients for each service. The list can be used by the
ﬁrewall to block unauthorized clients from accessing sensi-
tive services. Even if a malicious user were able to change
the access control list of the service itself, he would not be
able to gain any access, since the ﬁrewall would block any
connection attempt.
The second analyzer lists all the hosts in the network
with a given operating system that have a speciﬁc service
installed. This information is used when a network ad-
ministrator needs to decide which hosts are affected by a
new security vulnerability and need patching. Without a
database of all installed services in the network, this infor-
mation would have to be collected by some ad hoc scanning
tool. The construction of this tool would be time consum-
ing, and the results would likely be error-prone due to the
ad hoc nature of the tool.
6. Evaluation
NetMap’s functionality and performance have been
tested on both simulated and real networks. The real net-
works that have been scanned are subnets in the Computer
Science Department at UCSB. The tests on these real net-
works were performed to check whether NetMap is able to
map and analyze a network correctly. The tests also gave in-
formation about how long the discovery process takes. The
tests performed on the simulated network made it possible
to use more complicated network topologies.
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
query local1() {
result ipsetup*.(ipaddress,services*.(port,transport_prot));
assertion ipsetup.ipaddress:InIpRange(128.111.48.*);
}
query local2() {
result node*.(hostname,interfaces*.(mac,ipsetups*.(ipaddress,services*.(port,transport_prot))));
assertion ipsetup.ipaddress:InIpRange(128.111.48.*);
}
query department1() {
result node*.(hostname,interfaces*.(mac,ipsetups*.(ipaddress,services*.(port,transport_prot))));
assertion ipsetup.ipaddress:InIpRange(128.111.46-49.*);
}
query department2() {
result node*.(interfaces*.(ipsetups*.(netmask,ipaddress),link.network.netnumber));
assertion ipsetup.ipaddress:InIpRange(128.111.46-49.*);
}
Figure 6. Test queries used in the real network tests, expressed in NTL.
When using NetMap on the UCSB networks, the four
test queries shown in Figure 6 were used. Two queries were
run on the local class C network in the Reliable Software
Lab (RSL), and two queries were run on four subnets in
the Computer Science Department. The RSL network is
connected by a switch, and the other subnets used in the
tests have a similar topology. A router connects the different
subnets. For the performance test 26 hosts in the RSL were
used, and 22 hosts were used for the functionality tests.
6.1. Performance Test
The performance test focuses on how much time NetMap
requires for a given task and how much overhead NetMap
introduces. The test case is the “local1” query in Figure 6,
which is a query of all the open ports in the RSL. In Fig-
ure 7, we compare the time required for these different
methods. The ﬁrst run is performed by using a shell script to
perform a ping scan followed by a sequential port scan. The
other two runs are performed by NetMap. In the NetMap se-
quential run, the port scan is also performed sequentially for
all the input values. While in the parallel run, the number
of execution threads for port scan was set to 10.
The NetMap sequential run and the shell script run take
approximately the same time, which indicates that NetMap
imposes very little overhead on the processing. The timing
break down is discussed further in Section 6.2. The parallel
run reduces the total time from about four hours to about
half an hour, which is a factor of eight. All three runs ﬁnd
all the hosts in the network. The numbers of open ports,
however, are slightly different. This is because a port may
be opened or closed during the different test runs.
The reason that the scan took such a long time is that
most hosts in the RSL are running local ﬁrewalls, which
usually takes about 20 minutes per host to scan, while com-
puters without a ﬁrewall usually can be scanned within 10
seconds. The fact that most of the port scan time is waiting
for I/O is crucial for the parallel run. The data shows that
the CPU usage is under ﬁve percent, even in the case of ten
parallel port scans. For this reason, 15 threads were used
for port and OS scans in the functionality tests.
6.2. Functionality Test
The functionality test cases are shown in Figure 6. The
ﬁrst test is a query for all the open ports in the RSL. The
second query is for OS name, hostname, mac address, and
all open ports on the hosts in the RSL. The third query asks
for the same data from four subnets. The last query is for IP
address, netmask, and network from the same subnets.
The tools used in the test were:
Ping Finds hosts that are up by issuing an ICMP echo mes-
Imple-
sage and listening for an ICMP echo-reply.
mented using Nmap in ping scan mode.
NetARP Returns the ARP cache of a host given its IP ad-
dress.
Nslookup Does a reverse DNS lookup on an IP address.
Osdetect Performs OS ﬁngerprinting by sending various
packets to the host and matching the result against
a database of OS’s TCP/IP proﬁles. Implemented as
Nmap in OS detect mode.
Portscan Tries to connect to a range of ports on a given IP
address. Implemented as Nmap in port scan mode.
ICMP netmask Finds the netmask of an ipsetup by send-
ing an ICMP netmask request to the IP address.
Netﬁnd Takes the IP address and netmask of an ipsetup
as input and returns a network IP address. The net-
work IP address is the IP address ANDed with the net-
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
Testname
Shell Script
NetMap Sequential
NetMap Parallel
# of Host
26
26
26
# of open ports
167
162
174
Time
241:29
250:59
34:33
Figure 7. Performance testing of local network. Times are expressed in minutes and seconds.
mask. This tool does not do any active discovery. Im-
plemented as a shell script.
Figure 8 contains the tool schedule chosen for each
query, and the running time for each tool. The total col-
umn in the table shows the time it took to run the whole
query. The processing time is the total time minus the sum
of the tool times. This is the time NetMap uses to normalize
the data and insert it into the NetDB.
In both of the local tests all the collected data was cor-
rect. NetMap was also able to discover most of the attributes
queried. There were some problems detecting the OSs of
some of the hosts (i.e., 7 out of 22 hosts did not get an OS
mapping). The reason for this problem is that all the Linux
boxes in the RSL run local ﬁrewalls. This prevents the OS
discovery tool from ﬁngerprinting the hosts.
In the ﬁrst department scan, a higher percentage of the
OSs were ﬁngerprinted successfully compared to the local
scan (7 out of 78 did not get a mapping). These were the
same hosts as in the local test.
The second department scan was performed to determine
if NetMap is able to group the scanned hosts into subnets.
46 out of 77 hosts got their netmask attribute detected and
were successfully assigned to the correct network. The
hosts that failed the netmask detection were not assigned to
any network. However, these 31 hosts can be correctly as-
signed to the network by using the longest preﬁx match with
known network addresses. The second department scan was
not performed the same day as the ﬁrst one, which explains
the difference in the number of IP addresses.
By comparing the run times for the local and the ﬁrst
department scan one ﬁnds that the ping, NetARP, and
nslookup run times increase approximately linearly with the
number of hosts. The OS detect and port scan times do
not increase much at all, while NetMap processing time in-
creases considerably.
7. Conclusions and Future Work
This paper described the NetMap approach and the char-
acteristics of the implementation of the ﬁrst prototype. An
initial network model has been designed by analyzing ex-
isting models used by network management, discovery,
and analysis tools. A database-centered application, called
NetDB, has been implemented to store an inventory of net-
work objects conforming to the model, and two GUIs for
browsing the database have been developed.
The database is populated by using composable network
tools. The Network Tool Language has been deﬁned to de-
scribe the tools in an abstract way. A language to describe
network discovery tasks, called NetScript has also been de-
ﬁned. A prototype Query Processor component has been
implemented. The Query Processor takes a NetScript task
speciﬁcation as input and produces a schedule of tool execu-
tions that will produce the desired results. It then executes
each of the tools in the schedule and stores the result into
the NetDB. In addition, a preliminary set of algorithms to
deal with the reduction of inconsistent and/or redundant in-
formation has been designed and implemented. Tests have
been performed to show that the implementation is capable
of mapping network topology information, discover service
conﬁgurations, and perform security analysis. The tests also
showed that inconsistencies can be resolved.
In order to
perform the tests, a number of tools were integrated into
NetMap. The amount of work needed to do this was min-
imal, which supports the claim that NetMap can be easily
extended. Given more tools, it should be possible to map
every feature of the network that is interesting from a secu-
rity point of view.
Future work will focus on extending the current set of
tool descriptions, improving the reduction algorithms, and
using NetMap as the basis for intrusion detection. To be
more speciﬁc, we plan to validate the ﬂexibility of the Net-
work Tool Language by describing a wide range of tools.
By doing this the expressive power of the language as well
as the overall integration power of the approach will be thor-
oughly tested. We also plan to perform additional analy-
sis on the reduction algorithms that have been developed to
deal with inconsistent and duplicated information.
Finally, NetMap will be used to support a new approach
to detecting attacks, called the “status-based approach.” The
status-based approach identiﬁes attacks by analyzing the
differences between the intended network status as speciﬁed
by the model and the actual network status as detected by
the monitoring tools. This approach is similar to anomaly
detection approaches. A status-based IDS does not rely on
statistical models to represent the correct behavior of the
system; therefore, it does not need to be “trained” over a
long period of time. Furthermore, it can be used in highly
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
Testname
local1
local2
department1
Ping NetArp Nslookup Osdetect
:07
-
26:42
:06
:22
30:51
-
:07
:49
-
:17
:47
Portscan
25:21
25:20
25:48
Total
25:32
52:40
60:42
Processing
:04
:08
2:25
# IPs
22
22
82
Testname
department2
Ping
:19
icmp netmask
:34
netﬁnd
:38
Total
1:36
Processing
:05
# IPs
77
Figure 8. Results of the real world tests. Times are expressed in minutes and seconds.
[10] J. Postel.
Internet Control Message Protocol. RFC 792,
1981.
[11] J. Schonwalder and H. Langendorfer. Tcl Extensions for
In Proc. 3rd Tcl/Tk
Network Management Applications.
Workshop, Toronto (Canada), July 1995.
[12] D. Wood, S. Coleman, and M. Schwartz. Fremont, A Sys-
tem for Discovering Network Characteristics and Problems.
In Proceddings of the USENIX Conference, pages 335–348,
January 1993.
dynamic information systems where a well-deﬁned pattern
of usage cannot be determined.
Acknowledgments
This research was supported by the Army Research
Ofﬁce, under agreement DAAD19-01-1-0484 and by the
Defense Advanced Research Projects Agency (DARPA)
and Rome Laboratory, Air Force Materiel Command,
USAF, under agreement number F30602-97-1-0207. The
U.S. Government is authorized to reproduce and distribute
reprints for Governmental purposes notwithstanding any
copyright annotation thereon.
The views and conclusions contained herein are those
of the authors and should not be interpreted as necessar-
ily representing the ofﬁcial policies or endorsements, ei-
ther expressed or implied, of the Army Research Ofﬁce, the
Defense Advanced Research Projects Agency (DARPA),
Rome Laboratory, or the U.S. Government.
References
[1] Big brother system and network monitor homepage. http:
//bb4.com/, 2002.
[2] J. Case, K. McCloghrie, M. Rose, and S. Waldbusser. Proto-
col operations for version 2 of the simple network manage-
ment protocol (SNMPv2). Internet Engineering Task Force
(IETF), RFC 1905, January 1996.
[3] D. M. T. Force. Common Information Model (CIM) Core
Model. White Paper, August 2000. http://www.dmtf.
org.
[4] Fyodor. Nmap – the network mapper. http://www.
insecure.org/nmap/, 2002.
[5] O. Group. PROTOS Test-Suite: c06-snmpv1. http://
www.ee.oulu.fi/research/ouspg, February 2002.
[6] Hewlett Packard. Managing Your Network with HP Open-
View Network Node Manager, January 2000. Manufacturing
Part Number: J1240-90035.
[7] Internet Security Systems. Internet Scanner, 2002. http:
//www.iss.net/.
[8] Nessus homepage. http://nessus.org/, 2002.
[9] M. Newnham.
Getting Started with Tkined,
Jan-
http://wwwhome.cs.utwente.nl/
uary 1997.
˜schoenw/scotty/docs/getstart.html.
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE