attack reliably is to associate the temporal information with
the pointer and not with the object.
3) Pointer based approaches: Maintaining not only
bounds but also allocation information with pointers allows
enforcing full Memory Safety. Allocation information tells
if the pointed to object is still valid. It is not enough to just
keep an extra bit associated with each pointer indicating
the object’s validity, because all pointers pointing to it
have to be found and updated when the object is freed.
CETS [60] extends SoftBound and solves the problem by
eliminating the redundancy of the above described na¨ıve
idea. The validity bit is stored only at one place in a global
dictionary. Each new object gets a unique identiﬁer used as
the key to the dictionary and pointers are associated with
this unique ID. A special data structure for the dictionary
allows the quick and easy invalidation of objects and also
fast
lookups to check object validity. CETS is formally
proven to enforce temporal safety, if spatial safety is also
enforced. In other words, together with SoftBound, CETS
enforces Memory Safety. The average execution overhead
of the instrumentation enforcing temporal safety alone is
48%. When coupled with SoftBound to enforce complete
Memory Safety, the overhead is 116% on average on the
SPEC CPU benchmark. As a pointer based solution, CETS
suffers the same binary compatibility issues as SoftBound
when it comes to unprotected libraries.
VII. GENERIC ATTACK DEFENSES
Data Integrity and Data-ﬂow Integrity are weaker policies
than Memory Safety. They aim to protect against both control
data (hijacking) and non-control data attacks, but not against
e.g., information leaks. While the former policy prevents
data corruption, the latter detects it.
A. Data Integrity
Data Integrity solutions enforce an approximation of spa-
tial memory integrity. These techniques focus on the most
common attacks, which start by writing through an out of
bounds pointer. They do not enforce temporal safety, and
they only protect against invalid memory writes, not reads.
Furthermore,
integrity
enforced by the previously covered bounds checkers in order
to minimize the performance overhead. In all cases the
approximation is due to a static pointer analysis carried out
prior to the instrumentation.
they only approximate the spatial
1) Integrity of “safe” objects: The technique proposed
by Yong et al. [61] ﬁrst identiﬁes the subset of “unsafe
pointers”. A pointer is considered unsafe if it might go out
of bounds, e.g., because it is a computed value (p[i]). A
static pointer analysis identiﬁes the unsafe pointers together
with their points-to sets, i.e., their potential target objects.
Let us call the union of the identiﬁed points-to sets unsafe
objects. The code is instrumented to mark each byte of
an unsafe object in a shadow memory area at its creation
and clear it at deallocation. Checks are inserted before each
write dereference of an unsafe pointer to check whether the
location is marked in the shadow memory. This prevents the
corruption of any data in a memory area that does not belong
to an unsafe object.
This policy is sufﬁcient
to protect not only variables
which are never accessed through pointers, but, for instance,
saved return addresses as well. However, sensitive variables
can still be identiﬁed as unsafe objects and thus remain
unprotected. The authors also mention that out of 101
function pointers in their benchmark suite, two ended up
in the set of unsafe objects, which means that in case of a
memory error, these values can be corrupted. Since reads are
left unchecked, any value can be corrupted when read into
a register via a bad pointer. This allows certain control-ﬂow
hijack attacks, program speciﬁc attacks, and information leak
attacks as well.
The reported runtime overhead of Yong’s system varies
between 50-100% on the SPEC 2000 benchmark. Uninstru-
mented libraries raise compatibility issues. If a pointer is
dereferenced in the transformed module, accessing an object
created by an unprotected module, then a false alarm is
triggered. This problem can be mitigated in case of heap
objects by wrapping memory allocating functions to mark
every allocated area in the shadow memory.
5757
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:16 UTC from IEEE Xplore.  Restrictions apply. 
2) Integrity of points-to sets: The previous technique
restricts pointer dereferences to write only unsafe object.
Write Integrity Testing (WIT) [62] further strengthens the
above policy by restricting each pointer dereference to write
only objects in its own points-to set. Naturally, the pointer
analysis only results in a conservative approximation of the
set of objects a pointer may point to. The calculated distinct
points-to sets are associated with different ID numbers,
which are used to mark the objects in the shadow memory
area. While Yong’s approach only uses two IDs: 1 for
unsafe objects and 0 for everything else, WIT marks objects
belonging to separate points-to sets with different IDs.
Furthermore, WIT checks indirect calls as well to stop
hijacking attacks, which the previous policy left possible.
It protects indirect calls by calculating the points-to set
of pointers used by indirect call instructions and associate
them with IDs as well. The IDs are placed in the shadow
memory for valid code target addresses and, as in case
of indirect writes, before each indirect call
the IDs are
checked. Functions associated with the same ID are still
interchangeable.
The policy enforced by WIT is stronger than Yong’s
approach due to distinguishing different points-to sets, but
objects assigned to the same ID remain vulnerable. Since
WIT does not protect reads, data can be corrupted when
read into a register, and information leaks are possible as
well. Due to the missing read checks function pointers
can be corrupted, too. This is why WIT checks indirect
calls instead in order to detect the corruption. Checking the
target of indirect control transfers makes WIT a Control-
ﬂow Integrity approach, which is covered in Section VIII-B.
Notice that while calls are checked, returns are not. This is
because returns can only be corrupted via writes, as they
are never read by dereferencing a pointer, and thus they are
considered protected. Since WIT does not deal with temporal
errors either, overwriting a return address via an escaped
dangling pointer is still possible, however such bugs are rare
in practice.
The reported performance overhead of WIT is around 5-
25% for the SPEC benchmark. The approach is not binary
compatible. Using uninstrumented libraries can create false
alarms, because they do not maintain the object IDs at
allocations. Like in case of DSR, or other solutions dealing
with distinct points-to sets, modularity is also an issue, since
the resulting IDs depend on the global points-to graph. While
WIT works at compile time, BinArmor [63] aims to enforce
a similar policy with binary rewriting. Since the pointer
analysis the policy requires is infeasible to do in binaries,
the system tries to identify potentially unsafe dereferences
and their valid targets dynamically, by running and tracing
the program with various inputs. This approach can neither
guarantee the lack of false negatives, nor false positives, and
its performance overhead can go up to 180%.
B. Data-ﬂow Integrity
Data-Flow Integrity (DFI) as proposed by Castro et
al. [64] detects the corruption of any data before it gets used
by checking read instructions. DFI restricts reads based on
the last instruction that wrote the read location. In program
analysis terms, DFI enforces the reaching deﬁnition sets.
The reaching deﬁnition set of an instruction is the set of
instructions which might have last written (deﬁned) the
value that is used by the given instruction based on the
control-ﬂow graph. For instance, the policy ensures that the
isAdmin variable was last written by the write instruction
that the source code deﬁnes and not by some rogue attacker-
controlled write. Or it ensures that the return address used by
a return was last written by the corresponding call instruc-
tion. DFI also builds on static points-to analysis in order
to compute the global reaching deﬁnition sets. Similarly to
WIT, the resulting reaching deﬁnition sets are assigned a
unique ID. Each written memory location is marked in the
shadow memory with the writing instruction’s ID. Before
each read, this ID is checked whether it is the element of
the statically computed set of allowed IDs.
The previously discussed solutions checked every indirect
memory write, so the shadow memory area was automat-
ically protected. Contrarily, the Data-ﬂow Integrity policy
dictates the instrumentation of only reads. Unfortunately, in
order to protect the integrity of its metadata, DFI has to
check all indirect writes as well, and make sure that their
target addresses are outside of the shadow memory area.
The performance overhead of the technique varies be-
tween 50-100% on the SPEC 2000 benchmark. Similarly
to previous solutions, it is not binary compatible, since false
alarms can be caused by the lack of metadata maintenance
in unprotected libraries.
VIII. CONTROL-FLOW HIJACK DEFENSES
The following two policies focus only on hijacking at-
tacks. While the Code Pointer Integrity aims to prevent the
corruption of code pointers, Control-ﬂow Integrity detects it.
A. Code Pointer Integrity
While the integrity of some code pointers can and should
be protected, enforcing Code Pointer Integrity alone is
infeasible. Immutable code pointers, such as the ones in the
Global Offset Table or in virtual function tables (vtable), can
be easily protected by keeping them in read-only memory
pages. Most code pointers however, such as programmer
deﬁned function pointers or saved return addresses, must
remain writable. Furthermore, even if the integrity of all
code pointers in memory could be enforced, the hijacking
attack would still be possible, by exploiting an erroneous
indirect memory read to load the wrong value into the
register. Most use-after-free exploits, for instance, divert
the control-ﬂow by reading the “wrong” virtual function
table through a dangling pointer, which does not involve
5858
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:16 UTC from IEEE Xplore.  Restrictions apply. 
overwriting code pointers in memory at all. It follows from
this discussion that detecting a code pointer corruption
before its usage would be better.
B. Control-ﬂow Integrity
Control-ﬂow Integrity (CFI) solutions enforce some policy
regarding indirect control transfers, mitigating the hijacking
attack in Step 5. Note that direct control transfers cannot be
diverted, and hence they need no protection.
1) Dynamic return integrity: The most well known
control-ﬂow hijacking attack is the “stack smashing” at-
tack [65]. Stack smashing exploits a buffer overﬂow in
a local variable to overwrite the return address on the
stack. Stack cookies or canaries [66] are the ﬁrst proposed
solution against this attack. A secret value (cookie/canary)
is placed between the return address and the local variables.
If the return address is overwritten by a buffer overﬂow,
the cookie changes as well, what is detected by the check
placed before the return instruction. Stack cookies do not
protect indirect calls and jumps, and they are vulnerable
to direct overwrite attacks and information leaks. However,
stack cookies are popular and widely deployed, because the
performance overhead is negligible (less than 1%) and no
compatibility issues are introduced.
Shadow stacks [67] can solve some of the problems of
canaries, like information leaks and direct overwrites. To
eliminate the reliance on a secret, the saved return addresses
are pushed to a separate shadow stack as well, so upon
function return, the shadow copy can be compared with
the original return address. Simply making a copy and
checking if it still matches before the return makes the
attack much harder, even when the shadow stack is not
protected, since the attacker has to corrupt the return address
in two separate locations. To protect the shadow stack itself,
RAD [68] proposes the use of guard pages or switching
write permission to protect the shadow stack area. While
the former does not protect against direct overwrites, the
latter causes 10x slowdown. To estimate the performance
overhead of an unprotected shadow stack mechanism, we
implemented one as an LLVM plugin, which has an average
overhead of 5% on the SPEC2006 benchmark. Shadow
stack mechanisms also has to deal with compatibility issues,
e.g., to handle exceptions. However, we believe that false
positives can be avoided by a careful implementation.
2) Static control-ﬂow graph integrity: To prevent all
control-ﬂow hijacks, not only returns, but indirect calls and
jumps have to be protected as well. Section VII covers
how WIT identiﬁes and enforces the set of valid targets
(i.e., the points-to set) of each call instruction. This idea,
together with the term Control-ﬂow Integrity was originally
introduced by Abadi et al. [69]. Their work focuses on
statically determining the valid targets of not only calls, but
also function returns, and thus enforcing the resulting static
control-ﬂow graph. Unlike WIT, which stores the IDs in a
protected shadow memory, the CFI authors propose storing
them inside the code itself, by placing the ID right to the
target location, so it can be protected by Code Integrity.
To avoid compatibility issues, the IDs can be encoded into
instructions, which, if inserted, will not affect the semantics
of the code. Calls and returns are instrumented to check the
target address whether it has the right ID before jumping
there. Note, that this requires Non-executable Data as well,
to prevent forging valid targets.
As for returns, enforcing any statically predetermined
set of valid targets is a weaker policy than enforcing the
dynamic call stack enforced by a shadow stack. At run-time,
there is always exactly one correct target of a function return,
but since a function can be called from multiple call sites,
the statically determined set will include all of them as valid
targets.
Another issue with enforcing the unique points-to sets
of indirect control transfers is modularity support, as in
the case of all previously covered pointer analysis based
solutions. The precise points-to sets can only be determined
globally, which makes modularity and dynamic library reuse
challenging. This the main reason why this solution works
great with monolithic kernels [70] or hypervisors [71], where
every module is statically linked together, but has not been
deployed for dynamically linked applications. A weaker, but
more practical policy is restricting indirect control transfers
to the union of all their points-to sets (cf. Yong et al. in
Section VII-A). The original CFI implementation also uses
this approach, meaning that all indirectly callable function
is marked by the same ID. The advantage of this policy is
that it does not even need pointer analysis, because it is
enough to enumerate all functions whose address is taken.
This is a much more conservative policy, but it allows the
modular transformation and interchanging of libraries. For
many functions, this policy means that the allowed set of
return targets has to include all call sites in a program.
Since this is overly permissive, the authors suggest using
a shadows stack mechanism instead for checking returns.
The average performance overhead of the Abadi imple-
mentation is 15%, while the maximum measured is as high
as 45%. The implementation which uses a shadow stack
mechanisms for returns has an additional 10% overhead.
This solution is not binary compatible either, and since it
relies on the W⊕X policy, it can not be enforced in case of
JIT compilation.
IX. DISCUSSION
We summarize the properties of a selected set of solutions
in Table II, grouped by the policy categories identiﬁed
in Section II, except the following two: (i) Code Pointer
Integrity, because enforcing it
is infeasible without any
level of Memory Safety; (ii) Instruction Set Randomization,
because the same attack vectors can be defeated with page
permission enforcing Code Integrity and Non-executable
5959
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:16 UTC from IEEE Xplore.  Restrictions apply. 
.
t
o
r
p
c
i
r
e
n
e
G
.
t
o
r
p
k
c
a
j
i
H
-
F
C
Policy type (main approach)
Memory Safety
Data Integrity
Data Space Randomization
Data-ﬂow Integrity
Code Integrity
Non-executable Data
Address Space Randomization ASLR
Control-ﬂow Integrity
Technique
SofBound + CETS
SoftBound
Baggy Bounds Checking
WIT
DSR
DFI
Page permissions (R)
Page permissions (X)