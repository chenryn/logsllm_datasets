ci,t =(cid:98)xi,t + ρi,t.
AggrDec. At time t ∈ N, the aggregator receives
c1,t, . . . , cn,t. The aggregator may obtain the plain-
text simply by summing up these ciphertexts and its
capability ρ0,t.
V ← ρ0,t +
n(cid:88)
(cid:80)
(cid:98)xi as the desired sum.
i=1
n
(cid:80)
Since
t
i=1
ci,t.
i=0 ρi,t = 0, the aggregator obtains V =
(cid:80)
The question is how participants and the aggregator
can obtain random shares of 0 without having to interact
with each other in every time period. Our scheme relies
on a trusted setup phase during which each participant
obtains a secret key ski where i ∈ [n], and the aggrega-
i=0 ski = 0.
tor obtains a capability sk0. Moreover,
Let H denote a hash function (modeled as a random or-
acle) that maps an integer to an appropriate mathemati-
cal group. In every time period t, each participant com-
putes Ri,t = H(t)ski for i ∈ [n], and the aggregator
computes R0,t = H(t)sk0. Since the ski sum to zero,
i=0 Ri,t = 1. We leverage this property to construct
a scheme in which the participants never have to com-
municate with each other after the trusted setup phase.
(cid:81)
n
n
Furthermore, if Decisional Difﬁe-Hellman is hard in the
mathematical group in question, we prove that the num-
bers Ri,t are “seemingly” random under the random or-
acle model.
5.2 Basic Construction
Let G denote a cyclic group of prime order p for
which Decisional Difﬁe-Hellman is hard. Let H : Z →
G denote a hash function modelled as a random oracle.
Setup(1λ).
A trusted dealer chooses a random
generator g ∈ G, and n + 1 random secrets
s0, s1, . . . , sn ∈ Zp such that s0 + s1 + s2 + . . . +
sn = 0. The public parameters param := g. The
data aggregator obtains the capability sk0 := s0,
and participant i obtains the secret key ski := si.
NoisyEnc(param, ski, t,(cid:98)x). For participant i to encrypt
a value(cid:98)x ∈ Zp for time step t, she computes the
following ciphertext:
c ← gbx · H(t)ski
to her data before encryption, we use the term(cid:98)x :=
Becuase we assume that each participant adds noise
x + r mod p to denote the randomized plaintext.
AggrDec(param, sk0, t, c1, c2, . . . , cn). Compute
n(cid:89)
V ← H(t)sk0
ci.
Suppose ci = NoisyEnc(param, sk0, t,(cid:98)xi) for i ∈
i=1
[n]. It is not hard to see that V is of the form
V = g
(cid:80)
Pn
i=1bxi.
(cid:98)xi, it sufﬁces to com-
n
i=1
To decrypt the sum
pute the discrete log of V base g. When the plain-
text space is small, decryption can be achieved
through a brute-force search. A better approach
is to use Pollard’s lambda method [12] which re-
quires decryption time roughly square root in the
plaintext space. For example, suppose each partic-
ipant’s input is in the range {0, 1, . . . , ∆}. Then
the sum of the participants fall within the range
{0, 1, . . . , n∆}. In this case, decryption would re-
n∆ time using Pollard’s method. In other
quire
words, we require that n∆ is polynomial in the
security parameter λ to ensure successful decryp-
tion in polynomial time. Note that the limitation
of small plaintext space is in fact typical of Difﬁe-
Hellman-based encryption schemes when used as
additively homomorphic encryption schemes, e.g,
√
El Gamal encryption and the BGN homomorphic
encryption scheme [2].
6 Achieving Distributed Differential Pri-
vacy
The careful reader may now question how each par-
ticipant picks noise to add to her data. In Section 6,
we show that it is possible to pick an appropriate
distribution of noise that guarantees differential pri-
vacy and meanwhile ensures the ability to decrypt
with high probability.
Theorem 1. Assuming that
the Decisional Difﬁe-
Hellman problem is hard in the group G and that the
hash function H is a random oracle, then the above con-
struction satisﬁes aggregator oblivious security in the
“encrypt-once” model.
We present the proof of Theorem 1 in Appendix A.
Practical performance.
In the proposed crypto-
graphic construction, encryption consists of a hash oper-
ation (e.g., SHA-256), two modular exponentiations and
one multiplication in a Difﬁe-Hellman group. The run-
ning time is dominated by the two modular exponentia-
tions, as the time for computing the hash function and
group multiplication are much smaller in comparison
with the time for an expenentiation. According to bench-
marking numbers reported by the eBACS project [1],
on a modern 64-bit desktop PC, it takes roughly 3 ms
to compute a modular exponentiation using a classic
Difﬁe-Hellman group modular a 1024-bit prime. Us-
ing high-speed elliptic curves such as “curve25519”,
it takes only 0.3 ms to compute a modular exponen-
tiation. Therefore, encryption can be done in roughly
0.6 ms on a modern computer. Decryption of the aggre-
gate statistics requires taking a discrete log, and if one
uses the brute-force method, it takes one modular expo-
nentiation, that is 0.3 ms to try each possible plaintext.
Therefore, our scheme is practical in situations where
the plaintext space is small. For example, in the appli-
cation described by Rieffel et al. [17], each participant’s
plaintext is a bit indicating her availability for commu-
nication. In this case, with roughly 1000 participants,
decryption can be done in about 0.3 s using the brute-
force approach. We can have a further speed-up if we
adopt Pollard’s lambda method for decryption, reducing
n∆, where n is the number
the running time to about
of participants, and assuming each participant’s value
comes from {0, 1, . . . , ∆}.
√
6.1
Inituition
The cryptographic construction of Section 5 ensures
that the aggregator learns nothing other than what it al-
ready knows and the noisy statistic revealed during each
time period. Therefore, the aggregator has no direct ac-
cess to each individual’s data.
Individual privacy can
be violated indirectly, however, as the revealed statistic
may enable deductions about an individual’s data.
In
this section, we show how to build a guarantee of (, δ)-
differential privacy into the cryptographic construction.
In previous differential privacy literature, a trusted
aggregator is responsible for releasing statistics. The
trusted aggregator has access to all data, and is charged
with meeting privacy guarantees when releasing data. A
standard procedure for ensuring differential privacy is
for the aggregator to add an appropriate magnitude of
noise before publishing the desired statistic.
In our case, the participants do not trust the aggrega-
tor. Therefore, we cannot reveal the true statistic to the
aggregator. Instead, we must add noise before the aggre-
gator is able to decrypt the statistic. Our approach is to
let the participants be responsible for ensuring the differ-
ential privacy of their own data. Each participant would
add noise to their data before encrypting them. We need
to address the following two challenges when designing
a differentially private mechanism:
• Compromised participants. To ensure the differ-
ential privacy for participating individuals, the re-
vealed statistic must contain random noise r of an
appropriate magnitude. One naive solution is to
rely on a single participant to add an appropriate
magnitude of noise r to her data before submission.
However, this solution is problematic, because this
designated user knows the noise and hence can de-
duce from the output the true aggregated value. In
real-world settings, participants may not trust each
other. In particular, a subset of the participants may
be compromised and collude with the data aggrega-
tor. In the worst case, if every participant believes
that the other n − 1 participants may be compro-
mised and collude with the aggregator, each partic-
ipant would need to add sufﬁcient noise to ensure
the privacy of her own data. The resulting statistic
would accumulate a big error.
If at least γ fraction of the participants are honest
and not compromised, then we can distribute the
noise generation task amongst these participants.
Each participant may add less noise, and as long
as the noise in the ﬁnal statistic is large enough, in-
dividual privacy is protected. Our scheme assumes
that the participants have an apriori estimate on the
lower bound for γ. However, they need not know
exactly which participants are compromised. Each
participant is supposed to generate noise from a dis-
tribution that depends on γ. Honest participants
will follow this protocol, but the compromised par-
ticipants may reveal their noise to the data aggre-
gator or choose not to add noise. Our construction
guarantees that, with high probability, the revealed
statistic will accumulate sufﬁcient noise from the
honest participants, while keeping the error of the
ﬁnal statistic small.
• Algebraic constraints. Another challenge is to
work within the algebraic constraints induced by
the cryptographic construction. Most encryption
schemes require that the plaintext be picked from
a group comprised of discrete elements. Therefore,
we need to be able to encode our data and noise
values in a discrete group. Moreover, the crypto-
graphic construction proposed in Section 5 imposes
one more constraint, that the plaintext space must
be small. To work with discrete groups, we choose
to use a symmetric geometric distribution instead
of the more commonly used Laplace distribution.
The symmetric geometric distribution is un-
bounded, so it may overﬂow the size of the group,
or the size of the plaintext space. Our construction
ensures that the probability of an overﬂow is small,
so that the aggregator can successfully decrypt the
noisy statistics with high probability.
Next, we introduce some preliminaries on differential
privacy, and then detail our construction.
6.2 Differential Privacy Preliminaries
The differential privacy literature commonly adds
noise sampled from a Laplace distribution to the true
output to ensure individual privacy. However, as pointed
out earlier, because the encryption scheme uses discrete
groups, we need a discrete distribution instead. We
use symmetric geometric distribution, which can be re-
garded as a discrete approximation to the Laplace distri-
bution. The use of geometric distribution for the noise
was pioneered by Ghosh et al. [9]. We now provide
some background on the geometric distribution.
Deﬁnition 4 (Geometric Distribution). Let α > 1. We
denote by Geom(α) the symmetric geometric distribu-
tion that takes integer values such that the probability
mass function at k is α−1
α+1 · α−|k|.
We denote by Geom+(α) the one-sided geometric
distribution that takes positive integer values such that
the probability mass function at k is (α − 1)α−k.
The symmetric geometric distribution Geom(α) can
be viewed as a discrete version of the Laplace distri-
bution Lap(b) (where α ≈ exp( 1
b )), whose probabil-
ity density function is x (cid:55)→ 1
b ). The follow-
ing property of Geom distribution is useful for design-
ing differentially private mechanisms that output integer
values.
2b exp(−|x|
Fact 1. Let  > 0. Suppose u and v are two integers
such that |u − v| ≤ ∆. Let r be a random variable hav-
∆)). Then, for any integer
ing distribution Geom(exp( 
k, P r[u + r = k] ≤ exp() · P r[v + r = k].
Fact 1 suggests that if the targeted statistic f(x) has
sensitivity ∆, then adding geometric noise with magni-
tude proportional to ∆ is sufﬁcient to achieve differen-
tial privacy. As mentioned before, participants do not
trust the aggregator or each other. As a result, we can-
not entrust the aggregator with the task of noise gener-
ation, since revealing the true statistic to the aggregator
clearly violates differential privacy. Neither can we en-
trust any single participant with this task, since other-
wise, this designated participant would be able to learn
true statistic as well.
6.3 Achieving DD-Privacy for Summation
(cid:80)
n
domization function χ(xi, ri) := xi + ri mod p.
Let x = (x1, . . . , xn) ∈ Dn and r = (r1, . . . rn) ∈
Ωn represent the data and noise values respectively from
all participants in a certain time period. Here we have
D = O = Zp, the cyclic group equipped with ad-
dition modulo p, and Ω = Z. We consider the ag-
gregating function sum : Dn → O, with sum(x) =
i=1 xi mod p. Each participant uses the same ran-
For any two elements u, v ∈ Zp, we deﬁne |u − v|
to be the smallest non-negative integer s such that u =
v + s mod p or v = u + s mod p. Moreover, when
we add an integer to an element in Zp, we assume that
addition is performed modulo p.
We assume that each participant’s original data falls
within the domain {0, 1, . . . , ∆}, and hence the sensitiv-
ity of sum is ∆ with respect to one participant’s change.
In other words, if a single participant changes her data,
the sum changes by at most ∆. Recall from Fact 1 that if
∆)) noise is incorporated into the output,
a Geom(exp( 
then -differential privacy is achieved. In our case, the
participants jointly generate the noise in the ﬁnal output.
Our goal is to ensure that if at least γn participants are
honest and uncompromised, we will accumulate noise of
a similar magnitude. In this way, we not only guarantee
Algorithm 1: DD-Private Data Randomization Procedure.
Let α := exp( 
∆) and β := 1
Let x = (x1, . . . xn) denote all participants’ data in a certain time period.
foreach participant i ∈ [n] do
γn log 1
δ .
Sample noise ri according to the following distribution.
(cid:40)
Randomize data by computing(cid:98)xi ← xi + ri mod p.
ri ←
Geom(α) with probability β
0
with probability 1 − β
1
(cid:113)
differential privacy, but also ensure that the accumulated
noise is bounded in the ﬁnal output so that the error is
small.
Informally, our mechanism guarantees (, δ)-DD-
privacy, and meanwhile ensures small error of roughly
γ ) magnitude. As long as a constant fraction
O( ∆

γ of participants are honest, the error term is indepen-
dent of n, the number of participants. In fact, our re-
sult is nearly optimal, since an accumulated noise of
magnitude Θ( ∆
 ) is necessary to ensure differential pri-
vacy. Furthermore, consider the extreme case when
γ = O( 1
n), i.e., each participant believes that all other
participants may be compromised, or only a constant
number of them are honest. Then, our accumulated
noise would be O( ∆
n). This agrees

with our intuition as well, since each participant must
add a symmetric noise of magnitude Θ( ∆
 ) in this case
to ensure her privacy. It is not hard to show that the sum
of n independent symmetric noises of magnitude Θ( ∆
 )
results in a ﬁnal noise of magnitude O( ∆
n) with high

probability.
γ ) = O( ∆
(cid:113)
√
√
1

Below, we ﬁrst state the main theorem of this section,
and then describe our construction.
n log 1
Theorem 2 (DD-Private Procedure with Low Error).
Let  > 0 and 0 < δ < 1. Suppose each partic-
ipant’s data comes from integers inside an interval of
width ∆ in Zp, where ∆ ≥ 
3 . Suppose at least γ frac-
tion of the n participants are uncompromised such that
γ ≥ 1