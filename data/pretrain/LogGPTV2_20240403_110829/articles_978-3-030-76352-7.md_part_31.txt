once a week or a month and it can be done offline as well.
4.3 Q3. Parameter Sensitivity
Precog requires tuning of certain hyper-parameters like R2 score, and critical
time,whichcurrentlyaresetmanuallybasedontheexpertsknowledge.Figure5
comparesperformancefordifferentparametervalues,onsyntheticallygenerated
dataset.Ouralgorithmperformconsistentlywellacrossvalues.Settingminimum
R2 score above 0.8 corresponds to stricter fitting of the line and that is why the
accuracy drops. On the other hand, our data mostly contains trend lines which
would reach threshold withing 3 to 4 days, therefore setting minimum critical
timetooless(lessthan3days)wouldmeanthetrendlineneverreachingthresh-
oldwithinthetimeframeandhencedecreasingtheaccuracy.Theseexperiments
showsthat theseparametersdoesplayaroleintheoverall accuracyofthealgo-
rithm but at most of the values algorithm is insensitive to them. Furthermore,
198 A. Jindal et al.
(a) Training Time (b) Prediction Time
Fig.4. Precog’s prediction method scale linearly.
Fig.5. Insensitive to parameters: Precog performs consistently across parameter val-
ues.
to determine these automatically based on the historic data is under progress
and is out of the scope of this paper.
5 Conclusion
Memory leak detection has been a research topic for more than a decade. Many
approacheshavebeenproposedtodetectmemoryleaks,withmostofthemlook-
ingattheinternalsoftheapplicationortheobject’sallocationanddeallocation.
ThePrecogalgorithmformemoryleakdetectionpresentedinthecurrentworkis
mostrelevantforthecloud-basedinfrastructurewherecloudadministrator does
not have access to the source code or know about the internals of the deployed
applications. The performance evaluation results showed that the Precog is able
to achieve aF1-Scoreof 0.85 with lessthan half asecondprediction time on the
real workloads. This algorithm can also be useful in the Serverless Computing
where if a function is leaking a memory then its successive function invocations
will add on to that and resulting in a bigger memory leak on the underneath
system. Precog running on the underneath system can detect such a case.
Prospective directions of future work include developing online learning-
basedapproachesfordetectionandaswellusingothermetricslikeCPU,network
andstorageutilization forfurtherenhancingtheaccuracyofthealgorithms and
providing higher confidence in the detection results.
Online Memory Leak Detection in the Cloud-Based Infrastructures 199
Acknowledgements. ThisworkwassupportedbythefundingoftheGermanFederal
Ministry of Education and Research (BMBF) in the scope of the Software Campus
program.Theauthorsalsothanktheanonymousreviewerswhosecommentshelpedin
improving this paper.
References
1. Ataallah,S.M.A.,Nassar,S.M.,Hemayed,E.E.:Faulttoleranceincloudcomputing
-survey.In:201511thInternationalComputerEngineeringConference(ICENCO),
pp. 241–245, December 2015. https://doi.org/10.1109/ICENCO.2015.7416355
2. Chen, K., Chen, J.: Aspect-based instrumentation for locating memory leaks in
javaprograms.In:31stAnnualInternationalComputerSoftwareandApplications
Conference (COMPSAC 2007), vol. 2, pp. 23–28, July 2007). https://doi.org/10.
1109/COMPSAC.2007.79
3. Clause, J., Orso, A.: LeakPoint: pinpointing the causes of memory leaks. In: 2010
ACM/IEEE 32nd International Conference on Software Engineering, vol. 1, pp.
515–524, May 2010. https://doi.org/10.1145/1806799.1806874
4. Gokhroo, M.K., Govil, M.C., Pilli, E.S.: Detecting and mitigating faults in cloud
computing environment. In: 2017 3rd International Conference on Computational
IntelligenceCommunicationTechnology(CICT),pp.1–9,February2017.https://
doi.org/10.1109/CIACT.2017.7977362
5. Jain, N., Choudhary, S.: Overview of virtualization in cloud computing. In: 2016
Symposium on Colossal Data Analysis and Networking (CDAN), pp. 1–4, March
2016. https://doi.org/10.1109/CDAN.2016.7570950
6. Jump, M., McKinley, K.S.: Cork: dynamic memory leak detection for garbage-
collectedlanguages.In:Proceedingsofthe34thAnnualACMSIGPLAN-SIGACT
SymposiumonPrinciplesofProgrammingLanguages,POPL2007,NewYork,NY,
USA, pp. 31–38. ACM (2007). https://doi.org/10.1145/1190216.1190224. http://
doi.acm.org/10.1145/1190216.1190224
7. Mitchell,N.,Sevitsky,G.:LeakBot:anautomatedandlightweighttoolfordiagnos-
ing memory leaks in large java applications. In: Cardelli, L. (ed.) ECOOP 2003.
LNCS, vol. 2743, pp. 351–377. Springer, Heidelberg (2003). https://doi.org/10.
1007/978-3-540-45070-2 16
8. Pooja, Pandey, A.: Impact of memory intensive applications on performance of
cloud virtual machine. In: 2014 Recent Advances in Engineering and Computa-
tional Sciences (RAECS), pp. 1–6, March 2014. https://doi.org/10.1109/RAECS.
2014.6799629
9. Rudafshani,M.,Ward,P.A.S.:Leakspot:detectionanddiagnosisofmemoryleaks
in javascript applications. Softw. Pract. Exper. 47(1), 97–123 (2017). https://doi.
org/10.1002/spe.2406
10. Sor,V.,Srirama,S.N.:Astatisticalapproachforidentifyingmemoryleaksincloud
applications. In: CLOSER (2011)
11. Sor,V.,Srirama,S.N.:Memoryleakdetectioninjava:taxonomyandclassification
of approaches. J. Syst. Softw. 96, 139–151 (2014)
12. Sor, V., Srirama, S.N., Salnikov-Tarnovski, N.: Memory leak detection in plumbr.
Softw. Pract. Exper. 45, 1307–1330 (2015)
200 A. Jindal et al.
13. Vilk,J.,Berger,E.D.:Bleak:automaticallydebuggingmemoryleaksinwebappli-
cations.In:Proceedingsofthe39thACMSIGPLANConferenceonProgramming
Language Design and Implementation, PLDI 2018, New York, NY, USA, pp. 15–
29. ACM (2018). https://doi.org/10.1145/3192366.3192376. http://doi.acm.org/
10.1145/3192366.3192376
14. Xie, Y., Aiken, A.: Context- and path-sensitive memory leak detection. SIG-
SOFTSoftw.Eng.Notes30(5),115–125(2005).https://doi.org/10.1145/1095430.
1081728. http://doi.acm.org/10.1145/1095430.1081728
Multi-source Anomaly Detection
in Distributed IT Systems
B
Jasmin Bogatinovski( ) and Sasho Nedelkoski
Distributed Operating Systems, TU Berlin, Berlin, Germany
{jasmin.bogatinovski,nedelkoski}@tu-berlin.de
Abstract. Themulti-sourcedatageneratedbydistributedsystems,pro-
videaholisticdescriptionofthesystem.Harnessingthejointdistribution
of the different modalities by a learning model can be beneficial for crit-
ical applications for maintenance of the distributed systems. One such
importanttaskisthetaskofanomalydetectionwhereweareinterested
indetectingthedeviationofthecurrentbehaviourofthesystemfromthe
theoretically expected. In this work, we utilize the joint representation
from the distributed traces and system log data for the task of anomaly
detection in distributed systems. We demonstrate that the joint utiliza-
tion of traces and logs produced better results compared to the single
modalityanomalydetectionmethods.Furthermore,weformalizealearn-
ingtask-nexttemplatepredictionNTP,thatisusedasageneralization
for anomaly detection for both logs and distributed trace. Finally, we
demonstrate that this formalization allows for the learning of template
embedding for both the traces and logs. The joint embeddings can be
reused in other applications as good initialization for spans and logs.
· · ·
Keywords: Multi-source anomaly detection Multi-modal Logs
Distributed traces
1 Introduction
The complexity of the multi-layered IT infrastructures such as the Internet of
Things, distributed processing frameworks, databases and operating systems, is
constantlyincreasing[10].Tomeettheconsumers’expectationsoffluentservice
with low response times guarantees and availability, the service providers highly
relyonthehighvolumesofmonitoringdata.Themassivevolumesofdataleadto
maintenance overhead for the operators and require introducing of data-driven
tools to process the data.
Acrucialtaskforsuchtoolsistocorrectlyidentifythesymptomsofdeviation
ofthecurrentbehavioursystemfromtheexpectedone.Duetothelargevolumesof
data,theanomalydetectorshouldproduceasmallnumberoffalse-positivealarms,
J. Bogatinovski and S. Nedelkoski—Equal contribution
(cid:2)c SpringerNatureSwitzerlandAG2021
H.Hacidetal.(Eds.):ICSOC2020Workshops,LNCS12632,pp.201–213,2021.
https://doi.org/10.1007/978-3-030-76352-7_22
202 J. Bogatinovski and S. Nedelkoski
thusreducingtheeffortsoftheoperators,whileatthesametimeproducingahigh
detectionrate.Thebenefitoftimelydetectionallowspreventionofpotentialfail-
ures and increases the opportunity window for conducting a successful reaction
fromtheoperator.Thisisespeciallyimportantifurgentexpertiseand/oradmin-
istrationactivityisrequired.Thesymptomsoftenarenotifiedwheneverthereare
performance problems or system failures and usually manifests as some finger-
printswithinthemonitoreddata:logs,metricsordistributedtraces.
Themonitoredsystemdatarepresentthestateofthesystematanytimepoint.
Theyaregroupedintothreecategories-modalities:metrics,applicationlogs,and
distributed traces [12]. The metrics are time-series data that represent the uti-
lization of the available resources and the status of the infrastructure. Typically
theyinvolvemeasuringoftheCPU,memoryanddiskutilization,aswellasdata
asnetworkthroughput,andservicecalllatency.Applicationlogsareprintstate-
ments appearing in code with semi-structured content. They represent interac-
tionsbetweendata,files,services,orapplicationscontainingarichrepresentative
structureonaservicelevel.Service,microservices,andothersystemsgeneratelogs
whicharecomposedoftimestampedrecords.Distributedtraceschainstheservice
invocationsasworkflowsofexecutionofHTTPorRPCrequests.Eachpartofthe
chain in the trace is called an event or span. A property of this type of data is
thatitpreservestheinformationfortheexecutiongraphona(micro)servicelevel.
Thus,theinformationfortheinterplaybetweenthecomponentsispreserved.
Thelogdatacanproducearicherdescriptiononaservicelevelsincetheyare
fingerprints of the program execution within the service. On the other side, the
traces do not have much information on system-level information but preserve
the overall graph of request execution. Referring to the different aspects of the
system, the logs and traces provide orthogonal information for the distributed
systems behaviour. Building on this observation in this work, we introduce an
anomaly detection multi-source approach that can consider the data from both
the traces and logs, jointly. We demonstrate the usability of time-aligned log
and tracing data to produce better results on the task of anomaly detection as
compared to the single modalities as the main contribution to this work. The
results show that the model build under the joint loss from both the logs and
trace data can exploit some relationship between the modalities. The approach
is trainable end-to-end and does not require the building of separate models for
eachofthemodalities.Asasecondcontribution,weconsidertheintroductionof
vector embeddings for the spans within the trace. The adopted approach allows
thedefinitionofthespanvectorsasapoolingoverthewordstheyarecomposed
of. We refer to these vector embeddings as span2vec.
2 Related Work
The literature recognizes various approaches concerned with anomaly detection
in distributed systems from single modalities. We review the single modalities
approachesforbothlogsandtraces.Wealsoprovideanoverviewoftheexisting
multi-modal approaches, however, none of them jointly considers both traces
and logs.
Multi-source Anomaly Detection in Distributed IT Systems 203
The most common approaches for anomaly detection from log data roughly
follows a two-step composition - log parsing followed by a method for anomaly
detection. The first step allows for an appropriate log representation. One chal-
lenge during this procedure is the reduction of the noise in the log data. This
noise in a log message is present due to the various parameters parts of the log
can take during execution. To this end, there are many proposed techniques for
log parsing [3,7,14]. A detailed overview and comparison across benchmarks of
these techniques are given in [18]. After the template extraction, there are two
general approaches to represent the logs. The first one is based on word fre-
quencies and metrics derived from the logs (e.g. TF-IDF) [2,5,15,17] or reusing
wordrepresentationofthelogs,basedoncorporaofwords.Thesecondapproach
aims at translating the templates into sequences of templates - most often rep-
resented as sequences of integers or sequences of vectors. Such representation
allows modelling the sequential execution of a program workflow. One of the
most commonly utilized approaches is RNN-based(e.g. LSTM, GRU) [1]. They
often are coupled with an additional mechanism such as attention to allow for
betterpreservationofthesemanticinformationinsidethelogs[6].Dependingon
the data representation, various methods are utilized from both the supervised
andunsuperviseddomainsofmachinelearning.However,duetoeasierpractical
adoption and the absence of labels, the unsupervised methods are preferred.
Theavailableapproachesforanomalydetectionfromtracingdataarescarce.
They usually model the normal execution of a workload, represented within the
trace by utilizing history h of recent trace events as input. They decompose
the trace in its building blocks, the events/spans, and predict the next span in
the sequence. The anomaly detection is done with imposing thresholds on the
number of errors the LSTM is making for the corresponding trace predicted [9,
10].Furtherapproachesaimtocapturetheexecutionofacompleteworkloadinto
afinitestateautomata(FSA)[16].However,theFSAapproachesaredependent
onspecifictracingimplementationsystems.Theunificationofthisapproachwith
other types of modalities such as the log data due to the assumed homogeneous
structure of the states building the FSA is harder.
Several works on multi-modal learning for anomaly detection demonstrate
thefeasibilityofusingdifferentmodalities ofdataforanomalydetection[11,13].
In the context of large scale ICT systems, the authors in [10] consider the joint
exploitation of traces and the corresponding response times of the spans within
the trace. More specifically, a multi-modal LSTM-based method, trained jointly
on both modalities is introduced, showing the additional value added by the
shared information, improves the anomaly detection scores. In [4] a Multimodal
VariationalAutoencoderapproachisadoptedforeffectivelylearningtherelation-
shipsamongcross-domaindatawhichprovidegoodresultsforanomalydetection
build on the logs and metrics as modalitites. However, they do not preserve the
information for the overall microservice architecture.
To the best of our knowledge, the literature does not yet recognize methods
for joint consideration of logs and traces as fundamentally complementary data
sources describing the distributed IT systems. Hence in this work, we propose
an approach on how to jointly consider the complement information within the
logs and traces.
204 J. Bogatinovski and S. Nedelkoski
3 Multimodal Approach for Anomaly Detection
from Heterogeneous Data
Inthissection,wedescribethemulti-sourceapproachtowardsanomalydetection
using logs and tracing data. First, we describe the logs and traces as generated
by the system. We present their specifics that are exploited for the definition of
theNextTemplatePrediction(NTP)pseudo-task.Second,wedescribetheNTP
pseudo-task for anomaly detection. Thirdly, we describe one way to address the
NTP task utilizing deep learning architecture on a single modality description
of the system state. Next, we provide a solution that enables us to efficiently
solve the NTP problem as a pseudo task for joint detection of anomalies from
both logs and traces. Finally, we present an approach that uses the results from
the NTP task and performs anomaly detection.
3.1 Data Representation
Therawlogsandtracesasgeneratedbythesystem,containvariousinformation
about the specific operation being executed. Since some of the information is a
sporadicdescriptionoftheoperations,properfilteringandrepresentationshould
be done. Due to the specifics of the two modalities, we address them separately.
Logs. AlogisasequenceoftemporallyorderedunstructuredtextmessagesL=
{l i : i=1,2,...}.Eachtextmessagel i isgeneratedbyalogginginstruction(e.g.
printf(),log.info())withinthesoftwaresourcecode.Sincetheloggingfunctionis
part of the body of the whole program, it can serve as a proxy for the program
execution workflow. Hence one can infer the normal execution pattern within
the program workflow.
Thelogsconsistofaconstantandavaryingpart,referredtoaslogtemplate
and log parameters. Due to the large variability of the parameters, they can
introduce a lot of noise. To mitigate this problem common way to represent the
logs is with the extraction of the constant part through a log parsing procedure.
Itallowsforthecreationofadictionaryoflogtemplatesfromagivensetoflogs.
To unify the representations of the logs, the log templates are tokenized. A