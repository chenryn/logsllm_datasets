by starting a single instance of the protocol for a batch of re- 
quests.  We use a sliding-window mechanism to bound the 
number of protocol instances that can run in parallel with- 
out increasing latency in an unloaded system.  Let e be the 
sequence number of the last batch of requests executed by 
the primary and let p be the sequence number of the last pre- 
prepare  sent by  the primary.  When the primary receives a 
request, it starts the protocol immediately unless p  2 e+ W ,  
where W  is the window size.  In  the  latter case, it  queues 
the request. When requests execute, the window slides for- 
ward allowing queued requests to be processed.  Then, the 
primary  picks  the  first  requests  from  the queue  such  that 
the sum of their sizes is below a constant bound; it assigns 
them a sequence number; and it sends them in a single pre- 
prepare  message.  The protocol  proceeds  exactly  as it  did 
for a  single request except that  replicas execute the batch 
of  requests  (in the  order in  which they  were  added to the 
pre-prepare message) and they  send back  separate  replies 
for each request. 
We modified the algorithm to use separate request trans- 
mission:  requests  whose  size  is  greater  than  a  threshold 
(currently  255  bytes)  are  not  inlined  in  pre-prepare  mes- 
sages.  Instead,  the  clients multicast  these  requests  to  all 
replicas; replicas  authenticate the requests  in parallel; and 
they buffer those  that are authentic.  The primary  selects a 
batch of requests to include in a pre-prepare message but it 
only includes their digests in the message. 
4. Micro-Benchmarks 
This  section  presents  results  of  micro-benchmarks de- 
signed to characterize the performance of the BFT library 
in a service-independent way, and to evaluate the impact of 
each performance optimization. The experiments were per- 
formed using the setup in Section 4.1. Sections 4.2 and 4.3 
measure the latency and throughput of a simple replicated 
service using all  the optimizations.  The impact of the dif- 
ferent optimizations is studied  in  Section  4.4.  See [2] for 
a more detailed  performance evaluation  and description  of 
the experimental setup. 
4.1. Experimental Setup 
The experiments ran on Dell Precision 4 10 workstations 
with  a single 600 MHz Pentium 111 processor, 5 12 MB of 
memory, and a Quantum Atlas  10K  18WLS disk.  All ma- 
chines ran Linux 2.2.16-3 compiled without  SMP support. 
The machines were connected by a  100 Mb/s switched Eth- 
ernet.  The  switch  was  an  Extreme  Networks  Summit48 
V4.1.  Replicas  and  clients ran  on  different  machines and 
all experiments ran on an isolated network. 
The experiments compare the performance of two imple- 
mentations of a simple service:  one implementation, BFT, 
is replicated using the BFT library and the other, NO-REP, 
is not replicated and uses UDP directly for communication 
between the  clients and the  server.  The simple  service  is 
really the skeleton of a real  service:  it has no state and the 
service operations receive  arguments from  the clients and 
return (zero-filled) results but they perform no computation. 
We performed experiments with different argument and re- 
sult sizes for both read-only (RO) and read-write (RW) op- 
erations. It is important to note that this is a worst-case com- 
parison;  in  real  services, computation  or U0  at the clients 
and servers would  reduce the  slowdown introduced  by  the 
BFT library (as shown in Section 5). 
The results were  obtained  by  timing a  large number of 
invocations in at least three separate runs. We report the av- 
erage of the three runs. The standard deviation was always 
below  10% of the reported value. 
4.2. Latency 
We  measured  the  latency  to  invoke  an  operation  with 
four replicas when the service is accessed by a single client. 
Figure 2 shows the latency to invoke the replicated  service 
as the size of the operation  result  increases while keeping 
the argument size fixed at 8 B. It has one graph with elapsed 
times  and  another  with  the  slowdown of  BFT relative  to 
NO-REP. We also ran experiments  with  varying  argument 
sizes (see Figure 3) and obtained very similar results. 
The library introduces a significant slowdown relative to 
NO-REP but the slowdown decreases quickly as the oper- 
ation argument or result  sizes  increase.  In  both  cases, the 
slowdown decreases till  an asymptote of 1.26 [2]. The two 
major  sources  of  overhead  are  digest  computation  (of  re- 
quests  and replies)  and  the  additional communication due 
to the replication  protocol.  The cost of MAC computation 
is negligible. 
The read-only optimization improves performance by eli- 
minating  the  time  to prepare the  requests,  This time does 
515 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:06:48 UTC from IEEE Xplore.  Restrictions apply. 
0 
0 
2000  4000  6000  8000 
result size (bytes) 
2000  4000  6000  8000 
result size (bytes) 
Figure 2. Latency with and without BFT. 
0 
0 
not change as the argument or result size increases.  There- 
fore, the  speed  up afforded by  the read-only  optimization 
decreases to zero as the argument or result size increases, 
The experiments in Figure 2 ran in  a configuration with 
four replicas, which can tolerate one fault.  We believe this 
level  of  reliability  will  be  sufficient for most  applications 
but some may require more replicas. Figure 3 compares the 
latency  to  invoke the  replicated  service with  four replicas 
(f = 1) and seven replicas (f = 2). In both configurations, 
all the replicas had  a  600 MHz Pentium 111 processor and 
the client had a 700 MHz Pentium I11 processor. 
o h d o O ' 6 0 0 0  Sdoo 
argument size (bytes) 
result size (bytes) 
Figure 3. Latency with f  = 2 and with f  = 1. 
The results show that the slowdown caused by increasing 
the number of replicas to seven is low. The maximum slow- 
down  is 30% for the read-write operation and 26% for the 
read-only operation. Furthermore, the slowdown decreases 
quickly as the argument or result size increases. 
4.3. Throughput 
This section reports the result of experiments to measure 
the  throughput  of  BFT and NO-REP  as a  function  of  the 
number of clients accessing the simple service.  The client 
processes were evenly distributed over 5 client machines'. 
There were four replicas.  We measured throughput for op- 
erations with different argument and result sizes.  Each op- 
eration type is denoted by d b ,  where a and b are the sizes 
of the argument and result in KB. 
Figure 4 shows throughput results for operations O/O,  0/4, 
and 4/0. The bottleneck in operation 010 is the server's CPU. 
BFT has lower throughput than NO-REP due to extra mes- 
sages and  cryptographic  operations  that  increase the CPU 
load.  The read-only optimization  improves throughput by 
eliminating the cost of preparing the batch of requests. The 
'Two client machines had 700 MHz Pllls but were otherwise identical 
to the other machines. 
throughput of the read-write operation improves as the num- 
ber  of  clients  increases  because  the  cost  of  preparing  the 
batch  of  requests  is  amortized  over the  size of  the  batch. 
Throughput saturates because  the  batch  size  is  limited  by 
how many requests can be inlined in a pre-prepare message. 
BFT has better throughput than  NO-REP for operation 
0/4. 'The bottleneck for NO-,REP is the link bandwidth that 
imposes  an  upper  bound  of  3000 operations  per  second. 
BFT achieves better throughput because of the digest-replies 
optimization: clients obtain the replies with the 4 KB result 
in  parallel  from different replicas.  BFT achieves a maxi- 
mum  throughput of 6625 operations per  second (26MB/s) 
for the read-write operation and 8987 operations per second 
(35 MB/s) with the read-only  optimization. The bottleneck 
for EIFT is the replicas'  CPU. 
The bottleneck  in  operation 4/0 for both  NO-REP  and 
BFT  is  the  time  to  get  the  requests  through  the  network, 
which imposes a bound of 3000 operations per second. NO- 
REP achieves a  maximum  throughput  of 2921 operations 
per second while BFT achieves I 1% less for read-write ope- 
rations and 2% less with the read-only optimization. There 
are no points with more than  15 clients for NO-REP because 
of  lost request  messages;  NO-REP uses UDP directly and 
does not retransmit requests. 
4.4. Impact of Optimizations 
The experiments  in  the  previous  sections show perfor- 
mance  with  all  the  optimizations  for both  read-write  and 
read-only operations. This section analyses the performance 
impaqt of the other optimizations. 
,,.$;*"" 
. .  
.*;,, 
&..&  .A  .- A...&  ....  ..b. . ... 
- 
RW 
-A- RO 
RW NDR 
-*. RO NDR 
. 
:'.$ 
.I 
k 2000 
result size (bytes) 
O i
  20 
number of clients 
i o  . 60  $0  IO0 
Figure 5. Digest Replies Optimization 
Figure  5  compares the  performance  of  BFT with  and 
without the digest replies optimization.  We  called the ver- 
sion of  BFT without the optimization BFT-NDR.  The first 
graiph measures latency as the size of the operation result in- 
creases with the argument size fixed at 8 B, and the second 
shows the  throughput results  for operation 0/4.  We chose 
these experiments because the  impact of the digest replies 
optimization increases with the result size. 
The  digest  replies  optimization  reduces  the  latency  to 
invoke operations  with  large results significantly.  Further- 
more,  this  speedup increases  linearly  with  the  number of 
replicas.  Additionally, BFT achieves a throughput  up to 3 
times better than BFT-NDR. The bottleneck for BFT-NDR 
is  the  link bandwidth:  it  is  limited  to  a  maximum  of  at 
most 3000 operations per-second regardless of the number 
of replicas.  The digest replies  optimization enables band- 
width for sending replies to scale linearly with the number 
of  replicas and it also reduces load on replicas'  CPUs. 
516 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:06:48 UTC from IEEE Xplore.  Restrictions apply. 
0
0 
so 
number of clients 
100 
t
150  200 
0 
Figure 4. Throughput for operations O/O,  0/4 and 4/0. 
50 
150 
number of clients 
100 
0 
1
200 
0
number of clients 
40 
20 
60 
0