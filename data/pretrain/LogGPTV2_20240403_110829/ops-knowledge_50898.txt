User: I'm working on a python script that monitors a directory and uploads files that have been created or modified using scp. That's fine, except I want this to be done recursively, and I'm having a problem if a user creates a directory in the watch directory, and then modifies a file inside that new directory.
I can detect the directory creation and file nested file creation/modification just fine. But if I try to upload that file to the remote server, it won't work since the directory on the remote site won't exist. Is there a simple way to do this WITHOUT recursively copying the created directory? I want to avoid this because I don't want to delete the remote folder if it exists.
Also, please don't suggest rsync. It has to only use ssh and scp.
Assistant: Since you have ssh, can't you just create the directory first?  For example, given a file with absolute path /some/path/file.txt, issue a mkdir -p /home/path before uploading file.txt.
UPDATE:  If you're looking to lower the number of transactions, a better method might be to make a tar file locally, transfer that, and untar it.