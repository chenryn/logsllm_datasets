/
4
0
/
1
0
6
0
/
7
0
/
1
0
6
0
/
0
1
/
1
0
7
0
/
1
0
/
1
0
7
0
/
4
0
/
1
0
7
0
/
7
0
/
1
0
7
0
/
0
1
/
1
0
8
0
/
1
0
/
1
0
8
0
/
4
0
/
1
0
8
0
/
7
0
/
1
0
8
0
/
0
1
/
1
0
9
0
/
1
0
/
1
0
9
0
/
4
0
/
1
0
(a) PhpBB
(b) WordPress
(c) Movable Type
Fig. 2. Lines of codes in the repositories of PhpBB, WordPress, and Movable Type, over
time. Counts include only the code that manipulates HTTP responses, requests and
sessions.
ﬁeld in maps search), which manifested themselves as new parameters found in
the web search page (e.g. to take into account the country or the ZIP code). User
pages of YouTube were signiﬁcantly updated with new functionalities between
2008 and 2009. For instance, the new version allows users to rearrange widgets
in their personal pages. To account for the position of each element, new param-
eters are added to the proﬁle pages and submitted asynchronously whenever the
user drags widgets within the layout. The analysis on MySpace did not reveal
any signiﬁcant change. The results of these two experiments show that changes
in server-side applications are common. More importantly, these modiﬁcations
often involve the way user data is represented, handled, and manipulated.
For the third experiment, we analyzed changes in the requests and sessions
by inspecting the code repositories of three of the largest, most popular open-
source web applications: WordPress, Movable Type, and PhpBB. The goal was to
understand whether upgrading a web application to a newer release results in
signiﬁcant changes in the features that are used to determine its behavior. In this
analysis, we examined changes in the source code that aﬀect the manipulation of
HTTP responses, requests, and session data. We used StatSVN, an open-source
tool for tracking and visualizing the activity of SVN repositories (e.g., the
number of lines changed or the most active developers). We modiﬁed StatSVN
to incorporate a set of heuristics to compute approximate counts of the lines of
code that, directly or indirectly, manipulate HTTP session, request or response
data. In the case of PHP, examples representative of such lines include, but
are not limited to, REQUEST| SESSION| POST| GET|session |http |strip -
tags|addslashes. In order to take into account data manipulation performed
through library functions (e.g., WordPress’ custom Http class), we also generated
application-speciﬁc code patterns by manually inspecting and ﬁltering the core
libraries. Figure 2 shows, over time, the lines of code in the repositories of Ph-
pBB, WordPress, and Movable Type that manipulate HTTP responses, requests
and, sessions. These results show the presence of signiﬁcant modiﬁcations in
the web application in terms of relevant lines of code added or removed. More
30
F. Maggi et al.
importantly, such modiﬁcations aﬀect the way HTTP data is manipulated and,
thus, impact request, response or session models.
The aforementioned experiments conﬁrm that the class of changes we de-
scribed in Section 2.2 is common in real-world web applications. Therefore, we
conclude that anomaly detectors for web applications must incorporate proce-
dures to prevent false alerts due to concept drift. In particular, a mechanism is
needed to discriminate between legitimate and malicious changes, and respond
accordingly.
3 Addressing Concept Drift
In this section, we ﬁrst present our technique to distinguish between legitimate
changes in web application behavior and evidence of malicious behavior. We then
discuss how a web application anomaly detection system can eﬀectively handle
legitimate concept drift.
3.1 The Web Application as Oracle
The body of HTTP responses contains a set of links Li and forms Fi that refer
to a set of target resources. Each form also includes a set of input ﬁelds Ii.
In addition, each link li,j ∈ Li and form fi,j ∈ Fi has an associated set of
parameters.
From a resource ri, the client clicks upon a link li,j or submits a form fi,j.
Either of these actions generates a new HTTP request to the web application
with a set of parameter key-value pairs, resulting in the return of a new HTTP
response to the client, ri+1, the body of which contains a set of links Li+1 and
forms Fi+1. This process continues until the session has ended (i.e., either the
user has explicitly logged out, or a timeout has occurred).
Our key observation is that, at each step of a web application session, the
set of potential target resources is given exactly by the content of the current
resource. That is, given ri, the associated sets of links Li and forms Fi directly
encode a signiﬁcant sub-set of the possible ri+1. Furthermore, each link li,j and
form fi,j indicates a precise set of expected parameters and, in some cases, the
set of legitimate values for those parameters that can be provided by a client.
Example. Consider a hypothetical banking web application, where the cur-
rent resource ri = /account presented to a client is an account overview
containing a set of links Li = {/account/history?aid=328849660322, /ac-
count/history?aid=446825759916, /account/transfer, /logout} and forms
(represented as their target action) Fi = {/feedback, /search}.
From Li and Fi, we can deduce the set of legal candidate resources for the
next request ri+1. Any other resource would, by deﬁnition, be a deviation from
a legal session ﬂow through the web application as speciﬁed by the application
itself. For instance, it would not be expected behavior for a client to directly ac-
cess /account/transfer/submit (i.e., a resource intended to submit an account
funds transfer) from ri. Furthermore, for the resource /account/history, it is
Protecting a Moving Target: Addressing Web Application Concept Drift
31
clear that the web application expects to receive a single parameter aid with an
account number as an identiﬁer.
In the case of the form with target /feedback, let the associated input ele-
ments be:
General
User interface
Functionality 
It immediately follows that any invocation of the /feedback resource from ri
should include the parameters subject and message. In addition, the legal set
of values for the parameter subject is given by enumerating the enclosed  tags. Similarly, valid values for the new tz and datetime parameters
mentioned in the example of Section 2.2 can be inferred. Any deviation from
these speciﬁcations could be considered evidence of malicious behavior.
We conclude that the responses generated by a web application constitute a spec-
iﬁcation of the intended behavior of clients and the expected inputs to an applica-
tion’s resources. As a consequence, when a change occurs in the interface presented
by a web application, this will be reﬂected in the content of its responses. There-
fore, as detailed in the following section, our anomaly detection system performs
response modeling to detect and adapt to changes in monitored web applications.
3.2 Adaptive Response Modeling
In order to detect changes in web application interfaces, the response modeling
of webanomaly has been augmented with the ability to build Li and Fi from the
HTML documents returned to a client. The approach is divided into two phases.
Extraction and parsing. The anomaly detector parses each HTML document
contained in a response issued by the web application to a client. For each 
tag encountered, the contents of the href attribute is extracted and analyzed.
The link is decomposed into tokens representing the protocol (e.g., http, https,
javascript, mailto), target host, port, path, parameter sequence, and anchor.
Paths are subject to additional processing; for instance, relative paths are nor-
malized to obtain a canonical representation. This information is stored as part
of an abstract document model for later processing.
A similar process occurs for forms. When a  tag is encountered, the
action attribute is extracted and analyzed as in the case of the link href at-
tribute. Furthermore, any , , or  and  tags enclosed by a particular  tag are parsed as parameters
to the corresponding form invocation. For  tags, the type, name, and
value attributes are extracted. For  tags, the name attribute is
extracted. Finally, for  tags, the name attribute is extracted, as well
as the content of any enclosed  tags. The target of the form and its
parameters are recorded in the abstract document model as in the case for links.
32
F. Maggi et al.
qi
respi
qi+1
Client
qi
respi
qi+1
Parsing
Li, Fi
Change or attack?
Anomaly detector
Web app. server
Fig. 3. A representation of the interaction between the client and the web application
server, monitored by a learning-based anomaly detector. After request qi is processed,
the corresponding response respi is intercepted and link Li and forms Fi are parsed to
update the request models. This knowledge is exploited as a change detection criterion
for the subsequent request qi+1.
Analysis and modeling. The set of links and forms contained in a response
is processed by the anomaly engine. For each link and form, the corresponding
target resource is compared to the existing known set of resources. If the resource
has not been observed before, a new model is created for that resource. The
session model is also updated to account for a potential transition from the
resource associated with the parsed document and the target resource by training
on the observed session request sequence.
For each of the parameters parsed from links or forms contained in a response,
a comparison with the existing set of known parameters is performed. If a pa-
rameter has not already been observed (e.g., the new tz parameter), a proﬁle is
created and associated with the target resource model.
Any values contained in the response for a given parameter are processed
as training samples for the associated models. In cases where the total set of
legal parameter values is speciﬁed (e.g.,  and  tags), the
parameter proﬁle is updated to reﬂect this. Otherwise, the proﬁle is trained on
subsequent requests to the associated resource.
As a result of this analysis, the anomaly detector is able to adapt to changes
in session structure resulting from the introduction of new resources. In addition,
the anomaly detector is able to adapt to changes in request structure resulting
from the introduction of new parameters and, in a limited sense, to changes in
parameter values.
3.3 Advantages and Limitations
Due to the response modeling algorithm described in the previous section, our
web application anomaly detector is able to automatically adapt to many com-
mon changes observed in web applications as modiﬁcations are made to the
interface presented to clients. Both changes in session and request structure
such as those described in Section 2.2 can be accounted for in an automated
fashion. For instance, the I18N and L10N modiﬁcation of the aforementioned
example is correctly handled as it consists in an addition of the tz parameter
and a modiﬁcation of the datetime parameter. Furthermore, we claim that web
application anomaly detectors that do not perform response modeling cannot
Protecting a Moving Target: Addressing Web Application Concept Drift
33
reliably distinguish between anomalies caused by legitimate changes in web ap-
plications and those caused by malicious behavior. Therefore, as will be shown
in Section 4, any such detector that solely monitors requests is more prone to
false positives in the real world.
Clearly, the technique relies upon the assumption that the web application
has not been compromised. Since the web application, and in particular the doc-
uments it generates, is treated as an oracle for whether a change has occurred, if
an attacker were to compromise the application in order to introduce a malicious
change, the malicious behavior would be learned as normal by our anomaly de-
tector. Of course, in this case, the attacker would already have access to the web
application. However, we remark that our anomaly detector observes all requests
and responses to and from untrusted clients, therefore, any attack that would
compromise response modeling would be detected and blocked. For example, an
attacker could attempt to evade the anomaly detector by introducing a malicious
change in the HTTP responses and then exploits the change detection technique
that would interpret the new malicious request as a legit change. For instance,
the attacker could incorporate a link that contain a parameter used to inject the
attack vector. To this end, the attacker would have to gain control of the server
by leveraging an existing vulnerability1 of the web application (e.g., a buﬀer
overﬂow, a SQL injection). However, the HTTP requests used by the attacker
to exploit the vulnerability will trigger several models (e.g., the string length
model, in the case of a buﬀer overﬂow) and, thus, will be ﬂagged as anomalous.
In fact, our technique does not alter the ability of the anomaly detector to detect
attacks. On the other hand, it avoids many false positives, as demonstrated in
Section 4.2.
Besides the aforementioned assumptions, three limitations are important to
note. First, the set of target resources may not always be statically derivable from
a given resource. For instance, this can occur when client-side scripts are used
to dynamically generate page content, including links and forms. Accounting
for dynamic behavior would require the inclusion of script interpretation. This,
however, has a high overhead, is complex to perform accurately, and introduces
the potential for denial of service attacks against the anomaly detection system.
For these reasons, we have not included such a component in the current system,
although further research is planned to deal with dynamic behavior. Moreover,
as Section 4 demonstrates, the proposed technique performs well in practice.
Second, the technique does not fully address changes in the behavior of in-
dividual request parameters in its current form. In cases where legitimate pa-
rameter values are statically encoded as part of an HTML document, response
modeling can directly account for changes in the legal set of parameter values.
Unfortunately, in the absence of any other discernible changes in the response,
changes in parameter values provided by clients cannot be detected. However,
heuristics such as detecting when all clients switch to a new observable behavior
in parameter values (i.e., all clients generate anomalies against a set of models in
1 The threat model assumes that the attacker can interact with the web application
only by sending HTTP requests.
34
F. Maggi et al.
a similar way) could serve as an indication that a change in legitimate parameter
behavior has occurred.
Third, the technique cannot handle the case where a resource is the result of
a parametrized query and the previous response has not been observed by the
anomaly detector. In our experience, however, this does not occur frequently in
practice, especially for sensitive resources.
4 Evaluation
In this section, we show that our techniques reliably distinguish between le-
gitimate changes and evidence of malicious behavior, and present the resulting
improvement in terms of detection accuracy.
The goal of this evaluation is twofold. We ﬁrst show that concept drift in mod-
eled behavior caused by changes in web applications results in lower detection
accuracy. Second, we demonstrate that our technique based on HTTP responses
eﬀectively mitigates the eﬀects of concept drift. In both the experiments, the
testing data set includes samples of the most common types of attacks against
web applications such as cross-site scripting (XSS) (e.g., CVE-2009-0781), SQL