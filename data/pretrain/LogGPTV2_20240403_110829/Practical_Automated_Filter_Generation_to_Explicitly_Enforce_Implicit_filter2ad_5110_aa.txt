title:Practical Automated Filter Generation to Explicitly Enforce Implicit
Input Assumptions
author:Valentin Razmov and
Daniel R. Simon
Practical Automated Filter Generation
to Explicitly Enforce Implicit Input Assumptions
Valentin Razmov
University of Washington
PI:EMAIL
Abstract
too  often 
the  security  holes.  All 
Vulnerabilities  in  distributed  applications  are  being
uncovered  and  exploited  faster  than  software  engineers
can  patch 
these
weaknesses  result  from  implicit  assumptions  made  by  an
application  about  its  inputs.  One  approach  to  defending
against  their  exploitation  is  to  interpose  a  filter  between
the input source and the application that verifies that the
application’s  assumptions  about  its  inputs  actually  hold.
However, ad hoc design of such filters is nearly as tedious
and  error-prone  as  patching  the  original  application
itself.  We  have  automated  the  filter  generation  process
based on a simple formal description of a broad  class  of
assumptions about the inputs to an application. Focusing
on  the  back-end  server  application  case,  we  have
prototyped  an  easy-to-use  tool  that  generates  server-side
filtering scripts. These can then be quickly installed on a
front-end  web  server  (either 
the
application  or  when  a  vulnerability  is  uncovered),  thus
shielding the server application from a variety of existing
and  exploited  attacks,  as  solutions  requiring  changes  to
the  application  are  developed  and 
tested.  Our
measurements  suggest  that  input  filtering  can  be  done
efficiently  and  should  not  be  a  performance  concern  for
moderately  loaded  web  servers.  The  overall  approach
may  be  generalizable  to  other  domains,  such  as  firewall
filter generation and API wrapper filter generation.
in  concert  with 
1. Introduction
The majority of recent security attacks have exploited
various unwarranted assumptions about input data passed
to server applications. Among these vulnerabilities, buffer
overflows  have  accounted  for  over  50%  of  the  security
breaches [9, 25, 22, 24]. While simple to avoid, this type
of attack has seen such proliferation mainly because of the
typical  programmer’s  “natural”  disposition  not  to  expect
the unexpected, coupled with the relative ease – especially
magnified  through  attack  scripts  [1]  –  with  which
Daniel R. Simon
Microsoft Research
PI:EMAIL
malicious parties can exploit these vulnerabilities [10].
responsible 
anomalies  often 
Other 
input 
for
vulnerabilities include:
  parameters  having  unexpected  values,  especially
values outside of (expected) ranges;
  ambiguous  character  string  parameters  that  cause
data  to  be  misinterpreted  as  execution  code  [4].  Often
these  incorporate  special  escape  characters  that  have
different meanings in different contexts.
In all of the above cases, clearly and explicitly stating
and verifying all implicit assumptions about the inputs is
the key to trouble avoidance. However, it is unrealistic to
expect  that  application  developers  will  always  include
100%  of  the  necessary  validation  checks  on  the  inputs
their  applications  receive.  For  example,  many  existing
applications were originally written under the assumption
that they  would  run  in  trusted  environments,  and  so  lack
needed  input  validity  tests  when  used  in  environments
vulnerable  to  attack.  The  option  of  retrofitting  security
into each legacy application’s code in such circumstances
is  unrealistic.  More  generally, 
typical  programming
methodology neither requires nor helps the programmer to
express input validity assumptions, making it easy to fail
to verify  them  at  all  and  requiring  great  discipline  to  get
the verification right.
One approach is to externalize validation checks into a
filter  and  then  install  the  filter  (only)  in  environments
where  it  is  necessary.  This  decouples  input  sanitization
from  core  application  functionality,  thereby  making  it
possible  to  develop  an  input  filter  long  after  its  targeted
application  has  been  disseminated,  without  the  necessity
to  have  access  to  the  application  source  code,  and  with
much  less  effort  as  compared  to  developing  a  security
patch.  The  inherent  difference  in  complexity  between
simple  input  filters  and  full-fledged  applications  allows
assumptions  about  the  input  to  be  specified  quickly,
compactly and in a less error-prone manner. (For example,
a simple filter can be developed and deployed as soon as a
vulnerability  is  discovered,  and  removed  later  when  a
patch  becomes  available  and  is  installed.)  In  addition,
filters external to applications allow for efficiency-minded
omission of input validation if its presence is unnecessary.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:06:13 UTC from IEEE Xplore.  Restrictions apply. 
then  be 
The  decision  of  when  performing  input  validation  is
to 
worthwhile  can 
the  system
administrator,  who  can  decide 
the  performance
overhead  from  the  validity  checks  is  outweighed  by  the
need  for  protection  in  environments  which  cannot  be
guaranteed to be secure.
left  up 
if 
This  approach  is  already  the  norm  in  many  settings.
For example, some applications perform no authentication
or  input  validation,  implicitly  assuming  that  packets
reaching  them  at  a  certain  port  always  originate  from
senders inside their LAN.  In this case, packets directed at
that particular port but originating  from outside the  LAN
will  be  treated,  erroneously,  as  local  –  a  situation  which
has  not  been  anticipated  by  the  application  and  is  thus  a
possible  cause  of  a  security  breach.  Similarly,  server
applications  sometimes  implicitly  assume  that  clients
never  send  inputs  large  enough  to  overrun  the  available
buffer  space.  In  this  scenario,  the  server  application  is
prone  to  buffer  overrun  attacks,  which  have  been  shown
[25,  9]  to  open  the  door  to  execution  of  arbitrary
(untrusted) code on the server.
In  both  cases  there  are  simple  ways  to  prevent
potential  break-ins.  For  the  first,  a  firewall  filter  can
intercept and “filter out” packets coming from outside the
LAN and directed at the port on  which the application is
listening. For the second, an input filter could check if the
size (among other relevant characteristics) of the input is
within  an  acceptable  range  and  treat  the  input  as  unsafe
otherwise.  In  both  situations,  employing  such  a  filtering
approach would ensure that incoming data conforms to the
applications’ inherent assumptions about it [10].
Of  course,  complete  verification  of  the  validity  of  an
application’s  input  can  be  as  complex  as  the  application
itself.  However,  a  substantial 
fraction  of  security
vulnerabilities  (such  as  the  buffer  overruns  mentioned
above) can be prevented by filtering inputs based on a few
simple,  syntactic  properties  (e.g.,  input  length  or  the
presence  of  certain  “forbidden”  characters  or  character
sequences).  These  vulnerabilities  are  typically  the  first
target of attackers, since they are relatively easy to exploit,
requiring little understanding of the internal semantics of a
given  application.  Moreover 
they  are  a  common
phenomenon, given the prevalence of various error-prone
programming practices. The approach we take reflects our
belief in security through simplicity as advocated in [18];
the more complex a filter becomes, the less trustworthy it
tends to be.
Although  not  all  possible  vulnerabilities  can  be
addressed by applying purely syntactic filters, the bar for
breaking into a system merely by sending it invalid inputs
can thus be raised significantly. Syntactic filters have long
been  used 
to  stop  malformed  or  otherwise  unsafe
incoming data from wreaking havoc on vulnerable server
applications,  and  in  firewalls  to  protect  networks  from
external  (or  unauthorized  internal)  attackers  subverting
network-aware  applications  by  masquerading  as  internal
(or  authorized)  users.  However,  filtering  has  been  very
much an ad hoc practice so far, with administrators having
to  manually  develop  scripts,  each  specially  tailored  for  a
given application that needed shielding. While relying on
the  specifics  of  an  application  and  protecting  it  as  a
separate entity  helps build  the  most  resilient  of  defenses,
we  believe  that  too  much  unnecessary  burden  has  been
placed on administrators, who have had to  write intricate
ad hoc scripts (i.e., filters) and support them over time.
Automating  the  filter  generation  would  enhance  the
process immensely, reducing both the cost of creating and
maintaining filters and the chance for occasional scripting
errors  or  omissions.  With  the  burden  of  managing  filters
thus reduced, the reliability and responsiveness of system
defenses  should  improve,  making  them  more  resilient  to
attacks.
The next section provides an account of related work.
Section  3  discusses  the  design  decisions  behind  building
filters  and  describes  our  software  architecture.  Section  4
concentrates on the implementation details of a proof-of-
concept filter-generating tool, while Section 5 provides an
evaluation of our experience with writing filters using the
tool and a performance cost estimate of input filtering on
real  servers.  We  conclude  in  Section  6  stating  the
contributions  of  our  work  and  outlining  further  research
avenues.
2. Related Work
In [17] the authors deal with analyzing applet bytecode
before  applet  instantiation  in  order  to  verify  that  applets
conform  to  a  set  of  filtering  rules  designed  to  preclude
exploitation  of  known  bugs  in  the  JVM  implementation.
Rule-based filtering is proposed there (as well as in [12])
as an approach to patching bugs and preventing breaches.
Our prototype filters have a similar goal, but in the back-
end server context. We also enforce a set of assumptions
on  the  application  input,  rather  than  on  the  application
itself.
Clearly for any tool to be practical, usability needs to
be one of its primary goals. This requirement was a major
factor in our design. An approach similar in spirit is taken
in [3], where a generic representation scheme for firewall
filter  configuration  is  presented,  leading  to  a  usable  tool
for firewall management. In contrast, in [23] the emphasis
is on generality and formal assurance, with the result that
filters  are  expressed  in  a  rich  (and  heavyweight)  filter
specification language, as opposed to our simple one. We
hope tools like our prototype will  make generating back-
end  server  input  filters  simpler,  more  intuitive  and  less
error-prone.
Another  goal  we  have  set  for  our  tool  is  to  avoid
relying  on  access 
is  often
unavailable  in  practice.  This  distinguishes  our  approach
to  source  code,  which 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:06:13 UTC from IEEE Xplore.  Restrictions apply. 
from most other previous work, including [17], [12], [11]
and  [25].  The  decision  is  a  trade-off  between  wider
applicability  and  the  ability  to  do  (offline)  syntactic  as
well as limited semantic analysis of the application’s inner
workings, such as looking for spots where (not necessarily
maliciously  intended)  input  could  “trip”  on  a  bug,
resulting in a potential security hole. The authors of [14],
like  us,  do  not  rely  on  source  code  inspection  in  their
attempt to contain untrusted helper applications. They too
set  it  as  their  goal  to  keep  the  security  mechanism
orthogonal 
to  any  non-security-critical  functionality.
However,  they  use  “modules”  to  enforce  a  resource
sandboxing  policy,  rather  than  an  input  filtering  policy.
Hence,  their  modules  are  based  on  a  sophisticated
understanding  of  the  resources  available  on  a  user’s
machine,  their  security  criticality,  and  their  legitimate
uses, and are appropriate for protecting against viruses or
Trojan horses being downloaded and run  as  applications.
Several  other  “wrapper”  designs  have  been  proposed  for
the  same  general  sandboxing  task  [2,  16,  20],  or  for
network  security  policy  enforcement  [19],  but  they  have
all  had  generality  of  policy  expressiveness  as  their  main
goal,  and  are  thus  relatively  complex  and  difficult  to
apply.  Our filters, on the other hand, are meant to protect
against  simple  (yet  still  potentially  highly  damaging)
malformed inputs, and thus should be much easier to write
and apply.
3. Design
Next  we  discuss  the  design  decisions  behind  our
automated filter generator.
3.1. Architecture
To  be  effective,  a  filter  needs  to  be  specific  to  an
application.  For  any  given  application,  the  process  of
generating  a  filter  requires  that  at  some  point  the
assumptions about the application’s input be expressed in
a  formal  way.  If  the  application’s  internals  (i.e.,  source
code, etc.) are undisclosed, then the formal description can
be  provided  by  the  application’s  vendor  or  by  a  trusted
third party. Alternatively, an administrator can generate it
(using,  for  instance,  a  GUI-based  tool  like  the  one  from
our  prototype)  based  on  the  application’s  specification,
and/or  on  descriptions  (formal  or  informal)  of  particular
attacks the filter is meant to block.
The  full  process  of  filter  generation  is  illustrated  in
Figure 1. The components are:
 
Intermediate Description Synthesizer – a combined
(graphical user interface-based) description synthesis tool,
used  to  generate,  in  order,  a  formal  description  of  the
input structure (defining how the input is to be parsed into
a  sequence  of  tokens  –  we  refer  to  them  below  as
“parameters”) and a formal description of the assumptions
being  enforced  on  these  parameters.  Either  or  both  of
these descriptions could also be generated manually, or by
means  of  other  tools,  or  obtained  from  trusted  vendors.
However, 
improve
usability and may reduce potential user errors.
the  description  synthesizer  may 
  Filter  Generator  –  a  filter-generating  tool,  which
“compiles”  the  above  two  formal  descriptions  into  an
executable filtering script.
Intermediate Description
Synthesizer
Description of the
Parsing Scheme
Description of the
Assumptions
Filter Generator
(Description Parser and
Script Synthesizer)
Filtering Script
Figure 1. Filter generation process
At run time, the application’s input is intercepted (by a
special  module)  and  routed  to  the  filtering  script.  The
script,  which  encodes  the  class  of  valid  input  structures,
parses  the  given  input  into  parameters  and  then  tests  the
compiled  assumptions  on  them.  Once  the  checks  are
completed,  the  intercepting  module  receives  the  script’s
verdict and takes the appropriate action – passing the input
on to the application or dropping it (Fig.2).
Input
1
Intercepting