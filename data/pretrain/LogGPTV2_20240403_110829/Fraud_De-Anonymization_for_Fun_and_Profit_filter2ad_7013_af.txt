13 RELATED WORK
Author identification and cross-site identity linking. The au-
thor identification problem seeks to identify the original author of a
document [51]. Narayanan et al. [51] used linguistic stylometry to
perform large scale identification of blog post authors and argue
damaging implications to anonymous bloggers and whistleblow-
ers. Another closely related problem is that of cross-site identity
linking attacks [15, 16, 34, 62, 86]. Adversaries were shown to be
able to exploit linguistic [14] and location [30] patterns to link
pseudonymous identities of the same user across different sites.
Backes et al. [16] introduced relative and absolute linkability mea-
sures that rank identities by their anonymity, and used information
about matching identities to estimate linkability risks. Andreou et
al. [15] further studied relationships between anonymity and risks
of linkability of Facebook and Twitter accounts.
Venkatadri et al. [73] leveraged this attack to develop a frame-
work to transfer trust between sites and identify trustworthy ac-
counts. Jain et al. [34] observed that Facebook and Twitter pro-
files share attributes, to develop identity search methods that link
Twitter accounts to their owners’ Facebook accounts. Cloning at-
tacks [39], where adversaries clone the accounts of victims from
one site to another, may thwart this linkage.
In the context of our work, de-anonymization is not an attack but
a desirable feature. This problem is also more challenging: unlike
Twitter and Facebook, crowdsourcing and peer-opinion sites do
not facilitate explicit forms of inter-connection. Further, instead of
finding a one-to-one mapping, our research focuses on a many-to-
one de-anonymization strategy that seeks to attribute many fake
identities to a real identity (i.e. underlying fraud worker).
Sybil community detection. The pseudonymous fraudster dis-
covery problem is equivalent to uncovering Sybil (or sockpuppet)
communities. Sybil accounts disconnect physical from online iden-
tities, thus have a suite of malicious uses, that include gaining
control over systems [25], vandalism [63], or creating the illusion
of widespread support of ideas, people and products [66]. Early
Sybil detection work in online systems has focused on social net-
works [23, 72, 84, 85], and made the assumption that attackers can
easily form social relationships between Sybil accounts they con-
trol, but find it hard to establish links to honest accounts. However,
Yang et al. [81] showed that in Renren, Sybil accounts do not form
tight-knit communities, and are well connected with honest users.
In peer-opinion systems that lack strong social links between
user accounts, social graphs can be replaced by co-activity graphs,
such as our co-review graphs. Then, in discussion communities,
Kumar et al. [40] showed that Sybil accounts still differ from honest
accounts through social network structure, posting behavior and
linguistic traits. They leveraged the discovery that pairs of accounts
controlled by the same individual are more likely to interact on the
same discussion, to build a co-ownership predictor. Zheng et al. [87]
predict Sybil links between user accounts based on the similarity of
their reviews, in terms of the products targeted, times and ratings.
In Section 11.4 we show that our co-ownership predictor signif-
icantly outperforms the accuracy of Zheng et al. [87]’s predictor.
We did not compare against the predictor of Kumar et al. [40], that
uses community feedback features that are unavailable in sites like
Google Play. Further, after detecting Sybil communities, Detego
seeks to de-anonymize them by finding the crowdsourcing account
of the human fraud worker who controls them.
Fraud detection. There is a large body of research on defend-
ing against online system fraud. State of the art approaches use
inference on the social graph [12, 37, 53, 58, 75] and classical ma-
chine learning based on several assumptions. These assumptions
include: (i) bursty activity [27, 43, 44, 83], (ii) review plagiarism [31,
36, 37, 47] and distinguishability of machine vs. human generated
reviews [82], (iii) extreme reviews and deviation [47, 58, 77, 79],
(iv) lockstep behavior [18, 67, 71], and (v) ratio of singleton ac-
counts [58, 61, 83]. Unlike this work, that has focused on providing
binary classification of reviews as fake or honest, and accounts
as fraudulent or benign, we seek to identify the prolific workers
responsible for significant fraud. We implement a maximum likeli-
hood estimation and deep learning based guilt-by-association pro-
cess to expand seed, fraudster-controlled account sets, and assign
them to the crowdsourcing account of the fraudster who controls
them.
Fraud data collection. De Cristofaro et al. [24] deployed Facebook
honeypot pages and analyzed like farms based on demographic,
temporal and social dimensions. Some farms seemed to be operated
by bots while others mimic regular users’ behaviors. Stringhini et
al. [68] studied Twitter follower markets by purchasing followers
from different merchants and used such ground truth to discover
patterns and detect “market” accounts in the wild. In this paper
we use fraudster responses to conduct a live validation of our solu-
tions, and map accounts in the online peer-opinion system to the
controlling crowdsourcing worker.
14 CONCLUSIONS
In this paper we study the search rank fraud de-anonymization
problem and show that it is different from the well studied fraud or
spammer detection problem. We model fraud de-anonymization as
a maximum likelihood estimation problem and develop an uncon-
strained optimization fraud de-anonymization algorithm. We intro-
duce a graph based deep learning approach to predict co-ownership
of fraudulent account pairs, and use it to build discriminative fraud
de-anonymization and pseudonymous fraudster discovery algo-
rithms. Further, we introduce the first protocol to involve human
fraud workers in the task of evaluating the performance of fraud
de-anonymization algorithms. We show that our solutions achieve
high precision and recall on ground truth data, significantly outper-
form a state-of-the-art approach and are able to attribute thousands
of new accounts to known crowdsourced fraudsters.
ACKNOWLEDGMENTS
We thank the anonymous reviewers for their insightful feedback.
This research was supported by NSF grant CNS-1527153 and by the
Florida Center for Cybersecurity.
REFERENCES
[1] [n. d.]. Freelancer. http://www.freelancer.com.
[2] [n. d.]. The FTC’s Endorsement Guides: What People Are Asking. https://tinyurl.
com/p7hk9uz.
[3] [n. d.]. Upwork Inc. https://www.upwork.com.
[4] 2012. Yelp tries public shaming to discourage businesses from gaming re-
views and ratings. Digital Trends, https://www.digitaltrends.com/social-media/
yelp-cracking-down-on-fake-reviews/.
[5] 2013. Google I/O 2013 - Getting Discovered on Google Play. www.youtube.com/
[6] 2013. Why does Yelp hide reviews? Washington Post https://www.youtube.com/
watch?v=5Od2SuL2igA.
watch?v=s1lJuu44cJA.
[7] Last accessed November 2016. App Reviews. http://www.app-reviews.org.
[8] Last accessed November 2016. App Such. http://www.appsuch.com.
[9] Last accessed November 2016. Apps Viral. http://www.appsviral.com/.
[10] Last accessed November 2016. Rank Likes. http://www.ranklikes.com/.
[11] Last accessed November 2016.
The Social Marketeers.
http://www.
thesocialmarketeers.org/.
[12] Leman Akoglu, Rishi Chandy, and Christos Faloutsos. 2013. Opinion Fraud
Detection in Online Reviews by Network Effects. In Proceedings of AAAI ICWSM.
[13] Muhammad AL-Qurishi, Mabrook Alrakhami, Atif Alamri, Majed Alrubaian,
Sk Md Mizanur Rahman, and M Hossain. 2017. Sybil Defense Techniques in
Online Social Networks: A Survey. PP (01 2017), 1–1.
[14] Mishari Almishari and Gene Tsudik. 2012. Exploring linkability of user reviews.
In European Symposium on Research in Computer Security. Springer, 307–324.
[15] Athanasios Andreou, Oana Goga, and Patrick Loiseau. 2017. Identity vs. Attribute
Disclosure Risks for Users with Multiple Social Profiles. In Proceedings of the
IEEE/ACM International Conference on Advances in Social Networks Analysis and
Mining. 163–170.
[16] Michael Backes, Pascal Berrang, Oana Goga, Krishna P Gummadi, and Praveen
Manoharan. 2016. On profile linkability despite anonymity in social media
systems. In Proceedings of the 2016 ACM on Workshop on Privacy in the Electronic
Society. 25–35.
[17] Prudhvi Ratna Badri Satya, Kyumin Lee, Dongwon Lee, Thanh Tran, and Ja-
son Jiasheng Zhang. 2016. Uncovering Fake Likers in Online Social Networks. In
Proceedings of the ACM CIKM.
[18] Alex Beutel, Wanhong Xu, Venkatesan Guruswami, Christopher Palow, and Chris-
tos Faloutsos. 2013. CopyCatch: Stopping Group Attacks by Spotting Lockstep
Behavior in Social Networks. In Proceedings of the WWW.
[19] A. Broder. 1997. On the Resemblance and Containment of Documents. In Pro-
ceedings of the Compression and Complexity of Sequences 1997 (SEQUENCES ’97).
IEEE Computer Society, Washington, DC, USA, 21–. http://dl.acm.org/citation.
cfm?id=829502.830043
[20] Qiang Cao, Michael Sirivianos, Xiaowei Yang, and Tiago Pregueiro. 2012. Aid-
ing the Detection of Fake Accounts in Large Scale Social Online Services. In
Presented as part of the 9th USENIX Symposium on Networked Systems De-
sign and Implementation (NSDI 12). USENIX, San Jose, CA, 197–210. https:
//www.usenix.org/conference/nsdi12/technical-sessions/presentation/cao
[21] Nitesh V. Chawla, Kevin W. Bowyer, Lawrence O. Hall, and W. Philip Kegelmeyer.
2002. SMOTE: Synthetic Minority Over-sampling Technique. J. Artif. Int. Res. 16,
1 (June 2002), 321–357. http://dl.acm.org/citation.cfm?id=1622407.1622416
[22] Nicholas Confessore, Gabriel Dance, Richard Harris, and Mark Hansen. 2018.
The Follower Factory. The New York Times (Jan 2018). https://www.nytimes.
com/interactive/2018/01/27/technology/social-media-bots.html
[23] George Danezis and Prateek Mittal. 2009. SybilInfer: Detecting Sybil Nodes using
Social Networks. In NDSS.
[24] Emiliano De Cristofaro, Arik Friedman, Guillaume Jourjon, Mohamed Ali Kaafar,
and M. Zubair Shafiq. 2014. Paying for Likes?: Understanding Facebook Like Fraud
Using Honeypots. In Proceedings of the 2014 Conference on Internet Measurement
Conference (IMC ’14). 129–136.
[25] John R. Douceur. 2002. The Sybil Attack. In International workshop on peer-to-peer
systems. 251–260.
[26] Amir Fayazi, Kyumin Lee, James Caverlee, and Anna Squicciarini. 2015. Un-
covering Crowdsourced Manipulation of Online Reviews. In Proceedings of the
38th International ACM SIGIR Conference on Research and Development in In-
formation Retrieval (SIGIR ’15). ACM, New York, NY, USA, 233–242. https:
//doi.org/10.1145/2766462.2767742
[27] Geli Fei, Arjun Mukherjee, Bing Liu, Meichun Hsu, Malu Castellanos, and Rid-
dhiman Ghosh. 2013. Exploiting Burstiness in Reviews for Review Spammer
Detection. In Proceedings of AAAI ICWSM.
[28] Fiverr. [n. d.]. https://www.fiverr.com/.
[29] Jerome Friedman, Trevor Hastie, and Robert Tibshirani. 2010. Regularization
Paths for Generalized Linear Models via Coordinate Descent. Journal of Statistical
Software 33, 1 (2010), 1–22. http://www.jstatsoft.org/v33/i01/
[30] Oana Goga, Howard Lei, Sree Hari Krishnan Parthasarathi, Gerald Friedland,
Robin Sommer, and Renata Teixeira. 2013. Exploiting innocuous activity for
correlating users across sites. In Proceedings of the 22nd international conference
on World Wide Web. 447–458.
[31] Atefeh Heydari, Mohammadali Tavakoli, and Naomie Salim. 2016. Detection
of Fake Opinions Using Time Series. Expert Syst. Appl. 58, C (Oct. 2016), 83–92.
https://doi.org/10.1016/j.eswa.2016.03.020
[32] Bryan Hooi, Neil Shah, Alex Beutel, Stephan Günnemann, Leman Akoglu, Mohit
Kumar, Disha Makhija, and Christos Faloutsos. 2015. BIRDNEST: Bayesian
Inference for Ratings-Fraud Detection. CoRR abs/1511.06030 (2015).
[33] Bryan Hooi, Hyun Ah Song, Alex Beutel, Neil Shah, Kijung Shin, and Christos
Faloutsos. 2016. FRAUDAR: Bounding Graph Fraud in the Face of Camouflage.
In Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining (KDD ’16). ACM, New York, NY, USA, 895–904. https:
//doi.org/10.1145/2939672.2939747
[34] Paridhi Jain, Ponnurangam Kumaraguru, and Anupam Joshi. 2013. @ i seek’fb.
me’: Identifying users across multiple online social networks. In Proceedings of
the 22nd international conference on World Wide Web. ACM, 1259–1268.
[35] Nitin Jindal and Bing Liu. 2008. Opinion spam and analysis. In Proceedings of the
international conference on Web search and web data mining (WSDM ’08). ACM,
New York, NY, USA, 219–230. https://doi.org/10.1145/1341531.1341560
[36] Parisa Kaghazgaran, James Caverlee, and Majid Alfifi. 2017. Behavioral Analysis
of Review Fraud: Linking Malicious Crowdsourcing to Amazon and Beyond.. In
Proceedings of ICWSM.
[37] Parisa Kaghazgaran, James Caverlee, and Anna Squicciarini. 2018. Combat-
ing Crowdsourced Review Manipulators: A Neighborhood-Based Approach.
In Proceedings of the Eleventh ACM International Conference on Web Search
and Data Mining (WSDM ’18). ACM, New York, NY, USA, 306–314.
https:
//doi.org/10.1145/3159652.3159726
[38] David R Karger. 1993. Global Min-cuts in RNC, and Other Ramifications of a
Simple Min-Cut Algorithm.. In SODA, Vol. 93.
[39] Georgios Kontaxis, Iasonas Polakis, Sotiris Ioannidis, and Evangelos P Markatos.
2011. Detecting social network profile cloning. In Pervasive Computing and Com-
munications Workshops (PERCOM Workshops), 2011 IEEE International Conference
on. IEEE, 295–300.
[40] Srijan Kumar, Justin Cheng, Jure Leskovec, and V.S. Subrahmanian. 2017. An
Army of Me: Sockpuppets in Online Discussion Communities. In Proceedings of
the 26th International Conference on World Wide Web (WWW ’17). International
World Wide Web Conferences Steering Committee, Republic and Canton of
Geneva, Switzerland, 857–866. https://doi.org/10.1145/3038912.3052677
[41] Srijan Kumar, Bryan Hooi, Disha Makhija, Mohit Kumar, Christos Faloutsos, and
V. S. Subrahmanian. 2018. REV2: Fraudulent User Prediction in Rating Platforms.
In Proceedings of the ACM International Conference on Web Search and Data Mining.
333–341.
[42] Kyumin Lee, Steve Webb, and Hancheng Ge. 2014. The Dark Side of Micro-Task
Marketplaces: Characterizing Fiverr and Automatically Detecting Crowdturfing.
https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/view/8078
[43] Huayi Li, Zhiyuan Chen, Arjun Mukherjee, Bing Liu, and Jidong Shao. 2015.
Analyzing and Detecting Opinion Spam on a Large-scale Dataset via Temporal
and Spatial Patterns. In Proceedings of ICWSM. AAAI Press, 634–637.
[44] Huayi Li, Geli Fei, Shuai Wang, Bing Liu, Weixiang Shao, Arjun Mukherjee,
and Jidong Shao. 2017. Bimodal Distribution and Co-Bursting in Review Spam
Detection. In Proceedings of the 26th International Conference on World Wide Web
(WWW ’17). International World Wide Web Conferences Steering Committee,
Republic and Canton of Geneva, Switzerland, 1063–1072. https://doi.org/10.
1145/3038912.3052582
[45] Changchang Liu, Peng Gao, Matthew Wright, and Prateek Mittal. 2015. Exploiting
Temporal Dynamics in Sybil Defenses. In Proceedings of the 22Nd ACM SIGSAC
Conference on Computer and Communications Security (CCS ’15). ACM, New York,
NY, USA, 805–816. https://doi.org/10.1145/2810103.2813693
[46] Michael Luca and Georgios Zervas. 2016. Fake It Till You Make It: Reputation,
Competition, and Yelp Review Fraud. In Management Sciences. 3412–3427.
[47] Arjun Mukherjee, Abhinav Kumar, Bing Liu, Junhui Wang, Meichun Hsu, Malu
Castellanos, and Riddhiman Ghosh. 2013. Spotting Opinion Spammers Using
Behavioral Footprints. In Proceedings of ACM KDD.
[48] Arjun Mukherjee, Bing Liu, and Natalie Glance. 2012. Spotting Fake Reviewer
Groups in Consumer Reviews. In Proceedings of ACM WWW.
Blog,
[49] Arjun Mukherjee, Vivek Venkataraman, Bing Liu, and Natalie Glance. 2013.
What Yelp Fake Review Filter Might Be Doing. In Proceedings of the International
Conference on Weblogs and Social Media.
[50] Kazushi Nagayama and Andrew Ahn. 2016.
trusted: fighting fraud and spam installs.
Store
velopers
keeping-the-play-store-trusted-fighting-fraud-and-spam-installs.html.
Keeping the Play
Android De-
https://android-developers.googleblog.com/2016/10/
[51] Arvind Narayanan, Hristo Paskov, Neil Zhenqiang Gong, John Bethencourt, Emil
Stefanov, Eui Chul Richard Shin, and Dawn Song. 2012. On the Feasibility of
Internet-Scale Author Identification. In Proceedings of the IEEE Symposium on
Security and Privacy. 300–314.
[52] Arvind Narayanan and Vitaly Shmatikov. 2008. Robust De-anonymization of
Large Sparse Datasets. In Proceedings of the 2008 IEEE Symposium on Security
and Privacy (SP ’08). IEEE Computer Society, Washington, DC, USA, 111–125.
https://doi.org/10.1109/SP.2008.33
[53] Shashank Pandit, Duen Horng Chau, Samuel Wang, and Christos Faloutsos. 2007.
Netprobe: A Fast and Scalable System for Fraud Detection in Online Auction
Networks. In Proceedings of the 16th International Conference on World Wide Web
(WWW ’07). 201–210.
[54] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: Online Learn-
ing of Social Representations. In Proceedings of the International Conference on
Knowledge Discovery and Data Mining. 701–710.
[55] Mahmudur Rahman, Bogdan Carbunar, Jaime Ballesteros, George Burri, and Duen
Horng (Polo) Chau. 2014. Turning the Tide: Curbing Deceptive Yelp Behaviors.
In Proceedings of the SIAM International Conference on Data Mining (SDM).
[56] Mizanur Rahman, Nestor Hernandez, Bogdan Carbunar, and Duen Horng Chau.
2018. Search Rank Fraud De-Anonymization in Online Systems. In Proceedings
of the ACM Conference on Hypertext and Social Media.
[57] Mizanur Rahman, Ruben Recabarren, Bogdan Carbunar, and Dongwon Lee. 2017.
Stateless Puzzles for Real Time Online Fraud Preemption. In Proceedings of the
ACM Web Science Conference (WebSci).