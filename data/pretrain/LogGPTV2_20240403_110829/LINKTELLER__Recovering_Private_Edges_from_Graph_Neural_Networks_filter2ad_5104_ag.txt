GAT, Flickr
ˆk
Method
k/4
k/2
k
2k
4k
Ours
LSA2-post
LSA2-attr
Ours
LSA2-post
LSA2-attr
Ours
LSA2-post
LSA2-attr
Ours
LSA2-post
LSA2-attr
Ours
LSA2-post
LSA2-attr
low
unconstrained
high
precision
8.3 ± 11.8
0.0 ± 0.0
0.0 ± 0.0
14.3 ± 11.7
0.0 ± 0.0
0.0 ± 0.0
20.5 ± 3.6
0.0 ± 0.0
0.0 ± 0.0
10.7 ± 1.9
0.0 ± 0.0
0.0 ± 0.0
5.3 ± 0.9
0.7 ± 0.9
0.3 ± 0.5
recall
2.1 ± 2.9
0.0 ± 0.0
0.0 ± 0.0
5.3 ± 5.3
0.0 ± 0.0
0.0 ± 0.0
12.5 ± 4.5
0.0 ± 0.0
0.0 ± 0.0
12.5 ± 4.5
0.0 ± 0.0
0.0 ± 0.0
12.5 ± 4.5
2.1 ± 2.9
1.1 ± 1.6
precision
21.2 ± 9.7
0.0 ± 0.0
0.0 ± 0.0
19.5 ± 9.3
0.3 ± 0.4
0.0 ± 0.0
12.7 ± 6.4
0.4 ± 0.3
0.1 ± 0.2
7.5 ± 3.8
0.5 ± 0.2
0.1 ± 0.1
5.4 ± 1.5
0.9 ± 0.1
0.0 ± 0.0
recall
5.8 ± 3.3
0.0 ± 0.0
0.0 ± 0.0
9.9 ± 4.4
0.1 ± 0.2
0.0 ± 0.0
12.8 ± 5.8
0.4 ± 0.4
0.1 ± 0.2
15.1 ± 6.5
1.1 ± 0.6
0.1 ± 0.2
21.7 ± 3.8
3.6 ± 0.9
0.1 ± 0.2
precision
36.0 ± 5.6
3.4 ± 0.5
1.3 ± 0.7
26.6 ± 1.4
3.8 ± 0.8
0.6 ± 0.3
18.5 ± 2.1
3.3 ± 0.8
0.3 ± 0.2
12.5 ± 1.0
3.0 ± 0.4
0.2 ± 0.1
7.9 ± 0.7
2.7 ± 0.2
0.1 ± 0.0
low
unconstrained
high
precision
33.3 ± 47.1
0.0 ± 0.0
0.0 ± 0.0
16.7 ± 23.6
0.0 ± 0.0
0.0 ± 0.0
8.3 ± 11.8
0.0 ± 0.0
0.0 ± 0.0
4.2 ± 5.9
0.0 ± 0.0
0.0 ± 0.0
2.2 ± 3.1
0.0 ± 0.0
0.0 ± 0.0
recall
8.3 ± 11.8
0.0 ± 0.0
0.0 ± 0.0
8.3 ± 11.8
0.0 ± 0.0
0.0 ± 0.0
8.3 ± 11.8
0.0 ± 0.0
0.0 ± 0.0
8.3 ± 11.8
0.0 ± 0.0
0.0 ± 0.0
8.3 ± 11.8
0.0 ± 0.0
0.0 ± 0.0
precision
8.3 ± 11.8
0.0 ± 0.0
0.0 ± 0.0
4.8 ± 6.7
0.0 ± 0.0
0.0 ± 0.0
5.9 ± 4.3
0.0 ± 0.0
0.0 ± 0.0
3.0 ± 2.2
0.0 ± 0.0
0.0 ± 0.0
1.5 ± 1.1
0.0 ± 0.0
0.0 ± 0.0
recall
2.4 ± 3.4
0.0 ± 0.0
0.0 ± 0.0
2.4 ± 3.4
0.0 ± 0.0
0.0 ± 0.0
5.7 ± 4.2
0.0 ± 0.0
0.0 ± 0.0
5.7 ± 4.2
0.0 ± 0.0
0.0 ± 0.0
5.7 ± 4.2
0.0 ± 0.0
0.0 ± 0.0
precision
14.5 ± 3.2
0.4 ± 0.5
0.7 ± 1.0
7.3 ± 1.7
0.4 ± 0.3
0.4 ± 0.5
4.2 ± 1.0
0.2 ± 0.2
0.3 ± 0.4
2.6 ± 0.6
0.4 ± 0.2
0.4 ± 0.4
1.3 ± 0.3
0.3 ± 0.0
0.3 ± 0.2
recall
7.8 ± 0.9
0.7 ± 0.1
0.3 ± 0.1
11.5 ± 0.1
1.7 ± 0.4
0.3 ± 0.1
16.0 ± 1.7
2.8 ± 0.6
0.3 ± 0.1
21.7 ± 1.4
5.3 ± 0.5
0.3 ± 0.1
27.5 ± 1.3
9.2 ± 0.5
0.3 ± 0.1
recall
3.6 ± 0.3
0.1 ± 0.1
0.2 ± 0.3
3.6 ± 0.3
0.2 ± 0.1
0.2 ± 0.3
4.2 ± 0.7
0.2 ± 0.1
0.3 ± 0.4
5.1 ± 0.9
0.7 ± 0.4
0.8 ± 0.9
5.1 ± 0.9
1.2 ± 0.2
1.3 ± 0.9
and LAPGRAPH, vanilla GCN models which have no privacy
guarantee, as well as multi-layer perceptron (MLP) models
with only node features. We note that MLP can be viewed as
“perfectly” private since the edge information is not involved.
A. Datasets and Models
We use the datasets described in Section V-A. The DP
GCN models are derived using DP mechanisms EDGERAND
and LAPGRAPH under various privacy guarantees. For each
privacy budget ε, we execute the procedure outlined in Algo-
rithm 2, ﬁrst getting a perturbed copy of the adjacency matrix,
then using the perturbed training graph to train a GCN. We
follow the criteria in Section V-B for parameter searching and
model training, and leave more descriptions to Appendix F4.
We provide an evaluation of the model utility, aiming to
characterize the tradeoff between model utility and the suc-
cess rate of LINKTELLER. In evaluating the utility of the DP
GCNs, we compare with two baseline models: 1) vanilla GCNs
which are expected to have higher utility, though vulnerable to
LINKTELLER as previously shown; 2) MLPs trained only on
node features which may achieve lower classiﬁcation utility
but provide perfect protection of the edge information due to
the non-involvement of edge information in the model.
B. DP GCN against LINKTELLER
We validate the effectiveness of LINKTELLER under various
levels of privacy guarantees. We ﬁrst provide the experimental
setup, followed by concrete results including comparisons of
the attack effectiveness of LINKTELLER on different models.
1) Experimental Setup: We inspect
the effectiveness of
LINKTELLER on DP GCN using the same setup as Sec-
tion V-D. Similar to Section V-E, we use precision and recall
to evaluate the attack. For each dataset, we consider all combi-
nations of 2 DP mechanisms (EDGERAND and LAPGRAPH),
10 privacy budgets (1.0, 2.0, . . . , 10.0), 3 sampling strategies
(low, unconstrained, and high degree), and 5 density beliefs
(k/4, k/2, k, 2k, 4k). The reported result of each scenario is
averaged over 3 runs with different random seeds for sampling.
2) Evaluation Results: We leave the full evaluation results
for all scenarios in Appendix G4 and focus on density belief
ˆk = k here. In Figure 3(b), we plot the F1 score of the attack
w.r.t. DP budget ε. We see that the effectiveness of LINK-
TELLER decreases as a result of applying DP. Particularly, the
F1 score becomes almost 0 when the privacy budget ε becomes
smaller. When ε is large, however, the protection offered by
DP is limited. In these cases, LINKTELLER is able to achieve a
success rate close to that of attacking the non-private baseline.
We also note that the node degree distribution has an impact
on the performance of LINKTELLER. The trend is clear that
as the node degree increases, the attack success rate increases
substantially. Together with our previous observation in the
non-private scenario that the attack success rate does not differ
much for varying node degrees, we conclude that DP can offer
better protection to low degree nodes than high degree nodes.
We offer a simple and intuitive explanation as follows. By the
design of EDGERAND and LAPGRAPH, the perturbations in all
cells of the matrix are independent. As a result, nodes of low
degree (those incident to fewer edges) are more susceptible to
the inﬂuence, and therefore better protected by DP.
C. Model Utility Given DP Protection
We next present the evaluation of the model utility, not only
to complement the evaluation of the DP GCNs, but also to
provide insights about the tradeoff between model utility and
robustness against the LINKTELLER attack.
1) Experimental Setup: We evaluate the inﬂuence of ap-
plying DP (EDGERAND and LAPGRAPH) on the utility of
the GCN models by comparing the results with two baseline
models (a non-private vanilla GCN model and a “perfectly”
private MLP baseline). We adopt the same metric to evaluate
the utility of all four models: F1 score of the rare class for