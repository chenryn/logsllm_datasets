the infected bot and the command server may agree on a
secret coding or encryption in order to hide malicious com-
mands, so as they cannot be covered by clear-text detection
signatures.
For the sake of simplicity, we consider in the remainder of
this paper that the sender role is malicious, and the receiver
is honest. Our encryption protocol applies in the same way
in the context of an honest sender and a malicious receiver.
2.3 A New Security Model
Based on the above remarks, we now formally deﬁne the
security model that represents an ideal intrusion detection
system operating over an encrypted traﬃc. We ﬁrst model
the interactions between actors, and we then describe the
three main security properties that need to be satisﬁed by
the detection system.
We consider a set R of (non-encrypted) rules and a de-
tection algorithm, denoted Detect, taking as input a (non-
encrypted) traﬃc T and the set R. In the sequel, we say
that the traﬃc is malicious iﬀ Detect(T,R) = 0. Otherwise,
the traﬃc is safe and Detect(T,R) = 1. In both cases, some
auxiliary information aux can be also provided as output to
the detection algorithm. We also consider in our model that
the detection procedure can output more detailed informa-
tion (for example the number of malicious patterns that has
been recognized1).
Model for interactions. An intrusion detection system
over an encrypted traﬃc, denoted π, and played by the four
actors Service Editor (SE), Service Provider (SP), Sender
(S) and Receiver (R), is composed of ﬁve main procedures.
• Setup, on input the security parameter λ, generates
the public parameters param of the system, and the
potential keys of the actors. When an actor A (A ∈
{SE, SP, S, R}) manages a cryptographic key, we al-
ways consider that there is a key pair (skA, pkA) where
skA is secret and only known by A, and pkA is pub-
licly available. The latter key may be empty (in case
of a secret key based solution). Such a procedure can
be uniquely executed by one actor, or played by sev-
eral ones (for example, each actor A can create his/her
own keys). We consider that all public keys are now
included in the parameters param.
• RuleGen, on input the parameters param, the SE secret
key skSE and a set R of rules to detect a malicious
traﬃc, outputs a set B of blinded rules that are then
sent to SP.
• Send takes as input the public parameters param, po-
tentially the secret key skS of the sender and the public
key pkR of a receiver R, and a traﬃc T . It outputs an
encrypted traﬃc E for receiver R.
1Even if the pattern itself remains unknown by the Service
Provider executing the detection algorithm. For example,
in our construction, SP knows which trapdoor matches, but
does not know the underlying keyword, see Section 5 for
details.
563π,A(λ)
Experiment Expdet
(param, skSE, skR) ← Setup(1λ);
B ← RuleGen(param, skSE,R);
E ← A(1λ, param);
if Detect(param, E,B) = 1, then return 0;
T ← Receive(param, skR, E);
if Detect(T,R) = 0, then return 0.
return 1;
π,A (λ)
Experiment Exptr−ind
b ← {0, 1};
(param, skSE, skR) ← Setup(1λ);
T0, T1 ← A(1λ, param);
if type(T0, T1) = 0, return 0;
Eb ← Send(param, Tb);
b(cid:48) ← A(Eb);
return (b = b(cid:48));
Figure 1: Detection experiment
Figure 2: Traﬃc indistinguishability experiment
• Detect, on input param, the Service Provider public
key pkSP (if it exists), an encrypted traﬃc E and the
set B of blinded rules from SE, outputs a bit b ∈ {0, 1},
stating that the underlying traﬃc T is malicious (b =
0) or safe (b = 1). It may also return some auxiliary
information aux, such as for example the blinded rule
that matched. If something goes wrong, it outputs an
error message ⊥.
• Receive is executed by taking on input the parameters
param, the receiver’s secret key skR and an encrypted
traﬃc E. It outputs a plain traﬃc T , or an error mes-
sage ⊥.
Remark 1. After the execution of the procedure Setup
to generate the public parameters param and the keys, we
denote B = RuleGen(param, skSE,R) where R is the set of
rules, and E = Send(param, skS, pkR, T ) where T is a traﬃc.
An intrusion detection system over an encrypted traﬃc is
said correct iﬀ
T = Receive(param, skR, pkS, E), and
Detect(T,R) = Detect(param, E,B) (including aux).
Model for security properties. As sketched in the previ-
ous section, there are mainly three security properties that
should be veriﬁed by such a system. We call the ﬁrst one
the detection property, the second one the traﬃc indistin-
guishability property, and the last one the signature indis-
tinguishability property.
Detection. Informally speaking, the detection property sta-
tes that any malicious traﬃc (that is a traﬃc considered
as malicious when not encrypted) must be detected by the
Service Provider in the proposed intrusion detection sys-
tem over encrypted traﬃc. This is related to the security-
awareness feature, and gives a way to guarantee the correct-
ness of the detection.
More formally, we give the experiment in Figure 1, for
an adversary A. On input the parameters, A outputs an
encrypted traﬃc E such that Detect(param, E,B) = 1 (that
is stated as safe) while the decrypted version T is malicious
(that is Detect(T,R) = 0).
Then, an intrusion detection system over encrypted traﬃc
π is said detectable if for any probabilistic polynomial-time
A, there exists a negligible function ν(λ) such that:
(cid:104)
(cid:105) ≤ ν(λ).
Succdet
π,A(λ) = Pr
Expdet
π,A = 1
Traﬃc indistinguishability. The traﬃc indistinguishability
property informally states that it is not feasible for the Ser-
vice Provider to learn any information about the traﬃc,
other than it is malicious or safe. We here focus on the
privacy-friendly feature, that is no access to the clear-text
content is possible.
In a traditional indistinguishability property, the adver-
sary chooses two messages and should not be able to distin-
guish which of the two is encrypted by the challenger. In
our context, we have the problem that the adversary may
choose one malicious traﬃc and one safe traﬃc so that it
will be easy to distinguish which one is used by the chal-
lenger, simply by applying the Detect algorithm. Moreover,
the detection algorithm can also give to A some auxiliary in-
formation aux about the type of attack, so that it can choose
the two messages accordingly. We then introduce the notion
of type for a traﬃc, using the following deﬁnition.
Definition 1
(Traffic Type). Let T0 and T1 be two
traﬃcs and let R be a set of rules. We say that T0 and T1
are of the same type, denoted type(T0, T1) = 1, iﬀ
Detect(param, T0,R) = Detect(param, T1,R),
including the auxiliary information aux.
More formally, we then give the traﬃc indistinguishability
experiment in Figure 2, for an adversary A having access
to both a Receive oracle (given an encrypted traﬃc E of its
choice, A obtains the related plain traﬃc E) and the RuleGen
oracle (given a set of rules R of its choice, the adversary
gets back B ← RuleGen(param, skSE,R)). The adversary
ﬁrst chooses two traﬃcs T0 and T1 and, if they have the
same type, one of them, Tb is encrypted and given to A.
Eventually, A has to guess the bit b.
Then, an intrusion detection system over encrypted traf-
ﬁc π is said traﬃc-indistinguishable if for any probabilistic
polynomial-time A, there exists a negligible function ν(λ)
such that:
Advtr−ind
π,A (λ) =
Exptr−ind
π,A = 1
(cid:12)(cid:12)(cid:12) ≤ ν(λ).
(cid:105) − 1
(cid:104)
(cid:12)(cid:12)(cid:12)2 · Pr
Rule indistinguishability. Finally, the rule indistinguishabil-
ity property informally states that it is not feasible for the
Service Provider to learn any information about the rules.
Here, we treat the market-compliant feature, as it ensures
the privacy of the pattern signatures.
Again, we need to handle the fact that the Service Provider
can create any traﬃc of its choice, and make use of the en-
crypted rules to test them and learn some information. This
is a brute-force attack on the signatures, sending a lot of
(random) traﬃc to guess the logic behind the rules. This is
a typical test for security solutions and it works for both en-
crypted and non-encrypted rules: an intrusion detection sys-
tem over encrypted traﬃc cannot resist such an attack, and
564(λ)
π,A
Experiment Exprul−ind
b ← {0, 1};
(param, skSE, skR) ← Setup(1λ);
R0,R1 ← Af (1λ, param);
Bb ← RuleGen(param, skSE,Rb);
b(cid:48) ← Ag(skR,Bb);
return (b = b(cid:48));
Figure 3: Rule indistinguishability experiment
it should not be considered in the model. The main point is
that the SP cannot learn any information other than what
is provided as output to the Detect algorithm. Our idea is
then to use the high-min entropy property, which informally
states that the adversary cannot obtain the rule “by chance”.
More formally, we use the following deﬁnition (see e.g., [10]).
Definition 2
(Min-entropy). A probabilistic adver-
∀λ ∈ N ∀r ∈ R : Pr(cid:2)r
sary A = (Af ,Ag) has min-entropy µ if
(cid:48) ← Af (1λ, b) : r
−µ(λ) .
A is said to have high min-entropy if it has min-entropy µ
with µ(λ) ∈ ω(log λ).
= r(cid:3) ≤ 2
(cid:48)
The experiment related to rule indistinguishability is given
in Figure 3, for an adversary A = (Af ,Ag) with high-min
entropy (considering that Af and Ag cannot communicate
one to each other, as in e.g., [10]), that can create any traﬃc
of its choice. In a nutshell, the adversary Af chooses two
sets of rules R0 and R1, and one of them is used in the
RuleGen procedure. The output Bb is then given to Ag, that
eventually outputs the bit b.
Then, an intrusion detection system over encrypted traf-
ﬁc π is said rule-indistinguishable if for any probabilistic
polynomial-time A = (Af ,Ag) having high-min entropy,
there exists a negligible function ν(λ) such that:
Advrul−ind
π,A
(λ) =
Exprul−ind
π,A
= 1
(cid:104)
(cid:12)(cid:12)(cid:12)2 · Pr
(cid:105) − 1
(cid:12)(cid:12)(cid:12) ≤ ν(λ).
3. TECHNICAL CONTRIBUTIONS
We review in this section related work on application-level
security functions applied to encrypted traﬃc. We empha-
size on the BlindBox approach wich is the closest to our
work [25], and then we detail the main technical contribu-
tions of our work compared to BlindBox.
3.1 Related Work
Related work includes multiple recent studies that address
security requirements in the context of encrypted network
traﬃc. Authors in [16] provide a survey of main contri-
butions on intrusion detection over encrypted traﬃc. The
focus in [16] was exclusively on traﬃc analysis, using high
level features of the traﬃc, such as packet size, entropy, and
application identiﬁcation. Further statistics and machine
learning techniques applied to these features enable to de-
tect speciﬁc attack types such as scan attempts [29], denial
of service [7], and brute force [8, 9]. These statistical tech-
niques are mostly agnostic to the encryption protocol. They
do not support any DPI functionality, and apply in the same
way to both encrypted and clear-text traﬃc.
In [30], authors introduce a framework called QoS2 that
enables network middleboxes delivering encrypted content
to support performance-oriented capabilities such as con-
tent caching. QoS2 extends web servers with the ability
to serve mixed-content, including both encrypted and clear-
text content within the same connection. The main con-
cept is that content providers can separate private content
(to be sent over HTTPS) from other public content that is
sent over HTTP. QoS2 prevents man-in-the-middle attacks
by generating checksums for all public content and sending
these checksums over secure HTTPS connection. Content
caching will be further supported by network middleboxes
based only on the public content in each connection. Hence,
QoS2 limits itself to the public content delivered over regular
HTTP, but no security operations such as DPI are possible
for the private content. A malicious provider may thus dis-
simulate malicious content in the private connection, with-
out the possibility for network middleboxes to detect the
malicious content through DPI.
In [18], authors propose a deep packet ﬁltering protocol
that leverages the Software-Deﬁned-Networking paradigm
in order to supply ﬁltering functions over encrypted traf-
ﬁc. In this protocol, the service provider (SP) ﬁrst informs
the sender about the header ﬁelds that need to be inspected
for each new network connection. Then the sender and the
SP run an interactive protocol to encrypt the set of detec-
tion rules, where the sender inputs a self-generated key, and
the provider inputs the set of ﬁltering rules. The protocol
in [18] suﬀers from two main limitations. First, the ﬁlter-
ing rules are encrypted once for every single HTTPS con-
nection, which makes it hard to scale in large real-world
deployment scenarios. Second, the SP informs the sender
about the header ﬁelds that will be inspected by the ﬁlter-
ing rules, which requires the SP to have full access to these
rules in clear-text. This clearly does not ﬁt with the real-
world constraints for the security market ecosystem.
Melis et al. propose in [20, 6] a new solution that enables
the privacy-preserving outsourcing of network functions in
the cloud. The contribution in [20, 6] is similar to our work
by means of protecting the privacy of sensitive security poli-
cies against curious service providers. Nonetheless, it only
applies in private network environments. It requires an exit
gateway for the enterprise network to encrypt clear-text traf-
ﬁc content and to forward it to the cloud-based security func-
tion. Our solution is diﬀerent as it enables to encrypt the
traﬃc in an end-to-end way between the sender and receiver
of a network connection. It preserves the privacy of both se-
curity policies and the content of network communications.
The closest work to our contribution is BlindBox [25] and
its extension Embark that supports its outsourcing to the
cloud [17]. BlindBox uses multi-party computation such as
garbled circuits and oblivious transfers, and supports DPI
through three distinct detection protocols. The ﬁrst pro-
tocol enables the SP to search for patterns or keywords at
random locations in the encrypted traﬃc. The second pro-
tocol extends the ﬁrst one by enabling also to search for
patterns at speciﬁc oﬀsets. Finally, the third protocol sup-
ports probable cause decryption. It allows the SP to decrypt