(line 24 to 52 then jump to 21 for T0, line 39 to 54, then jump
to 21 for T1).
load,v + T i
w is denoted by T (I i
The execution time of these code segments depends on
their instructions and the memory hierarchy v on which the
data access (to variable V) operation w is performed (i.e.,
memory access latency). Therefore, the execution time of the
w, v), where i ∈ {0, 1}
code segment I i
and v ∈ {L1, L2, LLC, Memory}. We further denote T i
w,v =
T (I i
w, v) for short. As such, the period of thread Ti’s one
iteration of the store and load sequence (line 22 to 52, then
jump to 21 for T0, line 22 to 54, jump to 21 for T1) is
v = T i
Ri
store,v, i.e., the time between two adjacent
load instructions’ retirements of thread Ti when the data
accesses take place in memory hierarchy v.
We use variable Gv,u, where u ∈ {c, nc}, to denote the
communication time, i.e., the time that the updated state of V
appears in the other thread’s memory hierarchy v, after one
thread modiﬁes the shared variable V, if two threads are co-
located (u = c) or not co-located (u = nc).
Consider the data race happens in memory hierarchy v. If
T i
store,v  190 cycles (the
latency of cross-core communication). According to Table III,
store,v = 88.70. Therefore, Gv,c <
store,v = 95.90 and T 1
T 0
T i
store,v < Gv,nc, i ∈ {0, 1}. As such, data races will happen
only if the two threads are co-located. Altering the CPU
frequency will not change the analysis. According to Fig. 6,
store,v and Gv,nc.
frequency changes have similar effects on T i
That is, when the CPU frequency is reduced, both T i
and Gv,nc will increase, with similar derivatives. As a result,
when the adversary places T0 and T1 on different cores, and
reduces the frequency of these two cores, their communication
store,v
speed will be slowed down at the same pace as the slowdown
of the execution.
2) LLC Data Races: We next consider the cases where v =
{LLC}. This may happen when the adversary PRIMEs the
private caches used by T0 and T1 (from co-located logical
cores) to evict the shared variable V to the LLC.
Effects of cache PRIMEs. The data races can occur on the
shared LLC when the copies of V in the private L1 and
L2 caches are invalidated, which can only be achieved by
having an attacking thread frequently PRIMEing the shared
L1/L2 caches from the co-located logical core. To counter
such attacks, thread T0 and T1 both include in their padding
instructions redundant load instructions (i.e., line 46 to 49 of
T0 and line 42 to 50 of T1 in Fig. 2). These load instructions
precede the load instruction that measures data races, thus
they effectively pre-load V into the L1/L2 caches to prevent the
adversary’s PRIMEs of related cache lines. This mechanism not
only defends against attempts to PRIME local L1/L2 caches,
but TLBs and paging structure caches.
Discussion. According to our measurement study, the time
needed to PRIME one cache set in L1 and one cache set
in L2 (to ensure that V is not in L1 and L2 cache) is at
least 10 × (wL2 − 1) + 40 × 1 cycles (wL2 is the number
of cache lines in one L2 cache set), which is signiﬁcantly
larger than the interval between the pre-load instructions and
the actual load instruction (i.e., 1 cycle). Moreover, because
CPU frequency changes are effective on both logical cores of
the same physical core, altering CPU frequency will not help
the adversary. Therefore, we conclude that data race cannot
happen on LLC.
3) Data Races in Main Memory: We next consider the
cases where v = {M emory}. This may happen when the
adversary (1) PRIMEs the caches, (2) invalidates the caches,
or (3) disables the caching.
Latency of cache invalidation instructions. According to
Intel software developers manual [26, Chapter 8.7.13.1], the
wbinvd instruction executed on one logical core can in-
validate the cached data of the other logical core of the
same physical core. Directly measuring the latency of cache
187
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:38:29 UTC from IEEE Xplore.  Restrictions apply. 
 1e+06
 100000
)
s
e
c
n
a
t
s
n
i
(
#