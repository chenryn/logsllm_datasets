defined as
𝑔𝑙 (𝑥) =
(cid:26) v1𝑙 + v2𝑙
1(cid:1)
(5) P1 outputs 𝐾1 =(cid:0)𝐾𝑙
𝑝=1 SPFSS.Eval(cid:0)𝑏, 𝐾
Output𝜅
Expansion (MPFSS.Eval(𝑏, 𝐾𝑏, 𝑥)):
ℎ𝑝 (𝑥)
𝑏
0
1, 𝐾𝑙
2), with 𝑔𝑙 : [|𝐼𝑙|] → F
if 𝑇 [𝑙] ≠ ⊥ and 𝑥 = pos𝑙 (𝑇 [𝑙]),
otherwise.
2(cid:1)
𝑙∈[𝑚] and P2 outputs 𝐾2 =(cid:0)𝐾𝑙
, posℎ𝑝 (𝑥)(𝑥)(cid:1).
𝑙∈[𝑚].
However, as we will see at the end of this section, this step can be
omitted in the special case of Vector OLE.
In Steps (4) and (5), we generate and return SPFSS keys for each
of the buckets, where the values are the shares obtained in the
previous step, and the indexes are known to P2. Note that, since
𝑚 ≥ 𝑡, some positions in 𝑇 might be empty, so those instances have
the zero function associated to them (which is known only to P2).
Finally, the evaluation of an MPFSS key on an input 𝑥 is the sum
the evaluations of the SPFSS keys corresponding to the buckets into
which 𝑥 is mapped by the cuckoo hash functions.
Lemma 5.1. Assume a secure Known-Index SPFSS scheme with a
secure two-party key generation protocol, both with security param-
eter 𝜆. Then Protocol 4 implements a secure two-party protocol for
generating Known-Indices MPFSS keys in the semi-honest model with
statistical security 𝜂. Using Yao garbled circuits to instantiate step (2),
the 𝑀𝑃𝐹𝑆𝑆.𝐺𝑒𝑛 protocol is constant round, and requires 𝑂(𝑚𝜆 log 𝑛)
communication and 𝑂(𝜆𝜅𝑛 + 𝜆𝑚 log 𝑛) local computation per party,
where (𝑚, 𝜅) = ParamGen(𝑛, 𝑡, 𝜂) are cuckoo hashing parameters.
9
Protocol 5: MPFSS Optimization for VOLE
Public Params: Input domain [𝑛], number of points 𝑡,
hash table size 𝑚 = ˜𝑂(𝑡), and number of hash functions 𝜅.
Point function 𝑓i,𝑥y : [𝑛] → F, 𝑓i,𝑥y(𝑖 𝑗) = (𝑥y)𝑗 for all
𝑗 ∈ [𝑡], 𝑓i,𝑥y( 𝑗′) = 0 for all other inputs.
Parties: P1, P2
Inputs: P1: 𝑥; P2: 𝑖1, . . . 𝑖𝑡, 𝑦1, . . . , 𝑦𝑡
Key Generation (MPFSS.Gen(1𝜆, 𝑓i,𝑥y)):
1,2 These are the same as in Protocol 4.
(3a) Let u = ((𝑦 𝑗 , 𝑙 𝑗))𝑗 ∈[𝑡], where 𝑙 𝑗 is the location of 𝑖 𝑗 in
𝑇 . P2 locally computes the vector w ∈ F𝑚 defined as:
(cid:26) 𝑎
0
w𝑗 =
if (𝑎, 𝑗) ∈ u,
otherwise.
(3b) The parties run an MPC to compute shares of v = 𝑥w.
(4, 5) The rest of the protocol is as Protocol 4.
Proof Sketch. We outline the intuition for the proof of Lemma 5.1
here and provide the full proof in Appendix A.3. Proving the security
of the MPFSS protocol involves two steps: first, proving that the keys
generated from the generation algorithm satisfy the FSS security
requirements, and second, proving the generation protocol is a
secure two party computation protocol that reveals to each party
only its corresponding key. The first claim follows directly from
the security guarantee of the SPFSS construction used to generate
a key for each bucket. We prove this formally in Theorem A.8. The
second claim follows from the security of the two party protocol
used for the SPFSS key generation, which we prove formally in
Theorem A.9.
The communication and computation for the garbled circuit used
for Step (2) is 𝑂(𝜆𝑚 log 𝑚) since it needs to implement an oblivious
permutation protocol over 𝑚 items. For each SPFSS instance in
Step (3), we need 𝑂(𝜆 log 𝑛) communication, since in the worst
case each bucket has size 𝑂(𝑛). The computation that each party
does includes simple hashing of all elements in 𝑂(𝜆𝜅𝑛), SPFSS
distributed key generation for each bucket in 𝑂(𝜆𝑚 log 𝑛) and the
MPFSS evaluation in 𝑂(𝜆𝜅𝑛).
An Optimization for Vector-OLE. We leverage another observa-
tion related to the use of MPFSS in the context of vector OLE, which
allows us to construct a more efficient solution. In the VOLE gener-
ator of Boyle et al. [9], the non-zero values for 𝑡-point MPFSS are
of the form 𝑥𝑦1, . . . , 𝑥𝑦𝑡, where one party knows the indices of the
non-zero function values and 𝑦1, . . . , 𝑦𝑡, and the other party knows
𝑥. Thus, we can have a secure two party computation protocol
where one party inputs 𝑦1, . . . , 𝑦𝑡 padded with zero up to the size
of the cuckoo table, in the order in which they are mapped to the
cuckoo bins, and the other party inputs 𝑥. The protocol multiplies
𝑥 with the permuted vector and outputs shares of the result to the
two parties. That way, we can generate the MPFSS keys needed
for VOLE generation without the expensive secure permutation in
Step (3), and instead use a cheap multiplication protocol such as
Gilboa multiplication [31].
6 DISTRIBUTED PSEUDORANDOM VOLE
FROM MULTI-POINT FSS
In this section we present a new construction for two party com-
putation of pseudorandom vector OLE that relies on multi-point
function secret sharing. The main difference between our construc-
tion and the reduction described in the work of Boyle et al. [9] is
the observation that the multi-point function that the two parties
evaluate does not need to be completely hidden from both of them,
since one of the keys contains the non-zero points in the clear.
Thus, it suffices to use our distributed Known-Indices MPFSS from
the previous section. We present our construction in Protocol 6.
The goal of a pseudorandom VOLE is to enable two parties P1
and P2 to obtain the following correlated outputs: P1 obtains vec-
tors u and v, and P2 obtains integer value 𝑥 and a vector w such
that u𝑥 + v = w. The requirements for these correlated outputs
are that 1) u and v do not reveal information about 𝑥 and 2) given
w, u and v are indistinguishable from random vectors generated
subject to the above relation. Without any further efficiency con-
straints the above functionality can be realized using standard MPC
techniques. However, the goal here is to generate a VOLE correla-
tion with much less communication than the length of the vectors.
In this case, distributed VOLE faces the same problems as other
correlation generators (cf. Section 2.6 and Boyle et al. [11]), i.e.,
that protocol messages of sublinear size can’t be simulated from an
ideal uniform output. Hence, the VOLE functionality is divided into
two parts: an interactive setup protocol VOLE.Setup that produces
short seeds for each party, and an expansion protocol VOLE.Expand
that involves only local computation in which each party expands
the short seed it has obtained from the setup to generate its long
output vectors. It was shown that if these two phases satisfy Defi-
nition 2.3, the resulting pseudorandom correlation can securely be
used for various applications of VOLE, such as secure arithmetic
computation [9, 11].
The idea of the construction of Boyle et al. [9] is to start from
short vector a, b and c of length 𝑘 < 𝑛 that have the required
correlation, i.e., c = a𝑥 + b, which the two parties can generate
efficiently using MPC, and to expand them to long pseudorandom
vectors using the LPN assumption. This assumption states that for
appropriate code generating matrix C ∈ F𝑘×𝑛, the vector u = a·C+𝝁
is pseudorandom, where 𝝁 is a sparse random vector. Now if we
compute v = b · C − 𝝂1 and w = c · C + 𝝂2, where 𝝂1 and 𝝂2
are shares of 𝝁𝑥, we will achieve the correctness property that
u𝑥 + v = w. Additionally, in order to get security, we need that 𝝂1
and 𝝂2 are pseudorandom and do not reveal any information about
𝝁𝑥. This guarantees the pseudorandom properties of u and v under
the correlation and that 𝝂1 (and hence u and v) does not reveal any
information about 𝑥.
Given the above idea, the heart of the VOLE generation is obtain-
ing the shares 𝝂1 and 𝝂2 in a communication efficient manner. Boyle
et al. [9] propose using a distributed multi-point FSS protocol. Our
observation is that this functionality is more than what is needed
for the pseudorandom VOLE construction. More specifically, an FSS
protocol will guarantee that both shares 𝝂1 and 𝝂2 do not reveal any
information about the multi-point function defined by 𝝁𝑥. However,
while 𝑥 needs to remain hidden, 𝝁 is revealed to P1, which in turn
reveals the non-zero indices of 𝝁𝑥 = 𝝂1 + 𝝂2. This observation is
Protocol 6: Distributed Vector OLE
Public Params: Vector length 𝑛, LPN parameters 𝑡, 𝑘, code
generating matrix C ∈ F𝑘×𝑛.
Parties: P1, P2.
Inputs: None.
Outputs: P1 : u, v ∈ F𝑛; P2 : w ∈ F𝑛, 𝑥 ∈ F, such that
u𝑥 + v = w.
Share Generation (VOLE.Setup(1𝜆, F, 𝑛))
(1) P1 chooses a set of 𝑆 random positions 𝑆 = {𝑠1, . . . , 𝑠𝑡},
with 𝑠𝑖 ∈ [𝑛], 𝑡 random values y = (𝑦1, . . . , 𝑦𝑡) ∈ F𝑡, and a
pair of random vectors a, b ∈ F𝑘. P2 chooses random 𝑥 ∈ F.
multi-point function 𝑓𝑆,𝑥y.
from which P2 obtains a vector c = a𝑥 + b.
seed2 ← (𝐾2, 𝑥, c).
(2) P1 and P2 run MPFSS.Gen to obtain keys 𝐾1, 𝐾2 of the
(3) P1 and P2 run an MPC with inputs a, b and 𝑥 respectively,
(4) P1 outputs seed1 ← (𝐾1, 𝑆, y, a, b) and P2 outputs
Expansion (VOLE.Expand(𝑏, seed𝑏))
(i) If 𝑏 = 1, P1 runs 𝝂1[𝑖] ←MPFSS.Eval(1, 𝐾1, 𝑖) for 𝑖 ∈ [𝑛]
and defines a vector 𝝁 ∈ F𝑛 such that 𝝁[𝑠𝑖] = 𝑦𝑖 for all
𝑖 ∈ [𝑡] and 𝝁[𝑠] = 0 for all 𝑠 ∉ 𝑆. P1 outputs
u = a · C + 𝝁, v = b · C − 𝝂1.
and outputs w = c · C + 𝝂2.
(ii) If 𝑏 = 2, P2 runs 𝜈2[𝑖] ← MPFSS.Eval(2, 𝐾2, 𝑖) for 𝑖 ∈ [𝑛]
what allows us to use our known index MPFSS from Section 5 to
generate the shares 𝝂1 and 𝝂2 more efficiently.
We note that as discussed in Section 5, our batching scheme
introduces a small probability 2−𝜂 of failing to batch all 𝑡 non-zero
indices. This is also the case for the heuristic batch code construc-
tion of Boyle et al. [9]. However, as also pointed out there, this only
strengthens the required LPN assumption a little: If batching fails
(which results in some elements of 𝝁𝑥 becoming zero instead of
nonzero), the distribution of noise values will only slightly devi-
ate from uniform, but LPN for such a distribution remains a very
conservative assumption.
col is constant round, and requires 𝑂(cid:0)𝜆𝑚 log 𝑛 + 𝜆𝑘(cid:1) communica-
Theorem 6.1. Protocol 6 implements a secure distributed vec-
tor OLE generator in the semi-honest model. With step (3) instanti-
ated with OT-based Gilboa multiplication, MPFSS instantiated us-
ing Protocol 5, and C instantiated by a local linear code, the proto-
tion and 𝑂(𝜆𝜅𝑛 + 𝜆𝑚 log 𝑛) computation per party, where (𝑚, 𝜅) ←
ParamGen(n, t, 𝜂), 𝜆 is a computational security parameter, and 𝜂 is
the statistical security parameter of the MPFSS scheme.
Proof Sketch. As mentioned above, our protocol is obtained using
a simple modification of the scheme of Boyle et al. [9], i.e., using
known-index MPFSS instead of full MPFSS. Since the only addi-
tional information our variant reveals is already included in the
VOLE keys, their proof [9, Section 3.2.2] can be trivially adapted to
our protocol. We will give an overview here, but refer the reader
to [9] for the full details.
10
Correctness follows from the observation that 𝝁𝑥 = 𝝂1 + 𝝂2. It
follows that
u𝑥 + v = (a · C + 𝜇)𝑥 + b · C − 𝝂1
= (a𝑥 + b)C + 𝝁𝑥 − 𝝂1 = c · C + 𝜈2 = w.
To prove security we need to show that the two security proper-
ties from Definition 2.3 hold. To show the first property we observe
that the only part of seed1 that depends on 𝑥 is 𝐾1. However, since
it is generated using the distributed MPFSS construction, it follows
by the security of known-index MPFSS (see Appendix A.3) that
there is a simulator that can simulate 𝐾1 without knowledge of
𝑥. Note that the non-zero indices needed to simulate 𝐾1 are also
included in seed1.
To prove the second property we show a transition between the
distributions (u1, v1, seed2) and (u2, v2, seed2) in two steps and
argue that an adversary cannot distinguish the changes applied
in each of them. In the first step the input to the adversary is the
same but we replace the 𝐾2 with the simulated MPFSS key, which
is generated from F and 𝑛 alone. Security of the MPFSS scheme
guarantees that this simulated key is indistinguishable from the real
one. In this distribution u1 = a · C + 𝝁 and v1 = b · C − 𝝂1 = b · C +
𝝂2−𝝁𝑥 = c·C+𝝂2−(a·C+𝝁)𝑥 = c·C+𝝂2−u1𝑥. In the next step we
𝑅← F𝑛 and v2 ← w−u2𝑥 = c·C+𝝂2−u2𝑥.
replace u1 and v1 with u2
By the LPN assumption, u1 and u2 are indistinguishable and since
v1 and v2 are computed in the same way, the change in the second
step in indistinguishable for the adversary.
The communication in the protocol consists of the execution of
the distributed MPFSS key generation and the secure computation
for c, which have cost 𝑂(𝜆𝑚 log 𝑛) and 𝑂(𝜆𝑘), respectively. The
computation overhead additionally consists of the expansion of
the MPFSS, which is 𝑂(𝜆𝜅𝑛) and the vector matrix multiplications
with the matrix 𝐶, which using a local linear code is in 𝑂(𝑛).
In our evaluation (Section 8), rely on previous work [21] to