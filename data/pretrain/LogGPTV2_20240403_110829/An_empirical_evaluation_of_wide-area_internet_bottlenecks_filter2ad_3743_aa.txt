title:An empirical evaluation of wide-area internet bottlenecks
author:Aditya Akella and
Srinivasan Seshan and
Anees Shaikh
An Empirical Evaluation of Wide-Area Internet Bottlenecks
Aditya Akella, Srinivasan Seshan
Carnegie Mellon University
Pittsburgh, PA 15213
{aditya,srini+}@cs.cmu.edu
Anees Shaikh
IBM T.J. Watson Research Center
Hawthorne, NY 15213
PI:EMAIL
ABSTRACT
Conventional wisdom has been that the performance limitations in
the current Internet lie at the edges of the network – i.e last mile
connectivity to users, or access links of stub ASes. As these links
are upgraded, however, it is important to consider where new bot-
tlenecks and hot-spots are likely to arise. In this paper, we address
this question through an investigation of non-access bottlenecks.
These are links within carrier ISPs or between neighboring carriers
that could potentially constrain the bandwidth available to long-
lived TCP ﬂows. Through an extensive measurement study, we
discover, classify, and characterize bottleneck links (primarily in
the U.S.) in terms of their location, latency, and available capacity.
We ﬁnd that about 50% of the Internet paths explored have a non-
access bottleneck with available capacity less than 50 Mbps, many
of which limit the performance of well-connected nodes on the In-
ternet today. Surprisingly, the bottlenecks identiﬁed are roughly
equally split between intra-ISP links and peering links between
ISPs. Also, we ﬁnd that low-latency links, both intra-ISP and peer-
ing, have a signiﬁcant likelihood of constraining available band-
width. Finally, we discuss the implications of our ﬁndings on re-
lated issues such as choosing an access provider and optimizing
routes through the network. We believe that these results could be
valuable in guiding the design of future network services, such as
overlay routing, in terms of which links or paths to avoid (and how
to avoid them) in order to improve performance.
Categories and Subject Descriptors
C.2 [Computer Systems Organization]: Computer-Communication
Networks; C.2.5 [Computer-Communication Networks]: Local
and Wide-Area Networks
General Terms
Measurement, Performance
1.
INTRODUCTION
A common belief about the Internet is that poor network per-
formance arises primarily from constraints at the edges of the net-
work. These narrow-band access links (e.g., dial-up, DSL, etc.)
limit the ability of applications to tap into the plentiful bandwidth
and negligible queuing available in the interior of the network. As
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’03, October 27–29, 2003, Miami Beach, Florida, USA.
Copyright 2003 ACM 1-58113-773-7/03/0010 ...$5.00.
access technology evolves, enterprises and end-users, given enough
resources, can increase the capacity of their Internet connections
by upgrading their access links. The positive impact on overall
performance may be insigniﬁcant, however, if other parts of the
network subsequently become new performance bottlenecks. Ul-
timately, upgrades at the edges of the network may simply shift
existing bottlenecks and hot-spots to other parts of the Internet. In
this study, we consider the likely location and characteristics of fu-
ture bottleneck links in the Internet. Such information could prove
very useful in the context of choosing intermediate hops in overlay
routing services [1, 31] or interdomain trafﬁc engineering, and also
to customers considering their connectivity options.
Our objective is to investigate the characteristics of links within
or between carrier ISP networks that could potentially constrain
the bandwidth available to long-lived TCP ﬂows, called non-access
bottleneck links. Using a large set of network measurements, we
seek to discover and classify such links according to their location
in the Internet hierarchy and their estimated available capacity. By
focusing on interior links, we try to avoid access links near the
source and destination (i.e., ﬁrst-mile and last-mile hops), as these
are usually obvious bottlenecks in the current Internet. This paper
makes two primary contributions: 1) a methodology for measuring
bottlenecks links and 2) a classiﬁcation of existing bottleneck links.
Methodology for measuring non-access Internet bottleneck links:
Our main challenge in characterizing Internet bottlenecks is to mea-
sure paths that are representative of typical routes in the Internet,
while avoiding biases due to a narrow view of the network from
few probe sites, or probes which themselves are poorly connected.
Our results are based on measurements from 26 geographically di-
verse probe sites located primarily in the U.S., each with very high
speed access to the Internet. We measure paths from these sites to
a carefully chosen set of destinations, including paths to all Tier-
1 ISPs, as well as paths to a fraction of Tier-2, Tier-3, and Tier-4
ISPs, resulting in 2028 paths in total. In addition, we identify and
measure 466 paths passing through public Internet exchange points
in order to explore the common perception that public exchanges
are a major source of congestion in the Internet.
A second challenge lies in actually measuring the bottleneck link
and reporting its available bandwidth and location. Due to the need
for control at both ends of the path, we were unable to leverage any
of the existing tools to measure the available bandwidth. Hence, we
developed a tool, BFind, which measures available capacity using
a bandwidth probing technique motivated by TCP’s behavior, and
operates in a single-ended mode.
Classiﬁcation of bottleneck links: We apply our measurement
methodology to empirically determine the locations, estimated avail-
able bandwidth, and delay of non-access bottleneck links. In clas-
sifying these links, we draw extensively on recent work on charac-
terizing AS relationships [33, 8]. Our results show that nearly half
of the paths we measured have a non-access bottleneck link with
available capacity less than 50 Mbps. Moreover, the percentage
of observed paths with bottlenecks grows as we consider paths to
lower-tier destinations. Surprisingly, the bottlenecks identiﬁed are
roughly equally split between intra-ISP links and peering links be-
tween ISPs. Also, we ﬁnd that low-latency links, both within and
between ISPs have a signiﬁcant probability of constraining avail-
able bandwidth. Of the paths through public exchanges that had a
bottleneck link, the constrained link appeared at the exchange point
itself in nearly half the cases.
Our work complements and extends the large body of work on
measuring and characterizing the Internet. In particular, several re-
cent efforts have focused on end-to-end Internet path properties, as
these can have a signiﬁcant impact on application performance and
transport protocol efﬁciency. For example, recent wide-area mea-
surement studies focus on performance metrics like delay, loss, and
bandwidth [23, 36], packet reordering [15], routing anomalies [24,
11, 32], and path stability [16].
In addition, a number of mea-
surement algorithms and tools have been developed to measure the
capacity or available bandwidth of a path (see [13] for examples).
Our focus is on identifying and characterizing potential bottleneck
links through the measurement of a wide variety of Internet paths.
We believe that our observations provide valuable insights into
the location and nature of performance bottlenecks in the Internet,
and in some cases, address common impressions about constraints
in the network. In addition, we hope that our work could help im-
prove the performance of future network protocols and services in
terms of which bottlenecks to avoid (and how to avoid them).
In the next section we describe our measurement methodology
with additional details on our choice of paths and the design and
validation of BFind. Section 3 presents our observations of non-
access bottlenecks, and Section 4 offers some discussion about the
implications of our ﬁndings. In Section 5 we brieﬂy review related
work in end-to-end Internet path characterization and measurement
tools. Finally, Section 6 summarizes the paper.
2. MEASUREMENT METHODOLOGY
The Internet today is composed of an interconnected collection
of Autonomous Systems (ASes). These ASes can be roughly cat-
egorized as carrier ASes (e.g. ISPs and transit providers) and stub
ASes (end-customer domains). Our goal is to measure the char-
acteristics of potential performance bottlenecks that end-nodes en-
counter that are not within their own control. To perform this mea-
surement we need to address several issues, described below.
2.1 Choosing a Set of Trafﬁc Sources
Stub ASes in the Internet are varied in size and connectivity to
their carrier networks. Large stubs, e.g. large universities and com-
mercial organizations, are often multi-homed and have high speed
links to all of their providers. Other stubs, e.g. small businesses,
usually have a single provider with a much slower connection.
At the core of our measurements are trafﬁc ﬂows between a set of
sources, which are under our control, and a set destinations which
are random, but chosen so that we may measure typical Internet
paths (described in detail in Section 2.2). However, it is difﬁcult
to use such measurements when the source network or its connec-
tion to the upstream carrier network is itself a bottleneck. Hence,
we choose to explore bottleneck characteristics by measuring paths
from well-connected end-points, i.e.
stub ASes with very high
speed access to their upstream providers. Large commercial and
academic organizations are example of such end-points. In addi-
tion to connectivity of the stub ASes, another important factor in
choosing sources is diversity, both in terms of geographic locations,
and carrier networks. This ensures that the results are not biased by
repeated measurement of a small set of bottlenecks links.
We use hosts participating in the PlanetLab project [26], which
provides access to a large collection of Internet nodes that meet
our requirements. PlanetLab is a Internet-wide testbed of multi-
ple high-end machines located at geographically diverse locations.
Most of the machines available this time are in large academic in-
stitutions and research centers in the U.S. and Europe and have
very high-speed access to the Internet. Note that although our traf-
ﬁc sources are primarily at universities and research labs, we do
not measure the paths between these nodes. Rather, our measured
paths are chosen to be representative of typical Internet paths (e.g.,
as opposed to paths on Internet2).
Initially, we chose one machine from each of the PlanetLab sites
as the initial candidate for our experiments. While it is generally
true that the academic institutions and research labs hosting Plan-
etLab machines are well-connected to their upstream providers, we
found that the machines themselves are often on low-speed local
area networks. Out of the 38 PlanetLab sites operational at the out-
set of our experiments, we identiﬁed 12 that had this drawback.
In order to ensure that we can reliably measure non-access bottle-
necks, we did not use these 12 machines in our experiments.
Total #unique
providers
Avg. #providers
tier-1
tier-2
tier-3
tier-4
11
11
15
5
per PlanetLab source
0.92
0.69
0.81
0.10
Table 1: First-hop connectivity of the PlanetLab sites
The unique upstream providers and locations of the remaining
26 PlanetLab sites are shown in Table 1 and Figure 1(a), respec-
tively. We use a hierarchical classiﬁcation of ASes into four tiers
(as deﬁned by the work in [33]) to categorized the upstream ISPs
of the different PlanetLab sites. ASes in tier-1 of the hierarchy, for
example AT&T and Sprint, are large ASes that do not have any up-
stream providers. Most ASes in tier-1 have peering arrangements
with each other. Lower in the hierarchy, tier-2 ASes, including
Savvis, Time Warner Telecom and several large national carriers,
have peering agreements with a number of ASes in tier-1. ASes
in tier-2 also have peering relationships with each other, however,
they do not generally peer with any other ASes. ASes in tier-3,
such as Southwestern Bell and Turkish Telecomm, are small re-
gional providers that have a few customer ASes and peer with a
few other similar small providers. Finally, the ASes in tier-4, for
example rockynet.com, have very few customers and typically no
peering relationships at all [33].
2.2 Choosing a Set of Destinations
We have two objectives in choosing paths to measure from our
sources. First, we want to choose a set of network paths that are
representative of typical paths taken by Internet trafﬁc. Second,
we wish to explore the common impression that public network
exchanges, or NAPs (network access points), are signiﬁcant bot-
tlenecks. Our choice of network paths to measure is equivalent to
choosing a set of destinations in the wide-area as targets for our
testing tools. Below, we describe the rationale and techniques for
choosing test destinations to achieve these objectives.
2.2.1 Typical Paths
Most end-to-end data trafﬁc in the Internet ﬂows between stub
networks. One way to measure typical paths would have been to
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
Univ. of Bologna, IT
Lancaster University, UK
Univ. of Cambridge, UK
●
●
●
●
(a) Sources
●
●
●●
●
●
●
●
●
●
●
●
Univ. of Bologna, IT (2)
Univ. of Cambridge, UK (5)
(b) Destinations (mapped to the closest source)
Figure 1: Locations of PlanetLab sources (a) and destinations (b): Each destination location is identiﬁed by the PlanetLab source
with minimum delay to the destination. Three of our sources and seven destinations are located in Europe (shown in the inset). The
size of the dots is proportional to the number of sites mapped to the same location.
select a large number of stub networks as destinations. However,
the number of such destinations needed to characterize properties
of representative paths would make the measurements impractical.
Instead, we use key features of the routing structure of the Internet
to help choose a smaller set of destinations for our tests.
Trafﬁc originated by a stub network subsequently traverses mul-
tiple intermediate autonomous systems before reaching the destina-
tion stub network. Following the deﬁnitions of AS hierarchy pre-
sented in [33] (and summarized earlier), ﬂows originated by typi-
cal stub source networks usually enter a tier-4 or a higher tier ISP.
Beyond this, the ﬂow might cross a sequence of multiple links be-
tween ISPs and their higher-tier upstream carriers (uphill path). At
the end of this sequence, the ﬂow might cross a single peering link
between two peer ISPs after which it might traverse a downhill path
of ASes in progressively lower tiers to the ﬁnal destination, which
is also usually a stub. This form of routing, arising out of BGP poli-
cies, is referred to as valley-free routing. We refer to the portion of
the path taken by a ﬂow that excludes links within the stub network
at either end of the path, and the access links of either of the stub
networks, as the transit path.
Clearly, non-access bottlenecks lie in the transit path to the desti-
nation stub network. Speciﬁcally, the bottleneck for any ﬂow could
lie either (1) within any one of the ISPs in the uphill or the downhill
portion of the transit path or (2) between any two distinct ISPs in
either portion of the transit path. Therefore, we believe that measur-
ing the paths between our sources and a wide variety of different
ISPs would provide a representative view of the bottlenecks that
these sources encounter.
Due to the large number of ISPs, it is impractical to measure the
paths between our sources and all such carrier networks. However,
the reachability provided by these carriers arises directly from their
position in the AS hierarchy. Hence, it is more likely that a path will
pass through one or two tier-1 ISPs than a lower tier ISP. Hence,
we test paths between our sources and all tier-1 ASes. To make our
measurements practical, we only test the paths between our sources
and a fraction of the tier-2 ISPs (chosen randomly). We measure an
even smaller fraction of all tier-3 and tier-4 providers. The number
of ISPs we chose in each tier is presented in Table 2.
tier-1
tier-2
tier-3
tier-4
Number tested
Total in the Internet [33]
Percentage tested
20
20
100
18
129
14
25
897
3
15
971
1.5
Table 2: Composition of the destination set
In addition to choosing a target AS, we need to choose a target
IP address within the AS for our tests. For any AS we choose, say
, we pick a router that is a few (2-4) IP hops away from
the machine www..com (or .net as the case maybe). We
conﬁrm this router to be inside the AS by manually inspecting the
DNS name of the router where available. Most ISPs name their
routers according to their function in the network, e.g. edge (chi-
edge-08.inet.qwest.net) or backbone (sl-bb12-nyc-9-0.sprintlink.net),
routers. The function of the router can also be inferred from the
names of routers adjacent to it. In addition, we double check using
the IP addresses of the carrier’s routers along the path to www..com
(typically there is a change in the subnet address close to the web
server). We measure the path between each of the sources and the
above IP addresses. The diversity of the sources in terms of ge-
ography and upstream connectivity ensures that we sample several
links with the ISPs. The geographic location of the destinations is
shown in Figure 1(b). Each destination’s location is identiﬁed by
that of the trafﬁc source with the least delay to it.
2.2.2 Public Exchanges
The carrier ASes in the Internet peer with each other at a num-
ber of locations throughout the world. These peering arrangements
can be roughly categorized as public exchanges, or NAPs, (e.g.,
the original 4 NSF exchanges) or private peering (between a pair of
ISPs). One of the motivations for the deployment of private peering
has been to avoid the perceived congestion of public exchanges. As
part of our measurements, we are interested in exploring the accu-
racy of this perception. Therefore, we need a set of destinations to
test paths through these exchanges.
We selected a set of well-known NAPs, including Worldcom
MAE-East, MAE-West, MAE-Central, SBC/Ameritech AADS and
PAIX in Palo Alto. For each NAP, we gather a list of low-tier (i.e.,
low in the hierarchy) customers attached to the NAP. The customers
are typically listed at the Web sites of the NAPs. As in each of the
above cases, we use the hierarchy information from [33] to deter-
mine if a customer is small. Since these customers are low tier,
there is a reasonable likelihood that a path to these customers from
any source passes through the corresponding NAP (i.e., they are
not multihomed to the NAP and another provider). We then ﬁnd
a small set of addresses from the address block of each of these
customers that are reachable via traceroute. We use the complete
BGP table dump from the Oregon route server [30, 29] to obtain
the address space information for these customers.
Next, we use a large set of public traceroute servers (153 tracer-
oute sources from 71 providers) [34], and trace the paths from these
servers to the addresses identiﬁed above using a script to automate