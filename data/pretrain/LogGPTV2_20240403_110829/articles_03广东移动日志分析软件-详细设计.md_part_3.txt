将编码过的url进行解码，这个操作只能针对已经解析出来的字段。
（6）User Agent解析
分析HTTP日志中User Agent的用户操作系统和浏览器信息。
（7）时间戳识别
使用者通常关心日志发生的时间，比如检索最近几天的日志，需要转换日志中的timestamp字段的内容，日志分析软件平台系统就可以识别这条日志的时间戳。这就需要用户在之前抽取字段时就提取出timestamp字段。例如：
timestamp: \"150120 16:00:30\"
（8）JSON解析
JSON解析用来解析JSON格式的日志, 例如原始日志为：
{\"Name\": \"John Smith \", \"Age\": 23, \"Employed\": true,
\"Address\": {\"Street\": \"324 Chrome St\", \"City\": \"Portland, New
York,Los Angeles \", \"Country\": \"United States\"}}
（9）字段值拆分
将字符串切分，例如：
key：\"1.2.3.4, 2.4.5.6\"
可以根据"，"来对其进行切分成两个value:
key：\[\"1.2.3.4\", \"2.4.5.6\"\]
搜索
分析软件支持以下的提取规则，将接收到的数据属于非结构化数据的，进行结构化处理，对各类业务数据灵活提取数据结构
> 1.[正则解析 ](https://www.rizhiyi.com/docs/howtouse/logparse.html#a1)\
> [2.
> KeyValue分解](https://www.rizhiyi.com/docs/howtouse/logparse.html#a2)\
> [3.
> KeyValue正则匹配](https://www.rizhiyi.com/docs/howtouse/logparse.html#a3)\
> [4.
> 数值型字段转换 ](https://www.rizhiyi.com/docs/howtouse/logparse.html#a4)\
> [5. url解码 ](https://www.rizhiyi.com/docs/howtouse/logparse.html#a5)\
> [6. User
> Agent解析 ](https://www.rizhiyi.com/docs/howtouse/logparse.html#a6)\
> [7.
> 时间戳识别 ](https://www.rizhiyi.com/docs/howtouse/logparse.html#a7)\
> [8. geo解析 ](https://www.rizhiyi.com/docs/howtouse/logparse.html#a8)\
> [9.
> JSON解析 ](https://www.rizhiyi.com/docs/howtouse/logparse.html#a9)\
> [10.
> 字段值拆分 ](https://www.rizhiyi.com/docs/howtouse/logparse.html#a10)\
> [11.
> xml解析](https://www.rizhiyi.com/docs/howtouse/logparse.html#a11)\
> [12.
> syslog_pri解析](https://www.rizhiyi.com/docs/howtouse/logparse.html#a12)\
> [13.
> 自定义字典](https://www.rizhiyi.com/docs/howtouse/logparse.html#a13)\
> [14.
> 格式转换](https://www.rizhiyi.com/docs/howtouse/logparse.html#a14)\
> [15.
> 内容替换](https://www.rizhiyi.com/docs/howtouse/logparse.html#a15)
###### 6.2对业务数据进行统计和分析
通过对日志进行结构化提取之后，采用用spl语句可以直接对解析后的字段进行统计和分析
在完成数据接入工作后，对业务数据进行统计和分析：
1.原文检索：主要通过关键字、唯一标识符等低频词元，利用索引中倒排
表的高性能查找特性，快速定位和读取原始日志内容。找错误代码、关联跟踪特定订单或客户访问在多模块之间的流动情况、分析异常堆栈等等。
2.统计可视化：对检索数据集进行一系列指标运算，得到二维表格式的变换结果。常见场景有：错误事件数的时间趋势、特定用户登录行为的排行和分布、访问响应时间的百分比统计、KPI指标的平滑预测等等
每次搜索，都会生成简单直观的时间序列趋势图，这是搜索时间范围内所有索引日志事件的直方图，可以利用直方图比较随着时间推移的日志属性。如果需要更多统计及可视化功能，使用统计视图，可以得到更多图表和统计结果。并且可将图表保存到自定义仪表盘上随时查看。
功能要求：
（1）事件计数统计
事件计数可以绘制几个事件随着时间推进的计数和数值统计进行比对。选择"展现方式"和"添加字段"，图中将会展示该事件随时间变化的统计数。可以依次选取多个字段，便于比较查看。每选取一次图形下方会展示该字段名称，点击相应字段的删除符号可以去除该字段。勾选"独立数统计"可以进行去重统计。
（2）时间分段统计
选择"时间分段统计"，
选取字段，依次设定时间分段。需要提醒的是时间分段范围必须包含在用户搜索的时间范围中，并且各个时间分段不能有重叠交叉。系统将会按时间统计该事件的计数，同时进行环比统计。
（3）数值分段统计
选择"数值分段统计"是统计数值字段在各数值段的分布情况。选择字段后自行填写数值分段范围。用户可以点击"添加数值分段"产生新的分组。最后点击"生成图形"会生成柱状图。
（4）时间直方图
选择时间直方图，只需要设定"时间间隔"------在方框内填入数字，再选择合适的时间单位，完成后点击"生成图形"，即可看到相应的直方图。
（5）数值直方图
跟时间直方图类似，用户只需要选定字段，设定"数值间隔"，点击生成图表即可看到关于该数值字段的。需要提醒的是数值间隔设定值过小会造成生成的图表不可用。
（6）字段值分类统计
点击选择"字段值分类统计"用户将会看到对于某一字段的具体分类统计。选择字段后用户可以选择不同的展现方式。页面会显示搜索结果中该字段的所有值的比例，并生成相应的统计表格，显示出现次数最多的前几个字段值名称及统计次数。
（7）字段数值统计
字段数值统计是对字段的数值属性进行统计分析的功能，统计方式目前支持"总计/平均值/最大值/最小值/"四种选项。
（8）累计百分比统计
"累计百分比统计"是对数值字段的数值大小分布进行的统计功能，系统默认的百分比分段设置为1%，5%，25%，50%，75%，95%，99%，用户也可以调整或增加新的分段
（9）反向查询
可以在累积百分比反向查询中选择某个数值型字段后，输入查询数值，点击查询，即可获得查询结果。
（10）多级统计
多级统计可以满足针对某一字段的多重统计需求。多级统计最多支持三级。每次统计结果出现后都可以选择进行下一步统计或展现统计图。
###### 6.3支持分布式计算和存储
![](media/image3.png){width="5.770833333333333in" height="4.6875in"}
##### 7. 分布式应用程序协调管理
分布式处理模块均向协调管理模块注册，注册之后会在zookeeper中建立临时节点，当模块出现故障由zookeeper感知临时节点退出重新选举选出leader，由zookeeper统一协调管理模块并通过zookeeper协调各模块之间等通信，交换，通过ZooKeeper承载.涉及到消息队列，流处理，搜索引擎等分布式处理模块
一个针对大型分布式系统的高可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。由3台或3台以上奇数台服务器组建完成，具有如下3个特性：
1.提供丰富的构件来实现多种协调数据结构和协议。
2.访问原子性，客户端要么读到所有数据，要么读取失败，不会出现只读取部分的情况。
3.具有高可用性，帮助系统避免单点故障，故障时可以快速删掉故障服务器。故障回复时，重新加入到集群。
**功能特点：**
（1）通过ZooKeeper承载.涉及到消息队列，流处理，搜索引擎等分布式处理模块
（2）通过zookeeper协调各模块之间等通信，交换
（3）各个分布式处理模块均向协调管理模块注册，由zookeeper统一协调管理模块
![{A940A8B0-0346-BFD3-D9AE-AB50C6D04B72}](media/image4.jpeg){width="6.708333333333333in"
height="4.145833333333333in"}
##### 8.日志配置规则解析
####### 8.1流处理平台内置了常用的日志解析规则，能够识别、解析常见的日志格式。
**自动解析日志格式**
日志分析软件自动解析Apache，Nginx，JSON等类型的日志，用户可以通过分类检索、字段过滤对日志进行统计分析，用户会发现我们添加了一个名为\"logtype\"的字段来标识日志类型。对于不能被自动识别的日志，我们会对其全文索引，但是这将无法让用户充分使用日志分析软件的字段搜索功能。在本节中我们将介绍日志分析软件支持的日志类型，以及日志无法自动解析时如何处理。
可识别的日志格式
这里主要向用户介绍日志分析软件支持的日志格式，对于常见日志通常有详尽的官方文档说明供用户进一步参考。
另外，我们会持续添加更多的可识别日志格式，如果用户的日志暂时不能被正确识别并解析，希望用户通知我们，并提供一些日志样本。
我们目前支持以下日志格式：
[**Apache**](https://www.rizhiyi.com/docs/howtouse/resolve.html#Apache)
> 对于Apache或者Nginx日志，用户可以按需要配置服务器的日志格式，。
>
> 我们支持的apache日志格式如下：
%h %l %u %t \\\"%r\\\" %\>s %b
%h %l %u %t \\\"%r\\\" %\>s %b \\\"%{Referer}i\\\"
\\\"%{User-agent}i\\\"
%h %l %u %t \\\"%r\\\" %\>s %b \\\"%{Referer}i\\\"
\\\"%{User-agent}i\\\" \\\"%{X-Forwarded-For}i\\\"
其中各项配置的含义如下：
%b or %B - Size
%h RemoteIPOrHost
%l - RemoteLogname
%r - Request
%\>s - HttpStatusCode
%t - eventTime
%{Referer}i - Referer
%{User-agent}i - UserAgent
%{X-Forwarded-For}i -- XforwardedFor
另外，我们还可以自动识别Apache的error日志，通常情况下其日志格式如下:
\[Fri Jul 05 21:28:24 2013\] \[error\] child process 1245 still did not
exit, sending a SIGKILL
我们会为用户解析出如下字段:
timestamp, loglevel, message 等
[**Nginx**](https://www.rizhiyi.com/docs/howtouse/resolve.html#Nginx)
Nginx日志的日志格式与Apache基本相同我们支持的配置如下:
log_format main \'\$remote_addr - \$remote_user \[\$time_local\]
\"\$request\" \'
\'\$status \$body_bytes_sent\';
log_format combind \'\$remote_addr - \$remote_user \[\$time_local\]
\"\$request\" \'
\'\$status \$body_bytes_sent \"\$http_referer\" \'
\'\"\$http_user_agent\"\';
log_format default \'\$remote_addr - \$remote_user \[\$time_local\]
\"\$request\" \'
\'\$status \$body_bytes_sent \"\$http_referer\" \'
\'\"\$http_user_agent\" \"\$http_x\_forwarded_for\"\';
access_log /var/log/nginx/access.log main;
[**Log4j**](https://www.rizhiyi.com/docs/howtouse/resolve.html#Log4j)
> Log4j是java程序常用的日志库，具体的配置含义请参考Log4J配置文档，目前我们支持的日志格式的配置有：
>
> %d{ISO8601} %p %t %c.%M - %m%n
>
> 我们会解析出timestamp, log level, thread, class, method,
> message等字段。对于Java的Stack traceback等跨多行的日志，目前暂不支持。
[**JSON**](https://www.rizhiyi.com/docs/howtouse/resolve.html#JSON)
> 日志分析软件也支持JSON这种格式化数据，这里要求用户的日志整体是JSON格式，如果用户日志中仅一部分，我们暂不支持。
>
> 请首先使用JSON格式验证工具来检测用户的日志是否有效。
>
> 使用JSON日志格式，需要用户注意以下事项：
>
> 1 时间戳
>
> 我们需要准确地识别日志的时间戳，因此在产生日志时，需要配置日志使其满足如下条件：
-   必须在JSON的最顶级包含"timestamp"字段
-   时间戳格式只支持ISO8601的格式（例如 2014-09-11t01:13:24.012z）
> 例如：
>
> {\"timestamp\":\"2014-09-11t01:13:24.012z\",\"family\":{\"father\":\"LiLei\",\"mother\":\"HanMeimei\"}}
>
> 2 格式
>
> JSON的字段类型不能改变。例如，在一条日志中的一个字段为整数类型，在下一条日志中不能被赋予新的类型。下面给出的例子中对象为"company"：
>
> {\"company\": {\"boss\": \"Mr.Chen\", \"employer\": \"Mr.Li\" } }
>
> 重新输入一条"company"的日志，则这个字段不会被索引：
>
> { \"company\": 100 }
>
> JSON 字段名称
>
> 通常情况下，我们按照用户发送的JSON字段来建立索引，但是当字段名种包含空格或圆点(.)时，这些特殊字符将被下划线(\_)
> 替换，这是因为我们的搜索语法中不支持字段名称中包含这些符号。
>
> 例如：
>
> { \"a\": 1, \"b c\": 2, \"d.e\": 3, \"d\": { \"e\" : 4 } }
>
> 将被重写为：
>
> { \"a\": 1,\"b_c\": 2,\"d_e\": 3,\"d\": {\"e\" : 4 } }
>
> 这样可以明确区分json.d.e和json.d_e。
[**Linux**](https://www.rizhiyi.com/docs/howtouse/resolve.html#Linux)
> 如果用户需要分析一些Linux系统日志，需要先配置用户的上传模板。我们会将其包装成标准的syslog日志,并解析出如下字段：
>
> timestamp，appname, hostname，priority, facility, severity, message
[**Mysql**](https://www.rizhiyi.com/docs/howtouse/resolve.html#Mysql)
mysql日志记录了mysql本身的运行情况，例如