than those involving workarounds or “use as is” dispositions.
In fact, with the exception of Mission 6, ﬁxes occur more
frequently than WA+UAI mitigation types.
Table VII shows the frequencies of each mitigation type for
non-aging-related Mandelbugs in all eight missions. For most
missions, workaround and “use as is” mitigation types occur at
similar frequencies to ﬁxes. However, for all missions except
Mission 8 both workarounds and “use as is” mitigation types
taken together occur signiﬁcantly more often than ﬁxes.
Our ﬁndings are similar when we consider NAMs and ARBs
taken together, as seen from Table VIII. The main difference
between NAMs alone and NAMs and ARBs together appears
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:42:07 UTC from IEEE Xplore.  Restrictions apply. 
MITIGATION TYPE FREQUENCIES FOR INDIVIDUAL MISSIONS:
BOH+NAM+ARB
TABLE IX
Mission ID
Fix/Patch WA
UAI
WA+UAI
Mitigation includes
1
2
3
4
5
6
7
8
0.595
0.658
0.556
0.500
0.783
0.370
0.825
0.770
0.238
0.214
0.271
0.181
0.148
0.407
0.214
0.229
0.130
0.217
0.296
0.407
0.070
0.123
0.216
0.095
0.452
0.439
0.519
0.443
0.348
0.704
0.193
0.311
MITIGATION TYPE FREQUENCIES FOR EARLY VS. LATE MISSIONS
TABLE X
Mission group
Fix/Patch WA
UAI
WA+UAI
Mitigation includes
BOH
Missions 1–4
Missions 5–8
0.753
0.833
0.222
0.117
0.103
0.119
0.340
0.222
NAM
Missions 1–4
Missions 5–8
0.393
0.462
0.259
0.366
0.327
0.288
0.607
0.615
NAM+ARB
Missions 1–4
Missions 5–8
0.417
0.491
0.265
0.341
0.327
0.272
0.583
0.600
Missions 1–4
Missions 5–8
BOH+NAM+ARB
0.602
0.241
0.218
0.729
0.177
0.166
0.449
0.337
to be that ARBs are ﬁxed at a greater frequency than NAMs,
contributing to a smaller difference between the frequencies
of WA and UAI mitigation types taken together and ﬁxes.
ARBs are not considered separately on a mission-by-mission
basis because the number detected per mission is too small to
perform any meaningful analysis – there is total of 25 ARBs
over all missions.
Table IX shows the results of considering all three types of
faults together. Taking into account that the Mission IDs used
in this paper reﬂect the launch order (i.e., Mission 1 is the
ﬁrst one launched, while Mission 8 is the most recent one),
the table seems to suggest a difference between the earlier four
missions and the four later ones. For Missions 1–4, Fix/Patch
and WA+UAI occur at roughly the same frequencies. However,
there is no such pattern for the later four missions. Faults are
ﬁxed substantially more often for Missions 5, 7, and 8, while
WA and UAI types taken together occur at signiﬁcantly greater
frequency than ﬁxes for Mission 6.
To further investigate the possible differences between the
ﬁrst four missions and the last four with respect
to the
mitigating actions taken, we aggregate the data as shown in
Table X. This table is similar in layout to Tables VI–IX.
Instead of looking at individual missions, however, it groups
together Missions 1–4 and Missions 5–8. For each type of
fault, we see that the proportion of ﬁxes for the ﬁrst four
missions is smaller than the proportion of ﬁxes for the last four.
While the proportion of WA+UAI taken together decreases for
BOH and for all three fault types taken together, it remains
nearly the same for NAM and NAM+ARB.
V. DISCUSSION AND CONCLUSION
For the set of failure reports studied in this paper, we
have observed different types of mitigating actions taken in
response to different types of faults. The differences appear to
be consistent across the eight missions for which we have
analyzed failure reports, increasing the likelihood that our
ﬁndings will be applicable to future similar missions.
Our ﬁnding that most Bohrbugs are mitigated via ﬁxes,
combined with the earlier paper that suggested that Bohrbugs
appear to be the type of faults most commonly encountered
during mission operations [14] indicate that maintenance de-
velopment will continue to be an important part of mission
operations activities for future missions.
It may come as a surprise that ﬁxes are the most frequent
type of mitigating action taken not only for Bohrbugs, but for
non-aging-related Mandelbugs and aging-related bugs as well.
Given that these latter types of faults are difﬁcult to isolate, it
would be reasonable to suppose that developing workarounds
would be a more common mitigation mechanism. However,
workarounds often involve losing access to some portions
of a system’s functionality. Considering that the systems we
analyzed are one-of-a-kind systems deployed with the explicit
goal of acquiring high-value (and high-visibility) scientiﬁc
observations, it appears that in this case the development and
mission operations organizations make it a high priority to
be able to identify and remove these types of faults during
mission operations. Moreover, the spacecrafts on which the
ﬂight software is running log a huge amount of system
parameters. JPL/NASA operations personnel can analyze these
traces, play them back on test equipment, etc. Unlike in many
other industrial settings, it is thus often possible to determine
the root causes even for failures due to non-aging-related
Mandelbugs and aging-related bugs, making ﬁxes feasible.
We have also seen that as compared with non-aging-related
Mandelbugs, aging-related bugs are ﬁxed/patched more often,
while “use as is” dispositions are less frequent. This may be
explained by the fact that, although the error propagation of
aging-related bugs is complex due to the interaction with the
system-internal environment, aging effects (such as the buffer
overﬂow described in the ﬁfth failure report listed in Table II)
are rather easy to detect from system logs, which often allows
the underlying fault to be identiﬁed and ﬁxed. Furthermore,
while aging-related bugs could be dealt with proactive reboots
(i.e., software rejuvenation) for the missions analyzed in this
paper the JPL/NASA operations personnel did not employ
such techniques – either because they were unaware of them,
or because they rather decided to rely on ﬁxes/patches.
Finally, our analyses have revealed that, for each type of
fault, the earlier Missions 1–4 tend to show lower frequencies
of ﬁxes/patches than the more recent missions Missions 5–8.
We conjecture that improved logging of system parameters
may have further increased the ability of the operations
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:42:07 UTC from IEEE Xplore.  Restrictions apply. 
personnel to identify and correct the faults responsible for
the failures experienced. Moreover, we observed that during
the last period of a mission, proposed patches tend to get
discarded, because often the effort is deemed to outweigh the
beneﬁt due to the short remaining lifetime of the mission. This
might bias the ﬁx/patch frequencies for the missions launched
earlier. As the more recent missions continue their operations,
we will carry on with our analysis of the mitigation types to
determine whether or not the observed higher frequency of
ﬁxes for these missions is a characteristic of the missions as a
whole or an artifact of the smaller amounts of time they have
been in operation.
In future work, we will also examine the ground-based
support systems for the missions studied in this paper, to
investigate if the mitigating actions taken in response to each
fault type differ from those encountered for the ﬂight software.
ACKNOWLEDGMENT
The research described in this paper was carried out at the
Jet Propulsion Laboratory, California Institute of Technology
and at Duke University. The research was sponsored by the
National Aeronautics and Space Administration’s Ofﬁce of
Safety and Mission Assurance Software Assurance Research
Program. This task is managed locally by JPL’s Assurance
Technology Program Ofﬁce. Duke research was supported in
part by the NASA Ofﬁce of Safety and Mission Assurance
(OSMA) Software Assurance Research Program (SARP) un-
der the JPL subcontract #1440119. FAU research was sup-
ported by the Dr. Theo and Friedl Schoeller Research Center
for Business and Society.
REFERENCES
[1] D. Dvorak, Ed., “NASA study on ﬂight software complexity,” NASA,
Tech. Rep. NASA Ofﬁce of Chief Engineer, 2009. [Online]. Available:
http://www.nasa.gov/pdf/418878main FSWC Final Report.pdf
[2] M. Grottke and K. S. Trivedi, “A classiﬁcation of software faults,” in
Supplemental Proc. 16th International IEEE Symposium on Software
Reliability Engineering, 2005, pp. 4.19–4.20.
[3] M. Grottke and K. S. Trivedi, “Software faults, software aging and soft-
ware rejuvenation,” Journal of the Reliability Engineering Association
of Japan, vol. 27, no. 7, pp. 425–438, 2005.
[4] M. Grottke and K. S. Trivedi, “Fighting bugs: Remove, retry, replicate,
and rejuvenate,” IEEE Computer, vol. 40, no. 2, pp. 107–109, 2007.
[5] A. Aviˇzienis, J.-C. Laprie, B. Randell, and C. Landwehr, “Basic concepts
and taxonomy of dependable and secure computing,” IEEE Transactions
on Dependable and Secure Computing, vol. 1, pp. 11–33, 2004.
[6] R. Chillarege, “Understanding Bohr-Mandel bugs through ODC triggers
and a case study with empirical estimations of their ﬁeld proportion,”
in Proc. 2011 IEEE 3rd International Workshop on Software Aging and
Rejuvenation, 2011, pp. 7–13.
[7] J. Gray, “Why do computers stop and what can be done about it?”
Tandem Computers, Tech. Rep. 85.7, PN87614, 1985.
[8] M. Grottke, R. Matias, and K. S. Trivedi, “The fundamentals of software
aging,” in Proc. 1st International Workshop on Software Aging and
Rejuvantion, 2008.
[9] E. Marshall, “Fatal error: How Patriot overlooked a Scud,” Science, vol.
255, no. 5050, p. 1347, 1992.
[10] A. Avritzer and E. J. Weyuker, “Monitoring smoothly degrading systems
for increased dependability,” Empirical Software Engineering, vol. 2,
no. 1, pp. 59–77, 1997.
[11] V. Castelli, R. E. Harper, P. Heidelberger, S. W. Hunter, K. S. Trivedi,
K. Vaidyanathan, and W. P. Zeggert, “Proactive management of software
aging,” IBM Journal of Research & Development, vol. 45, no. 2, pp.
311–332, 2001.
[12] K. Chaudhuri, A. Kothari, R. Swaminathan, R. Tarjan, A. Zhang, and
Y. Zhou, “Server allocation problem for multi-tiered applications,” HP
Labs, Tech. Rep. HPL-2004-151, 2004.
[13] M. Grottke, L. Li, K. Vaidyanathan, and K. S. Trivedi, “Analysis of
software aging in a Web server,” IEEE Transactions on Reliability,
vol. 55, pp. 411–420, 2006.
[14] M. Grottke, A. P. Nikora, and K. S. Trivedi, “An empirical investigation
of fault types in space mission system software,” in Proc. 40th Annual
IEEE/IFIP International Conference on Dependable Systems and Net-
works, 2010, pp. 447–456.
[15] J. Alonso, M. Grottke, A. P. Nikora, and K. S. Trivedi, “The nature of
the times to ﬂight software failure during space missions,” in Proc. 23rd
IEEE International Symposium on Software Reliability Engineering,
2012, pp. 331–340.
[16] K. S. Trivedi, M. Grottke, and E. C. Andrade, “Software fault mitigation
and availability assurance techniques,” International Journal of Systems
Assurance Engineering and Management, vol. 1, no. 4, pp. 340–350,
2010.
[17] Y. Huang, C. Kintala, N. Kolettis, and N. D. Fulton, “Software rejuve-
nation: Analysis, module and applications,” in Proc. 25th International
Symposium on Fault-Tolerant Computing, 1995, pp. 381 – 390.
[18] J. Gray, “A census of Tandem system availability between 1985 and
1990.” IEEE Trans. Reliability, vol. 39, no. 4, pp. 409–418, 1990.
[19] M. Kaˆaniche and K. Kanoun, “Reliability of a commercial telecommu-
nications system,” in Proc. 7th International Symposium on Software
Reliability Engineering, 1996, pp. 207–212.
[20] J. Xu, Z. Kalbarczyk, and R. K. Iyer, “Networked Windows NT system
ﬁeld failure data analysis,” in Proc. 1999 Paciﬁc Rim International
Symposium on Dependable Computing, 1999, pp. 178–185.
[21] N. Talagala and D. Patterson, “An analysis of error behavior in a large
storage system,” EECS Department, University of California, Berkeley,
Tech. Rep. UCB/CSD-99-1042, 1999.
[22] A. Chou, J. Yang, B. Chelf, S. Hallem, and D. Engler, “An empirical
study of operating systems errors,” in Proc. 18th ACM Symposium on
Operating Systems Principles, 2001, pp. 73–88.
[23] P. Enriquez, A. Brown, and D. Patterson, “Lessons from the PSTN for
dependable computing - a study of FCC disruption reports,” in Proc.
Workshop on Self-Healing, Adaptive, and Self-Managed Systems, 2002.
[24] D. Oppenheimer, A. Ganapathi, and D. A. Patterson, “Why do internet
services fail, and what can be done about it?” in Proc. 4th Conference
on USENIX Symposium on Internet Technologies and Systems, vol. 4,
2003, pp. 1–16.
[25] A. R. Hoffman, N. H. Green, and H. B. Garrett, “Assessment of in-ﬂight
anomalies of long life outer planet missions,” in Environmental Testing
for Space Programmes, ser. ESA Special Publication, K. Fletcher, Ed.,
vol. 558, Aug. 2004, pp. 43–50.
[26] S. Peret and P. Narasimham, “Causes of failure in web applications,”
Carnegie Mellon University, Tech. Rep. CMU-PDL-05-109, 2005.
[27] N. W. Green, A. R. Hoffman, and H. B. Garrett, “Anomaly trends for
long-life robotic spacecraft,” Journal of Spacecraft and Rockets, vol. 43,
no. 1, pp. 218–224, 2006.
[28] N. W. Green, A. R. Hoffman, T. K. M. Schow, and H. B. Garrett,
“Anomaly trends for robotic missions to Mars: Implications for mission
reliability,” in Proc. 44th AIAA Aerospace Sciences Meeting and Exhibit,
2006, pp. 1–9.
[29] E. Pinheiro, W.-D. Weber, and L. A. Barroso, “Failure trends in a large
disk drive population,” in Proc. 5th USENIX Conference on File and
Storage Technologies, 2007, pp. 17–28.
[30] W. Jiang, C. Hu, Y. Zhou, and A. Kanevsky, “Don’t blame disks for
every storage subsystem failure,” The USENIX Magazine, vol. 33, no. 3,
pp. 22–31, 2008.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:42:07 UTC from IEEE Xplore.  Restrictions apply.