the client sends fake cells before sending real cells. The
proxy sees the client’s fake cells, drops them, and sim-
ilarly starts sending fake cells before sending real cells.
During a fake burst, the client and the proxy both use
fake burst end cells to mark the end of each fake burst.
The chief difﬁculty in our implementation was that the
Tor client had to stop delivering cells in the middle of
fake bursts. Otherwise, the fake burst would look dif-
ferent from real bursts. We did so by adding a queue
to each Tor circuit, so that each cell that was created in
between fake bursts would be queued. At the end of a
fake burst (signalled by the fake burst end cell), the client
empties the queue and sends the queued Tor cells as the
next burst. Our implementation does not rely on any Tor-
speciﬁc mechanics, and could be applied to other proxy
technologies.
Our implementation assumes that that the client can ei-
ther collect burst sequences or receive them from some-
where else. (Our security analysis assumes that the at-
tacker is allowed to see them.) We describe an alterna-
tive construction of Walkie-Talkie for which the client
has no information about any real burst sequences in Ap-
pendix A.
4.5 Security
We analyze the security of Walkie-Talkie against an at-
tacker who wants to know when a client has visited some
sensitive page s. The client really visits s at probability p
and chooses s as a decoy page for some other page with
probability p(cid:48). It is plain to see that the attacker’s preci-
sion cannot exceed p/(p + (1− p)p(cid:48)), as no attacker can
distinguish between real visits and decoy visits.
To achieve the maximum precision, the attacker must
be able to correctly determine the two subsequences that
make up any given cell sequence of WT. We will see
in the evaluation (Section 5.2) that no real attack comes
close to doing so. Even a theoretical perfect classiﬁer
fails to do so; in Section 5.4.2, we show that there are
often hundreds if not thousands of possible realistic sub-
sequences (from a set of 10,000 subsequences) for any
given cell sequence of WT.
We extend our analysis to include the scenario that the
client may not have chosen s as a decoy page. Consider
two types of clients: clients who really visit s at some
probability p taken from distribution X, and clients who
only use s as a decoy with probability p(cid:48) taken from some
distribution X(cid:48). To distinguish between those two types
of clients, the attacker must be able to judge if the client’s
visits of s come from X or X(cid:48). It is not practical for the at-
tacker to do so, as the attacker cannot directly measure X,
X changes over time in an unpredictable manner, many
page visits would include s as a subsequence (even with-
out choosing s as either a real page or a decoy page), and
the attacker’s estimation of X(cid:48) is signiﬁcantly affected
by observation error, especially if the set of decoy pages
is rotated regularly. Therefore, the attacker cannot de-
termine if any given client has ever really visited s, or
merely uses it as a decoy page.
5 Evaluation
Here we evaluate WT on data collected from Tor using
the methodology described next in Section 5.1. In Sec-
tion 5.2 we show that WT is effective against known WF
attacks. In Section 5.3 we compare our defense against
known defenses to show the signiﬁcantly lower overhead
of WT. WT is in fact effective against all possible WF
attacks; we rigorously deﬁne this notion and quantify
WT’s effectiveness against all WF attacks in Section 5.4.
USENIX Association
26th USENIX Security Symposium    1381
5.1 Setup and Data Collection
We collected our data on Tor Browser 6.0 (based on Fire-
fox 38.7.1) with Tor 0.2.8.1. To collect burst sequences
for WT, we modiﬁed Tor Browser to enable half-duplex
communication, as described in Section 4.1.2.
We collected data from Alexa’s top pages [1]; we
use long-standing pages to make our results more re-
producible and comparable to other papers in the ﬁeld.
We use 100 of the top pages as the non-sensitive set (af-
ter removing duplicates due to different localizations or
URLs of the same page), and we collected 100 instances
of each page in the non-sensitive set. We use the next
10,000 pages in Alexa’s top pages as the sensitive set. In
the closed-world scenario, we only use the former data
set, in which case the 100 top pages are sensitive instead;
to avoid confusion, in this case we refer to the top 100
pages as the closed-world set. We dropped any instance
with fewer than 50 cells (25 kB) in it, in order to discard
pages that failed to load.
We added the capability to generate fake cells on Tor
clients and relays, but we will not use the latter to achieve
burst molding in this section. Rather, we will simu-
late burst molding after collecting data using half-duplex
mode. This is because we want to present experimental
results for a large number of parameter choices for burst
molding, and re-collecting data for each set of parame-
ters is infeasible. Our simulated burst molding does not
consider network instability events such as packet loss
and proxy dropping; these events are rare and unlikely to
be caused by and therefore linkable to the server.
5.2 Walkie-Talkie versus Attacks
We implemented nine known WF attacks and tested each
of them against WT. Each WF attack we tested was the
state of the art at the time of its publication. Since many
of the older attacks were not designed for the open-world
scenario, we tested all of them in the closed-world sce-
nario for consistent comparison. We use 100 instances of
each of the 100 closed-world pages for training and test-
ing with 10-fold cross validation. Since the closed-world
scenario is strictly easier to attack than the open-world
scenario, our results are a conservative estimate of WT’s
effectiveness.
We show the results in Table 1 under two columns: the
original accuracy on a Tor data set without our defense
(Undefended), and the new accuracy on a Tor data set
with our defense (Defended).
Jaccard and MNBayes are highly inaccurate even in
our Undefended case because they rely on unique packet
lengths, but all of our cells have the same length (see
Section 3.1). Out of all the attacks, SVM by Panchenko
et al. [23] appears to suffer least from WT, perform-
Table 1: Closed-world accuracy (TPR) of known attacks
against Tor (Undefended), and Tor protected by WT (De-
fended).
Attack Undefended Defended
Jaccard [15]
Naive Bayes [15]
MNBayes [13]
SVM [23]
DLevenshtein [6]
OSAD [32]
FLevenshtein [32]
kNN [31]
CUMUL [22]
kFP [12]
0.01
0.49
0.03
0.81
0.94
0.97
0.79
0.95
0.64
0.86
0.01
0.16
0.02
0.44
0.19
0.25
0.24
0.28
0.20
0.41
Table 2: Open-world accuracy (TPR and FPR) of known
attacks against Tor (Undefended), and Tor protected by
WT (Defended).
True Positive Rate (TPR)
Attack Undefended Defended
SVM [23]
kNN [31]
CUMUL [22]
0.47
0.98
0.78
0.33
0.68
0.20
False Positive Rate (FPR)
Attack Undefended Defended
SVM [23]
kNN [31]
CUMUL [22]
0.05
0.09
0.04
0.20
0.62
0.35
ing slightly better than kNN [31]. Indeed, previous au-
thors [5,8] have noted the resilience of this attack against
random noise, possibly due to its use of a “kernel trick”
transforming distances between cell sequences, allowing
greater ﬂexibility in ignoring dummy cells. While our
experiments on the closed-world scenario show that WT
is successful, WT truly shines in the more realistic open-
world scenario, which we investigate next.
We designed WT for the open world, as it attempts to
confuse sensitive and non-sensitive pages. We focus on
three WF attacks that have been successful in the open-
world scenario: SVM, kNN, and CUMUL, and present
their TPR and FPR in Table 2. We see that the FPR for
each attack increases signiﬁcantly with the application
of WT. kNN adopts an aggressive strategy, achieving a
high TPR but suffering a high FPR, whereas CUMUL
and SVM both suffer a low TPR with a low FPR.
The base rate fallacy tells us that since the TPR and
FPR are similar for all three attacks, they are highly im-
precise if the base rate of sensitive page access is low.
This is an important consideration as realistically, clients
do not often visit sensitive pages. For example, if the rate
1382    26th USENIX Security Symposium
USENIX Association
Table 3: Accuracy of each feature category of kNN
against Tor (Undefended), and Tor protected by WT (De-
fended).
Category Undefended Defended
Sequence length
Location of outgoing cells
Ratio of outgoing cells
Cell bursts
Direction of initial cells
Intercell times
0.67
0.01
0.79
0.81
0.04
0.10
0.14
0.01
0.19
0.27
0.01
0.04
of sensitive page access is 5%, then kNN would have a
precision of only 5.5%; almost all of its sensitive classi-
ﬁcations are wrong. Despite having a decent recall rate,
kNN would be useless against WT as the attacker cannot
act upon its sensitive classiﬁcations.
We seek to delve deeper into the success of WT against
known WF attacks by examining how WT affects indi-
vidual features. To do so, we examine the feature cat-
egories deﬁned by kNN [31]. We choose kNN because
its feature categories are diverse and understandable, and
it is one of the better attacks. Returning to the closed-
world scenario for this experiment, we measure the ef-
fectiveness of each individual category by calculating the
classiﬁcation accuracy if only features from that category
were used for kNN classiﬁcation. We contrast the effec-
tiveness of each category before and after WT is applied
on our cell sequences.
We plot the six feature categories and their results in
Table 3. Each feature category that was useful for clas-
siﬁcation in the Undefended case has been covered by
WT. Although WT makes no explicit attempt to cover
intercell times, the addition of fake cells appears to dis-
rupt intercell times as a feature. Comparing Table 3 and
the entry for kNN in Table 1, we see that the accuracy of
kNN under WT would be almost unchanged if only the
sizes of the cell bursts were used and other feature cate-
gories were discarded. This reﬂects the fact that WT ef-
fectively reduces the information available to the attacker
to simply the burst sequences.
5.3 Walkie-Talkie versus Defenses
In the other direction, we compare WT with a basket
of known website ﬁngerprinting defenses in Table 4, in
terms of bandwidth overhead (BWOH), time overhead
(TOH), and accuracy of the kNN attack by Wang et
al. [31]. We use the kNN attack because it is the cur-
rent state-of-the-art attack on Tor. We implemented all
of these attacks based on their original authors’ descrip-
tions. We did not include some older defenses which had
no effect on cell sequences, as they only affected packet
sizes.
Table 4: Bandwidth overhead (BWOH) and time over-
head (TOH) of the best WF defenses, as well as the ac-
curacy of kNN on them in our data set.
Defense
Adaptive [29]
Decoy [23]
BuFLO [8]
Supersequence [31]
Tamaraw [5]
WT (this work)
BWOH TOH kNN acc.
16%
193%
100%
39%
145% 180%
222% 112%
103% 140%
31% 34%
0.67
0.25
0.08
0.05
0.05
0.28
We can see from Table 4 that WT has a markedly
smaller bandwidth overhead (BWOH) and time over-
head (TOH) than many of the previous attacks, and it
is still able to defeat kNN. Across our data set, the band-
width overhead of WT is 31%± 16% and its time over-
head is 34%± 5%; different cell sequences vary signiﬁ-
cantly in bandwidth overhead but not time overhead. Bu-
FLO, Supersequence, and Tamaraw are able to further
decrease kNN accuracy (0.05 to 0.08) compared to WT
(0.28), but this effectiveness comes at a high cost in over-
head. kNN’s higher accuracy against WT is not practi-
cally meaningful: nevertheless, the attacker cannot iden-
tify accesses to sensitive pages under WT due to the base
rate fallacy. For WT, any cell sequence always looks as if
it could have come from at least two different web pages
due to burst molding, which means that no WF attack
can reach an accuracy above 0.5. We develop this notion
further in Section 5.4.
Tamaraw, Supersequence, and WT are all tunable:
each defense can decrease its own time overhead by in-
creasing its bandwidth overhead and vice versa. Further-
more, each defense can increase either overhead to in-
crease the effectiveness of the defense against attacks.
A proper comparison of these defenses requires further
analysis. We focus on Tamaraw as it has a lower over-
head than Supersequence.
We investigate the trade-off between time overhead
and bandwidth overhead. To do so, we ﬁx the effective-
ness of Tamaraw and WT to be the same against attacks
in general (see Section 5.4 for details on how we com-
pute this). For Tamaraw, the trade-off is achieved by
varying the ﬁxed intercell times. For WT, the trade-off
is achieved by changing which cell sequences to choose
in burst molding. We can prefer cell sequences that min-
imize bandwidth overhead at the cost of time overhead