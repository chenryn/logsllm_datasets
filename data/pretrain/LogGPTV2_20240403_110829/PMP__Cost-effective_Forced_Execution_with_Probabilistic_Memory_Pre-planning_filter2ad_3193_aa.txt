title:PMP: Cost-effective Forced Execution with Probabilistic Memory Pre-planning
author:Wei You and
Zhuo Zhang and
Yonghwi Kwon and
Yousra Aafer and
Fei Peng and
Yu Shi and
Carson Harmon and
Xiangyu Zhang
2020 IEEE Symposium on Security and Privacy
PMP: Cost-effective Forced Execution with Probabilistic Memory Pre-planning
Wei You1, Zhuo Zhang1, Yonghwi Kwon2, Yousra Aafer1, Fei Peng1, Yu Shi1, Carson Harmon1, Xiangyu Zhang1
1Department of Computer Science, Purdue University, Indiana, USA
Email: {you58, zhan3299, yaafer, pengf, shi442, harmon35, xyzhang}@purdue.edu, PI:EMAIL
2Department of Computer Science, University of Virginia, Virginia, USA
Abstract—Malware is a prominent security threat and exposing
malware behavior is a critical challenge. Recent malware often
has payload that is only released when certain conditions are
satisﬁed. It is hence difﬁcult to fully disclose the payload by
simply executing the malware. In addition, malware samples
may be equipped with cloaking techniques such as VM detectors
that stop execution once detecting that the malware is being
monitored. Forced execution is a highly effective method to
penetrate malware self-protection and expose hidden behavior, by
forcefully setting certain branch outcomes. However, an existing
state-of-the-art forced execution technique X-Force is very heavy-
weight, requiring tracing individual instructions, reasoning about
pointer alias relations on-the-ﬂy, and repairing invalid pointers
by on-demand memory allocation. We develop a light-weight and
practical forced execution technique. Without losing analysis pre-
cision, it avoids tracking individual instructions and on-demand
allocation. Under our scheme, a forced execution is very similar
to a native one. It features a novel memory pre-planning phase
that pre-allocates a large memory buffer, and then initializes
the buffer, and variables in the subject binary, with carefully
crafted values in a random fashion before the real execution.
The pre-planning is designed in such a way that dereferencing
an invalid pointer has a very large chance to fall
into the
pre-allocated region and hence does not cause any exception,
and semantically unrelated invalid pointer dereferences highly
likely access disjoint (pre-allocated) memory regions, avoiding
state corruptions with probabilistic guarantees. Our experiments
show that our technique is 84 times faster than X-Force, has
6.5X and 10% fewer false positives and negatives for program
dependence detection, respectively, and can expose 98% more
malicious behaviors in 400 recent malware samples.
I. INTRODUCTION
The proliferation of new strains of malware every year
poses a prominent security threat. Recently reported attacks
demonstrate the emergence of new attacking trends, where
malware authors are designing for stealth and leaving lighter
footprints. For example, Fileless malware [5] infects a target
host through exploiting built-in tools and features, without
requiring the installation of malicious programs. Clickless
infections [1] avoid end-user interaction through exploiting
shared access points and remote execution exploits. Cryptocur-
rency malware [4] allow attackers to generate huge revenues
by illegally running mining algorithms using victim’s system
resources. According to [3], a massive cryptocurrency mining
botnet has generated $3 million revenue in 2018. Under this
new threatscape, malicious payloads have evolved and look
much different than traditional ones. Thus, a critical challenge
the security community is facing today is to understand and
analyze emerging malware’s behavior in an effort to prevent
potentially epidemic consequences.
A popular approach to understanding malware behavior is to
run it in a sandbox. However, a well-known difﬁculty is that
the needed environment or setup may not be present (e.g.,
C&C server is down and critical libraries are missing) such
that the malware cannot be executed. In addition, recent mal-
ware often makes use of time-bomb and logic-bomb that deﬁne
very speciﬁc temporal and contextual conditions to release
payload, and some samples even use cloaking techniques such
as packing, and VM/debugger detectors that prevent execution
when the malware is being monitored.
Researchers in [32] proposed a technique called forced-
execution (X-Force)
that penetrates these malware self-
protection mechanisms and various trigger conditions. It works
by force-setting branch outcomes of some conditional instruc-
tions. (e.g., those checking trigger conditions). As forcing
execution paths could lead to corrupted states and hence
exceptions, X-Force features a crash-free execution model
that allocates a new memory block on demand upon any
invalid pointer dereference. However, X-Force is a very
heavy-weight technique that is difﬁcult to deploy in practice.
Speciﬁcally, in order to respect program semantics, when X-
Force ﬁxes an invalid pointer variable (by assigning a newly
allocated memory block to the variable), it has to update
all the correlated pointer variables (e.g., those have constant
offsets with the original invalid pointer). To do so, it has
to track all memory operations (to detect invalid accesses)
and all move/addition/subtraction operations (to keep track of
pointer variable correlations/aliases). Such tracking not only
entails substantial overhead, but also is difﬁcult to implement
correctly due to the complexity of instruction set and the
numerous corner situations that need to be considered (e.g., in
computing pointer relations). As a result, the original X-Force
does not support tracing into library functions.
In this paper, we propose a practical forced execution
technique. It does not require tracking individual memory or
arithmetic instructions. Neither does it require on demand
memory allocation. As such, the forced execution is very
close to a native execution, naturally handling libraries and
dynamically generated code. Speciﬁcally, it achieves crash-
free execution (with probabilistic guarantees) through a novel
memory pre-planning phase, in which it pre-allocates a region
of memory starting from address 0, and ﬁlls the region with
carefully crafted random values. These values are designed in
such a way that (1) if they are interpreted as addresses and
further dereferenced, the addresses fall into the pre-allocated
region and do not cause exception; (2) they have diverse
© 2020, Wei You. Under license to IEEE.
DOI 10.1109/SP40000.2020.00035
1121
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:18:55 UTC from IEEE Xplore.  Restrictions apply. 
random values such that semantically unrelated pointer vari-
ables unlikely dereference the same random address and avoid
causing bogus program dependencies and corrupted states. An
execution engine is developed to systematically explores dif-
ferent paths by force-setting different sets of branch outcomes.
For each path, multiple processes are spawned to execute the
path with different randomized memory pre-planning schemes,
further reducing the probability of coincidental failures. The
results of these processes are aggregated to derive the results
for the particular path. The engine then moves forward to the
next path.
Our contributions are summarized as follows.
• We develop a practical forced-execution engine that does
not entail any heavy-weight instrumentation.
• We propose a novel memory pre-planning scheme that
provides probabilistic guarantees to avoid crashes and
bogus program dependencies. The execution under our
scheme is very similar to a native execution. Once the
memory is pre-planned and initialized at the beginning,
the execution just proceeds as normal, without requiring
any tracking or on the ﬂy analysis (e.g., pointer correla-
tion analysis).
• We have implemented a prototype called PMP and eval-
uated it on SPEC2000 programs (which include gcc),
and 400 recent real-world malware samples. Our results
show that PMP is a highly effective and efﬁcient forced
execution technique. Compared to X-Force, PMP is 84
time faster, and the false positive (FP) and false negative
(FN) rates are 6.5X and 10% lower, respectively, regard-
ing dependence analysis; and detect 98% more malicious
behaviors in malware analysis. It also substantially super-
sedes recent commercial and academic malware analysis
engines Cuckoo [2], Habo [10] and Padawan [8].
II. MOTIVATION
In this section, we use an example to motivate the problem,
explain the limitations of existing techniques, and illustrate our
idea. The code snippet in Figure 1 simulates the command and
control (C&C) behavior of a variant of Mirai [7], a notorious
IoT malware that launches distributed denial of service attacks
when receiving commands from the remote C&C server. In
particular, it reads the maximum number of destination hosts
(to attack) from a conﬁguration ﬁle (line 9), and allocates
a Cmd object with sufﬁcient memory to store destination
information in the Dest objects (lines 10-12). When the
C&C server is connectable (line 15), the malware scans the
local network for the destination hosts (line 16), receives the
requested command (line 17), and performs the corresponding
actions on the destination hosts (lines 18-22).
To expose such malicious behavior, analysts could run the
sample in a sandbox and monitor its system call sequences
and network ﬂows [8]. Unfortunately, a naive execution-based
analysis is incomplete and hence cannot reveal all the mali-
cious payloads, especially those that are condition-guarded and
environment-speciﬁc. In our example, if the conﬁguration ﬁle
does not exist or the C&C server is not connectable, the mali-
cious behavior will not be exposed at all. One may consider to
construct an input ﬁle and simulate the network data. However,
such a task is time-consuming and not practical for zero-
day malware whose input format and network communication
protocol are unknown. In addition, recent malware samples are
increasingly equipped with anti-analysis mechanism, which
prevents these samples from execution even if they are given
valid inputs (please refer to Section IV for real-world cases).
This poses great difﬁculties for dynamic analysis.
Forced execution [32] provides a practical solution to sys-
tematically explore different execution paths (and, hence reveal
different program behaviors) without any input or environment
setup. It works by force-setting branch outcomes of a small set
of predicates and jump tables. One critical problem faced by
forced execution is invalid memory accesses due to the absence
of necessary memory allocations and initializations, which
are present in normal execution. Without appropriate handling
of invalid memory accesses, the program is most likely to
crash before reaching any malicious payload. In our example,
the malicious behaviors were supposed to be exposed, if the
predicate in line 15 is forced to take the true branch, and
the jump table in line 18 is forced to iterate different entries.
However, the forced execution fails in line 30, because cmd is
not properly allocated and its dests ﬁeld is not initialized.
X-Force. In X-Force [32], researchers show that simply ignor-
ing exceptions does not work as that leads to cascading failures
(i.e., more and more crashes), they propose to recover from
invalid memory accesses by performing on-demand memory
allocation. In particular, X-Force monitors all memory oper-
ations (i.e., allocate, free, read and write) to maintain a list
of valid memory addresses. If an accessed memory address is
not in the valid list, a new memory block will be allocated
on demand for the access. To respect program semantics,
when a pointer variable holding an invalid address x is set
to the address of the allocated memory, all the other pointer
variables that hold a value denoting the same invalid address
or its offset (e.g., x + c with c some constant) need to be
updated. X-Force achieves this through linear set tracing,
which identiﬁes linearly correlated pointer variables that are
induced by address offsetting. When a pointer variable is
updated, all the correlated pointers in its linear set need to
be updated accordingly based on their offsets.
Assume in an execution instance, line 8 takes the false
branch and line 15 is forced to take the true branch. In this
execution, cmd is a NULL pointer, hence the dests pointer
in line 27 points to 0x8 (the offset of dests ﬁeld is 8). The
rounded rectangle in Figure 1 illustrates what X-Force does
for the memory access of dests[0]->ip in line 30. Linear
sets are maintained for each register and each memory address.
In particular, SR(r) and SM (a) are used to denote the linear
set of register r and address a, respectively. After executing
instruction α, the linear set of register rbx is updated to be
the same as that of &dests, i.e., SR(rbx) ← SM(&dests)
such that SR(rbx)=SM(&dests)={0x7ffdfffffed0}, which
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:18:55 UTC from IEEE Xplore.  Restrictions apply. 
1122
Cmd *cmd = NULL;
int max = 0;
if (config_file_exists()) {
cmd->dests[i] = malloc(sizeof(Dest));
Dest **dests = cmd->dests;
for (int i = 0; i ip, dests[i]->ip);
dests[i]->port = ntohl(host->port);
26 void scan_intranet_hosts(Cmd *cmd, int max) {
27
28
29
30
31
32
33 }
01 typedef struct{char ip[16]; long port;} Dest;
02 typedef struct{long act; Dest* dests[0];} Cmd;
03
04 int main(int argc, char *argv[]) {
05
06
07
08
09
10
11
12
13
14
15
16
17
18
19
20
21
22
23
/* Validate Memory Address: get accessible(0x0) = false (invalid read on 0x0) */
24
/* Allocate Memory Block: malloc(BLOCK SIZE) = 0x2532000 */
/* Update Reference: rdx = *(0x7ffdfffffed0) = 0x2532000 + 0x8 = 0x2532008 */
25 }
Fig. 1: Motivation example. The assembly code here is functionally equivalent with the original one for easy understanding.
// rbx = [rbp - 0x10] = [0x7ffdfffffed0] = 0x8
/* Validate Memory Address: get accessible(0x7ffdfffffed0) = true */
/* Update Linear Set: SR(rbx) ← SM(&dests) = {0x7ffdfffffed0} */
// ecx = [rbp - 0x14] = [0x7ffdfffffecc] = 0x0
/* Validate Memory Address: get accessible(0x7ffdfffffed4) = true */
/* Update Linear Set: SR(rcx) ← SM(&i) = {0x7ffdfffffecc} */
/* Update Linear Set: SR(rdx) ← SR(rbx) = {0x7ffdfffffed0} */
// rdx = rbx + 8*rcx = 0x8
/* Validate Memory Address: get accessible(0x8) = false (invalid read on 0x8) */
/* Allocate Memory Block: malloc(BLOCK SIZE) = 0x2531000 */
/* Update Reference: rdx = *(0x7ffdfffffed0) = 0x2531000 + 0x8 = 0x2531008 */
}
...
if (cnc_server_connectable()) {
scan_intranet_hosts(cmd, max);
cmd->act = get_action_from_cc_server();
switch (cmd->act) {
case 1: do_action_1(cmd->dest, max); break;
case 2: do_action_2(cmd->dest, max); break;
...
}
α. mov rbx, [rbp - 0x10]
β. mov ecx, [rbp - 0x14]
γ. lea rdx, [rbx + 8*rcx]
}
}
...
δ. mov rax, [rdx]
// rax = [rdx] = [0x8]
. mov rax, [rax]
// rax = [rax] = [0x0]
is the address of dests. Intuitively, the pointer value in rbx
is linearly correlated to that in dests. Hence, ﬁxing either
one entails updating the other. The linear correlation is further
propagated to register rdx after executing instruction γ, since
its value is derived from rbx by address offsetting (i.e.,
&dests[0] = &dests + 0). When executing instruction δ,
X-Force detects an invalid access through the pointer denoted
by rdx (i.e., &dests[0]), holding an invalid address 0x8.
Hence, it allocates a memory block with address 0x2531000
and initializes it with zero values. Register rdx is then
updated to 0x2531008. The value of &dest should also be
updated, since it linearly correlates with rdx. Similar memory
recovery operations are needed for instruction  that accesses
dests[0]->ip through an invalid memory address 0x0.
As we can see that each memory operation should be
intercepted by X-Force for memory address validation and
linear set tracing. Upon the recovery of an (invalid) pointer
variable, all the linearly correlated variables need to be updated
accordingly. This causes substantial performance degradation.
It was reported that X-Force has 473 times runtime overhead
over the native execution [32]. Furthermore, since many library
functions such as string functions in glibc can lead to linear
set explosion (due to substantial heap array operations), X-
Force chose not to trace into library functions to update linear
sets. As a result, its memory recovery is incomplete (see
Section IV for a real-world example).
Our technique. We propose a novel randomized memory pre-
planning technique (called PMP) to handle invalid memory
accesses with probabilistic guarantees. Instead of allocating
new memory blocks on demand, PMP pre-allocates a large
memory block with a ﬁxed size (e.g., 16KB) when the
program is loaded. The pre-allocated memory area (PAMA)
is ﬁlled with carefully crafted random values such that if these
values are interpreted as memory addresses, the corresponding
into PAMA. We call
accesses still fall
this self-contained
memory behavior (SCMB). In addition, these random val-
ues are designed in a way that they are self-disambiguated.
That is, it is highly unlikely that two semantically unrelated
memory operations access the same random address, causing
bogus dependencies. We call this self-disambiguated memory
behavior (SDMB). For example, the simplest way to achieve
SCMB is to pre-allocate a chunk of memory starting at 0x00
and ﬁll it with 0x00. As such, dereferences of null pointers
(e.g., ∗p with p = 0) or pointers with some offset from null
(e.g., ∗(p + 8)), yield value 0x00 due to the initialization.
If the yielded value 0x00 is further interpreted as a pointer,
its dereference continues to yield 0x00, without causing any
memory exception. However, such a scheme leads to sub-
stantial bogus program dependencies as semantically unrelated
memory operations through uninitialized/invalid pointer vari-
ables all end up accessing address 0x00. For example, assume
p and q are not properly initialized and both have a null value
due to forced execution and there are two pointer dereference
statements “1. ∗ p = ...; 2. ... = ∗q”. A bogus dependence
will be introduced between 1 and 2. Such bogus dependencies
further lead to highly corrupted program states. SDMB is to
ensure that unrelated pointer variables have a high likelihood
to contain disjoint addresses such that it is like they were all
properly allocated and initialized. Intuitively, PMP diversiﬁes
the values ﬁlled in the pre-allocated large memory region such
that dereferences at different offsets yield different values.
Consequently, follow-up dereferences (of these values) can
continue to disambiguate themselves.
In addition to the aforementioned pre-planning, during
execution, PMP also initializes global, local variables, and
heap regions allocated by the original program logic with
random values pointing to PAMA. Note that otherwise they
are initialized to 0 by default. As such, when these variables
are interpreted as pointers and dereferenced without being
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:18:55 UTC from IEEE Xplore.  Restrictions apply. 
1123
                      0     1     2     3     4     5     6     7     8     9     a     b     c     d     e     f
0 x 0 0 0 0       8 0   f e   0 0   0 0   0 0   0 0   0 0   0 0   5 0   3 8   0 0   0 0   0 0   0 0   0 0   0 0
0 x 0 0 1 0       4 8   7 4   0 0   0 0   0 0   0 0   0 0   0 0   f 8   0 4   0 0   0 0   0 0   0 0   0 0   0 0
0 x 0 0 2 0       d 0   f f   0 0   0 0   0 0   0 0   0 0   0 0   0 8   0 0   0 0   0 0   0 0   0 0   0 0   0 0
0 x f f d 0       8 8   1 9   0 0   0 0   0 0   0 0   0 0   0 0   3 0   3 0   0 0   0 0   0 0   0 0   0 0   0 0
0 x f f e 0       4 0   f c   0 0   0 0   0 0   0 0   0 0   0 0   9 8   2 0   0 0   0 0   0 0   0 0   0 0   0 0
0 x f f f 0       2 0   5 0   0 0   0 0   0 0   0 0   0 0   0 0   e 8   a 7   0 0   0 0   0 0   0 0   0 0   0 0
Fig. 2: Pre-allocated memory area. The data is presented in
the little-endian format for the x86 64 architecture. The bytes
in gray are free to be ﬁlled with 8-multiple random values.
......
properly initialized along some forced path, the accesses still
fall in PAMA and also have low likelihood to collide (on
the same address). Through SCMB, PMP enables crash-free
memory operations, which are critical for forced execution.
Since it does not require tracing memory operations or per-
forming on-demand allocation, it is 84 times faster than X-
Force (Section IV). Through SDMB, PMP respects program
semantics such that it can faithfully expose (hidden) program
behaviors with probabilistic guarantees. As shown in our
evaluation (Section IV), PMP has fewer false positives (FP)
and false negatives (FN) than X-Force as well.
Figure 2 illustrates a 64-KB pre-allocated memory area
mapped in the address space from 0x0 to 0xffff. Note that
although this memory region may overlap with some reserved
address ranges, we leverage QEMU’s address mapping to
avoid such overlap (see Section III-E). It is ﬁlled with crafted
random values that ensure both SCMB and SDMB. For our
motivation example, instruction δ reads the memory unit at
address 0x8 (i.e., &dests[0]) and gets the value 0x3850.
Subsequently, the instruction  uses 0x3850 as the address
to access dests[0]->ip. These two accessed addresses
(0x8, 0x3850) are contained in the PAMA, hence no memory
exception occurs. The data dependence between these two
addresses are also faithfully exposed, without undesirable
address collision. Observe that there is no memory validation
and linear set tracing required.
We want to point out while SCMB and SDMB can be
effectively ensured in forced execution, they may not be as
effective in regular execution. Otherwise, dynamic memory
allocation could be completely avoided. The reason is that
forced execution aims to achieve good coverage to expose
program behaviors such that it bounds loop iterations [32].
As a result, linear scannings of large memory regions are
mostly avoided, allowing to establish SCMB and SDMB
effectively and efﬁciently. Intuitively, one can consider that
our design is equivalent to pre-allocating many small regions
that are randomly distributed. This is particularly suitable for
heap accesses in forced-execution as they tend to happen in
smaller memory regions. Even if overﬂows might happen, the
likelihood of critical data being over-written is low due to the
random distribution.
A. Overview
III. DESIGN
Figure 3 presents the architecture of PMP, which consists
of three components: the path explorer, the dispatcher and the
path
schemG
memory schemG n
memory schemG 1
…
Path Explorer
Dispatcher
execution result
Executor 1
80 fe 00 00 00 00 00 00 50 38 00 00 00 00 00 00
48 74 00 00 00 00 00 00 f8 04 00 00 00 00 00 00
d0 ff 00 00 00 00 00 00 08 00 00 00 00 00 00 00
......
88 19 00 00 00 00 00 00 30 30 00 00 00 00 00 00
40 fc 00 00 00 00 00 00 98 20 00 00 00 00 00 00
20 50 00 00 00 00 00 00 e8 a7 00 00 00 00 00 00
high address
(0x7fffffffffff)
end of PAMA
low address
(0x0)
stack
heap
…
.bss
.text
Pre-Allocated
Memory Area
(PAMA)
Executor n
Fig. 3: Architecture of PMP.
executors. Given a target binary, the path explorer systemat-
ically generates a sequence of branch outcomes to enforce,
including the PCs of the conditional instructions and their
true/false values. We call it a path scheme. Note that like
X-Force, PMP does not enforce the branch outcome of all
predicates, but rather just a very small number of them (e.g.,
less than 20). The other predicates will be evaluated as usual.
PMP operates in rounds, each round executing a path scheme.
For each path scheme, PMP further generates multiple versions
of variable initializations, each having different initial values
but satisfying both SCMB and SDMB. We call them memory
schemes. The reason of having multiple memory schemes is
to reduce the likelihood of coincidental address collisions.
A process is forked for each path and memory scheme and
distributed to an executor for execution. At the end of a round,
the dispatcher aggregates the results from the executors (e.g.,
coverage). Another path scheme is then computed by the path
explorer to get into the next round, based on the results from
previous rounds.
Path Explorer. In essence, path exploration is a search process
that aims to cover different parts of the subject binary. In each
round, a new path scheme is determined by switching ad-
ditional/different predicates, or enforcing additional/different
jump table entries, to improve code coverage. Since the search
space of all possible paths is prohibitively large for real-world
binaries, PMP follows the same path exploration strategies in
X-Force [32], including the linear search, the quadratic search
and the exponential search. In particular in each round, the
linear search selects a new predicate or jump table entry to
enforce, which is usually the last one that does not have all its
branches covered in previous rounds. The exponential strategy
aims to explore all combinations of branch outcomes and is
hence the most expensive. It is only used to explore some
critical code regions. Quadratic search falls in between the
two. Since these are not our contributions, interested readers
are referred to the X-Force project [32].
Dispatcher. The dispatcher aggregates execution results (e.g.,
code coverage and program dependencies) of multiple ex-
ecutors in a conservative fashion. Speciﬁcally, it considers
a result valid if and only if it is agreed by n executors,
with n conﬁgurable. In our experience, n = 2 is good
enough in practice. Such aggregation further improves our
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:18:55 UTC from IEEE Xplore.  Restrictions apply. 
1124
Program Loading
During Execution
PAMA
(cid:78) (cid:66)(cid:81)
(cid:78)
PAMA Preparation
crafted file
address space
program entry
Global Variable Init
call instructions
Local Variable Init
memory allocation
Heap Init
Fig. 4: Workﬂow of Memory-preplanning.
probabilistic guarantees. Intuitively, assume PMP ensures that
a reported result has lower than p ∈ [0, 1] probability to be
incorrect during a single execution (on an executor), due to
the inevitable accidental violations of SCMB or SDMB. The
aggregation further reduces the probability to pn if the memory
schemes on the various executors are truly randomized (and
hence independent).
Executors. All executors are forked from the same main
process with the same initialized PAMA. Each executor then
enforces a given path and memory scheme assigned to it. Such
a design avoids the redundant initialization of PAMA. Note
that all memory accesses must start from some variable, whose
value is fully randomized across executors.
The rest of this section will explain in details the memory
pre-planning step and the probability analysis for SCMB and
SDMB guarantees. Execution result aggregation is omitted due
to its simplicity.
B. Memory Pre-planning
Overview. Figure 4 presents the workﬂow of memory pre-
planning. When a program is loaded, a pre-allocated memory
area (PAMA) is prepared by invoking the mmap system call
to map a crafted ﬁle to the program address space. The ﬁle
content is randomly generated beforehand. During execution,
program variables (including global, local variables and heap
regions) are initialized by PMP with random eight-multiple
values pointing to PAMA. Speciﬁcally, PMP intercepts: 1) the
program entry point for initializing global variables; 2) call
instructions for initializing local variables; and 3) memory
allocations for initializing heap regions. Note that PAMA
preparation happens a priori and incurs negligible runtime
overhead, while variable initialization occurs on-the-ﬂy during
execution. Both are generic and do not require case-by-case
crafting. We further discuss these steps in the following.
PAMA Preparation. PAMA is mapped at the lower part of
the address space starting from 0x0, in order to accommodate
null pointers or pointers with invalid small values. The word-
aligned addresses within PAMA (i.e., those having 0 at the
lowest three bits) are ﬁlled with carefully crafted random
values, such that if these values are interpreted as addresses,
they fall within PAMA. As such, the range of random values
that we can ﬁll is dependent on the size of PAMA. For a
64-KB PAMA (i.e., in the address range of [0, 0xffff]), the
ﬁrst two least-signiﬁcant bytes of a ﬁlling value are free to
be set with a random eight-multiple value. Other bytes are
ﬁxed to zero. Note that such a value is essentially a valid
word-aligned address in PAMA. For a 64-MB PAMA, the
ﬁrst three least-signiﬁcant bytes of a ﬁlling value can be set
randomly, providing better SDMB. The maximum PAMA can
be as large as 128 TB, as a larger PAMA would overlap with
the kernel space. While a feasible design is to change the entire
virtual space layout (by changing kernel), it would hinder the
applicability of our technique. In practice, we ﬁnd that 4-MB
of PAMA provides a good balance of SCMB and SDMB.
Global Variable Initialization. In an ELF binary, the unini-
tialized or zero-initialized global variables are stored in the
.bss segment. During loading, PMP reads the offset and size
information of the .bss segment from the ELF header. PMP
then initializes the segment like a heap region.
Heap Initialization. Pre-planning heap regions that are dy-
namically allocated by instructions in the subject binary is
relatively easier. PMP intercepts all memory allocations and
set
the allocated regions to contain random word-aligned
PAMA addresses. Note that PMP writes these values to each
word-aligned address in the heap region. If a regular compiler
is used to generate the subject binary, the compiler would
enforce pointer-related memory accesses to be word-aligned
through padding. However, malware may intentionally intro-
duce pointer accesses that are not word-aligned. Section III-E
will discuss how PMP handles such cases. In the following
discussion, we always assume word alignment.
Local Variable Initialization. Initializing local variables is
more complex. After initializing PAMA and before spawning
the executors, PMP initializes the entire stack region like a
heap region. Note that stack frames are pushed and popped
frequently and the same stack address space may be used by
many function calls. As such, the stack space may need to be
re-initialized. A plausible solution is to identify stack frame
allocations (e.g., updates of rsp register) and conduct initial-
ization after each allocation. However, due to the ﬂexibility
of stack allocations, it is difﬁcult to precisely identify them.
Inspired by stack canaries used to detect stack overﬂows, PMP
uses the following design to initialize stack regions. It inter-
cepts each function invocation. Then starting from the current
address denoted by rsp, it randomly checks eight 1 unevenly
distributed addresses lower than the rsp address (i.e., the
potential stack space to be allocated), in the order from high
to low, to see if they are PAMA addresses (meaning that they
were not overwritten by previous function invocations). We
also call these addresses canaries without causing confusion in
our context and use Ci to denote the ith canary. PMP identiﬁes
the lowest (last) canary that is not PAMA address, say Ct, and
then re-initializes [Ct+1, rsp] (note that stack grows from high
address to low address). If all eight canaries are overwritten,
PMP continues to check the next eight. Observe that since
stack writes may not be continuous, the detection scheme has
only probabilistic guarantees. In practice, our scheme is highly
1Eight is an empirical choice and works well in our evaluation. The number
and the distribution of canaries are conﬁgurable.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:18:55 UTC from IEEE Xplore.  Restrictions apply. 
1125
*e = 0x6038; // [0x0000] = 0x6038
long tmp = *f; // tmp = [0x0000]: bogus dep!
long *e = NULL, *f = NULL;
if (cond1()) init(e, f);
if (cond2()) {
01 typedef struct{double *f1; long *f2;} T;
02 typedef struct{char f3; long *f4; long *f5;} G;
03 G *g;
04
05 void case3() {
06
07
08
09
10
11
12 }
13
14 void case4() {
15
16
17
18
19
20 }
*(g->f4) = 0x0830;
long tmp = *(g->f5); // &(g->f5) = 0x10000
if (cond1()) init(g);
if (cond2()) {
}
}
}
21 void case1() {
22
23
24
25
26
27
28
29
30
31 }
32
33 void case2() {
34
35
36
37
38
39
40 }
}
long *c; double **d;
if (cond1()) init(c, d);
if (cond2()) {
*c = 0xdeadbeef;
// [0xffd8] = 0xdeadbeef
double tmp = **d; // [0xdeadbeef]: error!
long **a = malloc(...);
T *b;
if (cond1()) init(b);
if (cond2()) {
long *alias = b->f2;
*(b->f2) = **a; // [0x0008] = [0x0010]
*(b->f1) = 0.1; // [0xffd0] = 0.1
long tmp = *alias;
Local Variable (case1)
Heap Region
(a) code snippet.
a:0x01ed7010
b:0x20
canary C1
canary C2
...
...
...
canary C3
...
Global Variable
g:0xfff0
  0 x 1 e d 7 0 1 0       1 0   0 0   0 0   0 0   0 0   0 0   0 0   0 0  
PAMA
0     1     2     3     4     5     6     7     8     9     a     b     c     d     e     f
0 x 0 0 0 0       8 0   f e   0 0   0 0   0 0   0 0   0 0   0 0   5 0   3 8   0 0   0 0   0 0   0 0   0 0   0 0
0 x 0 0 1 0       4 8   7 4   0 0   0 0   0 0   0 0   0 0   0 0   f 8   0 4   0 0   0 0   0 0   0 0   0 0   0 0
0 x 0 0 2 0       d 0   f f   0 0   0 0   0 0   0 0   0 0   0 0   0 8   0 0   0 0   0 0   0 0   0 0   0 0   0 0
ef be ad de 00 00 00 00 after line 37
0 x f f d 0       8 8   1 9   0 0   0 0   0 0   0 0   0 0   0 0   3 0   3 0   0 0   0 0   0 0   0 0   0 0   0 0
0 x f f e 0       4 0   f c   0 0   0 0   0 0   0 0   0 0   0 0   9 8   2 0   0 0   0 0   0 0   0 0   0 0   0 0
0 x f f f 0       2 0   5 0   0 0   0 0   0 0   0 0   0 0   0 0   e 8   a 7   0 0   0 0   0 0   0 0   0 0   0 0
...
Local Variable (case2)
c:0xf1d8
d:0xffd8
(b) memory scheme.
Fig. 5: Memory pre-planning.
effective and we haven’t encountered any problems caused by
incorrect stack initialization.
Example. We use the code snippet shown in Figure 5a as
an example to explain the memory pre-planning process. In
the code, a global variable g is deﬁned at line 3, two local
variables a, b are deﬁned in function case1(). Assume in
an execution instance, line 24 takes the false branch and b
is not allocated and initialized; and line 25 is forced to take
the true branch. Although a is initialized by the original
program code with an allocated heap region, the data in the
heap region is not initialized. Without memory pre-planning,
the program would have exception at any of the memory
operations in lines 26-29.
In this example, the global variable g is set to a random
PAMA address at the beginning. Upon calling case1(),
PMP checks the canaries at C1, C2, and so on (see the stack
frame in the top-left corner of Figure 5b), and then identiﬁes,
say, the region from [C3,rsp] needs re-initialization, which
includes local variables a and b. Inside the function body,
a is set to a dynamically allocated heap region at line 22,
but other variables such as g and b keep their initial PAMA
address value (as line 24 is not executed). Speciﬁcally, g and b
point to 0xfff0 and 0x20 (in PAMA), respectively. Consider the
read operation at line 28 that triggers pointer dereferences on
b and then b->f1. The former dereferences address 0x20 and
yields value 0xffd0, which is further interpreted as an address
in the follow-up dereference of b->f1, yielding another valid
PAMA address. Observe that any following dereferences will
be within PAMA and do not cause any exceptions, illustrating
the SCMB property. The value of b->f1 (i.e., 0xffd0) deref-
erenced at line 28 is different from that of b->f2 (i.e. 0x08)
dereferenced at line 27, and hence disambiguate themselves,
illustrating SDMB.
C. Other PAMA Memory Behavior and Interference with
Regular Memory Operations.
Memory pre-planning is particularly designed to handle
exceptional memory operations (caused by forced execution).
As such, all the values ﬁlled in PAMA are essentially in
preparation for these values being interpreted as addresses and
further dereferenced. It is completely possible that the subject
binary does not interpret values from PAMA as addresses.
For example, it may interpret a PAMA region as a string
and access individual bytes in the region. In such cases, the
accessed values are just random values. This is equivalent to
how X-Force handles uninitialized/undeﬁned buffers.
A PAMA location can be written to and later read from
by instructions in the subject binary, dictated by the program
semantics. Program dependencies induced by PAMA are no
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:18:55 UTC from IEEE Xplore.  Restrictions apply. 
1126
different from those induced through regular memory regions.
For example, the code at line 26 in Figure 5a establishes
an alias between variable alias and b->f2. At line 27, a
memory write is conducted on b->f2. At line 29, a memory-
read is conducted on alias. PMP can correctly establish the
dependence between line 27 and line 29, since they both point
to the same memory address 0x8.
It may happen that a PAMA location is written to by the
subject binary and then read through a semantically unrelated
invalid pointer dereference later. As the written value may not
be a legitimate PAMA address, the later read causes exception.
For example,
line 37 at function case2() of Figure 5a
writes a value 0xdeadbeef that is not a word-aligned address
within PAMA to the address indicated by pointer c. Assume
c happens to have the same value 0xffd8 as an unrelated
pointer d. The write to *c also changes the value in *d to
0xdeadbeef. As such at line 38, an exception is triggered for
the read of **d. In the next subsection, our probability anal-
ysis shows that such cases rarely happen as the likelihood for
two semantically unrelated pointers are initialized to the same
random value is very low. Furthermore, PMP employs different
memory schemes in multiple executors, further reducing such
possibility.
In the worst situation, the subject binary uses its own in-
structions to set semantically unrelated pointers to null. In nor-
mal execution, these pointers would point to different properly
allocated memory regions. However in forced execution, they
may not be allocated, and all point to address 0. In such cases,
PMP cannot disambiguate the accesses of these variables, and
lead to bogus dependencies. For example, the local variables
e and f in function case3 () of Figure 5a are explicitly
set to null by the original program code. In forced execution
where line 7 is not executed, they point to the same address
0x0, resulting in bogus dependence (e.g., between lines 9 and
10). Our experimental results in Section IV show that such
cases rarely happen.
D. Probability Analysis
In this section, we study the probabilistic guarantee of
PMP for the SCMB and SDMB properties. Violations of
SCMB lead to exceptions whereas violations of SDMB lead to
bogus dependences and corrupted variable values. To facilitate
discussion, we introduce the following deﬁnitions. Let PA be
the set of all possible addresses within PAMA, and WA be its
word-aligned subset. Assume the size of PAMA is S. Then,
on a 64-bit architecture, we have equation (1).
S = |PA| = |WA| × 8
(1)
In addition, let FV be a random subset of WA, called the
ﬁlling value set, whose elements are used as the values to
be ﬁlled in PAMA. Without loss of generality, we assume 0
belongs to FV. We deﬁne the ratio between the size of FV
and the size of WA as diversity, denoted as d. Then, we have
equation (2).
|FV| = |WA| × d = d·S
8
(2)
The initialization of PAMA can be formulated as a mapping
f : WA (cid:5)→ FV, which assigns each word (with 8 bytes
alignment) in PAMA (i.e., denoted by addresses in WA) with
a random value selected from FV. Intuitively, a more diverse
FV leads to a more random memory scheme. The initialization
that ﬁlls the whole PAMA with value 0 can be considered an
extremal case where FV contains only a single element 0. Note
that in this case, SCMB is fully respected, while SDMB is
substantially violated as all invalid memory operations collide
on address 0.
Probabilistic Guarantee of SCMB. When a pointer variable
is initialized (by PMP) with a value indicating an address close
to the end of PAMA, dereference of its offset may result in an
access out of the bound of PAMA. As an example, consider
the dereference of g->f5 at line 18 of function case4() in
Figure 5a. Recall that g is set to be 0xfff0 by PMP. The address
of g->f5 is hence 0x10000, out of the bound of PAMA with
16 KB size.
Theorem 1. Let x be a ﬁlling value selected from FV, α be an
offset. The probability Perr1 of x + α being out of the bound
of PAMA is calculated by equation (3).
Perr1 = P ((x+α)(cid:7)∈ PA | x∈ FV) = α
S−8
1− 8
d · S
(cid:2)
(cid:3)
(3)
·
(cid:3)
(cid:4)
(cid:4)
(cid:5)
α(cid:2)
i
α(cid:2)
i
) = α
S(cid:2)−2
N−2
/N )·(
Proof. For PMP to access an out-of-bound address x +
set IA = WA ∩
α, x must belong to an address
{S−α, S−α+1, . . . , S−1}. To simplify discussion, let α
(cid:3) =
(cid:3) =|WA| and N =|FV|. Let the size of IA ∩ FV
|IA| = α/8, S
(cid:5)
(cid:4)
be i. We can infer conditional probability P (x∈ IA |x∈ FV) =
S(cid:2)−1
i/N , denoted as Pi1. Additionally, because there are
N−1
(cid:5)·(cid:4)
possible FVs that could be uniformly chosen from (recall
(cid:5)(cid:6)(cid:4)
0∈ FV always holds) and
S(cid:2)−α(cid:2)−1
(cid:4)
(cid:5)·(cid:4)
(cid:5)
FVs have i common
N−i−1
elements with IA, P (|FV ∩ IA| = i) =
S(cid:2)−1
S(cid:2)−α(cid:2)−1
,
N−i−1
N−1
(cid:5)(cid:6)(cid:4)
(cid:5)
(cid:5)
S−8 ·(cid:4)
(cid:7)α(cid:2)
(cid:3)}, Perr1 =
denoted as Pi2. Enumerating size i ∈ {1, . . . , α
i=1 Pi1·Pi2 = (α
1− 8
S(cid:2)−1
N−1
d·S
Intuitively, the larger the pre-allocated memory area (i.e.,
S) and the lower the diversity (i.e., d), the lower the Perr1. In
particular, the Perr1 of a naive initialization that ﬁlls PAMA
with value 0 is 0. In a typical setting of S = 0x400000, α = 8
and d = 1, Perr1 = 1.9073e−06, illustrating a very low chance
of exception. A plausible way to completely avoid SCMB
violation is to avoid using address values close to the end
of PAMA. However this requires knowing the largest possible
offset, which is difﬁcult in practice.
Probabilistic Guarantee of SDMB. SDMB will be compro-
mised when two unrelated pointers are initialized to the same
value by chance. Taking local variables c and d for case2()
in Figure 5a as an example, both of them are initialized to
0xffd8, causing invalid pointer dereference at line 38.
Theorem 2. Let x and y be two ﬁlling values independently se-
lected from FV. The probability Perr2 of coincidental address
collision, when x and y have the same value, is calculated by
equation (4).
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:18:55 UTC from IEEE Xplore.  Restrictions apply. 
1127
Perr2 = P (x = y | x∈ FV, y∈ FV) =
8
d·S
(4)
Proof. Recall x and y are independently selected from FV.
Thus, ﬁxing x = v0 as a constant, we can infer Perr2 = P (y =
v0 |y∈ FV) = 1/|FV| = 8/(d·S) .
With a typical setting d = 1 and S = 0x400000, Perr2 =
1.9073e−06, a very low probability.
Perr3 =P (l (x, β) ∩ l (y, γ) (cid:3)= ∅ | x∈ FV, y∈ FV)
≤ 64
d2·S2
+(1− 8
d·S
)2· β +γ− 8
S−8
(5)
Proof is elided due to space limitations. With a setting of
β = 0x1000, γ = 0x1000, and the rest as the same before,
Perr3 = 0.00195, still reasonably low. Note that one can
always improve the guarantee by having more executors with
different pre-plans.
E. Implementation
PMP is implemented based on the QEMU user-mode em-
ulator [9]. Speciﬁcally, PMP instruments conditional jumps
and indirect jumps to enforce path scheme. A path scheme is
a sequence of branch outcomes that need to be enforced. As
an instance, “401a4c:T, 4094fc:F, 40a322#40a566” is a path
scheme that contains three branch outcomes to be enforced in
order. Particularly, the predicates at 0x401a4c and 0x4094fc
should take the true branch and false branch respectively,
the jump table at 0x40a322 should take the entry at 0x40a566.
Currently, PMP supports ELF binary on the x86 64 platform.
It can be easily extended to support other architectures due to
the cross-platform feature of QEMU. We leave it as our future
work. In the rest of the subsection, we discuss a number of
practical challenges faced by PMP.
Handling File and Network I/O, Inﬁnite Loop and Re-
cursion. Forced execution may result in exceptional program
behaviors, such as invalid ﬁle/network access, inﬁnite loop
and inﬁnite recursion. To make PMP applicable to real-world
executables, these issues need to be handled. PMP follows
similar solutions to X-Force regarding these problems. The
difference lies in that we implement them on QEMU while
X-Force was on PIN. We brieﬂy discuss these solutions for
the completeness of discussion.
To handle invalid ﬁle access, PMP wraps ﬁle open functions
(e.g., open and fopen). If the ﬁle to be opened does not
exist, a ﬁle padded with random values will be used. To
handle inﬁnite loop, PMP adopts the proﬁling-based approach
proposed in [31] to dynamically identify loop structures. For
each identiﬁed loop structure, PMP resets the loop bound
to a pre-deﬁne constant. This is more sophisticated than X-
Force, which uses a ﬁxed global
loop bound. To handle
inﬁnite recursion, PMP intercepts call and return instructions
to maintain a call stack. At each function invocation, PMP
checks whether the appearances of the target function in the
call stack exceed a pre-deﬁned threshold. If so, PMP skips
the function invocation. Note that while maintaining a faithful
shadow call stack is very challenging due to the various strange
calling conventions, PMP does not require a precise shadow
stack.
Allocation of Large PAMA. PAMA is located at the lower
part of the address space starting from 0x0. The default load
address for non-position-independent executables is usually
0x400000. If the size of PAMA is larger than 4MB, there
will be overlap between PAMA and the text/data segment of
the subject executable, which is problematic.
(cid:2)
={x − base | x∈ FV}.
To support large-size PAMA, we enable the address map-
ping mechanism provided by QEMU, which translates a guest
address (denoted as GA) used by the subject executable to a
host address (denoted as HA) used by QEMU. In the user-
mode emulation, QEMU and the subject executable share the
same address space. The address mapping g2h is ﬂattened to
essentially an offsetting operation, such that ha = g2h(ga) =
ga + base, where ga∈ GA, ha∈ HA, and base is a pre-deﬁned
base address. We set the base address to the size of PAMA to
avoid any overlap. Consequently, we need to adjust the ﬁlling
values accordingly such that they are mapped to the addresses
within PAMA (started from 0x0 in the host space). Formally,
(cid:2)
be the set of the adjusted ﬁlling values. Then we have
let FV
FV
Misaligned Memory Access. The memory pre-planning of
PMP assumes that any pointer ﬁeld of a structure is word-
aligned. It is a reasonable assumption for most real-world
applications, since making pointer ﬁelds word-aligned (by
padding if needed) is the default behavior of compilers. For
example, mainstream compilers will place a 7-byte padding
between the f3 ﬁeld and the f4 ﬁeld of the structure G in
Figure 5a by default, such that the offset of f4 is word-aligned.
Although we didn’t ﬁnd any real-world cases in our eval-
uation, it is possible to disable word-alignment via a spe-
cial compilation option. The misalignment of a pointer ﬁeld
(within PAMA) may result in invalid memory access. For
example, assume the global variable g in Figure 5a points
to 0xfff0 set by PMP. If its pointer ﬁeld f4 is not word-
aligned, its value will be loaded from 0xfff1, which would be
0xe800000000000050. If this value is used as an address, the
access falls out of PAMA (even out of the user address space)
and causes exception.
We develop the following mechanism in the dispatcher
to handle misaligned memory accesses in a demand driven
fashion. If a path scheme results in invalid memory access in
all the executors (most likely induced by misaligned accesses),
the dispatcher checks the QEMU exception log to acquire
the instruction i that accesses misaligned address. Then PMP
additionally intercepts the code generation of instruction i
to mask the most-signiﬁcant bytes of the accessed memory
address to make it fall within PAMA. Note that while our
design anticipates misaligned pointer ﬁeld accesses are rare,
which is true according to our experience (see Section IV), it is
possible future malware may purposely introduce lots of such
misalignments. In this case, PMP would have to instrument
all memory operations to sanitize the addresses.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:18:55 UTC from IEEE Xplore.  Restrictions apply. 
1128
IV. EVALUATION
A. Experiment Setup
We evaluate PMP with the SPEC2000 benchmark set as
well as a set of malware samples provided by VirusTotal [12]
and Padawan [8]. The experiment on SPEC2000 is conducted
on a desktop computer equipped with an 8-core CPU (Intel R(cid:9)
CoreTM i7-8700 @ 3.20GHz) and 16G main memory. The
experiment on the malware samples is conducted on a virtual
machine (to sandbox their malicious behaviors) hosted on
the same desktop. On both experiments, the conﬁguration of
PMP is as follows: 4-MB pre-allocated memory area (i.e.,
S = 0x400000), diversity d = 1, and 2 executors (i.e., n = 2).
B. SPEC2000
SPEC2000 is a well-known benchmark set contains 12 real
world programs, some of them are large (e.g., 176.gcc). The
list of programs and the characteristics of their executables can
be found in Appendix A. We choose SPEC2000 for the pur-
pose of comparison as it was used in X-Force. Table I presents
the comparative results on different aspects, including forced
execution outcomes, code coverage and memory dependence.
Forced Execution. In this experiment, both PMP and X-Force
use the same linear path exploration strategy. Speciﬁcally, it
ﬁrst executes the binary once without forcing any branch out-
come. Then it traverses the executed predicates in the reverse
temporal order (the last predicate ﬁrst) and ﬁnds the predicate
that has an uncovered branch. A new path scheme is then
generated to force-set the uncovered branch. The procedure
repeats until there are no more schemes that can lead to new
coverage. Column 2 in Table I reports the total execution time
when PMP ﬁnishes the exploration. Columns 3 and 4 present
the number of executions that pass and fail (i.e., encounters
an exception), respectively. The number in parentheses denote
the number of executions ﬁnished per second. Columns 11-
13 show the corresponding results for X-Force. From these
results, we have the following observations. (1) PMP can
perform 12.6 forced executions per second on average, which
is 84 times faster than X-Force (0.15 execution per second).
Since PMP uses 2 executors for each path scheme, one may
argue that X-Force can be parallelized to use two cores (for fair
comparison). We want to point out that ﬁrst it is unclear how to
parallelize the linear search algorithm; and the second executor
in PMP is just to provide better probabilistic guarantees. In
most cases, such improvement may not have practical impact
(see our next experiment). Hence in deployment, additional
executors may be turned off. (2) The execution failure rate of
PMP is 3.5%, which is reasonably low and comparative with
X-Force. Note that the rate is higher than what we identiﬁed in
the SCMB probability analysis (Section III-D). The reason is
that the majority of failures reported by both PMP and X-Force
are not caused by memory exceptions, but rather inevitable as
the path explorer forces the execution to enter branches that
must lead to failures (e.g., forcing the true branch of a stack
smash check inserted by the compiler).
Code Coverage. Columns 5∼7 and 14∼16 show the code
coverage of PMP and X-Force, respectively. Observe that on
average PMP covers 83.8% instructions, 79.1% basic blocks
and 91.8% functions, which is comparable to X-Force. For
most of the benchmark programs, PMP achieves more than
80% code coverage. Speciﬁcally, for mcf and gzip, PMP
achieves 100% code coverage.
The worst cases are eon and gcc. Further manual inspection
shows that this is due to some inherent shortcoming of the
linear search strategy. To illustrate, consider the code snippet
in Figure 6, which is extracted from gcc that validates function
arguments before proceeding. When the check_arg() func-
tion is invoked for the ﬁrst time at line 2, the true branch of
predicate at line is taken by default. The linear path exploration
will force the next execution to take the false branch, since it
has not been covered before. At the second-time invocation of
check_arg() at line 3, the false branch of the predicate
at line 8 will not be forced to execute again (hence take the
true branch by default), since it has been covered before.
That means, the code after line 3 will not get executed due to
the validation failure at line 3.
The essence of the problem is that
linear search only
focuses on predicates, without considering their context. For
example, function check_arg() may be invoked from mul-
tiple places, and each calling context should be considered
differently. That is, a branch being covered in a context should
not prevent it from being explored again in a different context.
In our future work, we will explore a context-sensitive path
exploration method that can provide probabilistic guarantees.
Speciﬁcally, we will explore a sampling algorithm that can
sample a predicate, together with its unique context, in a
speciﬁc distribution (e.g., uniform distribution).
Memory Dependence. We also conducted an experiment,
in which we detect the program dependencies exercised by
forced execution. A dependence is exercised when an in-
struction writes to some address, which is later read by
another instruction. This is to evaluate the SDMB property
of PMP. Note that
is intractable to acquire the ground
truth of program dependencies, even with source code (due
to reasons such as aliasing). Therefore, we use two methods
to evaluate the quality of detected dependencies. First, we run
the SPEC programs on the inputs provided by the SPEC suite
(some of them are large and comprehensive) and collect the
dependencies observed. These must be true positive program
dependencies. As such, forced execution is supposed to expose
most of them. Any missing one is an FN. Second, we built a
static type checker to check if the source and destination of a
(detected) dependence must have the same type. We developed
an LLVM pass to propagate symbolic information to individual
instructions, registers, and memory locations such that we
know the type of each binary operation and its operands. Note
that we need the symbolic information just for this experiment.
PMP operates on stripped binaries. Ideally, force execution
should report as few mistyped dependencies as possible. Each
mistyped dependence must be an FP. Columns 8∼10 and
it
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:18:55 UTC from IEEE Xplore.  Restrictions apply. 
1129
TABLE I: SPEC2000 Results
Benchmark
164.gzip
175.vpr
176.gcc
181.mcf
execution status
time (s)
# run
382
24.6
(15.6/s)
1,006
76.8
(13.1/s)
3490.2 26,524
(7.6/s)
144
8.6
186.crafty
860.3
197.parser
252.eon
98.2
37.2
253.perlbmk
1,189
254.gap
1,054
255.vortex
487.0
256.bzip2
16.0
300.twolf
Average
221.4
-
(16.7/s)
2,753
(3.2/s)
1,590
(16.2/s)
707
(19.0/s)
10,318
(8.7/s)
7,754
(7.3/s)
7,232
(14.9/s)
249
(15.6/s)
2,972
(13.4/s)
12.6/s
PMP
code coverage
memory dependence
execution status
memory dependence
X-Force
code coverage
# run
369
(0.17/s)
1,000
9,436
(0.10/s)
347,014 26,647
(0.08/s)
164
(0.43/s)
2,830
(0.03/s)
1,685
(0.27/s)
659
(0.5%)
2
0
0
61
374
1,718
3,529
13,418
(100%)
(1%)
15
(0%)
20
(0%)
333
(2%)
11,467
(2%)
# fail
11
(3%)
82
(8%)
822
(3%)
699
(99%)
2,007
(71%)
16,104
(44%)
213
# insn # block # func # found # correct # mistyped time (s)
7,650
2,112
(100%)
26,783
(83%)
186,310
(49%)
2,977
(100%)
40,404
(96%)
22,093
(90%)
28,600
(71%)
118,135
(88%)
49,869
(54%)
100,718
(92%)
6,338
(92%)
52,351
(91%)
2,824
(80%)
226
8,983
(89%)
(67%)
1,239
(65%) 573,375 384,161
(67%)
1,248
24
(73%)
(100%)
14,300
104
(100%) 22,437
(64%)
6,664
279
9,958
(67%)
(94%)
4,457
502
(47%)
(82%)
28,394
692
(97%)
(43%)
20651
401
(54%)
(88%)
19,939
577
(36%)
(92%)
2,375
(86%)
10,333
(43%)
60.6%
68
(4%)
27
(4%)
508
(5%)
310
(4%)
157
(2%)
13
(95%)