Hacking in the 
Name of Science
Tadayoshi (Yoshi) Kohno (University of Washington)
Jon Callas (PGP Corporation)
Alexei Czeskis (University of Washington)
Daniel Halperin (University of Washington)
Karl Koscher (University of Washington)
Michael Piatek (University of Washington)
DEFCON 16 - August 8, 2008
Who We Are
✦ Researchers at the University of Washington
✦
Tadayoshi Kohno, http://www.cs.washington.edu/homes/yoshi/
✦
Alexei Czeskis,http://www.cs.washington.edu/homes/aczeskis/
✦
Daniel Halperin, http://www.cs.washington.edu/homes/
dhalperi/
✦
Karl Koscher, http://www.cs.washington.edu/homes/supersat/
✦
Mike Piatek, http://www.cs.washington.edu/homes/piatek/ 
✦ Co-founder of PGP Corporation
✦
Jon Callas, PI:EMAIL
Focus for Today
Explore “hacking” in the academic community
For concreteness, we base this talk on our own 
research (often in collaboration with others)
We call this line of work many things, like 
“attacks research” or “measurements,” but  
never “hacking”
About Yoshi
✦ Others will introduce themselves when they ﬁrst start
✦ Ph.D. from University of California San Diego
✦ Lots of crypto / mathy stuff
✦ But also lots of work on analyzing real systems -- 
and that’s the focus of today’s talk
✦ Past industry work:  Bruce Schneier’s old company, 
and Cigital
✦ Now:  Faculty at the University of Washington
Previews for Today
First public analysis of Diebold’s AccuVote-TS e-voting 
source code (2003, Kohno, Stubbleﬁeld, Rubin, Wallach)
Previews for Today
First public analysis of a common wireless implantable 
medical device (2008, Halperin, Heydt-Benjamin, Ransford, 
Clark, Defend, Morgan, Fu, Kohno, Maisel)
Previews for Today
Measurement study of in-ﬂight changes to web pages by ISPs 
and others (2008, Reis, Gribble, Kohno, Weaver)
ISP
Firewall
Previews for Today
Measurement study of DMCA notices in BitTorrent (2008, 
Piatek, Krishnamurthy, Kohno)
Previews for Today
Fingerprinting physical machines based on information 
leakage and clock skew (2005,Kohno, Broido, and Claffy)
Previews for Today
Information leakage and encrypted streaming multimedia: the 
case of the Slingbox Pro (2007, Saponas, Lester, Hartung, 
Agarwal, and Kohno)
Previews for Today
Information leakage and deniable ﬁlesystems like TrueCrypt 
(2008, Czeskis, St. Hilaire, Koscher, Gribble, Kohno, and 
Schneier)
Contents of a 
“hidden” ﬁle
Previews for Today
Exploring privacy in a future world with ubiquitous 
surveillance (the UW RFID Ecosystem team)
Previews for Today
Developing the “Security Mindset” in a University of 
Washington undergraduate computer security course
Previews for Today
Why is this science and not just hacking?
Previews for Today
The Industry Perspective
Previews for Today
Your Turn!  Let’s discuss!
What can academics learn from you?
What do you think we could do better?
What would you like us to look at next?
What shouldn’t we be doing?
Who/What/When/Where/Why/How ?
We Build Too!
We build secure systems too!
But the focus of this talk is on “academic 
security analyses,” so we omit many 
projects
Visit our websites if you are interested!
Part 1: “Our Hacks” 
Background
✦ The academic model
✦ We experiment with technologies
✦ Analyze existing ones
✦ Build new ones
✦ But we also need to publish our results in 
peer-reviewed venues (conferences, journals)
✦ As scientists, we seek to learn new things about 
and improve our world, and our approaches must 
be rigorous 
Background
✦ We provide links to our papers in subsequent 
slides
✦ If you’d like more detailed examples of what 
an academic paper looks like, please follow 
these links
✦ We will highlight some critical properties of 
academic security research
Type A: Analyzing 
Critical Systems  
Properties of these projects
✦ Focus on critical systems that are important 
to people and society
✦ Often previously understudied technologies / 
applications of technologies
✦ At least not studied by the public
✦ Papers must have lessons and/or bigger 
picture implications -- not just attacks
✦ Academic community generally frowns on 
papers that only break a system
Properties of these projects
✦ Results can have broad-reaching affects, to 
public policy, legislation, and so on
✦ Papers also often include discussions of 
possible defenses
Analysis of an electronic 
voting machine
Tadayoshi (Yoshi) Kohno (University of Washington)
Adam Stubbleﬁeld (Johns Hopkins University and ISE)
Aviel D. Rubin (Johns Hopkins University and ISE)
Dan S. Wallach (Rice University)
IEEE Symposium on Security and Privacy, 2004
(Previously JHU ISI Technical Report, 2003)
http://www.cs.washington.edu/homes/yoshi/papers/eVoting/vote.pdf
Cornerstone of Democracy
✦ Voting is cornerstone of our democracy
✦ Allows us to inﬂuence
✦ Crime prevention
✦ Healthcare
✦ Education
✦ Foreign policy...
✦ U.S. citizens have fought hard for their right 
to vote
Presidential Election, 2000
si.edu
Palm Beach County, FL
The FUTURE!
Case of the Diebold FTP Site
✦ Pre-2003
✦ Some computer scientists concerned about e-voting 
security
✦ But impossible for public to analyze
✦ 2003
✦ Diebold source code posted on anonymous ftp site
✦ Bev Harris found in January 2003
✦ CVS repository from 10/2000 to 4/2002
✦ First opportunity to publicly analyze source code of 
real e-voting machine
New Opportunity
✦ New opportunity to analyze critical software
✦ We analyzed Diebold’s AccuVote-TS version 
4.3.1 source code.
✦ In many ways, computer scientists “worst 
nightmares” were true
Step 1:  Determine 
How System 
Works
System Overview
Pre-Election
Ballot deﬁnition ﬁle
Pre-election:  Poll workers load 
“ballot deﬁnition ﬁles” on voting 
machine.
Poll worker
Active Voting
Voter token
Voter token
Interactively vote
Ballot deﬁnition ﬁle
Active voting:  Voters obtain single-use 
tokens from poll workers.  Voters use 
tokens to active machines and vote. 
Voter
Poll worker
Active Voting
Encrypted votes
Voter token
Voter token
Interactively vote
Ballot deﬁnition ﬁle
Active voting:  Votes 
encrypted and stored.  
Voter token canceled. 
Voter
Poll worker
Post-Election
Voter token
Tabulator
Voter token
Interactively vote
Ballot deﬁnition ﬁle
Post-election:  Stored 
votes transported to 
tabulation center. 
Encrypted votes
Recorded votes
Voter
Poll worker
Step 2:  Analyze 
Security and 
Privacy Under 
Different Threat 
Models
Problem:  An adversary (e.g., a poll worker, software developer, or 
company representative) able to control the software or the 
underlying hardware could do whatever he or she wanted.
What Software is Running?
Bad ﬁle
Tabulator
Voter token
Interactively vote
Ballot deﬁnition ﬁle
Encrypted votes
Problem:  Ballot deﬁnition ﬁles are not authenticated.
Example attack:  A malicious poll worker could modify ballot 
deﬁnition ﬁles so that votes cast for “Mickey Mouse” are 
recorded for “Donald Duck.”
Recorded votes
Voter
Poll worker
Voter token
Interactively vote
Ballot deﬁnition ﬁle
Problem:  Smartcards can perform cryptographic operations.  
But there is no authentication from voter token to terminal.
Example attack:  A regular voter could make his or her own 
voter token and vote multiple times.
Tabulator
Encrypted votes
Recorded votes
Voter
Poll worker
Ballot deﬁnition ﬁle
Tabulator
Encrypted votes
Problem:  Encryption key (“F2654hD4”) hard-coded into the 
software since (at least) 1998.  Votes stored in the order cast.
Example attack:  A poll worker could determine how voters 
vote.
Recorded votes
Voter
Voter token
Interactively vote
Voter
Poll worker
Ballot deﬁnition ﬁle
Tabulator
Encrypted votes
Problem:  When votes transmitted to tabulator over the 
Internet or a dialup connection, they are decrypted ﬁrst; the 
cleartext results are sent the the tabulator.
Example attack:  A sophisticated outsider could determine 
how votes vote.
Voter token
Interactively vote
Recorded votes
Voter
Poll worker
/* This is a bit of a hack for now. */
/* the BOOL beeped flag is a hack so we don't 
beep twice. This is really a result of the key 
handling being gorped. */
/* the way we deal with audio here is a gross 
hack. */
/* need to work on exception *caused by audio*.  
I think they will currently result in double-fault.*/
AudioPlayer.cpp
WriteIn.cpp
BallotSelDlg.cpp
BallotDlg.cpp
Software Development
Example Reactions
“The correctness of the software has been proven through an 
extensive testing process.” 
“These machines have never been attacked in the past, so we 
know that they won’t be attacked in the future.”
“Not having security mechanisms built into the software is OK since 
election procedures would detect any malicious activity.”
“The code we analyzed was old and that our results no longer 
apply.”
“School Board member Rita S. Thompson (R), who lost a 
close race to retain her at-large seat, said yesterday that the 
new computers might have taken votes from her. … County 
officials tested one of the machines in question yesterday 
and discovered that it seemed to subtract a vote for 
Thompson in about ‘one out of a hundred tries.’” – David 
Cho, The Washington Post, November 6, 2003.  [WINvote]
“Six electronic voting machines used in two North Carolina 
counties lost 436 ballots cast in early voting for the 2002 
general election because of a software problem.’’ – Kim 
Zetter, Wired News, February 9, 2003.  [iVotronic]
News Clips (Other Machines)
“[A]n e-voting glitch in Boone County [Indiana] showed that 
144,000 votes had been cast – an impossibility since the 
county had only 19,000 total registered voters, according to 
The Indianapolis Star.  A corrected count by the clerk 
showed just 5,352 ballots were cast.  ‘I about had a heart 
attack,’ County Clerk Lisa Garofolo told the newspaper 
about the problem, which she attributed to a ‘glitch’ in the 
software provided by MicroVote.” – Cynthia L. Webb, The 
Washington Post, November 13, 2003.
News Clips (Other Machines)
Step 3:  Follow 
Through
Toward Better E-Voting
✦ Identify, study, and address challenges to designing 
better e-voting machines
✦ Usability
✦ Cost
✦ What does “secure” mean?
✦ Active research area
✦ $5M NSF center for voting research
✦ New EVT workshop
✦ Lots of papers
✦ Working with other communities (not just computer 
scientists)
✦ Our report (July 2003)
✦ SAIC report (September 2003)
✦ “The system, as implemented in policy, procedure, and 
technology, is at high risk of compromise.”
✦ RABA report (January 2004)
✦ “The State of Maryland election system (comprising 
technical, operation, and procedural components), as 
conﬁgured at the time of this report, contains 
considerable security risks that can cause moderate to 
severe disruption in an election.”
✦ RABA had access to Diebold machines and implemented 
some of our attacks.
✦ More since then
Example Subsequent Analyses
New Paper Requirements
http://www.electionline.org/Default.aspx?tabid=290
Pacemaker and Implantable Cardiac 
Deﬁbrillators:  Software Radio 
Attacks and Zero-Power Defense
Daniel Halperin (University of Washington)
Thomas S. Heydt-Benjamin (UMass Amherst)
Benjamin Ransford (UMass Amherst)
Shane S. Clark (UMass Amherst)
Benessa Defend (UMass Amherst)
Will Morgan (UMass Amherst)
Kevin Fu (UMass Amherst)
Tadayoshi (Yoshi) Kohno (University of Washington)
William H. Maisel (BIDMC and Harvard Medical School)
IEEE Symposium on Security and Privacy, 2008
http://www.secure-medicine.org/icd-study/icd-study.pdf
About Dan
✦ Ph.D. student at University of Washington
✦ Systems, networks, and security
✦ Graduated from Harvey Mudd College
✦ Math and Comp Sci background
✦ Free time: Lock picking, Urban spelunking
✦ Interested in {designing,building,analyzing,breaking} 
practical systems in all of these domains
Implantable Medical 
Devices (aka IMDs)
✦ Common - 2.6 million pacemakers implanted 
1990-2002
✦ Computers with sophisticated functionality
✦ Perform vital, lifesaving functions in people
adapted from Ben Ransford, UMass Amherst  http://www.cs.umass.edu/~ransford/
Neurostimulator
Drug pump
Prosthetic
limb
Pharmacy
on a chip
Photos: Medtronic, Hearing Loss Assoc. of WA, St. Jude Medical, Otto Bock
Cardiac device
adapted from Ben Ransford, UMass Amherst  http://www.cs.umass.edu/~ransford/
Why would academics 
study IMD security?
✦ Find yet another vulnerable product....
✦ So what?
✦ If you just add encryption,
we can all go home...
Securing IMDs is hard!
adapted from Ben Ransford, UMass Amherst  http://www.cs.umass.edu/~ransford/
Cannot fail closed
✦ Closed:  No credentials, no admission!
✦ But, medical personnel need emergency access.
✦ Basic tension between patient safety + medical 
efﬁcacy and security and privacy.
✦ A challenge in this space is fail open design.
adapted from Ben Ransford, UMass Amherst  http://www.cs.umass.edu/~ransford/
So what did we do?
✦ Studied a real implantable device
✦ Found attacks with software radio
✦ Built prototypes looking towards 
potential defenses
Implantable cardiac deﬁbrillator
adapted from Ben Ransford, UMass Amherst  http://www.cs.umass.edu/~ransford/
Analysis of a
Real Device
Implantable Cardiac 
Deﬁbrillators
Heart
✦ Monitors heart waveforms
✦ Like a pacemaker, sets 
heart rhythm
✦ Also: delivers a large shock 
to resync heart
adapted from Ben Ransford, UMass Amherst  http://www.cs.umass.edu/~ransford/
Defensive 
Directions
Medical Devices
Need Continued 
Attention!
adapted from Ben Ransford, UMass Amherst  http://www.cs.umass.edu/~ransford/
Type B: Measuring 
What’s Happening 
in Today’s World  
Properties of these projects
✦ Many aspects of today’s world are unknown
✦ How do networks really work?  What do 
ISPs really do?
✦ Academic researchers try to shed light on the 
answers to these questions
✦ Many follow-on possibilities, including
✦ Improve artifacts of network or systems 
(e.g., make them faster or more secure)
✦ Protect against these networks or systems
Properties of these projects
✦ Results can also have broad affects, to public 
policy, legislation, and so on
✦ Measurement papers generally also include 
discussions
✦ Lessons learned from the measurements
✦ Predictions for how systems will evolve
✦ Possible improvements to the systems
✦ Possible defenses against the systems
Detecting In-Flight 
Page Changes with Web 
Tripwires
Charlie Reis (University of Washington)
Steven D. Gribble (University of Washington)
Tadayoshi (Yoshi) Kohno (University of Washington)
Nicholas C. Weaver (International Computer Science Institute)
USENIX Symposium on Networked Systems Design and 
Implementation, 2008
http://www.cs.washington.edu/research/security/web-tripwire/nsdi-2008.pdf
ISP-Injected Ads
✦ Reports of web page 
modiﬁcations
✦ ISPs injecting ads 
into web pages
✦ Is this really 
happening?  How 
often?
64
ISP
Server
Browser
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
Scientiﬁcally study 
and measure the 
phenomenon
Detecting Page Changes
✦ Can detect with JavaScript
66
ISP
✦ Built a Web Tripwire:
✦ Runs in client’s browser
✦ Finds most changes to HTML
✦ Reports to user & server
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
How it Works
✦ Fetch and render original page
✦ Fetch JavaScript code in background
✦ Second, encoded copy of page
✦ Compare against page’s source code
67
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
Attracting Visitors
✦ Wanted view of many clients on 
many networks
✦ Posted to Slashdot, Digg, etc.
✦ Visits from over 50,000 unique 
IP addresses
68
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
Analyze the Results
Many Users Affected
✦ 657 clients saw changes (1.3%)
✦ Many made by client software
✦ Some made by agents in network
Server
ISP
Client
Firewall
70
✦ Diverse incentives
✦ Often concerning for publishers
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
Many Types of Changes
Server
ISP
Client
Firewall
71
Internet Service Providers
Enterprise Firewalls
Client Proxies
Malware
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
Changes by ISPs
✦ Injected Advertisements (2.4%)
✦ NebuAd, MetroFi, LokBox, ...
Server
ISP
Client
Firewall
72
Revenue for ISP; annoy users
Growing Trend?
PerfTech, Front Porch, 
Adzilla, Phorm
✦ Compression (4.6%)
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
Changes by Enterprises
Server
ISP
Client
Firewall
73
✦ Security Checking Scripts (2.3%)
✦ BlueCoat Web Filter
Safer for clients; reduce risk
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
Changes by Client Proxies
Server
ISP
Client
Firewall
74
✦ Popup & Ad Blockers (71%)
✦ Zone Alarm, Ad Muncher, ...
Less annoying; impact revenue
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
Changes by Malware
Server
ISP
Client
Firewall
75
✦ Adware (1 client)
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
Changes by Malware
Server
ISP
Client
Firewall
76
✦ Adware (1 client)
✦ Worms (2 clients)
Helps malware author; risk to user
ARP
Poisoning
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
Unanticipated Impact
✦ Some changes inadvertently broke pages
✦ JavaScript errors
✦ Interfered with MySpace / forum posts
77
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
Introduced Vulnerabilities
✦ XSS allows script injection
✦ Usually ﬁxed at server
✦ Some proxies made otherwise 
safe pages vulnerable
✦ Ad Muncher, Proxomitron
✦ Affected most HTTP pages
✦ Like a root exploit
Server
Client
Proxy
78
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 
XSS via Proxy
✦ Proxy injected script code
✦ Page URL was included in code
✦ Attacker could place script code 
in a valid URL
✦ Users who follow the URL
run injected code
http://usbank.com/?attackCode...
Slide originally created by Charlie Reis, http://www.cs.washington.edu/homes/creis/ 