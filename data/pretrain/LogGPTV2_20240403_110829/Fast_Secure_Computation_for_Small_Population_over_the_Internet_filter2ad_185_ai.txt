tions. In ICALP, 2008.
[LADM14] John Launchbury, Dave Archer, Thomas DuBuisson, and Eric Mertens. Application-scale secure
multiparty computation. In ESOP, 2014.
[Lin13]
[Lin17]
[LP07]
[LP12]
Yehuda Lindell. Fast cut-and-choose based protocols for malicious and covert adversaries.
CRYPTO, 2013.
In
Yehuda Lindell. How to simulate it - A tutorial on the simulation proof technique. In Tutorials on the
Foundations of Cryptography., pages 277–346. 2017.
Yehuda Lindell and Benny Pinkas. An efﬁcient protocol for secure two-party computation in the
presence of malicious adversaries. In EUROCRYPT, 2007.
Yehuda Lindell and Benny Pinkas. Secure two-party computation via cut-and-choose oblivious trans-
fer. J. Cryptology, 25(4):680–722, 2012.
[LPSY15] Yehuda Lindell, Benny Pinkas, Nigel P. Smart, and Avishay Yanai. Efﬁcient constant round multi-
party computation combining BMR and SPDZ. In CRYPTO, 2015.
[MRSV17] Eleftheria Makri, Dragos Rotaru, Nigel P. Smart, and Frederik Vercauteren. Epic: Efﬁcient private
image classiﬁcation (or: Learning from the masters). Cryptology ePrint Archive, Report 2017/1190,
2017. https://eprint.iacr.org/2017/1190.
29
[MRZ15]
Payman Mohassel, Mike Rosulek, and Ye Zhang. Fast and secure three-party computation: The
garbled circuit approach. In ACM CCS, 2015.
[Nao91]
Moni Naor. Bit commitment using pseudorandomness. J. Cryptology, 4(2), 1991.
[NO16]
[PR18]
[RB89]
[RS04]
Jesper Buus Nielsen and Claudio Orlandi. Cross and clean: Amortized garbled circuits with constant
overhead. In TCC, 2016.
Arpita Patra and Divya Ravi. On the exact round complexity of secure three-party computation. IACR
Cryptology ePrint Archive, 2018:481, 2018.
Tal Rabin and Michael Ben-Or. Veriﬁable secret sharing and multiparty protocols with honest majority
(extended abstract). In STOC, 1989.
Phillip Rogaway and Thomas Shrimpton. Cryptographic hash-function basics: Deﬁnitions, implica-
tions, and separations for preimage resistance, second-preimage resistance, and collision resistance.
In FSE, 2004.
[Yao82]
Andrew Chi-Chih Yao. Protocols for secure computations (extended abstract). In FOCS, 1982.
[ZRE15]
Samee Zahur, Mike Rosulek, and David Evans. Two halves make a whole - reducing data transfer in
garbled circuits using half gates. In EUROCRYPT, 2015.
A The Security Model
We prove the security of our protocols based on the standard real/ideal world paradigm. Essentially, security of a
protocol is analyzed by comparing an adversary’s behaviour in a real execution to that of an ideal execution that is
considered secure by deﬁnition (in the presence of an incorruptible trusted party). In an ideal execution, each party
Figure 10: Ideal Functionality FFair
Each honest party Pi (i ∈ [3]) sends its input xi to the functionality. Corrupted parties may send the trusted
party arbitrary inputs as instructed by the adversary. When sending the inputs to the trusted party, the adversary
is allowed to send a special abort command as well.
Input: On message (Input, xi) from a party Pi, do the following: if (Input,∗) message was received from Pi,
then ignore. Otherwise record x(cid:48)
i = xi internally. If x(cid:48)
i = abort.
i = abort, send (Output,⊥) to all the parties. Else, send
Output: If there exists i ∈ [3] such that x(cid:48)
(Output, y) to party Pi for every i ∈ [3], where y = f (x(cid:48)
i is outside of the domain for Pi, consider x(cid:48)
1, x(cid:48)
2, x(cid:48)
3).
Figure 11: Ideal Functionality FGOD
Each honest party Pi sends its input xi to the functionality. Corrupted parties may send the trusted party
arbitrary inputs as instructed by the adversary.
Input: On message (Input, xi) from a party Pi (i ∈ [3]), do the following: if (Input,∗) message was received
from Pi, then ignore. Otherwise record x(cid:48)
i to be
some predetermined default value.
Output: Compute y = f (x(cid:48)
2, x(cid:48)
3) and send (Output, y) to party Pi for every i ∈ [3].
i is outside of the domain for Pi, set x(cid:48)
i = xi internally. If x(cid:48)
1, x(cid:48)
30
sends its input to the trusted party over a perfectly secure channel, the trusted party computes the function based on
these inputs and sends to each party its respective output. Informally, a protocol is secure if whatever an adversary
can do in the real protocol (where no trusted party exists) can be done in the above described ideal computation.
We refer to [Can00, Gol01, Lin17, CL14] for further details regarding the security model.
The “ideal" world execution involves a set of parties P with |P| = 3 or 4 (corresponding to 3PC / 4PC), an
ideal adversary S who may corrupt one of the parties, and a functionality F. The “real" world execution involves
the PPT set of parties P, and a real world adversary A who may corrupt one of the parties. We let IDEALF ,S(1κ, z)
denote the output pair of the honest parties and the ideal-world adversary S from the ideal execution with respect to
the security parameter 1κ and auxiliary input z. Similarly, let REALΠ,A(1κ, z) denote the output pair of the honest
parties and the adversary A from the real execution with respect to the security parameter 1κ and auxiliary input z.
Deﬁnition A.1. For n ∈ N, let F be a functionality and let Π be a 3/4-party protocol. We say that Π securely
realizes F if for every PPT real world adversary A, there exists a PPT ideal world adversary S, corrupting the same
parties, such that the following two distributions are computationally indistinguishable: IDEALF ,S c≈ REALΠ,A.
Target Functionalities. Taking motivation from [CL14, GLS15], we deﬁne two ideal functionalities FFair,FGOD
in Figures 10, 11 for secure 3PC of a function f with fairness and guaranteed output delivery respectively. The
functionalities can be deﬁned similarly for 4PC.
B Primitives
B.1 Properties of Garbling Scheme
Deﬁnition B.1. (Correctness) A garbling scheme G is correct if for all input lengths n ≤ poly(κ), circuits C :
{0, 1}n → {0, 1}m and inputs x ∈ {0, 1}n, the following probability is negligible in κ:
Pr(cid:0)De(Ev(C, En(e, x)), d) (cid:54)= C(x) : (C, e, d) ← Gb(1κ, C)(cid:1) .
Deﬁnition B.2. (Privacy) A garbling scheme G is private if for all input lengths n ≤ poly(κ), circuits C :
{0, 1}n → {0, 1}m, there exists a PPT simulator Spriv such that for all inputs x ∈ {0, 1}n, for all probabilistic
polynomial-time adversaries A, the following two distributions are computationally indistinguishable:
• REAL(C, x) : run (C, e, d) ← Gb(1κ, C), and output (C, En(x, e), d).
• IDEALSpriv (C, C(x)): output (C(cid:48), X, d(cid:48)) ← Spriv(1κ, C, C(x))
Deﬁnition B.3. (Authenticity) A garbling scheme G is authentic if for all input lengths n ≤ poly(κ), circuits
C : {0, 1}n → {0, 1}m, inputs x ∈ {0, 1}n, and all PPT adversaries A, the following probability is negligible in
κ:
(cid:32)(cid:98)Y (cid:54)= Ev(C, X)
∧De((cid:98)Y, d) (cid:54)= ⊥ :
Pr
X = En(x, e), (C, e, d) ← Gb(1κ, C)
(cid:98)Y ← A(C, X)
(cid:33)
.
B.2 Non-Interactive Commitment Schemes (NICOM)
Properties
– Correctness: For all pp, x ∈ M and r ∈ R, if (c, o) ← Com(x; r) then Open(c, o) = x.
– Binding: For all PPT adversaries A, it is with negligible probability (over uniform choice of pp and the random
coins of A) that A(pp) outputs (c, o, o(cid:48)) such that Open(c, o) (cid:54)= Open(c, o(cid:48)) and ⊥ /∈ {Open(c, o), Open(c, o(cid:48))}
– Hiding: For all PPT adversaries A, all pp, and all x, x(cid:48) ∈ M, the following difference is negligible:
(cid:12)(cid:12)Pr(c,o)←Com(x)[A(c) = 1] − Pr(c,o)←Com(x(cid:48))[A(c) = 1](cid:12)(cid:12)
31
We use a NICOM with the above properties for our 3-party protocols. The NICOM (sCom, sOpen) with strong
binding is used in our 4-party protocols. It has the same properties except that binding is deﬁned over all pp (not
just uniform choice of pp).
Instantiations Here we present two instantiations of NICOM borrowed from [MRZ15]. In the random oracle
model, the commitment is deﬁned as (c, o) = (H(x||r), x||r) = Com(x; r). The pp can in fact be empty. We use
this commitment scheme for implementation purposes where the random oracle is realized via SHA-256.
In the standard model, we can use a multi-bit variant of Naor’s commitment [Nao91]. For n-bit messages,
we need a pp ∈R {0, 1}4n. Let G : {0, 1}n → {0, 1}4n be a pseudorandom generator, and let Pad : {0, 1}n →
{0, 1}4n be the function that prepends 3n zeroes to its argument. Then the commitment scheme is:
- Com(x; r): set C = G(r) + pp · Pad(x), with arithmetic in GF(24n); set o = (r, x).
- Open(c, o = (r, x)): return x if c = G(r) + pp · Pad(x); otherwise return ⊥.
Note that binding of the Naor-based instantiation holds over uniform choice of pp. However, the random-oracle
based instantiation satisﬁes the stronger binding property needed in our 4-party protocol. We now present an
instantiation of NICOM (sCom, sOpen) based on injective one-way function (alternately one-way permutation)
where binding holds even for adversarially chosen pp.
In the standard model, we can use the following bit-
commitment scheme from any injective one-way function. Let f : {0, 1}n → {0, 1}n be a one-way permutation
and h : {0, 1}n → {0, 1} a hard core predicate for f (·). Then the commitment scheme for a single bit x is:
- sCom(x; r): set c = (f (r), x ⊕ h(r)); where r ∈R {0, 1}n; set o = (r, x).
- sOpen(c, o = (r, x)): return x if c = (f (r), x ⊕ h(r)); otherwise return ⊥.
B.3 Equivocal Non-interactive Commitment (eNICOM)
Properties
– Correctness For all (epp, t) ← eGen(1κ), x ∈ M and r ∈ R, if (c, o) ← eCom(x; r) then eOpen(c, o) = x.
– Binding: For all (epp, t) ← eGen(1κ) and for all PPT adversaries A, it is with negligible probability that
A(epp) outputs (c, o, o(cid:48)) such that eOpen(c, o) (cid:54)= eOpen(c, o(cid:48)) and ⊥ /∈ {eOpen(c, o), eOpen(c, o(cid:48))}
– Hiding: For all (epp, t) ← eGen(1κ) and for all PPT adversaries A, and all x, x(cid:48) ∈ M, the following difference
(cid:12)(cid:12)Pr(c,o)←eCom(x)[A(c, o) = 1]−Pr(c,o)←eCom(x(cid:48)),o←Equiv(c,x,t)[A(c, o) = 1](cid:12)(cid:12)
is negligible:
Instantiations The folklore commitment scheme (c, o) = (H(x||r), x||r) = Com(x; r) in the random oracle
model supports equivocation via programmability of the random oracle. The (epp, t = (t1, t2)) can in fact be
empty. For empirical purposes alone, we rely on this random oracle based commitment scheme where the random
oracle is realized using SHA-256.
In the standard model, we present the equivocal bit commitment scheme of [CIO98], which is based on Naor’s
commitment scheme [Nao91] for single bit message. This scheme avoids the use of public-key primitives. Let
G : {0, 1}n → {0, 1}4n be a pseudorandom generator.
- eGen(1κ): set (epp, t1, t2) = ((σ, G(r0), G(r1)), r0, r1), where σ = G(r0) ⊕ G(r1)
- eCom(x; r): set c = G(r) if x = 0, else c = G(r) ⊕ σ; set o = (r, x)
- eOpen(c, o = (r, x)): return x if c = G(r) ⊕ x · σ (where (·) denotes multiplication by constant); else return ⊥.
- Equiv(c = G(r0),⊥, x, (t1, t2)): return o = (r, x) where r = t1 if x = 0, else r = t2. Both t1, t2 are needed to
perform equivocation.
32
C Security Proof of f3PC Protocol
In this section, we provide a complete proof for the Theorem 3.2 that states the security of f3PC relative to its ideal
functionality.
Proof. We ﬁrst explain the technicality behind using an equivocal commitment scheme (eNICOM) to commit to
the decoding information. In our protocol, the adversary can decide whether to let the computation succeed or fail
till round 3. This forces the simulator to make the same decision on adversary’s behalf at the end of round 3. As a
result, the simulator can get access to the output, only after simulation of round three is completed, at the earliest.
Therefore, the simulator needs to send the GC, encoding information and the commitment on decoding information
without access to the output, while acting on behalf of the honest parties. This is achieved by invoking oblivious
simulator of GC which neither takes the output, nor returns the decoding information. Consequently, the simulator
commits to a dummy value in round 2. Later if and when FFair is invoked and y is known, Sprv is invoked with the
same randomness which simply returns the decoding information that makes the fake GC returned by Sobv output
y. Correspondingly, the simulator equivocates to the correct decoding information that it obtains from the privacy
simulator in round 4. Equivocality is enabled via a trapdoor which in our protocol remains distributed between the
garblers. The public parameter for eNICOM is generated jointly by the garblers (Appendix B.3).
We now describe the simulator Sf3PC for the case when P1, P3 is corrupt. The case of P2 being corrupt is
symmetric to that of P1. Since the protocol may result either in output computation or abort based on the corrupt
party’s behaviour until Round 3, the privacy simulator Sprv (Ref. [BHR12]) that demands the output can only be
invoked only at the end of Round 3. Therefore, the oblivious simulator of the garbling scheme Sobv (Ref. [BHR12])
that does not need output is invoked ﬁrst as a part of GC generation. We assume a garbling scheme such that Sobv
and Sprv when invoked on same randomness return the same (C, X) (Most known garbling schemes based on Yao
comply with this [Yao82, ZRE15, KS08]). Later, if the adversary behaves such that the protocol results in output
computation, the evaluator’s input is extracted, used to obtain output y via FFair and Sprv is invoked to retrieve
decoding information. Since this can be done earliest after Round 3, we use an equivocal commitment to explain
the commitment on decoding information sent in Round 2. The description of simulator S 3
f3PC corresponding to P3
(evaluator) corrupt and S 1
f3PC corresponding to P1 (garbler) corrupt is available in Figure 12 with R1/R2/R3/R4
indicating simulation for round 1, 2, 3 and 4 respectively.
Security against corrupt P ∗
views are shown to be indistinguishable via a series of intermediate hybrids.
3 We now argue that IDEALFFair,S3
c≈ REALf3PC,A, when A corrupts P3. The
f3PC
– HYB0: Same as REALf3PC,A.
– HYB1: Same as HYB0, except that P1, P2 use uniform randomness rather than pseudo-randomness.
– HYB2: Same as HYB1, except that some of the commitments of input wire labels sent by P1, P2, which will
not be opened are replaced with commitments of dummy values. Speciﬁcally, these are the commitments with
indices (cid:54)= m1, m2, x31, x32.
– HYB3 : Same as HYB2, except the following:
- HYB3.1: When the execution results in abort, the GC is created as (C(cid:48), X) ← Sobv(1κ, C) and the commit-
ment to the decoding information is created for a dummy value.
- HYB3.2: When the execution results in output y, the GC is created as (C(cid:48), X, d(cid:48)) ← Sprv(1κ, C, y), the
commitment c to the decoding information is created for a dummy value and later equivocated to d(cid:48) using o
computed via o ← Equiv(c, d(cid:48), t1, t2).
– HYB4: Same as HYB3, except that the protocol results in abort if neither P1 nor P2 receive Y obtained upon GC
evaluation from P3.
33
Figure 12: Description of Sf3PC
(a) S 3
f3PC (P ∗
3 is corrupt)
R1 Receive (pp1, x31) and (pp2, x32) privately from P ∗
is not received / invalid, consider a default value.
3 on the behalf of P1, P2 respectively. If the input share
R1 Send (h1, r1) and (h2, r2) to P3 according to the protocol on behalf of P1, P2 respectively.
R2 Use uniform randomness r on behalf of P1, P2 and run (C, X) ← Sobv(1κ, C), where Sobv is the
oblivious simulator of the garbling scheme.
α , cmα
(cid:96)+α, cxα
2
1
31
2(cid:96)+α, cxα
R2 Choose m1, m2 at random. Let {cmα
3(cid:96)+α}α∈[(cid:96)] be commitments to the entries of X, cor-
responding to pp1. If pp1 (cid:54)= pp2, the above is computed with respect to pp2 as well. Commit to dummy