title:Cache Me If You Can: Effects of DNS Time-to-Live
author:Giovane C. M. Moura and
John S. Heidemann and
Ricardo de Oliveira Schmidt and
Wes Hardaker
Cache Me If You Can:
Effects of DNS Time-to-Live
Giovane C. M. Moura (1)
1: SIDN Labs and TU Delft
John Heidemann (2)
Ricardo de O. Schmidt (3) Wes Hardaker (2)
2: USC/Information Sciences Institute
3: University of Passo Fundo
ABSTRACT
DNS depends on extensive caching for good performance, and ev-
ery DNS zone owner must set Time-to-Live (TTL) values to control
their DNS caching. Today there is relatively little guidance backed
by research about how to set TTLs, and operators must balance
conflicting demands of caching against agility of configuration. Ex-
actly how TTL value choices affect operational networks is quite
challenging to understand due to interactions across the distributed
DNS service, where resolvers receive TTLs in different ways (an-
swers and hints), TTLs are specified in multiple places (zones and
their parent’s glue), and while DNS resolution must be security-
aware. This paper provides the first careful evaluation of how these
multiple, interacting factors affect the effective cache lifetimes of
DNS records, and provides recommendations for how to configure
DNS TTLs based on our findings. We provide recommendations
in TTL choice for different situations, and for where they must be
configured. We show that longer TTLs have significant promise
in reducing latency, reducing it from 183 ms to 28.7 ms for one
country-code TLD.
CCS CONCEPTS
• Networks → Network measurement; Naming and address-
ing.
KEYWORDS
DNS, recursive DNS servers, caching
ACM Reference Format:
Giovane C. M. Moura, John Heidemann, Ricardo de O. Schmidt, Wes Hardaker.
2019. Cache Me If You Can: Effects of DNS Time-to-Live . In Internet Mea-
surement Conference (IMC ’19), October 21–23, 2019, Amsterdam, Netherlands.
ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3355369.3355568
1 INTRODUCTION
The Domain Name System (DNS) [33] is a core component of the
Internet. Every web page and e-mail message requires DNS informa-
tion, and a complex web page can easily require information from a
dozen or more DNS lookups. The DNS provides a low-latency, dis-
tributed database that is used to map domain names to IP addresses,
perform service location lookups, link distributed portions of the
DNS together, including in-protocol integrity protection using in-
protocol DNS key storage, linking and verification algorithms.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6948-0/19/10...$15.00
https://doi.org/10.1145/3355369.3355568
101
With this central position, often serving as the initial transaction
for every network connection, it is not surprising that DNS per-
formance and reliability is critical. For example, DNS performance
is seen as a component of web browsing that must be optimized
(for example, [50]), and DNS services providers compete to pro-
vide consistent, low-latency services around the world. Even in
less-latency sensitive services, such as the authoritative service for
the Root DNS, reducing latency is still a desired goal [47]. DNS
must always work, and failures of major DNS resolution systems
frequently makes public newspaper headlines. In 2016, when a
Distributed Denial-of-Service (DDoS) attack led to problems at a
DNS provider, it resulted in disruptions to multiple popular pub-
lic services (including Github, Twitter, Netflix, and the New York
Times) [41].
DNS is also often used to associate clients with near-by servers
by large content providers [10] and in Content-Delivery Networks
(CDNs) [12]. In this role, DNS helps both performance and reliability,
associating clients to nearby sites [47, 54], and implementing load
balancing, both to reduce latency, and to control traffic to support
site maintenance and react to DDoS attacks [36].
It is not surprising that DNS has developed a complex infras-
tructure, with client software (the stub resolver, provided by OS
libraries) that contacts recursive resolvers (a type of DNS server
that can iterate through the DNS tree for answers), which in turn
contact authoritative servers (which hold the answers being sought).
Large-scale recursive and authoritative resolvers are often carefully
engineered, with pools of servers operating behind load balancers,
sometimes in multiple layers [48], often employing IP anycast [1].
Caching is the cornerstone of good DNS performance and relia-
bility. A 15 ms response to a new DNS query is fast, but a 1 ms cache
hit to a repeat query is far faster. Caching also protects users from
short outages and can mute even significant DDoS attacks [36].
Time-To-Live values (TTLs) of DNS records control cache dura-
tions [33, 34] and, therefore, affect latency, resilience, and the role
of DNS in CDN server selection. While caching DNS servers and
anycast have been extensively studied, surprisingly, to date there
has been little evaluation of TTLs. Some early work modeled caches
as a function of their TTLs [26], and recent work examined their in-
teraction with DNS [36], but no research provides recommendations
about what TTL values are good.
Determining good TTL values for DNS is surprisingly challeng-
ing. A fundamental tension exists between short and longer TTL
values. Short TTLs allow operators to change services quickly, as
part of regular operation for load balancing in CDNs, or perhaps
to redirect traffic through a DDoS scrubber. Yet, long TTLs reduce
latency seen by clients, reduce server load, and provide resilience
against longer DDoS attacks.
Not only is there no “easy” optimal setting, but performance of
modern DNS (with its effects on web browsing) is affected by many
TTLs, since full resolution of a DNS name may require dozens of
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
G. C. M. Moura et al.
lookups across several organizations, all potentially using different
TTLs. As a distributed database, TTLs are given in both the parent
and child at a delegation boundary, and these may differ. In addition,
responses come in different flavors, with some values labeled as
authoritative, and others labeled as hints (“additional”). Finally, DNS
records sometimes depend on the freshness of other records, which
can be used as the basis of multiple points of attack. These concerns
have been exploited as part of sophisticated DNS hijacking to open
user accounts [28].
While there has be some study of what clients see (§7), there
has been only limited academic study of operator options and their
effects. Since operational requirements vary and choices are affected
by components run by multiple parties, it is not surprising that, to
our knowledge, there is no operational consensus for what TTL values
are reasonable. Lack of consensus and an operational preference
for “if it ain’t broke, don’t fix it”, results in a large range of values
in practice (§5), and offers new deployments limited guidance for
choosing TTLs.
The goal of this paper is to fill this gap. First, we explore how
these many factors influence what TTL is used by recursive re-
solvers (§2). Second, we provide recommendations about good TTL
values to zone operators for different scenarios, in light of user
experience and resilience. Our work complements prior work that
studied how recursive resolvers handle caching (see §7). We use
both controlled experiments and analysis of real-world data to make
informed recommendations to operators.
Our first contribution shows what the effective TTL is as a result
of TTLs stored in different places (§3) across multiple, cooperating
records (§4). Second, we examine real-world DNS traffic and de-
ployments to see how current use compares to our evaluation, and
how operators choose TTL values and how their choices between
short and long TTLs affect latency and operator flexibility (§5).
Finally, we show that DNS TTLs matter, since longer TTLs allow
caching, reducing latency and traffic (§6.2). We outline the trade-
offs and provide recommendations (§6): those using CDNs or load
balancers may require short TTLs (5 or 15 minutes), but most others
should prefer longer TTLs (a few hours).
Discussion of our early results with operators prompted increase
in their TTLs, and we show that the median latency drops from
183 ms with their earlier short TTLs, to only 28.7 ms now that
longer TTLs enable better caching. While these specific results are
from one ccTLD (.uy, §5.3), our crawls (§5.1) and discussion with
operators (§5.2) suggest our results apply elsewhere.
We will make the majority of datasets available at no charge. Ripe
Atlas datasets are public, and only data from .nl cannot be released.
Our measurements are all about public network infrastructure and
pose no ethical or privacy issues.
2 OUR QUESTION: WHICH TTLS MATTER?
DNS caching appears simple, with each record cached up to a given
time-to-live. However, the reality is more complex: DNS records
come from several places and resolution requires traversing multi-
ple names and types. We next look systematically at each source of
information and determine which, in practice, takes priority.
First, records are duplicated in multiple places, sometimes with dif-
ferent TTLs. Specifically, DNS records that cross delegation bound-
aries are in both the parent and the child zone and can have different
102
TTLs. In §3 we examine if recursives in the wild prefer TTL values
provided by the parent or child.
Second, resolution of a fully qualified domain name (FQDN) re-
quires identifying authoritative servers (NS records) and their IP ad-
dresses (A or AAAA records) for each part of the FQDN. FQDN traver-
sal raises two factors. First, communicating with an authoritative
server requires knowing its IP address(es), but the NS and A/AAAA
records for it may also have different TTLs. Second, records for it
may be in bailiwick (when they are under the domain being served,
so ns.example.org is in bailiwick of example.org [22]) or out of
bailiwick (ns.example.com would not be in bailiwick of example.org).
These factors interact: some recursive resolvers discard in-bailiwick
A/AAAA records when the NS record expires, as we show in §4.
The answer to these questions should be given in the DNS specifi-
cations. Unfortunately early specifications were somewhat informal,
and implementations varied in practice. The original DNS specifica-
tions left precedence unspecified [33, 34], while RFC2181 later gave
the child zone’s Authoritative Answers priority over the parent’s
glue [15], but did not require that both be fetched. DNSSEC [6, 7]
confirms that authoritative TTL values must be enclosed in and
verified by the signature record, which must come from the child
zone. Thus our question is: Do resolvers in the wild follow these
specifications for TTL priorities?
Answering these questions is also important to understand who
ultimately controls a zone’s caching.
3 ARE RESOLVERS PARENT- OR
CHILD-CENTRIC?
We first examine how DNS handles records that are served from
multiple places, to determine what controls caching. The DNS is a
distributed database with portions of the hierarchy (zones) managed
by different organizations through delegation. Glue records duplicate
content from a child zone in the parent, either for convenience or
out of necessity, if the authoritative server for the child zone is
named only in that child’s zone (in-bailiwick). A recursive resolver
much choose which TTL it prefers (parent or child) based on several
factors described below in §3.1.
We examine this question with a case-study and wild traffic
observed from the edge and from authoritative servers for a country
code TLD. We reach two key results of cross-zone TTLs: first, most
recursive resolvers are child-centric, trusting the TTL in the
child zone’s authoritative server over the glue in the parent zone.
Depending on the measurement technique, just 52% (§3.4, .nl from
the authoritative) to 90% (§3.2, .uy from RIPE Atlas) of queries are
child-centric.
Our second finding is that enough queries are parent-centric,
so parent TTLs still matter. Although only 10 to 48% of queries
are parent-centric, one must set TTLs the same in both parent and
child to accommodate this sizable minority. In cases where operator
is without control of the parent zone’s TTL, resolvers will see a mix of
TTLs for that zone.
3.1 Parent and Child TTLs in Chile’s .cl
To explore this question of whether the parent or child’s TTL in
the hierarchy is “believed more frequently”, we first look at Chile’s
country-code TLD, .cl. Resolving this name involves three author-
itative servers as shown in Table 1.
Cache Me If You Can
Q / Type Server
.cl / NS
k.root-servers.net
.cl/NS
a.nic.cl
Response
a.nic.cl/NS
a.nic.cl/A
a.nic.cl/AAAA
a.nic.cl/NS
a.nic.cl/A
a.nic.cl/AAAA
190.124.27.10/A
TTL
Sec.
172800 Auth.
Add.
172800
Add.
172800
3600⋆
Ans.
Add.
43200
Add.
43200
43200⋆
Ans.
a.nic.cl/A a.nic.cl
Table 1: a.nic.cl. TTL values in parent and child (⋆ indicates
an authoritative answer), on 2019-02-12.
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Frequency
Duration
Query
TTL Parent
TTL Child
Date
Probes
valid
disc
VPs
Queries
Responses
valid
disc.
.uy-NS
600s
2h
NS .uy
172800 s
300 s
20190214
8963
8863
100
15722
189506
188307
188225
82
a.nic.uy-A google.co-NS
600s
1h
NS google.co
900 s
345600 s
20190304
9127
9034
93
16078
97213
96602
96589
3
600s
3h
A a.nic.uy
172800 s