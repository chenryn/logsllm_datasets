Best aggregation fct.
Adaptive aggregation selection
False Negat. [# sources] False Posit. [# sources]
14.7
13.1
14.5
9.8
13.7
14.0
12.5
24.3
5.3
125.2
5.7
3.1
challenges combined), where it ﬂuctuates until the end of experiment. However, there
are two notable increases to explain: between steps 30 and 40, and after step 60.
These increases can be easily explained when looking at Fig. 9, which shows the
number of false positives in terms of unique source IP addresses. During these time
intervals, we can notice that the choice of an appropriate aggregation agent has a huge
impact on the quality of results, and that the adapted system is able to minimize the
number of false positives. The number of challenges is lower between steps 40 and
60, when all agents provide similar results, and increases again around 60, where the
performance of the aggregation agents varies somewhat more. On the other hand, we
can see that the user agent did not manage to avoid a spike in false positives around the
step 20, when it did not yet have a representative trust model.
The results shown in Fig. 9 are summarized in Table 1. We can see that the challenge-
based, dynamic adaptation mechanism clearly outperforms the simple arithmetic aver-
age aggregation, which is the optimal selection when we have no information regarding
the detection agent’s performance. It also outperforms any single aggregation function
selected using the a-posteriori knowledge from the pool of all 30 functions. All the
methods have a comparable rate of false negatives, but differ in the rate of false posi-
tives, where the dynamic selection clearly outperforms the best aggregation functions.
The relatively important margin of separation between the dynamic selection and best
false positives of any single aggregation is given by the fact that the dynamic selection
can avoid relatively high number of false positives during the periods when the indi-
vidual aggregation functions differ in performance, such as around the sets 30-40. This
further underlines the importance of the adaptive rate of challenge insertion, which
allows fast identiﬁcation of the optimal system output during the changes of system
characteristics.
In Fig. 10, we can see the dynamics of the aggregation operator/agent selection over
time. With an exception of the initial 6 intervals, when the operator #0 (arithmetic av-
erage) is selected by default, the system dynamically selects between the remaining
operators, with about half of the selections being the operators #23 and #24. Both
these operators include OWA as well as anomaly-detection-method-based weight av-
erage portion. They are identical in the ﬁxed part, where they attribute the weight 0.33
to each of the agents Xu [7], MINDS [10] and TAPS [11]. The operators differ in the
OWA part, where the ﬁrst one builds its opinion from the three lowest anomaly values,
76
M. Reh´ak et al.
D
I
t
n
e
g
a
r
e
i
f
i
s
s
a
c
l
d
e
t
c
e
e
S
l
28
26
24
22
20
18
16
14
12
10
8
0
10
20
30
Time
40
50
60
70
Fig. 10. Selected aggregation agent (identiﬁed by the ID number on axis y) for each time step
while the second considers the third and fourth anomaly values. The weights of the
detection-method-based averaging and order weighted averaging parts are 0.5 for both
operators. It is interesting to note that the system managed to pick the three methods
with the most diverse set of anomaly detection features (in the ﬁxed part), consistently
with basic ensemble classiﬁcation [17] principles. The quality of this result is there-
fore based not only on the absolute quality of underlying detection methods, but also
beneﬁts from the diversity of the anomaly detection methods.
In the above-described experiments, the challenges were inserted uniformly, regard-
less of the attack type. In the following, we will try to measure the effects of challenge
insertion in terms of system sensitivity with respect to speciﬁc attacks. To do so, we
have used the simple server compromise attack tree speciﬁed in Fig. 5 to generate the
challenges optimizing the system, and we have then attempted to compromise one of the
hosts on our network using the standard security tools, such as nmap or metasploit.
The attacks were repeated several times, with changes in speed, tools settings and in-
tensity. We have observed that the system selected the aggregation functions that were
able to maximize the likelihood of detection of various stages involved in the server
exploit attacks. The anomaly values attributed to horizontal sans, ﬁngerprinting and
vertical scans have increased considerably, making them far more likely to be detected.
The most dramatic change of behavior was related to the password brute force breaking
attempts. These were undetectable with the baseline system conﬁguration, but became
detectable with the case-speciﬁc system conﬁguration. Buffer overﬂow attacks were un-
detectable regardless of the aggregation function, as they are nearly impossible to detect
with NBA methods due to the low volumes of trafﬁc involved.
In Table 2, we present the effects of threat model-based adaptation in the trafﬁc used
in the ﬁrst series of experiments. This data set does not match the model at all and
provides a good worst case example. We can see that the number of alerts (typically
Runtime Monitoring and Dynamic Reconﬁguration for Intrusion Detection Systems
77
Table 2. Effects of scenario speciﬁc selection on alert numbers in unrelated trafﬁc. Obtained over
72 observation intervals 5 minutes long.
Result [# alerts]
Neutral challenge insertion
Case-speciﬁc insertion
False Negatives
39
37
False Positives
201
249
True Positives
146
161
greater than the number of malicious sources used in Table 1) generated by the system
has grown, and that the number of false positives increased by about 50. The number of
alerts classiﬁed as true positives have increased as well (by 15), and the number of false
negatives decreased by 2. Note that the total number of alerts is not necessarily identi-
cal due to the possible alert fragmentation. Overall, we can see that in order to detect
the attacks crucial in the server compromise scenario (e.g. password bruteforcing), the
system was able to increase its sensitivity and to ﬁnd a new equilibrium with different
detection proﬁle. It shall be also noted that most of the false positives are repetitive
occurrences of trafﬁc structures that are difﬁcult to predict, and that about 80% of them
can be eliminated with less than 20 rules in the alert processing engine.
7 Related Work
In literature, more sophisticated formalisms than attack trees have been proposed for
modeling attack structures, e.g., attack graphs [18] and attack grammars [19]. However,
for our purposes, we do not need to account for the order in which plans of attacks
are carried out or the relations between attacks, and hence, the attack tree formalism is
sufﬁciently rich.
In desktop grid computing, spot-checking [20,21] is used to make sure that hosts to
which a computation has been outsourced, return correct results. To this end, indistin-
guishable challenges for which the correct answer is already known are interspersed
with actual requests. For a spot-checking approach, where challenges are merged into
a vector among a set of real requests, Staab et al. [2] showed how to determine an op-
timal number of challenges for a given number of real requests. They focused on the
case where the answer to a challenge or a real request is binary. This was extended in
our work, where we handle the continuous case.
The use of ensemble classiﬁcation approaches [22] is functionally equivalent to our
approach, but with extremely strong assumptions. It requires a pre-classiﬁed training
data set and don’t dynamically adapt system to the changing conditions.
Ghanbari and Amza [23] train belief networks that represent complex systems by
injecting failures. At the outset, experts model a belief network that describes the de-
pendencies within a system. The inserted failures then change the prior beliefs of the
experts to form better estimates. Through fault injection, the dependencies between the
variables in the belief network become evident, and so the overall system can be trained.
Opposed to that, we inject challenges to evaluate classiﬁcation components in terms of
accuracy in order to select the most accurate one.
78
M. Reh´ak et al.
8 Conclusion
Our work presented in this paper aims to close the gap between security policies and
formal threat models and the practice of IDS deployment. To achieve this objective, we
have designed a runtime adaptation and monitoring framework running on the top of
the IDS. It evaluates the performance with respect to the threat models, that are deﬁned
as attack trees, with a value assigned to the achievement the objective (root) of the each
tree. Objective value can be deﬁned in two manners. In a decision theoretical paradigm,
we will aim to minimize our loss by associating an estimate of our loss (or risk) with the
achievement of each attack tree root. In the game theoretic model, the value of the attack
tree would reﬂect its value for the attacker. This second option allows us to differentiate
between different types of attackers, with different technical capabilities represented by
trees with growing complexity and corresponding risk values.
Either type of the threat/risk model can be used as an input for the online monitor-
ing and adaptation process, which is able to evaluate the probability that an attack as
deﬁned by the attack tree would pass undetected. This results in an estimate of the ex-
pected undetected loss, given the current trafﬁc status. This value is also a basis for
system adaptation, as the system dynamically reconﬁgures itself in order to minimize
the undetected loss value. The adaptation is based on the evaluation of system response
with respect to a set of challenges, pre-classiﬁed recorded samples of the past trafﬁc
modiﬁed to ﬁt the current trafﬁc. The adaptation components of the system use the
threat model to deﬁne the optimal mix of challenges to insert, in order to align the sys-
tem performance with the threat models. It is also able to dynamically adjust the number
of challenges to insert in response to changing trafﬁc characteristics. The experiments
performed with the system show that the dynamic selection of the optimal aggregation
function in the CAMNEP system can signiﬁcantly reduce the number of false positives
and that the targeted insertion of challenges selected according to threat models can
inﬂuence the system sensitivity to reﬂect the risks associated with each attack type.
The principal limitations of the work are related to the detection capabilities of the
individual detection agents aggregated in the system. Using the assumption of classiﬁer
diversity [24], we know that the statistical performance of the combined classiﬁer can be
signiﬁcantly better than the performance of individual classiﬁers. However, the system
can not detect (i.e. separate from the trafﬁc) the attacks that none of the individual
algorithms can robustly detect.
In our future work, we plan to improve the attack modeling capabilities by inclusion
plan-based attack modeling, and to integrate the outputs of the adaptation layer with the
alert fusion and correlation capabilities of the system. This combination assess which
attack stages are unlikely to be detected, and can use this information to improve the
alert correlation [25].
Acknowledgment. This material is based upon work supported by the ITC-A of the US
Army under Contract No. W911NF-08-1-0250. Any opinions, ﬁndings and conclusions
or recommendations expressed in this material are those of the author(s) and do not
necessarily reﬂect the views of the ITC-A of the US Army. Also supported by Czech
Ministry of Education grants 6840770038 (CTU) and 6383917201 (CESNET).
Runtime Monitoring and Dynamic Reconﬁguration for Intrusion Detection Systems
79
References
1. Denning, D.E.: An intrusion-detection model. IEEE Trans. Softw. Eng. 13, 222–232 (1987)
2. Staab, E., Fusenig, V., Engel, T.: Towards trust-based acquisition of unveriﬁable information.
In: Klusch, M., Pˇechouˇcek, M., Polleres, A. (eds.) CIA 2008. LNCS (LNAI), vol. 5180, pp.
41–54. Springer, Heidelberg (2008)
3. Reh´ak, M., Pechoucek, M., Grill, M., Bartos, K.: Trust-based classiﬁer combination for net-
work anomaly detection. In: Klusch, M., Pˇechouˇcek, M., Polleres, A. (eds.) CIA 2008. LNCS
(LNAI), vol. 5180, pp. 116–130. Springer, Heidelberg (2008)
4. Reh´ak, M., Pechoucek, M., Bartos, K., Grill, M., Celeda, P., Krmicek, V.: Improving anomaly
detection error rate by collective trust modeling. In: Lippmann, R., Kirda, E., Trachtenberg,
A. (eds.) RAID 2008. LNCS, vol. 5230, pp. 398–399. Springer, Heidelberg (2008)
5. Cisco Systems: Cisco IOS NetFlow (2007), http://www.cisco.com/go/netflow
6. Scarfone, K., Mell, P.: Guide to intrusion detection and prevention systems (idps). Technical
Report 800-94, NIST, US Dept. of Commerce (2007)
7. Xu, K., Zhang, Z.L., Bhattacharrya, S.: Reducing Unwanted Trafﬁc in a Backbone Net-
work. In: USENIX Workshop on Steps to Reduce Unwanted Trafﬁc in the Internet (SRUTI),
Boston, MA (2005)
8. Lakhina, A., Crovella, M., Diot, C.: Mining Anomalies using Trafﬁc Feature Distributions.
In: ACM SIGCOMM, Philadelphia, PA, pp. 217–228. ACM Press, New York (2005)
9. Lakhina, A., Crovella, M., Diot, C.: Diagnosis Network-Wide Trafﬁc Anomalies. In: ACM
SIGCOMM 2004, pp. 219–230. ACM Press, New York (2004)
10. Ertoz, L., Eilertson, E., Lazarevic, A., Tan, P.N., Kumar, V., Srivastava, J., Dokas, P.: Minds
- minnesota intrusion detection system. In: Next Generation Data Mining. MIT Press, Cam-
bridge (2004)
11. Sridharan, A., Ye, T., Bhattacharyya, S.: Connectionless port scan detection on the backbone,
Phoenix, AZ, USA (2006)
12. Yager, R.: On ordered weighted averaging aggregation operators in multicriteria decision
making. IEEE Transactions on Systems, Man, and Cybernetics 18, 183–190 (1988)
13. Rubinstein, B.I.P., Nelson, B., Huang, L., Joseph, A.D., Lau, S.-h., Taft, N., Tygar, J.D.:
Evading anomaly detection through variance injection attacks on PCA. In: Lippmann, R.,
Kirda, E., Trachtenberg, A. (eds.) RAID 2008. LNCS, vol. 5230, pp. 394–395. Springer,
Heidelberg (2008)
14. Moore, A.P., Ellison, R.J., Linger, R.C.: Attack modeling for information security and sur-
vivability. Technical Report CMU/SEI-2001-TN-001, CMU Software Engineering Institute
(2001)
15. Quine, W.: A way to simplify truth functions. American Mathematical Monthly 62, 627–631
(1955)
16. Moore, D.S.: The Basic Practice of Statistics, 4th edn. W. H. Freeman & Co., New York
(2007)
17. Polikar, R.: Esemble based systems in decision making. IEEE Circuits and Systems Mag. 6,
21–45 (2006)
18. Sheyner, O., Haines, J., Jha, S., Lippmann, R., Wing, J.M.: Automated generation and anal-
ysis of attack graphs. In: SP 2002: Proceedings of the 2002 IEEE Symposium on Security
and Privacy, Washington, DC, USA, p. 273. IEEE Computer Society, Los Alamitos (2002)
19. Zhang, Y., Fan, X., Wang, Y., Xue, Z.: Attack grammar: A new approach to modeling and
analyzing network attack sequences. In: Proc. of the Annual Computer Security Applications
Conference (ACSAC 2008), pp. 215–224 (2008)
20. Sarmenta, L.F.G.: Sabotage-tolerance mechanisms for volunteer computing systems. In: CC-
GRID 2001: Proc. of the 1st Int. Symposium on Cluster Computing and the Grid, Washing-
ton, DC, USA, p. 337. IEEE Computer Society, Los Alamitos (2001)
80
M. Reh´ak et al.
21. Zhao, S., Lo, V., GauthierDickey, C.: Result veriﬁcation and trust-based scheduling in peerto-
peer grids. In: P2P 2005: Proc. of the 5th IEEE Int. Conf. on Peer-to-Peer Computing, Wash-
ington, DC, USA, pp. 31–38. IEEE Computer Society, Los Alamitos (2005)
22. Giacinto, G., Perdisci, R., Rio, M.D., Roli, F.: Intrusion detection in computer networks by a
modular ensemble of one-class classiﬁers. Information Fusion 9, 69–82 (2008)
23. Ghanbari, S., Amza, C.: Semantic-driven model composition for accurate anomaly diagnosis.
In: ICAC 2008: Proceedings of the 2008 International Conference on Autonomic Computing,
Washington, DC, USA, pp. 35–44. IEEE Computer Society, Los Alamitos (2008)
24. Dietterich, T.G.: Ensemble methods in machine learning. In: Kittler, J., Roli, F. (eds.) MCS
2000. LNCS, vol. 1857, pp. 1–15. Springer, Heidelberg (2000)
25. Morin, B., M´e, L., Debar, H., Ducass´e, M.: M2D2: A formal data model for IDS alert corre-
lation. In: Wespi, A., Vigna, G., Deri, L. (eds.) RAID 2002. LNCS, vol. 2516, pp. 115–137.
Springer, Heidelberg (2002)