Low-overhead, software-only stack protection solutions
such as StackGuard [29] and shadow stacks [26] protect
return addresses, but do not protect other stack data and can
be defeated by attack techniques such as direct writes and
information leaks. Recent work found that shadow stacks
have a performance overhead of about 10% [26]; we in-
clude the optimized Parallel Shadow Stack variant
in our
taxonomy. Hardware support for shadow stacks has been
proposed (SmashGuard [43]); recently Intel has announced
upcoming hardware support for the feature in their Control-
ﬂow Enforcement Technology [16].
AddressSanitizer [44] instruments all memory accesses with
checks against “red zones” in a shadow memory that pads all
488
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:32:21 UTC from IEEE Xplore.  Restrictions apply. 
k
r
o
W
g
n
i
t
s
i
x
E
s
e
i
c
i
l
o
P
r
u
O
StackGuard [29] [26]
Parallel Shadow Stack [26]
SmashGuard [43]
Intel’s Control-ﬂow Enforcement Technology [16]
AddressSanitizer [44]
CPI/CPS [25]
Hardware-Assisted Dataﬂow-Isolation [12]
SoftBound [45]
HardBound [11]
Return Address Protection (Sec. IV-D1)
Static Authorities (Sec. IV-D2)
Depth Isolation (Sec. IV-D3)
Memory Safety
Data-ﬂow Integrity
Memory Safety
Data-ﬂow Integrity
X
X
X
X
X
X
X
X
X
X
X
R
R
X
X
X
X
X
X
X
R
R
X
X
X
X
X
X
X
X
R
R
R
R
2.8%
3.5%
∼ 0%
73%
8.5%/1.9%
< 2 %
67%
5-9%
1.2%
5.7%
3.6%
4.5%
2.4%
Read freed stack memory
Contiguous access return address
Arbitrary access return address
Contiguous access wrong stack object
Arbitrary access wrong stack object
Overhead
prevents the speciﬁed access; X allows it; R denotes cases where writes are allowed
but violations are detected when overwritten data or data that should be inaccessible is read.
Fig. 9: Stack threat taxonomy
objects. It protects stack and heap objects, but only against
the contiguous write case. It bears a high runtime overhead of
73% and a high memory usage overhead of 3.3×.
A recent research direction has proposed providing full
memory safety just for code pointers (Code Pointer Integrity
[25]). While this technique provides an effective level of
protection for the incurred overhead on commodity hardware,
it does not protect all stack data. Recent work has shown that
even non-control data attacks can be Turing complete [52].
The SafeStack component of this work explores splitting the
stack into a “safe stack” and a “regular stack”. Objects that
are accessed in a statically, provably-safe way, such as return
addresses and spilled registers, are placed onto the safe stack.
Other objects, like arrays and structs, are placed on the regular
stack. This spatial separation is useful for protecting items on
the safe stack and additionally has almost no performance
overhead; however, it is opportunistic, protecting the items
that can be cheaply protected and, without CPI, provides no
protection for items on the unsafe stack. The safe region itself
is protected only with information hiding on 64-bit systems,
and implementations have been attacked [53].
Hardware-Assisted Data-ﬂow Isolation (HDFI) [12] uses
a single metadata tag bit for efﬁcient security checks. This
enables it to achieve a low overhead, but with only a single
metadata bit it can only provide coarse protection (e.g., just
return addresses or just code pointers, similar to our Return
Address Protection). It can distinguish two classes of data and
make sure that data from one class is not mistaken for data
in the other, but cannot provide ﬁne-grained frame and object
separation. Recent work shows that single-bit tags, such as
needed for HDFI, can be added without changing the physical
memory word width by using a separate tag table with low
overhead [54]. LowRISC provides two bits of tagging in its
memory system that could be used to implement HDFI with
its ltag/stag operations [55], [56].
Some commercial products are beginning to provide fea-
tures that can approximate HDFI. ARM’s v8.3 pointer authen-
tication feature could be used on the return address, or other
code pointers, to detect tampering [57] without the need for
separate tag bits. Using a unique encoding per return point,
this can be extended to provide some CFI protection as well.
Oracle’s Application Data Integrity (ADI) could be used to
assign one of its 16 colors to spilled stack frames at a cache-
line granularity to serve a similar function to the single tag bit
in HDFI [58]. These offerings are available on commercially
available chips, but only provide protection similar to our
Return Address Protection policy.
Like other data-ﬂow integrity models [35], the DFI variants
of our policies keep track of writers to memory words.
Instead of using static instructions as writers, our policies use
identiﬁers for stack objects. In this case of Depth Isolation, we
differentiate dynamic instances of the same variable. However,
489
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:32:21 UTC from IEEE Xplore.  Restrictions apply. 
in this work we restrict the policies to just stack objects.
Bounds checking approaches such as SoftBound + CETS
[45], [3] can provide complete memory safety using software
checks, but are expensive (116% overhead). Hardware support
for bounds checking, such as HardBoud [11], Intel’s MPX [15]
and CHERI [14], [59] can reduce these overheads drastically.
Metadata tags are an alternative mechanism that can provide
memory protection, and so this work can be seen as exploring
the space of tag-based policies for memory safety.
B. SDMP Policies
The stack protection policies we present in this work are
complementary to, and can be composed with, other SDMP
policies. Prior work has detailed policies for Control-Flow
Integrity (CFI) [17], [60], Information-Flow Control (IFC)
[61], [62], Instruction and Data Tainting [17], Minimal Typing
[17], Compartmentalization [60], Dynamic Sealing [60], Self
Protection [60], and Heap Memory Safety [17], [60]. These
previous policies did not address protecting the program stack.
The previous memory safety work [17] [60] only addressed
heap allocated data, where simply instrumenting the allocator
was sufﬁcient to build the policies. As we have seen, object-
level stack memory protection is signiﬁcantly more involved.
Interesting future work would be to apply some of the opti-
mizations we describe in this work, such as the DFI variants
of the policies, to previous heap safety policies.
C. Policy Applicability
Several systems provide programmable, multi-bit metadata
tags that could exploit the policies we derive here [63], [23],
[64], [65]. Aries [63] would need to be extended to include
tags on memory. Harmoni [23] lacks instruction tags, but
does decode control from instructions; most of our uses of
instruction tags could be replaced with augmented instructions.
Here, Depth Isolation, where ownership comes from depth
on pointers, would make more sense than Static Authorities,
which would require authority to be embedded in the instruc-
tions. The original Harmoni design has only two inputs to
its tag update table (UTBL), while some of our rules need
3 inputs, beyond the instruction tag, to track tags on both
register arguments and the memory. The SAFE Processor [64]
has a hardware isolated control stack, so does not need to use a
metadata policy for protecting procedure call control data. The
policies in this work can be seen as an option to unify stack
protection under the single mechanism of tagged metadata,
rather than adding a separate mechanism for just protecting
stack control data. DOVER [65] follows SDMP closely and
would be a direct match for our policies.
Emerging ﬂexible, decoupled monitoring architectures sup-
port parallel checking of events with metadata maintained in a
parallel monitor [66], [67], [68]. LBA and FADE [66], [67] add
hardware support to ﬁlter and accelerate events with structures
similar to the SDMP rule cache. The accelerators in reported
designs do not include accelerated handling for metadata on
the program counter and instructions, but such extensions
appear feasible. As with Harmoni, instruction tags could be
handled as augmented instructions. ARMHEx exploits the
ARM CoreSight debug port, added instrumentation code, and
programmable logic to perform tagged information tracking on
existing ARM SoCs such as a Xilinx Zynq [68]. Combining
the instrumentation to pass necessary data and programmable
logic to implement tracking and checking, it should be able
to implement the stack policies described here. The Depth
Isolation and Static Authorities policies we describe have
richer metadata and are more sophisticated than any of the
policies assessed in these monitoring architecture papers.
IX. LIMITATIONS AND FUTURE WORK
Other variations of policies we present could be constructed.
With additional compiler support, subﬁeld sensitive policies
(i.e., object-ids for individual ﬁelds of structs) could be derived
for stronger protection. Variants of the policies that combine
the notions of static owner and depth could overcome the lim-
itations of the Static Authorities and Depth Isolation policies.
Our policies do not differentiate between arguments, which
would also be a straightforward addition. Policies designed
against a stronger threat model (e.g., untrusted code) would
also be an interesting extension to this work.
X. CONCLUSION
In this work we demonstrate how a general-purpose tagged
architecture can accelerate stack protection security policies
expressed in the Software-Deﬁned Metadata Processing
model. We propose a simple policy that only protects
return addresses, as well as two richer policies that provide
object-level protection of all stack data. Our policies carry
forward information available to the compiler about
the
arrangement of stack memory and the intent of the various
accesses to the stack and validate them at runtime with
metadata tags and rules. Our policies exploit
the locality
properties of typical programs to achieve effective hardware
acceleration via a metadata tag rule cache. The main source
of overhead incurred by the policies is the instructions added
to tag and clear stack memory. We explore optimizations
for reducing this overhead, bringing the overheads for our
policies below 6% for memory safety and 4% for data-ﬂow
integrity. Although we derive our policies in the SDMP
model, our designs and optimizations are likely applicable to
other tagged architectures.
ACKNOWLEDGEMENTS
The authors would like to thank the anonymous reviewers,
as well as C˘at˘alin Hrit¸cu, Benjamin Pierce, Greg Sullivan, Eli
Boling, Nathan Dautenhahn, Nikos Vasilakis and Ben Karel
for their valuable feedback. This research was funded by Na-
tional Science Foundation grant TWC-1513854. Any opinions,
ﬁndings, and conclusions or recommendations expressed in
this material are those of the authors and do not reﬂect the
ofﬁcial policy or position of the National Science Foundation
or the U.S. Government.
490
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:32:21 UTC from IEEE Xplore.  Restrictions apply. 
REFERENCES
[1] TIOBE. (2017) TIOBE Index for October 2017. https://www.tiobe.com/
tiobe-index/. 2017-10-14.
[2] GNU Project. (2006) GCC 4.1 Release Series Changes, New Features,
and Fixes. https://gcc.gnu.org/gcc-4.1/changes.html. 2017-05-05.
[3] S. Nagarakatte, J. Zhao, M. M. K. Martin, and S. Zdancewic, “CETS:
Compiler enforced temporal safety for C,” in International Symposium
on Memory Management, Jun. 2010.
[4] L. Szekeres, M. Payer, T. Wei, and D. Song, “SoK: Eternal
in memory,” in IEEE Symposium on Security and Privacy.
[Online]. Available:
war
IEEE Computer Society, 2013, pp. 48–62.
http://lenx.100871.net/papers/War-oakland-CR.pdf
[5] M. D. Schroeder and J. H. Saltzer, “A hardware architecture for
implementing protection rings,” Communications of the ACM, vol. 15,
no. 3, pp. 157–170, March 1972.
[6] E. A. Feustel, “Tagged architecture and the semantics of programming
languages: Extensible types,” in 3rd Annual Symposium on Computer
Architecture (ISCA). ACM, 1976, pp. 147–150.
[7] M. E. Houdek, F. G. Soltis, and R. L. Hoffman, “IBM System/38 Support
for Capability-based Addressing,” in Proceedings of the Eighth Annual
Symposium on Computer Architecture, 1981, pp. 341–348.
[8] O. Saydjari, J. Beckman, and J. Leaman, “Lock trek: Navigating
uncharted space,” in Proceedings of the 1989 IEEE Symposium on
Security and Privacy, 1989.
[9] E. Witchel, J. Cates, and K. Asanovi´c, “Mondrian memory protection,”
in 10th International Conference on Architectural Support
for
Programming Languages and Operating Systems, ser. ASPLOS X.
New York, NY, USA: ACM, 2002, pp. 304–316. [Online]. Available:
http://doi.acm.org/10.1145/605397.605429
[10] G. E. Suh, J. W. Lee, D. Zhang, and S. Devadas, “Secure program
execution via dynamic information ﬂow tracking,” in International
for Programming Languages
Conference on Architectural Support
and Operating Systems, 2004, pp. 85–96.
[Online]. Available:
http://csg.csail.mit.edu/pubs/memos/Memo-467/memo-467.pdf
[11] J. Devietti, C. Blundell, M. M. K. Martin, and S. Zdancewic, “Hard-
Bound: Architectural support for spatial safety of the C programming
language,” in Proceedings of the International Conference on Archi-
tectural Support for Programming Languages and Operating Systems,
2008, pp. 103–114.
[12] C. Song, H. Moon, M. Alam, I. Yun, B. Lee, T. Kim, W. Lee,
and Y. Paek, “HDFI: Hardware-assisted data-ﬂow isolation,” in IEEE
Symposium on Security and Privacy (Oakland S&P).
IEEE Computer
Society, May 2016.
[13] F. McKeen, I. Alexandrovich, A. Berenzon, C. V. Rozas, H. Shaﬁ,
V. Shanbhogue, and U. R. Savagaonkar, “Innovative instructions and
software model for isolated execution,” in Workshop on Hardware and
Architectural Support for Security and Privacy, 2013, pp. 10:1–10:1.
[Online]. Available: http://doi.acm.org/10.1145/2487726.2488368
[14] J. Woodruff, R. N. Watson, D. Chisnall, S. W. Moore, J. Anderson,
B. Davis, B. Laurie, P. G. Neumann, R. Norton, and M. Roe, “The
CHERI capability model: Revisiting RISC in an age of risk,” in Proc.
of the International Symposium on Computer Architecture (ISCA), June
2014, pp. 457–468.
Corporation.
Introduction
[15] Intel
(2013)
Intel Memory
https://software.intel.com/en-us/articles/
Protection
introduction-to-intel-memory-protection-extensions. 2017-05-12.
Extensions.
to
[16] ——,
“Control-ﬂow
Technology
https://software.intel.com/sites/default/ﬁles/managed/4d/2a/
control-ﬂow-enforcement-technology-preview.pdf,
2016,
17.
Enforcement
Preview,”
2017-05-
[17] U. Dhawan, C. Hrit¸cu, R. Rubin, N. Vasilakis, S. Chiricescu, J. M.
Smith, T. F. Knight, Jr., B. C. Pierce, and A. DeHon, “Architectural
support for software-deﬁned metadata processing,” in Proceedings of
the International Conference on Architectural Support for Programming
Languages and Operating Systems, 2015, pp. 487–502.
[18] U. Dhawan and A. DeHon, “Area-efﬁcient near-associative memories
on FPGAs,” Transactions on Reconﬁgurable Technology and Systems,
vol. 7, no. 4, pp. 3:1–3:22,
[Online]. Available:
http://doi.acm.org/10.1145/2629471
Jan. 2015.
[19] E. A. Feustel, “On the Advantages of Tagged Architectures,”
IEEE Transactions on Computers, vol. 22, pp. 644–652, Jul. 1973.
[Online]. Available: http://www.feustel.us/Feustel%20&%20Associates/
Advantages.pdf
[20] E. I. Organick, Computer System Organization: The B5700/B6700
Series. Academic Press, 1973.
[21] M. Dalton, H. Kannan, and C. Kozyrakis, “Raksha: a ﬂexible
information ﬂow architecture for software security,” in International
Symposium on Computer Architecture (ISCA), 2007, pp. 482–493.
[Online]. Available: http://www.engr.uconn.edu/∼zshi/course/cse5302/
ref/dalton07raksha isca.pdf
[22] G. Venkataramani,
I. Doudalis, Y. Solihin, and M. Prvulovic,
“FlexiTaint: A programmable accelerator for dynamic taint propagation,”
in Proceedings of the International Symposium on High-Performance
Computer Architecture, Feb. 2008, pp. 173–184. [Online]. Available:
http://www.cc.gatech.edu/∼milos/venkataramani hpca08.pdf
[23] D. Y. Deng and G. E. Suh, “High-performance parallel accelerator for
ﬂexible and efﬁcient run-time monitoring,” in IEEE/IFIP International
Conference on Dependable Systems and Networks (DSN).
IEEE
Computer Society, 2012, pp. 1–12. [Online]. Available: http://tsg.ece.
cornell.edu/lib/exe/fetch.php?media=pubs:ﬂex-dsn2012.pdf
[24] Y.-Y. Chen, P. A. Jamkhedkar, and R. B. Lee, “A software-hardware
architecture for self-protecting data,” in ACM Conference on Computer
and Communications Security. ACM, 2012, pp. 14–27. [Online].
Available: http://palms.princeton.edu/system/ﬁles/chen ccs12.pdf
[25] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar, and D. Song,
“Code-Pointer Integrity,” in Proceedings of the 11th USENIX Symposium
on Operating Systems Design and Implementation (OSDI), 2014.
[26] T. Dang, P. Maniatis, and D. Wagner, “The Performance Cost of Shadow
Stacks and Stack Canaries,” in Proceedings of the ACM Asia Conference
on Computer and Communications Security (ASIACCS), April 2015.
[27] Y. Kim, R. Daly, J. Kim, C. Fallin, J. H. Lee, D. Lee, C. Wilkerson,
K. Lai, and O. Mutlu, “Flipping Bits in Memory Without Accessing
Them: An Experimental Study of DRAM Disturbance Errors,” in 41st
International Symposium on Computer Architecture (ISCA).