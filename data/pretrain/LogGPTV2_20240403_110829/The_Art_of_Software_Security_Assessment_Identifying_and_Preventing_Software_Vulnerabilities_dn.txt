specifically for creating and managing mutexes. 
The CreateMutex() function is used to create a new mutex: 
HANDLE CreateMutex(LPSECURITY_ATTRIBUTES lpMutexAttributes, 
                    BOOL bInitialOwner, LPCSTR lpName) 
The lpMutexAttributes parameter describes security attributes for the mutex being 
created. Setting the bInitialOwner parameter to TRUE creates the mutex in a locked 
state and grants the caller initial ownership. The final parameter, lpName, passes the 
object's name or NULL for an unnamed mutex. If a mutex with the same name 
already exists, that existing mutex is returned to the caller instead of a new one. 
When an existing mutex is opened the bInitialOwner parameter is ignored. 
The following function opens an existing mutex object: 
HANDLE OpenMutex(DWORD dwDesiredAccess, 
                  BOOL bInheritHandle, LPCSTR lpName) 
The dwDesiredAccess parameter describes what access rights the caller is requesting. 
The bInheritHandle parameter describes whether this handle should be inherited 
across a CreateProcess() call, and the lpName parameter is the name of the mutex to 
open. 
The ReleaseMutex() function signals the mutex so that other threads waiting on it can 
claim ownership of it (lock it): 
BOOL ReleaseMutex(HANDLE hMutex) 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
782 
A thread using this function must own the mutex and have the MUTEX_MODIFY_STATE 
access right to perform this operation. The current owner of a mutex can repeatedly 
acquire it without ever blocking. However, the mutex is not released until the number 
of calls to Release mutex equals the number of times the mutex was acquired by the 
current owner. In the discussion on "IPC Object Scoreboards" later in this chapter, 
you see exactly how this can be an issue. 
Event Objects 
An event object is used to inform another thread or process that an event has 
occurred. Like a mutex, an event object is always in a signaled or nonsignaled state. 
When it's in a nonsignaled state, any thread that waits on the event is put to sleep 
until it becomes signaled. An event differs from a mutex in that it can be used to 
broadcast an event to a series of threads simultaneously. In this case, a thread 
doesn't have exclusive ownership of the event object. 
Event objects can be further categorized into two subtypes: manual-reset events and 
auto-reset events. A manual-reset event is one in which the object stays in a signaled 
state until a thread manually sets it to a nonsignaled state. An auto-reset event is one 
that's automatically set to a nonsignaled state after a waiting thread is woken up. 
Creating and manipulating an event requires using the functions described in the 
following paragraphs. 
The CreateEvent() function is used to create a new event object with the security 
attributes described by the lpEventAttributes parameter: 
HANDLE CreateEvent(LPSECURITY_ATTRIBUTES lpEventAttributes, 
                    BOOL bManualReset, BOOL bInitialState, 
                    LPCSTR lpName) 
The bManualReset parameter indicates whether the object is manual-reset or 
auto-reset; a value of TRUE creates a manual-reset object and a value of FALSE 
creates an auto-reset object. The bInitialState parameter indicates the initial state 
of the event; a value of TRUE sets the object to a signaled state and a value of FALSE 
sets it to a nonsignaled state. Finally, lpName indicates the name of the event object 
being created or NULL for an unnamed event. Like mutexes, passing the name of an 
existing event object causes it to be opened instead. 
The OpenEvent() function works in the same way OpenMutex() does, except it opens a 
previously created event rather than a mutex: 
HANDLE OpenEvent(DWORD dwDesiredAccess, BOOL  bInheritHandle, LPCSTR 
lpName) 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
783 
The SetEvent() function sets an event to a signaled state. The caller must have 
EVENT_MODIFY_STATE access rights to use this function: 
BOOL SetEvent(HANDLE hEvent) 
The ResetEvent() function sets an event to a nonsignaled state: 
BOOL ResetEvent(HANDLE hEvent) 
This function is used only for manual-reset events because they require threads to 
reset the event to a nonsignaled state. This function also requires that the caller has 
EVENT_MODIFY_STATE access rights for the event. 
Semaphore Objects 
As in other operating systems, semaphores are used to allow a limited number of 
threads access to some shared object. A semaphore maintains a count initialized to 
the maximum number of acquiring threads. This count is decremented each time a 
wait function is called on the object. When the count becomes zero, the object is no 
longer signaled, so additional threads using a wait function on the object are blocked. 
The functions for dealing with semaphores are described in the following paragraphs. 
The CreateSemaphore() function creates a new semaphore or opens an existing 
semaphore if one with the same name already exists: 
HANDLE CreateSemaphore(LPSECURITY_ATTRIBUTES lpAttributes, 
                       LONG lInitialCount, LONG lMaximumCount, 
                       LPCSTR lpName) 
The lInitialCount parameter indicates the initial value of the semaphore counter. 
This value must be between 0 and lMaximumCount (inclusive). If the value is 0, the 
semaphore is in a nonsignaled state; otherwise, it's in a signaled state when 
initialized. The lMaximumCount parameter specifies the maximum number of threads 
that can simultaneously wait on this object without blocking. 
The OpenSemaphore() function opens an existing semaphore and works in the same 
way that OpenMutex() and OpenEvent() do: 
HANDLE OpenSemaphore(DWORD dwDesiredAccess, BOOL bInheritable, 
                       LPCSTR lpName) 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
784 
The ReleaseSemaphore() function increments the semaphore count by the amount 
specified in lReleaseCount: 
BOOL ReleaseSemaphore(HANDLE hSemaphore, LONG lReleaseCount, 
                      LPLONG lpPreviousCount) 
This function fails if lReleaseCount causes the semaphore to exceed its internal 
maximum count. The lpPreviousCount stores the previous count held by the 
semaphore before this function call. Usually, a call to this function leaves the 
semaphore in a signaled state because the resulting count is greater than zero. 
Waitable Timer Objects 
A waitable timer, or timer, is used to schedule threads for work at a later time by 
becoming signaled after a time interval has elapsed. There are two types of waitable 
timers: manual-reset and synchronization timers. A manual-reset timer remains 
signaled until it's manually reset to a nonsignaled state. A synchronization timer stays 
signaled until a thread completes a wait function on it. In addition, any waitable timer 
can be a periodic timera timer that's automatically reactivated each time the specified 
interval expires. The functions for dealing with waitable timers are described in the 
following paragraphs. 
The CreateWaitableTimer() function works the same way other Create*() functions 
do: 
HANDLE CreateWaitableTimer(LPSECURITY_ATTRIBUTES lpAttributes, 
                           BOOL bManualReset, LPCSTR lpName) 
The bManualReset parameter specifies whether the timer should be a manual-reset 
timer or synchronization timer. A value of TRUE indicates it's a manual-reset timer, 
and a value of FALSE indicates it's a synchronization timer. 
The OpenWaitableTimer() function is used to open an existing named waitable timer 
object. It works the same way other Open*() functions do: 
HANDLE OpenWaitableTimer(DWORD dwDesiredAccess, BOOL bInheritable, LPCSTR 
lpName) 
The SetWaitableTimer() function is responsible for initializing a waitable timer with a 
time interval: 
BOOL SetWaitableTimer(HANDLE hTimer, const LARGE_INTEGER *pDueTime, 
                      LONG lPeriod, 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
785 
                      PTIMERAPCROUTINE pfnCompletionRoutine, 
                      LPVOID lpArgToCompletionRoutine, 
                      BOOL fResume) 
The pDueTime parameter specifies the interval for the timer to be signaled after, and 
the lPeriod parameter specifies whether this timer should be reactivated after the 
time interval has elapsed. A value larger than 0 indicates it should, and a value of 0 
indicates that it should signal only once. The next two parameters are a pointer to an 
optional completion routine that's called after the timer is signaled and an argument 
for that completion routine. The routine is queued as a user-mode APC. Finally, the 
fResume parameter indicates that the system should recover out of suspend mode if 
it's in suspend when the timer is activated. 
The following function deactivates an active timer: 
BOOL CancelWaitableTimer(HANDLE hTimer) 
The caller must have TIMER_MODIFY_STATE access to the object for this function to 
succeed. 
Vulnerabilities with Interprocess Synchronization 
Now that you're familiar synchronization primitives, you can begin to explore what 
types of vulnerabilities could occur from incorrect or unsafe use of these primitives. 
Lack of Use 
Obviously, there's a problem when synchronization objects are required but not used. 
In particular, if two processes are attempting to access a shared resource, a race 
condition could occur. Take a look at a simple example: 
char *users[NUSERS]; 
int curr_idx = 0; 
DWORD phoneConferenceThread(SOCKET s) 
{ 
    char *name; 
    name = readString(s); 
    if(name == NULL) 
        return 0; 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
786 
    if(curr_idx >= NUSERS) 
        return 0; 
    users[curr_idx] = name; 
    curr_idx++; 
    .. more stuff .. 
} 
Say a daemon accepted connections on a listening socket, and each new connection 
caused a thread to be spawned, running the code shown in the example. Clearly, 
there is a problem with modifying the users and curr_idx variables without using 
synchronization objects. You can see that the function is not reentrant due to its 
handling of global variables; so calling this function in multiple concurrent threads will 
eventually exhibit unexpected behavior due to not accessing the global variables 
atomically. A failure to use synchronization primitives in this instance could result in 
an overflow of the users array, or cause a name to unexpectedly overwritten in the 
users array. 
When you're auditing code that operates on an improperly locked shared resource, 
it's important to determine the implications of multiple threads accessing that 
resource. In reality, it's quite uncommon for developers to disregard concurrency 
issues and not use any form of synchronization objects. However, developers can 
make mistakes and forget to use synchronization primitives in unexpected or 
infrequently traversed code paths. The "Threading Vulnerabilities(? [????.])" section 
later in this chapter presents an example of this issue in the Linux kernel. 
Incorrect Use of Synchronization Objects 
Misusing synchronization objects can also cause problems. These types of errors 
generally occur because developers don't fully understand the API or fail to check 
when certain exceptional conditions occur, such as not checking for return values. To 
determine when this error has been made, you need to cross-check synchronization 
API calls with how they appear in the program, and then determine whether they 
correspond with the developer's intentions. The following code shows an example of 
incorrect use of a synchronization function. First, there's a function to initialize a 
program containing multiple threads. One thread reads requests from a network and 
adds jobs to a global queue, and a series of threads read jobs from the queue and 
process them. 
HANDLE queueEvent, jobThreads[NUMTHREADS+1]; 
struct element *queue; 
HANDLE queueMutex; 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
787 
SOCKET fd; 
DWORD initJobThreads(void) 
{ 
    int i; 
    queueEvent = CreateEvent(NULL, TRUE, FALSE, NULL); 
    if(queueEvent == NULL) 
        return -1; 
    queueMutex = CreateMutex(NULL, FALSE, NULL); 
    for(i = 0; i next; 
        ReleaseMutex(queueMutex); 
        .. process element .. 
    } 
    return 0; 
} 
DWORD processNetwork(LPVOID arg) 
{ 
    struct element *elem, *tmp; 
    struct request *req; 
    for(;;) 
    { 
        req = readRequest(fd); 
        if(req == NULL) // bad request 
            continue; 
        elem = request_to_job_element(req); 
        HeapFree(req); 
        if(elem == NULL) 
            continue; 
        WaitForSingleObject(queueMutex, INFINITE); 
        if(queue == NULL) 
        { 
            queue = elem; 
            SetEvent(queueEvent); 
        } 
        else 
        { 
            for(tmp = queue; tmp->next; tmp = tmp->next) 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
789 
                ; 
            tmp->next = elem; 
        } 
        ReleaseMutex(queueMutex); 
    } 
    return 0; 
} 
Do you see the problem with this code? Look at the way the event object is initialized: 
queueEvent = CreateEvent(NULL, TRUE, FALSE, NULL); 
Setting the second parameter to TRUE indicates the object is a manual-reset event. 
However, by reading the code, you can tell that the developer intended to use an 
automatic-reset event, because after the first time the event is signaled, the 
manual-reset event remains in that state forever, even when the queue is empty. The 
incorrect use of CreateEvent() in this example leads to a NULL pointer dereference in 
processJob(), as a successful return from WaitForSingleObject() indicates that the 
queue is not empty. Astute readers might notice an additional flaw: This code is 
vulnerable to deadlock. If the queue is empty when processJob() runs, the running 
thread calls WaitForSingleObject(), which puts the caller to sleep until the 
processNetwork() function signals the event object. However, the processJob() 
routine waiting on the event is holding the queueMutex lock. As a result, 
processNetwork() can never enter, thus resulting in deadlock. 
As you can see, errors resulting from incorrect use of synchronization objects are 
quite easy to make, especially when a multitude of objects are used. Creating a 
program without deadlocking and race conditions can be tricky; often the logic just 
isn't obvious, as shown in the previous example. In "IPC Object Scoreboards" later in 
this chapter, you learn a technique that utilizes scoreboards to track IPC object use. 
These scoreboards can help you determine how each object is used and whether 
there's a possibility it's being misused. 
Squatting with Named Synchronization Objects 
Chapter 11(? [????.]) introduced Windows namespace squatting, which occurs when 
a rogue application creates a named object before the real application can. This type 
of attack is a serious consideration for named synchronization objects. Imagine, for 
example, a program with the following code during its initialization: 
int checkForAnotherInstance(void) 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
790 
{ 
    HANDLE hMutex; 
    hMutex = OpenMutex(MUTEX_ALL_ACCESS, FALSE, "MyProgram"); 
    if(hMutex == NULL) 
        return 1; 
    CloseHandle(hMutex); 
    return 0; 
} 
The checkForAnotherInstance() function is called in the early stages of a program 
invocation. If it returns 1, the process exits because another instance of the program 
is already running. 
Note 
Synchronization objects are often used to prevent multiple instances of a program 
from running on a single host. 
Say you run another process that creates a mutex named MyProgram and holds the 
lock indefinitely. In this case, the checkForAnotherInstance() function always returns 
1, so any attempt to start this application fails. If this mutex is created in the global 
namespace, it prevents other users in a Terminal Services or XP environment from 
starting the application as well. 
In addition to creating objects for the purpose of preventing an application from 
running correctly, a rogue application might be able to take possession of an object 
that another application created legitimately. For example, consider a scenario in 
which a process creates a global object and a number of other processes later 
manipulate this object. Processes attempting to manipulate the object do so by 
waiting on a mutex, as shown in this example: 
int modifyObject(void) 