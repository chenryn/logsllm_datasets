power meter [31]. Fig. 19c confirms that videoconferencing
is an expensive task on mobile, draining up to 40% of its
2600mAh battery during an one-hour conference with camera
on. Overall, the figure shows no dramatic difference among
the three clients, whose battery usage is within 10% of each
other. Zoom is the most energy efficient client with gallery
view (LM-View), which provides a 20% reduction compared
with LM. Gallery view does not provide benefits to both Webex
and Meet, similar to what we reported for both CPU usage
and data rate. Finally, turning off the screen and relying on
audio only saves up to 50% of a user‚Äôs battery.
Videoconference size. Finally, we investigate the impact of
the number of conference participants on client-side resource
utilization. To do so, in addition to the meeting host, we
introduce up to eight cloud-VMs as participants. To further
stress the devices under test, we configure the host as well
as the extra eight cloud VMs to stream a high-motion video
simultaneously. We consider two UI settings in the Android
clients: full screen and gallery.
Table 4 summarizes the results; we report on average data
rate and median CPU utilization per device (S10/J3, in each
cell) and scenario. Note that ùëÅ = 3 is the scenario we have
evaluated so far, i.e., one cloud VM as a meeting host plus
two Android devices. In full screen mode, Meet incurs a
significant increase in both data rate (10%) and CPU usage
(50%). This is because, even in full screen, Meet still shows
a small preview of the video of the other two participants
(plus the device‚Äôs video, if on). Conversely, Zoom and Webex
appear visually equivalent in full screen regardless of ùëÅ.
Still, for Zoom we observe a small increases in its data rate
(5%) and CPU (12%) suggesting that some additional video
streams are being buffered in the background with the goal
to minimize latency in case a user decides to change the view
into gallery. Although we could not capture such latency,
we visually confirmed that both Zoom and Meet allow us
to rapidly switch between participants, while Webex incurs
some buffering time in the order of seconds.
If we focus on the gallery view, we see that the extra
participants cause a twofold data rate increase for Zoom,
but no additional CPU usage. A similar trend is observed
for Webex CPU-wise, but in this case we also observe a
counter-intuitive data rate reduction (from 600 Kbps down to
450 Kbps). Upon visual inspection, we find that this reduction
is associated with a significant quality degradation in the
video stream. Further increasing the participants to 11 does
not lead to additional resource consumption. This happens
because the gallery view of Zoom and Webex ‚Äì as well as the
only Meet‚Äôs setting ‚Äì show videos for up to four concurrent
participants.
6 LIMITATIONS
We conclude the paper by discussing several limitations of
our study and future works we plan to explore.
Effect of last mile. Our cloud-based vantage points may not
represent the realistic last-mile network environments (e.g.,
broadband, wireless) of typical videoconferencing users from
two perspectives. First, the upstream connectivity of cloud-
emulated clients (with multi-Gbps available bandwidth) is
too idealistic. While our experiments with bandwidth em-
ulation (Section 4.4) and a mobile testbed (Section 5) are
intended to address this limitation, a more realistic QoE
analysis would consider dynamic bandwidth variation and
jitter as well. Another caveat is that all our emulated clients
are created inside a single provider network (i.e., Azure net-
work). Thus any particular connectivity/peering of the Azure
network might influence our cloud experiments. Ideally, the
testbed should be deployed across multiple cloud providers to
mitigate any artifact of a single provider, or even encompass
distributed edge-based platforms provisioned across hetero-
geneous access networks (e.g., residential [20, 38], campus [2]
and enterprise networks [11, 12]). In fact, moving the evalua-
tion platform to the edge would allow us to extend the list
of target videoconferencing systems to study.7
Free-tier vs. paid subscription. The validity of our findings is
limited to the free-tier services. Given the prevalent multi-
CDN strategies [9] and differentiated product offerings, user‚Äôs
QoE can change under different subscription plans or any
special license arrangements. For example, Zoom is known
to allow users with a university license to connect to AWS in
Europe [34], which we do not observe with its free-tier/paid
subscription plans. In case of Webex, we confirm that, with
a paid subscription, its clients in US-west and Europe can
stream from geographically close-by Webex servers (with
RTTs < 20 ms). Our methodology allows us to easily extend
the scope of our study beyond the free-tier services.
Videoconferencing scalability. Our QoE analysis targets small-
size videoconferencing sessions (with up to 11 participants).
An interesting question is how well user‚Äôs QoE on each system
scales as a videoconferencing session is joined by a moder-
ate/large number of participants. One possible approach
would use a mix of crowd-sourced human users (who would
generate varied-size videoconferencing sessions) and cloud
VMs (which would be under our control for detailed QoE
analysis of such sessions).
7The use of Azure cloud prevents us from including Microsoft Team
in our evaluation list.
227
Can You See Me Now? A Measurement Study of Zoom, Webex, and Meet
IMC ‚Äô21, November 2‚Äì4, 2021, Virtual Event, USA
Black-box testing. Our measurement study is a case of black-
box testing, where we do not have any knowledge on inner
workings of individual systems we study. As such we are
severely limited in our ability to explain some of the observa-
tions we are making. That said, we still argue that our study
presents a valuable contribution to the community. For one,
our platform-agnostic methodology is general enough for any
arbitrary videoconferencing systems. Also, the proposed eval-
uation scenarios can be a useful input to videoconferencing
operators for enhancing their infrastructures and clients.
Videoconferencing client. Our emulated client runs on Linux
only (via in-kernel virtual devices). We consider that the
modern Linux environment is representative enough for video-
conferencing due to the good Linux support [13] or the use
of cross-platform web clients by the existing systems. For
completeness, one can extend the client emulation beyond
Linux, at least in a desktop environment, using similar device
emulation and workflow automation tools on Windows [5, 17]
and MacOS [4, 10]. The QoE analysis could then be extended
to cover different mobile and desktop environments in a more
comprehensive fashion.
REFERENCES
[1] 2020.
AWS and Zoom Extend Strategic Relationship.
https://press.aboutamazon.com/news-releases/news-release-
details/aws-and-zoom-extend-strategic-relationship/.
[2] 2020. CloudLab. https://www.cloudlab.us.
[3] 2020. Fsv2-series ‚Äì Azure Virtual Machines.
https://docs.
microsoft.com/en-us/azure/virtual-machines/fsv2-series.
[4] 2020. OBS (macOS) Virtual Camera.
https://github.com/
johnboiles/obs-mac-virtualcam.
[5] 2020. OBS-VirtualCam.
virtual-cam.
https://github.com/CatxFish/obs-
[6] 2020. VQMT: Video Quality Measurement Tool. https://www.
epfl.ch/labs/mmspg/downloads/vqmt/.
[7] 2021.
https://support.zoom.us/hc/en-us/articles/201362023-
System-Requirements-for-PC-Mac-and-Linux.
[8] 2021. https://help.webex.com/en-us/WBX22158/What-are-the-
Minimum-Bandwidth-Requirements-for-Sending-and-Receiving-
Video-in-Cisco-Webex-Meetings.
[9] 2021. 2020 Pandemic Network Performance. Broadband Internet
Technical Advisory Group. https://www.bitag.org/documents/
bitag_report.pdf.
[10] 2021. Automator User Guide for Mac. https://support.apple.
com/guide/automator/.
[11] 2021. AWS Snow Family. https://aws.amazon.com/snow/.
[12] 2021. Azure Stack Edge. https://azure.microsoft.com/en-us/
products/azure-stack/edge/.
[13] 2021. Desktop client, mobile app, and web client compari-
son. https://support.zoom.us/hc/en-us/articles/360027397692-
Desktop-client-mobile-app-and-web-client-comparison.
[14] 2021. Google Meet hardware requirements. https://support.
google.com/meethardware/answer/4541234.
[15] 2021. IP Latency Statistics by Verizon. https://www.verizon.
com/business/terms/latency/.
[16] 2021. Microsoft Azure. https://azure.microsoft.com.
[17] 2021. Power Automate - Microsoft Power Platform.
https:
//powerautomate.microsoft.com.
[18] 2021. Time sync for Linux VMs in Azure. https://docs.microsoft.
com/en-us/azure/virtual-machines/linux/time-sync.
[19] 2021. ViSQOL: Perceptual Quality Estimator for speech and
audio. https://github.com/google/visqol.
[20] Hyunseok Chang, Adiseshu Hari, Sarit Mukherjee, and T. V.
Lakshman. 2014. Bringing the Cloud to the Edge. In Proc. IEEE
Workshop on Mobile Cloud Computing.
[21] Ana-Paula Correia, Chenxi Liu, and Fan Xu. 2020. Evaluating
Videoconferencing Systems for the Quality of the Educational
Experience. Distance Education 41, 4 (2020), 429‚Äì452.
[22] Augusto Espin and Christian Rojas. 2021. The Impact of the
COVID-19 Pandemic on the Use of Remote Meeting Technologies.
SSRN. https://dx.doi.org/10.2139/ssrn.3766889.
[23] Anja Feldmann, Oliver Gasser, Franziska Lichtblau, Enric Pu-
jol, Ingmar Poese, Christoph Dietzel, Daniel Wagner, Matthias
Wichtlhuber, Juan Tapiador, Narseo Vallina-Rodriguez, Oliver
Hohlfeld, and Georgios Smaragdakis. 2020. The Lockdown Effect:
Implications of the COVID-19 Pandemic on Internet Traffic. In
Proc. ACM Internet Measurement Conference (IMC).
[24] Sadjad Fouladi, John Emmons, Emre Orbay, Catherine Wu,
Riad S. Wahby, and Keith Winstein. 2018. Salsify: Low-Latency
Network Video through Tighter Integration between a Video
Codec and a Transport Protocol. In Proc. NSDI.
[25] Pan Hu, Rakesh Misra, and Sachin Katti. 2019. Dejavu: En-
hancing Videoconferencing with Prior Knowledge. In Proc. the
20th International Workshop on Mobile Computing Systems and
Applications. 63‚Äì68.
[26] Randall Hunt. 2017. Keeping Time With Amazon Time Sync
Service. https://aws.amazon.com/blogs/aws/keeping-time-with-
amazon-time-sync-service/.
[27] Lisa M. Koonin, Brooke Hoots, Clarisse A. Tsang, Zanie Leroy,
Kevin Farris, Brandon Jolly, Peter Antall, Bridget McCabe, Cyn-
thia B.R. Zelis, Ian Tong, and Aaron M. Harris. 2020. Trends in
the Use of Telehealth During the Emergence of the COVID-19
Pandemic‚ÄîUnited States, January‚ÄìMarch 2020. Morbidity and
Mortality Weekly Report 69, 43 (Oct. 2020).
[28] Craig Labovitz. 2020. Network traffic insights in the time of
COVID-19: March 23-29 update. https://www.nokia.com/blog/
network-traffic-insights-time-covid-19-march-23-29-update/.
[29] Kyle MacMillan, Tarun Mangla, James Saxon, and Nick Feam-
ster. 2021. Measuring the Performance and Network Utilization
of Popular Video Conferencing Applications. arXiv preprint
arXiv:2105.13478 (2021).
[30] Arghir-Nicolae Moldovan and Cristina Hava Muntean. 2017. QoE-
aware Video Resolution Thresholds Computation for Adaptive
Multimedia. In Proc. IEEE International Symposium on Broad-
band Multimedia Systems and Broadcasting.
https://www.msoon.com.
[31] Monsoon Solutions Inc. 2021. High Voltage Power Monitor.
[32] Adam Ozimek. 2020. Economist Report: Future Workforce. Tech-
nical Report. ClearlyRated. https://www.upwork.com/press/
releases/economist-report-future-workforce.
[33] Otto Parra and Maria Fernanda Granda. 2021. Evaluating the
Meeting Solutions Used for Virtual Classes in Higher Education
during the COVID-19 Pandemic. In Proc. the 16th International
Joint Conference on Computer Vision, Imaging and Computer
Graphics Theory and Applications.
[34] Constantin Sander, Ike Kunze, Klaus Wehrle, and Jan R√ºth. 2021.
Video Conferencing and Flow-Rate Fairness: A First Look at Zoom
and the Impact of Flow-Queuing AQM. In Proc. International
Conference on Passive and Active Measurement.
[35] Hamid Rahim Sheikh and Alan C. Bovik. 2006. Image Information
and Visual Quality. IEEE Transactions on Image Processing 15,
2 (2006).
[36] Ravinder Singh and Soumya Awasthi. 2020. Updated Comparative
Analysis on Video Conferencing Platforms-Zoom, Google Meet,
Microsoft Teams, WebEx Teams and GoToMeetings. EasyChair
Preprint no. 4026 (2020).
[37] Sri Srinivasan. 2020. Cisco Webex: Supporting customers
during this unprecedented time. https://blog.webex.com/video-
conferencing/cisco-webex-supporting-customers-during-this-
unprecedented-time/.
[38] Matteo Varvello, Kleomenis Katevas, Mihai Plesa, Hamed Had-
dadi, and Benjamin Livshits. 2019. BatteryLab: A Distributed
Power Monitoring Platform For Mobile Devices. In Proc. HotNets
‚Äô19.
[39] Zhou Wang, Alan C. Bovik, Hamid R. Sheikh, and Eero P. Simon-
celli. 2004. Image Quality Assessment: From Error Visibility to
Structural Similarity. IEEE Transactions on Image Processing
13, 4 (2004).
[40] Cui Zou, Wangchuchu Zhao, and Keng Siau. 2020. COVID-19
Pandemic: A Usability Study on Platforms to Support eLearn-
ing. In Proc. International Conference on Human-Computer
Interaction. Springer, 333‚Äì340.
228