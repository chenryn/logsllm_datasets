time and packaged with the object code. When the code
is downloaded, the certiﬁcate is downloaded along with it.
The consumer can then run a veriﬁer, which inspects the
code and the certiﬁcate to verify compliance with a security
policy. If it passes the test, then the code is safe to run. The
veriﬁer is part of the consumer’s trusted computing base;
the compiler, the compiled code, and the certiﬁcate need
not be.
5.2.1 Java
instance of
large-scale practical
Perhaps the ﬁrst
the
language-based approach was the Java programming lan-
guage [8]. Javas language-based mechanism is designed
to protect against malicious applets. The Java runtime en-
vironment contains a bytecode veriﬁer that is supposed to
ensure the basic properties of memory, control ﬂow, and
type safety. In addition, a trusted security manager enforces
higher-level safety policies such as restricted disk I/O. The
Java compiler produces platform-independent virtual ma-
chine instructions or bytecode that can be veriﬁed by the
consumer before execution. The bytecode is then either in-
terpreted by a Java virtual machine (VM) interpreter or fur-
ther compiled down to native code.
Early versions of Java contained a number of highly pub-
licized security ﬂaws [3]. For example, a subtle defect in the
Java type system allowed an applet to create and control a
partially instantiated class loader. The applet could then use
this class loader to load, say, a malicious security manager
that would permit unlimited disk access.
Some authors [3, 9] blamed these problems on the lack
of an adequate semantic model for Java. Steps to remedy
this situation have since been taken [1, 19]. Despite these
initial failings, the basic approach was a signiﬁcant step for-
ward in practical programming language security.
It not
only pointed the way toward a simple and effective means
of providing a basic level of security, but also helped direct
the attention of the programming language and veriﬁcation
community to critical security issues resulting from the rise
of the Internet.
The machine-independent bytecode produced by the
Java compiler is still quite high-level, and that is a disad-
vantage. Once downloaded, the bytecode must either be
interpreted by a Java VM interpreter or compiled to native
code by a just-in-time (JIT) compiler. Either technique in-
curs a runtime penalty. If the safety certiﬁcate represented
in the bytecode were mapped down to the level of native
code by a back-end Java VM compiler, then the same degree
of safety could be ensured without the runtime penalty, be-
cause the code supplier could do the back-end compilation
before downloading. This would trade the platform inde-
pendence of Java VM for the efﬁciency of native code.
5.2.2 Proof Carrying Code (PCC)
Proof carrying code (PCC) [13, 14, 15, 16, 17, 18] is a strat-
egy for producing and verifying formal proofs that code
meets general security policies. The software supplier does
the hard work of generating the proof, and the software con-
sumer checks the proof before the code is run. The security
policy is expressed in ﬁrst-order logic augmented with sym-
bols for various language and machine constructs.
The most general version of PCC is somewhat more
complicated, involving a two-phase interaction between the
supplier and the consumer. In the ﬁrst phase of this proto-
col, the supplier produces and delivers a program consisting
of annotated object code. The annotations consist of loop
invariants and function pre- and post-conditions, and make
the next phase of the protocol easier. The consumer formu-
lates a safety policy and uses an automated tool to generate,
from the policy and the annotated program, a veriﬁcation
condition. The veriﬁcation condition is a logical formula
that implies that the program satisﬁes its security policy. In
the second phase of the protocol, the supplier proves the
veriﬁcation condition and sends the proof back to the con-
sumer. The consumer runs a proof checker to check that the
proof is valid.
The veriﬁcation condition generator is part of the con-
sumer’s trusted computing base—in a sense,
it deﬁnes
the security policy—but some communication cost can be
saved by having the supplier generate the veriﬁcation con-
dition using the same veriﬁcation condition generator that
the consumer uses. The consumer then checks that the ver-
iﬁcation condition produced by the supplier is the same as
the one produced locally.
A certifying compiler produces the initial annotation
of the code, using information from the program source
and program analysis during compilation. The Touchstone
compiler [14] is a certifying compiler for a type-safe sub-
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
set of C. It admits many common optimizations such as
dead code elimination, common subexpression elimination,
copy propagation, instruction scheduling, register alloca-
tion, loop invariant hoisting, redundant code elimination,
and the elimination of array bounds checks.
The advantages of the PCC approach are its expressive-
ness and its ability to handle code optimizations. In prin-
ciple, any security policy that can be constructed by a ver-
iﬁcation condition generator and expressed as a ﬁrst-order
veriﬁcation condition can be handled. The main disadvan-
tages are that it is a two-phase protocol, that it involves
weighty machinery such as a full-ﬂedged ﬁrst-order theo-
rem prover and proof checker, and that proof sizes are quite
large, roughly 2.5 times the size of the object code for type
safety and even larger for more complicated safety policies.
Given the limited space available on boot ﬁrmware, this size
penalty alone makes PCC inappropriate for our problem.
5.2.3 Typed Assembly Language (TAL)
Typed assembly language (TAL) [4, 9, 10, 12] can be
viewed as a specialized form of proof-carrying code de-
voted to verifying a form of type safety. It is a language-
based system in which type information from a strongly-
typed high-level language is preserved as compilation trans-
forms the source through a platform-independent typed in-
termediate language (TIL) [11, 23] down to the level of the
object code itself. The result is a type annotation of the ob-
ject code that can be checked by an ordinary type checker.
In this special case, proof checking is reduced to type check-
ing.
TAL is not as expressive as PCC, but it can handle any
security policy expressible in terms of the type system. This
includes memory, control ﬂow, and type safety, among oth-
ers. TAL is also robust with respect to compiler optimiza-
tions, since type annotations can be transformed along with
the code. TAL proofs, though much smaller than proofs
in PCC, are still signiﬁcantly larger than those needed by
ECC.
Proof size can be traded off against the complexity of
the veriﬁer, but that increases and complicates the amount
of trusted code.
6. Current Project Status
The long-term goal of this project is to adapt the ECC
technique to the analysis of Open Firmware fcode pro-
grams to detect malicious boot software. We are imple-
menting a certifying compiler and veriﬁer necessary for this
method. The ECC-based veriﬁer will then be incorporated
into an existing commercial implementation of the Open
Firmware standard in order to provide practical malicious
boot ﬁrmware detection to the marketplace.
At present, we have a working prototype of the J2F
compiler for Java Virtual Machine (JVM) bytecode to
Forth fcode for a single-threaded subset of the Java lan-
guage. This subset is appropriate for writing device drivers
and other ﬁrmware modules.
It provides access to Open
Firmware services through an API currently being de-
signed. The compiler will output a certiﬁcate appropriate
to the veriﬁcation tasks described below. The API takes ad-
vantage of the natural object-oriented structure of the Open
Firmware device tree and allows access to Open Firmware
services from within Java programs.
The BootSafe veriﬁer will initially verify only basic type
safety, roughly at the level provided by ECC and by the Java
bytecode veriﬁer. This initial version operates as a stand-
alone program.
We have successfully compiled sample device drivers for
a block-oriented storage device and a PCI bus. These are
good representatives of typical devices in current use. These
drivers can run under SmartFirmware (a commercial Open
Firmware implementation) in simulation mode.
7. Conclusions and Future Work
As noted, typical boot ﬁrmware is an amalgam of many
pieces, including libraries, the main boot program, and
boot-time device drivers from various vendors. To inter-
act successfully, these pieces must respect well-deﬁned ab-
straction boundaries and communicate only via standard-
ized interfaces. Yet at boot time, the pieces all run in the
same address space. There is no isolation and no exter-
nal enforcement of good citizenship. The existing Open
Firmware standard does not address this problem. It only
helps non-malicious designers by deﬁning the standard for
device interaction and process management during bootup.
Our approach has the potential to guarantee that all of
the pieces of boot ﬁrmware are good citizens:
that they
respect each other’s boundaries and interact only via pub-
lished standardized interfaces. Moreover, this guarantee is
refreshed each time the boot program runs with inexpen-
sive static checks. Rechecking each time counters the threat
of substituting malicious boot ﬁrmware components for ap-
proved ones.
We believe Open Firmware is the right context because
it is a clear, well-designed, and widely used standard. We
have designed a Java-to-fcode certifying compiler and built
an early prototype. Our current effort is directed toward
making this novel form of protection a practical reality by
integrating the veriﬁer with a commercial implementation
of Open Firmware.
Although we our developing our techniques in the con-
text of the Open Firmware standard, there is nothing to pre-
vent non-Open Firmware compliant boot ﬁrmware from be-
ing made veriﬁable using similar techniques.
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
Among the large-scale issues still to be addressed are:
(cid:15) the design of a Java API for Open Firmware that is both
convenient to use and supports the kind of veriﬁcation
that we require;
(cid:15) enhancement of the veriﬁer to verify compliance of
fcode programs with the second-order security policy
(this version of the veriﬁer will run as a stand-alone
program and will be directly integrated with Smart-
Firmware);
(cid:15) modiﬁcation of the J2F compiler to accommodate the
reﬁned Open Firmware API and enhanced veriﬁcation.
Acknowledgments
We are indebted to T. J. Merritt for valuable ideas and
comments and to David Baca and Kori Oliver for their as-
sistence with the implementation. We also thank the anony-
mous reviewers for their suggestions. This work was sup-
ported in part by DARPA contracts DAAH01-02-C-R080
and DAAH01-01-C-R026, NSF grant CCR-0105586, and
ONR Grant N00014-01-1-0968. The views and conclusions
contained herein are those of the authors and should not be
interpreted as necessarily representing the ofﬁcial policies
or endorsements, either expressed or implied, of these orga-
nizations or the US Government.
References
[1] M. Abadi and R. Stata. A type system for Java bytecode
subroutines. In Proc. 25th Symp. Principles of Programming
Languages, pages 149–160. ACM SIGPLAN/SIGACT, Jan-
uary 1998.
[2] William A. Arbaugh, David J. Farber, and Jonathan M.
Smith. A secure and reliable bootstrap architecture.
In
Proc. 1997 Symposium on Security and Privacy, pages 65–
71. IEEE, May 1997.
[3] Drew Dean, Ed Felten, and Dan Wallach. JAVA security:
From HotJava to Netscape and beyond. In Proc. Symp. Se-
curity and Privacy. IEEE, May 1996.
[4] N. Glew and G. Morrisett. Type-safe linking and mod-
ular assembly language.
In Proc. 26th Symp. Principles
of Programming Languages, pages 250–261. ACM SIG-
PLAN/SIGACT, January 1999.
[5] IEEE. IEEE Standard for Boot (Initialization Conﬁguration)
Firmware: Core Requirements and Practices, 1994. Stan-
dard 1275-1994.
[6] Dexter Kozen. Efﬁcient code certiﬁcation. Technical Report
98-1661, Computer Science Department, Cornell University,
January 1998.
[7] Dexter Kozen and Matt Stillerman. Eager class initialization
for Java. In W. Damm and E.R. Olderog, editors, Proc. 7th
Int. Symp. Formal Techniques in Real-Time and Fault Toler-
ant Systems (FTRTFT’02), volume 2469 of Lecture Notes in
Computer Science, pages 71–80. IFIP, Springer-Verlag, Sept.
2002.
[8] Tim Lindholm and Frank Yellin. The JAVA virtual machine
speciﬁcation. Addison Wesley, 1996.
[9] G. Morrisett, K. Crary, N. Glew, D. Grossman, R. Samuels,
F. Smith, D. Walker, S. Weirich, and S. Zdancewic. TALx86:
A realistic typed assembly language. In Proc. Workshop on
Compiler Support for System Software, pages 25–35. ACM
SIGPLAN, May 1999.
[10] G. Morrisett, K. Crary, N. Glew, and D. Walker. Stack-
based typed assembly language.
In Xavier Leroy and At-
sushi Ohori, editors, Proc. Workshop on Types in Compila-
tion, volume 1473 of Lecture Notes in Computer Science,
pages 28–52. Springer-Verlag, March 1998.
[11] G. Morrisett, D. Tarditi, P. Cheng, C. Stone, R. Harper, and
P. Lee. The TIL/ML compiler: Performance and safety
through types. In 1996 Workshop on Compiler Support for
Systems Software, 1996.
[12] Greg Morrisett, David Walker, Karl Crary, and Neal Glew.
From System F to typed assembly language. In 25th ACM
SIGPLAN/SIGSIGACT Symposium on Principles of Pro-
gramming Languages, pages 85–97, San Diego California,
USA, January 1998.
[13] George C. Necula. Proof-carrying code.
In Proc. 24th
Symp. Principles of Programming Languages, pages 106–
119. ACM SIGPLAN/SIGACT, January 1997.
[14] George C. Necula. Compiling with proofs. PhD thesis,
Carnegie Mellon University, September 1998.
[15] George C. Necula and Peter Lee. Safe kernel extensions
In Proc. 2nd Symp. Operating
without run-time checking.
System Design and Implementation. ACM, October 1996.
[16] George C. Necula and Peter Lee. The design and imple-
mentation of a certifying compiler. In Proc. Conf. Program-
ming Language Design and Implementation, pages 333–344.
ACM SIGPLAN, 1998.
[17] George C. Necula and Peter Lee. Efﬁcient representation and
validation of proofs. In Proc. 13th Symp. Logic in Computer
Science, pages 93–104. IEEE, June 1998.
[18] George C. Necula and Peter Lee. Safe, untrusted agents
In Giovanni Vigna, edi-
using using proof-carrying code.
tor, Special Issue on Mobile Agent Security, volume 1419
of Lect. Notes in Computer Science, pages 61–91. Springer-
Verlag, June 1998.
[19] Robert O’Callahan. A simple, comprehensive type system
for Java bytecode subroutines. In Proc. 26th Symp. Princi-
ples of Programming Languages, pages 70–78. ACM SIG-
PLAN/SIGACT, January 1999.
[20] Fred B. Schneider. Towards fault-tolerant and secure agen-
try. In Proc. 11th Int. Workshop WDAG ’97, volume 1320 of
Lecture Notes in Computer Science, pages 1–14. ACM SIG-
PLAN, Springer-Verlag, September 1997.
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
[21] Fred B. Schneider. Enforceable security policies. Technical
Report TR98-1664, Computer Science Department, Cornell
University, January 1998.
[22] Fred B. Schneider, editor. Trust in Cyberspace. Committee
on Information Systems Trustworthiness, Computer Science
and Telecommunications Board, National Research Council.
National Academy Press, 1999.
[23] D. Tarditi, G. Morrisett, P. Cheng, C. Stone, R. Harper, and
P. Lee. TIL: A type-directed optimizing compiler for ML. In
Conf. Programming Language Design and Implementation.
ACM SIGPLAN, 1996.
[24] R. Wahbe, S. Lucco, T. E. Anderson, and S. L Graham. Efﬁ-
cient software-based fault isolation. In Proc. 14th Symp. Op-
erating System Principles, pages 203–216. ACM, December
1993.
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE