dental (e.g., a user just downloaded 10 GB of multime-
dia ﬁles). When the system reaches predetermined thresh-
olds of unallocated resources and allocation rate, warn-
ing the administrator is appropriate even in non-intrusion
situations—attention is likely to be necessary soon. A stor-
age IDS could similarly warn the administrator when stor-
age activity exceeds a threshold for too long, which may
be a DoS attack or just an indication that the server needs
to be upgraded.
Although speciﬁc rules can spot expected intruder actions,
more general rules may allow larger classes of suspicious
activity to be noticed. For example, some attribute mod-
iﬁcations, like enabling “set UID” bits or reducing the
permissions needed for access, may indicate foul play.
Additionally, many applications access storage in a reg-
ular manner. As two examples: word processors often use
temporary and backup ﬁles in speciﬁc ways, and UNIX
password management involves a pair of inter-related ﬁles
(/etc/passwd and /etc/shadow). The corresponding
access patterns seen at the storage device will be a reﬂec-
tion of the application’s requests. This presents an oppor-
tunity for anomaly detection based on how a given ﬁle is
normally accessed. This could be done in a manner similar
to learning common patterns of system calls [10] or start-
ing with rules regarding the expected behavior of individ-
ual applications [19]. Deviation from the expected pattern
could indicate an intruder attempting to subvert the normal
method of accessing a given ﬁle. Of course, the downside
is an increase (likely substantial) in the number of false
alarms. Our focus to date has been on explicit detection
rules, but anomaly detection within storage access patterns
is an interesting topic for future research.
2.3.3 Content integrity
A third category of warning signs consists of changes that
violate internal consistency rules of speciﬁc ﬁles. This cat-
egory builds on the previous examples by understanding
the application-speciﬁc semantics of particularly important
stored data. Of course, to verify content integrity, the de-
vice must understand the format of a ﬁle. Further, while
simple formats may be veriﬁed in the context of the write
operation, ﬁle formats may be arbitrarily complex and veri-
ﬁcation may require access to additional data blocks (other
than those currently being written). This creates a perfor-
mance vs. security trade-off made by deciding which ﬁles
to verify and how often to verify them. In practice, there
are likely to be few critical ﬁles for which content integrity
veriﬁcation is utilized.
As a concrete example, consider a UNIX system pass-
word ﬁle (/etc/passwd), which consists of a set of well-
deﬁned records. Records are delimited by a line-break, and
each record consists of seven colon-separated ﬁelds. Fur-
ther, each of the ﬁelds has a speciﬁc meaning, some of
which are expected to conform to rules of practice. For
example, the seventh ﬁeld speciﬁes the “shell” program to
be launched when a user logs in, and (in Linux) the ﬁle
/etc/shells lists the legal options. During the “Capture
the Flag” information warfare game at the 2002 DEF CON
conference [21], one tactic used was to change the root
shell on compromised systems to /sbin/halt; once a tar-
geted system’s administrator noted the intrusion and at-
tempted to become root on the machine (the common ini-
tial reaction), considerable down-time and administrative
effort was needed to restore the system to operation. A
storage IDS can monitor changes to /etc/passwd and
verify that they conform to a set of basic integrity rules: 7-
ﬁeld records, non-empty password ﬁeld, legal default shell,
legal home directory, non-overlapping user IDs, etc. The
attack described above, among others, could be caught im-
mediately.
2.3.4 Suspicious content
A fourth category of warning signs is the appearance of
suspicious content. The most obvious suspicious content
is a known virus or rootkit, detectable via its signature.
Several high-end storage servers (e.g., from EMC [24] and
Network Appliance [28]) now include support for internal
virus scanning. By executing the scans within the storage
server, viruses cannot disable the scanners even after in-
fecting clients.
Two other examples of suspicious content are large num-
bers of “hidden” ﬁles or empty ﬁles. Hidden ﬁles have
names that are not displayed by normal directory listing
interfaces [7, p. 217], and their use may indicate that an
intruder is using the system as a storage repository, per-
haps for illicit or pirated content. A large number of empty
ﬁles or directories may indicate an attempt to exploit a race
condition [2, 30] by inducing a time-consuming directory
listing, search, or removal.
2.4 Limitations, costs, and weaknesses
Although storage-based intrusion detection contributes to
security efforts, of course it is not a silver bullet.
Like any IDS, a storage IDS will produce some false posi-
tives. With very speciﬁc rules, such as “watch these 100
ﬁles for any modiﬁcation,” false positives should be in-
frequent; they will occur only when there are legitimate
140
12th USENIX Security Symposium 
USENIX Association
changes to a watched ﬁle, which should be easily veriﬁed
if updates involve a careful procedure. The issue of false
alarms grows progressively more problematic as the rules
get less exact (e.g., the time reversal or resource exhaus-
tion examples). The far end of the spectrum from speciﬁc
rules is general anomaly detection.
Also like any IDS, a storage IDS will fail to spot some in-
trusions. Fundamentally, a storage IDS cannot notice intru-
sions whose actions do not cause odd storage behavior. For
example, three of the eighteen intrusion tools examined in
the next section modify the OS but change no ﬁles. Also,
an intruder may manipulate storage in unwatched ways.
Using network-based and host-based IDSs together with a
storage IDS can increase the odds of spotting various forms
of intrusion.
Intrusion detection, as an aspect of information warfare,
is by nature a “game” of escalation. As soon as one side
takes away an avenue of attack, the other starts looking
for the next. Since storage-based intrusion detection eas-
ily sees several common intruder activities, crafty intruders
will change tactics. For example, an intruder can make any
number of changes to the host’s memory, so long as those
modiﬁcations do not propagate to storage. A reboot, how-
ever, will reset the system and remove the intrusion, which
argues for proactive restart [3, 16, 43]. To counter this, at-
tackers must have their changes re-established automati-
cally after a reboot, such as by manipulating the various
boot-time (e.g., rc.local in UNIX-like systems) or peri-
odic (e.g., cron in UNIX-like systems) programs. Doing
so exposes them to the storage IDS, creating a traditional
intrusion detection game of cat and mouse.
As a practical consideration, storage IDSs embedded
within individual components of decentralized storage sys-
tems are unlikely to be effective. For example, a disk array
controller is a ﬁne place for storage-based intrusion detec-
tion, but individual disks behind software striping are not.
Each of the disks has only part of the ﬁle system’s state,
making it difﬁcult to check non-trivial rules without adding
new inter-device communication paths.
Finally, storage-based intrusion detection is not free.
Checking rules comes with some cost in processing and
memory resources, and more rules require more resources.
In conﬁguring a storage IDS, one must balance detection
efforts with performance costs for the particular operating
environment.
3 Case Studies
This section explores how well a storage IDS might fare
in the face of actual compromises. To do so, we examined
eighteen intrusion tools (Table 1) designed to be run on
compromised systems. All were downloaded from public
websites, most of them from Packet Storm [26].
Most of the actions taken by these tools fall into two cat-
egories. Actions in the ﬁrst category involve hiding evi-
dence of the intrusion and the rootkit’s activity. The second
provides a mechanism for reentry into a system. Twelve of
the tools operate by running various binaries on the host
system and overwriting existing binaries to continue gain-
ing control. The other six insert code into the operating
system kernel.
For the analysis in this section, we focus on a subset
of the rules supported by our prototype storage-based
IDS described in Section 5. Speciﬁcally, we include
the ﬁle/directory modiﬁcation (Tripwire-like) rules, the
append-only logﬁle rule, and the hidden ﬁlename rules. We
do not consider any “suspicious content” rules, which may
or may not catch a rootkit depending on whether its partic-
ular signature is known.1 In these eighteen toolkits, we did
not ﬁnd any instances of resource exhaustion attacks or of
reverting inode times.
3.1 Detection results
Of the eighteen toolkits tested, storage IDS rules would
immediately detect ﬁfteen based on their storage modiﬁ-
cations. Most would trigger numerous alerts, highlighting
their presence. The other three make no changes to per-
sistent storage. However, they are removed if the system
reboots; all three modify the kernel, but would have to be
combined with system ﬁle changes to be re-inserted upon
reboot.
Non-append changes to the system audit log. Seven of
the eighteen toolkits scrub evidence of system compro-
mise from the audit log. All of them do so by selectively
overwriting entries related to their intrusion into the sys-
tem, rather than by truncating the logﬁle entirely. All cause
alerts to be generated in our prototype.
System ﬁle modiﬁcation. Fifteen of the eighteen toolkits
modify a number of watched system ﬁles (ranging from
1 to 20). Each such modiﬁcation generates an alert. Al-
though three of the rootkits replace the ﬁles with bina-
ries that match the size and CRC checksum of the previ-
ous ﬁles, they do not foil cryptographically-strong hashes.
Thus, Tripwire-like systems would be able to catch them
as well, though the evasion mechanism described in Sec-
tion 3.2 defeats Tripwire.
Many of the ﬁles modiﬁed are common utilities for sys-
tem administration, found in /bin, /sbin, and /usr/bin
on a UNIX machine. They are modiﬁed to hide the pres-
ence and activity of the intruder. Common changes include
1An interesting note is that rootkit developers reuse code: four of the
rootkits use the same audit log scrubbing program (sauber), and another
three use a different program (zap2).
USENIX Association
12th USENIX Security Symposium 
141
Name
Description
Ramen
1ion
FK 0.4
Taskigt
SK 1.3a
Darkside 0.2.3
Knark 0.59
Adore
lrk5
Sun rootkit
FreeBSD Rootkit 2
t0rn
Advanced Rootkit
ASMD
Dica
Flea
Ohara
TK 6.66
Linux worm
Linux worm
Linux LKM rootkit and trojan ssh
Linux LKM rootkit
Linux kernel rootkit via /dev/kmem
FreeBSD LKM rootkit
Linux LKM rootkit
Linux LKM rootkit
User level rootkit from source
SunOS rootkit with trojan rlogin
User level FreeBSD rootkit
Linux user level rootkit
Linux user level rootkit
Rootkit w/SUID binary trojan
Linux user level rootkit
Linux user level rootkit
Rootkit w/PAM trojan
Linux user level rootkit
Syscall
redir.
Log
scrub
Hidden
dirs
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
Watched
ﬁles
2
10
1
1
1
20
1
15
20
10
1
9
20
4
10
Total
alerts
3
10
1
1
-
-
2
-
22
1
17
22
11
2
11
22
6
12
Table 1: Visible actions of several intruder toolkits. For each of the tools, the table shows which of the following actions are performed: redirecting
system calls, scrubbing the system log ﬁles, and creating hidden directories. It also shows how many of the ﬁles watched by our rule set are modiﬁed
by a given tool. The ﬁnal column shows the total number of alerts generated by a given tool.
modifying ps to not show an intruder’s processes, ls to not
show an intruder’s ﬁles, and netstat to not show an in-
truder’s open network ports and connections. Similar mod-
iﬁcations are often made to grep, find, du, and pstree.
The other common reason for modifying system binaries
is to create backdoors for system reentry. Most commonly,
the target is telnetd or sshd, although one rootkit added
a backdoored PAM module [33] as well. Methods for using
the backdoor vary and do not impact our analysis.
Hidden ﬁle or directory names. Twelve of the rootkits
make a hard-coded effort to hide their non-executable and
working ﬁles (i.e., the ﬁles that are not replacing existing
ﬁles). Ten of the kits use directories starting in a ‘.’ to hide
from default ls listings. Three of these generate alerts by
trying to make a hidden directory look like the reserved ‘.’
or ‘..’ directories by appending one or more spaces (‘. ’ or
‘.. ’). This also makes the path harder to type if a system
administrator does not know the number of spaces.
3.2 Kernel-inserted evasion techniques
Six of the eighteen toolkits modiﬁed the running operating
system kernel. Five of these six “kernel rootkits” include
loadable kernel modules (LKMs), and the other inserts it-
self directly into kernel memory by use of the /dev/kmem
interface. Most of the kernel modiﬁcations allow intrud-
ers to hide as well as reenter the system, similarly to the