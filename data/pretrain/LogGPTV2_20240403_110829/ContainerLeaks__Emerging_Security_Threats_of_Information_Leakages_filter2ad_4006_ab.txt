Kernel Data 
Space
Non-namespaced data
Namespaced data
Co-residence 
Veriﬁcation
Performance 
Inference
Synergistic 
Power Attack
Fig. 1: The framework for information leakage detection and
cloud inspection.
align and reorder the ﬁles based on their ﬁle paths and then
conduct pair-wise differential analysis on the contents of the
same ﬁle between these two contexts. If the system resources
accessed from a speciﬁc pseudo ﬁle has not been namespaced
in the Linux kernel, the host and container reach the same piece
of kernel data (as the case of  in Figure 1). Otherwise, if
properly namespaced, the container can retrieve its own private
and customized kernel data (as the case of  in Figure 1).
Using this cross-validation tool, we can quickly identify the
pseudo ﬁles (and their internal kernel data structures) that may
expose system-wide host information to the container.
B. Leakage Channel Analysis
We list all pseudo ﬁles that may leak host information in
Table I. Those leakage channels contain different aspects of host
information. Container users can retrieve kernel data structures
(e.g., /proc/modules shows the list of loaded modules), kernel
events (e.g., /proc/interrupts shows the number of interrupts
per IRQ), and hardware information (e.g., /proc/cpuinfo and
/proc/meminfo show the speciﬁcation of CPU and memory,
respectively). In addition, container users are able to retrieve
performance statistics data through some channels. For example,
containers can obtain hardware sensor data (if these sensors are
available in the physical machine), such as power consumption
for each package, cores, and DRAM through the RAPL sysfs
interface, and the temperature for each core through the
Digital Temperature Sensor (DTS) sysfs interface. Moreover,
the usage of processors, memory, and disk I/O is also exposed
to containers. While leaking such information seems harmless
at ﬁrst glance, it could be exploited by malicious adversaries to
launch attacks. More detailed discussion is given in Section IV.
We further investigate the root causes of these information
leakages by inspecting the kernel code (in the Linux kernel
version 4.7). Generally, the leakage problems are caused by the
incomplete implementation of namespaces in the kernel. To be
more speciﬁc, we summarize the two main causes as follows:
(1) Context checks are missing for existing namespaces, and (2)
some Linux subsystems are not (fully) namespaced. We give
two case studies on net prio.ifpriomap and RAPL in containers
to reveal the origins of leakages.
1) Case study I — net prio.ifpriomap: The pseudo ﬁle
net prio.ifpriomap (under /sys/fs/cgroup/net prio) contains
a map of the priorities assigned to trafﬁc starting from
processes in a cgroup and leaving the system on various
interfaces. The data format is in the form of [ifname pri-
ority]. We ﬁnd that the kernel handler function hooked at
net prio.ifpriomap is not aware of the NET namespace, and
thus it discloses all network interfaces on the physical machine
to the containerized applications. To be more speciﬁc, the read
operation of net prio.ifpriomap is handled by the function
read_priomap. Tracing from this function, we ﬁnd that it
invokes for_each_netdev_rcu and sets the ﬁrst parameter
as the address of init_net. It iterates all network devices of
the host, regardless of the NET namespace. Thus, from the view
of a container, it can read the names of all network devices of
the host.
2) Case study II — RAPL in containers: RAPL was recently
introduced by Intel for setting power limits for processor pack-
ages and DRAM of a single server, which can respond at the
millisecond level [19]. In the container cloud, the sysfs interface
of RAPL, which locates under /sys/class/powercap/intel-rapl, is
accessible to containers. Therefore, it is possible for container
tenants to obtain the system-wide power status of the host,
including the core, DRAM, and package, through this sysfs
interface. For example, container users can read the current
energy counter in micro joules from the pseudo ﬁle energy uj.
The function handler of energy uj in the Intel RAPL Linux
driver is get_energy_counter. This function retrieves the
raw energy data from the RAPL MSR. As namespace has
not been implemented for the power data, the energy_raw
pointer refers to the host’s energy consumption data.
We further investigate the information leakage problems on
container cloud services that adopt the Docker/LXC container
engine. We choose ﬁve commercial public multi-tenancy
container cloud services for leakage checking and present the
results in Table I. We anonymize the names (CCi stands for
ith Container Cloud) of these container cloud services before
the cloud providers patch the channels. The (cid:2) indicates that the
channel exists in the cloud, while the (cid:3) indicates the opposite.
We ﬁnd that most of the leakage channels on local machines
are also available in the container cloud services. Some of
them are unavailable due to the lack of support for speciﬁc
hardware (e.g., Intel processor before Sandy Bridge or AMD
processors that do not support RAPL). For cloud CC5, we ﬁnd
that the information of some channels is different from our local
testbed, which means that the cloud vendor has customized
some additional restrictions. For example, only the information
about the cores and memory belonging to a tenant is available.
However, those channels partially leak the host information
and could still be exploited by advanced attackers. We mark
them as (cid:4)(cid:3).
C. Inference of Co-resident Container
We further look in depth into speciﬁc cases to see whether
they could be exploited to detect co-resident containers.
1) Co-residence problems in cloud settings: Co-residence
is a well-known research problem in cloud security. In order
to extract a victim’s information, adversaries tend to move
malicious instances to the same physical host with the victim.
Zhang et al. have shown that it is possible for an attacker
to hijack user accounts [47] and extract private keys [46]
with co-resident instances. In addition, the cost of achieving
co-residence is rather low [36]. Co-residence still remains a
240
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:19:41 UTC from IEEE Xplore.  Restrictions apply. 
TABLE I: LEAKAGE CHANNELS IN COMMERCIAL CONTAINER CLOUD SERVICES.
Potential Vulnerability
Container Cloud Services1
Co-re
DoS
Info leak CC1 CC2 CC3 CC4 CC5
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:3)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:3)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:3)
(cid:2)
(cid:2)
(cid:2)
(cid:3)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:3)
(cid:3)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:3)
(cid:3)
(cid:3)
(cid:4)(cid:3)
(cid:4)(cid:3)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:4)(cid:3)
(cid:2)
(cid:4)(cid:3)
(cid:3)
(cid:4)(cid:3)
(cid:2)
(cid:3)
(cid:4)(cid:3)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:3)
(cid:3)
(cid:3)
Leakage Channels
Leakage Information
/proc/locks
/proc/zoneinfo
/proc/modules
/proc/timer_list
/proc/sched_debug
/proc/softirqs
/proc/uptime
/proc/version
/proc/stat
/proc/meminfo
/proc/loadavg
/proc/interrupts
/proc/cpuinfo
/proc/schedstat
/proc/sys/fs/*
/proc/sys/kernel/random/*
/proc/sys/kernel/sched_domain/*
/proc/fs/ext4/*
/sys/fs/cgroup/net_prio/*
/sys/devices/*
/sys/class/*
Files locked by the kernel
Physical RAM information
Loaded kernel modules information
Conﬁgured clocks and timers
Task scheduler behavior
Number of invoked softirq handler
Up and idle time
Kernel, gcc, distribution version
Kernel activities
Memory information
CPU and IO utilization over time
Number of interrupts per IRQ
CPU information
Schedule statistics
File system information
Random number generation info
Schedule domain info
Ext4 ﬁle system info
Priorities assigned to trafﬁc
System device information
System device information
problem in existing clouds, due to the intention of consolidating
server resources and reducing cost. Traditional methods to verify
co-residence are based on cache [44] or memory-based leakage
channels [38]. The accuracy of those methods may downgrade
due to the high noise in cloud settings.
2) Approaches and results of checking co-resident contain-
ers: Since containers can read the host information through the
leakage channels we discovered, we tend to measure whether
some channels can be used for checking container co-residence.
We deﬁne three metrics, namely uniqueness (U), variation (V),
and manipulation (M) to quantitatively assess each channel’s
capability of inferring co-residence.
The metric U indicates whether this channel bestows
characteristic data that can uniquely identify a host machine.
It is the most important and accurate factor for determining
whether two containers locate on the same host. We have found
17 leakage channels (ranked top 17 in Table II) that satisfy
this metric. Generally we can classify these channels into three
groups:
1) Channels containing unique static identiﬁers. For exam-
ple, boot id under /proc/sys/kernel/random is a random string
generated at boot time and is unique for each running kernel.
If two containers can read the same boot id, this is a clear
sign that they are running on the same host kernel. The data
for channels in this group are both static and unique.
2) Channels
into which container
tenants can dy-
namically implant unique signatures. For example, from
/proc/sched debug, container users can retrieve all active
process information of the host through this interface. A tenant
can launch a process with a uniquely crafted task name inside
the container. From the other containers, they can verify co-
residence by searching this task name in their own sched debug.
Similar situations apply to timer list and locks.
3) Channels containing unique dynamic identiﬁers. For
example, /proc/uptime has two data ﬁelds: system up time and
system idle time in seconds since booting. They are accumulated
1The most recent check on the leakage channels was made on November
28, 2016.
241
(cid:2)
(cid:2)
(cid:3)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:3)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:3)
(cid:2)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:2)
(cid:3)
(cid:3)
(cid:2)
(cid:2)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)