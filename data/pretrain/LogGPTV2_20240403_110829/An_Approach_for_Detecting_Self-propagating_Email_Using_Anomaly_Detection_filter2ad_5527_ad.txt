4a
4b
4b
4b
4b
4b.v2
detection
3.7 min
36.4 min
3.0 min
2.2 min
3.3 min
3.1 min
22.7 min
trafﬁc consumed by virus
< 5 percent
< 5 percent
< 5 percent
< 5 percent
< 5 percent
< 5 percent
< 5 percent
Fig. 7. Virus Detection
around 20 minutes after its introduction. Thus, detection took only two minutes after
the virus became active. In the case of virus 4a, the orchestrator was initially able to
contain the virus, and hence no alarms were reported by the anomaly detector. However,
after about 30 minutes of containment, the orchestrator lost control of the virus, which
subsequently took over the system. The detection occurred a few minutes after the point
when the virus got away.
4.3 False Alarm Analysis
As for Experiment I, false alarm rates were measured in two ways:
– Criteria 1: Count even a single alarm as a false alarm: Using this criteria, there were
a total of 18 false alarms across 6 runs, or a rate of about 0.3 false alarms per hour.
(Compare this to the 0.38 false alarms per hour obtained using this same criteria in
Experiment I.)
– Criteria 2: Set a threshold via experimentation. In this case, the threshold was set so
that not only do we mask false alerts, but also true alarms that are not sufﬁciently
severe to warrant a system shutdown. (Recall that the only response used in the
experiment was to shutdown the mail server when the anomaly detector produced
68
A. Gupta and R. Sekar
an alarm.) For this reason, the threshold was much higher than in Experiment I.
Speciﬁcally, we identiﬁed a threshold of 50 or more alarms in a period of 256
seconds. Using this criteria, no false alarms were observed. (In fact, the maximum
number of alarms produced within a period of 256 seconds in any of these six runs
was 14, which is well below the 50 threshold.)
We note that in the detection results reported in Figure 7, Criteria 2 was used. Thus,
those detection results were obtained with zero false alarm rate.
4.4 Runtime Performance and Memory Usage
The anomaly detector performance and memory usage in this experiment was similar to
that reported for 400 clients in experiment I.
5 Related Work
Self-propagating malicious programs have been analyzed ever since they came into
existence starting with the Morris worm [2]. Along with the growth of the Internet, the
threat of worms spreading into computer networks has also increased. To understand and
predict the propagation of such worms has become an increasingly important research
topic. Propagation analysis and detection has also been carried out for more recent Code
Red [12] and Melissa [1] viruses, where the email is used as the vehicle of propagation
for these malicious executables.
Incidents of virus propagation through the cyber realm have been viewed and mod-
eled using epidemiological modeling, mapping the Internet to mathematical models of
ecological systems [15]. Models have been developed to accurately predict the prop-
agation of worms and viruses through the networks. One such example is a variation
of Kermack-Mckendrick model, used to predict the propagation of the Code Red virus
through the Internet [39]. At IBM, Kephart and White have developed systems for de-
tection using these models [7],[8] [9]. In addition to borrowing ideas from mathematical
epidemiology, the model has been extended by incorporating network topological ef-
fects, using power-law relationships [20] which try to give some structure to the apparent
randomness of the Internet. [10] studies the propagation of viruses when a subset of the
hosts are immune to the virus. [18] studies the problem of network availability in the face
of viral attacks. The focus of all these efforts were to study the propagation of viruses,
whereas the focus of this paper is the development of an effective detection technique.
Anomaly detection techniques have long been used for intrusion detection [13, 27,
25, 32–34, 16, 36]. The approach developed in this paper is closely related to [36]. In
both approaches, a protocol state machine speciﬁcation forms the basis for detection.
This state machine is used to transform events (such as network packets, or sending
or delivery of emails) into frequency distributions that characterize normal behavior.
The training and detection phases are robust, and can operate without any supervision.
These factors contrast with most other anomaly detection approaches, especially at the
network level, where considerable knowledge and ingenuity was needed to identify the
set of “features” to be included in normal behavior characterization. Moreover, many
of these techniques required expert supervision to make sure that the normal behavior
characterization learned by the technique was indeed appropriate.
An Approach for Detecting Self-propagating Email Using Anomaly Detection
69
The Malicious Email Tracking (MET) system [17] was developed to track the ﬂow
of malicious emails such as self-replicating viruses through a network. It was designed
as a system to track ﬂow of malicious email trafﬁc on wide area network without hav-
ing to sample most of the emails exchanged in the network. However, its techniques
for detecting malicious emails, such as the use of MD5 sums for identiﬁcation of the
propagation of the same virus, can be defeated by polymorphic viruses such as those
considered in this paper.
While MET is focused speciﬁcally on emails, the earlier Graph-based intrusion
detection system (GrIDS) [31] work was focused on the more general problem of large-
scale automated attacks that propagate over the network. GrIDS is based on assembling
the activities on different network nodes into activity graphs that show the spread of
attacks through a network. It can also support policy-based detection of attacks by
detecting policy violations in the activity graph.
[6] uses a data mining approach to detect malicious executables embedded within
emails. Short sequences of machine instructions are the features used in this approach. A
Naive Bayes classiﬁer, trained on a set of malicious and a set of benign executables, was
used to detect whether an attachment contained malicious code. This approach assumes
that there are similarities among the binary code of malicious executables. While this is
shown to be true for viruses known today, it is easy enough to write stealthy viruses that
can escape detection by this technique.
The Email Mining Toolkit (EMT) [35] work complements MET in that it uses data
mining to synthesize the behavior proﬁles of users that is used by MET to detect ma-
licious email. EMT models “normal behavior” of each email user in terms of several
characteristics such as the identities of the other users they communicate with, and
the frequencies with which they communicate with these users. It can detect not only
viruses, but also changes in communication patterns that may result due to misuse or
other malicious user behavior. However, for the purpose of virus detection, this technique
is likely to have higher latency than the technique proposed in this paper. This is because
the sending of a single message, or even a few virus messages, cannot be considered a
signiﬁcant departure from normal communication pattern without increasing the false
alarm rate.
6 Conclusions and Future Work
In this paper, we presented a new technique for detecting self-propagating email viruses
using statistical anomaly detection. Our results suggest that the kinds of viruses preva-
lent today can be detected before a signiﬁcant fraction of the network is infected. Our
approach degrades gracefully when facing more stealthy viruses that use a combination
of low propagation factor, high incubation period and randomization. We note that an
email virus writer has to be careful in designing a stealthy virus: if it uses too low a
propagation factor, then it may “die” in the presence of hosts that are immune to the
virus (e.g., Microsoft Outlook viruses sent to Netscape or Lotus Notes users). A high
incubation period also delays the spread of the virus, which provides more opportunities
for a vigilant user or system administrator to notice the virus. Thus it is likely that very
stealthy viruses are not very stable.
When we began this work, we assumed that an anomaly detection technique such
as ours will have a signiﬁcant latency in detection, by which time most of the network
70
A. Gupta and R. Sekar
may be infected. While this assumption turned out to be true for the most stealthy of the
viruses used in our experiments, our results suggest that for a majority of the viruses, it
is potentially feasible to detect attacks when only a minority of the network is infected.
Note that with early detection, the costs associated with cleaning up such viruses can be
reduced.
While the results presented in this paper are promising, their main weakness is that
they are all based on simulation. Real systems often display behaviors that are more
complex and variable than those exhibited in simulations. This factor can artiﬁcially
inﬂate the effectiveness of anomaly detection systems during simulations. In order to
really assess the effectiveness of the approach, it is necessary to evaluate it using realistic
email trafﬁc. Our ongoing work develops techniques where email trafﬁc is no longer
simulated, but is taken from mail server logs. The virus models will continue to be
simulated. The trafﬁc presented to the anomaly detector is obtained by superimposing
the background trafﬁc from the logs with simulated virus email trafﬁc.
A second difﬁculty in extrapolating the simulation results is that on real systems,
email trafﬁc crosses organization boundaries frequently. In particular, a virus may prop-
agate from one user to any other user on the Internet, and not just on the intranet of
the user’s organization. At the same time, it is not realistic to assume that our anomaly
detector can be deployed Internet-wide. Thus, a question arises as to how well an Internet-
wide virus propagation can be detected by an anomaly detector observing the behavior
of email on an intranet. This is another question that needs to be addressed in future
research.
References
1. CERT/CC Co-ordination Center Advisories, Carnegie Mellon, 1988-1998,
http://www.cert.org/advisories/index.html.
2. Eugene H. Spafford, The Internet worm program: an analysis, Tech. Report CSD-TR-823,
Department of Computer Science, Purdue University, 1988.
3. Terran Lane, Carla E. Brodley, Temporal Sequence Learning and Data Reduction for Anomaly
Detection, ACM Transactions on Information and System Security, 1998.
4. T. Lunt, A. Tamaru, F. Gilham, R. Jagannathan, P. Neumann, H. Javitz, A. Valdes, T. Garvey,
A real-time intrusion detection expert system (IDES) - ﬁnal technical report. Technical report,
Computer Science Laboratory, SRI International, Menlo Park, California, February 1992.
5. T. Heberlein, G. Dias, K. Levitt, B. Mukherjee, J. Wood, D. Wobler, A Network Security
Monitor , Proceedings IEEE Symposium on Research in Computer Security and Privacy,
1990.
6. Matthew G. Schultz, Eleazar Eskin, and Salvatore J. Stolfo. “Malicious Email Filter - A UNIX
Mail Filter that Detects Malicious Windows Executables.” Proceedings of USENIX Annual
Technical Conference, 2001.
7. J.O. Kephart, S.R. White, Directed-graph Epidemiological Models of Computer Viruses, IBM
T.J. Watson Research Center, IEEE Computer Society Symposium on Research in Security
and Privacy, pp. 343-359, 1991.
8. J.O. Kephart, David M. Chess, S.R. White, Computers and Epidemiology, IBM T.J. Watson
Research Center, IEEE Spectrum, May 1993.
An Approach for Detecting Self-propagating Email Using Anomaly Detection
71
9. J.O. Kephart, G.B. Sorkia, M. Swimmer, S.R. White, Blueprint for a Computer Immune
System. Technical report, IBM T.J. Watson Research Center, Yorktown Heights, New York,
1997.
10. Chenxi Wang, John C. Knight, Matthew C. Elder, On Computer Viral Infection and the Effect
of Immunization, Department of Computer Science, University of Virginia, ACSAC 2000.
11. Klaus Julisch, Mining Alarm Clusters to Improve Alarm Handling Efﬁciency, IBM Research,
Zurich Research Laboratory, ACSAC 2001.
12. Stuart Staniford, Analysis of spread of July infestation of the Code Red worm, UC Davis,
http://www.silicondefense.com/cr/july.html.
13. D.Anderson, T. Lunt, H. Javitz,A. Tamaru, andA.Valdes, Next-generation Intrusion Detection
Expert System (NIDES): A Summary, SRI-CSL-95-07, SRI International, 1995.
14. S. Staniford, V. Paxson, N. Weaver, How to Own the Internet in Your Spare Time, Usenix
Security Symposium, 2002.
15. Jane Jorgensen, P. Rossignol, M. Takikawa, D. Upper, Cyber Ecology: Looking to Ecology
for Insights into Information Assurance, DISCEX 2001. Proceedings , Volume 2 , 2001.
16. Carol Taylor, Jim Alves-Foss, NATE, Network Analysis of Anomalous Trafﬁc Events, A
Low-cost Approach, New Security Paradigms Workshop, 2001.
17. Manasi Bhattacharyya, Shlomo Hershkop, Eleazar Eskin, and Salvatore J. Stolfo, MET: An
Experimental System for Malicious Email Tracking, Workshop on New Security Paradigms,
2002 (NSPW-2002).
18. Meng-Jang Lin, Aleta M. Ricciardi, Keith Marzullo, A New Model for Availability in the
Face of Self-Propagating Attacks, Workshop on New Security Paradigms, 1998.
19. Wenke Lee, Salvatore J. Stolfo, Kui W. Mok,A Data Mining Framework for Building Intrusion
Detection Models, IEEE Symposium on Security and Privacy, 1999.
20. M. Faloutsos, P. Faloutsos, C. Faloutsos, On Power-Law Relationships of the Internet, ACM
SIGCOMM, 1999.
21. M.G. Schultz, E.Eskin, E. Zadok, Data Mining Methods for Detection of New Malicious
Executables, IEEE Symposium on Security and Privacy, May 2001.
22. Ian Whalley, Bill Arnold, David Chess, John Morar, Alla Segal, Morton Swimmer, An En-
vironment for Controlled Worm Replication and Analysis, IBM TJ Watson Research Center,
Sept 2000.
23. L. Heberlein et al,A Network Security Monitor, Symposium on Research Security and Privacy,
1990.
24. J. Hochberg et al, NADIR:AnAutomated System for Detecting Network Intrusion and Misuse,
Computers and Security 12(3), May 1993.
25. W. Lee and S. Stolfo, Data Mining Approaches for Intrusion Detection, USENIX Security
Symposium, 1998.
26. V. Paxson, Bro: A System for Detecting Network Intruders in Real-Time, USENIX Security
Symposium, 1998.
27. P. Porras and P. Neumann, EMERALD: Event Monitoring Enabled Responses to Anomalous
Live Disturbances, National Information Systems Security Conference, 1997.
28. Inc. Network Flight Recorder. Network ﬂight recorder, http://www.nfr.com, 1997.
29. G. Vigna and R. Kemmerer, NetSTAT: A Network-based Intrusion Detection Approach, Com-
puter Security Applications Conference, 1998.
30. G. Vigna, S.T. Eckmann, and R.A. Kemmerer, The STAT Tool Suite, in Proceedings of DIS-
CEX 2000, IEEE Press, 2000.
72
A. Gupta and R. Sekar
31. Staniford-Chen, S. et al, GrIDS: A Graph-Based Intrusion Detection System for Large Net-
works. Proceedings of the 19th National Information Systems Security Conference, Balti-
more, 1996.
32. S. Forrest, S. Hofmeyr and A. Somayaji, Computer Immunology, Comm. of ACM 40(10),
1997.
33. A. Ghosh, A. Schwartzbard and M. Schatz, Learning Program Behavior Proﬁles for Intrusion
Detection, 1st USENIX Workshop on Intrusion Detection and Network Monitoring, 1999.
34. R. Sekar, M. Bendre, P. Bollineni and D. Dhurjati, A Fast Automaton-Based Approach for
Learning Program Behaviors, IEEE Symposium on Security and Privacy, 2001.
35. Salvatore J. Stolfo, Shlomo Hershkop, Ke Wang, Olivier Nimeskern, Chia-Wei Hu, Behav-
ior Proﬁling of Email, submitted to 1st NSF/NIJ Symposium on Intelligence and Security
Informatics(ISI 2003).
36. R. Sekar, A. Gupta, J. Frullo, T. Shanbhag, A. Tiwari, H. Yang, S. Zhou, Speciﬁcation-based
anomaly detection: a new approach for detecting network intrusions, ACM Computer and
Communication Security Conference, 2002.
37. R. Sekar, Y. Guang, T. Shanbhag and S. Verma, A High-Performance Network Intrusion
Detection System, ACM Computer and Communication Security Conference, 1999.
38. R. Sekar and P. Uppuluri, Synthesizing Fast Intrusion Prevention/Detection Systems from
High-Level Speciﬁcations, USENIX Security Symposium, 1999.
39. C.C. Zou, W. Gong, Don Towsley, Code Red Worm Propagation Modeling and Analysis,
ACM Computer and Communication Security Conference, 2002.