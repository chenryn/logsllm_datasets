## 经营、销售分析系统DB设计之PostgreSQL, Greenplum - 共享充电宝 案例实践    
### 作者                                                                  
digoal                                                                  
### 日期                                                                   
2017-09-23                                                          
### 标签                                                                  
PostgreSQL , 物联网、共享充电宝 , 经营分析系统 , 多表关联 , 明细补齐 , 取缔关联 , ltree树类型 , 并行计算 , PostgreSQL 10黑科技 , 销售管理         
----                                                                              
## 背景       
共享充电宝、共享单车、共享雨伞，共享女朋友^|^，共享汽车，。。。 共享经济最近几年发展确实非常迅猛。    
共享必定涉及被共享对象的管理、会员的管理等，实际上也属于一种物联网系统。    
本文以共享充电宝的场景为例，分享一下共享充电宝的经营分析、销售管理系统的后台数据库的设计。（老板关心的是整体销售的业绩，以及各个渠道的透视等。销售经理关心的是他管辖片区的销售业绩，运维人员关心的是设备的状态。）    
## 一、数据结构和数据量    
业务模式是什么样的？    
在饭店、商场、火车站、足浴店等各种场所，都能看到充电宝的身影。每个充电宝会有相对固定的位置（比如放在外婆家餐馆），每个固定的位置都有相对固定的销售（就好像古惑仔受保护费一样），每个销售都有固定的上级。    
用户借充电宝操作很简答，用户扫码，下单，借走；有些是不能借走的，那就扫码，下单，充电。    
（这里除了充电业务，实际上还可以与商户合作，搞一些用户画像和广告推送、商家促销的业务。当然，前提是有用户画像。）    
### 数据结构抽象    
![pic](20170923_01_pic_001.jpg)    
1、人员表（BOSS，销售总监，门店经理）。    
数据量预估：3000+，极少更新。    
2、类目表（足浴店、酒店、火车站、饭店。。。）    
数据量预估：100+ ， 极少更新    
3、门店表     
数据量预估：百万级以内 ， 极少更新    
4、设备表     
数据量预估：百万级 ， 每个设备 每隔N分钟上报一次心跳    
5、订单表     
数据量预估：百万级/天 ，插入、并且每个订单至少更新一次（创建订单、支付订单、退单等），订单有最终状态。    
## 二、分析需求    
1、实时分析需求：    
以日、月、年时间维度；再加上以全局、员工、员工一级下属、员工所有下属、类目、门店、设备等维度进行透视。    
2、聚合指标：    
新增设备数、在线设备数、离线设备数、新建订单量、成交订单量、退订量、账务流水等等。    
3、时间需求：    
有查询当天订单统计需求、有查询当天、前一天统一时间点统计需求，算同比。同样的也有月、年需求。    
4、查询并发：    
分析系统的查询并发通常不会太高，因为都是自己人使用的。一分钟可能不会超过3000。    
5、查询时效性：    
月、年统计 每天离线生成。（建议这么做，因为业务上月指标没必要实时看。）    
日维度的统计，实时产生。（日数据量并不大，实时产生，实时查询，可以满足并发、响应时间的需求。同时也满足业务的需求。）    
响应时间要求：几十毫秒级。    
并发要求：100以内。    
## 三、数据库选型    
PostgreSQL 10：HTAP数据库，支持10TB级OLTP和OLAP混合需求。TP性能强劲，功能丰富。支持多核并行计算，HASH JOIN等一系列强大的功能，AP性能亦适中。    
HybridDB for PostgreSQL：PB级，纯分析型数据库，支持多机并行计算。AP性能强劲，但是TP性能非常弱。    
如果想了解更多的详情，请参考：    
[《空间|时间|对象 圈人 + 透视 - 暨PostgreSQL 10与Greenplum的对比和选择》](../201709/20170918_02.md)      
本场景到底选哪个呢？干脆两个都来做个DEMO设计，对比一下。    
## 四、PostgreSQL 10 方案1    
### 设计表结构    
```    
create table a (          -- 员工层级信息    
  id int primary key,     -- 编号 ID    
  nick name,              -- 名字    
  pid int                 -- 上级 ID    
);    
create table c (          -- 类目    
  id int primary key,     -- 类目ID    
  comment text            -- 类目名称    
);    
create table b (          -- 终端门店    
  id int primary key,     -- 编号    
  nick text,              -- 名称    
  cid int,                -- 类目    
  aid int                 -- 门店经理ID    
);    
create table d (          -- 设备    
  id int primary key,     -- 设备编号    
  bid int,                -- 门店编号    
  alive_ts timestamp      -- 设备心跳时间    
);    
create table log (        -- 订单日志    
  did int,                -- 设备ID    
  state int2,             -- 订单最终状态    
  crt_time timestamp,     -- 订单创建时间    
  mod_time timestamp      -- 订单修改时间    
) partition by range (crt_time);    
create table log_201701 partition of log for values from ('2017-01-01') to ('2017-02-01') with (parallel_workers =32);     
create table log_201702 partition of log for values from ('2017-02-01') to ('2017-03-01') with (parallel_workers =32);      
create table log_201703 partition of log for values from ('2017-03-01') to ('2017-04-01') with (parallel_workers =32);      
create table log_201704 partition of log for values from ('2017-04-01') to ('2017-05-01') with (parallel_workers =32);      
create table log_201705 partition of log for values from ('2017-05-01') to ('2017-06-01') with (parallel_workers =32);      
create table log_201706 partition of log for values from ('2017-06-01') to ('2017-07-01') with (parallel_workers =32);      
create table log_201707 partition of log for values from ('2017-07-01') to ('2017-08-01') with (parallel_workers =32);      
create table log_201708 partition of log for values from ('2017-08-01') to ('2017-09-01') with (parallel_workers =32);      
create table log_201709 partition of log for values from ('2017-09-01') to ('2017-10-01') with (parallel_workers =32);      
create table log_201710 partition of log for values from ('2017-10-01') to ('2017-11-01') with (parallel_workers =32);      
create table log_201711 partition of log for values from ('2017-11-01') to ('2017-12-01') with (parallel_workers =32);      
create table log_201712 partition of log for values from ('2017-12-01') to ('2018-01-01') with (parallel_workers =32);      
create table log_201801 partition of log for values from ('2018-01-01') to ('2018-02-01') with (parallel_workers =32);    
create index idx_log_201701_1 on log_201701 using btree (crt_time) ;    
create index idx_log_201702_1 on log_201702 using btree (crt_time) ;    
create index idx_log_201703_1 on log_201703 using btree (crt_time) ;    
create index idx_log_201704_1 on log_201704 using btree (crt_time) ;    
create index idx_log_201705_1 on log_201705 using btree (crt_time) ;    
create index idx_log_201706_1 on log_201706 using btree (crt_time) ;    
create index idx_log_201707_1 on log_201707 using btree (crt_time) ;    
create index idx_log_201708_1 on log_201708 using btree (crt_time) ;    
create index idx_log_201709_1 on log_201709 using btree (crt_time) ;    
create index idx_log_201710_1 on log_201710 using btree (crt_time) ;    
create index idx_log_201711_1 on log_201711 using btree (crt_time) ;    
create index idx_log_201712_1 on log_201712 using btree (crt_time) ;    
create index idx_log_201801_1 on log_201801 using btree (crt_time) ;    
```    
### 初始化数据    
1、初始化员工层级 (0为老板，1-30为销售总监，31-3000为门店经理。)    
```    
do language plpgsql $$    
declare     
begin    
  truncate a;    
  insert into a select generate_series(0,3000);    
  update a set pid=0 where id between 1 and 30;    
  for i in 1..30 loop    
    update a set pid=i where id between 31+100*(i-1) and 31+100*i-1;    
  end loop;    
end;    
$$;    
```    
2、初始化类目    
```    
insert into c select generate_series(1,100);    
```    
3、初始化门店    
```    
insert into b select generate_series(1,500000), '', ceil(random()*100), 30+ceil(random()*(3000-30));    
```    
4、初始化设备    
```    
insert into d select generate_series(1,1000000), ceil(random()*500000);    
```    
5、生成1年订单，约3.65亿，实际写入3.78亿（每天100万比订单，90%支付，10%退款）     
```    
do language plpgsql $$    
declare    
  s date := '2017-01-01';    
  e date := '2017-12-31';    
begin    
  for x in 0..(e-s) loop    
    insert into log     
      select ceil(random()*1000000), case when random()<0.1 then 0 else 1 end, s + x + (i||' second')::interval     
      from generate_series(0,86399) t(i),     
           generate_series(1,12);      -- 12是100万一天除以86400得到的，主要是方便写入测试数据。      
  end loop;    
end;    
$$;    
postgres=# select count(*) from log;  
   count     
-----------  
 378432001  
(1 row)  
```    
6、索引（可选操作，优化项）    
（建议实时数据使用btree索引，静态数据使用BRIN块级索引，静态数据删除BTREE索引。）。    
例子    
当订单数据成为静态历史数据时，删除静态表旧btree索引，增加如下brin索引。    
```    
create index idx_log_201701_1 on log_201701 using brin (crt_time) ;    
create index idx_log_201702_1 on log_201702 using brin (crt_time) ;    
create index idx_log_201703_1 on log_201703 using brin (crt_time) ;    
create index idx_log_201704_1 on log_201704 using brin (crt_time) ;    
create index idx_log_201705_1 on log_201705 using brin (crt_time) ;    
create index idx_log_201706_1 on log_201706 using brin (crt_time) ;    
create index idx_log_201707_1 on log_201707 using brin (crt_time) ;    
create index idx_log_201708_1 on log_201708 using brin (crt_time) ;    
create index idx_log_201709_1 on log_201709 using brin (crt_time) ;    
create index idx_log_201710_1 on log_201710 using brin (crt_time) ;    
create index idx_log_201711_1 on log_201711 using brin (crt_time) ;    
create index idx_log_201712_1 on log_201712 using brin (crt_time) ;    
create index idx_log_201801_1 on log_201801 using brin (crt_time) ;    
```    
### 创建必要的UDF函数    
1、创建immutable函数，获取当前时间，前天，前年时间。(使用immutable函数，优化器将过滤不必查询的分区。)，如果要支持并行，设置为parallel safe.    
```    
create or replace function cdate() returns date as $$    
  select current_date;    
$$ language sql strict immutable PARALLEL safe;    
create or replace function cts(interval default '0') returns timestamp as $$        
  select (now() - $1)::timestamp;    
$$ language sql strict immutable PARALLEL safe;    
```    
### 透视SQL设计    
按人，查询下级所有层级，关联门店，关联设备，关联订单。    
输出统计信息：    
1、聚合项：    
今日截止总订单，今日截止支付订单，同比昨日截止总订单，同比昨日截止支付订单    
当月截止总订单，当月截止支付订单，同比上月截止总订单，同比上月截止支付订单    
当年截止总订单，当年截止支付订单，同比上年截止总订单，同比上年截止支付订单    
2、聚合维度：    
全量，TOP    
类目，TOP    
门店，TOP    
所有下属，TOP    
所有下属，类目，TOP    
所有下属，门店，TOP    
门店经理，TOP    
门店经理，类目，TOP    
门店经理，门店，TOP    
### 透视SQL性能指标举例    
1、全量透视，32个并发，77毫秒。    
```    
select t1.cnt, t1.succ_cnt, t2.cnt, t2.succ_cnt from    
(    
  select count(*) cnt, sum(state) succ_cnt from log where crt_time between cdate() and cts()    
) t1,    
(    
  select count(*) cnt, sum(state) succ_cnt from log where crt_time between cdate()-1 and cts(interval '1 day')    
) t2;    
  cnt   | succ_cnt |  cnt   | succ_cnt     
--------+----------+--------+----------    
 796621 |   716974 | 796620 |   716930    
(1 row)    
Time: 76.697 ms    
```    
2、类目 TOP，32个并发，446毫秒。    
```    
select c.id, count(*) cnt, sum(state) succ_cnt from c     
    join b on (c.id=b.cid)     
    join d on (b.id=d.bid)     
    join log on (d.id=log.did)     
  where crt_time between cdate() and cts()    
  group by c.id    
  order by cnt desc limit 10;    
 id | cnt  | succ_cnt     
----+------+----------    
 39 | 8369 |     7543    
 70 | 8346 |     7517    
 64 | 8281 |     7488    
 13 | 8249 |     7412    
 29 | 8222 |     7427    
  3 | 8217 |     7370    
 90 | 8200 |     7387    
 79 | 8199 |     7346    
 71 | 8175 |     7348    
 75 | 8169 |     7373    
(10 rows)    
Time: 446.977 ms    
```    
3、我的总销量（包括所有下属），464毫秒。    
这里用到了with recursive递归语法，根据当前登录用户的ID，树形查询所有下属。     
```    
with recursive tmp as (    
  select * from a where id=31                -- 输入我的USER ID    
  union all     
  select a.* from a join tmp on (a.pid=tmp.id)     
)    
select count(*) cnt, sum(state) succ_cnt from tmp     
  join b on (tmp.id=b.aid)    
  join d on (b.id=d.bid)    
  join log on (d.id=log.did)    
  where crt_time between cdate() and cts()    
  ;    
 cnt | succ_cnt     
-----+----------    
 296 |      268    
(1 row)    
Time: 463.970 ms    
```    
4、我的直接下属，TOP，2.6秒。    
这里用到了with recursive递归语法，根据当前登录用户的ID，树形查询所有下属。     
这里还用到了正则表达式，用于对直接下属进行分组聚合。得到他们的销量。     
```    
with recursive tmp as (               
  select id::text from a where id=0   -- 输入我的USER ID      
  union all     
  select tmp.id||'.'||a.id as id from a join tmp on (a.pid=substring(tmp.id, '([\d]+)$')::int)     
)    
select substring(tmp.id, '^[\d]*\.?([\d]+)'), count(*) cnt, sum(state) succ_cnt from tmp     
  join b on (substring(tmp.id, '([\d]+)$')::int=b.aid)    
  join d on (b.id=d.bid)    
  join log on (d.id=log.did)    
  where crt_time between cdate() and cts()    
  group by 1    
  order by cnt desc limit 10    
  ;    
   substring |  cnt  | succ_cnt     