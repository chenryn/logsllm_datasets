When using nn.ParameterList and nn.DataParallel at the same time, the length
of ParameterList will be 0 after DataParallel.
See and run this code (with pytorch=1.6+cu101 installed by pip):
    import torch
    class Model(torch.nn.Module):
        def __init__(self):
            super(Model, self).__init__()
            self.param = torch.nn.ParameterList([torch.nn.Parameter(torch.zeros(3,3)) for _ in range(16)])
            print('Before DataParallel: ' + str(len(self.param)))
        def forward(self, x):
            print('After DataParallel: ' + str(len(self.param)))
            return x
    model = Model()
    model = model.to(torch.device('cuda'))
    model = torch.nn.DataParallel(model)
    x = model(torch.zeros(3,3))
And the results are:
    Before DataParallel: 16
    After DataParallel: 0
    After DataParallel: 0
    After DataParallel: 0
    After DataParallel: 0
cc @pietern @mrshenli @pritamdamania87 @zhaojuanmao @satgera @rohan-varma
@gqchen @aazzolini @xush6528 @osalpekar @jiayisuse @agolynski @albanD
@mruberry