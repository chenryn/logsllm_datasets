user@docker1:~$
```
令人惊讶的是，这也有效。考虑到 Docker 不管理或不集成任何主机 IPv6 防火墙策略，您可能想知道这是如何工作的。答案其实很简单。如果我们查看第二个 Docker 主机开放的端口，我们会看到有一个`docker-proxy`服务绑定到端口`32769`:
```
user@docker2:~$ sudo netstat -plnt
……
Active Internet connections (only servers)
Local Address   Foreign Address         State       PID/Program name
0.0.0.0:22      0.0.0.0:*               LISTEN      1387/sshd
127.0.0.1:6010  0.0.0.0:*               LISTEN      3658/0
:::22           :::*                    LISTEN      1387/sshd
::1:6010        :::*                    LISTEN      3658/0
:::32769        :::*                    LISTEN      2390/docker-proxy
user@docker2:~$
```
正如我们在前面章节中看到的，`docker-proxy`服务促进了容器间和已发布端口的连接。为了实现这一点，`docker-proxy`服务必须绑定到容器发布的端口。回想一下，监听所有 IPv4 接口的服务使用`0.0.0.0`的语法来表示所有 IPv4 接口。以类似的方式，IPv6 接口使用`:::`的语法来指示同样的事情。您会注意到`docker-proxy`端口引用了所有的 IPv6 接口。尽管这可能因您的操作系统而异，但绑定到所有 IPv6 接口也意味着绑定到所有 IPv4 接口。也就是说，前面的`docker-proxy`服务实际上正在侦听所有主机的 IPv4 和 IPv6 接口。
### 注
请记住`docker-proxy`通常不用于入站服务。这些依赖于`iptables` NAT 规则将发布的端口映射到容器。然而，在这些规则不存在的情况下，主机仍然在其所有接口上监听到端口`32769`的流量。
这样做的最终结果是，尽管没有 IPv6 NAT 规则，我仍然能够通过 Docker 主机接口访问容器服务。这样，使用 IPv6 发布的端口仍然可以工作。然而，这仅在使用`docker-proxy`时有效。虽然这种操作模式仍然是默认的，但它将被删除，取而代之的是发夹型 NAT。我们可以在 Docker 主机上启用发夹 NAT，方法是将`--userland-proxy=false`参数作为服务级别选项传递给 Docker。这样做会阻止这种 IPv6 端口发布方式的工作。
最后，缺少防火墙集成也意味着我们不再支持出站伪装功能。在 IPv4 中，这个特性允许容器与外部网络对话，而不必担心路由或 IP 地址重叠。离开主机的容器流量总是隐藏在主机的一个 IP 接口后面。然而，这不是一个强制配置。正如我们在前面几章中看到的，您可以非常容易地禁用出站伪装功能，并为`docker0`网桥提供一个可路由的 IP 地址和子网。只要外部网络知道如何到达该子网，容器就很容易拥有唯一的可路由 IP 地址。
IPv6 出现的原因之一是因为 IPv4 地址的快速耗尽。IPv4 中的 NAT 在很大程度上成功地解决了地址耗尽问题，尽管同样麻烦。这意味着许多人认为我们不应该对 IPv6 实施任何类型的网络地址转换。相反，所有 IPv6 前缀都应该是本地可路由和可达的，而不需要混淆 IP 转换。由于缺乏 IPv6 防火墙集成，将 IPv6 流量本地路由到每台主机是 Docker 目前促进跨多台 Docker 主机和外部网络可达性的手段。这要求每个 Docker 主机使用唯一的 IPv6 CIDR 范围，并且 Docker 主机知道如何到达所有其他 Docker 主机定义的 CIDR 范围。虽然这通常要求物理网络具有网络可达性信息，但在我们简单的实验示例中，每台主机只需要一条到其他主机 CIDR 的静态路由。就像我们在第一个食谱中所做的那样，我们将在每台主机上添加一条 IPv6 路由，这样双方都知道如何到达另一个`docker0`网桥的 IPv6 子网:
```
user@docker1:~$ sudo ip -6 route add 2003:ef11::/64 via 2003:ab11::2
user@docker2:~$ sudo ip -6 route add 2003:cd11::/64 via 2003:ab11::1
```
添加路由后，每个 Docker 主机都知道如何到达另一台主机的 IPv6 `docker0`桥接子网:
![How to do it…](img/5453_10_06.jpg)
如果我们现在检查，我们应该在每个主机上的容器之间有可达性:
```
user@docker2:~$ docker exec web2 ifconfig eth0
eth0      Link encap:Ethernet  HWaddr 02:42:ac:11:00:02
          inet addr:172.17.0.2  Bcast:0.0.0.0  Mask:255.255.0.0
          inet6 addr: fe80::42:acff:fe11:2/64 Scope:Link
          inet6 addr: 2003:ef11::242:ac11:2/64 Scope:Global
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:43 errors:0 dropped:0 overruns:0 frame:0
          TX packets:34 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:3514 (3.5 KB)  TX bytes:4155 (4.1 KB)
user@docker2:~$
user@docker1:~$ docker exec -it web1 curl -g http://[2003:ef11::242:ac11:2]
    Web Server #2 - Running on port 80
user@docker1:~$
```
我们可以看到，主机`docker1`上的容器能够成功地直接路由到主机`docker2`上运行的容器。因此，只要每个 Docker 主机都有适当的路由信息，容器就能够直接相互路由。
这种方法的缺点是容器现在是一个完全暴露的网络端点。我们不再获得通过 Docker 发布的端口只向外部网络公开某些端口的优势。如果您想确保在您的 IPv6 接口上只暴露某些端口，此时用户域代理可能是您的最佳选择。在围绕 IPv6 连接设计服务时，请记住这些选项。
# 配置 NDP 代理
正如我们在上一份食谱中看到的，Docker 中 IPv6 支持的主要区别之一是缺少防火墙集成。没有这种集成，我们将失去出站伪装和完整的端口发布功能。虽然这可能不是在所有情况下都是必要的，但当不使用它时，会失去某些便利因素。例如，当在仅 IPv4 模式下运行时，管理员可以安装 Docker，并立即将您的容器连接到外部网络。这是因为只有通过 Docker 主机的 IP 地址才能看到容器的入站(发布端口)和出站(伪装)连接。这意味着不需要向外部网络通知额外的子网，因为外部网络只看到 Docker 主机的 IP 地址。在 IPv6 模型中，外部网络必须知道容器子网才能路由到它们。在本章中，我们将回顾如何配置 NDP 代理来解决这个问题。
## 做好准备
在本食谱中，我们将使用以下实验拓扑:
![Getting ready](img/5453_10_07.jpg)
您需要对每台主机进行根级访问，以更改网络配置。假设安装了 Docker，这是默认配置。
## 怎么做…
前面的拓扑显示，我们的主机是双栈连接到网络，但 Docker 尚未配置为使用 IPv6。正如我们在前面的配方中看到的，为 IPv6 配置 Docker 通常也意味着在外部网络上配置路由，因此它知道如何到达您为`docker0`网桥定义的 IPv6 CIDR。然而，暂时假设这是不可能的。假设您无法控制外部网络，这意味着您无法向其他网络端点通告或通知 Docker 主机上任何新定义的 IPv6 子网。
我们还假设，虽然您不能通告任何新定义的 IPv6 网络，但是您可以在现有网络中保留额外的 IPv6 空间。例如，主机当前具有在`2003:ab11::/64`网络中定义的接口。如果我们瓜分这个空间，我们可以把它分成四个`/66`网络:
*   `2003:ab11::/66`
*   `2003:ab11:0:0:4000::/66`
*   `2003:ab11:0:0:8000::/66`
*   `2003:ab11:0:0:c000::/66`
让我们假设允许我们保留最后两个子网供我们使用。我们现在可以在 Docker 中启用 IPv6，并将这两个网络分配为 IPv6 CIDR 范围。以下是每个 Docker 主机的配置选项:
*   `docker1`
    ```
    ExecStart=/usr/bin/dockerd --ipv6 --fixed-cidr-v6=2003:ab11:0:0:8000::/66
    ```
*   `docker2`
    ```
    ExecStart=/usr/bin/dockerd --ipv6 --fixed-cidr-v6=2003:ab11:0:0:c000::/66
    ```
将新配置加载到`systemd`并重新启动 Docker 服务后，我们的实验室拓扑现在看起来如下:
![How to do it…](img/5453_10_08.jpg)
让我们在两台主机上启动一个容器:
```
user@docker1:~$ docker run -d --name=web1 jonlangemak/web_server_1
user@docker2:~$ docker run -d --name=web2 jonlangemak/web_server_2
```
现在确定`web1`容器的分配的 IPv6 地址:
```
user@docker1:~$ docker exec web1 ip -6 addr show dev eth0
4: eth0@if5:  mtu 1500
    inet6 2003:ab11::8000:242:ac11:2/66 scope global nodad
       valid_lft forever preferred_lft forever
    inet6 fe80::42:acff:fe11:2/64 scope link
       valid_lft forever preferred_lft forever
user@docker1:~$
```
现在，让我们试着从`web2`容器到达那个容器:
```
user@docker2:~$ docker exec -it web2 ping6 \
2003:ab11::8000:242:ac11:2  -c 2
PING 2003:ab11::8000:242:ac11:2 (2003:ab11::8000:242:ac11:2): 48 data bytes
56 bytes from 2003:ab11::c000:0:0:1: Destination unreachable: Address unreachable
56 bytes from 2003:ab11::c000:0:0:1: Destination unreachable: Address unreachable
--- 2003:ab11::8000:242:ac11:2 ping statistics ---
2 packets transmitted, 0 packets received, 100% packet loss
user@docker2:~$
```
这将失败，因为 Docker 主机认为目的地址直接连接到他们的`eth0`接口。当`web2`容器尝试连接时，会发生以下操作:
*   容器进行路由查找，并确定地址`2003:ab11::8000:242:ac11:2`不在它的本地子网`2003:ab11:0:0:c000::1/66`内，因此它将流量转发到它的默认网关(T2 桥接口)
*   主机接收流量并进行路由查找，确定`2003:ab11::8000:242:ac11:2`的目的地址位于其本地子网`2003:ab11::/64` ( `eth0`)内，并使用 NDP 尝试找到具有该目的 IP 地址的主机
*   主机没有收到对此查询的响应，流程失败
我们可以通过检查`docker2`主机的 IPv6 邻居表来验证这是否发生:
```
user@docker2:~$ ip -6 neighbor show
fe80::20c:29ff:fe50:b8cc dev eth0 lladdr 00:0c:29:50:b8:cc STALE
2003:ab11::c000:242:ac11:2 dev docker0 lladdr 02:42:ac:11:00:02 REACHABLE
2003:ab11::8000:242:ac11:2 dev eth0  FAILED
fe80::42:acff:fe11:2 dev docker0 lladdr 02:42:ac:11:00:02 REACHABLE
user@docker2:~$
```
遵循正常的路由逻辑，一切都按照它应该的方式运行。然而，IPv6 有一个名为 NDP 代理的功能，可以帮助解决这个问题。熟悉 IPv4 中代理 ARP 的人会发现 NDP 代理提供了类似的功能。本质上，NDP 代理允许主机代表另一个端点回答邻居请求。在我们的例子中，我们可以告诉两个 Docker 主机代表容器回答。为此，我们需要首先在主机本身上启用 NDP 代理。这是通过启用内核参数`net.ipv6.conf.eth0.proxy_ndp`来完成的，如以下代码所示:
```
user@docker1:~$ sudo sysctl net.ipv6.conf.eth0.proxy_ndp=1
net.ipv6.conf.eth0.proxy_ndp = 1
user@docker1:~$
user@docker2:~$ sudo sysctl net.ipv6.conf.eth0.proxy_ndp=1
net.ipv6.conf.eth0.proxy_ndp = 1
user@docker2:~$
```
### 注
请记住，以这种方式定义时，这些设置不会在重新启动时保持不变。
启用后，我们需要手动告诉每台主机要应答哪个 IPv6 地址。我们通过向每台主机的邻居表添加代理条目来实现这一点。在前面的示例中，我们需要对源容器和目标容器都这样做，以便允许双向流量。首先，在主机`docker1`上为目的地添加条目:
```
user@docker1:~$ sudo ip -6 neigh add proxy \
2003:ab11::8000:242:ac11:2 dev eth0
```
然后，确定`web2`容器的 IPv6 地址，它将作为流量的来源，并在主机`docker2`上为此添加一个代理条目: