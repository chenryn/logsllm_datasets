known, legitimate ad networks, including doubleclick.com,
openx.com and admeld.com, are tricked into referring mali-
cious ad networks to Web clients. Out of the 101 malvertising
domain-paths involving DoubleClick, there exist only 8 domain-
paths where DoubleClick directly connects to a malicious node;
the remaining ones all involve multiple ad networks and are likely
caused by ad syndication.
Figure 7: For each node on the malvertising paths, the mini-
mum distance to a node detected by Safebrowsing or Forefront
(alarm node) vs. the number of infected publishers that it is
associated with.
Path distances among malicious nodes: Section 4.1 shows that
malvertising paths are usually longer. This ﬁnding is consistent
with previous observations [27]. However, we ﬁnd that longer paths
are not solely caused by ad syndication as reported before, since
malvertising paths tend to include multiple nodes whose roles are
unknown. These unknown nodes are often close in distance to the
malicious nodes detected by Safe Browsing or Forefront, suggest-
ing they are also suspicious. Speciﬁcally, we ﬁnd 15.53% of the
Figure 8: Node registration dates.
known malvertising paths include 3 consecutive nodes, all with un-
known roles. In contrast, only 0.23% of the remaining paths have
such cases. However, the exact positions of malicious nodes on
these paths differ in different types of attacks (as shown Figure 14
in Appendix D).
Figure 7 further shows that the closer a node stands to a mali-
cious node, the more likely it is involved in multiple malvertising
domain-paths. Since the detected malicious nodes are often redi-
rectors or exploit servers, their neighboring nodes are also likely
part of the malvertising infrastructure. We further inspect the reg-
istration dates of the neighboring nodes that are within 1 or 2 hops
to the malicious nodes. Figure 8 shows that a large fraction of
such nodes are newly registered in 2011. As a comparison, we also
show in Figure 8 the registration date distributions of two other sets
of nodes: the ﬁrst includes the set of nodes that are at least 3 hopes
away from a reported malicious node, and the second is a set of
randomly sampled nodes. In both cases, fewer than 20% of them
are newly registered.
4.4 Summary of Findings
Our measurement study shows that common node features, such
as node roles and domain registration times, do help differentiate
malicious ad nodes from legitimate ones to some extent. However,
using these features in isolation is not reliable for detection. Even
when they are used in combination on the individual nodes, the
differentiation power is still limited (see Appendix A).
On the other hand, ad redirections also have unique conventions
and characteristics that are different from typical Web site redirec-
tions. When we combine node features with ad paths, they become
more distinctive for identifying attacks. For example, the roles
played by different legitimate nodes (e.g., publishers, ad networks,
and trackers) and their orders are not completely random. It is un-
usual to observe multiple consecutive nodes, completely unrelated
with ads, staying together along the redirection chain of a normal
ad. We also ﬁnd that newly registered ad domains are much rarer
than newly registered normal Web sites. So studying the topology
and interactions among nodes, combined with their features, pro-
vides great opportunities for detection.
Finally, the observation that malicious nodes tend to stay to-
gether is helpful for detection.
It suggests that we do not need
to go beyond short path segments for detection—immediate neigh-
bors often provide rich information for characterizing malvertising
activities.
 051015202530354045012345678910Infected publisher page Minimum Distance To Alarmed Node  00.10.20.30.40.50.62Random6795. MALVERTISING DETECTION
In this section, we present the design and implementation of
our system, called MadTracer, for detecting malvertising activities.
Our measurement ﬁndings motivate us to explore ad-redirection
paths, annotated with rich node features, to represent the under-
lying ad topology. Previous work has also studied and measured
the characteristics of malicious Web redirection chains (e.g., [27]).
The question is how to leverage the topologies and the interactions
among ad nodes for detection.
Although we ﬁnd malicious ad paths tend to be longer than nor-
mal ad paths, directly relying on the entire redirection paths for
detection has two problems. First, a malicious path usually has
mixed malicious and legitimate nodes. The presence of legitimate
nodes adds noise to detection, especially when there exist multiple
of them playing different roles, e.g., publishers, ad networks, and
trackers. Second, the locations of the malicious nodes on a path are
usually not ﬁxed and we have encountered different cases in our
study. For example, in drive-by-downloads, the malicious nodes
often locate at the path tails. In click-fraud attacks, the malicious
nodes usually locate in the middle of a path, between legitimate
publishers and legitimate pay-per-click ad networks. Such diversi-
ﬁed path behaviors add additional complexity in detection.
On the other hand, exploring simple, lightweight short ad-path
segments holds great promise. Given malicious nodes usually stay
close to each other on a path, as shown in Section 4.3. using
short path segments mitigates the noises introduced by the presence
of legitimate nodes. In addition, they are cleaner representations
that eliminate the requirement of precisely identifying malicious
node positions. Finally, such a formulation signiﬁcantly reduces
the complexity of our problem space and allows efﬁcient solutions.
While we do lose some information regarding the knowledge of en-
tire paths, we ﬁnd that short path segments are often sufﬁcient to
characterize the interactions among malicious entities. We show in
Section 6 that such a representation works effectively in practice.
MadTracer consists of two major components. The ﬁrst compo-
nent identiﬁes malvertising paths by analyzing ad paths and their
features. The second is an analyzer component that intensively
monitors the infected publisher pages, so as to study cloaking tech-
niques and to expand our detection results. Figure 9 shows the
architecture of MadTracer.
Figure 9: The infrastructure of MadTracer.
5.1 Detection Methodology
Our detection technique is based on analyzing annotated ad path
segments. For each segment, we annotate every node with a set of
attributes, including node popularity, the role in ad delivery, the do-
main registration information, and URL properties. These features,
when applied to individual nodes, is not reliable for detection as
we will show in Appendix A, but they add value to detection when
they are combined with the topology information.
We adopt a statistical learning framework based on decision trees
to automatically generate a set of detection rules. Figure 10 shows
the process ﬂow. Given input ad paths, MadTracer ﬁrst annotates
each node with a set of predeﬁned attributes. It then extracts path
Figure 10: The process ﬂow of malicious ad detection.
segments and selects a subset of them as training data to learn rules.
When new data arrive, MadTracer apply the set of already learned
rules. Meanwhile it also generates new rules periodically. We elab-
orate the details below.
Node annotation. Based upon our measurement study, we use the
following four types of attributes to annotate a node:
Frequency attributes: The popularity of nodes and node pairs
across the entire ad topology provides information about the scales
of the corresponding Web sites and their business pairing relation-
ships. MadTracer computes the frequency of every node and node
pair in the collected data, and classiﬁes them into the popular and
unpopular categories according to an occurrence threshold (which
was set to 10 in our research). For a pair of consecutive nodes
A→B, we mark the pair’s popularity attribute at B.
Role attributes: As discussed in Section 4, a node belonging
to a known publisher or an ad-related entity is much less likely
a malicious one. In contrast, those with unknown roles are more
suspicious. Therefore, MadTracer annotates individual nodes with
the roles they played using EasyList and EasyPrivacy, as described
in Section 3.
Domain registration attributes: Our measurement suggests that
domain registration and expiration dates can help differentiate le-
gitimate domains from malicious ones. Therefore, for each node,
MadTracer queries the Whois server [34] to obtain the registered
lifetime of its domain, i.e., the duration between its registration and
expiration dates. We label a domain’s lifetime as long if it is longer
than one year and short otherwise.
URL attributes: Section 4.2 shows that some malicious nodes
can be characterized by the unique features of their domain names
and URLs. We use the following two methods to derive such fea-
tures. First, we identify free domain providers in our data (e.g.,
co.cc); many of them are also widely used by spammers [11].
MadTracer annotates all the nodes from such domains as domain-
suspicious and others as domain-normal. Second, we derive URL
regular expressions for each malvertising campaign captured in the
training data. Similar to the previous approach using URL fea-
tures to detect SEO campaign [16], we extract lexical features from
URLs alarmed by Safebrowsing and Forefront, and cluster the URLs
that share the same features. The lexical features include subdirec-
tory name, ﬁlename, and argument name. Then we manually gen-
erate regular expressions from the URL clusters. Note that this step
can be automated using regular expression generation tools such
as AutoRE [35]. In total we generate 37 URL regular expressions.
If a node matches any of the 37 regular expressions, MadTracer
annotates it as url-suspicious and otherwise as url-normal.
 Extract  Ad Paths Publisher Pages Crawling publishers Detector Cloaking Analyzer Malicious Paths    Node annotation Path segments extraction Training data labeling Likely good Known bad Unknown Rule learning Detection Malicious node identification  Input  Training data Output Testing data 680Ad path segment extraction. After annotating nodes, MadTracer
proceeds to derive ad path segments. Given our interest is in the ad-
delivery topology rather than speciﬁc publishers, MadTracer ﬁrst
removes all the known publishers from the input paths. Further-
more, if a set of consecutive nodes from the same domain share
identical attributes, MadTracer merges them into one node. Af-
ter this preprocessing, MadTracer extracts all possible 3-node path
segments from the input paths. For example, from a path a → b →
c → d → e, we can generate 3 segments: a → b → c, b → c → d
and c → d → e. If a path is shorter than three hops, we use empty
nodes (with all null attributes) as its preﬁx.
We ﬁnd that 3-node path segments work well empirically. As
discussed earlier, longer path segments might carry more informa-
tion, but they tend to be too speciﬁc and often involve legitimate
nodes. The classiﬁcation complexity also grows substantially with
longer segments, as the possible number of node attribute combi-
nations will grow signiﬁcantly.
Training data selection. MadTracer uses a “known bad” dataset
and a “likely good” dataset to generate detection rules. The “known
bad” set includes the malvertising paths detected by Safe Browsing
or Forefront. The second dataset contains all the remaining paths
that correspond to long-lasting domain-paths in our data. The ratio-
nale is that individual malvertising domain-paths are usually short-
lived, with the average lifetime being a few days as shown in Sec-
tion 4.1. Therefore, if a domain-path segment has a long life-span,
it reﬂects legitimate, stable business partnerships. So MadTracer
treats domain-paths whose lifetimes (between their ﬁrst and last ap-
pearances) are longer than one month as “likely good”. Although
this approach does not guarantee that the training set does not in-
clude any malicious nodes, it signiﬁcantly reduces the chance for
such contamination to happen.
Learning and detection. MadTracer generates a set of detection
rules via building a full decision tree. Since each node has 6 dif-
ferent attributes, the entire decision tree can have a large number of
leaf nodes. We take advantage of the relatively small “known bad”
dataset and prune the tree by selecting a subset of the leaf nodes
that can detect at least one malicious node from the training data.
We then sort them in an ascending order according to their false
positive rates on the “likely good” training data, and return a set of
l leaf nodes whose rules each result in a false positive rate no higher
than a pre-deﬁned threshold f pα (set to 0.02% in our research). Fi-
nally, we merge these selected rules along the tree structure (e.g., if
a certain attribute is agnostic, we remove it from the rules) to obtain
a set of more compact detection rules.
Detection can take place either online during crawling, or off-
line periodically. In the detection phase, MadTracer does not re-
quire Safebrowsing or Forefront. It uses the already produced rules
to match against each ad-path to be detected. If a path segment
matches any of the learned rules, MadTracer reports the corre-
sponding path as a malvertising path, and mark the corresponding
publisher as infected. The detected publishers are then handed over
to the analyzer component for further monitoring and analysis.
5.2 Attack Monitoring and Analysis
For each alarmed publisher page, the analyzer intensively crawls
it with different conﬁgurations in order to conduct further analysis,
including understanding cloaking and identifying more malicious
nodes and paths.
We deploy 12 VMs at three different geo-locations to perform
the monitoring 4. These VMs monitor already detected publishers
using different browser user-agent conﬁgurations (IE 6 and Fire-
fox 3.6) and cookie clearing strategies (“always clear cookies” and
“always store cookies”). Each VM continuously visits the entire
4These VMs are deployed in Chicago, San Diego and Florida.
set of detected publisher pages one by one, each time refreshing a
page three times consecutively before moving on to the next one.
As soon as it goes through the entire list, it restarts this process
from the beginning. This monitoring allows the discovery of new
malvertising domain-paths, which we report in our evaluation study.
The analyzer also gathers data useful for understanding cloaking
strategies. Finally, both the detected and the newly discovered
malvertising paths can serve as new learning data to adjust detec-
tion rules. Although the scale of our current cloaking study is rel-
atively small, a few interesting observations have already emerged
(e.g. , the preferences on browser types). Appendix C reports our
ﬁndings for this study.
6. EVALUATION RESULTS
We evaluate MadTracer using four-month data. In this section,
we ﬁrst categorize the detected attacks and validate them. Then, we
summarize newly identiﬁed malvertising characteristics and their
cloaking strategies. Finally, we compare our detection results with
those produced by existing methods.
6.1 Training and Detection Results
Dataset
Training-known-bad
Training-likely-good
Testing-likely-good
Testing-Jun-Sep
Testing-Oct
# of 3-node path segments
1,254
9,346,436
9,346,436
842,985
7,954,268
Table 4: Training and testing datasets
pages
domain-paths
# Total
51,444
1,198,136
#FP
57
899
%FP
0.11%
0.075%
Table 5: False positive rates (Testing-likely-good dataset).
scam pages
drive-by-download pages
click-fraud pages
all pages
scam domain-paths
drive-by-download domain-paths
click-fraud domain-paths
all domain-paths
# detected
56
172
155
326
104
1171
4221
5496
#FP
0
17
17
29
0
73
173
246
%FD
0.00%
9.88%
10.97%
8.90%
0.00%
6.23%
4.10%
4.48%
Table 6: Detection results (Testing-Jun-Sep dataset).