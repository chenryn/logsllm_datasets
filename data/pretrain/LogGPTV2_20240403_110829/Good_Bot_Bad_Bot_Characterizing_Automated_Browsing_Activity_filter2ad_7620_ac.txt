210,917 (90.5%)
77,574 (99.9%)
61 (0.026%)
4,785 (97.8%)
293,337 (92.3%)
agents
(“Googlebot/2.1”,
user
“Googlebot-Image/1.0”,
“AppEngine-Google”, and “Google Page Speed Insights”)
which match documentation from Google [41].
Of
the 317,820 requests claiming to originate from
search-engine bots, we veriﬁed that 293,337 (92.3%) are
indeed real search-engine bot requests. The share of requests
towards our honeysites from the identiﬁed search-engine bots
are listed in Table I.
Academic and Industry scanners. Apart from anonymous
scanners, we identiﬁed 30,402 (0.12%) requests originating
from scanners belonging to companies which collect website
statistics (such as BuiltWith [28] and NetCraft [42]), keep
historical copies of websites (such as the Internet Archive [43]),
and collect SEO-related information from websites (such as
Dataprovider.com). Moreover, the crawlers belonging to a
security group from a German university were observed on our
honeysites. We were able to verify all of the aforementioned
bots via reverse DNS lookups, attributing their source IP
address back to their respective companies and institutions.
2) Malicious bots
We deﬁne malicious requests by their endpoints and access
methods. As we described in Section III-A, we ensure that
the domains we register for Aristaeus never existed in the past.
Hence, since benign bots have no memory of past versions
of our sites, there should be no reason for a benign bot to
request a non-existent resource. Therefore, we can label all
invalid requests as reconnaissance (i.e., ﬁngerprinting and
exploitation attempts) requests, which we ultimately classify
as malicious. Similarly, we label bots that make unsolicited
POST requests to other endpoints, such as login pages, as
malicious. Overall, we labeled 15,064,878 requests (57% of
total requests) as malicious.
Credential brute force attempts. 13,445,474 (50.8%)
requests from 47,667 IP addresses targeted the login page of
our websites. By analyzing all unsolicited POST requests we
received and checking their corresponding URIs, we discovered
that different web applications attract different attacks. For
example, there are 12,370,063 POST requests towards Word-
Press, 90.3% of which are attempts to brute force wp-login.php
and xmlrpc.php. However, for Joomla,
there are 343,263
unsolicited POST requests with only 51.6% targeting the
Joomla log-in page. The remaining requests are not speciﬁc to
Joomla and are targeting a wide variety of vulnerable software
(e.g. requests towards /cgi-bin/mainfunction.cgi attack DrayTek
devices that are vulnerable to remote code execution [44]).
Interestingly, system management tools attract different
patterns of attacks. While 76.2% of POST requests towards
TABLE II: Top ﬁngerprinting requests
Path
# requests
Unique IPs
/CHANGELOG.txt
/(thinkphp|TP)/
(public|index)
/wp-content/plugins
/solr/
/manager/html
116,513
55,144
32,917
23,307
10,615
97
3,608
2,416
919
1,557
Target applications
Drupal, Joomla,
Moodle and spip
ThinkPHP
WordPress
Apache Solr
Tomcat Manager
phpMyAdmin targeted login endpoints, virtually all POST
requests (99.95%) for Webmin targeted its speciﬁc login
endpoints. This suggests that most bots targeting Webmin
focus on brute-forcing credentials, as opposed to targeting
other, publicly-accessible pages.
By examining the username and password combinations
that were attempted against our honeysites, we observe that
attackers always try to login as “admin” using either common
passwords [45], or variations of our honeysite domains (i.e.
attempting a “www.example.com” password on the honeysite
serving the example.com domain). From the number of
attempts, we found 99.6% of bots (as identiﬁed by their IP
address) issued fewer than 10 attempts per domain before chang-
ing their targets. Only 0.3% of bots issued more than 100 brute-
force attempts per domain. The most active bot issued 64,211
login-related requests towards our WordPress honeysites.
Reconnaissance attempts. To identify requests related
to reconnaissance, we incorporate a two-prong mapping
approach. First, we generate signatures based on popular
libraries and databases that include URIs related to Application
ﬁngerprinting, Exploitation attempts, Scanning for open-access
backdoors, and Scanning for unprotected backup ﬁles. We
provide details for each speciﬁc library and dataset later in
this section. Second, we manually identify the intention of
requests for endpoints that received more than 1,000 requests
in our dataset, mapping each request to the aforementioned
categories of attacks whenever possible. This ﬁltering step is
necessary since we cannot possibly create a comprehensive
database that includes signatures for all bot requests. As an
example of the power of this prioritized-labeling method,
via this process we discovered attacks exploiting the recent
CVE-2020-0618 vulnerability in MSSQL Reporting Servers
which was not part of our original database of signatures.
Overall, we collected a total of 16,044 signatures, with 179
signatures matching requests in our dataset. These signatures
cover 25,502 (9% of total) IP addresses which generated
659,672 requests.
• Application ﬁngerprinting: In this study, ﬁngerprinting
attempts refer to requests that aim to uncover the presence of
speciﬁc web-application versions and their plugins. To quantify
these requests, we use the signatures from BlindElephant [46]
and WhatWeb [47], two open-source ﬁngerprinting tools that
have large databases of ﬁngerprints for popular web applications
and their plugins. By requesting speciﬁc ﬁles and matching
their content with the signatures in their database, these tools
can identify the type and speciﬁc version of the target web
application. We extract the ﬁle paths from the databases of
ﬁngerprints and correlate these signatures with our web server
logs, to identify ﬁngerprinting attempts from malicious bots. To
ensure that we do not label regular crawling as ﬁngerprinting,
we discount requests towards generic ﬁles, such as, index.php
and robots.txt even if these are valuable in the context of web-
application ﬁngerprinting. Overall, our database includes 13,887
URL-based signatures used to identify ﬁngerprinting attempts.
Table II lists the top 5 paths in our database of ﬁngerprinting
signatures that received the most requests. In total, we received
223,913 requests that were categorized as ﬁngerprinting at-
tempts and originated from 12,183 unique bot IP addresses.
Within our database of signatures, /CHANGELOG.txt has
received the largest number of requests since this ﬁle can be
used to identify the version of Drupal, Joomla, Moodle (Online
learning platform), and SPIP (Collaborative publishing system).
Second, we observe requests towards remote-code execution
(RCE) vulnerabilities in ThinkPHP deployments which are
known to be targeted by multiple botnets [48]. The ﬁngerprint-
ing of Apache Solr is related to the versions that were reported
to be vulnerable to RCE in November 2019 [49]. Finally, in the
top ﬁve categories of ﬁngerprinting requests, we observe large
numbers of requests towards speciﬁc vulnerable WordPress plu-
gins as well as the default deployment of Tomcat Manager. The
rest of ﬁngerprinting-related requests follow the same patterns
of probing for highly-speciﬁc endpoints, belonging to applica-
tions that are either misconﬁgured or known to be vulnerable.
• Exploitation attempts: We deﬁne exploitation attempts
as requests towards URIs that are directly used to trigger known
exploits. We use exploits from exploit-db.com to generate
signatures for exploitation attempts. Unfortunately, automati-
cally generating signatures based on public exploit descriptions
is challenging due to the diverse format of vulnerability reports.
As a result, we incorporate a human-assisted automation tool
that extracts the URLs of signature candidates for the human
analyst to verify. At the same time, we hypothesize that bots
will most likely focus on server-side exploits that are easy
to mount (such as SQL injections and RCEs) and therefore
focus on these types of exploits, as opposed to including client-
side attacks, such as, XSS and CSRF. The resulting signature
database includes 593 signatures for the 5 web applications
in our dataset corresponding to vulnerabilities from 2014 to
2020. Our database includes 174 exploits for WordPress, 297
exploits for Joomla, 40 for Drupal, 52 for phpMyAdmin, and
19 exploits for Webmin, as well as 14 exploits extracted by
looking at the most requested paths on our honeysites.
Overall, we matched 238,837 incoming requests
to
exploitation attempts that originated from 10,358 bot IP
addresses. Table III includes the top 5 endpoints used in
these attempts. In this table, we report on the CVE number
whenever possible, and in the absence of a CVE number, we
report the EDB-ID (Exploit-db ID) for these vulnerabilities.
The RCE vulnerability in PHPUnit received the most
exploitation attempts, followed by a setup PHP code injection
vulnerability of phpMyAdmin, and an RCE on exposed XDebug
servers (PHP Remote debugging tool). Next, an RCE vulner-
TABLE III: Top exploit requests
Path
/vendor/phpunit/
.../eval-stdin.php
/scripts/setup.php
/?XDEBUG SESSION
START=phpstorm
/?a=fetch&content=die(
@md5(HelloThinkCMF))
/cgi-bin/mainfunction.cgi
# requests
Unique IPs
CVE/EDB-ID
70,875
67,417
23,447
21,819
20,105
346
1,567
7
953
2,055
CVE-2017-9841
CVE-2009-1151
EDB-44568
CVE-2019-7580
CVE-2020-8515
ability in ThinkCMF (CMS application based on thinkPHP)
is also targeted by malicious bots. The last entry in Table III
refers to a Draytech vulnerability which is signiﬁcant in that its
exploit was released during our study, allowing us to observe
how fast it was weaponized (discussed more in Section VIII).
IP addresses that sent
ﬁngerprinting or exploitation requests were observed in both
categories, suggesting that some bots cover a wide range of
vulnerabilities, as opposed to focusing on a single exploit.
Interestingly, 3,221 (14%) of
Next to exploitation attempts, we also searched for requests
that included tell-tale shell commands (such as rm -rf /tmp
and wget) in one or more request parameters. In this way, we
discovered an additional 24,379 shell-related requests.
attempt
commands
injected shell
Though most
to
download a malicious payload from a publicly accessible IP
address/domain, we discovered that 2,890 requests contain
the URL of a private IP address, such as “192.168.1.1:8088”
which of course is unreachable from our web servers. These
requests could either belong to a buggy bot that extracts the IP
address of the wrong network interface after exploiting a host,
or could indicate botnets which are meant to attack the routers
in a local network, but ﬁnally ended up on the public web.
• Scanning for open-access backdoors: We generate
a list of 485 well-known PHP, ASP, Perl, Java and bash,
backdoors. We use the same lists as Starov et al. [50] to extract
the signatures of known web backdoors and augment their
lists with two repositories that host web shells [51], [52]. Our
signatures matched 42 web shells (such as, shell.php, cmd.php
and up.php) requested 144,082 times by 6,721 bot IP addresses.
• Scanning for unprotected sensitive ﬁles: Another
group of bots query for unprotected sensitive ﬁles, by either
guessing the names of likely-sensitive ﬁles (such as backup.sql)
or capitalizing on administrator behavior (e.g. keeping known
working copies of sensitive ﬁles with a .old sufﬁx) and leaks
due to speciﬁc editors (such as accessing the temporary swap
ﬁles left behind by Vim).
Similar to web-shell signatures, we used popular word lists
used in security scanners, such as SecLists [51], to build a
database of 1,016 signatures. These signatures matched 52,840
requests from 5,846 unique bot IP addresses. Files with the
.env extension which include potentially sensitive environment
variables used in Docker as well as other popular development
platforms were requested 29,713 times by 1,877 unique bot IP
addresses. Bots also requested a wide range of likely sensitive
ﬁle extensions including .old, .sql, .backup, .zip, and .bak as
well as text editor cache ﬁles such as .php˜ and .swp ﬁles.
Based on all of our signatures introduced in this section,
we observe 929 unique bot IP addresses that participated in
all of the aforementioned types of attacks. This demonstrates
that there exist bots that are equipped with a large number
of exploits and are willing to exhaust them while attacking
a host, before proceeding to their next victim.
B. Duration and frequency of bot visits
We grouped the requests recorded by Aristaeus into
1,760,124 sessions. Overall, 44.9% of sessions only consist
of a single request. 46% of sessions include between 2-20
requests, whereas there exist 2,310 sessions that include more
than 1,000 requests. The majority of bots spend as little as 1-3
seconds on our honeysites. 58.1% of the bots that visited our
honeysites left within 3 seconds, and among these bots, 89.5%
left within 1 second. Contrastingly, 10.7% of bots spent more
than 30 minutes on our honeysites.
A large fraction of bots visiting our honeysites perform too
few and too generic requests for us to be able to categorize
them as benign or malicious. Speciﬁcally, 11,015,403 requests
(41.68% of total requests) fall into this category. We provide
additional details for these bots below:
Single-shot scanners. 50.04% of the IP addresses that
visited our honeysites only sent a single request and did
not exhibit any obviously malicious behavior. This is clearly
bot behavior since modern browsers make tens of follow-up
requests in order to load the required ﬁrst-party and third-party
resources. Similarly, these bots are unlikely to be indexing
websites since that would also require follow-up requests
for pages linked from the main page. We hypothesize that
these single-shot bots are either populating databases for later
processing (by more persistent bots) or are searching for
speciﬁc content that is not present on our setup.
Internet-wide scanners. We attributed 114,489 requests to
four different Internet-wide scanners, including Masscan [53]
(21.4%) and Zgrab [54] (73.1%). Moreover, our honeysites
recorded “Stretchoid” (34.3%) and “NetSystemsResearch”
(3.69%) bots, which claim to identify online assets of organiza-
tions and the availability of public systems. The exact intention
behind these requests remains unclear since these tools can be
collecting data for both benign as well as malicious purposes.
C. Unexpected changes in bot identity
In this section, we focus on bots that switched their identity
across requests. We look for changes in certain HTTP headers,
such as, the user agent, as well as artifacts of a change in the
used automation tool, such as, the reordering of HTTP headers.
Multiple User-Agents from the same IP address. At least
14.28% of all IP addresses that visited our honeysites sent
requests with two or more user agents. There may be benign
reasons why a bot would present two or more User-Agent
(UA) strings, such as, bots behind NATs and proxies, or bots
that upgraded their versions of browsers/crawling tools. At
the same time, we observed clear spooﬁng behavior, such as,
bots changing their UAs with every request. We summarize
the types of UA changes below:
1) Changing the operating system. As shown in the
following example, only the operating system part of the
user agent was changed across two requests.
• ”Mozilla/5.0 (X11; Ubuntu; Linux x86 64; rv:52.0)
Gecko/ 20100101 Firefox/52.0”
• ”Mozilla/5.0 (Windows NT 6.1; WOW64; rv:52.0)
Gecko/ 20100101 Firefox/52.0”
We identiﬁed 5,479 IP addresses that claimed more than
one OS during their requests. One possible explanation
is that these bots are searching for server-side cloaking,
i.e., our honeysites presenting different content to users
of Windows vs. Linux.
2) Changing the browser version. We use the Levenshtein