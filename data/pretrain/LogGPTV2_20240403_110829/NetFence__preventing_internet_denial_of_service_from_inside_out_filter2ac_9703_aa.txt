title:NetFence: preventing internet denial of service from inside out
author:Xin Liu and
Xiaowei Yang and
Yong Xia
NetFence: Preventing Internet Denial of Service from
Inside Out
Xin Liu
Xiaowei Yang
Yong Xia
Dept. of Computer Science
Dept. of Computer Science
Networking Systems Group
Duke University
PI:EMAIL
Duke University
PI:EMAIL
NEC Labs China
PI:EMAIL
ABSTRACT
Denial of Service (DoS) attacks frequently happen on the Inter-
net, paralyzing Internet services and causing millions of dollars
of ﬁnancial loss. This work presents NetFence, a scalable DoS-
resistant network architecture. NetFence uses a novel mechanism,
secure congestion policing feedback, to enable robust congestion
policing inside the network. Bottleneck routers update the feed-
back in packet headers to signal congestion, and access routers use
it to police senders’ trafﬁc. Targeted DoS victims can use the secure
congestion policing feedback as capability tokens to suppress un-
wanted trafﬁc. When compromised senders and receivers organize
into pairs to congest a network link, NetFence provably guaran-
tees a legitimate sender its fair share of network resources without
keeping per-host state at the congested link. We use a Linux imple-
mentation, ns-2 simulations, and theoretical analysis to show that
NetFence is an effective and scalable DoS solution: it reduces the
amount of state maintained by a congested router from per-host to
at most per-(Autonomous System).
Categories and Subject Descriptors
C.2.1 [Computer-Communication Networks]: Network Archi-
tecture and Design; C.2.6 [Computer-Communication Networks]:
Internetworking
General Terms
Design, Security
Keywords
Internet, Denial-of-Service, Capability, Congestion Policing
1.
INTRODUCTION
Large-scale Denial of Service (DoS) attacks remain as a po-
tent threat to the Internet. A survey from Arbor Networks shows
that DoS attacks continue to grow in both scale and sophistica-
tion [4]. The largest observed attack reached 49Gbps in 2009, a
104% growth over the past two years. The survey also ranks DoS
attacks as the largest anticipated threat in the next 12 months. This
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’10, August 30–September 3, 2010, New Delhi, India.
Copyright 2010 ACM 978-1-4503-0201-2/10/08 ...$10.00.
result is not surprising, as tens of gigabits ﬂooding trafﬁc could
easily overwhelm most links, routers, or sites on the Internet.
The destructive nature of DoS attacks has brought forth a fun-
damental research challenge: how can we design an open network
architecture that is resistant to large-scale DoS attacks? There have
been several proposals addressing this challenge [5,27,35,48,47,3].
These proposals enable DoS victims to suppress attack trafﬁc using
network capabilities or ﬁlters, but when malicious sender-receiver
pairs collude to ﬂood a link, the best defense mechanism these sys-
tems can offer is per-host queuing at the ﬂooded link to separate
legitimate trafﬁc from attack trafﬁc. This solution faces a scalabil-
ity challenge, as a ﬂooded router may forward packets for millions
of (malicious and legitimate) end systems.
This paper presents the design and evaluation of NetFence, a
scalable DoS-resistant network architecture. NetFence provably
guarantees each sender its fair share of bandwidth without keep-
ing per-host state at bottleneck routers even when malicious senders
and receivers collude into pairs to ﬂood the network. It also enables
DoS victims to suppress unwanted trafﬁc as in a capability-based
system [48, 35]. A key departure of NetFence from previous work
is that it places the network at the ﬁrst line of DoS defense rather
than relies on end systems (be it senders or receivers) to suppress
attack trafﬁc.
The NetFence design places a robust trafﬁc policing control loop
inside the network (§ 3 and § 4). Packets carry unforgeable con-
gestion policing feedback stamped by routers that suffer excessive
congestion (caused either by DoS attacks or other reasons, which
NetFence does not distinguish). Access routers at the trust bound-
aries between the network and end systems examine the feedback
and police the senders’ trafﬁc. A malicious sender cannot gain
more than its fair share of bandwidth even if it colludes with a
compromised receiver, because it cannot spoof valid congestion
policing feedback. Innocent DoS victims can use the unforgeable
congestion policing feedback as capability tokens to suppress the
bulk of unwanted trafﬁc, by not returning the feedback to mali-
cious senders. To be fail-safe in case access routers are compro-
mised, NetFence uses Autonomous System (AS)-level queues (or
rate-limiters) to separate trafﬁc from different source ASes, limit-
ing DoS damage to the ASes that harbor the compromised routers.
We have implemented NetFence in Linux and evaluated its over-
head and performance using theoretical analysis (§ 3.4), testbed
experiments, and large-scale simulations (§ 6). Our analysis shows
that regardless of attackers’ strategies, NetFence provides a legit-
imate sender its fair share of bottleneck bandwidth. The simula-
tion results correlate well with this analysis, and also show that
NetFence performs similarly to state-of-the-art capability- or ﬁlter-
plus-fair-queuing DoS defense systems [27, 48]. Our Linux pro-
255totype benchmarking results show that NetFence’s per-packet pro-
cessing overhead is low.
These results suggest that NetFence is an effective and scalable
DoS solution. NetFence’s bottleneck routers have O(1) per-packet
computational overhead, and maintain at most per-AS state (more
scalable design alternatives exist as discussed in § 4.5), while pre-
vious work requires these bottleneck routers to keep per-host state
to protect legitimate trafﬁc. One concern for the NetFence design is
that access routers need to keep per-(sender, bottleneck link) state
(§ 3), but we show in § 5.1 today’s access routers can meet such
scalability requirements.
The key contributions of this paper include a new DoS defense
primitive: secure congestion policing feedback, and based on it,
the construction of a robust, network-based, closed-loop conges-
tion policing architecture that scalably and effectively limits the
damage of DoS ﬂooding attacks. With a closed-loop design, Net-
Fence can ﬂexibly place different functionalities at different lo-
cations:
lightweight attack detection and congestion signaling at
bottleneck links, and congestion policing that requires per-(sender,
bottleneck link) state at access routers. This design makes it scale
much better than previous open-loop approaches that employ per-
host queuing at bottleneck routers [27, 48].
2. ASSUMPTIONS AND GOALS
Before we present the design of NetFence, we ﬁrst describe its
threat model, assumptions, and design goals.
2.1 Threat Model and Assumptions
Flood-based network attacks: NetFence focuses on mitigating
network-layer ﬂooding attacks where attackers send excessive traf-
ﬁc to exhaust network resources such as link capacity or router pro-
cessing power. It does not aim to mitigate DoS attacks that exploit
application vulnerabilities to exhaust end system resources.
Strong adversary: We assume that attackers can compromise
both end systems and routers. Compromised end systems involved
in an attack can grow into millions; they may launch brute-force or
strategic ﬂooding attacks. For instance, they may disguise attack
trafﬁc as legitimate trafﬁc, launch on-off attacks, or collude into
sender-receiver pairs to send ﬂooding trafﬁc. Attack trafﬁc may or
may not be distinguishable from legitimate trafﬁc.
We make two assumptions to assist NetFence’s design.
Trust: We assume that routers managed by the network are much
less likely to be compromised than end systems. We thus place
policing functions on routers rather than end systems. As a tradeoff
for scalability, we treat each AS as a trust and fate sharing unit.
When compromised routers exist, we aim to localize the damage
to the ASes that harbor compromised routers rather than protect all
the legitimate hosts within such ASes.
Line-speed lightweight cryptography: We assume that symmet-
ric key cryptography can be supported at line-speed. Some current
hardware can support AES operations at 40Gbps [20], and the latest
Intel Westmere processors have native support for AES [21].
2.2 Goals
Figure 1: The NetFence architecture. Packets carry unspoofable con-
gestion policing feedback stamped by bottleneck routers (Rb in this
ﬁgure). Access routers (Ra) use the feedback to police senders’ trafﬁc,
preventing malicious senders from gaining unfair shares of bottleneck
capacity. DoS victims can use the congestion policing feedback as ca-
pability tokens to suppress unwanted trafﬁc.
network, we resort to a weaker goal to guarantee a legitimate sender
its fair share of network resources. That is, for any link of capac-
ity C shared by N (legitimate and malicious) senders, each sender
with sufﬁcient demand should be guaranteed at least O( C
N ) band-
width share from that link. This mitigates the effect of large-scale
DoS attacks from denial of service to predictable delay of service.
ii) Open network: NetFence aims to keep the network open to
new applications, and thus places the attack trafﬁc identiﬁcation
function at the receivers to avoid false positives introduced by in-
network trafﬁc classiﬁcation. This goal is also shared by previous
work [3, 48, 5].
iii) Scalable and lightweight: NetFence may face millions of at-
tackers that attempt to congest a single link. To be effective at such
a scale, it does not assume that a router always has sufﬁcient re-
sources to warrant per-ﬂow or per-host state management. It aims
to keep little or no state in the core network and avoid heavyweight
operations such as per-ﬂow/host fair queuing in the core network.
To facilitate high-speed router implementation, NetFence aims to
incur low communication, computation, and memory overhead.
iv) Robust: NetFence should be robust against both simple, brute-
force ﬂooding attacks and sophisticated ones that attempt to bypass
or abuse NetFence itself.
v) Incrementally adoptable: We aim to make NetFence incre-
mentally deployable on today’s Internet. Speciﬁcally, we aim to
provide early adopters immediate deployment beneﬁts:
they can
form an “overlay” network of deployed regions and beneﬁt col-
lectively from the deployment. We aim not to require hop-by-hop
deployment from a congested link to compromised end systems to
be effective, unlike [30].
vi) Network self-reliant defense: We aim for a self-reliant solu-
tion that depends on only routers in the network, not other infras-
tructures such as trusted host hardware [2] or DNS extensions [35].
Our hypothesis is that extra dependencies increase security risk and
may create deployment deadlocks. That is, without the deploy-
ment or upgrade of other infrastructures, the design is not effective.
Hence, there is little incentive to deploy it, and vice versa.
NetFence aims to meet several design goals. It is these goals that
3. ARCHITECTURE
distinguish NetFence from previous work.
In this section, we present an overview of the NetFence architec-
i) Guaranteed network resource fair share: When DoS victims
can identify attack trafﬁc, we aim to enable them to suppress the at-
tack trafﬁc near the origins. This prevents attack trafﬁc from wast-
ing network resources. When DoS victims fail to identify attack
trafﬁc, or attackers collude into sender-receiver pairs to ﬂood the
ture, and defer design details to § 4.
3.1 System Components
NetFence has three types of packets: request packets, regular
packets, and legacy packets. The ﬁrst two, identiﬁed by a special
256Figure 2: Each NetFence router keeps three channels.
protocol number in the IP header, have a shim NetFence header
between their IP and upper-layer protocol headers. The NetFence
header carries unforgeable congestion policing feedback generated
by the network (§ 3.2 and § 4.4). A NetFence-ready sender sends
request and regular packets, while a non-NetFence sender sends
only legacy packets.
Each NetFence router, depicted in Figure 2, keeps three chan-
nels, one for each of the three packet types discussed above. To
motivate end systems to upgrade, the NetFence design gives legacy
channel lower forwarding priority than the other two. To prevent re-
quest ﬂooding attacks from denying legitimate requests, NetFence
has a priority-based backoff mechanism for the request channel
(§ 4.2). The request channel is also limited to consume no more
than a small fraction (5%) of the output link capacity, as in [48,35].
NetFence places its feedback and policing functions at bottle-
neck and access routers that are either inside the network or at the
trust boundaries between the network and end systems.
It does
not place any trusted function at end systems. As shown in Fig-
ure 1, a NetFence sender starts an end-to-end communication by
sending request packets to its NetFence-ready receiver (Step 1).
The access router inserts the nop feedback in the NetFence header
of the packet (Step 2, § 4.1). Along the path, a bottleneck router
might modify the feedback, in a way similar to TCP ECN [37] (Step
3). After the receiver returns the feedback to the sender (Step 4),
the sender can send valid regular packets that contain the feedback
(Step 5). In Step 4, two-way protocols like TCP can piggyback the
returned feedback in their data packets, while one-way transport
protocols such as UDP must send extra, low-rate feedback packets
from a receiver to a sender.
A NetFence router periodically examines each output link to de-
cide if an attack is happening at the link. It uses a combination of
link load and packet loss rate as an attack indicator (§ 4.3.1). If an
attack is detected, NetFence starts a monitoring cycle, which lasts
until i) no more attack is detected during the cycle, and ii) the cycle
has existed for an extended period (typically a few hours) after the
most recent attack is detected. During a monitoring cycle, the mon
congestion policing feedback (containing the link ID l, an action
ﬁeld, etc.) is stamped into the NetFence header of all the passing
request/regular packets (§ 4.3.2). The sender’s regular packets must
include this mon feedback to be considered valid, and they will be
policed by the access router (Step 6, § 4.3.3).
An access router maintains one rate limiter for every sender-
bottleneck pair to limit a sender’s regular trafﬁc traversing a bottle-
neck link. The router uses an Additive Increase and Multiplicative
Decrease (AIMD) algorithm to control the rate limit: it keeps the
rate limit constant within one pre-deﬁned control interval (a few
seconds); across control intervals, it either increases the rate limit