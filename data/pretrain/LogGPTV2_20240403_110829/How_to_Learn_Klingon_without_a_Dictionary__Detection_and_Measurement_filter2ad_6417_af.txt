### Phenomena in Other Languages, Regions, and Channels

**Dependency of Implementation:**
We utilized internal APIs and scanners from Baidu to implement KDES. These components enabled KDES to uncover a large quantity of black keywords in a short time. One might question the performance of KDES when deployed by other organizations without access to these components. Our assessment is that efficiency might be reduced (e.g., more time will be consumed for search queries without unthrottled API access), but effectiveness should not be significantly affected. Each component outside the territory of KDES can be replaced with publicly available alternatives. For instance, Baidu's scanners could be substituted with public scanners like VirusTotal [33].

**Responsible Disclosure and Deployment:**
We reported all detected black keywords (and their associated core words) to Baidu's security team, and the feedback has been positive. Many black keywords have been confirmed and included by Baidu. We will continue to run KDES and provide regular reports to Baidu. In summary, we envision four use cases where KDES could benefit search engines and other parties:

1. **Regulating Search Queries:**
   KDES helps search engines regulate search queries containing black keywords.

2. **URL Categorization:**
   The detected URLs can be categorized more precisely. For example, Baidu currently divides URLs related to the underground economy into three categories: lottery, pornography, and fraud. KDES can refine these categories further.

3. **Search Ad Regulation:**
   Search ads are regulated under stricter policies, but underground merchants exploit weaknesses in the screening process to sneak in illegal ads. KDES can assist auditors in understanding the real business behind search ads and rejecting the illegal ones.

4. **Trend Analysis for Legal Authorities:**
   Legal authorities and other parties can learn about the trends in the underground economy by analyzing the black keywords discovered by KDES. This makes it easier to identify illegal activities in other channels.

**Performance Considerations:**
A significant number of search queries were issued to Baidu during our study, which could have caused noticeable overhead on their servers. To minimize this, we scheduled the queries to run during nighttime when server usage was lower. The search result scanner fetches pages for URLs not found in its cache. If a URL belongs to a search ad, the advertiser might be charged unfairly. To avoid such charges, we excluded URLs of search ads from our queries.

### Related Work

**Blackhat SEO:**
Blackhat SEO has been extensively used to disseminate malicious and fraudulent content. Efforts by search engine companies, security firms, and academic institutions have focused on mitigating this issue. There are two main lines of research in this area:
1. **Revealing Strategies:**
   Many studies have uncovered the strategies of Blackhat SEOers, including constructing SEO botnets [34], spamming forums [35], compromising legitimate sites [36], text spinning [37], and cloaking [38], [39]. By exploiting the differences between blackhat and whitehat SEO, manipulated sites can be detected at scale [36], [37], [40].
2. **Ecosystem Understanding:**
   Research has also focused on understanding the ecosystems of blackhat SEO. Previous studies show that pharmaceutical affiliate programs and stores selling fake products heavily rely on blackhat SEO to reach potential buyers [41], [42], [43]. Our recent work et al. [8] uncovered a new blackhat SEO technique using wildcard DNS (spider pools) to tamper with search rankings under long-tail keywords. While this work used data from spider pools, its goal differs from KDES, which aims to detect black keywords rather than sites boosted by blackhat SEO.

**Underground Economy:**
Understanding and measuring the underground economy has been an active research area. Studies have provided insights into the operational models and ecosystems of cybercrimes, including email spam [42], pay-per-install malware [44], unwanted software [45], [46], Twitter spam [47], and illicit online pharmacies [48], [41]. Online anonymous marketplaces like Silk Road have attracted many buyers and sellers since 2011 [49], [50]. However, traditional channels such as forums [51], spam [52], and Blackhat SEO [43] remain important, especially in regions outside of Western countries [53], [54], [55]. Adversaries constantly invent new terms or obfuscate existing ones to evade detection, but our work shows that such terms can be effectively captured by their associated search results, even without understanding their semantic meanings.

**Retrofitting Search Engines for Detection:**
Previous works have shown that search engines can help detect compromised and malicious sites. Invernizzi et al. proposed EvilSeed, which automatically generates search queries by analyzing seeding malicious web pages, significantly increasing the probability of finding malicious sites [28]. Liao et al. studied promotional infection, an attack that injects advertising content into compromised sites [56]. Their study showed that the semantics of injected pages differ from those of hosting sites' sponsored top-level domains (sTLD). By querying terms irrelevant to sTLD semantics, promotional infections can be effectively spotted. Zhang et al. used search engine visibility (whether a site is indexed) as a factor to determine the maliciousness of a site [57]. In this work, we demonstrated that indexed pages of search engines can be used to discover trending terms in underground markets, a direction not previously explored.

**Search Query Abuse:**
While the public interface offered by search engines allows security practitioners to discover hacker-involved sites, it also provides hackers with a tool to identify their targets. A common type of search query abuse is "Google Dork Query" [58], which models the fingerprint of a website and is submitted by attackers to harvest URLs of sites built on specific templates (e.g., querying "Powered by WordPress" returns a list of WordPress sites [59]). With many vulnerabilities discovered on website templates, adversaries can easily find and exploit vulnerable sites. Although many Google Dorks have been published (e.g., exploit-db.com [60]), only a few are frequently exploited [61]. Toffalini et al. [62] characterized known dorks and showed that dorks can be created automatically. Adversaries also use bot clients to send large volumes of search queries to identify vulnerable sites, harvest emails, and scrape content [63]. Both black keywords and Google Dorks are harmful, but detecting black keywords is more challenging due to the lack of a public reference for the ever-changing vocabulary and the difficulty of analyzing them with classic NLP models.

### Conclusion

Black keywords are frequently used in the underground economy to evade law enforcement and search engine regulation. Capturing these keywords is difficult because they evolve quickly and are often obfuscated. In this work, we present the first approach to automatically detect black keywords by examining search results and using several search engine features to determine their labels. Running our system, we discovered over 400,000 black keywords, many of which were previously unknown, indicating the high effectiveness of our approach.

We believe our approach suggests a new direction in tackling security problems that are challenging for conventional methods, such as traditional NLP. In the future, we will explore translating black keywords through big-data analytics. In the short term, we will collaborate with search engines and online communities like Baidu to build additional defenses against illegal promotion by the underground economy.

### Acknowledgements

This work was supported by the Natural Science Foundation of China (grant No. U1636204 and 61472215) and sponsored by the CCF-Venustech Hongyan Research Initiative (016-014). We thank the anonymous reviewers for their insightful comments. Special thanks to Prof. James Mickens for his instructive advice on our paper. We are deeply indebted to Jinjin Liang, Fengpei Li, and Yiming Gong from Qihoo 360 for providing passive DNS data for this research. Finally, special thanks to our colleagues from Baidu for providing platform support and data.

### References

[References listed as in the original text]

---

This optimized version aims to enhance clarity, coherence, and professionalism while maintaining the original content and structure.