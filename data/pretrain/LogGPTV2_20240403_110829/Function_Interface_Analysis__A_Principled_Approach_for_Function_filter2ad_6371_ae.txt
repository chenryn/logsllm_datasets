0.00
68.75
70.77
0.00
80.64
0.00
64.94
62.72
75.28
0.00
73.74
71.43
73.61
84.31
50.00
40.15
43.06
41.02
29.55
67.02
1851
228
1602
0
1916
2
As shown in the ﬁgure, the percentage of each function
category is largely language and program dependent. For most
C and Fortran programs, direct calls contribute to the largest
number of identiﬁed functions. (Note that this includes direct
calls made within functions that are only indirectly reached.)
Some C programs (such as 445.gobmk), however, contain a
large number of indirect functions. For many C++ programs,
because virtual functions7 are abundant, there are generally
more indirectly reached functions. The fourth column presents
the percentage of functions that are reached only by direct
jumps (i.e.,
tail called). These functions are not rare in
optimized binaries.
Note that for some benchmarks, the percentage of unreach-
able functions is quite high (average 17.7% and up to 40%).
To verify these results, we selected a subset of these programs,
and used Pintools [27] to record the locations reached via calls
or jumps. We found that none of these addresses corresponded
to functions determined unreachable by our technique.
After checking source code, we found that the unreachable
functions are mostly global (i.e., non-static) functions which
are neither called directly nor have their addresses taken.
Although they are not used, compilers don’t generally remove
them unless speciﬁc actions are taken during the build process
to eliminate them. Note that
this is different from static
functions whose visibility is within the same compilation
unit — it is more common for unused static functions to be
7Virtual functions can only be indirectly called through a V-table.
removed by default.
Effectiveness of Interface Checking Techniques.
As discussed, function interface checking is critical
in
pruning spurious functions from the identiﬁed candidate set.
In this section, we evaluate the effectiveness of each checking
mechanism independently. The results are presented in Fig. 13.
Again, only GCC -O2 compiled binaries for x86-32 are shown.
As shown in the ﬁgure, each checking mechanism is in-
dependently effective in identifying a signiﬁcant fraction of
all spurious (“total pruned” in the ﬁgure) functions. How-
ever, in general, no single mechanism is able to detect all
spurious functions. It is through their combination that we
can effectively reduce the number of spurious functions to
a very low number. Note that for four of the binaries, no
spurious functions are pruned. This is because all the functions
enumerated happen to be real functions.
VII-F. Analysis Runtime Performance
Our focus so far has been on accuracy, and hence we have
not made any efforts to optimize runtime performance. Nev-
ertheless, for completeness, we summarize the performance
results we currently obtain.
As compared to machine learning based approaches [7, 35],
one of the advantages of our approach is that it does not require
training, which is expensive. The results of our analysis,
together with those from ByteWeight [7] and neural network
based system [35], are summarized in Fig. 14. The numbers
209
Experiment setup
x86-32 binaries
x86-64 binaries
Tool
ByteWeight
machine
desktop
Neural
Ours
Amazon EC2
c4.2xlarge
laptop
CPU
4-core 3.5GHz
i7-3770K
8-core 2.9GHz
Intel Xeon
4-core 1.7GHz
i5-4210U
RAM
16G
15G
8G
training
293 hc
(estimate)
20 h
testing
457,997 s
1,062 s
training
293 hc
(estimate)
20 h
testing
593,170 s
1,018 s
0
47,880 s
0
36,300 s
Fig. 14. Experiment setup and performance comparison (hc = compute hours, h = hours, s = seconds)
are based on our ﬁrst data set, and 10-fold cross validation for
machine learning systems.
The neural network based system uses much less time
for the testing because it only identiﬁes the bytes where
functions start and end, without recovering the function body.
As a comparison, ByteWeight and our system follow the CFG
to identify function ends, therefore can recognize the exact
instructions belonging to the function, and identify physically
non-contiguous parts of the function.
Currently, it takes about 40 seconds on average to analyze
a binary of our test suite. Although this is already satisfactory
for many cases, there are many opportunities for improvement.
For example, spurious functions can be immediately spotted
if the entry basic block has violating behavior and therefore
analysis of the whole function can be avoided. This is in
contrast to our current naive implementation that performs
complete analysis and checks.
VIII. CASE STUDIES
Since function recognition serves as an essential step for
many techniques working on binaries, to understand how well
our approach can be used, we analyze several representative
applications. Our focus in this section is on binary instrumen-
tation tasks that impose stringent requirements.
Many binary instrumentation techniques operate on indi-
vidual functions as a unit [12, 32, 10]. These applications are
sensitive to precision because a misidentiﬁed function could
cause misbehavior or failure of the instrumented program.
In this section, we analyze the applicability of our function
identiﬁcation system for these function-based instrumentation
applications.
Since directly called functions are free of errors and un-
reachable functions are not relevant for correct functionality
(as they will never be executed), imprecision could possibly
originate from two sources: indirectly reachable functions and
direct jump reached (tail called) functions. We analyze these
two cases respectively.
For the ﬁrst case, an address could be incorrectly identiﬁed
as an (indirectly reachable) function start
if our interface
checking mechanism is insufﬁcient. Although our comprehen-
sive checking schemes are generally effective and can remove
vast majority of the spurious function starts, such misses do
happen. Fig. 15 shows one example. In this case, since all
instructions access global memory and there are no stack
or general-purpose register operations, our interface checking
can’t identify [818c784, 818c8e4] as a spurious function.
0x86ed1d0 ;real function start
0x87202c0 ;spurious function start
0818ba30 :
818ba30:
818ba36:
...
818c784:
818c78a:
818c790:
818c796:
...
818c8d0:
818c8da:
818c8e4:
fld
fstp 0x8ca5af0
(similar instructions)
fld
fstp 0x8ca5908
fld
0x87202c8
fstp 0x8ca5910
(similar instructions)
mov
mov
ret
$0xf2,0x8ca5a4c
$0xf6,0x8ca5aec
Fig. 15. A falsely identiﬁed (indirectly reachable) function [818c784,
818c8e4]
Despite these imprecisions, one distinguishing feature of our
system is that the real function which encloses the spurious
one is always identiﬁed. In Fig. 15 for example, [818ba30,
818c8e4] is also recovered. And with this property, different
measures could be taken for different instrumentations to cope
with the imprecisions.
For RAD [12], no work is required at all because the
instrumentation is resistant to such imprecisions8. For more
complicated instrumentations [32, 10], the overlapping func-
tions could have their own instrumented version (which
are disjoint), and an address translation scheme for indirect
branches (commonly adopted by binary transformation sys-
tems [27, 45, 44, 37]) could be used. With this technique,
an indirect call target is translated at runtime to point to
its instrumented version before control
transfer. Since the
falsely identiﬁed function is never called at runtime, incorrect
instrumentation will not be executed.
Our system may also falsely recognize intra-procedural
jumps as direct tail calls (the second type of error). Essentially,
this is equivalent to splitting the original function into two.
However, we note that this will not introduce any correctness
problems, as all executed instructions and exercised control
ﬂows have been well captured.
Above analysis indicates that our function recognition is
effective and only leaves limited error possibility. The in-
accuracies tend to either have no effect for function-based
instrumentation correctness, or can be easily coped with. As
a comparison, since machine learning based approaches rely
on code or byte patterns, false positives of function starts and
8This is because, at the spurious function start, an extra (i.e., unneeded)
“return address” will be pushed on the shadow stack. While this slightly
increases attacker’s options, it does not break program functionality since at
the function epilogue, return addresses is popped repeatedly from the shadow
stack until there is a match. Note that the true return address is present in the
shadow stack, because the larger, real function is also recovered.
210
ends are much more random and difﬁcult to deal with. Finally,
as can be seen in these case studies, our system automatically
classiﬁes identiﬁed functions based on their reachability prop-
erty, which can enable more ﬂexible instrumentations.
IX. DISCUSSION
Special calling conventions. Currently our data ﬂow checking
technique is based on well-respected system ABIs and calling
conventions, and it can be adapted to other architectures
such as ARM [11]. We note although non-standard calling
conventions have not appeared in our tests, they could be used
in some cases, e.g., function calls within a single translation
unit. To deal with this issue, a “self-checking” mechanism can
be adopted.
Speciﬁcally, note that ABI violations can occur only in the
context of direct calls and jumps. (Since a compiler cannot
be sure about the target of an indirect control ﬂow transfer,
it cannot assume that such a transfer is intra-module.) Since
we don’t apply interface checks for direct calls, ABI violations
won’t pose a problem in their context. That leaves direct jumps
(i.e., direct tail calls) as the only problem case. We develop a
self-checking mechanism in this case. Speciﬁcally, we can per-
form interface checks on a subset of directly called functions
to determine whether ABI is respected. If not, we identify a
relaxed set of conventions that are respected in direct calls,
and apply these relaxed checks to tail call veriﬁcation. (Note
that veriﬁcation of indirectly called functions can continue to
rely on ABI.)
X. RELATED WORK
Function recognition. Many tools recognize functions using
call graph traversal and function prologue matching. Examples
include CMU BAP [8], angr binary analysis platform [36], and
the Dyninst instrumentation tool [22]. IDA [1] uses proprietary
heuristics and a signature database for function boundary
identiﬁcation to assist disassembling. Its problems include that
it underperforms for different compilers and platforms, and the
overhead of maintaining an up-to-date signature database.
Rosenblum et al. ﬁrst proposed using machine learning for
function start identiﬁcation [31]. The precision and perfor-
mance have been greatly improved by recent work from Bao
et al. [7] and Shin et al. [35], due to adoption of different
machine learning techniques such as weighed preﬁx trees
and neural networks. However, as discussed, machine learning
requires a good training set, and potentially subtle parameter
tuning. Moreover, existing machine learning techniques have
been focused on surrounding code, and may have difﬁculties
grasping valuable global evidences or deeper semantics — the
factors greatly beneﬁt our analysis.
Nucleus [5] is a concurrent work that is also based on
static analysis. Nucleus relies on control-ﬂow analysis to infer
inter-procedural edges and function starts. In contrast, our
approach leverages both control-ﬂow and data-ﬂow properties
211
for comprehensive function interface checking. We demon-
strate that ﬁne-grained static analysis [29] can recognize
functions with much greater accuracy, and has the potential
to support demanding applications such as automated analysis
and instrumentation.
Static binary analysis to recover high-level constructs. Other
than function boundaries, previous works also focus on recov-
ering other high-level constructs, such as variables and types
[6, 26, 3] or function signatures [17]. The more ambitious goal
is to recover source code through decompilation [21, 18, 33].
However, many of these tools are either best-effort analyses
designed for helping human audits, or only tested with a much
smaller corpus. We expect the precision of these downstream
analyses to be improved with more accurately recognized
functions.
XI. CONCLUSIONS
In this work, we present a static analysis based approach
for function boundary identiﬁcation in stripped binary code.
Compared with previous efforts that rely on matching of
code patterns, our approach is more principled by leveraging
the function interface abstraction and implementation. By
adopting a comprehensive checking mechanism that combines
stack discipline, control ﬂow and data ﬂow properties, our
approach can substantially improve accuracy over the best
previous systems that are either machine learning or static
analysis based. The deeper insights of identiﬁed functions
provide further opportunities to reduce error rates and enable
more ﬂexible applications.
REFERENCES
[1] Hex rays. https://www.hex-rays.com/index.shtml.
[2] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-ﬂow integrity.
In CCS, 2005.
[3] K. Anand, M. Smithson, K. Elwazeer, A. Kotha, J. Gruen, N. Giles,
and R. Barua. A compiler-level intermediate representation based binary
analysis and rewriting system. In ACM EuroSys, 2013.
[4] D. Andriesse, X. Chen, V. van der Veen, A. Slowinska, and H. Bos.
An in-depth analysis of disassembly on full-scale x86/x64 binaries. In
USENIX Security, 2016.
[5] D. Andriesse, A. Slowinska, and H. Bos. Compiler-agnostic function
detection in binaries. In EuroS&P, 2017.
[6] G. Balakrishnan and T. Reps. WYSINWYX: What you see is not what
you eXecute. ACM TOPLAS, 2010.
[7] T. Bao, J. Burket, M. Woo, R. Turner, and D. Brumley. Byteweight:
Learning to recognize functions in binary code. In USENIX Security,
2014.
[8] D. Brumley, I. Jager, T. Avgerinos, and E. J. Schwartz. Bap: A binary
analysis platform. In Computer aided veriﬁcation, 2011.
[9] M. Chandramohan, Y. Xue, Z. Xu, Y. Liu, C. Y. Cho, and H. B. K. Tan.
Bingo: Cross-architecture cross-os binary search. In FSE, 2016.
[10] X. Chen, A. Slowinska, D. Andriesse, H. Bos, and C. Giuffrida.
Stackarmor: Comprehensive protection from stack-based memory error
vulnerabilities for binaries. In NDSS, 2015.
[11] Y. Chen, D. Zhang, R. Wang, R. Qiao, A. Azab, L. Lu, H. Vijayakumar,
and W. Shen. Norax: Enabling execute-only memory for COTS binaries
on AArch64. In S&P, 2017.
[12] T. Chiueh and M. Prasad. A binary rewriting defense against stack based
overﬂows. In USENIX ATC, 2003.
[13] C. Cifuentes and M. Van Emmerik. Recovery of jump table case
In IEEE International Workshop on
statements from binary code.
Program Comprehension, 1999.
[14] P. Cousot and R. Cousot. Abstract interpretation: a uniﬁed lattice model
for static analysis of programs by construction or approximation of
ﬁxpoints. In POPL, 1977.
[15] Y. David, N. Partush, and E. Yahav. Statistical similarity of binaries. In
PLDI, 2016.
[16] M. Egele, M. Woo, P. Chapman, and D. Brumley. Blanket execution:
In
Dynamic similarity testing for program binaries and components.
USENIX Security, 2014.
[17] K. ElWazeer, K. Anand, A. Kotha, M. Smithson, and R. Barua. Scalable
variable and data type detection in a binary rewriter. In PLDI, 2013.
[18] M. Emmerik and T. Waddington. Using a decompiler for real-world
source recovery. In Working Conference on Reverse Engineering, 2004.
[19] H. Flake. Structural comparison of executable objects. In DIMVA, 2004.
[20] A. Fog. Calling conventions for different c++ compilers and operating
systems, 2015.
[21] I. Guilfanov. Decompilers and beyond. Black Hat USA, 2008.
[22] L. C. Harris and B. P. Miller. Practical analysis of stripped binary code.
ACM SIGARCH Computer Architecture News, 2005.
[23] N. Hasabnis, R. Qiao, and R. Sekar. Checking correctness of code
generator architecture speciﬁcations. In CGO, 2015.
[24] N. Hasabnis and R. Sekar. Extracting instruction semantics via symbolic
execution of code generators. In FSE, 2016.
[25] N. Hasabnis and R. Sekar. Lifting assembly to intermediate representa-
tion: A novel approach leveraging compilers. In ASPLOS, 2016.
[26] J. Lee, T. Avgerinos, and D. Brumley. TIE: Principled reverse engineer-
ing of types in binary programs. In NDSS, 2011.
[27] C. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney, S. Wallace,
V. J. Reddi, and K. Hazelwood. Pin: Building customized program
analysis tools with dynamic instrumentation. In PLDI, 2005.
[28] X. Meng and B. P. Miller. Binary code is not easy. In ISSTA, 2016.
[29] R. Qiao and R. Sekar. Effective function recovery for COTS binaries
using interface veriﬁcation. Technical report, Secure Systems Lab, Stony
Brook University, 2016.
[30] R. Qiao, M. Zhang, and R. Sekar. A principled approach for ROP
defense. In ACSAC, 2015.
[31] N. E. Rosenblum, X. Zhu, B. P. Miller, and K. Hunt. Learning to analyze
binary computer code. In AAAI, 2008.
[32] P. Saxena, R. Sekar, and V. Puranik. Efﬁcient ﬁne-grained binary
instrumentation with applications to taint-tracking. In CGO, 2008.
[33] E. J. Schwartz, J. Lee, M. Woo, and D. Brumley. Native x86 decompila-
tion using semantics-preserving structural analysis and iterative control-
ﬂow structuring. In Usenix Security, 2013.
[34] B. Schwarz, S. Debray, and G. Andrews. Disassembly of executable
code revisited. In Working Conference on Reverse Engineering, 2002.
[35] E. C. R. Shin, D. Song, and R. Moazzezi. Recognizing functions in
binaries with neural networks. In USENIX Security, 2015.
[36] Y. Shoshitaishvili, R. Wang, C. Salls, N. Stephens, M. Polino,
A. Dutcher, J. Grosen, S. Feng, C. Hauser, C. Kruegel, and G. Vigna.
(state of) the art of war: Offensive techniques in binary analysis.
In
IEEE S&P, 2016.
[37] M. Smithson, K. ElWazeer, K. Anand, A. Kotha, and R. Barua. Static
information: Overcoming the
binary rewriting without supplemental
tradeoff between coverage and correctness. In WCRE, 2013.
[38] D. Song, D. Brumley, H. Yin, J. Caballero, I. Jager, M. G. Kang,
Z. Liang, J. Newsome, P. Poosankam, and P. Saxena. BitBlaze: A
new approach to computer security via binary analysis. In International
Conference on Information Systems Security. Keynote paper., 2008.
[39] V. van der Veen, D. Andriesse, E. G¨oktas¸, B. Gras, L. Sambuc,
A. Slowinska, H. Bos, and C. Giuffrida. Practical context-sensitive CFI.
In CCS, 2015.
[40] V. van der Veen, E. G¨oktas, M. Contag, A. Pawlowski, X. Chen,
S. Rawat, H. Bos, T. Holz, E. Athanasopoulos, and C. Giuffrida. A
tough call: Mitigating advanced code-reuse attacks at the binary level.
In IEEE S&P, 2016.
[41] S. Wang, P. Wang, and D. Wu. Reassembleable disassembling.
In
USENIX Security, 2015.
[42] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant,
D. Song, and W. Zou. Practical control ﬂow integrity and randomization
for binary executables. In IEEE S&P, 2013.
[43] M. Zhang. Static Binary Instrumentation with Applications to COTS
Software Security. PhD thesis, Stony Brook University, 2015.
[44] M. Zhang, R. Qiao, N. Hasabnis, and R. Sekar. A platform for secure
static binary instrumentation. In VEE, 2014.
[45] M. Zhang and R. Sekar. Control ﬂow integrity for COTS binaries. In
USENIX Security, 2013.
[46] M. Zhang and R. Sekar. Control ﬂow and code integrity for COTS
In
binaries: An effective defense against real-world ROP attacks.
ACSAC, 2015.
212