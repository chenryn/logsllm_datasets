An accurate method to determine the level of disturbance is to
measure the distance (or normalized distance) between “normal”
trafﬁc (from hereon called baseline) and “abnormal” trafﬁc (traf-
ﬁc containing network anomalies). The difﬁculty faced by every
anomaly detection method is to correctly determine the baseline.
For our study, we have the advantage that we know the Blaster
anomaly in our trace very well. Thus, we are able to construct
an “ideal” baseline by removing the trafﬁc that constitutes to the
anomaly. In our case, that is removing all trafﬁc that matches a
Blaster heuristic: all packets with destination port 135 and packet
sizes of 40, 44, or 48 are removed.
An alternative approach for determining the baselines would have
been to use the average over some past time period. This is similar
to what anomaly detection methods which are based on past be-
havior would do. Yet, our approach of removing the anomaly from
the trace has two advantages: (1) it produces the “best-case” base-
line model that any anomaly detection method could achieve, and
(2) it is more general and is independent of the applied detection
methods.
The baseline and the original unsampled trace are depicted in
Figure 2 for packet counts, ﬂow counts, packet destination IP ad-
dress entropy, and ﬂow destination IP address entropy. While packet
counts do only show a minor increase in distance before and after
the Blaster outbreak, the other three metrics indicate a more drastic
and visible change.
1.000
0.800
0.600
0.400
0.200
pc, absolute difference, 17:00
fc, absolute difference, 17:00
pdip, absolute difference, 17:00
fdip, absolute difference, 17:00
0.250
0.200
0.150
0.100
0.050
pc, relative difference, 17:00
fc, relative difference, 17:00
pdip, relative difference, 17:00
fdip, relative difference, 17:00
0.000
 1
 10
 100
 250
 1000
0.000
 1
 10
 100
 250
 1000
(a) Absolute Difference vs. Sampling Rate
(b) Relative Difference vs. Sampling Rate
Figure 3: Anomaly size vs. sampling rates for four metrics: packet counts (pc), ﬂow counts (fc), ﬂow dst IP entropy (fdip), and packet
dst IP entropy (pdip). The plot shows the mean and 95% conﬁdence interval over 12 sampling runs for one 15 minute interval.
3.2 Measuring Anomaly Size
Having constructed the baselines and packet traces for different
sampling rates and metrics, we now answer the question: How is
anomaly detection impacted by packet sampling? To address this
question, we measure the anomaly size with respect to different
metrics at different sampling rates instead of focusing on a par-
ticular anomaly detection method. We deﬁne anomaly size as the
distance between a sampled view x and the corresponding sampled
baseline ˆx. We determine the anomaly size by measuring the devia-
tion from the baseline at each timebin using two distance measures:
• the absolute difference, deﬁned as: (x − ˆx)
• the relative difference, deﬁned as: (x − ˆx)/ˆx
In Fig. 3 we plot the sampling rate vs. the absolute difference
(normed to the respective value of each metric in the unsampled
trace) as well as the sampling rate vs.
the relative difference for
packet counts, ﬂow counts, ﬂow destination IP entropy, and packet
destination IP entropy. The Figure shows four curves, one for each
metric under investigation, at each sampling rate for one interval.
We selected as representative interval, the ﬁrst interval after the
Blaster outbreak around 17:00 UTC.
Let us consider volume metrics ﬁrst. For the ﬂow count metrics
the absolute as well as the relative difference decrease drastically
when sampling is applied. Thus, we conﬁrm the results of pre-
vious work, namely that ﬂow counts, while exposing Blaster very
well in the unsampled data, are not a suitable metric for detecting
ﬂow-based anomalies when packet sampling is used. In contrast,
packet counts are not impacted by packet sampling. Consequently,
the relative difference for packet counts remains constant. How-
ever, the problem with packet counts is that Blaster-type anomalies
which usually represent only a very small fraction of all packets
(less than 1% in our backbone trace) are not very visible even in
the unsampled data traces.
The ﬂow and the packet entropy curves stand in sharp contrast
to ﬂow counts. The absolute as well as the relative difference de-
crease only very slightly even for sampling rates as high as 1 out
of 1000 for both the entropy metrics, implying that the size of the
Blaster worm remains unaffected when viewed using entropy. For
other intervals (not shown here) we ﬁnd that ﬂow entropy can even
emphasize Blaster-type anomalies in sampled views. Such empha-
sis effects can occurs if sampling decreases the baseline entropy by
a larger factor than the anomaly entropy. This ﬁnding is consistent
with the results in [15].
To summarize, our results collectively demonstrate that entropy-
based metrics have two key beneﬁts over volume-based metrics: (1)
they capture the Blaster worm in unsampled trafﬁc, even though the
Blaster worm is not clearly visible in packet and byte counts; and
more importantly: (2) they are impacted little by sampling when
compared to ﬂow counts.
3.3 Metric Sensitivity to Anomaly Intensity
In the previous sections, we studied the effect of packet sam-
pling on the Blaster anomaly as originally contained in our data.
In this section, we evaluate how effective entropy is at capturing
Blaster-type anomalies of varying intensities. Therefore, we use
the given trace and attenuate or amplify the strength of the Blaster
anomaly. Speciﬁcally, to amplify the Blaster anomaly, for each
observed Blaster-packet we insert a second packet with the same
source IP and a destination IP randomly selected from the SWITCH
IP address range. To simulate and attenuated attack, we keep only
50%, 20%, and 10% of the attack packets in the packet trace.
Figure 4: Normalized anomaly deviation from the baseline for
ﬂow counts and ﬂow entropy across increasing sampling rates
and different intensities.
Figure 4 presents the anomaly size (relative difference from the
baseline) as captured in two metrics, ﬂow counts (dark gray) and
ﬂow entropy (light gray), across increasing sampling rates and dif-
ferent intensities1. It provides considerable insight into the efﬁcacy
of ﬂow counts and ﬂow entropy in exposing the Blaster anomaly at
various intensities and at various sampling rates.
As expected, the stronger the anomaly the larger is the relative
difference for both metrics. But, ﬂow counts decrease sharply as
the Blaster worm is attenuated, even with unsampled trafﬁc. More-
over, this decrease in ﬂow counts is even sharper as the sampling
rate increases. In contrast, ﬂow entropy decreases remarkably slow,
both with increasing sampling rate and for varying intensities of the
Blaster attack.
We conclude from this ﬁgure that ﬂow entropy is far more robust
to packet sampling than simple ﬂow count based summaries, when
exposing the Blaster worm at various intensities.
4. CONCLUSION
In this paper, we empirically evaluated the impact of packet sam-
pling on anomaly detection metrics. Starting with a week-long
dataset of unsampled NetFlow traces containing the Blaster worm,
we asked how packet sampling impacts volume metrics such as
the number of bytes, packets, and ﬂows that have been commonly
used in anomaly detection. To answer this question, we employed a
unique and general methodology – which treats anomalies as devia-
tion from an idealized baseline – to evaluate the ﬁdelity of sampled
trafﬁc in exposing anomalies. Such an approach allows us to draw
general conclusions, rather than limiting our ﬁndings to a particular
anomaly detection method.
Our ﬁrst ﬁnding is somewhat expected: we found that packet
sampling produces accurate estimates of byte and packet counts
(when compared to the underlying trace). However, packet sam-
pling produces grossly inaccurate estimates of ﬂow counts. Indeed,
the Blaster worm which was prominent in the unsampled trafﬁc
view of ﬂow counts disappears entirely at higher sampling rates.
This is because, as show in previous work, small (single packet)
ﬂows are entirely missed. Thus, anomalies that only impact packet
counts or byte counts, are likely to be visible in sampled views, but
anomalies that impact ﬂow counts (such as the Blaster worm in our
data) will not be visible.
We then evaluated the effect of packet sampling on feature en-
tropy. Surprisingly, we found that while the Blaster worm is en-
tirely undetectable in ﬂow counts of sampled traces, it is visible
in ﬂow entropy. The structure of the Blaster worm remains in the
sampled trace and is exposed when viewed in terms of feature en-
tropy. While sampled trafﬁc views are inherently incomplete and
imperfect, they are not completely useless. In fact, this paper shows
that sampled trafﬁc has utility for anomaly diagnosis, if it is ana-
lyzed using the appropriate metrics, such as entropy. The results
presented in this paper open up new directions for research on de-
vising detection metrics that are robust to packet sampling.
5. REFERENCES
[1] BARFORD, P., KLINE, J., PLONKA, D., AND RON, A. A
signal analysis of network trafﬁc anomalies. In Internet
Measurement Workshop (Marseille, November 2002).
[2] BRUTLAG, J. Aberrant behavior detection in timeseries for
network monitoring. In USENIX LISA (New Orleans,
December 2000).
1For presentation purposes, we normalized each surface by the
maximum size for that metric, so that the size of the anomaly for
each metric falls between 0 and 1.
[3] CHOI, B.-Y., PARK, J., AND ZHANG, Z.-L. Adaptive
random sampling for total load estimation. In IEEE
International Conference on Communications (2003).
[4] Cisco NetFlow. At www.cisco.com/warp/public/
732/Tech/netflow/.
[5] DUFFIELD, N., LUND, C., AND THORUP, M. Properties and
prediction of ﬂow statistics from sampled packet streams. In
ACM SIGCOMM Internet Measurment Workshop (2002).
[6] DUFFIELD, N., LUND, C., AND THORUP, M. Estimating
Flow Distributions from Sampled Flow Statistics. In ACM
SIGCOMM (Karlsruhe, August 2003).
[7] ESTAN, C., AND VARGHESE, G. New directions in trafﬁc
measurement and accounting. In Proceedings of the 2001
ACM SIGCOMM Internet Measurement Workshop (San
Francisco, CA, 2001), pp. 75–80.
[8] HOHN, N., AND VEITCH, D. Inverting Sampled Trafﬁc.
Internet Measurement Conference (Miami, October 2003).
[9] JUNG, J., KRISHNAMURTHY, B., AND RABINOVICH, M.
Flash crowds and denial of service attacks: Characterization
and implications for cdns and web sites. In Proceedings of
the International World Wide Web Conference (2002).
[10] JUNG, J., PAXSON, V., BERGER, A., AND
BALAKRISHNAN, H. Fast portscan detection using
sequential hypothesis testing. In Proceedings of the IEEE
Symposium on Security and Privacy (2004).
[11] KIM, M.-S., KANG, H.-J., HUNG, S.-C., CHUNG, S.-H.,
AND HONG, J. W. A Flow-based Method for Abnormal
Network Trafﬁc Detection. IEEE/IFIP Network Operations
and Management Symposium (Seoul, 2004).
[12] LAKHINA, A., CROVELLA, M., AND DIOT, C. Diagnosing
Network-Wide Trafﬁc Anomalies. ACM SIGCOMM
(Portland, August 2004).
[13] LAKHINA, A., CROVELLA, M., AND DIOT, C. Mining
Anomalies Using Trafﬁc Feature Distributions. ACM
SIGCOMM (Philadelphia, August 2005).
[14] MAI, J., CHUAH, C.-N., SRIDHARAN, A., YE, T., AND
ZANG, H. Is sampled data sufﬁcient for anomaly detection?
IMC 2006 (Rio de Janeiro, Brazil, October 2006).
[15] MAI, J., SRIDHARAN, A., CHUAH, C.-N., ZANG, H., AND
YE, T. Impact of packet sampling on portscan detection.
IEEE Journal on Selected Areas in Communication (2006).
[16] M ¨ULLER, O., GRAF, D., OPPERMANN, A., AND WEIBEL,
H. Swiss internet analysis, 2004.
http://www.swiss-internet-analysis.org/.
[17] SRIDHARAN, A., YE, T., AND BHATTACHARRYA, S.
Connectionless port scan detection on the backbone.
Malware workshop, held in conjunction with IPCCC
(Phoenix, AZ, April 2006).
[18] SWITCH. Swiss academic and research network.
http://www.switch.ch/, 2006.
[19] WAGNER, A., AND PLATTNER, B. Entropy based worm and
anomaly detection in fast ip networks. In Proceedings of the
STCA security workshop / WETICE 2005 (2005).
[20] WALLERICH, J., DREGER, H., FELDMANN, A.,
KRISHNAMURTHY, B., AND WILLINGER, W. A
methodology for studying persistency aspects of internet
ﬂows. SIGCOMM Comput. Commun. Rev. 35, 2 (2005).
[21] XU, K., ZHANG, Z.-L., AND BHATTACHARRYA, S.
Proﬁling internet backbone trafﬁc: Behavior models and
applications. In ACM Sigcomm 2005 (Philadelphia, PA,
August 2005).