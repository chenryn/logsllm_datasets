SUMMARY OF OUR SURVEY. (cid:2)= DEFINITION SATISFIES A DESIRABLE PROPERTY (THE MORE (cid:2)S A DEFINITION HAS, THE BETTER); = DEFINITION DOES
NOT SATISFY THE PROPERTY; ? = RESULT IS NOT ADDRESSED IN THE DEFINITION OR WE COULD NOT ESTABLISH IT FROM THE REFERENCE.
TABLE I
notion of zero-knowledge is an open research problem so we
choose to sketch an extension of ballot privacy that keeps the
setup assumption abstract thus sacriﬁcing some precision for
greater generality.
We also note that this extension is needed, not only to allow
for the analysis of more schemes, but also because in its vanilla
format BPRIV security would be too strong: the existence of
a simulator that can fake the proof without using a global
setup, would mean that secure schemes would not satisfy tally
uniqueness.
A global setup consists of a set public parameters and
algorithms that can be accessed by all parties, and in particular
by the adversary. These parameters are initialized at
the
beginning of the execution. We write GlobalSetup.init for
the algorithm that initializes the parameters of the global setup,
and write AGlobalSetup to indicate that algorithm A can access
GlobalSetup. For example, in the CRS case GlobalSetup.init
would select a random string (of some ﬁxed length) and
GlobalSetup simply makes this string available to all parties.
In the random oracle model GlobalSetup consist of a truly
random function to which parties only have oracle access.
The power of setup assumptions comes from the ability to
generate simulated setups, indistinguishable to an adversary
from a normal one. The simulated setup however, grant to
a simulator additional powers that are useful
in crafting
reduction proofs. For example in the CRS model the fake
setup would consist of a CRS indistinguishable from an
honestly generated one, but which comes with a trapdoor that
allows, for example, to produce valid looking proofs for false
statements. In the random oracle model the oracle is under the
control of a simulator who can “program” (i.e. ﬁx) its output
on some values of interest. Naturally, this programming should
be such that the adversary cannot distinguish the simulated or-
acle from a truly random one. We write SimGlobalSetup for a
simulated setup and SimGlobalSetup.init for its initialization
algorithm. When SimGlobalSetup is used, some of the parties
in the system may have access to its associated trapdoor (like
in the CRS setting), or control it in some other way (like in
the RO model).
The extension of BPRIV to global setups is as follows. In
both of the games we initialize a real and a fake setup via
GlobalSetup.init and SimGlobalSetup.init. When β = 0,
that is in the game that corresponds to the real execution
the adversary has access to GlobalSetup; in this experiment
SimGlobalSetup does not play any role – we simply initialize
it for simplicity and for ease of comparing with the other
experiment. When β = 1,
the adversary has access to
SimGlobalSetup. However, the fake global setup is under the
control of SimProof: all calls to SimGlobalSetup are sent to
SimProof which is in charge of answering them. Importantly,
in this experiment the result is produced by tallying the “real”
ballot box (BB0) and using the real GlobalSetup.
We provide a fully worked out instantiation of our deﬁnition
in the ROM in the full version of this paper [35], since this is
507507
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:30 UTC from IEEE Xplore.  Restrictions apply. 
Expbpriv,βA,V (λ)
(pk, sk) ← Setup(1k)
d ← AO
Output d
(pk)
OvoteLR(id, v0, v1)
Let b0 = Vote(id, v0) and b1 = Vote(id, v1).
If Valid(BBβ, bβ) = ⊥ return ⊥.
Else BB0 ← BB0(cid:10)b0 and BB1 ← BB1(cid:10)b1
If Valid(BBβ, b) = ⊥ return ⊥.
Else BB0 ← BB0(cid:10)b and BB1 ← BB1(cid:10)b.
Ocast(b)
Oboard()
return Publish(BBβ)
Otally() for β = 0
(r, Π) ← Tally(BB0, sk)
return (r, Π)
Otally() for β = 1
(r, Π) ← Tally(BB0, sk)
(cid:3) ← SimProof(BB1, r)
Π
return (r, Π
)
(cid:3)
Fig. 2. In the experiments Expbpriv,βA,V (λ) deﬁned above for β = 0, 1 adversary
A has access to the set of oracles O = {Ocast, Oboard, OvoteLR, Otally}.
The adversary is allowed to querry Otally only once. For β = 1 the
experiment also depends on SimProof – we do not show the dependence
explicitly to simplify notation.
the model used for Helios.
B. Strong Consistency
The ballot privacy deﬁnition BPRIV strongly relies on
a split between the result r and the auxiliary data Π re-
turned by the tally. This split should be meaningful, that is
r should correspond to the expected result and should not
contain hidden auxiliary data. To enforce this, we introduce
a companion deﬁnition of BPRIV, called strong consistency,
that has two main goals. Firstly, it ensures that the result
always corresponds to the result function applied to the votes,
and nothing more. Secondly, it controls the damages that an
intentionally leaky revote policy could implicitly cause while
tallying. In fact, since tallying takes as inputs the ballot box
and the secret key, this allows a malicious designer/election
administrator to implement a leaky revote policy. We limit the
damages of such a behaviour by asking the voting scheme to
satisfy a stronger correctness property, that we name strong
consistency.
Intuitively, strong consistency guarantees that
the Tally
algorithm behaves like ρ except possibly on invalid ballots.
(Note that BPRIV is independent of ρ.) We formalize the
requirement by requiring the existence of an “extraction”
algorithm which, with the help of the secret key, can determine
for each ballot the underlying vote and the identity/identiﬁer
with which it was created or ⊥ if the ballot is somehow invalid.
We require that from an honestly created ballot the extraction
algorithm works as desired. Using the extraction algorithm
we can capture the intuition that the Tally algorithm works as
expected: we demand that the result reported for some valid
ballot box BB by Tally is the same as the result function
applied to the votes that underlie the ballots on BB, as deﬁned
using the extraction algorithm.
Deﬁnition 8 (Strong consistency): A scheme V =
(Setup, Vote, Valid, Publish, Tally, Verify) relative to a result
∗ → R has strong consistency if there
function ρ : (I × V)
exist
• an extraction algorithm Extract that takes as input a secret
key sk and a ballot b and outputs (id, v) ∈ I × V or ⊥;
• a ballot validation algorithm ValidInd that takes as input
the public key of the election pk and a ballot b and outputs
(cid:6) or ⊥;
which satisfy the following conditions:
1) For any (pk, sk) that are in the image of Setup and
for any (id, v) ∈ I × V if b ← Vote(pk, id, v) then
Extract(sk, b) = (id, v) with overwhelming probability.
2) For any (BB, b) ← A, Valid(BB, b) = (cid:6) implies
ValidInd(b) = (cid:6).
3) Consider an adversary A which is given pk and consider
the experiment:
Exps-cons
A,V (λ)
(pk, sk) ← Setup(λ);
BB ← A
(r, Π) ← Tally(sk, BB)
If r (cid:8)= ρ(Extract(sk, b1), . . . , Extract(sk, bn))
Then return 1 Else return 0
Above we consider only adversaries A that return BB of the
form [b1, . . . , bn] such that ValidInd(bi) = (cid:6) for i = 1..n. We
require that the probability Pr[Exps-cons
A,V (λ) = 1] is negligible
in the security parameter.
In case the result function ρ does not use voter identiﬁers,
that is
(cid:3)
1, v1), . . . , (id
(cid:3)
n, vn))
ρ((id1, v1), . . . , (idn, vn)) = ρ((id
(cid:3)
j, then the function Extract is not required
for any vj, idj, id
to output the voter identiﬁer.
Informally, strong consistency prevents an adversary from
encoding instructions in her own ballots, causing the tallying to
leak information on the honest votes or prevent the validation
of honestly generated ballot boxes. Indeed,
the extraction
algorithm works “locally” on each ballot so it cannot respond
to instructions encoded in one ballot on how to treat another
ballot or to return no result. This is not
the
tallying algorithm cannot be aware of adversarial instructions
— indeed, it is free to write what it likes to the auxiliary data.
It is only the result that is protected by strong consistency.
The rest is handled by the BPRIV deﬁnition.
to say that
Just like in the case of the ballot privacy deﬁnition, we
started with a vanilla variant of strong consistency that does
not account for global setups. The deﬁnition above can be
extended to this more realistic setup by providing to adversary
508508
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:30 UTC from IEEE Xplore.  Restrictions apply. 
A and to the Tally algorithm access to GlobalSetup initialized,
as usual, via GlobalSetup ← GlobalSetup.init.
C. Strong Correctness
This notion requires a strong independence relation between
honestly created ballots and the ballot box (and the global
setup) in the voting scheme, which we capture by requiring
that an honestly created ballot is valid, even with respect to
an adversarially created ballot box.
Deﬁnition 9 (Strong correctness): Consider an adversary A
against π that takes as input pk and has access to a global
setup GlobalSetup generated as expected. Then,
Pr[(id, v, BB) ← A(pk); b ← Vote(id, v) : Valid(b, BB) (cid:8)= (cid:6)]
is negligible. The probability is over the coins used by the
adversary and Vote, but also over the coins used in the
generation of pk.
D. Necessity of Strong Consistency and Strong Correctness
that
Let us see an example of a voting scheme that satisﬁes
implements a leaky revote policy while
BPRIV but
tallying. Let V be a BPRIV voting scheme for the multiset
result function (i.e. ρ(v1, . . . , vn) outputs {v1, . . . , vn} viewed
as a multiset), such that Publish(BB) = BB, Π = ∅ (i.e.
there are no proofs of correct tallying), Verify(PBB, r,∅) = (cid:6)
(i.e. since there are no tallying proofs, we accept any result
published by the election administrator) and V = {0, 1}. To
simplify further, let us assume that V only allows single voting
(i.e. voters cannot revote).
We build a voting scheme V(cid:3) that inherits BPRIV privacy
from V, but which possibly reveals how the ﬁrst voter voted,
and thus it is, intuitively, not ballot private. V(cid:3) is obtained by
replacing algorithm Tally by Tally(cid:3)
(BB, sk)
ﬁrst checks whether the ﬁrst ballot in BB contains a 1-vote. If
so, removes this ballot from BB, and let BB(cid:3)
be the resulting
ballot box. Finally, outputs Tally(BB(cid:3)
, sk). Let us sketch a
proof that V(cid:3) is BPRIV.
as follows: Tally(cid:3)
In the ﬁrst place, let BB0 contain in its ﬁrst entry a 1-vote,
while BB1 contains in its ﬁrst entry a 0-vote. If β = 0, the
adversary sees ballot box BB0. The output of tallying in this
(BB0, sk) = Tally(BB0 \{b1}, sk). If β = 1, the
case is Tally(cid:3)
adversary sees ballot box BB1, but still sees the same tallying
output Tally(cid:3)
(BB0, sk).
In the second place, let us consider the complementary
case where BB0 contain in its ﬁrst entry a 0-vote, while
BB1 contains in its ﬁrst entry a 1-vote. If β = 0,
the
adversary sees board BB0. The output of tallying in this
case is Tally(cid:3)
(BB0, sk) = Tally(BB0, sk). If β = 1, the
adversary sees board BB1, but still sees the same tallying
output Tally(cid:3)
Finally, if BB0 and BB1 both contain ballots at their ﬁrst
entry for the same vote v ∈ {0, 1}, then Tally(cid:3)
does not
help distinguishing when compared to the original Tally.
Thus, for every adversary A(cid:3) against BPRIV of V(cid:3)
there
exists an adversary A against BPRIV of V with roughly
the same distinguishing advantage. If V is BPRIV, so is V(cid:3).
(BB0, sk).
Unfortunately, V(cid:3) reveals how a honest voter voted, since the
output of Tally tells whether the ﬁrst ballot on BB contains
the vote 1.
Our solution to defeat these leaky revote policies embedded
in Tally is to ask for strong consistency. Indeed, it is easy to see
that V(cid:3) does not satisfy strong consistency. Note that whenever
the ﬁrst ballot of BB is a 1-vote, then running Tally and
running the alternative tally procedure using Extract results
in different outputs.
Regarding the need for strong correctness, let us assume a
BPRIV voting scheme V(cid:3). We build a new voting scheme V
such that ballots b in V are obtained by appending a t-bit to
(cid:3)). The vote algorithm
ballots b
in V just appends a 0-bit to the result of the vote algorithm in
V(cid:3). Tally in V just drops the appended bit from any ballot b
and next applies the tally from V(cid:3). Valid(BB, b) is deﬁned as
follows:
(cid:3) in V(cid:3) (say at the beginning of b
• if there is any ballot in BB starting with 1-bit, rejects b
• otherwise, drops the the appended bit from any ballot
in BB and from b, let BB(cid:3)
(cid:3) be the corresponding
outputs, and computes Valid(cid:3)
(cid:3)
, b
V is BPRIV but not strongly correct. In particular, a
malicious voter can cause votes from honest voters to be
rejected. Actually, this remark also applies to other privacy
deﬁnitions, such as IND-BB.
and b
(BB(cid:3)
)
E. Revote policies
Formalizing revote policies has been rarely done in the
literature on foundations of electronic voting. Previously,
revote policies were considered as an external component of
the voting scheme. Roughly speaking, one used to proceed
as follows. Firstly the cryptographic workﬂow of the voting
protocol is described, next its ballot privacy is proven, and then
the revote policy is decided at the implementation level by
the election administrator. The bottom line is that reasonable
revote policies will not
the ballot privacy of the
underlying voting scheme, so they can chosen independently
of the scheme (we just need to make sure that the protocol
implements the given revote policy).