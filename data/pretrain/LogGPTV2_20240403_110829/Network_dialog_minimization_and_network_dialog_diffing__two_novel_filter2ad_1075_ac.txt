It takes as input a network trace and the goal function. It builds a
network dialog tree from the trafﬁc in the trace and uses the goal
function to remove any connections and messages after the goal
was reached, since they are unrelated to the goal. The core of
NDM is the network delta debugging module, which takes as in-
put the original dialog tree, the goal function, and the reset button.
It implements an iterative process. At each iteration it produces a
test network dialog by removing some elements from the original
dialog. The test dialog is passed to the replayer module, which re-
plays it to the remote peers and passes the responses back to the
network delta debugging module. The responses are checked with
the goal function to determine if the test passed or failed, and a new
test dialog is produced for the next iteration. This iterative process
eventually outputs the minimized dialog.
Network delta debugging. Network delta debugging applies ddmin
at each level of the network dialog tree from the root to the leaves,
using the goal function to determine if a test passed and the reset
button to restart the server state after each test. In a nutshell, ddmin
executes the following 3 steps:
1. Reduce to subset: Split the current conﬁguration into n par-
titions. Test each partition. If a partition reaches the goal,
treat it as the current conﬁguration and go to 1.
2. Reduce to complement: Test the complement of each parti-
tion. If any reaches the goal, treat it as the current conﬁgura-
tion and go to 1.
3. Increase granularity: Split the current conﬁguration into 2n
partitions, where n is the current number of partitions, and go
to 1. If the conﬁguration cannot be split further, the algorithm
outputs the current conﬁguration as the minimized dialog.
Figure 5 details the minimization process for the dialog tree in
Figure 2. First, it applies ddmin to the connections (level 1). Here,
ddmin splits the connections into 2 subsets and tests each subset
separately (tests §1–2). The ﬁrst test contains connection C1 (i.e.,
all messages in C1) and fails to reach the goal. The second test
contains {C2, C3} and this time the goal is reached. The current
conﬁguration is set to {C2},{C3}; the subtree rooted at C1 will no
longer be tested. Next, it reduces the current conﬁguration into 2
subsets, testing C2 and C3 individually (§3–4), both failing to reach
the goal. Since the complements have been tested and the granular-
ity cannot be increased, level 1 minimization outputs C2 and C3.
Next, ddmin is applied to the messages (level 2) of the remaining
     Trace Dialog   Generation Dialog    Tree Test dialog Responses Reset Server Requests Responses  Goal Function Network Delta Debugging  Replayer Minimized dialog  Figure 6: Example of dialog alignment (a) and similarity ma-
trix (b) for two dialogs with 4 and 3 messages respectively.
7. Server header: same value in both responses.
8. Location header: same value in both responses.
9. Content-Type header: same value in both responses.
10. Content length: computes 1− ||L1−L2||
max(L1, L2) where L1, L2 are
the content lengths for both responses (after joining chunks
and decompressing, if needed).
11. Response headers: Jaccard index between the set of response
headers (without values).
(cid:80)
i
Features 1–3, 5–9 are boolean, while 4, 10, and 11 output a value
in [0,1]. RRP similarity simply computes the average of the RRP
fi(RRP1, RRP2).
features: RRP sim(RRP1, RRP2) = 1
11
Message alignment. The ﬁrst step to align the messages in both
dialogs is building an N × N matrix, where N is the maximum
number of nodes in either dialog, and a row captures the similarity
between an RRP in dialog 1 and all RRPs in dialog 2. If a dialog has
less messages than the other, it is padded with dummy RRPs, and
the similarity of any RRP with a dummy RRP is zero. This matrix
can be represented as a complete bipartite graph G = (V1 ∪ V2, E)
where vi ∈ V1 corresponds to an RRP in dialog 1 and vj ∈ V2 to
an RRP in dialog 2. The bipartite graph is complete because there
is an edge between each RRP in one dialog and all RRPs in the
other dialog (vi ∈ V1, vj ∈ V2) weighted by their RRP similarity
score. Figure 6 shows the bipartite graph (a) and similarity matrix
(b) for two dialogs with 4 and 3 messages respectively, the latter
padded with one dummy RRP (N = 4).
Our insight is that aligning the messages in both dialogs cor-
responds to the assignment problem in graph theory, which ﬁnds
the mapping in a weighted bipartite graph that maximizes the total
weight of the mapping. The Hungarian algorithm [22] solves this
problem in polynomial time. The solid lines in Figure 6a corre-
spond to the alignment output by the Hungarian algorithm.
The reader may realize that our approach aligns messages with-
out considering connection structure. This is to handle misaligned
connections, e.g., a connection with 4 messages in one dialog may
align with 2 connections with 2 messages each in the other dialog.
Dialog difﬁng. For the difﬁng, RRPs aligned with similarity 1.0 are
considered identical. RRPs aligned with high similarity (s ≥ 0.7)
are considered changed. RRPs aligned with low similarity (s <
0.7) are considered new. Threshold selection is explained in Sec-
tion 6.5. In Figure 6, the difﬁng outputs two identical RRPs, one
changed, and one new.
Dialog similarity. The dialog similarity is computed by summing
the weights of all alignment edges and dividing by the maximum
number of nodes in a dialog:
sim(D1, D2) =
wi
(1)
N(cid:88)
i=1
1
N
Figure 5: Minimization of the dialog in Figure 2.
connections. The messages are split into 2 subsets, both failing to
reach the goal (§5–6). Here, ddmin increases the granularity to 2n,
halving the message subsets. Thus, M3 and M4 are tested sepa-
rately, both failing (§7–8). Note that M2 had already been tested in
§5. Next, the complement of M3 is tested reaching the goal (§9), so
the current conﬁguration is reduced to {M2},{M4}, but both fail
(§10–11). At this point, level 2 minimization ﬁnishes determining
that messages M2 in C2 and M4 in C3 are required to reach the
goal. We leave level 3 minimization as an exercise to the reader.
Figure 3 shows the resulting minimized dialog.
5. DIALOG DIFFING
Our dialog difﬁng approach ﬁrst computes similarity scores be-
tween messages in both dialogs. Then, it aligns the dialogs by ﬁnd-
ing an optimal mapping between their messages. Once aligned,
common and different parts are output and the dialog similarity
score is computed. The two dialogs are compared on their struc-
ture and message content. Similar dialogs are identiﬁed despite
changes in endpoints (domains, IPs), message reordering, and dif-
ferent number of connections and messages in both dialogs. End-
points often change with malware since C&C domains and IPs are
frequently updated, and also with benign dialogs if CDNs or load
balancers are involved. Many HTTP dialogs contain asynchronous
connections producing alternative message and connection order-
ings, which do not affect the dialog semantics. Furthermore, while
different number of messages make the dialogs less similar, it is
still possible to ﬂag similarity if the spurious messages are few.
RRP similarity. Rather than comparing individual messages, our
approach compares HTTP request-response pairs (RRPs). RRP
similarity uses 11 features:
1. Request type: same HTTP method in both requests.
2. URL path: same path in both requests’ URL.
3. URL ﬁlename: same ﬁlename in both requests’ URL.
4. URL parameters: Jaccard index of the sets of parameter names
(without values) in the URLs of both requests.
5. Referer: same value of the Referer header in both requests.
6. Response type: same response code and response status in
both responses.
In Figure 6, sim(D1, D2) = 2.9/4 = 0.725.
1C1 . .no2 .C2C3yes3 .C2 .no4 . .C3noRes. .C2C3doneTest casesGoal 5 M2 . .no6  .M3M4no7  M3 . no8  . .M4no9  M2 .M4yes10  M2 ..no11   . .M4noRes.  M2 .M4doneLevel 2Testing {M2}, {M3, M4} Increase granularity Testing {C1}, {C2, C3}Testing complements, Level 1 minimized. Removing C1 and its children from dialog tree. Level 1Starting NDM Level 2 minimized. Removing M3 and its children from dialog tree. Reduce to {C2, C3} Reduce to {M2, M4}  Testing {M3}, {M4} Testing {C2}, {C3}Testing {M2}, {M4}GET /302 FoundP11P12P13P14P21P22P23P24GET /200 OK GET /302 FoundPOST /login.php404 Not FoundGET /favicon.ico 200 OKDummyDialog1Dialog2 GET /200 OK 0.90.50.100.10.41.000.51.00.400.10.10.10P11P12P13P14P21P22P23P24(a) Dialog alignment (b) Similarity matrix 0 0.5 0.4 0.1 0.90.4 0.5 0 0 1.00.1 1.0 0 0.1 0.1 0.1 GET /favicon.ico 200 OKExploit
Kit
BlackHole 1.x
CoolExploit
CritiXPack
Eleonore
Phoenix
ProPack
RedKit
Serenity
Unknown
Dialog Generation
Pre-ﬁltering
Nodes
73
646
192
936
132
137
154
54
79
C:M:F
6:6:60
18:58:569
4:19:168
12:76:848
12:12:107
10:12:114
8:17:128
5:5:43
5:7:66
Filtered
C:M:F
5:5:50
5:5:49
2:7:62
8:66:736
7:7:73
6:6:57
2:6:57
5:5:43
5:7:66
IPs
2
2
2
2
1
2
1
1
2
Network Delta Debuging
L1
C:M:F
2:2:22
1:1:7
1:4:33
1:1:8
1:1:7
1:1:7
2:6:57
2:2:15
1:2:14
L2
C:M:F
2:2:22*
1:1:7*
1:1:7
1:1:8*
1:1:7*
1:1:7*
2:2:19
2:2:15*
1:1:7
L3
C:M:F
2:2:6
1:1:3
1:1:3
1:1:4
1:1:3
1:1:3
2:2:10
2:2:6
1:1:3
Tree
Nodes
11
6
6
7
6
6
15
11
6
IPs GDT
used
Pref.
33
15
17
27
15
15
71
28
18






