timestamp, t, we have two vectors of the following form:
(cid:126)a(t) = (ax, ay, az) and (cid:126)ω(t) = (ωx, ωy, ωz). The accelerom-
eter values include gravity, i.e., when the device is stationary
lying ﬂat on top of a surface we get a value of 9.81ms−2 along
the z-axis. We convert the acceleration vector into a scalar by
taking its magnitude: |(cid:126)a(t)| =
z. This technique
a2
x + a2
(cid:113)
y + a2
Seismic MassMovableAnchorFixed Electrode1dd2mYXZωvF         = −2m    * vCoriolisωDomain
Time
Frequency
#
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
Standard Deviation
Average Deviation
Feature
Mean
Skewness
Kurtosis
RMS
Max
Min
ZCR
Non-Negative count
Spectral Centroid
Spectral Spread
Spectral Skewness
Spectral Kurtosis
Spectral Entropy
Spectral Flatness
Spectral Brightness
Spectral Rolloff
Spectral Roughness
Spectral Irregularity
Spectral RMS
Low-Energy-Rate
Spectral ﬂux
Spectral Attack Time
Spectral Attack Slope
TABLE II: Explored temporal and spectral features
Description
The arithmetic mean of the signal strength at different timestamps
Standard deviation of the signal strength
Average deviation from mean
Measure of asymmetry about mean
Measure of the ﬂatness or spikiness of a distribution
Square root of the arithmetic mean of the squares of the signal strength at various timestamps
Maximum signal strength
Minimum signal strength
The rate at which the signal changes sign from positive to negative or back
Number of non-negative values
Represents the center of mass of a spectral power distribution
Deﬁnes the dispersion of the spectrum around its centroid
Represents the coefﬁcient of skewness of a spectrum
Measure of the ﬂatness or spikiness of a distribution relative to a normal distribution
Captures the peaks of a spectrum and their locations
Measures how energy is spread across the spectrum
Amount of spectral energy corresponding to frequencies higher than a given cut-off threshold
Deﬁnes the frequency below which 85% of the distribution magnitude is concentrated
Average of all the dissonance between all possible pairs of peaks in a spectrum
Measures the degree of variation of the successive peaks of a spectrum
Square root of the arithmetic mean of the squares of the signal strength at various frequencies
The percentage of frames with RMS power less than the average RMS power for the whole signal
Measure of how quickly the power spectrum of a signal changes
Average rise time to spectral peaks
Average slope to spectral peaks
discards some information, but has the advantage of making
the accelerometer data independent of device orientation; e.g.,
if the device is stationary the acceleration magnitude will
always be around 9.81ms−2, whereas the reading on each
individual axis will vary greatly (by +/- 1g) depending on how
the device is held. For the gyroscope we consider data from
each axis as a separate stream, since there is no corresponding
baseline rotational acceleration. In other words, if the device
is stationary the rotation rate across all three axes should be
close to 0 rads−1, irrespective of the orientation of the device.
Thus, our model considers four streams of sensor data in the
form of {|(cid:126)a(t)|, ωx(t), ωy(t), ωz(t)}.
For all data streams, we also look at frequency domain
characteristics. But since the browser, running as one of many
applications inside the phone, makes API calls to collect sensor
data the OS might not necessarily respond in a synchro-
nized manner2. This results in non-equally spaced data points.
We, therefore, use cubic-spline interpolation [47] to construct
new data points such that {|(cid:126)a(t)|, ωx(t), ωy(t), ωz(t)} become
equally-spaced.
B. Temporal and Spectral Features
To summarize the characteristics of a sensor data stream,
we explore a total of 25 features consisting of 10 temporal and
15 spectral features (listed in Table II). All of these features
have been well documented by researchers in the past. A
detailed description of each feature is available in our technical
report [48].
the source sensor. Any supervised learning classiﬁer has two
main phases: training phase and testing phase. During training,
features from all smartphones (i.e., labeled data) are used to
train the classiﬁer. In the test phase, the classiﬁer predicts
the most probable class for a given (unseen) feature vector.
We evaluate the performance of the following classiﬁers —
Support Vector Machine (SVM), Naive-Bayes classiﬁer, Mul-
ticlass Decision Tree, k-Nearest Neighbor (k-NN), Quadratic
Discriminant Analysis classiﬁer and Bagged Decision Trees
(Matlab’s Treebagger model) [49]. We found that
in gen-
eral ensemble based approaches like Bagged Decision Trees
outperform the other classiﬁers. We report
the maximum
achievable accuracies from these classiﬁers in the evaluation
Section V.
Evaluation metrics: For evaluation metric we use standard
multi-class classiﬁcation metrics like—precision, recall, and F-
score [50]—in our evaluation. Assuming there are n classes,
we ﬁrst compute the true positive (T P ) rate for each class,
i.e., the number of traces from the class that are classiﬁed
correctly. Similarly, we compute the false positive (F P ) and
false negative (F N) as the number of wrongly accepted and
wrongly rejected traces, respectively, for each class i (1 ≤ i ≤
n). We then compute precision, recall, and the F-score for each
class using the following equations:
Precision, P ri = T Pi/(T Pi + F Pi)
Recall, Rei = T Pi/(T Pi + F Ni)
F-Score, Fi = (2 × P ri × Rei)/(P ri + Rei)
(1)
(2)
(3)
C. Classiﬁcation Algorithms and Metrics
Classiﬁcation Algorithms: Once we have features extracted
from the sensor data, we use supervised learning to identify
2Depending on the load and other applications running, OS might
prioritize such API calls differently.
The F-score is the harmonic mean of precision and recall; it
provides a good measure of overall classiﬁcation performance,
since precision and recall represent a trade-off: a more con-
servative classiﬁer that rejects more instances will have higher
precision but lower recall, and vice-versa. To obtain the overall
performance of the system we compute average values in the
4
following way:
Avg. Precision, AvgPr =
Avg. Recall, AvgRe =
Avg. F-Score, AvgF =
(cid:80)n
(cid:80)n
i=1 P ri
n
i=1 Rei
n
2 × AvgP r × AvgRe
AvgP r + AvgRe
(4)
(5)
(6)
V. FINGERPRINTING EVALUATION
In this section we ﬁrst describe our experimental setup
(Section V-A). We then explore features to determine the
minimal subset of features required to obtain high classiﬁcation
accuracy (Section V-B). Lastly, we evaluate our ﬁngerprinting
approach under a controlled lab setting (Section V-C), an un-
controlled real-world setting (Section V-D) and a combination
of both settings (Section V-E).
A. Experimental Setup
Given that mobile accounts for a third of all global web
pages served [51], our experimental setup consists of develop-
ing our own web page to collect sensor data3. We use a simple
Javascript (code snippet available in Appendix A) to access
accelerometer and gyroscope data. However, since we collect
data through the browser the maximum obtainable sampling
frequency is lower than the available hardware sampling fre-
quency (restricted by the underlying OS). Table III summarizes
the sampling frequencies obtained from the top 5 mobile
browsers [52]4. We use a Samsung Galaxy S3 and iPhone
5 to test the sampling frequency of the different browsers.
Table III also highlights the motion sensors that are accessible
from the different browsers. We see that Chrome provides the
best sampling frequency while the default Android browser
is the most restrictive browser in terms of not only sampling
frequency but also access to different motion sensors. However,
Chrome being the most popular mobile browser [53], we
collect data using the Chrome browser.
TABLE III: Sampling frequency from different browsers
OS
Android 4.4
iOS 8.1.3
Browser
Chrome
Android
Opera
UC Browser
Standalone App [54]
Safari
Standalone App [55]
Sampling
Frequency (∼Hz)
100
20
40
20
200
40
100
Accessible
Sensorsa
A,G
A
A,G
A,G
A,G
A,G
A,G
ahere ‘A’ means accelerometer and ‘G’ refers to gyroscope
We start off our data collection from 30 lab-smartphones.
Table IV lists the distribution of the different smartphones
from which we collect sensor data. Now, as gyroscopes react
to audio stimulation we collect data under three different
background audio settings: no audio, an inaudible 20 kHz
sine wave, or a popular song. In the latter two scenarios,
the corresponding audio ﬁle plays in the background of the
browser while data is being collected. Under each setting we
collect 10 samples where each sample is about 5 to 8 seconds
3http://datarepo.cs.illinois.edu/DataCollectionHowPlaced.html
4Computed the avg. time to obtain 100 samples. http://datarepo.cs.illinois.
edu/SamplingFreq.html
5
worth of data. Now, since our ﬁngerprinting approach aims to
capture the inherent imperfections of motion sensors, we need
to keep the sensors stationary while collecting data. Therefore,
by default, we have the phone placed ﬂat on a surface while
data is being collected, unless explicitly stated otherwise. We,
however, do test our approach for the scenario where the user
is holding the smartphone in his/her hand while sitting down.
For training and testing the classiﬁers we randomly split
the dataset in such a way that 50% of data from each device
goes to the training set while the remaining 50% goes to the
test set. To prevent any bias in the selection of the training
and testing set, we randomize the training and testing set 10
times and report the average F-score. We also compute the
95% conﬁdence interval, but we found it to be less than 1%
in most cases and hence do not report them in such cases. For
analyzing and matching ﬁngerprints we use a desktop machine
with an Intel i7-2600 3.4GHz processor with 12GiB RAM. We
found that the average time required to match a new ﬁngerprint
was around 10–100 ms.
TABLE IV: Types of phones used
Maker
Quantity
Apple
Model
iPhone 5
iPhone 5s
Nexus S
Galaxy S3
Galaxy S4
Samsung
Total
4
3
14
4
5
30
B. Feature Exploration and Selection
therefore, explore all
At ﬁrst glance, it might seem that using all features to
identify the device is the optimal strategy. However, including
too many features can worsen performance in practice, due to
their varying accuracies and potentially-conﬂicting signatures.
We,
the features and determine the
subset of features that optimize our ﬁngerprinting accuracy.
For temporal features, no transformation of the data stream
is required, but for spectral features we ﬁrst convert the non-
equally spaced data stream into a ﬁxed-spaced data stream
using cubic spline interpolation. We interpolate at a sampling
rate of 8kHz5. Then, we use the following signal analytic tools
and modules: MIRtoolbox [56] and Libxtract [57] to extract
spectral features. We next look at feature selection where we
explore different combinations of features to maximize our
ﬁngerprinting accuracy. We use the FEAST toolbox [58] and
utilize the Joint Mutual Information criterion (JMI criterion
is known to provide the best tradeoff in terms of accuracy,
stability, and ﬂexibility with small data samples [59]) for
ranking the features.
Figure 3 shows the results of our feature exploration for the
30 lab-smartphones. We see that when using only accelerome-
ter data the F-score seems to ﬂatten after considering the top 10
features. For gyroscope data we see that using all 75 features
(25 per data stream) achieves the best result. And ﬁnally when
we combine both accelerometer and gyroscope features, the
5Although up-sampling the signal from ∼100 Hz to 8 kHz does not
increase the accuracy of the signal, it does make direct application of standard
signal processing tools more convenient.
Fig. 3: Exploring the number optimal features for different sensors. a) For accelerometer using more than top 10 features leads to diminished
returns, b) For gyroscope all 75 features contribute to obtaining improved accuracy, c) For the combined sensor data using more than 70
features leads to diminished returns.
top 70 features (from a total of 100 features) seems to provide
the best ﬁngerprinting accuracy. Among these top 70 features
we found that 21 of them came from accelerometer features
and the remaining 49 came from gyroscope features. In terms
of the distribution between temporal and spectral features, we
found that spectral features dominated with 44 of the top 70
features being spectral features. We use these subset of features
in all our later evaluations.
C. Results From Lab Setting
First, we look at ﬁngerprinting smartphones under lab
setting to demonstrate the basic viability of the attack. For
this purpose we keep smartphones stationary on top of a
ﬂat surface. Table V summarizes our results. We see that
we can almost correctly identify all 30 smartphones for all
three scenarios by combining the accelerometer and gyroscope
features. Even when devices are kept
in the hand of the
user we can successfully identify devices with an F-score
of greater than 93%. While the beneﬁt of the background
audio stimulation is not clear from the table, we will later on
show that audio stimulation do in fact enhance ﬁngerprinting
accuracy in the presence of countermeasure techniques like
sensor calibration and data obfuscation (more in Section VI).
Overall
is indeed possible to
ﬁngerprint smartphones through motion sensors.
these results indicate that
it
TABLE V: Average F-score under lab setting
Avg. F-score (%)
Gyroscope
Accelerometer+Gyroscope
Device
Placed
On Desk
In Hand
Stimulation
No-audio
Sine
Song
No-audio
Sine
Song
Accelerometer
96
98
93
88
88
84
95
99
98
83
94