While it is useful for the attacker to have access to e-mail lists that she can readily query,
it is also interesting for her to automatically generate new e-mail addresses that she
could then re-validate against the social networks. Using the e-mail guesser as discussed
earlier, we are able to generate addresses that we do not previously know, and verify
their existence in social networks. By starting with 650 proﬁles and using straight-
forward automated e-mail guessing techniques, we were able to identify the e-mails of
about 20,000 users along with their associated proﬁles (a thirty-fold increase compared
to the initial proﬁle set). Hence, our experiment demonstrated that even if the attacker
does not have access to a large e-mail database, by starting with a small set, she can still
successfully guess addresses and identify thousands of new proﬁles.
4.4 Detecting Anomalous Proﬁles by Cross-Correlation
In the following, we present the output of the correlation phase, and we discuss sev-
eral interesting examples of anomalous proﬁles we automatically discovered during our
empirical experiments.
Discovering Mismatched Proﬁles. Based on the data provided by the different social
networks, we conﬁgured the Correlator to analyze six information ﬁelds that are popular
among the different social networks we examined: Name, location, age, sex, current
relationship, and sexual preference.
Before proceeding to the comparison, we had to normalize the values provided in
the different social networks to a common dictionary. For example, sex was translated
to either “male” or “female,” while the current relationship and the sexual preference’s
values were translated into a set of common keywords built from an analysis of the en-
tire dataset. For instance, values like “heterosexual,” “straight,” and “man looking for
women” were all translated into the keyword “heterosexual.” Likewise, we normalized
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
434
M. Balduzzi et al.
Table 7. Information provided on multiple proﬁles belonging to the same user
# of Occurrences on X networks
Information
Name
Location
Age
Sex
Sexual preference
Current relation
3
4
5
2
6 7
Total
199,161 55,660 11,483 1,478 159 11 267,952
24,873
22,583 2,102
20,085
887
19,135
18,170
854
17,282
760
13
773
1,691
38
1,652
174
36
34
11
3
1
the current relationship ﬁeld to one of the four following values: “Single,” “in a rela-
tionship,” “married,” and “complicated.” Finally, we ﬁltered the geographical location
by comparing the ﬁeld (or part of it) against a dictionary of more than 260,000 cities.
Table 7 shows the number of users that provide a certain information on multiple
social networks. For example, 22,583 users included their location on two networks,
2,102 on three networks, and 174 on four networks. Since the name is a mandatory
ﬁeld, the ﬁrst line of the table matches the number of proﬁles reported in Table 2.
For each ﬁeld, the Correlator computed the total number of distinct values provided
by the same users across different networks. For example, if Alice is registered on three
social networks where she provides as age 26, 26, and 22 the Correlator reports two
mismatched values.
Table 8. Overview of proﬁles where a mismatch was detected - Data are normalized.
Information
Name
Location
Age
Sex
Sexual preference hetero, homo, bi
Current relation
Value
string
city
0 < n < 100
m, f
single, relationship,
married, complicated
mismatches
2
% Total % of mismatched values
4+
17.66
3.72
30.56
3
72.65 62.70 35.37
53.27 51.74 16.24
34.49 33.58 17.84
12.18 12.18
7.63 7.63
35.54 35.42 5.13
Table 8 summarizes the results. The ﬁrst column shows the percentage of proﬁles,
from the total shown in Table 7, for which the Correlator found mismatching values.
About one-third of the people seems to misrepresent their current relationship status,
declaring, for example, to be single on one network and to be married on a second one.
It is also interesting to note that 2,213 users (12% of the ones registered in more than
one network) pretend to be male on a network and female on a different one. The very
high percentage of people using different names is a consequence of various factors.
First, the name comparison is more problematic because, as explained in Section 2, we
only store the MD5 of the names to preserve the users privacy. This means that we
lose the ability to distinguish between small differences and completely fake names.
Second, in some social networks, it is very common to provide a nickname instead of
Abusing Social Networks for Automated User Proﬁling
435
the real user name. For example, John Doe on LinkedIn may appear simply as JDoe77
on MySpace.
The last three columns in Table 8 show how many unique values where provided by
the same user (either two, three, or more) on different social networks. These percent-
ages are normalized by the number of accounts owned by the user. That is, a value of
10% in Column 3 means that 10% of the people that own an account on at least three
social networks provided three different values for that speciﬁc ﬁeld.
Mismatches in Provided Age Information. Five of the eight social networks we ex-
amined either offer the possibility for a user to specify his age, or automatically com-
pute this information from the user’s birthday. During our experiments, the Correlator
automatically found a total of more than 20,000 users for which we had at least two
proﬁles on different networks which also included the person’s age. Surprisingly, about
one-third of these users (6,919) showed a mismatch for the age information provided in
the different proﬁles (see Table 9 for details). This number only includes those proﬁles
in which the difference of age is at least two years. In fact, a mismatch of only one year
is likely to be the consequence of outdated proﬁles (i.e., if a user needs to manually
specify his age, he might forget to update the value at each birthday).
Table 9. Overview of proﬁles where a mismatch was detected in the age.
#
Range
2 - 10
11 - 30
31 +
Proﬁles with Age 20,085
Total mismatched 6,919
%
4,163 60.17
1,790 25.87
966 13.96
Among the proﬁles with an age that differs more than two years, we were able to
identify 712 users (10% of this set) who claim to be underage, even though they appear
to be more than 18 years old in another networks (or vice versa). For example, we
observed that many teenagers increase their age to register to Badoo, since the site
restricts its access to adults only.
A Short Glimpse into Hidden Proﬁles. Probably the most serious consequence of
the attack presented in this paper is the ability to uncover hidden relationships between
different proﬁles, allowing an attacker to infer private information about a subject.
By looking at the results of our experiments, it is possible to ﬁnd examples of pos-
sibly hidden proﬁles and online identities that users probably wish to keep secret. As a
proof of concept of the impact that correlating proﬁle information can have on a user’s
privacy, we picked some random proﬁles that showed mismatching values. In one case,
a married person owned an account on a dating-related social network under a different
name, with a list of friends who were much younger. While such information may be
a complete misinterpretation, nevertheless, there may be many cases where an attacker
may try to use the information to his advantage.
436
M. Balduzzi et al.
Because of the ethically sensitive aspects of analyzing this kind of interconnections,
we did not perform an in-depth investigation of the problem, limiting the result of our
analysis to aggregated ﬁgures.
5 Countermeasures
In this section, we present several mitigation strategies that can be used to limit the
extent of our attack. Each approach has its own advantages and limitations, which we
review in the rest of the section. We discussed the different countermeasures with sev-
eral popular social network providers to incorporate also their view of the problem,
especially considering the operational practicability of each proposed solution.
1) Raising Awareness: Mitigation From the User’s Perspective. Clearly, if users were to
use a different e-mail address on each social networking site, it would become more dif-
ﬁcult for the attacker to automatically correlate the extracted information. Because the
e-mail address is the unique ID that identiﬁes a speciﬁc user, an effective defense tech-
nique would be to educate users to use a different e-mail address each time they register
for and enter personal information into a social networking site. Unfortunately, educat-
ing users on security and privacy issues is not an easy task. Often, users may choose
to ignore the risks and opt for the ease of use (e.g., analogous to users using the same
password across many web sites – which has been reported to be quite common [16]).
2) Possible Solution: CAPTCHAs. When searching for e-mail addresses, a user could
be forced to solve a CAPTCHA (i.e., a type of challenge-response test which is hard
to solve for a computer [17]). This would prohibit automated, large-scale queries to a
certain extent since CAPTCHAs cannot be (easily) solved by a computer.
However, introducing this kind of countermeasure has three main drawbacks. First,
the user experience is reduced if a user needs to solve a CAPTCHA frequently, and
this should be avoided by all means. Even if solving a CAPTCHA is only required
for users that perform many queries, the network operators tend to dislike this mitiga-
tion strategy due to a potential negative user experience. Second, using this approach
is not a real solution to the problem since an attacker can also hire real people to solve
the challenge-response tests. This type of service is surprisingly cheap on the under-
ground market, with 1,000 solved CAPTCHAs costing about $2 [18]. Third, different
CAPTCHA systems are prone to attack such that a computer can solve the test with a
reasonable success rate, completely defeating the countermeasure [19,20,21].
3) Possible Solution: Contextual Information. Another potential approach to mitigate
the problem is to require contextual information for each query. If a user U wishes to
search for his friends F1, F2, . . . Fn, he has some context information for each of them
that he should include in his query. For example, a user knows the full name of each
friend, he can estimate their age, or knows their approximate location. It is probable
that the attacker lacks this kind of information.
Unfortunately, it is inconvenient for a user to provide contextual information to per-
form a query. While a user can, for example, store the full name together with the e-mail
Abusing Social Networks for Automated User Proﬁling
437
address within the address book application, this information might no be available for
all friends. Furthermore, additional contextual information such as age or location needs
to be provided manually. As a result, this solution is likely not feasible from an opera-
tional point of view.
4) Possible Solution: Limiting Information Exposure. Our attack is possible since the
search result contains a mapping between the queried e-mail address and the proﬁle
name (if an account with this e-mail address is registered). Thus, a viable option to
prevent our attack is to not return a mapping between e-mail address and proﬁle name
in the search result. This could, for example, be implemented by simply returning a
list of registered accounts in a random order, without revealing which e-mail address
belongs to which account. Note that a user typically does not need the correct mapping,
he is only interested in the fact that one of his friends is registered on the social network
such that she can add him to his friends list.
5) Possible Solution: Incremental Updates. Another fact that enables our attack is the
huge number of searches we can perform: We can query thousands of e-mail addresses
at once, and also repeat this process as often as we wish. A natural approach for miti-
gation is, thus, to implement some kind of limitation for the queries a user is allowed to
perform. For example, by enforcing incremental updates, a user is allowed to initially
query many e-mail addresses, but this step can only be performed once. This enables
a user to search for his current friends on the given social network in the beginning.
Afterwards, the number of queries can be restricted to only a small number of e-mail
addresses (for example only 50). This enables a user to incrementally extend his net-
work, but also limits the number of e-mail addresses a user can search for.
6) Possible Solution: Rate-limiting Queries. Another viable option to limit our attack
is rate-limiting the number of queries: That is, we restrict the (total) number of queries
a user can send to the social network, therefore limiting the amount of e-mail addresses
a given user can check. An option could be to either rate-limit the number of queries
(e.g., only two large queries per week) or have a total upper bound of e-mail addresses
a user can search for (e.g., a total of 10K e-mail addresses a user can check).
Most social network providers already have different kinds of rate-limiting in place.
For example, rate-limiting is used to prohibit automated crawling of their site, or reg-
ulating how many messages a given user can send per day to stop spamming attacks.
Therefore, rate-limiting the number of e-mail searches a user is allowed to perform ﬁts
into the operational framework of these sites. When we contacted the most popular so-
cial network providers, the majority of them preferred this solution. In the meantime,
Facebook and XING have already implemented this countermeasure and now limit the
number of lookups that can be performed by a single source.
Limitations of the Countermeasures. Note that although there is much room for im-
provement in defending against e-mail-to-account mapping information leakage at-
tacks, the attacker could still extract information from the social networking site for
speciﬁc, targeted users (e.g., by only sending e-mail queries consisting of a single user).
Hence, if social networking sites choose to provide e-mail searching functionality, there
438
M. Balduzzi et al.
is always a potential for misuse and the privacy of the users may be at risk. However,
the countermeasures we described in this section raise the difﬁculty bar for the attacker,
mitigating the problem at least on a large scale.
6 Related Work
The large popularity of social networks and the availability of large amounts of personal
information has been unprecedented on the Internet. As a result, this increasing popu-
larity has lead to many recent studies that examine the security and privacy aspects of
these networks (e.g., [3,4,7,22,23,24,25,26]). As more and more Internet users are reg-
istering on social networking sites and are sharing private information, it is important
to understand the signiﬁcance of the risks that are involved.
The structure and topology of different social networks was examined by different
research groups (e.g., [27,28,29,30]). The main focus of previous work was either on
efﬁcient crawling or on understanding the different aspects of the graph structure of
social networks. We extend previous work by contributing a novel way to enumerate
users on social networks with the help of e-mail lookups. Furthermore, we implemented
several efﬁcient crawlers for social networks and – to the best of our knowledge – we
are the ﬁrst to perform large-scale crawls of eight social networks.
Our attack is facilitated by the fact that an attacker can use an e-mail address to link
proﬁles on different social networks to a single user. The idea of correlating data from
different sources to build a user proﬁle has been studied in different contexts before.
For example, Grifﬁth and Jakobsson showed that it is possible to correlate informa-
tion from public records to better guess the mother’s maiden name for a person [31].
Heatherly et al. [32], and Zheleva and Getoor [33] recently showed that hidden infor-
mation on a user’s proﬁle can also be inferred with the help of contextual information
(e.g., the political afﬁliation of a user can be predicted by examining political afﬁliation
of friends).
Concurrently and independently of our work, Irani et al. [14] performed a similar
study of social networks. They showed that it is straightforward to reconstruct the iden-
tify (what they call the social footprint) of a person by correlating social network pro-
ﬁles of different networks. The correlation is done either by using the user’s pseudonym
or by inferring it from the user’s real name. In contrast, our work focuses on automated
techniques to ﬁnd proﬁles of the same person on different networks. In fact, due to the
friend-ﬁnder weakness that we discovered on all tested networks, we are able to asso-
ciate proﬁles by e-mail addresses. As a result, we produce a more precise correlation:
On one hand, we can make sure that different proﬁles belong to the same individual
(Irani et al. have a positive score of only 40% for the pseudonym match and 10%-30%
for the real name match). On the other hand, we can reveal the “‘hidden proﬁles” of
users that they may actually wish to hide. Indeed, this is a major advantage of our
approach; we can link proﬁles that are registered using different pseudonyms or infor-
mation, but based on the same e-mail address. Finally, we conducted our studies on a
larger set of data by crawling 876,941 unique proﬁles (versus 21,764 proﬁles studied
by Irani et al.) and extracting up to 15 information ﬁelds from each proﬁle (versus 7).
Also, note that our work is also related to the area of de-anonymization, where an
attacker tries to correlate information obtained in different contexts to learn more about
Abusing Social Networks for Automated User Proﬁling
439
the identity of a victim. Narayanan and Shmatikov showed that by combining data with
background knowledge, an attacker is capable of identifying a user [34]. They applied
their technique to the Internet movie database (IMDb) as background knowledge and
the Netﬂix prize dataset as an anonymized dataset, and were indeed able to recognizes
users. Furthermore, the two researchers applied a similar technique to social networks
and showed that the network topology in these networks can be used to re-identify
users [35]. Recently, Wondracek et al. [36] introduced a novel technique based on social
network groups as well as some traditional browser history-stealing tactics to reveal
the actual identity of users. They based their empirical measurements on the XING
network, and their analysis suggested that about 42% of the users that use groups can