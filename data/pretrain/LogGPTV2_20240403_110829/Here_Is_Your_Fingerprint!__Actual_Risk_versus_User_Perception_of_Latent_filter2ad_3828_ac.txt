### Image Post-Processing
Figure 3-(vii) illustrates the result of the combination method. It is important to note that this method can be extended to incorporate more than one exactly matched Ti images. Additionally, images in Ts can also be utilized if they meet higher quality standards.

### Algorithm 1: Partial Image Cropping
**Input:**
- `descriptorH`
- `descriptorTs`
- `Ts`

**Output:**
- `T'`

1. `L_home = (0, 0) - descriptorH;`
2. `R_home = (250, 250) - descriptorH;`
3. `L_screen = descriptorTs + L_home;`
4. `R_screen = descriptorTs + R_home;`
5. `Crop(L_screen, R_screen);`

### Algorithm 2: Quality Assessment & Decision
**Input:**
- `nH`
- `nT'`
- `nH_inner`
- `bH_inner`

**Output:**
- `replace method`
- `combination method`

1. If `nT' >= nH`:
   - Return `replace method`.
2. Else if `nH > nT'`:
   - If `nH_inner / bH_inner >= 0.6`:
     - Return `combination method`.
   - Else if `nH_inner / bH_inner < 0.6`:
     - Return `replace method`.

### Algorithm 3: Combination Method
**Input:**
- `descriptorH`
- `descriptorTs`

**Output:**
- `H'` (overlapping Hd with corresponding blocks of T')

1. `blocksize = 25;`
2. For each block `Bi, j ∈ Hd`:
   - `L_homei, j = L(Bi, j) - descriptorH;`
   - `R_homei, j = R(Bi, j) + blocksize - descriptorH;`
   - `L_screeni, j = descriptorTs + L_homei, j;`
   - `R_screeni, j = descriptorTs + R_homei, j;`
   - `Overlap(L(Bi, j), R(Bi, j), L_screeni, j, R_screeni, j);`
3. End for

### Verification
We verified the fingerprint images reconstructed by the SCRAP attack using software. Specifically, we used the NBIS MINDTCT and BOZORTH3 packages to measure fingerprint image quality, minutiae quality, and match scores. This approach is considered a reasonable method for validation in our paper. Note that actual forgery attacks are covered in our separate follow-up work [26].

To measure match scores and for comparison, we prepared template images, which are sets of high-quality, firmly impressed fingerprint images. These fingerprints were taken using a touch screen cleaned with alcohol and then cut into smaller sizes. The three templates showed match scores between 21 and 32 (Mdn = 24) in cross-validation, as shown in Figure 5. The match score may vary depending on the nature of the user's fingerprint, but a score of 40 or higher typically indicates a true match for a full fingerprint [40]. Therefore, we use the median value of each user’s template scores as a reference point for success in our experiment. This method is reasonable for measuring the quality of a partial, limited portion of the fingerprint. In Figure 5, the hatched area above the reference point indicates a successful reconstruction, i.e., the fingerprint images were reconstructed with good quality.

To consider the actual area required for small touch sensors, we used the second generation Touch ID, which is larger than other related sensors. We cut the reconstructed fingerprint images and the template images into a circular shape according to the size of the Touch ID (200 × 200 pixels) and used these to verify image quality. Each image was handled as a 250 × 250 pixel image filled with a white background, as shown in Figure 6.

### Actual Risk: Attack Experiments
To understand the actual risk of our attack in realistic scenarios, we conducted an empirical study with user participation.

#### Methodology
We used an iPhone 6 for Touch ID users in our study and set the privacy policy to remove and never reuse user data after the study.

**Study Design:**
- We set six conditions to simulate realistic scenarios.
- Participants were asked to enroll at least one fingerprint for Touch ID and perform each scenario in sequence.
- Before starting each task, participants were asked to lightly rub the iPhone with a cloth.

**Conditions:**
1. **Tapping:** An ideal condition where the user taps on the touch screen. Participants tapped apps and keys for one minute.
2. **Passcode-typing:** A casual use case where the user types a passcode using a virtual keypad in the middle of the touch screen. Participants typed a random passcode.
3. **Text-typing:** Another use case where the user types text messages using a virtual keyboard at the bottom of the touch screen. Participants typed any text they wanted for two minutes.
4. **Facebook:** An active use case where the user taps, swipes, and types on the touch screen. Participants used Facebook for two minutes.
5. **In-pocket:** A harsh condition where the user puts the smartphone in a pocket. Participants put the iPhone in a back pocket and walked around eight meters after using it for one minute.
6. **Wiping:** Another harsh condition where the user intentionally wipes the touch screen. Participants wiped the iPhone after using it for one minute, as they would in daily use.

After completing a single task, we collected latent fingerprints in another room and returned the iPhone for the next task. The collected images were temporarily stored in our local computer for further analysis. When the participant completed all tasks, we removed the enrolled fingerprint from Touch ID, polished the iPhone with alcohol, and asked them to impress firm fingerprints of the enrolled finger on a clean touch screen, repeatedly for three times, for later verification of constructed fingerprints. We then collected these fingerprints in our photographic setup and set them as template images.

We proceeded with the remaining steps of the SCRAP attack and used the template images for verification as in Section 3.6.

#### Results
We recruited seven participants (three female, right-handed, average age 26, SD = 2.71) from a local university after IRB approval. Each participant spent about 30 minutes on the experiments and was compensated with a small gratuity.

**Latent Fingerprint Collection:**
- We collected 403 latent fingerprint images (361 on the touch screen and 42 on the home button) from 42 user tasks (seven users in six conditions).
- The Tapping condition produced the most latent fingerprints (73, Mean = 10.43, SD = 2.44), while the In-pocket condition showed the least (42, Mean = 6, SD = 3.06).

We used a one-way ANOVA test to compare the average number of latent fingerprint images across conditions. There were significant differences (F(5, 41) = 3.549, p < .05). By Fischer LSD post-hoc test, we observed significant differences between the group of Tapping, Passcode-typing, Text-typing, Facebook, and the group of In-pocket, Wiping (p < .05, respectively). The In-pocket and Wiping conditions are more likely to damage latent fingerprints due to contact with pants, palms, or fingers.

**Constructed Fingerprint Verification:**
- We computed 42 sets of match scores (six conditions × seven participants) for each fingerprint image.
- Figure 7 depicts the results of 42 cases. M(x) denotes the match score of x for Raw-captured, Template, and reConstructed fingerprint images based on the regulation used in Section 3.6.
- A success is marked with (cid:88) for the case that M(R) < M(T) ≤ M(C).
- It was interesting to see that M(R) was fairly higher than M(T) for some participants, e.g., a tapping case of P6. This may be related to pressing the home button with force.
- If M(T) < M(C), we marked it with (cid:88)* and considered it a success.
- The highest success rate was observed in Tapping and Passcode-typing conditions (85.7%), while the lowest was in Text-typing (42.9%).

#### Limitations
Our sample was small (n = 7) and so was the number of latent fingerprints (m = 403). This limitation occurred because we aimed to photograph smudges with participants’ consent. Due to the small sample size, we could not consider EER (equal error rate) and instead directly compared match scores, leading to a template dependency.

### User Perception: In-Person Surveys
To gain insight into users' touch behavior and their perception of Touch ID and latent fingerprints in daily use, we conducted in-person surveys.

#### Methodology
To understand users' behavioral practice and perception gap, we decided to conduct an in-person survey. This allowed us to validate participants' answers immediately and expect unforeseen answers with additional questions and explanations. After IRB approval, we recruited diverse participants from a local university, coffee shops, and shopping malls through message boards and flyers distribution from July 1 to November 30, 2016. All participants were given a small gratuity ($10) for their participation.

**Study Design:**
- We conducted paper surveys in person, followed by further communications and selective interviews if necessary.
- The collected answers were stored in our local computer for further data analysis.
- Our survey questionnaires consisted of the following parts:
  - **Part A:** Basic questions about iPhone experience and brief perception regarding the security and usability of Touch ID compared to other unlocking methods (e.g., passcode).
  - **Part B1:** Main questions about the Touch ID experience, focusing on security and usability.
  - **Part B2:** Main questions about the behavioral practice with fingers on Touch ID and touch screens, including enrollment for Touch ID and frequent finger usage on both Touch ID and touch screens (for Passcode typing, App selection, Text typing, and Swiping). We also asked about participants’ perception of latent fingerprints.
  - **Part C:** Demographic questions about age, gender, handedness, education, and occupation.

For validation of participants' answers, we asked participants to provide detailed responses and engaged in follow-up communications as needed.