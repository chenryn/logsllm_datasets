somware payments in the Bitcoin ecosystem. Journal
of Cybersecurity, 5(1), 2019.
[93] J. Park, W.-J. Jung, and B. Kim. The effect of informa-
tion security certiﬁcation announcement on the market
Journal of Information Technology
value of ﬁrms.
Services, 15(3):51–69, 2016.
[94] S. Rahaman, G. Wang, and D. Yao. Security certiﬁca-
tion in payment card industry: Testbeds, measurements,
In Proc. of the Conf. on Com-
and recommendations.
puter and Communications Security, pages 481–498.
ACM, 2019.
[95] V. Richardson, M. W. Watson, and R. E. Smith. Much
ado about nothing: The (lack of) economic impact of
data privacy breaches. J. of Information Systems, 2019.
[96] M. Riek and R. B¨ohme. The costs of consumer-facing
cybercrime: an empirical exploration of measurement
issues and estimates. J. of Cybersecurity, 4(1), 2018.
[97] J. Riekmann and M. Kraus. Tatort Internet: Kriminalit¨at
verursacht B¨urgern Sch¨aden in Milliardenh¨ohe. DIW-
Wochenbericht, 82(12):295–301, 2015.
[98] S. Romanosky. Examining the costs and causes of cyber
incidents. J. of Cybersecurity, 2(2):121–135, 2016.
[99] S. Romanosky, D. Hoffman, and A. Acquisti. Empirical
analysis of data breach litigation. Journal of Empirical
Legal Studies, 11(1):74–104, 2014.
[100] S. Romanosky, A. Kuehn, L. Ablon, and T. Jones.
Content analysis of cyber insurance policies: How do
carriers price cyber risk? J. of Cybersecurity, 5(1), 2019.
[101] A. Sarabi, P. Naghizadeh, Y. Liu, and M. Liu. Risky
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:54 UTC from IEEE Xplore.  Restrictions apply. 
226
business: Fine-grained data breach prediction using
business proﬁles. J. of Cybersecurity, 2(1):15–28, 2016.
[102] SAS Institute Inc. Oprisk global data: A comprehensive
database of operational loss information, 2015. [Online;
accessed 27-April-2020].
[103] Y. Sawaya, M. Sharif, N. Christin, A. Kubota,
A. Nakarai, and A. Yamada. Self-conﬁdence trumps
knowledge: A cross-cultural study of security behavior.
In Proc. of the Conf. on Human Factors in Computing
Systems, pages 2202–2214. ACM, 2017.
[104] B. Schroeder and G. Gibson. A large-scale study of
failures in high-performance computing systems. IEEE
Trans. on Dependable and Secure Computing, 7(4):
337–350, 2010.
[105] R. Sen and S. Borle. Estimating the contextual risk of
data breach: An empirical approach. Journal of Man-
agement Information Systems, 32(2):314–341, 2015.
[106] C. Simoiu, A. Zand, K. Thomas, and E. Bursztein.
Who is targeted by email-based phishing and malware?
measuring factors that differentiate risk. In Proc. of the
Internet Measure. Conf., page 567–576. ACM, 2020.
[107] G. Simpson and T. Moore. Empirical analysis of losses
from business-email compromise. In APWG Symp. on
Electronic Crime Research, 2020.
[108] D. Sornette and G. Ouillon. Dragon-kings: Mechanisms,
statistical methods and empirical evidence. The Euro-
pean Physical J. Special Topics, 205(1):1–26, 2012.
[109] K. Soska and N. Christin. Automatically detecting
vulnerable websites before they turn malicious.
In
Proc. of the USENIX Security Symp., pages 625–640.
USENIX, 2014.
[110] M. Spagnuolo, F. Maggi, and S. Zanero. Bitiodine:
Extracting intelligence from the Bitcoin network. In Int.
Conf. on Financial Cryptography and Data Security,
pages 457–468. Springer, 2014.
[111] B. Stock, G. Pellegrino, C. Rossow, M. Johns, and
M. Backes. Hey, you have a problem: On the feasi-
bility of large-scale web vulnerability notiﬁcation.
In
Proc. of the USENIX Security Symp., pages 1015–1032.
USENIX, 2016.
[112] B. Stone-Gross, C. Kruegel, K. Almeroth, A. Moser,
and E. Kirda.
In
Computer Security Applications Conf., pages 231–240.
IEEE, 2009.
Fire: Finding rogue networks.
[113] D. W. Straub Jr. Effective IS security: An empirical
study. Inf. Systems Research, 1(3):255–276, 1990.
[114] S. Tajalizadehkhoob, H. Asghari, C. Ga˜n´an, and M. J.
van Eeten. Why them? Extracting intelligence about tar-
get selection from Zeus ﬁnancial malware. In Workshop
on the Economics of Inf. Security, 2014.
[115] S. Tajalizadehkhoob, M. Korczy´nski, A. Noroozian,
C. Gan´an, and M. van Eeten. Apples, oranges and host-
ing providers: Heterogeneity and security in the hosting
market. In Network Operations and Management Symp.,
pages 289–297. IEEE, 2016.
[116] S. Tajalizadehkhoob, T. Van Goethem, M. Korczy´nski,
A. Noroozian, R. B¨ohme, T. Moore, W. Joosen, and
M. van Eeten. Herding vulnerable cats: A statistical
approach to disentangle joint responsibility for web
In Proc. of the Conf. on
security in shared hosting.
Computer and Communications Security, pages 553–
567. ACM, 2017.
[117] S. Tajalizadehkhoob, R. B¨ohme, C. Gan´an, M. Kor-
czy´nski, and M. van Eeten. Rotten apples or bad har-
vest? What we are measuring when we are measuring
abuse. ACM Trans. on Internet Tech., 18(4):1–25, 2018.
[118] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and V. Pax-
son. Trafﬁcking fraudulent accounts: The role of the
underground market in Twitter spam and abuse.
In
Proc. of the USENIX Security Symp., pages 195–210.
USENIX, 2013.
[119] O. K. Tosun. Cyber attacks and stock market activ-
ity. Avail. at SSRN: https://ssrn.com/abstract=3190454,
2019.
[120] F. Tram`er, F. Zhang, A. Juels, M. K. Reiter, and
T. Ristenpart. Stealing machine learning models via
prediction APIs. In Proc. of the USENIX Security Symp.,
pages 601–618. USENIX, 2016.
[121] UK Department for Business, Innovation and Skills.
[Online;
Information security breaches survey, 2015.
accessed 27-March-2020].
[122] M. Vasek, J. Wadleigh, and T. Moore. Hacking is not
random: A case-control study of webserver-compromise
risk. IEEE Trans. on Dependable and Secure Comput-
ing, 13(2):206–219, 2015.
[123] M. Vasek, M. Weeden, and T. Moore. Measuring
the impact of sharing abuse data with web hosting
In Proc. of the Workshop on Inf. Sharing
providers.
and Collaborative Security, pages 71–80. ACM, 2016.
[124] V. Verendel. Quantiﬁed security is a weak hypothesis:
A critical survey of results and assumptions. In Proc. of
the Workshop on New Security Paradigms, pages 37–50.
ACM, 2009.
[125] T. Wang, K. N. Kannan, and J. R. Ulmer. The as-
sociation between the disclosure and the realization of
information security risk factors. Information Systems
Research, 24(2):201–218, 2013.
[126] P. Warren, K. Kaivanto, and D. Prince. Could a cyber
attack cause a systemic impact in the ﬁnancial sector?
Bank of England Quarterly Bulletin, 58(4):21–30, 2018.
[127] S. Wheatley, T. Maillart, and D. Sornette. The extreme
risk of personal data breaches and the erosion of privacy.
The European Physical Journal B, 89(1):7, 2016.
[128] S. Wheatley, A. Hofmann, and D. Sornette. Addressing
insurance of data breach cyber risks in the catastrophe
framework. Geneva Papers on Risk and Ins. -Issues and
Prac. , In press, 2020.
[129] D. W. Woods and T. Moore. Does insurance have a
future in governing cybersecurity? IEEE Security &
Privacy, 18(1):21–27, 2020.
[130] D. W. Woods, T. Moore, and A. C. Simpson. The
county fair cyber loss distribution: Drawing inference
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:54 UTC from IEEE Xplore.  Restrictions apply. 
227
from insurance prices. In Workshop on the Economics
of Information Security, 2019.
[131] M. Xu, K. M. Schweitzer, R. M. Bateman, and S. Xu.
Modeling and predicting cyber hacking breaches. IEEE
Trans. on Inf. Forensics and Security, 13(11):2856–
2871, 2018.
[132] E. Zeng, F. Li, E. Stark, A. P. Felt, and P. Tabriz. Fixing
HTTPS misconﬁgurations at scale: An experiment with
In Workshop on the Economics
security notiﬁcations.
of Information Security, 2019.
[133] J. Zhang, Z. Durumeric, M. Bailey, M. Liu, and
M. Karir. On the mismanagement and maliciousness of
networks. In Network and Distributed System Security
Symp. Internet Society, 2014.
APPENDIX
Throughout model parameters are estimated to minimise
squared residuals. Regressing losses L on the security level
S in the artiﬁcial data in Table V reveals that
L ≈ 0.11 + 0.32∗S
(1)
A positive coefﬁcient for S means increasing security level is
associated with an increase in loss. Further, the coefﬁcient is
the slope of the solid blue line in Figure 1. The ∗ means
the p ≤ 0.05
the coefﬁcient
level. Security is associated with greater losses because the
high-threat population spend more on security and also suffer
greater losses. However, controlling for threat by re-estimating
the model in the high-threat population (T = 1), we see that
is statistically signiﬁcant at
L ≈ 0.63 − 0.59∗S
(2)
Security now has a negative coefﬁcient, as we would expect,
and is statistically signiﬁcant. Conversely, security has no
signiﬁcant effect in the low-threat population (T = 0).
L ≈ 0.03 + 0.05 S
(3)
The coefﬁcients in (2) and (3) correspond to the slopes of
the dotted red and dashed green line in Figure 1 respectively.
It is evident that the threat level causes losses, and security
moderates the effect of threat on losses.
This effect can be captured using an interaction between S
and T so that
L ≈ 0.03 + 0.6∗∗∗ T + 0.05 S − 0.6∗ T × S
(4)
In Model 4, threat is strongly signiﬁcant (p ≤ 0.001) and
positively associated with losses. Increasing security in the
overall population leads to a small increase in losses, although
this relationship is not statistically signiﬁcant. Whereas, the
same increase in the high-threat population leads to a ten-fold
larger decrease in loss (−0.56 + 0.05 = −0.50 vs +0.05),
and this is statistically signiﬁcant. The interaction term T × S
captures the intuition that security moderates the relationship
between threat and losses.
We can evaluate the ﬁt of each model using the coefﬁcient of
variation R2, which describes the proportion of the variance
ARTIFICIAL DATA USED FOR THE EXAMPLE IN FIG. 1
TABLE V
Low-threat (T = 0)
Loss L
Security S
High-threat (T = 1)
Loss L
Security S
0.06
0.08
0.65
0.01
0.29
0.13
0.59
0.00
0.37
0.23
0.00
0.15
0.00
0.08
0.21
0.01
0.11
0.00
0.01
0.24
0.00
0.00
0.00
0.20
0.50
0.00
0.00
0.00
0.00
0.00
0.00
0.10
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.37
0.57
0.35
0.73
0.38
0.47
0.47
0.57
0.90
0.70
0.35
0.21
0.43
0.20
0.29
0.40
0.29
0.58
0.48
0.46
0.56
0.54
0.73
0.38
0.25
0.40
0.46
0.30
0.00
0.23
0.68
0.57
0.32
0.56
0.40
0.13
0.27
0.43
0.05
0.21
TECHNICAL INDICATORS [116] CORRESPONDING TO Ix IN FIGURE 3
TABLE VI
Technical indicator
# domains in phishing blacklist
IC1
# domains in malware blacklist
IC2
# IPs on shared hosting
IE1
# domains on shared hosting
IE2
HTTP server version
IS1
SSL version
IS2
Admin panel version
IS3
PHP version
IS4
OpenSSH version
IS5
CMS version
IS6
HttpOnlyCookie
IS7
X-Frame-Options
IS8
X-Content-Type-Options
IS9
IS10 Mixed-content inclusions
IS11
IS12
IS13
IS14
IS15
Secure cookie
Content-Security-Policy
HTTP Strict-Transport-Security
SSL-stripping vulnerable form
Browser XSS protection
explained by the model. Model 1 only explains 10% of the
variance, whereas Model 2 and Model 4 can explain 21% and
58% respectively. Model 3 explains nothing. R2 values are
adjusted for the varying number of parameters. It is impossible
to explain all of the variance (R2 = 1) with a linear model,
given that the underlying data generation process is non-linear.
Structural equation modeling generalises this logic to allow
for multiple moderating factors. Moreover, it considers explicit
measurement models which estimate these structural relation-
ships between latent constructs interpolated from multiple
noisy indicators.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:54 UTC from IEEE Xplore.  Restrictions apply. 
228