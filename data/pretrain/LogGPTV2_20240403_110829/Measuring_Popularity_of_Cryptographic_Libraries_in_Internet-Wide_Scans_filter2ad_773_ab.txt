### 1. Introduction

Given that the distributions of cryptographic libraries are not mutually distinguishable, we employ clustering analysis to group sources with very similar properties. We use the Euclidean distance as the metric, with a threshold for cluster creation, following the approach in [36]. The clustering results are visualized in Figure 2 as a dendrogram. Instead of working with individual libraries, we analyze groups. Although we cannot differentiate between libraries within a group, the most popular libraries (e.g., OpenSSL and Microsoft) are represented by distinct or very small groups.

**Figure 2: Clustering Analysis Dendrogram**
- **Clusters** are created based on the Euclidean distance, with a separation threshold of 0.02 (indicated by the blue dashed line).
- **Group numbers** are listed in brackets next to the source names.

### 2. Feature Extraction and Analysis

**Figure 1: Features Extracted from Public RSA Moduli**
- **Moduli generated by OpenSSL**: Always equal to one modulo three (N % 3 = 1), but uniformly distributed modulo four (N % 4 = 1 and N % 4 = 3, with the same probability).
- **Most significant bits**: Never equal to 10002, and more frequently 11002 than 11112.
- **Modulus modulo 3**: An unexplained implementation decision in OpenSSL and other libraries avoids primes p if p − 1 has small divisors, other than 2. If p − 1 and q − 1 are never divisible by 3, then the modulus is always equal to 1 modulo 3 and never equal to 2 modulo 3. For larger prime divisors (5, 7, 11, etc.), this property is not directly observable and impractical for key classification.

We base our analysis on the deep examination of key generation processes and statistical properties presented in [36]. Our feature mask is constructed similarly, but we exclude the feature encoding the bit length of the modulus, as it is only relevant for one uncommon library implementation. The choice of the mask is illustrated in Figure 1, showing the distributions of mask values for OpenSSL. Compared to [36], we have also reordered the features in the mask for easier interpretation. The relevant biases for all sources are listed in Table 3 in the Appendix.

### 2.2 Clustering Analysis

For each source, we generate a large number of keys (typically one million), extract features according to the feature mask, and compute the distributions of the feature masks. The previous research [36] used a highly representative sample of cryptographic libraries in their most recent available versions. In addition, we included keys from two hardware security module devices, two cryptographic tokens, and PuTTY, a popular SSH implementation for Microsoft Windows. This is particularly valuable when considering the domain of SSH authentication keys collected from GitHub.

We also collected new keys from the latest implementations of the considered libraries, revealing a change in the behavior of Libgcrypt 1.7.6 in FIPS mode. Additionally, we added earlier releases of several libraries to support claims about older datasets. However, we detected a change in the algorithm only for Nettle 2.0.

### 2.3 Dataset Classification – Original Approach

The authors of [36] aimed to determine the origin (the most probable group G) of a particular key K using Bayes' rule:
\[ P(G|K) = \frac{P(K|G)P(G)}{P(K)} \]
- \( P(G|K) \): Conditional probability that a group G was used to generate a given key K.
- \( P(K|G) \): Conditional probability that a key K is generated by a given group G (obtained from reference distributions).
- \( P(G) \): Prior probability of a group G.
- \( P(K) \): Probability of a key K in a dataset.

The highest value of \( P(G|K) \) corresponds to the most probable group G. To reason about the popularity of libraries in large datasets, all keys were considered separately, and the information was summarized. A major shortcoming was the assumption that cryptographic libraries are chosen evenly by users, which is false. The method also failed to consider the "big picture" by analyzing keys in small batches, often assuming \( P(K) = 1 \).

### 2.4 Dataset Classification – Our Approach

We improved the method by using an appropriate prior probability \( P(G) \) for the domain where the key can be found (e.g., TLS, PGP, SSH). To our knowledge, no reliable estimates of \( P(G) \) for large domains have been published. Therefore, we propose and apply a method for estimating the proportion of cryptographic libraries in large datasets based on statistical inference. This allows us to construct a tailored prior probability estimate before making claims about individual keys.

To estimate the prior probability, we create a model based on our reference distributions and search for parameters that best match the observed sample using non-negative least squares fit (NNLSF) [30]. This method provides a two-fold increase in the accuracy of origin estimation for public keys in the TLS domain compared to the original approach of [36].

### 2.5 Limitations

- **Individual sources within a single group** cannot be distinguished. Fortunately, the two most significant TLS libraries, OpenSSL and Microsoft, belong to small groups.
- **Version identification** is limited to ranges of versions with the same key generation algorithm.
- **Prior probability estimation** requires a dataset with at least 10^5 keys. However, the classification of a single key still benefits from accurate prior probability.

### 3. Methodology in Detail

#### 3.1 Model
We assume there are \( m \) groups of sources, created by clustering analysis based on the similarity of the distributions of generated public keys. The probability \( P(K) \) that a randomly chosen key in the sample has a particular mask value \( K \) is given by:
\[ P(K) = \sum_{j=1}^{m} P(G_j)P(K|G_j) \]
where:
- \( P(G_j) \): Probability that a source from a group \( G_j \) is chosen in a particular domain.
- \( P(K|G_j) \): Conditional probability of generating a key with mask \( K \) when a library from the group \( G_j \) is used.

#### 3.2 Prior Probability Estimation
The process of estimating prior probabilities is automated and does not require user input. We find the likely prior probabilities of libraries that would lead to the observed distribution of keys in a given sample, based on the reference group profiles. The observed distribution is reconstructed by combining the 13 distributions in a specific ratio (prior probability estimated by our approach).

#### 3.3 Key Classification
We classify keys according to their origin using Bayes' rule, incorporating the estimated prior probabilities for more precise classification. The group \( G \) with the highest probability \( P(G|K) \) is the most likely origin of the key.

#### 3.4 Evaluation of Accuracy
We measure both the accuracy of the prior probability estimation and the average correctness of the overall classification process. For evaluation, we simulate large datasets, add noise, and perform our method.

##### 3.4.1 Random Noise
Even if keys in a large dataset were generated with the same library across many users, the overall distribution will not match our reference distribution exactly due to the non-deterministic nature of key generation. This contributes to random noise in the data.

##### 3.4.2 Systematic Noise
Our analysis does not cover all existing libraries used on the Internet. Unknown libraries with similar algorithms may belong to one of our groups, leading to errors in labeling. Additionally, there may exist groups with profiles that do not match any of our known groups, adding systematic noise to the sample. In simulations, we include a certain percentage of keys from unknown distributions to account for this.

This comprehensive approach ensures a more accurate and robust classification of cryptographic keys based on their origins.