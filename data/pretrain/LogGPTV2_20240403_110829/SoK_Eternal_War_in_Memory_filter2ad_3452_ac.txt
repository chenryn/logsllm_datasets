Read as a RGB color
User scripting
ActionScript
JavaScript
none
JavaScript
JavaScript
CVE-2012-1889 Microsoft Windows
XML Core Services
(affecting IE)
Internet Explorer 9/10
(Pwn2Own 2012)
CVE-2012-1876
Uninitialized pointer
Heap buffer overﬂow
Read a string after overwriting
its length
JavaScript
EXPLOITS THAT DEFEAT BOTH DEP AND ASLR USING ROP AND INFORMATION LEAKS
Table I
False negatives. The possibility of false negatives (pro-
tection failures) depends on the deﬁnition of the policy.
For probabilistic approaches, the probability of a successful
attack is always > 0 while it is ≥ 0 for deterministic
solutions. As shown in Section III, secrets that the protection
relies upon can not only be guessed, but also leaked.
False positives. The avoidance of false alarms (e.g., unnec-
essary crashes) is a very strict requirement for any practical
solution. Causing faults in normal operation is unacceptable
in production environments. In addition, compatibility issues
should not cause any false alarms.
B. Cost
Performance overhead. The cost of a solution is primar-
ily determined by the performance overhead it introduces.
Beside security, the most important requirement is speed.
To measure performance, both CPU-bound and I/O-bound
benchmarks can be used. CPU-bound benchmarks, such
as SPEC [36], are more challenging, because I/O-bound
programs spend more time in the kernel, relatively reducing
the impact of the user-space CPU overhead. Although some
proposals report good scores with selected benchmark pro-
grams or with I/O-bound server applications, their overheads
are much higher if measured using CPU-bound benchmarks.
We recommend that protection approaches considered for
wide adoption target CPU-bound client-side programs as
well, these being primary targets of today’s attacks.
Our comparison analysis in Section IX shows that tech-
niques introducing an overhead larger than roughly 10% do
not tend to gain wide adoption in production environments.
Some believe the average overhead should be less than
5% in order to get adopted by industry, e.g.,
the rules
of the Microsoft BlueHat Prize Contest [37] conﬁrm this
viewpoint.
Memory overhead. Inline monitors often introduce and
propagate some kind of metadata, which can introduce
signiﬁcant memory overhead as well. Some protection mech-
anisms (especially the ones using shadow memory) can even
double the space requirement of a program. In case of most
applications, however, this is much less of an issue than
runtime performance.
C. Compatibility
Source compatibility. An approach is source compatible
(or source agnostic) if it does not require application source
code to be manually modiﬁed to proﬁt from the protection.
The necessity of even minimal human intervention or effort
makes a solution not only unscalable, but too costly as well.
Most experts from the industry consider solutions which
require porting or annotating the source code impractical.
Binary compatibility. Binary compatibility allows compat-
ibility with unmodiﬁed binary modules. Transformed pro-
grams should still link with unmodiﬁed libraries. Backward
compatibility is a practical requirement to support legacy
libraries. Using unprotected libraries may leave parts of
the program exploitable, but allows incremental deployment.
Also, for instance on the Windows platform, system libraries
are integrity protected and thus cannot be easily changed.
Modularity support. Support for modularity means that
individual modules (e.g. libraries) are handled separately. A
compiler based solution should support separate compilation
of modules, while a binary rewriter should support hardening
each ﬁle (main executable or library) separately. Because
dynamic-link libraries (.dll and .so) are indispensable for
modern operating systems, all practical protections must
support them as well.
V. PROBABILISTIC METHODS
Probabilistic methods rely on randomization and se-
crets. There are three main approaches: Instruction Set
Randomization, Address Space Randomization, and Data
Space Randomization. Figure 1 shows that Instruction Set
Randomization (ISR) [38] mitigates attacks based on code
corruption and injection of shellcode. Code corruption is
prevented by read-only page permissions, and shellcode
injection is prevented by non-executable page permissions.
Due to hardware improvements, ISR has become obsolete.
5454
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:16 UTC from IEEE Xplore.  Restrictions apply. 
Address Space Randomization (ASR) mitigates control-ﬂow
hijacking attacks by randomizing the location of code and
data and thus the potential payload address. Data Space
Randomization (DSR) probabilistically mitigates all attacks
by randomizing (encrypting) the contents of the memory.
A. Address Space Randomization
Address Space Layout Randomization (ASLR) [5], [39]
is the most prominent memory address randomization tech-
nique. ASLR randomly arranges the position of different
code and data memory areas. If the payload’s address in the
virtual memory space is not ﬁxed, the attacker is unable to
divert control-ﬂow reliably. ASLR is the most comprehen-
sive currently deployed protection against hijacking attacks.
The diverted jump target can be some injected payload in
a data area or existing code in the code section. This is why
every memory area must be randomized, including the stack,
heap, main code segment, and libraries. The protection can
always be bypassed if not all code and data sections are
randomized. On most Linux distributions, for instance, only
library code locations are randomized but the main module
is at a ﬁxed address. Most programs are not compiled as
Position Independent Executables (PIE) to prevent a 10%
on average performance degradation [40].
Furthermore, on 32 bit machines the maximum possible
entropy allowed by the virtual memory space is ineffective
against brute-force or de-randomization attacks [41]. De-
randomization is often carried out by simply ﬁlling the
memory with repeated copies of the payload, which is called
heap-spraying or JIT-spraying [14], [42]. Another potential
attack vector is partial pointer overwrites. By overwriting
the least signiﬁcant byte or bytes of a pointer, it can be
successfully modiﬁed to point to a nearby address [43].
Even if everything is randomized with very high entropy
(e.g., on x64 machines), information leaks can completely
undermine the protection. Information leaks are the primary
attack vector against probabilistic techniques, and as Fig-
ure 1 shows, they are always possible if (some level of)
Memory Safety is not enforced.
Since the wide deployment of W⊕X the focus of ran-
domization has become code. As illustrated by Step 6 of
Figure 1, code reuse attacks became the primary threat. To
increase the entropy in code locations, researchers proposed
the permutation of functions [44] and instructions inside
functions [45] as well. Self-Transforming Instruction Relo-
cation (STIR) [46] randomly re-orders the basic blocks of
a binary at launch-time. While these techniques make ROP
attacks harder, they usually do not protect against return-
to-libc attacks. These techniques also assume that a code
reuse (ROP) exploit needs several gadgets, in which case
the provided entropy is high enough. However, sometimes
a single gadget is enough to carry out a successful attack.
The address of a single instruction, gadget, or function is
relatively easy to acquire via an information leak.
in the “data space”:
A technique in the border-land between Address Space
and Data Space Randomization is pointer encryption. Cowan
et al. [47] proposed PointGuard, which encrypts all pointers
in memory and only decrypts them right before they are
loaded into a register. This technique can be considered the
dual of ASLR, since it also introduces entropy in addresses,
but
it encrypts the stored address,
i.e., pointers’ values. To encrypt the pointers PointGuard
uses the XOR operation with the same key for all pointers.
Since it used only one key, by leaking out one known
encrypted pointer from memory,
the key can be easily
recovered [12]. However the primary reason what prevented
PointGuard from wide adoption was that
it was neither
binary nor source code compatible.
B. Data Space Randomization
Data Space Randomization (DSR) [48] was introduced
by Bhatkar and Sekar to overcome the weaknesses of
PointGuard and to provide stronger protection. Similarly
to PointGuard, DSR randomizes the representation of data
stored in memory, not the location. It encrypts all variables,
not only pointers, and using different keys. For a variable v,
a key or mask mv is generated. The code is instrumented
to mask and unmask variables when they are stored and
loaded from memory. Since several variables can be stored
and loaded by the same pointer dereference, variables in
equivalent “points-to” sets have to use the same key. The
computation of these sets requires a static pointer analysis
prior to the instrumentation. The protection is stronger,
because encrypting all variables not only protects against
control-ﬂow hijacks, but also data-only exploits. Also, the
use of multiple keys prevents the trivial information leak
described in PointGurad’s case, but not in all cases [12].
The average overhead of DSR is 15% on a custom
benchmark. The solution is not binary compatible. Protected
binaries will be incompatible with unmodiﬁed libraries.
Also, whenever points-to analysis is needed, modularity will
be an issue. Different modules cannot be handled separately,
because the points-to graph has to be computed globally.
To overcome this issue the authors propose computing
partial points-to graphs for separate modules and leave the
computation of the global graph to the dynamic linker.
VI. MEMORY SAFETY
Enforcing Memory Safety stops all memory corruption
exploits. For complete Memory Safety, both spatial and
temporal errors must be prevented without false negatives.
Type-safe languages enforce both spatial and temporal safety
by checking object bounds at array accesses and using
automatic garbage collection (the programmer cannot de-
stroy objects explicitly). Our focus is transforming existing
unsafe code to enforce similar policies by embedding low-
level reference monitors. The instrumentation may be in the
source code, intermediate representation, or binary level.
5555
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:16 UTC from IEEE Xplore.  Restrictions apply. 
A. Spatial safety with pointer bounds
The only way to enforce complete spatial safety is to
keep track of pointer bounds (the lowest and highest valid
address it can point to). CCured [49] and Cyclone [50]
use “fat-pointers” by extending the pointer representation
to a structure which includes the extra information. Un-
fortunately these systems need source-code annotations and
are therefore impractical for large code bases. Furthermore,
changing the pointer representation changes the memory
layout, which breaks binary compatibility.
SoftBound [51] addresses the compatibility problem by
splitting the metadata from the pointer, thus the pointer
representation remains unchanged. A hash table or a shadow
memory space is used to map pointers to the metadata.
The code is instrumented to propagate the metadata and to
check the bounds whenever a pointer is dereferenced. For
new pointers, the bounds are set to the starting and ending
address of the object it is pointed to. Runtime checks at
each pointer dereference ensure that the pointer stays inside
bounds. These checks stop all spatial errors in the second
step of our exploit model.
Pointer based bounds checking is capable of enforcing
spatial safety completely without false positives or false
negatives if and only if every module is protected. Soft-
Bound is formally proven to provide complete spatial vi-
olation detection. Unfortunately, the performance overhead
of SoftBound is high, 67% on average. While pointer based
approaches, e.g., SoftBound, provide a limited compatibility
with unprotected libraries, full compatibility is hard to
achieve. Consider, for instance, a pointer created by the pro-
tected module. If that pointer is modiﬁed by an unprotected
module, the corresponding metadata is not updated, causing
false positives. We summarize the properties of the main
approaches we cover at the end of the paper in Table II.
B. Spatial safety with object bounds
Because of the compatibility issues caused by pointer
based approaches, researchers proposed object based alter-
natives. Instead of associating the bounds information with
pointers, these systems associate the information with the
objects. Knowing only the bounds of allocation regions is not
enough information to catch errors at pointer dereferences,
because we do not know if the pointer points to the right
object. Hence, object based techniques focus on pointer
arithmetic (Step 1 in the model) instead of dereferences
(Step 2) to protect the bounds of pointers. Binary compatibil-
ity is possible because the metadata is only updated at object
creation and deletion. Consider the previous example. The
metadata this time is associated with the object rather than
with the pointer. If a pointer is updated in an unprotected
module, then the metadata will not go out-of-sync.
One problem with this approach, however, is that pointers
can legitimately go out of bounds as long as they are not
dereferenced. For instance, during the last iteration of a loop
5656
over an array, a pointer typically goes off the array by one,
but it is not dereferenced. The ﬁrst binary compatible object
based solution to enforce spatial safety is a GCC patch by
Jones and Kelly (J&K) [52], which solved this problem
by padding allocated objects with an extra byte. This still
caused false alarms when a pointer legitimately went out of
bounds more than one byte. A more generic solution to this
problem was later provided by CRED [53].
The main problem with object based approaches is that
they cannot provide complete spatial safety. False nega-
tives can occur, because memory corruption inside objects
or structures remains undetected. This is because the C
standard allows pointer arithmetic within struct ﬁelds.
E.g., for memset(&strct,0,sizeof(strct)); the
pointer needs to be allowed to iterate through the whole
structure.
J&K suffers a large performance overhead of 11-12x.
CRED decreased this overhead to around 2x, but by reducing
the checked data structures to character arrays only. Dhurjati
et al. [54] extend J&K’s work by building on a technique
called “automatic pool allocation” [55]. Automatic pool
allocation partitions the memory based on a static points-
to analysis. Partitioning allows using a separate and much
smaller data structures to store the bounds metadata for each
partition, which can decrease the overhead further to around
120%.
Baggy Bounds Checking (BBC) [56] is currently one
of the fastest object based bounds checkers. BBC trades
memory for performance and adds padding to every object
so that its size will be a power of two and aligns their
base addresses to be the multiple of their (padded) size.
This property allows a compact bounds representation and
an effective way to look up object bounds. The authors of
BBC claim that their solution is around twice as fast than the
previously mentioned Dhurjati’s automatic pool allocation
based optimization. BBC’s average performance overhead is
60% on the SPECINT 2000 benchmark. PAriCheck [57] was
developed concurrently with BBC. It pads and aligns objects
to powers of two as well for efﬁcient bounds checking. It
has slightly better performance cost and memory overhead
than BCC.
The motivation for object based approaches is to remain
compatible with unprotected libraries to reduce false posi-
tives. If an allocation or de-allocation happens in an unpro-
tected library, the metadata is set by intercepting malloc
and free. For every other object created in an unprotected
library, default values are used, allowing arbitrary arithmetic.
C. Temporal safety
Spatial safety alone does not prevent all vulnerabilities.
Use-after-free and double-free vulnerabilities remain unde-
tected by the previously discussed bounds checkers. Nu-
merous approaches have been proposed to enforce temporal
safety.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:16 UTC from IEEE Xplore.  Restrictions apply. 
1) Special allocators: The na¨ıve approach to protect
against use-after-free exploits would be to never reuse the
same virtual memory area, but that would be overly wasteful.
Special memory allocators, like Cling [58], are designed
to thwart dangling pointer attacks without signiﬁcant mem-
ory or performance overhead. Cling is a replacement for
malloc, which allows address space reuse only among
objects of the same type and alignment. This policy does not
prevent dereferences through dangling pointers, but enforces
type safe memory reuse, preventing the described use-after-
free attack. Dynamic memory allocator replacements of
course cannot prevent unsafe reuse of local, stack allocated
objects.
2) Object based approaches: Perhaps the most widely
used tools to detect memory errors in practice is Valgrind’s
Memcheck [30] tool and AddressSanitizer [59]. These tools
try to detect use-after-free bugs by marking locations which
were de-allocated in a shadow memory space. Accessing
a newly de-allocated location can be detected this way.
This approach, however, fails to detect errors after the area
is re-allocated for another pointer: the area is registered
again and the invalid access remains undetected. The object
based bounds checkers described in the previous subsection
offer the same protection, since de-allocation invalidates the
object in the metadata table. Valgrind, being a dynamic
translator, causes a 10x slowdown in average, while Ad-
dressSanitizer causes 73% slowdown by instrumenting code
at compile time. The only way to detect a use-after-free