




Fig. 5: Fault injection results for each benchmark.
l
e
d
o
M
e
h
t
f
o
l
l
a
c
e
R
100%
90%
80%
70%
60%
50%
Fig. 7: Precision for the crash bits predicted using the ePVF
methodology.
Crash rate estimate  using fault injection
Crash rate estimate  using ePVF
100%
80%
60%
40%
20%
0%
Fig. 6: Recall for the crash bits predicted using the ePVF methodol-
ogy.
Figure 6 presents the recall for each benchmark. Overall, our
methodology achieves an average of 89% recall across the ten
benchmarks (ranging from 85% to 92%). We manually ana-
lyzed the crash-causing bits that were not identiÔ¨Åed as crashes
by ePVF methodology. The main reason is that our validation
technique introduces approximations due to non-determinism
in execution environment: the segment boundaries may be
slightly shifted. As a result, it cannot be guaranteed to execute
fault injection runs with exactly the same environment, partic-
ularly the same memory allocation and the proÔ¨Åling. Through
manual veriÔ¨Åcation we found that, depending on benchmark,
this factor accounts for 92% to 99% of incorrect predictions.
Precision. We deÔ¨Åne precision as the ratio of the number
of correctly predicted crash-causing bits to the total num-
ber of predicted crash-causing bits. To estimate precision,
we randomly choose over 1,200 different bits from those
identiÔ¨Åed by the model as crash-causing (i.e., appear in the
CRASHING BIT LIST), and perform a targeted fault injection
experiment. Similar to the recall study, this time for each bit,
we specify the dynamic instruction and the register to inject
the fault into, as well as the bit that should be Ô¨Çipped. Precision
is calculated as the number of observed crashes over the total
number of fault injections performed.
Figure 7 shows the results of the evaluation. The average
precision across all benchmarks is 92% (ranges from 86%
to 98%). As in the case of recall, after manual inspection
we have conÔ¨Årmed that the main reason for not hitting 100%
precision is the difference between the run-time and modeled
environments, i.e., non-deterministic memory allocation.
Fig. 8: The crash rates estimates using ePVF (right bars) and using
fault injection experiments (left bars) are close. For fault injection
experiments, the error bars indicate the 95% conÔ¨Ådence intervals.
C. Q2: How close are the crash rates estimated using ePVF
and fault injection?
The ePVF methodology is able to identify crash-causing
bits with high accuracy. This can be used to estimate the crash
rate of a program as the fraction of crash-causing bits over the
total number of bits in an application. Such an estimate can
be important for techniques that use crash rates to determine
the level of protection to be provided, e.g., choosing the
checkpoint interval.
Figure 8 shows that estimating crash rates this way is a
good approximation for crash rates obtained through fault
injection experiments. The differences are within or close to
the 95% conÔ¨Ådence interval bounds, except for lavaMD and
lulesh. The reason the crash rate predictions are off for these
two applications is that ePVF calculates the crash bits only
based on the ACE graph, which contains 70% and 80% of
the whole DDG for lavaMD and lulesh respectively. On the
other hand, the fault injection uses the full program execution
corresponding to the whole DDG.
D. Q3: Does ePVF lead to a tighter estimate of SDC rate
than the original PVF?
We have shown that the ePVF methodology can accurately
estimate the crash bits of an application. We now ask whether
it can lead to better SDC rate estimates. As explained earlier,
ePVF provides an upper bound (i.e., overestimate) for the SDC
rate like PVF does. We compare the tightness of these two
upper bounds.
175
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:04 UTC from IEEE Xplore.  Restrictions apply. 
100%
80%
60%
40%
20%
0%
PVF value
ePVF value
SDC rate from FI
g
n
e
m
i
t
i
l
l
e
d
o
m
l
a
t
o
t
f
o
e
g
a
t
n
e
c
r
e
P
Buidling ACE graph
Crash and propagation modelling
100%
80%
60%
40%
20%
0%
3876 17640 14045 180
140
26
3657
808
3800
860
111
360
355
25
32
4
143
92
156
93
Fig. 9: ePVF (center bars) offers a much better upper bound estimate
for the SDC rate (right bars) than the original PVF methodology (left
bars). For SDC rates, error bars represent 95% conÔ¨Ådence intervals.
TABLE V: Number of nodes in the ACE graph and time taken by
the ePVF analysis for each benchmark
Benchmarks
hotspot
pathÔ¨Ånder
mm
particleÔ¨Ålter
nw
lulesh
bfs
lud
srad
lavaMD
# of Dynamic
IR instructions
954,920
839,163
464,438
352,866
376,022
322,738
274,170
75,543
72,041
17,814
ACE nodes Modelling time (s)
14,400
18,000
3,987
3,956
3,800
953
900
205
172
30
1,102,265
967,836
597,604
479,994
453,998
319,253
269,019
93,089
91,385
16,779
Figure 9 shows the original PVF and the ePVF values for
the ten benchmarks. The original PVF ranges from 71% to
98%, with an average of 92%. In contrast, the ePVF estimate
ranges from 25% to 40%, with an average value of 31%. The
average difference between PVF and ePVF is 61%, ranging
from 45% to 67% depending on the benchmarks.
Figure 9 also shows, for each benchmark, the SDC rate
obtained through the fault
injection experiments described
earlier. The SDC rate ranges from 1 to 25% depending on
the benchmark, with an average value of about 12% across
benchmarks. ePVF signiÔ¨Åcantly lowers the upper bound of es-
timated SDC vulnerability of a program. The above evaluation
suggests that our technique has higher predictive power than
the original PVF analysis to understand the SDC behaviour of
a program (we demonstrate that this can be used in practice
in ¬ßV). That said, there is still room for a tighter bound as we
will discuss in ¬ßVI.
E. Q4: How fast is the ePVF analysis?
Table V shows, for each benchmark, the number of dynamic
LLVM IR instructions, the number of nodes in the ACE graph,
and the total time to compute ePVF. The running time ranges
from less than a minute (lavaMD) to 5 hours (pathÔ¨Ånder).
As expected, the time taken correlates with the ACE graph
size. We also measured the time spent by various parts of the
ePVF analysis: most time is spent in the crash and propagation
models.
We discuss scalability in detail in Section ¬ßVI. Here we
propose an optimization to reduce the time to compute ePVF,
based on sampling the ACE graph. This approach is based on
Fig. 10: Breakdown of execution time between graph construction
(bottom bar) and running the crash and propagation models (top bar).
Labels on bars present absolute time in seconds.
predicted ePVF
computed ePVF
45%
30%
15%
0%
Fig. 11: The predicted ePVF value based on sampling only 10% of
the ACE graph and ePVF computed based on the entire graph are
close.
the intuition that many HPC applications consist of repetitive
program states and patterns, and hence a small sample of the
ACE graph will be representative of the overall application
behaviour. Since a dynamic instruction trace preserves the
temporal ordering of the instructions executed by the program,
the output nodes in the ACE graph can be ordered based on
their presence in the trace. To validate if the sampling works,
we pick the Ô¨Årst p% of the output nodes, and based on the
resulting partial ACE graph we estimate ePVF. For regular
applications, we Ô¨Ånd that there is a strong linear relationship
and we can linearly extrapolate the partial ePVF to the entire
application and thus estimate the overall ePVF accurately.
Figure 11 shows the extrapolated ePVF values based on
analyzing only 10% of the ACE graph. As can be observed,
for most benchmarks, the extrapolated ePVF values are a good
approximation for the overall ePVF: on average the error is
less than 1%, suggesting that these programs exhibit repetitive
behaviors as we expected.
Importantly, we can also estimate whether an application
displays repetitive behaviours and thus whether the ACE-graph
sampling be useful, without completing the full ACE analysis.
To demonstrate this, we randomly select multiple small sub-
sample of the ACE graph nodes (each 1%) and compute for
each of them the ePVF estimates. The normalized variance
is relatively low for benchmarks with repetitive behaviours
(e.g., 0.6 for lavaMD and 0.04 for particleÔ¨Ålter), but high for
applications where the ACE-graph sampling technique does
not offer high accuracy (e.g., 1.9 for lud).
176
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:04 UTC from IEEE Xplore.  Restrictions apply. 
V. CASE STUDY: SELECTIVE DUPLICATION
To demonstrate the practical usability of the ePVF method-
ology to improve application resilience, we use ePVF to
guide a selective instruction duplication technique to protect
against SDCs. The intuition is that a technique that prioritizes
protecting instructions with high ePVF values will offer good
SDC protection as the faults occurring in crashing bits are
unlikely to lead to SDCs. To establish a baseline, we compare
the SDC rate of a program protected by duplicating the high
ePVF instructions, with that protected by duplicating the hot
paths of the program. Prior studies [25], [31] have shown that
protecting hot paths is an effective technique (i.e., instructions
on the top 20% of most executed paths are responsible for
most of the SDCs - these constitute the hot paths).
We also attempted to use PVF to drive the choice of
instructions to duplicate. However, we found that the PVF
values of most instructions are clustered around 1, which
means that PVF has little discriminative power to inform
the choice of which instructions to protect. As an example,
we plot the CDF (Cumulative Distribution Function) of the
PVF and ePVF values of every instruction for two benchmark
programs, namely nw and lud in Figure 12. As can be seen in
the Ô¨Ågure, the CDF for PVF has a sharp spike near 1, while the
ePVF values are distributed more evenly throughout the range.
Therefore, we did not consider PVF-informed duplication as
a comparison point in this study.
To make the comparison fair, we control the performance
overhead incurred by both techniques we compare (by control-
ling the number of instructions we protect and measuring ex-
ecution time). Our hypothesis is that for a given performance
overhead bound,
the ePVF based duplication scheme can
offer higher SDC coverage than hot-path duplication. A full-
duplication technique (i.e., duplication of every instruction)
would offer 100% detection coverage, but incur signiÔ¨Åcant
performance overheads [13], [25]. Hence we do not consider
full-duplication technique in this work.
An ePVF-informed protection heuristic We Ô¨Årst com-
pute the ePVF value of each dynamic instruction using the
equation 3. Then, we compute the ePVF value of all static
instructions in the program by averaging the ePVF values of
all their dynamic instances, and rank the static instructions
in descending order of their ePVF values. We then select the
static instruction at the top of the list, and extract its backward
slice. Finally, we selectively duplicate the instructions in the
slice, and insert a comparison of the duplicated value with
the original value following the chosen instruction. Because
we need to limit protection within the overhead budget, we
measure the performance overhead incurred by duplication. If
the performance overhead bound is not exceeded, we choose
the next
the procedure.
Thus this is a greedy algorithm for choosing instructions to
duplicate. We use the same process for hot-path instructions,
with the difference that
the instructions are ranked in a
decreasing order of their execution frequencies instead of their
ePVF values.
instruction on the list and repeat
F
D
C
l
a
c