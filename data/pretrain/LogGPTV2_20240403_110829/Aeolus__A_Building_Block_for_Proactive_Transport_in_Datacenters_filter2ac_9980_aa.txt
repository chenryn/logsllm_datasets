title:Aeolus: A Building Block for Proactive Transport in Datacenters
author:Shuihai Hu and
Wei Bai and
Gaoxiong Zeng and
Zilong Wang and
Baochen Qiao and
Kai Chen and
Kun Tan and
Yi Wang
Aeolus: A Building Block for Proactive Transport in Datacenters
Shuihai Hu1,2⇤ Wei Bai1,3⇤ Gaoxiong Zeng1 Zilong Wang1 Baochen Qiao1 Kai Chen1
1SING Lab, Hong Kong University of Science and Technology
2Clustar
5Peng Cheng Lab
Kun Tan4 Yi Wang5
3Microsoft Research 4Huawei
ABSTRACT
As datacenter network bandwidth keeps growing, proactive trans-
port becomes attractive, where bandwidth is proactively allocated
as “credits” to senders who then can send “scheduled packets” at
a right rate to ensure high link utilization, low latency, and zero
packet loss. While promising, a fundamental challenge is that proac-
tive transport requires at least one-RTT for credits to be computed
and delivered. In this paper, we show such one-RTT “pre-credit”
phase could carry a substantial amount of ows at high link-speeds,
but none of existing proactive solutions treats it appropriately. We
present Aeolus, a solution focusing on “pre-credit” packet transmis-
sion as a building block for proactive transports. Aeolus contains
unconventional design principles such as scheduled-packet-rst
(SPF) that de-prioritizes the rst-RTT packets, instead of prioritizing
them as prior work. It further exploits the preserved, deterministic
nature of proactive transport as a means to recover lost rst-RTT
packets eciently. We have integrated Aeolus into ExpressPass[14],
NDP[18] and Homa[29], and shown, through both implementation
and simulations, that the Aeolus-enhanced solutions deliver sig-
nicant performance or deployability advantages. For example,
it improves the average FCT of ExpressPass by 56%, cuts the tail
FCT of Homa by 20⇥, while achieving similar performance as NDP
without switch modications.
CCS CONCEPTS
• Networks ! Transport protocols; Data center networks.
KEYWORDS
Data Center Networks, Proactive Transport, First RTT, Selective
Dropping
ACM Reference Format:
Shuihai Hu, Wei Bai, Gaoxiong Zeng, Zilong Wang, Baochen Qiao, Kai
Chen, Kun Tan and Yi Wang. 2020. Aeolus: A Building Block for Proactive
Transport in Datacenters. In Annual conference of the ACM Special Interest
Group on Data Communication on the applications, technologies, architectures,
and protocols for computer communication (SIGCOMM ’20), August 10–14,
2020, Virtual Event, NY, USA. ACM, New York, NY, USA, 13 pages. https:
//doi.org/10.1145/3387514.3405878
*Work done while Shuihai and Wei were both at SING Lab @ HKUST.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for prot or commercial advantage and that copies bear this notice and the full citation
on the rst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specic permission and/or a
fee. Request permissions from permissions@acm.org.
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-7955-7/20/08...$15.00
https://doi.org/10.1145/3387514.3405878
(b) Blind burst in pre-credit phase
(a) Waiting credits in pre-credit
phase
Figure 1: A substantial gap between existing proactive trans-
port baselines and the ideal performance. The setup is in §2.
Aeolus provides a common building block of proactive trans-
port to systematically bridge the performance gap caused by
the pre-credit phase.
1 INTRODUCTION
With datacenter network link speed growing rapidly from 1/10G to
100G, more ows become “smaller” and can be nished (in theory)
within a few RTTs (round trip time). Measurement of production
workloads reveals that, ideally, 60-90% of the ows can be nished
just in one RTT (§2.2). Therefore, it is crucial for transport to main-
tain low latency and high throughput at every single RTT.
Traditional "try and backo" transports (e.g., DCTCP [9], DC-
QCN [36], Timely [27]) are thus ill-suited to these requirements,
as they only react to congestion signals (e.g., ECN or delay) “after
the fact” and take multiple rounds to converge to the right rate.
While they can maintain good average performance for long ows,
it is hard to reach the right rate in each round, which is crucial for
small ows and tail performance. Hence, a recent line of work (e.g.
ExpressPass [14], NDP [18], Homa [29], FastPass [30], pHost [16])
explores a promising alternative, called proactive transport, in which
link capacities are proactively allocated, by the receivers or a cen-
tralized controller, as credits to each active sender who then can
send scheduled packets at an optimal rate to ensure high bandwidth
utilization, low queueing delay, and zero packet loss.
Despite being promising, on a closer analysis, we found all ex-
isting proactive solutions fall short of achieving the best possible
performance stated above. The key culprit is that, as they require
at least one RTT to allocate credits to a new ow, the rst RTT
(the “pre-credit phase”) poses a basic dilemma that compromises
the performance of these solutions (Figure 1). If the sender sends
no packet when waiting for credits (e.g. ExpressPass [14]), the new
ows will be paused by one RTT even though the network is under-
utilized (Figure 1(a)). If it bursts packets (e.g. Homa [29]), called
unscheduled packets, at a high rate, it can cause sporadic trac
spikes, non-trivial queueing delay, and eventually packet losses
of scheduled packets (Figure 1(b)). While there exists a potential
solution that relies on special hardware support from switches to
mitigate the consequence of packet losses (e.g. NDP [18]), it remains
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
S. Hu et al.
an open question whether the proactive transport’s potential can
be realized in a readily deployable way.
Aeolus is architecturally compatible with all existing proactive
solutions. We implemented an Aeolus prototype using DPDK [2]
and commodity switch hardware (§4.2), and integrated it with the
latest proactive solutions such as ExpressPass [14], Homa [29],
and NDP [18]. We further built a small testbed with one Mellanox
SN2000 switch and eight servers at 10Gbps (§5.1), together with
larger-scale trace-driven simulations at 100Gbps, to evaluate the
performance of Aeolus. We nd that:
• Aeolus + ExpressPass reduces the FCT by up to 33% on aver-
age at 10G testbed experiments, while achieving 56% improve-
ment in large-scale 100G simulations. This is because Aeolus
fully utilizes the spare bandwidth with pre-credit unscheduled
packets in the rst RTT which has not been used in ExpressPass.
• Aeolus + Homa reduces the tail FCT of small ows by 20⇥,
from 100s of ms to a few ms in 10G testbed experiments, while
achieving 1400⇥ improvement in simulations. This is because
Aeolus eectively eliminates losses of scheduled packets caused
by the burst of unscheduled packets, by enforcing the scheduled
packet rst principle.
• Aeolus + NDP achieves similar performance as NDP, but with-
out requiring switch modications. This is because similar to
the cutting payload technique [13] adopted by NDP, Aeolus
can eliminate large queue buildup by selectively dropping ex-
cessive unscheduled packets at the switch, while ensuring fast
loss recovery by reusing the preserved deterministic nature of
proactive transport.
2 BACKGROUND AND MOTIVATION
2.1 Proactive datacenter transport
Datacenter congestion control traditionally (e.g. [9, 22, 27, 36])
uses a “try and backo” approach and is thus largely reactive to
congestion. To meet increasing performance requirements, many
recent works are based on proactive transport, which operates in
a “request and allocation” style. The key conceptual idea behind
proactive transport is to explicitly allocate the bandwidth of bottle-
neck link(s) among active ows and proactively prevent congestion.
As a result, the switch will have ultra-low buer occupancy and
(near) zero packet loss. Central to proactive transport’s superior
performance is the perfect credit allocation to active ows, so any
new sender needs one RTT, which we call pre-credit phase, to inform
the receiver/controller to assign the credits.
There have been several implementations of the concept of proac-
tive transport. Fastpass [30] employs a centralized arbiter to enforce
a tight control over packet transmission time and path. PDQ [20]
and TFC [35] leverage switches to explicitly allocate link bandwidth
among the passing ows. ExpressPass [14], pHost [16], NDP [18]
and Homa [29] use receiver-driven credit-based approaches to ex-
plicitly schedule the arrival of data packets destined for dierent
receivers.
2.2 The pre-credit phase (1st RTT) matters
The rapid growth of DCN link speeds (from 1/10G to 100G) has
fundamentally changed the ow characteristics, in particular, an ex-
plosion number of the ows can complete in the rst RTT. Figure 2
shows the fraction of ows (and bytes) could have been nished
To address the problem, we observe that existing proactive trans-
ports can benet from an idealized pre-credit solution that meets
two seemingly contradicting principles:
• Fully utilizing spare bandwidth: new ows (with pre-credit
unscheduled packets) should burst in the rst RTT and strive to
complete if they can.
• Scheduled packet rst (SPF): scheduled packets should pro-
ceed as if no unscheduled packets are present.
As shown in Figure 1, this idealized pre-credit solution greatly
improves the average FCT for ExpressPass and tail FCT for Homa,
albeit for dierent reasons (see §2.3 for details).
The insight behind the idealized pre-credit solution is that proac-
tive transport is very susceptible to any delay or loss of scheduled
packets. A slight delay of scheduled packets can cause temporary
trac spikes at downstream switches, which can break the del-
icate bandwidth allocation and aect more ows in a cascading
style, eventually creating a perfect storm (§2.4). Moreover, these
uncertainties cripple the proactive transport’s unique performance
predictability. In our experiment, we found that dropping one sched-
uled packet can increase ow completion time by up to 100⇥ due
to the retransmission timeout. These problems can be further ex-
acerbated by the bursts of many short ows comprising mostly of
unscheduled packets.
To summarize, the deterministic nature of proactive transport
means any drop or delay of scheduled packets could inict a dispro-
portional damage. As a solution, the idealized pre-credit scheme can
eectively avoid the pitfalls in recent proactive solutions (e.g. [16,
18, 29]) by safeguarding the scheduled packets and de-prioritizing
the unscheduled packets, as opposed to the other way around.
The key contribution of this work is to make the above idealized
pre-credit solution practical. We present Aeolus1, a readily deploy-
able building block for proactive transport that meets the above
two principles of scheduled packet rst and fully utilizing spare
bandwidth with unscheduled packets simultaneously.
Aeolus realizes its design goal by proposing a novel selective
dropping mechanism (§3.2) which allows pre-credit new ows to
burst at line-rate when there exists spare bandwidth left over by
scheduled packets, but immediately drops them selectively once
the bandwidth is used up. In this way, Aeolus eectively utilizes
available bandwidth with unscheduled packets while safeguarding
the scheduled packets, thus achieving the above two principles
simultaneously. In particular, we show that our selective dropping
is readily implemented with only one queue at commodity switches
by using the Active Queue Management (AQM) feature (§4.1).
Furthermore, it is worthwhile to note that since we have pro-
tected the scheduled packets, as a reward, our loss recovery of
unscheduled packets can be designed much simpler yet ecient.
The idea is to reuse the preserved proactive transport as a reli-
able means to recover dropped pre-credit packets—any dropped
unscheduled packet will become a scheduled packet in the next
round, whose delivery is guaranteed. Therefore, we just need to
locate packet losses in the rst RTT and then retransmit them once
using scheduled packets (§3.3).
1We presented a preliminary idea of Aeolus in an earlier workshop paper [21]
Aeolus: A Building Block for Proactive Transport in Datacenters
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
(a)
(b)
Figure 2: A substantial fraction of ows (and bytes) could
have been nished within the rst RTT (pre-credit phase),
and this fraction grows rapidly as link speed increases.
within the rst RTT (pre-credit phase) under dierent link speeds.
Flows are generated according to four realistic workloads including
Web Server [31], Cache Follower [31] Web Search [9] and Data
Mining [17].
For Figure 2(a), we calculate FCTs of ows by simply dividing
ow size by the given link speed. For Figure 2(b), we calculate the
expected average ow size of a given workload (denoted as A), and
the number of bytes a given link speed can transmit in one RTT
(denoted as B). We simply use B/A as the fraction of bytes could
have been nished within the rst RTT. Although admittedly, this
methodology is greatly idealized, it suggests a clear trend that the
rise of high-speed DCNs have dramatically shifted the distributions
of ow completion time, with many ows, in theory, being able to
complete in the rst RTT.
In the light of existing proactive transport designs, the fact that
more ows can complete in the rst RTT has several important
implications:
• Many ows will benet from sending data immediately after they
arrive, as opposed to waiting for credits (as in [14, 30]). This
coincides with the ethos of recent proactive transport designs [16,
18, 29].
• There will be more spare bandwidth. This creates more poten-
tial benets and motivation to send (unscheduled) packets in a
speculative fashion to take advantage of the spare capacity.
• More packets will be rst-RTT packets. This means more frequent
contention between unscheduled packets (sent in the pre-credit
phase) and scheduled packets (sent with credits in all subsequent
RTTs), which potentially undermines the gains of unscheduled
packets.
In short, this short analysis indicates existing proactive transport
designs demand an eective pre-credit solution to fully utilize spare
bandwidth in the rst RTT as the link speed signicantly increases.
2.3 Performance issues of exiting solutions
Through an empirical analysis on the representative proactive trans-
port solutions, we demonstrate a key tradeo in how they handle
the rst RTT (i.e., the pre-credit phase).
Why not wasting the pre-credit phase? On the one hand, if
the sender holds during the pre-credit phase, it can deal a heavy
blow on short messages, which could have been completed in the
rst RTT. To concretely show its impact on performance, we chose
ExpressPass [14], the most recent proactive transport proposal that
(a) Cache Follower
(b) Web Server
Figure 3: FCT of 0-100KB ows under the original Express-
Pass and the hypothetical ExpressPass with idealized pre-
credit solution (fully utilizes the spare bandwidth in the rst
RTT).
(a) Cache Follower
(b) Web Server
Figure 4: FCT of 0-100KB ows under the original Homa
and the hypothetical Homa with idealized pre-credit solu-
tion (no interference between scheduled and unscheduled
packets).
sends only scheduled packets after the pre-credit phase (although