Age
18 - 23
24 - 30
31 - 40
41 - 50
51 or over
11
61
67
30
31
Participants
19
40
18
1
96
26
Education
Up to high school
Some college (1-4 years, no degree)
Associate’s degree
Professional school degree
Bachelor’s degree
Graduate Degree
6 User Studies: Analyze, Design, Evaluate
Since our attack is a phishing attack at its core, it is important
that it is persuasive to users. We speculate that users’ compre-
hension of runtime permissions and their expectations from
apps in this context will play a signiﬁcant role in how users
perceive our attack and impact its success. To this end, we
performed a survey-based user study to quantify user behavior
and used this quantiﬁcation in order to guide the design of
the attack and estimate its chances of success. Our ﬁndings
suggest that Android users generally have a good understand-
ing of the basics of the runtime permission model but appear
confused about its intricate details. In particular, users demon-
strate signiﬁcant lack of appreciation of the critical security
guarantees provided by runtime permissions. This leaves a
sufﬁcient gap in user understanding to enable an effective
attack. In addition to the survey study, we conducted an in-
lab user study, which involved fewer users than the survey
but provided a more realistic setting based on real devices
and common daily tasks performed with popular apps. We
provided each participant with an Android device on which
we launched our attacks and found that none of the partici-
pants detected our attack. We obtained IRB approval from our
institution prior to the commencement of our user studies.
6.1 Susceptibility and Design
Our survey has two goals. First, we would like to estimate the
susceptibility of users to false transparency attacks. Second,
we would like to verify the validity of our conjectures on what
makes users suspicious so the design of the phishing attack
can reﬂect the best options for deception. Previous work has
shown that permission requests not deploying our attack are
likely to be denied by users if the app is not highly-reputable
or does not provide any utility that requires the requested
permission [2]. We treat this as a baseline control compared
to our technique. We refer our readers to Appendix A for a
more detailed discussion on this.
Recruitment and incentives. We recruited 200 participants
from Amazon Mechanical Turk (mTurk) to complete our
online survey. Our inclusion criteria are 1) using Android
as a primary device, 2) having at least 100 approved Human
Intelligence Tasks (HIT), and 3) having a HIT approval rate
of at least 70%. We paid each participant $0.5 for their effort.
The median time to complete our survey was 7.08 minutes.
Employment
Arts & Entertainment
Business & Finance
Education
Engineering
Health Care
Human Resources
Information Technology
Management
Miscellaneous
Religion
Retail & Sales
Retired
Self-Employed
Student
Unemployed
Participants
11
23
9
18
11
4
37
12
17
1
17
4
24
2
10
Participant demographics can be observed in Table 3.
Methodology. At the beginning of this survey, we informed
our participants that they will be asked questions about their
experience with Android permissions; however, to avoid un-
necessarily priming them, we do not reveal that we are testing
the feasibility of our attacks. We ask questions to assess their
knowledge of runtime permissions to understand if there is
any underlying vulnerability due to lack of domain knowledge.
In addition, we ask questions to verify the design decisions
we discussed in Section 4.
Results. We now present our ﬁndings from this survey. The
percentages we quote below have a ±7% margin of error for
a 95% conﬁdence. We will specify the questions we obtained
these results from to help our readers easily follow our results.
Appendix B presents our survey questions in quiz format.
• Understanding of the runtime permission model. We ﬁrst
ask users to self-report their level of familiarity with Android
permissions. 8% of the users identify themselves as expert,
41% as knowledgeable, 37% as average, 13% as somewhat
familiar, and 1% as not familiar (Q1). 71% of the users are
aware that Android used to have an install-time permission
424    29th USENIX Security Symposium
USENIX Association
model (Q2). The vast majority of users (91%) have used the
new runtime permissions (Q4) while almost all of the users
(98%) are aware that runtime permission model allows them
to review and update their previous permission-related deci-
sions through the Settings app (Q21). These results indicate
that our participants are generally familiar with the basics of
runtime permissions.
In contrast, we observe that users’ answers are often wrong
when we ask more intricate questions about the inner work-
ings of runtime permissions. An app needs to be in the fore-
ground during a permission request, but less than half (47%)
of the users agreed with this, while 25% disagreed and 28%
said they did not know (Q24). This is worrisome because
this fact is central to the contextual security guarantee of the
runtime permission model as we explained in Section 4.1.
Indeed, as we will show, only one of the users who agreed
was able to use their understanding in practice to avoid our
attack.
When participants were asked whether they thought an
app could prompt the user again for a permission that was
previously granted to it, 41% agreed, 36% disagreed, and
23% said they did not know (Q10). This statement is false.
Android does not allow apps to re-prompt users for granted
permissions: permission dialogs are never shown again to the
users in this case. This misunderstanding can be exploited, as
shown with our attacks in Section 4.
We ask further questions to assess users’ awareness of the
identity security guarantee provided by app names in permis-
sion dialogs. First of all, we present them with a storyboard of
our attacks where we describe an actual scenario concerning
a popular app requesting permissions for its use. We ask them
to role-play based on screenshots of the permission requests.
For this purpose, we utilized Viber, a popular messaging app
with millions of downloads. In particular, we presented our
participants with a scenario where they use Viber to text their
friends and the app requires contacts permission for providing
this utility. Then, they switch to another app brieﬂy and switch
back to Viber again where they continue texting. Afterwards,
we ask them to grant or deny each permission request. The
ﬁrst time they use Viber, the permission dialog displayed to
them is benign and we use the name “Viber” (Q5). However,
the second time we instead display “this app” as the app name
in the permission dialog representing our multi-target attack
scenario (Q13, Q14). We observed that 77% of the partici-
pants granted the permission for the benign request (Q6) and
74% of them subsequently decided to allow the second (ma-
licious) permission request (Q15). Note that this difference
falls within our 7% margin of error. For participants who
denied the second request, we inquired if they declined due
to having noticed our attack. For this purpose, we provide
them a text ﬁeld under the “other” category to write their
comments. We had only one user who noticed the odd app
name and declined the permission because it looked “ﬁshy”.
In another role playing example, we presented an actual
scenario where they used Google Maps for navigation and
the app prompts for the location permission (Q17). We again
use “this app” for the attack app’s name and ask users to
grant or deny the permission (Q18). In this case, 89% of the
users decided to give the app the permission. We then asked
them which app they have given or denied the permission
to (Q19, Q20). 168 (84%) of our participants reported that
they granted or denied it to Google Maps, while the rest of
them had varying answers: 4 said Google, 4 mentioned a map
program, 2 could not remember the app name, 6 mentioned
another app (i.e., Viber (5), Yelp (1)), 1 said “this app”, 3
said “the app” or “the app I use”, 8 said they granted the
location permission. The rest (4) wrote somewhat irrelevant
text, not showing much understanding of what the question is
asking. Note that the participant who said “this app” denied
the permission request in this case, but they granted the re-
quested permission to Viber for the malicious request. To sum
up, we believe the results from both our Google Maps and
Viber examples demonstrate that users are generally unaware
of the identity guarantee provided in permission dialogs, as
the majority fails to recognize anything suspicious. To our
attack’s advantage, they seem to be mostly interested in the
context they are presented with at the time of the request (i.e.,
what they are seeing); they either do not pay attention to app
names in the requests or simply consider the plain English
interpretation of the statement shown in the dialogs.
In conclusion, although users demonstrate familiarity with
runtime permissions, we observe that they struggle with the
more intricate details of this permission model. They espe-
cially show lack of understanding of the security guarantees
of runtime permissions, thus leaving avenues for a false trans-
parency attack.
• Verifying the design decisions for the attacks. In this part
of the study, we verify the validity of our design decisions
made in Section 4 regarding the best conditions for the at-
tacks. First, we show that it is indeed suboptimal to request a
permission when there is no app in the foreground. Second,
we show that requesting a permission multiple times within
the same session would indeed alarm the users and lead them
to consider taking an action. Hence, we should only request
granted permissions. Third, success rate of a secondary mali-
cious request is as likely as a primary benign request. We do
not study how the relevance of a permission to an app’s utility
affects users’ decisions, as this relationship was previously
demonstrated to be correlated with higher grant rates [2].
First of all, we would like to verify it is indeed not ideal for
an attacker to request a permission when there is no app in
the foreground. For this purpose, we show a sample screen-
shot of a popular communication app requesting the contacts
permission when there is no visible app in the foreground
and ask them if they would grant or deny this request (Q7,
Q8). In this case, 53% of the users select deny, 27% select
allow, and 20% express that their decisions would depend on
additional factors. For when a similar popular communication
USENIX Association
29th USENIX Security Symposium    425
app requests the contacts permission while in the foreground
(i.e., our aforementioned Viber case), we observe the deny
rate to be 23%. We perform Chi-squared test on the deny rate
with Yates correction and get the p-value of 1.22× 10−9. At
the conﬁdence level of 0.05, this indicates that the deny rate
without a visible app in the foreground is signiﬁcantly higher
than that when a similar popular communication app is in the
foreground.
Next, we would like to verify that users would be alarmed
and prone to take an action if an app requested the same per-
mission multiple times within the same launch/session (Q22).
As we had explained, this case happens only if the attacker
requests a permission that was not previously granted. In this
case, only 17% of the participants said they would ignore and
proceed normally, 43% said they would be suspicious of the
requesting app, 23% said they would be suspicious of the other
apps installed on their device, 15% said they would be suspi-
cious of the operating system itself, and 2% mentioned they
would have other ideas. Participants were able to select multi-
ple options for this question, except for the ﬁrst option which
could be answered only exclusively. We additionally ask the
participants who did not say they would ignore the multiple
requests what actions they would consider taking (Q23). 43%
said uninstalling the app that requested the permission, 41%
said investigating other apps that request this permission via
the Settings app, 11% said reformatting the operating system
to go back to factory settings, and 5% mentioned taking other
actions. Again for this question, participants were allowed to
select multiple options simultaneously.
Additionally, we show that the grant rate for a secondary
permission request by an attacker is as successful as a ﬁrst
time request for the same permission by a victim, indicating
that the attacker is not compromising the success of their
attacks by requesting granted permissions. Looking at the
aforementioned Viber case, we observed the grant rate for
a primary benign request to be 77% (Q6) and 74% for a
secondary malicious request (Q15). Given our 7% margin of
error, we observe no statistical difference between these grant
rates. This shows that the request of a previously-granted
permission can be as effective as a ﬁrst time request initiated
by the victim, while avoiding unnecessarily alarming users.
6.2 Feasibility of the Attacks
In this part of our user study, we launch our attacks in a realis-
tic setting to evaluate the feasibility of our attacks. More
speciﬁcally, we are interested in whether the participants
would at least suspect they are under attack while performing
tasks they might come across in their every day life.
Recruitment. In order to evaluate the feasibility of our at-
tacks, we recruited 20 subjects to participate in our in-lab
study on a voluntary basis. We advertised our study via word-
of-mouth at the research institution where the study was con-
ducted. Our participant pool consists of undergraduate and
graduate students who major in computer science or other en-
gineering ﬁelds. Some of our participants even have graduate
course level background on security and privacy. Hence, we
expect this group to be relatively security-conscious, creating
notable difﬁculty for attackers to successfully execute their
attacks. We only recruited participants that have used Android.
To avoid priming our participants, we advertised our study’s
purpose to be a measurement of user expectations in terms
of performance for popular Android apps and debriefed them
after the completion of our study to disclose our real intent.
Methodology. In our experiments, we utilize three popular
Android apps as victims: 1) Google Maps, a navigation app
developed by Google, 2) Shazam, an app for song identiﬁca-
tion developed by Apple, and 3) Messenger, a communication
app developed by Facebook. For each app, we assign our
participants a simple yet realistic task to complete and ask a
question about the task upon completion. First, we ask our
participant to launch Google Maps to ﬁnd the walking route
between two predetermined points and tell us the duration of
this trip. Then, we ask our participants to launch Shazam to
identify the song we are playing during the experiment and
tell us the name of the song. Finally, we ask our participants
to launch Messenger to send a message to one of our test
accounts from the test account set up on the provided phone
and tell us what response they got in return.
We have three separate attack apps installed on the device,
each targeting only one of the victim apps. The attack apps
that target Google Maps and Shazam utilize the same app
name as their victims (i.e., Maps and Shazam respectively).
The attack app that targets Messenger uses “this app” as its
app name in order for us to also test for the feasibility of
our multi-targeted attack case. At the end of our experiments,
we have an exit survey where we ask the participants about
their overall experience with the tasks, i.e., whether they have
experienced any slowdown and if they have noticed anything
strange or unusual during any of the tasks. We also give them