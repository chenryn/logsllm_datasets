is 0.974, while the partial ROC AUC at 1% false positives is 0.0079
(compared to 0.987 and 0.0087, respectively, on the smaller benign
subset). Similarly, the corresponding VGG-16 ROC AUC is 0.781.
7 DISCUSSION
We discuss the implications of the efficacy of VisualPhishNet by
showcasing phishing examples that were correctly detected, and
failure modes with both false positive and false negative examples.
7.1 Evaluating Successful Cases
We categorize the successfully classified phishing pages into three
main categories. The first one is the easily classified ones consisting
of exact or very close copying of a corresponding legitimate web-
page from the training trusted-list. However, our model still showed
robustness to small variations such as the text language of login
forms (which shows an advantage over text-similarity methods),
small advertisements’ images changes, the addition or removal of
elements in the page, and changes in their locations. We observed
that these pages have approximately a minimum distance in the
range of 0-2 to the training set (as shown in the distances’ histogram
in Figure 7) and constitute around 25% of the correct matches. The
second category, which is relatively harder than the first one, is the
phishing webpages that look similar in style (e.g. location of ele-
ments and layout of the page) to training pages, however, they are
highly different in content (e.g. images, colors, and text). We show
examples of this second category in Figure 9. Similarly, these pages
correspond approximately to the distance range of 2-4 in Figure 7
and constitute around 35% of the correct matches.
Finally, the hardest category is the phishing pages showing dis-
parities in design when compared to the training examples as shown
t
s
e
t
g
n
i
h
s
i
h
P
h
c
t
a
m
t
s
e
s
o
l
C
(a)
(b)
Figure 8: Adversarial examples generated with FGSM on the
triplet loss with ϵ = 0.01 (a) and ϵ = 0.005 (b).
and 0.01. After training, we again applied FGSM on the phishing
test set using the tuned model. As shown in the last two columns
of Table 5, the performance improved to reach a comparable per-
formance to the original set in the case of the 0.005 noise. These
results demonstrate that VisualPhishNet, after retraining, is robust
against adversarial attacks with slightly added noise.
Evaluating different browsers. We studied the effect of the changes
caused by other browsers than the one we used to build the dataset
(Firefox) as an example of one of the factors that could be different
when deploying the system. Thus, we created a subset of 50 URLs
from 14 websites, and we used Firefox, Opera, Google Chrome,
Microsoft Edge, and Vivaldi browsers to take screenshots of these
pages of which we computed the VisualPhishNet’s embeddings.
In Table 6, we quantify the browsers’ changes by comparing the
L2 differences between Firefox’s embeddings (to match the dataset)
and other browsers’ ones, which we found smaller by at least ≈6.6x
than the differences caused by the slight hand-crafted perturbations
(applied on Firefox screenshots) we previously showed in the first
row of Table 4 and demonstrated that they already had a small
effect on the performance. Additionally, some of these browser
differences were due to advertisement or color differences which
are already included in the constructed dataset (see Appendix B).
6.8 Testing with New Crawled Data
Zero-day pages. To provide additional evidence for the efficacy
of VisualPhishNet in detecting zero-day pages, we crawled recent
955 PhishTank pages targeting the trusted-list (examples in Ap-
pendix B). These are new pages that were created and captured
after dataset collection, training, and evaluating the model with all
previous experiments, and therefore, they are future pages with
temporal separation with respect to the model. Additionally, We
used a different browser, machine, and screen size from the ones
Browser Chrome
Noise
0.278±0.54
Blurring
4.92±2.71
Opera
0.271±0.21
Edge
0.23±0.75
Gaussian Salt and Pepper
2.73±1.02
6.80±2.24
Vivaldi
0.41±0.57
Shift
5.43±2.36
Table 6: The L2 difference between Firefox screenshots’ em-
beddings and other browsers’ ones, compared to the L2 dif-
ference due to the studied slight perturbations.
Figure 9: Test phishing pages (first row) that were correctly
matched to the targeted websites (closest match from the
training set in the second row) with the closest pages having
a relatively similar layout but different colors and content.
10
in Figure 10. These pages had distances to the training set which
were higher than 4 and increased according to their differences and
they constitute around 40% of the correct matches. For example,
the first three columns show a match between pages with different
designs and elements’ locations. Also, the fourth phishing page has
a pop-up window that partially occludes information and changes
the page’s colors. The fifth phishing page is challenging as it does
not show the company logo, yet it was correctly matched to the
targeted website due to having other similar features. This suggests
that VisualPhishNet captures the look and feel of websites, which
makes it have an advantage over previous matching methods that
relied only on logo matching such as [1, 13]. The last two pages are
highly dissimilar to the matched page except for having the same
logo and other similar colors. Even though these examples could
arguably be easily recognized as phishing pages by users, they are
more challenging to be detected based on similarity and therefore
they were excluded in previous studies such as [33], however, we
included them for completeness. This analysis shows the ability of
VisualPhishNet to detect the similarity of phishing pages that are
partially copied or created with poor quality in addition to unseen
phishing pages with no counterparts in the training trusted-list,
which all are possible attempts to evade detection in addition to the
ones we previously discussed. We also show in Appendix A phish-
ing examples targeting different websites that have highly similar
colors but they were correctly distinguished from each other.
Since these successful matches suggest that the logo of a page
plays an important factor in the matching decision, possible false
matches could happen if a benign page contains another website
logo. To evaluate this, we collected a benign subset of 125 pages
(see Appendix B) that contain the logos of one or more of 9 trusted
websites. These pages are articles about a website, or login pages
with other websites’ sign-in or sharing options. However, only 3.07%
of these pages were matched to the website whose logo appears in
the screenshot which indicates that the learnt profiles incorporate
more visual cues than logos only.
7.2 Evaluating Failure Modes
We also analysed the failure modes of the model including wrong
websites matches and false positives. We found that the highest mis-
matches are for phishing examples belonging to Facebook, Dropbox,
Microsoft one drive, Microsoft Office, and Adobe. We found that
these websites have many phishing pages with dissimilar appear-
ances (and poor designs) compared to the targeted websites, such
as the first three phishing pages targeting Facebook and Microsoft
Excel in Figure 11 (see also Appendix B for more examples). On
the other hand, phishing pages targeting banks had higher qual-
ity in copying and appeared plausible and similar to the targeted
websites making them have fewer mismatches (see Appendix A for
a histogram of wrong matches). To analyse how successful these
dissimilar pages in fooling users, we conducted an online study
where users were shown dissimilar and relatively similar phishing
pages and were asked to evaluate how trustworthy they seem based
only on their appearance. Only 3.02% said that they would trust the
dissimilar examples as opposed to 65.3% in the case of the relatively
similar ones (see Appendix B for examples used in the study).
We also found some phishing pages that used outdated designs
or earlier versions of certain login forms such as the fourth example
in Figure 11 (that is now changed entirely in Microsoft website)
and were, therefore, matched to a wrong website. This could be
improved by including earlier versions of websites in the training
data. Moreover, the last three examples in Figure 11 show some of
the main limitations. Since our training trust-list contains a large
number of screenshots per website, we have many distractors of
potentially similar pages to the query screenshot, such as the fifth
and sixth examples in Figure 11 that were matched to similar screen-
shots from different websites. We also found that some phishing
pages have pop-up windows that completely covered the logo and
the page’s colors and structure, and were then matched to pages
with darker colors such as the last example in Figure 11. The wrong
matches had generally higher distances than the correct matches
which could make them falsely classified as legitimate examples.
We also show false positive examples (benign test pages) that
had high similarity to pages from the training set in Figure 12 and
would be falsely classified as phishing pages based on the threshold
in Figure 7. We observed that pages with forms were harder to
identify as dissimilar to other pages with forms in the trust-list es-
pecially when having similar colors and layout, since they contain
few distinguishable and salient elements and they are otherwise
similar. We believe that using the screenshot’s text (possibly ex-
tracted by OCR), or more incorporation of the logo features along
with other visual cues by region-based convolution [40] could be
future possible model optimization directions to help reduce the
t
s
e
t
g
n
i
h
s
i
h
P
h
c
t
a
m
t
s
e
s
o
l
C
Figure 10: Examples of test phishing webpages that were correctly matched to the targeted websites despite having large
differences in layout and content.
11
t
s
e
t
g
n
i
h
s
i
h
P
h
c
t
a
m
t
s
e
s
o
l
C
Figure 11: Examples of test phishing webpages that were matched to the wrong website from the training set.
false positives and also improve the matching of hard examples.
Additionally, tackling the phishing problem has many orthogonal
aspects; while we focus on visual similarity to detect zero-day and
unseen pages and achieve a significant leap in performance, our ap-
proach could still be used along with other allow-listing of trusted
domains to further reduce the false positives.
7.3 Deployment Considerations
We here discuss practical considerations for the deployment of
our system. First, regarding the required storage space and com-
putation time, our system does not require storing all screenshots
of the trusted-list, as it suffices to store the embedding vectors of
screenshots (512-dimensional vectors). Also, the system is compu-
tationally feasible since the training trusted-list embeddings can be
pre-computed, which at test time only leaves the relatively smaller
computations of the query image embedding and the L2 distances.
On a typical computer with 8 GByte RAM and Intel Core i7-8565U
1.80GHz processor, the average time for prediction was 1.1±0.7 sec-
onds which decreased to 0.46±0.25 seconds on a NVIDIA Tesla K80
GPU. If further speeding up is needed, the search for the closest
point could be optimized. Besides, the decision could only be com-
puted when the user attempts to submit information. We also show
in our analysis of possible perturbations that the learned similarity
is robust against partial removal of parts of the page, which sug-
gests that a page could be detected even if it was partially loaded.
Other deployment issues are the browser window size variations at
test time which could be solved by fixing the size of the captured
screenshot. Another issue is the maintenance of the domain names
of the trusted-list in case a website has changed its domain, which
could be solved by rolling updates of the trusted-list without the
need to retrain. Additionally, we observed that VisualPhishNet is
t
s
e
t
e
t
a
m
i
t
i
g
e
L
h
c
t
a
m
t
s
e
s
o
l
C
Figure 12: False positive examples of the top closest legiti-
mate test pages to the training list.
12
robust against small changes or updates in the website logo’s fonts
or colors (e.g. see Yahoo examples with different versions that were
still correctly detected in Appendix A). Larger or more significant
changes (that usually happen on long time intervals) might require
retraining and updating. Moreover, the current system and dataset
are focusing on Desktop browsers, however, the concept can be
extended to other devices (e.g. smartphones) which may require
re-training. Furthermore, our visual similarity model can either
be used as a standalone phishing detection model or, as the last
defense mechanism for unseen pages along with other (potentially
faster) listing or heuristics approaches. Regarding the VisualPhish
dataset, we point out that the manual work in curating the dataset
was mainly for constructing unbiased and non-duplicated test sets,
however, it is less needed in collecting the training trusted-list of
trusted websites. This enables the automatic update of the trusted-
list to add new websites when needed. Nevertheless, detecting du-
plicity can be automated by finding the closest pages to the newly
added one based on pixel-wise features (such as VGG features).
8 CONCLUSION
As visual similarity is a key factor in detecting zero-day phish-
ing pages, in this work, we proposed a new framework for visual
similarity phishing detection. We presented a new dataset (Visual-
Phish: 155 websites with 9363 screenshots) that covers the largest
trusted-list so far and overcomes the observed previous limitation.
Unlike previous work, instead of only matching a phishing page
to its legitimate counterpart, we generalize visual similarity to de-
tect unseen pages targeting the trusted websites. To that end, we
proposed VisualPhishNet that learns a visual profile of websites by
learning a similarity metric between any two same-website pages
despite having different contents. Based on our qualitative analysis
of the successful cases of VisualPhishNet, our network identified
easy phishing pages (highly similar to pages in training), and more
importantly, phishing pages that were partially copied, obfuscated,
or unseen. VisualPhishNet was found to be robust against the range
of possible evasion attacks and perturbations that we studied, which
makes our model less prone to the fierce arms race between attack-
ers and defenders.
In conclusion, our work introduces important contributions to
phishing detection research to learn a robust and proactive visual
similarity metric that demonstrates a leap in performance over prior
visual similarity approaches by an increase of 56 percent points in
matching accuracy and 30 in the classification ROC area under the
curve.
REFERENCES
[1] Sadia Afroz and Rachel Greenstadt. 2011. Phishzoo: Detecting phishing websites
by looking at them. In Proceedings of the IEEE International Conference on Semantic
Computing.
[2] APWG. 2019. Anti Phishing Working Group report.
(2019). https://www.
antiphishing.org/resources/apwg-reports/.
[10]
[3] Battista Biggio and Fabio Roli. 2018. Wild patterns: Ten years after the rise of
adversarial machine learning. Pattern Recognition 84 (2018), 317–331.
[4] Aaron Blum, Brad Wardman, Thamar Solorio, and Gary Warner. 2010. Lexical
feature based phishing URL detection using online learning. In Proceedings of
the ACM Workshop on Artificial Intelligence and Security.
[5] Ahmet Selman Bozkir and Ebru Akcapinar Sezer. 2016. Use of HOG descriptors
in phishing detection. In Proceedings of the IEEE International Symposium on