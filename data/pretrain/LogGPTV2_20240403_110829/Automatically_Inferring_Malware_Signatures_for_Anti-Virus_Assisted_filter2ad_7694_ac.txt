commercial anti-virus products. The setup is kept identical
to the previous experiment with the only exception that
we do not have access to the ground truth for the original
signatures. We therefore focus on statistically assessing the
quality and content of the derived signatures.
Derived Signatures
#Labels Hash sums Byte patterns Unknown
AV1
AV2
AV3
AV4
AV5
1327
277
522
282
586
1
940 (71%)
(0%)
323 (62%)
178 (63%)
177 (30%)
377 (28%)
255 (92%)
69 (13%)
93 (33%)
353 (60%)
10 (1%)
21 (8%)
130 (25%)
11 (4%)
56 (10%)
Average
598
323 (54%)
229 (38%)
45 (8%)
Table 2: Results of signature derivation.
Table 2 provides a ﬁrst overview of the derived signatures,
where AV1 corresponds to ClamAV and the remaining scan-
ners to commercial products. The scanners considerably
diﬀer in type and amount of signatures that can be derived.
On average, our approach is able to infer 38% pattern-based
signatures and 54% hash-based signatures, whereas only the
remaining 8% cannot be uncovered.
AV2 especially stands out with 92% byte patterns and only
a single hash-based signature, while for the other scanners
at least one third of all signatures corresponds to hash sums.
On the other end of the scale, for AV3 we fail to extract
one forth of all signatures. This may indicate the use of
advanced heuristics or that multiple pattern-based signatures
are assigned to the same label, implicitly constructing a
signature with long disjoint patterns. We discuss this in
more detail in Section 7.
To illustrate the quality of the derived signatures, let us
consider the byte patterns shown in Figure 5 and 6, respec-
tively. Figure 5 shows a signature for the malware family
Swizzor . Clearly, an eﬀort has been made to pinpoint the de-
cryption loop of the malware (starting at line 7) that unveils
the malicious payload at runtime. In particular a 5-byte long
key is used to decrypt data using the XOR operator (line 8).
By contrast, the signature shown in Figure 6 contains an
ASCII string that corresponds to the Windows product key
of the Anubis sandbox. The instructions at lines 6–11 are
part of a call to the RegOpenKeyExA API function. This sig-
nature captures a simple environment check used by several
backdoors that compares the product key of the execution
environment against known sandbox systems.
1md5: e7f7d72e1f7f3371e2cf495d76b2b88a
1
2
3
4
5
6
7
8
9
10
11
12
13
14
83 c7 43
89 fa
83 ea 2e
{2}
00 00
33 c0
8a 1f
32 1C 10
88 1F
40
83 f8 05
7c 02
33 c0
47
; add edi, 0x43
; mov edx, edi
; sub edx, 0x2e
; 2-byte gap
; xor eax, eax
; mov bl, byte ptr [edi]
; xor bl, byte ptr [eax + edx]
; mov byte ptr [edi], bl
; inc eax
; cmp eax, 5
; jl
; xor eax, eax
; inc edi
+2
Figure 5: Derived signature for the Swizzor malware:
The byte patterns match a XOR-based decryption
loop (line 7) with a 5-byte key (line 11).
1
2
3
4
5
6
7
8
9
10
11
12
13
49 64 00 00
37 36 34 38
37 2d 33 33
37 2d 38 34
32 39 39 35
35 2d 32 32
36 31 34 00
50
81 c4 f4 fe ff ff
33 c0
54
6a 01
6a 00
; "Id"
; "76487-337-8429955-22614"
; push eax
; add esp, 0xfffffef4
; xor eax, eax
; push esp
; push 1
; push 0
Figure 6: Derived signature for a generic backdoor:
The byte patterns correspond to the Windows prod-
uct key of the Anubis sandbox (line 2–5).
Not all of the signatures we derive can be interpreted as
clearly as these examples. Many signatures match resources,
wrongly aligned code, import tables or even compressed
data. To get a better understanding for the quality of these
signatures, we statistically analyze the characteristics of
the corresponding byte patterns derived by our method.
Figures 7(a) to 7(c) show for each of the ﬁve scanners the
distribution of the signature size, the number of gaps and
the entropy of the patterns.
With respect to the size, AV2 again draws attention: It
appears that this scanner makes use of very compact and
equally sized patterns that contain no or only a few gaps.
While short signatures generalize well, they may also induce
more false positives which presumably is the reason why other
scanners such as AV3 –AV5 use longer signatures—partly also
with more gaps between the byte patterns. As demonstrated
in Section 2 short signatures are good candidates for malicious
markers.
As malicious markers might be restricted to a speciﬁc
character set, it is also interesting to see how the entropy of
the byte patterns is distributed. An entropy of 0.0 indicates
uniform byte patterns, such as paddings, while values close
to 8.0 are reached by random, encrypted or compressed data.
Matched import tables reside on the lower end of the scale due
to the identical signiﬁcant bytes of addresses and x86 code
is mostly located in the middle and upper half of the scale.
Three of the scanners cover almost the full entropy range,
indicating the diversity of the byte patterns in the signatures.
592(a) Size of signatures
(b) Gaps in signatures
(c) Entropy of byte patterns
(d) Agreement with labels
Figure 7: Statistics for the derived byte-pattern signatures. The agreement with anti-virus labels is given as
F-measure of the labels and the clustered signatures.
Finally, we inspect how well the pattern-based signatures
have been derived by our method. Since we do not have
ground truth, we rate the quality of the signatures by cluster-
ing them and comparing the clusters to the groups of labels
the signatures correspond to. This conformity is plotted in
Figure 7(d) as the F-measure for the individual anti-virus
products. On average the derived signatures yield an agree-
ment with the labels of 96%, that is, for most of the dataset,
similar signatures are assigned to the same label, whereas dis-
similar signatures are associated with unequal labels. While
this experiment cannot prove that the derived signatures
exactly match their counterparts, it demonstrates that we
infer a representation that is at least closely related to the
original signatures.
4.4 Signature Overlap
Although anti-virus vendors openly share samples, con-
crete signatures usually are not exchanged as these represent
a company’s trade secret. We investigate to which extend
signatures nevertheless overlap between competing anti-virus
products. To this end we measure the number of (half-)bytes
in relation to a signature’s length that overlap between prod-
ucts. Figure 8 shows the average overlap of the ﬁve considered
engines to each other. Only 5.2% of the derived signatures
fully overlap with the signature of another vendor in a way
that both products raise an alarm on the same substring of
bytes. Consequently, for 94.8% of the signatures a virus scan-
ner raises an alarm while others do not. 21.9% even have no
resemblance among diﬀerent anti-virus products at all.
Figure 8: Average overlap (ratio of identical bytes)
of signatures derived from AV1 –AV5 .
4.5 Context and Semantics of Signatures
As ﬁnal experiment of our study, we analyze the quality
of the derived signatures. We are interested in determining
whether the signatures are bound to a speciﬁc context within
the ﬁle and if they model semantics of the targeted mali-
cious code. To this end, we examine how well the derived
signatures can be implanted in benign ﬁles that have nothing
in common with the original malware. Since our dataset is
mainly comprised of PE executables, we consider a set of
benign applications of the same format for this task, which
we have veriﬁed not to be ﬂagged as malicious by any of
the scanners. We proceed to implant the signatures derived
by our method into these applications, irrespective of the
relative position to PE sections or existing code, and apply
the virus scanners to the resulting ﬁles. A breakdown of the
detection results Table 3. On average 68% of the implants
are successful. Apparently, several of the pattern-based signa-
tures are applied without checking the context or semantics
of the matching region for plausibility, allowing the direct
transfer of signatures from one ﬁle to another. The situation
is especially troublesome for AV1 , AV2 and AV3 that simply
ﬂag the majority of implants as malicious. AV5 appears to
be the only one to use semantics-aware matching in most of
the cases. Still, the overall quantity of working implants is
higher than for AV3 or AV4 .
Byte patterns
Implantable
AV1
AV2
AV3
AV4
AV5
Average
377
255
69
93
353
229
358 (95%)
227 (89%)
65 (94%)
54 (58%)
80 (23%)
157 (68%)
Table 3: Detection results on pattern-based signa-
tures implanted in benign PE ﬁles.
5. CASE STUDIES
We proceed to demonstrate the threat of anti-virus assisted
attacks and feasibility of implanting malicious markers in
three diﬀerent scenarios: 1) covering up password guessing,
2) deleting a user’s emails and 3) facilitating web-based
attacks by removing browser cookies. For each scenario we
choose a diﬀerent anti-virus product to demonstrate the
generality of the approach.
AV1AV2AV3AV4AV5Virus scanners100101102103104105Signature size (bytes)AV1AV2AV3AV4AV5Virus scanners0100101102103Number of gapsAV1AV2AV3AV4AV5Virus scanners012345678Byte entropyAV1AV2AV3AV4AV5Virus scanners0.800.850.900.951.00Agreement (F-measure)Average0.00.20.40.60.81.0Signature overlap0%20%40%60%80%100%Derived signaturesAV1 ... AV5Average593Families Derived signatures ASCII characters * Printable-1 Printable-2 Printable-3 * Printable-4 *
AV1
AV2
AV3
AV4
AV5
37
28
28
37
36
35
27
27
33
31
34
26
27
31
31
34
26
27
31
31
20