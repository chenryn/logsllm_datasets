title:PGFUZZ: Policy-Guided Fuzzing for Robotic Vehicles
author:Hyungsub Kim and
Muslum Ozgur Ozmen and
Antonio Bianchi and
Z. Berkay Celik and
Dongyan Xu
PGFUZZ: Policy-Guided Fuzzing
for Robotic Vehicles
Hyungsub Kim, Muslum Ozgur Ozmen, Antonio Bianchi, Z. Berkay Celik, and Dongyan Xu
Purdue University
{kim2956, mozmen, antoniob, zcelik, dxu}@purdue.edu
Abstract—Robotic  vehicles  (RVs)  are  becoming  essential  tools 
of  modern  systems,  including  autonomous  delivery  services,  public 
transportation,  and  environment  monitoring.  Despite  their  diverse 
deployment, safety and security issues with RVs limit their wide adop-
tion. Most attempts to date in RV security aim to propose defenses 
that harden their control program against syntactic bugs, input val-
idation bugs, and external sensor spoofing attacks. In this paper, we 
introduce PGFUZZ, a policy-guided fuzzing framework, which vali-
dates whether an RV adheres to identified safety and functional poli-
cies that cover user commands, configuration parameters, and physi-
cal states. PGFUZZ expresses desired policies through temporal logic 
formulas with time constraints as a guide to fuzz the analyzed system. 
Specifically, it generates fuzzing inputs that minimize a distance met-
ric measuring “how close” the RV current state is to a policy violation. 
In addition, it uses static and dynamic analysis to focus the fuzzing ef-
fort only on those commands, parameters, and environmental factors 
that influence the “truth value” of any of the exercised policies. The 
combination of these two techniques allows PGFUZZ to increase the 
efficiency of the fuzzing process significantly. We validate PGFUZZ on 
three RV control programs, ArduPilot, PX4, and Paparazzi, with 56 
unique policies. PGFUZZ  discovered 156 previously unknown bugs, 
106 of which have been acknowledged by their developers.
I. 
INTRODUCTION
Robotic  Vehicles  (RVs)  are  becoming  widespread  both  in 
industrial and consumer environments [7], [35], [60]. Unfortunately, 
RVs face diverse threats including (1) physical external attacks such 
as sensor spoofing attacks [61], [65], (2) software crashes due to 
floating-point exceptions or memory corruption issues, (3) insider at-
tacks [4], [34], and (4) misimplementations causing safety and func-
tional issues, which leads to undesired behaviors in the RV. Previous 
efforts at fuzzing have introduced techniques to address (1), (2), and 
(3), but (4) has not received much attention. RVs must respect safety 
and security policies to avoid creating physical damage to the envi-
ronment in which they operate or to themselves. For instance, RVs 
are often equipped with a parachute. Due to safety concerns, RV’s 
software must check preconditions to safely release the parachute 
(e.g., the RV must be high enough when deploying the parachute). 
However, the control software’s careless design may allow the RV 
to release the parachute without checking these preconditions.
Such safety violations might lead to catastrophic consequences 
as reported in recent news [17], [63]. For instance, Tesla’s autopilot 
software failed to initiate an emergency brake maneuver [63], and 
the  Boeing-737  Max  airplanes  crashed  because  their  software
Network and Distributed Systems Security (NDSS) Symposium 2021
21-25 February 2021, Virtual
ISBN 1-891562-66-5
https://dx.doi.org/10.14722/ndss.2021.24096
www.ndss-symposium.org
improperly allowed them to activate the anti-stall system [17].
Unfortunately, previous fuzzing approaches cannot discover
this type of violations for the following two reasons. First,
they do not consider the entire input space of the RV’s control
software, including user commands, configuration parameters, and
environmental factors. Second, they only focus on finding memory
corruption bugs or RV’s control stability issues. Therefore, they
cannot detect safety policy violations, e.g., a drone is deploying
the parachute at a too-low altitude.
We develop PGFUZZ, a policy-based fuzzing framework
designed to address these challenges. PGFUZZ includes three
interconnected components: (1) Pre-Processing, (2) Policy-Guided
Fuzzing, and (3) Bug Post-Processing.
In the Pre-Processing component, we express the correct
operation of an RV through policies denoted by a metric temporal
logic (MTL). Thereafter, we minimize the fuzzing space via
finding inputs related to the tested policies that, when mutated,
could potentially trigger policy violations. For example, given
a policy in natural language stating that “the fail-safe mode
must be triggered when the engine temperature is higher than
100°C”, PGFUZZ expresses this policy with the MTL formula:
(cid:3) {(temperature>100°C) → (failsafe=on)}. It
then
decomposes this formula into the temperature and the fail-safe
mode states, and identifies fuzzing inputs such as user commands
increasing temperature) and configuration parameters
(e.g.,
(e.g., units of temperature), influencing the policy states.
Then, the Policy-Guided Fuzzing mutates inputs identified
by the Pre-Processing component. It implements two kinds of
distance metrics, propositional distances to guide the mutation
engine, and a global distance to detect when a policy violation
occurs. The distance metrics quantify how close the current system
states are to a policy violation. Positive distances indicate the policy
holds, whereas negative distances indicate the policy is violated.
Therefore, PGFUZZ mutates inputs to minimize the global distance.
After each input is sent to the control software, which runs in an
RV simulator, PGFUZZ collects the system states and computes the
distance metrics. The input’s impact on the distance metric (whether
it increases or decreases) is leveraged to decide on the next inputs.
When the global distance becomes negative, a policy violation is
detected. Turning to the fail-safe mode example, PGFUZZ mutates
inputs to increase the temperature to be larger than 100°C, and
checks whether, at the same time, the fail-safe mode is activated.
The last component, Bug Post-Processing, minimizes the input
sequence triggering the bugs by excluding inputs irrelevant to the
policy violation. The minimized input sequence is then used to
identify the root cause of each violated policy.
To verify the correctness and effectiveness of PGFUZZ, we
RVs mainly operate with three types of inputs, configuration
parameters (InputP), user commands (InputC), and environment
factors (InputE). (1) InputP allows users to configure many
aspects of how RVs operate. For instance, KP, Ki, and Kd of
the PID control algorithm denote tuning parameters for the
proportional, integral, and derivative terms. RVs specify ranges for
configuration parameters of KP, Ki, and Kd to safely tune the PID
control algorithm. (2) InputC enables the users to dynamically
operate RVs. The control software denies some of Inputc when
these commands lead to an undesired system state. For example,
disarming user command stops the vehicle’s all motors, and the
control software does not accept such a command while the vehicle
is flying in the air. (3) InputE (e.g., wind and sensor noise) also
affects the system outputs y(t). For instance, the control software
assigns a barometer sensor as a primary altitude source when GPS
signals are blocked or show biased altitude values.
Fuzzing. Fuzzing is an automated testing technique that randomly
or semi-randomly generates test inputs to discover bugs in programs.
Existing fuzzing approaches differ in how they handle two main
core aspects: input generation and bug oracle. The input generation
can be completely random or guided by some heuristics. For
instance, many approaches [5], [44], [48] use code coverage as a
heuristic. Regarding the bug oracle, traditional fuzzing approaches
use code crashes (typically caused by memory corruption) to detect
inputs triggering bugs in the analyzed program. We consider these
two aspects differently than in traditional, general-purpose fuzzers.
Specifically, about the bug oracle, since we are dealing with RVs,
we mainly aim at finding policy violations about the physical states
of RVs, in addition to software crashes in the control software. We
then run the control software in a simulator that is able to keep track
of the physical states of the tested control software. Lastly, we define
a metric measuring how “close” we are to violating one of these poli-
cies. We use this metric as a heuristic to guide our input generation.
III. MOTIVATING EXAMPLE
We provide an example of a safety issue that PGFUZZ targets.
ArduPilot drone control software can trigger a parachute release
when it recognizes that the drone is falling to the ground with an
uncontrolled attitude [10], [15]. Additionally, the user can manually
trigger parachute deployment. In both cases, the ArduPilot official
documentation states that the following four conditions must hold
to deploy a parachute while preserving the drone safety [13]:
(1) the motors must be armed, (2) the vehicle must not be in the
FLIP or ACRO flight modes, (3) the barometer must show that the
vehicle is not climbing, and (4) the vehicle’s current altitude must
be above the CHUTE_ALT_MIN parameter value.
Based on these requirements, we express a safety policy
(A.CHUTE1) through metric temporal logic (MTL) (Detailed in Sec-
tion V-A): (cid:3){(Parachute=on)}→{(Armed=true)∧(Modet(cid:54)=
FLIP/ACRO) ∧ (ALTt ≤ ALTt−1) ∧ (ALTt >CHUTE_ALT_MIN)}
where t and ALT denote time and altitude, and (cid:3) is always.
Traditional fuzzing techniques targeting program crashes [5],
[44], [48] clearly cannot detect such safety violations. Moreover,
randomly sending commands to the ArduPilot drone simulator
cannot efficiently test this policy, given the high number of
commands and parameters that could be potentially mutated.
Additionally, fuzzing approaches that specifically target
CPS [21], [22], [41] cannot discover this kind of safety violations
for two main reasons. First, policy violations are often triggered
Fig. 1: Workflow of RV’s control software.
used PGFUZZ to fuzz ArduPilot, PX4, and Paparazzi, the three
most popular flight control software packages used in many
commodity RVs [10], [32], [52]. PGFUZZ found 156 previously
unknown bugs in 48 hours1. Out of the 156 bugs, the developers
confirmed 106 bugs, and nine bugs have already been patched. We
compared PGFUZZ’s results with those from previous approaches
designed to find bugs in RVs. We found that 128 out of 156 found
bugs can only be discovered by PGFUZZ.
In summary, this paper makes the following contributions:
•
Behavior-aware Bug Oracle. We identify policies that
define RVs’ safety and functional requirements and
formally represent them via temporal logic formulas.
PGFUZZ leverages the identified policies to find bugs
allowing the violation of these policies.
Policy-Guided Mutation Engine. PGFUZZ follows a
novel fuzzing design that optimizes its bug search by (i)
mutating the inputs/parameters, trying to negate the iden-
tified security policies and using, as a heuristic, dedicated
distance metrics, and (ii) minimizing the fuzzing space of
the inputs and parameters related to the analyzed policies.
Evaluation in real-world RVs. We applied PGFUZZ to
the three most popular vehicle control software packages,
and we discovered 156 previously unknown bugs, 106
of which have been acknowledged by developers of the
affected packages.
•
•
To foster research on this topic, we make PGFUZZ publicly
available (https://github.com/purseclab/PGFUZZ).
II. BACKGROUND
Inputs and Outputs of RVs. A vehicle leads to incorrect operation
or failure when the system maintains an undesired state. For
instance, a vehicle crashes to the ground when it maintains incorrect
roll, pitch, and yaw angles. RVs often periodically follow three
steps (See Figure 1) for their correct operation: (1) the control
algorithm reads system outputs y(t) measured by the sensors (from
1 to 2 ), (2) the algorithm first computes errors e(t) based on
r(t)−y(t) where r(t) and t denote reference states and current
time, and (3) a Proportional–Integral–Derivative (PID) control
algorithm derives system inputs u(t) through e(t) ( 3 ).
1We made responsible disclosure to the developers of the flight control software.
2
Reference states r(t)PConfigurations for sensors and control algorithmCyber spacePhysical spaceControl algorithmInputC : User commandsInputP : ParametersInputE : Environment factorsCommands to actuatorsGathering sensor data Measured system outputs y(t)System inputs u(t)∑+−ID∑e(t) = r(t) –y(t)+++X: rollZ: yawY: pitchby the composition of different types of system inputs. However,
these approaches only focus on a single part of the input space,
meaning they do not consider unified behavior of user commands,
configuration parameters, and environmental factors. Second,
their bug oracles are designed to detect specific bug types,
such as deviated flight paths or instability. To detail, if a policy
violation causes unexpected physical behavior, e.g., failing to
trigger a GPS fail-safe mode, their bug oracles cannot detect such
undesired behavior although the failing GPS fail-safe mode leads
to unexpected states with potentially disastrous consequences.
To address these limitations, PGFUZZ uses MTL formulas to
guide both its input generation and detect safety violations. Turning
to the example safety policy, PGFUZZ issues system inputs that
trigger a mutation of the propositional variables of the formula. At
the same time, it checks whether the safety policy is violated after
each input generation. By using PGFUZZ, we found that ArduPilot
improperly checks the first three requirements. This leads to a policy
violation where the vehicle deploys the parachute when it is climb-
ing, causing it to crash on the ground (Detailed in Section VII-C1).
Threat Model. We consider as in-scope for this paper both design
flaws (from benign developers and users) and malicious intent (from
adversaries) that can cause unsafe or undesired states (e.g., physical
crashes) in RVs. Design flaws can happen due to poor parameter
documentation, unexpected environmental conditions (e.g., sensor
noise and wind), and buggy code. We assume that developers are
benign; they, however, could misimplement or incorrectly design
the system components. Furthermore, users can unintentionally
cause safety issues via either sending commands at an inappropriate
time or improperly changing configuration parameters.
While considering malicious actors, we assume that an
adversary is aware of inputs causing policy violations and can
trigger them with malicious intent. Particularly, an adversary
can control an RV’s three types of inputs. (1) An adversary can
manipulate the configuration parameters of an RV by either
overriding them before a flight or changing them after the drone
takes off (similar to [41]). (2) An adversary can replay or spoof
user commands sent to the RV by exploiting known vulnerabilities
in the RV’s communication protocol [43], [58]. (3) An adversary
can manipulate the environmental conditions (or wait until suitable
conditions are met) before conducting their attack (similar to [23],
[41]). We detail the number of violations for each subset of
these inputs in Section VII-B. For instance, we will show that an
adversary is able to trigger 77% of the found policy violations by
only changing the RV’s configuration parameters.
The adversary’s goal is to physically impact the RV’s operations
(e.g., causing a physical crash or disrupting the RV’s camera) by
stealthily triggering policy violations. We note that an adversary
could also simply drop or disarm the vehicle by sending a malicious
command (e.g., stopping actuators); however, these attacks are
not stealthy. Particularly, such self-sabotaging inputs can be easily
identified and prevented with run-time mission monitoring tools
enforced by both the vehicle and ground control system [25],
[46]. In contrast, policy violations triggered by sending an input
that looks innocent are stealthier and more difficult to detect by
monitoring tools. For these reasons, we do not consider these
self-sabotaging attacks in-scope of this paper. In addition, physical
sensor attacks (e.g., GPS and gyroscope spoofing) and malicious
code injections are out of scope. The main reasons are (1) the
root causes of sensor attacks arise in the hardware components
(e.g., acoustic attacks against gyroscope [61]), rather than buggy
code in the vehicle’s control program, and (2) there exist effective
techniques to detect sensor and code injection attacks [6], [28],
[37]–[39]. Lastly, although PGFUZZ is not designed to specifically
find floating-point exceptions and other software crashes in the
controller code, it reports them when triggered by the tested inputs.
IV. APPROACH OVERVIEW
In this section, we first present the design challenges of CPS
fuzzing. We then provide an overview of PGFUZZ.
A. Design Challenges
Traditional fuzzing techniques [5], [44], [48] including those
for CPS [21], [22], [41] have two main limitations that prevent their
adoption for policy-guided fuzzing in real-world systems. First, their
bug oracles are not designed to detect undesired system states that
do not cause a system crash, memory-access violation, or physical
instability. To address this limitation, we implement a Behavior-
aware Bug Oracle. Our bug oracle is aware of desired states of RVs
via MTL formulas and detects if the formulas are violated while
fuzzing the analyzed program. Second, the mutation engines of the
traditional fuzzers cannot intelligently generate inputs for the RVs.
This limitation is due to the large input space of the RVs, with tens
of different parameters and commands, each of which can have
a wide range of values. To address this limitation, we implement
a Policy-Guided Mutation Engine. This engine is based on:
1) A mapping connecting each term of a policy with the
inputs influencing the RV’s states;
2) A distance metric measuring the “distance” between a
vehicle’s current states and policy violation.
The mutation engine uses these to guide the input mutations
toward those more likely to generate a policy violation.
B. PGFUZZ Overview
PGFUZZ includes three interconnected components, (1)
(2) Policy-Guided Fuzzing, and (3) Bug
Pre-Processing,
Post-Processing, as depicted in Figure 2.
Pre-Processing. In this step, we identify and formally represent
the policies and reduce the large input space by eliminating the
inputs that are not relevant to the identified policies.
Users and developers derive requirements in the targeted system
by studying the RV documentation and evaluating the connections
between assets and functional constraints that restrict the use
or operation of assets [19], [20]. We then convert the identified
requirements from natural language to policies expressed with
MTL formulas ( 2 ). PGFUZZ next runs its profiling engine, which
determines for each policy the limited set of inputs, Inputmin,
relevant to the target policy (i.e., the limited set of inputs that, when
mutated, could potentially trigger policy violations). To achieve