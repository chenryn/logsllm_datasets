members of S do not individually sign (M, S), the signature
is not deemed legitimate. Thus, each signer knows precisely
with whom he shares responsibility for the signed message.
(In fact, some attacks on previous multisignature schemes
resulted not in forged signatures, but in providing a signer
incorrect information about his co-signers.)
One may envisage a diﬀerent basic solution in which any
member of G that wishes to sign M does so, sending the
signature to a clerk. The clerk then “constructs” S using the
signatures received. This approach has the advantage of not
requiring any advance agreement on S. The disadvantage,
however, is that the clerk, acting adversarially, can become
a “guardian angel” for some signers. Suppose a member of
G wants to get a document M signed but prefers not to have
to take responsibility for it if possible; that is, if suﬃciently
many other signers are willing to sign M , she would like her
signature to be excluded. She can then send her signature to
the clerk, but the clerk will include it in the ﬁnal output only
if it is absolutely necessary for the document to be deemed
valid.
Of course, both notions are valid and have applications.
In this paper, however, we only consider the ﬁrst one, in
247which S is explicitly speciﬁed. It is worth pointing out that
designing a non-trivial provable scheme of the other kind,
where the composition of S can be decided after the signa-
tures are received, is an interesting open problem.
ASM vs. Threshold. ASM schemes are diﬀerent from
threshold schemes not only because they “add accountabil-
ity”, but also because they empower any subgroup (rather
one of suﬃcient cardinality) to sign a message. At the same
time, a threshold can be easily added to an ASM scheme:
the veriﬁer simply checks that the cardinality of S exceeds
the threshold.
Security vs. Robustness. Notice that the basic solu-
tion is secure, in the sense that the adversary may not forge
the signature of a subgroup S (containing a “good” player).
Notice too, however, that the basic solution is not robust:
if a corrupted player of S “shuts oﬀ”, then, by deﬁnition,
S’s signature of a message M cannot be computed. We are
therefore not seeking robustness in our model. This allows
us to deﬁne the model in terms of a very strong adversary
who controls all possible communication lines, and thus can
prevent also the messages from good players to good players
from reaching their destinations. Such extreme adversar-
ial behavior, naturally, prevents robustness. At the same
time, such adversarial ability makes the security properties
of ASM schemes much stronger.
Weak Robustness. One could endow the basic solution
with a weak robustness property. Roughly said, if a subgroup
S fails to produce S’s signature of a message M , then at
least one corrupted player P in S will be exposed. This
way, the players may have the option of trying to sign M
not containing P .
again on behalf of a diﬀerent subgroup S
Weak robustness could be achieved in the basic solution if
broadcasting is available. Broadcasting could also be added
(in a simple fashion) to make our ASM scheme in Section 3
weakly robust. (Of course, weak robustness could also be
achieved by using some variant of secure computation [16, 4,
7], but with some eﬃciency loss.)
2.2 The Formal Notion
(cid:1)
We will assume that the total group G consists of L sign-
ers, and that every signer is a probabilistic polynomial-time
Turing machine that initially knows nothing but its unique
identiﬁcation number (which is, w.l.o.g., one of the numbers
1, 2, . . . , L) and a unary value 1k called the “security param-
eter.” We will also assume that 1k is the same for all the
signers. As will be explained in more detail later, we will
allow the adversary to control the network connecting the
members of G.
Components of an accountable-subgroup multisig-
nature. A ASM scheme has three components:
1. A (probabilistic) key generation protocol.
This protocol is performed only once (at the very be-
ginning) by all members of G. Each member receives
as input a description of G, that is, the list of the iden-
tities of all members of G. (If these identities are the
integers 1 through L, then it suﬃces to have just the
integer L as an input.)
The key generation protocol produces a local output
for each party Pi: a secret key, SKi, and the corre-
sponding public key, P Ki.
If an adversary is present during key generation, it may
provide diﬀerent inputs “G” to diﬀerent parties.
2. A (probabilistic) signing protocol.
This protocol is performed by the actual signers in S
for every message being signed. The input of each
signer consists of (a) a description of the subgroup
S; (b) the public keys of the members of S; (c) the
message M ; and (d) the signer’s own secret key. The
signature σ is generated jointly by the members of S,
and is actually output by one of the parties in S.
If an adversary is present during an execution of the
signing protocol, it may provide diﬀerent inputs S and
M to each signer, as well as incorrect public keys for
the other signers.
3. A (deterministic) veriﬁcation algorithm.
This algorithm is run to verify a given signature by an
individual veriﬁer, possibly not belonging to G. The
inputs of the veriﬁcation algorithm are: the subgroup
S, the public keys of the members of S, the message
M , and the alleged signature σ. The output is “YES”
or “NO”.
We require that these components be “correct.” That is,
suppose the signers in a subgroup S follow the protocols
faithfully, and suppose key generation terminates success-
fully for every party in S. Then, if the signers in S perform
a signing protocol on a message M (with correct inputs),
they will produce a signature σ that the veriﬁcation algo-
rithm will accept (if, again, given correct inputs).
The adversarial model. We consider an adversary F
(for “forger”) with the following capabilities:
• F fully controls all messages exchanged in the network:
whether the sender or the recipient is good or bad, it
can read any message sent, modify it or prevent its
delivery. In addition, F can send any message it wants
on behalf of any player. (In a sense, therefore, there
are no private or authenticated channels: all players
communicate via the adversary.)
• F can corrupt any player at any time, during both key
generation and signing. Upon corrupting a player Pi,
F learns the entire internal state of Pi (including all
secret information and past coin tosses).
• F controls the input of any uncorrupted player dur-
ing key generation (e.g., it can specify diﬀerent total
groups G to diﬀerent players).
• For any uncorrupted player Pi, F can conduct an adap-
tive chosen-message-and-subgroup attack: at any time,
it can request that Pi execute the signing protocol on
some speciﬁed message with some speciﬁed subgroup
of co-signers.
(Because the adversary fully controls
the network, it can choose whether the co-signers will
actually be really involved in this execution.)
Definition of Security.
Because the adversary fully
controls the network, it can always prevent the parties from
signing a message. Our security goal, therefore, is to prevent
forgeries of new signatures.
248Definition 1. We will say that an ASM scheme is secure
if, for all constants c > 0 and all suﬃciently large security
parameters k, no polynomial-time (in k) adversary has better
−c chance of outputting a triple (σ, M, S) such that:
than k
• σ is a valid signature on the message M by the sub-
group S of players
• there exists an uncorrupted player P ∈ S who has
never been asked by F to execute the signing protocol
on M and S.
Note that, in the above deﬁnition, S may not be a sub-
group of the original G. That is, we want also to prevent
the adversary from adding one of more “ﬁctitious” players,
(cid:1)
so as to (1) form a diﬀerent total group G
, and then (2) be
able to forge a signature of (M, S), where S is a subgroup
(cid:1)
. (Naturally, the single uncorrupted player P cannot
of G
be ﬁctitious: it should be a member of the original G.)
Of course, as is also the case for the single-signer schemes,
it is assumed that, when verifying an ASM signature of
(M, S), the veriﬁer obtains the proper public keys of the
members of S ∩ G. (The mechanism for enforcing the au-
thenticity and availability of such public keys is, as usual,
outside the scope of our deﬁnition.) The public keys of the
ﬁctitious players (S \ S ∩ G) might as well be successfully
faked by the adversary.
The Meaning of S in a Signature. Given that there are
no authentic channels and the adversary can provide incor-
rect inputs during the signing phase, one can reasonably ask
what exactly it means for signer P1 to be assured that she
is signing M with a signer named “P2,” when P1 doesn’t
even necessarily know who P2 is.
It means the following.
While P1 may not know who P2 is, the veriﬁer (necessar-
ily) must know authentically who P2 is, and must obtain
P2’s authentic public key for veriﬁcation. Then, assuming
that P2 has not been corrupted, P1 is assured that the ver-
iﬁer will deem the signature valid only if the person whom
the veriﬁer knows as P2 actually participated in the signing
protocol on M, S.
Random Oracles. As usual, it is possible to extend the
above deﬁnitions to the random oracle model, and the ac-
tual schemes we present will be in that model. To extend the
deﬁnitions, we will add a second security parameter k2 and
assume the existence of an oracle H : {0, 1}∗ → {0, 1}k2
to which all the parties have access. As is usual in the
random oracle model [3], security will be based on the as-
sumption that the oracle is chosen at random from all func-
tions {0, 1}∗ → {0, 1}k2 . The adversary is now also allowed
queries to H, which we will call “hash queries.”
Equivalent, but simpler adversary. The adversary
described above is extremely powerful, and provides for a
compelling notion of security. However, in Section A of the
Appendix, we show it equivalent to a diﬀerent type of ad-
versary, for which proofs of security become much easier.
3. AN IMPLEMENTATION OF ASM
The ASM scheme proposed here has a complex key gen-
eration, but it allows for very eﬃcient signing and verifying.
Namely, a subgroup S signs a message M by means of a 3-
round protocol, where each signer sends/receives a total of
3 messages and performs a single modular exponentiation.
The main cost of veriﬁcation is |S| modular multiplications
(that need be performed only once for a given S), and two
modular exponentiations. The signature length is that of a
single-signer signature, and does not grow with the number
of signers.
We construct our scheme by modifying the “two-cycle”
scheme of Section 6 of [29]. The scheme is based on the
discrete logarithm problem (DLP); more precisely, on the
signature scheme of Schnorr [33], summarized below, which
is known to be equivalent to the DLP in the random oracle
model.
3.1 The Schnorr (Single-Signer)
Signature Scheme
A user U generates two primes p and q such that q divides
p of order q, and a random s ∈ [0, q − 1].
p − 1, g ∈ Z
∗
U ’s secret key is s and its public key is (p, q, g, I), where
I = gs mod p. To sign a message M , U does the following:
• picks a random r ∈ [0, q − 1];
• computes a commitment X = gr mod p;
• queries the random oracle H to compute the challenge
e = H(X, M );
• computes y = es + r mod q;
• outputs (X, y) as the signature of M .
(cid:1)
(cid:1)
(cid:1)
) for M , one computes e
=
(cid:1)
To verify a signature (X
H(X
3.2
, M ) and checks whether gy(cid:1) ≡ X
Informal Description
, y
(cid:1) · I e(cid:1)
(mod p).
This subsection provides an introduction to our scheme
by presenting an (underlying) naive scheme (essentially, the
“two-cycle” scheme from [29]), and then pointing out diﬀer-
ent reasons for which it does not work, together with the
corresponding ﬁxes.
The naive scheme. All signers in G know each other and
common parameters p, q and g as in the Schnorr scheme.
Each signer i randomly and independently selects si ∈ [0, q−
1] and sets Ii = gsi mod p.
An (unordered) subgroup S = {Pi1 , . . . , Pi(cid:4)} signs a mes-
sage M in three rounds: all players i in S select a ran-
dom ri ∈ [0, q − 1], compute individual commitments Xi =
gri mod p, and multiply their Xi’s together (modulo p) to
obtain a joint commitment, (cid:1)X. Then, all players i in S com-
pute the joint challenge e = H((cid:1)X, M, S); the “individual
their individual signatures together to obtain(cid:1)y, and output
((cid:1)X,(cid:1)y) as S’s signature of M .
One veriﬁes ((cid:1)X
,(cid:1)y
= H((cid:1)X
(cid:4)
(cid:1)y(cid:1) ≡ (cid:1)X
signatures” yi = esi + ri mod q; and ﬁnally add (modulo q)
) to be S’s signature of M by comput-
, M, S) and checking whether
e(cid:1)
(cid:1)
ing e
(mod p).
(cid:1)
(cid:1)
(cid:1) ·
(cid:1)
g
Ii
Pi∈S
Problems and fixes.
Problem 1: How to generate common p, q and g? Only the
security parameter k and the random oracle H are assumed
to be common to all players. Thus, common p, q and g can
249be individually generated by the players in G using a com-
mon generating subroutine and relying on a canonical use of
H as a (common) source of randomness. Unlike the Schnorr
scheme, however, the adversary now also knows additional
information about p, q and g, namely, the very coin tosses
that generated them. This that may help the adversary
solve the discrete log problem in the g-generated subgroup
modulo p. (For instance, if p and q are found by running
Bach’s algorithm [2], then one also gets the entire factoriza-
tion of p − 1, which may perhaps be useful to a clever DLP
algorithm.)
Fix 1. The ﬁx simply consists of realizing this weakness and
incorporating the (p, q, g) generation process into the DLP
assumption. To be precise, one needs to incorporate also
the performance of this generation process. (For instance,
starting with a large prime q and searching for a prime p ≡ 1
(mod q) is not known to be guaranteed to terminate in ex-
pected poly(|q|) time.) To keep this ﬁx simple, we actually
propose to make q “as big as possible”, that is, we assume
that one can easily ﬁnd primes p of the form 2q + 1 (though
weaker assumptions, described in more detail in the full ver-
sion of this paper, can be used).
Problem 2: The naive scheme is not secure at all if the ad-
versary attacks key generation. Assume that player L is bad
(cid:8)−1
and generates his public key last by choosing a secret key
s ∈ [0, q − 1] and then setting
(cid:7)
L−1(cid:4)