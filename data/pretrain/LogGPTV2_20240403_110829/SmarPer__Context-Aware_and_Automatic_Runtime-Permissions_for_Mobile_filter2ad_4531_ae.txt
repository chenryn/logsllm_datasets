function is the popular 0-1 loss: L(y, y(cid:3)) = 1 when y (cid:6)= y(cid:3)
and 0 when y = y(cid:3). In this case, E is the standard incorrect
classiﬁcation rate metric (ICR). However, the 0-1 loss ignores
the ordering between the three categories of the decision y:
e.g., if we predict “allow” for “deny”, then it is more incorrect
than predicting “obfuscate”, as the latter allows some degree
of privacy. We use another loss function called mean-absolute
error (MAE) that reﬂects these types of errors. We recode the
decisions {“Allow”, “Obfuscate”, “Deny”} as {−1, 0, +1} and
we deﬁne the loss as follows: L(y, y(cid:3)) = |y − y(cid:3)|.
E. Performance Evaluation Methodology
We developed a machine learning framework to reliably
estimate the error measure for different methods. Our frame-
work uses the standard splitting of the data into training and
testing sets. We randomly select 50% of the participants for
testing (U = 20) to compute an estimate of the error, and the
remaining 21 participants for training to learn the parameters
for the BLR model by maximizing the log-likelihood. Note
that, for baseline and other methods evaluated, there are no
parameters to learn.
On the 20 test participants, we estimate the error measure
as follows. We ﬁrst form datasets Du,tu for each participant.
As participants have varied number of decisions, we select
a ﬁxed percentage of each participant’s data, e.g., for each
participant, we can select the ﬁrst 10% of their decisions, that
we denote by tu = 10%,∀u. We then form the dataset Dtest
by randomly selecting Nu = 20 decisions7 as test decisions
yui for each participant. Using the method M, we compute
predictions ˆyui|Dt,u for all yui ∈ Dtest. We choose only those
decisions as test points that were made after the ﬁrst half of
the decisions so that the test decisions resemble decisions that
the participant has to make in the far future. We repeat the
above splitting process 50 times with different random seeds
to get 50 different realizations of the error.
For our evaluation, we use features chosen using an additive
approach, also known as Forward Stepwise Selection [52].
We add each of the 37 features (Sections IV-C and V-A6)
in turn, and observe their effect on the model’s performance.
The feature that most improves performance is selected. We
7Some participants do not have more than 75 decisions, hence choosing 20
test decisions (around 30% of their data) allow us to include them.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:06 UTC from IEEE Xplore.  Restrictions apply. 
)
R
C
I
(
e
t
a
R
n
o
i
t
a
c
i
f
i
s
s
a
C
l
t
c
e
r
r
o
c
n
I
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
BLR-all
SVM-all
Static Policy
ZeroRt
GP-SE
D. Tree
SVM
BLR
20
10
Percentage of Decisions Used (Ordered by Time)
40
50
70
80
90
30
60
100
)
E
A
M
(
r
o
r
r
l
t
E
e
u
o
s
b
A
n
a
e
M
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
BLR-all
SVM-all
Static Policy
ZeroRt
GP-SE
D. Tree
SVM
BLR
20
10
Percentage of Decisions Used (Ordered by Time)
30
40
50
60
70
80
90
100
(a)
(b)
i
s
n
o
s
c
e
d
i
f
o
n
o
i
t
r
o
p
o
r
P
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Static Policy
ZeroR t
BLR
SVM
0
1
Prediction error
2
(c)
Fig. 6. Performance results for the machine learning models evaluated in our study. (a) and (b) show estimates of error measures as a function
of tu which is varied from 10% to 100%. (a) is obtained by using the 0-1 loss and reports ICR, while (b) is obtained by using MAE. In each
plot, thick lines (with markers on them) show the median of the error, while the shaded region behind shows the error between 25th and
75th percentile. Models that consider contextual information have signiﬁcantly lower error than our context-oblivious baselines. Moreover,
per-user models outperform one-size-ﬁts-all models, i.e., BLR-all and SVM-all. (c) shows the histogram of MAE over test decisions in Dtest
for one random partition and tu = 100%. Context-aware methods make very few mistakes with a loss of 2, which clearly shows that such
methods rarely make the mistake of predicting “allow” for “deny” and vice versa.
repeat the procedure to ﬁnd the second most important feature,
and so on. We continue this procedure until the performance
remains the same or decreases, as shown in Figure 8 for BLR.
Using this approach, we selected the following seven features
for BLR: method category (i.e., location, contacts, or storage),
method name (i.e., the actual API call), app name, whether the
app was in the foreground, whether denying the request causes
the app to crash, day of month, and battery-level percentage.
Note that the effect on performance of a set of features will
depend on the machine learning model selected. This is not
necessarily the best subset and combination of features for
BLR, as our selection approach was not exhaustive; the best
subset and combination of features may vary across partici-
pants. For BLR, a possible approach is to use regularization
to ﬁnd the best features, which also helps reducing overﬁtting.
In our evaluation, we use data from all the participants,
but only for decisions associated with popular apps, i.e., apps
with more than 200 decisions (Figure 5): Facebook, Twitter,
Instagram, WhatsApp, Viber, Skype, Snapchat, The Weather
Channel, and AccuWeather. We do so because we do not have
enough data for the remaining apps to reliably perform our
analysis (see Table II in the Appendix).
Our experimental framework and the models evaluated (see
next section) were implemented by using the Matlab Statistics
and Machine Learning toolbox, and the GPML toolbox [53].
Our code is publicly available in the SmarPer’s website [11].
F. Performance Evaluation Results
In our evaluation, we considered the following models:
static policy, ZeroRt, BLR, Gaussian Process with Squared
Exponential Kernel (GP-SE), decision tree (D. Tree), and 3-
binary support vector machines (SVM) with linear kernel. The
goal was to compare context-oblivious models with different
context-aware models. We also evaluated the training of one-
size-ﬁts-all models (i.e., BLR-all and SVM-all), i.e., training
a single model for all users.
Figure 6 shows estimates of error measures as a function
of tu. We vary tu from 10% to 100% for all test participants.
Figure 6(a) is obtained by using 0-1 loss function and shows
the median of the ICR obtained by the different models
evaluated. The shaded area shows the region between 25th
and 75th percentile. We can observe that both one-size-ﬁts-all
models (i.e., BLR-all and SVM-all) have a signiﬁcantly higher
error rate than most per-user models; BLR-all performs even
worse than our baselines. These results are consistent with
our observations about Figure 3, participants’ unique privacy
preferences make it difﬁcult to train a one-size-ﬁts-all model
that accurately predicts decisions at runtime. For tu = 100%,
the mean ICR is 0.39 (±0.04) for static policy, 0.30 (±0.03)
for ZeroRt, 0.20 (±0.03) for BLR, and 0.16 (±0.02) for SVM.
We can see that context-aware models obtain a much lower
error-rate than the baselines, which clearly shows the gain
obtained after adding context. Also note that, unlike the static
policy method, all the other per-user models are dynamic and
learn to predict better as the amount of data is increased.
In addition, note that BLR, SVM, GP-SE and D. Tree have
roughly similar performance. Still, BLR can be considered a
safer option, due to its simplicity, i.e., lower risk of overﬁtting
and computational overhead [54].
Figure 6(b) shows a similar trend for MAE loss. For
tu = 100%, the mean MAE was 0.48 (±0.06) for static policy,
0.39 (±0.04) for ZeroRt, 0.22 (±0.03) for BLR, and 0.19
(±0.03) for SVM. To put these numbers in perspective, note
that the MAE is in the range [0,2]. The gains obtained with our
context-aware methods are even larger here because the MAE
loss function captures the ordering between different types
1069
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:06 UTC from IEEE Xplore.  Restrictions apply. 
M
V
S
d
n
a
,
y
c
i
i
l
o
P
c
i
t
t
a
S
,
t
R
o
r
e
Z
f
o
E
A
M
1
0.8
0.6
0.4
0.2
0
ZeroRt vs BLR
Static Policy vs BLR
SVM vs BLR
0
0.2
0.4
0.6
MAE of BLR
0.8
1
Fig. 7. Comparison of the individual performance on 20 participants
for one random partition and tu = 100%. We plot MAE obtained by
the baselines and a SVM versus those obtained by our BLR model.
Each point corresponds to the MAE of a participant estimated using
(3) with Nu = 20 and U = 1. Note that not all the points are visible
due to the plot’s scale. A thin grey line joins the MAEs obtained on
the same participant. A point above the dashed grey line indicates
that the corresponding baseline gives worse performance than our
method, which is the case for most participants. Also, we can see
that SVM and BLR have comparable performances.
of decisions, which is ignored by the 0-1 loss. For example,
MAE penalizes decisions according to the degree of privacy
violation, i.e., predicting “allow” for “deny” has a loss of 2
compared to predicting “obfuscate” which has a loss of 1.
Under 0-1 loss these errors are treated equally with a loss of
1. Thus, MAE is a better measure of the loss for our problem.
Although we believe our results are quite encouraging (more
than 80% of correct predictions for modest training set sizes,
hence lower user burden), the level of user satisfaction for such
values of the performance metric must be evaluated through
dedicated experiments and user studies, which will be carried
out in the second phase of the project.
Furthermore, we show in Figure 6(c) the distribution of
MAE over test decisions in Dtest for one random partition
with tu = 100%, i.e., all the training data. Context-aware
methods such as BLR and SVM have very few mistakes with
a loss of 2, which clearly shows that such methods very rarely