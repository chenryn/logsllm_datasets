title:Automatically Inferring the Evolution of Malicious Activity on the
Internet
author:Shobha Venkataraman and
David Brumley and
Subhabrata Sen and
Oliver Spatscheck
Automatically Inferring the Evolution of Malicious Activity on the Internet
Shobha Venkataraman
AT&T Labs – Research
PI:EMAIL
David Brumley
Carnegie Mellon University
PI:EMAIL
Oliver Spatscheck
AT&T Labs – Research
PI:EMAIL
Subhabrata Sen
AT&T Labs – Research
PI:EMAIL
Abstract
Internet-based services routinely contend with a range of
malicious activity (e.g., spam, scans, botnets) that can po-
tentially arise from virtually any part of the global Internet
infrastructure and that can shift longitudinally over time. In
this paper, we develop the ﬁrst algorithmic techniques to au-
tomatically infer regions of the Internet with shifting secu-
rity characteristics in an online fashion. Conceptually, our
key idea is to model the malicious activity on the Internet as
a decision tree over the IP address space, and identify the
dynamics of the malicious activity by inferring the dynamics
of the decision tree. Our evaluations on large corpuses of
mail data and botnet data indicate that our algorithms are
fast, can keep up with Internet-scale trafﬁc data, and can
extract changes in sources of malicious activity substan-
tially better (a factor of 2.5) than approaches based on us-
ing predetermined levels of aggregation such as BGP-based
network-aware clusters. Our case studies demonstrate our
algorithm’s ability to summarize large shifts in malicious
activity to a small number of IP regions (by as much as two
orders of magnitude), and thus help focus limited operator
resources. Using our algorithms, we ﬁnd that some regions
of the Internet are prone to much faster changes than others,
such as a set of small and medium-sized hosting providers
that are of particular interest to mail operators.
1 Introduction
Business-critical Internet-based services have to rou-
tinely contend with and mitigate a range of malicious ac-
tivity (e.g. spam, scans, botnets) that can arise from vir-
tually any part of the global Internet infrastructure. Iden-
tifying the regions of malicious activity on the Internet is
valuable for enhancing the security of networks, applica-
tions, and end-users along multiple dimensions and time-
scales. However, static snapshots showing malicious activ-
ity at a particular point of time are of limited use because
evil is constantly on the move. Administrators often even-
tually discover and clean up infected hosts, which causes
attackers to target new vulnerabilities and attack new hosts
elsewhere. Indeed, operators care far more about the evolu-
tion of malicious activity than static snapshots, as the evo-
lution provides warning signs of emerging threats from re-
gions previously-considered benign.
However, there has been little work on developing al-
gorithms that can automatically infer how aggregations of
malicious IPs evolve over time. Previous work has either
created static snapshots [28, 29], or has explored the feasi-
bility of using various a priori ﬁxed IP clustering schemes
for spam-ﬁltering over longer periods [9, 13, 22, 27, 30],
among which BGP-based preﬁx clustering schemes, such
as network-aware clusters [19] have been especially popu-
lar. One challenge is it is not obvious a priori what level
of aggregation granularity to use. While we know mali-
cious IP addresses tend to be clustered, e.g., to ISPs with
poorly-managed networks [5, 21, 23, 30], many natural op-
tions for a particular granularity provide inaccurate results.
For instance, the individual IP address is too ﬁne-grained
to provide useful results [16, 23, 30, 31], e.g., DHCP can
cause a single attacker to appear and disappear quickly from
speciﬁc IP addresses. On the other hand, predetermined
aggregations of IP addresses such as by AS or BGP pre-
ﬁx also does not afford the correct granularity. For exam-
ple, network-aware clustering using BGP routing preﬁxes
are likely to cluster the well-managed infrastructure hosts
of an ISP together with its poorly-managed broadband ac-
cess customers. This is highlighted in several recent re-
sults [9, 13, 22, 27], which have illustrated that BGP-based
IP aggregations allow only for a coarse classiﬁcation of ma-
licious activity.
Since there are no obvious natural a priori aggregations
to use, we need to be able to automatically infer the ap-
propriate aggregation levels for detecting changes in dif-
ferent parts of the Internet, based on current observations.
The appropriate aggregation varies drastically from region
to region: some regions, such as small or mid-sized hosting
providers, likely need to be monitored at very ﬁne granu-
larities (such a /24 or smaller preﬁx size), while other re-
gions (e.g., entire countries that appear to be spam havens)
need to be monitored at much coarser granularities. The
problem becomes even more critical as IPv6 starts to get
widely deployed – it is infeasible to even enumerate every
IP address in the IPv6 address space. A practical algorithm
therefore needs to scale as a function of the number of dis-
tinct preﬁx aggregations needed, not as a function of the
size of the address space. A further complication is that
not every change in malicious activity is useful to ﬁnd, e.g.,
newly spamming IPs are of little interest if they belong to
a well-known spam haven, but of substantial interest if they
belong to a well-managed business network. Previous work
has not addressed this problem.
In this paper, we develop the ﬁrst algorithmic techniques
to automatically infer regions of the internet with shifting
security characteristics in an online fashion. We call an IP
preﬁx that turns from good to evil a ∆-bad preﬁx, and a bad
preﬁx that sees the light and becomes good a ∆-good preﬁx.
Our key idea is that shifts in malicious activity will trigger
errors in an accurate classiﬁer of the IP address space’s ma-
licious activity. We model the IP address space as a decision
tree, which when given a particular preﬁx, outputs a label
“good” or “bad”. We also periodicially measure the error in
the decision tree, i.e., measure when it labels an IP preﬁx as
good when it is, in fact, originating malicious trafﬁc. The
intuition is that when the decision tree has such errors on
preﬁxes that it used to label accurately, it is not indicative
of a problem with the decision tree, but instead indicative of
a ∆-good or ∆-bad change. An additional challenge is that
not all preﬁxes need to be modeled at the same granular-
ity, e.g., AT&T’s preﬁx should not be modeled at the same
granularity as MIT, even though both own a /8. A key com-
ponent of our algorithm is it automatically infers the right
granularity to minimize error in labeling IP preﬁxes ∆-good
or ∆-bad.
More speciﬁcally, we present two algorithms to answer
two main questions. First, can we identify the speciﬁc re-
gions on the Internet that have changed their malicious ac-
tivity? Second, are there regions on the Internet that change
their malicious activity much more frequently than others?
The ﬁrst question helps operators quickly focus their atten-
tion on the region of importance, e.g., if one of their net-
works is suddenly compromised. The second question ex-
plores structural properties about the nature of changes in
malicious activity, highlighting the preﬁxes that need to be
“under watch”, as they are among the most likely to be fu-
ture sources of attacks.
We present two algorithms, ∆-Change and ∆-Motion
respectively, that address the above two questions. At a
high-level, ∆-Change answers the ﬁrst question by analyz-
ing how well the different preﬁx aggregations in the static
snapshots model input data. By design, it ensures that every
preﬁx identiﬁed by our algorithms has indeed undergone a
change, i.e., our list of ∆-bad and ∆-good preﬁxes has no
false positives. ∆-Motion answers the second question by
using previously-accurate snapshots to identify individual
IP addresses that have changed their behaviour, and then
partitions the address space into regions that have a high
volume of changes and regions that have few changes. Our
algorithms work without assuming a ﬁxed distribution of
IP addresses (a common assumption in many learning al-
gorithms, which allows for easier learning and inference).
Indeed, part of the data comes from malicious adversaries
who have an incentive to mislead our algorithms and evade
detection.
We evaluate our algorithms experimentally on two dif-
ferent sources of malicious activity from a tier-1 ISP – four
months of mail data labeled with spamming activity, and
three months of network traces labeled with botnet activity,
and we demonstrate that our algorithmic techniques can ﬁnd
changes in spam and botnet activity. In particular, our ex-
periments show we can ﬁnd more shifts in malicious activ-
ity by a factor of 2.5 than by applying extensions of existing
static algorithms such as network aware clusters. Through
case studies, we demonstrate how our algorithms can pro-
vide operators with a network-wide understanding of mali-
cious activity (both internal as well as external), and help
them prioritize scarce manual effort to the most affected re-
gions. For example, in one case study, our algorithm sum-
marized a large shifts in botnet activity into a very small
number of ∆-change preﬁxes (22,000-36,000 new IPs from
DNSChanger and Sality botnets into 19-66 preﬁxes – a drop
of over two orders of magnitude). In another case study,
our algorithm discovered a large number of regional ISPs
whose spamming activity dropped during the takedown of
the Grum botnet.
Finally, we ﬁnd that there are certain
regions of the IP address space that are much more prone to
changes in spamming activity. For example, we found that a
set of small and mid-sized hosting providers (which do not
appear as distinct entities in BGP preﬁxes) are extremely
prone to changes in spam activity – this is an intuitive re-
sult which network operators can easily validate (and then
begin to monitor), and which our algorithm discovered au-
tomatically from noisy decision tree snapshots with nearly
100,000 nodes each.
Our algorithms are also scalable: our current (unopti-
mized) implementation is able to process a day’s worth
of data (30-35 million IPs) in around 20-22 minutes, on a
2.4GHz processor with only a single pass over the data and
uses only 2-3 MB of memory. Further, a switch to IPv6
will have relatively little impact on our algorithm, as the re-
quired size of the decision trees is only a function of the dis-
tinct administrative entities in terms of malicious behaviour,
rather than the size of the address space.
More broadly, our results show that while there is plenty
of change in the malicious (both spamming and botnet) ac-
tivity on the Internet, there is also signiﬁcant structure and
predictability in these changing regions, which may be use-
ful for enhancing mitigation strategies.
2 Deﬁnitions and Preliminaries
Our high-level goal is to design an algorithm that takes
as input a stream of IP addresses ﬂagged malicious or non-
malicious (e.g., spam logs, labeled with spam-ﬁltering soft-
ware), and ﬁnds a set of IP preﬁxes whose IP addresses
have changed from malicious to non-malicious, or vice-
versa, across the stream. In this section, we describe how
important changes can be naturally modeled by monitoring
a decision tree on the IP address space.
Background. We ﬁrst introduce some standard machine
learning terminology. A classiﬁcation function (or a classi-
ﬁer) is a function that takes as input a given IP address, and
outputs a label denoting whether the IP address is malicious
(also denoted by a “-”) or non-malicious (also denoted by a
“+”). The classiﬁcation function makes a mistake whenever
it labels a malicious IP address as non-malicious, or a non-
malicious IP address as malicious. The classiﬁcation error
of a classiﬁcation function is the fraction of the input IP ad-
dresses on which it makes a mistake.
We also introduce some networking background. An IP
address preﬁx (also called IP preﬁx) i/d denotes the part
of the IP address space that is covered by the ﬁrst d bits
of i, e.g., the preﬁx 10.0.0.0/8 indicates the part of the IP
address space whose ﬁrst octet is 10, i.e., all IP addresses
in the set 10. ∗ . ∗ .∗. Note that the preﬁx i/d + 1, (i.e.,
10.0.0.0/9 in our example) denotes a subset of the address
denoted that i/d (i.e., 10.0.0.0/8). The IP address hierarchy
can be naturally interpreted as a binary tree: the leaves of
the tree correspond to individual IP addresses, the internal
nodes correspond to the IP preﬁxes, and IP preﬁx i/d is the
parent of the preﬁx i/d + 1 in this representation. We say
that IP preﬁx x belongs to preﬁx y if x is a parent of y in
this tree, e.g., 10.0.0.0/9 belongs to 10.0.0.0/8.
2.1 Modeling the Problem
We begin with a motivating example. Consider a /23 pre-
ﬁx owned by an access provider, and suppose that a number
of hosts with IP addresses in this /23 get compromised and
start spamming. Now if this /23 preﬁx belongs to a larger
preﬁx (say, a parent /22) that is already a known spam-
haven, this new spamming activity of the /23 is not very
interesting to an operator, since the larger region is known
to spam (i.e., it is not surprising that a smaller region within
a known spam-haven also starts to spam). If, on the other
(a) No change
(b) Change
Figure 1. Example of ∆-bad Changes.
(a) shows a
preﬁx that is not ∆-bad, because /23 starts originating
malicious trafﬁc when its parent /22 is already known to
originate malicious trafﬁc (b) shows a preﬁx that is de-
ﬁned as ∆-bad, because the /23 starts originating mali-
cious trafﬁc when its parent /22 is not known to originate
malicious trafﬁc.
hand, the larger preﬁx (e.g., the parent /22) has originated
only legitimate trafﬁc so far, the new spamming activity be-
comes much more interesting to network operators, because
they previously assumed that the region did not spam. By
notifying operators of the change, they can control or block
the spam from the /23 to their networks. We illustrate this
example in Figure 1.
A key part of this example is having an accurate clas-
siﬁer for the the type of trafﬁc originated by the two /22
preﬁxes – we need to know what kind of trafﬁc a particular
region is expected to originate, before we can understand
when the region has changed its malicious activity. How-
ever, we do not have such a classiﬁer given to us as input,
and we need to infer it dynamically from a stream of IP ad-
dresses and their associated labels. Thus, to infer change,
we ﬁrst have to infer such a classiﬁer for the preﬁxes from
the labeled IP addresses, and then use this classiﬁer to infer
changes. Moreover, the appropriate preﬁx granularity for
such a classiﬁer is different in different parts of the Inter-
net, we need to also infer the required preﬁx granularities.
Because it is likely impossible to infer a classiﬁer with zero
error, we instead will look for changes relative to any clas-
siﬁer that makes no more than τ error on the data, for small
(input) τ > 0. By deﬁnition, all such classiﬁers must clas-
sify most of the data identically. In particular, let st denote
the stream of input  pairs appearing in epoch
t; our goal is to detect preﬁxes that have changed in st+1
relative to a classiﬁer that makes no more than an input τ
error on st.
Algorithmic constraints and Adversarial Model The
scale of network trafﬁc makes it infeasible to use compu-
tationally expensive algorithms.
In particular, a solution
should have constant processing time per IP, make only a
single pass over the input streams, and have memory re-
quirements that are sublinear in the input data size. Such al-
0.0.0.0/1
0.0.0.0/2
0.0.0.0/0
128.0.0.0/1
192.0.0.0/2
+
-
+
160.0.0.0/3
+
128.0.0.0/4
152.0.0.0/4
+
-
Figure 2. Example IPtree of size 6, since it has 6 leaves.
Each leaf has a ”+” or a ”-”, denoting whether the asso-
ciated preﬁx originates non-malicious or malicious traf-
ﬁc. Section 3 describes how we learn such a tree from
data.
gorithms are called online, and are among the most desired
(and difﬁcult to create). In addition, our data may have to
have some noise – e.g., an IP may be labeled as produc-
ing spam incorrectly. For example, if our labels are com-
ing from SpamAssassin, and SpamAssassin mislabels legit-
imate mail from an IP as spam, then our algorithm receives
an inaccuracy label for this IP, and must be able to cope with
this inaccuracy. Our algorithm’s performance thus needs to
scale gracefully as the noise increases, and be able to pro-
duce accurate output when the noise in the data is tiny. Fi-
nally, we cannot assume that input IPs are drawn from a
ﬁxed probability distribution over I. Although assuming a
ﬁxed distribution would be easier, it would make the algo-
rithm easier to evade. In particular, we assume an adversary
can pick the addresses from which malicious activity origi-
nates, and therefore, could mislead any algorithm assuming
that all IPs originate from a priori ﬁxed distribution.
Practical considerations There are additional constraints
that make the algorithm more useful by directing atten-
tion towards changes that are most actionable by operators.
First, we aim to detect preﬁxes with at least θ trafﬁc since
(1) data may be occasionally mislabeled, and (2) changes in
preﬁxes with very little trafﬁc may not be noteworthy.
In addition, operators only care about preﬁxes where the
change is directly evident: i.e., if the preﬁx changes from
originating mostly non-malicious activity to mostly mali-
cious activity, or vice versa. 1 To formalize this concept, we
introduce the concept of a state to reﬂect level of malicious
activity of a preﬁx. Formally, a state is deﬁned by an inter-
val in [0, 1]; the set of all states D input to the algorithm is