title:Who's Hosting the Block Party? Studying Third-Party Blockage of CSP
and SRI
author:Marius Steffens and
Marius Musch and
Martin Johns and
Ben Stock
Who’s Hosting the Block Party?
Studying Third-Party Blockage of CSP and SRI
Marius Steffens∗, Marius Musch†, Martin Johns†, and Ben Stock∗
∗CISPA Helmholtz Center for Information Security: {marius.steffens,stock}@cispa.de
†TU Braunschweig: {m.musch,m.johns}@tu-braunschweig.de
Abstract—The  Web  has  grown  into  the  most  widely  used 
application  platform  for  our  daily  lives.  First-party  Web  ap-
plications  thrive  due  to  many  different  third  parties  they  rely 
on  to  provide  auxiliary  functionality,  like  maps  or  ads,  to  their 
sites. In this paper, we set out to understand to what extent this 
outsourcing has adverse effects on two key security mechanisms, 
namely  Content  Security  Policy  (CSP;  to  mitigate  XSS)  and 
Subresource Integrity (SRI; to mitigate third-party compromises) 
by  conducting  a  longitudinal  study  over  12  weeks  on  10,000  top 
sites.  Under  the  assumption  that  a  ﬁrst  party  wants  to  deploy 
CSP and SRI and is able to make their code base compliant with 
these  mechanisms,  we  assess  how  many  sites  could  fully  deploy 
the  mechanisms  without  cooperation  from  their  third  parties. 
For those unable  to do so without cooperation,  we also measure 
how  many  third  parties  would  jointly  have  to  make  their  code 
compliant  to  enable  ﬁrst-party  usage  of  CSP  and  SRI.
To more  accurately  depict  trust  relations,  we  rely  on  holistic 
views  into  inclusion  chains  within  all  pages  of  the  investigated 
sites.  In  addition,  based  on  a  combination  of  heuristics  and 
manual  validation,  we  identify  different  eTLD+1s  belonging 
to  the  same  business  entity,  allowing  us  to  more  accurately 
discerning  parties  from  each  other.  Doing  so,  we  show  that  the 
vast majority of sites includes third-party code which necessitates 
the  use  of  unsafe-inline  (75%)  or  unsafe-eval  (61%), 
or  makes  deployment  of  strict-dynamic  impossible  (76%) 
without breakage of functionality. For SRI, based on the analysis 
of a single snapshot (within less than 12 hours), we also show that 
more  than  half  of  all  sites  cannot  fully  rely  on  SRI  to  protect 
them  from  third-party  compromise  due  to  randomized  third-
party  content.
I. INTRODUCTION
The  Web,  as  we  know  it  today,  is  deeply  intertwined  with
our everyday life. It allows us to perform essential tasks, such
as  keeping  in  touch  with  our  beloved  ones  through  social
media,  and  even  serves  us  feature-rich  business  appliances.
However,  since  the  advent  of  the  Web  2.0,  there  was  a
rapid  growth  in  complexity  on  the  client  side  [33].  Notably,
the  amount  of  different  contributors  from  which  scripting
resources  are  included  follows  this  increase,  resulting  in  a
continually  rising  reliance  on  third  parties.  For  example,  the
Web  site  of  a  coffee  shop  can  refer  to  an  external  library  to
incorporate  an  interactive  map  showing  the  quickest  route  to
Network  and  Distributed  Systems  Security  (NDSS)  Symposium  2021
21-25 February 2021, Virtual 
ISBN 1-891562-66-5
https://dx.doi.org/10.14722/ndss.2021.24028
www.ndss-symposium.org
the next store. The coffee shop can thus rely on a third party
to take care of this speciﬁc part, enabling the ﬁrst party to
focus on the needs of their core functionality. Other use cases
include advertisement, analytics, or simply hosting a widely
used library in a single place, reducing trafﬁc on one’s site.
The increasing reliance on third parties to provide func-
tionality to ﬁrst-party sites naturally comes with risks. In
particular,
including scripts from others allows such third
parties to add whatever code they deem necessary and even
delegate this privilege to arbitrary additional external parties.
Numerous research works in this area have shown that this
reliance on third parties increases the attack surface of ﬁrst-
party sites, e.g., via third-party compromise due to bad security
practices [22], the addition of malicious code via intertwined
inclusion chains [2, 8], and the introduction of client-side XSS
[18, 31, 32].
Hence, it is in a site developer’s best interest to defend
their site against such threats. Speciﬁcally, we focus on two
key mechanisms to protect Web sites: Content Security Policy
(CSP) and Subresource Integrity (SRI). CSP [29] primarily
aims to mitigate the impact of XSS vulnerabilities. In contrast,
SRI [20] aims to secure including sites against compromise
of third-party servers by only executing scripts that match the
cryptographic hash attached to their deﬁnition. Unfortunately,
both mechanisms lack widespread deployment [1]. Up to 95%
of deployed CSPs are utterly insecure [3, 39], and rolling out
CSP was recently shown to be a lengthy process in which
some sites ultimately give up and fail to arrive at a meaningful
policy [27]. New CSP features, such as strict-dynamic,
are intended to make a secure deployment of CSP easier for
the ﬁrst party. Speciﬁcally, the authors envision “with such a
policy, the owner would need to add nonces to static 
elements, but would be assured that only these trusted scripts
and their descendants would execute. This mode of deploying
CSP can signiﬁcantly improve the security of a policy and
facilitate adoption” [39]. Nevertheless, even though the feature
was added in 2016 to the CSP standard, it has not been
adopted by many sites, and script-controlling policies are still
as insecure as ever [27]. Similarly, while SRI’s popularity is
slowly increasing, this is primarily due to widespread libraries
like jQuery [4], leaving many other resources susceptible to
cause severe harm in case of compromised third parties.
The main focus of our work is to assess how many sites
are blocked from meaningful usage of CSP and SRI through
how many third parties; under the assumption that ﬁrst parties
want to secure their site (and are able to make their own code
compatible, especially with CSP). Virtually all prior research
on third parties [2, 8, 10, 22, 34] has used the notion of an
eTLD+1 to reason about parties. This assumption, however,
does not hold true as it is common for modern sites to split
their application logically across multiple eTLD+1s. Instead,
we deﬁne parties by the entity that operates them, e.g., Google
for Youtube and Doubleclick. We derive two heuristics to
identify candidates for our deﬁnition of an extended Same
Party and manually vet them to avoid false positives.
With this improved notion of a party, we tackle our main
research question through an extensive 12-week experiment of
the Tranco top 10,000, in which we collect inclusions, attribute
them to the respective parties, and observe the behavior the
different parties exhibit. In doing so, and assuming a ﬁrst
party that is willing to tackle the necessary modiﬁcations to
their own codebase to enable a meaningful CSP, we show
that the instability in inclusions through third parties limits the
applicability of host-based allowlists, the only universally sup-
ported mode of CSP (as even modern browsers like Safari lack
strict-dynamic support). Similarly, the usage of APIs
like eval and the parser-inserting addition of script elements
and event handlers hinders deployment of policies without
the unsafe-eval and unsafe-inline keywords, and
hampers roll-out of nonce-based strict-dynamic policies.
We also highlight that high-proﬁle third-party inclusions such
as Facebook or Doubleclick often randomize minuscule parts
of the script content, rendering the hash-based SRI deployment
impossible. With both these aspects, even a party willing
to make their own code base compliant with these security
mechanisms, will not be able to have meaningful security
without suffering from breakage of third-party functionality.
In sum, our paper makes the following contributions:
• Based on observed inclusion relations, we derive a new
notion of party beyond eTLD+1, dubbed extended Same
Party in Section IV. We then show that our new notion is
much closer to reality than using eTLD+1s, highlighting
the need for such an improved notion for the modern Web
(Section V).
• We measure how the behavior of ﬁrst, third, and delegated
code impacts the deployment of CSP in Section VI.
In particular, we study how the ﬂuctuation in included
hosts renders host-based CSPs infeasible, how often
sites would need to use the trivially insecure unsafe-
inline keyword, and how sites cannot use strict-
dynamic without causing breakage in their third-party
dependancies.
• In Section VII, we analyze the feasibility of restricting
the behavior of a site’s codebase to the script hash using
SRI and show that the ﬂuctuation of script content hosted
at static URLs does not allow the majority of sites to pin
their third-party dependencies. Furthermore, we show that
in the wild SRI’s protection is frequently undermined by
unpinned inclusions performed by pinned resources.
• Based on our empirical analyses, we provide calls to
action to both third-party script providers and browser
vendors. Furthermore, to aid developers in assessing the
adverse effects of third-party scripts, we open-source
SMURF, which allows to attribute CSP-incompatible
behavior to hosts.
II. TECHNICAL BACKGROUND
In this paper, we refer to a registerable domain (e.g.,
bbc.co.uk or google.com) as an eTLD+1 (effective top-
level domain+1). We use the term interchangeably with site,
aligned with, e.g., the notion of same-site that browsers use for
security mechanisms like site isolation [25]. In addition, we
use the term disconnect to reason about how connected a ﬁrst
party is to third-party code; i.e., whether they directly include
such code or whether any of the included parties added the
additional scripts.
A. JavaScript Inclusions
The Web’s core security concept is the Same-Origin Policy,
which ensures that a script can only access resources from the
same origin (protocol, host, and port). JavaScript inclusions are
partially exempt from this rule, as any HTML document may
include scripts from other origins. While the content of the
scripts cannot be read, the JavaScript engine will execute these
scripts; importantly, in the origin of the including document.
JavaScript can, in turn, add additional scripting resources,
be it through writing script tags or event handlers through
document.write, invoking eval to convert a string to
code, or programmatically adding scripts to the DOM through
document.createElement and appendChild. By de-
fault, inclusions cannot be restricted, i.e., any included script
can add additional content to its liking.
B. Content Security Policy
In its original form, the Content Security Policy (CSP) was
meant to mitigate the effects of Cross-Site Scripting and enable
a developer to limit the resources which could be loaded into
their site [29]. This is achieved by providing an allowlist
of origins from which external content can be included, in
combination with disallowing potentially dangerous constructs
such as inline scripts, event handlers, and eval by default.
To allow for backward compatibility in using those unsafe
practices while rolling out a strict CSP, unsafe-inline
and unsafe-eval are part of the CSP speciﬁcation. De-
ploying a policy with unsafe-inline essentially allows
an attacker abusing an injection vulnerability to insert their
script content directly as an inline script; such policies cannot
mitigate XSS. At
the same time, as removing any inline
script seemed infeasible, CSP added nonces and hashes [36].
Through this, developers can attach a random nonce to each
script (as contained in the CSP), making them executable;
similarly, scripts can be allowed through their hash sum. It
must be noted, though, event handlers cannot be allowed in
this fashion. The only option to achieve is to add the unsafe-
hashes [37] attribute to the policy, which enables event
handlers to be executed if their hash is explicitly allowed.
2
Orthogonally, if a site operator needs to use eval, they have
to resort to unsafe-eval.
Weichselbaum et al. [39] proposed strict-dynamic
to alleviate the burden of keeping a CSP up to date with
all
the hosts being added by third parties. If this mode
is enabled, any script that is allowed through a hash or a
nonce can programmatically add additional scripts, i.e., by
using createElement and appendChild, but not doc-
ument.write. Notably, when this option is enabled, any
host-based allowlist is disabled, meaning that even inclusions
from the same host must be done programmatically.
C. Subresource Integrity
While CSP aims to mitigate script injection attacks, Sub-
resource Integrity (SRI) was designed to disarm malicious
modiﬁcation of externally included resources, e.g., through
compromised Content Delivery Networks or via in-transit
alteration of script code done by network-based attacks [20].
To take advantage of this feature, the including party has
to specify the hash of the expected content
in a script’s
integrity attribute. In case of a mismatch between the hash
of the content and the integrity value, the browser refuses to
execute the script. Given the nature of the mechanism, a single-
byte change in the included script will lead to mismatching
hashes, effectively disabling the modiﬁed script. Hence, for
a script to be SRI-compatible, it must not change; a prime
example of an SRI-pinnable script
is jQuery, which can
be included centrally from jQuery.org through an explicit
version number in the URL, which never changes its content.
Recently, a work of Cherubini et al. [5] proposed to extend the
capabilities of SRI to also allow developers to pin the contents
of downloads which they link to on their own page, reducing
risk of erroneous checksum veriﬁcation of end-users.
III. EXPERIMENT PARAMETERS
To answer our main research question, namely whether
ﬁrst parties can simply change their own codebase to allow
for seamless integration of CSP and SRI, we utilize the
Tranco [12] list from January 13, 2020, to extract the 10,000
highest ranking sites1. To mitigate the impact of a single
party with multiple internationalized domains (e.g., Google
with around 80 different TLDs) on our results, we used
Tranco’s feature to group together those sites belonging to
one organization.
We set out to analyze not only a single snapshot of the
Web’s tangled nature, but instead also to investigate the rate of
change observable throughout a prolonged period. Therefore,
we ran crawls once a week from January 13th through March
30th, 2020. For each crawl, our crawlers visited the start
pages from the ﬁxed list and followed every same-site link. To
avoid inﬂuences of stale URLs, we repeat this process every
time, limiting ourselves to a maximum of 1,000 pages per
site. On average, each crawl yielded around 1 million URLs.
For results that do not consider the longitudinal aspect of
1https://tranco-list.eu/list/3Q2L
our data collection, we report on the data gathered in our
ﬁrst crawl. Overall, we could ﬁnd that of the 10,000 Tranco
entries, we could only analyze 8,389 by connecting to the
website by following the link http://entry. In 493 cases, we hit
a timeout in our crawling infrastructure. Besides sites that take
too long to visit, we could ﬁnd hints that some sites behaved
differently when crawling them from our analysis machines
compared to our home network. We expect that our public
IP addresses used are known to host crawlers, and we do
not take speciﬁc measures to conceal our trafﬁc as human-
generated. We were unable to connect to 603 entries because
of network-level
issues, such as NXDOMAIN, connection
refusals, or certiﬁcate errors. Another 515 sites redirected our
crawler to another site, which we therefore also excluded from
our analysis. We can ﬁnd 348 sites that do not include any
scripting resources at all. Manual investigation showed the
lack of scripting resources was mostly due to blank pages
(again likely as our IP is known as a crawler). Notably, we
also found instances in which Web sites refused us to access
the real content, e.g., at https://www.radio.com, which
instead showed a static warning page indicating unavailability
for our geolocation. Ultimately, this leaves us with 8,041 sites
with any script resource, which we consider throughout our
analyses.
IV. AN IMPROVED NOTION OF DISCONNECT
In order to understand which parties are introducing code
is incompatible with CSP and SRI, we ﬁrst need to
that
discuss how we can reliably attribute code locality to the
varying parties that jointly contribute to the overall code base
of sites. We ﬁrst highlight technical challenges that need to
be considered for collecting precise inclusion relations (i.e.,
which party includes scripts from which other parties) on
the level of single scripts. We then leverage the resulting
inclusion trees to analyze co-occurrence patterns, which serve
as heuristics for candidate hostname pairs that are likely to be
afﬁliated. Lastly, we discuss how we can use these patterns
in uncovering which hostnames actually belong to the same
entity using manual efforts for the ﬁnal veriﬁcation and how
we can quantify disconnect of code based on a holistic view
into a given site.
A. Collecting Inclusion Relations
The ﬁrst step in answering our research questions is the
collection of real-world inclusions. While previous work has
already developed the ﬁrst tools to capture inclusions [11], we
build upon their capabilities to address previously unaddressed
issues related to state-of-the-art JavaScript features. These
include asynchronous execution as well as incorrect attribution
of inclusions to well-known libraries. In the following, we
present how we address the shortcomings of prior works. In
the spirit of open science, our implementation will be open-
sourced as part of a lightweight analysis technique which
we coin SMURF (see Section VIII-C), helping developers
to uncover problematic inclusion decisions and allowing other
researchers to compare against our work.
3
1) Precisely Capturing Inclusion Relations: To capture
inclusion relations, we reconstruct which entity initiated a
particular script inclusion using call stack traces. Although this
has been done by prior work [11], through modern JavaScript
features such as Promises, call stacks can be asynchronous.
Based on the available implementations, this has not been
considered before. To address this shortcoming, rather than
relying on the stack trace available through regular Java-
Script, we resolve all preceding stack traces via the DevTools’
Debugger.getStackTrace API with the current trace’s
parentId in the arguments to get the full chain of events that
led to a given inclusion. While this change may appear minus-
cule, given the increasing language support, e.g., async/await
in ECMAScript 2017 [7], we believe this to be an important
point to consider for our as well as all future work.
2) Correctly Handling Libraries: Usually, one would tie
the notion of an inclusion’s initiator to the top-most entry of
the call stack. However, modern libraries present throughout
the top sites provide asynchronous execution functionality,
e.g., jQuery’s $(document).ready(callback). When
called, jQuery stores the function pointer to callback and