6
8
Table 2: Minimum timeout in seconds that would have cap-
tured c% of pings from r% of IP addresses in the IT63w
(20150117) and IT63c (20150206) datasets (where r is the
row number and c is the column number).
However, we see that a substantial fraction of IP addresses
also have surprisingly high latencies. For instance, to cap-
ture 95% of pings from 95% addresses requires waiting 5 sec-
onds. Restated, at least 5% of pings from 5% of addresses
have latencies higher than 5 seconds. Thus, even setting a
timeout as high as 5 seconds will infer a false loss rate of 5%
for these addresses.
Note that retrying lost pings cannot be used as a substi-
tute for setting a longer timeout since a retried ping is not
an independent sample of latency. Whatever caused the ﬁrst
one to be delayed is likely to cause the followup pings to be
delayed as well, as we show in Section 6.
At the extreme, we see 1% of pings from 1% of addresses
having latency above 145 seconds! These latencies are so
high that we investigate these addresses further. We now
consider 60 seconds to be a reasonable timeout to balance
progress with response rate, at least when studying outages
and latencies, although an ideal timeout may vary for diﬀer-
ent settings. A timeout of 60 seconds easily covers 98% of
pings to 98% of addresses, yet does not seem long enough to
slow measurements unnecessarily.
5. VERIFICATION OF LONG PING TIMES
In this section, we address doubts that long observed ping
times are real:
that they are a product of ISI’s probing
scheme, that they might be caused by errors in a partic-
ular data set, or that they might derive from discrimination
against ICMP.
5.1 Are high latencies observed by other prob-
ing schemes?
Some of the latencies in Table 2 are so high that we con-
sidered if they could be artifacts of ISI’s probing scheme. We
investigate latencies obtained using two other probing tech-
niques, Zmap and scamper, and check if the high latencies
observed in the ISI datasets are reproducible.
Does Zmap observe high latencies?
We check for high latencies using the Zmap scanner [5]. As
part of our extension of the ICMP probing module in the
Zmap scanner, we also embed the probe send time into the
echo request, and extract it from the echo response, allow-
ing us to estimate the RTT, albeit without the precision of
kernel send timestamps.
Zmap has performed these scans since April 2015. Scans
have been conducted over a range of diﬀerent times, diﬀer-
ent days of the week and across four months in 2015 (as of
Sep 5, 2015), as shown in Table 3. Typically, scans were per-
308(a) Before ﬁltering
(b) After ﬁltering
Figure 6: CDF of Percentile latency per IP address before and after ﬁltering unexpected responses. Each point represents
an IP address and each color represents the percentile from that IP address’s response latencies. Before ﬁltering unexpected
responses, there are bumps caused by broadcast responses at 330s, 165s and 495s, fractions of the 11 minute (660s) probing
interval.
Scan Date
Day Begin Time Echo Responses
Fri
Apr 17, 2015
Apr 19, 2015
Sun
Apr 23, 2015 Thu
Sun
Apr 26, 2015
Apr 30, 2015 Thu
Sun
May 3, 2015
May 17, 2015
Sun
Fri
May 22, 2015
Sun
May 24, 2015
May 31, 2015
Sun
Jun 4, 2015 Thu
Jun 15, 2015 Mon
Jun 21, 2015
Sun
Jul 2, 2015 Thu
Jul 5, 2015
Sun
Jul 9, 2015 Thu
Sun
339M
340M
343M
343M
344M
344M
347M
371M
369M
362M
368M
357M
368M
369M
368M
369M
367M
02:44
12:07
12:07
12:07
12:08
12:08
12:09
00:57
12:09
12:09
12:10
13:53
12:11
12:00
12:00
12:00
12:00
Jul 12, 2015
Table 3: Zmap scan details: For each Zmap scan in Fig-
ure 7, the table shows the date, day of the week, the time
at which the scan began (in UTC time), and the number of
destinations that responded with Echo Responses.
Figure 7: Distribution of RTTs for all Zmap scans performed
in 2015. Around 5% of addresses have latencies greater than
1s in each scan, and 0.1% of addresses observed latencies in
excess of 75s.
formed on Sundays or Thursdays, beginning at noon UTC
time. However, the scans on April 17, May 22, and June 15
were conducted on other days and at other times, increas-
ing diversity. Each Zmap scan takes 10 and a half hours to
complete and recovers Echo Responses from around 350M
addresses.
We choose all available scans and analyze the distribution
of RTTs for the Echo Responses in Figure 7. Most responses
arrive with low latency, having a median latency lower than
250ms for each scan. However, 5% of addresses responded
with RTTs greater than 1 second in each scan. Further, 0.1%
of addresses responded with latencies exceeding 75 seconds
in each scan although the 99.9th percentile latency exhibited
some variation: the May 22 scan had the lowest 99.9th per-
centile latency (77 seconds) whereas the July 9 scan had the
highest (102 seconds). We infer from these nearly identical
latency distributions that high latencies are persistent for a
consistent fraction of addresses.
Does scamper also observe high latencies?
Both ISI and Zmap probe millions of addresses, and we
investigate whether latencies are aﬀected by these probing
schemes triggering rate-limits or ﬁrewalls. We select a small
sample of addresses that are likely to have high latencies
from the ISI dataset, probe them using scamper [13], and
check for unusually high latencies.
In the 2011 - 2013 ISI dataset, 20,095 IP addresses had
at least 5% of their pings with latencies 100 seconds and
above. We chose 2000 random IP addresses from this subset
and sent 1000 pings to them, once every 10 seconds using
scamper [13] and analyzed the responses. In this analysis,
we used scamper’s default packet response matching mech-
anism: so long as scamper continues to run, received re-
sponses will be matched with sent packets. Because we used
scamper’s defaults, scamper ceased to run 2 seconds after the
last packet was sent, so we missed responses to the last few
pings that arrived after scamper ceased running. Although
scamper can be conﬁgured to wait longer for responses, in
0200400600latency (s)0.980.991.0CDFmedian80909598990200400600latency (s)0.980.991.0CDFmedian80909598990.010.1110100RTT (s)01.00.950.00.20.40.60.81.0CDFApr 17Apr 19Apr 23Apr 26Apr 30May 3May 17May 22May 24May 31Jun 4Jun 15Jun 21Jul 2Jul 5Jul 9Jul 12309Figure 8: Conﬁrmation of high latency: Percentile latency
per IP address for 2000 randomly chosen IP addresses from
ISI’s 2011 - 2013 surveys that had > 5% of pings with laten-
cies 100s and above. Each point represents an IP address
and the lines represent the percentile latency from that IP
address. 17% of them continue to observe 1% of their pings
with latencies > 100s.
later analyses, we ran tcpdump simultaneously and matched
responses to sent packets separately.
Of the 2000 addresses, 1244 responded to our probes. Fig-
ure 8 shows the percentile latency per IP address. The 95th
percentile latency for 50% of the addresses is now consid-
erably lower, at 7.3s. This suggests that addresses prone
to extremely high latencies vary with time: we investigate
addresses with this behavior further in Section 6.
Nevertheless, Figure 8 shows that scamper also observes
some instances of very high latencies. 17% of addresses ob-
serve latencies greater than 100 seconds for 1% of their pings.
We therefore rule out the possibility that the high latencies
are a product of the probing scheme.
5.2 Is it a particular survey or vantage point?
ISI survey data are collected from four vantage points
at diﬀerent times. Vantage points are identiﬁed by ini-
tial letter, and are in Marina del Rey, California, “w”; Ft.
Collins, Colorado, “c”; Fujisawa-shi, Kanagawa, Japan, “j”;
and Athens, Greece, “g”.
In this section, we look at summary metrics of each of
the surveys. In Figure 9, our intent was to ensure that the
results were consistent from one survey to the next, but we
found a surprising result as well. The consistency of val-
ues is apparent: the median ping from the median address
remains near 200ms for the duration. However, there are ex-
ceptions in the following data sets: IT59j (20140515), IT60j
(20140723), IT61j (20141002), IT62g (20141210). These
higher sampled latencies are coincident with a substantial
reduction in the fraction of responses that are matched: in
typical ISI surveys, 20% of pings receive a response; in these,
between 0.02% and 0.2% see a response.
It appears that
these data sets should not be considered further. Addition-
ally, it54c (20130524) it54j (20130618) and it54w (20130430)
were ﬂagged by ISI as having high latency variation due to
a software error [11].
Ignoring the outliers, trends are apparent. The timeout
necessary to capture 95% of responses from 95% of addresses
Figure 10: 98th percentile RTTs associated with high-
latency IP addresses using diﬀerent probe protocols. The
ﬁrst probe of a triplet (seq 0) often has a higher latency
than the rest; TCP probes appear to have a similar distri-
bution except for ﬁrewall-sourced responses.
increased from near two seconds in 2007 to near ﬁve seconds
in 2011. (We note that the apparent stability of this line may
be misleading; since the y-axis is a log scale and our latency
estimates are only precise to integer seconds when greater
than 3, small variations will be lost.) The 98th percentile la-
tency from the 98th percentile address has increased steadily
since 2011, and the 99th increased from a modest 20 seconds
in 2011 to a surprising 140 in 2013. These latency observa-
tions are not isolated to individual traces.
In sum, high latency is increasing, and although some sur-
veys show atypical statistics, early 2015 datasets that we
focus on appear typical of expected performance.
5.3 Is it ICMP?
One might expect that high latencies could be a result
of preferential treatment against ICMP. RFC 1812 allows
routers responding to ICMP to rate-limit replies [1,12], how-
ever, this limitation of ICMP should not substantially aﬀect
the results since each address is meant to receive a ping from
ISI once every eleven minutes. Nevertheless, one can imag-
ine ﬁrewalls or similar devices that would interfere speciﬁ-
cally with ICMP.
To evaluate this possibility, we selected high-latency ad-
dresses from the IT63c (20150206) survey. To these ad-
dresses we sent a probe stream consisting of three ICMP
echo requests separated by one second, then 20 minutes
later, three UDP messages separated by one second, then
again 20 minutes later, three TCP ACK probes separated
by one second. We avoided TCP SYNs because they may
appear to be associated with security vulnerability scanning.
We then consider the characteristics of these hosts in terms
of the diﬀerence between ICMP delay and TCP or UDP
delay.
“High-latency” addresses to sample
We choose the top 5% of addresses when sorting by each of
the median, 80th, 90th and 95th percentile latencies. Many
of these sets of addresses overlap: those who have among
the highest medians are also likely to be among the highest
80th percentiles. However, we considered these diﬀerent sets
0200400600RTT (s)00.20.40.60.81.0CDF95990.1110100RTT (s)01.00.00.20.40.60.81.0CDFICMP (seq 0)UDP (seq 0)TCP (seq 0)ICMP (seq 1, 2)UDP (seq 1, 2)TCP (seq 1, 2)310Figure 9: Top: Minimum timeout required to capture the cth percentile latency sample from the cth percentile address in
each survey, organized by time. Each point represents the timeout required to capture, e.g., 95% of the responses from 95%
of the addresses. The 1% line is indicative of the minimum. Bottom: Response rate for each survey; symbols represent which
vantage point was used. Surveys from Japan with very few successes are not plotted on the top graph.
to be important so that the comparison would include both
hosts with high persistent latency and those with high occa-
sional latency. After sampling 15,000 addresses from each of
these four sets, then removing duplicates, we obtain 53,875
addresses to probe.
From these addresses, we found that only 5,219 responded
to all probes from all protocols on April 29, 2015. This is
somewhat expected: Only 27,579 responded to any probe
from any protocol.
To complete the probing, we use Scamper [13] to send the
probe stream to each of the candidate addresses. Note that
scamper uses a 2s timeout by default although the timeout
can be conﬁgured. Instead of setting an alternate timeout
in Scamper, we run tcpdump to collect all received packets,
eﬀectively creating an “indeﬁnite” timeout. This allows us to
observe packets that arrive arbitrarily late since we continue
to run tcpdump days after the Scamper code ﬁnished.
All protocols are treated the same (mostly)
For each protocol, we select the 98th percentile RTT per
address and plot the distribution in Figure 10. We noticed
two obvious features of the data: that the ﬁrst packet of the
triplet often had a noticeably diﬀerent distribution of round
trip times, and that the TCP responses often had a mode
around 200ms. We will investigate the “ﬁrst ping” problem
in Section 6.3.
The TCP responses appear to be generated by ﬁrewalls
that recognize that the acknowledgment is not part of a
connection and sent a RST without notifying the actual des-
tination: this cluster of responses all had the same TTL and
applied to all probes to entire /24 blocks. That is, for each
address that had such a response, all other addresses in that
/24 had the same.
Ignoring the quick TCP responses apparently from a ﬁre-
wall, it does not appear that any protocol has signiﬁcant
preferential treatment among the high-latency hosts. Of
course, this observation does not show that prioritization
does not occur along any of these paths; our assertion is
only that such prioritization, if it exists, is not a source of
the substantial latencies we observe.
5.4 Summary
In this section, we conﬁrmed that extremely high latencies
are also observed by techniques besides ISI’s. We ﬁnd that
the high latencies are not a result of a few individual ISI
datasets, even though some did appear atypical. Further,
high latencies aﬀect all protocols the same.
We also found that the prevalence of high latencies has
been increasing since 2011. In 2015, a consistent 5% of ad-
dresses have latencies greater than a second.
6. WHY DO PINGS TAKE SO LONG?
In this section, we aim to determine what causes high
RTTs. We investigate the RTTs of satellite links and ﬁnd
that they account for a small fraction of high RTT addresses.
We follow up with an analysis of Autonomous Systems and
geographic locations that are most prone to two potentially
diﬀerent types of high RTTs: RTTs greater than 1s and
RTTs greater than 100s. We then investigate addresses that
exhibit each type of RTT and ﬁnd potential explanations.
6.1 Are satellites involved?
A reasonable hypothesis is that satellite links, widely known
for their necessarily high minimum latency, would also be
responsible for very high maximum latencies. Transmis-
sions via geosynchronous satellite must transit 35,786km to
20062007200820092010201120122013201420150.010.1110100Min Timeout (s)99%98%95%90%80%50%1%0.010.1110100200620072008200920102011201220132014201505101520Percentage of successful pingsccccccccccccccccccccccccccccccccccgjjjjjjjjjjjjjjjjjjwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwcColoradogGreecejJapanwCalifornia311Figure 11: Scatterplot of 1st and 99th percentile latencies for addresses with high values of both in survey IT63c; Left omits
satellite-only ISPs; Right includes only satellite-only ISPs.