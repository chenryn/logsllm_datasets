2828
2805
2822
2831
2850
2803
2826
2825
2821
2835
2811
2828
P.value
5.65E-63
5.82E-58
4.30E-47
4.58E-44
1.31E-44
7.03E-41
5.93E-37
4.44E-36
1.72E-32
1.45E-29
9.07E-27
5.62E-25
2.33E-21
3.41E-17
4.69E-15
2.15E-14
1.26E-12
7.74E-12
7.86E-11
1.33E-10
Truth Prop.
49884
0.05
0.05
47026
0.04
40077
0.04
36565
0.04
42747
44642
0.04
0.03
34895
0.04
38231
0.03
31234
0.03
33106
28295
0.03
0.03
29908
0.03
25984
0.02
20057
26913
0.03
0.02
24653
0.02
19110
0.02
20912
0.02
22141
17878
0.02
SNR
17.38
16.60
14.81
14.28
14.38
13.71
12.97
12.80
12.09
11.48
10.87
10.47
9.60
8.51
7.90
7.70
7.15
6.89
6.54
6.46
Table 1: Top-20 strings with their estimated fre-
quencies, standard deviations, p-values, true counts
and signal to noise ratios (SNR or z-scores).
This collection used 128 Bloom ﬁlter with 2 hash func-
tions and 8 cohorts. Privacy parameters were chosen such
that 1 = 1.0743 with q = 0.75, p = 0.5, and f = 0.5.
Given this conﬁguration, we optimistically expected to dis-
cover processes with frequency of at least 1.5%.
We identiﬁed 10 processes shown in Table 2 ranging in
frequency between 2.5% and 4.5%. They were identiﬁed by
controlling the False Discovery Rate at 5%. The “BADAP-
PLE.COM” process was estimated to have frequency of 2.6%.
The other 9 processes were common Windows tasks we would
expect to be running on almost every Windows machine.
Figure 5: Population of strings with their true fre-
quencies on the vertical axis (0.01 is 1%). Strings
detected by RAPPOR are shown in dark red.
p-values show high conﬁdence in our assessment that the
true counts are much larger than 0 and, in fact, comparing
columns 2 and 5 conﬁrms that. Figure 5 shows all 47 de-
tected strings in dark red. All common strings above the
frequency of approximately 1% were detected and the long
tail remained protected by the privacy mechanism.
5.3 Reporting on Windows Process Names
We collected 186,792 reports from 10,133 diﬀerent Windows
computers, sampling actively running processes on each ma-
chine. On average, just over 18 process names were collected
from each machine with the goal of recovering the most com-
mon ones and estimating the frequency of a particularly ma-
licious binary named “BADAPPLE.COM”.
N = 1e+040100200300400N = 1e+0501000200030004000N = 1e+0601000020000300000.000.010.020.030.041100200DetectedNot−detectedTable 2: Windows processes detected.
Est.
Process Name
8054
RASERVER.EXE
7488
RUNDLL32.EXE
7451
CONHOST.EXE
6363
SPPSVC.EXE
5579
AITAGENT.EXE
MSIEXEC.EXE
5147
SILVERLIGHT.EXE 4915
4860
BADAPPLE.COM
4787
LPREMOVE.EXE
DEFRAG.EXE
4760
Stdev
1212
1212
1212
1212
1212
1212
1212
1212
1212
1212
P.value
1.56E-11
3.32E-10
4.02E-10
7.74E-08
2.11E-06
1.10E-05
2.53E-05
3.07E-05
3.95E-05
4.34E-05
Prop.
0.04
0.04
0.04
0.03
0.03
0.03
0.03
0.03
0.03
0.03
5.4 Reporting on Chrome Homepages
The Chrome Web browser has implemented and deployed
RAPPOR to collect data about Chrome clients [9]. Data
collection has been limited to some of the Chrome users
who have opted in to send usage statistics to Google, and to
certain Chrome settings, with daily collection from approx-
imately ∼14 million respondents.
Chrome settings, such as homepage, search engine and
others, are often targeted by malicious software and changed
without users’ consent. To understand who the main players
are, it is critical to know the distribution of these settings
on a large number of Chrome installations. Here, we focus
on learning the distribution of homepages and demonstrate
what can be learned from a dozen million reports with strong
privacy guarantees.
This collection used 128 Bloom ﬁlter with 2 hash functions
and 32 cohorts. Privacy parameters were chosen such that
1 = 0.5343 with q = 0.75, p = 0.5, and f = 0.75. Given
this conﬁguration, optimistically, RAPPOR analysis can dis-
cover homepage URL domains, with statistical conﬁdence,
if their frequency exceeds 0.1% of the responding popula-
tion. Practically, this means that more than ∼14 thousand
clients must report on the same URL domain, before it can
be identiﬁed in the population by RAPPOR analysis.
Figure 6 shows the relative frequencies of 31 unexpected
homepage domains discovered by RAPPOR analysis. (Since
not all of these are necessarily malicious, the ﬁgure does not
include the actual URL domain strings that were identiﬁed.)
As one might have expected, there are several popular home-
pages, likely intentionally set by users, along with a long tail
of relatively rare URLs. Even though less than 0.5% out of
8,616 candidate URLs provide enough statistical evidence
for their presence (after the FDR correction), they collec-
tively account for about 85% of the total probability mass.
6 Attack Models and Limitations
We consider three types of attackers with diﬀerent capabil-
ities for collecting RAPPOR reports.
The least powerful attacker has access to a single report
from each user and is limited by one-time diﬀerential pri-
vacy level 1 on how much knowledge gain is possible. This
attacker corresponds to an eavesdropper that has temporary
ability to snoop on the users’ reports.
A windowed attacker is presumed to have access to one
client’s data over a well-deﬁned period of time. This at-
tacker, depending on the sophistication of her learning model,
could learn more information about a user than the attacker
Figure 6: Relative frequencies of the top 31 unex-
pected Chrome homepage domains found by ana-
lyzing ∼14 million RAPPOR reports, excluding ex-
pected domains (the homepage “google.com”, etc.).
of the ﬁrst type. Nevertheless, the improvement in her abil-
ity to violate privacy is strictly bounded by the longitudinal
diﬀerential privacy guarantee of ∞. This more powerful at-
tacker may correspond to an adversary such as a malicious
Cloud service employee, who may have temporary access to
reports, or access to a time-bounded log of reports.
The third type of attacker is assumed to have unlimited
collection capabilities and can learn the Permanent random-
ized response B(cid:48) with absolute certainty. Because of the
randomization performed to obtain B(cid:48) from B, she is also
bounded by the privacy guarantee of ∞ and cannot im-
prove upon this bound with more data collection. This cor-
responds to a worst-case adversary, but still one that doesn’t
have direct access to the true data values on the client.
Despite envisioning a completely local privacy model, one
where users themselves release data in a privacy-preserving
fashion, operators of RAPPOR collections, however, can
easily manipulate the process to learn more information than
warranted by the nominal ∞. Soliciting users to partic-
ipate more than once in a particular collection results in
multiple Permanent randomized responses for each user and
partially defeats the beneﬁts of memoization. In the web-
centric world, users use multiple accounts and multiple de-
vices and can unknowingly participate multiple times, re-
leasing more information than what they expected. This
problem could be mitigated to some extent by running col-
lections per account and sharing a common Permanent ran-
domized response. Notice the role of the operator to ensure
that such processes are in place and the required or assumed
trust on the part of the user.
It is likely that some attackers will aim to target speciﬁc
users by isolating and analyzing reports from that user, or a
small group of users that includes them. Even so, some
12345678910111213141516171819202122232425262728293031Figure 7: False Discovery Rate (FDR) as a function
of string frequency and f . Identifying rare strings
in a population without introducing a large num-
ber of false discoveries is infeasible. Also, FDR is
proportional to f .
Figure 8: Exact probabilities for inferring the true
value v given the two bits observed in a RAPPOR
report S corresponding to the two bits set by string
v. For rare strings, even when both bits are set to
1 (green lines), it is still much more likely that the
client did not report v, but some other value.
with probability (cid:0) 1
2 f(cid:1)h, clients will generate a Permanent
randomly-chosen users need not fear such attacks at all:
randomized response B(cid:48) with all 0s at the positions of set
Bloom ﬁlter bits. Since these clients are not contributing any
useful information to the collection process, targeting them
individually by an attacker is counter-productive. An at-
tacker has nothing to learn about this particular user. Also,
for all users, at all times, there is plausible deniability pro-
portional to the fraction of clients providing no information.
In one particular attack scenario, imagine an attacker that
is interested in learning whether a given client has a partic-
ular value v, whose population frequency is known to be
fv. The strongest evidence in support of v comes in the
form of both Bloom ﬁlter bits for v being set in the client’s
report (if two hash functions are used). The attacker can
formulate its target set by selecting all reports with these
two bits set. However, this set will miss some clients with
v and include other clients who did not report v. False dis-
covery rate (FDR) is the proportion of clients in the target
set who reported a value diﬀerent from v. Figure 7 shows
FDR as a function of fv, the frequency of the string v. No-
tably, for relatively rare values, most clients in the target set
will, in fact, have a value that is diﬀerent from v, which will
hopefully deter any would-be attackers.
The main reason for the high FDR rate at low frequencies
fv stems from the limited evidence provided by the observed
bits in support of v. This is clearly illustrated by Figure 8
where the probability that v was reported (1) or not re-
ported (0) by the client is plotted as a function of fv. For
relatively rare strings (those with less than 10% frequency),
even when both bits corresponding to v are set in the report,
the probability of v being reported is much smaller than of
it not being reported. Because the prior probability fv is
so small, a single client’s reports cannot provide suﬃcient
evidence in favor of v.
6.1 Caution and Correlations
Although it advances the state of the art, RAPPOR is not
a panacea, but rather simply a tool that can provide sig-
niﬁcant beneﬁts when used cautiously, and correctly, us-
ing parameters appropriate to its application context. Even
then, RAPPOR should be used only as part of a comprehen-
sive privacy-protection strategy, which should include lim-
ited data retention and other pragmatic processes mentioned
in Section 1.1, and already in use by Cloud operators.
As in previous work on diﬀerential privacy for database
records, RAPPOR provides privacy guarantees for the re-
sponses from individual clients. One of the limitations of
our approach has to do with “leakage” of additional informa-
tion when respondents use several clients that participate in
the same collection event. In the real world, this problem
is mitigated to some extent by intrinsic diﬃculty of linking
diﬀerent clients to the same participant. Similar issues occur
when highly correlated, or even exactly the same, predicates
are collected at the same time. This issue, however, can be
mostly handled with careful collection design.
Such inadvertent correlations can arise in many diﬀerent
ways in RAPPOR applications, in each case possibly lead-
ing to the collection of too much correlated information from
a single client, or user, and a corresponding degradation of
privacy guarantees. Obviously, this may be more likely to
happen if RAPPOR reports are collected, from each client,
on too many diﬀerent client properties. However, it may
0.00.20.40.60.81.0Frequency of string vFDRf = 0.25f = 0.5f = 0.7500.10.20.30.40.50.60.70.80.910.00.20.40.60.81.0Frequency of string vProbability of true value (0 or 1) given observed two bits00.10.20.30.40.50.60.70.80.9111010010also happen in more subtle ways. For example, the number