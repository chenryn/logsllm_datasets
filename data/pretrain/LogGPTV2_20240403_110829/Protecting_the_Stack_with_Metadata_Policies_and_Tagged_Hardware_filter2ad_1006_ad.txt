g
s
c
a
m
o
r
g
f
e
r
4
6
2
h
r
e
m
m
h
m
b
l
d
3
e
i
l
s
e
l
m
u
t
n
a
u
q
b
i
l
f
c
m
c
l
i
m
d
m
a
n
p
p
t
e
n
m
o
h
c
n
e
b
l
r
e
p
g
n
e
s
j
3
x
n
h
p
s
i
l
x
e
p
o
s
p
m
s
u
e
z
n
a
e
m
Fig. 5: Static Authorities overhead
DRAM
PUMPs
Misshandler
Added Instrs
Other
r
a
t
s
a
2
p
z
b
i
s
e
v
a
w
b
I
I
l
a
e
d
s
s
e
m
a
g
M
D
A
s
u
t
c
a
c
D
T
D
F
s
m
e
G
c
c
g
k
m
b
o
g
s
c
a
m
o
r
g
f
e
r
4
6
2
h
r
e
m
m
h
m
b
l
d
3
e
i
l
s
e
l
m
u
t
n
a
u
q
b
i
l
f
c
m
c
l
i
m
d
m
a
n
p
p
t
e
n
m
o
h
c
n
e
b
l
r
e
p
g
n
e
s
j
3
x
n
h
p
s
i
l
x
e
p
o
s
p
m
s
u
e
z
n
a
e
m
Fig. 6: Depth Isolation overhead
VI. OPTIMIZATIONS
In the preceding evaluation section, we show that
the
dominant source of overhead for the stack protection policies
arises from instructions added to tag the stack. Consequently,
to reduce the overhead we focus on techniques that allow us
to reduce or remove the need to add these instructions. Two of
the optimizations we present, Lazy Tagging and Cache Line
Tagging, allow us to speed up the policies without changing
their security properties. The last optimization we present,
Lazy Clearing, explores recasting the policies from memory
safety policies to data-ﬂow integrity [35] policies in order to
remove the instructions that clean up stack memory in the
function epilogue. When using this optimization, we consider
the policies to be fundamentally different and categorize them
separately in our taxonomy (Sec. VII-A).
A. Lazy Tagging
Asymptotically, an unfortunate overhead of the current
policy design is the cost of tagging stack elements that are
allocated but never used. The ratio of used stack frame words
to allocated stack frame words can be arbitrarily small (see
discussion about sjeng in Sec. V-B2). For the stack elements
that are used, the need to tag each with their appropriate frame-
id and object-id means the policies are doubling the stack write
trafﬁc for stack elements that are only written once. Ideally,
we’d like to combine the stack tagging operation with the ﬁrst
program write to the same word to avoid this overhead and
simultaneously avoid tagging unused stack elements.
We can address both of these issues for stack writes with
the Lazy Tagging optimization, in which we allow all stack
pointers to write over EMPTY STACK memory and update
the tag on the memory cell to that of the stack pointer or
instruction when a write occurs. This eliminates the need to tag
stack memory in the function prologue, and so we eliminate
those added instructions. From a security perspective, we are
still assured that stack pointers and instructions are never
used to access claimed (non EMPTY STACK) stack memory
that does not match the frame-id and object-id of the current
instruction and stack pointer. We keep the full cleanup loop
in function epilogues to maintain the invariant that unused
stack frames are marked with EMPTY STACK to allow future
function calls to succeed.
486
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:32:21 UTC from IEEE Xplore.  Restrictions apply. 
A write to the stack beyond the frame’s intended allocation
will not be prevented nor cleaned up, but it will be caught by
a frame-id and object-id mismatch when a later function at-
tempts to use the memory cell. By removing this initialization,
we cut the added instructions roughly in half. When applying
Lazy Tagging, the average overhead for Static Authorities goes
from 11.9% to 8.9% and the average overhead for Depth
Isolation goes from 8.5% to 6.3% (see Figs. 7 and 8).
B. Cache Line Tagging
Next, and independently from Lazy Tagging, we explore
the impact of adding a cache line wide write operation to the
Alpha ISA to perform rapid tagging of memory blocks. We
model a new instruction for this purpose—this is lightweight
to add both for the base datapath and for the metadata rule
cache. Typical cache lines are wider than a single word, and
the cache memory can read or write the entire line in a memory
cycle, so we are exploiting capabilities that the cache already
possesses.
To avoid complicating the SDMP rule checking, we de-
mand all words in the cache line have identical tags for this
instruction to succeed; this assures the same metadata rule
is applicable to every word in the cache line. The SDMP
processor applies the single metadata rule and writes the result
tag to all of the words in the cache line. If any of the tags
on words in the cache line differ, then the instruction instead
fails and the machine falls back by jumping to a displacement
encoded in the instruction that contains the logic for handling
a failure—we model this exception handling code as a series
of store instructions that write a value with the same tag as the
faulting cache line-wide store instruction would have written.
For this optimization, we align all stack frames to cache
lines and model the compiler using the new instruction for
the tagging and clearing of stack memory. While this approach
does not asymptotically remove the burden of stack frame tag-
ging, it provides an 8× speedup in the best case for the 64-byte
cache lines and 8-byte words we assume in our experiments.
This signiﬁcantly reduces the tagging overhead costs for large
stack frames such as those used in sjeng (See Figs. 7 and
8). We show the impact of both using Cache Line Tagging
alone (for both setup and cleanup) and when it is combined
with Lazy Tagging (used just for cleanup). When used alone,
the average overhead for Static Authorities goes from 11.9%
to 7.9% and the average overhead for Depth Isolation goes
from 8.5% to 5.5%. When combined with Lazy Tagging, the
average overhead for Static Authorities goes from 8.9% to
5.7% and the average overhead for Depth Isolation goes from
6.3% to 4.5%.
C. Lazy Clearing
Lazy Tagging removes the need for adding instructions in
the function prologue to claim memory, but it does not remove
the need to clear every allocated word in the epilogue when a
function returns. As a result, the policies are still faced with an
asymptotic overhead when the allocated stack frame size does
not match the actual stack frame usage. Removing the tags
from released stack frames is required by the policies so that
the subsequent functions, which use the same stack memory,
can claim clean cells tagged EMPTY STACK.
In the Lazy Clearing optimization, we remove the tag
cleanup loop in the function epilogue and allow all stack
writes to succeed. This way, future function calls do not
experience violations when they attempt to write over already-
claimed memory. When a write occurs, the memory cell gets
the authority and object (frame-id and object-id) for which
the write is intended. When using this optimization, we only
validate stack reads, which assure that the frame-id and object-
id of the stack word being read matches the intent of the
compiler as encoded in the instructions and pointers used in
the access. Erroneous code can overﬂow buffers and write
indiscriminantly over the stack memory, but the code tagging
rules assure that any violations to the stack abstraction will
be detected by the reading instruction before the corrupted
or unintended data is actually used. Violations that overwrite
data that is never read will not be detected, but that’s precisely
because those violations do not
the result of the
computation since they are not observed. In essence, with
this optimization, our policies provide a data-ﬂow integrity
property instead of a memory safety property.
impact
This change does mean that the tag on a memory cell during
a write can now be uncorrelated to the instruction and stack
pointer performing the write. If we needed to supply rules for
all combinations of instruction tags, stack pointer tags, and
old memory tags, we could end up needing a greater number
of rules than in the eager stack clearing case. However, if we
exploit the ability to indicate that the memory tag is irrelevant
to the rule computation (is a don’t-care), this will not result in
an increase in the number of necessary rules. The don’t-care
feature exists in [17], and it turns out to be quite important to
extracting the beneﬁts of Lazy Clearing for some applications.
While running with the Lazy Clearing optimization, we
discovered several cases in the SPEC2006 benchmarks where
the original C code does use uninitialized data from the stack.
These are errors, and our policy rules correctly ﬂag these errors
as violations. They allow data to ﬂow from an unintended
frame-id and object-id and to be used to effect the computa-
tion. We believe the correct response is to ﬁx these errors in
the original code. To generate a complete and consistent set
of data, we selectively disabled lazy optimizations on just the
functions that were ﬂagged as using uninitialized data.
The impact of Lazy Clearing, which we always combine
with Lazy Tagging, is shown in Figs. 7 and 8. When applied
in addition to Lazy Tagging, the average overhead for Static
Authorities goes from 8.9% to 3.6% and the average overhead
for Depth Isolation goes from 6.3% to 2.4%.
VII. SECURITY CHARACTERIZATION