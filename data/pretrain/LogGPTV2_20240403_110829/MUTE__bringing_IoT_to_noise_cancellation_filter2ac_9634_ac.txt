forcing a strict truncation of the non-causal filter, leaving a
residual error after cancellation.
Algorithm 1 LANC: Lookahead Aware Noise Cancellation
1: while True do
2:
3:
4:
5:
6:
7:
8:
9:
10: end while
Play Œ±(t) at anti-noise speaker
t = t + 1
Record the error e(t) at error mic.
Record future sample x(t + N) at reference mic.
for k = ‚àíN , k ‚â§ L, k + + do
hAF(k) = hAF(k) ‚àí ¬µe(t)hse(t) ‚àó x(t ‚àí k)
end for
Œ±(t) =L
k =‚àíN hAF(k)x(t ‚àí k)
(2) Predictive Sound Profiling
Another opportunity with lookahead pertains to coping with
more complex noise sources, such as human conversation.
Consider a common case where a human is talking intermit-
tently in the presence of background noise ‚Äì Figure 6(a) and
(b) show an example spectrum for speech and background
noise, respectively. Now, to cancel human speech, the adap-
tive filter estimates the channels from the human to the ear
device. However, when the speech pauses, the filter must re-
converge to the channels from the background noise source.
Re-convergence incurs latency since the hAF vector must
again undergo the gradient descent process to stabilize at a
new minimum. Our idea is to leverage lookahead to foresee
this change in sound profile, and swap the filtering coeffi-
cients right after the speech has stopped. Hence, we expect
our cancellation to not fluctuate even for alternating sound
sources, like speech or music.
(cid:4) Validation: Figure 7 explains the problem by illustrating
the convergence of a toy adaptive filter, hAF , with 7 taps.
(1)
Initially, the filter is h
AF , and since this vector is not accurate,
the corresponding error in Figure 7(b) is large. The vector
MUTE: Bringing IoT to Noise Cancellation
SIGCOMM ‚Äô18, August 20‚Äì25, 2018, Budapest, Hungary
Figure 6: Acoustic spectrum in the (a) presence and (b)
absence of speech. LANC recognizes the profile and
pre-loads its filter coefficients for faster convergence.
(2)
AF based on Equation 7, in the direction
then gets updated to h
(2)
that reduces the error. This makes h
AF closer to the ideal filter
and e(t)2 closer to zero. The filter continues to get updated
until the error becomes nearly zero ‚Äì at this point, the filter
is said to have converged, i.e., h
(3)
AF .
Figure 7: Convergence process of the adaptive filter,
hAF . (a) 7-tap hAF filter changes from time (1) to time
(3). (b) residual error e(t) converges to a minimum.
For persistent noise (like machine hum), the converged adap-
tive filter can continue to efficiently cancel the noise, as
shown in Figure 8(a). However, for intermittent speech sig-
nals with random pauses between sentences, the adaptive
filter cannot maintain smooth cancellation as shown in Fig-
ure 8(b). Every time the speech starts, the error is large and
the adaptive filter needs time to (re)converge again.
(cid:4) Predict and Switch: With substantial lookahead, LANC
gets to foresee the start and stop of speech signals. Thus, in-
stead of adapting the filter coefficients every time, we cache
Figure 8: LANC‚Äôs convergence timeline showing adap-
tive filtering with (a) continuous noise, (b) speech,
(c) lookahead aware profiling. LANC converges faster
due to its ability to anticipate profile transitions in ad-
vance.
and h
speech
AF
back–¥round
AF
the coefficient vector for the corresponding sound profiles.
A sound profile is essentially a statistical signature for the
sound source ‚Äì a simple example is the average energy dis-
tribution across frequencies. For 2 profiles ‚Äì say speech and
background noise ‚Äì LANC caches 2 adaptive filter vectors,
speech
, respectively. Then, by analyzing the
h
AF
lookahead buffer in advance, LANC determines if the sound
profile would change imminently. When the profile change
is indeed imminent (say the starting of speech), LANC di-
rectly updates the adaptive filter with h
, avoiding the
overhead of re-convergence.
To generalize, LANC maintains a converged adaptive fil-
ter for each sound profile, and switches between them at
the right time. So long as there is one dominant sound
source at any given time, LANC cancels it quite smoothly
as shown in Figure 8(c). Without lookahead, however, the
profile-change cannot be detected in advance, resulting in
periodic re-convergence and performance fluctuations.
With the LANC algorithm in place, we now turn to bringing
together the overall MUTE system.
4 MUTE: SYSTEM AND ARCHITECTURE
Recall that our basic system requires an IoT relay installed
near the user; the relay listens to the ambience and streams
‚Ñéùê¥ùêπùëíùë°2ùíâùê¥ùêπtaps23112301234567ùíâideal(a) ‚Ñéùê¥ùêπFilter Taps(b) Error vs. ‚Ñéùê¥ùêπSIGCOMM ‚Äô18, August 20‚Äì25, 2018, Budapest, Hungary
S. Shen, N. Roy, J. Guan, H. Hassanieh, and R. Roy Choudhury
the acoustic waveform over its RF interface in real time. The
receiver ‚Äì a hollow earphone ‚Äì receives the sound signal,
applies the LANC algorithm to compute the anti-noise signal,
and finally plays it through the speaker. Several components
have been engineered to achieve a fully functional system.
In the interest of space, we discuss 3 of these components,
namely: (1) the wireless relay hardware, (2) automatic relay
selection, and (3) privacy protection. Finally, as a conclusion
to this section, we envision architectural variants of MUTE
‚Äì such as noise cancellation as a service ‚Äì to demonstrate a
greater potential of our proposal beyond what is presented
in this paper. We begin with wireless relay design.
4.1 Wireless Relay Design
Figure 9 shows the hardware block diagram of the wireless
relay. MUTE embraces an analog design to bypass delays
from digitization and processing. Specifically, the relay con-
sists of a (reference) microphone that captures the ambient
noise signal, passes it through a low pass filter (LPF), and
then amplifies it. An impedance matching circuit connects
the audio signal to an RF VCO (voltage controlled oscillator).
The VCO outputs a frequency modulated (FM) signal, which
is then mixed with a carrier frequency generated by a phase
lock loop (PLL), and up-converted to the 900 MHz ISM band.
The RF signal is then band pass filtered and passed to a power
amplifier connected to a 900 MHz antenna. Thus, with au-
dio signal m(t) captured at the microphone, the transmitted
signal x(t) is:
(cid:18)
(cid:19)
‚à´ t
0
x(t) = Ap cos
2œÄ fct + 2œÄAf
m(œÑ)dœÑ
(9)
where fc is the carrier frequency, Ap is the gain of the RF
amplifier, and Af is the combined gain of the audio amplifier
and FM modulator1.
Figure 9: MUTE‚Äôs RF Relay Design
Why Frequency Modulation (FM)? The significance of
FM is three-fold. First, it delivers better audio quality because
noise mainly affects amplitude, leaving the frequency of the
signal relatively less affected. Second, since the bandwidth
used is narrow, hw(t) is flat in frequency and hence can be
represented with a single tap. As a result, there is no need to
1The receiver in the ear-device applies a reverse set of operations to the
transmitter and outputs digital samples that are then forwarded to the DSP.
estimate the wireless channel since it will not affect the audio
signal m(t). Finally, any carrier frequency offsets between
up-conversion and down-conversion appear as a constant
DC offset in the output of the FM demodulator which can
easily be averaged out. This precludes the need to explicitly
compensate for carrier frequency offset (CFO).
4.2 Automatic Relay Selection
MUTE is effective only when the wireless relay is located
closer to the sound source than the earphone. This holds
in scenarios such as Figure 1 ‚Äì the relay on Alice‚Äôs door is
indeed closer to the noisy corridor. However, if the sound
arrives from an opposite direction (say from a window), the
relay will sense the sound after the earphone. Even though
the relay forwards this sound, the earphone should not use
it since the lookahead is negative now (i.e., the wirelessly-
forwarded sound is lagging behind). Clearly, MUTE must
discriminate between positive and negative lookahead, and
in case of the latter, perhaps nudge the user to reposition the
relay in the rough direction of the sound source.
(cid:4) How to determine positive lookahead? MUTE uses
the GCC-PHAT cross-correlation technique [21]. The DSP
processor periodically correlates the wirelessly-forwarded
sound against the signal from its error microphone. The time
of correlation‚Äìspike tells whether the lookahead is positive
or negative. When positive, the LANC algorithm is invoked.
Correlation is performed periodically to handle the possibil-
ity that the sound source has moved to another location.
(cid:4) Multiple Relays: Observe that a user could place multiple
relays around her to avoid manually repositioning the relay
in the direction of the noise source. The correlation technique
would still apply seamlessly in such a scenario. The relay
whose correlation spike is most shifted in time is the one
MUTE would pick. This relay would offer the maximum
lookahead, hence the best cancellation advantage.
4.3 Architectural Variants
The basic architecture thus far is a wireless IoT relay (closer
to the sound source) communicating to an ear-device around
the human ear. We briefly sketch a few variants of this ar-
chitecture aimed at different trade-offs and applications.
1. Personal TableTop: MUTE removes the reference micro-
phone from the headphone, which in turn eliminates the
noise-absorbing material. As mentioned earlier, this makes
the ear-device light and hollow. Following this line of rea-
soning, one could ask what else could be stripped off from
the ear-device. We observe that even the DSP can be ex-
tracted and inserted into the IoT relay. In other words, the
IoT relay could compute the anti-noise and wirelessly trans-
mit to the ear-device; the ear-device could play it through
LPFAmplifierBPFPAVCOPLLMixerAudio to RFMatching CircuitFM ModulatorMUTE: Bringing IoT to Noise Cancellation
SIGCOMM ‚Äô18, August 20‚Äì25, 2018, Budapest, Hungary
Figure 10: Architectural variants: (a) Personal tabletop device includes DSP and reference microphone; sends anti-
noise signal to ear-device, which responds with error signal. (b) Noise cancellation as a edge service: the DSP server
is connected to IoT relays on the ceiling and computes the anti-noise for all users. (c) Smart noise, where noise
sources attach a IoT relay while users with MUTE ear-devices benefit.
the anti-noise speaker, and transmit back the error signal
from its error microphone. Observe that the IoT relay can
even become a portable table-top device, with the ear-device
as a simple ‚Äúclient‚Äù. The user can now carry her personal
MUTE tabletop relay (Figure 10(a)), eliminating dependen-
cies on door or wall mounted infrastructure.
2. Public Edge Service: Another organization is to move the
DSP to a backend server, and connect multiple IoT relays
to it, enabling a MUTE public service (Figure 10(b)). The
DSP processor can compute the anti-noise for each user and
send it over RF. If computation becomes the bottleneck with
multiple users, perhaps the server could be upgraded with
multiple-DSP cores. The broader vision is an edge cloud
[47] that offers acoustic services to places like call centers.
3. Smart Noise: A third architecture could be to attach IoT
relays to noise sources themselves (and eliminate the relays
on doors or ceilings). Thus, heavy machines in construction
sites, festive public speakers, or lawn mowers, could broad-
cast their own sound over RF. Those disturbed by these
noises can wear the MUTE ear-device, including the DSP.
Given the maximal lookahead, high quality cancellation
should be feasible.
We conclude by observing that the above ideas may be
viewed as a ‚Äúdisaggregation‚Äù of conventional headphones,
enabling new future-facing possibilities. This paper is an
early step in that direction.
4.4 Privacy Awareness
Two relevant questions emerge around privacy:
(cid:4) Will the IoT relay record ambient sounds and con-
versations? We emphasize that the relays are analog and
not designed to even hold the acoustic samples. The mi-
crophone‚Äôs output is directly applied to modulate the 900
MHz carrier signal with no recording whatsoever. In this
sense, MUTE is different from Amazon Echo, Google Home,
and wireless cameras that must record digital samples for
processing.