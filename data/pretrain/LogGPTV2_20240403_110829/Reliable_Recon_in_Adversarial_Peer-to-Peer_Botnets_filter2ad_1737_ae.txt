### Internet-Wide Scanning for P2P Botnet Node Discovery

Internet-wide scanning can be an efficient approach to node discovery in P2P botnets, but it does not generalize well to all protocols. This limitation is due to several factors:

1. **Port Range and Intrusiveness**: Many P2P botnets use a large port range, where each bot listens on only a single port within this range. For example, Zeus bots choose ports in the range 1024-10000 [2]. This makes Internet-wide scanning intrusive and inefficient, as thousands of ports must be scanned per host. In contrast, ZeroAccess operates on a single fixed port (depending on the version) [25, 36], making it a feasible target for Internet-wide scanning.

2. **Encryption and Node ID Dependency**: Some botnets, like Zeus, use a different encryption key for packets destined to each bot, based on the node ID of the receiving bot. This makes it impossible to probe bots without prior knowledge of their node ID. Consequently, Internet-wide scanning is inherently incompatible with botnets like Gameover Zeus, which employ this tactic.

3. **Non-Routable Nodes**: Similar to crawling, Internet-wide scanning cannot detect non-routable nodes hidden behind firewalls or NAT gateways.

Table 5 summarizes the susceptibility of major P2P botnets active since 2007 to Internet-wide scanning [28]. Two prerequisites for effective Internet-wide scanning in P2P botnet reconnaissance are:
1. The bot protocol must run on a known port (or a small port range).
2. It must be possible to construct a probe message to determine if a host is infected.

As shown in Table 5, only two of the analyzed botnets, ZeroAccess and Kelihos, run on a sufficiently small port range. Probe construction is possible for all botnets except Zeus, which requires prior knowledge of the node ID to contact a bot. These results indicate that Internet-wide scanning is not a full-fledged alternative to crawling or sensor injection. Additionally, there are significant scalability issues in very large address spaces like IPv6, which is expected to become ubiquitous soon. However, for susceptible P2P botnets in IPv4 networks, Internet-wide scanning remains a valid reconnaissance option when no bootstrap peer list is available for crawling.

### Discussion

This section discusses the trade-offs of various P2P botnet reconnaissance methods, considering their stealthiness and coverage. Table 6 summarizes these trade-offs and characteristics.

#### 8.1 Automating Protocol Logic Extraction

Current crawlers and sensors have protocol-specific shortcomings that make them easy to detect. Protocol-adherent recon tools require more implementation effort. To reduce this, part of the botnet protocol state machine can be extracted from bot samples using tools like Inspector Gadget [21]. This leaves only specific message types, such as peer list requests and responses, in need of special handling and manual implementation.

#### 8.2 Crawling vs. Sensor Injection

To detect syntactically sound reconnaissance implementations, botmasters must rely on semantic anomalies such as in-degree or out-degree fluctuations. Our results show that crawlers are more prone to this than sensors, as they aim to contact most of the bot population. High in-degrees are common in legitimate super-peers, making them less effective for detecting sensors. Therefore, sensors are a more naturally stealthy reconnaissance method. Properly announced sensors can also serve as launchpads for more invasive takedown efforts, such as sinkholing [28]. Data gathered by sensors is useful for mapping infected IPs for subsequent cleanup actions, especially since sensors can find 60–87% of NATed hosts [28].

On the downside, sensors cannot gather data about the edges between bot nodes, which is crucial for determining which peer list entries to poison in sinkholing attacks [28]. While it is possible to augment sensors with active peer list requests to gather edge data, this effectively adds a crawling component, requiring defenses against out-degree-based detection.

#### 8.3 Stealthy Crawling Strategies

In Section 6, we evaluated multiple stealthy crawling strategies. Individual crawlers that limit the contact ratio or restrict request frequency have reduced network coverage. A more promising method is distributed crawling, which can be implemented relatively easily given a large network address block (at least a /16 for the botnets we studied). Distributed crawling has no negative impact on coverage. However, it remains an open problem whether detection techniques for distributed network scanning generalize to distributed crawling [16]. Additionally, to prevent request frequency-based detection, crawlers must limit the per-address request rate, reducing network coverage. Coverage can be improved by running multiple rate-limited crawlers in parallel, each with a different node ID, effectively masquerading as a set of bots behind a NAT gateway.

#### 8.4 Internet-Wide Scanning

We investigated Internet-wide scanning as a reconnaissance alternative in Section 7 and found it unsuitable as a generic strategy. Its feasibility depends on the port range, bot protocol, and IP address space (IPv4 vs. IPv6) used by the target botnet. Moreover, Internet-wide scanning from a limited address range is prone to IP-based detection. The nature of Internet-wide scanning is to quickly cover large network blocks with lightweight probes. Implementing a full bot protocol defeats the simplicity of this method, meaning scanners do not behave like normal bots. Therefore, Internet-wide scanning should be used only as a one-time measure to bootstrap conventional crawling if no bootstrap peer list is available. We stress that Internet-wide scanning of botnets should be used with extreme care, as it may trigger IDS signatures even in uninfected networks. Unlike crawling, Internet-wide scanning cannot gather edge data and cannot find non-routable bots.

#### 8.5 Backbone-Based Sensors

An orthogonal approach uses sensors placed on Internet backbone systems. Given access to such systems and a suitable signature for a particular family of bot traffic, this allows for completely passive botnet reconnaissance, which cannot be detected or blocked by botmasters. While potentially highly efficient, this method requires the cooperation of backbone operators. Moreover, completely passive detection may be difficult for botnets like GameOver Zeus, which take active measures to thwart signature-based detection systems and encrypt traffic using destination-based keys.

### Related Work

To the best of our knowledge, our work is the first systematic study of anti-recon in P2P botnets. Prior work has hardened theoretical P2P botnets against recon and provided anecdotal evidence of anti-recon in practice. Our work expands on these results to provide a more complete picture of anti-recon and how to overcome it.

Early experiments with crawler-based node enumeration in P2P botnets were performed by Holz et al. in the Storm botnet [13]. At the same time, passive crawling inaccuracies due to address aliasing, firewalls, NAT gateways, and churn were studied by Rajab et al. [27] and Kanich et al. [17]. Recent work has compared the completeness and accuracy of sensors to crawlers in P2P botnets, showing that sensors can discover up to two orders of magnitude more peers while verifying their authenticity [28, 15]. Technical reports on specific P2P botnets have presented evidence of anti-recon in the wild [10, 25, 35, 19, 6, 13, 34, 33, 2, 4].

Our work systematizes this anecdotal evidence and performs the first in-depth study of the susceptibility of current and future recon tools to active disruption. Theoretical work has proposed botnet protocols that complicate crawling, such as proof-of-work schemes [14] and asymmetrically encrypted bot IDs [32]. These methods cannot be directly applied to current botnets and require complex and radically different P2P protocols.

Sarat et al. [30] detect sensors with faulty protocol implementations in structured P2P networks but do not investigate crawlers or protocol-agnostic anti-recon. Our work studies protocol-specific weaknesses in both crawlers and sensors, as well as protocol-agnostic crawler detection. Moreover, we evaluate improved recon strategies in practice.

Karuppayah et al. [18] propose reducing the set of crawled nodes by approximating a minimum vertex cover of the botnet graph. However, their results are based on simulations of Zeus, assuming all bots are simultaneously reachable and peer lists can be fully retrieved with a small number of requests. Our non-simulated observations show that Zeus crawling coverage decreases rapidly as the set of crawled nodes is reduced.

### Conclusion

We have systematically analyzed anti-recon in P2P botnets, showing that current botnets already take active measures to discourage and retaliate against crawlers and sensors, and that future recon tools are at risk of more invasive attacks. Current recon tools suffer from numerous shortcomings, significantly increasing their susceptibility to subversion. Crawlers are especially prone to protocol-agnostic detection due to their tendency for out-degree explosion. We have investigated several stealthier crawling strategies, with distributed crawling being the most promising—it does not negatively impact crawling coverage and is straightforward to implement given a large network address block. Alternatively, sensor injection supports node verification and improved network coverage, and can be augmented with graph connectivity information.

### Acknowledgements

This work was supported by the European Research Council through project ERC-2010-StG 259108 “Rosetta.” We also thank the anonymous reviewers for their insightful comments, which helped improve this work.

### References

[1] D. Andriesse, C. Rossow, and H. Bos. Distributed Crawler Detection in Peer-to-Peer Botnets, 2015. http://www.few.vu.nl/~da.andriesse/papers/imc-2015-addendum.pdf.
[2] D. Andriesse, C. Rossow, B. Stone-Gross, D. Plohmann, and H. Bos. Highly Resilient Peer-to-Peer Botnets Are Here: An Analysis of Gameover Zeus. In MALWARE’13, 2013.
[3] Brian Krebs. Operation Tovar Targets GameOver Zeus, CryptoLocker, 2014. http://krebsonsecurity.com/2014/06/operation-tovar-targets-gameover-zeus-botnet-cryptolocker-scourge/.
[4] CERT.pl. Zeus P2P Monitoring and Analysis, 2013. Tech report. http://www.cert.pl/PDF/2013-06-p2p-rap_en.pdf.
[5] CrowdStrike. GameOver Zeus and CryptoLocker Takedown, 2014. Tech report. http://www.crowdstrike.com/blog/gameover/index.html.
[6] C. Davis, J. Fernandez, S. Neville, and J. McHugh. Sybil Attacks as a Mitigation Strategy Against the Storm Botnet. In MALWARE’08, 2008.
[7] J. Dinger and H. Hartenstein. Defending the Sybil Attack in P2P Networks: Taxonomy, Challenges, and a Proposal for Self-Registration. In ARES’06, 2006.
[8] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The Second-Generation Onion Router. In USENIX Sec’04, 2004.
[9] Z. Durumeric, E. Wustrow, and J. A. Halderman. ZMap: Fast Internet-Wide Scanning and its Security Applications. In USENIX Sec’13, 2013.
[10] N. Falliere. Sality: Story of a Peer-to-Peer Viral Network, 2011. Tech report, Symantec.
[11] M. Garnaeva. Kelihos/Hlux Botnet Returns with New Techniques, 2012. Tech report, SecureList. http://securelist.com/blog/virus-watch/32021/.
[12] Hide My Ass. List of Proxy Addresses. https://www.hidemyass.com/proxy-list/.
[13] T. Holz, M. Steiner, F. Dahl, E. Biersack, and F. Freiling. Measurements and Mitigation of Peer-to-Peer-based Botnets: A Case Study on Storm Worm. In LEET’08, 2008.
[14] R. Hund, M. Hamann, and T. Holz. Towards Next-Generation Botnets. In EC2ND’08, 2008.
[15] B. B. H. Kang, E. Chan-Tin, C. P. Lee, J. Tyra, H. J. Kang, C. Nunnery, Z. Wadler, G. Sinclair, N. Hopper, D. Dagon, and Y. Kim. Towards Complete Node Enumeration in a Peer-to-Peer Botnet. In ASIACCS’09, 2009.
[16] M. G. Kang, J. Caballero, and D. Song. Distributed Evasive Scan Techniques and Countermeasures. In DIMVA’07, 2007.
[17] C. Kanich, K. Levchenko, B. Enright, G. M. Voelker, and S. Savage. The Heisenbot Uncertainty Problem: Challenges in Separating Bots from Chaff. In LEET’08, 2008.
[18] S. Karuppayah, M. Fischer, C. Rossow, and M. Mühlehauser. On Advanced Monitoring in Resilient and Unstructured P2P Botnets. In ICC’14, 2014.
[19] Kaspersky Lab. How Kaspersky Lab and CrowdStrike Dismantled the Hlux Botnet: Success Story, 2012. http://newsroom.kaspersky.eu/en/texts/detail/article/how-kaspersky-lab-and-crowdstrike-dismantled-the-second-hluxkelihos-botnet-success-story/.
[20] P. Kleissner. Me Puppet Master: Behind the Scenes of Crawling P2P Botnets, 2014. Tech report. http://blog.kleissner.org/?p=455.
[21] C. Kolbitsch, T. Holz, C. Kruegel, and E. Kirda. Inspector Gadget: Automated Extraction of Proprietary Gadgets from Malware Binaries. In S&P’10, 2010.
[22] Microsoft Digital Crimes Unit. Microsoft, the FBI, Europol and industry partners disrupt the notorious ZeroAccess botnet, 2013. http://www.microsoft.com/en-us/news/press/2013/dec13/12-05zeroaccessbotnetpr.aspx.
[23] S. Murdoch and G. Danezis. Low-Cost Traffic Analysis of Tor. In S&P’05, 2005.
[24] A. Nappa, Z. Xu, J. Caballero, and G. Gu. CyberProbe: Towards Internet-Scale Active Detection of Malicious Servers. In NDSS’14, 2014.
[25] A. Neville and R. Gibb. ZeroAccess In-Depth, 2013. Tech report, Symantec.
[26] A. Panchenko, L. Pimenidis, and J. Renner. Performance Analysis of Anonymous Communication Channels Provided by Tor. In ARES’08, 2008.
[27] M. A. Rajab, J. Zarfoss, F. Monrose, and A. Terzis. My Botnet is Bigger Than Yours (Maybe, Better Than Yours): Why Size Estimates Remain Challenging. In HotBots’07, 2007.
[28] C. Rossow, D. Andriesse, T. Werner, B. Stone-Gross, D. Plohmann, C. Dietrich, and H. Bos. P2PWNED: Modeling and Evaluating the Resilience of Peer-to-Peer Botnets. In S&P’13, 2013.
[29] H. Rowaihy, W. Enck, P. McDaniel, and T. la Porta. Limiting Sybil Attacks in Structured P2P Networks. In INFOCOM’07, 2007.
[30] S. Sarat and A. Terzis. On Tracking Peer-to-Peer Botnets. In LEET’08, 2008.
[31] SIDN. AbuseHUB Launched to Tackle Botnets, 2013. https://www.sidn.nl/en/news/news/article/abusehub-van-start-botnets-aangepakt-1/.
[32] G. Starnberger, C. Kruegel, and E. Kirda. Overbot: A Botnet Protocol Based on Kademlia. In SecureComm’08, 2008.
[33] B. Stock, M. Engelberth, F. C. Freiling, and T. Holz. Walowdac – Analysis of a Peer-to-Peer Botnet. In EC2ND’09, 2009.
[34] G. Tenebro. W32.Waledac Threat Analysis, 2009. Tech report, Symantec.
[35] T. Werner. Botnet Shutdown Success Story: How Kaspersky Lab Disabled the Hlux/Kelihos Botnet, 2011. Tech report, Kaspersky Lab. http://www.securelist.com/en/blog/208193137/.
[36] J. Wyke. ZeroAccess, 2012. Tech report, SophosLabs.
[37] G. Yan, S. Chen, and S. Eidenbenz. RatBot: Anti-Enumeration Peer-to-Peer Botnets. In Lecture Notes in Computer Science, vol. 7001, 2011.