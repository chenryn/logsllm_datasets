Internet-wide scanning can be an eﬃcient approach to
node discovery in P2P botnets, but unfortunately it does not
generalize well to all protocols. This is due to several factors.
(1) Many P2P botnets use a large port range, where each bot
listens on only a single port from this range. For instance,
Zeus bots choose ports in the range 1024-10000 [2]. This
makes Internet-wide scanning intrusive and ineﬃcient, as
thousands of ports must be scanned per host. Internet-wide
scanning is a feasible reconnaissance method for ZeroAccess
only because it runs on a single ﬁxed port (depending on
the version) [25, 36]. (2) Some botnets, like Zeus, use a
diﬀerent encryption key for packets destined to each bot,
based on the node ID of the receiving bot. This makes it
impossible to probe bots without a-priori knowledge of their
node ID. Consequently, Internet-wide scanning is inherently
incompatible with botnets like Gameover Zeus which use
this tactic. (3) Like crawling, Internet-wide scanning cannot
learn about non-routable nodes that remain hidden behind
a ﬁrewall or NAT gateway.
Table 5 summarizes the susceptibility of all major P2P
botnets active since 2007 to Internet-wide scanning [28]. We
consider two prerequisites for Internet-wide scanning in P2P
botnet reconnaissance: (1) the bot protocol must run on a
known port (or small port range), and (2) it must be possible
to construct a probe message to determine if a host is infected
or not. As shown in Table 5, only two of the analyzed botnets
run on a suﬃciently small port range, namely ZeroAccess and
Kelihos. Probe construction is possible for all botnets, except
Zeus, which requires a-priori knowledge of the node ID in
order to contact a bot. These results show that Internet-wide
scanning is not a full-ﬂedged alternative to crawling or sensor
injection. Moreover, there are serious scalability issues in
very large address spaces like IPv6, which is expected to
become ubiquitous within a relatively short timeframe. Still,
for susceptible P2P botnets in IPv4 networks, Internet-wide
scanning is a valid recon alternative if no bootstrap peer list
is available for crawling.
8. DISCUSSION
This section discusses tradeoﬀs of the various P2P botnet
reconnaissance methods, given the stealthiness and coverage
of the various alternatives as studied in this paper. We
summarize tradeoﬀs and recon characteristics in Table 6.
8.1 Automating Protocol Logic Extraction
Current crawlers and sensors have many protocol-speciﬁc
shortcomings which make them very easy to detect. On the
other hand, protocol-adherent recon tools inherently require
more implementation eﬀort. To reduce this implementation
eﬀort, part of the botnet protocol state machine can be
extracted from bot samples using tools like Inspector Gad-
get [21]. This leaves only particular message types, such as
peer list requests and responses, in need of special handling
and manual implementation.
8.2 Crawling vs. Sensor Injection
To detect syntactically sound reconnaissance implemen-
tations, botmasters must rely on semantic anomalies such
as in-degree or out-degree ﬂuctuations. Our results have
shown that crawlers are inherently more prone to this than
sensors, as they strive to actively contact all or most of the
bot population. At the same time, high in-degrees are not
uncommon in legitimate super-peers, and are thus not an
eﬀective metric for detecting sensors. This means that sen-
sors are a more naturally stealthy reconnaissance method
than crawlers. Moreover, properly announced sensors can
be used as a launchpad for more invasive botnet takedown
eﬀorts, for instance by serving as sinkholes [28]. Data gath-
ered by sensors also lends itself well to mapping infected IPs
for subsequent cleanup actions. This applies even more to
sensors than crawling and Internet-wide scanning, as sensors
can ﬁnd the expected 60–87% of NATed hosts [28].
On the downside, sensors cannot gather data about the
edges between bot nodes. As shown in Table 6, this data
can only be gathered by crawlers.
In sinkholing attacks,
edge data is crucial in determining which peer list entries
to poison [28]. While it is possible to augment sensors with
active peer list requests to gather edge data, this eﬀectively
adds a crawling component to them. Thus, both dedicated
crawlers and augmented sensors require defenses against
out-degree-based detection.
8.3 Stealthy Crawling Strategies
In Section 6, we have evaluated multiple stealthy crawl-
ing strategies in the wild. As we have shown, individual
crawlers which limit the contact ratio or restrict the request
frequency have a strongly reduced network coverage. A more
promising method is distributed crawling. Given a large
network address block (at least a /16 for the botnets we
studied), or several smaller blocks, it is relatively painless to
implement, and has no negative impact on crawling coverage.
A possible caveat is that it is still an open problem to deter-
mine whether detection techniques for distributed network
scanning generalize to distributed crawling [16]. Addition-
ally, to prevent request frequency-based detection, crawlers
must limit the per-address request rate, reducing network
coverage. Coverage can be improved by running multiple
rate-limited crawlers in parallel (each with a diﬀerent node
ID, if applicable), eﬀectively masquerading as a set of bots
behind a NAT gateway.
8.4 Internet-Wide Scanning
We have also investigated Internet-wide scanning as a re-
connaissance alternative in Section 7, and found it unsuitable
as a generic reconnaissance strategy. Whether or not it can
be used depends on the port range, bot protocol, and IP
address space (i.e., IPv4 vs. IPv6) used by the target botnet.
Moreover, Internet-wide scanning from a limited address
range is prone to IP-based detection. The nature of Internet-
wide scanning is to quickly cover large network blocks by
sending stand-alone lightweight probes. Implementing a full
bot protocol makes no sense, as this defeats the simplicity of
Internet-wide scanning. This means that scanners inherently
do not behave like normal bots. Therefore, Internet-wide
138Method
Crawling
Sensor
injection
Internet-wide
scanning
Generic Mapping Attacks
Stealth strategies
Advantages
Disadvantages
✓
✓
✗
Edges
I, P, S
• Protocol adherence
• Address distribution
• Rate limiting
Nodes
I, P, S
• Protocol adherence
• Announcement rate limiting
Nodes
I
• Sound probe syntax
• Address distribution
• One-time usage
• Find edges
• Fast deployment
• Cannot ﬁnd NATed nodes
• Need out-degree limiting
• Find NATed nodes
• Support sinkholing
• Node veriﬁcation
• Fast deployment
• No bootstrap list
• Cannot ﬁnd edge data
• Need announcements
• Cannot ﬁnd NATed nodes
• Cannot ﬁnd edge data
• Not generic
• Only probes
Table 6: Tradeoﬀs of P2P botnet reconnaissance methods. Attacks: I = Infection reporting, P = Partitioning, S = Sinkholing.
scanning should be used only as a one-time measure, to boot-
strap conventional crawling if no bootstrap peer list can be
obtained. We stress that Internet-wide scanning of botnets
should be used with extreme care, as by emulating the botnet
protocol it may trigger IDS signatures even in uninfected
networks. Unlike crawling, Internet-wide scanning cannot
gather edge data, and it also cannot ﬁnd non-routable bots.
8.5 Backbone-Based Sensors
An approach orthogonal to the recon methods we have
studied uses sensors placed on Internet backbone systems.
Given access to such systems and a suitable signature for
a particular family of bot traﬃc, this allows for completely
passive botnet recon, which cannot be detected or blocked
by botmasters. While potentially highly eﬃcient, an obvi-
ous caveat is that this method requires the cooperation of
backbone operators. Moreover, completely passive detection
may be diﬃcult for botnets like GameOver Zeus, which take
active measures to thwart signature-based detection systems
and encrypt traﬃc using destination-based keys.
9. RELATED WORK
To the best of our knowledge, our work is the ﬁrst sys-
tematic study of anti-recon in P2P botnets. Prior work has
hardened theoretical P2P botnets against recon, and pro-
vided anecdotal evidence of anti-recon in practice. Our work
expands on these results to provide a more complete picture
of anti-recon, and how to overcome it.
Early experiments with crawler-based node enumeration in
P2P botnets were performed by Holz et al. in the Storm bot-
net [13]. At the same time, passive crawling inaccuracies due
to address aliasing, ﬁrewalls, NAT gateways and churn were
studied by Rajab et al. [27] and Kanich et al. [17]. Recent
work has studied the completeness and accuracy of sensors
compared to crawlers in P2P botnets, showing that sensors
can discover up to two orders of magnitude more peers, while
also verifying their authenticity [28, 15]. Additionally, techni-
cal reports on speciﬁc P2P botnets have presented evidence
of anti-recon in the wild [10, 25, 35, 19, 6, 13, 34, 33, 2, 4].
Our work systematizes this anecdotal evidence, and performs
the ﬁrst in-depth study of the susceptibility of current and
future recon tools to active disruption.
Theoretical work has studied the design of botnet proto-
cols which inherently complicate crawling. Such designs were
proposed by Hund et al. [14], who use proof-of-work schemes
to prevent eﬃcient crawling, and by Starnberger et al., who
use asymetrically encrypted bot IDs to prevent node discov-
ery [32]. Additionally, Yan et al. propose a botnet design
which spreads disinformation to thwart crawlers [37]. These
methods cannot be directly applied to current botnets, and
require botmasters to implement complex and radically dif-
ferent P2P protocols. Moreover, the approach of Starnberger
et al. hides bots within legitimate P2P networks which bot-
masters cannot control. To the best of our knowledge, there
are currently no real-world botnets implementing these or
similar designs.
Sarat et al. detect sensors with faulty protocol implementa-
tions in structured P2P networks [30], but do not investigate
crawlers or protocol-agnostic anti-recon. Our work studies
protocol-speciﬁc weaknesses in both crawlers and sensors,
as well as protocol-agnostic crawler detection. Moreover, in
contrast to prior work, we evaluate improved recon strategies
in practice.
Karuppayah et al. propose to reduce the set of crawled
nodes by approximating a minimum vertex cover of the
botnet graph [18]. However, their results are based on simu-
lations of Zeus which assume that all bots are simultaneously
reachable, peer lists can be fully retrieved using only a small
number of requests, and peer addresses are distributed rel-
atively uniformly over the peer lists. In contrast, our own
experience based on non-simulated observations is that Zeus
crawling coverage decreases rapidly as the set of crawled
nodes is reduced (as it would be in a minimum vertex cover).
10. CONCLUSION
We have systematically analyzed anti-recon in P2P botnets,
showing that current botnets already take active measures
to discourage and retaliate against crawlers and sensors, and
that future recon tools are at risk of more invasive attacks.
Moreover, we have shown that current recon tools suﬀer from
a myriad of shortcomings, which signiﬁcantly increase their
susceptibility to subversion. Crawlers are especially prone to
protocol-agnostic detection, due to their tendency for out-
degree explosion. We have investigated several stealthier
crawling strategies, of which distributed crawling is the most
promising — it does not negatively impact crawling coverage,
and is straightforward to implement given a large network
address block. Alternatively, sensor injection supports node
veriﬁcation and improved network coverage, and can be
augmented with graph connectivity information.
Acknowledgements
This work was supported by the European Research Council
through project ERC-2010-StG 259108 “Rosetta”. We also
thank the anonymous reviewers for their insightful comments,
which helped improve this work.
13911. REFERENCES
[1] D. Andriesse, C. Rossow, and H. Bos. Distributed
Crawler Detection in Peer-to-Peer Botnets, 2015.
http://www.few.vu.nl/~da.andriesse/papers/imc-
2015-addendum.pdf.
[2] D. Andriesse, C. Rossow, B. Stone-Gross,
D. Plohmann, and H. Bos. Highly Resilient
Peer-to-Peer Botnets Are Here: An Analysis of
Gameover Zeus. In MALWARE’13, 2013.
[3] Brian Krebs. Operation Tovar Targets GameOver Zeus,
CryptoLocker, 2014.
http://krebsonsecurity.com/2014/06/operation-
tovar-targets-gameover-zeus-botnet-
cryptolocker-scourge/.
[4] CERT.pl. Zeus P2P Monitoring and Analysis, 2013.
Tech report.
http://www.cert.pl/PDF/2013-06-p2p-rap_en.pdf.
[5] CrowdStrike. GameOver Zeus and CryptoLocker
Takedown, 2014. Tech report. http:
//www.crowdstrike.com/blog/gameover/index.html.
[6] C. Davis, J. Fernandez, S. Neville, and J. McHugh.
Sybil Attacks as a Mitigation Strategy Against the
Storm Botnet. In MALWARE’08, 2008.
[7] J. Dinger and H. Hartenstein. Defending the Sybil
Attack in P2P Networks: Taxonomy, Challenges, and a
Proposal for Self-Registration. In ARES’06, 2006.
[8] R. Dingledine, N. Mathewson, and P. Syverson. Tor:
The Second-Generation Onion Router. In USENIX
Sec’04, 2004.
[9] Z. Durumeric, E. Wustrow, and J. A. Halderman.
ZMap: Fast Internet-Wide Scanning and its Security
Applications. In USENIX Sec’13, 2013.
[10] N. Falliere. Sality: Story of a Peer-to-Peer Viral
Network, 2011. Tech report, Symantec.
[11] M. Garnaeva. Kelihos/Hlux Botnet Returns with New
Techniques, 2012. Tech report, SecureList.
http://securelist.com/blog/virus-watch/32021/.
[12] Hide My Ass. List of Proxy Addresses.
https://www.hidemyass.com/proxy-list/.
[13] T. Holz, M. Steiner, F. Dahl, E. Biersack, and
F. Freiling. Measurements and Mitigation of
Peer-to-Peer-based Botnets: A Case Study on Storm
Worm. In LEET’08, 2008.
[14] R. Hund, M. Hamann, and T. Holz. Towards
Next-Generation Botnets. In EC2ND’08, 2008.
[15] B. B. H. Kang, E. Chan-Tin, C. P. Lee, J. Tyra, H. J.
Kang, C. Nunnery, Z. Wadler, G. Sinclair, N. Hopper,
D. Dagon, and Y. Kim. Towards Complete Node
Enumeration in a Peer-to-Peer Botnet. In ASIACCS’09,
2009.
[16] M. G. Kang, J. Caballero, and D. Song. Distributed
Evasive Scan Techniques and Countermeasures. In
DIMVA’07, 2007.
[17] C. Kanich, K. Levchenko, B. Enright, G. M. Voelker,
and S. Savage. The Heisenbot Uncertainty Problem:
Challenges in Separating Bots from Chaﬀ. In LEET’08,
2008.
[18] S. Karuppayah, M. Fischer, C. Rossow, and
M. M¨uhlh¨auser. On Advanced Monitoring in Resilient
and Unstructured P2P Botnets. In ICC’14, 2014.
[19] Kaspersky Lab. How Kaspersky Lab and CrowdStrike
Dismantled the Hlux Botnet: Success Story, 2012.
http://newsroom.kaspersky.eu/en/texts/detail/
article/how-kaspersky-lab-and-crowdstrike-
dismantled-the-second-hluxkelihos-botnet-
success-story/.
[20] P. Kleissner. Me Puppet Master: Behind the Scenes of
Crawling P2P Botnets, 2014. Tech report.
http://blog.kleissner.org/?p=455.
[21] C. Kolbitsch, T. Holz, C. Kruegel, and E. Kirda.
Inspector Gadget: Automated Extraction of
Proprietary Gadgets from Malware Binaries. In
S&P’10, 2010.
[22] Microsoft Digital Crimes Unit. Microsoft, the FBI,
Europol and industry partners disrupt the notorious
ZeroAccess botnet, 2013.
http://www.microsoft.com/en-us/news/press/
2013/dec13/12-05zeroaccessbotnetpr.aspx.
[23] S. Murdoch and G. Danezis. Low-Cost Traﬃc Analysis
of Tor. In S&P’05, 2005.
[24] A. Nappa, Z. Xu, J. Caballero, and G. Gu.
CyberProbe: Towards Internet-Scale Active Detection
of Malicious Servers. In NDSS’14, 2014.
[25] A. Neville and R. Gibb. ZeroAccess In-Depth, 2013.
Tech report, Symantec.
[26] A. Panchenko, L. Pimenidis, and J. Renner.
Performance Analysis of Anonymous Communication
Channels Provided by Tor. In ARES’08, 2008.
[27] M. A. Rajab, J. Zarfoss, F. Monrose, and A. Terzis. My
Botnet is Bigger Than Yours (Maybe, Better Than
Yours): Why Size Estimates Remain Challenging. In
HotBots’07, 2007.
[28] C. Rossow, D. Andriesse, T. Werner, B. Stone-Gross,
D. Plohmann, C. Dietrich, and H. Bos. P2PWNED:
Modeling and Evaluating the Resilience of Peer-to-Peer
Botnets. In S&P’13, 2013.
[29] H. Rowaihy, W. Enck, P. McDaniel, and T. la Porta.
Limiting Sybil Attacks in Structured P2P Networks. In
INFOCOM’07, 2007.
[30] S. Sarat and A. Terzis. On Tracking Peer-to-Peer
Botnets. In LEET’08, 2008.
[31] SIDN. AbuseHUB Launched to Tackle Botnets, 2013.
https://www.sidn.nl/en/news/news/article/
abusehub-van-start-botnets-aangepakt-1/.
[32] G. Starnberger, C. Kruegel, and E. Kirda. Overbot: A
Botnet Protocol Based on Kademlia. In
SecureComm’08, 2008.
[33] B. Stock, M. Engelberth, F. C. Freiling, and T. Holz.
Walowdac – Analysis of a Peer-to-Peer Botnet. In
EC2ND’09, 2009.
[34] G. Tenebro. W32.Waledac Threat Analysis, 2009. Tech
report, Symantec.
[35] T. Werner. Botnet Shutdown Success Story: How
Kaspersky Lab Disabled the Hlux/Kelihos Botnet,
2011. Tech report, Kaspersky Lab.
http://www.securelist.com/en/blog/208193137/.
[36] J. Wyke. ZeroAccess, 2012. Tech report, SophosLabs.
[37] G. Yan, S. Chen, and S. Eidenbenz. RatBot:
Anti-Enumeration Peer-to-Peer Botnets. In Lecture
Notes in Computer Science, vol. 7001, 2011.
140