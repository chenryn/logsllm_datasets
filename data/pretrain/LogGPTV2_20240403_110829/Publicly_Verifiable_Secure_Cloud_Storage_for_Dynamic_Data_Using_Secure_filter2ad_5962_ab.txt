A) and the veriﬁcation algorithm SNC.Verify requires the
knowledge of this secret key.
2.3 Secure Cloud Storage
In the age of cloud computing, clients may want to out-
source their huge amount of data to the cloud storage server.
As the cloud service provider (possibly malicious) might dis-
card old data to save some space, the clients need to be con-
vinced that the outsourced data are stored untampered by
the cloud server. A naive approach to ensure data integrity
is that a client downloads the whole data from the server
and veriﬁes them individually segment by segment. How-
ever, this process is ineﬃcient in terms of communication
bandwidth required.
Building Blocks: PDP and POR.
Researchers come up with proofs of storage in order
to resolve the issue mentioned above. Ateniese et al. [3]
introduce the concept of provable data possession (PDP)
where the client computes an authenticator (for example,
MAC) for each segment of her data (or ﬁle), and uploads
the ﬁle along with the authenticators. During an audit pro-
tocol, the client samples a predeﬁned number of random
segment-indices (challenge) and sends them to the server.
We denote the cardinality of the challenge set by l which is
typically taken to be O(λ). The server does some computa-
tions (depending upon the challenge) over the stored data,
and sends a proof (response) to the client who veriﬁes the
integrity of her data based on this proof. This scheme also
introduces the notion of public veriﬁability1 where the client
(data owner) can delegate the auditing task to a third party
auditor (TPA). The TPA with the knowledge of the pub-
lic key performs an audit. For privately veriﬁable schemes,
only the client having knowledge of the secret key can verify
the proof sent by the server. This is illustrated in Figure 1.
Other schemes achieving PDP include [4, 18, 39, 38].
The ﬁrst paper introducing proofs of retrievability (POR)
for static data is by Juels and Kaliski [23] (a similar idea
is given for sublinear authenticators by Naor and Roth-
blum [30]). According to Shacham and Waters [36], the
underlying idea of a POR scheme is to encode the original
ﬁle with an erasure code [26, 33], authenticate the segments
of the encoded ﬁle, and then upload them on the storage
server. With this technique, the server has to delete or mod-
ify a considerable number of segments to actually delete or
modify a data segment. This ensures that all segments of
the ﬁle are retrievable from the responses of the server which
passes an audit with some non-negligible probability. Fol-
lowing the work by Juels and Kaliski, several POR schemes
have been proposed for static or dynamic data [9, 16, 10, 37,
12]. For a detailed list of POR schemes, we refer to [35].
As we deal with a single cloud server in this work, we
1The term “public veriﬁability” discussed in this paper de-
notes (only) whether a third party auditor having the knowl-
edge of the public parameters can perform an audit on behalf
of the client (data owner). We mention that this notion im-
plicitly assumes that the client is honest. However, a mali-
cious client can publish incorrect public parameters in order
to get an honest server framed by a third party auditor [24].
109lenge set Q. The veriﬁer outputs 1 if the proof passes
the veriﬁcation; she outputs 0, otherwise.
An SSCS protocol is publicly veriﬁable if the algorithm
SSCS.Verify described above involves only the public key pk.
The algorithm SSCS.Verify in a privately veriﬁable SSCS
protocol requires the knowledge of the secret key sk.
Security of an SSCS Protocol.
An SSCS protocol must satisfy the following proper-
ties [36].
1. Authenticity The authenticity of storage requires
that the cloud server cannot forge a valid proof of stor-
age T (corresponding to the challenge set Q) without
storing the challenged segments and their respective
authentication information untampered, except with a
probability negligible in λ.
2. Extractability The extractability (or retrievability)
of data requires that, given a probabilistic polynomial-
time adversary A that can respond correctly to a chal-
lenge Q with some non-negligible probability, there ex-
ists a polynomial-time extractor algorithm E that can
extract (at least) the challenged segments (except with
negligible probability) by challenging A for a polyno-
mial (in λ) number of times and verifying the responses
sent by A. The algorithm E has a non-black-box access
to A. Thus, E can rewind A, if required.
The SSCS protocols based on PDP guarantee the extraction
of almost all the segments of the ﬁle F . On the other hand,
the SSCS protocols based on POR ensure the extraction of
all the segments of F with the help of erasure codes.
2.4 General Construction of an SSCS Proto-
col from an SNC Protocol
Chen et al. [14] propose a generic construction of a secure
cloud storage protocol for static data from a secure network
coding protocol. They consider the data ﬁle F to be stored
in the server to be a collection of m vectors (or packets) each
of which consists of n blocks. The underlying idea is to store
these vectors (without augmenting them with unit vectors)
in the server. During an audit, the client sends an l-element
subset of the set of indices {1, 2, . . . , m} to the server. The
server augments those vectors with the corresponding unit
vectors, combines them linearly in an authenticated fashion
and sends the output vector along with its tag to the client.
Finally, the client veriﬁes the authenticity of the received
tag against the received vector. Thus, the server acts as an
intermediate node, and the client acts as both the sender and
the receiver (or the next intermediate router). We brieﬂy
discuss the algorithms involved in the general construction
below.
• SSCS.KeyGen(1λ, m, n): Initially, the client executes
SNC.KeyGen(1λ, m, n) to generate a secret key-public
key pair K = (sk, pk).
• SSCS.Outsource(F, K, m, n, fid): The ﬁle F associ-
ated with a random ﬁle identiﬁer fid consists of m
vectors each of them having n blocks. We assume
that each of these blocks is an element of F. Then,
for each 1 (cid:54) i (cid:54) m, the i-th vector vi is of the form
[vi1, . . . , vin] ∈ Fn. For each vector vi, the client forms
Figure 1: The architecture of a secure cloud storage
protocol. The client processes the ﬁle and uploads it
to the cloud server. For static data, she can read the
outsourced data; for dynamic data, she can update
her data as well. If the scheme is privately veriﬁable,
the client having the secret key can perform audits
on the data (through challenge and response). In a
publicly veriﬁable protocol, she can delegate the au-
diting task to a TPA who performs audits on behalf
of the client.
only mention some secure cloud storage protocols in a dis-
tributed setting. Some of them include the works by Curt-
mola et al. [15] (using replication of data) and Bowers et
al. [8] (using error-correcting codes and erasure codes). On
the other hand, existing secure cloud storage schemes have
found applications in other areas as well [28, 34].
We deﬁne an SCS protocol for static data (SSCS) below.
We defer the deﬁnition of an SCS protocol for dynamic data
(DSCS) to Section 3.1. In general, the term veriﬁer is used
to denote an auditor for a secure cloud storage. The client
(for a privately veriﬁable protocol) or a third party auditor
(for a publicly veriﬁable protocol) can act as the veriﬁer.
Definition 2.2. A secure cloud storage protocol for static
data (SSCS) consists of the following algorithms.
• SSCS.KeyGen(1λ): This algorithm generates a secret
key-public key pair K = (sk, pk) for the client.
• SSCS.Outsource(F, K, fid): Given a data ﬁle F as-
sociated with a random ﬁle identiﬁer fid, the client
processes F to form another ﬁle F (cid:48) (including authen-
tication information computed using sk) and uploads
F (cid:48) to the server.
• SSCS.Challenge(pk, l, fid): During an audit, the ver-
iﬁer sends a random challenge set Q of cardinality
l = O(λ) to the server.
• SSCS.Prove(Q, pk, F (cid:48), fid): Upon receiving the chal-
lenge set Q, the server computes a proof of storage T
corresponding to the challenge set Q and sends T to
the veriﬁer.
• SSCS.Verify(Q, T, K, fid): The veriﬁer checks whether
T is a valid proof of storage corresponding to the chal-
110ui = [vi ei] ∈ Fn+m by augmenting the vector vi
with the unit coeﬃcient vector ei. Let V ⊂ Fn+m be
the linear subspace spanned by u1, u2, . . . , um. The
client runs SNC.TagGen(V, sk, m, n, fid) to produce
an authentication tag ti for the i-th vector ui for each
1 (cid:54) i (cid:54) m. Finally, the client uploads the ﬁle F (cid:48) =
{(vi, ti)}1(cid:54)i(cid:54)m to the server.
• SSCS.Challenge(pk, l, m, n, fid): During an audit, the
veriﬁer selects I, a random l-element subset of [1, m].
Then, she generates a challenge set Q = {(i, νi)}i∈I ,
R←− F. The veriﬁer sends the challenge
where each νi
set Q to the server.
• SSCS.Prove(Q, pk, F (cid:48), m, n, fid): Upon receiving the
challenge set Q = {(i, νi)}i∈I for the ﬁle identiﬁer
fid, the cloud server, for each i ∈ I, forms ui =
[vi ei] ∈ Fn+m by augmenting the vector vi with the
unit coeﬃcient vector ei. Then, the cloud server runs
SNC.Combine({ui, ti, νi}i∈I , pk, m, n, fid) to produce
another vector w ∈ Fn+m (along with its authentica-
i=1 νi · ui. Let y ∈ Fn be
the ﬁrst n entries of w. The server sends T = (y, t) to
the veriﬁer as a proof of storage corresponding to the
challenge set Q.
tion tag t) such that w =(cid:80)l
• SSCS.Verify(Q, T, K, m, n, fid): The veriﬁer uses Q =
{(i, νi)}i∈I and T = (y, t) to reconstruct the vector
w ∈ Fn+m, where the ﬁrst n entries of w are the same
as those of y and the (n + i)-th entry is νi if i ∈ I (0 if
i (cid:54)∈ I). The veriﬁer runs SNC.Verify(w, t, K, m, n, fid)
and returns the output of the algorithm SNC.Verify.
3. CONSTRUCTION OF AN SCS PROTO-
COL FOR DYNAMIC DATA USING AN
SNC PROTOCOL
In Section 2.4, we have discussed a general construction of
an SSCS protocol from an SNC protocol proposed by Chen
et al. [14]. In a secure network coding protocol, the number
of packets (or vectors) in the ﬁle to be transmitted through
the network is ﬁxed. This is because the length of the co-
eﬃcient vectors used to augment the original vectors has to
be determined a priori. That is why, such a construction is
suitable for static data in general. On the other hand, in a
secure cloud storage protocol for dynamic data, clients can
modify their data after they upload them to the cloud server
initially. In this section, we discuss whether we can provide
a general framework for constructing an eﬃcient and secure
cloud storage protocol for dynamic data (DSCS) from an
SNC protocol.
3.1 On the General Construction of an Efﬁ-
cient DSCS Protocol from an SNC Proto-
col
In a secure network coding (SNC) protocol, a tag is asso-
ciated with each packet such that the integrity of a packet
can be veriﬁed using its tag. The SNC protocols found in
the literature use homomorphic MACs [1] or homomorphic
signatures [13, 7, 19, 5, 11]. Following are the challenges in
constructing an eﬃcient DSCS protocol from these existing
SNC protocols. We exclude, in our discussion, the work of
Attrapadung and Libert [5] as their scheme is not eﬃcient
due to its reliance on (ineﬃcient) composite-order bilinear
groups.
1. The DSCS protocol must handle the varying
values of m appropriately. In the network coding
protocols mentioned above, the sender divides the ﬁle
in m packets and augments them with unit coeﬃcient
vectors before sending them into the network. The
length of these coeﬃcient vectors is m which remains
constant during transmission. In a secure cloud stor-
age for dynamic data, the number of vectors may vary
(for insertion and deletion). If we follow a similar gen-
eral construction for a DSCS protocol as discussed in
Section 2.4, we observe that the cloud server does not
need to store the coeﬃcient vectors. However, during
an audit, the veriﬁer selects a random l-element subset
I of [1, m] and the server augments the vectors with
unit coeﬃcient vectors of dimension m before gener-
ating the proof. Therefore, the veriﬁer and the server
need to keep an updated value of m.
This issue can be resolved in a trivial way. The client
includes the value of m in her public key and updates
its value for each authenticated insertion or deletion.
Thus, its latest value is known to the veriﬁer and the
server. We assume that, for consistency, the client
(data owner) does not update her data during an audit.
2. The index of a vector should not be embed-
ded in its authentication tag. In an SNC protocol,
the ﬁle to be transmitted is divided into m packets
v1, v2, . . . , vm, where each vi ∈ Fn for i ∈ [1, m] ([19]
replaces F by Z). The sender augments each vector to
form another vector ui = [vi ei] ∈ Fn+m for i ∈ [1, m],
where ei is the m-dimensional unit vector containing
1 in i-th position and 0 in others. Let V ⊂ Fn+m be
the linear subspace spanned by these augmented basis
vectors u1, u2, . . . , um. The sender authenticates the
subspace V by authenticating these augmented vectors
before transmitting them to the network [13, 1, 7, 19,
11].
In a scheme based on homomorphic MACs [1],
the sender generates a MAC for the i-th basis vector
ui and the index i serves as an input to the MAC algo-
rithm (for example, i is an input to the pseudorandom
function in [1]). On the other hand, for the schemes
based on homomorphic signatures, the sender gener-
ates a signature ti on the i-th basis vector ui. In some
schemes based on homomorphic signatures, the index i
is embedded in the signature ti on the i-th augmented
vector. For example, H(fid, i) is embedded in ti [7,
19], where fid is the ﬁle identiﬁer and H is a hash
function modeled as a random oracle [6].
These schemes are not suitable for the construction of
an eﬃcient DSCS protocol due to the following rea-
son. For dynamic data, the client can insert a vector
in a speciﬁed position or delete an existing vector from
a speciﬁed location. In both cases, the indices of the
subsequent vectors are changed. Therefore, the client
has to download all these subsequent vectors and com-
pute fresh authentication tags for them before upload-
ing the new vector-tag pairs to the cloud server. This
makes the DSCS protocol ineﬃcient. However, in a few
schemes, instead of hashing vector indices as in [7, 19],
there is a one-to-one mapping from the set of indices
111to some group [13, 11], and these group elements are
made public. This increases the size of the public key
of these schemes. However, an eﬃcient DSCS protocol
can be constructed from them. In fact, we construct
a DSCS protocol (described in Section 3.3) based on
the SNC protocol proposed by Catalano et al. [11]. We
note that Chen et al. [14] construct an SCS protocol
from the same SNC protocol, but for static data only.
3. The freshness of data must be guaranteed. For
dynamic data, the client can modify an existing vector.
However, a malicious cloud server may discard this
change and keep an old copy of the vector. As the old
copy of the vector and its corresponding tag are valid,
the client has no way to detect if the cloud server is
storing the latest copy.
We ensure the freshness of the client’s data, in our
DSCS construction, using an authenticated data struc-
ture (rank-based authenticated skip list) on the authen-
tication tags of all the vectors.
In other words, the
authenticity of the vectors is maintained by their tags,
and the integrity of the tags is in turn maintained by
the skip list. The advantage of building the skip list
on the tags (over building it on the vectors) is that the
tags are much shorter than a vector, and this decreases
the size of the proof sent by the server. When a vec-
tor is inserted (or modiﬁed), its tag is also updated
and sent to the server. The server updates the skip
list accordingly. For deletion of a vector, the server