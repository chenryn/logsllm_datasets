Walker)
F
Abstract 
Interpretation
AI
Renaming
Constraint 
Generation
Assertion
Restriction
Satisfiable
Unsatifiable
SAT solver
Assignment Sequences
Counter-
example 
Analyser 
Variables Requiring Sanitization
Runtime 
Protection
Secured PHP
Figure 8. WebSSARI system architecture. 
      Figure 9. The verification process.
4. System implementation 
developers  we  contacted,  38  acknowledged  our  findings 
and stated that they would provide patches (Figure 10). 
Project
GBook MX 
AthenaRMS
PHPCodeCabinet
BolinOS
PHP Surveyor
Booby
ByteHoard
PHPRecipeBook
phpLDAPadmin
Segue CMS 
Moregroupware
iNuke
InfoCentral
WebMovieDB
TestLink
Crafty Syntax 
Live Help 
To  test  our  approach,  we  developed  WebSSARI  to 
verify  real-world  Web  applications.  An  illustration  of 
WebSSARI’s system architecture is presented in Figure 8. 
A code  walker  consists  of  a  lexer,  a  parser,  an  AST 
(abstract  syntax  tree)  maker,  and  a  program  abstractor.
The program abstractor asks the AST maker to generate a 
full  representation  of  a  program’s  AST.  The  AST  maker 
uses the lexer and the parser to perform this task, handling 
external  file  inclusions  along  the  way.  By  traversing  the 
AST,  the  program  abstractor  generates  an  AI.  Using  the 
algorithms  described  in  Section  3,  the  BMC  engine
performs  verification  of  the  AI.  For  each  variable 
involved  in  an  insecure  statement,  it  inserts  a  statement 
that secures the variable by treating it with a sanitization 
routine. Sanitization routines are stored in a prelude, and 
users can supply the prelude with their own routines. The 
whole AI verification process is illustrated in Figure 9. 9
5. Experimental results 
SourceForge.net  [1],  the  world’s  largest  open-source 
development  website,  classifies  all  projects  according  to 
language,  purpose,  popularity,  and  development  status 
(also referred to as maturity). As part of our previous TS 
algorithm effort, we established a sample of 230 projects 
(written  in  PHP)  reflecting  a  broad  variation  in  terms  of 
the  SourceForge.net  classifications.  After  downloading 
their  sources  and  testing  them  with  WebSSARI,  we 
manually  inspected  every  single  report  of  a  security 
violation. If we identified an actual vulnerability, we sent 
an  email  notification  to  the  developer.  Of  the  69 
3 PHPFriendlyAdmin
90 PHP Helpdesk 
4 Media Mate 
2 Obelus Helpdesk 
8 eDreamers
13 Mad.Thought
2 SquirrelMail
2 PHPMyList
25 EGroupWare
A TS BMC Project
4
60
3
0
25
71
3
94
99 169
5
90
2
98
11
99
25
97
11
77
7
99
3
0
82 206
7
24
69
88
5 PHPList
9 PHPLetter
7 WebArchive
3 Nalanda
57 Site@School
1
A TS BMC
7
7
99
4
69 10
4
4
99
87 16 16
1
87
0 53 16
6
22
1
80
4
66
79 23 23
2
7
58 27
8
94 46 40
1
3
0 16
3
8
7
4
2
48 PHPPgAdmin
98
96
16
1 Anonymous Mailer 
73
7
7
ILIAS open 
source
PHP Multiple 
Newsletters
International Suspect
Vigilance Nexus 
20
2
2
68
30
30
0
20
12
PHP Support 
Tickets
Norfolk Household 
Financial Manager 
Tiki CMS 
Groupware
0 40 40
0 60 60
99 12 12
Total 980 578
A:   Project activity 
TS:   TS-reported errors  
BMC:   BMC-reported errors 
Figure 10. The number TS- and BMC-reported errors of the 
38 projects that responded to our notifications. 
The  230  projects  consisted  of  11,848  files  consisting 
of  1,140,091  statements;  515  files  were  identified  by  TS 
as  vulnerable.  Soon  after  starting  the  task  of  manually 
validating all reported vulnerabilities, the authors realized 
that the lack of counterexamples made for a laborious and 
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:49:16 UTC from IEEE Xplore.  Restrictions apply. 
to 
the  process,  we  added  features 
time-consuming  task  that  required  investigating  multiple 
function  calls  spanning  multiple  files.  In  an  effort  to 
speed  up 
the 
WebSSARI  GUI  that  helped  users:  a)  navigate  between 
different source files, function calls, and vulnerable lines; 
b)  identify  particular  variables  (such  as  highlighting 
variables  that  caused  assertions);  and  c)  search  for 
specific  variables  or  text  patterns.  However,  even  with 
these  special  features,  the  job  of  manual  validation 
remained  difficult.  We  therefore  added  a  tool  called 
PHPXREF  [27]  to  generate  cross-referenced  HTML 
documentations 
the 
enhancements,  it  still  took  two  of  us  four  full  working 
days  to  validate  the  515  files  that  were  identified  as 
vulnerable.
code.  Despite 
source 
of 
In the revised project that is the focus of this paper, we 
used BMC to provide counterexample traces. Differences 
in the TS and BMC reports on the 38 vulnerable projects 
whose  developers  acknowledged  our  findings  are  shown 
in  Figure  10.  For  these  projects,  the  total  number  of 
vulnerable statements originally reported by TS was 980. 
Using the same test set, BMC reported a total of 578 error 
introductions,  meaning  that  the  980  vulnerabilities  were 
caused  by  the  propagation  of  578  errors.  Compared  with 
TS,  this  process  yielded  an  additional  41.0  percent 
reduction in the number of instrumentations. 
6. Discussion
In 
this 
project,  we 
used  BMC-provided 
counterexamples  to  identify  the  cause  of  errors,  which 
increases  the  precision  of  both  error  reports  and  code 
instrumentation.  In  a  very  recent  project,  Ball,  Naik,  and 
Rajamani [2] made a very similar effort—they attempted 
to enhance their model checker SLAM with the ability to 
localize  errors.  As 
they  mentioned,  current  model 
checkers  report  error  symptoms  rather  than  the  actual 
causes.  Furthermore,  even  the  state-of-the-art  model 
checkers  today  report  only  a  single  error  trace  per  run. 
They  reported  their  experiences  in  using  their  algorithm 
to detect locking bugs in C device drivers.
Our  efforts  were  motivated  by  our  previous  effort  in 
verifying  Web  applications  using  the  TS  algorithm.  TS 
reported  individual  error  symptoms,  which  not  only 
resulted in inefficient automated patching, but also made 
it  difficult  to  report  a  meaningful  number  of  discovered 
vulnerabilities,  since  many  of  the  reported  errors  were 
attributed  to  the  same  cause  and  should  not  have  been 
double counted. Ball, Naik, and Rajamani [2] focused on 
locking  bugs,  which  usually  have  a  one-to-one  mapping 
between a symptom and a cause. However, we focused on 
information  flow  bugs,  which  are  much  more  complex 
and can have a many-to-many symptom-cause mapping—
the reason why localizing errors resulted in a MINIMUM-
INTERSECTING-SET problem. Furthermore, their efforts 
mainly  contributes  to  more  informative  error  reports, 
while  ours  also  results  in  more  efficient  automated 
patching. Like Ball, Naik, and Rajamani’s algorithm, ours 
also requires that all counterexample traces be identified. 
However,  since  SLAM  is  a  BDD-based  model  checker 
and  xBMC  is  a  SAT-based  bounded  model  checker,  our 
proposed  method  for  extracting  all  counterexamples  is 
unique from theirs. 
7. Conclusion
it 
that 
to  be  a  major  deficiency 
it  has  polynomial-time  complexity, 
In  this  paper  we  proposed  a  practical  approach  for 
formally  verifying  Web  application 
reliability  and 
security.  In  an  earlier  work,  we  used  a  typestate-based 
algorithm  (TS)  that  essentially  performs  breadth-first 
searches on control flow graphs and trades space for time. 
Although 
is 
traces.  This 
incapable  of  providing  counterexample 
proved 
reduced 
WebSSARI’s  potential  for  practical  use.  On  the  other 
hand,  we  considered  a  depth-first  search  algorithm  to  be 
too  costly  in  terms  of  time,  and  so  we  implemented  a 
bounded model checker using zChaff [19] (a mature SAT 
solver)  and  used  it  to  produce  counterexample  traces. 
Two  immediate  benefits  of  counterexample  traces  are  a) 
they allow for more informative error reports, and b) they 
can  be  used  to  identify  multiple  errors  (symptoms)  with 
the  same  root  cause.  Such 
information  not  only 
contributes  to  greater  report  accuracy,  but  also  sharply 
reduces  the  number  of  inserted  runtime  guards.  We 
showed  that  the  problem  of  finding  the  minimum  error 
causes  (groups)  is  NP-complete,  and  offered  a  greedy 
heuristic-based strategy. 
8. Acknowledgement
We  deeply  appreciate  the  anonymous  reviewers  for 
offering us many valuable comments. We would also like 
to thank Dr. Bow-Yaw Wang for his useful suggestions. 
9. References
[1] Augustin,  L.,  Bressler,  D.,  Smith,  G.  “Accelerating 
Software  Development  through  Collaboration."  In 
Proc. 24th International Conf. Software Engineering,
p.559-563, Orlando, Florida, 2002. 
[2] Ball,  T.,  Naik,  M.,  Rajamani,  S.  “From  Symptom  to 
Cause: Localizing Errors in Counterexample Traces.” 
In Proc.  30th  ACM  SIGPLAN-SIGACT  Symp.  on 
Principles  of  Programming  Languages,  p.97-105, 
New Orleans, Louisiana, 2003. 
[3] Biere, A., Cimatti, A., Clarke, E. M., Fujita, M., Zhu, 
Y.  “Symbolic  Model  Checking  without  BDDs.”  In 
Proc.  5th  Int’l  Conf.  Tools  and  Algorithms  for 
Construction  and  Analysis  of  Systems,  p.193-207, 
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:49:16 UTC from IEEE Xplore.  Restrictions apply. 
volume  LNCS  1579,  Amsterdam,  The  Netherlands, 
1999. Springer-Verlag. 
[4] Biere, A., Cimatti, A., Clarke, E. M., Fujita, M., Zhu, 
Y. 
“Symbolic  Model  Checking  using  SAT 
Procedures  instead  of  BDDs.”  In  Proc.  36th  Design 
Automation  Conference,  p.317-320,  New  Orleans, 
Las Angeles, 1999. 
[5] Chvatal, V. “A Greedy Heuristic for the Set Covering 
Problem.”  Mathematics  of  Operations  Research, 
4:33-235, 1979. 
[6] Clarke,  E.,  Kroening,  D.,  Yorav,  k.  “Behavioral 
Consistency  of  C  and  Verilog  Programs  using 
Bounded Model Checking.” Technical Report CMU-
CS-03-126,  Carnegie  Mellon  University,  School  of 
Computer Science, 2003. 
[7] Clarke,  E.,  Kroening,  D.,  Yorav,  K.  “Behavioral 
Consistency  of  C  and  Verilog  Programs  using 
Bounded  Model  Checking.”  In  Proc.  40th  Design 
Automation Conference, Session 23.3, Anaheim, CA, 
2003.
[8] Clarke,  E.,  Kroening,  D.  “ANSI-C  Bounded  Model 
Checker User Manual.” Carnegie Mellon University, 
School of Computer Science, 2003. 
[9] Cousot,  P.,  Cousot,  R.  “Abstract  Interpretation:  A 
Unified  Lattice  Model  for  Static  Analysis  of 
Programs  by  Constructions  or  Approximation  of 
Fixpoints.”  In  Conference  Record  of  the  4th  ACM 
Symp. Principles of Programming Languages, p.238-
252, 1977. 
[10] Curphey, M., Endler, D., Hau, W., Taylor, S., Smith, 
T., Russell, A., McKenna, G., Parke, R., McLaughlin, 
K.,  Tranter,  N.,  Klien,  A.,  Groves,  D.,  By-Gad,  I., 
Huseby,  S.,  Eizner,  M.,  McNamara,  R.  “A  Guide  to 
Building  Secure Web  Applications.”  The  Open Web 
Application Security Project, v.1.1.1, Sep 2002. 
[11] Cytron,  R.,  Ferrante,  J.,  Rosen,  B.  K.,  Wegman,  M. 
N.,  Zadeck,  F.  K.  “An  Efficient  Method  of 
Computing Static Single Assignment Form.” In Proc.
16th  ACM  SIGPLAN-SIGACT  Symp.  Principles  of 
Programming  Languages,  p.25-35,  Austin,  Texas, 
1989. ACM Press. 
[12] Denning,  D.  E.  “A  Lattice  Model  of  Secure 
Information  Flow.”  Communications  of  the  ACM, 
19(5):236-243, 1976. 
[13] Huang,  Y.  W.,  Huang,  S.  K.,  Lin,  T.  P.,  Tsai,  C.  H. 
“Web  Application  Security  Assessment  by  Fault 
Injection  and  Behavior  Monitoring.”  In  Proc.  12th 
Int’l  World  Wide  Web  Conference,  p.148-159, 
Budapest, Hungary, 2003. 
[14] Huang,  Y.  W.,  Yu,  F.,  Hang,  C.,  Tsai,  C.  H.,  Lee, 
D.T., Kuo, S. Y. “Securing Web Application Code by 
Static  Analysis  and  Runtime  Inspection.”  In:  Proc.
13th  Int’l  World  Wide  Web  Conference,  New  York, 
2004.
[15] Hughes,  F.  “PHP:  Most  Popular  Server-Side  Web 
Scripting Technology.” LWN.net.
http://lwn.net/Articles/1433/ 
[16] Kroening,  D.,  Strichman,  O.  “Efficient  Computation 
of  Recurrence  Diameters.”  In  Proc.  4th  Int’l  Conf. 
Verification,  Model  Checking, 
and  Abstract 
Interpretation, p.298-309, volume LNCS 2575, New 
York, 2003. Springer-Verlag. 
[17] Meier, J.D., Mackman, A., Vasireddy, S. Dunner, M., 
Escamilla,  R.,  Murukan,  A.  “Improving  Web 
Application 
and 
Countermeasures.” Microsoft Corporation, 2003. 
Security—Threats 
[18] Merzbacher, M., Patterson, D. “Measuring End-User 
Availability  on  the  Web:  Practical  Experience.”  In 
Proc.  2002  Int’l  Conf.  Dependable  Systems  and 
Networks, p.473-488, Washington, D.C., 2002. 
[19] Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, 
L.,  Malik,  S.  “Chaff:  Engineering  an  Efficient  SAT 
Solver.” 
In  Proc.  38th  Design  Automation 
Conference, session 33.1, New Orleans, LA, 2001. 
[20] OWASP.  “The  Ten  Most  Critical  Web  Application 
Security  Vulnerabilities.”  OWASP  Whitepaper, 
version 1.0, 2003. 
[21] Pottier, F., Simonet, V. “Information Flow Inference 
for  ML.”  ACM  Transactions  on  Programming 
Languages and Systems, 25(1):117-158, 2003. 
[22] Sandhu,  R.  S.  “Lattice-Based  Access  Control 
Models.” IEEE Computer, 26(11):9-19, 1993. 
[23] Sanjit,  A.  S.,  Bryant,  R.  E.,  “Unbounded,  Fully 
Symbolic Model Checking of Timed Automata using 
Boolean  Methods.”  In  Proc.  15th  Int’l  Conf. 
Computer-Aided  Verification,  p.154-166,  volume 
LNCS  2725,  Boulder,  Colorado,  2003.  Springer-
Verlag.
[24] Scott,  D.,  Sharp,  R.  “Abstracting  Application-Level 
Web  Security.”  In  Proc.  11th  Int’l  World  Wide  Web 
Conference, p.396-407, Honolulu, Hawaii, 2002. 
[25] Shankar,  U.,  Talwar,  K.,  Foster,  J.  S.,  Wagner,  D. 
“Detecting  Format  String  Vulnerabilities  with  Type 
Qualifiers.” 
In  Proc.  10th  USENIX  Security 
Symposium, p.201-220, Washington DC, 2002. 
[26] Strom,  R.  E.,  Yemini,  S.  A.  “Typestate:  A 
Programming  Language  Concept  for  Enhancing 
Software  Reliability.” 
IEEE  Transactions  on 
Software Engineering, 12(1):157-171, Jan 1986. 
[27] Watts,  G.  “PHPXref:  PHP  Cross  Referencing 
Documentation Generator.” Sep 2003. 
http://phpxref.sourceforge.net/ 
[28] Woodman,  S.,  Morgan,  G.,  Parkin,  S.  “Portal 
Replication  for  Web  Application  Availability  Via 
SOAP.” In Proc. 8th IEEE Int’l Workshop on Object-
Oriented Real-Time Dependable Systems, p.122-130, 
Guadalajara, Mexico, 2003. 
[29] Wright, A. K, Cartwright, R. “A Practical Soft Type 
for  Scheme.”  ACM  Transactions  on 
System 
Programming Languages and Systems, 19(1):87-152, 
Jan 1999.
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:49:16 UTC from IEEE Xplore.  Restrictions apply.