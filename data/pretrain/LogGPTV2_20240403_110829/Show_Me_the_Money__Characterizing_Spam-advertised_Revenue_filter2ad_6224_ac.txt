Out of the 324 samples in our dataset, we found a small
number of outliers (six) that we discuss here. Almost all
come from the GlavMed program. The outliers fall into
two categories: two singleton outliers completely outside
the normal order number range for the program, and one
group of four internally consistent order numbers that
were slightly outside the expected range, violating mono-
tonicity. We discuss these in more detail here, as well as
their possible explanations.
The ﬁrst singleton outlier was a purchase placed at a
Web site that is clearly based on the SE2 engine built
by GlavMed. However, the returned order number was
close to 16000 when co-temporal orders from all other
GlavMed sites returned orders closer to 1080000. The
site differs in a number of key features, including a
unique template not distributed in the standard package
made available to GlavMed afﬁliates, a different support
phone number, different product pricing, and purchases
processed via a different acquiring bank than used by
all other GlavMed purchases. Taken together, we believe
Figure 3: The amount of error—either in our measurement pro-
cess, or due to batching of order numbers—required for each
measurement in 2011 to be consistent with the Null Hypothesis
that order numbers are derived from a clock that advances at
some steady rate. Note that the y-axis is truncated at ±24 hrs,
though additional points lie outside this range.
of clock-driven batches, as follows. For each program,
we consider the purchases made in 2011. We construct
a least-squares linear ﬁt between the order numbers of
the purchases and the time at which we made them. If
the order numbers come from clock-driven batches (the
Null Hypothesis), then we would expect that all of the
points associated with our purchases to fall near the ﬁtted
line. Accordingly, for each point we compute how far we
would have to move it along the x-axis so that it would
coincide with the line for its program. If the Null Hypoth-
esis is true, then this deviation in time reﬂects the error
that must have arisen during our purchase measurement:
either due to poor accuracy in our own time-keeping, or
because of the granularity of the batches used by the pro-
gram for generating order numbers.
Figure 3 plots this residual error for each afﬁliate pro-
gram. For example, in the lower right we see a point for
a 33drugs purchase made in early February 2011. If the
Null Hypothesis holds, then the purchaser’s order num-
ber reﬂects a value that should have appeared 18 hours
earlier than when we observed it. That is, either we in-
troduced an error of about 18 hours in recording the time
of that purchase; or the program uses a batch-size of 18+
hours; or the Null Hypothesis fails to hold.
For all ten of the afﬁliate programs, we ﬁnd many pur-
chases that require timing errors of many hours to main-
tain consistency with the Null Hypothesis. (Note that
we restrict the y-axis to the range ±24 hr for legibil-
ity, although we ﬁnd numerous points falling outside that
2010.982011.022011.062011.10−20−1001020YearRequired Timing Error (Hours)lllllllllllllllllllllllllllllllllllllllllllll33drugs4rxeurosoftevaglavmedonlinepharmexroyalrx−promotionsoftsalesthis reﬂects a site that is simply using the SE2 engine, but
is not in fact associated with the GlavMed operation.5
The second outlier occurred in a very early (January
2010) purchase from a Pharmacy Express afﬁliate, which
returned an order number much higher than any seen in
later purchases. We have no clear explanation for this in-
congruity, and other key structural and payment features
match, but we note that the order numbers returned in
all subsequent Pharmacy Express transactions are only
ﬁve digits long, and that over nine months pass between
this initial outlier and all subsequent purchases. Conse-
quently, we might reasonably explain the discrepancy by
a decision to reset the order number space at some point
between January and October.
Finally, we ﬁnd a group of four early GlavMed pur-
chases whose order numbers are roughly the same mag-
nitude, but occur out of sequence (i.e., given the rate of
growth seen in the other GlavMed order numbers, these
four are from a batch that will only be used sometime
in 2013). These all occurred together in the last two
weeks of January 2010. This small outlier group remains
a mystery, and suggests either that GlavMed might main-
tain a parallel order space for some afﬁliates, or that they
reﬂect a “counterfeit” GlavMed operation. The remain-
ing 21 GlavMed purchase samples, as well as the 122 op-
portunistically gathered order numbers (occurring both
before and after January 2010), all use consistent order
numbering.
While we cannot completely explain these few out-
liers, they represent less than 2% percent of our dataset.
We also have found no unexplained instances within the
last 12 months. We remove these six data points in the
remainder of our analysis.
3.4 Order rates
Under these assumptions, we can now estimate the rate
of orders seen by each enterprise. Figure 4 plots the 2011
data points for each of the 10 programs. We also plot
the least squares linear interpolation as well as the slope
parameter of this line—corresponding to the number of
orders received per day on average. During this time pe-
riod, daily order rates for pharmacy programs vary from
a low of 227 for Rx–Promotion (recall that their order
IDs increment by two for each order) up to a high of 887
for EvaPharmacy (software programs range between 49
and 749). Together, these reﬂect a monthly volume of
over 82,000 pharmaceutical orders and over 37,000 soft-
ware orders. Again, these numbers reﬂect upper bounds
on completed orders, since undoubtedly some fraction of
these attempted orders are declined; however, it seems
clear that order volume is substantial.
We also note that while order volume is quite consis-
tent across January and February, there are signiﬁcant
fall offs for some programs when compared to the data
gathered earlier. For example, during 2010, the average
number of Rx–Promotion orders per day was 385, 70%
greater than during the ﬁrst two months of 2011. Sim-
ilarly, 2011 GlavMed orders are off roughly 20% from
their 2010 pace, and EvaPharmacy saw a similar de-
cline as compared to October and November of that year.
Other programs changed little and maintained a stable
level of activity.
4 Purchasing behavior
While the previous analysis demonstrates that pharma-
ceutical afﬁliate programs are receiving a signiﬁcant vol-
ume of orders, it reveals little about the source of these
orders or their contents. In this section, we use an oppor-
tunistic analysis of found server log data to explore these
issues for one such afﬁliate program.
4.1 EvaPharmacy image hosting
In particular, we examine EvaPharmacy, a “top 5” spam-
advertised pharmacy afﬁliate program.6 In monitoring
EvaPharmacy sites we observed that roughly two thirds
“outsourced” image hosting to compromised third-party
servers (typically functioning Linux-based Web servers).
This behavior was readily identiﬁable because visits to
such sites produced HTML code in which each image
load was redirected to another server—addressed via raw
IP address—at port 8080.
We contacted the victim of one such infection and they
were able to share IDS log data in support of this study.
In particular, our dataset includes a log of HTTP request
streams for a compromised image hosting server that
was widely used by EvaPharmacy sites over ﬁve days
in August of 2010. While the raw IP addresses in our
dataset have been anonymized (consistently), they have
ﬁrst been geolocated (using MaxMind) and these geo-
graphic coordinates are available to us. Thus, we have
city-level source identiﬁability as well as the contents of
HTTP logs (including timestamp, object requested, and
referrer).
Through repeated experimentation with live Eva-
Pharmacy sites, we inferred that the site “engine” can use
dynamic HTML rewriting (similar to Akamai) to rewrite
embedded image links on a per visit basis. On a new
visit (tracked via a cookie), the server selects a set of
ﬁve compromised hosts and assigns these (apparently in
a quasi-random fashion) to each embedded image link
served. During the ﬁve-day period covering our log data,
our crawler observed 31 distinct image servers in use.
5We have found third parties contracting for custom GlavMed tem-
plates on popular “freelancer” sites, giving reason to believe that inde-
pendent innovation exists around the SE2 engine created by GlavMed.
6Our page classiﬁers [16] identiﬁed EvaPharmacy in over 8% of
pharmacy sites found in spam-advertised URLs over three months, with
afﬁliates driving trafﬁc to over 11,000 distinct domains.
Figure 4: Collected data points and best ﬁt slope showing the inferred order rate for ten different spam-advertised afﬁliate programs.
Order numbers are zero-normalized and the vertical scale of each plot is identical.
However, our particular server was apparently dispropor-
tionately popular, as it appears in 31% of all contempo-
raneous visits made by our URL crawler (perhaps due
to its particularly good connectivity). In turn, each im-
age server hosts an nginx Web proxy able to serve the
entirety of the image corpus.
4.2 Basket inference
Since the log we use is limited to embedded Web page
images, and in fact only includes one ﬁfth of the images
fetched during a particular visit, there are considerable
challenges involved in inferring item selection purely
from this data. We next discuss how this inference tech-
nique works (illustrated at a high level in Figure 5) as
well as its fundamental limitations.7
We mapped out the purchasing workﬂow involved in
ordering from an EvaPharmacy site, and observed that all
purchases involve visiting four key kinds of pages in or-
der: landing, product, shopping cart, and checkout. The
landing page generally includes over 40 distinct embed-
ded images. Thus, even though images are split among
ﬁve servers, it is highly likely that multiple objects from
each landing page are fetched via our server (each with
a referrer ﬁeld identifying the landing page from which
it was requested).8 We observe 752,000 distinct IP ad-
7This general approach is similar in character to Moore and Clay-
ton’s inference of phishing page visits from Webalizer logs [20].
8We validated this observation using our crawled data, which
showed that the landing pages using :8080 image hosting always used
ﬁve distinct servers. Thus, any image server assigned to a particular
visit is guaranteed to see the landing page load for that visit.
dresses that visited and included referrer information
during our ﬁve-day period.
When a visitor selects a particular drug from the land-
ing page, the reply takes them to an associated product
page. This page in turn prompts them to select the par-
ticular dosage and quantity they wish to purchase. The
precise construction of product pages differs between the
set of site templates (i.e., storefront brands) used by Eva-
Pharmacy. However, all include at least a few new im-
ages not found on the landing page, and the most popu-
lar template fetches ﬁve additional images. The number
of additional images varies on a per-template basis, not
a per-product basis within each template. Thus, for some
templates we may have less opportunity to observe what
product the user selects, but this does not affect our esti-
mate of the distribution of products selected, because the
diminished opportunity is not correlated with particular
products.
Next, upon selecting a product, the user is taken to the
shopping cart page, which again includes a large number
(often a dozen or more) of new images representing prod-
uct recommendations. We observe 4,879 cart visits from
3,872 distinct IP addresses. This allows us to estimate
a product-selection conversion rate: the fraction of visi-
tors who select an item for purchase. Based on the total
number of visitors where we have referrer information,
the conversion percentage on an IP basis is 0.5%.9 Of
these, 3,089 cart additions have preceding visits to prod-
9For comparison, in our previous work we measured a visit-to-
product-selection conversion rate of 2% [10].
Order IDJan  5Jan 15Jan 25Feb  4llllllllllllllll323 id/day 33drugsJan  5Jan 15Jan 25Feb  4lllllllllllll263 id/day 4rxlllllllllllllllllllllllll749 id/day eurosoftllllllllllllllll887 id/day evalllllllllllllll582 id/day glavmedllllllllllllllll192 id/day onlinelllllllll261 id/day pharmexlllllllll443 id/day royalJan  5Jan 15Jan 25Feb  4lllllllllllllllllllllllllll455 id/day rx−promoJan  5Jan 15Jan 25Feb  4lllllllllll49 id/day softsalesFigure 5: How a user interacts with an EvaPharmacy Web site, beginning with the landing page and then proceeding to a product
page and the shopping cart. The main Web site contains embedded images hosted on separate compromised systems. When a
browser visits such pages, the referrer information is sent to the image hosting servers for every new image visited.
uct pages, which allows us to infer the selected product.
To quantify overall shopping cart addition activity, we
compare the total number of visits to the number of vis-
its to the shopping cart page. To quantify individual item
popularity, we examine the subset of visits for which the
customer workﬂow allows us to infer which speciﬁc item
was added to the cart.
There are three key limitations to this approach.
First and foremost, the ﬁnal page in the purchasing
workﬂow—the checkout page—generally does not in-
clude unique image content, and thus does not appear in
our logs (even if it did, our approach could not determine
whether checkout completed correctly). Thus, we can
only observe that a user inserted an item into their cart,
but not that they completed a purchase attempt. In gen-
eral, this is only an issue to the degree that shopping cart
abandonment correlates with variables of interest (e.g.,
drug choice). The second limitation is that pages typi-
cally use the same image for all dosages and quantities
on a given product page, and therefore we cannot distin-
guish these features (e.g., we cannot distinguish between
a user selecting 120 tablets of 25mg Viagra tablets vs.
an order of 10 tablets, each of 100mg). Finally, we can-
not disambiguate multiple items selected for purchase.
When a user visits a product page followed by the shop-
ping cart page, we can infer that they selected the associ-
ated product. However, if the visitor then continues shop-
ping and visits additional product pages, we cannot de-
termine whether they added these products or simply ex-
amined them (subsequent visits to the shopping cart page
add few new recommended products; recommendations
appear based on the ﬁrst item in the cart). We choose
the conservative approach and only consider the products
that we are conﬁdent the user selected, which will cause
us to under-represent those drugs typically purchased to-
gether.
Another issue is that pharmacy formularies, while
largely similar, are not identical between programs. In
particular, some pharmacy programs (e.g., Online Phar-
macy) offer Schedule II drugs (e.g., Oxycodone and Vi-
codin). However, since EvaPharmacy does not sell such
drugs, our data does not capture this category of demand.
Finally, our dataset also has potential bias due to the
particular means used to drive trafﬁc to it. We found
that 45 of the 50 top landing pages observed in the host-
ing data also appeared in our spam-driven crawler data,
demonstrating directly that these landing pages were ad-
vertised through email spam. While these pages could
also be advertised using less risky methods such as
SEO, this seems unlikely since spam-advertised URLs
are swiftly blacklisted [14]. Thus, we suspect (but cannot
prove) that our data may only capture the purchasing be-
havior for the spam-advertised pharmacies; different ad-
vertising vectors could conceivably attract different de-
mographics with different purchasing patterns.
Given these limitations, we now report the results
of two analyses: product popularity (what customers
buy) and customer distribution (where the money comes
from).
4.3 Product popularity
Our ﬁrst analysis focuses on simple popularity: what in-
dividual items users put into their shopping carts (Ta-
ble 3a) and what broad (seller-deﬁned) categories of
pharmaceuticals were popular (Table 3b) during our
measurement period. Although naturally dominated by
the various ED and sexually-related pharmaceuticals, we
ﬁnd a surprisingly long tail; indeed, 38% of all items
added to the cart were not in this category. We observed
289 distinct products, including popular mass-market
products such as Zithromax (31), Acomplia (27), Nex-
ium (26), and Propecia (27); but also Cipro (11; a com-
monly prescribed antibiotic), Actos (6; a treatment for
Type 2 diabetes), Buspar (12; anti-anxiety), Seoquel (9;
anti-schitzophrenia), Clomid (8; ovulation inducer), and
Gleevec (1; used to treat Leukemia and other cancers).
this reach is not necessarily all that useful: the population
actively engaging with EvaPharmacy sites and placing
orders is considerably less diverse than the superset sim-
ply visiting (perhaps inadvertently or due to curiosity).
For example, the Philippines constitutes 4% of the vis-
itors, but only 1% of the additions to the shopping cart.
Overall, countries other than the U.S., Canada, and West-
ern Europe generate 29% of the visitors but only 13% of
the items added to the shopping cart. Conversely, the vast
majority of shopping cart insertions originate from the
U.S. and Canada (80%) or Europe (6%), reinforcing the
widely held belief that spam-advertised pharmaceuticals
are ultimately funded with Western Dollars and Euros.
The United States dominates both visits (54%) and
cart additions (76%), and moreover has the highest rate
of conversion between visit and shopping cart insertion
(0.72%). Table 2 well illustrates this, listing the activ-