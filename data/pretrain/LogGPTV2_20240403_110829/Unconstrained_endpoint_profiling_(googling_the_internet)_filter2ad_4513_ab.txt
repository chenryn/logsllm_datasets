a list of malicious mail servers. Further, we insert all the keywords
in the cache. When a URL’s domain name is found in the cache,
then we can quickly classify that URL by using the list of keywords
present in the cache. In this way, the cache avoids having to classify
the URL on every hit and simpliﬁes the IP-tagging phase, as we
explain next.
2.1.3 IP tagging
The ﬁnal step is to tag an IP address based on the collected in-
formation. We distinguish between three different scenarios.
URL based tagging. In some scenarios, an IP address can be
directly tagged when the URL can be classiﬁed via rapid search
for keywords in the URL itself. One example is classifying eMule
p2p servers based on the emule-project.net domain name.
2In an alternative, yet more expensive method, we could have
stored all the past URLs and then retrieved all the webpages.
Another example is the torrent list found at torrentportal.
com. In such scenarios, we can quickly generate the appropriate
tags by examining the URL itself. In particular, we use the mapping
between a website class (Column 2) and IP tags (Column 3) in
Table 1 to generate the tags. In majority of the cases, such rapid
tagging is not possible and hence we have to examine the hit text
for additional information.
General hit text based tagging. For most of the websites, we
are able to accurately tag endpoints using a keyword based ap-
proach. The procedure is as follows. If we get a match in the web-
site cache (for the speciﬁc URL we are currently trying to match),
we check if any of the keywords associated with that domain match
in the search hit text. Surprisingly, we typically ﬁnd at least a single
keyword, which clearly reveals the given IP’s nature and enables
tagging. Table 1 provides the mapping between the domain class
and IP tags.
For hit texts which match multiple keywords, we explain the
generation of tags via an example. For instance, a URL such as
projecthoneypot.org provides multiple information about
an IP address, e.g., not only that it is a mail server but also a spam-
mer. Due to a match with both the keywords, this URL’s domain
would be entered in the website cache as a malicious mail servers’
list. Then queries to an ip-address that is listed at projecthoney-
pot.org could return either: (i) both the keywords mail server
and spam, in which case, the ip-address would be tagged by both
the tags mail server and spammer, (ii) only the keyword
mail server where the ip-address would be tagged as a mail
server only and (iii) only the keyword spam where the ip-address
would be tagged as spammer via the one-to-one mapping but also
as mail server. This expansion of tags (from spam to mail
server) can be done unambiguously because there is no rule in Ta-
ble 1 with only one keyword spam. Similarly, regardless of the
combination of keywords found in the hit text for gaming servers
list or gaming abuse list, their rules can be disambiguated as well.
In some cases, such as for Web logs and Proxy logs, we can
obtain additional tags (labeled by square brackets in Column 3 of
Table 1). For Web logs we can obtain the access date and, if the data
exists, the operating system and browser that was used. Similarly,
in the case of Proxy logs, we can obtain the site that was accessed
by the IP address.
Hit text based tagging for Forums. The keyword-based ap-
proach fails when a URL maps to an Internet forum site. This is
because a number of non-correlated keywords may appear at a fo-
rum page. Likewise, forums are speciﬁc because an IP address can
appear at such a site for different reasons. Either it has been auto-
matically recorded by a forum post, or because a forum user delib-
erately posted a link (containing the given IP address) for various
reasons.
In the case of forums, we proceed as follows. First, we use a
post-date and username in the vicinity of the IP address to de-
termine if the IP address was logged automatically by a forum
post. Hence, we tag it as the forum user.
If this is not the
case, the presence of the following keywords: http:\, ftp:\,
ppstream:\, mms:\, etc. in front of the IP address string in the
hit text suggests that the user deliberately posted a link to a shared
resource on the forum. Consequently, we tag the IP address as an
http share or ftp share, or as a streaming node sup-
porting a given protocol (ppstream, mms, tvants, sop, etc.).
Because each IP address generates several search hits, multiple
tags can be generated for an IP address. Thus aggregating all the
tags corresponding to an IP address either reveals additional be-
havior or reafﬁrms the same behavior. For the ﬁrst case, consider
the scenario where an IP address hosts multiple services, which
would then be identiﬁed and classiﬁed differently and thereby gen-
erate different tags for that IP address, revealing the multiple facets
of the IP address’ behavior. In the second case, if an IP address’
behavior has been identiﬁed by multiple sites, then counting the
unique sites which reafﬁrm that behavior would generate higher
conﬁdence. In this paper, we consider this conﬁdence threshold as
1, i.e., even if one URL hit proclaims a particular behavior then we
classify the endpoint accordingly. We relegate trade-offs involved
in setting such a threshold to future exploration.
2.1.4 Examples
To illustrate the methodology, we provide the analysis of two
IP addresses and the corresponding websites returned as Google
hits: (i) 200.101.18.182 - inforum.insite.com, and (ii) 61.
172.249.13 - ttzai.com. The ﬁrst site contains the word forum
in the URL. Thus, the rapid URL match succeeds and we classify
the site as a forum. Next, since the site is classiﬁed as forum, we
examine the hit text via the forum-based approach; as we ﬁnd a
post date next to a username in the hit text, we tag the IP address as
a forum user.
In the second case, at ﬁrst the rapid URL match fails, since the
website cache does not contain an entry for ttzai.com. Thus,
we initially install an entry to this website in the hash table, initial-
ize a counter for number of IP addresses to 1 and log the IP address.
Whenever another IP address returns a hit from the same site, the
threshold of 2 is crossed. Then, we retrieve the last URL, and a
search for the keyword set through the web page reveals the pres-
ence of at least one keyword that can classify the site as a Forum
site. Further, we proceed to the tagging phase. Because http:\ is
found in front of the original IP address (61.172.249.13), the sys-
tem concludes that a user deliberately posted the IP address on the
forum - as a part of the link to a shared resource. Hence, it tags the
IP accordingly.
2.2 Where Does the Information Come From?
Here, we attempt to answer two questions. First, which sites
‘leak’ information about endpoints? While we have already hinted
at some of the answers, we provide more comprehensive statistics
next. Second, our goal is to understand if and how such ‘information-
leaking’ sites vary in different world regions.
Sites containing information about endpoints could be catego-
rized in the following groups:
• Web logs: Many web servers run web log analyzer programs
such as AWStats, Webalizer, and SurfStats. Such programs col-
lect information about client IP addresses, statistics about access
dates, host operating systems and host browsers. They parse the
web server log ﬁle and generate a report or a statistics webpage.
• Proxy logs: Popular proxy services also generate logs of IP
addresses that have accessed them. For instance, the Squid proxy
server logs the requests’ IP addresses, and then displays them on a
webpage.
• Forums: As explained above, Internet forums provide wealth
of information about endpoints. Some forums list the user IP ad-
dresses along with the user names and the posting dates in order to
protect against forum spam. Examples are inforum.insite.
com.br or www.reptilesworld.com/bbs. Likewise, very
frequently clients use Internet forums to post links containing (of-
ten illegal) CDs or DVDs with popular movies as either ftp, http,
or streaming shares. We explained above how our methodology
captures such cases.
• Malicious lists: Denial of service attacks, and client misbe-
havior in general, are a big problem in today’s Internet. One of
the ways to combat the problem is to track and publicize malicious
endpoint behavior. Example lists are: banlists, spamlists, badlists,
gaming abuse lists, adserver lists, spyware lists, malware lists, fo-
rum spammers lists, etc.
• Server lists: For communication to progress in the Internet, in-
N. America
Asia
Table 2: Website caches - Top entries
Nr
Site
en.wikipedia.org
robtex.com
projecthoneypot.org
extremetracking.com
botsvsbrowsers.com
cuwhois.com
proxy.ncu.edu.tw
comp.nus.edu.sg
quia.jp
1 whois.domaintools.com
2
3
4
5
6
7
8
9
10
Cache size: 827
A:adservers, B:blacklist, D:domaindb, F:forum, M:mail/spam, N:dnsdb , P:proxy cache, S:Web logs, T:torrent, W:bot detector
1 weblinux.ciasc.gov.br
2
3
4
5
6
7 www.tracemagic.net
8 www.luziania.com.br
9
10
Cache size: 728
Site
jw.dhu.edu.cn
projecthoneypot.org
info.edu.sh.cn
czstudy.gov.cn
qqdj.gov.cn
zhidao.baidu.com
1bl.org
cqlp.gov.cn
cache.vagaa.com
bid.sei.gov.cn
Nr
1
2
3
4
5
6
7
8
9
10
Cache size: 892
Info
Hits
338 D
F
263
255
BDN
217 M
202
S
182 W
151 D
P
132
116
S
108 M
Hits
1381
Info Nr
S
377 M
S
268
S
227
181
S
F
176
B
154
S
149
T
142
122
S
S. America
Site
projecthoneypot.org
robtex.com
redes.unb.br
pt.wikipedia.org
appiant.net
pgl.yoyo.org
netﬂow3.nhlue.edu.tw
Info
Hits
395
S
371 M
BDN
252
S
252
F
200
S
136
S
116
91
F
90 A
76
S
formation about servers, i.e., which IP address one must contact in
order to proceed, must be publicly available. Examples are domain
name servers, domain databases, gaming servers, mail servers, IRC
servers, router (POP) lists, etc.
• P2P communication: In p2p communication, an endpoint can
act both as a client and as a server. Consequently, an IP’s in-
volvement in p2p applications such as eMule, gnutella, edonkey,
kazaa, torrents, p2p streaming software, etc., becomes publicly vis-
ible in general. Example websites are emule-project.net,
edonkey2000.cn, or cache.vagaa.com, which lists torrent
nodes. Gnutella is a special case since Google can directly iden-
tify and list gnutella nodes using their IP addresses. Given that our
system is Google-based, it inherits this desirable capability.
All the above examples conﬁrm that publicly available informa-
tion about endpoints is indeed enormous in terms of size and se-
mantics. The key property of our system is its ability to automat-
ically extract all this information in a uniﬁed and methodical way.
Moreover, because we operate on top of Google, any new source
of information becomes quickly revealed and exploited.
Table 2 answers the second question: how different are the end-
point information sites in different world regions? In particular,
Table 2 shows top entries for three different world regions we ex-
plored (details provided in the next section).3 While some sites,
e.g., projecthoneypot.org or robtex.com, show global
presence, other top websites are completely divergent in different
world regions. This reveals a strong locality bias, a feature we ex-
plore in more depth in Section 4 below.
3. EVALUATION
Next, we demonstrate the diversity of scenarios in which uncon-
strained endpoint proﬁling can be applied. In particular, we show
how it can be used to (i) discover active IP ranges without actively
probing the same, (ii) classify trafﬁc at a given network and pre-
dict application- and protocol trends in absence of any operational
traces from a given network, (iii) perform a semantically-rich traf-
ﬁc classiﬁcation when packet-level traces are available, and (iv)
retain high classiﬁcation capabilities even when only sampled ﬂow-
level data is available.
Table 3 shows the networks we study in this paper. They belong
to Tier-1 ISPs representative of one of the largest countries in dif-
ferent geographic regions: Asia (China), South America (Brazil),
North America (US), and Europe (France). The Asian and S. Amer-
ican ISPs serve IPs in the /17 and /18 range, while the N. American
and European ISPs serve larger network ranges.
In most scenarios (Asia, S. and N. America), we manage to ob-
tain either packet-level (Asia and S. America) or ﬂow-level (N.
America) traces from the given ISPs. The packet-level traces are
3We omit details for the fourth region - Europe - due to space con-
straints.
Table 3: Studied networks
Asia
XXX.39.0.0/17
XXX.172.0.0/18
XXX.78.192.0/18
XXX.83.128.0/17
XXX.239.128.0/18
XXX.69.128.0/17
XXX.72.0.0/17
S. America
XXX.96.128.0/17
XXX.101.0.0/17
XXX.103.0.0/17
XXX.140.128.0/18
XXX.163.0.0/17
XXX.193.192.0/18
XXX.10.128.0/18
XXX.14.64.0/18
XXX.15.64.0/18
XXX.24.0.0/18
XXX.25.64.0/18
XXX.34.0.0/18
N. America
XXX.160.0.0/12
XXX.160.0.0/13
XXX.168.0.0/14
XXX.70.0.0/16
XXX.0.0.0/11
Europe
62.147.0.0/16
81.56.0.0/15