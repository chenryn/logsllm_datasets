|---|---|---|---|---|---|---|---||---|---|---|---|---|---|---|---|
| 7.1 |Experimental setup |Experimental setup |of 4.9x to 9x) and Presto (from an average of 5.3x to 7.5x) |of 4.9x to 9x) and Presto (from an average of 5.3x to 7.5x) |of 4.9x to 9x) and Presto (from an average of 5.3x to 7.5x) |ur |2500 |
| 7.1 |Experimental setup |Experimental setup |from earlier versions of Impala9. |from earlier versions of Impala9. |from earlier versions of Impala9. |ur |2500 || All the experiments were run on the same 21-node cluster. |All the experiments were run on the same 21-node cluster. |All the experiments were run on the same 21-node cluster. |from earlier versions of Impala9. |from earlier versions of Impala9. |from earlier versions of Impala9. |ur |2500 || All the experiments were run on the same 21-node cluster. |All the experiments were run on the same 21-node cluster. |All the experiments were run on the same 21-node cluster. |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |ur |2500 || Each node in the cluster is a 2-socket machine with 6-core |Each node in the cluster is a 2-socket machine with 6-core |Each node in the cluster is a 2-socket machine with 6-core |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |ur |2000 || Intel Xeon CPU E5-2630L at 2.00GHz. Each node has 64GB |Intel Xeon CPU E5-2630L at 2.00GHz. Each node has 64GB |Intel Xeon CPU E5-2630L at 2.00GHz. Each node has 64GB |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |ur |2000 || RAM and 12 932GB disk drives (one for the OS, the rest for |RAM and 12 932GB disk drives (one for the OS, the rest for |RAM and 12 932GB disk drives (one for the OS, the rest for |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |ur |2000 || RAM and 12 932GB disk drives (one for the OS, the rest for |RAM and 12 932GB disk drives (one for the OS, the rest for |RAM and 12 932GB disk drives (one for the OS, the rest for |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |per Ho |1500 || HDFS). |HDFS). |HDFS). |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |per Ho |1500 || We run a decision-support style benchmark consisting of a |We run a decision-support style benchmark consisting of a |We run a decision-support style benchmark consisting of a |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |per Ho |1500 || subset of the queries of TPC-DS on a 15TB scale factor data |subset of the queries of TPC-DS on a 15TB scale factor data |subset of the queries of TPC-DS on a 15TB scale factor data |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |ueries  |1000 || set. In the results below we categorize the queries based on |set. In the results below we categorize the queries based on |set. In the results below we categorize the queries based on |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |ueries  |1000 || the amount of data they access, into interactive, reporting, |the amount of data they access, into interactive, reporting, |the amount of data they access, into interactive, reporting, |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |ueries  |1000 || the amount of data they access, into interactive, reporting, |the amount of data they access, into interactive, reporting, |the amount of data they access, into interactive, reporting, |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |Q |500 || and deep analytic queries. |and deep analytic queries. |In particular, the interactive |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |Q |500 || bucket contains queries: q19, q42, q52, q55, q63, q68, q73, |bucket contains queries: q19, q42, q52, q55, q63, q68, q73, |bucket contains queries: q19, q42, q52, q55, q63, q68, q73, |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |Q |500 || and q98; the reporting bucket contains queries: q27, q3, q43, |and q98; the reporting bucket contains queries: q27, q3, q43, |and q98; the reporting bucket contains queries: q27, q3, q43, |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |Q |500 || q53, q7, and q89; and the deep analytic bucket contains |q53, q7, and q89; and the deep analytic bucket contains |q53, q7, and q89; and the deep analytic bucket contains |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |Q |500 || queries: q34, q46, q59, q79, and ss max. The kit we use for |queries: q34, q46, q59, q79, and ss max. The kit we use for |queries: q34, q46, q59, q79, and ss max. The kit we use for |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |320 	302 7.3 	Mutli-User Performance  	Completion Time (in secs)  	Impala’s superior performance becomes more pronounced 10 Users in multi-user workloads, which are ubiquitous in real-world 240 202 applications. Figure 7 (left) shows the response time of the four systems when there are 10 concurrent users submitting 160 queries from the interactive category. In this scenario, Impala outperforms the other systems from 6.7x to 18.7x when going 77 from single user to concurrent user workloads. The speedup varies from 10.6x to 27.4x depending on the comparison. 25 	37 Note that Impala’s speed under 10-user load was nearly half 5 	11 that under single-user load–whereas the average across the 0 alternatives was just one-fifth that under single-user load. Impala SparkSQL Presto 	Hive 0.13 |Q |500 || queries: q34, q46, q59, q79, and ss max. The kit we use for |queries: q34, q46, q59, q79, and ss max. The kit we use for |queries: q34, q46, q59, q79, and ss max. The kit we use for |Similarly, Figure 7 (right) compares the throughput of the |Similarly, Figure 7 (right) compares the throughput of the |Similarly, Figure 7 (right) compares the throughput of the |Q |500 || these measurements is publicly available7. |these measurements is publicly available7. |these measurements is publicly available7. |Similarly, Figure 7 (right) compares the throughput of the |Similarly, Figure 7 (right) compares the throughput of the |Similarly, Figure 7 (right) compares the throughput of the |Q |500 || these measurements is publicly available7. |these measurements is publicly available7. |these measurements is publicly available7. |four systems. Impala achieves from 8.7x up to 22x higher |four systems. Impala achieves from 8.7x up to 22x higher |four systems. Impala achieves from 8.7x up to 22x higher |Q |500 || For our comparisons we used the most popular SQL-on- |For our comparisons we used the most popular SQL-on- |For our comparisons we used the most popular SQL-on- |four systems. Impala achieves from 8.7x up to 22x higher |four systems. Impala achieves from 8.7x up to 22x higher |four systems. Impala achieves from 8.7x up to 22x higher |Q |500 || For our comparisons we used the most popular SQL-on- |For our comparisons we used the most popular SQL-on- |For our comparisons we used the most popular SQL-on- |throughput than the other systems when 10 users submit |throughput than the other systems when 10 users submit |throughput than the other systems when 10 users submit |Q |500 || Hadoop systems for which we were able to show results8: |Hadoop systems for which we were able to show results8: |Hadoop systems for which we were able to show results8: |throughput than the other systems when 10 users submit |throughput than the other systems when 10 users submit |throughput than the other systems when 10 users submit |Q |500 || Hadoop systems for which we were able to show results8: |Hadoop systems for which we were able to show results8: |Hadoop systems for which we were able to show results8: |queries from the interactive bucket. |queries from the interactive bucket. |queries from the interactive bucket. |Q |500 || Impala, Presto, Shark, SparkSQL, and Hive 0.13. Due to the |Impala, Presto, Shark, SparkSQL, and Hive 0.13. Due to the |Impala, Presto, Shark, SparkSQL, and Hive 0.13. Due to the |queries from the interactive bucket. |queries from the interactive bucket. |queries from the interactive bucket. |Q |500 || Impala, Presto, Shark, SparkSQL, and Hive 0.13. Due to the |Impala, Presto, Shark, SparkSQL, and Hive 0.13. Due to the |Impala, Presto, Shark, SparkSQL, and Hive 0.13. Due to the |7.4 |Comparing against a commercial RDBMS |Comparing against a commercial RDBMS |Q |500 || lack of a cost-based optimizer in all tested engines except |lack of a cost-based optimizer in all tested engines except |lack of a cost-based optimizer in all tested engines except |7.4 |Comparing against a commercial RDBMS |Comparing against a commercial RDBMS |Q |500 || Impala we tested all engines with queries that had been |Impala we tested all engines with queries that had been |Impala we tested all engines with queries that had been |7.4 |Comparing against a commercial RDBMS |Comparing against a commercial RDBMS |Q |500 || Impala we tested all engines with queries that had been |Impala we tested all engines with queries that had been |Impala we tested all engines with queries that had been |From the above comparisons it is clear that Impala is on |From the above comparisons it is clear that Impala is on |From the above comparisons it is clear that Impala is on |Q |500 || converted to SQL-92 style joins. For consistency, we ran |converted to SQL-92 style joins. For consistency, we ran |converted to SQL-92 style joins. For consistency, we ran |From the above comparisons it is clear that Impala is on |From the above comparisons it is clear that Impala is on |From the above comparisons it is clear that Impala is on |Q |500 || converted to SQL-92 style joins. For consistency, we ran |converted to SQL-92 style joins. For consistency, we ran |converted to SQL-92 style joins. For consistency, we ran |the forefront among the SQL-on-Hadoop systems in terms of |the forefront among the SQL-on-Hadoop systems in terms of |the forefront among the SQL-on-Hadoop systems in terms of |Q |500 || those same queries against Impala, although Impala produces |those same queries against Impala, although Impala produces |those same queries against Impala, although Impala produces |the forefront among the SQL-on-Hadoop systems in terms of |the forefront among the SQL-on-Hadoop systems in terms of |the forefront among the SQL-on-Hadoop systems in terms of |Q |500 || those same queries against Impala, although Impala produces |those same queries against Impala, although Impala produces |those same queries against Impala, although Impala produces |performance. But Impala is also suitable for deployment in |performance. But Impala is also suitable for deployment in |performance. But Impala is also suitable for deployment in |Q |500 || identical results without these modifications. |identical results without these modifications. |identical results without these modifications. |performance. But Impala is also suitable for deployment in |performance. But Impala is also suitable for deployment in |performance. But Impala is also suitable for deployment in |Q |500 || identical results without these modifications. |identical results without these modifications. |identical results without these modifications. |traditional data warehousing setups. In Figure 8 we compare |traditional data warehousing setups. In Figure 8 we compare |traditional data warehousing setups. In Figure 8 we compare |Q |500 || Each engine was assessed on the file format that it performs |Each engine was assessed on the file format that it performs |Each engine was assessed on the file format that it performs |traditional data warehousing setups. In Figure 8 we compare |traditional data warehousing setups. In Figure 8 we compare |traditional data warehousing setups. In Figure 8 we compare |Q |500 || Each engine was assessed on the file format that it performs |Each engine was assessed on the file format that it performs |Each engine was assessed on the file format that it performs |the performance of Impala against a popular commercial |the performance of Impala against a popular commercial |the performance of Impala against a popular commercial |Q |500 || best on, while consistently using Snappy compression to |best on, while consistently using Snappy compression to |best on, while consistently using Snappy compression to |the performance of Impala against a popular commercial |the performance of Impala against a popular commercial |the performance of Impala against a popular commercial |Q |500 || best on, while consistently using Snappy compression to |best on, while consistently using Snappy compression to |best on, while consistently using Snappy compression to |columnar analytic DBMS, referred to here as “DBMS-Y” due |columnar analytic DBMS, referred to here as “DBMS-Y” due |columnar analytic DBMS, referred to here as “DBMS-Y” due |Q |500 || ensure fair comparisons: Impala on Apache Parquet, Hive |ensure fair comparisons: Impala on Apache Parquet, Hive |ensure fair comparisons: Impala on Apache Parquet, Hive |columnar analytic DBMS, referred to here as “DBMS-Y” due |columnar analytic DBMS, referred to here as “DBMS-Y” due |columnar analytic DBMS, referred to here as “DBMS-Y” due |Q |500 || ensure fair comparisons: Impala on Apache Parquet, Hive |ensure fair comparisons: Impala on Apache Parquet, Hive |ensure fair comparisons: Impala on Apache Parquet, Hive |to a restrictive proprietary licensing agreement. We use a |to a restrictive proprietary licensing agreement. We use a |to a restrictive proprietary licensing agreement. We use a |Q |500 || 0.13 on ORC, Presto on RCFile, and SparkSQL on Parquet. |0.13 on ORC, Presto on RCFile, and SparkSQL on Parquet. |0.13 on ORC, Presto on RCFile, and SparkSQL on Parquet. |to a restrictive proprietary licensing agreement. We use a |to a restrictive proprietary licensing agreement. We use a |to a restrictive proprietary licensing agreement. We use a |Q |500 || 0.13 on ORC, Presto on RCFile, and SparkSQL on Parquet. |0.13 on ORC, Presto on RCFile, and SparkSQL on Parquet. |0.13 on ORC, Presto on RCFile, and SparkSQL on Parquet. |TPC-DS data set of scale factor 30,000 (30TB of raw data) |TPC-DS data set of scale factor 30,000 (30TB of raw data) |TPC-DS data set of scale factor 30,000 (30TB of raw data) |Q |500 || 7.2 |Single User Performance |Single User Performance |and run queries from the workload presented in the previous |and run queries from the workload presented in the previous |and run queries from the workload presented in the previous |Q |500 |
| 7.2 |Single User Performance |Single User Performance |paragraphs. We can see that Impala outperforms DBMS-Y |paragraphs. We can see that Impala outperforms DBMS-Y |paragraphs. We can see that Impala outperforms DBMS-Y |Q |500 || Figure 6 compares the performance of the four systems |Figure 6 compares the performance of the four systems |Figure 6 compares the performance of the four systems |by up to 4.5x, and by an average of 2x, with only three |by up to 4.5x, and by an average of 2x, with only three |by up to 4.5x, and by an average of 2x, with only three |Q |500 || on single-user runs, where a single user is repeatedly submit- |on single-user runs, where a single user is repeatedly submit- |on single-user runs, where a single user is repeatedly submit- |by up to 4.5x, and by an average of 2x, with only three |by up to 4.5x, and by an average of 2x, with only three |by up to 4.5x, and by an average of 2x, with only three |Q |500 || on single-user runs, where a single user is repeatedly submit- |on single-user runs, where a single user is repeatedly submit- |on single-user runs, where a single user is repeatedly submit- |queries performing more slowly. |queries performing more slowly. |queries performing more slowly. |Q |500 || ting queries with zero think time. Impala outperforms all |ting queries with zero think time. Impala outperforms all |ting queries with zero think time. Impala outperforms all |8. |ROADMAP |ROADMAP |Q |500 |
| alternatives on single-user workloads across all queries run. |alternatives on single-user workloads across all queries run. |alternatives on single-user workloads across all queries run. |8. |ROADMAP |ROADMAP |Q |500 || Impala’s performance advantage ranges from 2.1x to 13.0x |Impala’s performance advantage ranges from 2.1x to 13.0x |Impala’s performance advantage ranges from 2.1x to 13.0x |8. |ROADMAP |ROADMAP |Q |500 |
| and on average is 6.7x faster. Actually, this is a wider gap of |and on average is 6.7x faster. Actually, this is a wider gap of |and on average is 6.7x faster. Actually, this is a wider gap of |In this paper we gave an overview of Cloudera Impala. |In this paper we gave an overview of Cloudera Impala. |In this paper we gave an overview of Cloudera Impala. |Q |500 || 7 https://github.com/cloudera/impala-tpcds-kit  8 There are several other SQL engines for Hadoop, for exam- |7 https://github.com/cloudera/impala-tpcds-kit  8 There are several other SQL engines for Hadoop, for exam- |7 https://github.com/cloudera/impala-tpcds-kit  8 There are several other SQL engines for Hadoop, for exam- |Even though Impala has already had an impact on modern |Even though Impala has already had an impact on modern |Even though Impala has already had an impact on modern |Q |500 || 7 https://github.com/cloudera/impala-tpcds-kit  8 There are several other SQL engines for Hadoop, for exam- |7 https://github.com/cloudera/impala-tpcds-kit  8 There are several other SQL engines for Hadoop, for exam- |7 https://github.com/cloudera/impala-tpcds-kit  8 There are several other SQL engines for Hadoop, for exam- |data management and is the performance leader among SQL- |data management and is the performance leader among SQL- |data management and is the performance leader among SQL- |Q |500 || 7 https://github.com/cloudera/impala-tpcds-kit  8 There are several other SQL engines for Hadoop, for exam- |7 https://github.com/cloudera/impala-tpcds-kit  8 There are several other SQL engines for Hadoop, for exam- |7 https://github.com/cloudera/impala-tpcds-kit  8 There are several other SQL engines for Hadoop, for exam- |on-Hadoop systems, there is much left to be done. |on-Hadoop systems, there is much left to be done. |Our |Q |500 || ple Pivotal HAWQ and IBM BigInsights. Unfortunately, |ple Pivotal HAWQ and IBM BigInsights. Unfortunately, |ple Pivotal HAWQ and IBM BigInsights. Unfortunately, |on-Hadoop systems, there is much left to be done. |on-Hadoop systems, there is much left to be done. |Our |Q |500 || ple Pivotal HAWQ and IBM BigInsights. Unfortunately, |ple Pivotal HAWQ and IBM BigInsights. Unfortunately, |ple Pivotal HAWQ and IBM BigInsights. Unfortunately, |9 http://blog.cloudera.com/blog/2014/05/new-sql-choices- |9 http://blog.cloudera.com/blog/2014/05/new-sql-choices- |9 http://blog.cloudera.com/blog/2014/05/new-sql-choices- |Q |500 || as far as we know, these systems take advantage of the De- |as far as we know, these systems take advantage of the De- |as far as we know, these systems take advantage of the De- |9 http://blog.cloudera.com/blog/2014/05/new-sql-choices- |9 http://blog.cloudera.com/blog/2014/05/new-sql-choices- |9 http://blog.cloudera.com/blog/2014/05/new-sql-choices- |Q |500 || Witt clause and we are legally prevented from presenting |Witt clause and we are legally prevented from presenting |Witt clause and we are legally prevented from presenting |in-the-apache-hadoop-ecosystem-why-impala-continues- |in-the-apache-hadoop-ecosystem-why-impala-continues- |in-the-apache-hadoop-ecosystem-why-impala-continues- |Q |500 || comparisons against them. |comparisons against them. |comparisons against them. |to-lead/ |to-lead/ |to-lead/ |Q |500 |
| Completion Time (in secs) | 320 | 302
Single User
 | 302
Single User
 |  |  |  |
|---|---|---|---|---|---|---|
| Completion Time (in secs) |320 |302 Single User  |302 Single User  | | | |
| Completion Time (in secs) |320 |302 Single User  |302 Single User  | | | || Completion Time (in secs) | |302 Single User  |302 Single User  | | | |
| Completion Time (in secs) | |302 Single User  |302 Single User  | | | |
| Completion Time (in secs) | |302 Single User  |302 Single User  | | | |
| Completion Time (in secs) | |302 Single User  |302 Single User  | | | |
| Completion Time (in secs) | |302 Single User  |302 Single User  | | | |
| Completion Time (in secs) | | | | | | |tured row-oriented format, such as Json, Avro or XML, or as 	iments for an organization to do something useful with its
text. On the other hand, from the perspective of performance 	data.a column-oriented format such as Parquet is ideal. Letting the user manage the transition from one to the other is often a non-trivial task in a production environment: it essentially requires setting up a reliable data pipeline (recognition of new data files, coalescing them during the conversion pro-cess, etc.), which itself requires a considerable amount of engineering. We are planning on adding automation of the conversion process, such that the user can mark a table for auto-conversion; the conversion process itself is piggy-backed onto the background metadata and statistics gathering pro-cess, which additionally schedules conversion queries that run over the new data files.Data management in the Hadoop ecosystem is still lacking some of the functionality that has been developed for commer-cial RDBMSs over the past decades; despite that, we expect this gap to shrink rapidly, and that the advantages of an open modular environment will allow it to become the dominant data management architecture in the not-too-distant future.