NAT rule’s output from Ri, as it could have occurred on its
own; a NAT rule that translates X to Y does not prevent Y
from occurring in the absence of X. We process the NAT
rule as follows:
Ri = Ri+1 ∪ (exist(Ri+1 ∩ P (cid:2)
i , Mi) ∩ T (cid:2)
i )
Goto rules remove what they match, because that reach-
ability would have been sent to some other chain: Ri =
Ri+1 − Pi. Plusgoto rules have no effect: Ri = Ri+1.
However, goto and plusgoto rules are treated differently
when we branch back to them from another chain: in this
case, evaluation of the rulegroup begins at
the goto or
plusgoto rule, not at the end of the rulegroup. We therefore
begin at the goto/plusgoto rule i with everything that the rule
could have sent to the chain that we’re now coming from:
=.
For example, consider again the chain graph of Figure 2
and hypothesize trafﬁc traveling backwards through eth2.
We begin on Chain 3 with T =. Processing
backwards, we would arrive at the start of Chain 3 with
S = ∗. This propagates to the accept disposition of Chain 1,
and also to the goto rule in the middle of chain 2’s rulegroup.
Upon arrival at the goto rule, we compute Pi ∩ ∗, yielding
Ri = 2 → b; the only trafﬁc that could have been sent to
Chain 3 by this goto rule is Pi = 2 → b, so that is all that
could be propagated backwards. From chain 2, the result
2 → b becomes the input to the default disposition of Chain
1.
We can now traverse Chain 1’s rulegroup backwards, as
shown in the right-hand side of Figure 1. The input is T =.
The last rule in the rulegroup, “Accept 4 → b,” computes
Ri = (Ri+1− Pi)∪(A∩ Pi); as a result, Ri = ((2, 4) → b).
The NAT rule manipulates the contents of Ri in reverse,
121
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:13:13 UTC from IEEE Xplore.  Restrictions apply. 
translating 4 → ∗ back to 1 → ∗ but not removing 4 → ∗.
The resulting Ri = ((1, 2, 4) → b).
Finally, the ﬁrst ﬁltering rule acts on . From this, Pi∩ Ri = (1 → a), so it’s added to the ﬁnal
answer, R1 = ((1, 2, 4) → b, 1 → a). This is the sum total of
reachability that could enter eth0 and emerge from eth2
as part of our originally hypothesized set T =.
The discussion above focuses on trafﬁc through ﬁrewalls.
Addressing trafﬁc from a victim host that has its own rules,
or to a malicious server that has not disabled its own ﬁrewall,
uses similar principles. If the trafﬁc is from a victim host
with address X, we start at the interface’s outbound chain
with T = and travel backwards as before.
Trafﬁc to a ﬁrewalled malicious server, however, is more
complicated, because there are no explicit exit nodes –
any chain reachable from the inbound chain could provide
reachability to the host itself. The NetSPA system therefore
computes forward reachability via S =, keeping
track of all chains reached, and then performs reverse
reachability from all of those chains as potential exit nodes.
E. Non-Transparent Proxies and IPS Systems
Transparent proxies look just like inline ﬁrewalls. To use
a non-transparent proxy, however, a client machine must be
conﬁgured to explicitly connect to the proxy host, which
then makes the connection on the client’s behalf. From
a reachability perspective, the client only connects to the
proxy, but the proxy can then connect to anywhere else on
behalf of the client.
We model this situation in NetSPA via destination NAT.
We add a NAT rule of the form [ * -> X : DNAT to
* ], where X is the proxy server’s own IP and port number.
Other target values, such as protocol and port number, could
be wildcarded as desired. IPS systems that then restrict the
servers that can be contacted could be modeled by adding
deny rules after the DNAT rule.
NetSPA uses a similar trick to model the effect of an IPS.
Assuming a mapping from attack vector to vulnerabilities
exists, NetSPA models the IPS by treating it like a ﬁrewall.
NetSPA’s ﬁltering model has been extended to permit block-
ing trafﬁc based on vulnerability, adding vulnerability to the
normal tuple of source IP, destination IP, destination port,
and protocol.
F. Grouping Hosts and Firewalls
An I K matrix for representing reachability is typically
highly redundant; on typical networks, groups of interfaces
are treated identically by the ﬁrewalls and other ﬁltering
devices. Interfaces within such a group will have identical
rows in the matrix, as they will all be able to reach the same
ports. NetSPA identiﬁes these forward reachability groups
and computes only one row for each, saving both time and
space.
To do this, NetSPA collects the set N of all IP address
singletons and ranges used in all ﬁrewall rules. Two inter-
faces on the same subnet with identical rules can be grouped
together if their listening addresses are in the same subset
of N ; reachability for one is identical to reachability for the
other. The grouping operation on a network with I interfaces
and L rules is O(IL + I log I), but the savings obtained
by running the algorithm is substantial. In the ideal case
of a network with one interconnected internal subnet and
a ﬁrewall that does not differentiate between the network’s
hosts, the factor of I in the I K matrix size can effectively
drop out and be replaced by a constant. In the pathological
case of a network where each interface is treated differently,
then no savings are achieved. In practice, we’ve found that
real networks typically receive a substantial beneﬁt from this
approach. In the ﬁrst case explored in Section VI-B2, we
dropped from 65,025 cells to 3,825 – a factor of 17 savings
in time and memory.
NetSPA can use a similar approach to create reverse
reachability groups, combining redundant columns in the
I K matrix.
In addition, NetSPA groups hosts with identical personal
ﬁrewall rulesets by forming target reachability groups. Two
single-homed hosts are in such a group if they are on
the same subnet and their inbound chains are isomorphic;
that is, they use the same rulegroup and all of the chains’
dispositions are isomorphic. NetSPA’s reachability engine
can then traverse a target reachability group’s common rules
once to attempt reachability to every host in the group.
However, the extra context means that the system also knows
to traverse their chains, outbound and inbound, when trafﬁc
moves between members of the group.
VI. PERFORMANCE
To evaluate the scalability of the new system, we con-
ducted a number of measured tests on various synthetic
networks. All tests were executed on a 2.4GHz Pentium 4
computer running Linux with 1GB of RAM. Peak memory
measurements were done via Linux’s libmemusage.so
library. We measured runtime via wallclock. For timing
tests, the system was run ﬁve times, discarding the ﬁrst
result and averaging the remaining four. In all cases the
system posited an external attacker, computed reachability
as needed, constructed the attack graph, and computed
recommended remediation steps.
A. Full- and Partially-Synthetic Networks
We begin by comparing the new system’s ability to
aggregate personal ﬁrewalls to the previous system’s costly
workaround. We use a set of test data from a small 251-host
network. We placed identical synthetic personal ﬁrewalls
on 52 of the hosts and varied the number of rules in the
common ruleset from 0 to 10,000; these results are shown
in the top of Figure 3. We then varied the number of hosts
122
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:13:13 UTC from IEEE Xplore.  Restrictions apply. 
Performance vs. Number of Personal Firewalls
Performance vs. Number of Hosts (4 Enclaves)
Old System (time)
New System (time)
Old System (memory)
New System (memory)
Time
Memory
Time (w/ Personal FW)
Memory (w/ Personal FW)
40,960 hosts
)
B
M
Δ
(
e
g
a
s
U
y
r
o
m
e
M
)
s
d
n
o
c
e
s
:
s
e
t
u
n
i
m
(
e
m
T
i
Number of personal ﬁrewalls
Number of hosts
Performance vs. Personal Ruleset Size
Performance vs. Number of Firewall Rules (4 Enclaves)
Old System (time)
New System (time)
Old System (memory)
New System (memory)
Time
Memory
Time (w/ Personal FW)
Memory (w/ Personal FW)
16,384 rules
)
B
M
Δ
(
e
g
a
s
U
y
r
o
m
e
M
)
s
d
n
o
c
e
s
:
s
e
t
u
n
m
i
(
e
m
T
i
)
B
M
(
y
r
o
m
e
M
)
B
M
(
y
r
o
m
e
M
)
s
d
n
o
c
e
s
(
e
m
T
i
)
s
d
n
o
c
e
s
(
e
m
T
i
Number of rules
Number of rules per ﬁrewall
Figure 3. NetSPA Performance with Personal Firewalls; Old System of
[4] vs. New System
Figure 4. NetSPA Performance with Enclave, Rule, and Host Scaling;
New System
with personal ﬁrewalls from 0 to 52, ﬁxing the common
ruleset at 250 rules. These results are shown on the bottom
of Figure 3. In both cases we show the total time consumed,
as well as the change in memory consumption from the zero
point of the X axis. We show only the change in memory
so scaling effects can clearly be seen between the two
systems, as the differences in baseline memory requirements
are comparatively unimportant.
The beneﬁt of the new system is clear: adding additional
personal ﬁrewalls with a shared ruleset causes almost no
impact. Adding rules to the ruleset causes a roughly linear
increase, though this is difﬁcult to see because the system
remains very fast throughout the test. In practice, we would
not expect personal ﬁrewall rulesets to exceed 2,000 rules.
We conducted additional scalability experiments on the
synthetic network shown in Figure 5. As shown, the network
Outside
DMZ
Internal
Enclave 1
Enclave 2