# BasisDetect: A Model-Based Network Event Detection Framework

## Authors
- Brian Eriksson, UW-Madison
- Paul Barford, UW-Madison and Nemean Networks
- Rhys Alistair Bowden, University of Adelaide
- Nick G. Duffield, AT&T Research
- Joel Sommers, Colgate University
- Matthew Roughan, University of Adelaide

## Abstract
The ability to detect unexpected events in large networks can significantly enhance daily network operations. Despite extensive research over the past decade, existing anomaly detection tools remain underutilized due to high false alarm rates. In this paper, we introduce BasisDetect, a flexible and precise modeling framework designed to improve the accuracy of detecting unexpected network events. Using a small dataset with labeled anomalies, BasisDetect allows us to define and detect a wide range of anomalies in various types of network data, both from single sources and from multiple, potentially diverse sources. The framework learns network anomaly signal characteristics via a novel basis pursuit methodology. We demonstrate the feasibility of BasisDetect and compare it to previous detection methods using a combination of synthetic and real-world data. Our results show a 50% reduction in false alarms for single node datasets and over 65% reduction for synthetic network-wide data.

## Categories and Subject Descriptors
C.2.3 [Computer-Communication Networks]: Network Operations—Network Monitoring

## General Terms
Measurement, Performance

## Keywords
Anomaly Detection

### Permission
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.

IMC’10, November 1–3, 2010, Melbourne, Australia.
Copyright 2010 ACM 978-1-4503-0057-5/10/11 ...$10.00.

## 1. Introduction
Networks are complex, dynamic, and subject to external factors beyond the control of their operators. Network operators must continuously monitor their networks for faults and other events that could compromise their contractual commitments to customers. While standard protocols exist for well-understood faults (e.g., link failures), unforeseen faults are more challenging to detect because they are not predefined. These faults often manifest as unusual measurements, commonly referred to as anomalies. Detecting and diagnosing these anomalies quickly and effectively would significantly enhance network operations. Developing a practical and effective anomaly detection framework is the objective of our work.

Numerous studies over the past decade have focused on developing methods to detect anomalous events in networks. The typical approach involves measuring network traffic, establishing a profile for "normal" behavior, and then applying a method to detect deviations from this norm. Most prior studies have taken a one-size-fits-all approach, leading to issues with accuracy and high false alarm rates.

A low false alarm rate is critical in any anomaly detection system. False alarms waste operator time and discredit results, leading to a "cry wolf" syndrome where the system is ignored. Existing systems suffer from unacceptably high false alarm rates, exacerbated by anomalies polluting the data used to determine the normal profile. This paper aims to improve the accuracy of network event detection to make it an effective tool for network operators.

To address this problem, we introduce the BasisDetect framework. The primary intuition behind BasisDetect is that both normal traffic and anomalies have features that can be modeled and exploited for automated detection. For example, traffic has well-known diurnal and weekly cycles. By considering traffic as a superposition of waveforms and decomposing these into their component parts, we can build detection models that separate energy into normal and anomalous traffic. The BasisDetect framework consists of three components:
1. Learning potential anomaly signal features from a small set of labeled network data.
2. Decomposing traffic into non-anomalous and anomalous components using a novel basis pursuit methodology.
3. Merging detected anomalous behavior using state-of-the-art statistical techniques.

Our framework also aims to be applicable to different data types and in both single-node and network-wide contexts. Prior work typically focuses on either spatial or temporal detection, but our combined approach offers significant opportunities to improve detection accuracy. We treat network-wide detection as a data fusion problem, reducing false alarms through the use of multiple time-series signals.

We rigorously assess the capabilities of our model-based detection methodology using both synthetic and real-world data. Our evaluation includes NetFlow data from a single router, synthetic data, and Internet2 byte count data. Results show that BasisDetect identifies all labeled anomalies with a 50% reduction in false alarms compared to the best competing methodology. For synthetic data, BasisDetect detects all injected anomalies with a false alarm rate over 65% lower than the current state-of-the-art. Finally, for Internet2 data, BasisDetect identifies PCA anomaly locations with 40% fewer false alarms than a competing state-of-the-art method.

The remainder of this paper is organized as follows. Section 2 provides background and related work. Section 3 describes the datasets used in our evaluation. Section 4 introduces the BasisDetect framework. Section 5 details our temporal signal decomposition methodology. Section 6 describes our intelligent data fusion methodology. Section 7 summarizes the BasisDetect methodology. Section 8 evaluates the results of applying our method and several other well-known methods to the given datasets. Section 9 concludes our work and discusses future directions.

## 2. Background and Related Work
Anomaly detection is a broad field, and we focus on studies directly relevant to our work. Our specific focus is on vector time-series data. Initial work in this area considered how Principal Component Analysis (PCA) would perform in a network-wide setting. Prior work primarily involved transforming the data temporally, assuming anomalies would stand out in the transformed space (e.g., wavelets, Exponentially Weighted Moving Average (EWMA), Fourier filtering). Anomalies were generated for each set of measurements. PCA's key benefits include taking advantage of the non-scalar nature of network data and finding an optimal linear transform to reveal inconsistent data points.

Zhang et al. showed how much of the prior work on anomaly detection, including PCA, could be seen in a single framework and highlighted the sparseness of anomalies as a useful feature. The PCA framework decomposes a traffic matrix into vector components capturing variance across all links or flows. The most dominant components represent standard operating characteristics, while less dominant components represent residual traffic. The amount of energy in the residual component determines whether an anomaly has occurred.

However, PCA has limitations, such as sensitivity to tuning parameters and corruption of modeled traffic components by large anomalies. Detected anomalies cannot be localized to specific links or routers, and PCA can lead to masking, where one anomaly hides another. Furthermore, the residual traffic does not necessarily represent anomalies, leading to false alarms. Additionally, PCA-based methods are vulnerable to attacks.

The Distributed Spatial Anomaly Detection technique addresses some of these limitations by generating test statistics at each router, reducing the need for centralized computation. However, this approach ignores temporal correlations between network anomaly events and considers only traffic volume. Detected anomalies may not be of interest to network administrators.

Our methodology uses non-parametric statistical techniques and an estimated feature vector of detected anomaly energy instead of raw packet counts. We leverage prior work on basis decomposition of signals, allowing for non-exact signal representation and penalizing selected dictionary signals.

## 3. Datasets
We use three datasets to evaluate our model-based detection methodology: synthetic traffic data, GEANT data, and Abilene real-world data.

### 3.1 Synthetic Traffic Data
Simulation is necessary for accurate testing of anomaly detection algorithms. Ringberg et al. explain the need for simulation, including the requirement for ground truth information, the need for many results to form accurate probability estimates, and the ability to vary parameters in a controlled manner. Our simulations generate a spatial traffic matrix using a gravity model, extended into the temporal domain with a periodic signal. Gaussian noise is added, and we consider a range of network sizes and anomaly lengths.

### 3.2 GEANT Data
This dataset contains time-series data from a GEANT network backbone router in Vienna, Austria, collected from January 14th to February 24th, 2009. The dataset includes packet counts, byte counts, and IP entropy, sampled in 1-minute intervals. Labeled anomalies include Denial of Service (DoS) attacks, portscan events, and Distributed Denial of Service (DDoS) attacks. This dataset is limited to single-node analysis but provides detailed anomaly annotations.

### 3.3 Abilene Real-World Data
This dataset consists of byte counts from the Abilene Internet2 backbone network, recorded from April 7th to April 13th, 2003, across 11 Points of Presence (PoPs) with 41 network links. Data is sampled in 10-minute intervals. This dataset is unlabeled, so we use it to study how BasisDetect detects anomalies found by previous network-wide anomaly detection algorithms.

## 4. BasisDetect Overview
BasisDetect is an automated framework for detecting network anomalies, divided into three components:
1. **Anomalous Dictionary Construction from Labeled Set**: Extracts signal characteristics from a training set of labeled anomalies.
2. **Anomaly Decomposition using Penalized Basis Pursuit**: Uses a novel basis pursuit methodology to decompose traffic into non-anomalous and anomalous components.
3. **Intelligent Data Fusion Methodology**: Merges detected anomalous behavior using advanced statistical techniques.

These components are predicated on having a small initial set of network data with labeled anomalies to learn event characteristics and optimize algorithm parameters.