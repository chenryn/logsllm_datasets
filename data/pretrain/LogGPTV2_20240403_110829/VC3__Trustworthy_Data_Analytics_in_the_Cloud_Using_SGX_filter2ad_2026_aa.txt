title:VC3: Trustworthy Data Analytics in the Cloud Using SGX
author:Felix Schuster and
Manuel Costa and
C&apos;edric Fournet and
Christos Gkantsidis and
Marcus Peinado and
Gloria Mainar-Ruiz and
Mark Russinovich
2015 IEEE Symposium on Security and Privacy
2015 IEEE Symposium on Security and Privacy
VC3: Trustworthy Data Analytics in the Cloud using SGX
Felix Schuster∗, Manuel Costa, C´edric Fournet, Christos Gkantsidis
Marcus Peinado, Gloria Mainar-Ruiz, Mark Russinovich
Microsoft Research
Abstract—We present VC3, the ﬁrst system that allows users
to run distributed MapReduce computations in the cloud while
keeping their code and data secret, and ensuring the correctness
and completeness of their results. VC3 runs on unmodiﬁed
Hadoop, but crucially keeps Hadoop, the operating system and
the hypervisor out of the TCB; thus, conﬁdentiality and integrity
are preserved even if these large components are compromised.
VC3 relies on SGX processors to isolate memory regions on
individual computers, and to deploy new protocols that secure
distributed MapReduce computations. VC3 optionally enforces
region self-integrity invariants for all MapReduce code running
within isolated regions, to prevent attacks due to unsafe memory
reads and writes. Experimental results on common bench-
marks show that VC3 performs well compared with unprotected
Hadoop: VC3’s average runtime overhead is negligible for its
base security guarantees, 4.5% with write integrity and 8% with
read/write integrity.
I. INTRODUCTION
Cloud providers provision thousands of computers into data
centers and make them available on demand. Users rent this
computing capacity to run large-scale distributed computations
based on frameworks such as MapReduce [4], [20]. This is a
cost-effective and ﬂexible arrangement, but it requires users to
trust the cloud provider with their code and data: while data
at rest can easily be protected using bulk encryption [35],
at some point, cloud computers typically need access to
the users’ code and data in plaintext
in order to process
them effectively. Of special concern is the fact that a single
malicious insider with administrator privileges in the cloud
provider’s organization may leak or manipulate sensitive user
data. In addition, external attackers may attempt to access this
data, e. g., by exploiting vulnerabilities in an operating system
or even a hypervisor deployed in the cloud infrastructure.
Finally, attackers may also tamper with users’ computations
to make them produce incorrect results. Typically, cloud users
hope for the following security guarantees:
I Conﬁdentiality and integrity for both code and data; i. e.,
the guarantee that they are not changed by attackers and
that they remain secret.
II Veriﬁability of execution of the code over the data; i. e.,
the guarantee that their distributed computation globally
ran to completion and was not tampered with.
In theory, multiparty computation techniques may address
these demands. For
instance, data conﬁdentiality can be
achieved using fully homomorphic encryption (FHE), which
enables cloud processing to be carried out on encrypted
*Work done while at Microsoft Research; afﬁliated with Horst G¨ortz Institut
(HGI) at Ruhr-Universit¨at Bochum, Germany.
[22]. However, FHE is not efﬁcient for most com-
data
putations [23], [65]. The computation can also be shared
between independent parties while guaranteeing conﬁdential-
ity for individual inputs (using e. g., garbled circuits [29])
and providing protection against corrupted parties (see e. g.,
SPDZ [19]). In some cases, one of the parties may have
access to the data in the clear, while the others only have
to verify the result, using zero-knowledge proofs (see e. g.,
Pinocchio [48], Pantry [13], and ZQL [21]). Still, our goals
cannot currently be achieved for distributed general-purpose
computations using these techniques without losing (orders
of magnitude of) performance. Other systems use speciﬁc
types of computation and provide practical guarantees, but do
not protect all code and data (see e. g., CryptDB [50] and
Cipherbase [6]).
We present Veriﬁable Conﬁdential Cloud Computing (VC3),
a MapReduce framework that achieves the security guarantees
(I and II) formulated above, with good performance. Our threat
model accounts for powerful adversaries that may control
the whole cloud provider’s software and hardware infrastruc-
ture, except for the certiﬁed physical processors involved in
the computation. Denial-of-service, side-channels, and trafﬁc-
analysis attacks are outside the scope of this work.
Our main contribution is the design, implementation, and
evaluation of a practical system that integrates hardware prim-
itives, cryptographic protocols, and compilation techniques.
We use trusted SGX processors [3], [27], [41] as a building
block, but we need to solve several challenges not directly
addressed by the hardware. The ﬁrst is to partition the system
into trusted and untrusted parts, to minimize its TCB. VC3
runs on unmodiﬁed Hadoop, but our design crucially keeps
Hadoop, the operating system and the hypervisor out of the
TCB. Thus, our conﬁdentiality and integrity guarantees hold
even if these large software components are compromised. To
keep the TCB small in our design, users simply write the usual
map and reduce functions in C++, encrypt them, bind them
to a small amount of code that implements our cryptographic
protocols, and ﬁnally upload the code to the cloud. On each
worker node, the cloud operating system loads the code into
a secure region within the address space of a process and
makes use of the security mechanisms of SGX processors to
make the region inaccessible to the operating system and the
hypervisor. Subsequently, the code inside the region runs our
key exchange protocol, decrypts the map and reduce functions,
and runs the distributed computation that processes the data.
By comparison, recent work [9] proposes loading a library
variant of Windows 8 together with an application into an
SGX-isolated region; this allows running unmodiﬁed Windows
© 2015, Felix Schuster. Under license to IEEE.
© 2015, Felix Schuster. Under license to IEEE.
DOI 10.1109/SP.2015.10
DOI 10.1109/SP.2015.10
38
38
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:24 UTC from IEEE Xplore.  Restrictions apply. 
binaries, but results in a TCB that is larger than VC3’s by
several orders of magnitude.
The second challenge is to guarantee integrity for the whole
distributed computation, since the processors guarantee only
integrity of memory regions on individual computers. We thus
propose an efﬁcient job execution protocol that guarantees the
correct and conﬁdential execution of distributed MapReduce
jobs: the computing nodes produce secure summaries of the
work they perform, and they aggregate the summaries they
receive from their peers. By verifying the ﬁnal summaries
included in the results, the user can check that the cloud
provider did not interfere with the computation. At the same
time,
the cloud provider can freely schedule and balance
the computation between the nodes, as long as all data is
eventually processed correctly.
The ﬁnal challenge is to protect the code running in the
isolated memory regions from attacks due to unsafe memory
accesses. SGX processors allow this code to access the en-
tire address space of its host process, thus unsafe memory
accesses can easily leak data or enable other attacks. Since
implementing full memory safety for C/C++ [43], [44], [60]
is expensive, we instead provide a compiler that efﬁciently
enforces two region self-integrity invariants for code in an
isolated region: region-write-integrity which guarantees that
writes through pointers write only to address-taken variables
or heap allocations in the isolated region, and that indirect call
instructions target only address-taken functions in the region;
and region-read-write-integrity, which further guarantees that
reads through pointers read only from addresses inside the
region. Users who want these additional security assurances
may use our compiler.
We implemented VC3 for the popular Hadoop distribution
HDInsight on the Windows operating system. Our implemen-
tation is based on the new hardware security mechanisms
of Intel SGX, but it could in principle target other secure
computing technologies [46]. Experimental results on com-
mon benchmarks show that VC3 performs well compared
with unprotected Hadoop; VC3’s average runtime overhead
is negligible for its base security guarantees, 4.5% with write
integrity and 8% with read/write integrity.
In summary we make the following contributions:
• We describe the design and implementation of VC3, the
ﬁrst system executing MapReduce jobs with good performance
while guaranteeing conﬁdentiality and integrity of code and
data, as well as the correctness and completeness of the
results. We propose a partitioning of the system that achieves
a small TCB: we keep Hadoop, the operating system and the
hypervisor out of the TCB. Our design runs on unmodiﬁed
Hadoop and works well with Hadoop’s scheduling and fault-
tolerance services.
• We design and implement two new security protocols,
for each MapReduce job, ﬁrst for cloud attestation and key
exchange, then for running the job and gathering evidence of
its correct execution. We establish their security by reduction
to standard cryptographic assumptions. The security proofs
appear in the extended version of this paper [55].
Input 
Splits
Intermediate
Key-Value Pairs
Output
Key-Value Pairs
M
M
M
Step 2
(mapping)
R
R
Step 3
(reducing)
Output
Input
Step 1
(splitting)
Fig. 1: The steps of a MapReduce job as discussed in this work with mappers
(M) and reducers (R).
• We design and implement efﬁcient, compiler-based,
region-write-integrity and region-read-write-integrity invari-
ants for all user code running within isolated regions.
• We report on the performance of a practical
imple-
mentation of VC3 under realistic conditions by running 7
applications on a Hadoop cluster.
We proceed as follows: we provide background (§II), in-
troduce our adversary model (§III), present an overview of
our design (§IV), present our cryptographic protocols (§V and
§VI), describe our region self-integrity invariants and how to
enforce them (§VII), discuss limitations (§VIII), present our
implementation (§IX), evaluate our approach (§X), discuss
related work (§XI), and conclude (§XII).
II. BACKGROUND
A. MapReduce
MapReduce [20] is a popular programming model for process-
ing large data sets: users write map and reduce functions, and
the execution of both functions is automatically parallelized
and distributed.
The abstract data-ﬂow of a parallel MapReduce job is de-
picted in Figure 1. Each job is a series of three steps: splitting,
mapping, and reducing. In the splitting step, the framework
breaks raw input data into so called input splits. Input splits are
then distributed between mappers. Each mapper node parses
its splits into input key-value pairs, and calls the map function
on each of them to produce intermediate key-value pairs. The
framework groups these pairs by key and distributes them
between reducers (partitioning and shufﬂing). Each reducer
node calls the reduce function on sets of all the values with
the same key to produce output key-value pairs.
Probably the most popular framework for the execution and
deployment of MapReduce jobs is Hadoop [4]. Hence, we
chose it as our default execution environment.
B. Intel SGX
SGX [3], [32], [41] is a set of x86-64 ISA extensions that
makes it possible to set up protected execution environments
(called enclaves) without requiring trust in anything but the
processor and the code users place inside their enclaves.
Enclaves are protected by the processor: the processor controls
access to enclave memory. Instructions that attempt to read
or write the memory of a running enclave from outside
the enclave will fail. Enclave cache lines are encrypted and
3939
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:24 UTC from IEEE Xplore.  Restrictions apply. 
integrity protected before being written out to RAM. This
removes a broad class of hardware attacks and limits the
hardware TCB to only the processor. The software TCB is
only the code that users decide to run inside their enclave.
Enclave code can be called from untrusted code by means
of a callgate-like mechanism that transfers control to a user-
deﬁned entry point inside the enclave. Enclave execution may
be interrupted due to interrupts or traps. In such cases, the
processor will save the register context to enclave memory and
scrub the processor state before resuming execution outside the
enclave. Enclaves reside within regular user mode processes.
Enclave code can access the entire address space of its host
process. This feature allows for efﬁcient interaction between
enclave code and the outside world.
SGX supports sealed storage and attestation [3]. While
different in many details, these features have the same basic
purpose as sealed storage and attestation in other trusted com-
puting hardware. During enclave construction (by untrusted
software), the processor computes a digest of the enclave
which represents the whole enclave layout and memory con-
tents. This digest is roughly comparable to the PCR values of
the TPM [62]. Untrusted software, like the operating system
(OS) or the hypervisor, can freely interfere with enclave
creation, but such interference will cause the processor to
register a different digest for the enclave. The sealing facilities
provide each enclave with keys that are unique to the processor
and the enclave digest. Local attestation allows an enclave to
prove to another enclave that it has a particular digest and
is running on the same processor. This privileged mechanism
can be used to establish authenticated shared keys between
local enclaves. It also enables the deployment of enclaves that
support remote attestation. To this end, each SGX processor is
provisioned with a unique asymmetric private key that can be
accessed only by a special quoting enclave (QE) [3]. We refer
to this special QE as SGX QE. The SGX QE signs digests of
local enclaves together with digests of data produced by them,
creating so called quotes. A quote proves to a remote veriﬁer
that certain information came from a speciﬁc enclave running
on a genuine SGX processor.
C. Cryptographic Assumptions
We now introduce standard notations and security assumptions
for the cryptography we use.
We write m | n for the tagged concatenation of two
messages m and n. (That is, m0 | n0 = m1 | n1 implies
both m0 = m1 and n0 = n1.)
Cryptographic Hash, PRF, and Enclave Digest
We rely on a keyed pseudo-random function, written
PRFk(text) and a collision-resistant cryptographic hash func-
tion, written H(text). Our implementation uses HMAC and
SHA-256.
We write EDigest(C) for the SGX digest of an enclave’s
initial content C. We refer to C as the code identity of an
enclave. Intuitively, EDigest provides collision resistance; the
SGX speciﬁcation [32] details its construction.
Public-key Cryptography
We use both public-key encryption and remote attestation