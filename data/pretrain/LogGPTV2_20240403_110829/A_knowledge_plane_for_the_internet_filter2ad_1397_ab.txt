necessary  that  the  information  about  network  configuration  and 
about user-observed problems be in the same framework.  
A  related  example  concerns  overlay  network  such  as  CDNs.  It  is 
easy  to  imagine  that  one  component  of  the  KP  is  topology  and 
performance  information  that  a  CDN  could  use  to  position  its 
delivery nodes “close” to users. This information could come from a 
diversity  of  sources  such  as  “network  weather”  services,  user-
reported  experience,  and  ISPs,  and  would  include  not  just  traffic 
measurements,  but 
traffic 
restrictions and local firewall restrictions (perhaps the “users” can’t 
receive  certain  types  of  content).  The  interested  parties  (users, 
CDNs)  benefit  from  having  this  information  integrated  and 
presented in a consolidated form. 
There  are  some  cases  where  the  KP  may  be  able  to  resolve  a 
problem on its own. If it discovers that the reason for a problem is a 
low-level decision that is not material to the high-level goals of the 
operators, it might change the decision. But to determine if a change 
is appropriate, KP needs access to the reasoning behind the setting. 
So the knowledge about planning needs to be in the same context as 
the repair problem. 
When  a component of the network makes a low-level observation 
about a possible anomaly, it has no idea what the relevance actually 
is.  This  observation  might  trigger  a  repair,  a  reconfiguration,  a 
notification to a network operator in a distant part of the network, a 
security alert, or something else quite different. So observations on 
network  conditions  cannot  be  thought  of  as  being  a  part  of  one 
problem space, but instead as being a part of the KP.   
We recognize that point solutions to specific problems may get part 
of  the  way  more  rapidly  that  the  general  solution  postulated here. 
But  the  core  of  our  hypothesis  is  that  to  get  to  the  final  goal:  a 
network  that  can  configure  itself,  that  can  explain  itself,  that  can 
repair  itself,  and  does  not  confound  the  user  with  mysteries,  the 
approach  based  on  the  combination  of  point  solutions  will  not 
succeed.  
2.3  Why a Cognitive System? 
Our objectives for the Knowledge Plane require it to meet a number 
of significant challenges: 
• 
It  must  function  usefully  in  the  presence  of  incomplete, 
inconsistent, and possibly misleading or malicious information. 
System failures, information filtering for privacy or competitive 
reasons,  and  finite  network  resources  are  just  some  of  the 
forces conspiring to create this requirement. 
It must perform appropriately in the presence of conflicting or 
inconsistent  higher-level  goals  among  the  Internet’s  different 
stakeholders.  This  is  a  manifestation  of  the  tussle  dilemma 
discussed in [12]. 
It must operate effectively in the face of generality, including 
the  introduction  of  new  technologies  and  applications  not 
conceived  of  at  the  time  of  its  design,  and  in  the  face  of  a 
highly  dynamic  environment,  including  both  short-term  and 
long-term  changes  in  the  structure  and  complexity  of  the 
underlying network.  
• 
• 
We  hypothesize  that  these  challenges  cannot  be  met  by  analytical 
solutions,  because  analytical  solutions  generally  require  complete 
information,  precise  problem  formulations,  and  a  relatively  static 
operating  environment.  Instead,  we  suggest 
that  “cognitive” 
techniques  will  be  needed.  The  key  benefit  of  these  techniques  is 
their potential to perform effectively, and to evaluate and improve 
their  own  performance,  in  the  presence  of  complex,  inconsistent, 
dynamic,  and  evolving  environments.  We  discuss  two  defining 
characteristics of a cognitive knowledge plane. 
First,  the  KP  must  eventually  “close  the  loop”  on  the  network  as 
does an ordinary control system.  As we gain experience and trust, 
the knowledge plane will first enable a recognize-explain cycle, then 
a  recognize-explain-suggest  cycle,  and  ultimately  a  recognize-act 
cycle  for  many  management  tasks.  Because  the  knowledge  plane 
must be more general and flexible than standard control systems, we 
look elsewhere for additional inspiration. Architectures inspired by 
theories of human cognition [18] have achieved some successes and 
hint  at  one approach. In the knowledge plane context, a cognitive 
architecture  would  of  course  be distributed and decentralized, and 
the  partitioning  would  be  effected  in  part  to  support  divergent 
interests of network stakeholders. 
Second,  the KP must be able to learn and reason. Learning is the 
principled accumulation of knowledge, and can take place through 
many means:  by trial and error, by instruction, by generalization, by 
analogy,  through  problem  solving  and  mental  search,  and  more.  
Some learning approaches require human involvement, and some do 
not. In a static problem environment, one simple enough to admit of 
analytic solution, learning is irrelevant. But IP networks, by design 
and  intent,  are  constantly  evolving  in  many  dimensions,  and  are 
infinite  in  potential  configurations.  To  the  extent  possible,  when 
new  situations  are  recognized  or  new  actions  performed  and 
evaluated, the knowledge plane should improve:  its knowledge base 
should grow in useful ways. The first and most immediate challenge 
of 
the  behavior,  dependencies,  and 
requirements  of  applications  through  the  obscuring  veil  of  our 
existing transparent data plane. 
Reasoning involves the composition of existing knowledge to draw 
new  inferences  and  beliefs.  Reasoning  processes  can  translate 
declarative  knowledge  (whether  handcrafted  or  learned)  into 
interpretations  of  observations  and  decisions  about  actions.  If  we 
wish  the  network  of  the  future  to  support  high-level  goals  and 
constraints,  we  will  need  reasoning  methods  that  can  operate  on 
these abstractions. 
In the long run, an interesting and important function of reasoning in 
the knowledge plane will be to support mediation between users and 
operators  whose  goals  may  conflict  with  each  other  and/or  with 
fixed design constraints. The inevitability of such conflicts suggests 
that we must develop new techniques for representing and reasoning 
about  constraints  and  policies.  Initially,  these  representations  will 
need to be inferred from low-level configurations and actions, but 
the ultimate goal is to express goals and policies at a high level and 
use those to generate low-level configurations.  
Even in the short run we can bring to bear a great deal of existing 
research  on  the  design  and  construction  of  a  knowledge  plane.  
Experience with cognitive architectures [18], recent work in multi-
agent  systems  [22],  and  the  emerging  field  of  algorithmic  game 
theory may prove directly useful.  However, the networking context 
also  raises  many  challenges  that  will  stretch  the  current  state  of 
cognitive systems and redirect research in new and intriguing ways 
[19,20]. 
to  model 
learning 
is 
3.  What is the Knowledge Plane Good For?  
At a high level, we proposed a unified goal for the KP: build a new 
generation  of  network  by  allowing  it  to  have  a  view  of  what  it 
supposed to be, and what it is supposed to be doing. To achieve this 
goal, there are more specific problem domains to be supported. Here 
we discuss in more detail some of them. 
Fault  diagnosis  and  mitigation:  Today,  when  some  part  of  the 
Internet fails, it is almost impossible for the end user to tell what has 
happened,  to  figure  out  who  should  be  notified,  or  what  to  do  to 
correct the fault. If we take the Internet of today as the starting point, 
it is appealing to imagine a command that a user can run to demand 
an  explanation  when  something  seems  to  be  broken.    This  is  the 
WHY(problem-x) command: why is x broken? So, for instance, the 
user might ask, “Why can’t I get to www.acm.org?”  
However, the WHY formulation is not bold enough. An over-bold 
alternative  would  be  that  if  the  KP  is  smart  enough,  the  network 
should never fail. In this case, there is no need for WHY.  But this 
ambition  is  fundamentally  flawed.  In  some  cases,  only  a  human 
knows enough to determine if what is happening is actually a fault. 
When Dave unplugs his laptop and puts it in his briefcase, there may 
be some applications that suddenly stop working, but this is not a 
fault. It is what Dave intended, and if some semi-smart KP wakes up 
each  time  he  disconnects  his  laptop  and  asks  if  he  wants  to 
reconnect it, this is a nightmare, not a success. So there will be times 
when  only  a  person  can  give  the  KP  guidance.  Instead  of 
WHY(problem-x),  this  is  FIX(problem-x).  The  user  is  saying  that 
something is broken, and make it right.   
Is this enough guidance that the KP can correct what is wrong? In 
fact, the interesting examples are when the “problem” is caused by 
conflicting  specifications  or  constraints  that  come  from  different 
people.  One  may  say  FIX(this  game  I  just  installed  that  does  not 
work), and the reason it is failing is that the ISP has blocked that 
game. One may say FIX(lousy bandwidth) but the problem is that 
one  has  exceeded  one’s  usage  quota  and  the  ISP  is  rate-limiting. 
These are cases where the KP may not be able to resolve the matter. 
What we might strive for, however, is a KP that can either resolve a 
problem or say why not. So one answer to FIX(problem-x) may be 
CANNOT(reason-y). And if the system does fix something, it may 
want  to  tell  a  person that this happened, in case there is a further 
action that only a person can take.  
This example suggests that the interaction between the user and the 
KP  is  bi-directional  and  expressive.  And  of  course,  the  KP  may 
communicate with many entities about a problem. The demand from 
a user FIX(broken-game) might trigger a message back to the user 
that the game is blocked, but might also trigger a message to the ISP 
that it has an unhappy user.  
A  further  extension  of  this  story  is  that  the  KP  can  provide  an 
assistant  for  user  and  managers,  an  agent  that  watches  what  the 
people do, and learns over time what is normal and what is not. So a 
KP agent on Dave’s laptop  might learn that Dave unplugs it all the 
time, while an agent on Dave’s desktop machine  might realize that 
he never disconnects it, and risk bothering Dave to ask if he meant 
to do that. In this way, the problem of fault diagnosis and mitigation 
has a learning component. 
Once the FIX(problem-x) function has been implemented in the KP, 
programs as well as people can use it. As the user’s agent learns, it 
should more and more often give this signal on its own. And other 
programs,  such  as  application  code,  may  detect  and  signal  that 
something  is  wrong.  The  KP  will  have  to  decide  how  much 
credence to give these signals, depending on where they come from. 
Behind  the  scenes,  the  FIX  command  will  trigger  a  range  of 
activities  in  the  KP.  The  FIX  command  would  start  with  a  local 
component  that  runs  on  the  user’s  machine,  and  then  exchanges 
information  with  the  KP  to  figure  out  what  is  wrong.  The 
diagnostics  can  check  out  functions  at  all  levels,  from  packet 
forwarding  to  application  function.  There  are  several  current 
research projects that this application could build on [13,14]. 
Once  the  end  node  has  performed  what  diagnosis  it  can,  the  next 
stage is for the tool to add assertions to the shared knowledge plane 
about  what  it  has  discovered,  and  ask  the  KP  for  relevant 
information. This contribution to the knowledge plane allows all the 
users on the network collectively to build a global view of network 
and  service  status.  This  data  can  be  combined  with  information 
derived from measurement efforts now going on across the Internet 
that attempt to build an overall model of network status [9,15]. Such 
aggregation is important if the failure is one that affects lot of users.  
Automatic  (re)configuration:  The  dynamic  routing  of  the  original 
Internet  did  not  take  into  account  administrative  and  policy 
constraints,  so  routing  today  is  more  and  more  defined  by  static 
policy  tables.  This  means  that  devices  such  as  routers  are 
increasingly  manually  configured  and  managed.  Static  tables  and 
manual  configuration  make  the  network  brittle  to  failure,  hard  to 
change, and even harder to reason about globally.  Imagine, as part 
of  the  KP,  a  configuration  manager  for  a  region  of  the  Internet, 
which would accept high-level assertions about how the components 
of  a  network  are  supposed  to  arrange  themselves,  and  guide  the 
actual  detailed  configuration  accordingly.  Examples 
include 
controlling the deployment of a consumer network in the home, an 
ad hoc network in support of a rapid deployment force, or a network 
for  a  small  business.  Successful  accomplishment  of  this  project 
could  lead  to  substantial  reductions  in  manpower  needed  to 
configure and operate networks. 
 The KP configuration manager should have enough understanding 
of low-level structure to detect if the network is properly configured 
according  to  the  high-level  constraints,  to  detect  if  a  better 
configuration  alternative  is  available,  and  to  detect  if  the  system 
appears to be corrupted. The reasoning must go in both directions. 
That is, the manager must be able to derive low-level settings given 
high-level  goals,  priorities  and  constraints,  and  it  must  be  able  to 
look  at  existing  low-level  settings  and  describe  the  resulting 
behavior in the high-level terms. 
Again, the interesting problem (once we get the basic idea to work) 
is  when  the  system  encounters  conflicting  assertions  made  by 
different 