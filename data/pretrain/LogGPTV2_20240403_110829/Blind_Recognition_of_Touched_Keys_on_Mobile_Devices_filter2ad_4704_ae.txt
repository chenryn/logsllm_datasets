includes further reﬁnement of the attack and design of alternative
authentication strategies for mobile devices.
9. ACKNOWLEDGEMENTS
This work is supported in part by National Key Basic Research
program of China under grant 2010CB328104, Macau FDCT 061-
2011-A3, International S&T Cooperation Program of China grant
2013DFA10690, US NSF grants 1116644, CNS-1318948 and 1262275,
National Science Foundation of China under grant 61272054. Any
opinions, ﬁndings, conclusions, and recommendations in this paper
are those of the authors and do not necessarily reﬂect the views of
the funding agencies.
10. REFERENCES
[1] M. Backes, T. Chen, M. Duermuth, H. Lensch, and M. Welk.
Tempest in a teapot: Compromising reﬂections revisited. In
Proceedings of 30th IEEE Symposium on Security and
Privacy, pages 315–327, 2009.
[2] M. Backes, M. Dürmuth, and D. Unruh. Compromising
reﬂections or how to read lcd monitors around the corner. In
Proceedings of IEEE Symposium on Security and Privacy,
pages 158–169, 2008.
[3] D. Balzarotti, M. Cova, and G. Vigna. Clearshot:
Eavesdropping on keyboard input from video. In Proceedings
of the 2008 IEEE Symposium on Security and Privacy, SP
’08, pages 170–183, 2008.
[4] H. Bay, A. Ess, T. Tuytelaars, and L. Van Gool. Speeded-up
robust features (surf). Comput. Vis. Image Underst.,
110(3):346–359, June 2008.
[5] H. Benko, A. D. Wilson, and P. Baudisch. Precise selection
techniques for multi-touch screens. In Proceedings of the
SIGCHI Conference on Human Factors in Computing
Systems, CHI ’06, pages 1263–1272, 2006.
[6] R. Biddle, S. Chiasson, and P. van Oorschot. Graphical
passwords: Learning from the ﬁrst twelve years. In ACM
Computing Surveys, 2012.
1412[7] G. R. Bradski and A. Kaehler. Learning opencv, 1st edition.
[26] Logitech. Logitech hd pro webcam c920. http://www.
O’Reilly Media, Inc., ﬁrst edition, 2008.
[8] A. Bulling, F. Alt, and A. Schmidt. Increasing the security of
gaze-based cued-recall graphical passwords using saliency
masks. In Proceedings of the ACM SIGCHI Conference on
Human Factors in Computing Systems (CHI), 2012.
[9] J. Canny. A computational approach to edge detection. IEEE
Trans. Pattern Anal. Mach. Intell., 8(6):679–698, 1986.
[10] N. Dalal and B. Triggs. Histograms of oriented gradients for
human detection. In Proceedings of the 2005 IEEE Computer
Society Conference on Computer Vision and Pattern
Recognition (CVPR’05) - Volume 1 - Volume 01, CVPR ’05,
pages 886–893. IEEE Computer Society, 2005.
[11] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and
D. Ramanan. Object detection with discriminatively trained
part-based models. IEEE Trans. Pattern Anal. Mach. Intell.,
32:1627–1645, 2010.
[12] C. Forlines, D. Wigdor, C. Shen, and R. Balakrishnan.
Direct-touch vs. mouse input for tabletop displays. In
Proceedings of the SIGCHI Conference on Human Factors in
Computing Systems, CHI ’07, pages 647–656, 2007.
[13] H. Grabner, M. Grabner, and H. Bischof. Real-time tracking
via on-line boosting. In Proceedings of the British Machine
Vision Conference, 2006.
[14] R. Hartley and A. Zisserman. Multiple View Geometry in
Computer Vision. Cambridge University Press, 2 edition,
2003.
[15] S. B. Hirsch. Secure input system. In United States Patent
No. 4,479,112, 1982.
[16] S. B. Hirsch. Secure keyboard input terminal. In United
States Patent No. 4,333,090, 1982.
[17] B. Hoanca and K. Mock. Screen oriented technique for
reducing the incidence of shoulder surﬁng. In Proceedings of
the International Conference on Security and Management
(SAM), 2005.
[18] P. Huber. Robust Statistics. John Wiley & Sons, 1981.
[19] Juniper Networks, Inc. Juniper networks third annual mobile
threats report. http://www.juniper.net/us/en/local/
pdf/additional-resources/
3rd-jnpr-mobile-threats-report-exec-summary.
pdf, 2013.
[20] Y. Ke, R. Sukthankar, and M. Hebert. Efﬁcient visual event
detection using volumetric features. In Proceedings of the
Tenth IEEE International Conference on Computer Vision
(ICCV’05) Volume 1 - Volume 01, ICCV ’05, pages 166–173,
2005.
[21] D. Kim, P. Dunphy, P. Briggs, J. Hook, J. W. Nicholson,
J. Nicholson, and P. Olivier. Multi-touch authentication on
tabletops. In Proceedings of the ACM SIGCHI Conference on
Human Factors in Computing Systems (CHI), 2010.
[22] I. Kim. Keypad against brute force attacks on smartphones.
In IET Information Security, 2012.
[23] J. Koch. Codescrambler. http://cydia.saurik.com/
package/org.thebigboss.codescrambler/, 2014.
[24] T. Lan, Y. Wang, and G. Mori. Discriminative ﬁgure-centric
models for joint action localization and recognition. In
International Conference on Computer Vision (ICCV), 2011.
[25] C. Lee. System and method for secure data entry. In United
States Patent Application Publication, 2011.
logitech.com/en-us/product/hd-pro-webcam-c920,
2013.
[27] D. G. Lowe. Distinctive image features from scale-invariant
keypoints. Int. J. Comput. Vision, 60(2):91–110, Nov. 2004.
[28] F. Maggi, S. Gasparini, and G. Boracchi. A fast
eavesdropping attack against touchscreens. In IAS, pages
320–325. IEEE, 2011.
[29] J. Matas, C. Galambos, and J. Kittler. Robust detection of
lines using the progressive probabilistic hough transform.
Comput. Vis. Image Underst., 78(1):119–137, 2000.
[30] K. E. McIntyre, J. F. Sheets, D. A. J. Gougeon, C. W.
Watson, K. P. Morlang, and D. Faoro. Method for secure pin
entry on touch screen display. In United States Patent No.
6,549,194, 2003.
[31] M. Muja and D. G. Lowe. Fast approximate nearest
neighbors with automatic algorithm conﬁguration. In In
VISAPP International Conference on Computer Vision
Theory and Applications, pages 331–340, 2009.
[32] Plugable. Plugable usb 2.0 digital microscope for windows,
mac, linux (2mp, 10x-50x optical zoom, 200x digital
magniﬁcation). http://www.amazon.com/
Plugable-Digital-Microscope-Windows-Magnification/
dp/B00AFH3IN4/ref=sr_1_1?ie=UTF8&qid=
1382796731&sr=8-1&keywords=optical+zoom+
webcam, 2013.
[33] R. Raguram, A. M. White, D. Goswami, F. Monrose, and
J.-M. Frahm. ispy: automatic reconstruction of typed input
from compromising reﬂections. In Proceedings of the 18th
ACM conference on Computer and communications security,
CCS ’11, pages 527–536, 2011.
[34] N. Sae-Bae, K. Ahmed, K. Isbister, and N. Memon.
Biometric-rich gestures: A novel approach to authentication
on multi-touch devices. In Proceedings of the 30th ACM
SIGCHI Conference on Human Factors in Computing
Systems (CHI), 2012.
[35] J. Shi and C. Tomasi. Good features to track. Technical
report, 1993.
[36] H.-S. Shin. Device and method for inputting password using
random keypad. In United States Patent No. 7,698,563, 2010.
[37] X. Suo, Y. Zhu, and G. S. Owen. Graphical passwords: A
survey. In Proceedings of Annual Computer Security
Applications Conference (ACSAC), 2005.
[38] R. Szeliski. Computer Vision: Algorithms and Applications.
Springer-Verlag New York, Inc., 1st edition, 2010.
[39] Y. Tian, R. Sukthankar, and M. Shah. Spatiotemporal
deformable part models for action detection. In Proceedings
of the 2013 IEEE Conference on Computer Vision and
Pattern Recognition, CVPR ’13, pages 2642–2649, 2013.
[40] F. Wang, X. Cao, X. Ren, and P. Irani. Detecting and
leveraging ﬁnger orientation for interaction with direct-touch
surfaces. In Proceedings of the 22nd annual ACM symposium
on User interface software and technology, UIST ’09, pages
23–32, 2009.
[41] F. Wang and X. Ren. Empirical evaluation for ﬁnger input
properties in multi-touch interaction. In Proceedings of the
SIGCHI Conference on Human Factors in Computing
Systems, CHI ’09, pages 1063–1072, 2009.
[42] J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba.
Sun database: Large-scale scene recognition from abbey to
zoo. pages 3485–3492. IEEE, 2010.
1413[43] Y. Xu, J. Heinly, A. M. White, F. Monrose, and J.-M. Frahm.
Seeing double: Reconstructing obscured typed input from
repeated compromising reﬂections. In Proceedings of the
20th ACM Conference on Computer and Communications
Security (CCS), 2013.
[44] Q. Yan, J. Han, Y. Li, J. Zhou, and R. H. Deng. Designing
leakage-resilient password entry on touchscreen mobile
devices. In Proceedings of the 8th ACM Symposium on
Information, Computer and Communications Security
(AsiaCCS), 2013.
[45] Y.Hu, L. Cao, F.Lv, S.Yan, Y.Gong, and T.S.Huang. Action
detection in complex scenes with spatial and temporal
ambiguities. ICCV, 2009.
[46] J. yves Bouguet. Pyramidal implementation of the lucas
kanade feature tracker. Intel Corporation, Microprocessor
Research Labs, 2000.
[47] Y. Zhang, P. Xia, J. Luo, Z. Ling, B. Liu, and X. Fu.
Fingerprint attack against touch-enabled devices. In
Proceedings of the second ACM workshop on Security and
privacy in smartphones and mobile devices, SPSM ’12,
pages 57–68, 2012.
Appendix
In this appendix, we discuss countermeasures to computer vision
based attacks introduced in this paper and related work. There are
many other authentication approaches immune to these attacks to
some extent, including biometric-rich gesture-based authentication
[34, 44, 21] and graphic password schemes [6, 37, 8]. The idea
of randomized keyboard has been proposed for legacy keypad and
touch-enabled devices [16, 15, 30, 17, 36, 25, 22]. We have de-
signed and developed the context aware Privacy Enhancing Key-
boards (PEK) for Android for the ﬁrst time. We have implemented
the PEK as a third party app and are also able to change the internal
system keyboard to implement the PEK.
Design and Implementation of PEK
A software keyboard may contain three sub-keyboards. The pri-
mary sub-keyboard is the QWERTY keyboard, which is the most
common keyboard layout. The second sub-keyboard is the numer-
ical keyboard that may also contain some symbols. The last sub-
keyboard is a symbol keyboard that contains special symbols. The
layout for these three sub-keyboards is stored in a XML ﬁle, which
records the positions of keys and corresponding key codes. The
system generates its keyboard in this way: the keys will be read
from the XML ﬁle and put in a right position.
PEK changes the key layout to implement randomized keys. When
a keyboard is needed, we ﬁrst generate a random sequence of key
labels for each of the three different keyboards. When a key is read
from the XML, we randomly choose an integer number between
one and the size of the key sequence. We use this number to pick
the speciﬁc key label from the randomized key sequence and also
remove this label from the key sequence. This randomly selected
key replaces the current key. In this way, we can shufﬂe the key po-
sitions on a normal keyboard. Another version of PEK is to make
each key move within the keyboard region in a Brownian motion
fashion by updating each key’s position repeatedly according to the
Brownian motion. In this way, the keys are moving all the time.
Even if the same key is pressed a few times, their positions are d-
ifferent. This is an improvement compared with PEK with shufﬂed
keys, in which the keyboard does not change in one session of pass-
word input. Figure 22 shows PEK with shufﬂed keys and Figure 23
shows PEK with the Brownian motion of keys.
Figure 22: PEK-Shufﬂed Keys Figure 23: PEK-Brownian Motion
)
c
e
S
(
i
e
m
T
t
u
p
n
I
45
40
35
30
25
20
15
10
5
0
Normal Keyboard Shufﬂed Keys Brownian Motion
Figure 24: Input Time of Three Distinct Keyboards
PEK is aware of the context and can pop up the randomized key-
board only if the input box is for sensitive information. The An-
droid class “EditorInfo” can be used to detect the input box type.
In our case, TYPE_NUMBER_VARIATION_PASSWORD, TYPE_TEXT_
VARIATION_PASSWORD, TYPE_TEXT_VARIATION_VISIBLE_PASSWORD
and TYPE_TEXT_VARIATION_WEB_PASSWORD are used to identify
the password input box. The ﬁrst type is the variation of TYPE_
CLASS_NUMBER, while the other three types are the variations of
TYPE_CLASS_TEXT. Once the password input box is triggered by
the user, a new randomized keyboard will be constructed. As a re-
sult, the user can have different key layouts every time she presses
the password input box.
Evaluation of PEK
To measure the usability of the PEK, we recruit 20 students, 5 fe-
male students and 15 male students, whose average age is 25 years
old. We implemented a test password input box and generated 30
random four-letter passwords. The students are required to input
these 30 passwords by using a shufﬂed keyboard and a Brownian
motion keyboard, and the test app records the user input time. Ta-
ble 7 shows the results of our evaluation and Figure 24 gives a box
plot of the input time of three different keyboards. The median in-
put time is around 2.2 seconds on the normal keyboard, 5.9 seconds
on the shufﬂed keyboard and 8.2 seconds on the Brownian motion
keyboard. The success rate is the probability that a user correctly
inputs four-letter passwords. The success rate of all three keyboards
are high while it is a little bit lower for the Brownian motion key-
board. The participants in our experiments feel PEK is acceptable
if PEK only pops up the randomized keyboard for sensitive infor-
mation input.
Table 7: Usability Test
Median Input Time (Second)
Success Rate
Normal
Keyboard
2.235
98.50%
Shufﬂed Brownian
Keys
5.859
98.83%
Motion
8.24
94.17%
1414