theoretical analysis and empirical evaluation on real-world
data, (2) private by analyzing the security properties of our
protocol with respect to client and database privacy, and (3)
efﬁcient in terms of concrete server-side computation and client-
server communication. See Sections VII and VIII for analytical
and empirical results, respectively.
Contributions. In summary, this paper makes the following
four contributions:
1) design of a single-round protocol for privacy-preserving
ANN search, achieving sublinear communication and
concrete query processing efﬁciency,
2) leakage analysis with quantiﬁable database privacy, which
we show asymptotically matches the optimal leakage,
3) security against malicious clients that may deviate from
protocol in an attempt to abuse leakage, and
4) an open-source implementation [1] which we evaluate on
real-world data with millions of feature vectors.
Limitations. Our protocol has greater database leakage com-
pared to the baseline leakage required for correct functionality.
We show that the database leakage is asymptotically optimal,
but concretely a small factor worse on real data; see empirical
analysis in Section VII. Additionally, in contrast to prior work,
our threat model assumes two non-colluding servers. In the
full version of this paper [76, Appendix E], we sketch how
our techniques also apply to the single-server setting (albeit
at a concrete efﬁciency cost). For now, however, the non-
colluding assumption enables lightweight privacy-preserving
systems [2, 18, 27, 32, 33, 35–37, 55, 66], including systems
deployed in industry [35, 45].
II. BACKGROUND: NEAREST NEIGHBOR SEARCH
We begin by describing the standard (non-private) approach
to approximate nearest neighbor search based on locality-
sensitive hashing. Even outside of a privacy-preserving context,
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:00:59 UTC from IEEE Xplore.  Restrictions apply. 
2912
nearest neighbor search in higher dimensions (d ≥ 10) requires
tolerating approximate results to achieve efﬁcient solutions [49].
In Section IV, we transform the ideas from non-private ANN
search into a private protocol instantiated between a client and
two servers holding replicas of the database.
A. Locality-sensitive hashing
The approximate nearest neighbor search problem is solved
using hashing-based techniques that probabilistically group
similar feature vectors together (see survey of Andoni et al. [6]).
Approximate solutions based on Locality-Sensitive Hashing
(LSH) provide tunable accuracy guarantees and only require
examining a small fraction of feature vectors in the database
to ﬁnd the approximate nearest neighbor(s).
LSH families are deﬁned over a distance metric (such as
Euclidean distance) and have the property that vectors close
to each other in space hash to the same value with good
probability. Formally, for a vector space D, output space R,
and a distance metric ∆, an LSH family is deﬁned as:
Deﬁnition 1 (Locality-Sensitive Hash (LSH)). A family of
hash functions H := {h : D → R} is (R, cR, p1, p2)-sensitive
for distance metric ∆ if for any pair of vectors v, q ∈ D,
if ∆(v, q) ≤ R then Pr[h(v) = h(q)] ≥ p1,
if ∆(v, q) ≥ cR then Pr[h(v) = h(q)] ≤ p2,
where R  p2.
Remark 1. Note that an LSH family is usually combined with
a universal hash function to map to a ﬁxed output size [34].
Without loss of generality, we will assume that the output of
the LSH function is mapped by a universal hash.
LSH for nearest neighbor search. In this work we adapt the
data structure of Gionis et al. [43], which is the standard
way of solving the ANN search problem using LSH [6].
The data structure consists of two algorithms: BUILD and
QUERY (described in Appendix A for completeness). At a
high level, BUILD hashes each vector into a hash table using a
locality-sensitive hash function. QUERY performs a lookup in
the hash table and returns the nearest-neighbor in the colliding
bucket. This process is repeated L times to increase accuracy.
Because the probability that a nearest neighbor collided with
the query in a subset of hash tables can be made arbitrarily high
(by tuning parameters), BUILD and QUERY ensure that the
nearest neighbor is found with high probability (see Figure 2).
N tables (N is the database
In practice, one must query L ≈ √
size) to obtain good accuracy and sublinear query time [6].
III. OVERVIEW
We adapt the standard LSH-based data structure described
in Section II into a privacy-preserving protocol between a client
with query vector q and two servers with access to replicas of
the database. We begin by describing the baseline functionality
of private ANN search.
Notation. We denote by DB the database of vectors and their
IDs. We let N be the total number of d-dimensional vectors in
Fig. 2: Visualization of the nearest neighbor search problem. Left:
collision probability of a LSH function as the distance between the
query and a point grows larger. Center: representation of the collision
radius centered at the query for a collection of points in the database.
The blue points within distance R have a high probability of colliding
with the query. The orange points within distance R and cR from
the query have a lower probability of colliding with the query. The
approximation factor c > 1 determines the quality of the results;
typically c = 2 in practical applications. Right: The query is likely
to collide with buckets containing the near neighbors (blue points)
when using a LSH function h to construct the hash table.
DB. A vector is denoted in bold as v where the ith coordinate
of v is denoted by vi. A distance metric (e.g., Euclidean
distance) is denoted ∆, where threshold distances R and cR
are as deﬁned in Section II-A. We let F denote any prime-
order ﬁnite ﬁeld (e.g., integers mod a prime p). A secret-share
of a value v ∈ F is denoted using bracket notation as [v].
Coordinate-wise secret-shares of a vector v are denoted as [v].
Variable assignment is denoted by x←y, where x R←S denotes
a random sample from S.
A. Baseline functionality
The baseline ANN search functionality is described in
Functionality 1. The functionality takes as input the public
parameters and query q to output the ID of the nearest neighbor
to the client. The servers obtain no output. Without loss of
generality, we assume the ID of the ANN is the index of the
ANN for some canonical ordering of the feature vectors in the
database. We let ID = 0 when no nearest neighbor exists.
Restricting the problem. Note that an LSH-based algorithm
will only return an answer that is within distance cR of
the query. We formalize this by assuming that the baseline
functionality outputs the nearest neighbor that is also a near2
(distance less than cR away from the query) neighbor. While
it is possible to imagine contrived databases where the nearest
neighbor is not also a near neighbor, most practical instances
of the problem impose this additional restriction (returning no
neighbor if the nearest neighbor is beyond a threshold distance
from the query) because points beyond some threshold are
effectively unrelated to the query. To this end, the baseline
functionality is deﬁned to reveal the ID of the nearest neighbor
(if one exists) within a ﬁxed distance R = Rmax from the query.
Following Bayer et al. [17], we deﬁne two quantities Dmax
and Dmin to be the maximum and minimum distance between
any two points, respectively. Because the distance between any
two vectors is at most Dmax, it sufﬁces to have Rmax  Rmax then
else output 0 to the client and ⊥ to the servers.
3: else output a to the client and ⊥ to the servers.
B. Threat model and security guarantees
Our protocol is instantiated with two non-colluding servers
and an arbitrary number of clients. Clients query the servers
to obtain the ANN ID from a remote database replicated on
both servers. We do not require any communication between
servers when answering queries.
Threat model.
• No client is trusted by either server. Clients may deviate
from protocol, collude with other clients, or otherwise behave
maliciously to learn more about the database.
• No server is trusted by any client. One or both servers may
deviate from protocol in an attempt to obtain information
on a client’s query or the resulting nearest neighbor.
Assumptions. Our core assumption, required for client privacy,
is that the two servers do not collude with each other. For
database privacy, we assume that neither server shares the
database with a client. We also require black-box public-
key infrastructure (e.g., TLS [74]) to encrypt communication
between the clients and the servers.
Guarantees. Under the above threat model and assumptions,
the protocol provides the following guarantees.
Correctness. If the client and servers both follow protocol,
then the client obtains the ID of the ANN with respect to its
query. The result is guaranteed to have the same approximation
accuracy of standard, non-private data structures for ANN
search, and has tunable accuracy guarantees.
Client privacy. If the servers do not collude, then neither server
learns any information on the client’s query, even if one or
both servers arbitrarily deviate from protocol.
Bounded leakage. Each query answer is guaranteed to leak a
small (and tightly bounded) amount of information over the
ideal functionality, even if the query is maliciously generated
by the client. We provide a precise deﬁnition and in-depth
analysis of this leakage in Section VII.
IV. MAIN IDEAS
To introduce privacy, as required for the client and the
database, we make several changes to the standard LSH data
structure (BUILD and QUERY; described in Section II). A
simple strawman protocol with client privacy (but no database
√
N (recall that L ≈ √
privacy) can be realized by applying well-known techniques
in Private Information Retrieval (PIR) to privately obtain the
answer to QUERY (see [28, 29, 40]). PIR allows a client to
privately retrieve a speciﬁed object from a remote database
without revealing which object was retrieved, which naturally
generalizes to retrieving buckets from a hash table [29]. While
PIR solves the client privacy problem, it provides no database
privacy. The client learns
N to provide
good accuracy) feature vectors from the database per query.
The challenge with database privacy. The primary challenge
in reducing database leakage comes from preventing the client
from learning extra vectors in the candidate set. This is non-
trivial to do given that the standard approaches to removing
false-positive candidates (vectors farther than cR from the
query) require some form of direct distance comparisons. In
the private setting, these become oblivious comparisons (a
comparison between secret-shared values), which in turn require
heavy cryptographic techniques (e.g., garbled circuits [84]).
The state-of-the-art approach for privacy-preserving ANN
search (SANNS [26]) prunes candidates by using an expensive
two-party computation, which requires several gigabytes of
communication between the client and database server.
The insight that we exploit to overcome this challenge is that
LSH can itself be used to accomplish the same goal of pruning
false-positives. By carefully tuning the LSH parameters, we
can eliminate a large number of false-positives from the ANN
candidates. We then apply a trick inspired by radix sorting [54]
to extract the nearest neighbor, fully removing the need for
direct comparisons between vectors. Our new data structure
is slightly less efﬁcient when viewed from an algorithmic
perspective (i.e., when not considering privacy). However, this
is not a problem for us given that oblivious comparisons are
the primary bottleneck in a privacy-preserving setting. We
elaborate on this observation in the next section.
A. Reframing the problem
LSH-based ANN search is typically optimized to minimize
the number of hash tables (L) and the size of the candidate set
for each query. Removing false-positives via brute-force com-
parisons is relatively “cheap” from a computational standpoint
while hash table lookups are relatively expensive. Therefore,
LSH-based ANN search is typically tuned to retrieve as many
(reasonable) candidates as possible from each table. The extra
candidates are then pruned via brute-force comparisons.
The privacy-preserving setting requires different priorities.
First, note that it is not possible to perform only one lookup
per hash table. To preserve privacy, all hash table buckets
must be “touched” by the database server(s) to avoid revealing
information on the client’s query. This is the lower bound on
private information retrieval [15, 28]: if it is not met, then the
servers learn that the client’s hash does not correspond to any
untouched bucket. This is exactly why existing solutions for
privacy-preserving ANN search require O(N ) communication
between the client and server, or alternatively, the use of fully-
homomorphic encryption (which requires linear server work).
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:00:59 UTC from IEEE Xplore.  Restrictions apply. 
4914
As such, we cannot hope to have sublinear (in N) work for
the servers when answering client queries.
With this in mind, we observe that
the optimal LSH
parameters in the non-private (a.k.a. algorithmic) setting might
not in fact be optimal for privacy-preserving setting. We
therefore approach the problem from a different angle by re-
designing and re-tuning the ANN search data structure of
Section II to limit the use of comparisons between vectors.
B. Eliminating oblivious comparisons
1, p(cid:48)
2 = pk
1 and p(cid:48)
One idea to remove comparisons is to prevent values that
will be pruned from being added to the candidate set in the
ﬁrst place. More precisely, by tuning the parameters of the
ANN search data structure, and the LSH functions it uses, we
can bound the probability of false-positives in the candidate
set to any 0  0, and any
(p1, p2, R, cR)-sensitive hash family where ρ = log(p1)
2.
log(p2) < 1
There exists a data structure solving the cR-approximate near
neighbor problem in O(N ρ(cid:48)
) space, where
ρ < ρ(cid:48) < 1. This data structure returns the true cR-approximate