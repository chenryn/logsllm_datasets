We now describe the methodology that we used to con-
duct our user study. Our study was focused on the usability
of each Bumpy variant in benign scenarios, the security of
each variant in attack scenarios, and the utility of warnings
for training users to handle attack scenarios. We describe
our simulation of each variant in §4.1 and how we recruited
participants in §4.2. We discuss the phases of the experi-
ment in §4.3 and detail the attack types in §4.4.
4.1 Simulation of User Interface Alternatives
The participants in our study were students enrolled in a
university course that was not taught by one of the authors.
Thus, we needed to be unintrusive so that the instructor need
not be concerned about the impact of our study on students’
ability to reach essential course materials. Consequently,
we could not control which computers students used to ac-
cess the course web page. We could not provide students
with a distinct physical TM, and we needed to support mul-
tiple browsers on multiple operating systems.
The most consequential change to the designs presented
in §3 is that we implemented the TM as part of the course
web page, not as a separate physical device. Rather, to
simulate a separate physical device to the extent possible,
we implemented the TM as a minimized window using the
Google Web Toolkit. The minimized window appears as a
title bar only. When the TM display is updated, the simu-
lated TM beeps to attract the user’s attention, as a real TM
would. In addition, to account for the possibility that the
student mutes the sound on her computer, the TM window’s
title bar ﬂashes when it is updated (as a real TM’s display
could). The user must expand the TM window to view the
TM’s display. The expanded TM is shown in the context
of Original in Figure 1(a). The elapsed time indicator gives
the user deﬁnitive evidence that the information displayed
on the TM is timely, i.e., is in response to the most recent
SAS.
In addition to simulating the TM, we instrumented
the course login web page to collect information about
keystroke, mouse click, and focus events. This data was
logged in a MySQL database that was the backend for the
login web page. Information collected includes the type of
event and a timestamp. For example, a user logging in with
design Original and password password might induce the
following sequence of log records: a focus event indicating
that the password ﬁeld is now focused; a keystroke @; an-
other keystroke @ (yielding @@ — the SAS); a mouse click
expanding the TM;2 a blur event indicating that the pass-
word ﬁeld lost focus; a focus event indicating that the pass-
word ﬁeld is now focused; a keystroke p; a keystroke a;
a keystroke s; ...; a keystroke d; a mouse click indicating
that the user clicked the “log in” button; and a blur event
indicating that the password ﬁeld lost focus.
This logging design enables us to observe user activi-
ties that would not be evident from the ﬁnal ﬁeld contents
upon form submission. For example, our logs include user
mistakes, such as typing password characters and backspac-
ing to remove them, which can be critical to accurately ac-
count for which password characters a user leaked to (simu-
lated) malware on her machine (as measured in §5.2–§5.3.)
The timestamps are primarily useful for ordering events, for
computing login durations (see §5.1), and for determining
when users have abandoned a session (e.g., walked away
from their computer mid-login).
2Note that in a real implementation, the TM would be a separate phys-
ical device, and so this mouse click, the accompanying blur and the subse-
quent focus would not occur.
4.2 Participant Enrollment
The participants in our study were 85 students enrolled in
COMP 380: Computers and Society, a one-semester course
offered at the University of North Carolina (UNC) that is
popular for satisfying general undergraduate requirements.
There were 28 majors represented by the study participants,
with the largest representations in Economics (14%), Busi-
ness Administration (11%), Psychology (8%), Management
and Society (6%), Biology (6%), and Journalism and Mass
Communication (6%). One student was a Computer Sci-
ence major, and there were no Engineering majors in the
class. The breakdown of participants by year of study was:
one freshman, one sophomore, 24 juniors, 58 seniors, and
one graduate student.
In the fall semester of 2009, there
were three sections of the course offered, of sizes 45, 45
and 46 students. In these three sections, 27, 27, and 31 stu-
dents opted in (yielding 85 total participants) while a total
of 51 students chose not to opt in.
The participants were recruited through 20-minute pre-
sentations to each of the sections by one of the authors dur-
ing the second week of class. These presentations covered:
a very high-level discussion of the threats that malware pose
and how Bumpy works; an explanation of the experiment;
the users’ rights as subjects in such an experiment; why the
students might want to participate; and a brief demonstra-
tion of the Bumpy variants that participants from that sec-
tion might see.
Students were motivated to enroll by the possibility of
winning a cash award up to $150, the exact amount of which
was determined by their performance in the experiment. We
intended through the design of the award system to give stu-
dents a ﬁnancial incentive both to use the system regularly
and to protect their passwords while doing so. In this award
system, we reduced a student’s possible winnings when she
leaked password characters to our simulated attacks (except
in the Control group, where the login provides no protec-
tion against the attacks), and we increased her possible win-
nings if she logged in frequently. Motivating the students
ﬁnancially to protect their passwords from our simulated
attacks was necessary, as they had no other motivation to do
so: since their chosen passwords were recorded in our logs
so that we could determine when they leaked characters of
their actual passwords — a fact made known to the students
— our simulated attacks posed no actual threat to their (al-
ready known) passwords. Moreover, because we capped the
amount of total money awarded across the whole class (stu-
dents would be drawn at random and awarded their earned
value until the cap was reached), the students were not mo-
tivated to assist each other. All of these points were made
to the students during the 20-minute presentations to each
course section.
Students opted in or out of the experiment upon access-
(a) Benign: Expanded TM.
(b) Initial: TM not checked warning.
(c) Attack: Wrong-Dest attack.
Figure 1. Screenshots with Bumpy(cid:173)enabled login page from within the Safari browser.
ing the course web page after this presentation. Those who
opted in ﬁlled out a background questionnaire prior to their
ﬁrst logins. According to their responses, the median com-
puter usage among participants was 2-4 hours per day. Af-
ter enrollment, there were 17 participants using Original, 16
using Graphical, 17 using NoTM, 19 using Challenge, and
16 using Control. None of these participants withdrew from
using the system after the experiment commenced.
4.3 Experiment Phases
We conducted our experiment in four phases, to which
each group of participants was subjected for the same du-
rations and in the same order. Throughout these phases,
each participant had access to an instructional video and
help pages to explain how to log into the course web page
(in benign circumstances) using the Bumpy design she was
using. In addition, the help page explained that if the user
detected what she thought might be an attack, she should
reload the page. The four phases were as follows:
Initial (In): This phase lasted 15 days. During it, the users
were not attacked and were provided automated instructions
to walk them through how to log in during benign circum-
stances. For example, if a user in group Original typed “@@”
in the password entry ﬁeld, and then continued with typing
her password without checking the TM (i.e., the TM was
still minimized), then the user would be interrupted with
instructions to check the TM before proceeding (see Fig-
ure 1(b)). In this phase, we provided as many such auto-
mated walk-through instructions as we could to ensure that
the user logged in correctly.
Benign (Be): This phase followed Initial and lasted 28 days.
It also had no simulated attacks, but the automated walk-
through instructions for helping users log in were disabled.
Attack (At): This phase followed Benign and lasted 26
days.
In this phase, we turned on the simulated attacks.
Each login page included an Active attack (see §4.4) with
probability 0.5; if the page was chosen to include an Active
attack, the attack performed was chosen uniformly at ran-
dom from among the Active attacks for that design. Auto-
mated instructions were still disabled in this phase. How-
ever, 12 days prior to starting this phase, we posted an an-
nouncement on the course web page to remind participants
that if they encountered what they thought might be an at-
tack, they simply need to reload the page and try again. The
reloaded login page was attacked with the same probability
as the original, i.e., our system did not treat reloaded pages
any differently than the initial login page. We posted this
announcement to avoid a situation where a user detected
a problem but proceeded anyway since they did not know
how to avoid it. Further, since we were controlling access
to an essential course web page, we needed to ensure that
students could always reach their course materials. Admit-
tedly, reloading the page presents less of a hurdle to users
than they would experience in practice to remedy malware
they detect; this is a limitation of our experiment (see §6).
Attack-and-Warn (AW): This phase followed Attack and
lasted 38 days. This phase was exactly like Attack, ex-
cept that after a login attempt with a simulated attack and
in which the user divulged password characters to the (sim-
ulated) malware, the system warned the user as to what ac-
tions she performed (or failed to perform) that caused the
password characters to be divulged. These warnings thus
served as a form of training to educate the users as to what
they did wrong. We emphasize that in this phase, warn-
ings appeared only after the login attempt was completed
(in contrast to Initial, in which interruptions occurred during
password entry). The only warnings that were suppressed
from the user were for logins in which the user appeared to
correct the error herself; e.g., she typed password characters
during
Figure
shows
the login count per
user
each
of
the four phases.
Each box shows the
second,
ﬁrst,
and
third quartiles;
the
whiskers cover points
within 1.5 times the
interquartile
range.
Outliers are shown as
circles.
Five
days
r
e
s
U
r
e
P
s
n
g
o
L
i
0
8
0
6
0
4
0
2
0
In Be At AW
Phase
and then backspaced to remove them before properly utiliz-
ing the system. In such cases, we did not warn the user to
avoid confusing her.
2
be-
the
Figure 2. Logins per
user
in experiment
phases.
fore the end of
Attack-and-Warn
phase, the non-Control group participants were asked to
complete an exit questionnaire. In order to remain eligible
for compensation, the questionnaire had to be completed
by the last day of this phase. Many of the questions were
meant to assess the helpfulness of the warning messages
from the Attack-and-Warn phase, allowing us to measure
their training effect (see §5.3). Out of the 69 non-Control
group students, 58 students completed the questionnaire.
4.4 Attacks
The simulated attacks to which we subjected participants
in the Attack and Attack-and-Warn phases were of four
types. These attack types were motivated by the threat
model against which the Bumpy system was designed to
protect, namely that the OS and its applications (e.g., web
browser) are potentially under the control of malware, but
that the Trusted Monitor (if any) and destination website
remain uncompromised. The ﬁrst three simulated attacks
described below, namely Feigned-Fail, Wrong-Dest, and
SAS-Present, are the Active attacks. In general, we counted
password characters as leaked in a login if they would have
been leaked to malware conducting the attack simulated in
that login, given the natural implementation of the Bumpy
variant in use. The fourth attack type is a Passive attack,
described below.
Feigned-Fail (FF): These attacks simulated malware that in-
terfered with Bumpy’s operation. In the designs that em-
ploy a TM (Original, Graphical, and Challenge), this was
implemented by simply not updating the TM, even after the
participant performed the actions that should have caused it
to be updated. We also implemented a Graphical variant in
which the password-entry ﬁeld would never turn green. In
these cases, any password characters that the user entered
were counted as leaked. In NoTM, which does not use a
TM, this attack was simulated by failing to recognize the
per-site SAS that the user entered (even if it was correct)
and displaying an error message indicating this to the user.
If the user then redeﬁned the SAS through the $ . . . $ in-
cantation (see §3.2.2), then all password characters typed
after this were counted as leaked, since in a real implemen-
tation, malware could have caused the new SAS deﬁnition
to apply to a site under its control, and hence captured the
password. In a real Bumpy implementation, malware could
mount these attacks, e.g., by simply blocking the Bumpy
module’s communication with the TM in designs Original,
Graphical and Challenge, and by displaying the error mes-
sage (and suppressing success indicators) in NoTM.
Wrong-Dest (WD): These attacks apply only to designs
that use a TM (Original, Graphical, and Challenge). The
simulated attack caused the wrong destination to be dis-
played on the TM. For our experiment, the destination dis-
played on the TM was cs.duke.edu and its graphical
logo; Duke University is a nearby sports rival of UNC. An
example TM display during this attack is shown in Fig-
ure 1(c). This behavior would be exhibited by a real im-
plementation of Original, Graphical, or Challenge if mal-
ware attempted to redirect the forthcoming input to cs.
duke.edu. Any password characters typed were counted
as leaked.
SAS-Present (SP): These attacks tried to induce the user to
enter her password without ﬁrst entering her SAS, by pro-
viding a password entry ﬁeld with the SAS already present.
Thus, this attack applied only to designs Original, NoTM,
and Challenge.
In Original and Challenge, the password
ﬁeld was presented with “@@” already present. In NoTM,
the SAS that that user previously speciﬁed for the course
website was already present in the ﬁeld when it was dis-
played. Though the SAS was already present, the TM (in
Original and Challenge) was not updated, as malware would
be unable to cause it to be updated in a real implementation.
Any password characters the user typed prior to retyping the
SAS were counted as leaked.
Passive (Pa):
Any login during phases Attack or
Attack-and-Warn that was not selected for an Active at-
tack was instead considered subject to a passive attack,
denoted Passive. Moreover, even a login selected for an
Active attack but for which the user did not elicit any evi-
dence of the chosen attack was instead included in Passive.
Speciﬁcally,
if in a login chosen for a Feigned-Fail or
Wrong-Dest attack, the user never entered her SAS (in
Original or Challenge) or toggled the password ﬁeld green
(in Graphical),
then failure of the TM to update when
it should (in a Feigned-Fail attack) or the appearance of
cs.duke.edu (in a Wrong-Dest attack) would never be
exhibited to the user. Such a login instance was labeled
as Passive-attacked, instead. (SAS-Present attacks were al-
ways exhibited to the user, and so never counted as Passive.)
In a Passive-attacked login, any password characters typed
prior to the update of the TM (induced by @@ in Original
or Challenge, or toggling the password ﬁeld to green in
Graphical) or, in NoTM, prior to entry of @str@ (where str
denotes any string), were considered leaked.
We do not claim that the Active attacks described above
are a complete set of active attacks that malware could
launch, though these include the most natural and subtle
ones that we could envision and also require the speciﬁ-
cation of few additional parameters that would be subject
to our own guesswork. In particular, we tried to devise at-
tacks that users may misinterpret as typical discontinuities
in the software experience, e.g., subtle changes between two
versions of a particular application or website. More ag-
gressive attacks could certainly be launched by displaying
to users instructions that contradict what they should do,
e.g., “We have upgraded to Bumpy 2.0. We now provide
the SAS for you, so that you need not enter it.” However,
the exact form of such instructions may matter to their ef-
fectiveness. As such, we did not endeavor to explore the
space of such active attacks. Given this, the primary pa-
rameter choice required by the above attacks is the selec-
tion of the destination in the Wrong-Dest attack. More
subtle, phishing-style options could have been chosen (e.g.,
using umc.edu, which appears similar to UNC’s domain
(unc.edu), without changing the graphic logo), but we
wanted to separate the participants’ susceptibility to such
phishing-style attacks, which are relevant outside the con-
text of Bumpy as well as within it, from the utility of Bumpy
itself.
5 Results of User Study
The experiment phases described in §4.3 provided an op-
portunity to study each Bumpy variant — Original (Or),
Graphical (Gr), NoTM (No), and Challenge (Ch) — in mul-
tiple scenarios. Usability in benign scenarios, security in
attack scenarios, and the effectiveness of warnings as a
form of training are addressed in §5.1, §5.2, and §5.3, re-
spectively. Also in §5.1, we compare the usability of each
Bumpy variant to our control group, Control (Co), though
Control is not considered in §5.2–5.3 since it does not of-
fer resilience to the attacks for which Bumpy was designed
(and thus that we tested in our attack experiments).
5.1 Usability in Benign Scenarios