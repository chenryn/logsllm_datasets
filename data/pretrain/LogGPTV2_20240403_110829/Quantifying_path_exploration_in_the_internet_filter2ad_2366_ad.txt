to routing changes inside the AS hosting the monitor, and
thus does not involve inter-domain path exploration.
Third, among the path changing events, Tdown events last
the longest, have the most updates, and explore the most
unique paths. Figures 10, 11 and 12 show the distributions
of event duration, number of updates per event, and number
unique paths explored per event respectively. The results
show that route fail-down events (Tdown) last considerably
longer than route fail-over events (Tlong). In fact, Figure 10
shows that about 60% of Tlong events have duration of zero,
while 50% of Tdown events last more than 80 seconds.
In
addition, Figure 11 shows that about 60% of Tlong events
have only 1 update, while about 70% of Tdown events have 3
or more updates. Figure 12 shows that Tdown explore more
unique paths than Tlong. These results are in accordance
with our previous analytical results in [19], but contrary to
the results of previous measurement work [12], which con-
cluded that the duration of Tlong events is similar to that
of Tdown and longer than that of Tup and Tshort.
In [19]
we showed that the upper bound of Tlong convergence time
is proportional to M (P − J), where M is the MRAI timer
value, P is the path length of to the destination after the
event, and J is the distance from the failure location to the
destination. Since P is typically small for most Internet
paths, and J could be anywhere between 0 and P , the dura-
tion of most Tlong events should be short. We believe that
the main reason [12] reached a diﬀerent conclusion is be-
cause they conducted measurements by artiﬁcially increas-
ing P to 30 AS hops using AS prepending. The analysis in
[19] shows that an overestimate of P would result in a longer
Tlong convergence time, which would explain why they ob-
served longer durations for beacon preﬁxes than what we
observed for operational preﬁxes.
4. POLICIES, TOPOLOGY AND ROUTING
CONVERGENCE
In this section we compare the extent of slow convergence
across diﬀerent preﬁxes and diﬀerent monitors to examine
the impacts of routing polices and topology on slow conver-
gence.
4.1 MRAI Timer
In order to make fair comparisons of slow convergence
observed by diﬀerent monitors, we need to be able to tell
whether a monitor enables MRAI timer or not. The BGP
speciﬁcation (RFC 4271 [22]) deﬁnes the MinRouteAdver-
tisementInterval (MRAI) as the minimum amount of time
that must elapse between two consecutive updates sent by
a router regarding the same destination preﬁx. Lacking
MRAI timer may lead to signiﬁcantly more update mes-
sages and longer global convergence time [9]. Even though
it is a recommended practice to enable the MRAI timer, not
all routers are conﬁgured this way. Since MRAI timer will
aﬀect observed event duration and number of updates, for
]
s
2
2
<
l
a
v
i
r
r
a
-
r
e
n
t
i
[
r
P
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
 0
 5
 10
 15
 20
 25
 30
 35
 40
 45
Monitor ID
Figure 13: Determining MRAI conﬁguration.
the purpose of studying impacts of policies and topology,
we should only make comparisons among MRAI monitors,
or among non-MRAI monitors, but not between MRAI and
non-MRAI monitors.
By default the MRAI timer is set to 30 seconds plus a
jitter to avoid unwanted synchronization. The amount of
jitter is determined by multiplying the base value (e.g., 30
seconds) by a random factor which is uniformly distributed
in the range [0.75, 1]. Assuming routers are conﬁgured with
the default MRAI values, we should (1) not observe consecu-
tive updates spaced by less than 30×0.75 = 22.5 seconds for
the same destination preﬁx, and (2) observe a considerable
amount of inter-arrival times between 22.5 and 30 seconds,
centered around the expected value, 30 × 0.75+1
2 = 26.5 sec-
onds.
For each monitor, we deﬁne a Non-MRAI Likelihood, LM ,
as the probability of ﬁnding consecutive updates for the
same preﬁx spaced by less than 22 seconds. Figure 13 shows
LM for all the 50 monitors in our initial set. Clearly, there
are monitors with very high LM and monitors with very
small LM . The curve has a sharp turn, hinting a major
conﬁguration change. Based on this, we decided to set
LM = 0.05 as a threshold to diﬀerentiate MRAI and non-
MRAI monitors. Those with LM < 0.05 are classiﬁed as
≥ 0.05 are classiﬁed as
MRAI monitors, and those with LM
non-MRAI monitors.
Using this technique, we detect that 15 routers from the
initial set of 50 are non-MRAI (see the vertical line in Figure
13), and 10 of them are part of the set of 32 routers we
used in previous section. We will use this set of 32-10=22
monitors for the next subsection to compare the extent of
slow convergence across monitors.
4.2 The Impact of Policy and Topology on Rout-
ing Convergence
Internet routing is policy-based. The “no-valley” policy
[8], which is based on inter-AS relationships, is the most
prevalent one in practice. Generally, most ASes have rela-
tionships with their neighbors as provider-customer or peer-
peer.
In provider-customer relationship, the customer AS
pays the provider AS to get access service to the rest of
the Internet; in peer-peer relationship, the two ASes freely
exchange traﬃc between their respective customers. As a
result, a customer AS does not forward packets between its
two providers, and a peer-peer link can only be used for traf-
ﬁc between the two incident ASes’ customers. For example,
in Figure 16, paths [3 5 4], [3 5 6] and [3 2 4] all violate
the “no-valley” policy and generally are not allowed in the
Internet.
Based on AS connectivity and relationships, the Internet
routing infrastructure can be viewed as a hierarchy.
• Core: consisting of a dozen or so tier-1 providers form-
ing the top level of the hierarchy.
• Middle: ASes that provide transit service but are not
part of the core.
• Edge: stub ASes that do not provide transit service.
They’re customers only.
We collect an Internet AS topology [30], infer inter-AS re-
lationships [28], and then classify all ASes into these three
tiers. Core ASes are manually selected based on their con-
nectivity and relationships with other ASes [30]; Edge ASes
are those that only appear at the end of AS paths; and the
rest are middle ASes. With this classiﬁcation, we can lo-
cate monitors and preﬁx origins with regard to the routing
hierarchy.
Our set of 22 monitors consists of 4 monitors in the core,
15 in the middle and 3 at the edge. We would like to have a
more representative set of monitors at the edge, but we only
found these many monitors in this class with consistent data
from the RouteViews and RIPE data archive. The results
presented in this subsection might not be quantitatively ac-
curate due to the limitation of monitor set, but we believe
they still illustrate qualititively the impact of monitor loca-
tion on slow convergence.
In the previous section we showed that Tdown events have
both the longest convergence time and the most path explo-
ration from all path change events. Furthermore, in a Tdown
event, the root cause of the failure is most likely inside the
destination AS, and thus all monitors should observe the
same set of events. Therefore, the Tdown events provide a
common base for comparison across monitors and preﬁxes,
and the diﬀerence between convergence time and the number
of updates should be most pronounced. In this subsection
we examine how the location of preﬁx origins and monitors
impact the extent of slow convergence.
Figure 14 shows the duration of Tdown events seen by
monitors in each tier. The order of convergence time is
core < middle < edge, and the medians of convergence
times are 60, 84 and 84 seconds for core, middle and edge
respectively. Taking into account that our edge monitor
ASes are well connected: one has 3 providers in the core
and the other two reach the core within two AS hops, we
believe that in reality edge will generally experience even
longer convergence times than the values we measured. Fig-
ure 15 shows that monitors in the middle and at the edge
explore 2 or more paths in about 60% of the cases, whereas
monitors in the core explore at most one path in about 65%
of the cases.
In a Tdown event, the monitor will not send a withdrawal
until it has explored all alternative paths. Therefore, the
event duration depends on the number of alternative paths
between the event origin and the monitor. In general, due to
no-valley policy [8], tier-1 ASes have fewer paths to explore
than lower tier ASes. For example, in Figure 16, node 3
(representing a tier-1 AS) has only one no-valley path to
)
F
D
C
(
y
c
n
e
u
q
e
r
F
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
2
4
1
3
5
Provider
Customer
Peer
Peer
6
7
core
middle
edge
 0
 50
 100
 150
 200
 250
Figure 16: Topology example.
Tdown event duration (s)
Figure 14: Duration of Tdown events as seen by mon-
itors at diﬀerent tiers.
)
F
D
C
(
y
c
n
e
u
q
e
r
F
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
)
F
D
C
(
y
c
n
e
u
q
e
r
F
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
core → core
edge → core
edge → middle
edge → edge
 200
 150
 250
 0
 50
 100
Tdown event duration (s)
 0
 1
 2
core
middle
edge
 3
Number of ASPATHs explored during Tdown
 4
Figure 17: Duration of Tdown events observed and
originated in diﬀerent tiers.
Figure 15: Number of unique paths explored during
Tdown as seen by monitors at diﬀerent tiers.
reach node 7 (path [3 4 6 7]), while node 5 has three paths
to reach the same destination: [5 6 7], [5 4 6 7] and [5 3 4
6 7]. In order to reach a destination, tier-1 ASes can only
utilize provider-customer links and peer-peer links to other
tier-1s, but a lower tier AS can also use customer-provider
links and peer-peer links in the middle tier, which leads to
more alternative paths to explore during Tdown events.
We studied how Tdown events are experienced by moni-
tors in diﬀerent tiers, but we do not know how the origin
of the event impacts the convergence process. Note that we
must divide again the results according to the monitor lo-
cation, otherwise we may introduce bias caused by the fact
that most of our monitors are in the middle tier. We use
the notation x → y, where x is the tier where the Tdown
event is originated from and y is the tier of the monitor
that observe the event. In our measurements, we observed
that the convergence times of x → y case were close to the
y → x case. Therefore, from these two cases we will only
show the case where we have a higher percentage of moni-
tors. For instance, between core → edge and edge → core
cases we will only show the later since our monitor set cov-
ers about 27% of the core but only a tiny percentage of the
edge. Figure 17 shows the duration of Tdown events for pre-
ﬁxes originated and observed at diﬀerent tiers. We omit the
cases middle → core and middle → middle for clarity of the
ﬁgure, since they almost overlap with curves edge → core
and edge → middle respectively. The ﬁgure shows that the
core → core case is the fastest, and the edge → middle,
edge → edge cases are the slowest. This observation is
also conﬁrmed by Figure 18, which shows the number of
paths explored during Tdown. Table 2 lists the median du-
rations of Tdown events originated and observed at diﬀerent
tiers. Events observed by the core have shortest durations,
which conﬁrms our previous observation (Figure 14). Note
that the edge → edge convergence is slightly faster than
the edge → middle convergence. We believe this happens
because, as mentioned before, our set of edge monitors are
very close to the core. Therefore, they may not observe so
much path exploration as the middle monitors, which may
have a number of additional peer links to reach other edge