other hand, the fuzzing loop is still conventional, covering seed
selection, mutation, and execution, with the exception that in
KRACE, a test case is considered “interesting” as long as new
progress is found in either of the coverage bitmaps. In addition,
all components are updated to handle the new seed format for
concurrency fuzzing: multi-threaded syscall sequences.
Code instrumentation. Since the focus of KRACE is file
systems, we only instrument memory access instructions in
the target file system module and its related components such
as the virtual file system layer (VFS) or the journaling module,
e.g., jbd2 for ext4. On the other hand, API annotations are
performed on the main kernel code base and have an effect even
when the execution goes out of the functions in our target file
system: the locks acquired and released, as well as the ordering
primitives (e.g., queuing a timer), will be faithfully recorded.
In this way, KRACE does not suffer from false positives in
cases like block layer calls into a callback in the file system
layer but we do not know the prior locking contexts.
Fuzzing loop. Figure 15 shows the fuzzing evolution algorithm
in KRACE. Fuzzing starts with producing a new program
by merging two existing seeds. The seed selection criterion
used in KRACE so far is simply frequency count, i.e., less
used seeds receive priority. We expect more advanced seed
selection algorithms to be developed later. After merging, each
program goes through several extension loops on which the
program structure is altered with syscalls added and deleted.
Each structurally changed program will further go through
several modification loops in which the syscall arguments
and distribution among the threads are mutated. Finally, each
modified program runs repeatedly for several times, each with
a different delay schedule, to probe for alias coverage.
Several implicit parameters can be used to fine-tune the
process, e.g., how many times to loop at each stage (see §B
for details). In general, we give preference to alias coverage
exploration over growing the multi-threaded syscall sequences,
as we prefer to explore the concurrency domain as much as
possible when the number of syscalls executed is small, making
it easier for kernel developers to debug a reported data race.
Offline checking. Data race checking is conducted offline, i.e.,
only when new coverage, either branch or alias, is found. The
reason is that data race checking is slow (several minutes) and
significantly hinders the fast fuzzing experience (which only
requires a few seconds to finish one execution). As a result, we
allow the fuzzers to quickly expand coverage and only dump
execution logs without checking them. A few background
threads check the execution logs for data races whenever they
have free capacity. The checking progress has difficulty keeping
up with seed generation in the beginning but will gradually
catch up, especially when the coverage is toward saturation.
Fig. 9: An overview of KRACE’s architecture and major components.
Components in italic fonts are either new proposals from KRACE or
existing techniques customized to meet KRACE’s purpose.
can establish Y happens-before X. On the other hand, if no
such path can be found, a happens-before relation cannot be
established and the pair should be flagged, as in the case of
i3 and i8. All other accesses are reachable in the graph, and
hence, they cannot be racing even without lock protections.
The happens-before relation commonly found in kernel file
systems can be broadly categorized into three types:
Fork-style relations include RCU callbacks registered with
call_rcu, work queues and kthread-simulated work queues,
direct kthread forking, timers, software interrupts (softirq),
as well as inter-processor interrupts (IPI). Hooking their kernel
APIs is as easy as finding corresponding functions that register
the callback and dispatch the callback.
Join-style relations include the completion API and a wide
variety of wait_* primitives such as wait_event, wait_bit,
and wait_page. Hooking their kernel APIs requires locating
their corresponding wake_up calls besides the wait calls.
Publisher-subscriber model mainly refers to the RCU pointer
assignment and dereference procedure [35]. For example, if
one user thread retrieves a file descriptor (fd) from the fdtable
which is RCU-guarded, the new fd must have been published
first, hence the causality ordering. The object allocate-and-use
pattern also falls into this realm: the publisher thread allocates
memory spaces for an object, initializes its fields, and inserts
the pointer to a global or heap-based data structure (usually a
list or hashtable), while the subscriber thread later dereferences
the pointer and uses the object. As a result, KRACE also tracks
the memory allocation APIs and monitors when the allocated
pointer is first stored into a public memory slot and when it is
used again to establish the ordering automatically.
VI. PUTTING EVERYTHING TOGETHER
A. Architecture
Figure 9 shows the overall architecture of KRACE. The
primary purpose of having the compile-time preparation is to
embed a KRACE runtime into the kernel such that alias coverage
(as well as branch coverage) can be collected dynamically. The
B. Benign vs harmful data races
An unexpected problem we encountered when reporting the
data races found by KRACE is on differentiating benign and
9
harmful data races. Despite the common belief that being data-
race free is one of the coding practices in the kernel, benign
data races are not totally uncommon. One major category is
statistics accounting, such as __part_stat_add in the block
layer. These statistics are meant for information and hints only
and do not provide any accuracy guarantees. Another example
is the reading and writing of different bits in the same 2-, 4-,
8-byte variable, especially bit-flags such as inode->i_flag or
flags in file system control structures like fs_info.
Based on our experience, checking whether a data race is
benign or harmful is often time consuming, as it requires careful
analysis of the code and documentation to infer developers’
intentions. In the worst cases, it may require consulting the file
system developers, who may not even agree among themselves.
One possibility to confirm a harmful data race is to keep the
system running until the data race causes any visible effects
such as violating assertions or memory errors. However, this is
not always feasible, as shown in the case in Figure 1. It might
need thousands of file operations running in parallel to trigger
an integer overflow. By then, debugging such an execution
trace will be another problem.
To avoid reporting benign data races to developers, KRACE
uses several simple heuristics to filter the reports. In particular,
a data race is mostly benign if:
• the race involves variables that have stat in their names
or occurs within functions for statistics accounting;
• the race involves reading and writing to different bits of
the same variable;
• the race involves kernel functions that can tolerate being
racy, e.g., list_empty_careful.
Unfortunately, these heuristics typically offer limited help for
the more complicated cases.
C. The aging OS problem
When fuzzing file systems, most generic OS fuzzers do
not reload a fresh copy of the kernel instance or file system
image [21–23] for a new fuzzing session. Instead, they directly
issue the syscall sequence on the old kernel state. The intention
is to remove the overhead of kernel booting, as a VM emulator
might take seconds to load and boot the kernel, as is evident
in our evaluations as well (§VII-B). However, this also means
that any bugs found in this approach might come from the
accumulated effects of hundreds or even thousands of prior
runs, making them extremely difficult to debug and confirm by
kernel developers, as is evident in the case when many bugs
found by Syzkaller cannot be confirmed [67].
The aging OS problem is already difficult for fuzzing in the
sequential domain, and bringing in the concurrency dimension
further complicates the story. Moreover, for KRACE, the aging
OS situation creates more problems, as the lengthy thread
interleaving traces are not only difficult to debug but also
renders analysis impossible. Slicing the execution traces does
not seem feasible either, as cutting the trace at the wrong
points means losing the locking and happens-before context,
ultimately leading to false alarms. As a result, KRACE is forced
10
to use a clean-slate execution for every fuzzing run, i.e., a fresh
kernel and a clean file system image.
The aging OS problem is also reported by Janus [5], which
uses a library OS—LKL [68]—to enable quick reloading. But
unfortunately, LKL does not support the symmetrical multi-
processing (SMP) architecture, which is the prerequisite for
multi-threading (e.g., without SMP, all spin_locks becomes
no-ops). As a result, LKL is mostly suitable for sequential
fuzzing, not for concurrency fuzzing.
D. Discussion and limitations
Deterministic replay. Being able to replay an execution
deterministically is extremely helpful for debugging and also
opens the door for advanced data race triaging techniques
such as controlled re-interleaving of thread executions. Un-
fortunately, we are sorry to report that even with a totally
linearized trace of basic block enter/exit, memory accesses,
lock acquisition/releases, and kernel synchronization API calls,
KRACE is unable to deterministically replay an execution end-
to-end. Part of the reason is the missing instrumentation in other
kernel components, including the kernel core (including the
task and IO scheduler), memory management, device drivers
(except the block device), and most of the library routines.
We expect that deterministic replay may be possible if we
instrument all kernel components but at the expense of huge
execution footprints (e.g., GB-level logs) as well as significant
performance drops. We are unaware of a system that permits
deterministic replay of over 60 kernel threads, but we are eager
to integrate if possible.
Debuggability. To partially compensate for not being able
to replay a found data race deterministically, KRACE tries to
generate a comprehensive report for each data race, including
1) the conflicting lines in source code, 2) the full call stack for
each thread, and 3) the callback graph. Since each instruction
is labeled with a compile-time random number, KRACE is able
to pinpoint the conflicting lines in the source code when a data
race occurs. Further coupled with the basic block branching
information, KRACE is able to recover the full call trace, up
to the syscall entry point or the thread creation point, for all
involving threads during the race condition. The report may
also involve the callback graph derived from the happens-
before analysis, to further assist the developers with the origin
of the threads. In fact, kernel developers have never asked
for a deterministic replay of the trace and are able to judge
whether the race is harmful or benign based on the information
provided.
Missing bugs. Offlining the data race checker means that
KRACE might miss data race bugs. As discussed in §III-B,
alias coverage is just an approximation of state exploration
progress in the concurrency dimension, and there might be new