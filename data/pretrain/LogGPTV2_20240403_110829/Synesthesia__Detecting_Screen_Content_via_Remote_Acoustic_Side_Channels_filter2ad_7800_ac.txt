misalignment made in the previous round. When correlation
of the reference chunk with the next chunk drops below T , we
enter a “sync” mode where the purpose is to re-synchronize the
chunk phase, again using correlation. If the algorithm enters
sync mode for more than 15% of the signal chunks, or if
the algorithm does not exit sync mode after three iterations,
it quits with an error. After averaging, we rotationally shift
the resultant array such that the highest value is the ﬁrst.3
Appendix A1 describes our algorithm in detail.
Choosing parameter values. d is chosen to be very small
to ensure we are not
increasing the noise by maximizing
correlation (see advantages below). We used 3 for the keyboard
snooping and cross-screen attacks, and 1 for the other ones. T
should be the threshold that differentiates best between out-of-
phase chunk pairs and in-phase chunk pairs. For clean signals
such as the close-range attack, we chose 0.9. For noisier signals
we chose 0.4-0.8, accepting some “false” entries into sync
mode. We measured S = 3206 to S = 3202 empirically
using the vsync probe. The attacker, however, does not need
to attach a probe to the victim computer: since the range of
possible values is small, the attacker can apply brute force
guessing and, using our algorithm, choose the value of S that
maximizes average chunk correlation with the master chunk
and minimizes sync mode iterations. This approach accurately
ﬁnds the correct S value using under a minute of victim
screen recordings. In our “cross-screen” experiments described
throughout
in Section VII), we performed
attacks without attaching a vsync probe to the victim screens.
Advantages of this approach.
First, it is less likely to
augment the noise introduced by the master chunk. This is
because of its strict limitation: the vast majority of chunks
found have to be consecutive and with a very tight size
constraint. Only the ﬁrst chunk in each sequence is leniently
aligned such that it correlates best with the master chunk.
the paper (e.g.
Second, the master chunk is not arbitrarily found, but is a
chunk that correlates well with at least its consecutive chunk.
An abnormally noisy chunk is less likely to be selected.
Third, the algorithm is not parametrized by the exact re-
fresh rate. Instead, it can use an approximation. Not depending
on the exact refresh rate is crucial, since it slightly changes
with time, so the attacker cannot be expected to track it.
Finally, this algorithm is much faster than the rotational-
shift-based baseline. The complexity of both methods is dom-
inated by the required Pearson correlation computations, an
operation with complexity O (S). The baseline’s approach
computes the Pearson correlation and performs this C × S
times, where C is the number of chunks. For a 5 s trace
at 192 kHz sample rate, our implementation of this approach
takes 166 s on an Intel Xeon E5-2609 v4. While in the worst
case (6000 × 0.15 × C correlation operations in sync mode,
and another 2× d× 0.85× C correlation operations in normal
mode), our algorithm performs only about three times fewer
correlation computations as the baseline; in practice it is over
two orders of magnitude faster on average. Even for recordings
captured using a parabolic mic, where the signal is noisy and
sync mode is entered relatively often, the average processing
time is less than 2 s for 5 s recordings.
Figure II.7 shows the output trace for the Punctured Si-
nusoidal Zebra image. Appendix A2 demonstrates how our
approach produces less noisy output
traces than a natural
baseline.
3This results in consistent trace phase alignment since, as we found, the
highest-value sample corresponds to one of a few refresh period phases.
858
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:34 UTC from IEEE Xplore.  Restrictions apply. 
tent, even when they are recorded using different setups. We
recorded multiple traces for zebras with 8, 16, 24, 32, and
40-pixel periods, as well as, again, a Punctured Zebra with
period 16 (as above). Alternating these patterns in a round-
robin fashion, we captured 10 3 s traces in the close-range
setting for one Dell 2208WFPt screen, and at a distance and
using the parabolic dish for another. We applied our signal
processing procedure to all traces. Next, we performed the
following for each of the two screens: ﬁrst, we randomly chose
a trace for each pattern from this screen’s traces. Then, for
every trace from the other screen, we computed its maximal
Pearson correlation over all rotational shifts, with each of the 6
chosen traces. In 100% of the cases, the trace of the matching
pattern was the one displaying the highest correlation value.
We thus conclude that screen content is the dominating factor
in the screen’s leakage signal, while screen-speciﬁc effects can
be considered as negligible.
III. ATTACK VECTORS
We consider four attack vectors. For each, we specify our
experimental setup, demonstrate that leakage exists and, in
following sections, evaluate screen content detection attacks.
A. Close-range and at-distance attacks
In this setting, the attacker uses a high-end microphone to
extract the image displayed on the screen. While a relatively
strong attack model compared to other models considered in
this paper, it is most effective for estimating the extent of
acoustic information leakage from various attack ranges.
Experimental setup. We used a setup similar to the one
in Section II-A. For the distance attack, we mounted the
microphone in a parabolic dish, placed about 10 meters away
from the screen. See Figure III.1 for an example of such
a setup. To simulate a realistic scenario, recordings were
taken in an ofﬁce environment, with some noise from nearby
equipment and people occasionally talking in the proximity of
the microphone. We do not expect speech to interfere, as most
of the leakage frequencies are well-above speech frequencies.
B. Phone attack
We consider a commodity phone placed in proximity to
a screen, recording its acoustic emanations using the phone’s
built-in microphone (see Figure III.2). This vector is useful in
a host of scenarios, such as spying on a turned-away screen
(e.g., in a business meeting) using a personal phone. The
attack can also be conducted remotely by an app, without the
phone owner’s knowledge, because many mobile apps have
permission to record audio at any time [43], [17].
Experimental setup.
For this attack setup, we used an
LG V20 phone (which supports a 192 kHz sample rateand,
empirically, exhibits good sensitivity to sound even beyond
40 kHz) directed at a screen and recording using its built-in
microphone. We used the Amazing MP3 Recorder app [44],
which supports high sample rates and offers an interface
we used for automating trace collection en masse: a “start
recording” and “stop recording” are exported by this app
and can be used by any other app on the device through
Android’s inter-app communication mechanisms. 4 In partic-
ular, we used the Android Debug Bridge (ADB) interface for
4 The app exposes interfaces (“broadcast receivers”) that can be used by
any app, regardless of its permissions, to record audio. This demonstrates the
commonplace nature of mobile based audio capturing adversaries.
Fig. II.7: The output trace of the image of II.5–a, using T =
0.9, S = 3206, d = 3. This is visually indistinguishable from
the product of chunking and averaging using the vsync probe
(see Figure II.6).
E. Cross-screen signal similarities
From a remote attacker’s perspective, the existence of leak-
age is not enough. If the leakage does not behave consistently
across screens, it will be hard for an attacker without physical
access to the victim’s screen to learn how to process its
emitted signal. This is particularly problematic for an attacker
who trains machine learning models on the leakage signal,
because they might overﬁt to screen-speciﬁc attributes. We
now show that the relationship between content and leakage
is largely predictable and similar across screens, even when
the signal is recorded through different setups and in different
environments.
Visually observing similarities. We used two Dell 2208WFPt
screens. We also used two setups: our setup from Section II-A,
the close-range setup, and one where the microphone is placed
2 meters from the screen in a parabolic dish. See Figure III.1
for an example of such a setup. Both setups were set in
different ofﬁces (with different environment noises). In each
setup for each screen, we displayed a Punctured Zebra (a Zebra
overlayed by a full-width third-height black rectangle at its
center) and recorded a 3 s trace. We applied our preprocessing
procedure from Section II-D and proceeded to visualize traces
of identical content, of the same screen, from different screens,
and from different screens and different recording settings.
Figure II.8 shows the result.
First, we compare Figure II.8a, displaying two traces of the
same Punctured Zebra on the same screen, and Figure II.8b,
displaying traces of the same pattern on different screens.
Clearly,
the correspondence of signal amplitude and pixel
intensity is similar on both screens. Next, we notice that the
traces do display some minor screen-speciﬁc traits, making
traces collected from the same screen (Figure II.8a) to be
more similar than ones collected from different screens (Fig-
ure II.8b).
Second, note that even two signals taken from different
screens and using different setups (Figure II.8c) display ob-
vious similarity: the at-distance signal is weaker, and yet has
the same characteristics, with the on-screen Black Hole clearly
inducing a ﬂat line in the middle portion of both, and the
zebra-like pixel color alternations manifesting as a sine wave
to the right and left of the ﬂat line. Below, we show this
quantitatively.
Quantifying similarity. We then applied a correlation test,
which showed that a relatively strong correlation exists be-
tween signals of different screens showing the same con-
859
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:34 UTC from IEEE Xplore.  Restrictions apply. 
(a) Different signals of the same content of the
same screen, taken using the close-range setup.
(b) Signals of two different screens, taken using
the standard setup.
(c) Signals of different screens, one (solid) taken
in close-range and one (dashed) taken from a
distance using the parabolic dish.
Fig. II.8: Signals recorded while screens were showing a Punctured Zebra (with 16-pixel period and black middle), after our
preprocessing procedure from Section II-D and correlation-based phase alignment.
order to maintain eye contact during video calls), or even
embedded into the screen itself. This microphone picks up
the screen’s acoustic emanations, the VoIP service relays it
digitally, and the remote attacker can (as we will show) analyze
this signal to extract the screen’s content.
Experimental setup.
Empirically demonstrating this, we
obtained the screen’s acoustic emanations by recording the
audio sent to a remote party during a Hangouts call, captured
using the victim’s own microphone (built into a commodity
webcam). Here, too, recordings were taken in an ofﬁce envi-
ronment with some environmental noise and human speech.
More speciﬁcally, to simulate the victim, we used a PC
running Windows 10, connected to a Dell 22" LCD monitor
(model 2208 WFPt) screen, and a Microsoft LifeCam Studio
webcam. The camera was placed naturally by the screen,
similarly to Figure III.3–a. To simulate the attacker, we used
a second PC running Ubuntu 16.04. We set up a Hangouts
connection between the attacker and victim, both running
Hangouts over a Firefox browser. At the attacker end, we
redirected all sound output from the soundcard into a loopback
device. We could then use arecord on the device to capture
sound originating at the victim end of the call.
Observing the leakage. We again performed measurements
by acquiring traces while displaying alternating Zebra patterns,
similar to those in Section II-B, but using various webcams and
screens. Figure III.3 summarizes our ﬁndings.
We discovered that, ﬁrst, commodity webcams and mi-
crophones can capture leakage. Second, natural and expected
positioning of cameras can be sufﬁcient. In fact, even the built-
in microphones in some screens (e.g., Apple LED Cinema 27-
inch, see Figure III.3–b) can be sufﬁcient. Third, the leakage
is present (and prominent) even when the audio is transmitted
through a Hangouts call; see Figure III.3–a.
Attack evaluation. See Section VI-B.
D. Virtual assistant / “smart speaker” attack
The contents of the user’s screen can be gleaned by voice-
operated virtual assistants and ”smart speakers“, such as the
Amazon’s Alexa assistant running on Amazon Echo devices
and the Google Assistant running on Google Home devices.
Once conﬁgured, such devices capture audio at all
times,
includign acoustic leakage from nearby screens. When a wake
phrase, such as “Alexa” or “Hey Google”, is detected by
the device’s elaborate microphone array, it enters an attention
Fig. III.1: Extracting an image from a screen using a parabolic
microphone at a distance of approximately 5 meters.
invoking recordings. Here, too, recordings were taken in an
ofﬁce environment with some environmental noise and human
speech.
Demonstrating leakage. We found that the phone, recording
at 192 kHz sample rate, can capture the leakage extremely well.
We performed an experiment similar to those in Section II-B
twice: once with the phone directed at the back of the screen
(simulating a physical attack in, e.g., a business meeting), and
once with the phone naturally positioned on a table near the
screen (simulating a remote attacker, e.g., an app). In both
cases, the measured screen was a Soyo DYLM2086 screen.
Figure III.2 shows the resulting spectrograms, containing the
expected leakage pattern. While for the naturally positioned
phone the signal is attenuated, it is still clearly visible on the
spectrogram. The leakage signal for the directed position is
dominant and is almost comparable to the leakage samples
recorded using high-end equipment.
Evaluation. We evaluate attacks using this vector: on-screen
keyboard snooping is evaluated in Section IV and a website
distinguishing attack is evaluated in Section VI.
C. VoIP attacker
We also consider a remote adversary who is conversing
with the target over the Internet, using a Voice over IP (VoIP)
or videoconferencing service. As long as the webcam (if any)
is not pointing at the screen (or at its reﬂection of some
object), the target would assume that remote participants in the
call cannot glean information about the local screen’s content.
However, the adversary receives an audio feed from the target’s
microphone, which is usually located close to the screen (in
860
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:34 UTC from IEEE Xplore.  Restrictions apply. 
(a) Phone microphone directed at the back of the screen.
(b) Phone placed on a desk by the screen.
Fig. III.2: Acoustic emanations (0-43 kHz, 10sec) of a BenQ q20ws screen while displaying Zebra patterns of different periods,
recorded using an LG V20 smartphone.
(a) Microsoft LifeCam Studio webcam positioned below a LED-backlit
Dell U2713H screen, recorded through a Hangouts call. The frequency
axis range is 0-13 kHz, due to the lower sampling rate used by Hangouts.
Fig. III.3: Time-frequency spectrum of alternating Zebra frequencies measured through various naturally positioned commodity
devices. The spectrograms of all combinations indicate similar acoustic leakage patterns.
(b) Self-measurement: an embedded
microphone in an LED-backlit Apple
LED Cinema 27-inch screen.