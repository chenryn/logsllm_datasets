nodes connected by n edges which are chosen randomly from
the En = N (N −1)
possible edges for the undirected networks
and from the En = N (N − 1) possible edges for the directed
networks.
In total there are
2
(cid:18)En
n (cid:19)
different graphs with N nodes and n arcs.
An alternative way in order to obtain a RG is to start with N
nodes and connect each pair of nodes with probability p. The
total number n of edges is a random variable with expectation
N (N − 1)
.
E(n) = p
2
In RG networks, the degree distribution P (k) follows a
Poisson distribution;
P r(k) ≈ e−pN (pN )k
k!
= e− k
k!
where  is the average degree of the network and the
distribution has a peak in .
4) Scale Free Network: In Scale Free (SF) networks, the
degree distribution P(k) follows a power-law [17]:
P r(k) ∼ k−γ
where γ is a real positive constant. SF networks manifest when
nodes are highly non-equivalent. Such networks have been
named Scale Free because a powerlaw has the property of
having the same functional form at all scales.
In fact, power- laws are the only functional forms that remain
unchanged, apart from multiplicative factors, under a rescaling
of the independent variable k. SF networks result
in the
simultaneous presence of a small number of very highly
connected nodes (the hubs) linked to a large number of poorly
connected nodes (the leaves).
In Table I we compare our approach, in terms of memory
and execution time, with respect to an implementation devel-
oped by ourselves of the algorithm proposed by Trivedi at al
in [22] and reported in Appendix, that as already explained
in the introduction, is a state of the art network unreliability
computation algorithm based on BDD.
Fig. 4. General scheme of our approximate approach
on the mincut probability: only the mincuts that contribute
more signiﬁcantly (above a given threshold) to the unreliability
are inserted in the mincut BDD.
Observe that, when all the edges have the same probability to
be up this corresponds to impose a limitation on the mincut
size (we shall call minpath size constraint).
Obviously,
these constraints deﬁne a trade-off between
accuracy of the approximation and computational resources
(memory and time) required for the solution, hence an incre-
mental iterative approach can be deﬁned where the network
reliability is iteratively improved relaxing the above constraints
until a sufﬁcient accuracy is reached or no more computational
resources are available.
The general scheme of our approximate approach is reported
in Fig. 4.
VI. EXPERIMENTAL RESULTS
In this section some experimental results are presented,
which were computed thanks to a prototype implementation
of the proposed approach where the BDD implementation
has been provided by an existing open–source library
(Meddly) [15].
Our choice to use this new open–source library was motivated
mainly by the fact that it automatically handles the complex
aspects of using BDDs (such as caching and garbage
collection) and provides a simple interface for common BDD
operations.
In order to test our approach we deﬁne a set of network
benchmarks of different topologies.
1) Regular Networks : Regular networks are represented by
graphs that can be described by means of deﬁned geometrical
properties.
In particular we have investigated networks where the nodes
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:09 UTC from IEEE Xplore.  Restrictions apply. 
undirected/directed random networks.
These experiments have been executed on a 2.13 GHz Intel
Xeon 64-bit processor with 132Gb RAM, and the exact value
of network unreliability has been computed using only the
minpaths.
for computing the approximate solution,
The ﬁrst three columns are related to the exact solution
and report the used memory, the execution time and the exact
unreliability value.
Instead, the last six columns are related to the approximate
approach and show the used constraints (time and path/cut
the total
size)
memory required,
the upper
(computed through a
subset of minpaths) and lower
(computed through a subset of mincuts) bounds for the
network unreliability and the accuracy of the approximation
in terms of the distance between the two bounds, divided by
the average of the two bounds. In the table a line is reported
instead of the accuracy value, when the bounds distance is
orders of magnitude wide.
the total execution time,
Observe
that often a
threshold U nrelT hr on the
the network reliability problem
unreliability is part of
formulation: in this case if the upper bound lays below the
U nrelT hr threshold, even if the bounds are very distant
from each other the objective of the study is reached.
If instead the lower bound lays above the U nrelT hr then
there is no hope that the system can satisfy the requirements.
So the accuracy is interesting only in case no speciﬁc
threshold is indicated, or when the indicated threshold lays
between the two bounds.
The experiments reported in this
table show how the
approximate approach can be a good solution when the
network complexity increases.
two
random undirected networks the approximate solution is able
to derive that exact unreliability is lower than 2.070248e−06
and 2.145800e−08 decreasing the used memory by a factor
of ∼ 7.5 and ∼ 18.5 and the execution time of 4 and 20
respectively.
This reduction in terms of memory and time is more notable
for the last model where the memory saving is about 350
times and the execution time is reduced by a factor of 840
times reaching a solution accuracy equal to 3.74.
Finally, table III shows some experiments obtained applying
our approximate approach on four different classes of
networks: scale-free, small-world, random and regular.
the ﬁrst
Indeed,
for
In detail, the ﬁrst three networks are scale-free and are
obtained varying the number of nodes and edges, and the
network diameter; the second two are small-world networks
obtained varying the number of nodes and edges and the
average degree of connectivity of each node.
Fig. 5. Benchmark network
Two scalable benchmarks have been carried out to evaluate
and to compare the efﬁciency of these two approaches: for the
former we take into account a regular n × n network topology
of increasing complexity.
Moreover, we consider random undirected network where
the pair of nodes connected by each edge are chosen randomly
among all nodes in the network.
These experiments have been executed on a 2.13 GHz Intel
Xeon 64-bit processor with 132Gb RAM, and the network
unreliability has been computed using only the minpaths and
increasing the network complexity - i.e. for the regular network
we increase the number of nodes, while for the random one we
increase both the number of nodes and the number of edges.
Moreover, for the regular network the upper left node and the
lower right node are selected as source and target, while for
the random network they are randomly chosen.
The reported experiments show that for the ﬁrst two net-
works our approach achieves a good memory saving and a
discrete execution time reduction with respect to the Trivedi
at Al. approach. For instance, the memory reduction factor
for the regular undirected network 7 × 7 is ∼ 170; while the
execution time is decreased by a factor of ∼ 19.
For the last two benchmarks the achieved reduction factor
still reaches a good memory saving increasing the model size
(e.g. for the random directed network with 500 nodes and
1494 edges the memory reduction is 18, and for the random
undirected network with 60 nodes and 160 edges the memory
reduction is 20.33); while only for the ﬁrst benchmark the
execution time is decreased.
These experimental results suggest us to plan, as future
work, a set of new experiments to better characterize for
which types of networks our approach allows a higher
reduction than the one proposed by Trivedi at Al.
In table II we compare in terms of memory, execution
time and solution quality our exact approach with the one
computing an approximation of the unreliability value on
Then, two random networks with different number of nodes
and edges are considered. Instead, the last benchmark is a
regular network with 223 nodes and 252 edges connected as
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:09 UTC from IEEE Xplore.  Restrictions apply. 
shown in Fig. 6.
For this model the exact reliability value can be easily
computed by decomposing it into as many components as
the number of repeating patterns with one source and one
destination, solving each component in isolation, and then
computing the reliability as the product of the reliabilities of
each components (since they are connected in series).
In the special case when all edges have same probability p it
is enough to compute with any method the reliability of any
component (since they are all identical) and then compute the
product.
We have thus computed the exact value, and in this case it is
very close to the upper bound obtained with the third set of
constraints.
The ﬁrst four columns in table III are related to the minpath
approximation; while the next four to the mincut approxima-
tion.
The last column represents the relative accuracy and is com-
puted as for Table II.
For each type of approximation the number of min-
paths/mincuts, the used constraints, the total execution time
(i.e. minpaths/mincuts search + connectivity graph generation
+ approximation computation), and the approximate value of
unreliability are reported.
The results in this last table highlight that our approximate
approach is able to compute a good approximation for network
that otherwise are intractable.
Two further considerations can be derived, ﬁrst the minpath
approximation is more efﬁcient (in terms of execution time
and solution quality) than the mincut one.
This is mainly due to the fact that the developed minpath
search, as explained in Sec.IV and Sec. V, is able to ﬁnd
the most important minpaths that can greatly decrease the
unreliability upper bound. For this reason, in the future we
are going to study how to improve the mincut search to ﬁnd
ﬁrst the most important mincuts.
The second consideration is related to the fact that in most
of these experiments to further increase the solution quality
quickly leads to an exponential growth of the execution time.
For instance, for the Small-world network with 500 nodes and
5000 edges and average degree of connectivity equal to 20,
a small increment in the number of considered minpaths (i.e.
∼ 150) increases the computation time more than 3 hours.
VII. CONCLUSION
In this paper we have presented a new symbolic approach
based on BDDs to compute the network reliability using the
minpaths and/or the mincuts.
The performance of this approach was compared to a state
of the art network reliability algorithm [22] through a set of
experiments on different types of networks; the comparison
has shown a generalized, and in same cases very consistent,
memory saving and execution time reduction.
Moreover, we have shown how the proposed approach can
be used for the computation of (un)reliability bounds: applying
the same approach to any subset of minpaths we obtain a
(upper)lower bound while applying the approach to any subset
of mincuts we obtain an (lower)upper bound.
The upper and lower bounds have been compared with the
exact solution in a ﬁrst set of experiments, highlighting how
a good accuracy can be obtained with a substantial saving in
memory occupation and computational time.
In a second set of experiments we have computed the bounds
for networks whose dimensions are far beyond the capabilities
of any exact algorithm, showing again how a good accuracy
can be attained with a reasonable computational effort.
From all these experiments two main considerations were
derived: ﬁrst, the implementation of the approximation based
on the minpaths is more efﬁcient (in terms of execution time
and solution quality) than the one based on the mincuts;
second, in most experiments a further increase in the solution
quality quickly leads to an exponential growth of the execution
time.
According to the obtained results two future developments
will be pursued. The ﬁrst one intends to investigate for which
type of networks our approach reaches higher speed up factors
with respect to traditional approaches. The second one, is
directed toward the possibility of improving the mincut search
ﬁnding a way to select the most important mincuts as we do
for the minpaths.
Finally we will investigate how other reduction policies (e.g.
zero-suppressed) may improve the performance of our ap-
proach.
REFERENCES
[1] J.A. Abraham. An improved algorithm for network reliability.
IEEE
Transaction on Reliability, 28:58–61, 1979.
[2] A. Agrawal, , and R. E. Barlow. A survey of network reliability and
domination theory. Operations Research, 32:478–492, 1984.
[3] A.O. Balan and L. Traldi. Preprocessing minpaths for sum of disjoint
IEEE Transaction on Reliability, 52(3):289–295, September
products.
2003.
[4] M.O. Ball. Computational complexity of network reliability analysis:
An overview. IEEE Transactions on Reliability, R-35:230–239, 1986.
[5] M. Beccuti, S. Donatelli, G. Franceschinis, and R. Terruggia. A new
symbolic approach for network reliability analysis. volume TR-INF-
2011-06-02-UNIPMN. Ed. Computer Science Department, UPO, 2011.
[6] A. Bobbio and R. Terruggia. Reliability and quality of service in
weighted probabilistic networks using algebraic decision diagrams. In
Proceedings IEEE Annual Reliability and Maintainability Symposium,
pages 19–24, Fort Worth, TX, 2009.
[7] R.E. Bryant. Graph-based algorithms for Boolean function manipulation.
IEEE Transactions on Computers, C-35:677–691, 1986.
[8] J.R. Burch, E.M. Clarke, K.L. McMillan, D.L. Dill, and J. Hwang.
Information and
Symbolic model checking: 1020 states and beyond.
Computation, 98:142–170, 1992.
[9] E. S. Elmallah and H. M. F. AboElFotoh. Circular layout cutsets:
An approach for improving consecutive cutset bounds for network
reliability. IEEE Transactions on Relibility, 55:602–612, 2006.
[10] P. Erd¨os and A. R´enyi. On Random Graphs. I. Publicationes Mathe-
maticae, 1959.
[11] G. Hardy, C. Lucet, and N. Limnios. Computing all-terminal reliability
In Proceedings
of stochastic networks by Binary Decision Diagrams.
Applied Stochastic Modeling and Data Analysis, 2005.
[12] G. Hardy, C. Lucet, and N. Limnios. K-terminal network reliability
IEEE Transactions on
measures with Binary Decision Diagrams.
Reliability, 56:506–515, 2007.
[13] K. Heidtmann. Statistical comparison of two sum-of-disjoint product
algorithms for reliability and safety evaluation.
In Proceedings 21st
International Conference SAFECOMP 2002, pages 70–81. Springer
Verlag, LNCS Vol 2434, 2002.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:09 UTC from IEEE Xplore.  Restrictions apply. 
Existing Approach
Our Approach
Mem.
T.
Mem.
T.
Mem. Red.
12
15.49
18.12
20.66
23.27
25.76
-
-
-
17.74
77
170.3
18
1.73
2.38
3.69
17.45
20.33
Size
n × n
8 × 8
9 × 9
10 × 10
11 × 11
12 × 12
13 × 13
14 × 14
15 × 15
16 × 16
n × n
5 × 5
6 × 6
7 × 7
N, E
2.9MB
8.8MB
25.9MB
71.8MB
194MB
509MB
out of memory
out of memory
out of memory
Regular Directed network
0
0
5
12
47
171
-
-
-
245KB
568KB
1.4MB
3.4MB
8,3MB
19.7MB
46MB
107MB
245.6MB
0
0
1
5
24
108
1089.52
4797.68
21707.78
Regular Undirected network
1.9MB
112MB
1.9GB
0
41
19,490
112KB
1.4MB
11.7MB
0
27.35
1,004.42
Random Directed network
32,400
5.4GB
25,200
500, 1494
97.2GB
N, E
20, 28
30, 36
30, 41
50, 144