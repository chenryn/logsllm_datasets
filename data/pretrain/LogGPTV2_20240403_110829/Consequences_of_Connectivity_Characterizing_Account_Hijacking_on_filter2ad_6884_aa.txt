title:Consequences of Connectivity: Characterizing Account Hijacking on
Twitter
author:Kurt Thomas and
Frank Li and
Chris Grier and
Vern Paxson
Consequences of Connectivity: Characterizing
Account Hijacking on Twitter
†
Kurt Thomas
†
Frank Li
†
University of California, Berkeley
∗
†∗
†∗
Chris Grier
International Computer Science Institute
Vern Paxson
{kthomas, frankli, grier, vern}@cs.berkeley.edu
ABSTRACT
In this study we expose the serious large-scale threat of crim-
inal account hijacking and the resulting damage incurred by
users and web services. We develop a system for detecting
large-scale attacks on Twitter that identiﬁes 14 million vic-
tims of compromise. We examine these accounts to track
how attacks spread within social networks and to determine
how criminals ultimately realize a proﬁt from hijacked cre-
dentials. We ﬁnd that compromise is a systemic threat, with
victims spanning nascent, casual, and core users. Even brief
compromises correlate with 21% of victims never returning
to Twitter after the service wrests control of a victim’s ac-
count from criminals.
Infections are dominated by social
contagions—phishing and malware campaigns that spread
along the social graph. These contagions mirror informa-
tion diﬀusion and biological diseases, growing in virulence
with the number of neighboring infections. Based on the
severity of our ﬁndings, we argue that early outbreak detec-
tion that stems the spread of compromise in 24 hours can
spare 70% of victims.
Categories and Subject Descriptors
K.4.1 [Public Policy Issues]: Abuse and crime involving
computers
Keywords
Account hijacking; compromise; social networks
1.
INTRODUCTION
In this paper, we expose the serious large-scale threat
of criminal account hijacking and the resulting damage in-
curred by users and web services. To conduct our study,
we develop a systematic approach for detecting large-scale
attacks on Twitter that we leverage to identify victims of
compromise, track how compromise spreads within the so-
cial network, and evaluate how criminals ultimately realize
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2957-6/14/11 15.00.
http://dx.doi.org/10.1145/2660267.2660282.
a proﬁt from hijacked credentials. We retrospectively apply
our detection scheme on a dataset consisting of 8.7 billion
tweets generated by 168 million Twitter users during a 10-
month period between January, 2013–October, 2013. In to-
tal, we identify 14 million users that fell victim to hijacking
in addition to nearly 5 million fraudulent accounts used to
fuel spam campaigns. While it is possible to repurpose our
detection techniques to operate in real time and to serve as
a defense, our key contribution with this research is to bring
to light the systemic risks legitimate users face on social
networks.
We ﬁnd that criminals succeed in hijacking accounts
from users around the globe, irrespective of user savviness.
Nascent, casual, and core users with hundreds to thou-
sands of followers all fall victim to attacks. Even brief
compromises—we ﬁnd a median duration of 1 day in our
dataset—correlate with 21% of victims never returning to
Twitter after the service wrests control of a victim’s account
from criminals. Furthermore, 57% of victims lose friends
post-compromise in response to spam the victim’s account
sends. These results illustrate that compromise is not a sim-
ple threat easily solved by password resets; instead, social
networks incur lasting damage after each attack with respect
to core success metrics such as user retention and engage-
ment.
Our results suggest that criminals rely heavily on social
contagions—phishing and malware campaigns that spread
along the Twitter social graph and exploit a user’s friends.
Of over 2,600 distinct outbreaks of compromise we identify,
88% exhibit graph connectivity between the victims. These
contagions grow in virulence with the number of neighbor-
ing victims, where a user with 20 compromised neighbors
is 10x more likely to become compromised compared to a
user with one compromised neighbor. We ﬁnd that the so-
cial process driving compromise mirrors that of information
diﬀusion [2, 5] and biological infections [21]. A direct conse-
quence is that compromise in social networks spreads much
slower compared to Internet worms [24], with only 30% of
victims emerging in the ﬁrst day of a contagion’s outbreak.
This opens up the possibility for the early detection of hi-
jacking attacks, where stopping contagions in 24 hours would
spare 70% of victims.
Finally, as compromise is a ﬁnancial endeavor, we exam-
ine how criminals monetize hijacked accounts. We identify
three dominant strategies: the sale of nutraceutical weight
loss supplements, fake follower (or retweet and favorite) pro-
grams, and lead-generation scams. Combined, 68% of com-
promised victims hawk these money-making schemes, ac-
489counting for 69% of all spam tweets generated by hijacked
credentials. These schemes are similar to previous Twitter
spam campaigns that rely on fraudulent accounts [16, 28],
though the challenge of reaching an audience is vastly sim-
pliﬁed by account hijacking.
In summary, we frame our contributions as follows:
• We demonstrate the hijacking by criminals of more
than 13 million Twitter accounts; this threat repre-
sents one of the single largest challenges facing web
services.
• We ﬁnd that even when Twitter wrests control of ac-
counts from criminals, 21% of victims never return to
the service and 57% lose friends.
• We show that criminals rely on phishing and malware
campaigns that exploit social connections to spread
in a similar fashion to memes and biological diseases,
making them increasingly virulent.
• We characterize how criminals ultimately proﬁt by
spamming a victim’s followers with weight loss sup-
plements, fake follower programs, and lead generation
scams.
2. BACKGROUND AND RELATED WORK
While the prevalence of compromised users amongst
spamming accounts has been identiﬁed by a number of prior
studies, the process driving account hijacking and the dam-
age that ensues has never been explored. We provide an
overview of the potential mechanisms criminals use to hijack
accounts as well as outline previous approaches for detecting
unwarranted behavior on a victim’s account. Whenever ap-
plicable, we highlight how our research ﬁts into the broader
context of abuse targeting social networks.
2.1 Account Hijacking Techniques
Database Dumps: Sophisticated attacks on companies are
emerging as a regular threat, where breaches have resulted
in the exposure of millions of usernames and passwords at
Adobe, LinkedIn, and Twitter [17, 22, 26]. When breaches
are directly linked to a social network, criminals can take
control of a victim’s account. Alternatively, break-ins at
unrelated services can still prove lucrative to criminals due
to 43% of users reusing passwords across services [8].
Password Guessing: Weak passwords face a signiﬁcant
risk from brute-force guessing. For example, miscreants
launched an attack targeting GitHub from 40,000 addresses,
aﬀecting an unknown number of victims [4]. Provided
enough time and resources, criminals can eﬀectively mine
the credentials of multiple victims to access their accounts.
Social Contagion: Rather than target weaknesses in a web
service, criminals can target a service’s users by disseminat-
ing phishing pages and malware via social engineering like
the Koobface botnet [29] or by drive-by exploits [15]. We
refer to attacks that spread within a social network along
graph edges as a social contagion.
External Contagion: Malware and phishing attacks
spreading externally to a social network can still result in
criminals stealing a victim’s social credentials. We refer to
such attacks as an external contagion.
2.2 Detecting Hijacked Accounts
Our approach for detecting hijacked accounts builds on a
large body of prior work for characterizing spam and abuse
in social networks. In particular, we iterate on previous ap-
proaches by Gao et al. [12, 13] and Grier et al. [16] for clus-
tering social network content into spam campaigns based on
text and URL features. One limitation of these approaches
is they fail to distinguish between fraudulent accounts used
solely to disseminate spam and compromised accounts ex-
hibiting symptoms of an infection. While the authors of both
works conclude that compromised accounts are responsible
for a substantial fraction of spam, this conclusion was based
purely on manual analysis, rather than devising an auto-
mated framework for detecting hijacking. Furthermore, the
authors focused their analysis on spam campaigns, omitting
any discussion of how victims were hijacked.
One existing approach for explicitly detecting hijacked
victims in social networks is COMPA [10]. This system
builds a historical model of a user’s activities such as ap-
plication usage, language, and posting frequency. When an
anomalous message appears on a victim’s account that vio-
lates the constructed usage proﬁle, the user is considered hi-
jacked. This signal is boosted by identifying clusters of users
that all post similar content. Our approach, while similar
in that we cluster hijacked victims, makes no assumptions
on the stability of user behavior (which may change due to
travel, installing new apps, or varying engagement levels)
and does not require an historical model per account, which
is expensive to maintain at scale. Furthermore, while we be-
lieve our detection framework can be deployed as a proactive
defense, its purpose in this paper is a means for generating a
sample of hijacked victims—our primary contribution in this
work is examining the impact and spread of compromise.
3. METHODOLOGY
Our strategy for identifying the hijacked accounts in so-
cial networks consists of ﬁve components, outlined in Fig-
ure 1. Over a 10 month period we collect 61% of all tweets
containing URLs, amounting to roughly 40M tweets per
day (). We organize these tweets into clusters (), clas-
sifying each cluster as either a benign meme, an infection
spreading via compromised accounts, or spam campaigns
produced by fraudulent accounts (). We then crawl the
social graph of the accounts involved in each cluster (),
allowing us to measure the connectivity of victims and as-
sociated graph properties. Finally, we label each account
in our dataset as benign, compromised, or fraudulent ().
The entire process uses a combination of Hadoop, Pig, and
Spark.
3.1 Data Collection
Our dataset consists of 8.7 billion tweets posted by 168
million users between January 7, 2013 through October 21,
2013. We collect tweets directly from Twitter’s stream-
1
using the statuses/ﬁlter method which we conﬁg-
ing API
ure to return a privileged sample of all tweets containing
URLs. Our feed does not provide a ﬁxed sample rate; in-
stead, we receive a reduced sample size during peak strain on
network routes between our collection point and Twitter’s
API infrastructure, a phenomenon previously documented
by Morstatter et al [20].
1
https://dev.twitter.com/docs/streaming-apis
490Figure 1: Data processing pipeline. We receive a stream of roughly 40M tweets per day, which we store into HDFS. We
then group these tweets into clusters, labeling them as memes, spam from fraudulent accounts, or infections based on whether
Twitter has since deleted or disabled the tweets or accounts. Once classiﬁed, we crawl the social graph of all accounts and
ﬁnally label each account.
100%
80%
60%
40%
s
t
e
e
w
T
f
o
e
g
a
t
n
e
c
r
e
P
Mon
Tue
Wed
Thu
Weekday
Fri
Sat
Sun
Figure 2: Average daily sample rate throughout our col-
lection period. We receive nearly 100% of all tweets with
URLs around midnight PST, while our sample rate drops to
roughly 40% during peak hours of network strain.
To understand how the network bottleneck impacts our
sample rate, we compare the overlap of our sample with
the statuses/sample feed (collected over the same period and
unaﬀected by network bottlenecks) which Twitter advertises
as a real-time truly random sample ﬁxed at 1% of all tweets.
We ﬁnd that we receive roughly 40% of all tweets with URLs
during peak hours of Twitter activity and nearly 100% of all
tweets with URLs during low periods of activity, as shown in
Figure 2. In total, we estimate we receive 61% of all tweets
with URLs averaged across all days and hours.
3.2
Identifying Tweet Clusters
We organize the billions of tweets in our dataset into clus-
ters through a combination of text, URL, and user cluster-
ing, similar to previous approaches for identifying memes
and spam clusters on Twitter [12, 13, 16, 27, 28]. Clustering
is a two step process, as shown in Figure 1 (): we ﬁrst group
all of the tweets in our dataset based on an approximation
of their content represented by a minhash [3]. We also em-
ploy a secondary clustering strategy, whereby we group any
tweets with the same URL. The clusters resulting from both
of these steps are then fed into a ﬁnal phase where we merge
clusters with overlapping users, storing the ﬁnal collections
of tweets and users.
3.2.1 Clustering on Similar Content
Apart from retweet chains where the provenance of a clus-
ter is explicit, identifying tweets that all discuss a similar
topic is typically a problem associated with near duplicate
detection and topic modeling. In order to measure the se-
mantic similarity between two tweets, there is a noteworthy
distinction between exact duplicates and near duplicates [27].
Exact Duplicates are any pair of tweets where every
character is identical. Legitimate exact duplicates result
from retweet chains, users sharing news stories, and auto-
generated messages from applications, while spam exact du-
plicates appear because a single spammer posts an identical
message distributed via multiple fraudulent or compromised
accounts.
Near Duplicates are any pair of tweets with a strong
degree of content overlap (as developed below). Cosmetic
diﬀerences occur because legitimate users rephrase a story or
news item, while spammers frequently permute spam tem-
plates in order to evade rudimentary text clustering. An
example from our dataset:
m1: Aweesomeee!
couple of surveys. http://t.co/cwG67lh4
m2: Awesome! I made $106.03 this week so far just ﬁlling out
a couple of surveys. http://t.co/PoHBayLz
I made $171.50 this week so far taking a
In order to detect whether a pair of tweets are near du-
plicate, we ﬁrst strip each tweet of Twitter speciﬁc nomen-
clature such as mentions (@user) and retweets (RT @user),
any URLs in the tweet, and any remaining non-alpha char-
acters (thus removing digits, punctuation, and whitespace).
We then compute the set of all character n-grams from the
message using a rolling window, where n is a tunable pa-
rameter. We consider two messages to be equal if their set
of n-grams Mi and Mj have a Jaccard similarity coeﬃcient
greater than τ , where we calculate the Jaccard metric as:
J(Mi, Mj) =
To avoid a pairwise O(N 2
|Mi ∩ Mj|
|Mi ∪ Mj|
) comparison of billions of
tweets, we rely on minhashing to serve as an estimator for
J(Mi, Mj). For each element e in the set of character n-
grams Mi we compute the hash H(e). We then sort the
resulting set of hashes and select the k minimum hashes
from the ordered set, where k is a tunable parameter. The
likelihood that two near duplicate messages share the same
k hashes is proportional to the Jaccard similarity coeﬃ-
cient [3]. We ignore messages with fewer than k hashes, pre-
venting us from treating simple tweets such as lol http://...
as part of the same cluster.
In order to determine the optimal parameters for n and k
given our text corpus, we perform a grid search over multiple
variants of the minhash algorithm on a sample dataset of
19M tweets. We calculate the average Jaccard coeﬃcient
for all pairs of messages with the same minhash, excluding
messages that are exact duplicates. We show our results
491y
t
i
r
a
l
i
i
m
S
d
r
a
c
c
a
J
0.8
0.6
0.4
0.2
0.0
2
3
4
5
6
7
Tokens
ngrams ●
2grams
3grams
4grams
Figure 3: Grid search of the relation between the Jaccard
similarity coeﬃcient and pairs of tweets sharing the same
minhash. We search over k, the number of hashed tokens to
use, and n, the size of n-grams.
in Figure 3. We ultimately elect a minhashing algorithm
set to n = 3 and k = 7 for a Jaccard similarity threshold
of τ = 0.8, which we ﬁnd strikes the best balance between
capturing wide variants of spam templates without colliding
with benign, unrelated messages.
Given our ﬁnal minhashing algorithm H(k,n), we trans-
form every tweet in our corpus into a key-value pair
(H(k,n)(m), tweet). We then group all tweets with the same
minhash and treat them as a single cluster. Once grouped,
we ﬁlter out any minhash clusters with fewer than a thou-
sand tweets to reduce the volume of clusters that we must
process and label. In total, this clustering approach yields
29,687 clusters.
3.2.2 Clustering on Duplicate URLs
Another canonical method for identifying the spread of
ideas or spam campaigns in social networks is by clustering
messages based on the URL they contain [13, 14, 28]. We
follow previous approaches and transform each tweet into
a key-value pair(URL, tweet) , subsequently grouping all
tweets by their URL key.
In the event a tweet contains
multiple URLs, we create a key-value pair for each URL,
allowing a tweet to be a member of multiple clusters. Once
grouped, we again ﬁlter out any URL clusters with fewer
than a thousand tweets.
In total, this step yields 36,994
clusters.
3.2.3 Merging Clusters of Overlapping Users
In our ﬁnal clustering step, we merge pairs of clusters with
overlapping sets of users. This step is necessary to combine
clusters of spam accounts that post multiple distinct mes-
sages and to merge duplicate minhash and URL clusters.
Similar to how we merge near duplicate tweets, given the
set of users for two clusters Ci and Cj, we merge the two