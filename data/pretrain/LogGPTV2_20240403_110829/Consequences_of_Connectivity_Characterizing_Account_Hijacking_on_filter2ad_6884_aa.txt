# Consequences of Connectivity: Characterizing Account Hijacking on Twitter

**Authors:**
- Kurt Thomas
- Frank Li
- Chris Grier
- Vern Paxson

**Affiliations:**
- University of California, Berkeley
- International Computer Science Institute

**Contact:**
- {kthomas, frankli, grier, vern}@cs.berkeley.edu

## Abstract

This study exposes the significant large-scale threat of criminal account hijacking and the resulting damage to users and web services. We developed a system for detecting large-scale attacks on Twitter, identifying 14 million victims of compromise. By examining these accounts, we track how attacks spread within social networks and determine how criminals profit from hijacked credentials. Our findings indicate that compromise is a systemic threat, affecting nascent, casual, and core users. Even brief compromises correlate with 21% of victims never returning to Twitter after the service regains control of their accounts.

Infections are primarily driven by social contagions—phishing and malware campaigns that spread along the social graph. These contagions mirror information diffusion and biological diseases, becoming more virulent with the number of neighboring infections. Based on our findings, we argue that early outbreak detection, which can stop the spread of compromise within 24 hours, can spare 70% of victims.

**Categories and Subject Descriptors:**
- K.4.1 [Public Policy Issues]: Abuse and crime involving computers

**Keywords:**
- Account hijacking, compromise, social networks

## 1. Introduction

In this paper, we expose the serious large-scale threat of criminal account hijacking and the resulting damage incurred by users and web services. To conduct our study, we developed a systematic approach for detecting large-scale attacks on Twitter. This approach allows us to identify victims of compromise, track how compromise spreads within the social network, and evaluate how criminals ultimately profit from hijacked credentials.

We retrospectively applied our detection scheme to a dataset consisting of 8.7 billion tweets generated by 168 million Twitter users over a 10-month period from January to October 2013. In total, we identified 14 million users who fell victim to hijacking, in addition to nearly 5 million fraudulent accounts used to fuel spam campaigns. While our detection techniques can be repurposed for real-time defense, our key contribution is to highlight the systemic risks legitimate users face on social networks.

Our findings show that criminals succeed in hijacking accounts from users globally, regardless of user savviness. Nascent, casual, and core users with hundreds to thousands of followers all fall victim to attacks. Even brief compromises, with a median duration of 1 day in our dataset, correlate with 21% of victims never returning to Twitter after the service regains control of their accounts. Furthermore, 57% of victims lose friends post-compromise due to spam sent from their accounts. These results illustrate that compromise is not a simple threat easily solved by password resets; instead, social networks incur lasting damage after each attack, impacting core success metrics such as user retention and engagement.

Criminals rely heavily on social contagions—phishing and malware campaigns that spread along the Twitter social graph and exploit a user’s friends. Of the over 2,600 distinct outbreaks of compromise we identified, 88% exhibit graph connectivity between the victims. These contagions grow in virulence with the number of neighboring victims, where a user with 20 compromised neighbors is 10 times more likely to become compromised compared to a user with one compromised neighbor. The social process driving compromise mirrors that of information diffusion and biological infections. A direct consequence is that compromise in social networks spreads much slower compared to Internet worms, with only 30% of victims emerging in the first day of a contagion's outbreak. This opens up the possibility for early detection of hijacking attacks, where stopping contagions within 24 hours could spare 70% of victims.

Finally, as compromise is a financial endeavor, we examined how criminals monetize hijacked accounts. We identified three dominant strategies: the sale of nutraceutical weight loss supplements, fake follower (or retweet and favorite) programs, and lead-generation scams. Combined, 68% of compromised victims promote these money-making schemes, accounting for 69% of all spam tweets generated by hijacked credentials. These schemes are similar to previous Twitter spam campaigns that rely on fraudulent accounts, though the challenge of reaching an audience is vastly simplified by account hijacking.

In summary, our contributions are as follows:
- We demonstrate the hijacking of more than 13 million Twitter accounts, representing one of the single largest challenges facing web services.
- We find that even when Twitter regains control of accounts, 21% of victims never return to the service and 57% lose friends.
- We show that criminals rely on phishing and malware campaigns that exploit social connections, spreading in a manner similar to memes and biological diseases, making them increasingly virulent.
- We characterize how criminals ultimately profit by spamming a victim’s followers with weight loss supplements, fake follower programs, and lead generation scams.

## 2. Background and Related Work

While the prevalence of compromised users among spamming accounts has been identified by several prior studies, the process driving account hijacking and the ensuing damage has not been thoroughly explored. We provide an overview of the potential mechanisms criminals use to hijack accounts and outline previous approaches for detecting unauthorized behavior on a victim’s account. Where applicable, we highlight how our research fits into the broader context of abuse targeting social networks.

### 2.1 Account Hijacking Techniques

- **Database Dumps:** Sophisticated attacks on companies, such as breaches at Adobe, LinkedIn, and Twitter, have resulted in the exposure of millions of usernames and passwords. When breaches are directly linked to a social network, criminals can take control of a victim’s account. Alternatively, break-ins at unrelated services can still prove lucrative due to 43% of users reusing passwords across services.
- **Password Guessing:** Weak passwords are at risk from brute-force guessing. For example, an attack targeting GitHub from 40,000 addresses affected an unknown number of victims. Given enough time and resources, criminals can effectively mine the credentials of multiple victims to access their accounts.
- **Social Contagion:** Criminals can target a service’s users by disseminating phishing pages and malware via social engineering, such as the Koobface botnet or drive-by exploits. We refer to attacks that spread within a social network along graph edges as social contagions.
- **External Contagion:** Malware and phishing attacks spreading externally to a social network can still result in criminals stealing a victim’s social credentials. We refer to such attacks as external contagions.

### 2.2 Detecting Hijacked Accounts

Our approach for detecting hijacked accounts builds on a large body of prior work for characterizing spam and abuse in social networks. Specifically, we iterate on previous approaches by Gao et al. and Grier et al. for clustering social network content into spam campaigns based on text and URL features. One limitation of these approaches is that they fail to distinguish between fraudulent accounts used solely to disseminate spam and compromised accounts exhibiting symptoms of an infection. While the authors concluded that compromised accounts are responsible for a substantial fraction of spam, this conclusion was based on manual analysis rather than an automated framework for detecting hijacking.

An existing approach for explicitly detecting hijacked victims in social networks is COMPA. This system builds a historical model of a user’s activities, such as application usage, language, and posting frequency. When an anomalous message appears on a victim’s account that violates the constructed usage profile, the user is considered hijacked. Our approach, while similar in that we cluster hijacked victims, makes no assumptions about the stability of user behavior and does not require a historical model per account, which is expensive to maintain at scale. Additionally, while our detection framework can be deployed as a proactive defense, its primary purpose in this paper is to generate a sample of hijacked victims, allowing us to examine the impact and spread of compromise.

## 3. Methodology

Our strategy for identifying hijacked accounts in social networks consists of five components, outlined in Figure 1. Over a 10-month period, we collected 61% of all tweets containing URLs, amounting to roughly 40 million tweets per day. We organized these tweets into clusters, classifying each cluster as either a benign meme, an infection spreading via compromised accounts, or spam campaigns produced by fraudulent accounts. We then crawled the social graph of the accounts involved in each cluster, allowing us to measure the connectivity of victims and associated graph properties. Finally, we labeled each account in our dataset as benign, compromised, or fraudulent. The entire process uses a combination of Hadoop, Pig, and Spark.

### 3.1 Data Collection

Our dataset consists of 8.7 billion tweets posted by 168 million users between January 7, 2013, and October 21, 2013. We collected tweets directly from Twitter’s streaming API using the statuses/filter method, which we configured to return a privileged sample of all tweets containing URLs. Our feed does not provide a fixed sample rate; instead, we receive a reduced sample size during peak strain on network routes between our collection point and Twitter’s API infrastructure, a phenomenon previously documented by Morstatter et al.

To understand how the network bottleneck impacts our sample rate, we compared the overlap of our sample with the statuses/sample feed, which Twitter advertises as a real-time, truly random sample fixed at 1% of all tweets. We found that we received roughly 40% of all tweets with URLs during peak hours of Twitter activity and nearly 100% of all tweets with URLs during low periods of activity, as shown in Figure 2. In total, we estimate we received 61% of all tweets with URLs averaged across all days and hours.

### 3.2 Identifying Tweet Clusters

We organized the billions of tweets in our dataset into clusters through a combination of text, URL, and user clustering, similar to previous approaches for identifying memes and spam clusters on Twitter. Clustering is a two-step process, as shown in Figure 1:

#### 3.2.1 Clustering on Similar Content

Apart from retweet chains where the provenance of a cluster is explicit, identifying tweets that discuss a similar topic is typically a problem associated with near duplicate detection and topic modeling. To measure the semantic similarity between two tweets, there is a noteworthy distinction between exact duplicates and near duplicates.

- **Exact Duplicates:** Any pair of tweets where every character is identical. Legitimate exact duplicates result from retweet chains, users sharing news stories, and auto-generated messages from applications, while spam exact duplicates appear because a single spammer posts an identical message distributed via multiple fraudulent or compromised accounts.
- **Near Duplicates:** Any pair of tweets with a strong degree of content overlap. Cosmetic differences occur because legitimate users rephrase a story or news item, while spammers frequently permute spam templates to evade rudimentary text clustering.

To detect whether a pair of tweets are near duplicates, we first strip each tweet of Twitter-specific nomenclature such as mentions (@user) and retweets (RT @user), any URLs in the tweet, and any remaining non-alpha characters. We then compute the set of all character n-grams from the message using a rolling window, where n is a tunable parameter. We consider two messages to be equal if their set of n-grams Mi and Mj have a Jaccard similarity coefficient greater than τ, where we calculate the Jaccard metric as:

\[ J(Mi, Mj) = \frac{|Mi \cap Mj|}{|Mi \cup Mj|} \]

To avoid a pairwise O(N^2) comparison of billions of tweets, we rely on minhashing to serve as an estimator for J(Mi, Mj). For each element e in the set of character n-grams Mi, we compute the hash H(e). We then sort the resulting set of hashes and select the k minimum hashes from the ordered set, where k is a tunable parameter. The likelihood that two near duplicate messages share the same k hashes is proportional to the Jaccard similarity coefficient. We ignore messages with fewer than k hashes, preventing us from treating simple tweets such as "lol http://..." as part of the same cluster.

To determine the optimal parameters for n and k given our text corpus, we performed a grid search over multiple variants of the minhash algorithm on a sample dataset of 19 million tweets. We calculated the average Jaccard coefficient for all pairs of messages with the same minhash, excluding messages that are exact duplicates. Our results are shown in Figure 3. We ultimately elected a minhashing algorithm set to n = 3 and k = 7 for a Jaccard similarity threshold of τ = 0.8, which we found strikes the best balance between capturing wide variants of spam templates without colliding with benign, unrelated messages.

Given our final minhashing algorithm H(k,n), we transformed every tweet in our corpus into a key-value pair (H(k,n)(m), tweet). We then grouped all tweets with the same minhash and treated them as a single cluster. Once grouped, we filtered out any minhash clusters with fewer than a thousand tweets to reduce the volume of clusters that we must process and label. In total, this clustering approach yielded 29,687 clusters.

#### 3.2.2 Clustering on Duplicate URLs

Another canonical method for identifying the spread of ideas or spam campaigns in social networks is by clustering messages based on the URL they contain. We followed previous approaches and transformed each tweet into a key-value pair (URL, tweet), subsequently grouping all tweets by their URL key. If a tweet contains multiple URLs, we created a key-value pair for each URL, allowing a tweet to be a member of multiple clusters. Once grouped, we again filtered out any URL clusters with fewer than a thousand tweets. In total, this step yielded 36,994 clusters.

#### 3.2.3 Merging Clusters of Overlapping Users

In our final clustering step, we merged pairs of clusters with overlapping sets of users. This step is necessary to combine clusters of spam accounts that post multiple distinct messages and to merge duplicate minhash and URL clusters. Similar to how we merge near duplicate tweets, given the set of users for two clusters Ci and Cj, we merged the two clusters if their sets of users had a Jaccard similarity coefficient greater than a specified threshold.

---

This revised version of the text is more structured, coherent, and professional, with clear headings and subheadings for better readability and understanding.