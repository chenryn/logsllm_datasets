(Sec 5.4)
Video
Reduction
Acoustic 
Reduction
Acoustic 
Signals
Whole Key 
Search Space
Click & Cluster 
Detection
(Sec 5.2)
Synthesized Click 
Pattern Extraction 
(Sec 5.3)
Click 
Detection
Cluster 
Detection
Refining Click 
Detection
Synthesized 
Patterns
Victim 
Key
Keycode  Rank
97252      1
25043      2
58324      3
⋮
⋮
Figure 5: Figure depicts Keynergy’s design. For audio-based
reduction, we utilize multiple key insertion recordings, and
synthesize a representative click pattern, to compare against
simulated patterns of keys to obtain a key rank-list. We obtain
the subset of keys that we utilize for this comparison from
video-based approach. The ﬁnal predicted key-rank of the
victim’s key is likely to be among the top ranks.
1
0.75
0.5
0.25
Noise 
Detected
Click 
Missed
0
0
0.02
0.05
0.07
0.09
0.12
0.14
(a)
Cluster 1 Cluster 2 Cluster 3 Cluster 4
Cluster 5
Cluster 3
Noise 
Missed
1
0.75
0.5
0.25
0
0
0.008
0.016
1
0.75
0.5
0.25
0
(b)
Cluster 4
0.018
0.028
0.009
(c)
1
0.75
0.5
0.25
0
0
Cluster 5
Click 
Detected
0.009
0.017
0.026
Figure 6: Figure depicts (a) detection of 15 clicks on the
weighted spectral ﬂux representation. (b) depicts the detec-
tion of clusters. (c) depicts how Keynergy reﬁnes the click
detection results with the help of cluster boundaries.
comparison and output a rank-list of keys, where a higher-
ranked key corresponds to the victim key.
5.2 Click and Cluster Detection
Click and Cluster Detection module is comprised of the fol-
lowing three sub-modules. First, the recordings of each inser-
tion are input to the Click Detection sub-module to determine
all potential clicks. It takes as input the audio recordings (for
n insertions) to determine the timing information of all 15
clicks for each insertion, which is the maximum number of
clicks in a 5-pin lock. The detected click timestamps are then
input to the Cluster Detection sub-module to identify the ﬁve
clusters present in each insertion. Subsequently, we utilize
Reﬁning Click Detection sub-module to ﬁne-tune the click
detection within each cluster as there may be incorrect clicks
initially detected due to the low signal-to-noise ratio (SNR).
Click Detection. We identify timing information of clicks by
Cluster 1 
Cluster 2 
Cluster 3 
Cluster 4 
Cluster 5 
(C1)
(C2)
(C3)
(C4)
(C5)
1
0.75
0.5
0.25
0
0
1
0.75
0.5
0.25
0
0
1
0.75
0.5
0.25
0
0
0.1
0.2
0.3
(a)
0.39
0.49
0.59
0.69
TC1-C2
TC2-C3
TC3-C4
TC4-C5
0.023
0.046
0.069
(b)
0.092
0.116
0.139
0.162
TC1-C2
TC2-C3
TC3-C4
TC4-C5
0.037
0.074
0.111
0.148
0.184
0.221
0.258
(c)
Figure 7: (a) Figure depicts the simulated patterns along with
their clusters, {C1, . . . ,C5}. (b) and (c) depict two instances of
human key insertion of the same key, where TCi−C j represents
the time-interval between clusters, Ci and C j. Clicks within
a cluster occur more closely than clicks of different clusters.
Also, the time-interval between clusters is inconsistent across
different insertions. However, clicks within a cluster exhibit
less variance in click patterns even across different insertions.
detecting their onsets, or the instant that marks the beginning
of clicks’ energy increase [14]. However, as it is difﬁcult to
extract the onsets directly from the audio signal, we transform
the audio signal to weighted spectral ﬂux representation [14],
where click onsets appear as amplitude peaks, which can then
be identiﬁed using peak detection approaches. Weighted spec-
tral ﬂux, W SF, captures the increase in energy by comparing
energies of adjacent time windows. More speciﬁcally, in order
to compute W SF from the audio, we partition it into T over-
lapping frames, {F1, . . . , FT }, each with ﬁxed time-interval (∼
0.7 ms), and obtain their magnitude spectrum {M1, . . . , MT },
which represents the energies at different frequencies com-
puted as the absolute value of their discrete Fourier transform
(DFT). We compute W SF(t) as the increase in energy of
the current frame, Ft , in comparison to an average of previ-
ous k frames (denoted by AMt−1), weighted by their frequen-
cies as: W SF(t) =
f1
∑
f = f0
h f × H (cid:0)Mt ( f ) − AMt−1( f )(cid:1)i where
H (x) = (x + |x|)/2, returns non-zero values only for energy
increases as they contribute towards identiﬁcation of click
onsets. Also, f0 and f1 indicate the frequency bins corre-
sponding to minimum and maximum frequencies of interest.
We consider frequencies above 15kHz, as higher frequencies
capture quick transitions in energy, which is important to
determine precise timing of clicks [59].
Subsequently, we set a minimum distance between clicks
in order to prevent choosing peaks in the noise ﬂoor and retain
peaks that are above a threshold (i.e., fraction of the maximum
amplitude). Finally, we select the largest 15 peaks to be the
resulting clicks of the key insertion as depicted in Figure 6(a).
We repeat this process across all n insertion recordings.
Cluster Detection. Taking as input all 15 click onsets, Cluster
Detection sub-module outputs ﬁve clusters for each insertion.
USENIX Association
30th USENIX Security Symposium    3259
Cluster 3
Cluster 4
Cluster 5
Trial 1
Trial 2
⋮
⋮
⋮
⋮
Trial n
Synthesized time-series
Cluster 3 – Trial 2
Cluster 4 – Trial 1
Cluster 5 – Trial n
Figure 8: Figure depicts the clusters across different trials to
ultimately obtain synthesized pattern.
To obtain the ﬁve clusters, we leverage the observation that
there is a relatively long pause between clusters, resulting
in longer time-intervals between adjacent clicks that belong
to neighboring clusters which are due to human insertion as
well as presence of distinct clusters in the key as shown in
Figure 7. Hence, we choose the four largest time-intervals as
shown in Figure 6(b). For further analysis, we only leverage
clicks from Cluster 3 onwards, as the ﬁrst two clusters have
too few clicks for pattern comparison. As every cluster is a
localised time-region within the key insertion, we observe
lower speed variations in each cluster as opposed to the en-
tire insertion (Figures 7(b) and (c)), hence resembling the
simulated patterns (Figures 7(a)) which is modeled based on
constant insertion speed.
Reﬁning Click Detection. Upon obtaining the clusters, we re-
ﬁne the click detection within each cluster for all n insertions,
because the Click Detection sub-module may be inaccurate
due to the following reasons: (1) clicks may be closely spaced,
or even occur simultaneously (i.e., overlapped), hence produc-
ing peaks that are difﬁcult to discern; (2) clicks may exhibit
low energy, thereby leading to reduced amplitude of peaks;
and (3) presence of noise, which may result in erroneous peaks
being detected as clicks. We overcome these challenges by
reﬁning click detection with the help of clusters. Speciﬁcally,
we make use of the upper bound on the number of clicks for
each cluster, i.e., Cluster p has at most p clicks, hence pre-
venting more than p clicks to be chosen within that cluster,
while also aiding the selection of closely-spaced clicks when
less that p clicks are initially chosen, e.g., we observe that in
Figure 6(c), Reﬁning Click Detection sub-module omits the
noisy peak in Cluster 3, while it identiﬁes a low amplitude
click in Cluster 5, unlike the Click Detection sub-module that
marks noise as click and vice versa (Figure 6(a)).
5.3 Synthesized Click Pattern Extraction
Despite the reﬁned clicks from the previous module, correctly
extracting all clicks within each insertion may still be error-
prone due to the aforementioned sources of noise. Synthesized
Click Pattern Extraction module solves this challenge by
"!"""#
$%/$$
!!!"!#
$$/$%
IntervalTrial	1 =
$%
IntervalTrial 2 =	
$$
Range
Range
!!
"!
"!
!!
,
,
!"
""
""
!"
,
,
!#
"#
"#
!#
Range-
MAX
ratio	error	
(e
range)
Figure 9: Figure depicts the pairwise error computation be-
tween two trials, ti and t j, with corresponding time-intervals,
{i1, i2, i3} and { j1, j2, j3}. We compute the range of the two
possible interval ratios (i.e., Range(i, j) and Range( j, i)), the
maximum of which constitutes the range-ratio error (erange).
fusing information across multiple insertions (or trials) as it
is unlikely for similar noise pattern to reoccur across different
insertions. This module takes as input n trials and chooses one
trial per cluster as a representative to ultimately synthesize a
new click pattern, which we refer to as synthesized pattern,
that most likely resembles an insertion with minimal noise.
Speciﬁcally, this module chooses one representative trial per
cluster (or trial – cluster pair), and merges across all three
clusters to output the synthesized pattern. Figure 8 illustrates
a set of trials, where we select the following trial – cluster
pairs to construct the ﬁnal synthesized pattern: Trials 2, 1,
and n, for Clusters 3, 4, and 5, respectively.
To select the most representative trial – cluster pair across
all trials, we employ a two-stage approach. First, for each
cluster, we only retain trials that contain the mode (or the
most frequently occurring) of the number of clicks and
discard the rest (as they may be more prone to missing
clicks or having additional noisy clicks), e.g., in Cluster 4
of Figure 8, Trials 1, 2, and n contain the maximum of four
clicks. Second, we select a representative trial out of the re-
tained trials. For this, we compute a pairwise error between
all combinations of retained trials, to ultimately output the
trial with the least error as the representative trial – clus-
ter pair, (e.g., Trial 1 for Cluster 4). For each pair of trials,
we compare the corresponding time-intervals across each of
the adjacent clicks within a cluster, e.g., in Figure 9, when
comparing Trial 1 with Trial 2 for Cluster 4, we ﬁrst com-
pute the intervals of the two trials such that IntervalTrial1 =
{i1, i2, i3} and IntervalTrial2 = { j1, j2, j3}. Subsequently, we
compute the ratio of corresponding time intervals, followed
by its range, or the difference between the maximum and
minimum ratios (i.e., Range(IntervalTrial1, IntervalTrial2) =
Range(i, j) = Max[ i1
]). In order to
j1
keep the error value consistent for different ordering of tri-
als, we compute the maximum of Range(i, j) and Range(i, j),
which we refer to as the range-ratio error (erange). We lever-
age this ratio to compare click interval patterns between any
two trials, without being affected by their different insertion
speeds. Finally, we choose a representative trial which has the
least sum of pairwise error with majority of the trials.
] − Min[ i1
j1
, i3
j3
, i2
j2
, i3
j3
, i2
j2
3260    30th USENIX Security Symposium
USENIX Association
5.4 Pattern Comparison
Parabolic 
Microphone
Condenser 
Microphone
Multiple Mic Types
§6.4
§6.4.2
Noise 
Source
55 – 75 dB
§6.4
Lock
0
5
10
15
20
25
Feet
…
Multiple Keys
§6.2 Multiple 
§6.4.3
Participants
(b)
Over time
§6.4.4
Smartphone
Lock
(a)
Pattern Comparison module takes as input - synthesized pat-
tern, simulated patterns of the reduced keyspace from Video
Analysis module (see Section 5.5) to output a rank-list of keys,
with a higher-ranked key being more likely to be the victim’s
key. This module compares the synthesized pattern against all
of the simulated patterns within the reduced keyspace, specif-
ically by comparing each of the clusters (i.e., 3, 4, and 5) sep-
arately, and then aggregating the comparison results across all
clusters. We choose such because the clicks within a cluster
exhibit low variations in speed as opposed to clicks across
the entire insertion, thereby exhibiting closer resemblance to
the simulated patterns, which is modeled based on constant
insertion speed (see Figure 7). However, this comparison still
poses some challenges due to remaining variability in speed
and occasional click misses within clusters. To overcome this
challenge, we compute two error functions to quantify their
dissimilarity, namely, pattern comparison and click detection
errors (or epattern and eclick, respectively). Utilizing the error
functions, this module ultimately outputs ranks of all keys.
Speciﬁcally, epattern error computes range-ratio error (sim-
ilar to Figure 9) to quantify the dissimilarity between simu-
lated patterns of all keys and the synthesized pattern. Hence,
keys with simulated patterns that exhibit similar patterns to
synthesized pattern would be assigned lower epattern values.
However, there may be cases where synthesized pattern has
missing clicks (e.g., when the clicks occur close together)
rendering epattern alone insufﬁcient for ranking keys. Hence,
upon a likely detection of missing clicks from the epattern
computation, we assign eclick as the largest click-interval adja-
cent to the potentially missed click(s). After assigning epattern
and eclick for all clusters of keys in the reduced keyspace, we
sum up the two errors across the clusters and list the keys
from lowest to highest error to obtain an aggregated rank-list.
5.5 Video Analysis
We now combine information from video footages in order to
achieve additional keyspace reduction. We ﬁrst re-implement
Sneakey [35] which performs image-based key-inference and
extend it further to work with video footages capturing blurry
key images due to the mobile key at unﬁxed angles. Sneakey’s
implementation normalizes the key image by manually anno-
tating eight keypoint locations (ﬁve and three from the key’s
head and blade, respectively) by the attacker, and transforms it
to the respective keypoints on a reference key (i.e., another key
of the same make-and-model that is known to the attacker).
We extend this design to utilize only four keypoints (three
and one on the key’s blade and tip, respectively), to account
for a more realistic attack scenario where the head of the
key may be occluded as the victim is holding the key. Subse-
quently, we identify the ﬁve bitting locations and depths on
the normalized image to yield the most likely bittings. Prior to
Figure 10: Figure depicts (a) the experimental setup with a
custom-made door with Miccond, Micparab, and Micphone; (b)
set of all varying experimental conditions.
applying the image-based inference, we choose the top three
frames that exhibit least blurriness from the video recording
by applying a variance of Laplacian operator, which measures
the amount of edges present in images, to utilize it for a blur
detection [51, 53]. Ultimately, this module outputs a reduced
key search space to be input to Pattern Comparison module
for further reduction.
6 Evaluation
We present the evaluation of Keynergy through comprehensive
real-world experiments, demonstrating its feasibility.
6.1 Experimental Setup
Apparatus. Figure 10 illustrates our experiment setup, where
we use a custom door setup with Schlage SC1 5-pin lock. This
setup follows the standard door width of 45 mm with the lock
installed at the conventional height of 42 inches above the
ground [60]. There are a total of 59,207 vulnerable keys for
the Schlage SC1 lock (which constitutes 79% of the original
keyspace due to distinct cluster-based ﬁltering as presented
in Section 4). We use the following three different types of
microphones with corresponding sampling rates (Fs):
• Miccond: AKG Lyra condenser mic (Fs = 192kHz) [1]
• Micparab: SoundShark Parabolic Collector with Coun-
tryman B3 Lavalier mic (Fs = 192kHz) interfaced with
Behringer UMC202HD audio interface [2, 4, 8]
• Micphone: Google Pixel (Fs = 44.1kHz) [5]
In addition, we use Adam Audio A3X studio monitor
speaker [11] with a ﬂat frequency response from 60 Hz up to
50kHz for an accurate reproduction of different noise sources
in Section 6.4. To evaluate the different attack scenarios
motivated in Sections 1 and 3, we perform experiments by
varying the position of the Micparab and the Micphone from
USENIX Association
30th USENIX Security Symposium    3261
Video Only
Video Only Mean
Video+Audio
Video+Audio Mean
e
c
a
p
S
y
e
K
d
e
c
u
d
e
R
300
250
200
150
100
50
0
10