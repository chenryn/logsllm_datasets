states that every conditional node must dominate all the nodes
between itself and its immediate post-dominator. Hence, for each
of these nodes, it identifies the immediate post-dominator. This is
always possible since the DAG has a single exit, thanks to the sink
node injected at the beginning of Preprocessing. In this way, for
each conditional node ğ¶, the algorithm identifies as set of nodes
D(ğ¶) between ğ¶ and its immediate post-dominator.
Second, for each node ğ‘ in D(ğ¶) that is not dominated by ğ¶ there
is some incoming edge ğ‘’ = âŸ¨ğ‘‹,ğ‘âŸ© such that source node ğ‘‹ is not
dominated by ğ¶. To enforce the Diamond Shape property, ğ‘ should
be dominated by ğ¶. Hence the node ğ‘ is duplicated, creating a basic
block node ğ‘ â€² that contains the same instructions as ğ‘ . Initially
ğ‘ â€² has no incoming nor outgoing edges. Then, for every outgoing
edge ğ‘’ğ‘† = âŸ¨ğ‘ ,ğ‘†âŸ© from ğ‘ , an outgoing edge ğ‘’â€²
ğ‘† = âŸ¨ğ‘ â€²,ğ‘†âŸ© is created
from ğ‘ â€². This ensures that ğ‘ â€² jumps in the same places where ğ‘
jumped, preserving the semantic of the program after ğ‘ . Then,
each incoming edge ğ‘’ğ‘ƒ =âŸ¨ğ‘ƒ,ğ‘âŸ© into ğ‘ such that ğ¶ dominates ğ‘ƒ is
substituted with an edge ğ‘’â€²
ğ‘ƒ =âŸ¨ğ‘ƒ,ğ‘ â€²âŸ© incoming into ğ‘ â€². This means
that after this transformation the node ğ‘ â€² is dominated by ğ¶, and
the node ğ‘ is not reachable from ğ¶ anymore. See Figure 10.b and
Figure 10.c for an example of this transformation.
Basically, the underlying idea is to group the incoming edges
in node ğ‘ in two sets: one composed by the edges dominated by
conditional node ğ¶, that will be moved to node ğ‘ â€², and the other
one composed by the edges not dominated by ğ¶, that will remain
attached to node ğ‘ .
This is sufficient to enforce the Diamond Shape property for ğ¶
and ğ‘ , but there might be other nodes in D(ğ¶). Repeating this on
each ğ‘ âˆˆ D(ğ¶) fully enforces the Diamond Shape property for the
conditional node ğ¶. In turn, repeating the process in post-order on
all conditional nodes in the DAG enforces the property on the whole
Region. Notice that the process either never touches a node ğ‘ (since
it already fulfills the Diamond Shape property for all the conditional
nodes from which it is reachable) or it splits the incoming edges
of ğ‘ into two sets.
At the end of the procedure, the Region DAG fulfills the Diamond
Shape property and is said to be combed.
Note that, as shown in Figure 10, the Combing can insert dummy
nodes (i.e., empty nodes) to reinstate the two predecessor property,
and highlight the diamond-shape.
Improved Combing Algorithm: Untangling Return Paths. The
Combing Algorithm as described above still has a drawback in some
common cases: it duplicates code very aggressively which can lead
to a big increase in code size if not controlled.
Consider Figure 11. The source code in the figure is very sim-
ple, and represents a pretty common case where some checks are
performed on the arguments (A and B), a complex computation
composes the body of the function (C), and some final error check
is performed going on.
As we can see in Figure 11(a), one of the typical optimizations
performed by compilers even at lower optimization levels is to
coalesce all the returns in a single node (R). This is intended to
reduce code size in the binaries, but from an analysis standpoint it
â€œentanglesâ€ different execution paths that were originally separate
(the two return statements at lines 4 and 10).
If the vanilla Combing Algorithm is applied on the graph in Fig-
ure 11(a), both nodes C and R would be duplicated, like shown in
Figure 11(b). This would be very detrimental, because it would end
up duplicating the whole bulk of the computation (C), unnecessarily
inflating the size of the decompiled source code.
In order to cope with this cases we devised an improved combing
algorithm: the Untangling Algorithm. The improved version of the
algorithm, the Untangling is focused on handling these cases, and
is performed just before the vanilla Combing Algorithm. After the
Untangling, the Combing is executed on the untangled graphs, so
that it can iron out all the situations left behind from the Untangling
because they were not beneficial to untangle.
The Untangling is applied on each conditional node in a Region
DAG, and only if beneficial. Its benefits are evaluated with an heuris-
tic that determines, for each conditional node, if the duplication
induced by untangling the return path is significantly lower than
the duplication that the Combing pass would introduce if the Un-
tangling is not performed. To do this, the heuristic assigns a weight
to each node in the graph, to evaluate the consequences of applying
the Untangling compared to the vanilla Combing. The weight of
each node is proportional to the number of instructions each node
Session 12: Software Security ASIA CCS '20, October 5â€“9, 2020, Taipei, Taiwan644B
R
B
R
A
C
A
C
C
R
A
B
R
R
(a)
if ( arg0 ) {
// A
fun_call () ; // B
// B
if ( arg1 )
return ;
// R
}
// complex // C
// C
// code
// here
// C
if ( err () ) // C
return ; // R
1
2
3
4
5
6
7
8
9
10
Figure 11: Situation in which the baseline Combing would be very
costly in terms of duplicated code size. The graph in (a) is the CFG
of the snippet of code on the left. The red dashed node (C) represent
a big and messy portion of the CFG that would greatly increase
code size if duplicated. With the baseline Combing both C and R
would be duplicated, like shown in (b). With the Untangling, only
R is duplicated instead, like shown in (c).
contains, and for collapsed Regions this number if computed cumu-
latively on all the nodes they contain. If, according to these weights,
Untangling would duplicate more code than vanilla Combing, the
graph is not untangled and only combed.
(b)
(c)
C
Whenever triggered on a conditional node ğ‘ (B in Figure 11),
the Untangling duplicates all the blocks from the post-dominator
of ğ‘ to the exit of the graph (only R in Figure 11, but potentially
any other node after R). This transformation allows the Combing
step to keep duplication under control.
Going back to Figure 11, we can see in Figure 11(c) how the
Untangling would transform the graph. Only R is duplicated, saving
a huge amount of unnecessary duplication if C is big. This is also an
example where, after the Untangling, the plain Combing Algorithm
does not have anything to do, because all nodes in Figure 11(c) are
dominated by all the conditional nodes from which they are reach-
able. This means that the Diamond Shape property already holds
after Untangling, saving the work that would have been necessary
to comb the graph.
Finally, notice how the graph in Figure 11(c) is much more struc-
turally close to the original source code than what plain Combing
would obtain, i.e. Figure 11(b).
4.6 Matching C Constructs
This phase builds the initial Abstract Syntax Tree (AST) represen-
tation of each of the combed Regions, and then manipulates it to
emit idiomatic C code.
4.6.1 Building the AST. Thanks to the Preprocessing and Combing
stages and all the enforced properties, building an AST is straight-
forward. The Two Successors rule ensures that each conditional node
can be emitted as an if, and since all the DAGs are diamond-shaped
regions, the DAG naturally represents a program with perfectly
nested scopes (each diamond-shaped part represents a scope). More-
over, all retreating edges have already been removed and converted
to break and continue nodes.
All these properties imply that the dominator tree of each DAG
Region is a tree where each node can have at most three children.
Exploiting this property, the algorithm works on the dominator tree
(from root to leaves) to emit the AST. If a node ğ´ in the dominator
tree has only a single child ğµ, ğ´ and ğµ are emitted as subsequent
statements in a single scope in C. If a node ğ´ in the dominator tree
has two or three children, then ğ´ is an if statement. Depending
on how ğ´ is connected to its children, they can represent the then
branch of ğ´, the else branch of ğ´, and the code that is emitted in
the AST after both the then and the else. This allows to represent
all the conditional nodes as well-structured if constructs.
A special treatment is reserved to nodes in a DAG Region that
represent another nested DAG Region, that was collapsed by the
Collapsing Regions step. Whenever one of such nodes is encoun-
tered, it is emitted in the AST as a while(1) {...} construct. The
AST representing the body of the loop is then generated iteratively
from the DAG of the collapsed Region. In general, this representa-
tion is not optimal for any loop, but itâ€™s only preliminary AST form
that will be made more idiomatic as described in the next section.
4.6.2 Matching Idiomatic C Constructs. The preliminary AST is
now post-processed to match idiomatic C constructs, striving to
emit even more readable code, while, at the same time, reducing the
duplication introduced by Combing, when this is possible without
sacrificing readability.
This post-processing is modular and extensible. We only report
some basic matching steps leading to significant improvements
with a reduced effort. Additional matching criteria can be devised
and added to the pipeline, to emit even better code.
Each matching criterion listed in the following is basically struc-
tured as a top-down visitâ€™ on the AST, which recognizes certain
patterns and transforms the AST to more idiomatic, but semanti-
cally equivalent, C constructs.
Short-Circuit Reduction. This criterion recognizes and recon-
structs short-circuited if statements in C. In fact, the Combing step
breaks these constructs as shown in Figure 10.c. This matching
criterion reverts that choice when possible, allowing the Combing
to handle general situations, while also emitting idiomatic short-
circuited ifs whenever possible.
Figure 10.c shows two nested if statements that have the same
duplicated node in their else branches. This criterion matches that
pattern. Whenever two nested if nodes on the AST have the same
code on one of their branches, they are transformed into a sin-
gle if node, short-circuiting their conditions with the appropriate
combination of &&, ||, and ! operators.
Note that the previous works [22] did not perform short-circuited
if matching, often leading to suboptimal results.
Switch Reconstruction. This criterion recognizes and builds switch
statements. As mentioned in Section 4.4.1, to enforce the Two Suc-
cessors property, switches are decomposed in nested ifs in the
preprocessing phase of the Restructuring.
This criterion looks in the AST for nested ifs whose conditions
compare a variable for equality with different constants. Matched
sequences of ifs are transformed into switches.
Loop Promotion. Similarly to what is done in Yakdan et al.[22],
this criterion manipulates loops, initially emitted as while(1) {...},
to transform them into more idiomatic loops, with complex exit
conditions and various shapes such as while(...) {...} and do {...}
while(...).
To match while loops, the AST is scanned looking for loops
whose body starts with a statement in the form of if(ğ‘‹ ) break;.
Any such cycle can be converted into a while(!ğ‘‹ ) {...}, leaving
the rest of the loop body untouched. To match do-while loops,
Session 12: Software Security ASIA CCS '20, October 5â€“9, 2020, Taipei, Taiwan645instead, the AST is scanned looking for loops whose bodyâ€™s final
statement is in the form if(ğ‘‹ ) continue; else break;. These
loops are transformed into do {...} while(ğ‘‹ ). The same is done
for loops where the continue and break statements are inverted,
simply negating the condition.
5 EXPERIMENTAL RESULTS
This section evaluates the proposed approach. Section 5.1 describes
the experimental setup, while Section 5.2 compares our implementa-
tion with state-of-the-art commercial and open-source decompilers.
5.1 Experimental Setup
To evaluate the performance of the Control Flow Combing described
in the previous section, the algorithm has been implemented on
top of the rev.ng static binary analysis framework [8, 9], based on
qemu [3] and llvm [16]. rev.ng is capable of generating CFGs from
binary programs for various CPU architectures. The Preprocessing
and Combing stages of the algorithm has been implemented on top
of the LLVM IR. After these phases, the Matching stage has been
implemented on a simple custom AST for C, that is then translated
into the AST employed by clang (LLVMâ€™s C/C++ compiler) and
finally serialized to C in textual form.
The resulting decompiler is called revng-c. The quality of the
code generated by revng-c is compared with two other well-known
decompilers: IDA Proâ€™s Hex-Rays Decompiler, the leading commer-
cial decompiler developed by Hex-Rays [13], and Ghidra, developed
by the National Security Agency (NSA) of the USA for internal use
and recently open-sourced [2].
For a more thorough comparison, we tried to reach the authors
of two other recent academic contributions in the control flow re-
structuring research area, namely [6] and [22]. Unfortunately, the
authors of Brumley et al. [6] were not able to retrieve the artifacts
to reproduce the results, while the main authors of DREAM [22]
have left academia to focus on different topics, and therefore were
not able to answer our inquiry. Given that DREAM [22] is the only
other approach to generate goto-free C code, it would have been
the perfect candidate to compare our approach with. This compar-
ison would have enabled an evaluation of the main novelty of our
approach: allowing duplication of code in order to reduce the cy-
clomatic complexity of the decompiled code, which is a measure of
the mental load required to an analyst to understand the program.
DREAM tries not to resort to duplication, while we accept small to
moderate duplication because it reduces the cyclomatic complexity
of the generated code. Lacking reproducible results to compare
directly with DREAM, we decided to focus on a restricted num-
ber of case-studies, that show how the code generated by revng-c
compares with their results. Given the limited reach this manual
comparison with DREAM, we have left it in Appendix B.
The remainder of this section provides comparisons between
revng-c, Ghidra, and Hex-Rays Decompiler. For these decompil-
ers, the quality of the decompiled code was evaluated on the GNU
Coreutils. These are the basic file, shell and text manipulation com-
mand line utilities of the GNU operating system. These benchmarks
have been used in the past in related works on control flow restruc-