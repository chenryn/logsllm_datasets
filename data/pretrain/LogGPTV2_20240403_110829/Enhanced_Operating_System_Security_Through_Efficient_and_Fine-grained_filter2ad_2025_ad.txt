the init message is to discriminate between fresh start and
rerandomization init. In the latter scenario, the message
contains a capability created by the microkernel, allow-
ing the new variant to read arbitrary data and metadata
from the old variant. The capability is attached to the IPC
endpoint of the designated OS process and can thus only
be consumed by the new variant, which by design inher-
its the old variant’s endpoint. This is crucial to transpar-
ently rerandomize individual operating system processes
without exposing the change to the rest of the system.
When the rerandomization init message is intercepted,
the message dispatcher requests the run-time migration
component to initialize the new variant properly and then
jumps to the top of the event-processing loop to resume
execution. This preserves the original control ﬂow se-
mantics and transparently restores the correct execution
state. The migration component is isolated in a library
and runs completely sandboxed in the new variant. RM
monitors the execution for run-time errors (i.e., panics,
crashes, timeouts). When an error is detected, the new
variant is immediately cleaned up, while the old vari-
ant is given back control to resume execution normally.
When the migration completes correctly, in contrast, the
old variant is cleaned up, while the new variant resumes
execution with a rerandomized memory layout. We have
also implemented rerandomization for RM itself, which
only required some extra microkernel changes to detect
run-time errors and arbitrate control transfer between the
Figure 3: The rerandomization process.
two variants. Our run-time error detection mechanism al-
lows for safe rerandomization without trusting the (com-
plex) migration code. Moreover, the reversibility of the
rerandomization process makes detecting semantic er-
rors in the migration code a viable option. For example,
one could transparently migrate the state from one vari-
ant to another, migrate it again to another instance of the
original variant, and then compare the results. Figure 3
depicts the proposed rerandomization process.
State migration. The migration starts by transferring
all the metadata from the old variant to a local cache in
the new variant. Our capability-based design allows the
migration code to locate a root metadata descriptor in the
old variant and recursively copy all the metadata nodes
and allocation descriptors to the new variant. To auto-
mate the metadata transfer, all the data structures copied
use a ﬁxed and predetermined layout. At the end, both
the old and the new metadata are available locally, al-
lowing the code to arbitrarily introspect the state of the
two variants correctly. To automate the data transfer, we
map every old metadata node in the local cache with its
counterpart in the new variant. This is done by pairing
nodes by ID and carefully reallocating every old dynamic
state object in the new variant. Reallocations are per-
formed in random order, thus enforcing a new unpre-
dictable permutation of heap and memory-mapped re-
gions. An interesting side effect of the reallocation pro-
cess is the compaction of all the live heap objects, an op-
eration that reduces heap fragmentation over time. Our
reallocation strategy is indeed inspired by the way a com-
pacting garbage collector operates [70].
The mapping phase generates all the perfect pairs of
state objects in the two variants, ready for data migra-
tion. Note that paired state objects may not reﬂect the
same type or size, due to the internal layout rerandom-
ization. To transfer the data, the migration code intro-
spects every state object in the old variant by walking
its type recursively and examining each inner state ele-
ment found. Nonpointer elements are simply transferred
by value, while pointer elements require a more care-
ful transfer strategy. To deal with layout randomization,
each recursive step requires mapping the current state el-
ement to its counterpart (and location) in the new variant.
This can be easily accomplished because the old type and
the new type have isomorphic structures and only dif-
fer in terms of member offsets for randomized struct
types. For example, to transfer a struct variable with
3 primitive members, the migration code walks the orig-
inal struct type to locate all the members, computes
their offsets in the two variants, and recursively transfers
the corresponding data in the correct location.
Pointer migration. The C programming language al-
lows several programming constructs that make pointer
migration particularly challenging in the general case.
Our approach is to fully automate migration of all the
common cases and only delegate the undecidable cases
to the programmer. The ﬁrst case to consider is a pointer
to a valid static or dynamic state object. When the pointer
points to the beginning of the object, we simply reini-
tialize the pointer with the address of the pointed object
in the new variant. Interior pointers (i.e., pointers into
the middle of an object) in face of internal layout reran-
domization require a more sophisticated strategy. Simi-
lar to our introspection strategy, we walk the type of the
pointed object and recursively remap the offset of the tar-
get element to its counterpart. This strategy is resilient
to arbitrary layout rerandomization and makes it easy to
reinitialize the pointer in the new variant correctly.
Another scenario of interest is a pointer which is as-
signed a special integer value (e.g., NULL or MAP FAILED
(-1)). Our migration code can explicitly recognize spe-
cial ranges and transfer the corresponding pointers by
value. Currently, all the addresses in reserved memory
ranges (e.g., zero pages) are marked as special values.
In another direction, memory addresses or other
layout-speciﬁc information may be occasionally stored
in integer variables. This is, unfortunately, a case of un-
solvable ambiguity which cannot be automatically set-
tled without programmer assistance. To this end, we sup-
port annotations to mark “hidden” pointers in the code.
Pointers stored in unions are another case of un-
solvable ambiguity. Since C does not support tagged
unions, it is impossible to resolve these cases automat-
ically. In our experiments with OS code, unions with
pointers were the only case of ambiguity that required
manual intervention. Other cases are, however, possi-
ble. For example, any form of pointer encoding or ob-
fuscation [13] would require knowledge on the particu-
lar encoding to migrate pointers correctly. Other classes
of pointers—guard pointers, uninitialized pointers, dan-
gling pointers—are instead automatically handled in our
implementation. In the last two cases, the general strat-
egy is to try to transfer the pointer as a regular pointer,
and simply reinitialize it to NULL in the new variant
whenever our dynamic pointer analysis reports an error.
Figure 4: Execution time of the SPEC CPU 2600 bench-
marks and our devtools benchmark normalized against
the baseline (no OS/benchmark instrumentation).
7 Evaluation
We have implemented our ASR design on the MINIX 3
microkernel-based operating system [32], which already
guarantees process-based isolation for all the core oper-
ating system components. The OS is x86-based and ex-
poses a complete POSIX interface to user applications.
We have heavily modiﬁed and redesigned the original OS
to implement support for our ASR techniques for all the
possible OS processes. The resulting operating system
comprises a total of 20 OS processes (7 drivers and 13
servers), including process management, memory man-
agement, storage and network stack. Subsequently, we
have applied our ASR transformations to the system and
evaluated the resulting solution.
7.1 Performance
To evaluate the performance of our ASR technique, we
ported the C programs in the SPEC CPU 2006 bench-
mark suite to our prototype system. We also put together
a devtools macrobenchmark, which emulates a typical
syscall-intensive workload with the following operations
performed on the OS source tree: compilation, find,
grep, copying, and deleting. We performed repeated
experiments on a workstation equipped with a 12-core
1.9Ghz AMD Opteron “Magny-Cours” processor and
4GB of RAM, and averaged the results. All the OS code
and our benchmarks were compiled using Clang/LLVM
2.8 with -O2 optimization level. To thoroughly stress the
system and identify all the possible bottlenecks, we in-
strumented both the OS and the benchmarks using the
same transformation in each run. The default padding
strategy used in the experiments extends the memory oc-
cupancy of every state object or struct member by 0-
30%, similar to the default values suggested in [14]. Fig-
ure 4 depicts the resulting execution times.
1.001.051.101.151.201.251.301.351.40bzip2perlbenchgccmcfmilcgobmkhmmersjenglibquantumh264reflbmsphinx3SPEC averagedevtoolsNormalized execution time ASR instrumentation   ASR+ASRR instrumentation  Figure 5: Rerandomization time against coverage of in-
ternal layout rerandomization.
Figure 6: Run-time overhead against periodic rerandom-
ization latency.
The ASR instrumentation alone introduces 0.9% run-
time overhead on average on SPEC benchmarks and
1.1% on devtools. The average run-time overhead in-
creases to 4.8% and 1.6% respectively with ASRR in-
strumentation. The maximum overhead reported across
all the benchmarks was found for perlbench (36%
ASRR overhead). Proﬁling revealed this was caused
by a massive amount of dynamic memory allocations.
This test case pinpoints a potential source of overhead
introduced by our technique, which, similar to prior ap-
proaches, relies on memory allocation wrappers to in-
strument dynamically allocated objects. Unlike prior
comprehensive solutions, however, our run-time over-
head is barely noticeable on average (1.9% for ASRR
without perlbench). The most comprehensive second-
generation technique presented in [14]—which, com-
pared to other techniques, also provides ﬁne-grained
stack randomization—introduces a run-time overhead of
11% on average and 23% in the worst case, even by in-
strumenting only the test programs. The main reasons for
the much higher overheads are the use of heavyweight
stack instrumentation and indirection mechanisms that
inhibit compiler optimizations and introduce additional
pointer dereferences for every access to code and data
objects. Their stack instrumentation, however, includes
a shadow stack implementation that could complement
our techniques to offer stronger protection against stack
spraying attacks.
Although we have not observed strong variations
in our macrobenchmark performance across different
runs, our randomization technique can potentially af-
fect the original spatial locality and yield nonoptimal
cache usage at runtime. The possible performance im-
pact introduced—inherent in all the ﬁne-grained ASR
techniques—is subject to the particular compiler and sys-
tem adopted and should be carefully evaluated in each
particular deployment scenario.
Figure 5 shows the rerandomization time (average,
median, max) measured across all the OS components.
With no internal layout rerandomization (ILR), a generic
component completes the rerandomization process in
272ms on average. A higher ILR coverage increases
the average rerandomization time only slightly (297ms
at 100% coverage). The impact is more noticeable for
OS servers than drivers, due to the higher concentra-
tion of complex rerandomized structs (and pointers to
them) that need to be remapped during migration. Al-
beit satisfactory, we believe these times can be further
reduced, for example using indexes to speed up our dy-
namic pointer analysis. Unfortunately, we cannot com-
pare our current results against existing solutions, given
that no other live rerandomization strategy exists to date.
Finally, Figure 6 shows the impact of periodic reran-
domization on the execution time of SPEC and devtools.
The experiment was performed by rerandomizing a sin-
gle OS component at the end of every predetermined
time interval. To ensure uniform coverage, the OS com-
ponents were all rerandomized in a round-robin fashion.
Figure 6 reports a barely noticeable overhead for reran-
domization latencies higher than 20s. For lower laten-
cies, the overhead increases steadily, reaching the value
of 42.7% for SPEC and 51.9% for devtools at 1s. The
rerandomization latency deﬁnes a clear tradeoff between
performance and unobservability of the system. Reason-
able choices of the rerandomization latencies introduce
no performance impact and leave a small window with a
stable view of the system to the attacker. In some cases, a
performance penalty may also be affordable to offer extra
protection in face of particularly untrusted components.
7.2 Memory usage
Table 1 shows the average run-time virtual memory over-
head introduced by our technique inside the OS during
the execution of our benchmarks. The overhead mea-
sured is comparable to the space overhead we observed
 0 100 200 300 400 500 600 700 800 900 1000AverageMedianMaxAverageMedianMaxAverageMedianMaxRerandomization time (ms)  ILR Coverage:     0% ILR Coverage:   50% ILR Coverage: 100%DRIVERSSERVERSALL 0 5 10 15 20 25 30 35 40 45 50 55 1 2 4 8 16 32Runtime overhead (%)Rerandomization latency (s) SPEC CPU 2006 benchmarks     devtools benchmark    Type
ASRR state
ASRR overall
ASR paddinga
ASR paddingr
Overhead
16.1%
14.6%
((8as + 2ah + 4a f )·10−4 + cbase)%
((2rs+0.6rh+3r f )·10−1 + cbase)%
Table 1: Average run-time virtual memory overhead
measured during the execution of our benchmarks.
for the OS binaries on the disk.
In the table, we re-
port the virtual memory overhead to also account for dy-
namic state object overhead at runtime. For the aver-
age OS component, support for rerandomization intro-
duces 16.1% state overhead (the extra memory neces-
sary to store state metadata w.r.t.
the original memory
occupancy of all the static and dynamic static objects)
and 14.6% overall memory overhead (the extra mem-
ory necessary to store state metadata and migration code
w.r.t. the original memory footprint) on average. The vir-
tual memory overhead (not directly translated to physical
memory overhead, as noted earlier) introduced by our
randomization strategy is only due to padding. Table 1
reports the overhead for two padding schemes using byte
granularity (but others are possible): (i) paddinga, gen-
erating an inter-object padding of a bytes, with a uni-
formly distributed in [0;as,h, f ] for static, heap, and func-
tion objects, respectively; (ii) paddingr, generating an
inter-object padding of r·s bytes, with a preceding ob-
ject of size s, and r uniformly distributed in [0;rs,h, f ]
for static, heap, and function objects, respectively. The
coefﬁcient cbase is the overhead introduced by the one-
time padding used to randomize the base addresses. The
formulations presented here omit stack frame padding,
which does not introduce persistent memory overhead.
7.3 Effectiveness
As pointed out in [14], an analytical analysis is more gen-
eral and effective than empirical evaluation in measur-
ing the effectiveness of ASR. Bhaktar et al. [14] present
an excellent analysis on the probability of exploitation