常扩展该数据以包含其他类型的信息。
需要与服务进行通信的使用者来说，此类存储主要用来提供服务的IP和端口。经
用在分布式系统中，注册表需要可伸缩、容错并分布在集群的所有节点上。对于
当前的环境并保存这些信息。注册表以键/值的格式完成存储。因为服务发现经常
有几个工具可以用来完成我们的目标，现在就来看一看。
使用服务发现工具，我们要查找的是数据。至少要能够找到服务的位置，
假设有两个服务：
服务发现工具往往会提供一些API，一个服务可以用这些API进行注册，其他
服务发现的基本想法是，对于每个服务（或应用）的新的实例，可以识别出它
一个是服务提供者，另一个是服务消费者。一旦部署了提
8.1服务注册表105
它
---
## Page 120
106第8章发现服务——分布式服务的关键
Zookeeper
Zookeeper
Manual Configuration
手动配置
比竞争产品要使用多得多的资源。除了这些问题，Zookeeper 还很复杂。维护它所
错，它很适合此类工作。Zookeeper 使用 Java 并依赖很多其他东西，让 Zookeeper
些不足，对 Java 的依赖及其复杂性是主要问题。Java 在很多情况下的表现都还不
端可以连接任何服务器来获取数据。
群上，那么 Zookeeper 共享所有节点的配置状况。每个集群选举一个领导者，客户
eBay、Yahoo等）。它的数据存储格式与文件系统的很相似。如果运行在服务器集
Hadoop 集群中的一系列组件。它成熟、可靠，广泛应用于很多大公司（YouTube、
快就不存在了。
的时候还有理由手工完成此类工作，但随着服务发现工具的出现，这样的理由很
变动需要手工处理，所以监控变得难以管理。虽然过去或者服务和服务器数量少
个数据源查询到这些数据。
的。但是大多数服务会产生很多不易获得的动态信息。当有需要时，也无法从一
杂。可见性是另外一个痛点。我们知道静态配置是什么，毕竟这是事先准备好
况下，响应时间一般都比较长，在某些场景下比如硬件故障，情况会变得更复
出哪台服务器的资源利用率比较低，生成并部署一套新的配置。在手工管理的情
二个实例意味着要重复所有的手工步骤。我们不得不启动一台新的服务器或者找
并且希望它可以正确运行数天之久。这种方式不具有可伸缩性。部署该服务的第
Zookeeper 的主要好处是它的成熟性、健壮性和丰富的功能。然而，它也有一
Zookeeper 是此类项目中历史最久的一个之一。它源于Hadoop，用来维护
响应时间长是必然的，能否从故障中快速恢复也很值得怀疑，由于非常多的
大多数服务还是手工管理的。我们要预先决定部署服务的位置和它的配置，
---
## Page 121
etcd
etcd
的命令行客户端）了。
vagrantssh serv-disc-01
vagrant up cd serv-disc-01 --provision
的cd虚拟机。
安装etcd
三方工具相结合才能用于服务发现。
性，它是安全的并有优秀的文档。
可以用来搭建服务发现。它非常容易部署、配置和使用，提供了可靠的数据持久
是因为那时没有更好的选择。如今，Zookeeper略显老态，还是选择其他的吧。
我们为不需要的东西所带来的复杂性买了单。
处变成了负担。一个应用的功能越多，越有可能不是我们所需要的。因此，最终
需要的知识，远超过我们对此类应用的期望。部分原因是由于其丰富的功能把好
tar xzf etcd-v2.1.2-1inux-amd64.tar.gz
cur1 -L https://github.com/coreos/etcd/releases/\
一旦集群节点 serv-disc-1 启动并运行，就可以安装 etcd 和 etcdct1（etcd
让我们来安装etcd。首先创建集群中的第一个节点（serv-disc-01）及已经熟悉
etcd 简单易用，与Zookeeper 相比，它是一个更好的选择。etcd 需要跟几个第
etcd >/tmp/etcd.1og 2>&1 &
rm-rfetcd-v2.1.2-linux-amd64*
sudomvetcd-v2.1.2-1inux-amd64/etcd*/usr/local/bin
download/v2.1.2/etcd-v2.1.2-linux-amd64.tar.gz\
etcd 是一个可以通过 HTTP 访问的键/值存储。它是分布式的层级配置系统，
略过 Zookeeper的例子，下面直接看看其他选项吧。
沿着 Zookeeper 开创的道路，其他应用有了显著进步。大公司使用 Zookeeper
-0 etcd-v2.1.2-1inux-amd64.tar.gz
8.1服务注册表107
---
## Page 122
108
第8章发现服务一
容：
sudo apt-get install-y jq
之前，需要安装jq，jq可以让我们看到格式化的输出：
于添加键ip 并赋值；最后两行命令用于输出这两个键的值。
后删除不需要的文件；最后运行etcd 并把输出重定向到/tmp/etcd.log。
jq'.不是必需的，但是我经常用它来格式化 JSON。输出应该类似于以下内
比如可以用它的HTTPAPI在etcd中添加一个键，然后用GET请求来获取它的
除了etcdctl，还可以使用 HTTP API来运行所有的命令。在尝试 HTTP API
因为前一行命令删除了键port，所以最后一行命令只输出了／myService/ip。
还可以列出指定目录里所有的键，或者删除一个键及其值。
第一行命令用于在目录 myService 中添加值为1234 的键port；第二行命令用
etcdctlget myService/ip #0utputs:1.2.3.4
etcdctlgetmyService/port #0utputs:1234
etcdctl set myService/ip "1.2.3.4"
etcdctlsetmyService/port"1234"
基本操作是 set和 get。请注意，可以在目录里设置键/值。
下面让我们来看看etcd 能做什么。
首先下载、解压缩，并把可执行文件放入/usr/local/bin 中以便于访问；然
curlhttp://1ocalhost:2379/v2/keys/myService/newPort\
cur1http://localhost:2379/v2/keys/myService/newPort\
etcdctllsmyService
etcdctlrmmyService/port
etcdctllsmyService
Ijq'.
-d value="4321"| jq '.'
XP
"action":"set",
PUT\
一分布式服务的关键
"key": "/myService/newPort",
"createdIndex":16,
---
## Page 123
etcd -name serv-disc-1\
CLUSTER_ToKEN=serv-disc-cluster
NODE_03="$NODE_03_NAME=$NODE_03_ADDRESS""
NODE_03_NAME=serV-disc-03
NODE_03_ADDRESS=http://10.100.197.203:2380
NODE_02_ADDRESS=http://10.100.197.202:2380
NODE_01_ADDRESS=http://10.100.197.201:2380
NODE_IP=10.100.197.20$N0DE_NUMBER
NODE_NAME=serv-disc-O$NODE_NUMBER
先不要运行）：
群，IP 为 10.100.197.201（servdisc-01）、10.100.197.202（serv-disc-02）和
中试试。etcd 需要几个额外的参数来建立集群。假设有一个由三个节点组成的集
命令时，我更喜欢etcdctl，如果是在代码中与 etcd交互，HTTP是首选的方式。
ODE_01="$NODE_01_NAME=$NODE_01_ADDRESS"
ODE_O2="$NODE_02_NAME=$NODE_02_ADDRESS"
DE_02_NAME=serV-disc-02
ODE_01_NAME=serV-disc-01
对于那些可以从一个服务器（或集群）变到另外一个服务器的部分，我把它们
$NODE_01,$NODE_02,$NODE_03\
-initial-cluster\
-initial-cluster-token $CLUSTER_TOKEN\
http://$N0DE_IP:2379,http://127.0.0.1:2379\
现在已经简单介绍了在单台服务器上 etcd 是如何工作的，下面让我们在集群
initial-cluster-state new
listen-client-urls
当需要远程查询etcd时，HTTP API非常有用。大多数情况下，当运行ad-hoc
"node":{
"action": "get",
"value":"4321"
"modifiedIndex": 16,
"key":"/myService/newPort",
"createdIndex":16,
"value":"4321"
"modifiedIndex": 16,
8.1服务注册表109
---
## Page 124
110
第8章发现服务一
defaults/main.yml中指定的值如下：
下来是with_items 声明，允许我们使用一个值列表。本例中，文件roles/etcd/
755。运行 roles 的用户将拥有读/写/执行权限，本组中的其他用户是读/写权限。接
块参数 src 指明了要复制的本地文件的名字及其在 role 中相对于 files 目录的位
tags:[etcd]
with_items: files
过的一条很长的命令）。在运行 playbook之前，先看一下它的内容。
把可执行文件复制到/usr/local/bin 目录并运行带有集群参数的etcd（之前讨论
创建一个 etcd 的 role 并以相同的名字把它加入 playbook。这个 role 比较简单。它
是一个相当容易的任务，要做的就是把已经运行的命令转换成 Ansible 格式。可以
Ansible 了，所以可以用它在集群中安装 etcd。因为已经有了所有的命令，所以这
vagrant up serv-disc-02 serv-disc-03
器（总共有三个服务器）：
了运行这个命令的IP 和服务器的名字，同时也指定了集群中所有的服务器。
提取出来放到变量里，以便你可以看得更清楚。我们不会详述每个参数的意思，
置。
copy:
name:Filesare copied
pkilletcd
。第二个copy 模块参数（dest）是远程服务器的目的路径。最后，将 mode 设为
name 的意思显而易见，紧接着是copy模块，然后指定几个模块参数。copy模
mode:0755
files:[
src:
roles/etcd/tasks/main.yml中的第一个任务如下：
在多台服务器上手工完成相同的任务，既单调又容易出错。因为已经使用过
在集群上开始部署 etcd 之前，让我们杀掉当前运行的实例并创建其他的服务
{src:'etcdctl',dest:‘/usr/local/bin/etcdctl'}
{src:'etcd',dest:'/usr/local/bin/etcd'},
"{{ item.src }}"
—分布式服务的关键
---
## Page 125
sudo:yes
main.yml中。所有任务都定义好了后，下面来看看 playbooketcd.yml:
roles:
serial:1
remote_user:vagrant
hosts:etcd
ansible_hostname 由 Ansible 来发现，其他变量都定义在 roles/etcd/defaults/
我们使用了很多个参数，所有可能变化的部分都放在变量中。其中一些变量如
去执行。etcd 总是以单实例运行，不用担心多次执行这个命令会产生多个实例。
行的命令不会检查某些东西的状态正确与否，只是每次运行 Ansible playbook 时才
在想只运行一个子集或把一些东西排除在外时是很方便的。
式。最后把任务的标签设为etcd。当运行 playbook 时，标签可以用来过滤任务
etcd，第二次是 etcdctl。变量中的值表示为{{和}}分隔的变量键，为 Jinja2 格
使用files 变量的任务遍历列表中的每一个值，在本例中，将运行两次，第一次是
要用这个role复制另外一个文件，就可以把文件加到这里从而避免打开任务文件。
通常 shell 模块是最后一部分，因为它是无状态的。大多数情况下，shell 中运
第二个任务如下：
外部变量是一种很好的把将来可能变化的部分与任务相分离的方式。比如，
tags:[etcd]
shell: "nohup etcd -name {{ ansible_hostname }}\
name:Is running
>/var/log/etcd.log2>&1&"
-initial-cluster-statenew\
{{cl_node_01 },{{ cl_node_02 }},{{ cl_node_03 }}\
-initial-cluster\
-initial-cluster-token {{ cl_token }}\
http://{{ip}}:2379\
-advertise-client-urls
http://{{ip}}:2379,http://127.0.0.1:2379\
-listen-client-urls\
http://{{ip}}:2380\
-listen-peer-urls\
http://{{ip}}:2380\
-initial-advertise-peer-urls\
8.1服务注册表111
---
## Page 126
112
第8章发现服务一
检查是否正确配置了etcd 集群：
个IP地址。
式，表示要使用所有在10.100.194.201和10.100.194.203之间的地址。总计有三
10.100.194.20[1:3]
置，使用vagrant 作为远程用户，使用 sudo执行命令，运行common和etcd roles。
[etcd]
etcd
-common
这些命令的输出应当和以下内容相似：
curlhttp://serv-disc-01:2379/v2/keys/test\
在一个服务器上添加一个值并从另一个服务器上得到它，可以用这种方法来
ansible-playbook\
vagrantsshcd
让我们来运行etcd playbook并查看它的运行情况：
在这个例子中，你可以使用不同的方式来定义主机。第二行是 Ansible 的方
让我们来看看hosts/serv-disc 文件。这是一个清单文件，包含使用的所有主
当运行这个 playbook 时，Ansible 会对定义在一个清单中的所有服务器进行配
curlhttp://serv-disc-03:2379/v2/keys/test\
Ijq'.'
-d value="works" | jq '.
-X
"node":{
"action":"set",
PUT\
/vagrant/ansible/etcd.yml\
一分布式服务的关键
"value":"works"
"modifiedIndex": 8,
"key":"/test",
"createdIndex":8,
---
## Page 127
们达到此目的的工具之一是Registrator。
视所有节点上的 Docker，在新容器运行或现有容器停止时去更新etcd。能帮助我
少容器运行的服务器上并使用一个随机分配的端口。理想情况下，该工具应该监
动发送给etcd，通常也不知道那些信息是什么。请记住，服务可能会被部署在有最
自动发送给etcd。毕竟，能自动完成的事情为什么要手动去做呢？即使想把信息手
很棒呢？
也就是说，通过集群中的任何服务器发送的数据在所有服务器上都可用。是不是
给服务器 serv-disc-03（10.100.197.203）发送 HTTP GET 请求以查询存储的值。
现在已有一个地方用来保存与服务相关的信息，还需要一个工具把这些信息
部署了几个容器之后，集群看起来如图8-6所示。
我们会给服务器 serv-disc-01（10.100.197.201）发送 HTTP PUT请求，然后
容器
容器
"node":{
"action": "get",
节点-01
etcd
"value":"works"
'modifiedIndex":8,
'key":"/test",
"createdIndex":8,
容器
容器
图8-6多节点与Docker 容器和etcd
容器
容器
节点-02
etcd
容器
容器