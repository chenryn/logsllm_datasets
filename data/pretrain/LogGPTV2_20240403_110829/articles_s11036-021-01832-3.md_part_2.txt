necessary information. If there is logging too much, it make full use of fine-grained features, such as code
may be redundant or useless and masking the important snippets, program flow, control flow, and historical
information. Over-logging also increase system runtime loggingstatements,etc.
overhead, storage and maintenance cost [10]. Most log (2) Coupling with subsequent processes. High-quality
enhancementtechnologiesofloggingstatementlocationcan logs can lay a solid foundation for the follow-
be divided into context-oriented method and subsequent- up processes and tasks. It is one of the popular
task-orientedmethod. strategies to reverse-drive log enhancement with
Fu et al. [5] analyzed the source code of a software specificfollow-uptargettasksastheguide.
system that runs stably for a long time. They divided (3) Establishment of specifications and criteria. One of
the context snippets of logging statements into five themostsignificantcontributionsoflogenhancement
categories,includingassertion-checklogging,return-value- istoreplacethepartofmanualworkwithautomated
checklogging,exceptionlogging,logic-branchlogging,and machinelearningtoavoidthechaoticofloggingprac-
observing-pointlogging.Theyfurtherproposedaproactive tice and promote the establishment of specifications
logging tool, which used the function name, class name, andcriteria.
comment,andother“keyword”textofthecontextsnippets
Inaddition,wealsofoundthefollowingopenissuesinlog
asfeaturestotrainadecisiontreemodel.
enhancementtechnologies:
Paper [22] is a follow-up work of paper [5]. Zhu
et al. designed a logging suggestion tool, LogAdvisor, (1) Featureselection.Mostlogenhancementtechnologies
which is also based on the decision tree classifier. The stillneedtoselectfeaturesmanually.Itwillhinderthe
difference between them is the latter has more fine- developmentofautomationandbringtheuncertainty
grained feature selection. Li et al. [23] thought that the of logging practice. So, an automatic or simplifying
methods mentioned above provide developers with post- featureengineeringisstilltheexplorationdirectionof
implementation guidelines. The previous methods can logenhancement.
provide code snippets to get location guidance after the (2) Knowledge transfer. Logging statements are almost
code is written. they cannot provide real-time suggestions everywhere, but not all scenarios have enough
during coding. Thus, Li et al. proposed a random forest- historical data and features for log enhancement.
based classifier, which can provide real-time suggestions One of the open issues is to transfer “experience”
whendeveloperssubmitcodemodifications. such as data and algorithms from other systems, and
Yuan et al. [10], and Cinque et al. [24] focus on continuously adjust and optimize them in the target
selecting ERROR logging statement locations for failure scenario to solve the problem of “cold start” in log
diagnosis.Yuanetal.designedErrLogtoidentifypotential enhancement.
logging points in the program. Cinque et al. proposed a (3) Intelligent industrial use. The current log enhance-
rule-based method and leveraged artifacts producedduring ment technology is still in the stage of development
system design. It formalize the location of the logging frommanualtoautomation.Anintelligent,systematic
statementswithinthesourcecode.Zhaoetal.[25]thought and scientific deployment pipeline of log enhance-
there are many failures, especially complicated ones with mentisstillanopenissuewhichisworthexploring.
Mobile Networks and Applications (2021) 26:2353–2364 2357
Table1 Summaryandcomparisonoflogenhancementtechnologies
Target Index Technique Features Application
Loglevelselection [6] CP-Miner Codesnippet Unlimited
[15] Ordinalregression Loggingstatementmetrics Unlimited
Containingblockmetrics
Filemetrics
Changemetrics
Historicalmetrics
Logvariables [17] Saturnstaticanalysis Programdataflow/controlflow FailureDiagnosis
determination [20] GloVe,RNN Textfeature Unlimited
Descriptiontext [21] N-gram Textfeature Unlimited
generation
Duplicatedlogging [19] Abstractsyntaxtree Textfeature Unlimited
checker Dataflowanalysis
Textanalysis
Loggingstatement [23] Randomforest CodechangesSourcecodesnapshot Unlimited
locationdecision [5,22] Decisiontree Textfeatures Unlimited
[24] Rules Systemartifacts FailureDiagnosis
[10] Saturnstaticanalysis Programdataflow/controlflow FailureDiagnosis
[25] Shannoninformationtheory Programcontrolflow FailureDiagnosis
4Logparsing clusters,andmatchcomplexrawlogentriesintosimplified
log events/log template. LKE [30], LogMine [36], and
Logs are rich in variety and complex in structure. A log LenMa[35]arelogparsersthatfollowtheideaofclustering.
entrycontainstext,numericvalues,non-wordsuchascamel LKE uses a K-means algorithm based on weighted edit
case and snake case, etc. Most log analysis methods based distances between pairwise logs to cluster and extract log
onmachinelearningrequirestructuredinput.Therawlogs key/logtemplatefromthecommonpartofthesamecluster.
cannot meet the standard. Therefore, a log parsing process LogMineusesahierarchicalclusteringalgorithmbasedon
is introduced before log analysis, aiming to organize, distance related to the log length and token position. Both
compress, extract datafrom theraw unstructuredlogs,and LKEandLogMineareofflinemethodsthatrequiremultiple
parse it into a structured form for the follow-up analysis. traversalsofloginformationforclusteringandadjustment.
One of the traditional log parsing methods is based on LenMaparseslogsinanonlinemanner.Itonlyneedstouse
regular expressions, such as Grok-based LogStash [26]. theCosinesimilaritytotraversethelogsforclusteringbased
However,regularexpressionreliesonmanualconfiguration oneachlogentry’swordlength.
andcannotadapttologs’evolution.Ittakesalotoftimeand
labourcoststoupdateandmodifytheexpressions.Thereare 4.2Frequentpatternmining/Iterativepartitioning
also some methods of source code analysis, as mentioned
in [27, 28], which face the challenges of cross-platform, Frequent patterns refer to itemsets, subsequences, or
cross-languages,andunreachable. substructures that appear in a data set with frequency
Manyrecentstudies,aswellasindustrialtools,proposed no less than a user-specified threshold. SLCT [29],
methodsandtechnologiesrelatedtologparsingtoeliminate LogCluster [34], and LFA [31] are log parsers based on
the limitations of traditional methods. We classify and frequent pattern mining. SLCT is a log parser based on a
introducethemaccordingtotechnologyandstrategyinthe modified Apriori algorithm. The limitations of SLCT are
followingsection. that it is sensitive to the word’s position in the log and the
noiseofthedelimiter.LogClusterextendsSLCTbysettinga
4.1Clustering changeablelengthparameterforafixedword.UnlikeSLCT
and LogCluster’s, which look for frequent log file items,
The raw logs are generated by logging statements, which LFA looks for frequent items in a log entry and obtains
have a smaller scale and limited patterns. Clustering based thelogtemplatebytraversingtwice.Inadditiontofrequent
log parsers divide large-scale logs into small scale log patterns, IPLoM [32] proposed by Makanju et al., is based
2358 Mobile Networks and Applications (2021) 26:2353–2364
on iterative partitioning, which partitions logs into their Mode Log parsers can be divided into online and offline
respectiveclustersthrougha3-stephierarchicalpartitioning modes. The offline mode means that all log data needs to
process.Awordgroupwithonlyauniquewordinaspecific be available before log parsing, and the log file may be
positionisusedasthepartitiondescriptionandregardedas traversedmultipletimes.Theonlinemodedoesnotneedall
alogtemplate. logdatatobeavailable,andtheincominglogdataisparsed
inreal-time.
4.3Tree
Technique The technique refers to the basic algorithm is
Tree is a hierarchical data structure which is easy to followedbythelogparsers.
construct, search, and adjust. It is suitable for log parsing
scenarios that require an online manner, fast search, and Preprocessing Ifthelogparserneedstoprocessthelogdata
incrementaladjustment. throughregularexpressions,keywords,andothermethods,
SHISO [33] is a real-time log parser. It created a markitas“”,otherwisemarkitas“×”.
structured tree with the nodes generated from logs, and it
can mine log formats, retrieve log types and parameters in Universality If the log parser can work on all log types,
incremental data. He et al. [38] proposed Drain, realized markitas“”,otherwisemarkitas“×”.
onlinelogtemplatematchingbyconstructingafixeddepth
parser tree. Zhang et al. [39] proposed FT-Tree. They Efficiency Theefficiency oflogparserscan becategorized
thought that the log template is the longest combination intohigh,medium,andlowlevels.
of frequent occurring words, which can be searched using
multiplefrequenttemplatetrees. Application If it has been applied to the industry, it is
markedas“”,otherwisemarkitas“×”.
4.4Languagemodel Table2isasummaryandcomparisonoflogparsers.we
believethatlogparsinghasthefollowingtrends:
Logs are semi-structured natural language text. There are
(1) Efficiency fifirst. Log parsing is the work of data
some explorations of log parsing technologies based on
pre-processing.Efficiencyrequirementsarerelatively
language models in recent years. Nedelkoski et al. [62]
strict in most scenarios, especially for tasks that
proposed NuLog, which applied a Masked Language
require low latency, such as real-time anomaly
Modeling (MLM) on log parsing and coupled it as a
detection and performance monitoring. Therefore, in
pre-training with a downstream anomaly detection task
recent years, most proposed log parsers focus on the
to achieve the lowest edit distance to the ground truth
improvementofparseefficiency.
templates.Daietal.[63]proposedLogram,whichleveraged
(2) Onlinemodeandincrementallearning.Logparsingin
then-gramdictionariestoachieveefficientandscalablelog
offline mode is a batch processing. Log data need to
parsing. They also deployed an online version Logram on
be available before log parsing. It is not suitable for
Spark.
modernlarge-scalesystemswherelogsaregenerated
4.5Others in real-time and evolving. Therefore, log parsing
needs to meet the requirement of real-time stream
processing, adapt to log evolution, the robustness of
In addition to the above-mentioned common strategies,
noise,andincrementallearning.
MoLFI[40]proposedbyMessaoudietal.,usedamodified
(3) Universality. The type of logs is varied. A high
evolutionary algorithm NSGA-II to resolve the goals of
availability log parser should process any log and
log parsing as a multi-objective optimization problem, and
not limited to specific types. The universality of log
searchthespaceofsolutionsforaParetooptimalsetoflog
parsers is also one of the focuses on the research of
templates. Spell proposed by Du et al. [37], was based on
logparsing.
the longest common subsequence algorithm. It parsed the
eventlogintheformofanonlinestream.
Therearealsosomeopenissuesinlogparsing:
4.6Summaryandtrends (1) Industrialdeployment.Wefoundthatmostrecentlog
parsers have few industrial deployment and applica-
Zhu et al. [41] provide an open-source toolkit of 13 tion, and only conduct experimental evaluations on
log parsers, and evaluated them on 16 log datasets. On public or collected data sets. Log parsers need to be
this basis, we establish six comparison indicators, and deployed in an industrial scenario to play to its util-
summarizethecharacteristicsofalllogparsers. ity and evaluate its performance fully. Therefore, the
Mobile Networks and Applications (2021) 26:2353–2364 2359
Table2 Summaryandcomparisonoflogparsers
Mode Technique Name Preprocessing Universality Efficiency Application
offline Clustering LKE[30]   low 
Clustering LogMine[36]   medium 
FrequentPatternMining SLCT[29] × × high ×
FrequentPatternMining LFA[31] ×  high ×
FrequentPatternMining LogCluster[34] × × high ×
IterativePartitioning IPLoM[32] ×  high ×
ModifiedNSGA-IIalgorithm MoLFI[40]   low ×