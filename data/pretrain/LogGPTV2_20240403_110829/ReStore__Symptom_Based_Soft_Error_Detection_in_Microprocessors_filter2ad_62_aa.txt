title:ReStore: Symptom Based Soft Error Detection in Microprocessors
author:Nicholas J. Wang and
Sanjay J. Patel
ReStore: Symptom Based Soft Error Detection in Microprocessors
Nicholas J. Wang Sanjay J. Patel
Department of Electrical and Computer Engineering
University of Illinois at Urbana-Champaign
Abstract
Device scaling and large scale integration have led to
growing concerns about soft errors in microprocessors. To
date, in all but the most demanding applications, implement-
ing parity and ECC for caches and other large, regular SRAM
structures have been sufﬁcient to stem the growing soft error
tide. This will not be the case for long, and questions remain
as to the best way to detect and recover from soft errors in
the remainder of the processor — in particular, the less struc-
tured execution core.
In this work, we propose the ReStore architecture,
which leverages existing performance enhancing checkpoint-
ing hardware to recover from soft error events in a low cost
fashion. Error detection in the ReStore architecture is novel:
symptoms that hint at the presence of soft errors trigger
restoration of a previous checkpoint.
Example symptoms include exceptions, control ﬂow mis-
speculations, and cache or translation look-aside buffer
misses. Compared to conventional soft error detection via full
replication, the ReStore framework incurs little overhead, but
sacriﬁces some amount of error coverage. These attributes
make it an ideal means to provide very cost effective error
coverage for processor applications that can tolerate a non-
zero, but small, soft error failure rate. Our evaluation of
an example ReStore implementation exhibits a 2x increase in
MTBF (mean time between failures) over a standard pipeline
with minimal hardware and performance overheads. The
MTBF increases by 7x if ReStore is coupled with parity pro-
tection for certain pipeline structures.
1. Introduction
Among the various issues facing the scaling of imple-
mentation technologies into the deep submicron regime, cost
effective design of reliable processors in the presence of tran-
sient errors remains a challenge. Transient errors can arise
from multiple sources: external sources such as high-energy
particles that cause current pulses in digital circuits, as well as
internal sources that include coupling, leakage, power supply
noise, and temporal circuit variations.
While transient errors (also known as soft errors) have
always to some extent plagued semiconductor-based digital
systems, the scaling of devices, operating voltages, and de-
sign margins for purposes of performance and functionality
raises concerns about the increased susceptibility of future-
generation systems to such transient effects. Historically,
transient errors were of concern for those designing high-
availability systems or systems used in electronics-hostile en-
vironments such as outer space. Because of the conﬂuence of
device and voltage scaling, and the increasing complexity of
digital systems, the problem of transient errors is forecast to
be a problem for all future digital systems. From high-energy
neutrons alone, experts estimate that Failures in Time (FITs)
for a chip will scale at a minimum with the number of devices
(i.e., with Moore’s Law).
Known, effective techniques exist for protecting large
on-chip SRAM structures such as caches (e.g., parity and
ECC), but the question of protecting the unstructured control
logic that exists within a modern processor pipeline remains
open. The amount of chip area devoted to such general logic
is increasing with chip complexity, and therefore the effects
of transient errors through combinational logic networks and
pipeline latches is of particular concern. Few, and mostly ad-
hoc and costly, techniques exist for protecting the instruction
processing pipeline of a modern high-performance processor.
As a case example, when IBM designed the S/390 Server
G5 [26], a high tolerance to soft errors was deemed necessary.
Parity and ECC provided error coverage for much of the de-
sign, but full duplication was used for the execution pipeline.
This decision was made to ensure minimal impact to perfor-
mance while providing maximal error coverage. This costly
approach may be acceptable for a ﬂagship product intended
for the high availability market segment. However, it may not
be suitable for mainstream use where cost is of greater con-
cern and where applications demand reliable operation but are
generally not mission critical. Instead, a lower cost (in terms
of die space, design complexity, and power consumption) so-
lution that provides sufﬁcient soft error coverage might pro-
vide an attractive alternative.
We propose the ReStore processor architecture, which
uses a combination of short term on-chip architectural check-
points with novel symptom-based error detection to provide
high degrees of transient error protection at low cost. In our
previous work [28], we observed that a very large fraction of
simulated transient errors injected into the latches and RAM
cells of a modern processor pipeline (using a Verilog proces-
sor model) were logically masked before they could adversely
affect the executing application. Those injected faults that
did corrupt the application often did so quickly and noisily.
That is, such faults cause events that are atypical of normal or
steady state operation in addition to generating a data corrup-
tion; these atypical events serve as warnings that something
is amiss. We call such events transient error symptoms. Ex-
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:08:52 UTC from IEEE Xplore.  Restrictions apply. 
amples of such symptoms include exceptions (e.g. memory
protection violation, etc) and incorrect control ﬂow (e.g. fol-
lowing the wrong path of a conditional branch). The tendency
for these symptoms to occur quickly after a transient, coupled
with a checkpointing implementation in hardware to restore
clean architectural state, enables a cost effective soft error de-
tection and recovery solution.
In the ReStore Architecture, checkpoints are created by
the hardware every n instructions, where n might range from
10 to 1000 instructions, depending on design tradeoffs. As
instructions are executed by the processor pipeline, detection
logic monitors the application for symptomatic behavior. De-
tection of a symptom triggers rollback to a checkpoint.
If
the checkpoint contains uncorrupted data, then the soft error
(if any) was successfully detected and recovered. Because
symptoms are early alarms, false positives can occur; a symp-
tom detector might falsely trigger a rollback in the absence of
an error. If this is the case, the rollback was unnecessary and
the processor incurs a slight performance loss.
Errors are detected through time redundancy in the Re-
Store Architecture. However, instead of providing complete
time redundancy, the symptom detectors trigger in situations
that are likely to occur in the presence of an error. Thus, the
cost of redundancy is only paid when a soft error is likely
to be present – in essence, redundancy on demand. While
additional hardware is required to implement such a frame-
work, we believe that many of the required components will
exist in future microprocessors for the purpose of high perfor-
mance execution (i.e., speculation). Current microprocessors
already maintain checkpoints across 10’s of instructions for
purposes of speculation recovery.
We make several contributions in this paper. We describe
and evaluate the ReStore processor architecture. We describe
the checkpointing process and argue that it is an extension of
the checkpointing performed by high-performance processors
today. We perform a series of statistical fault injection studies
to evaluate the coverage provided by symptom-based check-
point restoration. In particular, we examine two classes of
symptom detectors that we empirically observe to be the most
common harbingers of data corruption due to soft errors: ex-
ceptions and errant control ﬂow. We ﬁnd that with these two
symptom detectors, we are able to reduce the incidence of
soft error-related silent data corruption by 2x over a standard,
contemporary high-performance pipeline, with marginal ef-
fect on performance and a slight increase in implementation
complexity. If the ReStore pipeline is augmented with par-
ity protection on certain pipeline structures, the mean time
between data corruptions increases to 7x over a contempo-
rary baseline. In addition, to support implementation, we pro-
pose the use of event logs to compare and contrast the events
that occur during the original and redundant executions. This
mechanism enables error logging and dynamic control of the
error coverage/performance tradeoff.
2. Processor Architecture
In this section, we present a high level overview of the
ReStore processor architecture. ReStore is an augmentation
Instruction Flow
Fetch
Decode
Rename
Issue
Execute
Commit
restore
Symptom Detect
Figure 1. ReStore architecture diagram
Checkpoint
of a modern high performance processor with components for
soft error symptom detection, checkpoint storage, and recov-
ery. We argue in this section that the additional mechanisms
required for ReStore, in particular the checkpointing mech-
anism, are straightforward extensions to hardware currently
added to today’s processors.
2.1. Microarchitectural overview
Figure 1 presents a conceptual block diagram of a
generic processor pipeline, augmented with the ReStore
mechanisms. Key features of this architecture include a
checkpoint store that stores a snapshot of architectural state
from 10–1000 instructions in the past. This state is the “safe”
state, and is restored when one of the symptom detectors sig-
nals that an error might have occurred. These detectors are
distributed throughout the execution pipeline, depending on
the symptom they are based on; in the ﬁgure, they are con-
ceptually located in the Symptom Detect block.
Logically, a checkpoint is a snapshot of the architectural
register ﬁle and memory image at an instance in time. At the
hardware level, the register ﬁle can be checkpointed by saving
off its contents, either through explicit copying or by saving
the current mapping between architectural registers and phys-
ical registers. Various techniques for doing so exist, some of
which are used in today’s microprocessors [5]. Depending
upon the implementation, the latency of register checkpoint-
ing can be minimal (e.g., 1 cycle) with the appropriate hard-
ware resources, with negligible impact on the performance of
the processor.
Creating checkpoints for memory state is more involved.
The basic idea is to buffer the memory updates executed be-
tween each checkpoint. This store buffer can be implemented
as a dedicated gated store buffer in the execution core [15],
or the L1 cache can be extended to provide this functional-
ity [27]. Clearly, in order to preserve correct execution se-
mantics, load instructions will need to check the store buffer
for recent store activity prior to checking the caches.
New checkpoints are taken periodically to maintain a re-
cent recovery point. Furthermore, checkpoints must be taken
on external synchronization events. For example, interrupts
and synchronizing memory instructions force checkpoints to
be taken, in order to maintain correctness.
In order for the ReStore approach to provide resilience
to errors, the checkpointed state of the processor needs to be
hardened against data corruption. Because the update fre-
quency of this state is relatively low, it can be protected with
ECC for recoverability, or parity for detectability. Further-
more, propagation of corrupt data into the checkpoint store
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:08:52 UTC from IEEE Xplore.  Restrictions apply. 
from neighboring components can be minimized through
careful design.
The speciﬁc design and implementation of the check-
pointing mechanisms are beyond the scope of this paper. In
this paper, we assume that architects have designed low la-
tency and low overhead checkpointing mechanisms to ac-
tivate performance enabling speculation. We then leverage
their mechanisms for soft error detection and recovery.
2.2. Speculation and checkpointing background
To further our argument that
low-level architectural
checkpointing is well understood, we examine how architec-
tural checkpointing is used in today’s processors. We also
examine the concept of control ﬂow speculation, as it neces-
sitates the use of checkpointing and is a prelude to one of
our symptom-based error detection schemes that we discuss
in the next section.
Today, almost all processors are pipelined to increase in-
struction throughput, and most pipelines execute instructions
in an out-of-order fashion to extract instruction-level paral-
lelism from the instruction stream. In order to make efﬁcient
use of such deeply-pipelined, out-of-order machines, specu-
lation is required. And in order to support speculation, low-
level architectural checkpointing is required.
Deep pipelines force the instruction fetch unit at the front
of the pipeline to speculate and fetch instructions well before
it is known whether they are needed or not. In particular, as
branch instructions are fetched, their outcome (e.g., taken or
not taken) is predicted by the fetcher. Only when the branch
executes at the tail end of the pipeline is it known whether the
speculation was correct or incorrect. If incorrect, the pipeline
is ﬂushed and the fetch unit resumes fetching instructions at
the correct memory address.
Because instructions can execute out-of-order, certain in-
structions after a speculated branch (i.e, those on the wrong
execution path) might have executed and modiﬁed architec-
tural state, and need to be undone, in some sense. To perform
recovery, register ﬁle values are restored by recovering archi-
tectural to physical register mappings, and memory state is
restored by ﬂushing younger store instructions from the store
buffer [15]. In a modern processor such as the Pentium 4 [5],
the pipeline can ﬂush back to an arbitrary instruction in the
pipeline, which amounts to about 10-to-100 instructions of
checkpointed state.
The historical trend of processor design has been to spec-
ulate over longer periods of time partly due to increased
pipeline depth and out-of-order scheduling windows, requir-
ing longer checkpointing intervals. These longer intervals
are important to the ReStore architecture, since they enable
detection and recovery of soft errors with longer soft error
to symptom propagation latencies. Proposed future architec-
tures clearly reﬂect the trend of more speculation and longer
checkpointing intervals [1]. Because these checkpoints are
generated and managed by the processor hardware, they can
be created and restored with low latency.
3. Symptom-based Detection
The novelty of the ReStore architecture is the use of
symptoms to perform error detection. Error detection has his-
torically been the costliest, most problematic part of error-
tolerant processor design. A symptom-based approach re-
laxes the constraints on the error detection mechanism, al-
lowing it to be approximate.
In this section, we empirically derive two candidate
symptoms by performing fault injection studies, and discuss
how their detection might be accomplished in a processor
pipeline. We also discuss the use of event logs to aid in the
implementation of a ReStore processor. Finally, we general-
ize the notion of symptom-based detection.
3.1. Examining the wake of a soft error
When a soft error occurs in a processor pipeline, one of
three possible outcomes will arise:
1. The soft error will be masked, or overwritten before it
can cause incorrect behavior. Since the error does not
result in a persistent data corruption or program crash,
we are not concerned with symptoms in this category.
2. The soft error induces a failure by causing a deadlock or
livelock condition with the processor hardware. These
conditions are often easily detected by watchdog timers
or other liveness checks, and can often be recovered by
ﬂushing the pipeline.
3. The soft error propagates into live software visible state
(registers or memory state) and is not overwritten. Such
errors are called persistent data corruptions, and soft er-
rors that fall into this category are the focus of this work.
As software runs on a processor, it continuously operates
upon architectural state — reading values from registers and
memory, performing operations on the values, and writing
the results back. If the software operates on corrupt values,
not only could the data result be incorrect, but the error could
result in “side-effects”. For example, exceptions (memory ac-
cess faults or arithmetic overﬂow) and incorrect control ﬂow
(following the wrong path after a conditional branch) can be
caused by corrupt data values feeding into a pointer, arith-
metic value, or branch instruction. These events are examples
of invalid program behavior — events that should not occur
in normal program execution.
In addition, more subtle events like cache and TLB
misses can also be caused by soft errors. These events are
valid and occur during normal processor operation, since
memory caches and translation look-aside buffers are de-
signed to only buffer a subset of all possible entries. These
events are infrequent in steady state execution and can indi-
cate the presence of a soft error.
The essential question is: what happens to an executing
application shortly after a soft error has corrupted its archi-
tectural state? Are there detectable events that can be used
for symptom-based detection? We investigate this question
via fault injection campaigns on an instruction set simulator
capable of running Alpha ISA binaries. We elected to per-
form this initial study on a virtual machine to remove any
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:08:52 UTC from IEEE Xplore.  Restrictions apply. 
register