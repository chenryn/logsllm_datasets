        livenessProbe:
          httpGet:
            port: 8000
        volumeMounts:
        - name: public
          mountPath: /public
 - name: secrets
 mountPath: /tmp/secrets
 readOnly: true
        command:
        - uwsgi
        - --http=0.0.0.0:8000
        - --module=todobackend.wsgi
        - --master
        - --die-on-term
        - --processes=4
        - --threads=2
        - --check-static=/public
        env:
        - name: DJANGO_SETTINGS_MODULE
          value: todobackend.settings_release
 - name: SECRETS_ROOT
 value: /tmp/secrets
 - name: MYSQL_HOST
 value: todobackend-db
 - name: MYSQL_USER
 value: todo
```
您必须定义`secrets`体积，并确保只有`MYSQL_PASSWORD`和`SECRET_KEY`项目暴露在**至**容器中。在**中以只读方式装载卷以装入**应用容器后，必须使用`secrets`装载路径配置`SECRETS_ROOT`环境变量。回想一下，在上一章中，我们增加了对**至**应用消费 Docker 机密的支持，默认情况下，Docker 机密位于`/run/secrets`。然而，由于`/run`是一个特殊的 tmpfs 文件系统，您不能在这个位置使用常规文件系统挂载来挂载您的机密，因此我们需要配置`SECRETS_ROOT`环境变量，它重新配置应用将查看的机密位置。我们还必须配置`MYSQL_HOST`和`MYSQL_USER`环境变量，以便随着`MYSQL_PASSWORD`的机密一起，**到**应用具有连接到数据库服务所需的信息。
如果您现在部署更改，您应该能够验证正确的机密项目是否安装在**至**容器中:
```
> kubectl apply -f k8s/app/
service "todobackend" unchanged
deployment.apps "todobackend" configured
> kubectl get pods
NAME                             READY   STATUS    RESTARTS   AGE
todobackend-74d47dd994-cpvl7     1/1     Running   0          35s
todobackend-74d47dd994-s2pp8     1/1     Running   0          35s
todobackend-db-574fb5746c-xcg9t  1/1     Running   0          12m
> kubectl exec todobackend-74d47dd994-cpvl7 ls /tmp/secrets
MYSQL_PASSWORD
SECRET_KEY
```
如果您浏览到`http://localhost/todos`，您应该会收到一个错误，指示数据库表不存在，这意味着应用现在已经成功连接并验证到数据库，但是缺少应用所需的模式和表。
# 运行作业
我们的**todo back and**应用几乎完全正常运行，但是我们需要执行一个关键的部署任务，那就是运行数据库迁移，以确保在**todo back and**数据库中存在正确的模式和表。正如您在本书中所看到的，数据库迁移应该在每次部署中只执行一次，而不管我们的应用运行了多少个实例。Kubernetes 通过一个特殊类型的控制器*作业*来支持这种性质的任务，顾名思义，它运行一个任务或进程(以 pod 的形式)，直到作业成功完成。
要为所需的数据库迁移任务创建作业，我们将在`todobackend`存储库中创建一个名为`k8s/app/migrations.yaml`的新文件，它允许您独立于位于同一位置的`deployment.yaml`文件中定义的其他应用资源运行作业:
```
apiVersion: batch/v1
kind: Job
metadata:
  name: todobackend-migrate
spec:
  backoffLimit: 4
  template:
    spec:
      restartPolicy: Never
      volumes:
      - name: secrets
        secret:
          secretName: todobackend-secret
          items:
          - key: MYSQL_PASSWORD
            path: MYSQL_PASSWORD
      containers:
      - name: migrate
        image: 385605022855.dkr.ecr.us-east-1.amazonaws.com/docker-in-aws/todobackend
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - name: secrets
          mountPath: /tmp/secrets
          readOnly: true
        command: ["python3","manage.py","migrate","--no-input"]
        env:
        - name: DJANGO_SETTINGS_MODULE
          value: todobackend.settings_release
        - name: SECRETS_ROOT
          value: /tmp/secrets
        - name: MYSQL_HOST
          value: todobackend-db
        - name: MYSQL_USER
          value: todo
```
您必须指定一种`Job`来将此资源配置为作业，并且在大多数情况下，该配置与我们之前创建的 pod/部署模板非常相似，除了`spec.backoffLimit`属性和模板`spec.restartPolicy`属性，前者定义了如果作业失败，Kubernetes 应尝试重新运行作业的次数，后者应始终设置为`Never`用于作业。
如果现在运行作业，您应该验证数据库迁移是否成功运行:
```
> kubectl apply -f k8s/app
service "todobackend" unchanged
deployment.apps "todobackend" unchanged
job.batch "todobackend-migrate" created
> kubectl get jobs
NAME                  DESIRED   SUCCESSFUL   AGE
todobackend-migrate   1         1            6s
> kubectl logs jobs/todobackend-migrate
Operations to perform:
  Apply all migrations: admin, auth, contenttypes, sessions, todo
Running migrations:
  Applying contenttypes.0001_initial... OK
  Applying auth.0001_initial... OK
  Applying admin.0001_initial... OK
  Applying admin.0002_logentry_remove_auto_add... OK
  Applying contenttypes.0002_remove_content_type_name... OK
  Applying auth.0002_alter_permission_name_max_length... OK
  Applying auth.0003_alter_user_email_max_length... OK
  Applying auth.0004_alter_user_username_opts... OK
  Applying auth.0005_alter_user_last_login_null... OK
  Applying auth.0006_require_contenttypes_0002... OK
  Applying auth.0007_alter_validators_add_error_messages... OK
  Applying auth.0008_alter_user_username_max_length... OK
  Applying auth.0009_alter_user_last_name_max_length... OK
  Applying sessions.0001_initial... OK
  Applying todo.0001_initial... OK
```
此时，您已经成功地将 todo back and 应用部署到了完全正常的状态，您应该能够连接到 todo back and 应用并创建、更新和删除 todo 项。
# 创建 EKS 集群
现在，您已经对 Kubernetes 有了坚实的了解，并且已经定义了在本地部署和运行 todobackend 应用所需的核心资源，现在是时候将我们的注意力转移到弹性 Kubernetes 服务(EKS)上了。
EKS 支持的核心资源是 EKS 集群，它代表了一个完全管理的、高可用性的 Kubernetes 管理器集群，为您管理 Kubernetes 控制平面。在本节中，我们将重点关注在 AWS 中创建 EKS 集群，建立对集群的认证和访问，以及部署 Kubernetes 仪表板。
创建 EKS 集群包括以下主要任务:
*   **安装客户端组件**:为了管理您的 EKS 集群，您需要安装各种客户端组件，包括`kubectl`(您已经安装了)和用于 Kubernetes 工具的 AWS IAM 认证器。
*   **创建集群资源**:这建立了 Kubernetes 的控制平面组件，由 Kubernetes 主节点组成。使用 EKS 时，主机作为完全托管的服务提供。
*   **为 EKS 配置 kubectl**:这允许您使用本地 kube CTL 客户端管理 EKS。
*   **创建工作节点**:这由 Kubernetes 节点组成，旨在运行您的容器工作负载。使用 EKS 时，您负责创建自己的工作节点，通常以 EC2 自动扩展组的形式部署。就像对于 ECS 服务一样，AWS 提供了一个 eks 优化的 AMI([https://docs . AWS . Amazon . com/eks/latest/user guide/eks-optimized-AMI . html](https://docs.aws.amazon.com/eks/latest/userguide/eks-optimized-ami.html))，其中包括工作节点加入 EKS 集群所需的所有软件组件。
*   **部署 Kubernetes 仪表板**:Kubernetes 仪表板为您提供了基于 web 的管理界面，用于管理和监控您的集群和容器应用。
At the time of writing, EKS clusters are not part of the AWS free tier and cost $0.20 USD per minute to run, so bear this in mind before you continue (see [https://aws.amazon.com/eks/pricing/](https://aws.amazon.com/eks/pricing/) for latest pricing information). We will be using CloudFormation templates to deploy both the EKS cluster and EKS worker nodes, so you can easily tear down and recreate your EKS cluster and worker nodes as required to reduce costs.
# 安装客户端组件
要管理您的 EKS 集群，您必须安装`kubectl`以及用于 Kubernetes 组件的 AWS IAM 认证器，该认证器允许`kubectl`使用您的 IAM 凭证向您的 EKS 集群进行认证。
您已经安装了`kubectl`，所以要为 Kubernetes 安装 AWS IAM 认证器，您需要安装一个名为`aws-iam-authenticator`的二进制文件，该文件由 AWS 发布，如下所示:
```
> curl -fs -o /usr/local/bin/aws-iam-authenticator https://amazon-eks.s3-us-west-2.amazonaws.com/1.10.3/2018-07-26/bin/darwin/amd64/aws-iam-authenticator
> chmod +x /usr/local/bin/aws-iam-authenticator
```
# 创建群集资源
在创建 EKS 群集之前，您需要确保您的 AWS 帐户满足以下先决条件:
*   **VPC 资源** : EKS 资源必须部署到一个至少有三个子网的 VPC。AWS 建议您为每个 EKS 群集创建自己的专用 VPC 和子网，但是在本章中，我们将使用在您的 AWS 帐户中自动创建的默认 VPC 和子网。请注意，当您创建 VPC 并定义集群将使用的子网时，您必须指定*所有*子网，您期望您的工作节点*和*负载平衡器将部署在这些子网中。推荐的模式是在私有子网中部署工作节点，并确保您也包括公共子网，以便 EKS 可以根据需要创建面向公共的负载平衡器。
*   **EKS 服务角色**:创建 EKS 集群时，您必须指定一个 IAM 角色来授予对 EKS 服务的访问权限，以管理您的集群。
*   **控制平面安全组**:您必须提供一个安全组，用于 EKS 集群管理器和工作节点之间的控制平面通信。EKS 服务将修改安全组规则，因此您应该为此要求创建一个新的空安全组。
aws 文档包括一个入门部分，其中提供了如何使用 AWS 控制台创建 eks 集群的详细信息。考虑到 cloud information 和我们在本书中使用的基础架构即代码方法支持 EKS，我们需要在`todobackend-aws`存储库中创建一个名为`eks`的文件夹，并在名为`todobackend-aws/eks/stack.yml`的新 cloud information 模板文件中定义我们的 EKS 集群和相关的 EKS 服务角色:
```
AWSTemplateFormatVersion: "2010-09-09"
Description: EKS Cluster
Parameters:
  Subnets:
    Type: List
    Description: Target subnets for EKS cluster
  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: Target VPC
Resources:
  EksServiceRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: eks-service-role
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - eks.amazonaws.com
            Action:
              - sts:AssumeRole