title:Information Flow Analysis of Component-Structured Applications
author:Peter Herrmann
Information Flow Analysis of Component-Structured Applications
University of Dortmund, Computer Science Department, 44221 Dortmund, Germany
PI:EMAIL
Peter Herrmann
Abstract
Software component
technology facilitates the cost-
effective development of specialized applications. Never-
theless, due to the high number of principals involved in a
component-structured system, it introduces special security
problems which have to be tackled by a thorough security
analysis. In particular, the diversity and complexity of infor-
mation ﬂows between components hold the danger of leak-
ing information. Since information ﬂow analysis, however,
tends to be expensive and error-prone, we apply our object-
oriented security analysis and modeling approach. It em-
ploys UML-based object-oriented modeling techniques and
graph rewriting in order to make the analysis easier and to
assure its quality even for large systems. Information ﬂow
is modeled based on Myers’ and Liskov’s decentralized la-
bel model combining label-based read access policy mod-
els and declassiﬁcation of information with static analysis.
We report on the principles of information ﬂow analysis of
component-based systems, clarify its application by means
of an example, and outline the corresponding tool-support.
1. Introduction
Due to the increasing deployment of information tech-
nology in enterprises, information system security is getting
more and more important. In order to guarantee secure and
reliable operation, a security model is designed identifying
relevant principals, components, attributes, functions, and
component interactions for a class of systems on a relatively
abstract level. Based on a model a system-speciﬁc security
policy(cid:1) is deﬁned for a particular system enforcing certain
security services which provide objectives concerning con-
ﬁdentiality, integrity, availability, and accountability [2].
In order to apply suitable security services for an existing
or newly designed information system, it has to undergo a
(cid:1)This term should not be confused with the term “organizational se-
curity policy” describing a management’s security strategy for protecting
assets.
security analysis. Here, the system is audited for vulnerabil-
ities, threats, and risks. Based on the audit results effective
safeguards are selected, designed, and conﬁgured. A secu-
rity analysis, however, is mostly expensive and laborious.
Due to the complexity of modern IT systems, the audit has
to be performed by well-trained experts. Moreover, system
users often require that the analysis considers extensive rec-
ommendations and standards in order to guarantee certain
security levels (e.g., UK Government recommends the use
of the security method CRAMM for systems employed in
government departments). Furthermore, one has to be con-
stantly aware of changing system threats requiring a new
security analysis in regular intervals.
A survey of security analysis approaches is provided
in [6]. Typically, an audit comprises a possibly iterated se-
ries of phases concerning the following subtasks:
1. Identiﬁcation of the system, its components, and the
related principals,
2. valuation of the assets contained in the system and def-
inition of the security objectives,
3. identiﬁcation of vulnerabilities and threats,
4. assessment of resulting risks,
5. planning, design, and evaluation of suitable counter-
measures.
To reduce the expense of a security analysis, abstract mod-
els of the systems as well as of the security-related require-
ments are developed recently (cf. [6]). The system model
forms the basis for the introduction of problem solutions
which are described by model modiﬁcations. Finally, the
abstract solutions are reﬁned to implementable countermea-
sures.
Our object-oriented security analysis approach [18] ap-
plies abstract modeling, model-based analysis, and logical
transformation. Unlike some other approaches (e.g., [5, 11,
24, 26]) it uses object-oriented techniques and graph rewrit-
ing to facilitate the subtasks and to enable automation. The
corresponding tool-support is similar to object-oriented de-
sign tools which are well established in the ﬁeld of software
engineering (e.g., [37, 43]). In fact, it re-uses the graph edit-
ing framework of the Argo project [43].
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:09:06 UTC from IEEE Xplore.  Restrictions apply. 
The tool supports the interactive design of graphical sys-
tem models in form of class and object diagrams as they
are deﬁned in the well-known Uniﬁed Modeling Language
(UML) [10]. The ﬁrst two subtasks (i.e., system model-
ing, asset valuation, and objective deﬁnition) are supported
by libraries of predeﬁned object classes which model sys-
tem component types. By multiple inheritance the classes
can be associated in order to support separation of concern.
Moreover, the classes deﬁne basic attributes and methods
for automated analysis and evaluation.
The remaining three subtasks of a security analysis are
performed in a highly automated fashion by application of
graph rewrite systems (e.g., [4]). A rewrite system consists
of a set of graph rewrite rules. Each rule is a tuple of two
graph patterns — a pre-pattern and a post-pattern —, an ap-
plication condition, and an effect function. The rule can be
applied to a graph if the graph contains a subgraph which
is an instance of its pre-pattern. Moreover, the object at-
tributes in the subgraph have to fulﬁll the application con-
dition. By application of the rule the subgraph is replaced
by an instance of the post-pattern. The attributes of the re-
placement objects are set according to the effect function.
In our approach a separate rewrite system is deﬁned for
each subtask. For instance, the rules of the rewrite sys-
tem for vulnerability identiﬁcation contains pre-patterns de-
scribing IT system scenarios which come along with certain
vulnerabilities for the systems. The corresponding post-
patterns describe the scenario augmented by special objects
representing vulnerabilities and threats on the scenario el-
ements. Thus, by application of these rules the graphical
system model can be provided by vulnerability and threat
representations. Likewise, by the other graph rewrite sys-
tems one can augment the model by suitable risk and safe-
guard representations.
By provision of different sets of class libraries and
rewrite systems one can facilitate security analysis in var-
ious application domains. A ﬁrst domain speciﬁc real-
ization [20] allows analysis of applications based on the
middleware platform CORBA [34] which will be audited
and protected according to the CORBA security speciﬁca-
tion [35].
This paper is centered on the domain of component-
structured systems. We will introduce the use of our se-
curity analysis approach for analyzing information ﬂow be-
tween software components. As a basis we use the decen-
tralized label model of Myers and Liskov [30, 31, 32] which
is well-suited to our work. In contrast to other information
ﬂow approaches it facilitates the checks at design time in-
stead of run-time which makes it feasible to security analy-
sis which is performed at design time as well.
In the sequel we will give a short introduction into
component-structured software and outline its major secu-
rity aspects. Thereafter we will sketch the decentralized la-
bel model and our security analysis approach. Afterwards,
we will introduce the application of our approach for in-
formation ﬂow analysis of component-structured systems.
Finally, an example application will be discussed.
2. Component Security
Applications coupled from software components (cf.
e.g., [42]) get more and more popular since their creation is
quite easy and cost-effective and they can be tailored to the
particular needs of their customers. Moreover, component-
based software can easily be extended and modiﬁed by
changing components and their coupling dynamically. The
components are supplied by different developers and of-
fered on an open market. The application designer selects
and conﬁgures suitable components — probably from var-
ious sources — and couples them to the target application.
The combination process utilizes the concept of explicit
contracts. A contract is legally binding and describes the
agreed properties of a component, especially its interface,
its operations, and the relation with its environment. More-
over, component coupling is comforted by rich run-time
support like special component methods providing reﬂec-
tion and introspection [40] (i.e., the exploration of compo-
nent properties, methods, and interfaces at run-time). Fur-
thermore, coupling is facilitated by scripting languages or
visual application builder tools. One can also realize dis-
tributed component-structured systems. Here, components
are executed on remote hosts and can be booked as com-
munication services. Platforms for component-structured
software comprise Java Beans [40], COM/DCOM [29], and
the CORBA Component Model [33].
Component-structured systems, however, impose new
security aspects since in comparison with ordinary dis-
tributed object-oriented systems more principals and roles
are involved. Besides users and application owners, one has
to consider also component vendors, remote host providers,
and application builders. These new principals introduce
new types of threats since, generally, they cannot trust each
other to full extent. In particular, a malicious component
may spoil security objectives of the whole application if
it, for instance, secretly lacks data to principals who have
not the privilege to read them. Therefore, like other appli-
cations the security of component-structured systems has
to recognize the deﬁnition of user classes and roles, the
authentication of users, and access control. Since com-
ponents may be coupled via networks, services for secure
communication must be enforced as well. Moreover, dis-
tributed components are executed on different hosts. As
the host and application owners not necessarily trust each
other, components have to be protected against malicious
host environments and vice versa (cf. [13, 23]). Similarly,
application owners and component vendors have to be pro-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:09:06 UTC from IEEE Xplore.  Restrictions apply. 
tected against each others, too. An application has to be
safeguarded against malicious components which may vi-
olate the integrity of the application and its resources, the
conﬁdentiality and availability of the managed information
and supported operation, and the accountability of the per-
formed actions. In contrast, a component vendor has to be
protected against wrong accusations due to spite of appli-
cation administrators, malicious surrounding components,
and host malfunctions. Moreover, the vendor needs protec-
tion against unlicensed use of components.
The corresponding security model
identiﬁes various
roles like users, resource owners, application owners, and
component vendors. Objects in the model comprise soft-
ware components, component interfaces, resources, host
environments, and communication facilities. Associations
between objects express the conﬁguration of components to
an application and the contribution of a component to the
functionality of the application. A component accesses re-
sources and forwards information and control to other com-
ponents resp. the application environment. Component in-
terfaces provide several types of mechanisms like method
invocations, event coupling, and infobusses [41]. During
run-time a series of interface events occur which forms the
behavior of the component. Based on the security model
a component-speciﬁc system security policy constrains the
behavior by deﬁning static and dynamic conditions in or-
der to guarantee security-related objectives for a certain
component-structured system.
One can check that a component fulﬁlls these condi-
tions by utilizing the explicit component contracts (cf. [42])
which can be extended in order to describe security-relevant
obligations (e.g., a certain data unit must only be forwarded
via an explicit interface). The obligations may be speciﬁed
formally in the form of behavior constraints (cf. [3, 17])
enabling the component user to prove in two steps that a
component fulﬁlls owner’s security policy. At ﬁrst, one has
to verify that all obligations and their combinations fulﬁll
the conditions of the security policy. This proof can be per-
formed at design time by means of a security analysis. For
instance, by analyzing the data ﬂow between components
one can check that data units pass only principals who are
entitled to read them. At second, one must check that the
obligations are kept by the components which is performed
either at design time by source code analysis resp. byte
code veriﬁcation or at run-time by security wrappers [19].
Here, the interface behavior of a component is observed and
checked for correspondence with the obligations.
Access control and information ﬂow models are well-
suited to prove that components guarantee the conﬁdential-
ity of applications. Access control (and also authentication)
is used to limit the access to single components to a set of
entitled principals (cf. [7, 25, 38]). Our security analysis
approach can also be used for introducing access control
and authentication systems to IT systems and components
which is described in [18].
While access control models constrain the release of in-
formation, they do not limit its propagation between the
components of the application (cf. [31]).
In contrast, by
application of information control models one may prevent
unauthorized disclosure of information due to wrong prop-
agation paths. By these models one can prove that the path
of an data unit contains only components granting reading
access to readers allowed to read the data unit. Moreover,
one can distinguish harmless from dangerous components.
Unlike a harmless component, a dangerous component (cid:1)
is coupled to a component (cid:1) granting access to a princi-
pal who is not privileged to read a data unit (cid:2) passing (cid:1).
(cid:1) is potentially dangerous since it may maliciously or er-
roneously leak (cid:2) to (cid:1) exposing it to a read access by a
non-privileged principal. Dangerous components have to be
scrutinized for compliance with the information ﬂow poli-
cies of the system owner.
3. Decentralized Labeling
In order to carry out information ﬂow control in a secu-
rity analysis at design time, we have to use a model facili-
tating static analysis. We selected Myers’ and Liskov’s de-
centralized label model [30, 31, 32] since it combines static