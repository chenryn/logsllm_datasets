# Information Flow Analysis of Component-Structured Applications

**Author:** Peter Herrmann  
**Affiliation:** University of Dortmund, Computer Science Department, 44221 Dortmund, Germany  
**Email:** [PI:EMAIL]

## Abstract
Software component technology enables the cost-effective development of specialized applications. However, due to the high number of principals involved in a component-structured system, it introduces unique security challenges that require thorough analysis. The complexity and diversity of information flows between components pose a significant risk of information leakage. Given that information flow analysis can be expensive and error-prone, we employ an object-oriented security analysis and modeling approach. This approach uses UML-based object-oriented modeling techniques and graph rewriting to simplify the analysis and ensure its quality, even for large systems. Information flow is modeled based on Myers' and Liskov's decentralized label model, which combines label-based read access policies and declassification of information with static analysis. We discuss the principles of information flow analysis for component-based systems, illustrate its application through an example, and outline the corresponding tool support.

## 1. Introduction
The increasing deployment of information technology in enterprises has made information system security more critical than ever. To ensure secure and reliable operation, a security model is designed to identify relevant principals, components, attributes, functions, and component interactions at a relatively abstract level. Based on this model, a system-specific security policy is defined to enforce certain security services, such as confidentiality, integrity, availability, and accountability [2].

To apply suitable security services to an existing or newly designed information system, a security analysis must be conducted. This involves auditing the system for vulnerabilities, threats, and risks, and then selecting, designing, and configuring effective safeguards. However, security analysis is often expensive and labor-intensive, requiring well-trained experts due to the complexity of modern IT systems. Additionally, system users often demand that the analysis adheres to extensive recommendations and standards to ensure specific security levels (e.g., the UK Government recommends the CRAMM method for systems in government departments). Furthermore, changing system threats necessitate regular reanalysis.

A survey of security analysis approaches is provided in [6]. Typically, an audit consists of a series of phases:
1. Identification of the system, its components, and related principals.
2. Valuation of the assets contained in the system and definition of security objectives.
3. Identification of vulnerabilities and threats.
4. Assessment of resulting risks.
5. Planning, design, and evaluation of suitable countermeasures.

To reduce the expense of a security analysis, abstract models of the systems and security-related requirements have been developed recently (cf. [6]). These models form the basis for introducing problem solutions, which are described by model modifications. Finally, the abstract solutions are refined into implementable countermeasures.

Our object-oriented security analysis approach [18] employs abstract modeling, model-based analysis, and logical transformation. Unlike some other approaches (e.g., [5, 11, 24, 26]), it uses object-oriented techniques and graph rewriting to facilitate the subtasks and enable automation. The corresponding tool support is similar to established object-oriented design tools in software engineering (e.g., [37, 43]) and reuses the graph editing framework of the Argo project [43].

The tool supports the interactive design of graphical system models using class and object diagrams as defined in the Unified Modeling Language (UML) [10]. The first two subtasks (system modeling, asset valuation, and objective definition) are supported by libraries of predefined object classes that model system component types. By multiple inheritance, these classes can be associated to support separation of concerns and define basic attributes and methods for automated analysis and evaluation.

The remaining three subtasks of a security analysis are performed in a highly automated manner using graph rewrite systems (e.g., [4]). A rewrite system consists of a set of graph rewrite rules, each comprising a pre-pattern, a post-pattern, an application condition, and an effect function. The rule is applied if the graph contains a subgraph that matches the pre-pattern and satisfies the application condition. The subgraph is then replaced by an instance of the post-pattern, with attributes set according to the effect function.

In our approach, a separate rewrite system is defined for each subtask. For example, the rules for vulnerability identification contain pre-patterns describing IT system scenarios with certain vulnerabilities. The corresponding post-patterns describe the scenario augmented with special objects representing vulnerabilities and threats. Similarly, other graph rewrite systems augment the model with risk and safeguard representations.

By providing different sets of class libraries and rewrite systems, our approach can be adapted to various application domains. A domain-specific realization [20] allows the analysis of CORBA-based applications, which are audited and protected according to the CORBA security specification [35].

This paper focuses on the domain of component-structured systems. We introduce the use of our security analysis approach for analyzing information flow between software components, using Myers' and Liskov's decentralized label model [30, 31, 32]. This model facilitates checks at design time rather than run-time, making it suitable for security analysis conducted at design time.

In the following sections, we provide a brief introduction to component-structured software and its major security aspects. We then sketch the decentralized label model and our security analysis approach. Next, we discuss the application of our approach for information flow analysis in component-structured systems. Finally, we present an example application.

## 2. Component Security
Component-structured software applications, which are composed of reusable software components (cf. [42]), are becoming increasingly popular due to their ease of creation and cost-effectiveness. They can be tailored to meet the specific needs of customers and can be easily extended and modified by dynamically changing components and their coupling. Components are supplied by different developers and offered on an open market. The application designer selects and configures suitable components from various sources and couples them to create the target application.

The combination process utilizes explicit contracts, which are legally binding and describe the agreed properties of a component, including its interface, operations, and relationship with its environment. Component coupling is facilitated by rich runtime support, such as reflection and introspection [40], and by scripting languages or visual application builder tools. Distributed component-structured systems can also be realized, where components are executed on remote hosts and can be booked as communication services. Platforms for component-structured software include Java Beans [40], COM/DCOM [29], and the CORBA Component Model [33].

However, component-structured systems introduce new security challenges due to the involvement of multiple principals and roles, such as users, application owners, component vendors, remote host providers, and application builders. These principals may not fully trust each other, and a malicious component could compromise the security objectives of the entire application by, for example, secretly leaking data to unauthorized principals. Therefore, like other applications, the security of component-structured systems must address user class and role definitions, user authentication, and access control. Secure communication services must also be enforced, especially when components are coupled via networks. Additionally, distributed components running on different hosts need protection against malicious environments, and vice versa (cf. [13, 23]).

The corresponding security model identifies various roles, such as users, resource owners, application owners, and component vendors. Objects in the model include software components, component interfaces, resources, host environments, and communication facilities. Associations between objects express the configuration of components within an application and the contribution of each component to the application's functionality. A component accesses resources and forwards information and control to other components or the application environment. Component interfaces provide mechanisms like method invocations, event coupling, and infobusses [41]. During runtime, a series of interface events forms the behavior of the component. Based on the security model, a component-specific system security policy constrains the behavior by defining static and dynamic conditions to ensure security objectives for a given component-structured system.

One can verify that a component meets these conditions by using explicit component contracts (cf. [42]), which can be extended to describe security-relevant obligations (e.g., a certain data unit must only be forwarded via an explicit interface). These obligations can be formally specified as behavior constraints (cf. [3, 17]), enabling the component user to prove in two steps that a component fulfills the ownerâ€™s security policy. First, one must verify that all obligations and their combinations meet the conditions of the security policy, which can be done at design time through security analysis. For example, by analyzing the data flow between components, one can check that data units pass only through principals entitled to read them. Second, one must ensure that the obligations are upheld by the components, either at design time through source code analysis or byte code verification, or at runtime through security wrappers [19].

Access control and information flow models are well-suited for proving that components guarantee the confidentiality of applications. Access control (and authentication) limits access to single components to a set of entitled principals (cf. [7, 25, 38]). Our security analysis approach can also be used to introduce access control and authentication systems to IT systems and components, as described in [18].

While access control models constrain the release of information, they do not limit its propagation between components (cf. [31]). In contrast, information flow models can prevent unauthorized disclosure of information by ensuring that the path of a data unit contains only components that grant reading access to authorized readers. This allows distinguishing harmless from dangerous components. A dangerous component (C1) is one that is coupled to a component (C2) granting access to a principal who is not privileged to read a data unit (D) passing through C1. C1 is potentially dangerous because it may leak D to C2, exposing it to a non-privileged principal. Dangerous components must be scrutinized for compliance with the information flow policies of the system owner.

## 3. Decentralized Labeling
To conduct information flow control in a security analysis at design time, we use a model that facilitates static analysis. We selected Myers' and Liskov's decentralized label model [30, 31, 32] because it combines static and dynamic analysis, allowing for the effective management of information flow.