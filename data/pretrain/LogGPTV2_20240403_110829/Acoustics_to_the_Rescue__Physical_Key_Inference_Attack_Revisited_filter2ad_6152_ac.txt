0
74 Test Keys Sorted By Best to Worst Rank/Pool Size
40
50
60
20
30
70
o
i
t
a
R
n
o
i
t
c
u
d
e
R
e
c
a
p
S
y
e
K
1
0.8
0.6
0.4
0.2
0
0
87% of Keys with >50%
Key Space Reduction
10
20
30
40
50
60
70
74 Test Keys Sorted By Best to Worst Rank
Figure 11: Figure depicts the overall performance comparing
Video-only pool-size vs. Keynergy (Video + Acoustics) rank.
Figure 12: Performance of Acoustics-only approach.
5ft up to 25ft away from the door setup. We also perform
our experiments in different locations including university’s
lecture hall, multipurpose room and a dormitory room.
We conduct the experiments with a total of 78 keys (where
75 and three keys are each used for test and train, respectively),
with 10 − 12 trials of insertions for each instance of experi-
ments. We collect more than 3,600 insertions by recruiting
a total of 13 participants over a span of three months. We
conduct the experiments by adhering to our university’s In-
stitutional Review Board (IRB). We present the speciﬁc data
collection methods accordingly in the subsequent subsections.
Performance Metrics. We deﬁne and utilize three metrics in
order to measure Keynergy’s attack performance.
• Key Rank (Rankkey): Rank of each key in keyspace from
Keynergy’s attack; A higher ranked key (e.g., Rank 1) is
more likely to match the victim’s key.
• Keyspace Reduction Ratio (RatioReduction): Fraction of
keys in the keyspace that yield lower ranks than the
victim key’s rank (e.g., if victim’s key is predicted as
Rank 10, then RatioReduction = 59,207−10
59,207 ≈ 0.999.
• Search Pool Size (Poolsearch): Reduced key search space
from video analysis (see Section 6.3.3). Keys within the
pool are equally likely to be the victim key.
6.2 Attack Performance
We present Keynergy’s overall attack accuracy, and acoustics-
only attack accuracy. We utilize 74 different Schlage SC1
keys, out of 75 randomly purchased keys, with one key ﬁltered
out due to the lack of distinct clusters (see Section 4.2). We
collect key insertion audio when a single participant inserts
all 74 keys for ten trials per key in a dormitory room with the
representative Miccond located 1ft away from the door setup.
6.2.1 Overall Attack Accuracy
We present the overall results by combining audio and visual
information for reducing keyspace as depicted in Figure 11.
We plot in sorted order the keyspace reduction results of
Keynergy (i.e., Video + Acoustics approach) depicted with
‘∗’ (red curve) across all 74 keys averaged over ten trials per
key. We also plot the results of the baseline (i.e., Video-only
approach) in sorted order, depicted with ‘o’ (blue curve) by
utilizing the prediction error distribution again, on all 74 keys
averaged over ten trials per key (based on real-world video
analysis further explained and evaluated in Section 6.3.3). The
video-only approach yields an average keyspace reduction
(i.e., Poolsearch) of 166 keys (with a recall of 92% (σ = 62)
with a minimum of 15 and a maximum of 242 keys. Keynergy
further signiﬁcantly improves the results by achieving an
average rank (i.e., Rankkey) of 63 with 92% recall (σ = 47).
The combined acoustics-video approach achieves the smallest
and largest average rank of 1 and 206, respectively, with six
keys achieving an average rank below 10 across ten different
iterations. The results demonstrate around 62% improvement
of Keynergy (i.e., Video + Acoustics approach) over the Video-
only approach on average. We note that many of the 166
keys (in the reduced keyspace from video-only approach)
contain similar bittings, rendering this further reduction to
60 keys signiﬁcantly difﬁcult. This ﬁne-grained reduction
is possible because Keynergy makes use of resulting click
patterns that produce subtle differences, ultimately having
acoustics complement the Video-only approach.
6.2.2 Acoustics-only Attack Accuracy
To further study the effects of the acoustics-based reduction,
we evaluate the Acoustics-only approach by depicting the
sorted RatioReduction on all 74 keys in Figure 12. Overall, this
approach yields an average reduction rate of 75%, with 87%
of keys (i.e., 65 keys) achieving more than 50% reduction.
This result translates to an average Rankkey of around 14,835,
with highest rank of 119. This result demonstrates the util-
ity of acoustics for key inference, while also depicting its
insufﬁciency to realise a practical attack on its own. Keyn-
ergy overcomes this challenge by combining audio and video
modalities, and achieves high reduction ratios (> 99%).
6.3 Modules Evaluation
We evaluate the different modules of our Keynergy design and
use the results to justify our choice of model parameters.
3262    30th USENIX Security Symposium
USENIX Association
(a)
4
.
4
9
8
.
9
8
6
.
2
9
9
.
6
7
.
7
8
7
.
7
8
7
8
.
7
7
.
4
9
6
)
100
%
100
(
y
c
a
r
u
c
c
A
n
o
i
t
c
e
t
e
D
r
e
80
80
60
60
40
40
20
20
n
o
i
t
c
e
t
e
D
r
e
t
s
u
C
l
t
n
e
m
e
n
i
f
e
R
k
c
i
l
C
)
%
(
y
c
a
r
u
c
c
A
)
%
(
y
c
a
r
u
c
c
A
)
100
%
100
80
80
60
60
40
40
20
20
(
y
c
a
r
u
c
c
A
t
n
e
m
e
n
i
f
e
R
k
c
i
l
C
.
8
0
8
5
.
4
6
2
6
3
.
5
5
t
s
u
C
l
0
0
All Clusters
All Clusters
Weighted Flux
Superflux
High Frequency Content
k-means Clustering-based
Last 3 Clusters
Last 3 Clusters
(a)
(b)
Weighted Flux
Superflux
High Frequency Content
k-means Clustering-based
.
3
7
7
2
.
3
6
.
1
0
5
.
3
1
3
1
.
3
7
3
.
3
5
2
.
0
4
.
6
3
3
0
0
Cluster 3
Cluster 3
Cluster 4
Cluster 4
Cluster 5
Cluster 5
(b)
Figure 13: Performance of (a) different cluster detection ap-
proaches, (b) different click detection approaches.
6.3.1 Click and Cluster Detection Performance
To evaluate this module, we capture audio recordings from
the Miccond at the university’s lecture hall. We recruited three
participants to insert three keys (different from the aforemen-
tioned 75 keys) with twelve trials per key, ultimately totaling
108 key insertions. In order to identify the best approach for
cluster and click detection, we evaluate different onset detec-
tion techniques, namely – (a) Weighted Flux [14], that captures
differences in high-frequency energies (see Section 5.2), (b)
Superﬂux [18], that captures energy differences and is robust
to signal ﬂuctuations in frequency and loudness, (c) High
Frequency Content [41], that captures high frequency ener-
gies, and (d) K-Means Clustering [37], which is a well-known
clustering approach that identiﬁes unique spectral energy dis-
tribution around click onsets. We consider a frequency range
of 15 − 48kHz for the ﬁrst three approaches as high frequen-
cies capture sudden variations in energy, while we consider
the entire frequency range for the clustering-based approach
to identify additional lower frequency features that contribute
to click detection. For all approaches, we ﬁx the spectrogram
window size to a low value of 127 (about 0.66 ms) with a
75% overlap between windows for better time resolution of
clicks. Furthermore, we manually annotate the clicks and their
corresponding clusters to utilize it as the ground truth.
Cluster Detection. We evaluate the performance of the Clus-
ter Detection sub-module by plotting the cluster detection
accuracy when varying across the different techniques. Specif-
ically, we assign a score of one when the computed cluster
boundaries include all of the manually annotated clicks be-
longing to the cluster, and zero otherwise. As depicted in
Figure 13(a), Weighted Flux technique yields highest cluster
detection accuracy of 78.7% across all clusters, and 94.4%
across the last three clusters. From this sub-module, we empir-
ically choose the optimal values of design parameters includ-
ing an amplitude threshold of 0.15, and a minimum duration
between adjacent clicks of 4 time windows (i.e., 0.66 ms).
k
n
a
R
g
n
i
t
u
b
i
r
t
n
o
C
7
7
6
6
k
n
5
5
a
R
4
g
4
n
i
t
u
3
3
b
i
r
t
n
2
o
2
C
1
1
0
0
Pattern Comparison Error (e
)
pattern
Click Detection Error (e
)
click
Cluster Average
5
6
3
.
8
2
4
.
7
9
3
.
7
0
3
.
6
4
3
.
6
2
3
.
7
3
.
1
0
3
.
6
3
3
.
Cluster 3
Cluster 3
Cluster 4
Cluster 4
Cluster 5
Cluster 5
Figure 14: Figure depicts contributing rank of cluster–error
pairs as well as each cluster, where a lower contributing rank
implies higher contribution towards ﬁnal Rankkey.
Click Detection Reﬁnement. We evaluate the click detec-
tion reﬁnement accuracy within each cluster by comparing
detected clicks against the manually annotated clicks. We
assign scores based on the ratio of correctly detected clicks
but penalize any wrong clicks by assigning zero for the en-
tire cluster. Figure 13(b) shows that weighted-ﬂux technique
yields highest reﬁnement accuracy for all three clusters with
80.8%, 77.3% and 73.1%, respectively. We obtain prominence
threshold of 0.2, and a minimum duration between adjacent
clicks of 5 time windows (i.e., 0.83 ms). The increase in the
minimum duration between adjacent clicks (from 0.66 ms