title:The QUIC Transport Protocol: Design and Internet-Scale Deployment
author:Adam Langley and
Alistair Riddoch and
Alyssa Wilk and
Antonio Vicente and
Charles Krasic and
Dan Zhang and
Fan Yang and
Fedor Kouranov and
Ian Swett and
Janardhan R. Iyengar and
Jeff Bailey and
Jeremy Dorfman and
Jim Roskind and
Joanna Kulik and
Patrik Westin and
Raman Tenneti and
Robbie Shade and
Ryan Hamilton and
Victor Vasiliev and
Wan-Teh Chang and
Zhongyi Shi
The QUIC Transport Protocol:
Design and Internet-Scale Deployment
Adam Langley, Alistair Riddoch, Alyssa Wilk, Antonio Vicente, Charles Krasic, Dan Zhang, Fan
Yang, Fedor Kouranov, Ian Swett, Janardhan Iyengar, Jeff Bailey, Jeremy Dorfman, Jim Roskind,
Joanna Kulik, Patrik Westin, Raman Tenneti, Robbie Shade, Ryan Hamilton, Victor Vasiliev,
Wan-Teh Chang, Zhongyi Shi *
Google
PI:EMAIL
ABSTRACT
We present our experience with QUIC, an encrypted, multiplexed,
and low-latency transport protocol designed from the ground up to
improve transport performance for HTTPS traffic and to enable rapid
deployment and continued evolution of transport mechanisms. QUIC
has been globally deployed at Google on thousands of servers and
is used to serve traffic to a range of clients including a widely-used
web browser (Chrome) and a popular mobile video streaming app
(YouTube). We estimate that 7% of Internet traffic is now QUIC. We
describe our motivations for developing a new transport, the princi-
ples that guided our design, the Internet-scale process that we used
to perform iterative experiments on QUIC, performance improve-
ments seen by our various services, and our experience deploying
QUIC globally. We also share lessons about transport design and the
Internet ecosystem that we learned from our deployment.
CCS CONCEPTS
• Networks → Network protocol design; Transport protocols;
Cross-layer protocols;
ACM Reference format:
Adam Langley, Alistair Riddoch, Alyssa Wilk, Antonio Vicente, Charles
Krasic, Dan Zhang, Fan Yang, Fedor Kouranov, Ian Swett, Janardhan Iyengar,
Jeff Bailey, Jeremy Dorfman, Jim Roskind, Joanna Kulik, Patrik Westin,
Raman Tenneti, Robbie Shade, Ryan Hamilton, Victor Vasiliev, Wan-Teh
Chang, Zhongyi Shi . 2017. The QUIC Transport Protocol: Design and
Internet-Scale Deployment. In Proceedings of SIGCOMM ’17, Los Angeles,
CA, USA, August 21-25, 2017, 14 pages.
https://doi.org/10.1145/3098822.3098842
INTRODUCTION
1
We present QUIC, a new transport designed from the ground up
to improve performance for HTTPS traffic and to enable rapid de-
ployment and continued evolution of transport mechanisms. QUIC
replaces most of the traditional HTTPS stack: HTTP/2, TLS, and
*Fedor Kouranov is now at Yandex, and Jim Roskind is now at Amazon. Author names
are in alphabetical order.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
© 2017 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-4653-5/17/08.
https://doi.org/10.1145/3098822.3098842
Figure 1: QUIC in the traditional HTTPS stack.
TCP (Figure 1). We developed QUIC as a user-space transport with
UDP as a substrate. Building QUIC in user-space facilitated its
deployment as part of various applications and enabled iterative
changes to occur at application update timescales. The use of UDP
allows QUIC packets to traverse middleboxes. QUIC is an encrypted
transport: packets are authenticated and encrypted, preventing mod-
ification and limiting ossification of the protocol by middleboxes.
QUIC uses a cryptographic handshake that minimizes handshake
latency for most connections by using known server credentials on
repeat connections and by removing redundant handshake-overhead
at multiple layers in the network stack. QUIC eliminates head-of-line
blocking delays by using a lightweight data-structuring abstraction,
streams, which are multiplexed within a single connection so that
loss of a single packet blocks only streams with data in that packet.
On the server-side, our experience comes from deploying QUIC
at Google’s front-end servers, which collectively handle billions of
requests a day from web browsers and mobile apps across a wide
range of services. On the client side, we have deployed QUIC in
Chrome, in our mobile video streaming YouTube app, and in the
Google Search app on Android. We find that on average, QUIC re-
duces latency of Google Search responses by 8.0% for desktop users
and by 3.6% for mobile users, and reduces rebuffer rates of YouTube
playbacks by 18.0% for desktop users and 15.3% for mobile users1.
As shown in Figure 2, QUIC is widely deployed: it currently ac-
counts for over 30% of Google’s total egress traffic in bytes and
consequently an estimated 7% of global Internet traffic [61].
We launched an early version of QUIC as an experiment in 2013.
After several iterations with the protocol and following our de-
ployment experience over three years, an IETF working group was
formed to standardize it [2]. QUIC is a single monolithic protocol in
1Throughout this paper "desktop" refers to Chrome running on desktop platforms
(Windows, Mac, Linux, etc.) and "mobile" refers to apps running on Android devices.
183
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
A. Langley et al.
header, has become fair game for middleboxes to inspect and mod-
ify. As a result, even modifying TCP remains challenging due to
its ossification by middleboxes [29, 49, 54]. Deploying changes to
TCP has reached a point of diminishing returns, where simple pro-
tocol changes are now expected to take upwards of a decade to see
significant deployment (see Section 8).
Implementation Entrenchment: As the Internet continues to evolve
and as attacks on various parts of the infrastructure (including the
transport) remain a threat, there is a need to be able to deploy changes
to clients rapidly. TCP is commonly implemented in the Operat-
ing System (OS) kernel. As a result, even if TCP modifications
were deployable, pushing changes to TCP stacks typically requires
OS upgrades. This coupling of the transport implementation to the
OS limits deployment velocity of TCP changes; OS upgrades have
system-wide impact and the upgrade pipelines and mechanisms are
appropriately cautious [28]. Even with increasing mobile OS popula-
tions that have more rapid upgrade cycles, sizeable user populations
often end up several years behind. OS upgrades at servers tend to
be faster by an order of magnitude but can still take many months
because of appropriately rigorous stability and performance testing
of the entire OS. This limits the deployment and iteration velocity
of even simple networking changes.
Handshake Delay: The generality of TCP and TLS continues to
serve Internet evolution well, but the costs of layering have become
increasingly visible with increasing latency demands on the HTTPS
stack. TCP connections commonly incur at least one round-trip delay
of connection setup time before any application data can be sent,
and TLS adds two round trips to this delay2. While network band-
width has increased over time, the speed of light remains constant.
Most connections on the Internet, and certainly most transactions on
the web, are short transfers and are most impacted by unnecessary
handshake round trips.
Head-of-line Blocking Delay: To reduce latency and overhead costs
of using multiple TCP connections, HTTP/1.1 recommends limiting
the number of connections initiated by a client to any server [19].
To reduce transaction latency further, HTTP/2 multiplexes multi-
ple objects and recommends using a single TCP connection to any
server [8]. TCP’s bytestream abstraction, however, prevents applica-
tions from controlling the framing of their communications [12] and
imposes a "latency tax" on application frames whose delivery must
wait for retransmissions of previously lost TCP segments.
In general, the deployment of transport modifications for the
web requires changes to web servers and clients, to the transport
stack in server and/or client OSes, and often to intervening mid-
dleboxes. Deploying changes to all three components requires in-
centivizing and coordinating between application developers, OS
vendors, middlebox vendors, and the network operators that deploy
these middleboxes. QUIC encrypts transport headers and builds
transport functions atop UDP, avoiding dependence on vendors and
network operators and moving control of transport deployment to
the applications that directly benefit from them.
2TCP Fast Open [11, 53] and TLS 1.3 [55] seek to address this delay, and we discuss
them later in Section 8.
Figure 2: Timeline showing the percentage of Google traffic served over
QUIC. Significant increases and decreases are described in Section 5.1.
Figure 3: Increase in secure web traffic to Google’s front-end servers.
our current deployment, but IETF standardization will modularize
it into constituent parts. In addition to separating out and specify-
ing the core protocol [33, 34], IETF work will describe an explicit
mapping of HTTP on QUIC [9] and separate and replace QUIC’s
cryptographic handshake with the more recent TLS 1.3 [55, 63].
This paper describes pre-IETF QUIC design and deployment. While
details of the protocol will change through IETF deliberation, we
expect its core design and performance to remain unchanged.
In this paper, we often interleave our discussions of the protocol,
its use in the HTTPS stack, and its implementation. These three are
deeply intertwined in our experience. The paper attempts to reflect
this connectedness without losing clarity.
2 MOTIVATION: WHY QUIC?
Growth in latency-sensitive web services and use of the web as a plat-
form for applications is placing unprecedented demands on reducing
web latency. Web latency remains an impediment to improving user-
experience [21, 25], and tail latency remains a hurdle to scaling the
web platform [15]. At the same time, the Internet is rapidly shifting
from insecure to secure traffic, which adds delays. As an example
of a general trend, Figure 3 shows how secure web traffic to Google
has increased dramatically over a short period of time as services
have embraced HTTPS. Efforts to reduce latency in the underlying
transport mechanisms commonly run into the following fundamental
limitations of the TLS/TCP ecosystem.
Protocol Entrenchment: While new transport protocols have been
specified to meet evolving application demands beyond TCP’s sim-
ple service [40, 62], they have not seen wide deployment [49, 52, 58].
Middleboxes have accidentally become key control points in the In-
ternet’s architecture: firewalls tend to block anything unfamiliar for
security reasons and Network Address Translators (NATs) rewrite
the transport header, making both incapable of allowing traffic from
new transports without adding explicit support for them. Any packet
content not protected by end-to-end security, such as the TCP packet
184
The QUIC Transport Protocol
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
3 QUIC DESIGN AND IMPLEMENTATION
QUIC is designed to meet several goals [59], including deployabil-
ity, security, and reduction in handshake and head-of-line blocking
delays. The QUIC protocol combines its cryptographic and trans-
port handshakes to minimize setup RTTs. It multiplexes multiple
requests/responses over a single connection by providing each with
its own stream, so that no response can be blocked by another. It en-
crypts and authenticates packets to avoid tampering by middleboxes
and to limit ossification of the protocol. It improves loss recovery by
using unique packet numbers to avoid retransmission ambiguity and
by using explicit signaling in ACKs for accurate RTT measurements.
It allows connections to migrate across IP address changes by us-
ing a Connection ID to identify connections instead of the IP/port
5-tuple. It provides flow control to limit the amount of data buffered
at a slow receiver and ensures that a single stream does not consume
all the receiver’s buffer by using per-stream flow control limits. Our
implementation provides a modular congestion control interface for
experimenting with various controllers. Our clients and servers nego-
tiate the use of the protocol without additional latency. This section
outlines these elements in QUIC’s design and implementation. We
do not describe the wire format in detail in this paper, but instead
refer the reader to the evolving IETF specification [2].
3.1 Connection Establishment
Figure 4: Timeline of QUIC’s initial 1-RTT handshake, a subsequent
successful 0-RTT handshake, and a failed 0-RTT handshake.
QUIC relies on a combined cryptographic and transport hand-
shake for setting up a secure transport connection. On a successful
handshake, a client caches information about the origin3. On sub-
sequent connections to the same origin, the client can establish an
encrypted connection with no additional round trips and data can
be sent immediately following the client handshake packet with-
out waiting for a reply from the server. QUIC provides a dedicated
reliable stream (streams are described below) for performing the
cryptographic handshake. This section summarizes the mechanics of
QUIC’s cryptographic handshake and how it facilitates a zero round-
trip time (0-RTT) connection setup. Figure 4 shows a schematic of
the handshake.
Initial handshake: Initially, the client has no information about the
server and so, before a handshake can be attempted, the client sends
an inchoate client hello (CHLO) message to the server to elicit a
reject (REJ) message. The REJ message contains: (i) a server config
3An origin is identified by the set of URI scheme, hostname, and port number [5].
185
that includes the server’s long-term Diffie-Hellman public value, (ii)
a certificate chain authenticating the server, (iii) a signature of the
server config using the private key from the leaf certificate of the
chain, and (v) a source-address token: an authenticated-encryption
block that contains the client’s publicly visible IP address (as seen at
the server) and a timestamp by the server. The client sends this token
back to the server in later handshakes, demonstrating ownership of
its IP address. Once the client has received a server config, it au-
thenticates the config by verifying the certificate chain and signature.
It then sends a complete CHLO, containing the client’s ephemeral
Diffie-Hellman public value.
Final (and repeat) handshake: All keys for a connection are es-
tablished using Diffie-Hellman. After sending a complete CHLO,
the client is in possession of initial keys for the connection since it
can calculate the shared value from the server’s long-term Diffie-
Hellman public value and its own ephemeral Diffie-Hellman private
key. At this point, the client is free to start sending application data
to the server. Indeed, if it wishes to achieve 0-RTT latency for data,
then it must start sending data encrypted with its initial keys before
waiting for the server’s reply.
If the handshake is successful, the server returns a server hello
(SHLO) message. This message is encrypted using the initial keys,
and contains the server’s ephemeral Diffie-Hellman public value.
With the peer’s ephemeral public value in hand, both sides can cal-
culate the final or forward-secure keys for the connection. Upon
sending an SHLO message, the server immediately switches to send-
ing packets encrypted with the forward-secure keys. Upon receiving
the SHLO message, the client switches to sending packets encrypted
with the forward-secure keys.
QUIC’s cryptography therefore provides two levels of secrecy:
initial client data is encrypted using initial keys, and subsequent
client data and all server data are encrypted using forward-secure
keys. The initial keys provide protection analogous to TLS session
resumption with session tickets [60]. The forward-secure keys are
ephemeral and provide even greater protection.
The client caches the server config and source-address token, and
on a repeat connection to the same origin, uses them to start the
connection with a complete CHLO. As shown in Figure 4, the client
can now send initial-key-encrypted data to the server, without having
to wait for a response from the server.
Eventually, the source address token or the server config may
expire, or the server may change certificates, resulting in handshake
failure, even if the client sends a complete CHLO. In this case, the
server replies with a REJ message, just as if the server had received
an inchoate CHLO and the handshake proceeds from there. Further
details of the QUIC handshake can be found in [43].
Version Negotiation: QUIC clients and servers perform version
negotiation during connection establishment to avoid unnecessary
delays. A QUIC client proposes a version to use for the connection
in the first packet of the connection and encodes the rest of the
handshake using the proposed version. If the server does not speak
the client-chosen version, it forces version negotiation by sending
back a Version Negotiation packet to the client carrying all of the
server’s supported versions, causing a round trip of delay before
connection establishment. This mechanism eliminates round-trip
latency when the client’s optimistically-chosen version is spoken
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
A. Langley et al.