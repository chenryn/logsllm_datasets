Figure 8: Number of malicious apps overtime.
Figure 9: The distribution of common code across malware.
and distributed them to the third-party stores in China.
Instead, malware repackaging appears to be quite
localized, mostly between the app stores in the same
region or even on the same store. A possible explanation
could be the effort that malware authors need to make
on the original app so that it works for a new audience,
which is certainly higher than simply repackaging the
popular one in the local markets.
Figure 9 illustrates the distribution of common code
across malware, as discovered from the intersection anal-
ysis. A relatively small set of methods have been reused
by a large number of malicious apps. The leading one
has been utilized by 9,438 Google-Play malware and by
144 suspicious apps in the third-party markets. This
method turns out to be part of the library (“com/star-
tapp”) extensively used by malware. Over 98% of the
apps integrating this library were ﬂagged as malicious
by VirusTotal and the rest were also found to be suspi-
cious through our manual validation. This method sends
users’ ﬁne-grained location information to a suspicious
website. Similarly, all other popular methods are appar-
ently also part of malware-building toolkits. Examples
include “guohead”, “purchasesdk” and “SDKUtils”. The
malware integrating such libraries are signed by thou-
sands of different parties. An observation is that the use
of these malicious SDKs is pretty regional: in Chinese
markets, “purchasesdk” is popular, while “startapp” is
widely used in the US markets. We also noticed that a
number of libraries have been obfuscated. A close look
at these attack SDKs shows that they are used for getting
sensitive information like phone numbers, downloading
ﬁles and loading code dynamically.
Signatures and identities. For each conﬁrmed mali-
cious app, we took a look at its “signature”, that is, the
public key on its X.509 certiﬁcate for verifying the in-
tegrity of the app. Some signatures have been utilized by
more than 1,000 malware each: apparently, some mal-
ware authors have produced a large number of malicious
apps and successfully disseminated them across differ-
ent markets (Table 3). Further, when we checked the
meta data for the malware discovered on Google Play,
we found that a few signatures have been associated with
many identities (e.g., the creator ﬁeld in the meta-
data). Particularly, one signature has been linked to 604
identities, which indicates that the adversary might have
Signature
# of malicious apps
c673c8a5f021a5bdc5c036ee30541dde
a2993eaecf1e3c2bcad4769cb79f1556
3be7d6ee0dca7e8d76ec68cf0ccd3a4a
f8956f66b67be5490ba6ac24b5c26997
86c2331f1d3bb4af2e88f485ca5a4b3d
1644
1258
615
559
469
Table 3: Top 5 signatures used in apps.
created many accounts to distribute his app (Table 4).
Case studies. Among the suspicious apps MassVet re-
ported are a set of APKs not even VirusTotal found to
be malicious. We analyzed 40 samples randomly cho-
sen from this set and concluded that 20 of them were
indeed problematic through manual analysis, likely to be
zero-day malware. We have reported them to 4 malware
companies (F-Secure, Norton, Kaspersky, Trend Micro)
for further validations. The behaviors of these apps in-
clude installing apps without user’s consent, collecting
user’s private data (e.g., take screen shots of other apps)
even though such information does not serve apps’ stated
functionalities, loading and executing native binary for
command and control.
These apps use various techniques to evade detec-
tion. For example, some hide the suspicious function-
ality for weeks before starting to run it. “Durak card
game” is such an game, which has been downloaded over
5,000,000 times. It was on Google Play before BBC re-
ported it on February 4th 2015 [25]. So far, only two
scanners hosted by VirusTotal can detect it. This mal-
ware disguises as warning messages when the user un-
lock her Android smartphone. It waits for several weeks
before performing malicious activities.
Its advertise-
ments also do not show up until at least one reboot. Al-
though Google removes “Durak card game”, other apps
with similar functionalities are still on the Play Store
now. We also found that some malicious apps conceal
their program logic inside native binaries. Some even
encrypt the binaries and dynamically decrypt them for
execution. Further some utilize Java reﬂection and other
obfuscation techniques to cover their malicious code.
Signature
# of different identities
02d98ddfbcd202b13c49330182129e05
a2993eaecf1e3c2bcad4769cb79f1556
82fd3091310ce901a889676eb4531f1e
9187c187a43b469fa1f995833080e7c3
c0520c6e71446f9ebdf8047705b7bda9
Table 4: Top 5 signatures used by different identities.
604
447
321
294
145
USENIX Association  
24th USENIX Security Symposium  671
13
5 Discussion
As discussed before, MassVet aims at repackaging mal-
ware, the mainstay of potentially harmful mobile apps:
this is because malware authors typically cannot afford
to spend a lot of time and money to build a popular app
just for spreading malware, only to be forced to do this
all over again once it gets caught. Our technique ex-
ploits a weakness of their business model, which relies
on repackaging popular apps with a similar attack pay-
load to keep the cost for malware distribution low. With
the fundamentality of the issue and the effectiveness of
the technique on such malware, our current implementa-
tion, however, is still limited, particularly when it comes
to the defense against evasion.
Speciﬁcally, though simply adding the junk views con-
nected to an existing app’s view graph can affect user ex-
perience and therefore may not work well (Section 3.3),
a more effective alternative is to obfuscate the links be-
tween views (calls like StartActivity). However,
this treatment renders an app’s UI structure less clear
to our analyzer, which is highly suspicious, as the vast
majority of apps’ view graphs can be directly extracted.
What we could do is to perform a dynamic analysis on
such an app, using the tools like Monkey to explore the
connections between different views. Note that the over-
all performance impact here can still be limited, simply
because most apps submitted to an app store are legiti-
mate and their UI structures can be statically determined.
Further, to evade the commonality analysis, the ad-
versary could obfuscate the malicious methods. As dis-
cussed earlier (Section 3.3), this attempt itself is nontriv-
ial, as the m-cores of those methods can only be moved
signiﬁcantly away from their original values through
substantial changes to their CFGs each time when a le-
gitimate app is repackaged. This can be done by adding
a large amount of junk code on the CFGs. Our current
implementation does not detect such an attack, since it is
still no there in real-world malware code. On the other
hand, further studies are certainly needed to better under-
stand and mitigate such a threat.
Critical to the success of our DiffCom analysis is re-
moval of legitimate libraries. As an example, we could
utilize a crawler to periodically gather shared libraries
and code templates from the web to update our whitelists.
Further, a set of high-proﬁle legitimate apps can be ana-
lyzed to identify the shared code missed by the crawler.
What can also be leveraged here is a few unique re-
sources in the possession of the app market. For exam-
ple, it knows the account from which the apps are up-
loaded, even though they are signed by different certiﬁ-
cates. It is likely that legitimate organizations are only
maintaining one account and even when they do have
multiple ones, they will not conceal the relations among
them. Using such information, the market can ﬁnd out
whether two apps are actually related to identify the in-
ternal libraries they share. In general, given the fact that
MassVet uses a large number of existing apps (most of
which are legitimate) to vet a small set of submissions, it
is at the right position to identify and remove most if not
all legitimate shared code.
6 Related Work
Malicious app detection. App vetting largely relies on
the techniques for detecting Android malware. Most ex-
isting approaches identify malicious apps either based
upon how they look like (i.e., content-based signa-
ture) [20, 27, 21, 45, 51, 57, 19, 54, 17, 22, 4] or how
they act (behavior-based signature) [11, 31, 48, 47, 42,
18, 34]. Those approaches typically rely on heavyweight
static or dynamic analysis techniques, and cannot detect
the unknown malware whose behavior has not been mod-
eled a priori. MassVet is designed to address these is-
sues by leveraging unique properties of repackaging mal-
ware. Most related to our work is PiggyApp [54], which
utilizes the features (permissions, APIs, etc.) identiﬁed
from a major component shared between two apps to ﬁnd
other apps also including this component, then clusters
the rest part of these apps’ code, called piggybacked pay-
loads, and samples from individual clusters to manually
determine whether the payloads there are indeed mali-
cious. In contrast, MassVet automatically detects mal-
ware through inspecting the code diff among apps with a
similar UI structure and the common methods shared be-
tween those unrelated. When it comes to the scale of our
study, ANDRUBIS [26, 46] dynamically examined the
operations of over 1 million apps in four years. Different
from ANDRUBIS, which is an off-line analyzer for re-
covering detailed behavior of individual malicious apps,
MassVet is meant to be a fast online scanner for iden-
tifying malware without knowing its behavior. It went
through 1.2 million of apps within a short period of time.
Repackaging and code reuse detection. Related to our
work is repackaging and code reuse detection [55, 21,
1, 9, 10, 41, 35, 5]. Most relevant to MassVet is the
Centroids similarity comparison [7], which is also pro-
posed for detecting code reuse. Although it is a building
block for our technique, the approach itself does not de-
tect malicious apps. Signiﬁcant effort was made in our
research to build view-graph and code analysis on top of
it to achieve an accurate malware scan. Also, to defeat
code obfuscation, a recent proposal leverages the simi-
larity between repackaged apps’ UIs to detect their rela-
tions [50]. However, it is too slow, requiring 11 seconds
to process a pair of apps. In our research, we come up
with a more effective UI comparison technique, through
mapping the features of view graphs to their geometric
centers, as Centroids does. This signiﬁcantly improves
the performance of the UI-based approach, enabling it to
672  24th USENIX Security Symposium 
USENIX Association
14
help vet a large number of apps in real time.
7 Conclusion
We present MassVet, an innovative malware detection
technique that compares a submitted app with all other
apps on a market, focusing on its diffs with those hav-
ing a similar UI structure and intersections with others.
Our implementation was used to analyze nearly 1.2 mil-
lion apps, a scale on par with that of Google Play, and
discovered 127,429 malicious apps, with 20 likely to be
zero-day. The approach also achieves a higher coverage
than leading anti-malware products in the market.
Acknowledgement
We thank our shepherd Adam Doup´e and anonymous re-
viewers for their valuable comments. We also thank Dr.
Sencun Zhu and Dr. Fangfang Zhang for sharing their
ViewDroid code, which allows us to understand how
their system works, and VirusTotal for the help in val-
idating over 100,000 apps discovered in our study. IU
authors were supported in part by the NSF 1117106,
1223477 and 1223495. Kai Chen was supported in part
by NSFC 61100226, 61170281 and strategic priority re-
search program of CAS (XDA06030600). Peng Liu was
supported by NSF CCF-1320605 and ARO W911NF-09-
1-0525 (MURI).
References
[1] ANDROGUARD.
goodware analysis of android applications
http://code.google.com/p/androguard/, 2013.
Reverse
engineering, malware
and
... and more.
[2] APPBRAIN. Ad networks - android library statistics — app-
brain.com. http://www.appbrain.com/stats/libraries/ad. (Visited
on 11/11/2014).
[3] APPCELERATOR.
6
steps
to
great mobile
apps.
http://www.appcelerator.com/. 2014.
[4] ARZT, S., RASTHOFER, S., FRITZ, C., BODDEN, E., BARTEL,
A., KLEIN, J., LE TRAON, Y., OCTEAU, D., AND MCDANIEL,
P. Flowdroid: Precise context, ﬂow, ﬁeld, object-sensitive and
lifecycle-aware taint analysis for android apps. In PLDI (2014),
ACM, p. 29.
[5] BAYER, U., COMPARETTI, P. M., HLAUSCHEK, C., KRUEGEL,
C., AND KIRDA, E. Scalable, behavior-based malware cluster-
ing. In NDSS (2009), vol. 9, Citeseer, pp. 8–11.
[6] CHEN, K. A list of shared libraries and ad libraries used in
android apps. http://sites.psu.edu/kaichen/ 2014/02/20/a-list-of-
shared-libraries-and-ad-libraries-used-in-android-apps.
[7] CHEN, K., LIU, P., AND ZHANG, Y. Achieving accuracy and
scalability simultaneously in detecting application clones on an-
droid markets. In ICSE (2014).
2014
[8] CISCO.
report,”.
security
annual
“cisco
http://www.cisco.com/web/offer/gist ty2 asset/
Cisco 2014 ASR.pdf, 2014.
[9] CRUSSELL, J., GIBLER, C., AND CHEN, H. Attack of the
clones: Detecting cloned applications on android markets. ES-
ORICS (2012), 37–54.
[10] CRUSSELL, J., GIBLER, C., AND CHEN, H. Scalable semantics-
In ESORICS
based detection of similar android applications.
(2013).
[11] ENCK, W., GILBERT, P., CHUN, B.-G., COX, L. P., JUNG, J.,
MCDANIEL, P., AND SHETH, A. Taintdroid: An information-
ﬂow tracking system for realtime privacy monitoring on smart-
phones. In OSDI (2010), vol. 10, pp. 1–6.
[12] ENCK, W., OCTEAU, D., MCDANIEL, P., AND CHAUDHURI,
S. A study of android application security. In USENIX security
symposium (2011), vol. 2, p. 2.
[13] ENVATOMARKET.
Android notiﬁcation templates library.
http://codecanyon.net/item/android-notiﬁcation-templates-
library/5292884. 2014.
[14] ERNST, M. D., JUST, R., MILLSTEIN, S., DIETL, W. M.,
PERNSTEINER, S., ROESNER, F., KOSCHER, K., BARROS, P.,
BHORASKAR, R., HAN, S., ET AL. Collaborative veriﬁcation of
information ﬂow for a high-assurance app store.
[15] F-SECURE. F-secure : Internet security for all devices. http://f-
secure.com, 2014.
[16] F-SECURE.
Threat report h2 2013.
Tech. rep., f-secure,
http://www.f-secure.com/documents/996508/1030743/
Threat Report H2 2013.pdf, 2014.
[17] FENG, Y., ANAND, S., DILLIG, I., AND AIKEN, A. Ap-
poscopy: Semantics-based detection of android malware through
static analysis. In SIGSOFT FSE (2014).
[18] GILBERT, P., CHUN, B.-G., COX, L. P., AND JUNG, J. Vi-
sion: automated security validation of mobile apps at app mar-
kets.
In Proceedings of the second international workshop on
Mobile cloud computing and services (2011), ACM, pp. 21–26.
[19] GRACE, M., ZHOU, Y., ZHANG, Q., ZOU, S., AND JIANG,
X. Riskranker: scalable and accurate zero-day android mal-
ware detection. In Proceedings of the 10th international confer-
ence on Mobile systems, applications, and services (2012), ACM,
pp. 281–294.
[20] GRIFFIN, K., SCHNEIDER, S., HU, X., AND CHIUEH, T.-C.
Automatic generation of string signatures for malware detec-
tion. In Recent Advances in Intrusion Detection (2009), Springer,
pp. 101–120.