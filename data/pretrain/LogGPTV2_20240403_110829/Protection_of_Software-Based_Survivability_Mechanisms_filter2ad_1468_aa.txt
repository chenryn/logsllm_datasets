# Title: Protection of Software-Based Survivability Mechanisms

# Authors:
- Chenxi Wang
- Jonathan Hill
- John C. Knight
- Jack W. Davidson

## Affiliations:
- **Chenxi Wang, Jonathan Hill, and John C. Knight**: Department of Computer Science, University of Virginia, {cw2e, jch8f, knight}@cs.virginia.edu
- **Jack W. Davidson**: Microsoft Research, Redmond, WA, jwd@microsoft.com

## Abstract
Many existing survivability mechanisms rely on software-based system monitoring and control. Some of this software is deployed on application hosts that may not be entirely trustworthy. The integrity of these software components is crucial for the reliability and trustworthiness of the survivability scheme. This paper addresses the problem of protecting trusted software on untrustworthy hosts through software transformations. Our techniques include systematically introducing aliases in combination with a "break-down" of the program control flow, transforming high-level control transfers to indirect addressing through aliased pointers. These transformations make it difficult to extract precise data flow information from the transformed program. We present a theoretical result showing that, in the general case, a precise analysis of the transformed program is NP-hard. We also provide empirical results to demonstrate the effectiveness of our techniques.

## 1. Introduction
In building survivable systems, many existing mechanisms [5, 9] rely on software-based network monitoring and management. Since some of the software components for the survivability mechanism will execute on hosts that are not necessarily trusted, the reliability and trustworthiness of the survivability mechanism are of significant concern.

This paper addresses the problem of software protection in a potentially malicious environment, focusing on a survivable distributed system [9]. In this system, software probes are deployed on network nodes for monitoring and control purposes. These probes are dispatched from a set of trusted servers. Each probe may employ different algorithms for monitoring local information and communicating with the servers. To defeat this network-wide monitoring mechanism and gain control of the network, an adversary must deduce either the algorithm the probe uses for monitoring or the protocol with which the probe communicates with the server. Both of these attacks require some level of understanding of the program behavior, which can be obtained through program analysis.

This paper focuses on one important aspect of software protection: the prevention of static analysis of programs.

Static program analysis can reveal a great deal of information about the program, such as the control flow and possible uses of data at runtime [11]. This information can facilitate dynamic analysis and, in some cases, aid in direct tampering with the program. In this paper, we introduce a compiler-based approach to harden software against static analysis. Our approach consists of a set of code transformations designed to obstruct static analysis. The key difference between our approach and previously proposed code-obfuscation techniques [4, 5, 7] is that our techniques are supported by both theoretical and empirical complexity measures. Without these measures, code-obfuscation techniques are, at best, ad hoc.

The problem of software protection has been investigated in other studies, including Intel's IVK project [2], Collberg’s code obfuscation work [4, 5], and mobile cryptography [20]. The IVK work introduced the concept of Tamper-Resistant Software but came with the cost of considerable runtime overhead. The mobile cryptography study proposed executing programs in an encrypted form, but this technique has limited applicability (e.g., rational functions).

The approach described in this paper is based on well-understood programming language principles, which serve as the basis for the complexity measures. The structure of the paper is as follows: Section 2 presents the system model and assumptions. Section 3 describes the basics of static analysis. Sections 4 and 5 detail the transformations to hinder control-flow and data-flow analysis. Section 6 discusses the theoretical and practical foundations of the proposed scheme. Section 7 presents our implementation and experimental results.

## 2. The System Model
In this section, we describe the assumptions and the system model to set the context for discussion. Our system consists of a set of computing hosts connected via a network and a set of communicating processes running on these hosts. The hosts are divided into two categories: application hosts and survivability control hosts. The processes relevant to the survivability control mission are the control processes running on the control hosts and the probe programs running on the application hosts. The probes are responsible for local monitoring and reconfiguration. The control processes collect monitoring information from the probes, conduct network-wide analysis, and issue reconfiguration commands if real-time changes are necessary. An overview of the system architecture is depicted in Figure 1.

### Key Characteristics and Assumptions:
- **Trusted Control Servers:** The control servers and the control processes running on them are presumed trusted.
- **Trusted Network Communications:** We assume the network communications between the control processes and the software probes are trusted.
- **Diversity in the Probing Mechanism:** The probing mechanism uses temporal diversity (periodic replacement of probes) and spatial diversity (installation of different versions of probes across the network). Each version of the probes may use a different probing algorithm, communication protocol, and operational semantics [21]. This diversity makes it essential for an adversary to learn the program algorithm to launch an intelligent tampering or impersonation attack.
- **High Level of Interactions Between Probes and Control Processes:** The probes maintain a high level of interaction with their control servers via predetermined protocols. The probes perform integrity checks, whose results are verified by the control servers. The checking mechanisms are installation-unique, and the integrity checks establish the probe’s identity and authenticity.

### Types of Attacks:
- **Intelligent Tampering:** This refers to scenarios where an adversary modifies the program or data in a way that allows the program to continue operating in a seemingly unaffected manner (from the trusted server’s point of view), but on corrupted state or data.
- **Impersonation:** This attack involves establishing a rogue version of the legitimate program. Unlike intelligent tampering, impersonation aims to modify the program or its data directly.

Denial-of-execution attacks are not considered here because they produce straightforward symptoms that can be readily identified by the trusted server. Intelligent tampering or impersonation attacks, however, may not be immediately obvious and can inflict substantial harm by manipulating the program to perform seemingly valid but malicious tasks.

With the diversity scheme and integrity checks in place, a successful intelligent tampering or impersonation attack requires knowledge about the probe algorithm and communication protocol to bypass or defeat the checking mechanism. This, in turn, requires information about the program semantics, which we aim to protect. For example, consider the following code segment:

```c
int a = function1();
int b = function2();
Check-for-intrusion(&a, &b);
p = &a;
integrity-check(p);
```

If an adversary were to tamper with the `Check-for-intrusion()` function, they would need to understand how this function changes the values of `a` and `b` and whether `a` or `b` will be used later in the program. Without this knowledge, their actions could be revealed when `integrity-check(p)` is called.

Our premise is that an adversary aiming to tamper with or impersonate the program in an intelligent way must understand the effect of their actions, which boils down to an understanding of the program semantics. One way this understanding can be acquired is through program analysis. This paper deals with the obstruction of program analysis, particularly static analysis of programs. Our approach consists of a framework of code transformations designed to increase the difficulty of static program analysis, which is described in the remaining sections.

## 3. Static Analysis of Programs
Static analysis refers to techniques designed to extract information from a static image of a computer program. Static analysis is often more efficient than dynamic analyses, such as simulated execution.

From a software-protection perspective, static analysis can yield useful information for targeted manipulation of software. Consider again the code example in the last section. A use-def analysis [11] of the code segment would quickly reveal that a possible definition of the data quantity `a` in the `Check-for-intrusion()` function will be propagated to its alias `p` in the `integrity-check(p)` function. Based on this knowledge, an adversary could perform specific modifications to `Check-for-intrusion()` so long as they leave the semantics of `a` intact for its later use.