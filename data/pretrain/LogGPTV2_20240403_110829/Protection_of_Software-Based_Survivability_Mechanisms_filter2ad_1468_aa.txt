title:Protection of Software-Based Survivability Mechanisms
author:Chenxi Wang and
Jonathan Hill and
John C. Knight and
Jack W. Davidson
Protection of Software-based Survivability Mechanisms 
Chenxi Wang, Jack Davidson *, Jonathan Hill, John Knight 
Department of Computer Science 
University of Virginia 
{ cw2e I jch8f I knight} @cs.virginia.edu 
Microsoft Research* 
Redmond, WA 
jwd @microsoft.com 
Abstract 
Many  existing  survivability mechanisms  rely  on sofi- 
ware-based  system  monitoring  and  control.  Some  of  the 
software resides on application hosts that are not necessar- 
ily trustworthy.  The integrity of  these software  components 
is therefore  essential to the  reliability  and  trustworthiness 
of  the  survivability  scheme.  In  this paper  we  address the 
problem  of  protecting  trusted  software  on  untrustworthy 
hosts by software  transformations. Our techniques include 
U  systematic  introduction  of aliases  in combination with a 
“break-down ” of  the program  control-jlow; transforming 
high-level control  transfers to indirect  addressing  through 
aliased pointers.  In so doing, we  transform programs to a 
form that yields data jlow information very  slowly and/or 
with  little precision.  We present a  theoretical  result  which 
shows  that a precise  analysis of the  transformed program, 
in the general case, is NP-hard and demonstrate the appli- 
cabilip of our techniques with empirical results. 
1.  Introduction 
In  building  survivable systems, many  existing mecha- 
nisms [S, 91 rely on software-based network monitoring and 
management.  Because  some  of  the  software components 
for the  survivability  mechanism will  execute on  hosts  that 
are  not  necessarily  trusted,  the  reliability  and  trustworthi- 
ness of the survivability mechanism is, therefore,  of a great 
concern. 
In this paper, we address the problem  of software pro- 
tection  in  a  potentially  malicious environment.  We  study 
this problem  within  the context of  a survivable distributed 
system  [9]. In  this  system,  software  probes  are  deployed 
onto network  nodes  for  monitoring  and  control  purposes. 
These probes  are dispatched from a set  of  trusted  servers. 
Each  probe  may  employ  different  algorithms for  monitor- 
ing local information  and for communication with the serv- 
ers. For  instance,  different probes might  use  different  data 
sequences, transmit  with  a  different  protocol,  or  monitor 
different information. To defeat this network-wide monitor- 
ing  mechanism, and  thereby  obtaining control  of  the  net- 
work, an  adversary  must  deduce  either the  algorithm that 
the probe uses when monitoring  or the protocol  with which 
the  probe  communicates  with  the  server.  Each  of  these 
attacks requires some level of understanding of the program 
behavior, which can be obtained through program analysis. 
This paper addresses one important aspect of software pro- 
tection-prevention 
of static analysis of programs, 
Static program analysis can reveal a great deal of infor- 
mation about the program such as the control flow and pos- 
sible  uses  of  data  quantities  at  run-time  [ll].  This 
information  can  be  used  to  facilitate dynamic analysis of 
the  program, and  in  some cases, aid  direct tampering  with 
the program.  In  this  paper,  we introduce a compiler-based 
approach  to  harden  software  against. static  analysis.  The 
basic approach consists of  a set of code transformations that 
are designed to obstruct static analysis. The key difference 
between our approach and previously  proposed  code-obfus- 
cation  techniques  [4,  5, 71 is  that  our  techniques  are sup- 
ported  by  both 
theoretical  and  empirical  complexity 
measures. Without the complexity measures, code-obfusca- 
tion techniques are at best ad hoc. 
The problem  of  software protection has been  investi- 
gated  in  other studies.  The  notable  ones  include INTEL‘S 
IVK  project  [2], Collburg’s  code  obfuscation  work  [4, 51 
and  mobile cryptography  [20]. The IVK  work  coined  the 
phrase  Tamper  Resistant  Sopware.  Their  technique  was 
novel but came with the price of considerable run-time cost. 
The  mobile  cryptography  study  proposed  a  technique  to 
execute programs in an encrypted form. In its present  form, 
the technique has  limited  applicability  (e.g.,  rational  func- 
tions). 
The  approach  described  in  this  paper  is  developed 
based  on  well-understood  programming  language  princi- 
ples, which  serve as the basis for the complexity measures. 
We structure the paper as follows: In section  2, we present 
the  system model  and  assumptions on  which  this  work  is 
based. Section 3 describes the basics of static analysis. Sec- 
tions 4 and 5 present  the transformations to hinder control- 
flow and  data-flow analysis.  Sections 6 discusses theoreti- 
cal and practical  foundations of the proposed  scheme. Sec- 
tions  7  presents  our  implementation  and  experimental 
results. 
0-7695-1101-5/01 $10.00 0 2001 IEEE 
193 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:00:07 UTC from IEEE Xplore.  Restrictions apply. 
2.  The system model 
In  this  section  we  describe  the  assumptions  and  the 
system model to set the context for discussion. Our system 
consists  of  a  set  of  computing  hosts  connected  via  a  net- 
work  and  a  set  of  communicating  processes  running  on 
these  hosts.  The  hosts  are  divided  into  two  categories: 
application  hosts  and  survivability  control  hosts.  The pro- 
cesses relevant  to the  survivability  control  mission  are the 
control  processes  running  on  the  control  hosts  and  the 
probe  programs  running  on  the  application  hosts.  The 
probes are responsible for  local monitoring and reconfigu- 
ration.  The  control  processes  collect  monitoring  informa- 
tion  from the  probes,  conduct  network-wide analysis, and 
issue  reconfiguration commands to  the probes  if  real-time 
changes are deemed necessary. An  overview of the system 
architecture is depicted in Figure  1. 
Several characteristics and assumptions about the  sys- 
tem are important for the discussion. They are listed below: 
Trusted control servers: In  our  system,  the  control 
servers and the control processes running on top of them are 
presumed trusted. 
Trusted network communications: We assume the 
network communications between the control processes and 
the software probes are trusted. 
Diversity in the probing mechanism: In this system, 
the probing mechanism makes use of two forms of diversity 
that are essential  to the approach detailed  in later sections. 
They are temporal diversity and spatial diversity. Temporal 
diversity takes the form of periodic replacement of the probes 
with  a  new  version  dispatched  from  the  trusted  control 
servers. Spatial diversity refers to the installation of different 
versions  of  probes  across the network. Each version  of the 
probes  may  use  a  different  probing  algorithm,  a different 
protocol  to communicate with  the control server, and may 
appear to  have a different  operational semantics  [21]. The 
use  of diversity  here  makes it essential  for an adversary  to 
Applic 
b e  A) 
Application  Host  €3 
/ 
(probe  E) 
Application  Network 
Application  Network 
01 
01 
Control  Servers 
Figure 1 : A controlled network 
learn the program algorithm in order to launch an intelligent 
tampering or impersonation attack. 
High level of interactions between the probes and the 
control processes: While executing  on a remote  host,  the 
probes maintain  a high  level of  interaction  with  its control 
server  via  predetermined  protocols.  It  is assumed that  the 
probes perform  integrity  checks whose results  are  verified 
by  the  control  servers. The checking  mechanisms are also 
installation-unique  in that each probe program may employ 
a set of different  checks.  It  is  not  the task  of  this paper  to 
devise the checking mechanisms. It suffices to state that the 
integrity checks may be performed on the software itself as 
well as its executing environment. The result of the integrity 
checks  establishes  the  basis  of  the  probe’s  identity  and 
authenticity. 
In  this  work, we are primarily  interested in defending 
against  sophisticated attacks that fall under the category of 
intelligent tampering and impersonation attacks. 
Intelligent Tampering. Intelligent tampering  refers to 
scenarios in which an adversary modifies the program or data 
in some specific way that allows the program to continue to 
operate in a seemingly unaffected manner (from the trusted 
server’s point of view), but on corrupted state or data. 
Impersonation. An  impersonation  attack  is similar to 
intelligent tampering in that the attacker seeks to establish a 
rogue version of the legitimate program. The difference lies 
in  that  the  former  attempts  to emulate  the  behavior of  the 
original program, while the latter aims to modify the program 
or its data directly. 
It should  be noted  that  denial-of-execution attacks are 
not considered here. In this problem context, denial-of-exe- 
cution  produces  straightforward  symptoms  that  can  be 
readily identified by the trusted  server (e.g. loss of commu- 
nication). Unlike denial-of-execution, an intelligent tamper- 
ing  or  impersonation  attack  may  not  be  immediately 
obvious; if the attacker has detailed knowledge of what  the 
software is supposed to do and the appropriate privilege  to 
instantiate a malicious copy, he can replace the original pro- 
gram  and  make  the  replacement  virtually  undetectable. 
Such attacks therefore have the potential  to inflict substan- 
tial  harm-the 
adversary  could  manipulate  the  program to 
perform seemingly valid but malicious tasks. 
With  the diversity  scheme and  the  integrity  checks in 
store,  a  successful  intelligent  tampering  or  impersonation 
attack  requires  knowledge  about  the  probe  algorithm  and 
the communication protocol in order to bypass or defeat the 
checking  mechanism.  This  in  turn  requires  information 
about the program  semantics, and it is this information that 
we endeavor to protect.  For example, consider  the follow- 
ing code segment: 
194 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:00:07 UTC from IEEE Xplore.  Restrictions apply. 
int a =  functionl( ) ;  
int b =  function2( ) ;  
Check-for-intrusion(&a,  &b); 
p  =  &a; 
integrity-check(p); 
adversary  were 
an 
If 
to 
tamper  with 
the 
Checkfbr-intrusion()  function,  he  or she needs to  under- 
stand  whether and how  the  Checkfbr-intrusion() function 
changes the  values  of a and b, and whether a or b will  be 
used  later  in  the  program.  Without  this  knowledge,  his 
action can be revealed  when integrit)l-check(p)  is called. 
Our premise is that an adversary aiming to tamper with 
or  impersonate  the  program  in  an  intelligent  way  must 
understand  the effect of his action, and this boils down to an 
understanding  of  the  program  semantics.  One  way  this 
understanding can be acquired is through program analysis. 
This paper  deals with  obstruction  of  program  analysis, in 
particular,  static  analysis  of  programs.  Our approach con- 
sists of  a  framework of  code  transformations designed to 
increase the difficulty of static program analysis, and that is 
described in the remaining sections. 
3.  Static analysis of programs 
Static analysis refers  to techniques designed to extract 
information  from  a  static  image  of  a  computer  program. 
Static  analysis  is  often  more  efficient  than  analyses  per- 
formed dynamically such as simulated execution. 
From the software-protection  point of view, static anal- 
ysis could  yield  useful  information  for targeted  manipula- 
tion  of  software. Consider again  the  code example in  the 
last  section. A  use-def analysis  [ I l l  of  the  code  segment 
would  quickly  reveal that  a possible  definition of  the  data 
quantity a in function  Checkjor-intrusion() will be propa- 
gated 
function 
integrity_check().  Based  on  this  knowledge,  an  adversary 
could 
to 
Checkfbr-intrusion()  so long as he leaves the semantics of 
a intact for its later use. 
specific  modification 
its  alias  p )   in 
to  a  use 
(through 
perform 