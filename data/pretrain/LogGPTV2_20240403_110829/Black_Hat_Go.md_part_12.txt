when no API exists. Rather than rehashing what you already
know, we’ll take this as an opportunity to introduce a new
method of extracting data. You’ll use an excellent package,
goquery, which mimics the functionality of jQuery, a JavaScript
library that includes an intuitive syntax to traverse HTML
documents and select data within. Start by installing goquery:
$ go get github.com/PuerkitoBio/goquery
Fortunately, that’s the only prerequisite software needed to
complete the development. You’ll use standard Go packages
to interact with Open XML files. These files, despite their file
type suffix, are ZIP archives that, when extracted, contain
XML files. The metadata is stored in two files within the
docProps directory of the archive:
$ unzip test.xlsx
$ tree
--snip--
|---docProps
| |---app.xml
| |---core.xml
--snip—
The core.xml file contains the author information as well as
modification details. It’s structured as follows:
Dan Kottmann❶
Dan Kottmann❷
2016-12-06T18:24:42Z
2016-12-06T18:25:32Z
The creator ❶ and lastModifiedBy ❷ elements are of primary
interest. These fields contain employee or usernames that you
can use in a social-engineering or password-guessing
campaign.
The app.xml file contains details about the application type
and version used to create the Open XML document. Here’s
its structure:
Microsoft Excel❶
0
false
Worksheets
1
Sheet1
ACME❷
false
false
false
15.0300❸
You’re primarily interested in just a few of those elements:
Application ❶, Company ❷, and AppVersion ❸. The version itself
doesn’t obviously correlate to the Office version name, such as
Office 2013, Office 2016, and so on, but a logical mapping
does exist between that field and the more readable,
commonly known alternative. The code you develop will
maintain this mapping.
Defining the metadata Package
In Listing 3-20, define the Go types that correspond to these
XML datasets in a new package named metadata and put the
code in a file named openxml.go—one type for each XML file
you wish to parse. Then add a data mapping and convenience
function for determining the recognizable Office version that
corresponds to the AppVersion.
type OfficeCoreProperty struct {
XMLName xml.Name `xml:"coreProperties"`
Creator string `xml:"creator"`
LastModifiedBy string `xml:"lastModifiedBy"`
}
type OfficeAppProperty struct {
XMLName xml.Name `xml:"Properties"`
Application string `xml:"Application"`
Company string `xml:"Company"`
Version string `xml:"AppVersion"`
}
var OfficeVersions❶ = map[string]string{
"16": "2016",
"15": "2013",
"14": "2010",
"12": "2007",
"11": "2003",
}
func (a *OfficeAppProperty) GetMajorVersion()❷ string {
tokens := strings.Split(a.Version, ".")❸
if len(tokens) < 2 {
return "Unknown"
}
v, ok := OfficeVersions❹ [tokens[0]]
if !ok {
return "Unknown"
}
return v
}
Listing 3-20: Open XML type definition and version mapping (/ch-3/bing-
metadata/metadata/openxml.go)
After you define the OfficeCoreProperty and OfficeAppProperty
types, define a map, OfficeVersions, that maintains a relationship
of major version numbers to recognizable release years ❶. To
use this map, define a method, GetMajorVersion(), on the
OfficeAppProperty type ❷. The method splits the XML data’s
AppVersion value to retrieve the major version number ❸,
subsequently using that value and the OfficeVersions map to
retrieve the release year ❹.
Mapping the Data to Structs
Now that you’ve built the logic and types to work with and
inspect the XML data of interest, you can create the code that
reads the appropriate files and assigns the contents to your
structs. To do this, define NewProperties() and process() functions,
as shown in Listing 3-21.
func NewProperties(r *zip.Reader) (*OfficeCoreProperty, *OfficeAppProperty,
error) {❶
var coreProps OfficeCoreProperty
var appProps OfficeAppProperty
for _, f := range r.File {❷
switch f.Name {❸
case "docProps/core.xml":
if err := process(f, &coreProps)❹; err != nil {
return nil, nil, err
}
case "docProps/app.xml":
if err := process(f, &appProps)❺; err != nil {
return nil, nil, err
}
default:
continue
}
}
return &coreProps, &appProps, nil
}
func process(f *zip.File, prop interface{}) error {❻
rc, err := f.Open()
if err != nil {
return err
}
defer rc.Close()
if err := ❼xml.NewDecoder(rc).Decode(&prop); err != nil {
return err
}
return nil
}
Listing 3-21: Processing Open XML archives and embedded XML documents (/ch-
3/bing-metadata/metadata/openxml.go)
The NewProperties() function accepts a *zip.Reader, which
represents an io.Reader for ZIP archives ❶. Using the zip.Reader
instance, iterate through all the files in the archive ❷,
checking the filenames ❸. If a filename matches one of the
two property filenames, call the process() function ❹❺, passing
in the file and the arbitrary structure type you wish to populate
—either OfficeCoreProperty or OfficeAppProperty.
The process() function accepts two parameters: a *zip.File and
an interface{} ❻. Similar to the Metasploit tool you developed,
this code accepts a generic interface{} type to allow for the file
contents to be assigned into any data type. This increases code
reuse because there’s nothing type-specific within the process()
function. Within the function, the code reads the contents of
the file and unmarshals the XML data into the struct ❼.
Searching and Receiving Files with Bing
You now have all the code necessary to open, read, parse, and
extract Office Open XML documents, and you know what you
need to do with the file. Now, you need to figure out how to
search for and retrieve files by using Bing. Here’s the plan of
action you should follow:
1. Submit a search request to Bing with proper filters to retrieve targeted results.
2. Scrape the HTML response, extracting the HREF (link) data to obtain direct
URLs for documents.
3. Submit an HTTP request for each direct document URL
4. Parse the response body to create a zip.Reader
5. Pass the zip.Reader into the code you already developed to extract metadata.
The following sections discuss each of these steps in order.
The first order of business is to build a search query
template. Much like Google, Bing contains advanced query
parameters that you can use to filter search results on
numerous variables. Most of these filters are submitted in a
filter_type: value format. Without explaining all the available filter
types, let’s instead focus on what helps you achieve your goal.
The following list contains the three filters you’ll need. Note
that you could use additional filters, but at the time of this
writing, they behave somewhat unpredictably.
site Used to filter the results to a specific domain
filetype Used to filter the results based off resource file type
instreamset Used to filter the results to include only certain
file extensions
An example query to retrieve docx files from nytimes.com
would look like this:
site:nytimes.com && filetype:docx && instreamset:(url title):docx
After submitting that query, take a peek at the resulting
URL in your browser. It should resemble Figure 3-1.
Additional parameters may appear after this, but they’re
inconsequential for this example, so you can ignore them.
Now that you know the URL and parameter format, you
can see the HTML response, but first you need to determine
where in the Document Object Model (DOM) the document
links reside. You can do this by viewing the source code
directly, or limit the guesswork and just use your browser’s
developer tools. The following image shows the full HTML
element path to the desired HREF. You can use the element
inspector, as in Figure 3-1, to quickly select the link to reveal
its full path.
Figure 3-1: A browser developer tool showing the full element path
With that path information, you can use goquery to
systematically pull all data elements that match an HTML
path. Enough talk! Listing 3-22 puts it all together: retrieving,
scraping, parsing, and extracting. Save this code to main.go.
❶ func handler(i int, s *goquery.Selection) {
url, ok := s.Find("a").Attr("href")❷
if !ok {
return
}
fmt.Printf("%d: %s\n", i, url)
res, err := http.Get(url)❸
if err != nil {
return
}
buf, err := ioutil.ReadAll(res.Body)❹
if err != nil {
return
}
defer res.Body.Close()
r, err := zip.NewReader(bytes.NewReader(buf)❺, int64(len(buf)))
if err != nil {
return
}
cp, ap, err := metadata.NewProperties(r)❻
if err != nil {
return
}
log.Printf(
"%25s %25s - %s %s\n",
cp.Creator,
cp.LastModifiedBy,
ap.Application,
ap.GetMajorVersion())
}
func main() {
if len(os.Args) != 3 {
log.Fatalln("Missing required argument. Usage: main.go domain ext")
}
domain := os.Args[1]
filetype := os.Args[2]
❼ q := fmt.Sprintf(
"site:%s && filetype:%s && instreamset:(url title):%s",
domain,
filetype,
filetype)
❽ search := fmt.Sprintf("http://www.bing.com/search?q=%s",
url.QueryEscape(q))
doc, err := goquery.NewDocument(search)❾
if err != nil {
log.Panicln(err)
}
s := "html body div#b_content ol#b_results li.b_algo div.b_title h2"
❿ doc.Find(s).Each(handler)
}
Listing 3-22: Scraping Bing results and parsing document metadata (/ch-3/bing-
metadata/client/main.go)
You create two functions. The first, handler(), accepts a
goquery.Selection instance ❶ (in this case, it will be populated
with an anchor HTML element) and finds and extracts the href
attribute ❷. This attribute contains a direct link to the
document returned from the Bing search. Using that URL, the
code then issues a GET request to retrieve the document ❸.
Assuming no errors occur, you then read the response body
❹, leveraging it to create a zip.Reader ❺. Recall that the
function you created earlier in your metadata package,
NewProperties(), expects a zip.Reader. Now that you have the
appropriate data type, pass it to that function ❻, and
properties are populated from the file and printed to your
screen.
The main() function bootstraps and controls the whole
process; you pass it the domain and file type as command line
arguments. The function then uses this input data to build the
Bing query with the appropriate filters ❼. The filter string is
encoded and used to build the full Bing search URL ❽. The
search request is sent using the goquery.NewDocument() function,
which implicitly makes an HTTP GET request and returns a
goquery-friendly representation of the HTML response
document ❾. This document can be inspected with goquery.
Finally, use the HTML element selector string you identified
with your browser developer tools to find and iterate over
matching HTML elements ❿. For each matching element, a
call is made to your handler() function.
A sample run of the code produces output similar to the
following:
$ go run main.go nytimes.com docx
0:
http://graphics8.nytimes.com/packages/pdf/2012NAIHSAnnualHIVReport041713.docx
2020/12/21 11:53:50 Jonathan V. Iralu Dan Frosch - Microsoft Macintosh
Word 2010
1: http://www.nytimes.com/packages/pdf/business/Announcement.docx
2020/12/21 11:53:51 agouser agouser - Microsoft Office Outlook 2007
2: http://www.nytimes.com/packages/pdf/business/DOCXIndictment.docx
2020/12/21 11:53:51 AGO Gonder, Nanci - Microsoft Office Word
2007
3: http://www.nytimes.com/packages/pdf/business/BrownIndictment.docx
2020/12/21 11:53:51 AGO Gonder, Nanci - Microsoft Office Word
2007
4: http://graphics8.nytimes.com/packages/pdf/health/Introduction.docx
2020/12/21 11:53:51 Oberg, Amanda M Karen Barrow - Microsoft
Macintosh Word 2010
You can now search for and extract document metadata for
all Open XML files while targeting a specific domain. I
encourage you to expand on this example to include logic to
navigate multipage Bing search results, to include other file
types beyond Open XML, and to enhance the code to
concurrently download the identified files.
SUMMARY
This chapter introduced to you fundamental HTTP concepts in
Go, which you used to create usable tools that interacted with
remote APIs, as well as to scrape arbitrary HTML data. In the
next chapter, you’ll continue with the HTTP theme by learning
to create servers rather than clients.
4
HTTP SERVERS, ROUTING, AND
MIDDLEWARE
If you know how to write HTTP servers from scratch, you can
create customized logic for social engineering, command-and-
control (C2) transports, or APIs and frontends for your own
tools, among other things. Luckily, Go has a brilliant standard
package—net/http—for building HTTP servers; it’s really all
you need to effectively write not only simple servers, but also
complex, full-featured web applications.
In addition to the standard package, you can leverage third-
party packages to speed up development and remove some of
the tedious processes, such as pattern matching. These
packages will assist you with routing, building middleware,
validating requests, and other tasks.
In this chapter, you’ll first explore many of the techniques
needed to build HTTP servers using simple applications. Then
you’ll deploy these techniques to create two social engineering
applications—a credential-harvesting server and a keylogging
server—and multiplex C2 channels.
HTTP SERVER BASICS
In this section, you’ll explore the net/http package and useful
third-party packages by building simple servers, routers, and
middleware. We’ll expand on these basics to cover more
nefarious examples later in the chapter.
Building a Simple Server
The code in Listing 4-1 starts a server that handles requests to
a single path. (All the code listings at the root location of /
exist under the provided github repo
https://github.com/blackhat-go/bhg/.) The server should locate
the name URL parameter containing a user’s name and respond
with a customized greeting.
package main
import (
"fmt"
"net/http"
)
func hello(w http.ResponseWriter, r *http.Request) {
fmt.Fprintf(w, "Hello %s\n", r.URL.Query().Get("name"))
}
func main() {
❶ http.HandleFunc("/hello", hello)
❷ http.ListenAndServe(":8000", nil)
}
Listing 4-1: A Hello World server (/ch-4/hello_world/main.go)
This simple example exposes a resource at /hello. The
resource grabs the parameter and echoes its value back to the
client. Within the main() function, http.HandleFunc() ❶ takes two
arguments: a string, which is a URL path pattern you’re
instructing your server to look for, and a function, which will
actually handle the request. You could provide the function
definition as an anonymous inline function, if you want. In this
example, you pass in the function named hello() that you