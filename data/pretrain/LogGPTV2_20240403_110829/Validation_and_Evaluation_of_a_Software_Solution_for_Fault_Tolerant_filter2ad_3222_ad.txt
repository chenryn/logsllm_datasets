T
ds2|tkfailed
  2π
Figure 7. The model for checking synchro-
nization
Figure 8. The modiﬁed DS model
The set built by PROD contains 15 markings and it was
automatically named %4. If we now build the intersection
among %4 and the livelock set (named %%0 by a previous
PRODquery), with:
0#build %%0 & %4
we get an empty set: none of the markings of the live-
lock has the table entries all set to NR. A posteriori this
is not surprising, indeed after the ﬁrst synchronization takes
place there is always a level for each task that is equal to
LR (to memorize the last level on which the task has syn-
chronized). This behaviour has been approved by the DS
designers, and therefore we have not modiﬁed the initial
marking.
On the ﬁnal closed model we have performed our exper-
iments, and we report here only an example of study of the
size of the reachability graph and of a performance index.
Table 1 reports the number of vanishing and tangible
markings for various values of tasks and levels. The ﬁrst
two columns are the ordinary marking, while the last two
columns are the symbolic markings, obtained using the
symbolic reachability graph solver of GreatSPN. The size
of the Markov chain to be solved is given by the number
of tangible symbolic markings, and it can be seen that the
saving can be quite signiﬁcant.
As an example of a performance index we have consid-
ered the mean waiting time of tasks in place tk5, where the
tasks wait for a message of reached synchronization. The
diagram of Figure 9 plots two curves of the mean waiting
time in front of a synchronization barrier for a number of
tasks of 2 and 3, all with 2 levels, with the rate of the timed
transition “working” on the x-axis: as expected the waiting
times are larger for the three tasks case, and the faster the
task activity the smaller is the waiting time. The two curves
have been obtained analytically, while for number of tasks
larger than 4 simulation is the only possibility. The dia-
gram of Figure 10 plots instead a similar situation of tasks
and levels, but under the hypothesis that no fault can hap-
pen. By comparing the two diagrams it appears that the
tasks
levels
RG
SRG
TM
4
5
22
73
130
6
1133
307
15636
754
7
15841
1451
VM TM
4
4
13
24
34
4
127
43
567
75
4
527
74
38
98
339
2370
2390
202
45510
15580
898510
15317
388
686454
99390
VM
38
54
178
630
534
63
4217
1608
28354
1254
72
19849
3435
1
2
1
2
1
3
2
3
3
1
4
2
4
1
1
2
2
3
1
3
2
3
4
1
4
2
Table 1. Ordinary and Symbolic Reachability
Graphs.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:16:05 UTC from IEEE Xplore.  Restrictions apply. 
presence of faults decreases the waiting time, which may
appear counter-intuitive, but it is perfectly right, since the
DS mechanisms does not block, waiting for failed tasks,
while trying to reach a global synchronization.
Mean waiting time to synchronize: fault case
Tk3Lv2
Tk2Lv2
12
10
8
6
4
2
0
0.2
0.4
0.6
0.8
1
working rate of tk1 (1/ms)
Figure 9. Performance measure for the DS
Mean waiting time to synchronize: absence of faults
Tk3Lv2
Tk2Lv2
14
12
10
8
6
4
2
0
0.2
0.4
0.6
0.8
1
working rate of tk1 (1/ms)
Figure 10. Performance measure for the DS
6 Conclusion
In this paper we have presented the validation and evalu-
ation process for a software solution to distributed synchro-
nization. We have a long list of items that deserve more
attention in the future, and of things that we have learned
from this case study.
The ﬁrst observation is that for the analysis from the
early stages of the design to be effective it should be fast and
not be perceived as a non useful add-on to the project (eval-
uation from the early stages encounters similar problems as
formal speciﬁcation of systems), and that for a model to
be correct it is essential that the speciﬁcation comes with
“properties” to be proved, since the fact that a model has
an ergodic behaviour is obviously not enough to tell that its
behaviour is correct. If (reasonably formal and complete)
speciﬁcations are not available, then it may be better to limit
the study to the macro behaviour of the system (point 3 of
the introduction list).
To be fast enough for the results to be useful, the avail-
ability of compositional facilities and of an experiment
planner is a necessity.
Symmetries in the model should be exploited also in the
analysis: indeed the case of the four livelocks that are in-
stances of the same problem that we have encountered in
the case study could have been better tackled if a single
parametrized livelock was reported.
Large models can be very tricky, and although the ob-
vious answer is that they can be solved using simulation,
still there is a need to show that the model used for the sim-
ulation is adherent with reality. Model checkers are well
known to validate systems with billions of states using very
efﬁcient solution methods, but our experience with PROD
showed that no efﬁcient and tricky solution methods could
be used due to the presence of priorities over transitions.
We have not yet investigated other model checkers, but we
shall do it in the near future since, if on one side PROD has
the big advantage of allowing properties to be expressed as
net elements, on the other side it is not very user-friendly.
In particular we found it quite difﬁcult to specify properties,
both conceptually (choosing the “good property” is not an
easy tasks for performance engeneers) and syntactically.
The model that we have built has basically no time as-
sociated to the synchronization mechanism. If timed transi-
tions are introduced in the check activity or in sending and
receiving of messages through the mailboxes then the num-
ber of states increases very signiﬁcantly: a phenomenon that
we still do not master completely.
As a ﬁnal comment let us draw your attention on the
problem of modelling failure:
in the model we have as-
sumed that tasks can fail only when they are in the work-
ing state, but what happens if instead they can fail in any
state, for example while waiting for a synchronization? The
model can change signiﬁcantly and the number of states can
increase accordingly.
References
[1] M. Ajmone Marsan, G. Balbo, G. Conte, S. Donatelli, and
G. Franceschinis. Modelling with Generalized Stochastic
Petri Nets. J. Wiley, 1995.
[2] S. Balsamo and M. Simeoni. On transforming UML mod-
els into performance models. In ETAPS01 Satellite Event,
Genova (ITALY) April,2001.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:16:05 UTC from IEEE Xplore.  Restrictions apply. 
[12] G. Chiola, C. Dutheillet, G. Franceschinis, and S. Haddad.
On Well-Formed coloured nets and their symbolic reacha-
bility graph.
In Proc. 11th Intern. Conference on Appli-
cation and Theory of Petri Nets, Paris, France, June 1990.
Reprinted in High-Level Petri Nets. Theory and Applica-
tion, K. Jensen and G. Rozenberg (editors), Springer Verlag,
1991.
[13] G. Chiola, C. Dutheillet, G. Franceschinis, and S. Haddad. A
Symbolic Reachability Graph for Coloured Petri Nets. The-
oretical Computer Science B (Logic, semantics and theory
of programming), 176(1&2):39–65, April 1997.
[14] G. Ciardo and A. S. Miner.
SMART: Simulation and
In proc.
Markovian Analyzer for Reliability and Timing.
IEEE International Computer Performance and Dependabil-
ity Symposium (IPDS’96), Urbana-Champaign, IL, USA.
Sept. 1996. IEEE Comp. Soc. Press.
[15] J.M. Couvreur and J. Martinez. Linear invariants in commu-
tative high-level nets. In proc. 10th Intern. Conference on
Application and Theory of Petri Nets, Bonn, Germany, June
1989.
[16] P. Kemper F. Bause, P. Buchholz. A toolbox for functional
and quantitative analysis of DEDS. In proc. of the 10th In-
ternational Conference on Modelling Techniques and Tools
for Computer Performance Evaluation Palma de Mallorca,
Spain, 1998; Springer and Verlag LNCS 1469.
[17] K.L. McMillan. Symbolic Model Checking. Kluwer Aca-
demic Publishers, 1993.
[18]
W. D. Obal
II, M. A. Qureshi, D. D. Deav-
and W. H. Sanders. Overview of UltraSAN.
IEEE Int. Performance and Dependabil-
IL, USA, Sept. 4-6, 1996.
ours,
In proc. of
ity Symposium, Urbana,
http://www.crhc.uiuc.edu/UltraSAN.
[19] K. Varpaaniemi, J. Halme, K. Hiekkanen, and T. Pyssysalo.
PROD reference manual. Technical Report Series B, num-
ber 13, Helsinki University of Technology, August 1995.
[20] Zimmermann, A.; Freiheit, J.; German, R. Hommel, G.:
Petri Net Modelling and Performability Evaluation with
TimeNET 3.0. In the proc. of the 11th Int. Conf. on Mod-
elling Techniques and Tools for Computer Performance
Evaluation (TOOLS’2000), Springer and Verlag LNCS
1786, pp. 188-202, 2000.
[3] J. Merseguer, J. Campos, and E. Mena. Performance evalu-
ation for the design of agent-based systems: A Petri net ap-
proach. In Mauro Pezz`e and Sol M. Shatz, editors, Proceed-
ings of the Workshop on Software Engineering and Petri
Nets, within the 21st International Conference on Applica-
tion and Theory of Petri Nets, Aarhus, Denmark, June 2000.
[4] A. Bondavalli, I. Maizik, and I. Mura. Automated Depend-
ability Analysis of UML Designs.
Proc. ISORC’99
- 2nd IEEE International Symposium on Object-oriented
Real-time distributed Computing, Saint Malo, France, 1999,
IEEE Computer Society Press.
In
[5] C.
G.
Bruno,
Bertoncello,
Franceschinis,
G. Lungo Vaschetti, and A. Pigozzi.
SWN models of
th International
a contact center: a case study. In Proc. 	
Workshop on Petri Nets and Performance Models, Aachen,
Germany, Sept. 11-14 2001. IEEE Computer Society Press.
G.
[6] S. Bernardi, C. Bertoncello, S. Donatelli, G. Franceschi-
nis, R. Gaeta, M. Gribaudo, and A. Horv´ath. GreatSPN in
the new Millenium.
In Tools of Aachen 2001, Int. Mul-
ticonference on Measurement, Modelling and Evaluation of
Computer-Communication Systems, Dortmund, (Germany),
Sept. 2001. Technical report no.760/2001 - Dortmund Uni-
versitaet
[7] S. Bernardi, S. Donatelli, and A. Horv`ath. Compositionality
in the GreatSPN tool and its application to the modelling of
industrial applications.
Int. Journal of Software Tools for
Technology Transfer (STTT), 3(4), August 2001. Springer
and Verlag.
[8] V. DeFlorio, S. Donatelli, and G. Dondossola. Flexible De-
velopment of Dependability Services: An Experience De-
rived from Energy Automation Systems. In proc. of the 9th
annual IEEE Conference and Workshop on Engineering of
Computer-Based Systems, Lund, Sweden, April 8-10(11),
2002.
[9] S. Donatelli, and L. Ferro. Validation of GSPN and SWN
models through the PROD tool. In proc. of the 12th Inter-
national Conference on Modelling Tools and Techniques for
Computer and Communication System Performance Eval-
uation, London, UK, April 2002, Springer Verlag LNCS
2324.
[10] O. Botti, V. De Florio, G. Deconinck, R. Lauwreins,
F. Cassinari, A. Bobbio, S. Donatelli, A. Lein, H. Kufner,
E. Thurner, and E. Verhulst. The TIRAN approach to reusing
software implemented fault-tolerance.
In Proc. 8th Eu-
romicro Workshop on Parallel and Distributed Processing
(PDP2000) , Rhodos, Greece, Jan. 2000. IEEE Comp. Soc.
Press.
[11] G. Chiola, G. Franceschinis, R. Gaeta, and M. Ribaudo.
GreatSPN 1.7: GRaphical Editor and Analyzer for Timed
and Stochastic Petri Nets. Performance Evaluation, special
issue on Performance Modelling Tools, (1), 24, 1996.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:16:05 UTC from IEEE Xplore.  Restrictions apply.