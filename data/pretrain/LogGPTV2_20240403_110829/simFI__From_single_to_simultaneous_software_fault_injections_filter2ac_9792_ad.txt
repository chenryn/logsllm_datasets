i
a
F
d
e
v
r
e
s
b
O
n
o
i
t
c
e
j
n
I
r
e
p
 1
 0.8
 0.6
 0.4
 0.2
 0
Failure Class
AE
AH
SC
F
F
F
F
F
F
Z
Z
Z
Z
Z
Z
0
1
2
0
/
F
0
/
F
1
/
F
Z
Z
Z
1
2
2
Injection into Parameter(s)
Fig. 17: Example for masking effects of the FuzzFuzz model
models include the respective counts for the FZ and BF models
(we assume that these are not previously implemented). The
actual mechanism for combining any two existing models
for simultaneous injections into different parameters of the
same service invocation accounts for only 105 DSIs and an
accumulated cyclomatic complexity of 18.
We conclude that simultaneous fault injections entail mod-
erate overhead for implementation and execution time.
5) Masking and ampliﬁcation: We have found masking
and ampliﬁcation effects to depend highly on the individual
injection target,
i.e., parameter for the SimBF model and
service for the FuzzFuzz and FuzzBF models. These effects
need to be discussed for each such target individually, and due
to space limitations we restrict ourselves to only discussing a
few illustrative examples. Detailed plots for all tested services
are available on our web site [32].
Figure 17 shows an example of masking using the Fuzz-
Fuzz model. While the FZ model provokes SC failures in
more than 80% of the injections into parameters 0 and 1 and
achieves injection efﬁciencies of 100% for both parameters,
their combination in the FuzzFuzz model yields an injection
efﬁciency of less than 10%, all of which are AE failures.
Also for combinations with injections into parameter 2, the SC
failure causes for the ﬁrst two parameters do not dominate the
experiment outcome. In contrast, Figure 18 shows an example
of ampliﬁcation for the same model
targeting a different
service. While single fuzzing only results in a modest amount
of SC failures in parameter 2, the simultaneous injections into
parameters 0 and 2 result in higher SC failure rates. To avoid
sampling effects in the comparisons, we have backed up our
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:56:01 UTC from IEEE Xplore.  Restrictions apply. 
s
e
s
s
a
l
C
e
r
u
l
i
a
F
d
e
v
r
e
s
b
O
n
o
i
t
c
e
j
n
I
r
e
p
 1
 0.8
 0.6
 0.4
 0.2
 0
Service: CEDDK - MmMapIoSpace
Failure Class
AE
AH
SC
F
F
F
F
F
F
Z
Z
Z
Z
Z
Z
0
1
2
0
/
F
0
/
F
1
/
F
Z
Z
Z
1
2
2
Injection into Parameter(s)
Fig. 18: Example for ampliﬁcation effects of the FuzzFuzz
model
results by additional experiments, as discussed in Section V-C.
E. Discussion
The simultaneous models add value to the performed
evaluation, as they detect service faults that are not covered
by other models. On efﬁciency considerations,
the SimBF
model outperforms discrete fault models in most cases. The
implementation overhead of all considered simultaneous mod-
els is moderate compared to the discrete models. Especially
for critical applications the consideration of coincident faults
threatening dependability may well be worth the effort.
Caveats: As we have discussed previously, exhaustive
tests are feasible for the BF and SimBF models, while they
are not for the FZ-based models. Consequently, we were
able to exhaustively inject BF and SimBF faults and had to
select a ﬁxed number of test cases for the FZ-based models.
Interestingly, the BF and SimBF faults that we injected are
also among the injection candidates of the FZ model. However,
we see signiﬁcantly different results for the (simultaneous) bit
ﬂips, indicating that there are signiﬁcant effects depending on
the chosen samples for the FZ-based models. An investigation
of why and how systematically derived faults, e.g., the BF-
based models, give better evaluation results is beyond the scope
of this paper and left as subject to future research.
We observed differing performance of the different fault
models for different drivers. Furthermore some interfaces are
only used by some drivers and not by others. We therefore
assume that the efﬁciency of an evaluation depends on an
interplay of fault models and the precise system conﬁguration,
comprising fault loads and applied workloads.
VI. RELATED WORK
While basic simultaneous fault injections have previously
been conducted, they have not been detailed for either spatial
or temporal resolutions as in our work. We discuss related
approaches to put our contributions in context.
A. Simultaneous Injections into Function Call Parameters
In the Ballista project, simultaneous injections into multiple
parameters of a function call have been performed with a
data-type fault model [33]. The authors do not differentiate
between valid and invalid parameters that are combined it
the tests and do not quantitatively analyze the impact of
simultaneous injections, i.e., the combination of invalid inputs.
However, they report that simultaneous injections have not had
a signiﬁcant impact on the detection probability of robustness
vulnerabilities [34], [28], which contradicts our results. We see
three possible reasons for this deviation, which we are planning
to investigate in more depth in the future: (1) Ballista and
our work target different interfaces of the OS (driver interface
vs. API), (2) the quoted Ballista results were obtained more
than a decade ago and may not hold for newer systems, and
(3) the results may signiﬁcantly differ due to the different fault
models. We plan to investigate these possible causes in future
work.
Although not discussed explicitly, automated fault injec-
tions applied for the determination of the robust argument
type for n-ary functions in HEALERS [35] probably also
use simultaneous injections into different parameters: If the
robust types of multiple arguments depend on each other, this
dependency can only be reﬂected by simultaneous injections.
If there is no such dependency, simultaneous tests for robust
types of independent arguments can reduce the test effort.
B. Validating software-implemented hardware fault-tolerance
Software replication (e.g., N-copy programming [36], or
process-level redundancy [37]) is a common technique to
handle the effects of non-deterministic hardware errors on
software. In order to validate the effectiveness of setups with
more than two replicas, multiple hardware faults are emulated
to provoke the coincident failure of several replicas. Joshi et
al. [38] discuss the problem of exponentially increasing test
candidates if multiple hardware failures are considered in a
distributed setting and suggest strategies to reduce them. In
contrast to our evaluation of coincidence effects on experiment
outcomes, their pruning heuristics use static properties that do
not account for test results.
Another motivation behind the emulation of multiple cor-
related or uncorrelated hardware errors affecting software
is the increasing error rate expected from future hardware
architectures with ever increasing transistor densities. In order
to evaluate the impact increasing error rates would have on
software built on the assumption of perfectly reliable hardware,
the effects of coincident hardware errors on software are
emulated, e.g., by modifying machine instructions generated
by a compiler [39]. The work in this paper differs from these
approaches, as we do not restrict ourselves to the emulation
of hardware-induced software errors. We do not make any
assumption about a fault, apart from constituting an external
fault [10] to the component under evaluation.
C. Higher order mutation testing
Mutation testing [40] is an approach to assess the quality
of test suites. Mutants of programs are created using mutation
operators. A test suite that is capable of distinguishing the
original program from the mutant is considered better than
one that cannot. Program mutation can be considered fault
injection, as it alters software in a controlled manner to assess
defect detection. Jia and Harman introduced higher order
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:56:01 UTC from IEEE Xplore.  Restrictions apply. 
mutants [41] resulting from consecutive applications of multi-
ple traditional ﬁrst-order mutation operators, thereby possibly
injecting both temporally coincident and temporally spread
faults according to our notions. They classify higher order
mutants according to their impact in test suite evaluations, as
opposed to our classiﬁcation according to where and at what
granularity injections are applied.
While mutation order and interface fault coincidence have
similar intent, our proposed coincidence notion is more gen-
eral, as we provide deﬁnitions for both white-box and black-
box assessment scenarios. We also consider coincidence at
different spatial and temporal resolutions instead of restricting
ourselves to a speciﬁc spatial or temporal scope, such as
individual programs.
D. Accumulating fault effects
If fault activations do not immediately result in a detectable
failure, errors may remain dormant in the system. In such
cases the effects of multiple fault activations can accumulate in
the system. Software aging is an example of minor deviations
accumulating over time. For accumulating fault effects, related
work on fault injections falls in two categories. One class of
work (e.g., [8], [42]) tries to avoid accumulating effects for
methodological reasons, as these complicate the identiﬁcation
of effects that an individual fault activation has on the system
(cf. Section III-B). The second class of work (e.g., [43], [44])
considers accumulating fault effects and either accepts that no
direct causal relation between an individual fault activation can
be established or performs additional experiments to establish
these relations. Our work falls in the latter category. While
existing work has partially considered temporal spread in terms
of software aging, our work also explores temporal coincidence
in both our deﬁnitions and experiments.
Moreover, our deﬁnitions for temporally spread faults pro-
vide a general template for deﬁning fault models to emulate
software aging effects, which can be used to assess and
optimize the effectivness of software rejuvenation strategies, as
mandated by experimental analyses of complex systems code
[45], [46].
VII. CONCLUSION
Surprisingly, the interaction of coincident fault effects is
often neglected in software robustness analyses. In this paper
we have investigated the beneﬁts and costs that come with
a consideration of coincident faults in terms of evaluation
efﬁciency. Our paper makes the following contributions.
(C1) establishes coincidence notions for SWIFI covering
both the temporal and spatial domains.
(C2) investigates conceptual and technical arguments that
affect the effectiveness of coincident fault injections in soft-
ware evaluations.
(C3) details the design and implementation of three simul-
taneous, i.e., temporally coincident, fault models for SWIFI
experimentation.
The proposed coincidence notions enable a large number
of novel fault models for SWIFI experiments and although we
have limited ourselves to the design and assessment of only
three models, our experimental results indicate that coincident
fault models have signiﬁcant effects on the coverage in a
software robustness evaluation. Depending on the temporal and
spatial granularity, there may be defects that cannot be covered
by certain coincident models by design, as discussed for the
FuzzFuzz and FuzzBF models. However, even these models
cover a number of defects that are not covered by discrete
models in our experiments.
Our analyses of the Windows CE driver interface have
shown signiﬁcant fault interactions in kernel functions. This
ﬁnding contradicts a fundamental assumption, i.e., the absence
of fault interactions, on which most contemporary fault injec-
tion frameworks and combinatorial testing [14] as a test case
reduction technique are based on. Thus, our results indicate
that such reductions could potentially be fallacious, and results
based on such assumptions may need careful re-investigation.
From our work we, hence, conclude both the need and
the practicability of simultaneous fault injections for software
robustness evaluations.
VIII. ACKNOWLEDGEMENTS
The authors would like to thank Thorsten Piper and Holger
Rother for comments on a previous draft of the paper. The
work in this paper has been supported by CASED (http://www.
cased.de).
REFERENCES
[1] G. Candea, M. Delgado, M. Chen, and A. Fox, “Automatic Failure-
Path Inference: A Generic Introspection Technique for Internet Appli-
cations,” in Proc. WIAPP 2003, 2003, pp. 132 – 141.
[2]
ISO 26262-1:2011, Road vehicles – Functional safety – Part 1: Vocab-
ulary.
ISO, Geneva, Switzerland, 2011.
[3] R. Moraes, R. Barbosa, J. Duraes, N. Mendes, E. Martins, and
H. Madeira, “Injection of Faults at Component Interfaces and Inside
the Component Code: Are They Equivalent?” in Proc. EDCC, 2006,
pp. 53–64.
[4] A. Johansson, N. Suri, and B. Murphy, “On the Selection of Error
Model(s) for OS Robustness Evaluation,” in Proc. DSN, 2007, pp. 502–
511.
[5]
[6]
J. Christmansson and R. Chillarege, “Generation of an error set that
emulates software faults based on ﬁeld data,” in Proc. FTCS, 1996, pp.
304–313.
J.-C. Fabre, M. Rodriguez, J. Arlat, and J.-M. Sizun, “Building depend-
able COTS microkernel-based systems using MAFALDA ,” in Proc.
PRDC, 2000, pp. 85 –92.
[7] D. Stott, B. Floering, D. Burke, Z. Kalbarczpk, and R. Iyer, “NFTAPE:
a framework for assessing dependability in distributed systems with
lightweight fault injectors,” in Proc. IPDS, 2000, pp. 91 –100.
[8] P. Costa, M. Vieira, H. Madeira, and J. Silva, “Plug and Play Fault
Injector for Dependability Benchmarking,” in Dependable Computing,
ser. LNCS. Springer, 2003, vol. 2847, pp. 8–22.
[9] R. Natella, “Achieving Representative Faultloads in Software Fault
Injection,” Ph.D. dissertation, Universit`a di Napoli Federico II, 2011.
[10] A. Aviˇzienis, J. Laprie, B. Randell, and C. Landwehr, “Basic Concepts
and Taxonomy of Dependable and Secure Computing,” IEEE Trans.
Dependable Secure Comput., vol. 1, no. 1, pp. 11–33, 2004.
[11] C. Szyperski, Component Software - Beyond Object-Oriented Program-
ming. Addison-Wesley, 1998.
(C4) assesses the simultaneous models’ performance quan-
titatively in an actual robustness evaluation.
[12]
IEEE, “Standard Glossary of Software Engineering Terminology,” IEEE
Std 610.12-1990, p. 1, 1990.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:56:01 UTC from IEEE Xplore.  Restrictions apply. 
[13] P. D. Marinescu and G. Candea, “Efﬁcient Testing of Recovery Code
Using Fault Injection,” ACM Trans. Comput. Syst., vol. 29, no. 4, pp.
11:1–11:38, Dec. 2011.
[14] D. Kuhn, D. Wallace, and J. Gallo, A.M., “Software fault interactions
and implications for software testing,” Software Engineering, IEEE
Transactions on, vol. 30, no. 6, pp. 418–421, 2004.
[39] M. de Kruijf and K. Sankaralingam, “Exploring the synergy of emerging
workloads and silicon reliability trends,” in SELSE, 2009.
[40] Y. Jia and M. Harman, “An Analysis and Survey of the Development
of Mutation Testing,” IEEE TSE, vol. 37, no. 5, pp. 649 –678, 2011.
[41] ——, “Higher Order Mutation Testing,” Information and Software
Technology, vol. 51, no. 10, pp. 1379 – 1393, 2009.
[15]
ISO 26262-5:2011, Road vehicles – Functional safety – Part 5: Product
development at the hardware level.
ISO, Geneva, Switzerland, 2011.
[42] M. Vieira, N. Laranjeiro, and H. Madeira, “Assessing Robustness of
Web-Services Infrastructures,” in Proc. DSN, 2007, pp. 131–136.
[43] M. Kaaniche, L. Romano, Z. Kalbarczyk, R. Iyer, and R. Karcich, “A
hierarchical approach for dependability analysis of a commercial cache-
based RAID storage architecture,” in Proc. FTCS, 1998, pp. 6–15.
[44] M. Kaaniche, J.-C. Laprie, and J.-P. Blanquart, “Dependability engi-
neering of complex computing systems,” in Proc. ICECCS, 2000, pp.
36–46.
[45] G. Carrozza, D. Cotroneo, R. Natella, A. Pecchia, and S. Russo,
“Memory leak analysis of mission-critical middleware,” Journal of
Systems and Software, vol. 83, no. 9, pp. 1556 – 1567, 2010.
[46] D. Cotroneo, R. Natella, R. Pietrantuono, and S. Russo, “Software aging
analysis of the linux operating system,” in Proc. ISSRE, 2010, pp. 71–
80.
[16] H. Hecht, “Rare Conditions – An Important Cause of Failures,” in Proc.
COMPASS, 1993, pp. 81–85.
[17] R. R. Lutz and I. C. Mikulski, “Operational Anomalies as a Cause of
Safety-Critical Requirements Evolution,” JSS, vol. 65, no. 2, pp. 155 –
161, 2003.
[18] A. Chou, J. Yang, B. Chelf, S. Hallem, and D. Engler, “An Empirical
Study of Operating Systems Errors,” in Proc. SOSP, 2001, pp. 73–88.
[19] D. Simpson, “Windows XP Embedded with Service Pack 1 Reliabil-
ity,” http://msdn.microsoft.com/en-us/library/ms838661(WinEmbedded.
5).aspx.
[20] A. Ganapathi, V. Ganapathi, and D. Patterson, “Windows XP Kernel
Crash Analysis,” in Proc. LISA, 2006, pp. 12–22.
[21] N. Palix, G. Thomas, S. Saha, C. Calv`es, J. Lawall, and G. Muller,
“Faults in linux: ten years later,” in Proc. ASPLOS, 2011, pp. 305–318.
[22] A. Albinet, J. Arlat, and J.-C. Fabre, “Characterization of the impact
of faulty drivers on the robustness of the Linux kernel,” in Proc. DSN,
2004, pp. 867 – 876.
[23] M. M. Swift, B. N. Bershad, and H. M. Levy, “Improving the reliability
of commodity operating systems,” in Proc. SOSP. ACM, 2003, pp.
207–222.
[24] MSDN, “Stream Interface Driver Implementation (Windows CE .NET
4.2),” http://msdn.microsoft.com/en-us/library/ms895309.aspx.
[25] ——, “Implementing CEDDK.dll,” http://msdn.microsoft.com/en-us/
library/ms898217.aspx.
[26] ——,
“coredll Module,”
http://msdn.microsoft.com/en-us/library/
aa448387.aspx.
[27] ——, “Network Driver Functions,” http://msdn.microsoft.com/en-us/
library/ms895631.aspx.
[28] P. Koopman, K. Devale, and J. Devale, “Interface Robustness Test-
ing: Experience and Lessons Learned from the Ballista Project,” in
Dependability Benchmarking for Computer Systems, K. Kanoun and
L. Spainhower, Eds., 2008, pp. 201–226.
[29] S. Winter, C. Sˆarbu, N. Suri, and B. Murphy, “The impact of fault
models on software robustness evaluations,” in Proc. ICSE, 2011, pp.
51–60.
[30] T. Liu, Z. Kalbarcyzk, and R. K. Iyer, “Software-Embedded Multilevel
Faul Injection Mechanism for Evaluation of a High-Speed Network
System under Windows NT,” in Proc. IOLTW, 1999.
[31] T. McCabe, “A Complexity Measure,” IEEE Trans. Softw. Eng., vol.
SE-2, no. 4, pp. 308–320, 1976.
[32] DEEDS Group, “Robustness Evaluation of Windows CE using Simul-
taneous Fault Injections,” http://www.deeds.informatik.tu-darmstadt.de/
simFI.
[33] N. Kropp, P. Koopman, and D. Siewiorek, “Automated robustness
testing of off-the-shelf software components,” in Proc. FTCS, 1998,
pp. 230 –239.
[34]
J. Pan, “The Dimensionality of Failures – A Fault Model for Charac-
terizing Software Robustness,” in Proc. FTCS, 1999.
[35] C. Fetzer and Z. Xiao, “An automated approach to increasing the
robustness of C libraries,” in Proc. DSN, 2002, pp. 155 – 164.
[36] P. E. Ammann and J. C. Knight, “Data diversity: an approach to software
fault tolerance,” IEEE Trans. Comput., vol. 37, no. 4, pp. 418–425,
1988.
[37] A. Shye, J. Blomstedt, T. Moseley, V. J. Reddi, and D. A. Connors,
“PLR: A Software Approach to Transient Fault Tolerance for Multicore
Architectures,” IEEE Trans. Dependable Secure Comput., vol. 6, no. 2,
pp. 135–148, 2009.
[38] P. Joshi, H. S. Gunawi, and K. Sen, “PREFAIL: a programmable tool
for multiple-failure injection,” in Proc. OOPSLA, 2011, pp. 171–188.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:56:01 UTC from IEEE Xplore.  Restrictions apply.