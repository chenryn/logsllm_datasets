something with it,” because he has “seen similar behavior
before where ﬁrmware is written in generically.” Other REs
consider the assembly instructions chosen by the compiler
(N=8) or function prototypes (N=5) to determine the data
types of variables. P02V explained, “It is very important to
understand. . . how compilers map code to the actual binary
output.” As an example, he pointed out instructions at the start
of a function and said, “that’s just part of saving the values. . . I
Figure 2: Screenshot of botnet code investigated by P11M,
which performs a network connectivity check. This provides
an example of API calls and strings recognized during sub-
component scanning giving program functionality insights.
level, because it’s really easy to get caught in the weeds when
there could be something much better to look at.” The middle
column of Figure 1 gives an overview of this analysis phase.
Scan for many beacons (RQ2). Most commonly, REs scan
through functions or code segments prioritized in the overview
(N=15), looking for a variety of beacons indicating possi-
ble behaviors. These include APIs (N=15), strings (N=15),
constants (N=11), and variable names (N=11). For exam-
ple, while investigating a piece of malware, P02V saw
GetProcAddress was called. This piqued his interest because
1882    29th USENIX Security Symposium
USENIX Association
The diversity of beacons represents a second diﬀerence
from program comprehension (RQ3). While program com-
prehension research has identiﬁed several similar beacons
(API calls, strings, variable names, sequences of operations,
and constants [28, 33–35]), developers have been shown to
struggle when variable names and other semantic information
are obfuscated [33]. However, REs adapt to the resource-
starved environment and draw on additional beacons (i.e.,
control ﬂow structures, compiler artifacts, and program ﬂow).
5.3 Focused Experimentation (RQ1)
Finally, when REs identify a speciﬁc question or hypothesis,
they shift to focused experimentation: setting up small experi-
ments, varying program inputs and environmental conditions,
and considering the program’s behavior in these states to
ﬁnd a concrete answer or prove whether speciﬁc hypotheses
hold. This phase’s results are fed back into sub-component
scanning, to reﬁne high-level hypotheses and the RE’s inter-
pretation of observed beacons. Again, REs rely on a wide
range of methods for this analysis.
Execute the program (RQ2). In most cases, REs validate
their hypotheses by running the code under speciﬁc condi-
tions to observe whether the expected behavior occurs (N=13).
They may try to determine what value a certain variable holds
at a particular point (e.g., input to a function of interest) un-
der varying conditions (N=13) or whether user input ﬂows to
an unsafe function (N=9). For example, after reviewing the
data-ﬂow path of the program’s arguments, P03V hypothe-
sized that the program required two input ﬁles with a speciﬁc
string in the ﬁrst line to allow execution to reach potentially
vulnerable code. To test this hypothesis, she ran the program
in a debugger with the expected input and traced execution to
see the state of memory at the potentially vulnerable point.
While running the program, REs gather information in a va-
riety of ways. Most execute the code in a debugger (N=12) to
probe memory and have full control over execution. Some use
other tools like packet capturers and ﬁle monitors to observe
speciﬁc behaviors (N=8). In some cases, REs manipulate the
execution environment by dynamically changing registry val-
ues (N=7) or patching the binary (N=5) to guide the program
down a speciﬁc path. As an example, while analyzing mal-
ware that “checks for whether it is being run in a debugger,”
P16M simply changes the program “so that the check will
always just return false [not run in debugger].”
Finally, some REs fuzz program inputs to identify mutation-
speciﬁc behavior changes. In most cases, fuzzing is performed
manually (N=6), where the RE hand-selects mutations. Au-
tomation is used in later stages, once a good understanding
of the program is established (N=1). P08V explained, “I wait
until I have a good feel for the inputs and know where to look,
then I patch the program so that I can quickly pump fuzzed
Figure 3: Program investigated by P02V to determine whether
he could trigger an undeﬁned memory read. The code has
been converted to a pseudo-code representation including
only relevant lines. It shows the control ﬂow graph for two
functions: main and id_alloc. Rectangles represent basic
blocks, and arrows indicate possible control ﬂow paths.
can safely skip those.” Then he identiﬁed a series of regis-
ters and observed “those are the function’s arguments. . . after
checking the codebase of FreeBSD, I know the second argu-
ment is actually a packed structure of arguments passed from
outside the kernel. This is [the data] we control in this func-
tion context.” Finally, REs consider the code’s relation to the
overall program ﬂow (N=6). For example, P08V identiﬁed
a function as performing “tear down” procedures—cleaning
up the state of the program before terminating—because it
“happened after the main function.”
Focused on speciﬁc data-ﬂow and control-ﬂow paths
(RQ2). Some REs also scanned speciﬁc data- (N=8) and
control-ﬂow (N=7) paths, only considering instructions af-
fecting these paths. These analyses were commonly used to
understand how a function’s input (N=7) or output (N=4) is
used and whether a particular path is realizable (N=4). For
example, while reviewing the program summarized in Fig-
ure 3, P02V asked whether a control-ﬂow path exists through
id_alloc in which x is not written. Memory for x is allocated
before the id_alloc call and read after, so if such a path is
possible, “we can have it read from undeﬁned memory.” To
answer this question, P02V scanned each control ﬂow path
through the function from the bottom of the graph up. If he
saw a write to x, he moved on to the next path. This check
invalidated the ﬁrst two control-ﬂow paths (counting left-to-
right) in Figure 3. Additionally, in main, the program exits if
the return value of id_alloc is -1. Thus his next step was to
check the data ﬂow to id_alloc’s return value to see whether
it was set to -1. He found the return value was set to -1 in both
remaining control-ﬂow paths, indicating it was not possible
to read from undeﬁned memory.
USENIX Association
29th USENIX Security Symposium    1883
inputs from angr [76] into the parts I care about.”
Compare to another implementation (RQ2). Some REs
chose to re-write code segments in a high-level language
based on the expected behavior (N=8) or searched for public
implementations (e.g., libraries) of algorithms they believed
programs used (N=5). They then compared the known im-
plementation’s outputs with the subject program’s outputs to
see if they matched. For example, once P10B recognized the
encryption algorithm he was looking at was likely Blowﬁsh,
he downloaded an open-source Blowﬁsh implementation. He
ﬁrst compared the open-source code’s structure to the encryp-
tion function he was reviewing. He then ran the reference
implementation and malware binary on a ﬁle of all zeros say-
ing, “we can then verify on this sample data whether it’s real
Blowﬁsh or if it’s been modiﬁed.”
Read line-by-line only for simple code or when execution
is diﬃcult (RQ2). Finally, REs resorted to reading the code
line-by-line and mentally tracking the program state when
other options became too costly (N=9). In some cases, this
occurred when they were trying to answer a question that
only required reading a few, simple lines of code. For exam-
ple, P05V described a situation where he read line-by-line
because he wanted to fully understand a small number of
speciﬁc checks, saying, “After Google Project Zero identiﬁed
some vulnerabilities in the system, the developers tried to
lock down that interface by adding these checks. Basically
I wanted to ﬁgure out a way to bypass these speciﬁc checks.
At this point I ended up reading line-by-line and really trying
to understand the exact nature of the checks.” While no par-
ticipants quantiﬁed the number of lines or code complexity
they were willing to read line-by-line, we did not observe
any participants reading more than 50 lines of code. Further,
this determination appeared goal- and participant-dependent,
with wide variation between participants and even within indi-
vidual participants’ own processes, depending on the current
experiment they were carrying out.
REs also chose to read line-by-line instead of running the
program when running the program would require signiﬁcant
setup (e.g., when using an emulator to investigate uncommon
ﬁrmware like home routers). P09V explained, “The reason I
was so IDA [disassembler] heavy this time is because I can’t
run this binary. It’s on a cheap camera and it’s using a shared
memory map. I mean, I could probably run this binary, but
it’s going to take a while to get [emulation] set up.”
During this line-by-line execution, a few REs said they
used symbolic execution to track inputs to a control ﬂow
conditional of interest (N=2). P03V explained, “I write out
the conditions to see what possible states there are. I have
all these variables with all these constraints through multiple
functions, and I want to say for function X, which is maybe
10 deep in the program, what are the possible ranges for each
of these variables?” In both cases, the REs said they generally
performed this process manually, but used a tool, such as Z3,
when the conditions became too complicated. As P03V put
it, “It’s easier if you can just do it in your brain of course, but
sometimes you can’t. . . if there are 10 possibilities or 100
possibilities, I’ll stick it in a SAT solver if I really care about
trying to get past a barrier [conditional].”
Beacons are still noticed and can provide shortcuts
(RQ2). While REs focus on answering speciﬁc questions in
this phase, some also notice beacons missed in prior analyses.
If inferences based on these beacons invalidated prior be-
liefs, REs quickly stop focused experimentation that becomes
moot. For example, while P04V was reverse engineering a
card-game challenge binary, he decided to investigate a reset
function operating on an array he believed might be impor-
tant. There were no obvious beacons on initial inspection
and there were only a few instructions, so he decided to read
line-by-line. However, he quickly recognized two constants
that allowed him to infer functionality. He saw that “it’s incre-
menting values from 0 to 51. So at this point, I’m thinking it’s
a deck of cards. And then it has this variable hold. Hold is a
term for poker, and it sets 0 to 4.” Once he realized what these
variables were, he decided he had suﬃcient information to
stop analyzing the function, and he moved back to the calling
function to resume sub-component scanning.
Simulation methods mostly overlap with program com-
prehension (RQ3). Most of the methods described above,
including using a debugger and reading code line-by-line,
are found in the program comprehension literature. However,
comparing program execution to another implementation ap-
pears unique to REs. As in sub-component scanning, this
extra method is likely necessitated by the additional complex-
ity inherent in an adversarial environment.
6 Results: Cross-phase Trends
In addition to the phases themselves, we observed several
cross-phase trends in our participants’ RE approaches, which
we discuss in this section. This includes both answers to
our research questions which were not unique to a speciﬁc
phase and additional observations regarding tool usage which
inform future tool development. Figure 4 includes some of
these trends as they interact with the phases.
Begin with static methods and ﬁnish with dynamic (RQ2).
Most of the simulation methods described in the ﬁrst two anal-
ysis phases focused on static program representations, i.e., the
binary or decompiled code. In contrast, focused experimenta-
tion was mainly performed dynamically, i.e., by running the
program. Reverse engineers typically make this switch, as
P05V stated, “because this thing is so complex, it’s hard to
trace the program ﬂow [statically], but you can certainly tell
when you analyze an [execution] trace. You could say this
was hit or this wasn’t hit.” However, REs sometimes choose
not to switch when they perceive the switch to be diﬃcult.
1884    29th USENIX Security Symposium
USENIX Association
go to the function list and say the larger function is proba-
bly interesting...as long as I can distinguish the actual code
versus library code, this technique is actually pretty useful.”
Similarly, REs employ heuristics to decide which functions
not to investigate. For example, P16M said, “If the function is
cross-referenced 100 times, then I will avoid it. It’s probably
something like an error check the compiler added in.”
In sub-component scanning, experience plays an even more
important role. As in the previous analysis phase, REs must
decide which data- (N=8) and control-ﬂow paths (N=7) to
consider. Again, this is done ﬁrst by prior experience (N=6)
and then by simple strategies (N=4). As they perform their
analyses, REs must also determine potential hypotheses re-
garding program functionality (N=16) and possible vulnera-
bilities (N=9)—exploitable ﬂaws in the case of vulnerability
discovery, or signaturable behaviors for malware analysis. In
most cases, these determinations are made by recognizing
similarities with previous experiences (N=15). For example,
when P08V saw a function named httpd_ipc_init, he rec-
ognized this might introduce a vulnerability, saying, “IPC
generally stands for inter-process communication, and many
router ﬁrmwares like this set up multiple processes that com-
municate with each other. If it’s doing IPC through message
passing, then that opens up the attack surface to anything that
can send messages to this httpd binary.” If the RE is unable to
generate hypotheses based on prior experience, they instead
make determinations based on observed behaviors (N=16),
obtained via more labor intensive investigation of the program
execution or in-depth code review.
Experience used to select analysis method throughout
(RQ1). There were typically multiple ways to answer a ques-
tion. The most common example, as discussed in Section 5.3,
was deciding between executing the program or reading line-
by-line during focused experimentation (N=9). Similar deci-
sions occurred in the other phases. For example, some REs
choose to simply skip the overview phase all together and
start with the main function (N=5) whenever, as P03V said,
“it’s clear where the actual behavior starts that matters.”
REs also decide the granularity of analysis, weighing an
approximation’s beneﬁts against the inaccuracy introduced
(N=5). For example, several participants discussed choosing
to use a decompiler to make the code easier to read, knowing
that the decompilation process introduces inaccuracies in
certain circumstances. P04V said, “I actually spend most of
my time in Hex-Rays [decompiler]. A few of my friends
generally argue that this is a mistake because Hex-Rays can
be wrong, and disassembly can’t be. And this is generally
true, but Hex-Rays is only wrong in speciﬁc ways.” Further,
because these are explicit decisions, REs are also able to
recognize situations where the inaccuracies are common and
can switch analysis granularities to verify results (N=5). For
example, when using a decompiler, the RE has some intuition
regarding what code should look like. P04V explained, “I’ve
Figure 4: Overview of the analysis phases and trends observed
across them. The arrows shown between the phases indicates
information ﬂow. The brackets indicate which phases the
adjacent item is relevant to.
P15V explained “[switching] was a little daunting to me. I