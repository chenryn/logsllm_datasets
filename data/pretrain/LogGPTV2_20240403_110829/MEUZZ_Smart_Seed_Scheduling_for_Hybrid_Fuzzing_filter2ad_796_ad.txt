### Dependability Factors and Program Loops

Dependability in software systems can be influenced by a variety of factors, including the presence of program loops. These loops can impact the overall reliability and performance of the system. The following sections provide an in-depth analysis of these factors and their implications.

#### Gini Importance of Features

The Gini importance of various features is illustrated in the figure below. The features include reachable label size, external call path length, reached labels, undiscovered neighbors, indirect calls, and new coverage. The Gini importance values are plotted against the feature names, with the Gini importance on the Y-axis and the feature names on the X-axis.

```
Feature                      Gini Importance
reachable labelsize          0.00
extcallpath length           0.10
cmpreached labels            0.20
undiscovered neighbours      0.30
indcall                       0.40
new cov                      0.50
```

#### Branch Coverage Over Time

The branch coverage over time for different fuzzers (AFL, AFLFast, Angora, QSYM, SAVIOR, MEUZZ-OL, MEUZZ-RF, MEUZZ-EN) is shown in the figures below. The X-axis represents time in hours, and the Y-axis represents the number of branches covered.

- **Figure 1: Branch Coverage Over 24 Hours**
  - **tcpdump**: 
    - AFL and AFLFast generate only 6 inputs in total after 24 hours.
    - Systems augmented with concolic execution and taint analysis generate more inputs.
  - **djpeg**:
    - MEUZZ-RF outperforms other fuzzers with a significant p-value (< 0.05), indicating the effectiveness of the non-linear model.

- **Figure 2: Additional Branch Coverage Data**
  - Similar trends are observed in other programs, with MEUZZ variants generally outperforming other fuzzers.

### Model Reusability and Transferability

Building machine learning models for fuzzing is a valuable but time-consuming task. Reusing models can improve generalization, speed up training, and enhance model accuracy. Additionally, reusability can indicate that the model correctly captures the utility of inputs during testing.

#### Experiment Setup

To test the reusability of learned models, we conducted an experiment where a pre-trained model was used to fuzz the same target program. The following changes were made compared to the previous experiment:
1. Initial seeds were replaced with a naive input consisting of 4 whitespaces.
2. All MEUZZ variants were initialized with the models they learned in the effectiveness test.

#### Results

- **Coverage Improvement**:
  - MEUZZ variants performed well from the beginning, likely due to the initial models.
  - "Pure-AFL" fuzzers did not perform well with the naive initial seed.
  - MEUZZ-RF showed significant improvement in djpeg, with a p-value < 0.05.

### Model Transferability

Model transferability was evaluated by conducting a cross-program experiment to determine if a model trained on one type of program could effectively fuzz a new program. This is known as transfer learning in the ML field.

#### Experiment Setup

- **Baseline**: Coverage result from the learning effectiveness experiment using valid seeds without model initialization.
- **Representative System**: MEUZZ-OL.
- **Test Programs**: Each program was fuzzed using MEUZZ-OL initialized with 8 pre-learned models.

#### Results

- **Coverage Improvement**:
  - MEUZZ-OL observed an average 7.1% increase in code coverage when tested on the same program it was initialized with.
  - 67.9% success rate in 38 out of 56 cross-testing cases, with 10 cases showing more than 10% coverage improvement.
  - Different programs had varying sensitivity to transferred models. For example, readelf showed the highest improvement, even when using the tcpdump model.

### Discovered Bugs

To evaluate the effectiveness of MEUZZ in discovering new bugs, we analyzed all reported undefined behaviors and crashes. UBSan, ASAN, and LeakSAN were used to triage the bugs.

- **Total Unique Bugs Found**: 54
- **MEUZZ Performance**: Found 47 unique bugs, outperforming other fuzzers and supporting the correlation between higher code coverage and bug discovery.

### Related Work

#### Machine Learning for Fuzzing

- **Input Generation**: DL techniques have been applied to learn patterns in input files and identify likely input forms to trigger new coverage.
- **Crash Analysis**: ML can categorize crashes and predict exploitability.
- **Seed Selection**: MEUZZ is the first to apply ML for seed selection, demonstrating practicality through reusability and transferability.

#### Seed Scheduling Heuristics

- **Scheduling in Fuzzing**: Various heuristics have been developed, such as preferring seeds with new coverage and smaller size.
- **Hybrid Testing**: Techniques like random scheduling and Monte-Carlo models have been proposed.
- **MEUZZ Advantage**: Uses ML to learn a utility prediction model, making it more scalable and performant than manual heuristics.

### Conclusion

MEUZZ is a hybrid fuzzing system that leverages machine learning and data-driven seed scheduling. It outperforms state-of-the-art fuzzers in both code coverage and bug discovery. The learned models demonstrate good reusability and transferability, making MEUZZ a practical and effective solution for hybrid fuzzing.

### Acknowledgments

We thank the anonymous reviewers for their insightful comments. This project was supported by the National Science Foundation (Grant#: CNS-1748334) and the Office of Naval Research (Grant#: N00014-17-1-2891).

### References

[1] AddressSanitizer. https://clang.llvm.org/docs/AddressSanitizer.html.
[2] AFL Technical Details. http://lcamtuf.coredump.cx/afl/technical_details.txt.
[3] angr/tracer: Utilities for generating dynamic traces. https://github.com/angr/tracer.
[4] Announcing OSS-Fuzz: Continuous Open Source Software Fuzzing. https://testing.googleblog.com/2016/12/announcing-oss-fuzz-continuous-fuzzing.html.
[5] Binutils Test Cases. https://github.com/mirrorer/afl/tree/master/testcases/others/elf.
[6] Clang Undefined Behavior Sanitizer. http://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html#ubsan-checks.
[7] Leaksanitizer. https://clang.llvm.org/docs/LeakSanitizer.html.
[8] libFuzzer â€“ A Library for Coverage-Guided Fuzz Testing. https://llvm.org/docs/LibFuzzer.html.
[9] Libjpeg Test Cases. https://github.com/mirrorer/afl/tree/master/testcases/images/jpeg.
[10] Libtiff Test Cases. https://github.com/mirrorer/afl/tree/master/testcases/images/tiff.
[11] Libxml Test Cases. https://github.com/mirrorer/afl/tree/master/testcases/others/xml.