title:Micro-Policies: Formally Verified, Tag-Based Security Monitors
author:Arthur Azevedo de Amorim and
Maxime D&apos;enès and
Nick Giannarakis and
Catalin Hritcu and
Benjamin C. Pierce and
Antal Spector-Zabusky and
Andrew Tolmach
2015 IEEE Symposium on Security and Privacy
2015 IEEE Symposium on Security and Privacy
Micro-Policies
Formally Veriﬁed, Tag-Based Security Monitors
Arthur Azevedo de Amorim1,2 Maxime D´en`es1,2 Nick Giannarakis2,3,4
C˘at˘alin Hrit¸cu2
Benjamin C. Pierce1 Antal Spector-Zabusky1 Andrew Tolmach5
1University of Pennsylvania
2Inria Paris-Rocquencourt
3ENS Cachan 4NTU Athens
5Portland State University
Abstract—Recent advances in hardware design have demon-
strated mechanisms allowing a wide range of low-level secu-
rity policies (or micro-policies) to be expressed using rules on
metadata tags. We propose a methodology for deﬁning and
reasoning about such tag-based reference monitors in terms of
a high-level “symbolic machine,” and we use this methodology
to deﬁne and formally verify micro-policies for dynamic sealing,
compartmentalization, control-ﬂow integrity, and memory safety;
in addition, we show how to use the tagging mechanism to
protect its own integrity. For each micro-policy, we prove by
reﬁnement
the symbolic machine instantiated with the
policy’s rules embodies a high-level speciﬁcation characterizing a
useful security property. Last, we show how the symbolic machine
itself can be implemented in terms of a hardware rule cache and
a software controller.
that
Index Terms—security; dynamic enforcement; reference mon-
itors; low-level code; tagged hardware architecture; metadata;
formal veriﬁcation; reﬁnement; machine-checked proofs; Coq;
dynamic sealing; compartmentalization; isolation; least privilege;
memory safety; control-ﬂow integrity
Introduction
1
Today’s computer systems are distressingly insecure. However,
many of their vulnerabilities can be avoided if low-level code
is constrained to obey sensible safety and security properties.
Ideally, such properties might be enforced statically, but for
obtaining pervasive guarantees all the way to the level of
running machine code it is often more practical to detect
violations dynamically using a reference monitor [3], [13],
[29]. Monitors have been used for many tasks, including
enforcement of memory safety [27] or control-ﬂow integrity
(CFI) [1], taint tracking, ﬁne-grained information-ﬂow control
(IFC), and isolation of untrusted code [33], [35]. They are
sometimes implemented in software [13], but this can signiﬁ-
cantly degrade performance and/or cause designers to settle for
rough approximations of the intended policy that are potentially
vulnerable to attack [10], [14]. Hardware acceleration is thus an
attractive alternative, especially in an era of cheap transistors.
Many designs for hardware monitors have been proposed,
with early designs focusing on enforcing single, hard-wired
security policies [30] and later ones evolving toward more
programmable mechanisms that allow quicker adaptation to a
shifting attack landscape. Recent work has gone yet further
in this direction by deﬁning a generic, fully programmable
hardware/software architecture for tag-based monitoring on a
conventional processor extended with a Programmable Unit
© 2015, Arthur Azevedo De Amorim. Under license to IEEE.
© 2015, Arthur Azevedo de Amorim. Under license to IEEE.
DOI 10.1109/SP.2015.55
DOI 10.1109/SP.2015.55
813
813
for Metadata Processing (PUMP) [11].
The PUMP architecture associates each piece of data in
the system with a metadata tag describing its provenance
or purpose (e.g., “this is an instruction,” “this came from
the network,” “this is secret,” “this is sealed with key k”),
propagates this metadata as instructions are executed, and
checks that policy rules are obeyed throughout the computation.
It provides great ﬂexibility for deﬁning policies and puts no
arbitrary limitations on the size of the metadata and the number
of policies supported. Hardware simulations show [11] that
an Alpha processor extended with PUMP hardware achieves
performance comparable to dedicated hardware when simulta-
neously enforcing memory safety, CFI, and taint tracking on a
standard benchmark suite. Monitoring imposes modest impact
on runtime (typically under 10%) and power ceiling (less than
10%), in return for some increase in energy usage (typically
under 60%) and chip area (110%).
Coding correct, efﬁcient policies to run on the PUMP ar-
chitecture can be nontrivial. Indeed, it is often challenging
even to give a high-level speciﬁcation for a policy of interest.
In prior work, we showed how to address this challenge for
one speciﬁc policy by giving a mechanized correctness proof
for an information-ﬂow control (IFC) policy running on an
idealized machine incorporating PUMP-like hardware [4]. This
proof is organized around three layers of machines sharing
a common core instruction set: an abstract machine whose
instruction semantics has a speciﬁc IFC policy built in; an
intermediate symbolic machine that allows for different dynamic
IFC mechanisms to be expressed using a simple domain-
speciﬁc language; and a concrete machine, where the IFC
policy is implemented by a software controller that interacts
with low-level tag-management mechanisms of the hardware. A
noninterference property is established at the abstract machine
level and transferred to the other levels via two steps of
reﬁnement.
In this paper, we extend this IFC-speciﬁc proof to a generic
framework for formalizing and verifying arbitrary policies
enforceable by the PUMP architecture. We use the term micro-
policies for such instruction-level security-monitoring mecha-
nisms based on ﬁne-grained metadata. We use this methodology
to formalize and verify a diverse collection of micro-policies
using the Coq proof assistant.
The heart of our methodology is a generic symbolic machine
(middle layer in Figure 1) that serves both as a programming
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:44 UTC from IEEE Xplore.  Restrictions apply. 































 



















Figure 1. System overview
interface—abstracting away unnecessary implementation de-
tails and providing a convenient platform for micro-policy
designers—and as an intermediate step in correctness proofs.
This machine is parameterized by a symbolic micro-policy that
expresses tag propagation and checking in terms of structured
mathematical objects rather than low-level concrete represen-
tations. Each symbolic micro-policy consists of (i) sets of
metadata tags that are used to label every piece of data in
the machine’s memory and registers (including the program
counter); (ii) a transfer function that uses both the current
opcode and the tags on the pc, on the current instruction, and on
the instruction operands to determine whether the operation is
permitted and, if it is, to specify how the pc and the instruction’s
result should be tagged in the next machine state; and (iii) a
set of monitor services that can be invoked by user code. For
example, in a micro-policy for dynamic sealing (a language-
based protection mechanism in the style of perfect symmetric
encryption [23], described below in §4) the set of tags used
for registers and memory might be {Data, Key k, Sealed k},
where Data is used to tag ordinary data values, Sealed k is
used to tag values sealed with the key k, and Key k denotes
a key that can be used for sealing and unsealing values. The
transfer function for this micro-policy would allow, for example,
arithmetic operations on values tagged Data but deny them on
data tagged Sealed or Key. Monitor services are provided to
allow user programs to create new keys and to seal and unseal
data values with given keys.
We instantiate this symbolic machine with a diverse set
of security micro-policies: (a) dynamic sealing [23], [31];
(b) compartmentalization, which sandboxes untrusted code and
allows it to be run alongside trusted code [32]; (c) control-ﬂow
integrity (CFI), which prevents code-reuse attacks such as
return-oriented programming [1]; and (d) memory safety, which
prevents temporal and spatial violations for heap-allocated
data [11]. The intended behavior of each micro-policy is
speciﬁed by an abstract machine (top layer in Figure 1), which
gives a clear characterization of the micro-policy’s behavior
as seen by a user-level programmer. The abstract machine
enforces the invariants of the micro-policy by omitting insecure
behaviors from its transition function: a program that violates
the micro-policy gets stuck. Where appropriate, we prove
that the abstract machine for a micro-policy satisﬁes standard
properties from the literature. For example, for the CFI micro-
policy we prove a variant of the original CFI property proposed
by Abadi et al. [1], while for our compartmentalization micro-
policy we prove a single-step property drawn from Wahbe et
al.’s original software fault isolation (SFI) model [32]. For
each micro-policy, we prove backward reﬁnement between the
abstract and symbolic machines, i.e., every possible symbolic
machine behavior is a valid abstract behavior—hence, the
symbolic machine always fail-stops on policy violations.
Finally, we extend this methodology to the hardware level
by showing how instances of the symbolic machine can be
realized on a low-level concrete machine, a minimalist RISC
ISA extended with the key mechanisms of the PUMP hardware
architecture [11] (bottom layer in Figure 1). Every word of
data in this machine is associated with a piece of metadata
called a tag—itself a full machine word that can, in particular,
hold a pointer to an arbitrary data structure in memory. The
interpretation of tags is left entirely to software; the hardware
simply propagates tags from operands to results according to
software-deﬁned concrete rules. To propagate tags efﬁciently,
the processor is augmented with a rule cache that operates
in parallel with instruction execution. On a rule cache miss,
control is transferred to a trusted miss handler which, given the
tags of the instruction’s arguments, decides whether the current
operation should be allowed and, if so, computes appropriate
tags for its results. It then adds this set of argument and
result tags to the rule cache so that when the same situation
is encountered in the future, the rule can be applied without
slowing down the processor.
Each micro-policy can be implemented at the concrete
level by providing machine code for the transfer function
and monitor services, along with a concrete bit-encoding for
symbolic tags. This monitor code can make use of a handful
of privileged instructions of the concrete machine, allowing
it to inspect and change tags and to update the cache. For all
micro-policies, it is obviously necessary to protect the integrity
of the monitor’s code and data, and to prevent user programs
from invoking the privileged instructions. We show that we
can achieve this protection using only the tagging mechanism
itself (no special kernel protection modes, page table tricks,
etc.). We also give a generic proof of backward reﬁnement
between the symbolic and concrete machines, modulo some
assumptions characterizing the behavior of the micro-policy-
speciﬁc concrete code. Composing this reﬁnement with the
abstract-symbolic reﬁnement described above gives a proof that
the concrete machine always fail-stops on policy violations. For
CFI, we additionally show that the corresponding higher-level
property [1] is preserved by reﬁnement, allowing us to transfer
it to any valid implementation of the micro-policy.
Our focus throughout is on proving safety properties, which
we formalize as backward reﬁnements: the observable behaviors
of the lower-level machine are also legal behaviors of the
higher-level machine, and in particular the lower-level machine
fail-stops whenever the higher-level machine does. Liveness,
or forward reﬁnement (the lower-level machine only fail-stops
814814
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:44 UTC from IEEE Xplore.  Restrictions apply. 
when the higher-level one does), is also a desirable property;
indeed, a completely inert machine (i.e., one that never steps)
at the symbolic or concrete level would satisfy backward
reﬁnement but would be of no use. However, full forward
reﬁnement doesn’t always hold for our micro-policies. In
particular, resource constraints that we prefer to ignore at the
abstract level (e.g., word size and memory capacity) become
visible at the symbolic or concrete level when tags and monitor
data structures are made explicit. Fortunately, in practice it is
reasonable to check that the lower-level machines are “live
enough” by testing.
Our main contributions are as follows. First, we introduce a
generic symbolic machine (§2-§3) for conveniently deﬁning and
effectively verifying a wide range of micro-policies for a simple