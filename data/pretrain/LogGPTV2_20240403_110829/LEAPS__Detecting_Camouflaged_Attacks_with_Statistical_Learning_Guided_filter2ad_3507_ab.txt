tinguishing instructions from data entries, dynamic loaded
libraries, obfuscation, binary packing, and the impracticality
of instrumenting real world binaries to collect ﬁne grained
dynamic execution information. Hence, we decide to derive
CFGs only from the application stack trace extracted from the
system event log. While the completeness of the inferred CFG
is dependent on the frequency of the system events and the
exercised functionality when logging is enabled, it is sufﬁcient
to produce an incomplete CFG that can approximately reﬂect
the general execution structure of the application. As we will
show later, we leverage a heuristic algorithm to predict the
missing parts of the benign CFGs and recognize malicious
payloads that do not belong to the original benign graphs.
Therefore, a unique advantage of LEAPS is that it only relies
on the system log, without analyzing the binaries.
We give a concrete example in Figure 3. For each indi-
vidual event, there is an application stack trace attached to
it. There are two events shown in this ﬁgure. For Event 1,
the application stack trace starts from Addr_1 to Addr_5.
Event 2 is the subsequent event and its stack trace becomes
different from Event 1 after Addr_3, which invokes Addr_6
and Addr_7. We are able to identify two types of control
ﬂow within the application stack trace. We call the ﬁrst type
of control ﬂow an explicit path, which indicates the function
invocations in the stack trace. For example, the execution path
from Addr_1 to Addr_2 is an explicit path. We call the other
type of control ﬂow an implicit path, which we infer from stack
traces of two adjacent events. In Figure 3, Addr_3 invokes
Addr_4 in Event 1 and Addr_6 in Event 2, which indicates
there is a control ﬂow from Addr_4 to Addr_6 in the program.
Based on these two criteria, we build the CFG incrementally
by enumerating all events and their application stack traces.
Algorithm 1 Control Flow Graph Inference
Input:
funcentry ← GEN_CFG
ast ← stack_trace_ﬁle
cfg ← empty_dict
while line do
if isEvent(line) then
if cfg.haskey(start) then
cfg[start].add(end)
1: procedure ADDTO_CFG(cfg, start, end)
2:
3:
4:
5:
6: procedure BRANCH_POINT(prev_stacklist, curr_stacklist)
7:
8:
9: procedure GEN_CFG(ast, cfg)
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
prev_stacklist := curr_stacklist
curr_stacklist.clear()
else if isStack(line) then
funcaddr := EXTRACT_FUNCADDR(line)
curr_stacklist.push(funcaddr)
line := ast.readline()
else
cfg[start] := set([end])
index := COMMON_PREFIX_LEN(prev_stacklist, curr_stacklist)
return index
branchidx := BRANCH_POINT(prev_stacklist, curr_stacklist)
ADDTO_CFG(cfg, prev_stacklist[branchidx], curr_stacklist[branchidx])
for i ∈ [0, LEN(stacklist)-1] do
ADDTO_CFG(cfg, curr_stacklist[i], curr_stacklist[i+1])
traces and add the implicit path in Line 13. In Line 15, we
add the explicit paths for all the function invocations within
one stack trace.
We apply this CFG inference algorithm on both the benign
application stack trace and the mixed application stack trace.
Thus we are able to generate two CFGs. Figure 4-(1) shows the
CFG of a benign execution of Vim, whereas Figure 4-(2) shows
the CFG of a trojaned Vim that contains the malicious payload
of a Reverse TCP Shell. By comparing these two CFGs (e.g.,
aligning nodes with the same address in two graphs), it is not
difﬁcult to identify that the left subgraph of the Vim mixed
CFG is similar to the Vim benign CFG because both use the
benign functionality of Vim. But the right subgraph of the
Vim mixed CFG is unique, indicating that this is more likely
to be from the anomalous execution caused by the malicious
payload. We point out that, although the CFG alone may be
used as a attack signature for detection, it is not robust enough
when encountering polymorphic malware in the real world.
This is the reason we introduce the statistical learning model
for a behavior-based attack detection system.
C. Weight Assessment
With the inferred benign CFG, we aim to assess the degree
of “benignity” for each event in the mixed dataset. We show
the algorithm for the weight assessment in Algorithm 2.
The input to this algorithm is the benign CFG and the
mixed CFG inferred from the application stack traces. When
building the CFG from the mixed application stack trace, we
also create a reverse mapping, named memap in Algorithm 2’s
input, from the program path to the event number.
We start by iterating each program path in the mixed CFG.
We check whether the start and end vertices of this path are
also connected in the benign CFG. If they are connected, we
assign 1 to the weight (whose range is [0, 1]) for this path.
Otherwise, it means this path does not exist in the benign
CFG.
We present the detailed algorithm in Algorithm 1. In Line
12, we ﬁnd the branch point by comparing two adjacent stack
As mentioned before, the inferred CFG is not complete.
It is possible that some paths in the mixed CFG are benign,
6060
Similar Subgraph
(1) Vim Benign Control Flow Graph
Anomalous Subgraph
(2) Vim Mixed Control Flow Graph (with Reverse TCP Shell as Payload)
Fig. 4: Comparison of (1) Vim Benign CFG and (2) Vim Mixed CFG
return True
return True
for end ∈ endset do
density_array.add(start)
density_array.add(end)
if CHECK_CFG(value, end, cfg, level) then
Algorithm 2 Weight Assessment
Input:
return False
if eventmap[key] (cid:5)= nil then:
valueset := cfg.get(start)
if valueset.empty() then
return False
level := level + 1
for value ∈ valueset do
return SORT(density_array)
if start = end ∧ level (cid:5)= 0 then
funcentry ← COMPARE_CFG
bcfg ← benign_cfg_dict
mcfg ← mixed_cfg_dict
memap ← mixed_event_dict
1: procedure GEN_CFG_DENSITY(cfg)
for start, endset ∈ cfg.iter() do
2:
3:
4:
5:
6:
7: procedure CHECK_CFG(start, end, cfg, level)
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18: procedure SET_WEIGHT(eventmap, key, weight, result)
19:
20:
21:
22:
23:
24:
25:
26: procedure ESTIMATE_WEIGHT(addr, density_array)
27:
28:
29:
30:
31: procedure COMPARE_CFG(bcfg, mcfg, memap)
32:
density_array := GEN_CFG_DENSITY(bcfg)
for start, endset ∈ mcfg.iter() do
33:
34:
35:
36:
37:
38:
39:
40:
41:
42:
for eventnum ∈ eventmap[key] do
if result[eventnum] = nil then
else
weight := 0
for end ∈ endset do
weight := 1
else
if CHECK_CFG(start, end, bcfg) then
result[eventnum] := {’weight’:weight, ’number’:1}
else
number := result[eventnum][’number’]
result[eventnum] := {REBALANCE(weight,number), number+1}
addr_idx := BISECT(density_array, addr)
mindiff := MIN(start - density_array[addr_idx-1], density_array[addr_idx] - addr)
weight := 1 - mindiff/(density_array[addr_idx] - density_array[addr_idx-1])
return weight
if WITHIN_RANGE(start, end, density_array) then
weight := ESTIMATE_WEIGHT(start, density_array)
SET_WEIGHT(memap, start+end, weight, result)
but missing in the benign CFG due to its incompleteness.
For example, some additional benign functionality might be
executed and recorded in the mixed system log, but not in
the benign system log. In order to address this problem, we
create a density array by inserting all the addresses of nodes
appearing in the benign CFG. For any path that is not in the
benign CFG, if it is in the range of this density array, we
estimate its weight based on its normalized distance to the
closest nodes in the benign CFG. For all other paths that
exceed the boundary of the density array, we assign 0 as
its weight. This weight assessment approach is based on the
observation that code close to the benign code is more likely
to be benign and code far away from the benign code is more
likely to be malicious. That is also the reason why LEAPS can
tolerate the incompleteness of the inferred CFG.
With the weight for each program path in the mixed CFG,
we search the reverse mapping memap to ﬁnd its corresponding
event number. Each event may have multiple paths mapped.
We compute the weight of each event by averaging all its
paths’ weights.
D. Binary Classiﬁcation Model
The building of the benign/malicious classiﬁcation model
is a key component in LEAPS. Given the benign dataset and
mixed dataset with assigned weights, our goal is to learn
an accurate binary classiﬁer from these training data. This
classiﬁer will be used to distinguish malicious events from
benign ones in the unseen testing data.
We build two binary classiﬁcation models for comparison.
The ﬁrst is purely based on the system-level function call graph
(with no statistical learning) and the second uses WSVM. We
discuss their strengths and weaknesses separately and compare
the results quantitatively in the evaluation section.
1) Decision Model Based on System-level Call Graph:
System-level behaviors, such as functions from shared libraries
6161
and the OS kernel, represent the interactions between appli-
cations and their underlying execution environment. These
features are widely adopted in anomaly detection systems
to reveal aberrant execution of the application. Conceptually
similar to existing system behavior based classiﬁcation systems
[23], [24], we build our ﬁrst classiﬁcation model based on the
system-level function call graph (built from the system stack
trace in the system event log). From the benign/mixed system
stack trace, we extract the function invocation chain from the
stack trace of each event. Thus we can build the two system-
level function call graphs, the benign call graph (BCG) and
mixed call graph (MCG), separately. We use the former as
the positive model and the latter as the negative model. In
the Testing Phase, we extract the call relations from the stack
trace in the testing data and check them in both the BCG and
MCG. We make a classiﬁcation decision for each individual
event based on the existence of such call relations in both call
graphs.
From the results presented in Section V, we ﬁnd that the
hit rates are low for classifying benign testing data for all
datasets. The ﬁrst reason for this is that the system-level call
graph model is not able to classify data points that do not
appear in the training set. The second reason is that the stack
traces of benign events may exist in both the BCG and MCG,
which make it difﬁcult for the model to accurately predict their
classes.
Furthermore, we ﬁnd that in some speciﬁc datasets (e.g.,
chrome_reverse_https and chrome_reverse_tcp), the hit rates
are also low for classifying malicious testing data. We manu-
ally check the events that lead to this problem. The main cause
is that some outlier points may greatly affect the classiﬁcation
decision. To give a speciﬁc example, consider a kernel function
invoked by both benign and malicious code. Assume the
benign code only calls the function once and the malicious
code calls it 1000 times, the corresponding function invocation
edges in both call graphs will be the same. Thus the call graphs
cannot yield any information of the invocation frequency.
Further assume that this function invocation appears in the
testing data. From a statistical perspective, this invocation is
likely to be from the malicious code, but it will be classiﬁed
as “undecidable” by the call graph model.
2) Weighted Support Vector Machine: Considering the lim-
itations of the call graph model above, we design a more
sophisticated binary classiﬁcation model based on statistical
learning. There are multiple machine learning techniques for
learning binary classiﬁers, such as Logistic Regression (LR)
[25], SVM [26], and Decision Tree [27]. Due to the dis-
criminative classiﬁcation power of SVM and its popularity,
we use SVM to build our classiﬁcation model. Furthermore,
to incorporate the weights assigned to the training data, we
employ a Weighted SVM method in this work to ﬁnd an
optimal classiﬁer by taking the conﬁdence of each data point
into consideration.
Suppose there are n training data points from both the
benign and mixed datasets, denoted D = {(xi, yi, ci), i =
1, . . . , n} where xi is the feature generated from data prepro-
cessing for the i-th data point and yi is its binary label. We
treat the benign data as positive samples, while the mixed data
are viewed as negative samples, i.e., yi = 1 for the benign data
and yi = −1 for the mixed data. ci corresponds to the weight.
Benign Points (+1)
Mixed Points (-1)
Original Decision Boundary
WSVM Decision Boundary
Decrease Weight 
Increase Weight 
Fig. 5: An illustration of the classiﬁers learned by the original
SVM model and the Weighted SVM model.
Note that the weight ci is a real value between 0 and 1. For the
benign data, the weight is simply 1. For the mixed data, we
obtain the weight from the weight assessment in Section III-C.
The purpose of the Weighted SVM is to learn a classiﬁer w,
which can accurately distinguish benign data from malicious
data. We give the formulation of the Weighted SVM as follows:
min
w,ξ
s.t.
(cid:2)
(cid:2)w(cid:2)2 + λ
ciξi
yiwT xi ≥ 1 − ξi
i
ξi ≥ 0
(2)
(cid:3)
here ξi is the classiﬁcation error of the i-th data point. wT xi
is the prediction score of xi based on the classiﬁer w, i.e., the
i ciξi
larger the value, the more likely xi is benign. The term
in the objective function is the total classiﬁcation loss/error
weighted by the importance of the data, which we are trying
to minimize. The term (cid:2)w(cid:2)2 is the regularizer on the classiﬁer
to avoid the overﬁtting problem [25], which is widely adopted
in statistical machine learning applications. λ is the trade-off
parameter to balance the two terms. The constraint enforces
that the prediction of the data point, wT xi, is consistent with
its label yi. For example, for a benign point with label yi = 1,
if the classiﬁer’s output, wT xi, is negative, then the model will
incur a large classiﬁcation error ξi due to this constraint.
Based on the generalized representer theorem [28], the
minimizer to the optimization problem in Eqn. 2 exists and
has a representation of the form:
wT xi =
αjyjk(xi, xj)
(3)
n(cid:2)
j=1
where k(xi, xj) is a kernel function deﬁned on the fea-
ture space. We use a Gaussian Kernel, k(xi, xj) =
exp(−(cid:6)xi−xj(cid:6)2
), in this work, and σ2 is the radius parameter.
Substituting Eqn. 3 into Eqn. 2, we can obtain an equivalent
problem:
σ2
min
α
(cid:2)
− (cid:2)
i
αi +
1
2
s.t.
αiαjyiyjk(xi, xj)
i,j
0 ≤ αi ≤ λci
(4)
The above optimization problem can be solved efﬁciently using
a quadratic programming solver. By minimizing this objective
function, we can achieve an optimal classiﬁer. We illustrate
the difference between the original SVM method and the
6262
Weighted SVM method in Figure 5. We can see from this
ﬁgure that the classiﬁer learned from the original SVM model
may misclassify benign points to malicious. The reason is
that a certain amount of mixed data points actually belong
to benign events. By minimizing the classiﬁcation error on
these mislabeled data points,
the SVM classiﬁer does not
perform well especially on benign data. On the other hand, by
assigning proper weights via CFG guidance (i.e., decreasing
the weights of mislabeled points and increasing the weights of
true malicious points), the classiﬁer learned from the Weighted
SVM distinguishes the benign points from the malicious ones
more accurately.
In the Testing Phase, we apply the learned classiﬁcation
model to the testing data xt to give the prediction as follows:
yt = wT xt =
n(cid:2)
i=1
αiyik(xi, xt)
(5)
where xt is classiﬁed as malicious if yt < 0.
IV.
IMPLEMENTATION
We leverage the Event Tracing for Windows (ETW) [29]