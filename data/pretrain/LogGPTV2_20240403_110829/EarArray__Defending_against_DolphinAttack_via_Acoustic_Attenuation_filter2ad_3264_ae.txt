### Figure 17(d) Analysis
The plot in Fig. 17(d) indicates that the accuracy was above 96.8% and was slightly affected by angles, particularly when the angle was between 120 and 150 degrees. This is likely due to the minimal difference in acoustic attenuation among the three channels when the speaker is at these positions, which can reduce the overall accuracy. In summary, EarArray also demonstrates good performance on smartphones even with a reduced number of microphones (down to three). As the number of microphones increases and they are placed around the device facing different directions, the acoustic attenuation is measured more comprehensively, leading to better performance.

### VI. Related Work

#### A. Audible Attacks on Voice Control Systems (VCSs)
As Voice Control Systems (VCSs) become increasingly important in daily life, cyber attacks against them have gained significant attention. These attacks can be categorized into two types: audible and inaudible. 

**Inaudible Attacks:** The attacker approaches the victim and plays recorded audio, which is typically generated in a way that is incomprehensible to humans but understandable to the device. In inaudible attacks, malicious voice commands are modulated on ultrasonic carriers, making them inaudible to human ears but still receivable by microphones due to nonlinear effects in microphone circuits. These attacks are imperceptible to the user.

**Audible Attacks:** While theoretically feasible, audible attacks have practical limitations. The audio used for such attacks is often distinguishable from white noise. Researchers have explored the use of Generative Adversarial Networks (GANs) to generate incomprehensible audio commands that appear as random noise [25], [28]. For example, one study [26] proposed hiding executable voice commands in adversarial audio that sounds like simple music to humans. Nicholas et al. [10], [11] demonstrated that targeted audio adversarial examples can be generated by modifying existing audio, introducing a new domain for studying adversarial examples. Metamorph achieves over-the-air attacks based on this work.

**Defenses Against Audible Attacks:** As speech biometrics recognition replaces traditional identification technologies, Automatic Speaker Verification (ASV) systems have been developed to defend against VCS attacks. However, replay attacks, where pre-recorded audio is played back, remain a significant threat. Villalba et al. [30] highlighted vulnerabilities in ASV systems to far-field replay attacks. Witkowski et al. [32] suggested detecting replay attacks by analyzing high-frequency bands in the replayed recordings. Zeyan et al. [33] improved the detection of replay attacks by proposing new auditory filter-based relative phase features. Lee et al. [12] introduced a sonar-based liveness detection system, Speaker-Sonar, which emits inaudible sound to track the user's direction and compare it with the direction of the received voice command. If the attack is launched by a nearby moving attacker, this method may fail.

#### B. Inaudible Attacks on VCSs
Kasmi et al. [34] introduced a new type of voice command injection using intentional electromagnetic interference with headphone cables, though this attack requires the device to be plugged into a smartphone. DolphinAttack [14], [5], [8] translates audible voice commands into ultrasonic frequencies, making them inaudible to humans but still decipherable by microphones and always-on voice assistants. Defense strategies include software-level methods based on audio feature extraction [14], [5]. However, these methods are device-dependent, as signal features vary significantly across different microphones. For instance, amplitude skewness, a key feature for nonlinearity, is valid for some devices like the Samsung Galaxy S6 Edge+ but not for others like the iPhone 4S and iPhone SE [35].

Light Commands [6] use light to inject commands into voice-controlled systems by aiming an amplitude-modulated light at the microphone's aperture. To detect light-based command injection, signals from multiple microphones or a barrier film before the microphone diaphragm can be used. EarArray can also detect Light Commands by monitoring the signal received by multiple microphones. SurfiingAttack [9] uses ultrasound propagation in solid media, leveraging nonlinearity to demodulate and recognize the ultrasound signal. By monitoring high-frequency components, SurfiingAttack can be detected. Unlike these methods, EarArray utilizes the difference in propagation attenuation between ultrasound and sound to detect attacks. UltraComm [4] proposes an acoustic communication approach that leverages the nonlinearity effect of microphones to transmit modulated data above 20 kHz and recover it in the audible frequency band.

### VII. Conclusion and Future Work
Voice assistants have brought convenience to our daily lives but have also exposed us to various malicious attacks using inaudible voice commands. In this paper, we proposed EarArray, a lightweight mechanism to defend against inaudible voice command attacks. We analyzed the attenuation properties of audible and inaudible voice commands and proposed using sound field distribution as a feature to differentiate between normal and inaudible commands. Our experiments show that EarArray can achieve 99% accuracy in attack detection and 97.89% localization accuracy for inaudible voice commands.

Future work will focus on overcoming the limitation of mobile phones reading multi-channel data simultaneously, extracting field patterns from different voice assistant devices, and generalizing our defense algorithm for all voice assistant devices.

### Acknowledgment
We would like to thank our reviewers for their valuable comments, which significantly improved our paper. Special thanks to Bo Yang, Weizhen He, Dingkui Liu, and Ruihao Mao for their help in simulations and experiments. This work is supported by China NSFC Grants 61925109, 61941120, 62071428, and ZJNSF Grant LGG19F020020. Gang Qu's work was done during his visit to Zhejiang University as a Qiushi Chair Professor.