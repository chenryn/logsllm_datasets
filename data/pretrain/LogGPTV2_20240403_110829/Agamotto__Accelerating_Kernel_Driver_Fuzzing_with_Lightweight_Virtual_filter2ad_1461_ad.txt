from the baseline.
5.2 Delta Restore
Run-Time Overhead. Figure 7 shows the run-time over-
head of our implementation of the delta restore algorithm de-
pending on the number of pages that are restored when restor-
ing a 512MiB memory virtual machine. We used QEMU’s
default restoration mechanism as the baseline, which restores
a virtual machine state from a non-incremental, full snapshot
image. The smaller the number of restored pages as computed
by our delta restore algorithm, the less time it takes to restore
USENIX Association
29th USENIX Security Symposium    2549
IncrementalQEMUSnapshot(Baseline)Table 2: USB and PCI fuzzing targets.
Target
USB
(§5.3)
PCI
(§5.4)
Path (/drivers/...)








RSI
MWIFIEX
AR5523
BTUSB
PN533
GO7007
SI470X
USX2Y
ATLANTIC
RTL8139
STMMAC
SNIC
net/wireless/rsi
net/wireless/marvell/mwiﬁex
net/wireless/ath/ar5523
bluetooth/btusb.c
nfc/pn533
media/usb/go7007
media/radio/si470x
sound/usb/usx2y
net/ethernet/aquantia
net/ethernet/realtek
net/ethernet/stmicro
scsi/snic




a virtual machine state. The number of restored pages, as
observed in actual fuzzing runs, is signiﬁcantly lower than
the total number of pages in memory (see Section 5.3). With
an average number of under 8,000 restored guest and device
memory pages, our delta restore implementation can restore
the virtual machine in 12.5ms on average, 8.9 times faster than
the baseline, QEMU’s implementation of the full snapshot
restore approach, which takes 112ms on average.
5.3 Syzkaller-USB Fuzzing
Experimental Setup. We fuzzed USB drivers individually,
one in each experiment. We chose 8 USB drivers, as shown
in Table 2, which include drivers (i) of 5 different classes, (ii)
of different numbers of source lines of code, and (iii) from
different vendors. We ran 32 fuzzing instances for three hours
in fuzzing each driver. Each instance fuzzed the driver running
in a 512MiB memory virtual machine.
We enabled all USB related functions and constrained the
parameters of syz_usb_connect—i.e., device and interface
descriptors—to fuzz the drivers individually in each exper-
iment. To minimize the effects of non-determinism in our
experiment, we limited coverage instrumentation to the driver
code as well as generic kernel code that drivers call into.4
The fuzzing algorithm of Syzkaller was not modiﬁed. We
only increased Syzkaller’s default ﬁve-second timeout to ten
seconds to encourage deeper exploration.5 We started fuzzing
without any seed input to eliminate its impact on the results.
To minimize the randomness inherent in fuzzing algorithms,
we used different but ﬁxed sets of PRNG seed values for
different instances, using the equation, {idinst + #crashesinst ∗
128} where inst = {0,1, ...,31}. This equation ensures that
seed values (i) are always unique across instances, and (ii)
4We instrumented the source code under the following directories: drivers,
sound/{usb, core}, and net/{bluetooth, nfc, wireless}.
5We followed Syzkaller’s default timeout model, where each test case can
execute for at most three seconds, but, as long as the last action has returned
within last one second, it can execute up to ten seconds.
y
c
n
e
u
q
e
r
F
0
1
2
3
4
5 (s)
0
1
2
3
4
5 (s)
(a) Agamotto execution time
(b) Normal execution time
Figure 8: Distribution of the execution time per test case in
Syzkaller-USB fuzzing.
change after each kernel crash. With these adjustments, the
randomness of Syzkaller’s fuzzing algorithm was controlled;
note, however, that the randomness originating in the target
system, e.g., coverage signal, was not controlled. To account
for this randomness, we ran each experiment three times.
We ran two different versions of Agamotto—(i) a full-
ﬂedged Agamotto and (ii) Agamotto with only the root check-
point enabled (Agamotto-R)—to quantify the effectiveness
of checkpoints dynamically created by Agamotto. We used
Syzkaller as a baseline, only with the aforementioned changes
for controlling timeout and randomness. We conﬁgured Ag-
amotto with the following additional parameters: The check-
point pool size was conﬁgured to be 12GiB per instance, and
we used 500ms as the initial checkpoint creation interval.
Execution Time of Individual Test Cases. Figure 8 shows
how much time Agamotto skips in executing each test case.
By using ﬁne-grained checkpoints created by Agamotto, the
initial parts of many test cases were skipped. We measured
each test case’s execution time in all experiments (Figure 8a)
and computed each test case’s normal execution time, the
time each test case execution could have taken if ﬁne-grained
checkpoints were not used (Figure 8b). Agamotto successfully
reduced the execution time of many test cases—a large portion
of test cases took less than a second with Agamotto, as shown
in Figure 8a.
Overall Fuzzing Throughput. Figure 9 illustrates how
much Agamotto improves Syzkaller’s USB fuzzing through-
put. This overall fuzzing throughput includes the overhead of
Agamotto itself. One common trend observed in all experi-
ments is that Agamotto’s fuzzing throughput peaks in the ﬁrst
10 minutes. This is because, as fuzzing instances are started,
lots of test cases producing new coverage were discovered
and minimized. Each minimized test case was then mutated
100 times and executed in a row. During this period of time in
which new inputs were frequently discovered, a large number
of similar test cases were executed in a row, the throughput
of which was greatly improved by Agamotto. As the fuzzing
continued, coverage-increasing test cases were seldom discov-
ered, stabilizing the throughput. Still, Agamotto’s throughput
2550    29th USENIX Security Symposium
USENIX Association
(a) RSI
(b) MWIFIEX
(c) AR5523
(d) BTUSB
(e) PN533
(f) GO7007
(g) SI470X
(h) USX2Y
Figure 9: Syzkaller-USB fuzzing throughput (execs/second) measured every 10 minutes for 3 hours.
Table 3: Checkpoint hit and guest execution time statistics.*
Guest Exec. Time
# Checkpoints
# Executions
Created Evicted Total
Hit
(Rate)
Total
Skipped
(Rate**)
RSI
MWIFIEX
AR5523
BTUSB
PN533
GO7007
SI470X
USX2Y
Geo. Mean
ATLANTIC
RTL8139
STMMAC
SNIC
Geo. Mean
87k
19k
91k
74k
89k
105k
88k
92k
8.4k
17.9k
4.8k
4.0k
63k 201k 120k (59%) 90.3h
9.8k 236k
60k (25%) 28.0h
71k 201k 116k (57%) 95.0h
59k 254k 145k (57%) 94.7h
65k 199k 116k (58%) 95.2h
83k 201k 126k (62%) 95.1h
67k 223k 130k (58%) 94.9h
76k 195k
90k (46%) 95.0h
51.5%
42.1h (31%)
18.3h (39%)
38.6h (28%)
47.1h (33%)
39.7h (29%)
44.5h (31%)
43.6h (31%)
29.4h (23%)
30.9%
18.5h (22%)
43k (22%) 95.2h
0.6k 191k
78.9h (46%)
6.5k 272k 128k (47%) 91.5h
0.3k 160k
15.9h (14%)
23k (14%) 95.2h
0.2k 153k 8.3k (5.4%) 95.3h 5.35h (5.3%)
17.0%
16.7%
* Median values from 3 independent runs.
** Skipped/(Skipped+Total)
was consistently higher than the baseline. Of the eight ana-
lyzed drivers only two experienced kernel crashes (MWIFIEX
and RSI). The performance improvement of the remaining tar-
gets is therefore solely due to the reduced average execution
time by using the checkpoints created by Agamotto.
Checkpoint Utilization and Effectiveness. We identify a
checkpoint hit as selecting a non-root checkpoint in executing
a test case, and a checkpoint miss as selecting the root check-
point. The hit rate refers to the portion of executions that had
a checkpoint hit among all executions. At each checkpoint
hit, a different amount of time is skipped depending on the
checkpoint used. Table 3 summarizes the hit rates, as well
as the amounts of the guest execution time skipped in each
fuzzing experiment. The hit rates and time skip rates vary
depending on the driver targeted in each experiment; on av-
erage, we achieved 51.5% of hit rate, saving 30.9% in guest
execution time.
To quantify the effectiveness of multiple checkpoints cre-
ated by Agamotto, we compare the throughput of Agamotto
and Agamotto-R; the throughput was improved by 38% on
average. The shape of the checkpoint tree used to achieve this
improvement is characterized in Figure 10. The depths of the
checkpoint nodes—i.e., the number of edges from the root
node—created and evicted by Agamotto ranged from 1 to
3, and the resulting checkpoint trees had an average branch-
ing factor of 175. This large branching factor reﬂects (i) how
Syzkaller explores the input space, and (ii) that our checkpoint
management policies favor checkpoint nodes of lower depths
in the checkpoint tree. In these checkpoint trees, the length of
the restoration path—i.e., the path from the node representing
the dirty system state after each test case execution to the node
being restored—ranged from 1 to 6, as shown in Figure 11.
The widely ranging lengths of the restoration paths mean that
different checkpoints created at various depths were actively
used for virtual machine restoration, which also supports the
utility of multiple checkpoints created by Agamotto.
Resilience to Kernel Panics. Agamotto found several
known bugs in RSI and MWIFIEX that were already found
and reported in earlier kernel versions by Syzbot [62], but left
unﬁxed. Agamotto found one unknown bug in MWIFIEX.
This bug was not found in the baseline (nor Syzbot), as it
was obscured by a known, shallow bug in MWIFIEX, which
repeatedly caused immediate kernel panics in the baseline. In
contrast, since Agamotto puts the fuzzer outside the virtual
USENIX Association
29th USENIX Security Symposium    2551
AgamottoAgamotto-RSyzkaller(Baseline)012301020012301020012305101520012301020012301020012301020012301020012301020h
t
p
e
D
1
2
3
1
2
3
101
103
105
101
103
105
# of checkpoints
# of checkpoints
(a) Created checkpoints
(b) Evicted checkpoints
USX2Y
SI470X
GO7007
PN533
BTUSB