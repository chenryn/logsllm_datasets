title:ICLab: A Global, Longitudinal Internet Censorship Measurement Platform
author:Arian Akhavan Niaki and
Shinyoung Cho and
Zachary Weinberg and
Nguyen Phong Hoang and
Abbas Razaghpanah and
Nicolas Christin and
Phillipa Gill
ICLab: A Global, Longitudinal
Internet Censorship Measurement Platform
Arian Akhavan Niaki∗† Shinyoung Cho∗†‡ Zachary Weinberg∗§
Nguyen Phong Hoang‡ Abbas Razaghpanah‡ Nicolas Christin§ Phillipa Gill†
§Carnegie Mellon University
{zackw, nicolasc}@cmu.edu
†University of Massachusetts, Amherst
{arian, shicho, phillipa}@cs.umass.edu
‡Stony Brook University
{shicho, nghoang, arazaghpanah}@cs.stonybrook.edu
Abstract—Researchers have studied Internet censorship for
nearly as long as attempts to censor contents have taken place.
Most studies have however been limited to a short period of time
and/or a few countries; the few exceptions have traded off detail
for breadth of coverage. Collecting enough data for a compre-
hensive, global, longitudinal perspective remains challenging.
In this work, we present ICLab, an Internet measurement
platform specialized for censorship research. It achieves a new
balance between breadth of coverage and detail of measurements,
by using commercial VPNs as vantage points distributed around
the world. ICLab has been operated continuously since late
2016. It can currently detect DNS manipulation and TCP packet
injection, and overt “block pages” however they are delivered.
ICLab records and archives raw observations in detail, making
retrospective analysis with new techniques possible. At every stage
of processing, ICLab seeks to minimize false positives and manual
validation.
Within 53,906,532 measurements of individual web pages,
collected by ICLab in 2017 and 2018, we observe blocking of
3,602 unique URLs in 60 countries. Using this data, we compare
how different blocking techniques are deployed in different
regions and/or against different types of content. Our longitudinal
monitoring pinpoints changes in censorship in India and Turkey
concurrent with political shifts, and our clustering techniques
discover 48 previously unknown block pages. ICLab’s broad
and detailed measurements also expose other forms of network
interference, such as surveillance and malware injection.
I. Introduction
For the past 25 years, the Internet has been an important
forum for people who wish to communicate, access information,
and express their opinions. It has also been the theater of
a struggle with those who wish to control who can be
communicated with, what information can be accessed, and
which opinions can be expressed. National governments in
particular are notorious for their attempts to impose restrictions
on online communication [29]. These attempts have had
unintentional international consequences [9], [15], [56], [78],
and have raised questions about export policy for network
management products with legitimate uses (e.g., virus detection
and protection of confidential information) that can also be
used to violate human rights [26].
The literature is rich with studies of various aspects of
Internet censorship [6], [7], [8], [9], [10], [15], [17], [23],
[25], [26], [34], [36], [37], [43], [48], [56], [61], [64], [65],
[66], [72], [76], [78], [79], [88], [89] but a global, longitudinal
baseline of censorship covering a variety of censorship methods
∗Authors contributed equally
remains elusive. We highlight three key challenges that must
be addressed to make progress in this space:
Challenge 1: Access to Vantage Points. With few ex-
ceptions,1 measuring Internet censorship requires access to
“vantage point” hosts within the region of interest.
The simplest way to obtain vantage points is to recruit
volunteers [37], [43], [73], [80]. Volunteers can run software
that performs arbitrary network measurements from each
vantage point, but recruiting more than a few volunteers per
country and retaining them for long periods is difficult. Further,
volunteers may be exposed to personal risks for participating
in censorship research.
More recently, researchers have explored alternatives, such
as employing open DNS resolvers [66], [72], echo servers [79],
Web browsers visiting instrumented websites [17], and TCP
side channels [32], [65]. These alternatives reduce the risk
to volunteers, and can achieve broader, longer-term coverage
than volunteer labor. However, they cannot perform arbitrary
network measurements; for instance, open DNS resolvers can
only reveal DNS-based censorship.
Challenge 2: Understanding What to Test. Testing a single
blocked URL can reveal that a censorship system exists within
a country, but does not reveal the details of the censorship
policy, how aggressively it is enforced, or all of the blocking
techniques used. Even broad test lists, like those maintained
by the Citizen Lab [22], may be insufficient [28]. Web pages
are often short-lived, so tests performed in the present may be
misleading [84].
Challenge 3: Reliable Detection. Censors can prevent access
to content in several different ways. For instance, censors
may choose to supply “block pages” for some material, which
explicitly notify the user of censorship, and mimic site outages
for other material (see §II-C) [27], [43].
Many recent studies focus on a single technique [17], [32],
[65], [66], [72], [79]. This is valuable but incomplete, because
censors may combine different techniques to filter different
types of content.
As the Internet evolves and new modes of access appear
(e.g., mobile devices), censorship evolves as well, and monitor-
ing systems must keep up [6], [59]. Ad-hoc detection strategies
without rigorous evaluation are prone to false positives [89].
1China filters inbound as well as outbound traffic, making external
observation simpler.
For example, detecting filtering via DNS manipulation requires
care to deal with CDNs [66], [72] and detection of block pages
requires taking regional differences in content into account [48].
A. Contributions
We present ICLab, a censorship measurement platform that
tackles these challenges. ICLab primarily uses commercial
Virtual Private Network servers (VPNs) as vantage points, after
validating that they are in their advertised locations. VPNs offer
long-lived, reliable vantage points in diverse locations, but still
allow detailed data collection from all levels of the network
stack. ICLab also deploys volunteer-operated devices (VODs)
in a handful of locations.
ICLab is extensible, allowing us to implement new experi-
ments when new censorship technologies emerge, update the
URLs that are tested over time, and re-analyze old data as
necessary. To date ICLab has only been used to monitor
censorship of the web, but it could easily be adapted to monitor
other application-layer protocols (e.g., using techniques such
as those in Molavi Kakhki et al. [59]). Besides ICLab itself,
and its collected data, we offer the following contributions:
Global, longitudinal monitoring. Since its launch in 2016,
ICLab has been continuously conducting measurements in 62
countries, covering 234 autonomous systems (ASes) and testing
over 45,000 unique URLs over the course of more than two
years. The platform has detected over 3,500 unique URLs
blocked using a variety of censorship techniques. We discuss
our discoveries in more detail in Section V.
Enhanced detection accuracy.
ICLab collects data from all
levels of the network stack and detects multiple different types
of network interference. By comparing results across all the
detection techniques, we can discover inaccuracies in each and
refine them. We have eliminated all false positives from our
block page detector. DNS manipulation detection achieves a
false positive rate on the order of 10−4 when cross-checked
against the block page detector (see Section IV-A). Similar
cross-checking shows a negligible false positive rate for TCP
packet injection (see Section IV-B).
Semi-automated block page detection. We have developed a
new technique for discovering both variations on known block
pages and previously unknown block pages. These explicit
notifications of censorship are easy for a human to identify, but
machine classifiers have trouble distinguishing them from other
short HTML documents expressing an error message. Existing
systems rely on hand-curated sets of regular expressions, which
are brittle and tedious to update.
ICLab includes two novel machine classifiers for short error
messages, designed to facilitate manual review of groups of
suspicious messages, rather than directly deciding whether
each is a block page. Using these classifiers we discovered 48
previously undetected block page signatures from 13 countries.
We describe these classifiers and their discoveries in more
detail in Section IV-C.
II. Background
Here we briefly review the techniques used to block access
to information online, two different options for implementation,
and how the censor’s goals affect their implementation choices.
A. Network-level blocking techniques
Abstractly, all attempts to interfere with website access
are man-in-the-middle (MITM) attacks on communications
between a web browser and server. Depending on the location
and configuration of their MITM devices, censors may interfere
with traffic outside the borders of their own authority [15], [36],
[78].
DNS manipulation. When visiting a website, the user’s
browser must first resolve the web server’s IP address using
DNS. DNS traffic is unencrypted, and less than 1% of it is
authenticated [81]. Using either DNS servers they control, or
packet injection from routers, censors can forge responses carry-
ing DNS error codes such as “host not found” (NXDOMAIN),
non-routable IP addresses, or the address of a server controlled
by the censor [8], [91].
IP-based blocking. Once the browser has an IP address of a
web server, it makes a TCP connection to that server. Censors
can discard TCP handshake packets destined for IP addresses
known to host censored content, reply with a TCP reset packet,
or reroute them to a server controlled by the censor [46].
TCP packet injection. Censors can also allow the TCP
handshake to complete, and then inject a packet into the
TCP stream that either supersedes the first response from the
legitimate server, or breaks the connection before the response
arrives [82]. For unencrypted websites, this technique allows
the censor to observe the first HTTP query sent by the client,
and thus block access to individual pages [24].
Transparent proxy. Censors wishing to exercise finer control
can use a “transparent proxy” that intercepts all HTTP traffic
leaving the country, decodes it, and chooses whether or not
to forward it [26]. Transparent proxies act as TCP peers and
may modify HTTP traffic passing through, which makes them
detectable [83]. They permit fine-grained decisions about how
to block access to content. However, they are specific to
unencrypted HTTP and cannot be used to censor traffic in
any other protocol.
B. On-path and in-path censors
Hardware performing DNS manipulation, IP-based blocking,
or TCP packet injection can be connected to the network in two
different ways. It is not known which option is more commonly
used [44], [80].
On-path equipment observes a copy of all traffic passing
through a network link. It can react by injecting packets into
the link, but cannot modify or discard packets that are already
within the flow. While on-path techniques are relatively cheap
and easy to deploy, detection is also easy, as injected packets
appear alongside legitimate traffic.
In-path equipment operates on the actual traffic passing
through the network link, and can inject, modify, or discard
packets. In-path equipment must operate at the line-rate of a
backbone router, so it is more expensive and its features may
be limited (e.g., payload inspection may not be an option), but
it is harder to detect.
C. Overt and covert censorship
Censorship’s visible effects can be either overt or covert.
In overt censorship, the censor sends the user a “block page”
instead of the material that was censored. In covert censorship,
the censor causes a network error that could have occurred
for other reasons, and thus avoids informing the user that
the material was censored. Censors may choose to be overt
for some material and covert for other material. For instance,
Yemen has been observed to overtly block pornography, which
is illegal there, and to covertly block disfavored, but legal,
political content [43].
Overt censorship can be accomplished with a transparent
HTTP proxy, an injected TCP packet or DNS response that
directs the browser to a server controlled by the censor, or
by rerouting TCP traffic to a server controlled by the censor.
Covert censorship can be accomplished with a transparent
HTTP proxy, an injected TCP reset packet, an injected DNS
error or non-routable address, or by discarding packets.
III. System Architecture
ICLab is a platform for measuring censorship of network
traffic. As shown in Figure 1, it consists of a central control
server and a set of vantage points distributed worldwide. The
central server schedules measurements for each vantage point
to perform, distributes test lists, and collects measurement
results for analysis. The vantage points send and receive
network traffic to perform each measurement, and upload their
observations to the central server. All analysis is done centrally
after the measurements have completed. Raw observations,
including complete packet logs, are archived so that new
analysis techniques can be applied to old data. There are two
types of vantage points: volunteer-operated devices (VODs)
configured by us and installed in locations of interest by
our volunteers,2 and VPN-based clients, which forward traffic
through commercial VPN proxies located in various countries.
A. Design Goals
We designed ICLab to achieve the following properties:
Global, continuous monitoring. The techniques used for
Internet censorship, the topics censored, and the thoroughness
with which censorship is enforced are known to vary both
among [16], [26], [28], [43], [44], [66] and within [1],
[33], [51], [86], [88] countries. Therefore, the system should
operate vantage points in multiple locations within each of
many countries, to produce a comprehensive global view of
censorship. Censorship may ratchet upward over time [29], [39],
may change abruptly in response to political events [25] and
may even cease after governing parties change [43]. Therefore,
the system should perform its measurements continuously over
a period of years, to detect these changes as they happen.
2Most of these are low-cost Raspberry Pi devices.
Fig. 1. Architecture of ICLab. (1) The central server sends a measurement
schedule along with an associated test list to vantage points. (2) The vantage
points perform measurements. (3) Collected data is uploaded to the central
server. (4) Censorship detection is done centrally.
Reproducible and extensible. The basic techniques for cen-
soring network traffic (described in §II-A) are well-known [80],
[82] but new variations appear regularly [6], [36]. The short
lifetime of “long tail” content means that the current content
of a website may bear no relationship to what it was when it
was originally censored [84]. Therefore, the system needs to be
extensible with new types of measurement, and should record
as much information as possible with each measurement (e.g.,
packet traces and detailed contextual information).
Minimal risk to volunteers. Censorship monitoring involves
accessing material that is forbidden in a particular country,
from that country, and provoking a response from the censor.
The response we expect is one of the MITM attacks described
in §II-A, but legal or extralegal sanctions aimed at the volunteer
operating the vantage point are also possible. The risk may be
especially significant for volunteers already engaged in human
rights reporting or advocacy. Use of commercial VPNs as
vantage points is intended to mitigate these risks. VODs are
only deployed in locations where we believe legal or extralegal
sanctions are unlikely, and we obtain informed consent from
the volunteers who operate them.
B. Vantage Points
Of ICLab’s 281 vantage points, 264 are VPN-based, obtain-
ing access to locations of interest via commercial VPN services.
17 vantage points are VODs. The measurement software is
the same for both types of vantage; the only difference is that
VPN-based vantages route their traffic through a VPN while
performing measurements.
VPN-based vantages. ICLab uses VPN-based vantages when-
ever possible, because of their practical and ethical advantages.
We do not need to recruit volunteers from all over the world,
or manage physical hardware that has been distributed to them,
but we still have unrestricted access to the network, unlike,
for instance, phone or web applications [17], [37]. The VPN
operator guarantees high availability and reasonable bandwidth,
and they often offer multiple locations within a country. For
75% of the countries where we use VPN-based vantages, the
Vantage points (worldwide: 264 VPNs, 17 volunteers)Oct. 2016 ∼ presentCentral serverVPN clientsWeb sites beingtested for censorshipVPN servervantageControlvantageVolunteervantage(4)Collected datato censorshipdetectors(3) Collected dataDNS Query/ResponseHTTP Request/ResponseTLS CertiﬁcatesTraceroutesPacket Logs(1) Schedule and URL list(varies by country) VPN protocol(2) Perform measurements on a URL listDNSHTTPTracerouteVPNs give us access to at least two ASes within that country
(see Appendix A).
On the ethical side, a commercial VPN operator is a company
that understands the risks of doing business in each country it
operates in. It is unlikely that they would deploy a server in
a country where the company or its employees might suffer
legal or extralegal sanctions for the actions of its users.
A disadvantage of VPNs is that they only supply a lower
bound on the censorship experienced by individuals in each
country, because their servers are hosted in commercial data
centers. There is some evidence that network censorship is less
aggressively performed by data centers’ ISPs than by residential
ISPs [3], [88]. According to the CAIDA AS classification [18],
41% of the networks hosting our VPN-based vantages are
“content” networks, which are the most likely to be subject to
reduced levels of censorship. However, we have visibility into
at least one other type of AS in 83% of the countries we can
observe. In countries where we have both VPNs and VODs,