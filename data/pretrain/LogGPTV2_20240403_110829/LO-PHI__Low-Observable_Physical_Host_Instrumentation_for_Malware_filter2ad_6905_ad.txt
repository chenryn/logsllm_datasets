Table
0
0
0
Entry Index
0x0000f7
0x0000ad
0x000091
Address
0xf7c5b406
0xf7c5b44c
0xf7c5b554
Name
NtSetValueKey
NtQuerySystemInformation
NtQueryDirectoryFile
Module
hookssdt.sys
hookssdt.sys
hookssdt.sys
Created Filename
/. . . /lophi/$$ rk sketchy server.exe
/. . . /lophi/hookssdt.sys
/. . . /lophi/sample 0742475e94904c41de1397af5c53dff8e.exe
(e) SSDT Hooks (ssdt)
(f) Disk Event Log (81 Entries Truncated)
Fig. 6: Post-ﬁltered semantic output from rootkit experiment (Section VII-C1).
B. Filtering Background Noise
While the ability to provide a complete log of modiﬁcations
to the entire system is useful in its own right, it is likely more
relevant to extract only those events that are attributed to the
binary in question. To ﬁlter out the activity not attributed to
a sample’s execution, we ﬁrst build a controlled baseline for
both our physical and virtual SUTs by creating a dataset (10
independent executions in our case) using a benign binary
(rundll32.exe with no arguments). We then use our analysis
framework to extract all of the system events for those trials
and created a ﬁlter based on the events that frequently occurred
in this benign dataset. Two of our memory analysis modules,
i.e., ﬁlescan and timers, had particularly high false positives
and proved less useful for our automated analysis. To reduce
false positives in our disk analysis, we decouple the ﬁlenames
from their respective master ﬁle table (MFT) record number.
C. Experiment 1: High-ﬁdelity Output
To verify that LO-PHI is, in fact, capable of extracting be-
haviors of malware, we ﬁrst evaluated our system with known
malware samples, for which we have ground truth. In our ﬁrst
case study, we evaluated a rootkit that we developed utilizing
techniques from The Rootkit Arsenal [15] (Section VII-C1).
Similarly, we were able to obtain a set of 213 malware samples
that were constructed in a cleanroom environment, and were
accompanied by their source code with detailed annotations.
All the binaries in this experiment were executed on both
physical and virtual machines that were running Windows XP
(32bit, Service Pack 3) as their operating system.
1) Homemade Rootkit: Our rootkit stealths itself by adding
hooks to the Windows Global Descriptor Table (GDT) and
System Service Dispatch Table (SSDT) that will hide any
directory or running executable with the preﬁx $$ rk and then
opens a malicious FTP server. The rootkit module is embedded
inside a malicious PDF ﬁle that drops and loads a mali-
cious driver ﬁle (hookssdt.sys) and the FTP server executable
($$ rk sketchy server.exe). Figure 6 shows the complete post-
ﬁltered results obtained when running this rootkit through our
framework. Note that we received identical results for both
virtual and physical machines, which exactly matches what
we would expect given our ground truth. We clearly see our
rootkit drop the ﬁles to disk (Figure 6f), load the kernel model
(Figure 6d), hook the kernel (Figure 6e and Figure 6c), and
then execute our FTP server (Figure 6a and Figure 6b). We
have omitted the creation of numerous temporary ﬁles by
Adobe Acrobat Reader and Windows as well as accesses to
existing ﬁles (81 total events) in Figure 6f to save space,
however all disk activity was successfully reconstructed. Note
that we can trivially detect the presence of the new process
as we are examining physical memory and are not foiled by
execution-level hooks.
We also ran our rootkit on the Anubis and Cuckoo analysis
frameworks. Anubis failed to execute the binary, likely due
to the lack of Acrobat Reader or some other dependencies.
Cuckoo produced an analysis with very similar ﬁle-system-
level output to ours, reporting 156 ﬁle events, compared to
our 81 post ﬁltered. However, we were unable to ﬁnd our
listening socket, or our GDT and SSDT hooks from analyzing
their output. While our FTP server was deﬁnitely executed,
and thus created a listening socket on port 21, it is possible
that our kernel module may not have executed properly on
their analysis framework. Nevertheless, we feel that our ability
to introspect memory to ﬁnd these obvious tells of malware,
is a notable distinction. Subsequently, the lack of execution
for such a simple rootkit also emphasizes the importance of
having a realistic software environment as well as a hardware
environment. We attempt to address this issue for our analysis
in Section VII-E.
2) Labeled Malware: For the analysis of our 213 well-
annotated malware samples, we ﬁrst performed a blind analy-
sis, and then later veriﬁed our ﬁndings with the labels. Note
that there were samples that exhibited more behaviors than
those listed here, only the most interesting ﬁndings are shown.
a) VM-detection: We found that 66 of these sam-
ples were labeled as employing either anti-VM or anti-
debugging capabilities. However, none of the 66 anti-VM sam-
ples performed QEMU-KVM detection; instead they focused
on VMWare, VirtualPC, and other virtualization suites. As
expected, all of the samples executed their full payload in both
our virtual and physical analysis environments.
b) New Processes: We found that 79 of the samples
created new long-running processes detected by our memory
analysis. The most commonly created process was named
svchost.exe, which occurred in 15 samples. In addition, 2
9
other samples had variations of svchost.exe, i.e., dddsvchost.exe
and cbasvchost.exe. These 17 samples dropped their own sv-
chost.exe binary to disk, which was detected by our ﬁlesystem
analysis, and executed the binary, which opened up a TCP
listening socket on port 1053. Port 1053 is associated with the
“Remote Assistance” service by the Internet Assigned Num-
bers Authority (IANA). The second most common process
was named bot.exe and occurred in 12 samples, and 4 of
these 12 samples also had the third most common process,
which was named dwwin.exe. The dwwin.exe binary claimed
to be Dr. Watson, a debugger included in Windows, but also
appeared to be injected with malicious code. The 4 samples
each created 2 UDP listening sockets on ports 1045 and 1046,
one owned by bot.exe and the other owned by dwwin.exe
respectively. We inferred from this behavior that these two
groups of samples were derived from the same two malware
families and contained remote administration tools (RATs),
which we conﬁrmed with the ground truth labels.
We also found 3 samples that executed the SUT’s legiti-
mate ﬁrefox.exe browser, but loaded with a suspicious library
needful.dll that they dropped to disk. The ﬁrefox.exe process
opened TCP listening sockets on ports 1044 and 1045 in 2
of the 3 samples, suggesting that these samples were also
RATs attempting to masquerade as the Firefox browser. This
supposition was also conﬁrmed by the ground truth data.
c) Data Exﬁltration: We successfully detected 46 sam-
ples that attempted to collect and exﬁltrate data through a com-
bination of our disk and memory analysis. We initially ﬂagged
2 particular samples because they appeared to be exﬁltrating
data over external IPs over port 25, which is reserved for
the Simple Mail Transfer Protocol (SMTP). Our disk analysis
of these samples showed a number of suspicious ﬁle reads,
including reads of Firefox’s cert8.db and key3.db for all user
proﬁles stored on the SUT. These ﬁles store user installed
certiﬁcates and saved passwords respectively, and there were
no Firefox processes running during the execution of those
samples. Searching for similar suspicious disk behavior in
the rest of the labeled set yielded 44 additional samples that
appeared to be exﬁltrating data. Again, our detections correctly
matched the ground truth data.
d) Worms and Network Scanning: We detected approx-
imately 30 labeled samples having worm propagation and
network scanning behavior, which was also conﬁrmed by
the ground truth data. These samples contacted a signiﬁcant
number of IP addresses and opened up a large number of
network sockets in our ﬁve minute window. For example, 8 of
the samples contacted over 140 IP addresses, and 13 samples
opened more than 2000 sockets. The same 13 samples ap-
peared to target external IPs over port 135, which is associated
with Microsoft RPC, a service that has had remote exploitable
vulnerabilities targeted by worms in the past.
e) Command and Control (C2) and DNS: We detected
14 samples that attempted to contact external servers over TCP
port 6667, which is associated with the Internet Relay Chat
(IRC) protocol. IRC is also commonly used as a C2 mechanism
for remotely controlling malware, which was the case for these
samples as conﬁrmed by the ground truth data. The most
common DNS queries were for the hostnames 579.info (55
samples), windowsupdate.net (16 samples), time.windows.com
(11 samples), wpad (11 samples), and google.com (10 sam-
ples). The ground truth data indicated that some of these
queries were intended as red herrings while other queries were
for actual contact with more suspicious hostnames such as
irc.site406.com, asdf.it, etc.
f) Kernel Modules: We detected 3 samples that un-
loaded the ipnat.sys driver and appeared to gain persistence
by replacing it with a malicious version.
D. Experiment 2: Unlabeled Malware
In this experiment, we demonstrate our framework’s ability
to scale and extract useful results from completely unknown
malicious binaries, which were obtained from the same source
as the labeled data and also said to target Windows XP. The
physical SUT was the same as described previously (Dell
T7500 with 1GB of RAM) but the virtual machines were
instantiated on a server with six quad-core Xeon X5670s
(24 logical cores) and 68GB of RAM. This enabled us to
instantiate a pool of 20 virtual machines with instrumentation.
Due the vast difference in runtimes and resources, we were
able to run far fewer samples in our physical environment. We
ran 1091 samples in both environments before running out
of available storage for our data on our development server.
We present the general types of behaviors detected by LO-
PHI in this section. Without ground truth data or manual
reverse engineering, we are unable to verify any strong claims
from our ﬁndings—however, we feel that the ﬁndings clearly
demonstrate the usefulness of our system. Basic statistics for
our analysis of these unlabled samples are shown in Table I.
TABLE I: Overall statistics for unlabeled malware (Section VII-D).
Observed Behavior
Number of Samples
Created new process(es)
Opened socket(s)
Started service(s)
Loaded kernel modules
Modiﬁed GDT
Modiﬁed IDT
765
210
300
20
58
10
g) New Processes: A large majority (70%) of the wild
samples created new processes that persisted until the end of
our analysis. The most common names are shown in Table II.
Unsurprisingly, most of the malware appeared to either start
legitimate processes or masquerade as innocuously named
processes. We discovered 4 samples that started a process with
the same name as the currently logged in user. We found 11
samples created at least 10 new processes on the SUT, one of
which created an unusual 84 new processes.
TABLE II: Top processes created by wild malware (Section VII-D).
New Process
IEXPLORE.exe
dwwin.exe
svchost.exe
explorer.exe
urdvxc.exe
dfrgntfs.exe
wordpad.exe
defrag.exe
Number of Samples
31
30
30
14
13
13
12
12
10
h) Sockets: About 19% of the wild samples opened at
least one network socket. The most commonly opened sockets
are shown in Table III. Three samples stood out as potential
worms or network scanners as they created over 1900 sockets;
the next highest sample created a mere 44 sockets. Unlike our
labeled set, none of the wild malware seemed to use obvious
C2 channel ports such as 6667 (IRC). For example, only one
sample sent trafﬁc over port 80.
TABLE III: Top 6 sockets (by port and protocol) created by wild
malware (Section VII-D).
Port
1038
1039
1042
1038
1040
1041
Protocol Number of Samples
UDP
TCP
TCP
TCP
TCP
TCP
58
42
37
36
36
32
i) Services: About 27.5% of the wild samples started
and installed at least one new system service. Most of these
services suspiciously claimed to be hardware drivers such as
USB or audio drivers. For example, over 250 samples loaded a
driver claiming to be hidusb.sys (for Human Interface Devices
over USB), possibly as an attempt to perform key logging.
E. Experiment 3: Evasive Malware
In this section, we exhibit LO-PHI’s ability to analyze
evasive malware, which thwart existing analysis frameworks.
Because we aim to analyze modern malware samples, we ran
these analyses on the same hardware, but with Windows 7 (64-
bit) as our operating system. Subsequently, we also installed
numerous potentially vulnerable and frequently targeted appli-
cations [5]. Speciﬁcally, Acrobat 9.4.01, Flash 10.1.85.3, Java
7u0 (64-bit), Firefox 38.0.1, Chrome 43.0.2357.64 (64-bit),
.NET 4.5.2, and Python 2.7 (64-bit). The analysis was done
exactly as described above. However, the Volatility modules
used were limited to those that supported Windows 7, from
which we selected the following to use in our analysis: psscan,
envars, ssdt, netscan, ldrmodules, driverirp, and psxview (See
Figure IV). It is worth noting that the ssdt and driverip modules
did not return any ﬁndings in our dataset.
1) Paranoid Fish: First, we highlight our ability to analyze
evasive binaries with a ground truth sample. We chose Paranoid
Fish (paﬁsh v054) [54], a proof-of-concept open-source tool
that demonstrates various VM detection and anti-debugging
techniques used by actual malware. When paﬁsh is executed,
it writes a ﬁle to disk for each artifact that it observes. Paﬁsh
is currently able to detect most popular analysis frameworks.
For example, when run against Anubis [7], paﬁsh dropped the
following ﬁles:
hi qemu
hi sandbox NumberOfProcessors less 2 GetSystemInfo
hi sandbox NumberOfProcessors less 2 raw
hi sandbox drive size
hi sandbox drive size2
hi sandbox mouse act
hi sandbox physicalmemory less 1Gb
1This was the last release before strict sandboxing.
Similarly, Cuckoo Sandbox had the following artifacts:
hi CPU VM rdtsc
hi CPU VM rdtsc force vm exit
hi sandbox mouse act
hi sandbox drive size
hi sandbox drive size2
hi hooks deleteﬁle m1
hi virtualbox