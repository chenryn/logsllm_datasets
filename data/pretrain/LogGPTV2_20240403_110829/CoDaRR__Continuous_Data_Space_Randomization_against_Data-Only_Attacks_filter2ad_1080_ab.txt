do not appear anywhere in the binary code of the program.
This dedicated hardware support for masked loads and stores
reduces the overhead of DSR to 6.61%.
3 ATTACKING DSR
All randomizing mitigations rely on keeping secret informa-
tion from an adversary. In the case of data space randomiza-
tion, this secret information is the random XOR key used to
mask data in memory. If the attacker can disclose the mask
for a targeted class of data, they can undo the effects of DSR
and proceed with a traditional memory-corruption attack. In
the following motivating attacks against compile-time DSR,
we show that we can disclose a mask and bypass DSR by
leaking information from the target.
We discuss two different approaches to leaking the secret
key and demonstrate that, with a single masked word value
from the heap, we can break the guarantees of DSR. First
we show a family of attacks that exploits the cryptographic
weakness of the XOR masking used in all prior DSR imple-
mentations. We then demonstrate a side-channel attack that
can disclose keys regardless of the chosen encryption primi-
tive without relying on any properties of the targeted data.
To show the practical viability of our attacks, we instantiate
them to bypass a DSR protecting the Nginx web server.
3.1 Threat Model
The goal of an adversary in this setting is to derandomize and
modify DSR-protected data in order to facilitate a data-only
exploit, bypassing deployed control-flow hijacking defenses.
We note that such multi-step exploits are increasingly popular
and common in practice [14, 18, 20, 22, 26â€“28].
In our attacks we show how an adversary can disclose infor-
mation from the protected application in one of two ways: (i)
disclosing masked data directly via a memory disclosure vul-
nerability, or (ii) gradually disclosing data via a side-channel
attack such as Spectre [30] or its remote variant NetSpec-
tre [43]. After exploiting one of these disclosure attacks, we
assume the attacker can then control a memory-corruption
vulnerability sufficient to write to the targeted address once
they have computed the required payload.
We target the ideal (theoretical) DSR implementation with
perfect alias analysis, i.e., we do not rely on implementation
weaknesses of any concrete DSR defense. In our direct mem-
ory disclosure attacks we assume the DSR implementation
uses XOR as the data randomization operation. Although
all previous software implementations of DSR rely on XOR
masking for performance reasons, our side-channel attack also
bypasses implementations that use stronger cryptographic
primitives [7, 8, 11].
In summary, we assume the following properties:
âˆ™ Vulnerable application: the target application is
a user-space process containing a memory-corruption
vulnerability that can overwrite the targeted data.
âˆ™ Code-injection and code-reuse defenses: control-
flow hijacking attacks are prevented by deployed de-
fenses such as ASLR [39], DEP [36], and CFI [1].
âˆ™ Data Space Randomization: the memory represen-
tation of the data the attacker is attempting to modify
(targeted data) is randomized by DSR. We assume the
For a concrete example of this attack, consider the
ngx chain s struct in Nginx. This linked list struct has two
fields, a buffer pointer and a next pointer, which are both
masked with the same key. The next field of this object
is often null, so letting the address of a null next field be
ð´ð‘ƒ in the above attack description means that ð‘‰ð‘ƒ = 0 and
we can derive the key for the struct, allowing us to rewrite
the buffer pointer to a chosen value. While this particular
example assumes field-insensitive pointer analysis, the attack
still applies as long as the attacker can find a known or
controllable encrypted value in the target class.
3.3 Attack 2 â€“ Transient Execution
Even without XOR key reuse or a direct memory disclosure,
the attacker may still be able to disclose DR keys by exploit-
ing side channel observations. Spectre [30] attacks allow an
adversary to exfiltrate program internals, such as register con-
tents, by causing the target program to speculatively execute
an appropriate Spectre gadget. In the following we show how
the attacker can leverage this covert channel to disclose DR
keys while they are stored in machine registers (Attack 2.a)
or by speculatively reading execute-only program memory
(Attack 2.b).
3.3.1 Attack 2.a â€“ Reading a mask from a register with Spectre
V2. In this attack we target a DSR mask while it is stored in
a register across an indirect call. Listing 2 shows an example
of code from Nginx that fits the requirements of this attack.
The program loads a DR key into register R15 at label a:.
It then uses this key, preserves it across the indirect call at
b:, and reuses the key at c:. If an adversary can control
the prediction of the call at b:, they can cause transient
execution of a chosen gadget that leaks some bit(s) from R15.
To demonstrate the practical viability of this attack ap-
proach, we created a proof-of-concept attack using the BTB-
CA-IP Spectre variant [12] targeting the indirect call in
Listing 2. From an attack process co-located with the target
Nginx process, we mistrain the target branch by repeatedly
executing an indirect call from the address b: to the address
where the Spectre gadget is located in the target address
space. After sufficient mistraining we send a POST request
to the server which triggers the indirect call with attacker
control of the third parameter, size, which we use to con-
trol which bit of the mask the Spectre gadget will leak. We
can then observe cache effects of the speculative execution
using a timing side channel such as FLUSH+RELOAD [52]
or PRIME+PROBE [48].
With the attacking and target processes pinned to the
same core of an Intel Core i5-4690K CPU, we were able to
successfully leak a 64-bit mask value in about 25 seconds,
although further optimization could lower this time. We ini-
tially found that our targeted branch destination address was
almost always cached and could not be reliably mispredicted,
so we added a cache flush of this address before the call in
Nginx. In a practical setting the attacker could force this
value out of cache by evicting its cache set with congruent
loads [34, 40]. To simplify our attack implementation we
Figure 1: Direct memory disclosure attack on a
reused XOR key. R: read V, unmasking with key ð¾ð‘…,
W: write V, masking with key ð¾ð‘Š .
DSR implementation stores its keys as constants em-
bedded in execute-only code memory so that the keys
are not accessible via any direct memory disclosure
vulnerabilities.
3.2 Attack 1 â€“ Direct Memory Disclosure
XOR masking is not secure when a key is reused to encrypt
more than a single value in memory, and we can exploit this
property to derandomize data under some circumstances. In
Attack 1, we assume that the attacker can find a memory
location already containing a known plaintext value masked
with the target key, ð¾ð‘‡ . In practice, attackers should be
able to find many such targets because a majority number of
variables are initialized with zero and more than one variable
often share the same key as sound pointer analyses typically
overapproximate alias sets [5, 7]. Figure 1 illustrates an
example attack on reused XOR masking.
Step 1: Derive ð‘‹ = ð¾ð‘Š âŠ• ð¾ð‘…. We first use attacker-
controlled write operation W to write a known plaintext
value ð‘‰0 (e.g., zero) to a scratch memory location ð´ð‘† that
will not cause the target process to crash. We then read
ð´ð‘† using attacker-controlled read operation R, disclosing
the value ð‘‰0 âŠ• ð¾ð‘Š âŠ• ð¾ð‘…. Since we know ð‘‰0, we can derive
ð‘‹ = ð¾ð‘Š âŠ• ð¾ð‘….
Step 2: Derive ð‘Œ = ð¾ð‘‡ âŠ• ð¾ð‘…. Next, we need to know
the plaintext value of a memory location masked with target
key ð¾ð‘‡ . If ð¾ð‘‡ is only ever used to mask unknown values,
this attack will only succeed with the probability that an
adversary correctly guesses the relevant bits of one of these
plaintext values. Assuming we know the plaintext value ð‘‰ð‘ƒ
stored at ð´ð‘ƒ but masked with ð¾ð‘‡ , we can read this value
through R to disclose ð‘‰ð‘ƒ âŠ• ð¾ð‘‡ âŠ• ð¾ð‘…, from which we can
derive ð‘Œ = ð¾ð‘‡ âŠ• ð¾ð‘….
Step 3: Overwrite target data. With the values from steps
1 and 2, we have full control of the overwrite of ð´ð‘‡ . Assume
we want to overwrite ð´ð‘‡ with value ð‘‰ . We can write value
ð‘‰ âŠ• ð‘‹ âŠ• ð‘Œ using W, which results in storing the value
ð‘‰ âŠ• ð¾ð‘‡ to ð´ð‘‡ , as desired.
AS:AT:V0V0 âŠ• KW âŠ• KR AP:VP âŠ• KT âŠ• KR â„â„let X = V0 âŠ• KW âŠ• KR âŠ• V0 let Y = VP âŠ• KT âŠ• KR âŠ• VP V âŠ• X âŠ• Y V âŠ• KTV âŠ• KWV âŠ• KWVP âŠ• KTV âŠ• KTn g x _ h t t p _ d o _ r e a d _ c l i e n t _ r e q u e s t _ b o d y :
a : MOV
XOR
R15 ,0 x 1 7 c 3 6 9 2 a b e 5 f 0 0 8 7
RAX , R15
; Load mask into R15
; Mask RAX
.
.
.
b : CALL
.
.
.
qword ptr [ R14 + 0 x20 ]
; c - > recv (c , buf , size ) ;
c : XOR
RAX , R15
; Mask RAX
Listing 2: Target indirect call in Nginx
injected a Spectre gadget that leaks a bit of R15 by loading
one of two different array values depending on value of the
selected bit. Our attack observes the cache effects of this
load using a FLUSH+RELOAD attack with clflush and
timing instructions we added to the target Nginx process. In
practice, an adversary could observe this covert channel from
the attacking process or even remotely, as in the NetSpectre
attack [43].
3.3.2 Attack 2.b â€“ Reading masks from execute-only memory
with Meltdown-PK. As mentioned in Section 3.1, we assume
masks embedded in program code are protected from direct
disclosure by execute-only memory permissions. However,
because speculative execution occurs before the CPU checks
memory permissions, the attacker may be able to specu-
latively compute using values from execute-only memory
regions and observe side-effects of that computation. Canella
et al. demonstrated that they could successfully read val-
ues from memory protected by Intelâ€™s Memory Protection
Keys (MPK) using a Meltdown variant they term Meltdown-
PK [12]. We speculate that such an adversary may be able to
leak masks from a remote target process by using speculative
execution to suppress the resulting exception, although we
have not explored this idea further.
4 CoDaRR DESIGN
As we show in the previous section, all existing DSR imple-
mentations are vulnerable to real-world attacks either based
on memory corruption or through side channels. We designed
CoDaRR to be resilient to such attacks. By refreshing the
randomization secrets dynamically at run time and updating
the programâ€™s memory representation accordingly, we ensure
that there is not enough time for an adversary to launch an
attack after disclosing the necessary secret information. How-
ever, since purely periodic rerandomization approaches are
prone to timing-window attacks [6, 44], we also incorporate
event-driven, on-demand rerandomization. CoDaRR is, to
the best of our knowledge, the first tool to apply rerandom-
ization to the program data representation and could only
be realized after we tackled the challenges outlined in the
following subsection.
4.1 Challenges
Several other exploit mitigations also implement rerandom-
ization, but focus exclusively on code while leaving the data
untouched [9, 15, 16, 25, 35, 50, 51]. Designing a rerandom-
ization system for data is fundamentally more difficult than
for binary code for the following reasons:
(C-1) Enabling dynamic rerandomization of data.
All existing rerandomization approaches focus on relocat-
ing and updating code pages since this can be implemented
efficiently by routing control-flow transfers through an in-
direction layer to dynamically adjust code pointers on-the-
fly [15, 50, 51]. Applying a similar approach to data transfers
would incur excessive run-time overhead, however, as memory
access instructions occur much more frequently in real-world
programs [3]. As a result, rerandomization of data currently
remains an open challenge.
Our primary goal is to enable dynamic rerandomization
of data. To achieve this, CoDaRR must refresh masks and
re-encrypt all encrypted data accordingly, which means that
CoDaRR needs to accurately track all keys and encrypted
data. There are several reasons why implementing dynamic
key updates is technically challenging: for instance, data
accesses under DSR are not atomic operations. A load op-
eration, for example, takes at least two atomic steps, since
the load instruction returns a masked value that must be
unmasked using a separate instruction. Moreover, updating
the keys invalidates all references to the data that still use
the old key.
(C-2) Securing the rerandomization mechanism.
Our threat model assumes an attacker with the ability to
trigger a memory-corruption vulnerability in the victim
application. This means that application memory could
be disclosed or tampered with unless it is protected by
additional defenses. For data randomization specifically,
this means the masks must be protected. In the case of
static DSR, where all keys are embedded directly into the
protected applicationâ€™s code, one could simply apply an
execute-only memory mechanism to protect the keys against
disclosure attacks [6, 19, 24]. Rerandomization adds a layer
of complexity, since the memory that stores the masks must,
at least briefly, be writable.
(C-3) Minimizing run-time overhead. In contrast to
static Data Randomization, which happens entirely at com-
pile time, our approach incorporates a runtime component to
continuously refresh the randomization secrets (i.e., masks).
Minimizing any performance overhead introduced by the
runtime monitor is another key challenge.
4.2 Overview
Figure 2 shows CoDaRRâ€™s high-level components and design:
a compile-time analysis and instrumentation pass, a run-time
allocation tracking mechanism embedded into the protected
program, and a run-time process monitor that refreshes keys
and updates memory.
The compiler first analyzes the source code of the appli-
cation. Specifically, we compute equivalence classes using a
points-to analysis. This is similar to previous DSR schemes.
In the figure, the application defines two data structures
â€” class-1 and class-2 â€” which the analysis places into
different equivalence classes (see Section 4.3).
Figure 2: Overview of CoDaRRâ€™s main components.
To provide the information necessary for challenge C-1, we
extend the compiler to add metadata tracking the locations
of masks in registers and spilled to the stack (see Section 4.4).
The compiler also adds metadata tracking the masks used to
encrypt global values, and dynamic instrumentation to track
the masks used in the heap (see Section 4.5). Combined, the
static and dynamic metadata provide our run-time monitor