title:Finding Clues for Your Secrets: Semantics-Driven, Learning-Based Privacy
Discovery in Mobile Apps
author:Yuhong Nan and
Zhemin Yang and
Xiaofeng Wang and
Yuan Zhang and
Donglai Zhu and
Min Yang
Finding Clues for Your Secrets: Semantics-Driven,
Learning-Based Privacy Discovery in Mobile Apps
Yuhong  Nan∗,  Zhemin  Yang∗‡,  Xiaofeng  Wang†,  Yuan  Zhang∗,  Donglai  Zhu∗  and  Min  Yang∗§ 
∗School of Computer Science, Fudan University
‡Shanghai  Insitute  of  Intelligent  Electronics  &  Systems
§Shanghai  Institute  for  Advanced  Communication  and  Data  Science
{nanyuhong,  yangzhemin,  yuanxzhang,  zhudl,  m  yang}@fudan.edu.cn,  PI:EMAIL
Shanghai  Key  Laboratory  of  Data  Science
†Indiana  University  Bloomington
Abstract—A long-standing challenge in analyzing information
leaks within mobile apps is to automatically identify the code
operating on sensitive data. With all existing solutions relying
on System APIs (e.g., IMEI, GPS location) or features of user
interfaces (UI), the content from app servers, like user’s Facebook
proﬁle, payment history, fall through the crack. Finding such
content is important given the fact that most apps today are web
applications, whose critical data are often on the server side. In
the meantime, operations on the data within mobile apps are often
hard to capture, since all server-side information is delivered to
the app in the same way, sensitive or not.
A unique observation of our research is that in modern apps,
a program is essentially a semantics-rich documentation carrying
meaningful program elements such as method names, variables
and constants that reveal the sensitive data involved, even when
the program is under moderate obfuscation. Leveraging this
observation, we develop a novel semantics-driven solution for
automatic discovery of sensitive user data, including those from
the server side. Our approach utilizes natural language processing
(NLP) to automatically locate the program elements (variables,
methods, etc.) of interest, and then performs a learning-based
program structure analysis to accurately identify those indeed
carrying sensitive content. Using this new technique, we analyzed
445,668 popular apps, an unprecedented scale for this type
of research. Our work brings to light the pervasiveness of
information leaks, and the channels through which the leaks
happen, including unintentional over-sharing across libraries and
aggressive data acquisition behaviors. Further we found that
many high-proﬁle apps and libraries are involved in such leaks.
Our ﬁndings contribute to a better understanding of the privacy
risk in mobile apps and also highlight the importance of data
protection in today’s software composition.
I.
INTRODUCTION
Mobile apps today are more composed than written, of-
ten built on top of existing web services (e.g., analytics or
single-sign-on SDK). Such functionality composition, how-
ever, comes with signiﬁcant privacy implications: private user
information given to an app could be further shared to other
parties through their components integrated within the app
(e.g., libraries), in the absence of the user’s consent. Indeed,
prior research reveals that third-party services like ad libraries
and analytics aggressively collect sensitive device information
(e.g, IMEI, phone number, and GPS location data) [22], [37],
[40]. Less noticeable here is the disclosure of the private user
data an app downloads from its cloud or uploads from its local
ﬁle, which could become completely oblivious to the user.
As an example, Figure 1 illustrates how The-Paper [14],
one of the most popular Chinese news apps, works. The app
integrates a third-party library ShareSDK [12] for sharing
news posts to Weibo, a popular Chinese social-media platform,
through its APIs. A problem we found is that the library
actually acquires the user’s access token, without a proper
authorization, from Weibo and further utilizes it to gather
the user’s personal information (like one’s detail proﬁles, her
social activities, etc.) from the Weibo cloud. Unlike access to
on-device data, which requires permissions from the user, or
manually entering secrets (e.g., password) into the app’s UI,
collecting such server-side information is completely unaware
to the user, since there is no user involvements (e.g., permission
granting) at all before the information is exposed to ShareSDK
and delivered to the untrusted party.
Such information disclosure is serious and can also be
pervasive, given the fact that most mobile apps are essentially
web applications, keeping most of their sensitive user data on
the server side. An in-depth study to understand the scope and
magnitude of the problem at a large scale, however, has never
been done before, due to the technical challenge in automatic
identiﬁcation of such data sources inside the app code.
Network and Distributed Systems Security (NDSS) Symposium 2018
18-21 February 2018, San Diego, CA, USA
ISBN 1-1891562-49-5
http://dx.doi.org/10.14722/ndss.2018.23092
www.ndss-symposium.org
Fig. 1. User’s sensitive data in Weibo server leaks to another service without
her consent
Leakage analysis: challenges. More speciﬁcally, to ﬁnd infor-
mation leaks in an app, ﬁrst one needs to locate the sources of
sensitive data within the app code. Typically, these sources are
discovered from the program based upon a set of System APIs
that handle private on-device data, such as IMEI, phone num-
ber, GPS locations, etc. However, as mentioned earlier, private
information comes from various sources, which can hardly be
covered by these manually labeled System APIs. An example
is user interfaces (UIs), whose inputs can be sensitive (e.g.,
password, home address) or public (e.g., comments) from the
same API (e.g., editText.getText()). They are classiﬁed in the
prior research [25], [32] using the semantics of their context,
particularly tags of GUI items (such as the string “Password”
right in front of a password entry). More complicated here is
the user information managed by the app, which can be stored
in local ﬁles or the app’s server-side database. Loading such
information into the app goes through generic APIs without
any tags (ﬁle access, network communication), thereby giving
little clue about the importance of the data transferred. As a
result, disclosure of such information to unauthorized parties
cannot be easily discovered.
1 # Getting location data in somewhere
2 Location location =
LocationManager.getLastKnownLocation();
"latitude"+ location.getLatitude() + "\n"
+ "longitude" + location.getLongitude();
3 this.locationStr =
4
5
6 ....
7 # Gathering user profile in somewhere else and
send to server
8 # Method getUserBasicInfo()
9 Json fBUserJson = getDataFromFacebook();
10 ...
11 HashMap basicInfo = new HashMap();
12 basicInfo.put("first_name",
fBUserJson.get("First_name"));
13 basicInfo.put("last_name",
fBUserJson.get("Last_name"));
14 basicInfo.put("last_location", this.locationStr);
15 ...
16 return basicInfo;
Fig. 2. Motivating example. Code snips from app SnapTee in Google-Play
A key observation in our research is that most apps today
contain a large amount of semantic information for supporting
their development and maintenance. As an example, we can
see from the code snippet of a real-world app SnapTee [13] in
Figure 2 that variables, functions, methods and other program
elements are all given meaningful names, and plain-text con-
tent (strings in double quotation marks) is included in the code
to explain other related content such as the value of a speciﬁc
key. Further, these program elements tend to be organized in
distinctive ways within the app, supporting unique operations
on sensitive user data: for example, formating the information
as key-value pairs and storing them in a HashMap (line 12-
16 in Figure 2). Essentially, the whole program here can be
viewed as a semantics-rich dataset, from which sensitive user
content can be discovered with proper data analysis techniques.
Such semantic information could also help information-ﬂow
tracking (which often cannot be done both efﬁciently and
accurately), through connecting program locations to related
semantics (e.g., directly conﬁrming the presence of location
data at line 14 from the constant “last location”, instead of
tracking the data ﬂow from the geolocation API at line 4).
Semantic clue discovery. Based upon the observation, we
developed a new technique that automatically mines app code
to recover semantic “clues” indicating the presence of sensitive
information, which enables an effective leakage analysis across
a large number of popular apps (Section V). Our technique,
called ClueFinder, ﬁrst utilizes a set of keywords, preﬁxes and
unique acronyms representing various types of sensitive user
information to identify the program elements (methods, vari-
ables, constants, etc.) that might involve sensitive content (e.g.,
getUserPwd, home addr, “Last name”). These elements are
then inspected through Natural Language Processing (NLP),
to remove those not representing any sensitive content. Often-
times, variables, constants and method names carrying privacy-
related terms end up being unrelated to sensitive information.
For example, the method getStreetViewActivity includes the
address-related keyword “street” but clearly does not involve
private data. Another example is the constant “invalid input
for home directory”, which has nothing to do with the user’s
home. To identify these false positive instances, ClueFinder
performs a grammatical analysis, ﬁnding the matched terms
or preﬁxes or acronyms not serving as the “theme” of their
semantic context: for example, the word “street” here only
plays the role of describing “activity”, which is the true subject
of the whole term (the activity name). On the other hand, when
a keyword acting as a noun in its element and also as a subject
of a verb (e.g., “getEmail”), it looks more like a clue for the
presence of operations on sensitive user data.
Learning-Based identiﬁcation. Such semantics analysis
alone, however, can still be insufﬁcient to avoid false positives,
that is, mistakenly reporting a non-sensitive program element
as involving sensitive content: e.g., sending a message with a
constant-string setMessage(“are you sure to delete account?”)
or throwing an exception like formatInvalidExp(“username”,
Exception e). To address this issue, ClueFinder further evalu-
ates the program structures related to those identiﬁed elements,
looking for the operations most likely to happen on sensi-
tive user data. More speciﬁcally, it runs a machine-learning
approach to classify the program statements containing such
elements, based upon a set of key program structural features
(Section III-C). For example, in Figure 2, line 14, we expect
that within a method invocation statement basicInfo.put(), an
identiﬁed constant
text string involving sensitive keywords
(“location”) appears together with a variable parameter of a
data type (String for the variable “locationStr”), which likely
indicates the presence of a key-value pair. Note that this feature
helps exclude the operation that simply displays the text with
keywords (e.g., “account”), as in the aforementioned example
“are you sure to delete account?”. Altogether we identiﬁed 5
features and trained an SVM model based upon the features to
discover sensitive-data related operations from Android code,
thus to identify the actual private content in mobile apps.
The design of ClueFinder enables efﬁcient discovery of
sensitive data sources, covering not only those labeled by
System APIs, but also server-side private data (e.g., user
proﬁles) and other content controlled by individual apps. Even
in the presence of moderate obfuscation (e.g., produced by Pro-
Guard [9]), our semantics-based approach still works, thanks to
2
the program features that needs to be preserved during obfus-
cation to avoid disrupting an app’s normal execution (e.g., API
names, parameters, constants, even some data operations, see
Section IV-B). Although ClueFinder is primarily designed to
ﬁnd hidden data sources, we show that the semantic knowledge
recovered by our approach also supports a more efﬁcient data-
ﬂow tracking (see Section III-C), which enables a large-scale
leakage analysis.
We implemented ClueFinder and evaluated its effectiveness
in our research (Section IV). The experimental results show
that ClueFinder accurately discovers sensitive data sources in
app code (with a precision of 91.5%), signiﬁcantly outperform-
ing all prior approaches [35], [25], [32], [26], in terms of both
coverage and precision.
Measurement and ﬁndings. Armed with more sensitive data
sources discovered by ClueFinder, we were able to evaluate
information leaks in 445,668 apps downloaded from 2 different
app markets, gaining new insights into the way private user
information (especially for those app-speciﬁc sensitive data)
is accessed by third-party libraries. Across all these apps,
our study shows that at least 118,296 (26.5%) disclose their
customers’ information to 3,502 libraries, which constitutes
a privacy risk much more signiﬁcant than reported by all
prior studies. More speciﬁcally, we found that personal content
has been extensively disseminated,
including one’s proﬁle,
installed app list, her social networking activities (e.g. proﬁles
on Facebook and personal posts) and others. Particularly,
among 13,500 most popular apps downloaded from Google-
Play in 2015, 39.9% of them were found to expose user’s
information to 709 distinct third-party libraries, with each app
on average sharing more than 7.6 private data items (e.g.,
address, proﬁle, etc.) with at least 2 third-party libraries. Many
of the libraries were found to indeed send collected user data
out to the Internet, and only a few of them could be conﬁrmed
to only use such information on device (See Section V-B).
Also, such an information exposure risk (that is, using
third-party libraries to process sensitive user data, which often
leads to an unauthorized leak of the data to a third-party,
as further showed in our adversary model) occurs when the
app developer over-shares data for functionality enrichment
or the third-party library aggressively gathers data through its
hosting app. Among the top 100 libraries with the risk, 65% of
them are non-ad libraries, such as Analytics, Social-Network
utilities, etc., with hundreds of millions of installs through
popular apps. A prominent example is Tinder (case study in
Section V-C), a popular dating app that exposes its user’s
proﬁles and account name on Instagram, together with her
instant locations to the library Appboy [6]. Also high-proﬁle
libraries like ShareSDK are given or actively acquire private
information (e.g., user’s social network proﬁles) unrelated
to their missions (Section V-C). Not only do these ﬁndings
conﬁrm the long-standing suspicion that user information has
been inappropriately disseminated through apps, but they also
underline the scale and the breadth of such risks, which have
never been fully understood before.
Contributions. The contribution of this paper are summarized
as follows:
• New technique for sensitive data source discovery. We
designed and implemented an innovative, semantics-driven
technique for automatically recovering sensitive user data
from app code, a critical step for leakage analysis. Our ap-
proach leverages semantic information of program elements,
together with the unique program structures of their context,
to accurately and also efﬁciently identify the presence of
sensitive operations, which takes a step towards solving this
long-standing challenge in app leakage analysis.
• Large-scale exposure risk analysis and new ﬁndings. Using
our new technique, we investigated the potential information
exposure to third-party libraries over 445,668 popular apps,
a scale never achieved before in comparable studies. Our
research brings to light the gravity of the problem, which
has never been fully understood, and the channels through
which such exposures happen, including over-sharing by app
developers and aggressive data acquisition by third-party
libraries. Further many high-proﬁle apps and libraries were
found to be involved in the information leaks. These ﬁndings
help better understand this privacy risk and highlight the im-
portance of data protection in today’s software composition.
Roadmap. The rest of the paper is organized as follows:
Section II presents the background of our research and assump-
tions we made; Section III elaborates the design of ClueFinder;
Section IV presents the implementation and evaluation of
ClueFinder and the supports it provides for a scalable leakage
analysis; Section V describes our large-scale leakage study
over 445,668 apps and our ﬁndings; Section VI discusses
the limitations of our research and potential future research;
Section VII surveys the related prior work and Section VIII
concludes the paper.
II. BACKGROUND
In this section, we lay out the background for our study,
including privacy leakage analysis, the NLP preliminaries used
in our research, and the assumptions we made.
App leakage analysis. Mobile users’ privacy has long been
known to be under the threats from the apps running on
their devices. Information can be leaked both intentionally
(often by malicious or gray app components) [42] or inadver-
tently (e.g., by leveraging the vulnerabilities in apps/mobile