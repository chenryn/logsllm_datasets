### 3.6.2 Test Targets

The test target can be a subset of a system, including:
- Functions or classes
- Software modules or components
- Client or server implementations
- Protocol stacks or parsers
- Hardware, such as a network interface card (NIC)
- Operating systems

The testing target varies depending on the phase in the software development life cycle. In earlier phases, tests may focus on smaller units like parsers and modules. In later phases, the target can be a complete network-enabled server farm, augmented with other infrastructure components.

### 3.6.3 Fuzz Testing as a Profession

We have conducted discussions with various fuzzing specialists from both Quality Assurance (QA) and Vulnerability Assessment (VA) backgrounds. This section is based on the analysis of those interviews. We will examine the tasks from the perspectives of both security and testing professions, starting with security.

Fuzzing typically falls under the purview of the security team, often named the Product Security Team (PST). Risk assessment is a key tool in deciding where to apply fuzzing and what to fuzz, or whether to fuzz at all. Security teams are usually small and rarely have budgets for tool purchases, relying instead on funding from product development organizations. Although fuzzing has been known in QA for decades, the push to introduce it into development often comes from the security team, driven by increasing security alerts in their products or new knowledge from resources like this book.

Initially, most security organizations rely on consultative fuzzing, but they quickly transition to in-house fuzzing. The primary reason is that purchasing fuzzing from external sources often results in unmaintained proprietary fuzzers and high service costs. Most security professionals advocate for the integration of fuzzing tools into the development organization but want to maintain control over the chosen tools and veto rights on consultative services purchased by development groups.

### 3.6.4 Testing Organization Structure

In our example testing organization, the structure is divided into three segments:
- **Tools and Techniques (T&T)**: One-fourth of the staff focuses on specific testing domains, such as performance testing, automated regression runs, and fuzz testing.
- **Quality Assurance Processes (QAP)**: Another one-fourth of the staff focuses on quality assurance processes.
- **Product Line Testing (PLT)**: The remaining 50% of testers work on various projects, with team sizes varying according to project size.

#### Tools and Techniques (T&T)

Test specialists in the T&T division each focus on one or more specific testing domains. For example, one team might handle performance testing, while another manages automated regression runs. A dedicated team is responsible for fuzz testing and supports projects with their fuzzing needs. These specialists may also manage white-box security tools and can be part of the security auditing team outside the traditional QA organization.

#### Integration into QA Processes

Before integrating fuzzing tools into the QA process, the requirement must come from product management, and the integration must be coordinated with the QAP team. The initial position in the QA process may not be optimal, so the QAP team closely monitors and improves testing tactics. Maintaining a good relationship with security auditors is crucial, as third-party audits can become very expensive if flaws are not already being addressed in the QA process.

#### Project Manager Responsibilities

The main responsibility for fuzzing lies with the individual project managers in PLT, who must integrate fuzzing into their projects and report the results to the customer. PLT is also responsible for the budget and authorizing product purchases.

When introducing a new fuzzing tool, the lead test specialist responsible for fuzzing should select the tool. If the tool is the first in its category, a new specialist may be appointed. Without this structured approach, tool purchases can go awry, with decisions based on criteria other than quality and efficiency. A poor fuzzer can waste both money and time.

### 3.7 Job Descriptions in Testing

- **QA Leader**: Works on individual QA projects within PLT, selecting processes and tools based on company policies. They handle test planning, resourcing, staffing, and budget, and ensure QA continuity, including transitioning test plans between versions and releases. Goals include integrating test automation and reviewing best practices.
- **QA Technical Leader**: Focuses on T&T-related tasks, researching new tools and best practices, and making tool recommendations. They may build in-house tools and test scripts, assist PLT teams in understanding test technologies, and help with ROI analysis and test automation integration.
- **Test Automation Engineer**: Builds test automation harnesses, sets up test tools, creates scripts for nightly and weekly tests, and ensures regression tests are up-to-date. They monitor test executions and handle failures.
- **Test Engineer/Designer**: Builds test cases for conformance and performance testing, selects templates for mutation-based fuzzing, and sometimes performs manual tasks to ensure test execution progresses as planned.

### 3.8 Purposes of Black-Box Testing

Black-box testing can serve several general purposes:
- Feature or conformance testing
- Functional security testing
- Functional safety testing
- Interoperability testing
- Performance testing
- Robustness testing

### 3.8.1 Conformance Testing

Conformance testing validates the software against specifications and standards. In the context of fuzz testing, test cases from a conformance test suite can be used as seeds for mutation-based fuzzers.

### 3.8.2 Functional Security Testing

Functional security testing considers intentional attacks and negative requirements, such as "the system should not accept wrong passwords." Model-based fuzzers can help validate these requirements, which may require extensive instrumentation of the target system.

### 3.8.3 Functional Safety Testing

Functional safety testing is applicable to software where malfunctions could cause physical injury or damage to health. Understanding safety requirements and failure modes can improve software instrumentation and detection of safety-related failures during fuzzing.

### 3.8.4 Interoperability Testing

Interoperability testing ensures the product can communicate with other industry products. True conformance is often difficult to achieve, but the product must at least interoperate with widely used devices or systems. Interoperability testing can be facilitated by events where developers compare their products.

### 3.8.5 Performance Testing

Performance testing assesses the software's efficiency in real-use scenarios, including stress testing, performance testing, and load testing. The goal is to ensure the software performs well under various conditions.

### 3.8.6 Robustness Testing

Robustness testing, or negative testing, assesses the software's reliability when subjected to semi-valid requests. Sources of negative tests include requirement specifications, system specifications, design specifications, interface specifications, and programming limitations.

### 3.9 Testing Metrics

There is no single metric for black-box testing; instead, various metrics are needed for different testing approaches:
- Specification coverage
- Input space coverage
- Attack surface coverage

### 3.9.1 Specification Coverage

Specification coverage applies to all types of black-box testing. Tests are only as good as the specifications they are built from. For example, in VoIP testing, a tool that covers multiple industry standard specifications has better coverage than one that covers only one specification.

### 3.9.2 Input Space Coverage

Each interface specification defines a range of inputs. Achieving high input space coverage means testing a wide range of possible inputs, such as trying all possible pin codes for a user name.

### 3.9.3 Interface Coverage

Testing multiple interfaces provides better coverage than testing just one. Each interface can consist of several protocols and protocol layers.

### 3.9.4 Code Coverage

Code coverage metrics are useful but do not necessarily indicate the quality of the tests. A test with smaller code coverage can sometimes find more flaws than a test with large code coverage.

### 3.10 Black-Box Testing Techniques for Security

Before concluding, we summarize the tools and techniques used in various types of security testing, some of which are relevant to fuzzing.

#### Load Testing

Load testing evaluates the system's performance under heavy loads. Repeating fuzz tests rapidly can uncover issues missed by slower fuzzing tools. Load testing can also help measure changes in the system's load tolerance when used in conjunction with fuzzing tools.

#### Stress Testing

Stress testing alters the operational environment by restricting access to required resources, such as memory, disk, network, and processing power. Stress tests are often executed in a controlled environment like a sandbox or simulation.

#### Security Scanners

Security scanners are used to identify vulnerabilities in the system. While not directly related to fuzzing, they complement the overall security testing strategy.