The test target can also be a subset of a system, such as:
• Function or class;
• Software module or component;
• Client or server implementation;
• Protocol stack or parser;
• Hardware such as network interface card (NIC);
• Operating system.
The target of testing can vary depending on the phase in the software develop-
ment life cycle. In the earlier phases, the tests can be first targeted to smaller units
such as parsers and modules, whereas in later phases the target can be a complete
network-enabled server farm augmented with other infrastructure components.
3.6.3 Fuzz Testing as a profession
We have had discussions with various fuzzing specialists with both QA and VA
background, and this section is based on the analysis of those interviews. We will
look at the various tasks from the perspectives of both security and testing profes-
sions. Let’s start with security.
Typically, fuzzing first belongs to the security team. At a software development
organization, the name of this team can be, for example, Product Security Team (PST
for short). Risk assessment is one of the tools in deciding where to fuzz and what
to fuzz, or if to fuzz at all. Security teams are often very small and very rarely have
any budget for tool purchases. They depend on the funding from product develop-
ment organizations. Although fuzzing has been known in QA for decades, the push
to introduce it into development has almost always come from the security team,
perhaps inspired by the increasing security alerts in its own products or perhaps by
new knowledge from books like this. Initially, most security organizations depend
on consultative fuzzing, but very fast most interviewed security experts claimed that
6760 Book.indb 86 12/22/17 10:50 AM
3.6 Black-Box Testing 87
they have turned almost completely toward in-house fuzzing. The primary reason
usually is that buying fuzzing from consultative sources almost always results in
unmaintained proprietary fuzzers and enormous bills for services that seem to be
repeating themselves each time. Most security people will happily promote fuzzing
tools into the development organization, but many of them want to maintain control
on the chosen tools and veto right on consultative services bought by the develop-
ment groups. This brings us to taking a closer look at the testing organization.
The example testing organization we will explore here is divided into three
segments. One-fourth of the people are focused on tools and techniques, which we
will call T&T. And one-fourth is focused on quality assurance processes, which
we will call QAP. The remaining 50% of testers work for various projects in the
product lines, with varying size teams depending on the project sizes. These will
be referred to as product line testing (PLT) in this text.
The test specialists from the tools and techniques (T&T) division each have focus
on one or more specific testing domains. For example, one dedicated team can be
responsible for performance testing and another on the automated regression runs.
One of the teams is responsible for fuzz testing and in supporting the projects with
their fuzzing needs. The same people who are responsible for fuzzing can also take
care of the white-box security tools. The test specialist can also be a person in the
security auditing team outside the traditional QA organization.
But before any fuzzing tools are integrated into the quality assurance processes,
the requirement needs to come from product management, and the integration of
the new technique has to happen in cooperation with the QAP people. The first
position in the QA process often is not the most optimal one, and therefore the QAP
people need to closely monitor and improve the tactics in testing. The relationship
with security auditors is also a very important task to the QAP people, as every
single auditing or certification process will immediately become very expensive
unless the flaw categories discovered in third-party auditing are already sought
after in the QA process.
The main responsibility for fuzzing is on each individual project manager from
PLT who is responsible for both involving fuzzing into his or her project, and in
reporting the fuzzing results to the customer. PLT is almost always also responsible
for the budget and will need to authorize all product purchases.
When a new fuzzing tool is being introduced to the organization, the main
responsibility for tool selection should still be on the shoulders of the lead test spe-
cialist responsible for fuzzing. If the tool is the first in some category of test automa-
tion, a new person is appointed as the specialist. Without this type of assignment,
the purchases of fuzzing tools will go astray very fast, with the decisions being made
not on the actual quality and efficiency of the tools but on some other criteria such
as vendor relations or marketing gimmicks. And this is not beneficial to the testing
organization. Whereas it does not matter much which performance testing suite is
used, fuzzing tools are very different from their efficiency perspective. A bad fuzzer
is simply just money and time thrown away.
Let’s next review some job descriptions in testing:
• QA Leader: Works for PLT in individual QA projects and selects the used
processes and tools based on company policies and guidelines. The QA leader
6760 Book.indb 87 12/22/17 10:50 AM
88 Quality Assurance and Testing
does the test planning, resourcing, staffing, and budget and is typically also
responsible for the QA continuity, including transition of test plans between
various versions and releases. One goal can include integration of test auto-
mation and review of the best practices between QA teams.
• QA Technical Leader: Works for T&T-related tasks. He or she is responsible
for researching new tools and best practices of test automation, and doing
tool recommendations. That can include test product comparisons either with
third parties or together with customers. The QA technical leader can also
be responsible for building in-house tools and test scripts that pilot or enable
integration of innovative new ideas and assisting the PLT teams in understand-
ing the test technologies, including training the actual hands-on testers in the
usage of the tools. The QA technical leader can assist QA leader in perform-
ing ROI analysis of new tools and techniques and help with test automation
integration either directly or through guidelines and step-by-step instructions.
He or she can either perform the risk assessments with the product-related
QA teams, or can recommend outsourced contractors that can perform those.
• Test Automation Engineer: Builds the test automation harnesses, which can
involve setting up the test tools, building scripts for nightly and weekly tests,
and keeping the regression tests up-to-date. In some complex environments,
the setting up of the target system can be assigned to the actual developers
or to the IT staff. The test automation engineer will see that automated test
executions are progressing as planned, and that the failures are handled and
that the test execution does not stop for any reason. All monitors and instru-
ments are also critical in those tasks.
• Test Engineer/Designer: These are sometimes also called manual testers,
although that is becoming more rare. The job of a test engineer can vary
from building test cases for use in conformance and performance testing to
selecting the templates that are used in mutation-based fuzzing, if a large
number of templates is required. Sometimes when manual tasks are required,
the test engineer/designer babysits the test execution to see that it progresses
as planned—for example, by pressing a key every hour, or rebooting the
device after it has failed. Most test automation tools are designed to eliminate
manual testing.
3.7 purposes of Black-Box Testing
Black-box testing can have the following general purposes:
• Feature or conformance testing;
• Functional security testing;
• Functional safety testing;
• Interoperability testing;
• Performance testing;
• Robustness testing.
We will next examine each of these in more detail.
6760 Book.indb 88 12/22/17 10:50 AM
3.7 Purposes of Black-Box Testing 89
3.7.1 Conformance Testing
The first category of black-box testing is feature testing or conformance testing.
The earliest description of the software being produced is typically contained in the
requirements specification. The requirements specification of a specific software
project can also be linked to third-party specifications, such as interface definitions
and other industry standards. In quality assurance processes, the people responsible
for validation evaluate the resulting software product against these specifications and
standards. Such a process aims at validating the conformity of the product against
the specifications. In this book we use the term conformance testing for all testing
that validates features or functional requirements, no matter when or where that
testing actually takes place. In the context of fuzz testing, test cases from a confor-
mance test suite can be used as a seed for a mutation-based fuzzer.
3.7.2 Functional Security Testing
Many of the details for the functional security testing process can be derived from
the conformance test methodology but, in addition to benign, legitimate users, func-
tional security testing also considers the possibility of intentional attacks attempt-
ing to use the resources from the system without legitimate right to use it. Security
requirements are often expressed as negative requirements such as “system should
not accept wrong password”, and therefore single requirement can require tens or
sometimes millions of unique tests to validate the functionality. This is where model-
based fuzzers can help. The process of observations and evaluation regarding test
outcome or expected results, can be very different from traditional functional testing
as they might require extensive instrumentation of the target system. Documents
like ETSI TVRA7 and Common Criteria8 have been created to describe functional
security testing in the context of system evaluation and certification.
3.7.3 Functional Safety Testing
Functional safety testing is a form of testing applicable to software where malfunc-
tion could cause unacceptable risk of physical injury or of damage to the health of
people either directly or indirectly. The requirements for the testing can be derived
from the standard of functional security, specific for the SUT area of industry. For
example, automotive and medical industry have different set of standards to com-
ply. In regards to fuzzing, understanding the safety requirements and system failure
modes can help in improving the software instrumentation and therefore detection
of safety-related failures when conducting fuzzing.
7 ETSI TS 102 165-1: “Telecommunications and Internet converged Services and Protocols for Advanced
Networking (TISPAN); Methods and protocols; Part 1: Method and proforma for Threat, Risk,
Vulnerability Analysis.”
8 ISO/IEC 15408:2009: “Information technology—Security techniques—Evaluation criteria for IT
security—Part 1: Introduction and general model.”
6760 Book.indb 89 12/22/17 10:50 AM
90 Quality Assurance and Testing
3.7.4 Interoperability Testing
Interoperability is basically a subset of conformance testing. Interoperability test-
ing is a practical task in which the final product or its prototype is tried against
other industry products, or selected reference products. In real life, true confor-
mance is very difficult if not impossible to reach. But still, the product must at least
be able to communicate with a large number of devices or systems widely used in
the industry. This type of testing can take place at various interoperability events,
where software developers fight it out, in a friendly manner, to see who has the
most conformant product. In some cases, if a dominant player decides to do it his
or her own way, a method that complies with standards may not necessarily be the
correct method. An industry standard can be defined by an industry forum or by
an industry player who controls a major share of the industry. For example, if your
Web application does not work on the most widely used Web browser, even if it is
completely standards compliant, you will probably end up fixing the application
instead of the browser vendor fixing the client software. Interoperability is also an
important feature for a fuzzer because it makes it easier to use the fuzzer to test
multiple different products. Interoperability testing methodology can also be used
in fuzzing to ensure that different products, or product versions, behave similarly
when handling fuzz test cases.
3.7.5 performance Testing
Performance testing comes from real-use scenarios of the software. When the soft-
ware works according to the feature set and with other vendors’ products, testers
need to assess if the software is efficient enough in real-life use scenarios. There
are different categories of tests for this purpose, including stress testing, perfor-
mance testing, and load testing. In this book we use the term performance testing
for all of these types of tests, whether they test strain conditions in the host itself
or through a load over communication interfaces, and even if the test is done by
profiling the efficiency of the application itself. All these tests aim at making the
software perform fast enough. The metric for final performance can be given as
the number of requests or sessions per given time, the number of parallel users that
can be served, or a number of other metrics. There are many types of throughput
metrics that are relevant to some applications but not to others. Note that many
performance metrics are often confused with quality-of-service metrics. Quality
of service is, for the most part, a subset of performance, or at least it can be fixed
by improving performance. Attacks that aim for denial of service are also typically
exploiting performance issues in software. Some performance testing tools behave
like a fuzzer, injecting more or less valid test cases at a high rate to trigger error
conditions in the target.
3.7.6 robustness Testing
The fourth black-box testing category is negative testing, or robustness testing.
This is often the most important category from the security perspective. In nega-
tive testing, the software is tortured with semi-valid requests, and the reliability of
6760 Book.indb 90 12/22/17 10:50 AM
3.8 Testing Metrics 91
the software is assessed. The sources of negative tests can come from the systems
specifications, such as
• Requirement specifications: These are typically presented as shall not and
must not requirements.
• System specifications: Physical byte boundaries, memory size, and other
resource limits.
• Design specifications: Illegal state transitions and optional features.
• Interface specifications: Boundary values and blacklisted characters.
• Programming limitations: Programming language specific limits.
3.8 Testing Metrics
There is no single metric for black-box testing, but instead various metrics are
needed with different testing approaches. At least three different levels of metrics
are easily recognized:
• Specification coverage;
• Input space coverage;
• Attack surface coverage.
We will next give a brief overview of these, although they are explained in more
detail in Chapter 4.
3.8.1 Specification Coverage
Specification coverage applies to all types of black-box testing. Tests can only be as
good as the specification they are built from. For example, in voice over IP (VoIP)
testing, a testing tool has to cover about 10 different protocols with somewhere from
one to 30 industry standard specifications for each protocol. A tool that covers only
one specification has smaller test coverage than a tool that covers all of them. All
tests have a specification, whether it is a text document, a machine-understandable
interface model, or a capture of a test session that is then repeated and modified.
3.8.2 Input Space Coverage
Each interface specification defines a range of inputs that can be given to the soft-
ware. This is sometimes represented in BNF form at the end of RFC documents.
Let’s illustrate this with a fictitious example of an interface that consists of two
values: an eight-character string as a user name and a four-digit pin code. Trying
one predefined user name with a small sample of pin codes achieves less input space
coverage than trying all ten thousand pin codes for the same user name.
3.8.3 Interface Coverage
Software has different communication interfaces, and different pieces of code are
touched through each one. Testing just one interface can give you less test coverage
6760 Book.indb 91 12/22/17 10:50 AM
92 Quality Assurance and Testing
in the target system than testing two interfaces. Each interface can also consist of
several protocols and protocol layers.
3.8.4 Code Coverage
Different code coverage metrics are available for different purposes. But, be careful
when using them, as code coverage metrics do not necessarily indicate anything about
the quality of the tests to the end customer. In some cases, a test with smaller code
coverage can find more flaws than a test with large code coverage. Code coverage
can also be impossible for the customer to validate.
3.9 Black-Box Testing Techniques for Security
Before turning our attention away from a QA focus in fuzzing, we want to sum-
marize the various tools and techniques used in various types of security testing.
Many of these have very little relevance to fuzzing, but might help you resolve some
misconceptions other people have about security testing.
3.9.1 Load Testing
The easiest and best-known attack category to QA people are various DoS situa-
tions. The majority of DoS attacks are based on load. In load testing, the perfor-
mance limitations of the system are tested with fast repetition of a test case and by
running several test instances in parallel. This is relevant to fuzzing because these
tests can be fuzz tests. When a fuzz test is repeated very fast, it can discover prob-
lems that are missed by slowly executing fuzzing tools. One example of such a test
is related to testing for memory leaks or performance problems. If a test case indi-
cates that there could be some problems, the test case can be extracted and loaded
into a performance test tool through the record-and-playback functionality most
of these tools possess. Another benefit from load testing comes when testing proxy
components such as gateways and firewalls. When a load-generation tool is used
in parallel with fuzzing tools, the load-testing tool will help measure the change in
the load tolerance of the system. Fuzz tests under a load can also result in different
test results. All these results are very feasible in a live server, which almost always
will be under a normal system load when an attack arrives.
3.9.2 Stress Testing
A stress test will change the operational environment for the SUT by restricting
access to required resources. Examples of changes include
• Size and speed of available memory;
• Size and speed of available disk;
• Availability of network resources;
• The number of processors available and the processing speed of the processors;
• Environmental variables.
6760 Book.indb 92 12/22/17 10:50 AM
3.9 Black-Box Testing Techniques for Security 93
Most often stress tests are executed in a test automation framework that will
enable you to run the SUT inside a controlled environment such as a sandbox or
software development simulation.
3.9.3 Security Scanners