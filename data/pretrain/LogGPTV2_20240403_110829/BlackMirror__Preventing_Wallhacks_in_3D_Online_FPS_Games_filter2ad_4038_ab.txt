Entities
Self
origin,angles
field-of-view
Others
origin,angles
origin,angles
origin,angles
model
model
model
1
2
worldToClip
localToWorld
localToWorld
localToWorld
Geometry
Geometry
Geometry
Textures
Textures
Textures
3
r
e
v
i
r
D
l
e
n
r
e
K
Geometry Pipeline
4
5
Rasterization Pipeline
7
GPU
Vertex
Processor
Primitive
Assembly
Rasterizer
Depth Test
Fragment
Processor
Post
Processing
Screen
Depth map
6
Local Space
World Space
Clip Space
Depth map
self
𝑒2
𝑒1
𝑒3
wall
self
field-of-view
𝑒1
𝑒3
𝑒2
𝑒3
𝑒2
𝑒3
wall
localToWorld
worldToClip
𝑒1 is discarded (out-of-view)
𝑒2 is discarded (occluded)
𝑒3 is displayed (visible)
wall is displayed
Figure 3: Overview of rendering pipeline (top) and corresponding transformations in coordinate systems (bottom)
Stage 2: Geometry Pipeline on GPU. Upon receiving the request
from CPU, GPU starts the geometry pipeline stage. The goal of
this stage is to apply a series of coordinate transform to entities,
therefore transforming them from the local space to the clip space.
The most crucial units in this stage is the vertex processor, which
applies the transformations defined in the vertex shader to input
geometry. A typcical vertex shader define the following transfor-
mation, therefore transforming from the local space into clip space:
v’ = worldToClip * localToWorld * v.
As a result, entities in the local space, 𝑒1, 𝑒2, 𝑒3 and the wall
are transformed into the clip space as shown in Figure 3. Notably,
the 𝑧 value in the clip space represents the distance between an
entity and the camera, which we refer to depth value. Next, the
primitive assembler groups vertices into geometric primitives such
as triangles.
After completing the geometry pipeline, vertices in clip space are
passed to the next stage, the rasterization pipeline, with additional
information about their grouping.
Stage 3: Rasterization Pipeline on GPU. This stage takes an
entity in the clip space and determines i) which portion of an entity
is shown to the 2D screen, and ii) its final color.
First of all, the rasterizer transforms input clip space into a screen
space, where (𝑥, 𝑦) coordinates correspond to the index of pixel in
the final 2D scene ( 4 → 5 ). Then, the GPU also computes missing
attribute values of each pixel (e.g., the depth value) that overlaps
with an entity. Recall that previously the GPU only knows the
attributes of points in the geometry, not the surfaces.
Next, the depth test stage takes an entity in the screen space and
determines visible pixels. The primary goal of depth testing is to
keep the correctness of the rendered scene, e.g, entities behind the
wall should not be drawn. To this end, the GPU keeps an internal
data structure, depth map, which keeps the closest depth values
that have been rendered. For example, imagine the wall in Figure 3
is rendered in advance to 𝑒2, and the GPU is now about to render
it. At this point, the depth values of the wall is already stored in
the depth map, and these are closer than the depth values of 𝑒2.
Consequently, the GPU discards the entity 𝑒2, thus the following
stages are not performed for 𝑒2. ( 6 )
Lastly, the fragment processor runs the fragment shader code
for all visible visible entities to compute their color. In particular,
it performs texture mapping and lighting to compute the color for
each pixel ( 7 ), which comprises expensive operations.
2.3 Intel Software Guard eXtensions (SGX)
Intel SGX [12, 13] allows a user-level process to create its own
isolated execution environment, called enclave, which is protected
against all privileged softwares including OS and hypervisors. En-
claves reside in a pre-determined (at boot-time) location of physical
memory called the Enclave Page Cache (or EPC). However, Intel
SGX has various well-known limitations.
In particular, SGX does not provide trusted I/O paths off-the-
shelf. Enclaves can seal [13] persistent data before storing it on the
disk and encrypt network communication, yet there are scenarios
where sealing is not helpful. For example, GPU communication
is in plaintext, due to lack of encrypted communication capabili-
ties within commodity GPUs. On the other hand, data from input
devices such as a keyboard and a mouse are not protected, either. Al-
though existing research has considered this problem, they require
complicated changes to the software or hardware ecosystem of SGX,
such as using a trusted hypervisor [14], extra hardware [15, 16] or
hardware changes [17, 18].
3 THREAT MODEL AND ATTACK SUMMARY
3.1 Threat Model
We assume the attackers control their machine including the periph-
eral devices, and privileged software including OS and hypervisors.
In particular, an attacker i) is capable of monitoring and modifying
the client memory, ii) eavesdropping on and tampering with the
communication between the CPU and the GPU and/or iii) read or
write kernel memory.
(a) Benign view
(b) Wallhack view
Figure 4: An example of wallhacks. The opponent entity be-
hind the wall is rendered to the scene, which is highlighted
with the red box in Figure 4b.
We assume that game server is correctly implemented, run by
a trusted party (e.g., a game company), and is not colluding with
a player. This is also a fair assumption since the game companies
have an incentive to maintain their reputation amongst players.
On the other hands, we leave the following as out-of-scope:
i) side-channels and micro-architectural attacks and ii) software
vulnerability in enclaves. SGX has been a famous target for various
side-channel attackers and micro-architectural attacks [19–25]. In
this work, we are not dealing with these attacks. Furthermore,
enclave code possibly contains software vulnerabilities, e.g. buffer
overflow [26, 27], and existing solutions [28, 29] should be used to
prevent them.
3.2 Wallhack Cheats
The attacker wants to perform better than other players in com-
petitive online games. To achieve this goal, the attacker uses the
infamous wallhack cheats [30], which result in hidden entities (e.g.,
rival players behind a wall or out-of-view) appearing on the at-
tacker’s screen. For example, consider entities in the world space
of Figure 3, where only 𝑒3 is visible, and entity 𝑒2 and 𝑒3 are hidden
at this point (𝑒2 is blocked by the wall and 𝑒1 is out-of-view).
Root Cause of Wallhacks. The root cause of wallhacks originates
from an inherent feature of current online multiplayer games, i.e.,
the client application holds more states than required to render a
scene. To elaborate, the server sends information of non-visible
opponent entities to the client to improve gameplay (§2.1). As far
as honest players are concerned, these states are inconsequential
since they will not be rendered in the current scene. However, the
attackers can exploit these states to perform a wallhack.
Unfortunately, filtering unauthorized information at the server
has various issues. In particular, the server has to perform addi-
tional computation for each player, especially if many clients are
connected to the server at the same time. Additionally, filtering
information at the server can result in unpredictable gameplay.
For example, the user may observe visual glitches (e.g., opponents
appearing out of thin air), if the server-side filtering is too strict.
Furthermore, the server lags behind the client due to network de-
lays, and therefore server-side filtering cannot be as precise as the
client-side solutions. As a result, server-side filtering ends up being
too conservative.
Figure 3 describes how unauthorized states propagate within the
rendering pipeline, until they are discarded. In particular, the client
application blindly runs rendering pipeline without performing
visibility-testing. These states propagate in the memory and the
GPU, until depth-testing is performed and they are discarded.
Attack Surfaces. In the following, we summarize possible attack
surfaces of wallhacks, based on investigation of publicly available
wallhacks [8, 9, 31–33]. Recall that the client is provided with states
of non-visible entities and it blindly issues rendering calls for them,
therefore sensitive information propagates from the client memory
to the GPU.
Game Client. The attacker can read sensitive information from
client memory, or modify the client to tamper with the its execution.
Typically attackers attempt to locate the opponents’ entities in the
memory [7, 34], read their positions and overlaying the scene with
these information [35] Alternatively, the attackers may exploit
existing code to render extra information on the scene. [33]
Communication between CPU and GPU. An attacker can exploit
the kernel subsystem or communication between the CPU and the
GPU to leak secrets and manipulate rendering result. The rendering
requests issued by the client are mediated by the kernel subsys-
tem or the driver before transmission to the GPU. For example,
an attacker tampers with the rendering process by hooking the
rendering functions [8, 9].
GPU Computation. Lastly, an attacker can undermine the integrity
of computations performed on the GPU. For example, an attacker-
controlled driver may modify the shader, or reject certain rendering
requests (e.g., skip rendering the walls). Consequently, if the GPU
issues a rendering requests for an opponent entity behind the walls,
the opponent entity will appear on the screen. On the other hand,
an attacker may fool the GPU to disable depth testing of certain
entities [8], therefore drawing the entities over the wall.
4 LIMITATIONS OF CURRENT ANTI-CHEAT
In the following, we describe the shortcomings of modern anti-cheat
software, which we try to overcome with our proposed design.
Commercial Anti-Cheat Software. Many commercial games are
deployed with third-party anti-software [3–5, 38] or their own anti-
cheat solutions [39]. However, we observe that these approaches
fail to provide sufficient security guarantees, resulting in an arms
race between attackers and anti-cheat developers.
As shown in Figure 5a, anti-cheat solutions are commonly de-
ployed as an external process, and an anti-cheat kernel driver [3,
6]. In particular, anti-cheat software continuously challenges the
player’s game client to prove there is no violations. For example, it
looks for malicious contents (i.e., known cheats) loaded on the client
memory, detects hypervisors and manipulated control flow [40].
Despite their efforts, tech-savvy cheaters keep bypassing such
defenses and the anti-cheat developers keep patching their miti-
gation solutions in response. Even worse, such an arms race has
moved to the kernel space, since modern cheats operates in ker-
nel or hypervisor to avoid anti-cheat and the game companies
deploy specific anti-cheat kernel modules as countermeasures. In
consequence, the users are enforced to run kernel-level anti-cheat
modules to play the game, and unfortunately this opens up new
attack vectors [6, 30].
5 WALLHACK PREVENTION USING TEEs
In this section, we explore potential designs to protect games against
wallhacks by leveraging the confidentiality and integrity protec-
tions provided by TEEs.
: Trusted Components
: Attack Surfaces
CPU
Game Client
Entity
States
Kernel Driver
Anti-Cheat
Process
Anti-Cheat
Driver
CPU
Game Client
Entity
States
Kernel Driver
Geometry
Raster
Depth Map
z-buffer
GPU
Geometry
Raster
Depth map
z-buffer
GPU
CPU
Game Client
Entity
States
Software Renderer
Raster
Depth map
z-buffer
Geometry
Kernel Driver
GPU
CPU
Game Client
Entity
States
Kernel Driver
CPU
Game Client
BlackMirror
Trusted
States
BMTest
Raster*
Depth map
z-buffer
Geometry*
Entity
States
Kernel Driver
Geometry
Raster
Depth map
z-buffer
GPU + TEE
Geometry
Raster
Depth map
z-buffer
GPU
(a) Anti-Cheat Software [3, 4]
(b) Client in Enclave [36]
(c) Software Renderer [37]
(d) Trusted GPU [17, 18]
(e) Our Approach
Figure 5: Comparisons between Our Approach, Anti-Cheat Software and Alternative Approaches Using Trusted Execution
D1. Enclosing Game Client within Enclave. The most straight-
forward design is to enclose the game client within an enclave (Fig-
ure 5b). In fact, this design is identical to typical use-cases of TEEs to
augment application security—running entire applications within
enclaves (e.g., using Library OS [36, 41]). As far as security is con-
cerned, this design prevents access to sensitive entities (i.e., vio-
lating confidentiality), and modifying the original client code (i.e.,
violating integrity).
However, by nature of existing TEEs, this design has a critical
limitation, i.e., it only protects the game client within the enclave,
and interfaces between the enclave and rest of the system are left
unprotected. In particular, the CPU-GPU channel and GPU compu-
tation (refer Figure 5b) are still possible wallhack attack surfaces.
Therefore, this approach by itself is insufficient.
D2. Software-only Rendering inside Enclave.
Improving on
D1, this design implements the entire rendering pipeline within
an enclave. Therefore, this design is more secure as compared to
D1, because the rendering pipelines are now placed within the pro-
tection boundary of the TEE. However, this design has to perform
the software-only rendering, so it has to abandon crucial GPU-
acceleration for rendering computation. Therefore, the rendering
performance of such a solution is unimaginably slow (§9.2), and
incapable of meeting current gameplay requirements.
D3. Rendering with Trusted GPU. Previous works on trusted
hardware [15–18] have introduced promising ways of extending
trusted execution to external accelerators or augmenting SGX using
I/O protection. Unfortunately, these approaches require hardware
changes to existing architectures/devices, which would be challeng-
ing to achieve given the diversity of trusted execution environments