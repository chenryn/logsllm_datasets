+
图12-2Map/Reduce 管理界面（部分截图）
HDFS 存储管理地址：http://192.168.1.20:50070/，如图12-3 所示。
NameNode
'SN2013-08-020:9000
Started:
Yersion:
Fr1 Asg 22 22:14:01 CST 2014
1.2. 1. r1500152
Coepiled:
1119s 5Q 2102 30 60:821 22 10[ 9
Upgredes:
There are so sgrades in progress.
Brokse_he_fileszstes
Saacaode_Logs
Cluster Summary
31 files end direetories, 9 blocks = 40 tota1. Beap Size is 15. 38 MB / 966.69 MB (1%)
Configored Capecity
DFS Used
8. $6 GB
456 KB
paea Sag 9og
DFS Reasining
764.23 B
7.12 GB
DFS Used%
0.01 %
Lixe_Sodss
DFS Rcssining%
91.28 %
Dead_Sodea
图12-3HDFS管理界面（部分截图）
12.3使用Python编写MapReduce
Map与Reduce为两个独立函数，为了加快各节点的处理速度，使用并行的计算方式，
map运算的结果再由reduce继续进行合并。例如，要统计图书馆有多少本书籍，首先一人一
排进行统计（map），其次将每个人的统计结果进行汇总（reduce），最终得出总数。Hadoop除
---
## Page 229
208第二部分高级篇
了提供原生态的Java来编写MapReduce任务，还提供了其他语言操作的API——Hadoop
Streaming，它通过使用标准的输入与输出来实现map与reduce之前传递数据，映射到
Python中便是 sys.stdin输入数据、sys.stdout 输出数据。其他业务逻辑也直接在Python中
编写。
下面实现一个统计文本文件（/home/test/hadoop/inputtxt）中所有单词出现的词频功能，
分别使用原生Python与框架方式来编写mapreduce。文本文件内容如下：
[ /home/test/hadoop/input.txt ]
1s93 awoo[an 2eoq nof ooereq oqe xnnb xeq oogsqet xnnb oogoo]
abc labs foo me python hadoop ab ac bc bec python
12.3.1用原生Python编写MapReduce详解
（1）编写Map代码
见下面的mapper.py代码，它会从标准输人（stdin）读取数据，默认以空格分割单词，
然后按行输出单词及其词颊到标准输出（stdout），不过整个Map处理过程并不会统计每个单
词出现的总次数，面是直接输出“word1"，以便作为 Reduce的输人进行统计，要求mapper.
py具备可执行权限，执行 chmod+x/home/test/hadoop/mapper.py。
[ /home/test/hadoop/mapper.py ]
#1/usr/bin/esv python
输入为标准输入stdin;
import sys
for 1ine in sys,stdin:
删除开头和结尾的空格：
1Lne = 1ine,strip ()
以致认空格分属行单词到words列表；
vords = 1ine,split()
for word in words1
print *4s\t$s* s (word, 1)
（2）编写Reduce 代码
见下面的reducer.py代码，它会从标准输人（stdin）读取mapper.py 的结果，然后统计每
个单词出现的总次数并输出到标准输出（stdout），要求reducer.py同样具备可执行权限，执行
chmod +x /home/test/hadoop/reducer.py
[ /home/test/hadoop/reducer.py ]
#1/usx/bin/env python
---
## Page 230
第12章Python大数据应用详解209
fron operator import itemgetter
lnport sys
current_word = None
current_count = 0
UON = pz0x
获取标准喻入，即mapper-Py的喻出；
for line in sys.stdini
删除开头和结尾的空格：
line = line.strip()
繁析mapper-py输出作为租序的输入，以tab 作为分照符；
vord, count = 1ine.split('\t*, 1)
特换count 从字将至成整型；
try:
count = int (count)
except ValueError:
count非数字时，怒略此行：
continue
要求mapper.py的验出氟排序（sort）操作，以便对连续的word微判断：
1f current_word *= word:
current_count *= count
else:
if current_vord:
输出当前word 统计结果到标准输出
print&s\tas'(current_word, current_count)
qunoo=unooue1no
current_word = word
输出最后一个word统计
if current_word -= vord:
print *4s\tts*(current_word, curzent_count)
（3）测试代码
我们可以在Hadoop平台运行之前在本地进行测试，校验mapper.py与reducer.py运行的
结果是否正确，测试结果如图12-4所示。
测试reducer.py时需要对mapper.py的输出做排序（sort）操作，当然，Hadoop环境会自
动实现排序，如图12-5所示。
（4）在Hadoop平台运行代码
首先在HDFS上创建文本文件存储目录，本示例中为/user/root/word，运行命令：
 /usr/loca1/hadoop-1.2,1/bin/hadoop dfs -mkdir /user/root/word
---
## Page 231
210第二部分高级篇
上传文件至HDFS，本示例中为/home/test/hadoop/input.txt，如果有多个文件，可采用以
下方法进行操作，因为Hadoop分析目标默认针对目录，目录下的文件都在运算范围中。
/usr/loca1/hadoop-1.2.1/bin/hadoop fs -put /home/test/badoop/input,txt /usez/
/usr/1oca1/hadoop-1.2.1/bin/hadoop dfs -1s /user/root/vord/
root/vord/
Found 1 items
-rv---r*-
dno161edne10oxZ
118 2014-02-10 09:49 /u8er/root/word/1nput,txt
图12-4mapper执行结果（部分截图）
图12-5reducer 执行结果
下一步便是关键的执行MapReduce任务了，输出结果文件指定/output/word，执行以下
命令：
/usr/1oca1/hadoop-1.2.1/bin/badoop Jar /usr/loca1/hadoop-1.2.1/contrib/
---
## Page 232
第12章Python大数据应用详解211
Tg- Ad·zaddeu/* zaddes- Kd·xaddew/* a- xe{*1*z*I-Surweozis-doopeu/buruea21s
pxox/nd4no/ sndpno- pzon/soo3/zasn/ 4ndut- Ad·xeonpea/+ 1eonpex- &d·xeonpe2/*
图12-6为返回的执行结果，可以看到map及reduce计算的百分比进度。
门日
E/
121/
图12-6执行MapReduce任务结果
访间http://192.168.1.20:50030/jobtracker.jsp，点击生成的Jobid，查看mapreduce job 信
息，如图12-7所示。
Kind
% Coeplete
Nun Tasks
Pending
Conplete
Killed
Eailed/KLLled
10.00
Tesk_Atleapt8
2
0
9 / 1
100.00
9
0
0 / 0
lap
Reduee
Total
File Inpu
t Forne
tes lesd
D
ITT
SLOTSILLIS_APS
L34, 815
Bed rrdluce teiks
0
fotal tiar
witisg eftei
Tetal tiae
Jr_a11 ergs vsitisg after
ched nrp tesk
[930]*19
s8p tasks
图 12-7Web查看 mapreduce job 信息（部分截图）
查看生成的分析结果文件清单，其中/output/word/part-00000为分析结果文件，如
---
## Page 233
212第二部分高级篇
图12-8所示。
 2004-48-10 22:52 /
图12-8任务输出文件清单
最后查看结果数据，图12-9显示了单词个数统计的结果，整个分析过程结束。
图12-9查看结果文件part-00000 内容
票HDFS常用操作命令有：
1）创建目录，示例：bin/hadoop dfs -mkdir /data/root/test。
2）列出目录清单，示例：bin/hadoop dfs -ls /data/root。
3）删除文件或目录，示例：bin/hadoop fs -rmr/data/root/test。
4 )上传文作,示例:bin/hadoop fs -put /home/test/hadoop/*.txt /data/root/test.。
5 ）查香文件内容，示例：bin/hadoop dfs -cat/output/word/part-00000。
12.3.2用Mrjob框架编写MapReduce详解
Mrjob ( http:/pythonhosted.org/mrjob/index.html）是个 编 写 MapReduce 任务 的 开 源
Python 框架，它实际上对Hadoop Streaming的命令行进行了封装，因此接触不到Hadoop 的
数据流命令行，使我们可以更轻松、快速编写MapReduce任务。Mrjob具有如下特点。
1）代码简洁，map及reduce 函数通过一个Python文件就可以搞定；
2）支持多步骤的 MapReduce任务工作流：
---
## Page 234
第12章Python大数据应用详解213
3）支持多种运行方式，包括内嵌方式、本地环境、Hadoop、远程亚马逊；
4）支持亚马逊网络数据分析服务ElasticMapReduce（EMR）；
5）调试方便，无须任何环境支持。
安装Mrjob要求环境为Python 2.5及以上版本，源码下载地址：https://github.com/yelp/
mrjob.
python setup.py instal1漂码安装方式
pip install mrjobPyPI 安方式
回到实现一个统计文本文件（/home/test/hadoop/input.txt）中所有单词出现的词颊功能，
Mrjob通过mapper0与reducerO方法实现了MR操作，实现代码如下：
 /home/test/hadoop/word_count.py 1
from mrjob.job inport MRJob
class MRWordCounter (MRJob) :
def mapper (self, key, 1ine) :
for word in line.split ():
yield word, 1
def reducer (self, ord, occurrences) :
yield word, sum (occurrences)
：,ueu-ouuT
MRiordCounter,run ()
可以看出代码行数只是原生Python的1/3，逻辑也比较清晰，代码中包含了mapper、
reducer函数。mapper函数接收每一行的输人数据，处理后返回一对key:value，初始化value
为数据1；reducer接收mapper输出的key-value对进行整合，把相同key的value作累加
（sum）操作后输出。Mrjob利用Python的yield 机制将函数变成一个Generators（生成器），通
过不断调用nextO去实现key-value的初始化或运算操作。前面介绍Mrjob支持四种运行方
式，包括内嵌（-r inline）、本地（-r local)、Hadoop （-r hadoop）、Amazon EMR（-r emr），下面
主要介绍前三者的运行方式。
（1）内嵌（-rinline）方式
特点是调试方便，启动单一进程模拟任务执行状态及结果，默认（-rinline）可以省略，
 python word_count ,py -r Inline 1nput,txt >output.txt
 python word_count,py input,txt =o output,txt
输出文件output.txt 内容见图12-10。
---
## Page 235
214第二部分高级篇
图12-10查看输出 outpuL.txt 文件内容
（2）本地（-r local）方式
用于本地模拟Hadoop调试，与内嵌（inline）方式的区别是启动了多进程执行每一个任
务，如：
 python word_count-py -r local input,txt >output,txt
执行的结果与inline一样，只是运行过程存在差异。
（3） Hadoop (-r hadoop）方式
用于Hadoop环境，支持Hadoop运行调度控制参数，如：
指定 Hadoop 任务调度优先级（VERY_HIGH|HIGH），如，-jobconf mapreducejob
priority=VERY_HIGH。
Map及Reduce 任务个数限制，如，--jobconf mapred.map.tasks=10-jobconf mapred
reduce.tasks=5 。
注意，执行之前需要指定Hadoop环境变量，执行结果见图12-11。
访问 http:/192.168.1.20:50030/jobtracker.jsp，显示的最后一行便是任务执行的信息，从
中可以看到任务的优先级、map及reduce的总数，如图12-12所示。
查看Hadoop分析结果文件，内容见图12-13。
Mrjob框架的介绍告一段落，下一节重点以实际案例进行说明。
---
## Page 236
第12章Python大数据应用详解215
2.1
图12-11任务执行结果（部分截图）
Completed Jobs
bid
Fr1 Aus
102 150
OREL
Aui
VERY_BTG
图12-12已完成任务清单（部分截图）
图12-13查看任务结果文件内容
---
## Page 237
216第二部分高级篇
12.4实战分析
在互联网企业中，随着业务量、访问量的不断增长，用户产生的数据也越来越大，如何
处理大数据的存储与分析问题呢？比如Web服务器的访间log，当日志只有GB单位大小时，
我们还可以勉强通过shell、awk进行分析，当达到上百GB，甚至上PB级别时，通过脚本
的方式已经力不从心了。另外一个待解决的问题就是数据存储。Hadoop很好地解决了这两
个问题，即分布式存储与计算。下面将通过示例介绍如何从Web日志中快速获取访问流量、
HTTP状态信息、用户IP信息、连接数/分钟统计等。
12.4.1示例场景
站点www.website.com共有5台Web设备，日志文件存放位置：/data/logs/日期
（20140215)/access.log，日志为默认的Apache定义格式，如：
u0d/05e1/ex31/x91e9/ 130[000+ c919916010102/5/101 - - 8*82*92*521
"Mozi1la/4,0 (compatible MSIE 8,0: Windows NT 5.1/ Trident/4.0; GTB6.5)
InfoPath.1/ .NET CLR 2.0.50727; yie8) *
1187 "-* "Mozi1la/4.0 (compatible/ MSIE 8.0; Windows NT 5.1; Trident/4.0;
GTB6.5; InfoPath.1: .NETCLR 2.0.50727: yie8)*
66.249.65.37 - - [01/Aug/2010:09:57:59 +0700] *G8r /picture/49-02/DSC02630.Jpg
dxu/6u2/ 120000+611616010102//10]--0596*99
m=2sca1_y=2011 HTTP/1.1* 200 9232 *-" "Mozi11a/5.0 (compatible; Googlebot/2.1;
+http: //www, google.com/bot.htn1) *
共有12列数据（空格分隔），分别为：①客户端IP；②空白（远程登录名称）：③空白（认
证的远程用户）；④请求时间：UTC时差；方法：资源；⑧协议：状态码：发送