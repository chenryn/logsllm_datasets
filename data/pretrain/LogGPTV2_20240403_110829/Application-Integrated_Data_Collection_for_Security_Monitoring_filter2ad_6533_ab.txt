transactions (request–response) and user sessions. To extract that information,
a network-based monitor must perform expensive reconstruction of transactions
and sessions from single network packets, and it is still not guaranteed to cor-
rectly mimic the end-point reconstruction. In contrast, the application-integrated
Application-Integrated Data Collection for Security Monitoring
27
module is handed complete transaction and session records directly from the ap-
plication, and there is consequently no discrepancy between the interpretations.
The IDS could be preemptive. IDSs are at times criticized for being of
limited use as they can only report intrusions, usually too late to stop any
damage. By being part of the application, the module could supervise all steps
of the processing cycle and could react at any time. For example, it could deny a
single operation that appears malicious without otherwise compromising server
performance.
3.3 Disadvantages
The disadvantages of the application-integrated monitor coincide with some of
the disadvantages of the host-based monitors in general, as described in Sec-
tion 2.
Any monitoring process running on the same host as the monitored service
risks to impact the performance of the server. It is therefore important that a
goal in the monitor design and implementation is to minimize this performance
impact.
Given that one needs to have a distinct application-integrated monitor for
every single type of application one wants to monitor, the development eﬀorts
could be signiﬁcant. However, in today’s situation where a handful of products
dominate the ﬁeld of network server applications, the eﬀorts and costs required
for a satisfactory coverage could be lower than they might ﬁrst appear. This is
particularly true for applications that are open source and/or provide an API
for modules.
The application-integrated monitor can only be a complement to other types
of IDSs. As it is part of the application, it sees only the data reaching the ap-
plication. By targeting a protocol below the application layer, an attacker could
evade detection by our module, but would be within the scope of a network-based
IDS or possibly another host-based sensor specialized in lower-level protocols.
4 Design Principles and Implementation
As discussed in the previous section, current network infrastructure makes a
few applications critical. Of these, the Web server stands out as being both
ubiquitous and vulnerable. First, most organizations need a Web server, and
it is the service most users associate with the Internet. Second, even though
the server software might be as stable (or unstable) as other types of software,
many sites have customized programs connected to the server allowing access
to legacy database systems. Because these programs are easy to write, they
are often developed by junior programmers who do not properly consider the
security aspects of letting any user in the world supply any input to programs
run locally. As a result, new vulnerabilities in CGI programs are discovered
daily. Furthermore, the Web server is among the ﬁrst to be probed during a
28
M. Almgren and U. Lindqvist
reconnaissance. The vulnerabilities are easy to comprehend (e.g., add a semicolon
after the request in your browser), and the gratiﬁcation is instant (change the
Web pages and all your friends can admire your deed).
For these reasons, we chose to focus our prototype on a Web server. The
major Web server brands also have an API which provides the capabilities we
desire for application-integrated event data collection. The remaining question
is which server product to target.
Netcraft continuously conducts a survey of Web servers on the Internet [7].
Some results from the February 2001 survey are shown in Table 1. It shows that
there are three main players in the market covering more than 85%. We decided
to build our ﬁrst application-integrated data collection module for the Apache
Web server, as it is the most popular one.
Table 1. Market shares for the top Web server products [7]
Product
Developer Market Share
Apache
Microsoft-IIS
Netscape-Enterprise
Apache
Microsoft
iPlanet
60.0%
19.6%
6.2%
The market penetration for SSL is very diﬀerent. Unfortunately, the data
is considered commercially valuable and is available as a commodity only for
a prohibitively high price. Furthermore, the Netcraft survey counts each site
equally. This reﬂects neither the popularity of the site nor the risk and associated
cost of attacks. We are not aware of any other survey of this kind, and even if
the numbers above are subject to discussion, there is no doubt that Apache has
a large share of the market.
4.1
Implementation
As it turns out, it is quite easy to extend the Apache server with our data
collection module, primarily due to the following reasons.
– There is a well-deﬁned API for modules and the data concerning each request
is clearly distinguishable in distinctive data structures.
– Each request is processed in several stages, and there are so-called hooks or
callbacks in each of these stages that a module can use (see Fig. 1).
– After each stage, the module can give feedback to the server as to whether
it should continue executing the request.
– There is support for extensive logging capabilities through the reliable piped
logs interface (explained below).
Application-Integrated Data Collection for Security Monitoring
29
REQUEST
(wait)
post-read-request
URI translation
cleanup
Header parsing
access control
authentication
authorization
MIME type checking
logging
RESPONSE
fixups
document
Fig. 1. The Apache request loop [12]. The solid lines show the main transaction path,
while the dashed lines show the paths that are followed when an error is returned
Host
Web server
Data
collection
module
EMERALD
libraries
Transaction records
Auxiliary
communication
process
eFunnel
eXpert-HTTP
Fig. 2. The architecture and data ﬂow in the implementation
30
M. Almgren and U. Lindqvist
We built the module within the framework of EMERALD [8], which among
other components include the eXpert-HTTP analysis engine and the eFunnel
communications process described below. The layout of our system is depicted
in Fig. 2. For each request, the following happens:
1. The Web server passes control to our module in the logging stage of the
request cycle.
2. The module takes relevant data of the request and packs it into a format the
analysis engine eXpert-HTTP can understand.
3. Through the reliable piped logs interface of Apache, we pass the informa-
tion to an auxiliary program, which just hands the information to a second
program, eFunnel, through a socket.
4. eFunnel, in turn, communicates with an eXpert-HTTP on an external host.
5. The eXpert-HTTP performs the analysis.
Below we discuss each of these steps in detail. The design reﬂects mainly three
concerns. Most importantly, we do not want to introduce vulnerabilities into the
server software. For this reason, we decided to keep as little code as possible
within the server. The second issue is performance. If the module makes the
server slow, it will not be used. By limiting the analysis on the server host, we
gain speed but we lose interactivity between the module and the server. Third,
we wanted to reuse as much code as possible, both in the server and from the
EMERALD system.
As our major concern was the risk of introducing vulnerabilities into the
server, we decided against letting the analysis engine be part of the server.
This would have added a lot of extra code, thus increasing the complexity and
making the server more vulnerable to bugs [2, Theorem 1]. Although the analysis
engine could have been placed on the same host, we wanted to demonstrate that
larger sites can use this approach and satisfy critical performance requirements.
However, removing the analysis engine from the server in turn means we limit
the preemptive capabilities we described in Section 3, as the distance introduces
latency between the receiving of a request and the ﬁnal analysis. In Section 7, we
propose a two-tier architecture that oﬀers an acceptable trade-oﬀ between the
ability to react in real time while still minimizing performance penalties. Note
that the setup with the server existing on a separate host is more complicated
than having the analysis engine on the same host. On sites where performance
is not of critical importance, we recommend the simpler approach.
The introduced latency described in the previous paragraph restricts the
reactive capabilities of the module. For this reason, we decided to let our module
be called only in the last step of the request cycle—the logging step. By this time,
the server has interpreted the request and sent the data to the client, and all
information about the request is available for logging, which makes it easy for
our module to extract it. Even though this seems to be marginally better than
a system reading log ﬁles, we would like to point out two advantages with our
proposed application-integrated module.
First, we have access to more information. For example, consider the request
http://www.w3c.org/phf. The application-integrated monitor can determine if
Application-Integrated Data Collection for Security Monitoring
31
the server will handle the request as a CGI script (possibly bad), or if it ac-
cesses an HTML ﬁle (that, for example, describes the phf attack). Second, the
information is immediately available with the application-integrated approach.
A monitor watching a log ﬁle must wait for the application to write the informa-
tion to the ﬁle, the caching within the operating system, and possibly the next
monitor polling time.
The last steps of our design are explained by considering code reuse. Within
the EMERALD framework, we have a component called eFunnel. This program
accepts incoming connections where EMERALD messages can be transmitted,
and passes the information to outgoing connections. It can duplicate incoming
information (e.g., having two diﬀerent analysis engines for the same application)
or multiplex several incoming ﬂows into one outgoing connection (e.g., comparing
the results of a network-based monitor with an application-integrated monitor
for discrepancies). This program takes into account problems that might appear
in interprocess communication, such as lost connections or necessary buﬀering.
Thus, eFunnel exactly matches our needs to send information from the module
to other components.
On the server side, Apache provides a reliable pipe log interface. This inter-
face sends the log information directly to a program. The term reliable signiﬁes
that Apache does some checking on the opened channel, such as making sure
the connection is still accepting data. If that is not the case, it restarts the
program [12, p. 563]. We also hope to capitalize on future advances within the
implementation of this interface.
As noted, we would like to use both eFunnel and Apache’s “reliable log
format” but we run into a practical problem. In our tests, Apache started the
receiving program twice [12, p. 59], but eFunnel binds to certain predeﬁned
sockets locally, and can thus be started only once. Our solution involves the
auxiliary program described in Step 3 above, which provides a clear interface
between the Web server and the IDS. Apache can restart this program as often
as necessary, without the IDS being aﬀected.
4.2 Analysis Engine
Within EMERALD, we are developing a package of network-based IDS com-
ponents, one of them being eXpert-HTTP, an analysis component for HTTP
traﬃc. It was developed to receive event messages from the network data col-
lection component etcpgen, but can equally well receive the messages from the
application-integrated module. Actually, we can use exactly the same knowledge
base independent of the source of the data and no additional development cost
is necessary for the analysis engine. After we had completed the data collection
module, we could directly test it by having it send the data to eXpert-HTTP. It
is not surprising that as more information is available through the module than