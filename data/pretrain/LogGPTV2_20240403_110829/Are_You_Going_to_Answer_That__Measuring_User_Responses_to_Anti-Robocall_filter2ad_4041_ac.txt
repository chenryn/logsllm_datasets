### Background Color for Spam Warning

Our findings led us to minimize the use of red in the background and instead utilize other colors, such as yellow and orange, based on the color scheme suggestions provided by participants in the Focus-Spam group. We chose a yellow-to-red gradient because participants indicated that yellow and orange are also alarming. For the text, we selected a black box with white text to ensure clear contrast between elements on the screen. 

For Focus-AID, the authenticated warning, we used a blue gradient background and a blue notification box at the top of the screen. This design choice was based on focus group results, which showed that users prefer a blue background color.

### Table I: Independent Variables and Their Levels for the Experiment

| Variable | Levels |
|----------|--------|
| Response | Accept, Did Not Accept |
| Round | R1, R2, R3 |
| Warning Design | Focus-AID, Focus-Spam, Control, Avail-CID, Avail-Spam |
| Number | N1, N2, N3, N4, N5, N6 |

### Pilot Study

Before conducting the user study, we conducted a pilot study with five participants to test the Focus designs and ensure they were acceptable. Specifically, we wanted to confirm that the Focus-Spam design was alerting even without the color red. Participants provided feedback, with two requesting a smaller spam warning icon and an increase in text size, and one suggesting a green background for the authenticated call notice. The color scheme for the Focus-Spam designs was not changed for several reasons: no participant had issues with the current spam color scheme, and focus group participants stated that yellow and orange would also be alerting. Additionally, research suggests that these colors can express different hazard levels [36].

We did not change the background of Focus-AID because the majority of focus group participants (16) approved the blue color scheme in the examples presented. Research also indicates that blue motivates people to "behave in a more explorative, risky manner" [37], [38], [39], which is beneficial in this context.

### Setup

Each design was shown with an incoming call from six unique numbers, chosen based on the types of spam calls experienced by the focus group participants:
- **N1, N2**: Two known numbers entered by the participant.
- **N3**: An unknown number where the contact name is a city and state.
- **N4**: "Harold Rogers," whose number includes the same first 9 digits as the participant’s number.
- **N5**: "Veranda Gardens," which appears to be located in the same area as the participant.
- **N6**: "Ashford Loans," a loan organization with an area code different from the participant.

Participants were informed that they were testing potential app alert designs for an upcoming robocall application and were asked to respond to each incoming call as they would in real life. They provided two known numbers (N1, N2) and entered the contact information of two individuals they regularly communicate with. Each mock call displayed until the fifth ring of a monophonic or polyphonic ringtone (∼23 sec). If the participant did not respond within the allotted time, the next call appeared. Participants saw every possible combination of numbers and designs six times across three rounds in random order. Each round included three practice mock calls followed by 30 experimental mock calls, randomly displayed twice. After each round of 63 mock calls, participants were given a 5-minute break.

### Data Collection and Analysis

A total of 34 participants responded to 30 mock calls shown six times in random order, resulting in 6,120 data points. All independent variables are listed in Table I, and each warning design is described in Table II. The experiment was designed to detect cause and effect, ensuring high internal validity. We aimed to minimize external influences, providing a best-case scenario for participants to focus on the warning design.

#### Participants

- **Total**: 34
- **Age**: 20-32 (mean = 24.5, SD = 3.369)
- **Gender**: 50% female
- **Racial and Ethnic Backgrounds**:
  - East Asian: 15%
  - Caucasian: 26%
  - African American: 18%
  - South Asian: 26%
  - Latinx/Hispanic: 6%
  - Middle Eastern: 6%
  - Caribbean: 3%

Participants were recruited through a participatory system at a university, with some volunteering and others receiving extra credit. There was no overlap in participants between the focus groups and this study. Participants had to be 18 years of age or older and have experience with spam calls.

#### Analysis

For each mock call, we recorded the reaction time (time-lapse from when the call was shown until the participant pressed the button to accept or decline) and the final decision (accept or reject). We reviewed participants’ responses to ensure no one responded in a pattern to all calls, especially N1, N2, and N6. Shapiro-Wilkes and Anderson-Darling tests were run using R, and the first 5,000 data points were tested for normality. The resulting p-values were less than .001, indicating non-parametric data, confirmed with a histogram. The Aligned Rank Transform (ART) was used to transform the data, followed by a Repeated Measures Analysis of Variance (RM ANOVA).

The RM ANOVA calculated significant differences in reaction time within the independent variables: Warning Design, Number, and Round. All main effects, except Number, and interactive effects on reaction time were statistically significant (α = .05, p < .05 in all cases).

### Tables

#### Table III: Repeated Measures ANOVA Results

| Independent Variable | Reaction Time | Response |
|----------------------|---------------|----------|
| Warning Design       | p < .001, F = 5.013 | p < .001, F = 62.085 |
| Number               | p = .192, F = 1.055 | p < .001, F = 51.49 |
| Warning Design: Number | p < .001, F = 7.962 | p < .001, F = 22.361 |
| Round                | p < .001, F = 177.262 | - |
| Warning Design: Round | p < .001, F = 5.202 | - |
| Number: Round        | p = .017, F = 2.887 | - |
| Warning Design: Number: Round | p < .001, F = 1.8232 | - |

#### Table IV: Percent of Accepted Calls for Each Warning Design and Pairwise Comparisons Results for Known and Unknown Numbers (Response)

| Warning Design | All Numbers | Known #s (N1, N2) | Unknown #s (N3, N4, N5, N6) | p-value |
|----------------|-------------|-------------------|------------------------------|---------|
| Control        | 56.4%       | 100%              | 65%                          | -       |
| Focus-AID      | 61%         | 100%              | 95%                          | ns      |
| Focus-Spam     | 25%         | 34%               | 35%                          | < .001  |
| Avail-CID      | 55%         | 42%               | 34%                          | < .001  |
| Avail-Spam     | 13%         | 5%                | 3%                           | < .001  |

#### Table V: Percent of Calls Nudged in Intended Direction for Each Warning Design and Pairwise Comparisons Results for Known and Unknown Numbers for Nudge Response

| Warning Design | All Numbers | Known #s (N1, N2) | Unknown #s (N3, N4, N5, N6) | p-value |
|----------------|-------------|-------------------|------------------------------|---------|
| Control        | 77%         | 100%              | 99%                          | -       |
| Focus-AID      | 61%         | 99%               | 66%                          | .002    |
| Focus-Spam     | 75%         | 95%               | 65%                          | < .001  |
| Avail-CID      | 55%         | 42%               | 34%                          | < .001  |
| Avail-Spam     | 87%         | 35%               | 97%                          | < .001  |