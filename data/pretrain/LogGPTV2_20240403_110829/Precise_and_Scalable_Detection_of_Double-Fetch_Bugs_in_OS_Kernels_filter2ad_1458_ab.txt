and later fetch in the whole data. A common rationale behind
these cases is to abort the processing early if the request is
erroneous and save the cost of buffer allocation and a full
request copying.
Summary: It is worth noting that the goal of this analysis and
categorization is not to enumerate all possible patterns that
might cause double-fetch bugs; instead, it motivates us to ﬁnd
a generic, formal, yet comprehensive deﬁnition of multi-reads
and double-fetch bugs that can unify all these patterns as well
as potentially undiscovered ones.
C. Reﬂections on prior works
Prior works [9], [10] have been successful in ﬁnding double-
fetch bugs. However, the imprecision in their empirically
crafted detection rules makes them suffer from a high number
of both false alerts and missing bugs. As shown in §II-B,
Wang et al. [10] use code patterns to lexically match against
the kernel source code. Although this approach is scalable,
there is no guarantee that manually deﬁned patterns cover
all possible multi-reads. For example, Figure 1, 2, 3 are
double-fetch bugs, but they might not fall into the pre-deﬁned
patterns. Furthermore, simply assuming that there are no double-
fetch bugs across loops or function calls (i.e., lack of inter-
procedural analysis) might be dangerous. For example, Figure 3
is one case of a double-fetch bug that involves loops. More
cases, including inter-procedural double-fetch bugs, can be
found in Table II. In addition, the underlying pattern-matching
engine, Coccinelle [16], does not thoroughly support macro
expansion, which is heavily used in kernels and could introduce
double-fetch bugs when certain conﬁgurations are enabled. For
example, when CONFIG_COMPAT is enabled, functions designed
for compatibility reasons will be in effect, and several of them
can be buggy, as shown in Table II. Ignoring these functions
might lead to missing bugs.
663
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:58 UTC from IEEE Xplore.  Restrictions apply. 
Bochspwn [9] instead is a dynamic approach. It deﬁnes a
multi-read as at least two memory reads to the same userspace
virtual address 1) in which both originate from kernel code
execution and 2) that happen within a pre-deﬁned time frame.
Although this deﬁnition conforms to the memory access pattern
when a multi-read occurs, the dynamic nature of this approach
makes it very hard to scale to a full-ﬂedged kernel, and the
code coverage is inherently low. This has two implications: 1)
Bochspwn is limited to ﬁnding bugs within hardware devices
that can be emulated, which only account for a fraction of
drivers covered in the Linux kernel; and 2) even among the
emulated drivers, the actual amount of code that can be tested
highly depends on the test suites, which, in most cases, only
cover the hot paths.
More critically, neither of these works attempts to distinguish
double-fetch bugs from multi-reads and they completely leave
it to manual veriﬁcation. A quick scan over the Linux kernel,
however, reveals that over 1,000 multi-reads are present in the
kernel. Under the deﬁnitions in [9], [10], each of them could be
a double-fetch bug and requires manual veriﬁcation. Although
simple heuristics can be applied to ﬁlter out trivial cases, the
number of remaining cases might still be overwhelming for
manual effort. Therefore, it is important to distinguish between
multi-reads and double-fetch bugs at deﬁnition.
III. DOUBLE-FETCH BUGS: A FORMAL DEFINITION
As discussed in §II-B, relying on empirical code patterns
for double-fetch bug detection is imprecise and could result in
a lot of manual effort to verify that a multi-read is indeed a
double-fetch bug. Instead, DEADLINE labels an execution path
as a double-fetch bug when the following four conditions are
met:
1) There are at least two reads from userspace memory,
i.e., it must be a multi-read. As discussed in §II-A, a
userspace fetch can be identiﬁed by transfer functions like
copy_from_user.
2) The two fetches must cover an overlapped memory region
in the userspace. If this condition is met, we call the
multi-read an overlapped-fetch.
3) A relation must exist based on the overlapped regions
between the two fetches. We consider both control and
data dependence as relations.
4) DEADLINE cannot prove that the relation established still
holds after the second fetch. In other words, a user process
can do a race condition to change the content in the
overlapped region to destroy the relation.
Conditions 1) and 2) are straightforward to understand. For
condition 3), if the execution path can be deviated based
on the values from the ﬁrst fetch, it implies an assumption
about these values, and this assumption should be honored
by the second fetch. A typical example is shown in Figure 2,
whereby after the ﬁrst fetch, the control ﬂow is deviated if
header.version != TLS_1_2_VERSION, i.e., the second fetch
can never happen. The fact that line 13 can be reached already
implies that header.version == TLS_1_2_VERSION, which is
664
not re-checked after the second fetch and this makes it a
double-fetch bug.
For data dependence, consider the bug shown in Figure 1,
where the value khdr.iocnum is used to look up the correct
adapter, iocp, to handle the request. The fact that line 18 (the
second fetch) can be reached implies that an adapter is already
found and a mutex is already held. However, in line 22, the
adapter is looked-up again (with kfwdl.iocnum), but this time,
an adapter different from iocp can be found if the iocnum is
changed, leading to a request performed without the intended
adapter whose mutex is held.
It is also possible that both control and data dependence
exist. This typically happens when a variable representing total
message size is fetched in, sanity-checked, and later used to
do the second fetch, as shown in Figure 4a. The variable size
must be within a reasonable range, and attr->size should
hold the effective size of the attr buffer. However, after the
second fetch, both relations might not hold anymore.
For condition 4), if the relation established in condition
3) is control dependence only, we need to prove that the
same set of constraints still holds for the values copied
in after the second fetch. In the example of Figure 2, we
should check that full->version == TLS_1_2_VERSION still
holds. On the other hand, if a data dependence is estab-
lished, re-checking the conditions is not sufﬁcient and a full
equality proof is needed. In the case of Figure 4a, check-
ing that PERF_ATTR_SIZE_VER0 size size holds the
effective size of attr. The correct way is to prove that
attr->size == size in all cases.
Put the above description in formal terms:
Fetch. We use a pair (A, S) to denote a fetch, where A
represents the starting address of the fetch and S represents
the size of the memory (in bytes) copied into kernel.
Overlapped-fetch. Two fetches, (A0, S0) and (A1, S1), are
considered to have an overlapped region if and only if:
A0 ∈ Setmr do
P aths ← Construct_Execution_Paths(F0, F1, F n)
for P ∈ P aths do
if Symbolic_Checking(P , F0, F1) == UNSAFE then
Bugs.add()
4
5
6
7
8
9
10
11
12
13 end
end
end
end
whether the multi-read is a double-fetch bug based on the
formal deﬁnitions. This step is depicted in detail in §VI.
V. FINDING MULTI-READS
Finding multi-reads is the ﬁrst step for double-fetch bug
detection. Prior works either used empirical rules [10] or relied
on dynamic memory access patterns [9] to ﬁnd multi-reads,
both of which could be problematic (e.g., assuming multi-
reads are intra-procedural). To inherently improve the ﬁnding
of multi-reads, DEADLINE instead employs static and symbolic
program analyses to systematically ﬁnd multi-reads against the
whole kernel codebase.
A. Fetch pairs collection
In this step, the goal for DEADLINE is to statically enu-
merate all multi-reads that could possibly occur. In particular,
DEADLINE tries to identify all the fetch pairs that can be
reached at least statically, i.e., there exists a reachable path in
the control ﬂow graph (CFG) between the two fetches (i.e., a
fetch pair).
One approach is to 1) identify all fetches in the kernel,
i.e., calls to transfer functions; 2) construct a complete, inter-
procedural CFG for the whole kernel; and 3) perform pair-
wise reachability tests for each pair of fetches. Although 1) is
easy, given the scale and complexity of kernel software, both
2) and 3) are hard if not impossible in practice. Therefore,
DEADLINE chooses to ﬁnd fetch pairs in a bottom-up manner,
as described in Algorithm 2. In short, starting at each fetch,
within the function it resides in, DEADLINE scans through
both the reaching and reachable instructions for this fetch and
among those instructions, either marks that we have found a
fetch pair (line 6, 15) or inline the function containing a fetch
and re-executes the search (line 9, 18).
Note that, in addition to the two fetches, the enclosing
function F n is also attached to the pair, and we use this
triple to denote a multi-read in DEADLINE. Conceptually, this
F n is the deepest function in the global call graph (if it
can ever be constructed) that encloses both fetches, and later
the execution paths will be constructed within this F n. This
alleviates DEADLINE in constructing execution paths from
ﬁxed entry and exit points such as syscall enter and syscall
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:58 UTC from IEEE Xplore.  Restrictions apply. 
Algorithm 2: Collect_Multi_Reads(F )
In : F - A fetch, i.e., a call to a transfer function
Out : R - A set of triples  representing multi-reads
1 F n ← Function that contains F ;
2 R ← ∅;
3 Setup ← Get_Upstream_Instructions(F n, F );
4 for I ∈ Setup do
if I is a fetch then
R.add()
end
if I is a call to a function that contains a fetch then
5
6
7
8
9
10
11 end
12 Setdn ← Get_Downstream_Instructions(F n, F );
13 for I ∈ Setdn do
Inline I, redo the algorithm
end
if I is a fetch then
R.add()
end
if I is a call to a function that contains a fetch then
Inline I, redo the algorithm
14
15
16
17
18
19
20 end
end
return, which are usually very lengthy with many irrelevant
instructions to the forming of a double-fetch bug.
Indirect calls. One special case in this process is an indirect
call, which is often used in kernel to simulate polymorphism
behaviors. DEADLINE does not attempt to resolve the actual
targets of an indirect call (in fact, in many cases, they can only
be resolved at runtime). Instead, DEADLINE conservatively
identiﬁes all potential targets of an indirect call. Speciﬁcally,
DEADLINE ﬁrst collects the address-taken functions and then
employs the type-analysis-based approach [18], [19] to ﬁnd the
targets of indirect calls. That is, as long as the type of arguments
of an address-taken function matches with the callsite of an
indirect call, we assume it is a valid target of the indirect call.
B. Execution path construction
In this step, DEADLINE is given a triple 
which represents a multi-read, and the goal for DEADLINE is
twofold: 1) to ﬁnd all execution paths within the enclosing
function (F n) that connect both fetches (F0 and F1) and 2) to
slice out the irrelevant instructions that have no impact on the
fetches or are not affected by the fetches, for each execution
path.
Both parts can be solved with standard program analysis
techniques. The ﬁrst part can be done by a simple CFG traversal
within the function F n, while the second part can be achieved
by slicing the function CFG with the following criteria:
• An instruction is considered to have an impact on a fetch
if the address or size of the fetch is either derived from
it or constrained by it.
• An instruction is considered to be affected by a fetch if it
is derived from the fetched-in value or it constrains the
fetched-in value.
With these criteria, we preserve all the control and data
dependence relations that we need to prove and thus to decide
whether a multi-read is a double-fetch bug, as deﬁned in §III.
Linearize an execution path. One last step in the path
construction is to linearize the paths into a sequence of
IR instructions. For a path without loops, linearization is
simply a concatenation of the basic blocks; however, for a
path with loops, unrolling is required. DEADLINE decides
to unroll a loop only once1. This imposes a limitation
to DEADLINE: DEADLINE is unable to ﬁnd double-fetch
bugs caused by one fetch overlapping with itself when the
loop is executed multiple times. In fact,
in kernel, such
double-fetch bugs can almost never happen, as fetches in
loops are usually designed in an incremental manner, e.g.,
copy_from_user(kbuf, ubuf, len); ubuf += len;. In this
case, the two fetches are always from non-overlapping memory
regions and will never satisfy the condition for a double-fetch
bug. On the other hand, unrolling the loop once does help
DEADLINE ﬁnd double-fetch bugs caused by two fetches across
loops, as shown in Figure 3.
VI. FROM MULTI-READS TO DOUBLE-FETCH BUGS
Prior works [9], [10] rely on manual veriﬁcation to check
whether a multi-read turns into a double-fetch bug, which can
be time consuming and error-prone. Instead, DEADLINE applies
symbolic checking to automatically vet whether a multi-read
is a double-fetch bug based on the formal deﬁnitions in §III.
A. A running example
To help illustrate the concepts in this section, we provide a
running example in Figure 4. It is a double-fetch bug found
by DEADLINE in the perf_copy_attr function and has been
patched in Linux kernel 4.13. In summary, the ﬁrst fetch
(line 8) copies in a 4-byte value size, which is later sanity
checked (line 12, 13) and also used for the second fetch (line
17). However, after the second fetch, the overlapped region
attr->size is not subject to any constraints until the end of
the function. In this case, a user process could put a proper
value, say uattr->size = 128, before the ﬁrst fetch so that it
will pass both sanity checks and later uses a race condition