-   日志异常模式识别方法研究：利用机器学习技术对历史数据进行学习并实现自动训练，通过学习训练出的日志异常检测模式，将模型与对实时日志的聚类模式进行对比，实现对未知错误类型、错误出现的异常占比模型进行实时检测发现，从而达到日志模式异常检测的目的。
-   海量告警降噪收敛方法研究：在当前复杂的应用架构中，一个小故障就会触发大规模告警风暴，有大量无效的告警，对于系统产生的告警事件，通过智能归并算法实现告警智能归并，减少无效告警等告警噪声，从海量告警中识别有效告警，让运维人员能够从重复的低附加工作中解放出来聚焦于更有价值的系统优化类高附加值工作。
## 4.1 多维系统日志智能规范化方法
数据质量和数据组织格式是智能运维模型能否成功落地的首要前提条件，如果没有良好的数据基础，再好的数据模型也很难达到预期的分析效果，优质的数据基础是智能运维模型落地的重要保障。
这些基础监控工具采集的运行状态数据和运行性能数据，需要具备足够存量的数据和数据增量；以及足够的数据维度覆盖度（时间维度、空间维度、系统级维度、应用级维度等）才能进行建模利用。
![](media/image6.jpeg){width="5.5375in" height="4.002777777777778in"}
本次研究提出多维系统日志智能规范化的处理流程和具体处理方法，可以实现自动识别日志类型，并将原始非结构化数据转化为结构化数据。
4.1.1 多维系统日志
对于多维系统日志，日志可以按照以下方式分类
运维数据按照所更新的频率可分为静态数据和动态数据。
-   静态数据
主要包含CMDB数据、变更管理数据、流程管理数据、平台配置信息数据等。此类数据一般情况下在一定时间范围内是固定不变，主要是为动态数据分析提供基础的配置信息。对此类数据的查询操作多，增删改操作较少。当智能运维平台启动时，部分静态数据可直接加载到内存数据库中，因此静态数据一般保存在结构化数据库中或者Hive平台。
-   动态数据
主要包含各类监控指标数据、日志数据以及第三方扩展应用所产生的数据。此类数据一般是实时生成并被获取，并作为基础数据，需要通过数据清洗转换成可使用的样本数据。动态数据一般按不同的使用场景保存在不同大数据组件中，如用于分析的数据保存在Hive数据库，用于检索的日志数据可保存在ES（即ElasticSearch）中。
按照日志来源分析
包括电力信息系统系统产生的应用日志、服务器日志、中间件日志、数据库日志、网络安全设备日志等日志数据，以及网络监控系统、应用管理系统等运维保障系统产生的告警数据，数据种类繁多，存在多行日志数据、多线程打印数据、特殊编码格式数据等，需要做智能运维分析的前提一定要将需要的数据字段进行提取格式化，做到格式统一，方便分析处理。
一般情况下，对非结构化数据的处理通过智能化匹配，提取字段后建立字段索引，则可形成新的结构化数据形式，提高搜索效率。但是非结构化机器数据格式是经常改变，对于没有提取到字段信息的数据，如果需要进行字段统计，则需要实现搜索时提取字段功能。
如果说"日志"是一段文本，记载着设备每天所做的各类工作和运行状态，那么字段就是其中有意义的单词或短语。多维系统智能规范化需要完成"字段解析"，即把日志中的字段提取出来。
字段解析能够将日志提取为更加精简有效的信息，它是智能运维中的重要步骤，也是众多其他日志处理方法的前提步骤。
4.1.2 字段
通常来说，日志是某些操作及其结果的集合，它们按照时间排序。这些信息都可以作为字段被提取出来。以下是一条日志记录的示例：
192.168.1.103 - - \[01/Aug/2014:12:07:39 +0800\] \"GET / HTTP/1.1\\\"
200 3228 \"-\" \"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1;
Trident/4.0; .NET CLR 2.0.50727;
.NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET CLR 1.1.4322;
.NET4.0C)"
可抽取出的部分字段如下：
-   \"client_ip\":\"192.168.1.103\"
-   \"timestamp\":\"01/Aug/2014:12:07:39+0800\"
-   \"method\":\"GET\"
-   \"status\":200
-   \"resp_len\":3228
-   \"os\":\"WindowsNT5.1\"
可以直观地看到，该条日志记录包含了日志来源地址、日志产生的时间戳、请求方式、状态码、消息长度、系统描述等信息。不难理解，字段（field）就是从日志记录中抽取出的一段文本信息，如示例中的client_ip字段，有其特定的含义。
不同的字段，对于不同的管理人员有不同的意义。对应上面的例子，系统描述、时间戳等都是基本的字段信息。但对于网络管理员来说，他可能比较关注的是浏览器版本（如MSIE
8.0）、网络操作系统（如Windows NT
5.1）等字段；而对于数据库管理员来说，他可能比较关注某类数据库信息，更希望提取到与"MySQL"相关的信息。
4.1.3 通用的日志字段
日志来源的不同会导致日志内容也有所不同，但有一组字段是存在于大多数日志当中的，它包含了日志产生的基本信息，称之为通用字段。以下对常用的一组字段分别进行阐述。
1.  时间戳
时间戳，表示日志产生的日期和时间，包含年月日、时分秒，理想情况下还应包含时区。例如：
2017-06-08T11:29:29.209Z
上述示例是标准的XML
Schema日期型数据格式，'T'代表后面跟着时间，'Z'代表0时区，或者叫UTC统一时间（UTC通用标准时）。
值得注意的是，时间戳有各种各样的格式：
-   如果符合ISO8601标准的格式，则形式如：FriJul0521:28:242013ISO8601；
-   如果符合UNIX系统的格式，则形式如：1412899200.000。
2.  日志来源
"日志来源"表明日志从哪里来。机房中的各种软件（系统、防火墙等）和硬件（交换机、路由器等）都在不断地生成日志，都可能成为日志来源。第四章中已经提到，根据日志采集方式分类，基于"推"的主要日志来源有：Syslog、SNMP、Windows；基于"拉"的日志来源有：拉取的Checkpoint防火墙日志、拉取的MySQL数据库日志等。
举例一些常见的日志来源：
-   操作系统：记录操作系统的各种活动信息，例如Linux的登录信息；
-   网络守护进程：记录各类网络连接服务的消息；
-   应用程序：记录应用程序用户的活动信息。
3.  执行结果
日志通常会明确地表明该条目代表的系统活动是成功还是失败，并给出提示信息。下例ERROR就是明确的报错信息，具体表示数据库连接失败：
ERROR: DB connection error!
4.  日志优先级
日志优先级代表了日志消息的严重性，用户可以根据需求，解析出不同等级的日志。以Apache的一个开源项目Log4j为例，Log4j定义了8种日志级别，优先级从高到低依次为：OFF、FATAL、ERROR、WARN、INFO、DEBUG、TRACE、ALL。
-   ALL：最低等级的，用于打开所有日志记录。
-   TRACE：很低的日志级别，一般不会使用。
-   DEBUG：指出细粒度信息事件对调试应用程序是非常有帮助的，主要用于开发过程中打印一些运行信息。
-   INFO：消息在粗粒度级别上突出强调应用程序的运行过程。打印一些程序员感兴趣的或者重要的信息，这个可以用于生产环境中输出程序运行的一些重要信息，但是不能滥用，避免打印过多的日志。
-   WARN：表明会出现潜在错误的情形，有些信息不是错误信息，但是也要给程序员一些提示。
-   ERROR：指出虽然发生错误事件，但仍然不影响系统的继续运行。打印错误和异常信息，如果不想输出太多的日志，可以使用这个级别。
-   FATAL：指出每个严重的错误事件将会导致应用程序的退出，级别比较高。重大错误，出现这种级别的提示，可以直接停止程序
-   OFF：最高等级的，用于关闭所有日志记录。
值得注意的是，当解析某一个级别的日志时，比此级别优先级高的所有日志也会被解析出来。例如，如果优先级设置为WARN，那么OFF、FATAL、ERROR、WARN四个级别都在输出的考虑范围内。
4.1.3 日志语法
任何格式的日志文件都具有语法。日志语法在概念上与人类语言（如英语）语法相似。人类语言语法中的句子通常包含主语、谓语、还有表语、补语、定语等。了解日志的语法，就能将日志分解成各个组成部分，便于之后的日志抽取和分析。
对Syslog的单条记录做一次"语法分析"，如此条记录：
SERVERS.NET class 1 do not match hint records
"主语"是一个class，"谓语"是match，"宾语"是records。
4.1.4 处理流程
多维系统非结构化数据智能规范化处理流程如下：
![解析](media/image7.png){width="5.833333333333333in"
height="4.861111111111111in"}
图 4 数据智能规范化处理流程图
1.  收到一条原始非结构化数据raw_event
2.  提取关键信息key(token +
    appname（appname不存在则使用hostname）)，从ParserCache中找对应的解析规则EventParser
3.  如果找到对应的解析规则并且处理成功 ，则返回structured event
4.  如果没找到对应的解析规则EventParser 或解析 EventParser
    处理不成功，进入ParserContainer处理
5.  看token+appname是否有对应的用户Custom配置
6.  如果有则使用按照其配置产生的Parser来处理，如果处理成功则产生event_parser和structured
    event,更新cache，若不成功则使用DefaultParser只保留raw_message，不提取任何字段
7.  如果没有，则使用Common配置处理，需要依次使用各种类型的Parser去尝试处理，如果处理成功则产生event_parser和结构化数据structured
    event，更新cache，若不成功则使用DefaultParser只保留raw_message，不提取任何字段