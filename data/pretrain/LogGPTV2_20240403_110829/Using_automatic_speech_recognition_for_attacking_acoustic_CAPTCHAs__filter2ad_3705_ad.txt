1
0
2
4
6
Time [s]
8
10
Figure 4: Example of the proposed CAPTCHA design for
T60 = 100 ms showing the digit sequence “01-64-75-36”.
5.3 Usability
We assess the usability of the proposed CAPTCHA, i.e.,
the human success rate, by means of the same listening ex-
periment as it is outlined in Sec. 4.2. This environment does,
of course, constitute an ideal situation, which has been cho-
sen for reproducibility and consistency of results.
Two diﬀerent variants of the proposed CAPTCHA are
compared, one with a reverberation time of 100 ms and the
other with a reverberation time of 300 ms. In the experi-
ment, we ﬁnd the results for 200 randomly selected signals
at each reverberation time.
The overall number of individual participants was 20 and
each participant was asked to transcribe a set of 50 audio
signals per experiment. In order to derive the transcription
agreements as in Sec. 4.2, each signal is labeled by four dif-
ferent listeners. Some participants attended multiple times
where we again ensured that no CAPTCHA was labeled
more than once by the same listener.
Table 5: Human recognition scores in percent for the pro-
posed CAPTCHA. The scores are based on the listening
test results of 800 CAPTCHAs (sentences), corresponding
to 7,280 digits (words).
Sent Acc. Word Acc.
Mean
Std. dev.
56.38
21.47
91.74
7.18
(a) T60 = 100 ms
Sent Acc. Word Acc.
Mean
Std. dev.
37.81
17.65
86.88
7.90
(b) T60 = 300 ms
The results for the transcription agreement between the
participants are shown in Tab. 4a and Tab. 4b, for the rever-
beration time T60 = 100 ms and for T60 = 300 ms, respec-
tively. The actual human recognition scores, computed by
using the reference transcription, are presented in Tab. 5.
Considering ﬁrst the reverberation time T60 = 100 ms,
we can see from Tab. 4a that the majority of digit blocks
(53.63 %) received a transcription agreement from all par-
ticipants, whereas the number of agreements on the full
transcription is comparatively low (18.50 %). This eﬀect is
also reﬂected in the human recognition scores (cf. Tab. 5a),
where the word accuracy is satisfactorily high (91.74 %) but
the sentence accuracy is only 56.38 %. For the reverberation
time T60 = 300 ms, the number of transcription agreements
is signiﬁcantly lower than with T60 = 100 ms. Here, the
majority of CAPTCHA signals (i.e., 57.50 %) has no agree-
ment on the full transcription. Furthermore, only 0.37 %
of the digit blocks show an agreement between all partici-
pants and no CAPTCHA has a full transcription agreement
between all participants. Regarding the human recognition
scores for T60 = 300 ms, we can see from Tab. 5b that only
37.81 % of the CAPTCHAs are transcribed correctly.
5.4 Security Analysis
The security analysis of the proposed CAPTCHA is based
on the same ASR system that is used in the previous sec-
tions, to allow for a fair comparison.
System Setup.
Since we have generated all CAPTCHAs ourselves, we
have the exact knowledge about the temporal positions of
digits within the audio signals. Thus, we utilize 200 signals
for bootstrapping the HMM parameters, which represents a
high-quality initialization procedure compared to Sec. 3 and
Sec. 4, since the transcriptions are perfectly time-aligned
with the spoken digits.
After initializing the HMMs, the model parameters are
reestimated using a varying number of CAPTCHA signals
to analyze the inﬂuence of additional training material on
the recognition performance. Here, we vary the number of
training examples that are used for model reestimation be-
tween 200 and 1600 CAPTCHAs. In addition, we compare
the results for three diﬀerent reverberation times, i.e., 0 ms,
100 ms, and, 300 ms, where the former represents the case
of a non-reverberant signal.
In each case, the recognition
results are based on 10,000 randomly chosen CAPTCHAs.
We apply a task-speciﬁc grammar for signal decoding:
S → N B N B N B N B N [B N] ,
B → D D ,
(22)
where the symbols S, B, D and N are as deﬁned by Eq. 11.
Results.
Table 6 shows the ASR recognition results for a vary-
ing number of training examples and diﬀerent reverberation
times. It should be emphasized that this security analysis
of the proposed CAPTCHA is much more rigorous than the
one applied to reCAPTCHA (cf. Sec. 4.4) as we make use of
the ideal reference transcriptions for training the ASR sys-
tem. Furthermore, the number of digits that were utilized
for training is 1.2–9.6 × (1800–14400 digits) higher than for
reCAPTCHA (1500 digits).
We can see from Tab. 6 that the sentence accuracy for
the non-reverberant case, i.e., T60 = 0 ms, and the low-
est amount of training examples, i.e., 200 CAPTCHAs, is
Table 6: ASR results in percent for the proposed scheme.
The scores are based on 10,000 diﬀerent CAPTCHAs (sen-
tences), corresponding to 90,140 digits (words).
# Train T60 [ms]
Sent Acc. Word Acc.
200
200
200
400
400
400
800
800
800
1600
1600
1600
0
100
300
0
100
300
0
100
300
0
100
300
15.86
5.33
1.25
17.42
5.06
2.34
20.38
6.87
3.14
26.43
6.26
4.11
77.03
64.49
56.11
78.38
65.32
60.20
79.71
67.21
62.88
82.43
67.37
64.66
comparatively high at 15.86 %. Additionally, the word and
sentence accuracies are further improved by increasing the
number of training examples. Here, it appears that the
relationship between the number of training examples and
the resulting accuracies is virtually linear. Thus, an ASR-
based CAPTCHA solver can easily cope with the overlap-
ping digit sequences as well as with the babble noise seg-
ments to some degree, rendering these signals non-robust
against automated attacks.
For T60 = 100 ms, the word and sentence accuracy drops
by approximately 10–20 %, depending on the number of train-
ing examples. This demonstrates that already moderate re-
verberation eﬀects are already problematic for speech recog-
nition. However, the ASR system is able to ﬁnd the correct
transcription for approximately 6 % of the attacked CAPT-
CHA signals, averaged over the number of utilized training
examples.
As one would expect, the lowest ASR scores are given
for T60 = 300 ms. Here, the ASR system only identiﬁes
approximately 3 % of the CAPTCHAs correctly.
We can conclude that the best trade-oﬀ between usabil-
ity and security for the proposed scheme is given for T60 =
100 ms. A side-by-side comparison between the proposed
CAPTCHA and the current reCAPTCHA scheme is pro-
vided by Tab. 7. Here, the success rate of the attack is
5.33 % when using 1800 digits for training the ASR system.
This is a factor 12 below the success rate found for the re-
CAPTCHA scheme (62.8 %) by using 1500 digits for system
training. Furthermore, the human success rate for the pro-
posed scheme was found to be 56.38 % that is twice as high
as for the current reCAPTCHA scheme.
Table 7: Summary of recognition scores in percent for ASR
and human listeners, shown for the proposed CAPTCHA
(T60 = 100 ms) and the current reCAPTCHA scheme.
ASR Human
Proposed CAPTCHA
reCAPTCHA 03/2014
5.33
62.8
56.38
24.40
6. CONCLUSION AND FUTURE WORK
In this paper, we show that it is advisable to utilize state-
of-the-art speech recognition techniques for evaluating the
security of acoustic CAPTCHAs, as this yields signiﬁcantly
higher success rates for CAPTCHA solving than previously
suggested classiﬁcation methods and is therefore more in-
dicative of the security risk of a CAPTCHA. Using the well-
known reCAPTCHA as an example, we can see that the
general characteristics of the scheme have not changed no-
tably within the last four years, which leads to compara-
tively high success rates for automated attacks. In addition,
the degree of signal distortion has been increased for this
scheme at the cost of reducing human accuracy, rendering
the trade-oﬀ between usability and security problematic.
We propose an experimental CAPTCHA scheme that ex-
ploits both the auditory capabilities of humans and weak-
nesses in current ASR techniques. In this scheme, we render
the ASR-based attack more diﬃcult by introducing overlap-
ping speakers and artiﬁcial room reverberation eﬀects. The
outcome of our experiments is that the proposed CAPTCHA
exhibits a far better trade-oﬀ between human usability and
security as the current reCAPTCHA scheme.
Our results conﬁrm the ﬁndings of previous research in
that we show that a very conservative CAPTCHA, even if
it is only barely intelligible for humans, can potentially be
learned by an automated system at a relatively low cost.
We can hence assume that it is infeasible to create a small-
vocabulary-based CAPTCHA with a very high human suc-
cess rate (≥ 90 %) while remaining robust against automatic
solvers, i.e., yielding only insigniﬁcantly low success rates
(≤ 1 % or even ≤ 0.01 %). Thus, it becomes necessary to
investigate into new directions for CAPTCHA design, such
as the utilization of a larger vocabulary or the incorporation
of context-based questions that require human intelligence.
For the time being, though, our acoustic CAPTCHA did
succeed in signiﬁcantly improving human pass rates—from
24 % to 56 %—while reducing the attack success rate of an
ASR solver from 63 % to 5 %, when comparing with the cur-
rent, state-of-the-art reCAPTCHA scheme. This lends cred-
ibility to the general approach of explicitly considering hu-
man auditory processing capabilities in CAPTCHA designs,
and should serve as a building block for new systems that
oﬀer a satisfactory trade-oﬀ between usability and security.
Acknowledgments
The authors would like to thank all participants of the listen-
ing experiments. The research was supported by the DFG
Research Training Group GRK 1817/1. The CAPTCHA ex-
amples of our proposed scheme are available upon request.
7. REFERENCES
[1] S. Bohr, A. Shome, and J. Z. Simon. Improving
Auditory CAPTCHA Security. Technical report, ISR,
A. James Clark School of Engineering, 2008.
[2] A. S. Bregman. Auditory scene analysis: The
perceptual organization of sound. MIT press, 1994.
[3] E. Bursztein, R. Bauxis, H. Paskov, D. Perito,
C. Fabry, and J. C. Mitchell. The Failure of
Noise-Based Non-Continuous Audio Captchas. In
Proc. IEEE Symposium on Security and Privacy, 2011.
[4] E. Bursztein and S. Bethard. Decaptcha Breaking 75%
of eBay Audio CAPTCHAs. In Proc. WOOT, 2009.
[5] K. Chellapilla, K. Larson, P. Y. Simard, and
M. Czerwinski. Building Segmentation Based
Human-Friendly Human Interaction Proofs (HIPs). In
Human Interactive Proofs. Springer, 2005.
[6] R. Datta, J. Li, and J. Z. Wang. IMAGINATION: A
Robust Image-based CAPTCHA Generation System.
In Proc. ACM MM, 2005.
[7] dfactory. Math Captcha, 2014.
http://wordpress.org/plugins/wp-math-captcha/.
[8] R. Dingledine, N. Mathewson, and P. Syverson. Tor:
The Second-generation Onion Router. In Proc.
USENIX Security Symposium, 2004.
[9] P. Divenyi. Speech separation by humans and
machines. Springer, 2005.
[10] I. Fischer and T. Herfet. Visual CAPTCHAs for
document authentication. In Proc. MMSP, 2006.
[11] M. Gales and S. Young. The Application of Hidden
Markov Models in Speech Recognition. Foundations
and Trends in Signal Processing, 2007.
[12] Google. reCAPTCHA. http://www.recaptcha.net.
[13] H. Hermansky, B. Hanson, and H. Wakita.
Perceptually based linear predictive analysis of speech.
In Proc. ICASSP, 1985.
[14] A. Hindle, M. W. Godfrey, and R. C. Holt. Reverse
Engineering CAPTCHAs. In Proc. WCRE, 2008.
[15] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r.
Mohamed, N. Jaitly, A. Senior, V. Vanhoucke,
P. Nguyen, T. N. Sainath, et al. Deep neural networks
for acoustic modeling in speech recognition: The
shared views of four research groups. IEEE Signal
Processing Magazine, 2012.
[16] G. Kochanski, D. P. Lopresti, and C. Shih. A reverse
turing test using speech. In Proc. INTERSPEECH,
2002.
[17] R. G. Leonard and G. Doddington. TIDIGITS
Linguistic Data Consortium, 1993. Linguistic Data
Consortium.
[18] R. P. Lippmann. Review of neural networks for speech
recognition. Neural computation, 1989.
[19] N. Morgan, H. Bourlard, and H. Hermansky.
Automatic Speech Recognition: An Auditory
Perspective. In Speech Processing in the Auditory
System. Springer, 2004.
[20] picatcha.com, 2014. http://picatcha.com.
[21] L. Rabiner and B.-H. Juang. Fundamentals of Speech
Recognition. Prentice Hall, 1993.
[22] S. Sano, T. Otsuka, and H. Okuno. Solving Google’s
Continuous Audio CAPTCHA with HMM-Based
Automatic Speech Recognition. In Advances in
Information and Computer Security, 2013.
[23] A. Schlaikjer. A dual-use speech CAPTCHA: Aiding
visually impaired web users while providing
transcriptions of Audio Streams. LTI-CMU Technical
Report, 2007.
[24] R. Soni and D. Tiwari. Improved captcha method.
IJCA, 2010.
[25] J. Tam, J. Simsa, D. Huggins-Daines, L. von Ahn, and
M. Blum. Improving Audio CAPTCHAs. In Proc.
SOUPS, 2008.
[26] J. Tam, J. Simsa, S. Hyde, and L. von Ahn. Breaking
Audio CAPTCHAs. In Proc. NIPS, 2008.
[27] A. Varga and H. J. M. Steeneken. Assessment for
automatic speech recognition: II. NOISEX-92: A
database and an experiment to study the eﬀect of
additive noise on speech recognition systems. Speech
Communication, 1993.
[28] T. Virtanen, R. Singh, and B. Raj. Techniques for
Noise Robustness in Automatic Speech Recognition.
Wiley, 2012.
[29] L. von Ahn, M. Blum, N. J. Hopper, and J. Langford.
CAPTCHA: Using Hard AI Problems for Security. In
EUROCRYPT. Springer, 2003.
[30] L. von Ahn, M. Blum, and J. Langford. Telling
Humans and Computers Apart Automatically.
CACM, 2004.
[31] J. Yan and A. S. El Ahmad. Breaking visual captchas
with naive pattern recognition algorithms. In Proc.
ACSAC, 2007.
[32] J. Yan and A. S. El Ahmad. A Low-cost Attack on a
Microsoft CAPTCHA. In Proc. ACM CCS, 2008.
[33] S. Young. The HTK Hidden Markov Model Toolkit:
Design and Philosophy. Entropic Cambridge Research
Laboratory, Ltd, 1994.