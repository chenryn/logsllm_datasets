title:Cost-Aware Robust Tree Ensembles for Security Applications
author:Yizheng Chen and
Shiqi Wang and
Weifan Jiang and
Asaf Cidon and
Suman Jana
Cost-Aware Robust Tree Ensembles for 
Security Applications
Yizheng Chen, Shiqi Wang, Weifan Jiang, Asaf Cidon, and 
Suman Jana, Columbia University
https://www.usenix.org/conference/usenixsecurity21/presentation/chen-yizheng
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.Cost-Aware Robust Tree Ensembles for Security Applications
Yizheng Chen, Shiqi Wang, Weifan Jiang, Asaf Cidon, and Suman Jana
Columbia University
Abstract
There are various costs for attackers to manipulate the fea-
tures of security classiﬁers. The costs are asymmetric across
features and to the directions of changes, which cannot be
precisely captured by existing cost models based on Lp-norm
robustness. In this paper, we utilize such domain knowledge
to increase the attack cost of evading classiﬁers, speciﬁcally,
tree ensemble models that are widely used by security tasks.
We propose a new cost modeling method to capture the fea-
ture manipulation cost as constraint, and then we integrate the
cost-driven constraint into the node construction process to
train robust tree ensembles. During the training process, we
use the constraint to ﬁnd data points that are likely to be per-
turbed given the feature manipulation cost, and we use a new
robust training algorithm to optimize the quality of the trees.
Our cost-aware training method can be applied to different
types of tree ensembles, including gradient boosted decision
trees and random forest models. Using Twitter spam detec-
tion as the case study, our evaluation results show that we
can increase the attack cost by 10.6⇥ compared to the base-
line. Moreover, our robust training method using cost-driven
constraint can achieve higher accuracy, lower false positive
rate, and stronger cost-aware robustness than the state-of-the-
art training method using L•-norm cost model. Our code is
available at https://github.com/surrealyz/growtrees.
1 Introduction
Many machine learning classiﬁers are used in security-
critical settings where adversaries actively try to evade them.
Unlike perturbing features (e.g., pixels, words) in other ma-
chine learning applications, the attacker has different cost to
manipulate different security features. For example, to evade
a spam ﬁlter, it is cheaper to purchase new domain names than
to rent new hosting servers [37]. In addition, a feature may be
expensive to increase, but easy to decrease. For example, it
is easier to remove a signature from a malware than to add
one signed by Microsoft to it [27]. We need cost modeling
methods to capture such domain knowledge about feature
manipulation cost, and utilize the knowledge to increase the
attack cost of evading security classiﬁers.
Since it is extremely hard, if not impossible, to be robust
against all attackers, we focus on making a classiﬁer robust
against attackers bounded by the feature manipulation cost
model. To evaluate cost-aware robustness against unbounded
attackers, we measure the attack cost as the total cost re-
quired to manipulate all features to evade the trained classi-
ﬁers. However, existing cost modeling based on Lp-norm is
not suitable for security applications, since it assumes uni-
form cost across different features and symmetric cost to
increase and decrease the features. Moreover, many recent
works focus on improving the robustness of neural network
models [17, 19, 25, 36, 38, 40, 41, 51, 52, 54, 55], whereas se-
curity applications widely use tree ensemble models such
as random forest (RF) and gradient boosted decision trees
(GBDT) to detect malware [34], phishing [16, 20, 26], and
online fraud [31, 42, 49], etc. Despite their popularity, the
robustness of these models, especially against a strong adver-
sary is not very thoroughly studied [11, 29, 44]. The discrete
structure of tree models brings new challenges to the robust-
ness problem. Training trees does not rely on gradient-guided
optimization, but rather by enumerating potential splits to
maximize the gain metric (e.g., Information gain, Gini impu-
rity reduction, or loss reduction). It is intractable to enumerate
all possible splits under attacks [11].
Figure 1 shows an example where we can obtain better
accuracy and stronger robustness against realistic attackers,
if we train a robust decision tree model using knowledge
about feature manipulation cost, instead of using the L•-norm
bound. In the left ﬁgure, the square box denotes L•-norm
bound for four data points with two feature dimensions. We
use the dashed line to denote the classiﬁcation boundary of
the robust split, which can achieve 75% accuracy, and 75%
robust accuracy against L•-norm bounded attacks. However,
in practice, the classiﬁer may not have 75% robust accuracy
against realistic attackers. The dashed rectangular box for
the cross on the left side represents the realistic perturbation
bound, that it is easier to increase a data point than to decrease
it along feature 1, and it is harder to perturb feature 2 than
feature 1. Thus, the data point can be perturbed to evade
the robust split, and the actual robust accuracy is only 50%
against the realistic attack. In comparison, if we can model the
feature manipulation cost as constraints for each data point’s
perturbation bound, we can learn the robust split in the right
ﬁgure and achieve 100% accuracy and robust accuracy.
In this paper, we propose a systematic method to train cost-
aware robust tree ensemble models for security, by integrating
domain knowledge of feature manipulation cost. We ﬁrst pro-
USENIX Association
30th USENIX Security Symposium    2291
feat(cid:88)re 2
feat(cid:88)re 2
X
O
deci(cid:86)i(cid:82)n 
b(cid:82)(cid:88)nda(cid:85)(cid:92)
X
O
X
O
deci(cid:86)i(cid:82)n 
b(cid:82)(cid:88)nda(cid:85)(cid:92)
X
O
feat(cid:88)re 1
feat(cid:88)re 1
Figure 1: An example that we can obtain better model perfor-
mance and cost-aware robustness if we use cost-driven con-
straints in robust training than L•-norm bound. The dashed
lines are the classiﬁcation boundary. The left ﬁgure shows
that robust training using L•-norm bound (solid square box)
achieves 75% accuracy. Given the cost-aware perturbation
(dashed red rectangular box), the model has only 50% ac-
curacy under attack. The right ﬁgure shows that using cost-
driven constraint, we can achieve 100% accuracy with and
without attack.
pose a cost modeling method that summarizes the domain
knowledge about features into cost-driven constraint, which
represents how bounded attackers can perturb every data point
based on the cost of manipulating different features. Then,
we integrate the constraint into the training process as if an
arbitrary attacker under the cost constraint is trying to maxi-
mally degrade the quality of potential splits (Equation (8) in
Section 3.2.2). We propose an efﬁcient robust training algo-
rithm that solves the maximization problem across different
gain metrics and different types of models, including random
forest model and gradient boosted decision trees. Lastly, we
evaluate the adaptive attack cost against our robust training
method, as a step towards understanding robustness against
attacks in the problem space [45]. We propose an adaptive
attack cost function to represent the total feature manipula-
tion cost (Section 3.3), as the minimization objective of the
strongest whitebox attacker against tree ensembles (the Mixed
Integer Linear Program attacker). The attack objective specif-
ically targets the cost-driven constraint, such that the attacker
minimizes the total cost of perturbing different features.
Our robust training method incorporates the cost-driven
constraint into the node construction process of growing trees,
as shown in Figure 2. When any potential split x j < h (on
the j-th feature) is being considered, due to the constraint,
there is a range of possible values a data point can be changed
into for that feature (formally deﬁned in Section 3.1.1). Thus,
data points close to the splitting threshold h can potentially
cross the threshold. For example, on a low cost feature, many
data points can be easily perturbed to either the left child
or the right child. Therefore, the constraint gives us a set
of uncertain data points that can degrade the quality of the
split, as well as high conﬁdence data points that cannot be
moved from the two children nodes. We need to quantify
the worst quality of the split under the constraint, in order to
compute the gain metric. To efﬁciently solve this, we propose
a robust training algorithm that iteratively assigns training
data points to whichever side of the split with the worse gain,
Spli(cid:87) da(cid:87)a o(cid:89)er fea(cid:87)(cid:88)re 
(cid:90)i(cid:87)h (cid:87)hreshold 
Cons(cid:87)rain(cid:87)s De(cid:192)ned
Cos(cid:87)-dri(cid:89)en
b(cid:92) E(cid:91)per(cid:87)s
& Training Se(cid:87)
Inp(cid:88)(cid:87)
Cos(cid:87)-a(cid:90)are Rob(cid:88)s(cid:87)
Training Algori(cid:87)hm
O(cid:88)(cid:87)p(cid:88)(cid:87)
Cos(cid:87)-a(cid:90)are
Rob(cid:88)s(cid:87) Models
High Con(cid:192)dence
(cid:172)Lef(cid:87)(cid:172)Se(cid:87)
High Con(cid:192)dence
Righ(cid:87) Se(cid:87)
Uncer(cid:87)ain Se(cid:87)
Figure 2: An overview of cost-aware robust tree ensemble
training process. Our robust training algorithm incorporates
the cost-driven constraint while constructing nodes. The con-
straint gives the set of data points that can potentially cross
the split threshold h given domain knowledge about the j-th
feature, i.e. uncertain set.
regardless of the choice of the gain function and the type
of tree ensemble model. As an example, we can categorize
every feature into negligible, low, medium, or high cost to be
increased and decreased by the attacker. Then, we use a high-
dimensional box as the constraint. Essentially, the constraint
gives the bounded attacker a larger increase (decrease) budget
for features that are easier to increase (decrease), and smaller
budget for more costly features. The cost-driven constraint
helps the model learn robustness that can maximize the cost
of evasion for the attacker. We have implemented our training
method in the state-of-the-art tree ensemble learning libraries:
gradient boosted decision trees in XGBoost [13] and random
forest in scikit-learn [4].
We ﬁrst evaluate the performance of our core training tech-
nique without the cost-driven constraint, against regular train-
ing method as well as the state-of-the-art robust tree ensemble
training method from Chen et al. [11]. In the gradient boosted
decision trees evaluation, we reproduce existing results to
compare models over 4 benchmark datasets with the goal of
improving robustness against attackers bounded by L•-norm
(Section 4.2). Using the same settings of number of trees and
maximal depth hyperparameters from existing work, our ro-
bust training algorithm achieves on average 2.78⇥ and 1.25⇥
improvement over regular training and state-of-the-art robust
training algorithm [11], respectively, in the minimal L• dis-
tance required to evade the model. In addition, we show that
our algorithm provides better solutions to the optimization
problem than the state-of-the-art [11] in 93% of the cases on
average (Section 4.2.4).
In the random forest models evaluation, we have imple-
mented Chen’s algorithm in scikit-learn since it was only
available in XGBoost. We ﬁrst train 120 models in total to
perform grid search over number of trees and maximal depth
hyperparameters. Then, we choose the hyperparameters with
the best validation accuracy for each training algorithm and
compare their robustness against the strongest whitebox at-
2292    30th USENIX Security Symposium
USENIX Association
tack. On average over the four benchmarking datasets, we
achieve 3.52⇥ and 1.7⇥ robustness improvement in the mini-
mal L• evasion distance compared to the baseline and Chen’s
algorithm, repsectively. This shows that our core training tech-
nique alone has made signiﬁcant improvements to solve the
robust optimization problem.
Next, we evaluate the cost-aware robust training method
for security, using Twitter spam URL detection as a case
study. We reimplement the feature extraction over the dataset
from [35] to detect malicious URLs posted by Twitter spam-
mers. The features capture that attackers reuse hosting infras-
tructure resources, use long redirection chains across different
geographical locations, and prefer ﬂexibility of deploying dif-
ferent URLs. Based on domain knowledge, we specify four
families of cost-driven constraints to train 19 different ro-
bust models, with key results summarized as follows. First,
compared to regular training, our best model increases the
cost-aware robustness by 10.6⇥. Second, our robust training
method using cost-driven constraints can achieve higher accu-
racy, lower false positive rate, and stronger cost-aware robust-
ness than L•-norm cost model from Chen’s algorithm [11].
Third, specifying larger perturbation range in the cost-driven
constraint generally decreases accuracy and increases false
positive rate; however, it does not necessarily increase the
obtained robustness. We need to perform hyperparameter tun-
ing to ﬁnd the best cost model that balances accuracy and
robustness. Lastly, by training cost-aware robustness, we can
also increase the model’s robustness against L1 and L2 based
MILP attacks [29].
Our contributions are summarized as the following:
• We propose a new cost modeling method to translate
domain knowledge about features into cost-driven con-
straint. Using the constraint, we can train models to
utilize domain knowledge outside the training data.
• We propose a new robust training algorithm to train cost-
aware robust tree ensembles for security, by integrating
the cost constraint. Our algorithm can be applied to both
gradient boosted decision trees in XGBoost and random
forest model in scikit-learn.
• We use Twitter spam detection as the security applica-
tion to train cost-aware robust tree ensemble models.
Compared to regular training, our best model increases
the attack cost to evade the model by 10.6⇥.
2 Background and Related Work
2.1 Tree Ensembles
A decision tree model guides the prediction path from the
root to a leaf node containing the predicted value, where each
internal node holds a predicate over some feature values. An
ensemble of trees consists of multiple decision trees, which
aggregates the predictions from individual trees. Popular ag-
gregation functions include the average (random forest) and
the sum (gradient boosted decision tree) of the prediction
values from each decision tree.
2.1.1 Notations
i ,x2
i , ...,xd
We use the following notations for the tree ensemble in this
paper. The training dataset D has N data points with d features
D ={(xi,yi)|i = 1,2, ...,N}(xi 2 Rd,y2 R). Each input xi can
be written as a d-dimensional vector, xi = [x1
i ]. A
predicate p is in the form1 of x j < h, which evaluates the
j-th feature x j against the split threshold h. Speciﬁcally, for
the i-th training data, the predicate checks whether x j
i < h. If
p = true, the decision tree guides the prediction path to the
left child, otherwise to the right child. This process repeats
until xi reaches a leaf. We use a function f to denote a decision
tree, which gives a real-valued output for the input data point
x with the true label y. For classiﬁcation trees, f (x) represents
the predicted probability for the true label y.
The most common decision tree learning algorithms use
a greedy strategy to construct the nodes from the root to the
leaves, e.g., notably CART [8], ID3 [46], and C4.5 [47]. The
algorithm greedily picks the best feature j⇤ and the best split
value h⇤ for each node, which partitions the data points that
reach the current node (I) to the left child (IL) and the right
child (IR), i.e., I = IL [ IR. The training algorithm optimizes
the following objective using a scoring function to maximize
the gain of the split:
j,h
j,h
j⇤,h⇤ = arg max
Gain(IL,LR) = arg max
(s(I)  s(IL,IR))
(1)
In Equation (1), s denotes a scoring function. For example,
we can use Shannon entropy, Gini impurity, or any general
loss function. Splitting a node changes the score from s(I)
to s(IL,IR). For example, using the Gini impurity, we have
Gain(IL,LR) = Gini(I)  Gini(IL,IR). A common strategy to
solve Equation (1) is to enumerate all the features with all the
possible split points to ﬁnd the maximum gain. Starting from
the root node, the learning algorithm chooses the best feature
split with the maximum gain, and then recursively constructs
the children nodes in the same way, until the score does not
improve or some pre-determined threshold (e.g., maximum
depth) is reached.
A tree ensemble uses the weighted sum of prediction values
from K decision trees, where K is a parameter speciﬁed by
the user. Each decision tree can be represented as a function
ft. Then, the ensemble predicts the output ˆy as follows.
ˆy = f(x) = a⇤
K
Â
t=1
ft(x)
(2)
Ensemble methods use bagging [7] or boosting [21, 22,
50] to grow the decision trees. Random forest and gradient
1Oblique trees which use multiple feature values in a predicate is rarely
used in an ensemble due to high construction costs [43].
USENIX Association
30th USENIX Security Symposium    2293
boosted decision tree (GBDT) are the most widely used tree
ensembles. The random forest model uses a = 1
K , and the
GBDT model set a = 1. They use different methods to grow
trees in parallel or sequentially, which we describe next.
2.1.2 Random Forest
A random forest model uses bagging [7] to grow the trees
in parallel. Bagging, i.e., bootstrap aggregation, uses a random
subset of the training data and a random subset of features
to train individual learners. For each decision tree ft, we
ﬁrst randomly sample N0 data points from D to obtain the
training dataset Dt = {(xi,yi)}, where |Dt| = N0 and N0 
N. Then, at every step of the training algorithm that solves
Equation (1), we randomly select d0 features in I to ﬁnd the
optimal split, where d0  d. The feature sampling is repeated
until we ﬁnish growing the decision tree. The training data
and feature sampling helps avoid overﬁtting of the model.
Random forest model has been used for various security ap-
plications, e.g., detecting malware distribution [34], malicious
autonomous system [32], social engineering [42], phishing
emails [16, 20, 26], advertising resources for ad blocker [28],
and online scams [31,49], etc. In some cases, researchers have
analyzed the performance of the model (e.g., ROC curve)
given different subsets of the features to reason about the
predictive power of feature categories.
2.1.3 Gradient Boosted Decision Tree
Gradient boosted decision tree (GBDT) model uses boost-
ing [21, 22, 50] to grow the trees sequentially. Boosting itera-
tively train the learners, improving the new learner’s perfor-
mance by focusing on data that were misclassiﬁed by existing
learners. Gradient boosting generalizes the boosting method
to use an arbitrarily differentiable loss function.