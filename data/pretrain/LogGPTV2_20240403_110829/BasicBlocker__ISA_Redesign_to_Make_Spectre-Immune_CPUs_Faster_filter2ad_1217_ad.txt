tions in the block. This is done directly before code emission to
ensure that the number of instructions does not change due to
optimizations. Linker relaxation, however, is one optimization that
could reduce the number of instructions by substituting calls with a
short jumping distance by a single jump instruction instead of two
instructions (aupic and jalr). Since linker relaxation is not a major
optimization, we simply disabled it, but it would also be possible to
modify the linker to implement BasicBlocker-aware relaxation.
Our modifications to the semantics of terminating instructions
(branches, calls, returns and jumps) allow them to be scheduled
BasicBlocker: ISA Redesign to Make Spectre-Immune CPUs Faster
ArXiv Version, 2021, May
Figure 5: Bitmap of the new RISC-V instructions.
before the end of a basic block and rescheduling them earlier is also
crucial to the performance of the code. This is done in a top-down
list scheduler that is placed after register allocation and prioritizes
terminating instructions. Additionally, we run another pass after-
wards that relocates the terminating instructions to earlier positions
in the basic blocks if this is supported by register dependencies.
6 EVALUATION
In the following we provide a performance evaluation of BasicBlocker
on VexRiscv and Gem5 by comparing the execution time of differ-
ent variants of the two CPUs. Thereby, special care is given to the
impact of CPU features and code characteristics.
6.1 Selection of Benchmarks
Both implementations of BasicBlocker presented in this paper en-
force the presence of exactly one bb instructions in every basic
block (i.e. misplaced or missing bb instructions cause a program to
crash). This ensures that the benchmarks only measure the perfor-
mance of BasicBlocker without noise from legacy code snippets,
e.g. library functions, but also requires all code to be compiled by
our modified compiler. Since this forces us to perform the bench-
marks bare-metal (i.e. without OS support), it is quite difficult to
run typical user level benchmarks such as SPEC.
We chose the benchmarks included in the Embench benchmark
suite [24], the well-known Coremark benchmark [25] and our own
pointer-chasing benchmark for our evaluation. The selection of pro-
grams within the Embench suite resemble code from different use
cases such as cryptography (nettle-sha, nettle-aes), image process-
ing (picojpeg) and matrix multiplication (matmult-int). For three of
the programs we also included our own optimized version (-opt),
targeted at general architectures and discussed in more detail in
Appendix B. All those programs are characterized by minimal de-
pendencies and are thus well suited for bare-metal benchmarking.
Since all of the benchmarks require the libc library (and some
also libm), we compiled Newlib [29] using our modified LLVM com-
piler. However, some of the benchmark programs require further
dependencies, e.g. libgcc, and could thus not be compiled for our
target. For the evaluation we included all available benchmark pro-
grams that compiled with the modified libc and libm and passed
the test for functional correctness.
We compiled three versions of each benchmark program, as
listed in Table 1: one without BasicBlocker, one with a new compile
flag enabling the insertion of bb instructions, and one with bb plus
rescheduling of terminator instructions. Except for these differences,
the compiler and compile flags are identical. The compile flags are
listed in Appendix C.
We ran those programs on several variants of VexRiscv and Gem5,
as listed in Table 2. The simplest non-speculative variant (NoSpec)
Name
Baseline
BB Info
BB Resched
Description
Standard RISC-V version.
As in Baseline, but every basic block starts with
a bb instruction.
As in BB Info, but with high-priority reschedul-
ing of terminator instructions.
Table 1: Compiled versions used for benchmarking.
disables branch prediction and speculative fetching. The control-
flow speculation configuration (CFS) implements the unmodified
version of the CPU with the default branch predictor.
Name
NoSpec
Control-Flow Speculation (CFS)
BasicBlocker (this work)
BB
no
no
yes
SF
no
yes
no
BP
no
yes
no
Table 2: Processor instantiation options. BB: supports bb in-
struction. SF: speculative fetching. BP: branch predictor
As we execute our benchmarks bare-metal, we observe only
minimal noise through the microarchitectural state of the VexRiscv.
The Gem5 platform has no noise at all, as it is a deterministic
simulation with a reset prior to each run. The raw benchmark
results are included in Appendix E.
6.2 VexRiscv Evaluation
We first evaluate the performance of BasicBlocker on VexRiscv,
which resembles a small-scale, in-order, embedded-like processor,
by comparing the execution time of the CPU variants in Table
2 together with the program versions of Table 1. We chose the
strictly non-control-flow-speculative processor as a naive but secure
baseline and report the relative execution time of the other variants
in Figure 6. The average speedup over all benchmarks is 2.88×
and 2.12× for the version using control-flow speculation (CFS)
and the BasicBlocker version with instruction rescheduling (BB
Resched), respectively. The maximal and minimal speedups are
3.93× (crc32) and 1.44× (pointer-chase) for control flow speculation
and 3.09× (crc32-opt) and 1.07× (pointer-chase) for BasicBlocker
with rescheduling.
For several benchmarks the speedup of control-flow speculation
is comparable to BasicBlocker with instruction rescheduling. This
is true for ud, matmult-int, nettle-sha, nettle-aes, and crc32-opt. For
nettle-aes and crc32-opt BasicBlocker with instruction rescheduling
even outperforms control-flow speculation (speedup of 2.88× vs.
2.78× and 3.09× vs. 2.79× respectively). This is possible as with
9
LCNTcounterimm.[11:0]rs000rd1011011BBsize[15:0]s-ﬂags[3:0]e-ﬂags[3:0]sq01010113120161512870ArXiv Version, 2021, May
J. Thoma, J. Feldtkeller, M. Krausz, T. Güneysu, D. J. Bernstein
Figure 6: Performance results for various benchmarks on VexRiscv measured in clock cycles. The results are relative to the
NoSpec configuration of VexRiscv (red line). Sorted descended by speedup delta in BB Resched vs CFS case. Lower delta is better.
For abbreviations see Tables 1 and 2.
enough rescheduling opportunities no pipeline stalls are necessary
at all. For other benchmarks, control-flow speculation outperforms
BasicBlocker with a larger margin (e.g. minver, Coremark, nbody,
and huffbench).
In general, BasicBlocker performs best for benchmarks that have
large basic blocks and less branches (e.g. nettle-aes, and nettle-sha)
whereas the large difference of speedup between control-flow spec-
ulation and BasicBlocker occurs for branch heavy code with small
basic blocks (e.g. minver). A more thorough analysis of code char-
acteristics is given in Section 6.4. We emphasize that many opti-
mization techniques for execution time tend also to prefer large
basic blocks with less branches over small basic blocks with a lot
of branches, e.g. loop unrolling, or function inlining.
6.3 Gem5 Evaluation
We conduct the same performance analysis with the Gem5 simula-
tor, which resembles a more sophisticated, out-of-order, and multi-
scalar processor. Again, the strictly non-control-flow-speculative
processor variant serves as a naive but secure baseline. The Gem5
CPU model processes up to two instructions in every clock cycle.
The strictly non-speculative version cannot utilize this capacity as
fetching multiple instructions at once implies speculative fetching.
The relative execution time of the benchmarks for the evaluated
processor variants are reported in Figure 7. The average speedup
over all running benchmarks is 3.69× and 2.13× for the version us-
ing control-flow speculation and BasicBlocker with rescheduling of
instruction respectively. The maximum and minimum speedups are
4.80× (minver) and 1.07× (pointer-chase) for control-flow specula-
tion and 3.09× (crc32-opt) and 1.07× (pointer-chase) for BasicBlocker
with rescheduling. Hence, the speedup achieved by BasicBlocker on
Gem5 is overall comparable to the speedup achieved on VexRiscv
and for well performing cases slightly higher. However, the speedup
achieved by the means of control-flow speculation is higher than
in the VexRiscv example.
Taking a closer look at specific benchmarks reveals again some
cases where BasicBlocker matches the performance of control-flow
speculation, e.g. pointer-chase crc32-opt, nettle-sha, or matmult-int
while for others control-flow speculation is considerably faster, e.g.
minver, nbody, or picojpeg. As analyzed in the following, the code
characteristics have a high influence on the performance. The low
speedup for pointer-chase at all Gem5 architectures is expected, as
memory-access time clearly dominates any pipeline characteristic
for this benchmark.
The results show the applicability of BasicBlocker on super-
scalar, out-of-order processors. We further analyze the influence of
processor characteristics in Section 6.5.
6.4 Influence of Code Characteristics
To analyze how the structure of the code influences the perfor-
mance of BasicBlocker, we evaluate the code characteristics of each
benchmark regarding the average size of basic blocks and aver-
age rescheduling of control-flow instructions. Since the impact of
basic blocks that are executed frequently during the benchmarks
is higher than those that are executed only once, we perform a
dynamic hotspot analysis and weight the results based on the fre-
quency of invocation. In Figure 8 the resulting distribution of basic
block sizes is pictured. The Figure shows, that there are strong differ-
ences in the basic block sizes for the benchmarks. For matmult-int,
nettle-aes and nettle-sha, the highest arithmetic average size of the
basic blocks executed during the benchmark is reached with more
than 25 instructions, whereas minver and coremark have a rela-
tively small average basic block size, below five instructions. The
optimized versions of aha-mont, crc32 and st increase the mean
basic block size by enabling more inlining and thus contribute to
a smaller delta in the benchmarks between the BasicBlocker and
speculative version of the cpu. For crc32-opt the distribution of basic
block sizes changed dramatically and lead to a speedup of 2.13×
and more for all cpu versions compared to the original benchmark.
10
aha-montaha-mont-optcrc32crc32-optcubicednhuffbenchmatmult-intminvernbodynettle-aesnettle-shapicojpegpointer-chaseqrduinostst-optstatemateudCoremark00.51NoSpecbaselineClockCyclesrelativetoNoSpecVexRiscvBBInfoBBReschedCFSBasicBlocker: ISA Redesign to Make Spectre-Immune CPUs Faster
ArXiv Version, 2021, May
Figure 7: Performance results for various benchmarks on Gem5 measured in simulation ticks. The results are relative to the
NoSpec configuration of Gem5 (red line). Sorted descended by speedup delta in BB Resched vs CFS case. Lower delta is better.
For abbreviations see Tables 1 and 2. Huffbench and Coremark did not compile for the 64-bit target.
Figure 8: Distribution of basic block sizes (measured in in-
structions), weighted by the number of invocations, dynam-
ically derived from the hotspot analysis.
Figure 9: Distribution of instruction rescheduling per basic
block, weighted by the number of invocations, dynamically
derived from the hotspot analysis.
Figure 9 shows the average number of instructions that follow
the control flow instruction (this is only relevant for the BB Resched
case, not for the BB Info). The intuitive assumption is that large basic
blocks allow for higher rescheduling of control flow instructions.
This assumption is confirmed by the results shown in the figure.
While the average rescheduling number for the aforementioned
benchmarks with large basic blocks is high (above 15 instructions on
average), benchmarks with smaller basic blocks such as Coremark
and minver offer less average rescheduling opportunities.
The performance results in Figure 6 and 7 show, that programs
with large basic blocks in their core functions (and therefore good
rescheduling opportunities) perform better with BasicBlocker than
those benchmarks with small basic blocks. For real world workloads,
the core functions that are regularly executed are often well opti-
mized and - in many cases - try to avoid branches to gain improved
performance [15, 20, 21].
6.5 Influence of Pipeline Characteristics
Pipeline Length. We analyze the influence of additional pipeline
stages on the execution time of our benchmarks to give an estima-
tion of run time on other CPU architectures. As for space restric-
tions we analyze the influence of the pipeline length for a smaller
sample of the above shown benchmarks. With matmult-int and
minver, we chose one well performing benchmark and one with
higher performance penalty. We modified the VexRiscv soft core
and placed additional dummy pipeline stages between fetch and
11
aha-montaha-mont-optcrc32crc32-optcubicednmatmult-intminvernbodynettle-aesnettle-shapicojpegpointer-chaseqrduinostst-optstatemateud00.51NoSpecbaselineTicksrelativetoNoSpecGem5OOOCPUBBInfoBBReschedCFS0510152025coremarkudstatematest-optstqrduinopicojpegnettle-shanettle-aesnbodyminvermatmult-inthuffbenchedncubiccrc32-optcrc32aha-mont-optaha-mont©©©Instructionsmedianarithmeticmean05101520coremarkudstatematest-optstqrduinopicojpegnettle-shanettle-aesnbodyminvermatmult-inthuffbenchedncubiccrc32-optcrc32aha-mont-optaha-mont©©InstructionsmedianarithmeticmeanArXiv Version, 2021, May
J. Thoma, J. Feldtkeller, M. Krausz, T. Güneysu, D. J. Bernstein
decode such that the original architecture has a pipeline delay of
zero and each additional stage increments the pipeline delay by one.
The results are shown if Figure 10 and Figure 11 for matmult-int
and minver respectively.
We conducted a similar analysis for the Gem5 out-of-order pro-
cessor and the results show the same behavior as the discussed
examples, as can be seen in Appendix D.
Superscalarity. By using superscalarity modern processors can
process several instructions in parallel within a single clock cycle.
We, therefore, modify our Gem5 implementation to evaluate the
performance impact of superscalar processors using BasicBlocker.
As described above, our default configuration for the Gem5 uses
a 2× superscalar pipeline. Figure 12 and 13 show the performance
results for an up to 7× superscalar pipeline for matmult-int and
minver respectively. Graphs for other benchmarks can be found in
Appendix D.
Figure 10: Influence of additional pipeline stages on the ex-
ecution time for the benchmark matmult-int on VexRiscv.
Figure 12: Influence of superscalarity on the performance of
BasicBlocker using the matmult-int benchmark on Gem5.
Figure 11: Influence of additional pipeline stages on the ex-
ecution time for the benchmark minver on VexRiscv.
The data clearly show that additional pipeline stages have nearly
no effect when control-flow speculation is used (CFS), which is
expected as the longer pipeline only introduces a penalty if a mis-
sprediction occurs. Also the linearly increasing penalty for the
naive BasicBlocker implementation is to be expected, since a con-
stant amount of additional clock cycles is added to all transitions
between basic blocks. More interesting is the case where the com-
piler is allowed to reschedule control-flow instructions. Here we
can see clear differences between the benchmarks. While the im-
pact of additional stages is only small and non-linear in the case of
matmult-int running on VexRiscv, we can observe a mirroring of
the naive BasicBlocker behavior for minver running on VexRiscv.
We can explain this as an artifact of the code structure, as discussed
earlier. Minver is composed of mostly small basic blocks resulting
in only a few rescheduling options. Hence, the impact of the longer
pipeline is preserved nearly entirely. In contrast, matmult-int has
better options for rescheduling and, hence, the penalty can be better
absorbed through the early determination of the next basic block.
We also analyzed one additional configuration, where we im-
plemented a decoding of the bb instruction directly after the in-
struction cache and, hence, before the pipeline delay is introduced.
Figures 10 and 11 show that this can reduce the performance impact
of longer pipelines, as the penalty only occurs for the computation
of the next basic block and not for the determination of the basic
block length and sequential flag.
Figure 13: Influence of superscalarity on the performance of
BasicBlocker using the minver benchmark on Gem5.
The red line in Figures 12 and 13 show the strictly non-speculative
version of the CPU. Since it is not allowed to do speculative fetching,
only one instruction can be fetched at a time. Thus, the superscalar-
ity has no effect in this scenario. The results for the well-performing
matmult-int benchmark strikingly demonstrate the potential of Ba-
sicBlocker using superscalar pipelines. The bb info version as well
as the rescheduled version incur minimal performance overhead
over the original configuration using speculation. That is, large
basic blocks allow optimal utilization of the superscalar pipeline.
For the minver benchmark, which has much smaller basic blocks,
it shows that the additional pipeline slots can barely be filled for a
superscalarity larger than two. The lines for bb info and resched-
uled converge for a large pipeline width. That is, small basic blocks
will eventually be fetched within a single clock cycle, making any
rescheduling irrelevant to the performance.
12
01234567891044.24.44.6·106PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode01234567891000.511.52·106PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode1234567012·109PipelineWidthTicksCFSBBInfoBBReschedNoSpec123456702468·108PipelineWidthTicksCFSBBInfoBBReschedNoSpecBasicBlocker: ISA Redesign to Make Spectre-Immune CPUs Faster
ArXiv Version, 2021, May
7 CONCLUSION
In this work, we demonstrated a universal countermeasure against
control-flow speculation attacks such as Spectre. We have chosen a