were
the
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:25:20 UTC from IEEE Xplore.  Restrictions apply. 
449
evaluate the protocol on a large number of inputs, we ran our
local randomizer on one random recognized word per tweet.7
This means n ≈ 3.7· 106. Because tweets are public by nature,
we did not modify their contents (e.g. remove identifying
names).
We used privacy parameters ε = 1 and δ = 10−7, the former
due to the reasonable level of privacy it offers and the latter
in order to facilitate comparison with Balcer & Cheu (whose
analysis required δ = o(1/n)).
We simulated each of the protocols on the dataset a hundred
times. Because PFLIP has a parameter k that governs the error-
message tradeoff, we ran these experiments for four different
values of k. The same type of repetition was also done for the
GKMP protocol since it also has a tradeoff parameter γ.
A. Evaluation of Maximum Error and Message Complexity
Recall that in our bound on the error (Theorem III.4), increas-
ing the number of fake users k drives down a multiplicative
factor f (k). This theory is backed by our experimental results:
Figure 3 depicts the error introduced by PFLIP for varying
choices of k, which is within a small multiplicative factor of
the bound in Corollary III.5 (a precursor to Theorem III.4).
Figure 3: Maximum error of frequency estimates in experiments,
as a (decreasing) function of k. Conﬁdence bounds (red ﬁlled
circles) are derived from Corollary III.5.
In Figure 4, we compare four points on the error-message
tradeoff curve of PFLIP against that of the GKMP protocol.
Although the latter introduces less error, its expected message
complexity lies between 7 · 105 and 1.1 · 106. This is multiple
orders of magnitude worse than PFLIP which only demands a
handful of messages.
B. Evaluation of Top-t selection
Recall the simple top-t selection strategy from Section III-D:
report the top-t items of a private version of the histogram.
And in Corollary III.18, we gave a bound on the error as a
function of the parameters k, q, d, n.
In Table III, we ﬁx t = 6000 and present that bound
alongside the maximum observed value in our experiments.
We remark that the frequency of the rank-t word is 1.33· 10−5.
This is an upper bound on α that holds with probability 1,
7This grants differential privacy to each tweet rather than each user, who
can send more than one tweet. We leave user-level privacy for future work.
Figure 4: Here, we plot the max error of PFLIP as a function
of the message complexity. To the side, we also plot the
corresponding values from the GKMP protocol.
since the worst that can happen is that a word with frequency
0 displaces the t-th most common word.
Bound from Corollary III.18 Maximum observed
PFLIP’s α-approximation of top-6000
1.43 · 10−4
1.24 · 10−4
1.17 · 10−4
1.13 · 10−4
1.33 · 10−5
k
1
2
3
4
Table III: Comparing the bound on the error of top-t selection
with experimental results.
In Figure 5, we plot the F1 score of the report-top-t strategy
for the three shufﬂe protocols. PFLIP preserves ≈ 95% of the
top-2000 words in the dataset and only drops to ≈ 70% at
t = 6000. This is signiﬁcantly more accurate than the protocol
by Balcer & Cheu, whose scores are all under 0.1. To see why
this is the case, recall that the maximum error of the Balcer &
δ ) while PFLIP ensures a bound of
Cheu protocol is O( 1
O( log d
δ ). d is orders of magnitude smaller
than 1/δ in our application, which is why PFLIP has less error.
For the four choices of hyperparameter γ we tested, GKMP
protocol has extremely high accuracy for the three values of t.
But we have already shown that this performance demands an
extremely large message complexity.
ε2n log 1
log d log 1
n + 1
εn
(cid:113)
V. REDUCING COMMUNICATION COMPLEXITY
Although PFLIP has a constant message complexity for a
large range of n, each message is a binary string of length
d. The communication complexity is therefore linear in the
dimension. In this section, we show how to change this rate.
A. Replacing Binary Strings with Lists
In this subsection, we use the observation that the messages
are binary strings that are likely sparse so that they can be
equated with a short list of indices. More precisely, let RFLIP2
be the local randomizer that, on input x, computes messages
from RFLIP(x) but replaces each binary string it creates with a
list of the indices that contain bit 1. Let AFLIP2 be the analyzer
that converts each of the messages output by the shufﬂer back
into a binary string and then runs AFLIP.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:25:20 UTC from IEEE Xplore.  Restrictions apply. 
450
is an instance of a general method of transforming any shufﬂe
protocol for histograms.
The pseudocode for the randomizer and analyzer is given
in Algorithms 8 and 9, respectively. The heart of the trans-
formation is hashing the universe [d] to [ ˆd]. If an element
j experiences no collisions, note that its frequency in the
hashed dataset is the same as in the original dataset. Otherwise,
the frequency is an overestimate. When there are many hash
functions, it is likely that there is some hash function where
j experiences no collisions; taking the minimum over the
frequencies in the hashed datasets would recover the original
frequency. We execute PFLIP2 once for each hashed datset to
obtain estimates of the frequencies.
Algorithm 8: RFLIP3 a local randomizer for histograms
Input: x ∈ Xd; parameters V, ˆd, k ∈ N, q ∈ (0, 1/2)
Output: (cid:126)y ∈ ([V ] × [ ˆd]∗)∗
Sample {h(v) : Xd → X ˆd} from public randomness.
Initialize (cid:126)y to the empty vector
For v ∈ [V ]
Compute messages (cid:126)y(v) ← RFLIP2(h(v)(x)) using
dimension ˆd
For y ∈ (cid:126)y(v)
Append labeled message (v, y) to (cid:126)y
Return (cid:126)y
V, ˆd, k ∈ N, q ∈ (0, 1/2)
Algorithm 9: AFLIP3 an analyzer for histograms
Input: (cid:126)y ∈ ([V ] × [ ˆd]∗)∗; parameters
Output: (cid:126)z ∈ Rd
Sample {h(v) : Xd → X ˆd} from public randomness.
Assign zj ← ∞ for all j ∈ [d]
For v ∈ [V ]
Initialize (cid:126)y(v) ← ∅
For (v(cid:48), y) ∈ (cid:126)y
Append message y to (cid:126)y(v) if label v(cid:48) matches v
Compute ˆz(v) ← AFLIP2((cid:126)y(v)) using dimension ˆd
For j ∈ [d]
ˆj ← h(v)(j)
zj ← min(zj, ˆz(v)
)
ˆj
Figure 5: F1 scores for top-t word selection, for both tested
protocols. The lines connect medians while the error bars
represent the complete range of observed values.
ε2n log 1
Theorem V.1. If parameters k, q are chosen in the same
manner as in Theorem III.4, then PFLIP2 = (RFLIP3,AFLIP2)
has the same number of messages and accuracy as PFLIP but
now the expected length of each message is ≤ log2 d·(1+dq) =
O(log d(1 + d
Proof. A message is generated from either Rd,q(0d) or
Rd,q(x ∈ Xd). By construction, Rd,q(0d) produces a string
where each bit is drawn from Ber(q). This means the number
of 1s is drawn from Bin(d, q). Meanwhile, the number of
1s generated from executing Rd,q(x ∈ Xd) is a sample from
Ber(1 − q) + Bin(d − 1, q).
nk log d)) bits.
δ + d
Recall we set q to be q = O( 1
nk log d).
This means the expected number of 1s in any message is
nk log d). And we need log2 d bits to represent
O( d
ε2n log 1
each index.
ε2n log 1
δ + 1
δ + d
Because the length of an index list is a random variable, it
could present a challenge to implementation. A straightforward
solution is to compute a high-probability bound on the
maximum length of the lists. If a list exceeds that length, it
can be broken up into shorter lists. Privacy is unaffected since
this sharding can be done as post-processing of the shufﬂer’s
output.8
B. An Adaptation of Count-Min
Return (cid:126)z
The change-of-representation in the preceding section is
powerful when n approaches (or exceeds) d. This subsection
describes a method to reduce the communication complexity
when n is not so large, at the price of logarithmic message
complexity. The new protocol, which we call PFLIP3, uses the
randomizer and analyzer of PFLIP2 as black boxes. Based upon
the Count-Min technique from the sketching literature, PFLIP3
8If users can attach anonymous identiﬁers to their messages, resilience to
manipulability is also preserved: an analyst can remove an index from a user’s
list if it appears multiple times.
We ﬁrst analyze the protocol in terms of the parameter V ,
which determines the number of hash functions and protocol
repetitions. We will choose a value for V later in the section.
Claim V.2. Fix any ε = O(1), δ 
, then there is a choice
max
of parameter q < 1/2 such that PFLIP3 has the following
properties:
(cid:17)
n ln 20 ˆdV − 1
(cid:16) 134
eε−1 )2 ln 4
5n ( eε+1
δ , 2
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:25:20 UTC from IEEE Xplore.  Restrictions apply. 
451
(cid:16)
δ + ˆd
ε2n log 1
a. Each user sends V · (k + 1) messages, each consisting
nk log ˆd)) bits in
of O(log V + log ˆd(1 + ˆd
expectation.
b. PFLIP3 is
c. For any (cid:126)x ∈ X n
ε(eε − 1) · V + ε ·(cid:113)
(cid:114)
private for inputs from Xd
(cid:126)z such that the maximum error is
-shufﬂe
d , PFLIP3((cid:126)x) reports approximate histogram
(cid:33)
2V log 1
V δ , 2V δ
(cid:32)
(cid:17)
(cid:107)(cid:126)z − hist((cid:126)x)(cid:107)∞ = O
1
δ
with probability ≥ 9/10 − (1/100)V .
1
εn
log
log ˆdV +
log ˆdV
n
Proof. We will choose q in much the same way as Theorems
III.4 and V.1. The sole modiﬁcation is that we change the
ln 20d term to ln 20 ˆdV .
The protocol executes PFLIP2 exactly V times using the
hashed dimension ˆd. So the number of messages is simply
V · (k + 1). Each message is generated via RFLIP2 and then
labeled by the execution number v, so Part a is immediate
from Theorem V.1. Meanwhile, Part b follows directly from
advanced composition (Fact II.4).
To prove Part c, we ﬁrst analyze the randomness from
hashing and consider privacy noise later. For any j ∈ [d],
let Ej denote the event that there is at least one hash function
where j experiences no collisions with a user value j(cid:48) (cid:54)= j.
Formally, ∃v∗ ∀j(cid:48) ∈ (cid:126)x, j(cid:48) (cid:54)= j h(v∗)(j) (cid:54)= h(v∗)(j(cid:48)). We will
now bound the probability that Ej does not occur.
[¬Ej] = P
P
(cid:126)h
(cid:104)∀v ∃j(cid:48) ∈ (cid:126)x h(v)(j) = h(v)(j(cid:48))
(cid:105)
(cid:104)∃j(cid:48) ∈ (cid:126)x h(v)(j) = h(t)(j(cid:48))
(cid:105)V
(cid:18)
(cid:105)(cid:19)V
(cid:104)
(cid:126)h
= P
(cid:126)h
n · P
(cid:126)h
≤
h(v)(j) = h(v)(j(cid:48))
= (n/ ˆd)V = (1/100)V · 1
d
By a union bound, the probability that there is some j where
Ej does not occur is at most (1/100)V
The remainder of the proof conditions on Ej occurring for
all j. In this event, each j can be paired with some v∗ where
the count of h(v∗)(j) in the hashed dataset is exactly the count
of j in the original dataset. For any v (cid:54)= v∗, observe that the
count of h(v)(j) in the hashed dataset is must be either (1)
an overestimate due to collision or (2) also equal. Thus, the
minimum over the counts yields the correct value.
Now we incorporate the fact that AFLIP3 only has private
estimates of the counts. When β = 1/10 ˆdV , Claim III.2 and
a union bound imply each protocol execution has (cid:96)∞ error
(cid:18) 1
(cid:19)
k + 1
n
q(1 − q) ln 20 ˆdV ·
1 − 2q
(cid:114)
2
except with probability ≤ 1/10V A second union bound over
the V executions ensures that the privatized count of h(v∗)(j)
in the hashed dataset is the minimum of all privatized counts.
Substitution of q completes the proof.
any
ε
=
log 1
If n
O(1).
We argue that there is a value of V such that the expected
communication complexity has only a polylogarithmic depen-
dence on d and n.
Theorem V.3. Fix
=
Ω( log d
δ log log d
δ ), δ = O(1/n), and V = log2 d,
then there are choices of parameters V, k ∈ N and q < 1/2
ε2
such that PFLIP3 has the following properties:
a. Each user sends 2 log2 d messages, each consisting of
b. PFLIP3 is (ε, δ)-shufﬂe private for inputs from Xd
c. For any (cid:126)x ∈ X n
d , PFLIP3((cid:126)x) reports approximate histogram
(cid:19)(cid:19)
(cid:126)z such that the maximum error is
ε2 log d log3 log d
bits in expectation.
(cid:16) 1
(cid:18) log d
(cid:112)log d log3/2
(cid:107)(cid:126)z − hist((cid:126)x)(cid:107)∞ = O
(cid:18) 1
(cid:17)
O
δ
εn
δ
with probability ≥ 9/10 − (1/100)log2 d.
The above result follows from straightforward substitutions.
We conclude this section by bounding the impact of corrupt
users on estimates generated by PFLIP3.
Claim V.4. Fix any ε = O(1), δ < 1/100, and n, q, V as
in Theorem V.3. For any input (cid:126)x ∈ X n
d , any coalition of m
corrupt users can introduce O( m
Proof Sketch. Each honest user transmits O(V ) messages,
where each message is an output of RFLIP◦h(v) labeled by v. A
corrupt user is therefore limited a “budget” of O(V ) messages
each with the same structure. But all of these messages could
share the same label v. In this case, we can adapt the analysis
of PFLIP to show that m corrupt users will add O( m
n · V ) bias
to the v-th execution of PFLIP.
n · log d) error to PFLIP3.
VI. CONCLUSION
We have presented a shufﬂe protocol for computing d-bin
histograms where the message complexity is as low as two
when the number of users is logarithmic in d. The low message
complexity limits the impact of corrupt users on the protocol’s
estimates. Meanwhile, our empirical work shows that the new
protocol can obtain accurate estimates for word frequency
data and conﬁrms an error-message tradeoff. We also provide
techniques to send shorter messages.
Future work could explore the error-message tradeoffs of
other protocols. Speciﬁcally, our work does not rule out the
possibility that the very low error of the GKMP protocol is
possible with very few messages like PFLIP. The compression
done in Section V inspires a related line of thought: there may
be an alternative to the generic hashing-based construction
which results in a histogram protocol with shorter messages.
ACKNOWLEDGMENT
We thank Kobbi Nissim, Rasmus Pagh, and Jonathan Ullman
for discussion and insight for the count-min analysis. We also
thank the anonymous reviewers for their detailed editorial
comments. This work began while A.C. was a PhD. candidate
at Northeastern University, where he was funded by NSF grants
CCF-1750640, CNS-1816028, CNS-1916020.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:25:20 UTC from IEEE Xplore.  Restrictions apply. 
452
REFERENCES
[1] Andris Ambainis, Markus Jakobsson, and Helger Lipmaa.
Cryptographic randomized response techniques. In Public
Key Cryptography - PKC 2004, 7th International Work-
shop on Theory and Practice in Public Key Cryptography,
Singapore, March 1-4, 2004, pages 425–438, 2004.
[2] Victor Balcer and Albert Cheu. Separating local and
shufﬂed differential privacy via histograms. In Information
Theoretic Cryptography (ITC), 2020.
[3] Borja Balle, James Bell, Adrià Gascón, and Kobbi Nissim.
The privacy blanket of the shufﬂe model. In International
Cryptology Conference (CRYPTO), 2019.
[4] Raef Bassily and Adam Smith. Local, private, efﬁcient
protocols for succinct histograms. In Symposium on the
Theory of Computing (STOC), 2015.
[5] Andrea Bittau, Úlfar Erlingsson, Petros Maniatis, Ilya
Mironov, Ananth Raghunathan, David Lie, Mitch
Rudominer, Ushasree Kode, Julien Tinnes, and Bernhard
Seefeld. Prochlo: Strong privacy for analytics in the
crowd. In Symposium on Operating Systems Principles
(SOSP), 2017.
[6] Mark Bun, Kobbi Nissim, and Uri Stemmer. Simultaneous
private learning of multiple concepts. In Innovations in
Theoretical Computer Science (ITCS), 2016.
[7] Xiaoyu Cao, Jinyuan Jia, and Neil Zhenqiang Gong. Data