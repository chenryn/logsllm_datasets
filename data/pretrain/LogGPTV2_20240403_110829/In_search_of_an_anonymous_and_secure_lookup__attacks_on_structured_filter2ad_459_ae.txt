m
o
r
p
m
o
C
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
f=0.2, l=15 (n=10000)
f=0.15, l=15 (n=10000)
f=0.1, l=15 (n=10000)
f=0.2, l=14 (n=5000)
f=0.15, l=14 (n=5000)
f=0.1, l=14 (n=5000)
500
1000
1500
2000
Phi (seconds)
2500
3000
3500
Figure 12: Eﬀect on varying the client’s maximum
waiting time Φ. ν = 500, and π = 25.
upon seeing an invalid certiﬁcate is not a necessity. Instead,
the random walk can step back one hop and choose another
random ﬁnger as the next hop. If all ﬁngers of a particular
hop are malicious, the random walk can step back one more
hop and try other branches. By doing so, it would be infea-
sible for the attacker to interrupt a random walk, and thus
honest nodes can ﬁnd buddies as expected.
However, it is important to note that the querier under
buddy exhaustion attack may still need substantial time to
ﬁnd enough buddies to get through the ﬂooding lookup re-
quests, even though random walks are not interrupted. For
example, when ν = 1200, l = 15 and π = 25, it will take the
victim node 2lϕν
π ≈ 5min to ﬁnd enough buddies to perform
a lookup. It is very likely that the client will not wait 5min
before starting communication.
We can speed up the process of buddy selection via some
cryptographic mechanisms. For example, if the certiﬁcates
associated with each hop are formed into Merkle trees, the
computational latency at each hop could be reduced6. How-
ever, the eﬀectiveness of this strategy still depends on the
attacker’s capability of sending ﬂood requests. Finally, we
note that each bogus lookup request may generate consid-
6Forming certiﬁcates into Merkle trees increases mainte-
nance costs, since whenever a node joins/churns or a sig-
nature expires, all related Merkle trees have to be recon-
structed.
3161
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
)
)
|
R
R
B
(
r
P
(
y
t
i
l
i
b
a
i
l
i
e
r
/
e
s
m
o
r
p
m
o
C
0
0.06
0.08
0.1
n=1000 (l=13)
n=2000 (l=13)
n=5000 (l=14)
0.16
0.18
0.2
0.12
0.14
Fraction of malicious nodes (f)
Figure 13: Simulation results: fraction of compro-
ν = 500,
mised circuits in the reliable circuits.
Φ = 5min, and π = 25.
erable traﬃc due to the buddy selection process, and there-
fore buddy exhaustion attack could substantially degrade
network performance and may lead to system overload.
6. RELATED WORK
P2P anonymous communication systems have been the
subject of a lot of research [17, 24, 9, 29, 19, 25, 16]. AP3 and
Salsa are among the ﬁrst attempts at using DHT lookups for
anonymous communication. Their secure lookup protocols
rely heavily on redundancy and are shown to be vulnerable
to information leak attacks [18]. NISAN and Torsk are also
based on DHT lookups, but they are speciﬁcally designed
to mitigate information leak attacks. We have proposed a
variety of passive and active attacks on NISAN and Torsk
that signiﬁcantly reduce user anonymity.
An alternate approach to building circuits for anonymous
communication is to connect relays into a restricted topology
and construct circuits along paths in this topology [9, 29, 19].
For example, in Tarzan [9], each node has a small set of mim-
ics, and all circuits must be created on links between mim-
ics. To verify that paths are constructed correctly, nodes in
Tarzan maintain a global view of the system. This limits
Tarzan to networks of about 10 000 or fewer nodes. Mor-
phMix [29] is designed to eliminate such scalability con-
straints by creating a randomized, unstructured overlay be-
tween relays, with circuits built on paths along the over-
lay. Instead of maintaining a global view, MorphMix uses
a collusion detection mechanism involving witness nodes to
verify neighbor information. However, the collusion detec-
tion mechanism can be circumvented by a set of colluding
adversaries who model the internal state of each node, thus
violating anonymity guarantees [32].
In [25], the authors
of NISAN also considered a random walk construction to
complement their DHT-lookup-based design, which is found
to be vulnerable to active attacks. ShadowWalker [19] is
a recent design that proposes the use of redundant struc-
tured topologies to enable veriﬁcation of neighbor informa-
tion while mitigating information leak attacks.
Danezis and Clayton [5] studied attacks on peer discovery
and route setup in anonymous P2P networks. They showed
that if the attacker learns the subset of nodes known to the
initiator (by observing lookups, for example), its routes can
be ﬁngerprinted unless the initiator knows about the vast
majority of the network. Danezis and Syverson [7] extended
this work to observe that an attacker, who learns that certain
nodes are unknown to the initiator, can carry out attacks as
well and separate traﬃc going through a relay node.
Reiter and Rubin [28] proposed the predecessor attack,
which was later extended by Wright et al. [34, 35, 36]. In this
attack, an attacker tracks an identiﬁable stream of commu-
nication over multiple communication rounds and logs the
preceding node on the path. To identify the initiator, the
attacker uses the observation that an initiator is more likely
to be the predecessor than any other node in the network.
Similar to predecessor attacks, there is a thread of research
that deals with degradation of anonymity over a period of
time. Berthold et al. [2] and Raymond [27] proposed inter-
section attacks that aim to compromise sender anonymity
by intersecting sets of users that were active at the time the
intercepted message was sent, over multiple communication
rounds. Similarly, Kesdogan et al. [12] used intersection to
ﬁnd recipients of a given user’s message. A statistical ver-
sion of this attack was proposed by Danezis [4] and later
extended by Mathewson and Dingledine [14].
An important point of our paper is that, when building
anonymous systems, it is important not to abstract away the
properties of the system that can aﬀect anonymity. Similar
in spirit to ours, a lot of recent research has focused on
details abstracted away by conventional analysis models to
break the anonymity of the system. Such details include
congestion and interference [22, 1], clock skew [21], hetero-
geneous path latency [11, 1], the ability to monitor Internet
exchanges [23], and reliability [3]. For example, Murdoch
and Zieli´nski [23] showed that Internet exchange-level adver-
saries are capable of observing a vast majority of user traﬃc
and could degrade user anonymity by performing end-to-end
timing analysis. Borisov et al. [3] proposed selective-DoS at-
tack and showed that attackers could selectively aﬀect the
reliability of the system to degrade user anonymity.
7. CONCLUSION
In this paper, we have analyzed mechanisms that hide the
relationship between a user and its selected relays in two
state-of-the-art anonymous communication systems NISAN
and Torsk. We presented passive attacks on the NISAN
lookup and show that it is not as anonymous as previously
thought. Information learned from the NISAN lookup can
be used degrade anonymity of constructed circuits.We have
also shown that the information leaks in the Torsk lookup
allow an attacker to launch active attacks to defeat its se-
cret buddy mechanism, and substantially compromise user
anonymity. Our analysis of NISAN and Torsk shows that
their key mechanisms to anonymously look up a node are
vulnerable to either passive attacks or active attacks, moti-
vating the search for a secure and anonymous DHT lookup.
8. ACKNOWLEDGMENTS
We would like to thank Andriy Panchenko and Nicholas
Hopper for helpful discussions to let us better understand
the NISAN and Torsk schemes. We are very grateful to An-
driy Panchenko for sharing their code for the NISAN sim-
ulation, and George Danezis for motivating us to work on
this problem. We also thank the anonymous reviewers for
their invaluable feedback on the draft manuscript. This re-
search was supported in part by NSF grants: CNS-0627671
and CNS-0524695.
3179. REFERENCES
[1] A. Back, U. M¨oller, and A. Stiglic. Traﬃc analysis
attacks and trade-oﬀs in anonymity providing systems.
In I. S. Moskowitz, editor, IH, pages 245–257.
Springer-Verlag, LNCS 2137, April 2001.
[2] O. Berthold, H. Federrath, and M. K¨ohntopp. Project
anonymity and unobservability in the Internet. In
CFP, pages 57–65, New York, NY, USA, 2000. ACM.
[3] N. Borisov, G. Danezis, P. Mittal, and P. Tabriz.
Denial of service or denial of security? ACM CCS,
2007.
[4] G. Danezis. Statistical disclosure attacks: Traﬃc
conﬁrmation in open environments. In Gritzalis,
Vimercati, Samarati, and Katsikas, editors,
Proceedings of Security and Privacy in the Age of
Uncertainty, (SEC2003), pages 421–426, Athens, May
2003. IFIP TC11, Kluwer.
[5] G. Danezis and R. Clayton. Route Fingerprinting in
Anonymous Communications. IEEE Int. Conf. on
Peer-to-Peer Computing, pages 69–72, 2006.
[6] G. Danezis, R. Dingledine, and N. Mathewson.
Maxminion: Design of a type iii anonymous remailer
protocol. in IEEE Symposium on Security and
Privacy, May 2003.
[7] G. Danezis and P. Syverson. Bridging and
ﬁngerprinting: Epistemic attacks on route selection. In
PETS, pages 151–166, Berlin, Heidelberg, 2008.
Springer-Verlag.
[8] R. Dingledine, N. Mathewson, and P. Syverson. Tor:
The second-generation onion router. In USENIX
Security Symposium, August 2004.
[9] M. J. Freedman and R. Morris. Tarzan: A peer-to-peer
anonymizing network layer. ACM CCS, 2002.
[10] D. Goodin. Tor at heart of embassy passwords leak.
The Register, September 10 2007.
[11] N. Hopper, E. Y. Vasserman, and E. Chan-Tin. How
much anonymity does network latency leak? In ACM
CCS, October 2007.
[12] D. Kesdogan, D. Agrawal, and S. Penz. Limits of
anonymity in open environments. In F. Petitcolas,
editor, IH. Springer-Verlag, LNCS 2578, October 2002.
[13] K. Loesing. Measuring the tor network: Evaluation of
client requests to the directories. Tech. Report, 2009.
https://git.torproject.org/checkout/metrics/master/
report/dirreq/directory-requests-2009-06-26.pdf.
[14] N. Mathewson and R. Dingledine. Practical traﬃc
analysis: Extending and resisting statistical disclosure.
In PET, volume 3424 of LNCS, pages 17–34, 2004.
[15] P. Maymounkov and D. Mazieres. Kademlia: A
peer-to-peer information system based on the xor
metric. IPTPS, 2001.
[16] J. McLachlan, A. Tran, N. Hopper, and Y. Kim.
Scalable onion routing with torsk. ACM CCS,
November 2009.
[17] A. Mislove, G. Oberoi, A. Post, C. Reis, P. Druschel,
and D. S. Wallach. Ap3: Cooperative, decentrialized
anonymous communication. ACM SIGOPS European
Workshop, 2004.
[18] P. Mittal and N. Borisov. Infomation leaks in
structured peer-to-peer anonymous communication
systems. ACM CCS, 2008.
[19] P. Mittal and N. Borisov. Shadowwalker: Peer-to-peer
anonymous communication using redundant
structured topologies. ACM CCS, November 2009.
[20] U. Moller, L. Cottrell, P. Palfrader, and L. Sassaman.
Mixmaster protocol – version 2. IETF Internet Draft,
July 2003.
[21] S. J. Murdoch. Hot or not: Revealing hidden services
by their clock skew. In ACM CCS, October 2006.
[22] S. J. Murdoch and G. Danezis. Low-cost traﬃc
analysis of Tor. In IEEE Symposium on Security and
Privacy. IEEE CS, May 2005.
[23] S. J. Murdoch and P. Zieli´nski. Sampled traﬃc
analysis by Internet-exchange-level adversaries. In
N. Borisov and P. Golle, editors, PETS, Ottawa,
Canada, June 2007. Springer.
[24] A. Nambiar and M. Wright. Salsa: A structured
approach to large-scale anonymity. ACM CCS, 2006.
[25] A. Panchenko, S. Richter, and A. Rache. Nisan:
Network information service for anonymization
networks. ACM CCS, November 2009.
[26] L. D. Paulson. News briefs. IEEE Computer,
39(4):17-19, April 2006.
[27] J.-F. Raymond. Traﬃc Analysis: Protocols, Attacks,
Design Issues, and Open Problems. In H. Federrath,
editor, Proceedings of Designing Privacy Enhancing
Technologies: Workshop on Design Issues in
Anonymity and Unobservability, pages 10–29.
Springer-Verlag, LNCS 2009, July 2000.
[28] M. Reiter and A. Rubin. Crowds: Anonymity for web
transactions. ACM TISSEC, 1(1), June 1998.
[29] M. Rennhard and B. Plattner. Introducing morphmix:
Peer-to-peer based anonymous internet usage with
collusion detection. WPES, 2002.
[30] I. Stoica, R. Morris, D. Liben-Nowell, D. R. Karger,
M. F. Kaashoek, F. Dabek, and H. Balakrishnan.
Chord: A scalable peer-to-peer lookup protocol for
internet applications. IEEE/ACM Trans. Netw.,
11(1):17–32, 2003.
[31] P. Syverson, G. Tsudik, M. Reed, and C. Landwehr.
Towards an analysis of onion routing security.
International Workshop on Design Issues in
Anonymity and Unobservaility, vol. 2009, LNCS,
Springer, July 2000.
[32] P. Tabriz and N. Borisov. Breaking the collusion
detection mechanism of MorphMix. In G. Danezis and
P. Golle, editors, PET, pages 368–384, Cambridge,
UK, June 2006. Springer.
[33] P. Wang, I. Osipkov, N. Hopper, and Y. Kim. Myrmic:
Secure and robust dht routing. Tech. Rep. Univerity of
Minnesota DTC Research Report, 2006.
[34] M. Wright, M. Adler, B. N. Levine, and C. Shields.
An analysis of the degradation of anonymous
protocols. In NDSS. IEEE, February 2002.
[35] M. Wright, M. Adler, B. N. Levine, and C. Shields.
Defending anonymous communication against passive
logging attacks. In IEEE Symposium on Security and
Privacy, May 2003.
[36] M. Wright, M. Adler, B. N. Levine, and C. Shields.
The predecessor attack: An analysis of a threat to
anonymous communications systems. ACM TISSEC,
4(7):489–522, November 2004.
318