chance of success of a random guessing success when n is small,
but as n increases, the probability of a random guess attack goes
down. As for the user experience, the time users spent on the
CAPTCHA task increases as the size of candidate image pool in-
crease, but the effect of an increased size of answer set on users
time is not obvious. We think the optimum choice of n and k might
depends on particular content of the images used, and a specialized
user study can be conducted if such data is desired.
4.2 Security Analysis
We consider an adversary model wherein a bot has access to the
unlabeled and uncategorized database of images from which we
form our challenges. It is to be noted that given ample time and
resources some of the attacks discussed below could succeed but
taking a long time defeats the primary purpose of the bot. Our goal
as in any CAPCTHA system is to make current attacks as difﬁcult
as possible, so that any successful attack would need a major step
forward in technology. We now identify and analyze possible ways
of attacks against our system and how it fares against them.
4.2.1 Attacks using machine learning techniques
Similar techniques used to attack Asirra [22] could be used to at-
tack our system too. The attack on Assira was an attack on the ﬁrst
level of our model namely simple “image recognition”. In essence,
attackers try to get a certain number of correctly labeled images,
and train on several different classiﬁers, either based on color in-
formation or texture information. However, solving a SEMAGE
challenge not only requires image recognition but also identifying
the “semantic relationship”. The identiﬁcation of “semantic rela-
tionship” among images is an unsolved AI problem. Moreover,
even if the semantic correlation is weak and the semantic label is
just the object name, SEMAGE accommodates much more object
classes than Asirra (which had only 2), and the attacker will need
to build many more types of classiﬁers accordingly.
Now let us consider a very simple example of “semantic relation-
ship”, e.g., “real and cartoon” images of the same animal (as used
in Section 5). The color and texture data between a cartoon specie
and real animal specie varies much more than in between cartoons
and real animals, as illustrated in Figure 4. While attackers might
attempt to train classiﬁer of real animal and cartoon animal inde-
pendently, the performance decreases as the number of classiﬁers
increase which could be very complex. Thus the success rate of
attacks using this sort of algorithm is likely to be very low.
Figure 4: Example limitations of the texture-based machine learn-
ing attack; (a) shares more commonality with (b) than with (c) ,
while (a) and (c) are of the same type (rabbit).
Attacks using template ﬁtting techniques: In image recogni-
tion, one developed area is to ﬁt objects into (visual) feature tem-
plates. For example, a chair can be identiﬁed if given the template
of ‘four legs and a horizontal top’. Accordingly, for a rabbit, the
feature should probably be ‘upwards pointing long ears’. However,
it is much harder to deﬁne ‘long’ than ‘upwards’. A deer, with
pointy upward ears would be classiﬁed into the ‘rabbit’ template.
Furthermore, not all objects have such uniquely identiﬁable simple
feature.
4.2.2 Random guess attack
For a SEMAGE scheme that presents n candidate images and
asks the user to select k matching images, the success rate of ran-
dom guessing is 1/C(n, k). As shown in Figure 5, choosing a low
value of n and k could make the system more vulnerable to ran-
dom guess attacks. On the other hand a low n, k makes the system
more user friendly and less frustrating for the user. Our imple-
mentation for the user study uses low n, k values making it more
susceptible to random guess attacks. In case of a low n, k system,
multiple rounds of SEMAGE could constitute one challenge; such
technique is already in use in current systems such as reCAPCTHA.
By choosing a relatively low n, k value, we sacriﬁce a bit of secu-
rity against random guess attacks for usability. We do so because
we can make up for the relatively high susceptibility of SEMAGE
to random guess attacks and deter brute force attackers by enhanc-
ing SEMAGE with Token Buckets [20] system. Assira needs more
images in each challenge set to be secure because of the limited set
of differentiating classes of objects (two to be precise, just cats and
dogs) whereas there can be theoretically thousands of differentiat-
ing classes in our SEMAGE implementation. The added security
provided by SEMAGE’s two-factor design allows us to use a low
n, k system without sacriﬁcing security much.
A SEMAGE system could also be complemented with other tech-
niques such as the Partial Credit Algorithm in [20], which would
allow a large n, k and an ‘almost right’ answer can be deﬁned
as missing one image in the answer set. Token buckets [20] can
also be implemented to prevent brute-force attackers from making
a number of continuous random guess attacks.
4.2.3 Attack using the static image name in source
If the source code of the HTML page hosting the challenge uses
image names, an attacker could potentially use those names to iden-
tify similar images. However, this sort of attack is easily defeated
by randomizing the images name in the source. In our system im-
plementation, names of the images in the challenge are in no way
exposed to the user. The image names in the html source is ran-
domized when sent to the user.
Figure 5: Random guess attack success rate with respect to k and
n
4.2.4 Attack by creating an attack database using the
general relationships used in the system
The attacker might manually identify the general “semantic re-
lationship” used in the system and then search and build an image
repository to create an attack database. Using the labeled images
of the attack database, a brute force search against the candidate set
might yield him a correct ‘similar’ set. However comparing each
image of the challenge with all the images in the attacker’s image
archive would take lots of time and resources than what would con-
stitute a feasible attack; also this might exceed the maximum time
allowed to take a challenge.
4.2.5 Attack by mining Textual description of images
Potentially an attacker could use systems such as google’s gog-
gle1, an image based search system, to uncover textual descriptions
of the candidate image set and then use the textual descriptions to
identify relationships among images. We argue that ﬁrst of all im-
age recognition or search is still not mature enough for now (very
hard problem for unknown images). In addition, identifying rela-
tionships among objects even with textual descriptions is a com-
plex AI problem to solve, especially since the correct similar im-
ages depend on the semantic context. Such an attack would poten-
tially defeat most present image-based systems such as Assira, PIX,
SQ-PIX, but because of the two level design of SEMAGE, the bot
would still need to understand and identify the semantic correla-
tion. Having a textual description only possibly solves the problem
of image recognition. There may exist images with overlapping de-
scriptions but are not a part of the ‘semantic similar’ image set in
the context. Consider for example a candidate image set wherein
the context is identifying ‘four legged’ animals among images of
insect, deer, lion, human, electronics item and other unrelated ob-
jects. Now even with accompanying textual descriptions such a
relationship is hard for a bot to ﬁnd and relate to lion and deer.
5. EVALUATION
We conducted a large-scale user study to evaluate the usability of
SEMAGE as compared to Assira and reCAPTCHA. For this pur-
pose, we ﬁrstly built a website which would present the users with
sample SEMAGE challenges.
5.1 Sample Implementation of SEMAGE
In our sample implementation, each challenge consists of a set
of images (the number of images is conﬁgurable) where a sub-
set of images would share a distinct relationship/feature with each
other. The images are furthermore randomly distorted by intro-
ducing noise and changing the texture. Our implementation was
carried out in PHP with MySQL being used as the database. Figure
6 gives a high level design of the implementation.
1http://www.google.com/mobile/goggles/
Figure 6: Overall Implementation Illustration
have a fast and easy way to build up a large database. In reality,
since the automated search does not always yield relevant results,
we manually weed out the irrelevant images from the collection.
Dynamic Noise Addition: To make machine learning attacks
based on image classiﬁers difﬁcult, we randomly introduce noise
in the images of the challenge set at each challenge creation phase.
We introduce noise in the form of random shapes and color scale
alteration in the image with the help of the ImageMagick library
[5]. The position of inserting the random shapes varies from the
center of the images to its edges. Also scale of color adjustment
is also randomly varied to prevent the bot classiﬁers from easily
weeding out the noise. Such random noise introduction makes sure
that each image appears with different noise levels. Figure 8 shows
a SEMAGE challenge after the introduction of noise.
Figure 7: Screenshot of sample SEMAGE implementation with Im-
age 2 and 5 being similar, both snakes.
Choosing the “semantic relationship”: In our particular im-
plementation, the challenge set consists of real and cartoon images
of animals with the relationship deﬁning the ‘similar’ subset be-
ing “real and cartoon images” of the same animal. The advantages
of choosing the ‘real and cartoon’ relationship to deﬁne “semantic
relationship” between images are as follows:
• The relationship between real and cartoon images of the same
animal in most cases is subtle and variable. The reason is that
the animals may completely differ in visual characteristics
such as size, shape and outline in real and cartoon represen-
tations.
• Humans with inherent capability to relate visibly dissimilar
objects would be able to pass the challenge easily whereas
the current state-of-the-art bots cannot. We test this assump-
tion of ours in the user study we conduct, discussed in details
in Section 5.
• Generating a large database is easier. A simple search for
an animal on images.google.com yields millions of entries,
hence we have a fast and easy way to build up a large database.
Figure 7 shows a sample SEMAGE challenge of our simple im-
plementation. The total number of images in one challenge is six
with the “semantically similar” set of two images, one a real image
and the other a cartoon image of the same animal.
Database Generation: The ﬁrst step for SEMAGE implemen-
tation after deﬁning the semantic relationship between the “simi-
lar” images is database generation. An image search and down-
load tool was implemented shown as Image Retriever in Figure 6,
which searches and downloads the required images from the web.
The tool would take in the search keywords (to search for real or
cartoon images of the animals), image dimensions, and number of
images to download and the label tags. It then automatically down-
loads the images and stores in the database. A simple search for an
animal on images.google.com yields millions of entries, hence we
Figure 8: Example of noise addition in our implementation. Here
we can clearly see noise but still identify Image 2 and 5 being simi-
lar, both lions. The changes in color scale are not visible due to the
black and white nature of images.
Interface: As shown in Figures 8 and 7, each challenge appears
as a tabular strip of images. The title of the tabular strip presents the
challenge and then the user needs to click on the similar images and
press submit to send the response to the server for veriﬁcation. We
experimented with different layouts, e.g., the images being apart
from one another, images in a single straight strip, and found that
it is much easier to identify similar images if they are bunched to-
gether in a tabular format.
5.2 User Study Methodology
A comprehensive IRB approved user study was then conducted
to gather data about how user-friendly SEMAGE is, which is one of
the most essential criterion for a CAPTCHA to be deployed in real
systems. We also incorporated reCAPTCHA, a text-based system
and Asirra, an image-based system from Microsoft in the user study
to carry out a comparative analysis. Both Asirra and ReCAPTCHA
are available as a free web service allowing us to easily integrate
them in our study. The volunteers took the study remotely and
were given a brief 1-page pictorial description of what they need to
do to pass a challenge for all the systems. We logged the time taken
to complete each challenge as the difference in time between when
the test ﬁrst appears on the screen and the time user clicks on the
‘submit’ button to submit his attempt. The users were let known
of whether they passed or failed the previous challenge before pre-
senting a new one.
A total of 174 volunteers took the study and the population was
a mix of graduate and under-graduate students. The subject pool
was diverse with most of the users from a non-computer science
discipline, with a mix of native and non-native English speakers.
The subject pool consisted of 66 females and 108 males. The sub-
ject pool were in no way made aware of the fact that SEMAGE is
our system. We collected the time taken by each user to complete
a challenge for each of the system as described earlier. We monitor
the time taken for all attempts irrespective of whether it was suc-
cessful or not. We also collected numbers of successful and failed
attempts to solve a challenge.
5.3 User Study Layout
The user study was carried out via a website with the following
sections:
• An initial questionnaire asking the users to rate their famil-
iarity with CAPTCHAs, proﬁciency in English language and
other demographic questions such as sex and age range.
• A 1-page pictorial description of EMAGE, Assira and re-
CAPTCHA, showing users how to solve each challenge.
• 5 different challenges from SEMAGE.
• 5 different challenges from Asirra.
• 5 different challenges from ReCAPTCHA.
• A ﬁnal short questionnaire asking users to rate SEMAGE for
fun factor and ease of use as compared to Assira.
We believe a pictorial description of each of the systems was nec-
essary for fair usage statistics on the image recognition systems. It
was probably a user’s ﬁrst time seeing an image-based CAPCTHA
whereas all the users had invariably taken a text-based challenge
before. Presenting a brief description of what they need to do to
pass a challenge would prepare them with necessary basic infor-
mation of each system and allow us to collect fair usage data. The
study took an average of 8.7 minutes to complete.
We divide the usability evaluation in different sections presented
below according to the following metrics:
• How fast can a user complete a challenge?
• How many times does the user pass the challenge success-
fully?
• Does the user consider the system to be fun and easy?
5.4 Timing Statistics
As shown in Table 1, users complete text-based and SEMAGE
challenges faster than Asirra. Each user takes an average of 6 sec-
onds more to complete an Assira challenge.
Time Taken in
seconds