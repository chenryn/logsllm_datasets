title:The Power of Evil Choices in Bloom Filters
author:Thomas Gerbet and
Amrit Kumar and
C&apos;edric Lauradoux
2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
The Power of Evil Choices in Bloom Filters
Thomas Gerbet
Université Joseph Fourier, France
e-mail: PI:EMAIL
Amrit Kumar, Cédric Lauradoux
INRIA, France
e-mail: {amrit.kumar, cedric.lauradoux}@inria.fr
Abstract—A Bloom ﬁlter is a probabilistic hash-based data
structure extensively used in software including online security
applications. This paper raises the following important question:
Are Bloom ﬁlters correctly designed in a security context? The
answer is no and the reasons are multiple: bad choices of
parameters, lack of adversary models and misused hash functions.
Indeed, developers truncate cryptographic digests without a
second thought on the security implications. This work constructs
adversary models for Bloom ﬁlters and illustrates attacks on three
applications, namely SCRAPY web spider, BITLY DABLOOMS
spam ﬁlter and SQUID cache proxy. As a general impact, ﬁlters
are forced to systematically exhibit worst-case behavior. One
of the reasons being that Bloom ﬁlter parameters are always
computed in the average case. We compute the worst-case
parameters in adversarial settings, show how to securely and
efﬁciently use cryptographic hash functions and propose several
other countermeasures to mitigate our attacks.
Keywords—Bloom ﬁlters; Hash functions; Digest truncation;
Pre-image attack; Denial-of-Service;
I.
INTRODUCTION
Bloom ﬁlter [1], is a space-time efﬁcient probabilistic data
structure for set-membership query. They are very popular
among software developers since they often reduce the mem-
ory consumption of applications. While the goal of some
of these applications is simply to provide a robust end-to-
end service, Bloom ﬁlters also form a backbone of more
critical and sensitive infrastructures such as malware/phishing
detection tools and spam ﬁlters among many others.
In this work, we show that Bloom ﬁlters should be judi-
ciously deployed as this seemingly “innocuous” data structure
can be easily exploited and can be forced to behave as per
the terms of an adversary. Our ﬁndings demonstrate that if
Bloom ﬁlter parameters are ill-chosen, they are prone to severe
algorithmic complexity attacks [2].
We present attacks on critical
infrastructures built on
Bloom ﬁlters. Our attacks rely on the vulnerability of weak
hash functions or the inordinate use of secure hash functions.
In fact, due to the hashing abstractions, software developers
are often in the dilemma of selecting a “good hash function”
for the concerned application. Considering the application
distinctions, hash functions can be broadly classiﬁed into non-
cryptographic and cryptographic ones. Clearly, using the latter
to perform the task of the former entails an efﬁciency overhead.
Developers are however tempted to employ non-cryptographic
hash functions to boost the performance of their applications.
Another temptation for developers related to hash function is
digest truncation. Hash functions, in general, produce more bits
than required by an application. Several bits of the digest are
thus discarded. There might be several motivations to truncate
digests: it could be a deliberate and arbitrary choice of the
developer or it could be required by the underlying algorithm.
Unfortunately, either of these temptations is a security sin and
hence can be easily exploited.
We deﬁne adversary models for our attacks and present
our ﬁndings on several applications. The main result of our
adversarial model is the computation of the worst case error
probability for Bloom ﬁlters. We show that if Bloom ﬁlter
parameters are not chosen according to the worst case error
probability, an adversary can pollute a ﬁlter with well chosen
inputs, forcing it to deviate from its normal behavior. She can
also query the ﬁlter to make it produce erroneous answers
(or false positives). Once again, our attacks rely on a kind of
forgery similar to ﬁnding pre-images and second pre-images
of digests. The forgery is feasible either due to the use of
non-cryptographic hash functions or due to the truncation of
cryptographic digests: the bad habits of developers have not
changed since [2]. Finally, we also show how to strengthen
Bloom ﬁlters against adversaries. We explore the trade-off
between the query time, the memory consumption and the
security with respect to the proposed countermeasures.
The contribution of the paper is threefold. First, we de-
scribe adversary models for Bloom ﬁlters. We show how they
can be polluted/saturated using pre-image attacks and how it
increases the false-positive probability. Then, we show how to
forge false-positives. In the adversarial settings, we have the
liberty to assume that the inputs to the ﬁlter are non-uniformly
distributed. This observation leads to our second contribution:
we compute the worst case false-positive probability and obtain
new equations for Bloom ﬁlter parameters. Finally, we provide
techniques to save calls to cryptographic hash functions when
used in a Bloom ﬁlter. To support our contributions, we provide
three attacks on software applications based on Bloom ﬁlters:
Bloom-enabled SCRAPY web spider, BITLY DABLOOMS spam
ﬁlter and SQUID web cache. Our attacks retain some form of
DoS and rely on forging Uniform Resource Locators (URLs)
matching certain pre-image or second pre-image property.
The paper is organized in three parts. In the ﬁrst part,
we succinctly provide essential material on hash functions
(Section II) and Bloom ﬁlters (Section III). In the second
part, we ﬁrst describe our adversary models (Section IV) and
then proceed with the three illustrations. Section V presents
SCRAPY and our pollution and query attacks against its déjà
vu URL list. In Section VI, we extend our attack to a variant of
Bloom ﬁlter: DABLOOMS, a data structure proposed by BITLY
to ﬁlter malicious URLs. Section VII introduces SQUID proxy
and describes an attack against its cache digest mechanism.
The third part of the paper describes countermeasures (Sec-
tion VIII) and the related work (Section IX).
978-1-4799-8629-3/15 $31.00 © 2015 IEEE
978-1-4799-8629-3/15 $31.00 © 2015 IEEE
DOI 10.1109/DSN.2015.21
DOI 10.1109/DSN.2015.21
101
101
II. HASH FUNCTIONS
A hash function compresses inputs of arbitrary length to
digest/hash of ﬁxed size. It is a very popular primitive used
in algorithms [3] and in cryptography/security [4]. The design
of a “good hash function” depends on the ﬁeld of application.
Non-cryptographic hash functions such as MurmurHash [5] or
Jenkins hash [6] are designed to be fast, to uniformly distribute
their outputs and to satisfy several other criteria such as the
avalanche test [5]. The SMHASHER suite [5] provides a good
overview of these functions and the tests they must satisfy.
The design of a cryptographic hash function is very dif-
ferent. Cryptographic hash functions are slower than their
non-cryptographic siblings. Furthermore, a cryptographic hash
function h must verify the following properties:
• Pre-image resistance: Given a digest d, it is computation-
• Second pre-image resistance: Given an input x and the
digest h(x), it is computationally infeasible to ﬁnd another
input x(cid:2) (cid:2)= x, such that h(x) = h(x(cid:2)
• Collision resistance: It is computationally infeasible to
ﬁnd two inputs x (cid:2)= x(cid:2) such that h(x) = h(x(cid:2)
ally infeasible to ﬁnd an input x, such that h(x) = d.
).
).
Non-cryptographic hash functions are not designed to satisfy
these properties [2], [7].
Let us consider a hash function h with (cid:2)-bit digests.
The choice of (cid:2) is critical for cryptographic hash functions
because the basic complexities for ﬁnding pre-image, second
pre-image and collisions are 2(cid:2), 2(cid:2) and 2(cid:2)/2 respectively. A
cryptographic hash function is considered secure if there is no
attack with a lower complexity. The NIST recommendation for
cryptographic hash functions are SHA-256, SHA-384, SHA-
512 [9] and SHA-3 [10].
We provide in this paragraph the notion of truncated
digests. In fact, many applications need to reduce the size
of the full digest. Truncated digests must be carefully used
as explained in [8], since it is commonly assumed that for a
truncated digest of (cid:2)(cid:2) bits the security is reduced at least to
2(cid:2)(cid:2)
(pre-image and second pre-image) and 2(cid:2)(cid:2)/2 (collision). If
(cid:2)(cid:2) is too small, computation of pre-image, second pre-image
or collisions are feasible. In the following, we cover a popular
application of hashing: Bloom ﬁlters.
III. BLOOM FILTERS
Bloom ﬁlters introduced by Bloom [1] is a space-efﬁcient
probabilistic data structure that provides an algorithmic so-
lution to the set-membership query problem, which consists
in determining if a given item belongs to a predeﬁned set.
To this end, Bloom ﬁlter offers a succinct representation of a
set of items which can dramatically reduce space, at the cost
of introducing false positives. If false positives do not cause
signiﬁcant problems, then Bloom ﬁlter may provide improved
performance of an application.
Since its conception, Bloom ﬁlters have been used for
various purposes in networking: resource routing [11], web
caching [12] or ﬁltering [13]. They have also been used in
cryptography in designing efﬁcient primitives such as search-
able encryption [14] and private set intersection [15] among
102102
there is a signiﬁcant
literature
others. As a consequence,
on Bloom ﬁlters. Our contribution to Bloom ﬁlter theory
(see Section VIII) is the analysis of false positive probability
under adversarial settings, where an adversary may choose
items to be inserted into the ﬁlter.
In the following, we recall the Bloom ﬁlter data structure,
and in the next section, we explain how an adversary can
pollute/saturate a ﬁlter or how he can generate items leading
to false positives.
Description
Essentially, a Bloom ﬁlter is represented by a binary vector
(cid:3)z of size m. In the following, we deﬁne the support of a vector
(cid:3)z of size m, i.e., (cid:3)z = (z0, . . . , zm−1) denoted by supp((cid:3)z) as
the set of its non-zero coordinate indexes:
supp((cid:3)z) = {i ∈ [0, m − 1], zi (cid:2)= 0} .
We also denote wH ((cid:3)z), the Hamming weight of the ﬁlter (cid:3)z,
i.e., the number of 1s in the ﬁlter. We use x with eventual
subscripts to denote items inserted in the ﬁlter, while y with
eventual subscripts to denote items queried to the ﬁlter.
In case of a classical Bloom ﬁlter, the vector (cid:3)z is initialized
to (cid:3)0. The ﬁlter is then incrementally built by inserting items
of a set S by setting certain bits of the ﬁlter to 1. By checking
if these bits are set to 1, one may verify the belonging of an
item in the ﬁlter. A detailed description follows:
a) Insertion: An item x ∈ S is inserted into a Bloom
to k independent hash functions
ﬁlter by ﬁrst feeding it
{h1, . . . , hk} (supposed to be uniform) to retrieve k digests
modulo m: Ix = {h1(x) mod m, . . . , hk(x) mod m} . These
reduced hashes give k bit positions of (cid:3)z. Finally, insertion of x
in the ﬁlter is achieved by setting the bits of (cid:3)z at these positions
to 1. Since all the operations on digests are truncated modulo
m in Bloom ﬁlters, for simplicity we omit mod m in the rest
of the paper.
b) Query: To determine if an item y belongs to S,
we check if y has been inserted into the Bloom ﬁlter (cid:3)z.
Achieving this requires y to be processed (as in insertion)
by the same hash functions to obtain k indexes of the ﬁlter,
Iy = {h1(y), . . . , hk(y)}. If the bit of (cid:3)z at any of these indexes
is 0, then the item is not in the ﬁlter, otherwise if Iy ⊆ supp((cid:3)z),
the item is present (with a small false positive probability).
Bloom ﬁlters can store items of arbitrary size using only m
bits and the insertion/query runs in constant time: computation
of k hash functions. However, this space and time efﬁciency
of Bloom ﬁlter, comes at the cost of false positives.
c) False positive probability: False positives arise due
to the collision on the reduced digests (see [11] for a detailed
analysis). Let n be the number of insertions into the ﬁlter, then
the probability of obtaining a false positive is:
(cid:5)k
(cid:4)kn
.
(cid:2)
(cid:3)
f =
1 − 1
m
1 −
(cid:6)
1 − e− kn
m
f ≈
(cid:7)k
For large m and relatively small k, we have:
.
(1)
We note that (1) is not the most accurate approximation
of the false positive probability (see [16] for a more accurate
result). However, it is often used in software implementations
and hence we abide by it throughout the paper.
There are two competing forces behind the false positive
probability. On the one hand, using more hash functions gives
a higher chance to ﬁnd a bit not set for an item which is not
a member of the ﬁlter, while on the other hand, using fewer
hash functions increases the fraction of bits not set in the ﬁlter
and hence decreases the false positive probability. The optimal
number of hash functions that minimizes the false positive
probability is (see [11]):
kopt =
· ln 2 ,
m
n
and the corresponding false positive probability satisﬁes:
ln (fopt) = − m
n
· (ln 2)2 .
(2)
(3)
Another important result is on the expected number of set
bits in the ﬁlter. Let X be the random variable representing
the number of 0s in the ﬁlter. After the insertion of n random
elements, it follows that:
E(X) =
(cid:4)
m(cid:8)
i · P (X = i)
(cid:3)
m(cid:8)
(cid:10)kn ≈ e− kn
= mp ,
m
i
m
.
=
i=0
i=0
i ·
(cid:9)
1 − 1
m
where, p =
(1 − p)
pi
m−i
(4)
Hence, in the optimal case, the expected number of 0s in
the ﬁlter is m
2 . Broder and Mitzenmacher [11] further show
that the exact fraction of unset bits is extremely concentrated
around its expectation, using a simple martingale argument.
Speciﬁcally, they prove using the Azuma-Hoeffding inequality,
that for any  > 0,
P (|X − mp| ≥ m) ≤ 2e−2m2/nk
.
(5)
x1
2
1
x2
x3
1
2
1
2
0 0 0 0 1 1 0 1 1 0 1 0
1
2
y1 /∈ S
1
2
y2 = x2
2
1
y3(false positive)
Fig. 1: Bloom ﬁlter with m = 12 and k = 2.
Example 3.1 (Bloom ﬁlter): Fig. 1 presents a Bloom ﬁlter
of size m = 12 bits, constructed using k = 2 hash functions.
The inserted set consists of 3 items, S = {x1, x2, x3}. A
collision occurs on the ﬁrst reduced digests of x1 and x3