2,000
1,000
)
B
M
(
y
r
o
m
e
M
Rank
Unrank
1.2
1
0.8
0.6
0.4
0.2
)
s
m
(
e
m
T
i
0
1,000
1,500
2,000
2,500
3,000
3,500
4,000
0
1,000
1,500
2,000
2,500
3,000
3,500
4,000
0
1,000
1,500
2,000
2,500
3,000
3,500
4,000
25
20
15
10
5
)
s
(
e
m
T
i
60
40
20
)
B
M
(
y
r
o
m
e
M
Rank
Unrank
)
s
m
(
e
m
T
i
25
20
15
10
5
0
1,000
1,500
2,000
2,500
3,000
3,500
4,000
0
1,000
1,500
2,000
2,500
3,000
3,500
4,000
0
1,000
1,500
2,000
2,500
3,000
3,500
4,000
Slice size
Slice size
Slice size
Figure 5: Results for the (top row) C99 grammar, (middle row) C992 grammar, and (bottom row) GD grammar
using slices n = 1000, 1100, . . . ,4000. (Left column) The memoization time is the time to execute NS(n) (using NS from
Algorithm 3, when A = S) for the ﬁrst time. (Middle column) The memoization space is estimated using the /proc
interface. (Right column) Ranking and unranking was performed as in Algorithm 1 and Algorithm 2.
The results are shown in Figure 5, where we report on
initialization time (ﬁrst column), memoization space uti-
lization (second), and ranking and unranking times (last
column). Note that the ranking/unranking times are mea-
sured in milliseconds, and these operations are fast. We also
computed the size of the intermediate sets exactly, but we
noticed that they can be approximated as |I| (cid:24)10
1.87×n
for C99, |I| (cid:24)10
for
GD. Thus in all cases the size of the intermediate set I was
exponential in the slice size n.
for C992, and |I| (cid:24)10
1.67×n
0.83×n
5.2.3 Ambiguity
Although C99 is ambiguous, our experiments detected no
outsiders even after we increased the repeat count C from
100 to 10000 trials per slice. The reason is that the density
of ambiguous strings is very low.
To better understand this, consider the smaller, but still
ambiguous grammar GA in Figure 6. The lexical token ID
represents an identiﬁer, and the token NUM represents an in-
teger constant; both have arbitrary length. GA allows a clas-
sic example of ambiguity: the statement if(a)if(b)c;else
d; can be parsed in two ways: if(a){if(b)c;else d;}, or
if(a){if(b)c;}else d;.
StatementList: S | S StatementList
S : AS | IF ’(’E’)’ S | IF ’(’E’)’ S ELSE S | ’{’S’}’
AS : E ’;’ | ID ’=’ E ’;’
E : ID | NUM
Figure 6: An example of an ambiguous grammar GA
We purposely crafted grammar GA to be ambiguous and
to have few kinds of unambiguous statements. Yet, we de-
tected no outsiders for a slice size of 1000 in C = 10, 000
trials. One intuitive explanation is that an ambiguous string
requires an if..if..else construct. The keywords use 2 +
2 + 4 = 8 bytes out of the 1000 bytes slice size. We could
remove the keywords and ﬁll those 8 bytes with identiﬁers or
constants in many ways. Thus for a single ambiguous word
we can get potentially many more unambiguous ones, hence
a low density of ambiguous words. To test this explanation,
we reduced the number of possible lexical tokens, and we
changed the regexes of ID and NUM to match exactly one
value each. This should increase the density of ambiguous
strings. Indeed, in this case we counted U = 9 outsiders in
C = 100 trials, and estimated β (cid:24) C/(C − U ) (cid:24) 1.1. We re-
peated the experiment by enforcing various bounds for the
number of elements that ID and NUM can match. Table 1
1302Experiment Parameters
Limit on # of tokens Trials Measured
|L(ID)|
|L(NUM)|
U
9
1257
111
33
422
20
14
2
0
Inferred
β
1.1
1.14
1.01
1.003
1.004
1.002
1.001
1
1
1
1
2
3
3
4
4
10
15
1
1
2
2
2
2
3
10
10
C
102
104
104
104
105
104
104
105
105
Table 1: Counting the number of outsiders for GA. C is the
number of attempts to ﬁnd an outsider, and U is the number
of outsiders found, i.e. r (cid:18)= Rank(Unrank(r)). The notation
|L(X)| = 2 means that token X may only take one of two
values, say x1 or x2. The ambiguity-factor β is estimated as
β (cid:24) C/(C − U )
shows the results. It backs the hypothesis that, at least in
this case, the more values lexical tokens can take, the lower
it is the percentage of ambiguous strings (which require ﬁxed
keywords).
Discussion. The experiments indicate that our method for
relaxed ranking based on CFGs is both usable and eﬃcient.
Once the memoization is performed, ranking and unrank-
ing are fast, even for complex languages such as C99, and
run in under one second even for slices as large as 4,000
bytes. While theoretically an impediment, in practice am-
biguity is not a a problem for commonly used grammars.
Even when we used a highly ambiguous grammar, we could
not experimentally detect any outsiders unless we artiﬁcially
bounded the number of values that lexical tokens could take
on to be very small numbers. Even in the extreme case
when we allowed only one value for each token, the mea-
sured ambiguity-factor was less than 2. This means, for
instance, that the expected number of cycle walks for FPE
is at most 2 in the scheme from Section 2. Thus encryption
and decryption will be fast.
Acknowledgements
We thank the reviewers for their helpful comments. This
work was supported in part by the US National Science
Foundation (NSF) grants CNS-1228782, CNS-1228620, CNS-
1064944, CNS-1330308, CNS-1065134, CNS-1253870, CNS-
0845610 and CNS-1319061.
6. REFERENCES
[1] The gnu multiple precision arithmetic library.
http://gmplib.org/.
[2] M. Bellare, T. Ristenpart, P. Rogaway, and T. Stegers.
Format-preserving encryption. In Selected Areas in
Cryptography, pages 295–312. Springer-Verlag, 2009.
[3] J. Black and P. Rogaway. Ciphers with arbitrary ﬁnite
domains. In Topics in Cryptology–CT-RSA 2002,
pages 114–130. Springer Berlin Heidelberg, 2002.
[4] M. Brightwell and H. Smith. Using
datatype-preserving encryption to enhance data
warehouse security. In 20th National Information
Systems Security Conference Proceedings (NISSC),
pages 141–149, 1997.
[5] Ansi c99 grammar yacc speciﬁcation. http:
//www.quut.com/c/ANSI-C-grammar-y-1999.html.
[6] R. Dingledine, N. Mathewson, and P. Syverson. Tor:
the second-generation onion router. In Proceedings of
the 13th conference on USENIX Security Symposium -
Volume 13, pages 21–21, Berkeley, CA, USA, 2004.
USENIX Association.
[7] K. P. Dyer, S. E. Coull, T. Ristenpart, and
T. Shrimpton. Protocol misidentiﬁcation made easy
with format-transforming encryption. In Proceedings
of the 20th ACM Conference on Computer and
Communications Secuirty (CCS 2013), November
2013.
[8] A. Goldberg and M. Sipser. Compression and ranking.
In Proceedings of the seventeenth annual ACM
symposium on Theory of computing, STOC ’85, pages
440–448, New York, NY, USA, 1985. ACM.
[9] M. Holzer and M. Kutrib. Descriptional complexity of
(un)ambiguous ﬁnite state machines and pushdown
automata. In Proceedings of the 4th international
conference on Reachability problems, RP’10, pages
1–23, Berlin, Heidelberg, 2010. Springer-Verlag.
[10] O. H. Ibarra and B. Ravikumar. On sparseness,
ambiguity and other decision problems for acceptors
and transducers. In 3rd annual symposium on
theoretical aspects of computer science on STACS 86,
pages 171–179, New York, NY, USA, 1985.
Springer-Verlag New York, Inc.
[11] S. Kannan, Z. Sweedyk, and S. Mahaney. Counting
and random generation of strings in regular languages.
In Proceedings of the sixth annual ACM-SIAM
symposium on Discrete algorithms, SODA ’95, pages
551–557, Philadelphia, PA, USA, 1995. Society for
Industrial and Applied Mathematics.
[12] L. Lee. Fast context-free grammar parsing requires
fast boolean matrix multiplication. J. ACM,
49(1):1–15, Jan. 2002.
[13] J. Levine, T. Mason, and D. Brown. Lex & Yacc, 2Nd
Edition. O’Reilly, second edition, 1992.
[14] D. Luchaup, K. P. Dyer, S. Jha, T. Ristenpart, and
T. Shrimpton. Libfte: A user-friendly toolkit for
constructing practical format-abiding encryption
schemes. In Proceedings of the 14th conference on
USENIX Security Symposium, 2014.
[15] E. M¨akinen. Ranking and unranking left szilard
languages. Technical report, ISO/IEC
JTC1/SC29/WGll/N2467, Atlantic City, 1997.
[16] A. Nijenhuis and H. S. Wilf. Combinatorial
Algorithms. New York : Academic Press, 1975.
[17] B. Ravikumar and O. H. Ibarra. Relating the type of
ambiguity of ﬁnite automata to the succinctness of
their representation. SIAM J. Comput.,
18(6):1263–1282, Dec. 1989.
[18] R. Schroeppel and H. Orman. The hasty pudding
cipher. AES candidate submitted to NIST, page M1,
1998.
[19] M. Sipser. Introduction to the Theory of Computation.
Cengage Learning, 2012.
1303