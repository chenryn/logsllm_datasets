(sched_yield), before waiting for a randomly sampled number of
nops. Then, the event is triggered with probability 1/2.
We consider the instances listed in Figure 6iii and Figure 6iv.
All instances start from an already-prepared state, using the top-
ranking Prime from Table 1 for both Prime+Probe and Prime+
Scope. The windowless instances (FF, PPc, PS) perform back-to-
back measurements, so the preparation phase does not need to be
repeated (indicated with /). In contrast, the windowed instances
(FR, PPwA, PPwB) comprise a measurement, a preparation phase,
and a waiting period until the end of the window. All instances run
iteratively, and they terminate either when an event is detected, or
when there was no event and the random process has terminated.
This experiment is repeated for 1 000 runs of 10 000 events for
each window size and each technique, and the global accuracy
(true positives and true negatives divided by total) is recorded. We
also record the fundamental maximal resolution (i.e., the minimal
window size that is able to contain one measurement iteration), as
well as the maximal resolution that delivers an accuracy of 95%.
Note that this micro-benchmark serves to quantify, for each
technique, the maximal probing resolution for reliable cross-core
cache event detection. It should not be interpreted as a comparison
of these techniques in a general setting, where more error sources
are at play that are not captured here (e.g., noise). However, a poor
resolution in this experiment implies a poor resolution in practice.
Also, the experiment assumes that the initial cache preparation
is already successfully performed, which may paint an optimistic
picture for windowed techniques. For instance, for the CD, the EVr
of a single unordered probe of 𝑊 lines is quite low [65]. Hence,
a windowed Prime+Probe (PPw) has lower accuracy than in this
experiment, due to false negatives incurred by the imperfect EVr, but
its temporal resolution is adequately estimated by this experiment.
601002004001000100000.50.60.70.80.91WindowSize[cycles]AccuracyFFFRPPcPPwAPPwBPS1002004001000100000.50.60.70.80.91WindowSize[cycles]AccuracyFFFRPPcPPwPSSession 11A: Attestation and Firmware Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2913Results. For both the LLC (Figure 6i) and the CD (Figure 6ii), the
resolution of Prime+Scope can be seen to tower above the other
techniques, i.e., around 70 cycles or 25ns, while correctly detecting
the majority of events (>98%). Figure 6iii and Figure 6iv indicate
the maximal resolution (both fundamentally and for 95% accuracy).
As expected, windowed techniques have poor accuracy for small
window sizes, with many events landing in blind spots (i.e., false
negative errors). This is especially apparent for Flush+Reload,
where small-window instances miss almost all events (cf. [3, 67]).
The resolution for windowless Prime+Probe (PPc) is already
fairly high (390 cycles for the LLC, and 210 cycles for the CD). In
contrast to typical applications of Prime+Probe [31, 37, 55], the
windowless paradigm decouples Prime and Probe. This permits to
optimize the Prime stage for high EVr, and Probe stage for speed.
The inflated time difference for Flush+Flush on the Cascade-
Lake server makes it more accurate than Flush+Reload for all
window sizes. However, the accuracy increases with the window
size, indicating that the Flush measurement on this platform has a
blind spot, i.e., it is not concurrent (cf. Section 3.2).
Method
PS
PP𝑃𝑆
PP𝐶𝑆𝑇
PS
PP𝑃𝑆
PP𝐶𝑆𝑇
PS
PP𝑃𝑆
PP𝐶𝑆𝑇
Stress Correct
98.24
99.42
98.72
0
1
5
79.71
83.83
81.74
78.38
82.80
81.94
Miss
1.44
0.45
1.15
2.35
0.54
0.56
2.42
0.68
0.00
Multi
0.32
0.12
0.13
17.94
15.63
17.70
19.20
16.51
18.06
Figure 7: Distribution of time slots along correct, miss and
multi categories for Prime+Scope and Prime+Probe (aver-
ages over 200 runs of more than 25 000 time slots). Stress in-
dicates the amount of stress workers, pinned to different
cores, that are active in the background. The properties of
the Prime patterns are as follows:
6.2 Susceptibility to Noise
Like Prime+Probe, Prime+Scope is susceptible to noise resulting
from activity in the targeted cache set, other than the event which
is to be monitored. This limitation is fundamental to the cache
contention leakage mechanism. It is natural to ask whether the
more precise Prime patterns for Prime+Scope make it more fragile
in the presence of noise. We explore it in the following experiment.
We consider two threads pinned to different cores of an Intel
Core i7-7700K (Kaby Lake, 16 ways), where one thread monitors the
other’s memory accesses under different levels of noise. The stress
tool is used to generate heavy memory load on one or more other
cores (e.g., as in [39]). One thread accesses a predetermined address
periodically (every 10 000 cycles), as ground truth, while the other
thread continuously monitors the cache set for events, and records
the timestamps at which the events are detected. Timestamps are
obtained using the CPU’s time stamp counter, which is synchro-
nized across cores. After execution, the collected timestamps are
analyzed to evaluate the detection accuracy of the techniques.
In the ideal case, only one event is detected in each time slot,
being the ground-truth periodic access. In the experiment, three
cases are distinguished: correct when only one event is detected, and
it was detected right after the event occurred; miss when the ground-
truth event was not detected in the time slot (false-negative error);
and multi when events were detected that did not correspond to
the ground-truth access (false-positive error). If a time slot contains
both error types, which is uncommon, it is classified as multi.
Prime+Scope (PS) is compared with two windowless Prime+
Probe instances. As indicated in Figure 7, the first one (PP𝑃𝑆) in-
herits the Prime access pattern of Prime+Scope. The second one
(PP𝐶𝑆𝑇 ) uses a custom Prime+Probe pattern, which is also obtained
with PrimeTime, but optimized for EVr instead of EVCr.
For the Prime+Probe instances, the indicated Prime is repeated
continuously and serves both as preparation (where duration is
the number of cycles needed to prepare the cache after an event)
and measurement (where precision is the number of cycles between
successive measurements in the absence of an event). Note that
Pattern
PS
PP𝑃𝑆
PP𝐶𝑆𝑇
R3_S4_P01SS2SS301230123
R2_S4_P01SS2SS301230123
R2_S1_P01
EVr
100% 99.9%
100% 99.9%
NA
100%
EVCr Duration Precision
1810
1255
1190
70
1170
700
PP𝑃𝑆 performs much more accesses than PP𝐶𝑆𝑇 , which is almost
completely hidden in the preparation stage in the shade of cache
misses, but is clearly visible in the measurement precision. As in
Figure 1ii-H, the Prime right after detection of an event is ignored,
as its execution time may still be affected by that event.
A naive implementation of Prime+Scope performs the Prime
just once for every detected event. However, suppose that the Prime
is unsuccessful in fixing the EVC, e.g., due to noise. This will blind
the following Scope operations, as they may be fast even if some
elements of the cache set have been evicted. To overcome this issue,
the Prime step is repeated when no events were detected within a
chosen period (in this experiment, roughly 12 000 cycles).
Results. For each technique and noise level, Figure 7 indicates
the distribution of time slots along correct, miss and multi rates.
This micro-benchmark provides a rough indication of how noise
translates to false-positive and false-negative errors for the different
windowless techniques. We can draw the following conclusions:
- The miss rates of Prime+Scope are slightly (a few p.p.) higher
than Prime+Probe. The main cause of such false-negative errors
are accesses during the preparation phase of the attack, which
may result in an imperfectly prepared set [11]. Hence, the ob-
served behavior is clarified by imperfect preparation affecting
the EVCr slightly more than the EVr. If high noise levels are to
be expected, Prime+Scope fares well with an upwards correction
of the Prime repetitions compared to the output of PrimeTime
(e.g., as in this experiment, where R2_* → R3_*).
- In terms of multi rates, all instances are comparable. The main
cause of such false-positive errors is noise during the measure-
ment phase, evicting the EVC. As this leads to high access laten-
cies for both Probe and Scope, this source of errors is expected
to affect Prime+Scope and Prime+Probe equally.
Session 11A: Attestation and Firmware Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2914Figure 8: Covert Channel Operation (𝑚 = 3 bits per symbol).
6.3 Cross-Core Covert Channel
To show that Prime+Scope can discern fine-grained temporal cache
activity, we build a high-capacity cross-core covert channel based
on variable-time access leakage (cf. Figure 5ii). It temporally encodes
𝑚-bit symbols by performing a memory access in one of 2𝑚 slots,
where slots may be as short as 80 processor cycles.
As a representative sample, we implement it on the LLC of a Kaby
Lake processor, and on the CD of CascadeLake-SP. For our proof-of-
concept implementation, we assume a synchronized transmitter and
receiver that have agreed on a contention set (e.g., as in [43, 44, 65]).
Figure 8 visualizes the working mechanism of the covert channel,
as well as its defining parameters (duration of preparation stage,
transmission slots, and transmitter-receiver offset). First, the re-
ceiver primes the set. Then, the transmitter sends an 𝑚-bit symbol
𝑀 by accessing a congruent line in slot number 𝑖 = 𝑀. At the same
time, the receiver scopes the set every SLOT cycles, decoding 𝑀 as
the slot number in which the scope line S is evicted.
Optimizations. We perform a few modifications to improve the
channel bandwidth. Instead of the canonical encoding, we encode
the bitstream into 𝑚-bit symbols with reflected binary Gray codes to
ensure that off-by-one symbol errors only lead to single-bit errors.
For the LLC channel, the receiver uses the Prime patterns of
Section 5.1. We find that if the transmitter flushes the line right
after accessing it, it slightly speeds up the prime for the receiver.
For the CD channel, the Prime stages consist of alternating
pointer chases (cf. Section 5.2). To amortize the latency arising
from serialization, four sets are primed simultaneously with their
accesses interleaved (e.g., as in [16]). After the combined Prime,
there are four rounds of 2𝑚 slots, where each round encodes 𝑚 bits.
Evaluation. Figure 9 gives capacity and error rate as a function
of bandwidth, and summarizes the parameters for which the LLC-
and CD-based channels obtain peak capacity. Respectively, the
capacities are 3.5 Mbps and 3.1 Mbps, which is much higher than
Prime+Probe on the LLC (e.g., 500 Kbps at 1% bit error rate [25]).
Furthermore, they are in the same order of magnitude as state-of-
the-art stateless channels without shared memory, such as Pessl
et al. [44] (DRAM row buffer contention, 2.1 Mbps capacity) and
Paccagnella et al. [43] (LLC ring contention, 4.1 Mbps capacity).
To our knowledge, the only other covert channel using the CD
is due to Yan et al. [65], with a bandwidth of 0.2 Mbps (error rate
not reported). The order-of-magnitude capacity improvement of
our channel stems from both a fast and efficient Prime pattern (cf.
Section 5.2), and the precision of Prime+Scope (cf. Section 6.1).
As the goal is to characterize the temporal precision of Prime+
Scope, we limit the study of this covert channel to synchronized
parties on idle systems. In practice, further engineering challenges
need to be overcome (e.g., as undertaken in [37–39]).
Figure 9: Covert Channel Capacities and error rates for the
Kaby Lake (KBL) and CascadeLake-SP (CXL) platform. For
the peak capacities, the configuration in the following table
are used, where PREPARE, OFFSET and SLOT are in cycles.
Platform
Core i7-7500 (KBL)
Xeon Pl. 8280 (CXL) CD
𝐶𝑆 𝑚 Capacity
3.5 Mbps
LLC 4
3
3.1 Mbps
PREPARE
1 400
4 750
OFFSET
90
125
SLOT
100
100
6.4 Side-Channel Attack on AES
We now revisit the seminal first-round known-plaintext attack on
the T-table implementation of AES [42], a standard benchmark for
cache attack techniques (e.g., [18, 25, 57]). The time precision of
Prime+Scope allows a novel attack technique against AES, based
on variable-access time leakage (cf. Figure 5ii), rather than tradi-
tional access leakage. As it can learn more information from each
encryption, much fewer traces are needed to extract the secret.
Although a windowless Prime+Probe can also absorb some of this
information, Prime+Scope requires 10-70x fewer traces. We first
give a high-level outline of the traditional attack (for details, refer
to [42, 55]). Like prior work, we attack OpenSSL 1.0.1e (or similar).
Traditional Attack. The implementation features four precom-
puted tables 𝑇 𝑒 𝑗, of 16 cache lines each. The attacker monitors
accesses to such table lines 𝑇 𝑒 𝑗 [𝑀] which, on CPUs with 64-byte
cache lines, leak the upper four bits (nibble) of every key byte 𝑘𝑖.
We implement this attack with Prime+Probe (for comparison) and
Flush+Reload (for reference), where the attacker prepares the
cache, triggers an encryption with known plaintext, and measures
afterwards. For plaintexts where ⌈𝑝𝑖⌉4 = ⌈𝑘𝑖⌉4 ⊕ 𝑀, cache line
𝑇 𝑒𝑖 mod 4[𝑀] is accessed in the first round, and hence, in 100% of
encryptions. For other 𝑝𝑖, it is accessed in 92.5% of encryptions, so
each monitored 𝑇 𝑒 𝑗 [𝑀] carries information in 7.5% of encryptions.
Variable-Time Access: Prime+Scope. Consider the code snippet in
Figure 10. Indeed, not only the access to a table encodes information,
but also the encryption round in which it happens. We now show
that, through its time precision, Prime+Scope is able to capture such
void AES_encrypt(...) {
... // s0-s3 contain p_i xor k_i
// round 1:
t0 = Te0[s0>>24] ^ Te1[(s1>>16) & 0xff]
1 AES_encrypt
2
Te0/Te1/Te2/Te3
^ Te2[(s2>>8) & 0xff] ^ Te3[s3 & 0xff] ^ rk[4];
t1 = ... ; t2 = ...; t3 = ...; // similar to t0
... // rounds 2-10 (similar to round 1)
Figure 10: Variable-time access leakage for AES
1.522.533.544.551234Bandwidth(Mbps)Capacity(Mbps)Capacity(KBL)Capacity(CXL)00.050.10.150.2ErrorRateBitErrorRate(KBL)BitErrorRate(CXL)Session 11A: Attestation and Firmware Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2915with as many as 100 000 traces, which may indicate that the timing
differences are too small to be distinguished by Prime+Probe.
6.5 Finding Congruent Addresses
Cache contention attacks require the adversary to find eviction
sets, i.e., sets of congruent addresses in the target cache. This prac-
tical challenge has been investigated thoroughly [18, 31, 37, 60, 65].
However, the principles underlying Prime+Scope enable an effi-
cient congruence test, resulting in a faster and simpler routine that,
counter-intuitively, requires fewer platform-specific parameters.
Algorithm: LLC. The foundation of the proposed LLC eviction
set construction routine is given in Algorithm 2. It repeatedly mea-
sures the access latency of the TARGET address and, between each
measurement, accesses a guess. As TARGET is continuously accessed,
it is always served from the L1 cache, which does not influence its
LLC replacement state. Guesses that turn out to be congruent with
the TARGET are installed in the LLC, and each time this happens,
the EVC in the LLC changes. After enough congruent guesses, the
TARGET becomes the EVC. The next congruent guess then evicts
TARGET from the LLC and, due to the inclusion property, also from
the private caches. Therefore, the next access to TARGET is slow,
indicating the congruence of the latest guess. The attacker repeats
this procedure until she has obtained enough congruent addresses.
To speed up the routine, between lines 4 and 5 in Algorithm 2, we