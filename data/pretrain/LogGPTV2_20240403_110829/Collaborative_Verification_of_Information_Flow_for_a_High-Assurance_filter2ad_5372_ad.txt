one of the user’s feeds is updated, so VIBRATE is listed
in the manifest ﬁle as expected. However, the app’s user
would not expect the app to cause random vibrations, so
RANDOM→VIBRATE is malicious.
Table 3: Results from the annotation burden experiment.
App
LOC (min.) ump. src.+sink=total ratio
Time Ass-
Annotations
in GPS 3,
3.6 Flows using parameterized permissions
For 10 apps, the malicious information ﬂow is apparent
only via use of parameterized permissions (Sect. 2.2.1).
For example,
the location data should
only ﬂow to maps.google.com, but
it also ﬂows to
maps.google-cc.com. To express this, the ﬂow policy lists
LOCATION→INTERNET(“maps.google.com”) but not LOCATION
→INTERNET(“maps.google-cc.com”). Another app, Geo-
caching, should only send data from speciﬁc geocaching
NFC tags to the server, but it collects all NFC tags in
range and sends them to the server, NFC(“*”)→INTERNET.
For two of these apps, PGP Encryption 2 and Password
Saver, the leaked information is allowed to ﬂow to the
sensitive sink, but only if it is encrypted ﬁrst. IFC cannot
yet express this property, but Sect. 3.15 describes how to
extend it to catch this sort of vulnerability.
3.7 Malware not related to information ﬂow
The malware in 10 out of the 57 malicious applications is
not related to information ﬂow. These applications neither
exhibit unjustiﬁed permissions nor reveal an unjustiﬁed
or exploited information ﬂow. These apps implement
types of attacks that are out of the scope of IFC. For
example, Backup transposes digits in a phone number
during backup. This is a functional correctness error,
which IFC does not address. In a high-assurance app store,
IFC would be used with complementary tools designed
to ﬁnd malware besides exploited information ﬂow.
3.8 Bugdoors
In 8 apps, our tools found a bugdoor (undesired, ex-
ploitable functionality) that the Red Team was unaware of.
Even though the Red Team had written and/or modiﬁed
the app before presenting it to us for analysis, they had
not noticed these.
GPS 1 passes the device ID as a waypoint to the remote
server. This allows the remote server to correlate location
to speciﬁc devices and to other information collected
using the device ID.
Password Saver saves unencrypted passwords in shared
preferences, where they are accessible to other applica-
tions on the device.
Furthermore, 6 apps exﬁltrated sensitive data to the log,
which Android does not require a permission to write. It
does, however, require a permission in our ﬁner-grained
permission system (see Sect. 2.2). Consequently, IFC
reported an information ﬂow violation.
6 + 5 = 11 .12 6%
20 .22
CameraTest
92
Shares Pictures† 141
12 + 0 = 12 .09 4%
10 .07
9 + 0 = 9 .05 3%
10 .05
183
BusinessCard
7 + 0 = 7 .01 1%
40 .08
520
Calculator 3
66 + 0 = 66 .11 6%
625 300 .48
Dynalogin
51 + 3 = 54 .05 3%
1098 295 .27
TeaTimer
27 + 18 = 45 .04 3%
1108 120 .11
FourTrack
1322 180 .14
41 + 26 = 67 .05 4%
RingyDingy
1360 185 .14 11 68 + 44 =112 .08 4%
VoiceNotify
33 + 35 = 68 .05 3%
1441 240 .17
Sky
1547 165 .11
71 + 58 =129 .08 5%
Pedometer
1
0
1
0
0
7
0
2
5
0
Total
9437 1565 .17 26 391+189=580 .06 4%
Boldfaced numbers (time, annotations) are per line of code.
“Assump.” is trusted assumptions. Annotation ratio compares
the number of annotations written to how many could have been
written — the number of uses of types in the app’s source code.
Throughout, lines of code (generated using David A. Wheeler’s
“SLOCCount”) omit whitespace and comment lines.
†Malicious applications
3.9 Control team results
For the third and ﬁfth batches of applications, our spon-
sor hired a control team to evaluate the applications and
search for malware. The control team consisted of 4 PhD
students with, on average, 11 years of Java experience and
.5 years of Android experience — very similar to our team.
The control team used both static and dynamic analysis
tools, including Androguard, Eclipse, and emulators.
For the third batch of apps, the control team took an av-
erage of 9.5 hours per application to declare it malicious
or benign, and their answer was right 60% of the time.
Our team, using IFC plus simple tools that search for sus-
picious code, spent 42 minutes on average per application
and correctly classiﬁed 80% of the applications.
For the ﬁfth batch of apps, the control team took an av-
erage of 2.3 hours per application and correctly classiﬁed
63% of the apps. Our team spent 1.25 hours per app on
average and correctly classiﬁed 75% of the apps.
3.10 Annotation burden
The IFC veriﬁcation methodology and toolset provide
guarantees, but at a cost: the developer must write source
code annotations that express the relevant information
ﬂows.
In order to estimate this cost, ﬁve of the authors of this
paper annotated 11 applications. 1 app was a malicious
app written by the Red Teams and 10 apps were benign
10
apps written by third-party developers or the Red Teams.
Each person was given an unannotated application and a
ﬂow policy. The person fully annotated the application
even if they found malware, in which case they suppressed
a warning and continued the task. The annotator had
never seen the application before, so the vast majority of
their time was spent reverse-engineering the application
— work that would not be necessary for the application
vendor.
Table 3 shows the results. On average, the annotators
annotated 6 lines of code per minute, which was primarily
the effort to understand the code. This compares favor-
ably with industry-standard averages of about 20 lines of
delivered code per day [4, 29, 42, 22].
The annotated code contained on average one annota-
tion per 16 lines of code. This compares favorably with
the annotation burden for Jif, another information-ﬂow
system for Java. In three studies over a 6-year period,
Jif required one annotation per 4–9 lines of code [50],
one annotation per 3 lines [51], and one annotation per 4
lines [6]. In our case studies, the annotator wrote an anno-
tation in 4% of the places an annotation could have been
written; the other locations were defaulted or inferred.
The number of annotations per application is not corre-
lated with the number of lines of code nor the number of
possible annotations. Rather, the number of annotations
is dependent on how, and how much, information ﬂows
through the code. When information ﬂow is contained
within procedures, type inference reduces the number of
annotations required (Sect. 2.6.1).
3.11 Auditing burden
Another cost in the use of a static tool is the need to exam-
ine warnings to determine which ones are false positives.
This cost falls on the developer, then again on the audi-
tor. We wished to determine the cost to the app store of
approving an app, which requires auditing the ﬂow policy
and each trusted assumption.
Two of the authors of this paper acted as app store
auditors. They reviewed the applications developed in the
Annotation Burden experiment from the previous section.
The auditors had never before seen the applications that
they reviewed, and they did not know whether they were
malware. The review was split into two phases: a review
of the app description and policy, then a review of the
trusted assumptions and conditionals in the source code.
This is exactly the same workﬂow as an app store auditor.
Table 4 summarizes the results.
The ﬁrst part of the review ensures that the description
of the app matches the ﬂow policy. An auditor begins by
reading the app description and writing a ﬂow policy; then
the auditor compares that to the submitted ﬂow policy. If
there is any difference, the developer must modify the
11
Table 4: Results from the collaborative app store experiment.
Accepted
App Name
Reviewed
Review
time (min.) Assump. Cond.
CameraTest
Shares Pictures†
BusinessCard
Calculator 3
Dynalogin
TeaTimer
FourTrack
RingyDingy
VoiceNotify
Sky
Pedometer
26
5
11
11
10
50
61
20
35
25
15
Total
269
.28
.04
.06
.02
.02
.05
.06
.02
.03
.02
.01
.03
1
0
1
0
0
7
0
2
11
5
0
27
0% Accept
0
0
0% Reject
1 14% Accept
3
5% Accept
10 37% Accept
20 22% Accept
11 14% Accept
11
9% Accept
73 47% Accept
19 15% Accept
65 57% Accept
213 27%
Boldfaced times are per line of code. All trusted assumptions
were reviewed. The Reviewed Conditions column gives the num-
ber of reviewed conditions and the percentage of all conditional
sinks that needed to be reviewed. †Malicious applications
description or ﬂow policy. The policy review took 35%
of total auditing time.
The second part of the review ensures that all trusted
assumptions and indirect information ﬂows are valid.
The auditor ﬁrst reviewed each suppressed warning its
developer-written justiﬁcation. Only CameraTest had one
rejected justiﬁcation, which the developer rectiﬁed in a re-
submission. The other justiﬁcations were accepted by the
auditors. Then, the auditors investigated the information
ﬂow into conditional sinks, ensuring that any dependency
is benevolent.
After the experiment, auditors mentioned that there
were many unexpected ﬂows, which ended up being nec-
essary. Also, they wanted clear guidelines to accept or
reject ﬂow policies. We believe that both concerns will be
resolved as auditors and app stores get more experience;
this was their ﬁrst time to audit apps.
We have not evaluated the effort of analyzing an up-
date to an existing app, but this should also be low. An
update can re-use the explicit ﬂow policy speciﬁcation,
annotations, and justiﬁcations for trusted assumptions) of
previous versions.
3.12 Learnability
IFC integrates smoothly with Java and re-uses type system
concepts familiar to programmers. Nonetheless, learning
about information ﬂow, or learning our toolset, may prove
a barrier to some programmers. The programmers in the
study of Sect. 3.10 were already familiar with Android
and IFC. We wished to determine how difﬁcult it is to
come up to speed on IFC.
We conducted a study involving 32 third-year under-
graduate students enrolled in an introductory compilers
class. Most of the students had no previous experience
with Android. They received a two-hour presentation,
then worked in pairs to annotate an app of 1000–1500
lines. The apps came from the f-droid.org catalog; we
do not have access to the source code of most apps in the
Google Play Store.
The students’ task was to learn Android, information
ﬂow theory, and the IFC toolset, then to reverse-engineer
the app and to annotate it so that IFC issues no warnings.
On average the task required 15 hours. The students
reported that the ﬁrst annotations were the most time-
consuming because they were still learning to understand
IFC; after that the task was easier.
3.13 Lessons learned
This section states a few lessons we learned during our