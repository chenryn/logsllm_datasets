\- java log4j： log4j默认格式的日志
**时间戳顺序**
识别时间戳的顺序如下
1\. agent识别到的时间戳
2\. 用"时间戳解析"解析出来的时间戳
3\. agent事件源时间戳
4\. collector收到的时间戳
5\. 当前时间戳
  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  日志类型     前置条件                               操作步骤                                           结果
  ------------ -------------------------------------- -------------------------------------------------- ----------------------------------------------------------------------
  Apache日志   1，日志分析平台搭建完成，正常启动；\   使用文件方式将apache样本数据采集到日志分析平台。   在日志分析平台的查询界面，输入logtype:apache进行查询能够检索出数据。
               2，日志分析平台安装heka agent；\                                                          
               3，准备apache样本数据。                                                                   
  Nginx日志    1，日志分析平台搭建完成，正常启动；\   使用文件方式将nginx样本数据采集到日志分析平台。    在日志分析平台的查询界面，输入logtype:nginx进行查询能够检索出数据
               2，日志分析平台安装heka agent；\                                                          
               3，准备nginx样本数据。                                                                    
  Log4j日志    1，日志分析平台搭建完成，正常启动；\   使用文件方式将LOG4j样本数据采集到日志分析平台。    在日志分析平台的查询界面，输入logtype:log4j进行查询能够检索出数据
               2，日志分析平台安装heka agent；\                                                          
               3，准备LOG4j样本数据。                                                                    
  JSON日志     1，日志分析平台搭建完成，正常启动；\   使用文件方式将LOG4j样本数据采集到日志分析平台。    在日志分析平台的查询界面，输入logtype:json进行查询能够检索出数据
               2，日志分析平台安装heka agent；\                                                          
               3，准备json样本数据。                                                                     
  Linux日志    1，日志分析平台搭建完成，正常启动；\   使用文件方式将linux                                在日志分析平台的查询界面，输入linux_secure进行查询能够检索出数据
               2，日志分析平台安装heka agent；\       secure样本数据采集到日志分析平台。                 
               3，准备linux secure样本数据。                                                             
  MySQL日志    1，日志分析平台搭建完成，正常启动；\   使用文件方式将mysql样本数据采集到日志分析平台。    在日志分析平台的查询界面，输入mysql进行查询能够检索出数据
               2，日志分析平台安装heka agent；\                                                          
               3，准备mysql样本数据。                                                                    
  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
例如支持自动解析的apache日志格式如下：
%h %l %u %t \\\"%r\\\" %\>s %b
%h %l %u %t \\\"%r\\\" %\>s %b \\\"%{Referer}i\\\"
\\\"%{User-agent}i\\\"
%h %l %u %t \\\"%r\\\" %\>s %b \\\"%{Referer}i\\\"
\\\"%{User-agent}i\\\" \\\"%{X-Forwarded-For}i\\\"
其中各项配置的含义如下：
%b or %B - Size
%h RemoteIPOrHost
%l - RemoteLogname
%r - Request
%\>s - HttpStatusCode
%t - eventTime
%{Referer}i - Referer
%{User-agent}i - UserAgent
%{X-Forwarded-For}i - XForwardedFor
自动识别Apache的error日志，通常情况下日志格式为:
\[Fri Jul 05 21:28:24 2013\] \[error\] child process 1245 still did not
exit, sending a SIGKILL
自动解析出如下字段:
timestamp, loglevel, message 等
> **自定义日志解析能力试验**
**正则解析：**
原始日志:
192.168.1.139 - - \[24/Jan/2015:17:03:49 +0800\] \"GET
/api/v0/search/fields/?field=tag&filters=&order=desc&page=1&query=\*&size=50&sourcegroup=all&sourcegroupCn=%E6%89%80%E6%9C%89%E6%97%A5%E5%BF%97&time_range=-2d,now&type=fields
HTTP/1.1\" 200 363
\"http://alltest.rizhiyi.com/search/?query=\*&time_range=-2d%2Cnow&order=desc&size=20&page=1&sourcegroup=all&type=timeline&\_t=1422088066859&title=%E9%BB%98%E8%AE%A4&index=0\"
\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:35.0) Gecko/20100101
Firefox/35.0\"
可以采用如下配置：
%{ApcClientIP} %{ApcIdent} %{ApcUser} %{ApcTimestamp} %{ApcRequest}
%{ApcStatus} %{ApcRespLen} %{ApcReferer} %{ApcUa}
![http://www.rizhiyi.cn/img/rzy/doc/howtouse/type1.png](media/image2.png){width="6.131944444444445in"
height="2.2777777777777777in"}
**KeyValue分解：**
解析明显的KV字符，输入request_query字段为：
field=tag&filters=&order=desc&page=1&query=\*&size=50&sourcegroup=all&sourcegroupCn=%E6%89%80%E6%9C%89%E6%97%A5%E5%BF%97&time_range=-2d,now&type=fields
即添加解析规则：KeyValue分解，source字段选择request_query，定义字段间分隔符为&，定义k-v分隔符为=
![http://www.rizhiyi.cn/img/rzy/doc/howtouse/type2.png](media/image3.png){width="5.930555555555555in"
height="2.3402777777777777in"}
> **结语**
非结构化机器数据范式化处理是大数据技术的基础，是实现海量数据实时检索和统计分析的前提。本文主要对大数据中的非结构化机器数据的范式处理技术进行分析和探讨，并对自动解析和自定义解析两种方式做出实验验证，上述技术已在机器数据搜索分析平台成功实现，并在金融、电力、通信运营商等行业得到应用。
参考文献
\[1\]郎波 面向大数据的非结构化数据管理平台关键技术\[J\] 信息技术与标准化
2013,10
\[2\]冯宇 非结构化数据管理平台研究与建设\[J\] 电力信息化 2016,02
\[3\]黄海峰 2013年绿色通信呈现四大发展趋势\[J\] 通信世界 2013,26
\[4\]陈氢 基于信息链的跨部门政府信息共享架构研究\[J\] 情报杂志 2013,11