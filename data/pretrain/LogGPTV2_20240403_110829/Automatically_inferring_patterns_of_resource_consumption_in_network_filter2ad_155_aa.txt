# Automatically Inferring Patterns of Resource Consumption in Network Traffic

**Authors:**
- Cristian Estan
- Stefan Savage
- George Varghese

**Affiliation:**
Computer Science and Engineering Department, University of California San Diego

**Contact:**
cestan, savage, PI:EMAIL

## Abstract
The Internet service model emphasizes flexibility, allowing any node to send any type of traffic at any time. While this design has facilitated the emergence of new applications and usage models, it also presents significant challenges for network management. This paper introduces a novel method for traffic characterization that automatically groups traffic into minimal clusters of conspicuous consumption. Unlike traditional static analyses that focus on specific flows, applications, or network-to-network traffic matrices, our approach dynamically generates hybrid traffic definitions that align with actual usage patterns. For instance, instead of reporting five hundred small flows, the amount of TCP traffic to port 80, or the "top ten hosts," our method might reveal that a certain percentage of traffic is generated by TCP connections between AOL clients and a particular group of Web servers. Additionally, our technique can automatically classify new traffic patterns, such as network worms or peer-to-peer applications, without prior knowledge of their structure. We present a series of algorithms for constructing these traffic clusters and minimizing their representation. We also describe the design of our prototype system, AutoFocus, and our experiences using it to discover dominant and unusual modes of usage on several production networks.

## Categories and Subject Descriptors
C.2.3 [Computer-Communication Networks]: Network Operations—Network monitoring

## Keywords
Traffic measurement, Network monitoring, Data mining

## 1. Introduction
The Internet is a dynamic and ever-evolving environment. Flash crowds, streaming media, content delivery networks (CDNs), denial of service (DoS) attacks, network worms, and peer-to-peer applications are just a few of the factors that shape today's network traffic. Each year, new applications and usage models emerge, leading to new communication patterns. This flexibility is a hallmark of the Internet architecture and a key factor in its success. However, it also poses serious challenges for network management. Unlike traditional voice networks, which are built around a single high-level abstraction for application data transfer ("calls"), IP-based networks require managers to infer the type of traffic and its relationship to applications and users. To understand and react to changes in network usage, a network manager must first analyze the bit patterns in individual packets, extract an appropriate traffic model, and then reconfigure network elements to recognize that model.

To make this process feasible, managers often use a standard set of predefined patterns to identify well-known aspects of network traffic. For example, they might classify traffic based on IP header fields such as Protocol and SrcPort. Such an analysis might determine that 90% of traffic uses the TCP protocol, 75% of TCP traffic is for HTTP, 10% is for SMTP, 5% for FTP, and so on. Similarly, to identify individual conversations between pairs of hosts, the five-tuple (SrcIP, DstIP, Protocol, SrcPort, DstPort) is used to define a "flow" abstraction. These types of analyses, exemplified by popular monitoring tools like FlowScan and Cisco’s FlowAnalyzer, are a staple of modern network management. However, they have two significant limitations: insufficient dimensionality and excessive detail.

While network traffic can be characterized by many different criteria, it is easiest to aggregate traffic along one dimension at a time. Unfortunately, this approach inevitably loses any interesting, but orthogonal, structure. For example, by aggregating traffic according to an application-oriented view (i.e., Protocol and SrcPort), a network manager might conclude that peer-to-peer file-sharing applications are widely used, when in fact a small set of hosts are responsible for most of the file-sharing traffic. While the network manager can expose this structure by using finer-grained representations, such as flows, she then must manage the excessive detail contained in such a representation. Instead of identifying the file-sharing traffic concisely, the flow-oriented view decomposes it into thousands of individual network transfers.

Consequently, network managers spend considerable time manually "hunting for needles" in their data, trying to understand the real and significant sources of traffic in their network and which components of usage are changing over time. This problem is exacerbated when there is a pressing need to understand and respond to sudden traffic spikes, such as those caused by network worms or DoS attacks. Moreover, automated techniques for addressing these issues, such as network pushback, also require a means to identify malicious aggregates.

Our work aims to automate these tasks, and this paper makes four contributions:
1. In Section 2, we motivate the need for a new approach to traffic monitoring that can automatically classify traffic into appropriate multi-dimensional clusters.
2. We define a concrete and practical instance of such traffic clusters and describe a set of operations for reducing their size and increasing their utility.
3. In Section 3, we describe and evaluate algorithms for cluster construction and for implementing the key operations described in Section 2.
4. In Section 4, we describe AutoFocus, our prototype system, and in Section 5, we describe our experience using it on several production networks. At the end of the paper, we relate our efforts to previous work and summarize our results.

## 2. Multi-Dimensional Traffic Clusters
The goal of every traffic analysis method is to provide the human operator with improved understanding. However, there is an inherent contradiction between the level of detail provided and the capacity of humans to absorb information: more detail can lead to a deeper understanding but makes the report harder to read. The simplest solution is to report only the largest flows, so-called "top ten" reports, but this approach has a serious flaw: aggregates made up of many small flows can be important, but each individual flow may not be large. For example, a busy Web server might generate the bulk of the traffic, but since all of its flows are relatively small, the "top ten" report might only contain transfers from a nearby FTP server hosting a few large files.

Another solution is to aggregate individual flows into a common category (e.g., by source or destination port, source or destination address, prefix, or Autonomous System number). However, if we choose the wrong dimension to aggregate over, we may miss the interesting characteristics of the traffic. For example, if we aggregate traffic by port number, we may miss the importance of traffic generated by a denial-of-service attack using random port numbers. In this case, aggregating traffic by destination address would likely be a more useful approach.

In some cases, significant information is hidden by aggregating on any single field but revealed by aggregating according to a combination of fields (multi-dimensional aggregates). For example, aggregating traffic by IP address might identify a set of popular servers, and aggregating traffic by port might identify popular applications, but to identify which server generates which kind of traffic requires aggregating according to two fields simultaneously.

Our solution is to focus on dynamically-defined traffic clusters instead of individual flows or other predefined aggregates. Our aim is to define the clusters so that any meaningful aggregate of individual flows is a traffic cluster. For example, a single cluster might represent all TCP client traffic originating from America Online’s network destined for a cluster of replicated Web servers on Google’s network. Another cluster might represent significant amounts of traffic originating from a host infected by the Sapphire worm destined to random addresses at UDP port 1434. While the goal is attractive, automatically building such clusters is challenging. In practice, creating effective clusters requires balancing three key requirements:

- **Dimensionality**: The dimensionality of the problem is defined by how many distinct properties are considered in constructing a traffic cluster. If there is too little dimensionality, important traffic categories can be masked; if there is too much, the computational overhead of computing cluster combinations can become infeasible.
- **Detail**: While multi-dimensional clusters allow us to capture the structure of the traffic being analyzed, this does nothing to reduce the magnitude of data that must be evaluated. One can easily create thousands of clusters from a traffic trace. To make such data useful, a clustering algorithm must carefully prune this set to remove "unimportant" clusters and trade off the loss in detail for corresponding gains in conciseness.
- **Utility**: Network managers are not merely passive observers of traffic but active parties who attempt to control and react to changes in traffic load and usage. Therefore, while we could construct traffic clusters using arbitrary combinations of packet header bit patterns, it is far more useful to restrict our choices to header fields that are already well-classified by network hardware and can therefore be acted upon.

### 2.1 Defining Traffic Clusters
Based on these principles, we define our traffic clusters in terms of the five fields typically used to define a fine-grained flow: source IP address, destination IP address, protocol, source port, and destination port. Unlike individual flows defined by unique values for each of these fields, clusters are defined by sets of values for each of these fields. These sets can contain a single value, all possible values (denoted by *), or restricted subsets of possible values.

Evaluating all possible subsets of the values for each field would make the problem of finding all large clusters unnecessarily difficult. Instead, we use the natural hierarchies that exist for each field. For IP addresses, a cluster can be defined by prefixes of length from 8 to 32 (for individual IP addresses) or (*) for all IP addresses. For port numbers, clusters can be defined by a particular port number (e.g., port 80) or the set of all possible values (*). Because well-known ports statically allocated for services are below 1024 and ephemeral ports allocated on-demand to clients are above 1023, the set of high (> 1023) port numbers and that of low (< 1024) ones can also define clusters. Finally, the protocol field can take on exact values or (*).

For example, the cluster defined as (SrcIP=10.8.200.3, DstIP=*, Proto=TCP, SrcPort=80, DstPort=*) represents Web traffic from the server with address 10.8.200.3. The cluster (SrcIP=*, DstIP=172.27.0.0/16, Proto=TCP, SrcPort=low, DstPort=high) represents TCP traffic coming from low ports and going to high ports destined to a certain prefix. Finally, (SrcIP=*, DstIP=*, Proto=ICMP, SrcPort=*, DstPort=*) represents all ICMP traffic. Notice that the first two clusters overlap with each other, while the third cluster is unique.

There are many ways to further generalize the definition of traffic clusters. For example, we could define hierarchies based on Autonomous System number, integer ranges of port numbers, or arbitrary user-defined categories (e.g., Universities, Broadband Access, Data Centers, etc.). We could also employ heuristics such as those for identifying passive FTP and Napster traffic (that use random ports) in [14]. While these additions may provide greater value in some settings, they do not require any fundamental changes in our approach, merely a different set of aggregation criteria when constructing clusters. For the remainder of this paper, we restrict our discussion to the "vanilla" cluster definitions we have described previously.

There are three advantages to this cluster definition:
1. It is sufficiently general to capture much of the usage structure in existing applications and networks.
2. It is consistent with current packet classifiers [8], allowing a manager to apply controls, such as policy routing and hardware rate limiting, to the clusters we dynamically identify.
3. It allows a simple, visually appealing rule-based display of clusters (Section 4).
4. Initial results on several distinct networks (Section 5) indicate that clusters defined in this way do identify interesting resource consumption patterns that managers care about.

Our definition of clusters satisfies two of the requirements: the need for multi-dimensional clusters (dimensionality) and field selection constrained by existing field hierarchies (utility). However, satisfying the remaining requirement, reducing detail, requires significant additional effort.

### 2.2 Operations on Traffic Clusters
A traffic report is a list of clusters presented to a manager. Even restricting ourselves to IP prefixes and very simple port ranges, there is an exponential number of raw clusters. There are approximately \(2^{33}\) possible source IP prefixes alone! The first step in reducing this onslaught of data is to restrict the report to only include high-volume clusters, where volume may be defined as the number of bytes or the number of packets contained in the cluster.