title:Automatically inferring patterns of resource consumption in network
traffic
author:Cristian Estan and
Stefan Savage and
George Varghese
Automatically Inferring Patterns of Resource Consumption
in Network Trafﬁc
Cristian Estan, Stefan Savage, George Varghese
Computer Science and Engineering Department
University of California San Diego
cestan,savage,PI:EMAIL
ABSTRACT
The Internet service model emphasizes ﬂexibility – any node
can send any type of traﬃc at any time. While this design
has allowed new applications and usage models to ﬂourish,
it also makes the job of network management signiﬁcantly
more challenging. This paper describes a new method of
traﬃc characterization that automatically groups traﬃc into
minimal clusters of conspicuous consumption. Rather than
providing a static analysis specialized to capture ﬂows, ap-
plications, or network-to-network traﬃc matrices, our ap-
proach dynamically produces hybrid traﬃc deﬁnitions that
match the underlying usage. For example, rather than re-
port ﬁve hundred small ﬂows, or the amount of TCP traﬃc
to port 80, or the “top ten hosts”, our method might reveal
that a certain percent of traﬃc was used by TCP connec-
tions between AOL clients and a particular group of Web
servers. Similarly, our technique can be used to automat-
ically classify new traﬃc patterns, such as network worms
or peer-to-peer applications, without knowing the structure
of such traﬃc a priori. We describe a series of algorithms
for constructing these traﬃc clusters and minimizing their
representation. In addition, we describe the design of our
prototype system, AutoFocus and our experiences using it
to discover the dominant and unusual modes of usage on
several diﬀerent production networks.
Categories and Subject Descriptors
C.2.3 [Computer-Communication Networks]: Network
Operations—Network monitoring
Keywords
Traﬃc measurement, Network monitoring, Data mining
1.
INTRODUCTION
The Internet is a moving target. Flash crowds, stream-
ing media, CDNs, denial of service (DoS) attacks, network
worms, peer-to-peer applications – these are but a few of the
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’03, August 25–29, 2003, Karlsruhe, Germany.
Copyright 2003 ACM 1-58113-735-4/03/0008 ...$5.00.
forces that shape traﬃc on today’s networks. Each year, new
applications and usage models emerge, and from these arise
new communications patterns. This ﬂexibility is a hallmark
of the Internet architecture and can be credited with much
of the Internet’s success. At the same time, this quality
also brings serious challenges for network management. Un-
like the traditional voice networks, which are built around
a single high-level abstraction for application data transfer
(“calls”), managers of IP-based networks are forced to in-
fer the type of traﬃc and how it relates to applications and
users. Consequently, to understand and react to changes in
network usage, a network manager must ﬁrst analyze the bit
patterns in individual packets, extract an appropriate traﬃc
model and then reconﬁgure network elements to recognize
that model appropriately.
To make this process feasible in practice, managers use a
standard set of pre-deﬁned patterns to identify well-known
aspects of network traﬃc. For example, network managers
frequently construct a model of application usage by clas-
sifying traﬃc according to the IP header ﬁelds: Protocol
and SrcPort. Such an analysis might determine that 90 per-
cent of traﬃc uses the TCP protocol, 75 percent of TCP
traﬃc is for the HTTP service, 10 percent is for SMTP, 5
percent for FTP and so on. Similarly, to identify individ-
ual conversations between pairs of hosts, the ﬁve tuple (Sr-
cIP, DstIP, Protocol, SrcPort, DstPort), is used to impart
a “ﬂow” abstraction on traﬃc. These kinds of analyses,
exempliﬁed by popular monitoring tools such as FlowScan,
and Cisco’s FlowAnalyzer, are a staple of modern network
management [14]. However, they have two signiﬁcant lim-
insuﬃcient dimensionality
itations when used in practice:
and excessive detail.
While network traﬃc may be characterized by many dif-
ferent criteria, it is easiest to aggregate traﬃc along one
dimension at a time. Unfortunately, by aggregating traﬃc
along any single dimension, the network manager inevitably
loses any interesting, but orthogonal, structure. For ex-
ample, by aggregating traﬃc according to an application-
oriented view (i.e. Protocol and SrcPort), a network man-
ager might conclude that peer-to-peer ﬁle sharing applica-
tions are in wide use, when in fact a small set of hosts are
responsible for most of the ﬁle sharing traﬃc [15]. While the
network manager can expose this structure by using ﬁner-
grained representations, such as ﬂows, she then must man-
age the excessive detail contained in such a representation.
Rather than identifying the ﬁle-sharing traﬃc concisely, the
ﬂow-oriented view decomposes it into thousands of individ-
ual network transfers.
Consequently, network managers spend considerable time
manually “hunting for needles” in their data – trying to un-
derstand what are the real and signiﬁcant sources of traﬃc in
their network and which components of usage are changing
over time. This problem is only exacerbated when there is
a pressing need to understand and respond to sudden traﬃc
spikes such as network worms or denial-of-service attacks.
Moreover, automated techniques for addressing these issues
– such as network pushback [11] – also require a means to
identify malicious aggregates.
The focus of our work is to help automate these tasks
and this paper makes four contributions in this direction.
First, in Section 2 we motivate the need for a new approach
to traﬃc monitoring that can automatically classify traﬃc
into appropriate multi-dimensional clusters. We deﬁne a
concrete and practical instance of such traﬃc clusters and
describe a set of operations for reducing their size and in-
creasing their utility. Based on this deﬁnition, Section 3 de-
scribes and evaluates algorithms for cluster construction and
for implementing the key operations described in Section 2.
Finally, in Section 4 we describe AutoFocus, our prototype
system, and in Section 5 we describe our experience using
it on several production networks. At the end of our paper,
we relate our eﬀorts to previous work and then summarize
our results.
2. MULTI-DIMENSIONAL TRAFFIC
CLUSTERS
While the goal of every traﬃc analysis method is to em-
power the human operator with improved understanding,
there is an inherent contradiction between the level of detail
provided and the capacity of humans to absorb information:
more detail can lead to a deeper understanding but makes
the report harder to read – at one extreme is a bandwidth
meter, at the other extreme are raw packet traces. The sim-
plest solution is to report only the largest ﬂows, so-called
“top ten” reports, but this approach has a serious ﬂaw: ag-
gregates made up of many small ﬂows can be important,
but each individual ﬂow may not be large. For example, a
busy Web server might generate the bulk of the traﬃc, but
since all of its ﬂows are relatively small, the “top ten” re-
port might only contain transfers from a nearby FTP server
hosting a few large ﬁles.
Another solution is to aggregate the individual ﬂows into a
common category (e.g. by source or destination port, source
or destination address, preﬁx or Autonomous System num-
ber). However, if we chose the wrong dimension to aggregate
over then we may miss the interesting characteristics of the
traﬃc. For example, if we aggregate traﬃc by port num-
ber, we may miss the importance of traﬃc generated by a
denial-of-service attack using random port numbers. In this
case, aggregating traﬃc by destination address would likely
be a more useful approach.
However, in some cases there is signiﬁcant information
that is hidden by aggregating on any single ﬁeld, but is re-
vealed by aggregating according to a combination of ﬁelds
(multi-dimensional aggregates). For example, aggregating
traﬃc by IP address might identify a set of popular servers
and aggregating traﬃc by port might identify popular ap-
plications, but to identify which server generates which kind
of traﬃc requires aggregating according to two ﬁelds simul-
taneously.
Our way out of this impasse is to focus on dynamically-
deﬁned traﬃc clusters instead of individual ﬂows or other
predeﬁned aggregates. Our aim is to deﬁne the clusters so
that any meaningful aggregate of individual ﬂows is a traf-
ﬁc cluster. For example, a single cluster might represent all
TCP client traﬃc originating from America Online’s net-
work destined for a cluster of replicated Web servers on
Google’s network. Another cluster might represent signif-
icant amounts of traﬃc originating from a host infected by
the Sapphire worm destined to random addresses at UDP
port 1434. While the goal is clearly attractive, automati-
cally building such clusters is quite challenging. In practice,
creating eﬀective clusters requires balancing three key re-
quirements:
• Dimensionality. The dimensionality of the problem
is deﬁned by how many distinct properties are consid-
ered in constructing a traﬃc cluster.
If there is too
little dimensionality then important traﬃc categories
can be masked, while if there is too much, the compu-
tational overhead of computing cluster combinations
can become infeasible.
• Detail. While multi-dimensional clusters allow us to
capture the structure of the traﬃc being analyzed, this
does nothing to reduce the magnitude of data that
must be evaluated – one can easily create thousands of
clusters from a traﬃc trace. To make such data useful,
a clustering algorithm must carefully prune this set to
remove “unimportant” clusters and tradeoﬀ the loss in
detail for corresponding gains in conciseness.
• Utility. In the end, network managers are not merely
passive observers of traﬃc, but are active parties who
attempt to control and react to changes in traﬃc load
and usage. Therefore, while we could construct traﬃc
clusters using arbitrary combinations of packet header
bit patterns, it is far more useful to restrict our choices
to header ﬁelds that are already well-classiﬁed by net-
work hardware and can therefore be acted upon.
2.1 Deﬁning Trafﬁc Clusters
Based on these principles, we deﬁne our traﬃc clusters in
terms of the ﬁve ﬁelds typically used to deﬁne a ﬁne-grained
ﬂow: source IP address, destination IP address, protocol,
source port and destination port. Unlike individual ﬂows
deﬁned by unique values for each of these ﬁelds, clusters are
deﬁned by sets of values for each of these ﬁelds. These sets
can contain a single value, all possible values (we use * to
denote this case) or restricted subsets of possible values.
Evaluating all possible subsets of the values for each ﬁeld
would have made the problem of ﬁnding all large clusters
unnecessarily diﬃcult. Instead, we use the natural hierar-
chies that exist for each ﬁeld. For IP addresses a cluster can
be deﬁned by preﬁxes of length from 8 to 32 (for individual
IP addresses) or (*) for all IP addresses. For port num-
bers, clusters can be deﬁned by a particular port number
(e.g. port 80) or the set of all possible values (*). Because
well known ports statically allocated for services are below
1024 and ephemeral ports allocated on-demand to clients
are above 1023 the set of high (> 1023) port numbers and
that of low (< 1024) ones can also deﬁne clusters. Finally,
the protocol ﬁeld can take on exact values or (*).
For example, the cluster deﬁned as (SrcIP=10.8.200.3,
DstIP=*, Proto=TCP, SrcPort=80, DstPort=*) represents
Web traﬃc from the server with address 10.8.200.3.
cIP=*, DstIP=172.27.0.0/16, Proto=TCP, SrcPort=low, Dst-
Port=high) represents TCP traﬃc coming from low ports
and going to high ports destined to a certain preﬁx. Finally,
(SrcIP=*, DstIP=*, Proto=ICMP, SrcPort=*, DstPort=*)
represents all ICMP traﬃc. Notice that the ﬁrst two clusters
overlap with each other while the third cluster is unique.
(Sr-
There are many ways to further generalize the deﬁnition
of traﬃc clusters. For example, we could deﬁne a hierar-
chies based on Autonomous System number, integer ranges
of port numbers, or arbitrary user-deﬁned categories (e.g.
Universities, Broadband Access, Data Centers, etc.). We
could also employ heuristics such as those for identifying
passive FTP and Napster traﬃc (that use random ports)
in [14]. While these additions may provide greater value in
some settings, they do not require any fundamental changes
in our approach, merely a diﬀerent set of aggregation criteria
when constructing clusters. For the remainder of this paper
we restrict our discussion to the “vanilla” cluster deﬁnitions
we have described previously.
There are three advantages to this cluster deﬁnition. First,
our deﬁnition is suﬃciently general to capture much of the
usage structure in existing applications and networks. Sec-
ond, our deﬁnition is consistent with current packet clas-
siﬁers [8] and consequently a manager can apply controls,
such as policy routing and hardware rate limiting, to the
clusters we dynamically identify. Third, our deﬁnition al-
lows a simple visually appealing rule-based display of clus-
ters (Section 4). Finally, initial results on several distinct
networks (Section 5) indicate that clusters deﬁned in this
way do identify interesting resource consumption patterns
that managers care about.
Our deﬁnition of clusters satisﬁes two of the requirements:
the need for multi-dimensional clusters (dimensionality) and
ﬁeld selection constrained by existing ﬁeld hierarchies (util-
ity). However, satisfying the remaining requirement, reduc-
ing detail, requires signiﬁcant additional eﬀort.
2.2 Operations on Trafﬁc Clusters
A traﬃc report is a list of clusters presented to a manager.
It is very easy to see that even restricting ourselves to IP
preﬁxes and very simple port ranges, that there is an expo-
nential number of raw clusters. There are approximately 233
possible source IP preﬁxes alone! The ﬁrst step in reducing
this onslaught of data is to restrict the report to only in-
clude high volume clusters, where volume may be deﬁned as
the number of bytes or the number of packets contained in