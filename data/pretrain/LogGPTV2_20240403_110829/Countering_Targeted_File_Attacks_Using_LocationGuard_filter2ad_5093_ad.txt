based ﬁle system. In due course of time, the adversary
might be able to gather enough information to infer the
location of a target ﬁle. Location rekeying is a general
defense against both known and unknown inference at-
tacks. Users can periodically choose new location keys
so as to render all past inferences made by an adversary
useless. In order to secure the system from Biham’s key
collision attacks [4], one may associate an initialization
vector (IV) with the location key and change IV rather
than the location key itself.
Location rekeying is analogous to rekeying of cryp-
tographic keys. Unfortunately, rekeying is an expensive
operation: rekeying cryptographic keys requires data to
be re-encrypted; rekeying location keys requires ﬁles to
USENIX Association
14th USENIX Security Symposium
91
be relocated on the overlay network. Hence, it is im-
portant to keep the rekeying frequency small enough to
reduce performance overheads and large enough to se-
cure ﬁles on the overlay network.
In our experiments
section, we estimate the periodicity with which location
keys have to be changed in order to reduce the probabil-
ity of an attack on a target ﬁle.
8 Discussion
In this section, we brieﬂy discuss a number of issues re-
lated to security, distribution and management of Loca-
tionGuard.
Key Security. We have assumed that in LocationGuard
based ﬁle systems it is the responsibility of the legal
users to secure location keys from an adversary. If a user
has to access thousands of ﬁles then the user must be re-
sponsible for the secrecy of thousands of location keys.
One viable solution could be to compile all location keys
into one key-list ﬁle, encrypt the ﬁle and store it on the
overlay network. The user now needs to keep secret only
one location key that corresponds to the key-list. This
128-bit location key could be physically protected using
tamper-proof hardware devices, smartcards, etc.
Key Distribution. Secure distribution of keys has been a
major challenge in large scale distributed systems. The
problem of distributing location keys is very similar to
that of distributing cryptographic keys. Typically, keys
are distributed using out-of-band techniques. For in-
stance, one could use PGP [18] based secure email ser-
vice to transfer location keys from a ﬁle owner to ﬁle
users.
Key Management. Managing location keys efﬁciently
becomes an important issue when (i) an owner owns sev-
eral thousand ﬁles, and (ii) the set of legal users for a ﬁle
vary signiﬁcantly over time. In the former scenario, the
ﬁle owner could reduce the key management cost by as-
signing one location key for a group of ﬁles. Any user
who obtains the location key for a ﬁle f would implicitly
be authorized to access the group of ﬁles to which f be-
long. However, the later scenario may seriously impede
the system’s performance in situations where it may re-
quire location key to be changed each time the group
membership changes.
The major overhead for LocationGuard arises from
key distribution and key management. Also, location
rekeying could be an important factor. Key security, dis-
tribution and management in LocationGuard using group
key management protocols [11] are a part of our ongoing
research work.
Other issues that are not discussed in this paper in-
clude the problem of a valid user illegally distributing
the capabilities (tokens) to an adversary, and the robust-
ness of the lookup protocol and the overlay network in
the presence of malicious nodes. In this paper we as-
sume that all valid users are well behaved and the lookup
protocol is robust. Readers may refer to [24] for de-
tailed discussion on the robustness of lookup protocols
on DHT based overlay networks.
9 Experimental Evaluation
In this section, we report results from our simulation
based experiments to evaluate the LocationGuard approach
for building secure wide-area network ﬁle systems. We
implemented our simulator using a discrete event sim-
ulation [8] model, and implemented the Chord lookup
protocol [25] on the overlay network compromising of
N = 1024 nodes. In all experiments reported in this pa-
per, a random p = 10% of N nodes are chosen to behave
maliciously. We set the number of replicas of a ﬁle to be
R = 7 and vary the corruption threshold cr in our ex-
periments. We simulated the bad nodes as having large
but bounded power based on the parameters α (DoS at-
tack strength), λ (node compromise rate) and µ (node
recovery rate) (see the threat model in Section 3). We
study the cost of using location key technique by quan-
tifying the overhead of using location keys and evaluate
the beneﬁts of the location key technique by measuring
the effectiveness of location keys against DoS and host
compromise based target ﬁle attacks.
9.1 LocationGuard
Operational Overhead. We ﬁrst quantify the perfor-
mance and storage overheads incurred by location keys.
All measurements presented in this section were obtained
on a 900 MHz Intel Pentium III processor running Red-
Hat Linux 9.0. Let us consider a typical ﬁle read/write
operation. The operation consists of the following steps:
(i) generate the ﬁle replica identiﬁers, (ii) lookup the
replica holders on the overlay network, and (iii) process
the request at replica holders. Step (i) requires computa-
92
14th USENIX Security Symposium
USENIX Association
tions using the keyed-hash function with location keys,
which otherwise would have required computations us-
ing a normal hash function. We found that the compu-
tation time difference between HMAC-MD5 (a keyed-
hash function) and MD5 (normal hash function) is negli-
gibly small (order of a few microseconds) using the stan-
dard OpenSSL library [17]. Step (ii) involves a pseudo-
random number generation (few microseconds using the
OpenSSL library) and may require lookups to be retried
in the event that the obfuscated identiﬁer turns out to
be unsafe. Given that unsafe obfuscations are extremely
rare (see Table 1) retries are only required occasionally
and thus this overhead is negligible. Step (iii) adds no
overhead because our access check is almost free. As
long as the user can present the correct ﬁlename (token),
the replica holder would honor a request on that ﬁle.
Now, let us compare the storage overhead at the users
and the nodes that are a part of the overlay network.
Users need to store only an additional 128-bit location
key (16 Bytes) along with other ﬁle meta-data for each
ﬁle they want to access. Even a user who uses 1 mil-
lion ﬁles on the overlay network needs to store only an
additional 16MBytes of location keys. Further, there is
no extra storage overhead on the rest of the nodes on the
overlay network. For a detailed description of our im-
plementation of LocationGuard and benchmark results
for ﬁle read and write operations refer to our tech-report
[23].
Denial of Service Attacks. Figure 4 shows the proba-
bility of an attack for varying α and different values of
corruption threshold (cr). Without the knowledge of the
location of ﬁle replicas an adversary is forced to attack
(DoS) a random collection of nodes in the system and
hope that that at least cr replicas of the target ﬁle is at-
tacked. Observe that if the malicious nodes are more
powerful (larger α) or if the corruption threshold cr is
very low with respect to the size (N) of the network,
then the probability of an attack is higher. If an adver-
sary were aware of the R replica holders of a target ﬁle
then a weak collection of B malicious nodes, such as
102 = 0.07,
B = 102 (i.e., 10% of N) with α = R
can easily attack the target ﬁle. It is also true that for
a ﬁle system to handle the DoS attacks on a ﬁle with
α = 1, it would require a large number of replicas (R
close to B) to be maintained for each ﬁle. For example,
in the case where B = 10% × N and N = 1024, the
system needs to maintain as large as 100+ replicas for
each ﬁle. Clearly, without location keys, the effort re-
quired for an adversary to attack a target ﬁle (i.e., make
B = 7
it unavailable) is dependent only on R, but is indepen-
dent of the number of good nodes (G) in the system. On
the contrary, the location key based techniques scale the
hardness of an attack with the number of good nodes in
the system. Thus even with a very small R, the location
key based system can make it very hard for any adver-
sary to launch a targeted ﬁle attack.
Host Compromise Attacks. To further evaluate the ef-
fectiveness of location keys against targeted ﬁle attacks,
we evaluate location keys against host compromise at-
tacks. Our ﬁrst experiment on host compromise attack
shows the probability of an attack on the target ﬁle as-
suming that the adversary can not collect capabilities (to-
kens) stored at the compromised nodes. Hence, the tar-
get ﬁle is attacked if cr or more of its replicas are stored
at either malicious nodes or compromised nodes. Figure
5 shows the probability of an attack for different values
(mea-
of corruption threshold (cr) and varying ρ = µ
λ
sured in number of node recoveries per node compro-
time
mise). We ran the simulation for a duration of 100
λ
denotes the mean time required for
units. Recall that 1
λ
one malicious node to compromise a good node. Note
that if the simulation were run for inﬁnite time then the
probability of attack is always one. This is because, at
some point in time, cr or more replicas of a target ﬁle
would be assigned to malicious nodes (or compromised
nodes) in the system.
From Figure 5 we observe that when ρ ≤ 1, the sys-
tem is highly vulnerable since the node recovery rate is
lower than the node compromise rate. Note that while
a DoS attack could tolerate powerful malicious nodes
(α > 1), the host compromise attack cannot tolerate the
situation where the node compromise rate is higher than
their recovery rate (ρ ≤ 1). This is primarily because
of the cascading effect of host compromise attack. The
larger the number of compromised nodes we have, the
higher is the rate at which other good nodes are compro-
mised (see the adversary model in Section 3). Table 2
shows the mean fraction of good nodes (G0) that are in
an uncompromised state for different values of ρ. Ob-
serve from Table 2 that when ρ = 1, most of the good
nodes are in compromised state.
As we have mentioned in Section 4.3, the adversary
could collect the capabilities (tokens) of the ﬁle replicas
stored at compromised nodes; these tokens can be used
by the adversary at any point in future to corrupt these
replicas using a simple write operation. Hence, our sec-
ond experiment on host compromise attack measures the
USENIX Association
14th USENIX Security Symposium
93
k
c
a
t
t
A
l
u
f
s
s
e
c
c
u
S
f
o
y
t
i
l
i
b
a
b
o
r
P
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
α
 = 0.5
α
 = 1.0
α
 = 2.0
α
 = 4.0
 3
 3.5
 4
 4.5
 5
 5.5
 6
 6.5
 7
Corruption Threshold (cr)
k
c
a
t
t
A
l
u
f
s
s
e
c
c
u
S
f
o
y
t
i
l
i
b
a
b
o
r
P
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
ρ
 = 1.1
ρ
 = 1.2
ρ
 = 1.5
ρ
 = 3.0
k
c
a
t
t
A
l
u
f
s
s
e
c
c
u
S
f
o
y
t
i
l
i
b
a
b