title:Scalable Bias-Resistant Distributed Randomness
author:Ewa Syta and
Philipp Jovanovic and
Eleftherios Kokoris-Kogias and
Nicolas Gailly and
Linus Gasser and
Ismail Khoffi and
Michael J. Fischer and
Bryan Ford
2017 IEEE Symposium on Security and Privacy
Scalable Bias-Resistant Distributed Randomness
Ewa Syta∗, Philipp Jovanovic†, Eleftherios Kokoris Kogias†, Nicolas Gailly†,
Linus Gasser†, Ismail Khofﬁ‡, Michael J. Fischer§, Bryan Ford†
† ´Ecole Polytechnique F´ed´erale de Lausanne, Switzerland
Trinity College, USA
University of Bonn, Germany
Yale University, USA
∗
§
‡
Abstract—Bias-resistant public randomness is a critical com-
ponent in many (distributed) protocols. Generating public ran-
domness is hard, however, because active adversaries may behave
dishonestly to bias public random choices toward their advan-
tage. Existing solutions do not scale to hundreds or thousands
of participants, as is needed in many decentralized systems.
We propose two large-scale distributed protocols, RandHound
and RandHerd, which provide publicly-veriﬁable, unpredictable,
and unbiasable randomness against Byzantine adversaries. Rand-
Hound relies on an untrusted client to divide a set of randomness
servers into groups for scalability, and it depends on the pigeon-
hole principle to ensure output integrity, even for non-random,
adversarial group choices. RandHerd implements an efﬁcient,
decentralized randomness beacon. RandHerd is structurally
similar to a BFT protocol, but uses RandHound in a one-time
setup to arrange participants into veriﬁably unbiased random
secret-sharing groups, which then repeatedly produce random
output at predeﬁned intervals. Our prototype demonstrates that
RandHound and RandHerd achieve good performance across
hundreds of participants while retaining a low failure probability
by properly selecting protocol parameters, such as a group size
and secret-sharing threshold. For example, when sharding 512
nodes into groups of 32, our experiments show that RandHound
can produce fresh random output after 240 seconds. RandHerd,
after a setup phase of 260 seconds, is able to generate fresh
random output in intervals of approximately 6 seconds. For this
conﬁguration, both protocols operate at a failure probability of
at most 0.08% against a Byzantine adversary.
I. INTRODUCTION
A reliable source of randomness that provides high-entropy
output is a critical component in many protocols [11], [22].
The reliability of the source, however, is often not the only
criterion that matters. In many high-stakes protocols,
the
unbiasability and public-veriﬁability of the randomness gen-
eration process are as important as ensuring that the produced
randomness is good in terms of the entropy it provides [31].
More concretely, Tor hidden services [25] depend on the
generation of a fresh random value each day for protection
against popularity estimations and DoS attacks [34]. Anytrust-
based systems, such as Herbivore [32], Dissent [60], and
Vuvuzela [59], as well as sharded blockchains [23], use bias-
resistant public randomness for scalability by sharding par-
ticipants into smaller groups. TorPath [30] critically depends
on public randomness for setting up consensus groups. Public
randomness can be used to transparently select parameters for
cryptographic protocols or standards, such as in the generation
of elliptic curves [2], [40], where adversaries should not be
able to steer the process to select curves with weak security
parameters [6]. Other use-cases for public randomness include
voting systems [1] for sampling ballots for manual recounts,
lotteries for choosing winning numbers, and Byzantine agree-
ment algorithms [15], [46] for achieving scalability.
The process of generating public randomness is nontrivial,
because obtaining access to sources of good randomness,
even in terms of entropy alone, is often difﬁcult and error-
prone [19], [36]. One approach is to rely on randomness
beacons, which were introduced by Rabin [49] in the context
of contract signing, where a trusted third party regularly emits
randomly chosen integers to the public. The NIST beacon [45]
provides hardware-generated random output from quantum-
mechanical effects, but it requires trust in their centralized
beacon—a problematic assumption, especially after the Dual
EC DRBG debacle [8], [54].
This work is concerned primarily with the trustworthi-
ness, rather than the entropy, of public randomness sources.
Generating public randomness without a trusted party is
often desirable, especially in decentralized settings such as
blockchains, where many mutually-distrustful users may wish
to participate. Producing and using randomness in a distributed
setting presents many issues and challenges, however, such
as how to choose a subset of available beacons, or how
to combine random outputs from multiple beacons without
permitting bias by an active adversary. Prior approaches to
randomness without trusted parties [48] employ Bitcoin [4],
[13], slow cryptographic hash functions [40], lotteries [2], or
ﬁnancial data [21] as sources for public randomness.
Our goal is to provide bias-resistant public randomness in
the familiar (t, n)-threshold security model already widely-
used both in threshold cryptography [24], [47] and Byzantine
consensus protocols [15]. Generating public randomness is
hard, however, as active adversaries can behave dishonestly in
order to bias public random choices toward their advantage,
e.g., by manipulating their own explicit inputs or by selectively
injecting failures. Although addressing those issues is rela-
tively straightforward for small values of n ≈ 10 [15], [38],
we address scalability challenges of using larger values of n,
in the hundreds or thousands, for enhanced security in real-
world scenarios. For example, scalable randomness is relevant
for public cryptocurrencies [39], [44] which tend to have
© 2017, Ewa Syta. Under license to IEEE.
DOI 10.1109/SP.2017.45
444
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:21:04 UTC from IEEE Xplore.  Restrictions apply. 
hundreds to thousands of distinct miners or for countries with
thousands of national banks that might want to form a national
permissioned blockchain with secure random sharding.
This paper’s contributions are mainly pragmatic rather than
theoretical, building on existing cryptographic primitives to
produce more scalable and efﬁcient distributed randomness
protocols. We introduce two scalable public-randomness gen-
eration protocols: RandHound is a “one-shot” protocol to gen-
erate a single random output on demand, while RandHerd is a
randomness beacon protocol that produces a regular series of
random outputs. Both protocols provide the same key security
properties of unbiasability, unpredictability, availability, and
third-party veriﬁability of their random outputs.
RandHound is a client-server randomness scavenging pro-
tocol enabling a client to gather fresh randomness on demand
from a potentially large set of nearly-stateless randomness
servers, preferably run by independent parties. A party that
occasionally requires trustworthy public randomness, such as
a lottery association, can use RandHound to produce a random
output that includes contributions of – and trustworthiness
attestations from – all participating servers. The RandHound
client (e.g., the lottery association) ﬁrst publicly commits to
the parameters of a unique RandHound protocol run, such
as the time and date of the lottery and the set of servers
involved, so a malicious client cannot bias the result by
secretly rerunning the protocol. The client
then splits the
servers into balanced subgroups for scalability. Each subgroup
uses publicly veriﬁable secret sharing (PVSS) [52], [56]
to produce secret inputs such that an honest threshold of
participants can later recover them and form a third-party-
veriﬁable proof of their validity. To tolerate server failures,
the client selects a subset of secret inputs from each group.
Application of the pidgeonhole principle ensures ensures the
integrity of RandHound’s ﬁnal output even if some subgroups
are compromised, e.g., due to biased grouping. The client
commits to his choice of secrets, to prevent equivocation,
by obtaining a collective signature [58] from participating
servers. After the servers release the selected secrets, the client
combines and publishes the collective random output along
with a third-party veriﬁable transcript of the protocol run.
Anyone can subsequently check this transcript to verify that
the random output is trustworthy and unbiased, provided not
too many servers were compromised.
RandHerd is a complementary protocol enabling a poten-
tially large collection of servers to form a distributed public
randomness beacon, which proactively generates a regular
series of public random outputs. RandHerd runs continually
and need not be initiated by any client, but requires stateful
servers. No single or sub-threshold group of failing or mali-
cious servers can halt the protocol, or predict or signiﬁcantly
bias its output. Clients can check the trustworthiness of any
published beacon output with a single, efﬁcient check of one
collective signature [58]. RandHerd ﬁrst invokes RandHound
once, at setup or reconﬁguration time,
to divide the set
of servers securely into uniformly random groups, and to
generate a short-term aggregate public key used to produce
and verify individual beacon outputs. RandHerd subsequently
uses a threshold collective signing protocol based on Shamir
secret sharing [9], [53], to generate random outputs at regular
intervals. Each of RandHerd’s random outputs doubles as
a collective Schnorr signature [57], [58], which clients can
validate efﬁciently against the group’s aggregate public key.
The dominant cost in both protocols is publicly veriﬁable
secret sharing (PVSS), which normally incurs O(n3) com-
munication and computation costs on each of n participants.
RandHound and RandHerd run PVSS only among smaller
groups, however, whose conﬁgured size c serves as a security
parameter. RandHound therefore reduces asymptotic cost to
O(n) if c is constant. By leveraging efﬁcient tree-structured
communication, RandHerd further reduces the cost of produc-
ing successive beacon outputs to O(log n) per server.
We implemented the RandHound and RandHerd protocols
in Go, and made these implementations freely available as part
of the EPFL DEDIS lab’s Cothority framework.1 Experiments
with our prototype implementations show that, among a collec-
tive of 512 globally-distributed servers divided into groups of
32, RandHerd can produce a new 32-byte collective random
output every 6 seconds, following a one-time setup process
using RandHound that takes approximately 260 seconds. The
randomness veriﬁcation overhead of RandHerd is equivalent
to verifying a single Schnorr multisignature [51], typically
less than 100 bytes in size, which clients can check in
constant time. Using RandHound alone to produce a random
output on demand, it takes approximately 240 seconds to
produce randomness and approximately 76 seconds to verify it
using the produced 4 MByte transcript. In this conﬁguration, a
Byzantine adversary can compromise the availability of either
protocol with a probability of at most 0.08%.
This paper is organized as follows. Section II explores
background and motivation for public randomness. Sections III
and IV introduces the design and security properties of Rand-
Hound and RandHerd, respectively. Section V evaluates the
prototype implementations of both protocols. Finally, Sec-
tion VI summarizes related work and Section VII concludes.
II. BACKGROUND AND MOTIVATION
We ﬁrst introduce notation and summarize techniques for
secret sharing and Schnorr signing, which RandHound and
RandHerd build on. We then consider a series of strawman
protocols illustrating the key challenges in distributed random-
ness generation of commitment, selective aborts, and malicious
secret shares. We end with RandShare, a protocol that offers
the desired properties, but unlike RandHound and RandHerd
is not third-party veriﬁable and does not scale well.
For the rest of the work, we denote by G a multiplicatively
written cyclic group of order q with generator G, where the
set of non-identity elements in G is written as G∗. We denote
by (xi)i∈I a vector of length |I| with elements xi, for i ∈ I.
Unless stated otherwise, we denote the private key of a node
i by xi and the corresponding public key by Xi = Gxi.
1https://github.com/dedis/cothority
445
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:21:04 UTC from IEEE Xplore.  Restrictions apply. 
A. Publicly Veriﬁable Secret-Sharing
A (t, n)-secret sharing scheme [9], [53] enables an honest
dealer to share a secret s among n trustees such that any
subset of t honest trustees can reconstruct s, whereas any
subset smaller than t learns nothing about s. Veriﬁable secret-
sharing (VSS) [20], [26], [50] adds protection from a dishonest
dealer who might intentionally produce bad shares and prevent
honest trustees from recovering the same, correct secret.
A publicly veriﬁable secret sharing (PVSS) [52], [56]
scheme makes it possible for any party to verify secret-shares
without revealing any information about the shares or the
secret. During the share distribution phase, for each trustee
i, the dealer produces an encrypted share Ei(si) along with a
non-interactive zero-knowledge proof (NIZK) [18], [27], [28]
that Ei(si) correctly encrypts a valid share si of s. During the
reconstruction phase, trustees recover s by pooling t properly-
decrypted shares. They then publish s along with all shares
and NIZK proofs that show that the shares were properly
decrypted. PVSS runs in three steps:
1) The dealer chooses a degree t − 1 secret sharing poly-
(cid:2)t−1
j=0 ajxj and creates, for each trustee
i ∈ {1, . . . , n}, an encrypted share (cid:3)Si = X s(i)
of the
shared secret S0 = Gs(0). He also creates commitments
Aj = H aj , where H (cid:4)= G is a generator of G, and
for each share a NIZK encryption consistency proof (cid:3)Pi.
Afterwards, he publishes (cid:3)Si, (cid:3)Pi, and Aj.
2) Each trustee i veriﬁes his share (cid:3)Si using (cid:3)Pi and Aj,
(cid:3)Si)x−1
and, if valid, publishes the decrypted share Si = (
together with a NIZK decryption consistency proof Pi.
3) The dealer checks the validity of Si against Pi, discards
invalid shares and, if there are at least t out of n de-
crypted shares left, recovers the shared secret S0 through
Lagrange interpolation.
nomial s(x) =
i
i
B. Schnorr Signature Schemes
RandHound and RandHerd rely on variations of the well-
known Schnorr (multi-)signature schemes [3], [42], [51].
1) Threshold Signing: TSS [57] is a distributed (t, n)-
threshold Schnorr signature scheme. TSS allows any subset
of t signers to produce a valid signature. During setup, all
n trustees use VSS to create a long-term shared secret key
x and a public key X = Gx. To sign a statement S, the n
trustees ﬁrst use VSS to create a short-term shared secret v
and a commitment V = Gv and then compute the challenge
c = H(V (cid:5) S). Afterwards, each trustee i uses his shares vi
and xi of v and x, respectively, to create a partial response
ri = vi−cxi. Finally, when t out of n trustees collaborate they
can reconstruct the response r through Lagrange interpolation.
The tuple (c, r) forms a regular Schnorr signature on S, which
can be veriﬁed against the public key X.
2) Collective Signing: CoSi [58] enables a set of witness-
ing servers coordinated by a leader to efﬁciently produce a
(cid:4)n−1
collective Schnorr signature (c, r) under an aggregate public
i=0 Xi. CoSi scales Schnorr multisignatures to
key (cid:3)X =
446
thousands of participants by using aggregation techniques and
communication trees.
holds the aggregate commit (cid:3)V =
A CoSi round runs in four steps over two round-trips
between a leader and his witnesses. To sign a statement
S sent down the communication tree by the leader, each
server i computes a commitment Vi = Gvi and in a bottom-
(cid:4)n−1
up process, all commitments are aggregated until the leader
i=0 Vi. Once the leader
(cid:3)V (cid:5) S), each server i responds with a partial response
computes and multicasts down the tree the collective challenge
c = H(
ri = vi − cxi. Lastly, the servers aggregate all responses into
(cid:2)n−1
i=0 ri in a ﬁnal bottom-up process.
r =
C. Insecure Approaches to Public Randomness
(cid:5)
For expositional clarity, we now summarize a series of
inadequate strawman designs: (I) a naive, trivially insecure
design, (II) one that uses a commit-then-reveal process to
ensure unpredictability but fails to be unbiasable, and (III) one
that uses secret sharing to ensure unbiasability in an honest-
but-curious setting, but is breakable by malicious participants.
(cid:5)n−1
Strawman I. The simplest protocol for producing a random
output r =
i=0 ri requires each peer i to contribute their
secret input ri under the (false) assumption that a random
input from any honest peer would ensure unbiasability of r.
However, a dishonest peer j can force the output value to be
ˆr by choosing rj = ˆr
i:i(cid:4)=j ri upon seeing all other inputs.
Strawman II. To prevent the above attack, we want to
force each peer to commit to their chosen input before seeing
other inputs by using a simple commit-then-reveal approach.
Although the output becomes unpredictable as it
is ﬁxed
during the commitment phase, it is not unbiasable because a
dishonest peer can choose not to reveal his input upon seeing
all other openings of committed inputs. By repeatedly forcing
the protocol to restart, the dishonest peer can obtain output
that is beneﬁcial for him, even though he cannot choose its
exact value. The above scenario shows an important yet subtle
difference between an output that is unbiased when a single,
successful run of the protocol is considered, and an output that
is unbiasable in a more realistic scenario, when the protocol
repeats until some output is produced. An attacker’s ability to
re-toss otherwise-random coins he does not like is central to