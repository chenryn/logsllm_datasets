title:Finding Unknown Malice in 10 Seconds: Mass Vetting for New Threats
at the Google-Play Scale
author:Kai Chen and
Peng Wang and
Yeonjoon Lee and
XiaoFeng Wang and
Nan Zhang and
Heqing Huang and
Wei Zou and
Peng Liu
Finding Unknown Malice in 10 Seconds: 
Mass Vetting for New Threats at  
the Google-Play Scale
Kai Chen, Chinese Academy of Sciences and Indiana University; Peng Wang,  
Yeonjoon Lee, Xiaofeng Wang, and Nan Zhang, Indiana University;  
Heqing Huang, The Pennsylvania State University; Wei Zou, Chinese Academy of Sciences; 
Peng Liu, The Pennsylvania State University
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/chen-kai
This paper is included in the Proceedings of the 
24th USENIX Security Symposium
August 12–14, 2015 • Washington, D.C.
ISBN  978-1-939133-11-3
Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXFinding Unknown Malice in 10 Seconds: Mass Vetting for New Threats at
the Google-Play Scale
Kai Chen‡,†, Peng Wang†, Yeonjoon Lee†, XiaoFeng Wang†, Nan Zhang†, Heqing Huang§, Wei Zou‡ and Peng Liu§
{chenkai, zouwei}@iie.ac.cn, {pw7, yl52, xw7, nz3}@indiana.edu, PI:EMAIL, PI:EMAIL
‡State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences
†Indiana University, Bloomington
§College of IST, Penn State University
Abstract
An app market’s vetting process is expected to be scal-
able and effective. However, today’s vetting mechanisms
are slow and less capable of catching new threats.
In
our research, we found that a more powerful solution
can be found by exploiting the way Android malware is
constructed and disseminated, which is typically through
repackaging legitimate apps with similar malicious com-
ponents. As a result, such attack payloads often stand out
from those of the same repackaging origin and also show
up in the apps not supposed to relate to each other.
Based upon this observation, we developed a new
technique, called MassVet, for vetting apps at a mas-
sive scale, without knowing what malware looks like
and how it behaves. Unlike existing detection mecha-
nisms, which often utilize heavyweight program analy-
sis techniques, our approach simply compares a submit-
ted app with all those already on a market, focusing on
the difference between those sharing a similar UI struc-
ture (indicating a possible repackaging relation), and the
commonality among those seemingly unrelated. Once
public libraries and other legitimate code reuse are re-
moved, such diff/common program components become
highly suspicious. In our research, we built this “Diff-
Com” analysis on top of an efﬁcient similarity compar-
ison algorithm, which maps the salient features of an
app’s UI structure or a method’s control-ﬂow graph to
a value for a fast comparison. We implemented MassVet
over a stream processing engine and evaluated it nearly
1.2 million apps from 33 app markets around the world,
the scale of Google Play. Our study shows that the tech-
nique can vet an app within 10 seconds at a low false
detection rate. Also, it outperformed all 54 scanners in
VirusTotal (NOD32, Symantec, McAfee, etc.) in terms
of detection coverage, capturing over a hundred thou-
sand malicious apps, including over 20 likely zero-day
malware and those installed millions of times. A close
look at these apps brings to light intriguing new obser-
vations: e.g., Google’s detection strategy and malware
authors’ countermoves that cause the mysterious disap-
pearance and reappearance of some Google Play apps.
1 Introduction
The phenomenal growth of Android devices brings in
a vibrant application ecosystem. Millions of applica-
tions (app for short) have been installed by Android users
around the world from various app markets. Prominent
examples include Google Play, Amazon Appstore, Sam-
sung Galaxy Apps, and tens of smaller third-party mar-
kets. With this prosperity, the ecosystem is tainted by the
rampancy of Android malware, which masquerades as a
useful program, often through repackaging a legitimate
app, to wreak havoc, e.g., intercepting one’s messages,
stealing personal data, sending premium SMS messages,
etc. Countering this menace primarily relies on the effort
from the app markets, since they are at a unique position
to stop the spread of malware in the ﬁrst place. Accom-
plishing this mission, however, is by no means trivial,
as highlighted by a recent report [8] that 99% of mobile
malware runs on Android devices.
Challenges in app vetting. More speciﬁcally, the pro-
tection today’s app market puts in place is a vetting pro-
cess, which screens uploaded apps by analyzing their
code and operations for suspicious activities. Particu-
larly, Google Play operates Bouncer [24], a security ser-
vice that statically scans an app for known malicious
code and then executes it within a simulated environ-
ment on Google’s cloud to detect hidden malicious be-
havior. The problem here is that the static approach does
not work on new threats (i.e., zero-day malware), while
the dynamic one can be circumvented by an app capable
of ﬁngerprinting the testing environment, as discovered
by a prior study [30]. Also the dynamic analysis can be
heavyweight, which makes it hard to explore all execu-
tion paths of an app.
New designs of vetting techniques have recently been
USENIX Association  
24th USENIX Security Symposium  659
proposed by the research community [57, 28] for captur-
ing new apps associated with known suspicious behavior,
such as dynamic loading of binary code from a remote
untrusted website [57], operations related to component
hijacking [28], Intent injection [12], etc. All these ap-
proaches involve a heavyweight information-ﬂow anal-
ysis and require a set of heuristics that characterize the
known threats. They often need a dynamic analysis in ad-
dition to the static inspection performed on app code [57]
and further human interventions to annotate the code or
even participate in the analysis [14]. Moreover, emula-
tors that most dynamic analysis tools employ can be de-
tected and evaded by malware [23]. Also importantly,
none of them has been put to a market-scale test to un-
derstand their effectiveness, nor has their performance
been clearly measured.
Catching unknown malice. Actually, a vast majority of
Android malware are repackaged apps [56], whose au-
thors typically attach the same attack payload to different
legitimate apps. In this way, not only do they hide their
malicious program logic behind the useful functionali-
ties of these apps, but they can also automate the repack-
aging process to quickly produce and distribute a large
number of Trojans1. On the other hand, this practice
makes such malware stand out from other repackaged
apps, which typically incorporate nothing but advertis-
ing libraries [2]. Also as a result of the approach, similar
code (typically in terms of Java methods) shows up in
unrelated apps that are not supposed to share anything
except popular libraries.
These observations present a new opportunity to catch
malicious repackaged apps,
the mainstay of Android
malware, without using any heuristics to model their be-
havior. What we can do is to simply compare the code
of related apps (an app and its repackaged versions, or
those repackaged from the same app) to check their dif-
ferent part, and unrelated apps (those of different ori-
gins, signed by different parties) to inspect their com-
mon part to identify suspicious code segments (at the
method level). These segments, once found to be in-
explicable (e.g., not common libraries), are almost cer-
tain to be malicious, as discovered in our study (Sec-
tion 4.2). This DiffCom analysis is well suited for ﬁnd-
ing previously unknown malicious behavior and also can
be done efﬁciently, without resorting to any heavyweight
information-ﬂow technique.
Mass vetting at scale. Based on this simple idea, we de-
veloped a novel, highly-scalable vetting mechanism for
detecting repackaged Android malware on one market
or cross markets. We call the approach mass vetting or
simply MassVet, as it does not use malware signatures
1Those Trojans are typically signed by different keys to avoid
blocking of a speciﬁc signer.
and any models of expected malicious operations, and
instead, solely relies on the features of existing apps on
a market to vet new ones uploaded there. More specif-
ically, to inspect a new app, MassVet runs a highly ef-
ﬁcient DiffCom analysis on it against the whole market.
Any existing app related to the new one (i.e., sharing the
same repackaging origin) is quickly identiﬁed from the
structural similarity of their user interfaces (aka., views),
which are known to be largely preserved during repack-
aging (Section 2). Then, a differential analysis happens
to those sharing the similar view structure (indicating a
repackaging relation between them) when a match has
been found. Also, an intersection analysis is performed
to compare the new app against those with different view
structures and signed by different certiﬁcates. The code
components of interest discovered in this way, either the
common (or similar) methods (through the intersection
analysis) or different ones (by the differential analysis),
are further inspected to remove common code reuses
(libraries, sample code, etc.) and collect evidence for
their security risks (dependence on other code, resource-
access API calls, etc.), before a red ﬂag is raised.
Supporting this mass vetting mechanism are a suite
of techniques for high-performance view/code compar-
isons. Particularly, innovations are made to achieve a
scalable analysis of different apps’ user interfaces (Sec-
tion 3.2). The idea is to project a set of salient features of
an app’s view graph (i.e., the interconnections between
its user interfaces), such as types of widgets and events,
to a single dimension, using a unique index to represent
the app’s location within the dimension and the similar-
ity of its interface structure to those of others.
In our
research, we calculated this index as a geometric center
of a view graph, called v-core. The v-cores of all the
apps on the market are sorted to enable a binary search
during the vetting of a new app, which makes this step
highly scalable. The high-level idea here was applied
to application clone detection [7], a technique that has
been utilized in our research (mapping the features of a
Java method to an index, called m-core in our research)
for ﬁnding common methods across different apps (Sec-
tion 3.3). It is important to note that for the view-graph
comparison, new tricks need to be played to handle the
structural changes caused by repackaging, e.g., when ad-
vertisement interfaces are added (Section 3.2).
Our ﬁndings. We implemented MassVet on a cloud
platform, nearly 1.2 million real-world apps collected
from 33 app markets around the world. Our experimen-
tal study demonstrates that MassVet vetted apps within
ten seconds, with a low false positive rate. Most impor-
tantly, from the 1.2 million apps, our approach discov-
ered 127,429 malware: among them at least 20 are likely
zero-day and 34,026 were missed by the majority of the
malware scanners run by VirusTotal, a website that syn-
660  24th USENIX Security Symposium 
USENIX Association
2
dicates 54 different antivirus products [43]. Our study
further shows that MassVet achieved a better detection
coverage than any individual scanner within VirusTotal,
such as Kaspersky, Symantec, McAfee, etc. Other high-
lights of our ﬁndings include the discovery of malicious
apps in leading app markets (30,552 from Google Play),
and Google’s strategies to remove malware and malware
authors’ countermoves, which cause mysterious disap-
pearance and reappearance of apps on the Play Store.
Contributions. The contributions of the paper are sum-
marized as follows:
• New techniques. We developed a novel mass vet-
ting approach that detects new threats using nothing but
the code of the apps already on a market. An innova-
tive differential-intersection analysis (i.e., DiffCom) is
designed to exploit the unique features of repackaging
malware, catching the malicious apps even when their
behavior has not been proﬁled a priori. This analysis
is made scalable by its simple, static nature and the fea-
ture projection techniques that enable a cloud-based, fast
search for view/code differences and similarities. Note
that when the v-core and m-core datasets (only 100 GB
for 1.2 million apps) are shared among multiple markets,
MassVet can help one market to detect malicious submis-
sions using the apps hosted by all these markets.
• New discoveries. We implemented MassVet and eval-
uated it using nearly 1.2 million apps, a scale unparal-
leled in any prior study on Android malware detection,
up to our knowledge, and on a par with that of Google
Play, the largest app market in the world with 1.3 million
apps [39]. Our system captured tens of thousands of mal-
ware, including those slipping under the radar of most or
all existing scanners, achieved a higher detection cover-
age than all popular malware scanners within VirusTotal
and vetted new apps within ten seconds. Some malware
have over millions of installs. 5,000 malware were in-
stalled over 10,000 times each, impacting hundreds of
millions of mobile devices. A measurement study fur-
ther sheds light on such important issues as how effective
Google Play is in screening submissions, how malware
authors hide and distribute their attack payloads, etc.
2 Background
Android App markets. Publishing an app on a market
needs to go through an approval process. A submission
will be inspected for purposes such as quality control,
censorship, and also security protection. Since 2012,
Google Play has been under the protection of Bouncer.
This mechanism apparently contributes to the reduction
of malware on the Play store, about 0.1% of all apps
there as discovered by F-Secure [15]. On the other hand,
this security vetting mechanism was successfully cir-
cumvented by an app that ﬁngerprints its simulator and
strategically adjusts its behavior [33]. Compared with
the Android ofﬁcial market, how third-party markets re-
view submitted apps is less clear. The picture painted by
F-Secure, however, is quite dark: notable markets like
Mumayi, AnZhi, Baidu, etc. were all found riddled with
malware inﬁltrations [16].
Attempts to enhance the current secure vetting mecha-
nisms mainly resort to conventional malware detection
techniques. Most of these approaches, such as Vet-
Droid [52], rely on tracking information ﬂows within
an app and the malicious behavior modeling for detect-
ing malware. In the case that what the malware will do
is less clear to the market, these approaches no longer
help. Further, analyzing information ﬂows requires se-
mantically interpreting each instruction and carefully-
designed techniques to avoid false positives, which are
often heavyweight. This casts doubt on the feasibility of
applying these techniques to a large-scale app vetting.
Repackaging. App repackaging is a process that mod-
iﬁes an app developed by another party and already re-
leased on markets to add in some new functionalities be-
fore redistributing the new app to the Android users. Ac-
cording to Trend Micro (July 15, 2014), nearly 80% of
the top 50 free apps on Google Play have repackaged
versions [49]. Even the Play store itself is reported to
host 1.2% repackaged apps [58]. This ratio becomes
5% to 13% for third-party markets, according to a prior
study [55]. These bogus apps are built for two purposes:
either for getting advertisement revenues or for distribut-
ing malware [7]. For example, one can wrap Angry-
Bird with ad libraries, including his own adverting ID
to beneﬁt from its advertising revenue. Malware authors
also found that leveraging those popular legitimate apps
is the most effective and convenient avenue to distribute
their attack payloads: repackaging saves them a lot of ef-
fort to build the useful functionalities of a Trojan and the
process can also be automated using the tools like smal-
i/baksmali [36]; more importantly, they can free-ride the
popularity of these apps to quickly infect a large number
of victims. Indeed, research shows that the vast majority
of Android malware is repackaged apps, about 86% ac-
cording to a study [56]. A prominent feature shared by
all these repackaged apps, malicious or not, is that they
tend to keep the original user interfaces intact, so as to
impersonate popular legitimate apps.
Scope and assumptions. MassVet is designed to detect
repackaged Android malware. We do not consider the
situation that the malware author makes his malicious
payload an inseparable part of the repackaged app, which
needs much more effort to understand the legitimate app
than he does today. Also, MassVet can handle typi-
cal code obfuscation used in most Android apps (Sec-
tion 3). However, we assume that the code has not been
USENIX Association  
24th USENIX Security Symposium  661
3