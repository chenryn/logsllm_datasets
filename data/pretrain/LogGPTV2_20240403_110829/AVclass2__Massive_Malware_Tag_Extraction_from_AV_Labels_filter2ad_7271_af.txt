100%
F1
49% 59%
70% 73%
54% 67%
93% 91%
85% 89%
74%
76%
86%
90%
94%
T
2,126
331
593
53
208
controlled vocabularies, that are incomplete and require frequent
updates.
An analyst that requires advanced searches or the extra intelli-
gence should use AVclass2, but those that exclusively need family
labels could still use the faster AVclass. Our vision is that in the
future both AVclass2 and AVclass take as input the same data
files, avoiding duplicate work to keep both tools up-to-date. For
this, we plan to integrate our AVclass* modifications into AVclass,
so that both tools take as input the same files. This will enable the
community to collaboratively update the malware knowledge in the
taxonomy, tagging rules, and expansion rules, avoiding duplicate
efforts, while maintaining backwards compatibility.
6 RELATED WORK
AV labels have been widely studied for over a decade. Early works
showed the problem of different AV engines disagreeing on labels
for the same sample [2, 5]. Despite this problem, AV labels have
been widely used to build training datasets and evaluate malware
detection and clustering approaches [1–3, 7, 12, 14, 19, 25, 26, 30,
31, 33, 34]. Li et al. [21] studied AV labels as a reference to evaluate
clustering results. They showed that including only a subset of
samples, for which AV engines largely agree, biases the evaluation
towards samples that are easier to label. Other works have focused
on the quality of the labels from different AV engines. Mohaisen and
Alrawi [28] proposed metrics for evaluating AV labels, identifying
clusters of AV engines that copy their labels [28]; Kantchelian et
al. [17] discussed that AV engines have varying label quality and
proposed to weight them differently; and Hurier et al. [13] proposed
metrics to evaluate ground truth datasets built using AV labels.
The dynamics of AV labels have been another target of analysis.
Some works have shown how AV engines change their labels for
the same samples over time as a result of signatures and analysis
being refined [10, 17] and that detection systems should be trained
with the labels available at training, not testing, time [26]. Recently,
Zhu et al. [40] analyze daily snapshots of 14K samples over a year.
Among other results, they confirm that certain sets of AV engines
produce strongly correlated labels, as observed in AVMeter [28]
and implemented in AVClass [35], show that hand-picking of a few
trusted engines does not always perform well, and measure that
detection thresholds between two and 14 exhibit little differences
in precision and recall.
Malware labeling. One approach to tackle disagreements on mal-
ware names is to use naming conventions such as the 1991 CARO
Virus Naming Convention [6]. Another attempt was the Common
Malware Enumeration (CME) Initiative [4] that provided unique
identifiers for malware. Unfortunately, conventions have not achieved
wide adoption, possibly due to their use of predefined tags, i.e.,
An alternative approach is to automatically extract accurate fam-
ily names from AV labels. A precursor of this was VAMO [32] that
proposed an automated approach for evaluating clustering results
by building a graph of the normalized labels of 4 AV engines. It in-
troduced the use of label co-occurrence, i.e., the fraction of samples
where labels, possibly from different engines, appear together.
Tools like AVclass [35] and Euphony [9] have demonstrated
that it is possible to extract accurate family tags from AV labels.
One key idea of these works is to avoid using the whole label as
family name, as AV labels encode other non-family information.
AVclass and Euphony take as input AV labels for a large number of
samples, and output a family name for each sample. They both use
co-occurrence to automatically identify family aliases. However,
there are some key differences between them. AVclass proposes
that aliases and generic tokens learned from one dataset can be
reused on other datasets. Instead, Euphony uses a graph-based
approach that identifies aliases within the dataset, but does not
produce relations that can be reused. In addition, AVclass avoids
predicting which AV engines are better at labeling samples. Instead,
it makes the tokenization as AV engine independent as possible.
Instead, Euphony tries to learn the structure of the labels from
a selected subset of AV engines. As shown in Section 5.5, these
differences result in improved accuracy and scalability for AVclass,
a key reason why we build AVclass2 on top of AVclass.
Compared to prior malware labeling tools, AVclass2 leverages
that AV labels contain a wealth of information beyond family names
such as malware classes, file properties, and behaviors. Such infor-
mation is not extracted by tools like AVclass and Euphony and can
be used to produce tags to categorize and index malware samples.
Malware tagging. The use of tags to characterize malware is at
the heart of information sharing standards like Malware Attribute
Enumeration and Characterization (MAEC) [24] and Malware Infor-
mation Sharing Platform (MISP) [27]. In addition, tags are already
used by some malware repositories to enable efficient search. To
further the use of malware tags, we present AVclass2, an automatic
tool to extract tags from the wealth of information on AV labels. The
generated tags can be incorporated by those repositories to enable
richer searches. Most related to our work is simultaneous work by
Ducau et al. [8] that extract 11 pre-defined tags, mostly malware
classes, from the AV labels of 10 AV engines. They use the tags as
training set for a classifier that predicts the tags in new samples.
Some key differences of AVclass2 are that it does not pre-define the
tags, instead building an open taxonomy (which currently has 150
non-family tags), handles tag aliasing (e.g., downloader and dropper
AVclass2: Massive Malware Tag Extraction from AV Labels
ACSAC 2020, December 7–11, 2020, Austin, USA
are aliases in our taxonomy), provides support for updating the
input rules and taxonomy, does not limit the supported AV engines,
and is open source.
7 CONCLUSION
Automatically extracting tags from AV labels is an efficient ap-
proach to categorize and index massive amounts of malware sam-
ples. But, it is challenging due to the different vocabularies used by
AV engines. In this work, we have presented AVclass2, an open
source automatic malware tagging tool. Given the AV labels for a
potentially massive number of samples, AVclass2 extracts clean
tags that categorize the samples according to their class, family,
file properties, and behaviors. The extracted tags can be used by
malware repositories and analysis services to enable, or enhance,
searches for samples of interest. Those samples, can in turn be used
as ground truth for machine learning approaches. AVclass2 uses,
and helps building, an open taxonomy that organizes concepts in AV
labels, but is not constrained to a predefined set of tags. AVclass2
provides an update module that uses tag co-occurrence to automat-
ically identify taxonomy updates, as well as tagging and expansion
rules that capture relations between tags. Thus, it can be easily
updated as AV vendors introduce new tags. We have evaluated
AVclass2 on 42M samples.
ACKNOWLEDGMENTS
This research was supported by the Regional Government of Madrid
through grants BLOQUES-CM P2018/TCS-4339 and PEJD-2018-
PRE/TIC-9571 and by the Spanish Government through the SCUM
grant RTI2018-102043-B-I00 and fellowship FPU18/06416. Any opin-
ions, findings, and conclusions or recommendations expressed in
this material are those of the authors or originators, and do not
necessarily reflect the views of the sponsors.
REFERENCES
[1] Daniel Arp, Michael Spreitzenbarth, Malte Huebner, Hugo Gascon, and Konrad
Rieck. 2014. Drebin: Efficient and Explainable Detection of Android Malware in
Your Pocket. In Network and Distributed System Security.
[2] Michael Bailey, Jon Oberheide, Jon Andersen, Zhuoqing Morley Mao, Farnam
Jahanian, and Jose Nazario. 2007. Automated Classification and Analysis of
Internet Malware. In International Symposium on Recent Advances in Intrusion
Detection.
[3] Ulrich Bayer, Paolo Milani Comparetti, Clemens Hlauschek, Christopher Kruegel,
and Engin Kirda. 2009. Scalable, Behavior-Based Malware Clustering. In Network
and Distributed System Security.
[4] Desiree Beck and Julie Connolly. 2006. The Common Malware Enumeration
Initiative. In Virus Bulletin Conference.
[5] Julio Canto, Marc Dacier, Engin Kirda, and Corrado Leita. 2008. Large Scale Mal-
ware Collection: Lessons Learned. In IEEE SRDS Workshop on Sharing Field Data
and Experiment Measurements on Resilience of Distributed Computing Systems.
[6] CARO [n.d.]. CARO Virus Naming Convention. http://www.caro.org/articles/
naming.html.
[7] George E. Dahl, Jack W. Stokes, Li Deng, and Dong Yu. 2013. Large-Scale Mal-
ware Classification using Random Projections and Neural Networks. In IEEE
International Conference on Acoustics, Speech and Signal Processing.
[8] Felipe N Ducau, Ethan M Rudd, Tad M Heppner, Alex Long, and Konstantin
Berlin. 2019. SMART: Semantic Malware Attribute Relevance Tagging. arXiv
preprint arXiv:1905.06262 (2019).
[9] Euphony [n.d.]. Harmonious Unification of Cacophonous Anti-Virus Vendor
Labels for Android Malware. https://github.com/fmind/euphony.
[10] Ilir Gashi, Bertrand Sobesto, Stephen Mason, Vladimir Stankovic, and Michel
Cukier. 2013. A Study of the Relationship between Antivirus Regressions and
Label Changes. In International Symposium on Software Reliability Engineering.
[11] Harry Halpin, Valentin Robu, and Hana Shepherd. 2007. The Complex Dynamics
of Collaborative Tagging. In International Conference on World Wide Web.
[12] Wenyi Huang and Jack W. Stokes. 2016. MtNet: A Multi-Task Neural Network
for Dynamic Malware Classification. In Detection of Intrusions and Malware, and
Vulnerability Assessment.
[13] Médéric Hurier, Kevin Allix, Tegawendé Bissyandé, Jacques Klein, and Yves Le
Traon. 2016. On the Lack of Consensus in Anti-Virus Decisions: Metrics and
Insights on Building Ground Truths of Android Malware. In Detection of Intrusions
and Malware, and Vulnerability Assessment.
[14] Jiyong Jang, David Brumley, and Shobha Venkataraman. 2011. BitShred: Feature
Hashing Malware for Scalable Triage and Semantic Analysis. In ACM Conference
on Computer and Communications Security.
[15] Jiyong Jang, Maverick Woo, and David Brumley. 2013. Towards Automatic
Software Lineage Inference. In USENIX Security Symposium.
[16] JoeSandbox [n.d.]. Joe Sandbox. https://www.joesandbox.com/.
[17] Alex Kantchelian, Michael Carl Tschantz, Sadia Afroz, Brad Miller, Vaishaal
Shankar, Rekha Bachwani, Anthony D Joseph, and JD Tygar. 2015. Better Malware
Ground Truth: Techniques for Weighting Anti-Virus Vendor Labels. In ACM
Workshop on Artificial Intelligence and Security.
[18] Christian Körner, Dominik Benz, Andreas Hotho, Markus Strohmaier, and Gerd
Stumme. 2010. Stop Thinking, Start Tagging: Tag Semantics Emerge from Col-
laborative Verbosity. In International Conference on World Wide Web.
[19] Platon Kotzias, Srdjan Matic, Richard Rivera, and Juan Caballero. 2015. Certified
PUP: Abuse in Authenticode Code Signing. In ACM Conference on Computer and
Communication Security.
[20] Chaz Lever, Platon Kotzias, Davide Balzarotti, Juan Caballero, and Manos Anton-
akakis. 2017. A Lustrum of Malware Network Communication: Evolution and
Insights. In Proceedings of the 38th IEEE Symposium on Security and Privacy. San
Jose, CA, USA.
[21] Peng Li, Limin Liu, Debin Gao, and Michael K Reiter. 2010. On Challenges in
Evaluating Malware Clustering. In International Symposium on Recent Advances
in Intrusion Detection.
[22] Martina Lindorfer, Alessandro Di Federico, Federico Maggi, Paolo Milani Com-
paretti, and Stefano Zanero. 2012. Lines of Malicious Code: Insights into the
Malicious Software Industry. In Annual Computer Security Applications Confer-
ence.
[23] Martina Lindorfer, Matthias Neugschwandtner, Lukas Weichselbaum, Yanick
Fratantonio, Victor van der Veen, and Christian Platzer. 2014. ANDRUBIS-
1,000,000 Apps Later: A View on Current Android Malware Behaviors. In Interna-
tional Workshop on Building Analysis Datasets and Gathering Experience Returns
for Security.
[24] MAEC [n.d.]. Malware Attribute Enumeration and Characterization.
http:
//maec.mitre.org/.
[25] Federico Maggi, Andrea Bellini, Guido Salvaneschi, and Stefano Zanero. 2011.
Finding Non-Trivial Malware Naming Inconsistencies. In International Conference
on Information Systems Security.
[26] Brad Miller, Alex Kantchelian, Michael Carl Tschantz, Sadia Afroz, Rekha Bach-
wani, Riyaz Faizullabhoy, Ling Huang, Vaishaal Shankar, Tony Wu, George Yiu,
Anthony D. Joseph, and J. D. Tygar. 2016. Reviewer Integration and Performance
Measurement for Malware Detection. In Detection of Intrusions and Malware, and
Vulnerability Assessment.
[27] misp [n.d.]. MISP Standard. https://www.misp-standard.org/.
[28] Aziz Mohaisen and Omar Alrawi. 2014. AV-Meter: An Evaluation of Antivirus
Scans and Labels. In Detection of Intrusions and Malware, and Vulnerability As-
sessment.
[29] Antonio Nappa, M. Zubair Rafique, and Juan Caballero. 2015. The MALICIA
Dataset: Identification and Analysis of Drive-by Download Operations. Interna-
tional Journal of Information Security 14, 1 (February 2015), 15–33.
[30] Roberto Perdisci, Andrea Lanzi, and Wenke Lee. 2008. McBoost: Boosting Scal-
ability in Malware Collection and Analysis using Statistical Classification of
Executables. In Annual Computer Security Applications Conference.
[31] Roberto Perdisci, Wenke Lee, and Nick Feamster. 2010. Behavioral Clustering
of HTTP-Based Malware and Signature Generation Using Malicious Network
Traces. In USENIX Symposium on Networked Systems Design and Implementation.
[32] Roberto Perdisci and U. ManChon. 2012. VAMO: Towards a Fully Automated
Malware Clustering Validity Analysis. In Annual Computer Security Applications
Conference.
[33] Konrad Rieck, Thorsten Holz, Carsten Willems, Patrick Düssel, and Pavel Laskov.
2008. Learning and Classification of Malware Behavior. In Detection of Intrusions
and Malware, and Vulnerability Assessment.
[34] Konrad Rieck, Philipp Trinius, Carsten Willems, and Thorsten Holz. 2011. Au-
tomatic Analysis of Malware Behavior using Machine Learning. Journal of
Computer Security 19, 4 (2011).
[35] Marcos Sebastián, Richard Rivera, Platon Kotzias, and Juan Caballero. 2016. AV-
Class: A Tool for Massive Malware Labeling. In Proceedings of the 19th Interna-
tional Symposium on Research in Attacks, Intrusions and Defenses. Evry, France.
[36] VirusTotal [n.d.]. VirusTotal. https://virustotal.com/.
[37] vtTags
list of VirusTotal
[n.d.].
Full
Intelligence
tag modifier.
https://support.virustotal.com/hc/en-us/articles/360002160378-Full-list-
of-VirusTotal-Intelligence-tag-modifier.
ACSAC 2020, December 7–11, 2020, Austin, USA
Silvia Sebastián and Juan Caballero
[38] Fengguo Wei, Yuping Li, Sankardas Roy, Xinming Ou, and Wu Zhou. 2017. Deep
Ground Truth Analysis of Current Android Malware. In Conference on Detection
of Intrusions and Malware & Vulnerability Assessment.
[39] Yajin Zhou and Xuxian Jiang. 2012. Dissecting Android Malware: Characteriza-
tion and Evolution. In IEEE Symposium on Security and Privacy.
[40] Shuofei Zhu, Jianjun Shi, Limin Yang, Boqin Qin, Ziyi Zhang, Linhai Song, and
Gang Wang. 2020. Measuring and Modeling the Label Dynamics of Online
Anti-Malware Engines. (2020).