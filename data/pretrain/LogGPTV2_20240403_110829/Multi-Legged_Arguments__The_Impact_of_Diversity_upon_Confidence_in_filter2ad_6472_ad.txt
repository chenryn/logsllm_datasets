,
|
B
A
A
)
B
=
)
B
A
|
,
(
(
P G E E
+
+
+
A
A
A
B
B
B
A
A
A
P G E E ass ass P ass ass
) (
,
,
,
,
|
P G E E ass ass P ass ass
) (
(
,
,
,
,
|
P G E E ass ass P ass ass
) (
(
,
,
,
,
|
A
A
A
A
B
B
B
A
B
B
)
)
)
B
B
B
B
)
B
the  first  and  third  terms  on  the  right  hand  side  are  zero,
because G  is  true  with  certainty,  from  leg  B,  if  the
verification,  based  on  valid  assumptions,  supports G.  So
the probability of incorrectly deciding that G is true is:
=
)
B
P G E E ass ass P ass ass
) (
(
,
,
,
,
|
B
A
A
)
B
A
|
,
(
(
P G E E
+
≤
=
|
A
P G E E ass ass P ass ass
) (
,
,
,
,
|
B
A
A
,
(
P G E ass P ass ass
α
P ass ass
B
P ass ass
) (
+
)
,
(
)
(
,
,
A
A
A
A
B
A
P ass ass
(
,
A
)
B
+
)
B
Here we have assumed, conservatively, that G is false
if the two sets of assumptions are false; and that if just assB
is false, then confidence in G depends only upon leg A.
This bound contrasts with the single argument cases (in
an obvious extension of the earlier notation):
P G E
(
|
P G E
(
|
−
+
p
A
)
p
A
≤
≤
α1
(
p
B
)
)
A
B
If  we  assume  independence  here,  the  bound  for  the
two-legged argument becomes:
α(
1 −
p p
)
A
+
B
p p
A
B
(9)
Letting pA=pB=0.1, confidence in the claim G is 98.1%,
an increase from 81% from the A argument alone, or 90%
from the B argument alone. Note, however, that this 98.1%
falls short, as would be expected, of the 100% confidence
we have when the B assumption is known to be true with
certainty.  On  the  other  hand,  it  is  better  than  could  be
attained by A alone even if we knew assA were true.
5. Discussion and conclusion
We  have  only  considered  in  this  paper  some  quite
special  examples  of  the  use  of  diverse  argument  legs.
Although further work is needed, we think that they give
us  some  insight  into  the  way  that  diverse  argument  legs
work,  and 
in
dependability claims that they can bring.
the  benefits  of  extra  confidence 
The examples show that – not surprisingly – there is
an  increase  in  confidence  about  a  dependability  claim,
when  using  a  two-legged  argument,  compared  with  the
confidence to be gained from either of the legs alone. On
the  other  hand,  it  is not easy to quantify this increase in
confidence  without  making  many  simplifying
assumptions,  such  as  independence  between  different
argument  assumptions.  Another  huge  difficulty  is  to
assign numerical values to the many different parameters
in expressions like (3) and its successors.
An issue that needs further exploration is the interplay
between ‘evidence’ and ‘assumptions’ in arguments – in
particular the trade-offs that are possible here in arriving
at  maximum  confidence  in  the  required  dependability
claim. Arguments like A and B differ in the way evidence
contributes to confidence. In a statistical argument,    like
A, it is reasonable to talk of the extensiveness of evidence:
if  the  assumptions  underpinning  such  an  argument  are
true,  the  level  of  confidence  (1-(cid:68))  in  the  dependability
claim will  depend  upon  the  nature  and  extent  of  the
evidence. For example, if we could fortuitously see more
failure-free  operation  in  test,  we  could  make (cid:68)  smaller.
This  contrasts  with  an  argument  like  B,  where  the
evidence (the proof) can only completely  support (or not)
the claim of ‘perfection’: if it does support it, then we are
certain that the claim is true (so long as the assumptions
are true with certainty).
It  may  be  that  in  some  cases  it is possible to exploit
these  trade-offs  between  evidence  and  assumptions.  For
example, if we had the luxury of choosing to structure our
argument as in Example 2 above, involving two statistical
legs, or as in Example 3, involving a deterministic proof
leg and a statistical leg, could we decide which would be
best?
Not  surprisingly, 
issues  of  dependence  (and
independence) play an important role in determining the
levels  of  confidence  that  come  from  multi-legged
arguments.  A  naïve  claim  of  independence  in  the
confidence we place in the truth of the two different sets
of  argument  assumptions  seems  unreasonable  in  this
example  for  exactly  the  same  reasons  that  Eckhardt  and
Lee [13]  first  proposed  in  the  case  of  design  diversity.
Specifically,  it  seems  likely  that  if  we  were  to  discover
that assA  were  false,  we  might  decrease  our  confidence
that assB were  true.  The  reasoning  here  is  that  the
evidence  of  assA’s  falsity  suggests  that  we  ‘do  not
understand  things  well’  in  a  general  sense.  Thus  if  we
found  out  that  our  statistical  testing  was  not  an  accurate
representation  of  operational  use,  this  might  make  us
doubt whether we had correctly captured the engineering
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
requirements  in  other  ways  -  in  particular  in  writing  a
formal  specification  against  which  to  conduct  a
verification  for  argument B.  The  detailed  mechanisms  of
commonality  here  would  presumably  concern  the
‘difficulty’  of  the  assurance  problem  (cf  Eckhardt  and
Lee),  or  errors  in  a  higher  level  description  of  what  is
required  (cf  the  common  faults  of  Knight  and  Leveson
[14]).
On the other hand, continuing the analogy with design
diversity, there is a possibility in certain circumstances of
deploying  arguments  of  forced  diversity,  as  in [11].  That
is, assumptions might be devised such that
P ass ass
(
,
A
<
)
B
P ass P ass
) (
(
A
)
B
In design diversity, such claims would generally be treated
with  justifiable  suspicion.  Is  there  any  reason  to  be  less
sceptical  in  the  case  of  diverse  argument  legs?  The
optimistic  view  would  be  that  we  might  have  a  better
understanding of the potential weaknesses of arguments –
and so be able to build ones that are complementary to one
another with respect to these weaknesses – than is the case
in systems design.
Even if this could be done, there would presumably be
a price to be paid in the amounts of evidence needed in the
individual  legs:  the  new  assumptions  would  be  of
necessity  ‘weaker’.  We  might  need,  for  example,  to
circumscribe ourselves  strongly  in  each  case  as  to  what
could  be  assumed,  in  order  to  seek  this  ‘negative
dependence’.  And  it  seems  reasonable  to  expect  that  to
support  a  claim  at  a  particular  level  of  confidence  with
weaker  assumptions  would  require  stronger  (e.g.  more)
evidence.
Example 3 shows an interesting aspect of dependence
between  legs  when  the  evidence  from  the  testing  leg, A,
includes at least one failure of the system. In this case the
testing leg completely refutes the proof leg, B: if a fault is
found in testing, of a type that the proof leg claimed was
completely  absent,  the  confidence  in  the  proof  leg  is
immediately reduced to zero.7 The result is that the multi-
legged argument is reduced to the single testing leg, which
may  or  may  not  have  sufficiently  strong  evidence  to
support the claim at the required confidence (e.g. if there
is only one failure, but 6635 failure-free demands seen in a
test, then argument A will support a claim for a pfd of 10-3
at 99% confidence [12])
Examples  like  the  ones  above  may  be  somewhat
special, inasmuch as each argument alone allows the same
claim to be made with a certain confidence – namely that
the pfd is smaller than 10-3 (even B does this), which is the
top-level claim for the overall two-legged argument. Such
examples are thus analogous to the use of design diversity
7  We  are  not,  here,  considering  what  might  be  claimed  after  the
supposed removal of this fault. It may be that the previous (flawed) proof
can be used, together with evidence of the efficacy of the fault removal,
to support a non-zero confidence that the software is now completely free
of this class of faults.
in  a  1-out-of-2  system  in  which  each  subsystem  has
similar  functionality.  It  was  this  special  structure  that
allowed  us  to  discuss  ‘dependency’  above  simply  via
confidence.  Not  all  multi-legged  arguments  have  this
useful symmetry, just as not all applications of diversity
in  system  design  are  of  the  1-out-of-n  type.  It  might  be
interesting  to  consider  other  types  of  diverse  system
design  and  see  whether  there  are  analogies  for  diverse
arguments.
There  are  many  other  aspects  of  dependability
arguments  that  could  be  explored  in  future  work.  For
example, diverse arguments may be deployed to address
some  of  the  ‘softer’  attributes  like  maintainability,
competency and trust. Can  we model these and look, for
example,  at  similar  trade  offs  between  evidence  and
assumption  doubt? Similarly,  different  stakeholders  may
have  different  confidence  in  the  evidence  provided,  so
diverse  arguments  may  have  a  role  in  building  a
consensus. Also the different legs may be shaped by  the
need  to  be  robust  to  changes  in  the  environment  and
system. All these issues are further complications: first we
need  a  sound  understanding  of  the  different  underlying
issues.
Whilst  we  have  concentrated  upon  the  analogy
between diverse arguments and diverse system design, it
is of course true that diversity exists in other contexts. In
fact  it is striking how ubiquitous notions of diversity are.
At  an  informal  level  diversity  is  taken  for  granted  to  be
effective - e.g. different forms of testing and checking of
software,  and  of  other  designs;  the  general  expectation
that  ‘two  heads  are  better  than  one’  in  any  human
judgement. It would be interesting to look at the lessons
that can be drawn from the use of diversity in these wider
human  endeavours.  After  all,  one  could  argue  that
diversity in system design and in dependability arguments
is always being used as a means to mask human failings.
There seems to have been little study of such matters, at
least  not  in  the  rather  formal  quantitative  way  that  we
require.
This paper has tentatively addressed only a small part
of  what  seems  to  be  a  large  and  difficult  problem.
Obviously, there is much research work to be done before
we have a formal model that supports the effective use of
diversity  in  dependability  arguments.  Nevertheless,  the
approach  does  seem  promising,  and  such  research  will
have  been  worthwhile  if  it  eventually  allows  us  to  say
how much our confidence in dependability claims can be
increased by the use of diversity.
6. Acknowledgements
This  work  was  partially  supported  by  the  DISPO-2
(DIverse  Software  PrOject)  Project,  funded  by  British
Energy  Generation  Ltd  and  BNFL  Magnox  Generation
under  the  IMC  (Industry  Management  Committee)
Nuclear  Research  Programme  under  Contract  No.
PP/40030532, and by the project DIRC (‘Interdisciplinary
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Research  Collaboration  in  Dependability  of  Computer-
Based Systems’) funded by UK Engineering and Physical
Sciences Research Council (EPSRC).
7. References
[1]
B.  Littlewood,  P.  Popov,  and  L.  Strigini,
“Modelling  software  design  diversity  -  a  review,”  ACM
Computing Surveys, vol. 33, pp. 177-208, 2002.
[2]
D.  M.  Hunns  and  N.  Wainwright,  “Software-
based  protection  for  Sizewell  B:  the  regulator's
perspective,” Nuclear  Engineering  International,  vol.
September, pp. 38-40, 1991.
[3]
HSE,  “Safety  Assessment  Principles  for  Nuclear
Plants,” Health and Safety Executive ISBN 011 882043 5,
1992.
[4]
MoD,  “The  Procurement  of  Safety  Critical
Software  in  Defence  Equipment,”  Ministry  of  Defence
Def-Stan 00-55, Issue 2, August, 1997 1997.
CAA, “Regulatory Objective for Software Safety
[5]
Assurance  in  Air  Traffic  Service  Equipment,”  Civil
Aviation Authority SW01, 2001.
[6]
M.  Henrion  and  B.  Fischhoff,  “Assessing
uncertainty in physical constants,” Americal J. of Physics,
vol. 54, pp. 791-798, 1986.
[7]
J. C. Knight and N. G. Leveson, “A reply to the
criticisms  of  the  Knight  and  Leveson experiment,” ACM
Software Engineering Notes, vol. 15, 1990.
[8]
G.  Guiho  and  C.  Hennebert, “SACEM software
validation,” presented at 12th International Conference on
Software Engineering, 1990.
[9]
B.  Littlewood,  “The  use  of  proofs  in  diversity
arguments,” IEEE  Trans  Software  Engineering,  vol.  26,
pp. 1022-1023, 2000.
E.  W.  Dijkstra,  “Notes  on  structured
[10]
programming,” in Structured Programming, O.-J. Dahl, E.
W.  Dijkstra,  and  C.  A.  R.  Hoare,  Eds.  London  and  New
york: Academic, 1972, pp. 1-82.
[11]
B.  Littlewood  and  D.  R.  Miller,  “Conceptual
Modelling  of  Coincident  Failures  in  Multi-Version
Software,” IEEE Trans on Software Engineering, vol. 15,
pp. 1596-1614, 1989.
[12]
B. Littlewood and D. Wright, “Some conservative
stopping rules for the operational testing of safety-critical
software,” IEEE Trans Software Engineering, vol. 23, pp.
673-683, 1997.
[13]
D.  E.  Eckhardt  and  L.  D.  Lee,  “A  Theoretical
Basis  of  Multiversion  Software  Subject  to  Coincident
Errors,” IEEE  Trans.  on  Software  Engineering,  vol.  11,
pp. 1511-1517, 1985.
[14]
J.  C.  Knight  and  N.  G.  Leveson,  “Experimental
evaluation  of  the  assumption  of  independence  in
multiversion  software,” 
IEEE  Trans  Software
Engineering, vol. 12, pp. 96-109, 1986.
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE