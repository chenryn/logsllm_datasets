propagation as well as faults. The difﬁculty is that recovery
actions have high rates compared to most failures. However,
since they are not enabled unless a failure has occurred, they
are dependent on a rare enabling condition. Latent sector
errors also partially fall into this category. While an initial
LSE is deﬁned by a locally rare rate, studies [12] have
shown that there is a period afterwords during which they
become frequent. This precondition of a recent LSE creates
a condition where an otherwise common event, is rare due
to the state in which it is common being rare.
While calculation of all rare enabling conditions is a
difﬁcult problem, we can use domain knowledge of storage
system reliability models to aid us in ﬁnding certain classes
Figure 5: Overview of solution Method
Figure 6: Model repartition after each rare event.
of rare enabling conditions. As we noted before, recovery
actions are by necessity paired with a previous fault in the
model. Without a fault, the state variables in the model
can not have values such that the recovery action can ﬁre,
and so recovery actions directly depend on rare events. By
analyzing the dependence relationships in our model we
can identify these rare events given the assumption that our
model begins with no initial faults.
B. Partitioning
We identify a certain subset ER ⊂ E as rare events, given
some partitioning scheme, as ﬁrst discussed in Section VI-A.
For the models we have studied, it has been appropriate to
assume a static partitioning parameter µmax. We select a
value for µmax based on the fact that fault events are many
orders of magnitude rarer than non-fault events. Two clusters
of rates were easily identiﬁed using k-means clustering with
two clusters. Given a value for µmax, we ﬁnd those events
ei ∈ E for which Λ(ei, q) < µmax∀q and deﬁne the set
of these events as ER. This partitioning identiﬁes those rare
events that are rare due to a locally rare rate, or competition.
VII. DECOMPOSITION
In this section we present an algorithm for decomposing
M, using the MDG generated from M, GM . M will be
decomposed into a set of n submodels Ξ = {ξ0, ξ1, . . . , ξn}
that can be considered independent in the absence of the
ﬁring of a rare event. We also discuss how to repartition M
using GM after a rare event has ﬁred, producing a new set
of independent submodels, as illustrated in Figure 5. When
visualizing our simulation as a time-line, as shown in Figure
6, we represent the ﬁring of a rare event with the symbol τ.
Each time a rare event ﬁres, it results in a reevaluation of our
decomposition of M, represented in Figure 5 as τ. Given a
model and a set of reward variables, we generate an MDG
and a set of identiﬁed rare events, ER. Using the MDG, GM ,
the set of rare events, ER, and the current values of all state
variables in the model M, we produce a decomposition of
s0e2s0e2e2s0r0s0r0e2−dependence∆ΛΦ∆RR}Reward dependenceExternal dependenceRate dependencea)b)c)d)e)ModelVariablesRewardIdentifyRare EventsModelGraphDependenceDecompositionDecomposedSubmodelsSimNumτSolve for nextΞsimΞnumτττAlgorithm 1 Remove rare-event-based dependencies from
G(cid:48)
M .
M = (V (cid:48), A(cid:48), L(cid:48)) ← GM
G(cid:48)
P ← ER
while P (cid:54)= ∅ do
Remove all edges in A(cid:48) containing at least one vertex in P .
Do not remove vertices with edges labeled Φ or Λ if the vertex
is in ER.
P ← ∅
for all vi ∈ V (cid:48)
if !∃vivj ∈ A(cid:48) such that vivj has label ∆ then
S do
V (cid:48) ← V (cid:48) \ vi
Create a new constant vertex vci ∈ VC
V (cid:48) ← V (cid:48) ∪ vci
Associate a value equal to the initial marking of si ∈ S
associated with vi with vci
if ∃vi|vivj ∈ A(cid:48) labeled Φ such that vi ∈ VC then
if !∃q consistent with the constant markings associated
with vertices in VC and Φ(ej, q) = 1 then
end if
if ∃vi|vivj ∈ A(cid:48) labeled Λ such that vi ∈ VC then
if !∃q consistent with the constant markings associated
with vertices in VC and Λ(ej, q) (cid:54)= 0 then
end if
P ← P ∪ vj
end if
end for
for all vj ∈ V (cid:48)
E do
P ← P ∪ vj
end if
end if
end for
V (cid:48) ← V (cid:48) \ P
end while
i , A(cid:48)
i = (V (cid:48)
i such that v(cid:48)
our technique is not applicable. The sub-graphs of G(cid:48)
M
correspond to the submodels in our partition Ξ. For a given
sub-graph, g(cid:48)
i), for each v(cid:48)
i such that
j ∈ VS, we add the corresponding state variable to ξi. For
v(cid:48)
j ∈ V (cid:48)
j ∈ VE, we add the corresponding
each v(cid:48)
event to ξi. In addition, for each ξi ∈ Ξ we restrict the
deﬁnitions of Φ(ej, q), Λ(ej, q), and ∆(ej, q) to ej ∈ ξi
and q ∈ N1, N2, . . . , N|Sξi| such that Sξi ∈ ξi. An example
decomposition of a small model is is shown in Figure 7.
j ∈ V (cid:48)
A. Mitigation, Recovery, and Propagation Events
In Section VI we mentioned that by using methods dis-
cussed in this section, we would be able to ﬁnd mitigation,
recovery and fault propagation events. Through execution of
Algorithm 1 on M, with state variables set to represent an
initially fault-free model, removing state variables and events
in the manner described by Algorithm 1, it is guaranteed that
recovery, mitigation and propagation events will be removed.
This is due to the fact that the fault associated with those
actions have yet to occur. Since recovery, mitigation and
propagation actions have a direct correspondence with faults
in the system (giving them their rare enabling conditions),
in the absence of a fault, their enabling conditions cannot
(a) Composed Model
(b) Decomposed Model
Figure 7: Example decomposition of a model dependency
graph GM to G(cid:48)
M .
the model M into a set of submodels ΞR and Ξ!R. From
ΞR, Ξ!R, and the subset ΞER ∈ Ξ of all submodels (in both
ΞR and Ξ!R) that contain events in ER, we produce two
new sets of submodels:
ΞSim = ΞR ∪ (Ξ!R ∩ ΞER)
ΞNum = Ξ!R \ (Ξ!R ∩ ΞER).
(4)
(5)
The submodels in the sets ΞSim and ΞNum will then be
passed to an appropriate solution method and solved until a
rare event ﬁres, at which point we repeat the decomposition
step based on the new state of the model.
By decomposing our model
in this fashion, we hope
to remove from consideration events for which there is
no current direct or indirect dependency from our reward
variables in the absence of a rare event ﬁring. In order
to form this decomposition, however, we must analyze the
dependencies in GM , and from the results of that analysis
form a decomposed model dependency graph G(cid:48)
M that can
be used to identify a submodel decomposition of M. We
form a decomposed model dependency graph G(cid:48)
M for M
by ﬁrst removing all ∆-dependencies that involve events in
ER. For every vertex associated with a state variable whose
only ∆-dependencies involve events in ER, we replace those
vertices with new vertices from a set VC, which represent
constant state variables whose values are equal
to their
initial conditions. All vertices that represent events with rates
dependent on state variables that are now represented by
constant vertices are examined. If such events have transition
rate function speciﬁcations such that Λ(e, q) = 0 for all
q ∈ N1×N2× . . .×Nn given VC, or have enabling function
speciﬁcations such that Φ(e, q) = 0 for all q given VC,
they are removed. All dependencies of removed events are
also removed. The process is repeated, examining all VS
and VE iteratively until no new vertices are removed. This
process for generating G(cid:48)
M using GM and ER is presented
in Algorithm 1.
The graph G(cid:48)
M that results from the application of Al-
gorithm 1 to GM and ER is then used to determine if a
valid partition of the model M exists for our technique.
If G(cid:48)
M =
{g(cid:48)
1 ∪ . . .}, a valid partition exists. If it does not,
M deﬁnes multiple unconnected sub-graphs, G(cid:48)
0 ∪ g(cid:48)
sseeessseeeer0100216543234∆∆ΦΦΦΦ∆∆Λ∆RR∆∆∆∆Φsseeesseeeer0100216543234∆∆ΦΦΦ∆Λ∆RR∆∆Φc}{{G’G’G’012be met by the constant placeholders we use to represent the
effects of a fault event’s ﬁring. Thus those events will be
removed during our decomposition step.
When Algorithm 1 is used, the set of all events added
to P is the set of fault events in ER plus any events that
depend on ER; that represent recovery, mitigation, or fault
propagation; and that are added to ER when our model is
being decomposed and solved during simulation.
B. Analyzing Reward Variable Dependencies
Reward variable dependencies prevent decomposition of
otherwise independent sub-graphs by maintaining connectiv-
ity based on reward dependence and help us choose solution
methods for submodels in Ξ.
Proposition 1. In the absence of the ﬁring of a rare event,
the reward variable θi is independent from a submodel ξj
if no direct dependence exists in G(cid:48)
M from θi to a vertex in
g(cid:48)
j.
Proof: If a direct dependence existed between a reward
variable θi and a state or event in ξj then G(cid:48)
M would have
an edge connecting θi to a vertex in g(cid:48)
j, and a path would
exist. If there were an indirect dependency between θi and
a vertex in g(cid:48)
j, then a path would exist between a vertex
vk that has a direct dependency with θi and a vertex in g(cid:48)
j.
Then vk would be a vertex in g(cid:48)
j, and θi would have an edge
connecting directly to a vertex in g(cid:48)
j.
M , we divide all submodels in Ξ deﬁned by the
independent sub-graphs of G(cid:48)(cid:48)
M into two sets: those upon
which reward variables do and do not depend in the absence
of rare events. These sets of submodels are called ΞR and
Ξ!R, respectively.
Given G(cid:48)
VIII. SOLVING THE DECOMPOSED MODEL
We present in this section an algorithm for hybrid simu-
lation of decomposed models, and a discussion of comple-
mentary solution methods from the literature. Our hybrid
simulation algorithm was designed to help us study the
dependability characteristics of deduplicated data storage
systems.
A. Hybrid Simulation of Rare-Event Decomposed Systems
Our study of rare-event-based decomposition methods was
motivated by a desire to study the dependability character-
istics of storage systems that utilize data deduplication, in a
fault environment characterized by rare events. In order to
estimate the value of reward variables deﬁned for models
of these systems, we have employed our decomposition
methods and a hybrid simulation algorithm.
When solving our model, we view trajectories of model
execution as a time series τ0 −→ τ1 −→ τ2 −→ τ3 −→ . . .
where τ0 represents our start time, and each subsequent τi
represents the ﬁring of a rare event. The set ΞSim contains
all submodels that contain either a rare event or a reward
Algorithm 2 Hybrid Simulation of M
Given M, ΘM , GM and initial values for all state variables.
while ΘM not converged do
M and Ξ from GM .
Generate G(cid:48)
Derive ΞSim and ΞNum.
Simulate ΞSim until the next event is in the set ER.
Generate π∗
Generate a random state for ξi ∈ ΞNum treating π∗
pmf of the random variable.
Recompose M. Simulate the next rare event in M.
Use current state of M as the next initial state.