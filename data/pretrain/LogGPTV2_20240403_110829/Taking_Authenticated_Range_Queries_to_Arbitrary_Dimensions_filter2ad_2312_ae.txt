πPi,j,l were indeed computed by the owner speciﬁcally for bucket
Bi,j; this is conceptually similar to their usage in the basic scheme.
We explain the proof construction and veriﬁcation process using
Figure 6, focusing on Ri. In our example, Ri fully covers buckets
Bi,κ(cid:48)+1, . . . , Bi,κ, and partially covers buckets Bi,κ(cid:48) and Bi,k+1.
Observe that we can decompose Ri into three sets, let 1(cid:13), 2(cid:13), 3(cid:13)
(so that we alleviate our notation and allow an easy reference to the
ﬁgure), such that Ri = 1(cid:13) ∪ 2(cid:13) ∪ 3(cid:13) and 1(cid:13), 2(cid:13), 3(cid:13) are pairwise
disjoint (the importance of the latter property will become clear
in Section 5.2). Observe also that 1(cid:13) = Pi,κ(cid:48),k \ Pi,κ(cid:48),k(cid:48), 2(cid:13) =
Pi,κ \ Pi,κ(cid:48), and 3(cid:13) = Pi,κ(cid:48)+1,k. Therefore, the server builds the
, πPi,κ,
proof π by including proof components πPi,κ(cid:48),k, πPi,κ(cid:48),k(cid:48)
, πPi,κ(cid:48)+1,k. Moreover, it includes (i, j, πPi,j ), τPi,j,l, their
πPi,κ(cid:48)
proper proofs from SMA(cid:48)
i,SMAi,j,SMAi,SMA, as well as
π 1(cid:13) = acc( 1(cid:13)), π 2(cid:13) = acc( 2(cid:13)), π 3(cid:13)=acc( 3(cid:13)). With all the above,
the client can verify that π 1(cid:13), π 2(cid:13), π 3(cid:13) are the truthful proofs for
sets 1(cid:13), 2(cid:13), 3(cid:13).
The client next needs to combine π 1(cid:13), π 2(cid:13), π 3(cid:13) in order to ver-
ify that proof πRi = acc(Ri), also included in the ﬁnal π by the
server, indeed corresponds to the Ri that is the union of 1(cid:13), 2(cid:13),
3(cid:13). After that point, the client can proceed to prove the ﬁnal re-
sult R in an identical way to the basic scheme. For this particular
task, we utilize our own customized set union sub-protocol, which
is included in Section 5.2. This sub-protocol is motivated by sim-
ilar reasons that motivated our set-difference sub-protocol in Sec-
tion 4.3; we need it to be executed in time ˜O(|Ri|), and be secure
under standard cryptographic assumptions. What enables us to do
this is the extra constraint that the participant sets must be a priori
proven pairwise disjoint. At a high level, its ProveUnion routine
outputs a proof π∪ on input sets 1(cid:13), 2(cid:13), 3(cid:13), which later facilitates
the VerifyUnion routine invoked on π 1(cid:13), π 2(cid:13), π 3(cid:13), πRi.
Figure 6: Representation of Ri through sets
√
Consider that tuple t is inserted in bucket Bi,j (deletions are han-
dled similarly). This insertion affects all b bucket preﬁxes in the
worst case, and all n/b hash preﬁxes in Bi,j. It is important to ob-
serve that t does not affect any hash preﬁx of any other bucket; in
√
that sense, the buckets isolate the effect of the update within their
n · m)
boundaries. Setting b =
preﬁxes in overall, each with a single exponentiation. Moreover,
it should propagate the changes of the corresponding proofs inside
the SMA structures, whose cost is asymptotically the same as in
√
the case of the basic scheme. Therefore, the total update time in this
construction reduces from O(n·m) to O(
n·m). Interestingly, the
asymptotic complexities of all other algorithms and the proof size
remain unaffected. However, the absolute costs slightly increase
n, the owner must update O(
due to the extra bucket preﬁxes, as conﬁrmed by our experiments
in Section 6. Due to space limitations, we delegate the security and
correctness proofs, as well as the detailed algorithm descriptions
and complexity analysis to the long version of our work.
5.2 A Set Union Sub-protocol
We present a sub-protocol for proving the correctness of a union
operation among a number of sets Xi under the constraint that they
are pairwise disjoint. We focus on the case of three input sets, as
this is the way it is utilized in Section 5. The sub-protocol consists
of two routines, ProveUnion and VerifyUnion. The former receives
sets X1, X2, X3, and outputs a proof π∪ for the integrity of the
union operation X = X1 ∪ X2 ∪ X3. The latter receives succinct
descriptions πX1 , πX2 , πX3 , πX of X1, X2, X3, X, respectively,
as well as a proof π∪, and returns accept if X is the union of the
three sets, and reject otherwise. We provide the pseudo codes of
the two routines below.
Algorithm ProveUnion(X1, X2, X3, pk)
1. Output π∪ = acc(X1 ∪ X2)
Algorithm VerifyUnion(πX1 , πX2 , πX3 , πX , π∪, pk)
1. Verify e(πX1 , πX2 ) = e(π∪, g)
2. Verify e(π∪, πX3 ) = e(πX , g)
3. If veriﬁcation in Lines 1-2 fails, return reject, else return accept
Similar to the set-difference sub-protocol, these routines are mean-
ingful only as part of a SOA scheme based on bilinear accumu-
lators. ProveUnion runs in time ˜O(|X1| + |X2| + |X3|). For
VerifyUnion, it is the responsibility of the caller to check that πX1,
πX2, πX3 are the accumulation values of pairwise disjoint X1, X2,
and X3, prior to calling the routine. Its cost is O(1) pairings.
6. EXPERIMENTS
We performed our experiments on a 64-bit machine with Intel
Core i5 CPU 2.5GHz, running Linux. We measured the perfor-
mance of all schemes implementing the necessary cryptographic
primitives in C++, using the following libraries: DCLXVI [2] for
fast bilinear pairing computations, Flint [3] for modular arithmetic,
and Crypto++ [1] for SHA-256 hash operations. DCLXVI employs
a 256-bit BN elliptic curve and an asymmetric optimal ate pairing,
offering bit-level security of 128 bits. We represent elements of G1
with 768 bits using Jacobi coefﬁcients, which yield faster opera-
tions. Elements in G2 are roughly twice as large as those of G1.
We chose an asymmetric pairing for efﬁciency reasons, but we note
that this choice does not introduce any redundancy to our schemes
as presented with symmetric pairings. We instantiate all SMAs
with Merkle trees [19] and bilinear accumulator trees [22]. Table 2
summarizes all primitive costs involved in our schemes.
Operation
Exp. in G1 / G2
Mult. in Zp / GT
SHA-256 / Bilinear pairing
Quicksort in Zp
Acc. in G1
Acc. in G2
Polynom. Mult in Zp[r]
XGCD in Zp[r]
Cost
0.55 / 0.94 ms
7 µs / 0.09 ms
5 µs / 1.41 ms
0.1 / 0.9 / 4.6 ms
25.3 / 236 / 2, 628 ms
32.6 / 338 / 3, 471 ms
0.4 / 7.3 / 92.9 ms
8.4 / 599 / 108, 093 ms
(100/1000/10000 elems.)
(100/1000/10000 coeffs.)
–(cid:113)–
–(cid:113)–
–(cid:113)–
Table 2: Costs of primitive operations
We test four possible conﬁgurations: (i) our basic scheme with
Merkle trees (Basic-Mer), (ii) our basic scheme with accumula-
tor trees (Basic-Acc), (iii) our update-efﬁcient scheme with Merkle
h3Bi,κ′Bi,κ+1...Bi,κ′+1Pi,κ′Pi,κ......h4h5h6......Bi,κPi,κ′,k′Pi,κ′,kPi,κ′+1,kRi1!2!3!827trees (UpdEﬀ-Mer), and (iv) our update-efﬁcient scheme with ac-
cumulator trees (UpdEﬀ-Acc). For each conﬁguration, we assess
the performance at the client, owner and server, varying several pa-
rameters. We run each experiment 10 times and report the average
costs. Note that the performance of all schemes does not depend on
the data distribution, but rather on the table schema and the result
selectivities, hence we chose to use synthetic data in our evalua-
tion. We stress that our goal here is not to construct an optimized
prototype, but rather to demonstrate the feasibility of our schemes.
As such, we have left numerous optimizations regarding database
storage and query handling as future work.
Client. Figure 7 depicts the veriﬁcation cost at the client. This
overhead is mainly affected by the result size |R| and the number
of query dimensions d. Figure 7(a) shows the CPU time (in ms)
as a function of |R|, ﬁxing d = 32, n = 106 and m = 64. The
veriﬁcation cost increases with |R| in all schemes. Basic-Mer is
the fastest for |R| ≤ 1, 000. This is because the Merkle-based
schemes are faster than the accumulator-based ones, as they entail
hash operations for the SMA proofs, which are much cheaper than
the pairings needed in accumulation trees. Moreover, the overhead
in the update-efﬁcient schemes is slightly larger than that in their
basic counterparts, due to the extra proof veriﬁcations of the bucket
preﬁxes and the taller SMA hierarchy. Nevertheless, observe that,
for |R| = 10, 000 the performance of all schemes converges. The
reason is that the computation of πR = acc(R) that is common to
all techniques becomes the dominant factor, which effectively hides
the costs of the SMA proofs and all set-operation veriﬁcations.
Figure 7(b) illustrates the CPU time versus d, when |R| = 1, 000,
n = 106 and m = 64. The performance of the schemes is qual-
itatively similar to Figure 7(a) for the same reasons. Once again,
all costs increase linearly with d because the veriﬁcation overhead
of the set-differences and intersections is also linear in d. However,
the effect of d on the total CPU time is not as signiﬁcant as that
of |R|, since the common accumulation cost for R emerges as the
dominant cost when |R| = 1, 000. In both ﬁgures, the veriﬁcation
time for all constructions is between 20 ms and 3.36 seconds.
(a) Time vs. |R|
(b) Time vs. d
Figure 7: Veriﬁcation overhead at client
Table 3 includes the proof sizes for the four schemes when vary-
ing d. We make three observations. First, all sizes increase with d,
since the proof includes components for every dimension. Second,
the basic schemes have smaller proofs than their counterparts, again
because of the extra bucket preﬁx proofs and taller SMA hierar-
chy. Third, although Basic-Acc outperforms Basic-Mer , this is not
true for UpdEﬀ-Acc and UpdEﬀ-Mer. This is because, although
accumulators provide asymptotically smaller proofs than Merkle
trees, this does not hold in practice for the database sizes we tested.
Overall, the proofs for all schemes are quite succinct, ranging from
4.5 to 153.5 KBs, which are independent of the result size that
could easily be in the order of MBs.
d
Basic-Mer
Basic-Acc
UpdEﬀ-Mer
UpdEﬀ-Acc
2
4.5
3.6
9.2
9.6
4
9.1
7.2
18.4
19.2
8
18.1
14.3
36.9
38.4
16
36.3
28.8
73.8
76.8
32
72.5
57.5
147.5
153.5
Table 3: Proof size in KB (n = 106, m = 64)
Owner. Figure 8 assesses the performance of the owner for the
setup stage (which includes the key generation), and updates. In this
set of experiments, we focus only on the Merkle-based schemes that
have a clear performance advantage over the accumulator-based, as
evident also from our evaluation for the client above. Figure 8(a)
plots the pre-processing cost when varying n and ﬁxing m = 64.
Naturally, the overhead increases linearly with n in both schemes.
This overhead is dominated by the computation of πPi,j for all i, j,
which completely hides the sorting and hashing costs (see also Ta-
ble 2). As expected, UpdEﬀ-Mer is more than twice as slow as
Basic-Mer. Although the pre-processing time can reach up to three
hours for n = 106, recall that this is a one-time cost for the owner.
(a) Setup time vs. n
(b) Update time vs. # updates
Figure 8: Setup and update overhead at owner
is (cid:80)d
Figure 8(b) evaluates the update time as a function of the number
of updates performed in a single batch operation, where n = 105
and m = 64. Note that we report the respective worst case in both
schemes. For Basic-Mer, the CPU time is practically unaltered and,
in fact, is as bad as the setup overhead. On the contrary, UpdEﬀ-
Mer is greatly beneﬁted by the bucket isolation and becomes up to
more than two orders of magnitude more efﬁcient than Basic-Mer.
As the number of updates in the batch increase, the performance
gap between the two schemes closes, since the updates in the batch
are likely to affect more buckets. For the tested settings, the update
time ranges between 30 seconds and one hour.
Server. Figure 9 reports the proof generation time at the server.
As explained in our complexity analysis, the dominant factor here
i=1 |Ri|. Therefore, due to the lack of real-world data and
query workloads, it sufﬁces to vary |Ri| and ﬁx it across all dimen-
sions, rather than varying d and setting an arbitrary partial result
size per dimension. Figure 9 depicts the CPU time at the server,
when varying |Ri| and setting n = 105, m = 64, d = 32 and
|R| = 0.1·|Ri| (i.e., 10% of a 1-dimensional result). At every point
of the curve, we also provide the percentages of the three dominant
computational costs, namely the construction of Wi, Fi (for the in-
tersection proof) and πRi. The performances of two schemes differ
marginally. This is because the generation of the extra set union
proof of UpdEﬀ-Mer incurs negligible cost compared to the large
burden of computing the three types of elements mentioned above.
The most interesting observation is that, for |Ri| = 10, the cost
for Wi is 51% and for Fi is 15%, whereas for |Ri| = 10, 000,
the two costs become 7% and 87%, respectively. This is because
computing Fi requires running the Extended Euclidean (XGCD)