posted by account j on app i. nw is the total number of reviews
posted by the worker to app i. ASO worker F7 (left) shows a nearly
perfect lockstep behavior with the same set of 15 accounts used for
almost all the 40 apps, and in the same order. We also see attempts at
“variation”: F7 uses his accounts in exact reverse order to promote
app 5. Further, for several sets of apps (black rectangles in Figure 10),
F7 does not use the same set of accounts, and uses all his other
accounts in the same order.
However, 14 participants exhibit less pronounced lockstep be-
haviors, e.g., F36 (Figure 10 right). Out of 121 apps reviewed, in only
two apps, F36 used more than 50% of the 17 accounts he revealed.
Summary. 6 out of 18 interview participants claimed lockstep-
indicative behaviors; 25 of the 39 quantitative study participants
exhibit lockstep behaviors, some even using their accounts in the
same order to review multiple apps. This is consistent with and
provides evidence for assumptions made in previous work, e.g., [32,
48, 59, 77, 81, 86, 93, 94, 97, 100].
However, we also report claims (8 of 18 participants) and evi-
dence (14 of 39 participants) of random account and device choice.
We conjecture that ASO workers may adopt evasion strategies, e.g.,
by using di(cid:29)erent sets of accounts for di(cid:29)erent jobs, and use organic
workers, less likely to be frequently active at the same time.
5.9 Timing: Fraud Event Points
Early bird fraud. 14 participants said that they have worked on
recently launched apps, and either the hiring developer mentions
that the app was recently launched, or that they infer this infor-
mation based on the app status when posting their (cid:27)rst review.
Declared numbers range from 1–2 jobs in the past month (P1, P11)
to 20–40 (P9, P10, P13). P7 said that “We even work on apps which
are going to be launched soon. A few of our clients rely on our agency
from pre-launch to launch and then post-launch.”
Re-hires. All 18 participants claimed to have been re-hired for apps
that they previously promoted (total times M = 186.1, SD = 190.7,
Min = 15, Max = 600). P1 said that “If the app is getting bad reviews,
the developer will hire us again to get good reviews. We have seen this
case for minimum 30 to 40 apps per year.” P12 said “I have around 20
regular clients. They hired me for the same app, around 40–50 times.”
Further, all of the 18 participants claimed to have regular customers,
who hire them to promote multiple apps.
Figure 10: Lockstep matrices for F7 (left) and F32 (right).
Rank (color) indicates the order in which an account was
used to review an app. F7 exhibits strong lockstep behaviors,
having used almost all his revealed 15 accounts to review all
the 40 apps (exceptions shown within black rectangles). F32
however exhibits less obvious reviewing patterns.
However, P5 and P9 claimed to only provide one review from one
device for an app. P15 and P16 keep track of which accounts they
use to log in to any device, and once they log out from one account,
they wait 7–10 days before they use it again.
P5 claimed to use a (cid:27)xed set of 2–3 accounts to log in to one
device at a time, then uses those accounts to review multiple apps.
However, he also claimed that he only provides one review from
one account for an app. P6 said that he instructs his remote workers
to log in to at most 2 accounts from any device (at a time), however,
they can review the target app from both accounts. P7 mostly use 2–
3 accounts from a device for safety. P8 claims to login to 5 accounts
on his device, and his Whatsapp group members log in to 3–5
accounts per device. P9 claims that he has logged into 4 accounts
in a device, but he does not allow his workers to post more than
one review from any device.
Summary. ASO workers generally claim that it is possible to re-
view an app from di(cid:29)erent accounts using the same device. We
have tested this claim and veri(cid:27)ed that it works as suggested. This
vulnerability facilitates the creation of fake reviews by reducing
the amount of resources needed from the ASO worker.
5.8 Lockstep Behaviors
Interview participants revealed di(cid:29)erent strategies to choose which
of their accounts and devices to use for a job. Several participants
revealed lockstep-indicative behaviors, based on a spreadsheet of
accounts and devices that they maintain across all their jobs. P5, P7,
P10, P13, P18 select the devices in a sequential, round-robin manner,
while P5, P7, P13, P15, P16, P18, select the accounts sequentially. For
instance, P15 claimed that “We have statistics on how many times an
account was used previously. From there we try to (cid:27)nd accounts that
have been used fewer times. We also track which device was used for
which account, so next time we use the same device for that account.”
Others however claimed non-lockstep indicative behaviors. 7 of
the 18 participants (P6, P8, P9, P11, P12, P14, P17) claimed a random
choice of accounts and devices, including made by their remote
online employees. P16 claimed to monitor the reviews (cid:27)ltered, and
choose accounts based on their (cid:27)lter avoidance success rate.
Session 10D: Mobile SecurityCCS ’19, November 11–15, 2019, London, United Kingdom2446(a)
(b)
(c)
We call the inactive intervals of an ASO worker for an app, to be
the time di(cid:29)erences between consecutive reviews that he posted to
that app, from accounts that he controls. Figure 11(b) shows the per-
worker distribution of the maximum inactive interval computed
over each app that the worker reviewed from accounts that he
controls. We show only the workers with enough points to compute
statistics. 8 workers have very short inactive intervals, thus are
more intensively active for the apps that they target. However, ASO
workers such as F3, F24, F32 and F33, have longer inactive intervals,
suggesting rehiring. For instance, we found 16 cases where the
worker was inactive for more than 8 months for an app.
Figure 11: (a) Relative likelihood for the time di(cid:29)erence between launch time and reviews by ASO workers, for 585 apps that
received at least 10 fraudulent reviews. Vertical dashed line is the median. (b) Per-worker distribution of the maximum inactive
interval measured in days for each targeted app. 8 participants, e.g., F7 and F9 are intensely active, however, F3, F24, F32 and
F33 exhibit more evidence of later rehiring. (c) Density function of number of jobs received by ASO workers from the same
developer. One worker worked on 38 apps of the same developer. The vertical dashed line corresponds to the median value.
provide review samples, from which they are supposed to generate
Quantitative Investigation. Figure 11(a) plots the time di(cid:29)erence
variations. 3 participants (P7, P8, P15) said that they either prefer
in days, between the app launch time and the posting time of
or even ask the developer to provide the review text. P3 and P13
each review from a fraudulent account controlled by any of the 39
participants in the quantitative study (§ 4.2), over the 585 apps that
said that they study the app before writing the review. P13 claimed
to ask the developer to provide the app’s main features, which he
received at least 10 fraudulent reviews in total. The distribution is
left-skewed, with 50% of the reviews being posted after less than 3
uses to fabricate reviews.
Review posting process. The participants revealed a mixed strat-
months after app launch. However, we observe cases where the (cid:27)rst
egy of typing the reviews directly on the device, vs. cut-and-pasting
reviews from any of the accounts of our 39 participants, are posted
long after the app was released: the median and 3rd quartile are
them from a separate source. 11 of the 18 participants said that they
113 and 344 days respectively. Thus, about 25% of the fake reviews
type the reviews directly from their devices. For instance, P5 said
that they cut-and-paste reviews if provided by the hiring developer,
were written after one year.
otherwise they type their own (short reviews). However, P7 noted
that most devices do not allow cut-and-paste. Several participants
organize teams of remote ASO workers, thus stated that they are
not aware of their review-typing actions.
Review plagiarism: 8 participants (P1, P3, P5, P12, P13, P14, P15,
P18) denied plagiarism and self-plagiarism. P2, P4, P6, P9, P11 and
P17 however admitted to some form of plagiarism. P2 blamed it
on developers: “Yes, sometimes we copy, but only if buyers mention
the source, for example, apps hosted in other sites.” P4 said that “we
don’t copy-paste. But our reviews are short and sometimes similar.”
P16 said “We have a review data set, and we use those reviews for all
apps. Sometimes we change a the reviews bit for di(cid:29)erent apps.” P9
said that “Not exact copy-paste. But sometime we copy and modify
reviews from other apps that are similar.” P12 also complained about
some organic users, who are careless and write random comments,
e.g., “nice game” for a non-game app.
Review length: 11 participant claimed that their reviews exceed
10 words (10–40). P3 and P4 admitted that their reviews are short
(3–5 words). P4 motivated this choice: “We don’t use many words
or big sentences because Google may match the pattern. We always
use short messages like “Good app”, “Awesome”, “Fantastic”. These are
very common but easy to write and Google may not complain.” P6
argued that “if you write too long reviews, they will certainly look like
paid reviews, because real users don’t have time to post a paragraph.”
Quantitative Investigation. Figure 12 shows the empirical CDF
of the review word count over all the reviews posted by the 39
participants, and also only for F7 and F26, who wrote 542 and 771
reviews respectively, and are the ASO workers with the most distant
CDFs from one another: P(Len❕th ≤ 10|F7) = 0.88 (cid:29) P(Len❕th ≤
10|F26) = 0.06. The overall fake review word count CDF is closer
to F7, with the overall P(Len❕th ≤ 10) = 0.63.
Further, we identi(cid:27)ed exact review duplicates among the 21,767
reviews posted by the 39 participants (§ 4.2), and sorted them by
Figure 11(c) plots the density function of the number of apps
uploaded by the same developer, and reviewed by the same worker,
over the 39 workers of the quantitative investigation. We observe
that the mean number of jobs assigned is 3.48, and 7 workers have
been hired by the same developer more than 10 times. We found
one developer that hired 6 workers to each promote at least 10 apps.
Summary. Our qualitative and quantitative studies provide ev-
idence con(cid:27)rming observations and assumptions made in previ-
ous work, that (1) ASO workers tend to be hired early after app
launch, or even before launch, to control review sentiment, see
e.g., [38, 53, 61, 63, 64, 96, 100] and (2) developers rehire some of
these workers at later times, when honest feedback reduces the
product rating [53].
5.10 Review Writing
We asked interview participants about, and report (cid:27)ndings on the
source of review text, plagiarism, and review length:
Review text source. 2 participants (P3, P4) said that they always
write their own reviews. The other participants said that they both
receive or request the review text from the developer, and they
also write their own reviews. P2 said that they receive instructions
about the reviews from the developer. P11 reported developers who
Session 10D: Mobile SecurityCCS ’19, November 11–15, 2019, London, United Kingdom2447rating goes up to 4.3 or 4.4, I also write a few 3-star reviews.” P7 said
that “when posting more than 200 reviews, we suggest to the client to
have at least 5 to 6 reviews with 3 star ratings.” P15 claimed to post a
10%-30%-70% ratio of 3, 4, 5-star reviews.
Negative campaigns. When asked if they were ever hired to post
negative (1-2 star) reviews, and how many such jobs they worked on,
only two participants said that they participated in such negative
review campaigns. P3 had participated in only one such job, but
later morally objected to it, while P4 also admitted to have worked
on only a few such jobs (5-7). The other participants said that
they never participated in negative campaigns. We did not ask
participants how many such campaign jobs they have seen.
The gold standard fraud data we collected from 39 participants
con(cid:27)rms that 95.52% of the 21,767 reviews posted from the accounts
they control, were either 4 or 5 stars. Only 1.67% were 3-star and
2.81% were 1 or 2 star reviews.
Summary. Both interview participants and gold standard fraud
data reveal the prevalence of positive ratings. This con(cid:27)rms obser-
vations and assumptions made in previous fraud detection work,
e.g., [24, 51, 52, 63–65, 74, 93, 94]. However, we found that nega-
tive review campaigns (or negative ratings) are unpopular. Further,
several interviewed participants reported rating-level detection eva-
sion strategies, e.g., the sprinkling of neutral and negative ratings,
among positive reviews.
5.12 Proof of Work
After ASO workers (cid:27)nish their jobs, it is expected for developers to
ask for proof of work. 12 participants said that they use screenshots
of their reviews. 5 participants said that they send the usernames
of accounts that they used to post reviews. P6 claimed “I check my
reviews for 2–3 days and then send the permalinks that are direct
links of the review I post, or names I used to post the reviews.”
Team-level veri(cid:27)cations. Work veri(cid:27)cations can take place at the
team level. For instance, P3 said that “[..] we ask everyone to post
reviews in the team. Then I track how many reviews we provide and
they also send me the screenshot. If the buyer requires the screenshots
I send him those too.” P6 said that “If we get a report that any review is
being deleted then we check that user’s mobile and ask him to provide
a screenshot of the app installed immediately. If he fails to provide
that, I (cid:30)ag him as a bad user and we consider him less for the next
tasks.” P9 also verify that their team members do not post multiple
reviews from the same device, by looking at the screenshots sent.
Follow-up. P3 said that “Sometimes, the developer keeps track of the
reviews we post, and gives us 24 hours to show that the reviews are
alive. If any review is deleted during this time, we have to re-post the
reviews.” P7 claim to provide guarantees of reviews sticking for 5–7
days and re(cid:27)ll deleted ones for free.
5.13 Account Creation
13 of the 18 interview participants, mentioned use of fake name
generators, e.g., [6], to name their user accounts. Some of them
create account names to correspond to speci(cid:27)c geographic regions,
as sometimes also requested by developers. P2 even claimed to send
the chosen names to the employer for feedback. P11 claimed to use
random names from Google search and P7 said that they have their
own name database. P4, P7 and P14 said that their use of organic
ASO workers, ensures that they use real user names.
Figure 12: Empirical CDF for two extreme behaviors shown
by two participants. All other workers have their corre-
sponding CDF between these two curves and are not dis-
played for better visualization. We note that P(Len❕th ≤
25|F3) = 0.99 (cid:29) P(Len❕th ≤ 25|F26) = 0.46, and the all-worker
ECDF is closer to worker 7 who writes shorter reviews.
the geometric mean between the number of ASO workers who
have written the review and its overall frequency. An advantage of
the geometric mean is that it gives a balance between two quanti-
ties that are in di(cid:29)erent ranges. 993 reviews were empty (154.37).
The next 10 most repeated reviews ordered by geometric mean
were “good” (30.51), “Good” (27.42), “nice” (20.63), “Love it” (15.19),
“app” (13.71), “Excellent” (13.26), “Awesome” (12.64), “Like it” (11.83),
“Nice app” (11.18), “Great app” (10.95). We note that these reviews
are short, generic, and app-agnostic. This analysis validates the
survey answers by some ASO workers, that short reviews may be
preferable since long reviews may trigger Google’s defenses and
block their content.
Summary. Most interviewed participants said that the text of the