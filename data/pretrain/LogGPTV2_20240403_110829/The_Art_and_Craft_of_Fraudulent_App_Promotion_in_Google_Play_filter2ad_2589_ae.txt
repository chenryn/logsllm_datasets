### 5.8 Lockstep Behaviors

**Account and Device Usage Patterns:**
- **F7's Behavior:** ASO worker F7 demonstrates a nearly perfect lockstep behavior, using the same set of 15 accounts for almost all 40 apps in the same order. In one instance, F7 uses the accounts in exact reverse order to promote app 5. For several sets of apps (indicated by black rectangles in Figure 10), F7 does not use the same set of accounts but follows the same order with his other accounts.
- **F36's Behavior:** In contrast, F36 exhibits less pronounced lockstep behaviors. Out of 121 apps reviewed, F36 used more than 50% of his 17 revealed accounts for only two apps.

**Summary:**
- 6 out of 18 interview participants and 25 out of 39 quantitative study participants exhibit lockstep behaviors, often using their accounts in the same order to review multiple apps. This aligns with previous research [32, 48, 59, 77, 81, 86, 93, 94, 97, 100].
- However, 8 out of 18 participants and 14 out of 39 participants claim or show evidence of random account and device choices, suggesting possible evasion strategies such as using different sets of accounts for different jobs and employing organic workers who are less likely to be frequently active at the same time.

### 5.9 Timing: Fraud Event Points

**Early Bird Fraud:**
- 14 participants reported working on recently launched apps. The hiring developer often mentions that the app was recently launched, or the participants infer this from the app status when posting their first review.
- The number of such jobs ranges from 1-2 per month (P1, P11) to 20-40 (P9, P10, P13). P7 noted, "We even work on apps that are going to be launched soon. A few of our clients rely on our agency from pre-launch to launch and then post-launch."

**Re-hires:**
- All 18 participants claimed to have been re-hired for previously promoted apps (M = 186.1, SD = 190.7, Min = 15, Max = 600).
- P1 stated, "If the app is getting bad reviews, the developer will hire us again to get good reviews. We have seen this case for a minimum of 30 to 40 apps per year."
- P12 added, "I have around 20 regular clients. They hired me for the same app, around 40–50 times."

**Device and Account Management:**
- P5 and P9 claimed to provide only one review from one device for an app.
- P15 and P16 keep track of which accounts they use to log in to any device and wait 7-10 days before reusing an account.
- P5 uses a fixed set of 2-3 accounts to log in to one device at a time, while P6 instructs remote workers to log in to at most 2 accounts from any device.
- P7 and P8 use 2-3 and 3-5 accounts per device, respectively, for safety.

**Summary:**
- ASO workers generally claim it is possible to review an app from different accounts using the same device. This has been verified and reduces the resources needed for creating fake reviews.

### 5.10 Review Writing

**Review Text Source:**
- 2 participants (P3, P4) always write their own reviews.
- Other participants both receive or request review text from the developer and write their own reviews.
- P2 receives instructions about the reviews from the developer, while P11 reports developers who provide specific text.

**Plagiarism and Review Length:**
- 8 participants (P1, P3, P5, P12, P13, P14, P15, P18) denied plagiarism and self-plagiarism.
- P2, P4, P6, P9, P11, and P17 admitted to some form of plagiarism.
- 11 participants claimed their reviews exceed 10 words (10-40), while P3 and P4 admitted to writing short reviews (3-5 words).

**Quantitative Investigation:**
- Figure 12 shows the empirical CDF of the review word count. P(Len ≤ 10|F7) = 0.88 and P(Len ≤ 10|F26) = 0.06. The overall CDF is closer to F7, with P(Len ≤ 10) = 0.63.
- 993 reviews were empty, and the next 10 most repeated reviews were short, generic, and app-agnostic.

**Summary:**
- Most interviewed participants prefer short, generic reviews to avoid triggering Google's defenses. This aligns with previous fraud detection work [24, 51, 52, 63-65, 74, 93, 94].

### 5.12 Proof of Work

**Verification Methods:**
- 12 participants use screenshots of their reviews.
- 5 participants send usernames of accounts used to post reviews.
- P6 checks reviews for 2-3 days and sends permalinks or names used to post reviews.
- Team-level verifications involve tracking reviews and sending screenshots, ensuring no multiple reviews from the same device.

**Follow-up:**
- P3 mentioned that developers sometimes track reviews and give 24 hours to show that the reviews are still active.
- P7 provides guarantees of reviews sticking for 5-7 days and refills deleted ones for free.

### 5.13 Account Creation

**Account Naming:**
- 13 out of 18 participants use fake name generators, sometimes corresponding to specific geographic regions.
- P2 sends chosen names to the employer for feedback.
- P11 uses random names from Google search, and P7 has a name database.
- P4, P7, and P14 use organic ASO workers to ensure real user names.

**Summary:**
- Most participants use various methods to create and manage account names, including fake name generators and real user names, to maintain the authenticity of their reviews.