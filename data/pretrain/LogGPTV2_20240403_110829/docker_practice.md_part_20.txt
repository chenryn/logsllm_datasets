rio@083:~$ sudo docker run -d swarm join --addr=192.168.1.83:237
5 token://b7625e5a7a2dc7f8c4faacf2b510078e
3b3d9da603d7c121588f796eab723458af5938606282787fcbb03b6f1ac2000b
这条命令通过 -d 参数启动了一个容器，使得83这台机器加入到集群。如果这个
容器被停止或者被删除，83这台机器就会从集群中消失。
250
使用
启动swarm manager
因为我们要使用 83 这台机器充当 swarm 管理节点，所以需要在83这台机器上面执
行 swarm manage 命令：
sudo docker run -d -p 2376:2375 swarm manage token://b7625e5a7a2
dc7f8c4faacf2b510078e
执行结果如下：
rio@083:~$ sudo docker run -d -p 2376:2375 swarm manage token://
b7625e5a7a2dc7f8c4faacf2b510078e
83de3e9149b7a0ef49916d1dbe073e44e8c31c2fcbe98d962a4f85380ef25f76
这条命令如果执行成功会返回已经启动的 Swarm 的容器的 ID，此时整个集群已经
启动起来了。
现在通过 docker ps 命令来看下有没有启动成功。
rio@083:~$ sudo docker ps
CONTAINER ID IMAGE COMMAND C
REATED STATUS PORTS
NAMES
83de3e9149b7 swarm:latest "/swarm manage token 4
minutes ago Up 4 minutes 0.0.0.0:2376->2375/tcp
stupefied_stallman
可以看到，Swarm 已经成功启动。 在执行 Swarm manage 这条命令的时候，有
几点需要注意的：
这条命令需要在充当 swarm 管理者的机器上执行
Swarm 要以 daemon 的形式执行
映射的端口可以使任意的除了 2375 以外的并且是未被占用的端口，但一定不
能是 2375 这个端口，因为 2375 已经被 Docker 本身给占用了。
集群启动成功以后，现在我们可以在任何一台节点上使用 swarm list 命令查看
集群中的节点了，本实验在 124 这台机器上执行 swarm list 命令：
251
使用
rio@124:~$ sudo docker run --rm swarm list token://b7625e5a7a2dc
7f8c4faacf2b510078e
192.168.1.84:2375
192.168.1.124:2375
192.168.1.83:2375
输出结果列出的IP地址正是我们使用 swarm join 命令加入集群的机器的IP地
址。
现在我们可以在任何一台安装了 Docker 的机器上面通过命令(命令中要指明swarm
manager机器的IP地址)来在集群中运行container了。 本次试验，我们在
192.168.1.85 这台机器上使用 docker info 命令来查看集群中的节点的信息。
其中 info 也可以换成其他的 Docker 支持的命令。
rio@085:~$ sudo docker -H 192.168.1.83:2376 info
Containers: 8
Strategy: spread
Filters: affinity, health, constraint, port, dependency
Nodes: 2
sclu083: 192.168.1.83:2375
└ Containers: 1
└ Reserved CPUs: 0 / 2
└ Reserved Memory: 0 B / 4.054 GiB
sclu084: 192.168.1.84:2375
└ Containers: 7
└ Reserved CPUs: 0 / 2
└ Reserved Memory: 0 B / 4.053 GiB
结果输出显示这个集群中只有两个节点，IP地址分别是 192.168.1.83 和
192.168.1.84，结果不对呀，我们明明把三台机器加入了这个集群，还有 124 这一
台机器呢？ 经过排查，发现是忘了修改 124 这台机器上面改 docker daemon 的监
听方式，只要按照上面的步骤修改写 docker daemon 的监听方式就可以了。
在使用这个方法的时候，使用swarm create可能会因为网络的原因会出现类似于下
面的这个问题：
252
使用
rio@227:~$ sudo docker run --rm swarm create
[sudo] password for rio:
time="2015-05-19T12:59:26Z" level=fatal msg="Post https://discov
ery-stage.hub.docker.com/v1/clusters: dial tcp: i/o timeout"
使用文件
第二种方法相对于第一种方法要简单得多，也不会出现类似于上面的问题。
第一步：在 swarm 管理节点上新建一个文件，把要加入集群的机器 IP 地址和端口
号写入文件中，本次试验就是要在83这台机器上面操作：
rio@083:~$ echo 192.168.1.83:2375 >> cluster
rio@083:~$ echo 192.168.1.84:2375 >> cluster
rio@083:~$ echo 192.168.1.124:2375 >> cluster
rio@083:~$ cat cluster
192.168.1.83:2375
192.168.1.84:2375
192.168.1.124:2375
第二步：在083这台机器上面执行 swarm manage 这条命令：
rio@083:~$ sudo docker run -d -p 2376:2375 -v $(pwd)/cluster:/tm
p/cluster swarm manage file:///tmp/cluster
364af1f25b776f99927b8ae26ca8db5a6fe8ab8cc1e4629a5a68b48951f598ad
使用 docker ps 来查看有没有启动成功：
rio@083:~$ sudo docker ps
CONTAINER ID IMAGE COMMAND C
REATED STATUS PORTS
NAMES
364af1f25b77 swarm:latest "/swarm manage file: A
bout a minute ago Up About a minute 0.0.0.0:2376->2375/tcp
happy_euclid
253
使用
可以看到，此时整个集群已经启动成功。
在使用这条命令的时候需要注意的是注意：这里一定要使用-v命令，因为cluster文
件是在本机上面，启动的容器默认是访问不到的，所以要通过-v命令共享。
接下来的就可以在任何一台安装了docker的机器上面通过命令使用集群，同样的，
在85这台机器上执行docker info命令查看集群的节点信息：
rio@s085:~$ sudo docker -H 192.168.1.83:2376 info
Containers: 9
Strategy: spread
Filters: affinity, health, constraint, port, dependency
Nodes: 3
atsgxxx: 192.168.1.227:2375
└ Containers: 0
└ Reserved CPUs: 0 / 4
└ Reserved Memory: 0 B / 2.052 GiB
sclu083: 192.168.1.83:2375
└ Containers: 2
└ Reserved CPUs: 0 / 2
└ Reserved Memory: 0 B / 4.054 GiB
sclu084: 192.168.1.84:2375
└ Containers: 7
└ Reserved CPUs: 0 / 2
└ Reserved Memory: 0 B / 4.053 GiB
254
调度器
swarm 调度策略
swarm支持多种调度策略来选择节点。每次在swarm启动container的时候，swarm
会根据选择的调度策略来选择节点运行container。目前支持的有:spread,binpack和
random。
在执行 swarm manage 命令启动 swarm 集群的时候可以通过 --strategy 参数
来指定，默认的是spread。
spread和binpack策略会根据每台节点的可用CPU，内存以及正在运行的containers
的数量来给各个节点分级，而random策略，顾名思义，他不会做任何的计算，只是
单纯的随机选择一个节点来启动container。这种策略一般只做调试用。
使用spread策略，swarm会选择一个正在运行的container的数量最少的那个节点来
运行container。这种情况会导致启动的container会尽可能的分布在不同的机器上运
行，这样的好处就是如果有节点坏掉的时候不会损失太多的container。
binpack 则相反，这种情况下，swarm会尽可能的把所有的容器放在一台节点上面
运行。这种策略会避免容器碎片化，因为他会把未使用的机器分配给更大的容器，
带来的好处就是swarm会使用最少的节点运行最多的容器。
spread 策略
先来演示下 spread 策略的情况。
rio@083:~$ sudo docker run -d -p 2376:2375 -v $(pwd)/cluster:/tm
p/cluster swarm manage --strategy=spread file:///tmp/cluster
7609ac2e463f435c271d17887b7d1db223a5d696bf3f47f86925c781c000cb60
ats@sclu083:~$ sudo docker ps
CONTAINER ID IMAGE COMMAND C
REATED STATUS PORTS
NAMES
7609ac2e463f swarm:latest "/swarm manage --str 6
seconds ago Up 5 seconds 0.0.0.0:2376->2375/tcp
focused_babbage
255
调度器
三台机器除了83运行了 Swarm之外，其他的都没有运行任何一个容器，现在在85
这台节点上面在swarm集群上启动一个容器
rio@085:~$ sudo docker -H 192.168.1.83:2376 run --name node-1 -d
-P redis
2553799f1372b432e9b3311b73e327915d996b6b095a30de3c91a47ff06ce981
rio@085:~$ sudo docker -H 192.168.1.83:2376 ps
CONTAINER ID IMAGE COMMAND C
REATED STATUS PORTS
NAMES
2553799f1372 redis:latest /entrypoint.sh redis 2
4 minutes ago Up Less than a second 192.168.1.84:32770->6
379/tcp 084/node-1
启动一个 redis 容器，查看结果
rio@085:~$ sudo docker -H 192.168.1.83:2376 run --name node-2 -d
-P redis
7965a17fb943dc6404e2c14fb8585967e114addca068f233fcaf60c13bcf2190
rio@085:~$ sudo docker -H 192.168.1.83:2376 ps
CONTAINER ID IMAGE COMMAND
CREATED STATUS PORTS
NAMES
7965a17fb943 redis:latest /entrypoint.sh redis Less t
han a second ago Up 1 seconds 192.168.1.124:49154->6379
/tcp 124/node-2
2553799f1372 redis:latest /entrypoint
.sh redis 29 minutes ago Up 4 minutes 192.168
.1.84:32770->6379/tcp 084/node-1
再次启动一个 redis 容器，查看结果
256
调度器
rio@085:~$ sudo docker -H 192.168.1.83:2376 run --name node-3 -d
-P redis
65e1ed758b53fbf441433a6cb47d288c51235257cf1bf92e04a63a8079e76bee
rio@085:~$ sudo docker -H 192.168.1.83:2376 ps
CONTAINER ID IMAGE COMMAND
CREATED STATUS PORTS
NAMES
7965a17fb943 redis:latest /entrypoint
.sh redis Less than a second ago Up 4 minutes 192.168
.1.227:49154->6379/tcp 124/node-2
65e1ed758b53 redis:latest /entrypoint
.sh redis 25 minutes ago Up 17 seconds 192.168
.1.83:32770->6379/tcp 083/node-3
2553799f1372 redis:latest /entrypoint
.sh redis 33 minutes ago Up 8 minutes 192.168
.1.84:32770->6379/tcp 084/node-1
可以看到三个容器都是分布在不同的节点上面的。
binpack 策略
现在来看看binpack策略下的情况。在083上面执行命令：
rio@083:~$ sudo docker run -d -p 2376:2375 -v $(pwd)/cluster:/tm
p/cluster swarm manage --strategy=binpack file:///tmp/cluster
f1c9affd5a0567870a45a8eae57fec7c78f3825f3a53fd324157011aa0111ac5
现在在集群中启动三个 redis 容器，查看分布情况：
257
调度器
rio@085:~$ sudo docker -H 192.168.1.83:2376 run --name node-1 -d
-P redis
18ceefa5e86f06025cf7c15919fa64a417a9d865c27d97a0ab4c7315118e348c
rio@085:~$ sudo docker -H 192.168.1.83:2376 run --name node-2 -d
-P redis
7e778bde1a99c5cbe4701e06935157a6572fb8093fe21517845f5296c1a91bb2
rio@085:~$ sudo docker -H 192.168.1.83:2376 run --name node-3 -d
-P redis
2195086965a783f0c2b2f8af65083c770f8bd454d98b7a94d0f670e73eea05f8
rio@085:~$ sudo docker -H 192.168.1.83:2376 ps
CONTAINER ID IMAGE COMMAND C
REATED STATUS PORTS
NAMES
2195086965a7 redis:latest /entrypoint.sh redis 2
4 minutes ago Up Less than a second 192.168.1.83:32773->6
379/tcp 083/node-3
7e778bde1a99 redis:latest /entrypoint.sh redis 2
4 minutes ago Up Less than a second 192.168.1.83:32772->6
379/tcp 083/node-2
18ceefa5e86f redis:latest /entrypoint.sh redis 2
5 minutes ago Up 22 seconds 192.168.1.83:32771->6
379/tcp 083/node-1
可以看到，所有的容器都是分布在同一个节点上运行的。
258
过滤器
Swarm 过滤器
swarm 的调度器(scheduler)在选择节点运行容器的时候支持几种过滤器 (filter)：
Constraint,Affinity,Port,Dependency,Health
可以在执行 swarm manage 命令的时候通过 --filter 选项来设置。
Constraint Filter
constraint 是一个跟具体节点相关联的键值对，可以看做是每个节点的标签，这个
标签可以在启动docker daemon的时候指定，比如
sudo docker -d --label label_name=label01
也可以写在docker的配置文件里面（在ubuntu上面是
/etc/default/docker ）。
在本次试验中，给083添加标签--label label_name=083,084添加标签--label
label_name=084,124添加标签--label label_name=124,
以083为例，打开/etc/default/docker文件，修改DOCKER_OPTS：
DOCKER_OPTS="-H 0.0.0.0:2375 -H unix:///var/run/docker.sock --l
abel label_name=083"
在使用docker run命令启动容器的时候使用 -e constarint:key=value 的形
式，可以指定container运行的节点。
比如我们想在84上面启动一个 redis 容器。
rio@085:~$ sudo docker -H 192.168.1.83:2376 run --name redis_1 -d
-e constraint:label_name==084 redis
fee1b7b9dde13d64690344c1f1a4c3f5556835be46b41b969e4090a083a6382d
注意，是两个等号，不是一个等号，这一点会经常被忽略。
259
过滤器
接下来再在084这台机器上启动一个redis 容器。
rio@085:~$ sudo docker -H 192.168.1.83:2376 run --name redis_2 -d
-e constraint:label_name==084 redis 4968d617d9cd122fc2e
17b3bad2f2c3b5812c0f6f51898024a96c4839fa000e1
然后再在083这台机器上启动另外一个 redis 容器。
rio@085:~$ sudo docker -H 192.168.1.83:2376 run --name redis_3 -d
-e constraint:label_name==083 redis 7786300b8d2232c2335
ac6161c715de23f9179d30eb5c7e9c4f920a4f1d39570
现在来看下执行情况：
rio@085:~$ sudo docker -H 192.168.1.83:2376 ps
CONTAINER ID IMAGE COMMAND C
REATED STATUS PORTS NAMES
7786300b8d22 redis:latest "/entrypoint.sh redi 1
5 minutes ago Up 53 seconds 6379/tcp 083/r
edis_3
4968d617d9cd redis:latest "/entrypoint.sh redi 1
6 minutes ago Up 2 minutes 6379/tcp 084/r
edis_2