III. THE IMPACT OF SENSOR BUGS
We reviewed bugs reported and resolved on the public
GitHub repositories of ArduPilot (206 cases) and PX4 (188
cases) from 2016-2019. In total, we reviewed 394 bugs.
We excluded bug reports related to software development
environments and tools (29). We also removed duplicates,
false reports, reports unrelated to control ﬁrmware and bugs
that were described too vaguely to repeat or understand (150).
After pruning, we were left with 215 bugs.
We classiﬁed bugs by their root causes: Semantic bugs were
caused by logically incorrect behavior of the UAV without
a preceding hardware fault; Memory bugs stemmed from
incorrect memory allocation or invalid accesses; Sensor bugs,
as described earlier, were triggered by a sensor fault. Finally,
we grouped all remaining bugs, including concurrency bugs,
under the label other.
We also classiﬁed bugs by the ﬂight conditions where they
manifested. Some bugs were easy to reproduce, because they
could be triggered under default settings, i.e., with standard
environment and hardware conﬁgurations. We distinguished
bugs that required special settings. Finally, we also classiﬁed
bugs by their symptoms. Some bugs were asymptomatic.
Others had transient affects, such as jerks during ﬂight. The
most serious bugs resulted in a crash or the UAV ﬂew away.
Finding 1: Sensor bugs account for 20% of control
ﬁrmware bugs.
We found that semantic bugs accounted for 68% of reported
bugs. Sensor bugs were second most common, accounting for
20% of reported bugs. However, as shown in Figure 3(A),
sensor bugs represented 40% of reported bugs that caused the
UAV to crash.
We believe sensor bugs are common for a several reasons.
(1) ArduPilot and PX4 have adopted Valgrind [26] to detect
memory bugs during in-house testing [6], [29], depressing
3
(A) Sensor bugs       are common(C) Sensor bugs       are serious(B) Sensor bugs       are reproducibleSensorMemorySemanticOtherType of BugDefault settingsCustom envCustom env & hwBug ManifestationsCrash/Fly awayTransientNo symptomsSensor-Bug OutcomesFig. 4: An overview of Avis. Arrows denote the direction of
information ﬂow.
sensor inputs to determine its next motor controls. The actuator
drivers communicate the motor controls to the simulator (not
shown). The simulator uses these controls to generate the ve-
hicle’s new physical state. One iteration of this communication
is called a simulation time-step.
Avis relies on simulation instead of real UAV ﬂights for
three reasons. First, recall that sensor bugs can have serious
symptoms; simulating the behavior of the UAV under a fault
injection scenario allows Avis to expose a sensor bug without
suffering from the bug’s symptom, e.g., crashing the vehicle.
Second, simulations can be performed faster than real experi-
ments, improving test throughput. Last but not least, all UAV
ﬁrmware modules (except for drivers) are identical to the ones
used in real systems, enabling Avis to use simulation to check
real UAV ﬁrmware. Next, we discuss the three components of
Avis in more details.
A. Workloads and Environments
Pilots send commands using a ground-control station to
control a UAV’s movements. A sequence of pilot commands
constitutes a workload. UAVs typically communicate with
the ground-control station using the MAVLink [21] protocol.
Ideally, all control ﬁrmware would support the same MAVLink
messages and strictly implement their semantics. In practice,
implementations have subtle quirks that make it difﬁcult for
users to develop portable workloads. To mitigate this issue,
Avis provides default workloads that work on both ArduPilot
and PX4. We also provide a high-level framework developers
can use to extend our workloads and build their own.
We design our workloads to exercise common commands
such as takeoff, ﬂy-to-waypoint, and land. Each command
maneuvers the vehicle in a simple way, e.g. along a polygon.
This allows Avis to trigger bugs that UAV pilots are most
likely to experience.
The simulator provides an environment, a model of the
physical world that contains obstacles and weather effects.
Workloads navigate the UAV in the environment. Some unsafe
conditions can only be recreated in speciﬁc environments, e.g.
due to adverse weather or obstacles such as trees. Avis uses
an environment without hostile weather or obstacles.
B. Fault Injection Engine
Avis injects sensor failures during simulated ﬂights to
expose bugs in control ﬁrmware that lead to unsafe conditions.
The main challenge Avis faces is exploring a huge fault space.
Exhaustively injecting every possible fault is not feasible and,
4
Fig. 5: UAV modes and the corresponding UAV code executed
at different times ti during a test run. Each circle represents
the failure state of the GPS and barometer. Similar states are
colored black.
in most cases, would yield normal executions that do not aid
root cause analysis. In this subsection, we ﬁrst elaborate on
this challenge. Then, we propose a new search strategy, called
SABRE, for fault injection based on the UAV’s operating
mode. Finally, we show how to avoid fault injections that yield
redundant states to further improve search efﬁciency.
Fault Model and Challenges: Avis models clean sensor
failures, where a sensor instance stops communicating with
the ﬁrmware and the driver reports the instance has failed.
Any sensor instance can fail at any time (controlled by Avis).
Moreover, a failed sensor will not recover during the same test
run. Avis focuses on such a simple fault model because it is
realistic. More importantly, UAVs are expected to handle this
simple fault model.
Usually, a UAV samples its sensors thousands of times each
second. Consequently, there are far too many fault injection
sites to exhaustively cover. Moreover, since UAV workloads
usually take minutes to execute, effectively exploring fault
injection sites becomes even more important. On a simple
vehicle with 7 onboard sensors and no backups, there are more
than (27 − 1) × 103 ≈ 105 fault injection sites each second.
To maximize the number of unsafe scenarios identiﬁed as
we search the fault space, we rely on a key observation: there
are many similar fault injection sites within each mode.
Figure 5 demonstrates this observation using an example.
Since injecting the same failures in the same mode likely leads
to the same UAV behavior, injecting sensor failure at t3 can
be similar to injecting failures at t2. However, injecting sensor
failures at t4 exposes different UAV code to failures, likely
causing different UAV behaviors.
This observation motivates us to prioritize fault injection
at mode boundaries. Consider the bug described in Figure 1.
In a narrow window while the UAV has low altitude but has
not yet landed, it is vulnerable to an IMU failure blinding the
AVISworkloadcontrol firmwareenvironmentsensor driversfaultinjectinvariantmonitorsimulatorunmanned aerial vehicleGPS, BaroBaroØt1t4t5TakeoffAutot2t3LandGPSif CanPrune(timestamp, failureSet, seenBugs,
injectedFailures) then
continue;
end
failures ← injectedFailures ∪ {(failure,
timestamp) : failure ∈ failureSet};
result ← RunExperiment(Workload, failures);
if Ok(result) then
for modeTimestamp ∈
result.modeTransitions do
Enqueue(transitionQueue,
(modeTimestamp, failures));
end
else
end
reportBug(failures, result);
seenBugs ← seenBugs ∪ {failures};
end
Enqueue(transitionQueue, (timestamp + 1,
injectedFailures));
21 end
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
ﬁrmware to the effects of its own actuation. By considering
the area between landing and disarming early in the injection
space exploration, Avis quickly triggers this scenario.
Search Strategies: Inspired by the previous observation, we
propose SABRE—a stratiﬁed breadth-ﬁrst search. SABRE ex-
plores the space of sensor failures using injection sites across
all modes. Before we describe SABRE, we ﬁrst consider two
common search strategies to understand their drawbacks.
Figure 5 shows the fault space that should be explored given
two sensors (GPS and Barometer) and a workload with ﬁve
time-steps. Depth-ﬁrst search is an intuitive way to search
the fault space, which results in the following sequence of
executions:
(cid:104)∅,∅,∅,∅,∅(cid:105)
(cid:104)∅,∅,∅,∅,{GPS}(cid:105)
(cid:104)∅,∅,∅,∅,{Baro}(cid:105)
(cid:104)∅,∅,∅,∅,{GPS, Baro}(cid:105)
(cid:104)∅,∅,∅,{GPS},{GPS}(cid:105)
. . .
In each sequence (cid:104)F1, . . . , F5(cid:105), Fi denotes the set of sensors
that are failed at time ti. This search is ineffective because
similar fault injection scenarios (e.g. failing the GPS at t4 and
failing the GPS at t5) are explored before the scenarios in
different modes (e.g., failing GPS at t3). Given a limited test
budget, depth-ﬁrst search tends to test a small area of the UAV
ﬁrmware.
An alternative approach is to use breadth-ﬁrst search to
explore the fault space. We explore the fault space across time
to reach dissimilar moments faster. This approach results in the
following sequence of executions:
(cid:104)∅,∅,∅,∅,∅(cid:105)
(cid:104){GPS},{GPS},{GPS},{GPS},{GPS}(cid:105)
(cid:104){Baro},{Baro},{Baro},{Baro},{Baro}(cid:105)
(cid:104){GPS, Baro},{GPS, Baro}, . . . ,{GPS, Baro}(cid:105)
(cid:104)∅,{GPS},{GPS},{GPS},{GPS}(cid:105)
(cid:104)∅,∅,{GPS},{GPS},{GPS}(cid:105)
. . .
. . .
However, this strategy is ineffective because it also explores
similar fault scenarios ﬁrst. Speciﬁcally, after injecting failures
at t2, breadth-ﬁrst search considers similar failures at t3
next. This delays exploration of complex fault scenarios (i.e.,
failing different sensors at different times) until all the simple
scenarios are checked. Given the limited test budget, complex
fault scenarios may never be explored by breadth-ﬁrst search.
In contrast to depth-ﬁrst search and breadth-ﬁrst search,
SABRE prioritizes exploring the most different states in the
fault space by considering the UAV’s mode. Speciﬁcally,
SABRE ﬁrst explores the scenarios that inject sensor failures
around mode transitions, allowing SABRE to consider fault
scenarios that fail different sensors at different modes before
the aforementioned two strategies. Note that SABRE only
: the sensor failures to inject
Algorithm 1: SABRE
Workload: the workload to execute
Failures
1 transitionQueue ←
2 seenBugs ← {};
3 while transitionQueue is not empty do
4
Queue(ProﬁleExperiment(Workload));
timestamp, injectedFailures ←
Dequeue(transitionQueue);
for failureSet in PowerSet(Failures) do
prioritizes the search to uncover bugs earlier – exhaustive
search is still possible, but is prohibitively expensive.
Algorithm 1 shows how Avis uses SABRE to guide its
fault-space exploration. Here, we walk through the algorithm
using the example shown in Figure 5. Avis ﬁrst executes the
workload to determine when mode transitions occur (Line 1).
Mode transitions are discovered at t1, t2, and t4. As a result,
Avis initializes its transition queue to (cid:104)(t1,∅), (t2,∅), (t4,∅)(cid:105),
where each (ti, set) means to inject new faults at ti alongside
the fault combinations (cid:104)sensor, timestamp(cid:105) in set. Next,
Avis dequeues the injection scenario (t1,∅) from the queue
(Line 4) and applies all possible sensor failures to this point
(Line 5) but only if they are not redundant (Lines 6-8). Thus,
Avis tests the following executions:
(cid:104){GPS},{GPS},{GPS},{GPS},{GPS}(cid:105)
(cid:104){Baro},{Baro},{Baro},{Baro},{Varo}(cid:105)
(cid:104){GPS, Baro},{GPS, Baro}, . . . ,{GPS, Baro}(cid:105)
Avis also re-enqueues each bug-free scenario it
tests for
generating new fault scenarios in later runs (Lines 11-14). Fi-
nally, Avis re-enqueues the dequeued scenario with a changed
timestamp so that it will explore injecting faults at different
5
times in later runs. The next tuple dequeued by Avis is (t2,∅)
since it is the second mode transition discovered during the
proﬁling run. So, Avis injects faults at t2 as it did at t1.
Next, Avis dequeues the mode transition (t4,∅). So, rather than
conducting fault injection at t3 next like breadth-ﬁrst search,
Avis considers this fault combination:
(cid:104)∅,∅,∅,{GPS},{GPS}(cid:105).
C. Invariant Monitor
At the end of each simulation iteration, Avis’s invariant
monitor checks two simple rules:
• Safety - The UAV does not collide with an obstacle.
• Liveliness - The UAV must always make progress to-
wards its goal. This may be compromised under special
circumstances to preserve safety.
In this way, Avis prioritizes injecting faults around the mode
transitions. This process repeats until the queue is exhausted.
1) Redundancy Elimination: While SABRE guides the or-
der that injection sites are searched, it does not avoid redundant
injection scenarios. Avis uses two policies, i.e., found bug
pruning and sensor instance symmetry,
to eliminate these
redundancies.
In the found bug pruning policy, if injecting a sensor failure
F0 at time t triggers a bug, Avis will not try to inject F0 plus
other failures at time t in the later test runs. The intuition
behind this policy is that if a vehicle cannot handle a single
sensor failure then it is unlikely to correctly handle multiple
failures in the same program context.
The sensor instance symmetry policy exploits the role of
a sensor, i.e., primary or backup, to reduce the combinatorial
size of the fault space. UAV systems are usually equipped
with multiple sensor instances of the same sensor type to
tolerate sensor failures. One of these redundant sensors is
the primary, while the other instances are the backups. We
ﬁnd that, when handling sensor failures, the UAV’s behavior
depends on the role of the failed sensors instead of which
instances fail. Therefore, Avis skips a sensor failure scenario if
the same failed sensor roles have been tested before, regardless
of the actual instances.
Figure 6 illustrates the sensor instance symmetry policy with
an example. Consider a UAV with three compasses labeled as
“P,” “B1,” and “B2,” corresponding to the primary and the two
backups respectively. Assume Avis is injecting sensor failures
at time t. In the ﬁrst two runs, Avis fails sensor P (Figure
6a) and sensor B1 (Figure 6b), respectively. These are two
different scenarios since P is a primary sensor while B1 is a
backup sensor. Then, Avis considers failing B2 but decides
to skip it (Figure 6c). This is because B2 is a backup sensor
and Avis has tried failing one backup sensor in a previous