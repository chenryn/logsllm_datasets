datasets, the smallest dataset is made up of 467,696 visitors.
Table 2 summarizes the results of all our queries. In total,
we collected and queried 53 Font, 46 Canvas and 16 WebGL
ﬁngerprints. Interestingly, we noticed that many crawlers
continued to carry the same BFPs as the ones we saw in our
longitudinal study despite the 6-month difference in time.
For example, all ﬁngerprints collected from APWG and
6Canvas and Font ﬁngerprints are relatively stable for a user with a median
lifetime of more than 9 months [47].
7For some crawlers such as PhishTank and Bitdefender the markers on
the y-axis refer to multiple ﬁngerprints. In these cases, if at least one of those
ﬁngerprints was found in the previous study, we marked that point solid.
3782    30th USENIX Security Symposium
USENIX Association
10203040506070Days0.00.20.40.60.81.0Fraction of FPs(a) IP Address                                   #IPsAPWG          2726Bitdefender     62GSB            619SmartScreen     50PhishTank     4096VT Bucket     779510203040506070Days0.00.20.40.60.81.0(b) Font                                     #FPsAPWG             7Bitdefender     46GSB              2SmartScreen     13PhishTank       55VT Bucket      11110203040506070Days0.20.40.60.81.0(c) Canvas                                     #FPsAPWG             7Bitdefender     38GSB              2SmartScreen      8PhishTank       69VT Bucket       97010−310−210−1100101Font FP Prevalence (in %)0.00.20.40.60.81.0Fraction of BFPs                                     #FPs   %SumAPWG          2   0.05Bitdefender  17   7.73GSB           2   0.25SmartScreen   4   0.98PhishTank    43   19.51010−310−210−1100101Canvas FP Prevalence (in %)                                     #FPs   %SumAPWG          2   0.02Bitdefender  13   4.99GSB           3   0.07SmartScreen   2   1.61PhishTank    40   10.25Conﬁg
# Sessions
#IPs
# 
SR
DRR
Similarity
954
799
-
291
188
0.046
10
10
0.54
Table 3: Results of Diverse Repeated Reporting Experiment
SmartScreen were already seen in the previous study. In total,
71.3% of ﬁngerprints were already collected previously. The
table shows the distribution of prevalence (in %) of the 3
ﬁngerprints and the graphs in Fig. 3 break this data down by
each crawler. Similar to results from prior privacy-oriented
studies [29], this data shows that most of the ﬁngerprints
are very rare with only a handful of them being prevalent
in more than 1% of the visitors. For example, as many as
20 Font ﬁngerprints were unique and not seen among any
of the visitors. The table also shows the sum of all these
prevalence percentages which could be used as a direct
measure of speciﬁcity if these ﬁngerprints were individually
used as cloaking vectors. For example, the lowest of these
is 10.47% for Canvas thus indicating that attackers will only
lose about 10.47% of potential victims if they were to use a
blocklist made solely of Canvas-based crawler ﬁngerprints as
their cloaking vector. However, if they used a more speciﬁc
cloaking vector such as the triplet , we could expect
this lost victim percentage be even lesser. Fig. 3 shows that
this situation is even bleaker for individual crawlers with
both APWG and GSB’s Canvas ﬁngerprints accounting for
only 0.02% and 0.07% of all visitors. Thus, despite their
massive network infrastructure, due to this extreme lack in
the diversity of ﬁngerprints, attackers can speciﬁcally evade
these crawlers without fear of losing any potential victims.
3.2.2 Diverse Repeated Reporting Experiment
In August 2020, we performed another control experiment.
The goal of this was to study any potential effects that
repeated reporting of token URLs from diverse sources could
have on the proﬁling information that is collected from the
crawlers. We note that during our 10-week longitudinal study,
we only registered a single domain and reported each token
site’s subdomain created under it only a single time to each
crawler. To replicate this setup, we created a similar conﬁgu-
ration in this study by creating 50 different subdomains under
a single .xyz domain (called SR). We then set up an alternate
conﬁguration for diverse and repeated reporting (called DRR)
by using 5 different .xyz TLDs. On a single day, we used
PhishPrint to report each of the 50 SR URLs to 10 different
crawlers from a U.S. IP address (namely: AlienVault, APWG,
Fortinet, GSB, SmartScreen, Norton, OpenPhish, Outlook,
Sophos and ZeroCert). On the same day, we used a private
VPN provider to connect to 10 IP addresses located in 7
different countries around the world and submitted 10 reports
on each domain in DRR set to all the 10 crawlers. For some
crawlers such as Outlook and APWG which use e-mail re-
porting, we created and used 10 different e-mail addresses for
each domain in the DRR set. This setup ensured that an equal
number of URL reports get sent from each conﬁguration (50
to each crawler) in order to keep the comparison balanced.
Table 3 shows an overview of the comparison between the
proﬁling results obtained from the two conﬁgurations. We
can see that despite repeated diverse reporting, the URLs
reported via the SR conﬁguration involved more sessions and
more crawler IP addresses. We surmise that this could be a
result of some crawlers deliberately ignoring repeated reports
even if coming from diverse sources. For example, we noticed
that PhishTank’s website shows an error message saying
the URL is already submitted even if we try to do a repeat
submission from a different account. The ﬁnal rows show the
Jaccard Similarity between the IP addresses and the 
sets from the two conﬁgurations. The high variability in
the IP addresses used by crawlers could have caused the
low similarity between the two sets. It is to be noted that if
we consider the associated Autonomous Systems of the IPs
instead the similarity rises to about 0.57. Furthermore, break-
ing these results down by crawlers shows that all the ASs
used by 8 of the 10 crawlers in the DRR set are also present
in the SR set. The same is the case with s where 4
of the 6 crawlers from which we collected s have
a complete match. Further, the crawlers such as OpenPhish
and AlienVault which showed very little diversity in their IP
space previously, have displayed exactly the same behavior in
the DRR set as well. Overall, this experiment shows that using
a non-diverse URL reporting setup as we did in our study can
still enable the collection of valuable proﬁling information.
4 Evading Security Crawlers
Our analysis of the proﬁling data from the crawlers showed
that ﬁve of the six cloaking vectors we devised can exploit
existing weaknesses in crawlers: Real Browser Anomaly,
Crawler Artifacts Anomaly, IP, AS and  ﬁngerprint
Blocklists.
In this section, we present supplementary
experiments that directly put these ﬁve vectors in action
against crawlers as well as real users with goals to directly
assess and conﬁrm their evadability beneﬁts as well as false
positive consequences for the attackers.
4.1 Phishing Experiments
In order to conﬁrm the real-world utility of these vectors,
we build phishing websites powered with the candidate
cloaking vectors, self-report them to crawlers and measure
how long they will survive without getting blocked in any of
the browsers (via a Monitoring Module). Here, our approach
will be similar to prior works [37, 39]. These experiments
constitute the Attack Module 8 depicted in Fig. 1.
4.1.1 Setup
For these experiments, we built two kinds of phishing
websites: Baseline sites which do not employ any cloaking
and PhishPrint-cloaked sites which use all the ﬁve cloaking
vectors. The cloaked sites show benign content if any of the 5
USENIX Association
30th USENIX Security Symposium    3783
vectors decide that the visitor should be given a cloaked page.
All the cloaking logic is implemented in server-side using
a simple PHP script. The phishing payload stays encrypted
(using AES-256) until the cloaking logic returns a key to
the client. If any of the ﬁve vectors decide not to show the
phishing content, then some benign content gets loaded into
the pages instead of the phishing payload. We have used two
kinds of simulated phishing payloads: “PayPal” and “Bank of
America”. For benign payloads, we built multiple simple web
pages discussing topics such as food and famous personalities.
As mentioned before in §2, the Proﬁling Module needs to
be running in parallel during these experiments in order to
keep the IP and ﬁngerprint blocklists updated with the latest
data. Hence, we have started performing this experiment
25 days after Proﬁling Module’s deployment (ﬁrst week
of February 2020) to give some bootstrap time for the two
blocklists to be populated while still allowing both modules
to run in parallel. In the rest of this section, we will discuss
the site monitoring, reporting and web site conﬁguration
aspects of these experiments.
Monitoring Module. As the ultimate goal of the attacker
is to be able to continue to deliver phishing content to the
victims, we built a fully automated Monitoring Module to
periodically check if phishing sites are still functional or
blocked in web browsers. We have chosen Chrome, IE and
Opera desktop browsers for this as they employ different
blocklists (GSB, SmartScreen and Opera) that cover most
of the web users [37, 39]. The module loads phishing sites
inside the browsers and checks if the sites are blocked or
not. As browser automation libraries tend to disable browser
blocklists [37], we used a web-based cross-browser testing
platform [4] for this purpose. The monitoring module runs a
headless Chrome browser to open the target site in the testing
platform and uses an OCR library to do the liveness check.
We found this to be a more light-weight approach than using
VMs as suggested in [37]. We did this check every 2 hours for
each site. Note that while previous studies have done this mon-
itoring for 3 [37] or 7 [39] days, we kept monitoring our sites
for a period of 1 month in order to capture any late blocking
that might happen due to our aggressive reporting strategy.
Aggressive Reporting. We used our Proﬁling Module’s
Web Scan Requestor ( 2 in Fig. 1), to self-report all our web-
site to crawlers. In contrast to prior works that reported each
phishing site only one time [37,39] to a few crawlers, we opted
for a much more aggressive approach where we repeatedly
report each site (once daily) over a period of two weeks to all
the 23 crawlers. It is to be noted that during the longitudinal
study, we noticed that a couple of crawlers share most of their
URLs to VirusTotal. Conﬁrming similar behavior, we found
that all our phishing sites have been shared with VirusTotal
too. As a result, our phishing sites were shared and scanned by
more than 80 crawlers that are hosted on VirusTotal as well.
Site conﬁguration. For our experiments, we set up a total
of 26 phishing websites. All 26 websites were hosted with
accounts by the same hosting provider (Hostinger) and had
different domain names. We used 6 of these as baseline sites
(with 3 free accounts) and 20 of these as the cloaked sites
powered by the 5 cloaking vectors (with 1 paid account).
It is to be noted here that despite multiple requests and
conversations about the nature of our research, we were
unsuccessful in getting immunity for any of our accounts
from the hosting provider. We chose only 6 sites for our
baseline as there are already prior studies [39] establishing
clearly the baseline blocklisting speed. For the same reason,
we did not choose to register separate domains for these 6
baseline sites but used the free subdomains (TLD+2 level)
provided by the hosting provider to conserve ﬁnancial
resources. For the cloaked sites, we registered 20 different
.xyz domain names as we were unable to obtain that many
free subdomains. Other than this minor difference, the setup
for the experiments for both sets of sites is exactly the same.
In order to prevent pre-emptive blocklisting of our websites
without scanning [37], we avoided deceptive keywords such
as ‘paypal’ or ‘bank’ in the URLs for the phishing pages. We
instead used benign content related words for all the URLs.
4.1.2 Results
The results show that our 6 baseline sites were quickly
blocked on all the browsers. Chrome (GSB) was the quickest
to do this in 3 hours and 10 minutes. In fact, all the browsers
blocked the 6 sites in about 10.5 hours. This agrees well with a
recent large-scale study done on browser blocklists [39] which
showed that the fastest blocklist (GSB) would block most of
its 324 baseline sites in about 3 hours time. On the other hand,
none of the 20 PhishPrint-cloaked sites were blocked in the
ﬁrst four days despite repeated reporting to all the crawlers. In
the one-month period in which we did the monitoring, only 2
sites (say, ‘A’ and ‘B’) got blocked as shown in Table 4. A was
blocked on day 58 while B got blocked on day 16. It is to be
noted that even for cloaked sites such lengthy blocking time is
highly unusual. For reference, [39] showed that most cloaked
sites either get blocked in a few hours or remain unblocked.
Given this, we surmised that both the blocked sites were due
to manual vetting. To conﬁrm this, we investigated site A’s
case by reloading the site in the browser that ﬁrst blocked
it (Opera). We noted that the browser message speciﬁed the
source for the blockage as a third-party report from Phish-
Tank. When we looked up the URL on PhishTank, we saw
that our site was manually veriﬁed as a phishing URL by 3
users thus conﬁrming our suspicions. Interestingly, we note
that 1 user has also marked our site as a benign site.
As for site B, we found that it was not blocklisted by any
browser, but was taken down by xyz registrar on day 16
due to an abuse report. We were unable to get further details
on what the source for this report could be. The remaining
18 cloaked sites continued to be functional throughout the
8Our cloaked sites experienced a 10 hour down time after A got blocked
as our hosting provider disabled our account. We then moved all our sites to
another provider (Namecheap).
3784    30th USENIX Security Symposium
USENIX Association
Type
# Sites
Alive Time
Baseline
Cloaked site A
Cloaked site B
6
1
1
3h, 10min
4 days, 11h
15 days, 14h
Source
#
Users
 - Ours
Canvas - [29]
Canvas - [22]
1007
118,934
2,067,942
#
Distinct
592
8,375
78,037
#
Unique
469
5,533
65,787
#
Shared
123
2,842
12,250
Normalized
Entropy
0.865
0.491
0.407
Table 4: Lifetimes of the blocked phishing sites
Table 5: Analysis of ﬁngerprints from user studies
monitoring period of 1 month. We veriﬁed manually that
even at the time of writing this manuscript in September
2020, the 18 remaining phishing sites are still live and
loading the phishing payloads on all the major browsers.
Thus, we can conclude that the ﬁve cloaking vectors powered
by PhishPrint are very effective in vastly increasing the
survival chances and lifetimes of phishing websites.
4.2 User Study Experiment
Along with evasive power, we also need to study the speci-
ﬁcity of these vectors and conﬁrm that they are not excluding
a lot of potential victims. For this, we did an empirical evalua-
tion with the help of a user study. We modeled our experiment
as a survey on the MTurk platform as this allowed us to ensure
that unique workers take part in our experiment. We designed
our experiment such that after obtaining prior user consent,
users are exposed to a web page with exactly the same client-
side ﬁngerprinting code and server-side cloaking logic as in
the phishing experiments. However, we removed the phish-
ing payloads for this experiment to avoid showing malicious
content to real users. Also, same as in the phishing experi-
ments, the IP and  blocklists were powered by the
data collected by the proﬁling module in real-time. In the end,
we made measurements of whether or not any of the cloaking
vectors decide to show cloaked content to the visiting users.
We received an exemption from our university IRB board
for this experiment. In compliance with the terms of the
exemption, we took measures to not store any sensitive
information persistently such as the s or any other
information identifying the users such as IP addresses and
request headers in our web servers. But, we did store the AS
information for each client’s IP address in order to gauge the
geographical variety in locations of participants.
We performed this experiment from the third week of
February 2020 to the ﬁrst week of March 2020 as the proﬁling
module was collecting data for the longitudinal study. 1150
unique users participated in our study that lasted about 16
days. 66% of the participants in our study were from the
United States. However, the remaining 34% of participants
were spread across 35 countries in 6 continents. Overall,
the results showed that PhishPrint-powered cloaking logic
decided to show phishing content for 79% of the users. These
numbers are 76.1% for U.S. users and 81.4% for non-U.S.
users. This shows that the PhishPrint-based evasive cloaking
logic is largely speciﬁc to crawlers and can inﬂict harm on
a large portion of users irrespective of their geographical
location.
False Positive Analysis. Breaking down the 21% false
positive rate by cloaking vectors, we saw these numbers:
 Fingerprint Blocklist: 17.5%, AS Blocklist: 1.7%,
Crawler Artifacts: 1%, Real Browser: 0.7%, IP Blocklist:
0.1%. This was expected as other than ﬁngerprints, all
others cloaking vectors are known to be speciﬁc either by
deﬁnition (anomaly vectors and ASs) or due to the nature of
the identiﬁer used (chance of a crawler and a victim sharing
the same exact IP address is very low).
In order to understand the reasons for the overlap between
 ﬁngerprints of MTurk users and crawlers, we sought
a more permissive IRB exemption allowing us to store user
ﬁngerprints. We then performed a second MTurk study during
a 10-day period in January 2021 with 1007 participants
in which we collected 592 distinct  ﬁngerprints.
Table 5 shows more details of these ﬁngerprints. While 469
of the collected ﬁngerprints are unique, there are also 123
“shared” ﬁngerprints each of which belong to at least 2 users.
The two most popular of these shared ﬁngerprints were only
among 23 and 20 users. Further, more than 25% of them
are shared among at least 5 users and more than 55% of
them are shared among at least 3 users each. This shows that
while there are a large number of unique ﬁngerprints, there
also exist many shared ﬁngerprints with no small subset of
ﬁngerprints being extremely dominant. Interestingly, prior