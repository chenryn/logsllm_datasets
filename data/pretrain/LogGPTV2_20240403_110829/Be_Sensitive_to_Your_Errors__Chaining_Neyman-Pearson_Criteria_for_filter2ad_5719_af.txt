36.2
98.0
97.7
87.5
98.3
FPR
8.0
4.3
0.9
3.0
5.6
7.1
7.3
18.2
0.5
1.2
3.0
0.7
DR
89.2
97.0
99.2
97.8
81.3
87.2
95.8
75.2
99.4
99.2
97.3
99.0
FPR
3.5
8.5
2.5
1.4
15.3
7.4
21.8
8.0
3.5
1.4
3.4
2.9
DR
22.1
94.4
97.8
98.2
72.2
80.1
95.8
46.0
96.8
98.9
95.0
98.3
FPR
8.1
4.4
0.9
2.6
9.9
10.4
6.6
20.0
1.0
1.0
3.8
1.9
DR
86.0
95.6
99.1
97.3
81.8
84.7
95.2
74.9
99.6
99.2
96.3
99.0
is still expected to be less than half an minute. This time
can be further reduced if multiple cores are used.
Interestingly, there are signiﬁcant diﬀerences among the
execution times by the classiﬁer ensembles trained for the
12 malware families. On average, the classiﬁer ensemble
trained for the Rbot family takes the longest time, which
is 0.776 second, and the one trained for the Sdbot family
takes the least time, which is 0.0466 second. The diﬀerences
can be attributed to a number of reasons, such as the set of
features used for classiﬁcation, fraction of positive samples,
how likely positive samples can be detected at the early stage
of the classiﬁer ensemble, and the execution times of SVM-
Light under various conﬁgurations.
6.4 Analysis of Genetic Algorithm
We next show how the genetic algorithm performs in ﬁnd-
ing the optimal conﬁgurations. We examine the executions
of the genetic algorithm over all the 12 malware families,
and ﬁnd that about 50.8% of them do not return plausible
solutions, which lead to unused feature types seen in Table 1
(i.e., those marked with ’-’). Next we consider only the cases
in which the genetic algorithm returns a plausible solution.
Generation
Fraction Crossover
Partial
Full
1
2
3
49.2%
24.6%
26.2%
0
22.2%
27.1%
Mutation Mutation
0
35.6%
39.6%
100%
42.2%
33.3%
The above table breaks down the fraction of solutions
found from each generation.
It is noted that almost half
of the conﬁgurations found come from the ﬁrst generation,
which essentially uses full mutation to randomly generate
solutions. Each of the second and third generations pro-
duces one fourth of the plausible solutions. One interest-
ing observation is that among the solutions in the second
and third generations, the full mutation scheme still con-
tributes to a signiﬁcant fraction of these solutions; however,
when the reproduction process continues, the fraction of so-
lutions randomly generated from full mutation decreases.
This is because the evolutionary process gradually improves
the quality of the population from both the crossover and
the partial mutation schemes. Hence, if there are only a
small number of searches used to ﬁnd the optimal conﬁg-
uration, global search, which randomly explores the entire
conﬁguration space by full mutation, is more eﬃcient in ﬁnd-
ing a good solution; however, with more searches allowed,
local search, either crossover or partial mutation, is able
to focus the searches in those regions with good solutions
and can thus improve the current solutions more eﬃciently.
This suggests that the genetic algorithm can combine the
advantages of both local search and global search in ﬁnding
optimal conﬁgurations.
7. RELATED WORK AND DISCUSSIONS
Due to scalability advantages over manual malware analy-
sis, machine learning has been applied in a number of previ-
ous studies for distinguishing malware programs from benign
ones (e.g., [30, 14, 25, 27, 1, 32]). Malware detection is a dif-
ferent task from malware classiﬁcation, which is the theme
of this study, as the goal of the later is to classify malware
variants into their corresponding families.
In some recent
works, machine learning has also been applied to automate
the process of malware classiﬁcation (e.g., [21, 40, 15, 19,
38, 20, 39]). The main diﬀerences among these works lie
in the types of features used for malware classiﬁcation. Al-
though the malware features used in this study are far from
being exhaustive, they cover key malware features collected
from both static analysis and dynamic analysis, and those
features considered in the previous eﬀorts can be easily in-
corporated in our malware classiﬁcation framework based
on the chain Neyman-Pearson criterion. More importantly,
what really distinguishes our work from these previous ef-
forts is that they do not consider diﬀerent requirements on
diﬀerent types of errors induced by malware classiﬁcation.
For instance, if we want to study the trend of a malware
family, we expect that the majority of the samples in this
family should indeed belong to this family, which requires
us to have a malware classiﬁer with a low false positive rate
even though we have to sacriﬁce its detection rate. Hence, it
is of important to have the ﬂexibility of balancing the false
positive rate and the detection rate in malware classiﬁcation,
which cannot be achieved by any of existing methods.
The performance evaluation of of this work relies upon
a malware dataset with labels derived from consensus from
AV software detection results. It is known that the labels
obtained in such a way may lead to a biased dataset [16,
18]. Even with such a ﬂaw, it is noted that using the same
dataset, the proposed solution outperforms standard ensem-
ble learning techniques in classiﬁcation performances. In the
future, we plan to use other malware datasets with truthful
labels to further evaluate our approach.
Like many other machine learning techniques, the pro-
posed ensemble classiﬁer is trained assuming that the test
data would have the same or a similar distribution as the
training data. However, the population of malware vari-
ants in a malware family can be nonstationary, which is
called concept drift in parlance of machine learning [33]. In
an adversarial environment, concept drift can bring signiﬁ-
cant challenges to malware classiﬁcation [13]. Concept drift
131requires us to monitor changes of malware populations; if
an abrupt change is observed, the classiﬁers need to be re-
trained. Adapting the proposed ensemble malware classiﬁer
to deal with concept drift remains as our future work.
In this work, we use the cost-sensitive SVM as the basic
block to train individual classiﬁers. Davenport et al. consid-
ered how to tune the costs in cost-sensitive SVM based on
the Neyman-Pearson criterion [7] with a coordinate descent
method. The genetic algorithm used in this work can be eas-
ily parallelized, and has a single parameter (i.e., the number
of generations) to control the number of search attempts.
The existing ensemble learning techniques, such as boost-
ing, bagging, and stacking [9], can be orthogonal to our
work: they can be used to improve the performance of an in-
dividual classiﬁer when a speciﬁc feature type is considered
in our malware classiﬁcation framework. Moreover, the way
in which our work combines multiple classiﬁers also diﬀers
from these existing techniques. First, the ‘OR’ rule used in
our method enables us to take advantage of the correlation
among multiple feature types: If adding a new feature type
does not help improve the classiﬁcation performance over
previous feature types, our classiﬁcation framework does not
collect its values from a malware sample. Second, missing
feature values render it diﬃcult to apply existing methods
directly. For example, given a malware sample, if we cannot
collect values for a speciﬁc feature type, we cannot assign a
weight to it in the boosting algorithm. Third, by applying
the chain Neyman-Pearson criterion, we recursively train a
set of classiﬁers that leads to the optimal performance col-
lectively. Here, the performance of a classiﬁer ensemble is
evaluated according to the Neyman-Pearson criterion, rather
than the classiﬁcation errors used in some existing methods.
Acknowledgment We thank anonymous reviewers for
their comments and our paper shepherd, Aziz Mohaisen, for
his great help on improving the ﬁnal version of this paper.
8. REFERENCES
[1] B. Anderson, D. Quist, J. Neil, C. Storlie, and T. Lane.
Graph-based malware detection using dynamic analysis.
Journal of Computer Virology, 7(4):247–258, 2011.
[2] http://securitywatch.pcmag.com/security/
323419-symantec-says-antivirus-is-dead-world-rolls-eyes.
[3] E. B. Baum and D. Haussler. What size net gives valid
generalization? Neural computation, 1(1):151–160, 1989.
[4] http://cnx.org/content/m11548/1.2/.
[5] C. J.C. Burges. A tutorial on support vector machines for
pattern recognition. Data mining and knowledge discovery,
2(2):121–167, 1998.
[6] O. Chapelle, B. Sch¨olkopf, and A. Zien. Semi-supervised
learning, volume 2. MIT press Cambridge, 2006.
[7] M. A. Davenport, R. G. Baraniuk, and C. D. Scott. Tuning
support vector machines for minimax and neyman-pearson
classiﬁcation. IEEE Trans. Pattern Anal. Mach. Intell.,
32(10):1888–1898, October 2010.
[8] T. G. Dietterich. Ensemble methods in machine learning.
In Multiple classiﬁer systems. Springer, 2000.
[9] T. Hastie, R. Tibshirani, and J. Friedman. The elements of
statistical learning: Data Mining, Inference, and
Prediction. Springer, 2009.
[10] H. He and E. A. Garcia. Learning from imbalanced data.
IEEE Trans. on Knowledge and Data Engineering, 2009.
[11] http://www.imperva.com/docs/HII_Assessing_the_
Effectiveness_of_Antivirus_Solutions.pdf.
[12] http://www.pintool.org/.
[13] A. Kantchelian, S. Afroz, L. Huang, A. C. Islam, B. Miller,
M. C. Tschantz, R. Greenstadt, A. D. Joseph, and J. D.
Tygar. Approaches to adversarial drift. In ACM AISec’13.
[14] J. Z. Kolter and M. A. Maloof. Learning to detect and
classify malicious executables in the wild. Journal of
Maching Learning Research, 7:2721–2744, December 2006.
[15] D. Kong and G. Yan. Discriminant malware distance
learning on structural information for automated malware
classiﬁcation. In Proceedings of ACM KDD’13, 2013.
[16] P. Li, L. Liu, D. Gao, and M. K Reiter. On challenges in
evaluating malware clustering. In RAID’10.
[17] http://www.csie.ntu.edu.tw/~cjlin/libsvm/.
[18] A. Mohaisen and O. Alrawi. AV-meter: An evaluation of
antivirus scans and labels. In Proceedings of DIMVA’14.
[19] A. Mohaisen and O. Alrawi. Unveiling zeus: automated
classiﬁcation of malware samples. In Proceedings of the
22nd international conference on WWW companion, 2013.
[20] A. Mohaisen, A. G. West, A. Mankin, and O. Alrawi.
Chatter: Exploring classiﬁcation of malware based on the
order of events. In IEEE Conference on Communications
and Network Security (CNS’14).
[21] L. Nataraj, V. Yegneswaran, P. Porras, and J. Zhang. A
comparative assessment of malware classiﬁcation using
binary texture analysis and dynamic analysis. In
Proceedings of ACM AISec’11.
[22] http://www.offensivecomputing.net/.
[23] http://orange.biolab.si/.
[24] N. C. Oza and K. Tumer. Classiﬁer ensembles: Select
real-world applications. Information Fusion, 9(1), 2008.
[25] R. Perdisci, A. Lanzi, and W. Lee. Mcboost: Boosting
scalability in malware collection and analysis using
statistical classiﬁcation of executables. In ACSAC’08.
[26] K. Raman. Selecting features to classify malware. In
Proceedings of InfoSec Southwest, 2012.
[27] K. Rieck, P. Trinius, C. Willems, and T. Holz. Automatic
analysis of malware behavior using machine learning. J.
Comput. Secur., 19(4):639–668, December 2011.
[28] C. Rossow, C. J. Dietrich, C. Grier, C. Kreibich,
V. Paxson, N. Pohlmann, H. Bos, and M. Van Steen.
Prudent practices for designing malware experiments:
Status quo and outlook. In IEEE Symposium on Security
and Privacy, pages 65–79. IEEE, 2012.
[29] M. Saar-Tsechansky and F. Provost. Handling missing
values when applying classiﬁcation models. Journal of
Machine Learning Research, 8:1623–1657, December 2007.
[30] M. G. Schultz, E. Eskin, E. Zadok, and S. J. Stolfo. Data
mining methods for detection of new malicious executables.
In IEEE Symposium on Security and Privacy, 2001.
[31] C. Scott and R. Nowak. A neyman-pearson approach to
statistical learning. IEEE Transactions on Information
Theory, 51(11), 2005.
[32] M. Z. Shaﬁq, S. M. Tabish, F. Mirza, and M. Farooq.
Pe-miner: Mining structural information to detect
malicious executables in realtime. In RAID’09.
[33] A. Singh, A. Walenstein, and A. Lakhotia. Tracking concept
drift in malware families. In Proceedings of ACM AISec’12.
[34] http://svmlight.joachims.org/.
[35] Symantec Internet security threat report. Symantec
Corporation, 2011.
[36] V. N. Vapnik and A. Y. Chervonenkis. On the uniform
convergence of relative frequencies of events to their
probabilities. Theory of Probability & Its Applications,
16(2):264–280, 1971.
[37] https://www.virustotal.com/.
[38] A. G. West and A. Mohaisen. Metadata-driven threat
classiﬁcation of network endpoints appearing in malware.
In Proceedings of DIMVA’14.
[39] Z. Xu, J. Zhang, G. Gu, and Z. Lin. Autovac: Towards
automatically extracting system resource constraints and
generating vaccines for malware immunization.
[40] G. Yan, N. Brown, and D. Kong. Exploring discriminatory
features for automated malware classiﬁcation. In Detection
of Intrusions and Malware, and Vulnerability Assessment
(DIMVA’13). 2013.
132