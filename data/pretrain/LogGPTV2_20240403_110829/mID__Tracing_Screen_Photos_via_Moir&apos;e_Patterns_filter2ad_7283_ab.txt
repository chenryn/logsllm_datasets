via k-means clustering with the assistance of check codes.
4.3 mID Generation
4.3.1 mID Framing
To label the information source via Moiré-pattern-based ID,
we design an N-bit mID that consists of (1) a 2-bit front check
code, (2) a payload, and (3) a 2-bit end check code. The
payload represents the identity of the information source and
appears as a sequence of binary digits (bits), each having
either the value “0” or “1”. We envision it can provide photo
forensics from three levels.
• Device level. When devices and users are tightly bound,
e.g., the devices can only be accessed by the owners,
the payload can be generated based on the hardware
information of the display device, e.g., the MAC (media
access control) address.
• Operating system (OS) level. When multiple users
share the same device but use their own OS accounts,
the payload can be generated at the OS level based on
the OS user account information.
• Application level. For sensitive applications, e.g., the
internal mail system or the database of companies, the
payload can be generated based on the account informa-
tion associated with the application.
The front (end) check code is a two-digit segment “01”
that appears before or after the payload of mID. As thus,
a 14-bit mID with front and end check codes appears as
01XXXXX...01. We design such a check code to facilitate
decoding with twofold beneﬁts. First, the check code can help
restore the exposure-imbalanced images and can thus improve
the decoding accuracy. Second, it provides a baseline for the
k-means clustering to determine which cluster maps to bit “0”
or “1”, as we will reveal in detail in Sec. 4.6.
4.3.2 Display Grating Generation
(cid:48)
As mentioned in Sec. 2, the screen pixels (layer l
1) is pro-
jected onto the camera sensors to form layer l1, and the CFA
of the camera forms layer l2, with their superposition gen-
(cid:48)
erating mIDs. Among the three layers l
1, l1, l2, we can only
manipulate the screen pixels (l(cid:48)
1) for mID grating generation,
since the CFA layer (l2) is determined by the physical struc-
ture of smartphone built-in cameras and the projected screen
display (l1) is affected by the cameras as well. Recall that a
periodical grating layer can be modeled with a frequency and
a phase term:
l(x,y) = p(φ(x,y))
(3)
where l(x,y) represents the pixel value at the coordinate (x,y),
p(·) is a periodic function that determines the frequency of
the grating, and φ(x,y) is a phase function that determines
its geometric layout, as shown in Fig. 2. We explain how to
select appropriate periodic and phase functions for the layer
(cid:48)
l
1 to generate mIDs.
Periodic Function Selection. Due to the long photograph-
ing distance and the pinhole effect of cameras, layer l1 has
(cid:48)
an increased frequency compared with that of layer l
1. Ac-
cording to the Pinhole Camera Theory [35], the object size
projected onto a camera sensor is inversely proportional to
the distance between the object and the camera sensor:
Scam =
Sob j × L f
D
(4)
where Scam and Sob j are the photographed and actual sizes of
the object respectively, L f is the focal length of the camera,
and D is the distance between the camera and the object. Due
to that the photographing distance D is usually much larger
than the focal length L f , the size of layer l
D per
(cid:48)
1 shrinks to L f
2972    30th USENIX Security Symposium
USENIX Association
· f
(cid:48)
unit area, which gives f1 = D
1. As a result, the frequency
L f
(cid:48)
1 − f2.
of the generated Moiré patterns can be given as D
L f
As the camera focal length L f and the CFA frequency f2 are
ﬁxed by the photographing device, for a speciﬁc device, the
Moiré patterns are mainly determined by the photographing
distance and the frequency of the generated grating.
· f
Considering the goal of adversaries is to capture the con-
tents on the screen completely and clearly, the photographing
distance D used by adversaries shall be within a range. For
a 24" LCD display commonly-seen on the market, the pho-
tographing distance D is usually larger than 60 cm for various
smartphones, as calculated in Appendix 11.1. To improve
the chances of the generated Moiré patterns to be captured
by cameras, the frequency of the periodic function p(·) shall
match the photographing distance, and should be as small
as possible since thinner strips are more likely to appear as
uniformly colored compared with wider stripes. Thus, we set
the frequency of p(·) to be 2 pixels, which is shown to be
effective in Sec. 6.
Phase Function Selection. While the periodic term affects
the density of the grating, the phase function determines its
geometric layout and thus the Moiré patterns. Due to that
in LCD panels, unit structures of the same color are usually
arranged in vertical, the natural grating formed by the LCD
display is vertical stripes of red, green, and blue respectively,
as shown in Fig. 3. To achieve vision insensitivity to the
adversary, we design mID that imitates the Moiré patterns
that are generated naturally by the screen-camera channel.
Speciﬁcally, with the selected frequency, we generate a binary
display grating for each bit of mID in the form of vertical
stripes, as given below:
l
(cid:48)
1(x,y) = p1(φ1(x,y))
p1(u) = 0.5 + 0.5cos(πu)
φ1(x,y) = y mod 2
(5)
As the generated mID display grating has a frequency of 2
pixels while the digital screen structure has a frequency of 1
pixel, the mID-related and the natural Moiré patterns appear
at different distances and will not interfere with each other.
4.3.3 Intensity-based ID Encoding
Existing work [17, 30, 43, 45] usually hides information in
the Moiré patterns by manipulating the phase of one of the
gratings, e.g., two secret images show no obvious patterns
when observed separately, but reveal hidden information when
overlapped. However, manipulating the phase is likely to bend
the vertical stripes, and thus may result in visible changes to
adversaries. In addition, phase-based methods usually induce
signiﬁcant patterns in the generated Moiré fringes, which is
likely to alert the adversaries and is unacceptable.
Intensity of Moiré Pattern. To address it, we modify the
intensity of Moiré patterns. Speciﬁcally, mID-related Moiré
patterns are new frequency components generated by the su-
(b) Discretized bipolar NRZ coding for bi-
nary sequence “10”.
(a) Unipolar NRZ coding for
binary sequence “101010001”.
Figure 5: The improved discretized bipolar NRZ coding en-
sures a ﬂat edge between bits “0” and “1”.
perposition of the display grating and the camera CFA. Since
the latter is determined by the camera, the intensity of the
mID-related Moiré patterns depends on the intensity of the
display grating. Thus, the intensity of the generated Moiré
patterns can be changed by manipulating the pixel values of
two adjacent grating stripes in the RGB color space, i.e., the
contrast of two adjacent stripes. Such an observation is also
validated by our experiments. As the generated grating has
a spatial frequency of 2, we can denote the even column in
the generated grating as c0 = (r0,g0,b0), and the odd one
as c1 = (r1,g1,b1). With Equ. 6, c0 = (255,255,255) and
c1 = (0,0,0) generate the most intensive Moiré patterns. De-
note the color distance between two adjacent stripes, or in
other words, a pair of color vectors {c0,c1}, as their l2-norm
in the RGB space:
Cd = ||{c0,c1}||2 =
(cid:113)
(r0 − r1)2 + (g0 − g1)2 + (b0 − b1)2
(6)
A larger Cd represents a larger contrast between two adjacent
stripes and thus represents a more signiﬁcant stripe grating,
which results in more intensive Moiré patterns. When Cd
decreases to zero, i.e., the even and odd columns are identical,
the generated grating loses its periodicity and thus no Moiré
patterns will be observed.
Based on it, we propose to embed identity numbers into the
generated Moiré pattern via its intensity levels. Intuitively, we
can utilize the high intensity level to represent bit “1”, and the
low intensity level to represent bit “0”, which is also known
as the unipolar non-return-to-zero (NRZ) code [31], as shown
in Fig, 5(a). However, such an implementation introduces
discontinuity at the junction of bit “0” and bit “1”, and thus
may aggravate suspicious patterns to adversaries if they are
adjacently encoded.
Discretized Bipolar Non-return-to-zero Encoding. To
alleviate the problem of discontinuity, we discretize both the
high and low levels to make the possible junction smooth,
which we call the discretized bipolar NRZ encoding. As
shown in Fig. 5(b), we discretize the high (low) intensity
level into k sub-levels with each sub-level consisting of n grat-
ing columns to approximate a cosine function, for the sake
of being ﬂat at the edge of a bit. Another beneﬁt of such an
implementation is that bipolar encoding increases Cd between
bit “0” and bit “1” compared with the unipolar one, which
may ease the difﬁculty of decoding.
Nonlinearity of Color Perception. In the discretized bipo-
lar NRZ encoding, each intensity level is represented with
USENIX Association
30th USENIX Security Symposium    2973
101010000110(a) Color vector pairs with identical distance.
(b) Color vector pairs with the same c0+c1
2
but increasing distances.
(c) Color vector pairs with luminance correction and increasing distances.
Figure 6: An illustration of ten intensity levels for encoding
using three methods, and the ones created by the proposed
luminance correction scheme (c) show almost no visual differ-
ence and can embed mID without being noticed by adversaries.
one pair of color vectors {c0,c1} in the RGB space. Since bit
“0” and bit “1” share the same baseline, the encoding requires
(2k− 1) intensity levels in total, i.e., (2k− 1) pairs of color
vectors with increased color distances.
We employ the visual average effect of human visual sys-
tem (HVS) [51] to generate the required color vectors, which
suggests that human eyes take the average of contiguous ob-
jects as their perception and many image scaling methods are
built upon it [18]. As a result, we attempt to generate various
color vectors for different intensity levels while keep their
average RGB vector c0+c1
identical, which we assume may
have the potential to ensure the evenness of the generated
grating image.
2
Take the mid-gray (128,128,128) as the background color
for an instance, we can generate k pairs of vectors with in-
creased color distances such as:
Leveli : {c0,c1}i = {(128 + 5i,128 + 5i,128 + 5i),
(128− 5i,128− 5i,128− 5i)},i ∈ {1,2, ...,k}
(7)
2
Compared with the naive color vector pairs with an identi-
cal distance shown in Fig.6(a), the proposed ones, i.e., color
vectors with the same c0+c1
but increasing distances, exhibit
much fewer visual differences as shown in Fig. 6(b). Yet, it is
insufﬁcient to generate an even grating image. After careful
analysis, we ﬁnd it is because that adjusting the distance of
{c0,c1} changes its luminance perceived by human eyes, as
a result of the Gamma Correction [25] adopted by modern
display devices.
As humans perceive light and color non-linearly, with
greater sensitivity to relative differences between darker tones
than between lighter ones, gamma encoding is applied in im-
ages to optimize the usage of bits when encoding an image, or
bandwidth used to transmit an image [32]. Correspondingly,
modern display devices conduct gamma correction to reveal
the true colors. Both gamma encoding and gamma correction
follow a pow-law expression [47]:
Vout = AV γ
in
(8)
where the input value Vin is multiplied by the constant A and
powered by the gamma value γ to get the output value Vout,
with γ  1 for correction (decoding).
As a result, the generated RGB vector is expanded before
display and the luminance perceived by human eyes is not the
arithmetic mean c0+c1
as supposed.
2
Luminance Correction. To further make the encoding
unnoticeable, we propose a luminance correction algorithm
based on gamma correction and the non-uniformity color
perception of HVS. Speciﬁcally, we model the average lu-
minance Y of an RGB vector pair {c0,c1} by removing the
gamma compression, which transforms the image to a linear
RGB color space as follows:
Y{c0,c1} = wr(rγ
where γ = 2.2 for most modern display devices [47]. wr, wg
and wb are the weights of the RGB channels respectively,
which represent the intensity (luminance) perception of typ-
ical humans to lights of primary colors. Given that human
vision is most sensitive to green and least sensitive to blue,
wg has the largest value of 0.7152 and wb has the smallest
value of 0.0722, with wr = 0.2126 [48].
1) + wg(gγ
1) + wb(bγ
0 + bγ
1)
0 + gγ
0 + rγ
(9)
With luminance correction, we can generate RGB vector
pairs with even luminance by optimizing the following equa-
tions:
E = |Y{c0,c1}−Ybg|
bg + wggγ
Ybg = wrrγ
mmmaaaxxx Cd = ||{c0,c1}||2
bg + wbbγ
bg
(10)
s.t. E < ε
s.t.
ri,gi,bi ∈ Z∩ [0,255] ,i = 0,1
We utilize the global search algorithm to solve the above opti-
mization problem. However, as we can see, the solution to the
formula is not unique and the number of searched vector pairs
is determined by the error threshold ε. A larger ε contributes
to more RGB vector pairs at the cost of less evenness of the
generated grating image. Thus, ε can be determined upon
the requirement of k, or in other words, the number of RGB
vector pairs needed to implement the discretized bipolar NRZ
encoding. After luminance correction, the generated grating
is almost invisible even with increasing color distances, as
shown in Fig. 6(c).
In summary, we utilize the discretized bipolar NRZ en-
coding to embed identity numbers into the generated Moiré
pattern via its intensity, and employ luminance correction to
ensure the evenness of the generated gratings.
4.4 mID Embedding
To embed the generated gratings and maximize their possibil-
ity of being captured in photos, we automatically analyze the
2974    30th USENIX Security Symposium
USENIX Association
current page of the screen.
Region of Interest. Given the company’s goal is to prevent
cyber-theft of trade secrets, some regions of the current page
that contain conﬁdential information such as texts or images,
are of more interests to the company, i.e., regions of interest
(ROIs). To search for suitable regions for mID embedding, we
ﬁrst locate the possible ROI of the current page with computer
vision (CV) techniques [14, 24, 54], which mainly extract the
locations of texts and images, as shown in Fig. 7. The number
of ROI extracted is determined by the screen content, and we
calculate the centroid of these regions as the center of ROI for
the current page. Alternatively, the defenders can manually
mark the ROIs according to their demands.
Region of Embedding. To maximize the possibility that
mID is captured in the screen photos, we embed the generated
gratings in the vicinity of the ROI center, i.e., regions of
embedding (ROEs). In general, we assume that ﬂat regions
close to the ROI center are more suitable for embedding since
(1) mID is more likely to be captured in the screen photos,