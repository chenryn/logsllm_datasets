### Evaluation of Interpreters

#### Performance Evaluation
The performance of interpreters, with a lower score indicating better performance, is assessed. Existing in-distribution samples (S.R.T.D.) perform poorly, especially with fewer dimensions, highlighting the necessity of searching for references in DeepAID. The results also show that supervised interpreters are not suitable for unsupervised learning due to their low fidelity. Notably, DeepAID significantly outperforms other methods, particularly when using fewer dimensions (e.g., DeepAID with 10% dimensions exceeds others by >50%).

#### Stability Evaluation
Stability of interpreters refers to the consistency of interpretations for the same samples across multiple runs. Following the approach in [14, 54], we focus on the index of important feature dimensions rather than their values. Given two interpretation vectors \( \mathbf{v}_1 \) and \( \mathbf{v}_2 \) of important dimension indexes, we use Jaccard Similarity (JS) to measure the similarity, defined as:
\[ \text{JS}(\mathbf{v}_1, \mathbf{v}_2) = \frac{| \text{set}(\mathbf{v}_1) \cap \text{set}(\mathbf{v}_2) |}{| \text{set}(\mathbf{v}_1) \cup \text{set}(\mathbf{v}_2) |} \]
We repeatedly measure the JS for each anomaly and calculate the average. The results, shown in Figure 5b, indicate that approximation/perturbation-based methods perform poorly due to their random sampling/perturbation, while backpropagation-based methods (DeepAID and DeepLIFT) exhibit strong stability.

#### Robustness Evaluation
We evaluate the robustness of interpreters against random noise and adversarial attacks. Only tabular Kitsune is evaluated since DeepLog's time series data is discrete.

**Robustness to Noise:**
We measure the JS of results interpreting tabular features before and after adding Gaussian noise \( N(0, \sigma^2) \) with \( \sigma = 0.01 \). As shown in Figure 5c, S.R.T.D. is highly sensitive to noise when selecting references. COIN and DeepLIFT are relatively robust compared to other baselines, but still fall short of DeepAID's performance.

**Robustness to Attacks:**
DeepAID is a backpropagation (B.P.)-based method. We develop an adaptive attack, called optimization-based attack, which adds small perturbations to an anomaly \( \mathbf{x}^\circ \) (denoted as \( \tilde{\mathbf{x}}^\circ \)) to induce large changes in the finally searched reference \( \mathbf{x}^* \). Formally:
\[ \arg\max_{\tilde{\mathbf{x}}^\circ} \| D_{\text{tab}}(\tilde{\mathbf{x}}^\circ; \tilde{\mathbf{x}}^\circ) - D_{\text{tab}}(\mathbf{x}^\circ; \mathbf{x}^\circ) \|_p \quad \text{s.t.} \quad \| \tilde{\mathbf{x}}^\circ - \mathbf{x}^\circ \|_p < \delta_a \]
Results show that DeepAID maintains high JS (above 0.91 when \( \delta_a = 0.2 \) and decreases linearly as \( \delta_a \) increases), thanks to its search-based approach. The effectiveness of Input Randomization Noise (I.R.N.) is also demonstrated, as it mitigates most attack effects when \( \sigma_n \geq 0.02 \) without significantly impacting the original stability (JS > 0.95 even when \( \sigma_n = 0.04 \)). Thus, choosing a small \( \sigma_n \) can mitigate attack effects without compromising stability, as shown in Figure 5c.

**Distance-Based Attacks:**
We also evaluate distance-based adversarial attacks that mislead distance calculations in DeepAID. The results show that DeepAID is robust against such attacks. Detailed definitions, results, and analysis are provided in Appendix D.2.

#### Efficiency Evaluation
Efficiency is evaluated by recording the runtime for interpreting 2,000 anomalies for each interpreter. For approximation-based interpreters (LIME, LEMNA, and COIN), the time includes training the surrogate model, and for CADE, it includes training the encoding model. The results, shown in Figure 6, indicate that DeepAID and DeepLIFT are at least two orders of magnitude faster than other methods.

### Conclusions
Experiments in ยง6.2 (summarized in Table 1) show that only DeepAID effectively meets all special requirements of security domains and produces high-quality interpretations for unsupervised deep learning-based anomaly detection.

### Practical Applications of DeepAID

#### Understanding Model Decisions
DeepAID can help capture well-known rules and discover new knowledge. 

**Tabular Data Interpretations:**
Using network intrusion detector Kitsune, we interpret two representative anomalies in Mirai botnet traffic: remote command execution and ARP scanning. The operator, knowing the ground truth, uses DeepAID to verify if the DL model has learned the expected rules. With \( K = 5 \) important feature dimensions, the interpretations (Table 3a and 3b) are both interpretable and reasonable, confirming that the DL model has learned the expected rules.

**Time-Series Interpretations:**
For HDFS log anomaly detector DeepLog, we set sequence length \( t = 6 \) and use \( K = 1 \) dimension for interpretation. In Case 1, the Interpreter determines that the abnormality occurs at \( \mathbf{x}^\circ_t \) and replaces 17 with 11, capturing a well-known rule. In Case 2, the Interpreter identifies an anomaly at \( \mathbf{x}^\circ_1 \) with 5, suggesting a blockmap update without preceding block operations, demonstrating the discovery of new heuristics.

#### Enabling Debuggability
DeepAID interpretations can be used to diagnose explicit errors in the system. Using Kitsune, we showcase how DeepAID helps in debugging and improving the reliability of anomaly detection. The performance of reliable detection based on Distiller is summarized in Table 4, showing that DeepAID enhances the f1-micro and f1-macro scores, especially with increasing \( K \).

By providing high-fidelity and stable interpretations, DeepAID significantly enhances the practicability and reliability of security systems.