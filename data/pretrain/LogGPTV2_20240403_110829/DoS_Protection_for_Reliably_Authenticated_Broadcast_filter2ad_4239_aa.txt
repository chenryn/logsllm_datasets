title:DoS Protection for Reliably Authenticated Broadcast
author:Carl A. Gunter and
Sanjeev Khanna and
Kaijun Tan and
Santosh S. Venkatesh
DoS Protection for Reliably Authenticated Broadcast
Carl A. Gunter, Sanjeev Khanna, Kaijun Tan, and Santosh Venkatesh
University of Pennsylvania
Abstract
Authenticating broadcast packet
communications
poses a challenge that cannot be addressed e–ciently
with public key signatures on each packet, or securely
with the use of a pre-distributed shared secret key, or
practically with unicast tunnels. Unreliability is an
intrinsic problem: many broadcast protocols assume
that some information will be lost, making it problem-
atic to amortize the cost of a single public key signa-
ture across multiple packets. Forward Error Correction
(FEC) can compensate for loss of packets, but denial
of service risks prevent the naive use of both public
keys and FEC in authentication. In this paper we in-
troduce a protocol, Broadcast Authentication Streams
(BAS), that overcomes these barriers and provides a
simple and e–cient scheme for authenticating broad-
cast packet communications based on a new technique
called selective veriﬂcation. We analyze BAS theoreti-
cally, experimentally, and architecturally.
1 Introduction
Authenticating packet broadcasts is an interesting
technical challenge. If a common symmetric key is used
to authenticate the packets then any party that has the
key can spoof the broadcast. Using a public key signa-
ture would solve this problem, but signing and verify-
ing each packet would be expensive. Signing a group
of packets would reduce this cost, but many types of
broadcast are unreliable: if a signature is for a group of
packets and one or more of them is dropped, then it is
not possible to check the signature. A variety of ideas
have been proposed to address this problem with public
keys by including some kind of redundancy such as in-
cluding multiple copies of hash values or using Forward
Error Correction (FEC). Such approaches are vulner-
able to a Denial of Service (DoS) attack on either the
redundancy scheme itself or the public key signature
packets.
In the former case, false parity information
makes it expensive to reconstruct valid packets, and,
in the latter case, a (cid:176)ood of false signatures burdens
the recipient with too many signature checks.
This paper proposes an approach to solving these
and other DoS threats by a technique called selective
veriﬂcation. The idea is to use public key signature
packets to authenticate hashes, parity information, and
data, while using random checking of signature packets
to defend against signature (cid:176)ooding and sequence num-
bers and time stamps to combat replay attacks. The
sender sends many copies of its signature packets and
the recipient checks the signature packets it receives
with a given probability. The number of copies and
the probability of veriﬂcation can be varied to match
the load that the recipient is able to check to cope with
an expected level of attack. For example, suppose a
sender sends a 10Mbps stream to a receiver, but this is
mixed with a 10Mbps stream of DoS packets devoted
entirely to bad signatures. To relieve the recipient of
the need to check all of these bad signatures, the re-
ceiver can check signatures with a probability of 25%,
and, if the sender sends about 20 copies of each signa-
ture packet, the receiver will ﬂnd a valid packet with
a probability of more than 99% even if the network
drops 40% of the sender’s packets. This technique is
inexpensive, eﬁective against severe DoS attacks, and
adaptable to many diﬁerent network characteristics.
To demonstrate selective veriﬂcation we have de-
veloped a protocol called Broadcast Authentication
Streams (BAS) that provides authentication for a data
stream by adding a pair of authentication streams. Our
target is to show that BAS can be used eﬁectively on
stock PCs over mid to high bandwidth links ranging
from 10Mbps to almost 1Gbps. To this end we pro-
vide a theoretical analysis of BAS, an implementation,
and experiments. The theory describes how to set
parameters that aﬁect features such as latency, over-
head, recovery conﬂdence, and maximum buﬁer size
requirements. The experiments conﬂrm our theoreti-
cal calculations and provide practical information such
as throughputs on the target systems. Our implemen-
tation of BAS for a sender takes an array of input RTP
packets and produces an array of authentication data.
For a receiver, it takes an array of packets based on
models of packet loss and a \shared channel" model
of DoS attacks introduced in this paper and processes
these to ﬂnd authenticated data packets. These experi-
ments conﬂrm estimates like the one above and provide
information about throughput capacities. For instance,
the packets from a 10Mbps sender with 40% loss can
be authenticated with the use of less than 10% of pro-
cessor time even during an attack of 10Mbps. Our the-
ory predicts and our experiments conﬂrm that selective
veriﬂcation and BAS work well on PCs for applications
that can tolerate 1-2 second latencies under signature
(cid:176)ood attacks that range up to 500Mbps. This can be
compared to latencies for playout buﬁers for Internet
multi-media streams, which often use latencies of 5-10
seconds.
Another contribution of the paper is a rigorous model
for analysing and quantifying the eﬁectiveness of a DoS
protection scheme. We call the one introduced here the
shared channel model. It is based on the idea that an
adversary can insert packets into a valid stream and
may aﬁect the loss rate of the stream statistically, but
cannot choose exactly which valid packets are actually
received. This contrasts with the Dolev-Yao model in
which the adversary is considered to have control over
exactly which packets are delivered. We argue that the
weaker model is more appropriate for analyzing DoS
threats in many cases.
The paper is divided into nine sections. Section 2
introduces the shared channel model, which serves as
the foundation for our analysis. Section 3 provides an
informal description of the BAS protocol. Section 4 de-
scribes related work. We specify the BAS protocol in
Section 5 and analyze it theoretically in Section 6. We
describe our prototype implementation of BAS with se-
lective veriﬂcation in Section 7. This was used to carry
out experiments described in Section 8. Section 9 con-
cludes. Appendices contain details of the loss models
and error-correction codes used, theoretical results and
proofs, and additional experimental data.
2 Shared Channel Model
The shared channel model assumes that a legitimate
sender and an attacker share a packet communication
channel to a receiver. A given model is characterized
by a 4-tuple (W0; W1; A; p) consisting of the minimum
bandwidth W0 of the sender, the maximum bandwidth
W1 of the sender (where W0 • W1), the bandwidth A
of the adversary, and the loss rate p of the sender where
0 • p  1, it is a disproportionate attack. A
proportionate attack with a loss rate of 20% is depicted
in Figure 1. In an informed shared channel model, the
adversary is assumed to know all of the values sent
by the receiver and is able to forge predictable values
Sender Packet
Dropped Sender Packet
S1
A1
S2
S3
S4
A2
A3
S5
A4
A5
Attacker Packet
Figure 1: Shared Channel Model
like sequence numbers. This makes a considerable dif-
ference for some protocols. For instance, an informed
attack on TCP could use sequence numbers in an on-
going connection to break the connection, providing a
much cheaper attack than an uninformed approach like
SYN (cid:176)ooding. An adversary may ‘modify’ a packet by
replaying a modiﬂed version of a previously-seen sender
packet. However, the adversary is unable to cause spe-
ciﬂc sender packets to be dropped or modiﬂed: sender
packets are dropped probabilistically at rate p. The
model assumes that sender packets arrive in the order
in which they were sent when they do arrive. However,
packets may appear to arrive out-of-order if an adver-
sary replays dropped packets. Many protocols, includ-
ing BAS, will treat reordered packets as dropped if they
are grossly out-of-order (say, by more than a few hun-
dred packets), so the assumption of in-order delivery
for sender packets is not as strong as it may appear.
Reordering can be modeled by taking a higher value
of p and assuming that the adversary replays many
dropped packets.
The shared channel model is more appropriate for
analyzing denial of service than the much-studied
Dolev-Yao model [3], which assumes that an adversary
is able to drop all sender packets. An adversary with
this ability is ensured of a DoS capability. The shared
channel model is weaker than one that assumes that the
adversary has all of the channel bandwidth (W1 = 0).
When a host can handle the load with this assumption
(for instance, by rejecting all of bad packets without
excessive processing), it can handle it with, say, a pro-
portionate attack. But, there are cases (as shown later)
where W0 6= 0 makes a major diﬁerence in how large A
must be to achieve an eﬁective attack. That is, if the
legitimate sender can get some packets through, then
these can be used to raise the bar for a successful DoS
attack.
A signature (cid:176)ood attack is one in which an adver-
sary sends false signatures. Checking these signatures
is costly and burdens the victim’s processor. Typical
costs1 are given in Table 1. The table provides signa-
1These are for a 2.4GHz PC with Redhat Linux 7.3 using
Table 1: Cryptographic Costs
Crypto Operations Operating Time
Sign(3)
Check(3)
Sign(17)
Check(17)
Sign(65,537)
Check(65,537)
Hash(1460)
Hash(10)
4.92ms
86.8„s
4.96ms
124„s
5.10ms
270„s
13.3„s
1.57„s
ture and veriﬂcation times for RSA on 10 bytes with
exponents of 3, 17, and 65537 as well as SHA hashes
on 10 and 1460 bytes. One can see from the ﬂgures for
public key signatures that the processor is only able to
create about 200 signatures each second. The costs of
a Public Key Check (PKC) depends somewhat on the
exponent. We will work with an exponent of 17 in this
paper. A signature (cid:176)ood that results in 8000 PKC/sec
would completely overwhelm a processor. We will typ-
ically work in terms of a PKC budget, for instance, one
that requires that no more than 5% of processor time be
spent on PKCs. So an eﬁective (cid:176)ood could be achieved
by forcing 400 PKC/sec. In a proportionate attack at
high bandwidths, this could be easy. For instance, in
Figure 1, if packet S5 holds a signature on hashes for
packets S1-S4 and packets A1-A5 are false signature
packets that look like S5 but contain a bad signature,
then the receiver may end up checking most or all of
these bad signatures. Since the entire bandwidth of
the adversary could be devoted to the signature (cid:176)ood,
the attack could realize a very high PKC burden at the
receiver.
3 Informal Description
Our protocol, BAS, is based on a combination of FEC
and repetition coding to provide modest bandwidth
overhead and robust DoS protection. BAS uses FEC
to reduce the costs of repeated hashes; it uses repeated
signatures to secure the FEC-encoded hashes and ad-
dress DoS attacks based on fake signature packets.
Overall the architecture consists of three streams of
packets as pictured in Figure 2. The ﬂrst stream, called
the data stream, consists of the data packets; these are
not required to contain any cryptographic information.
The BAS protocol aims to authenticate this stream;
the data packets may be encrypted if it is important
operations from OpenSSL 0.9.6.
Data Stream
Hash/Parity Stream
Signature Stream
Hash
Hash
Hash
Parity
Figure 2: Architecture for Broadcast Authentication
Streams (BAS)
to preserve their conﬂdentiality, but the BAS protocol
does provide this service. The second stream, called
the Hash/Parity (HP) stream, consists of two kinds of
packets. The ﬂrst kind are called hash packets. These
contain hashes of data packets. The second kind are
called parity packets. These contain FEC coding infor-
mation that allows dropped hash packets to be recon-
structed. The third stream, called the signature stream,
consists of packets that sign hashes of HP packets. The
collection consisting of the data packets together with
their corresponding hash, parity, and signature packets
is called a transmission group (TG). Figure 2 shows the
packets in one transmission group. In general, a trans-
mission group will include more than a thousand data
packets, as determined by the allowable latency for au-
thentication, a number of hash and parity packets that
depends on the number of data packets and loss rate,
and a number of signature packets that depends on the
bandwidth and DoS threat.
Our approach to DoS prevention is based on two
strategies. First, FEC-encoded information is pro-
tected by a digital signature. Thus spurious packets
intended to burden FEC decoding will be discarded
as quickly as their hashes can be checked. Second,
we address DoS based on public key signature (cid:176)ood-
ing with selective veriﬂcation. We discuss two kinds
of selective veriﬂcation, sequential and bin.
In both
cases the idea is to send copies of signature packets to
the receiver. The receiver checks a subset of the signa-
ture packets it receives. Some of these may be spoofed
by an attacker, but the receiver will ﬂnd a valid one
quickly enough and with su–ciently modest computa-
tional eﬁort to defeat signature (cid:176)ooding. In sequential
veriﬂcation, the receiver veriﬂes signature packets ran-
domly until ﬂnding a valid signature. After a su–cient
number of such trials the probability of ﬂnding a valid
signature will be high and the next signature packet
can be sought. In bin selection we use sequence num-
bers in redundant signature packets. That is, the same
signature is sent, but with a diﬁerent sequence num-
ber for each copy. Suppose for example that a channel
with a 25% average loss rate between the sender and
receiver supports an attack in which an adversary can
send 500 fake signature packets per second. In bin veri-
ﬂcation, we divide the spooﬂng eﬁorts of the adversary
between a collection of signature packets using distinct
sequence numbers. For example, suppose the sender
creates 10 signature packets numbered 1 through 10
in a given second. The receiver waits long enough to
receive some or all of these, together with up to 500
spoofed signature packets from an attacker. For at
least 2 of the ten sequence numbers there will be no
more than 102 spoofed and legitimate packets using
that number. There is about a 93% probability that a
legitimately signed packet is in this group of 102 pack-
ets. Thus the attacker is typically only able to force an
additional 100 veriﬂcations with 500 spoofed packets.
Increasing the number of sequence-numbered packets
improves the burden at the receiver at the cost of a
modest additional bandwidth.
Our approach to loss is also based on two strategies.
The ﬂrst, as discussed already, is to use FEC where
possible and repetition where necessary. Since repeti-
tion was necessary to thwart denial of service in some
cases anyway, and FEC oﬁers very signiﬂcant savings
over repetition, this provides a comfortable tradeoﬁ.
The second strategy involves spacing hash, parity, and
signature packets though the data stream to improve
robustness against bursts. The idea is illustrated in
Figure 3. The ﬂgure shows packets from three trans-
0
1
0
1
0
1
0
1
-1
0
0
1
0
1
0
1
0
-1
1
0
0
1
0
1
0
1
0
1
0
-1
1