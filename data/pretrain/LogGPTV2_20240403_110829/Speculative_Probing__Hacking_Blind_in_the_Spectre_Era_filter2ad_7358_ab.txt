is fast (i.e., a cache hit), then the victim must have accessed the
shared cache line. p+p can operate even without shared memory
between attacker and victim since it detects accesses to a (shared)
cache set. In p+p, attackers first build eviction sets [82, 95] (i.e.,
sets of memory addresses that map to the same cache set and with
at least as many elements as the cache’s associativity). Accessing
an eviction set replaces all the cache lines in the corresponding
cache set. Briefly, in modern architectures all the cache lines in an
eviction set correspond to data at the same offset of their respective
memory pages. We say that these cache lines, and the corresponding
eviction set (and hence their pages), have the same color. Under
p+p, attackers access an eviction set to prime the target cache set.
After a potential victim operation, the target cache set is probed
using the eviction set to measure the access latency. A slow probe
(i.e., a cache miss) signals the victim’s activity.
2.4 Speculative Execution Attacks
Modern CPUs execute instructions ahead-of-schedule to increase
performance, e.g., to hide memory-access delays. This is done by
predicting the outcome of control-flow decisions, which cannot
be determined yet, and speculatively executing instructions based
on these predictions. CPUs contain multiple predictors, both for
conditional and indirect (i.e., pointer-based) branch instructions.
Results produced during this speculation window are “parked” until
the branch instruction completes, i.e., the instruction is retired. If
the prediction fails, the CPU discards the parked results, leaving no
trace in architectural state (e.g., registers and memory). However,
speculative execution does leave observable results, or side effects,
in the microarchitectural state of the processor (e.g., the cache),
even if the instructions operated on privileged data [61].
This observation has led to numerous attacks [53, 61, 94], coined
speculative (or transient) execution attacks, where a local attacker
exfiltrates data from the kernel. The attacks massage the microarchi-
tectural state (e.g., by manipulating the state of branch predictors) to
force controlled speculative execution and run specific gadgets that
access sensitive data. By carefully picking the gadgets, traces of that
data are left in the microarchitectural state and can be exfiltrated
using a cache attack such as p+p.
For instance, in a Spectre-BCB (v1) attack, attackers may pick
kernel gadgets that perform speculative out-of-bounds accesses
determined by a syscall-controlled value x:
if (x < array1_size)
y = array2[array1[x] * 4096];
Attackers first force the if-protected statement to be speculatively
executed (e.g., by training the branch predictor with a sequence
of small values for x). They then provide an out-of-bound x to
speculatively read an arbitrary value in the conditional branch and
use it as an index into array2. Finally, they use a cache attack to
infer the array index and leak the value of array1[x].
Similarly, in a Spectre-BTB (v2) attack, attackers poison the
Branch Target Buffer (BTB) to speculatively hijack indirect calls
to a controlled target (e.g., by repeatedly issuing indirect branches
to a colliding user address). By carefully picking a target gadget,
attackers can again use a cache attack to exfiltrate the data.
Kernel mitigations against these attacks perform ad-hoc array in-
dex masking to thwart user-controllable speculative out-of-bounds
accesses [21] and either prevent user-level indirect branch poison-
ing with hardware support [46] or stall indirect branch speculation
using Retpolines [88]. None of these (and other) mitigations affects
BlindSide, which (i) exploits conditional branch mispredictions (a la
Spectre-BCB) but does not rely on (masked) user-controlled array
gadgets; (ii) exploits speculative control-flow hijacking (a la Spectre-
BTB) but does not rely on indirect branch mispredictions—based
on poisoning the BTB or other buffers [90].
3 THREAT MODEL
We assume a realistic threat model with an attacker who is able
to execute code on the target machine. We further assume that
the attacker has access to a software vulnerability in the higher-
privileged code that allows her to overwrite code pointers. The
attacker’s goal is to exploit the vulnerability to escalate privileges.
While this scenario is common in browsers, OS kernels, or hyper-
visors, in this paper we mostly focus on a modern Linux kernel
with all the mitigations enabled. To defend against software vul-
nerabilities, the Linux kernel enforces common mitigations against
control-flow hijacking attacks such as DEP, stack canaries, and
(possibly fine-grained and leakage-resistant) randomization. It also
enforces SMEP, SMAP, and NX-physmap to prevent ret2usr [50]
and ret2dir [49] attacks. To defend against fault-based speculative
execution attacks, the Linux kernel enforces Kernel Page Table Isola-
tion (KPTI) to mitigate Meltdown [61], encodes swapped page table
entries to mitigate Foreshadow [89], and flushes microarchitectural
buffers to mitigate MDS [94]. To defend against Spectre, the Linux
kernel restricts indirect branch speculation or instead uses retpo-
lines to mitigate speculative hijacking of code pointers [88]. It also
utilizes array-index masking to mitigate unauthorized out-of-bound
memory accesses [21].
4 SPECULATIVE PROBING
Starting from the ability to corrupt a code pointer, speculative
probing relies on the ability to speculatively hijack the control flow
to a controlled target in the victim (e.g., the kernel). On the surface,
a victim code snippet that can be exploited for this purpose looks
like a hybrid Spectre-BCB/BTB snippet:
if (expression) {
/* ... */
f_ptr(...);
/* ... */
}
The if conditional branch allows the attacker to control spec-
ulative execution, while the indirect call via the f_ptr function
pointer enables speculative control-flow hijacking. In contrast to
Spectre-BTB’s speculative hijacks (caused by indirect branch mis-
prediction), we hijack the control flow by corrupting f_ptr with a
software vulnerability similar to plain code reuse. However, unlike
real code reuse, we control speculative execution via the conditional
branch to ensure the corrupted pointer is only dereferenced on a
speculative (later-aborted) path, never in “real” execution.
Note that, since modern microarchitectures support multiple
levels of speculation [66], the indirect call will also speculate on its
own, but that is irrelevant for the purpose of speculative probing.
When the if-induced speculative execution reaches the indirect
call, the CPU starts a second-level speculative execution window
due to indirect branch target prediction. But, at the end of that
window, the execution goes back to first-level speculation where
the “real" (but corrupted) function pointer gets executed. Defenses
like Retpoline [88] can only cripple the second-level speculation
here, which only makes our speculative control-flow hijack more
robust by removing unnecessary speculative instructions.
In essence, to implement speculative probing, an attacker needs
to deviate only slightly from a typical code-reuse workflow. After
exploiting a memory corruption vulnerability to corrupt one or
more function pointers, the attacker needs to pick one that is called
within the speculative execution window of a conditional branch
that controls its execution. Since modern processors support spec-
ulative execution windows of hundreds of instructions [53], this
is often straightforward. For instance, as detailed later, over 90%
of kernel indirect branches are 10 or less instructions away from
a conditional branch that controls their execution. To control the
prediction at a conditional branch, attackers have many different
options. They can either prime the PHT part of the BTB [27] shared
between user and kernel [26], tweak the input leading up to the
function pointer dereference to train the dynamic branch predic-
tor [53], or directly corrupt the data conditional using the software
vulnerability to cause the CPU to take (or skip) the branch. The
latter option was the simplest to use in our exploits.
In practice, the extra effort required by speculative probing com-
pared to plain code reuse is relatively low. For instance, after lo-
cating the function pointers that we could corrupt with a given
vulnerability and potential candidates for indirect call sites (as done
for code reuse), it only took us a few hours to select the ideal call
site for our speculative probing exploits discussed in Section 6.
5 SPECULATIVE PROBING PRIMITIVES
Starting from a speculative control-flow hijacking snippet, attackers
can repeatedly hijack speculative execution to controlled targets
and craft a variety of speculative probing primitives tailored to
each specific exploitation scenario. For instance, in a classic KASLR
code-reuse scenario we need specialized probing primitives to lo-
cate the base address of code, heap/physmap (i.e., the memory area
where modern kernels map practically all physical memory in a
direct mapping), and the heap object storing the code-reuse pay-
load [49]. On the other hand, in face of fine-grained randomization,
we need more general, albeit less efficient, arbitrary memory read
primitives [73, 91], which in our case we implement speculatively.
We distinguish between Stage 1 and Stage 2 primitives, where
Stage 1 denotes fundamental probing primitives that can be blindly
used without any a priori knowledge of the code location/layout,
while Stage 2 primitives use Stage 1 primitives to find gadgets tar-
geting specific exploitation scenarios. Primitives to find executable
pages (code region probing) and gadgets (gadget probing) are in
the former category, while example primitives we use to find the
region containing heap/physmap (data region probing), target ob-
jects inside the heap (object probing), or arbitrary memory content
using a Spectre gadget (Spectre probing), are all in the latter.
All these primitives use the same underlying mechanism: they
probe the address space by corrupting the chosen function pointer
subsequently dereferenced during speculative execution. After-
wards, we mount a last-level cache (LLC) p+p attack (or, as detailed
later, f+r when possible, as an optimization) to detect cache traces
of our targets (e.g., code fragments and/or data regions) left by
speculative execution of the corrupted function pointer. In the fol-
lowing, we discuss the Stage 1 and Stage 2 primitives using Figure 1.
5.1 Code Region Probing
In any code-reuse attack, the first step is to identify the location of
code regions in memory. In the presence of coarse-grained KASLR,
finding the base of the kernel code is already sufficient to disclose
the predictable location of all the necessary gadgets.
As we see in Figure 1a, probing for code consists of several steps.
First, the attacker uses the software vulnerability to overwrite a
victim code pointer. The next step is to train the CPU’s predictor
to dereference the corrupted code pointer speculatively next time
the kernel code executes. Then the attacker primes (fills) part of
the cache with an eviction set. After these preparatory steps, the
attacker issues a syscall to speculatively hijack the control flow
to a desired location. Even if the location is invalid or not exe-
cutable, there will be no crashes, since the speculative execution
will mask all exceptions. However, if the target location contains
(arbitrary, even invalid) code on an executable page, the executed
code speculatively fills the corresponding cache lines. By subse-
quently probing the matching cache sets with p+p, the attacker
determines if the address is in the cache (and thus if the chosen
target page is executable).
5.2 Gadget Probing
In the presence of fine-grained and possibly leakage-resistant ran-
domization, code region probing alone is insufficient to find all
the necessary gadgets. Instead, we need to blindly locate specific
gadgets in the randomized code region. Gadgets of interest include
traditional code-reuse fragments as well as speculative execution
(e.g., Spectre) gadgets. As before, we use a speculative probing prim-
itive, but this time we look for specific signals in the cache. While
Stage 1 primitives
(a) Unlike other elements, leaking a code page requires no gadget. The corrupted function pointer contains the probe target (pt). In a successful
probe attempt, this function pointer points to a code page and the probe induces a signal in the cache by speculatively executing the target.
(b) Probing for gadgets looks for activity in an attacker-controlled cache set. The Spectre gadget targeted by the corrupted function pointer
in this example activates the cache set if the probe target (pt) formed by the value read at V plus ∗B (corrupted by the attacker) points to it.
Note: no gadgets are needed a priori for this primitive.
Stage 2 primitives
(c) Leaking a data page requires speculative execution of a gadget with 2 chained dereferences. The function pointer targets a gadget that uses
corrupted inputs. In successful probes, p1 points to a data page so the gadget induces a signal in the cache by reading the probe target.
(d) Leaking a data-controlled page requires speculative execution of a gadget with 3 chained dereferences. The function pointer targets a gadget
which gets input from the corrupted page. In a successful probe attempt, the probing input points to the data-controlled page which contains
the probe target. The probe induces a signal in the cache by reading the probe target after retrieving it from the data-controlled page.
(e) Probing with Spectre is similar to the previous case except we use Spectre in two different ways: to leak an actual value (regular Spectre)
and to verify quickly if the value at an address contains 4 specific bytes. For brevity, the figure shows only the latter. It configures memory
such that it can check for a value by ensuring that the dereference in Line 4 only hits the target cache set if the memory contains this value.
The Spectre gadget requires 4 chained dereferences originating from the corrupted page, i.e. 2 to load ∗T, 1 to load ∗B and 1 to load pt.
Figure 1: Probing primitives—green arrows represent successful probe attempts and gray dotted ones the unsuccessful ones.
the cache behavior of code fragments may be quite diverse, we can
optimize the search by limiting ourselves to gadgets (or their neigh-
bors [81]) that announce their presence using an easily detectable
signal. For instance, we may target a gadget dereferencing a pointer
that the attacker controls and check if the corresponding cache set
gets activated. Gadget probing is illustrated in Figure 1b.
In principle, the attacker can observe arbitrary microarchitec-
tural side effects due to accesses to code pages, data pages, and com-
binations thereof, but the current BlindSide attack targets cache
behavior that attackers can observe both efficiently and reliably. In
particular, we focus on gadgets for which successful execution acti-
vates one particular cache set that is under control of the attacker
(and as noise free as possible).
As an example, suppose we want to probe for a Spectre gadget as
shown in Figure 1b. In this case, the buffer overflow overwrites an
object that also contains a function pointer. The values overwritten
by the overflow are controlled by the attacker. Since we control the
values that the target Spectre gadget consumes, we can configure
those values in a way that they leave a signal in an expected cache
set. We now start probing different code locations until we observe
a signal that indicates a successful detection of a Spectre gadget.
Note that the only vulnerability-specific aspects here are the
registers that point to the overwritten memory and the size of the
buffer overflow, but BlindSide is agnostic to both: as long as it
sees activity in the target cache set, it knows that it has found an
appropriate gadget. For this reason, our current gadget probing
implementation focuses on gadgets for which the correct behavior