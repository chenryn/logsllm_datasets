Xi ∈ {0, 1}:
1 − δ
2 ≤ Pr[Xi = 0|X1 = x1, X2 = x2,··· , Xi−1 = xi−1] ≤ 1 + δ
2 , where xi ∈ {0, 1}.
Note that this class of sources is similar to the class of Independent-Bit Sources, as for all
sources Xi, the bias is also bounded between δ and (1 − δ), however, in this class of sources,
the independence between the sources is not required. Lemma 1 shows that the deterministic
extraction of more than a single bit is impossible for this class of sources.
Extract−1(0)
S
Extract−1(1)
Extract
{0, 1}
Figure 2.2 – Impossibility of Deterministic Extraction for δ-Unpredictable-bit sources
Lemma 1. For every p ∈ N, δ > 0 and every map Extract : {0, 1}p → {0, 1}, there exists a δ-
Unpredictable-bit source X such that Pr[Extract(X) = b] ≥ 1
2(1 + δ), for at least one b ∈ {0, 1}.
Proof. Partition the set {0, 1}p between Extract−1(0) and Extract−1(1). Then at least for one
b ∈ {0, 1} we have that |Extract−1(b)| ≥ 2p−1. As illustrated in Figure 2.2, consider a subset
S ⊆ Extract−1(b), of size 2p−1 and the source X such that ∀x ∈ {0, 1}p, Pr[X = x] = 1+δ
if
2p
if x /∈ S. Then X is a δ−Unpredictable-bit Source and we have
x ∈ S and Pr[X = x] = 1−δ
2p
that:
Pr[Extract(X) = b] ≥ Pr[X ∈ S] = 1
2(1 + δ).
As a consequence of the previous examples, one objective of research on deterministic extractors
is to identify the richest classes of randomness sources for which deterministic extraction is
possible, and construct explicit extractors for those sources.
In this thesis, we do not rely on the potential results from this line of research, as we want
to build schemes that do not depend on the structure of the randomness source. As described
before, the notion of k-source comes naturally as it is the most general way to formalize that a
source contains k bits of randomness. Therefore, we will assume in the following that all sources
of randomness are k-sources.
Unfortunately, Lemma 2 below shows that the deterministic extraction of even a single bit is
impossible for this class of sources and motivates the use of a more elaborate notion of extractor
that uses a second source of randomness called seed.
Lemma 2. For every map Extract : {0, 1}p → {0, 1}, there exists a (p − 1)-source X such that
Extract(X) is constant.
— 14 —
2.6. Randomness Extractors
Extract−1(0)
Extract−1(1)
Extract
{0, 1}
Figure 2.3 – Impossibility of Deterministic Extraction for k-sources
Proof. Partition the set {0, 1}p between Extract−1(0) and Extract−1(1), as illustrated in Fig-
ure 2.3. Then at least for one b ∈ {0, 1} we have that |Extract−1(b)| ≥ 2p−1. Deﬁne the
source X as the uniform distribution on Extract−1(b), where |Extract−1(b)| ≥ 2p−1. Then X is
a (p − 1)-source and Extract(X) = b is constant.
Consider now that the function Extract is chosen randomly from the set of all functions from
{0, 1}p to {0, 1} and suppose that one wants to exhibit a similar source than the one from the
previous Lemma. Recall that the set of all functions from {0, 1}p to {0, 1} is of size 22p, therefore
we can consider that a random choice for the function Extract is done in the set {Extracti}i=1···22p.
Suppose that one deﬁnes again the source X as the uniform distribution on Extract−1
i (b), where
|Extract−1
i (b)| ≥ 2p−1, for a randomly chosen i ∈ {1··· 22p}, then as before, X is a (p−1)-source.
However, for j 6= i, Extractj(X) is balanced with high probability, as illustrated in Figure 2.4.
Therefore one cannot construct a (p − 1)-source as in Lemma 2. The formal statement is given
in the proof of Theorem 3 below based on the probabilistic method.
X
Source X deﬁnition
Extract−1
1 (0)
X
Extract−1
1 (1)
Extract1
{0, 1}
...
...
Extract−1
i (0)
Extract−1
22p(0)
...
X
Extract−1
i (1)
Extracti
{0, 1}
...
Extract22p
{0, 1}
X
Extract−1
22p(1)
Figure 2.4 – Randomly Chosen Function Extract
— 15 —
Chapter 2. Preliminaries
This illustrates that the impossibility result of Lemma 2 can be overcome with the probabilistic
method: if we allow to choose the extraction function at random, then, with a high probability,
it will become possible to extract the randomness from each k-source. To choose the extractor
at random, we will assume that it belongs to a family of functions (which can be the family of all
functions from {0, 1}p to {0, 1}m) and we uniformly select a random element from this family.
The selection process implies choosing a random parameter called seed ∈ {0, 1}s and setting the
extraction function as Extractseed = Extract(., seed).
This discussion leads to the notion of seeded extractor, as in Deﬁnition 4.
Deﬁnition 4 (Seeded Extractors). A function Extract : {0, 1}p × {0, 1}s → {0, 1}m is a (k, ε)-
seeded extractor if for all k-sources X, the distributions Extract(X, seed) and Um are ε-close,
where seed $← {0, 1}s is chosen independently of X.
Hence the diﬀerence between deterministic and seeded extractors relies on the use of the sup-
plementary random parameter seed $← {0, 1}s. Moreover, the above deﬁnition means that the
extraction works for all k-sources. In addition, we can now prove that (k, ε)-extractors exist,
with Theorem 3 below. The proof of Theorem 3 uses the Chernoﬀ bound:
Proposition 1 (Chernoﬀ Bound [Sho06]). Let Z1, Z2,··· , Zn be independent random variables
such that 0 ≤ Zi ≤ 1,∀i. Let Z =P
E[Zi]. Then for all ε > 0,
i Zi and µ = E[Z] =P
Pr[|Z − µ| ≥ εµ] ≤ 2 exp(− ε2
i
3 µ).
Theorem 3. For every p ∈ N, k ∈ [0,··· , p], there exists a (k, ε)-extractor Extract : {0, 1}p ×
{0, 1}s → {0, 1}m, with m = k + log(p − k) and s = log(p − k) + 2 log(1/ε) + O(1).
Proof. The proof uses the probabilistic method. We give the proof for ﬂat k-sources (that is, with
uniform distribution over a subset of {0, 1}p of size 2k), the proof extends to general k-sources
(see [Vad12]). Consider (a) a randomly chosen function Extract : {0, 1}p × {0, 1}s → {0, 1}m (b)
a ﬂat k-source X and (c) T a subset of {0, 1}m.
Then as X is a ﬂat k-source, the random variable (X, seed) is a ﬂat (k + s)-source.
Consider the (indicator) random variables Zx,y = 1Extract(x,y)∈T and the random variable:
X
X
Z =
Zx,y =
(x,y)∈supp(X,seed)
(x,y)∈supp(X,seed)
1Extract(x,y)∈T
Then as Extract is chosen randomly and seed is sampled independently of X, the random variables
Zx,y are independent and E(Zx,y) = |T|
2m and as (X, seed) is uniform on its support, Pr[X =
x, seed = s] = 1
2m . We can apply Proposition 1
to the random variables Zx,y:
2k+s in the support only and therefore E(Z) = 2k+s|T|
Pr(|Z − 2k+s|T|
2m | ≥ ε · 2k+s|T|
2m ) ≤ 2 exp(− ε2
3
2k+s|T|
2m ),
which implies, with ε = ε0 2m
|T|:
Pr(| Z
Then as Pr[Um ∈ T] = |T|
2k+s − |T|
2m | ≥ ε0) ≤ 2 exp(− ε02
2m , the last inequality shows that:
3
2k+s2m
|T|
).
Pr(| Pr[Extract(X, seed) ∈ T] − Pr[Um ∈ T]| ≥ ε0) ≤ 2 exp(− ε02
3
2k+s2m
|T|
),
— 16 —
Then as 2m
|T| ≥ 1, we have that:
2.6. Randomness Extractors
Pr(| Pr[Extract(X, seed) ∈ T] − Pr[Um ∈ T]| ≥ ε0) ≤ 2 exp(− ε022k+s
3
).
There are 22m possible sets T ∈ {0, 1}m and1 (cid:0)2p
(cid:1) ≤ (cid:16) 2pe
(cid:17)2k ﬂat k-sources in {0, 1}p. By the
2k
2k
union bound over all possible sets and all possible ﬂat k-sources, the probability that Extract is
a (k, ε)-extractor for all ﬂat k-sources satisﬁes:
2 exp(− ε022k
3 ),
| Pr[Extract(X, seed) ∈ T] − Pr[Um ∈ T]| ≤ ε0) ≤ 22m(cid:18)2pe
(cid:17)2k 2 exp(− ε022k+s
2k
(cid:19)2k
Pr( max
T⊆{0,1}m
Then 22m(cid:16) 2pe
3
3
2k
ε0 ) + log(12) + 1.
) < 1 as soon as 2m + 1 + 2k(p − k + log(e)) < ε022k+s
ε0 ) − log(12) − 1 and (b) s = log(p − k) + 2 log( 1
, which is
satisﬁed if (a) 6 · (2m + 1) < ε022k+s and (b) if 6 · 2k(p − k + log(e)) < ε022k+s, that are satisﬁed
if (a) m = k + s − 2 log( 1
Doing this, we can consider that the extraction is deﬁned over the product set {0, 1}p × {0, 1}s,
where {0, 1}p will be the set from which randomness will be extracted and {0, 1}s will be the
set from which the parameter seed will be chosen. Hence the new objective is to analyze the
statistical distance of the distribution Extract(X, seed) and the uniform distribution, where X is
a k-source (H∞(X) ≥ k) and seed $← {0, 1}s.
The use of a second random parameter is not suﬃcient to guarantee that the extraction is
possible for any source.
It is indeed straightforward to see that there is a new impossibility
result (Lemma 3 below) when the source of parameter seed and the randomness source are not
independent. The proof of Lemma 3 is the same as the proof of Lemma 2.
Lemma 3. For every map Extract : {0, 1}p × {0, 1}s → {0, 1}m and every seed ∈ {0, 1}s, there
exists a (p − 1)-source X (depending on seed) such that Extract(X, seed) is constant.
Lemma 3 shows that we face two issues: (a) the generation of the uniformly random parameter
seed and (b) the potential correlation between seed and the source from which we will try to
extract randomness. Hence in an adversarial viewpoint, we need to consider situations where
the seed or the environment may be controlled by an adversary, and situations where a potential
correlation between the randomness source and seed may be exploited to mount an attack against
the scheme. This may occur for example in a hardware device, that extracts from physical sources
of randomness of a computer (e.g. timing of various events). These sources may be modiﬁed
by the device and hence this behavior implies correlations between seed and the randomness
sources. Therefore, we need to add optional requirements, either on the independence between
the source and seed, or on the capabilities of the adversary.
Suppose now that the independence between the source and seed cannot be ensured and we
want to model situations where we need to perform randomness extraction. As noted before,
to overcome the impossibility result, we mainly have two options: (a) restrict the randomness
source to a given family of k-sources (which is a similar strategy as for deterministic extractors)
or (b) restrict the adversary A.
We ﬁrst propose to limit the extraction to a ﬁnite family of k-source for which we are sure that
extraction is possible. This leads to the notion resilient extractor, as in Deﬁnition 5.
1For n, m ∈ N, such that 2 ≤ m ≤ n,(cid:0) n
(cid:1) ≤(cid:0) ne
m
(cid:1)m
m
— 17 —
Chapter 2. Preliminaries
Deﬁnition 5 (Resilient Extractor). A function Extract : {0, 1}p×{0, 1}s → {0, 1}m is a (k, ε, δ)-
resilient extractor if for all ﬁnite families of k-sources F, with probability at least (1 − δ) over
the choice of seed $← {0, 1}s, the distributions (seed, Extract(X, seed)) and (seed,Um) are ε-close,
for all X ∈ F.
Note that to simplify the number of parameters, one can set ε = δ in the above deﬁnition, in
this case, we refer to (k, ε)-resilient extractors.
Resilient extractors stand for (a) bounded family of randomness source and (b) correlated seed
and source. Deﬁnition 5 can be expressed in terms of hash functions: Let H = {h : {0, 1}p →
{0, 1}m} be a family of hash functions. Then H is a (k, ε)-resilient extractor if for any random
variable I over {0, 1}p with H∞(I) ≥ k, the distributions h(I) and Um are ε-close with probability
(1− δ) over the choice of h, where Um is uniformly random over {0, 1}m. An important result is
the Leftover Hash Lemma, presented in Section 2.7, that constructively leads resilient extractors
from pairwise independent families of hash functions.
This notion of extractor is used in the model of Barak, Shaltiel and Tromer [BST03], described
in Section 3.5 and in the model of Barak and Halevi [BH05], described in Section 3.6. In these
models, a ﬁnite family of k-sources is ﬁrst chosen, then the random parameter seed is chosen
and ﬁnally a source is adversarially chosen (and therefore without independence with seed).
Suppose now that we do not want to limit the extraction to a ﬁnite family of sources. Deﬁnition 6,
which generalizes Deﬁnition 5, describes the objectives for a randomness extractor.
Deﬁnition 6 (Seed Dependent Extractor). A function Extract : {0, 1}p ×{0, 1}s → {0, 1}m is a
seed-dependent (k, ε)-extractor if for all probabilistic adversaries A who take as input a random
seed seed $← {0, 1}s and output X ← A(seed) of entropy H∞(X|seed) ≥ k, the distributions
(seed, Extract(X, seed)) and (seed,Um) are ε-close.
One way to restrict adversary A is to force its running time to be less than the running time of
the extractor Extract. This idea was formalized by Trevisan and Vadhan in [TV00]. In this work,
they show how seed-dependent randomness extraction is possible from a samplable distribution,
provided that the complexity of the extractor is larger than the complexity of the adversary A
that generates the source X. In particular, they show that if the adversary’s running time is
larger than the extractor’s one by a factor of t, it can ﬁx roughly log(t) bits of the output. Note
that this result motivates the introduction of randomness condensers, as described in [DRV12].
In this work, we do not consider randomness condensers but focus on randomness extractors, as
we will want that the output of the extraction phase is ε-close to uniform, to apply a standard
pseudo-random number generator G after extraction. Hence to consider adversarial situations
where seed and the source may be correlated, without restriction on the randomness source, it