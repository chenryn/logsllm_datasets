the entire ensemble of features as a whole. As a result, we argue
that even if attackers are aware of our tool’s presence, it will not be
trivial to evade detection by selectively patching individual features.
Model Generalizability
Utilizing network-level features increases the robustness of our
classifier against many of the modifications attackers can make
to thwart fingerprinting attempts. However, we seek to create a
classifier that is not only effective in detecting the three identified
toolkits in their current form, but is also generalizable to updates
to the existing toolkits as well as toolkits created in the future.
We test the effect of MITM phishing toolkit updates on model
performance by downloading all releases of the three MITM phish-
ing toolkits, dating up to two years old, and collecting data on each
using the same methodology described in Section 3.4. We then
train our classifier on the oldest release available of each toolkit
along with known non-MITM phishing toolkit data, and test on the
remaining releases. In total, we collected 13 MITM phishing toolkit
versions with Evilginx, Muraena, and Modlishka having four, seven,
and two versions respectively. The results of this experiment are
shown in Table 2B. We find that, generally, the network-level fea-
tures of each toolkit remain constant through incremental updates.
The only exception to this is Muraena, which included support for
HTTP requests in the most recent release (version 0.3) with prior
releases only answering HTTPS requests. This discrepancy in be-
havior leads to the observed dropoff in performance. However, this
experiment represents a worst-case-scenario for defenders where
the classifier is not updated to match changes in the MITM phishing
toolkit space for multiple years.
To measure our classifier’s performance when encountering a
previously unknown MITM phishing toolkit, we iteratively remove
each toolkit’s data from our training set, leaving only the two re-
maining toolkits and known non-MITM phishing toolkit data. We
then train with this new dataset, and test with the toolkit whose data
we left out. This excluded data effectively acts as a new toolkit, pre-
viously unknown to the classifier. The results of this experiment are
shown in Table 2C. We find that the accuracy of our classifier drops
by less than 2% when testing on data from a completely unknown
MITM phishing toolkit. As network architecture is constant across
all MITM phishing toolkits, our classifier maintains consistently
high performance regardless of the introduction of unfamiliar data.
3.6 PHOCA: MITM Phishing Toolkit Detection
Utilizing the previously described machine learning classifier, we
develop a tool to automatically collect data on, and classify MITM
phishing toolkits on the web. We call this tool PHOCA, after the
Latin word for “seal.” Seals are aquatic mammals known to hunt
hidden prey using vibrations generated by their breathing. Similarly
to this hunting technique, PHOCA can detect previously-hidden
MITM phishing toolkits using features inherent to their nature, as
opposed to visual-cues.
When provided either a URL or domain-name, PHOCA probes
the desired web server to collect the previously mentioned network-
level features. PHOCA then uses our trained classifier to determine
if the web server is a MITM phishing toolkit. Using this tool, new
training data can be easily generated for any future MITM phish-
ing toolkit iteration. Additionally, PHOCA can be integrated into
existing anti-phishing workflows to fingerprint active threats.
4 DISCOVERING
MITM PHISHING SITES IN THE WILD
Using PHOCA, we conduct a large-scale search for MITM phishing
toolkits in the wild. We seek to determine the online presence of
these tools, and uncover patterns in their usage. This allows us to
expose the source of phishing campaigns leveraging these tools, as
well as targeted users and trademarks.
We start by designing and implementing a URL crawling infras-
tructure that visits thousands of potential phishing web pages each
day, recording information about them, and classifying them as a
MITM phishing toolkit or not.
Session 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea41Figure 5: Architecture of framework used to collect network data on real world MITM phishing websites.
4.1 Phishing Website Crawling Infrastructure
We design a URL crawling infrastructure that visits phishing web-
sites as they are created. Our crawlers collect information about
each website and a label using PHOCA.
URL Collection
To obtain a comprehensive view into the MITM phishing ecosys-
tem, we crawl URLs from popular open-source phishing databases
(Phishtank [19] and OpenPhish [18]), as well as Certificate Trans-
parency logs [4]. We utilize the Facebook Certificate Transparency
Phishing API [9] to receive alerts for certificate registrations of
impersonating domain names. Additionally, we supplement this
source with our own Certificate Transparency log parser which uses
regular expressions to search for combosquatting domains [40]. In
total, we search for impersonating domains of 22 trademarks using
Certificate Transparency (full list of trademarks can be found in Ta-
ble ?? in the Appendix). We note that both Facebook’s and our own
Certificate Transparency log parsers do not classify MITM phish-
ing websites, but rather search for domain names that appear to be
impersonating known trademarks. We use all URLs and domains
provided from each source as input to our crawling infrastructure
to find MITM phishing websites deployed in the wild.
It is important to note that our reliance on Certificate Trans-
parency and phishing lists excludes, by design, any test deploy-
ments of the evaluated MITM phishing toolkits by security analysts
and researchers. Namely, we argue that setting up a subdomain
or purchasing a domain name that matches the target site and de-
ploying a phishing toolkit there, crosses the line between benign
and malicious. Had we used Internet-wide scanning tools (such as
ZMAP [35]) to identify MITM phishing toolkits, we would not be
able to reliably differentiate between test deployments and deploy-
ments by attackers.
We also note that our use of Certificate Transparency logs limits
us to only domain names rather than full URLs, which are typi-
cally available on phishing blocklists. However, since PHOCA uses
network-level features to discover MITM phishing toolkits, we do
not require access to phishing content. This is a strength of our de-
tection technique, as we are intuitively fingerprinting the phishing
web server rather than the phishing content, as is the case with
traditional phishing detection.
Crawling Infrastructure
Figure 5 presents a high-level view of our URL crawling infras-
tructure. (1) Our queue-based system takes as input URLs from a
number of sources, including phishing blocklists and impersonat-
ing domains found on the Certificate Transparency logs, and (2)
dispatches one of our crawlers to collect data on the corresponding
website in real time. Each crawler consists of two modules: a head-
less Selenium [21] browser, and a PHOCA worker. For each website
encountered, we record the following information: i) HTML and
screenshot of landing page, ii) TLS certificate offered to our browser,
iii) original and redirected (if applicable) domain IP address, and
iv) original and redirected (if applicable) classification.
(3) This data is forwarded to the analysis module which clusters
web pages based on their content, assisting in the manual verifica-
tion of the classifications made by our model. Furthermore, using
information such as TLS certificates, web server IP addresses, and
domain names allows us to uncover connections between seemingly
independent phishing websites and cluster individual phishing sites
into phishing campaigns.
(4) Our system also utilizes time-based re-queuing to record data
on websites previously crawled in order to map the life cycle of
MITM phishing websites over time. We make use of this when
crawling domains from the Certificate Transparency logs. Since
these domains are captured as soon as their certificates are cre-
ated, there is a high probability that there will be no web server
responding to requests at that moment. Thus, we re-crawl all such
domains periodically following their initial recording. Moreover,
we re-crawl all URLs classified as one of the phishing tools in order
to measure how long these websites remain active after creation.
4.2 Experimental Evaluation and Results
MITM Phishing Toolkit Presence
We deployed our phishing website crawling infrastructure for 365
days from March 25, 2020 to March 25, 2021. This period was broken
up into two phases. The first phase was an exploratory one which
included URLs from both Certificate Transparency as well as the
phishing URL databases OpenPhish and PhishTank. We used this
phase to determine the most effective sources to capture MITM
phishing websites.
During this first phase, we captured 17 MITM phishing websites
from the URLs reported by OpenPhish and PhishTank, compared
to the 189 captured from the domains reported by Facebook’s Cer-
tificate Transparency API. We find that the highly targeted nature
of attacks conducted using MITM phishing toolkits makes it diffi-
cult for user-curated blocklists to effectively report these websites
in a timely manner. Furthermore, the cloaking abilities of MITM
Session 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea42Table 3: MITM phishing websites discovered per autonomous system
Autonomous System
Amazon.com, Inc.
DigitalOcean, LLC
Microsoft Corporation
Google LLC
Versatel Deutschland GmbH
Choopa, LLC
OVH SAS
Linode, LLC
HKT Limited
Other
IPs Domains
136
162
160
386
165
62
61
37
1
15
50
14
13
38
40
9
1
8
150
354
Through close inspection of all false positives in our dataset, we
find 5,298 belong to domain parking services, 5,158 of which belong
to the domain parking service sedo.com. By analyzing the network
timings and TLS fingerprints of sedo.com web pages, we infer that
this service utilizes a reverse proxy infrastructure with similar net-
work timing properties to MITM phishing toolkits. In practice, a
web page classification system such as ours would benefit greatly
from a pre-filtering step to remove common sources of misclassifica-
tion. The addition of such a step that can filter websites that resolve
to an IP address in the autonomous system of a domain parking
service would leave only 563 false positives during our entire data
collection period. This would result in an adjusted false positive rate
of 0.067% or two false positives each day. This is in line with the re-
sults of our classifier in a laboratory setting (described in Section 3).
The remaining false positives consist of sites that we could not
verify as being malicious based on our verification methodology.
These consist of 230 empty or error web pages and 333 seemingly
benign web pages that were included based on the similarity of their
domain to a popular trademark that we followed. We theorize that
these websites use a network architecture similar to that of MITM
phishing toolkits with reverse proxy or caching servers. We note
that these sites do not redirect visitors (e.g. for cloaking purposes),
which could act as a second-level check to prevent false positives.
In total, we discovered 1,220 verified websites operated by MITM
phishing toolkits over our entire data collection period, shown in
Figure 6. We observe an upward trend in the number of MITM phish-
ing toolkits discovered each month of our data collection period.
This implies an increase in adoption of these toolkits by attackers—
a trend we anticipate to continue into the future. We note a drop
in the number of MITM phishing websites discovered in December
2020. We discovered that during this month, we received signifi-
cantly fewer phishing URLs from our Certificate Transparency log
API sources. However, we observe that the ratio of true positives to
all phishing URLs in this month is consistent with all other months
in this upward trend.
MITM Phishing Website Locations
We use the collected IP addresses to map each MITM phishing
website we encountered, both in terms of its geographical loca-
tion as well as the autonomous system in which the server hosting
the toolkit belongs. This information allows us to identify hosting
patterns as well as potential victims.
Figure 7 shows the geographic distribution of IP addresses as-
sociated with MITM phishing websites discovered by our crawling
Figure 6: Number of MITM phishing websites identified each month
of our data collection period.
Figure 7: Geographic locations of MITM phishing websites. Larger
circles indicate more IP addresses in a given area
phishing toolkits make it such that only victims possessing the to-
kenized URL will see the malicious content, while all other visitors
are redirected to a benign website. This further complicates the task
of identifying and blocklisting these websites as existing crawlers
will never observe the malicious content.
Preemptively scanning potential phishing websites from sources
such as Certificate Transparency is clearly the most effective way to
detect attacks from these toolkits before damage is done. Thus, after
our exploratory phase, we remove Phishtank and OpenPhish from
our URL sources, opting to focus our infrastructure’s resources on
an additional Certificate Transparency source (to supplement Face-
book’s Certificate Transparency feed, as mentioned in Section 4.1).
During this second phase, PHOCA labeled 6,875 sites as operated
by MITM phishing toolkits, 849 from Facebook’s Certificate Trans-
parency API and 6,026 from our own Certificate Transparency Log
parser. For brevity, we will refer to these two sources as Certificate
Transparency for the remainder of this paper.
Upon completion of the second phase, we manually inspected
the data collected on each website labeled as a MITM phishing
toolkit to remove false positives. We did this by analyzing the
screenshot, HTML, and classification data of each positively labeled
phishing website and confirming that the content targets a popular
trademark, and the network-level data matches the profile of a
MITM phishing toolkit. In total, we identified 5,861 false positives
from a total of 7,081 positive classifications, and promptly removed
them from our dataset before conducting any further data analysis.
Throughout our recording period, we classified 841,711 web pages,
meaning PHOCA had a 0.6% false positive rate during our data
collection period—approximately sixteen per day, on average.
3-20204-20205-20206-20207-20208-20209-202010-202011-202012-20201-20212-20213-2021Month020406080100120MITM Phishing WebsitesSession 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea43(a)
(b)
(c)
Figure 8: (a) Days between MITM phishing domain registration and detection by our system (b) Hours before MITM phishing websites captured
from Certificate Transparency logs go online (b) Days MITM phishing sites remain active
infrastructure. We find that while MITM phishing toolkits are in use
around the world, most instances are located in North America and
Europe. Further, these locations correspond to areas with large con-
centrations of hosting providers. We confirm this in Table 3 which
shows the top autonomous systems in which MITM phishing web-
sites were found, composed mostly of popular hosting providers.
The ability for attackers to quickly launch and remove cloud
servers on hosting providers makes them a popular location for
MITM phishing websites. In addition, since these toolkits attempt to
impersonate real websites, being located on popular web hosting in-
frastructure could thwart security scanners searching for websites
hosted in low-quality autonomous systems.
MITM Phishing Website Life Cycle