of API functions from API documentation and specify the effects
using Horn clauses [8, 45]. The reason for this is that most API
functions are given properly-chosen function names to convey their
semantics, such as getSystemService(...), setRingerMode(...), and
generateAudioSessionId(). To generate the Horn clauses, we first
parse the API documentation to identify classes that contain such
functions. We then parse the function names and declarations to
extract the semantics. For example, the API documentation shows
that getSystemService(...) is a function of the Context class. This
means that to call the function, a Context object must exist. The
:ContextS0getSystemService("audio")S1mode=10setRingerMode(0)S2 mode=0broadcast ringer_silentsetRingerMode(2):AudioManagersetRingerMode(0)setRingerMode(2)Legend:           points to an initial state, :A denotes an object of class A.         S3 mode=2broadcast ringer_normal203StateDroid
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Figure 4: Three Attack State Machines for detecting different blocking call attacks.
These can be translated into the following API call sequences:
x=context.getSystemService(“AUDIO_SERVICE”);
x.setRingerMode(2); (broadcast ringer_normal)
x=context.getSystemService(“AUDIO_SERVICE”);
x.setRingerMode(0); (broadcast ringer_silent)
x=context.getSystemService(“AUDIO_SERVICE”);
x.setRingerMode(0); x.setRingerMode(2);
x.setRingerMode(0); (broadcast ringer_silent)
5.4 Constructing Object State Machines
The OSMs are constructed by processing the proofs of the API call
sequences. The algorithm is simple and straightforward. First, it
pushes “broadcast(action-name)” and “_call(...)” onto a stack whe-
never they are encountered. Second, it pops and processes each
element of the stack as follows. If the element is “_call(...)” such
as “_call(y=getSystemService(“AUDIO_SERVICE”), x, S0)”, then the
algorithm generates a state transition from state S0 to S1, labe-
led as “y=getSystemService(“AUDIO_SERVICE”)”. If S0 or S1 with
matching object state does not exist, then it creates the state and
labels it accordingly as follows. The state of the object is determi-
ned by looking up the Horn clause that formalizes the effect of
the API function. For example, in state S0, the state of the Context
object is “[ ]”, which means nothing needs to be specified. Horn
clause C1 formalizes the getSystemService(...) function, and the
postcondition asserts that the state of the AudioManager object is
“[mode=10].” These generate a state S0, a state S1 with object state
“[mode=10]”, and a transition from S0 to S1 labeled by the function
call (see Figure 3). If the element is “broadcast(action-name),” then
add “broadcast action-name” to the last destination state. Such a
state is an action detection state. Finally, enclose states that be-
long to an object class in a rectangle and label the rectangle with
“:Object Class Name.” Following the above algorithm, we are able to
automatically generate OSMs like the example shown in Figure 3.
6 ATTACK DETECTOR
StateDroid models each category of attack using an attack state
machine (ASM). Figure 4 shows three attack state machines for
detecting the blocking call attack in three different situations. Each
state of an ASM represents the status of an attack and a transition
represents a detected action. Each ASM begins with an initial state
(pointed to by an small arrow with a dot tail), and ends with an
attack state (indicated by a grey circle). It makes a transition to
a new state if an action is received from the action detector, and
the ASM is in a state expecting the action. An attack is detected
if one of the ASMs enters into an attack state. To construct the
ASMs, we use Horn clauses to specify the effects of actions as well
as the hostile intents of attacks. Theorem proving is performed
to generate the action sequences, each of which begins with an
initial state of an attack and enters into an attack state. The action
sequences are then used to generate the attack state machines.
6.1 Action-Effect & Attack Formalization
Action-Effect Formalization: The effects of actions are specified
by Horn clauses, which are derived from the Horn clauses that
formalize the effects of API calls described in Section 5. For example,
Horn clauses C2 and C3 below detect the ringer_silent action.
C2: -AudioManager(x, [mode=y], u) | (-$NE(y,0)) |
AudioManager(x, [mode=0], _call(setRingerMode(0), x, u)).
C3: -AudioManager(x, [mode=0], u) | broadcast(ringer_silent, u).
These clauses imply that whenever the ringer_silent action is
broadcast, the AudioManager has mode=0, and this can happen if
the conditions stated in C2 are fulfilled. These lead to the following
Horn clauses that formalize the effects of the ringer_silent action.
-AudioManager(x, 2, z, u) | (-$LE(z, 2)) | AudioManager(x, 0, $SUM(z,1),
_received(ringer_silent,u)).
AudioManager(x,2,z,u) means x is an AudioManager object with
ringer mode = 2, in state u, the variable z is introduced to prevent the
theorem prover to enter into an infinite loop of setting the ringer to
silent and normal modes repeatedly. $LE(z,2) and $SUM(z,1) mean
z ≤ 2 and z + 1, respectively. They are built-in functions of the
theorem prover.
Attack Formalization: We use Horn clauses to formally specify
the effect of an attack in terms of an initial state and an attack state.
For example, the blocking call attack terminates a call. It involves
two objects: a Telephony object and an AudioManager object, and
these two objects must exist in the “Ringer Normal” initial state.
The blocking call attack is detected whenever the status of the Te-
lephony object is “call ended ....” We wish to prove that such attacks
can be detected. The Horn clauses to formalize the three blocking
call attacks in Figure 4 are as follows:
-Telephony(x, “call ended ringer mode=2”, u) | ResDenied(x, “brutal”,
u).
(brutal)RingerNormal(a) Deny system resource:a brutal attackCall Blockedblock_callRingerSilentringer_silentringer_normalRingerNormalCall Blockedringer_silentRingerSilentblock_callringer_normal(w/ringer silent)RingerNormalCall Blockedringer_silentRingerSilentblock_callringer_normalRingerNormal(stealthy)(b) Deny system resource:with ringer silent(c) Deny system resource:a stealthy attackringer_normal204ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Mohsin Junaid, Jiang Ming, and David Kung
-ResDenied(x, “brutal”, u) | $ans(Attack(“Call blocked brutal”, u)).
-Telephony(x, “call ended ringer mode=0”, u) | ResDenied(x, “w/ringer
silent”, u).
-ResDenied(x, “w/ringer silent”, u) | $ans(Attack(“Deny syst res w/rin-
ger silent”, u)).
-Telephony(v, “call ended ringer mode=0”, u) | ResDenied(v, “stealth”,
_receive(ringer_normal, u)).
-ResDenied(x, “stealth”, u) | $ans(Attack(“Call blocked stealth”, u)).
6.2 Frame Axioms
Before we adopt a theorem prover to produce proofs, we need to
generate the so-called frame axioms [35]. Such axioms state that
anything that is not changed by an action remains true in the
resulting new state. For the attacks shown in Figure 4, we need
frame axioms because the status of the Telephony object needs to
be reasserted in the new state resulting from the ringer_silent or
ringer_normal state. The following two Horn clauses serve this
purpose. Without these two clauses, the theorem prover can only
prove the brutal blocking call attack (Figure 4(a)) but not the other
two attacks (Figure 4(b) and (c)).
C14: -Telephony(x, y, u) | -AudioManager(v, 2, z, u) | (-$LE(z,2)) |
Telephony(x, y, _received(ringer_silent,u)).
C15: -Telephony(x, y, u) | -AudioManager(v, 0, z, u) | (-$LE(z,2)) |
Telephony(x, y, _received(ringer_normal,u)).
In our approach, frame axioms are generated by a Java program.
For each action, the program generates a frame axiom for each
predicate that is not changed by the action.
Generating Action Sequences and Attack State Machines: Si-
milar to generating API call sequences, we use Prover9/Mace4 [36]
to generate action sequences from the Horn clauses. Like the gene-
ration of OSMs, the Horn-clause proofs are processed by a parser to
automatically generate the ASMs like three cases shown in Figure 4.
7 EVALUATION
We perform our experiments to address the following research
questions: RQ1: How accurately can Action Detector detect attack
actions? RQ2: Can Attack Detector effectively identify multi-action
sequence based stealthy attacks? RQ3: How well StateDroid per-
forms in comparison with existing tools? RQ4: What is the over-
head of StateDroid? To answer above questions, we collect apps
from multiple sources.
Ground-truth Apps: This set comprises 28 Android apps, and
their complete behaviors are known to us in advance. These ground-
truth apps are used to evaluate the effectiveness of StateDroid.
16 of them are hand-crafted apps that implement action based
attacks, such as blocking or answering phone calls and sending auto
reply to incoming SMS messages. Sherlock vs Moriarty dataset [39],
containing 12 apps, is designed to help researchers in developing
and validating their malicious-behavior detection methods. We add
all these 12 malicious apps into our ground-truth dataset.
Malicious Apps: This dataset contains 1, 369 malware samples in
total. Most of the samples, 1, 260 apps of 55 families, are obtained
from the very popular Genome Malware dataset [61]. Another 15
apps, representing 6 families, are downloaded from an online mal-
ware database called Contagio Malware Dump [1]. We collect the
remaining 94 apps (grouped as 7 families) from VirusTotal malware
database [2]. They represent an emerging threat: mobile ransom-
ware [5, 46]. It is very interesting to evaluate StateDroid’s efficacy
to this growing threat, such as whether ransomware samples also
reveal stealthy behaviors before they pop up ransom notes.
Benign Apps: The benign apps contain applications downloaded
from Google Play store. The app set consists of top free 1505 apps
from all 32 categories (∼50 apps/category) on the Play store. Google
performs vetting on uploaded Play store apps using Google Bouncer
[31] before making them available on market. However, it has been
reported that malicious apps can still find their way into the Google
Play store [40]. Our goal is to find out whether Google Play apps
reveal unexpected stealthy behaviors.
7.1 RQ1: Accuracy of Action Detector
Evaluation on Ground-truth Apps: StateDroid first runs analy-
sis on the 16 hand-crafted apps, for which the API Call Detector
generates 23 API call events. We confirm that Action Detector
successfully detects all actions in these 16 hand-crafted apps.
Evaluation on Malware Apps: We first present analysis results
for 1275 samples from Genome and Contagio datasets. For these
malware apps, StateDroid detects 604 actions representing 22 action
categories. Top five actions which constitute 62% (373) of the de-
tected actions are information leakage (161), sending SMS messages
(81), aborting SMS or call notifications (56), deleting data from SMS
and call content providers (43), and making phone calls (32).
We perform manual verification on the 604 detected actions and
find out none of the detected actions is false positive. The reason
is Action Detector does not report an action as detected unless it
detects an action-specific APIs, relevant objects with specific states,
or specific parameter values of API calls. However, StateDroid may
miss some actions when analyzing highly obfuscated malware such
as packed samples. Code obfuscation is a common barrier to static
analysis of malware apps [23, 42, 56]. Currently, StateDroid is resi-
lient to trivial obfuscation techniques such as code reordering, junk
code insertion, and reflection with static string values. To dissect
packed Android apps, we can leverage the recent work on adaptive
unpacking of Android apps [58].
Out of the total 61 malware families collected from Genome and
Contagio, StateDroid finds various malicious actions in 49 families.
Figure 5 shows the detected actions for top 25 malware families
based on the number of unique detected actions. An action for a
family is reported if any of its samples is found to contain that
action. We find that info_leak is the most common action, and 14
malware families exhibit five or more actions. NickySpy contains
the most 14 actions, followed by BaseBridge and Android.Hehe.
Figure 6 shows 16 detected action categories for all of the 7 ran-
somware families we collect. While many actions in Figure 6 and
Figure 5 are overlapped, Action Detector also detects two unique
actions (lock_device, encrypt_file) in ransomware families. Figure 6
shows that 5 families lock the device using lockNow() API, and
after locking, 3 of them also change the device password using
205StateDroid
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Figure 5: Top 25 malware families out of 55 families in terms of the number of unique detected actions.
abort_notification
check_screenlock
change_volume
delete_database
autoreply_SMS
display_home
hide_dialpad
answer_call
block_call
leak_info
turnOff_vibration
turnOn_vibration
remove_shortcut
ringer_normal
silence_ringer
save_database
turnOn_WiFi
record_video
ringer_silent
turnOn_data
send_SMS
start_call
Actions
Family
Malware
ADRD
Android.Hehe
AnserverBot
BaseBridge
BeanBot
Bgserv
CoinPirate
DroidDream
DroidDreamLight
DroidKungFu1
DroidKungFu2
DroidKungFu3
DroidKungFu4
Endofday
Geinimi
GGTracker
HippoSMS
Moubad
NickyBot
NickySpy
Pjapps
Plankton
socialPath
YZHC
# Families
RemoteControlSmach
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
13
1
2
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
5
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
7
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
5
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
11
(cid:88)
(cid:88)
(cid:88)
(cid:88)
3
1
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)