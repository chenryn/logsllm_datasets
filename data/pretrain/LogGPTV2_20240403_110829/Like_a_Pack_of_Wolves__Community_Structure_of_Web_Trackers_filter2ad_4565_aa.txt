title:Like a Pack of Wolves: Community Structure of Web Trackers
author:Vasiliki Kalavri and
Jeremy Blackburn and
Matteo Varvello and
Konstantina Papagiannaki
Like a Pack of Wolves: Community Structure
of Web Trackers
Vasiliki Kalavri1(B), Jeremy Blackburn2, Matteo Varvello2,
and Konstantina Papagiannaki2
1 KTH Royal Institute of Technology, Stockholm, Sweden
PI:EMAIL
2 Telefonica Research, Barcelona, Spain
Abstract. Web trackers are services that monitor user behavior on the
web. The information they collect is ostensibly used for customization
and targeted advertising. Due to rising privacy concerns, users have
started to install browser plugins that prevent tracking of their web
usage. Such plugins tend to address tracking activity by means of crowd-
sourced ﬁlters. While these tools have been relatively eﬀective in pro-
tecting users from privacy violations, their crowdsourced nature requires
signiﬁcant human eﬀort, and provide no fundamental understanding of
how trackers operate. In this paper, we leverage the insight that funda-
mental requirements for trackers’ success can be used as discriminating
features for tracker detection. We begin by using traces from a mobile
web proxy to model user browsing behavior as a graph. We then per-
form a transformation on the extracted graph that reveals very well-
connected communities of trackers. Next, after discovering that trackers’
position in the transformed graph signiﬁcantly diﬀerentiates them from
“normal” vertices, we design an automated tracker detection mechanism
using two simple algorithms. We ﬁnd that both techniques for automated
tracker detection are quite accurate (over 97 %) and robust (less than
2 % false positives). In conjunction with previous research, our ﬁndings
can be used to build robust, fully automated online privacy preservation
systems.
1 Introduction
The massive growth of
the web has been funded almost entirely via
advertisements shown to users. Web ads have proven superior to traditional
advertisements for several reasons, the most prominent being the ability to show
personally relevant ads. While the content of the web page the ad is being served
on can help provide hints as to relevance, web advertisement agencies also rely
on mechanisms to uniquely identify and track user behavior over time. Known
as trackers, these systems are able to uniquely identify a user via a variety of
methods and over time can build up enough information about a user to serve
extremely targeted ads.
While ad agencies’ use of trackers has enabled services to provide access to
users free of charge, there is also a certain degree of “creepiness” in the way the
c(cid:2) Springer International Publishing Switzerland 2016
T. Karagiannis and X. Dimitropoulos (Eds.): PAM 2016, LNCS 9631, pp. 42–54, 2016.
DOI: 10.1007/978-3-319-30505-9 4
Like a Pack of Wolves: Community Structure of Web Trackers
43
current ecosystem works that has also been highlighted in the US congress [12].
Recent work [5] has even shown that government agencies can easily exploit
trackers to spy on people. Privacy concerns have led to the creation of client
side applications that block trackers and ads. For example, AdBlock [1] blocks
trackers by ﬁltering requests through a set of crowdsourced rules. Unfortunately,
such lists are mostly opaque: there is no straight forward way to understand why
a tracker was added to the list or to get a sense as to how trackers work on an
individual or group basis, and users can be left out in the cold as evidenced by
the recent sale of AdBlock to an undisclosed buyer who immediately enabled
opting in to the “Acceptable Ads” program [14].
In the research community, several strategies for detecting and defending
against trackers have been introduced [7,10,13]. Overall, these works focus on
understanding the methods that trackers use in order to deﬁne techniques for
obfuscating a user’s browsing behavior. However, these previous works are gen-
erally focused on lower level intricacies, e.g., how trackers ﬁngerprint users or
ensure that cookies persist even after users clean them.
In this paper, we take a diﬀerent approach and attempt to characterize
some more fundamental aspects of trackers. Our rationale is that user requests,
e.g., accessing google.com, and requests to trackers, e.g., 3rd party request to
doubleclick.net, can be represented as a bipartite graph from which we can
derive unique tracker properties, allowing for the optimization and automation
of the tracker detection problem.
This work makes several contributions.
1. We model user browsing as a 2-mode graph using 6 months (November 2014–
April 2015) of traﬃc logs from an explicit web proxy. By analyzing this graph,
we discover that trackers are very well connected: 94 % appear in the largest
connected component of the graph.
2. We explore the communities trackers form by inducing a 1-mode projection
of the 2-mode browsing graph. We ﬁnd that trackers form very well-deﬁned
communities that distinguish them from regular URLs.
3. We show that the 1-mode projection graph is a useful tool to automatically
classify trackers with high precision and very low false positive rate. More
importantly, using the projection graph for tracker detection is very robust
to evasion since it captures a fundamental necessity of the tracking ecosystem:
presence of trackers on multiple sites, and presence of multiple trackers on the
same site, which allows publishers to better monetize ad display through real
time bidding. Changing such a behavior would limit the eﬃciency of tracking
as a whole.
2 Background and Dataset
Trackers enable targeted advertising and personalization services by monitoring
user behavior on the web. To understand web tracking, let us consider what
happens in the browser when a user visits a URL. First, the browser issues an
44
V. Kalavri et al.
HTTP request to the site to fetch the contents of the web page. The response con-
tains the page resources, including HTML, and references to embedded objects
like images and scripts. These references might then instruct the browser to
make additional HTTP requests (e.g., for the image itself) until the page is fully
loaded. Embedded objects can be hosted on diﬀerent servers than the page con-
tent itself, in which case they are referred to as third-party objects. A fraction
of these third-party objects open connections to trackers, e.g., the popular Face-
book “like” button, at which point the users’ online whereabouts are logged for
targeting/personalization purposes.
2.1 Dataset
Our dataset is derived from 6 months (November 2014–April 2015) of traﬃc logs
from an explicit web proxy. The proxy is operated by a major telecom located in
a large European country. Our data is delivered to us in the form of augmented
Apache logs. The logs include ﬁelds to identify the user that made the access,
the URL that was requested, headers, performance information like latency and
bytes delivered. We call this dataset the proxy log, and in total it represents 80
million accesses to 2 million individual sites. In the following section, we describe
how we use the proxy log to model web tracking as a graph problem. We label
URLs in our dataset as tracker or other based on ground truth derived from the
EasyPrivacy list for AdBlock [3].
2.2 Web Tracking as a Graph Problem
A 2-mode graph is a graph with two diﬀerent modes (or classes) of vertices,
where edges are only allowed between vertices belonging to diﬀerent modes.
The interactions between explicit user requests and background requests, both
page content and third-party objects like web tracking services, can be naturally
modeled as a 2-mode graph. The ﬁrst mode of vertices in the graph are URLs
that the user intentionally visits, while the second mode are URLs for objects
that are embedded in the visited page.
More precisely, we represent the URLs that a browser accesses as a 2-mode
graph G = (U, V, E), where U are the URLs that the user explicitly visits,
V are the URLs that are embedded within those pages, and E is the set of
edges connecting vertices in U (explicitly visited URLs) to vertices in V (URLs
embedded within visited pages). In this paper, we call vertices in U referers,
vertices in V hosts, and G the referer-hosts graph.
In graph analysis, communities are groups of vertices that are well-connected
internally, and sparsely connected with other groups of vertices. Vertices belong-
ing to the same community are more likely to be similar with respect to con-
nectivity and network position than vertices belonging to diﬀerent communities.
V contains both regular embedded objects and third-party objects potentially
associated with trackers. We expect regular embedded objects to only appear
on the hosting web page, while tracker objects need to appear on as many
web pages as possible to enable successful tracking of users across websites.
Like a Pack of Wolves: Community Structure of Web Trackers
45
Fig. 1. Example of the hosts-projection graph transformation. Vertices preﬁxed with
r are the pages the user explicitly visited while those preﬁxed with h were embedded
within the r vertex they have an edge with. Note that additional information associ-
ated with the vertex (e.g., tracker/non-tracker/unknown label) is not aﬀected by the
transformation.
This implies that: (1) tracker vertices in V should be linked to many diﬀerent
vertices in U and (2) tracker vertices are members of well-deﬁned communities
in G.
Unfortunately, working with communities in 2-mode graphs like ours can be
tricky. For example, the relationships between vertices in the same mode are only
inferred from relationships that pass through vertices in the second mode, which
can lead to unexpected results from standard community detection algorithms
run on a raw 2-mode graph. This is especially a problem when the community
structures of the two modes are diﬀerent as we might expect in our case [9]. To
avoid this problem, it is typical to extract and analyze 1-mode projections of
2-mode graphs.
Assuming that users do not intentionally visit tracker sites, U should not
contain tracker URLs which are instead contained in V . Accordingly, we can
project the 2-mode graph into a 1-mode graph that only contains the vertices in
V , by creating the hosts-projection graph G(cid:3). In G(cid:3), we create an edge between
any two vertices in V that share a common neighbor in G. I.e., if two vertices,
v and v(cid:3) from V both share an edge with a vertex u from U, then there is
an edge e = (v, v(cid:3)) in G(cid:3). Figure 1 illustrates this transformation. This way,
G(cid:3) preserves much of the original graph’s structural information and captures
implicit connections between trackers through other sites.
3 Trackers’ Position in the Graph
In this section we present an analysis on the referer-hosts graph and the hosts-
projection graph. We are especially interested in discovering whether trackers
have diﬀerent properties than “normal” URLs in these graphs.
3.1 In the Referer-Hosts Graph
We ﬁrst investigate trackers’ degree centrality, or how well trackers are con-
nected to other vertices in the graph. Although trackers are essentially required
46
V. Kalavri et al.
1.00
0.75
F
D
C
0.50
0.25
0.00
kind
Other
Tracker
t
n
u
o
C
105
104
103
102
101
100
100
102
104
In−degree
106
101
102
103
Component Size
104
105
(a) CDF of in-degree.
(b) Connected components distribution.
Fig. 2. Basic analysis of referer-hosts graph.
to appear on many diﬀerent pages to collect meaningful data, we are interested
in quantifying this. We begin by plotting the in-degree of vertices in mode V
of the referer-hosts graph, broken down into “trackers” and “others” in Fig. 2a.
The ﬁgure can be thought of as illustrating the number of unique referers that
tracker/non-tracker hosts are embedded within. Surprisingly, we ﬁnd that track-
ers tend to have a slightly lower in-degree than other URLs, which contradicts
our initial observation that trackers must appear on many diﬀerent pages in
order to work. When looking at things a bit closer, we discovered that this is
due to the use of user/page speciﬁc tracking URLs, mostly from Google, such
unique-hash.metrics.gstatic.com. It follows that simply assuming high in-
degree vertices as characteristic of trackers is not suitable. As we will discuss
later, the hosts-projection graph transformation can be used to shed additional
light on this situation.
Next, to see how well connected trackers are to each other we extract con-
nected components and plot the distribution of their sizes in Fig. 2b. A connected
component is a subgraph in which there exists a path between any two of its
vertices. As expected, there are many 2-vertex components (pages that were
only visited once and that host no, or very uncommon 3rd party content) and
one dominant component. This largest connected component (LCC) contains
500,000 vertices, i.e., one fourth of the distinct URLs in our dataset, and 94 %
of all trackers in our dataset (identiﬁed via EasyPrivacy list) are in the LCC. We
will leverage this ﬁnding in Sect. 4 when showing how the community structure
of trackers can be exploited for detection purposes.
3.2
In the Hosts-Projection Graph
We create the hosts-projection graph from the largest connected component in
the referer-hosts graph. The projection has 80,000 vertices and 43 million edges.
We note that the only substantive information lost in the projection graph is
the number of unique pages a tracker appears on (i.e., the in-degree of the
Like a Pack of Wolves: Community Structure of Web Trackers
47
kind
Other
Tracker
1.00
0.75
F
D
C
0.50
0.25
0.00
100
101
102
103
degree
104
105
Fig. 3. CDF of degrees in the hosts-projection graph for trackers and others.
vertex within the referer-hosts graph). We ﬁrst look at the degree distribution of
trackers, and then examine the composition of their neighborhoods within the
hosts-projection graph.
Trackers’ Degree Distribution is a Distinguishing Factor. Figure 3 shows
the degree distribution of trackers and other hosts in the hosts-projection graph.
As opposed to the referer-hosts case, here we observe a clear diﬀerence between
the degree distribution of trackers and other pages, noting that the low-degree
skew of trackers has disappeared. This is due to the construction of the projection
graph: while in the referer-hosts graph, trackers only have edges to the pages
they are embedded within, in the projection graph, they are directly connected
with any URL that co-appears on the same page. For example, if we have three
trackers that are only embedded within a single page, they will each have an
in-degree of 1 in the referer-hosts graph, however, they will all be connected in
the projection graph, resulting in a degree of 2. In general, we note that a higher
degree might imply that trackers are more “important” in the projected graph
than other pages.
Figure 3 also illustrates another distinguishing factor of trackers. Their degree
distribution skews extremely high, with about 80 % having a degree of over 3,000.
The explanation for this is that URLs that point to content on sites (e.g., CDNs)
tend to be unique, or at least tend to appear on only a few sites. On the other
hand, trackers must appear on multiple sites to be eﬀective, and thus co-appear
with many other URLs (some tracker, some not).
Trackers are Mainly Connected to Other Trackers. Next, we examine
trackers’ neighborhoods more closely. Figure 4a shows the ratio of a vertex’s
neighbors that are trackers, distinguishing between tracker vertices and other.
We observe that the vast majority of trackers’ neighbors are other trackers. To
further investigate how well-connected trackers are among them, we plot the
ratio of a vertex’s neighbors that are trackers over the total number of trackers
in Fig. 4b and observe that trackers tend to be direct neighbors with most of
48