xmax,x(cid:2)
max (ˆtmax)
max (ˆtmax)
(ˆtmax)
max
(cid:4)
(cid:4)
(cid:4)
.
According to Proposition 1 together with (40) it follows that
B1, B2 = oP (1). Thus to show weak convergence of (41)
(which is key to our asymptotic result) we can show weak
convergence of B3.
In order to study B3 we consider the more general object
(cid:12)
(cid:3)
(cid:4)
G(t) :=
N hmax
(cid:8)xmax,x(cid:2)
max (t) − ˆ(cid:8)
∗
xmax,x(cid:2)
(t)
max
which is deﬁned for any t ∈ Uζ(M) (for some small enough,
ﬁxed ζ s.t. (30) and (31) hold), where from now on
M := arg max
t∈C
(cid:8)xmax,x(cid:2)
max (t).
We now notice that with probability converging to 1 it holds
for all t ∈ Uζ(M) that
xmax (t)) − ln( ˆf
∗
∗
sign(ln( ˆf
x(cid:2)
=sign(ln(fxmax (t)) − ln(fx(cid:2)
max (t))).
(42)
(t)))
max
This follows because the density estimators are uniformly
consistent (see Section II-B, equation (10)),
together with
boundedness away from 0 on Uζ(M) (see (30)).
For simplicity of presentation, we subsequently assume that
(cid:12)
the signum on the right side of (42) is always 1. This means
that with probability converging to 1
(cid:3)
xmax (t)) − ln(fxmax (t))]
∗
[ln( ˆf
− [ln( ˆf
∗
x(cid:2)
max (t))]
(t)) − ln(fx(cid:2)
max
(cid:4)
.
G(t) =
N hmax
By the mean value theorem we can transform the right side to
(cid:12)
N hmax
(cid:9) ˆf
xmax (t) − fxmax (t))
∗
ξ1(t)
∗
− ˆf
x(cid:2)
max
(t) − fx(cid:2)
ξ2(t)
max (t)
(cid:11)
.
∗
Here ξ1(t) lies between ˆf
xmax (t) and fxmax (t), and ξ2(t)
∗
between ˆf
max (t). We now focus on the fraction
x(cid:2)
of densities in xmax (the other one is analyzed step by step
in the same fashion). Using (30) and the uniform consistency
of the density estimates it is a simple calculation to show that
(t) and fx(cid:2)
max
xmax (t) − fxmax (t))
∗
ˆf
xmax (t) − fxmax (t)
∗
ˆf
ξ1(t)
=
fxmax (t)
+ Rem,
√
a
(negligible)
where Rem is
size
N hmax) (here we have applied the same techniques
oP (1/
as in the discussion of (33)). We can rewrite the fraction on
the right side as follows
remainder
of
(cid:11)
t − X
∗
i
hmax
(cid:21)
.
− fxmax (t)
xmax (t) − fxmax (t)
∗
ˆf
fxmax (t)
N(cid:6)
1
=
N fxmax (t)
i=1
(cid:9)
(cid:4)
−1
maxK
h
(cid:20)
(cid:3) t−X∗
(cid:13)
(cid:11)
i
hmax
−1
maxK
t − X
∗
i
hmax
(cid:13)
By standard arguments it is now possible to replace fxmax (t)
in the sum by Eh
, while only incurring a (uni-
formly in t) negligible error. More precisely:
t − s
hmax
fxmax (s)ds
−1
maxK
−1
maxK
(cid:9)
(cid:9)
(cid:11)
Eh
=
h
(cid:13)
=
K(s)fxmax (shmax + t)ds
=fxmax (t) +
=fxmax (t) + O(|hmax|β)
K(s)|fxmax (shmax + t) − fxmax (t)|ds
Here we have used symmetry of the kernel (K1) in Appendix
B) in the second and H¨older continuity of order β in the
last equality (see Assumption (C1); for a deﬁnition of H¨older
continuity recall (9)). We also notice that O(|hmax|β) =
N hmax), which makes the remainder asymptotically
oP (1/
negligible. By similar calculations we can show that
√
(cid:9)
Var
−1
maxK
h
−1
maxfxmax (t)
=h
(cid:11)(cid:11)
(cid:9)
t − X
∗
(cid:13)
i
hmax
K 2(y)dy + Rem2,
(43)
where Rem2 is a remainder of negligible order. We can use
the same considerations for fx(cid:2)
max to rewrite
N(cid:6)
i=1
G(t) =
1√
N
{Zi(t) − EZi(t)} + oP (1),
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:54 UTC from IEEE Xplore.  Restrictions apply. 
420
ˆtmax is the image measure of ˆtmax. Again we use that
where P
asymptotically the probability that ˆtmax (cid:3)∈ Uζ(M) converges
to 0 (see (28)). Now adding and substracting α yields
(cid:11)
− α dP
(cid:11)
(48)
(cid:2)(cid:2)(cid:11)
.
(cid:13)
α + o(1)
(cid:9)
+
Uζ (M)
(cid:9)
=α + o(1)
+ O
sup
t∈Uζ (M)
(cid:9)
(cid:2)(cid:2)P
S(t) ≤ Φ
−1(α)
P
ˆtmax (t)
S(t) ≤ Φ
−1(α)
− Φ(Φ
−1(α))
Given some ﬁxed t, the sum S consists of i.i.d. random vari-
ables with unit variance and expectation 0. We can therefore
apply the Berry-Esseen theorem to see that
− Φ(Φ
(cid:2)(cid:2) = o(1),
S(t) ≤ Φ
−1(α))
−1(α)
(cid:2)(cid:2)P
(cid:9)
(cid:11)
sup
t∈Uζ (M)
if we can show that (uniformly in t)
E| ˜Z1(t) − E ˜Z1(t)|3
√
N
= o(1).
Similar calculations as before show that
E| ˜Z1(t) − E ˜Z1(t)|3 = O(h
−1/2
max ),
which proves the approximation and thus entails that (48)
equals α + o(1). This again implies by (45), (46), that the
weak convergence in (27) holds and thus Theorem 2 part i).
where
Zi(t) = h
−1/2
max
(cid:20)
(cid:9)
K
(cid:11)
(cid:9)
+ K
(cid:11)(cid:21)
.
t − Y
∗
i
hmax
t − X
∗
i
hmax
All variables Zi are i.i.d. and, according to (43) (and analogous
calculations for fx(cid:2)
max), asymptotically have variance
(cid:13)
(cid:3)
σ2(t) :=
K 2(y)dy
[fxmax (t)]
−1 + [fx(cid:2)
max (t)]
−1
Now deﬁne the estimator
(cid:13)
ˆσ2(t) :=
K 2(y)dy
(cid:3)
∗
[ ˆf
xmax (t)]
∗
−1 + [ ˆf
x(cid:2)
max
−1
(t)]
(cid:4)
(cid:4)
,
,
which is identical to ˆσ2
N in MPL for t = ˆtmax. By similar
techniques as before, we can show that ˆσ2(t) is uniformly
(for t ∈ Uζ(M)) consistent for σ2(t). As a consequence, we
have G(t)/ˆσ(t) = S(t) + oP (1), where
N(cid:6)
(cid:12)
i=1
S(t) :=
1√
N
and ˜Zi(t) := {Zi(t)−EZi(t)}/
the identity (27): First notice that
(cid:9)
P(LB ≤ 
C) = P(LB ≤ xmax,x(cid:2)
∗
−1(α)ˆσ
(cid:9)
(cid:3)
(ˆtmax) +
cN
max (ˆtmax) − ˆ(cid:8)
∗
xmax,x(cid:2)
∗
ˆ(cid:8)
xmax,x(cid:2)
(cid:8)xmax,x(cid:2)
=P
=P
Φ
max
cN
ˆσ
+ o(1).
˜Zi(t)
(44)
Var(Zi). We can now prove
max,C)
≤ sup
t∈C
(cid:8)xmax,x(cid:2)
max (t)
(cid:4) ≤ Φ
(ˆtmax)
max
(cid:11)
(45)
(cid:11)
−1(α)
In the second equality we have used the decomposition (41),
together with the fact, that B1, B2 = oP (1). We can plug in
the deﬁnition of the process G into the probability on the right
of (45), which gives us
(cid:9)
(cid:9)
≤ Φ
G(ˆtmax)
S(ˆtmax) ≤ Φ
ˆσ
P
=P
(cid:11)
(cid:11)
−1(α)
−1(α)
+ o(1).
(46)
Here we have used the deﬁnition of S in (44), as well as the
(above mentioned) identity G(t)/ˆσ = S(t) + oP (1), which
holds uniformly in t ∈ Uζ(M) (recall that ˆtmax ∈ M with
probability converging to 1 according to (28)). Moreover,
we have strictly speaking used that S has (asymptotically)
a continuous distribution function (see below). Now recall
that ˆtmax (which is based on the samples X1, ..., Xn and
Y1, ..., Yn from the ﬁrst step of the algorithm) is independent
∗
N (and so loosely speaking of the
of all X
randomness in ˜Zi(·)). Thus we can express
∗
N , Y1, ..., Y
∗
1 , ..., X
(cid:9)
(cid:13)
P
=
(cid:11)
(cid:11)
−1(α)
−1(α)
dP
(cid:9)
S(ˆtmax) ≤ Φ
S(t) ≤ Φ
P
ˆtmax (t),
(47)
421
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:54 UTC from IEEE Xplore.  Restrictions apply.