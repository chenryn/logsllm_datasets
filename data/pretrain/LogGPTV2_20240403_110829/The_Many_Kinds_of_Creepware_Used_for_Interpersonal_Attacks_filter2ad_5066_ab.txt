entirely on co-installation data and does not use app properties
or metadata (in contrast to [5]).
We now turn to developing an exploratory graph mining
algorithm that exploits the GBA hypothesis. The algorithm,
CreepRank, takes as input a set of seed apps, an installation
dataset, and outputs a ranking for each app in the dataset.
When seeded with known creepware apps, high-ranking apps
are likely to be associated with interpersonal attack or defense.
This section proceeds by describing seed set selection for
CreepRank, its use of ﬁrst-order correlations among apps,
its false-positive mitigation scheme, and ﬁnally, the method
whereby it captures high-order correlation among apps.
A. Seed Set Selection
Our method is fundamentally a one-class algorithm in that
it measures the relevance between a focused set of seed apps
and all other apps. No other labeled data is required. Our
examination and coding of creepware apps is based on a seed
set of 18 overt surveillance apps identiﬁed by Chatterjee et
al. [5] that openly market themselves as usable for intimate
partner surveillance purposes, and which are sold outside
of the Google Play app marketplace because they do not
conform to marketplace rules. In Section VII-B we experiment
with CreepRank’s ability to explore narrower ecosystems by
seeding it with a variety of different seed sets.
B. First-Order Graph Algorithm
We determined that the most direct way to leverage the GBA
principle for mobile apps was to estimate the frequency with
which each app appears on a device that has been infected
with a seed set app. We start by representing installation data
as a graph, in which we represent apps and devices as nodes,
and add edges to represent the installation of apps on devices.
(a)
(b)
Fig. 2: Example bipartite graph representations of app instal-
lation data. An edge represents installation of the app on the
device. Seed set nodes are shown in red.
(cid:2)
(cid:3)
In Figure 2a, for example, app A is a seed set app installed
on Device 0, while app B is installed on Devices 0 and 1, one
of which is infected by a seed set app, while the other is not.
Formally, we model k, the number of infected devices on
which an app appears out of n total devices as a random
variable X drawn from a binomial distribution B(n, p), such
that P (X = k|p) =
pk(1 − p)n−k, where p denotes the
probability that the app appears on an infected device. Then,
probability p can be readily estimated from the installation
data using maximum likelihood estimation (MLE), which
yields p = k/n. Thus, the MLE method would estimate the
probability with which an app appears on an infected device
by dividing its observed installations on infected devices by
its total observed installations, which can then be used as a
risk score for the app and to rank all unknown apps.
n
k
C. Adding False Positive Suppression
While the MLE method of probability estimation is appeal-
ingly simple, when applied to our data to rank creepware,
it suffers from high false positive (FP) rates. To understand
why, consider apps E and G in Figure 2b. App E appears on
only one device, which is infected by app D, so MLE outputs
pE = 1/1, whereas for app G, which is on 14 infected devices,
it returns pG = 14/20. When we consider that the dataset
contains observations about more than 10 million apps, nearly
all of which are benign, app G is intuitively more suspicious
than the millions of rare apps like app E, whose sole instance
could have appeared on an infected device by random chance.
This intuition was born out in practice; our attempts to apply
the MLE method as a ranking tool yielded low quality rankings
with many irrelevant apps, as described in Section VI-A.
CreepRank therefore uses maximum a posteriori (MAP)
probability estimates, which are similar to MLE’s optimiza-
tion method, except
the a posteriori estimates incorporate
the random variable’s prior probability into the maximization
objective. That is, the MAP method incorporates an estimate of
the prior probability that apps appear on infected devices and
applies Bayes’ rule to choose the parameters of the posterior
probability distribution that maximize the probability of the
observed data given knowledge of the prior.
We must therefore estimate the prior probability distribution
with which apps appear on infected devices, which we do by
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:59 UTC from IEEE Xplore.  Restrictions apply. 
629
CreepRank
Input: Per-device edge lists of installed apps and list of seed set apps
1: Initialize seed-set apps with app score=1, otherwise app score=0
2: Set each dev score = max(app scores) across connected apps
3: Set each app score = avg(dev score)
4: Normalize app scores
5: If not converged then goto step 2
6: Apply MAP formula to obtain ﬁnal app scores
Output: Apps ranked in decreasing order of app scores
Fig. 3: The CreepRank algorithm to capture high-order corre-
lations between apps and devices they are co-installed on.
Device Scores
Normalized App Scores
Round
0
1
2
3
4
5
6
7
0
–
1
1
1
1
1
1
1
1
–
0
0.5
0.3
0.342
0.331
0.334
0.333
A
1
1
1
1
1
1
1
1
B
0
0.5
0.75
0.65
0.671
0.666
0.667
0.667
C
0
0
0.5
0.3
0.342
0.331
0.333
0.333
Table II: CreepRank applied to the graph of Figure 2a, showing
convergence to 3 signiﬁcant digits by the 7th iteration.
applying the MLE method from Section IV-B to all apps that
appear on at least 100 devices (we do not include rare apps as
these may produce unreliable MLE values). We then model the
prior probability distribution as a beta distribution Beta(α, β)
that we ﬁt to our MLE values, obtaining α = 1.09 and
β = 186. Our use of a beta distribution to model the prior is
convenient, as the beta distribution is a conjugate prior for the
binomial distribution with which we model our observations,
meaning that the posterior probability distribution is also a
beta distribution, with parameters Beta(α + k, β + n − k), for
which the MAP estimate of the mode of this distribution is
readily derived as (k + α − 1)/(n + α + β − 2).
Note that for our prior of Beta(1.09, 186), the MAP esti-
mates contrast with MLE primarily by adding a large constant
to the denominator of the estimate. Practically, this means that
the MAP estimate assigns small CreepRank values to apps that
are not observed on infected devices in large numbers, but the
effect of the prior diminishes as k and n increase.
D. Capturing High-Order Correlations Among Apps
The ﬁnal component of CreepRank reduces the algorithm’s
sensitivity to the small seed sets for which it is designed
by enabling it to capture high-order correlations between the
seed set and the broader ecosystem of creepware apps. We
considered alternative high-order graph-based methods, such
as random walk with restart (RWR) [11], [12], which provides
no mechanism to suppress false positives among rare apps,
causing it to include many irrelevant apps.
The steps of our algorithm, CreepRank, are shown in
Figure 3. Iterative application of these steps to the graph
shown in Figure 2a results in the values shown in Table II.
The input to CreepRank is a list of the apps installed on
each device, and a list of seed set apps. From this input, a
bipartite graph between device and app nodes is constructed,
with edges indicating an app’s presence on a particular device.
CreepRank’s ﬁrst step initializes the seed set apps with score
1 and all other apps with score 0. In Step 2, each device
receives an infection score that is the maximum value of all
apps installed on the device (these scores are binary in the
ﬁrst iteration). In Step 3, apps are assigned a score based on
the average score of the devices on which the app appears,
and the scores are normalized in Step 4 to ensure that the
sum of the app scores is equal to the sum of all MLE values
obtained by the ﬁrst-order method described in Section IV-B.
In the absence of normalization, the max function applied in
Step 2 would cause app scores to increase with each iteration
of the algorithm. Any desired convergence criteria can be set
for Step 5. We ran our algorithm for 10 iterations, since by
then the rankings became stable even for graphs of 500 million
edges. For instance, the maximum score delta was .00085 in
the algorithm’s 10th iteration for 2017 data, for a seed set of
18 apps (scores range from 0 to 1).
E. Implementation
Our datasets are quite large. For example, the graph cor-
responding to the 2017 installation dataset consists of 546
million edges, 25 million device nodes, and 10.6 million app
nodes. We therefore implemented CreepRank for use in a
distributed setting. The algorithm required only 77 lines of
code, which consist of 29 Scala commands that make ample
use of Spark. The algorithm ran on 100 Spark worker nodes
on an AWS cluster, each node consisting of a single CPU
core and 10GB of RAM, plus a driver node with 15GB of
RAM. These workers ran on a mix of AWS instances of type
m5.12xlarge (48 cores and 192GB RAM) and r5.4xlarge (16
cores and 128GB RAM). The average execution time, taken
over 10 executions of CreepRank on the 2017 dataset, was 24
minutes, 21 seconds with a standard deviation of 115 seconds.
Writing out the ranking scores of all 10 million apps to a
Hadoop File System takes an additional 90 seconds.
V. CATEGORIZING CREEPWARE
After running CreepRank on 2017 data with a seed set of
18 covert surveillance apps, we wanted to characterize the
categories of apps discovered. To achieve this, we manually
coded 1,000 apps that (1) were highest ranked by the algorithm
and therefore most risky, and (2) had at some point been
available on the Google Play store and for which we could
therefore obtain sufﬁciently detailed data via Internet searches.
The overarching question we sought to answer was: What cat-
egories of creepware exist beyond interpersonal surveillance
apps, and how prevalent are those categories?
A. Manual Coding Methods
We used a manual coding process to iteratively develop and
reﬁne a codebook of app categories. For each of the 1,000
highest-ranked apps, we presented coders with (1) the app
title and ID, (2) a link to a Google query for a marketplace
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:59 UTC from IEEE Xplore.  Restrictions apply. 
630
description of each app, and (3) additional metadata for each
app (e.g., installation counts, permissions, genre, etc.).
Our team consisted of four coders. We began by randomly
choosing a set of 25 apps that all
team members coded
independently. The guidelines were to (1) assign each app
one and only one code, and (2) assign codes using a two-level
hierarchy of categories and sub-categories that were developed
in the process of coding (e.g., Surveillance - Location). When
no sub-category was appropriate, apps were assigned the most
relevant top-level category (e.g., Surveillance - Misc).
After independently coding the ﬁrst round of 25 apps, the
group met to establish consensus and converge on appropriate
code names. The results of the team’s discussion were captured
in a codebook that was reﬁned in subsequent rounds of coding.
We proceeded in this fashion for 4 rounds of 25, 25, 25,
and 35 apps, jointly coding 110 apps. Having found that
the codebook had largely stabilized after two rounds, we
measured inter-coder agreement over the last 60 apps coded
by the whole group. Fleiss’ kappa statistic [33] indicated the
coders’ agreement was 0.77 when assigning apps to high-level
categories, and 0.75 when assigning apps to sub-categories,
indicating substantial agreement in both cases.
The remaining 890 apps were split evenly among the four
coders. We took multiple precautions to ensure that coding
consistency on the remaining apps would be at least as high as
that attained on the 60 apps on which we measured agreement.
Team members assigned a code of “other-discuss” for any
app that did not ﬁt into any category, and tagged all apps
they were uncertain about as “unsure”, providing explanatory
comments about such apps. All apps tagged as “other-discuss”
or “unsure” were reviewed by a second coder. In addition, all
apps that ﬁt into a high-level category and in a miscellaneous
sub-category were reviewed to identify any trends that might
only become apparent once all 1,000 apps had been reviewed.
All coding modiﬁcations that resulted from this review process
were discussed by the team to ensure agreement.
B. Results of Manually Coding Apps
Our algorithm captures both ﬁrst-order correlation between
apps that are highly likely to directly appear on devices on
which our seed set of overt surveillance apps are installed,
as well as apps that indirectly but strongly correlate with the
seed set. The coding process revealed remarkably few apps
that are not part of a clear trend; even among apps that have
no obvious abusive use cases. All apps mentioned by their title
here and elsewhere in the paper are listed under the code to
which they pertain in Appendix C’s Table IX.
The ﬁnal codebook consisted of 10 high-level categories
(e.g., Surveillance, Harassment, Spoof ) and 50 sub-categories
(e.g., Surveillance - Location, Harassment - Social Media,
and Spoof - SMS). Figure 4 shows apps assigned to sub-
categories, with the legend indicating the counts in parenthesis
for the corresponding high-level categories. The three most
prevalent sub-categories are all part of the Surveillance high-
level category: Surveillance - Social Media, Surveillance -
Location, and Surveillance - Thorough.
The rest of this section summarizes categories that suggest
apps are used to facilitate interpersonal attacks, categories that
suggest apps are used to defend against such attacks, and
categories without an immediate abusive or defensive purpose.
A comprehensive description of every code category, sub-
category, and examples is provided in Appendix C.
Characterizing potentially abusive apps. The largest cate-
gory of potentially abusive apps that we coded was Surveil-
lance, which is unsurprising given that the seed set we selected
consisted of surveillance apps. Apps in this category include
those that (1) both covertly and overtly track someone’s
location, (2) record phone call audio, call metadata and call
logs, (3) forward or snoop on SMS messages, (4) continu-
ously surveil social media accounts (mostly WhatsApp and
Facebook), (5) turn on the phone’s camera and microphone
and forward a stream to a remote device, and (6) apps that
record, stream, and/or take a snapshot of a device’s screen.
Although CreepRank’s discovery of so many surveillance apps
will clearly be useful in terms of warning users about such
apps or recommending that they be blocked from the app store,
the nature of such surveillance apps has also been the focus
of prior work [5] and thus we focus this discussion on other
categories of apps, relegating the details of our surveillance-
app ﬁndings to Appendix C.
We found 115 apps that enabled a variety of ways to spoof
information, including faking images, call logs, web content,
SMSs, WhatsApp messages, voice, and more. We coded 41 of
these apps as Spoof - Burner Phone because they support the
ability to make anonymous calls or SMS messages, with many
explicitly advertising as useful for evading call blocking. Even
more concerning and unambiguously malicious are apps that
enable impersonation. Many such apps enable abusers to bait
victims into a compromising response, sometimes allowing
entire conversations of messages to be faked. Developers
recommend their apps for putting words into the mouths
of unsuspecting victims, as in the case of the “Spoof Text
Message” app (see Figure 1), whose YouTube trailer2 says,
“Don’t like you buddy’s girlfriend? Well, break them up! Just
send a fake text message!”. Further scrutiny of SMS spooﬁng
apps and their malicious use cases is provided in Section
VII-B.
We used Harassment codes to categorize apps that could be
used to harass people in ways other than the mechanisms cap-
tured under surveillance, spooﬁng, control, and information-
extraction codes (discussed elsewhere). One unexpected and
prevalent type of app in this category were fake surveillance
apps, usually marketed as prank apps,
that are typically
designed to be installed on a prankster’s phone and brieﬂy
shown to a victim as the app simulates hacking the victim’s
device or accounts. Anecdotal evidence that fake-surveillance
apps can cause real stress is provided by the following user
review for “Other Number Location Tracker”, which was on
the Google Play store as of June 1, 2019 and subsequently
removed after we reported it to Google: