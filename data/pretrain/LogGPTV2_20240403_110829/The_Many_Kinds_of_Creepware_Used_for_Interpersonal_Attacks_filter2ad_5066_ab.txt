### Leveraging Co-Installation Data for Creepware Detection

This approach relies solely on co-installation data, without utilizing app properties or metadata, in contrast to the method proposed by [5]. We will now develop an exploratory graph mining algorithm that leverages the Guilt By Association (GBA) hypothesis. The algorithm, named CreepRank, takes as input a set of seed apps and an installation dataset, and outputs a ranking for each app in the dataset. When seeded with known creepware apps, high-ranking apps are likely to be associated with interpersonal attack or defense mechanisms. This section will cover seed set selection, first-order correlations among apps, false-positive mitigation, and capturing high-order correlations.

#### A. Seed Set Selection

CreepRank is fundamentally a one-class algorithm, measuring the relevance between a focused set of seed apps and all other apps, without requiring additional labeled data. Our seed set consists of 18 overt surveillance apps identified by Chatterjee et al. [5], which are marketed for intimate partner surveillance and sold outside the Google Play store due to non-compliance with marketplace rules. In Section VII-B, we experiment with different seed sets to explore narrower ecosystems.

#### B. First-Order Graph Algorithm

To leverage the GBA principle, we estimate the frequency with which each app appears on devices infected with a seed set app. We represent installation data as a bipartite graph, where nodes represent apps and devices, and edges indicate app installations on devices. For example, in Figure 2a, app A is a seed set app installed on Device 0, while app B is installed on Devices 0 and 1, one of which is infected by a seed set app.

Formally, we model the number of infected devices \( k \) out of \( n \) total devices as a random variable \( X \) drawn from a binomial distribution \( B(n, p) \), such that \( P(X = k | p) = \binom{n}{k} p^k (1 - p)^{n-k} \), where \( p \) is the probability that the app appears on an infected device. Using maximum likelihood estimation (MLE), we estimate \( p \) as \( k/n \). Thus, the MLE method estimates the probability of an app appearing on an infected device by dividing its observed installations on infected devices by its total observed installations, which can then be used as a risk score for ranking unknown apps.

#### C. False Positive Suppression

While the MLE method is simple, it suffers from high false positive rates when applied to our data. Consider apps E and G in Figure 2b: App E appears on only one device, which is infected by app D, resulting in \( p_E = 1/1 \). App G, on 14 infected devices, has \( p_G = 14/20 \). Given the dataset's size and the rarity of malicious apps, app G is more suspicious than app E, whose single instance could be a random occurrence.

To address this, CreepRank uses maximum a posteriori (MAP) probability estimates, which incorporate prior probabilities into the maximization objective. We estimate the prior probability distribution using MLE for apps appearing on at least 100 devices, fitting a beta distribution \( \text{Beta}(\alpha, \beta) \) to these values. For our prior \( \text{Beta}(1.09, 186) \), the MAP estimates add a large constant to the denominator, assigning small CreepRank values to apps not frequently observed on infected devices, with the effect diminishing as \( k \) and \( n \) increase.

#### D. Capturing High-Order Correlations Among Apps

To reduce sensitivity to small seed sets, CreepRank captures high-order correlations between the seed set and the broader ecosystem of creepware apps. Alternative methods like Random Walk with Restart (RWR) do not suppress false positives among rare apps, leading to many irrelevant inclusions.

The steps of CreepRank are shown in Figure 3. The input includes per-device edge lists of installed apps and a list of seed set apps. The algorithm initializes seed set apps with a score of 1 and others with 0. Each device receives an infection score based on the maximum app score, and apps are scored based on the average device score. Scores are normalized to ensure the sum of app scores equals the sum of MLE values. Convergence is typically achieved within 10 iterations, even for large graphs.

#### E. Implementation

Our datasets are extensive, with the 2017 installation dataset containing 546 million edges, 25 million device nodes, and 10.6 million app nodes. CreepRank was implemented for distributed settings, requiring 77 lines of Scala code and running on 100 Spark worker nodes on an AWS cluster. The average execution time for the 2017 dataset was 24 minutes and 21 seconds, with a standard deviation of 115 seconds. Writing the ranking scores to a Hadoop File System takes an additional 90 seconds.

### Categorizing Creepware

After running CreepRank on 2017 data with a seed set of 18 covert surveillance apps, we manually coded 1,000 highest-ranked apps to categorize them. The overarching question was: What categories of creepware exist beyond interpersonal surveillance apps, and how prevalent are they?

#### A. Manual Coding Methods

We used a manual coding process to iteratively develop and refine a codebook of app categories. For each of the 1,000 highest-ranked apps, coders were provided with the app title, ID, a link to a Google query for a marketplace description, and additional metadata. Four coders independently coded 25 apps, establishing consensus and refining the codebook over four rounds. Inter-coder agreement, measured by Fleiss' kappa, indicated substantial agreement (0.77 for high-level categories, 0.75 for sub-categories).

#### B. Results of Manually Coding Apps

CreepRank captures both first-order and high-order correlations, revealing few apps without clear trends. The final codebook included 10 high-level categories (e.g., Surveillance, Harassment, Spoof) and 50 sub-categories. The most prevalent sub-categories were under Surveillance: Surveillance - Social Media, Surveillance - Location, and Surveillance - Thorough.

**Characterizing Potentially Abusive Apps:**
- **Surveillance:** The largest category, including apps that track location, record phone calls, forward SMS messages, surveil social media, and stream device screens.
- **Spoof:** 115 apps enabled spoofing information, including faking images, call logs, web content, and impersonation. Some apps, like "Spoof Text Message," are explicitly designed for malicious use.
- **Harassment:** This category includes fake surveillance apps, often marketed as pranks, which can cause real stress. An example is "Other Number Location Tracker," which simulates hacking a victim's device.

Further details and examples of each category and sub-category are provided in Appendix C.