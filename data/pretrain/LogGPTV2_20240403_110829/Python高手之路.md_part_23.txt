11.2多进程与多线程
163
---
## Page 171
熊猫爱中国www.xiongmaoi.com
熊猫爱中国
传输，以使进程间可以彼此交换信息。
且可以通过它的 multiproce ssing.managers 对象在网络中分散负载。它还提供了双向
示例11.2使用multiprocessing的 worker
50498016,505378991
来说，实现是相当直接的。
显然它做不到，即使并行运行8个进程，它仍然卡在了129%，这只是硬件能力的32%。
50543387,505114931
164
python workermp.py 16.53s user 0.12s system 363% cpu 4.581 total
python worker.py 13.04s user 2.11s system 129% cpu 11.662 total
每次考虑在一定的时间内并行处理一些工作时，最好是依靠多进程创建（fork）多个作
此外，multiprocessing 模块不仅可以有效地将负载分散到多个本地处理器上，而
执行时间减少到60%，这次程序可以消耗363%的CPU能力，超过CPU能力的90%。
Resu1ts: [50495989, 50566997, 50474532, 50531418, 50522470, 50488087,
现在，我们使用multiprocessing 重写一下如示例11.2 所示。对于这种简单的例子
这个程序运行在四核的CPU上，这意味着 Python 最多可以利用 400%的CPU能力。
Resu1ts: [50517927, 50496846, 50494093, 50503078, 50512047, 50482863,
$ time python workermp.py
在同样的条件下运行这个程序，结果如示例11.3所示。
print("Results: %s" % pool.map(compute, range(8)))
#Start 8 workers
import multiprocessing
$ time python worker.py
pool=multiprocessing.Pool(8)
def compute(n):
import random
第11章扩展与架构
return sum(
[random.randint(1, 100) for i in range(1000000)])
本电子书仅限学习交流使用，请勿用于商业用途
但
---
## Page 172
熊猫爱中国www.xiongmaoi.com
熊猫为每个事件创建一个线程的方式?。这并不意味着二者互不兼容，这只是表明可以通过事件
①关于这个的进一步阅读，可以看看C10K问题（http://www.kegel.com/c10k.html#nb.kqueue）。
示例11.4使用select的基本示例
件驱动系统，尽管这显得有些乏味。使用 select 的基本示例如示例11.4 所示。
它们会对几个文件描述符进行监听，并在其中之一准备好读或写时做出响应。
到事件。其核心思想是令程序在等待输入输出完成前保持忙碌状态，最基本的事件通常类似
驱动机制摆脱多线程。
这样的模块。
式可以解决这个问题。
使用多线程的方法。
11.3
业，以便能够在多个CPU核之间分散负载。
在 Python 中，这些系统调用通过 select 模块开放了出来。很容易用它们构造一个事
在 Unix中,用于构建这种事件循环的标准函数是系统调用 select（2)或者 poll（2）。
事件驱动架构背后的技术是事件循环的建立。程序调用一个函数，它会一直阻塞直到收
我们已经在前面讨论了前面两种选择的优劣，本节只讨论事件驱动机制。
（1）每次有新连接建立时就创建（fork）一个新进程，需要用到 multiprocessing
import select
考虑这样一个程序，它想要监听一个套接字的连接，并处理收到的连接。有以下三种方
import socket
事件驱动编程会一次监听不同的事件，对于组织程序流程是很好的解决方案，并不需要
（现在）众所周知的是，使用事件驱动方法对于监听数百个事件源的场景的效果要好于
（3）将这个新连接加入事件循环（event loop）中，并在事件发生时对其作出响应。
（2）每次有新连接建立时创建一个新线程，
异步和事件驱动架构
本电子书仅限学习交流使用，请勿用于商业用途
，需要用到threading这样的模块。
11.3
异步和事件驱动架构
165
---
## Page 173
熊猫爱中国www.xiongmaoi.com
熊猫爱中国
接口兼容，而且将实现互操作。
中。?这个包的目标就是提供一个标准的事件循环接口。将来，所有的框架和库都将与这个
有的代码以及对标准函数的 monkey补丁。如果要长期使用和维护的话实际并非好的选择。
能互操作。而且，它们大多基于回调机制，这意味着在阅读代码时，程序的流程不是很清晰。
libevent、libev 或者libuv）也提供了高效的事件循环。
多年来在这方面已经成为了事实上的标准。也有一些提供了Python 接口的C 语言库（如
没有被广泛使用，而且演进也不太多。
166
最近，Guido Van Rossum开始致力于一个代号为 tulip 的解决方案，其记录在 PEP 3156
尽管它们都能解决同样的问题，但不利的一面在于现在选择太多了，而且它们之间大多数不
或者，还有很多其他框架通过更为集成化的方式提供了这类功能，如Twisted
不久前一个针对这些底层接口的包装器被加入到了 Python 中，名为 asyncore。它还
while True:
server.listen(8)
((00001 ',4sou1eoot,))putq'taa1as
# Bind the socket to the port
server.setblocking(0)
# Never block on read/write operations
server = socket.socket(socket.AF INET,
第11章扩展与架构
if server in inputs:
inputs, outputs, excepts = select.select(
# are ready to be read, written to or raised an error
# select() returns 3 arrays containing the object (sockets, files.) that
[serverl, [l, [server])
 connection.send("hello!\n") 
本电子书仅限学习交流使用，请勿用于商业用途
socket.SOCK_STREAM)
---
## Page 174
熊猫爱中国www.xiongmaoi.com
熊猫爱中国
示例11.5pyev示例
kqueue(2)。
还可以自动利用 polling 的最好的接口，如 Linux 上的 epoll(2)或者 BSD上的
持用于得Io对象，而且支持对子进程的跟踪，计时器、信号量和空闲时的事件回调。libev
写作时，还没有什么应用使用了asyncio模块。这意味着用了它很可能面临巨大的挑战。
一个事件循环呢？
名为trollius（htps://pypi.python.org/pypi/trollius），目标是令其可以兼容 Python 2.6及其后续版本。
需通过运行 pip install asyncio 即可安装。Victor Stinner 已经开始进行移植并将 tulip 命
话，也可以通过 PyPI（https://pypi.python.org/pypilasyncio）上提供的版本装在 Python 3.3上，只
#Never block on read/write operations
server = socket.socket(socket.AF_INET,
import pyev
如示例 11.5 所示，pyev 的接口是很容易掌握的。通过对1ibev的使用，它通不但支
·如果只针对Python 3，那就用 asyncio。刚开始会比较痛苦，因为没有太多的例子
在当前的 Python 开发中，这个问题很难回答。这门语言仍然在转换阶段。截止到本书
现在你已经拿到了所有的牌，你肯定会想：那我到底该用什么在事件驱动的应用中构建
tulip 已经被重命名并被并入了 Python 3.4的 asyncio包中。如果不打算依赖Python 3.4 的
import socket
·如果只针对Python 2，asyncio基本不用考虑。对我来说，接下来最好的选择是基
下面是目前我能给出的一些建议。
如果目标是同时支持Python的主要版本（Python2和Python3），最好使用能同时
和文档可以参考，但这是个安全的选择。你将会是先驱。
和trollius 也是个不错的方案。
中到处产生内部结构对事件库的依赖。如果愿意冒险的话，尝试混合使用asyncio
移到asyncio上。所以有一个最小化的抽象层会很有帮助，并且不要在整个程序
支持两个版本的库，如 pyev。不过，我必须强烈建议你记住，未来很可能需要迁
于 libev 的库，如 pyev (https://pypi.python.org/pypi/pyev)。
socket.SOCK_STREAM)
本电子书仅限学习交流使用，请勿用于商业用途
11.3异步和事件驱动架构
167
---
## Page 175
熊猫爱中国www.xiongmaoi.com
熊猫爱中国
多后端的RPC机制。AMQ 协议（http://www.amqp.org/）是主要的一个。但同样支持 Redis
程序的通信协议存在，对任何一个协议的详尽描述都需要一整本书的篇幅。
端用户)进行通信，并提供一个可支持多个连接协议的抽象RPC机制，最常用的就是AMQP。
面的表现是非常优秀的。如果不熟悉这方面的话，线上有大量相关的文档和评论。
似乎难以规避。然而，Python 在实现面向服务架构（Service-OrientedArchitecture，SOA）方
11.4面
168第11章扩展与架构
(http://redis.io/)、MongoDB (https://www.mongodb.org/)、BeanStalk (http://kr.github.io/beanstalkd/)、
（Representational state transfer）风格的架构。这类架构非常容易实现、扩展、部署和理解。
在Python 中，有许多库可以用来构建 RPC（Remote Procedure Call）系统。Kombu
然而，当在内部暴露和使用API时，使用HTTP可能并非最好的协议。有大量针对应用
SOA是OpenStack所有组件都在使用的架构。组件通过 HTTP REST和外部客户端（终
当需要暴露API给外界时，目前最好的选择是HTTP，并且最好是无状态设计，例如REST
在你自己的场景中，模块之间沟通渠道的选择关键是要明确将要和谁进行通信。
考虑到前面阐述的问题和解决方案，Python在解决大型复杂应用的可扩展性方面的问题
loop.start()
server.setblocking(0)
watcher.start()
watcher = pyev.Io(server, pyev.EV_ READ, loop, server_activity)
def server_activity(watcher,
server.listen(8)
server.bind(('localhost',10000))
# Bind the socket to the port
loop= pyev.default_loop()
connection, client _address = server.accept()
connection.close()
connection.send("hello!\n")
面向服务架构
本电子书仅限学习交流使用，请勿用于商业用途
revents):
---
## Page 176
熊猫爱中国www.xiongmaoi.com
熊猫爱
了和前面例子中同样的worker，但是利用了ZeroMQ 作为分发和通信的手段。
能选择的话还是最好使用无状态的组件。
要比用多线程好。可以在每个计算节点上启动多个worker。尽管不必如此，但是在任何时候：
每一块都将是一个不同的 Python 进程，正如我们在上面看到的，在分发工作负载时这样做
上。要做的只是需要有一个系统在 worker之间负责分发工作，这个系统提供了相应的 API。
程为每一个连接创建一个新worker，因而可以将连接分发到同一个计算节点的不同worker
API，那么可以运行多个守护进程暴露这些API。例如，Apache httpd将使用一个新的系统进
(http://zookeeper.apache.org/)。
国
ZeroMQ（http://zeromq.org/）是个套接字库，可以作为并发框架使用。下面的例子实现
最后，使用这样松耦合架构的间接收益是巨大的。如果考虑让每个模块都提供并暴露
context = zmg.Context()
def worker():
def compute():
z od
import multiprocessing
使用ZeroMQ的Worker
import random
while True:
poller.register(work_receiver, zmq.POLLIN)
poller = zmq.Poller()
result_sender.connect("tcp://0.0.0.0:5556")
result_sender = context.socket(zmq.PUSH)
work_receiver.connect("tcp://0.0.0.0:5555")
work_receiver = context.socket(zmg.PULL)
context = zmq.Context()
return sum(
if socks.get(work_receiver) == zmq.POLLIN:
socks = dict(poller.poll())
[random.randint(1, 100) for i in range(1000000)])
obj = work_receiver.recv_pyobj ()
result_sender.send_pyobj(obj())
本电子书仅限学习交流使用，请勿用于商业用途
11.4面向服务架构
169
---
## Page 177
熊猫爱中国www.xiongmaoi.com
熊猫爱中国
上，现如今，没理由不将软件设计为分布式的，或者受任何一种语言的限制。
异步 API，从而轻松地从一台计算机扩展到几千台。它不会将你限制在一种特定技术或语言
也许有他们的偏好，或者对于问题的某个部分，其他语言可能是更好的选择。
语言和平台构建系统的各个部分。尽管我们都认同 Python 是一门优秀的语言，但其他团队
布式的应用程序间通信。
保持本书中的例子尽量清晰和简洁，不难想象基于其上建立一个更为复杂的通信层。
的 inproc 信道。显然在这个例子中，基于ZeroMQ 构造的通信协议是非常简单的，这是为了
表明我们可以在网络中运行这个程序。应该注意的是，ZeroMQ 也提供了利用Unix套接字
170
最后，使用传输总线（transport bus）解耦应用是一个好的选择。它允许你建立同步和
注意，类似 HTTP、ZeroMQ或者AMQP这样的协议是同语言无关的。可以使用不同的
通过这种协议，不难想象通过网络消息总线（如ZeroMQ、AMQP等）构建一个完全分
如你所见，ZeroMQ提供了非常简单的方式来建立通信信道。我这里选用了TCP传输层，
print("Results: %s" % results)
for p in processes:
# Terminate all processes
for x in range(8):
results = []
#Read 8results
# Start 8 jobs
for x in range(8):
# Start 8 workers
result_receiver.bind("tcp://0.0.0.0:5556")
result receiver = context.socket(zmq.PuLL)
# Build a channel to receive computed results
work_sender.bind("tcp://0.0.0.0:5555")
work_sender = context.socket(zmq.PUSH)
# Build a channel to send work to be done
processes=[]
第11章扩展与架构
p.terminate()
results.append(result_receiver.recv_pyobj ())
work_sender.send_pyobj (compute)
processes.append (p)
p.start()
p = multiprocessing.Process(target=worker)
本电子书仅限学习交流使用，请勿用于商业用途
---
## Page 178
熊猫爱中国www.xiongmaoi.com