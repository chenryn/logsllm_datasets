## (流式、lambda、触发器)实时处理大比拼 - 物联网(IoT)\金融,时序处理最佳实践  
##### [TAG 18](../class/18.md)
### 作者                                                                                           
digoal                                         
### 日期                                           
2017-05-18                                       
### 标签                                         
PostgreSQL , 物联网 , 传感器 , lambda , 调度 , 实时 , 流式更新 , UPSERT , insert on conflict do update                      
----                                        
## 背景          
越来越多的数据要求实时的分析、聚合、展示最新值、展示异常值、实时的搜索。    
例如 金融数据、物联网传感器的数据、网络游戏的在线数据等等。    
![pic](20170518_01_pic_001.jpg)    
关于实时搜索，可以参考这篇最佳实践：    
[《行为、审计日志 实时索引/实时搜索 - 最佳实践》](../201705/20170516_01.md)      
关于海量数据的"写入、共享、存储、计算"，以及离线分析，则可以参考这篇最佳实践：    
[《海量数据 "写入、共享、存储、计算" - 最佳实践》](../201705/20170509_02.md)      
关于实时分析、实时更新、实时聚合、实时展示最新值、异常值，是本文的主要内容。    
提起实时分析，不得不说流式计算，用户可以参考本文：    
[《流计算风云再起 - PostgreSQL携PipelineDB力挺IoT》](../201612/20161220_01.md)      
pipelinedb是一个SQL接口的流计算数据库，正在进行插件化的改造，未来可以作为PostgreSQL数据库的插件使用。    
本文将以传感器数据的实时写入、实时更新最新值、实时统计为例，分析三种不同的方案（流式、lambda式、同步实时）的优缺点。    
## 场景设计    
有一百万个传感器，每个传感器定期上报数据，用户需求：    
1\. 实时的查看传感器的最新值，    
2\. 实时按时间段查看传感器历史数据的统计值。    
3\. 实时查看传感器的历史明细数据。    
4\. 实时按其他维度查看传感器历史数据的统计值。    
由于数据量可能非常庞大（100TB级），为了实现这4个需求，要求统计数据需要实时或准实时的被计算出来。    
### 表结构设计    
#### 明细数据    
```    
create table sensor_data(    
  pk serial8 primary key, -- 主键    
  ts timestamp,  -- 时间戳    
  sid int,  -- 传感器ID    
  val numeric(10,2)  -- 数据    
);    
```    
### 实时聚合设计    
1\. 每个传感器最后的value    
```    
create table sensor_lastdata(    
  sid int primary key,  -- 传感器ID，主键    
  last_ts timestamp,  -- 时间戳    
  last_val numeric(10,2)  -- 值    
);    
```    
2\. 每个传感器每个时段（例如小时）的所有值，总和，记录数，最大值，最小值，平均值，方差。    
```    
create table sensor_aggdata(    
  sid int,  -- 传感器ID    
  ts_group varchar(10),  -- 时间维度分组，例如小时(yyyymmddhh24)    
  sum_val numeric,  -- 和    
  min_val numeric(10,2),  -- 最小值    
  max_val numeric(10,2),  -- 最大值    
  avg_val numeric(10,2),  -- 平均值    
  count_val int,  -- 计数    
  all_vals numeric(10,2)[],  -- 明细值    
  unique (sid,ts_group)  -- 唯一约束    
);    
```    
3\. 按地域或其他维度，实时统计传感器上报的数据    
略    
## 如何从明细数据取传感器的最新值    
取出每个传感器ID的最新值。使用SQL来取，有两种方法，一种是聚合，另一种是窗口函数。    
插入一批测试数据    
```    
postgres=#  insert into sensor_data(ts,sid,val) select clock_timestamp(), random()*100, random()*10000 from generate_series(1,100000);    
```    
方法1，聚合。    
按SID分组，将VAL聚合为数组（按PK逆序排序），取数组的第一个VALUE。    
参考用法：https://www.postgresql.org/docs/9.6/static/functions-aggregate.html    
```    
postgres=#  select sid, (array_agg(ts order by pk desc))[1] as last_ts, (array_agg(val order by pk desc))[1] as last_val from sensor_data group by sid;    
 sid |          last_ts           | last_val     
-----+----------------------------+----------    
   0 | 2017-05-18 14:09:10.625812 |  6480.54    
   1 | 2017-05-18 14:09:10.627607 |  9644.29    
   2 | 2017-05-18 14:09:10.627951 |  3995.04    
   3 | 2017-05-18 14:09:10.627466 |   840.80    
   4 | 2017-05-18 14:09:10.627703 |  1500.59    
   5 | 2017-05-18 14:09:10.627813 |  3109.42    
   6 | 2017-05-18 14:09:10.62754  |  4131.31    
   7 | 2017-05-18 14:09:10.627851 |  9333.88    
......    
```    
方法2，窗口。    
```    
postgres=# select sid,ts,val from (select sid,ts,val,row_number() over(partition by sid order by pk desc) as rn from sensor_data) t where rn=1;    
 sid |             ts             |   val       
-----+----------------------------+---------    
   0 | 2017-05-18 14:09:10.625812 | 6480.54    
   1 | 2017-05-18 14:09:10.627607 | 9644.29    
   2 | 2017-05-18 14:09:10.627951 | 3995.04    
   3 | 2017-05-18 14:09:10.627466 |  840.80    
   4 | 2017-05-18 14:09:10.627703 | 1500.59    
   5 | 2017-05-18 14:09:10.627813 | 3109.42    
   6 | 2017-05-18 14:09:10.62754  | 4131.31    
   7 | 2017-05-18 14:09:10.627851 | 9333.88    
......    
```    
这两种方法哪种好一点呢？请看执行计划    
```    
postgres=# set work_mem ='16MB';    
SET    
postgres=# explain (analyze,verbose,timing,costs,buffers) select sid, (array_agg(ts order by pk desc))[1] as last_ts, (array_agg(val order by pk desc))[1] as last_val from sensor_data group by sid;    
                                                             QUERY PLAN                                                                 
------------------------------------------------------------------------------------------------------------------------------------    
 GroupAggregate  (cost=7117.15..7823.57 rows=101 width=44) (actual time=29.628..88.095 rows=101 loops=1)    
   Output: sid, (array_agg(ts ORDER BY pk DESC))[1], (array_agg(val ORDER BY pk DESC))[1]    
   Group Key: sensor_data.sid    
   Buffers: shared hit=736    
   ->  Sort  (cost=7117.15..7293.38 rows=70490 width=26) (actual time=29.273..36.249 rows=70490 loops=1)    
         Output: sid, ts, pk, val    
         Sort Key: sensor_data.sid    
         Sort Method: quicksort  Memory: 8580kB    
         Buffers: shared hit=736    
         ->  Seq Scan on public.sensor_data  (cost=0.00..1440.90 rows=70490 width=26) (actual time=0.243..9.768 rows=70490 loops=1)    
               Output: sid, ts, pk, val    
               Buffers: shared hit=736    
 Planning time: 0.077 ms    
 Execution time: 88.489 ms    
(14 rows)    
postgres=# explain (analyze,verbose,timing,costs,buffers) select sid,ts,val from (select sid,ts,val,row_number() over(partition by sid order by pk desc) as rn from sensor_data) t where rn=1;    
                                                                QUERY PLAN                                                                    
------------------------------------------------------------------------------------------------------------------------------------------    
 Subquery Scan on t  (cost=7117.15..9408.08 rows=352 width=18) (actual time=46.074..81.377 rows=101 loops=1)    
   Output: t.sid, t.ts, t.val    
   Filter: (t.rn = 1)    
   Rows Removed by Filter: 70389    
   Buffers: shared hit=736    
   ->  WindowAgg  (cost=7117.15..8526.95 rows=70490 width=34) (actual time=46.072..76.115 rows=70490 loops=1)    
         Output: sensor_data.sid, sensor_data.ts, sensor_data.val, row_number() OVER (?), sensor_data.pk    
         Buffers: shared hit=736    
         ->  Sort  (cost=7117.15..7293.38 rows=70490 width=26) (actual time=46.065..51.742 rows=70490 loops=1)    
               Output: sensor_data.sid, sensor_data.pk, sensor_data.ts, sensor_data.val    
               Sort Key: sensor_data.sid, sensor_data.pk DESC    
               Sort Method: quicksort  Memory: 8580kB    
               Buffers: shared hit=736    
               ->  Seq Scan on public.sensor_data  (cost=0.00..1440.90 rows=70490 width=26) (actual time=0.245..9.863 rows=70490 loops=1)    
                     Output: sensor_data.sid, sensor_data.pk, sensor_data.ts, sensor_data.val    
                     Buffers: shared hit=736    
 Planning time: 0.100 ms    
 Execution time: 82.480 ms    
(18 rows)    
```    
## 实时更新、统计 - 设计与压测    
### 1. lambda    
lambda方式，传感器数据写入明细表，以任务调度的方式，从明细表取出数据并删除，将取出的数据进行增量统计，合并到统计结果中。    
![pic](20170518_01_pic_002.jpg)    
统计维度可能较多，为了并行，剥离数据获取和删除部分的功能。    
批量获取并删除明细数据，按pk排序，批量获取若干条。    
函数如下：    
```    
create or replace function get_sensor_data(i_limit int) returns sensor_data[] as $$    
declare    
  arr_pk int8[];    
  arr_sensor_data sensor_data[];    
begin    
  select array_agg(t.sensor_data), array_agg((t.sensor_data).pk)    
    into arr_sensor_data, arr_pk    
    from (select sensor_data from sensor_data order by pk limit i_limit for update skip locked) t ;    
  delete from sensor_data WHERE pk = any (arr_pk);    
  return arr_sensor_data;    
end;    
$$ language plpgsql strict;    
```    
明细数据获取到之后，继续下一步的动作。    
存在则更新，不存在则插入，采用PostgreSQL的insert on conflict语法。    
1\. 实时更新传感器的最新值    
```    
insert into sensor_lastdata    
  select sid, (array_agg(ts order by pk desc))[1] as last_ts, (array_agg(val order by pk desc))[1] as last_val from     
    unnest(get_sensor_data(1000))     
  group by sid    
on conflict (sid) do update set last_ts=excluded.last_ts,last_val=excluded.last_val;    
```    
2\. 批量增量统计传感器的值    
统计值的合并方法请关注SQL内容，明细数据按SID聚合为数组按PK顺序存放。    
```    
insert into sensor_aggdata (sid,ts_group,sum_val,min_val,max_val,avg_val,count_val,all_vals)    
select sid,to_char(ts,'yyyymmddhh24'),sum(val),min(val),max(val),avg(val),count(val),array_agg(val order by pk) from unnest(get_sensor_data(1000))     
  group by sid,to_char(ts,'yyyymmddhh24')    
  on conflict (sid,ts_group) do update set     
    sum_val=sensor_aggdata.sum_val+excluded.sum_val,    
    min_val=least(sensor_aggdata.min_val, excluded.min_val),    
    max_val=greatest(sensor_aggdata.max_val, excluded.max_val),    
    avg_val=(sensor_aggdata.sum_val+excluded.sum_val)/(sensor_aggdata.count_val+excluded.count_val),    
    count_val=sensor_aggdata.count_val+excluded.count_val,    
    all_vals=array_cat(sensor_aggdata.all_vals, excluded.all_vals);    
```    
#### 压测    
```    
create table sensor_data(    
  pk serial8 primary key, -- 主键    
  ts timestamp,  -- 时间戳    
  sid int,  -- 传感器ID    
  val numeric(10,2)  -- 数据    
);    
create table sensor_lastdata(    
  sid int primary key,  -- 传感器ID，主键    
  last_ts timestamp,  -- 时间戳    
  last_val numeric(10,2)  -- 值    
);    
create table sensor_aggdata(    
  sid int,  -- 传感器ID    
  ts_group varchar(10),  -- 时间维度分组，例如小时(yyyymmddhh24)    
  sum_val numeric,  -- 和    
  min_val numeric(10,2),  -- 最小值    
  max_val numeric(10,2),  -- 最大值    
  avg_val numeric(10,2),  -- 平均值    
  count_val int,  -- 计数    
  all_vals numeric(10,2)[],  -- 明细值    
  unique (sid,ts_group)  -- 唯一约束    
);    
```    
##### 压测1，实时写入，并实时更新传感器的最新值    
```    
vi ins.sql    