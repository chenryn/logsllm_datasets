title:Electing an Eventual Leader in an Asynchronous Shared Memory System
author:Antonio Fern&apos;andez and
Ernesto Jim&apos;enez and
Michel Raynal
Electing an Eventual Leader
in an Asynchronous Shared Memory System (cid:0)
Antonio FERN ´ANDEZyy
Ernesto JIM ´ENEZz
Michel RAYNAL(cid:0)
y LADyR, GSyC, Universidad Rey Juan Carlos, 28933 M´ostoles, Spain
z EUI, Universidad Polit´ecnica de Madrid, 28031 Madrid, Spain
(cid:0) IRISA, Universit´e de Rennes, Campus de Beaulieu 35 042 Rennes, France
PI:EMAIL
PI:EMAIL
PI:EMAIL
Abstract
This paper considers the problem of electing an eventual
leader in an asynchronous shared memory system. While
this problem has received a lot of attention in message-
passing systems, very few solutions have been proposed
for shared memory systems. As an eventual leader can-
not be elected in a pure asynchronous system prone to pro-
cess crashes, the paper ﬁrst proposes to enrich the asyn-
chronous system model with an additional assumption. That
assumption, denoted AWB, requires that after some time
(1) there is a process whose write accesses to some shared
variables are timely, and (2) the timers of the other pro-
cesses are asymptotically well-behaved. The asymptotically
well-behaved timer notion is a new notion that generalizes
and weakens the traditional notion of timers whose dura-
tions are required to monotonically increase when the val-
ues they are set to increase. Then, the paper presents two
AWB-based algorithms that elect an eventual leader. Both
algorithms are independent of the value of t (the maximal
number of processes that may crash). The ﬁrst algorithm
enjoys the following noteworthy properties: after some time
only the elected leader has to write the shared memory,
and all but one shared variables have a bounded domain,
be the execution ﬁnite or inﬁnite. This algorithm is conse-
quently optimal with respect to the number of processes that
have to write the shared memory. The second algorithm en-
joys the following property: all the shared variables have
a bounded domain. This is obtained at the following addi-
tional price: all the processes are required to forever write
the shared memory. A theorem is proved which states that
(cid:0)The work of A. Fern´andez and E. Jim´enez was partially supported by
the Spanish MEC under grants TIN2005-09198-C02-01, TIN2004-07474-
C02-02, and TIN2004-07474-C02-01, and the Comunidad de Madrid un-
der grant S-0505/TIC/0285. The work of Michel Raynal was supported by
the European Network of Excellence ReSIST.
yThe work of this author was done while on leave at IRISA, supported
by the Spanish MEC under grant PR-2006-0193.
this price has to be paid by any algorithm that elects an
eventual leader in a bounded shared memory model. This
second algorithm is consequently optimal with respect to
the number of processes that have to write in such a con-
strained memory model.
In a very interesting way, these
algorithms show an inherent tradeoff relating the number
of processes that have to write the shared memory and the
bounded/unbounded attribute of that memory.
1 Introduction
Equipping an asynchronous system with an oracle An
asynchronous system is characterized by the absence of a
bound on the time it takes for a process to proceed from a
step of its algorithm to the next one. Combined with process
failures, such an absence of a bound can make some syn-
chronization or coordination problems impossible to solve
(even when the processes communicate through a reliable
communication medium). The most famous of these “im-
possible” asynchronous problems is the well-known con-
sensus problem [7].
Intuitively, this impossibility comes
from the fact that a process cannot safely distinguish a
crashed process from a very slow process.
One way to address and circumvent these impossibilities
consists on enriching the underlying asynchronous systems
with an appropriate oracle [27]. More precisely, in a system
prone to process failures, such an oracle (sometimes called
failure detector) provides each process with hints on which
processes are (or are not) faulty. According to the quality
of these hints, several classes of oracles can be deﬁned [3].
So, given an asynchronous system prone to process failures
equipped with an appropriate oracle, it becomes possible to
solve a problem that is, otherwise, impossible to solve in
a purely asynchronous system. This means that an oracle
provides processes with additional computability power.
Fundamental issues related to oracles for asynchronous
systems Two fundamental questions can be associated
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:49:55 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007with oracles. The ﬁrst is more on the theoretical side and
concerns their computability power. Given a problem (or
a family of related problems), which is the weakest oracle
that allows solving that problem in an asynchronous system
where processes can experience a given type of failures?
Intuitively, an oracle Ow is the weakest for solving a prob-
lem P if it allows solving that problem, and any other oracle
Onw that allows solving P provides hints on failures that are
at least as accurate as the ones provided by Ow (this means
that the properties deﬁning Onw imply the ones deﬁning
Ow, but not necessarily vice-versa). It has been shown that,
in asynchronous systems prone to process crash failures, the
class of eventual leader oracles is the weakest for solving
asynchronous consensus, be these systems message-passing
systems [4] or shared memory systems [20]1. It has also
been shown that, for the same type of process failures, the
class of perfect failure detectors (deﬁned in [3]) is the weak-
est for solving asynchronous interactive consistency [14].
The second important question is on the algo-
rithm/protocol side and concerns the implementation of or-
acles (failure detectors) that are designed to equip an asyn-
chronous system. Let us ﬁrst observe that no such ora-
cle can be implemented on top of a purely asynchronous
system (otherwise the problem it allows solving could be
solved in a purely asynchronous system without additional
computability power). So, this fundamental question trans-
lates as follows. First, ﬁnd “reasonably weak” behavioral
assumptions that, when satisﬁed by the underlying asyn-
chronous system, allow implementing the oracle. “Reason-
ably weak” means that, although they cannot be satisﬁed by
all the runs, the assumptions are actually satisﬁed in “nearly
all” the runs of the asynchronous system. Second, once such
assumptions have been stated, design efﬁcient algorithms
that implement correctly the oracle in all the runs satisfying
the assumptions.
Content of the paper Considering the asynchronous
shared memory model where any number of processes can
crash, this paper addresses the construction of eventual
leader oracles [4]. Such an oracle (usually denoted (cid:0))2 pro-
vides the processes with a primitive leader(cid:1)(cid:2) that returns a
process identity, and satisﬁes the following “eventual” prop-
erty in each run R: There is a time after which all the in-
vocations of leader(cid:1)(cid:2) return the same identity, that is the
identity of a process that does not crash in the run R.
As already indicated, such an oracle is the weakest to
solve the consensus problem in an asynchronous system
where processes communicate through single-writer/multi-
readers (1WnR) atomic registers and are prone to crash
1Let us also notice that the Paxos fault-tolerant state machine replica-
tion algorithm [18] is based on the (cid:0) abstraction. For the interested reader,
an introduction to the family of Paxos algorithms can be found in [12].
2Without ambiguity and according to the context, (cid:0) is used to denote
either the class of eventual leader oracles, or an oracle of that class.
failures [20].
The paper has three main contributions.
(cid:1) It ﬁrst proposes a behavioral assumption that is partic-
ularly weak. This assumption is the following one. In
each run, there are a ﬁnite (but unknown) time (cid:0) and
a process p (not a priori known) that does not crash in
that run, such that after (cid:0):
– (1) There is a bound (cid:3) (not necessarily known)
such that any two consecutive write accesses to
some shared variables issued by p are separated
by at most (cid:3) time units, and
– (2) Each correct process q (cid:4) p has a timer that
is asymptotically well-behaved. Intuitively, this
notion expresses the fact that eventually the du-
ration that elapses before a timer expires has to
increase when the timeout parameter increases.
It is important to see that the timers can behave ar-
bitrarily during arbitrarily long (but ﬁnite) periods.
Moreover, as we will see in the formal deﬁnition, their
durations are not required to strictly increase according
to their timeout periods. After some time, they have
only to be lower-bounded by some monotonously in-
creasing function.
It is noteworthy to notice that no process (but p) is re-
quired to have any synchronous behavior. Only their
timers have to eventually satisfy some (weak) behav-
ioral property.
(cid:1) The paper then presents two algorithms that construct
an (cid:0) oracle in all the runs that satisfy the previous
behavioral assumptions, and associated lower bounds.
All the algorithms use atomic 1WnR atomic registers.
The algorithms, that are of increasing difﬁculty, are
presented incrementally.
– In the ﬁrst algorithm, all (but one of) the shared
variables have a bounded domain (the size of
which depends on the run). More speciﬁcally,
this means that, be the execution ﬁnite or inﬁnite,
even the timeout values stop increasing forever.
Moreover, after some time, there is a single pro-
cess that writes the shared memory. The algo-
rithm is consequently write-efﬁcient. It is even
write-optimal as at least one process has to write
the shared memory to inform the other processes
that the current leader is still alive.
– The second algorithm improves the ﬁrst one in
the sense that all the (local and shared) variables
are bounded. This nice property is obtained by
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:49:55 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007using two boolean ﬂags for each pair of pro-
cesses. These ﬂags allow each process p to in-
form each other process q that it has read some
value written by q.
(cid:1) The third contribution is made up of lower bound re-
sults are proved for the considered model. Two theo-
rems are proved that state (1) the process that is even-
tually elected has to forever write the shared memory,
and (2) any process (but the eventual leader) has to
forever read from the shared memory. Another the-
orem shows that, if the shared memory is bounded,
then all the processes have to forever write into the
shared memory. These theorems show that both the
algorithms presented in the paper are optimal with re-
spect to these criteria.
Why shared memory-based (cid:0) algorithms are important
Multi-core architectures are becoming more and more de-
ployed and create a renewed interest for asynchronous
shared memory systems.
In such a context, it has been
shown [10] that (cid:0) constitutes the weakest contention man-
ager that allows transforming any obstruction-free [15] soft-
ware transactional memory into a non-blocking transac-
tional memory [16]. This constitutes a very strong moti-
vation to look for requirements that, while being “as weak
as possible”, are strong enough to allow implementing (cid:0) in
asynchronous shared memory environments prone to pro-
cess failures.