m
(
y
c
n
e
t
a
L
.
g
o
c
e
R
 1000
 800
 600
 400
 200
 0
0
Baseline
FlowFence
2
1
5
Recog. DB Size (num. of images)
3
4
Figure 5: FaceDoor Recognition Latency (ms) on vary-
ing DB sizes for Baseline and FlowFence. Using Flow-
Fence causes 5% increase in average latency.
HeartRateMonitor Metric (fps)
Throughput with no Image Processing
Throughput with Image Processing
Baseline
Avg
(SD)
23.0
(0.7)
22.9
(0.7)
FlowFence
Avg
(SD)
22.9
(0.7)
22.7
(0.7)
Table 3: Throughput for HeartRateMonitor on Baseline
(Stock Android) and FlowFence. FlowFence imposes lit-
tle overhead on the app.
size of 290.3kB (SD=15.2).
We observed an enroll latency of 811ms (SD=37.1) in
the baseline case, and 937ms (SD=60.4) for FlowFence,
averaged over 50 trials. The increase in latency (15.5%)
is due to QM load time, and marshaling costs for trans-
ferring bitmaps over process boundaries. While the in-
crease in latency is well within bounds of network varia-
tions, and undetectable by user in both previous cases; it
is important to recognize that most of this increase is re-
sulted from setup time and the effect on actual processing
time is much more modest. Figure 5 shows latency for
face recognition, averaged over 10 trials, for Baseline,
and FlowFence. We varied the recognition database size
from 1 to 5 images. In each test, the last image enrolled
in the database is a specific person’s face that we desig-
nated as the test face. While invoking the recognition op-
eration, we used another image of the same test person’s
face. We observe a modest, and expected increase in la-
tency when FaceDoor runs on FlowFence. For instance,
it took 882ms to successfully recognize a face in a DB of
5 images and unlock the door on FlowFence, compared
to 841ms on baseline—a 4.9% increase. This latency is
smaller than 100ms and thus small enough to not cause
user-noticeable delays in unlocking a door once a face is
recognized [13].
Throughput. Table 3 summarizes the throughput in
frames per second (fps) for HeartRateMonitor. We ob-
served a throughput of 23.0 f ps on Stock Android for
an app that read frames at maximum rate from a camera
over a period of 120 seconds. We repeated the same ex-
periment with the image processing load of heart rate de-
tection, and observed no change in throughput. These re-
sults matched our expectations, given that the additional
serialization and call latency is too low to impact the
throughput of reading from the camera (camera was the
bottleneck). Thus, we observed no change in the app’s
abilities to derive heart rate.
6 Discussion and Limitations
Overtainting. Overtainting is difficult to avoid in taint
propagation systems. FlowFence limits overtainting in
two ways: (1) by not propagating taint labels from a QM
to its caller—an opaque handle returned as a result of a
call to a QM has an associated taint but does not cause
the caller to become tainted (unless the caller is a QM
that dereferences the handle), limiting the taints to QMs;
and (2) a QM (and associated sandbox) is ephemeral.
Since FlowFence sanitizes sandboxes if a new occupant’s
taints differ from the previous occupant, reusing sand-
boxes does not cause overtainting. Nevertheless, Flow-
Fence does not prevent overtainting due to poor applica-
tion decomposition into QMs.
A malicious publisher can potentially overtaint a con-
sumer by publishing overtainted data that the consumer
subscribes to, leading to poison-pill attacks [37]. A plau-
sible defense strategy is to allow a consumer to inspect
an item’s taint and not proceed with a read if the item is
overtainted [63]. However, this risks introducing a sig-
naling mechanism from a high producer to a low con-
sumer via changes to the item’s taint set. To address
the attack in the context of our system. We first observe
that most publishers will publish their sensor data un-
der a known, fixed taint. The key idea is to simply re-
quire publishers to define a taint bound T Mc, whenever
a channel c is created.8 If the publisher writes data with
a taint set T that is not a subset of T Mc to the channel c,
the write operation is denied and results in an exception;
else the write is allowed. The consumer, to avoid get-
ting overtainted, can inspect this channel’s taint bound
(but not the item’s taint) before deciding to read an item
from the channel. The taint bound cannot be modified,
once defined, avoiding the signaling problem. A simi-
lar defense mechanism was proposed in label-based IFC
systems [63, 62].
Applicability of Opacified Computation to other do-
mains. In this work we only discussed Opacified Com-
8Same idea applies when creating keys, with a taint bound defined
at that time for any future value associated with the key.
USENIX Association  
25th USENIX Security Symposium  543
putation in the context of IoT frameworks (e.g., Flow-
Fence Key-Value Store and Event Channels are inspired
by our IoT framework study). The basic Opacified Com-
putation model is broadly applicable. For example, there
is nothing fundamental preventing our hub from being
a mobile smartphone and the app running on it being a
mobile app. But, applying FlowFence to existing mo-
bile apps is challenging because of the need to refactor
apps and the libraries they use (many of the libraries ac-
cess sensitive data as well as sinks). As another design
point, there is no fundamental limitation that requires
IoT hub software to run in a user’s home; it could well
be cloud-hosted and provided as a trusted cloud-based
service for supporting computations on sensitive data.
Use of a cloud-based service for executing apps is not
unusual—SmartThings runs all apps on its cloud, using
a hub to primarily serve as a gateway for connecting de-
vices to the cloud-based apps.
Usability of Flow Prompts. FlowFence suffers from
the same limitation as all systems where users need to
make security decisions, in that we cannot prevent users
from approving flows that they should not. FlowFence
does offer additional information during prompts since it
presents flow requests with sources and sinks indicating
how the app intends to use data, possibly leading to more
informed decision-making.
Flow prompts to request
user permissions could be avoided if publisher policies
always overrode consumer policies, with no user over-
ride allowed. But that just shifts the burden to specifying
publisher policies correctly, which still may require user
involvement. User education on flow policies and further
user studies are likely going to be required to examine
usability of flow prompts.
In some IoT environments,
the right to configure policies or grant overrides could be
assigned to specially-trained administrators who manage
flow policies on behalf of users and install apps and de-
vices for them.
Measuring flows. Almuhimedi et al. performed a user
study that suggests that providing metrics on frequency
of use of a previously granted permission can nudge
users to patch their privacy policy [6]. For example, if
a user is told that an app read their location 5,398 times
over a day, they may be more inclined to prevent that app
from getting full access to the location. Adding support
for measuring flows (both permitted and denied) to assist
users in evaluating past flow permissions is part of future
work.
Side Channels. A limitation of our current design is that
attackers can encode sensitive data values in the time it
takes for QMs to return. Such side channel techniques
are primarily applicable to leaking low-bandwidth data.
Nevertheless, we are investigating techniques to restrict
this particular channel by making QMs return immedi-
ately, and have them execute asynchronously, thus elim-
inating the availability of fine-grain timing information
in the opaque handles (as in LIO [61]). This would in-
volve creating opaque handle dependency graphs that de-
termine how to schedule QMs for later execution. Fur-
thermore, timing channel leakages can be bounded using
predictive techniques [72].
7 Related Work
IoT Security. Current research focuses around analyz-
ing the security of devices [35, 27], protocols [44, 11],
or platforms [26, 12]. For example, Fernandes et al.
showed how malicious apps can steal pincodes [26]. Cur-
rent IoT frameworks only offer access control but not
data-flow control primitives (§2). In contrast, our work
introduces, to the best of our knowledge, the first security
model targeted at controlling data flows in IoT apps.
Permission Models. We observe that IoT framework
permissions are modeled after smartphone permissions.
There has been a large research effort at analyzing, and
improving access control in smartphone frameworks [20,
49, 22, 24, 51, 50, 10, 16, 43, 68]. For instance, Enck et
al. introduced the idea that dangerous permission combi-
nations are indicative of possibly malicious activity [20].
Roesner et al.
introduced User-Driven Access control
where apps prompt for permissions only when they need
it [51, 50]. However, permissions are fundamentally only
gate-keepers. The PlaceRaider sensory malware abuses
granted permissions and uses smartphone sensors (e.g.,
camera) to reconstruct the 3D environment of the user for
reconnaissance [64]. This malware exploits the inability
of permission systems to control data usage once access
in granted. The IoT fundamentally has a lot more sensi-
tive data than a single smartphone camera, motivating the
need for a security model that is capable of strictly con-
trolling data use once apps obtain access. PiBox does
offer privacy guarantees using differential-privacy algo-
rithms after apps gain permissions, but it is primarily
applicable to apps that gather aggregate statistics [43].
In contrast, FlowFence controls data flows between arbi-
trary types of publishers and consumers.
Label-based Information Flow Control. FlowFence
builds on substantial prior work on information flow con-
trol that use labeling architectures [52, 42, 18, 71, 63,
28, 62, 41, 15, 38, 46]. For example, Flume [42] en-
forces flow control at the level of processes while re-
taining existing OS abstractions, Hails [28] presents a
web framework that uses MAC to confine untrusted web
apps, and COWL [63] introduces labeled compartments
for JavaScript code in web apps. Although FlowFence
is closely related to such systems, it also makes design
choices tailored to meet the needs specific to the IoT do-
main. In terms of similarities, FlowFence shares the de-
sign principles of making information flow explicit, con-
544  25th USENIX Security Symposium 
USENIX Association
trolling information flow at a higher granularity than the
instruction-level, and supporting declassification. How-
ever, these systems only support producer (source) de-
fined policies whereas FlowFence supports policies de-
fined by both producing and consuming apps. This fea-
ture allows for more versatility in environments such as
IoT, where a variety of consuming apps could request for
a diverse set of flows. Our evaluation shows hows such a
mix of flow policies supports real IoT apps (§5.2).
Computation on Opacified Data. Jana et al. built the
recognizer OS abstraction and Darkly [39, 40]—systems
that enable apps to compute on perceptual data while
protecting the user’s privacy. These systems also use
opaque handles, but they only support trusted functions
operating on the raw data that handles refer to. In con-
trast, FlowFence supports untrusted third-party functions
executing over raw data while providing flow control
guarantees. Furthermore, these systems leverage char-
acteristics of the data they are trying to protect to achieve
security guarantees. For example, Darkly depends on
camera streams being amenable to privacy transforms,
allowing it to substitute low-fidelity data for high-fidelity
data, and it depends on apps being able to tolerate the
differences. However, in the general case, neither IoT
data nor their apps may be amenable to such transforms.
FlowFence is explicitly designed to support computation
over sensitive IoT data in the general case.
Taint Tracking. Taint tracking systems [69, 19] are
popular techniques for enforcing flow control that mon-
itor data flows through programs [60]. Beyond perfor-
mance issues [48], such techniques suffer from an in-
ability to effectively handle implicit flows, and concur-
rency [59]. Although there are techniques to reduce com-
putational burden [54, 65], they often require specialized
hardware, not necessarily available in IoT environments.
These techniques are also difficult to apply to situations
where taint labels are not known a priori (e.g., man-
age tainted data that is generated by apps, rather than
known sources). Compared to these techniques, Flow-
Fence adds little performance overhead. Furthermore,
FlowFence does not require specialized hardware, and
does not suffer from implicit flow attacks.
Static Analysis. Another class of systems such as Flow-
Droid [9], and Amandroid [66] use static taint tracking
to enforce flow control. While these techniques do not
suffer from performance issues associated with dynamic
systems, they still suffer from same shortcomings asso-
ciated with concurrency and implicit flows [9]. Besides
static analysis techniques, there are also language-based
techniques, such as JFlow [45], that require the devel-
oper to learn and use a single security-typed language.
In contrast, FlowFence supports building apps using un-
modified existing languages and development tools, en-
abling developers to quickly port their apps.
8 Conclusions
Emerging IoT programming frameworks only support
permission based access control on sensitive data, mak-
ing it possible for malicious apps to abuse permissions
and leak data.
In this work, we introduce the Opaci-
fied Computation model, and its concrete instantiation,
FlowFence, which requires consumers of sensitive data
to explicitly declare intended data flows. It enforces the
declared flows and prevents all other flows, including
implicit flows, efficiently. To achieve this, FlowFence
requires developers to split their apps into: (1) A set
of communicating Quarantined Modules with the unit
of communication being opaque handles—taint tracked,
opaque references to data that can only be dereferenced
inside sandboxes; (2) Non-sensitive code that does not
compute on sensitive data, but it still orchestrates execu-
tion of Quarantined Modules that compute on sensitive
data. We ported three IoT apps to FlowFence, each re-
quiring less than 140 additional lines of code. Latency
and throughput measurements of crucial operations of
the ported apps indicate that FlowFence adds little over-
head. For instance, we observed a 4.9% latency increase
to recognize a face in a door controller app.
Acknowledgements
We thank the anonymous reviewers and our shepherd,
Deian Stefan, for their insightful feedback on our work.
We thank Kevin Borders, Kevin Eykholt, and Jaeyeon
Jung for providing feedback on earlier drafts. This re-
search is supported in part by NSF grant CNS-1318722
and by a generous gift from General Motors. Mauro
Conti is supported by a Marie Curie Fellowship funded
by the European Commission (agreement PCIG11-GA-
2012-321980). His work is also partially supported by
the EU TagItSmart! Project (agreement H2020-ICT30-
2015-688061), the EU-India REACH Project (agreement
ICI+/2014/342-896), the Italian MIUR-PRIN TENACE
Project (agreement 20103P34XC), and by the projects
“Tackling Mobile Malware with Innovative Machine
Learning Techniques,” “Physical-Layer Security for
Wireless Communication,” and “Content Centric Net-
working: Security and Privacy Issues” funded by the
University of Padua. Any opinions, findings, conclu-
sions, and recommendations expressed in this paper are
those of the authors and do not necessarily reflect the
views of the sponsors.
References
[1] Android auto. https://www.android.com/auto/. Accessed:
May 2016.
[2] Android wear. https://www.android.com/wear/. Accessed:
May 2016.
USENIX Association  
25th USENIX Security Symposium  545
[3] Logitech harmony hub. http://www.logitech.com/en-us/
product/harmony-hub. Accessed: May 2016.
[4] Samsung SmartThings Home Automation.
smartthings.com/. Accessed: Oct 2015.
http://www.
[5] Vera Smart Home Controller.
http://getvera.com/
controllers/vera3/. Accessed: Oct 2015.
[6] ALMUHIMEDI, H., SCHAUB, F., SADEH, N., ADJERID, I., AC-
QUISTI, A., GLUCK, J., CRANOR, L. F., AND AGARWAL, Y.
Your Location Has Been Shared 5,398 Times!: A Field Study on
Mobile App Privacy Nudging.
In ACM Conference on Human
Factors in Computing Systems (CHI) (2015).