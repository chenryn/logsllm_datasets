title:Denial of Service via Algorithmic Complexity Attacks
author:Scott A. Crosby and
Dan S. Wallach
USENIX Association
Proceedings of the
12th USENIX Security Symposium
Washington, D.C., USA
August 4–8, 2003
© 2003 by The USENIX Association
Phone: 1 510 528 8649
FAX: 1 510 548 5738
THE ADVANCED COMPUTING SYSTEMS ASSOCIATION
All Rights Reserved
Email: PI:EMAIL
For more information about the USENIX Association:
WWW: http://www.usenix.org
Rights to individual papers remain with the author or the author's employer.
 Permission is granted for noncommercial reproduction of the work for educational or research purposes.
This copyright notice must be included in the reproduced paper. USENIX acknowledges all trademarks herein.
Denial of Service via Algorithmic Complexity Attacks
Scott A. Crosby
PI:EMAIL
Dan S. Wallach
PI:EMAIL
Department of Computer Science, Rice University
Abstract
We present a new class of low-bandwidth denial of
service attacks that exploit algorithmic deﬁciencies
in many common applications’ data structures. Fre-
quently used data structures have “average-case”
expected running time that’s far more efﬁcient than
the worst case. For example, both binary trees and
hash tables can degenerate to linked lists with care-
fully chosen input. We show how an attacker can
effectively compute such input, and we demonstrate
attacks against the hash table implementations in
two versions of Perl, the Squid web proxy, and the
Bro intrusion detection system. Using bandwidth
less than a typical dialup modem, we can bring a
dedicated Bro server to its knees; after six min-
utes of carefully chosen packets, our Bro server was
dropping as much as 71% of its trafﬁc and consum-
ing all of its CPU. We show how modern universal
hashing techniques can yield performance compa-
rable to commonplace hash functions while being
provably secure against these attacks.
1 Introduction
When analyzing the running time of algorithms,
a common technique is to differentiate best-case,
common-case, and worst-cast performance. For ex-
ample, an unbalanced binary tree will be expected
to consume O(nlog n) time to insert n elements,
but if the elements happen to be sorted beforehand,
then the tree would degenerate to a linked list, and
it would take O(n2) time to insert all n elements.
Similarly, a hash table would be expected to con-
sume O(n) time to insert n elements. However, if
each element hashes to the same bucket, the hash
table will also degenerate to a linked list, and it will
take O(n2) time to insert n elements.
While balanced tree algorithms, such as red-black
trees [11], AVL trees [1], and treaps [17] can avoid
predictable input which causes worst-case behav-
ior, and universal hash functions [5] can be used
to make hash functions that are not predictable by
an attacker, many common applications use simpler
algorithms. If an attacker can control and predict
the inputs being used by these algorithms, then the
attacker may be able to induce the worst-case exe-
cution time, effectively causing a denial-of-service
(DoS) attack.
Such algorithmic DoS attacks have much in com-
mon with other low-bandwidth DoS attacks, such as
stack smashing [2] or the ping-of-death 1, wherein a
relatively short message causes an Internet server to
crash or misbehave. While a variety of techniques
can be used to address these DoS attacks, com-
mon industrial practice still allows bugs like these
to appear in commercial products. However, unlike
stack smashing, attacks that target poorly chosen al-
gorithms can function even against code written in
safe languages. One early example was discovered
by Garﬁnkel [10], who described nested HTML
tables that induced the browser to perform super-
linear work to derive the table’s on-screen layout.
More recently, Stubbleﬁeld and Dean [8] described
attacks against SSL servers, where a malicious
web client can coerce a web server into perform-
ing expensive RSA decryption operations. They
1http://www.insecure.org/sploits/
ping-o-death.html has a nice summary.
USENIX Association
12th USENIX Security Symposium 
29
Bucket
0
1
2
3
4
5
Bucket
0
1
2
3
4
5
Figure 1: Normal operation of a hash table.
Figure 2: Worst-case hash table collisions.
suggested the use of crypto puzzles [9] to force
clients to perform more work before the server does
its work. Provably requiring the client to con-
sume CPU time may make sense for fundamen-
tally expensive operations like RSA decryption, but
it seems out of place when the expensive opera-
tion (e.g., HTML table layout) is only expensive
because a poor algorithm was used in the system.
Another recent paper [16] is a toolkit that allows
programmers to inject sensors and actuators into a
program. When a resource abuse is detected an ap-
propriate action is taken.
This paper focuses on DoS attacks that may be
mounted from across a network, targeting servers
with the data that they might observe and store in
a hash table as part of their normal operation. Sec-
tion 2 details how hash tables work and how they
can be vulnerable to malicious attacks. Section 3
describes vulnerabilities in the Squid web cache,
the DJB DNS server, and Perl’s built-in hash ta-
bles. Section 4 describes vulnerabilities in the Bro
intrusion detection system. Section 5 presents some
possible solutions to our attack. Finally, Section 6
gives our conclusions and discusses future work.
2 Attacking hash tables
Hash tables are widely used throughout computer
systems. They are used internally in compilers to
track symbol tables. They are used internally in op-
erating systems for everything from IP fragment re-
assembly to ﬁlesystem directory lookup. Hash ta-
bles are so common that programming languages
like Perl provide syntactic sugar to represent hash
tables as “associative arrays,” making them easy for
programmers to use. Programmers clearly prefer
hash tables for their constant-time expected behav-
ior, despite their worst-case O(n) per-operation run-
ning time. After all, what are the odds that a hash
table will degenerate to its worst case behavior?
In typical usage, objects to be inserted into a
hashtable are ﬁrst reduced to a 32-bit hash value.
Strings might be hashed using a checksum oper-
ator like CRC32 or MD5, but are usually hashed
by much simpler algorithms. More complex ob-
jects might have custom-written hash-value oper-
ators. The hash table then takes this hash value,
modulo the bucket count, the size of the array of
pointers to data being stored in the hash table, de-
termining the bucket that will hold the reference to
the object being inserted. When two inputs map
the the same bucket, a collision has occurred. To
deal with this case, each hash bucket holds a linked
list of all inserted objects whose hash value, mod-
ulo the bucket count, maps to that particular bucket
(see Figure 1). These linked lists are referred to
as hash chains. When the total number of objects
in the hash table grows too large, resulting in long
average chain length, the size of the array of hash
buckets is typically increased, perhaps multiplied
by a constant factor, and the entries in the table are
reinserted, taking their hash values modulo the new
bucket count.
There are other methods of implementing hash ta-
bles, including open addressing, where collisions
are not resolved using hash chains.
Instead, the
30
12th USENIX Security Symposium 
USENIX Association
system follows a deterministic strategy to probe for
an empty hash bucket, where the object is then in-
serted. Although this paper focuses on hash chain-
ing, the attacks described here will be at least as
effective on open addressing hash tables.
tack. We describe such limits in Section 2.2.
2.1 Constructing a speciﬁc attack
(cid:1)
1
b
(cid:2)n−1 for b buckets and n ob-
The worse case (see Figure 2) can occur for two rea-
sons: either the 32-bit hash values are identical, or
the hash values modulo the bucket count becomes
identical. Of course, for randomly chosen input, the
odds of every object hashing to the same bucket is
vanishingly small —
jects. For maliciously chosen input, however, it be-
comes entirely feasible. If the hash table is check-
ing for duplicates when a new object is inserted,
perhaps to guarantee that it acts as a mapping from
object keys to values, then it will need to scan ev-
ery entry in the hash bucket. This will induce the
worst-case O(n) behavior for each insert.
The ﬁrst step in analyzing a program’s vulnerabil-
ities to this attack is to determine where hash ta-
bles are being used and identifying whether exter-
nal, untrusted input can be fed directly into the ta-
ble. This can be time consuming. As an example,
the Bind DNS server places some four different ab-
straction layers between the network and the ulti-
mate hash table storing DNS bindings. Tracing this
can be tedious work for an attacker unfamiliar with
the source code.
2.1.1 Hash collision versus bucket collision
There are only a few requirements in order to en-
gage in such an attack. First, the hash function be-
ing used must be deterministic and known to the at-
tacker. Second, the attacker needs the ability to pre-
dict or supply all of the input being used by the hash
function. Third, the attacker needs to ensure that a
sufﬁcient volume of attack input gets to the victim
such that they experience a performance degrada-
tion.
An attacker may not know the bucket count ex-
actly; many implementations change the bucket
count based on the number of objects stored in the
hash table. However, given the application’s source
code, an attacker may be able to guess possible val-
ues for the bucket count. This leads to two avenues
of attack:
those where you don’t care about the
bucket count and those where you know or guess
the bucket count.
The attacker must understand how raw data, ini-
tially read by the application from the network,
is processed before it is inserted into the hash ta-
ble. Knowing this, the attacker must compute ob-
jects that will eventually collide, either in the 32-bit
hash-value space, or only in the eventual hash buck-
ets. Section 2.1 will describe how these collisions
can be efﬁciently computed for some hash func-
tions. At worst, computing hash collisions requires
an attacker to exhaustively search within the space
of possible inputs. While expensive, the attacker
can do this work ahead of time. Ultimately, the
question is whether the victim will accept enough
attack-input for the O(n2) worst-case behavior to
manifest itself. Furthermore, some victims may en-
force various limits on the growth of their hash ta-
bles, making them robust against this class of at-
If collisions can be computed in the full 32-bit hash-
value space, then the bucket count is irrelevant;
the hash table will exhibit worst-case behavior re-
gardless of how many buckets it has. More for-
mally, we wish to derive inputs k1, k2, . . . ki such that
Hash(k1) = Hash(k2) = . . . = Hash(ki). We refer
to these as hash collisions. If the inputs have dif-
ferent hash values, but still collide into the same
bucket (e.g., after a modulo operation has taken
place), we refer to these as bucket collisions. For-
mally, a bucket collision is when we derive inputs
k1,k2, . . . ki such that f (k1) = f (k2) = . . . = f (ki)
where f is the the function mapping from inputs to
buckets. In many cases, f (k) = Hash(k) (mod n) ,
with n being the number of buckets.
While hash collisions would seem straightforward,
they do not always result in a feasible attack. For
USENIX Association
12th USENIX Security Symposium 
31
example, consider an attacker who wishes to at-
tack an intrusion detection system (IDS) scanning
TCP/IP SYN packets to detect SYN ﬂooding ac-
tivity.
If the IDS is remembering packets based
purely on the source and destination IP addresses
and port numbers, this would give the attacker a
96-bit search space. However, the destination ad-
dress must be close enough to the IDS for the IDS
to observe the trafﬁc. Likewise, the attacker’s ser-
vice provider may do egress ﬁltering that prevents
forged source IP addresses. This could reduce the
attacker to as little as 48-bits of freedom in selecting
packets. If the hash function reduces these packets
to 32-bit hash values, then there will be, on aver-
age, 216 packets that an attacker can possibly send
which will collide in the 32-bit hash-value space.
216 values stored in the same hash bucket may or
may not be enough to noticeably degrade the IDS’s
performance.
Conversely, suppose the attacker wishes to com-
pute bucket collisions rather than hash collisions.
Because the bucket count is much smaller than the
size of the hash-value space, it will be easier to ﬁnd
bucket collisions. Thus, if the attacker can predict
the precise bucket count, then many more possible
collisions can be computed. This ﬂexiblity may al-
low effective attacks on applications hashing inputs
as short as 32-bits. However, if there are several
possible bucket counts, then the attacker has sev-
eral options:
• Guess the bucket count.
• Compute collisions that work for several dif-
ferent bucket counts.
• Send several streams of attack data, where
each stream is designed to collide for one par-
ticular bucket count.
Computing collisions that work for multiple bucket
counts is not practical; the search space grows pro-
portionally to the least common multiple of the can-
didate bucket counts. This can easily exceed the
32-bit space of hash values, making hash collisions
more attractive to compute than bucket collisions.
(cid:1)
c
(cid:2)(cid:2)
1− 1
However, if the number of candidate bucket counts
(c) is small enough, then the attacker can com-
pute separate attack streams focused on each po-
tential bucket count.
If the attacker sends n ob-
(cid:1)
jects of attack data, then most of the attack data
will be distributed throughout the hash
n
table, with an expected O(1) insert per object. The
(cid:3)(cid:1)
remaining n
(cid:2)
c objects, however, will cause an ex-
n
total running time. Furthermore,
pected O
c
if the hash table happens to be resized and one of
the attack streams corresponds to the new bucket
count, then the resulting hash table will still exhibit
quadratic performance problems.
(cid:4)
2
For simplicity, the remainder of this paper focuses
on computing hash collisions. Later, when we de-
scribe attacks against an actual IDS (see Section 4),
we will show that 216 collisions in one bucket are
more than sufﬁcient to mount an effective attack.
2.1.2 Efﬁciently deriving hash collisions
The hash functions used by typical programs for
their hash tables are generally not cryptographically
strong functions like MD5 or SHA-1. Instead, they
tend to be functions with 32 bits of internal state,
designed primarily for speed. Because this state is
limited, we need only ﬁnd inputs such that the in-
ternal state after hashing is the same as the initial
state.
Consider a hash function with the initial state of
0.
Imagine we can ﬁnd generators, or inputs
k1,k2, . . . ki such that 0 = Hash(k1) = Hash(k2) =
. . . = Hash(ki). Then the concatenation of any num-
ber of these generators in any combination and any
order also hashes to 0. So, k1k2 also hashes to 0,
as will k1k1 or k2k1k3k2. Thus, by ﬁnding three in-
puts k1, k2, k3 via exhaustive search and concatenat-
ing them combinatorially, we can generate a large
number of collisions without requiring any addi-
tional searching. The number of possible collisions
is bounded only by the maximum length to which
we are willing to allow concatenated generators to
grow. This process can be generalized by ﬁnding
32
12th USENIX Security Symposium 
USENIX Association
a set of generators closed over a small number of
hash states (i.e., searching for generators that take
hash states less than a small integer to other hash
states less than the same small integer).
In simple tests, attacking the Perl 5.6.1 hash func-
tions on a 450MHz Pentium-2 processor, 30 min-
utes of CPU time enumerating and hashing all 8
character alphabetic strings was sufﬁcient to ﬁnd
46 generators that hash to zero. By concatenating
three of them combinatorially, we derive 463 (97k)
alphabetic inputs, 24 characters long, that will all
hash to the same 32-bit hash value.
Hash collisions can be efﬁciently computed for a