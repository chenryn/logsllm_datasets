dition between read and write operations, making a pipelined hard-
ware implementation extremely simple. Note that in traditional
data processing, a datum has to be locked after read and unlocked
after write to ensure consistency. Second, blind streaming also dou-
bles the streaming speed by eliminating the reading process. Third,
the loss of accuracy due to this blindness is tolerable, as we will
show in Section 5.
3. DESIGN DETAILS
3.1 Space-Code Bloom Filter
The core of our scheme is a novel data structure called Space-
Code Bloom Filter (SCBF). It approximately represents a multiset,
extending the capability of a traditional Bloom Filter (BF) to rep-
resent a set. Given an element x, it not only allows one to check if
x is in a multiset, but also counts the number of occurrences of x.
In the following, we describe the design of both BF and SCBF.
A traditional bloom ﬁlter representing a set S = {x1, x2, .., xn}
of size n is described by an array A of m bits, initialized to 0. A
Bloom ﬁlter uses k independent hash functions h1, h2, ..., hk with
1. Insertion phase (given x):
2.
3.
i = rand(1, l);
Set bits A[hi
1(x)], ..., A[hi
k(x)] to 1;
ˆθ = 0;
for(i = 1; i ≤ l; i + +)
4. Query phase (given y):
5.
6.
7.
8.
9.
return MLE(ˆθ);
ˆθ = ˆθ + 1;
if (bits A[hi
1(x)], ..., A[hi
k(x)] are all 1)
Figure 2: Insertion and Query in SCBF
range {1, ..., m}. We refer to this set of hash functions as a group.
In the insertion phase, given an element x to be inserted into a set
S, we set the bits A[hi(x)], 1 ≤ i ≤ k, to 1. In the query phase,
to check if an element y is in S, we check the value of the bits
A[hi(y)], i = 1, 2, ..., k. The answer to the query is yes if all these
bits are 1, and no otherwise.
A bloom ﬁlter guarantees not to have any false negatives, i.e.,
returning “no” while the set contains the element. However, it may
contain false positives, i.e., returning “yes” while the element is not
in the set. There is a convenient tradeoff between the false positive
and the number of elements the ﬁlter tries to hold. It was shown
in [5] that ﬁxing a false positive threshold γ, the ﬁlter can hold the
highest number of elements n when the parameter k is set to around
(− log2 γ). In this case the completely full ﬁlter contains exactly
half 1’s and half 0’s. We refer to this as the “50% golden rule”.
1(x), h2
2(x), ..., h2
k(x)] are set to 1.
1(x), hi
1(x)], A[hi
2(x), ..., h1
2(x), ..., hl
2(x), ..., hi
2(x)], ..., A[hi
The insertion and query algorithms of SCBF are shown in Fig-
ure 2. In a traditional bloom ﬁlter, once an element x is inserted,
later insertions of x will write to the same bits A[h1(x)], A[h2(x)],
··· , A[hk(x)], and will not result in any change to A. SCBF, on
the other hand, uses a ﬁlter made up of l groups of hash func-
k(x)}, ··· ,
k(x)}, {h2
tions {h1
1(x), h1
and {hl
k(x)}. Each group can be viewed as a
1(x), hl
traditional bloom ﬁlter. In the insertion phase, one group of hash
k(x)} is chosen randomly, and the
functions {hi
bits A[hi
In the query
phase, to ﬁnd out the number of occurrences of element y in the
set, we count the number of groups that y has matched. An element
y matches a group {hi
2(y)],
··· , A[hi
k(y)] are all 1. Based on the number of groups that y has
matched, denoted as ˆθ, we use a maximum likelihood estimation
(MLE) procedure to estimate its multiplicity in the SCBF, return-
ing M LE(ˆθ). We can precompute an MLE table for all possible
values of ˆθ so that later decoding involves only a straightforward
lookup. However, the theory behind the computation of the MLE
table is involved and will be discussed in Section 4. We refer to
the scheme as Space-Code Bloom Filter because each group can
be viewed as a code for an element, and in SCBF, multiple groups
spread codes of an element to a larger space.
k} if the bits A[hi
1(y)], A[hi
1, hi
2, ..., hi
3.2 Multi-Resolution Space-Code Bloom Fil-
ter
In the Internet, the potential size of a ﬂow can be very high. By
the famous coupon collector problem, all l groups in a SCBF will
be matched at least once after about (l ln l) copies of x are inserted.
Accurate estimation of the number of occurrences of x will not be
possible beyond this threshold. Making l very large does not solve
this problem for two reasons. First, the number of false positives
(noise) become large with larger l, and if the multiplicity of an ele-
ment y (signal) is small, the noise will overwhelm the signal. Sec-
for(j = 1; j ≤ r; j + +)
1. Insertion phase (given x):
2.
3.
4.
Insert x into SCBF j with probability pj
/*shown in Figure 2.*/
Check y(cid:2)s occurrences in SCBF 1, 2, ..., r
5. Query phase (given y):
6.
7.
8.
return M LE(ˆθ1, ˆθ2, ..., ˆθr);
and obtain counts ˆθ1, ˆθ2, ..., ˆθr respectively;
Figure 3: Insertion and Query Algorithms in MRSCBF
Resolution 2
Resolution 4
0
Resolution 1
Resolution 3
Resolution 5
Multiplicity
Legend
 Range of coverage
Range of accurate coverage
Figure 4: The conceptual design of MRSCBF
ond, the storage efﬁciency of the scheme becomes low as multiple
occurrences of an element are spread to a very large space.
Our solution to this problem is Multi-Resolution SCBF (MRSCBF).
It employs multiple SCBFs, operating at different resolutions. Its
insertion and query algorithms are shown in Figure 3. The inser-
tion algorithm for MRSCBF is a simple extension of that of SCBF.
When a packet arrives, it will result in an insertion into SCBF i
with a sampling probability pi. Suppose there are a total of r ﬁl-
ters. Without loss of generality, we assume p1 > p2 > ... > pr.
The higher pi value corresponds to higher resolution. Our goal is
that elements with low multiplicities will be estimated by ﬁlter(s)
of higher resolutions, while elements with high multiplicities will
be estimated by ﬁlters of lower resolutions. In the query algorithm,
we count the number of groups that x matches in ﬁlters 1, 2, ..., r,
denoted as ˆθ1, ˆθ2, ..., ˆθr respectively. The ﬁnal estimate will be
M LE(ˆθ1, ˆθ2, ..., ˆθr), the result of a joint MLE procedure based on
the observations. Like in SCBF, the decoding table for this MLE
procedure again will be precomputed. However, without any ap-
proximation, its precomputation would take years. We developed
techniques,discussed in section 4.2, to reduce this complexity to
acceptable ranges without sacriﬁcing accuracy.
Tuning the sampling probabilities p1, p2, ..., pr, and the num-
ber of groups l is closely related to the level of estimation accu-
racy we would like to achieve. To achieve the constant relative
error tolerance (discussed in Section 2.1), the probabilities are set
as pi = ci−1, i = 1, 2, ..., r, i.e., a geometric progression. Here
c < 1 is a constant, which is a function of the number of groups
l. The philosophy behind setting parameters this way is captured
in Figure 4. Each group covers a certain multiplicity range and in
part of this range, it has accurate coverage. When the parameters
(cid:2)
is are set as above, the accurate coverage ranges of these groups
p
“touch” each other on the borders and jointly cover the whole mul-
tiplicity range. In an operating MRSCBF we use throughout the
rest of the paper, we set l = 32 and c = 1
4 .
This multi-resolution design works very well for Internet trafﬁc,
in which the majority of the ﬂows are mice but a small number of
large ﬂows (elephants) account for the majority of the packets (the
aforementioned “quasi-Zipf” law). Our design ensures that each
ﬂow will have a resolution that measures its count with reasonable
accuracy. Its storage efﬁciency is reasonable since the small ﬂows
will not occupy too many bits and the bits occupied by large ﬂows
will grow only logarithmically with their size. However, MRSCBF
pays a little price on storage efﬁciency for blind streaming, which
is that the high multiplicity elements will completely ﬁll up all the
high resolution ﬁlters so that these ﬁlters do not carry much infor-
mation1. Nevertheless, this price is moderate because the fraction
of large ﬂows is very small in the Internet trafﬁc.
3.3 Performance Guarantees
r
computational complexity of the scheme is clearly 
In this section, we evaluate the performance of a MRSCBF con-
ﬁgured with aforementioned parameters, according to the three per-
formance metrics discussed in Section 2.1, namely, computational
complexity, storage complexity, and accuracy. Let ki be the num-
ber2 of hash functions used in a group belonging to ﬁlter i. The
i=0 ki ∗ pi
bits per packet. When pi follows geometric progression as above,
this value tends to be small. In our MRSCBF scheme, we set k1 to
4, and k2,..., kr to 6. With other parameters shown above (l = 32,
c = 1
4 ), the total complexity is no more than 6 bits per packet.
This would allow us to comfortably support OC-192+ speed using
10ns SRAM. The storage complexity is to a certain extent trafﬁc-
dependent. Experimental results show that we achieve high storage
efﬁciency on backbone trafﬁc. For example, on one Tier-1 ISP
backbone trace, we found that the storage efﬁciency is about 2 bits
per packet with an array of size 1MB. In other words it takes about
2 million packets to ﬁll up half of the bits (according to the “50%
golden rule”) in an array of size 1MB. As to accuracy, our estimates
are on the average within 15% of the actual value for ﬂows of all
sizes according to mathematics analysis shown in Section 4.
4. MAXIMUM LIKELIHOOD ESTIMATION
AND ANALYSIS
In this section, we study the mathematics behind the MLE proce-
dure and its accuracy. We also discuss the impact of various design
parameters on the complexity-accuracy tradeoff.
4.1 MLE with observations from one SCBF in
MRSCBF
f
We ﬁrst describe the MLE procedure for one SCBF in a MRSCBF.
Let Θ be the set of groups that are matched by an element x in
SCBF i. We know from the design of MRSCBF that elements are
inserted into SCBF i with sampling probability pi. To ﬁnd out
the number of occurrences of x from the observation Θ, we use
the principle of MLE, i.e., we would like to ﬁnd f that maximizes
P r(F = f|Θ). In other words, ˆF = argmax
P r(F = f|Θ).
However, to compute P r(F = f|Θ), we need to prescribe an a
priori distribution for F . We found that, when F is assumed to
P r(F = f|Θ) =
have a uniform a priori distribution, argmax
P r(Θ|F = f ). In this case, MLE using P r(F = f|Θ)
argmax
produces the same value as MLE using P r(Θ|F = f )! This sig-
1Note that ﬂows with distinct labels hash to different location in
the ﬁlter array. Though a high multiplicity element ﬁlls up the high
resolution ﬁlter for itself, it does not have any impact at all on the
accuracy of the same ﬁlter for other elements.
2Group sizes can be different from one SCBF to another in
MRSCBF.
f
f
f
f
argmax
Now we explain why
niﬁcantly simpliﬁes the MLE process since P r(Θ|F = f ) has a
closed form solution (albeit sophisticated).
P r(F = f | Θ ) =
P r(Θ|F = f ), when F has a uniform a priori distri-
P r(Θ|F =f )∗P r(F =f )
argmax
bution. By Bayes’ rule, P r(F = f|Θ) =
.
Since the value P r(Θ) on the denominator is a constant, the f
that maximizes P r(F = f|Θ) has to maximize P r(Θ|F = f ) ∗
P r(F = f ), the numerator. When F has uniform a priori distri-
bution, P r[F = f ] becomes a constant with respect to f and the
result follows.
P r(Θ)
How to prescribe the default a priori distribution (the belief be-
fore any observation) has always been a controversial issue in statis-
tics [10]. It is however a widely acceptable practice to use uniform
as the default when there are no obviously better choices. Assum-
ing uniform as the default is reasonable also for the following rea-
son.
It can be shown quantitatively that the evidence Θ in gen-
eral signiﬁcantly outweighs the skew caused by any a priori dis-
tribution that is slowly varying. A distribution is slowly varying if
|P r[F = f ]−P r[F = f +1]| ≤  when  is a very small constant.
Clearly there is no reason to believe that the a priori distribution of
F is not slowly varying.
Now that maximizing P r(F = f|Θ) is the same as maximizing
P r(Θ|F = f ), we can use the following theorem that character-
izes how to compute P r(Θ|F = f ). Its proof is involved, and
omitted here due to space limitations.
THEOREM 1. Let θ = |Θ| and α be the percentage of “1” in
q
f
l−θ
(f−q)
the MRSCBF. Then P r[Θ|F = f ] is equal to
Xq=0 f
q!p
(cid:16)1 − α
(1 − p)