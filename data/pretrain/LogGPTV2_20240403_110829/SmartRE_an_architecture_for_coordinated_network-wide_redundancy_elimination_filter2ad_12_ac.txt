P
P
The objective then is to maximize
r Sp,r. Note that max-
imizing this objective, subject to the constraints captured by Equa-
tions 1–3 is a linear programming (LP) formulation and thus can be
solved efﬁciently using off-the-shelf LP solvers (we use CPLEX).
p,r}, the optimal solution to
The output of the LP solver is d∗ = {d∗
the formulation.
p
We can augment this framework to incorporate resource con-
straints on ingress nodes as well. We omit this extended formu-
lation for brevity, but use it in our evaluation.
4.3 Encoding and Decoding
In the next few sections, we provide details on the actions taken
by nodes in the network given the allocations derived by the central
conﬁguration module.
Assigning caching responsibilities: The output of the optimiza-
tion framework is a set of caching manifests which specify the
caching responsibilities for each node. Each node’s manifest is
a set of key-value pairs {(cid:6)p, HashRange(cid:7)}, indexed by the path
identiﬁer p. We use a simple procedure takes in the solution d∗
as
input and iterates over the paths one by one. For each p, a vari-
able Range (initially zero) is advanced in each iteration per node,
in order of location on the path, by the value d∗
p,r, and node r is
assigned the hash range [Range, Range + d∗
p,r). Thus, nodes on
the path p are assigned non-overlapping hash ranges to ensure that
the caching responsibilities for nodes on the path are disjoint. We
use the on-path ordering to simplify the encoding algorithm (see
the discussion in §5.1).
For example, suppose there are three nodes r1 , r2 , and r3 on
path p (in order of distance from the ingress), and the optimal so-
lution has values d∗
p,r3 = 0.1.
The ranges assigned to r1 , r2 , and r3 for path p will be [0, 0.2),
[0.2, 0.5), and [0.5, 0.6).
p,r2 = 0.3, and d∗
p,r1 = 0.2, d∗
For each path p, an interior node r only stores packets whose
hashes falls within the range assigned to it for p. To do this, the inte-
rior node computes a hash over the packet header HASH(pkt.header )
and decides whether or not to cache the packet. HASH is computed
over the ﬁelds of the packet header that uniquely identify a packet,
the src/dst IPs, src/dst ports, protocol, and the IP ID ﬁeld, and re-
turns a value in the range [0, 1]. These are invariant ﬁelds that do
not change along the routing path [17].
Encoding at the ingresses: We ﬁrst present a high-level overview
of the encoding algorithm at each ingress. We defer to more de-
tailed issues in §5.
Figure 4 shows the pseudocode for an ingress node. The ingress
encodes packets with respect to packets in its store. When matches
are found, it computes a shim header (Figure 5). The shim header
has 2 parts: a ﬁxed length path identiﬁer ﬁeld specifying the path
identiﬁer for the current packet3, and a (possibly variable length)
description of the matches. Each match is speciﬁed using three
ﬁelds: (i) the path identiﬁer for the packet in the ingress’s cache
with which a match was found, (ii) the unique hash for the match-
ing packet computed over the invariant header ﬁelds, and (iii) the
matched byte region.
The ingress stores packets whose hashes fall in the total covered
range for the path. It ignores other packets as matches with these
cannot be decoded downstream. When the ingress cache is full, it
evicts packets in FIFO order.
3If interior nodes can get the pathid from MPLS labels or routing
information, this is not necessary.
91PROCESSPACKETINGRESS(pkt, ingress)
PROCESSPACKETINTERIOR(encodedpkt , r)
// Steps 1–4 are for encoding
// Use routing/MPLS info for the next two steps
1 egress ← FINDEGRESS(pkt )
2 pathid ← GETPATHID(ingress , egress )
3 candidates ← GETCANDIDATES(pathid )
4 encodedpkt ← ENCODE(pkt , candidates )
// encodedpkt carries the shim header (Figure 5)
// this step depends on the overlapmatrix (see §5)
// Steps 5–7 are for caching
// what is
P
r∈PATH(pathid ) dpathid,r for this path?
5 coveredrange ← GETCOVEREDRANGE(pathid )
6 h ← HASH(pkt.header )
7 if (h ∈ coveredrange ) then
// only store packets with hash within covered range
ADDPKTTOSTORE(pkt , pathid , h)
// forward as usual
8 FORWARD(encodedpkt )
Figure 4: Pseudocode for ingress node.
Pathid of 
Matched Packet
Hash of matched 
packet’s header
Matched region 
Pathid
MatchSpec 1 MatchSpec 2
...
MatchSpec n
IP Header 
Transport
Header
SmartRE Shim
Header
Packet
Payload
// r is the node id
// Steps 1–2 are for decoding
// Check if any decoding needs to be done
// Steps 3–6 are for caching
// this may only partially reconstruct the packet
1 mymatches ← PROCESSSHIM(encodedpkt.shim )
2 decodedpkt ← DECODE(encodedpkt , mymatches)
3 pathid ← GETPATHID(encodedpkt )
4 myrange ← GETRANGE(pathid , r)
5 h ← HASH(pkt.header )
6 if (h ∈ myrange) then
// what is my assigned hash range for this path?
ADDPKTTOSTORE(decodedpkt , pathid , h)
// forward as usual
7 FORWARD(decodedpkt )
Figure 6: Pseudocode for an interior node.
OverlapMatrix [P_i,P_j] = range for packets
 on path P_i that can be chosen to encode 
packets on path P_j
P1
E1
P1,R1 [0,0.2]
P1,R2 [0.2,0.5]
I
R1
R2
R3
P1,R3 [0.5,0.7]
P2,R1 [0,0.1]
P2,R2 [0.1,0.4]
P2,R4 [0.4,1.0]
R4
P2
OverlapMatrix[P1,P2] = [0,0.4]; 
R1,R2 (common to P1,P2) store pkts in this range on P2
OverlapMatrix[P2,P1] = [0,0.5]; 
R1,R2 store pkts in this range on P1
E2
Figure 5: Format of the SmartRE shim header.
Figure 7: Example showing the overlap matrix.
Decoding at interior nodes: Figure 6 shows the algorithm at an
interior node. The node reads the shim header and checks if any of
the matches are in packets that it is currently caching. Each match-
spec carries the pathid and the hash of the reference packet with
which a match was found. Thus, the interior node can determine
if it has cached the reference packet.4 If so, the node reconstructs
the corresponding match region(s). Note that different matched re-
gions may be reconstructed by different downstream nodes as the
packet traverses the path.
5. ENSURING CORRECTNESS IN SmartRE
As we saw in the previous section, there are three key features
in SmartRE: (1) it allows a packet to be decoded multiple hops
downstream from the ingress where it was encoded, (2) it splits
caching (and decoding) responsibilities along the RE elements on a
path, and (3) it uses a network-wide approach for allocating caching
responsibilities.
These three features are essential for efﬁciently utilizing the avail-
able RE resources (e.g., caches, memory accesses) to derive close
to optimal network-wide beneﬁts. For example, (1) means that each
decoding operation performed by an interior router H hops down-
stream is H times as effective in reducing the network-wide foot-
print as the same operation performed by the router adjacent to the
ingress. Similarly, (2) means that each cache entry is utilized efﬁ-
ciently. (3) combines these features to achieve network-wide goals;
this could mean that RE elements common to paths that share re-
dundant content are assigned inter-path decoding responsibilities.
4Errors due to hash collisions are highly unlikely.
However, these features raise some issues with respect to correct-
ness; i.e., will an encoded packet be decoded correctly before it
leaves the network perimeter. Speciﬁcally, we identify three issues:
1. How can an ingress decide if encoding a packet w.r.t a pre-
vious packet will be valid–will that previous packet be avail-
able in a cache on the path taken by the current packet? (§5.1)
2. Since interior elements may be assigned responsibilities across
multiple ingresses, how does each encoder maintain a con-
sistent view of the caches at interior elements? That is, if an
ingress encodes a packet, will the decoders have the required
matched packets or would they have evicted them? (§5.2)
3. As decoding responsibilities are split across a path, some
packets may be encoded when they reach their assigned caching
nodes. Should we cache such encoded packets? (§5.3)
We present lightweight solutions to address these issues in the
context of SmartRE. However, the issues themselves are more gen-
eral to the design of network-wide RE solutions.
5.1 Identifying valid inter-path encodings
If the ingress identiﬁes a match with a packet that traversed the
same path it can encode the match. However, when the ingress sees
a match with a packet from another path, it needs to ensure that
this can be successfully decoded downstream. The overlapmatrix
speciﬁes valid inter-path encodings, and in Figure 4, the function
GETCANDIDATES checks overlapmatrix to ﬁnd valid encodings.
Figure 7 shows a simple example of what the overlap matrix
means. We have two paths P1 and P2. The caching responsibil-
ities of each node are speciﬁed in terms of hash-ranges per path.
Suppose a new packet A belonging to P1 arrives at I. I ﬁnds a
92match with packet B sent earlier along P2. Now, I has to de-
cide whether A if encoded w.r.t B can be decoded downstream.
If HASH(B) ≤ overlapmatrix [P1 , P2 ], one of R1 or R2 will be
able to decode the match. Otherwise, B is stored on nodes that do
not lie on P1 and thus A cannot be encoded with respect to B.
Let us go back to the discussion of on-path ordering (§4.3). The
conﬁguration module generates the overlapmatrix from the LP
solution and distributes it to the ingresses. On-path ordering en-
sures that each entry in this matrix is one contiguous range instead
of several disjoint ranges. This simpliﬁes the description of the
overlapmatrix and also simpliﬁes the process by which the in-
gresses identify valid encodings.
5.2 Using cache buckets to ensure consistency
In hop-by-hop RE, each node’s packet store is perfectly in sync
with the upstream node’s packet store. However, SmartRE needs to
explicitly ensure that ingress and interior caches are consistent.
To see why this is necessary, consider the following scenario.
Packet X is initially cached at interior node R and the ingress
I. Consider the case when R and I maintain independent FIFO
caches. Suppose X is evicted from R’s cache due to a sudden in-
crease in trafﬁc along paths from other ingresses. Now, packet Y
arrives at I. I ﬁnds a match with X and encodes X with respect
to Y . Clearly, R will not be able to reconstruct the matched region
for Y . The packet Y would thus have to be dropped downstream
or rejected by the application at the end-host.
To address this, we use a lightweight, yet robust, consistency
mechanism. The main idea is to divide the ingress packet store
into buckets; each bucket corresponds to a hash range assigned to a
speciﬁc interior node-path pair. Interior stores are organized simi-
larly. As a packet arrives at the ingress, it is stored into the per-path
per-range bucket into which its hash falls. This explains the pa-
rameters pathid and h to ADDPKTTOSTORE in Figures 4 and 6
– together they identify the bucket in which to store the packet.
Each bucket is a circular buffer; as a bucket gets full, packets get
evicted in FIFO order to accommodate newer packets. The size of
each bucket is determined by the LP solution and the trafﬁc patterns
p,r × vp); the conﬁguration module also speciﬁes these sizes
(i.e., d∗
as part of the caching manifests. When new solutions are computed
in response to trafﬁc or routing dynamics, the bucket sizes can be
reassigned appropriately.
5.3 Handling gaps in encoded packets
An interior node may not have the full payload for packets for
which it is assigned caching responsibilities. This could happen if
at the time the packet reaches this node, there is still some decoding
to be done downstream. Thus, the node only sees a partially recon-
structed packet. This creates a problem if subsequent packets need
to be encoded with respect to a packet with some decoding “gaps”.
To see why this is an issue, consider the example in Figure 8. In the
example, even though the ingress can encode C with respect to its
cached version of B, R1 which is storing an incomplete version of
B cannot decode this match.
One option is that the ingress does not use encoded packets for
future encodings. Thus, packet B which was encoded with respect
to A is not even stored at I. Another option is to use these encoded
packets maximally, i.e., all non-gap regions in the packet are used
to match further packets. Thus, router I in the example stores B
but nulliﬁes the bytes in B that matched A. Future packets can only
be encoded with respect to non-null regions of B. Both solutions
ensure correct end-to-end packet delivery, but provide lower redun-
dancy elimination than the ideal case when there are no decoding
gaps. Since the second solution achieves better redundancy elim-
A arrives, 
cached at I, R2
B arrives
partial match with A
Encoded w.r.t A
Cached at I, R1
C arrives, 
partial match with A,B
Cannot encode w.r.t B!
I 
R1 
R2 
A
A
B
R1 stores 
B-with-gap
A is evicted
A is evicted
B
C
D arrives
matches non-gaps in B
Can encode w.r.t B
Figure 8: Example of how decoding gaps may occur.
D
B
In our experiments with real
ination, we implement this option.
packet traces, we found that with the second option, the effective
loss in redundancy elimination is less than 3%.
IMPLEMENTATION ISSUES
6.
6.1 Encoder and Decoder Implementation
We implement the encoding and decoding algorithms from §4.3
and §5 in Click [21]. The key components of the encoder are: ﬁn-
gerprint computation per packet, a packet store for caching packets,
and a hash table for mapping ﬁngerprints to the packets they were
found in (similar to [29, 12]).
Like most RE systems, we use Rabin ﬁngerprinting [24]. Each
Rabin ﬁngerprint captures a ﬁxed 64 byte region in a packet [12].
We store a maximum of F = 10 ﬁngerprints per packet in the ﬁn-
gerprint hash table. This reﬂects a reasonable throughput-redundancy
tradeoff based on real traces.
We segment the packet store into logical buckets per interior-
node-path pair (§5.2). The encoder inserts each packet into the
appropriate bucket in FIFO order. In addition to payloads, we store
the IP headers for each packet because a hash of the headers is used
to decide decoding and storage responsibilities (Figure 5). Also, the
encoder ﬂags one bit in the IP header (e.g., TOS ﬁeld) to indicate
that the packet has one or more shims that need to be decoded.
In prior RE solutions [29, 12], each ﬁngerprint in the ﬁngerprint
hash table is associated with the most recent packet for which it is
computed. In SmartRE, this raises issues with packets being un-
decodable due to gaps. (To elaborate, this most recent packet may
itself have been encoded and thus further encodings with respect
to this packet will lead to decoding gaps as discussed in §5.) To
address this issue, when a packet sees a match and the match re-