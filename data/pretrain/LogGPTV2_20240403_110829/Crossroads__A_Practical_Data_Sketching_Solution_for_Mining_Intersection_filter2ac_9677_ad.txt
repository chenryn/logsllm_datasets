size(A ∩ B)
size(A)
, IRB =
size(A ∩ B)
size(B)
,
(2)
where size() denotes the number of packets contained
in a set. IRA and IRB are equivalent respectively to
γA and γB deﬁned earlier, if the V values of all the
packets are identical.
This IR has a great inﬂuence on the relative errors of
our estimations, for M0, M1, and M2, over the intersec-
tion A ∩ B. For example, if IRA = IRB = 0.01, which
means the intersection constitutes only 1% of the size of
A or B, then these relative errors will be approximately
100 times larger than the relative errors of our estima-
tions over A or B alone. When IRA and IRB are both
very small (e.g., 10−4), A ∩ B is so small compared to
A and B that our approach will not produce accurate
estimations over the intersection without consuming
an excessive amount of counter memory. In our imple-
mentations, we dimension just enough counter memory
for the cases in which IRA and IRB are both around
or above 0.005.
2. The ID attribute. It has been shown that the ﬁrst
invariant (i.e., not including ﬁelds that are modiﬁed
hop by hop by routers such as TTL) 28 bytes in an IP
packet header suﬃce to uniquely identify a packet [21].
In the spirit of that, a similar set of bytes is used as the
aforementioned ID attribute for the cellular network
packets (diﬀerent from IP). Our approach can also be
extended to ﬂow-level by using the unique identiﬁer of
each ﬂow instead of each individual packet.
3. Sketch resource allocation. In this work, we are in-
terested in estimating the average RTT, or equivalently
M1(RT T )
M0(RT T ) , from the underlying Tug-of-War sketches.
However, since M0(RT T ) is the denominator, its esti-
mation accuracy aﬀects the overall accuracy more than
228the numerator M1(RT T ). Therefore, we allocate more
sketch memory, in terms of the number of counters and
hash functions, for measuring M0 than for measuring
M1.
4. No median and all averaging. The original Tug-of-
War sketch used a median of mean of the counters [1]
mainly for proving accuracy bounds rigorously. The
number of diﬀerent counters used is usually s = s1 · s2,
where s1 represents the number of counters we average
to improve the accuracy and s2 represents the number
of such averages we take the median of to improve the
conﬁdence. In this work, we decided to simply average
all s counters together to arrive at our estimator, in-
stead of also taking median, because our experiments
show no improvement in empirical accuracy by doing
so. Note that upon the arrival of each packet, all s
counters must be updated no matter how s splits into
s1 and s2, so unlike the bucketing issue described be-
low, this decision does not aﬀect the computational
complexity of the per-packet update procedure.
5. Tug-of-War bucketing. Since the computational
complexity of the update procedure of the original Tug-
of-War algorithm can be quite high, especially when a
large number of counters and hash functions are used,
a bucketing technique ﬁrst introduced in [26] is used in
our implementations to reduce this complexity. Buck-
eting works by partitioning the available memory into
several disjoint buckets of counters and introducing a
new hash function. For every arriving packet, we map
it to a bucket by hashing its packet ID using this new
hash function. Counters in this bucket will then be
updated in the same way as in the original Tug-of-War
sketch. The second moment of the stream can be es-
timated by ﬁrst obtaining the second moments of the
sub-streams encoded by the buckets, and then adding
them up. The computational complexity of each up-
date can thus be reduced by a factor of the number of
buckets. The accuracy loss due to bucketing is negligi-
ble, as shown in [26].
6. Intersection overhead. While the update of the
sketches are optimized to be possible online, the in-
tersection of pairs of sketches can be done oﬄine as
needed. There is a small computational overhead of
O(K) operations, where K is the sketch size used (a
few thousand counters in the following experimental
section). This overhead is small enough to be negligi-
ble, and well worth the savings in storage cost.
6. EVALUATION
In this section, we evaluate the accuracy and eﬃciency
of our estimation algorithms using two types of data: real-
world cellular network data from a major cellular service
carrier in the US and synthetic traﬃc data. The cellular net-
work data was collected during a one month period across
the entire United States and was anonymized and aggre-
gated. No personally identiﬁable information was gathered
or used in conducting this study. We also generated syn-
thetic data statistically similar to the real data so that we
had more control over various parameters such as the sizes
of the sets A and B to be intersected and the amount of
overlap between them. Our results on real data show that
Figure 4: Synthetic results for M2 intersection rela-
tive errors when the total memory is ﬁxed to 4096
counters while the sketch size and the number of
buckets are varied
our approach uses a memory space about 170 times smaller
than the naive full-table approach (i.e., devoting one or a
few statistics counters to each Ai
about 10% loss in estimation accuracy.
6.1 Results for Synthetic Data
(cid:84) Bj) while suﬀering only
In our synthetic data, all RTTs were randomly generated
values between 0 and 100 milliseconds, similar to the values
we found in the real data set. For each experiment, we gen-
erated data according to whether we would like to vary the
full data size (number of packets or unique combinations)
or the size of the intersection compared with the size of the
individual sets (i.e., intersection ratio).
We ﬁrst evaluate the eﬀect of bucketing on estimation ac-
curacy by comparing estimation outcomes without bucket-
ing (viewed as having one bucket containing all counters)
with those with bucketing. In all cases, an identical number
(4096) of counters are used. For this experiment, we ﬁx the
sizes (number of packets) of the intersecting sets A and B to
be 0.1M and both intersection ratios to be 0.05. As we can
see from Fig. 4, when the total number of counters we use
in each sketch is set, and we vary the bucket size, deﬁned
as the number of counters in each bucket, and the number
of buckets while keeping the total number of counters per
sketch constant, the results do not vary substantially. This
means that bucketing does not negatively impact the esti-
mation accuracy while reducing computational complexities
of the update procedure. We got similar results with various
other total counter counts (not shown here in the interest of
space). As there seems to be no marked performance bene-
ﬁt to avoid bucketing, we ﬁxed the number of counters per
bucket 16 in subsequent experiments. This means that each
packet only triggers 16 counter updates, which is aﬀordable
computationally even for processing high-speed cellular net-
work traﬃc.
Next, we vary the number of buckets, while ﬁxing the
bucket size to 16 (counters per bucket), to see how it aﬀects
the relative mean intersection estimation error and the rel-
ative mean sketch error in Fig. 5. Again the sizes (packets
number) of both intersecting sets A and B are set to 0.1M
and both intersection ratios 0.05. We found that the results
for M2, M1 and M0 were comparable. The reason for this is
that the 3 frequency moment estimation processes all use the
10110210310400.050.10.150.20.25sketch sizerelative error  estimating M0estimating M1estimating M2229Figure 6: Synthetic results for mean intersection rel-
ative errors when varying intersection ratio. Bucket
size set to 16 counters and the number of buckets to
1024
Figure 5: Synthetic results for mean intersection rel-
ative errors and sketch relative errors when varying
(the number of ) buckets. Bucket size set to 16 coun-
ters and the total memory usage is bucket size ×
buckets
same Tug-of-War sketch. In both ﬁgures, as the number of
buckets gets larger, both relative sketch estimation error and
intersection estimation error decrease, but with diminishing
returns.
Next, we study the situation in which the intersection ra-
tios IRA and IRB are varied simultaneously. The results
are shown in Fig. 6. As IR increases, mean relative error
decreases very quickly. The eﬀect of increasing IR is quite
notable for decreasing relative error. When IR is quite small
(e.g., 10−5), getting an accurate estimation for the inter-
section part is very diﬃcult. As the intersection ratio gets
larger, we get increasingly accurate estimates of the inter-
section. Note that the intersection ratio will not aﬀect our
sketch estimating errors; it aﬀects only the intersection esti-
mation error.
We also varied the size of A and B (with size(A) =
size(B)) while keeping their IR constant. The results are
shown in Fig. 7. We found that the mean relative error
increases only slightly with the size of both sets. This sug-
gests that the sizes of both sets do not signiﬁcantly aﬀect
the relative intersection error as long as the intersection ra-
tio remains constant. Hence, our method can be used for
even larger data sets (i.e., larger packet streams) with little
degradation in estimation accuracy.
Figure 7: Synthetic results for mean intersection rel-
ative errors when varying the number of packets in
the set. Bucket size set to 16 and buckets to 1024
6.2 Data Sets for Real Data
Our real-world data was collected from a major cellular
service carrier in the US over the month of January 2014. It
consists of anonymized TCP ﬂow level data collected from
the core network for the 3G data service provided by the
cellular service carrier.
Figure 8 illustrates the architectural overview of the core
network, which consists of two main types of nodes: the
Serving GPRS Support Node (SGSN) and the Gateway GPRS
Support Node (GGSN). The GGSN is the root node in the
hierarchy of the cellular data network and responsible for
sending and receiving Internet traﬃc to and from the cel-
lular network. SGSN is an intermediate node that connects
the lower level nodes to the GGSN through the Gn interface.
Typically, a single SGSN is connected to multiple Radio Net-
work Controllers (RNCs) and each RNC serves a geograph-
ical region through cell towers.
The raw data is collected at the Gn interface which con-
nects the SGSNs to the GGSNs. Speciﬁcally, for each TCP
ﬂow, we ﬁrst measure its end-to-end round trip time (RTT)
by comparing the timestamps of IP packets during the TCP
10210310400.050.10.150.20.250.30.35buckets numberrelative error  M2 intersection errorM1 intersection errorM0 intersection error10210310400.010.020.030.04buckets number relative error  M2 sketch errorM1 sketch errorM0 sketch error0.020.030.040.050.060.0700.10.20.30.40.5intersection ratiorelative error  M2 intersection errorM1 intersection errorM0 intersection error10210410600.020.040.060.080.10.12number of packets in the setrelative error  M2 intersection errorM1 intersection errorM0 intersection error230Figure 8: Data Collection Architecture
handshake and then associate the RTT value with various
ﬂow attributes such as standard coordinated universal time
(UTC), the serving RNC that describes the user access point,
the handheld device type, the application type, the content
provider being accessed, etc. Due to the sheer amount of
traﬃc volume, instead of storing the raw data for all individ-
ual ﬂows, we only store the hourly total number of RTT mea-
surements, the hourly summation of the RTT measurements
and the hourly average RTT (computed as the sum divided
by the total number) over eight diﬀerent ﬂow attributes:
serving RNC, handheld device manufacturer/model, hand-
held device speed category, service category, content provider,
day of week, hour and access point network (APN). No per-
sonally identiﬁable information is retained in the aggregate
statistics. Being able to query these statistics for an arbi-
trary cross-section of the eight diﬀerent ﬂow attributes is
critical for service providers to manage their service perfor-
mance. In order to be able to perform a query for any arbi-
trary 8-tuple of these quantities, we divided these attributes
into two groups. The results of some preliminary measure-
ments showed that making serving RNC, service category,
handheld device speed category and day of week as a group,
and handheld device manufacturer/model, content provider,
access point network and hour as another group, would min-
imize the total number of sketches that we would need to
perform a query for an arbitrary slice of the data.
There are about 1.4 million distinct combinations for the
former group described above and about 1.5 million for the
latter. Thus, the cost of maintaining the value of each and
every combination (a table with one counter per combina-
tion) would result in a space usage of 1.4M × 1.5M × 4
bytes, or more than 7.5 TB of storage capacity. In contrast,
if we use 4096 counters in each sketch, our method needs
only (1.4M + 1.5M ) × 4096 × 4 bytes, or less than 45 GB.
This is a savings of over two orders of magnitude that is paid
for with a small loss in estimation error. Note that working
with even larger data sets (for instance, monitoring a year’s
worth of data) will give even greater savings.
Since the data we get is already aggregated by hour, we
were unable to perform per-packet processing. Instead, we
updated our sketch data structures using the measurement
count and measurement values for each tuple aggregated at
each hour across 36 sub-regions that span the United States.
A limitation of this aggregated data was that we were un-
able to compute the second moment values for the RTTs
since we did not have these individual values available to
Figure 9: Results of mean intersection relative er-
rors with ﬁxed memory to 4096 counters and varying
bucket size and the number of buckets
Figure 11: Results of mean intersection relative er-
rors when varying buckets for real data. Bucket size
set to 16
us. In the future, when our algorithm is deployed directly at
each RNC, we will be able to measure the second moment as
well to estimate the variance of the RTT (or other) values.
Since it was infeasible to measure estimates for all possi-
ble combinations of tuples, we instead sampled one hundred
tuples at random and computed the average relative error
for these combinations. The variance of these measurements
was found to be small.
6.3 Results for Real Data
We tested our algorithms on the cellular traﬃc data de-
scribed above. For anomaly detection and other change de-
tection problems, it suﬃces to have a relative estimation
error that is within 15% since we are only interested in de-
tecting signiﬁcant changes from the normal values. For in-
stance, we may not want to sound an alarm until the RTT
has nearly doubled from its usual value. Of course, in other
applications we may want to bound the error to under a few
percent; our evaluation extends to this range as well.
Unlike the experiments on synthetic data, we did not have
the ability to change all parameters (e.g., relative set size
or intersection ratio). Also note that it was infeasible to
compute M2 for the real data because they had already been
aggregated into ﬂow records. Therefore, we focused on M0
and M1, which can be computed from the aggregated data,
and the average (Avg = M1/M0).