d
z0 = 1. Then f (x) =
i; j=0 ai+jdyizj. This can speed up “table
lookups”, which are typically encoded as polynomial evaluation.
For S(N)ARK-friendly cryptography [33], supporting quadratic
equations is very useful. Matrix-vector multiplications are efficient
∑
even when both matrix and vector are secret. “Embedding” an el-
liptic curve (see Jubjub [1]), is also more efficient than for R1CS.
For general point addition in a (twisted) Edwards curve, we need
5 instead of 8 constraints per bit.
Similar to SNARK- and MPC-friendly cryptography, quadratics-
friendly cryptography may enable significant speedups. A prime
candidate is multi-variate quadratic cryptography, where suitably
adapted schemes might integrate very well with our proof system.
p
1.2.4 Correctness of a shuffle. By instantiating the shuffle proof of
Bayer and Groth [5] with LMPAZK and QESAZK as sub-protocols,
we obtain an argument (cid:5)shuffle for correctness of a shuffle. To the
best of our knowledge, this is the first efficient argument with
proof size O(log(N )). Our computational efficiency is compara-
ble to [5], which has proof size O(
N ). More concretely, we (very
roughly) estimate at worst 2–3(cid:2) the computation.
1.2.5 Knowledge errors, tightness and short-circuit extraction. From
a quantitative perspective, our notion of testing distributions and
their soundness errors, are useful to separate study of knowledge
errors and extraction in the setting of special soundness. Testing
distributions have associated soundness errors, which (up to tech-
nical difficulties we state as open problems) translate to knowledge
errors of the protocol. Explicit knowledge errors achieve tuneable
(cid:0)256, which impacts
levels of soundness, e.g. 2
runtime positively.
(cid:0)120 instead of 2
Short-circuit extraction. We give a definition of short-circuit ex-
traction. This treats extraction assertions such as “Ext either finds a
witness or it solves a hard problem”. It formalises the (common) be-
haviour of an extractor to either find a witness with few transcripts,
or solve the hard problem (e.g. equivocating a commitment). With-
out distinguishing these cases, the bounds on the necessary num-
ber of transcripts for extraction is much higher. For example, we
show that the extractor for the LMPAZK and IPAalmZK (and also
[10, 13]) needs a tree of transcripts of size O(log(n)n) in the worst
case. For QESAZK, extracting a proof for N quadratic equations in
n variables requires O(log(n)nN ) transcripts. The extractor in [13]
needs O(n3N ) transcripts, which for n; N (cid:25) 216 implies a secu-
rity loss of (cid:25) 264 instead of (cid:25) 234. This also opens the possibil-
ity for using small exponents as challenges, further improving our
argument systems performance. Note that, due to their structure,
Bulletproofs [13] are not well-suited for small exponents.
In the full version [31], we give a conjectured relation between
communication efficiency and extraction efficiency, which implies
n
log(n) ) transcripts would be optimal. We
that extraction from O(
also elaborate on a loophole in above security estimates, namely
how to efficiently obtain the transcripts.
1.2.6 Dual testing distributions. Dual testing distributions are a
technical tool which allow us to sample a “new” commitment key
from a given one, such that knowledge (e.g. commitment opening)
cannot be transferred. This turns out to be more communication
efficient than letting the verifier send a new commitment key. To
the best of our knowledge, this is a new technique.
1.2.7 Theoretical comparison to [13] and improved inner product ar-
gument (IPA). In Table 1, we compare our argument systems with
Session 9C: Zero-Knowledge ProofsCCS ’19, November 11–15, 2019, London, United Kingdom2095related work in the group setting. In Table 2, we give precise effi-
ciency measures for LMPAZK and QESAZK. In any case, n = jwj
is the size of the witness w 2 Fn
p . Since it is statement dependent,
we ignore that QE is more powerful than R1CS, possibly allowing
smaller witness size (as seen in the example ⟨x; x⟩ = t above). In
Table 2, we omit the verifier’s computation, since after optimisa-
tions [13], both are almost identical. For the prover, we do not op-
timise (e.g. we use no multi-exponentiations), and are not aware of
non-generic optimisation. Much of our theoretical improvement is
due to our improvements to the IPA. Using [13] with our IPA yields
identical asymptotics. Even then, QESAZK covers general quadratic
equations, while Bulletproofs [13] which only cover R1CS.
7
KoE
1
Setup Ass. Moves
Comm. Comp. P Comp. V Nat. R
R1CS
[21]
O(1)
O(n)
R1CS
[13] 3 dlog O(log(n)) O(log(n)) O(n)
QE
This 3 dlog O(log(n)) O(log(n)) O(n)
Table 1: Comparison of [21], Bulletpoofs [13] and this
work. Setup: Common random string sufficient? Secu-
rity Ass(umption): Knowledge of exponents (KoE); Hard-
ness of dlogs. Moves: The number of messages sent.
Comm(unication) in group elements. Comp(upation) in
group exponentiations. Nat(ive) relation R.
(cid:20) jwj
jwj
jwj
Comm. G
(cid:25) 4m log2(n)
LMPAZK
QESAZK 2⌈log(n + 2)⌉ + 3
2⌈log(n)⌉ + 8
[13]
Comm. Fp Comp. P R
(cid:25) 4mn
LMP
(cid:25) 8n
QE
(cid:25) 12n R1CS
4m
2
5
Table 2: Estimates in terms of the group elements and expo-
nentiations. By “(cid:25) f ” we denote f + O(log(f )).
1.2.8 Comparison with other proof systems. It is hard to make a
fair comparison of proof systems. There are many relevant param-
eters, such as setup, assumptions, quantum resistance, native lan-
guages, etc. beyond mere proof size and performance. See Sec-
tion 1.3 for a high-level discussion. To draw (non-trivial) conclu-
sions from comparisons on an implementation level, one should
compare fully optimised implementations. Thus, we restrict our-
selves to a comparison with Bulletproofs (which we reimplemented
with the same optimisation level as our proof systems). For some-
what concrete numbers regarding (implementation) performance,
as well as other factors relevant to the comparison of proof sys-
tems, we refer to [7, Figure 2]. Our proof systems are similar enough
to Bulletproofs for these comparisons to still hold.
Implementation. In Section 5, we compare our implemen-
1.2.9
tations of (aggregate) range proofs. The theoretical prediction of
0:75(cid:2) prover runtime compared to [13] is close to measurements,
which suggest 0:7(cid:2). Using 140bit exponents, we experimentally at-
tain (cid:25) 0:63(cid:2) compared to [13] on the same platform. As an impor-
tant remark, we compare the dedicated range proofs of [13] with
our generic instantiation of QESAZK.
1.3 Related work
Due to space constraints, we only elaborate on the most important
concepts and related work. We refer to [29] for an overview and a
general taxonomy.
The dlog setting and ILC. Very closely related works are [10, 12,
13, 25], which are efficient proofs in the dlog setting. Many zero-
knowledge proofs in the group setting are instantiations of [16,
36]. The possibilities of our setting, namely ability to apply linear
transformations to a committed witness has been abstracted in the
ideal linear commitment model [11]. (Our techniques for QESAZK
are amenable to ILC.)
Knowledge assumptions. Another line of work [9, 18, 21, 26, 27,
35] gives non-interactive arguments using knowledge of exponent
assumptions. They attain constant size proofs for arithmetic cir-
cuits and sublinear verification costs, but require a trusted setup.
PCPs, IOPs, MPC-in-the-head. Techniques, such as probabilisti-
cally checkable proofs (PCP), MPC-in-the-head [32], interactive
oracle proofs (IOP) and more, construct efficient zero-knowledge
proofs without relying on public key primitives. The possible per-
formance gain (and quantum resistance) is interesting from a prac-
tical point of view. There is much progress on improving these
techniques [3, 7, 14, 22, 39], which until recently suffered from
relatively large proof size or unacceptable constants. In [7], Ben-
Sasson et al. present a logarithmic communication IOP for R1CS,
which, by avoiding public key primitives, likely outperforms our
QESAZK by order(s) of magnitude. Still, according to [7], proof
sizes for R1CS statements of size N = 106 are about 130kb whereas
our proofs, like Bulletproofs, stay well below 2kb. For combining
proofs in the “symmetric key” setting with efficient proofs for “pub-
lic key” algebraic statements, [2] can be used. Our proofs can be
directly combined with algebraic statements over the same group
G.
2 PRELIMINARIES
For a set S and probability distribution χ on S we write s   χ for
drawing s according to χ. We write s   S for a uniformly random
element. We also write y   A(x; r ) for running an algorithm A
with randomness r and y   A(x) for running A with (uniformly)
random r   R (where R is the randomness space). We let κ denote
the security parameter and note that almost all objects are implic-
itly parameterised by it. By negl we denote some (fixed) negligible
function, i.e. a function with limκ!1 κc negl(κ) = 0 for any c 2 N.
We assume we can sample uniformly random from any f1; : : : ; ng.
The number p 2 N will always denote a prime, Fp B Z/pZ, and G
is a (cyclic abelian) group of order p. We use additive implicit nota-
tion for G as introduced in [20]. That is, we write [1] for some (fixed
public) generator associated with G and [x] B x[1]. We extend this
notation to vectors and matrices, i.e. for compatible A; B; C over Fp,
we write A[B]C = [ABC]. Matrices are bold, e.g. [a], components
not, e.g. [ai ]. By ei we denote the i-th standard basis vector. We
write diag(M1; : : : ; Mn ) for a block-diagonal matrix. By idn we
denote the n (cid:2) n identity matrix.
Session 9C: Zero-Knowledge ProofsCCS ’19, November 11–15, 2019, London, United Kingdom20962.1 Matrix kernel assumptions and Pedersen
commitments
Instead of discrete logarithm assumptions, the generalisation of
hard (matrix) kernel assumptions [37], but for right-kernels, bet-
ter suits our needs.
Definition 2.1. Let G   GrpGen(1κ ) be a group generator (we
let [1] and p be implicitly given by G). Let Dm;n be a (efficiently
samplable) distribution over Gm(cid:2)n (where m and n may depend on
κ). We say Dm;n has a hard kernel assumption if for all efficient
adversaries A, we have
G   GrpGen(1κ ); [A]   Dm;n ;
x   A(1κ ; G; [A]) : [A]x = 0 ^ x , 0
(cid:20) negl(κ)
(
P
)
For simplicity, we will often only implicitly refer to Dm;n and
just say [A] has hard kernel assumption. Matrix kernel assump-
tions generalise DLOG assumptions: A non-trivial kernel element
of [h; 1] 2 G2 immediately yields the discrete logarithm h of [h].
If Dm;n is a matrix distribution with hard kernel assumption,
then [A]   Dm;n is a (Pedersen) commitment key ck. Commit to
x 2 Fn
p via Comck(x) = [c] 2 Gm. Breaking the binding property
of the commitment is equivalent to finding non-trivial elements
in ker([A]). The common case will be [д] 2 G1(cid:2)(n+1) drawn uni-
formly as commitment key ck. Breaking the hard kernel assump-
tion for [д] is tightly equivalent to breaking the dlog assumption in
G. Write x = (rw ; w) with rw 2 Fp, w 2 Fn
p . If rw   Fp is drawn
uniformly, it is evident that [c] = [д]x perfectly hides w, i.e. [c] is
uniformly distributed in G.
2.2 Interactive arguments, extractability and
zero-knowledge
Our setting will be the common reference string model, i.e. there
is some CRS crs, typically a commitment key, set up by a trusted
party. In the following R denotes a binary relation for which (st; w) 2
R is efficiently decidable. We call st the statement and w the wit-
ness. (R does depend on crs, i.e. actually we consider (crs; st; w)
tuples, but we suppress this.) The (NP-)language L defined by R
is the language of statements in R, i.e. L = fst j 9w : (st; w) 2 Rg.
Definition 2.2. An (interactive) argument system for a rela-
tion R is a protocol between two parties, a prover P and a verifier
V. We use the name (interactive) proof system interchangably.
The transcript of the interaction of P and V on inputs x and y is
denoted ⟨P(x); V(y)⟩ where both parties have a final “output” mes-
sage. We write b = ⟨P(x); V(y)⟩, for the bit b indicating whether
an (honest) verifier accepts (b = 1) the argument.
(
Definition 2.3 (Completeness). An interactive argument system
for (st; w) 2 R is (computationally) complete if for all efficient
adversaries A, the probability
crs   GenCRS(1κ ); (st; w)   A(crs) : (st; w) < R or
)
P
⟨P(st; w); V(st)⟩ = 1
is overwhelming, i.e. bounded below by 1(cid:0)negl(κ). It is perfectly
complete if negl = 0.
In the full version [31], we give a definition of witness-extended
emulation [10, 28] with extraction error (i.e. knowledge error). It
turns out that preserving a good extraction error over multiple
rounds is non-trivial. See Sections 2.3 and 2.4.
Definition 2.4 (Public coin). An interactive argument system for
R is public coin if all of the verifier’s challenges are independent
of any other messages or state (essentially V makes his random
coins public). Furthermore, V’s verdict is a function Verify(tr) of
the transcript.
Honest verifier zero-knowledge guarantees the existence of a
simulator which, without the witness, generates transcripts which
are indistinguishable from transcripts of a real interaction with an
honest verifier. Hence, an honest verifier learns nothing from the
proof.
Definition 2.5. Let (P; V) be an interactive argument system for
R. We call (P; V) (ε-statistical) honest-verifier zero-knowledge
(HVZK), if there exists an expected polynomial-time simulator Sim
such that for all expected polynomial-time A the probabiliy distri-
butions of (crs; tr; state), where
(cid:15) crs   GenCRS(1κ ); (st; w)   A(crs); tr   ⟨P(st; w); V(st)⟩
(cid:15) crs   GenCRS(1κ ); (st; w)   A(crs); tr   Sim(st; ρ);
are indistinguishable (have statistical distance at most ε), assuming
tr B ? if (st; w) < R.
Remark 2.6. We focus on HVZK, not special HVZK, The latter
states that even if the adversary chooses statement, witness and
the verifier’s randomness (ρ in Definition 2.5), the special simulator
will “succeed”. Our security proofs make use of honest challenges.
Different (more complex) security proofs may be possible.
Full-fledged zero-knowledge. To obtain security against dis-
2.2.1
honest verifiers, i.e. full-fledged zero-knowledge, simple transfor-
mations exist [15, 17, 24, 34] for public coin HVZK arguments. The
most straightforward one is to use an equivocable coin toss be-
tween prover and verifier to generate the challenge.
2.2.2 The Fiat–Shamir heuristic. In the random-oracle model (ROM),
public coin arguments can be converted to non-interactive argu-
ments by computing the (verifier’s) challenges as the hash of the
transcript (and relevant “context”) up to that point. The statement
of the argument should be part of the “context” [8].
2.3 Testing distributions
Intuitively, testing distributions are a special form of probabilis-
tic verification where one can efficiently recover the “tested” value
given enough “tests”. Thus, they are used to recover the witness
in proofs of knowledge. We only define testing distributions over
Fm
p .
Example 2.7. To test if a vector [c] 2 Gm is [0], test if x
?
= [0]
[c]
⊤
for random x 2 Fm
p . The soundness error is 1/p.
∑
Definition 2.8 (Subdistribution). Let χ and ψ be distributions on
Fm
p . We call ψ a subdistribution of χ of weight ε if
(cid:15) there exists a subdensity ρψ : Fm
p ! [0; 1]. (It is important
that ρψ (x) (cid:20) 1.)
(cid:15) ε =
p ρψ (x)χ (x), and
(cid:15) ψ has probability ψ (x) = 1
density 1
ε ρψ (x) to pick x. (That is, ψ has
x 2Fn