title:Differential Privacy for Directional Data
author:Benjamin Weggenmann and
Florian Kerschbaum
Differential Privacy for Directional Data
Benjamin Weggenmann
SAP Security Research
Karlsruhe, Germany
Florian Kerschbaum
University of Waterloo
Waterloo, ON, Canada
ABSTRACT
Directional data is an important class of data where the magnitudes
of the data points are negligible. It naturally occurs in many real-
world scenarios: For instance, geographic locations (approximately)
lie on a sphere, and periodic data such as time of day, or day of week
can be interpreted as points on a circle. Massive amounts of direc-
tional data are collected by location-based service platforms such
as Google Maps or Foursquare, who depend on mobility data from
users’ smartphones or wearable devices to enable their analytics and
marketing businesses. However, such data is often highly privacy-
sensitive and hence demands measures to protect the privacy of the
individuals whose data is collected and processed. Starting with the
von Mises–Fisher distribution, we therefore propose and analyze
two novel privacy mechanisms for directional data by combining
directional statistics with differential privacy, which presents the
current state-of-the-art for quantifying and limiting information
disclosure about individuals. As we will see, our specialized privacy
mechanisms achieve a better privacy–utility trade-off than ex post
adaptions of established mechanisms to directional data.
CCS CONCEPTS
• Security and privacy → Data anonymization and sanitiza-
tion; Pseudonymity, anonymity and untraceability; • Information
systems → Spatial-temporal systems; Location based services.
KEYWORDS
directional data; differential privacy; data anonymization
ACM Reference Format:
Benjamin Weggenmann and Florian Kerschbaum. 2021. Differential Privacy
for Directional Data. In Proceedings of the 2021 ACM SIGSAC Conference on
Computer and Communications Security (CCS ’21), November 15–19, 2021,
Virtual Event, Republic of Korea. ACM, New York, NY, USA, 18 pages. https:
//doi.org/10.1145/3460120.3484734
1 INTRODUCTION
In recent years, large-scale collection and processing of directional
data have become important drivers for the digital economy: For
instance, crowd-sourced data from mobile or wearable devices often
includes the geographic location where and the time when the data
was recorded. Prominent applications include location-based mar-
keting and analytics, as provided by platforms such as Foursquare,
and the collection of check-in data by online mapping services such
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea
© 2021 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-8454-4/21/11.
https://doi.org/10.1145/3460120.3484734
as Google Maps who provide, e.g., daily “busyness” histograms of
visit times at places like stores or restaurants, from which users can
estimate how busy a location is during different times of the day.
While such techniques provide substantial value for businesses
and drive innovation, the data collected in such scenarios is often
privacy-sensitive, and users may be reluctant to share their where-
abouts during the course of the day. In many cases, directional data
conveys particularly sensitive information, as illustrated by recent
news about location tracking on smartphones or fitness trackers
[18, 37]. Personal locations are suspect to various attacks, cf. the
survey by Krumm [24], in particular when combined with temporal
information as shown by Primault et al. [33] or Pyrgelis et al. [35].
Problem. To protect the privacy of individuals while maintaining
data-driven business models, the concept of differential privacy (DP)
by Dwork et al. [10] presents the current state-of-the-art for quan-
tifying and limiting information disclosure about individuals. DP
mechanisms have been proposed for various settings and data types,
e.g., the standard Laplace mechanism [10] which extends infinitely
on the real line, or the Planar Laplace mechanism by Andrés et al.
[2] which is defined for planar locations. While post-processing,
such as clipping or wrapping, can be applied to adapt these mech-
anisms to periodic domains, none of them intrinsically considers
the potentially directional nature of the underlying data. In fact,
adapted standard mechanisms based on wrapping can behave even
worse than uniform noise, as we show in Section 4.2.1. We hence
argue that specialized, directional privacy mechanisms are needed
to provide superior privacy–utility trade-offs and investigate proper
ways to provide DP intrinsically for directional data (cf. Section 3).
Inspired by the notion of geo-indistinguishability [2], a variant
of metric privacy [4] for planar location data, we propose directional
privacy as adaptation for directional data. As benefit, this notion
allows relaxing the guarantees of pure DP to protect data within a
given protection radius (i.e., surface distance or angle) 𝑟 > 0 with
a specified privacy level ℓ. By setting the protection radius 𝑟 = Δ
to the sensitivity, this also covers pure 𝜖-DP. Relaxing the privacy
guarantees to a smaller radius is very useful when working in the
local model, e.g., when we want to protect spatial or temporal data
that are close to each other, such as restaurants or other venues
in densely populated areas, where pure DP would inject too much
noise. We demonstrate this in our experiments in Section 4.3.2.
As we observe in Section 4.2, several directional statistics such
as the circular mean benefit from our specialized mechanisms: At
𝜖 = 1.0, we achieve a more than 4.8-fold reduction in the number
of required survey responses over adapted baselines to reach an
error below 0.1, so that the service provider needs to collect only
≈ 750 responses instead of over 3600. Conversely, given the same
number of responses, our proposed mechanisms achieve MAEs of
only 0.407 and 0.321, which is less than half of 0.695 as for the
Wrapped Laplace baseline. Strikingly, for such directional statistics,
local DP is necessarily more accurate than central DP and hence
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1205the method of choice, since it does not require a trusted aggregator.
Moreover, in Section 4.3, we observe that a wrapped Planar Laplace
variant for geolocations yields larger errors for histograms than
our proposed mechanisms in the critical range 10−1 ≲ 𝜖 ≲ 10.
Contributions. Our results concern theoretical aspects (Section 3)
in the areas of privacy and directional statistics, as well as experi-
ments (Section 4) to substantiate the theory and its applicability:
• As for privacy, in Section 3, we propose the notion of di-
rectional privacy, an adaptation of metric privacy [2, 4] for
directional data based on the surface distance on the sphere.
To realize this notion, we form the novel von Mises–Fisher
and Purkayastha privacy mechanisms from the eponymous
distributions and prove their (differential) privacy properties.
• We derive analytical formula in terms of confluent hyper-
geometric series for the expected Euclidean distance and the
cumulative distribution function (CDF) of the mixture density
of the Von Mises–Fisher distribution in Section 3.2, as well
as closed-form solutions in terms of elementary functions
for the expected surface distance and the CDF of the angular
density of the Purkayastha distribution in Section 3.3. We use
those formulas to compare our directional with traditional
baseline mechanisms in Section 3.6 and assess their error.
• In Section 3.5, we make use of our closed-form solution for
the angular CDF to build an approximate inversion sampling
method for the Purkayastha distribution. To our best knowl-
edge, this is the first published method for this distribution
which has been deemed numerically hard to sample from
in dimensions over 150 [7]. Our benchmarks show that it is
applicable in up to tens of thousands of dimensions.
• We apply our proposed mechanisms in several real-world
settings and compare their privacy–utility trade-offs: We
consider the periodic mean in the central and local privacy
models for time-of-day data in Section 4.2, as well as his-
tograms of location and time-of-day data in the local model
in Section 4.3. We also illustrate privately collecting check-in
time and location data to create “busyness” histograms of
popular visit times even if the data curator is untrusted.
• Finally, we perform supplementary simulation experiments
in Appendix B.1 to support the correctness of our derived
formula for the expected distances and CDFs. Based on the
empirical expected distances, we also compare the privacy-
utility trade-off for both mechanisms at a given privacy level.
2 BACKGROUND
This section provides terminology and results of differential privacy
and directional statistics as required in the paper.
2.1 Differential Privacy
In the following, we introduce some basic notions of differential and
metric privacy. We roughly adopt the notation of Chatzikokolakis
et al. [4]. For a broader introduction and details, we refer the reader
to the books by Dwork and Roth [11] or Li et al. [29].
Probability distributions. For a given set Z, we denote by PZ
the set of probability distributions (or measures) on Z, i.e., the set of
normed and 𝜎-additive functions P : 𝜎(Z) → [0, 1] where 𝜎(Z)
is a 𝜎-algebra on Z. The probability of an event Z ∈ 𝜎(Z) (i.e.,
a measurable subset of Z) is thus given by P[Z]. A distribution
P is typically specified by its probability density function (PDF),
which we denote by P[z] by slight reuse of notation. For univariate
distributions on Z ⊆ R, we also denote the cumulative distribution
function (CDF) at Z by P[z ≤ Z], shorthand for P[{z ∈ R : z ≤ Z}].
We often consider families of distributions parametrized by one
or more parameters, such as 𝝁 or 𝜖, which we append in parentheses
as in P(𝝁, 𝜖)[·], or simply P(𝝁, 𝜖).
Definition 1. Let X and Z be two sets. A random mechanism
from X to Z is a function M : X → PZ that assigns to each input
𝒙 a probability distribution on Z. M can be specified through a
parametrized family of distributions M(𝒙) on Z via M(𝒙) = M(𝒙)
for 𝒙 ∈ X; we then say M is the mechanism induced by M. From
an algorithmic perspective, we run a random mechanism M on
a given input 𝒙 by sampling a realization z from the distribution
M(𝒙). We write this as z (cid:123) M(𝒙).
Differential privacy (DP) and its models. DP has been introduced
by Dwork et al. [10] under the name 𝜖-indistinguishability. Its goal
is to give semantic privacy by quantifying the risk of an individual
that results from participation in data collection.
In the original, central model, we assume the collected data is
stored in a central database with one record per participant. If
we consider adjacent databases that differ by at most one record
(i.e., one individual’s data), a differentially private query on both
databases should yield matching results with similar probabili-
ties, i.e., answers that are probabilistically indistinguishable. This
is achieved via random mechanisms on the universe of datasets
X = D that return noisy query results, thus masking the impact of
each individual.
Definition 2. Let 𝜖 > 0 be a privacy parameter. A random mech-
anism M : D → PZ fulfills 𝜖-DP if for all adjacent databases
𝒙, 𝒙′ ∈ D, and all sets of possible outputs Z ⊂ suppM,
M(𝒙)[Z] ≤ 𝑒𝜖 · M(𝒙′)[Z].
In the local model [9], noise is added locally at the data source,
before the data is collected and stored in a central database. A
basic example is randomized response [43], where each survey
participant either provides a truthful or a random answer depending
on the flip of an (unbiased) coin.
2.1.1 Generalization with metrics. A limitation with DP is that the
indistinguishability is achieved between two inputs on a per-record
level regardless of their actual values. This can be especially prob-
lematic in the local model, where each user might just submit one
single record, in which case a DP mechanism with small privacy
parameter 𝜖 would enforce all submitted records to be indistin-
guishable, thus rendering the collected data essentially useless.
To the same end, Chatzikokolakis et al. [4] argue that in some sce-
narios, the (in)distinguishability between two databases as enforced
by a privacy mechanism should depend on the values themselves
instead of the number of differing records. They hence propose
a generalized notion of privacy on metric spaces that also covers
domains other than databases where a conforming mechanism run
on nearby elements still has similar output probabilities:
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1206Definition 3 (Metric privacy). Let 𝜖 > 0 be a privacy parameter.
On a metric space (X, 𝑑), a mechanism M satisfies 𝜖𝑑-privacy if
for all 𝒙, 𝒙′ ∈ X and all Z ⊂ suppM,
M(𝒙)[Z] ≤ exp(cid:0)𝜖 · 𝑑(𝒙, 𝒙′)(cid:1) · M(𝒙′)[Z].
S𝑛−1
𝝃 ∼ Uni(S𝑛−2 ⊥ 𝝁)
x
√
1 − 𝑡2
ℎ =
= sin(𝜃)
𝝁
𝜃
𝑡 = 𝝁ᵀx
= cos 𝜃
In other words, the level of indistinguishability of any two points
𝒙, 𝒙′ is bounded by 𝜖 times their distance. Andrés et al. [2] provide
another interpretation: If we consider an arbitrary but fixed dis-
tance 𝑟 > 0, any two points with 𝑑(𝒙, 𝒙′) ≤ 𝑟 achieve a level of
indistinguishability at most 𝜖𝑟; hence, an 𝜖𝑑-private mechanism M
achieves a privacy level ℓ = 𝜖𝑟 within a protection radius 𝑟.
Note that we recover the original notion of 𝜖-DP on the space
of databases X = D if we use the record-level edit distance 𝑑±1,
as datasets 𝒙, 𝒙′ ∈ D differ by at most one record if and only if
𝑑±1(𝒙, 𝒙′) ≤ 1. This motivates the following broader definition:
In a metric space (X, 𝑑), we say that two inputs
Definition 4.
𝒙, 𝒙′ ∈ X are adjacent (with respect to 𝑑) if 𝑑(𝒙, 𝒙′) ≤ 1. We write
this as 𝒙 ∼𝑑 𝒙′ (or 𝒙 ∼ 𝒙′ if 𝑑 is understood from the context).
2.2 Directional statistics
Directional statistics is an area of statistics that is concerned with di-
rections, i.e., data points whose magnitudes can be neglected. Here-
after, we introduce some terms and notions as required in the paper.
As reference, we recommend the book by Mardia and Jupp [30].
Since directions are independent of magnitude, they can be iden-
tified by unit vectors, i.e., points on a unit sphere:
Definition 5. For 𝑛 ∈ N, the unit (𝑛 − 1)-sphere
S𝑛−1 := {𝑥 ∈ R𝑛 : ∥𝑥∥2 = 1}
𝑛
1
2
2 .
(cid:17).
𝑛−1 =
is the set of unit vectors in 𝑛-dimensional Euclidean space. We write
𝑟 S𝑛−1 for the (𝑛 − 1)-sphere of radius 𝑟 > 0.
Fact 6. The surface area of the unit sphere S𝑛−1 is given by its
(𝑛 − 1)-dimensional volume
2 · Γ−1(cid:16) 𝑛
𝑆𝑛−1 := vol(cid:0)S𝑛−1(cid:1) = 2 · 𝜋
2 Γ(cid:0) 𝑛
2(cid:1)𝜋− 𝑛
For a sphere of radius 𝑟, we have vol(𝑟 S𝑛−1) = 𝑆𝑛−1𝑟𝑛−1.
Example 7. The uniform distribution Uni(S𝑛−1) on S𝑛−1 has a
constant PDF Uni(S𝑛−1)[x] ≡ 𝑆−1
2.2.1 Rotationally symmetric distributions. We consider unimodal
distributions on S𝑛−1 that are rotationally symmetric about the
mode 𝝁 ∈ S𝑛−1. The corresponding densities P[x] depend on x only
through the projection 𝑡 = 𝝁ᵀx of x on the modal axis through 𝝁,
so all points x with 𝝁ᵀx = 𝑡 have constant density P[x] = ¯P[𝝁ᵀx] =
¯P[𝑡] for a corresponding kernel function ¯P : [−1, 1] → R≥0.
To sample from such distributions, it is helpful to consider mar-
ginal distributions that are easier to handle. A way to obtain them
is through the so-called tangent-normal decomposition (cf. Fig. 1): A
random vector x ∈ S𝑛−1 can be decomposed into two components
along the mode 𝝁 and along a tangential unit vector 𝝃 ⊥ 𝝁 as
x = 𝑡 𝝁 +(cid:112)1 − 𝑡2𝝃 , where 𝑡 = 𝝁ᵀx.
(1)
Due to the rotational symmetry, 𝝃 ∈ S𝑛−2 ⊥ 𝝁 is distributed
uniformly on the subsphere orthogonal to 𝝁 (marked in green).
Figure 1: Tangent-normal decomposition of a random unit
vector x into orthogonal components along the mode 𝝁 and
a tangential vector 𝝃 ⊥ 𝝁 of lengths 𝑡 and ℎ, respectively.
Following Ulrich [38], the length 𝑡 = 𝝁ᵀx along 𝝁 (marked in blue)
is called the mixture variable. Its associated mixture density
∫
x:𝝁ᵀx=𝑡
P[x] dx,
PMix[𝑡] =
𝑡 ∈ [−1, 1],
can be evaluated as follows (proof in Appendix A.2):
Lemma 8 (Mixture density). Given a rotationally symmetric distri-
bution P with kernel function ¯P[𝑡], we can express its mixture density
PMix[𝑡] in terms of the kernel function as
PMix[𝑡] = 𝑆𝑛−2 ·(cid:0)1 − 𝑡2(cid:1) 𝑛−3
𝑡 ∈ [−1, 1].
· ¯P[𝑡],
x = cos(𝜃)𝝁 + sin(𝜃)𝝃 ,
Alternatively, by substituting 𝑡 = cos(𝜃) in Eq. (1), we can write
(2)
where 𝜃 = arccos(𝝁ᵀx) is the angle or arc length between x and
the mode 𝝁 (marked in red). The angular density of 𝜃 is as follows:
Corollary 9 (Angular density). Given a rotationally symmetric
distribution P with kernel function ¯P[𝑡], we can express its angular
density PArc[𝜃] for an angle 𝜃 ∈ [0, 𝜋] as
2
PArc[𝜃] = 𝑆𝑛−2 sin𝑛−2(𝜃) · ¯P[cos(𝜃)].
Importantly, the tangent-normal decomposition thus reduces the