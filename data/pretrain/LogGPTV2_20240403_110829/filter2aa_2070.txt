# ChatGLM-6B: Fine-Tuning and Deployment Guide

## Table of Contents
1. **Introduction**
2. **Prerequisites: Mixed Precision, ZeRO**
3. **Fine-Tuning Methods: P-tuning, Full Parameter, LoRA**
4. **Deployment with Gradio**
5. **Demo Environment Setup**
6. **Download Checkpoints**
7. **Play with ChatGLM-6B in CLI and Gradio**
8. **Fine-Tuning: Mixed Precision and ZeRO**
9. **P-tuning v2: AdGen Example**
10. **Full Parameter Fine-Tuning**
11. **FAQs and Troubleshooting**
12. **LoRA: Low-Rank Adaptation**
13. **Conclusion and Questions**

---

### 1. Introduction
This guide provides a comprehensive overview of how to fine-tune and deploy the ChatGLM-6B model. The model can be fine-tuned on consumer-grade GPUs, making it accessible for a wide range of users.

### 2. Prerequisites: Mixed Precision, ZeRO
Before proceeding, ensure you have the following prerequisites:
- **Mixed Precision**: Reduces memory usage and speeds up training.
- **ZeRO (Zero Redundancy Optimizer)**: Optimizes memory usage during training.

### 3. Fine-Tuning Methods
#### P-tuning
P-tuning is a method that saves GPU memory and training time while maintaining similar performance to full parameter fine-tuning.

#### Full Parameter
Full parameter fine-tuning updates all model parameters, which can be resource-intensive.

#### LoRA
LoRA (Low-Rank Adaptation) reduces the number of trainable parameters, making fine-tuning more efficient.

### 4. Deployment with Gradio
Gradio can be used to create a web-based interface for interacting with the fine-tuned ChatGLM-6B model.

### 5. Demo Environment Setup
- **GPU**: NVIDIA GeForce RTX 3090
- **Docker Image**: `nvidia-pytorch:22.08-py3`
- **Pip Configuration**:
  ```bash
  pip config set global.extra-index-url https://pypi.tuna.tsinghua.edu.cn/simple
  pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
  pip config set global.trusted-host https://pypi.tuna.tsinghua.edu.cn/simple
  ```

### 6. Download Checkpoints
#### Option 1: From HuggingFace Repo
1. Install `git-lfs`:
   ```bash
   git lfs install
   ```
2. Clone the repository:
   ```bash
   git clone https://huggingface.co/THUDM/chatglm-6b
   ```

#### Option 2: Manual Download
1. Clone the repository without large files:
   ```bash
   GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/THUDM/chatglm-6b
   ```
2. Download large files from Tsinghua Cloud:
   ```bash
   git clone PI:EMAIL:chenyifanthu/THU-Cloud-Downloader.git
   cd THU-Cloud-Downloader
   pip install argparse requests tqdm
   python main.py --link https://cloud.tsinghua.edu.cn/d/fb9f16d6dc8f482596c2/ --save ../chatglm-6b/
   ```

### 7. Play with ChatGLM-6B in CLI and Gradio
#### CLI
```python
# cli_demo.py
from transformers import AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True)
model = AutoModel.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True).half().cuda()

# Run
python cli_demo.py
```

#### Gradio
```python
# web_demo.py
# Specify model path
# Run
python web_demo.py
```

### 8. Fine-Tuning: Mixed Precision and ZeRO
- **Mixed Precision**: Reduces memory usage and speeds up training.
- **ZeRO**: Optimizes memory usage during training by partitioning model states.

### 9. P-tuning v2: AdGen Example
#### Dependencies
```bash
pip install rouge_chinese nltk jieba datasets
```

#### Dataset
- [Download from Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1)

#### Training
```bash
# Specify model path, dataset path & device ordinal in train.sh and evaluate.sh
bash train.sh
```

#### Evaluation
```bash
bash evaluate.sh
```

### 10. Full Parameter Fine-Tuning
- **Install DeepSpeed**:
  ```bash
  pip install deepspeed
  ```
- **Specify model and dataset in `ds_train_finetune.sh` and `evaluate_finetune.sh`**:
  ```bash
  bash ds_train_finetune.sh
  ```

### 11. FAQs and Troubleshooting
- **Broken Pipe Error**:
  - Add a lock to prevent contention:
    ```python
    with FileLock("model.lock"):
        config = AutoConfig.from_pretrained(model_args.model_name_or_path, trust_remote_code=True)
    # Repeat for tokenizer and model
    ```

### 12. LoRA: Low-Rank Adaptation
- **Overview**:
  - LoRA reduces the number of trainable parameters, making fine-tuning more efficient.
- **Implementation**:
  - Use a community implementation: [zero_nlp](https://github.com/yuanzhoulvpi2017/zero_nlp)
  - Download checkpoint: `git clone https://huggingface.co/yuanzhoulvpi/chatglm6b-dddd`
  - Fine-tune on `alpaca_chinese` dataset and adapt for `AdGen` dataset.

### 13. Conclusion and Questions
Thank you for following this guide. If you have any questions or need further assistance, feel free to ask.

---