title:SPOILER: Speculative Load Hazards Boost Rowhammer and Cache Attacks
author:Saad Islam and
Ahmad Moghimi and
Ida Bruhns and
Moritz Krebbel and
Berk G&quot;ulmezoglu and
Thomas Eisenbarth and
Berk Sunar
Spoiler: Speculative Load Hazards Boost 
Rowhammer and Cache Attacks
Saad Islam and Ahmad Moghimi, Worcester Polytechnic Institute; Ida Bruhns and 
Moritz Krebbel, University of Luebeck; Berk Gulmezoglu, Worcester Polytechnic Institute; 
Thomas Eisenbarth, Worcester Polytechnic Institute and University of Luebeck; Berk Sunar, 
Worcester Polytechnic Institute
https://www.usenix.org/conference/usenixsecurity19/presentation/islam
This paper is included in the Proceedings of the 28th USENIX Security Symposium.August 14–16, 2019 • Santa Clara, CA, USA978-1-939133-06-9Open access to the Proceedings of the 28th USENIX Security Symposium is sponsored by USENIX.SPOILER: Speculative Load Hazards Boost Rowhammer and Cache Attacks
Saad Islam1, Ahmad Moghimi1, Ida Bruhns2, Moritz Krebbel2, Berk Gulmezoglu1, Thomas Eisenbarth1, 2,
and Berk Sunar1
1Worcester Polytechnic Institute, Worcester, MA, USA
2 University of Lübeck, Lübeck, Germany
Abstract
Modern microarchitectures incorporate optimization tech-
niques such as speculative loads and store forwarding to
improve the memory bottleneck. The processor executes the
load speculatively before the stores, and forwards the data
of a preceding store to the load if there is a potential depen-
dency. This enhances performance since the load does not
have to wait for preceding stores to complete. However, the
dependency prediction relies on partial address information,
which may lead to false dependencies and stall hazards.
In this work, we are the ﬁrst to show that the dependency
resolution logic that serves the speculative load can be ex-
ploited to gain information about the physical page mappings.
Microarchitectural side-channel attacks such as Rowhammer
and cache attacks like Prime+Probe rely on the reverse engi-
neering of the virtual-to-physical address mapping. We pro-
pose the SPOILER attack which exploits this leakage to speed
up this reverse engineering by a factor of 256. Then, we show
how this can improve the Prime+Probe attack by a 4096
factor speed up of the eviction set search, even from sand-
boxed environments like JavaScript. Finally, we improve the
Rowhammer attack by showing how SPOILER helps to con-
duct DRAM row conﬂicts deterministically with up to 100%
chance, and by demonstrating a double-sided Rowhammer
attack with normal user’s privilege. The later is due to the
possibility of detecting contiguous memory pages using the
SPOILER leakage.
1 Introduction
Microarchitectural attacks have evolved over the past decade
from attacks on weak cryptographic implementations [5] to
devastating attacks breaking through layers of defenses pro-
vided by the hardware and the Operating System (OS) [52].
These attacks can steal secrets such as cryptographic keys [4,
44] or keystrokes [33]. More advanced attacks can entirely
subvert the OS memory isolation to read the memory content
from more privileged security domains [35], and to bypass
defense mechanisms such as Kernel Address Space Layout
Randomization (KASLR) [11, 17]. Rowhammer attacks can
further break the data and code integrity by tampering with
memory contents [29,47]. While most of these attacks require
local access and native code execution, various efforts have
been successful in conducting them remotely [50] or from
within a remotely accessible sandbox such as JavaScript [42].
Memory components such as DRAM [29] and cache [43]
are not the only microarchitectural attack surfaces. Spectre
attacks on the branch prediction unit [30, 38] imply that side
channels such as caches can be used as a primitive for more
advanced attacks on speculative engines. Speculative engines
predict the outcome of an operation before its completion,
and they enable execution of the following dependent instruc-
tions ahead of time based on the prediction. As a result, the
pipeline can maximize the instruction level parallelism and re-
source usage. In rare cases where the prediction is wrong, the
pipeline needs to be ﬂushed resulting in performance penal-
ties. However, this approach suffers from a security weakness,
in which an adversary can fool the predictor and introduce ar-
bitrary mispredictions that leave microarchitectural footprints
in the cache. These footprints can be collected through the
cache side channel to steal secrets.
Modern processors feature further speculative behavior
such as memory disambiguation and speculative loads [10]. A
load operation can be executed speculatively before preced-
ing store operations. During the speculative execution of the
load, false dependencies may occur due to the unavailability
of physical address information. These false dependencies
need to be resolved to avoid computation on invalid data. The
occurrence of false dependencies and their resolution depend
on the actual implementation of the memory subsystem. Intel
uses a proprietary memory disambiguation and dependency
resolution logic in the processors to predict and resolve false
dependencies that are related to the speculative load. In this
work, we discover that the dependency resolution logic suffers
from an unknown false dependency independent of the 4K
aliasing [40, 49]. The discovered false dependency happens
during the 1 MB aliasing of speculative memory accesses
USENIX Association
28th USENIX Security Symposium    621
which is exploited to leak information about physical page
mappings.
The state-of-the-art microarchitectural attacks [25, 45] ei-
ther rely on knowledge of physical addresses or are signiﬁ-
cantly eased by that knowledge. Yet, knowledge of the physi-
cal address space is only granted with root privileges. Cache
attacks such as Prime+Probe on the Last-Level Cache (LLC)
are challenging due to the unknown mapping of virtual ad-
dresses to cache sets and slices. Knowledge about the physical
page mappings enables more attack opportunities using the
Prime+Probe technique. Rowhammer [29] attacks require
efﬁcient access to rows within the same bank to induce fast
row conﬂicts. To achieve this, an adversary needs to reverse
engineer layers of abstraction from the virtual address space
to DRAM cells. Availability of physical address information
facilitates this reverse engineering process. In sandboxed en-
vironments, attacks are more limited, since in addition to the
limited access to the address space, low-level instructions
are also inaccessible [18]. Previous attacks assume special
access privileges only granted through weak software conﬁg-
urations [25,34,55] to overcome some of these challenges. In
contrast, SPOILER only relies on simple operations, load and
store, to recover crucial physical address information, which
in turn enables Rowhammer and cache attacks, by leaking
information about physical pages without assuming any weak
conﬁguration or special privileges.
1.1 Our Contribution
We have discovered a novel microarchitectural leakage which
reveals critical information about physical page mappings
to user space processes. The leakage can be exploited by a
limited set of instructions, which is visible in all Intel genera-
tions starting from the 1st generation of Intel Core processors,
independent of the OS and also works from within virtual ma-
chines and sandboxed environments. In summary, this work:
1. exposes a previously unknown microarchitectural leak-
age stemming from the false dependency hazards during
speculative load operations.
2. proposes an attack, SPOILER, to efﬁciently exploit this
leakage to speed up the reverse engineering of virtual-to-
physical mappings by a factor of 256 from both native
and JavaScript environments.
3. demonstrates a novel eviction set search technique from
JavaScript and compares its reliability and efﬁciency to
existing approaches.
4. achieves efﬁcient DRAM row conﬂicts and the ﬁrst
double-sided Rowhammer attack with normal user-level
privilege using the contiguous memory detection capa-
bility of SPOILER.
5. explores how SPOILER can track nearby load operations
from a more privileged security domain right after a
context switch.
1.2 Related Work
Kosher et al. [30] and Maisuradze et al. [38] have exploited
vulnerabilities in the speculative branch prediction unit. Tran-
sient execution of instructions after a fault, as exploited by
Lipp et al. [35] and Bulck et al. [52], can leak memory con-
tent of protected environments. Similarly, transient behavior
due to the lazy store/restore of the FPU and SIMD registers
can leak register contents from other contexts [48]. New vari-
ants of both Meltdown and Spectre have been systematically
analyzed [7]. The Speculative Store Bypass (SSB) vulnera-
bility [21] is a variant of the Spectre attack and relies on the
stale sensitive data in registers to be used as an address for
speculative loads which may then allow the attacker to read
this sensitive data. In contrast to previous attacks on specu-
lative and transient behaviors, we discover a new leakage on
the undocumented memory disambiguation and dependency
resolution logic. SPOILER is not a Spectre attack. The root
cause for SPOILER is a weakness in the address speculation of
Intel’s proprietary implementation of the memory subsystem
which directly leaks timing behavior due to physical address
conﬂicts. Existing spectre mitigations would therefore not
interfere with SPOILER.
The timing behavior of the 4K aliasing false dependency
on Intel processors have been studied [12, 61]. MemJam [40]
uses this behavior to perform a side-channel attack, and Sul-
livan et al. [49] demonstrate a covert channel. These works
only mention the 4K aliasing as documented by Intel [24],
and the authors conclude that the address aliasing check is a
two stage approach: Firstly, it uses page offset for the initial
guess. Secondly, it performs the ﬁnal resolution based on the
exact physical address. On the contrary, we discover that the
undocumented address resolution logic performs additional
partial address checks that lead to an unknown, but observable
aliasing behavior based on the physical address.
Several microarchitectural attacks have been discovered to
recover virtual address information and break KASLR by ex-
ploiting the Translation Lookaside Buffer (TLB) [22], Branch
Target Buffer (BTB) [11] and Transactional Synchronization
Extensions (TSX) [27]. Additionally, Gruss et al. [17] ex-
ploit the timing information obtained from the prefetch
instruction to leak the physical address information. The main
obstacle to this approach is that the prefetch instruction is
not accessible in JavaScript, and it can be disabled in native
sandboxed environments [62], whereas SPOILER is applicable
to sandboxed environments including JavaScript.
Knowledge of the physical address enables adversaries to
bypass OS protections [28] and ease other microarchitectural
attacks [34]. For instance, the procfs ﬁlesystem exposes
physical addresses [34], and Huge pages allocate contiguous
622    28th USENIX Security Symposium
USENIX Association
physical memory [25, 36]. Drammer [55] exploits the An-
droid ION memory allocator to access contiguous memory.
However, access to the aforementioned primitives is restricted
on most environments by default. We do not have any assump-
tion about the OS and software conﬁguration, and we exploit
a hardware leakage with minimum access rights to ﬁnd virtual
pages that have the same least signiﬁcant 20 physical address
bits. GLitch [13] detects contiguous physical pages by ex-
ploiting row conﬂicts through the GPU interface. In contrast,
our attack does not rely on a speciﬁc integrated GPU conﬁgu-
ration, and it is widely applicable to any system running on
an Intel CPU. We use SPOILER to ﬁnd contiguous physical
pages with a high probability and verify it by producing row
conﬂicts. SPOILER is particularly helpful for attacks in sand-
boxed low-privilege environments such as JavaScript, where
previous methods require a time-consuming brute forcing of
the memory addresses [18, 42, 47].
2 Background
2.1 Memory Management
The virtual memory manager shares the DRAM across all
running tasks by assigning isolated virtual address spaces to
each task. The assigned memory is allocated in pages, which
are typically 4 kB each, and each virtual page will be stored as
a physical page in DRAM through a virtual-to-physical page
mapping. Memory instructions operate on virtual addresses,
which are translated within the processor to the correspond-
ing physical addresses. The page offset comprising the least
signiﬁcant 12 bits of the virtual address is not translated. The
processor only translates the bits in the rest of the virtual
address, the virtual page number. The OS is the reference for
this translation, and the processor stores the translation results
inside the TLB. As a result, repeated translations of the same
address are performed more efﬁciently.
2.2 Cache Hierarchy
Modern processors incorporate multiple levels of caches to
avoid the DRAM access latency. The cache memory on Intel
processors is organized into sets and slices. Each set can store
a certain number of lines, where the line size is 64 bytes. The
6 Least Signiﬁcant Bits (LSBs) of the physical address are
used to determine the offset within a line and the remaining
bits are used to determine which set to store the cache line in.
The number of physical address bits that are used for mapping
is higher for the LLC, since it has a large number of sets, e.g.,
8192 sets. Hence, the untranslated part of the virtual address
bits which is the page offset, cannot be used to index the LLC
sets. Instead, higher physical address bits are used. Further,
each set of LLC is divided into multiple slices, one slice for
each logical processor. The mapping of the physical addresses
to the slices uses an undocumented function [26]. When the
processor accesses a memory address, a cache hit or miss
occurs. If a miss occurs in all cache levels, the memory line
has to be fetched from DRAM. Accesses to the same memory
address would be served from the cache unless other memory
accesses evict that cache line. In addition, we can use the
clflush instruction, which follows the same memory access
check as other memory operations, to evict our own cache
lines from the entire cache hierarchy.
2.3 Prime+Probe Attack
In the Prime+Probe attack, the attacker ﬁrst ﬁlls an entire
cache set by accessing memory addresses that are mapped
to the same set, an eviction set. Later, the attacker checks
whether the victim program has displaced any entry in the
cache set by accessing the eviction set again and measuring
the execution time. If this is the case, the attacker can de-
tect congruent addresses, since the displaced entries cause an
increased access time. However, ﬁnding the eviction sets is
difﬁcult due to the unknown translation of virtual addresses
to physical addresses. Since an unprivileged attacker has no
access to hugepages [23] or the virtual-to-physical page map-
ping such as the pagemap ﬁle [34], knowledge about the phys-
ical address bits greatly speeds up the eviction set search.
2.4 Rowhammer Attack
DRAM consists of multiple memory banks, and each bank is
subdivided into rows. When the processor accesses a memory
location, the corresponding row needs to be activated and
loaded into the row buffer. If the processor accesses the same