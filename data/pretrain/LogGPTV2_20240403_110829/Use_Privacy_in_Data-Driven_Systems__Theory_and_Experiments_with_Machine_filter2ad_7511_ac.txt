𝒫
Definition 4 (Decomposition). Given a program p, a decompo-
sition (p1, X , p2) consists of two programs p1, p2, and a fresh variable
X , such that p = [p1/X]p2.
For the purposes of our proxy use definition we view the first
component p1 as the intermediate computation suspected of proxy
use, and p2 as the rest of the computation that takes in p1 as an
input.
Definition 5 (Influential Decomposition). Given a program
p, a decomposition (p1, X , p2) is influential iff X is influential in p2.
Main definition
𝒫
Definition 6 (Proxy Use). A program ⟨X, p⟩
has proxy use of
Z if there exists an influential decomposition (p1, X , p2) of ⟨X, p⟩
,
𝒫
and(cid:74)p1(cid:75)(X) is a proxy for Z.
Example 3.6. In Figure 1d, this definition would identify proxy
use using the decomposition (p1, U , p2), where p2 is the entire tree,
but with the condition (a1, a2 ∈ purchases) replaced by the variable
U . In this example, U is influential in p2, since changing the value
of U changes the outcome. Also, we assumed that the condition
(a1, a2 ∈ purchases) is a perfect predictor for pregnancy, and is
therefore a proxy for pregnancy. Therefore, according to our def-
inition of proxy use, the model in 1d has proxy use of pregnancy
status.
3.4 A Quantitative Relaxation
Definition 6 is too strong in one sense and too weak in another.
It requires that intermediate computations be perfectly correlated
with a protected attribute, and that there exists some input, however
improbable, in which the result of the intermediate computation is
relevant to the model. For practical purposes, we would like to cap-
ture imperfect proxies that are strongly associated with an attribute,
but only those whose influence on the final model is appreciable. To
relax the requirement of perfect proxies and non-zero influence, we
quantify these two notions to provide a parameterized definition.
Recognizing that neither perfect privacy nor perfect utility are prac-
tical, the quantitative definition provides a means for navigating
privacy vs. utility tradeoffs.
ϵ-proxies We wish to measure how strongly a random variable
X is a proxy for a random variable Z. Recall the two key require-
ments from the earlier definition of a proxy: (i) the association
needs to be capture equivalence and measure association in both
directions, and (ii) the association needs to be invariant under re-
naming of the random variables. The variation of information metric
dvar(X , Z) = H(X|Z) + H(Z|X) [12] is one measure that satisfies
these two requirements. The first component in the metric, the
conditional entropy of X given Z, H(X|Z), measures how well X
can be predicted from Z, and H(Z|X) measures how well Z can be
predicted from X, thus satisfying the requirement for the metric
measuring association in both directions. Additionally, one can
show that conditional entropies are invariant under renaming, thus
satisfying our second criteria. To obtain a normalized measure in
[0, 1], we choose 1− dvar(X,Z)
H(X,Z) as our measure of association, where
the measure being 1 implies perfect proxies, and 0 implies statistical
independence. Interestingly, this measure is identical to normal-
ized mutual information [12], a standard measure that has also
been used in prior work in identifying associations in outcomes of
machine learning models [63].
Definition 7 (Proxy Association). Given two random variables
X and Z, the strength of a proxy is given by normalized mutual
information,
d(X , Z) def
= 1 − H(X|Z) + H(Z|X)
H(X , Z)
where X is defined to be an ϵ-proxy for Z if d(X , Z) ≥ ϵ.
We do not present the complexity of association computation
independently of detection as we rely on pre-computations to re-
duce the amortized runtime of the entire detection algorithm. The
complexity as part of our detection algorithm is discussed in Ap-
pendix E.2.
δ-influential decomposition Recall that for a decomposition
(p1, X , p2), in the qualitative sense, influence is interference which
Here x1, x2 are values of p1, that for a given x, change the outcome of
p2. However, this definition is too strong as it requires only a single
pair of values x1, x2 to show that the outcome can be changed
by p1 alone. To measure influence, we quantify interference by
using Quantitative Input Influence (QII), a causal measure of input
influence introduced in [14]. In our context, for a decomposition
implies that there exists x, x1, x2, such that(cid:74)p2(cid:75)(x, x1) (cid:44)(cid:74)p2(cid:75)(x, x2).
= EX,X′ $←𝒫
Pr(cid:0)(cid:74)p2(cid:75)(X,(cid:74)p1(cid:75)(X)) (cid:44)(cid:74)p2(cid:75)(X,(cid:74)p1(cid:75)(X′))(cid:1) .
(p1, X , p2), the influence of p1 on p2 is given by:
ι(p1, p2) def
Intuitively, this quantity measures the likelihood of finding ran-
domly chosen values of the output of p1 that would change the
outcome of p2. Note that this general definition allows for proba-
bilistic models though in this work we only evaluate our methods
on deterministic models.
The time complexity of influence computation as part of our
detection algorithm can be found in Appendix E.2, along with
discussion on estimating influence.
Definition 8 (Decomposition Influence). Given a decomposi-
tion (p1, X , p2), the influence of the decomposition is given by the QII
of X on p2. A decomposition (p1, X , p2) is defined to be δ-influential
if ι(p1, p2) > δ.
(ϵ, δ)-proxy use Now that we have quantitative versions of the
primitives used in Definition 6, we are in a position to define quan-
titative proxy use (Definition 9). The structure of this definition is
the same as before, with quantitative measures substituted in for
the qualitative assertions used in Definition 6.
𝒫
Definition 9 ((ϵ, δ)-proxy use). A program ⟨X, p⟩
has (ϵ, δ)-
proxy use of random variable Z iff there exists a δ-influential decom-
position (p1, X , p2), such that(cid:74)p(cid:75)(X) is an ϵ-proxy for Z.
This definition is a strict relaxation of Definition 6, which reduces
to (1, 0)-proxy use.
3.5 Axiomatic Basis for Definition
We now motivate our definitional choices by reasoning about a
natural set of properties that a notion of proxy use should satisfy.
We first prove an important impossibility result that shows that no
definition of proxy use can satisfy four natural semantic properties
of proxy use. The central reason behind the impossibility result is
that under a purely semantic notion of function composition, the
causal effect of a proxy can be made to disappear. Therefore, we
choose a syntactic notion of function composition for the definition
of proxy use presented above. The syntactic definition of proxy use
is characterized by syntactic properties which map very closely to
the semantic properties.
Property 1. (Explicit Use) If Z is an influential input of the model
⟨{X, Z},𝒜⟩
𝒫
, then ⟨{X, Z},𝒜⟩
𝒫
has proxy use of Z.
This property identifies the simplest case of proxy use: if an
input to the model is influential, then the model exhibits proxy use
of that input.
Property 2. (Preprocessing) If a model ⟨{X, X},𝒜⟩
use of random variable Z, then for any function f such that Pr(f (X) = X) =
1, let 𝒜′(x) def
= 𝒜(x, f (x)). Then, ⟨X,𝒜′⟩
has proxy use of Z.
has proxy
𝒫
𝒫
This property covers the essence of proxy use where instead of
being provided a protected information type explicitly, the program
uses a strong predictor for it instead. This property states that
models that use inputs explicitly and via proxies should not be
differentiated under a reasonable theory of proxy use.
, define 𝒜′ such that for
Property 3. (Dummy) Given ⟨X,𝒜⟩
𝒫
= 𝒜(x), then ⟨X,𝒜⟩
has proxy use for some Z
𝒫
has proxy use of Z.
all x, x′, 𝒜′(x, x′) def
iff ⟨{X, X},𝒜′⟩
𝒫
This property states that the addition of an input to a model that
is not influential, i.e., has no effect on the outcomes of the model,
has no bearing on whether a program has proxy use or not. This
property is an important sanity check that ensures that models
aren’t implicated by the inclusion of inputs that they do not use.
Property 4. (Independence) If X is independent of Z in 𝒫, then
⟨X,𝒜⟩
𝒫
does not have proxy use of Z.
Independence between the protected information type and the
inputs ensures that the model cannot infer the protected informa-
tion type for the population 𝒫. This property captures the intuition
that if the model cannot infer the protected information type then
it cannot possibly use it.
While all of these properties seem intuitively desirable, it turns
out that these properties can not be achieved simultaneously.
Theorem 1. No definition of proxy use can satisfy Properties 1-4
simultaneously.
See Appendix A for a proof of the impossibility result and a
discussion. The key intuition behind this result is that Property 2
requires proxy use to be preserved when an input is replaced with a
function that predicts that input via composition. However, with a
purely semantic notion of function composition, after replacement,
the proxy may get canceled out. To overcome this impossibility
result, we choose a more syntactic notion of function composition,
which is tied to how the function is represented as a program, and
looks for evidence of proxy use within the representation.
We now proceed to the axiomatic justification of our definition
of proxy use. As in our attempt to formalize a semantic definition,
we base our definition on a set of natural properties given below.
These are syntactic versions of their semantic counterparts defined
earlier.
Property 5. (Syntactic Explicit Use) If X is a proxy of Z, and X
has proxy
is an influential input of ⟨{X, X}, p⟩
use.
, then ⟨{X, X}, p⟩
𝒫
Property 6. (Syntactic Preprocessing) If ⟨{X, X}, p1⟩
𝒫
use of Z, then for any p2 such that Pr((cid:74)p2(cid:75)(X) = X) = 1, ⟨X,[p2/X]p1⟩
has proxy
has proxy use of Z.
𝒫
𝒫
Property 7. (Syntactic Dummy) Given a program ⟨X, p⟩
has proxy use for some Z iff ⟨{X, X}, p⟩
, ⟨X, p⟩
𝒫
𝒫
has proxy use of Z.
𝒫
Property 8. (Syntactic Independence) If X is independent of Z,
then ⟨X, p⟩
𝒫
does not have proxy use of Z.
Properties 5 and 6 together characterize a complete inductive
definition, where the induction is over the structure of the program.
Suppose we can decompose programs p into (p1, X , p2) such that
p = [p1/X]p2. Now if X, which is the output of p1, is a proxy
for Z and is influential in p2, then by Property 5, p2 has proxy
use. Further, since p = [p1/X]p2, by Property 6, p has proxy use.
This inductive definition where we use Property 5 as the base
case and Property 6 for the induction step, precisely characterizes
Definition 6. Additionally, it can be shown that Definition 6 also
satisfies Properties 7 and 8. Essentially, by relaxing our notion
of function composition to a syntactic one, we obtain a practical
definition of proxy use characterized by the natural axioms above.
Algorithm 1 Detection for expression programs.
Require: association (d), influence(ι) measures
procedure ProxyDetect(p, X, Z , ϵ, δ)
P ← ∅
for each subprogram p1 appearing in p do
for each program p2 such that [p2/u]p1 = p do
if ι(p1, p2) ≥ δ ∧ d((cid:74)p1(cid:75)(X), Z) ≥ ϵ then
P ← P ∪ {(p1, p2)}
return P
4 DETECTING PROXY USE
In this section, we present an algorithm for identifying proxy use of
specified variables in a given machine-learning model (Algorithm 1,
Appendix B contains a more formal presentation of the algorithm
for the interested reader). The algorithm is program-directed and
is directly inspired by the definition of proxy use in the previous
section. We prove that the algorithm is complete in a strong sense —
it identifies every instance of proxy use in the program (Theorem 3).
We also describe three optimizations that speed up the detection
algorithm: sampling, reachability analysis, and contingency tables.
4.1 Environment Model
The environment in which our detection algorithm operates is
comprised of a data processor, a dataset that has been partitioned
into analysis and validation subsets, and a machine learning model
trained over the analysis subset. We assume that the data processor
does not act to evade the detection algorithm, and the datasets
correspond to a representative sample from the population we wish
to test proxy use with respect to. Additionally, we assume that
information types we wish to detect proxies of are also part of the
validation data. We discuss these points further in Section 8.
For the rest of this paper we focus on an instance of the proxy use
definition, where we assume that programs are written in the simple
expression language shown in Figure 2. However, our techniques
are not tied to this particular language, and the key ideas behind
them apply generally. This language is rich enough to support
commonly-used models such as decision trees, linear and logis-
tic regression, Naive Bayes, and Bayesian rule lists. Programs are
functions that evaluate arithmetic terms, which are constructed
from real numbers, variables, common arithmetic operations, and
if-then-else (ite(·, ·, ·)) terms. Boolean terms, which are used as con-
ditions in ite terms, are constructed from the usual connectives
and relational operations. Finally, we use λ-notation for functions,
i.e., λx .e denotes a function over x which evaluates e after replac-
ing all instances of x with its argument. Details on how machine
learning models such as linear models, decision trees, and random
forests are translated to this expression language are discussed in
Appendix B.2 and consequences of the choice of language and de-
composition in that language are further discussed in more detail
in Section 8.
Distributed proxies Our use of program decomposition pro-
vides for partial handling of distributed representations, the idea
that concepts can be distributed among multiple entities. In our
case, influence and association of a protected information type can
be distributed among multiple program points. First, substitution
ite(⟨bexp⟩, ⟨aexp⟩, ⟨aexp⟩)
⟨aexp⟩ ::= R | var | op(⟨aexp⟩, . . . , ⟨aexp⟩)
|
⟨bexp⟩ ::= T | F | ¬ ⟨bexp⟩
| op(⟨bexp⟩, . . . , ⟨bexp⟩)
relop(⟨aexp⟩, ⟨aexp⟩)
|
⟨prog⟩ ::= λvar1, . . . , varn . ⟨aexp⟩
Figure 2: Syntax for the language used in our analysis.
(denoted by [p1/X]p2) is defined to replace all instances of vari-
able X in p2 with the program p1. If there are multiple instances
of X in p2, they are still describing a single decomposition and
thus the multiple instances of p2 in p1 are viewed as a single proxy.
Further, implementations of substitution can be (and is in our im-
plementation) associativity-aware: programs like x1 + x2 + x3 can