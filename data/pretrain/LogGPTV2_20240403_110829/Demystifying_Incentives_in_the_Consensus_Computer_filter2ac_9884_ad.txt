Although the total veriﬁcation work that the ε-consensus
computer has to do is the same regardless of whether we use
a single or multiple scripts, splitting the task guarantees a
correct outcome because the ε-consensus computer correctly
veriﬁes smaller. We illustrate an alternative implementation
for outsourcing matrix multiplication in n2 steps where Wtx
is O(n) in Figure 5 (instead of 1 transaction where Wtx is
O(n3) as in Figure 4).
The execution of the contract in Figure 5 works as follows.
P ﬁrst submits C to the contract as the solution for A × B.
Figure 5: Matrix multiplication with O(n) work per transaction
on a consensus computer.
The veriﬁcation happens across the next n2 steps when P
sends n2 transactions to the contract. Each transaction ver-
iﬁes a particular and diﬀerent element Ci,j of the submitted
result. A counter stores the number of passed checks (Lines
13–15).
Advantage across multiple transactions. A careful
reader may be concerned that a rational miners might recog-
nize the global connection between the n2 transactions and
skip verifying all of them to gain an advantage. However,
the advantage from skipping the veriﬁcation of transactions
in the i-th block only helps the miners ﬁnd the (i + 1)-th
block faster. In other words, one cannot “save” the “unspent”
advantage in skipping the veriﬁcation in one block and use
that in the future since the competition for ﬁnding a new
block “restarts” after every block. Essentially, we amortize
the advantage of the computation across multiple transac-
tions and blocks such that at any given block, the advantage
of rational miners is bounded by εWblk. Thus our approach
does not break the incentive compatibility of the ε-consensus
computer model.
Depending on the nature of the application, multiple steps
can either happen in parallel or must be executed sequen-
tially. For example in matrix multiplication, P can send
simultaneously n2 transactions. The reason is verifying Ci,j
does not rely on the correctness of Ci,j−1, and the order of
verifying the two elements does not matter. On the other
hand, if, say, Ci,j = 2· Ci,j−1, the prover would have to wait
until Ci,j−1 gets veriﬁed before sending the next transac-
tion which veriﬁes Ci,j. In section 6, we illustrate these two
scenarios with case studies.
4.3.2 Approximate consensus computation
Our second approach avoids the latency of sequential com-
putation processes by employing probabilistic, light-weight
veriﬁcation. This approach will guarantee the correctness
of the solution to a certain (adjustable) extent while only
having to check a small portion of the solution.
Deﬁnition 6. Let us denote a problem Z : {0, 1}n →
{0, 1}m, an input x ∈ {0, 1}n and a claimed solution y(cid:48) ∈
{0, 1}m of Z(x). We say Z is (δ, λ)-approximate veriﬁable if
there exists a veriﬁcation function f such that f accepts y(cid:48)
only if y(cid:48) diﬀers from Z(x) in at most δ bits with probability
greater than λ.
Our task is to encode f to ensure that if a solution y(cid:48) is
deemed correct only when y(cid:48) does not diﬀer much from the
correct solution, i.e., diﬀerent in at most δ bits. Further-
more, in order to run f in a ε-consensus computer model, f
should not require more than Wtx work to ﬁnish. The high
level insight to encode such a f is that by randomly sampling
and checking an entry of the output, there is some proba-
bility that we can detect if the output is incorrect at that
sample. If we ﬁnd an incorrect sample, we can conclude that
the submitted solution is wrong and reject the solution. The
more samples we take, the better the probability of catching
an error. Otherwise, the solution is close to a correct one
with an overwhelming probability greater than λ.
In Deﬁnition 6, we avoid deﬁning too precisely the notion
of “bits” and distance between two solutions since they vary
slightly on speciﬁc encoding of the veriﬁcation function f .
One can translate “bits” as the positions in an array, or the
pairs of elements, where the solution diﬀers. In either case,
the fraction of errors δ would change accordingly to the deﬁ-
nition of “bit.” For example, in the case of sorting, each “bit”
would correspond to a pair (i, j) where i  y(cid:48)[j].
We borrow the above sampling idea from the property
testing literature which shows that in many practical in-
stances one can determine whether a large object has a de-
sired property by inspecting a small number of samples [29,
30]. For instance, property testing is a technique which al-
lows a veriﬁer to sample the output to decide whether an
array is sorted. Property testing diﬀers from veriﬁable com-
putation, however, in that veriﬁable computation deals with
general computations whereas property testing can only con-
sider decision problems. Decision problems are not inter-
esting for consensus veriﬁability because without doing any
work a prover P can simultaneously post two solutions, “0”
and “1,” and one of these is guaranteed to be correct. Such
an answer shifts the entire burden of computation onto the
veriﬁer unless the prover also provides some certiﬁcate which
helps the veriﬁer to check his answer more quickly. To use
property testing in veriﬁable computation, we need to check
the two following properties:
• Property 1. The provided solution diﬀers in at most
δ-bits from a solution that satisﬁes the property of the
computation with high probability.
• Property 2. The provided solution is computed from
the given input x with high probability.
Note that given a particular number of samples, the correct-
nesses that we can guarantee for Property 1 and Property 2
are diﬀerent. For example, in the case of sorting a n-element
array, n random samples may be suﬃcient to check whether
the provided solution has the same elements as the given
array with a 1 − λ = 99% guarantee (Property 2). However,
it may take more than n samples to fully check if the pro-
vided solution is sorted (Property 1). Thus, to achieve the
overall 99% guarantee of correctness for both Property 1 and
Property 2, the number of samples one must take is the max-
imum of the numbers of samples to attain 99% guarantee of
correctness for either of the checks.
5.
IMPLEMENTATION
In this section we discuss the challenges while encoding a
veriﬁcation function f in our ε-consensus computer model.
We further discuss techniques to address those challenges.
5.1 Challenges in implementation
The presence of contract and Turing-complete language
in Ethereum enables a veriﬁable computing environment in
which users can ask anyone to solve their problem and get
the results veriﬁed by the network. We have established how
to encode those veriﬁcation computations f in Section 4.2 to
work with our ε-consensus computer model. In fact, P can
do the computation to arrive at the solution on his physical
computer. G encodes the veriﬁcation function f such that
it takes P’s solution and auxiliary data for the veriﬁcation
process. For example, if G asks P to sort an array, G can
encode f to ask P to provide the sorted array (result) with
the map between the result and the input. Our previous
contract in Figure 5 is a concrete example where the matrix
multiplication is outsourced to the network. We summarize
the properties such a contract in our ε-consensus computer
model can achieve.
1. Correctness. G receives correct results.
2. No prior trust. No pre-established trust between P
and G is required.
3. No interaction. No interaction between P and G is
required in order to verify the result.
4. Eﬃciency. G and P have to do only a modest amount
of work.
5. Fairness. P is rewarded for a valid solution.
Properties 1–4 are immediate when we encode the veriﬁca-
tion function f in our ε-consensus computer model. Speciﬁ-
cally, correctness is guaranteed since miners are incentivized
to verify all computation. P and G do not need to trust or
know each other, yet G cannot deviate after knowing the
result. However, there are several challenges while imple-
menting those veriﬁcation function using smart contracts.
In fact, simple smart contracts like the one in Figure 5 can-
not guarantee fairness property due to one of the challenges
that we describe below.
• Insecure relay attack. Once P ﬁnds a solution C,
he broadcasts a transaction having C to his neighbors
and to the whole network. However, since the solution
is in the plaintext, a rational neighbor node may copy
C, delay or even discard the prover’s transaction and
forge a new transaction to claim the reward.
• How to randomly sample in Ethereum? In order
to verify computations via sampling, we need a mech-
anism for generating random numbers. We want to
make sure that the random generator is unbiased in
seed selection, and that the seed is unpredictable. If it
is biased or predictable, the correctness property may
be violated since P can submit a solution which is cor-
rect only in the “bits” that will be sampled. Ethereum
does not natively support a random generator opera-
tor. We discuss our solution in Section 5.2.
Another desirable property of a random generator is
that it should be consistent across the network, i.e., it
should return the same sample set to everyone. Oth-
erwise an honest miner M could verify that a solution
Commitment: TX b
from: Prover
to: contract CT
data: TX a’s ID
commit
Contract: CT
1. Accept commitment
2. Accept solution C
Solution: TX a
from: Prover
to: contract CT
data: matrix C
release
3. Verify C
4. Send reward
Figure 6: The commitment scheme used in our outsourced com-
putation case studies. CT accepts the commitment in transaction
TX b before recieving solution in TX a. That means P should see
TX b in the blockchain before he broadcasts TX a to CT .
is correct with his samples but the other miners see
it incorrect since they have a diﬀerent sets of sam-
ples. Although M is honest, the other miners reject
his block because with their sample sets M ’s transac-
tion including his solution is invalid. It is unfair for
M and problematic for the network as a whole since
network consensus then becomes probabilistic.
One na¨ıve approach to defeat the insecure relay attack
above is for the prover P to encrypt and sign his solution
since a key management system already exists in Ethereum.
Unfortunately this does not work since every miner needs
to access P’s solution in order to verify the corresponding
puzzle. In the next section, we devise a commitment scheme
which helps us obtain fairness and discuss how to implement
all the necessary components in our ε-consensus computer
protocol.
5.2 Construction
We now resolve the bullet points raised above in Sec-
tion 5.1.
Achieving fairness via a commitment scheme. A
commitment scheme provides two important features. First,
it ensures that other users cannot see, thus steal P’s solution
and claim the reward. Second, P once commits a solution
cannot later alter it. This is to prevent some prover from
submitting a fake answer to win the race with others (since
only one prover is paid for correct solution), then spending
more time computing the correct solution.
Our commitment scheme leverages the one-way hash func-
tion SHA2, which is already used in current cryptocurrencies
to compute proof-of-work and transaction ID’s. Speciﬁcally,
we ask P to prepare a transaction TX a that he includes
his solution, and a transaction TX b to commit TX a to the
contract. P ﬁrst sends TX b, which includes TX a’s ID, to
the contract to say that he has the solution and will send
that in the next transaction TX a—commit phase. Once the
contract accepts P’s commitment, he sends TX a and pro-
ceeds further as in without having the commitment—release
phase. Our commitment scheme is shown in Figure 6.
Since an ID is computed by crytographically hashing the
transaction data, other miners by observing TX a’s ID in
TX b are not able to construct TX a to get C. Moreover, P
cannot alter TX a by a diﬀerent solution since doing that will
raise a conﬂict between the committed ID and the new one.
In addition, once TX b gets accepted and P broadcasts TX a,
the neighbors cannot claim the rewards with the solution
observed in TX a. This is because the contract is waiting for
transaction TX a which has been committed before.
Random sampling in Ethereum. Recall that for prob-
abilistic veriﬁcation, we need a psuedo random generator to
randomly sample elements in a solution. Our key idea is
to leverage some data in future blocks that miners do not
know and cannot predict at the time of creating the trans-
action/contract. For instance, the randomness source can
be the hash of the next block. Given a pseudo-random vari-
able R as the next block hash, one can generate n other
pseudo-random numbers simply by taking a hash as:
SHA256(R || i)
in which 1 ≤ i ≤ n, and || is a concatenation operator.
Since the information of a block is public and consistent in
the network, all miners when run the above pseudo-random
generator will get the same set of samples, thus achieving
consistency. Further, the information of block is unknown
before it is mined by miners, coupling with the random-
ness of SHA256 function makes our pseudo-random generator
fair.
6. CASE STUDIES
In this section, we exhibit several problems that can be
solved by using our ε-consensus computer model. We are
interested in the problems that require high computational
resource to verify if are encoded na¨ıvely without using our
techniques discussed in Section 4.2. The purpose of those
examples is to illustrate the practicality of our techniques,
and also describe how to encode f for various δ-approximate
verifable problems. Our examples consists of several prob-
lems in diverse domains such as Graph Theory, Linear Al-
gebra, Number Theory and simple operations like matrix
multiplication and sorting. In several of these cases we are
able to easily verify whether a solution is correct. However,
for several interesting problems verifying the correctness of a
solution appears to be elusive. We try to circumvent this dif-
ﬁculty by taking a recourse in an approximate veriﬁability.
We illustrate how one can encode the veriﬁcation function
f to employ the light-weight veriﬁcation and approximately
verify the correctness of several problems. For the conve-
nience of readers, we list our case studies in Table 1.
In
this section, we consider the basic operations as basic arith-
metic operations, e.g., addition, multiplication and compar-
ison over 32-bit integers, unless otherwise stated.
6.1 Exact computations
We show several applications that we can encode f to
guarantee the correctness of a solution in an ε-consensus
computer model. We also discuss the potential high latency
due to the need of distributing the computation to multiple
transactions.
6.1.1 GCD of Large Numbers