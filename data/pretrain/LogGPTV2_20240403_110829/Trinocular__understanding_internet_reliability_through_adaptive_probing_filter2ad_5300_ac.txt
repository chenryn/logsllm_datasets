### Network Target List and A-Estimation Updates

Our system updates the target list and A-estimations every two months as new long-term data becomes available. At shorter timescales, we must handle or adapt when parameter estimates diverge from reality. Underestimating \( E(b) \) (the expected number of responsive addresses in a block) misses an opportunity to spread traffic over more addresses. Underestimating \( A(E(b)) \) (the availability of responsive addresses) reduces the weight of each probe. In both cases, these errors slightly affect performance but do not impact correctness.

When \( E(b) \) is too large due to the inclusion of non-responsive addresses, it is equivalent to overestimating \( A(E(b)) \). If \( A(E(b)) \) exceeds the actual availability, negative probes are given too much weight, leading to incorrect inference of outages. Ideally, \( A(E(b)) \) should evolve as a side-effect of probing to avoid false outages when it diverges from the long-term average. Currently, our system does not track \( A \) dynamically (although work is underway), so we detect divergence in post-processing and identify and discard inaccurate blocks. This results in increased traffic but fewer false outages.

### Traffic Considerations

We do not count long-term observations against Trinocular’s traffic budget since it is an ongoing effort independent of our outage detection. However, even if we take responsibility for all traffic needed to build the history, it adds only 0.18 probes per hour per /24 block, as collection is spread over two months.

### Outage Scope from Multiple Locations

A single site provides only one view of the Internet, and prior work has shown that about two-thirds of outages are partial. We use two approaches to determine outage scope: detecting and eliminating outages where probers are effectively off the network, and merging views from multiple observers to distinguish between partial and global outages. In §7.1, we report on the frequency of these occurrences in the Internet.

#### Prober-Local Outages

Router failures immediately upstream of a prober can misleadingly suggest that nearly the entire Internet is down. We detect and account for outages that affect more than half the probed blocks.

#### Partial and Global Outages

We determine outage scope by merging observations from multiple vantage points. Since each site operates independently and observations tend to occur at multiples of a round, direct comparison of results from different sites can show timing differences of up to one round. We correct these differences by taking the earlier of two changes, as periodic probes always delay detection of a change in block status. We correct disagreements in the merged results only when:
- Both sites agree before and after the disagreement,
- The disagreement lasts less than 1.1 rounds,
- The network changes state before and after the disagreement.

Rules (a) and (b) detect transient disagreements likely caused by phase differences. Rule (c) avoids incorrectly changing very short outages local to one vantage point. Merging results thus improves precision. After correction, any remaining disagreement represents partial outages.

### Operational Issues

Our system implementation considers operational issues to ensure it does not harm the Internet.

#### Probing Rate

In addition to per-block limits, we rate-limit all outgoing probes to 20k probes/s using a simple token bucket. Rate limiting at the prober ensures we do not overwhelm our first-hop router and provides a fail-safe mechanism. In practice, we have never reached this limit. This limit is spread across all targets, and Figure 4 shows that only a tiny fraction of this traffic is seen at each target block.

We expect our monitor to run indefinitely, so we have implemented a simple checkpoint/restart system that saves the current belief about the network. This mechanism accommodates service on the probing machine. We restart our probers every 5.5 hours as a form of garbage collection. We have run Trinocular for several multi-day periods and expect to run it continuously when adaptive computation of \( A \) is added.

#### Implementation

We use a high-performance ICMP probing engine that can handle thousands of concurrent probes. Memory-optimized data structures keep state for each block, with CPU cost primarily for matching probe replies with the relevant block. A single prober can sustain 19k probes/s on one core of our 4-core Opteron. Probing parallelizes easily, and with four concurrent probers, a single modest computer can track all outages on the analyzable IPv4 Internet.

### Validating Our Approach

We validate correctness with controlled experiments and probe rate through simulation and Internet experiments.

#### Correctness of Outage Detection

We first explore the correctness of our approach: if an outage occurs, do we always see it? For a controlled evaluation, we run Trinocular and probe 4 /24 blocks at our university from three sites: our site in Los Angeles, and universities 1600 km and 8800 km distant in Colorado and Japan. We control these blocks and configure them in a two-hour cycle where the network is up for 30 minutes, goes down at some random time in the next 20 minutes, stays down for a random duration between 0 and 40 minutes, then comes back up. This cycle ensures Trinocular will reset between controlled outages. We studied these blocks for 122 cycles, yielding 488 observations as dataset \( A_{\text{controlled}} \), combining data for 4 controlled blocks from datasets \( A_{1w} \) (2013-01-19, 4 days), \( A_{3w} \) (2013-01-24, 1 day), \( A_{4w} \) (2013-01-25, 2 days), and \( A_{7w} \) (2013-02-12, 2 days).

Figure 2 shows these experiments, with colored areas showing observed outage duration rounded to integer numbers of rounds. We group true outage duration on the x-axis into rounds with dotted black lines. Since periodic probing guarantees we test each network every round, we expect to find all outages that last at least one round or longer. We also see that we miss outages shorter than a round roughly in proportion to outage duration (the white region of durations less than 11 minutes). While these experiments are specific to blocks where addresses always respond (\( A(E(b)) = 1 \)), they generalize to blocks with \( A \geq 0.3 \) since we later show that we take enough probes to reach a definitive conclusion for these blocks (Figure 1).

These results confirm what we expect based on our sampling schedule: if we probe a block with \( A \geq 0.3 \), we always detect outages longer than one round.

#### Precision of Event Timing

Figure 2 shows we do detect outages. We next evaluate the precision of our observed outage durations. We continue with dataset \( A_{\text{controlled}} \) in Figure 3, comparing ground truth outage duration against observed outage duration at second-level precision. Our system measures block transition events with second-level precision, but when we examine outage durations, we see they group into horizontal bands around multiples of the round duration, not the diagonal line that represents perfect measurement. We also see that error in each case is uniformly distributed with error plus or minus one-half round. As expected, we miss some outages that are shorter than a round; we show these as red circles at duration 0. Finally, we also see a few observations outside bands, both here and marked with an asterisk in Figure 2. These are cases where checkpoint/restart stretched the time between two periodic probes.

These results are consistent with measurement at a fixed probing interval sampling a random process with a uniform timing. When we compare observed and real event start- and end-times, it confirms this result, with each transition late with a uniform distribution between 0 and 1 round. These experiments use blocks where addresses are always responsive (\( A(E(b)) = 1 \)). We carried out experiments varying \( A \) from 0.125 to 1 and can confirm that we see no missed outages longer than one round and similar precision as long as Trinocular can reach a conclusion (\( A > 0.3 \)). Greater precision is possible by reducing the round duration, given more traffic.

#### Probing Rate

Our goal is good precision with low traffic, so we next validate the traffic rate. We use simulation to explore the range of expected probing rates, then confirm these based on our Internet observations.

**Parameter Exploration:** We first use simulation to explore how many probes are needed to detect a state change, measuring the number of probes needed to reach conclusive belief in the new state. Our simulation models a complete block (\( |E(b)| = 256 \)) that transitions from up-to-down or down-to-up. When up, all addresses respond with probability \( A(E(b)) \). When down, we assume a single address continues to reply positively (the worst case outage for detection).

Figure 1 shows the up-to-down and down-to-up costs. Down-to-up transitions have high variance and therefore have boxes that show quartiles and whiskers at 5%ile and 95%ile values. Up-to-down transitions typically require several probes because Trinocular must confirm a negative response is not an empty address or packet loss, but they have no variance in these simulations. Trinocular reaches a definitive belief and a correct result in 15 probes for all blocks with \( A > 0.3 \). For down-to-up transitions, 15 probes are sufficient to resolve all blocks in 50% of transitions when \( A > 0.15 \), and in 95% of transitions when \( A > 0.3 \). Variance is high because, when \( A \) is small, one will probe many unused addresses before finding an active one. This variance motivates recovery probing (the black “still down” line).

**Experimentation:** To validate these simulations, Figure 4 shows probe rates from \( A_{7w} \), a 48-hour run of Trinocular on 3.4M Internet-wide, analyzable blocks starting 2013-02-12 T14:25 UTC. Here we examine the subset \( A_{7w-5.5h} \) from this data: the first 5.5 hours (30 rounds) from one of the four probers, with 1M blocks; other subsets are similar. As expected, in most rounds, most blocks finish with just a few probes: about 73% use 4 or fewer per round. This distribution is skewed, with a median of 13.2 probes/hour, but a mean of 19.2 probes/hour, because a few blocks (around 0.18%) reach our probing limit per round. Finally, we report that 0.15% of blocks actually show more than expected traffic (the rightmost peak on the graph). We find that a small number of networks generate multiple replies in response to a single probe, either due to probing a broadcast address or a misconfiguration. We plan to detect and blacklist these blocks.

This experiment shows we meet our goals of generating only minimal traffic, with probing at 0.4% (median) to 0.7% (mean) of background radiation, and bounding traffic to each block.

**Probe Rate as a Function of \( A(E(b)) \):** The above experiment shows most blocks require few probes, and our simulations show probe rate at transition depends strongly on address responsiveness. To verify this relationship, Figure 5 breaks down probes required by transition type and each block’s \( A(E(b)) \).

The dotted line and thick quartile bars show aggregate performance across all states. We track blocks with \( A > 0.3 \) with less than 4 probes per round, with relatively low variance.

**Intermittent Blocks (A = 85 p/h):** Our strategy samples per /24 which addresses, precision, and recall. Table 2 compares the precision and recall of different probing targets. Dataset: \( S_{50j} \).

**Effect on Outage Detection:** To evaluate the impact of probing choice on outages, we examine a single dataset with three choices of probe target. We use Internet survey "it50j" [13], a 2-week ICMP probing of all addresses in 40k /24 blocks starting 2012-10-27 (here called \( S_{50j} \)). We define any response in probes to all addresses as ground truth since it is the most complete. We define a false outage (fo) as a prediction of down when it’s really up in all-probing, with analogous definitions of false availability (fa), true availability (ta), and true outages (to). We then compute precision (ta/(ta + fa)) and recall (ta/(ta + fo)).

Table 2 compares these design choices. Here we focus on the effect of the number of targets on precision and recall. While precision is uniformly good (inference of "up" is nearly always correct), recall suffers because there are many false outages. We conclude that probing one target (single and hitlist cases) has lower recall. The problem is that in some cases, a single target may not be representative of the entire block.