10%
0%
Product Division1 P11
Secure Coding Practices Completion Summary
P12
P13
P14
P15
P16
Product Division2 P21
P22
P23
P24
P25
P26
P32
P33
P44
P55
Product Division3 P31
Development Organization
Figure 2.   OSCS Training Completion Status – Pre-OSOC Meeting 
To reiterate that  this  was  not  intended  to be  a  “gotcha” 
exercise, Oracle Global Product Security: 
•  Published  the  then-current  scorecard  about  two 
months  in  advance  of  the  semi-annual  Oracle 
security  oversight  committee  meeting  at  which  the 
numbers would be reported 
•  With  a  notation  that  the  final  results  would  be 
•  And  a  reminder  that  the  class  was  mandatory  for 
most  of  development  (individual  managers  were 
reminded of the specific names of those who worked 
for them who had to take the class) 
•  And a request to comply  with the training mandate 
compiled and reported in two months’ time 
as soon as feasible 
In  other  words,  this  was  geared  as  a  reminder  –  with  a 
long lead-time – of the  requirement  to take  the class and a 
notation  that  the  results  would  be  reported  to  executive 
management.  One  could  argue  that  it  should  not  require 
“reporting  to  the  boss”  to  ensure  compliance  but  the  fact 
remains  that  compliance  rates  dramatically  increased  when 
the  results  clearly  showed  the  outliers.  The  results  also 
showed groups that had made a dramatic improvement, and 
the written analysis also credited the security leads for those 
groups who had used the opportunity to exhort their teams to 
compliance.  In  other  words,  the  report  taken  in  toto  was 
geared to show “who has done very well” as well as “who is 
falling behind.” 
Figures  2  and  3  show,  respectively,  compliance  rates 
before  the  numbers  were  reported  to  the  Oracle  Security 
Oversight  Committee,  and  compliance  rates  four  months 
later  (in  reality,  the  most  dramatic  compliance  increase 
occurred within the first two months). 
When all else fails, public “naming and shaming” works, 
and numbers don’t lie. 
It’s  not  clear  that  there  is  a  direct  correlation  between 
expanded secure coding training and security bug reduction, 
in particular because automated tools have also become more 
broadly  deployed  and  thus  more  security  bugs  are  found 
earlier.  That  said,  the  foundation  for  OSSA  is  the  Oracle 
Secure Coding Standards. The training class is intended to be 
familiarization  for  developers  that  they  do  indeed  have 
responsibilities  and  standards  of  practice,  and  pointers  to 
sources of more information. Getting developers to “get it” is 
the  main  purpose  of  the  class,  and  other  processes,  tools, 
checks  and  balances  and  compliance  constitute 
the 
framework  to  make  it easier for developers to  write  secure 
code than not. 
d
e
n
a
r
T
i
t
n
e
c
r
e
P
100%
90%
80%
70%
60%
50%
40%
30%
20%
10%
0%
Product Division1 P11
Secure Coding Practices Completion Summary
P23 P24 P25
P12 P13
P14 P15
P16
Product Division2 P21 P22
P32 P33 P34
P35 P36
P26
Product Division 3 P31
Development Organization
Figure 3.   OSCS Training Completion Status – Four Months Post-OSOC 
Meeting 
VI.  TASTES GREAT AND LESS FILLING, TOO? 
One of the benefits of a thriving metrics program is that 
in many cases information you collect for one purpose may 
have a secondary use. Of course, this is what privacy experts 
worry  about  vis-à-vis  personally  identifiable  information 
(PII). Metrics you develop for your own use do not have the 
same concerns: in fact, one hopes that a metric developed for 
a good business reason proves to have secondary benefits.  
That is not the primary reason to collect data – “I might 
need that some day” – but a secondary use can help validate 
the metrics function and in some cases can provide business 
justification  “with  teeth”  that  would  not  otherwise  be 
available.  For  example,  one  of  the  challenges  for  Oracle 
related to acquisitions is – as noted in the earlier discussions 
of OSSA – getting acquired entities to adopt standard secure 
development  practices, 
including  Oracle  vulnerability 
handling  processes.  In  many  cases,  an  acquired  entity  may 
not have a pre-existing security vulnerability handling team 
or processes; also, an acquired entity may become a target of 
the research community after the product becomes an Oracle 
branded product, post-acquisition.   
193
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:06:29 UTC from IEEE Xplore.  Restrictions apply. 
Therefore,  the  challenge  is  both  the  “how”  to  integrate 
the  entity  with  Oracle  vulnerability  handling  processes  and 
determining  the  correct  number  of  “whos”  to  do  the  work. 
Even 
lot  of  automation  around  security 
vulnerability  handling  processes,  as  Oracle  has  done,  does 
not mean that no additional bodies are needed to handle an 
increased workload. 
instituting  a 
Fortunately,  the area  of  vulnerability  handling is one in 
which Oracle’s security metrics include: 
and growth rate 
•  Number of  open  security  bugs being  tracked,  aged, 
•  Number of security bulletins or alerts issued per year 
•  Volume  of  email  correspondence  to  the  security 
vulnerability  handling  team  (i.e.,  from  external 
reporters who are not customers) 
Managers  made  the  business  case  for  the  number  of 
people needed to resource the security vulnerability handling 
function (at the yearly budgeting cycle) based upon what was 
known  about  the  “security  bug  load”  of  recently  acquired 
entities.  (Similar  analysis  was  used  to  justify  additional 
headcount  for  the  oversight  function.)  More  specifically, 
looking at workload items such as volumes of emails to the 
vulnerability  group,  number  of  security  bulletins/advisories 
issues,  backlogs  of  security  vulnerabilities  that  required 
tracking  and  resolution  was  used  as  raw  data  to  justify 
headcount increases. 
At Oracle, the tracking system for security vulnerabilities 
tracks not only the reporter but also “buckets” the reporters 
for metrics purposes. Specifically, we differentiate among: 
•  Customer reported bugs 
•  Security researcher- reported bugs 
• 
• 
Internally found bugs (general) 
Internally found bugs (found by the ethical hacking 
team) 
One of the main reasons to differentiate among the above 
groups is that – all things being equal – we believe it is more 
important  to  speedily  resolve  researcher-reported bugs  than 
comparably  severe  bugs  reported  by  other  sources.  The 
reasons  include  the  concern  that  researchers  may  become 
impatient if their bugs are not speedily addressed (and thus 
they may “out” the bug before there is a fix available, thus 
increasing risk to customers). Also, researchers whose bugs 
are  not  fixed  promptly  may  complain  publicly,  which  –  in 
addition to generating bad PR – generates work to respond to 
the  bad  PR  and  thereby  address  customer  concerns.  (Note: 
one  of  the  best  ways  to  avoid  negative  PR  generated  by 
security  researchers  is  to  give  them  nothing  that  is  both 
negative and accurate to say. To the extent bad PR is based 
on incorrect information, it can be refuted; to the extent it is 
accurate,  the  root  cause  needs  to  be  addressed  by  the 
vendor.)  
At Oracle, the purpose of having an ethical hacking team 
focused  on  product  assessments  (rather  than,  for  example, 
doing  penetration  tests  of  production  systems)  is  twofold. 
The first is to find vulnerabilities in our own product suites 
before  third  party  researchers  or  actual  hackers  do;  the 
second  (though,  in  a  way,  the  first)  is  to  effect  knowledge 
transfer  to  development  (in  the  form  of  in-house  “hacking 
tools,”  secure  coding  standards,  “case  law”  on  hacker-
resistant development practices and the like). It is a general 
goal  of  our  vulnerability  handling  processes  to  address 
internal,  ethical-hacking  team  found  vulnerabilities  quickly 
since  the  entire  goal  of  turning  the  hackers  loose  on  a 
product is to beat third party researchers or actual hackers to 
the punch. (There’s nothing worse than having a third party 
researcher  report  the  exact  same  bug  that  was  found 
internally,  has  not  been  fixed  and  is  still  languishing  in 
development.)  
There was a concern that ethical hacking bugs were not 
being fixed quickly enough. The ramifications of that would 
include a higher cost to the company (because, to the extent 
the fixes for those vulnerabilities are ultimately released on 
multiple platforms and versions, the longer they languish, the 
greater the cost to remediate as we miss a version going out 
the  door  which  could  contain  the  fix  and  may  thus  need  a 
separate patch later).   
An analysis of the metrics of how many issues had been 
reported to-date in each “reporter” category (shown in Figure 
4) plus the percentage of issues that were still open showed 
that “gut feeling” was not accurate. In fact, next to researcher 
reported bugs, “ethical hacking bugs” had the highest degree 
of bug closure (see below chart). (Note: “external, no credit” 
category  captures  third  party  researchers  who  do  not  care 
about receiving credit in security advisories.) A quick review 
of “the facts” helped alleviate the concern over what was, in 
fact, anecdotal but not accurate. More importantly, it helped 
Oracle avoid an  expensive  fire drill  to  solve  a  non-existing 
problem. 
Reporter
Customer
External, No Credit 
Researchers 
Internal 
Internal (ethical hacking 
team) 
Percentage of Reported 
Bugs That Are Open
9.9 
3.3 
3.6 
11.7 
5.2 
Figure 4.   Percentage of Open Bugs by Reporter 
VII.  SUMMARY 
Metrics are a useful tool in many areas of management, 
including  security  and  more  particularly,  in  the  area  of 
security  vulnerability  handling  and  security  assurance. 
Oracle’s security metrics program has moved from a gleam 
in a manager’s eye to an active program used to change the 
way we allocate security resources. Giving access to security 
metrics  to  developers  themselves  has  helped  highlight 
to  help 
successes  (as  well  as  “needs  work”  areas) 
development  organizations  better  manage 
their  own 
194
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:06:29 UTC from IEEE Xplore.  Restrictions apply. 
workload. Providing assurance compliance metrics to senior 
management  has  helped  increase  the  visibility  of  the 
assurance  function  within  Oracle  and  harnessed  peer 
pressure in pursuit of more secure code.  
ACKNOWLEDGMENT 
Thanks  to  Darius  Wiles  of  Oracle  Global  Product 
Security for development of the Oracle security metrics wiki 
and to John Heimann of Oracle Global Product Security for 
the Oracle Security Compliance Scorecard. 
[1]  Rudolph W. Giuliani, Leadership, Miramax, 2005. 
REFERENCES 
195
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:06:29 UTC from IEEE Xplore.  Restrictions apply.