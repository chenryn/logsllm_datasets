1
Fraction of changed features
Fig. 7. Unseen app detection performance vs changes in both features.
The x-axis denotes the % of changed features. Where the expected amount of
change over time is denoted by the dashed vertical lines.
So far we assumed each device in the network to have 100
apps installed, however FLOWPRINT may perform better or
worse in case this number differs. To evaluate the effect of the
number of installed apps, we train FLOWPRINT by varying
the number of apps N in the training data. Recall that our
approach builds its model on a per-device basis. Hence, while
our database may contain millions of ﬁngerprints, FLOWPRINT
only matches ﬁngerprints against apps installed on the moni-
tored device. We train FLOWPRINT with N apps, ranging from
1 to 200 for the ReCon and Cross Platform datasets, which
is already much higher than the average number of installed
apps on a device [10]. For the Andrubis dataset, we range
N from 1 to 1,000 to evaluate the extreme scenario. We ﬁrst
analyze the performance of our approach in app recognition
on the testing data of the same apps. In the second experiment,
for each N we introduce 20% previously unseen apps, which
FLOWPRINT has to correctly detect. All experiments use 10-
fold cross validation.
Figure 8 shows the performance of the different datasets
in app recognition. Here we see that for all datasets,
the
performance of all metrics initially decreases, but stabilizes
after a certain point (note that the y-axis starts from 0.85).
Even up to the tested scenario of 1,000 apps, for the Andrubis
dataset, the F-1 score remains constant at 0.9. This indicates
that FLOWPRINT easily discerns between relatively few apps,
because it can still rely on network destinations to differentiate
between apps. However, once apps start to share network desti-
nations, the performance drops slightly and quickly stabilizes.
Once stabilized, FLOWPRINT leverages temporal correlations
in network destinations found by our correlation-graph, which
provide a much more robust way of recognizing apps. We
see the same mechanism, although to a lesser degree, for
the unseen app detection scenario in Figure 9. Here the
recall is initially affected because FLOWPRINT only detects
an app as previously unseen if its ﬁngerprint differs enough
from the existing ones. When the training data includes more
13
1
0.95
0.9
e
c
n
a
m
r
o
f
r
e
P
0.85
F1-score
Precision
Recall
Cross Platform
ReCon
Andrubis
0
40
80
120
160
200
Number of training apps
Fig. 8. App recognition performance vs training size.
e
c
n
a
m
r
o
f
r
e
P
1
0.8
0.6
0.4
0.2
0
Cross Platform
ReCon
Andrubis
F1-score
Precision
Recall
40
80
120
160
200
Number of training apps
Fig. 9. Unseen app detection performance vs training size.
shared destinations, the probability that a new app overlaps
with the original dataset becomes larger, and therefore the
detection rate, initially, slightly decreases. Once the training
data contains a sufﬁcient amount of shared destinations the per-
formance becomes more consistent. The ﬂuctuations are due
to apps producing trafﬁc to shared clusters, which occasionally
produce incorrect matches with known apps. Finally, we note
that the Andrubis dataset performs notably worse than the other
datasets because it contains apps that produce relatively few
ﬂows. This is in accordance with the results found in Table V.
G. Assessment of Execution Time
In addition to the aforementioned metrics, the effectiveness
of our approach in a real environment also depends on its
execution time. As we employ some seemingly high-cost op-
erations, such as clustering and clique discovery, we also assess
the individual components of our approach to better understand
the actual time complexity involved. We note that, due to the
setup of our approach, its complexity depends on the number
of network ﬂows rather than the amount of communicated
bytes. In order for our approach to run smoothly, it should be
able to process all received ﬂows within each batch time τbatch,
which in our prototype is set to ﬁve minutes. We assessed the
Time (seconds)
103
102
101
100
10−1
10−2
10−3
10−4
10
100
1k
10k
100k
Flows
1m
Fingerprinting
Clustering
Batch time
Fig. 10. Average execution time of FLOWPRINT when ﬁngerprinting n
ﬂows in a single batch. The ﬁngerprint generation time includes clustering.
execution time of FLOWPRINT by running it on a single core
of an HP Elitebook laptop containing an Intel Core i5-5200U
CPU 2.20GHz processor.
Figure 10 shows the average performance over 10 runs
of FLOWPRINT when generating ﬁngerprints. Here we ﬁnd
that our prototype is able to process roughly 400k ﬂows
within the time window of ﬁve minutes. To put this number
into perspective, the ReCon and Andrubis datasets contain an
average of 117 and 22 ﬂows and a maximum of 845 and 1,810
ﬂows per ﬁve-minute interval respectively. This means that at
peak communication activity FLOWPRINT is able to handle
221 devices simultaneously on a mid-range laptop, making our
approach feasible to run in practice. Both the clustering and
cross-correlation have a theoretical time complexity of O(n2),
however, from Figure 10 we see that in our approach these
components act almost linearly. For the clustering, each ﬂow
is clustered together with ﬂows containing the same destination
(IP, port)-tuple or the same TLS certiﬁcate. Our prototype
implements these checks using a hashmap giving the clustering
a linear time complexity. For the cross-correlation we note
that ﬂows that have the same activity pattern c[0]...c[T ] have
a mutual cross-correlation of 1 and the same correlation with
respect to other ﬂows. Hence, they only need to be computed
once, reducing the time complexity.
Generated ﬁngerprints need to be matched against a
database of known ﬁngerprints. We consider two scenarios: (1)
ﬁnding the closest matching ﬁngerprint (for app recognition),
and (2) checking for any match (in case of unseen app detec-
tion). Figure 11 shows the average performance over 10 runs
for matching 1,000 generated ﬁngerprints against a database
of size n. The complexity of matching ﬁngerprints grows both
with the database size and the amount of ﬁngerprints matched
against this database. Figure 11 shows that even for databases
containing one million ﬁngerprints, the required time to match
is 73 seconds, which is well beneath the ﬁve-minute mark
of τbatch. Assuming an average of 100 apps per device and a
high cardinality of 20 ﬁngerprints per app (see Section V-D), a
database containing one million ﬁngerprints would be able to
deal with 500 devices simultaneously on a mid-range laptop.
These results suggest the feasibility of our approach in high-
volume trafﬁc scenarios as well.
14
Time (seconds)
102
101
100
10−1
10−2
10
100
1k
10k
100k
Size DB
1m
Find closest ﬁngerprint
Check for unseen apps
Fig. 11. Average execution time of FLOWPRINT when matching 1,000
ﬁngerprints against a database containing n ﬁngerprints.
VI. DISCUSSION
We have shown that our approach succeeds in creating
semi-supervised ﬁngerprints for mobile apps, and that such
ﬁngerprints can be used for both app recognition and detecting
previously unseen apps. Nevertheless, there are some aspects
of our approach that should be addressed in future work.
Potential for evasion. We construct our ﬁngerprints based
on the set of network destinations, and the timing of com-
munication with such destinations. In order for authors of an
adversarial app to evade detection by our approach, they have
two options. First, they may redirect all trafﬁc of their app
using a VPN or proxy. When doing this only for their app
and not system-wide, its single destination would still show
up as a ﬁngerprint, thus that speciﬁc app can still be detected.
Setting a system-wide proxy or VPN connection for all apps
on the device (1) requires manual conﬁrmation by the user;
and (2) would be recognizable as unusual device behavior as
our approach would detect all device trafﬁc as originating from
a single app. Hence, with this evasion technique our approach
would still be able to detect the presence of an unknown app
but it will have trouble identifying the speciﬁc app. The second
option is to either avoid producing network trafﬁc (limiting
the damage of potentially harmful apps), or to try to simulate
the trafﬁc patterns of a genuine app. We expect that being
restricted to use the same set of destinations and timing of
an existing genuine app severely limits the potential for an
attack, especially if the attacker does not have control over
such destinations.
Low-trafﬁc apps. During our evaluation, we observed cases of
apps that cannot be reliably ﬁngerprinted using our approach.
This includes, in particular, apps that only communicate with
widely used services, e.g. advertisement networks and CDNs,
which may be difﬁcult to ﬁngerprint. After all, our ﬁngerprints
rely on patterns shown in network destinations. If the pattern
generated by an app is common to many other apps, we cannot
discern said speciﬁc app. We mainly observed this behavior in
apps that do not require any form of server for their main
functionality, but that still communicate with advertisement
and analytics services, probably as a way for monetization.
Unfortunately, we expect most network-based monitoring ap-
15
proaches to suffer from the same limitation due to the generic
nature of advertisement and analytics communication.
Simultaneously active apps. A limitation of a semi-supervised
approach is that it has difﬁculty distinguishing multiple apps
that are running at the same time. Android allows apps to
exchange network trafﬁc in the background, although this be-
havior is typically found only in a limited set of apps (i.e., mu-
sic streaming apps, and apps to make phone calls). In addition,
since Android 7, two apps can be in the foreground at the time
by splitting the screen of the device. Furthermore, Android
10 allows those apps also to be active simultaneously [58].
We expect this heavy multi-app scenario to create challenges
for our ﬁngerprinting approach, and therefore, future work
needs to investigate the ﬁngerprint generation for multiple
simultaneously active apps.
Repackaged apps. While one of our datasets, the Andrubis
dataset, also contains ﬂows from potentially harmful and
malicious apps, we did not speciﬁcally investigate the effect
of repackaged apps on our ﬁngerprinting. As malware authors
frequently repackage benign apps with their malicious pay-
load [38], it would be interesting for future work to investigate
whether the additional ﬁngerprints introduced by this payload
could be used to detect this type of malware.
Fingerprint coverage. Our evaluation has shown an app
may have multiple ﬁngerprints. When detecting new apps,
it takes some time for our approach to converge to a state
where a sufﬁcient number of ﬁngerprints has been created to
accurately characterize the network trafﬁc of an app. Continella
et al. [24] already observed this as a limitation when dealing
with unknown trafﬁc. Future work could explore approaches
similar to theirs to automatically decide when enough network
trafﬁc has been ﬁngerprinted to sufﬁciently cover the network
behavior of an app. Furthermore, while the ﬁngerprints of
previously unseen apps can be immediately used to recognize
the same apps later on, if an unseen app produces multi-
ple ﬁngerprints, FLOWPRINT recognizes each ﬁngerprint as
a separate app. Future work could explore approaches to
automatically determine whether a burst of new ﬁngerprints
belong to the same previously unseen app.
AppScanner reimplementation. While we faithfully reim-
plemented AppScanner following the approach described in
the original paper, our implementation might still slightly
differ from the original tool. Therefore, it is possible that
the two implementations have slightly different performances.
However, we expect this difference to be minimal, if present.
Privacy implications. One of the advantages of our work
is that it works on encrypted trafﬁc. One can argue that in
enterprise networks, TLS can be decrypted by deploying man-
in-the-middle TLS proxies and therefore other approaches are
still applicable. However, trafﬁc decryption weakens the over-
all security [27] and violates users’ privacy, thus we believe it
should be avoided. At the same time, our approach shows the
high precision with which apps can be identiﬁed despite trafﬁc
encryption. From a privacy perspective, the use of certain
apps can reveal information about medical conditions, religion,
sexual orientation, or attitude towards the government of users.
Identifying individual apps from the network trafﬁc alone also
opens the door for censorship and trafﬁc differentiation [37].
Furthermore,
individuals may be identiﬁed and tracked to
a certain degree based on the unique set of apps they are
using [3]. Since devices from different vendors and carriers
often introduce a unique set of pre-installed apps [30], it should
at least be feasible to identify a speciﬁc device manufacturer
or type, which we leave for future work.
VII. RELATED WORK
Related work already explored the use of network ﬁnger-
prints for both mobile and desktop devices. However, related
approaches are either supervised, i.e., require prior training on
labeled apps, or only work on unencrypted network trafﬁc.
App recognition. App recognition, also referred to as trafﬁc
classiﬁcation, is closely related to app ﬁngerprinting as both
approaches attempt to map trafﬁc to the app that produced
it. Related work suggested the use of deep packet inspection
(DPI) for this purpose. Some approaches attempt to automat-
ically identify clear-text snippets in network trafﬁc that are
unique to an app [64, 68]. Other classiﬁers focus speciﬁcally
on HTTP headers in combination with traditional machine
learning [44] or deep learning approaches [19]. Choi et al. [20]
even suggested automatically learning the optimal classiﬁer for
each app. As app recognition can only be used for apps for
which a ﬁngerprint exists, several approaches extended HTTP-
based ﬁngerprints by automating the process of ﬁngerprint
creation [17, 25]. However, all these approaches rely on DPI,
meaning that they cannot be used on encrypted trafﬁc. Given
that 80%–90% of Android apps nowadays communicate over
HTTPS, i.e., use TLS [31, 50], any ﬁngerprinting solution
should be able to deal with TLS-encrypted trafﬁc.
AppScanner [62] uses statistical features of packet sizes
in TCP streams to train Support Vector and Random Forest
Classiﬁers for recognizing known apps. This system is able to
re-identify the top 110 most popular apps in the Google Play
Store apps 99% accuracy. However, to achieve these results,
AppScanner only makes a prediction on trafﬁc for which its
conﬁdence is high enough. This results in the system only
being able to classify 72% of all TCP streams. BIND [4],
like AppScanner, creates supervised app ﬁngerprints based on
statistical features of TCP streams. BIND also uses temporal
features to better capture app behavior and reaches an average
accuracy of 92.6%. However, the authors observed a decay
in performance over time, and suggest to retrain the system
periodically if lower performance is observed.
Concurrent to our work, Petagna et al. [48] demonstrated
that individual apps can also be recognized in trafﬁc that
is anonymized through Tor. Their supervised approach uses
timing, size, packet direction and burst features of TCP ﬂows.
Similar to our work,
the authors observed web browsers
posing a particular challenge, since each visited website might
produce different patterns.
Other approaches include the use of Na¨ıve Bayes classiﬁers
in combination with incoming and outgoing byte distribu-
tions [39], the use of statistical ﬂow features in combination
with decision trees [12] and the possibility of combining
existing classiﬁers [2]. Alan et al. [5] train a classiﬁer on the
packet sizes of the launch-time trafﬁc of apps. However, as
the authors acknowledge, detecting the launch of an app in
real-world trafﬁc is challenging, and and app might already be
launched when a phone enters a network.
Finally, several techniques attempt to identify not the apps
themselves, but rather user activity within apps [23, 55].
These methods are able to detect even more subtle differences
within app usage which can subsequently be linked to the