| TopN |Plan |at HDFS  |at HDFS  |MergeAgg |MergeAgg |TopN || Agg |Scan: t3 |at HBase  |at HBase  |Hash(t1.custid) |Hash(t1.custid) |Scan: t3 |
| Agg |Scan: t3 |at Coordinator |at Coordinator |Hash(t1.custid) |Hash(t1.custid) |Scan: t3 |
| HashJoin |Scan: t3 |at Coordinator |at Coordinator |Hash(t1.custid) |Hash(t1.custid) |Scan: t3 |
| HashJoin |Scan: t3 |at Coordinator |at Coordinator |Pre-Agg |Pre-Agg |Scan: t3 || HashJoin |Scan: t2 |at Coordinator |at Coordinator |HashJoin |Broadcast |Scan: t3 |
| Scan: t1 |Scan: t2 |Scan: t1 |Hash(t1.id1) |HashJoin |Hash(t2.id) |Scan: t2 |
Figure 2: Example of the two phase query optimization.
aggregated once more to compute the final aggregation result. The same two-phased approach is applied to the top-n, and the final top-n step is performed at the coordinator, which returns the results to the user.IntVal'my_func(const'IntVal&'v1,'const'IntVal&'v2)'{' ''return'IntVal(v1.val'*'7'/'v2.val);'
}' function 
| 5. | BACKEND | function 
pointer | function 
pointer | (col1 + 10) * 7 / col2 |
|---|---|---|---|---|
| Impala’s backend receives query fragments from the fron- |Impala’s backend receives query fragments from the fron- |+ |col2 |(col1 + 10) * 7 / col2 || tend and is responsible for their fast execution. It is designed |tend and is responsible for their fast execution. It is designed |function  |function  |(col1 + 10) * 7 / col2 |
| to take advantage of modern hardware. The backend is writ- |to take advantage of modern hardware. The backend is writ- |pointer |pointer |(col1 + 10) * 7 / col2 || ten in C++ and uses code generation at runtime to produce |ten in C++ and uses code generation at runtime to produce |pointer |pointer |(col1 + 10) * 7 / col2 |
| ten in C++ and uses code generation at runtime to produce |ten in C++ and uses code generation at runtime to produce |col1 |10 |codegen’d |
| efficient codepaths (with respect to instruction count) and |efficient codepaths (with respect to instruction count) and |col1 |10 |codegen’d || small memory overhead, especially compared to other engines |small memory overhead, especially compared to other engines |interpreted |interpreted |codegen’d |
| implemented in Java. |implemented in Java. |interpreted |interpreted |codegen’d |
Impala leverages decades of research in parallel databases.
The execution model is the traditional Volcano-style with Exchange operators [7]. Processing is performed batch-at-a-time: each GetNext() call operates over batches of rows,Figure 3: Interpreted vs codegen’ed code in Impala.
| similar to [10]. With the exception of “stop-and-go” opera- | 5.1 | Runtime Code Generation |