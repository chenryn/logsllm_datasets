delay matrix, namely the Lipschitz embedding in the L∞
norm, discussed earlier in Section 2.
Figure 4(c) presents the application of this approach to
the delay space as represented by the Meridian matrix. The
common practice suggests that the dimensionality of a dataset
is determined by the point d in the x-axis in which the
contribution of the corresponding component diﬀers signif-
icantly from the previous one, and the percentage variance
explained by components with labels greater than d becomes
negligible. However, as in the case of this plot, it is not al-
ways clear where to establish this threshold. Since we use
PCA for the purpose of comparison of the dimensionality
values of diﬀerent networks, we deﬁne our PCA measure as
the percentage variance explained by the three most signif-
icant components. Accordingly, low dimensionality implies
more variance being captured by these components whereas
high dimensionality tends to spread the variance across a
greater number of components. In the case of Figure 4(c),
the PCA measure equals 42.66%.
As PCA is a method grounded in linear algebra, when
applied directly to a distance matrix, it is oblivious to non-
linear relationships between diﬀerent dimensions. 5 For ex-
ample, if the points are sampled uniformly at random from a
circle in the plane, PCA applied to the distance matrix will
strongly indicate a 2-dimensional dataset despite the fact
that all of the points belong to a 1-dimensional curve. Here
is where the fractal measures come into play: by capturing
non-linear, as well as linear, relationships among the dimen-
sions, the fractal measures are able to capture patterns in
the data otherwise ignored by PCA. Therefore, they provide
a more genuine characterization of dimensionality.
Isomap
4.3.3
Finally, we apply Isomap [41], a geometric dimensional-
ity reduction technique, proposed in the Machine Learning
community, which is sensitive to both linear and non-linear
correlations between the dimensions. Like PCA, when ap-
plied to a dataset, Isomap outputs the fraction of the total
variance explained by each of the dimensions and produces a
d-dimensional non-linear embedding where the d is a tunable
parameter. Our results indicate that, similarly to the frac-
tal measures, Isomap displays higher sensitivity to Internet
structural properties as compared to PCA and the embed-
ding dimension (see Section 5.2), thereby indicating that
the delay space is rich in non-linearity. The Isomap results
5PCA can in principle capture non-linear relationships when
combined with kernels [27]
presented in this paper were produced using the code that
implements Isomap available on the authors’ websites [41].
5. ON THE DELAY SPACE STRUCTURE
In an attempt to understand the features of the delay
space that contribute to its dimensionality behavior, we study
how and to which extent network properties, such as the ge-
ographic structure and some features of the AS topology,
are reﬂected in its delay space dimensionality. The analysis
in this section also demonstrates the applicability and eﬀec-
tiveness of each dimensionality measure in capturing these
properties.
5.1 The Geographic Component
Our ﬁrst experiment aims at quantifying the impact of the
Internet’s geographic structure on the delay space. For this
purpose, we computed the great circle distances (in miles)
for every pair of nodes and generated a new distance matrix.
The ﬁrst observation is that the pair-count plot, presented
in Figure 5(a), exhibits a power-law that also persists for
approximately two decimal orders of magnitude. As a con-
sequence, it can also be measured using the correlation di-
mension and has exponent D2 = 0.897. The plot for Haus-
dorﬀ dimension, shown in Figure 5(b), is less conclusive,
although it can also be approximated by a straight line with
slope D0 = 0.891. As expected, PCA applied on the dis-
tance matrix results in the two ﬁrst components explaining
100% of the variation in the data.
Note that the geographic dimensionality value is less than
1 while the surface of a sphere has dimensionality 2. This
diﬀerence can be ascribed to the large empty spaces (i.e.,
oceans) and the non-uniform geolocation of nodes (i.e., dom-
inant clusters in North America, Europe and Asia).
Since the dimensionality of the geographic space is sig-
niﬁcantly smaller than that of the delay space, the contri-
bution of geolocation does not fully explain the delay space
dimensionality, albeit it is indeed a strong component, in
accordance with the analysis by [16] and [39]. However, the
fractal measures of dimensionality allow us to quantify the
extent to which geolocation contributes to the overall delay
space structure. Furthermore, it shows that the fractal be-
havior of the delay space is in fact present in the underlying
geodesic space.
5.2 Dimensionality Reducing Decomposition
On searching for a (possibly recursive) structural feature
of the delay space that could explain its fractal behavior, we
discovered a dimensionality shift that can be ascribed to the
structural conﬁguration of the AS topology.6
Our intuition is based on the observation that peering
points, especially those corresponding to transit links be-
tween two Tier-1 networks, are contained on a signiﬁcant
fraction of the Internet routes joining nodes which are down-
stream from diﬀerent Tier-1 providers. Even though there
is an abundance of peering points between non-Tier-1 net-
works, and multihomed domains are the norm, the signiﬁ-
cance of paths traversing transit links between two Tier-1
6In the interest of space, we present only a subset of the
graphs from which we derived the conclusions in this section.
However, the remaining graphs corresponding to all results
presented here can be found in the companion website at
http://www.cs.cornell.edu/∼rdk/inetdim
Figure 6: Network decomposition into intersecting
pieces, each corresponding to a Tier-1 AS together
with its downstream network.
networks could still have a major inﬂuence on the geome-
try of the Internet delay space. Thus, we ask the follow-
ing question: what is the geometric eﬀect of analyzing each
Tier-1 AS downstream network in isolation, thus removing
the distances that contain a contribution from the traversal
of Tier-1 transit links?
We expected that this process would result in subnetworks
whose delay space geometry is better behaved, as compared
to their superposition, in which the subspaces corresponding
to the diﬀerent Tier-1 AS downstream networks would pri-
marily connect to one another in the Tier-1 peering points,
as illustrated in Figure 6.
An example of this scenario was previously hinted in [28]
where the geometry exhibited by a more homogeneous net-
work, when observed in isolation, is better behaved, as com-
pared to a more diverse network. In the case of this study,
the embedding of the Abilene network, connecting hosts
through a fast Internet2 backbone, resulted in gains in accu-
racy as high as 40% in relative errors, using the same number
of dimensions as in the embedding of a global network. This
improvement was ascribed to the overall short distances of
the paths.
In order to quantify the extent to which transit links are
reﬂected in the Internet delay space, we measured each sub-
network (deﬁned according to the decomposition presented
in Section 3) using embedding dimension, correlation dimen-
sion, Hausdorﬀ dimension, and PCA.
In order to conﬁrm that the dimensionality reduction ob-
served in this experiment is attributable to eﬀects arising
from the AS-level topology of the Internet, and not some
other simpler explanation, we tested two alternative hy-
potheses: that the dimensionality of the delay space can
be reduced by decomposing it into pieces of smaller cardi-
nality, or that it can be reduced by decomposing into pieces
of smaller diameter.
The ﬁrst hypothesis is partially justiﬁed by Bourgain’s
theorem [8] that the Euclidean distortion of a metric space
grows logarithmically with its cardinality, in the worst case.
To test the hypothesis that cardinality reduction leads to
dimension reduction, we created 121 random subsets of the
whole matrix, each containing 1454 hosts (the median car-
dinality among all subnetworks). In Table 2, we denote by
random x% the statistics derived from these random subsets
corresponding to the x-th quartiles of these values.
Table 2: Dimensionality measures: correlation di-
mension (D2), Hausdorﬀ dimension (D0) and PCA
found for the diﬀerent AS networks.
Dimensionality
Network
D2
D0
PCA
Meridian
1.783
1.510
42.66
1239
1.780
1.333
46.54
209
1.637
1.225
28.42
2914
3356
3549
3561
7018
1.618
1.161
44.25
1.691
1.230
48.60
1.634
1.265
48.96
1.686
1.239
49.54
1.710
1.304
49.68
701
1.701
1.244
49.68
random 0% 1.725
1.389
27.71
random 25% 1.762
1.465
45.76
random 50% 1.775
1.506
46.67
random 75% 1.789
1.554
53.10
random 100% 1.837
1.682
72.86
To test the second hypothesis, that diameter reduction
leads to dimensionality reduction, we created a new decom-
position of the distance matrix by the following process.
Starting from an element selected from a geographically di-
verse set of hosts, we grew a ball around it by selecting its
1454 closest neighbors, and examined the delay space con-
sisting of all inter-distances among these 1454 hosts. We
have constructed 12 of these subsets centered at hosts lo-
cated in 9 diﬀerent countries, 4 continents.
Table 2 summarizes the dimensionality of each the sub-
networks and values of the statistic thereof for the random
subsets7 in terms of the correlation dimension, Hausdorﬀ di-
mension, and PCA measures. The corresponding measures
for the whole network are also displayed in the table for
reference, under the label Meridian.
The ﬁrst observation is that the power-law behavior ob-
served in the whole matrix was preserved over the same
range of distances in the submatrices, though not necessarily
with the same exponent. Second, with the exception of the
correlation dimension of the subnetwork rooted at AS 1239
(Sprint), all other networks exhibit smaller dimensionality
than the whole matrix according to the two fractal measures.
The values of both the correlation and Hausdorﬀ dimen-
sions for the random networks, including the minimum of
these values (random 0%), are consistently higher than those
of every subnetwork (except for the pair count of network
1239), and a higher percent of these values are close to that
of the whole matrix. As one increases the size of the original
dataset and the number of representatives in the set of ran-
dom networks, one expects even less deviation between the
correlation and Hausdorﬀ dimensions of the original dataset
7The decomposition based on low-diameter subsets pro-
duced results which are incomparable with these results be-
cause the clustering rule signiﬁcantly altered the nature of
the power-law behavior, as explained further below. Hence
the results of these experiments are not included in Table 2.
and the median values measured in the random subnetworks.
The decomposition based on clustering of growing balls
resulted in the following observations. For all clusters, the
pair-count plots present a power-law persisting over one dec-
imal order of magnitude less than the whole matrix. For
smaller values of r (in the range 3ms to 10ms) the number
of pairs at distance r is signiﬁcantly higher than the number
of pairs predicted by the power-law approximation. This is
perhaps not surprising, since the clusters were selected for
their proximity to a single central host. Figure 5(c) shows
one example of this outcome for one of the clusters. More-
over, the pair-count exponents (i.e., correlation dimensions)
computed over the range in which the power-law persists in-
dicate dimensionality consistently greater than that of the
whole matrix. The deviation from a power-law is also ob-
served in the range from 20ms to 30ms of set cover plots. In
addition, the Hausdorﬀ dimension measured over the range
from 30 to 90ms is consistently greater than that of the
whole matrix for all clusters.
Interestingly, delay space dimensionality reduction cannot
be explained by a corresponding reduction in the geographic