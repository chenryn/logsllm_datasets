# kafka
Kafka 是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域
## 特点
- 多生产者 多消费者
- 基于磁盘的数据存储
- 伸缩性
  -  broker可以不断扩展
- 高性能
## 基础概念
消息和批次
  - 消息是kafka的数据单元
  - 批次是一组消息
模式
  - schema 使用额外的结构定义消息内容
主题和分区
  - 消息通过主题分类
  - 主题被分为若干个分区 通过分区来实现数据冗余和伸缩性
![屏幕截图 2020-08-12 152257](/assets/屏幕截图%202020-08-12%20152257.png)
生产者和消费者
  - 生产者创建消息
  - 消费者读取消息 一个分区只能由一个组内消费者消费 通过偏移量记录消息消费位置
![屏幕截图 2020-08-12 152638](/assets/屏幕截图%202020-08-12%20152638.png)
broker 和集群
  - broker 独立的 kafka 服务器
  - 每个集群都有一个broker 充当集群控制器
![屏幕截图 2020-08-12 152955](/assets/屏幕截图%202020-08-12%20152955.png)
对于消息 kafka会保留一段时间或者达到一定大小的字节数 旧的消息会被删除
多集群
![屏幕截图 2020-08-12 153137](/assets/屏幕截图%202020-08-12%20153137.png)
## 使用场景
- 活动跟踪
  - 生产者产生事件 消费者读取事件进行统计
- 传递消息
- 度量指标 日志记录
  - 收集系统度量指标和日志
- 日志系统
- 流处理
## 架构
![屏幕截图 2020-08-03 133557](/assets/屏幕截图%202020-08-03%20133557.png)
- Partition ：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，
一个 topic  可以分为多个 partition，每个 partition 是一个有序的队列；
- Replica： ：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，
一个 leader 和若干个 follower。
- leader ：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对
象都是 leader。
  - 生产者和消费者只与 leader 副本交互,当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选
- follower ：每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据
的同步。leader 发生故障时，某个 follower 会成为新的 follower。
### 分区与副本机制
- 各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）
- 副本极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间
ISR：中的副本都是与 leader 同步的副本
为了描述一个副本是否与 leader 副本同步，replica.lag.time.max.ms 用来描述这个最大延迟，如果 follower 副本与 leader 副本的复制延迟超过这个时间，则认为不同步
Leader epoch：可以用来确定最新的分区副本，由两部分数据组成。一个是Epoch,一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号
### zk的作用
主要为 Kafka 提供元数据的管理的功能
- Broker 注册 ：在 Zookeeper 上会有一个专门用来进行 Broker 服务器列表记录的节点
- Topic 注册：分区信息及与 Broker 的对应关系也都是由 Zookeeper 在维护
## 应用场景
- 消息队列
- 行为跟踪
- 日志收集
- 流处理
- 事件源
- 持久性日志
## 搭建
- 操作系统选用 Linux，可以充分利用 epoll 、零拷贝提升 IO 性能
- 存储选用磁盘，可以被 Kafka 顺序 IO 充分利用
- 磁盘容量规划需要计算一下每天处理多少数据，每条数据多大，数据保留多久，在此基础上预留一定额外空间
- 根据集群节点数，网络带宽，最大只能让 Kafka 使用 70 %的带宽
## 配置
broker 配置
- broker.id
  - 在集群中唯一
  - 需要多少个broker
    - 需要多少磁盘空间保留数据
    - 集群处理请求的能力
- port
- zookeeper.connect
- log.dirs
  - 消息保存在磁盘上的位置
- num.recovery.threads.per.data.dir
  - 使用指定的线程池来处理日志
- auto.create.topics.enable
  - 自动创建主题
    - 当一个生产者开始往主题写入消息时
    - 当一个消费者开始读取
    - 客户端向主题发送元数据请求
主题配置
- num.partitions
  - 默认分区数量
- log.retention.ms
  - 数据保留多久
- log.retention.bytes
  - 主题保留的数据大小
- log.segment.bytes
  - 一个日志片段的最大大小
- log.segment.ms
  - 日志片段的最长打开时间
- message.max.bytes
  - 消息最大大小
## 命令操作
- 列出topic
```sh
./kafka-topics.sh --list --zookeeper 172.17.0.1:2181
```
- 创建topic
```sh
/opt/kafka/bin/kafka-topics.sh --create --zookeeper 172.17.0.1:2181 --replication-factor 1 --partitions 2 --topic my_log
```
- 生产者
```sh
./kafka-console-producer.sh --topic first --broker-list 172.17.0.1:9092
```
- 消费者
```sh
./kafka-console-consumer.sh --topic first --bootstrap-server 172.17.0.1:9092
```
## 工作流程
![屏幕截图 2020-08-05 153846](/assets/屏幕截图%202020-08-05%20153846.png)
Kafka 中消息是以 topic 进行分类的，生产者生产消息，消费者消费消息，都是面向 topic的
每个 partition 对应于一个 log 文件，该 log 文件中存储的就是 producer 生产的数据
消费者组中的每个消费者，都会实时记录自己消费到了哪个 offset，以便出错恢复时，从上次的位置继续消费
### 日志
消息日志文件（.log）、位移索引文件（.index）、时间戳索引文件（.timeindex）、已中止（Aborted）事务的索引文件（.txnindex）
- .index：K：4字节的相对偏移量，V：4字节的消息物理位置。Kafka 使用了 8 字节的整数表达消息偏移量，但由于每个索引文件额外保存了一个基础偏移量，所以绝对偏移量 = 基础偏移量 + 相对偏移量得到，可以节省不少存储空间
- .timeindex：K：8字节的时间戳，V：4字节的相对偏移量
```mermaid
stateDiagram-v2
  topic --> partition0
  topic --> partition1
  topic --> partition2
  partition1 --> log
  log --> segment1
  log --> segment2
  log --> segment3
  segment2 --> .log
  segment2 --> .index
  segment2 --> .timeindex
  segment2 --> .txindex
```
一个非空的日志段 segment 在超过一段时候后，即使还没有写满，也会强制滚动（roll，也就是新建）日志段
#### 日志段写入
Producer 生产的数据会被不断追加到 log 文件的末端，在对该文件进行读写时，Kafka 会充分利用 PageCache 来加速读写，每条数据都有自己的 offset
Kafka 在写入消息时，会根据这批写入的最大 offset 、时间戳等来判断要不要追加索引
#### 日志段读取
![index与log文件的作用](/assets/屏幕截图%202020-08-05%20155619.png)
#### 恢复
在启动 broker 时，kafka 会遍历所有日志段。为了从磁盘读取索引数据，对于某一个 segement，恢复操作会从 log 文件重建索引，清除掉之前的索引文件。并删除掉日志文件跟索引文件末尾无效的数据
#### 高水位管理
Kafka 使用高水位（HW, Hight WaterMark）来标识分区下的哪些消息是可以被消费者消费以及进行副本间的同步
```java
public final class LogOffsetMetadata {
    ...
    public final long messageOffset; // 消息位移值
    public final long segmentBaseOffset; // 位移值在日志段的上的位置
    public final int relativePositionInSegment; // 位移值所在日志段的物理磁盘位置
    ...
}
```
![](/assets/2023113019631.webp)
#### 日志段管理
```java
public class LogSegments {
  /* the segments of the log with key being LogSegment base offset and value being a LogSegment */
  private final ConcurrentNavigableMap segments = new ConcurrentSkipListMap<>();
}
```
在写入数据时，Kafka 就是是对最后一个日志段执行的写入操作
```scala
segments.activeSegment.append(lastOffset, largestTimestamp, shallowOffsetOfMaxTimestamp, records)
```
在读取数据时，则是根据起始偏移量、读取多少数据，不断地日志段中读取数据
```scala
while (fetchDataInfo == null && segmentOpt.isPresent) {
  ...
  fetchDataInfo = segment.read(startOffset, maxLength, maxPosition, minOneMessage)
  if (fetchDataInfo != null) {
    ...
  } else segmentOpt = segments.higherSegment(baseOffset)
}
```
#### 索引文件
```java
public abstract class AbstractIndex implements Closeable {
    ...
    private final long baseOffset; // 对应日志段对象的起始位移值，如 00000000000000000123.index 123就是起始位移值
    private final int maxIndexSize; // 控制索引文件的最大长度
    private final boolean writable;
    private volatile File file;
    // Length of the index file
    private volatile long length;
    private volatile MappedByteBuffer mmap; // 内存映射磁盘读写
    /**
     * The maximum number of entries this index can hold
     */
    private volatile int maxEntries;
    /** The number of entries in this index */
    private volatile int entries;
    ...
}
```
Kafka 对 offset 的查找是基于[二分查找](/算法与数据结构/查找.md#二分查找)实现的：
首先通过index文件查找offset所在的大概范围，然后再在这个范围内进行顺序查找，为了使用更少的内存空间，Kafka 采用的是稀疏不连续的索引
其会根据第一条消息的偏移量以及所需读取的大小或者最大能读取的大小，去读取数据
Kafka 利用 mmap，将更大的磁盘文件映射到了一个虚拟内存空间，也就是最近读写的数据更有可能在内存中，对于什么读写的冷数据如果进行访问，会触发[缺页中断](/操作系统/内存管理.md#分页)，所以 Kafka 的二分查找会优先查找热区，即最近操作的那部分数据，找到的话就不用去查冷区的数据，以此提升性能