threaded environments, Song et al. [28] demonstrated that Web
Workers [31]—which enable JavaScript programs to spawn
multiple threads that can communicate with one another—
could be used to circumvent such transient memory protections
by creating a race condition. While one thread coerces the
language runtime into making a particular memory region
writable (e.g., by triggering an inline cache patch), another
thread exploits a vulnerability that corrupts the writable JIT
code memory. This attack does, however, require that
the
attacker be able to predict the address of the JIT code memory
that will be made writable by the former thread, which is an as-
sumption that does not go hand in hand with a spraying attack.
JITDefender [9] and JITSafe [10] take a different approach
and seek to prevent malicious code reuse; they allow JIT code
to be writable at all times and enable executability only when
the language runtime enters it. JITSafe and JITDefender incur
0x1ffff
that are being moved into a register or pushed onto the stack.
This implementation fails to protect against even Blazakis’
originally-publicized JIT spraying attack and only applies to
x86-32 and x86-64. Athanasakis et al.’s [4] investigation into
Internet Explorer’s Chakra JIT uncovered that it always blinds
constants >0xffff, but this was not enough to prevent them
from using untrusted constants to encode ROP gadgets.
c) Call frame randomization: Call frame randomiza-
tion [32] scrambles the instructions that are used to access
values such as arguments, local variables, spilled temporary
values, etc. in a function’s call frame. These instructions usu-
ally access memory at predictable immediate offsets relative to
the stack pointer or a call frame register, which as we show in
§III-B, can provide an attacker with a convenient predictable
memory access instruction for reuse.
2) Code layout randomization: Predictable are not only the
contents of JIT code, but also the layout of its instructions
relative to one another and the boundaries of coarser-grained
memory allocation units. Nearly all JIT spraying attacks we
have seen so far rely on predictable code layout either to
prevent an unintended instruction stream from resynchronizing
to the intended stream or to predict the relative or absolute
locations of instructions. Two strategies have been proposed
to diversify JIT code layout at both ﬁne and coarse granu-
larity: random NOP insertion and base offset randomization,
respectively.
a) Random NOP insertion: Random NOP inser-
tion [14], [15], [32], [25], [33] involves injecting semantic
NOP instructions at random in JIT code. Its effect is both
to randomize the offset of any given instruction from the
beginning of the unit of code compilation and, more gen-
erally,
to randomize the relative offset between any given
pair of instructions. Like constant blinding, the overhead of
random NOP insertion comes from increased code footprint
(leading to increased i-cache pressure) and wasted cycles at
runtime; however the overhead for random NOP insertion
scales with code size rather than the number of untrusted
constants compiled. Lian et al.’s [17] study of JavaScriptCore
revealed that JSC’s non-optimizing JIT avoids the scaling
overhead problem by only randomly inserting a single NOP
instruction at a ﬁxed location at the beginning of certain units
of code compilation, which provides very little security beneﬁt.
Athanasakis et al. [4] report that Internet Explorer’s Chakra
JIT employs random NOP insertion, but they omit details of
its implementation.
b) Base
offset
randomization:
offset
randomization [25] places a random amount of “dead”
space before the beginning of each unit of code compilation,
either in the form of NOP instructions or free space. This
perturbs both the offset of the ﬁrst unit of code compilation
Base
when the JIT compiler maps a fresh region of executable
memory and the relative offsets between consecutively-
compiled units of code compilation. The absence of base
offset randomization is critical to the heap feng shui [29] used
to pinpoint gadget addresses in gadget chaining attacks such
as [17] and our V8 attack (§ III-B). Base offset randomization
would have drastically reduced the reliability of these attacks
with less overhead than random NOP insertion.
V. EVALUATION OF DIVERSIFICATION MITIGATIONS
As we saw in § IV, very few JIT spraying mitigations
that have been proposed have been deployed in production
browser releases, and those like constant blinding and random
NOP insertion that are deployed have been severely limited
to the point that they have lost their effectiveness. We argue
that JIT code reuse can be effectively mitigated via fully-
functional diversiﬁcation defenses with only modest, but ul-
timately worthwhile, overhead. However, the answers to the
questions of how much performance overhead diversiﬁcation
defenses incur and to what extent they improve security are
muddled. Various incarnations of the diversiﬁcation mitiga-
tions described in § IV-C are mixed and matched to compose
many different defense systems mentioned in the literature [3],
[4], [10], [14], [15], [32], [33]. Many of these implementations
are not fully speciﬁed, and what descriptions exist often vary
considerably. Moreover, performance evaluations of diversi-
ﬁcation mechanisms are often reported as aggregates with
each other and other unrelated mitigations; and the hardware
and benchmarking suites on which the implementations are
evaluated vary by author.
Thus, there has been no clear source in the literature pro-
viding detailed implementation descriptions and measurements
of their associated runtime overheads on consistent hardware
and benchmarks. The purpose of this section is to provide that
information so that JIT compiler authors considering adopting
these defenses can more comfortably weigh the costs and
beneﬁts of diversiﬁcation defenses. To better understand the
beneﬁts of each defense, we also analyze each defense with
respect to concrete JIT spraying attacks to quantify the factor
by which the probability of a successful attack is reduced.
To this end, we implemented all ﬁve diversiﬁcation de-
fense techniques described in § IV-C on the SpiderMonkey
JavaScript engine for both its non-optimizing (Baseline) and
optimizing (IonMonkey) JIT compilers on the ARM32 and
x86-64 architectures.5 Our implementations are by no means
highly optimized; instead, our priority is to avoid creating
corner cases that can be exploited by a wily attacker to improve
her chances of defeating the mitigation. During development,
we found that random design decisions in the JIT backend
greatly impacted the difﬁculty of integrating defenses into
the existing system. That is not to say that these decisions
were made carelessly, but rather that they were perhaps not
made with thought towards the generality necessary to support
mitigations. The source code for our mitigations is available
as a public fork of Mozilla’s GitHub repository; our work is
based on top of commit ce31ad5.6
5We did not implement register randomization for x86-64’s non-optimizing
compiler for reasons described later.
6The fork can be found at https://github.com/wwlian/gecko-dev.
A. Register randomization
Implementing register randomization for IonMonkey is
extraordinarily non-invasive. IonMonkey compiles scripts to
an intermediate representation (IR) and performs analyses over
the IR in order to run a register allocator. We simply permute
the order in which the allocator considers physical registers to
satisfy allocation requirements. The changes for our implemen-
tation span 6 lines of code and randomize both ﬂoating point
and general purpose register allocations. Some IR instructions
are assigned ﬁxed source or destination registers which cannot
be randomized at the level of the register allocator; however,
these ﬁxed assignments do not bind to actual physical registers,
but rather “abstract registers” which are mapped to physical
registers. Fortunately, randomizing registers for the Baseline
JIT involves randomizing the mappings from these same
abstract registers to physical registers.
SpiderMonkey’s Baseline JIT does not use a register allo-
cator; instead it emits statically-deﬁned instruction sequences
for bytecode instructions for a stack-based virtual machine.
The instruction sequences implementing bytecodes are de-
ﬁned by C++ code that allocates abstract registers as source,
destination, and temporary registers used by each bytecode’s
implementation. To the C++ programmer, using an abstract
register “feels” like using a physical register, but they are
simply variables named after the physical registers that hold
an integer value identifying an actual physical register.
Randomizing registers for the Baseline JIT (and indirectly,
IonMonkey) involves permuting the underlying values that
are assigned to the abstract register variables named after
physical registers. Any uses of these variables will propagate
the randomized physical register mapping. However, additional
complexity must be introduced at the call and return control
ﬂow edges between statically-compiled native code and JIT
code since certain values are expected to be passed between
native and JIT code in speciﬁc physical registers in accordance
with the architecture’s ABI. To ensure that JIT code—which
is deﬁned in C++ under the assumption that abstract registers
named after physical registers actually refer to those physical
registers—is able to conform to the architecture ABI, we
introduce a sequence of pushes and pops into the trampolines
that execute at the boundaries between native and JIT code;
the pushes and pops have the effect of permuting registers or
inverting the permutation as needed.
In addition to the interoperability issues with native code,
there were other cases where assumptions regarding the bind-
ings between abstract registers and speciﬁc physical registers
caused no small number of headaches. In these corner cases,
violating these assumptions via randomization leads to incor-
rect behavior and data corruption that eventually causes a hard-
to-debug crash much later than the misbehavior itself. These
corner cases were very difﬁcult to track down because the
assumptions relied on very low level details that were not
documented in any central location. For example, ARM is able
to load two 32-bit values from memory into two consecutively-
numbered general purpose registers as long as the lower-
numbered register is even. If C++ code used abstract registers
named after qualifying registers for such a load, randomization
can easily invalidate the consecutivity, parity, and ordering
assumptions.
10
Floating point register randomization is unnecessary for the
Baseline JIT because it does not generate code that operates
on ﬂoating point registers (with the exception of IC stubs,
which are shared and cannot be sprayed). Instead, ﬂoating
point values in Baseline JIT code are stored in general purpose
registers and passed to IC stubs or host functions which
perform the desired ﬂoating point operations.
Special care must also be taken to maintain abstract reg-
isters’ volatility; in other words, we only permute volatile
(a.k.a. caller-saved) registers with other volatile registers and
likewise for non-volatile (callee-saved) registers. This is neces-
sary because there are instances where code using an abstract
register assumes that it maps to a non-volatile register and does
not save that register’s value prior to calling a subroutine. This
limitation only applies to the abstract-to-physical remapping;
in IonMonkey, values that are not bound to an abstract register
are free to be allocated to any register.
Because of the many intricacies of permuting the mapping
from abstract registers to physical registers, we limited our
remapping implementation to the ARM architecture. We also
limit randomization to registers that SpiderMonkey consid-
ers “allocatable,” which excludes the program counter, stack
pointer, link register, and a register used internally by the com-
piler for very short-lived scratch values. Although it presents
a signiﬁcant weakness to our implementation, we do not
randomize the abstract register mapping that refers to the archi-
tecture ABI’s integer return register, as a considerable amount