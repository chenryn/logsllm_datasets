COTS 1 Outputs
COTS 2 Outputs
Comparisons
Output differences
Design faults
Design differences
Vulnerabilities
Classical design faults
False Positives
Elimination
Alerts
False Positives
Elimination
Fig. 2. Taxonomy of Detected Differences
The output differences detected that are due to classical design faults or speciﬁca-
tion differences are actually false positives, because they do not lead to violations of the
security policy. These false positives must, of course, be eliminated. Most of the time,
the COTS we have selected have been used for years and can now be considered rea-
sonably fault free in the context of a normal use. (This hypothesis has been conﬁrmed
by the tests we have conducted, see Section 4.2.) Consequently, we do not expect to
detect a lot of classical design faults. Thus, most of the false positives will be due to
design differences that are not the consequence of design faults. As a consequence, we
decided to concentrate on the elimination of these differences. This elimination is per-
formed by masking the legitimate differences. The masking functions are thus applied
by modifying the request before it is processed (pre-request masking: proxy masking
function) or after the request has been performed (post-request masking: rule masking
mechanisms). In both cases, the easy solution we chose was an off-line experimental
identiﬁcation of the speciﬁcation differences (See 4.1 for an application).
Extending majority voting fault masking mechanism to COTS output difference
masking. In order to insert fault tolerance mechanisms in a N-version programming
scheme, it is required to implement fault masking mechanisms. These mechanisms pro-
vide a way to return a correct answer despite the fact that one version delivers a faulty
output. In classical diversity, this output is an error because all the versions are known to
have the same speciﬁcation. In our case, a difference at the output level will be mainly
COTS Diversity Based Intrusion Detection and Application to Web Servers
51
due to a design difference in the COTS: it is thus necessary to extend the notion of
fault masking to COTS difference masking. As an example, we suppose that the fault
masking function is a majority voting algorithm.
Formally, a voting fault masking function in the context of N-version programming
can be described as follows: I be the set of inputs of the service, Idi f f the subset of I
that produces an output difference in one of the versions. Let Oi = {oi
} the
1,oi
2, ...,oi
set of outputs of the versions for a given entry i ∈ Idi f f . The majority voting function M
N
is a masking function M : Oi (cid:6)→ oi
∈ Oi if there is
a majority of j ∈ {1,2, ...N} | oi
k that returns either a correct value oi
k
k, or an error if no majority is found.
j = oi
In the case of COTS diversity, the elements of Oi can differ from each other because
of a design difference between the versions, even if no fault has been activated. These
differences must then be considered as legal, and must thus be masked. In order to mask
these differences, we use a transitive equivalence function: for i ∈ Idi f f , two elements
(oi
j,oi
k) if they are both known correct outputs
of the versions j and k (i.e., no intrusion has occurred). The majority voting function M
∈ Oi if there is
is a masking function M : Oi (cid:6)→ oi
a majority of j ∈ {1,2, ...N} | oi
k that returns either a correct value oi
≡ oi
k
k) ∈ Oi × Oi are equivalent (noted oi
j, or an error if no majority is found.
These deﬁnitions are very closed in term of algorithm complexity, and thus the mask-
ing rule based mechanism described in Section 4.1 does not produce a very higher com-
plexity algorithm than a simple fault masking voting algorithm.
≡ oi
j
k
Intrusion tolerance at the proxy and IDS levels. Intrusion tolerance is not completely
ensured, because both the proxy and the IDS can be considered as a single point of fail-
ure in case of an attack against them succeeds. Nevertheless, notice that the complexity
of the proxy is pretty low (as shown by the output difference masking deﬁnition mech-
anism deﬁned in the previous paragraph), and thus it should be less vulnerable than the
servers. In fact, this architecture is devoted to intrusion detection, not intrusion toler-
ance. To ensure intrusion tolerance, some additional mechanisms must be added, such
as proxy diversity or redundancy (coupled with consensus Byzantine agreement pro-
tocols), or eventually proxy monitoring via model checking. Some of these ideas have
been tackled in [18] as part of the DIT project. We also plan to apply such approaches
to our architecture, which actually is part of the CNRS/ACISI DADDi (Dependable
Anomaly Detection with Diagnosis) project. In that project, the proxy dependability
will be tackled by one of our partner.
4 A COTS-Diversity Based IDS for Web Servers
The approach we have presented in the previous section can be applied to any type
of service (ftp server, mail server, etc.) if the hypothesis of vulnerability decorrela-
tion can be veriﬁed. In this section, we apply it to web servers (as, once again, the
reference [17] shows that the hypothesis is veriﬁed) in order to demonstrate the feasi-
bility of the approach through experimental results.
Web servers constitute the electronic front door of many organisations, if not all.
More and more critical applications are developed on the web in various ﬁelds like
ﬁnance, e-commerce. In the same time, web servers and web-based applications are
52
E. Totel, F. Majorczyk, and L. Mé
popular attack targets. A large number of disclosure of vulnerabilities concerns web
servers or web-applications. For instance, in the time of writing, Snort 2.2 devotes 1064
of its 2510 signatures to detect web-related attacks. Finally, many COTS implementing
web servers are available and widely used. Thus, we decided to apply our approach to
web servers.
In this section, we ﬁrst give the detection algorithm in the case of web servers and
discuss on the choices that have been made. Then, we give some experimental results
that aim at giving evidence on the reliability and on the accuracy of the approach.
4.1 Detection Algorithm
The detection algorithm depends on the application monitored and must be developed
speciﬁcally for each application considered. We give here an algorithm for web servers.
We view the web servers as black boxes and their interactions with the environment
are the only things that can be observed. The only identiﬁed common part of the spec-
iﬁcation is the HTTP protocol. We must then compare the HTTP responses from the
several web servers. The common speciﬁcation part does not a priori deﬁne other out-
puts, such as system calls for example. That is why we restrict the data processed by
the detection algorithm to HTTP responses.
The HTTP protocol is based on a request/response paradigm. A client establishes a
connection with a server and sends a request to the server. A response is then given in
return to the client. This HTTP response is composed of two parts: the header part and
the body. The header part is well deﬁned. For example, the ﬁrst ﬁeld is the status line,
which is principally composed by the version of the HTTP protocol and the status code.
If not empty, the body can be almost everything depending on the request.
A binary comparison of the HTTP headers cannot be performed because the servers
actually uses different headers. Moreover, some headers may be ﬁlled differently by dif-
ferent servers, such as the header “Date” or the header “Server”. The semantic of each
header has to be taken into account in the comparison process. Also, we have to care-
fully analyse which headers to process during the comparison. The status code is ob-
viously an important element. Other headers are interesting: Content-Length, Content-
Type, Last-Modiﬁed. These three headers are almost always sent by web servers. A
difference in these headers can notably be a piece of evidence of a defacement.
The bodies, when they are not empty, are also compared. We have restricted our
experiments to static http contents. In that particular case, a binary comparison of the
bodies is possible. Even in this restricted case, we may have a problem during binary
comparisons; for example the comparison of directory listings, as different servers pro-
vide different bodies when answering to this type of request (this can be clearly identi-
ﬁed as a speciﬁcation difference). For the moment, our web variants are conﬁgured so
that access to directories is not allowed.
The detection algorithm is composed of two phases:
– a watchdog timer provides a way to detect that a server is not able to answer to a
request. All servers that have not replied are considered to be unavailable, and an
alert is raised for each of them;
– then, the comparison algorithm is applied on the set of answers that have been
collected.
COTS Diversity Based Intrusion Detection and Application to Web Servers
53
Algorithm 1. Detection Algorithm by Comparison of Web server Answers
Data: n the number of web servers and R = {Ri|1 ≤ i ≤ n} the set of responses from the
web servers to a given request Req, D the set of known design differences for the
used web servers, headers the table such that headers[0] = ’Content-Length’,
headers[1] = ’Content-Type’, headers[2] = ’Last-Modiﬁed’
if (Req, R) ∈ D then
/* Handle design differences that are not vulnerabilities */
modify R to mask the differences
∀(Rl, Rk) ∈ C2
∀(i, j) ∈ [1,m]2, i (cid:11)= j,Ci ∩C j = /0, m the number or partitions
i , Rl.statusCode = Rk.statusCode
Partition R in Ci,
1 ≤ i ≤ m ≤ n
if ∀i Card(Ci) 
directory request without a final ’/’
^.*[^/]$
^.*$
apache
301
text/html
iis
thttpd
302
text/html
no
iis
no
no
Fig. 3. Directory Rule: The tags regexpURI (deﬁnition of the URL) and regexpMethod (deﬁnition
of the HTTP method) deﬁne the server entries using regular expressions. The server tags deﬁne
the outputs of the servers Si, i.e., the expected outputs produced by the several servers when they
take one of the values deﬁned as entry. The other tags : compareContent, response, warn and alert
deﬁne the set of actions that must be performed by the IDS in order to mask the difference or
generate an alert.
COTS Diversity Based Intrusion Detection and Application to Web Servers
55
Table 1. Attacks against the Web servers
Attack against...
Conﬁdentiality (1)(see Appendix A) CVE-2000-0884 CAN-2001-0925
BuggyHTTP
IIS
Apache
Integrity
Availability
(2)(see Appendix A) CVE-2000-0884
(3)(see Appendix A) CVE-2000-0884
-
-
Content-Type headers. For example, a rule can deﬁne a relation between the outputs,
e.g., between the status code of the several outputs. Another example would be to link a
particular input type to its expected outputs. These rules deﬁne the equivalence relation
that have been deﬁned in Section 3.3. For example, the Figure 3 describes a particular
rule where we deﬁne that apache does not return the same status code than IIS or thttpd
when a directory content is requested but the last ’/’ character is missing: Apache returns
301 when IIS and thttpd returns 302. If this speciﬁcation difference is detected, the
Apache answer status code is modiﬁed to be equal to the IIS reponse. Then, a classical
voting algorithm can be applied to the responses.
The deﬁnition of the rules must be precise enough to ensure that no intrusion would
be missed (i.e., a difference due to a vulnerability must not be part of these rules).
This deﬁnition is, in the current state of this work, made incrementally by analysing
manually the alerts that are provided by the IDS. The accuracy of the detection is thus
driven by a base of rules that must be built by the administrator. This set of rules is
dependent on a number of parameters, such as the COTS used, and their version. As
a consequence, it requires an effort in order to update the base of rules (e.g., at each
upgrade of the web servers). According to our experience, this effort is low (the analysis
of differences and the deﬁnition of the rules for one month of HTTP requests took us
only one day).
It is not possible to deﬁne all differences using these rules. For example, Windows
does not differentiate lower case letters from upper case letters, and thus we had a lot
of behaviour differences due to this system speciﬁcation difference. Thus we added a
mechanism in the proxy which processes the requests to standardize them before they
are sent to the servers. Thus, all web servers provide the same answers.
The output difference masking is thus divided in two parts: pre-request masking
mechanisms that standardize the inputs and post-request masking mechanisms that
mask the differences that are not due to errors in the servers.
4.2 Experimental Results
The objective of the tests that have been conducted is to evaluate the proposed approach
in terms of both reliability and accuracy of the detection process. The reliability of the
approach is its ability to detect correctly the intrusions, as the accuracy refers to its
behaviour in term of false positives generation.
In this section, we detail the two phases of the evaluation process. The reliability is
evaluated by conducting attacks against the set of web servers composing the architec-
ture. The accuracy is evaluated by applying the detection method to a set of server logs.
This second set of results is then compared with the ones obtained with well known
IDSes.
56
E. Totel, F. Majorczyk, and L. Mé
Output Differences Detected
Alerts raised; 131; 0,37%