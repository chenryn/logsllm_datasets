Regarding the lack of context and knowledge (C2), all participants provided
positive feedback (17/17). The only concern was about extracting information
frommultipleSLRsfollowingdifferentapproachesandthetoolmixingthemup.
Thestrategies toaddressthelimitation ofdigital libraries (C3) also received
positive feedback (15/17). The argument against it came from an author not
sureabouttheeffectiveness“I’m not sure if searching by [RQs] will help identify
an area which needs more research or just other SLRs .. [it] just seems like a
‘type’ filter as e.g. in Scopus or adding ‘review’ in Title from Google Scholar”.
Among the suggestions we can mention: i) adapt the builtin guidelines to
the target domain of the SLR, and consider other frameworks such as PICO, ii)
extend the SLR extraction capabilities to recommend highly reputable venues,
infer the guidelines to follow and create a to-do list authors could follow, iii)
expand the search to suggest research that is very relevant, and iv) include
explanations for as to why papers are suggested.
On How Cognitive Computing Will Plan Your Next Systematic Review 329
4 Conceptual Architecture
In delivering on the vision of cognitive support in the planning of SLRs, we rely
on the framework for cognitive process augmentation by Barukh et al. [2].
As we will see, the strategies we devised inform this architecture at different
layers.
Foundation: Existing technology provides support for coordinating data, tasks
and collaboration that we can leverage to build our vision of a cognitively-
augmented planning process. Starting from the process itself, we have seen the
planning of SLRs to be an incremental and iterative process leading to a review
protocol. The process management in this context could rely on lightweight
artifact-centric systems (e.g., Gelee [1]) where the researcher drives the process
whilethesystemadvisesonthestepstotakebasedoncommunity-specificguide-
lines.Alongtheprocess,sometasksarealreadysupportedbycurrentonlineser-
vices,suchthesearchandaccesstoscientificarticles.Digitallibrariesandsearch
engines provide access to article data and metadata, but under the limitations
pointedoutintheprevioussection,requiringresearcherstoengageinsignificant
manualeffort.Thus,althoughthedataandknowledgerequiredtoelaboratethe
research protocol and inform the process is available, identifying, curating and
adopting such knowledge is a challenging endeavour.
Enablement: The next layer leverages existing data sources and services to
apply domain-specific data extraction and enrichment that will enable cognitive
augmentation. Components such as article recommendation, enabling search for
similar SLRs and papers, article augmentation, enriching SLRs with domain-
specific metadata, activity recommendation, recommending steps based on pro-
cessdefinitionsandprogress,andknowledgegraph,aggregatingknowledgeabout
theprocessinqueryableformat,areamongtheenablingcomponents.Inthiscon-
text,SLRs,primaryresearcharticles,andguidelinesonhowtoruntheSLRpro-
cess,arethemainsourcesofinformation.Lower-levelalgorithmssuchasnamed-
entity recognition, word-embeddings and similarity serve as building blocks for
these higher level components.
Delivery: The researcher finally experiences the cognitive augmentation in the
planning through Conversational AI as well as intelligent GUIs. Conversational
AI helps in delivering assistance in the process, providing a natural language
interface to query the vast knowledge encoded in guidelines, and receive practi-
cal assistance in each step of the process. In the form of more general conversa-
tional interfaces, guided prompts would provide step-by-step guidance to assist
researchers in knowledge-intensive tasks (e.g., defining RQs). We also recognise
the need for serving more traditional delivery systems such as GUIs, to dote
complex tasks with intelligent features (e.g., domain-specific search).
5 Prototype Implementation and Evaluation
In this section we describe our ongoing exploration into the technical feasibility
of our approach.
330 M. Badami et al.
We started with article recommendation as it emerged as a promising com-
ponent based on the feedback from SLR authors, but raised concerns in terms
of feasibility. We note however that providing support for identifying related
SLRs has all the potential benefits but fewer of the concerns (e.g., recall and
accuracy) with respect to assisting the identification and screening of relevant
literature [12]. In the planning, bringing up the most relevant SLRs and papers
canprovidetheadditionalcontextinataskthatsomepeoplearenotevenaware
of.
Prototype. The prototype is our initial exercise into understanding the tech-
nical requirements of the system, as well as a working tool to serve evaluation
purposes. On the surface, the current version of the prototype provides a set of
REST APIs (and an accompanying user interface) that given a set of RQs in
input,itreturnsthemostrelevantSLRs,alongwiththerelevancescorecomputed
based on the available models. Figure4 presents the pipeline of the implemen-
tation.
The source of information is currently a curated database of SLRs, where
domain-specific information has been manually extracted so as to evaluate the
recommendationcomponentinisolation.Theendgoalistohaveadatalayerthat
can interface with existing services to access structured and unstructured data,
which can then be processed to automatically extract relevant domain-specific
information.WhilewecurrentlyuseaMySQLdatabasetostoreandretrieveraw
andcurateddata,theconceptofData Lake [3]emergesasapromisingdirection
to store and query structured and unstructured SLR data.
Collecting Data Raw and Curated Data
Input ,Raw Data (e A.g b. s, tR rae cs te sa )rch Question, SLR Data pre-processing and cleaning Save ECIVRES
Data Storage (MYSQL)
Extracting Data
LUFTSER
Retrive
Output ,Curated Data (e.g., Similarity of Word Embedding Learning
research question and abstracts ) Raw and Curated Data
Similarity calculation and matching
Delivery Layer Cognitive Augmentation (Enablement Layer) Data Layer
Fig.4. Architecture pipeline
In entering the augmentation layer, the data is pre-processed in two steps:
(a)normalizingtextcorpus(e.g.,removingspecialcharactersandstopwords,all
to lowercase); and (b) lemmatizing and converting each word to its base form.
We leverage Stanford CoreNLP toolkit2 to perform this process.
Following the data cleaning, the next step is to extract meaningful informa-
tionfromthedata.Theinspirationbehindourproposedapproachisleveraginga
similar approach to the word embedding’s model [18] that represents words in a
VectorSpaceModel(VSM).Wehaveextendedtheideaofconsideringa“word”
2 https://nlp.stanford.edu/software/tagger.html.
On How Cognitive Computing Will Plan Your Next Systematic Review 331
asavectortorepresenttheSLR-relatedcorpus(e.g.,RQsandSLRabstracts)in
a vector space. To create the VSMs, we employ an N-gram selector component
to extract all the keywords (nouns and verbs) from sentences of the given con-
text. We leverage Stanford Part-Of-Speech (POS) Tagger [15] to achieve this.
Then,wecreatealistofn-gramsoutofthesekeywordsandtransformtheminto
vectorrepresentationsforeachcorpus.Afterencodingthegivencorporaintovec-
tors, these vectors are used to calculate the similarity between desired corpora.
Information is then augmented based on a pool of word embedding models.
Our work leverages state-of-the-art algorithms widely used in NLP communi-
ties.Severalsuchalgorithms(e.g.GloVe[21],Word2Vec[17],Numberbatch[24],
WikiNewsFast[4],andGoogleNews[5])comewithefficientimplementationsthat
are readily available as libraries to use.
TheRESTAPIsthenexposethefunctionalityofthearticlerecommendation
componentforprogrammaticaccess.Afront-endapplicationtakestheseservices
and wraps them up in a user interface.
Planned Evaluation. The goal of the initial evaluation is to inform specific
design decisions regarding the algorithmic support for recommending papers.
Among the main design decisions we consider: i) What models will better serve
thespecifictask? Theideaistoidentifyamongtheembeddingmodelsandarchi-
tectures the most promising candidates to build on, and understand whether
investingindomain-specificembeddingmodelsisrequired.Then,ii)Whatinfor-
mation should we leverage when assessing the relevance calculations? (e.g.,title,
title-abstract, RQs, full-text). The aim is to understand what (combinations of)
information to focus when assessing the relevance of SLRs from an input RQs,
and therefore to consider in the extraction process.
The prototype supports these two dimensions, models and selective infor-
mation, so as to serve the evaluations. The dataset of SLRs is being manually
constructedtoincorporateforeachSLRasetofrelatedSLRs(asreportedinthe
reviews) and not relevant SLRs as judged by human experts. Armed with the
human-annotated dataset, we evaluate the quality of word embedding models
by assessing how well the similarity scores of the word vectors correlate with
human judgment [23]. The similarity is calculated as the distance between the
vectors representing RQs and SLRs, using cosine similarity as measure, which
has been found suitable for SLRs in prior work [14].
We rely on Spearman’s rank (r s) correlation between the word embedding
models similarity score and researchers annotations to evaluate how well the
similarity of the given pairs (e.g., RQs and abstracts) agrees with human judg-
ments[10].Weperformedapreliminarytestruntotunetheexperimentalsetup,
andtheearlyresultsareencouraging.Resultsunderlimitedsettings(e.g.,dataset
of 160 SLRs, only abstract-RQ comparisons) already show good level of agree-
ment (rs = 0.67), for the best performing model, although at this point this is
anecdotal since more comprehensive tests are required.
332 M. Badami et al.
6 Conclusion and Future Work
Wehaveseenthatplanningisachallengingendeavor,requiringresources,exper-
tise or context that is often missing when undertaking a new topic, when per-
forming it for the first time, or when resources arelacking – all typical scenarios
in research. This paper shows that cognitive processes provide the ingredients
to address these issues and support researchers in this often overlooked but
impactful phase. As for ongoing and future work, we are in the process of refin-
ingthetechnicaldetailsofthefirstexperiment,andplanninganevaluationwith
end-users so as to assess the actual benefits of the approach when compared
to standard tools. We also continue with our human-centered design approach
to the development of the overall tool and algorithms, which will inform all
components of the platform.
Acknowledgments. WeacknowledgeCSIROData61forfundingscholarshiponthis
research.
References
1. B´aez,M.,etal.:Gelee:cooperativelifecyclemanagementfor(composite)artifacts.
In: Baresi, L., Chi, C.-H., Suzuki, J. (eds.) ICSOC/ServiceWave -2009. LNCS,
vol. 5900, pp. 645–646. Springer, Heidelberg (2009). https://doi.org/10.1007/978-
3-642-10383-4 50
2. Barukh,M.C.,etal.:Cognitiveaugmentationinprocesses.In:Aiello,M.,Bouguet-
taya,A.,Tamburri,D.A.,vandenHeuvel,W.-J.(eds.)Next-GenDigitalServices.
A Retrospective and Roadmap for Service Computing of the Future. LNCS, vol.
12521, pp. 123–137. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-
73203-5 10
3. Beheshti, A., Benatallah, B., Nouri, R., Chhieng, V.M., Xiong, H.T., Zhao, X.:
Coredb: a data lake service. In: Proceedings of the 2017 ACM on Conference on
Information and Knowledge Management, pp. 2451–2454 (2017)
4. Bojanowski, P., Grave, E., Joulin, A., Mikolov, T.: Enriching word vectors with
subword information. Trans. Assoc. Comput. Linguist. 5, 135–146 (2017)
5. Kenneth Ward Church: Word2vec. Nat. Lang. Eng. 23(1), 155–162 (2017)
6. Cr´equit, P., Trinquart, L., Yavchitz, A., Ravaud, P.: Wasted research when sys-
tematic reviews fail to provide a complete and up-to-date evidence synthesis: the
example of lung cancer. BMC Med. 14(1), 8 (2016)
7. Garousi, V., Felderer, M.: Experience-based guidelines for effective and efficient
data extraction in systematic reviews in software engineering. In: Proceedings of
the21stInternationalConferenceonEvaluationandAssessmentinSoftwareEngi-
neering, pp. 170–179 (2017)
8. Hassler,E.,Carver,J.C.,Hale,D.,Al-Zubidy,A.:IdentificationofSLRtoolneeds-
results of a community workshop. Inf. Software Technol. 70, 122–129 (2016)
9. Howard,B.E.,etal.:Swift-review:atext-miningworkbenchforsystematicreview.
Syst. Rev. 5(1), 87 (2016)
10. Huang, E.H., Socher, R., Manning, C.D., Ng, A.Y.: Improving word representa-
tionsviaglobalcontextandmultiplewordprototypes.In:Proceedingsofthe50th
AnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:Long
Papers), pp. 873–882 (2012)
On How Cognitive Computing Will Plan Your Next Systematic Review 333
11. Kitchenham, B.: Procedures for performing systematic reviews. Keele, UK, Keele
University 33(2004), 1–26 (2004)
12. Kontonatsios, G., et al.: A semi-supervised approach using label propagation to
support citation screening. J. Biomed. Inform. 72, 67–76 (2017)
13. Krivosheev, E., Casati, F., Baez, M., Benatallah, B.: Combining crowd and
machines for multi-predicate item screening. Proc. ACM Hum.-Comput. Interact.
2(CSCW), 1–18 (2018)
14. Lopes, A.A., Pinho, R., Paulovich, F.V., Minghim, R.: Visual text mining using
association rules. Comput. Graph. 31(3), 316–326 (2007)
15. Manning, C.D., Surdeanu, M., Bauer, J., Finkel, J.R., Bethard, S., McClosky,
D.: The Stanford Corenlp natural language processing toolkit. In: Proceedings of
52nd Annual Meeting of the Association for Computational Linguistics: System
Demonstrations, pp. 55–60 (2014)
16. Marshall,I.J.,Kuiper,J.,Wallace,B.C.:Robotreviewer:evaluationofasystemfor
automatically assessing bias in clinical trials. J. Am. Med. Inform. Assoc 23(1),
193–201 (2016)
17. Mikolov, T., Chen, K., Corrado, G., Dean, J.: Efficient estimation of word repre-
sentations in vector space. arXiv preprint arXiv:1301.3781 (2013)
18. Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J.: Distributed repre-
sentationsofwordsandphrasesandtheircompositionality.InAdvancesinNeural
Information Processing Systems, pp. 3111–3119 (2013)
19. Ouzzani, M., Hammady, H., Fedorowicz, Z., Elmagarmid, A.: Rayyan-a web and
mobile app for systematic reviews. Syst. Control Found. Appl. 5(1), 210 (2016)
20. Palomino, M., D´avila, A., Melendez, K.: Methodologies, methods, techniques and
toolsusedonSLRelaboration:amappingstudy.In:Mejia,J.,Mun˜oz,M.,Rocha,
A´., Pen˜a, A., P´erez-Cisneros, M. (eds.) CIMPS 2018. AISC, vol. 865, pp. 14–30.
Springer, Cham (2019). https://doi.org/10.1007/978-3-030-01171-0 2
21. Pennington, J., Socher, R., Manning, C.D.: Glove: global vectors for word repre-
sentation.In:Proceedingsofthe2014ConferenceonEmpiricalMethodsinNatural
Language Processing (EMNLP), pp. 1532–1543 (2014)
22. Sampson, M., Shojania, K.G., Garritty, C., Horsley, T., Ocampo, M., Moher, D.:
Systematic reviews can be produced and published faster. J. Clin. Epidemiol.
61(6), 531–536 (2008)
23. Shi, B., Lam, W., Jameel, S., Schockaert, S., Lai, K.P.: Jointly learning word
embeddings and latent topics. In: Proceedings of the 40th International ACM
SIGIR Conference on Research and Development in Information Retrieval, pp.
375–384 (2017)
24. Speer, R., Chin, J., Havasi, C.: Conceptnet 5.5: an open multilingual graph of
general knowledge. arXiv preprint arXiv:1612.03975 (2016)
25. Sun, Y., et al.: Crowdsourcing information extraction for biomedical systematic
reviews. arXiv preprint arXiv:1609.01017 (2016)
26. Vaish, R., et al.: Crowd research: open and scalable university laboratories. In:
Proceedingsofthe30thAnnualACMSymposiumonUserInterfaceSoftwareand
Technology, pp. 829–843 (2017)
Security Professional Skills
Representation in Bug Bounty Programs
and Processes
B B
Sara Mumtaz1( ), Carlos Rodriguez2( ), and Shayan Zamanirad1
1 School of Computer Science and Engineering, UNSW Sydney,
Kensington, NSW 2052, Australia
{s.mumtaz,shayan.zamanirad}@unsw.edu.au
2 Universidad Cat´olica Nuestra Sen˜ora de la Asunci´on, Asunci´on, Paraguay
PI:EMAIL
Abstract. The ever-increasing amount of security vulnerabilities dis-
covered and reported in recent years are significantly raising the con-
cernsoforganizationsandbusinessesregardingthepotentialrisksofdata
breachesandattacksthatmayaffecttheirassets(e.g.thecasesofYahoo
and Equifax). Consequently, organizations, particularly those suffering
fromtheseattacksarerelyingonthejobofsecurityprofessionals.Unfor-
tunately,duetoawiderangeofcyber-attacks,theidentificationofsuch
skilledsecurityprofessionalisachallengingtask.Onesuchreasonisthe
“skillgap”problem,amismatchbetweenthesecurityprofessionals’skills
andtheskillsrequiredforthejob(vulnerabilitydiscoveryinourcase).In