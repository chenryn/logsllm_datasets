Bind
Memcached
Redis
SVF
38.2K
23.8K
3.0K
67.9K
7.6K
33.8K
+ Arg. Type
+ Address Taken
11.6K
12.4K
2.7K
33.7K
6.2K
18.6K
11.5K
11.1K
2.7K
33.3K
5.8K
18.6K
Application Bitcode
Size(MB)
Nginx
Apache
Lighttpd
Bind
Memcached
Redis
1.9
2.1
1.0
11.0
1.6
9.2
Default
(min)
1
3
1
3
1
1
SVF w.
Arg. Type
+80
+13
+1
+554
+1
+21
+ Addr.
Taken
+2
+1
+1
+5
+1
+1
Temp.
Total
83
17
3
562
3
23
100 client requests and validated the responses, without en-
countering any issues. We also compared the server logs in
both cases to further ensure the absence of any internal errors
that are not visible at the client side.
6.1 Call Graph Analysis
Identifying the transition boundary between the initializa-
tion and serving phase for the applications we consider is
straightforward. We begin by providing some further de-
tails for each application. For Nginx [7], we use the de-
fault conﬁguration with all the default modules enabled.
Nginx has three functions that can act as transition points
to the serving phase: ngx_worker_process_cycle and
ngx_single_process_cycle are used for handling client
requests, while ngx_cache_manager_process_cycle is re-
sponsible for cache management. Each of them runs in its
own separate thread.
We use the vanilla conﬁguration of Apache Httpd [15],
statically compiled with libapr and libapr-util to make
our analysis simpler. Our conﬁguration enables all default
modules. The transition boundary of the serving phase is the
child_main function.
Lighttpd has an event-driven architecture, not relying on a
primary–secondary process model. It can be launched with a
conﬁgurable number of processes, and each process executes
the server_main_loop function to handle client requests.
Bind is one of the most widely used DNS servers, acting as
both an authoritative name server and as a recursive resolver.
Bind uses multi-threading to handle client requests and enters
the serving phase after creating the secondary threads, by
invoking the isc_app_ctxrun function.
Memcached and Redis are both in-memory key-value
databases. Similarly to Lighttpd, Memcached also has an
event-driven architecture and executes the worker_libevent
function to serve client requests. In Redis, the aeMain func-
tion serves as the event processing loop.
As shown in Table 1, these applications vary in complexity,
with the number of edges in the initial call graph (generated
by SVF) ranging from 3K for Lighttpd to 67.9K for Bind.
By applying our pruning techniques based on argument types
and taken addresses, the precision of the points-to analysis
Table 3: Number of system calls retained (out of 333 available)
after applying library debloating and temporal specialization.
Application
Nginx
Apache
Lighttpd
Bind
Memcached
Redis
Library
Debloating
Temporal Specialization
Initialization
Serving
104
105
95
127
99
90
104
94
95
99
99
90
97
79
76
85
84
82
improves signiﬁcantly, reducing the number of spurious edges
to half or even less, especially for the most complex applica-
tions. This improvement allows us to disable more system
calls during the serving phase of each application. For exam-
ple, in case of Apache Httpd, using the more imprecise results
of SVF alone does not allow the removal of security-sensitive
system calls such as execve.
The complexity of each application affects the analysis
time required to generate the call graph. Table 2 shows the
breakdown of the amount of time required for generating
the call graph in each step, with the total time for the whole
toolchain in the last column. We compiled each application
10 times and report the average time. The compilation time is
only a few seconds different in each case for all applications.
The analysis time ranges from three minutes for Lighttpd to
more than nine hours for Bind. The most time-consuming
aspect of our approach is running Andersen’s points-to analy-
sis algorithm, which is expected. While one could use other
algorithms, such as Steensgard’s [54], which are both more ef-
ﬁcient and more scalable, they come at the price of precision.
We discuss other algorithms and tools which can be used to
generate call graphs in Section 7.
6.2 Filtered System Calls
We compare our approach with library specialization [12, 51]
to show the beneﬁt of applying temporal specialization. As
shown in Table 3, once entering the long-term serving phase,
temporal specialization retains fewer system calls than static
USENIX Association
29th USENIX Security Symposium    1757
Table 4: Critical system calls removed by library specialization (“Lib.”) and temporal specialization (“Temp.”).
Syscall
n clone
o
i
t
u
c
e
x
E
d
m
C
n
o
i
s
s
i
m
r
e
P
g
n
i
k
r
o
w
t
e
N
execveat
execve
fork
ptrace
chmod
mprotect
setgid
setreuid
setuid
accept4
accept
bind
connect
listen
recvfrom
socket
Nginx
Lib.

















Temp.

















Apache Httpd
Lib.
Temp.

















*
















Lighttpd
Lib.

















Temp.
*

O














Bind
Temp.
*
















Lib.

















Memcached
Lib.
Temp.





