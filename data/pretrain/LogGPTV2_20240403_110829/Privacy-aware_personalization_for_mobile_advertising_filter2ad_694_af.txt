protect anonymity of users and privacy of their locations [26]. A
user’s location in the query is replaced by a broader region [20]
with at least k users in it [38]. This approach is extended to gen-
eral contexts beyond location [36]. Following the principles of (cid:96)-
diversity [32] a region is broad enough if it’s area is large enough
and its ratio of sensitive area to total area is low enough (see for
instance [9]). Most solutions (e.g., [35]) follow a hybrid approach
in which, given a generalized context, the server returns a super-
set of the results [26], which can lead to high communication cost.
Notable exceptions approximate the results and allow to trade off
efﬁciency and accuracy [10, 28, 47]. We follow the same goals of
LBS: privacy, utility and efﬁciency. While LBS focus on nearest
neighbor queries measuring utility as proximity, our work focuses
on target advertisements measuring utility as revenue or ad rele-
vance. Previous techniques cannot be applied to this problem.
Privacy-Preserving Distributed Count Protocols.Previous work
on distributed counting protocols [1, 12, 37, 40] provides strong
privacy guarantees. Early work by Dwork et al. [12] required the
exchange of a number of messages quadratic in the number of
users. This is prohibitively expensive in our setting. Follow-up
work by Rastogi et al. [37], Shi et al. [40], and Ács et al. [1] re-
duced the number of messages to be linear in the number of users.
In Section 5.5, we empirically showed that even under modest as-
sumptions on user dynamics, all these existing protocols need to
repeat various phases impractically high numbers of times. This is
problematic in our setting with a large number of transient mobile
users.
Follow-up work by Chen et al. [8] extended our Count pro-
tocol in order to guarantee accuracy and prevent malicious users
from arbitrarily altering the result. This is achieved by using the
Goldwasser-Micali bit encryption scheme [17] and adding noise at
the proxy.
7. CONCLUSION
We have addressed the problem of personalizing ad delivery to
a smart phone, without violating user privacy. We showed that the
problem of selecting the most relevant ads under constraints on pri-
vacy and efﬁciency is NP-hard and proposed a solution with a tight
approximation guarantee. We also proposed the ﬁrst differentially-
private distributed protocol to compute various statistics required
for our framework even in the presence of a dynamic and malicious
set of participants. Our experiments on real click logs showed that
reasonable levels of privacy, efﬁciency, and ad relevance can be
achieved simultaneously.
8. REFERENCES
[1] Gergely Ács and Claude Castelluccia. I have a dream!: differentially
private smart metering. In Proceedings of the 13th international
conference on information hiding (IH), 2011.
[2] Gagan Aggarwal, Mayank Bawa, Prasanna Ganesan, Hector
Garcia-Molina, Krishnaram Kenthapadi, Rajeev Motwani, Utkarsh
Srivastava, Dilys Thomas, and Ying Xu. Two can keep a secret: A
distributed architecture for secure database services. In CIDR, 2005.
[3] Bhuvan Bamba, Ling Liu, Peter Pesti, and Ting Wang. Supporting
anonymous location queries in mobile environments with
privacygrid. In WWW, 2008.
[4] Thorben Burghardt, Klemens Böhm, Achim Guttmann, and Chris
Clifton. Anonymous search histories featuring personalized
advertisement - balancing privacy with economic interests.
Transactions on Data Privacy, 4(1):31–50, 2011.
[5] Georg Buscher, Susan T. Dumais, and Edward Cutrell. The good, the
bad, and the random: an eye-tracking study of ad quality in web
search. In SIGIR, 2010.
[6] A. Chen. Gcreep: Google engineer stalked teens, spied on chats.
http://gawker.com/5637234, September 2010.
[7] Bee-Chung Chen, Daniel Kifer, Kristen LeFevre, and Ashwin
Machanavajjhala. Privacy-preserving data publishing. Foundations
and Trends in Databases, 2(1-2):1–167, 2009.
[8] Ruichuan Chen, Alexey Reznichenko, Paul Francis, and Johannes
Gehrke. Towards statistical queries over distributed private user data.
In NSDI, 2012.
[9] Reynold Cheng, Yu Zhang, Elisa Bertino, and Sunil Prabhakar.
Preserving user location privacy in mobile data management
infrastructures. In Privacy Enhancing Technologies, 2006.
[10] Chi-Yin Chow, Mohamed F. Mokbel, Joe Naps, and Suman Nath.
Approximate evaluation of range nearest neighbor queries with
quality guarantee. In SSTD, 2009.
[11] Direct Marketing News. Mobile marketing to ’explode’ in 2012.
http://www.dmnews.com/
mobile-marketing-to-explode-in-2012/article/
222991/, January 2012.
[12] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya
Mironov, and Moni Naor. Our data, ourselves: Privacy via distributed
noise generation. In EUROCRYPT, volume 4004, 2006.
[13] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.
Calibrating noise to sensitivity in private data analysis. In TCC, 2006.
[14] Uriel Feige. A threshold of ln n for approximating set cover. Journal
of the ACM, 45:314–318, 1998.
[15] Matthew Fredrikson and Benjamin Livshits. REPRIV: Re-imagining
content personalization and in-browser privacy. In IEEE Symposium
on Security and Privacy (Oakland), 2011.
[16] William Gasarch. A survey on private information retrieval. Bulletin
of the EATCS, 82:72–107, 2004.
[17] Shaﬁ Goldwasser and Silvio Micali. Probabilistic encryption. J.
Comput. Syst. Sci., 28(2):270–299, 1984.
[18] Michaela Götz. On User Privacy in Personalized Mobile Services.
PhD thesis, Cornell University, 2012.
[19] Michaela Götz, Ashwin Machanavajjhala, Guozhang Wang, Xiaokui
Xiao, and Johannes Gehrke. Publishing search logs - a comparative
study of privacy guarantees. TKDE, 99(PrePrints), 2011.
[20] Marco Gruteser and Dirk Grunwald. Anonymous usage of
672location-based services through spatial and temporal cloaking. In
MobiSys, 2003.
[21] Saikat Guha, Bin Cheng, and Paul Francis. Challenges in Measuring
Online Advertising Systems. In IMC, 2010.
[22] Saikat Guha, Alexey Reznichenko, Kevin Tang, Hamed Haddadi, and
Paul Francis. Serving Ads from localhost for Performance, Privacy,
and Proﬁt. In HotNets, 2009.
[23] Moritz Hardt and Guy Rothblum. A multiplicative weights
mechanism for interactive privacy-preserving data analysis. In
FOCS, 2010.
[24] Michael Hay, Vibhor Rastogi, Gerome Miklau, and Dan Suciu.
Boosting the accuracy of differentially private histograms through
consistency. PVLDB, 3(1):1021–1032, 2010.
[25] Dorit Hochbaum and Anu Pathria. Analysis of the Greedy Approach
in Problems of Maximum k-Coverage. Naval Research Logistics,
45(6):615–627, 1998.
[26] Christian S. Jensen, Hua Lu, and Man Lung Yiu. Location Privacy
Techniques in Client-Server Architectures, pages 31–58.
Springer-Verlag, 2009.
[27] Ari Juels. Targeted advertising ... and privacy too. In CT-RSA, 2001.
[28] Ali Khoshgozaran and Cyrus Shahabi. Blind evaluation of nearest
neighbor queries using space transformation to preserve location
privacy. In SSTD, 2007.
[29] Aleksandra Korolova. Privacy violations using microtargeted ads: A
case study. In PADM, 2010.
[30] Andreas Krause and Eric Horvitz. A utility-theoretic approach to
privacy and personalization. In AAAI, 2008.
[31] Ashwin Machanavajjhala, Daniel Kifer, John M. Abowd, Johannes
Gehrke, and Lars Vilhuber. Privacy: Theory meets practice on the
map. In ICDE, 2008.
[32] Ashwin Machanavajjhala, Daniel Kifer, Johannes Gehrke, and
Muthuramakrishnan Venkitasubramaniam. (cid:96)-diversity: Privacy
beyond k-anonymity. TKDD, 1(1), 2007.
[33] Frank McSherry and Ratul Mahajan. Differentially-private network
trace analysis. In SIGCOMM, 2010.
[34] Emiliano Miluzzo, Cory T. Cornelius, Ashwin Ramaswamy,
Tanzeem Choudhury, Zhigang Liu, and Andrew T. Campbell. Darwin
phones: The evolution of sensing and inference on mobile phones. In
MobiSys, 2010.
[35] Mohamed F. Mokbel, Chi-Yin Chow, and Walid G. Aref. The new
casper: A privacy-aware location-based database server. In ICDE,
2007.
[36] Linda Pareschi, Daniele Riboni, Alessandra Agostini, and Claudio
Bettini. Composition and generalization of context data for privacy
preservation. In PerComm, 2008.
[37] Vibhor Rastogi and Suman Nath. Differentially private aggregation
of distributed time-series with transformation and encryption. In
SIGMOD, 2010.
[38] Pierangela Samarati and Latanya Sweeney. Protecting privacy when
disclosing information: k-anonymity and its enforcement through
generalization and suppression. Technical report, CMU, SRI, 1998.
[39] Xuehua Shen, Bin Tan, and ChengXiang Zhai. Implicit user
modeling for personalized search. In CIKM, 2005.
[40] Elaine Shi, T-H. Hubert Chan, Eleanor Rieffel, Richard Chow, and
Dawn Song. Privacy-preserving aggregation of time-series data. In
NDSS, 2011.
[41] Eran Toch, Justin Cranshaw, Paul Hankes Drielsma, Janice Y. Tsai,
Patrick Gage Kelley, James Springﬁeld, Lorrie Cranor, Jason Hong,
and Norman Sadeh. Empirical models of privacy in location sharing.
In Ubicomp, 2010.
[42] Vincent Toubiana, Helen Nissenbaum, Arvind Narayanan, Solon
Barocas, and Dan Boneh. Adnostic: Privacy preserving targeted
advertising. In NDSS, 2010.
[43] Xiaokui Xiao, Guozhang Wang, and Johannes Gehrke. Differential
privacy via wavelet transforms. In ICDE, 2010.
[44] Yabo Xu, Ke Wang, Benyu Zhang, and Zheng Chen.
Privacy-enhancing personalized web search. In WWW, 2007.
[45] Mingqiang Xue, Panos Kalnis, and Hung Keng Pung. Location
diversity: Enhanced privacy protection in location based services. In
LoCA, 2009.
[46] Jun Yan, Ning Liu, Gang Wang, Wen Zhang, Yun Jiang, and Zheng
Chen. How much can behavioral targeting help online advertising?
In WWW, 2009.
[47] Man Lung Yiu, Christian S. Jensen, Xuegang Huang, and Hua Lu.
Spacetwist: Managing the trade-offs among location privacy, query
performance, and query accuracy in mobile services. In ICDE, 2008.
APPENDIX
A. PROOFS
A.1 Proof of Corollary 4.3
PROOF. Consider two neighboring click logs L, L(cid:48) where L(cid:48) is ob-
tained from L by adding or deleting the data of a single user. Consider
the hierarchy H consisting of height(H) levels where level i contains 2i
many nodes. We denote by cl,j (c(cid:48)
l,j, respectively) the count of the jth
node at level l in L (L(cid:48), respectively). We denote by cl,j,a,1 (c(cid:48)
l,j,a,1) the
count of the clicks on a in the jth node at level l and by cl,j,a,0 (c(cid:48)
l,j,a,0)
the count of the views of a in the jth node at level l that did not result in
clicks in L (L(cid:48), respectively).
Within a level of the hierarchy the L2-sensitivity of each count is at most
m. Overall the square of the L2-sensitivity is at most
(cl,j − c(cid:48)
l,j )2
height(H)−1(cid:88)
2l(cid:88)
(cid:88)
(cl,j,a,1 − c(cid:48)
height(H)−1(cid:88)
j=1
l=0
+
a
≤
3 · m2
l=0
l,j,a,1)2 + (cl,j,a,0 − c(cid:48)
l,j,a,0)2
(1)
(2)
(3)
= 3height(H)m2
Thus, the L2-sensitivity is bounded by (cid:112)(3height(H)m. From Theo-
rem 4.1 it follows that choosing σ2 ≥ 3height(H)m22 log(4/δ)/2 guar-
antees (, δ) probabilistic differential privacy.
A.2 Utility Analysis of Algorithm 2
We deﬁne the utility of an estimate (cid:91)CTR(a|v) by comparing it to the
(4)
true click-through-rate:
clicks_truea,v
clicks_truea,v + no_clicks_truea,v
We say the estimate is (α, β)-accurate if with probability at least β:
(cid:91)CTR(a|v) ≥
(cid:91)CTR(a|v) ≤
clicks_truea,v − α
clicks_truea,v + no_clicks_truea,v + 2α
clicks_truea,v + α
clicks_truea,v + no_clicks_truea,v − 2α
(5)
(6)
Consider our protocol Estimates (and its parameters N, t, σ as in Corol-
lary 4.3) and suppose all users respond truthfully. Then the computed esti-
mates are (α, β)-accurate for
β ≤ 1−3/(2πα)σ(cid:112)(N/((1−t)N −1)) exp−α2((1−t)N−1)/(2N σ2) .
The proof follows from a Gaussian tail bound that we can use to bound the
probabilities of
|clicks_truea,v − clicksa,v| > α and
|no_clicks_truea,v − no_clicksa,v| > α
(7)
(8)
However, it may happen that the algorithm does not output an estimate
(cid:91)CTR(a|v) for some a, v if the noisy count of context v or some ancestor in
the context hierarchy is less than the min_support.
673