o
i
t
c
n
u
F
g
n
i
r
e
d
r
o
e
R
k
c
o
l
B
c
i
s
a
B
(cid:2)* (cid:2)* (cid:2)* (cid:2)* (cid:2)*
(cid:2)*
(cid:2)* (cid:2)*
.
d
n
a
R
.
g
n
i
p
p
a
M
.
l
l
a
c
s
y
S
(cid:2)
.
d
n
a
R
t
u
o
y
a
L
k
c
a
t
S
(cid:2)
(cid:2)
(cid:2)
(cid:2)
.
d
n
a
R
.
r
d
d
A
e
s
a
B
(cid:2)
(cid:2)
(cid:2)
(cid:2)
.
d
n
a
R
t
n
i
o
P
y
r
t
n
E
.
b
i
L
(cid:2)*
(cid:2)
.
d
n
a
R
g
n
i
d
o
c
n
E
.
g
o
r
P
(cid:2)*
(cid:2)
(cid:2)
.
d
n
a
R
h
p
a
r
G
l
l
a
C
.
d
n
a
R
a
t
a
D
(cid:2)* (cid:2)*
(cid:2)*
(cid:2)*
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)* (cid:2)* (cid:2)* (cid:2)* (cid:2)* (cid:2)*
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)* (cid:2)*
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)* (cid:2)*
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2) (cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)*
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2) (cid:2) (cid:2) (cid:2)
(cid:2)
(cid:2)
Legend: A. . .implementation time, C. . .compilation time, L. . .load time, B. . .link time, I. . .installation time, E. . .execution time, U . . .update time.
ASLR4 is implemented. A compiler prepares the code for base
address randomization by generating position-independent code;
the operating system loader and dynamic linker then adjust the
virtual memory addresses at which the code is loaded.
Consequently, with deferred diversiﬁcation, all instances
of a program share the same on-disk representation—only the
in-memory representations vary. This has several important
implications. Deferred approaches remain compatible with
current software distribution practices; the program delivered to
end users by simply copying the program or program installer.
When diversiﬁcation is deferred, the program vendor avoids
the cost of diversifying each program copy. Instead the cost
is distributed evenly among end users. The end user systems,
however, must be sufﬁciently powerful to run the diversiﬁcation
engine. While this is not an issue for traditional desktop and
laptop systems, the situation is less clear in the mobile and
embedded spaces.
Second, when diversiﬁcation is deferred, an attacker does
not improve the odds of a successful attack with knowledge of
the on-disk program representation.
However, deferred diversiﬁcation cannot provide protection
from certain attacks. Client-side tampering [15] and patch
reverse-engineering [17] remain possible since end users can
inspect the program binaries before diversiﬁcation. Software
4ASLR is an example of a diversiﬁcation technique that required compiler
customization to produce position independent code. All major C/C++ compilers
currently support this security feature.
diversiﬁcation can also be used for watermarking [23]. If a
seed value drives the diversiﬁcation process and a unique seed
is used to produce each program variant, the implementation
of each variant is unique, too. If each customer is given a
unique program variant, and the seed is linked to the purchase,
unautorized copying of the program binary can be traced back
to the original purchase. However, such use of diversity is also
hampered by deferred diversiﬁcation.
11) Implementation: The idea of software diversity was
originally explored as a way to obtain fault-tolerance in mission
critical software. Approaches to software fault-tolerance are
broadly classiﬁed as single-version or multi-version techniques.
Early examples of the latter kind include Recovery Blocks [52]
and N-Version programming [4] that are based on design
diversity. The conjecture of design diversity is that components
designed and implemented differently, e.g., using separate
teams, different programming languages and algorithms, have
a very low probability of containing similar errors. When
combined with a voting mechanism that selects among the
outputs of each component, it is possible to construct a robust
system out of faulty components.
Since design diversity is only increased at the expense of
additional manpower, these techniques are far too costly to see
application outside specialized domains such as aerospace and
automotive software. The remaining techniques we will discuss
aim to provide increased security, and are fully automatic and
thus relevant to a greater range of application domains. This
means that diversity is introduced later in the software life-cycle
281
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:27 UTC from IEEE Xplore.  Restrictions apply. 
Implementation
Randell’ 75
Avizienis and Chen’ 77
Sources
Compilation &
Linking
Memory Errors
Pax’01
Bhatkar et al.’05
Jackson et al.’11
Giuffrida et al.’12
Forrest et al.’97
Bhatkar et al.’03
de Sutter et al.’09
De Sutter et al.’09
Homescu et al.’13a
de Sutter et al.’09
Cohen ’93
Installation
Chew and Song’02
Loading
Execution
Bhatkar et al.’08
Native Code
Collberg et al.’12
de Sutter et al.’09
Jakob et al.’08
Pappas et al.’12
Hiser et al.’12
Wartell et al.’12
Gupta et al.’13
Davi et al.’13
Barrantes et al.’05
Williams et al.’09
Shioji et al.’12
Kc et al.’03
Novark et al.’10
Camouﬂage
Wei et al.’11
Homescu et al.’13b
Camouﬂage
Old Code
New Code
Updating (Linking)
Coppens et al.’13
i
p
r
e
-
d
s
t
r
i
b
u
t
i
o
n
i
p
o
s
t
-
d
s
t
r
i
b
u
t
i
o
n
p
r
e
-
d
s
t
.
i
Fault 
Tolerance
Memory 
Corruption
(§II.A.2)
Code 
Injection
(§II.A.3)
Code 
Reuse
(§II.A.4)
JIT 
Attacks
(§II.A.5)
Tampering
(§II.A.6)
Reversing
(§II.A.7)
Fig. 1: Approaches to software diversity in relation to the software life-cycle, their inputs, and the attacks they mitigate.
by a compiler or binary rewriting system.
12)Compilation and Linking: Implementing diversity in a
compiler makes the process automatic by avoiding changes to
the source code of programs. In contrast to humans, compilers
do not have a high-level understanding of the input source code
and must preserve semantics above all. This limits compile-time
diversity (and other fully automated approaches) to program
transformations that can be proven to preserve semantics. This
generally excludes high-level transformations such as changes
to the algorithms that make up a program; as Table I shows, a
plethora of lower-level transformations are possible.
Conceptually, compilers are structured as a sequence of
code transformation passes. The major passes include parsing
the source code into a compiler intermediate representation
(IR), performing machine-independent optimizations on the IR,
and ﬁnally converting the IR into a lower-level representation
to perform machine-dependent optimizations. The machine-
dependent passes make up the compiler back-end and include
optimizations such as instruction selection, instruction schedul-
ing, and register allocation. The randomizing transformations
surveyed in the preceding section are often implemented by
adding new pipeline passes; randomized register allocation or
randomized function inlining only require a few modiﬁcations
to the heuristics of existing passes. On the other hand,
transformations such as garbage insertion or opaque predicate
insertion are often added as new compilation passes. When
adding a diversifying transformation, care must be taken to
prevent later optimization passes from undoing its effects, e.g.,
dead-code elimination might unintentionally remove garbage
code.
From a software engineering perspective, re-purposing a
compiler to perform diversiﬁcation offers at least four beneﬁts:
Reuse avoids duplication of effort: Many of the ran-
domizing transformations described in Section III require data-
ﬂow analysis to determine if the randomizing transformation
is possible. Since compilers already contain the prerequisite
analyses [62], such transformations are easy to support.
Compilers target multiple hardware platforms: Com-
pilers are highly sophisticated and thus costly to produce and
maintain. The high costs are typically amortized by supporting
multiple instruction sets in the compiler back-end. The GNU
Compiler Collection release 4.8, for example, supports over 50
different hardware models and conﬁgurations. Consequently,
randomizing transformations can easily target all platforms
supported by the host compiler.
Compilation avoids the need for disassembly: The
transformation from source code to object code is a lossy
transformation. Optimizations obscure the original program
structure and code and data is interspersed. As a result,
perfect recovery of the original program control ﬂow is not
generally possible [13], [33]. Consequently, disassemblers rely
on heuristics that work most of the time. To preserve correctness
when these heuristics fail, runtime mechanisms are necessary