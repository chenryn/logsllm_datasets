tent storage (e.g., paper) for the human to check.
7.2 Coverage Criteria
We say that a test suite T satisﬁes our coverage criteria if the re-
sulting set of traces of P satisﬁes the following conditions:
C0: (Initial State Coverage) There is a test in which, from the ini-
tial output screen z0, P receives the cast input.
C1: (Transition Coverage)
(a) (Selection transitions) For every contest i, every selec-
tion state si within contest i, and every input b ∈ IS,
there is some trace where P receives b in a state (i, s)
where the ith component of s is si.
(b) (Navigation transitions) For every contest i, and every
input b ∈ IN , there is some trace where P receives b
in a state of the form (i, s).
C2: (Output Screen Coverage) For every contest i and every se-
lection state si of P within contest i, there is some trace of
P where the last transition within contest i ended at si and
then at some point thereafter P receives the cast input.
Criterion C0 speciﬁes that a human tester must verify that A and P
start with the same selection state.
Criterion C1 speciﬁes that we must cover all transitions of each Mi
within P (for every i), and all transitions of Mnav within P.
Criterion C2 ensures that for every (i, si), the tester gets an oppor-
tunity to view the output screen for that si as the last step in contest
i. This in turn ensures (through properties P2 and P3) that this se-
lection state of A for contest i appears on the cast vote record. The
main purpose of this criterion is to check that the interpretation
function IO is consistent with A’s output function, call it ρA, as
deﬁned by A’s Display module. Formally, IO must be the inverse
of A’s output function ρA. We know from Property P0 that ρA is
invertible, and that in contest i, it is only a function of (i, si), not of
any sj for i 6= j. Thus, effectively, C2 ensures that for every (i, si)
pair, the human tester computes (i′, s′
i) = IO(ρA(i, si)). The test
passes only if i = i′ and si = s′
i; i.e., only if IO is the inverse of
ρA. We formalize this result in Appendix C.
7.3 Main Theorem
We now state our main theorem that shows how our test coverage
criteria and results of formal veriﬁcation combine to ensure trace-
equivalence of A and P (up to an application of I).
Recall from Section 3.2 that A is correct iff Tr(P) = {I(τ ) : τ ∈
Tr(A)}.
THEOREM 1. Consider a test suite T that satisﬁes coverage
criteria C0–C2. Then, T passes if and only if A is correct.
The “if” part of the above theorem follows trivially. For brevity, we
only sketch out the proof of the “only if” part here, and include the
full proof in Appendix C.
PROOF. (sketch) Brieﬂy, the proof works by induction on the
length of the input sequence to the voting machine.
The idea is as follows. Consider an arbitrary input sequence T to
A. Due to determinism, we know that there is a single trace τA of
A on T . Correspondingly, we can extract the sequence I(τA), the
sequence of button presses for P, and P’s trace τP .
Due to coverage criterion C1, we know that each transition in τP ,
for each (i, si) pair, has been covered by some test. We case-split
on the input supplied on this transition and show that in each case,
the veriﬁed properties P0–P5 ensure that the contest numbers and
selection states in I(τA) are identical to those in τP .
7.4 A Sample Testing Protocol
We present one way to meet the coverage criteria C0–C2 stated
above. We assume that it is possible to provide a cast input from
any screen of the voting machine. This is clearly possible for P,
by deﬁnition.
It is also possible in the voting machine we have
designed.
The testing protocol builds upon the following ideas:
1. Due to properties P2–P4, we can cover transitions of Mnav and
each Mi by separate tests. Note that transitions can be parti-
tioned into two sets depending on the inputs labeling those tran-
sitions (in IS or IN ).
4722. Each trace makes selections in at most one contest. For each
i and for each transition of Mi, there is a trace that makes no
selections in any contest other than i (simply following next
button presses to reach contest i) and at some point follows this
transition in Mi.
3. Similarly, for each transition of Mnav, we explore the shortest
trace that ends in that transition and then a cast.
Operationally, human testers would do the following:
1. Supply the input sequences (prev), (next), (next, prev),
(next, next), (next, next, prev), etc., each followed by a
cast, and then check that the correct output is received. Each
of these tests contains 0 to N + 1 nexts, followed possibly by
a prev, followed by a cast. These tests cover the transitions of
Mnav, and in particular, note that they satisfy coverage criterion
C0. For N contests, there are O(N ) tests of this form.
2. Recall that in contest i, the selection state si is a set si ⊆
{0, 1, . . . , ki − 1}, subject to the constraint |si| ≤ ℓi, where
contest i involves selecting at most ℓi out of ki possible candi-
dates. For each contest i and for each valid selection state si in
this contest, perform the test
(nexti, c1, . . . , cj, 0, 0, 1, 1, 2, 2, . . . , k − 1, k − 1, cast),
where si = {c1, . . . , cj}. Intuitively, we navigate to contest i
using i nexts; we select the candidates speciﬁed by si; we try
de-selecting and subsequently re-selecting each selected candi-
date; we try selecting and subsequently de-selecting each unse-
lected candidate; and ﬁnally we cast the ballot. If the machine
is working properly, de-selecting and immediately re-selecting
a candidate (or vice versa) should leave the selection state un-
changed, and thus return one to the same output screen as be-
fore. In the special case of selecting exactly ℓi candidates, i.e.,
where |si| = ℓi, selecting an unselected candidate should have
no effect, so doing that twice should also have no effect.
Note that these tests satisfy coverage criteria C1 and C2.
If
every contest involves selecting at most one candidate (i.e.,
ℓ1 = · · · = ℓN = 1), there are O(N · k) tests of this form.
Thus, if the voting machine is correct, this protocol certiﬁes its
correctness with O(N · k) tests (assuming ℓ1 = · · · = ℓN = 1).
8. DISCUSSION
Related Work. There has been considerable prior work on using
formal veriﬁcation to build high-assurance systems. In many cases,
the designers manually constructed a model of the system and then
formally veriﬁed that the model satisﬁes desirable properties. In
comparison, we directly verify the source code itself, which pro-
vides higher assurance. Like much prior work on high-assurance
systems, we too have carefully chosen our design to be modular
and to reduce the size of the correctness-critical portion of the code
(the TCB) [15].
We are not the ﬁrst to propose a new architecture for voting ma-
chines, with the goal of greater assurance. The “frog” architec-
ture is based upon separating vote-selection (which is performed
on one device) from vote-conﬁrmation (which is performed on an-
other device), to reduce the trust that is needed in the vote-selection
device [5]. Later, Sastry et al. showed how to provide this func-
tional separation with a single device, and also introduced the idea
of forcibly resetting the system after each voter ﬁnishes, to ensure
independence of voter sessions [26]. We borrow the idea of using
resets for independence. Also, Yee et al. proposed pre-rendering
of the user interface as a technique to reduce the size of the TCB,
and showed that this makes it possible to build a voting machine
with a rich UI in only 300–500 lines of Python code [28–30]. We
adopt the pre-rendering approach to simplify interpretation of user
inputs and generation of screen images. These systems were built
in a general-purpose programming language and thus rely upon the
correctness of an OS, language runtime/interpreter, and language
libraries; in contrast, because our system is implemented directly
in Verilog, we eliminate the need for these elements (although we
trust the tools that synthesize a circuit from Verilog) and thus fur-
ther reduce the size of the TCB. More recently, others have built a
voting machine on a FPGA platform [22]. However, none of these
systems were subjected to formal veriﬁcation.
Our use of determinism to help verify complex, application-speciﬁc
properties was inspired by other work on veriﬁcation of functional
purity [10].
Many authors have explored the use of independent, orthogonal
mechanisms to verify the vote totals. Today, one widely deployed
example is the use of a voter-veriﬁed paper audit trail (VVPAT)
printer attached to a DRE, combined with post-election audits of
the VVPAT records [3, 12, 14, 18, 19, 21]. However, one recent
study showed that about two-thirds of voters failed to notice er-
rors on the summary screen [9], raising questions about the effec-
tiveness of VVPAT records. Many researchers have studied cryp-
tographic mechanisms for end-to-end veriﬁcation that the voter’s
vote has been recorded and counted accurately [1, 6, 8, 20, 24, 25].
These techniques provide a way to detect problems after the fact,
but may not provide any way to recover from some failures and
do not proactively prevent election-day failures. For instance, if
the voting machine displays the set of options inaccurately—e.g.,
inverting the explanation of a bond measure—the voter might be
tricked into voting contrary to her intentions (previously dubbed
a presentation attack [11]). Preventing these kinds of failures re-
quires verifying the user interface logic to a high degree of assur-
ance, as our work does. On the other hand, our approach provides
no way for an ordinary voter to verify, for herself, without trust in
complex technology, that her vote was recorded and counted accu-
rately; that requires some form of independent veriﬁcation. Conse-
quently, we believe that our techniques are complementary to end-
to-end veriﬁcation measures: it would make sense to use both.
Analysis of Limitations. Our general philosophy is to pare a
voting machine down to the simplest possible core, and as a re-
sult our design provides only a bare minimum of functionality. We
do support contests, ballot measures, propositions, and any contest
that can be expressed in terms of selecting at most ℓ out of a list
of k options. We do not support write-ins, straight-party voting,
controlled contests, or cross-endorsement. Some of these are ob-
scure or arguably unnecessary features, but the lack of support for
write-ins is a signiﬁcant limitation.
Also, our system is not as ﬂexible, in terms of the kinds of user
interface designs that can be supported, as a system written in a
general-purpose programming language. We require that contests
be presented one per screen: contests cannot be split across two
pages, and one page cannot contain more than one contest. We
currently do not support alternative languages, audio output, some
kinds of accessible input mechanisms (e.g., sip-and-puff devices),
zoomable display, or high-contrast or reverse-color modes. Many
of these would be needed before our system could be considered
accessible to voters with disabilities. We do not provide a summary
screen that voters can use to conﬁrm their selections before casting
their ballot; this is a signiﬁcant limitation.
We have not yet implemented a module to interface with external
memory; this will be necessary to store votes in non-volatile stor-
age (e.g., on ﬂash). It also has consequences for both the touch
screen and the video output. Our synthesized voting machine in-
473cludes a module to translate analog inputs from the touchscreen to
(x, y) coordinates and a module to drive an LCD display however,
both these modules require access to data in the EDF. As a tempo-
rary measure, we hard-coded in values needed by the touch screen
module and the video output module. In addition, in the case of the
video output module we use a very simpliﬁed display. We expect
the memory interface to be relatively straightforward to implement,
and consequently we view these gaps as primarily a shortcoming of
our implementation, rather than a fundamental limitation of our ar-
chitecture.
We do not provide any kind of administrative functionality, e.g., for
poll workers to conﬁgure the machine. We do not support casting
of provisional ballots.
It is reasonable to suppose our architecture could be extended to
provide veriﬁably correct implementations of some of these fea-
tures, such as alternative languages and summary screens, more
easily than others, such as write-ins or audio. Of course, it would
be straightforward to extend our design with unveriﬁed implemen-
tations of these additional features, but we believe that it would be
preferable to provide the same high level of assurance for all modes
of operation of the voting machine.
9. CONCLUSION
We have designed a simple ﬁnite-state voting machine guided by
the goals of veriﬁcation and testability. A voter’s view of correct
operation was formalized using the concept of a speciﬁcation vot-
ing machine. We used the results of formal veriﬁcation to develop
coverage criteria with which human testers can provably assure, us-
ing a reasonable (polynomial) number of tests, the correct operation
of a voting machine prior to an election. The code and veriﬁcation
results are available online at http://uclid.eecs.berkeley.edu/vvm/.
Although several features remain to be addressed, the presented
framework is an important step towards a fully formally-veriﬁed
voting machine.
Acknowledgments
We thank Brian Lam and Kristian Lyngbaek for their work on the
implementation of the voting machine prototype. We also thank
David Molnar and the anonymous reviewers for helpful comments
on an earlier draft of this paper. This research was supported
by NSF grants CNS-0524745, CNS-0644436, and CNS-0627734,
SRC contract 1355.001, a University of California Chancellor’s
Fellowship, and an Alfred P. Sloan Research Fellowship.
10. REFERENCES
[1] B. Adida. Helios: Web-based open-audit voting. In USENIX
Security Symposium. USENIX Association, 2008.
[2] K. Alexander and P. Smith. Verifying the vote in 2008
presidential election battleground states, Nov. 2008.
http://www.calvoter.org/issues/votingtech/pub/
pres2008_ev.html.
[3] A. Appel. Effective audit policy for voter-veriﬁed paper
ballots. Presented at 2007 Annual Meeting of the American
Political Science Association, Sept. 2007. http://www.cs.
princeton.edu/~appel/papers/appel-audits.pdf.
[4] Beaver SMT solver for bit-vector arithmetic.
http://uclid.eecs.berkeley.edu/beaver/.
[5] S. Bruck, D. Jefferson, and R. L. Rivest. A modular voting
architecture (“Frogs”). In Workshop on Trustworthy
Elections, August 2001. http:
//www.vote.caltech.edu/wote01/pdfs/amva.pdf.
[6] D. Chaum, R. Carback, J. Clark, A. Essex, S. Popoveniuc,
R. L. Rivest, P. Y. Ryan, E. Shen, and A. T. Sherman.
Scantegrity II: End-to-end veriﬁability for optical scan
election systems using invisible ink conﬁrmation codes. In
EVT’08: Proceedings of the 2008 USENIX/Accurate
Electronic Voting Technology Workshop.
[7] E. M. Clarke, O. Grumberg, and D. A. Peled. Model
Checking. MIT Press, 2000.
[8] M. R. Clarkson, S. Chong, and A. C. Myers. Civitas: Toward
a secure voting system. In Proceeding of the 2008 IEEE
Symposium on Security and Privacy.
[9] S. P. Everett. The Usability of Electronic Voting Machines
and How Votes Can Be Changed Without Detection. PhD
thesis, Rice University, 2007.
[10] M. Finifter, A. Mettler, N. Sastry, and D. Wagner. Veriﬁable
functional purity in Java. In ACM CCS 2008.
[11] D. Jefferson. New concerns about electronic voting: What
VVVPAT cannot ﬁx, Apr. 2004. Personal communication.
[12] D. Jefferson, E. Ginnold, K. Midstokke, K. Alexander,
P. Stark, and A. Lehmkuhl. Evaluation of Audit Sampling
Models and Options for Strengthening California’s Manual
Count, July 2007. http://www.sos.ca.gov/elections/
peas/final_peaswg_report.pdf.
[13] S. Jha, R. Limaye, and S. A. Seshia. Beaver: Engineering an
efﬁcient SMT solver for bit-vector arithmetic. In Proc.
Computer-Aided Veriﬁcation (CAV), LNCS 5643. Springer,
2009.
[14] D. W. Jones. Auditing elections. Communications of the
ACM, 47(10):46–50, Oct. 2004. http://www.cs.uiowa.