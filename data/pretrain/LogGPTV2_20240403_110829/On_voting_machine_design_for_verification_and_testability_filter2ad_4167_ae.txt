### Tentative Storage (e.g., Paper) for Human Verification

#### 7.2 Coverage Criteria
We define a test suite \( T \) as satisfying our coverage criteria if the resulting set of traces of \( P \) meets the following conditions:

**C0: Initial State Coverage**
- There exists a test where, from the initial output screen \( z_0 \), \( P \) receives the cast input.

**C1: Transition Coverage**
- **(a) Selection Transitions**: For every contest \( i \), every selection state \( s_i \) within contest \( i \), and every input \( b \in IS \), there is a trace where \( P \) receives \( b \) in a state \( (i, s) \) where the \( i \)-th component of \( s \) is \( s_i \).
- **(b) Navigation Transitions**: For every contest \( i \), and every input \( b \in IN \), there is a trace where \( P \) receives \( b \) in a state of the form \( (i, s) \).

**C2: Output Screen Coverage**
- For every contest \( i \) and every selection state \( s_i \) of \( P \) within contest \( i \), there is a trace where the last transition within contest \( i \) ends at \( s_i \) and then, at some point thereafter, \( P \) receives the cast input.

**Criterion C0** specifies that a human tester must verify that \( A \) and \( P \) start with the same selection state.

**Criterion C1** ensures that all transitions of each \( M_i \) within \( P \) (for every \( i \)) and all transitions of \( M_{nav} \) within \( P \) are covered.

**Criterion C2** ensures that for every \( (i, s_i) \), the tester has the opportunity to view the output screen for that \( s_i \) as the last step in contest \( i \). This, in turn, ensures (through properties P2 and P3) that this selection state of \( A \) for contest \( i \) appears on the cast vote record. The main purpose of this criterion is to check that the interpretation function \( I_O \) is consistent with \( A \)'s output function, denoted as \( \rho_A \), as defined by \( A \)'s Display module. Formally, \( I_O \) must be the inverse of \( \rho_A \). Given Property P0, \( \rho_A \) is invertible, and in contest \( i \), it is only a function of \( (i, s_i) \), not of any \( s_j \) for \( j \neq i \). Thus, C2 ensures that for every \( (i, s_i) \) pair, the human tester computes \( (i', s'_i) = I_O(\rho_A(i, s_i)) \). The test passes only if \( i = i' \) and \( s_i = s'_i \); i.e., only if \( I_O \) is the inverse of \( \rho_A \). We formalize this result in Appendix C.

#### 7.3 Main Theorem
We now state our main theorem, which shows how our test coverage criteria and results of formal verification combine to ensure trace-equivalence of \( A \) and \( P \) (up to an application of \( I \)).

**Recall from Section 3.2** that \( A \) is correct if and only if \( Tr(P) = \{I(\tau) : \tau \in Tr(A)\} \).

**THEOREM 1.** Consider a test suite \( T \) that satisfies coverage criteria C0–C2. Then, \( T \) passes if and only if \( A \) is correct.

The "if" part of the theorem follows trivially. For brevity, we only sketch out the proof of the "only if" part here, and include the full proof in Appendix C.

**PROOF (sketch):** Briefly, the proof works by induction on the length of the input sequence to the voting machine.

Consider an arbitrary input sequence \( T \) to \( A \). Due to determinism, there is a single trace \( \tau_A \) of \( A \) on \( T \). Correspondingly, we can extract the sequence \( I(\tau_A) \), the sequence of button presses for \( P \), and \( P \)'s trace \( \tau_P \).

Due to coverage criterion C1, we know that each transition in \( \tau_P \), for each \( (i, s_i) \) pair, has been covered by some test. We case-split on the input supplied on this transition and show that in each case, the verified properties P0–P5 ensure that the contest numbers and selection states in \( I(\tau_A) \) are identical to those in \( \tau_P \).

#### 7.4 A Sample Testing Protocol
We present one way to meet the coverage criteria C0–C2 stated above. We assume that it is possible to provide a cast input from any screen of the voting machine. This is clearly possible for \( P \) by definition and also in the voting machine we have designed.

The testing protocol builds upon the following ideas:
1. Due to properties P2–P4, we can cover transitions of \( M_{nav} \) and each \( M_i \) by separate tests. Note that transitions can be partitioned into two sets depending on the inputs labeling those transitions (in \( IS \) or \( IN \)).
2. Each trace makes selections in at most one contest. For each \( i \) and for each transition of \( M_i \), there is a trace that makes no selections in any contest other than \( i \) (simply following next button presses to reach contest \( i \)) and at some point follows this transition in \( M_i \).
3. Similarly, for each transition of \( M_{nav} \), we explore the shortest trace that ends in that transition and then a cast.

**Operationally, human testers would do the following:**
1. Supply the input sequences (prev), (next), (next, prev), (next, next), (next, next, prev), etc., each followed by a cast, and then check that the correct output is received. Each of these tests contains 0 to \( N + 1 \) nexts, followed possibly by a prev, followed by a cast. These tests cover the transitions of \( M_{nav} \), and in particular, they satisfy coverage criterion C0. For \( N \) contests, there are \( O(N) \) tests of this form.
2. Recall that in contest \( i \), the selection state \( s_i \) is a set \( s_i \subseteq \{0, 1, \ldots, k_i - 1\} \), subject to the constraint \( |s_i| \leq \ell_i \), where contest \( i \) involves selecting at most \( \ell_i \) out of \( k_i \) possible candidates. For each contest \( i \) and for each valid selection state \( s_i \) in this contest, perform the test:
   \[
   (\text{next}_i, c_1, \ldots, c_j, 0, 0, 1, 1, 2, 2, \ldots, k - 1, k - 1, \text{cast}),
   \]
   where \( s_i = \{c_1, \ldots, c_j\} \). Intuitively, we navigate to contest \( i \) using \( i \) nexts; we select the candidates specified by \( s_i \); we try de-selecting and subsequently re-selecting each selected candidate; we try selecting and subsequently de-selecting each unselected candidate; and finally, we cast the ballot. If the machine is working properly, de-selecting and immediately re-selecting a candidate (or vice versa) should leave the selection state unchanged, and thus return one to the same output screen as before. In the special case of selecting exactly \( \ell_i \) candidates, i.e., where \( |s_i| = \ell_i \), selecting an unselected candidate should have no effect, so doing that twice should also have no effect.

Note that these tests satisfy coverage criteria C1 and C2. If every contest involves selecting at most one candidate (i.e., \( \ell_1 = \cdots = \ell_N = 1 \)), there are \( O(N \cdot k) \) tests of this form. Thus, if the voting machine is correct, this protocol certifies its correctness with \( O(N \cdot k) \) tests (assuming \( \ell_1 = \cdots = \ell_N = 1 \)).

### 8. Discussion
**Related Work.** There has been considerable prior work on using formal verification to build high-assurance systems. In many cases, designers manually constructed a model of the system and then formally verified that the model satisfies desirable properties. In comparison, we directly verify the source code itself, which provides higher assurance. Like much prior work on high-assurance systems, we too have carefully chosen our design to be modular and to reduce the size of the correctness-critical portion of the code (the TCB) [15].

We are not the first to propose a new architecture for voting machines, with the goal of greater assurance. The "frog" architecture is based on separating vote-selection (which is performed on one device) from vote-confirmation (which is performed on another device), to reduce the trust needed in the vote-selection device [5]. Later, Sastry et al. showed how to provide this functional separation with a single device and introduced the idea of forcibly resetting the system after each voter finishes, to ensure independence of voter sessions [26]. We borrow the idea of using resets for independence. Also, Yee et al. proposed pre-rendering of the user interface as a technique to reduce the size of the TCB and showed that this makes it possible to build a voting machine with a rich UI in only 300–500 lines of Python code [28–30]. We adopt the pre-rendering approach to simplify interpretation of user inputs and generation of screen images. These systems were built in a general-purpose programming language and thus rely on the correctness of an OS, language runtime/interpreter, and language libraries. In contrast, because our system is implemented directly in Verilog, we eliminate the need for these elements (although we trust the tools that synthesize a circuit from Verilog) and thus further reduce the size of the TCB. More recently, others have built a voting machine on an FPGA platform [22]. However, none of these systems were subjected to formal verification.

Our use of determinism to help verify complex, application-specific properties was inspired by other work on verification of functional purity [10].

Many authors have explored the use of independent, orthogonal mechanisms to verify the vote totals. Today, one widely deployed example is the use of a voter-verified paper audit trail (VVPAT) printer attached to a DRE, combined with post-election audits of the VVPAT records [3, 12, 14, 18, 19, 21]. However, one recent study showed that about two-thirds of voters failed to notice errors on the summary screen [9], raising questions about the effectiveness of VVPAT records. Many researchers have studied cryptographic mechanisms for end-to-end verification that the voter's vote has been recorded and counted accurately [1, 6, 8, 20, 24, 25]. These techniques provide a way to detect problems after the fact but may not provide any way to recover from some failures and do not proactively prevent election-day failures. For instance, if the voting machine displays the set of options inaccurately—e.g., inverting the explanation of a bond measure—the voter might be tricked into voting contrary to her intentions (previously dubbed a presentation attack [11]). Preventing these kinds of failures requires verifying the user interface logic to a high degree of assurance, as our work does. On the other hand, our approach provides no way for an ordinary voter to verify, for herself, without trust in complex technology, that her vote was recorded and counted accurately; that requires some form of independent verification. Consequently, we believe that our techniques are complementary to end-to-end verification measures: it would make sense to use both.

**Analysis of Limitations.** Our general philosophy is to pare a voting machine down to the simplest possible core, and as a result, our design provides only a bare minimum of functionality. We support contests, ballot measures, propositions, and any contest that can be expressed in terms of selecting at most \( \ell \) out of a list of \( k \) options. We do not support write-ins, straight-party voting, controlled contests, or cross-endorsement. Some of these are obscure or arguably unnecessary features, but the lack of support for write-ins is a significant limitation.

Also, our system is not as flexible, in terms of the kinds of user interface designs that can be supported, as a system written in a general-purpose programming language. We require that contests be presented one per screen: contests cannot be split across two pages, and one page cannot contain more than one contest. We currently do not support alternative languages, audio output, some kinds of accessible input mechanisms (e.g., sip-and-puff devices), zoomable display, or high-contrast or reverse-color modes. Many of these would be needed before our system could be considered accessible to voters with disabilities. We do not provide a summary screen that voters can use to confirm their selections before casting their ballot; this is a significant limitation.

We have not yet implemented a module to interface with external memory; this will be necessary to store votes in non-volatile storage (e.g., on flash). It also has consequences for both the touch screen and the video output. Our synthesized voting machine includes a module to translate analog inputs from the touchscreen to (x, y) coordinates and a module to drive an LCD display. However, both these modules require access to data in the EDF. As a temporary measure, we hard-coded in values needed by the touch screen module and the video output module. In addition, in the case of the video output module, we use a very simplified display. We expect the memory interface to be relatively straightforward to implement, and consequently, we view these gaps as primarily a shortcoming of our implementation, rather than a fundamental limitation of our architecture.

We do not provide any kind of administrative functionality, e.g., for poll workers to configure the machine. We do not support casting of provisional ballots.

It is reasonable to suppose our architecture could be extended to provide verifiably correct implementations of some of these features, such as alternative languages and summary screens, more easily than others, such as write-ins or audio. Of course, it would be straightforward to extend our design with unverified implementations of these additional features, but we believe that it would be preferable to provide the same high level of assurance for all modes of operation of the voting machine.

### 9. Conclusion
We have designed a simple finite-state voting machine guided by the goals of verification and testability. A voter's view of correct operation was formalized using the concept of a specification voting machine. We used the results of formal verification to develop coverage criteria with which human testers can provably assure, using a reasonable (polynomial) number of tests, the correct operation of a voting machine prior to an election. The code and verification results are available online at http://uclid.eecs.berkeley.edu/vvm/.

Although several features remain to be addressed, the presented framework is an important step towards a fully formally-verified voting machine.

### Acknowledgments
We thank Brian Lam and Kristian Lyngbaek for their work on the implementation of the voting machine prototype. We also thank David Molnar and the anonymous reviewers for helpful comments on an earlier draft of this paper. This research was supported by NSF grants CNS-0524745, CNS-0644436, and CNS-0627734, SRC contract 1355.001, a University of California Chancellor’s Fellowship, and an Alfred P. Sloan Research Fellowship.

### 10. References
[1] B. Adida. Helios: Web-based open-audit voting. In USENIX Security Symposium. USENIX Association, 2008.
[2] K. Alexander and P. Smith. Verifying the vote in 2008 presidential election battleground states, Nov. 2008. http://www.calvoter.org/issues/votingtech/pub/pres2008_ev.html.
[3] A. Appel. Effective audit policy for voter-verified paper ballots. Presented at 2007 Annual Meeting of the American Political Science Association, Sept. 2007. http://www.cs.princeton.edu/~appel/papers/appel-audits.pdf.
[4] Beaver SMT solver for bit-vector arithmetic. http://uclid.eecs.berkeley.edu/beaver/.
[5] S. Bruck, D. Jefferson, and R. L. Rivest. A modular voting architecture ("Frogs"). In Workshop on Trustworthy Elections, August 2001. http://www.vote.caltech.edu/wote01/pdfs/amva.pdf.
[6] D. Chaum, R. Carback, J. Clark, A. Essex, S. Popoveniuc, R. L. Rivest, P. Y. Ryan, E. Shen, and A. T. Sherman. Scantegrity II: End-to-end verifiability for optical scan election systems using invisible ink confirmation codes. In EVT'08: Proceedings of the 2008 USENIX/Accurate Electronic Voting Technology Workshop.
[7] E. M. Clarke, O. Grumberg, and D. A. Peled. Model Checking. MIT Press, 2000.
[8] M. R. Clarkson, S. Chong, and A. C. Myers. Civitas: Toward a secure voting system. In Proceeding of the 2008 IEEE Symposium on Security and Privacy.
[9] S. P. Everett. The Usability of Electronic Voting Machines and How Votes Can Be Changed Without Detection. PhD thesis, Rice University, 2007.
[10] M. Finifter, A. Mettler, N. Sastry, and D. Wagner. Verifiable functional purity in Java. In ACM CCS 2008.
[11] D. Jefferson. New concerns about electronic voting: What VVVPAT cannot fix, Apr. 2004. Personal communication.
[12] D. Jefferson, E. Ginnold, K. Midstokke, K. Alexander, P. Stark, and A. Lehmkuhl. Evaluation of Audit Sampling Models and Options for Strengthening California’s Manual Count, July 2007. http://www.sos.ca.gov/elections/peas/final_peaswg_report.pdf.
[13] S. Jha, R. Limaye, and S. A. Seshia. Beaver: Engineering an efficient SMT solver for bit-vector arithmetic. In Proc. Computer-Aided Verification (CAV), LNCS 5643. Springer, 2009.
[14] D. W. Jones. Auditing elections. Communications of the ACM, 47(10):46–50, Oct. 2004. http://www.cs.uiowa.edu/~jones/voting/published/audit.pdf.