German hosting provider.
It is sufﬁcient to use a commodity PC, issuing queries at the rate
of 40 to 50 queries per second. This rate that can be achieved at a
residential vantage point with no complications [11].
Scaling up the query rate is easy by using multiple vantage points
in parallel, e.g., by utilizing PlanetLab nodes, but our experiments
show that a simple setup serves the purpose of this study.
With regards to the queries, we use hostnames from the Alexa list
and the ISP traces and the source preﬁxes from our preﬁx datasets.
Note, that because a large fraction of IPv6 connectivity is still han-
dled by 6to4 tunnels [16] and related techniques, we do not include
IPv6 in this preliminary study.
For each query we issue we add an entry to our SQL database
which includes all parameters including the timestamp, the returned
records (answers) including TTL and returned scope. Before and
after each experiment, we collect the most recent preﬁxes for each
dataset. To speed-up the experiments, we compile a set of unique
preﬁxes before starting an experiment.
5. EVALUATION
To evaluate the capabilities of ECS as a measurement tool, we
explore how difﬁcult it is to (i) uncover the footprint of ECS adop-
ters, (ii) assess the effect of ECS on cacheability of DNS records,
and (iii) capture snapshots of how ECS adopters assign users to
server locations. All queries are sent for a single hostname (e.g.,
www.google.com) to one of the authoritative name servers of
the service provider (e.g., ns1.google.com).
While for the RIPE, RV, ISP and ISP24 dataset we use the pre-
ﬁxes as announced, for the UNI dataset an ECS preﬁx length of 32
is chosen, as this dataset contains individual IP addresses.
5.1 Uncovering Infrastructure Footprints
We ﬁrst report on our experiences with using ECS to uncover the
footprint of the four selected ECS adopters. Apparently the oper-
ational community also did some investigation [5] in enumerating
CDN servers using ECS.
Table 1 summarizes the number of unique server IPs, subnets,
ASes, and locations. The footprint of Google is by far the most
interesting one, with more than 6,300 server IPs across 166 ASes
in 47 countries4. We also notice that GGCs are typically located in
ASes that are “categorized” as enterprise customers and small tran-
sit providers [18] in both developed and developing countries. In
March 2013, Google servers are found in 81 enterprise customers,
62 small transit providers, 14 content/access/hosting providers, and
only 4 large transit providers (a small number of ASes that host
Google server IPs do not belong to any of these categories). While
4For geolocation we use MaxMind [6]. We are aware that geolo-
cation of CDN servers can be inaccurate, e.g., MaxMind maps the
IPs of the main Google AS (AS15169) to California, but it is ac-
curate on the country level for IPs that belong to ISPs [31] and
thus, good enough for the purpose of this study. A more sophisti-
cated approach of geolocating Google server IPs in the Google AS
is presented in [14].
Preﬁx set
Server
IPs
Sub
nets
ASes
Countries
Google
(03/26/13)
RIPE
RV
PRES
ISP
ISP24
UNI
MySqueezebox
(03/26/13)
Edgecast
(04/21/13)
ALL \ UNI
UNI
RIPE/RV/PRES
ISP/ISP24/UNI
CacheFly
(04/21/13)
RIPE/RV
PRES
ISP
ISP24
UNI
6,340
6,308
6,088
207
535
123
10
6
4
1
18
21
6
5
1
329
328
313
28
44
13
7
4
4
1
18
21
6
5
1
166
166
159
1
2
1
2
1
1
1
10
11
5
4
1
47
47
46
1
2
1
2
1
2
1
10
11
5
4
1
Table 1: ECS adopters: Uncovered footprint.
illustrative and also informative (e.g., we uncover more locations
than previously reported [12, 33]), the main and more surprising
ﬁnding is the simplicity with which we can uncover this infrastruc-
ture using ECS from a single vantage point in less than 4 hours.
For validation purposes, we check each server IP—all of them
serve us the Google search main page. In addition, the reverse look-
up reveals that while all servers inside the ofﬁcial Google AS use
the sufﬁx 1e100.net [21], those deployed in third-party ASes use
different hostnames (e.g., cache.google.com, or names containing
the strings ggc or googlevideo.com).
In some cases we observe
legacy names that indicate the prior use of the IP range by the ISP.
This means we cannot infer the presence of a GGC purely by look-
ing at the reverse DNS zones.
5.1.1 Choosing the Right Preﬁx Set
Both the RIPE as well as the RV preﬁx sets are sufﬁciently com-
plete to yield the same results. We attribute this to the fact that the
advertised address space of both datasets overlaps signiﬁcantly. We
see around 500K announced preﬁxes in the data sets at various ag-
gregation levels. Using only the most speciﬁcs without overlap this
reduces to about 130K preﬁxes. For our experiments we decided
to use the preﬁxes as announced. We think this corresponds to the
distribution to be seen at an ECS enabled nameserver5 and reﬂects
the public IP-address space being used.
Next we compare our results (RIPE only) to a study of Calder
et al.[14], where queries were made using /24 preﬁxes. We see a
94% overlap in the discovered Google server IP-addresses while
issuing signiﬁcantly less DNS queries in our approach.
PRES however is not sufﬁcient to uncover the full set of Google
Web servers, but yields a major fraction of them in only 55 minutes
per experiment. Alternatively, one can use a subset of the RIPE/RV
preﬁx sets. Using a random preﬁx from each AS reduces the num-
ber of RIPE/RV preﬁxes to 43,400 (8.8% of RIPE preﬁxes) and
results in 4,120 server IPs in 130 ASes and 40 countries in 18 min-
utes (with 40 requests/second). By doubling the number of selected
preﬁxes to two per AS, we uncover 4,580 server IPs in 143 ASes,
and 44 countries.
When relying on the ISP, ISP24, and UNI data sets, we see the
effect of mapping end-users to server IPs using ECS. In the case of
Google we uncover a much smaller number of servers. However,
by using the de-aggregated preﬁx set of the ISP (i.e., ISP24), we
are able to expand the coverage from 200 to more than 500 server
IPs. More than 95% of them are in the Google AS while the rest
is located in a neighbor AS to that ISP. A more careful investi-
5A study on this is currently being performed.
Date
(RIPE)
2013-03-26
2013-03-30
2013-04-13
2013-04-21
2013-05-16
2013-05-26
2013-06-18
2013-07-13
2013-08-08
IPs
6340
6495
6821
7162
9762
9465
14418
21321
21862
Sub
nets
329
332
331
346
485
471
703
1040
1083
ASes
Countries
166
167
167
169
287
281
454
714
761
47
47
46
46
55
52
91
91
123
Table 2: Google growth within ﬁve months.
gation reveals that the client preﬁxes served from the neighbor AS
are from a customer of this ISP whose preﬁx is not announced sepa-
rately but only in aggregated form (i.e., together with other preﬁxes
of the ISP). Our conjecture is that this is due to the BGP feed sent
to the GGC by the ISP [13].
Of the ASes uncovered by using the RIPE preﬁx set, only 845
and 96 server IPs are in the ASes of Google and YouTube, respec-
tively. All the others IPs are in ASes not associated with Google.
This shows the profound effect of GGCs which have been deployed
to many ASes. We repeat the experiments by using the Google
Public DNS server and observe that the returned answers are al-
most always identical (99%). This is not necessarily the case when
using Google’s Public DNS server for other lookups. However,
we ﬁnd Google’s Public DNS server forwarding our ECS queries
unmodiﬁed to white-listed authoritative DNS servers of other ECS
adopters. Therefore, we can even (ab)use Google’s Public DNS
server as intermediary for measurement queries and thus (i) hide
from discovery or (ii) explore if these ECS adopters use a different
clustering for Google customers.
Table 1 also shows that the footprints of the other ECS adopters
are “less” interesting, mainly because their footprint is not as widely
distributed compared to Google. Nevertheless, we see in principle
similar results. Most of the infrastructure can be uncovered with
the RIPE/RV/PRES preﬁx sets. The ECS adopters again use clus-
tering such that the ISP, ISP24, and UNI preﬁxes are all mapped to
a single server IP. Note that Edgecast may use HTTP-based redi-
rection which cannot be uncovered using only DNS. While Edge-
cast uses a single AS, CacheFly, and MySqueezebox are utilizing
infrastructures across multiple ASes. We also observe that both
players map the UNI and ISP/ISP24 preﬁxes to infrastructures in
Europe (e.g., MySqueezebox maps them to the European facility
of Amazon EC2).
5.1.2 Tracking the Expansion of CDNs Footprints
Our method allows us to track the expansion of ECS adopters’
footprints over time. This becomes increasingly important as many
CDNs continuously deploy servers at the network edges or within
ISPs. Thus, one can not infer the operator of a cache by simply
looking at the IP address or AS number [15]. As we show above,
RIPE and RV public preﬁx sets uncover by far more IPs than the
other preﬁx sets. We use the RIPE preﬁx set to track the expan-
sion of ECS adopters as it is updated more frequently than RV. In
Table 2 we report the rapid increase of discovered Google server
IPs over a four month period (March-August 2013). We observe
that the number of Google server IPs at least triples (345%), the
number of ASes hosting Google infrastructure increases by 595
(458%) and the global presence at least doubles (261%). In Au-
gust 2013, Google servers are found in 372 enterprise networks,
224 small transit providers, 102 content/access/hosting providers,
and 11 large transit providers. Starting mid May we include the
YouTube website in our measurements and notice that while the