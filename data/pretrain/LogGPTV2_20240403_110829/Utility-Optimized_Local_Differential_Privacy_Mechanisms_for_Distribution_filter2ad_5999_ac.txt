Q1 ◦ Q0 provides (XS,ZP,ε)-ULDP.
Note that Q1 needs to preserve data types for utility; i.e.,
to make all y ∈ YI invertible (as in Deﬁnition 2) after post-
processing. The DP guarantee for y ∈ YP is preserved by any
post-processing algorithm. See Appendix A.1 for details.
Compatibility with LDP. Assume that data collectors A
and B adopt a mechanism providing ULDP and a mechanism
providing LDP, respectively. In this case, all protected data
in the data collector A can be combined with all obfuscated
data in the data collector B (i.e., data integration) to perform
data analysis under LDP. See Appendix A.2 for details.
Lower bounds on the l1 and l2 losses. We present lower
bounds on the l1 and l2 losses of any ULDP mechanism by
using the fact that ULDP provides (5) for any x,x(cid:48) ∈ XS and
any y ∈ YP. Speciﬁcally, Duchi et al. [20] showed that for
ε ∈ [0,1], the lower bounds on the l1 and l2 losses (minimax
|X|√
rates) of any ε-LDP mechanism can be expressed as Θ(
nε2 )
USENIX Association
28th USENIX Security Symposium    1881
Figure 2: Utility-optimized RR in the case where XS = YP =
{x1,x2,x3} and XN = YI = {x4,x5,x6}.
Figure 3: Utility-optimized RAPPOR in the case where XS =
{x1,··· ,x4} and XN = {x5,··· ,x10}.
|X|
and Θ(
nε2 ), respectively. By directly applying these bounds
to XS and YP, the lower bounds on the l1 and l2 losses of
any (XS,YP,ε)-ULDP mechanisms for ε ∈ [0,1] can be ex-
|XS|
pressed as Θ(
nε2 ), respectively. In Section 4.3,
we show that our utility-optimized RAPPOR achieves these
lower bounds when ε is close to 0 (i.e., high privacy regime).
|XS|√
nε2 ) and Θ(
4 Utility-Optimized Mechanisms
In this section, we focus on the common-mechanism scenario
and propose the utility-optimized RR (Randomized Response)
and utility-optimized RAPPOR (Sections 4.1 and 4.2). We then
analyze the data utility of these mechanisms (Section 4.3).
4.1 Utility-Optimized Randomized Response
We propose the utility-optimized RR, which is a generaliza-
tion of Mangat’s randomized response [37] to |X|-ary alpha-
bets with |XS| sensitive symbols. As with the RR, the output
range of the utility-optimized RR is identical to the input do-
main; i.e., X = Y . In addition, we divide the output set in the
same way as the input set; i.e., XS = YP, XN = YI.
Figure 2 shows the utility-optimized RR with XS = YP =
{x1,x2,x3} and XN = YI = {x4,x5,x6}. The utility-optimized
RR applies the ε-RR to XS. It maps x ∈ XN to y ∈ YP (= XS)
with the probability Q(y|x) so that (5) is satisﬁed, and maps
x ∈ XN to itself with the remaining probability. Formally, we
deﬁne the utility-optimized RR (uRR) as follows:
Deﬁnition 3 ((XS,ε)-utility-optimized RR). Let XS ⊆ X
and ε ∈ R≥0. Let c1 =
|XS|+eε−1 , and c3 =
1−|XS|c2 = eε−1
|XS|+eε−1 . Then the (XS,ε)-utility-optimized RR
(uRR) is an obfuscation mechanism that maps x ∈ X to y ∈ Y
(= X ) with the probability QuRR(y|x) deﬁned as follows:
|XS|+eε−1 , c2 =
eε
1
c1
c2
c2
c3
0
QuRR(y|x) =
(if x ∈ XS, y = x)
(if x ∈ XS, y ∈ XS \{x})
(if x ∈ XN, y ∈ XS)
(if x ∈ XN, y = x)
(otherwise).
(6)
Proposition 2. The (XS,ε)-uRR provides (XS,XS, ε)-ULDP.
4.2 Utility-Optimized RAPPOR
Next, we propose the utility-optimized RAPPOR with the
input alphabet X = {x1,x2,··· ,x|X|} and the output alpha-
bet Y = {0,1}|X|. Without loss of generality, we assume
that x1,··· ,x|XS| are sensitive and x|XS|+1,··· ,x|X| are non-
sensitive; i.e., XS = {x1,··· ,x|XS|}, XN = {x|XS|+1,··· ,x|X|}.
Figure 3 shows the utility-optimized RAPPOR with XS =
{x1,··· ,x4} and XN = {x5,··· ,x10}. The utility-optimized
RAPPOR ﬁrst deterministically maps xi ∈ X to the i-th stan-
dard basis vector ei. It should be noted that if xi is sensitive
data (i.e., xi ∈ XS), then the last |XN| elements in ei are al-
ways zero (as shown in the upper-left panel of Figure 3).
Based on this fact, the utility-optimized RAPPOR regards
obfuscated data y = (y1,y2, . . . ,y|X|) ∈ {0,1}|X| such that
y|XS|+1 = ··· = y|X| = 0 as protected data; i.e.,
YP = {(y1, . . . ,y|XS|,0,··· ,0)|y1, . . . ,y|XS| ∈ {0,1}}.
(7)
Then it applies the (θ,ε)-generalized RAPPOR to XS, and
maps x ∈ XN to y ∈ YP (as shown in the lower-left panel of
Figure 3) with the probability Q(y|x) so that (5) is satisﬁed.
We formally deﬁne the utility-optimized RAPPOR (uRAP):
Deﬁnition 4 ((XS,θ,ε)-utility-optimized RAPPOR). Let
XS ⊆ X , θ ∈ [0,1], and ε ∈ R≥0. Let d1 =
(1−θ)eε+θ , d2 =
(1−θ)eε+θ
. Then the (XS,θ,ε)-utility-optimized RAPPOR
(uRAP) is an obfuscation mechanism that maps xi ∈ X to
y ∈ Y = {0,1}|X| with the probability QuRAP(y|x) given by:
(8)
QuRAP(y|xi) = ∏1≤ j≤|X| Pr(y j|xi),
eε
θ
where Pr(y j|xi) is written as follows:
(i) if 1 ≤ j ≤ |XS|:
1− θ
θ
1− d1
d1
(if i = j, y j = 0)
(if i = j, y j = 1)
(if i (cid:54)= j, y j = 0)
(if i (cid:54)= j, y j = 1).
(if i = j, y j = 0)
(if i = j, y j = 1)
(if i (cid:54)= j, y j = 0)
(if i (cid:54)= j, y j = 1).
(9)
(10)
Pr(y j|xi) =
(ii) if |XS| + 1 ≤ j ≤ |X|:
d2
1− d2
1
0
Pr(y j|xi) =
1882    28th USENIX Security Symposium
USENIX Association
x1x1x2x2x3x3x4x4x5x5x6x6ࣲࣲࣳௌࣲேࣳ௉ࣳூܿଵൌ݁ఌ|ࣲௌ|൅݁ఌെ1ܿଶൌ1|ࣲௌ|൅݁ఌെ1ܿଷൌ݁ఌെ1|ࣲௌ|൅݁ఌെ1ݔଷ݁ଷൌሺ0,0,1,0,0,0,0,0,0,0ሻݕൌሺ1,0,1,1,0,0,0,0,0,0ሻݔ଺݁଺ൌሺ0,0,0,0,0,1,0,0,0,0ሻݕൌሺ0,1,0,1,0,0,0,0,0,0ሻߠ݀ଵൌߠ1െߠ݁ఌ൅ߠ݀ଶൌ1െߠ݁ఌ൅ߠ݁ఌProposition 3. The (XS,θ,ε)-uRAP provides (XS,YP,ε)-
ULDP, where YP is given by (7).
Although we used the generalized RAPPOR in XS and YP
in Deﬁnition 4, hereinafter we set θ = eε/2
eε/2+1 in the same
way as the original RAPPOR [23]. There are two reasons for
this. First, it achieves “order” optimal data utility among all
(XS,YP,ε)-ULDP mechanisms in the high privacy regime, as
shown in Section 4.3. Second, it maps xi ∈ XN to y ∈ YI with
probability 1− d2 = 1− e−ε/2, which is close to 1 when ε is
large (i.e., low privacy regime). Wang et al. [51] showed that
the generalized RAPPOR with parameter θ = 1
2 minimizes the
variance of the estimate. However, our uRAP with parameter
2 maps xi ∈ XN to y ∈ YI with probability 1− d2 = eε−1
θ = 1
2eε
which is less than 1− e−ε/2 for any ε > 0 and is less than 1
2
even when ε goes to inﬁnity. Thus, our uRAP with θ = eε/2
eε/2+1
maps xi ∈ XN to y ∈ YI with higher probability, and therefore
achieves a smaller estimation error over all non-sensitive data.
We also consider that an optimal θ for our uRAP is different
from the optimal θ (= 1
2) for the generalized RAPPOR. We
leave ﬁnding the optimal θ for our uRAP (with respect to the
estimation error over all personal data) as future work.
We refer to the (XS,θ,ε)-uRAP with θ = eε/2
eε/2+1 in short-
hand as the (XS,ε)-uRAP.
4.3 Utility Analysis
We evaluate the l1 loss of the uRR and uRAP when the em-
pirical estimation method is used for distribution estimation2.
In particular, we evaluate the l1 loss when ε is close to 0 (i.e.,
high privacy regime) and ε = ln|X| (i.e., low privacy regime).
Note that ULDP provides a natural interpretation of the latter
value of ε. Speciﬁcally, it follows from (5) that if ε = ln|X|,
then for any x ∈ X , the likelihood that the input data is x is
almost equal to the sum of the likelihood that the input data
is x(cid:48) (cid:54)= x. This is consistent with the fact that the ε-RR with
parameter ε = ln|X| sends true data (i.e., y = x in (2)) with
probability about 0.5 and false data (i.e., y (cid:54)= x) with probabil-
ity about 0.5, and hence provides plausible deniability [29].
uRR in the general case. We begin with the uRR:
Proposition 4 (l1 loss of the uRR). Let ε ∈ R≥0, u = |XS| +
eε − 1, u(cid:48) = eε − 1, and v = u
u(cid:48) . Then the expected l1 loss of
2We note that we use the empirical estimation method in the same way
as [29], and that it might be possible that other mechanisms have better utility
with a different estimation method. However, we emphasize that even with
the empirical estimation method, the uRAP achieves the lower bounds on
the l1 and l2 losses of any ULDP mechanisms when ε ≈ 0, and the uRR and
uRAP achieve almost the same utility as a non-private mechanism when
ε = ln|X| and most of the data are non-sensitive.
the (XS,ε)-uRR mechanism is given by:
E [l1(ˆp,p)] ≈(cid:113) 2
nπ
(cid:18)
(cid:113)(cid:0)p(x) + 1/u(cid:48)(cid:1)(cid:0)v− p(x)− 1/u(cid:48)(cid:1)
p(x)(cid:0)v− p(x)(cid:1)(cid:19)
(cid:113)
∑
x∈XS
+ ∑
x∈XN
,
(11)
where f (n) ≈ g(n) represents limn→∞ f (n)/g(n) = 1.
Let pUN be the uniform distribution over XN; i.e., for any
x ∈ XS, pUN (x) = 0, and for any x ∈ XN, pUN (x) = 1|XN|. Sym-
metrically, let pUS be the uniform distribution over XS.
For 0 < ε < ln(|XN| + 1), the l1 loss is maximized by pUN :
Proposition 5. For any 0 < ε < ln(|XN| +1) and |XS| ≤ |XN|,
(11) is maximized by pUN :
E [l1(ˆp,p)] (cid:46) E [l1(ˆp,pUN )]
(cid:18)|XS|√|XS|+eε−2
(cid:113) 2
(cid:113)|XS||XN|
(cid:19)
eε−1 +|XN|− 1
nπ
=
,
where f (n) (cid:46) g(n) represents limn→∞ f (n)/g(n) ≤ 1.
eε−1
+
(12)
For ε ≥ ln(|XN| + 1), the l1 loss is maximized by a mixture
distribution of pUN and pUS:
Proposition 6. Let p∗ be a distribution over X deﬁned by:
p∗(x) =
|XS|+|XN|
 1−|XN|/(eε−1)
(cid:113) 2(|X|−1)
1+|XS|/(eε−1)
|XS|+|XN|
(if x ∈ XS)
(otherwise)
(13)
(14)
Then for any ε ≥ ln(|XN| + 1), (11) is maximized by p∗:
E [l1(ˆp,p)] (cid:46) E [l1(ˆp,p∗)] =
· |XS|+eε−1
,
eε−1
where f (n) (cid:46) g(n) represents limn→∞ f (n)/g(n) ≤ 1.
nπ
Next, we instantiate the l1 loss in the high and low privacy
regimes based on these propositions.
uRR in the high privacy regime. When ε is close to 0, we
have eε − 1 ≈ ε. Thus, the right-hand side of (12) in Proposi-