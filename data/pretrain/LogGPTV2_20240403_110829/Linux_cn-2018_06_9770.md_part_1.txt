---
author: Jean-tiare Le Bigot
category: 技术
comments_data: []
count:
  commentnum: 0
  favtimes: 0
  likes: 0
  sharetimes: 0
  viewnum: 6110
date: '2018-06-22 14:43:21'
editorchoice: false
excerpt: 在最新的 Linux 内核（&gt;=4.4）中使用 eBPF，你可以将任何内核函数调用转换为一个带有任意数据的用户空间事件。这通过 bcc 来做很容易。这个探针是用
  C 语言写的，而数据是由 Python 来处理的。
fromurl: https://blog.yadutaf.fr/2016/03/30/turn-any-syscall-into-event-introducing-ebpf-kernel-probes/
id: 9770
islctt: true
largepic: /data/attachment/album/201806/22/144303vbnrgmmynvhcwczl.jpg
permalink: /article-9770-1.html
pic: /data/attachment/album/201806/22/144303vbnrgmmynvhcwczl.jpg.thumb.jpg
related: []
reviewer: ''
selector: ''
summary: 在最新的 Linux 内核（&gt;=4.4）中使用 eBPF，你可以将任何内核函数调用转换为一个带有任意数据的用户空间事件。这通过 bcc 来做很容易。这个探针是用
  C 语言写的，而数据是由 Python 来处理的。
tags:
- eBPF
- 内核
thumb: false
title: 怎么去转换任何系统调用为一个事件：对 eBPF 内核探针的介绍
titlepic: true
translator: qhwdw
updated: '2018-06-22 14:43:21'
---
![](/data/attachment/album/201806/22/144303vbnrgmmynvhcwczl.jpg)
长文预警：在最新的 Linux 内核（>=4.4）中使用 eBPF，你可以将任何内核函数调用转换为一个带有任意数据的用户空间事件。这通过 bcc 来做很容易。这个探针是用 C 语言写的，而数据是由 Python 来处理的。
如果你对 eBPF 或者 Linux 跟踪不熟悉，那你应该好好阅读一下整篇文章。本文尝试逐步去解决我在使用 bcc/eBPF 时遇到的困难，以为您节省我在搜索和挖掘上花费的时间。
### 在 Linux 的世界中关于推送与轮询的一个看法
当我开始在容器上工作的时候，我想知道我们怎么基于一个真实的系统状态去动态更新一个负载均衡器的配置。一个通用的策略是这样做的，无论什么时候只要一个容器启动，容器编排器触发一个负载均衡配置更新动作，负载均衡器去轮询每个容器，直到它的健康状态检查结束。它也许只是简单进行 “SYN” 测试。
虽然这种配置方式可以有效工作，但是它的缺点是你的负载均衡器为了让一些系统变得可用需要等待，而不是 … 让负载去均衡。
可以做的更好吗？
当你希望在一个系统中让一个程序对一些变化做出反应，这里有两种可能的策略。程序可以去 *轮询* 系统去检测变化，或者，如果系统支持，系统可以 *推送* 事件并且让程序对它作出反应。你希望去使用推送还是轮询取决于上下文环境。一个好的经验法则是，基于处理时间的考虑，如果事件发生的频率较低时使用推送，而当事件发生的较快或者让系统变得不可用时切换为轮询。例如，一般情况下，网络驱动程序将等待来自网卡的事件，但是，像 dpdk 这样的框架对事件将主动轮询网卡，以达到高吞吐低延迟的目的。
理想状态下，我们将有一些内核接口告诉我们：
> 
> * “容器管理器，你好，我刚才为容器 *servestaticfiles* 的 Nginx-ware 创建了一个套接字，或许你应该去更新你的状态？
> * “好的，操作系统，感谢你告诉我这个事件”
> 
> 
> 
虽然 Linux 有大量的接口去处理事件，对于文件事件高达 3 个，但是没有专门的接口去得到套接字事件提示。你可以得到路由表事件、邻接表事件、连接跟踪事件、接口变化事件。唯独没有套接字事件。或者，也许它深深地隐藏在一个 Netlink 接口中。
理想情况下，我们需要一个做这件事的通用方法，怎么办呢？
### 内核跟踪和 eBPF，一些它们的历史
直到最近，内核跟踪的唯一方式是对内核上打补丁或者借助于 SystemTap。[SytemTap](https://en.wikipedia.org/wiki/SystemTap) 是一个 Linux 系统跟踪器。简单地说，它提供了一个 DSL，编译进内核模块，然后被内核加载运行。除了一些因安全原因禁用动态模块加载的生产系统之外，包括在那个时候我开发的那一个。另外的方式是为内核打一个补丁程序以触发一些事件，可能是基于 netlink。但是这很不方便。深入内核所带来的缺点包括 “有趣的” 新 “特性” ，并增加了维护负担。
从 Linux 3.15 开始给我们带来了希望，它支持将任何可跟踪内核函数可安全转换为用户空间事件。在一般的计算机科学中，“安全” 是指 “某些虚拟机”。在此也不例外。自从 Linux 2.1.75 在 1997 年正式发行以来，Linux 已经有这个多好年了。但是，它被称为伯克利包过滤器，或简称 BPF。正如它的名字所表达的那样，它最初是为 BSD 防火墙开发的。它仅有两个寄存器，并且它仅允许向前跳转，这意味着你不能使用它写一个循环（好吧，如果你知道最大迭代次数并且去手工实现它，你也可以实现循环）。这一点保证了程序总会终止，而不会使系统处于挂起的状态。还不知道它有什么用？你用过 iptables 的话，其作用就是 [CloudFlare 的 DDos 防护的基础](https://blog.cloudflare.com/bpf-the-forgotten-bytecode/)。
好的，因此，随着 Linux 3.15，[BPF 被扩展](https://blog.yadutaf.fr/2016/03/30/turn-any-syscall-into-event-introducing-ebpf-kernel-probes/TODO) 成为了 eBPF。对于 “扩展的” BPF。它从两个 32 位寄存器升级到 10 个 64 位寄存器，并且增加了它们之间向后跳转的特性。然后它 [在 Linux 3.18 中被进一步扩展](https://lwn.net/Articles/604043/)，并将被移出网络子系统中，并且增加了像映射（map）这样的工具。为保证安全，它 [引进了一个检查器](http://lxr.free-electrons.com/source/kernel/bpf/verifier.c#L21)，它验证所有的内存访问和可能的代码路径。如果检查器不能保证代码会终止在固定的边界内，它一开始就要拒绝程序的插入。
关于它的更多历史，可以看 [Oracle 的关于 eBPF 的一个很棒的演讲](http://events.linuxfoundation.org/sites/events/files/slides/tracing-linux-ezannoni-linuxcon-ja-2015_0.pdf)。
让我们开始吧！
### 来自 inet\_listen 的问候
因为写一个汇编程序并不是件十分容易的任务，甚至对于很优秀的我们来说，我将使用 [bcc](https://github.com/iovisor/bcc)。bcc 是一个基于 LLVM 的工具集，并且用 Python 抽象了底层机制。探针是用 C 写的，并且返回的结果可以被 Python 利用，可以很容易地写一些不算简单的应用程序。
首先安装 bcc。对于一些示例，你可能会需要使用一个最新的内核版本（>= 4.4）。如果你想亲自去尝试一下这些示例，我强烈推荐你安装一台虚拟机， *而不是* 一个 Docker 容器。你不能在一个容器中改变内核。作为一个非常新的很活跃的项目，其安装教程高度依赖于平台/版本。你可以在  上找到最新的教程。
现在，我希望不管在什么时候，只要有任何程序开始监听 TCP 套接字，我将得到一个事件。当我在一个 `AF_INET` + `SOCK_STREAM` 套接字上调用一个 `listen()` 系统调用时，其底层的内核函数是 [`inet_listen`](http://lxr.free-electrons.com/source/net/ipv4/af_inet.c#L194)。我将从钩在一个“Hello World” `kprobe` 的入口上开始。
```
from bcc import BPF
# Hello BPF Program
bpf_text = """ 
#include 
#include 
// 1. Attach kprobe to "inet_listen"
int kprobe__inet_listen(struct pt_regs *ctx, struct socket *sock, int backlog)
{
    bpf_trace_printk("Hello World!\\n");
    return 0;
};
"""
# 2. Build and Inject program
b = BPF(text=bpf_text)
# 3. Print debug output
while True:
    print b.trace_readline()
```
这个程序做了三件事件：
1. 它通过命名惯例来附加到一个内核探针上。如果函数被调用，比如说 `my_probe` 函数，它会使用 `b.attach_kprobe("inet_listen", "my_probe")` 显式附加。
2. 它使用 LLVM 新的 BPF 后端来构建程序。使用（新的） `bpf()` 系统调用去注入结果字节码，并且按匹配的命名惯例自动附加探针。
3. 从内核管道读取原生输出。
注意：eBPF 的后端 LLVM 还很新。如果你认为你遇到了一个 bug，你也许应该去升级。
注意到 `bpf_trace_printk` 调用了吗？这是一个内核的 `printk()` 精简版的调试函数。使用时，它产生跟踪信息到一个专门的内核管道 `/sys/kernel/debug/tracing/trace_pipe` 。就像名字所暗示的那样，这是一个管道。如果多个读取者在读取它，仅有一个将得到一个给定的行。对生产系统来说，这样是不合适的。
幸运的是，Linux 3.19 引入了对消息传递的映射，以及 Linux 4.4 带来了对任意 perf 事件的支持。在这篇文章的后面部分，我将演示基于 perf 事件的方式。
```
# From a first console
ubuntu@bcc:~/dev/listen-evts$ sudo /python tcv4listen.py 
              nc-4940  [000] d... 22666.991714: : Hello World!
# From a second console
ubuntu@bcc:~$ nc -l 0 4242
^C
```
搞定！
### 抓取 backlog
现在，让我们输出一些很容易访问到的数据，比如说 “backlog”。backlog 是正在建立 TCP 连接的、即将被 `accept()` 的连接的数量。
只要稍微调整一下 `bpf_trace_printk`：
```
bpf_trace_printk("Listening with with up to %d pending connections!\\n", backlog);
```
如果你用这个 “革命性” 的改善重新运行这个示例，你将看到如下的内容：
```
(bcc)ubuntu@bcc:~/dev/listen-evts$ sudo python tcv4listen.py 
              nc-5020  [000] d... 25497.154070: : Listening with with up to 1 pending connections!
```
`nc` 是个单连接程序，因此，其 backlog 是 1。而 Nginx 或者 Redis 上的 backlog 将在这里输出 128 。但是，那是另外一件事。
简单吧？现在让我们获取它的端口。
### 抓取端口和 IP
正在研究的 `inet_listen` 来源于内核，我们知道它需要从 `socket` 对象中取得 `inet_sock`。只需要从源头拷贝，然后插入到跟踪器的开始处：
```
// cast types. Intermediate cast not needed, kept for readability
struct sock *sk = sock->sk;
struct inet_sock *inet = inet_sk(sk);
```
端口现在可以按网络字节顺序（就是“从小到大、大端”的顺序）从 `inet->inet_sport` 访问到。很容易吧！因此，我们只需要把 `bpf_trace_printk` 替换为：
```
bpf_trace_printk("Listening on port %d!\\n", inet->inet_sport);
```
然后运行：
```
ubuntu@bcc:~/dev/listen-evts$ sudo /python tcv4listen.py 
...
R1 invalid mem access 'inv'
...
Exception: Failed to load BPF program kprobe__inet_listen