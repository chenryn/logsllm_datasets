(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
Table 2. Classiﬁcation of legitimate extensions.
(Normal use), and (iii) with our infrastructure attached to
the browser, hence during detection (Detection time).
All the experiments have been performed multiple times
and their results averaged—with negligible variance. The
last two experiments represent the performance overhead
perceived by the user during normal use and during detec-
tion, respectively. The infrastructure attached to the browser
at detection time introduces overhead, ranging from 6.67×
for IE to 8.39× for Firefox. When comparing our memory
proﬁler with other solutions that rely on dynamic instrumen-
tation [30], our infrastructure yields signiﬁcantly lower over-
head, for our ability to ignore memory regions of no interest
a priori. Finally, the performance variations introduced by
our infrastructure when detached is always negligible. This
conﬁrms that our technique does not interfere with the nor-
mal browsing experience.
7. Discussion
A number of interesting ﬁndings emerge from our evalu-
ation. Our model can be effectively used across different
browser versions and implementations. We presented results
for the most widespread versions of the 3 most popular
browsers. We have also experimented with other major re-
leases of Firefox and Chrome obtaining very similar results.
Even if we never found false negatives in our experi-
ments, it is worth considering the potential evasion tech-
niques that a malicious extension may adopt to escape de-
tection. We consider two scenarios. First, an extension could
attempt to leak sensitive data by using some browser func-
tionality that was already represented as a training feature.
By deﬁnition, however, the extension cannot avoid exhibit-
ing relevant memory activity for the particular feature used.
The resulting feature value will inevitably reveal a more in-
tensive memory activity with respect to the baseline and con-
tribute to classifying the extension correctly. Conversely, an
extension could attempt to rely on some browser functional-
ity that did not emerge as a training feature. In this case, the
suspicious behavior will still be detected from the correlation
found between the injection vector and the MPC distribution
of the emerged feature. The only chance to escape detection
is to lower the resulting correlation by performing disguise-
ment activities. While more research is needed to assess the
viability of this strategy in the context of browser extensions,
prior approaches using PCC-based detection have already
discussed the difﬁculty of such an evasion technique [28].
Finally, an attacker could instruct an extension to perform
privacy-breaching activities only in face of particular events,
e.g., when the user visits a particular website. To address this
scenario, our solution allows the user the start a detection run
on all the active extensions at any time, for example before
entering sensitive data into a particular website.
Finally, we comment on how to apply our detection
model to other classes of privacy-breaching extensions. As
done for keylogging extensions, we can easily instantiate our
model to any class of extensions that react to certain sensi-
tive events, as long as it is feasible to (i) artiﬁcially inject
the events of interest into the browser and (ii) determine a
training set that achieves separability between positive and
negative examples. As an example, to detect form-snifﬁng
behavior, we would need to simulate form submission events
and train our model with both form sniffers and regular ex-
tensions that do not record form submission events.
8. Related Work
Many approaches [11, 18, 19] have been initially proposed to
detect privacy-breaching browser extensions, and in partic-
ular the class of malicious software known as spyware add-
ons. These approaches relied on whole-system ﬂow track-
ing [11] and on monitoring the library calls between browser
and BHOs [18]. Besides being tailored to IE and hence not
meeting the requirement of a cross-browser detection model,
they are either dependent on the adopted window of obser-
vation for a successful detection, or unable to set apart ma-
licious add-ons from legitimate extensions using the same
library calls. In the case of [19], the interactions of a BHO
with the browser are regulated by a set of user-deﬁned poli-
cies. However, this approach can not be applied to extensions
where the code run in the same context of the browser.
Recently new approaches focused on taint tracking the
execution of JS by either instrumenting the whole JS en-
gine [9, 33], or rewriting the JS scripts according to some
policies [17]. In both cases the underlying idea is that an ob-
ject containing sensitive information shall not be accessed in
an unsafe way. In our setting this translates to an extension
that shall never be allowed to disclose the user’s private data
to a third-party. All these approaches however, besides incur-
ring high overheads, can not be disabled unless the user re-
places the instrumented binary with its original version. Fur-
thermore they fail to meet our cross-browser requirements.
In particular, given the complexity of modern JS engines,
porting and maintaining them to multiple versions or im-
plementations is both not trivial and requires access to the
source code. Besides being feasible only for browsers which
source-code is freely available, e.g., Firefox and Chrome,
only the vendor’s core teams have all the knowledge required
for the job. In contrast, our approach merely requires to re-
train the model to retroﬁt different versions and implemen-
tations. This does not require any speciﬁc knowledge about
the browser, takes a limited amount of time, and can also be
carried out by unexperienced users.
Since browsers and their extensions were more and more
both target and vector of malicious activities, many stud-
ies recently addressed the more general problem of assuring
the security of the whole browser, extensions included. In
particular, Djeric et al. [10] tackled the problem of detect-
ing JS-script escalating to the same privileges of a JS-based
extension, hence nullifying the protection provided by the
browser’s sandbox. This may happen for two different rea-
sons: in case of bugs in the browser implementation or in
case of a poorly programmed extension, where the input is
not sufﬁciently sanitized. In the last scenario, [2] proposed
a framework to detect these bad practices and help vetting
extensions. In any case the mischief is always the ability to
load arbitrary code, possibly acquiring higher privileges. No
protection is provided against extensions intended to be ma-
licious that disclose private data on purpose.
The basic idea of relying on the correlation between the
activity of a program and its input has been initially intro-
duced in [1, 28], where the main focus was the class of
monitoring applications. These applications execute in the
background and intercept all the keystrokes regardless of
the application being used by the user. Besides being tai-
lored to a limited class of privacy-breaching behaviors, mon-
itoring a program in terms of network [1] and I/O activ-
ity [28] is a coarse-grained approach also bound to fail when
the gathered private data is not immediately leaked away.
The approach proposed in [29] raised the bar by adopting
a more ﬁne-grained approach where individual memory ac-
cesses were monitored; since memory accesses can not be
delayed or postponed, they were able to overcome the limit
of the adopted window of observation. However, all these
approaches cannot be used to solve the problem of detect-
ing privacy-breaching browser extensions. First, the class of
events deemed sensitive is limited to user-issued keystrokes.
Second, a browser always reacts to its input, thus making
a correlation test prone to false positives. Third, they all
assume the malicious program to run in the background,
thus failing to identify a misbehaving browser because of
a privacy-breaching extension installed.
9. Conclusions and Future Work
With their growing availability and ease of distribution,
browser extensions pose a signiﬁcant security threat. In par-
ticular, privacy-breaching extensions that intercept and log
sensitive events are becoming increasingly widespread. Ex-
isting solutions designed to detect privacy-breaching exten-
sions are typically tailored to a particular browser version or
require signiﬁcant efforts to support and maintain multiple
browser implementations over time. Unfortunately, browsers
undergo continuous changes nowadays and the need for
cross-browser detection techniques is stronger than ever.
In this paper, we introduced a generic cross-browser de-
tection model to address this important concern. In addition,
we showed an application of the model to privacy-breaching
extensions with keylogging behavior, and we evaluated both
effectiveness and precision against a set of real-world ex-
tensions. We showed that the performance overhead intro-
duced by our detection infrastructure is conﬁned to a very
limited time window, hence relieving the user from unnec-
essary overhead during the normal browsing experience.
In our future work, we plan to further validate our model
against several classes of privacy-breaching extensions. In
particular, due to the recent gain of momentum [6], our next
focus is validating our model with extensions surreptitiously
intercepting form submissions. In addition, we are planning
to investigate context-speciﬁc policies to automatically ini-
tiate a detection run in the background (e.g., in face of par-
ticular events or when the browser is idle), thus increasing
the dynamic coverage of our analysis to effectively address
trigger-based behavior.
References
[1] Y. Al-Hammadi and U. Aickelin. Detecting bots based on
keylogging activities. Proceedings of the Third International
Conference on Availability, Reliability and Security, pages
896–902, 2008.
[2] S. Bandhakavi, S. T. King, P. Madhusudan, and M. Winslett.
Vex: Vetting browser extensions for security vulnerabilities.
Proceedings of the 19th USENIX Security Symposium (SSYM
’10), pages 339–354, 2010.
[3] Bitdefender. Trojan.PWS.ChromeInject.B. http://www.
bitdefender.com/VIRUS-1000451-en--Trojan.PWS.
ChromeInject.B.html. Accessed: November 2011.
[4] C.-C. Chang and C.-J. Lin. Libsvm: A library for support
vector machines. ACM Transactions on Intelligent Systems
and Technology (TIST), 2:1–27, May 2011.
[5] O. Chapelle, V. Vapnik, O. Bousquet, and S. Mukherjee.
Choosing multiple parameters for support vector machines.
Machine Learning, 46:131–159, March 2002.
ISSN 0885-
6125.
[6] G. Cluley. Mozilla pulls password-snifﬁng ﬁrefox add-on.
http://nakedsecurity.sophos.com/2010/07/15/
mozilla-pulls-passwordsniffing-firefox-addon/.
Accessed: November 2011.
[7] CNET. Internet explorer add-ons. http://download.cnet.
com/windows/internet-explorer-add-ons-plugins.
Accessed: September 2011.
[8] C. Cortes and V. Vapnik. Support-vector networks. Machine
Learning, 20:273–297, 1995.
[9] M. Dhawan and V. Ganapathy. Analyzing information ﬂow in
javascript-based browser extensions. Proceedings of the 2009
Annual Computer Security Applications Conference (ACSAC
2009), pages 382–391, 2009.
[10] V. Djeric and A. Goel. Securing script-based extensibility
in web browsers. Proceedings of the 19th USENIX Security
Symposium (SSYM ’10), pages 355–370, 2010.
[11] M. Egele, C. Kruegel, E. Kirda, H. Yin, and D. Song. Dy-
namic spyware analysis. Proceedings of the 2007 USENIX
Annual Technical Conference (ATC ’07), pages 1–14, 2007.
[12] Google.
Google Chrome Releases.
//googlechromereleases.blogspot.com,
November 2011.
http:
. Accessed:
[13] Google.
Chromebook.
http://www.google.com/
chromebook/, . Accessed: November 2011.
[14] Google. Chrome Web Store. https://chrome.google.
com/webstore, . Accessed: November 2011.
[15] Graydon. Cycle collector landed. http://blog.mozilla.
com/graydon/2007/01/05/cycle-collector-landed/.
Accessed: November 2011.
[16] J. Han, J. Kwon, and H. Lee. Honeyid: Unveiling hidden
spywares by generating bogus events. Proceedings of The
IFIP TC11 23rd International Information Security Confer-
ence, pages 669–673, 2008.
[17] D. Jang, R. Jhala, S. Lerner, and H. Shacham. An empirical
study of privacy-violating information ﬂows in javascript web
applications. Proceedings of the 17th ACM conference on
Computer and communications security (CCS 2010), pages
270–283, 2010.
[18] E. Kirda, C. Kruegel, G. Banks, G. Vigna, and R. Kemmerer.
Behavior-based spyware detection. Proceedings of the 15th
USENIX Security Symposium (SSYM ’06), pages 273–288,
2006.
[19] Z. Li, X. Wang, and J. Y. Choi. Spyshield: Preserving privacy
from spy add-ons. Proceedings of the 10th International
Symposium on Recent Advances in Intrusion Detection (RAID
2007), pages 296–316, 2007.
[20] A. Lieuallen. Greasemonkey. https://addons.mozilla.
org/en-US/firefox/addon/greasemonkey/. Accessed:
November 2011.
[21] Y. Mankani.
tensions Of
12-most-popular-google-chrome-extensions-of-2011.
Accessed: September 2011.
12 Most Popular Google Chrome Ex-
2011.
http://www.techzil.com/
[22] D. Meyer, F. Leisch, and K. Hornik. The support vector
machine under test. Neurocomputing, 55(1-2):169–186, 2003.
[23] Microsoft. Microsoft Security Bulletin Search. http://www.
microsoft.com/technet/security/current.aspx. Ac-
cessed: November 2011.
[24] Mozilla. Blocked Add-ons. https://addons.mozilla.
. Accessed: November
org/en-US/firefox/blocked/,
2011.
[25] Mozilla. Add-ons for Firefox. https://addons.mozilla.
org/en-US/firefox/, . Accessed: November 2011.
[26] Mozilla. Firefox Releases. http://www.mozilla.com/
en-US/firefox/releases/, . Accessed: November 2011.
[27] Nick Freeman. Feed sidebar ﬁrefox extension - privileged
code injection. http://lwn.net/Articles/348921/. Ac-
cessed: December 2011.
[28] S. Ortolani, C. Giuffrida, and B. Crispo. Bait your hook: a
novel detection technique for keyloggers. Proceedings of the
13th International Symposium on Recent Advances in Intru-
sion Detection (RAID 2010), pages 198–217, 2010.
[29] S. Ortolani, C. Giuffrida, and B. Crispo. KLIMAX: Proﬁl-
ing memory write patterns to detect keystroke-harvesting mal-
ware. Proceedings of the 14th International Symposium on
Recent Advances in Intrusion Detection (RAID 2011), pages
81–100, 2011.
[30] D. Quist. Covert debugging circumventing software armoring
techniques. Black Hat Brieﬁngs, 2007.
[31] G. Richards, S. Lebresne, B. Burg, and J. Vitek. An analy-
sis of the dynamic behavior of javascript programs. Proceed-
ings of the 2010 ACM SIGPLAN conference on Programming
language design and implementation (PLDI ’10), pages 1–12,
2010.
[32] S. Ross. Peirce’s criterion for the elimination of suspect
experimental data. Journal of Engineering Technology, 20,
2003.
[33] M. Ter Louw, J. Lim, and V. Venkatakrishnan. Enhancing
web browser security against malware extensions. Journal in
Computer Virology, 4:179–195, 2008.
[34] TricksMachine.
The Top 10 Mozilla Firefox Add-ons,
June 2011. http://www.tricksmachine.com/2011/06/
the-top-10-mozilla-firefox-add-ons-june-2011.
html. Accessed: September 2011.
[35] Various Authors. Trixie.
http://www.bhelpuri.net/
Trixie/. Accessed: October 2011.
[36] W3Schools. Web Statistics and Trends.
http://www.
w3schools.com/browsers/browsers_stats.asp. Ac-
cessed: December 2011.
[37] C. Wuest and E. Florio. Firefox and malware: When browsers
attack. Symantec Security Response, pages 1–15, 2009.