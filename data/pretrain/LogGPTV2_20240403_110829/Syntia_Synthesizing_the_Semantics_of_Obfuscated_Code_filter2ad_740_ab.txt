patcher routine into the individual handler functions such
that handlers execute in a chained manner, instead of
returning to a central dispatcher. Nevertheless, the dis-
patcher still indexes a global handler table.
In Klint’s paper, however, he describes an extension of
TC, Direct Threaded Code (DTC). As in the TC approach,
the dispatcher is appended to each handler. The handler
table, though, is inlined into the bytecode of the instruc-
tion. Each instruction now directly speciﬁes the address
of its corresponding handler. This way, in presence of
bytecode blinding, not all handler addresses are exposed
immediately, but only those used on a certain path in the
bytecode.
Attacks. Several academic works have been published
that propose novel attacks on virtualization-based obfus-
cators [13, 44]. Section 6.3 discusses and classiﬁes them.
In addition, it draws a comparison to our approach.
2.1.2 Return-oriented Programming
In Return-oriented Programming (ROP) [30, 52], shell-
code is expressed as a so-called ROP chain, a list of
references to gadgets and parameters for those. In the
preliminary step of an attack, the adversary makes esp
point to the start of the chain, effectively triggering the
chain upon function return. Gadgets are small, general
instruction sequences ending on a ret instruction; other
ﬂavors propose equivalent instructions. Concrete values
are taken from the ROP chain on the stack. As an example,
consider the gadget pop eax; ret: It takes the value on
top of the stack, places it in eax and, using the ret instruc-
tion, dispatches the next gadget in the chain. By placing
an arbitrary immediate value imm32 next to this gadget’s
address in the chain, an attacker effectively encodes the
instruction mov eax, imm32 in her ROP shellcode. De-
pending on the gadget space available to the attacker, this
technique allows for arbitrary computations [39, 51].
Automated analysis of ROP exploits is a desirable goal.
However, its unique structure poses various challenges
compared to traditional shellcode detection. In their pa-
per, Graziano et al. outline them and propose an analysis
framework for code-reuse attacks [19]. Amongst others,
they mention challenges such as verbosity of the gadgets,
stack-based chaining, lack of immediates, and the distinc-
tion of function calls and regular control ﬂow. Further,
they stress how an accurate emulation of gadgets is im-
portant for addressing these challenges. Considering the
aforementioned challenges, at its core, Return-oriented
Programming can be seen as an albeit weaker ﬂavor of
obfuscated code. In particular, the chained invocation of
gadgets is reminiscent of handlers in VM-based obfusca-
tion schemes following the threaded code principle.
In addition to its application to exploitation, ROP has
seen other ﬁelds of applications such as rootkit devel-
opment [59], software watermarking [34], steganogra-
phy [33], and code integrity veriﬁcation [1], which rein-
forces the importance of automatic ROP chain analysis.
2.1.3 Mixed Boolean-Arithmetic
Zhou et al. propose transformations over Boolean-
arithmetic algebras to hide constants by turning them
into more complex, but semantically equivalent expres-
sions, so called MBA expressions [14, 63]. In Section 6.2,
we provide details on their proposal of MBA expressions
and show how our approach is still able to simplify them.
2.2 Trace Simpliﬁcation
Due to the complexity of static analysis of obfuscated
code, many deobfuscation approaches proposed recently
make use of dynamic analysis [13,19,19,53,62]. Notably,
they operate on execution traces that record instruction
addresses and accompanying metadata, e. g., register con-
tent, along a concrete execution path of a program. Sub-
sequently, trace simpliﬁcation is performed to strip the
obfuscation layer and simplify the underlying code. De-
pending on the approach, multiple traces are used for sim-
pliﬁcation or one single trace is reduced independently.
Coogan et al. [13] propose value-based dependence
analysis of a trace in order to track the ﬂow of values
into system calls using an equational reasoning system.
This allows them to reduce the trace to those instructions
relevant to the previously mentioned value ﬂow.
Graziano et al. [19] mainly apply standard compiler
transformations such as dead code elimination or arith-
metic simpliﬁcations to reduce the trace.
Yadegari et al. [62] use bit-level taint analysis to iden-
tify instructions relevant to the computation of outputs.
For subsequent simpliﬁcation, they introduce the notion
of quasi-invariant locations with respect to an execution.
These are locations that hold the same value at every use
in the trace and can be considered constants when per-
forming constant propagation. Similarly, they use several
other compiler optimizations and adapt them to make use
646    26th USENIX Security Symposium
USENIX Association
Bound for Trees (UCT) [5,17,29] provides a good balance
between exploration and exploitation. It is obtained by
(cid:115)
X j +C
lnn
n j
,
(1)
Figure 2: Illustration of a single MCTS round (taken from
Browne et al. [5]).
of information about quasi-invariance to prevent over-
simpliﬁcation.
2.3 Monte Carlo Tree Search
Monte Carlo Tree Search (MCTS) is a stochastic, best-
ﬁrst tree search algorithm that directs the search towards
an optimal decision, without requiring much domain
knowledge. The algorithm builds a search tree through
reinforcement learning by performing random simula-
tions that estimate the quality of a node [5]. Hence,
the tree grows asymmetrically. MCTS has had sig-
niﬁcant impact in artiﬁcial intelligence for computer
games [16, 35, 49, 56], especially in the context of Com-
puter Go [17, 54].
In an MCTS tree, each node represents a game state; a
directed link from a parent node to its child node repre-
sents a move in the game’s domain. The core algorithm
iteratively builds the decision tree in four main steps that
are also illustrated in Figure 2: (1) The selection step
starts at the root node and successively selects the most-
promising child node, until an expandable leaf (i. e., a
non-terminal node that has unvisited children) is reached.
(2) Following, one or more unvisited child nodes are
added to the tree in the expansion step. (3) In the sim-
ulation step, node rewards are determined for the new
nodes through random playouts. For this, consecutive
game states are randomly derived until a terminal state
(i. e., the end of the game) is reached; the game’s outcome
is represented by a reward. (4) Finally, the node rewards
are propagated backwards through the selected nodes to
the root in the backpropagation step. The algorithm ter-
minates if either a speciﬁed time/iteration limit is reached
or an optimal solution is found [5, 8].
Selecting the most-promising child node can be treated
as a so called multi-armed bandit problem, in which a
gambler tries to maximize the sum of rewards by choosing
one out of many slot machines with an unknown probabil-
ity distribution. Applied to MCTS, the Upper Conﬁdence
where X j represents the average reward of the child
node j, n the current node’s number of visits, n j the visits
of the child node and C the exploration constant. The
average reward is referred to as exploitation parameter:
if C is decreased, the search is directed towards nodes
with a higher reward. Increasing C, instead, leads to an
intensiﬁed exploration of nodes with few simulations.
2.4 Simulated Annealing
Simulated Annealing is a stochastic search algorithm that
has been used to effectively solve NP-hard combinatorial
problems [27]. The main idea of Simulated Annealing is
to approximate a global optimum by iteratively improving
an initial candidate and exploring the local neighborhood.
To avoid a convergence to local optima, the search is
guided by a falling temperature T that decreases the prob-
ability of accepting worse candidates over time [25]; in
the following, we assume that a falling temperature de-
pends on a decreasing loop counter.
Figure 3: Simulated Annealing approximates a global
optimum (the darkest area in the map).
Figure 3 illustrates this process on the example of ﬁnd-
ing the darkest area in a given map. Starting in an initial
state (s0), the algorithm always accepts a candidate that
has a better score than the current one (green arrows). If
the score is worse, we accept the worse candidate with
some probability (the red arrow from s2 to s3) that de-
pends on the temperature (loop counter) and how much
worse the candidate is. The higher the temperature, the
more likely the algorithm accepts a signiﬁcantly worse
candidate solution. Otherwise, the candidate is discarded
(e. g., the crossed out red arrow at s4); in this case, we pick
another one in the local neighborhood. This allows the
algorithm to escape from local optima while the tempera-
ture is high; for low temperatures (loop counters closer to
0), it mainly accepts better candidate solutions. The algo-
rithm terminates after a speciﬁed number of iterations.
USENIX Association
26th USENIX Security Symposium    647
TreePolicyDefaultPolicySelectionExpansionSimulationBackpropagation3.2 Random Sampling
The goal of random sampling is to derive input-output
relations that describe the semantics of a trace window.
This happens in two steps: First, we determine the inputs
and outputs of the trace window. Then, we replace the
inputs with random values and obverse the outputs.
Generally speaking, we consider register and memory
reads as inputs and register and memory writes as outputs.
For inputs, we apply a read-before-write principle: inputs
are only registers/memory locations that are read before
they have been written; for outputs, we consider the last
writes of a register/memory location as output.
1 mov rax , [ rbp + 0 x8 ]
2 add rax , rcx
3 mov [ rbp + 0 x8 ], rax
4 add [ rbp + 0 x8 ], rdx
Following this principle, the code above has three in-
puts and two outputs: The inputs are the memory read M0
in line 1, rcx (line 2) and rdx (line 4). The two outputs
are o0 (line 2) and o1 (line 4).
In the next step, we generate random values and ob-
verse the I/O relationship. For instance, we obtain the
outputs (7,14) for the input tuple (2,5,7); for the inputs
(1,7,10), we obtain (8,18).
By default, we use register locations as well as memory
locations as inputs and outputs. However, we support the
option to reduce the inputs and outputs to either register or
memory locations. For instance, if we know that registers
are only used for intermediate results, we may ignore
them since it reduces the complexity for the synthesis.
3.3 Synthesis
This section demonstrates how we synthesize the seman-
tics of assembly code; we discuss the inner workings of
our synthesis approach in the next section.
After we obtained the I/O samples, we combine the
different samples and synthesize each output separately.
These synthesis instances are mutually independent and
can be completely parallelized.
To exemplify, for the I/O pairs above, we search an
expression that transforms (2,5,7) to 7 and (1,7,10) to 8
for o0; for o1, the expression has to map (2,5,7) to 14 and
(1,7,10) to 18. Then, the synthesizer ﬁnds o0 = M0 +rcx
and o1 = M0 + rcx + rdx.
4 Program Synthesis
In the last section, we demonstrated how we obtain I/O
samples from assembly code and apply program synthesis
to that context. This section describes our algorithm in
detail; we show how we ﬁnd an expression that maps
all inputs to their corresponding outputs for all observed
Figure 4: Dissecting a given trace (a) into several trace
windows (b). The trace windows can be used to recon-
struct a (possibly disconnected) control-ﬂow graph (c).
3 Approach
Given an instruction trace, we dissect the instruction trace
into trace windows (i. e., subtraces) and aim at learning
their high-level semantics which can be used later on
for further analysis. In the following, we describe our
approach which is divided into three distinct parts:
1. Trace Dissection. The instruction trace is partitioned
into unique sequences of assembly instructions in a
(semi-)automated manner.
2. Random Sampling. We derive random input-output
pairs for each trace window. These pairs describe
the trace window’s semantics.
3. Program Synthesis. Expressions that map all pro-
vided inputs to their corresponding outputs are syn-
thesized.
3.1 Trace Dissection
The choice of trace window boundaries highly impacts
later analysis stages. Most notably, it affects synthesis
results: if a trace window ends at an intermediary com-
putation step, the synthesized formula is not necessarily
succinct or meaningful at all, as it includes spurious se-
mantics.
Yet, we note how trace dissection of ROP chains and
VM handlers lends itself to a simple heuristic. Namely,
we split traces at indirect branches. In the ROP case, this
describes the transition between two gadgets (commonly,
on a ret instruction), whereas for VM handlers it distin-
guishes the invocation of the next handler (cf. Section 6.3).
Figure 4 illustrates the approach. Given concrete trace
window boundaries, we can reconstruct a control-ﬂow
graph consisting of multiple connected components. A
trace window then describes a particular path through a
connected component.
648    26th USENIX Security Symposium
USENIX Association
samples. We use Monte Carlo Tree Search, since it has
been proven to be very effective when working on inﬁnite
decision trees without requiring much domain knowledge.
We consider program synthesis as a single-player game
whose purpose is to synthesize an expression whose input-
output behavior is as close as possible to given I/O sam-
ples. In essence, we deﬁne a context-free grammar that
consists of terminal and non-terminal symbols. (Partially)
derived words of the grammar are game states; the gram-
mar’s production rules represent the moves of the game.
Terminal nodes are expressions that contain only terminal
symbols; these are end states of the game.
Given a maximum number of iterations and I/O sam-
ples, we iteratively apply the four MCTS steps (cf. Sec-
tion 2.3), until we ﬁnd a solution or we reach the timeout.
Starting with a non-terminal expression as root node, we
select the most-promising expandable node. A node is
expandable, if there still exist production rules that have
not been applied to this node. We choose a production
rule randomly and expand the selected node. To evaluate
the quality of the new node, we perform a random play-
out: First, we randomly derive a terminal expression by
successively applying random production rules. Then, we
evaluate the expressions based on the inputs from the I/O
pairs and compare the output similarity. The similarity
score is the node reward. A reward of 1 ends the synthe-
sis, since the input-output behavior is the same for the
provided samples. Finally, we propagate the reward back
to the root.
In the following, we give details on node selection, our
grammar, random playouts and backpropagation. Finally,
we discuss the algorithm conﬁguration and parameter
tuning. To demonstrate the different steps of our approach,
we use the following running example throughout this
section:
Example 1 (I/O relationship). Working with bit-vectors of
size 3 (i. e., modulo 23), we observe for an expression with
two inputs and one output the I/O relations: (2,2) → 4
and (4,5) → 1. A synthesized expression that maps the
inputs to the corresponding outputs is f (a,b) = a + b.
4.1 Node Selection
Since we have an inﬁnite search space for program syn-
thesis, node selection must be a trade-off between ex-
ploration and exploitation. The algorithm has to ex-