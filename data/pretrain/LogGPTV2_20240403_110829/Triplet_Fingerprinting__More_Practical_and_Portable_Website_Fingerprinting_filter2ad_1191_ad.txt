a WF attack under more realistic and more challenging scenarios
than found in most papers on WF attacks. We propose the Triplet
Fingerprinting (TF) attack leveraging triplet networks for N-shot
learning, which allows an attacker to train on just a few samples per
site. We evaluate the TF attack under several challenging scenarios.
The results show that the TF attack remains effective with 85%
accuracy even in a scenario in which the data used for training
and testing are from multiple years apart and collected on different
networks. Moreover, we also demonstrate that the TF attack is
effective in the open-world setting and can outperform traditional
transfer learning. These results demonstrate that an attacker with
relatively low computing resources can also perform WF attacks
with fairly effective performance.
Reproducibility
The source code of the implementation and a dataset to repro-
duce our results is publicly available at https://github.com/triplet-
fingerprinting/tf.
ACKNOWLEDGMENTS
We appreciate our discussions with Dr. Leon Reznik, Dr. Sumita
Mishra and Dr. Peizhao Hu that helped develop this paper. Moreover,
we thank the anonymous reviewers for their helpful feedback and
Dr. Amir Houmansadr for shepherding our work.
This material is based upon work supported by the National
Science Foundation under Grants No. CNS-1423163, CNS-1722743
and DGE-1433736.
Figure 8: Open-world: Precision and Recall of the TF attack
against larger open world with growing sizes of unmoni-
tored websites.
Table 13: The performance of the TF attack against WTF-
PAD defense (Accuracy of the attack)
Type of
Experiment
N-Example
1
5
10
15
20
Disjointed Websites
20.5 ± 1.6 54.1 ± 0.7 57.8 ± 0.6 60.2 ± 0.4 61.2 ± 0.4
Different Distributions 15.5 ± 1.7 39.8 ± 0.5 47.2 ± 1.1 50.1 ± 0.4 51.7 ± 0.5
contains both packet direction and timing. Furthermore, we use a
model trained on the WTF-PAD simulated DF95 dataset and WTF-
PAD simulated Wang100 as the N-training and testing datasets,
respectively, to evaluate the performance of the TF attack with
different data distributions.
Result: Table 13 shows the performance of the TF attack against
WTF-PAD defense in two different scenarios. The results reveal
that the accuracy of the attacks in both cases significantly decrease
compared to the non-defended dataset in Table 5 and Table 7. As we
see, it requires at least 15 examples in the case of WF attacks with
similar but mutually exclusive datasets to reach to 60% accuracy.
In the case of WF attacks with different data distributions, the
performance can only reach to 50% accuracy with 15 examples.
However, if we compare the performance of the TF attack using
small dataset with the previously-proposed WF attacks, the TF
attack achieves comparable results. For example, the TF attack
(60.2%) performs nearly the same as the CUMUL (60.3%) and AWF
(60.8%) attacks. Moreover, it can outperform SDAE (36.9%), k-NN
(16.0%) and k-FP (57.0%) attacks.
8 DISCUSSION
Based on what we have observed in our experiments, we now
discuss other key benefits of NSL in WF:
WF attacks against interactive websites: Many websites change
content frequently, as new articles or other information is posted,
and these sites are particularly challenging to fingerprint. NSL
allows the attacker to quickly collect mostly up-to-date network
traffic examples and immediately use them to train the WF classifier.
This may allow the attacker to achieve better performance on these
frequently changing sites by using very fresh data that accurately
characterizes the current state of the site.
Webpage fingerprinting: Most prior work (with exception of [21])
only performs WF on the homepages of each websites and does
REFERENCES
[1] 2011. Test Pilot New Tab Study Results. https://blog.mozilla.org/ux/2011/08/test-
pilot-new-tab-study-results/. (2011). (accessed: August, 2018).
[2] 2017. Keras. https://keras.io/. (2017).
[3] 2017. Users - Tor metrics. https://metrics.torproject.org/userstats-relay-country.
html. (2017).
[4] 2019. New Release: Tor 0.4.0.5. https://blog.torproject.org/new-release-tor-0405.
(2019). [Online; accessed May-2019].
[5] K. Abe and S. Goto. 2016. Fingerprinting attack on Tor anonymity using deep
learning. In in the Asia Pacific Advanced Network (APAN).
[6] Sanjit Bhat, David Lu, Albert Kwon, and Srinivas Devadas. 2018. Var-CNN and
DynaFlow: Improved Attacks and Defenses for Website Fingerprinting. "https:
//arxiv.org/pdf/1802.10215.pdf". (2018). (accessed: August, 2018).
[7] F. Chollet. 2017. Xception: Deep Learning with Depthwise Separable Convolu-
tions. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
1800ś1807. https://doi.org/10.1109/CVPR.2017.195
[8] Li Fei-Fei, R. Fergus, and P. Perona. 2006. One-shot learning of object categories.
IEEE Transactions on Pattern Analysis and Machine Intelligence 28, 4 (April 2006),
594ś611. https://doi.org/10.1109/TPAMI.2006.79
[9] Ben Harwood, BG Kumar, Gustavo Carneiro, Ian Reid, Tom Drummond, et al. 2017.
Smart mining for deep metric learning. In Proceedings of the IEEE International
Conference on Computer Vision. 2821ś2829.
[10] Jamie Hayes and George Danezis. 2016. k-fingerprinting: A robust scalable
website fingerprinting technique. In USENIX Security Symposium. USENIX Asso-
ciation, 1ś17.
[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 770ś778.
[12] Dominik Herrmann, Rolf Wendolsky, and Hannes Federrath. 2009. Website
fingerprinting: attacking popular privacy enhancing technologies with the multi-
nomial Naïve-Bayes classifier. In ACM Workshop on Cloud Computing Security.
ACM, 31ś42.
[13] Marc Juarez, Sadia Afroz, Gunes Acar, Claudia Diaz, and Rachel Greenstadt. 2014.
A critical evaluation of website fingerprinting attacks. In ACM Conference on
Computer and Communications Security (CCS). ACM, 263ś274.
[14] Marc Juarez, Mohsen Imani, Mike Perry, Claudia Diaz, and Matthew Wright. 2016.
Toward an efficient website fingerprinting defense. In European Symposium on
Research in Computer Security (ESORICS). Springer, 27ś46.
[15] Simonyan Karen and Zisserman Andrew. 2015. Very deep convolutional networks
for large-scale image recognition. (2015).
[16] Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov. 2015. Siamese neural
networks for one-shot image recognition. In ICML Deep Learning Workshop,
Vol. 2.
[17] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. ImageNet classifica-
tion with deep convolutional neural networks. In Advances in Neural Information
Processing Systems. Curran Associates, Inc., 1097ś1105.
[18] Akshaya Mani, T. Wilson-Brown, Rob Jansen, Aaron Johnson, and Micah Sherr.
2018. Understanding Tor Usage with Privacy-Preserving Measurement. In Pro-
ceedings of the Internet Measurement Conference 2018 (IMC ’18). ACM, New York,
NY, USA, 175ś187. https://doi.org/10.1145/3278532.3278549
[19] Alireza Bahramali Milad Nasr and Amir Houmansadr. 2018. DeepCorr: Strong
Flow Correlation Attacks on Tor, Using Deep Learning. In ACM Conference on
Computer and Communications Security (CCS). ACM, 1962ś1976. https://doi.org/
10.1145/3243734.3243824
[20] Se Eun Oh, Saikrishna Sunkam, and Nicholas Hopper. 2018. p-FP: Extraction,
Classification, and Prediction of Website Fingerprints with Deep Learning. "https:
//arxiv.org/abs/1711.03656.pdf". (2018). (accessed: August, 2018).
[21] Andriy Panchenko, Fabian Lanze, Andreas Zinnen, Martin Henze, Jan Pennekamp,
Klaus Wehrle, and Thomas Engel. 2016. Website fingerprinting at Internet scale.
In Network & Distributed System Security Symposium (NDSS). IEEE Computer
Society, 1ś15.
[22] Omkar M Parkhi, Andrea Vedaldi, Andrew Zisserman, et al. 2015. Deep face
recognition.. In BMVC, Vol. 1. 6.
[23] Mike Perry. 2015.
Tor Protocol Specification
Proposal. https://gitweb.torproject.org/torspec.git/tree/proposals/254-padding-
negotiation.txt. (2015). (accessed: October 1, 2017).
Padding Negotiation.
[24] Vera Rimmer, Davy Preuveneers, Marc Juarez, Tom Van Goethem, and Wouter
Joosen. 2018. Automated Website Fingerprinting through Deep Learning. In
Proceedings of the 25nd Network and Distributed System Security Symposium
(NDSS 2018). Internet Society.
[25] Florian Schroff, Dmitry Kalenichenko, and James Philbin. 2015. FaceNet: A
Unified Embedding for Face Recognition and Clustering. In The IEEE Conference
on Computer Vision and Pattern Recognition (CVPR).
[26] Roei Schuster, Vitaly Shmatikov, and Eran Tromer. 2017. Beauty and the Burst:
Remote identification of encrypted video streams. In USENIX Security Symposium.
USENIX Association, 1357ś1374.
[27] Payap Sirinam, Mohsen Imani, Marc Juarez, and Matthew Wright. 2018. Deep
Fingerprinting: Undermining Website Fingerprinting Defenses with Deep Learn-
ing. The 25th ACM SIGSAC Conference on Computer and Communications Security
(CCS ’18) (2018).
[28] Yixin Sun, Anne Edmundson, Laurent Vanbever, Oscar Li, Jennifer Rexford, Mung
Chiang, and Prateek Mittal. 2015. RAPTOR: Routing Attacks on Privacy in Tor..
In USENIX Security Symposium. 271ś286.
[29] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015.
Going deeper with convolutions. (June 2015).
[30] Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, and Lior Wolf. 2014. Deepface:
Closing the gap to human-level performance in face verification. In Proceedings
of the IEEE conference on computer vision and pattern recognition. 1701ś1708.
[31] C. v. d. Weth and M. Hauswirth. 2013. DOBBS: Towards a Comprehensive
Dataset to Study the Browsing Behavior of Online Users. In 2013 IEEE/WIC/ACM
International Joint Conferences on Web Intelligence (WI) and Intelligent Agent
Technologies (IAT), Vol. 1. 51ś56. https://doi.org/10.1109/WI-IAT.2013.8
[32] Oriol Vinyals, Charles Blundell, Tim Lillicrap, Daan Wierstra, et al. 2016. Match-
ing networks for one shot learning. In Advances in Neural Information Processing
Systems. 3630ś3638.
[33] Tao Wang, Xiang Cai, Rishab Nithyanand, Rob Johnson, and Ian Goldberg. 2014.
Effective attacks and provable defenses for website fingerprinting. In USENIX
Security Symposium. USENIX Association, 143ś157.
[34] Tao Wang and Ian Goldberg. 2016. On realistically attacking Tor with website
fingerprinting. In Proceedings on Privacy Enhancing Technologies (PoPETs). De
Gruyter Open, 21ś36.
[35] Yixiao Xu, Tao Wang, Qi Li, Qingyuan Gong, Yang Chen, and Yong Jiang. 2018.
A Multi-tab Website Fingerprinting Attack. In Proceedings of the 34th Annual
Computer Security Applications Conference (ACSAC ’18). ACM, New York, NY,
USA, 327ś341. https://doi.org/10.1145/3274694.3274697
[36] Junhua Yan and Jasleen Kaur. 2018. Feature Selection for Website Fingerprinting.
In Proceedings on Privacy Enhancing Technologies (PETS).
[37] Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. 2014. How Transfer-
able Are Features in Deep Neural Networks?. In Proceedings of the 27th Interna-
tional Conference on Neural Information Processing Systems - Volume 2 (NIPS’14).
MIT Press, Cambridge, MA, USA, 3320ś3328. http://dl.acm.org/citation.cfm?id=
2969033.2969197
[38] Ye Zhu, Xinwen Fu, Bryan Graham, Riccardo Bettati, and Wei Zhao. 2010.
Correlation-based traffic analysis attacks on anonymity networks. IEEE Transac-
tions on Parallel and Distributed Systems 21, 7 (2010), 954ś967.
A DATASET’S DISTRIBUTION ANALYSIS
In Section 7.5, we study the performance of the triplet fingerprinting
attack under more challenging scenarios. One of the experiments
that we aim to evaluate is the performance of the attack against
the adverse effect causing from a data mismatch issue. The issue
happens when the distributions of training and testing datasets
are significantly different. We use two different datasets including
1) AWF dataset collected in 2016 using Tor browser version 6 as
the training data, and 2) Wang dataset collected in 2013 using Tor
browser version 3 as the testing data.
Even if the three-year gap of different periods and three differ-
ent versions of Tor browsers between AWF and Wang datasets
can presumably ensure the significant difference in term of their
distributions, we provide further investigation to evaluate how
significantly different between these datasets are. We provide eval-
uations based on two metrics including the basic network traffic
statistic and the similarity measurement.
A.1 Basic Network Traffic Statistic
Common Websites in Wang and AWF datasets: We analyze
the network traffic statistic on websites that are commonly listed
in the Wang and the AWF datasets. We first evaluate the number
of incoming and outgoing packets which directly represents the
change in each website’s contents in term of the size of the website
over periods of time. Table 14 demonstrates the average numbers
m = 0.1 can provide better results than others with ∼0.3ś2.9%
higher accuracy.
• Optimizer: The optimizer is a mathematical model used to
measure and update the weights’ learning with respect to the
loss model. We evaluate different types of optimizer used dur-
ing the training process including SGD, ADAM, Adamax and
RMProp. SGD performs best with slightly higher performance
compared to others with ∼0.3ś1.7% better accuracy. Thus, we
choose SGD as optimizer used during the model’s training
process.
• Batch Size: Batch size is the number of inputs that are sampled
to be fed to the network during the training process. We find
that batch size = 64 and batch size = 128 can provide ∼1.5%
better accuracy than others. Thus, we choose to use them as
the final choices.
• Embedded Vector’s Size: The embedded vectors size is the
size of the last dense layer in each subnetwork. It contains
the vectors of the output after feeding the input through the
learned model to extract features. We find that there is no
noticeable difference between our candidates. Thus, we simply
select the embedded vectors size = 64 as the final selection
because it requires less number of training parameters in the
network helping reduce the time for training the model.
accuracy of the attack gradually improves as k gets smaller
except for 1-Shot learning that gains significant increase with
∼5% accuracy when k is reduced from k = 100 to k = 50.
Overall, the results show the consistent increase of the accuracy
with the larger Top-n and smaller k-Way. The improved accuracy
form Top-1 to Top-2 can be interpreted that the triplet model cannot
perform well enough to move the embedded vector to be closest to
the corresponding website in the embedding space. However, it is
closed enough to be in the second closest neighbor. This suggests
that the improvement of the subnetwork or the larger number of
websites used for training model can possibly be the key factors to
substantially improve quality of the model and ultimately increase
the performance of the attacks. The results also reveal that if the
attacker is interested in detecting a smaller set of websites, the
performance of the attack can be improved.
D TF ATTACK’S HYPERPARAMETER
TUNING PROCESS
In this part, we provide intuitive explanation and the preliminary
results used for each parameter selection in addition to what is
mentioned in Section 6.1. For each selection, we vary the range of
parameters to run the model. We only use the subset of training
and testing data due to the fact that using the full size of data
requires large amount of time to complete each evaluation. We then
compare the result given by each setting and finally selected the
most effective one.
• Based Model: We test with previously-proposed state-of-the-
art DL models used in image recognition literature including
GoogleNet [29], RestNet [11] and Xception [7] and compared
with DF [27] model; the state-of-the-art model dedicatedly
designed for the WF task. Our preliminary results demonstrate
that the DF model can perform slightly better with significantly
less training time required. It turns out that using the DF as
the base model takes approximately 400s on each epoch of
training. On the other hand, the very deep learning models
such as GoogleNet, RestNet and Xception require over 600s on
each epoch of training. Thus, we choose the DF model as the
subnetwork in the triplet networks.
• Distance Metrics: We compare two distance metrics generally
used in the N-Shot learning applications including Cosine
distance and Euclidean distance. Our preliminary results shows
that using the Cosine distance provides higher performance
than using the Euclidean one with ∼2ś3% better accuracy.
• Mining Strategy: We evaluate three different mining strate-
gies used to generate the triplets input including Random, Hard-
Negative and Semi-Hard-Negative. The results shows that the
Semi-Hard-Negative perform better than the rest in term of
the accuracy of the attack e.g. ∼7% and ∼40% when compared
with Random and Hard-Negative minings respectively.
• Margin: The margin’s value defines a radius around the em-
bedded vector and helps for the learning process. The value is
specific for each type of data’s input, thus, we have to find the
best m value that is suitable for network traffic and provide ef-
fective performance to the model. We find that margin’s value