would have been able to measure the correct RTT est.
Multiple BBR Flows vs Loss-Based Flows: We now return to
multiple BBR flows vs loss-based flows. As we saw when BBR flows
were only competing with each other, if the BDP is not large enough
to accommodate 4N packets during ProbeRTT, BBR’s RTT estimate
will be too large. If we assume 4N additional packets are in the
queue during ProbeRTT, then,
RTTest =
pq + 4N
c
+ l .
(7)
Here, we also include l, no longer assuming it is negligible compared
to queueing delay. Plugging (7) and (2) into (1), in aggregate all N
BBR flows will have:
inflightcap = 2(1 − p)c
+ l
.
(8)
(cid:18) pq + 4N
c
(cid:19)
To compute the BBR flows’ aggregate fraction of the link, we set
inflightcap equal to the amount of data BBR flows have in-flight
and solve for p:
(cid:18) pq + 4N
(cid:19)
2(1 − p)c
+ l
c
5.5 Extended Model: ProbeRTT Duration
During ProbeRTT, BBR stops sending data while it waits for its in-
flight data to fall to 4 packets. You can see this behavior impacting
goodput in Fig. 1c. If the queue is large and also full when BBR
goes into ProbeRTT, this results in long intervals where BBR is not
sending any data. 4 This results in BBR on average consuming a
lower fraction of link capacity than if it were sending constantly at
a rate proportional to its inflight cap.
Model: If the total duration of time the flows are competing (after
convergence) is d, the fraction of the link BBR flows will use when
competing with loss-based CCAs is:
BBRf r ac = (1 − p) ×
(cid:18) d − Probetime
(10)
(cid:19)
,
d
where p is computed using (9). During Probetime throughput is
nearly zero.
We compute Probetime by computing the length of time spent
in ProbeRTT state, and multiply by how many times BBR will
go into ProbeRTT state. Assuming the queue is full before BBR
enters ProbeRTT state, BBR will have to wait for the queue to drain
before its data in-flight falls to 4 packets. Once it reaches this in-
flight cap, BBR also waits an additional 200ms and a packet-timed
round trip before exiting ProbeRTT. Assuming synchronized flows
and the queue is typically full, BBR flows should rarely measure a
smaller RTT outside of ProbeRTT state so it should enter ProbeRTT
about every 10 seconds. Altogether, this means probe time increases
linearly with queue size:
Probetime =
+ .2 + l
(11)
(cid:16) q
c
(cid:17) × d
10
Validating Prober tt : First, we measure the probe time from exper-
iments with competing BBR flows in for a 40ms×15 Mbps network
for experiments run for 400 seconds after convergence (d=400)
for Cubic We compare this to our prediction computed from (11).
Fig. 7 compares (11) to measured probe time—the model fits the
observations well. Most commonly the predicted probe time for
experiments with Cubic is 1-3 seconds larger than the expectation
and is at most about 8 seconds too large.
Validating the Extended Model: We measure the average through-
put for BBR competing against Cubic or Reno after convergence
(d = 400 for Cubic, d = 200 for Reno). We use (10) to compute BBR’s
expected fraction of the link versus our measurements. Our expec-
tations closely follow empirical results in most cases, validating our
model. Fig. 8 compares (10) to the BBR flows aggregate fraction of
the link when competing with Reno or Cubic. The median error
competing against Cubic 5%, and against Reno 8%.
= (1 − p)q + (1 − p)cl
p = 1
2
− 4N
q
− 1
2X
(9)
4In fact, BBR authors have even noted that this is a significant limitation on BBR’s
performance, and in BBRv2 design change ProbeRTT so that it reduces BBR’s inflight
cap to 50% of it’s BDPest instead of 4 packets [7].
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Ranysha Ware et al.
(a) 40ms × 10 Mbps, vs 1 Cubic Flow
(b) 30ms × 50 Mbps, vs 1 Cubic Flow
(c) 40ms × 10 Mbps, vs 1 Reno Flow
Figure 8: Model compared to observed aggregate fraction of the link.
For Cubic, the model fits the observations best with large queue
sizes and large numbers of flows. In this case, our assumptions
that the queue is typically full, and 4N BBR packets will be in the
queue during ProbeRTT, inflating RTTest , are more likely to be true.
However, Reno reveals an opposite trend: the model does worse as
the queue becomes larger. We suspect this is due to Reno’s slower
(relative to Cubic) additive increase failing to take advantage of the
available capacity and hence leaving a larger share of throughput
for BBR.
6 RELATED WORK
The first independent study of BBR was presented by Hock et al.
[11]. Their analysis of BBR identifies the important property that
multiple BBR flows operate at their in-flight cap in buffer-bloated
networks. Further, they present experiments for 1 BBR flow and
1 Cubic flow, noting that in large buffers, they oscillate around
equally sharing the bottleneck. They also observe that when 2 BBR
flows compete with 2 Cubic flows in a shallow-buffered network,
BBR flows will starve the Cubic flows. Several additional empirical
studies have reproduced and extended these results [9, 14, 16].
Scholz et al. [14] run tests for up to 10 BBR flows competing with up
to 10 Cubic flows in a large buffer and conclude that, “independent
of the number of BBR and Cubic flows, BBR flows are always able
to claim at least 35% of the total bandwidth." Dong et al. [9] also
note that as 1 BBR flow competes with an ever increasing number
of Cubic flows, BBR’s fraction of the bandwidth remains the same.
Each of these studies touches on important aspects of BBR’s
behavior, but we are the first to model BBR’s behavior in these
scenarios rather than to simply observe it. Through our model,
we are able to explain the missing parts of seemingly conflicting
conclusions drawn in prior work.
Google is actively developing BBRv2 and very recently released
a Linux kernel implementation of BBRv2 [2, 7, 8]. Early presen-
tations [8] imply that it primarily resolves the fairness issues dis-
cussed by Hock et al [11], but does not touch on the fixed proportion
of link capacity as discussed in this paper.
7 CONCLUSION
In this paper, we have shown that BBR’s inflight cap – a ‘safety
mechanism’ added to handle delayed and aggregated ACKs – is in
reality central to BBR’s behavior on the Internet. When BBR flows
compete with other traffic (BBR, Cubic, or Reno), BBR becomes
window-limited and ACK-clocked, sending packets at a rate entirely
determined by its inflight cap.
When competing with loss-based TCPs such as Cubic and Reno,
BBR’s cap can be computed using the bottleneck buffer size, the
number of concurrent BBR flows, and the baseline network RTT.
However, the number of competing loss-based flows are not a factor
in computing this cap. Hence, BBR does not reduce its sending rate
even as more loss-based flows arrive on the network. This is the
cause of reports arguing that BBR is ‘unfair’ to legacy TCPs.
8 ACKNOWLEDGEMENTS
We thank the Neal Cardwell, Yucheng Cheng, Soheil Hassas Yeganeh,
and Jana Iyengar for the fruitful conversations surrounding BBR
and our analysis, as well as our shepherd Srikanth Sundaresan
for guiding the revision process. This research was funded by a
Facebook Emerging Scholar Fellowship, NSF Grant #1850384, and
a Google Faculty Research Award.
REFERENCES
[1] 2018. iperf3. https://software.es.net/iperf/. (2018).
[2] 2019. BBRv2 alpha Linux code. https://github.com/google/bbr/blob/v2alpha.
[3] N. Cardwell, Y. Chen, S. Hassas Yeganeh, and V. Jacobsen. 2017. BBR Congestion
Control. IETF Draft draft-cardwell-iccrg-bbr-congestion-control-00. (2017).
[4] Neal Cardwell, Yuchung Cheng, C Stephen Gunn, Soheil Hassas Yeganeh, and
(2019).
Van Jacobson. 2016. BBR congestion control. In IETF meeting.
[5] Neal Cardwell, Yuchung Cheng, C. Stephen Gunn, Soheil Hassas Yeganeh, and
Van Jacobson. 2017. BBR: Congestion-based Congestion Control. Commun. ACM
60, 2 (Jan. 2017), 58–66. https://doi.org/10.1145/3009824
[6] Neal Cardwell, Yuchung Cheng, C Stephen Gunn, Soheil Hassas Yeganeh, and
Van Jacobson. 2017. BBR Congestion Control: An update. In Presentation in
ICCRG at IETF 98th meeting.
[7] N. Cardwell, Yuchung Cheng, Soheil Hassas Yeganeh, Ian Swett, Victor Vasiliev,
Priyaranjan Jha, Yousuk Seung, Matt Mathis, and Van Jacobson. 2019. BBRv2: A
Model-Based Congestion Control. In Presentation at IETF104.
[8] N. Cardwell, Yuchung Cheng, Soheil Hassas Yeganehand Priyaranjan Jha, , Yousuk
Seung, Ian Swett, Victor Vasiliev, Bin Wu, Matt Mathis, and Van Jacobson. 2019.
Modeling BBR’s Interactions with
Loss-Based Congestion Control
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
BBRv2: A Model-Based Congestion Control IETF 105 Update. In Presentation at
IETF105.
[9] Mo Dong, Tong Meng, Doron Zarchy, Engin Arslan, Yossi Gilad, Brighten Godfrey,
and Michael Schapira. 2018. PCC Vivace: Online-Learning Congestion Control.
In 15th USENIX Symposium on Networked Systems Design and Implementation
(NSDI 18). USENIX Association, Renton, WA, 343–356. https://www.usenix.org/
conference/nsdi18/presentation/dong
[10] Sangjin Han, Keon Jang, Aurojit Panda, Shoumik Palkar, Dongsu Han, and Sylvia
Ratnasamy. 2015. SoftNIC: A Software NIC to Augment Hardware. Technical Report
UCB/EECS-2015-155. EECS Department, University of California, Berkeley. http:
//www2.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-155.html
[11] Mario Hock, Roland Bless, and Martina Zitterbart. 2017. Experimental evaluation
of BBR congestion control. In 2017 IEEE 25th International Conference on Network
Protocols (ICNP). IEEE, 1–10.
[12] Christian Kreibich, Nicholas Weaver, Boris Nechaev, and Vern Paxson. 2010. iNet-
alyzr: Illuminating the Edge Network. In Proceedings of the 10th ACM SIGCOMM
Conference on Internet Measurement (IMC ’10). ACM, New York, NY, USA, 246–259.
https://doi.org/10.1145/1879141.1879173
[13] Rob Marvin. 2018. Netflix and YouTube Make Up Over a Quarter of Global
Internet Traffic. PC Magazine (15 10 2018).
[14] Dominik Scholz, Benedikt Jaeger, Lukas Schwaighofer, Daniel Raumer, Fabien
Geyer, and Georg Carle. 2018. Towards a Deeper Understanding of TCP BBR
Congestion Control. In IFIP Networking 2018. Zurich, Switzerland.
[15] Scott Shenker, Lixia Zhang, and David D Clark. 1990. Some observations on
the dynamics of a congestion control algorithm. ACM SIGCOMM Computer
Communication Review 20, 5 (1990), 30–39.
[16] Belma Turkovic, Fernando A Kuipers, and Steve Uhlig. 2019. Fifty Shades of
Congestion Control: A Performance and Interactions Evaluation. arXiv preprint
arXiv:1903.03852 (2019).
[17] R. Ware, M. K. Mukerjee, J. Sherry, and S. Seshan. 2018. The Battle for Bandwidth:
Fairness and Heterogeneous Congestion Control. In Poster at NSDI 2018.