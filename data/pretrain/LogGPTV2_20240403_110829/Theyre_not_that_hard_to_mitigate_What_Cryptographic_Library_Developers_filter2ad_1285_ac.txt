✓
27
(75%)
27
(75%)
✓
✓
✓
✓
✓
✓
p
✓
✓
✓
p
✓
✓
✓
✓
✓
✓
✓
No public CI
✓
✓
✓
✓
✓
p
No public CI
✓
✓
✓
✓
No public CI
No public CI
✓
✓
No public CI
✓
✓
✓
✓
p
✓
✓
p
p
✓
✓
✓
p
✓
✓
✓
✓
p
No public CI
✓
✓
No public CI
No public CI
No public CI
✓
p
p
p
27
(75%)
16
(44%)
p
p
✓
p
✓
p
p
✓
✓
p
p
p
p
p
✓
p
p
p
p
p
p
p
p
p
p
✓
p
6
(17%)
* Java
† Rust
‡ Includes being fuzzed by OSS-Fuzz or cryptofuzz.
LIBRARIES AND PRIMITIVES INCLUDED AND THE ACTIONS THEY
PERFORM IN THEIR PUBLIC CONTINUOUS INTEGRATION PIPELINES.
TABLE II
a) Foundations
of
constant-time
programming:
by
programming
is
foundations
supported
rigorous
Constant-time
typically establish that
foundations. These
programs are protected against passive adversaries
that
observe program execution. However, Barthe et al. [52] show
that constant-time programs are protected against system-level
adversaries that control the cache (in prescribed ways) and
the scheduler. Recently, these foundations have been extended
to reflect micro-architectural attacks [59]–[62]. In parallel,
a large number of tools are being developed to prove that
programs are speculative-constant-time, a strengthening of
the constant-time property which offers protection against
Spectre [9] attacks. We expect that many of the takeaways of
our work are applicable to this novel direction of work.
b) High-assurance cryptography: High-assurance cryp-
tography is an emerging area that aims to build efficient
implementations that achieve functional correctness, constant-
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:37:33 UTC from IEEE Xplore.  Restrictions apply. 
635
timeness, and security. High-assurance cryptography has al-
ready achieved notable successes [8]. The most relevant suc-
cess in the context of this work is the EverCrypt library [63],
[64], which has been deployed in multiple real-world systems,
notably Mozilla Firefox and Wireguard VPN. The EverCrypt
library is formally verified for constant-timeness (and func-
tional correctness). However, the library is conceived as drop-
in replacements for existing implementations, and despite
relying on an advanced infrastructure built around the F*
programming language, this work does not explicitly target
open-source cryptographic library developers as potential users
of their infrastructure. Other projects that enforce constant-
time by default, such as Jasmin [65], [66] or FaCT [47], target
open source cryptographic library developers more explicitly,
but rely on domain-specific languages, which may hinder their
broad adoption. In contrast, we focus on tools that do not
impose a specific programming framework for developers.
c) Human factor research: Researchers have tried to
answer the question of why cryptographic advances do not
necessarily reach users. In a 2017 study, Acar et al. find that
bad cryptographic library usability contributes to misuse, and
therefore insecure code [67]. Krueger et al. developed and built
upon a wizard to create secure code snippets for cryptographic
use cases [68], [69]. Unlike these prior studies that investigate
users of cryptographic libraries, we study the developers of
cryptographic libraries, their threat models and decisions as
they relate to timing attacks.
Haney et al. investigate the mindsets of those who develop
cryptographic software, finding that company culture and
security mindsets influence each other positively, but also
that some cryptographic product developers do not adhere
to software engineering best practices (e.g., they write their
own cryptographic code) [70]. We expand on this research by
surveying open-source cryptographic library developers with
respect to their decisions and threat models as they relate to
side-channel attacks.
In the setting of constant-time programming, Cauligi et
al. [47] carry a study with over 100 UCSD students to
understand the benefits of FaCT, a domain-specific framework
that enforces constant-time at compile-time, with respect to
constant-time programming in C. They find that tool support
for constant-time programming is helpful. We expand on
their study by surveying open-source cryptographic library
developers and considering a large set of tools.
Very recently, there have been calls to make formal verifi-
cation accessible to developers: Reid et al. suggest “meeting
developers where they are” and integrating formal verification
functionality in tools and workflows that developers are al-
ready using [71]. To our knowledge, ours is the first survey
that empirically assesses cryptographic library developers’
experiences with formal verification tools.
III. METHODOLOGY
In this section, we provide details on the procedure and
structure of the survey we conducted with 44 developers of
popular cryptographic libraries and primitives. We describe
the coding process for qualitative data, as well as the approach
for statistical analyses for quantitative results. We explain our
data collection and ethical considerations, and discuss the
limitations of this work.
A. Study Procedure
We asked 201 representatives of popular cryptographic li-
braries or primitives to participate in our survey. The recruited
developers reside in different time zones and each may have
different time constraints. As we were mainly interested in
qualitative insights, based on the small number of qualifying
individuals and our past experiences with low opt-in rates
when attempting to recruit high-level open source developers
into interview studies, we opted for a survey with free-text
answers.
a) Questionnaire Development: We used our research
questions as the basis for our questionnaire development, but
we also let our experience with the development of cryp-
tographic libraries, constant-time verification tools (both as
authors as well as users), and conducting developer surveys in-
fluence the design. Our group of authors consists of one human
factors researcher and experts from cryptographic engineering,
side-channel attacks, and constant-time tool developers. The
human factors researcher introduced and facilitated the use
of human factors research methodology to answer experts’
research questions posited in this paper. In particular,
the
human factor researcher explained methods when appropriate,
facilitated many discussions and helped the team to develop
the survey, pilot it, gather feedback, and evaluate the results.
While iterating over the questionnaire, we also collected
feedback and input from members of the cryptographic library
development community.
b) Pre-Testing: Following the principle of cognitive in-
terviews [72], we walked through the survey with three partic-
ipants who belonged to our targeted population, and updated,
expanded and clarified the survey accordingly.
c) Recruitment and Inclusion Criteria: We created a list
of the most active contributors to libraries that implement cryp-
tographic code, including those that implement cryptographic
primitives. If a library had any formal committee for making
technical decisions, we invited its members. The list of most
active developers was extracted from source control by taking
the developers with the largest amount of commits down to
a cut-off point that was adjusted per library. Table II gives
an overview of projects for which we invited participants. All
authors then identified those contributors that belonged to their
own personal or professional networks and invited those in a
personalized email. All others were invited by a co-author
who is active in the formal verification and cryptography
community, for whom we assumed that they would be widely
known and have the best chance of eliciting responses. All
contributors were sent an invitation with a personalized link.
We did not offer participants compensation, but offered them
links to all the tools we mentioned in our survey, as well as
the option to be informed about our results.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:37:33 UTC from IEEE Xplore.  Restrictions apply. 
636
B. Survey Structure
The survey consisted of six sections (see Figure 2) detailed
below. The full questionnaire can be found in Appendix A.
Fig. 2. Survey flow as shown to participants.
1. Participant background: We asked participants about
their background in cryptography, their years of experience
in developing cryptographic code, and their experience as a
cryptographic library / primitive developer.
2. Library properties and decisions: We asked about
participants’ role in ’s development, how they are
involved in design decisions for . We asked about the
intended use cases for , ’s threat model with
respect to side-channel attacks, whether they consider timing
attacks a relevant threat for the intended use of 
and its threat model, and asked for an explanation for their
reasoning. We also asked whether and how  protects
against timing attacks, and whether, how, and how often they
test or verify resistance to timing attacks.
3. Tool awareness: We asked whether they were aware of
tools that can test or verify resistance to timing attacks. We
then listed 25 tools from Section II-B and asked them whether
they were aware of them, and how they learned about them.
4. Tool use: We asked participants about their past ex-
perience, interactions, comprehension, and satisfaction with
using tools to test/verify resistance to timing attacks, including
challenges with using them.
5. Hypothetical tool use: We showed participants a descrip-
tion of properties that their code would have to fulfill in order
to be able to use a group of tools and given a description
of the guarantees the tools would give them, asking them
about usage intentions and reasoning. The tools were grouped
into dynamic instrumentation based, statistical test based, and
formal analysis tools.
6. Miscellaneous: Finally, we asked about any comments
on (resistance to) timing attacks, our survey, and whether they
wanted us to inform them about our results.
C. Coding and Analysis
Those who engaged with participant responses came from
different backgrounds, with different views, contributing to
the multi-faceted evaluation. Three researchers familiar with
constant-time verification and open-source cryptographic li-
brary development conducted the qualitative coding process,
facilitated by one researcher with experience with human fac-
tors research with developers. We followed the process for the-
matic analysis [73]. The three coders familiarized themselves
with all free-text answers, and annotated them. Based on these
annotations, themes were developed, as well as a codebook.
The codebook was developed inductively based on questions,
and iteratively changed based on responses we extracted from
the free-text answers; all codes were operationalized based on
discussions within the team. The three coders then coded all
responses with the codebook, iterating over the codebook until
they were able to make unanimous decisions. The codebook
codifies answers to free-text questions, as well as identifying
misconceptions, concerns, and wishes. In some cases where
documentation was available, and participant answers were
incomplete or ambiguous, or when participants linked to
documentation, coders supplemented their code assignment
based on the documentation. Our coding process was only
one step in the quest for our goal: identifying themes and
answering our research questions. All codes were discussed,
and eventually agreed upon by three coders3. In line with
contemporary human factors research, we therefore omit inter-
coder agreement calculations [74]. For the comparison of the
likelihood of using certain tools with certain requirements in
exchange for guarantees (Q5.1, Q6.1, Q7.1), we used Fried-
man’s test with Durbin post-hoc tests [75] with Benjamini-
Hochberg multiple testing corrections [76].
D. Data Collection and Ethics
While our survey was sent
to open-source contributors
without solicitation, we only emailed them up to twice. During
and after the survey,
they could opt-out of participation.
We do not link participant names to results, nor participant
demographics to libraries to keep responses as confidential
as possible. We also do not link quotes to libraries or their
developers, and report mostly aggregate data. Quotes are
pseudonymized. Our study protocol and consent form were
approved by our institution’s data protection officer and ethics
board and determined to be minimal risk. Participant names
and email addresses were stored separately from study data,
and only used for contacting participants.
3Our
usablect_sp22.