logistic sigmoid acting on a function f ( (cid:2)w) parametrized by
the vector (cid:2)w as p (C, t| (cid:2)w) = σ(tf ) = (1 + e
−1. Thereby
f determines through f = 0 a decision boundary of equal
output probabilities. For a given training set M of CRPs
the boundary is positioned by choosing the parameter vector
(cid:2)w in such a way that the likelihood of observing this set is
maximal, respectively the negative log-likelihood is minimal:
ˆ(cid:2)w = argmin (cid:2)wl(M, (cid:2)w) = argmin (cid:2)w
−ln (σ (tf ( (cid:2)w, C)))
(cid:2)
−tf )
(C, t)∈ M
(1)
As there is no analytical solution to determine the optimal
parameter vector ˆ(cid:2)w, it has to be optimized iteratively, e.g.,
239using the gradient information
∇l(M, (cid:2)w) =
t(σ(tf ( (cid:2)w, C)) − 1)∇f ( (cid:2)w, C)
(2)
(cid:2)
(C, t)∈ M
From the diﬀerent optimization methods which we tested
in our ML experiments (standard gradient descent, iterative
reweighted least squares, RProp [21] [22]), RProp gradient
descent performed best. Logistic regression has the asset
that the examined problems need not be (approximately)
linearly separable in feature space, as is required for suc-
cessful application of SVMs, but merely diﬀerentiable.
In our ML experiments, we used an implementation of LR
with RProp programmed in our group, which has been put
online, see [23]. The iteration is continued until we reach
a point of convergence, i.e., until the averaged prediction
rate of two consecutive blocks of ﬁve consecutive iterations
does not increase anymore for the ﬁrst time. If the reached
performance after convergence on the training set is not suf-
ﬁcient, the process is started anew. After convergence to
a good solution on the training set, the prediction error is
evaluated on the test set.
The whole process is similar to training an Artiﬁcial Neu-
ral Network (ANN) [21]. The model of the PUF resembles
the network with the runtime delays resembling the weights
of an ANN. Similar to ANNs, we found that RProp makes a
very big diﬀerence in convergence speed and stability of the
LR (several XOR-PUFs were only learnable with RProp).
But even with RProp the delay set can end up in a region
of the search space where no helpful gradient information is
available (local minimum). In such a case we encounter the
above described situation of converging on a not suﬃciently
accurate solution and have to restart the process.
2.1.2 Evolution Strategies
Evolution Strategies (ES) [24, 25] belong to an ML sub-
ﬁeld known as population-based heuristics. They are in-
spired by the evolutionary adaptation of a population of in-
dividuals to certain environmental conditions. In our case,
one individual in the population is given by a concrete in-
stantiation of the runtime delays in a PUF, i.e., by a concrete
instantiation of the vector (cid:2)w appearing in Eqns. 1 and 2.
The environmental ﬁtness of the individual is determined by
how well it (re-)produces the correct CRPs of the target PUF
on a ﬁxed training set of CRPs. ES runs through several
evolutionary cycles or so-called generations. With a grow-
ing number of generations, the challenge-response behavior
of the best individuals in the population better and better
approximates the target PUF. ES is a randomized method
that neither requires an (approximately) linearly separable
problem (like Support Vector Machines), nor a diﬀerentiable
model (such as LR with gradient descent); a merely param-
eterizable model suﬃces. Since all known electrical PUFs
are easily parameterizable, ES is a very well-suited attack
method.
We employed an in-house implementation of ES that is
available from our machine learning library PyBrain [26].
The meta-parameters in all applications of ES throughout
this paper are (6,36)-selection and a global mutation oper-
ator with τ = 1√
n . We furthermore used a technique called
Lazy Evaluation (LE). LE means that not all CRPs of the
training set are used to evaluate an individual’s environmen-
tal ﬁtness; instead, only a randomly chosen subset is used for
evaluation, that changes in every generation. In this paper,
we always used subsets of size 2,000 CRPs, and indicated
this also in the caption of the respective tables.
2.2 Employed Computational Resources
We used two hardware systems to carry out our exper-
iments: A stand-alone, consumer INTEL Quadcore Q9300
worth less than 1,000 Euros. Experiments run on this sys-
tem are marked with the term “HW (cid:2)”. Secondly, a 30-
node cluster of AMD Opteron Quadcores, which represents
a worth of around 30,000 Euros. Results that were obtained
by this hardware are indicated by the term “HW (cid:3)”. All
computation times are calculated for one core of one proces-
sor of the corresponding hardware.
2.3 PUF Descriptions and Models
Arbiter PUFs.
Arbiter PUFs (Arb-PUFs) were ﬁrst introduced in [11]
[12] [9]. They consist of a sequence of k stages, for exam-
ple multiplexers. Two electrical signals race simultaneously
and in parallel through these stages. Their exact paths are
determined by a sequence of k external bits b1 ··· bk applied
to the stages, whereby the i-th bit is applied at the i-th
stage. After the last stage, an “arbiter element” consisting
of a latch determines whether the upper or lower signal ar-
rived ﬁrst and correspondingly outputs a zero or a one. The
external bits are usually regarded as the challenge C of this
PUF, i.e., C = b1 ··· bk, and the output of the arbiter ele-
ment is interpreted as their response R. See [11] [12] [9] for
details. The parameter k is often referred to as the bitlength
of the Arbiter PUF.
It has become standard to describe the functionality of
Arb-PUFs via an additive linear delay model [17] [10] [19].
The overall delays of the signals are modeled as the sum
of the delays in the stages. In this model, one can express
the ﬁnal delay diﬀerence Δ between the upper and the lower
path in a k-bit Arb-PUF as Δ = (cid:2)wT (cid:2)Φ, where (cid:2)w and (cid:2)Φ are of
dimension k +1. The parameter vector (cid:2)w encodes the delays
for the subcomponents in the Arb-PUF stages, whereas the
feature vector (cid:2)Φ is solely a function of the applied k−bit
challenge C [17] [10] [19].
0/1
In greater detail, the following holds. We denote by δ
i
the runtime delay in stage i for the crossed (1) respectively
uncrossed (0) signal path. Then
(cid:2)w = (w
1 − δ
2
1
1
0
where w1 = δ
2, . . . , k, and wk+1 = δ
, wi =
1
0
k + δ
k
1
2
, w
, . . . , w
k+1
k
, w
)
T
0
i−1 + δ
δ
1
i−1 + δ
2
. Furthermore,
2
k
1
(cid:2)Φ( (cid:2)C) = (Φ
( (cid:2)C), . . . , Φ
(cid:3)k
( (cid:2)C), 1)
i=l(1 − 2bi) for l = 1, . . . , k.
T
,
,
i − δ
0
1
i
(3)
for all i =
(4)
where Φl( (cid:2)C) =
The output t of an Arb-PUF is determined by the sign
of the ﬁnal delay diﬀerence Δ. We make the technical con-
vention of saying that t = −1 when the Arb-PUF output is
actually 0, and t = 1 when the Arb-PUF output is 1:
t = sgn(Δ) = sgn( (cid:2)w
T (cid:2)Φ).
(5)
Eqn. 5 shows that the vector (cid:2)w via (cid:2)wT (cid:2)Φ = 0 determines a
separating hyperplane in the space of all feature vectors (cid:2)Φ.
Any challenges C that have their feature vector located on
the one side of that plane give response t = −1, those with
240feature vectors on the other side t = 1. Determination of
this hyperplane allows prediction of the PUF.
seems fair to attack it in the described manner; in any case,
our results challenge the bit security of the Lightweight PUF.
XOR Arbiter PUFs.
One possibility to strengthen the resilience of arbiter ar-
chitectures against machine learning, which has been sug-
gested in [9], is to employ l individual Arb-PUFs in parallel,
each with k stages (i.e., each with bitlength k). The same
challenge C is applied to all of them, and their individual
outputs ti are XORed in order to produce a global response
tXOR. We denote such an architecture as l-XOR Arb-PUF.
A formal model for the XOR Arb-PUF can be derived as
follows. Making the convention ti ∈ {−1, 1} as done earlier,
it holds that tXOR =
i=1 ti. This leads with equation (5)
to a parametric model of an l-XOR Arb-PUF, where (cid:2)wi and
(cid:2)Φi denote the parameter and feature vector, respectively, for
the i-th Arb PUF:
(cid:3)l
l(cid:4)
l(cid:4)
tXOR =
i=1
= sgn
T
i (cid:2)Φi) = sgn(
T
i (cid:2)Φi)
(cid:2)w
(6)
i=1
= sgn( (cid:2)w
T
XOR(cid:2)ΦXOR)(7)
sgn( (cid:2)w
(cid:5) l(cid:6)
(cid:7) (cid:8)(cid:9) (cid:10)
T
(cid:2)w
i
i=1
(cid:11)
l(cid:6)
(cid:7) (cid:8)(cid:9) (cid:10)
(cid:2)Φi
i=1
(cid:2)wXOR
(cid:2)ΦXOR
Whereas (6) gives a non-linear decision boundary with l(k +
1) parameters, (7) deﬁnes a linear decision boundary by a
separating hyperplane (cid:2)wXOR which is of dimension (k + 1)l.
Lightweight Secure PUFs.
Another type of PUF, which we term Lightweight Secure
PUF or Lightweight PUF for short, has been introduced in
[10].
It is similar to the XOR Arb-PUF of the last para-
graph. At its heart are l individual standard Arb-PUFs
arranged in parallel, each with k stages (i.e., with bitlength
k), which produce l individual outputs r1, . . . , rl. These in-
dividual outputs are XORed to produce a multi-bit response
o1, ..., om of the Lightweight PUF, according to the formula
(cid:12)
oj =
r(j+s+i) mod l
for j = 1, . . . , m.
(8)
i=1,...,x
Thereby the values for m (the number of output bits of the
Lightweight PUF), x (the number of values rj that inﬂuence
each single output bit) and s (the circular shift in choosing
the x values rj) are variable design parameters.
1 ··· bl
1 ··· b2
1 · ·· b1
k, C2 = b2
k, . . . , Cl = bl
Another diﬀerence to the XOR Arb-PUFs lies in the l in-
puts C1 = b1
k which
are applied to the l individual Arb-PUFs. Contrary to XOR
Arb-PUFs, it does not hold that C1 = C2 = . . . = Cl = C,
but a more complicated input mapping that derives the in-
dividual inputs Ci from the global input C is applied. This
input mapping constitutes the most signiﬁcant diﬀerence be-
tween the Lightweight PUF and the XOR Arb PUF. We
refer the reader to [10] for further details.
In order to predict the whole output of the Lightweight
PUF, one can apply similar models and ML techniques as
in the last section to predict its single output bits oj . While
the probability to predict the full output of course decreases
exponentially in the misclassiﬁcation rate of a single bit,
the stability of the full output of the Lightweight PUF also
decreases exponentially in the same parameters. It therefore
Feed Forward Arbiter PUFs.
Feed Forward Arbiter PUFs (FF Arb-PUFs) were intro-
duced in [11] [12] [17] and further discussed in [19]. Some of
their multiplexers are not switched in dependence of an ex-
ternal challenge bit, but as a function of the delay diﬀerences
accumulated in earlier parts of the circuit. Additional ar-
biter components evaluate these delay diﬀerences, and their
output bit is fed into said multiplexers in a “feed-forward
loop” (FF-loop). We note that an FF Arb-PUF with k-bit
challenges C = b1 ··· bk (i.e., with bitlength k) and l loops
has s = k + l multiplexers or stages.
The described dependency makes natural architecture mod-
els of FF Arb-PUFs no longer diﬀerentiable. Consequently,
FF Arb-PUFs cannot be attacked generically with ML meth-
ods that require linearly separable or diﬀerentiable mod-
els (like SVMs or LR), even though such models can be
found in special cases, for example for small numbers of
non-overlapping loops.
The number of loops as well as the starting and end point
of the FF-loops are variable design parameters, and a host of
diﬀerent architectures for an FF Arb-PUF with a moderate
or even large number of loops are possible. The architec-
ture we investigated in this paper consists of loops that are
distributed at equal distances over the structure, and which
just overlap each other: If the starting point of loop m lies in
between stages n and n+1, then the previous loop m−1 has
its end point in the immediately following stage n + 1. This
seemed the natural and straightforward architectural choice;
future experiments will determine whether this is indeed the
optimal (i.e., most secure) architecture.
Ring Oscillator PUFs.
Ring Oscillator PUFs (RO-PUFs) were discussed in [9].
They are based on the inﬂuence of fabrication variations on
the frequency of several, identically designed ring oscillators.
While [9] describes the use of Ring Oscillator PUFs in the
context of Controlled PUFs and limited-count authentica-
tion, it is worth analyzing them as candidate Strong PUFs.
A RO-PUF consists of k oscillators, each of which has its
own, unique frequency caused by manufacturing variations.
The input of a RO-PUF consists of a tuple (i, j), which
selects two of the k oscillators. Their frequencies are com-
pared, and the output of the RO-PUF is “0” if the former
oscillates faster than the latter, and “1” else. A ring oscilla-
tor can be modeled in a straightforward fashion by a tuple
of frequencies (f1, . . . , fk). Its output on input (i, j) is “0” if
fi > fj , and “1” else.
2.4 CRP Generation, Prediction Error, and
Number of CRPs
Given a PUF-architecture that should be examined, the
challenge-response pairs (CRPs) that we used in our ML
experiments were generated in the following fashion: (i) The
delay values for this PUF architecture were chosen pseudo-
randomly according to a standard normal distribution. We
sometimes refer to this as choosing a certain PUF instance in
the paper. In the language of Equ. 3, it amounts to choosing
the entries wi pseudo-randomly. (ii) If a response of this
PUF instance to a given challenge is needed, it is calculated
by use of the delays selected in step (i), and by application
241ML
Bit
Prediction
CRPs
Training
Method Length
LR