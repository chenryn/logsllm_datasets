---
## Page 310
286
.Druid管理
数据源
·Docker-Druid：帮助用户通过Docker迅速搭建起Druid集群。网址：https://github.com/
·Druid-Metrics-Kafka：帮助用户收集并转发Druid指标数据到Kafka上，省去了自己搭
·Storm：Twitter开源的分布式实时计算系统，可以轻松读取不同数据源的数据，并将
·Kafka：分布式消息订阅发布系统，具备很强的容错性和可扩展性，已经成为了大数据
界面访问DataSource和Segment等相关信息。网址：http://druid.io/docs/latest/design/co-
Druid-Console：Druid项目中Coordinator组件自身所带的交互界面，用户可以通过该
建HTTP Server 和写Kafka Producer 的相关工作。网址：https://github.com/quantiply/
久且扩展性高的云存储。网址：https://aws.amazon.com/cn/s3。
S3：Amazon Simple Storage Service（Amazon S3）为开发人员和IT团队提供安全、耐
计算结果输出到不同的数据源或计算系统。网址：http://storm.apache.org。
http://hadoop.apache.org
HDFS：使用极其广泛的分布式文件，属于大名鼎鼎的Hadoop项目的一部分。网址：
相关领域事实上的标准组件。网址：http://kafka.apache.org。
Druid管理
ordinator.html.
druid-metrics-to-kafka.
数据管理
分析平台
数据源
Druid-C
Kafka
图11-1Druid数据分析生态系统
HDFS
Druid
Druid实时大数据分析原理与实践
53
Pivot
数据可视化
访问扩展
---
## Page 311
5
3.访问扩展
第11章Druid生态与展望
·Imply：由Druid主要创始人创建的公司，其提供的IAP平台包含了若干个基于Druid
分析平台
数据管理
·Calcite：Apache Calcite是分布式系统领域里的一个查询引擎。它能够连接各种数据
·PyDruid：提供了访问Druid的Python接口。网址：https://github.com/druid-io/pydruid。
·Tranqulity：Tranquility帮助用户发送实时数据流到Druid,并且能够操作数据文件的分
·Pulsar：由eBay开源的实时分析平台和流处理框架，具有高扩展性、高可用性和基于
·Druid-Spark-Batch：使用户能够通过Spark批处理任务完成Druid的数据索引工作。网
·PlyQL：基于Plywood项目，提供了访问Druid的SQL接口。网址：https://github.com/im-
·SQL4D：提供了访问Druid的SQL接口。网址：https://github.com/srikalyc/Sql4D。
的开源项目。网址：https://github.com/implydata。
Spark-Druid-OLAP：SparklineBIAccelerator是基于SparkSQLAPI实现的一个商务智
h址l:https://github.com/metamx/druid-spark-batch.
RDruid：提供了访问Druid的R接口。网址：https://github.com/druid-io/RDruid。
补充、变异和过滤等）。网址：https://github.com/pulsarIO。
事件处理语言，并且用户可以基于它自定义流事件，并最终完成对数据的加工（聚合、
度。网址l :https://github.com/SparklineData/spark-druid-olap。
能（Business Intelligence，BI）计算引擎。它能够在一个逻辑立方体或星型模型上快
并做综合处理。网址：https://calcite.apache.org。
plydata/plyqlo
/druid-io/tranquility.
区、复制等任务，使得用户能够灵活地完成Druid数据消费任务。网址：https://github.com
事件驱动等特征，能够实时收集与处理用户行为和业务事件。它提供了一种类SQL的
了Druid的适配器，使得用户可以同时通过Calcite查询Druid和其他数据源的数据，
源，并提供了标准的SQL语言、多种查询优化、OLAP和流处理等接口。Calcite提供
druid-io/docker-druid.
287
---
## Page 312
便形成了 IAP（Imply Analytics Platform），如图 11-2所示。
个开源组件，以帮助用户更好地基于Druid搭建自已的应用，而这几个开源组件加上Druid
动Druid这个开源项目持续发展的中坚力量。目前该公司也基于稳定的Druid版本提供了几
11.2.1
11.2
6.数据可视化
288
Imply公司是Druid创始人创建的公司，旨在提供主要基于Druid的技术服务，并成为推
·其他Druid相关开源项目，比如Druid-Metrics-Kafka（地址：https://github.com/quantiply
·Imply公司在github上的项目（地址：https://github.com/implydata），比如 Plywood
·druid.io在github上的项目（地址：https://github.com/druid-io），比如 Druid核心项
目前Druid生态系统中的开源项目主要分三类。
·Pivot：基于 Plywood实现的对 Druid 进行交互式数据探索的开源组件。与 Plywood、
·Caravel：来自AirBnB公司，与Pivot一样是一个开源的数据可视化平台（之前的名字
·Grafana-Plugins：作为优秀的前端展示组件，Grafana通过Plugins扩展了其功能。通过对
·MetaBase：帮助企业用户快捷实现商务智能与分析的软件，它提供了连接多个数据源
叫作Panoramix）。网址：https://github.com/airbnb/caravel。
/druid-metrics-to-kafka）等。
建立的Implyio所发展的开源项目。
Committer甚至PMC成员。
等都是Druid官方提供的项目，这些项目的积极贡献者则有可能成为druid.io社区的
目、Tranquility、Docker-Druid、Druid-Benchmark、Druid-Console、RDruid 和PyDruid
Druid生态系统资源
PlyQL一样由 Imply开源。网址：https://github.com/implydata/pivot。
IAP
/grafana-plugins/tree/master/datasources/druid。
Druid的支持插件，Grafana实现了对Druid的访问功能。网址：https:/github.com/grafana
Google BigQuery等。网址：https://github.com/metabase。
Druid实时大数据分析原理与实践
---
## Page 313
前还支持MySQL，并且以后会支持更多的数据源。
Node.js运行环境中。值得一提的是，Plywood的数据存储层不局限于支持Druid数据源，
问数据存储层数据及创建基于数据的应用。Plywood本质上是一个JavaScript库，可运行在
11.2.2
询服务器一类。
一步提高了Druid的可访问性，太大方便了用户对Druid的使用，因此IAP也将它们列为查
第11章Druid生态与展望
Plywood是介于数据存储层与数据访问层之间的一个代理层，旨在协助用户更容易地访
目前IAP主要提供的新开源组件有三个，即Plywood、PlyQL和 Pivot。它们从技术上进
·控制服务器（Master Server），包含Druid协调节点和统治节点。
·数据服务器（DataServer），包含Druid历史节点和中间管理者。
·查询服务器（Query Server），包含Druid查询节点、Pivot和 PlyQL。
IAP将Druid集群的所有节点分为三类，如图11-3所示。
Plywood
Streams
Hadoop
Kafka
Metadata
Your
Store
MasterServer
图11-3IAP集群节点分类
→
图11-2IAP
Data
Server
←→
PlyQL
PIyQL
Pivot
Application
Druid Broker
Plywood
289
---
## Page 314
一般来说，使用Plywood分为以下几个步骤。
使用Plywood。现在为大家举一个Implyio官网上的例子，以便对Plywood有更感性的认识。
External.fromJS({
言之，这是一个通用的数据源接人模块。下面是一个外部访问模块定义的例子。
询执行计划。正如上文所提到的，目前支持的数据访问层除了Druid外，还有MySQL。总而
varex=ply（)
中返回，这样无疑会大大降低Druid数据访问层的复杂度。下面是一个Plywood原语的例子。
语句能够被转换为多条数据库查询语句，并且最后会将查询结果组装在一个嵌套的数据结构
Hadley Wickham的 split-apply-combine原则及可视化库D3的API设计。
290
C
requester：druidRequester//负责完成Druid请求的实例
timeAttribute:'time',
dataSource:wikipedia',
engine:'druid'
apply('Pages',
apply('TotalAdded',
apply('Count’，$('wiki').count())
可以通过 npm轻松地完成 Plywood 的安装：“npm install plywood"，也可以在浏览器中
主要用来定义数据访问层的种类和基本连接信息等参数，并负责为具体的数据源生成查
$(’wiki').split(*$page'，‘Page')
首先，像其他产品或项目一样，在使用某个库或其依赖之前需要先将它们引人到程序中。
为方便使用Plywood提供了一些帮助函数。
该表达式语言是领域专用语言（Domain SpecicLanguage，DSL），在设计方面借鉴了
Plywood主要由三个大的模块组成。
（3）帮助模块（Helper）
（2）外部访问模块（External）
apply('Count'，$(‘wiki").count())
（1）Plywood表达式语言（expression language），简称plywood（小写字母p开头）
.limit(6)
sort（‘$Count'，‘descending')
$wiki.sum($added)')
// Druid中代表时间属性的列名
//Druid中DataSource的名字
Druid实时大数据分析原理与实践
一条Plywood原生
---
## Page 315
varex=ply()
var context={
在其中自定义变量等。
3,druidRequester);
varwikiDataset=External.fromJS（{
var druidRequester =druidRequesterFactory({
Requester。
varExternal=plywood.External;
发生；$O语句则负责创建一个Plywood原语的引用。
var $=plywood.$;
var ply= plywood.ply;
var plywood =require('plywood’);
第11章
//指定External，以及作用于该External的基于时间和语言的过滤器
seventy:70
wiki:wikiDataset
engine:'druid',
host：192.168.60.100:8082′//定义用户自己的Druid路径
context:
timeAttribute:'time',
dataSource:'wikipedia'
timeout:10000 // Druid context
此时，程序便可以执行具体的查询语句了。
为了方便在执行环境中更好地定义查询语句，我们还可以创建执行上下文（context)，并
通过JSON格式的定义来创建数据集实例。
接下来，
在访问Druid数据源之前，需要先得到对应的External和druidRequesterFactory实例。
其中plyO方法负责创建一个空的数据集，之后许多Plywood的操作都会基于该数据集
Druid生态与展望
便可以通过druidRequesterFactory实例得到访问Druid数据源所必需的druid-
//Druid中代表时间属性的列名
//Druid的dataSource
291
---
## Page 316
1).done(）;
ex.compute(context).then(function(data){
292
console.log(JsoN.stringify(data.toJS(),null, 2));
//将数据转换成可读的格式并记录到日志中
apply('70*，$('seventy'));
//引用在context中定义的变量seventy
.apply(*TotalAdded',‘$wiki.sum($added)*);
//计算“added”属性列的总和
apply(‘Count'，$('wiki').count(）)
//计算数量
apply("wiki",
1).and($('channel').is('en')))
$(wiki').filter($("time"）.in（{
·用户创建基于网络和数据驱动的应用，并且后台服务运行于Node.js运行环境中，这
鉴于Plywood的设计理念和工程特性，
"Count": 113240
"TotalAdded":32553107,
“70":70
得到查询结果。本例的查询结果是只包含一条数据的数据集。
end:newDate("2015-09-13T00:00:00Z")
start: new Date("2015-09-12T00:00:00Z"),
Plywood组件则会将接收到的Plywood原语的查询请求翻译成一系列数据访问层的查
于Plywood原语的查询请求，并随后接收来自后者的返回结果；Node.js运行环境中的
时，网络应用层中的Plywood组件可以向Node.js运行环境中的Plywood组件发送基
时可以在网络应用层和Node.js运行环境中均使用Plywood作为数据访问代理。此
，通常使用Plywood访问数据存储层有多种方法。
Druid实时大数据分析原理与实践
---
## Page 317
第11章
·应用并没有使用Nodejs运行环境，
佳实践的模式，起码不符合现代系统分层的主流架构思想，但又不是所有应用的后端
当然，在很多场合中，在网络应用层直接通过Plywood访问数据存储层并不是符合最
于 Node.js的架构模式，如图11-6所示。本章后面介绍的服务模式的 PlyQL 组件便是
都会运行在Nodejs运行环境中，因此这就形成了既基于两层Plywood组件又不依赖
据存储层，如图11-5所示。
采用这种架构。
种架构。
询语言，
Druid生态与展望
图11-6
图11-4
并对结果进行封装，
既基于两层Plywood组件又不依赖于Nodejs的架构示意图
图11-5
DB Queries
基于Plywood和使用Node.js的网络应用架构示意图
DBQuenes
直接通过Plywood组件访问数据存储层
Backend (not node.js)
Backend (not node.js)
Backend (node.js)
如图11-4所示。本章后面介绍的Pivot组件便是采用这
(lewaloe Exrssins
DBQuerie
八
Webapp
Webapp
Webapp
Plywood
PiywoodR
Plywood
etc.
293
---
## Page 318
NoSQL数据库编写类似的 SQL访问接口，比如基于Hadoop HDFS文件系统和 MapReduce 计
口。正因如此，在NoSQL数据库日渐大行其道的当下，软件工程师依然乐此不疲地为不同的
库作为引擎已经得到了广泛接受，但是从它们所提供的访问接口来看依然存在诸多问题。
了自己的价值，因此在这些解决方案中基本上替代了传统数据库。然而，即使NoSQL数据
不高的场景中。目前NoSQL数据库已经成为各类解决方案的首选，并且以出色的表现证明
决方案中都已经占有了一席之地，特别是在大数据处理领域、对事务等传统数据库特性要求
OnlySQL）数据库通常泛指非传统关系型数据库，一般分为四大类。
熟的传统关系型数据库外，还有很多NoSQL数据库不断涌现并茁壮成长起来。NoSQL（Not
11.2.3
使用何种方式通过Plywood组件简化Druid数据访问应用。
294
·NoSQL数据库提供的访问接口不同于传统的SQL，因此软件工程师学习NoSQL数据
时至今日，NoSQL数据库早已不是停留在论文里的纯概念或“黑科技”，而是在许多解
·键值（Key-Value）存储数据库。通过键值对的方式组织数据格式，其特点是上手简单，
当今的数据库软件世界正处于“百花齐放，百家争鸣”的时代，因为除了有已经非常成
显而易见，直截了当地解决上述问题的方法就是为这些NoSQL数据库提供SQL访问接
·不同的NoSQL数据库提供的访问接口大相径庭，因此在不同的数据引擎之间进行数
·图形（Graph）数据库。数据格式基于图形模型设计，适用于社交网络和关系图谱等
以上都是对使用Plywood组件的不同架构的介绍，用户可以根据自己的现实需求来决定
·文档型数据库。本质上属于特殊版的键值存储数据库，因为它不仅有键的概念，而且
·列存储数据库。数据行中仍有键的概念，但是各个属性列被分别存放在不同的数据文
据迁移成本高昂。
缝集成。
库需要额外的成本，并且已有的数据应用难以与新的NoSQL数据库引擎直接进行无
应用场景，其特点是方便基于它进行图计算。代表是Neo4J和Titan。
代表是MongoDB、CouchDB以及国内已经开源的SequoiaDB。
它的值可以是半结构化、嵌套格式的文档结构，其特点是结构灵活，查询效率较高。
者认为Druid也能被归为本类数据库。
件中，其特点是适合在分布式系统中处理海量数据。代表是HBase和Cassandra。笔
部署容易。代表是Redis。
PlyQL
Druid实时大数据分析原理与实践
---
## Page 319
命令实例。
过网络访问该监听端口来使用PlyQL所支持的SQL语法了。以下是启动PlyQL监听端口的
过“-json-server”参数启动PlyQL监听端口———这样就可以从其他未安装PlyQL的机器上通
对其使用方法有更直观的认识。
来我们依然借用Implyio官网上的例子来介绍这两类访问方法，并且可以通过该介绍让大家
plyql-h 192.168.60.100:8082-qSELECT MAX(__time)ASmaxTime FROM wikipedia
在命令中指明要访问的查询节点主机名和端口，以及查询语句。
安装完成以后，就可以通过plyql命令对其功能进行调用了。其命令也比较简单，一般需要
发当中的语法如下。
从库往外查询一类，比如SELECT、DESCRIBE和SHOWTABLES。目前暂时不支持但正在开
行工具中提供类SQL访问接口。在诞生之日，PIyQL便受到了广泛好评。
来说，为其提供一个类SQL访问接口同样具有积极的意义，所以 PlyQL组件因此产生了。
算框架的 Hive组件，以及基于HBase的Phoenix项目等。对于同样是NoSQL数据库的Druid
第11章Druid生态与展望
SQL-over-HTTP方法使得用户除了可以直接通过plyql命令执行SQL命令外，还可以通