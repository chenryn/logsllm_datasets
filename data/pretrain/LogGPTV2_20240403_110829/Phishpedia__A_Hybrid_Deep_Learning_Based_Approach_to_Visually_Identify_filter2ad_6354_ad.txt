way using Triplet loss. In this experiment, we use Triplet loss
function [65] to train the model. For Op4, we replace the
Siamese model with a standard perceptual hashing algorithm
implemented in [8].
5.5.2 Results
Table 4 shows our experimental results on the different tech-
nical options. Overall, we observe that Yolov3 has a good
3802    30th USENIX Security Symposium
USENIX Association
0.70.80.90.80.90.70.80.90.70.80.90.60.70.80.910.60.70.80.91ResNet GrayscaleResNet RGBResNetV2 GrayscaleResNetV2 RGBTable 4: Evaluation of alternative technical options
Detection Rate Model
Technical Option
Identi-
ﬁcation
Rate
99.68% 99.13% 88.67% 0.19
Precision Recall
Prediction
Time (s)
96.59% 96.33% 63.92% 0.20
99.63% 99.29% 81.07% 0.19
90.89% 88.61% 78.57% 0.19
24.58% 59.03% 79.37% 0.10
Option
Base
Op1
Op2
Op3
Op4
Identity Logo
Recognition
Faster
-RCNN
Yolov3
Faster
-RCNN
Faster
-RCNN
Faster
-RCNN
Brand
Recognition
two-stage
training
two-stage
training
one-stage
training
non-transfer
learning
perceptual
hashing
identiﬁcation accuracy although it misses a lot of phishing
webpages. Moreover, we see that two-stage training for the
Siamese model improves the recall in comparison to one-
stage training, and training Siamese model in a conventional
way has adverse effect on the overall performance. Finally, we
observe that perceptual hashing algorithm is not as competent
as the Siamese model since it is less ﬂexible to minor changes
in logos. Thus, we conclude that Phishpedia employs a sound
solution in terms of logo recognition and logo comparison.
5.6 Adversarial defense (RQ5)
5.6.1 Experiment on Gradient-based Technique
In this set of experiments, we apply state-of-the-art adversarial
attacks on both the object detection model and the Siamese
model, with two speciﬁc goals: (i) to analyze the efﬁcacy of
Phishpedia in defending against adversarial attacks, and (ii) to
evaluate the effect of adversarial defense technique on the
performance (in terms of accuracy) of Phishpedia.
We use DAG adversarial attack [78] to evaluate the robust-
ness of our object detection model. We apply DAG on a test
set of around 1,600 screenshots (as in Section 5.3.1). We se-
lect four adversarial attacks to evaluate the robustness of our
Siamese model: DeepFool [48], i-FGSM [25], i-StepLL [34],
and JSMA [24]. We apply these adversarial attacks on lo-
gos labelled in 1,000 screenshots as in Section 5.3.2, to see
whether the Siamese model can still accurately match them
against the logos in a target brand list. For each adversarial
attack, we set the attack iteration limit as 100. Moreover, we
take the attack learning rate e of 0:5 for DAG attack, and 0:05
for i-FGSM, and i-StepLL attack (note, DeepFool and JSMA
use no learning rate).
Table 5 reports the effect of the adversarial attacks on the
object detection model; the prediction accuracy of both the
original model and the transformed model (i.e., after the ap-
plication of the defense technique described in Section 3.3)
are shown. Similarly, Table 6 reports results of adversarial
attacks on the Siamese model. As for the logo match accuracy
in Table 6, we have N (=1,000) logos fed into the Siamese
model. If k logos are matched to a logo variant of its correct
brand in the target list, the logo match accuracy is computed
as k
N . We observe that (i) our defense technique effectively
defends against existing state-of-the-art adversarial attacks;
Table 5: Defense effect and model accuracy for adversarial
attacks on the object detection model
Defense
Original
Transformed
Accuracy (mAP)
without Attack
Accuracy (mAP) after
Applying Adversarial Attack (DAG)
59.6
58.9
12.9 (-46.7)
58.7 (-0.02)
Table 6: Defense effect and model accuracy for adversarial
attacks on the Siamese model
Defense
Original
Transformed
Logo Match Accuracy
without Attack
93.5%
93.5%
Logo Match Accuracy After
Applying Adversarial Attacks
i-FGSM i-StepLL JSMA DeepFool
0.0%
93.5%
0.1%
0.1%
93.5% 93.5% 93.5%
80.9%
and (ii) the accuracy of Phishpedia is well preserved and not
affected by the defense technique.
5.6.2 Experiment with Gradient-recovering Technique
While our gradient-masking based approach is effective to
popular gradient-based attacks, some adversarial attacks are
designed to recover the gradients to facilitate the attack. In this
experiment, we adopt a state-of-the-art gradient-recovering
technique, BPDA (Backward Pass Differentiable Approxi-
mation) [12], to attack Phishpedia. BDPA assumes that the
gradient-masked layers in the neural network are known; it
then recovers the gradient by its gradient estimation technique.
Assuming the gradient-masking layers in our model are
known by an attacker, we carry out attacks on Phishpedia’s
Siamese model with different numbers of masked layers un-
der the default settings of BPDA. The results are presented in
Table 7, where we compare the model accuracy before and
after the attacks. BPDA is seen to be effective for a small
number of masked layers, but less so for a large number of
masked layers. With increasing estimated layers, BPDA intro-
duces more bias in the gradients it recovers. As a result, the
adversarial attack is conducted in a biased direction when the
number of masked layers increases.
6 Phishing discovery in the wild (RQ6)
We also design a phishing discovery experiment to compare
Phishpedia with ﬁve phishing detection/identiﬁcation solu-
tions in literature, on their effectiveness in detecting new
phishing pages in the wild (i.e., the Internet).
6.1 CertStream Service
We use CertStream service [2] which contains new domains
registered from Certiﬁcate Transparency Log Network. Cer-
tiﬁcate Transparency is usually used to openly audit and mon-
itor the event where a new domain is issued a TLS/SSL certiﬁ-
cate. In this experimental study, we use this service to retrieve
emerging new domains.
USENIX Association
30th USENIX Security Symposium    3803
Table 7: The performance of BPDA on our Siamese model
with different number of masked layers
#Masked Layers
3
7
13
17 (all)
Accuracy before
Accuracy after attack
93.5%
93.5%
93.6%
93.6%
64.6%
90.5%
92.3%
92.6%
6.2 Phishing discovery experiment
By integrating the reported emerging new domains and a
phishing detector or identiﬁer, we construct a phishing locator.
We apply Phishpedia to scan and identify phishing webpages
from the reported emerging domains every day. In this experi-
ment, (as detailed in the next section) we select ﬁve known
approaches in the literature to evaluate how many real-world
phishing pages can they report and how precise their reported
phishing pages are. We ran all the solutions for 30 days (from
Sep, 10 to Oct 9, 2020). During the experiments, we record
the landing URL and screenshot of each URL for postmortem
analyses. For each solution, we use the conﬁguration corre-
sponding to the best results in Section 5.2.3; this results in
each solution reporting a different number of phishing pages.
Among the reported phishing URLs, we picked top reported
phishing webpages (that is, the ones predicted with highest
probability) for manually investigating the ground truth. The
number of samples picked for each solution we evaluated is
given in Table 9. Each reported phishing webpage is eval-
uated by two examiners independently. For those phishing
webpages upon which they did not agree, we let them discuss
and come to a consensus. Then, we use VirusTotal [9] to check
whether it reports the same results. VirusTotal is equipped
with more than 70 engines for malicious webpage detection
(e.g., Google Safebrowsing). If a real phishing webpage is
reported by a speciﬁc solution (i.e., one of the ﬁve baselines
or Phishpedia), but none of the VirusTotal engines report it
suspicious on the same day, we consider that the solution
discovered a zero-day phishing webpage.
6.3 Baselines
We select the baselines covering phishing detectors and identi-
ﬁers, as shown in Table 8. URLNet [36] and StackModel [80]
are the two most recent techniques reported to outperform
other state-of-the-art detection techniques. Besides, they work
on different inputs: URLNet uses only URL string as input,
where as StackModel predicts on URL and HTML content
of a given page. Based on our discussion with various in-
dustry players, we are also aware that solutions similar to the
above are being considered by security vendors. For the exper-
iments here, we train both models with our dataset of phishing
(from OpenPhish) and benign (from Alexa) webpages (see
Section 5.1). Furthermore, we select PhishCatcher [5] as an-
other baseline candidate, as it is an open-source version of
the commercial product PhishFinder [6] searching for phish-
Table 8: Solutions for searching new phishing pages
Tool
PhishCatcher
Category
Deteciton
Input
URL
Description
A rule-based phishing de-
tector to compare how sim-
ilar a new domain (e.g.,
foceb00k.com) is with an
existing legitimate domain
(e.g., facebook.com).
A CNN-based approach
that predicts on a given
URL.
A tree-model consisting
of multiple layers of ran-
dom forest which takes
input
features extracted
from URL and HTML
code.
See Section I.
See Section I.
See Section III.
URLNet
Deteciton
URL
StackModel
Deteciton
URL+HTML
EMD
Phishzoo
Phishpeida
Identiﬁcation
Identiﬁcation
Identiﬁcation
URL+Screenshot
URL+Screenshot
URL+Screenshot
Table 9: Phishing discovery results
#Real
Tool
Category
Phishing
PhishCatcher Deteciton
URLNet
Deteciton
StackModel Deteciton
EMD
Phishzoo
Phishpeida
#Reported
Phishing
1,421,323
422,093
327,894
299,082
9,127
1,820
Identiﬁcation
Identiﬁcation
Identiﬁcation
1000
1000
1000
1000
1000
1000
#Top Ranked
Samples
5
13
9
3