We study how end-to-end round-trip time varies for the duration
of the measurement. We use two measures of variability: standard
deviation (STD) and interquartile range (IQR). Standard deviation
represents the variability of all data points equally, while interquar-
tile range—the difference between the 75th and 25th percentiles—
measures the variability of the 50% of points around the median.
Figure 3 shows the cumulative distributions of STD and IQR for
the three data sets with small granularities. Each point on the plots
is associated with a pair of nodes. We make the following observa-
tions:
• All distributions have long tails; each data set has a few
pairs of nodes that exhibit high variations in latency. 5%
of the pairs in K200-1000pairs-5min and K200-allpairs-3h
and 12% of the pairs in K200-allpairs-1h have standard de-
viations of more than 100ms.
• Second, in all data sets, less than 10% of the pairs have in-
terquartile ranges of more than 40ms. Combined with the
previous observation, this implies that the variability of the
latency comes mainly from the more extreme values, rather
than values closer to the median.
• Finally, the pairs in K200-allpairs-1h have higher standard
deviations than the pairs in K200-allpairs-3h. This suggests
that variability decreases with an increase in sampling inter-
val. We conﬁrm that this is true in Section 4.2.
4.2 Causes of Variations
Determining the exact cause that leads to each latency change is
difﬁcult. Instead, we classify the possible causes of variation into
three categories:
• Load-based causes refer to events such as queuing delay at
the routers or transient load at the DNS servers involved in
179)
s
m
(
y
c
n
e
t
a
l
)
s
m
(
y
c
n
e
t
a
l
 500
 400
 300
 200
 100
 500
 0
 400
 300
 200
 100
 0
2-hop latency
1-hop latency
final latency
 0
 50
 100
 150
 200
 250
time (x 5min)
)
s
m
(
y
c
n
e
t
a
l
)
s
m
(
y
c
n
e
t
a
l
 500
 400
 300
 200
 100
 500
 0
 400
 300
 200
 100
 0
2-hop latency
1-hop latency
final latency
 0
 50
 100
 150
 200
 250
time (x 5min)
Figure 4: Examples of latency variations between pairs of nodes: left) the latency between 66.189.0.29 and 200.31.70.18 exhibits
variations due to load; because both 1-hop and 2-hop latencies have similar variations, we conclude that it is either network load
from S to A or DNS load on A; right) the latency between 216.61.143.252 and 147.136.250.51 varies during the duration of the
measurement; besides the occasional spikes given by load, there are long periods of time (from 1h to 8h) when the latency changes
signiﬁcantly (by 70ms)
measurements. They are likely to manifest as short-duration
spikes or oscillations [16].
• Routing-based causes are path changes in the Internet deter-
mined by link or node failures or by routing changes. Al-
though routes can also oscillate, their oscillations tend to
have longer durations [17]. Thus, path changes are more
likely to trigger longer-term changes in latencies.
• Measurement-based causes depend on the parameters of the
measurement process. We consider two potential sources of
variation:
the sampling interval and the time at which we
measure each sample. Since we limited the number of pairs
probed per sampling interval to avoid unnecessarily loading
DNS servers, we do not consider load on name servers a
measurement-based cause of variation.
Routing-based and Load-based causes.
We focus ﬁrst on the routing-based and load-based causes of
variation. We select two pairs from the K200-1000pairs-5min data
set and show their latency distributions in Figure 4. We deﬁne the
latency from the source of the measurement to the ﬁrst DNS server
(nsA in Figure 2) as the 1-hop latency, and the latency from the
source to nsB through nsA as the 2-hop latency. The ﬁnal latency
is obtained by subtracting the two values. We show the distribu-
tions of 1-hop and 2-hop latencies in the top part of Figure 4. Every
point on the plot is associated with one measurement. We make the
following observations:
• the variation of latency in Figure 4(left) exhibits many short-
duration oscillations for the ﬁrst 350 minutes; this is most
likely a load-based event. After 350 minutes, the latency
stops oscillating.
• the variation of latency in Figure 4(right) shows fewer os-
cillations and the latency tends to stabilize around two val-
ues (30ms and 100ms) for periods ranging from 1 hour to 12
hours; this behavior suggests a routing-based event.
• in Figure 4(left), the variations of the ﬁnal, 1-hop and 2-hop
latencies follow the same trends; in Figure 4(right), the 1-hop
latencies remain constant over the ﬁrst 200 intervals, while
the 2-hop latencies change; this indicates the location of the
event that causes the variation: a spike that appears on the
2-hop latency distribution but not on the 1-hop latency distri-
bution must be caused by an event that occurred on the path
between the two DNS servers.
We compute the sample correlation for the 1-hop and 2-hop la-
tencies for each pair in K200-allpairs-1h. We use this data set
because it has the smallest time granularity of the ones that con-
tain all-pair latencies and because it exhibits the greatest variability.
Figure 5(left) shows that there is less correlation among the pairs
with the top 5% interquartile ranges—these are the more variable
pairs. This indicates that the source of high variance typically lies
between the two DNS servers probed by King. It also suggests that
the source of the measurement has less impact on the variability of
the data, as we show in Section 4.2.
We also compute the average absolute difference between con-
secutive measurements for each pair in K200-allpairs-1h. The av-
erage consecutive difference estimates how a prior measurement
predicts a future one. A low average consecutive difference indi-
cates that the data varies with low frequency (and the variation is
likely due to a routing-based cause), while a high average consec-
utive difference indicates that the data varies with high frequency
(possibly due to a load-based cause). Figure 5(right) shows that, for
the pairs in the top 5% among interquartile ranges, the average con-
secutive difference is larger than for pairs in general. Indeed, we
would expect that the more variable pairs have higher average con-
secutive differences. Less than 20% of those high-variance pairs
have at most 30 ms of average consecutive differences; in those
cases the cause of the variance is most likely due to path changes.
For the remaining pairs, the variance changes rapidly; the source of
the variance in those cases is most likely due to loaded DNS servers
or high queuing delay at routers.
Measurement-based causes of variation.
Another source of variation may be the process of measurement
itself. Next we verify whether the sampling interval or the time
when we measure each sample affect the variability of the data.
We split the K200-1000pairs-5min data set into k more coarsely
grained subsets. In each subset, measurements for the same pair of
180F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
-0.2
all pairs
top 5% IQR
 0
 0.2
 0.4
 0.6
 0.8
 1
Sample Correlation
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
 1
all pairs
top 5% IQR
 10
 100
Average Consecutive Difference
Figure 5: Cumulative distributions of left) sample correlation
between 1-hop and 2-hop latencies, and right) average dif-
ference between consecutive latency measurements, in K200-
allpairs-1h, for all pairs and for the top 5% of pairs when or-
dered by IQR.
l
s
e
p
i
r
t
f
o
%
 7
 6
 5
 4
 3
 2
 1
 0
using individual latencies
using medians
 0
 5  10  15  20  25  30  35  40
Time (x 1h)
D
T
S
n
a
d
e
M
i
 4
 3.5
 3
K200-1000pairs-5min
 2.5
4 subsets
 2
16 subsets
 1.5
64 subsets
 1
R
Q
i
I
n
a
d
e
M
K200-1000pairs-5min
4 subsets
16 subsets
64 subsets
 4
 3.5
 3
 2.5
 2
 1.5
 1
Subset
Subset
Figure 6: Median left) standard deviations and right) in-
terquartile ranges for the pairs in each subset in the K200-
1000pairs-5min data set. Each point represents the median
value for one of the subsets. As the sampling interval decreases,
so does the median standard deviation.
nodes are collected at k × 5 minute intervals 1. For example, when
using k = 4 subsets, subset i contains all measurements taken at
sample intervals i, i + 4, i + 8 and so on. Dividing the original
data set in this way allows us to obtain k different measurement
sets with k × 5 minute sampling intervals. All subsets appear to
start at ﬁve minute intervals over the course of k × 5 minutes.
We compute the standard deviation (STD) and the interquartile
range (IQR) for all pairs of nodes in each of the subsets, for k = 1
(the entire data set), k = 4, k = 16, and k = 64. Figure 6 shows
the median STD and IQR. While the median STD decreases when
using sparser samples, the median IQR remains approximately the
same. We would expect that by sampling less often we are less
likely to measure unusually high values. However, such values are
always above the 75th percentile of the data, so they do not signiﬁ-
cantly affect the IQR. Also, the median STD and IQR do not change
signiﬁcantly between subsets, indicating that the time at which the
measurement starts does not affect latency variance.
This analysis highlights a trade-off between sampling rate and