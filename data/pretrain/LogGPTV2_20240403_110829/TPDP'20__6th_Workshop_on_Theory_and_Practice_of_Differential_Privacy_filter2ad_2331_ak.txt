εn
d log(1/δ)
εn
(cid:19)1/2
(cid:19)1/2
log(1/δ)
εn
Qmeans
Qconj
t
, t (cid:28) d
Qconj
Theorem 5.13 (packing lower bound [58, 10]). Let C ⊆ Xn be a collection of datasets all at
Hamming distance at most m from some ﬁxed dataset x0 ∈ Xn, and let {Gx}x∈C be a collection of
disjoint subsets of Y. If there is an (ε, δ)-diﬀerentially private mechanism M : Xn → Y such that
Pr[M(x) ∈ Gx] ≥ p for every x ∈ C, then
1
|C| ≥ p · e−m·ε − δ.
In particular, when p = 1/2 and δ = 0, we have |C| ≤ 2 · emε.
Proof. By Group Privacy (Lemma 2.2), for every x ∈ C, we have
Pr[M(x0) ∈ Gx] ≥ p · e−mε − mδ.
Since the sets Gx are disjoint, we have
1 ≥ Pr
(cid:34)
M(x0) ∈ (cid:91)
(cid:88)
x∈C
(cid:35)
Gx
Pr [M(x0) ∈ Gx]
=
≥ |C| · (p · e−mε − mδ).
x∈C
eεn (cid:28) |X|n datasets on which a diﬀerentially private mechanism’s behavior is really distinct.
Note that when δ = 0, the theorem (setting m = n) says that we can only have roughly
But when δ > 0, note that the theorem says nothing when m > ln(1/δ)/ε (because p · e−mε −
mδ  log(1/δ).
Proof. For a dataset x ∈ Xn, let Gx be the closed (cid:96)∞ ball of radius α around the vector (q(x))q∈Q.
The assumption about M implies that for every dataset x ∈ Xn, we have Pr[M(x) ∈ Gx] ≥ 1/2.
We will now construct a set C of |X| datasets for which the Gx’s are disjoint. Speciﬁcally, for
each w ∈ X, let x(w) ∈ Xn be the dataset whose ﬁrst m = (cid:98)2αn + 1(cid:99) rows are all equal to w,
and whose remaining n − m rows are all equal to w0 for a ﬁxed element w0 ∈ X. We’ll take
C = {x(w) : w ∈ X}. To see that Gx(w) and Gx(w(cid:48)) are disjoint for every w (cid:54)= w(cid:48), let q be a query
such that q(w) (cid:54)= q(w(cid:48)) (which exists by hypothesis). Then |q(x(w)) − q(x(w(cid:48)))| = m/n > 2α. The
datasets in C are all at distance at most m from the dataset x(w0). Thus by Theorem 5.13, we
deduce that
1
|X| ≥ e−εm/2 − δ,
which implies that either δ ≥ e−εm/4, in which case α ≥ Ω(ln(1/δ)/εn), or 1/|X| ≥ e−εm/4, in
which case α ≥ Ω(log |X|/εn).
Now, let’s see how the Packing Lower Bound can be applied to arbitrary sets Q of counting
queries to obtain tight bounds on the sample complexity — how large n needs to be achieve an arbi-
trarily small, but constant error α — with the matching upper bound coming from an instantiation
of the exponential mechanism.
To formalize this, let X be our data universe, and consider the |X| vectors in RQ corresponding
to the tuples of answers that can be achieved on individual elements on X. That is for each
w ∈ X, let aw = (q(w))q∈Q. Now, following Hardt and Talwar [58], we consider the convex body
43
K = ConvexHull({aw : w ∈ X}) that is the convex hull of all of these vectors. Notice that for any
dataset x ∈ X, the tuple of answers on x is ax = (1/n)(cid:80)n
i=1 axi ∈ K.
Deﬁne the packing number Pα(K) to be the largest number of points we can ﬁt in K such that
all the pairwise (cid:96)∞ distances are greater than α. (That is, the closed (cid:96)∞ balls of radius α/2 centered
at the points are disjoint. But we don’t require that the balls themselves are entirely contained
within K; this notion of packing is sometimes referred to as metric entropy.)
Theorem 5.15 (Packing Characterization of Sample Complexity).
1. For all suﬃciently small
β > 0, there is an α > 0 such that the following holds for all sets Q = {q : X → {0, 1}} of
counting queries, n ∈ N and ε ∈ (0, 1): If M : Xn → RQ is an (ε, 0)-diﬀerentially private
mechanism that, on every dataset x ∈ Xn answers all of the queries in Q to within error at
most α with high probability, then:
n ≥ log(Pβ(K))
βε
,
where K is the convex body corresponding to Q as deﬁned above.
2. For every α > 0, there is a β > 0 such that the following holds for all sets Q = {q : X → {0, 1}}
of counting queries, n ∈ N and ε ∈ (0, 1): If
n ≥ log(Pβ(K))
βε
,
where K is the convex body corresponding to Q, then there is an (ε, 0)-diﬀerentially private
mechanism that, on every dataset x ∈ Xn answers all of the queries in Q to within error at
most α with high probability.
Thus, to achieve error α = o(1), it is necessary and suﬃcient to have n = ω(Po(1)(K)). The
above theorem is based on ideas from [92, Lecture 6].6
Proof.
1. Let M = Pβ(K) and let a1, . . . , aM be the corresponding points in K, all at pairwise
(cid:96)∞ distance greater than β.
Our ﬁrst step will be to approximate the points aj by points ay(j) for datasets of size m = βn/2,
so that (cid:107)aj − ay(j)(cid:107)∞ ≤ β/3. The deﬁnition of K tells us that for each point aj there is a
distribution Dj on X such that aj = Ew←Dj [aw], where aw = (q(w))q∈Q is the vertex of
K corresponding to the answers on w ∈ X. We will probabilistically construct the dataset
y(j) ∈ Xm by randomly sampling m rows according to Dj. As mentioned in the proof of
Theorem 4.1, if m ≥ O(VC(Q) · log(1/β)/β2), then standard results in learning theory show
that with high probability we have (cid:107)aj − ay(j)(cid:107)∞ ≤ β/3, as desired. By Proposition 5.11 and
Theorem 5.8, we know that n ≥ Ω(VC(Q)/α) (for suﬃciently small α), and thus m = βn/2 ≥
Ω(β VC(Q)/α). Thus we can take α small enough (depending on β), to ensure that we have
m ≥ O(VC(Q) · log(1/β)/β2) as needed.
6In [92, Lecture 6], the bounds are stated in terms of the discrete set of points Kn = {ax : x ∈ Xn} rather
than the convex body K. An advantage of Theorem 5.15 is that the set K does not depend on n (since we are
trying to characterize n in terms of it), but the formulation in [92] has the advantage of applying even to arbitrary
low-sensitivity families (rather than just counting or statistical queries).
44
Given the datasets y(j) ∈ Xm, observe that the points ay(j) are at pairwise distance greater
than β − 2β/3 = β/3 (by triangle inequality). Now we construct datasets x(j) ∈ Xn of size n
by padding the y(j)’s with n − m copies of a ﬁxed row w from X; the points ax(j) now are at
pairwise distance greater than (m/n) · (β/3) = β2/6. So if for every x ∈ Xn, we take the set
Gx to be a closed (cid:96)∞ ball of radius β2/12, then the sets {G
x(j)}1≤j≤M are disjoint. Moreover
we can take α ≤ β2/12, and then the α-accuracy hypothesis on M says that for every x ∈ Xn,
Pr[M(x) ∈ Gx] ≥ 1/2.
So all the conditions of Theorem 5.13 are satisﬁed (with p = 1/2, δ = 0) and we obtain
2(log e)·(βn/2)·ε = em·ε ≥ M
2
≥ M (log e)/2,
where the latter inequality uses M ≥ 1/(2β) ≥ 23.6 ≥ 21/(1−(log e)/2) for any Q containing a
nonconstant query and suﬃciently small β. This implies that n ≥ log(Pβ(K)/βε, as desired.
2. Let M = Pβ(K), and let a1, . . . , aM be the corresponding points in K all at pairwise distance
greater than β from each other. By the maximality of the packing, every point in K is at
(cid:96)∞ distance at most β from at least one of the ai’s (otherwise we could add the point to
obtain a larger packing).7 On a dataset x ∈ Xn, we will use the exponential mechanism
(Proposition 4.2) to sample a point aj that is close to ax in (cid:96)∞ distance, in a manner similar
to Theorem 4.1. Speciﬁcally,
M(x) : output aj with probability ∝ e−εn·(cid:107)aj−ax(cid:107)∞.
Indeed, Theorem 4.1 is a special case of this mechanism where we take the aj’s to be the answer
vectors ay that we get from small datasets y ∈ Xm. By Proposition 4.2 (with score(x, aj) =
−(cid:107)aj − ax(cid:107)∞), this mechanism is 2ε-diﬀerentially private, and achieves error at most β +
O(log M )/εn with high probability. Thus, if n ≥ (log M )/β(2ε) and β is suﬃciently small
(depending on α), we obtain error at most α with high probability.
Note that there is a signiﬁcant loss in the dependence on the error α in the proofs, so this
theorem does not determine the rate at which we can get the error to decay as a function of the
other parameters (for example, whether we can get it to decay linearly in n or
n). If we work
with (cid:96)2 rather than (cid:96)∞ error, then tighter characterizations of the rate of error decay are known
(up to factors polylog(|Q|,|X|)), by applying more sophisticated geometric methods to the convex
body K [58, 11, 84].
√
5.3 Fingerprinting Lower Bounds
The lower bounds from Sections 5.1 and 5.2 above address two extreme ranges of δ. Reconstruction
attacks prove lower bounds even for constant δ (e.g. δ = .1), and packing (mainly) proves lower
bounds for δ = 0. Recall that for satisfactory privacy guarantees, the desired range of δ is that
it should be cryptographically negligible, i.e. δ = n−ω(1), as (ε, δ)-diﬀerential privacy allows for
In particular, when δ ≥ 1/n, we can output a subsample
leaking each row with probability δ.
consisting of a δ fraction of the rows of the dataset, which in turns allows for answering any family
7In other words {a1, . . . , aM} form a β-net of K with respect to (cid:96)∞ norm.
45
Q of counting queries to within accuracy α = O((cid:112)(log |Q|)/δn) (by a Chernoﬀ Bound). (When δ
is constant, this matches the best lower bound we can get from discrepancy in the regime where
n (cid:28) min{|Q|,|X|}, cf. Thm. 5.12.) Thus, to prove lower bounds of the form α = Ω(1), we need to
focus on the regime δ ≤ O(log |Q|)/n.
It turns out that a very well-suited tool for this task is ﬁngerprinting codes, which were developed
in the cryptography literature by Boneh and Shaw [15] for a completely diﬀerent task. Speciﬁcally,
they were designed for preventing piracy of digital content. Imagine a digital movie distribution
company that wants to deliver copies of a movie to n diﬀerent customers, and the company wants
to mark each copy so that if one of the customers or a coalition S of the customers released a
pirated copy of the movie created from their own copies, the distribution company would be able
to point a ﬁnger at one of the pirates in S. There are d scenes in the movie and each of the scenes
can be watermarked by either 0 or 1 (say by choosing one of the slightly diﬀerent two angles from
which the movie was shot.) The colluding pirates may splice their copies to evade detection. The
ﬁngerprinting code should help protect the movie by specifying for each scene and each customer
whether it should be watermarked by 0 or 1. An associated tracing algorithm should determine
one of the colluding pirates with high probability from the code and a pirated copy.
Deﬁnition 5.16 (ﬁngerprinting codes, syntax). A ﬁngerprinting code of length d = d(n) for n
users consists of two randomized algorithms:
1. A generating algorithm Gen that takes the number n of users and produces an n × d binary
ﬁngerprinting matrix C where Ci,j ∈ {0, 1} determines the watermark of customer i in scene j
along with a tracing key tk . (It turns out that without loss of generality we can take tk = C.)
2. A tracing algorithm Trace that takes as input the tracing key tk and watermarks w ∈ {0, 1}d
from a potentially pirated movie and outputs an element of [n] ∪ {⊥} (which we interpret as
an accused customer or “fail”).
For a generating matrix C and a coalition S ⊆ {1, . . . , n}, we say that w ∈ {0, 1}d is feasible for
S if for every j ∈ {1, . . . , d}, wj equals to ci,j for some i ∈ S. Put diﬀerently, if CS, the submatrix
of C consisting of the rows in S, is constant on value bj on some column j, then we require that
wj = bj. This captures the constraint that the coalition produces its pirated movie by splicing its
copies together.
That is, a coalition S can deploy an arbitrary (randomized) pirating algorithm P : {0, 1}|S|×d →
{0, 1}d that takes as its input CS for a generating matrix C and produces a watermark sequence w
that is feasible for S. (So we will require security even against pirates who are able to determine
the watermarks in their movie copies.)
Deﬁnition 5.17 (ﬁngerprinting codes, security). A ﬁngerprinting code (Gen, Trace) is secure if for
every n, every S ⊆ {1, . . . , n} and every randomized pirating algorithm P : {0, 1}|S|×d → {0, 1}d,
we have:
[w is feasible for C and S, and Trace(C, w) (cid:54)∈ S] ≤ negl(n).
Pr
C←Gen(1n)
w←P (CS )
(Recall that negl(n) denotes a negligible probability, i.e. n−ω(1).)
An optimal construction of ﬁngerprinting codes was given by Tardos [100]:
46
Theorem 5.18 (optimal ﬁngerprinting codes [100]). For every n, there is a ﬁngerprinting code of
length d = ˜O(n2) for n users.
We won’t prove this theorem, but will instead show a simpler but suboptimal construction from
the original paper of Boneh and Shaw [15].
A ﬁngerprinting code of length ˜O(n3): Gen(1n) outputs a matrix obtained by randomly
permuting columns of the matrix