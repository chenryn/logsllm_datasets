the cluster as its centroid, namely that which minimizes the
average distance to all cluster members. Instead of deciding
the number of clusters in advance, we employ the following
of the cluster.
2) For each cluster, ﬁnd the packet furthest from its
medoid as a candidate for a new medoid. Choose the
furthest one among these candidates as the medoid of
a new cluster.
3) Re-cluster all packets, assigning each packet to the
closest existing medoid. After that, re-compute the
medoid of each cluster.
4) Repeat steps 2 and 3 until no packet is further than 𝑟
times the average medoid-to-medoid distance.
Therefore, the number of generated clusters depends on the
input parameter 𝑟.
D. Alignment of Packets
The clusters output from the procedure described in
Section III-C are the clusters from which our algorithm
selects representatives (with at least one representative being
selected from each cluster). In preparation for performing
this selection, we ﬁrst align all of the packets in each cluster
collectively. We now detail how the alignment is done, and
discuss the selection of representatives later.
A key challenge in performing multiple sequence align-
ment in our setting is the fact that we may need to operate
over clusters with thousands of packets. For efﬁciency, we
use a progressive method, which generates an alignment by
ﬁrst aligning the most similar sequences and then succes-
sively adding less similar sequences to the growing align-
ment until all packets in the cluster have been incorporated.
With progressive alignment, the quality of the ﬁnal align-
ment generally depends on the order with which the se-
quences are incorporated. To determine this order, we treat
the cluster as a graph with vertices being the packets and an
edge between each pair of packets weighted by their distance
(1). We then use Prim’s algorithm [28] to create a minimum
spanning tree, and integrate (i.e., align) the vertices together
in the order in which they are included in the tree. Since
Prim’s algorithm adds vertices in increasing order of their
distance to their nearest vertex already in the tree, aligning
vertices in this order should intuitively delay the insertion
of gaps in the overall alignment as long as possible (and
hopefully render most gaps unnecessary).
The detailed algorithm is shown as Algorithm 1. The
nodes of the minimum spanning tree are denoted mst, which
is initialized to the medoid of the cluster (line 2). The use of
Prim’s algorithm is evident in the while loop on lines 4–15,
which selects the next closest packet to incorporate (line 5)
and adds it (line 15). The construction of a mutual alignment
for the packets is done using the align function in line 6.
This call aligns the chosen packet and a reference alignment
denoted consensusSeq[
], which is updated by align. In
addition, align outputs a boolean array isNewGap[ ] of length
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:32:40 UTC from IEEE Xplore.  Restrictions apply. 
497equal to the updated consensusSeq[ ], such that isNewGap[𝑗]
is true iff consensusSeq[𝑗] is a gap inserted in this call to
align. As its last step, align outputs the aligned form of the
chosen packet.
dist(pkt, pkt′)
pkt∈cluster
Algorithm 1 ClusterAlign (cluster)
1: medoid ← arg min
avg
pkt′∈cluster
2: mst ← {medoid}; mstSize ← ∣mst∣
3: consensusSeq[ ] ← tokenize(medoid)
4: while mstSize ≤ ∣cluster∣ do
pkt∈cluster∖mst
min
5:
pkt∗ ← arg
(consensusSeq[ ], isNewGap[ ], seq[mstSize + 1][ ])
← align(consensusSeq[ ], tokenize(pkt∗))
dist(pkt, pkt′)
pkt′∈cluster
min
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
for 𝑘 = 1 . . . mstSize do
𝑖 ← 1; temp[ ] ← [ ]
for 𝑗 = 1 . . .∣isNewGap[ ]∣ do
if isNewGap[𝑗] then
temp[𝑗] ← gap
temp[𝑗] ← seq[𝑘][𝑖]; 𝑖 ← 𝑖 + 1
else
seq[𝑘][ ] ← temp[ ]
mst ← mst ∪ {pkt∗}; mstSize ← ∣mst∣
16: return seq[1 . . .∣cluster∣][ ]
The gaps inserted by align,
in locations indicated by
isNewGap[ ], are then propagated to the aligned forms of
the packets already integrated into the tree, i.e., by inserting
the gaps into the same positions in those sequences. This is
shown in lines 7–14, where the new version of the aligned
sequence for the 𝑘-th integrated packet is assembled in an
array temp[ ]and then copied back into seq[𝑘][ ] (line 14).
The behavior of align differs in an important way from
sequence alignment as described in Section III-C. To avoid
the introduction of gaps into the aligned sequences seq[𝑘][ ]
to the extent possible, we alter align in line 6 to (i) output
in consensusSeq[𝑗] the disjunction of the tokens from inputs
consensusSeq[ ] and tokenize(pkt∗) that it aligns to position
𝑗 (under an optimal alignment as deﬁned in Section III-C);
and (ii) assign a matching award (in value or type) to
tokens if the token of tokenize(pkt∗) matches any disjunct
of the token of input consensusSeq[ ] (and where a gap in
consensusSeq[ ] type-matches nothing). Consequently, after
propagating gaps to the other sequences already integrated
into the tree (lines 7–14), an invariant of the loop 4–15 is
seq[𝑘][𝑗]. Figure 3 shows
that consensusSeq[𝑗] =
the result of aligning a cluster of ten packets using this
algorithm. Notice that ﬁelds with similar type or value have
been correctly aligned.
⋁mstSize
𝑘=1
E. Selecting Representatives for Inspection
this stage in our overall process,
the elements
of each cluster are aligned in equal-length sequences
At
seq[1 . . .∣cluster∣][ ]. To select representatives and present
them to the worker for inspection, we borrow a tech-
nique from Pan et al. [24]. The input required by this
technique is a collection of equal-length feature vectors.
To generate this input, we simply deﬁne feature vectors
seqFV[1 . . .∣cluster∣][ ] so that seqFV[𝑘][𝑖] = 0 if seq[𝑘][𝑖] =
gap and seqFV[𝑘][𝑖] = 1 otherwise. Due to the alignment of
seq[1 . . .∣cluster∣][ ], the tokens of all sequences at position
𝑖 typically have the same type, and so a binary gap/no gap
representation for these feature vectors sufﬁces. The tech-
nique of Pan et al. then uses these feature vectors to select
representatives that maximize their mutual information and
minimize their redundancy.
Figure 3 shows representative sequences generated for
a particular cluster. The most closely similar sequences,
grouped via the method of [24], are labeled with the same
shape (e.g., star). One representative is picked per group
of similar sequences, based on maximizing the mutual
information and minimizing redundancy. In this way, the ap-
proach for selecting representatives improves the efﬁciency
of worker inspection by dramatically decreasing the number
of sequences presented for inspection.
Figure 3. Example of representative selection; each representative and its
most similar packets are denoted by the same shape (e.g., star).
F. Applying Worker Feedback
The representatives selected as described in Section III-E
are presented to a group of workers, via an interface such
as that described in the appendix. Our technique does not
require a speciﬁc interface, though it should present the
representatives to the worker in a way that promotes the
identiﬁcation of sensitive ﬁelds and that provides the worker
an ability to mark which ﬁelds she believes to be sensitive.
In Section IV-B, we evaluate two features of such a user
interface that we believe, based on previous ﬁndings about
user perception [9, 1], can ease the worker’s task, namely
presenting similar representatives from one cluster at a time
and presenting tokenized representatives in their aligned
form.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:32:40 UTC from IEEE Xplore.  Restrictions apply. 
498The distinct capacities of the workers in identifying sen-
sitive ﬁelds make it challenging to apply their markings to
the full dataset — recruited workers may have diverse skill
levels and training. This motivates our attempt to achieve
better accuracy by leveraging inputs from only the most
skilled in the worker pool. To identify these most skilled
workers, we compare the ﬁelds indicated as sensitive by
each worker in a small subset of the representatives that
worker examined, to ground truth for those representatives
as determined by the expert. We make this comparison on
the basis of standard measures, namely precision and recall:
∣{identiﬁed ﬁelds} ∩{sensitive ﬁelds}∣
Precision =
Recall =
∣{identiﬁed ﬁelds}∣
∣{identiﬁed ﬁelds} ∩{sensitive ﬁelds}∣
∣{sensitive ﬁelds}∣
To select the best workers, however, it is necessary to reduce
these two measures to one, on which worker performance
can be ordered. For this, we use the F-score [29] statistic,
which computes a weighted average of recall and precision:
F𝛼 = (1 + 𝛼2) ⋅
Precision ⋅ Recall
𝛼2 ⋅ Precision + Recall
Essentially, F𝛼 measures the effectiveness of identiﬁcation
with respect to the participant who places 𝛼 times as much
importance to recall as precision [29]. (We will comment on
the values of 𝛼 we employ in Section IV.)
Those workers with the highest F-scores on these repre-
sentatives are selected for applying their inputs to the entire
dataset, in a manner described below. For the remainder
of our discussion, we presume that the best two workers
are used. Once these best workers are selected, the goal
is to utilize their identiﬁcation of sensitive ﬁelds in the
representatives they examined to identify sensitive ﬁelds
in the rest of the dataset. To do so, we process each
new packet not directly examined by the workers by ﬁrst
ﬁnding the examined representative that is closest to this
packet (i.e., for which the distance (1) is the smallest).
Pairwise sequence alignment is performed between the new
packet and each representative of the cluster that contains
this closest representative. We then adopt the most liberal
strategy in marking tokens; that is, we mark a token in the
new packet as sensitive if it aligns to a ﬁeld in any of these
representatives that either worker marked as sensitive. We
do so because in the domain of packet sanitization, higher
recall is typically favored over precision.
IV. EVALUATION
In this section, we evaluate the effectiveness of our
approach when it is used to identify the sensitive ﬁelds
contained in packet payloads. For the purpose of our evalu-
ation, we deemed several types of ﬁelds as sensitive. These
ﬁelds were domain names, IP addresses, ﬁle names (and
directories), user names, passwords, host (server) names,
and email addresses. These seven types of ﬁelds were used
as ground truth for what in the data is “sensitive”. We
emphasize that these speciﬁc ﬁelds were chosen only to
measure the recall and precision achieved by subjects using
our approach. The datasets we used are:
The UNV-DNS dataset. This dataset consists of 20,000
network packets recorded at a university campus. The
trace contains bidirectional trafﬁc to a DNS server. Of the
seven speciﬁed sensitive ﬁelds, DNS packets contain domain
names and IP addresses.
The KDDCup-FTP dataset. This dataset was selected from
the International Knowledge Discovery and Data Mining
Tools Competition.3 We prepared the dataset by speciﬁcally
choosing the raw FTP Control packets, which contain 31,020
FTP queries and responses. The speciﬁed sensitive ﬁelds
contained in FTP Control
trafﬁc are domain names, IP
addresses, ﬁle names (directories), user names, passwords,
host (server) names, and email addresses.
The Wireshark-SMB dataset.
is from
the WiresharkTM trace repository. It contains 22,807 SMB
(server message block) requests and responses. The speciﬁed
sensitive ﬁelds it contains are domain names, ﬁle names (di-
rectories), user names, passwords, and host (server) names.
This dataset
The motivation for selecting these three datasets is that
they contain packets with diverse types of sensitive ﬁelds and
complex message formats. For example, the DNS response
packets in the UNV-DNS dataset are very diverse and can
be quite complex (e.g., with IP addresses appearing in many
different places in the response packets). The KDDCup-FTP
dataset has packets with all the sensitive ﬁelds speciﬁed
above, and also has many different types of message formats
in FTP reply packets. Similar reasons justify our choice
of the Wireshark-SMB dataset. For these datasets, we
wrote a parser that read the XML packet detail exported by
Wireshark to automatically locate all instances of the seven
speciﬁed ﬁelds contained in the payloads. The number and
locations of these ﬁelds are used only as ground truth.
For the remainder of this paper, we apply standard
measures of effectiveness when evaluating our approach,
speciﬁcally the F-score F𝛼 (see Section III-F) achieved for
identifying all sensitive ﬁelds either in the entire dataset
or simply in the representatives for each cluster. (We will
clarify which is used in each case.) Because in the context
of packet trace sanitization, recall is often more important
than precision — after all, the most common practice when
releasing network traces is simply to remove all payload
3While this dataset has been criticized as being too unrealistic as a basis
for evaluating intrusion detection systems (e.g., [21]), we use it here for
a completely different purpose, namely as a source of payload-bearing
packets that contain some of the sensitive ﬁeld types listed above.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:32:40 UTC from IEEE Xplore.  Restrictions apply. 
499α=1.2
40%
80%
100%
1
0.98
0.96
0.94
0.92
α
F
0.9
0.88
0.86
0.84
0.82
1
0.95
0.9
0.85
0.8
α
F
0.75
0.7
0.65
0.6
0.55
α=1.2
40%
80%
100%
1
0.95
0.9
0.85
α
F
0.8
0.75
0.7
0.65
α=1.2
40%
80%
100%
0.8
10
20
30
40
50
60
70
Number of clusters
80
90
100
0.5
0
5