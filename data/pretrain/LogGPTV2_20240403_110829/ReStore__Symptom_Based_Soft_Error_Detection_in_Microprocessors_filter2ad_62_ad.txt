s
1.1
1
0.9
0.8
0.7
0.6
0.5
imm
delayed
25
50
100
200
500
1000
checkpoint interval (insns)
Figure 7. Performance impact of false positive
symptoms
on top of the parity and ECC resulted in an overall rate of
about 1%. Note that the two mechanisms combine to provide
a signiﬁcant level of soft error protection. This is because
the parity and ECC placements worked mostly to detect and
recover from soft error corruptions in SRAM structures (e.g.
the register ﬁle and alias tables and fetch queue), while the
ReStore architecture is more effective at detecting soft errors
in latches (as observed in Section 5.1.2). When ReStore is
coupled with precisely placed parity/ECC, the mean time be-
tween failures improves by 7x over that of a conventional,
unprotected pipeline.
5.2.3. Performance impact. In this subsection, we evaluate
the performance impact incurred from false positive symp-
toms. We expect that symptoms originating from watchdog
timer saturation and exception events to be infrequent enough
to have negligible impact on performance. Thus, we focus on
the cost in performance due to checkpoint rollbacks from high
conﬁdence branch mispredictions.
We perform this evaluation on a timing model conﬁgured
to resemble our processor model. In order to support a roll-
back distance of at least one checkpoint interval, two check-
points are maintained at all times. Thus, when a rollback is
required, the older checkpoint is used to restore architectural
state. The average rollback distance is therefore one and a
half times the checkpoint interval. During re-execution of
a checkpoint interval, a branch outcome event log is used to
provide perfect prediction of control ﬂow, eliminating control
misspeculations during re-execution.
The results of this experiment are presented in Figure 7.
The x-axis plots checkpointing intervals, while the y-axis
plots relative performance when compared against a baseline
processor without checkpointing. The imm bars indicate the
performance impact when rollback occurs immediately upon
discovery of a symptom. This has the disadvantage of pos-
sibly incurring multiple rollbacks to a single checkpoint if
multiple symptoms arise within the same checkpoint interval.
As an alternative, we also simulated the performance impact
when checkpoint rollback is delayed until the entire interval
is executed. The data from this experiment is represented by
the delayed bars.
Overall, the performance hit is minor for shorter check-
pointing intervals. A checkpointing interval of 100 instruc-
tions yields a performance hit of approximately 6%. The de-
layed conﬁguration slightly underperforms the imm conﬁg-
uration at smaller intervals, but begins to gain an advantage
at 500 instruction intervals. Using more accurate branch and
10000
)
s
r
u
o
h
f
o
s
n
o
i
l
l
i
b
(
e
m
i
t
n
i
s
e
r
u
l
i
a
f
1000
100
10
1
0.1
baseline
ReStore
lhf
lhf+ReStore
MTBF goal
k
0
5
k
0
0
1
k
0
0
2
k
0
0
4
k
0
0
8
M
6
.
1
M
2
.
3
M
4
.
6
design size (bits of storage)
M
8
.
2
1
M
6
.
5
2
Figure 8. FIT rates with device scaling
conﬁdence [2] predictors would mitigate some of this perfor-
mance loss and also obtain better error coverage.
5.3. Scaling trends
In this section, we examine silent data corruption FIT
rates as a function of design size for a variety of architectures.
FIT stands for Failures in Time, in billions of hours, and is a
measure of the reliability of a given design.
To generate the results shown in Figure 8, we assumed
a raw FIT of 0.001 per bit [11], which is a widely accepted
estimate for per-bit FIT rate in SRAMs. The different pro-
cessor conﬁgurations are the baseline processor without any
error detection (baseline), with ReStore (ReStore), with care-
fully placed parity/ECC (lhf) (i.e., the “low-hanging fruit”
pipeline described in Section 5.2), and with both techniques
(lhf+ReStore). The FIT extrapolations are made assuming
that the soft error masking rate of the larger designs remains
constant as design size is scaled. A reliability goal of 1000
MTBF, or mean time (years) between failures is reﬂected by
the horizontal line at 115 FIT. Any design whose FIT rises
above this line fails to meet this goal. Our model consists
of approximately 46,000 bits of “interesting” state — state
within the pipeline that is particularly problematic to protect.
That is, all processor state excluding caches and prediction
structures not needed for correctness. This is approximately
represented by the ﬁrst data point in Figure 8. The interesting
thing to observe is that the lhf+ReStore conﬁguration yields a
MTBF comparable to a design 1/7th the size.
6. Related Work
Gu et al. [8, 9] and Smolens et al. [25] explored fail-
ure modes from fault injections into general purpose regis-
ters. They also noted a high percentage of failures from
exceptions. We investigate error propagation from microar-
chitectural state to architectural state and eventually excep-
tions. Furthermore, we evaluate the use of exceptions and
other symptoms to aid soft error detection.
Patel et al. [22] explore the error coverage provided by
the rePLay framework, which performs checkpoint rollbacks
on highly biased branch mispredictions. Like Gu et al.,
they performed fault injections into general purpose registers.
Here, we perform a microarchitectural evaluation in a more
general framework.
Previous work has explored using parity, ECC and TMR
to provide spatial redundancy in processor cores [6, 10].
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:08:52 UTC from IEEE Xplore.  Restrictions apply. 
Franklin [4] noted different modes of failure throughout the
pipeline and proposed mechanisms to guard against them. We
propose an alternative, more cost effective approach to soft
error detection and recovery.
Other work has introduced other forms of redundancy to
mitigate the effects of soft errors [20, 24, 29]. Each relies
on “full-time” redundancy, where the cost of redundant exe-
cution is paid for on each instruction. Rather than utilizing
redundancy to detect and recover from soft errors, Weaver et
al. [30] reduce the exposure of instructions to soft errors by
squashing instructions upon encountering long latency events
like cache misses. Here, we introduce the ReStore architec-
ture to provide efﬁcient “on-demand” time redundancy.
7. Conclusion
In this work, we propose the ReStore architecture which
leverages existing performance enhancing hardware for the
purpose of soft error detection and recovery. Selected high
level events from microarchitectural structures (soft error
symptoms) are used to diagnose the likely presence of failure
causing soft errors, initiating checkpoint recoveries for de-
tection. Thus, the ReStore architecture employs on-demand
time redundancy, minimizing hardware cost and performance
impact. Such an approach sacriﬁces some amount of error
coverage, but would be suitable for environments where reli-
able operation is desired but not at all costs.
The baseline processor had an intrinsic error masking
rate of approximately 93%, indicating that only 7 out of every
100 introduced faults propagate to persistent data corruption.
With a 100 instruction checkpoint interval, an example Re-
Store implementation detects and recovers from half of all
failures. Covering the most vulnerable portions of the base-
line processor core with parity/ECC and overlaying ReStore
extends the mean time between failures by 7x, while incur-
ring minimal hardware and performance cost.
8. Acknowledgments
We thank the other members of the Advanced Computing
Systems group as well as the FACT group at Intel, Zbigniew
Kalbarczyk, Claudio Basile, and the anonymous referees for
providing feedback during various stages of this work. This
work was supported by the C2S2 Marco center, NSF grant
EIA-0224453, and equipment donation from AMD.
References
[1] H. Akkary, R. Rajwar, and S. T. Srinivasan. Checkpoint pro-
cessing and recovery: Towards scalable large instruction win-
dow processors. In MICRO-36, Dec. 2003.
[2] H. Akkary, S. T. Srinivasan, R. Koltur, Y. Patil, and W. Refaai.
Perceptron-based branch conﬁdence estimation. In HPCA-10,
pages 265–274, Feb. 2004.
[3] B. A. Gieseke et al. A 600MHz superscalar RISC micropro-
cessor with out-of-order execution.
In 1997 IEEE Interna-
tional Solid-State Circuits Conference Digest of Technical Pa-
pers, pages 176–178, Feb. 1997.
[4] M. Franklin. Incorporating fault tolerance in superscalar pro-
In Proceedings of High Performance Computing,
cessors.
pages 301–306, Dec. 1996.
[5] G. Hinton et al. The Microarchitecture of the Pentium 4 Pro-
cessor. Intel Technology Journal, Jan. 2001.
[6] J. Gaisler. A portable and fault-tolerant microprocessor based
on the SPARC V8 architecture. In DSN-2002, Sept. 2002.
[7] D. Grunwald, A. Klauser, S. Manne, and A. Pleszkun. Con-
ﬁdence estimation for speculation control. In ISCA-25, pages
122–131, June 1998.
[8] W. Gu, K. Kalbarczyk, and R. K. Iyer. Error sensitivity of the
linux kernel executing on powerpc g4 and pentium 4 proces-
sors. In DSN-2004, June 2004.
[9] W. Gu, K. Kalbarczyk, R. K. Iyer, and Z. Yang. Characteriza-
tion of linux kernel behavior under errors. In DSN-2003, June
2003.
[10] H. Ando et al. A 1.3 GHz ﬁfth generation SPARC64 micro-
processor. In Design Automation Conference, June 2003.
[11] P. Hazucha and C. Svensson.
Impact of CMOS Technol-
ogy Scaling on the Atmospheric Neutron Soft Error Rate.
IEEE Transactions on Nuclear Science, 47(6):2586–2594,
Dec. 2000.
[12] E. Jacobsen, E. Rotenberg, and J. E. Smith. Assigning conﬁ-
dence to conditional branch predictions. In MICRO-29, pages
142–152, 1996.
[13] D. A. Jiminez. Fast path-based neural branch prediction. In
MICRO-36, Dec. 2003.
[14] T. Karnik, P. Hazucha, and J. Patel. Characterization of soft
errors caused by single event upsets in CMOS processes.
IEEE Transactions on Dependable and Secure Computing,
1(2):128–143, Apr. 2004.
[15] A. Klaiber. The technology behind Crusoe processors. Tech-
nical report, Transmeta Corporation, Jan. 2000.
[16] S. S. Lumetta and S. J. Patel. Characterization of essential
dynamic instructions. In SIGMETRICS 2003, June 2003.
[17] A. Mahmood and E. J. McCluskey. Concurrent error detection
using watchdog processors - a survey. IEEE Transactions on
Computers, 37(2):160–174, Feb. 1988.
[18] S. McFarling. Combining branch predictors. Technical Report
TN-36, Digital Western Research Laboratory, June 1993.
[19] D. Meyer. AMD-K7  
 Technology Presentation. Advanced
Micro Devices, Inc., Sunnyvale, CA, Oct. 1998. Microproces-
sor Forum presentation.
[20] S. S. Mukherjee, M. Kontz, and S. K. Reinhardt. Detailed de-
sign and evaluation of redundant multithreading alternatives.
In ISCA-29, pages 99–110, May 2002.
[21] S. S. Mukherjee, C. Weaver, J. Emer, S. K. Reinhardt, and
T. Austin. A systematic methodology to compute the archi-
tectural vulnerability factors for a high-performance micro-
processor. In MICRO-36, pages 29–40, Dec. 2003.
[22] S. J. Patel, Z. Kalbarczyk, R. K. Iyer, W. Magda, and
N. Nakka. A processor-level framework for high-performance
and high-dependability. In Workshop on Evaluating and Ar-
chitecting Systems for Dependability, 2001.
[23] S. K. Reinhardt and S. S. Mukherjee. Transient fault detection
via simultaneous multithreading. In ISCA-27, June 2000.
[24] E. Rotenberg. AR-SMT: A microarchitectural approach to
fault tolerance in microprocessors. In FTCS, June 1999.
[25] J. C. Smolens, B. T. Gold, J. Kim, B. Falsaﬁ, J. C. Hoe, and
A. G. Nowatzyk. Fingerprinting: Bounding soft-error detec-
tion latency and bandwidth. In ASPLOS-11, Oct. 2004.
[26] L. Spainhower and T. A. Gregg. IBM S/390 parallel enterprise
server G5 fault tolerance: A historical perspective. IBM Jour-
nal of Research and Development, 43(5/6):863–873, 1999.
[27] J. G. Steffan and T. C. Mowry. The potential for using thread-
level data speculation to facilitate automatic parallelization. In
HPCA-4, Feb. 1998.
[28] N. J. Wang, J. Quek, T. M. Rafacz, and S. J. Patel. Charac-
terizing the effects of transient faults on a high-performance
processor pipeline. In DSN-2004, June 2004.
[29] C. Weaver and T. Austin. A fault tolerant approach to micro-
processor design. In ISCA-29, May 2002.
[30] C. Weaver, J. Emer, S. S. Mukherjee, and S. K. Reinhardt.
Techniques to reduce the soft error rate of a high-performance
microprocessor. In ISCA-31, June 2004.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:08:52 UTC from IEEE Xplore.  Restrictions apply. 

