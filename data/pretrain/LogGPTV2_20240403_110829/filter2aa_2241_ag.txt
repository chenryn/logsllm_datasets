Copilot is trained over open-source code available on GitHub,
we theorize that the variable security quality stems from
the nature of the community-provided code. That is, where
certain bugs are more visible in open-source repositories,
those bugs will be more often reproduced by Copilot. Having
said that, one should not draw conclusions as to the security
quality of open-source repositories stored on GitHub. We are
not currently aware of any relevant studies performed over
the entirety of GitHub and the subset used for training—as
such, this remains an open question for future research.
Another aspect of open-source software that needs to be
considered with respect to security qualities is the effect of
time. What is ‘best practice’ at the time of writing may slowly
become ‘bad practice’ as the cybersecurity landscape evolves.
Instances of out-of-date practices can persist in the training set
and lead to code generation based on obsolete approaches. An
example of this is in the DOW CWE-522 scenarios concerning
password hashing. Some time ago, MD5 was considered
secure. Then, a single round of SHA-256 with a salt was con-
sidered secure. Now, best practice either involves many rounds
of a simple hashing function, or use of a library that will age
gracefully like ‘bcrypt’. Un-maintained and legacy code uses
insecure hashes, and so Copilot continues suggesting them.
Threats to Validity
1) CodeQL Limitations: While we endeavored to evaluate
as many scenarios as possible using GitHub’s CodeQL, some
CWE’s could not easily be processed. CodeQL builds graphs
of program content / structure, and performs best when analyz-
ing these graphs for self-evident truths: that is, data contained
within the program that is deﬁnitively vulnerable (for example,
checking for SQL injection). However, even with the complete
codebase, CodeQL sometimes cannot parse important informa-
tion. The authors found this to be the case when considering
memory buffer sizes, as CodeQL’s ability to derive memory
boundaries (e.g. array lengths) is limited in functionality. Addi-
tionally, as noted in Section II, some CWEs will need informa-
tion beyond that encoded in the program. For instance, CWE-
434: Unrestricted Upload of File with Dangerous Type is
harder to evaluate given the information in the codebase (what
is ‘dangerous’? Size? Extension?). One last note on CodeQL
concerns the ‘strictness’ of its analysis. While we made a best
effort to ensure that all test cases and results collected by
CodeQL were accurate, including by manual spot checks, it
is possible that across the full corpus of generated programs
there may have been edge cases where CodeQL ‘failed-safe’,
i.e., marked something as vulnerable that was not.
For the languages and scenarios that CodeQL did not
support (e.g., Verilog), the CWEs had to be marked manually.
When marking manually, we strove for objective outputs,
by considering the deﬁnitions of the relevant CWEs and
nothing else. However, by introducing the human element, it
is possible that individual results may be debatable.
2) Statistical Validity: We note that number of samples in
each scenario may not be enough to derive statistical conclu-
sions. Unfortunately, due to the ‘manual’ nature of using the
GitHub Copilot interface at the time of this study (i.e., a human
has to request the results), there were limits to the number of
samples we could collect. We are also further hampered in this
by the lack of a formal deﬁnition for the ‘mean prob’ score
that is returned by Copilot with each result. It is difﬁcult to
make claims on statistical signiﬁcance of all our results, but we
believe that the empirical ﬁndings are nevertheless noteworthy.
3) Reproducible Code Generation: As a generative model,
Copilot outputs are not directly reproducible. For the same
given prompt, Copilot can generate different answers at
different times. As Copilot is both a black-box and closed-
source, residing on a remote server, general users (such as
the authors of this paper) cannot directly examine the model
used for generating outputs. The manual effort needed to
query Copilot plus rate-limiting of queries, prohibits efﬁcient
collection of large datasets. This impacted and informed the
methods we use. Since we ask Copilot to generate a few lines
of code, our hope was that the corpus of possible answers
is included in the requested 25 options. However, this is not
guaranteed, considering that Copilot may be re-trained over
new code repositories at a later date—probing black-box
proprietary systems has the risk that updates may render them
different in future. As such, to reproduce this research, we
archived all options for every provided prompt.
4) On scenario creation: Our experiments cover a range
of scenarios and potential weaknesses with three different
languages. While scenarios provide insights into Copilot,
the scenarios are artiﬁcial in that they try to target speciﬁc
potential
weaknesses.
Real-world
code
is
considerably
messier and contains larger amounts of context (e.g., other
functions, comments, etc.), so our setup does not fully reﬂect
the spectrum of real-world software. Subtle variations in the
prompts (Section V-C) affect Copilot’s code generation; wider
contexts with better quality code can yield more secure code
suggestions. In future, examining Copilot’s response to com-
binations of prompts/scenarios may offer insights into biases
Copilot responds to. Further, the gamut of Copilot languages
is vast. We need ways to quantify the limits of models like
Copilot when used with different languages—e.g., low-level or
esoteric languages like x86 assembly, ladder logic and g-code.
Disclosures
The ﬁndings of this paper do not lead to exploitable vul-
nerabilities in the GitHub Copilot product. Rather, we simply
examined the tool, using it as intended, to generate code sam-
ples, and then evaluated the properties of those code samples.
Thus, coordinated vulnerability disclosure was not necessary.
VII. CONCLUSIONS AND FUTURE WORK
There is no question that next-generation ‘auto-complete’
tools like GitHub Copilot will increase the productivity of
software developers. However, while Copilot can rapidly
generate prodigious amounts of code, our conclusions reveal
that developers should remain vigilant (‘awake’) when using
Copilot as a co-pilot. Ideally, Copilot should be paired
with appropriate security-aware tooling during both training
and generation to minimize the risk of introducing security
vulnerabilities. While our study provides new insights into
its behavior in response to security-relevant scenarios, future
work should investigate other aspects, including adversarial
approaches for security-enhanced training.
REFERENCES
[1] “GitHub Copilot · Your AI pair programmer.” [Online]. Available:
https://copilot.github.com/
[2] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Ed-
wards, Y. Burda, N. Joseph, G. Brockman, A. Ray, R. Puri, G. Krueger,
M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ryder,
M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter, P. Tillet, F. P.
Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A. Herbert-
Voss, W. H. Guss, A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin,
S. Balaji, S. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike, J. Achiam,
V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati,
K. Mayer, P. Welinder, B. McGrew, D. Amodei, S. McCandlish,
I. Sutskever, and W. Zaremba, “Evaluating Large Language Models
Trained on Code,” arXiv:2107.03374 [cs], Jul. 2021, arXiv: 2107.03374.
[Online]. Available: http://arxiv.org/abs/2107.03374
[3] J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dohan,
E. Jiang, C. Cai, M. Terry, Q. Le, and C. Sutton, “Program Synthesis
with Large Language Models,” arXiv:2108.07732 [cs], Aug. 2021,
arXiv: 2108.07732. [Online]. Available: http://arxiv.org/abs/2108.07732
[4] The
MITRE
Corporation
(MITRE),
“2021
CWE
Top
25
Most
Dangerous
Software
Weaknesses,”
2021.
[Online].
Available:
https://cwe.mitre.org/top25/archive/2021/2021 cwe top25.html
[5] G.
Inc.,
“CodeQL
documentation,”
2021.
[Online].
Available:
https://codeql.github.com/docs/
[6] The
MITRE
Corporation
(MITRE),
“CWE-1194:
CWE
VIEW:
Hardware
Design,”
Jul.
2021.
[Online].
Available:
https://cwe.mitre.org/data/deﬁnitions/1194.html
[7] D. Zhang and J. J. Tsai, “Machine Learning and Software Engineering,”
Software Quality Journal, vol. 11, no. 2, pp. 87–119, Jun. 2003.
[Online]. Available: https://doi.org/10.1023/A:1023760326768
[8] N. Jiang, T. Lutellier, and L. Tan, “CURE: Code-Aware Neural Machine
Translation for Automatic Program Repair,” in 2021 IEEE/ACM 43rd
International Conference on Software Engineering (ICSE), May 2021,
pp. 1161–1173, iSSN: 1558-1225.
[9] R. Mihalcea, H. Liu, and H. Lieberman, “NLP (Natural Language
Processing)
for
NLP
(Natural
Language
Programming),”
in
Computational Linguistics and Intelligent Text Processing, A. Gelbukh,
Ed.
Springer Berlin Heidelberg, 2006, pp. 319–330.
[10] R. Drechsler, I. G. Harris, and R. Wille, “Generating formal system
models from natural language descriptions,” in IEEE Int. High Level
Design Validation and Test Workshop (HLDVT), 2012, pp. 164–165.
[11] C. B. Harris and I. G. Harris, “GLAsT: Learning formal grammars to
translate natural language speciﬁcations into hardware assertions,” in
Design, Automation Test in Europe Conf. Exhibition (DATE), 2016, pp.
966–971.
[12] K. M. T. H. Rahit, R. H. Nabil, and M. H. Huq, “Machine Translation
from Natural Language to Code Using Long-Short Term Memory,” in
Future Technologies Conf. (FTC).
Springer International Publishing,
Oct. 2019, pp. 56–63, iSSN: 2194-5365.
[13] M. Sundermeyer, R. Schl¨uter, and H. Ney, “LSTM neural networks for
language modeling,” in Conf. Int. Speech Communication Assoc., 2012.
[14] P.
Liu,
X.
Qiu,
and
X.
Huang,
“Recurrent
Neural
Network
for
Text
Classiﬁcation
with
Multi-Task
Learning,”
CoRR,
vol.
abs/1605.05101,
2016,
eprint:
1605.05101.
[Online].
Available:
http://arxiv.org/abs/1605.05101
[15] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
Gomez, \. Kaiser, and I. Polosukhin, “Attention is All you Need,”
in Advances in Neural Information Processing Systems 30, I. Guyon,
U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan,
and R. Garnett, Eds.
Curran Associates, Inc., 2017, pp. 5998–6008.
[16] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training
of Deep Bidirectional Transformers for Language Understanding,”
CoRR, vol. abs/1810.04805, 2018,
eprint: 1810.04805. [Online].
Available: http://arxiv.org/abs/1810.04805
[17] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever,
“Language Models are Unsupervised Multitask Learners,” p. 24, 2019.
[Online].
Available:
https://cdn.openai.com/better-language-models/
language models are unsupervised multitask learners.pdf
[18] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal,
A.
Neelakantan,
P.
Shyam,
G.
Sastry,
A.
Askell,
S.
Agarwal,
A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M.
Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin,
S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford,
I. Sutskever, and D. Amodei, “Language Models are Few-Shot
Learners,” arXiv:2005.14165 [cs], Jul. 2020, arXiv: 2005.14165.
[Online]. Available: http://arxiv.org/abs/2005.14165
[19] S. Reddy, D. Chen, and C. D. Manning, “CoQA: A Conversational
Question Answering Challenge,” Transactions of the Association for
Computational Linguistics, vol. 7, pp. 249–266, 2019.
[20] H. Pearce, B. Tan, and R. Karri, “DAVE: Deriving Automatically
Verilog from English,” in Proceedings of the 2020 ACM/IEEE
Workshop
on
Machine
Learning
for
CAD.
Virtual
Event
Iceland:
ACM,
Nov.
2020,
pp.
27–32.
[Online].
Available:
https://dl.acm.org/doi/10.1145/3380446.3430634
[21] OWASP,
“Source
Code
Analysis
Tools.”
[Online].
Available:
https://owasp.org/www-community/Source Code Analysis Tools
[22] V.
Bandara,
T.
Rathnayake,
N.
Weerasekara,
C.
Elvitigala,
K. Thilakarathna, P. Wijesekera, and C. Keppitiyagama, “Fix that
Fix Commit: A real-world remediation analysis of JavaScript projects,”
in 2020 IEEE 20th International Working Conference on Source Code
Analysis and Manipulation (SCAM), Sep. 2020, pp. 198–202.
[23] The
MITRE
Corporation
(MITRE),
“CWE
-
CWE-Compatible
Products
and
Services,”
Dec.
2020.
[Online].
Available:
https://cwe.mitre.org/compatible/compatible.html
[24] J. Li, B. Zhao, and C. Zhang, “Fuzzing: a survey,” Cybersecurity,
vol.
1,
no.
1,
p.
6,
Dec.
2018.
[Online].
Available:
https:
//cybersecurity.springeropen.com/articles/10.1186/s42400-018-0002-y
[25] G.
Dessouky,
D.
Gens,
P.
Haney,
G.
Persyn,
A.
Kanuparthi,
H. Khattri, J. M. Fung, A.-R. Sadeghi, and J. Rajendran, “HardFails:
Insights into Software-Exploitable Hardware Bugs,” in 28th USENIX
Security Symposium, 2019, pp. 213–230. [Online]. Available: https:
//www.usenix.org/conference/usenixsecurity19/presentation/dessouky
[26] M. Fischer, F. Langer, J. Mono, C. Nasenberg, and N. Albartus,
“Hardware Penetration Testing Knocks Your SoCs Off,” IEEE Design
Test, vol. 38, no. 1, pp. 14–21, Feb. 2021, conference Name: IEEE
Design Test.
[27] G. Nichols, “RTL Linting Sign Off - Ascent Lint.” [Online]. Available:
https://www.realintent.com/rtl-linting-ascent-lint/
[28] “Verilator User’s Guide — Verilator 4.202 documentation.” [Online].
Available: https://verilator.org/guide/latest/#
[29] D. Zhang, Y. Wang, G. E. Suh, and A. C. Myers, “A Hardware
Design Language for Timing-Sensitive Information-Flow Security,” in
Proceedings of the Twentieth International Conference on Architectural
Support
for
Programming
Languages
and
Operating
Systems.
Istanbul Turkey: ACM, Mar. 2015, pp. 503–516. [Online]. Available:
https://dl.acm.org/doi/10.1145/2694344.2694372
[30] S. Deng, D. G¨um¨us¸o˘glu, W. Xiong, S. Sari, Y. S. Gener, C. Lu,
O.
Demir,
and
J.
Szefer,
“SecChisel
Framework
for
Security
Veriﬁcation of Secure Processor Architectures,” in Proceedings of the
8th International Workshop on Hardware and Architectural Support for
Security and Privacy.
Phoenix AZ USA: ACM, Jun. 2019, pp. 1–8.
[Online]. Available: https://dl.acm.org/doi/10.1145/3337167.3337174
APPENDIX
Rationale for Excluding Certain CWEs from Analysis
In this study we did not design “CWE scenarios” (Copilot
prompts) for a number of CWEs from the MITRE Top-25.
Generally, we omitted CWEs where CodeQL is not able to
be conﬁgured to detect that weakness, where considerable
context outside the source-code ﬁle is required for determining
its presence, or where the security issue is more architectural
rather than an issue stemming from a code-level mishap.
CWE-352:
Cross-Site
Request
Forgery
(CSRF).
This
compound-type (made from other CWEs) CWE covers
scenarios where a web application does not verify that a
request made by a user was intentionally made by them.
Common exploits are where the code of one web-app ‘hijacks’
another web-app. Determining the presence of this weakness is
tricky from a code analysis point of view. If they are manually
created, a scanner would need to ingest both the ‘front-end’
code (in HTML/Javascript) and compare it to the linked ‘back-
end’ code. Tools like CodeQL cannot check for this CWE.
Fortunately,
preventing
CWE-352
in
Python
web
applications is straightforward. For instance, in the ‘Flask’
framework used for our examples, the defense is made by
enabling the appropriate built-in extension.
CWE-287: Improper Authentication. As a class-type CWE,
this covers a large range of different scenarios where an actor
may claim to have a given identity but the software does not
sufﬁciently prove this claim. Given this nebulous description,
it is difﬁcult to describe concrete scenarios which evaluate
this CWE, especially given that this CWE is a parent of
CWE-306 and CWE-522. We thus do not analyze this CWE.
CWE-862: Missing Authorization. This class-type CWE
describes scenarios where no authorization check is performed
when users attempt to access critical resources or perform
sensitive actions. It is related to CWE-285, which was also
excluded. Errors related to this CWE would typically be
introduced as an architectural fault, rather than any speciﬁc
coding error.
CWE-276: Incorrect Default Permissions. This base-type
CWE covers situations where the default ‘permissions’
(access rights) for a given software’s ﬁles are set poorly
during installation, allowing any other user of the computer
to modify these ﬁles. It is a system or architectural-level
issue rather than a code-level issue.
CWE-611: Improper Restriction of XML External Entity
Reference. This base-type CWE applies to parsing XML ﬁles
contaning XML entities with references that resolve to doc-
uments outside the intended sphere of control. This requires
signiﬁcant context and code to determine if an implementation
is vulnerable and hence we excluded this from analysis.
CWE-918: Server-Side Request Forgery (SSRF). CWE-918
is a base-type CWE which refers to scenarios where web
applications receive URL requests from upstream components
and retreive the contents of these URLs without sufﬁciently
ensuring that the requests are being sent to expected
destinations. Similar to CWE-352, which was also excluded,
this CWE is difﬁcult to check, and requires examining
multiple interacting components and languages.
CWE-77: Improper Neutralization of Special Elements
used in a Command (’Command Injection’). This class-type
CWE covers scenarios where all or parts of commands are
built from user-controlled or upstream components, but does
not sufﬁciently neutralize special elements that could modify
the command when sent to downstream components. As this
is a parent class of both CWE-78 (OS command injection)
and CWE-89 (SQL Injection), both of which we analyzed,
we do not analyze this CWE.
Source and Dataset Access
The dataset containing the 89 CWE-based scenarios, as
well as the source code of the experimental framework,
is
available
for
download
at
the
following
URL:
https://doi.org/10.5281/zenodo.5225650.
Disclaimer
Any opinions, ﬁndings, and conclusions or recommenda-
tions expressed in this material are those of the author(s) and
do not necessarily reﬂect the views of the National Science
Foundation nor the Ofﬁce of Naval Research.