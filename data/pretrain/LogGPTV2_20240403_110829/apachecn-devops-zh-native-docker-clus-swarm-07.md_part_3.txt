```
docker run -ti fsoppelsa/spark-worker /spark/bin/run-example 
    SparkPi
```
在大量的输出信息之后，Spark 完成了计算，给出了我们:
```
...
Pi is roughly 3.14916
...
```
如果我们回到 Spark UI，我们可以看到我们惊人的 Pi 应用已经成功完成。
![Testing Spark](img/image_07_013.jpg)
更有趣的是运行一个连接到主服务器的交互式 Scala shell 来执行 Spark 作业:
```
$ docker run -ti fsoppelsa/spark-worker \
/spark/bin/spark-shell --master spark://:7077
```
![Testing Spark](img/image_07_014.jpg)
## 使用弗洛克储存
仅出于本教程的目的，我们现在使用之前创建的 spark 卷运行一个示例，以从 Spark 读取和写入一些持久性数据。
为了做到这一点，并且由于弗洛克对复制因子的限制，我们杀死了当前的三个工人，创建了一个只有一个工人的集合，安装火花:
```
$ docker service rm spark-worker
$ docker service create \
--constraint 'node.labels.type == sparkmaster' \
--network spark \
--name spark-worker \
--replicas 1 \
--env SPARK\_MASTER\_IP=10.0.0.3 \
--mount type=volume,target=/data,source=spark,volume-driver=flocker\
fsoppelsa/spark-worker
```
我们现在通过以下方式获得主机`aws-105`的 Docker 凭证:
```
$ eval $(docker-machine env aws-105) 
```
我们可以通过连接到 Spark 主容器来尝试在`/data`中写入一些数据。在本例中，我们只需将一些文本数据(lorem ipsum 的内容，例如可在[http://www.loremipsum.net](http://www.loremipsum.net/)获得)保存到`/data/file.txt`。
```
$ docker exec -ti 13ad1e671c8d bash
# echo "the content of lorem ipsum" > /data/file.txt
```
![Using Flocker storage](img/image_07_015.jpg)
然后，我们连接到 Spark shell 来执行一个简单的 Spark 作业:
1.  加载`file.txt`。
2.  将它包含的单词映射到它们出现的次数。
3.  Save the result in `/data/output`:
    ```
    $ docker exec -ti 13ad1e671c8d /spark/bin/spark-shell
    ...
    scala> val inFile = sc.textFile("file:/data/file.txt")
    scala> val counts = inFile.flatMap(line => line.split(" 
            ")).map(word => (word, 1)).reduceByKey(_ + _)
    scala> counts.saveAsTextFile("file:/data/output")
    scala> ^D
    ```
    ![Using Flocker storage](img/image_07_016.jpg)
现在，让我们在任何 Spark 节点上启动一个`busybox`容器，并检查`spark` 卷的内容，验证输出是否已写入。我们运行以下代码:
```
$ docker run -v spark:/data -ti busybox sh
# ls /data
# ls /data/output/
# cat /data/output/part-00000
```
![Using Flocker storage](img/image_07_017.jpg)
前面的截图显示了预期的输出。Flocker 卷的有趣之处在于，它们甚至可以从一台主机移动到另一台主机。许多操作可以用可靠的方式完成。如果你正在为 Docker 寻找一个好的存储解决方案，Flocker 是一个好主意。例如，Swisscom Developer cloud([http://developer.swisscom.com/](http://developer.swisscom.com/))在生产中使用了它，它允许您调配数据库，例如由 Flocker 技术支持的 **MongoDB** 。即将发布的弗洛克将致力于精简弗洛克代码库，使其更加精简和耐用。接下来要做的事情包括内置高可用性、快照、证书分发和容器中易于部署的代理。所以，前途一片光明！
# 缩放火花
现在我们来说明蜂群模式最惊人的特点-`scale`命令。我们恢复了在尝试 Flocker 之前的配置，因此我们销毁了`spark-worker`服务，并使用`3`的副本因子重新创建了它:
```
aws-101$ docker service create \
--constraint 'node.labels.type != sparkmaster' \
--network spark \
--name spark-worker \
--replicas 3 \
--env SPARK_MASTER_IP=10.0.0.3 \
--env SPARK\_WORKER\_CORES=1 \
--env SPARK\_WORKER\_MEMORY=1g \
fsoppelsa/spark-worker
```
现在，我们使用下面的代码通过`30` Spark 员工来扩展服务:
```
aws-101$ docker service scale spark-worker=30
```
几分钟后，最终需要拉出映像，我们再次检查:
![Scaling Spark](img/image_07_018.jpg)
从火花网络用户界面:
![Scaling Spark](img/image_07_019.jpg)
缩放可用于放大或缩小副本的大小。到目前为止，仍然没有用于自动扩展或向新添加的节点分配负载的自动化机制。但是它们可以用定制的实用程序来实现，或者我们甚至可以期待它们很快被集成到 Swarm 中。
# 监控群托管应用
2016 年 8 月，我(Fabrizio)在 Reddit([https://www . Reddit . com/r/docker/comments/4 zous 1/monitoring _ containers _ under _ 112 _ Swarm/](https://www.reddit.com/r/docker/comments/4zous1/monitoring_containers_under_112_swarm/))上关注一个线程，用户抱怨新的 Swarm Mode 更难监控。
如果说目前还没有官方的 Swarm 监控解决方案，那么新兴技术最受欢迎的组合之一就是:谷歌的 **cAdvisor** 收集数据， **Grafana** 展示图形， **Prometheus** 作为数据模型。
## 普罗米修斯
普罗米修斯的团队将该产品描述为:
> *Prometheus 是一个开源的系统监控和警报工具包，最初是在 SoundCloud 构建的。*
普罗米修斯的主要特点是:
*   多维数据模型
*   灵活的查询语言
*   不依赖分布式存储
*   时间序列收集通过拉模型进行
*   通过网关支持推送时间序列
*   支持多种绘图和仪表板模式
关于 https://prometheus.io/docs/introduction/overview/有一个很棒的介绍，我们在这里不再重复。在我们看来，普罗米修斯的首要特点是易于安装和使用。普罗米修斯本身只包含一个由 Go 代码构建的二进制文件，外加一个配置文件。
## 安装监控系统
事情可能很快就会发生变化，所以我们只是勾画了一个为 Swarm 建立监控系统的方法，在 Docker 1 . 12 . 3 版本上进行了尝试。
首先，我们创建一个新的覆盖网络来不干扰`ingress`或`spark`网络，称为`monitoring`:
```
aws-101$ docker network create --driver overlay monitoring
```
然后，我们在模式`global`下启动一个 cAdvisor 服务，这意味着一个 cAdvisor 容器将在每个 Swarm 节点上运行。我们在容器内安装了一些系统路径，以便 cAdvisor 可以访问:
```
aws-101$ docker service create \
 --mode global \
 --name cadvisor \
 --network monitoring \
 --mount type=bind,src=/var/lib/docker/,dst=/var/lib/docker \
 --mount type=bind,src=/,dst=/rootfs \
 --mount type=bind,src=/var/run,dst=/var/run \
 --publish 8080 \
 google/cadvisor
```
然后我们用`basi/prometheus-swarm`来建立普罗米修斯:
```
aws-101$ docker service create \
 --name prometheus \
 --network monitoring \
 --replicas 1 \
 --publish 9090:9090 \
 prom/prometheus-swarm
```
我们添加了`node-exporter`服务(同样`global`，必须在每个节点上运行):
```
aws-101$ docker service create \
 --mode global \
 --name node-exporter \
 --network monitoring \
 --publish 9100 \
 prom/node-exporter
```
最后，我们从一个副本开始 **Grafana** :
```
aws-101$ docker service create \
 --name grafana \
 --network monitoring \
 --publish 3000:3000 \
 --replicas 1 \
 -e "GF_SECURITY_ADMIN_PASSWORD=password" \
 -e "PROMETHEUS_ENDPOINT=http://prometheus:9090" \
 grafana/grafana
```
## 在格拉夫纳进口普罗米修斯
当 Grafana 可用时，为了获得令人印象深刻的 Swarm 运行状况图，我们使用以下凭证登录 Grafana 运行的节点，端口`3000`:
```
"admin":"password"
```
作为管理员，我们点击 Grafana 标志，进入**数据源**，添加`Prometheus`:
![Importing Prometheus in Grafana](img/image_07_020.jpg)
会出现一些选项，但是映射已经存在，所以**保存&测试**就足够了:
![Importing Prometheus in Grafana](img/image_07_021.jpg)
现在我们可以回到仪表板，点击**普罗米修斯**，这样我们将看到格拉夫纳主面板:
![Importing Prometheus in Grafana](img/image_07_022.jpg)
我们再次利用开源社区发布的东西，仅仅用一些简单的命令就将不同的固执己见的技术粘在一起，以获得期望的结果。监控 Docker Swarm 及其应用是一个现在完全开放的研究领域，因此我们也可以期待那里的惊人发展。
# 总结
在这一章中，我们使用 Flocker 为 Swarm 基础设施增加了存储容量，并设置了一个专用的覆盖网络，使我们的示例应用 Spark 集群能够在其上工作，并通过添加新节点(也在新的提供商上，如 DigitalOcean)而易于扩展。在使用了我们的 Spark 安装和 Flocker 之后，我们最终引入了 Prometheus 和 Grafana 来监控 Swarm 的健康和状态。在接下来的两章中，我们将看到可以插入 Swarm 的新的附加功能，以及如何保护 Swarm 基础设施。