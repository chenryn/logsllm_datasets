the Mahalanobis distance using the same divisor as the Eu-
clidean (normed) detector.
5.8. Nearest-neighbor (Mahalanobis)
This detector was described by Cho et al. [4].
In the
training phase, the detector saves the list of training vectors,
and calculates the covariance matrix. In the test phase, the
detector calculates the Mahalanobis distance between each
of the training vectors and the test vector. The anomaly
score is calculated as the distance from the test vector to the
nearest training vector.
5.9. Neural-network (standard)
This detector was described by Haider et al. [8]. It in-
corporates a feed-forward neural-network trained with the
back-propagation algorithm [5].
In the training phase, a
network is built with p input nodes, one output node, and
(cid:3)2p/3(cid:4) hidden nodes. The original detector was designed
speciﬁcally with 6 input nodes and 4 hidden nodes because
the researchers only considered 6-feature timing vectors.
Our vectors are 31-features long, so we extended their struc-
ture to include 31 input nodes while maintaining a ratio of
2 hidden nodes for every 3 input nodes.
The network weights were all initialized to 0.1, and the
bias term of each node was initialized randomly, as de-
scribed in the source study. The detector was trained to
produce a 1.0 on the output node for every training vector.
We trained for 500 epochs using a learning-rate parameter
of 0.0001. During testing, the test vector was run through
the network, and the output of the network was recorded. If
s denotes the output of the network, the anomaly score was
calculated as 1 − s since, intuitively, if s is close to 1.0, the
test vector is similar to the training vectors, and with s close
to 0.0, it is dissimilar.
5.10. Neural-network (auto-assoc)
This detector was described by Cho et al. [4], who called
it an “auto-associative, multilayer perceptron.” It also in-
corporates a feed-forward neural-network trained with the
back-propagation algorithm, but unlike a typical neural net-
work, the structure of the network is designed for use in an
anomaly detector [9]. Intuitively, the training phase teaches
the network to produce output vectors close to the inputs for
the training vectors (hence the “auto-associative” descrip-
tor). Then, during the test phase, input vectors that produce
dissimilar outputs are assigned high anomaly scores.
In the training phase, the neural network is constructed
with p input nodes and p output nodes (where p is the num-
ber of timing-vector features). We used p hidden nodes as
well (as described by one of the sources [4]). The network
is trained to reproduce each input timing vector as the out-
put. We trained for 500 epochs using a learning-rate of
0.0001 and a momentum parameter of 0.0003 (equivalent
to those reported by Cho and his colleagues since our times
are in seconds not milliseconds). In the test phase, the p-
feature test vector is run through the network, producing
a p-feature output vector. The Euclidean distance between
the test vector and the output vector is calculated and used
as the anomaly score.
5.11. Fuzzy-logic
This detector was described by Haider et al. [8]. It incor-
porates a fuzzy-logic inference procedure. The key idea is
that ranges of typing times are assigned to fuzzy sets (e.g.,
the times in the range of 210–290 milliseconds are part of
a set named “very fast”). The sets are called fuzzy because
elements can partially belong to a set (e.g., the time 255 is
strongly in the “very fast” set while 290 is only weakly a
member of the set).
In the training phase,
the detector determines how
strongly each feature belongs to each set, and each feature
is matched with the set in which its membership is strongest
(e.g. the t-hold-time feature will be matched with the “very
fast” set if most t hold times are around 255 milliseconds).
In the test phase, each timing feature is checked to see if
it belongs to the same set as the training data (e.g., the test
vector’s t hold time is checked for membership in the “very
fast” set). The anomaly score is calculated as the average
lack of membership across all test vector timing features.
Note that we added sets (e.g., “very very fast”) to accom-
modate faster times than seen in the source study.
5.12. Outlier-counting (z-score)
This detector was described by Haider et al. [8], who
called it the “statistical technique.” In the training phase,
the detector calculates the mean and standard deviation of
each timing feature.
In the test phase, the detector com-
putes the absolute z-score of each feature of the test vector.
The z-score for the i-th feature is calculated as |xi − yi| /si,
where xi and yi are the i-th features of the test and mean
vectors respectively and si is the standard deviation from
the training phase. The anomaly score is a count of how
many z-scores exceed a threshold (which was unspeciﬁed,
so we used 1.96, typical for outlier detection in this setting).
5.13. SVM (one-class)
This detector was described by Yu and Cho [21]. It in-
corporates an algorithm called a support-vector machine
(SVM),
that projects two classes of data into a high-
dimensional space and ﬁnds a linear separator between the
two classes. A “one-class” SVM variant was developed for
anomaly detection. It projects the data from a single class
and ﬁnds a separator between the projection and the origin.
In the training phase, the detector builds a one-class
SVM using the training vectors. In the test phase, the test
vector is projected into the same high-dimensional space
and the (signed) distance from the linear separator is calcu-
lated. The anomaly score is calculated as this distance, with
the sign inverted, so that positive scores are separated from
the data. The SVM parameter ν was set to 0.5; the source
study set ν with a “heuristic search” but did not elaborate.
5.14. k-means
This detector was described by Kang et al. [11]. It uses
the k-means clustering algorithm to identify clusters in the
training vectors, and then calculates whether the test vector
is close to any of the clusters.
In the training phase, the
detector simply runs the k-means algorithm on the training
data (with k = 3). The algorithm produces three centroids
such that each training vector should be close to at least one
of the three centroids. In the test phase, the anomaly score is
calculated as the Euclidean distance between the test vector
and the nearest of these centroids.
6. Evaluation methodology
The ﬁnal step was to evaluate each of the 14 detectors
using the password-timing data. Each detector was trained
and tested using the same procedure, and the anomaly
scores output by each detector were converted into standard
measures of error.
6.1. Training and testing the detectors
Consider a scenario in which a user’s long-time pass-
word has been compromised by an impostor. The user is
assumed to be practiced in typing their password, while the
impostor is unfamiliar with it (e.g., typing it for the ﬁrst
time). We measure how well each of our detectors is able to
discriminate between the impostor’s typing and the genuine
user’s typing in this scenario.
We start by designating one of our 51 subjects as the gen-
uine user, and the rest as impostors. We train an anomaly
detector and test its ability to recognize the genuine user and
impostors as follows:
1. We run the training phase of the detector on the timing
vectors from the ﬁrst 200 password repetitions typed by
the the genuine user. The detector builds a model of the
user’s typing behavior.
2. Then, we run the test phase of the detector on the timing
vectors from the remaining 200 repetitions typed by the
genuine user. We record the anomaly scores assigned to
each timing vector as user scores.
3. Finally, we run the test phase of the detector on the tim-
ing vectors from the ﬁrst ﬁve repetitions typed by each
of the 50 impostors. We record the anomaly scores as-
signed to each timing vector as impostor scores.
This process is then repeated, designating each of the other
subjects as the genuine user in turn. After training and test-
ing each of the 14 detectors, we have a total of 741 sets of
user and impostor scores (51 subjects × 14 detectors).
It may seem that 200 repetitions is an unrealistically
large amount of training data. We were concerned that
fewer passwords might unfairly cause one or more detec-
tors to under-perform (e.g., Table 1 shows detectors trained
with up to 325 passwords). Likewise, an unpracticed impos-
tor might seem unrealistic, since impostors might practice if
Nearest Neighbor (Mahalanobis)
Subject 19
zero−miss rate
equal−error rate
e
t
a
R
t
i
H
0
.
1
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
0.0
0.2
0.4
0.6
0.8
1.0
False Alarm Rate
Figure 1. An example ROC curve depicts the
performance of the Nearest Neighbor (Maha-
lanobis) detector with subject 19 as the gen-
uine user. The curve shows the trade-off be-
tween the hit rate and the false-alarm rate.
Proximity to the top-left corner of the graph
is a visual measure of performance.
they knew timing mattered. We believe that our choices are
fair for a ﬁrst evaluation; experiments involving fewer train-
ing repetitions and more practiced impostors are planned.
6.2. Calculating detector performance
To measure detector performance, we used the scores
to generate a graphical summary of performance called an
ROC curve [20]. An example ROC curve is shown in Fig-
ure 1. The hit rate is the frequency with which impostors
are detected (i.e., 1 − miss rate), and the false-alarm rate
is the frequency with which genuine users are mistakenly
detected as impostors. Whether or not a password gener-
ates an alarm depends on how the threshold on the anomaly
scores is chosen. The choice of threshold establishes the
operating point of the detector on the ROC curve. Over the
continuum of possible thresholds, the ROC curve illustrates
the hit and false-alarm rates that would be attained at each
possible detector operating point.
The ROC curve is a common visualization of a detector’s
accuracy, and on the basis of the ROC curve, various mea-
sures of error can be derived. Table 1 lists several studies
that have chosen a threshold using detector-speciﬁc heuris-
tics. As the ROC curve shows, the nature of these heuristics
could have a major effect on the reported miss and false-
alarm rates. Further, if different heuristics are used for dif-
ferent detectors, comparing detector performance becomes
difﬁcult.
Two measures are commonly used for determining a
Detector
SVM (one-class)
equal-error rate
1 Manhattan (scaled)
0.096 (0.069)
2 Nearest Neighbor (Mahalanobis) 0.100 (0.064)
3 Outlier Count (z-score)
0.102 (0.077)
0.102 (0.065)
4
5 Mahalanobis
0.110 (0.065)
0.110 (0.065)
6 Mahalanobis (normed)
0.136 (0.083)
7 Manhattan (ﬁlter)
0.153 (0.092)
8 Manhattan
0.161 (0.080)
9 Neural Network (auto-assoc)
10 Euclidean
0.171 (0.095)
0.215 (0.119)
11 Euclidean (normed)
0.221 (0.105)
12 Fuzzy Logic
13 k Means
0.372 (0.139)
14 Neural Network (standard)
0.828 (0.148)
Detector
SVM (one-class)
zero-miss false-alarm rate
1 Nearest Neighbor (Mahalanobis) 0.468 (0.272)
0.482 (0.273)
2 Mahalanobis
0.482 (0.273)
3 Mahalanobis (normed)
0.504 (0.316)
4
5 Manhattan (scaled)
0.601 (0.337)
0.757 (0.282)
6 Manhattan (ﬁlter)
7 Outlier Count (z-score)
0.782 (0.306)
0.843 (0.242)
8 Manhattan
0.859 (0.220)
9 Neural Network (auto-assoc)
10 Euclidean
0.875 (0.200)
0.911 (0.148)
11 Euclidean (normed)
0.935 (0.108)
12 Fuzzy Logic
13 k Means
0.989 (0.040)
14 Neural Network (standard)
1.000 (0.000)
Table 2. The average equal-error rates (left side) and average zero-miss false-alarm rates (right side)