[0, 0, 0, 1, 0]
[0, 0, 0, 0, 1]
Extra Args
N/A
T : 0, N : 1
T : 0, N : 1
T : 0, N : 1
T : 0, N : 1
T : 0, N : 1
T : 0, N : 1
T : 3, M: 4
N/A
Output
0
[#f , #f , #f , #f , #t]
[#f , #f , #f , #f , #t]
[#f , #f , #f , #f , #t]
[0, 0, 0, 0, 1]
[0, 0, 0, 0, 17]
[0, 0, 0, 0, 0]
[#f , #f , #f , #f , #t]
0
3
4
4
4
4
8
4
4
3
Iterations Time(s)
StatDP [23]
5.7
3.2
2.0
2.1
5.7
14.2
8.6
6.3
3.7
11.2
4.9
15.6
9.1
10.6
3.8
Search Failed
Search Failed
22.4 (Semi-Manual)
DP-Finder [14]
2561.5
3847.5 (Semi-Manual)
4126.1 (Semi-Manual)
3476.2 (Semi-Manual)
11611.6 (Semi-Manual)
Search Failed
Search Failed
Search Failed
1128.5
DiPC [4]
N/A
N/A
N/A
269
N/A
N/A
N/A
N/A
N/A
Table 2: Alignments found for the correct algorithms. Ω∗ stands for the branch condition in each mechanism, where ΩN M =
q[i] + η > bq ∨ i = 0, ΩSV T = q[i] + η2 ≥ Tη, ΩT op = q[i] + η2 − Tη ≥ σ, ΩMiddle = q[i] + η3 − Tη ≥ 0
Mechanism
ReportNoisyMax
PartialSum
SmartSum
SVT
Monotone SVT (Increase)
Monotone SVT (Decrease)
GapSVT
NumSVT
AdaptiveSVT
η1
ΩN M ? 1 −(cid:98)q[i] : 0
−sum
−sum −(cid:98)q[i]
1
0
0
1
1
1
Alignment
η2
N/A
N/A
−(cid:98)q[i]
η3
N/A
N/A
N/A
N/A
N/A
N/A
N/A
ΩSV T ? 1 −(cid:98)q[i] : 0
ΩSV T ? 1 −(cid:98)q[i] : 0
ΩSV T ? −(cid:98)q[i] : 0
ΩSV T ? 1 −(cid:98)q[i] : 0
ΩT op ? 1 −(cid:98)q[i] : 0 ΩMiddl e ? 1 −(cid:98)q[i] : 0
−(cid:98)q[i]
ΩSV T ? 2 : 0
Iterations Time (s)
ShadowDP [50] Coupling [3]
DiPC [4]
10
2
6
4
8
8
6
4
10
69.3
5.6
6.8
6.2
18.4
20.5
13.5
8.8
25.6
Manual
Manual
Manual
Manual
N/A
N/A
Manual
Manual
N/A
22
14
255
580
N/A
N/A
N/A
5
N/A
193
N/A
N/A
825
N/A
N/A
N/A
N/A
N/A
of CheckDP and expressiveness of our template generation algo-
rithm, we also evaluate on a couple of correct/incorrect mechanisms
that, to the best of our knowledge, have not been proved/disproved
by existing verifiers and counterexample generators. This set of
mechanisms include: Sparse Vector with monotonic queries [40],
AdaptiveSVT (called Adaptive Sparse Vector with Gap in [24]) as
well as new incorrect variants of SVT, AdaptiveSVT and SmartSum.
For all mechanisms we explore, CheckDP is able to: (1) provide a
proof if it satisfies differential privacy, or (2) provide a counterexam-
ple if it violates the claimed level of privacy. Neither false positives
nor false negatives were observed. In this section, we discuss the
new cases; detailed explanations can be found in the Appendix.
Sparse Vector with Monotonic Queries. The queries in some usages
of SVT are monotonic. In such cases, a Lap 2N/ϵ noise (instead of
Lap 4N/ϵ in SVT) is sufficient for ϵ-privacy [40].
AdaptiveSVT, BadAdaptiveSVT and BadSmartSum. Ding et al. [24]
recently proposed a new variant of SVT which adaptively allocates
privacy budget, saving privacy cost when noisy query answers are
much larger than the noisy threshold. The difference from standard
(correct) SVT is that it first draws a η2 := Lap 8N/ϵ noise (instead
of Lap 4N/ϵ in SVT) and checks if the gap between noisy query and
noisy threshold Tη is larger than a preset hyper-parameter σ (if
q[i] + η2 - Tη ≥ σ). If the test succeeds, the gap is directly returned,
hence costing only ϵ/(8N) (instead of ϵ/(4N)) privacy budget. Oth-
erwise, it draws η3 := Lap 4N/ϵ and follows the same procedure
as SVT. We also create an incorrect variant called BadAdaptiveSVT.
It directly releases the noisy query answer instead of the gap after
the first test. Sampling-based methods can have difficulty detecting
the privacy leakage because the privacy-violating branch of the
BadAdaptiveSVT code is not executed frequently. We also create
an incorrect variant of SmartSum by releasing a noise-less sum
11
of queries in an infrequent branch. Details of SmartSum and this
variant can be found in the Appendix.
SVT with Wrong Privacy Claims (Imprecise SVT). We also study
another interesting yet quite challenging violation of differential
privacy: suppose a mechanism satisfies 1.1-differential privacy but
claims to be 1-differentially private. This slight violation requires
precise reasoning about the privacy cost and poses challenges for
prior sampling-based approaches. We thus evaluate a variant of SVT,
referred to as Imprecise SVT, which is ϵ = 1.1-differentially private
but with an incorrect claim of ϵ = 1 (check(1) in the signature).
5.2 Experiments
We evaluate CheckDP on a Intel® Xeon® E5-2620 v4 CPU machine
with 64 GB memory. To compare CheckDP with the state-of-the-art
tools, we either directly run tools on the benchmark when they
are publicly available (including ShadowDP [50], StatDP [23] and
DP-Finder [14]), or cite the reported results from the corresponding
papers (including Coupling [3] and DiPC [4]).5 For the latter case,
we note that the numbers are for reference only, due to different
settings, including hardware, used in the experiments.
Counterexample Generation. Table 1 lists the counterexamples
(i.e., a pair of related inputs and a feasible output that witness the
violation of claimed level of privacy) automatically generated by
CheckDP for the incorrect algorithms. For all incorrect algorithms,
CheckDP is able to provide a counterexample (validated by PSI [33])
in 15 seconds and 8 iterations.6
Notably, both StatDP and DP-Finder fail to find the privacy viola-
tions in BadSmartSum and BadAdaptiveSVT, as well as the violation
5Default settings are used in our evaluation: 100K/500K samples for event selection/hy-
pothesis testing components of StatDP; 50 iterations for sampling and optimization
components of DP-Finder where each iteration collects 409,600 samples on average.
6We note that the counterexample of BadSmartSum is validated on a slightly modified
algorithm since PSI does not support modulo operation.
of ϵ = 1-privacy in Imprecise SVT after hours of searching.7 This
is due to the limitations of sampling-based approaches. In certain
cases, we can help these sampling-based algorithms by manually
providing proper values for the extra arguments that some of the
mechanisms require (4th column of Table 1). This extra advantage
(labeled Semi-Manual in the table) sometimes allows the sampling-
based methods to find counterexamples. We note that CheckDP, in
contrast, generates all inputs automatically.
Verification. Table 2 lists the automatically generated proofs (i.e.,
alignments) for each random variable in the correct algorithms.
Due to the soundness of CheckDP, all returned proofs are valid.
We note that correct algorithms on average take more iterations
(and hence, time) to verify; still all of them are verified within 70
seconds. . Report Noisy Max is the only example that uses shadow
execution; the selector generated is S = q[i] +η2 ≥ bq∨i = 0?†:◦,
the same as the manually generated one in [50].
Performance. We note that all examples finish within 10 itera-
tions. We contribute the efficiency to the reduced search space of
Algorithm 1 (e.g., the alignment template for GapSVT only con-
tains 7 “holes”) as well as our novel verify-invalidate loop that
allows verification and counterexample generation components
to communicate in meaningful ways. Compared with StatDP and
DP-Finder, CheckDP is more efficient on the cases where they do
find counterexamples. Compared with static tools [3, 4], we note
that CheckDP is much faster on BadSVT3, SmartSum and SVT. In
summary, CheckDP is mostly more efficient compared to coun-
terexample detectors and automated provers.
6 RELATED WORK
Proving and Disproving Differential Privacy. Concurrent works [4,
30] also target both proving and disproving differential privacy.
Barthe et al. [4] identify a non-trivial class of programs where
checking differential privacy is decidable. Their work also supports
approximate differential privacy. However, the decidable programs
only allow finite inputs and outputs, while CheckDP is applicable to
a larger class of programs. Moreover, CheckDP is more scalable, as
observed in our evaluation. Farina [30] builds a relational symbolic
execution framework, which when combined with probabilistic
couplings, is able to prove differential privacy or generate failing
traces for SVT and its two incorrect variants. However, it is unclear
if the employed heuristic strategies work on other mechanisms,
such as Report Noisy Max. Moreover, CheckDP is likely to be more
scalable since their approach treats both program inputs and proofs
in a symbolic way, whereas in the novel verify-invalidate loop of
CheckDP, either program inputs or proofs are concrete.
Formal Verification of Differential Privacy. From the verification
perspective, CheckDP is mostly related to LightDP [51] and Shad-
owDP [50] – all use randomness alignment. The type system of
CheckDP is directly inspired by that of [50, 51]. However, the most
important difference is that CheckDP is the first that automati-
cally generates alignment-based proofs; both LightDP and Shad-
owDP assume manually-provided proofs. As discussed in Section 3,
CheckDP also simplifies the previous type systems and defers all
7For StatDP, we use 1000X of the default number of samples to confirm the failure.
12
privacy-related checks to later stages. Both changes are important
for automatically generating proofs and counterexamples.
Besides alignment-based proofs, probabilistic couplings and lift-
ings [3, 7, 9] have also been used in language-based verification
of differential privacy. Most notably, Albarghouthi and Hsu [3]
proposed the first automated tool capable of generating coupling
proofs for complex mechanisms. Coupling proofs are known to be
more general than alignment-based proofs, while alignment-based
proofs are more light-weight. Since CheckDP and [3] are built on
different proof techniques, the proof generation algorithm in [3]
is not directly applicable in our context. Moreover, [3] does not
generate counterexamples and we do not see an obvious way to
extend the Synthesize-Verify loop of [3] to do so .
With verified privacy mechanisms, such as SVT and Report Noisy
Max, we still need to verify that the larger program built on top of
them is differentially private. An early line of work [8, 10, 11, 32, 44]
uses (variations of) relational Hoare logic and linear indexed types
to derive differential privacy guarantees. For example, Fuzz [44]
and its successor DFuzz[32] combine linear indexed types and light-
weight dependent types to allow rich sensitivity analysis and then
use the composition theorem to prove overall system privacy. We
note that CheckDP and those systems are largely orthogonal: those
systems rely on trusted mechanisms (e.g., SVT and Report Noisy
Max) without verifying them, while CheckDP is likely less scalable;