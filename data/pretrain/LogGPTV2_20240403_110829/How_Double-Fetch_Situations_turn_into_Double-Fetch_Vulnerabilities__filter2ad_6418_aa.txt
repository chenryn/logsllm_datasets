title:How Double-Fetch Situations turn into Double-Fetch Vulnerabilities:
A Study of Double Fetches in the Linux Kernel
author:Pengfei Wang and
Jens Krinke and
Kai Lu and
Gen Li and
Steve Dodier-Lazaro
How Double-Fetch Situations turn into Double-
Fetch Vulnerabilities: A Study of Double Fetches  
in the Linux Kernel
Pengfei Wang, National University of Defense Technology; Jens Krinke, University College 
London; Kai Lu and Gen Li, National University of Defense Technology;  
Steve Dodier-Lazaro, University College London
https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/wang-pengfei
This paper is included in the Proceedings of the 26th USENIX Security SymposiumAugust 16–18, 2017 • Vancouver, BC, CanadaISBN 978-1-931971-40-9Open access to the Proceedings of the 26th USENIX Security Symposium is sponsored by USENIXHow Double-Fetch Situations turn into Double-Fetch Vulnerabilities:
A Study of Double Fetches in the Linux Kernel
Pengfei Wang
National University of Defense Technology
Jens Krinke
University College London
National University of Defense Technology
Kai Lu
National University of Defense Technology
Gen Li
Steve Dodier-Lazaro
University College London
Abstract
We present the ﬁrst static approach that systematically
detects potential double-fetch vulnerabilities in the Linux
kernel. Using a pattern-based analysis, we identiﬁed 90
double fetches in the Linux kernel. 57 of these occur
in drivers, which previous dynamic approaches were un-
able to detect without access to the corresponding hard-
ware. We manually investigated the 90 occurrences, and
inferred three typical scenarios in which double fetches
occur. We discuss each of them in detail. We further de-
veloped a static analysis, based on the Coccinelle match-
ing engine, that detects double-fetch situations which can
cause kernel vulnerabilities. When applied to the Linux,
FreeBSD, and Android kernels, our approach found six
previously unknown double-fetch bugs, four of them in
drivers, three of which are exploitable double-fetch vul-
nerabilities. All of the identiﬁed bugs and vulnerabilities
have been conﬁrmed and patched by maintainers. Our
approach has been adopted by the Coccinelle team and
is currently being integrated into the Linux kernel patch
vetting. Based on our study, we also provide practical so-
lutions for anticipating double-fetch bugs and vulnerabil-
ities. We also provide a solution to automatically patch
detected double-fetch bugs.
1
Introduction
The wide use of multi-core hardware is making concur-
rent programs increasingly pervasive, especially in oper-
ating systems, real-time systems and computing inten-
sive systems. However, concurrent programs are also
notorious for diﬃcult to detect concurrency bugs. Real-
world concurrency bugs can be categorized into three
types: atomicity-violation bugs, order-violation bugs,
and deadlocks [20].
A data race is another common situation in concurrent
programs. It occurs when two threads are accessing one
shared memory location, at least one of the two accesses
is a write, and the relative ordering of the two accesses is
not enforced by any synchronization primitives [30, 15].
Data races usually lead to concurrency bugs because
they can cause atomicity-violations [22, 21, 23] or order-
violations [33, 40]. In addition to occurring between two
threads, data races can also happen across the kernel and
user space. Serna [32] was the ﬁrst to use the term “dou-
ble fetch” to describe a Windows kernel vulnerability
due to a race condition in which the kernel fetches the
same user space data twice. A double-fetch bug occurs
when the kernel reads and uses the same value that re-
sides in the user space twice (expecting it to be identi-
cal both times), while a concurrently running user thread
can modify the value in the time window between the
two kernel reads. Double-fetch bugs introduce data in-
consistencies in the kernel code, leading to exploitable
vulnerabilities such as buﬀer overﬂows [1, 32, 14, 37].
Jurczyk and Coldwind [14] were the ﬁrst to study dou-
ble fetches systematically. Their dynamic approach de-
tected double fetches by tracing memory accesses and
they discovered a series of double-fetch vulnerabilities in
the Windows kernel. However, their dynamic approach
can achieve only limited coverage. In particular, it can-
not be applied to code that needs corresponding hard-
ware to be executed, so device drivers cannot be analyzed
without access to the device or a simulation of it. Thus,
their analysis cannot cover the entirety of the kernel. In
fact, their approach has not discovered any double-fetch
vulnerability in Linux, FreeBSD or OpenBSD [13]. Be-
sides, Jurczyk and Coldwind have brought attention to
not only on how to ﬁnd but also on how to exploit double-
fetch vulnerabilities. Instructions on how to exploit dou-
ble fetches have recently become publicly available [11].
Thus, auditing kernels, in particular drivers, for double-
fetch vulnerabilities has become urgent.
Device drivers are critical kernel-level programs that
bridge hardware and software by providing interfaces be-
tween the operating system and the devices attached to
the system. Drivers are a large part of current operat-
USENIX Association
26th USENIX Security Symposium    1
ing systems, e.g., 44% of the Linux 4.5 source ﬁles be-
long to drivers. Drivers were found to be particularly
bug-prone kernel components. Chou et al. [7] empiri-
cally showed that the error-rate in device drivers is about
ten times higher than in any other parts of the kernel.
Swift et al. [34] also found that 85% of system crashes
in Windows XP can be blamed on driver errors. Further-
more, Ryzhyk et al. [29] found that 19% of the bugs in
drivers were concurrency bugs, and most of them were
data races or deadlocks.
Because drivers are such a critical point of failure in
kernels, they must be analyzed for security vulnerabili-
ties even when their corresponding hardware is not avail-
able. Indeed, 26% of the Linux kernel source ﬁles belong
to hardware architectures other than x86 which cannot be
analyzed with Jurczyk and Coldwind’s x86-based tech-
nique. Thus, dynamic analysis is not a viable, aﬀordable
approach. Therefore, we developed a static pattern-based
approach to identify double fetches in the Linux kernel,
including the complete space of drivers. We identiﬁed 90
double fetches which we then investigated and catego-
rized into three typical scenarios in which double fetches
occur. We found that most double fetches are not double-
fetch bugs because although the kernel fetches the same
data twice, it only uses the data from one of the two
fetches. We therefore reﬁned the static pattern-based ap-
proach to detect actual double-fetch bugs and vulnera-
bilities, and analyzed Linux, Android and FreeBSD with
it.
We found that most of the double fetches in Linux 4.5
occur in drivers (57/90) and so do most of the identiﬁed
double-fetch bugs (4/5). This means dynamic analysis
methods fail to detect a majority of double fetch bugs,
unless researchers have access to the complete range of
hardware compatible with the kernel they analyze. This
is conﬁrmed by a comparison with Bochspwn, a dynamic
analysis approach, which was unable to ﬁnd any double-
fetch bug in Linux 3.5.0 [13] where our approach ﬁnds
three. In summary, we make the following contributions
in this paper:
(1) First systematic study of double fetches in the
Linux kernel. We present the ﬁrst (to the best of our
knowledge) study of double fetches in the complete
Linux kernel, including an analysis of how and why a
double fetch occurs. We used pattern matching to auto-
matically identify 90 double-fetch situations in the Linux
kernel, and investigated those candidates by manually
reviewing the kernel source. We categorize the identi-
ﬁed double fetches into three typical scenarios (type se-
lection, size checking, shallow copy) in which double
fetches are prone to occur, and illustrate each scenario
with a detailed double fetch case analysis. Most (57/90)
of the identiﬁed double fetches occur in drivers.
(2) A pattern-based double-fetch bug detection ap-
proach. We developed a static pattern-based approach to
detect double-fetch bugs1. The approach has been imple-
mented on the Coccinelle program matching and trans-
formation engine [17] and has been adapted for check-
ing the Linux, FreeBSD, and Android kernels. It is the
ﬁrst approach able to detect double-fetch vulnerabilities
in the complete kernel including all drivers and all hard-
ware architectures. Our approach has been adopted by
the Coccinelle team and is currently being integrated into
the Linux kernel patch vetting through Coccinelle.
(3) Identiﬁcation of six double-fetch bugs. In total, we
found six real double-fetch bugs. Four are in the drivers
of Linux 4.5 and three of them are exploitable vulner-
abilities. Moreover, all four driver-related double-fetch
bugs belong to the same size checking scenario. The bugs
have been conﬁrmed by the Linux maintainers and have
been ﬁxed in new versions as a result of our reports. One
double-fetch vulnerability has been found in the Android
6.0.1 kernel, which was already ﬁxed in newer Linux ker-
nels.
(4) Strategies for double-fetch bug prevention. Based
on our study, we propose ﬁve solutions to anticipate
double-fetch bugs and we implemented one of the strate-
gies in a tool that automatically patches double-fetch
bugs.
The rest of the paper is organized as follows: Sec-
tion 2 presents relevant background on memory access in
Linux, speciﬁcally in Linux drivers, and on how double-
fetch bugs occur. Section 3 introduces our approach to
double fetch detection, including our analysis process,
the categorization of the identiﬁed double fetches into
three scenarios, and what we learned from the identi-
ﬁed double-fetch bugs. Section 4 presents the evaluation
of our work, including statistics on the manual analysis
and the results of applying our approach to the Linux,
FreeBSD, and Android kernels. Section 5 discusses the
detected bugs, implications of double-fetch bug preven-
tion, an interpretation of our ﬁndings, as well as limi-
tations of our approach. Related work is discussed in
Section 6, followed by conclusions.
2 Background
We provide readers with a reminder of how data is ex-
changed between the Linux kernel and its drivers and the
user space, and of how race conditions and double-fetch
bugs can occur within this framework.
1Our analysis is available at https://github.com/UCL-CREST/
doublefetch
2    26th USENIX Security Symposium
USENIX Association
2.1 Kernel/User Space Protection
In modern computer systems, memory is divided into
kernel space and user space. The kernel space is where
the kernel code executes and where its internal data is
stored, while the user space is where normal user pro-
cesses run. Each user space process resides in its own
address space, and can only address memory within that
space. Those virtual address spaces are mapped onto
physical memory by the kernel in such a way that iso-
lation between separate spaces is guaranteed. The kernel
also has its own independent address space.
Special schemes are provided by the operating sys-
tem to exchange data between kernel and user space.
In Windows, we can use the device input and output
control (IOCTL) method, or a shared memory object
method to exchange data between kernel and user space2
which is very similar to shared memory regions.
In
Linux and FreeBSD, functions are provided to safely
transfer data between kernel space and user space which
we call transfer functions.
For instance, Linux has
four often used transfer functions, copy_from_user(),
copy_to_user(), get_user(), and put_user(), that
copy single values or an arbitrary amount of data to
and from user space in a safe way. Transfer functions
not only exchange data between kernel and user space
but also provide a protection mechanism against invalid
memory access, such as illegal addresses or page faults.
Therefore, any double fetch in Linux will involve multi-
ple invocations of transfer functions.
2.2 Memory Access in Drivers
Device drivers are kernel components responsible for en-
abling the kernel to communicate with and make use of
hardware devices connected to the system. Drivers have
typical characteristics, such as support for synchronous
and asynchronous operations and the ability to be opened
multiple times [8]. Drivers are critical to security be-
cause faults in them can result in vulnerabilities that
grant control of the whole system. Finally, drivers of-
ten have to copy messages of variable type or variable
length from the user space to the hardware, and, as we
will see later, this often leads to double-fetch situations
that cause vulnerabilities.
In Linux, all devices have a ﬁle representation which
can be accessed from user space to interact with the hard-
ware’s driver. The kernel creates a ﬁle in the /dev di-
rectory for each driver, with which user space processes
can interact using ﬁle input/output system calls. The
driver provides implementations of all ﬁle related op-
erations, including read() and write() functions. In
such functions, the driver needs to fetch the data from
2https://support.microsoft.com/en-us/kb/191840
Figure 1: Principal Double Fetch Race Condition
the user space (in write) or copy data to the user space
(in read). The driver uses the transfer functions to do so,
and again, any double fetch will involve multiple invoca-
tions of transfer functions.
2.3 Double Fetch
A double fetch is a special case of a race condition
that occurs in memory access between the kernel and
user space. The ﬁrst vulnerability of this type was pre-
sented by Serna [32] in a report on Windows double-
fetch vulnerabilities. Technically, a double fetch takes
place within a kernel function, such as a syscall, which
is invoked by a user application from user mode. As il-
lustrated in Figure 1, the kernel function fetches a value
twice from the same memory location in the user space,
the ﬁrst time to check and verify it and the second time to
use it (note that the events are on a timeline from left to
right, but the user data is the same object all the time).
Meanwhile, within the time window between the two
kernel fetches, a concurrently running user thread modi-
ﬁes the value. Then, when the kernel function fetches the
value a second time to use, it gets a diﬀerent value, which
will not only result in a diﬀerent computation outcome,
but may cause a buﬀer overﬂow, a null-pointer crash or
even worse consequences.
To avoid confusion, we use the term double fetch or
double-fetch situation in this paper to represent all the
situations in which the kernel fetches the same user data
more than once, and a so-called double fetch can be fur-
ther divided into the following cases:
Benign double fetch: A benign double fetch is a case
that will not cause harm, owing to additional protection
schemes or because the double-fetched value is not used
twice (details will be discussed in Section 5.3).
Harmful double fetch: A harmful double fetch or
a double-fetch bug is a double fetch that could actually
cause failures in the kernel in speciﬁc situations, e.g., a
race condition that could be triggered by a user process.
Double-fetch vulnerability: A double-fetch bug can
also turn into a double-fetch vulnerability once the conse-
quence caused by the race condition is exploitable, such
USENIX Association
26th USENIX Security Symposium    3
preparedataclonesyscallmaliciousupdate1st fetch(check)2nd fetch(real use)entryKernel SpaceUser Spaceuser datatimereturn -EINVAL;
return -EINVAL;
if(CMSG_COMPAT_ALIGN(ucmlen)  kmsg->msg_controllen)
if(get_user(ucmlen, &ucmsg->cmsg_len))
return -EFAULT;
struct compat_cmsghdr __user *ucmsg;
struct cmsghdr *kcmsg, *kcmsg_base;
compat_size_t ucmlen;
kcmsg_base = kcmsg = (struct cmsghdr *)stackbuf;
ucmsg = CMSG_COMPAT_FIRSTHDR(kmsg);
while(ucmsg != NULL) {
140 int cmsghdr_from_user_compat_to_kern(struct msghdr *kmsg,
unsigned char *stackbuf, int stackbuf_size)
141
142 {
143
144
145
...
149
150
151
152
153
...
156
157
158
159
160
161
...
166
167
168 if(kcmlen == 0)
169
...
183
184 while(ucmsg != NULL) {
185
186
187
188
...
193
194
195
...
212 }
CMSG_COMPAT_DATA(ucmsg),
(ucmlen - CMSG_COMPAT_ALIGN(sizeof(*ucmsg)))))
__get_user(ucmlen, &ucmsg->cmsg_len);
tmp = ((ucmlen - CMSG_COMPAT_ALIGN(sizeof(*ucmsg))) +
CMSG_ALIGN(sizeof(struct cmsghdr)));
}