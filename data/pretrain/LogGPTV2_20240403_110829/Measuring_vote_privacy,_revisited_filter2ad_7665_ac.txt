worst possible outcome from a privacy point of view, which hap-
∞(v1 | ρ) = − log(1) = 0. This ab-
pens when ρ is not empty: H⊥
sence of entropy reﬂects that there is an election outcome for which
v1 has no privacy at all. Besides these two natural questions, the
conditional min-entropy measures the average of the min-entropy
2 · 0 + 1
2 · 100 = 50.
on all possible outcomes: H∞(v1 | ρ) = 1
This last measure seems much less useful however.
Hartley entropy based notions. A second natural question for P1
is: “In how many different ways can I pretend that I have voted?”
The answer to this question is given using Hartley entropy and,
in particular, by the min-Hartley entropy which gives a measure
945of the minimum number of ways P1 is guaranteed to be able to
0 (v1 | ρ) = log(1) = 0. This reﬂects
pretend that he has voted: H⊥
the case where ρ reveals P (cid:48)
1s choice. The average Hartley entropy
gives a measure of the number of ways P1 can expect to be able to
pretend he voted: ˜H0(v1 | ρ) = log` 1
2 · 2100´ ≈ 99. This
2 · 1 + 1
information of an average equivocation level of 299 seems however
less useful: while being correct, it hides the fact that, in half of the
cases, there is no ambiguity left on the vote. Conditional Hartley
entropy seems even less useful.
Another observation can be made of the min-Hartley entropy:
just as the classic Hartley entropy, this notion does not require any
probabilities: it only reﬂects the size of the smallest set in a set of
sets. So, this measure can be used meaningfully even when one
ignores the probability distribution of the honest votes, but only
know which votes are possible.
Shannon entropy based notions. Shannon entropy measures the
average number of extra bits of information that an observer would
need to determine a vote (or any other target) given the election
outcome. We should however keep in mind that Shannon entropy
remains an average notion: the measure we get here is the average
number of bits needed for the worst possible outcome. So, even if
the minimal Shannon entropy is very high, it remains possible that
some votes could be identiﬁed with a single extra bit of informa-
tion.
The minimal Shannon entropy gives that measure for the worst
possible outcome from a privacy point of view: H⊥(v1 | ρ) =
0, which reﬂects the case where ρ is not empty. The conditional
2 · 0 +
Shannon entropy gives the average case: H(v1 | ρ) = 1
2 · 100 = 50. This measure reﬂects that, in half of the cases, the
1
choice of P1 keeps 100 bits of Shannon entropy and 0 bits in the
remaining cases. It however seems even less informative than the
previous one, as it hides the worst case which happens with high
probability. Average Shannon entropy seems also quite unnatural
in our context.
three entropy notions provide useful information:
Conclusion Our analysis of the example above shows that at least
• Average min-entropy measures, for a given distribution of
the votes, the probability that an observer guesses the target
function of the votes.
• Min min-entropy measures the probability that an observer
guesses the target function of the votes for the worst possible
election outcome that is in the support of the vote distribu-
tion.
• Min Hartley entropy measures the minimum number of val-
ues that the target function can take for any assignment of the
votes.
This last notion can be particularly convenient when the distribu-
tion of the votes is unknown and as an indication of the level of
deniability that voters can expect.
Other entropy notions might be of interest in speciﬁc cases.
5. DISCUSSION AND EXAMPLES
In this section, we test the robustness and meaningfulness of our
privacy measures in several different ways.
We ﬁrst demonstrate that, for ideal elections where all that the
adversary sees are the choices made by the corrupted voters and
the election outcome, our computational privacy measures coin-
cide with the corresponding purely information theoretic measures
and identify the worst adversary from a privacy point of view. We
believe that this is an important sanity check. Furthermore we will
also show, in the next section, the beneﬁts of this property for the
modular analysis of voting systems that rely on computationally
secure cryptographic primitives.
We next illustrate, through simple case studies, the impact on
the privacy of the votes of several important parameters: the result
function, which may correspond to the election outcome but also to
the content of various audit data, and the ballot format and ﬁlling
rules.
Finally, we perform an analysis of the audit data provided as part
of the audit trail of the 2009 Takoma Park election and discuss some
practical lessons that can be taken from this analysis.
For readability, from now on we use the following notational
convention. We write Mk for a computational privacy measure
when the underlying conditional privacy function is Hk(· | ·) for
some k. Furthermore, for average versions of the entropy functions,
i.e. ˜Hk(· | ·), we write ˜Mk for the resulting computational privacy
measure. For example ˜M∞(·,·,·) is the computational privacy
measure we obtain if F is the average conditional min-entropy ˜H∞.
Since F captures the loss of privacy that revealing the results of
the election entails, it is sufﬁcient to understand the relation to the
context of an idealized system where a trusted third party gathers
the vote and publishes the results.
5.1 Ideal Protocols
Assume that ρ is an arbitrary function on V∗. We deﬁne Iρ,
the ideal process that computes ρ as follows. The process samples
the honest votes according to D and allows the adversary to cast
votes on behalf of the remaining voters. The adversary then signals
that it wants to receive the result and obtains ρ((cid:126)v), where (cid:126)v is the
list of all cast votes. Notice that we are tacitly assuming that ρ
is such that the order in which the votes are cast does not matter.
[23] analyzes the privacy offered by several protocols of this type.
Similar idealizations are possible for complex result functions; one
simply needs to specify more carefully how and when the votes are
cast by the honest parties and the adversary.
The following theorem says that for ideal protocols, the pri-
vacy with respect to MF is essentially the information-theoretic
privacy of the function ρ. This is obtained by having the adversary
cast votes from a distribution v∗
C that minimizes the information-
theoretic entropy left in D, given the result of the vote:
THEOREM 5. Let ρ be an order independent function on V∗.
Let v∗
C = argmin
F(T(D) | RD,vA,Iρ ). Then,
vA
MF(D, T,Iρ) = F(T(D) | RD,v∗
C
)
In other words, the conditional computational privacy of an ideal
protocol is the minimum information theoretic entropy that can be
obtained by setting the votes of the adversary. The proof of the
theorem is in the full version of our paper.
5.2 The Role of the Result Function
We now give some examples on how the result function can in-
ﬂuence the privacy measure. As we would intuitively expect, the
more the result function reveals about the votes, the lower the level
of privacy.
Consider a poll in which each voter may cast a single yes/no vote
by submitting 1 or 0 to the trusted party in an ideal protocol. Fix
the distribution D to be as follows: let there be three voters and let
every voter pick his vote uniformly at random. Let T be the vote
of the ﬁrst voter. We compare the privacy of the following result
functions where |(cid:126)v|0 is the number of 0-votes in the vector (cid:126)v of all
votes cast.
946c (const.)
1 if |(cid:126)v|1 ≥ |(cid:126)v|0 else 0
(|(cid:126)v|0,|(cid:126)v|1)
ρ1
ρ2
ρ3
ρ4 (cid:126)v
Each of these result functions contains strictly more information
than the previous one. The ﬁrst is just a constant, the second is the
majority vote (with 1 in case of a tie), the third is the number of 0-
and 1-votes submitted and the fourth reveals all votes.
We consider the privacy measures based on the three entropy
notions highlighted the previous section, namely the average min-
entropy ˜H∞, the min-min-entropy H⊥
∞, and the min-Hartley en-
tropy H⊥
0 .
M⊥
∞
1
˜M∞
1
ρ
ρ1
ρ2 ≈ 0.415 ≈ 0.415
ρ3 ≈ 0.415
ρ4
0
0
0
0
M⊥
1
1
0
0
We give some interpretation of these results.
• Rows 1 and 4 of this table are obvious: if nothing about the
target vote (that starts with one bit of entropy) is revealed,
the entropy remains at 1 bit; if everything is revealed the
conditional privacy drops to zero.
• M⊥
0 (ρ2) = 1 occurs because for any of the two possible
outcomes (majority vote is 0 or 1) the target voter could
have cast a 0-vote or a 1-vote. In other words, the condi-
tional probabilities P [T = t | R = r] (where R is the ran-
dom variable for the result) are nonzero for any (t, r) pair in
their respective domains. We may observe that ˜M0(ρ2) has
the same value.
• However, in the case of average-min and min-min entropies,
the level of privacy decreases. This reﬂects the fact that,
given any outcome, the probability that P1 supported the
winning candidate is 3/4, resulting in an entropy of 0.415 ≈
− log 3/4.
• In the case of ρ3, the min-min and min-Hartley entropies fall
to 0. This is because the worst-case outcomes (0, 3) and
(3, 0) determine the choice of P1.
• The average min-entropy does not decrease, though, which
might be surprising. We can however observe that the prob-
ability of the adversary guessing the choice of P1 remains
equal to 3/4: with probability 1/4, the three candidates voted
in the same way, giving a probability of guessing the choice
of P1 equal to 1, and with probability 3/4, two candidates
voted in one way and one voted in the other, giving a proba-
bility of 2/3 of doing a correct guess given the outcome. We
eventually observe that 1 · 1/4 + 1/3 · 3/4 = 3/4.
All these results hence are in accordance with the intuition that
we can get from those simple examples.
5.3 The Role of the Ballot Format
Ballot formats differ largely among elections: ballots can contain
from one or two candidates up to a few hundred candidates and
even offer the possibility to voters to nominate people who are not
listed, they can require the voter to pick a single candidate, to pick
up to a ﬁxed number of candidates, to rank the candidates, and so
on. The tallying rules can be very diverse as well.
One common approach for running veriﬁable elections, espe-
cially when ballots are complex, is to use mixnets [9, 30, 16, 7,
6]. All voters encrypt their vote, the encrypted ballots are shufﬂed
by a series of mixers and then decrypted. This allows any observer
to verify the result (as they can recompute it themselves from the
revealed votes) but the random order does not allow anyone to link
votes to voters as long as at least one of the mixers is honest. How-
ever, mixnet-based tallying can destroy entropy if the number of
choices a voter is presented with greatly exceeds the number of
voters. We give an example.
Consider a poll in which each of 210 voters is asked to answer
n yes/no questions, whose answers are encrypted in a single ci-
phertext to be shufﬂed. The main factor that distinguishes mixnet-
based tallying from the other main approach to cryptographic vot-
ing, namely homomorphic tallying, is that the ballots themselves
can reveal relations between the answers to the various questions:
for example, it may be possible to observe that the second ques-
tion was more often answered with “yes” by voters who also said
“yes” to the ﬁrst question. This kind of information would not be
deducible from the number of “yes” answers given to each question
individually.
We consider the level of privacy offered by such an election as
a function of the number n of questions. The level of privacy can
clearly not exceed n: there are just 2n choices. It might however
be lower than n when the number of voters becomes smaller than
2n: there will not be enough voters to make all possible choices,
which will allow an observer to eliminate some of them. So, in our
election, the level of privacy is also upper bounded by 10, since no
more than 210 choices can be made.
Assuming that the voters make their choices uniformly at ran-
dom, we estimate our privacy measure based on average min-entropy
for different values of n.
2
n
˜M∞ 1.9
6
5.3
10
7.5
14
8.7
18
9.1
22
9.9
This table shows that, for 2 and 6 choices, the measure of pri-
vacy is fairly close to optimal: an observer will not be able to guess
the choice of a speciﬁc voter much better than by a random guess.
When the number of choices increases, the measure of privacy pro-
gressively tends to 10. This corresponds to the fact that, when see-
ing the decrypted ballots, an observer can be convinced that any
voter made one of the ≈ 210 choices that appear after decryp-
tion instead of the 2n choices that were initially possible. These
≈ 210 choices still give 10 bits of privacy, a non-negligible mea-
sure, which is acknowledged by our measure.
Our measures of min-min-entropy and min-Hartley entropy will
all provide an outcome equal to 0. There is indeed a non-zero prob-
ability that the 210 voters make exactly the same choice, in which
case they completely lose their privacy.
5.4 Analysis of the 2009 Takoma Park Elec-
tion Data
The Scantegrity [10] voting system has been used in two pub-
lic elections in Takoma Park, in 2009 [7] and in 2011. Scantegrity
is a paper-based universally veriﬁable voting system. As part of
the voting process, each voter is invited to ﬁll in his paper ballot
with a special pen: every time a voter marks a candidate, a conﬁr-
mation code is unveiled, which the voter is invited to write on his
receipt. When coming back home the voter has then the possibil-
ity to check the presence of the receipt codes he noted on a public
bulletin board. The design of the system is expected to guarantee
that it is not possible to link any speciﬁc code to a particular voter
choice.
The tallying procedure then proceeds to a veriﬁable shufﬂe of
the ballots, and the shufﬂed ballots are made available on the bul-
letin board as well, for audit purposes. We note that this mixnet-
based tallying procedure provides voters with more information
than usual: all voters can now see all shufﬂed ballots, while they are
947usually only able to see the ﬁnal election outcome only (expressed
in terms of number of votes for each candidate), unless they are
part of the tallying ofﬁcers.
for n candidates, there arePn
The Takoma Park elections have another speciﬁcs: they are based
on instant-runoff voting (IRV), that is, voters are invited to rank any
number of candidates on their ballot (including a write-in position).