@fchollet and other kerasors,  
We all know that if we are dealing with large scale of data such as ImageNet,
we could write a customized generator which produces batch data (often as
numpy.array) from disk. Then we could train our model with
`model.fit_generator()`. But, if we want to use `ImageDataGenerator` to do the
online data augmentation at the same time, what is the simplest way to
implement? Note that I would like to use its `flow()` method instead of
`flow_from_directory()` method.