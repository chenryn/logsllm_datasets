of objects that are only modiﬁed by the trusted subjects. A
problem is that some objects are written only by trusted sub-
jects, but are known to contain adversary-controlled data,
such as log ﬁles. We assume these objects to be untrusted.
More such cases are discussed in the evaluation.
This method computes the object labels inside the in-
tegrity wall for a subject label, and all other objects labels
are outside the integrity wall for that subject. Access to
objects outside the wall will be the focus in building each
program’s attack surface.
3.2
Identifying Attack Surfaces
Using an integrity wall for a subject, we can ﬁnd the at-
tack surfaces of all programs that run under that subject.
As noted, it is impractical to identify these entry points stat-
ically, because any system call is authorized to access any
object to which the program’s subject is authorized. There-
fore, we propose a runtime analysis to locate entry points.
Runtime analysis provides a lower-bound for the number of
entry points in an attack surface, but nonetheless, we have
found many non-trivial attack surfaces with recent vulnera-
bilities and we identiﬁed new vulnerabilites (Section 5).
The most important design decision is to deﬁne what an
entry point is. To ﬁnd the program entry points, we obtain
the process’s execution stack at the time of the system call.
Consider a program performing a system call that receives
input, through a stack of function calls F1, F2, . . . , Fn, where
Fi calls Fi+1. The entry point into the program occurs at
the greatest index i where Fi is not trusted to ﬁlter all input.
That is, we may trust libc to protect itself from untrusted
input, making the caller of libc the entry point. This is
often, but not always, the program executable instruction
that invoked the library call.
Developing a runtime analysis for identifying program at-
tack surfaces must meet the following requirements.
1. All security-sensitive operations from all processes must
be mediated,
2. The subject and object labels of each operation are
available, and
3. The context of the process execution (e.g., the instruc-
tion pointer and process stack) is available.
First, both user-level and kernel-level mechanisms have
been designed to mediate system calls, but the use of kernel-
level mediation is preferred in this case because: (1) multiple
security-sensitive operations and objects may be accessed in
one system call, and it requires signiﬁcant parsing eﬀort in
user-space to ﬁnd them all accurately and (2) all processes
can be mediated in a single location for low overhead. In
several modern operating systems, reference monitors have
been implemented to mediate all security-sensitive opera-
tions [36, 35, 32], which we extend to detect accesses of
objects outside the integrity wall.
Second, we need to know the subject and object labels of
the operation to determine if this operation is outside the
integrity wall for that subject. The label information is ob-
tained from the reference monitor module enforcing system
security (e.g., SELinux [22] and AppArmor [21] for Linux).
We use this information to determine whether the subject
is accessing an object outside its wall based on the trusted
objects Is or its set complement Os.
Third, when an untrusted object is accessed, we ﬁnd the
process’ user stack at the time of the call to ﬁnd the entry
point. The main challenge is to search up the stack to ﬁnd
the ﬁrst stack frame that is not trusted to ﬁlter all inputs.
Each frame must be mapped to its code ﬁle to determine
whether it is trusted for all inputs. We use the virtual mem-
ory mappings to determine the code ﬁle, and we maintain a
table of those that are fully trusted. The speciﬁc mechanism
is described in the implementation.
Finally, we log entry points to user-space, so they can
be collected and analyzed. A log entry record consists of
the subject and object labels of the operation and the entry
point in the process’ user stack at the time of the operation.
4.
IMPLEMENTATION
In this section, we describe how we implemented our de-
sign on Ubuntu 10.04.2 LTS Desktop Edition running a
Linux 2.6.35 kernel, with SELinux as the MAC enforcement
mechanism. We ﬁrst describe our implementation to con-
struct the integrity wall for subjects, and then our modiﬁca-
tion of the Linux kernel to log the entry points at runtime.
We also explain how we extended our system to deal with
interpreters. Our modiﬁcations added 1189 lines of code to
the Linux 2.6.35 kernel: 588 lines of code for interpreter pro-
cessing and the rest to fetch the stack backtrace, detect if the
operation is untrusted, and log fresh entries to userspace.
4.1 Integrity Wall Construction
We implement the design described in Section 3.1. We
implement the algorithms for each step in XSB/Prolog. In
total, the algorithms required 101 Prolog statements, 77 of
these were for parsing the SELinux policy, and the rest for
the wall generation. The main input is the system’s SELinux
MAC policy, which consists of a set of policy modules for
individual Linux applications deployed on the system5. We
describe implementation of the algorithms in terms of TCB
computation and the subject label’s integrity wall computa-
tion.
To construct the TCB of the system, we manually identify
a set of 13 kernel objects (Kernel(P )), write access to which
could directly compromise the kernel (e.g., /dev/kmem). Us-
ing Steps 1 and 2 of Section 3.1, the SELinux policy and the
kernel objects are used to identify the set of subjects that
can write to these kernel objects and to perform a transitive
closure of the writers of the binaries of the kernel subjects.
The SELinux policy identiﬁes all write operations (Write)
and the objects that may be executables for a subject for
computing Writex. SELinux deﬁnes the object types6 for
initiating a subject using type_transition rules. The ob-
ject type in such rules corresponds to the label of the corre-
sponding executable ﬁle.
Using the SELinux MAC policy, we compute the integrity
wall for SELinux subject types in the Ubuntu distribution,
using Steps 3-6 in Section 3.1. To identify helper subjects,
we need to identify the subjects that are part of the same
application (App(s)). SELinux oﬀers policy modules for ap-
plications, and we consider all subjects deﬁned in an appli-
cation policy module as being part of the same application.
All TCB subjects use the same integrity wall.
As a special case, we force all log ﬁles to be outside the in-
tegrity wall of all subjects. Log ﬁle types are easily identiﬁed
in the SELinux policy (e.g., var_log_t).
4.2
Identifying Attack Surfaces
Once we have the integrity wall, we use it to locate op-
erations crossing the wall using runtime analysis. Figure 2
details our implementation in Linux, which leverages the
Linux Security Modules (LSM) framework [36]. We use the
SELinux LSM running in the Linux kernel to ﬁnd untrusted
operations. This satisﬁes the three requirements for identify-
ing untrusted operations (Section 3.2). First, it mediates all
security-sensitive operations using the LSM interface. Sec-
ond, we instrument the SELinux access decision function,
avc_has_perm, which authorizes a subject type to perform
an operation on an object of a particular object type. Fi-
nally, the kernel always has details about the currently exe-
cuting process.
Our implementation enables: (1) uploading of integrity
walls; (2) identifying operations outside the wall for a pro-
cess; (3) ﬁnding the process entry point; and (4) logging the
operation. We examine implementation of these below.
To upload the integrity walls into the kernel, we export
5Many, but not all Linux applications have SELinux mod-
ules. Those programs without their own modules run under
a generic label, such as user_t for generic user programs.
6In SELinux, labels are called types.
Figure 2: When the program makes a syscall, the SELinux func-
tion avc_has_perm is hooked through LSM hooks. If the calling
function reads an object with a label outside the wall for that
process, then a log entry including the entry point into the user
program is generated to a relayfs ﬁle. A userspace logging dae-
mon collects this data into a log ﬁle, and a summarizer analyzes
this ﬁle to output the attack surface. The integrity walls for each
subject label are pushed into the kernel via a debugfs ﬁle.
a debugfs ﬁle to communicate the integrity wall for each
subject type to the kernel.
To identify operations accessing objects outside a sub-
ject’s wall, we look for operations that input data (i.e., read-
like operations). We use the permission map from Apol [33],
which identiﬁes whether an operation is read-like, write-like,
or both. Interesting to note is that the permission map clas-
siﬁes operations from most covert (least actual input, such
as ﬁle locking) to most overt (most actual input, such as
ﬁle reading). We ignore covert operations, excepting for
directory searches. We ﬁnd these valuable because they in-
dicate the presence of an attack surface if the directory is
untrusted, even if the ﬁle itself is not present. For example,
when a program searches for libraries in the current work-
ing directory (untrusted search path), the library ﬁle itself
is not present in benign conditions, but the search indicates
an attack surface.
Once we identify an operation that reads from outside
the wall, we ﬁnd the entry point into the process. We ﬁrst
obtain the user stack trace of the process, and then identify
the exact entry point. The user stack trace is available by
a simple unrolling of the linked list of base pointers on the
userspace stack. Such functionality is already available using
the ftrace framework in the Linux kernel, which we use.
To ﬁnd the entry point, we search for the stack frame
that belongs to a code object that cannot protect itself from
all input. In Linux, the vma_struct is associated with the
name of its code object ﬁle (current->comm). Thus, for an
instruction pointer, we retrieve its code object ﬁle through
the vma_struct to identify entry points. Due to address-
space randomization, the exact IP may vary across diﬀerent
runs of the same process. Thus, we use the oﬀset from the
base of the binary, which is a constant. Then, this informa-
Library CallSyscallProcess StackLibraryProcessavc_has_permDebugfsFileIntegrity Wall DetailsIs subject trusted and object untrusted?Yes: generate log and export log through relayfsLogging DaemonAdministratorRelayfsFileLog ﬁleSummarizerSubject: httpd_tNumber of intf: 301:()... recv(sock, ...)Kernel SpaceLSM HookPROCESS: httpd CONTEXT: system_u:system_r:httpd_t
Number of entry points: 30
1:
(
0x2EC4A, /home/user/httpd-2.2.14/server/core_filters.c:383,
15, FILE__READ, system_u:object_r:httpd_user_content_t
)
--------------------------
2:
(
0x6758A, /home/user/httpd-2.2.14/server/listen.c:140,
38, TCP_SOCKET__LISTEN, system_u:object_r:httpd_t
)
Figure 3: A log entry from recording of untrusted operations.
Two entry points for Apache, with its location information.
tion can be used oﬄine to ﬁnd the exact line of code in the
program if versions of the binaries are available with debug
information (many of these are readily available in Ubuntu
repositories).
To export the data to userspace, we use relayfs. A
userspace daemon reads the kernel output and dumps the
output to a ﬁle. The daemon registers itself with the kernel
so it itself will not be traced. For each untrusted operation,
we log the following: (1) process name; (2) process ID; (3)
the entry point IP into the process as an oﬀset from the base
of the binary; (4) the SELinux context of the subject7; (5)
the SELinux context of the object; (6) operations requested;
and (7) ﬁlename, if object is a ﬁle.
Once the log is available in userspace, it is parsed to out-
put a list indexed by process name(Figure 3). For each pro-
cess, each entry point indexed by IP is listed, with the op-
eration(s), types of data read through that entry point, and
the number of times that entry point is invoked. If debug
information is available for the process, we also print the C
source line of code that the entry point is associated with.
4.3 Finding Attack Surfaces in Interpreted Code
For interpreted programs, a normal backtrace of the user
stack will supply an entry point into the interpreter, and not
the script that it is executing. Several shell scripts are run
during normal operation of the system, some of which have
fallen victim to adversaries, so we also have to accurately
identify the attack surfaces of interpreted programs.
We built a kernel-based mechanism for extracting entry
points from programs in a variety of interpreted languages
(PHP, Python, Bash). This mechanism takes advantage of
the common architecture of interpreters. First, these in-
terpreters execute their programs by running each language
instruction in a function that we call the fundamental loop
function. Each interpreter also maintains a global current
interpreter object that represents the state execution of the
program, much like a process control block describes pro-
cesses. Second, when an error occurs, the fundamental loop
functions each call print backtrace function, that extracts
the stack frames of the currently executing program from
the current interpreter object.
To collect entry points for interpreted code, we made inter-
preter state visible to our kernel mechanism. This involved
creating kernel modules that are aware of each interpreter:
(1) obtaining access to each’s current interpreter object from
their ELF binary symbol tables and (2) using each’s print
backtrace functions to ﬁnd entry points. First, the ELF bi-
7An SELinux context includes a type and other information,
including a user identity and role. We are mainly interested
in the type.
nary loader already contains mechanisms for accessing the
symbol table during program loading that we used to gain
access to the desired references. Second, we integrate the
backtrace code from the interpreter into the kernel module
to ﬁnd entry points. This task is complicated because we
need to use this code to access user addresses from kernel
space. To do this safely, we use macros to handle page faults
that may result from user space access (copy_from_user)
and remove code that causes side-eﬀects (any writes to user
space). Ultimately, very little code needed to be transferred
from user space: Bash required 59 lines of code, most of it to
handle hash tables in which it stores its variables, whereas
PHP required just 11 lines of code. Ultimately, 588 lines of
code were added to the kernel for the three interpreters, but
391 lines are for deﬁning data structure headers.
4.4 Enforcing Attack Surfaces
We note that the same infrastructure that logs attack sur-
face entry points can also enforce them.
In other words,
any access crossing the integrity wall would be blocked un-
less made through one of the authorized entry points for
that program and between appropriate types. When any
previously unknown entry point crossing the integrity wall
is found, its details can be reported to the OS distributor
much like crash reports are sent currently, who can decide
if the entry point is valid. Note that our enforcing mode
can block entry points exercising improper permissions such
as untrusted search paths (even those having previously un-
known bugs), while access control cannot (as the process
might legitimately have those permissions at another entry
point). To make our tool performant for online logging and
enforcement, we made some enhancements. The integrity
walls for subjects are stored as a hash table so looking up
whether an object is inside or outside the wall is fast. Also,
we only log operations if they have not been logged already.
5. EVALUATION
In this section, we present the results of our analysis of
attack surfaces for the system TCB of an out-of-the-box
install of Ubuntu Desktop LTS 10.04.2, with the SELinux
policy from the repositories. Our aim in this evaluation is
to demonstrate the eﬀectiveness of our approach in com-
puting the attack surfaces for all the system programs in
a widely-used Linux distribution in relation to its default
SELinux policy. In addition, we performed a detailed study
of application programs, including Apache httpd, sshd and
the Icecat browser, the GNU version of Firefox. While the
Apache and OpenSSH are mature programs, we show that
our approach can identify attack surface entry points that
are easily overlooked. Icecat is a relatively new program, so
its analysis demonstrates how our approach may aid in the
proactive defenses of immature programs.
We found the following results. For the system TCB, we
found that: (1) our analysis was able to obtain an attack sur-
face of 81 entry points, including in scripts and some subtle
entry points, 35 of which have had previous vulnerabilities,
and (2) the attack surface of these programs is a small per-
centage of their total number of entry points. Examining
the system TCB attack surface, we found a vulnerability in
one entry point in a script that has been present in Ubuntu
for several years. For Apache and sshd, we were able to
associate attack-surface entry points with the conﬁguration
option that enabled them by correlation with the conﬁgura-
Types Inside Wall
Subjects Objects
Types Outside Wall
Subjects Objects
System TCB
Apache (httpd t)
111
118
679
700
153
146
142
121
Table 1: Wall statistics for the system TCB types and Apache.
Subject types correspond to processes, and object types corre-
spond to OS objects (e.g., ﬁles) and processes.
tion used by their test suites. In sshd, we found an entry
point in the privilege-separated part that was missed by ear-
lier manual identiﬁcation [29]. In Icecat, we found an entry
point that was part of the attack surface due to a bug.
5.1 Policy Analysis
This section presents the results of the wall generation
algorithm described in Section 3.1, on Ubuntu 10.04.2’s
SELinux policy. This policy used 65 application policy mod-
ules, and had 1058 types (subject and object) in total.
System TCB. We ﬁrst need to locate the TCB that is
common to all applications. We build the TCB as described
in Section 4.1.
In total, we had 111 subject types in the
TCB.
Wall Generation Results. Table 1 shows the number
of subject types inside and outside the wall for the system
TCB subject types and the Apache subject types and the
resulting number of high and low integrity object types. We
note that only seven new subject types are added to the
integrity wall for Apache over the system TCB subject types,
which it must already trust.
Interestingly, the number of
high integrity object types given this wall outnumbers low
integrity types by more than 4:1.
We conﬁrmed that for the system TCB programs we ex-
amined, the integrity wall derived from the policy corre-
sponded to our intuitive notion of dependence and ﬁltering,
(i.e.,) conﬁguration ﬁles and library ﬁles were within the
wall, and user-controlled input outside; we present more de-
tails of the wall when we discuss individual applications.
Violating permissions. We found that of 115,611 rules
in our SELinux policy, 34.4% of these rules (39,848) crossed
across the system TCB integrity wall, allowing input from
object types outside the system TCB to subjects in the sys-
tem TCB. The attack surface will consist of entry points in
TCB programs that exercise a permission that crosses the
wall. These cannot be found from the MAC policy; we need
information from the program.
5.2 Runtime Analysis
System TCB
5.2.1
Evaluation of the system’s TCB demonstrates that: (1)
the number of attack surface entry points is a small per-
centage of the total number of entry points, (2) some attack
surface entry points are subtle, and (3) even for mature pro-
grams in the system TCB, it is beneﬁcial to locate the attack
surface, as demonstrated by a bug we found in an entry point
in a mature script that sets up the X server. We gathered the