to identify the relevant code and then analyzing it thoroughly. Unfortunately,
analysis-resistance techniques force the analyst out of the usual mode of binary
S. Jha, R. Sommer, and C. Kreibich (Eds.): RAID 2010, LNCS 6307, pp. 317–338, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
318
K.A. Roundy and B.P. Miller
analysis, which involves statically analyzing the binary prior to instrumenting
regions of interest and performing a controlled execution of the program. Instead,
the analyst must execute the malicious code to analyze it, as static analysis
can fail to analyze dynamically generated, modiﬁed, and obfuscated code. The
analyst must therefore construct a virtual environment that allows the malware
to interact with other hosts and that is suﬃciently convincing that the malware
will display its normal behavior while executing in isolation from the outside
world. Many analysts prefer the analyze-then-execute model and therefore resort
to expending considerable manual eﬀort to strip analysis-resistance features from
malicious binaries [12,40].
The goal of our research is to simplify malware analysis by enabling a return to
the traditional analyze-then-execute model, which has the beneﬁt of bringing the
malicious code under the analyst’s control before it executes. We address these
goals by combining static and dynamic techniques to construct and maintain
the control- and data-ﬂow analyses that form the interface through which the
analyst understands and instruments the code. A key feature of our approach
is its ability to update these analyses to include dynamically unpacked and
modiﬁed code before it executes. Our work makes the following contributions:
– Pre-execution analysis and instrumentation makes it possible for the analyst
to control the execution of malicious code. For example, our work allows
interactions with other infected hosts to be simulated through instrumenta-
tion’s ability to patch the program, removing the need for complex virtual
environments involving multiple hosts. Additionally, our work can comple-
ment a virtualization strategy by identifying and disabling the malware’s
attempts to detect its virtual-machine environment [36].
– We give the analyst the ability to instrument malware intuitively and eﬃ-
ciently by providing data-ﬂow analysis capabilities and a control ﬂow graph
(CFG) as an interface to the code. For example, the CFG allows us to ﬁnd
transitions to dynamically unpacked code by instrumenting the program’s
statically unresolved control transfers (see Section 5). By contrast, prior
instrumentation-based unpacking tools did not maintain a CFG and there-
fore had to monitor all of the program’s control transfers and memory writes
to detect the execution of code that is written at run-time [23,41]. We achieve
a hundred-fold reduction in the number of monitored program locations.
– Our structural analysis allows analysts to be selective in the components
they monitor, the operations in those components that they select, and in
the granularity of data they collect. Current tools that can monitor analysis-
resistant malware do not provide ﬂexible instrumentation mechanisms; they
trace the program’s execution at a uniform granularity, either providing ﬁne-
grained traces at the instruction or basic-block level [17,36], or coarse grained
traces (e.g., at interactions with the OS) [52]. These tools either bog the
analyst down with irrelevant information (a signiﬁcant problem for inexpe-
rienced analysts [42]), or can only give a sketch of the program’s behavior.
– By combining static and dynamic techniques we allow the analyst to ﬁnd and
analyze code that is beyond the reach of either static or dynamic analysis
Hybrid Analysis and Control of Malware
319
alone, thereby providing a fuller understanding of the malware’s possible
behavior. Prior combinations of static and dynamic analysis only operate on
non-defensive code, and only ﬁnd and disassemble the code [34] or produce
their analysis results only after the program has fully executed [28].
Analysts have controlled and monitored malicious code either by executing the
malware in a process that they control through the debugger interface [44], or by
executing the malware in a virtual machine [36]. There are advantages to both
approaches. The debugger approach makes it easy to collect process information
and intercept events, and allows for the creation of lightweight tools that do
not have to worry about anti-emulation techniques [36]. Among the beneﬁts of
virtual machines are that they isolate the underlying system from the malware’s
eﬀects, they provide the ability to revert the machine to a clean state or to
a decision point, and allow for stealthy monitoring of the program’s execution
[17,36]. While in this paper we demonstrate an instrumentation and analysis tool
that executes malicious processes through the debugger interface, our techniques
are orthogonal to this choice and beneﬁt both scenarios. For example, in the
former case, pre-execution analysis and control allows the analyst to limit the
damage done to the system, while the latter case beneﬁts from the ability to
detect and disable anti-emulation techniques.
Our analysis and instrumentation tool is not the ﬁrst to analyze code prior to
its execution (e.g., Dyninst [22], Vulcan [48]), but existing tools rely exclusively
on static analysis, which can produce incomplete information even for binaries
that are generated by standard compilers. Despite recent advances in identi-
fying functions in stripped compiler-generated binaries, on the average, 10% of
the functions generated by some compilers cannot be recognized by current tech-
niques [43], and even costly dataﬂow analyses such as pointer aliasing may be
insuﬃcient to predict the targets of pointer-based control transfers [5,21].
Most malware binaries make analysis and control harder by employing the
analysis-resistance techniques of code packing, code overwriting, and control
transfer obfuscations. Code packing techniques, wherein all or part of the bi-
nary’s malicious code is compressed (or encrypted) and packaged with code that
decompresses the malicious payload into the program’s address space at run-
time, are present in 75% of all malware binaries [8,50]. Dealing with dynamic
code unpacking is complicated by programs that unpack code in stages, by the
application of multiple code-packing tools to a single malicious binary, and by
a recent trend away from well-known packing tools, so that most new packed
binaries use custom packing techniques [9,10].
To further complicate matters, many packing tools and malicious programs
overwrite code at run-time. While code unpacking impacts static analysis by
making it incomplete, code overwriting makes the analysis invalid and incom-
plete. A static analysis may yield little information on a self-modifying program,
as potentially little of the code is exposed to analysis at any point in time [2].
Malware often uses control-transfer obfuscations to cause static analysis algo-
rithms to miss and incorrectly analyze large swaths of binary code. In addition to
the heavy use of indirect control transfers, obfuscated binaries commonly include
320
K.A. Roundy and B.P. Miller
non-conventional control transfer sequences (such as the use of the return instruc-
tion as an indirect jump), and signal- and exception-based control transfers [18].
Additionally, malicious binaries and packers often contain hand-written assem-
bly code that by its nature contains more variability than compiler-generated
code, causing problems for most existing code-identiﬁcation strategies, as they
depend on the presence of compiler-generated instruction patterns [24,43].
We analyze binaries by ﬁrst building a CFG of the binary through static pars-
ing techniques. As the binary executes, we rely on dynamic instrumentation and
analysis techniques to discover code that is dynamically generated, hidden by ob-
fuscations, and dynamically modiﬁed. We then re-invoke our parsing techniques
to update our CFG of the program, identifying the new code and presenting
the updated CFG to the analyst. The structural information provided by our
analysis allows us to discover new code by instrumenting the program lightly,
only at control transfer instructions whose targets cannot be resolved through
static analysis, making our tool’s execution time comparable to that of existing
unpacking tools despite the additional cost that we incur to provide an updated
CFG. (see Section 8).
Other analysis resistance techniques that can be employed by malicious
program binaries include anti-debugging checks, anti-emulation checks, timing
checks, and anti-tampering (e.g., self-checksumming) techniques. Since our cur-
rent implementation uses the debugger interface, we have neutralized the com-
mon anti-debugging checks [18]. In practice, anti-debugging and timing checks
leave footprints that are evident in our pre-execution analysis of the code and
that the analyst can disable with the instrumentation capabilities that we pro-
vide. Our research is investigating multiple alternatives for neutralizing the eﬀect
of anti-tampering techniques, but this work is beyond the scope of this paper.
We proceed by discussing related work in Section 2 and we give an overview
of our techniques and algorithm in Section 3. Our code-discovery techniques
are described in Sections 4-7. In Section 8 we show the utility of our approach
by applying our tool to analysis-resistant malware, and to synthetic samples
produced by the most prevalent binary packing tools. We conclude in section 9.
2 Related Work
Our work is rooted in the research areas of program binary analysis, instrumen-
tation, and unpacking.
Analysis. Static parsing techniques can accurately identify 90% or more of the
functions in compiler-generated binaries despite the lack of symbol information
[43], but are much worse at analyzing arbitrarily obfuscated code [24,51], and
cannot analyze the packed code that exists in most malicious binaries [9]. Thus,
most malware analysis is dynamic and begins by obtaining a trace of the pro-
gram’s executed instructions through single-step execution [17], dynamic instru-
mentation [41], or the instrumentation capabilities of a whole-system emulator
[32]. The resulting trace is used to construct an analysis artifact such as a vi-
sualization of the program’s unpacking behavior [42], a report of its operating
Hybrid Analysis and Control of Malware
321
system interactions [6], or a representation that captures the evolving CFG of
a self-modifying program [4]. As these analysis artifacts are all produced after
monitoring the program’s execution, they are potential clients of our analysis-
guided instrumentation techniques rather than competitors to them.
Madou et al. [28] and Cifuentes and Emmerik [13] combine static and dynamic
techniques to identify more code than is possible through either technique alone.
Madou et al. start from an execution trace and use control-ﬂow traversal parsing
techniques to ﬁnd additional code, whereas Cifuentes and Emmerik start with
speculative static parsing and use an instruction trace to reject incorrect parse
information. Their hybrid approaches to CFG-building are similar to ours in
spirit, but they analyze only code that is statically present in the binary as they
lack the ability to capture dynamically unpacked and overwritten code.
Instrumentation. Existing tools that provide analysis-guided binary instru-
mentation [22,49,48] cannot instrument code that is obfuscated, packed, or self-
modifying, as their code identiﬁcation relies exclusively on static analysis. Our
tool uses Dyninst’s [22] dynamic instrumentation and analysis capabilities, up-
dating its analysis of the code through both static and dynamic code-capture
techniques, prior to the code’s execution.
The BIRD dynamic instrumenter [34] identiﬁes binary code by augmenting
its static parse with a run-time analysis that ﬁnds code by instrumenting control
transfers that could lead to unknown code areas. BIRD works well on compiler-
generated programs, but does not handle self-modifying programs and performs
poorly on programs that are packed or obfuscated, as it is not optimized for ex-
tensive dynamic code discovery (it uses trap instructions to instrument all return
instructions and other forms of short indirect control transfers that it discovers
at runtime). BIRD also lacks a general-purpose interface for instrumentation
and does not produce analysis tools for the code it identiﬁes.
Other dynamic instrumentation tools forgo static analysis altogether, instead
discovering code as the program executes and providing an instruction-level in-
terface to the code (e.g., PIN [27], Valgrind [7]). These tools can instrument
dynamically unpacked and self-modifying code, but do not defend against
analysis-resistance techniques [18]. As with BIRD, the lack of a structural anal-
ysis means that it is diﬃcult to selectively instrument the code and that it may
not be possible to perform simple-sounding tasks like hooking a function’s return
values because compiler optimizations (and obfuscations) introduce complexities
like shared code, frameless functions, and tail calls in place of return statements.
Unpacking. The prevalence of code packing techniques in malware has driven
the creation of both static and dynamic approaches for detecting packed mali-
cious code. Some anti-virus tools (e.g., BitDefender [8]) create static unpackers
for individual packer tools at signiﬁcant expense, but this approach will not scale
with the explosive growth rate of new packing approaches [9,35]. Anti-virus tools
also employ “X-Ray” techniques that can statically extract the packed contents
of binaries that employ known compression schemes or weak encryption [37].
Coogan et al. [15] use static analysis to extract the unpacking routine from a
322
K.A. Roundy and B.P. Miller
packed binary and then use the extracted routine to unpack it. These static ap-
proaches are unsuccessful when confronted with malware that employs multiple
packing layers (e.g., Rustock [12]), and Coogan et al.’s static techniques are also
unable to deal with heavily obfuscated code [33,46].
Most dynamic unpacking tools take the approach of detecting memory loca-
tions that are written to at run-time and later executed as code. OmniUnpack
[30], Saﬀron [41], and Justin [20] approach the problem at a memory-page gran-
ularity by modifying the operating system to manipulate page write and execute
permissions so that both a write to a page and a subsequent execution from that
page result in an exception that the tool can intercept. This approach is eﬃcient
enough that it can be used in an anti-virus tool [30], but it does not identify
unpacked code with much precision because of its memory-page granularity.
Other unpackers identify written-then-executed code at a byte level by tracing
the program’s execution at a ﬁne granularity and monitoring all memory writes.
EtherUnpack [17] and PolyUnpack [44] employ single-step execution of the bi-
nary, whereas Renovo [23] and “Saﬀron for Intel-PIN” [41] use the respective
instruction-level instrumentation capabilities of the Qemu whole-system emula-
tor [7] and the PIN instrumenter [27]. By contrast, our analysis-guided instru-
mentation allows us to unpack and analyze program binaries with a hundred-fold
reduction in instrumented program locations and comparable execution times.
3 Technical Overview
Our hybrid algorithm combines the strengths of static and dynamic analysis. We
use static parsing techniques to analyze code before it executes, and dynamic
techniques to capture packed, obfuscated, and self-modifying code. Hybrid anal-
ysis allows us to provide analysis-guided dynamic instrumentation on analysis-
resistant program binaries for the ﬁrst time, based on the following techniques:
Parsing. Parsing allows us to ﬁnd and analyze binary code by traversing stati-
cally analyzable control ﬂow starting from known entry points into the code. No
existing algorithm for binary code analysis achieves high accuracy on arbitrarily
obfuscated binaries, so we create a modiﬁed control-ﬂow traversal algorithm [47]
with a low false-positive rate. Our initial analysis of the code may be incomplete,
but we can fall back on our dynamic capture techniques to ﬁnd new entry points
into the code and use them to re-seed our parsing algorithm.
Dynamic Capture. Dynamic capture techniques allow us to ﬁnd and analyze
code that is missed by static analysis either because it is not generated until
run-time or because it is not reachable through statically analyzable control ﬂow.
Our static analysis of the program’s control ﬂow identiﬁes control transfer in-
structions that may lead to un-analyzed code; we monitor these control transfers
using dynamic instrumentation, thereby detecting any transition to un-analyzed
Hybrid Analysis and Control of Malware
323
1. Load the program into memory, paused at its entry point
2. Remove debugging artifacts
3. Parse from known entry points
4. Instrument newly discovered code
5. Resume execution of the program
6. Handle code discovery event, adding new entry points
7. Goto 3
Fig. 1. Algorithm for binary code discovery, analysis, and instrumentation
code in time to analyze and instrument it before it executes. This approach is
similar to BIRD’s [34], but monitors a smaller set of control transfers.
Code Overwrite Monitoring. Code overwrites invalidate portions of an ex-
isting code analysis and introduce new code that has not yet been analyzed. We
adapt DIOTA’s [29] mechanism for detecting code overwrites by write-protecting
memory pages that contain code and handling the signals that result from write
attempts. Accurately detecting when overwriting ends is important, as it allows
us to update our analysis only once when large code regions are overwritten in
small increments. We detect the end of code overwriting in a novel way by using
our structural analysis of the overwrite code to detect any loops that enclose the
write operations, allowing us to delay the analysis update until the loop exits.
Signal- and Exception-Handler Analysis. We use dynamic analysis to re-
solve signal- and exception-based control transfer obfuscations [18,38]. We detect
signal- and exception-raising instructions and ﬁnd their dynamically registered
handlers through standard techniques, and then add the handlers to our analysis
and instrument them to control their execution.
Figure 1 illustrates how we combine the above techniques into an iterative
algorithm that allows us to provide analysis-guided dynamic instrumentation
of analysis-resistant program binaries. The key feature of this algorithm is that
it allows all of the program’s code to be analyzed and instrumented before it
executes. Our algorithm’s incremental instrumentation of the code is similar
to Mirgorodskiy and Miller’s use of “self-propelled instrumentation” to trace a
program’s execution [31], but we also analyze and instrument analysis-resistant
code, whereas they can instrument only statically analyzable code.
4 Parsing
The purpose of our parsing algorithm is to accurately identify binary code and
analyze the program’s structure, producing an interprocedural control ﬂow graph
of the program. Existing parsing techniques for arbitrarily obfuscated code have
attempted to identify code with good accuracy and coverage, and have come up
short on both counts [24]. Instead, we prioritize accurate code identiﬁcation, as
an incorrect parse can cause incorrect program behavior by leading to the instru-
mentation of non-code bytes, and is ultimately not very useful. The competing
324
K.A. Roundy and B.P. Miller
goal of good coverage is relatively less important, because our dynamic tech-
niques compensate for lapses in coverage by capturing statically un-analyzable
code at run-time and triggering additional parsing.
Control-ﬂow traversal parsing [47] is the basis for most accurate parsing tech-
niques, but it makes three unsafe assumptions about control ﬂow that can re-
duce its accuracy. First, it assumes that function-call sites are always followed by
valid code sequences. Compilers violate this assumption when generating calls to
functions that they know to be non-returning, while obfuscated programs (e.g.,
Storm Worm [39]) often contain functions that return to unexpected locations
by tampering with the call stack [25]. Second, the algorithm assumes that con-
trol ﬂow is only redirected by control transfer instructions. Obfuscated programs
often use an apparently normal instruction to raise a signal or exception, thereby
transferring control to code that is hidden in a signal or exception handler [18].
The handler can further obfuscate control ﬂow by telling the operating system to
resume execution away from the signal- or exception-raising instruction, poten-
tially causing non-code bytes to be parsed following the instruction [38]. Third,
the algorithm assumes that both targets of conditional branch instructions can
be taken and therefore contain valid code. Program obfuscators can exploit this
assumption by creating branches with targets that are never taken, thereby di-
luting the analysis with junk code that never executes [14].
In our experience with analysis-resistant binaries, we have found that by far
the most targeted vulnerability is the assumption that code follows each call
instruction, and we have addressed this vulnerability in our current parsing
algorithm. We detect and resolve signal- and exception-based obfuscations at
run-time (see Section 7), when we analyze and instrument any hidden code
and correct our analysis to include the obfuscated control transfer. The use of
branches with targets that are never taken dilutes the analysis with junk code
but has thus far not been a problem for our hybrid analysis and instrumentation
techniques. Our ongoing work will improve upon our parser’s accuracy by adding
static detection of some fault-based control transfers and never-taken branch
targets, thereby making our instrumentation of the program safer and more
eﬃcient. In the meantime, our current parsing algorithm achieves signiﬁcant
accuracy improvements relative to existing techniques for parsing obfuscated
code, allowing us to analyze and instrument most analysis-resistant programs.
Non-returning Calls. When a called function either never returns or returns
to an unexpected location by tampering with the call stack [25], one or more junk
bytes may follow the function call site. The simplest approach to this problem
would be to adopt the assumption made by BIRD [34] and Kruegel et al.’s
obfuscated code parser [24], that function calls never return, and then rely on
run-time monitoring of return instructions to discover code that follows call sites.
This runtime-discovery approach is taken by BIRD, and while it is our technique
of last resort, our data-ﬂow analysis of called functions can often tell us whether
the function will return, and to where, thereby increasing the code coverage
attained through parsing and avoiding unnecessary instrumentation.
Hybrid Analysis and Control of Malware
325
push ADDR
...
retn
(a)
ebp
pop
inc
ebp
push ebp
retn
(b)
Fig. 2. Code sequences that tamper with return addresses on the call stack
We take advantage of the depth-ﬁrst nature of our parsing algorithm to use
the analysis of called functions in deciding whether or not to continue parsing
after call instructions. We do not resume parsing after the call site if our analysis
of the called function contains no return instructions, or if our static call stack