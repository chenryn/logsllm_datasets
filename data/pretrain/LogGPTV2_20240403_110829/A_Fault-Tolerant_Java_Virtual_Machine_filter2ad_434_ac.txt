collector). As was the case for native threads, we cannot
reproduce scheduling events that involve system threads. 1
Ignoring system thread scheduling creates problems when
application and system threads share resources, such as the
heap, because both types of threads can contend for the
same locks.
In particular, interaction with system threads might result
in either of two events occurring during the recovery of an
application thread t:
1. t is forced to wait at the backup for a lock that was
acquired without contention at the primary. In this
case, t runs the risk of being rescheduled by the backup
before it can complete the sequence of instructions ex-
ecuted by its counterpart at the primary. We solve
this problem by adding a separate scheduler thread
and a private runnable queue (as in user-level thread
libraries) to guarantee that t will continue to be sched-
uled, without being interleaved with other application
threads, until necessary.
2. t acquires without contention at the backup a lock
for which it was forced to wait at the primary. So,
while t was rescheduled at the primary, it might not be
rescheduled at the backup. It is easy to use mon cnt to
enforce the correct scheduling.
Threads can also perform wait operations on a monitor,
blocking the thread until a corresponding notify or notifyAll
is performed.
If multiple threads are awakened, we need
to guarantee that they will acquire the monitor in the same
order at the primary and the backup. To do so, we store the
l asn of the monitor lock as part of the thread scheduling
record.
A ﬁnal subtle point arises when the backup completes
recovery, i.e. when it ﬁnishes processing the sequence of
thread scheduling records logged by the primary before fail-
ing. The last scheduling record in this sequence contains
the t id t(cid:1)
of the next thread that the primary intended to
schedule—the primary failed before recording at the backup
the scheduling record for t(cid:1)
. Nevertheless, the backup must
schedule t(cid:1)
might have interacted
because at the primary t(cid:1)
1Replicating thread scheduling at the OS level in the native threads li-
brary would allow us to handle all threads, but at the cost of reduced porta-
bility. Further, we would still have to modify the JVM to handle other
sources of non-determinism.
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 06:58:33 UTC from IEEE Xplore.  Restrictions apply. 
with the environment. t(cid:1)
these interactions are reproduced.
4.3. Garbage Collection
will execute at the backup until
Garbage collection in Sun’s JVM is both asynchronous
and synchronous. Any thread can synchronously collect
garbage by invoking a JRE native method. Asynchronous
garbage collection is performed periodically by a garbage
collector thread and during memory allocation when mem-
ory pressure indicates collection is needed. Since garbage
is unused memory by deﬁnition, we initially avoided repli-
cating the behavior of the asynchronous collector thread.
However, asynchronous garbage collection can be a source
of non-deterministic read sets. Indeed, both soft references
and ﬁnalizer methods create paths for non-deterministic in-
put to application threads.
Soft references are used to implement caches. By
fudging the deﬁnition of garbage, the referenced objects
are guaranteed to be garbage collected before an out-of-
memory error is returned to the application. Because R0
prevents such an error from being raised at all replicas, col-
lection of soft references might occur at different times at
different replicas. For instance, the primary might ﬁnd an
object in its cache, while the backup might not, leading the
execution of primary and backup to diverge. 2 Although we
could replicate the behavior of the asynchronous garbage
collector by recording when it locks the heap, we use a
much simpler solution: all soft references are simply treated
as strong references, which represent active objects and are
therefore never collected. This shortcut has no effect on our
experiments because there is never enough memory pres-
sure to dictate the collection of soft references.
Another possible source of non-determinism is improper
use of ﬁnalizer methods. These methods are intended to
allow objects to reclaim resources that cannot be freed au-
tomatically by the garbage collector (e.g., if memory was
allocated in a native method). The Java language speciﬁca-
tion states that ﬁnalizer methods are invoked on objects be-
fore the memory allocated to the object is reused, but does
not specify exactly when, allowing different behaviors at
the primary and the backup. Our current implementation
assumes that ﬁnalizer methods only free unused memory or
perform other deterministic actions on local memory. Since
no data is shared between the thread that runs the ﬁnalizer
on dead objects and any threads that previously used those
objects, no new source of non-determinism is introduced.
However, it is possible to write improper ﬁnalizer methods
that do more than free unused memory: in fact, they can
perform arbitrary actions, possibly with non-deterministic
side effects. Although we don’t currently replicate the invo-
cation of ﬁnalizers, it would be easy to do so using one of
the approaches discussed in Section 4.2.
4.4. Environment Output
We deal with output commands in native method through
a novel approach based on what we call side effect handlers
2Similar arguments also apply to weak references [8], which we treat
similarly.
(SE handlers). SE handlers are used to store and recover
volatile state of the environment and to ensure exactly-once
semantics for output commands. A handler consists of ﬁve
separate methods that are called at various stages of execu-
tion at each replica.
register This method registers with the JVM information
about the native methods that the handler will man-
age, including the signature of the method, whether
the method is a non-deterministic command and/or an
output command, and whether its arguments should be
logged (i.e., if they are also output arguments).
test The backup calls this method to test during recovery
whether an output command succeeded. For example,
the ﬁrst output command after recovery is terminated
is uncertain—we cannot in general decide whether the
command has completed.
test is called on an uncer-
tain command to determine whether a testable output
completed before failure, guaranteeing exactly-once
semantics. Commands for which the test method is
not deﬁned are considered idempotent and are simply
replayed.
log The primary calls this method after executing an out-
put command. The system provides log with the argu-
ments to the native method that performed the output
(including the class instance object), the return value
from the native method, and extra information about
the internal state of the JVM. log saves and returns in a
message all state necessary to recover the output of the
command. For example, on a ﬁle write this message
might store the ﬁle descriptor and the amount written
(or the current ﬁle pointer offset).
receive The backup calls this method to receive the state
stored by the primary through the log method. Before
saving the state, receive can compress it: for example,
receive could compress the results of several ﬁle writes
into one offset for the ﬁle pointer.
restore The backup calls this method during recovery. It
restore recovers the volatile
is invoked only once.
state affected by output commands.
If receive has
compressed the results of multiple commands, restore
might be able to recover the appropriate state directly
instead of replaying the commands. For example, to
recover an open ﬁle restore would open the ﬁle and set
the ﬁle pointer to the appropriate offset.
Each SE handler can manage a set of related native meth-
ods. For example, we have one handler for all native ﬁle
I/O methods. The handlers we have written for the stan-
dard libraries are automatically added to the system during
startup. Applications can incorporate their own handlers us-
ing the same functions. Using SE handlers allowed us to
add support for ﬁle I/O in the standard libraries. The same
approach can be used by application writers to incorporate
user-supplied output commands.
5. Experiments
Our experimental setup consists of two Sun E5000
servers, each with 15 400MHz UltraSPARC II cpus and
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 06:58:33 UTC from IEEE Xplore.  Restrictions apply. 
Implementation
Both
Replicated
Lock
Acquisition
Replicated
Thread Scheduling
Table 2: Properties of benchmarks pertinent to our implementation.
Event
Intercepted NM
NM Output Commits
Logged Messages
Locks Acquired
Objects Locked
Largest l asn
Logged Messages
Avg. Reschedules
jess
64088
763
4873592
4809503
4515
1410798
64089
0
jack
631295
34
12833046
12201750
505223
746136
631296
0
compress
419
102
2355
1935
102
633
420
0
db mpegaudio
10031
10
14717
4685
21
1955
10032
0
96011
703
53492759
53396747
15612
5286641
96012
0
mtrt
1473
133
701738
700264
161
34738
30638
29163
2GB memory running SunOS 5.8 connected by a 100 Mbps
Ethernet. The primary runs on one machine and logs events
at the backup running on the other. On performing an out-
put, the primary waits until the backup acknowledges hav-
ing logged all events up to the output event. The backup
keeps its log in volatile memory.
Sun’s JVM does not include the source code for Just-In-
Time (JIT) bytecode compilation, which dynamically con-
verts methods from bytecodes into native machine code in-
structions. Without the source we cannot use JIT compila-
tion because we cannot include our modiﬁcations to some
bytecode executions (e.g., interception of native method in-
vocations). Hence, all of our experiments are performed in
interpreted mode (i.e., without JIT compilation). JIT com-
pilation reduces the execution time of CPU intensive code
but has little effect on communication, which is our pri-
mary source of overhead. Hence, although the overhead
on a JVM using JIT compilation is hard to predict, we be-
lieve that probably it wouldn’t change signiﬁcantly except
for compress, which is 2 times faster on Sun’s HotSpot JVM
with JIT compilation. The other benchmarks vary from 20%
faster to 20% slower execution time, probably resulting in
comparable changes to the overhead.
To estimate the costs of adding fault tolerance to the
JVM, we run the SPEC JVM98 benchmark on the repli-
cated lock acquisition implementation, the replicated thread
scheduling implementation, and the original Sun JVM. The
programs in the benchmark vary widely in their character-
istics. Compress is a CPU-intensive Lempel-Ziv compres-
sion application. Jack is a parser generator which is run on
input to generate a parser for itself. Db contains a memory-
resident database that is queried multiple times. Jess is an
expert shell system that computes on a set of common puz-
zles with progressively larger rule sets. Mpegaudio decom-
presses MPEG-Layer 3 audio ﬁles. Mtrt is the only multi-
threaded application in the benchmark and consists of a ray-
tracer rendering a scene of a dinosaur. Though Mtrt is the
only multi-threaded application, several other apps (notably
Db) contain much synchronized code. We did not include
results for javac (included in SPEC JVM98) because we
could not get the application to run on Sun’s original JVM.
Table 2 summarizes the properties of the benchmark ap-
plications with respect to our implementation. Database
queries in Db result in the most lock acquisitions by far,
while Jack locks more unique objects. All applications have
few intercepted native methods and even fewer output com-
)
d
e
z
i
l
a
m
r
o
n
(
e
m
T
n
o
i
t
u
c
e
x
E
i
5
4
3
2
1
0
TS primary
TS backup
Lock primary
Lock backup
jess
jack
compress
db
mpegaudio
mtrt
Figure 2: Comparison of our implementations using green
threads normalized to our JVM without replication. The TS
columns represent our replicated thread scheduler imple-
mentation, and the Lock columns represent the replicated
lock acquisition implementation. The execution times of
each benchmark are (in secs): jess (167), jack (182), com-
press(541), db (354), mpegaudio (419), mtrt (163).
mits. The largest l asn shows that the lock acquisitions are
skewed—few locks are responsible for most acquisitions.
The average number of reschedules in the last row shows
that though many locks are acquired in all of the bench-