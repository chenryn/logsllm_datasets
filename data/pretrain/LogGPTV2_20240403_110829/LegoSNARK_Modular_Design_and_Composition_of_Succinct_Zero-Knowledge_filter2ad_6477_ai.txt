Efficiency. Our CPlin proves the result of a matrix-vector multiplication F · u = x for F ∈ Fn×m.
The prover sends one CPsc proof, two CPpoly proofs, three commitments and two ﬁeld elements.
31
CPlin.KeyGen(ck) → (ek, vk) :
(eks, vks) ← CPsc.KeyGen(ck) ; (ekp, vkp) ← CPpoly.KeyGen(ck)
ek := (ck, eks, ekp) ; vk := (cvk, vks, ekp)
CPlin.Derive((ek, vk), F ) :→ (ekF , vkF )
(cF , oF ) ← ComPoly
ekF := (ek, cF , F , oF ) ; vkF := (vk, cF )
(ck, ˜F )
∗
CPlin.Prove∗(ekF , x, cu, u, ou) → π :
Let g(S) := ˜F (r, S) · ˜u(S) ≡ g1(S) · ˜u(S) ; g0(S) := 1 ; (c1, o1) ← ComPoly(ck, g1)
r ← H1(cF , cu, x),
∗
)
π1 ← CPpoly.Prove(ekp, σ, (c1, c
πF ← CPpoly.Prove(ekp, (r, σ), (cF , c
t ← ˜x(r) ; (ct, ot) ← ComVal(ck, t) ; πsc ← CPsc.Prove(eks, g0(S), (ct, c1, cu), (t, ot, g1, o1, ˜u, ou))
π := (ct, ot, c1, c
; σ ← H2(cF , c1, r) ; y
), (o1, o
∗ ← g1(σ) ; (c
∗
), ( ˜F , ˜F (r, σ)), (oF , o
) ← ComVal
∗
), (g1, y
(ck, y
, o
))
))
∗
∗
∗
∗
∗
∗
CPlin.VerProof∗(cid:0)vkF , x, cu, π(cid:1) → b ∈ {0, 1} :
, π1, πF , πsc)
, y
∗
∗
r ← H1(cF , cu, x) ; t ← ˜x(r) ; σ ← H2(cF , c1, r) ; Let g0(S) := 1
b ← VerCommit(cvk, ct, t, ot) ∧ VerCommit
∗
(cvk, c
, y
∗
∗
) ∧ CPsc.VerProof(vkp, g0(S), (ct, c1, cu), πsc)
∧ CPpoly.VerProof(vks, σ, (c1, c
∗
), π1) ∧ CPpoly.VerProof(vkp, (r, σ), (cF , c
∗
), πF )
Figure 6: CP-SNARK for specializable universal Rlin
Here the polynomial used inside sum-check is at most degree 2 in each of its µ = log m variables.
Here, p = 2 = d because g0 is the constant polynomial and does not increase the total maximum
degree inside sum-check. Also, the number of variables for the ﬁrst CPpoly proof over g1(S) is log m
and the number of monomials is m. For the second one over ˜F (r, S) with N monomials, the number
of variables is log n + log m = log N. The crs output by the derivation function includes matrix F .,
whereas the output of CPlin.KeyGen has (2 · 2ν+µ + 3)G1 + (ν + µ + 3)G2 elements; that is, we are
not considering the derived version including the description of matrix F (as this is part of the
statement).
Theorem 5.4. In the random oracle model, assuming PolyCom is an extractable trapdoor commit-
ment and CPpoly and CPsc are zero-knowledge CP-SNARKs for PolyCom, then CPlin in Figure 6 is
a zero-knowledge CP-SNARK for PolyCom and relations Rlin.
5.6 A CP-SNARK for Matrix Multiplication
In this section we propose a CP-SNARK for PolyCom for the relation Rmm over DA × DB × DC
where DA = Fn×n(cid:48), DB = Fn(cid:48)×m, DC = Fn×m and Rmm(A, B, C) = 1 ⇐⇒ C = A · B. Namely,
for two committed matrices A and B, one can prove that another committed matrix C equals to
their product.
The scheme is inspired by the interactive proof of matrix multiplication of Thaler [Tha13],
making it a ZK argument with similar ideas to those in [ZGK+17b]. We build our scheme for the
polynomial commitment scheme PolyCom and CP-SNARKs CPpoly and CPsc for the relations Rpoly
and Rsc for factored polynomials.
We present this scheme for square matrices for readability, but the protocol can be simply
adapted to the general form. Let matrices A, B, C ∈ Fn×n, we build their multilinear extension
32
˜C ∈ Fµ×Fµ → F with µ = log n, which is the unique polynomial such that ˜C(i1, . . . , iµ, j1, . . . , jµ) =
Ci,j if {ik}µ
k=1 are the binary representation of indexes i and j (resp. ˜A and ˜B).
k=1 and {jk}µ
Then, we can represent matrix multiplication as
(cid:88)
˜C(I, J ) =
˜A(I, b) · ˜B(b, J )
b∈{0,1}µ
where (I, J ) could be seen as as a single vector of length 2µ. However, we will stick to this notation
instead as it makes clearer that multilinearity is conserved after the product of ˜A and ˜B.
The protocol works as follows. The prover evaluates ˜C on a randomly chosen value (ρ|σ) and
obtains a proof that the output t is indeed the result of the polynomial evaluation t = ˜C(ρ, σ)
using CPpoly. Then, the prover convinces the veriﬁer that ˜C is well-formed using CPsc, i.e. t =
0 gi(S), where g1(S) := ˜A(ρ, S), g2(S) := ˜B(S, σ) and g0(S) := 1 is
(cid:80)
b∈{0,1}µ g(b). Here g(S) =(cid:81)2
the all-ones constant polynomial.
Efficiency. The cost of this scheme is given by the complexity of CPpoly and CPsc. The proving
time of the former is linear in the number of monomials of the polynomial ˜C, which is 22µ by
construction. Similarly, the latter’s is linear in the monomials of g(S), which is again 22µ. This
makes a linear prover in the number of elements (N = n2). The veriﬁer runtime is linear in the
number of variables of the polynomials (i.e. 2µ). The crs size is given by that of CPpoly for committed
polynomials of length 2µ and δ = 1 (because ˜A, ˜B and ˜C are multilinear polynomials of log n + log n
variables). That is, it has linear length in the matrix size with 2n2 + 3 G1 and 2µ + 3 G2 elements.
The proof involves one CPpoly proof (4µ + 2 G1, with 2µ variables), one CPsc proof (11µ + 11 G1
and µ + 5 F, with µ variables) and one commitment (2 G1).
Theorem 5.5. In the random oracle model, assuming that PolyCom is an extractable trapdoor com-
mitment, CPpoly and CPsc are zkSNARKs for PolyCom and relations Rpoly and Rsc respectively, then
the scheme CPmm
16 described above is a zkSN ARK for PolyCom and relation Rmm.
CP-SNARK for Matrix Multiplication with Known Output
In this section we propose a variation of our CPmm for PolyCom for the relation Rmmp over DX ×
DA × DB where Dx = Fn×m, DA = Fn×n(cid:48), DB = Fn(cid:48)×m and Rmmp(X, A, B) = 1 ⇐⇒ X = A · B.
Namely, for two committed matrices A and B, one can prove that a public matrix X equals to
their product. This version is more eﬃcient than the obvious solution of opening the commitment
to C in the CPmm scheme.
These two versions only vary only subtly on the way the matrix X is treated. Here, the veriﬁer
can check the correct evaluation on a random value t ?= ˜X(ρ, σ), with no need of relying on CPpoly.
We give the complete protocol in Figure 7 for completeness but we do not provide a formal proof,
as its security is trivially implied by that of CPmm.
The asymptotic complexity of the prover in this scheme is the same as that in CPmm. In practice
however, the prover is twice faster, as it will not run CPpoly. Conversely, the veriﬁer will be slower
because evaluating ˜X(ρ, σ) is more costly than verifying a CPpoly proof (about O(n2) ﬁeld operations
vs. O(log n) group operations). Note here that evaluating the MLE of X as
χb(x1, . . . , x2µ) · X(b)
˜X(x1, . . . , x2µ) :=
(cid:88)
b∈{0,1}2µ
16 This scheme was occasionally referred to as LegoMM in the proceedings version of this paper.
33
CPmm.KeyGen(ck) → (ek, vk) :
(eks, vks) ← CPsc.KeyGen(ck)
(ekp, vkp) ← CPpoly.KeyGen(ck)
return (ck, ekp, eks, H), (cvk, vkp, vks, H)
CPmm.VerProof(vk, cA, cB, cC , π) → b ∈ {0, 1} : Let g(S) := ˜A(ρ, S) · ˜B(S, σ) ≡ g1(S) · g2(S)
Deﬁne constant function g0(S) := 1
b ← CPpoly.VerProof(vkp, (ρ, σ), cC , ct, πt)
CPmm.Prove(ek, cA, cB, cC , A, B, C, oA, oB, oC , ) → π :
(ρ|σ) ← H(cA, cB, cC ) ; t ← ˜C(ρ, σ)
(ct, ot) ← ComVal(ck, t)
Deﬁne constant function g0(S) := 1
πt ← CPpoly.Prove(ekp, (ρ, σ), (cC , ct), ( ˜C, t), (oC , ot))
πsc ← CPsc.Prove(eks, g0(S), (ct, cA, cB), (t, ot, ˜A, oA, ˜B, oB))
return π ← (ct, πt, πsc)
∧ CPsc.VerProof(vks, g0(S), (ct, cA, cB), πsc)
CPmmp.KeyGen(ck) →(cid:0)ek, vk(cid:1) :
return(cid:0)(ck, eks, H), (cvk, vks, H)(cid:1)
(eks, vks) ← CPsc.KeyGen(ck)
CPmmp.Prove(ek, cA, cB, X, A, B, oA, oB) → π :
(ρ|σ) ← H(X, cA, cB) ; t ← ˜X(ρ, σ) ; (ct, ot) ← ComVal(ck, t)
Let g(S) := ˜A(ρ, S) · ˜B(S, σ) ≡ g1(S) · g2(S) ; g0(S) := 1
π ← CPsc.Prove(eks, g0(S), (ct, cA, cB), (t, ot, ˜A, oA, ˜B, oB))
CPmmp.VerProof(vk, X, cA, cB, π) → b ∈ {0, 1} :
(ρ, σ) ← H(X, cA, cB) ; t ← ˜X(ρ, σ) ; (ct, ot) ← ComVal(ck, t) ; g0(S) := 1
b ← CPsc.VerProof(vks, g0(S), (ct, cA, cB), π)
where χb(x1, . . . , x2µ) :=(cid:81)2µ
j=1
Figure 7: CP-SNARK for matrix multiplication with committed output (top) and CP-SNARK for
matrix multiplication with known output (bottom)
(cid:0)bj · xj + (1 − bj)(1 − xj)(cid:1), takes both the prover and the veriﬁer
b∈{0,1}2µ X(b)(cid:81)2µ
(cid:80)
22µ · 2µ operations naively. Following the strategy of [Tha13], the terms χb can be precomputed
oﬄine so that computing each χb(x) · X(b) takes a constant time and evaluating ˜X(ρ, σ) becomes
a quadratic-time task in n (as 22µ = n2).
Efficiency. Our CPmmp proves matrix multiplication X = A · B where the output X is given
in clear. We consider square matrices of N = n × n elements with n = 2µ. Both prover and
veriﬁer evaluate the ˜X on a 2µ−length random point. By construction of the MLE ˜X(r1, . . . , r2µ) =
j=1 χbj (rj), this carries a cost of 22µ·2µ = 2n2 log n = O(N log n) ﬁeld operations,
which can be reduced to O(N ) through dynamic programming techniques [Tha13]. As the degree–2
polynomial g(S) inside sum-check has µ variables, the proving algorithm in CPsc involves O(µ)
group operations. Checking πsc requires O(µ) more group operations from the veriﬁer. The proof
contains one CPsc proof consisting of (11µ + 11)G1 and (µ + 5)F. The crs in this scheme is the same
as the one in CPsc for p = 2 = d and δ = 1, which also coincides with that of CPmm. That is, it has
linear length in the matrix size with (2n2 + 3)G1 and (2µ + 3)G2 elements. We do not include the
description of the public matrix as this is part of the statement.
Theorem 5.6. In the random oracle model, assuming that PolyCom is an extractable trapdoor com-
mitment and CPsc is a zkSNARK for PolyCom and relation Rsc, then the scheme CPmmp is a zk-
SNARK for PolyCom and relation Rmmp.
34
6 LegoSNARK Applications and Evaluation
In this section we show how to use the modular commit-and-prove approach to obtain new CP-
SNARKs for computations expressible by arithmetic circuits (ACs) and we discuss the resulting
instantiations. Precisely, we show new CP-SNARKs for (1) arithmetic circuit satisﬁability, and (2)
parallel computation on joint inputs.
In both constructions the idea is to break the target problem into the conjunction of simpler
relations with shared input. Once having done this, and assuming the existence of CP-SNARKs
for these simpler relations and that share the same commitment scheme, we immediately obtain a
CP-SNARK for the target problem by applying our composition Theorem 3.1. Furthermore, thanks
to our lifting transformation of Section 3.5 sharing the same commitment scheme is not a restricting
requirement.
6.1 Preliminaries and Building Blocks
We begin by formalizing some basic relations useful to express our target problems.
Equalities Among Vector Entries. A common building block in both schemes of this section is
a system for proving that the entries of a vector satisfy a set of equalities between them. Namely,
given a set S of pairs of indices (i, k), we deﬁne a relation Rveq
that holds for a vector u iﬀ ui = uk
for all (i, k) ∈ S.
Deﬁnition 6.1 (Relation for equalities among vector entries). Let D be some domain (e.g.,
j=0 nj. Given
S over D0 ×···×D(cid:96) = Dm such
a set S = {(i1, k1), . . . , (il, kl)} ⊂ [m]× [m], we deﬁne a relation Rveq
that: Rveq
a ﬁnite ﬁeld F), let n0, . . . , n(cid:96) be positive integers such that Dj := Dnj and let m =(cid:80)(cid:96)
(cid:1) = 1 ⇐⇒ ∀(i, k) ∈ S : yi = yk, where y := (x, (uj)j∈[(cid:96)]).
(cid:0)x, (uj)j∈[(cid:96)]
S
S
φ
S
can be expressed using Rsfprm
In what follows, we discuss diﬀerent ways to encode this relation.
The relation Rveq
in Deﬁnition 5.2 for an appropriate permutation
φ that encodes S. The idea is that a set S ⊂ [m] × [m] can be seen as the description of an
undirected graph with 2m vertices. From S it is possible to extract another set S(cid:48) ⊂ [m] × [m]
that contains a cycle ((i1, k1), . . . , (it, kt)) for every connected component of the graph represented
by S. Taking the product of all the cycles in S(cid:48) deﬁnes a permutation φ : [m] → [m] such that
∀(i, k) ∈ S : yi = yk iﬀ ∀j ∈ [m] : yj = yφ(j). Then for such φ computed from S we have
S (x, (uj)j∈[(cid:96)]) ⇐⇒ Rsfprm
Rveq
(x, (uj)j∈[(cid:96)]). We refer to [Gro09, BCG+17] for more details on the
idea of this permutation encoding. Here is a small example. Consider an arbitrary m and assume
S = {(1, 2), (1, 3), (3, 4), (6, 7)}. One can deﬁne a permutation φS over [m] as: φS(1) = 2, φS(2) = 3,
φS(3) = 4, φS(4) = 1, φS(6) = 7, φS(7) = 6, and φS(j) = j for all 8 ≤ j ≤ m.
φ
At this point one can either assume to have a proof system for Rsfprm
(as in Section 5.4) or to
use an encoding of Rsfprm
based on linear constraints that can be obtained as follows. The idea is to
deﬁne a relation on a vector y ∈ Fm that is true iﬀ Z·y = 0, where Z ∈ Fm(cid:48)×m, with m(cid:48) ≤ m, is the
matrix obtained by removing the zero rows from (I − Σφ) ∈ Fm×m, where Σφ is the permutation
matrix representing φ. Then clearly Rsfprm
Z (0, x, (uj)j∈[(cid:96)]) holds, where the
relation Rlin, modelling the linear property over (committed) vectors, is formally deﬁned as follows.
(x, (uj)j∈[(cid:96)]) holds iﬀ Rlin
φ
φ
φ
35
Dnj}j∈[1,2], {Du,j := Dmj}j∈[(cid:96)], and m = n2 +(cid:80)(cid:96)
Deﬁnition 6.2 (Linear property relation). Let n1, n2, m1, . . . , m(cid:96) be integers such that {Dx,j :=
j=1 mj. Given a matrix F ∈ Dn1×m, we deﬁne a