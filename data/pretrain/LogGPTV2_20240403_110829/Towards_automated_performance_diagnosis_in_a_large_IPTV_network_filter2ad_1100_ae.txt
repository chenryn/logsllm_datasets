Games
Total
13
10.1
14
0
17
28
87
19.1
70
60.4
21.1
70
69
75
91
57
17.2
8.3
58
25
0.4
56.3
5.5
5.5
4.5
6
6
39
4.1
17
1.2
29
5.3
11.5
15.4
6.5
4
20
15.8
0.6
5.9
3.8
10.2
17.7
Table 6: Trouble ticket characterization by problem (row) and
mitigation actions (column). Each entry represents a percent-
age.
4.3.2 Video Quality Alarms
In this subsection, we focus on symptom series from alarms gen-
erated by the video quality monitors deployed inside the IPTV ser-
vice provider network. An alarm indicates an impairment in video
quality due to problems such as excessive delay factor (DF), media
loss rate (MLR), video stream outage, transport stream outage, IP
ﬂow bit rate thresholding crossing, transport stream synchroniza-
tion errors and transport stream bit rate thresholding crossing. The
video quality monitors are deployed at VHOs. Each VHO is re-
sponsible for a geographical region, which is the highest spatial
level deﬁned in Giza. We consider each type of alarms as a symp-
tom event-series and correlate it with other event-series extracted
from router syslogs at the VHO and the trouble tickets from cus-
tomers that are associated with the VHO.
Correlation results. We perform the correlation analysis for data
collected over one month. The correlation time window is set as
60 seconds. When correlating alarms data with customer tick-
ets, we use a time lag of four hours. We observe strong statis-
tical correlations between video quality alarms and syslog events
in the provider network such as conﬁguration changes, SAP port
state changes, SDP bind status changes, BGP session downs, PPP
/ RSVP / SONET link downs, multicast neighbor loss, MPLS path
re-routes and layer-1 link ﬂaps. However, most types of the video
quality alarms do not statistically correlate with customer trouble
tickets. This is partially because the alarms from the monitoring
device are too low-level – the intention of the alarms is for moni-
toring the health of video distribution network as opposed to mon-
itoring customer perceived performance. The alarmed short term
packet losses or delay jitters can be automatically repaired by FEC
or retransmission of RUDP without introducing interruption on de-
coding of the video stream, hence have no impact to customers. By
looking at the signiﬁcance of the correlation result, we can easily
distinguish the alarms that would produce severe performance im-
pairment of the video stream delivered to customers from those that
would not. For example, the alarm on long term (24 hour) excessive
media loss rate are likely due to a persistent video feed problem and
is identiﬁed to be correlated with customer complaints. We have
also validated the discovered dependencies of video quality alarms
on network events (extracted from router syslogs) with network op-
erators. We will further investigate the causal relationships among
the network events in the next section.
240Number of
event-series
Pairs to
correlate
Strong
pair-wise
correlations
ℓ1 + statistical
change lag
correlation
ℓ1 +max lag
correlation
1318
867,903
3352
960
972
Table 7: Provider network syslog correlation and causality re-
sults.
Layer−1 alarms
VRRP Packet
Discards
Link Down
Configuration
Changes
OSPF Interface
State Down
Multicast (PIM)
Neighbor Loss
MPLS Interface
State Changes
SAP Port
State Changes
SDP Bind
Status Changes
MPLS Path
Re−routes
tual router. When the primary physical router is down, the back-up
router takes over.
The strong statistical correlation between VRRP packet discards
at VHO and SHO and multicast neighbor loss was due to pack-
ets looping within the network that causes the multicast protocol
to timeout and resulting in neighbor loss. The behavior was more
prevalent within the SHO and at VHOs closer to the SHO. Interest-
ingly, when VRRP packet discards have a temporal correlation (or
join) with multicast neighbor loss, we do not observe link downs.
Thus, the packet looping does not appear to have been caused by
link failures. We are currently collaborating with the operations
team to analyze this scenario to further understand the behavior.
Figure 12: Causal graph between certain network syslog event-
series.
5. RELATED WORK
In this section, we present related work.
4.4 Case Study: Provider Network Events
As discussed in Section 4.3.1, we observe statistical correla-
tion between certain provider network syslog events (such as link
downs, SAP/SDP state changes, multicast neighbor loss, MPLS
path re-routes) and different types of trouble tickets. In this sec-
tion we further investigate statistical dependencies of these events
on other provider network events.
The provider network syslog data contains a diverse set of events.
Creating a separate time-series based on each unique message type
results in the creation of hundreds of individual event-series from
syslogs at every VHO or SHO. This provides us with a perfect op-
portunity to apply our statistical lag correlation and ℓ1 norm mini-
mization algorithms, to analyze how well they cope with the scale.
We use one week worth of data to perform the causality analy-
sis on 80 VHO and SHO routers within the provider network. We
focus on four symptom event-series that demonstrate strong corre-
lations with trouble tickets: (i) link down, (ii) SAP state changes,
(iii) multicast neighbor loss, (iv) MPLS path re-routes.
Correlation and causality discovery results. Table 7 shows the
correlation and causality discovery results for the provider network
syslog data. There are a total of 1318 syslog event-series at several
VHO and SHO locations. The total number of pairs to correlate is
867,903 (= 1318∗1317
), out of which 3352 have strong correlation.
For correlation, we perform the analysis for events that occur at
the same VHO or SHO. This achieves a reduction of 99.6% com-
pared to the number of pairs for correlation. ℓ1 norm minimization
along with lag correlation further reduces the number of pairs and
achieves around 99.89% reduction.
2
A part of the causal graph reported by Giza is shown in Fig. 12.
As can be seen in the ﬁgure, the root cause for link downs is layer-
1 alarms. Link downs in turn cause SAP port state changes, OSPF
interface state changes, SDP bind status changes, MPLS interface
state changes, and multicast neighbor loss. These conclusions are
consistent with domain knowledge, and with how the network tech-
nologies were designed to operate. The advantage of Giza is that it
can discover the causal graph with minimal domain knowledge.
Findings. For the week analyzed, MPLS path re-routes had their
major root cause as in conﬁguration changes. As would be ex-
pected, the strong statistical correlation is observed during the main-
tenance time-window - the time during which network operations
personnel are executing planned maintenance activities. Multicast
neighbor losses demonstrated strong correlations with both link
downs and conﬁguration changes.
We also observed an interesting previously unknown dependency
between multicast neighbor loss and VRRP packet discards. VRRP
stands for virtual router redundancy protocol and is used for in-
creased network reliability. It is achieved by advertising a virtual
router as a default gateway to the hosts instead of one physical
router. Two or more physical routers are conﬁgured to act as a vir-
IPTV, P2P, VoD Analysis. Cha et al.
[6] present the ﬁrst large-
scale study of user behaviors in IPTV system. They characterize
user behaviors such as channel popularity and dynamics, viewing
sessions, geographic locality and channel surﬁng probabilities. Qiu
et al. [24] develop a model that captures the dynamics of channel
popularity in IPTV network. There are many previous measure-
ment studies on VoD [8, 19, 31], P2P IPTV [18, 25].
Our study, on the other hand, focuses on characterizing perfor-
mance impairments and faults in a large-scale IPTV system. We
believe, this is the ﬁrst characterization study aiming to understand
the performance issues in large-scale operational IPTV networks.
Hierarchical Heavy Hitter (HHH) Detection. There has been
a great deal of work on ﬁnding heavy hitters at multiple aggrega-
tion points in network trafﬁc data. Their goal is to identify source-
destination preﬁxes at multiple hierarchies that contribute to a large
fraction of the total network trafﬁc. Cormode et al.
[12] was the
ﬁrst to extend the idea of heavy hitters to multiple dimensions. Aut-
oFocus [16] presents several heuristics to detect interesting traf-
ﬁc clusters corresponding to anomalous trafﬁc conditions.
[13]
presents online algorithms to identify approximate HHHs in one
pass. [1, 32] propose algorithms to discover changes in hierarchi-
cal summaries.
The key difference of our signiﬁcance test for detecting hierar-
chical heavy hitters is our ability to handle the diversity of distribu-
tion of spatial components across different aggregation levels.
Network Troubleshooting using Statistical Analysis. Recently,
there has been an increasing interest in applying statistical anal-
ysis for network troubleshooting. The goal is given a symptom
problem, identify the set of root-causes that can best explain the
symptom. SCORE [22] applies bipartite graph to solve the fault
diagnosis problem. Shrink [21] extends this model to deal with
probabilistic settings. Sherlock [4] proposes a multi-level graph
inference to learn the dependencies in enterprise networks. eX-
pose [20] learns communication rules in edge networks using spec-
tral graph partitioning that is useful in monitoring and intrusion
detection. WISE [28] is a what-if analysis tool that estimates the
effects of possible changes to network conﬁguration on service re-
sponse times.
Yemini et al. [30] present an event correlation library that de-
scribes faults and the symptoms of faults using a codebook. Net-
Diagnoser [14] performs fault localization using Boolean tomogra-
phy. Orion [7] uses delay spike analysis to discovery pair-wise de-
pendencies in network trafﬁc. NICE [23] focuses on troubleshoot-
ing undesirable chronic network conditions using Pearson’s corre-
lations. NetPrints [2] uses decision-tree learning for troubleshoot-
ing home network mis-conﬁgurations.
[27] is a white paper that
discusses recent research efforts at Alcatel Lucent for designing
end-to-end diagnosis capabilities in IPTV. Causal modeling is an
area of active research, with rich literature in data mining and ma-
chine learning [3, 5, 9, 11, 17, 26].
241Property
Sherlock
Orion
Auto-correlation
Multi-variate analysis
Multi-collinearity
Automated edge directionality
Multi-resolution analysis
X
X
X
√
X
X
X
X
√
X
NICE WISE
√
X
X
X
X
X
√
X
√
X
Giza
√
√
√
√
√
Table 8: Troubleshooting Infrastructure Taxonomy.
We provide a qualitative comparison of several recently pro-
posed troubleshooting infrastructures in Table 8. As you can see,
Sherlock and Orion focuses mainly on pair-wise correlation analy-
sis and aims to automatically discover the directionality of the cor-
relation. NICE addresses the auto-correlation within each event-
series and reduces false alarms when discovering the correlation
graph. WISE is the ﬁrst to apply multi-variate correlation tech-
niques. However, WISE does not address auto-correlation and multi-
collinearity when discovering causal dependencies. This leads to
lower accuracy as we show in Section 4. Giza addresses auto-
correlation, goes beyond pair-wise analysis, handles multi-collinearity
problem when performing the regression, discovers edge direction-
ality automatically and performs multi-resolution analysis.
6. CONCLUSIONS
In this paper, we presented the ﬁrst characterization study of
faults and performance impairments in the infrastructure of a large
IPTV service provider in North America. Our analysis spanned
routers in the backbone to set top boxes (STB) and residential gate-
ways (RGs) in home networks, hardware and software crashes to
video quality impairments. To deal with the scale and heterogene-
ity of the IPTV network, we proposed and designed a novel multi-
resolution data analysis approach termed Giza that enables fast de-
tection and localization of problems. We also proposed novel tech-
niques comprising of statistical lag correlations and ℓ1 norm min-
imization for effective and scalable causal discovery. Our experi-
ence with applying Giza in the IPTV network has been very posi-
tive. The infrastructure promises to be of immense value to IPTV
network operators in automatically detecting and troubleshooting
important performance issues.
Acknowledgement
We thank Aldo Adriazola, Seungjoon Lee, and Sigcomm anony-
mous reviewers for their feedback. We are also grateful to the
network operations and customer support teams of the anonymous
IPTV service provider for their kind help on the data collection and
the case study analysis. This work was supported in part by NSF
grants CNS-0546720, CNS-0615104, and CNS-0627020.
7. REFERENCES
[1] D. Agarwal, D. Barman, D. Gunopulos, N. E. Young,
F. Korn, and D. Srivastava. Efﬁcient and effective
explanation of change in hierarchical summaries. In ACM
KDD, 2007.
[2] B. Aggarwal, R. Bhagwan, V. N. Padmanabhan, and
G. Voelker. NetPrints: Diagnosing home network
misconﬁgurations using shared knowledge. In NSDI, 2009.
[3] A. Arnold, Y. Liu, and N. Abe. Temporal causal modeling
with graphical granger methods. In ACM KDD, pages 66–75,
2007.
[4] P. Bahl, R. Chandra, A. Greenberg, S. Kandula, D. A. Maltz,
and M. Zhang. Towards highly reliable enterprise network
services via inference of multi-level dependencies. In
Sigcomm, 2007.
[5] W. Buntine. Theory reﬁnement on Bayesian networks. In
Proc. Uncertainty in artiﬁcial intelligence, 1991.
[6] M. Cha, P. Rodriguez, J. Crowcroft, S. Moon, and
X. Amatriain. Watching Television over an IP Network. In
ACM IMC, 2008.
[7] X. Chen, M. Zhang, Z. M. Mao, and P. Bahl. Automating
network application dependency discovery: Experiences,
limitations, and new solutions. In OSDI, 2008.
[8] B. Cheng, L. Stein, H. Jin, and Z. Zhang. Towards cinematic
internet video-on-demand. In ACM EuroSys, 2008.
[9] P. R. Cohen, L. A. Ballesteros, D. E. Gregory, and R. S.
Amant. Regression can build predictive causal models.
Technical Report UM-CS-1994-015, 1994.
[10] P. R. Cohen, D. E. Gregory, L. Ballesteros, and R. S. Amant.
Two algorithms for inducing structural equation models from
data. Technical Report UM-CS-1994-080, 1994.
[11] G. F. Cooper and E. Herskovits. A bayesian method for the
induction of probabilistic networks from data. Machine
Learning, 9(4):309–347, 1992.
[12] G. Cormode, F. Korn, S. Muthukrishnan, and D. Srivastava.
Finding hierarchical heavy hitters in data streams. In VLDB,
2003.
[13] G. Cormode, F. Korn, S. Muthukrishnan, and D. Srivastava.
Diamond in the rough: ﬁnding hierarchical heavy hitters in
multi-dimensional data. In ACM Sigmod, 2004.
[14] A. Dhamdhere, R. Teixeira, C. Dovrolis, and C. Diot.
Netdiagnoser: troubleshooting network unreachabilities
using end-to-end probes and routing data. In CoNEXT, 2007.
[15] D.L.Donoho. For most large underdetermined systems of
equations, the minimal l1-norm near solution approximates
the sparsest near-solution. In http://www-stat.stanford.edu/
donoho/Reports/, 2004.
[16] C. Estan, S. Savage, and G. Varghese. Automatically
inferring patterns of resource consumption in network trafﬁc.
In ACM Sigcomm, 2003.
[17] C. W. J. Granger. Investigating causal relations by
econometric models and cross-spectral methods. In
Econometrica, 1969.
[18] X. Hei, C. Liang, J. Liang, Y. Liu, and K. W. Ross. A
measurement study of a large-scale P2P IPTV system. IEEE
Transaction on Multimedia, 2007.
[19] Y. Huang, T. Z. Fu, D.-M. Chiu, J. C. Lui, and C. Huang.
Challenges, design and analysis of a large-scale P2P-VoD
system. In ACM Sigcomm, 2008.
[20] S. Kandula, R. Chandra, and D. Katabi. What’s going on?
learning communication rules in edge networks. In Sigcomm,
2008.
[21] S. Kandula, D. Katabi, and J.-P. Vasseur. Shrink: A tool for
failure diagnosis in IP networks. In MineNet, 2005.
[22] R. R. Kompella, J. Yates, A. Greenberg, and A. C. Snoeren.
Detection and localization of network blackholes. In
Infocom, 2007.
[23] A. Mahimkar, J. Yates, Y. Zhang, A. Shaikh, J. Wang, Z. Ge,
and C. T. Ee. Troubleshooting chronic conditions in large IP
networks. In ACM CoNEXT, 2008.
[24] T. Qiu, Z. Ge, S. Lee, J. Wang, J. Xu, and Q. Zhao. Modeling
channel popularity dynamics in a large IPTV system. In
ACM Sigmetrics, 2009.
[25] T. Silverston and O. Fourmaux. P2P IPTV measurement: a
case study of TVants. In ACM CoNEXT, 2006.
[26] P. Spirtes, C. N. Glymour, and R. Scheines. Causation,
prediction and search. Lecture Notes in Statistics, 1993.
[27] K. Sridhar, G. Damm, and H. C. Cankaya. End-to-end
diagnostics in IPTV architectures. Bell Lab. Tech. J., 2008.
[28] M. Tariq, A. Zeitoun, V. Valancius, N. Feamster, and
M. Ammar. Answering what-if deployment and
conﬁguration questions with WISE. In SIGCOMM, 2008.
[29] Wikipedia. Chebyshev inequality.
http://en.wikipedia.org/wiki/Chebyshev’
s_inequality.
[30] S. A. Yemini, S. Kliger, E. Mozes, Y. Yemini, , and D. Ohsie.
High speed and robust event correlation. In IEEE Comm.,
1996.
[31] H. Yu, D. Zheng, B. Y. Zhao, and W. Zheng. Understanding
user behavior in large-scale video-on-demand systems. ACM
Sigops Operating Systems Review, 2006.
[32] Y. Zhang, S. Singh, S. Sen, N. Dufﬁeld, and C. Lund. Online
identiﬁcation of hierarchical heavy hitters: algorithms,
evaluation, and applications. In ACM IMC, 2004.
242