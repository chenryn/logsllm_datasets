title:Secure Tera-scale Data Crunching with a Small TCB
author:Bruno Vavala and
Nuno Ferreira Neves and
Peter Steenkiste
2017 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Secure Tera-scale Data Crunching with a Small TCB
1LaSIGE, Faculdade de Ciˆencias, Universidade de Lisboa, Portugal
2CSD, Carnegie Mellon University, U.S.
Bruno Vavala1,2,
Nuno Neves1,
Peter Steenkiste2
Abstract—Outsourcing services to third-party providers comes
with a high security cost—to fully trust the providers. Us-
ing trusted hardware can help, but current trusted execution
environments do not adequately support services that process
very large scale datasets. We present LASTGT, a system that
bridges this gap by supporting the execution of self-contained
services over a large state, with a small and generic trusted
computing base (TCB). LASTGT uses widely deployed trusted
hardware to guarantee integrity and veriﬁability of the execution
on a remote platform, and it securely supplies data to the
service through simple techniques based on virtual memory. As
a result, LASTGT is general and applicable to many scenarios
such as computational genomics and databases, as we show
in our experimental evaluation based on an implementation of
LASTGT on a secure hypervisor. We also describe a possible
implementation on Intel SGX.
1.
INTRODUCTION
Outsourced applications such as cloud services (databases,
storage, etc.) are widely deployed but strong security guaran-
tees are taken for granted. The de facto security model assumes
that the service provider is fully trusted. In the real world, how-
ever, one third of the top threats listed by the Cloud Security
Alliance [33] concern an attacker tampering with the integrity
of computation or data, namely: (i) service hijacking [38], (ii)
malicious insiders [1], (iii) system vulnerabilities [39], and (iv)
shared technology issues [2]. This can raise suspicions on the
trustworthiness of the results produced by a service.
The above threats stem from at least three issues:
• the lack of strong execution isolation, whereby a sub-
verted OS, or hypervisor, or service application, can make
threats affect other running software.
• a large TCB, which makes systems hard to verify; also,
when it includes the OS—containing millions of lines of
code [35]—a bug in the kernel [34] endangers security of
all the applications and data.
• a complex OS interface—hundreds of system calls—
which is difﬁcult to secure [30] and whose malicious
alteration can subvert an application [3].
Unfortunately, service owners and end-users have little or no
means to distinguish between correct and compromised service
code or input data by just looking at the results received from
the cloud.
Trusted Computing (TC) technology is making progress
towards allowing clients to verify results. The technology (e.g.,
Trusted Platform Modules (TPMs) [4] and Intel SGX [29]) is
available in commodity platforms, and it is tied to a hardware
root of trust certiﬁed by the manufacturer. This can be used
by a service provider to isolate the service execution and to
attest the identity of the executed code for remote veriﬁcation.
Software support for such trusted hardware however is not
(or just partially) suitable for many applications that process
a huge amount of data (e.g., clinical decision support [5],
predictive risk assessment for diseases [6], malware detection
[7], workloads for sensitive ﬁnancial records outsourced on
public clouds [8], and genome analytics [9]). Previous systems
support the execution of either small pieces of code and data
[10], or large code bases [11], or speciﬁc software like database
engines [12] or MapReduce applications [13]. Recent work
[14] has shown how to support unmodiﬁed services. However,
since ”the interface between modern applications and operating
systems is so complex” [30], it relies on a considerable TCB
that includes a library OS. In addition, the above systems are
speciﬁc for TPMs [10], [15], secure coprocessors [12], or Intel
SGX [13]. Hence, porting them to alternative architectures
(e.g., the upcoming AMD Secure Memory Encryption and
Secure Encrypted Virtualization [36], [37]) requires signiﬁcant
effort. Clearly, it is desirable to design a generic system “not
relying on idiosyncratic features of the hardware” [16].
We present LASTGT, a system that can handle a LArge
STate on a Generic Trusted component with a small TCB.
LASTGT supports a wide range of applications and hardware
because its design only relies on commonly available hardware
features—mainly paged virtual memory. LASTGT uses mem-
ory maps that allow the application to manage the placement
of data in memory, and authenticated data structures for
efﬁciently validating the data before it is processed. As most
of the LASTGT’s mechanisms (e.g., data validation and mem-
ory management) are implemented at the application level,
they can be optimized for different application requirements.
LASTGT ultimately delivers the following guarantee: if the
client can verify the results attested by the trusted component
on the service provider platform, then the client request was
processed by the intended code on the intended input state, so
the received response can be trusted.
We provide the following contributions.
• We describe LASTGT’s design, and show how it can
protect large-scale data in memory efﬁciently and how it
enables a client to verify the correctness of service code,
data and results.
• We detail how LASTGT has been implemented on XMHF-
TrustVisor [10] using a commodity platform equipped
with a TPM. Also, we discuss a possible implementation
using the Intel SGX instruction set. In addition, we high-
light important differences between the two architectures
and how LASTGT deals with them.
• We evaluate our XMHF-TrustVisor-based implementation
for datasets up to one terabyte. We show that LASTGT has
a small TCB compared to state-of-the-art prototypes, and
good performance. We also discuss expected improve-
ments with an SGX-based implementation.
2. RELATED WORK
We describe related work on trusted execution,
trusted
execution targeting large-scale data, and other solutions for
ensuring the integrity of computation on large data.
Trusted Execution Environments. TrustVisor [10], Mini-
box [15] and Haven [14] all support secure execution. The
ﬁrst two focus on keeping the TCB small by removing the
OS from the trust boundaries, thus supporting self-contained
applications (i.e., with statically linked libraries and no OS
2158-3927/17 $31.00 © 2017 IEEE
DOI 10.1109/DSN.2017.53
169
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:21:49 UTC from IEEE Xplore.  Restrictions apply. 
dependencies). Haven instead bloats the TCB with a library
OS—a refactored Windows 8—and can therefore run unmod-
iﬁed binaries. Security is achieved through hardware-based
isolation mechanisms and by removing [10] or reducing [15],
[14] the interface with the untrusted environment to protect
against Iago attacks [3] (i.e., system calls that return values
crafted by a malicious kernel).
These systems handle data I/O as follows. TrustVisor [10]
transfers data to/from the secure environment at execution
startup and termination only. The application thus receives all
input data upfront. This can be inefﬁcient if not all data is used,
and the data size is also bounded by the physical memory.
MiniBox [15] and Haven [14] implement additional system
calls for dynamic memory and secure ﬁle I/O. Both construct
a hash tree over the data, encrypt the data and handle I/O
through the interface with the untrusted environment for disk
access. However, working with a full hash tree in memory does
not scale for applications that operate on a large state, since the
hash tree itself can consume a large amount of memory. Also,
their design introduces several system calls (thereby enlarging
the interface), though fewer than an OS interface, that must be
secured against Iago attacks.
Trusted execution on large data. M2R [17] and VC3 [13]
were designed for trusted execution of large-scale MapReduce
applications. VC3 leverages Intel SGX for guaranteeing in-
tegrity and conﬁdentiality of map and reduce functions. M2R
improves the level of privacy by hiding the memory access
patterns through a secure data shufﬂer. Compared with the
earlier platforms, these two systems achieve a small TCB at
the expense of generality, since they only support MapReduce.
Other SGX applications. Graphene-SGX [41] can run un-
modiﬁed Linux applications. As it includes a library OS, the
same arguments that we used for Haven apply. Scone [18]
secures Docker container applications while Panoply [19] se-
cures Linux applications. The former supports multi-threaded
container applications and has a larger TCB, mainly due to
the libc library, while the latter is designed for multi-process
applications and has a smaller TCB since it exposes a POSIX-
level interface thus leaving the libc library outside the enclave.
Ryoan [20] secures a distributed sandbox by leveraging SGX
to ensure that possibly untrusted code can use but not leak
sensitive data. These systems are orthogonal to LASTGT since
they focus on secure concurrent/distributed processing, not
large-scale data. In addition, they expose from tens [18][20] to
hundreds [19] of interface calls, many of which are related to
data I/O from/to ﬁles. LASTGT complements them with secure
in-memory large-scale data handling that requires no additional
interface, but instead relies on page faults, and handles data
authentication in a scalable fashion.
Additional approaches. SecureMR [21] TrustMR [22] BFT-
MR [23] use different replication technique for MapReduce
computations to provide security guarantees against misbehav-
ing execution replicas. VPR [24] proposes a secure passive
replication scheme based on trusted hardware for improving
the availability of generic services. LASTGT does not use
replication and is orthogonal to VPR.
3. LASTGT OVERVIEW
We give an overview of LASTGT, presenting its key ideas,
beneﬁts and challenges.
application execution flow
resume
4
access data 
in block bi
is bi in 
memory?
yes
continue execution flow
 trusted environment 
no
1
handle  
page fault
2
load data
3
validate data
Fig. 1: Example of a program execution inside a trusted environment that
ofﬂoads data I/O from storage or network devices to untrusted code.
Operation. LASTGT allows a client to send requests and
verify the results produced by a large-state service that runs
on an untrusted platform. The execution of the self-contained
service application is secured by means of a trusted hardware
component. This component enables the establishment of an
isolated execution environment, where the trusted code is
identiﬁed and later attested. The service executes requests
received from the client by reading and writing local state of
up to a tera-byte (in our implementation) maintained in a set
of ﬁles. LASTGT ensures the integrity of the data used during
the secure execution, exploiting the key ideas described below.
Next, the service generates an attested reply for the client. The
reply binds together the identities of the service code, the local
state used by the service, the client’s request, and the reply.
Finally, the client veriﬁes and accepts (if valid) the reply.
Key ideas. The core of LASTGT is a secure and efﬁcient
data loading technique based on paged virtual memory and
asynchronous handlers (Fig. 1). LASTGT presents the large
state to the service code as a memory region in its address
space, thus allowing it to access the data directly (shaded
area, left-side) without requiring explicit calls to privileged
code. Data however is not preloaded for efﬁciency reasons
and possible memory constraints. Instead, accesses result in
page faults  that LASTGT handles transparently by moving
the data from the untrusted part of the system  into the
secure environment. While the service application remains
the data is cryptographically validated  by
interrupted,
a trusted application-level handler (shaded area, right-side)
whose execution is asynchronous (i.e., independent from the
service application). Only if the loaded data is valid, is the
interrupted service allowed to resume .
Beneﬁts offered by this design include:
• First, it reduces the problem of large-scale data handling to
a virtual memory management problem. As virtual memory
is widely supported, LASTGT can be implemented on pretty
much any TC-capable systems, enabling hardware diversity.
• Second, it keeps the TCB small by not including the OS.
Moreover, it does not involve system calls to privileged or
untrusted code, that may create vulnerabilities.
• Third, it does not need alterations to the service code since
data validation and integrity protection is done transparently.
• Fourth, data validation, integrity protection and (un)loading
are handled by customizable application-level code. This
allows tuning the authenticated data structures to data access
patterns, upgrading deprecated cryptographic algorithms, or
devising application-speciﬁc data eviction policies.
170
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:21:49 UTC from IEEE Xplore.  Restrictions apply. 
3. send 
    request
5. receive
    authenticated 
  reply
4. execute
    command
P
2. outsource  
    large state
1. provide state authentication data
V
S
Fig. 2: Three-party (Veriﬁer, Prover, Source) system model.
Challenges.
Implementing LASTGT has several challenges:
Ofﬂoading I/O securely to untrusted code. Transferring data
(e.g., disk I/O) is not useful computation for the application,
but can increase the TCB size and put peripherals in the
trust boundaries. Ofﬂoading such operations to untrusted code
reduces the TCB but requires means to validate or protect data
when it crosses the trust boundaries.
Transparency. Services should only have to access data
and perform computation, without dealing with orthogonal
issues such as data loading and state management. Hence,
making such mechanisms fully transparent simpliﬁes service
development and the use of LASTGT.
Securely overcoming memory constraints. Physical memory
is limited, especially for secure executions. For example, on
a recent Dell Optiplex 7040, SGX is constrained to use up to
128MB of memory (out of 32GB). Hence, efﬁcient memory
management is needed for handling a terabyte-scale state and
the associated authenticated data structure in memory.
Dealing with architectural differences. The hardware plat-
forms for secure execution have very different architectures,
making it hard to hide their differences through abstraction. For
example, XMHF-TrustVisor and SGX use completely different
mechanisms for secure execution and for paging. Devising a
single design that works for both platforms is challenging.
4. SYSTEM MODEL
We assume three parties (Fig. 2): a trusted source S pro-
ducing lots of data (user state); an untrusted service provider
P with signiﬁcant computational resources; a trusted veriﬁer V
that uses P ’s resources. S gives authentication data to V (Step
1) and the user state to P (Step 2). V sends requests to P (Step
3), who applies them to the data (Step 4) and returns replies
(Step 5) that V checks. We focus on a single request/reply
exchange with the client. Extensions can be devised to deal
with subsequent requests and to authenticate state updates.
Assumptions. We make common assumptions [10], [14], [11].
P is untrusted as it may be subject to internal/external
attacks. For example, P ’s system administrator could compro-
mise the software running on the platform, including the OS
and running services/applications.
P is equipped with a trusted component that provides
hardware-based security services such as isolated code exe-
cution, code identiﬁcation (cryptographic hash of code) and
attestation—a digital signature, computed by the trusted hard-
ware with its embedded (or securely provisioned [31]) keys, of
one or more identities (assertions [31], or cryptographic hash
values). The trusted component is assumed to be robust against
software attacks and free from physical tampering. Also any