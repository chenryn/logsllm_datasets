title:Cryptographically Secure Information Flow Control on Key-Value Stores
author:Lucas Waye and
Pablo Buiras and
Owen Arden and
Alejandro Russo and
Stephen Chong
Cryptographically Secure Information Flow Control on
Key-Value Stores
Lucas Waye
Harvard University
Cambridge, Massachusetts
PI:EMAIL
Pablo Buiras
Harvard University
Cambridge, Massachusetts
PI:EMAIL
Owen Arden
University of California, Santa Cruz∗
Santa Cruz, California
PI:EMAIL
Alejandro Russo
Chalmers University of Technology
Gothenburg, Sweden
PI:EMAIL
Abstract
We present Clio, an information flow control (IFC) system that
transparently incorporates cryptography to enforce confidentiality
and integrity policies on untrusted storage. Clio insulates develop-
ers from explicitly manipulating keys and cryptographic primitives
by leveraging the policy language of the IFC system to automati-
cally use the appropriate keys and correct cryptographic operations.
We prove that Clio is secure with a novel proof technique that is
based on a proof style from cryptography together with standard
programming languages results. We present a prototype Clio imple-
mentation and a case study that demonstrates Clio’s practicality.
CCS Concepts
• Security and privacy → Information flow control; Key manage-
ment; Digital signatures; Public key encryption;
Keywords
information-flow control, cryptography
1 Introduction
Cryptography is critical for applications that securely store and
transmit data. It enables the authentication of remote hosts, au-
thorization of privileged operations, and the preservation of confi-
dentiality and integrity of data. However, applying cryptography
is a subtle task, often involving setting up configuration options
and low-level details that users must get right; even small mistakes
can lead to major vulnerabilities [37, 48]. A common approach to
address this problem is to raise the level of abstraction. For exam-
ple, many libraries provide high-level interfaces for establishing
TLS [19] network connections (e.g., OpenSSL1) that are very similar
to the interfaces for establishing unencrypted connections. These
∗Work done while author was at Harvard University.
1https://www.openssl.org/
CCS ’17, October 30-November 3, 2017, Dallas, TX, USA
© 2017 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-4946-8/17/10.
https://doi.org/10.1145/3133956.3134036
Stephen Chong
Harvard University
Cambridge, Massachusetts
PI:EMAIL
libraries are useful (and popular) because they abstract many con-
figuration details, but they also make several assumptions about
certificate authorities, valid protocols, and client authentication.
Due in part to these assumptions, the interfaces are designed for
experienced cryptography programmers and as a result can be used
incorrectly by non-experts in spite of their high level of abstrac-
tion [61]. Indeed, crypto library misuse is a more prevalent security
issue than Cross-Site Scripting (XSS) and SQL Injection [57].
Information flow control (IFC) is an attractive approach to build-
ing secure applications because it addresses some of these issues.
There has been extensive work in developing expressive informa-
tion flow policy languages [3, 39, 53] that help clarify a program-
mer’s intent. Furthermore, many semantic guarantees offered by
IFC languages are inherently compositional from a security point
of view [24, 64]. However, existing IFC languages (e.g., [18, 28, 41,
47, 54, 55, 63]) generally assume that critical components of the sys-
tem, such as persistent storage, are trustworthy—the components
must enforce the policies specified by the language abstraction.
This assumption makes most IFC systems a poor fit for many of
the use-cases that cryptographic mechanisms are designed for.
It is tempting to extend IFC guarantees to work with untrustwor-
thy data storage by simply “plugging-in” cryptography. However,
the task is not simple: the threat model of an IFC system extended
with cryptography differs from both the standard cryptographic
threat models and from standard IFC threat models. Unlike most
IFC security models, an attacker in this scenario may have low-level
abilities to access signatures and ciphertexts of sensitive data, and
the ability to deny access to data by corrupting it (e.g., flipping bits
in ciphertexts).
Attackers also have indirect access to the private cryptographic
keys through the trusted runtime. An attacker may craft and run
programs that have access to the system’s cryptographic keys in
order to trick the system into inappropriately decrypting or sign-
ing information. Cryptographic security models often account for
the high-level actions of attackers using oracles that mediate what
information an active attacker can learn through interactions with
the cryptosystem. These oracles abstractly represent implemen-
tation artifacts that could be used by the attacker to distinguish
ciphertexts. Ensuring that an actual implementation constrains its
behavior to that modeled by an oracle is typically left to developers.
An attacker’s actual interactions with a system often extend
beyond the semantics of specific cryptographic primitives and into
Session I2:  Information FlowCCS’17, October 30-November 3, 2017, Dallas, TX, USA1893application-specific runtime behavior such as how a server responds
when a message fails to decrypt or a signature cannot be verified. If
an attacker can distinguish this behavior, it may provide them with
information about secrets. Building real implementations that pro-
vide no additional information to attackers beyond that permitted
by the security model can be very challenging.
Therefore, to give developers better tools for building secure
applications, we need to ensure that system security is not violated
by combining attackers’ low-level abilities and their ability to craft
their own programs. This requires extending the attacker’s power
beyond that typically considered by IFC models, and representing
the attacker’s interactions with the system more precisely than
typical cryptographic security models.
Attackers may also perform low-level fetch and store opera-
tions directly on the key-value store. Using these low-level oper-
ations, an attacker may corrupt ciphertexts to make them invalid
even when it does not possess the signing keys to make valid mod-
ifications. We treat these actions as attacks on the availability of
data, rather than on its integrity. A low-availability store is vul-
nerable to availability attacks, and thus should be prevented from
storing data that requires high-availability. Clio’s information flow
control mechanisms mediate the attacker’s ability to discover new
information or modify signed values by interacting with a Clio
program through fetchs and stores to a Clio store.
This paper presents Clio, a programming language that recon-
ciles IFC and cryptography models to provide guarantees on both
ephemeral data within Clio applications and persistent data on
an untrusted key-value store. Clio extends the IFC-tool LIO [54]
with store and fetch operations for interacting with a persistent key-
value store. Like LIO, Clio expresses confidentiality and integrity
requirements using security labels: flows of information are con-
trolled throughout the execution of programs to ensure the policies
represented by the labels are enforced. Clio encrypts and signs data
as it leaves the Clio runtime, and decrypts and verifies as it enters
the system. These operations are done automatically according to
the security labels—thus avoiding both the mishandling of sensitive
data and the misuse of cryptographic mechanisms. Because the
behavior of the system is fully specified by the semantics of the
Clio language, an attacker’s interactions with the system can be
characterized precisely. This results in a strong connection between
the power of the attacker in our formal security model and in actual
Clio programs.
Clio transparently maps security labels to cryptographic keys
and leverages the underlying IFC mechanisms to ensure that keys
are not misused within the program. Since we consider attackers
capable of denying access to information by corrupting data, Clio
extends LIO labels with an availability policy that tracks who can
deny access to information (i.e., who may corrupt the data).
Figure 1 presents an overview of the Clio threat model. At a
high-level, a Clio program may be a malicious program written by
the attacker. All interactions between the runtime and the store are
visible to the attacker. Only the (trusted) Clio runtime has access
to the keys used to protect information from the attacker, but the
attacker may have access to other “low” keys. The Clio runtime
never exposes keys directly to program code: they are only used
implicitly to protect or verify data as it leaves or enters the Clio
runtime.
Figure 1: Clio threat model. Attackers write Clio programs, read
from and write to the store, and observe the runtime’s interactions.
This paper makes the following contributions:
• A formalization of the ideal semantics of Clio, which models
its security without cryptography, and a real semantics, which
enforces security cryptographically.
• A novel proof technique that combines standard programming
language and cryptographic proof techniques. Using this ap-
proach, we characterize the interaction between the high-level
security guarantees provided by information flow control and the
low-level guarantees offered by the cryptographic mechanisms.
• For confidentiality, we have formalized these guarantees as chosen-
term attack (CTA) security, an extension of chosen-plaintext at-
tack (CPA) security to systems where an attacker may choose
arbitrary Clio programs that encrypt and decrypt information
through the Clio runtime. Though CTA security is predicated
on the relatively weak guarantees of CPA crypto primitives, CTA
security provides stronger guarantees since it applies to the end-
to-end flow of information through the system, including the
interactions an active, adaptive attacker might use to distinguish
ciphertexts.
• For integrity, we have defined leveraged existential forgery, an
extension of existential forgery to systems where an attacker may
choose and execute a program to produce signed values.
• A prototype Clio implementation in the form of a Haskell library
extending LIO. Our prototype system employs the DC labels
model [53], previously used in practical systems (e.g., Hails [23]
and COWL [55]). Our implementation extends DC-labels with
an availability component, which may be applicable to these
existing systems as well.
Our approach uses a computational model of cryptography. How-
ever, we do not rely on a formal definition of computational nonin-
terference [30]. Instead, we phrase security in terms of an adversary-
based game with a definition much closer to standard cryptographic
definitions of security such as CPA security [43]. This approach
helps to model an active adversary on the store, something that com-
putational noninterference can not easily capture. Furthermore, we
incorporate the semantics of Clio programs and potential attacks
against them into the security model. This approach captures the
CLIO programsget/putoperationspublic keys,low private keys public keys,all private keys get/putoperationsCLIO runtimeStoreAttackerSession I2:  Information FlowCCS’17, October 30-November 3, 2017, Dallas, TX, USA1894power of the attacker more precisely than cryptographic models for
active attackers like chosen-ciphertext attack (CCA) security [43].
Our CTA model applies a game-based definition of security in
a language setting and is a novel aspect of this work. Computa-
tional noninterference and related approaches consider attackers
that can only provide different secret inputs to the program. Thus
a key contribution of our work is capturing the abilities of an ac-
tive attacker (that can both supply code to execute and directly
manipulate the store) in a crypto-style game that goes beyond CPA
security and standard IFC guarantees (noninterference, including
computational noninterference). Although our results are specific
to Clio, we expect our approach to be useful in proving the security
of cryptographic extensions of other information flow languages.
The rest of the paper is structured as follows. Section 2 intro-
duces LIO and Section 3 describes the extensions to it in order to
interact with an untrusted store. Section 4 describes the computa-
tional model of Clio with cryptography, and Section 5 shows the
model’s formal security properties. Section 6 describes the proto-
type implementation of Clio along with a case study. And finally
Section 7 discusses related work. and Section 8 concludes.
2 Background
In this section, we describe the programming model of Clio. Clio
is based on LIO [54], a dynamic IFC library implemented in Haskell.
LIO uses Haskell features to control how sensitive information is
used and to restrict I/O side-effects. In particular, it implements an
embedded language and a runtime monitor based on the notion of
a monad, an abstract data type that represents sequences of actions
(also known as computations) that may perform side-effects. The
basic interface of a monad consists in the fundamental operations
return and (≫=) (read as “bind”). The expression return x denotes
a computation that returns the value denoted by x, performing no
side-effects. The function (≫=) is used to sequence computations.
Specifically, t ≫= λx .t′ takes the result produced by t and applies
function λx .t′ to it (which allows computation t′ to depend on the
value produced by t). In order to be useful, monads are usually
extended with additional primitive operations to selectively allow
the desired side-effects. The LIO monad is a specific instance of this
pattern equipped with IFC-aware operations that enforce security.
LIO, like many dynamic IFC approaches (e.g., [14, 46, 65]), em-
ploys a floating label. Security concerns are represented by labels
which form a lattice, a partially-ordered (⊑) set with least upper
bounds (⊔) and greatest lower bounds (⊓). A runtime monitor main-
tains as part of its state a distinguished label lcur known as the cur-
rent label. The current label is similar to the program counter (pc)
label of static IFC systems (e.g., [41, 49]): it restricts side-effects in
the current computation that may compromise the confidentiality
or integrity of data. For example, a computation whose current label
is secret cannot write to a public location. LIO operations adjust
this label when sensitive information enters the program and use
it to validate (or reject) outgoing flows.
When an LIO computation with current label lcur observes an
entity with label l, its current label is increased (if necessary) to the
least upper bound of the two labels, written lcur⊔l. Thus, the current
label “floats up” in the security lattice, so that it is always an upper
bound on the security levels of information in the computation.
Ground Value: v (cid:70) true | false | () | l | (v, v)
Value: v (cid:70) v | (v, v) | x | λx .t | tCLIO | ‹v :l›