ganization. In total three different types of users participated: “re-
searcher”, “developer”, and “general administration”, leading to
event logs from 37 client machines. Due to corporate security pol-
icy, it was not possible to perform the attack on the user’s client
machine. Therefore, all intrusions were performed on a separate
different client machine. The intrusions were executed based on
four different strategies according to real cyber attacks reported in
the past, details shown in Table 3. All client machines run Windows
10, and the event log data was collected with CDIR-C4. For evalua-
tion, we used cyber attack strategy A4, and for each user type the
event log data from 6 client machines. Cyber attack strategies A1,
A2 and A3, and the remaining user client machines’ log data were
used for estimating the hyper-parameters of our proposed model.
The users’ log data was interleaved with the event log data from
one intrusion. The intrusion was either simulated to be performed
in one time window (one block), or separated over three different
time windows (three block). In order to ensure enough variety for
a faithful evaluation, for each intrusion, we employed a different
tactic5 based on one of the four cyber attack strategies. We filtered
out windows background processes that were common to all event
logs. The average number of different processes employed by an
intrusion was 23.7 (with standard deviation 8.0). The number of
different processes from the users are shown in Table 2.
4Available at https://github.com/CyberDefenseInstitute/CDIR.
5That means a different sequence of commands, but with the same goal.
6https://www.aist.go.jp/pdf/aist_j/topics/to2018/to20180720/20180720aist.pdf
7https://www.mci.gov.sg/pressroom/news-and-stories/pressroom/2019/1/
public-report-of-the-coi
8https://ics.sans.org/media/E-ISAC_SANS_Ukraine_DUC_5.pdf
9https://eromang.zataz.com/2013/04/02/dark-south-korea-total-war-review/
Poster Session ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan923Table 2: Number of client machines and average number
of different processes (standard deviation in brackets) from
three types of users: “developer”, “researcher”, and “general
administration”. Last row shows the percentage of attacker
process names that are common to the ones from the user.
“developer”
“researcher”
“administration”
client machines
different processes
intrusion overlap
10
179.0 (33.5)
61.9 (11.0)
21
194.3 (43.7)
47.1 (17.0)
6
189.3 (35.9)
58.5 (9.6)
Table 3: Description of cyber attack strategies.
Description
Illegal access to AIST’s information system.6
Id
A1
A2 Attack on Singapore health services patient database.7
A3
A4 Attack on South Korea’s bank and broadcast stations.9
Attack on the Ukrainian power grid.8
For our baseline we use Isolation Forest (IForest) [7], and an im-
proved version which we call Block IForest. The work in [5] shows
that IForest is state of the art for anomaly detection. However, IFor-
est scores each process individually, and thus does not incorporate
the assumption that attacker’s processes appear close in time to
each other. Therefore, as an additional baseline, we introduce Block
IForest, which adds a post-processing step that marks all processes
in one time window as belonging to the attacker, if the average
anomaly score within the time window is higher than outside the
time window. In detail, let sj, for j ∈ [1, n], be the anomaly score
of the j-th process calculated with IForest. We set the number of
intrusion processes na to the average number of intrusion processes
λa found in the training data. The start of the intrusion i is then
set to
(cid:0) 
(cid:12)(cid:12)(cid:12) 1
na
j∈[i ,i +na−1]
argmax
i
sj(cid:1) −
(cid:0)
1
n − na

sj(cid:1)(cid:12)(cid:12)(cid:12) .
j∈[1,i−1]∪[i +na ,n]
Since we are interested in high recall, we show the false discovery
rate of all methods for recall level 99% and 95%. The false discovery
rate (FDR) is defined as the number of false alarms (=false positives)
divided by the total number of alarms (= false positives + true
positives). Therefore, FDR directly corresponds to the manual work
load of checking false alarms. The results, shown in Table 4 and 5,
suggest that our proposed method achieves lower FDR than IForest
and its improved version Block IForest.
4 CONCLUSIONS
We proposed a new Bayesian block model for identifying all pro-
cesses related to an attacker. In the situation, where the intrusion
was executed in one consecutive sequence in time, the proposed
method achieves considerably lower FDR than ad-hoc methods
based on Isolation Forest. However, our experimental evaluation
also shows that when intrusion was spread over time in three
blocks, instead of one, FDR considerably increases, which we hope
to improve in future work.
Table 4: Results when intrusion is limited to one consecu-
tive sequence of events (One Block). Shows the average false
discovery rate of all methods at recall 99% and 95%.
Method
Proposed
Block IForest
IForest
Proposed
Block IForest
IForest
Recall = 99%
“developer”
0.739 (0.333)
0.837 (0.348)
0.989 (0.006)
“researcher”
0.586 (0.42)
0.987 (0.007)
0.985 (0.009)
“administration”
0.321 (0.343)
0.678 (0.441)
0.977 (0.015)
Recall = 95%
0.742 (0.334)
0.837 (0.348)
0.982 (0.009)
0.588 (0.421)
0.875 (0.252)
0.932 (0.044)
0.312 (0.34)
0.678 (0.441)
0.977 (0.015)
Table 5: Results when intrusion activity is spread over time
in three consecutive sequences of events (Three Block).
Method
Proposed
Block IForest
IForest
Proposed
Block IForest
IForest
Recall = 99%
“developer”
0.985 (0.006)
0.991 (0.003)
0.988 (0.007)
“researcher”
0.968 (0.037)
0.987 (0.007)
0.974 (0.031)
“administration”
0.968 (0.02)
0.987 (0.007)
0.975 (0.018)
Recall = 95%
0.964 (0.051)
0.991 (0.003)
0.982 (0.009)
0.957 (0.04)
0.987 (0.007)
0.937 (0.038)
0.958 (0.029)
0.987 (0.007)
0.975 (0.018)
REFERENCES
[1] B Balajinath and SV Raghavan. 2001. Intrusion detection through learning behavior
model. Computer communications 24, 12 (2001), 1202–1212.
[2] Robert A Bridges, Tarrah R Glass-Vanderlan, Michael D Iannacone, Maria S Vincent,
and Qian Chen. 2019. A Survey of Intrusion Detection Systems Leveraging Host
Data. ACM Computing Surveys (CSUR) 52, 6 (2019), 1–35.
[3] Gideon Creech and Jiankun Hu. 2013. Generation of a new IDS test dataset: Time
to retire the KDD collection. In 2013 IEEE Wireless Communications and Networking
Conference (WCNC). IEEE, 4487–4492.
[4] Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. 2017. Deeplog: Anomaly
detection and diagnosis from system logs through deep learning. In Proceedings
of the 2017 ACM SIGSAC Conference on Computer and Communications Security.
1285–1298.
[5] Xiaoyi Gu, Leman Akoglu, and Alessandro Rinaldo. 2019. Statistical Analysis
of Nearest Neighbor Methods for Anomaly Detection. In Advances in Neural
Information Processing Systems. 10921–10931.
[6] Ling Li and Constantine N Manikopoulos. 2004. Windows NT one-class mas-
querade detection. In Proceedings from the Fifth Annual IEEE SMC Information
Assurance Workshop, 2004. IEEE, 82–87.
[7] Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008. Isolation forest. In 2008
Eighth IEEE International Conference on Data Mining. IEEE, 413–422.
[8] DA Stephens. 1994. Bayesian retrospective multiple-changepoint identification.
Journal of the Royal Statistical Society: Series C (Applied Statistics) 43, 1 (1994),
159–178.
Poster Session ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan924