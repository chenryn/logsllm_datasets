### Organization and Methodology

Three distinct user types participated in the study: "researcher," "developer," and "general administration," resulting in event logs from 37 client machines. Due to corporate security policies, it was not feasible to perform the attack directly on the users' client machines. Consequently, all intrusions were executed on a separate, dedicated client machine. The intrusions were based on four different strategies, each reflecting real-world cyber attacks reported in the past, as detailed in Table 3. All client machines operated on Windows 10, and event log data was collected using CDIR-C4.

For the evaluation, we utilized cyber attack strategy A4, and for each user type, we analyzed event log data from six client machines. Cyber attack strategies A1, A2, and A3, along with the remaining user client machines' log data, were used to estimate the hyper-parameters of our proposed model. The users' log data was interlaced with the event log data from one intrusion, which was either simulated to occur in a single time window (one block) or distributed across three different time windows (three blocks). To ensure sufficient variety for a robust evaluation, each intrusion employed a different tactic based on one of the four cyber attack strategies. We filtered out common background processes present in all event logs. On average, an intrusion involved 23.7 different processes (with a standard deviation of 8.0). The number of different processes from the users is shown in Table 2.

**Table 2: Number of Client Machines and Average Number of Different Processes (Standard Deviation in Brackets) from Three Types of Users: “Developer,” “Researcher,” and “General Administration.” Last Row Shows the Percentage of Attacker Process Names Common to Those from the User.**

| User Type         | Client Machines | Different Processes | Intrusion Overlap |
|-------------------|-----------------|---------------------|-------------------|
| Developer         | 10              | 179.0 (33.5)        | 61.9 (11.0)       |
| Researcher        | 21              | 194.3 (43.7)        | 47.1 (17.0)       |
| General Admin     | 6               | 189.3 (35.9)        | 58.5 (9.6)        |

**Table 3: Description of Cyber Attack Strategies.**

| ID  | Description                                                                 |
|-----|-----------------------------------------------------------------------------|
| A1  | Illegal access to AIST’s information system. [6]                             |
| A2  | Attack on Singapore health services patient database. [7]                    |
| A3  | Attack on the Ukrainian power grid. [8]                                     |
| A4  | Attack on South Korea’s bank and broadcast stations. [9]                     |

### Baseline and Proposed Method

For our baseline, we used Isolation Forest (IForest) [7] and an enhanced version called Block IForest. According to [5], IForest is state-of-the-art for anomaly detection. However, IForest evaluates each process individually, failing to account for the assumption that an attacker's processes tend to appear close together in time. Therefore, we introduced Block IForest, which adds a post-processing step to mark all processes within a time window as belonging to the attacker if the average anomaly score within the window exceeds that outside the window.

Specifically, let \( s_j \) be the anomaly score of the \( j \)-th process calculated using IForest. We set the number of intrusion processes \( n_a \) to the average number of intrusion processes \( \lambda_a \) found in the training data. The start of the intrusion \( i \) is then determined by:

\[
i = \arg\max_i \left( \frac{1}{n_a} \sum_{j=i}^{i+n_a-1} s_j - \frac{1}{n - n_a} \sum_{j \in [1, i-1] \cup [i+n_a, n]} s_j \right)
\]

Given our focus on high recall, we report the false discovery rate (FDR) for recall levels of 99% and 95%. FDR is defined as the number of false positives divided by the total number of alarms (false positives + true positives), directly corresponding to the manual workload of checking false alarms. The results, presented in Tables 4 and 5, indicate that our proposed method achieves a lower FDR compared to IForest and Block IForest.

**Table 4: Results When Intrusion is Limited to One Consecutive Sequence of Events (One Block). Shows the Average False Discovery Rate of All Methods at Recall 99% and 95%.**

| Method          | Recall = 99%    | Recall = 95%    |
|-----------------|-----------------|-----------------|
| Developer       | 0.739 (0.333)   | 0.742 (0.334)   |
| Researcher      | 0.586 (0.42)    | 0.588 (0.421)   |
| Administration  | 0.321 (0.343)   | 0.312 (0.34)    |
| Block IForest   | 0.837 (0.348)   | 0.837 (0.348)   |
| IForest         | 0.989 (0.006)   | 0.982 (0.009)   |

**Table 5: Results When Intrusion Activity is Spread Over Time in Three Consecutive Sequences of Events (Three Block).**

| Method          | Recall = 99%    | Recall = 95%    |
|-----------------|-----------------|-----------------|
| Developer       | 0.985 (0.006)   | 0.964 (0.051)   |
| Researcher      | 0.968 (0.037)   | 0.957 (0.04)    |
| Administration  | 0.968 (0.02)    | 0.958 (0.029)   |
| Block IForest   | 0.991 (0.003)   | 0.991 (0.003)   |
| IForest         | 0.988 (0.007)   | 0.982 (0.009)   |

### Conclusions

We proposed a new Bayesian block model for identifying all processes related to an attacker. In scenarios where the intrusion was executed in a single consecutive sequence, our method achieved significantly lower FDR than ad-hoc methods based on Isolation Forest. However, when the intrusion was spread over time in three blocks, the FDR increased, indicating a need for further improvement in future work.

### References

[1] B Balajinath and SV Raghavan. 2001. Intrusion detection through learning behavior model. Computer communications 24, 12 (2001), 1202–1212.

[2] Robert A Bridges, Tarrah R Glass-Vanderlan, Michael D Iannacone, Maria S Vincent, and Qian Chen. 2019. A Survey of Intrusion Detection Systems Leveraging Host Data. ACM Computing Surveys (CSUR) 52, 6 (2019), 1–35.

[3] Gideon Creech and Jiankun Hu. 2013. Generation of a new IDS test dataset: Time to retire the KDD collection. In 2013 IEEE Wireless Communications and Networking Conference (WCNC). IEEE, 4487–4492.

[4] Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. 2017. Deeplog: Anomaly detection and diagnosis from system logs through deep learning. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. 1285–1298.

[5] Xiaoyi Gu, Leman Akoglu, and Alessandro Rinaldo. 2019. Statistical Analysis of Nearest Neighbor Methods for Anomaly Detection. In Advances in Neural Information Processing Systems. 10921–10931.

[6] Ling Li and Constantine N Manikopoulos. 2004. Windows NT one-class masquerade detection. In Proceedings from the Fifth Annual IEEE SMC Information Assurance Workshop, 2004. IEEE, 82–87.

[7] Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008. Isolation forest. In 2008 Eighth IEEE International Conference on Data Mining. IEEE, 413–422.

[8] DA Stephens. 1994. Bayesian retrospective multiple-changepoint identification. Journal of the Royal Statistical Society: Series C (Applied Statistics) 43, 1 (1994), 159–178.