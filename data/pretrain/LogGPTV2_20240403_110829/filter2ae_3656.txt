## 简介
跳一跳是一个微信小程序。 2017年12月28日，微信更新的 6.6.1 版本开放了小游戏，微信启动页面还重点推荐了小游戏“跳一跳”。
小游戏非常的火 各种稀奇古怪的外挂很多都出来了
看到排行榜都是一些几千的，不禁也想动手试试  
尝试抓包提交后发现需要参数和签名现在已经需要对应，在无可奈何无奈作罢。  
不过想起最近很火的图片处理和机器学习，于是想尝试两者结合一下。制作一个AlphaJump(=.=)
## 编写过程和思路
  * 识别主体
  * 识别流程和触发形式
  * 图片采样
  * 图片特征提取
  * 实验
## 识别主体
识别主体很简单，即紫色棋子抵达白色区域的中心位置的距离。我们根据距离的长短来控制触控屏幕的时长，来抵达目标位置
## 识别流程和触发形式
  * **手机平台**  
由于安卓还是比苹果方便调试，  
这里直接使用了安卓机作为调试的平台 。
  * **额外工具** adb  
使用 ADB工具 作为主要的调试和输入输出工具
    * [截图] adb shell /system/bin/screencap -p /sdcard/screenshot.png 
    * [下载截图] adb pull /sdcard/screenshot.png d:/screenshot.png
    * [触摸] adb swipe x1 y1 x2 y2 duration(ms)  
-[注] adb好像没有触摸 不过有滑动 ,所以把 x1 y1 x2 y2 变成一个像素点,加上时间即可变成长按 
  * **语言** python  
主要使用 PIL的Image
  * **识别流程和触发形式**
## 图片采样
我们先来看一下完整的跳一跳的程序截图
主要分为
  * 分数以及返回按钮部分
  * 游戏主体部分
  * 尾部分享部分
那么我们主要的分析部分就是在主体部分 。在主体部分我们完成特征提取的功能。
## 图片特征提取
首先，我们用PIL的IMG以RGB的形式载入图片
`im = Image.open('./12345.jpg').convert('RGB')`
仔细观察主体后发现[用ps去拾色]背景是由单一的颜色渐变而来。我们第一步先驱除背景。
  * 这里没办法用固定色值 因为背景玩着玩着会改变 T.T 
### 驱除背景
  * 先对 0，0的元素采样 
  * 对采样得到RGB三个颜色的误差在正负50以内的 直接转为 白色[255,255,255]
看得出结果还可以 。
### 找棋子
去掉背景后，我们开始找参考线。多次玩游戏发现棋子的颜色是不变的。其RGB的范围在 [60,60,103]附近游走
经过多次测试,在RGB的值的范围如下时，基本可以覆盖棋子，
  * R 40-70 
  * G 40-70
  * B 60-103
把RGB在如上范围的像素进行染色 如下图
虽然无法覆盖部分高光，但是顶端和尾部基本都覆盖了 。  
只要可以确定棋子的最低点和最高点即可。[因为要获取棋子的高度]
对最高点和最低点添加两条辅助线 如图  
### 找目标盒子的落点位置
找目标盒子不难，但是找落点比较难  
因为盒子有高有矮，有时候还会有遮挡  
无法通过简单的最高点和最低点除2获得落点位置  
在没有掌握足够的计算机图像识别的能力情况下  
我通过一个比较取巧的方法去获得 落点位置
通过多次游戏可以知道：
  * 棋子完美落点的位置 恰好是棋子高度一半 在目标盒子上
  * 目标盒子上方基本为空白，比较容易获得最高点的位置
  * 一般最高点的X和中心落点一致 (因为都是规则的几何体)
于是落点的xy计算公式：
  * `x = 目标盒子最高点X`
  * `y = 目标盒子最高点Y + 棋子高度/2`
计算一下落点位置，添加一条辅助线和对落点位置进行着色
可以看到 落点位置已经非常准确的标注出来。  
提取特征已经完成
## 实验
找一台安卓机开始实验  
实验效果如图：
## 总结
目前来说 还未涉及到机器学习核心部分  
只是完成机器学习的第一步制作样本文件。  
下一篇我们用机器学习去优化我们的阿尔法跳的参数
所有代码我会同步在这里
  * 