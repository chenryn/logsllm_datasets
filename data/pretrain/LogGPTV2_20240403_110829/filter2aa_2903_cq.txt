Syntax error, unexpected LITERAL, expecting RPAREN, or COMMA
threadIdx(100,0,0)
              ^    error at column 15
This breakpoint instance will hit unconditionally.
出现上述错误是因为使用threadIdx宏时缺少@符号。
9.10 数据断点
与CPU端的数据断点类似，在使用Nsight调试时，也可以对算核函
数要访问的变量设置数据断点。数据断点有时也称为数据监视断点，或
者简称监视断点和监视点。
9.10.1 设置方法
Nsight的数据断点功能复用了Visual Studio的界面，因此设置方法与
设置CPU的数据断点方法非常类似。首先，使用下面两种方法之一调出
图9-23所示的“新建数据断点”界面。
图9-23 “新建数据断点”对话框
在菜单栏中单击“调试”→“新建断点”→“数据断点”。
在菜单栏中单击“调试”→“窗口”→“断点”打开“断点”窗口，然后
在“断点”窗口中单击左上角的“新建”→“数据断点”。
接下来，只要把要监视变量的地址和长度输入到对话框中即可。值
得强调的是，一定要输入变量的地址，而不只是变量名。举例来说，对
于一直作为例子的向量加法程序，如果希望数组C的28000号元素变化时
中断，那么应该在地址栏中输入@C[28000]，而不只是C[28000]。如果
输入C[28000]，那么会把这个元素的值（默认为0）当作地址送给
GPU，导致这个断点永远不会命中。
对于64位的算核程序，目前支持的数据断点长度为1、2、4、8四个
值。
另一点值得说明的是，通过Nsight设置的数据断点只能监视写操
作，在读操作中不会命中。
9.10.2 命中
图9-24显示了GPU的数据断点命中时的场景。弹出的对话框中包含
了数据断点所监视的地址和长度信息。单击“确定”按钮关闭对话框后，
把鼠标指针悬停在C[i] = A[i] + B[i]这一行，意思是这一行修改了
被监视的内存。在“断点”子窗口中，命中的断点会加粗显示。
观察“反汇编”窗口，可以看到执行点对应的指令是下面这条存储
（Store）指令。
0x000cfc58                       ST.E [R2], R8, P0;
图9-24 数据断点命中
上面指令可以描述为根据谓词寄存器P0决定是否把R8写到R2所指
向的地址。从寄存器窗口观察R2值，发现它与断点的监视地址
（0x60133f0c0）并不相同，即使去掉最高位6，余下的部分也不一样，
不过二者比较接近，只差4字节。这是为什么呢？下面给出了寄存器信
息。
R0 = 0x0000752f R1 = 0x00fffc80 R2 = 0x0133f0bc R3 = 0x00000005 R4 = 0x013
3f0bc 
R5 = 0x00000000 R6 = 0x0000752f R7 = 0x00000000 R8 = 0x3f37436e R9 = 0x000
0752f 
R10 = 0x0000752f CFA = 0x00fffc80 P0 = 1 P1 = 0 P2 = 1 P3 = 0 P4 = 0 
P5 = 0 P6 = 0 CC = 0x0 
LogicalPC = 0x000cfc58 FunctionRelativePC = 0x00000598
观察图9-24右上角的CUDA Info窗口，会发现有两条管线都显示断
点状态，目前显示的是上面一条，双击下面一条切换到另一个线程，再
观察以下寄存器信息。
R0 = 0x00007530 R1 = 0x00fffc80 R2 = 0x0133f0c0 R3 = 0x00000005 R4 = 0x013
3f0c0 
R5 = 0x00000000 R6 = 0x00007530 R7 = 0x00000000 R8 = 0x3f339167 R9 = 0x000
07530 
R10 = 0x00007530 CFA = 0x00fffc80 P0 = 1 P1 = 0 P2 = 1 P3 = 0 P4 = 0 P5 = 
0 
P6 = 1 CC = 0x0 
LogicalPC = 0x000cfc58 FunctionRelativePC = 0x00000598
这次R2就与数据断点地址的低位部分完全匹配了。如此看来，至少
对于作者使用的软硬件配置，数据断点命中，不但刚好访问断点地址的
执行单元会进入断点状态，而且访问附近地址的执行单元也可能会进入
断点状态，这应该与GPU以Warp为单位并行执行的特征有关。
那么，为什么断点地址的高位部分与R2不一样呢？这应该是Nvidia
GPU分配和访问内存的方法决定的。观察CUDA Info的“内存分配”窗
口，我们会发现所有内存都具有一个共同特征，那就是最高（十六进
制）位都一样，推测它们都属于同一个段，具有相同的基地址。上面的
R2寄存器所含地址是基于这个基地址的偏移量。这与x86 CPU上的段概
念非常类似。
另外值得说明的是，GPU是在执行写操作之前中断的，用官方文档
上的话来说，是在刚好要对断点地址执行写操作之前中断的（just prior
to writing data to that address）。举例来说，对于设置在&C[30000]的断
点，中断下来后，我们观察C[30000]，它的值还是0，还没有变化。这
与x86 CPU中的数据断点行为是不一样的。
9.10.3 数量限制
CPU上的数据断点是有数量限制的（纯软件模拟的情况除外）。那
么GPU上的数据断点是否有数量限制呢？在Nsight的手册上，没有这个
问题的答案。作者曾经故意设置了30个数据断点，也没有触碰到限制。
看来，GPU支持的数据断点数量远远超过CPU。
9.10.4 设置时机
与在没有开始调试就可以设置代码断点不同，只有当调试会话建立
后，才可以设置数据断点。因此，通常需要先设置一个代码断点，中断
后再设置数据断点。
9.11 调试符号
调试符号是衔接二进制信息和源代码信息的桥梁，很多调试功能都
是依赖调试符号的。本节将简要介绍CUDA程序的调试符号。一个
CUDA程序包含两类代码，一类是在CPU上执行的主机部分，另一类是
在GPU上执行的设备部分。本节只介绍设备部分的调试符号，也就是用
于GPU调试的信息。
9.11.1 编译选项
在CUDA的编译和链接选项中都有关于调试符号的设置，通过-G选
项可以配置是否产生GPU调试信息。
CUDA编译器的很多地方都与LINUX和GCC编译器有关，作者认为
或许这是当初开发CUDA技术时制订的策略。比如，-G选项很容易让人
联想起GCC中的-g（小写）选项。在GCC中，-g选项用于产生CPU的调
试符号。
9.11.2 ELF载体
CUDA程序的GPU代码是以ELF文件存放的。ELF的全称是
Executable and Linkable Format，是Linux操作系统上使用的可执行文件
格式。
对于Windows平台上的CUDA程序，把ELF文件形式的GPU代码存
放到Windows中PE（Portable and Executable）格式的可执行文件中。
使用CUDA工具包中的cuobjdump可以观察或者提取出PE文件中的
ELF部分。比如，下面的命令会列出simplePrintf.exe中包含的所有ELF内
容（在编译时针对不同微架构产生了多个ELF文件）。
D:\apps\cuda91\bin\win64\Debug>..\..\cuobjdump -lelf simplePrintf.exe
ELF file    1: simplePrintf.1.sm_30.cubin
ELF file    2: simplePrintf.2.sm_35.cubin
ELF file    8: simplePrintf.8.sm_70.cubin
可以使用-elf选项来观察ELF文件的详细信息，比如....\cuobjdump -
elf simplePrintf.exe。
9.11.3 DWARF
DWARF是一种开放的调试信息格式，被包括GCC在内的很多编译
器所采用。CUDA编译器也使用了这个格式来描述GPU的调试符号。
在GCC中，DWARF调试信息是与编译好的可执行代码放在同一个
ELF文件中的。与此类似，CUDA编译出的GPU调试符号也是与GPU代
码一起放在ELF文件中的。在Windows平台上，它们又一起嵌入PE文件
中。这意味着，对于Windows平台上的CUDA程序，CPU部分的调试信
息是放在PDB中的，而GPU的调试信息是放在可执行文件中的。
本书后续分卷将详细介绍DWARF格式。
9.12 CUDA GDB
在Linux系统上，除了可以使用Eclipse插件形式的Nsight调试器外，
还可以使用CUDA GDB来调试CUDA程序。
CUDA GGB是基于著名的GDB开发的。CUDA GDB的大部分代码
是开源的，可以在GitHub上下载其代码。
9.12.1 通用命令
使用CUDA GDB调试CUDA程序与使用普通GDB调试普通程序在很
多地方都是相同的。或者说，CUDA GDB只是在GDB的基础上做了一
些扩展，让其可以支持GPU代码和GPU目标。为了减少读者的学习时
间，CUDA GDB尽可能保持与普通GDB的一致性，很多命令的格式和
用法都是保持不变的。我们把与普通GDB相同的命令叫通用命令。比
如，开始调试会话的file和run命令、观察栈回溯的bt命令、设置断点的b
命令、恢复执行的c命令、反汇编的disassemble命令等都是通用命令。
举例来说，可以使用break命令对foo.cu中的算核函数设置断点。
(cuda-gdb) break foo.cu:23
也可以使用cond命令对断点附加条件。
(cuda-gdb) cond 3 threadIdx.x == 1 && i < 5
也可以把上面两条命令合成如下一条。
(cuda-gdb) break foo.cu:23 if threadIdx.x == 1 && i < 5
上面条件中的threadIdx是CUDA的内置变量，代表执行算核函数的
线程ID。
9.12.2 扩展
为了支持GPU调试的特定功能，CUDA GDB对一些命令做了扩展，
主要是set和info命令。
CUDA GDB增加了一系列以set cuda开头的命令，比如set cuda
break_on_launch application和set cuda memcheck on等。前者执行后，每
次启动算核函数时都会中断到调试器；后者用于启用内存检查功能，检
测与内存有关的问题。
类似地，CUDA GDB还增加了很多个以info cuda开头的命令，用于
观察GPU有关的信息。比如，info cuda devices可以显示GPU的硬件信
息。此外，info cuda后面可以跟随的参数如下。
sms：显示当前GPU的所有流式多处理器（SM）的信息。
warps：显示当前SM的所有Warp的信息。
lanes：显示当前Warp的所有管线的信息。
kernels：显示所有活跃算核的信息。
blocks：显示当前算核的所有活跃块（active block），支持合并格
式和展开格式，可以使用set cuda coalescing on/off来切换。
threads：显示当前算核的所有活跃线程，支持合并格式和展开格
式，可以使用set cuda coalescing on/off来切换。
launch trace：当在算核函数中再次启动其他算核函数时，可以用这
个命令显示当前算核函数的启动者（父算核）。
launch children：查看当前算核启动的所有子算核。
contexts：查看所有GPU上的所有CUDA任务（上下文）。
9.12.3 局限
与Windows平台上的Nsight相比，CUDA GDB是有一些局限的，比
如针对GPU算核代码的监视点是不支持的。
本书后续分卷将详细介绍GDB以及它的变体，包括重要调试命令的
详细解析，以及常用功能的工作原理和核心代码。为了避免重复，本节
只做简单介绍。
9.13 CUDA调试器API
CUDA GDB内部使用一套名叫CUDA调试器API（CUDA Debugger
API）的编程接口来访问底层信息和GPU硬件。CUDA的工具包包含了
这套API的文档。在CUDA GDB的开源代码中，包含了API的头文件和
用法。
9.13.1 头文件
在CUDA GDB源代码目录的include子目录中，可以找到CUDA调试
器API的核心头文件cudadebugger.h。这个头文件包含了调试器API的常
量、结构体定义和函数指针表。
其中，最重要的一个结构体就是包含函数指针表的CUDBGAPI_st
结构体，它的字段都是函数指针。
struct CUDBGAPI_st {
    /* Initialization */
    CUDBGResult (*initialize)(void);
    CUDBGResult (*finalize)(void);
    /* Device Execution Control */
    CUDBGResult (*suspendDevice)(uint32_t dev);
    CUDBGResult (*resumeDevice)(uint32_t dev);
    CUDBGResult (*singleStepWarp40)(uint32_t dev, uint32_t sm, uint32_t wp
);
    /* Breakpoints */
    CUDBGResult (*setBreakpoint31)(uint64_t addr);
    CUDBGResult (*unsetBreakpoint31)(uint64_t addr);
…
};
这个结构体包含了调试API的所有函数接口，根据功能分为如下多
个小组，上面列出了三组，分别为初始化、设备执行控制以及断点。设
备执行控制小组包含3个函数：suspendDevice用于暂停执行，
resumeDevic用于恢复执行，singleStepWarp40用于单步执行。为了节约