likely to increase usability if cached) ultimately enters the cache,
as opposed to one which appears multiple times in a single (and
possibly anomalous) login attempt. For example, if a typo ˜𝑤𝑛 is
repeated once across 𝑟 login attempts in which the least frequently
used typo ˜𝑤𝑜 is not entered at all, the probability that ˜𝑤𝑛 will not
enter the cache is approximately
than 1/𝑒 if 𝑟 ≈ 𝑓 ˜𝑤𝑜 > 2. Conversely, if the same typo appears
𝑟 ≈ 𝑓 ˜𝑤𝑜 times in a single login attempt, the probability that it does
not then enter the cache is
(cid:17) 𝑟, which is less
(cid:17) ≈ 1/2 > 1/𝑒.
1 − 1/(1 + 𝑓 ˜𝑤𝑜 )
1 − 𝑟/(𝑓 ˜𝑤𝑜 + 𝑟)
Second, by setting the frequency count for the newly cached
typo to 𝑓 ˜𝑤𝑛 +𝑓 ˜𝑤𝑜, the PLFU scheme increases the eventual stability
of the cache, as the increasing frequency counts of the cached typos
mean that the probability that they are replaced by a wait listed typo
decreases over time. In contrast the LFU caching scheme updates
the cache on each login attempt, increasing the chance that useful
typos are accidentally evicted from the cache.
(cid:16)
(cid:16)
A.2 Modeling the Typo Distribution 𝜏𝑤
In this section, we describe the procedure with which we built
the typo model 𝜏 used for the simulations on Page 8. We use a
supervised training method to learn the typo distribution using the
typo data collected in our MTurk study (Section 6.1) and the data
released with [8]. Our approach is inspired by that of Houser et
al. [14].
A simple way to build the typo model would be to compute the
frequency distribution of typos for each password. However, our
data set contains only 30, 000 typos of 20, 000 distinct passwords in
total. As such, both the set of passwords on which we have typo data,
and the amount of typo data we have for the individual passwords,
is too small to build a good frequency based model. Therefore,
we make two simplifying assumptions about typographical errors:
that a typo of a given character in a password is influenced by the
characters very close to it, and that this typo is independent of the
characters in the remainder of the string.
Given a list of pairs of passwords and typos, we first align each
pair by inserting a special symbol “␣” zero or more times (as re-
14
quired), such that the resulting pair of strings are of the same
length, and have the same DL distance as the originals. For exam-
ple, the password-typo pair (password, pasword) may be aligned
to (password, pa␣sword). If there are multiple alignments possible,
we consider all of them. For each of the aligned password-typo
pairs (𝑤, ˜𝑤), we take the set of substring pairs (𝑤𝑖:𝑗 , ˜𝑤𝑖:𝑗 ) for all
0 ≤ 𝑗 ≤ 𝑘; 0 ≤ 𝑖 ≤ |𝑤| − 𝑗, and compute the frequency distribu-
tion of those pairs across all the aligned password-typo pairs. Here
|𝑥| denotes the length of the string 𝑥; 𝑥𝑖:𝑛 denotes the sub-string
of length 𝑛 of 𝑥 beginning at location 𝑖 ≤ |𝑥|− 𝑛; and 𝑘 is a param-
eter of the model. We let 𝐸 denote the frequency distribution of
these pairs of strings, and will use it in subsequent steps to compute
the typo probability of a given password.
We define an edit as a triplet (𝑖, 𝑙, 𝑟), where 𝑖 denotes a location
in the string, and 𝑙 and 𝑟 are strings of length at most 𝑘. An edit
(𝑖, 𝑙, 𝑟) is valid for a password 𝑤 if 𝑤𝑖:|𝑙| = 𝑙. Transforming a
password 𝑤 by applying a valid edit (𝑖, 𝑙, 𝑟) means, replacing 𝑤𝑖:|𝑙|
with the sub-string 𝑟. For a given password 𝑤 we let 𝐸𝑤 denote
the set of all possible valid edits in the set Z|𝑤| × 𝐸. We assign
weights to each edit (𝑖, 𝑙, 𝑟) in 𝐸𝑤 as the frequency of the pair (𝑙, 𝑟)
according to the frequency distribution 𝐸, divided by the number
of locations 𝑗 ∈ [0,|𝑤|] for which (𝑗, 𝑙, 𝑟) is a valid edit for 𝑤. The
weights are then normalized to define a probability distribution 𝑃𝑤
over the valid edits of 𝑤.
With this in place, the process of sampling a typo of a password
𝑤 according to the typo model 𝜏𝑤 is reduced to sampling an edit
from 𝑃𝑤 and applying it to 𝑤. Note that there could be multiple
edits of a password 𝑤 which result in the same typo ˜𝑤. Thus, 𝜏𝑤 ( ˜𝑤)
is equal to the sum of the probabilities of all edits that transform 𝑤
into ˜𝑤.
Efficacy of the typo model. We use the average log likelihood
— which is a typical measure for evaluating generative models —
to gauge the efficacy of our typo model. We compare our model
against the naive uniform model, that assigns uniform probabilities
to all the typos. Note, a model is better if the average log likelihood
value is higher.
We perform a cross validation of our model over five 80:20 train-
test splits of the data set of password / typo pairs. For each split,
we train our typo model using the training data, and compute the
average log likelihood of test samples as the average of log 𝜏𝑤 ( ˜𝑤)
taken over all pairs (𝑤, ˜𝑤) in the test data. We find that the average
log likelihood of the test data according to our model is –7.2 with
standard deviation 0.4, which is much better than base uniform
model, which obtains an average likelihood of –11. This suggests
that our model captures the real world typo distribution fairly well.
A.3 Proofs from Section 5
Proof of Lemma 5.1. We begin by proving Lemma 5.1 which we
shall utilize in subsequent analysis.
Proof: We argue by a series of game hops. Let game G0 denote
game OFFDIST𝒜
Π,𝒯 (as defined in Figure 4), so
Π,𝒯 (𝒜) = 2 ·
(cid:12)(cid:12)(cid:12)(cid:12)Pr [ G0 ⇒ 1 ] − 1
Advoffdist
Recall that the cache of TypTop stores up to (𝑡 + 1) ciphertexts,
each of which corresponds to a password-based encryption (using
(cid:12)(cid:12)(cid:12)(cid:12) .
2
The TypTop System
CCS ’17, October 30-November 3, 2017, Dallas, TX, USA
the canonical PBE scheme PBE[SH, SE]) of the secret key of the
PKE scheme 𝑠𝑘 under the real password and each of the (at most 𝑡)
cached typos.
We define a new game G1 which is identical to G0 except that
the keys sampled to encrypt cached ciphertexts are now sam-
pled without replacement. In more detail, when a new typo is
cached during the evolution of the challenge state 𝑠𝑛, a salt is
chosen sa ←$ {0, 1}ℓsalt, and the cached ciphertext is computed as
𝑐 ←$ E(SH(sa|| ˜𝑤), 𝑠𝑘). In game G0 oracle SH responds to fresh
queries of this form by returning k𝑗 ←$ {0, 1}𝜅, whereas in G1
oracle SH samples these keys without replacement. In the distin-
guishing phase of G1, SH returns to sampling keys with replace-
ment. These games run identically unless two keys sampled during
the computation of these cached ciphertexts collide. Since at most
(𝑡· (𝑛 + 1) + 1) such keys are sampled while processing a transcript
of length 𝑛 (where the (𝑡 + 1) term corresponds to the maximum
number of keys sampled to encrypt the ciphertexts in the initial
cache, and the 𝑡 · 𝑛 term arises as processing each of the 𝑛 typos in
the transcript can introduce at most 𝑡 new ciphertexts in the typo
cache), it follows that
2 · |Pr [ G0 ⇒ 1 ] − Pr [ G1 ⇒ 1 ]| ≤ (𝑡 · (𝑛 + 1) + 1)2
Next we define game G2 which is identical to G1 except we re-
place Checker[Π] with PChecker[Π] and a sequence of statements
that encrypt the final typo cache, state and wait list returned by it
as specified by the scheme. Notice that these games run identically
unless during the process of updating the state we find two distinct
keys k1 (cid:44) k2 such that Dk2 (Ek1 (𝑠𝑘)) (cid:44)⊥ where 𝑠𝑘 denotes the
secret key of the PKE scheme which is encrypted under each of the
cached typos. As such the fundamental lemma of game playing [3]
implies that the gap between game G1 and G2 is upper-bounded by
the probability that this event occurs. Notice that we can further
SE (ℛ) as follows. Consider
upper bound this probability by Advrob
an adversary ℛ in game ROBℛ
SE who simply executes the game G1,
simulating SH by sampling random strings without replacement,
and checking if there ever exists a typo cache ciphertext Ek1 (𝑠𝑘)
that decrypts under some subsequently sampled k2 (cid:44) k1 (recall
that since G1 samples without replacement, all keys are distinct).
The gap between these two games is upper bounded by the proba-
bility that this event occurs, and so the robustness of the encryption
scheme implies that
2𝜅
.
2 · |Pr [ G1 ⇒ 1 ] − Pr [ G2 ⇒ 1 ]| ≤ 2 · Advrob
SE (ℛ) .
Next we define game G3 which is identical to G2 except we return
SH to sampling keys with replacement. An analogous argument
to that above bounding the probability that two keys collide en-
sures that the gap between these games is again bounded above by
(𝑡·(𝑛+1)+1)2
Notice that G3 is identical to game OFFDISTΠ,𝒯 , and so may
be perfectly simulated by an attacker 𝒜′ in this game. On input
challenge state 𝑠𝑛, attacker 𝒜′ passes this state to 𝒜 in game G3,
simulating 𝒜’s random oracle by querying his own oracle SH, and
returning the responses. Since 𝒜′ makes precisely the same set of
oracle queries as 𝒜, it follows that if 𝒜 makes at most 𝑞 queries,
then 𝒜′ does also. At the end of the game 𝒜′ outputs whatever bit
2𝜅
.
𝒜 does, and so
2 ·
(cid:12)(cid:12)(cid:12)(cid:12)Pr [ G3 ⇒ 1 ] − 1
2
(cid:12)(cid:12)(cid:12)(cid:12) = Advoffdist
Π,𝒯 (𝒜′
) ,
concluding the proof.
2(𝜅−1)
SE (ℛ) +
Π,𝒯 (𝒜′
(𝑡 · (𝑛 + 1) + 1)2
Π,𝒯 (𝒜) ≤ Advoffdist
Proof of Theorem 5.2. We now provide the full proof of Theo-
rem 5.2.
Proof: Consider an adversary 𝒜 in game OFFDIST𝒜
Π,𝒯 . Recall
that by Lemma 5.1, there exist adversaries 𝒜′ and ℛ both running
in time approximately that of 𝒜 and where 𝒜′ makes the same
number of oracle queries as 𝒜 such that,
) +2·Advrob
Advoffdist
;
so it is sufficient to upper bound the success probability of an
𝒜′
attacker 𝒜′ in game OFFDIST
Π,𝒯 . We argue by a series of game
hops, shown in Figure 10. We begin by defining game G0, which is
𝒜′
identical to game OFFDIST
Π,𝒯 with 𝑏 = 0. We also set two flags,
bad-sa and bad neither of which affect the outcome of the game.
Next we define game G1 which is identical to G0 except the
salts used by the canonical PBE scheme to compute the cipher-
texts in the challenge state are now sampled without replacement.
Games G0 and G1 run identically unless the flag bad-sa is set to
true. Since there are at most 𝑡 + 1 salts sampled, the birthday bound
and the fundamental lemma of game playing therefore imply that
this transition is bounded above by (𝑡+1)2
|Pr [ G0 ⇒ 1 ] − Pr [ G0 ⇒ 1 ]| ≤ Pr [ bad-sa = true in game G1 ]
2ℓsalt +1 , and so
≤ (𝑡 + 1)2
2ℓsalt+1 .
We now define game G2 which is identical to G1 except we change
the way in which the random oracle SH responds to queries. Now
if in the guessing phase 𝒜 queries SH on a salt / password pair
(sa, 𝑤) on which it was queried during the computation of the
challenge state 𝑠𝑛, it responds with an independent random string
k ←$ {0, 1}𝜅 updating its hash table to this new value, as opposed
to the previously used value. Accordingly in G2 the keys k used by
the SE encryption scheme are now random and independent of the
underlying password. Games G1 and G2 run identically unless 𝒜
manages to guess and query SH on one of the cached passwords and
corresponding salt; an event we mark by setting a flag bad = true.
The fundamental lemma of game playing then implies that,
|Pr [ G1 ⇒ 1 ] − Pr [ G2 ⇒ 1 ]| ≤ Pr [ bad = true in game G2 ] ,
a probability which we shall upper bound in a later game.
Next we define game G3, which is identical to G2 except we
replace all symmetric encryptions with random ciphertexts. This
transition is bounded by a reduction to the MKROR security of SE.
Formally, let ℬ1 be an adversary in game MKRORℬ1,𝑡
SE with chal-
′. Adversary ℬ1 runs (𝑤0, ˜𝑤1, . . . , ˜𝑤𝑛) ←$ 𝒯 , followed
lenge bit 𝑏
by ¯𝑠𝑛 ←$ PChecker[Π](𝑤0, ˜𝑤1, . . . , ˜𝑤𝑛), and generates a public /
secret key pair (𝑝𝑘, 𝑠𝑘) ←$ 𝒦. ℬ1 then constructs the encrypted
state 𝑠𝑛 as follows. ℬ1 first chooses sa𝑖 ←$ {0, 1}𝜅 and uses his
RoR oracle to compute 𝑐𝑖 = RoR(𝑖, 𝑠𝑘) for 𝑖 = 0, . . . , 𝑡, placing
the salt / ciphertext pairs in the appropriate positions in the cache.
(Recall that from game G2, the symmetric keys used to create the
15
CCS ’17, October 30-November 3, 2017, Dallas, TX, USA
Chatterjee et al.
proc. main//𝐺0, 𝐺1, 𝐺2
(𝑤0, ˜𝑤1, . . . , ˜𝑤𝑛) ←$ 𝒯
¯𝑠𝑛 ←$ PChecker[Π](𝑤0, ˜𝑤1, . . . , ˜𝑤𝑛)
parse ¯𝑠𝑛 as (S, T, W, 𝛾)
(𝑝𝑘, 𝑠𝑘) ←$ 𝒦
For 𝑖 = 0, . . . , 𝑡
If T[𝑖] (cid:44) ⊥
sa𝑖 ←$ {0, 1}ℓsalt
If sa𝑖 ∈ {sa0, . . . , sa𝑖−1}
bad-sa ← true
sa𝑖 ←$ {0, 1}ℓsalt /{sa0, . . . , sa𝑖−1}
k𝑖 ← SH(sa𝑖 ‖ T[𝑖])
𝑐𝑖 ←$ Ek𝑖 (𝑠𝑘)
T[𝑖] ← (sa𝑖, 𝑐𝑖)
𝑐𝑖 ←$ 𝒞E
T[𝑖] ←$ (sa𝑖, 𝑐𝑖)
Else
𝑐 ←$ ℰ𝑝𝑘 (S)
For 𝑗 = 0, . . . , 𝜔 do
W[𝑗] ←$ ℰ𝑝𝑘 (W[𝑗])
𝑠𝑛 ← (𝑝𝑘, 𝑐, T, W, 𝛾)
𝑏′ ←$ 𝒜SH (𝑠𝑛)
Return 𝑏 = 𝑏′
proc. main//𝐺3, 𝐺4
(𝑤0, ˜𝑤1, . . . , ˜𝑤𝑛) ←$ 𝒯
¯𝑠𝑛 ←$ PChecker[Π](𝑤0, ˜𝑤1, . . . , ˜𝑤𝑛)
parse ¯𝑠𝑛 as (S, T, W, 𝛾)
(𝑝𝑘, 𝑠𝑘) ←$ 𝒦
For 𝑖 = 0, . . . , 𝑡
sa𝑖 ←$ {0, 1}ℓsalt
If sa𝑖 ∈ {sa0, . . . , sa𝑖−1}
bad-sa ← true
sa𝑖 ←$ {0, 1}ℓsalt /{sa0, . . . , sa𝑖−1}
𝑐𝑖 ←$ 𝒞E
T[𝑖] ← (sa𝑖, 𝑐𝑖)