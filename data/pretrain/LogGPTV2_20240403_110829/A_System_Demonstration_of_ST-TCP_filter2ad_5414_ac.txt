### 0-7695-2282-3/05 $20.00 © 2005 IEEE

#### 4. Application Failure Detection and Handling
When the backup application fails, it immediately sends a FIN (Finish) signal. However, the primary does not generate a FIN. In this scenario, the backup TCP generates a FIN due to a failure, which is then suppressed. The primary transitions to non-fault-tolerant mode. This transition occurs at `MaxDelayFIN` if the primary cannot detect the backup's application failure; otherwise, it happens as soon as the primary detects the failure.

In the cases of application failures described above, the failures are likely to be detected if the application is actively reading or writing bytes when the failure occurs. If there is no application activity, the failure may not be immediately detected. This is not a problem for the application failures where a FIN is not generated, as the failure will be detected when there is some application activity. However, in situations where a FIN is generated, it may not be possible to conclusively distinguish between a normal closure and a failure based solely on information at the TCP layer. This challenge applies to any primary/backup system.

To ensure detection of application failures under all circumstances, either additional backup servers must be deployed, or more information from the application layer is needed. Deploying additional backup servers allows for a majority decision in case of a conflict between the primary and a backup. For additional information from the application layer, an application can support a watchdog mechanism where the application continually sends a heartbeat to a watchdog. The watchdog monitors the application's health and informs ST-TCP in case of any suspected failure.

#### 4.3 Local Network Failures
This section discusses network failures that are local to the primary or backup server, such as a NIC (Network Interface Card) failure. We assume both the primary and the backup have a single NIC. As mentioned in Section 3, the Heartbeat (HB) between the primary and the backup is exchanged over two separate links: an IP link and a serial link.

If a local network failure occurs, only the HB on the IP link fails. The servers continue to exchange the HB on the serial link, enabling them to determine that a local network failure has occurred. To determine if the failure has occurred at the primary or the backup, the servers examine the "last client byte received" information (LastByteReceived) in the HB. If the client is sending data, the server with the NIC failure will not receive it, while the server without the NIC failure will. Based on the LastByteReceived in the HB, the primary or the backup can determine if the other is lagging behind in terms of the client bytes received. For example, if the backup determines that the primary has lagged behind by more than a threshold number of bytes, or if a particular byte has not been received by the primary for more than a threshold period of time, it shuts down the primary and takes over the connection. These threshold values are configurable. Similarly, the primary shuts down the backup if it determines that the backup is lagging behind.

One limitation of this failure detection method is that it depends on the client sending data. Some applications, such as FTP, do not require the client to send a lot of data, making this method ineffective. This problem can be partially addressed by having the primary and backup look at the acknowledgments (ACKs) received from the client. If the backup NIC is down, the latest client ACK information (LastAckReceived) received by the primary from the backup via the HB on the serial link will indicate that the backup is behind. However, this does not work if the primary NIC has failed. If the primary NIC is down, the client will not receive any bytes from the server and thus will not send any ACKs.

In the new version of ST-TCP, we have added another mechanism to address this issue. When the servers detect a failure of the HB on the IP link but not on the serial link, both the primary and the backup send ping requests to their gateway. The results of these requests—whether they succeeded or not—are exchanged in the HB via the serial link. If ping requests continue to fail for the primary but succeed for the backup, the backup takes over the TCP connection and shuts down the primary.

**Temporary Local Network Failures:**
Temporary failures in the NIC or the IP stack (e.g., buffer overflow) can lead to packet drops. In this case, the HB remains active on both links. If packets are dropped at the backup, the backup requests the missing bytes from the primary. There may be instances where the backup takes a long time to catch up or is unable to catch up. If the additional receive buffer space at the primary fills up, the primary considers the backup failed and runs in non-fault-tolerant mode. Note that temporary network failures at the primary are not an issue, as these will be handled in the normal course of TCP operation—the primary does not acknowledge these bytes, and the client will retransmit them.

If the primary crashes while the backup is retrieving missed bytes, the backup has no way of obtaining these bytes since the primary has already acknowledged them. For critical applications, a logger can be added to the system to address this output commit problem, as described in [2]. For other applications, ST-TCP treats this failure as unrecoverable.

#### 5. Planned Demonstrations
We present five experiments that we plan to demonstrate live at the symposium. These experiments are designed to showcase different aspects of ST-TCP:

1. **Client-Transparent, Seamless Failover:** Demonstrate seamless failover to the backup server when the primary fails.
2. **Dependence of Failover Time on HB Frequency:** Examine how the failover time depends on the HB frequency.
3. **Insignificant Overhead During Normal Operation:** Show that the overhead of using ST-TCP during failure-free operation is negligible.
4. **Failure Detection and Recovery in Case of Application Crash Failures:** Demonstrate how ST-TCP handles application crash failures.
5. **Failure Detection and Recovery in Case of NIC Failures:** Show how ST-TCP detects and recovers from NIC failures.

**Experimental Setup:**
Figure 2 shows the experimental setup used for the demonstrations. An Ethernet switch connects the primary and the backup, and the client is directly connected to the same switch. The primary and backup are installed with a modified Linux kernel, incorporating changes required to support ST-TCP. Virtual NICs (VNICs) are created using the IP aliasing feature of the Linux kernel on both the primary and backup machines. These VNICs are assigned the `serviceIP` address, which is the address that clients connect to for receiving service. The primary and backup are also associated with a multicast Ethernet address (`multiEA`). A static ARP protocol entry is created on the gateway (the client in this case) mapping `serviceIP` to `multiEA`. Any IP packet destined for `serviceIP` is sent to the `multiEA` Ethernet address, allowing both the primary and the backup to receive all packets sent to the `serviceIP` address. The HB is exchanged between the servers over the IP link, and a duplicate copy is exchanged over a secondary link, as described in Section 3.

**Demo 1: Client-Transparent Seamless Failover**
The goal of this demonstration is to show that in the event of a primary server failure, ST-TCP provides a client-transparent, fast, and seamless failover to the backup. A GUI client-server application is used, where the client continually requests and receives data from the server. As the client receives the data, it dynamically updates a pie chart reflecting the percentage of the data already received. While the transfer is in progress, the primary server is crashed, causing the TCP connection to fail over to the backup. This failover process is seamless to the client, as evident by the continuous progression of the pie chart.

This demonstration also shows that, in the absence of ST-TCP, even if a hot backup is available, the failure of the server would lead to a disruption in the service, and the client would have to reconnect. In contrast, with ST-TCP, the failure at worst appears as a glitch to the user.

**Demo 2: Dependence of Failover Time on HB Frequency**
In this experiment, we examine the dependence of the failover time on the HB frequency. One component of the failover time is the failure detection time. The other depends on how much the backup and the client TCP have backed off during the time it took to detect the failure. Recall that TCP backs off exponentially as retransmissions fail. If the primary fails, both the backup and the client (assuming both the server and the client are sending data) would start retransmitting and backing off (in the case of the backup, the retransmissions get discarded until it takes over the connection). Once the failure is detected and the backup takes over, there is still a delay until the next client or backup retransmission before the TCP stream gets restarted. In this demonstration, we try three different values of HB period (200ms, 500ms, and 1s) and measure the failover times in each case.

**Demo 3: Insignificant Overhead During Normal Operation**
In this demonstration, a large file (about 100 MB) is transferred to the client both with ST-TCP enabled and with ST-TCP disabled. We compare the time taken for the file transfer in both cases. The aim of this experiment is to show that under normal operation (no failures), the overhead of using ST-TCP is negligible.

**Demo 4: Application Crash Failure**
The goal of this demonstration is to show that ST-TCP tolerates application failures. The GUI application used in Demo 1 is also used here. Two different scenarios of application failures are simulated. In the first scenario, the application on the primary crashes, but the socket is not closed, so a FIN segment is not generated. In the second scenario, the OS cleans up the application and closes the socket, generating a FIN. In both scenarios, the application failure is detected, and the TCP connection is migrated to the backup.

**Demo 5: NIC Failure**
This demonstration has two parts. In the first part, we simulate a failure of the NIC at the primary; in the second, a failure of the NIC at the backup. In both cases, the HB on the IP link between the servers fails, but the one on the secondary link stays up. The servers use the information in the HB to determine whether the failure has occurred at the primary or the backup.

#### 6. Conclusions
TCP is the most popular transport-level protocol for constructing distributed applications over the Internet. Current fault tolerance techniques typically require software updates at both the client and the server, limiting their applicability. Several research projects have addressed this problem by providing server fault tolerance support at the TCP layer. ST-TCP is one such effort to address this problem.

This paper describes lessons learned from using ST-TCP in different computing environments. Specifically, the paper reports on three issues. First, it discusses peculiar behavior of servers under specific computing conditions and the design enhancements that ST-TCP has undergone to address them. Second, it details how ST-TCP handles different failure scenarios, particularly application failures and local network failures. Finally, the paper describes five experiments that will be demonstrated at the conference.

### References
[1] R. R. Koch, S. Hortikar, L. E. Moser, and P. M. Melliar-Smith. Transparent TCP connection failover. In Proceedings of the IEEE Int. Conf. on Dependable Systems and Networks, San Francisco, June 2003.

[2] M. Marwah, S. Mishra, and C. Fetzer. TCP server fault tolerance using connection migration to a backup server. In Proceedings of IEEE Int. Conf. on Dependable Systems and Networks, San Francisco, June 2003.

[3] M. Orgiyan and C. Fetzer. Tapping TCP streams. In Proceedings of the IEEE International Symposium on Network Computing and Applications, February 2002.

[4] D. A. Patterson. A simple way to estimate the cost of downtime. In Proceedings of LISA ’02: Sixteenth Systems Administration Conference, November 2002.

[5] A. C. Snoeren, D. G. Andersen, and H. Balakrishnan. Fine-grained failover using connection migration. In Proceedings of the 3rd USENIX Symposium on Internet Technologies and Systems, March 2001.

[6] F. Sultan, K. Srinivasan, D. Iyer, and L. Iftode. Migratory TCP: Connection migration for service continuity over the internet. In Proceedings of the 22nd IEEE International Conference on Distributed Computing Systems, Vienna, Austria, July 2002.

[7] D. Zagorodnov, K. Marzullo, L. Alvisi, and T. Bressoud. Engineering fault tolerant TCP/IP services using FT-TCP. In Proceedings of IEEE Int. Conf. on Dependable Systems and Networks, San Francisco, June 2003.

---

**Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05)**  
0-7695-2282-3/05 $20.00 © 2005 IEEE