Performance optimization: Using all hops of a random
walk for anonymous communication has signiﬁcant perfor-
mance limitations. First, the latency experienced by the user
scales linearly with the random walk length. Second, long
circuit lengths reduce the overall throughput that a system
can offer to a user. Inspired by prior work [38], we propose
the following performance optimization. Instead of using
all hops of a random walk for anonymous communication,
the initiator can use the random walk as a peer discovery
process, and leverage the kth hop and the last hop to build
a two-hop circuit for anonymous communication.
In our
evaluation, we ﬁnd that values of k that are close to half
the random walk length provide a good trade-off between
anonymity and performance.
4 Evaluation
In this section, we evaluate Pisces with theoretical anal-
ysis as well as experiments using real-world social network
topologies.
In particular, we (a) show the security bene-
ﬁts provided by the reciprocal neighbor policy, (b) evaluate
the security, performance, and overhead of our protocol that
implements the policy, and (c) evaluate the overall anony-
mity provided by Pisces. We consider four datasets for our
experiments, which were processed in a manner similar to
the evaluation done in SybilLimit [67] and SybilInfer [12]:
(i) a Facebook friendship graph from the New Orleans re-
gional network [62], containing 50,150 nodes and 772,843
edges; (ii) a Facebook wall post interaction graph from
the New Orleans regional network [62], containing 29,140
users and 161,969 edges; (iii) a Facebook interaction graph
from a moderate-sized regional network [66], containing
about 380,564 nodes and about 3.24 million edges; (iv) a
Facebook friendship graph from a moderate-sized regional
network [66], containing 1,033,805 nodes and about 13.7
million edges.
4.1 Reciprocal Neighbor Policy
To demonstrate the effectiveness of the reciprocal neigh-
bor policy for implementing trust-based anonymity, let us
(a)
(b)
(c)
Figure 1. Probability of the l’th hop being compromised (Sampling Bias), under an increasing node degree attack
[Facebook wall post graph] (a) Without attack (b) g=30000 attack edges, (c) g=60000 attack edges. For
short random walks, this is a losing strategy for the adversary. For longer random walks, the
adversary does not gain any advantage.
(a)
(b)
(c)
Figure 2. Probability of l’th hop being compromised (Sampling Bias) under route capture attack with global black-
listing [Facebook wall post graph] (a) l = 1, (b) l = 5, (c) l = 25 . As more edges to the honest nodes are
removed, the attacker’s loss is higher.
assume for now that there is a mechanism to securely
achieve the policy, i.e., that if a node X does not advertise a
node Y in its neighborlist, then Y also excludes X. In this
scenario, we are interested in characterizing the probability
distribution of random walks.
Figure 3. Attack Model.
Theorem 1. Node degree attack: Given h honest nodes
and m malicious nodes (including Sybil nodes) that have
g edges (attack edges) amongst each other in an undirected
and connected social network, the stationary probability of
random walks starting at an honest node and terminating at
a malicious node cannot be biased by adding edges amongst
malicious nodes. Moreover, this stationary probability is in-
dependent of the topology created amongst malicious nodes
(as long as the social graph is connected).
Proof. Let us denote (cid:25)i as the stationary probability of ran-
1
degree(i) ;
1
(cid:17)
degree(j)
), observe that 8z; (cid:25)z = 1
dom walks (independent of the initial state of the random
walk) for node i, and let Pij denote the transition probabil-
ity from node i to node j. Let n denote the total number
of nodes in the social network (n = h + m). Since the
(cid:16)
transition probabilities between nodes in the Metropolis-
Hastings random walks are symmetric (Pij = Pji =
n is so-
min
lution to the equation (cid:25)i (cid:1) Pij = (cid:25)j (cid:1) Pji. Since social net-
works are non-bipartite as well as undirected graphs, the so-
lution to the above equation ((cid:25) = 1
n ) must be the unique sta-
tionary distribution for the random walk [3]. Thus the sta-
tionary probability of random walks terminating at any node
in the system is uniform and independent of the number of
edges amongst malicious nodes, or the topology amongst
malicious nodes in the system (as long as the graph remains
connected).
We validate Theorem 1 using simulation results on the
Facebook wall post interaction graph. Figure 1(a) depicts
the probability of a Pisces random walk terminating at a
malicious node as a function of random walk length for
g = 30000 (2900 malicious nodes) and g = 60000 (7300
malicious nodes). We can see that the random walk quickly
reaches its stationary distribution, and at the stationary dis-
HMPPMHHMMMHHPPtribution, the probability of a random walk terminating at
one of the malicious nodes is 0.1 and 0.25 respectively
(which is the adversary’s fair share). Figure 1(b) and (c)
depict the probability of a random walk terminating at one
of the malicious nodes under the node degree attack, for
g = 30000 and g = 60000 respectively. We can see that
adding edges amongst malicious nodes does not help the
adversary (even for transient length random walks).
Theorem 2. Global blacklisting: suppose that x (cid:20) m ma-
licious nodes sacriﬁce y1 (cid:20) g attack edges, and that these
malicious nodes originally had y2 (cid:20) g attack edges. The
stationary probability of random walk terminating at ma-
licious nodes gets reduced proportional to x. The tran-
sient distribution of random walks terminating at malicious
nodes is reduced as a function of y2.
Proof. If x malicious nodes perform the route capture at-
tack and are globally blacklisted, these nodes become dis-
connected from the social trust graph. It follows from our
analysis of Theorem 1 that the stationary distribution of
the random walk is uniform for all connected nodes in the
graph. Thus, the stationary distribution of random walks
terminating at malicious nodes gets reduced from m
m+h to
m(cid:0)x
m(cid:0)x+h.
To characterize the transient distribution of the random
walk, we model the process as a Markov chain. Let us de-
note the honest set of nodes by H, and the set of malicious
nodes by M. The probability of an l hop random walk end-
ing in the malicious region (P (l)) is given by:
P (l) = P (l (cid:0) 1) (cid:1) PMM + (1 (cid:0) P (l (cid:0) 1)) (cid:1) PHM (2)
The terminating condition for the recursion is P (0) = 1,
which reﬂects that the initiator is honest. We can estimate
the probabilities PHM and PM H as the forward and back-
ward conductance [27] between the honest and the mali-
cious nodes, denoted by (cid:30)F and (cid:30)B respectively. Thus we
have that:
P (l) = P (l (cid:0) 1) (cid:1) (1 (cid:0) (cid:30)B) + (1 (cid:0) P (l (cid:0) 1)) (cid:1) (cid:30)F
= P (l (cid:0) 1) (cid:1) (1 (cid:0) (cid:30)B (cid:0) (cid:30)F ) + (cid:30)F
(3)
P (l) = (cid:30)F (cid:1) [1 + (1 (cid:0) (cid:30)B (cid:0) (cid:30)F ) + (1 (cid:0) (cid:30)B (cid:0) (cid:30)F )2
: : : + (1 (cid:0) (cid:30)B (cid:0) (cid:30)F )l(cid:0)1] (4)
We note that if an adversary connects a chain of Sybils
(say of degree 2) to an attack edge, a random walk starting
from an honest node and traversing the attack edge to enter
the malicious region has a non-trivial probability of coming
back to the honest region - via the attack edge (Pisces allows
backward transition along edges). Our analysis models the
probability of returning to the honest region using the notion
of backward conductance.
With g edges between honest and malicious nodes, we
can estimate the forward conductance (cid:30)F as follows:
(cid:6)x2H (cid:6)y2M (cid:25)x (cid:1) Pxy
(cid:6)x2H (cid:6)y2M (cid:1) Pxy
(cid:25)H
jHj
= O
(cid:17)
(cid:16)
g
h
(5)
(cid:30)F =
=
Similarly, with g edges between honest and malicious
nodes, the backward conductance (cid:30)B is estimated as:
h ) (cid:1) h
(cid:30)F (cid:1) jHj
jMj =
(6)
= O
g
m
(cid:30)B =
O( g
m
Thus, we have that (cid:30)F = O( g
h ), and (cid:30)B = O( g
m ). If
malicious nodes exclude y edges to honest nodes from their
ﬁngertables, application of the RNP ensures that the hon-
est nodes also exclude the y edges from their ﬁngertables
(local blacklisting). Thus, route capture attacks result in
deleting of attack edges which reduces both forward and
backward transition probabilities. Observe that the proba-
bility of the ﬁrst hop being in the malicious region is equal
to (cid:30)F , which gets reduced under attack. We will now show
this for a general value of l. Following Equation 4 and using
i=0 xi = 1(cid:0)xm+1
(cid:6)i=m
1(cid:0)x
for 0 < x < 1, we have that:
(cid:16)
(cid:17)
(cid:30)F (cid:1) (1 (cid:0) (1 (cid:0) (cid:30)B (cid:0) (cid:30)F )l)
1 (cid:0) (1 (cid:0) (cid:30)B (cid:0) (cid:30)F )
(cid:30)F
(cid:1) (1 (cid:0) (1 (cid:0) (cid:30)B + (cid:30)F )l)
P (l) =
=
Using (cid:30)B = h
m
(cid:30)F + (cid:30)B
(cid:1) (cid:30)F , we have that:
P (l) =
P (l) =
m
n
m
n
(cid:16)
(cid:1) (cid:30)F
(cid:18)
(cid:19)
(cid:1) (1 (cid:0) (1 (cid:0) (cid:30)B + (cid:30)F )l)
1 (cid:0)
(cid:1)
(cid:18)
l (cid:1)
1 (cid:0) n
m
(cid:16)
1 (cid:0) n
m
(cid:17)l
(cid:17)l(cid:0)1
(cid:1) (cid:30)F
m
n
(cid:1)
(cid:19)
(7)
(8)
Differentiating P (l) with respect to (cid:30)F , we have that:
d
d(cid:30)F
d
(P (l)) =
(9)
Note that (1(cid:0) n
m (cid:30)F ) = (1(cid:0)(cid:30)B(cid:0)(cid:30)F ) (cid:21) 0. This implies
P (l) (cid:21) 0. Thus, P (l) is an increasing function of (cid:30)F ,
d(cid:30)F
and since the reduction of the number of attack edges re-
duces (cid:30)F , it also leads to a reduction in the transient distri-
bution of the random walk terminating at malicious nodes.
Thus, it follows that a reduction in the number of remaining
attack edges y2 reduces the transient distribution of random
walks terminating at malicious nodes.
Figure 4. Probability of end(cid:173)to(cid:173)end timing
analysis under route capture attack with
global blacklisting [Facebook wall graph]
Figure 5. Probability of detecting a route cap(cid:173)
ture [Facebook wall post interaction graph].
The attack model includes 10 Sybils per at(cid:173)
tack edge.
Figure 2 depicts the probability of random walks termi-
nating at malicious nodes as a function of number of attack
edges as well as the fraction of deleted edges when honest
nodes use a global blacklisting policy. We can see that sac-
riﬁcing attack edges so as to perform route capture attacks
is a losing strategy for the attacker. Moreover, the decrease
is similar for all random walk lengths; this is because even
the stationary distribution of the random walk terminating
at malicious nodes is reduced.
Anonymity Implication: To de-anonymize the user
without the help of the destination node (e.g.
the web-
site to which the user connects anonymously), both the ﬁrst
hop and the last hop of the random walk need to be mali-
cious to observe the connecting user and her destinations,
respectively. End-to-end timing analysis [22, 65] makes
it so that controlling these two nodes is sufﬁcient for de-
anonymization. Figure 4 depicts the probability of such
an attack being successful as a function of the number of
attack edges and the fraction of deleted edges using the
global blacklisting policy. We can see that the probability
of attack is a decreasing function of the fraction of deleted
edges.Thus we conclude that route capture attacks are a los-
ing strategy against our approach.
So far, we validated our analysis using simulations as-
suming an an ideal Sybil defense. We also validated our
analysis using a more realistic Sybil defense that permits a
bounded number (set to 10 [67]) of Sybils per attack edge,
which we show in our technical report [2].
4.2 Securing Reciprocal Neighborhood Policy
We now discuss the security and performance of our pro-
tocol that implements the reciprocal neighbor policy.
Security proof sketch: Suppose that a malicious node A
aims to exclude an honest node B from its neighborlist. To
pass node B’s local integrity checks, node A has to return
a neighborlist to node B that correctly advertises node B.
Since random walks for anonymous communication are in-
distinguishable from testing random walks, there is a prob-
ability that the adversary will advertise a conﬂicting neigh-
bor list that does not include node B to an initiator of the
testing random walk. The initiator of the testing random
walk will insert the malicious neighbor list into the Whanau
DHT, and node B can perform a robust lookup for node A’s
key to obtain the conﬂicting neighbor list. Since Whanau
only provides availability, node B can check for integrity
of the results by verifying node A’s signature. Since hon-
est nodes never advertise two conﬂicting lists within a time
interval, node B can infer that node A is malicious.
Performance Evaluation: We analyze the number of
testing random walks that each node must perform to
achieve a high probability of detecting a malicious node that
attempts to perform a route capture attack. Nodes must per-
form enough testing walks such that a high percentage of
compromised nodes (which are connected to honest nodes)
have been probed in a single time slot. First, we consider a
defense strategy where honest nodes only insert the termi-
nal hop of the testing random walks in Whanau (Strategy 1).
Intuitively, from the coupon collectors problem, log n walks
per node should sufﬁce to catch a malicious node with high
probability. Indeed, from Figure 5, we can see that six test-
ing walks per time interval sufﬁce to catch a malicious node
performing route capture attacks with high probability. The
honest nodes can also utilize all hops of the testing random
walks to check for conﬂicts (Strategy 2), in which case only
two or three testing walks are required per time interval (at
the cost of increased communication overhead for the DHT
operations).
Next, we address the question of how to choose the du-
ration of the time interval (t). The duration of the time slot
governs the trade-off between communication overhead and
reliability of circuit construction. A large value of the time
slot interval results in a smaller communication overhead
but higher unreliability in circuit construction, since nodes
selected in the random walk are less likely to still be on-
line. On the other hand, a smaller value of the time interval
provides higher reliability in higher circuit construction at
lengths; Figure 7 depicts our experimental results. Using
these results, we estimate that 25 hop circuits would take
about 1 minute to construct.
4.3 Anonymity
Earlier, we considered the probability of end-to-end tim-
ing analysis as our metric for anonymity. This metric con-
siders the scenario where the adversary has exactly de-