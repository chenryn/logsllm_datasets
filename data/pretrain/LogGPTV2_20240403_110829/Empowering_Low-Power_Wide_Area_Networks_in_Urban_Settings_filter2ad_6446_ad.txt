close to one another are likely to have several overlapping bits, one
can use this information to obtain a coarse view of sensor data in a
given geographical region.
316
Figure 6: Testbed: (a) Sensor testbed spans four floors of a large university
building; floor plan of one such floor is shown with sensor locations marked
by dots. (b) Anonymized map of the neighborhood surrounding CMU campus
with testbed spanning 10 square kilometers.
The rest of this section addresses various challenges in achiev-
ing such a design. First, how do we ensure that teams of sensors
transmit packets that are synchronized in time? Second, how do
we detect and decode their collisions, despite the fact that individ-
ual sensors are beyond communication range? Finally, how do we
choose which sensors transmit concurrently?
7.1 Coordinating Transmissions from Sensor
Teams
Consider a team of sensors that are individually beyond commu-
nication range but would like to transmit identical data packets.
Indeed, gathering a large team of sensors would cause the overall
received power to add up, increasing signal power. However, to do
so one would have to ensure that the transmissions are synchro-
nized in time so that identical symbols across transmitters add up
to reinforce received power.
Time Synchronization. We rely on the fact that Choir is immune
to timing offset. Specifically, we first make the base station transmit
a beacon packet that solicits a response from all sensors in a given
geographic boundary. Given that the base station affords a much
higher transmit power (and superior antennas) as compared to the
client, its signal will be received by all these sensors, even if their
signals are individually too weak to reach the base station. The
sensors then respond concurrently with packets in the next time slot
(i.e. after a fixed pre-agreed duration of time). However, in practice,
such synchronization is never perfect and packets between different
sensors will continue to have a small timing offset. Fortunately,
given the relatively long symbol durations of LP-WAN (∼ 10 ms),
this timing offset is smaller than one symbol (see Sec. 9.1-9.3). As
described in Sec. 6, such timing offsets can be interpreted as a
corresponding frequency offset between the different transmitters.
Recall that Choir exploits such frequency offsets to obtain distinct
peaks corresponding to each client in any collision (as in Fig. 3).
As a result, the coarse time-synchronization provided by the base
station’s beacon packet is sufficient to observe such peaks, at least
for sensors above the noise-floor at the base station.
Whom do we coordinate? Now that we have a mechanism to co-
ordinate sensors, how do we decide whom to coordinate or schedule
at any given time. In practice, making this decision is a function of
the spatial distribution of sensor data, which can vary between dif-
ferent kinds of sensors and different environments. Given that sen-
sors are often deployed statically in buildings over long durations,
User 1User 2f1f1f2f2ff|f||f|- Test Locations- Base Locations3.4 km3.2 km- Sensors95 m40 m(a)  (b)Empowering Low-Power Wide Area Networks in Urban Settings
SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
one can learn the extent of these correlations over time. Indeed,
such a scheduling algorithm can estimate the signal-to-noise ratio
of clients to schedule larger groups of sensors for transmitters that
are further away. In effect, this leads to a system whose resolution
of measured sensor data increases for sensors that are geographi-
cally closer to the base station. Our results in Sec. 9 measures the
correlation of data from various subsets of temperature sensors
deployed across multiple buildings in CMU campus.
7.2 Decoding Beyond Communication Range
Now that we have synchronized collisions from a desired group of
clients, we next detect and decode their data.
Detecting Packets. A key challenge however is that for trans-
mitters far away from the base station, all peaks may be buried
below the noise-floor. Indeed, this makes detecting collided packets
from teams of weak client transmitters particularly challenging.
Our solution to overcome this problem relies on the multiplicity of
clients that collide as well as preamble symbols. In particular, we
coherently add the power of the Fourier representation, given by
Eqn. 1 over sliding windows of n symbols, where n is the size of the
preamble. Despite the fact that peaks in any one symbol are below
the noise, they are unlikely to be buried in noise when averaged
over a large number of symbols. This allows us to both detect the
packet as well as obtain coarse estimates of frequency offsets as
required by Algm 1.
Decoding Algorithm. While averaging over symbols is useful to
detect the energy of the preamble, one cannot do so for the data
given that each data symbol carries a unique sequence of bits. There-
fore, our solution to decode data relies on a maximum-likelihood
approach that exploits the knowledge of frequency offsets. Specifi-
cally, we reconstruct different possible collisions of the transmitters
given their channels and frequency offsets (from Algm. 1) for each
possible sequence of data bits in a symbol. We then obtain the data
bits by identifying the collision that best fits the observed data sym-
bol. Mathematically, for any received signal y, channels hi, timing
offsets ti and frequency offsets fi for each client i, we obtain the
data symbol d as
||y −(cid:88)
i
d = arg min
d
hiej2π (fi+B ∆ti
T
+d)tC||2
(6)
where C is the known preamble chirp that spans a bandwidth B
over time T, as before. Given that the above equation models and
exploits the presence of multiple clients in the collision, it provides
a robust method to decode data despite each individual client’s
signal being below noise.
Dealing with Collisions. Despite scheduling certain teams of
transmitters with a beacon from the base station, it is possible that
such transmissions will experience collisions with other sensors
closer to the base station. Our approach to deal with such unwar-
ranted collisions is very similar to Choir’s solution for the near-far
effect in Sec. 5.2. In particular, we first measure and subtract peaks
above the noise from the received signal until repeatedly using
Algm. 1 until no clear peaks are visible. Finally, we apply the de-
tection and decoding steps described above to extract scheduled
transmissions from clients that are below the noise floor.
A few points are worth noting: (1) Like any other protocol, Choir
may be unable to recover collisions owing to excessive interference
or noise leading to some packets unacknowledged. In this scenario,
Choir relies on LoRaWAN’s underlying MAC protocol (ALOHA or
TDMA) to identify such loses (e.g. using acknowledgments) and
re-transmit. (2) To achieve gains, Choir requires that overlapping
chunks of bits of sensor data lead to overlapping chunks of sig-
nals that then add up in power. However, interleaving and coding
schemes may cause even data different by one bit to have few coded
bits in common. Our solution to resolve this is to splice sensed data
into smaller packets that carry different chunks of consecutive
sensed bits so that those with most significant bits remain identical,
even after coding.
8 IMPLEMENTATION
We implement Choir on a testbed of software radio base stations
and clients built using commodity components and the LoRaWAN
chip. Our base stations are composed of USRP N210 software radios
and the WBX daughterboards operating at the 900 MHz bands5. We
use the UHD+GnuRadio library and develop our own LoRaWAN
decoder and Choir’s algorithms in C++ and MATLAB to process
signals. Unless specified otherwise, our base station uses a single
S469AM-915 antenna and a ZX60-0916LN+ low noise amplifier. We
mounted the base station on the top floors of three tall buildings
on CMU campus. Our experiments using MU-MIMO deploy with
up to 3 base-station antennas synchronized by a Jacksonlab Fury
clock.
The clients are SX1276MB1LAS boards with an embedded Lo-
RaWAN chip that is mBed compatible. We connect these boards
with NUCLEO-L152RE boards with the mBed platform to program
the LoRaWAN chips to transmit sensor data at regular time peri-
ods. The boards operate at a center frequency of 902 MHz over a
bandwidth of 500 KHz or 125 KHz depending on the data rate the
wireless channel supports [5]. We consider three different types
of data: (1) Random sequence of bits per packet that are transmit-
ted periodically at regular intervals (500 ms). (2) A specific known
sequence of bytes at the same period. (3) Sensor data from tem-
perature and humidity sensors placed across different buildings in
the university campus, as they are observed. We leverage an open
environmental sensor board platform with an Atmel Atmega32L
microcontroller and on-board BME280 temperature and humidity
sensors.
Evaluation: We evaluate our system in a neighborhood of CMU
campus. The campus contains and is surrounded by several multi-
storey buildings, trees and hilly terrain. We make up to 30 client
nodes simultaneously transmit from as many as 100 locations across
four floors of five different buildings in different parts of the campus
as well as in buildings, roads and pedestrian walkways outside
campus over an area spanning 10 square kilometers around the
campus. Fig. 6 plots the scale of our testbed area with the actual
roads and building shapes omitted due to anonymity. We note that
we consider concurrent transmissions from multiple distributed
client nodes to a single base station at any time.
Baseline: We compare our system with two baselines: (1)
LoRaWAN: A standard LoRaWAN baseline that uses slotted
5Note that dedicated LoRa base stations can support better ADCs than the USRP given
that the base station can afford to be more expensive and power hungry.
317
SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
R. Eletreby, D. Zhang, S. Kumar, and O. Yağan
(a)
(b)
(c)
(d)
Figure 7: Characterizing Hardware Offsets:
(a)-(b) Measures the CDF of the time plus frequency offset and only the frequency offset as observed across 30
LoRaWAN LP-WAN nodes. (c)-(d) Measures the average and standard deviation of the root mean-squared error of the relative timing offset and the frequency
offset plus timing offset within a packet.
ALOHA coupled with exponential backoff to retransmit; (2) Lo-
RaWAN+Oracle: LoRaWAN with an oracle scheduler that explicitly
schedules transmissions optimally to avoid collisions; (3) Choir: Our
System which decouples collisions using hardware offsets. When
deploying multi antenna stations (Sec. 9.5), we additionally compare
our system with the state-of-the-art uplink MU-MIMO [40].
9 RESULTS
9.1 Characterizing Hardware Offsets
In this experiment, we characterize the distribution of observed
frequency and timing offsets measured across different LoRaWAN
hardware. We do this to characterize the diversity of these offsets
with real hardware, which is crucial to separate different users. We
further evaluate how stable they remain across symbols over the
duration of a packet.
Method: We consider a testbed with two single-antenna LP-WAN
radio which transmit a known sequence of bits concurrently. We
synchronize transmissions using beacon packets as described in
Sec. 6. We receive collisions from these transmitters on a USRP N210
software radio emulating a single-antenna LP-WAN base station.
We repeat this experiment across multiple packets and measure the
timing and frequency offset on a per-symbol basis as described in
Sec. 5 and 6. We further perform this experiment for different pairs
of LoRaWAN radios across 30 LP-WAN radios.
Results: Fig. 7(a) and (b) plot the cumulative distribution of time
plus frequency offset, and only the frequency offset, respectively, as
measured across 30 nodes. We specifically focus on the fractional
component of frequency offset and sub-symbol timing offsets, given
that these are the quantities that help us separate transmissions
of users. We note that observed sub-symbol timing offsets and
frequency offsets in the wild across nodes are equally likely to span
the entire range of possible values. The diversity of these hardware
offsets makes them suitable vehicles to track and separate users.
Next, we evaluate the stability of these values across symbols
and our ability to measure them accurately. We plot the average and
standard deviation of the root mean-squared percentage error of
the relative timing offset and the frequency offset plus timing offset
within a packet in fig. 7(c) and (d) across a range of SNR values. As
a percentage relative to the duration of symbol and bandwidth of a
subcarrier, respectively, we observe the mean error of these offsets
to be just 1.84 % and .04 % respectively, attesting the stability of
these values and Choir’s ability to track them accurately.
9.2 Disentangling Collisions
In this experiment, we present our results from disentangling colli-
sions from simultaneous transmissions by a large number of LP-
WAN nodes.
Method: We consider a testbed, initially with two single-antenna
LP-WAN radios which each transmit a randomly chosen sequence
of bits concurrently. We receive collisions from these transmitters
on a USRP N210 software radios emulating a single-antenna LP-
WAN base station. We repeat this experiment across a range of
locations of the two LP-WAN nodes where both nodes experience
different levels of signal-to-noise ratio (SNR). We then progressively
add nodes until the network has as many as 10 nodes transmitting
concurrently at any time. We measure three metrics: (1) network
throughput of all nodes; (2) latency measured between a beacon
packet from the base station and the response packet from a client;
(3) total number of transmissions and re-transmissions required to
send one packet worth of data – a useful metric to measure energy
efficiency, as that packet transmission is a major drain on battery
for sensors [3].
Results: Fig. 8(a)-(c) Measures the throughput, latency and num-
ber of transmissions for Choir and the LoRaWAN baseline for two
radios across different SNR regimes – low (20 dB). Nodes transmit at the fastest data rate
that can be supported by the SNR. We observe that Choir experi-
ences a 2.58×(2.113×) gain in throughput vs. LoRaWAN(+Oracle),
3.9×(1.5×) reduction in latency and 3.0549×(6) × reduction in num-
ber of transmissions required to send a useful packet of data over
standard LoRaWAN. Indeed, Choir’s performance remains consis-
tent across SNR regimes. Fig. 8(d)-(f) measures the throughput,
latency and number of transmissions for Choir and the LoRaWAN
baseline as the number of concurrent users colliding progressively
increases. Our system’s performance increases progressively as
the number of users increases, given the opportunities to decode
multiple users simultaneously, with 29.02×(6.84×) gain in through-
put vs. LoRaWAN(+Oracle), and 19.37×(4.88×), 4.54× reduction in
latency and retransmissions respectively for 10 simultaneous users.
We observe that the scaling, while impressive is not unbounded.
This is because at such a large number of concurrent users, the
near-far effect coupled with collisions in hardware offsets become
increasingly likely to limit system performance.
6Oracle has perfect performance in # transmissions
318
 0 0.2 0.4 0.6 0.8 1 0 20 40 60 80 100 120 140CDFObserved CFO+TO (Hz)ObservedIdeal 0 0.2 0.4 0.6 0.8 1-80-60-40-20 0 20 40 60 80CDFObserved Frequency Offset (Hz)ObservedIdeal 0 5x10-6 1x10-5 1.5x10-5 2x10-5 2.5x10-5 3x10-5LowMediumHighStdev of Relative TO (s)SNR 0 0.02 0.04 0.06 0.08 0.1 0.12LowMediumHighStdev CFO+TO (Hz)SNREmpowering Low-Power Wide Area Networks in Urban Settings
SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
(a)
(d)
(b)
(e)
(c)
(f)
Figure 8: Disentangling Collisions: Consider concurrent transmissions from several LP-WAN nodes across a wide range of SNRs decoded at a single-antenna
LP-WAN base station. (a)-(c) Measures the throughput, latency and number of transmissions for Choir and the LoRaWAN baseline across low (<5 dB), medium