### 1-4. Steps 1-4 are run as before. In Step 4, the client receives Epk(dH + ri) and decrypts the result.

### 5. Next, the parties compute the appropriate output value by invoking an OT2dmax+1 protocol, where the server is the receiver and the client is the sender:

- Let \( L_D = 2d_{\text{max}} \). The input of the server is \( (t_i + r_i) \mod (L_D + 1) \).
- The client has inputs \( X_0, \ldots, X_{L_D} \), where
  \[
  X_j =
  \begin{cases}
  1 & \text{if } (d_H + r_i - d_{\text{max}}) \mod (L_D + 1) \leq j \leq (d_H + r_i) \mod (L_D + 1) \\
  0 & \text{otherwise}
  \end{cases}
  \]

**Figure 3: The Fthreshold protocol where the server learns the output.**

The security of the protocol is proven similarly to the security of the protocol in Figure 2. The details are provided in the full version of the paper.

### F. Computing Fmin+t

The Fmin+t functionality finds the item in the server’s database whose distance from the client’s input is minimal, as long as this distance is below the threshold. This functionality can be implemented in a straightforward manner using a generic method for secure computation, such as Yao’s protocol. In the Appendix, we describe a specific protocol for this task, which is more efficient and simpler to implement. It does not use a circuit representation of the function and is based on oblivious transfer, similar to the protocols described previously.

### G. Security against Malicious Adversaries

The protocols described are secure against semi-honest adversaries. A malicious adversary can deviate from the prescribed protocols and change the computed function, potentially learning information about the other party’s input.

There are known generic transformations that convert any semi-honest protocol into one secure against malicious adversaries [20], but these are not efficient in practice. More efficient protocols with this level of security have been presented for specific applications. However, several obstacles need to be overcome for the applications discussed:
1. The protocol must ensure that the inputs \( w \) and \( w' \) of the parties are in the format of a face representation, rather than arbitrary binary vectors.
2. The client must send encryptions of bits in Step 1, rather than arbitrary values.
3. The server must send back an encryption of the Hamming distance (plus a random value), rather than another function of the messages it receives.
4. The inputs to the OT must be according to the protocol.

Some of these issues can be addressed efficiently (e.g., [28] provides a method for verifying the inputs to the OT stage by replacing the OT with oblivious polynomial evaluation). However, ensuring that the entire protocol computes the desired functionality efficiently remains challenging. Another option is to design protocols that provide security only against covert adversaries, meaning that adversaries not following the protocol are detected with some non-negligible probability. This level of security might be sufficient to deter most attacks in our setting. See [30] for a discussion of security against covert adversaries.

### V. An Example of a Real-Time Security System

The proposed algorithms can be combined in different configurations depending on the application. This section describes an example of a security system for recognizing suspected individuals using a remote camera module installed in a public place.

As described in Section II, the system consists of a server and a client. During the preprocessing phase, the server generates face representations of suspects, converts them to binary vectors, and computes individual thresholds. The binary representations and individual thresholds are stored on the server. The cryptographic protocol is initialized by the client, which sends encryptions of the bits of a random binary vector and performs the preprocessing step of the OTs. The server computes the sum of consecutive pairs of bits, as required by the optimized protocol.

The client obtains an image from a real-time face detection algorithm, builds a binary face representation, and sends homomorphic encryptions of its bits to the server. For each subject in the database, the parties execute the Fthreshold cryptographic algorithm. The output, which can be learned by one or both parties, is a set of binary bits, one for each database entry. If all bits are 0 (the most likely case, since most people should not match any suspect), the client continues with the next image. If one or more bits are 1, the system operator is notified.

### VI. Experiments

As detailed in Section II, the proposed system can be separated into a face recognition part and a secure computation part. The face recognition part generates face representations independently by each party, while the secure computation part checks if there is a match between the acquired face and the server’s database.

We separated our experiments into two parts. First, we examined the face recognition algorithm used in SCiFI, focusing on its accuracy. Our current implementation in MATLAB takes about 10 seconds to process a face; a C implementation would likely be faster, possibly by a factor of 4-5. Then, we examined the performance (latency) of the secure computation protocol.

#### A. Face Recognition Experiments

The face recognition experiments consist of two parts:
1. **Real Security System Experiment:** Simulates a real security system that stores a list of subjects on the server and decides whether an input image obtained by the client matches one of the faces on the list. We constructed an ensemble of people to determine individual thresholds based on the smallest Hamming distance between each subject and the rest of the people in the ensemble.

   - **Public Set Y:** Constructed from images with frontal illumination using a subset of 34 3D models of faces supplied by USF.
   - **Benchmark Databases:** Tested the proposed face representation on two benchmark databases, checking its robustness to various factors and comparing it to the Eigenfaces method.
   
     - **Large Illumination Variation:** Tested on the CMU-PIE database, which contains images of white, black, and Asian faces under 43 illuminations. The results show that our method outperforms Eigenfaces, achieving 93% recognition with 15% false alarms.
     - **Near-Frontal Changes in Pose, Mild Facial Expressions, and Mild Illumination Changes:** Tested on the FERET database, showing 97% recognition success with a 5% false alarm rate, compared to 87% for Eigenfaces.
     - **Robustness to Illumination Changes and Partial Occlusions:** Tested the effects of partial occlusions in eye, nose, and mouth areas. The results show that our method is robust to partial occlusions, with almost no degradation in recognition rate.

2. **Identification Performance:** Tested the recognition power of the proposed binary representation in an identification task in a closed universe, meaning all probes are in the gallery. The tests were conducted on benchmark data sets to allow comparison with existing methods.

   - **CMU-PIE Database:** Achieved 80% recognition for the closest match and 95% recognition within the top 6 matches.
   - **FERET fc:** Achieved lower recognition rates compared to CMU-PIE, but comparable to previously reported results, with a larger gallery size explaining the performance degradation.

#### B. Secure Computation Experiments

A prototype of SCiFI was implemented in Java using Sun’s JDK 1.6.0 12. Homomorphic encryption was implemented using Paillier’s algorithm with a modulus N of 1024 bits. The implementation of OT21 was based on the Bellare-Micali scheme and El Gamal encryption in a subgroup of order q of Z∗p, where |p| = 1024 and |q| = 160. Symmetric encryption was done using AES.

The results show that the system is extremely fast, taking about 0.3 seconds to compare the vector representing the client’s input with the vector representing an image in the server’s database. During the server preprocessing phase, for every pair of consecutive bits sent by the client, the server precomputes the four possible values that can be added to the Hamming distance. This computation is performed only once and used for all images.