1-4. Steps 1-4 are run as before. In Step 4 the client receives
Epk(dH + ri) and decrypts the result.
5. Next, the parties compute the appropriate output value,
protocol where the server is
by invoking a OT2dmax+1
the receiver and the client is the sender:
1
- Let LD = 2dmax. The input of the server is (ti +
ri) mod (LD + 1).
- The client has inputs X0, . . . , XLD, where
⎧⎨
⎩
1
0
Xj =
if dH + ri − dmax mod (LD + 1) ≤ j
and j ≤ dH + ri mod (LD + 1)
otherwise
Figure 3: The Fthreshold protocol where the server learns the
output.
The security of the protocol is proved similarly to the
security of the protocol of Figure 2. The details are given
in the full version of the paper.
F. Computing Fmin+t
The Fmin+t functionality ﬁnds the item in the server’s
database whose distance from the client’s input is mini-
mal, as long as this distance is below the threshold. This
functionality can be implemented in a rather straightforward
manner using a generic method for secure computation,
such as Yao’s protocol. We describe in the Appendix a
speciﬁc protocol for this task, which is more efﬁcient and
more simple to implement, as it does not use a circuit
representation of the function, and is based on oblivious
transfer as the previous protocols that we have described.
G. Security against malicious adversaries
The protocols that we described are secure against semi-
honest adversaries. A malicious adversary can deviate from
the prescribed protocols, and can deﬁnitely change the
function that is computed and learn information about the
other party’s input.
There are known generic transformations of any semi-
honest protocol to a protocol secure against malicious ad-
versaries [20], but these are not efﬁcient in practice. More
efﬁcient protocols with this level of security were presented
for speciﬁc applications. There are, however, several obsta-
cles that need to be overcome in the case of the applications
that we discuss: (1) The protocol must ensure that the inputs
w, w(cid:2) of the parties are in a format of a face representation,
249
rather than being arbitrary binary vectors (namely, that the
number of “1” bits and their locations are as deﬁned in
Section III-C). (2) The client must send in Step 1 encryptions
of bits rather than of arbitrary values. (3) The server must
send back an encryption of the Hamming distance (plus
a random value), rather than of another function of the
messages it receives. (4) The inputs to the OT must be
according to the protocol.
Some of these issues can be solved rather efﬁciently (see
for example [28] for a method for verifying the inputs to
the OT stage, by replacing the OT with oblivious poly-
nomial evaluation). However, ensuring in an efﬁcient way
that the entire protocol computes the desired functionality
seems challenging. Another, possibly simpler, option is to
design protocols which provide security only against covert
adversaries, roughly meaning that adversaries which do not
behave according to the protocol are caught with some
non-negligible probability. This level of security might be
sufﬁcient to deter most attacks in our setting. See [30] for
a discussion of security against covert adversaries.
V. AN EXAMPLE OF A REAL-TIME SECURITY SYSTEM
The proposed algorithms can be combined in different
conﬁgurations depending on the application. In this section
we describe an example of a security system for recognition
of suspected individuals using a remote camera module
installed in a public place.
As was described in Section II, the system is composed
of a server and a client. During the preprocessing phase,
the server generates face representations of suspects, as
described in Section III-C, and converts them to binary
vectors as was shown in Section IV-B. The individual
thresholds are computed as is described in Section III-D. The
binary representations and individual thresholds are stored
in the server. The cryptographic protocol is initialized by
the client, which sends encryptions of the bits of a random
binary vector, and performs the preprocessing step of the
OTs. The server computes the sum of consecutive pairs of
bits, as is required by the optimized protocol.
The client obtains an image from a real-time face de-
tection algorithm (e.g., [1], [2]), builds a binary face rep-
resentation (Sections III-C, IV-B) and sends homomorphic
encryptions of its bits to the server. For each subject i in the
database, the parties executes the Fthreshold cryptographic
algorithm. The output, which can be learnt by one party or
both parties, according to the variant of the protocol that is
used, is a set of binary bits, one for every database entry. If
all bits are equal to 0 (which is the most likely case, since
most of the people should not match any suspect), the client
continues with the next image. If one or more of the bits
are 1 then the operator of the system is notiﬁed.
VI. EXPERIMENTS
As was detailed in Section II, the proposed system can be
separated into a face recognition part and a secure computa-
tion part. The face recognition part generates representations
of the faces in the server’s database and of the face acquired
by the client, and is run independently by each party. In the
secure computation part the two parties jointly execute a
secure protocol which checks if there is a match between
the acquired face and the server’s database.
In light of this architecture we separated our experiments
into two parts. We ﬁrst examined the face recognition
algorithm used in SCiFI, with an emphasis on examining
its accuracy. (Our current implementation of the algorithm
in Matlab and takes about 10 seconds to process a face; it
is clear that an implementation in C will be faster, probably
by a factor of 4-5.) Then we examined the performance, i.e.
latency, of the secure computation protocol.
A. Face Recognition Experiments
The face recognition experiments consist of two parts.
The ﬁrst part (presented in Section VI-A1) includes tests
that simulate a real security systems with server and client.
The second part (presented in Section VI-A2) includes
experiments conducted according to the protocols used in
the face recognition community. These tests are performed
on benchmark sets which allows direct comparison with the
state of the art in face recognition.
1) Real security system experiment: Our tests simulate
a real security systems that stores a list of subjects in the
server and decides whether an input image obtained by a
client matches one of the faces on the list. To determine
a threshold on the Hamming distance for each person we
constructed an ensemble of people which included other
individuals from the server’s list and images of unrelated
people which represent typical inputs to the system. An
individual threshold for the ith subject is set based on the
smallest Hamming distance between him and the rest of the
people in the ensemble.
We constructed the public set Y of faces from which the
part vocabularies will be taken, by rendering images with
frontal illumination using a subset of 34 3D models of faces
supplied by USF.4
We tested the proposed face representation on two bench-
mark databases, checking its robustness to various factors
that
inﬂuence the intra-user variation, and comparing it
to the Eigenfaces method, which was the only other face
recognition algorithm for which a secure protocol is known.
(For the Eigenfaces method we pre-aligned all images and
normalized them for brightness.)
4USF HumanID 3D Face Database, Courtesy of Prof. Sudeep Sarkar,
University of South Florida, Tampa, FL.
Large illumination Variation: We tested the robustness
of the representation to large illumination changes on the
frontal pose subset of CMU-PIE database [5] that contains
images of white, black, and asian faces of males and females,
in total 68 subjects under 43 illuminations (see Figure 1, top
row for a few examples from this data set).
The server’s list included 12 persons under frontal illu-
mination. The client’s set (a stream of images) contained
2912 images (which is equivalent
to an hour of video,
with a processing rate of 1 image per sec.) of 68 subjects,
from which 504 belonged to the subjects from the server’s
list. All of the client’s images contained faces in a frontal
pose under large illumination changes, which make the face
identiﬁcation task much harder. About third of the subjects
on the server’s list wear glasses, but then remove them in
half of the client’s images. The results are shown (Figure
4) in a form of a recognition rate plotted as a function of
false positive rate. For example, our method spots suspects
in about 93% of images with 15% false alarms. This is
dramatically better than the Eigenface performance, which is
less than 50% recognition at this false alarm rate. This result
was, however, expected, since Eigenface cannot generalize
well to unseen conditions, such as changes in lighting and
local occlusions such as glasses.
Near-frontal changes in pose, mild facial expressions
and mild illumination changes: Although the current imple-
mentation of the system does not allow large variations in
pose or facial expression, it can still handle some variation
in these factors. To test our representation in a more realistic
setting, namely, near-frontal variation in pose and mild
changes in facial expressions and illumination, we ran our
system on the gallery and the fc probe set (i.e. thet set
of test images) of the FERET [4] database. The probe set
includes 194 images taken with a different camera and under
different illumination than the images in the gallery set
which includes 1196 subjects. The bottom row of Figure 1
shows some of the variations present between the gallery set
and the probe set. We took 100 subjects from the fc probe
set for the server’s list, and used all 1196 gallery images
as a client’s set. Figure 5 shows the results of our method
compared to the Eigenface, which again shows the beneﬁt
of our approach. For example, with a false alarm rate of 5%,
our algorithm has 97% recognition success while Eigenface
succeeds with probability of about 87%.
Robustness to illumination changes and partial oc-
clusions: One of the advantages of using a part-based
representation is its robustness to partial occlusions. We
tested the effects of partial occlusions in eye, nose and
mouth areas separately. To simulate occlusions we used a
square area with size of 20% of the image width ﬁlled with
random noise (Figure 8 shows some examples of partial
occlusions used in the test). Occlusion was applied to images
obtained from the client and not to images in the server’s
list. Table II summarizes the recognition results, tested on
250
images of 68 people from the CMU-PIE database under 10
illuminations and partial occlusions. The right column of the
table describes the number of patches with at least half of
their area occluded. For example, hiding the nose hides 3
of the 30 patches, and yet the recognition rate shows almost
no degradation (92.8% compared to 93% for a 15% false
positive rate).
2) Identiﬁcation Performance: In order to test the recog-
nition power of the proposed binary representation we used
it in an identiﬁcation task in a closed universe, meaning
that all probes are in the gallery (see [4])5. The tests were
conducted on benchmark data sets to allow comparison with
the existing methods.
Following the FERET [4] evaluation of identiﬁcation in
a closed universe, we report the performance statistics by
a graph of cumulative match. The horizontal axis of the
graph is a rank (rank=c corresponds to the c persons who
have the smallest distance to the probe among all persons
in the gallery), and the vertical axis is the probability of
identiﬁcation. These graphs are obtained as follows: for
each probe the galleries are ordered by their distance to the
probe (from minimum to maximum). The rank corresponds
to the threshold on the number of galleries considered.
The recognition is deﬁned to be successful for rank r, if
the correct person is found within the r galleried in the
ordered list corresponding to the probe. Our plots show the
percentage of probes that are of a particular rank or less. For
example, in Figure 6, 80% of the probes have the correct
identity as their closest match, and 95% of the probes have
the correct identity among the 6 closest matches.
In the large gallery test, FERET reports the top 50 matches
for each probe [4]. In our experiments we set the number of
top matches relative to the number of subjects in the gallery.
In the CMU-PIE frontal pose
subset [5] we used frontal illumination with ambient light
CMU-PIE database:
Figure 4: The illumination robustness test on CMU-PIE
Figure 5: Robustness test to a combination of several factors.
The test has been performed on the gallery and fc probe set
of the FERET database.
as a gallery image and other 42 illuminations as probes, in
total 2856 probe images. Note that our setting tests not only
illumination variation, but also the effects of glasses, since
28 out of 68 subjects wear glasses in the gallery image and
then remove them in the half of the probe images (without
ambient light). The results are shown in Figure 6. A separate
test in which all galleries and probes include ambient light
shows 100% recognition. A test in which all galleries and
probes have no ambient light and no glasses shows 99%.
The recognition results in this test are comparable to the
state of the art [31], [32].
FERET fc: We ran our tests on the gallery and fc
probe sets of FERET [4]. The gallery of FERET contains
1196 subjects and the fc probe set includes images of 194
subjects taken with a different camera and under different
illumination. Besides the illumination, some variation in fa-
cial expression (smiling and blinking) and near-frontal pose
variation are present between the gallery and the probe sets.
The results are reported in Figure 7. The recognition results
on FERET are lower than CMU-PIE, but are comparable
with previously reported results [4], [33]. The gallery in
this test is about 17 times larger than in CMU-PIE, which
explains the degradation in performance.
B. Secure Computation Experiments
A prototype of SCiFI was implemented in Java using
Sun’s JDK 1.6.0 12. Homomorphic encryption was imple-
mented using Paillier’s algorithm, with a modulus N of
length 1024 bits.6 The implementation of OT2
1 was based
on the Bellare-Miacli scheme and El Gamal encryption in a
p, where |p| = 1024 and |q| = 160.
subgroup of order q of Z∗
Symmetric encryption was done using AES.
The results, which are detailed below, are extremely fast,
taking about 0.3 second to compare the vector representing
the client’s input with the vector representing an image in
5The gallery contains images of people stored in the database, probes
are images that must be identiﬁed. Each probe image is compared against
all images in the gallery for identiﬁcation
6The implementation was based on the Java implementation in
http://www.bricks.dk/˜jurik/research.html.
251
Section IV-A.
Server preprocessing phase. For every pair of consecutive
bits sent by the client, i.e., E(v2j), E(v2j+1) the server
precomputes the four possible values that can be added to
the Hamming distance, namely E(v2j + v2j+1), E(v2j +1−
v2j+1), E(1 − v2j + v2j+1) and E(2 − v2j − v2j+1). This
computation is performed only once and used for all images