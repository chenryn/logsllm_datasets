title:Attack Surface Metrics and Automated Compile-Time OS Kernel Tailoring
author:Anil Kurmus and
Reinhard Tartler and
Daniela Dorneanu and
Bernhard Heinloth and
Valentin Rothberg and
Andreas Ruprecht and
Wolfgang Schr&quot;oder-Preikschat and
Daniel Lohmann and
R&quot;udiger Kapitza
Attack Surface Metrics and Automated Compile-Time OS Kernel Tailoring
Anil Kurmus1, Reinhard Tartler2,
Daniela Dorneanu1, Bernhard Heinloth2, Valentin Rothberg2, Andreas Ruprecht2,
Wolfgang Schr¨oder-Preikschat2, Daniel Lohmann2, and R¨udiger Kapitza3
1IBM Research - Zurich
2Friedrich-Alexander University Erlangen-N¨urnberg
3TU Braunschweig
Abstract
The economy of mechanism security principle states that
program design should be kept as small and simple as possi-
ble. In practice, this principle is often disregarded to max-
imize user satisfaction, resulting in systems supporting a
vast number of features by default, which in turn offers at-
tackers a large code base to exploit. The Linux kernel ex-
empliﬁes this problem: distributors include a large number
of features, such as support for exotic ﬁlesystems and socket
types, and attackers often take advantage of those.
A simple approach to produce a smaller kernel is to man-
ually conﬁgure a tailored Linux kernel. However, the more
than 11,000 conﬁguration options available in recent Linux
versions make this a time-consuming and non-trivial task.
We design and implement an automated approach to pro-
duce a kernel conﬁguration that is adapted to a particular
workload and hardware, and present an attack surface eval-
uation framework for evaluating security improvements for
the different kernels obtained. Our results show that, for
real-world server use cases, the attack surface reduction
obtained by tailoring the kernel ranges from about 50% to
85%. Therefore, kernel tailoring is an attractive approach
to improve the security of the Linux kernel in practice.
1 Introduction
The Linux kernel is a commonly attacked target. In 2011
alone, 148 Common Vulnerabilities and Exposures (CVE)1
entries for Linux have been reported, and this number is ex-
pected to grow every year. This is a serious problem for sys-
1http://cve.mitre.org/
tem administrators who rely on a distribution-maintained
kernel for the daily operation of their systems. On the
Linux distributor side, kernel maintainers can make only
very few assumptions on the kernel conﬁguration for their
users: Without a speciﬁc use case, the only option is to en-
able every available conﬁguration option to maximize the
functionality. The ever-growing kernel code size, caused by
the addition of new features, such as drivers and ﬁle sys-
tems, at an increasing pace, indicates that the Linux kernel
will be subject to ever more vulnerabilities.
In addition, as a consequence of the development, test-
ing, and patching process of large software projects, the less
a functionality is used, the more likely it is to contain de-
fects. Indeed, developers mostly focus on ﬁxing issues that
are reported by their user base. As rarely used functionali-
ties only account for reliability issues in a small portion of
the user base, this process greatly improves the overall re-
liability of the software. However, malicious attackers can,
and do, still target vulnerabilities in those less-often-used
functionalities. A recent example from the Linux kernel is
an arbitrary kernel memory read and write vulnerability in
the reliable datagram sockets (RDS) (CVE-2010-3904), a
rarely used socket type.
If the intended use of a system is known at kernel com-
pilation time, an effective approach to reduce the kernel’s
attack surface is to conﬁgure the kernel to not include un-
needed functionality. However, ﬁnding a suitable conﬁgu-
ration requires extensive technical expertise about currently
more than 11,000 Linux conﬁguration options, and needs to
be repeated at each kernel update. Therefore, maintaining
such a custom-conﬁgured kernel entails considerable main-
tenance and engineering costs.
Moreover, while it is widely accepted that making pro-
grams “smaller” improves security, quantitatively measur-
1
ing security improvements remains a difﬁcult and impor-
tant problem [49]. Existing work on system security of-
ten measures improvements in terms of Trusted Comput-
ing Base (TCB) reduction, which in practice often trans-
lates into a measurement of the total number of source lines
of code (SLOC) (e.g., [19, 34]). Although these metrics
are sensible (as every line of code can have a vulnerabil-
ity) and easy to obtain, they can be imprecise. For instance,
on a given kernel conﬁguration, a large part of the kernel
sources will not be compiled, many parts will only be com-
piled as kernel modules which might never be loaded, and
some functions might simply not be within reach of an at-
tacker.
This paper presents metrics for quantifying the security
of an OS kernel and a tool-assisted approach to automat-
ically determine a kernel conﬁguration that enables only
kernel functionalities that are actually necessary in a given
scenario. Although it is easy to quantify the size of the re-
sulting kernel binaries, this is not convincing evidence that
the resulting kernel indeed presents less of an attack surface
to potential attackers. Hence, after deﬁning what attack sur-
face means, we quantify the security gains in two distinct
security models in terms of attack surface reduction. The
ﬁrst security model considers that the entire kernel can be
subject to attacks and is therefore a good reference for com-
parison to previous work, whereas the second considers the
scenario of a restricted attacker, and is a good reference for
evaluating the security improvements of conﬁguration tai-
loring in the context of unprivileged local attackers. Our
measurements take into account the static call graph of the
kernel and the possible entry points of the attacker to pro-
vide a more accurate comparison.
Our automated kernel-tailoring approach builds on our
previous work [51], and extends it with multiple improve-
ments, including loadable kernel module (LKM) support.
When compared to other hardening solutions, a notable ad-
vantage of the kernel-conﬁguration tailoring approach is
that it makes no changes to the source code of the kernel:
therefore, it is impossible to introduce new defects into the
kernel source. This approach uses run-time traces as input
for deducing a suitable kernel conﬁguration, and we show
it to work equally well in different use cases. We detail
the use our tool to tailor a “Linux, Apache, MySQL and
PHP (LAMP) stack” kernel on server hardware, as well
as a network ﬁle system (NFS) running on a workstation.
We obtain comparative measurements of the tailored ker-
nels that show that conﬁguration-tailoring incurs no over-
head and no stability issues, while greatly reducing the at-
tack surface in both security models.
The major contributions of this paper are:
• A deﬁnition of an attack surface and an attack-surface
metric based on static call graphs and security models;
examples of metrics satisfying this deﬁnition, and a
comparison of the effects of these choices on our mea-
surements.
• A tool that, given the kernel sources and run-time
traces characterizing a use case, produces a small ker-
nel conﬁguration, taking into account LKMs, which
includes all kernel functionalities necessary for the
workload.
• An evaluation of the attack surface reduction as well
as performance results in the case of a LAMP-based
server and a workstation providing access to ﬁles via
NFS.
The remainder of this paper is structured as follows: Sec-
tion 2 deﬁnes the notions of attack surface and attack sur-
face measurement, as well as a set of attack surface met-
rics that can be used in practice for our evaluation. Sec-
tion 3 presents an overview of the tailoring process, and
the implementation of the underlying automated kernel-
conﬁguration-tailoring tool. Section 4 evaluates the attack
surface reduction and performance of such an approach in
two use cases and with several attack surface reduction met-
rics. These results are then discussed in Section 5. Section 6
presents related work. The paper concludes in Section 7.
2 Security Metrics
In this section, we present two distinct security models,
and, for each of them, security metrics (attack surface mea-
surements) which we use in Section 4 to evaluate and quan-
tify the security of a running Linux kernel. The dependence
between notions deﬁned or used in this section are summa-
rized in Figure 1.
2.1 Preliminary deﬁnitions
Deﬁnition 1 (Call graph). A call graph is a directed graph
(F,C), where F ⊆ N is the set of nodes and represents the
set of functions as declared in the source of a program, and
C ⊆ F × F the set of arcs, which represent all direct and
indirect function calls. We denote the set of all call graphs
by G .
In practice, static source code analysis at compile time
(that takes all compile-time conﬁguration options into ac-
count) is used to obtain such a call graph.
Deﬁnition 2 (Entry and barrier functions). A security
model deﬁnes a set of entry functions E ⊆ F, which cor-
responds to the set of functions directly callable by an at-
tacker, and a set of barrier functions X ⊆ F, which corre-
sponds to the set of functions that, even if reachable, would
prevent an attacker from progressing further into the call
graph.
Figure 1. Dependencies between notions de-
ﬁned in this section.
E would typically be the interface of the program that
is exposed to the attacker, whereas X would typically be
the set of functions that perform authorization for privileges
that the attacker is not assumed to have in the security model
(e.g., administrator privileges).
Deﬁnition 3 (Attack Surface). Given a call graph G =
(F,C), a set of entry functions E ⊆ F and a set of barrier
functions X ⊆ F, let G(cid:48) be the subgraph of G induced by the
nodes F(cid:48) = F \ X, and let E(cid:48) = E \ X. The attack surface
is then the subgraph GAS of G(cid:48) induced by all nodes f ∈ F(cid:48)
such that there exists e ∈ E(cid:48) and a directed path from e to f .
By abusing notation, we denote GAS = (G,E,X).
The rationale behind this deﬁnition is that for most types
of kernel vulnerabilities due to defects in the source code,
the attacker needs to trigger the function containing the vul-
nerability through a call to an entry function (which, for
local attackers, would be a system call). For example:
for exploiting a double-free vulnerability, the attacker will
need to provoke the extraneous free; for exploiting a stack-
or heap-based buffer overﬂow, the function writing to the
buffer will be reachable to the attacker; for exploiting a
user-pointer dereference vulnerability, the attacker owning
the user-space process will often provoke the dereference
through the system call interface.
Therefore, the attack surface represents the set of func-
tions that an attacker can potentially take advantage of.
2.2 Security Models
Quantifying a program’s security without specifying a
security model is attractive because it provides an “absolute
value” to compare other programs to. However, taking into
account a security model, and more generally the actual use
of the program, can only result in security metrics that re-
ﬂect the system’s security better. As a simple example, it
is common practice to measure a kernel’s security by the
total SLOC. However, the source code will often contain
branches that will never be compiled such as architecture-
speciﬁc code for other architectures. Hence, limiting the
SLOC by excluding unused architecture-speciﬁc code, be-
cause this code cannot be exercised by an attacker, is al-
ready an improvement in precision.
Figure 2. On the left, the GENSEC model. On
the right, the ISOLSEC model.
We now consider the case of the Linux kernel. First, we
deﬁne a generic security model that covers the dependabil-
ity of the entire running kernel, and then a more speciﬁc
model covering local attacks from unprivileged user space
directed against the kernel. They are depicted in Figure 2.
In both cases, the hardware and the compile-time con-
ﬁguration of the kernel are ﬁxed and taken into account.
In both cases, the high-level security goal is to provide the
traditional conﬁdentiality, integrity and availability guaran-
tees for the kernel: for instance, an attacker could target
full control with arbitrary code execution in kernel mode,
or more limited attacks such as information leakage (e.g.,
recover uninitialized kernel memory content) to breach con-
ﬁdentiality, and denial of service by crashing the kernel to
reduce the system’s availability. In addition, we assume that
the hardware and the ﬁrmware the system is running on are
trusted.
2.2.1 Generic Model GENSEC
The GENSEC model covers all possible kernel failures, to
obtain an attack surface that is similar to the notion of TCB
used for measuring security in prior work (e.g., [19, 34]).
More precisely, the attacker is both local and remote, i.e.,
it has an account on the target system, but can also interact
with all hardware devices (e.g., sending layer-1 trafﬁc to
network interface cards). We also assume that the attacker
has some amount of control over a privileged application.
This means the model includes failures due to defects in the
kernel in code paths that are only accessibly from a privi-
leged application.
Therefore, in this model, a defect in any part of the
running kernel — including the core kernel and all loaded
LKMs, as well as any LKM that might be loaded in the fu-
ture, e.g., when new hardware is plugged in — can cause a
failure.
This security model may not seem intuitive, but cor-
responds to what is implicitly assumed when considering
SecuritymodelProgram source and configurationEntry and barrierfunctionsCall graph:functions and callsAttack surfaceAttack surfacemeasurementAttack surfacemetricSystem call interfaceHardware interfaceCore KernelLKMLKM(on-demand loadable)Application(privileged)HardwareApplication(unprivileged)attackerattack surfacerunning kernelpartial a.s.System call interfaceHardware interfaceCore KernelLKMApplication(privileged)HardwareApplication(unprivileged)LKM(on-demand loadable)LKM(driver)LKM(other)LKM(driver)LKM(other)the entire compiled kernel included in the TCB, a common
practice.
GENSEC attack surface
In the GENSEC model above,
the attack surface is composed of the entire running kernel,
as well as LKMs that can be loaded. Hence, the barrier
functions set X is empty, and all entry points of the ker-
nel are included in E (both hardware interrupts and system
calls, as well as kernel initialization code).
2.2.2 Isolation Model ISOLSEC
The ISOLSEC model reﬂects a common model in multi-
user systems and in systems implementing defense in depth,
where it is assumed an attacker has local access, e.g, by
compromising an unprivileged isolated (or sandboxed) pro-
cess on the system, and aims to escape the isolation by di-
rectly targeting the kernel. In this model, the attacker is ma-
licious and has unprivileged local access, therefore it can
exercise the system call interface, but not all code paths:
for instance, the attacker cannot make the system call for
the insertion of a new kernel module. We will detail below,
when evaluating the attack surface, exactly which barrier
functions should be considered.