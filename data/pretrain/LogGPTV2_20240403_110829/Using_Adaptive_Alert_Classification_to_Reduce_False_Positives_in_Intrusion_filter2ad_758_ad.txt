# Optimized Text

## Number of Alerts Processed
### (b) Data Set B, ICR=50
**Figure 4.** Number of alerts processed autonomously by ALAC in agent mode.

As shown in Figure 4(a), with a sampling rate of 0.25, more than 45% of false alerts were processed and discarded by ALAC. Simultaneously, the number of unnoticed false negatives is half that of the recommender mode. Our experiments demonstrate that the system is valuable for intrusion detection analysts as it significantly reduces the number of false positives without making many mistakes.

## 3.5 Results Obtained with Data Set B
We used the second dataset as an independent validation of the system. To avoid overfitting, we used the same set of parameters as for the first data set. However, the ROC curve in Figure 2(b) shows that the classifier achieves a much higher true positive rate and a much lower false negative rate than for the first data set, indicating that Data Set B is easier to classify. This can be attributed to Data Set B containing fewer intrusions and more redundancy compared to the first data set.

The ROC curve consists of two distinct parts. The left part corresponds to RIPPER run for small ICRs, where it learns rules describing true alerts. The right part of the curve corresponds to high ICRs, where RIPPER learns rules describing false alerts. The better performance in the first case can be explained by the fact that the intrusions in this data set are more structured and therefore easier to learn. Conversely, false alerts are more difficult to describe, resulting in poorer performance.

### Background Knowledge and Setting ALAC Parameters
Results from ROC analysis (Figure 2(b)) show that the classifier correctly classifies most examples, and adding background knowledge has little effect on classification. To maintain consistency with the first data set, we decided to use the full background knowledge. We also noted that ICR = 50 is not the optimal value for this dataset, as it results in a high false positive rate (FN = 0.002, FP = 0.05).

We observed that ALAC, when run with 30% of the alerts as an initial classifier, classified the remaining alerts with very few learning runs. To demonstrate its incremental learning capabilities, we decided to reduce the initial amount of training data from 30% to 5% of all the alerts.

### ALAC in Recommender Mode
Figure 5 shows that in recommender mode, the system has a much lower overall false negative rate (FN = 0.0045) and a higher overall false positive rate (FP = 0.10) than for the DARPA 1999 data set, which is comparable to the results of classification in batch mode. We also observed that learning only occurred for approximately the first 30% of the entire data set, and the classifier classified the remaining alerts with no additional learning. This can be explained by the fact that Data Set B contains more regularities, making it easier to build the classifier.

This is different for the DARPA 1999 data set, where the classifier was frequently rebuilt in the last 30% of the data. For the DARPA 1999 data set, the behavior of ALAC is explained by the fact that most of the intrusions actually took place in the last two weeks of the experiment.

### ALAC in Agent Mode
In agent mode, we obtained results similar to those in recommender mode, with a large number of alerts being processed autonomously by the system (FN = 0.0065, FP = 0.13). As shown in Figure 4(b), with a sampling rate of 0.25, more than 27% of all alerts were processed by the agent. Simultaneously, the actual number of unnoticed false negatives is one-third smaller than the number of false negatives in recommender mode, confirming the system's usefulness with an independent data set.

Similar to observations in Section 3.4 with lower sampling rates, the agent will seemingly have fewer false negatives but will miss more alerts. As expected, the total number of false negatives is lower with higher sampling rates. This effect is not as clearly visible as with the DARPA 1999 data set.

## 3.6 Understanding the Rules
One requirement of our system was that the rules can be reviewed by the analyst and their correctness can be verified. The rules built by RIPPER are generally human-interpretable and thus can be reviewed by the analyst. Here is a representative example of two rules used by ALAC:

1. `(cnt_intr_w1 = 1) and (cnt_sign_w1 >= 1) and (cnt_dstIP_w1 >= 1) => class=FALSE`
2. `(cnt_srcIP_w3 = 2) and (sign = ICMP PING NMAP) => class=FALSE`

The first rule reads: If the number of alerts classified as intrusions in the last minute (window w1) equals zero and there have been other alerts triggered by a given signature and targeted at the same IP address as the current alert, then the alert should be classified as a false positive. The second rule states that if the number of NMAP PING alerts originating from the same IP address is less than six in the last 30 minutes (window w3), there have been no intrusions in the last 5 minutes (window w2), and there has been at least one alert with an identical source or destination IP address, then the current alert is a false positive.

These rules are intuitively appealing: If there have been similar alerts recently and they were all false alerts, then the current alert is also a false alert. The second rule indicates that if the number of NMAP PING alerts is small and there have been no recent intrusions, then the alert is a false alert.

We observed that the comprehensibility of rules depends on several factors, including the background knowledge and the cost ratio. With less background knowledge, RIPPER learns more specific and harder-to-understand rules. The effect of varying the cost ratio is particularly apparent for rules produced while constructing the ROC curve, where RIPPER induces rules for either true or false alerts. This is due to the use of RIPPER running in ordered rule set mode.

## 4 Conclusions and Future Work
We presented a novel concept of building an adaptive alert classifier based on an intrusion detection analystâ€™s feedback using machine learning techniques. We discussed the issues of human feedback and background knowledge, and reviewed machine learning techniques suitable for alert classification. Finally, we presented a prototype implementation and evaluated its performance on synthetic and real intrusion data.

We showed that background knowledge is useful for alert classification, especially for the DARPA 1999 data set. For the real-world dataset, adding background knowledge had little impact on classification accuracy. The second set was much easier to classify, even with no background knowledge. Hence, we did not expect improvement from background knowledge in this case. We also showed that the system is useful in recommender mode, where it adaptively learns the classification from the analyst. For both datasets, we obtained false negative and false positive rates comparable to batch classification. Note that in recommender mode, all system misclassifications would have been corrected by the analyst.

Additionally, we found that our system is useful in agent mode, where some alerts are autonomously processed (e.g., false positives classified with high confidence are discarded). More importantly, for both data sets, the false negative rate of our system is comparable to that in the recommender mode. At the same time, the number of false positives has been reduced by approximately 30%.

The system has several numeric parameters that influence its performance and should be adjusted depending on the input data. In the future, we intend to investigate how these parameter values can be automatically determined. We are also aware of the limitations of the data sets used. We aim to evaluate the performance of the system on more realistic intrusion detection data and integrate an alert correlation system to reduce redundancy in alerts.

Our system uses RIPPER, a noise-tolerant algorithm, but the extent to which ALAC can tolerate errors in the data is currently unknown. We will address this issue by introducing artificial errors and observing their effects on the system. The topic of learning comprehensible rules is very interesting, and we plan to investigate it further. We are currently looking at learning multiple classifiers for each signature and using RIPPER in unordered rule set mode.

In the machine learning part, we intend to focus on the development of incremental machine learning techniques suitable for learning a classifier for intrusion detection. Initially, we want to perform experiments with partial memory techniques and batch classifiers. Later, we will focus on truly incremental techniques. It is important that such techniques be able to incorporate the required background knowledge.

## Acknowledgments
Many thanks to Klaus Julisch and Andreas Wespi for their contributions to the system and valuable comments. Thanks also go to other members of the Global Security Analysis Laboratory and anonymous reviewers for their insightful remarks.

## References
[References remain unchanged]