 0
 0
 10000
 20000
 30000
 40000
 50000
 60000
Alerts Processed
(b) Data set B, ICR=50
Fig. 4. Number of alerts processed autonomously by ALAC in agent mode.
As shown in Fig. 4(a), with the sampling rate of 0.25, more than 45% of false
alerts were processed and discarded by ALAC. At the same time the number
of unnoticed false negatives is half the number of mistakes for recommender
mode. Our experiments show that the system is useful for intrusion detection
Using Adaptive Alert Classiﬁcation
119
analysts as it signiﬁcantly reduces number of false positives, without making
many mistakes.
3.5 Results Obtained with Data Set B
We used the second dataset as an independent validation of the system. To
avoid “ﬁtting the model to the data” we used the same set of parameters as for
the ﬁrst data set. However, a ROC curve in Fig. 2(b) shows that the classiﬁer
achieves much higher true positive rate and much lower false negative rate than
for the ﬁrst data set, which means that Data Set B is easier to classify. The likely
explanation of this fact is that Data Set B contains fewer intrusions and more
redundancy than the ﬁrst data set.
Notice that the ROC curve consists of two distinct parts. An analysis shows
that the left part corresponds to RIPPER run for small ICRs, where it learns
the rules describing true alerts. The right part of the curve corresponds to high
ICRs, where RIPPER learns the rules describing false alerts. Better performance
in the ﬁrst case can be explained by the fact that the intrusions in this data set
are more structured and therefore easier to learn. On the other hand, false alerts
are more diﬃcult to describe and hence the performance is poorer.
Background Knowledge and Setting ALAC Parameters. Results with ROC anal-
ysis (Fig. 2(b)) show that the classiﬁer correctly classiﬁes most of the exam-
ples, and adding background knowledge has little eﬀect on classiﬁcation. To
have the same conditions as with the ﬁrst data set, we nonetheless decided
to use the full background knowledge. We also noticed that ICR = 50 is not
the optimal value for this dataset as it results in a high false positive rate
(F N = 0.002, F P = 0.05).
We observed that ALAC, when run with 30% of the alerts as an initial
classiﬁer, classiﬁed the remaining alerts with very few learning runs. Therefore,
to demonstrate its incremental learning capabilities, we decided to lower the
initial amount of training data from 30% to 5% of all the alerts.
ALAC in Recommender Mode. Figure 5 shows that in recommender mode the
system has a much lower overall false negative rate (F N = 0.0045) and a higher
overall false positive rate (F P = 0.10) than for DARPA 1999 data set, which is
comparable to the results of the classiﬁcation in batch mode. We also observed
that the learning only took place for approximately the ﬁrst 30% of the entire
data set and the classiﬁer classiﬁed the remaining alerts with no additional
learning. This phenomena can also be explained by the fact that Data Set B
contains more regularities and the classiﬁer is easier to build.
This is diﬀerent in the case of the DARPA1999 data set, where the classiﬁer
was frequently rebuilt in the last 30% of the data. For DARPA1999 data set the
behavior of ALAC is explained by the fact that most of the intrusions actually
took place in the last two weeks of the experiment.
120
Tadeusz Pietraszek
ALAC in Agent Mode. In agent mode we obtained results similar to those in
recommender mode, with a great number of alerts being processed autonomously
by the system (F N = 0.0065, F P = 0.13). As shown in Fig. 4(b), with the
sampling rate of 0.25, more than 27% of all alerts were processed by the agent.
At the same time the actual number of unnoticed false negatives is one third
smaller than the number of false negatives in recommender mode. This conﬁrms
the usefulness of the system tested with an independent data set.
Similarly to observation in Sect. 3.4 with lower sampling rates, the agent will
have seemingly fewer false negatives, in fact missing more alerts. As expected the
total number of false negatives is lower with higher sampling rates. This eﬀect
is not as clearly visible as with DARPA1999 data set.
)
n
f
(
s
e
v
i
t
a
g
e
N
e
s
a
F
l
 90
 80
 70
 60
 50
 40
 30
 20
 10
 0
 0
Agent - sampling 0.1
Agent - sampling 0.25
Agent - sampling 0.5
Recommender
Batch Classification
)
p
f
(
s
e
v
i
t
i
s
o
P
e
s
a
F
l
 10000
 20000
 30000
 40000
 50000
Alerts Processed
 4500
 4000
 3500
 3000
 2500
 2000
 1500
 1000
 500
 0
 0
 10000
 20000
 30000
 40000
 50000
Alerts Processed
Fig. 5. False negatives and false positives for ALAC in agent and recommender modes
(Data set B, ICR=50).
3.6 Understanding the Rules
One requirement of our system was that the rules can be reviewed by the analyst
and their correctness can be veriﬁed. The rules built by RIPPER are generally
human interpretable and thus can be reviewed by the analyst. Here is a repre-
sentative example of two rules used by ALAC:
(cnt_intr_w1 = 1) and (cnt_sign_w1 >= 1)
and (cnt_dstIP_w1 >= 1) => class=FALSE
(cnt_srcIP_w3 = 2)
and (sign = ICMP PING NMAP) => class=FALSE
The ﬁrst rule reads as follows: If a number of alerts classiﬁed as intrusions in the
last minute (window w1) equals zero and there have been other alerts triggered
by a given signature and targeted at the same IP address as the current alert,
then the alert should be classiﬁed as false positive. The second rule says that,
if the number of NMAP PING alerts originating from the same IP address is less
than six in the last 30 minutes (window w3), there have been no intrusions in
the last 5 minutes (window w2) and there has been at least 1 alert with identical
source or destination IP address, then the current alert is false positive.
Using Adaptive Alert Classiﬁcation
121
These rules are intuitively appealing: If there have been similar alerts recently
and they were all false alerts, then the current alert is also a false alert. The
second rule says that if the number of NMAP PING alerts is small and there has
not been any intrusions recently, then the alert is a false alert.
We observed that the comprehensibility of rules depends on several factors
including the background knowledge and the cost ratio. With less background
knowledge RIPPER learns more speciﬁc and diﬃcult to understand rules. The
eﬀect of varying cost ratio is particularly apparent for rules produced while
constructing the ROC curve, where RIPPER induces rules for either true or
false alerts. This is due to the use of RIPPER running in ordered rule set mode.
4 Conclusions and Future Work
We presented a novel concept of building an adaptive alert classiﬁer based on
an intrusion detection analyst’s feedback using machine learning techniques. We
discussed the issues of human feedback and background knowledge, and reviewed
machine learning techniques suitable for alert classiﬁcation. Finally, we presented
a prototype implementation and evaluated its performance on synthetic as well
as real intrusion data.
We showed that background knowledge is useful for alert classiﬁcation. The
results were particularly clear for the DARPA 1999 data set. For the real-world
dataset, adding background knowledge had little impact on the classiﬁcation
accuracy. The second set was much easier to classify, even with no background
knowledge. Hence, we did not expect improvement from background knowledge
in this case. We also showed that the system is useful in recommender mode,
where it adaptively learns the classiﬁcation from the analyst. For both datasets
we obtained false negative and false positive rates comparable to batch classiﬁ-
cation. Note that in recommender mode all system misclassiﬁcations would have
been corrected by the analyst.
In addition, we found that our system is useful in agent mode, where some
alerts are autonomously processed (e.g., false positives classiﬁed with high con-
ﬁdence are discarded). More importantly, for both data sets the false negative
rate of our system is comparable to that in the recommender mode. At the same
time, the number of false positives has been reduced by approximately 30%.
The system has a few numeric parameters that inﬂuence its performance
and should be adjusted depending on the input data. In the future, we intend to
investigate how the value of these parameters can be automatically determined.
We are also aware of the limitations of the data sets used. We aim to evaluate
the performance of the system on the basis of more realistic intrusion detection
data and to integrate an alert correlation system to reduce redundancy in alerts.
Our system uses RIPPER, a noise-tolerant algorithm, but the extent to which
ALAC can tolerate errors in the data, is currently unknown. We will address this
issue by introducing an artiﬁcial error and observing how it aﬀects the system.
The topic of learning comprehensible rules is very interesting and we plan
to investigate it further. We are currently looking at learning multiple classiﬁers
for each signature and using RIPPER in unordered rule set mode.
122
Tadeusz Pietraszek
In the machine learning part we intend to focus on the development of incre-
mental machine learning technique suitable for learning a classiﬁer for intrusion
detection. Initially we want to perform experiments with partial memory tech-
nique and batch classiﬁers. Later we will focus on truly incremental techniques.
It is important that such techniques be able to incorporate the required back-
ground knowledge.
Acknowledgments
Many thanks to Klaus Julisch and Anderas Wespi for their contribution to the
system and valuable comments. Thanks also goes to other members of the Global
Security Analysis Laboratory and anonymous reviewers for their insightful re-
marks.
References
1. Anderson, J.P.: Computer security threat monitoring and surveillance. Technical
report, James P. Anderson Co (1980).
2. Axelsson, S.: The base-rate fallacy and its implications for the intrusion detection.
In: Proceedings of the 6th ACM conference on Computer and Communications
Security, Kent Ridge Digital Labs, Singapore (1999) 1–7.
3. Bloedorn, E., Hill, B., Christiansen, A., Skorupka, C., Talbot, L., Tivel, J.: Data
Mining for Improving Intrusion Detection. Technical report, MITRE (2000).
4. Cohen, W.W.: Fast eﬀective rule induction. In Prieditis, A., Russell, S., eds.: Pro-
ceedings of the 12th International Conference on Machine Learning, Tahoe City,
CA, Morgan Kaufmann (1995) 115–123.
5. Cuppens, F.: Managing alerts in multi-intrusion detection environment. In: Pro-
ceedings 17th Annual Computer Security Applications Conference, New Orleans
(2001) 22–31.
6. Dain, O., Cunningham, R.K.: Fusing a heterogeneous alert stream into scenarios.
In: Proc. of the 2001 ACM Workshop on Data Mining for Security Application,
Philadelphia, PA (2001) 1–13.
7. Debar, H., Wespi, A.: Aggregation and correlation of intrusion-detection alerts.
In: Recent Advances in Intrusion Detection (RAID2001). Volume 2212 of Lecture
Notes in Computer Science., Springer-Verlag (2001) 85–103.
8. Denning, D.E.: An intrusion detection model. IEEE Transactions on Software En-
gineering SE-13 (1987) 222–232.
9. Domingos, P.: Metacost: A General Method for Making Classiﬁers Cost-Sensitive.
In: Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, San Diego, California (1999) 155–164.
10. Fan, W.: Cost-Sensitive, Scalable and Adaptive Learning Using Ensemble-based
Methods. PhD thesis, Columbia University (2001).
11. Fawcett, T.: ROC graphs: Note and practical considerations for researchers (HPL-
2003-4). Technical report, HP Laboratories (2003).
12. Giraud-Carrier, C.: A Note on the Utility of Incremental Learning. AI Communi-
cations 13 (2000) 215–223.
13. Hettich, S., Bay, S.D.: The UCI KDD Archive. Web page at http://kdd.ics.uci.
edu (1999).
Using Adaptive Alert Classiﬁcation
123
14. Jacobson, V., Leres, C., McCanne, S.: TCPDUMP public repository. Web page at
http://www.tcpdump.org/ (2003).
15. Julisch, K.: Using Root Cause Analysis to Handle Intrusion Detection Alarms.
PhD thesis, University of Dortmund (2003).
16. Lavraˇc, N., Dˇzeroski, S.: Inductive Logic Programming: Techniques and Applica-
tions. Ellis Horwood (1994).
17. Lee, W.: A Data Mining Framework for Constructing Features and Models for
Intrusion Detection Systems. PhD thesis, Columbia University (1999).
18. Lee, W., Fan, W., Miller, M., Stolfo, S.J., Zadok, E.: Toward cost-sensitive model-
ing for intrusion detection and response. Journal of Computer Security 10 (2002)
5–22.
19. Lippmann, R., Haines, J.W., Fried, D.J., Korba, J., Das, K.: The 1999 DARPA
Oﬀ-Line Intrusion Detection Evaluation. Computer Networks: The International
Journal of Computer and Telecommunications Networking 34 (2000) 579–595.
20. Lippmann, R., Webster, S., Stetson, D.: The eﬀect of identifying vulnerabilities
and patching software on the utility of network intrusion detection. In: Recent
Advances in Intrusion Detection (RAID2002). Volume 2516 of Lecture Notes in
Computer Science., Springer-Verlag (2002) 307–326.
21. Mahoney, M.V., Chan, P.K.: An Analysis of the 1999 DARPA/Lincoln Laboratory
Evaluation Data for Network Anomaly Detection. In: Recent Advances in Intru-
sion Detection (RAID2003). Volume 2820 of Lecture Notes in Computer Science.,
Springer-Verlag (2003) 220–237.
22. Maloof, M.A., Michalski, R.S.: Incremental learning with partial instance memory.
In: Proceedings of Foundations of Intelligent Systems: 13th International Sym-
posium, ISMIS 2002. Volume 2366 of Lecture Notes in Artiﬁcial Intelligence.,
Springer-Verlag (2002) 16–27.
23. Manganaris, S., Christensen, M., Zerkle, D., Hermiz, K.: A Data Mining Analysis
of RTID Alarms. Computer Networks: The International Journal of Computer and
Telecommunications Networking 34 (2000) 571–577.
24. Mar´ıa, J., Hidalgo, G.: Evaluating cost-sensitive unsolicited bulk email catego-
rization. In: Proceedings of the 2002 ACM Symposium on Applied Computing,
Springer-Verlag (2002) 615–620.
25. McHugh, J.: The 1998 Lincoln Laboratory IDS Evaluation. A critique. In: Recent
Advances in Intrusion Detection (RAID2000). Volume 1907 of Lecture Notes in
Computer Science., Springer-Verlag (2000) 145–161.
26. Michalski, R.: On the quasi-minimal solution of the general covering problem. In:
Proceedings of the V International Symposium on Information Processing (FCIP
69)(Switching Circuits). Volume A3., Yugoslavia, Bled (1969) 125–128.
27. Mitchel, T.M.: Machine Learning. Mc Graw Hill (1997).
28. Morin, B., M´e, L., Debar, H., Ducasse, M.: M2D2: A formal data model for IDS
alert correlation. In: Recent Advances in Intrusion Detection (RAID2002). Volume
2516 of Lecture Notes in Computer Science., Springer-Verlag (2002) 115–137.
29. Provost, F., Fawcett, T.: Robust classiﬁcation for impresice environments. Machine
Learning Journal 42 (2001) 203–231.
30. Quinlan, R.: C4.5: Programs for Machine Learning. Morgan Kaufman (1993).
31. Roesch, M.: SNORT. The Open Source Network Intrusion System. Web page at
http://www.snort.org (1998–2003).
32. Sommer, R., Paxson, V.: Enhancing Byte-Level Network Intrusion Detection Sig-
natures with Context. In: Proceedings of the 10th ACM conference on Computer
and Communication Security, Washington, DC (2003) 262–271.
124
Tadeusz Pietraszek
33. Ting, K.: Inducing cost-sensitive trees via instance weighting. In: Proceedings of
The Second European Symposium on Principles of Data Mining and Knowledge
Discovery. Volume 1510 of Lecture Notes in AI., Springer-Verlag (1998) 139–147.
34. Valdes, A., Skinner, K.: Probabilistic alert correlation. In: Recent Advances in
Intrusion Detection (RAID2001). Volume 2212 of Lecture Notes in Computer Sci-
ence., Springer-Verlag (2001) 54–68.
35. Wang, J., Lee, I.: Measuring false-positive by automated real-time correlated hack-
ing behavior analysis. In: Information Security 4th International Conference. Vol-
ume 2200 of Lecture Notes in Computer Science., Springer-Verlag (2001) 512–.
36. Witten, I.H., Frank, E.: Data Mining: Practical machine learning tools with Java
implementations. Morgan Kaufmann, San Francisco (2000).