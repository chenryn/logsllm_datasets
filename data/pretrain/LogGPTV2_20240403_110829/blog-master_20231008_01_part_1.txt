## 体验DuckDB Iceberg(大型分析数据集的开源表格式) extension     
### 作者          
digoal          
### 日期          
2023-10-08          
### 标签          
PostgreSQL , DuckDB , Iceberg    
----          
## 背景    
## Apache Iceberg  
https://iceberg.apache.org/docs/latest/  
Apache Iceberg 是一种适用于大型分析数据集的开放表格式。Iceberg 使用高性能表格式向 Spark、Trino、PrestoDB、Flink、Hive 和 Impala 等计算引擎添加表，其工作方式与 SQL 表类似。  
### 用户体验  
Iceberg 避免了令人不快的意外。架构演化有效，不会无意中取消删除数据。用户无需了解分区即可获得快速查询。  
- 模式演化支持添加、删除、更新或重命名，并且没有副作用  
- 隐藏分区可防止用户错误导致无提示的错误结果或极慢的查询  
- 分区布局演变可以随着数据量或查询模式的变化而更新表的布局  
- 时间旅行支持使用完全相同的表快照的可重复查询，或者让用户轻松检查更改  
- 版本回滚允许用户通过将表重置到良好状态来快速纠正问题  
### 可靠性和性能  
Iceberg 是为巨大的桌子而建造的。Iceberg 用于生产环境，其中单个表可以包含数十 PB 的数据，甚至这些巨大的表也可以在没有分布式 SQL 引擎的情况下读取。  
- 扫描计划很快- 不需要分布式 SQL 引擎来读取表或查找文件  
- 高级过滤– 使用表元数据通过分区和列级统计数据修剪数据文件  
Iceberg 旨在解决最终一致的云对象存储中的正确性问题。  
- 可与任何云存储配合使用，并通过避免列出和重命名来减少 HDFS 中的 NN 拥塞  
- 可序列化隔离– 表更改是原子的，读者永远不会看到部分或未提交的更改  
- 多个并发写入器使用乐观并发，即使写入冲突，也会重试以确保兼容更新成功  
### 开放标准  
Iceberg 被设计和开发为一个开放社区标准，其规范可确保跨语言和实现的兼容性。  
开源代码:   
https://github.com/apache/iceberg  
## 在duckdb中体验Iceberg  
https://duckdb.org/docs/extensions/iceberg  
你可以使用如下任意docker image来启动duckdb 0.9.0  
- [PolarDB开源数据库实验室, 永久免费. 可能需要pull刷新一下docker image](https://developer.aliyun.com/adc/scenario/f55dbfac77c0467a9d3cd95ff6697a31)       
- [持续更新, 已集成180余热门插件和工具的PostgreSQL Docker镜像学习环境 ARM64版](../202308/20230814_02.md)       
- [持续更新, 已集成180余热门插件和工具的PostgreSQL Docker镜像学习环境 X86_64版](../202307/20230710_03.md)      
进入容器后, 下载iceberg测试数据, 并查询iceberg数据:  
```  
su - postgres  
wget https://duckdb.org/data/iceberg_data.zip  
unzip iceberg_data.zip  
Archive:  iceberg_data.zip  
   creating: data/  
   creating: data/iceberg/  
   creating: data/iceberg/lineitem_iceberg/  
  inflating: data/iceberg/lineitem_iceberg/README.md    
   creating: data/iceberg/lineitem_iceberg/data/  
  inflating: data/iceberg/lineitem_iceberg/data/00041-414-f3c73457-bbd6-4b92-9c15-17b241171b16-00001.parquet    
 extracting: data/iceberg/lineitem_iceberg/data/.00041-414-f3c73457-bbd6-4b92-9c15-17b241171b16-00001.parquet.crc    
  inflating: data/iceberg/lineitem_iceberg/data/00000-411-0792dcfe-4e25-4ca3-8ada-175286069a47-00001.parquet    
 extracting: data/iceberg/lineitem_iceberg/data/.00000-411-0792dcfe-4e25-4ca3-8ada-175286069a47-00001.parquet.crc    
   creating: data/iceberg/lineitem_iceberg/metadata/  
 extracting: data/iceberg/lineitem_iceberg/metadata/version-hint.text    
 extracting: data/iceberg/lineitem_iceberg/metadata/.version-hint.text.crc    
 extracting: data/iceberg/lineitem_iceberg/metadata/.snap-7635660646343998149-1-10eaca8a-1e1c-421e-ad6d-b232e5ee23d3.avro.crc    
 extracting: data/iceberg/lineitem_iceberg/metadata/.cf3d0be5-cf70-453d-ad8f-48fdc412e608-m0.avro.crc    
 extracting: data/iceberg/lineitem_iceberg/metadata/.10eaca8a-1e1c-421e-ad6d-b232e5ee23d3-m0.avro.crc    
 extracting: data/iceberg/lineitem_iceberg/metadata/.10eaca8a-1e1c-421e-ad6d-b232e5ee23d3-m1.avro.crc    
  inflating: data/iceberg/lineitem_iceberg/metadata/10eaca8a-1e1c-421e-ad6d-b232e5ee23d3-m1.avro    
  inflating: data/iceberg/lineitem_iceberg/metadata/snap-7635660646343998149-1-10eaca8a-1e1c-421e-ad6d-b232e5ee23d3.avro    
 extracting: data/iceberg/lineitem_iceberg/metadata/.v2.metadata.json.crc    
  inflating: data/iceberg/lineitem_iceberg/metadata/10eaca8a-1e1c-421e-ad6d-b232e5ee23d3-m0.avro    
  inflating: data/iceberg/lineitem_iceberg/metadata/cf3d0be5-cf70-453d-ad8f-48fdc412e608-m0.avro    
 extracting: data/iceberg/lineitem_iceberg/metadata/.snap-3776207205136740581-1-cf3d0be5-cf70-453d-ad8f-48fdc412e608.avro.crc    
  inflating: data/iceberg/lineitem_iceberg/metadata/snap-3776207205136740581-1-cf3d0be5-cf70-453d-ad8f-48fdc412e608.avro    
  inflating: data/iceberg/lineitem_iceberg/metadata/v2.metadata.json    
 extracting: data/iceberg/lineitem_iceberg/metadata/.v1.metadata.json.crc    
  inflating: data/iceberg/lineitem_iceberg/metadata/v1.metadata.json   
期待duckdb  
./duckdb  
```  
```  
# README  
this iceberg table is generated by using DuckDB (v0.7.0) to generated TPC-H lineitem  
SF0.01 then storing that to a parquet file.  
Then pyspark (3.3.1) was used with the iceberg extension from https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.3_2.12/1.0.0/iceberg-spark-runtime-3.3_2.12-1.0.0.jar  
to write the iceberg table.  
finally, using pyspark, a delete query was performed on this iceberg table:  
```  
DELETE FROM iceberg_catalog.lineitem_iceberg where l_extendedprice < 10000  
```  
The result for Q06 of TPC-H on this table according to pyspark is now:  
```  
[Row(revenue=Decimal('1077536.9101'))]  
```  
Note: it appears that there are no deletes present in this iceberg table, the whole thing was rewritten.  
this is likely due to the fact that the table is so small?  
```  
进入duckdb shell操作:    
```  
D install iceberg;  
D load 'iceberg';  