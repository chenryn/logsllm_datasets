title:Challenges in Inferring Internet Interdomain Congestion
author:Matthew J. Luckie and
Amogh Dhamdhere and
David D. Clark and
Bradley Huffaker and
kc claffy
Challenges in Inferring Internet Interdomain Congestion
Matthew Luckie
CAIDA / UC San Diego
PI:EMAIL
Amogh Dhamdhere
CAIDA / UC San Diego
PI:EMAIL
David Clark
MIT
PI:EMAIL
Bradley Huffaker
CAIDA / UC San Diego
PI:EMAIL
ABSTRACT
We introduce and demonstrate the utility of a method to
localize and quantify inter-domain congestion in the Inter-
net. Our Time Sequence Latency Probes (TSLP) method
depends on two facts: Internet traﬃc patterns are typically
diurnal, and queues increase packet delay through a router
during periods of adjacent link congestion. Repeated round
trip delay measurements from a single test point to the two
edges of a congested link will show sustained increased la-
tency to the far (but not to the near) side of the link, a
delay pattern that diﬀers from the typical diurnal pattern
of an uncongested link. We describe our technique and its
surprising potential, carefully analyze the biggest challenge
with the methodology (interdomain router-level topology in-
ference), describe other less severe challenges, and present
initial results that are suﬃciently promising to motivate fur-
ther attention to overcoming the challenges.
Categories and Subject Descriptors
C.2.5 [Local and Wide-Area Networks]: Internet; C.2.1
[Network Architecture and Design]: Network topology
Keywords
Interdomain congestion; Internet topology
1.
INTRODUCTION
Unlike traﬃc congestion on links within a single network
(AS), where responsibility for resolving the congestion un-
ambiguously belongs to that network, congestion on AS in-
terconnection links (or interdomain congestion) may reﬂect a
peering dispute, accompanied by ﬁnger-pointing over which
network should pay to upgrade the link to handle the traf-
ﬁc demand. The two primary forms of interconnection are
transit, when one AS sells another ISP access to the global
Internet, and peering, when two ISPs interconnect to ex-
change customer traﬃc. The historical basis for settlement-
free peering was a presumed balance of value to both parties.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
IMC’14, November 5–7, 2014, Vancouver, BC, Canada.
Copyright 2014 ACM 978-1-4503-3213-2/14/11 ...$15.00.
http://dx.doi.org/10.1145/2663716.2663741.
kc claffy
CAIDA / UC San Diego
PI:EMAIL
Peering disputes arise when one party believes the ex-
change is no longer beneﬁcial to them. Historically, peer-
ing disputes were between large transit networks (e.g. [5,10,
32]) where one party would fall out of compliance with the
agreement and be disconnected by the other party until a
new agreement was reached. More recent peering disputes
are fueled by exploding demand for high-bandwidth content
(e.g., streaming video), and growing concentration of con-
tent among a few content distribution networks (e.g. [1, 3,
4, 6, 13, 14, 37]), some large and sophisticated enough to ad-
just loading (and thus congestion levels) on interconnection
links [9,15]. Many disputes do not lead to disconnection but
stalled negotiation about who should pay for installation of
new capacity to handle the demand, leaving the congested
link as an externality for all users of the link until the dispute
is resolved.
Unsurprisingly, there is growing public policy interest in
the extent and scope of congestion induced by persistently
unresolved peering disputes, and how harmful it is to con-
sumers. Unfortunately, almost no data is available for re-
searchers to study interconnection controversies. Traﬃc data
and peering terms are almost always under NDA for news-
worthy peering disputes; providers obfuscate network iden-
tities when they discuss congestion at all [35].
We provide three contributions to understanding the preva-
lence of interdomain congestion. First, we introduce and
demonstrate the utility of a highly scalable probing method
that allows us, from the edge of a given network to localize
and characterize congestion on its interdomain links (sec-
tion 2). Second, we analyze the many challenges associated
with using this method to create a map of interdomain con-
gestion, and how we have either started or plan to handle
them (section 3). Third, we apply our method to illustrate
evidence of persistent interdomain congestion involving large
access and content providers (section 4). We compare our
approach with related work in section 5 and identify ongoing
future work in section 6.
2. TIME SEQUENCE LATENCY PROBES
The idea behind the time-sequence latency probes (TSLP)
method is to frequently repeat round trip time (RTT) mea-
surements from a vantage point (VP) to the near and far
routers of an interdomain link. The measured RTTs are a
function of the queue lengths of the routers on the forward
and reverse paths: as queue lengths increase, so does RTT.
When RTTs increase to the far router but not to the near
router, we infer that a queue between these two routers in-
duced the delay.
15 120
 100
 80
 60
 40
 20
 0
 3
 2
 1
 0
Thu
7th
)
s
m
(
T
T
R
)
%
(
e
t
a
r
s
s
o
L
RTT measurements of border routers
Cogent (far)
Comcast (near)
Loss rate to far border router
Wed
Fri
13th
8th
Day of week in November 2013 (in New York)
Mon
11th
Tue
12th
Sat
9th
Sun
10th
Thu
14th
Figure 1: Comparing link utilization (top panel)
with measured RTT (middle panel) on a 50Mbps
customer link operated by a R&E network. The
bottom scatterplot suggests that as the 1-minute
average load exceeds ≈85%, increasing numbers of
probes to the far side of the link encounter a queue,
suggesting congestion at that moment.
Lending some conﬁdence to this method, ﬁgure 1 plots
a week of traﬃc (SNMP byte counters sampled per-minute)
and RTT measurements across a research and education net-
work link known by the operator to be well utilized. The 30-
minute average utilization on the link (top graph) correlates
with periods when some probes experience increased RTT
to the far end of the interdomain link (middle graph). The
bottom graph shows that most RTT measurements above
10ms occur when the average utilization is above 85%. To
maximize the chance of observing RTT variation across a
speciﬁc link, TSLP sends TTL-limited packets toward the
same destination that expire at the near and far routers,
rather than send packets addressed to the border routers.
If a link is so busy that a tail-drop queue is always close
to full, a time series of RTT measurements to the far router
will approximate a square wave, with the minimum RTT
during the low state reﬂecting probes that did not experi-
ence delay, and the minimum RTT during the high state
reﬂecting probes consistently encountering a queue close to
full. Queue lengths are ﬁnite, limiting the delay contributed
by any one queue, reﬂected by the top of the square wave.
Figure 2 shows such an RTT pattern on a peering link be-
tween Comcast and Cogent; the minimum RTT measured
every ﬁve minutes to the Cogent router increased from 20ms
to 70ms for 14-18 hours per day. We also probed every sec-
ond to observe packet loss across this link, which we only
observed in periods where we also observed increased RTT.
We hypothesize that the increasing loss rate correlates with
increasing demand on the link, and that the width of the
period with elevated delays reﬂects the length of time the
Figure 2: Congestion on an interdomain link be-
tween Comcast and Cogent, measured from a VP
within Comcast. The RTT to the Cogent (far)
router increases from 20ms to 70ms while the RTT
to the Comcast (near) router is stable at 20ms. The
approximate square wave indicates the queue is al-
ways close to full when the RTT increases to 70ms.
The loss rate from the Cogent router increases af-
ter this level shift occurs, as the load on the link
continues to increase.
link was congested. The height of the elevated period is not
an indication of the degree of congestion, but rather the size
of a queue in a router serving the interdomain link.
We asked the ISPs involved to validate our inferences of
this and other links that exhibit this behavior, but they
are generally blocked by NDAs from sharing traﬃc data.
Informal feedback from content, transit, and access network
operators has given us conﬁdence in our observations.
We believe the TSLP approach is a relatively lightweight
method for obtaining data to map which interdomain links
attached to the local network are congested. Compared
with available bandwidth measurement techniques, such as
pathload which sends 12 streams of 100 packets in 15 sec-
onds [21] and requires tomography to identify which is the
constraining link, TSLP uses 2 packets every 5 minutes to
sample a targeted interdomain link, and does not require a
cooperative end-host at the other end of the path. However,
TSLP does send enough traﬃc that it would not scale to
deployment in video players for diagnostic purposes. Many
concurrent TSLP ﬂows would trigger router ICMP response
rate-limiting which defeats the method. Furthermore, TSLP
requires a delay history to detect level shifts, and consumer
video devices tend to operate only when the user wants to
view a video. The value of TSLP is not in its potential uni-
versal deployment, but the insight that a remarkably sparse
deployment can provide to all users sending or receiving traf-
ﬁc over TSLP-measured interconnection links.
Tulip [27] sends ICMP timestamp messages directly to
routers to infer per-hop queuing delay for routers in the for-
ward path as part of a system for diagnosing and pinpointing
faults in Internet paths. Compared with their work, we are
focused on ﬁnding which interdomain links are consistently
underprovisioned, and we do not sample an interdomain link
by sending packets directly to routers.
16Figure 3: Challenges in AS boundary inference from traceroute for network X. In (a), it is unclear whether
x2, announced by X, or a1 announced by A correspond to the far border router. In (b), X’s peer C responds
using an address d1 originated by D, which could cause a false AS link inference X-D. In (c), we observe X’s
(unseen) peer with address x6 originated by X, which could cause E’s customers F and G to be incorrectly
inferred as connected to X. In (d), we do not observe any responding address in H, which could cause us to
not infer that x8 represents H’s border router.
3. METHODOLOGICAL CHALLENGES
3.2 Inferring Interdomain Links
While TSLP is a simple and surprisingly eﬀective method
for inferring congested links, there are many challenges to
applying it eﬀectively: identifying congestion on links with
active queue management and/or weighted fair queueing
policies; accurately ﬁnding and identifying all interdomain
links involving the AS hosting a vantage point; proving the
response from the far router returns over the targeted inter-
domain link; determining the direction of congestion; robust-
ness to ICMP queuing behavior; adapting to path dynamics;
and scaling processing to thousands of interdomain links.
3.1 AQM and WFQ
Active Queue Management (AQM) and Weighted Fair
Queueing (WFQ) present challenges to TSLP. AQM tech-
niques such as Random Early Detection [17] (RED) and
successors try to maintain a small average queue size by dis-
carding packets before a queue becomes full, as a function
of the queue’s current length. RED tries to prevent TCP
global synchronization, where multiple senders experience
packet loss at the same time and collectively reduce their
transmission rate, resulting in an ineﬃcient use of capacity.
However, AQM techniques are not widely deployed [31], in
part because operators traditionally provision links to meet
forecasted demand; the only measurement study of RED de-
ployment we know of was among access networks [12] rather
than interdomain links. Where AQM techniques such as
RED are deployed on congested links such as that in ﬁg-
ure 2, we hypothesize that the level shift from low to high
state will be more gradual as TCP connections encounter
earlier loss, though we still expect to see the queue approach
a state where it is nearly always full with this oﬀered load.
A larger challenge is links that use a fair queueing strategy,
where the router places packets in diﬀerent queues accord-
ing to some property, such as the incoming port or sender.
TSLP cannot infer link congestion when our packets are
placed in a queue that does not experience delay. From
an interaction with one network operator, we learned that
they had deployed WFQ on some of their persistently con-
gested links; TSLP observed no level shift on these links,