然后就会得到返回结果。
PlyQL依赖于Node（版本需大于4.x.x），因此可以通过npm安装：“npm install-g plyql”。
PlyQL同样属于Imply公司出品的开源组件，它搭建于Plywood组件之上，并在其命令
从0.7版本开始，PlyQL提供了 SQL-over-HTTP和MySQLGateway 两类访问方法。接下
"maxTime":{
·查询仿真。旨在预览即将被执行的查询，而非真正执行它们。
目前PlyQL的版本为0.8.x，其主要支持的SQL语法比较简单，并且均属于纯粹将数据
窗口函数。
·对JOIN算子的支持。
"value":"2015-09-12T23:59:00.000Z"
"type": "TIME",
，在WHERE子句中提供子查询功能。
295
---
## Page 320
mysql-gateway"
用户基础。因此，为了与已有的MySQL数据库应用和访问客户端进行集成，PlyQL提供了
法。与此同时，MySQL作为目前最成功的开源传统关系型数据库，它拥有大量的应用支持和
得许多现存的数据应用已基本通过这类方式来访问数据库，而且其使用者都已经熟悉了该方
一脉相承，但是它却不算是符合传统关系型数据库的经典访问方式。对于传统关系型数据
访问方法，这符合大多数NoSQL数据库的访问风格设计，也与Druid原生提供的访问方法
curl-X P0SThttp://localhost:8083/plyql\
plyql-h your.druid.broker:8082-i P2Y--json-server 8083
MySQLGateway访问方法。
库，一般会通过JDBC/ODBC驱动或基于其建立的客户端对后台数据库数据进行访问，这使
296
"sql":"SELECT COUNT(*) FROM wikipedia WHERE\"2015-09-12T01\":/metrics，然后就可以直接运行Druid-Metrics-Kafka项目了。运行的命令
数设置其发送的服务器地址为http://<socket_
Kafka项目。下载后就可以安装，安装的要求也比较简单，只需要如下操作。
已搭建HTTPServer和写KafkaProducer的相关工作。
方式在分布式系统中比较方便，特别是在集群规模比较大的时候。
第11章
的工具。
了Druid-Metrics-Kafka项目，便可轻松地收集并转发Druid指标数据到Kafka上，省去了自
。它支持非常方便地创建Dashboard，支持企业级别的用户认证管理，深度集成了Druid
用户可以通过https://github.com/quantiply/druid-metrics-to-kafka地址下载Druid-Metrics-
Caravel除了支持Druid数据源，还支持其他的数据库，例如MySQL、Oracle等，其内部
Caravel是一个开源的数据可视化平台（之前的名字叫作Panoramix），来源于Airbnb公
在运行Druid-Metrics-Kafka项目前，需要先通过“druid.emitter.http.recipientBaseUrl”参
·安装python-pip。
开源项目Druid-Metrics-Kafka的目标正是为了完成这两个工作，所以用户只要安装使用
·将HTTPServer所接收的指标数据转发到Kafka上。
·创建并启动一个HTTPServer来接收Druid通过HTTP方式发送的指标数据。
，从数据可视化的角度来看，它是除Pivot之外，非常不错的选择Druid数据可视化
Caravel(Airbnb)
Druid生态与展望
---
## Page 326
间里，Druid不但在国外有了如 Yahoo、MetaMarkets、Neflix这类的大玩家做背书，在中国
被开源出来，但是这并没成为它被大家广泛接受的一个阻碍。事实上，在短短不到三年的时
11.4
建设中起到了十分积极的作用。目前Druid的社区讨论组主要有如下两个。
11.3
302
在大数据开源组件的生态系统中，Druid算是比较晚人场的一位一
值得一提的是，与其他成功的开源软件一样，Druid的社区讨论组在Druid生态系统的
Druid展望
加人。
Druid的社区讨论组
8.61970
5.00%
.00%
1975
Germany
83R
1980
1985
图11-11
1990
趋势图
1995
2000
Druid实时大数据分析原理与实践
2005
United Stales
一它在2013年年底才
2010
201
---
## Page 327
参考资料
始，接下来Druid的发展很可能会更加迅猛，因为有一些关于Druid发展的利好因素正在日
里——这无疑证明了Druid在技术方面的确有其独到并领先之处。然而，这仅仅是故事的开
国内也逐渐培养起来一大批主要来自于前沿互联网公司的拥是，在发展速度上可谓日行千
第11章Druid生态与展望
领域自由和民主协作的人们的黄金时代。
件发展的美好时代一这是一个开源软件真正蓬勃发展的大好年代，也是一个属于愿在软件
了一个能帮助我们解决某个技术领域问题的开源项目，更重要的是我们正在一起经历一个软
拥有一个更加绚烂的明天。此时此刻，我们为这一切感到激动的原因，绝不仅仅是因为又多
趋成熟。
https://github.com/implydata
根据上述的分析，我们有理由相信Druid项目不仅正在经历一个成功的今天，也势必将
·用户社区的壮大。Druid的创始团队正在努力将 Druid 推广到更强大的开源社区平台
http://imply.io
·商业公司的兴起。Druid的几位创始人刚创建了Imply 公司，旨在为客户提供基于
进Druid健康发展的辅助因素，而真正能从根本上决定一项技术发展的因素永远都是
技术环境的优化。无论是“用户社区的壮大”还是“商业公司的兴起”，本质上都属于促
分析有着愈发旺盛的需求，这一切无疑是Druid发展所需的必要土壤与养分。
势头——它们在继续创造更加海量的时序数据的同时，也对海量数据做实时MOLAP
环境正处于蓬勃发展的状态之中：互联网和物联网技术与生态依旧保持着迅猛发展的
之，当需求萎靡时，技术的前进动力便如同无本之木。幸运的是，目前Druid所处的技术
实际需求，即技术发展所需的环境。当需求旺盛时，技术的发展便如烈火烹油一般；反
的例证），来自于商业客户的需求也将促进Druid自身向着更加完善的方向发展。
的支持与推动（本章介绍的优秀的Druid相关组件Plywood、PlyQL和Pivot就是很好
Druid技术的商业服务。有了商业活动的支持，Druid势必会得到更有力的公司级别
沙龙等活动，对培养国内用户起到了重要的积极作用。
与此同时，中国国内的Druid社区也在不断发展壮大，并且定期举办很多线下的技术
的 ApacheHadoop和ApacheHive等项目一样成为大数据领域某一方面事实上的标准。
大计，对其今后的发展无疑起到了极大的推动作用，甚至有可能使其像目前功成名就
当中，以利用社区的力量来推广和发展Druid。其中，大名鼎鼎的Apache社区便是
一个极有可能的选项一
一旦双方达成一致，那么对Druid来说就像完成了“招安
303
---
## Page 328
4.实时写入方式的Segment没有落地的原因？
3.Druid数据写人失败的原因？
自定义格式，需要自己编写RegEx或者JavaScript解析。
2.Druid支持什么格式的数据人库？
1.Druid是否支持非结构化数据？
A.1
助读者解决一些实际应用当中的问题。
常见问题（FAQ）
附录1
·Druid更新Metadata Storage失败，需要确保连接Metadata Storage正确。
Druid支持JSON、CSV、TSV或者有明确分隔符的原始数据。除此之外，Druid还支持
Druid不支持非结构化数据，
本附录列出了Druid的一些常见的问题，并针对这些问题做了简要的回答，希望能够帮
·离线：离线写人的数据时间需在指定的interval范围内。
·实时：实时流数据的写入有一个以当前时间为基准的时间窗口（windowPeriod）设置，
若待写入数据的时间不在该时间窗口内，则无法写入Druid。
写人
，数据摄入时依赖预先定义好的结构对数据进行处理。
---
## Page 329
indexer/vl/task/task_id/status）检查任务状态。
task）给Overlord节点并获取返回的taskId。
8.如何监控批量人Druid方式的任务？
ingestion任务的方式覆盖指定时间范围内的数据。
合规则变化、Roll-up聚合粒度改变等，可以利用离线方式重算数据，然后通过重跑batch-
的Segment就将替代旧的Segment。
附录A常见问题（FAQ）
9.
6.
auto
格式
数据时间格式如何设置？
（3）最后定期利用taskId向Overlord节点发送HTTPGET请求（http://overlord_ip:port/druid/
（2）然后通过inputSpec发送HTTP POST请求（http://overlord_ip:port/druid/indexer/v1/
如何更新历史数据？
Druid 可以通过对数据重新摄入生成新的 Segment，一旦新的 Segment 成功生成，新生成
数据更新是怎么回事？
如何使用HDFS作为Deep Storage？
（1）首先离线ETL处理后把待写入Druid的数据放置在指定HDFS路径中。
以Hadoop导入数据方式为例：
Druid 中历史数据的更新基于Segment，如 Schema变化（新增或减少字段）、Metric 聚
·确保安装包中包含druid-hdfs-storage 组件。
·Deep Storage连接配置不正确。
·历史节点没有足够的容量用于本地缓存Segment。
·在服务启动命令中增加 Hadoop classpath 依赖，或者在_common目录下增加 Hadoop
。在common.runtime.properties 的 druid.extensions.loadList配置中加入 druid-hdfs-storage,
相关配置文件（core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml )。
且在middleManager配置中加人对应的Hadoop依赖项。
由 Druid自动判断时间格式，若含有非数字字符，则按iso解