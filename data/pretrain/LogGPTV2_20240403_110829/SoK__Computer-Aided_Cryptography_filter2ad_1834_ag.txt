even just formally specifying it, can reveal ﬂaws. The imple-
mentation of TLS 1.2 with veriﬁed cryptographic security by
Bhargavan et al. [70] discovered new alert fragmentation and
ﬁngerprinting attacks and led to the discovery of the Triple
Handshake attacks [72]. The symbolic analysis of TLS 1.3
draft 10 using Tamarin by Cremers et al. [2] uncovered a
potential attack allowing an adversary to impersonate a client
during a PSK-resumption handshake, which was ﬁxed in
draft 11. The symbolic analysis of TLS 1.3 using ProVerif
by Bhargavan et al. [3] uncovered a new attack on 0-RTT
client authentication that was ﬁxed in draft 13. The symbolic
analysis of draft 21 using Tamarin by Cremers et al. [4]
revealed unexpected behavior that
inhibited certain strong
authentication guarantees. In nearly all cases, these discoveries
led to improvements to the protocol, and otherwise clariﬁed
documentation of security guarantees.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:10:25 UTC from IEEE Xplore.  Restrictions apply. 
789
Lesson: Cryptographic protocol designs are moving tar-
gets; machine-checked proofs can be more easily updated.
The TLS 1.3 speciﬁcation was a rapidly moving target, with
signiﬁcant changes being effected on a fairly regular basis.
As changes were made between a total of 28 drafts, previous
analyses were often rendered stale within the space of a few
months, requiring new analyses and proofs. An important ben-
eﬁt of machine-checked analyses and proofs over their manual
counterparts is that
they can be more easily and reliably
updated from draft to draft as the protocol evolves [2]–[4].
Moreover, machine-checked analyses and proofs can ensure
that new ﬂaws are not introduced as components are changed.
Lesson: Standardization processes can facilitate analysis
by embracing minor changes that simplify security argu-
ments and help modular reasoning. In contrast
to other
protocol standards, the TLS 1.3 design incorporates many
suggestions from the academic community. In addition to secu-
rity ﬁxes, these include changes purposed to simplify security
proofs and automated analysis. For example, this includes
changes to the key schedule that help with key separation,
thus simplifying modular proofs; a consistent tagging scheme;
and including more transcript information in exchanges, which
simpliﬁes consistency proofs. These changes have negligible
impact on the performance of the protocol, and have helped
make analyzing such a complex protocol feasible.
VII. CONCLUDING REMARKS
A. Recommendations to Authors
Our ﬁrst recommendation concerns the clarity of trust
assumptions. We observe that, in some papers, the distinction
between what parts of an artifact are trusted/untrusted is
not always clear, which runs the risk of hazy/exaggerated
claims. On one hand, crisply delineating between what is
trusted/untrusted may be difﬁcult, especially when multiple
tools are used, and authors may be reluctant to spell out an
artifact’s weaknesses. On the other hand, transparency and
clarity of trust assumptions are vital for progress. We point
to the paper by Beringer et al. [173] as an exemplar for how
to clearly delineate between what is trusted/untrusted. At the
same time, critics should understand that trust assumptions are
often necessary to make progress at all.
Our second recommendation concerns the use of metrics.
Metrics are useful for tracking progress over time when used
appropriately. The HACL∗ [5] study uses metrics effectively:
To quantify veriﬁcation effort, the authors report proof-to-code
ratios and person efforts for various primitives. While these are
crude proxies, because the comparison is vertical (same tool,
same developers), the numbers sensibly demonstrate that, e.g.,
code involving bignums requires more work to verify in F∗.
Despite their limitations, we argue that even crude metrics
(when used appropriately) are better than none for advancing
the ﬁeld. When used inappropriately, however, metrics become
dangerous and misleading. Horizontal comparisons across
disparate tools tend to be problematic and must be done with
care if they are to be used. For example, lines of proof or
analysis times across disparate tools are often incomparable,
since modeling a problem in the exact same way is non-trivial.
B. Recommendations to Tool Developers
Although we are still in the early days of seeing veriﬁed
cryptography deployed in the wild, one major pending chal-
lenge is how to make computer-aided cryptography artifacts
maintainable. Because computer-aided cryptography tools sit
at the bleeding-edge of how cryptography is done, they are
constantly evolving, often in non-backwards-compatible ways.
When this happens, we must either allow the artifacts (e.g.,
machine-checked proofs) to become stale, or else muster
signiﬁcant human effort to keep them up to date. Moreover,
because cryptography is a moving target, we should expect that
even veriﬁed implementations (and their proofs) will require
updates. This could be to add functionality, or in the worst
case, to swiftly patch new vulnerabilities beyond what was
veriﬁably accounted for. To this end, we hope to see more
interplay between proof engineering research [184], [185] and
computer-aided cryptography research in the coming years.
C. Recommendations to Standardization Bodies
Given its beneﬁts in the TLS 1.3 standardization effort, we
believe computer-aided cryptography should play an important
role in standardization processes [186]. Traditionally, cryp-
tographic standards are written in a combination of prose,
formulas, and pseudocode, and can change drastically be-
tween drafts. On top of getting the cryptography right in
the ﬁrst place, standards must also focus on clarity, ease of
implementation, and interoperability. Unsurprisingly, standard-
ization processes can be long and arduous. And even when
they are successful, the substantial gap between standards and
implementations leaves plenty of room for error.
Security proofs can also become a double-edged sword
in standardization processes. Proposals supported by hand-
written security arguments often cannot be reasonably audited.
A plausible claim with a proof that cannot be audited should
not be taken as higher assurance than simply stating the
claim—we believe the latter is a lesser evil, as it does not
create a false sense of security. For example, Hales [187]
discusses ill-intentioned security arguments in the context of
the Dual EC pseudo-random generator [188]. Another example
is the recent discovery of attacks against the AES-OCB2 ISO
standard, which was previously believed to be secure [189].
To address these challenges, we advocate the use of
computer-aided cryptography, not only to formally certify
compliance to standards, but also to facilitate the role of
auditors and evaluators in standardization processes, allowing
the discussion to focus on the security claims, rather than on
whether the supporting security arguments are convincing. We
see the current NIST post-quantum standardization effort [190]
as an excellent opportunity to put our recommendations into
practice, and we encourage the computer-aided cryptography
community to engage in the process.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:10:25 UTC from IEEE Xplore.  Restrictions apply. 
790
ACKNOWLEDGMENTS
We thank the anonymous reviewers for their useful sugges-
tions; Jason Gross, Boris K¨opf, Stever Kremer, Peter Schwabe,
and Alwen Tiu for feedback on earlier drafts of the paper; and
Tiago Oliveira for help setting up Jasmin and benchmarks.
Work by Manuel Barbosa was supported by National Funds
through the Portuguese Foundation for Science and Technol-
ogy (FCT) under project PTDC/CCI-INF/31698/2017. Work
by Gilles Barthe was supported by the Ofﬁce of Naval
Research (ONR) under project N00014-15-1-2750. Work by
Karthik Bhargavan was supported by the European Research
Council (ERC) under the European Union’s Horizon 2020
research and innovation programme (grant agreement no.
683032 - CIRCUS). Work by Bruno Blanchet was sup-
ported by the French National Research Agency (ANR) under
project TECAP (decision no. ANR-17-CE39-0004-03). Work
by Kevin Liao was supported by the National Science Founda-
tion (NSF) through a Graduate Research Fellowship. Work by
Bryan Parno was supported by a gift from Bosch, a fellowship
from the Alfred P. Sloan Foundation, the NSF under Grant No.
1801369, and the Department of the Navy, Ofﬁce of Naval
Research under Grant No. N00014-18-1-2892.
REFERENCES
[1] A. Delignat-Lavaud, C. Fournet, M. Kohlweiss, J. Protzenko, A. Ras-
togi, N. Swamy, S. Z. B´eguelin, K. Bhargavan, J. Pan, and J. K.
Zinzindohoue, “Implementing and proving the TLS 1.3 record layer,”
in IEEE Symposium on Security and Privacy (S&P).
IEEE Computer
Society, 2017, pp. 463–482.
[2] C. Cremers, M. Horvat, S. Scott, and T. van der Merwe, “Automated
analysis and veriﬁcation of TLS 1.3: 0-rtt, resumption and delayed
authentication,” in IEEE Symposium on Security and Privacy (S&P).
IEEE Computer Society, 2016, pp. 470–485.
[3] K. Bhargavan, B. Blanchet, and N. Kobeissi, “Veriﬁed models and
reference implementations for the TLS 1.3 standard candidate,” in IEEE
Symposium on Security and Privacy (S&P).
IEEE Computer Society,
2017, pp. 483–502.
[4] C. Cremers, M. Horvat, J. Hoyland, S. Scott, and T. van der Merwe,
“A comprehensive symbolic analysis of TLS 1.3,” in ACM Conference
on Computer and Communications Security (CCS). ACM, 2017, pp.
1773–1788.
[5] J. K. Zinzindohou´e, K. Bhargavan, J. Protzenko, and B. Beurdouche,
“HACL*: A veriﬁed modern cryptographic library,” in ACM Confer-
ence on Computer and Communications Security (CCS). ACM, 2017,
pp. 1789–1806.
[6] A. Erbsen, J. Philipoom, J. Gross, R. Sloan, and A. Chlipala, “Simple
high-level code for cryptographic arithmetic - with proofs, without
compromises,” in IEEE Symposium on Security and Privacy (S&P).
IEEE, 2019, pp. 1202–1219.
[7] J. Protzenko, B. Parno, A. Fromherz, C. Hawblitzel, M. Polubelova,
K. Bhargavan, B. Beurdouche, J. Choi, A. Delignat-Lavaud, C. Fournet,
N. Kulatova, T. Ramananandro, A. Rastogi, N. Swamy, C. Winter-
steiger, and S. Zanella-Beguelin, “EverCrypt: A fast, veriﬁed, cross-
platform cryptographic provider,” in IEEE Symposium on Security and
Privacy (S&P).
IEEE, 2020.
[8] M. Bellare and P. Rogaway, “The security of triple encryption and a
framework for code-based game-playing proofs,” in Annual Interna-
tional Conference on the Theory and Applications of Cryptographic
Techniques (EUROCRYPT), ser. LNCS, vol. 4004.
Springer, 2006,
pp. 409–426.
[9] R. Canetti, “Universally composable security: A new paradigm for
cryptographic protocols,” in IEEE Annual Symposium on Foundations
of Computer Science (FOCS).
IEEE Computer Society, 2001, pp.
136–145.
[10] S. Halevi, “A plausible approach to computer-aided cryptographic
proofs,” IACR Cryptology ePrint Archive, vol. 2005, p. 181, 2005.
[11] K. G. Paterson and G. J. Watson, “Plaintext-dependent decryption: A
formal security treatment of SSH-CTR,” in Annual International Con-
ference on the Theory and Applications of Cryptographic Techniques
(EUROCRYPT), ser. LNCS, vol. 6110. Springer, 2010, pp. 345–361.
[12] A. Boldyreva, J. P. Degabriele, K. G. Paterson, and M. Stam, “Security
of symmetric encryption in the presence of ciphertext fragmentation,”
in Annual International Conference on the Theory and Applications
of Cryptographic Techniques (EUROCRYPT), ser. LNCS, vol. 7237.
Springer, 2012, pp. 682–699.
[13] J. P. Degabriele, K. G. Paterson, and G. J. Watson, “Provable security
in the real world,” IEEE Security & Privacy, vol. 9, no. 3, pp. 33–41,
2011.
[14] V. Shoup, “Sequences of games: a tool for taming complexity in
security proofs,” IACR Cryptology ePrint Archive, vol. 2004, p. 332,
2004. [Online]. Available: http://eprint.iacr.org/2004/332
[15] Y. Lindell, “How to simulate it - A tutorial on the simulation proof
technique,” in Tutorials on the Foundations of Cryptography. Springer
International Publishing, 2017, pp. 277–346.
[16] S. F. Doghmi, J. D. Guttman, and F. J. Thayer, “Searching for shapes
in cryptographic protocols,” in International Conference on Tools and
Algorithms for the Construction and Analysis of Systems (TACAS), ser.
LNCS, vol. 4424. Springer, 2007, pp. 523–537.
[17] J. Bengtson, K. Bhargavan, C. Fournet, A. D. Gordon, and S. Maffeis,
“Reﬁnement types for secure implementations,” ACM Trans. Program.
Lang. Syst., vol. 33, no. 2, pp. 8:1–8:45, 2011.
[18] M. Backes, C. Hrit¸cu, and M. Maffei, “Union, intersection and reﬁne-
ment types and reasoning about type disjointness for secure protocol
implementations,” J. Comput. Secur., vol. 22, no. 2, pp. 301–353, Mar.
2014.
[19] S. Escobar, C. A. Meadows, and J. Meseguer, “Maude-npa: Crypto-
graphic protocol analysis modulo equational properties,” in Founda-
tions of Security Analysis and Design (FOSAD), ser. LNCS, vol. 5705.
Springer, 2007, pp. 1–50.
[20] B. Blanchet, “Modeling and verifying security protocols with the
applied pi calculus and ProVerif,” Foundations and Trends in Privacy
and Security, vol. 1, no. 1–2, pp. 1–135, Oct. 2016.
[21] K. Bhargavan, C. Fournet, A. D. Gordon, and S. Tse, “Veriﬁed inter-
operable implementations of security protocols,” ACM Transactions on
Programming Languages and Systems, vol. 31, no. 1, 2008.
[22] V. Cheval, V. Cortier, and M. Turuani, “A little more conversation,
a little less action, a lot more satisfaction: Global states in proverif,”
in IEEE Computer Security Foundations Symposium (CSF).
IEEE
Computer Society, 2018, pp. 344–358.
[23] D. L. Li and A. Tiu, “Combining proverif and automated theorem
provers for security protocol veriﬁcation,” in International Conference
on Automated Deduction (CADE), ser. LNCS, vol. 11716. Springer,
2019, pp. 354–365.
[24] M. Arapinis, E. Ritter, and M. D. Ryan, “Statverif: Veriﬁcation of
stateful processes,” in IEEE Computer Security Foundations Sympo-
sium (CSF).
IEEE Computer Society, 2011, pp. 33–47.
[25] C. J. F. Cremers, “The scyther tool: Veriﬁcation, falsiﬁcation, and anal-
ysis of security protocols,” in International Conference on Computer-
Aided Veriﬁcation (CAV), ser. LNCS, vol. 5123. Springer, 2008, pp.
414–418.
[26] S. Meier, C. J. F. Cremers, and D. A. Basin, “Strong invariants for
the efﬁcient construction of machine-checked protocol security proofs,”
in IEEE Computer Security Foundations Symposium (CSF).
IEEE
Computer Society, 2010, pp. 231–245.
[27] S. Meier, B. Schmidt, C. Cremers, and D. A. Basin, “The TAMARIN
prover for the symbolic analysis of security protocols,” in International
Conference on Computer-Aided Veriﬁcation (CAV), ser. LNCS, vol.
8044. Springer, 2013, pp. 696–701.
[28] S. Kremer and R. K¨unnemann, “Automated analysis of security proto-
cols with global state,” in IEEE Symposium on Security and Privacy
(S&P).
IEEE Computer Society, 2014, pp. 163–178.
[29] M. Turuani, “The cl-atse protocol analyser,” in International Confer-
ence on Term Rewriting and Applications (RTA), ser. LNCS, vol. 4098.
Springer, 2006, pp. 277–286.
[30] D. A. Basin, S. M¨odersheim, and L. Vigan`o, “OFMC: A symbolic
model checker for security protocols,” Int. J. Inf. Sec., vol. 4, no. 3,
pp. 181–208, 2005.
[31] A. Armando and L. Compagna, “SATMC: A sat-based model checker
for security protocols,” in European Conference on Logics in Artiﬁcial
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:10:25 UTC from IEEE Xplore.  Restrictions apply. 
791
Intelligence (JELIA), ser. LNCS, vol. 3229. Springer, 2004, pp. 730–
733.
[32] R. Chadha, V. Cheval, S¸tefan Ciobˆac˘a, and S. Kremer, “Automated
veriﬁcation of equivalence properties of cryptographic protocols,” ACM
Trans. Comput. Log., vol. 17, no. 4, pp. 23:1–23:32, 2016.
[33] V. Cheval, “APTE: an algorithm for proving trace equivalence,” in
International Conference on Tools and Algorithms for the Construction
and Analysis of Systems (TACAS), ser. LNCS, vol. 8413.
Springer,
2014, pp. 587–592.
[34] V. Cheval, S. Kremer, and I. Rakotonirina, “DEEPSEC: deciding
equivalence properties in security protocols theory and practice,” in
IEEE Symposium on Security and Privacy (S&P).
IEEE Computer
Society, 2018, pp. 529–546.
[35] V. Cortier, A. Dallon, and S. Delaune, “Sat-equiv: An efﬁcient tool
for equivalence properties,” in IEEE Computer Security Foundations
Symposium (CSF).
IEEE Computer Society, 2017, pp. 481–494.
[36] A. Tiu and J. E. Dawson, “Automating open bisimulation checking for
the spi calculus,” in IEEE Computer Security Foundations Symposium
(CSF).
IEEE Computer Society, 2010, pp. 307–321.
[37] J. K. Millen, “A necessarily parallel attack,” in In Workshop on Formal