新添加的警报(可能)是绿色的(未触发)。我们需要生成一些缓慢的请求才能看到它的运行。
请执行以下命令发送三十个请求，随机响应时间最长为一万毫秒(十秒)。
```
 1  for i in {1..30}; do
 2    DELAY=$[ $RANDOM % 10000 ]
 3    curl "http://$GD5_ADDR/demo/hello?delay=$DELAY"
 4  done
```
普罗米修斯需要一些时间来获取新的度量标准，并让警报检测到阈值已经达到。过一会儿，我们可以再次打开警报屏幕，检查警报是否确实正在触发。
```
 1  open "http://$PROM_ADDR/alerts"
```
我们可以看到警戒状态正在开火。如果不是你的情况，请再等一会儿，刷新屏幕。在我的例子中(下面的截图)，该值为 0.125，这意味着只有 12.5%的请求持续时间为 0.25 秒或更短。
There might be two or more active alerts inside `AppTooSlow` if `prometheus-server`, `prometheus-alertmanager`, or some other application is responding slow.
![](img/17e9cd6e-41dc-486b-9ee1-cfaf8eedb886.png)
Figure 3-11: Prometheus' alerts screen with one alert firing
警报是红色的，这意味着普罗米修斯将其发送给警报管理器，警报管理器又将其转发给 Slack。让我们确认一下。
```
 1  open "https://devops20.slack.com/messages/CD8QJA8DS/"
```
如您所见(截图如下)，我们收到了两个通知。由于我们将`TooManyNodes`警报的阈值恢复到三个以上的节点，而我们的集群只有更少的节点，普罗米修斯向警报管理器发送了问题已解决的通知。因此，我们在 Slack 中获得了一个新的通知。这一次，信息的颜色是绿色。
再往前，一条新的红色信息出现了，表明一个`Application is too slow`。
![](img/f8549f2d-8a88-4179-933a-57b9f13b7e5a.png)
Figure 3-12: Slack with alerts firing (red) and resolved (green) messages
我们通常不能依赖一个适用于所有应用的单一规则。例如，普罗米修斯和詹金斯将是内部应用的一个很好的候选人，我们不能期望内部应用在 0.25 秒以上的响应时间少于 5%。因此，我们可能需要进一步过滤警报。我们可以为此使用任意数量的标签。为了简单起见，我们将继续利用`ingress`标签，但是这一次，我们将使用正则表达式从警报中排除一些应用(Ingresses)。
让我们再次打开图形屏幕。
```
 1  open "http://$PROM_ADDR/graph"
```
请输入下面的表达式，按下执行按钮，切换到*图形*选项卡。
```
 1  sum(rate(
 2    nginx_ingress_controller_request_duration_seconds_bucket{
 3      le="0.25", 
 4      ingress!~"prometheus-server|jenkins"
 5    }[5m]
 6  )) 
 7  by (ingress) / 
 8  sum(rate(
 9    nginx_ingress_controller_request_duration_seconds_count{
10      ingress!~"prometheus-server|jenkins"
11    }[5m]
12  )) 
13  by (ingress)
```
对之前查询的补充是`ingress!~"prometheus-server|jenkins"`过滤器。`!~`用于选择标签与`prometheus-server|jenkins`字符串不匹配的指标。由于`|`相当于`or`声明，我们可以将该过滤器翻译为“不是`prometheus-server`或不是`jenkins`的所有内容。”我们的集群中没有詹金斯。我只是想向你展示一种排除多个值的方法。
![](img/0e6442a6-12b5-48d9-ab0c-b7da6c30abdc.png)
Figure 3-13: Prometheus graph screen with the percentage of requests with 0.25 seconds duration and the results excluding prometheus-server and jenkins
我们可以把它变得更复杂一点，并指定`ingress!~"prometheus.+|jenkins.+`作为过滤器。在这种情况下，它将排除所有以`prometheus`和`jenkins`开头的入口。关键在于`.+`的添加，在正则表达式中，匹配任何字符(`.`)的一个或多个条目(`+`)。
我们将不深入解释 RegEx 语法。我希望你已经熟悉了。如果你不是，你可能想谷歌一下或者访问*正则表达式维基*页面([https://en.wikipedia.org/wiki/Regular_expression](https://en.wikipedia.org/wiki/Regular_expression))。
前面的表达式只检索非`prometheus-server`和`jenkins`的结果。我们可能需要创建另一个只包含这两个的。
请键入下面的表达式，然后按“执行”按钮。
```
 1  sum(rate(
 2    nginx_ingress_controller_request_duration_seconds_bucket{
 3      le="0.5",
 4      ingress=~"prometheus-server|jenkins"
 5    }[5m]
 6  )) 
 7  by (ingress) /
 8  sum(rate(
 9    nginx_ingress_controller_request_duration_seconds_count{
10      ingress=~"prometheus-server|jenkins"
11    }[5m]
12  ))
13  by (ingress)
```
唯一不同的是，与之前的表达式相比，这次我们使用了`=~`运算符。它选择与提供的字符串正则匹配的标签。此外，桶(`le`)现在被设置为`0.5`秒，考虑到两个应用可能需要更多的时间来响应，我们同意这一点。
在我的例子中，图表显示`prometheus-server`有 100%的请求持续时间在 0.5 秒以内(在你的例子中，这可能不是真的)。
![](img/1a0043b8-213c-4c76-9209-2fa3a1ca851a.png)
Figure 3-14: Prometheus graph screen with the percentage of requests with 0.5 seconds duration and the results including only prometheus-server and jenkins
几个延迟示例应该足以让您使用这种类型的指标，因此我们将转向流量。
# 交通相关问题警报
到目前为止，我们测量了应用的延迟，并创建了警报，当达到基于请求持续时间的特定阈值时，就会触发警报。这些警报不是基于传入的请求数(流量)，而是基于慢速请求的百分比。只要持续时间超过阈值，即使只有一个请求进入应用，也会触发`AppTooSlow`。为了完整性，我们需要开始测量流量，或者更准确地说，测量发送到每个应用和整个系统的请求数量。通过这一点，我们可以知道我们的系统是否承受了很大的压力，并决定是扩展我们的应用、增加更多的工作人员，还是应用一些其他解决方案来缓解问题。如果请求数量达到异常数量，明确表明我们受到**拒绝服务** ( **DoS** )攻击([https://en.wikipedia.org/wiki/Denial-of-service_attack](https://en.wikipedia.org/wiki/Denial-of-service_attack))，我们甚至可能选择阻止部分传入流量。
我们将从创建一点流量开始，我们可以用它来可视化请求。
```
 1  for i in {1..100}; do
 2      curl "http://$GD5_ADDR/demo/hello"
 3  done
 4
 5  open "http://$PROM_ADDR/graph"
```
我们向`go-demo-5`应用发送了一百个请求，并打开了普罗米修斯的图形屏幕。
我们可以通过`nginx_ingress_controller_requests`检索进入入口控制器的请求数量。既然是计数器，我们可以结合`sum`继续使用`rate`功能。最后，我们可能想知道按`ingress`标签分组的请求率。
请输入下面的表达式，按下执行按钮，切换到*图形*选项卡。
```
 1  sum(rate(
 2    nginx_ingress_controller_requests[5m]
 3  ))
 4  by (ingress)
```
我们可以在图表的右侧看到一个尖峰。它显示了通过入口进入`go-demo-5`应用的同名请求。
在我的例子中(截图如下)，峰值接近每秒一个请求(你的会不同)。
![](img/713e0fd7-3d7e-414a-b4df-02526e34bb83.png)
Figure 3-15: Prometheus' graph screen with the rate of the number of requests
我们可能对应用的每个副本每秒的请求数更感兴趣，因此我们的下一个任务是找到检索该数据的方法。由于`go-demo-5`是部署，我们可以使用`kube_deployment_status_replicas`。
请键入下面的表达式，然后按“执行”按钮。
```
 1  kube_deployment_status_replicas
```
我们可以看到系统中每个部署的副本数量。`go-demo-5`应用，在我的例子中被涂成红色(截图如下)，有三个副本。
![](img/f1c0b08a-afb3-4988-87d2-d90ec102adb9.png)
Figure 3-16: Prometheus' graph screen with the number of replicas of Deployments
接下来，我们应该组合这两个表达式，以获得每个副本每秒的请求数。然而，我们面临一个问题。对于要加入的两个指标，它们需要有匹配的标签。`go-demo-5`的部署和入口都有相同的名称，因此我们可以将其用于我们的利益，假设我们可以重命名其中一个标签。我们将借助`label_join`([https://Prometheus . io/docs/Prometheus/latest/query/functions/# label _ join()](https://prometheus.io/docs/prometheus/latest/querying/functions/#label_join()))函数来实现。
For each timeseries in v, `label_join(v instant-vector, dst_label string, separator string, src_label_1 string, src_label_2 string, ...)` joins all the values of all the `src_labels` using the separator and returns the timeseries with the label `dst_label` containing the joined value.
如果之前对`label_join`函数的解释令人困惑，那么你并不孤单。相反，让我们通过添加包含来自`deployment`标签的值的`ingress`标签来完成转换`kube_deployment_status_replicas`的示例。如果我们成功了，我们将能够把结果与`nginx_ingress_controller_requests`结合起来，因为两者将具有相同的匹配标签(`ingress`)。
请键入下面的表达式，然后按“执行”按钮。
```
 1  label_join(
 2    kube_deployment_status_replicas,
 3    "ingress", 
 4    ",", 
 5    "deployment"
 6  )
```
由于我们这次主要对标签的值感兴趣，请通过单击选项卡切换到控制台视图。
从输出中可以看到，每个指标现在都包含一个额外的标签`ingress`，其值与`deployment`相同。
![](img/d8145093-7933-49c7-9fdf-65a9fcf30124.png)
Figure 3-17: Prometheus' console view of Deployment replicas status and a new label ingress created from the deployment label
现在我们可以将这两个指标结合起来。
请键入下面的表达式，然后按“执行”按钮。
```
 1  sum(rate(
 2    nginx_ingress_controller_requests[5m]
 3  ))
 4  by (ingress) /
 5  sum(label_join(
 6    kube_deployment_status_replicas,
 7    "ingress",
 8    ",",
 9    "deployment"
10  ))
11  by (ingress)
```
切换回*图形*视图。
我们计算了每个应用的请求数量的比率(`ingress`)并将其除以每个应用的副本总数(`ingress`)。最终结果是每个应用(`ingress`)和每个副本的请求数量比率。
值得注意的是，我们无法检索每个特定副本的请求数量，而是检索每个副本的平均请求数量。考虑到 Kubernetes 网络在大多数情况下会执行循环调度，导致向每个副本发送或多或少相同数量的请求，因此这种方法应该有效。
总而言之，现在我们知道了副本每秒接收多少请求。
![](img/d4f2cc20-dd55-4a80-af2a-177918f74576.png)
Figure 3-18: Prometheus' graph screen with the rate of requests divided by the number of Deployment replicas
既然我们已经学习了如何编写一个表达式来检索每个副本每秒的请求数，我们应该将其转换为一个警报。
因此，让我们来看看普罗米修斯图表值的新旧定义之间的区别。
```
 1  diff mon/prom-values-latency.yml \
 2      mon/prom-values-latency2.yml
```
输出如下。
```
62a63,69
> - alert: TooManyRequests
>   expr: sum(rate(nginx_ingress_controller_requests[5m])) by (ingress) / sum(label_join(kube_deployment_status_replicas, "ingress", ",", "deployment")) by (ingress) > 0.1
>   labels:
>     severity: notify
>   annotations: