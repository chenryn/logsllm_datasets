is by itself. Note that bucket 5 is also pure with Z by itself, and
is signaled by a count of -1. Decoding proceeds by ﬁrst deleting
either V or Z, and then iterating until no pure cells remain.
Into how many cells should each element be hashed? We refer
to this parameter as the hash_count. If the hash_count is
too small, say 1, then there will be a high probability of ﬁnding
pure cells initially, but once a pure element has been recorded and
removed there are no other cells from which to remove it. Thus,
two or more keys that have been hashed into the same cell cannot
be decoded. On the other hand, if hash_count is too big, it
is unlikely that there will be a pure element by itself to begin the
process. We will show that hash_count values of 3 or 4 work
well in practice.
Encode. First, assume that we have an oracle which, given SA
and SB, returns the size of the set difference, d. We will describe
the construction of such an oracle in Section 3.2. We allocate an
IBF, which consists of a table B with n = αd cells, where α ≥ 1.
Each cell of the table contains three ﬁelds (idSum, hashSum and
count) all initialized to zero.
Additionally, hosts agree on two hash functions, Hc and Hk, that
map elements in U uniformly into the space [0, h), where h ≤ u.
Additionally, they agree on a value, k, called the hash_count
which is the number of times each element is hashed. The algo-
rithm for encoding a set S into an IBF is given in Algorithm 1 and
illustrated in Figure 1. For each element in S, we generate k dis-
tinct random indices into B. To do this we recursively call Hk()
with an initial input of si and take the modulus by n until k dis-
tinct indices have been generated. More simply, an implementation
could choose to use k independent hash functions. Regardless, for
each index j returned, we XOR si into B[j].idSum, XOR Hc(si)
into B[j].hashSum, and increment B[j].count.
Algorithm 1 IBF Encode
for si ∈ S do
for j in HashToDistinctIndices(si, k, n) do
B[j].idSum = B[j].idSum ⊕si
B[j].hashSum = B[j].hashSum ⊕Hc(si)
B[j].count = B[j].count + 1
Subtract. For each index i in two IBF’s, B1 and B2, we subtract
B2[i] from B1[i]. Subtraction can be done in place by writing the
resulting values back to B1, or non-destructively by writing values
V
X
Y
V
W
X
idSum:
hashSum:
count:
V + X + Y
V + W + X
H(V)+H(X)+H(Y)
H(V)+H(W)+H(X)
3
3
B2=
idSum:
hashSum:
count:
B3= B1 - B2
W
Z
W + Z
H(W) + H(Z)
2
W
V
X
Z
Y
Y
H(Y)
1
Y
V
X
X
X
H(X)
1
Z
Z
H(Z)
1
X
Z
idSum:
hashSum:
count:
V + X
V + X + Z
X + Z
H(V) + H(X)
H(V)+H(X)+H(Z)
H(X) + H(Z)
2
1
0
V
W
Y
W
Y
V + W + Y
W + Y
H(V)+H(W)+H(Y)
H(W) + H(Y)
3
2
W
Y
Z
W
Y
W + Y
W + Y + Z
H(W) + H(Y)
H(W)+H(Y)+H(Z)
2
3
W
Y
V
V
H(V)
1
W
Y
Z
Z
H(Z)
-1
Figure 2: IBF Subtract. IBF B3 results from subtracting IBF
B2 from IBF B1 cell by cell. To subtract cells, the idSum and
hashSum ﬁelds are XOR’ed, and count ﬁelds are subtracted.
The elements common to B1 and B2 (shown shaded) are can-
celled during the XOR operation.
to a new IBF of the same size. We present a non-destructive version
in Algorithm 2. Intuitively, this operation eliminates common ele-
ments from the resulting IBF as they cancel from the idSum and
hashSum ﬁelds as shown in Figure 2.
Algorithm 2 IBF Subtract (B3 = B1 − B2)
for i in 0, . . . , n − 1 do
B3[i].idSum = B1[i].idSum ⊕B2[i].idSum
B3[i].hashSum = B1[i].hashSum ⊕B2[i].hashSum
B3[i].count = B1[i].count- B2[i].count
Decode. We have seen that to decode an IBF, we must recover
“pure” cells from the IBF’s table. Pure cells are those whose idSum
matches the value of an element s in the set difference. In order to
verify that a cell is pure, it must satisfy two conditions: the count
ﬁeld must be either 1 or -1, and the hashSum ﬁeld must equal
Hc(idSum). For example, if a cell is pure, then the sign of the
count ﬁeld is used to determine which set s is unique to. If the
IBF is the result of subtracting the IBF for SB from the IBF for
SA, then a positive count indicates s ∈ DA−B, while a negative
count indicates s ∈ DB−A.
Decoding begins by scanning the table and creating a list of
all pure cells. For each pure cell in the list, we add the value
s =idSum to the appropriate output set (DA−B or DB−A) and re-
move s from the table. The process of removal is similar to that of
insertion. We compute the list of distinct indices where s is present,
then decrement count and XOR the idSum and hashSum by s
and Hc(s), respectively. If any of these cells becomes pure after s
is removed, we add its index to the list of pure cells.
Decoding continues until no indices remain in the list of pure
cells. At this point, if all cells in the table have been cleared (i.e. all
Algorithm 3 IBF Decode (B → DA−B, DB−A)
for i = 0 to n − 1 do
if B[i] is pure then
Add i to pureList
while pureList 6= ∅ do
i=pureList.dequeue()
if B[i] is not pure then
continue
s=B[i].idSum
c=B[i].count
if c > 0 then
add s to DA−B
else
add s to DB−A
for j in DistinctIndices(s, k, n) do
B[j].idSum = B[j].idSum ⊕s
B[j].hashSum = B[j].hashSum ⊕Hc(s)
B[j].count = B[j].count- c
for i = 0 to n − 1 do
if B[i].idSum 6= 0 OR B[i].hashSum 6= 0 B[i].count 6= 0
then
return FAIL
return SUCCESS
ﬁelds have value equal to zero), then the decoding process has suc-
cessfully recovered all elements in the set difference. Otherwise,
some number of elements remain encoded in the table, but insufﬁ-
cient information is available to recover them. The pseudocode is
given in Algorithm 3 and illustrated in Figure 3.
3.2 Strata Estimator
To use an IBF effectively, we must determine the approximate
size of the set difference, d, since approximately 1.5d cells are re-
quired to successfully decode the IBF. We now show how to es-
timate d using O(log(u)) data words, where u is the size of the
universe of set values. If the set difference is large, estimators such
as random samples [14] and Min-wise Hashing [3, 4] will work
well. However, we desire an estimator that can accurately estimate
very small differences (say 10) even when the set sizes are large
(say million).
Flajolet and Martin (FM) [12] give an elegant way to estimate
set sizes (not differences) using log(u) bits. Each bit i in the esti-
mator is the result of sampling the set with probability 1/2i; bit i
is set to 1, if at least 1 element is sampled when sampling with this
probability. Intuitively, if there are 24 = 16 distinct values in the
set, then when sampling with probability 1/16, it is likely that bit
4 will be set. Thus the estimator returns 2I as the set size, where I
is the highest strata (i.e., bit) such that bit I is set.
While FM data structures are useful in estimating the size of two
sets, they do not help in estimating the size of the difference as
they contain no information that can be used to approximate which
elements are common. However, we can sample the set difference
using the same technique as FM. Given that IBF’s can compute set
differences with small space, we use a hierarchy of IBF’s as strata.
Thus Peer A computes a logarithmic number of IBF’s (strata), each
of some small ﬁxed size, say 80 cells.
Compared to the FM estimator for set sizes, this is very expen-
sive. Using 32 strata of 80 cells is around 32 Kbytes but is the only
estimator we know that is accurate at very small set differences and
yet can handle set difference sizes up to 232. In practice, we build
a lower overhead composite estimator that eliminates higher strata
and replaces them with a MinWise estimator, which is more accu-
rate for large differences. Note that 32 Kbytes is still inexpensive
when compared to the overhead of naively sending a million keys.
Proceeding formally, we stratify U into L = log(u) partitions,
P0, . . . , PL, such that the range of the ith partition covers 1/2i+1
of U. For a set, S, we encode the elements of S that fall into par-
tition Pi into the ith IBF of the Strata Estimator. Partitioning U
can be easily accomplished by assigning each element to the par-
tition corresponding to the number of trailing zeros in its binary
representation.
A host then transmits the Strata Estimator for its set to its remote
peer. For each IBF in the Strata Estimator, beginning at stratum
L and progressing toward stratum 0, the receiving host subtracts
the corresponding remote IBF from the local IBF, then attempts to
decode. For each successful decoding, the host adds the number
of recovered elements to a counter. If the pair of IBF’s at index i
fails to decode, then we estimate that the size of the set difference
is the value of the counter (the total number of elements recovered)
scaled by 2i+1. We give the pseudocode in Algorithms 4 and 5.
We originally designed the strata estimator by starting with stra-
tum 0 and ﬁnding the ﬁrst value of i ≥ 0 which decoded success-
fully, following the Flajolet-Martin strategy and scaling the amount
recovered by 2i. However, the estimator in the pseudocode is much
better because it uses information in all strata that decode success-
fully and not just the lowest such strata.
In the description, we assumed that the elements in SA and SB
were uniformly distributed throughout U. If this condition does not
hold, the partitions formed by counting the number of low-order
zero bits may skew the size of our partitions such that strata i does
not hold roughly |S|/2i+1. This can be easily solved by choosing
some hash function, Hz, and inserting each element, s, into the IBF
corresponding to the number of trailing zeros in Hz(s).
Algorithm 4 Strata Estimator Encode using hash function Hz
for s ∈ S do
i = Number of trailing zeros in Hz(s).
Insert s into the i-th IBF
Algorithm 5 Strata Estimator Decode
count = 0
for i = log(u) down to −1 do
if i < 0 or IBF1[i] − IBF2[i] does not decode then
return 2i+1× count
count += number of elements in IBF1[i] − IBF2[i]
The obvious way to combine the Strata Estimator and IBF is to
have node A request an estimator from node B, use it to estimate
d, then request an IBF of size O(d). This would take two rounds
or at least two round trip delays. A simple trick is to instead have
A initiate the process by sending its own estimator to B. After B
receives the Strata Estimator from A, it estimates d and replies with
an IBF, resulting in one round to compute the set difference.
4. ANALYSIS
In this section we review and prove theoretical results concerning
the efﬁciency of IBF’s and our stratiﬁed sampling scheme.
THEOREM 1. Let S and T be disjoint sets with d total elements,
and let B be an invertible Bloom ﬁlter with C = (k + 1)d cells,
where k = hash_count is the number of random hash functions in
B, and with at least Ω(k log d) bits in each hashSum ﬁeld. Suppose
that (starting from a Bloom ﬁlter representing the empty set) each
Step 1: Initial Scan
Step 2: Record
V
X
Z
V
X
X
Z
V + X
V + X + Z
X + Z
V
V
H(V) + H(X)
H(V)+H(X)+H(Z)
H(X) + H(Z)
H(V)
idSum:
hashSum:
count:
Index:
2
0
1
1
X
Z
X
X
idSum:
hashSum:
count:
Index:
X + Z
X + Z
H(X)
H(X) + H(Z)
H(X) + H(Z)
1
0
0
1
0
2
Pure:
DA-B:
DB-A:
{3, 4}
{}
{}
Z
Z
H(Z)
-1
4
Pure:
DA-B:
DB-A:
{4, 0}
{V}
{}
Z
Z
H(Z)
-1
4
1
3
0
0
0
3
0
2
X
Z
V
X
Z
V
X
X
Z
V + X
V + X + Z