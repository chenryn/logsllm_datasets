k such that
• Local fractional ofﬂine (LFA ofﬂine): in each interval i we
determine the trafﬁc allocation t[i]
k ) is
minimized. This essentially minimizes the total cost assum-
ing that the cost is a function of the trafﬁc in the current in-
terval (instead of based on qk percentile trafﬁc volume). To
determine the optimal allocation, we apply the dynamic pro-
gramming algorithm described in Section 4.2, which takes
the total trafﬁc in the current interval as input to derive an
allocation that leads to the minimum cost.
k ck(t[i]
(cid:80)
• Dedicated links: in today’s market there is an option to pur-
chase dedicated links besides burstable links. Dedicated links
have ﬂat rates which are independent of usage, even when the
assigned trafﬁc is 0.
We derive the cost of a burstable link based on the 95th-percentile
charging model throughout our evaluation. For a given trace, we
determine the cost of using dedicated links by ﬁnding the cheap-
est set of links whose total capacity can accommodate the maximal
load in the current charging period.
We start our evaluation by considering simple pricing functions:
the price of an ISP link is a constant value if the charging volume is
greater than 0, and the value is one of the entries shown in Table 1.
In our ﬁrst experiment, we consider a user with 4 links connected
to the Internet. We randomly pick 4 burstable links from the ten
links shown in Table 1 with the corresponding capacity constraints.
We allow duplicates, since it is possible to have multiple links of
the same type. Figure 11 shows the normalized cost achieved us-
ing different trafﬁc assignment algorithms across 5 sets of traces.
Here normalized cost is deﬁned as the ratio between the cost of a
burstable link based on a speciﬁc trafﬁc assignment algorithm and
that of using the dedicated links. Note that except for GIA-online,
all of the algorithms are ofﬂine algorithms; thus they know trafﬁc
patterns in advance.
We make the following observations. First, as expected, GFA-
ofﬂine yields the best performance. GIA-online incurs a moder-
ately higher cost than its ofﬂine version due to prediction errors.
Figure 12: Comparison of the total cost across different traces,
where each user has 4 links to the Internet, and each link’s cost
is a piece-wise linear function of trafﬁc volume as shown in Fig-
ure 2.
Nevertheless, it is still able to yield cost comparable to (and of-
ten slightly lower than) LFA-ofﬂine, and much lower cost than
the round robin and equal split. Second, we observe that apply-
ing GFA-ofﬂine, GIA-online or LFA-ofﬂine to burstable links can
result in lower cost than using dedicated links. On the other hand,
applying round robin or equal split to burstable links can incur sig-
niﬁcantly higher cost than using dedicated links. Finally, we ob-
serve that the relative ranking among these algorithms remains the
same as the charging period changes from one week to one month.
We next use the more complex pricing functions, described in
Section 3, to evaluate the robustness of our algorithms to vary-
ing pricing functions. Figure 12 summarizes the results. We ob-
serve that GFA-ofﬂine continues to perform the best.
Its online
version performs slightly worse due to prediction errors, but still
out-performs the other algorithms.
Next, we study the impact of varying the number of available
links. Figure 13 shows the cost as we vary the number of links
from 2 to 15. As before, GFA-ofﬂine yields the best performance,
with GIA-online closely following it. We observe that the normal-
ized cost of GFA-ofﬂine and GIA-online tend to decrease with the
number of available links. This is because they can burst ISPs at
their full capacities during peak load without incurring additional
cost. In comparison, we observe that the normalized costs of the
round robin, equal split, and LIA-ofﬂine algorithms increase with
the number of links.
Finally, we look at the dynamics of cost over time. Figure 14
plots how cost varies over a period of 13 weeks, where the charg-
ing period is one week. As shown, GFA-ofﬂine and GIA-online
perform signiﬁcantly better than the other three algorithms. Since
the normalized costs of GFA-ofﬂine and GIA-online are often much
lower than 1, the cost of using these algorithms on burstable links is
signiﬁcantly lower compared with using dedicated links. We also
observe that GFA-online can sometimes outperform GFA-ofﬂine,
e.g., week 4 in Figure 14 (b). This is because GFA-ofﬂine is not
guaranteed to be optimal when there are capacity constraints.
00.511.522.53Red HatMITUCLAWisconsinWeb ServerNormalized costGFA offlineGIA onlineround robinequalLFA offline00.40.81.21.62Red HatMITUCLAWisconsinWeb ServerNormalized costGFA offlineGIA onlineround robinequalLFA offline00.511.522.53Red HatMITUCLAWisconsinWeb ServerNormalized costGFA offlineGIA onlineround robinequalLFA offline00.20.40.60.811.21.41.6Red HatMITUCLAWisconsinWeb ServerNormalized costGFA offlineGIA onlineround robinequalLFA offline(a) Red Hat Inc.
(b) University of Wisconsin, Madison
(c) Web server
Figure 13: Comparison of cost among different routing schemes using piece-wise linear pricing functions shown in Figure 2.
(a) Red Hat Inc.
(b) University of Wisconsin, Madison
(c) Web server
Figure 14: Time series plots of cost across different traces, where each user has 4 links to the Internet, and each link’s cost is a
piece-wise linear function of its charging volume shown in Figure 2.
Summary: Our evaluation results show that the GFA-ofﬂine al-
gorithm achieves the lowest cost, as we expect. Moreover, its on-
line version is also competitive despite ﬂuctuations in trafﬁc — it
is often able to out-perform the other alternatives by a signiﬁcant
amount.
6.2 Evaluation of Performance Optimization
Under Cost Constraints
Next we evaluate latency optimization under cost constraints. In
this section, we mainly focus on evaluating our online algorithm in
the presence of realistic RTT variations in the Internet. In the next
section, we will further examine the performance of smart routing
when multiple users interact with each other.
To evaluate the performance beneﬁts of smart routing for a given
trafﬁc demand trace, we would ideally use round-trip time (RTT)
measurements between the sources and destinations in the traf-
ﬁc traces during the period of trace collection. Due to a lack of
such measurement data, we use the measurements published by
NLANR [16] for our evaluation. The NLANR traces consist of
RTT measurements between pairs of 140 universities from Oct.
2003 to Jan. 2004. In order to get the delay for a ﬂow in the trafﬁc
trace, we ﬁrst construct virtual ISPs in the following way. We map
ISPs from the Rocketfuel dataset [22] to a set of universities by as-
signing each of their nodes to the geographically closest university
in the NLANR trace. In addition, we map the origin of each of our
Abilene traces to the closest university in the NLANR trace. Us-
ing a database from CAIDA’s NetGeo project, we obtain physical
coordinates for each destination preﬁx in our Abilene traces. We
map each preﬁx to the closest node of each ISP. The delay through
a given ISP from origin to preﬁx is then assigned to be the RTT be-
tween the universities in the NLANR trace representing the origin
and the node of the ISP assigned to the preﬁx. We also add a last
hop delay based on the speed of light and the distance between a
preﬁx and its ISP node. In this way, we obtain delay traces reﬂect-
ing realistic Internet RTT variations and geographically correlated
performance variations across ISPs.
Note that the delay traces from NLANR are mostly between
hosts within the US, so we ﬁlter out trafﬁc with destination preﬁxes
that are outside the US. Such ﬁltering reduces trafﬁc by 20% - 60%,
and increases trafﬁc variability (due to smaller aggregation). This
increased variability will further stress-test our online algorithms.
Figure 15 compares the cost and performance of different routing
schemes, where the cost in Figure 15 (a) is normalized by the cost
of the ofﬂine cost optimization scheme. We make the following
observations.
First, comparing the three ofﬂine schemes, we observe that opti-
mizing performance alone increases cost by up to a factor of 2.75
compared with optimizing cost alone, whereas optimizing cost alone
increases latency by up to 33% compared with the performance op-
timal. In contrast, the ofﬂine cost-performance scheme achieves the
best of both worlds: it yields low cost and low latency.
Second, comparing the ofﬂine schemes with their corresponding
online versions, we observe that the online versions incur higher
cost due to prediction errors. Note that the cost differences between
the ofﬂine and online versions are larger than those in the previous
sections, because here we ﬁlter out a signiﬁcant amount of non-
US trafﬁc and thus increase variability. Nevertheless, the online
cost-performance optimization yields much lower cost than opti-
mizing performance alone, while achieving similar latency (within
10-20%).
Figure 16 further compares the latency of different schemes us-
ing time series plots. As it shows, in most cases the latency achieved
using the online cost-performance scheme follows that of the of-
ﬂine performance optimization scheme. This suggests that the on-
line cost-performance algorithm can effectively track variations in
latency and trafﬁc volume. Sometimes its latency is noticeably
higher than pure performance optimization. This is due to the cost
constraints, and indicates that there is a trade-off between optimiz-
ing cost versus optimizing performance. But the performance dif-
ference between the two is usually small (below 10%). When com-
pared with optimizing cost alone, the online cost-performance al-
gorithm often avoids delay spikes that pure cost-optimization can
produce.
012345678246810121416Normalized cost# available linksGFA offlineGIA onlineRound robinEqualLIA offline012345678246810121416Normalized cost# available linksGFA offlineGIA onlineRound robinEqualLIA offline0123456246810121416Normalized cost# available linksGFA offlineGIA onlineRound robinEqualLIA offline00.511.522.533.5024681012Normalized costWeekGFA offlineGIA onlineRound robinEqualLIA offline00.511.522.533.5024681012Normalized costWeekGFA offlineGIA onlineRound robinEqualLIA offline00.511.522.533.5024681012Normalized costWeekGFA offlineGIA onlineRound robinEqualLIA offline(a) Red Hat Inc. (AS 22753)
(b) UCLA (AS 52)
(c) National Library of Medicine (AS 70)
Figure 16: Performance comparison of different routing schemes.
4 ASes (to simulate ISPs) in the United States from the Rocket-
fuel data to construct a network topology of over 170 nodes and
600 edges. For each intra-domain link, we use the inferred OSPF
weight and propagation delay from the data; for each peering link,
we use the estimated propagation delay from the data. Once a user
selects an ISP, its inter-domain route is determined based on the
shortest AS hop count, and its intra-domain route follows the short-
est OSPF path. Since the Rocketfuel data do not contain link band-
width, we set the peering links to be OC3 (155 Mbps) and intra-
domain links to be OC12 (622 Mbps). We use the M/M/1 latency
function (i.e., l(x) = 1
µ−x + prop, where l(x) is the latency for
trafﬁc load of x, µ is the link capacity, and prop is the propagation
delay) for all links in the network to capture the effect of trafﬁc load
on link latency.
We evaluate smart routing by connecting users to a varying num-
ber of ASes in the topology. For each smart routing user, its ﬁrst-
hop nodes in different ASes are geographically co-located. Further,
we create trafﬁc demands for each user using one of the nine Abi-
lene traces described in Section 6. During each time interval, we
select the top 100 destination preﬁxes in the traces, which account
for over 90% trafﬁc, and randomly map them to nodes in the sim-
ulation topology. The user sends trafﬁc to the destination nodes at
the trafﬁc rate speciﬁed by the trace.
During every 5-minute time interval, we derive the latency un-
der different routing schemes by computing the trafﬁc equilibria
based on the current topology and trafﬁc demands using the ap-
proach in [20].
7.2 Smart Routing with Self-Interference
We start with an evaluation on the effects of self-interference.
The online smart routing algorithm described in Section 5 assumes
that trafﬁc assignment would not affect link latency. If this is not
the case (i.e., the latency of a link depends on trafﬁc assignment),
the above algorithm results in selﬁsh routing, since each ﬂow is
routed without considering its effects on other ﬂows. In contrast,
to optimize the total latency of all ﬂows, a smart routing algorithm
ideally needs to explicitly take into account this self-interference,
and route trafﬁc cooperatively to minimize the overall latency. As
shown in [13, 23], the theoretical worst case performance differ-
ence between cooperative routing and selﬁsh routing at trafﬁc equi-
libria3 can be quite large. Below we quantify the difference through
simulations, and show that the impact of self-interference is small.
In our evaluations, the smart routing user has 4 ISPs and the
burstable links to the ISPs are randomly selected from Table 1; the
topology and real trafﬁc traces are described in Section 7.1. In the
interest of clarity, throughout this section we plot the results for
only a small number of time intervals. The results for other time
periods are consistent.
3A trafﬁc equilibrium is deﬁned as a state in which no trafﬁc can
improve its latency by unilaterally changing its link assignment.
We adopt the approach in [20] to compute trafﬁc equilibria.
(a) Comparison of total cost
(b) Comparison of performance
Figure 15: Comparisons of the total cost and performance
across different traces during four weeks, where each user has
4 links to the Internet, and each link’s cost is a piece-wise linear
pricing function shown in Figure 2 based on a one-week charg-
ing period.
7. GLOBAL EFFECTS OF SMART
ROUTING
In the preceding sections, we have investigated how an individual
user can use smart routing to optimize cost and performance. Such
optimization is selﬁsh, since an individual user tries to optimize its
own metrics without considering its impacts on other trafﬁc. More-
over, the trafﬁc of an individual user may self-interfere if trafﬁc
assignment may change link latency. Therefore, a comprehensive
evaluation on the global effects of smart routing should address the
following issues: (i) how well the smart routing algorithms perform
when trafﬁc assignment can affect link latency; (ii) how well dif-
ferent smart routing users co-exist; and (iii) how well smart routing
users co-exist with single-homed users whose routing is controlled
by the network. Below we investigate these issues, focusing on the
performance at trafﬁc equilibria.
7.1 Evaluation Methodology
Our topology is constructed using the Rocketfuel inter-domain
topology data [22]. To make our simulations scalable, we select
 30 40 50 60 70 80 90 100 110 120 4860 4890 4920 4950 4980 5010Average latency (ms)Time interval (5 minutes)online costoffline costonline cost+perfoffline cost+perfoffline perf 55 60 65 70 75 80 85 1650 1700 1750 1800 1850Average latency (ms)Time interval (5 minutes)online costoffline costonline cost+perfoffline cost+perfoffline perf 20 30 40 50 60 70 80 90 100 3680 3700 3720 3740 3760 3780Average latency (ms)Time interval (5 minutes)online costoffline costonline cost+perfoffline cost+perfoffline perf00.511.522.5317012275335259662970ASCost normalized by offline cost offline costoffline cost+perfonline costonline cost+perfoffline perf01020304050607017012275335259662970ASAverage Latency (ms)offline costoffline cost+perfonline costonline cost+perfoffline perf(a) Red Hat Inc.
(a) User latency
(b) University of Wisconsin, Madison
Figure 17: Evaluation of the effects of self-interference.
Figure 17 compares the latency of optimal routing versus that
of smart routing at trafﬁc equilibria, with and without enforcing
the cost constraints. When there are no cost constraints, link ca-
pacities are always equal to their raw bandwidth; and when there
are cost constraints, link capacities are equal to their pseudo ca-
pacities during the interval. We observe that under the same cost
constraint, smart routing and optimal routing achieve similar la-
tency. This suggests that ignoring self-interference incurs little per-
formance penalty. In addition, removing the cost constraint yields
slightly lower latency. This is consistent with the results in Sec-
tion 6, which show that there is a trade-off between optimizing cost
versus optimizing performance, but the trade-off is usually small.
7.3 Evaluation of Smart Routing in a Global
Setting
Having established the robustness of our smart routing algorithms
against self-interference, we next evaluate smart routing when there
are multiple users.
7.3.1 Performance Beneﬁts of Smart Routing
We start by studying the performance beneﬁts of smart routing
in the presence of other trafﬁc. In our ﬁrst experiment, we have 3
users generating trafﬁc, where user 1 is a smart routing user sub-
scribing to a varying number of ISPs, and users 2 and 3 are both
single-homed. We observe that user 1 improves its performance by
10% when it changes from using one ISP to two ISPs, and further
improves its performance by 8% when it uses four ISPs.
In our second experiment, we scale up the trafﬁc by a factor of
3 to examine how smart routing performs in a highly utilized net-
work. Figure 18 (a) shows the latency of the smart routing user over
100 time intervals. We observe that when user 1 changes from us-
ing one ISP to two ISPs, its performance is improved by 19%; when
the number of ISPs increases to four, a further improvement of 9%
is achieved. Smart routing achieves higher performance beneﬁts
under higher load, since it is able to route around network conges-
tion whereas single-homed trafﬁc follows a ﬁxed path.
In addition, as shown in Figure 18 (b), increasing the number of
ISPs also helps to reduce maximum link utilization. In particular,
we observe a 12% reduction when user 1 changes from subscribing
(b) Maximum link utilization
Figure 18: Performance beneﬁt of smart routing when the la-