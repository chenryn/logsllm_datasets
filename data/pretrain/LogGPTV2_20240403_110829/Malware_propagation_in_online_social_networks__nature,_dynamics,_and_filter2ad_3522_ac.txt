graph formed from the user friendships and activity events
generated by each user. In addition to BrightKite users, we
also simulate the BrightKite server, which keeps messages
until they are fetched by the recipients.
In the simulation, when the machine used by a client is
infected, it sends a message embedded with a URL that
points to a malware server that hosts the malicious code to
each of the client’s friends in the social graph. The message
is ﬁrst delivered to the online social network server after an
end-to-end delay drawn from distribution D; on the arrival
of the message, the server keeps the message locally until it
is fetched by the recipient.
A client’s machine becomes online whenever there is an
activity event in the BrightKite dataset. When it becomes
online, it sends a request to the online social network server
and the server sends back a list of messages that are des-
tined to the client. The end-to-end delay that a message
experiences is also generated from distribution D. When a
client receives a list of incoming messages, if there is a URL
link in it, she clicks on it with probability p. The think-
ing time before clicking on it follows distribution T . After a
client clicks on a malicious URL, a request is sent to the mal-
ware server, which in return sends back the malware code.
The end-to-end delay between the client’s machine and the
malware server is also randomly drawn from distribution D.
The transmission delay of the malware code by the malware
server is drawn from distribution R. When the malware
code arrives at the client machine, if it is not infected yet,
the machine gets infected and the above process repeats.
The propagation model we described above is essentially
the classical SI (Susceptible-Infective) model. It is worthy
noting the diﬀerence between it and the SIR (Susceptible-
Infective-Removed) which takes into cosideration node re-
covery from an infected state in the context of online social
Figure 7: Number of activity events vs. node degree
Y = fyigi=1;:::;n, where yi denote the number of activity
events generated by user i. The correlation coeﬃcient is
deﬁned as follows:
∑
n
i=1(xi (cid:0) ¯X)(yi (cid:0) ¯Y )
∑
∑
c(X; Y ) =
[
n
i=1(xi (cid:0) ¯X)2]1=2[
n
i=1(yi (cid:0) ¯Y )2]1=2
;
where ¯X and ¯Y are the mean of X and Y , respectively. If
c(X; Y ) > 0, X and Y are positively related; if c(X; Y ) < 0,
X and Y are negatively correlated; otherwise, there is no
correlation between X and Y . If jc(X; Y )j is closer to 1, the
correlation between X and Y is stronger and jc(X; Y )j = 1
means that X and Y have an exact linear relationship.
For the BrightKite dataset, we ﬁnd that the correlation
coeﬃcient between X and Y is 0.3809, which is positive
but much smaller than 1. Hence, the number of friends a
BrightKite user has is positively correlated with how active
he is in the network, although only in a weak sense. This
observation may aﬀect the design of intelligent malware. For
instance, if a malware aims to evade detection by limiting
the number of messages it generates in the network [37], it
may want to let each infected machine contact only a small
number of neighbors (or friends). As the number of friends
a user has is only weakly correlated with his online activity
intensity, attempting to infect the most popular neighbors
may not always be a wise decision.
4. TRACE-DRIVEN SIMULATION
In the previous section, we have statically analyzed the
BrightKite dataset from both friendship and activity per-
spectives. Although such analysis sheds light on implications
of structural and behavioral properties on malware propa-
gation in online social networks, we are still unclear on the
dynamics of malware propagation in online social networks,
such as how long it takes to infect the majority of the vulner-
able population. Answers to such questions are instrumental
200
1001011021031041    296  1811 5493 Rank (log scale)                                  c = 0.341927, a= 2.211, b = 24.879R2 = 0.974326                    100101102103104data in log−yc scaleSE model fitdata in log−log scale 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 100 200 300 400 500 600CCDFNumber of days 0 500 1000 1500 2000 2500 3000 3500 4000 4500 5000 0 100 200 300 400 500 600Number of users with activity eventsDay Id 0 500 1000 1500 2000 2500 3000 3500 4000 0 50 100 150 200 250 300 350 400Number of activity eventsDegreenetwork worms. For traditional Internet worms like Code
Red [8] and Slammer [29], machines infected by these worms
often perform scanning continuously to look for new vulner-
able machines for infection. Hence, cleaning these infected
machines into a healthy state slows down malware propaga-
tion, as it leads to fewer infective machines that search for
new victims. By contrast, malware propagation in online so-
cial networks uses a diﬀerent approach for spreading: when
a user account is compromised, a malicious message is sent
(or broadcast) to each of her friends, irrespective of whether
her friends are online or not. In our work, we do not consider
that cleaned nodes are reinfected and then send malicious
links again. Consequently, whether an infected machine is
cleaned or not later, it will not change the course of mal-
ware propagation any more. Given these observations, we
adopt the simple SI model ﬁrst when we study the propaga-
tion dynamics of online social network worms in Section 5
as the SIR model would only change the total number of
infectives in the network but not the dynamics of the mal-
ware propagation process. In Section 6, we shall continue
to study approaches that combine both the SIR model and
some warning mechanisms to slow down worm propagation
in online social networks.
5. PROPAGATION DYNAMICS
In this section, we use trace-driven simulation to study the
impact of initial infection, user click probability, social graph
structures, and activity patterns on malware propagation.
We choose end-to-end delays form the empirical distribution
of packet delays collected from traces by CAIDA [4]. The
thinking time T before a user clicks on a URL (or decides
not to) is drawn from a normal distribution with both mean
and standard deviation as 10 seconds, and the transmission
delay of the malware code is uniformly distributed between
5 and 15 seconds. Although these assumptions may not
reﬂect real network conditions, they pose little impact on
the propagation dynamics of online social network malware
because their time scales are much smaller than those of
BrightKite users’ activity events. For a similar reason, we
ignore normal user messages.
5.1 Initial Infection
We ﬁrst analyze the eﬀect of initial infection on the prop-
agation dynamics. In all the experiments, we assume that
each user clicks on an embedded URL with probability 0.5.
We choose the initial infection as follows: we divide all the
users in the BrightKite dataset into k groups, where users
in group i (0 (cid:20) i (cid:20) k (cid:0) 1) have [2i; 2i+1) outbound friends.
From each group, we randomly choose 50 users as the initial
infection point (if there are less than 50 users in a group,
we simply choose all the users). For each infection point, we
simulate malware propagation 20 times with diﬀerent seeds
to generate random numbers. In total, we have 10,200 sam-
ple runs spread over 13 groups.
Figure 8 depicts the number of infections after one day,
one week, one month, and six months against diﬀerent initial
infections. Each sample run corresponds to a point in the
ﬁgure. From Figure 8, we observe that as time passes by,
the number of infections tends to fall into two extremes, far
from being evenly distributed. This is further veriﬁed as
follows. For each measurement time t (one day, one week,
one month, and six months after initial infection), we obtain
the largest number of infections I (max)
over all 10,200 cases.
t
(1) After one day
(2) After one week
(3) After one month
(4) After six months
Figure 8: Number of infections in each sample run
under diﬀerent initial infection points
t
The ratio of the number of infections at time t in each case
to I (max)
falls into ﬁve diﬀerent bins: less than 20% (Bin 1),
between 20% and 40% (Bin 2), between 40% and 60% (Bin
3), between 60% and 80% (Bin 4), and between 80% and
100% (Bin 5). Figure 9 depicts the number of cases in each
bin. Clearly, at each measurement time, most of the cases
belong to either Bin 1 or 5. This phenomenon agrees well
with other types of Internet worms: once the infection takes
oﬀ, it does not take long for malware to infect the majority
of the entire vulnerable population.
For ease of explanation, we say that a sample run (or case)
leads to rare infections if the number of infections is no more
than 10. For each measurement time, we remove the cases
with rare infections. The following table shows the mean,
standard deviation (std), and coeﬃcient of variation (COV)
of the remaining cases for each measurement time:
1 day
1274.45
368.20
0.2889
1 week
5534.34
668.88
0.1209
1 month
10157.78
926.05
0.0912
6 months
19686.02
2085.83
0.1060
mean
std
COV
The table shows that for all four measurement times, the
COV is much smaller than 1. Hence, without considering
those cases with rare infections, there is low variation among
remaining ones.
We further explore what properties of initial infection
points aﬀect the malware propagation speed. As the ini-
tial phase is crucial to malware spreading, we analyze the
cases still with rare infections after six months. In Figure
10(1), we plot the number of sample runs with rare infec-
tions after six months against the degree of the initial in-
fection point. We observe that although a low degree tends
to cause more sample runs with rare infections, infecting a
node with a number of neighbors initially does not neces-
sarily cause a signiﬁcant number of infected nodes after six
months. It is noted that the average number of neighbors in
the BrightKite dataset is about 8. For one initial infection
point with as many as 38 neighbors, 15 of the 20 runs do not
lead to a signiﬁcant number of infections after six months.
After examining the cases where the initial infection point
has a high degree but leads to only a few infections after 6
months, we ﬁnd that in these cases, although the initial in-
201
 0 200 400 600 800 1000 1200 1400 1600 1800 0 2000 4000 6000 8000 10000Number of infected nodesWorm starting node ID 0 1000 2000 3000 4000 5000 6000 0 2000 4000 6000 8000 10000Number of infected nodesWorm starting node ID 0 2000 4000 6000 8000 10000 12000 0 2000 4000 6000 8000 10000Number of infected nodesWorm starting node ID 0 5000 10000 15000 20000 25000 0 2000 4000 6000 8000 10000Number of infected nodesWorm starting node IDFigure 9: Fraction of cases in each
bin
Figure 10: Number of cases vs. degree and active neighbors with rare
infections after 6 months
(1) Degree
(2) Active neighbors
only 29,323 of them have been active at least once. Regard-
ing the activity models, we use three diﬀerent methods. In
the ﬁrst method (BrightKite activities), we directly use
the set of activity events produced by the giant component
of the BrightKite graph.
In the second method (locally
randomized activities), we keep the number of activity
events generated by a user intact but the time of each ac-
tivity event is uniformly drawn from the simulated interval,
which lasts six months. In the last method (globally ran-
domized activities), we randomly choose 29,323 nodes and
each of them produces 60 activity events. The time of each
of these activity events is uniformly drawn from the simu-
lated interval. Note that the three activity models generate
about the same number of activity events in each simula-
tion run. In the third method, we only choose 29,323 nodes
because only active users can possibly be infected. With
diﬀerent combinations of social graphs and activity models,
we have the following six scenarios:
Scenario
Social Graph
Activity Model
A
B
C
D
E
F
Locally randomized
Globally randomized
BrightKite
BrightKite
BrightKite