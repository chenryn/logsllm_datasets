[37] Joël Plisson, Nada Lavrac, Dunja Mladenic, et al. A rule based
approach to word lemmatization. In Proceedings of IS, 2004.
[38] Enislay Ramentol, Yailé Caballero, Rafael Bello, and Fran-
cisco Herrera. Smote-rsb*: a hybrid preprocessing approach
based on oversampling and undersampling for high imbalanced
data-sets using smote and rough sets theory. Knowledge and
information systems, 33(2):245–265, 2012.
[39] Cedrick Ramos.
Spam campaigns with malware ex-
ploiting cve-2017-11882 spread in australia and japan.
https://www.trendmicro.com/vinfo/us/threat-
encyclopedia/spam/3655/spam-campaigns-with-
malware-exploiting-cve201711882-spread-in-
australia-and-japan, 2017.
[40] Pau Rodríguez, Miguel A Bautista, Jordi Gonzalez, and Sergio
Escalera. Beyond one-hot encoding: Lower dimensional target
embedding. Image and Vision Computing, 75:21–31, 2018.
[41] Mike Schuster and Kuldip K Paliwal. Bidirectional recurrent
neural networks. IEEE Transactions on Signal Processing,
45(11):2673–2681, 1997.
REC-prov-dm-20130430/, 2013. Accessed: 2020-06-06.
[49] David Wagner and Paolo Soto. Mimicry attacks on host-based
intrusion detection systems. In ACM SIGSAC Conference on
Computer and Communications Security, 2002.
[50] Qi Wang, Wajih Ul Hassan, Ding Li, Kangkook Jee, Xiao Yu,
Kexuan Zou, Junghwan Rhee, Zhengzhang Chen, Wei Cheng,
C Gunter, et al. You are what you do: Hunting stealthy malware
via data provenance analysis.
In Network and Distributed
Systems Security Symposium, 2020.
[51] Runqing Yang, Shiqing Ma, Haitao Xu, Xiangyu Zhang, and
Yan Chen. Uiscope: Accurate, instrumentation-free, and visi-
ble attack investigation for gui applications. In Network and
Distributed Systems Symposium, 2020.
[52] Alec Yenter and Abhishek Verma. Deep cnn-lstm with com-
bined kernels from multiple branches for imdb review senti-
ment analysis. In IEEE 8th Annual Ubiquitous Computing,
Electronics and Mobile Communication Conference, 2017.
Appendix
A LSTM Model Details
As shown in Table 7, we detail model architecture and pa-
rameters to train the LSTM model. Below we present each
layer of the model, what parameters represent and how we
specify their values. We refer interested readers to a relevant
research [52] for more details about the model.
The embedding layer transforms the network index number
of each word to an embedding vector. The “Input Maximum
Features” represents how many words ATLAS model can learn.
Since our vocabulary contains 30 words, we set it to 31 to
accommodate the in-vocabulary words and include an addi-
tional word for sequences padding. The “Embedding Size”
USENIX Association
30th USENIX Security Symposium    3021
Table 7: Architecture and parameters of LSTM model.
Model Architecture
Embedding
Input Maximum Features
Embedding Size Maximum Input Length
Convolution
(1-dimensional)
Max Pooling
(1-dimensional)
Dropout
LSTM
Dense
400
Activation
ReLU
31
Filters
64
128
Kernel Size
5
Pool Size
8
Rate
0.2
Output Size
256
Output Size
1
Activation
Sigmoid
Compiled Model
Loss Function
Binary Cross Entropy
Optimizer
Adam
Metrics
Accuracy
Batch
Epoch
(# samples/batch)
1
(# training iterations)
8
Probability Threshold
(Classify as attack if equal/greater)
0.5
represents the output vector size for each input word. We
found that 128 yields a better result than other values. The
“Maximum Input Length” represents the maximum length
(i.e., number of words) in a sequence that ATLAS can process.
We set this parameter to 400 since we found that processing
longer sequences lead to the vanishing gradients problem [14].
The 1-dimensional convolution layer is effective in learning
spatial features, such as learning adjacent words. The “Filters”
parameter represents the convolution output ﬁlter size. “Ker-
nel Size” speciﬁes how many embedded words are contained
in each convolution branch. We found that setting “Filters”
to 64 and “Kernel Size” to 5 yields a better result than other
values. The convolution “Activation” is set to the Rectiﬁed
Linear Unit (ReLU), which replaces negative output values
with zeroes, and leads to a better model generalization than
other activation functions [52]. Max pooling layer reduces
input dimensionality to minimize training time and to mit-
igate the training overﬁtting problem [14]. The “Pool Size”
speciﬁes the output size; we found that setting this parameter
to the value 8 yields a good result. Dropout layer is used to
reduce the model overﬁtting by the factor speciﬁed in the
parameter “Rate”, which we set to 0.20 as we found this value
yields a better model in our dataset.
The LSTM layer is used to learn from sequential data ef-
fectively. The LSTM output size parameter is set to 256 since
we found that the model is more effective when this value
is used. Dense layer input is a merged (i.e., concatenated)
from the LSTM output and is transformed into a single array.
The “Output Size” parameter for the dense layer speciﬁes the
overall model output size. We set it to 1 because we seek to
ﬁnd a scalar value representing the sequence class predicted
probability. The dense “Activation” is set to Sigmoid to repre-
sent the predicted probability as a single value between 0 and
1. The model “Loss Function” parameter is set to a binary
Table 8: Statistics of the simulated normal user behaviors in
audit logs for each attack.
Attack
ID
S-1
S-2
S-3
S-4
M-1
M-2
M-3
M-4
M-5
M-6
Avg.
# Processes
# I.
# U.
# Files
# U.
# I.
# Domain names
# U.
# I.
# IP Addresses
# U.
# I.
# Socket send/recv
# U.
# I.
# Web Requests
# U.
# I.
46
49
25
39
78
52
85
72
79
85
61
67,338
376,315
113,933
99,770
217,010
206,992
285,859
236,405
585,524
328,490
251,764
3,847
82,200
5,030
4,782
8,450
7,948
11,366
8,856
21,500
12,505
16,648
57,684
310,229
78,899
68,998
154,549
157,001
197,404
162,751
432,745
224,471
184,473
89
300
91
186
592
573
158
188
636
206
302
610
1,323
972
843
3,319
3,537
1,220
1,610
3,096
2,550
1,908
120
450
143
177
758
736
278
309
753
392
412
4,031
35,366
5,946
4,684
15,520
18,188
8,501
10,256
15,071
13,371
13,093
920
7,685
1,353
1,289
3,318
3,671
1,782
2,247
3,328
2,740
2,833
920
7,685
1,353
1,289
3,318
3,671
1,782
2,247
3,328
2,740
2,833
530
1,106
723
753
1,131
1,010
425
729
841
762
801
1,372
3,065
2,161
1,968
3,121
2,606
1,082
2,169
2,165
2,293
2,200
* U. means Unique Objects and I. means Instances.
entropy loss function, which is an effective and standard loss
function for binary classiﬁcation network architectures. The
model “Optimizer” parameter speciﬁes what optimizer we use
to optimize the model training accuracy using a loss function
feedback. We set this parameter to Adam optimizer since we
found that it yields a better classiﬁcation result. The model
“Metric function” parameter speciﬁes what metric the model
uses to measure the model performance during the training
phase. We set this parameter to the Accuracy metric function
as we found that it leads to a more effective model learning.
The “Batch” parameter speciﬁes how many sequences the
model can process at a time. We set this parameter to 1 since
we found that that model yields a better precision when it
processes the sequences one by one. The “Epoch” parameter
speciﬁes how many times the model iterates over each se-
quence during the training phase. We set this value to 8 since
we found that this value leads to a more effective model.
The “Probability Threshold” parameter speciﬁes ATLAS
classiﬁer threshold at attack investigation, such that if a pre-
dicted probability value is greater or equal to the speciﬁed
threshold, ATLAS then classiﬁes the sequence as an attack;
otherwise ATLAS classify the sequence as non-attack. Since
ATLAS is trained with balanced datasets using sampling (de-
tailed in Sec. 4.2.3), the classiﬁcation is no longer biased
towards one of the two classes; for this reason, we have cho-
sen the value 0.5 as the probability threshold.
B Attack Simulation
Table 8 presents the details of a user behavior within our col-
lected audit logs, including various activities such as running
processes, accessing ﬁles, browsing the web, and download-
ing ﬁles. We compute the statistics of different activities dur-
ing the deployment of each attack. For each type of activity
(e.g., the number of running processes), column U. shows how
many unique objects were accessed, and column I. shows how
many times these objects were accessed (i.e., object instances)
during the simulation.
3022    30th USENIX Security Symposium
USENIX Association