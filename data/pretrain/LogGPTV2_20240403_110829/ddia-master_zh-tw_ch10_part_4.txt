- 你可以将一个流水线阶段的输出写入档案，并将该档案用作下一阶段的输入。这使你可以重新启动后面的阶段，而无需重新执行整个管道。
因此，与关系资料库的查询最佳化器相比，即使 Unix 工具非常简单，但仍然非常有用，特别是对于实验而言。
然而，Unix 工具的最大局限在于它们只能在一台机器上执行 —— 而 Hadoop 这样的工具即应运而生。
## MapReduce和分散式档案系统
MapReduce 有点像 Unix 工具，但分布在数千台机器上。像 Unix 工具一样，它相当简单粗暴，但令人惊异地管用。一个 MapReduce 作业可以和一个 Unix 程序相类比：它接受一个或多个输入，并产生一个或多个输出。
和大多数 Unix 工具一样，执行 MapReduce 作业通常不会修改输入，除了生成输出外没有任何副作用。输出档案以连续的方式一次性写入（一旦写入档案，不会修改任何现有的档案部分）。
虽然 Unix 工具使用 `stdin` 和 `stdout` 作为输入和输出，但 MapReduce 作业在分散式档案系统上读写档案。在 Hadoop 的 MapReduce 实现中，该档案系统被称为 **HDFS（Hadoop 分散式档案系统）**，一个 Google 档案系统（GFS）的开源实现【19】。
除 HDFS 外，还有各种其他分散式档案系统，如 GlusterFS 和 Quantcast File System（QFS）【20】。诸如 Amazon S3、Azure Blob 储存和 OpenStack Swift【21】等物件储存服务在很多方面都是相似的 [^iv]。在本章中，我们将主要使用 HDFS 作为示例，但是这些原则适用于任何分散式档案系统。
[^iv]: 一个不同之处在于，对于 HDFS，可以将计算任务安排在储存特定档案副本的计算机上执行，而物件储存通常将储存和计算分开。如果网路频宽是一个瓶颈，从本地磁碟读取有效能优势。但是请注意，如果使用纠删码（Erasure Coding），则会丢失区域性，因为来自多台机器的资料必须进行合并以重建原始档案【20】。
与网路连线储存（NAS）和储存区域网路（SAN）架构的共享磁碟方法相比，HDFS 基于 **无共享** 原则（请参阅 [第二部分](part-ii.md) 的介绍）。共享磁碟储存由集中式储存装置实现，通常使用定制硬体和专用网路基础设施（如光纤通道）。而另一方面，无共享方法不需要特殊的硬体，只需要透过传统资料中心网路连线的计算机。
HDFS 在每台机器上运行了一个守护程序，它对外暴露网路服务，允许其他节点访问储存在该机器上的档案（假设资料中心中的每台通用计算机都挂载著一些磁碟）。名为 **NameNode** 的中央伺服器会跟踪哪个档案块储存在哪台机器上。因此，HDFS 在概念上建立了一个大型档案系统，可以使用所有执行有守护程序的机器的磁碟。
为了容忍机器和磁碟故障，档案块被复制到多台机器上。复制可能意味著多个机器上的相同资料的多个副本，如 [第五章](ch5.md) 中所述，或者诸如 Reed-Solomon 码这样的纠删码方案，它能以比完全复制更低的储存开销来支援恢复丢失的资料【20,22】。这些技术与 RAID 相似，后者可以在连线到同一台机器的多个磁碟上提供冗余；区别在于在分散式档案系统中，档案访问和复制是在传统的资料中心网路上完成的，没有特殊的硬体。
HDFS 的可伸缩性已经很不错了：在撰写本书时，最大的 HDFS 部署执行在上万台机器上，总储存容量达数百 PB【23】。如此大的规模已经变得可行，因为使用商品硬体和开源软体的 HDFS 上的资料储存和访问成本远低于在专用储存装置上支援同等容量的成本【24】。
### MapReduce作业执行
MapReduce 是一个程式设计框架，你可以使用它编写程式码来处理 HDFS 等分散式档案系统中的大型资料集。理解它的最简单方法是参考 “[简单日志分析](#简单日志分析)” 中的 Web 伺服器日志分析示例。MapReduce 中的资料处理模式与此示例非常相似：
1. 读取一组输入档案，并将其分解成 **记录（records）**。在 Web 伺服器日志示例中，每条记录都是日志中的一行（即 `\n` 是记录分隔符）。
2. 呼叫 Mapper 函式，从每条输入记录中提取一对键值。在前面的例子中，Mapper 函式是 `awk '{print $7}'`：它提取 URL（`$7`）作为键，并将值留空。
3. 按键排序所有的键值对。在日志的例子中，这由第一个 `sort` 命令完成。
4. 呼叫 Reducer 函式遍历排序后的键值对。如果同一个键出现多次，排序使它们在列表中相邻，所以很容易组合这些值而不必在记忆体中保留很多状态。在前面的例子中，Reducer 是由 `uniq -c` 命令实现的，该命令使用相同的键来统计相邻记录的数量。
这四个步骤可以作为一个 MapReduce 作业执行。步骤 2（Map）和 4（Reduce）是你编写自定义资料处理程式码的地方。步骤 1（将档案分解成记录）由输入格式解析器处理。步骤 3 中的排序步骤隐含在 MapReduce 中 —— 你不必编写它，因为 Mapper 的输出始终在送往 Reducer 之前进行排序。
要建立 MapReduce 作业，你需要实现两个回拨函式，Mapper 和 Reducer，其行为如下（请参阅 “[MapReduce 查询](ch2.md#MapReduce查询)”）：
* Mapper
  Mapper 会在每条输入记录上呼叫一次，其工作是从输入记录中提取键值。对于每个输入，它可以生成任意数量的键值对（包括 None）。它不会保留从一个输入记录到下一个记录的任何状态，因此每个记录都是独立处理的。
* Reducer
  MapReduce 框架拉取由 Mapper 生成的键值对，收集属于同一个键的所有值，并在这组值上迭代呼叫 Reducer。Reducer 可以产生输出记录（例如相同 URL 的出现次数）。
在 Web 伺服器日志的例子中，我们在第 5 步中有第二个 `sort` 命令，它按请求数对 URL 进行排序。在 MapReduce 中，如果你需要第二个排序阶段，则可以透过编写第二个 MapReduce 作业并将第一个作业的输出用作第二个作业的输入来实现它。这样看来，Mapper 的作用是将资料放入一个适合排序的表单中，并且 Reducer 的作用是处理已排序的资料。
#### 分散式执行MapReduce
MapReduce 与 Unix 命令管道的主要区别在于，MapReduce 可以在多台机器上并行执行计算，而无需编写程式码来显式处理并行问题。Mapper 和 Reducer 一次只能处理一条记录；它们不需要知道它们的输入来自哪里，或者输出去往什么地方，所以框架可以处理在机器之间移动资料的复杂性。
在分散式计算中可以使用标准的 Unix 工具作为 Mapper 和 Reducer【25】，但更常见的是，它们被实现为传统程式语言的函式。在 Hadoop MapReduce 中，Mapper 和 Reducer 都是实现特定介面的 Java 类。在 MongoDB 和 CouchDB 中，Mapper 和 Reducer 都是 JavaScript 函式（请参阅 “[MapReduce 查询](ch2.md#MapReduce查询)”）。
[图 10-1](../img/fig10-1.png) 显示了 Hadoop MapReduce 作业中的资料流。其并行化基于分割槽（请参阅 [第六章](ch6.md)）：作业的输入通常是 HDFS 中的一个目录，输入目录中的每个档案或档案块都被认为是一个单独的分割槽，可以单独处理 map 任务（[图 10-1](../img/fig10-1.png) 中的 m1，m2 和 m3 标记）。
每个输入档案的大小通常是数百兆位元组。MapReduce 排程器（图中未显示）试图在其中一台储存输入档案副本的机器上执行每个 Mapper，只要该机器有足够的备用 RAM 和 CPU 资源来执行 Mapper 任务【26】。这个原则被称为 **将计算放在资料附近**【27】：它节省了透过网路复制输入档案的开销，减少网路负载并增加区域性。
![](../img/fig10-1.png)