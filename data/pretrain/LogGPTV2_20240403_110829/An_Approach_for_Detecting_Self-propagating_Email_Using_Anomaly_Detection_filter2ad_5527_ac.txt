Fanout = 08
Fanout = 04
Fanout = 32
Fanout = 64
10
Incubation Period (Seconds)
100
1000
10000
Fig. 3. Percentage of Infected Hosts
3.2 Metrics Used for detection
The ﬁrst and most obvious metric is the detection time: the time between the introduction
of the virus and the time of detection. Figure 2 shows how the detection time changes
as the propagation factor (also known as fanout) and incubation period are changed.
Note that longer incubation periods and lower propagation factors delay detection. The
detection delay is somewhat mitigated by the fact that the virus itself propagates more
slowly in these cases. We therefore look at other metrics that factor out the speed at
which a virus spreads. Some of these metrics are:
– percentage of clients that are infected at the time of detection
– percentage of email trafﬁc due to viruses at the time of detection
The ﬁrst of these metrics is related to the costs for cleaning up after the virus infection.
The other metric relates to the load on the email server, and the degree to which its
function is degraded by the virus.
Figure 3 shows the percentage of infected hosts at the time of detection of the attack.
The results are for an intranet consisting of 400 clients. This ﬁgure shows that for noisy
64
A. Gupta and R. Sekar
i
s
e
n
h
c
a
M
d
e
t
c
e
f
n
I
f
o
e
g
a
t
n
e
c
r
e
P
s
e
s
u
r
i
V
l
i
a
m
E
f
o
e
g
a
t
n
e
c
r
e
P
100
80
60
40
20
0
1
Infected Machines at Detection Time, Fanout = 8
Size = 0400 Clients
Size = 0800 Clients
Size = 1600 Clients
10
Incubation Period (Seconds)
100
1000
10000
90
80
70
60
50
40
30
20
Fig. 4. Infected Hosts
Fraction of Email Virus traffic at Detection
Fanout = 32, Network size = 1600 Clients
1
10
100
1000
10000
Incubation Period of the Virus (Seconds)
Fig. 5. Percentage of Virus Carrying Emails
viruses, detection occurs early, but very stealthy viruses, especially those that use a
combination of large incubation periods and low propagation factors, can potentially
infect most of the network before being detected. Figure 4 shows that for a given value
of propagation factor (ﬁxed at 8 for this graph), and incubation period, the fraction of
infected hosts is lower when the number of clients in the intranet is higher.
Figure 5 shows the fraction of email trafﬁc that is due to the viruses as of the time
of detection. Speciﬁcally, we calculated the fraction of email trafﬁc due to viruses in
the few seconds (2 seconds) preceding the detection. Note that the virus trafﬁc is in the
40% to 70% range, which means that the email server is only slightly overloaded. Due
to burstiness of emails, servers are typically designed to handle a few to several times
the average rate at which emails are generated in the system. For this reason, a 40% to
70% increase in email trafﬁc is not very signiﬁcant.
An Approach for Detecting Self-propagating Email Using Anomaly Detection
65
3.3 False Alarms
False alarm rates were computed using two different criteria:
– Criteria 1: Count even a single alarm as a false alarm: Using this criteria, there were
a total of 3 false alarms across 8 runs, or a rate of about 0.38 false alarms per hour.
– Criteria 2: Apply a threshold criteria, and count a false alarm when the threshold
is exceeded. This threshold is established through experimentation. We found that
by registering an alarm when more than 3 alarms are reported over a period of two
seconds, zero false alarm rate could be achieved in our simulation.
We note that in the detection results reported earlier, Criteria 2 was used. Thus, those
detection results were obtained with zero false alarm rate.
Runtime Performance and Memory Usage.
The whole implementation was done in Java. With 400 clients, about 800 frequency
distributions were maintained, each over 8 time scales. Due to these structures the total
memory use of the Java program was 30MB. When run on a Intel Pentium III system
operating at 1GHz, it was able to simulate about 500 cycles per second, i.e., simulate 100
seconds in one second of operation. In addition to the simulation, the anomaly detector
was processing about 100 messages per second. This performance was adequate to
provide fast simulation. If used in a live environment, these performance results show
that the anomaly detector will consume 1% of CPU on a similar system.
4 Experiment II
This experiment was conducted as part of the DARPA SWWIM program. The SWWIM
Autonomic ResponseArchitecture (SARA) experiment was conducted by a collaborative
team of organizations, each responsible for a key function. This experiment differed from
the previous experiment in several aspects. First, the user models were asymmetric, i.e.,
the behavior models for different users were different. Second, the experiment was
conducted with real email servers (sendmail) and clients. Third, the simulation as well
as the viruses were designed by a third party that had no vested interest in how the
detectors from different organizations performed.
The overall goal of the SARA experiment was to evaluate the value of orchestrated re-
sponse to attacks. The system consisted of several virus detection components, response
components in the form of mail server and client enhancements to purge suspected
messages, and an orchestrator. The orchestrator took its input from the detection compo-
nents, evaluated the system state based on these inputs, selected a response action, and
communicated these actions to the response components. Several detection components
were built, including (a) simple behavior based detectors that looked for more than a
certain number emails within a certain time period or within a certain time period after
an attachment was opened, (b) more complex behavior based detectors that were tuned
to detect the tree-like ﬂow of emails produced by email viruses, and (c) our anomaly
detector.
Early on in the experimental design, it was decided that the above detectors would
be used in different stages of virus spread: the behavior based techniques will be used
for early detection, at which point the system would attempt a carefully orchestrated
sequence of responses. But these detectors can be fooled by stealthy viruses, at which
66
A. Gupta and R. Sekar
point, the results from the anomaly detector would be used to identify the spread of the
virus. Note that the anomaly detector cannot provide precise identiﬁcation of offending
email messages — the only thing that can be said is that a predominant number of
email messages causing an alarm are bound to be viruses. Due to the absence of precise
identiﬁcation of virus-carrying emails, and given the time constraints associated with the
conduct of this experiment, it was decided that the orchestrator would simply shutdown
the system if the only information it had was from the anomaly detector. Clearly, this
is a response of last resort, and not to be attempted unless every thing else failed. In
particular, the orchestrator should be allowed to try intelligent responses based on inputs
from other detectors; and only when all of this failed, it should consider shutting down
the system. In order to make sure that these responses were given adequate time to work,
it was decided that the anomaly detector would artiﬁcially delay detection until such
time it became clear that the virus was established in spite of an orchestrated response.
4.1 Experimental Setup
The experiment was carried out using a “full scale” simulation of an email system
for a single subnet of 400 clients. This included an email server (modiﬁed version of
sendmail) and 400 email clients. The detection, response, and orchestration components
communicated and worked in conjunction with the email server and clients.
Similar to Experiment I, the actions of users were emulated by 400 “bots.” However,
these bots were signiﬁcantly more complex than user models used in Experiment I. In
particular, user behavior was simulated by 400 bots that were implemented as processes
that run concurrently. User behavior was modeled using a three-state Markov model, with
the states corresponding to the user reading email, composing email and being idle. The
bots will make transitions at random among these states, with a speciﬁed probability
for each of the six possible transitions. In this manner this model avoids the pitfalls
associated with a Poisson model used in Experiment I.
A second important improvement in the user model is that it is asymmetric, and it
captures the concept of address books. When a user composes email, the set of recipients
is assumed to come from his or her address book. The address book size is unlimited,
i.e., it can be as large as the user population. These factors mean that it is much more
common for emails with a large number of recipients to be generated in this experiment.
Several different types of viruses were used in the experiment. These virus types are
shown in Figure 6. Higher numbered viruses were intended to be progressively more
stealthy.
4.2 Detection Effectiveness
Hundreds of simulation runs were carried out with the above types of viruses. Due to
the fact that the anomaly detector was tuned explicitly for delayed detection of viruses,
no alarms were generated in those runs where the orchestrator was able to contain the
virus. There were seven runs in which the orchestrator was unable to contain the virus.
It is signiﬁcant that in every one of these cases, the anomaly detector was able to detect
the virus, as shown in Figure 7. In most cases, the detection took place 2 or 3 minutes
after the detection of virus.
In some cases, the detection was rather slow. For virus 4b.v2, the delay was due to
the fact that it had a very long incubation period, so it was not propagating fast until
An Approach for Detecting Self-propagating Email Using Anomaly Detection
67
Virus type Description
1
2a
2b
3a
3b
4a
4a.v1
4b
4b.v1
4b.v2
4b.v3
4b.v4
Static
Randomized Addresses - (taken from sent items)
Randomized Addresses - (taken from received items)
Randomized - (random number of recipients)
Delayed Randomized (random no. of recipients and time delay)
Polymorphic - (virus attachments all end in .vbs)
Polymorphic - (virus attachments have variable extensions)
Persistent Polymorphic - (virus attachments all end in .vbs, lives forever)
Persistent Polymorphic - (fast propagating version)
Persistent Polymorphic - (slow propagating version)
Persistent Polymorphic - (medium propagating version)
Persistent Polymorphic - (viruses have variable extensions, lives forever)
Fig. 6. Properties of Viruses Used
Time of
Virus type (post-virus release)
Percentage of
2b