1.62 (0.11)
User Experience: We now consider the data collected via direct user
responses during the post-study phase. The average SUS score from
the study came out to be only 49.88 (std dev = 5.29). This is rather
low given that average scores for commerical usable systems range
from 60-70 [21], and suggests a poor usability of the system. This
means that it would be difﬁcult for human users to perform well at
the relay attack task and implies that launching relay attacks against
DCG captchas can be quite challenging for an attacker.
Table 8 shows the 5-point Likert scores (‘1’ is “Strong Disagree-
ment”; ‘5’ is “Strong Agreement”) for the visual appeal and pleasur-
ability of the games. Although the former average ratings are on the
positive side (more that 3), the latter ratings are low, suggesting the
participants did not ﬁnd the games to be pleasurable. In our games,
we made use of visual and audio stimuli to which the users had to
respond. In order to understand what type of stimulus worked best
for the participants, we asked them to what extent the audio, visual or
both stimuli together was useful as an indicator to respond fastest to
10
the game. These ratings are depicted in Table 8. The responses were
on average in favor of the visual stimulus, followed by the two stim-
uli together, and ﬁnally the audio stimulus. 35% participants found
audio stimulus and visual stimulus to be sufﬁcient whereas 45% par-
ticipants agreed or strongly agreed with the statement that both visual
and audio stimulus are necessary to play the game. We further per-
formed the ANOVA test for responses corresponding to the three –
visual, audio and visual+audio – stimuli, but did not ﬁnd a statisti-
cally signiﬁcant difference. Finally, 80% of the participants felt that
training will help them play the games better with an average score
of 3.95. This suggests an attacker might improve success in relay
attack through advance training of human solvers.
Table 8: Participant Feedback Summary
Features
Visually Attractive
Pleasurable
Visual Stimulus
Audio Stimulus
Both Audio and Visual
Need Training
Likert Mean (std dev)
3.20 (0.92)
2.85 (0.99)
3.20 (1.17)
2.95 (0.93)
3.10 (1.25)
3.95 (1.01)
Summary of Relay Attack Analysis: Our analysis suggests that sub-
jecting the DCG captcha to relay attacks poses certain challenges in
practice. Speciﬁcally, for the Static Relay attack to succeed, the hu-
man solvers have to perform a reaction time task (average reaction
time is more than 2s). This task, except for the Shapes game, takes
much longer (> about 30s on average), is signiﬁcantly more error
prone (error rates more than 20%; per click error rates more than
50%), and much harder for the users when compared to directly play-
ing the games by honest users under a non-relay attack setting. In real
life, where the communication delays between the bot and solver’s
machine will be non-zero and average solver population samples are
used (unlike our attack set-up), the timings and error rates might be
higher and launching a relay attack might be even more difﬁcult. Al-
though our experiments were conducted on our 4 DCG captcha in-
stances, we believe that our analysis is generally applicable to other
DCG captcha types involving moving answer objects.
7. CONCLUSIONS AND FUTURE WORK
This paper represents the ﬁrst academic effort towards investigat-
ing the security and usability of game-oriented captchas in general
and DCG captchas in particular. Our overall ﬁndings are mixed. On
the positive side, our results suggest that DCG captchas, unlike other
known captchas, offer some level of resistance to relay attacks. We
believe this to be a primary advantage of these captchas, given that
other captchas offer no relay attack resistance at all. Furthermore,
the studied representative DCG captcha category demonstrated high
usability. On the negative side, however, we have also shown this
category to be vulnerable to a dictionary-based automated attack.
An immediate consequence from our study is that further research
on DCG captchas could concentrate on making these captchas better
resistant to automated attacks while maintaining a good level of us-
ability.8 Moreover, our paper focused on “pure automated” and “pure
relay attacks” (in line with traditional captchas). However, hybrid at-
tacks can also be envisioned, which combine the computing power
and human knowledge. Future research is necessary to investigate
how well hybrid attacks work, and how they alter the economics
of captcha-solving (following up [23]). Finally, the results of our
user study on reaction-time task performance may have general ap-
plications in human-centered computing (security and non-security)
domains. For instance, these results may rule out the possibility of
usable captcha schemes themselves based on reaction-time tests.
8The modiﬁcations made to the original DCG captchas to resist au-
tomated attacks, such as a dynamic background, may further make
relay attacks more difﬁcult.
Acknowledgments
We thank: the team of “are you a human” for creating the CAPTCHAs
that inspired our work; John Grimes, John Sloan and Anthony Skjel-
lum for guiding us regarding the ethical aspects of our work; So-
nia Chiasson, Fabian Monrose and Gerardo Reynaga regarding early
discussions; and various members of the SPIES group at UAB and
PreCog group at IIITD for helpful suggestions throughout the study.
The work of Mohamed, Georgescu, Gao and Saxena is partially sup-
ported by a grant on “Playful Security” from the National Science
Foundation CNS-1255919. Van Oorschot holds the Canada Research
Chair in Authentication and Computer Security and acknowledges
NSERC for funding the chair and a Discovery Grant.
8. REFERENCES
[1] Cracking the areyouahuman captcha.
http://spamtech.co.uk/software/bots/cracking-
the-areyouhuman-captcha/.
[2] L. V. Ahn, M. Blum, N. J. Hopper, and J. Langford. Captcha: using
hard ai problems for security. In EUROCRYPT, 2003.
[3] Amayeta. Swf encrypt: Encrypt, obfuscate & protect your ﬂash swf
actionscript & resources from decompilers.
http://www.amayeta.com/software/swfencrypt/.
[4] Are You a Human. https://www.areyouahuman.com/.
[5] Are You a Human. Terms of service. Available at:
http://portal.areyouahuman.com/termsofservice.
[6] A. Bangor, P. T. Kortum, and J. T. Miller. An empirical evaluation of
the system usability scale. International Journal of Human-Computer
Interaction, 24(6):574–594, 2008.
[7] A. Basso and F. Bergadano. Anti-bot strategies based on human
interactive proofs. In Handbook of Information and Communication
Security. 2010.
[8] J. Brooke. SUS: a “quick and dirty” usability scale. In P. W. Jordan,
B. Thomas, B. A. Weerdmeester, and A. L. McClelland, editors,
Usability Evaluation in Industry. Taylor and Francis, London, 1996.
[9] E. Bursztein, S. Bethard, C. Fabry, J. Mitchell, and D. Jurafsky. How
Good Are Humans at Solving CAPTCHAs? A Large Scale Evaluation.
In IEEE Symposium on Security and Privacy, 2010.
[10] C. Doctorow. Solving and Creating CAPTCHAs with Free Porn. In
Boing Boing, Available at: http://www.boingboing.net/
2004/01/27/solving_and_creating.html, 2004.
[11] K. Chellapilla, K. Larson, P. Simard, and M. Czerwinski. Designing
human friendly human interaction proofs (hips). In ACM CHI, 2005.
[12] S. ching Chen, M. ling Shyu, C. Zhang, and R. L. Kashyap. Identifying
overlapped objects for video indexing and modeling in multimedia
database systems. In Multimedia Database Systems, International
Journal on Artiﬁcial Intelligence Tools, 2001.
[13] Dancho Danchev. Inside indias captcha solving economy. Available at:
http://blogs.zdnet.com/security/?p=1835.
[14] M. Egele, L. Bilge, E. Kirda, and C. Kruegel. Captcha smuggling:
hijacking web browsing sessions to create captcha farms. In
Proceedings of the 2010 ACM Symposium on Applied Computing,
2010.
[15] G. Keizer. Spammers’ Bot Cracks Microsoft’s CAPTCHA. In
Computer World, Available at:
http://www.computerworld.com/s/article/9061558/
Spammers_bot_cracks_Microsoft_s_CAPTCHA_, 2008.
[16] C. Gentry, Z. Ramzan, and S. Stubblebine. Secure distributed human
computation. In Proceedings of the 6th ACM conference on Electronic
commerce, EUROCRYPT, 2005.
[17] J. M. G. Hidalgo and G. Alvarez. CAPTCHAs: An Artiﬁcial
Intelligence Application to Web Security. Advances in Computers,
Volume 83 (editor: Marvin V. Zelkowitz), pages 110–181, 2011.
[18] Jeff Yan and Ahmad Salah El Ahmad. A Low-cost Attack on a
Microsoft CAPTCHA. In ACM CCS, 2008.
[19] K. Kluever. Breaking the PayPal.com CAPTCHA. Available at:
http://www.kloover.com/2008/05/12/breaking-the-
paypalcom-captcha, 2008.
[20] R. Kosinski. A literature review on reaction time. Available at:
http://biology.clemson.edu/bpc/bp/Lab/110/
reaction.htm, 2012.
11
[21] J. Lewis and J. Sauro. The factor structure of the system usability scale.
In Human Computer Interaction International Conference (HCII),
2009.
[22] M. Mohamed, S. Gao, N. Saxena, and C. Zhang. Dynamic cognitive
game captcha usability and detection of streaming-based farming. In
the Workshop on Usable Security (USEC), co-located with NDSS,
2014.
[23] M. Motoyama, K. Levchenko, C. Kanich, D. McCoy, G. M. Voelker,
and S. Savage. Re: Captchas-understanding captcha-solving services in
an economic context. In USENIX Security Symposium, 2010.
[24] NuCaptcha. Nucaptcha: Adaptive captcha authentication.
http://www.nucaptcha.com/.
[25] J. Ogden. Captcha can kill your conversion rate. Available at:
http://www.evancarmichael.com/Marketing/6352/
CAPTCHA-Can-Kill-Your-Conversion-Rate.html.
[26] OnLive. http://www.onlive.com/.
[27] PRNewsWire. Are you a human’s user-friendly game-based security
solution aims to replace distorted text captchas. Available at:
http://www.prnewswire.com/news-releases/are-
you-a-humans-user-friendly-game-based-
security-solution-aims-to-replace-distorted-
text-captchas-152266285.html.
[28] S. Prasad. Googles CAPTCHA Busted in Recent Spammer Tactics.
Available at: http://securitylabs.websense.com/
content/Blogs/2919.aspx, 2008.
[29] D. Stefan and D. Yao. Keystroke-dynamics authentication against
synthetic forgeries. In CollaborateCom, pages 1–8, 2010.
[30] S. Wesolkowski. Stochastic nested aggregation for images and random
ﬁelds. In Ph.D. Thesis, University of Waterloo, 2007.
[31] Y. Xu, G. Reynaga, S. Chiasson, J.-M. Frahm, F. Monrose, and P. C.
van Oorschot. Security and usability challenges of moving-object
captchas: Decoding codewords in motion. In USENIX Security, 2012.
[32] Yan, Jeff and El Ahmad, Ahmad Salah. Usability of CAPTCHAs Or
usability issues in CAPTCHA design. In SOUPS, 2008.
[33] B. B. Zhu, J. Yan, Q. Li, C. Yang, J. Liu, N. Xu, M. Yi, and K. Cai.
Attacks and design of image recognition captchas. In ACM CCS, 2010.
APPENDIX
A. ADDITIONAL FIGURES AND TABLES
(a) A star indicating correct ob-
ject match
(b) A cross indicating incorrect
object match
Figure 6: User Feedback per Game Interaction
B. TARGET AREA DETECTION USING THE
EXCLUSION METHOD
A design alternative for target area detection, called the exclusion
method is to detect the target area by simply removing foreground
object pixels accumulated from all the sample frames. However,
while this alternative is slightly faster but still at about the same time
efﬁciency as the MBR-based method, it is less robust than the latter
especially when the objects are moving slow such that the remaining
area, i.e., the detected target area, may include too much of the fore-
ground object moving area that has not had a chance to be covered
by the footprints of foreground objects extracted from the limited
set of sample frames. Figure 8 shows our experimental results for
this design alternative applied to four different challenges, where the
blue dots represent the detected target area centers. This alternative
method failed to detect the correct target center in all four cases.
(a) The solver is asked to choose a
target object
(b) The solver is asked to choose the
next answer object, if any
Table 9: Usability Study Participant Demographics
Gender
Male
Female
Age
18 - 24
25 - 35
Education
Highschool
Bachelors
Masters
Ph. D.
Profession / ﬁeld of study
Computer Science
Engineering
Science, Pharmaceuticals
Law
Journalism
Finance
Business
Others
N=40
(%)
50
50
(%)
80
20
(%)
45
27.5
22.5
5
(%)
60
5
10
2.5
2.5
2.5
5
12.5
(c) The solver is asked to select a new
target object, if any
Figure 7: User interface implementing the reaction time relay exper-
iment (95 represents the User ID; the red rectangle in (c) represents
our visual stimulus)
Table 10: Relay Attck User Study Participant Demographics
Gender
Male
Female
Age
18 - 24
25 - 35
35 - 50
Education
Highschool
Bachelors
Masters
Ph. D.
Profession / ﬁeld of study
Computer Science
Engineering
Medicine
N=20
%
70
30
%
35
60
5
%
25
45
30
0
%
90
5
5
Figure 8: The target area centers (blue dots) detected by exclusion
method
View publication stats
View publication stats
12
 Original animation Exclusion method Animals Game   Parking Game   Shapes Game   Ships Game