title:MPI: Multiple Perspective Attack Investigation with Semantic Aware
Execution Partitioning
author:Shiqing Ma and
Juan Zhai and
Fei Wang and
Kyu Hyung Lee and
Xiangyu Zhang and
Dongyan Xu
MPI: Multiple Perspective Attack Investigation 
with Semantics Aware Execution Partitioning
Shiqing Ma, Purdue University; Juan Zhai, Nanjing University; Fei Wang, Purdue University; 
Kyu Hyung Lee, University of Georgia; Xiangyu Zhang and Dongyan Xu, Purdue University
https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/ma
This paper is included in the Proceedings of the 26th USENIX Security SymposiumAugust 16–18, 2017 • Vancouver, BC, CanadaISBN 978-1-931971-40-9Open access to the Proceedings of the 26th USENIX Security Symposium is sponsored by USENIXMPI: Multiple Perspective Attack Investigation with Semantics Aware
Execution Partitioning
Shiqing Ma
Purdue University
Juan Zhai
Nanjing University
Xiangyu Zhang
Purdue University
Abstract
Traditional auditing techniques generate large and inac-
curate causal graphs. To overcome such limitations, re-
searchers proposed to leverage execution partitioning to
improve analysis granularity and hence precision. How-
ever, these techniques rely on a low level programming
paradigm (i.e., event handling loops) to partition execu-
tion, which often results in low level graphs with a lot of
redundancy. This not only leads to space inefficiency and
noises in causal graphs, but also makes it difficult to un-
derstand attack provenance. Moreover, these techniques
require training to detect low level memory dependencies
across partitions. Achieving correctness and complete-
ness in the training is highly challenging. In this paper,
we propose a semantics aware program annotation and
instrumentation technique to partition execution based
on the application specific high level task structures. It
avoids training, generates execution partitions with rich
semantic information and provides multiple perspectives
of an attack. We develop a prototype and integrate it with
three different provenance systems: the Linux Audit sys-
tem, ProTracer and the LPM-HiFi system. The evaluation
results show that our technique generates cleaner attack
graphs with rich high-level semantics and has much lower
space and time overheads, when compared with the event
loop based partitioning techniques BEEP and ProTracer.
1
Introduction
Provenance tracking is critical for attack investigation,
especially for Advanced Persistent Threats (APTs) that
are backed by organizations such as alien governments
and terrorists. APT attacks often span a long duration
of time with a low profile, and hence are difficult to
detect and investigate. A provenance tracking system
records the causality of system objects (e.g. files) and
subjects (e.g. processes). Once an attack symptom is
detected, the analyst can utilize the provenance data to
Fei Wang
Purdue University
Dongyan Xu
Purdue University
Kyu Hyung Lee
University of Georgia
understand the attack including its root cause and ramifi-
cations. Such inspection is critical for timely response to
attacks and the protection of target systems. Most existing
techniques [38, 46, 49, 50, 59] entail hooking and record-
ing important system level events (e.g. file operations),
and then correlating these events during an offline inves-
tigation process. The correlations have multiple types:
between two processes such as a process creating a child
process through sys_clone(); between a process and a sys-
tem object, e.g., a process reads a file through sys_read().
However, these techniques suffer from the dependence
explosion problem, especially for long running processes.
The reason is that a long running process may have de-
pendencies with many objects and other processes during
its lifetime although only a small subset is attack related.
For instance, a Firefox process may visit numerous pages
over its lifetime while only one page is related to a drive-
by-download attack.
Researchers proposed to partition execution to units so
that only the events within a unit are considered causally
related [43, 46]. For instance, the execution of a long
running server is partitioned to individual units, each han-
dling a request. Although existing execution partitioning
based systems such as BEEP [43] and ProTracer [46] have
demonstrated great potential, they partitioned execution
based on event handling loops. That is, each iteration of
an event handling loop is considered a unit. Despite its
generality, such a partitioning scheme has inherent lim-
itations. (1) Event loop iterations are too low level and
cannot denote high level task structure. For instance, in UI
programs, an event loop iteration may be to handle some
user interaction. (2) There are often inter-dependencies
across units. Therefore, BEEP and ProTracer rely on a
training phase to detect such dependencies in the form
of low level memory reads and writes. Achieving com-
pleteness in training is highly challenging. Note that the
problem could not be addressed even when source code
is provided because there are typically a lot of program
dependencies across event loop iterations and only a sub-
USENIX Association
26th USENIX Security Symposium    1111
set of them are important. (3) A high level task is often
composed of many units (e.g., those denoting event loop
iterations in multiple worker threads that serve the same
high level task). Ideally, we would like to partition execu-
tion based on the high level task structure.
Note that high level task structure is application specific.
Therefore, developers’ input on what denotes a task/unit
is necessary. We observe that a high level task/unit has
its corresponding data structure in the software. Our pro-
posal is hence to allow the developer/user to inform our
system what task/unit structure they desire by annotating
a small number of data structures (e.g., the tab data struc-
ture in Firefox). Our system MPI1 takes the annotations
and automatically instruments (a large number of) pro-
gram locations that denote unit boundaries through static
program analysis. The analysis handles complex thread-
ing models in which the executions of multiple tasks/units
interleave. The instrumentation emits special syscalls
upon unit context switches so that the application specific
task/unit semantics is exposed to the underlying prove-
nance tracking systems. MPI allows annotating multiple
task/unit structures simultaneously so that the forensic an-
alyst can inspect an execution from multiple perspectives
(e.g., tab and domain perspectives for Firefox). This is
highly desirable for attack investigation as we will show
later in the paper. Asking for developers/users input in au-
dit logging is a strategy adopted in practice. For example,
the audit system on Windows, Event Tracing for Windows
(ETW) requires the developers to explicitly plant audit-
ing API calls in their source code if they would like to
perform any customized logging. Nonetheless, reducing
manual efforts is critical to the real world deployment of
the technique. MPI is highly automated as the user only
needs to annotate a few data structures and then the invo-
cations to logging commands are automatically inserted
through program analysis. Most of the programs we use
in our experiment require only 2-3 annotations for each
perspective. In addition, MPI provides a data structure
profiler, called the annotation miner, to recommend the
potential data structures to annotate. As shown in §4.2, it
makes the correct recommendations in most cases.
MPI is a general execution partitioning scheme or-
thogonal to the underlying OS-level provenance collec-
tion system. We integrate it with three different prove-
nance collection systems: the widely adopted Linux audit
framework, and two state-of-the-art research projects, Pro-
Tracer [46]2 and the LPM [23] enabled HiFi [55] system
(LPM-HiFi) which features secure audit logging.
In summary, we make the following contributions:
• We propose the novel idea of partitioning execution
based on data structures to support different granu-
1MPI is short for “Multiple Perspective attack Investigation”
2ProTracer is based on BEEP, we replace the BEEP with MPI.
larities and facilitate multi-perspective, application-
semantics-aware attack investigation.
• We develop program analysis and runtime tech-
niques to enable such partitioning. Given a small
number of annotations on data structure definitions,
program analysis is conducted to identify places that
need to be instrumented to emit events at runtime
that denote unit boundaries and unit inheritance. The
number of such places may be very large, rendering
manual instrumentation infeasible.
• We develop an annotation miner that can recommend
the data structures to annotate with high accuracy,
substantially alleviating the manual efforts.
• We develop a prototype based on LLVM. The evalu-
ation on a set of commonly used Linux applications
and three different provenance systems shows that
our approach can effectively partition program execu-
tion in different granularities. We also use a number
of case studies that simulate real-world attacks to
demonstrate the strength of the proposed technique,
in comparison with BEEP [43] and ProTracer [46].
2 Motivation
In this section, we use an example to illustrate the dif-
ferences between the classic provenance tracking sys-
tems [23, 49, 50, 55], the existing event loop based exe-
cution partitioning approaches [43, 46], and the proposed
approach. This example simulates an important kind of
real-world attacks, watering hole attack [18, 19],
2.1 Motivating Example
Watering hole is a popular attack strategy targeting large
enterprises such as Apple [11] and Google [12]. The ad-
versaries do not directly attack the enterprise networks or
websites, which are well protected. Instead, they aim to
compromise the websites that are frequently visited by
the employees of the target enterprise, which are usually
much less protected. Recently, there have been a number
of real incidents of watering hole attacks, e.g., by compro-
mising Github [8] and CSDN [3]. There are exploit kits
(e.g., BeEF [2]) to make it easy to conduct such attacks.
In our example case, a developer in an enterprise opens
Firefox, and then uses Bing to look for a utility program
for file copying. The search engine returns a number of
relevant links to technical forums, blogs, wikis and online
articles. Some of these links further lead to other rele-
vant resources such as pages comparing similar programs.
Some pages host software for download. In many cases,
the software was uploaded by other developers. After
intensive browsing and researching, the developer settles
down on a forum that hosts not only the wanted software,
1112    26th USENIX Security Symposium
USENIX Association
but also many other interesting resources, including tor-
rents for a few tutorial videos. The developer downloads
the program and also a few torrents from the forum. Af-
ter the download, he starts to use the program. He also
uses a p2p software Transmission to download the videos
described by the torrents.
Unfortunately, the forum website was compromised,
targeting enterprises whose developers tend to use the
forum for technical discussion and information sharing.
The program downloaded, fcopy, is malicious. In addition
to the expected functionality, the malware creates a re-
verse TCP connection and provides a shell to the remote
attacker. The malware causes unusual network bandwidth
consumption and is eventually noticed by the administra-
tor of the enterprise. To understand the attack and prepare
for response, the administrator performs forensic analysis,
trying to identify the root cause and assess the potential
damage to the system. At the very beginning, the binary
file fcopy is the only evidence. Hence, the creation of the
file is used as the symptom event.
2.2 Traditional Solutions
Traditional techniques such as backtrackers [38, 39], audit
systems [10] and provenance-aware file systems [50, 55]
track the lineage of system objects or subjects without
being aware by the applications. These techniques col-
lect system subjects (e.g. processes and threads) and
objects (e.g. files, network sockets and pipes) information
at run time with system call hooking or Linux Security
Modules (LSM) [62], and construct dependency graph or
causal graph for inspection. Note that these two terms
are interchangeable in this paper. While they use differ-
ent approaches to trace system information, the graphs
generated by these systems are similar.
A general workflow for these techniques is as follows.
Starting from the given symptom subject or object, they
identify all the subjects and objects that the symptom di-
rectly and indirectly depends on using backtracking. They
also allow identifying all the effects induced by the root
cause using forward tracking. For the case mentioned
in §2.1, the administrator identifies the Firefox process
and all its data sources by backtracking, and then dis-
closes the downloaded files and the operations on these
files with forward tracking. Figure 1 shows the simpli-
fied graph generated. In this graph and also the rest of
the paper, we use diamonds to represent sockets, oval
nodes to represent files, and boxes to represent processes
or execution units. In Figure 1, many network sockets
point to the Firefox process, and the process points to a
large number of files including the torrent files and others
like fcopy, which reflect the browsing and downloading
behaviors of Firefox.
While we only show part of the original graph in Fig-
ure 1 for readability, the original graph contains more than
500 nodes in total, with most files and network socket
accesses being (undesirably) associated with the Firefox
and Transmission nodes. These bogus dependencies make
manual inspection extremely difficult.
2.3 Loop Based Partitioning Solutions
It was observed in [43] that the inaccuracy of traditional
approaches is mainly caused by long running processes,
which interact with many other subjects and objects dur-
ing their lifetime. Traditional approaches consider the en-
tire process execution as a node so that all the input/output
interactions become edges to/from the process node, re-
sulting in considerably large and inaccurate graphs. Take
the Transmission process as an example. It has depen-
dencies with many torrent files and network sockets, ob-
fuscating the true causalities (e.g., a torrent file and the
corresponding downloaded file).
Event loop based partitioning techniques [43, 45, 46]
leverage the observation that long running processes are
usually event driven and the whole process execution
can be partitioned by the event handling loops (through
binary instrumentation). They proposed the concept of
execution unit, which denotes one iteration of an event
handling loop. This fine-grained execution abstraction en-
ables accurate tracing of dependency relationship. It was
shown that these techniques can generate much smaller
and more accurate dependency graphs. However, these
techniques still have the following limitations that hinder
their application in the real-world.
Units Are Too Low Level. Assume the administrator
applies BEEP/ProTracer to the motivation case in §2.1.
He constructs the causal graph starting from the file fcopy.
He acquires the download event in Firefox, which is asso-
ciated with the web socket a.a.a.a. Then, he traces back
to the forum website, and eventually the search engine.
As part of the investigation, the administrator applies for-
ward tracking from the search engine page to understand
if other (potentially malicious) pages were accessed and if
other (potentially malicious) programs were downloaded
and used. Since the developer visited many links returned
by the search engine, the forward tracking includes many
web pages and their follow-ups in the resulting graph.
The simplified graph is shown in Figure 2.
In this case, Firefox is used for 5 minutes with 11 tabs
containing 7 websites. There are thousands of nodes
in the graph. This is because all user interactions like
scrolling the web pages, moving mouse pointer over a
link and clicking links are processed by unique event loop
iterations, each leading to a unit/node. Moreover, Fire-
fox has internal events including timer events to refresh
pages. As these events operate on DOM elements, they
are connected in the dependency graph due to memory
USENIX Association
26th USENIX Security Symposium    1113
Figure 1: Simplified causal graph for the case in §2.1 generated by traditional solutions (Tool in [16]).
dependencies, making the graph excessive.
The root cause of the limitation lies in that BEEP ex-
poses very low level semantics (i.e., event loop iterations)
in partitioning. The onus is on the user to chain low
level units to form high level tasks. Unfortunately, BEEP
graphs have little information to facilitate this process as
they lack high level semantic information such as which
high level task (e.g., tab) a low level unit belongs to.
Depending on Training. BEEP and ProTracer are train-
ing based due to the difficulty of binary analysis. It re-
quires intensive training to identify the event handling
loops and memory accesses that disclose dependencies
across units (e.g., one event loop inserts a task to the
queue which is later loaded and processed by another
event loop). The completeness of the training inputs is
hence critical. Otherwise, there may be missing or even
wrong causal relations. Note that providing source code
does not address this problem as identifying event han-
dling loops and cross-unit dependencies requires in-depth
understanding of low level program semantics, which is
much easier through dynamic analysis by observing con-
crete states than static analysis, in which everything is
abstract. Specifically, there are a large number of loops in
a program. Statically determining which ones are event
handling loops is difficult. Furthermore, while static anal-
ysis can identify memory dependencies, a lot of cross-unit
dependencies should be ignored as they have nothing to
do with the high level work flow (e.g., those caused by
memory management or statistics collection).
In our motivating example, we did not use the “Go
back" button in the initial training of Firefox. As a result,
we were not able to get the full causal chain in Figure 2,
which was broken at one web page that contains a lot of
clicking-link and going-back actions. We had to enhance
our training set by providing a going-back case.