1
-
with the automatically generated signatures.
Table I shows the ranks of the vulnerable functions in
OpenSSL, where “From” indicates the architecture that we
used to derive the bug signature, and “To” indicates the
architecture of the target program. Each cell contains the
ranking of both vulnerable functions (heartbeat for TLS and
DTLS). Table I shows that
the combination of semantic
hashes and BHB works well, giving almost perfect rankings.
For example, the highlighted cell shows that our algorithm
ranks the vulnerable TLS and DTLS functions in the MIPS
binary at rank 1 and 2, respectively, when searching with the
corresponding signature from an ARM binary.
Again, we observe that
the improved semantic hash
(k-MinHash) improves accuracy. E. g., for OpenSSL x86
vs. MIPS with the DTLS-signature, we noticed improved
ranks, because seven basic blocks had duplicated formulas,
which Multi-MinHash cannot detect (see Section III-C).
Searching from and to ARM and x86 works almost per-
fectly, while combinations with MIPS sometimes work a little
less well (e. g., for OpenSSL x86 vs. DD-WRT). Usually, due
to its RISC instruction set, MIPS has either more basic blocks
(about 13% more for BusyBox ARM vs. MIPS) or more
formulas (1.42 times for OpenSSL MIPS vs. x86).
2) BusyBox Vulnerabilities: In late 2013, a bug was dis-
covered in BusyBox versions prior to v1.21.1, where sub-
directories of /dev/ are created with full permissions (0777),
which allows local attackers to perform denial-of-service at-
tacks and to achieve local privilege escalation (CVE 2013-
1813 [38]). The affected function build_alias() is inlined
into the make_device() function, which complicates mat-
ters for techniques relying on function equivalence. Table II
shows that our technique succeeds in identifying similar code
in the context of inlining, where,
to function
matching, only a subarea of a function should be matched.
Note that the ranking is not perfect when searching in ARM
code, where make_device() has only 157 basic blocks,
with a bug signature from MIPS code (183 basic blocks).
in contrast
3) RouterOS Vulnerability: In 2013, a vulnerable function
in MikroTik’s RouterOS v5 and v6 was found in the
SSH daemon. Due to a missing length check in the method
getStringAsBuffer(), the attacker can trigger a seg-
mentation fault. This allows a remote heap corruption without
prior authentication, which can be leveraged to arbitrary code
execution [23]. RouterOS is available for both MIPS and x86.
Using the vulnerable function for either architecture as a bug
signature, we reliably found the vulnerable function for the
other architecture at rank 1. We obtained similar results for all
hashing methods, but omit the table due to space constraints.
4) SerComm Backdoor: Lastly, we show that our approach
can also be used in other contexts, such as ﬁnding known back-
doors. To demonstrate this, we search for a known backdoor in
SerComm-powered ﬁrmwares [41], which opens a shell once
it receives a special packet on TCP port 32764. Hardware by
SerComm is used by multiple router manufacturers (like Cisco,
Linksys and Netgear). We deﬁned the socket_read()
function as a bug signature and searched for similar backdoors
in MIPS-based Netgear ﬁrmware (DGN1000, DGN3500,
DM111Pv2, JNR3210). Table III shows that we ﬁnd the
backdoors reliably in all combinations.
5) libpurple Vulnerability: Up to this point, we only
showed case studies with full functions as signatures, even
though we do not consider this our primary use case. Our main
motivation for doing so lies in the fact that any hand-crafted
signature has to be justiﬁed, so as not to be dismissed as
tweaked for the particular example. Nevertheless, we feel the
need to highlight that, especially for bug search, full function
matching (as, e. g., done with BLEX [11]) is not sufﬁcient.
CVE-2013-6484 documents an attack that allows an attacker
to crash versions prior to v2.10.8 of Pidgin, a popular
instant messenger. Both the Windows version of Pidgin
and its Mac OS X counterpart Adium (v1.5.9) suffer from
this vulnerability. In this example, the vulnerable function
in Pidgin contained many basic blocks of other inlined
functions, whereas Adium did not inline them. Consequently,
the Pidgin function had 25% more basic blocks.
Intuitively, both functions differed signiﬁcantly, and par-
ticularly using the larger function as a bug signature may
introduce problems. Indeed, our tool—presumably similarly
to purely function-wise matching approaches, such as BLEX—
could not achieve good ranks for full function signatures. From
Windows to Mac OS X and vice versa we achieved rank
#165 and rank #33, respectively.
However, when choosing ten basic blocks by hand, we
achieved rank #1 in both cases. We did so in a methodical way:
We included all basic blocks from the function start through
the vulnerability, while avoiding the early-return error states.
D. Unpatched vs. Patched Code
We noticed that a patch typically introduces few changes
to a vulnerable function. This causes our approach to also
identify patched code parts as similar to the bug signature,
effectively causing false positives. In an experiment to tackle
this issue, we created two bug signatures: in addition to the
one for the vulnerable function, we also deﬁned a signature
for the patched function. Although both signatures will match
reasonably well, intuitively, the latter signature has a higher
similarity for patched code than the original bug signature.
Tab. IV shows that for the bugs in OpenSSL and BusyBox,
720720
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:33 UTC from IEEE Xplore.  Restrictions apply. 
TABLE IV: Unpatched/patched signature similarities with
Multi-MinHash in OpenSSL and BusyBox.
From → To
OpenSSL x86 → ReadyNAS (ARM)
v1.0.1f (unpatched) → v6.1.6 (unpatched)
v1.0.1g (patched) → v6.1.6 (unpatched)
v1.0.1f (unpatched) → v6.1.7 (patched)
v1.0.1g (patched) → v6.1.7 (patched)
BusyBox ARM → BusyBox x86
v1.20.0 (unpatched) → v1.20.0 (unpatched)
v1.21.1 (patched) → v1.20.0 (unpatched)
v1.20.0 (unpatched) → v1.21.1 (patched)
v1.21.1 (patched) → v1.21.1 (patched)
Entity
BusyBox, ARM
BusyBox, MIPS
BusyBox, x86
OpenSSL, ARM
OpenSSL, MIPS
OpenSSL, x86
Normalized Avg.
#BBs
60,630
67,236
65,835
14,803
14,488
14,838
10,000
28
35
51
8
9
12
6.2
Rank
Similarity
1
1
1
1
0.3152
0.1759
0.3021
0.3034
1
1
1
1
80.3
86.9
85.0
16.3
16.3
20.2
12.5
0.2676
0.1689
0.1658
0.2941
k-MH
1522
1911
1855
349.7
434.0
485.2
279.9
TABLE V: Runtime in minutes in the ofﬂine-phase.
IR-Gen. Multi-MH
either bug signature (patched or unpatched) ranked both soft-
ware versions at rank 1. However, in all cases, the unpatched
version is more similar to the “buggy” bug signature, and vice
versa (considerably in three cases, marginally in one). This
could give valuable information to an analyst deciding whether
he is looking at a false positive.
E. Performance
Lastly, we evaluate the performance and the scalability of
our system. Our approach has three computational phases (IR
generation, semantic hashing and signature search) for which
we will give separate performance evaluations.
IR generation: The IR formulas only need to be computed
once per binary. The runtime to describe the I/O behavior
increases linearly with the number of basic blocks, but varies
with each basic block’s complexity. If it consists only of a
jump, this step is considerably faster than for a basic block
with many instructions. Since both types of basic blocks
regularly appear, Table V shows the average timings achieved
in real-life programs, showing that formulas can be created in
less than an hour for all programs under analysis.
Semantic hashing: In the case of hashing, the number
of formulas in a basic block and their respective number
of input variables dominates the runtime. We thus limited
the number of samples to 3000, whereas we used fewer
samples for formulas with fewer input variables. The sample
set is sufﬁciently large to capture semantic differences and
the accuracy did not signiﬁcantly improve for larger sets. At
the same time, as shown in Table V, sampling and MinHash
of real-life programs scales. Clearly, the higher accuracy of
k-MinHash (see Table I) comes at the price of performance
degradation of a factor of ≈ 22.5 on average. Again, note
that this computation is a one-time-only effort and can be
parallelized trivially down to a basic block level.
Signature Search: The two previous steps represent one-
time costs and do not inﬂuence the overall performance as
much as this third step: the actual search phase. Recall that
we initially search for promising candidates for each basic
TABLE VI: Runtimes of the signature search.
BusyBox v1.20.0
ARM → MIPS
ARM → x86
OpenSSL v1.0.1f
MIPS → ARM
MIPS → x86
Normalized Avg.
Sig
157
157
25
25
1
# BBs
Runtime
Target Multi-MH
k-MH
70,041
66,134
14,803
14,838
10,000
230.6s
197.7s
754.0s
644.4s
14.2s
14.4s
0.3s
46.8s
46.9s
1.0s
block in a signature by comparing it against all basic blocks
in the target program. The runtime thus increases in a linear
fashion for both the number of basic blocks in the signature
(usually a few dozen) and the number of basic blocks in the
target program (usually in the order of 104).
Table VI gives exemple runtimes for the signature search
in various scenarios. Typically, the runtime is in the order
of minutes for the real-world use cases. In the worst case, it
took about 12.5 minutes to search for bugs with k-MinHash
in a MIPS-based BusyBox. The evaluations show that the
complexity of the signature has a high impact on the runtime.
V. DISCUSSION
This section discusses some of the remaining challenges of
our system, most of which we plan to address in future work.
A. Vulnerability Veriﬁcation
that our approach cannot verify that
One challenge that we already touched upon in Section IV
the code
is the fact
part that was found is actually vulnerable. Such an automatic
veriﬁcation would be ideal, but surely is a research topic
in itself and is outside the scope of this work. The ranking
produced by our system gives an ordered list of functions
that have to be manually inspected by an analyst to verify if
those functions are actually vulnerable. This way, the manual
process is greatly reduced, as the analyst will oftentimes ﬁnd
the vulnerability in the top-ranked functions.
In case a binary does not contain the bug that was searched,
the ranking scheme still gives a list of functions. Naturally, an
analyst would then fail to ﬁnd vulnerable functions, even when
inspecting all ranked functions. Ideally, we could give some
indication if there is a reasonable match at all. This could, e.g.,
be based on the similarity score, which represents the semantic
similarity between the bug signature and a function: If the
functions ranked ﬁrst have “low” similarities, this suggests
that even the best hits are not vulnerable.
In future work, we will investigate whether we can expand
our scheme with “similarity thresholds” that can separate
potential matches from non-matches in the ranking. The
heuristics that we used in Section IV-B are only a ﬁrst step. A
better, more reliable mechanism to determine actual matches
will allow for further use cases of our work, such as large-scale
binary searches to identify license violations.
B. False Negatives
A few challenges could cause false negatives in our ap-
proach, i.e., it would miss actual vulnerabilities. Note that
we explicitly exclude obfuscated binaries from our scope.
721721
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:33 UTC from IEEE Xplore.  Restrictions apply. 
We have shown that although common off-the-shelf compiler
optimizations may weaken detection results, the extent of this
is limited. For example, our method relies on basic blocks
being split in a similar way and does not tolerate substantial
changes to the CFG in the important (i.e., buggy) parts of the
code. We showed that these assumptions are indeed met in
many practical examples, even across processor architectures.
One of the core problems of comparing software at the
binary level is that its representation (even on a single architec-
ture) heavily depends on the exact build environment that was
used to compile the binary. Varying compilers have different
strategies to translate the same source code to binaries, as
they implement different optimization techniques (and levels).
In the following, we brieﬂy discuss some of the most common
optimization techniques and compiler idiosyncrasies and how
our system tackles them.
1) Register spilling: The number of general-purpose regis-
ters varies between the CPU architectures: x86 features 8 such
registers, legacy ARM 15, and MIPS 32. Architectures with
fewer registers typically need to spill registers more frequently,
i.e., they have to move data between memory and registers.
Na¨ıvely, this has an effect on the I/O pairs of basic blocks, and
thus complicates comparison between different architectures.
As described in Section III, we successfully addressed this
issue by ﬂattening nested memory indirections.
4) Common Subexpression Elimination: When compilers
eliminate common subexpressions, such as when optimizing
the expression (x ∗ y) − 2 ∗ (x ∗ y), neither the output value
nor the number of inputs change. However, our system will
create additional formulas for additional temporary variables
that the compiler may use.
5) Constant Folding: Our approach can easily deal with
constant folding, such as 2 + 4 becoming 6 at compile time.
Either way, using sampling, the output variables will have
equal values. This is an additional advantage of comparing
2) Function Inlining: Function inlining heavily changes
the CFG of a program and may thus become problematic
for our approach. However, if the bug signature covers the
inlined function, then our approach can still ﬁnd the code
parts. In fact, the larger context in which the vulnerable code
parts are embedded is not relevant for our approach, as long
as the sub-CFGs remain similar. Thus, as also demonstrated
with BusyBox, we can ﬁnd buggy code that has been
inlined (cf. Section IV-C2). Things become slightly worse if
the bug signature was derived from a function that included