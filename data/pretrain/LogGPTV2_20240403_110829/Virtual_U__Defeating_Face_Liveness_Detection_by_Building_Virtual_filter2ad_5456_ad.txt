### High False Rejection Rates in Face Authentication under Varying Illumination Conditions

We observed a very high false rejection rate when live users attempted to authenticate themselves under different illumination conditions. To test this, we registered the faces of five participants indoors on four mobile systems. Each user then attempted to log in to each system 10 times indoors and 10 times outdoors on a sunny day, and we recorded the number of successful logins in each environment for each system.

- **True Key and Mobius**:
  - Indoor Logins: 98% and 100% success rates, respectively.
  - Outdoor Logins: 96% and 100% success rates, respectively.

- **BioID and 1U App**:
  - Indoor/Outdoor Login Rates: 50%/14% and 96%/48%, respectively.

The high false rejection rates under outdoor illumination indicate that these two systems struggle significantly with authentication when the user's environment changes. Our impression is that 1U’s single-image user registration lacks the necessary training data to accommodate different illumination settings. BioID is highly sensitive to various factors, including head rotation and illumination, leading to many false rejections. (Possibly recognizing this, the makers of BioID allow three login attempts per session.)

Despite these challenges, as shown in Table 2, our method still effectively defeats the liveness detection modules of these systems given images of the user in the original illumination conditions, suggesting that all tested systems are vulnerable to our VR-based attack.

### Generalization and Robustness of the Attack

Our findings also suggest that our approach can successfully handle significant changes in facial expression, illumination, and, for the most part, physical characteristics such as weight and facial hair. Additionally, the method generalizes well across users regardless of gender or ethnicity. Given its effectiveness on a varied collection of real-world data, we believe the attack presented here represents a realistic security threat model that could be exploited today.

### Evaluating System Robustness

To gain a deeper understanding of the realism of this threat, we examined the conditions necessary for our method to bypass the various face authentication systems we tested. We also considered the main factors contributing to the failure cases of our method.

#### 4.1 Resolution and Viewing Angle

To further understand the limitations of the proposed spoofing system, we tested its robustness against resolution and viewing angle, which are crucial factors for the social media photos users upload.

##### 4.1.1 Blurry, Grainy Pictures Still Say A Lot

To assess our ability to spoof face authentication systems using low-resolution images, we textured the 3D facial models of our sample users with an indoor, frontal view photo. This photo was downsampled at various resolutions, ensuring the distance between the user’s chin and forehead ranged from 20 to 50 pixels. We then attempted to spoof the True Key, BioID, and KeyLemon systems with these downsampled photos. If successful at a certain resolution, it implies that the resolution leaks the user’s identity information to our spoofing system. The spoofing success rates for various image resolutions are shown in Figure 8.

- **Results**: Our approach robustly spoofs face authentication systems when the height of the face in the image is at least 50 pixels. If the resolution is less than 30 pixels, the photo is likely too low-resolution to reliably encode useful features for identifying the user. In our sample set, 88% of users had more than six online photos with a chin-to-forehead distance greater than 100 pixels, easily satisfying the resolution requirement of our proposed spoofing system.

##### 4.1.2 A Little to the Left, a Little to the Right

To evaluate the robustness of the proposed system against head rotation, we first determined the maximum yaw angle allowed for our system to spoof baseline systems using a single image. For all 20 sample users, we collected multiple indoor photos with yaw angles varying from 5 degrees (approximately frontal view) to 40 degrees (significantly rotated view). We then performed 3D reconstruction for each image and each user on the same three face authentication systems. The spoofing success rate as a function of head rotation is illustrated in Figure 9 (left).

- **Results**: The proposed method successfully spoofs all baseline systems when the input image has a largely frontal view. As the yaw angle increases, it becomes more difficult to infer the user’s frontal view, leading to a decreased spoofing success rate.

##### 4.1.3 For Want of a Selfie

The results in Figure 9 (left) show that our success rate drops dramatically if given only a single image with a yaw angle larger than 20 degrees. However, we argue that high-resolution side-angle views can serve as base images for facial texturing if additional low-resolution frontal views of the user are available. We tested this hypothesis by using the rotated images from the previous section along with one or two low-resolution frontal view photos (chin-to-forehead distance of 30 pixels). We then reconstructed each user’s facial model and used it to spoof our baseline systems. Alone, the provided low-resolution images provide insufficient texture for spoofing, and the higher-resolution side view does not provide adequate facial structure. As shown in Figure 9 (right), by using the low-resolution front views to guide 3D reconstruction and then using the side view for texturing, the spoofing success rate for large-angle head rotation increases substantially. From a practical standpoint, low-resolution frontal views are relatively easy to obtain, often found in publicly posted group photos.

### Seeing Your Face Is Enough

Our approach not only defeats existing commercial systems with liveness detection but fundamentally undermines the process of liveness detection based on color images. To illustrate this, we used our method to attack the recently proposed authentication approach of Li et al. [34], which achieves a high rate of success in guarding against video-based spoofing attacks. This system adds another layer to motion-based liveness detection by requiring that the movement of the face in the captured video be consistent with the data obtained from the motion sensor of the device. Fortunately, as discussed in §3, the data consistency requirement is automatically satisfied with our virtual reality spoofing system because the 3D model rotates in tandem with the camera motion.

- **Central to Li et al. [34]’s approach** is building a classifier that evaluates the consistency of captured video and motion sensor data. The learned classifier is used to distinguish real faces from spoofed ones. Since their code and training samples have not been made public, we implemented our own version of Li et al. [34]’s liveness detection system and trained a classifier with our own training data. We refer the reader to [34] for a full overview of the method.

Following the methodology of [34], we captured video samples (and inertial sensor data) of approximately 4 seconds from the front-facing camera of a mobile phone. In each sample, the phone was held at a distance of 40 cm from the subject and moved back-and-forth 20 cm to the left and right. We captured 40 samples of real subjects moving the phone in front of their face, 40 samples where a pre-recorded video of a user was presented to the camera, and 30 samples where the camera was presented with a 3D reconstruction of a user in our VR environment. For training, we used a binary logistic regression classifier trained on 20 samples from each class, with the other samples used for testing. Due to the relatively small size of our training sets, we repeated our classification experiments four times, with random train/test splits in each trial, and reported the average performance over all four trials.

- **Results**: The results of our experiments are shown in Table 3. For each class (real user data, video spoof data, and VR data), we report the average number (over four trials) of test samples classified as real user data. We experimented with three different training configurations. The first row shows the results when using real user data as positive samples and video spoof data as negative samples. In this case, the real-versus-video identification is almost perfect, matching the results of [34]. However, our VR-based attack is able to spoof this training configuration nearly 100% of the time. The second and third rows show the classification performance when VR spoof data is included in the training data. In both cases, our approach defeats the liveness detector in 50% of trials, and the real user data is correctly identified as such less than 75% of the time.

All three training configurations clearly indicate that our VR system presents motion features close to real user data. Even if the liveness detector of [34] is specifically trained to look for our VR-based attack, one out of every two attacks will still succeed, with the false rejection rate also increasing. Any system using this detector will need to require multiple login attempts to account for the decreased recall rate; allowing multiple login attempts, however, provides our method more opportunities to succeed. Overall, the results indicate that the proposed VR-based attack successfully spoofs Li et al. [34]’s approach, which is, to our knowledge, the state of the art in motion-based liveness detection.

### Defense in Depth

While current facial authentication systems succumb to our VR-based attack, several features could be added to confound our approach. Here, we detail three such features: random projection of light patterns, detection of minor skin tone fluctuations related to pulse, and the use of illuminated infrared (IR) sensors. Of these, the first two could still be bypassed with additional adversary effort, while the third presents a significantly different hardware configuration that would require non-trivial alterations to our method.

- **Light Projection**: The principle is simple: using an outward-facing light source (e.g., the flashlight commonly included on camera-equipped mobile phones), flash light on the user’s face at random intervals. If the observed change in illumination does not match the random pattern, face authentication fails. An adversary could modify our proposed approach to detect the random flashes of light and, with low latency, subsequently add rendered light to the VR scene. Random projections of structured light [62], i.e., checkerboard patterns and lines, would increase the difficulty of such an attack, as the 3D-rendering system must quickly and accurately render the projected illumination patterns on a model. However, structured light projection requires specialized hardware typically not found on smartphones and similar devices, decreasing the feasibility of this mitigation.

- **Pulse Detection**: Recent computer vision research [2, 58] has explored the prospect of video magnification, which transforms micro-scale fluctuations over time into strong visual changes. One application is detecting human pulse from a standard video of a human face. The method detects small, periodic color changes related to pulse in the region of the face and amplifies this effect, making the face appear to undergo strong changes in brightness and hue. This amplification could be used as an additional method for liveness detection by requiring that the observed face have a detectable pulse. Similar ideas have been applied to fingerprint systems that check for blood flow using light emitted from beneath a prism. An attacker using our proposed approach could simply add subtle color variation to the 3D model to approximate this effect. Nevertheless, such a method would provide another layer of defense against spoofed facial models.

- **Infrared Illumination**: Microsoft released Windows Hello as a more personal way to sign into Windows 10 devices with just a look or a touch. The new interface supports biometric authentication, including face, iris, or fingerprint authentication. The platform includes Intel’s RealSense IR-based, rather than a color-based, facial authentication method. In principle, their approach works similarly to contemporary face authentication methods but uses an IR camera to capture a video of the user’s face. The attack presented in this paper would fail to bypass this approach because typical VR displays are not built to project IR light; however, specialized IR display hardware could potentially be used to overcome this limitation.

One limiting factor that may make IR-based techniques less common, especially on mobile devices, is the requirement for additional hardware to support this enhanced form of face authentication. As of this writing, only a handful of personal computers support Windows Hello. Nevertheless, the use of infrared illumination offers intriguing possibilities for the future.

### Takeaway

In our opinion, it is highly unlikely that robust facial authentication systems will be able to operate using solely web/mobile camera input. Given the widespread nature of high-resolution personal online photos, today’s adversaries have a goldmine of information at their disposal for synthetically creating fake face data. Moreover, even if a system can robustly detect a certain type of attack—be it using a paper printout, a 3D-printed mask, or our proposed method—generalizing to all possible attacks will increase the possibility of false rejections and limit the overall usability of the system. The strongest facial authentication systems will need to incorporate non-public imagery of the user that cannot be easily printed or reconstructed (e.g., a skin heat map from special IR sensors).

### Discussion

Our work outlines several important lessons for both the present and future states of security, particularly as it relates to face authentication systems. First, our exploitation of social media photos to perform facial reconstruction underscores the notion that online privacy of one’s appearance is tantamount to online privacy of other personal information, such as age and location. The ability of an adversary to recover an individual’s facial characteristics through online photos is an immediate and very serious threat, albeit one that clearly cannot be completely neutralized in the age of social media. Therefore, it is prudent that face recognition tools become increasingly robust against such threats to remain a viable security option in the future.

At a minimum, it is imperative that face authentication systems be able to reject synthetic faces with low-resolution textures, as we show in our evaluations.