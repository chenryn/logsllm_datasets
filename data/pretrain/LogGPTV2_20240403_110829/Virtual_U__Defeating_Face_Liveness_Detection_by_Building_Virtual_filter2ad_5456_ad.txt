a very high false rejection rate when live users attempt
to authenticate themselves in different illumination con-
ditions. To test this, we had 5 participants register their
faces indoors on the 4 mobile systems.8 We then had
each user attempt to log in to each system 10 times in-
doors and 10 times outdoors on a sunny day, and we
counted the number of accepted logins in each environ-
ment for each system. True Key and Mobius, which we
found were easier to defeat, correctly authenticated the
users 98% and 100% of the time for indoor logins, re-
spectively, and 96% and 100% of the time for outdoor
logins. Meanwhile, the indoor/outdoor login rates of
BioID and the 1U App were 50%/14% and 96%/48%,
respectively. The high false rejection rates under outdoor
illumination show that the two systems have substantial
difficulty with their authentication when the user’s envi-
ronment changes. Our impression is that 1U’s single-
image user registration simply lacks the training data
necessary to accommodate to different illumination set-
tings. BioID is very sensitive to a variety of factors in-
cluding head rotation and illumination, which leads to
many false rejections. (Possibly realizing this, the mak-
ers of BioID therefore grant the user 3 trials per login
attempt.) Even so, as evidenced by the second column
in Table 2, our method still handily defeats the liveness
detection modules of these systems given images of the
user in the original illumination conditions, which sug-
gests that all the systems we tested are vunerable to our
VR-based attack.
Our findings also suggest that our approach is able to
successfully handle significant changes in facial expres-
sion, illumination, and for the most part, physical charac-
teristics such as weight and facial hair. Moreover, the ap-
proach appears to generalize to users regardless of gen-
der or ethnicity. Given that it has shown to work on a var-
ied collection of real-world data, we believe that the at-
8As it is a desktop application, KeyLemon was excluded.
506  25th USENIX Security Symposium 
USENIX Association
tack presented herein represents a realistic security threat
model that could be exploited in the present day.
Next, to gain a deeper understanding of the realism
of this threat, we take a closer look at what conditions
are necessary for our method to bypass the various face
authentication systems we tested. We also consider what
main factors contribute to the failure cases of our method.
4.1 Evaluating System Robustness
To further understand the limitations of the proposed
spoofing system, we test its robustness against resolu-
tion and viewing angle, which are two important factors
for the social media photos users upload. Specifically,
we answer the question: what is the minimum resolu-
tion and maximum head rotation allowed in an uploaded
photo before it becomes unusable for spoofing attacks
like ours? We further explore how low-resolution frontal
images can be used to improve our success rates when
high-resolution side-view images are not available.
4.1.1 Blurry, Grainy Pictures Still Say A Lot
To assess our ability to spoof face authentication systems
when provided only low-resolution images of a user’s
face, we texture the 3D facial models of our sample users
using an indoor, frontal view photo. This photo is then
downsampled at various resolutions such that the dis-
tance between the user’s chin and forehead ranges be-
tween 20 and 50 pixels. Then, we attempt to spoof
the True Key, BioId, and KeyLemon systems with fa-
cial models textured using the down-sampled photos.9 If
we are successful at a certain resolution, that implies that
that resolution leaks the user’s identity information to our
spoofing system. The spoofing success rate for various
image resolutions is shown in Figure 8.
The result indicates that our approach robustly spoofs
face authentication systems when the height of the face in
the image is at least 50 pixels. If the resolution of an up-
loaded photo is less than 30 pixels, the photo is likely of
too low-resolution to reliably encode useful features for
identifying the user. In our sample set, 88% of users had
more than 6 online photos with a chin-to-forehead dis-
tance greater than 100 pixels, which easily satisfies the
resolution requirement of our proposed spoofing system.
4.1.2 A Little to the Left, a Little to the Right
To identify the robustness of the proposed system against
head rotation, we first evaluate the maximum yaw angle
allowed for our system to spoof baseline systems using a
9We skip analysis of Mobius because its detection method is similar
to True Key, and our method did not perform as well on True Key. We
also do not investigate the robustness of our method in the 1U system
because of our inability to spoof this system using online photos.
Figure 8: Spoofing success rate with texture taken from photos
of different resolution.
single image. For all 20 sample users, we collect multi-
ple indoor photos with yaw angle varying from 5 degrees
(approximately frontal view) to 40 degrees (significantly
rotated view). We then perform 3D reconstruction for
each image, for each user, on the same three face au-
thentication systems. The spoofing success rate for a
single input image as a function of head rotation is il-
lustrated in Figure 9 (left). It can be seen that the pro-
posed method successfully spoofs all the baseline sys-
tems when the input image has a largely frontal view. As
yaw angle increases, it becomes more difficult to infer
the user’s frontal view from the image, leading to a de-
creased spoofing success rate.
4.1.3 For Want of a Selfie
The results of Figure 9 (left) indicate that our success rate
falls dramatically if given only a single image with a yaw
angle larger than 20 degrees. However, we argue that
these high-resolution side-angle views can serve as base
images for facial texturing if additional low-resolution
frontal views of the user are available. We test this hy-
pothesis by taking, for each user, the rotated images from
the previous section along with 1 or 2 low-resolution
frontal view photos (chin-to-forehead distance of 30 pix-
els). We then reconstruct each user’s facial model and
use it to spoof our baseline systems. Alone, the pro-
vided low-resolution images provide insufficient texture
for spoofing, and the higher-resolution side view does
not provide adequate facial structure. As shown in Fig-
ure 9 (right), by using the low-resolution front views to
guide 3D reconstruction and then using the side view for
texturing, the spoofing success rate for large-angle head
rotation increases substantially. From a practical stand-
point, low-resolution frontal views are relatively easy to
obtain, since they can often be found in publicly posted
group photos.
USENIX Association  
25th USENIX Security Symposium  507
Figure 9: Spoofing success rate with different yaw angles. Left: Using only a single image at the specified angle. Right: Supple-
menting the single image with low-resolution frontal views, which aid in 3D reconstruction.
4.2 Seeing Your Face Is Enough
Our approach not only defeats existing commercial sys-
tems having liveness detection — it fundamentally un-
dermines the process of liveness detection based on color
images, entirely. To illustrate this, we use our method
to attack the recently proposed authentication approach
of Li et al. [34], which obtains a high rate of success
in guarding against video-based spoofing attacks. This
system adds another layer to motion-based liveness de-
tection by requiring that the movement of the face in the
captured video be consistent with the data obtained from
the motion sensor of the device. Fortunately, as discussed
in §3, the data consistency requirement is automatically
satisfied with our virtual reality spoofing system because
the 3D model rotates in tandem with the camera motion.
Central to Li et al. [34]’s approach is to build a classi-
fier that evaluates the consistency of captured video and
motion sensor data. In turn, the learned classifier is used
to distinguish real faces from spoofed ones. Since their
code and training samples have not been made public,
we implemented our own version of Li et al. [34]’s live-
ness detection system and trained a classifier with our
own training data. We refer the reader to [34] for a full
overview of the method.
Following the methodology of [34], we capture video
samples (and inertial sensor data) of ∼4 seconds from
the front-facing camera of a mobile phone. In each sam-
ple, the phone is held at a distance of 40cm from the
subject and moved back-and-forth 20cm to the left and
right. We capture 40 samples of real subjects moving
the phone in front of their face, 40 samples where a pre-
recorded video of a user is presented to the camera, and
30 samples where the camera is presented with a 3D re-
construction of a user in our VR environment. For train-
ing, we use a binary logistic regression classifier trained
on 20 samples from each class, with the other samples
used for testing. Due to the relatively small size of our
training sets, we repeat our classification experiments 4
times, with random train/test splits in each trial, and we
report the average performance over all four trials.
Real
Training Data
Real+Video
19.50 / 20
Real+Video+VR 14.00 / 20
Real+VR
14.75 / 20
Video
0.25 / 20
0.00 / 20
—
VR
9.75 / 10
5.00 / 10
5.00 / 10
Table 3: Number of testing samples classified as real users.
Values in the first column represent true positive rates, and the
second and third columns represent false positives. Each row
shows the classification results after training on the classes in
the first column. The results were averaged over four trials.
The results of our experiments are shown in Table 3.
For each class (real user data, video spoof data, and VR
data), we report the average number (over 4 trials) of test
samples classified as real user data. We experiment with
three different training configurations, which are listed in
the first column of the table. The first row shows the re-
sults when using real user data as positive samples and
video spoof data as negative samples.
In this case, it
can easily be seen that the real-versus-video identifica-
tion is almost perfect, matching the results of [34]. How-
ever, our VR-based attack is able to spoof this training
configuration nearly 100% of the time. The second and
third rows of Table 3 show the classification performance
when VR spoof data is included in the training data. In
both cases, our approach defeats the liveness detector in
50% of trials, and the real user data is correctly identified
as such less than 75% of the time.
All three training configurations clearly point to the
fact that our VR system presents motion features that are
close to real user data. Even if the liveness detector of
[34] is specifically trained to look for our VR-based at-
tack, 1 out of every 2 attacks will still succeed, with the
false rejection rate also increasing. Any system using
508  25th USENIX Security Symposium 
USENIX Association
this detector will need to require multiple log-in attempts
to account for the decreased recall rate; allowing multi-
ple log-in attempts, however, allows our method more
opportunties to succeed. Overall, the results indicate
that the proposed VR-based attack successfully spoofs
Li et al. [34]’s approach, which is to our knowledge the
state of the art in motion-based liveness detection.
5 Defense in Depth
While current facial authentication systems succumb to
our VR-based attack, several features could be added to
these systems to confound our approach. Here, we detail
three such features, namely random projection of light
patterns, detection of minor skin tone fluctuations related
to pulse, and the use of illuminated infrared (IR) sensors.
Of these, the first two could still be bypassed with addi-
tional adversary effort, while the third presents a signif-
icantly different hardware configuration that would re-
quire non-trivial alterations to our method.
Light Projection The principle of using light projec-
tion for liveness detection is simple: Using an outward-
facing light source (e.g., the flashlight commonly in-
cluded on camera-equipped mobile phones), flash light
on the user’s face at random intervals. If the observed
change in illumination does not match the random pat-
tern, then face authentication fails. The simplicity of this
approach makes it appealing and easily implementable;
however, an adversary could modify our proposed ap-
proach to detect the random flashes of light and, with
low latency, subsequently add rendered light to the VR
scene. Random projections of structured light [62], i.e.,
checkerboard patterns and lines, would increase the diffi-
culty of such an attack, as the 3D-rendering system must
be able to quickly and accurately render the projected
illumination patterns on a model. However, structured
light projection requires specialized hardware that typi-
cally is not found on smart phones and similar devices,
which decreases the feasibility of this mitigation.
Pulse Detection Recent computer vision research [2,
58] has explored the prospect of video magnification,
which transforms micro-scale fluctuations over time into
strong visual changes. One such application is the detec-
tion of human pulse from a standard video of a human
face. The method detects small, periodic color changes
related to pulse in the region of the face and then am-
plifies this effect such that the face appears to undergo
strong changes in brightness and hue. This amplification
could be used as an additional method for liveness detec-
tion by requiring that the observed face have a detectable
pulse. Similar ideas have been applied to fingerprint sys-
tems that check for blood flow using light emitted from
beneath a prism. Of course, an attacker using our pro-
posed approach could simply add subtle color variation
to the 3D model to approximate this effect. Nevertheless,
such a method would provide another layer of defense
against spoofed facial models.
Infrared Illumination Microsoft released Windows
Hello as a more personal way to sign into Windows 10
devices with just a look or a touch. The new interface
supports biometric authentication that includes face, iris,
or fingerprint authentication. The platform includes In-
tel’s RealSense IR-based, rather than a color-based, fa-
cial authentication method. In principle, their approach
works in the same way as contemporary face authentica-
tion methods, but instead uses an IR camera to capture
a video of the user’s face. The attack presented in this
paper would fail to bypass this approach because typi-
cal VR displays are not built to project IR light; how-
ever, specialized IR display hardware could potentially
be used to overcome this limitation.
One limiting factor that may make IR-based tech-
niques less common (especially on mobile devices) is
the requirement for additional hardware to support this
enhanced form of face authentication. Indeed, as of this
writing, only a handful of personal computers support
Windows Hello.10 Nevertheless, the use of infrared illu-
mination offers intriguing possibilities for the future.
Takeaway
In our opinion, it is highly unlikely that ro-
bust facial authentication systems will be able to op-
erate using solely web/mobile camera input. Given
the widespread nature of high-resolution personal online
photos, today’s adversaries have a goldmine of informa-
tion at their disposal for synthetically creating fake face
data. Moreover, even if a system is able to robustly de-
tect a certain type of attack – be it using a paper printout,
a 3D-printed mask, or our proposed method – generaliz-
ing to all possible attacks will increase the possibility of
false rejections and therefore limit the overall usability of
the system. The strongest facial authentication systems
will need to incorporate non-public imagery of the user
that cannot be easily printed or reconstructed (e.g., a skin
heat map from special IR sensors).
6 Discussion
Our work outlines several important lessons for both the
present state and the future state of security, particularly
as it relates to face authentication systems. First, our ex-
ploitation of social media photos to perform facial re-
construction underscores the notion that online privacy
of one’s appearance is tantamount to online privacy of
other personal information, such as age and location.
10See “PC platforms that support Windows Hello” for more info.
USENIX Association  
25th USENIX Security Symposium  509
The ability of an adversary to recover an individual’s fa-
cial characteristics through online photos is an immedi-
ate and very serious threat, albeit one that clearly can-
not be completely neutralized in the age of social media.
Therefore, it is prudent that face recognition tools be-
come increasingly robust against such threats in order to
remain a viable security option in the future.
At a minimum, it is imperative that face authentica-
tion systems be able to reject synthetic faces with low-
resolution textures, as we show in our evaluations. Of