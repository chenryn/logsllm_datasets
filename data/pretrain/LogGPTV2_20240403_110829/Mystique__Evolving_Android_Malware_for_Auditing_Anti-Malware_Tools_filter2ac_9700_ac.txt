i=1
Di(x))/ | Sd |
(3)
where Di(x) returns 1 if the malware of x is detected by the tool di
and | Sd | denotes the number of the tools.
5.1 Feature Selection via IBEA
Rather than encode three objectives into one weighted ﬁtness
function, we treat all the three objectives equally and solve Multi-
objective Optimization Problems (MOPs) using the Pareto domi-
nance relation [30].
A k-objective optimization problem could be written in the fol-
lowing form2 (in our case, k = 3):
Minimize (cid:126)F = (F1(x), F2(x), ..., Fk(x))
(4)
where (cid:126)F is a k-dimensional objective vector and Fi(x) is the value
of (cid:126)F for ith objective.
Deﬁnition 4 Given two chromosomes (cid:126)x,(cid:126)y ∈ Bn and an objective
vector (cid:126)F : Bn → Rk,(cid:126)x dominates(cid:126)y ((cid:126)x ≺(cid:126)y) if
∀i ∈ {1, ...,k} Fi((cid:126)x) (cid:54) Fi((cid:126)y)
∃j ∈ {1, ...,k} Fj((cid:126)x) < Fj((cid:126)y)
(5)
(6)
otherwise(cid:126)x (cid:54)≺(cid:126)y
2Evasiveness and detectability need to be minimized, but aggressiveness
needs to be maximized. In implementation, maximizing is minimizing the
negative value of the objective.
369Figure 3: Multi-objective guided malware generation
Algorithm 1: Multi-objective guided malware generation
Input: featureModel: the feature model of Android malware, maxIter:
the maximum number of iterations of the generation process,
popSize: the size for each generation
Output: allMal: a list of malicious apps with different feature
combinations
1 allMal ← ∅;
2 for 1 to maxIter do
3
4
5
6
7
newGeneration ← ∅;
if allMal == ∅ then
for 1 to popSize do
malware ← randomFeatureSelection(featureModel);
newGeneration ← newGeneration∪{malware};
8
9
10
11
12
13
14
15
16
17
18
19
20
else
for newGeneration.size() < popSize do
select i,j ∈ [1,|allMal|];
malware = ibea crossover(allMal[i],allMal[j]);
newGeneration ← newGeneration∪{malware};
select k ∈ [1,|allMal|];
malware = ibea mutation(allMal[k]);
newGeneration ← newGeneration∪{malware};
for mal ∈ newGeneration do
evaluate(mal);
for mali ∈ newGeneration do
if ∃malj | malj ∈ newGeneration ∧ i (cid:54)= j • malj ≺ mali then
newGeneration ← newGeneration\ mali ;
if newGeneration ⊂ allMal then
allMal ← allMal∪ newGeneration;
break;
21
22
23
24 return allMal;
Deﬁnition 5 Given chromosomes(cid:126)x and a set of chromosomes S(cid:126)x,(cid:126)x
is non-dominated iff
∀(cid:126)xi ∈ S(cid:126)x (cid:126)xi (cid:54)≺(cid:126)x
(7)
Algorithm 1 shows how IBEA guides the feature selection. The
input of this algorithm is the feature model of Android malware, the
number of iterations for the generation process, and the population
size. In the beginning, it creates the initial population, randomly
selecting features in the feature model (line 4 to 7), otherwise we
can generate new malware derived from the existing malware (line 9
to 15). First, it selects two candidates with a probability and do
an ibea crossover operation (line 11) to generate a new malicious
app. Second, it selects one candidate in a probability and do an
ibea mutation operation (line 14) to generate a new malicious app.
Once the generation is created, all apps in this generation are evalu-
ated by the proposed three objectives to get the ﬁtness value (line 16,
17). The algorithm utilizes the Pareto dominance relation to remove
malware that is dominated by others in the evaluation (line 18 to
20). The algorithm will stop once the selected features converges
(line 21) or exceeds the maximal times of iteration (line 2).
5.2 Code Assembly
In this section, we elaborate how to assemble code according to
the selected features. The input of this step is a list of features. The
output of this step is the assembled source code of the malware.
The translation from selected features to corresponding source
code is inspired by Aspect-Oriented Programming (AOP) [33]. One
feature has at least one implementation. For example, the source
feature TELEPHONY::IMEI can be implemented by invoking the
Android APIs—getSystemService, getDeviceId, in sequence. All the
implementations are integrated into a candidate app, and we se-
lect speciﬁc implementations in terms of the selected features to
generate a malicious app. Meanwhile, in the code generation, we
also write scripts to automatically check constraints from feature
dependencies and context, and generate the conﬁguration ﬁles, such
as AndroidManifest.xml.
Constraints in Assembly. To assure the soundness and validity of
the assembled code, we have the following rules:
• Feature dependency constraint. Feature model has features
dependencies inside, which are constraints to be satisﬁed in code
assembly. For example, the permission feature android.permission.
READ PHONE STATE is needed for feature getDeviceId. When
a component attempts to start an activity via ICC, in order to
maintain the activity list in the history stack, it has to set the ﬂag
FLAG ACTIVITY NEW TASK.
• Context constraint. We consider extra constraints to be veriﬁed
in code assembly, speciﬁcally, some operations can only occur in
a speciﬁc context. For example, the incoming SMS message is
only accessed in the context of onReceive, and the receipt of ICC in
a service is onStartCommand. All these constraints are not feature-
relevant at requirement level, but speciﬁc to implementation. All
these constraints should be satisﬁed to avoid runtime exception.
5.3 Evasion Application
For information leakage, AFs and EFs are orthogonally separated,
which implies the independence between the choice of AFs and EFs.
After AFs and EFs are selected by IBEA, the EFs are categorized
into two types: ﬂow based ones or transformation based ones.
Evasion based on source-sink ﬂow. The evasion is applied in
constructing the code, and the purpose is to complicate the ﬂow
between the source and the sink. One malicious behavior may
stretch through multiple components. Therefore, we employ the
evasion features (§ 4.2) to obfuscate ﬂows. For example, Android
Lifecycle is used to complicate control ﬂows and ICC can be used
to complicate both control and data ﬂows.
Evasion based on transformation. This evasion is applied after the
step of code assembly. DROIDCHAMELEON can directly work with
the deployment package of Android app. For the 12 transformations
mentioned (§ 4.2), we provide 12 EFs. If EFs are selected by IBEA
in step 1, we will later apply the corresponding transformations.
5.4 Objective Evaluation
According to Deﬁnition 1-3, we calculate the ﬁtness value for
each generated malicious app. The ﬁtness value is used as the
guidance to the feature selection in the next generation. We inspect
all apps in the new generation. If no new feature combination is
produced, the evolution process converges and would be terminated
M1 (1) Feature Selection (2) Code Assembly (3) Evasion Application (4) Objective Evaluation Evasiveness Aggressiveness Detectability F1 F2 F3 F4 M2 M3 M4 crossover  M5 mutation Multi-objective guided input output F1 Feature model F2 F3 F4 F5 F6 M1 Aggressiveness Evasiveness M2 M3 M4 M5 Malware variants Implementation I1 I2 I3 I4 getSysService getDevId Code Template 370Figure 4: The working process of an AMT
as line 21 in Algorithm 1. Finally, we get the collection of new
generated malware that serves the benchmark for auditing AMTs.
6. BRIEF ON ANTI-MALWARE TOOLS
In this section, we explore the capabilities of off-the-shelf AMTs.
Fig. 4 shows the working process of a typical AMT. Basically, it
contains Collector which collects evidence (§ 6.1.1) from Android
ecosystem. The evidence is sent to a Detector which determines
whether the app is malicious or not. Generally, the detector makes
the decision based on Knowledge Base (§ 6.1.2). Additionally (as
shown by dashed line), the conﬁrmed malware can be supplemented
into the knowledge base to update the knowledge base. Finally,
according to our survey and testing on AMTs, we list detection
mechanisms adopted by mainstream AMTs in Section 6.2.
6.1 Detection Mechanism
6.1.1 Evidence Collection
AMTs need to collect and extract evidence as proof to identify
Android malware. Evidence can be collected from various sources
in Android ecosystem, ranging from different program entities (e.g.,
AndroidManifest.xml and class ﬁles) to various program output of
dynamic execution.
The source of evidence are threefold: manifest ﬁle, binary code
and runtime information. In the manifest ﬁle, AMTs can collect as
evidence the information: used permissions [7, 21, 43], hardware
components [7], Android components [7], and Intent ﬁlters [7];
AMTs can extract from binary code Android APIs [7, 9, 25, 27],
constant strings [7, 51], control ﬂow [6, 23, 27, 43], data ﬂow [20,
23, 27], and program dependency graph [52]; Some AMTs may run
apps in a real device or an emulator to collect the execution traces
of Android apps [11]. As malware often launches attacks via HTTP
or SMS, [19] collects the HTTP behaviors to ﬁngerprint Android
apps. Interested users can refer to [1] for more details.
As the attack of privacy leakage involves both data and operations,
some attack hints can be found in all the above types of evidence.
Some other types of attack are more closely relevant to some certain
types of evidence, e.g., the attack of functionality abuse is mainly
behavior-oriented and highly identiﬁable based on AA and AB.
6.1.2 Knowledge-base Detection
The knowledge base is the basis and criteria of distinguishing
malware from benignware. After obtaining the evidence, AMTs that
use the knowledge base conﬁrm malware by the following strategies:
Signature of Known Malware (SKM). An abundance of malware
collections [2, 7, 55] is publicly available for industrial and academic
research. Such abundance of malware enables to fast detect malware
based on signatures or features. For example, DROIDSIFT extracts
behavior graph from known malware. Many commercial anti-virus
tools use the hash value of malware as the signature [22]. However.
approaches based on exact matching with known malware (e.g.,
comparing hash value) are not resistent to new variants.
Attack Pattern (AP). To overcome the limitation of signature based
detection, existing AMTs can leverage the knowledge of attacks,
including attack targets, attack techniques, attack camouﬂages and
so forth. We herein call it attack pattern [14, 20] — generally, some
form of modeling of attack behaviors with aforementioned evidence.
6.2 Anti-malware Tools & Hypothesis
According to the general analysis techniques employed in detec-
tion, AMTs can be categorized into the following four types. Some
tools, such as [9, 25, 26, 52] that use both of static analysis and
machine learning, are categorized into machine learning approach.
Machine Learning. Owing to the popularity and availability, we
mainly analyze and audit the following machine learning approaches:
DREBIN [7], ADAGIO [26], ALLIX et al. [6] and REVEALDROID [25].
State Analysis. Considering the efﬁciency and ease of setting up,
most of existing approaches rely on static analysis. Since we con-
struct malware of privacy leakage, we consider the following open-
source detection tools targeting privacy leakage: SCANDROID [24],
FLOWDROID [8], DROIDSAFE [27] and ICCTA [34].
Dynamic Analysis. Approaches based on dynamic analysis can
be accurate at rumtime, but they face the difﬁculty in triggering
malware and the scalability issue. Besides, they are hard to set up.
We only audit the famous tool TAINTDROID [20] on this side.
Anti-virus Tools. We use the online service of VIRUSTOTAL [4] to
audit the state-of-the-art Anti-virus tools. VIRUSTOTAL provides
the recent version of 57 anti-virus tools.
In this study, we focus on evaluation of different detection mech-
anisms rather than comparison of the particular tools. The above
list of AMTs may not be complete, but we try to cover the existing
detection mechanisms. Before auditing AMTs, We propose the
following four commonsense hypothesis :
Hypothesis 1 Mainstream AV tools, which rely on signature or
pattern based approaches, cannot detect the variants of the existing
malware, even those with similar attack features.
Hypothesis 2 Evasion features in privacy leakage, e.g., ﬂow com-
plication, can help the malware to evade the detection, despite which
detection approach is used by the AMTs.
Hypothesis 3 AMTs based on dynamic analysis should be more
accurate than those based on static analysis or machine learning,
regardless of the time and the difﬁculty in setup.
Hypothesis 4 The human check of malware in online app store,
involving both static and dynamic analysis, is the most complete
and sound solution to detect malware in reality.
7. MALWARE AND AMT EVALUATION
MYSTIQUE is implemented in about 12K lines of Java code.
Moreover, test scripts written for experiments are of 1K lines of
Shell and Python. All the experiments are conducted on a Ubuntu
14.04 machine with Intel Xeon(R) CPU E5-16500 and 16G memory.
In this section, our experiments are aimed to answer the following
research questions:
RQ1. Are the modularized AFs and EFs valid? Is the generated
malware valid and workable?
RQ2. Can we use the generated malware to audit AMT? Are the
Hypothesis 1 to 4 in Section 6.2 accepted or rejected?
RQ3. Is our generated malware representative? How useful is
MYSTIQUE in generating malware?
7.1 Evaluation Subjects
To evaluate the effectiveness of MYSTIQUE and the defense ca-
pabilities of AMTs, we generate multiple sets of malicious apps
for different evaluation targets with MYSTIQUE. The malware is
grouped based on its attack targets, and covers multiple attack and
Knowledge Base Android Ecosystem *.java *.xml traces messages … Collector Detector evidence Mal. rule, Sig…. malware 371evasion features. On the other hand, we use the malware to test
the defense capabilities of AMTs, especially, the state-of-the-art
public AMTs introduced in Section 6.2. The evaluation subjects are
described in the following two aspects.
Offence: to evaluate the strength of the malware generated using
MYSTIQUE. Each malware sample has at least one attack target,
which is listed in Section 4.1. We give feature labels for malware to
assess the attack capabilities. All the features used in MYSTIQUE
feature model are manually summarized from the 1,260 malware
samples in GENOME. Totally, we have 266 attack features and 14
evasion features in our feature model (§ 4.1). We sketch a diagram
in Fig. 5 of the cumulative distribution for each kind of AF deﬁned
in GENOME. Since EFs are difﬁcult to be categorized from the code,
we do not show the distribution of EFs.
Defense:.
to evaluate the four types of tools (§ 6.2) to cover a
complete protection from three aspects: untrusted app analysis,
install-time checking, and continuous runtime monitoring [49]. We