from the per-packet feature sequences. This module periodically
polls the required information from the high speed packet parser
module with a fixed time interval. After acquiring the extracted
per-packet features, it encodes the per-packet feature sequences
as vectors and extracts the sequential information via frequency
domain. These features with low redundancy are provided for the
statistical clustering module. However, it is difficult to extract the
frequency domain features of traffic in high throughput networks in
realtime because of the various complicated, irregular, and dynamic
flow patterns [14, 63]. We cannot apply deep learning models, e.g.,
recurrent neural networks, to extract features due to their long
processing latency though they can extract more richer features for
detection. We will present the details of this module in Section 4.1.
Automatic Parameter Selection Module. This module calcu-
lates the encoding vector for the feature extraction module. We
decide the encoding vector by solving a constrained optimization
problem that reduces the mutual interference of different per-packet
features. In the training phase, this module acquires the per-packet
feature sequences and solves an equivalent Satisfiability Modulo
Theories (SMT) problem to approximate the optimal solution of
the original problem. By enabling automatic parameter selection,
Frequency Domain Feature Extraction ModuleStatistical Clustering Module13EncodingVectorAutomatic Parameter Selection ModuleHigh Speed Packet Parser Module2Training OnlyDetectionPacketsâ€¦â€¦Per-packetFeature SequencesA. Packet Feature Encodingâ€¦B. Fourier Trans. on FramesReducingFeature ComplexityReducing the Scale of Features C. Log. Trans. on Modulus LAddressingNumeric InstabilityâŠ—=NormalAbnormalClustering the Frequency Domain FeaturesFrequency DomainFeaturesSession 12C: Traffic Analysis and Side ChannelsCCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea3433we significantly reduce the manual efforts for parameter selection.
Therefore, we can fix and accurately set the encoding vector in
the detection phase. We will describe the details of the module in
Section 4.2.
Statistical Clustering Module. In this module, we utilize a light-
weight statistical clustering algorithm to learn the patterns of the
frequency domain features from the feature extraction module. In
the training phase, this module calculates the clustering centers of
the frequency domain features of benign traffic and the averaged
training loss. In the detection phase, this module calculates the dis-
tances between the frequency domain features and the clustering
centers. Whisper detects traffic as malicious if the distances are
significantly larger than the training loss. We will elaborate on the
statistical clustering based detection in Section 4.3.
4 DESIGN DETAILS
In this section, we present the design details of Whisper, i.e., the
design of three main modules in Whisper.
4.1 Frequency Feature Extraction Module
In this module, we extract the frequency domain features from high
speed traffic. We acquire the per-packet features of ğ‘ packets from
the same flow by polling the high speed packet parser module. We
use the mathematical representation similar to Bartos et al. [4] to
denote the features. We use ğ‘ (ğ‘–) and ğ‘€ to indicate the ğ‘–ğ‘¡â„ per-packet
feature and the number of per-packet features, respectively. Matrix
S denotes the per-packet features of all packets, where sğ‘–ğ‘˜ is defined
as ğ‘–ğ‘¡â„ packetâ€™s ğ‘˜ğ‘¡â„ property:
S = [ğ‘ (1), . . . , ğ‘ (ğ‘–), . . . , ğ‘ (ğ‘€)] =
(1)
ğ‘ 11
...
ğ‘ ğ‘ 1
 .
Â· Â· Â·
. . .
Â· Â· Â·
ğ‘ 1ğ‘€
...
ğ‘ ğ‘ ğ‘€
ğ‘€
ğ‘˜=1
Packet Feature Encoding. We perform a linear transformation
ğ‘¤ on S to encode the features of a packet to a real number ğ‘£ğ‘–. ğ‘£
denotes the vector representation of traffic:
ğ‘£ = Sğ‘¤ = [ğ‘£1, . . . , ğ‘£ğ‘–, . . . , ğ‘£ğ‘]T,
ğ‘£ğ‘– =
ğ‘ ğ‘–ğ‘˜ğ‘¤ğ‘˜ .
(2)
The feature encoding reduces the scale of features, which signifi-
cantly reduces the processing overhead of Whisper. In Section 4.2,
we will describe how Whisper automatically selects parameters for
the encoding vector ğ‘¤.
Vector Framing. Now we segment the vector representation with
the step length of ğ‘Šseg. The goal of segmentation is to reduce the
complexity of the frequency domain features by constraining the
long-term dependence between packets. If the frames are exces-
sively long, the frequency domain features will become too complex
to learn in the statistical learning module. ğ‘ğ‘“ denotes the number
of the frames. We obtain the following equations:
ğ‘“ğ‘– = ğ‘£[[(ğ‘– âˆ’ 1) Ã— ğ‘Šseg : ğ‘– Ã— ğ‘Šseg]]
(cid:22) ğ‘
(cid:23)
.
ğ‘ğ‘“ =
ğ‘Šseg
(1 â‰¤ ğ‘– â‰¤ ğ‘ğ‘“ ),
(3)
(4)
Discrete Fourier Transformation. In the next step, we perform
the Discrete Fourier Transformation (DFT) on each frame ğ‘“ğ‘– to
extract the sequential information via frequency domain and reduce
the information loss incurred by the flow-level methods. We can
acquire the frequency features of each frame as follows:1
ğ¹ğ‘– = F (ğ‘“ğ‘–)
(1 â‰¤ ğ‘– â‰¤ ğ‘ğ‘“ ),
ğ¹ğ‘–ğ‘˜ =
âˆ’ğ‘— 2ğœ‹ (ğ‘›âˆ’1) (ğ‘˜âˆ’1)
ğ‘Šseg
ğ‘“ğ‘–ğ‘›ğ‘’
(1 â‰¤ ğ‘˜ â‰¤ ğ‘Šseg),
ğ‘Šseg
ğ‘›=1
(5)
(6)
where ğ¹ğ‘–ğ‘˜ is a frequency component of ğ‘–ğ‘¡â„ frame with the frequency
of 2ğœ‹(ğ‘˜ âˆ’ 1)/ğ‘Šseg. Note that, all frequency features output by DFT
are vectors with complex numbers, which cannot be used directly
as the input for machine learning algorithms.
Calculating the Modulus of Complex Numbers. We transform
the complex numbers to real numbers by calculating the modu-
lus for the frequency domain representation. For simplicity, we
transform ğ¹ğ‘–ğ‘˜ to a coordinate plane representation:
ğ¹ğ‘–ğ‘˜ = ğ‘ğ‘–ğ‘˜ + ğ‘—ğ‘ğ‘–ğ‘˜,
ğ‘ğ‘–ğ‘˜ =
ğ‘ğ‘–ğ‘˜ =
ğ‘“ğ‘–ğ‘› cos 2ğœ‹ (ğ‘›âˆ’1)(ğ‘˜âˆ’1)
âˆ’ğ‘“ğ‘–ğ‘› sin 2ğœ‹ (ğ‘›âˆ’1)(ğ‘˜âˆ’1)
ğ‘Šseg
ğ‘Šseg
ğ‘Šseg
ğ‘Šseg
ğ‘›=1
ğ‘›=1
(7)
(8)
.
We calculate the modulus for ğ¹ğ‘–ğ‘˜ as ğ‘ğ‘–ğ‘˜ in (9). For the ğ‘–ğ‘¡â„ frame,
we select the first half of the modulus as vector ğ‘ƒğ‘–. Because the
transformation results of DFT are conjugate, the first half and the
second half are symmetrical. Thus, we can obtain:
(1 â‰¤ ğ‘˜ â‰¤ ğ‘Šseg),
(ğ¾ğ‘“ =
(cid:22)ğ‘Šseg
(10)
(cid:23)
(9)
ğ‘–ğ‘˜
ğ‘ğ‘–ğ‘˜ = ğ‘2
ğ‘–ğ‘˜ + ğ‘2
ğ‘ƒğ‘– = [ğ‘ğ‘–1, . . . , ğ‘ğ‘–ğ¾ğ‘“ ]T
ğ¹ğ‘–ğ‘˜ = ğ¹âˆ—
+ 1),
ğ‘–(ğ‘Šsegâˆ’ğ‘˜) â‡’ ğ‘ğ‘–ğ‘˜ = ğ‘ğ‘–(ğ‘Šsegâˆ’ğ‘˜) .
2
(11)
Logarithmic Transformation. To make the frequency domain
features to be numerically stable [23] and prevent float point over-
flow during the machine learning model training, we perform a
logarithmic transformation on ğ‘ƒğ‘–, and use constant ğ¶ to adjust the
range of the frequency domain features:
ln(ğ‘ƒğ‘– + 1)
ğ¶
(1 â‰¤ ğ‘– â‰¤ ğ‘ğ‘“ ),
ğ‘…ğ‘– =
Rğ¾ğ‘“ Ã—ğ‘ğ‘“ = [ğ‘…1, . . . , ğ‘…ğ‘–, . . . , ğ‘…ğ‘ğ‘“ ].
(12)
(13)
As the output of the features extraction module, the ğ‘–ğ‘¡â„ column
component of R is the frequency domain features of the ğ‘–ğ‘¡â„ frame.
Matrix R is the input for the statistical clustering module.
Take an example, we collect three types of benign traffic (90%)
mixed with the malicious traffic (10%) in Wide Area Network (WAN).
We select 1500 continuous packets (ğ‘ = 1500) from each type of
traffic and extract three per-packet features (ğ‘€ = 3) including the
packet length, the protocol type, and the arriving time interval.
We fix the framing length ğ‘Šseg = 30. Therefore, ğ‘ğ‘“ = 50 and
ğ¾ğ‘“ = 16. Then we perform a min-max normalization operation on
the frequency domain features R and map the results to the RGB
space. We visualize the frequency domain features that are similar
to the Spectrogram in speech recognition [1]. As shown in Figure 2,
1 ğ‘— denotes an imaginary number.
Session 12C: Traffic Analysis and Side ChannelsCCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea3434(a) Benign TLS traffic and side-channel attack traffic
(b) Benign UDP traffic and SSL DoS traffic
(c) Outbound NAT traffic and LowRate TCP DoS traffic
Figure 2: We map the frequency domain features, which are extracted from the traffic with three types of typical attacks, to the
RGB space, and observe that a small number of malicious packets incur significant changes in the frequency domain features.
of (17). For the ğ‘–ğ‘¡â„ per-packet feature, we perform a min-max nor-
malization on ğ‘ ğ‘– and use ğ‘›ğ‘– to indicate the normalized vector. We
list constrains (19). And we obtain the satisfied (SAT) solutions of
the SMT problem and maximize the following objective:
ğ‘¤ğ‘€ğ‘›ğ‘€ğ‘˜ âˆ’ ğ‘¤1ğ‘›1ğ‘˜ âˆ’
2ğ‘¤ğ‘–ğ‘›ğ‘–ğ‘˜ âˆ’ ğ‘¤ğ‘–âˆ’1ğ‘›(ğ‘–âˆ’1)ğ‘˜ âˆ’ ğ‘¤ğ‘–+1ğ‘›(ğ‘–+1)ğ‘˜,
[ğ‘Šğ‘šğ‘–ğ‘›,ğ‘Šğ‘šğ‘ğ‘¥]
ğµ
ğ‘¤ğ‘–+1ğ‘›(ğ‘–+1)ğ‘˜
ğ‘¤ğ‘–âˆ’1ğ‘›(ğ‘–âˆ’1)ğ‘˜ + ğ‘¤ğ‘–+1ğ‘›(ğ‘–+1)ğ‘˜ .
(18)
(19)
we observe that the area associated with the frequency domain
features of the malicious traffic is significantly lighter than that of
the benign traffic.
4.2 Automatic Parameters Selection Module
Now we determine the encoding vector ğ‘¤ for the feature extraction
module that uses ğ‘¤ to encode the per-packet feature sequences
and acquires the vector representation of the traffic. In general, we
formulate the encoding vector selection problem as a constrained
optimization problem, and transform the original problem into an
equivalent SMT problem. We approximate the optimal solution of
the original problem through solving the SMT problem.
We assume that we can find a set of continuous functions to
describe the changes of each kind of the per-packet feature ğ‘ (ğ‘–).
Thus, we consider all obtained per-packet features are the samples
of the continuous functions, which are denoted as â„ğ‘–(ğ‘¡) (1 â‰¤ ğ‘– â‰¤ ğ‘€).
We need to find a vector ğ‘¤ to amplify and superpose all these
functions. Our key optimization objective is to minimize mutual
interference and bound the overall range when superposing the
functions. We can first bound the range of encoding vector ğ‘¤ and
the range of the superposition function in the following:
ğ‘Šğ‘šğ‘–ğ‘› â‰¤ ğ‘¤ğ‘– â‰¤ ğ‘Šğ‘šğ‘ğ‘¥
(1 â‰¤ ğ‘– â‰¤ ğ‘€),
ğ‘€
ğ‘–=1
ğ‘¤ğ‘–â„ğ‘–(ğ‘¡) â‰¤ ğµ,
(14)
(15)
where ğ‘Šğ‘šğ‘–ğ‘›, ğ‘Šğ‘šğ‘ğ‘¥, ğµ are constants. We constrain the order pre-
serving properties of the functions to ensure that different types
of per-packet features do not interfere with each other when the
feature extraction module performs packet encoding:
(1 â‰¤ ğ‘– â‰¤ ğ‘€ âˆ’ 1).
(16)
Second, we optimize ğ‘¤ to maximize the distances between the
functions so that we can minimize the mutual interference of the
per-packet features and bound the ranges of all the functions. There-
fore, under the constrains of (14) (15) (16), we obtain the optimiza-
tion object:
ğ‘¤ğ‘–â„ğ‘–(ğ‘¡) â‰¤ ğ‘¤ğ‘–+1â„ğ‘–+1(ğ‘¡)
ğ‘¤ğ‘€â„ğ‘€(ğ‘¡) âˆ’ ğ‘¤1â„1(ğ‘¡)dğ‘¡ âˆ’
|2ğ‘¤ğ‘–â„ğ‘–(ğ‘¡) âˆ’ ğ‘¤ğ‘–+1â„ğ‘–+1(ğ‘¡) âˆ’ ğ‘¤ğ‘–âˆ’1â„ğ‘–âˆ’1(ğ‘¡)|dğ‘¡ .
(17)
In practice, we cannot determine the convexity of the optimiza-
tion object because the closed-form representations of â„ğ‘–(ğ‘¡) are
not available. Thus, we reform the origin constrained optimization
problem to a Satisfiability Modulo Theories (SMT) problem (19)
with optimization object (18) to approximate the optimal solution
âˆ« +âˆ
0
Ë†ğ‘¤ = arg max
âˆ« +âˆ
0
ğ‘€âˆ’1
ğ‘–=2
ğ‘
(cid:101)ğ‘¤ = arg max
ğ‘€âˆ’1
ğ‘˜=1
ğ‘–=2
subjects to:
ğ‘¤ğ‘–
ğ‘€
âˆˆ
ğ‘¤ğ‘–ğ‘›ğ‘–ğ‘˜ â‰¤
â‰¤
â‰¤
ğ‘–=1
ğ‘¤ğ‘–ğ‘›ğ‘–ğ‘˜
2ğ‘¤ğ‘–ğ‘›ğ‘–ğ‘˜
Note that, we reform the absolute value operation in the opti-
mization object (17) into constrains (19) because most SMT solvers
do not support absolute value operations.
4.3 Statistical Clustering Module
Now we utilize the statistical clustering algorithm to learn the pat-
terns of the frequency domain features obtained from the feature
extraction module with the selected parameters. We train the statis-
tical clustering algorithm with only benign traffic. In the training
phase, this module calculates the clustering centers of the frequency
domain features and the averaged training loss. In order to improve
the robustness of Whisper and reduce false positive caused by the
extreme values, we segment the frequency domain feature matrix
R with a sampling window of length ğ‘Šğ‘¤ğ‘–ğ‘›. We use ğ‘ğ‘¡ to denote
the number of samples and ğ‘™ to denote the start points. We average
the sampling window on the dimension of the feature sequence
and use ğ‘Ÿğ‘– to indicate the input of the clustering algorithm. We can
obtain:
ğ‘™ = ğ‘–ğ‘Šğ‘¤ğ‘–ğ‘›
(0 â‰¤ ğ‘– < ğ‘ğ‘¡), ğ‘ğ‘¡ =
,
(20)
(cid:22) ğ‘ğ‘“
(cid:23)
ğ‘Šğ‘¤ğ‘–ğ‘›
ğ‘Ÿğ‘– = mean(R[[ğ‘™ : ğ‘™ + ğ‘Šğ‘¤ğ‘–ğ‘›]]).
(21)
We perform the statistical clustering algorithm and acquire all
clustering centers to represent the benign traffic patterns. We use
ğ¶ğ‘˜ to denote the ğ¾ğ¶ clustering centers, where (1 â‰¤ ğ‘˜ â‰¤ ğ¾ğ¶), and
then calculate the averaged training loss. For each ğ‘Ÿğ‘–, we find the
closest clustering center as Ë†ğ¶ğ‘– and we take averaged L2-norm as
01020304050051015Side-channelAttackBenignEncryptedTraï¬ƒc01020304050051015SSLDoSAttackBenignVideoTraï¬ƒc01020304050051015Low-rateDoSAttackBenignOutboundNATTraï¬ƒcSession 12C: Traffic Analysis and Side ChannelsCCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea3435the training loss:
Ë†ğ¶ğ‘– = arg min
ğ¶ğ‘˜
âˆ¥ğ¶ğ‘˜ âˆ’ ğ‘Ÿğ‘–âˆ¥2
(1 â‰¤ ğ‘– â‰¤ ğ‘ğ‘¡),
(cid:13)(cid:13)ğ‘Ÿğ‘– âˆ’ Ë†ğ¶ğ‘–(cid:13)(cid:13)2 .
(22)
(23)
ğ‘ğ‘¡
ğ‘–=1
train_loss =
1
ğ‘ğ‘¡
In the detection phase, this module calculates the distances be-
tween the frequency domain features of traffic and the clustering
centers. For each given frequency domain feature, we sample ğ‘ğ‘¡
segments on R with length ğ‘Šğ‘¤ğ‘–ğ‘›, which is the same as the training
phase. We can find the closest clustering center Ë†ğ¶ğ‘– as an estimate
of ğ‘Ÿğ‘–. We calculate the L2-norm as the estimation error:
(1 â‰¤ ğ‘˜ â‰¤ ğ¾ğ¶).
(24)
If the estimation error lossğ‘– â‰¥ (ğœ™ Ã— train_loss), we can conclude
that the statistical clustering algorithm cannot understand the fre-
quency domain features of the traffic, which means the traffic is
malicious.