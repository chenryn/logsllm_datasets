–
2
–
9
45,892
–
–
–
45,903
misconﬁgured devices, we want to emphasize that we treated
the topic carefully by following the RFC-recommended way
for obtaining the external IP address [71, Section 11.6]. This
involves requesting a short-lived mapping for obtaining the
bound external IP address, which in complex setups cannot be
known before the mapping has already been made. As such,
we sent a legitimate request to these devices that follows the
standard. For the actual measurement, we chose the unlikely
used TCP port 9 (discard) with a short-lived lifetime (in
our case one second) as instructed in the RFC. Again, we
extensively tested this request
in
different conﬁgurations to make sure that it does not create
any unintended side effects.
in our lab environment
B. Evaluation
1) Responsive PCP Endpoints: Our Internet-wide scans
revealed a total of 625,057 exposed endpoints. The results
(shown in Table IV) show that a majority of 89 % of all re-
sponding servers supported only NAT-PMP by responding with
UNSUPP_VERSION. Almost all PCP-supporting (“version 2”)
servers furthermore responded with NOT_AUTHORIZED, in-
dicating that this feature is either disabled or that we are not
allowed to access it.
2) Checking for THIRD PARTY Support: The results (see
Table IV, rightmost column) indicate that some 31,000 servers
reported back as expected, and to our surprise, there were no
servers not supporting this option or they responded with a
different error code, or simply silently ignored our request.
The lower number of responsive hosts is at least partially due
to IP address churn, as the follow-up scans did take place one
day after the initial ANNOUNCE scan.
3) Creating a Port Mapping: This scan resulted in similar
observations as during our initial ANNOUNCE scan: Most of
the services reported that we are not authorized to perform this
action, concluding that the PCP server population seems to be
securely conﬁgured against this type of attack. Nevertheless,
we want to note that these over 600,000 hosts should not be
responsive to our probes in the ﬁrst place.
C. Hijacking Internal Trafﬁc
We found that also a small population of misconﬁgured
NAT-PMP enabled routers exist which report an internal IP
address as their external IP address. First reported by Hart [31]
in 2014, this confusion may allow creating mappings which
cause trafﬁc destined to the router’s given port to whoever
creates the mapping. Although not as bad as having the ability
to allow arbitrary port mappings, this may still allow hijacking
trafﬁc (e. g., DNS queries) destined to the router. To analyze
this aspect, we downloaded recent scan results from Rapid7’s
NAT-PMP scan and found that 1,3 % of NAT-PMP supporting
devices (out of about 480,000) were still reporting an RFC1918
IP address as their external address.
D. NAT-PMP/PCP Key Findings
In conclusion, our ﬁndings can be summarized as follows:
while we received responses from several hundred thousands
of NAT-PMP hosts that should not be exposed to the Internet,
we could not conﬁrm that these could be misused for accessing
internal hosts, as was the case with UPnP. Only a fraction of
these hosts supported the newer PCP, indicating to a better
security posture of newer installations. Therefore, we hope that
this part of our paper will help raise knowledge of this rather
obscure protocol and safer conﬁgurations that do not expose
these devices at all will be deployed in the future.
IV. NETWORK PROXIES
After having extensively studied NAT traversal protocols,
we now focus on network proxies as a complimentary exam-
ple of application-layer middlebox protocols given that such
proxies are typically used to route packets between network
edges. In contrast to the previously discussed protocols, which
form permanent port mappings by changing the routing tables
to allow external connections to hosts behind NAT, proxies act
as temporal conduits between the client and its targets, passing
messages in between. Hence proxies are more often used to
control access to external networks, e. g., for blocking access to
unwanted websites or ﬁltering malicious content. Although the
importance of network proxies has decreased due to Tor [17]
and cheap VPN solutions, there are still many open network
proxies which can for example be used to bypass geo-blocking
by a simple conﬁguration change.
In this section, we cover two types of network proxies
in detail: HTTP proxies (Section IV-A) and SOCKS proxies
(Section IV-B). After introducing these protocols, we describe
our measurement approach in Section IV-C. We ﬁrst focus on
ﬁnding proxy candidates and how we check if they are proxies,
followed by checking if they are vulnerable for allowing access
to internal networks. We evaluate our ﬁndings on the proxy
ecosystem in Section IV-D, which is followed by our ﬁndings
on services hosted on internal networks of vulnerable proxy
systems and ﬁnally complement our Internet-wide scans by
crawling for Internet proxies.
A. HTTP Proxies
HTTP proxy servers act as an intermediary between the
client and the target server, and there are two ways deﬁned in
RFC 2616 [21] to do that:
(i) Using an absolute URI, where the client requests the
full URI instead of the path (i. e., requesting GET http:
//localhost/ HTTP/1.1). In this case, the proxy acts as
an intermediary by conversing HTTP with both participants.
The HTTP 1.1 standard mandates that even non-proxying
implementations must accept this absolute addressing form for
future compatibility.
8
(ii) Using the more powerful CONNECT method [37],
[4], in which the proxy acts merely as a conduit between
the endpoints, allowing non-HTTP protocols (e. g., TLS for
HTTPS, or SSH [56]) to be tunneled through it. In response
to connect requests, the proxy either responds with a “200”
status indicating that the tunnel has been established, or an
error message (such as “407 Proxy Authentication Required”).
The standard HTTP error codes [23] are used with both
methods. For brevity and the wider applicability (i. e., not be-
ing limited to HTTP requests), we concentrate on CONNECT-
supporting proxies, if not noted otherwise.
B. SOCKS Proxies
SOCKS is a protocol for relaying arbitrary, TCP-based
communication on the Internet and was presented ﬁrst by
Koblas [38] in 1992. Currently, there are two major, wire-
incompatible (for comparison, packet headers are shown in
Figure 4 and the status codes in Table XIII in Appendix B)
versions of SOCKS: version 4 (as deﬁned by Lee [41]) and
the ﬁrst IETF-standardized version 5 (RFC 1928 [44], 1996),
which both use port 1080 for communication. We now brieﬂy
introduce both deployed versions of the protocol and explain
the main differences between them.
1) SOCKS4(A): SOCKS4 [38] deﬁnes only two com-
mands: CONNECT for establishing a tunnel and BIND for
creating a binding to allow connections behind the proxy to
connect back to the original client (e. g., for FTP active mode).
To establish a tunnel, the client sends a CONNECT request
to the proxy (potentially containing the username), which
either grants the connection or responds with an error (Ta-
ble XIII in Appendix B lists all standardized error codes). If
the connection is granted, the server replaces the destination
address and the port with those it has bound for the outgoing
connection and the communication between the endpoints can
begin. SOCKS4A [42] extends SOCKS4 with DNS resolving
capabilities by using a non-routable IP address as the destina-
tion, and appending a domain name ending with a null-byte
after the username.
2) SOCKS5: SOCKS5 [44] is the ﬁrst RFC-deﬁned version
which was created to ﬁx several limitations of SOCKS4. Most
notably, it adds support for authentication negotiation, IPv6
and UDP proxying (UDP ASSOCIATE command), and the
ability to delegate DNS resolving to the proxy.
In the initial handshake, the client offers its list of sup-
ported authentication methods for the server to choose from.
Depending on the chosen method (e. g., no authentication or
username & password [43]), the authentication protocol has
to be completed before SOCKS commands can be sent. As
we concentrate on open proxies, we omit further details of
different authentication methods. To proxy UDP packets, the
server assigns an external port, on which the client shall send
UDP datagrams to be forwarded to the target destination.
The created UDP conduit is kept open as long as the control
connection stays alive.
C. Measurement Approach
Our measurement approach contains three separate steps,
as illustrated in Figure 3. In the ﬁrst step (Section IV-C1)
Fig. 3.
Proxy measurement approach:  Scan the Internet with ZMap
and complement the results with crawling. The responsive hosts are added
to a work queue for the next step. (Sec. IV-C1).  The work queue is
read simultaneously and our scanner checks if the host is an open proxy
(Sec. IV-C2).   If the given host is an open proxy, we check if it allows
requesting internal resources (Sec. IV-C3).
we locate potential proxy candidates by Internet scans or by
crawling, and add them into our working queue. In the second
step, we verify if the host is a proxy (Section IV-C2), followed
by checking for internal access (Section IV-C3) if the given
host is an open proxy.
1) Finding Internet Proxies: To ﬁnd Internet proxies, we
leverage a two-step analysis pipeline. We run ZMap SYN
scan on corresponding ports and seed the work queue for our
crawler similarly to our previous scans. However, instead of
having a single worker, we launched 20 concurrent crawlers
reading from the same work queue. Each scan was ﬁnished
in approximately eight hours in sync with the corresponding
ZMap scan. All tests were run sequentially within one week
in February 2019.
Based on the related works ([47], [69], [57], [61], see
summary in Table XII) and our investigation on popular
proxy software, we decided to scan the following ports: 1080
(SOCKS), 3128 (Squid), 8080 (common HTTP proxy port),
8118 (Privoxy), 8123 (Polipo), and 8888 (Tinyproxy). We
emphasize that before we conducted any scans, we extensively
9
❶ Finding Internet Proxies (Section IV-C1)Proxybroker CrawlingSYN scan (ZMap)811888888123312880801080Our ScannerProxy Sources❷ Verifying Openness (Section IV-C2)❸ Checking for Internal Access (Section IV-C3)Judge8044322345CONNECT JUDGE:80 HTTP/1.1HTTP/1.1 200 OKGET /?type=HTTP-CONNECT&proxy=192.0.2.12:80&.. HTTP/1.1{"src": "192.0.2.12:80",  "type": "HTTP-CONNECT",  "token": "7461726a617061756c69"   .. }Proxy 192.0.2.12:80Establish TCP connection192.168.123.80:1080Proxy 192.0.2.12:80CONNECT 127.0.0.1:22 HTTP/1.1Services listening on localhost22HTTP/1.1 200 OKSSH-2.0-OpenSSH_7.9p1 Debian-6Establish TCP connection21232580TABLE V.
OVERVIEW OF TESTED NETWORK PROXIES
Name
3proxy
Srelay
antinat
Dante
S
K
C
O
S
Squid (3128)
P
T
T
H
Tinyproxy (8888)
Polipo (8123)
Privoxy (8118)
Security in default conﬁguration
Example conﬁg requires authentication, disallows
connections to 127.0.0.1
Example conﬁg given, but not directly usable.
Allows everything if started directly.
Default: allow in only from RFC1918 ranges,
disallows connections to 127.0.0.1
Default conﬁg has variety of examples, blocks
everything per default
Binds to all interfaces. Inbound from RFC1918.
Allowed ports: 443, 80, 21, 70, 210, 280, 488,
591, 777, 1025-65535, 443 (connect)
Binds to all interfaces. Inbound from 127.0.0.1.
CONNECT only on 443 and 563
Binds only to 127.0.0.1. Allows GET (80-100,
1024-65535), CONNECT (22, 80, 109-110, 143,
443, 873, 993, 995, 2401, 5222, 9418)
Binds only to 127.0.0.1
Updated
18.4.2018
25.12.2017
20.2.2017
6.2.2017
2.7.2018
1.1.2016
15.5.2014
26.8.2016
tested all speciﬁcally mentioned proxies in our laboratory
environment
to understand their behavior and restrictions.
Table V lists these implementations.
2) Verifying Openness: For verifying the functionality of
proxies, we try to use them to access a website (“proxy judge”)
created and hosted by ourselves. To this end, we encode some
information (including query type, proxy address, and port)
to the requested URIs. This information is mirrored back to
us with some additional information (e. g., the requesting IP
address and request headers). Based on the responses, we tag
each proxy (consisting of a tuple (cid:104)ipaddress, port(cid:105)) with the
information we use to summarize our ﬁndings. We call a proxy
open if it has delivered us our expected payload. If we receive
an unexpected response, we differentiate between the protocol-
conforming responses (e. g., requiring us to authenticate by
sending an HTTP 407 status or SOCKS error) and non-
conforming (e.g., a regular web-page being delivered). We
mark the former as proxy and the latter responsive, accordingly.
a) Verifying HTTP Proxies: To verify the functionality
of proxies, we issued GET requests on the following three ports
on our judge server: (i) 80 to verify regular HTTP functionality,
(ii) 443 to conﬁrm if HTTPS requests are possible, and (iii)
22345 to verify if the target port can be arbitrarily chosen. On
port 443, we serve clients with TLS encryption using our self-
signed certiﬁcate, and we do not check for the validity of the
certiﬁcate in our scanner. For each potential proxy, we launch
these three requests simultaneously. When receiving an HTTP
response (no matter the response content or status code), we
launch two more requests with CONNECT, one for port 80
and one for port 22345. The ﬁrst check is used to ascertain if
such requests are generally allowed (also on non-TLS ports)
and the second one if we are limited to speciﬁc port ranges.
b) Verifying SOCKS Proxies: We use the same GET
request payloads and probe the same ports for both SOCKS
versions. In case of a successful SOCKS connection, we
create additional requests based on the protocol version: (i) for
SOCKS4, we also try to check for DNS resolving (SOCKS4A)
support by requesting our proxy judge with its domain name,
and (ii) for SOCKS5, we try to verify DNS support as well
as support for UDP and IPv6 connections. To verify UDP
connectivity, we send a datagram containing information about
the proxy similarly to our HTTP queries to our judge server.
Furthermore, to understand if identd authentication is actively
used for SOCKS4, we also host a program capturing the
incoming requests on TCP port 113.
3) Checking for Internal Access: This phase is done only
on open proxies, with the additional requirement for HTTP
proxies, where we expect that the proxy allows proxying using
the CONNECT method.
In this phase, we send several additional requests to un-
derstand if the proxy is misconﬁgured and allows access to
internal hosts. For this purpose, we use the targets “127.0.0.1”
and “192.168.0.1”, and create connections without sending any
payload on banner-yielding ports 21, 22, 23, and 25. Addi-
tionally, we send an HTTP GET request to the regular HTTP
port. We chose the target hosts based on the intuition that
when regular sockets are used by proxy implementations, the
packets passed through them are routed as any other network
trafﬁc, allowing us to detect if the proxy is vulnerable for
misuses targeting non-Internet-routable addresses. For HTTP,
we consider a proxy to be potentially vulnerable if we receive a
200 status code for any of our CONNECT requests, indicating
that a successful connection to the target host has been made.
On the other hand, for SOCKS we settle for receiving a status
code indicating success.
In order to report on deﬁnitely vulnerable proxies, we
deploy the following port-speciﬁc heuristics to decide whether
the received payload is protocol-conforming: (1) SSH (22)
begins with SSH-, 2) FTP and SMTP (21, 25) begins with
220, and (3) HTTP (80) has an HTTP status line with
status code “200”, and (4) Telnet (23) payload has to contain
word “telnet” (after a preliminary empirical analysis) after
the proxy connection establishment (i.e., status code 200 for
CONNECT, or a successful SOCKS reply).
4) Complementary Proxy Crawling: To complement our
network scans, we also crawl proxy lists by utilizing freely
available ProxyBroker [58] as also done by Mani et al. [47].
However, instead of leveraging its built-in functionality checks,
we use it only to download a list of available proxies which
we process using the method described above. The results
from this analysis are handled separately from the Internet-
wide results in our evaluation.
D. Evaluation
In the following, we ﬁrst provide an overview of all proxies
on the Internet, based on proxy-conforming responses (Sec-
tion IV-D1). This is followed by an analysis of open proxies
(Section IV-D2) and an analysis of the results from proxies
allowing access to internal networks (Section IV-D4). The
summarized results can be seen in Table VI. For readibility,
we round the numbers in text and refer our readers to the table
for exact numbers. After that, we discuss our crawling results
(Section IV-D5), and discuss a case study of misconﬁgured
proxies hosted by a large European ISP (Section IV-D6).
1) Global View on Internet Proxies: In order to quantify
the total number of the HTTP proxies on the Internet, we
leverage the authorization requests sent back to our requests. If
authentication is required, the proxy sends an HTTP status 407
and must add a Proxy-Authenticate header informing
how and on which realm the user needs to authenticate [24]. In
total, almost 615,000 proxies sent this header with only a few
10
TABLE VI.
SUMMARY OF FUNCTIONALITIES OF PROXIES IN STANDARD PROXY PORTS
Total
Squid (3128)
Generic (8080)
Privoxy (8118)
polipo (8123)
tinyproxy (8888)
SOCKS4
SOCKS5
4,392,588
45,363
2,162
263 (12.1 %)
4,838,874
1,467,605
66,251
1,878 (2.8 %)
4,897,877
250,495
31,706
1,518 (4.8 %)
4,897,877
250,495
19,932
1,429 (7.2 %)
263
247
232
250
124
117
39
53 (20.0 %)
15 (5.7 %)
1 (0.4 %)
12 (4.6 %)
0 (0.0 %)
2 (0.8 %)
8 (3.0 %)
1,874
1,811
1,704
1,788
888
868
870
679 (36.2 %)