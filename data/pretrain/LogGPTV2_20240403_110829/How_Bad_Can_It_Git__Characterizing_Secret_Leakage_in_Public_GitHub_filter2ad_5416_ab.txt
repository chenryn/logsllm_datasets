Square
PayPal Braintree
Amazon MWS
Gmail
Twilio
MailGun
MailChimp
Google Drive
Amazon AWS
RSA
EC
PGP
General
Google Cloud Platform
Access Token
Access Token
API Key
OAuth ID
API Key
Standard API Key
Restricted API Key
Access Token
OAuth Secret
Access Token
Auth Token
API Key
API Key
API Key
(same as YouTube)a
Access Key ID
(same as YouTube)a
Cryptographic key
Cryptographic key
Cryptographic key
Cryptographic key
(same as YouTube)a
(same as YouTube)a
(same as YouTube)a
(same as YouTube)a
or
M
S
S
M
S
S
S
S
S
S
M
S
S
S
S
M
M
M
M
Monetary
Loss
X
X
X
X
X
X
X
X
X
X
X
Privacy
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
Message
Abuse
X
X
X
X
X
X
X
X
X
X
X
X
X
a These secrets share the same format as part of the Google platform, but have different risks and are thus considered
different
compromise the security of an account, irrespective of difﬁculty.
2) Asymmetric Private Keys: Asymmetric cryptography is
used frequently for many applications. For example, authen-
tication over SSH often uses a private key located in one’s
˜/.ssh/id_rsa ﬁle, or certiﬁcate-based authentication for
OpenVPN may include the private key within the *.ovpn
conﬁguration ﬁle. In many cases, the private key will be
stored in Privacy-enhanced Electronic Mail (PEM) format,
which is identiﬁable due to its header consisting of the text
-----BEGIN [label]-----, where label may be one
of many strings such as RSA PRIVATE KEY [38], [42]. We
identify 4 commonly leaked types of private keys, including
those generated using popular tools such as ssh-keygen,
openssl, and gpg, shown in Table I. The regular expression
for each can be found in Table IV in the Appendix.
B. Phase 1A: GitHub Search API File Collection
In this section, we describe the ﬁrst approach for collecting
candidate ﬁles to be scanned with our distinct secret regular
expressions, shown as Phase 1a in Figure 1. GitHub provides
a search engine API that allows users to query repositories for
code contents, metadata, and activity [22]. We carried out a
longitudinal analysis of GitHub by continually querying this
API for almost 6 months, from October 31, 2017 to April
20, 2018. Because this API [22] provides results in near real-
time as ﬁles are pushed to GitHub, all search results are from
actively developed repos.
The Search API is a ﬂexible, powerful tool, but it does have
two limitations that we had to address: no support for regular
expressions and set limits on call rate and result count. Querying
the Search API requires two parameters: the query string and
the sort type. Unfortunately, advanced search techniques such
as regular expressions are not supported in the query string
[24]. To address this limitation, we ﬁrst created a set of queries
that would identify ﬁles likely to contain secrets. These queries
on their own are not sufﬁcient to ﬁnd secrets, but we are able
to download the resulting ﬁles and then scan them ofﬂine with
our regular expressions in Phase 2. There were two separate
groups of queries that we executed: (1) general queries against
any potential secret without targeting a speciﬁc platform (e.g.,
api_key) and (2) speciﬁc queries created to target the distinct
secrets identiﬁed in Section III-A derived from their regular
expression (e.g., AKIA for Amazon AWS keys). These queries
are shown in Table V in the Appendix. For the sort type
parameter, we always used sort=indexed which returns the
most recently indexed results, ensuring we received real-time
results. We excluded .gitignore ﬁles from these results as
they rarely contained secrets but made up a large percentage of
search results1. For each query, the API returned a collection
of ﬁles and their metadata. We then perform another request to
the API’s content endpoint [18] to get the contents of the ﬁle.
GitHub provides stipulations on their search platform,
namely that only a maximum of 1,000 results are returned
and only ﬁles less than 384KB are indexed for search [22],
[24]. In addition, GitHub imposes a rate limit; an authenticated
user may only perform 30 search queries a minute [23] and a
separate total of 5,000 non-search queries an hour [17]. In our
experiments, each individual query required at most 10 search
requests and 1,000 non-search queries for contents. Only 5
queries could be carried out an hour in this manner. However,
since many of the search queries do not generate 1,000 new
results per hour, we could only collect ﬁles that were new
to the dataset to reduce API calls. This way, we can run all
queries every thirty minutes within the rate limits using a
single API key. We show in Section VI-A that this interval
achieves 99% coverage of all ﬁles on GitHub containing our
queries. Ultimately, the rate limit is trivial to bypass and is not
a substantial obstacle to malicious actors.
1We return to the contents of .gitignore ﬁles in Section VIII.
4
C. Phase 1B: BigQuery GitHub Snapshot File Collection
In addition to using GitHub’s Search API, we also queried
GitHub’s BigQuery dataset in Phase 1B. GitHub provides
a queryable weekly snapshot of all open-sourced licensed
repositories via Google BigQuery [27]. All repositories in
this dataset explicitly have a license associated with them,
which intuitively suggests that the project is more mature and
intended to be shared. This snapshot contains full repository
contents and BigQuery allows regular expression querying, so
we were able to query against the contents with our distinct
secret regular expressions from Section III-A to obtain ﬁles
containing matching strings. Unfortunately, BigQuery’s regular
expression support is not fully-featured and does not support
the use of negative lookahead or lookbehind assertions, and so
the query results were downloaded for a more rigorous ofﬂine
scan in later Phase 2, similar to in Phase 1A.
While both our ﬁle collection approaches queried GitHub
data, the two approaches allowed analysis of two mostly non-
overlapping datasets. BigQuery only provides a single snapshot
view of licensed repos on a weekly basis, while the Search
API is able to provide a continuous, near-real time view of all
public GitHub. Using both approaches simultaneously gave us
two views of GitHub. We collected BigQuery results from the
snapshot on April 4, 2018.
D. Phase 2: Candidate Secret Scan
Via Phase 1, we collected a large dataset of millions of
ﬁles potentially containing secrets. Next, we further scanned
these ﬁles ofﬂine using the distinct secret regular expressions
to identify ﬁles actually containing secrets and to extract the
secrets themselves. This process yielded a set of candidate
secrets that could undergo additional validation in a later step.
This scanning process is shown in Phase 2 of Figure 1.
Recall that limitations meant the ﬁles from the Search API
and from BigQuery in Phase 1 were retrieved using methods
that could not guarantee they contained a matching distinct
secret. These ﬁles were downloaded to be evaluated ofﬂine
against the distinct secret regular expressions from Phase 0.
In Phase 2, we performed this ofﬂine scan and noted ﬁles
and strings that match one or more of the regular expressions.
Note that each regular expression was preﬁxed with negative
lookbehind (?<![\w]) and sufﬁxed with negative lookahead
(?![\w]) to ensure that no word characters appeared before
or after the regular expression match and improve accuracy.
The set of strings that resulted from this scan were classiﬁed
as “candidate secrets”.
E. Phase 3: Validity Filters
It is possible that the candidate secrets provided by Phase
2 were not actually secret, although they matched a regular
expression. In Phase 3, we passed the candidate secrets through
three independent ﬁlters that worked to identify whether a given
string should be considered “valid”. We deﬁne a valid secret as
a string that is a true instance of the distinct secret for which it
matches. As an example, consider that the regular expression
for the Amazon AWS secret, AKIA[0-9A-Z]{16}, would
match the string AKIAXXXEXAMPLEKEYXXX, which is likely
not valid, while AKIAIMW6ASF43DFX57X9 would be.
Unfortunately, it is a non-trivial task to identify a string as
being a valid secret for a certain target with complete accuracy,
even for a human observer. Intuitively, the best approximation
that a human observer could make is whether the candidate
secret appears random. We were inspired by and improve upon
the algorithms used by TrufﬂeHog [59] and an open-source
neural-networked-based API key detector [12] to build our
ﬁlters. The ﬁlters perform three checks against a string: that
(1) the entropy of the string does not vary signiﬁcantly from
similar secrets, (2) the string does not contain English words
of a certain length, and (3) the string does not contain a pattern
of characters of a certain length. A string failing any one of
these checks is rejected by the ﬁlter as invalid; all others are
accepted as valid. The valid secrets were stored in a database
and were used for all later analysis.
Entropy Filter While there is no guaranteed mathematical
test for randomness, a good estimator is Shannon Entropy.
Consider a discrete random variable X. We wish to quantify
how much new information is learned when X is observed.
The Shannon Entropy formula deﬁnes the average amount of
information transmitted for X [6], [12]:
H(X) = − n(cid:88)
P (xi) log2 P (xi)
(1)
i=0
where X has possible values x1, ..., xn and P (xi) is the
probability for X to be the value xi. Intuitively, a random
string should consist of a rare values, giving it a high entropy;
on the other hand, English text has been shown to have fairly
low entropy—roughly one bit per letter [12], [51].
To apply this stage of the ﬁlter, our goal was to eliminate
all strings that deviated signiﬁcantly from the average entropy
for a given target secret. To do this, we failed a string for
this check if its entropy was more than 3 standard deviations
from the mean of all candidate strings for a given target secret,
effectively classifying it as an outlier. This approach relied on
the candidate set containing almost exclusively valid secrets;
we determined that this was the case for almost all targets, and
for those where it were not, the other stages of the ﬁlter could
still be applied.
Words Filter Another intuition is that a random string
should not contain linguistic sequences of characters [12]. For
this check, we compiled a dictionary of English words of length
as least as long as a deﬁned threshold. Then we searched each
candidate string for each one of these words and failed the
check if detected.
A trade-off exists in choosing this threshold. If it is too
small, randomly occurring sequences that happen to create
words will create false negatives (marking valid secrets as
invalid), but if it is too large, legitimate words will be missed
and create false positives (marking invalid secrets as valid). In
our experiments, we set the word length threshold to be 5. This
threshold was chosen as a best judgment after careful manual
review; unfortunately, experimental derivation of this threshold
was not possible given limited initial ground truth.
A dictionary of every English word would contain words
that would not likely be used as part of a string in a code ﬁle and
cause high amounts of false negatives. Therefore, we took the
intersection of an English dictionary [45] and a dictionary of the
5
most common words used in source code ﬁles on GitHub [40].
The resulting dictionary contained the 2,298 English words that
were likely to be used within code ﬁles, reducing the potential
for false negatives.
Pattern Filter Similar to linguistic sequences of characters,
random strings should also not contain mathematical sequences
of characters [12]. We identiﬁed three such possible patterns
to search for: repeated characters (e.g., AAAA), ascending
characters (e.g., ABCD), and descending characters (e.g., DCBA).
To apply this check, we searched each candidate string for one
of these patterns at least as long as a deﬁned threshold and
failed the check if detected. We settled on a pattern length
threshold of 4, with the same trade-off considerations addressed
previously addressed.
IV. ETHICS AND DISCLOSURE
This paper details experiments collecting over 200,000
leaked credentials to services that could have serious con-
sequences if abused. In this section, we discuss issues related
to the ethical conduct of this research.
First and foremost, our institutional review board (IRB)
informed us that our data collection and analysis was exempt
from review because we only work with publicly available data,
not private data or data derived from interaction with human