≥
k
2NR B⁄
But we can control the memories individually, and supply each
device with a separate address. In this way, we can write (read)
multiple packets in parallel to (from) different memories. We call
such a router a Parallel Shared Memory router.
physi-
cal memories are arranged in parallel, where B is the bandwidth of
one memory device. We are interested in the conditions under
which the Parallel Shared Memory router behaves identically to a
shared memory router. More precisely, if we apply the same traffic
to a Parallel Shared Memory router and to an ideal shared memory
router, we would like to find the conditions under which identical
packets will depart from both at the same time.6 This is equivalent
to asking if we can always find a memory that is free for writing
when a packet arrives, and will be also be free for reading when
the packet needs to depart. We will, shortly, show how; but first
we’ll describe a simple technique, called Constraint Sets, that we
will use repeatedly to analyze Deterministic SB routers.
A. Constraint Sets
1) Pigeons and pigeon holes
Consider M pigeon holes, where each hole may contain several
pigeons. Each time slot, up to N pigeons arrive which must imme-
diately be placed into a pigeon hole. Likewise, each time slot up to
N pigeons depart. Now suppose we constrain the pigeon hole so
that in any one time slot at most one pigeon may arrive to it, or at
most one pigeon may depart from it. We do not allow a pigeon to
enter a pigeon hole while another one is departing.
5. For example, a 160Gb/s shared memory router built from memories with
a random access time of 50ns requires the data bus to be at least 16,000 bits
wide (50 minimum length packets).
6. We shall ignore time differences due to propagation delays, pipelining
etc. and consider only queueing delays in this comparison.
254Now we ask the question: How many pigeon holes do we need
so that the N departing pigeons are guaranteed to be able to leave,
and the N arriving pigeons are guaranteed a pigeon hole?
a1
a2
a3
a4
a5
a6
a7
a8
a9
a10 a11 a12
(a) Initial Queue order
D t( )
Consider a pigeon arriving at time t that will depart at some
. We need to find a pigeon hole, H, that meets the
future time,
following three constraints: (1) No other pigeon is arriving to H at
time t; (2) No pigeon is departing from H at time t; and (3) No
other pigeon in H wants to depart at time
. Put another way,
the pigeon is barred from no more than
pigeon holes by
other arrivals, N departures and
other future depar-
N 1–
tures. Hence by the well-known pigeon-hole principle,
if
M 3N 1–
our pigeon can find a hole.
D t( )
3N 2–
N 1–
≥
2) Using Constraint Sets
In a Deterministic SB router, the arriving (departing) packets are
written to (read from) memories that are constrained to either read
or write in any one time slot. We can use the pigeonhole technique
to determine how many memories are needed, and to design an
algorithm to decide which memory each arriving packet is written
into. We use the following three steps:
1. Determine packet’s departure time,
: If packets depart
in FCFS order to a given output, and if the router is work-con-
serving, the departure time is simply one more than the depar-
ture time of the previous packet. If the packets are scheduled to
depart in a more complicated way, for example using WFQ,
then it is harder to determine its departure time. We’ll consider
this in more detail in Section C. For now, we’ll assume that the
D t( )
is known for each packet.
D t( )
2. Define the Constraint Sets: Identify the constraints on the
resource (such as buffer, switch fabric, etc.) for each incoming
packet.
3. Apply the Pigeon-hole principle: Add up all the constraints,
and apply the pigeon-hole principle.
Overall, the technique of using constraint sets is a generalization
of the approach used by Clos to find the conditions under which a
3-stage circuit switch is strictly non-blocking [25].
B. A Parallel Shared Memory router can
emulate an FCFS shared memory router
Using Constraint Sets it is easy to see how many memories are
needed for the Parallel Shared Memory router to emulate an ideal
shared memory router.
Theorem 1: (Sufficiency) A total memory bandwidth of 3NR is
sufficient for a Parallel Shared Memory Router to emulate an ideal
FCFS shared memory router.
Proof: (Using Constraint Sets) See Appendix A. (cid:1)
The algorithm described in the Appendix sequentially searches
the linecards to find a non-conflicting location for an arriving
packet. Hence the complexity of the algorithm is
. Also the
algorithm needs to know the location of every packet buffered in
the router. While this appears expensive, we will explore ways to
reduce the complexity in Section VI.
O N(
)
a1
a2
a3’ a3
a4
a5
a6
a7
a8
a9
a10 a11 a12
(b) Queue order after arrival of cell a3’
a1’ a1
a2
a3’ a3
a4
a5
a6
a7
a8
a9
a10 a11
a12
(c) Queue order after arrival of cell a1’
Time Slot: 1
Time Slot: 2
Time Slot: 3 Time Slot: 4
t
Order of departures for a single PIFO queue
Figure 3: Maintaining a single PIFO queue in a PSM router.
C. QoS in a Parallel Shared Memory Router
Some routers provide weighted fairness among flows, or delay
guarantees using WFQ or GPS [1][27]. We will now find the
conditions under which a Parallel Shared Memory Router can
emulate an ideal shared memory router that implements WFQ. We
will use the generalization of WFQ known as a “Push-in First-out”
(PIFO) queue [7]. A PIFO queue is defined as follows:
1. Arriving packets are placed at (or, “pushed-in” to) an arbitrary
location in the departure queue.
2. The relative ordering of packets in the queue does not change
once packets are in the queue.
3. Packets depart from the head of line.
PIFO queues include strict priority queues, and a variety of
work-conserving QoS disciplines such as WFQ. In what follows
we will explore how a PSM router can emulate a shared memory
router that maintains N separate PIFO queues.
1) Constraint Sets and PIFO queues in a Parallel
Shared Memory router
We saw above that if we know a packet’s departure time when it
arrives — which we do for FCFS — we can immediately identify
the memory constraints to ensure the packet can depart at the right
time. But in a router with PIFO queues, the departure time of a
packet can change as new packets arrive and push-in ahead of it.
This complicates the constraints; but as we will see, we can intro-
duce an extra Constraint Set so as to choose a memory to write the
arriving packet into.
)
a4(
is the third packet, packet
First, we’ll explain how this works by way of an example; the
general principle follows easily. Consider a Parallel Shared Mem-
ory router with three ports, and assume that all packets are of fixed
size. We’ll denote each packet by its initial departure order: Packet
a3(
is the fourth packet to
depart, and so on. Figure 3a shows a sequence of departures,
assuming that all the packets in the router are stored in a single
PIFO queue. Since the router has three ports, three packets leave
the router from the head of the PIFO queue in every time slot. Sup-
a3(
)
a2(
and
pose packet
)
a3'
(see Figure 3b). If no new packets push-in, packet
will
)
(which
depart at time slot 1, along with packets
arrived earlier and are already in memory). So that they can depart
arrives, and is inserted between
(
a2(
a1(
a3′
)
)
)
and
255a1
b1
c1
a2
b2
c2
a3
b3
c3
a4
b4
c4
(a) Queue order before arrival of cell a2’
a1
b1
c1
a2’ b2
c2
a2
b3
c3
a3
b4
c4
a4
(b) Queue order after arrival of cell a2’
Time Slot: 1
Time Slot: 2 Time Slot: 3
Time Slot: 4
t
Order of departures for N PIFO queues
Figure 4: Maintaining N PIFO queues in a PSM router.
at the same time, packets
ent memories. Therefore,
memory.
a1(
)
,
)
(
a3'
(
)
and
a2(
must be in differ-
must be written into a different
a3'
)
,
)
(
)
(
)
(
)
(
)
a1'
a3'
a3'
a3'
a4(
a3(
a3'
)
)
and
(
a3(
arriving and pushing
now conflicts with packets
)
In summary, when
Things get worse when we consider what happens when a
packet is pushed from one time slot to the next. For example,
Figure 3c shows
into time slot 2.
Packet
, which
were in memory when
arrived, and are also scheduled to
depart in time slot 2. So that they can depart at the same time,
packets
)
arrives and is inserted into the PIFO
queue, there are only four packets already in the queue that it could
)
a4(
,
ever conflict with:
ahead of it, and
behind it. Therefore, we only need to make sure that
is writ-
ten into a different memory from these four packets. Of course,
new packets that arrive and are pushed in among these four packets
will be constrained and must pick different memories, but these
four packets are unaffected.
must be in different memories.
a3(
)
)
a3′
a4(
)
and
(
a1(
a2(
a3′
)
)
(
,
In general, we can see that when packet P arrives to a PIFO
queue, it should not use the memories used by the
packets
scheduled to depart immediately before or after P, and so con-
strains the packet not to use
2 N 1–(
memories.
N 1–
)
2) Complications when there are N PIFO queues
The example above is not quite complete. A PSM router holds N
independent PIFO queues in one large pool of shared memory.
When a memory contains multiple PIFO queues, the memory as a
whole does not operate as a single PIFO queue, and so the con-
straints are more complicated. We’ll explain by way of another
example.
)
)
and
c3(
b3(
Consider the same Parallel Shared Memory router with three
ports a, b, and c. We’ll denote each packet by its output port and
its departure order at that output: Packet
are the
third packets to depart from output b and c, and so on. Figure 4a
shows an example of packets waiting to depart; one packet is
scheduled to depart from each output during each time slot.
Assume that packet
)
(
)
arrives for output port a and is
)
a2(
and
(two packets scheduled to depart
inserted between
(
consecutively from port a).
delays the departure time of all
a2'
the packets behind it destined to output a, but leaves unchanged
the departure time of packets destined to other outputs. The new
departure order is shown in Figure 4b.
a1(
a2'
)
Taken as a whole, the memory (which consists of N PIFO
queues) does not behave as one large PIFO queue. This is illus-
trated by packet
which is pushed back to time slot 4, and is
a3(
)
) and
) has changed after they were in memory, and so (by definition
now scheduled to leave after
b3
(
of a PIFO) the queue is not a PIFO.
. The relative order of (
a3
b3(
)
)
)
)
)
and
and
c5(
b4(
a3(
a2(
. Beforehand,
; afterwards, it conflicts with
The main problem is that the number of potential memory
conflicts is unbounded. This could happen if a new packet for
)
a3(
output a was inserted between
)
c4(
)
b5(
conflicted with
, both of which might already have been present in
and
a3(
arrived. This argument can be continued.
memory when
)
Thus when packet
arrives, there is no way to bound the
number of memory conflicts that it might have with packets
already present. In general, the arrivals of packets create new
conflicts between packets already in memory.
)
a3(
,
(
=
a1 b1 … n1
3) Modifying the departure order to prevent memory
conflicts amongst packets destined to different outputs
We can prevent packets destined to different outputs from con-
flicting with each other by slightly modifying the departure order.
Instead of sending one packet to each output per time-slot, we can
instead transmit several packets to one output, and then cycle
through each output in turn. More formally, consider a router with
n ports and k shared memories. If the departure order was:
) … ak bk … nk
Π
,
i.e., in each time slot a packet is read from memory for each output
port, we will permute it to give:
Π'
,
i.e., exactly k packets are scheduled to depart each output during
the k time slots, and each output can simply read from the k shared
memories without conflicting with the other outputs. When an out-
put completes reading the k packets, all the memories are now
available for the next output to read from. This resulting conflict-
free permutation prevents memory conflicts between outputs.
) … n1 n2 … nk
,
) a2 b2 … n2
,
) b1 b2 … bk
,
a1 a2 … ak
=
(
(
(
(
(
)
)
,
,
,
,
,
,
,
,
,