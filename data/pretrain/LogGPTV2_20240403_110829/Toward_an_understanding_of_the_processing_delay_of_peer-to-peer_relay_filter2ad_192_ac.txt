• Level-Shifted: The levels of PDs are increased or de(cid:173)
creased by a significant magnitude, say, larger than 10
ms. This indicates that a heavily loaded task starts or
stops running on the relay node during the call.
• Periodic: Bursts of high PDs occur at regular intervals,
possibly because of the behavior of an application. For
example, the one-minute interval in the processing delays
of Call 214 is likely caused by an email notification
program with a one-minute check interval.
• Loaded: The level of PDs remains large, say 100 ms
or higher. This implies that
the relay node is under
a heavy workload generated by computation- or 1/0(cid:173)
intensive applications.
Fig. 7(a) and Fig. 7(b) plot the distributions of the average
and maximum PDs of each call. It can be seen that the average
PDs are generally shorter than 20 ms. The maximum PDs,
however, have a much broader range, which spreads over 0
to 500 ms with a mean around 100 ms. We use the ratio
between the maximum and average PDs to quantify the degree
of maximum PD variation in a call, and plot its distribution
in Fig. 7(c). The median of the ratios is 30, while its 90%
percentile is around 200. The high variability of the ratios
indicates that the variation of PDs can be extremely large,
even within a 10-minute period.
B. Stability Analysis
We now tum to the stability of processing delays, which is
closely related to the workload structure of a relay node. We
begin our analysis with a definition of the metric busy level,
which is designed to capture the level of the workload on the
relay node. The busy level (BL) is defined as the 95% quantile
of processing delays within a window of 10 seconds.
1-4244-2398-9/08/$20.00 ©2008 IEEE
415
DSN 2008: Chen & Lou
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:21:03 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
SUMMARY OF Busy LEVELS OF STABLE AND UNSTABLE RELAY NODES
TABLE III
BLMin
BL Mean
BL Max
BL SD
Stable RN Unstable RN
6 ms
17 ms
120 ms
16 ms
5 ms
6 ms
8 ms
1 ms
Ratio
1.26
2.75
14.17
24.72
We choose the 95% quantile, rather than a more intuitive
50% quantile, because even on a heavily loaded machine, the
processing delays incurred by relay packets are not always
large due to the thread scheduling mechanism. More specif(cid:173)
ically, when a relay load is lightly loaded, a source packet
is always serviced by the relay application as soon as it
arrives at the node. In contrast, a source packet sometimes
has to wait a long time before it is serviced on a heavily
loaded node. The processing delay of a packet depends on
the exact time it arrives at the relay node. If a source packet
arrives at a node just before the relay application's execution
time,
it will receive almost no processing delay no matter
how heavy the workload is. Otherwise, the packet will be
postponed by a load-dependent period before being processed.
For these reasons, the busy levels are defined bias toward high
processing delays in order to obtain the true workload.
After computing the busy levels for each second in a call,
we detect change points where BLs differ significantly. Rather
than employ a mathematical definition of change points [9,
28], we identify a BL change from an operational point of view
as follows. The time t is deemed a change point if the BLs of
two consecutive seconds, t and t + 1, have a difference larger
than 10 ms. Based on the detected change points, we classify
each relay node into two categories: stable and unstable. A
relay node is considered stable if its PD series contains no
change points, and unstable otherwise. In our traces, 75% of
relay nodes are classified as stable and 25% as unstable.
10
15
Local hour
20
24
Fig. 8. The average ratios of all relay nodes and unstable relay nodes for
each hour of a day, where the ratios are relative to the number of all relay
nodes and unstable relay nodes respectively.
ratio of BL standard deviations is 24).
VI.
IMPACT OF PROCESSING DELAY ON VoIP QUALITY
Currently, peer-to-peer relaying technology is adopted by
VoIP applications for the following reasons: 1) relaying can
help bypass the connection restriction of NATs and firewalls
because communication availability is an important consider(cid:173)
ation for widely used VoIP services; 2) VoIP requires a high
degree of real-timeliness and interactivity, and relaying can
help reduce network latency; 3) the bandwidth requirement
of VoIP communication is not high, e.g., 32 Kbps, which
is not a high bandwidth overhead to a relay node. In many
cases, if we choose a relay node carefully, we are likely to
find a relayed path that yields better network quality than the
native Internet routing path. Thus, a number of studies have
been devoted to finding a good relay node that yields a better
quality path in terms of network latency or the packet loss
rate [2-5, 11, 15, 21, 27]. However, without considering the
workload on the relay nodes, the processing of relay packets
may introduce significant delays to the relayed data stream
and therefore degrade the application performance.
Having shown that the processing delays at a relay node
are not always negligible, we now consider the impact of
relay processing delays on VoIP quality. Via trace-driven
simulations, we show that such delays may have a negative
impact on VoIP quality. We also perform a characterization of
busy periods on relay nodes and show that the busy status of
relay nodes is generally quite unstable.
The stability of relay nodes can also seen an indicator of the
activity of the relay host. In other words, if the busy levels of
a relay node change significantly during a call, it is likely that
the computer is in use for that period. We verify the correctness
of the inferred stability of relay nodes based on the intuition
that a host is more likely to be active during working hours.
To do so, we compute the local time of each call by mapping
a relay node's IP address to its geographical address and time
zone. The ratios of all hosts and unstable hosts for each hour of
a day are plotted in Fig. 8. We observe that, while the numbers
of observed relay nodes are roughly constant, the numbers
of unstable nodes are significantly higher from 8AM to 4PM A. Methodology
in each node's local time. These results strongly support the
contention that
the
true workload on relay nodes and can indicate whether the
computer is currently being used by a person or running a
workload-varying application.
the measured processing delays reflect
We use trace-driven simulations to assess the impact of
processing delays on VoIP quality. To measure the effect of
processing delays under various network conditions, in each
run, we combine a network delay trace and a processing delay
trace to simulate a VoIP call with and without packet relaying.
We summarize the busy levels of stable and unstable relay We use ack response times extracted from the collected
nodes in Table III. The table also lists the ratios of the BL
calls as the input of network delays. As each of our 1,115
statistics of unstable and stable relay nodes. The results show traces provides a series of network delays and a series of
processing delays separately, our simulation comprises a total
that
the busy levels of unstable relay nodes are not only
of 1,243,225 runs. The simulation time of each run is set to
significantly higher than those of stable nodes (the ratio of
BL maximums is 14), but are also much more variable (the
250 sec and the packet rate is set to 33 pkt/sec.
1-4244-2398-9/08/$20.00 ©2008 IEEE
416
DSN 2008: Chen & Lou
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:21:03 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
During each simulation run, we compute the end-to-end
delay and packet loss rate based on a given pair of network
delay and processing delay traces. The end-to-end delay is
decided by the playout buffer size, which also determines the
end-to-end loss rate because a packet is considered lost if it
cannot meet the playout schedule. There are two common
schemes for adjusting the playout buffer size, namely static
and adaptive, both of which are included in our simulations.
For the static buffer strategy, we use a fixed 60-ms buffer after
Skype's setting [23]. Our adaptive buffer is computed by the
following equation:
di + 4 X Vi,
a X di + (1 - a) X ni,
{3 x Vi -1 + (1 - a) Idi
(1)
(2)
(3)
where Pi is the buffer size for packet i + 1, ni is the network
delay of packet i, and a = {3 = 1-0.998002 according to [20].
We use the ITU-T E-model [12] to quantify the voice quality
of each simulated call. Essentially, the E-model transforms a
set of transmission impairments into a psychological satisfac(cid:173)
tion level. The main computation equation of the E-model is
- ni I ,
R = Ro - Is - Id - Ie + A,
where Ro represents the fundamental signal-to-noise ratio, Is
represents the impairments occurring simultaneously with the
voice signal, I d represents the impairments related to delays,
and Ie represents the impairments related to information loss.
The advantage factor A is used for compensation when there
are other advantages of access available to the user. Since the
computation of R o and Ie is codec-dependent, for simplicity,
we assume the voice codec is the widely deployed G.711. The
output of the E-model is the R-score, which represents the
overall voice quality via a 100-pt scale. In our settings, the
R-score reaches a maximum of 93.2 without any end-to-end
delay or loss. Generally an R-score higher than 80 implies
a satisfactory VoIP quality, while an R-score lower than 70
implies a quality that many users find unacceptable [19].
Following Table 1 in [19], we use a reduction of 10-points
in the R-score to denote a significant degradation in VoIP
conversation quality.
B. Performance Degradation
LL
0
U
~
ClO
d
(0
d
"'t
d
C\l
d
0
c:i
LL
0
U
ClO
d
(0
c:i
"'t
c:i
C\l
c:i
0
d
5
10
50 100
(a) Avarage delay increase (ms)
20
0.02
2
(b) Packet loss rate increase (%)
0.5
0.1
1
Fig. 9.
increase of packet loss rate in each call.
The distributions of (a) average increase of end-to-end delays, (b)
LL
0
U
~
co
c:i
(0
c:i
"'t
c:i
C\l
c:i
0
c:i
-10
0
10
20
30
40
50
(a) Avarage R-score decrease
LL
0
U
~
co
d
(0
c:i
"'t
c:i
C\l
c:i
0
c:i
20
80
(b) Maximum R-score decrease
60
40
Fig. 10.
R-score increase in each call.
The distributions of (a) average R-score increase, (b) maximum
resilient enough to absorb highly variable processing delays,
as it leads to both longer delays and higher packet loss rates
than the static buffer scheme. In addition, the static buffer
always absorbs delay deviations shorter than 60 ms such that
only 1% of calls have an end-to-end loss rate higher than 1%,
compared to 10% of calls under the adaptive buffer strategy.
2) VoIP Quality: With respect to VoIP quality degradation,
we can see from Fig. 10(a) that the average R-score decrease
caused by relay processing is generally small; most calls
have an average R-score decrease smaller than 10. A few
calls with adaptive buffering do have better voice quality, i.e.,
an increased R-score. Our analysis shows that this counter(cid:173)
intuitive behavior is due to a lower packet loss rate. The lower
rate is a consequence of a larger playout buffer, which in
tum is caused by a higher degree of delay variation due to
relay processing. At the same time, the adaptive buffer scheme
also leads to poor conversation quality, as about 20% of calls
have an average R-score decrease of more than 10, which we
consider a significant degradation in quality.
1) Transmission Delay and Loss: For each pair of network
delay and relay processing delay traces, we assess the quality
degradation by evaluating the network performance separately,
i.e., end-to-end delay and loss, as well as voice quality, with
The performance degradation is much more obvious if
and without relay processing. First, we consider the network we check the distribution of maximum R-score decreases in
performance degradation shown in Fig. 9. From the figure,
Fig. 1O(b). The adaptive buffer scheme still performs much
we observe that the average delay increase caused by relay worse than the static buffer scheme. However, both schemes
are subject
processing is not large because the playout buffer absorbs
to significant quality degradation due to relay
processing; 40% and 58% of calls experienced considerable
the variability introduced by processing delays. However, a
fraction of calls still experience significant end-to-end delay
quality degradation for the static and adaptive buffer strategies
increases, say, greater than 50 ms. The reason for the larger
respectively.
delay increase in the adaptive buffer scheme is that the buffer
the