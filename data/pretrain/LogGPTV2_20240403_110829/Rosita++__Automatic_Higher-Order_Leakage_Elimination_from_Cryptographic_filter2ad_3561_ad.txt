generated while running the code segment in a fixed vs. random
input configuration.
Finally, Algorithm 3.1 is run to find the leaky components at
the leaky points recognised in the previous step. The two utility
functions that are used by Algorithm 3.1 are Normalised Product of
Samples (NPS) and NotLeaky. The first function, NPS returns the
combined traces for a given set of sample points and a given set of
components. In a nutshell, NPS returns the results of Equation 1
for an arbitrary set of components and an arbitrary set of sample
points. As the name suggests, the NotLeaky function differenti-
ates between trace sets which are significantly similar and ones
which are not. NotLeaky requires an additional run of the code
segment with all random input configuration instead of a fixed vs.
random input configuration. This run collects information required
to calculate the mean differences and variances required by TOST.
Algorithm 3.1 Find Leaky Components
𝑳: A 3D matrix with component values for Elmo* organised by trace index,
sample index and component index.
S: Set of 𝑑 sample points that participate in the leakage.
C: Set of all components that are in Elmo*.
NPS(𝑳, S, C): Normalised Product of Samples. Returns the normalised
product of the power samples from reduced models which only
contain a given set of components (C) at some given sample points
(S) from a 3D matrix that holds component samples (𝑳).
NotLeaky(𝒀): Determine the absence of leakage using TOST.
⊙: Elementwise multiplication operator.
1: function FLC(𝑳, S, C)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15: end function
𝒙 ← NPS(𝑳, S \ 𝑠, C)
for 𝑡 ∈ C do
𝑢 ← C \ 𝑡
𝒚 ← NPS(𝑳, 𝑠, 𝑢)
𝒛 = 𝒚 ⊙ 𝒙
if NotLeaky(𝒛) then
𝑟 ← 𝑟 ∪ {(𝑠, 𝑡)}
end if
𝑟 ← {}
for 𝑠 ∈ S do
end for
return 𝑟
end for
Session 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea691While the component elimination method is efficient, it may
sometimes fail. For example, if multiple model components leak
the same share, removing any one of these components will not
eliminate the leak. Similarly, TOST may fail to demonstrate the
equivalence of the two distribution even when removing a model
component eliminates the leak.
The Monte-Carlo Method
In the Monte-Carlo approach we
run a preset number of random experiments where, in each ex-
periment, we select a random subset of the model components,
and perform the 𝑡-test on hypothetical power traces with only the
selected components. For each component, we keep track of the
number of random experiments it participates in and how many
of those experiments indicate significant leakage. After we repeat
the experiment a preset number of times, we arrive at a subset of
components that contribute significantly more to the leakage.
To select the preset number of random experiments we first
performed an analysis for a code segment from Xoodoo cipher
(shown in Listing 4) only by using Monte Carlo method to detect
and remove leakage. We use the chosen preset number in all our
subsequent experiments. We first gathered 100,000 traces from this
cipher implementation and performed the initial leakage analysis.
Initially, it had 45 total leakage points. Figure 2 shows the reduction
of remaining leaky points as we gradually increase the number of
Monte Carlo experiments starting from 10. Figure 2 shows that in-
creasing number of experiments improves detection of root causes,
but after about 30 experiments the reduction of leakage is nearly
constant4. Therefore, we decided to settle at using 50, slightly more
than 30 for the sake of certainty, as the preset experiment count for
our experiments.
Figure 2: Effectiveness in removing leakage of Monte Carlo
method for increasing number of experiments
Observe that both component elimitation and the Monte-Carlo
method are independent of the security order. We evaluate both
methods in the second and third order in Section 4.
In our experiments we find that we need to fallback to the Monte-
Carlo method in four out of 16 root-cause detections in Xoodoo, in
70 out of 262 in present, and in one out of 15 in the Boolean-to-
arithmetic conversion algorithm.
4We have noticed no further leakage reduction even for 1000 experiments.
3.5 Code Rewrite
After finding the root cause of the leakage, Rosita++ selects the
code-rewrite rule that best match the detected root cause using the
code-rewrite engine of Rosita.
In a nutshell, Rosita reserves the register r7, which it initialises
with a random value. When an unintended interaction is detected,
the code rewrite engine inserts instructions that use r7 to elimi-
nate the interaction. For example, when the detected interaction is
caused by a pipeline register that is updated by two consecutive in-
structions, Rosita inserts the instruction mov r7, r7, to buffer
between the interacting instructions. Similarly, when the leakage is
from an interaction with the memory subsystem, Rosita inserts the
pair of instructions push {r7} followed by pop {r7}, which
wipes the internal state of the memory pipeline. Many other fine-
grained fixes are used to erase internal state set by other instructions
(i.e. instructions related to ALU’s operations).
Observe that we use the same code rewriting engine that was
initially designed for fixing univariate leakage. We find that it is
usable as is to also fix multivariate leakage becasue the output
of our root-cause detection algorithm matches the format of the
original Rosita output. The downside of reusing the code rewriting
engine is that we may miss opportunities for addressing multiple
leaks with a single fix. We leave optimising the code-rewrite engine
to future work.
4 EVALUATION
In this section we evaluate the effectiveness of Rosita++ in elimi-
nating leakage. First, we describe our physical experiment setup.
Second, we present toy Boolean masked examples of second and
third order where Rosita++ fixes a single leaky point. Third, we
present the evaluation results of Rosita++’s emulation process
and root cause detection. Finally, we demonstrate effectiveness of
Rosita++ on practical code segments implemented with 3-shares.
Due to practical reasons, we limit the discussion to second and
third order. We note that Rosita++ can detect and apply fixes at
any order.
4.1 Experimental Setup
Our experimental hardware setup is depicted in Figure 3. For eval-
uation we use the STM32F030 Discovery evaluation board by ST
Microelectronics, which features an ARM Cortex-M0 based on
STM32F030R8T6 System-on-Chip (SoC), running at 8 MHz. To avoid
switching noise, we power the evaluation board with batteries in-
stead of a mains-connected power supply.
To measure the power consumption of the evaluation board, we
introduce a shunt resistor across one of its power terminals. We
measure the voltage drop across the shunt resistor with a PicoScope
6404D oscilloscope, configured at a sampling rate of 78.125 MHz
(12.8 ns sample interval) which translates to roughly 9.77 samples
per clock cycle. The voltage is measured with a PicoTechnology TA
046 differential probe connected to the oscilloscope via a Langer
PA 303 preamplifier.
We use two of the I/O pins of the board to trigger the acquisi-
tion. One indicates trace start and the other indicates the end. To
increase signal stability, interrupts are disabled for the duration of
 0 10 20 30 10 20 30 40 50 60 70 80 90 100Remaining Leaky PointsMonte Carlo Experiment Count95% conﬁdence intervalAverage remainingSession 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea692each trace, using __disable_irq() before the start trigger and
__enable_irq() after the end trigger.
Figure 3: Measurement setup
To orchestrate the experiment, we used a PC with a serial con-
nection to our device under test. The PC controls all aspects of the
experiment, and in particular it selects the type of the experiment
(i.e. fixed vs. random) and the randomness used. The tested device
is oblivious to the type of experiment and uses the inputs received
from the PC. To reduce the communication overhead the PC uses
bulk transfer to send the inputs for multiple successive experiments,
which the device executes sequentially.
We post-processed the traces to improve signal quality. Firstly,
we aligned the traces statically using a correlation-based alignment,
reducing sample drift. We then used a highpass filter to remove
frequencies below 400 KHz. Before filtering, the signal was zero
padded to avoid introduction of transients [63].
4.2 Evaluation of second and third-order
Boolean masked toy example
Before we evaluate Rosita++ on real-world software examples, we
demonstrate its effectiveness on a toy example, shown in Listing 1.
The code presents a typical operation in second-order protected
implementation that uses Boolean masking. Specifically, it assumes
that registers r1, r2, and r3 contain the addresses of three shares
that represent a secret value. The code uses three ldrb instructions
to load the masked value into three registers, r4, r5, and r6. We
note that the code is nominally second-order secure, because all
instructions process at most one share of the secret. However, as we
see below, unintended interactions between the load instructions
at Lines 6 and 7 result in second-order leakage.
To avoid first-order leakage through a combination of the three
load instructions, we separated the first load (Line 2) from the rest of
the code. We added the push and pop instructions in Lines 3 and 4
to remove interactions between the first load and the following
two loads. (See Shelton et al. [61] for details.) We further added
sequences of nine nop instructions (concretely, mov r7, r7) to
avoid unintended interaction through the processor’s pipeline and
to achieve a clear temporal separation between the loads. Last, we
add short sequences of nop instructions around the code to create
a temporal separation between the measured code and the triggers.
In Figure 4a we see the results of bivariate leakage analysis on
two million traces collected using our experimental setup. The
figure is a heatmap, where the X and Y axes indicate the samples
that are combines to create the artificial bivariate sample. The
colour of each combined sample indicates the magnitude of the
fixed vs. random 𝑡-test analysis for the combined sample. The figure
is symmetric across its main diagonal.
Examining the figure we find that there are two regions that
show a 𝑡-test value above our threshold of 4.5. These occur at the
combinations of samples around 50, which corresponds to Line 2
of Listing 1, and sample 200, which corresponds to Line 7. Running
Rosita++ also shows that the combination of Line 2 and Line 7
leaks. Root-cause analysis shows that Lines 6 and 7 interact both
through the processor pipeline and through the memory bus.
To fix the leakage, Rosita++ first inserts a mov r7, r7 in-
struction between Line 6 and Line 7, and repeats the analysis to
check that the leakage has been eliminated. Finding that there is
still leakage through the memory bus, Rosita++ further adds a
combination of push and pop instructions, producing the code in
Listing 2. Rosita++ required 200,000 emulated traces to apply fixes
for this implementation. Running the bivariate analysis on the code
shows no evidence of second-order leakage, as shown in Figure 4b.
1
2
3
4
5
6
7
8
9
10
11
12
; nop padding
mov r7, r7
ldrb r4, [r1]
push {r7}
pop {r7}
; nop padding
ldrb r5, [r2]
mov r7, r7
push {r7}
pop{r7}
ldrb r6, [r3]
; nop padding
; nop padding
ldrb r4, [r1]
push {r7}
pop {r7}
; nop padding
ldrb r5, [r2]
ldrb r6, [r3]
1
2
3
4
5
6
7
8
; nop padding
Listing 1: A Toy Example (second order)
Listing 2: Fixed Toy Example
Session 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea693(a) Before applying code fixes. Leakage is visible around coordinates