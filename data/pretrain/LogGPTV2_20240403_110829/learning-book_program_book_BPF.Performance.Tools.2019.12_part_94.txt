be both deliberately vague and suficiently descriptive. Using hard numbers would be misleading
as the specific metrics depend on the workload and system. With that caveat in mind, here is a
rough guide to those terms:
 Negligible: 5%
 Expensive: >30%
%000
Control
5.97243
k:vfs_read { 1 }
Kprobe
6.75364
76
kr:vfs_read { 1 }
Kretprobe
8.13894
212
t:syscalls:sys_enter_read { 1 )
Tracepoint
6.95894
96
t:syscalls:sys_exit_read ( 1 )
Tracepoint
6.9244
93
u:libc:_read { 1 }
Uprobe
19.1466
1287
ur:libc:_read { 1 }
 Uretprobe
25.7436
1931
{ t 1 /0  out.txt
This shows that kprobes (on this system) are fast, adkding only 76 nanoseconds per call increasing
to around 200 nanoseconds when a map with a key is used. Kretprobes are much slower, as would
be expected due to instrumenting the function entry and inserting a trampoline handler for the
return (see Chapter 2 for details). Uprobes and uretprobes ad the most overhead, over one
microsecond per event: this is a known problem that we would like to improve in a future version
of Linux.
These are all short BPF programs. It is possible to write lengthy BPF programs that cost much
more, measured in microseconds
636 nanoseconds for teo BPF events
-30 this 1s really
---
## Page 768
18.2 Sample at 49 or 99 Hertz  731
These were measured on Linux 4.15 with BPF JTT enabled, Intel(R) Core(TM) i7-8650U CPU
@ 1.90GHz CPUs, using taskset(1) to bind to one CPU only for consistency, and taking the
fastest of 10 runs (principle of least perturbations) while checking the standard deviation for
consistency. Bear in mind that these numbers can all change based on the speed and architecture
of the system, the running workload, and future changes to BPE.
18.1.3  Test Yourself
If you can accurately measure an application’s performance, you can do so with and without a
BPF tracing tool running and measure the difference. If a system is running at CPU saturation
(100%), then BPF will take CPU cycles away from the application, and the difference may be
measurable as a drop in request rate. If the system is running with CPU idle, then the difference
may be seen as a drop in available CPU idle.
18.2Sampleat49or99Hertz
The point of sampling at these seemingly odd rates is to avoid lockstep sampling.
ad saqdures oot jo ape y 'aremos pare aup go aunrd asieoo e 1ured o sapdues paup aqet a
second (100 Hertz), or 50 per second, is usually sufficient to provide details for solving both big
and small performance wins.
Consider 100 Hertz. This takes a sample every 10 milliseconds. Now consider an application
thread that wakes up every 10 milliseconds to do 2 milliseconds of work. Its consuming 20% of
one CPU. If we sample at 100 Hertz, and by coincidence run our profiling tool at just the right
time, every sample will coincide with the two-milisecond window of work, so our profile will
show it on-CPU 100% of the time. Or, if we hit Enter at a different time, every sample will miss
and show that application thread 0% of the time. Both results are deeply misleading and are
examples of aliasing errors.
By using 99 Hertz instead of 100, the time offsets where we take samples will no longer always
coincide with the application's work. Over enough seconds, it will show that the application is
on-CPU 20%6 of the time. It’s also close enough to 100 Hertz that we can reason about it as though
it were 100. Eight-CPU system for one second? Roughly 800 samples. I frequently make such
calculations when sanity-checking my results.
If instead we picked, say, 73, that would also avoid lockstep sampling, but we wouldn’t be able to
make such quick calculations in our heads. 73 Hertz on four CPUs for eight seconds? Give me a
calculator!
The 99 Hertz strategy only works because application programmers usually pick round numbers
dde aspuos o iasa puoas iad su ot puos I aa :ase pu na aog
tion developers began picking 99 times per second for their timed activities, we’d have the lock-
step problem again.
Let’s call 99 the *profiler number.* Don’t use it for anything other than profiling!
---
## Page 769
732
Chapter 18 Tips, Tricks, and Common Problems
18.3YellowPigs and GrayRats
In mathematics, the number 17 is special and has been nicknamed the *yellow pig” number;
there is even a yellow pig day, July 17 [178]. It is also a useful number for tracing analysis, although
I prefer 23.
You will often be faced with an unknown system to analyze, not knowing which events to start
tracing. If you are able to inject a known workload, then frequency counting events may reveal
which are related to your workload.
write I/O, but you didn’t know which events to trace. We will create a known workload using
dd(1) to perform 23 writes, or even better, 230,000 writes so that they stand out from other
activity:
 dd if=/dev/zero of=test bs=1 count=230000
23000o+0 recozds 1n
23000o+0 recozds out
230000 bytes (230 kB, 225 KiB)copied, 0.732254 s, 314 kB/s
While this ran, all functions beginning with *ext4_° were traced for 10 seconxds:
funccount -d 10 'ext4_*'
Tracing 509 functions for *ext4_*... Hit Ctrl-C to end.
FUNC
COUNT
xegxm"dnox"sefxe
ext4_renane2
1
1
[..]
ext4_bio_veita_page
89
ext4_es_lokup_extent.
142
pebxeu"equeossxe
217
ext4_getattr
5125
ext4_file_getatte
6143
ext4_vrite_checks
230117
ext4_file_xrlte_iter
230117
poaatt.xepxa
230185
ext4_nonda_svitch
230191
ext4_block_vrite_begin
230200
ext4_da_vrite_begin
230216
ext4_dirty_inode
230299
ext4_nark_inode_dirty
osapdno36abxa
230355
ext4_1node_csun.isra,56
9SE052
asunoapoux
230356
ext4_reserve_inode_vx1te
230357
ext4_nark_iloc_dirty
230357
---
## Page 770
18.4 Write Target Software
733
apouaepdnopxa
230360
ext4_lnode_table
230446
ext4_journal_check_start
460551
De tach.ing - . *
Notice that 15 of these functions were called a little over 230,000 times: these are very likely
related to our known workload. Out of the 509 ext4 functions traced, using this trick we've
coincide with other unrelated event counts. What else would also happen 230,000 times during
narrowed them down to 15 candidates. 1 like using 23 (or 230, 2300, etc.) as it is unlikely to
10 seconds of tracing?
23 and 17 are prime numbers, which tend to occur less naturally in computing than othes
numbers, such as powers of 2 or 10. 1 prefer 23 because it has distance from other power-of-two
and 10 numbers, unlike 17. Id call 23 the “gray rat° number.*
See Section 12.4 in Chapter 12, which also used this trick to discover functions.
18.4WriteTargetSoftware
It can save you time and headaches to write load generation software first, then write the tracing
tool to measure it.
noA op aauM seap sanbas pue ouagel mous pue ssanbau SNI aoes os papuem noA kes s,μa]
start, and how do you know if your program is working? If you begin by writing a simple DNS
request generator, you'll learn which functions to trace, how the request details are stored in
structs, and the return values of the request functions. You'llikely learn this quickly, as there
is usually an abundance of documentation for programmers that can be found with Internet
searches, including code snippets.
In this case, the man page for the getaddrinfo(3) resolver function contains entire programs that
you can use:
S nan getaddrinfo
[..]
remset (4hints, 0, slzeof (struct addrinfo)1 
hints,ai_fanily = AF_UNsPEC;
/* Allou IPv4 or IPv6 */
h1nts,al_socktype = S0Cx_DGRAH; /* Datagzan socket */
h.ints.a1_flags = 0;
hlnts.al_protocol = 0
/+ toooqoxd fuY +/
α = getaddrinfo (argv [1] , argv[2] , shint.s, szesult) ;
if (s != 0) 1
fpxintf (stderr, “getaddzinfo: Is,n*, gal_strezroz (s)) ;
exit (EXIT_FAILURE) 
[...]
5 It counts how many whiskers there 8re on 8 gray rat. I also own many gray rat stuffed toys from Ikea—maybe 23.
---
## Page 771
734
Chapter 18 Tips, Tricks, and Common Problems
By starting here, you'll end up with a tool to generate known requests. You can even modify it to
make 23 requests (or 2300) to help you find other related functions in the stack (see Section 18.3).
18.5
5LearnSyscalls
System calls are rich targets for tracing.
They are documented in man pages, they have tracepoints, and they provide useful insight for
resource usage by applications. For example, you use the BCC syscount(8) tool and discover a high
rate of setitimer(2). What is that?
 nan setitiner
GETITINER (2)
Linux Prograrnex*s Manual
GETITINER (2)
BAME
getitimer, setitiner - get or set value of an interval tiner
SYHOPSIS
#1nclude 
int getitiner (1nt which, struct Itinerval *curr_value) ;
int setitiner(int which, const struct itimerva] *nex_valve,
stzuct itinexval *o1d_value) ;
DESCRIPTION
These systen calls provide access to interval timers, that is, tiners
1e  (fTteuotadol pue *exnang ea uT aurod euos ie sxrdxe AtteratuT seus
ated fox the calling pzocess, and the tiner is zeset to the  specified
regular intervals after that. Xhen a timer expires, a signal is gener
interval (if the Lnterval is nonzero) .
[...]
setitimer ()
uotun Aq ptetoeds zeua ega suzestp zo suxe ( aeuataes uotaoung eu
by setting the tiner to the value specified by nev_value. If old_value
is non-NULl, the buffez it points to is used to zeturn the prevlous
value of the timer (i.e., the sane infornation that is returned by
getitimer ()1 -
[..-]
RETURN VALUE
On success, zero is returned. On error, -1l is returned, and errno is
set appxopxlately-
---
## Page 772
18.7 Missing Events
735
The man page explains what setitimer(2) does, along with its entry arguments and return
value. These can all be inspected by the tracepoints syscalls:sys_enter_setitimer and
syscalls:sys_exit_setitimer.
18.6
KeepItSimple
Avoid writing long and complex tracing programs
BPF tracing is a superpower that can trace everything, and it can be easy to get carried away and
add more and more events to a tracing program and lose sight of the original problem you wanted
to solve. This has the following drawbacks:
Unnecessary overhead: The original problem might have been solved by tracing only a few
events, but the tool now traces many more, adding little insight to the common use case
but costing overhead for everyone who uses it.
• Maintenance burden: This is especially the case with kprobes and uprobes, as they are
an unstable interface that can change between software versions. We've already had a
number of kernel changes during the Linux 4.x series that have broken BCC tools. The fix
was to include code for each kernel version (often selected by checking for the existence of
functions, as kernel version numbers are an unreliable indicator due to backports), or to
simply duplicate the tools, keeping copies for older kernels in the tools/old directory.
Best case: tracepoints were added so that such breakage stops happening (e-g., with
sock:inet_sock_set_state for the tcp tools).
Fixing the BCC tools has not been arduous, as each one typically traces only a few events or event
types (as I designed them to do). Were they to trace dozens of events each, breakage would be
more frequent, and fixing them would be more complicated. Also, the tests required would be
magnified: testing all event types across all kernel versions that the tool has specific code fot.
I learned this the hard way when I developed a tool called tcpsnoop(1m) 15 years ago. My goal
was to show which processes were causing TCP I/O, but I solved this by writing a tool to trace
all packet types with the PID (TCP handshake, port refused packets, UDP, ICMP, etc.) so that it
matched the output of a network sniffer. This involved tracing many unstable kernel details,
and the tool broke several times due to kernel updates. I'd lost sight of the original problem and
developed something that became impractical to maintain. (For more details on this lesson, see
tcpsnoop in Chapter 10.)
The bpftrace tools I developed and included in this book are the result of 15 years of experience:
I’'m deliberately restricting them to trace the fewest events required, solving the specific problem
and no more. Where possible, I recommend that you do the same.
18.7MissingEvents
This is a common problem: an event can be instrumented successfully, but it doesn’t seem to
fire, or a tool produces no output. (If the event can’t be instrumented at all, see Section 18.10.)
Instrumenting the events using the Linux perf(1) utility can help determine whether the isue is
with BPF tracing or with the event itself.
---
## Page 773
736
5 Chapter 18 Tips, Tricks, and Common Problems
The following demonstrates using perf(1) to check if the block:block_rq_insert and
block:block_rq_requeue tracepoints are occurring:
C
Performance counter stats for *systen vide*:
f1
blsck:bleck_rq_insert
U
emenbexbx"xootq:xoo[a
2.545953756 seconds time elapsed
In this example, the block:block_rq_insert tracepoint fired 41 times, and the block:block_rq_requeue
tracepoint fired zero times. If a BPF tool was tracing block:block_rq_insert at the same time, and it did
not see any events, then it would suggest a problem with the BPF tool. If both a BPF tool and perf(1)
showed zero events, then it would suggest there is a problem with the event: it is not occurring.
Now an example of checking if the vfs_read() kernel function is called, using kprobes:
+ perf probe vfs_read
Added nex event:
probe:vfs_read
(on vfs_read)
You can nox use it in all perf tools, such as:
I deets ge- peexsgn:qoud s- pxooea Jxed
C
3, 029
probe:vfs_read
1. 9509８0658 seconds tixe elapsed
+ perf probe --del probe:vfs_read
Renoved event: probe:vfs_read
The perf(1) interface required separate commands to create and delete the kprobe, and it is similar
with uprobes. This example showed that vfs_read0 was called 3029 times while tracing.
sa punnsu isnoaad aam aue aemos e sae uadde saauos sasa Suss
are no longer called.
One common ocurrence is where a library function is traced from its shared library location,
but the target application is statically compiled, and that function is called from the application
binary instead
---
## Page 774
18.8 Missing Stacks Traces
737