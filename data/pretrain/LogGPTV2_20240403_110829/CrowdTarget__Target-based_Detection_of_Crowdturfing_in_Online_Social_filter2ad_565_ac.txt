5.2 Twitter Application
We ﬁnd that most of the collusion-based crowdturﬁng
services have third-party Twitter applications to generate
retweets. Their web sites provide custom interfaces for work-
ers to easily create retweets for tweets of crowdturﬁng cus-
tomers. Therefore, for each tweet receiving retweets, we
compute the ratio of the number of the retweets generated
by the most dominant application to the total number of
retweets.
Figure 6 shows the ratio distributions of the dominant
applications used to generate retweets. We found that domi-
nant applications generated approximately 90% of the crowd-
turﬁng retweets and approximately 99% of the black-market
retweets on average. In contrast, dominant applications gen-
erated approximately 40% of the normal retweets on aver-
age. Therefore, the ratio of the dominant applications can
be a feature of crowdturﬁng tweets.
5.3 Unreachable Retweeter
We observe that most retweeters of a crowdturﬁng tweet
do not follow the user who posts the tweet because crowd-
turﬁng services promote the tweet to unspeciﬁed individuals
without considering their friendships on Twitter. But, in
general, a tweet is propagated between users who are con-
nected with each other on Twitter. Thus, retweeters are
usually connected to a posting user by follower-following re-
lationships.
To attest the observation, we measure how many retweet-
ers are unreachable to posting users on Twitter. Figure 7
shows that approximately 80% of the crowdturﬁng tweets
have over 80% of unreachable retweeters. In contrast, less
than 10% of normal tweets have over 80% of unreachable
retweeters. Hence, the ratio of the unreachable retweeters is
another feature of crowdturﬁng tweets.
5.4 Click Information
One of the main purpose of malicious accounts in OSNs is
spreading links to many OSN users to promote their websites
or spread malwares. When malicious accounts post tweets
with malicious links, they abnormally boost the tweets to
expose the links to as many users as possible. Thus, de-
tecting URL tweets retweeted by crowdturﬁng services is an
important problem.
Our hypothesis is that when retweeting tweets that con-
tain links, crowdturﬁng accounts are not willing to click on
the links because it is not their duty. Therefore, even if a
tweet with a link is heavily retweeted by such services, the
number of clicks that the link receives could be small.
To conﬁrm our hypothesis, we should measure how many
times a link in a tweet is clicked on. Fortunately, many
Twitter users use URL shortening services (e.g., bit.ly and
goo.gl) to share URLs via Twitter and the services provide
the click analytics for each shortened URL [22]. This allows
us to count the number of clicks that each link receives.
We extract tweets that contain bit.ly and goo.gl short-
ened URLs from our dataset: 6,024 normal tweets, 3,093
crowdturﬁng tweets, and 282 black-market tweets (when we
purchased retweets from black markets, all our tweets con-
tained shortened URLs.) We crawl the click analytics of
each shortened URL and extract the number of clicks via
Twitter according to the referrer information.
Figure 8 shows the ratio of the number of clicks to the
number of retweets per tweet. Over 80% of links in the
normal tweets receive a larger number of clicks than the
number of retweets. However, approximately 90% of links
in the crowdturﬁng tweets receive a smaller number of clicks
than the number of retweets. Furthermore, most of the
links in the black-market tweets are never clicked on. From
the results, we conﬁrm that most crowdturﬁng and black-
market accounts perform retweets without clicking on con-
tained links because they have no reason to visit the links
to retweet them. Therefore, we use the click information as
the ﬁnal feature of crowdturﬁng tweets.
6. DETECTION OF CROWDTURFING TAR-
GETS
In this section, we explain how we build our classiﬁers,
CrowdTarget, to detect crowdturﬁng targets and evaluate
their accuracy. We treat both crowdturﬁng tweets and black-
market tweets as malicious tweets and attempt to distin-
guish them from normal tweets.
6.1 Building Classiﬁers
We ﬁrst explain how we prepared training and testing data
using the dataset in Section 3. Note that in real-world ser-
vices, the number of malicious messages is fairly smaller than
the number of normal messages. For example, Twitter has
announced that the portion of spam tweets is approximately
1% of the total tweets [26]. Therefore, we decided to set the
ratio of malicious tweets as 1% of the total tweets. We over-
sampled normal tweets to satisfy the requirement. I.e., we
randomly duplicated normal tweets until their number be-
came 99 times larger than the number of malicious tweets.
We built classiﬁers by using the seven features of retweets
explained in Section 5: (i) mean, (ii) standard deviation,
(iii) skewness, and (iv) kurtosis of retweet time distribution,
(v) the ratio of dominant applications used for retweets,
(vi) the ratio of unreachable retweeters, and (vii) the ra-
tio of the number of clicks to the number of retweets for
tweets containing URLs. We normalized all feature values
to be lie between 0 and 1. With these features, we tested
several classiﬁers provided by the scikit-learn library (a
799Figure 6: Ratio of the most dominant application
performing retweets. Almost the same applications
generate crowdturﬁng and black-market retweets
unlike normal retweets.
Figure 9: ROC curve showing TPRs and FPRs of
CrowdTarget. We test Ada boost, Gaussian Na¨ıve
Bayes, and k-nearest neighbors algorithms with 10-
fold cross validation.
Python machine-learning library) [21] and then selected top
three classiﬁers showing good accuracy: Ada Boost, Gaus-
sian na¨ıve Bayes, and k-nearest neighbors. We validated
classiﬁcation results with 10-fold cross-validation.
6.2 Basic Classiﬁcation
First, we distinguish malicious tweets from normal tweets
without using click information to deal with both tweets
with and without URLs. Figure 9 shows receiver operating
characteristics (ROC) curves of the algorithms that draw
how TPRs change according to the changes of FPRs. We
deﬁne TPR and FPR are as follows:
T P R =
#T P
#T P + #F N
and F P R =
#F P
#F P + #T N
,
where TP stands for true positive and FP stands for false
positive.
We aim to build a classiﬁer whose target FPR is 0.01
while increasing TPR as high as possible. When the FPR
was 0.01, the TPR of the k-nearest neighbors algorithm was
0.96, the TPR of the Ada Boost algorithm was 0.95, and
the TPR of the Gaussian na¨ıve Bayes algorithm was 0.87.
Therefore, we selected the k-nearest neighbors algorithm as
our classiﬁer.
We also measured the area under the ROC curve (AUC)
values of the three algorithms. The AUC of the Ada Boost
algorithm was 0.994, the AUC of the k-nearest neighbors
algorithm was 0.991, and the AUC of the Gaussian na¨ıve
Bayes algorithm was 0.99.
6.3 Classiﬁcation with Click Information
Next, we distinguish the malicious tweets containing URLs
from the normal tweets containing URLs by additionally
considering how many times the URLs are clicked on. We
extracted tweets containing bit.ly and goo.gl links from
our dataset. Then, we classiﬁed them with a link-based fea-
ture: the ratio of the number of clicks to the number of
retweets. Since the k-nearest neighbors algorithm showed
the best results in Section 6.2, we only tested the algorithm
in this experiment for simplicity.
Figure 7: Ratio of unreachable retweeters per tweet.
Most crowdturﬁng and black-market retweets are
generated by unreachable retweeters who do not fol-
low the posting users.
Figure 8: Ratio of the number of clicks to the num-
ber of retweets per tweet. Unlike normal retweet-
ers, crowdturﬁng and black-market retweeters do
not click the URLs included in the retweeted tweets.
800Figure 10: ROC curve showing TPRs and FPRs of
CrowdTarget in distinguishing with click informa-
tion and without click information. We only test
k-nearest neighbors algorithm with 10-fold cross val-
idation.
Figure 10 compares the classiﬁcation results with and with-
out click information. CrowdTarget increased accuracy by
additionally considering click information. The TPR in-
creased from 0.95 to 0.98 at FPR of 0.01, and the AUC
increased from 0.989 to 0.993. Therefore, we conclude that
the click information is useful to detect the malicious tweets
with links.
The main shortcoming of this evaluation is that we cannot
check other links that do not associated with bit.ly and
goo.gl because we have no mechanism to obtain their click
information. We can solve the problem if we can access the
click information of t.co links in future (Section 7.4).
6.4 Error Analysis
In this section, we analyze the reasons of false negatives
and false positives.
6.4.1 False-negative analysis
We analyzed the malicious tweets that CrowdTarget could
not detect (i.e., false negatives) and ﬁgured out the follow-
ing three reasons. First, we observed that CrowdTarget
misjudged certain crowdturﬁng tweets that received a small
number of retweets. Figure 11a compares the number of
retweets of the detected crowdturﬁng tweets and that of the
undetected crowdturﬁng tweets. The undetected crowdturf-
ing tweets had a smaller number of retweets than that of
the detected crowdturﬁng tweets. Approximately 75% of
the undetected tweets were retweeted less than 100 times.
Although CrowdTarget cannot detect crowdturﬁng tweets
with a small number of retweets, it is not a serious problem
because their negative eﬀects against normal Twitter users
are limited.
Next, we discovered that the ratio of unreachable retweet-
ers led to more errors than other features in CrowdTarget.
Figure 11b shows that approximately 50% of the undetected
crowdturﬁng tweets were mostly retweeted by reachable ac-
counts; the ratio of unreachable retweeters were approxi-
mately 17%. We expect that the posting users of such un-
detected crowdturﬁng tweets bought followers on the same
(a) The number of retweets of detected and unde-
tected crowdturﬁng tweets
(b) The ratio of unreachable retweeters of de-
tected and undetected crowdturﬁng tweets
(c) The click ratio of detected and undetected
crowdturﬁng tweets
Figure 11: Comparisons between detected and un-
detected crowdturﬁng tweets
crowdturﬁng service, so that their tweets will be frequently
retweeted by shared followers.
Lastly, on the analysis of false negatives in the classiﬁca-
tion with click information, we recognized that a few links in
801the undetected crowdturﬁng tweets receive a larger number
of clicks than retweets (Figure 11c). We searched those links
on Twitter and found that they were distributed via many
other tweets. Therefore, we expect that the number of clicks
we measured is the aggregated number of clicks originated
from every tweet containing the same links. Unfortunately,
we cannot diﬀerentiate the number of clicks per tweet be-
cause bit.ly and goo.gl APIs only return domain name
when retrieving referrer information (e.g., t.co and twit-
ter.com). If we can access private data of bit.ly, goo.gl,
or Twitter, we can exclude clicks from other tweets such that
we can decrease the false-negative rate of CrowdTarget.
6.4.2 False-positive analysis
We manually analyzed the normal tweets classiﬁed as ma-
licious by CrowdTarget (i.e., false positives). Most of the
false positives are due to automated applications or embed-
ded tweets [2].
First, we found that tweets of a few veriﬁed accounts were
retweeted by automated applications. Table 2 shows ex-
amples of veriﬁed accounts that received retweets from the
automated applications. We visited homepages of the appli-
cations to know their purposes and identiﬁed that they are
automatic retweet applications. For example, TweetAdder
is a famous automated application that was sued by Twitter
due to its creation of many spam tweets [7]. Therefore, in
fact, these are not false positives.
Second, CrowdTarget classiﬁed the embedded tweets in
websites as malicious. Twitter oﬀer an application, “Twit-
ter Web Client”, to allow a user to embed his or her tweets
into a website. Any visitors of the website can retweet em-
bedded tweets. However, we cannot guarantee that the visi-
tors who have retweeted the embedded tweets are the user’s
followers. Consequently, the ratio of unreachable retweeters
of embedded tweets is higher than normal tweets such that
they can be misclassiﬁed. We think that if we can access
the private date of Twitter, e.g., IP addresses of retweeters,
we can avoid this problem.
7. FEATURE ROBUSTNESS
In this section, we discuss the robustness of our features
against feature fabrication attempts.
7.1 Retweet Time Distribution
Retweeters can cooperate each other to artiﬁcially manip-
ulate retweet time distributions. For the goal, they should
arrange a retweet time schedule similar with a normal retweet
time distribution and perform retweets as scheduled. How-
ever, it is diﬃcult to do that by themselves because crowd-
turﬁng workers act independently.
The crowdturﬁng services also can attempt to manipulate
the retweet time distributions. First, the services can manip-
ulate every boosting task of a worker by installing a program
at the worker’s device. However, it is a strong assumption
because the services need to persuade workers to install a
program or install the software without the perception of
workers.
Second, the services can handle every boosting task at the
server. The services collect the tasks of workers and trans-
mit the tasks to the target OSN when they wants. However,