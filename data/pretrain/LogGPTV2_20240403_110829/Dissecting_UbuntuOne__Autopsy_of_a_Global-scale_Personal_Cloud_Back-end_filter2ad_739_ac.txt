the variability of the R/W ratio in U1 (1-hour bins). The
boxplot in Fig. 2(c) shows that the R/W ratio variability can
be important, exhibiting diﬀerences of 8x within the same
day. Moreover, the median (1.14) and mean (1.17) values of
the R/W ratio distribution point out that the U1 workload
is slightly read-dominated, but not as much as it has been
observed in Dropbox [2]. One of the reasons for this is that
the sharing activity in U1 was much lower than for Dropbox.
We also want to explore if the R/W ratios present patterns
or dependencies along time due to the working habits of
users. To verify whether R/W ratios are independent along
time, we calculated the autocorrelation function (ACF) for
each 1-hour sample (see Fig. 2(c)). To interpret Fig. 2(c), if
R/W ratios are completely uncorrelated, the sample ACF is
approximately normally distributed with mean 0 and vari-
ance 1/N , where N is the number of samples. The 95% con-
ﬁdence limits for ACF can then be approximated to ±2/√N .
As shown in Fig. 2(c), R/W ratios are not independent,
since most lags are outside 95% conﬁdence intervals, which
indicates long-term correlation with alternating positive and
negative ACF trends. This evidences that the R/W ratios
of U1 workload are not random and follow a pattern also
guided by the working habits of users.
Concretely, averaging R/W ratios for the same hour along
the whole trace, we found that from 6am to 3pm the R/W
ratio shows a linear decay. This means that users download
more content when they start the U1 client, whereas uploads
are more frequent during the common working hours. For
evenings and nights we found no clear R/W ratio trends.
We conclude that diﬀerent Personal Clouds may exhibit
disparate R/W ratios, mainly depending on the purpose and
strengths of the service (e.g., sharing, content distribution).
Moreover, R/W ratios exhibit patterns along time, which
can be predicted in the server-side to optimize the service.
5.2 File-based Workload Analysis
File operation dependencies. Essentially, in U1 a ﬁle
can be downloaded (or read) and uploaded (or written) mul-
tiple times, until it is eventually deleted. Next, we aim at
inspecting the dependencies among ﬁle operations [17, 18],
which can be RAW (Read-after-Write), WAW (Write-after-
Write) or DAW (Delete-after-Write). Analogously, we have
WAR, RAR and DAR for operations executed after a read.
First, we inspect ﬁle operations that occur after a write
(Fig. 3(a)). We see that WAW dependencies are the most
common ones (30.1% of 170.01M in total). This can be due
to the fact that users regularly update synchronized ﬁles, such
as documents of code ﬁles. This result is consistent with the
results in [17] for personal workstations where block updates
are common, but diﬀers from other organizational storage
systems in which ﬁles are almost immutable [18]. Further-
more, the 80% of WAW times are shorter than 1 hour, which
seems reasonable since users may update a single text-like
ﬁle various times within a short time lapse.
In this sense, Fig. 3(a) shows that RAW dependencies
are also relevant. Two events can lead to this situation: (i)
the system synchronizes a ﬁle to another device right after
its creation, and (ii) downloads that occur after every ﬁle
update. For the latter case, reads after successive writes
can be optimized with sync deferment to reduce network
overhead caused by synchronizing intermediate versions to
multiple devices [5]. This has not been implemented in U1.
Second, we inspect the behavior of X-after-Read depen-
dencies (Fig. 3(b)). As a consequence of active update pat-
terns (i.e., write-to-write) and the absence of sync defer-
ment, we see in Fig. 3(b) that WAR transitions also occur
1601
0.8
F
D
C
0.6
0.4
0.2
0
Total inter-operation times: 73.17M
WAW depen. (44%) 
RAW depen. (30%) 
DAW depen. (26%) 
0.1s
1s
1h
Inter-operation times
60s
8h 1d
1w 1m
1
0.8
0.6
0.4
0.2
F
D
C
0
0
10
1
0.8
0.6
F
D
C
0.4
0.2
0
Total inter-operation times: 33.84M
WAR depen. (10%)
RAR depen. (66%)
DAR depen. (24%)
1
10
2
10
Downloads per file
3
10
0.1s
1s
60s
1h
8h 1d
1w 1m
Inter-operation times
0,30
0,25
F
D
C
0,20
0,15
0,10
0,05
File lifetime
Directory lifetime
F
D
C
0.2
0.15
0.1
0.05
0
0.1s 1s
1m 10m 1h 8h
1d
Time (Days)
2
4
6
8
10
12
14
16
18
20
22
24
26
28
Time (Days)
(a) X-after-Write inter-arrival times.
(b) X-after-Read inter-arrival times.
(c) File/directory lifetime.
Figure 3: Usage and behavior of ﬁles in U1.
1
0.8
0.6
0.4
0.2
F
D
C
0
10
0
Distribution of duplicated files per hash
Data deduplication ratio: 0.171 
1
10
2
10
3
10
Duplicated files
F
D
C
1
0.8
0.6
0.4
0.2
0
F
D
C
1
0.8
0.6
0.4
0.2
0
All files
90% < 1MB
10-3
1 102
File Size (MBytes)
jpg
mp3
pdf
doc
java
zip
10-5
10-4
10-3
10-2
10-1
100
101
102
103
File Size (MBytes)
0.3
0.25
0.2
0.15
0.1
s
e
l
i
f
f
o
n
o
i
t
c
a
r
F
Popularity vs storage consumption of file categories
Code
Pictures
0.05
Binary
0
0
Documents
Compressed
Audio/Video
0.05
0.1
0.15
0.2
0.25
Fraction of storage space
(a) Duplicated ﬁles per hash.
(b) Size of ﬁles per extension.
(c) Number/storage share of ﬁle types.
Figure 4: Characterization of ﬁles in U1.
within reduced time frames compared to other transitions.
Anyway, this dependency is the least popular one yielding
that ﬁles that are read tend not to be updated again.
In Fig. 3(b), 40% of RAR times fall within 1 day. RAR
times are shorter than the ones reported in [18], which can
motivate the introduction of caching mechanisms in the U1
back-end. Caching seems specially interesting observing the
inner plot of Fig. 3(b) that reveals a long tail in the distri-
butions of reads per ﬁle. This means that a small fraction
of ﬁles is very popular and may be eﬀectively cached.
By inspecting the Delete-after-X dependencies, we de-
tected that around 12.5M ﬁles in U1 were completely unused
for more than 1 day before their deletion (9.1% of all ﬁles).
This simple observation on dying ﬁles evidences that warm
and/or cold data exists in a Personal Cloud, which may mo-
tivate the involvement of warm/cold data systems in these
services (e.g., Amazon Glacier, f4 [19]). To eﬃciently man-
aging warm ﬁles in these services is object of current work.
Node lifetime. Now we focus on the lifetime of user ﬁles
and directories (i.e., nodes). As shown in Fig. 3(c), 28.9%
of the new ﬁles and and 31.5% of the recently created direc-
tories are deleted within one month. We also note that the
lifetime distributions of ﬁles and directories are very similar,
which can be explained by the fact that deleting a directory
in U1 triggers the deletion of all the ﬁles it contains.
This ﬁgure also unveils that a large fraction of nodes are
deleted within a few hours after their creation, especially
for ﬁles. Concretely, users delete 17.1% of ﬁles and 12.9% of
directories within 8 hours after their creation time.
All in all, in U1 ﬁles exhibit similar lifetimes than ﬁles in
local ﬁle systems. For instance, Agrawal et al. in [15] ana-
lyzed the lifetimes of ﬁles in corporative desktop computers
for ﬁve years. They reported that around 20% to 30% of
ﬁles (depending on the year) in desktop computers present
a lifetime of one month, which agrees with our observations.
This suggests that users behave similarly deleting ﬁles either
in synchronized or local folders.
5.3 File Deduplication, Sizes and Types
File-based deduplication. The deduplication ratio (dr)
is a metric to quantify the proportion of duplicated data. It
takes real values in the interval [0, 1), with 0 signaling no ﬁle
deduplication at all, and 1 meaning full deduplication. It is
expressed as dr = 1 − (Dunique/Dtotal), where Dunique is
the amount of unique data, and Dtotal is equal to the total
storage consumption.
We detected a dr of 0.171, meaning that 17% of ﬁles’ data
in the trace can be deduplicated, which is similar (18%) to
that given by the recent work of Li et al. [5]. This suggests
that ﬁle-based cross-user deduplication could be a practical
approach to reduce storage costs in U1.
Moreover, Fig. 4(a) demonstrates that the distribution of
ﬁle objects w.r.t unique contents exhibits a long tail. This
means that a small number of ﬁles accounts for a very large
number of duplicates (e.g., popular songs), whereas 80% ﬁles
present no duplicates. Hence, ﬁles with many duplicates
represent a hot spot for the deduplication system, since a
large number of logical links point to a single content.
File size distribution. The inner plot of Fig. 4(b) il-
lustrates the ﬁle size distribution of transferred ﬁles in the
system. At ﬁrst glance, we realize that the vast majority of
ﬁles are small [14, 15, 16]. To wit, 90% of ﬁles are smaller
than 1MByte. In our view, this can have important impli-
cations on the performance of the back-end storage system.
The reason is that Personal Clouds like U1 use object stor-
age services oﬀered by cloud providers as data store, which
has not been designed for storing very small ﬁles [8].
In this sense, Fig. 4(b) shows the ﬁle size distribution of
the most popular ﬁle extensions in U1. Non-surprisingly, the
distributions are very disparate, which can be used to model
realistic workloads in Personal Cloud benchmarks [3]. It is
worth noting that in general, incompressible ﬁles like zipped
ﬁles or compressed media are larger than compressible ﬁles
(docs, code). This observation indicates that compressing
ﬁles does not provide much beneﬁts in many cases.
File types: number vs storage space. We classi-
ﬁed ﬁles belonging to the 55 most popular ﬁle extensions
into 7 categories: Pics (.jpg, .png, .gif, etc.), Code (.php,
.c, .js, etc.), Docs (.pdf, .txt, .doc, etc.), Audio/Video
(.mp3, .wav, .ogg, etc.), Application/Binary (.o, .msf, .jar,
etc.) and Compressed (.gz, .zip, etc.). Then, for each cat-
161RPC
Session
Auth
Storage
01/15
01/16
02/06
7
10
6
10
5
10
r
u
o
h
r
e
p
s
t
s
e
u
q
e
R
8
6
4
2
r
u
o
h
r
e
p
s
r
e
s
U
4
x 10
Online vs Active users in U1
Active users
Online users
4
10
6AM
6PM
6AM
6PM
6AM
6AM 6PM 6AM
Time
0
0
2
4
6
8
10 12 14 16 18 20 22 24 26 28 30
Time (days)
Figure 5: DDoS attacks detected in our trace.
Figure 6: Online vs active users per hour.
egory, we calculated the ratio of the number of ﬁles to the
total in the system. We did the same for the storage space.
This captures the relative importance of each content type.
Fig. 4(c) reveals that Audio/Video category is one of the
most relevant types of ﬁles regarding the share of consumed
storage, despite the fraction of ﬁles belonging to this class
is low. The reason is that U1 users stored .mp3 ﬁles, which
are usually larger than other popular text-based ﬁle types.
Further, the Code category contains the highest fraction
of ﬁles, indicating that many U1 users are code developers
who frequently update such ﬁles, despite the storage space
required for this category is minimal. Docs are also popular
(10.1%), subject to updates and hold 6.9% of the storage
share. Since the U1 desktop client lacks delta updates and
deferred sync, such frequent updates pose a high stress for
desktop clients and induce signiﬁcant network overhead [5].
5.4 DDoS and Abuse of Personal Clouds
A Distributed Denial of Service (DDoS) can be deﬁned as
the attempt to disrupt the legitimate use of a service [20].
Normally, a DDoS attack is normally accompanied by some
form of fraudulent resource consumption in the victim’s side.