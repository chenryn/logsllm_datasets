# 23｜ 实战：如何用深度学习模型实现Sparrow RecSys的个性化推荐功能？你好，我是王喆。今天又是一堂实战课。在这节课里，我会带你利用我们现阶段掌握的所有知识，来实现SparrowRecSys中"猜你喜欢"的功能。具体来说，我们会根据一位用户的历史行为，为 TA推荐可能喜欢的电影。这个功能几乎会用到所有的推荐系统模块，包括离线的特征工程、模型训练以及线上的模型服务和推荐逻辑的实现。如果说完成了第 14 节课slate-object="inline"的"相似电影"功能，还只是你"武功小成"的标志，那啃透了这节课的实践，就代表你掌握了推荐系统技术框架中的大部分内容，你就能在推荐系统的实际工作中做到"驾轻就熟"啦。"清点技能库"，看看我们已有的知识储备有哪些正式开始实践之前，我们还是先来清点一次自己的技能库。看看经过推荐模型篇的学习，我们技能库中的"兵器"又增加了多少，哪些可以用来实现"猜你喜欢"这个功能。下面，我就按照从离线到线上，由数据到模型的顺序，为你依次梳理一下特征工程、模型离线训练、模型服务、推荐服务器逻辑这四大部分的技能点。1. 模型特征工程特征工程是所有机器学习项目的起点，咱们的推荐模型也不例外。为了训练推荐模型，我们需要准备好模型所需的样本和特征。此外，在进行模型线上推断的时候，推荐服务器也需要线上实时拼装好包含了用户特征、物品特征、场景特征的特征向量，发送给推荐模型进行实时推断。在"模型实战准备二"这节课，我们就通过 Spark 处理好了TensorFlow 训练所需的训练样本，并把 Spark 处理好的特征插入了 Redis特征数据库，供线上推断使用。不熟悉这部分内容的同学，最好再复习一下相关内容，把这把武器装进自己的技能库。2. 模型离线训练为了在线上做出尽量准确或者说推荐效果尽量好的排序，我们需要在离线训练好排序所用的推荐模型。我们在这一篇中学习和实践的所有深度推荐模型，都是围绕着这个目的展开的。虽然这些深度推荐模型的结构各不相同，但它们的输入、输出都是一致的，输入是由不同特征组成的特征向量，输出是一个分数，这个分数的高低代表了这组特征对应的用户对物品的喜好程度。具体实践的时候，我们在 TensorFlow 平台上实现了 EmbeddingMLP、Wide&Deep、NeuralCF、双塔模型、DeepFM等几种不同的深度推荐模型，它们中的任何一个都可以支持"猜你喜欢"的排序功能。在实际的工业级系统中，我们会通过离线、在线等不同的评估手段来挑出最好的那个模型，去支持真实的应用场景。在SparrowRecsys 中，我们以 NeuralCF模型为例，实现"猜你喜欢"功能。其他模型的上线方法与 NeuralCF几乎一致，唯一的区别是，对于不同的模型来说，它们在模型服务的部分需要载入不同的模型文件，并且在线上预估的部分也要传入模型相应的输入特征。3. 模型服务模型服务是推荐系统中连接线上环境和线下环境的纽带之一（另一个关键的纽带是特征数据库）。在离线训练好模型之后，为了让模型在线上发挥作用，做出实时的推荐排序，我们需要通过模型服务的模块把推荐模型部署上线。我们曾经在第 13 节课slate-object="inline"中详细介绍过主流的模型服务方法，它们是"预存推荐结果"，"预训练Embedding+ 轻量级线上模型"，"利用 PMML 转换和部署模型"以及"TensorFlowServing"。因为我们这一篇的深度学习模型都是基于 TensorFlow训练的，所以这节课我们也会采用 TensorFlow Serving作为模型服务的方式。4. 推荐服务器内部逻辑实现模型服务虽然可以做到"猜你喜欢"中电影的排序，但要进行排序，仍然需要做大量的准备工作，比如候选集的获取，召回层的构建，特征的获取和拼装等等。这些推荐逻辑都是在推荐服务器内部实现的。推荐服务器就像推荐系统的线上的心脏，是所有线上模块的核心。我们曾经在"相似电影"功能中实现过整套的推荐逻辑，今天我们重点关注其中不同的部分，就是特征的拼装，以及从推荐服务器内部请求模型服务API 的方法。至此，我们准备好了自己的技能库。接下来，就让我们使出十八般武艺，来打造"猜你喜欢"这个推荐功能吧。"猜你喜欢"推荐功能的技术架构与"相似电影"功能一样，"猜你喜欢"相关的技术架构同样是由数据模型部分、线上部分和前端部分组成的。我们先来看看整个功能的技术架构图，再来说说每部分的具体实现细节。下图1就是"猜你喜欢"功能的技术架构图，接下来，你就跟着我，按照从左上到右下的顺序，一起随着数据流的走向过一遍这个架构图吧。![](Images/3c840f844b9c78300b5750421aba0f04.png)savepage-src="https://static001.geekbang.org/resource/image/64/ee/642ca5a4260959fcce69b97000c3c4ee.jpg"}图1 "猜你喜欢"功能的技术架构图首先，我们来看数据和模型部分。左上角是我们使用的数据集MovieLens，它经过 Spark的处理之后，会生成两部分数据，分别从两个出口出去，特征部分会存入 Redis供线上推断时推荐服务器使用，样本部分则提供给 TensorFlow训练模型。 TensorFlow 完成模型训练之后，会导出模型文件，然后模型文件会载入到TensorFlow Serving 中，接着 TensorFlow Serving 会对外开放模型服务API，供推荐服务器调用。接下来，我们再看推荐服务器部分。在这部分里，基于 MovieLens数据集生成的候选电影集合会依次经过候选物品获取、召回层、排序层这三步，最终生成"猜你喜欢"的电影推荐列表，然后返回给前端，前端利用HTML 和 JavaScript把它们展示给用户。整个过程中，除了排序层和 TensorFlow Serving的实现，其他部分我们都已经在之前的实战中一一实现过。所以今天，我们会重点讲解推荐服务器排序层和TensorFlow Serving 的实现。排序层 +TensorFlow Serving 的实现在推荐服务器内部，经过召回层之后，我们会得到几百量级的候选物品集。最后我们到底从这几百部电影中推荐哪些给用户，这个工作就交由排序层来处理。因为排序的工作是整个推荐系统提高效果的重中之重，在业界的实际应用中，往往交由评估效果最好的深度推荐模型来处理。整个的排序过程可以分为三个部分：1.       准备线上推断所需的特征，拼接成 JSON    格式的特征样本；        2.       把所有候选物品的特征样本批量发送给 TensorFlow Serving    API；    3.       根据 TensorFlow Serving API    返回的推断得分进行排序，生成推荐列表。        接下来，我们就详细来讲讲这三步中的实现重点。**首先，第一步的实现重点在于特征样本的拼接**。因为实践例子里，我们选用了 NeuralCF 作为排序模型，而NerualCF 所需的特征只有 `userId` 和 `itemId`，所以特征是比较好准备的。我们下面看一下如何拼接特征形成模型推断所需的样本。详细的代码，你可以参考com.wzhe.sparrowrecsys.online.recprocess.RecForYouProcess。    /**     * call TenserFlow serving to get the NeuralCF model inference result     * @param user              input user     * @param candidates        candidate movies     * @param candidateScoreMap save prediction score into the score map     */    public static void callNeuralCFTFServing(User user, List candidates, HashMap candidateScoreMap){        if (null == user || null == candidates || candidates.size() == 0){            return;        }        //保存所有样本的JSON数组        JSONArray instances = new JSONArray();        for (Movie m : candidates){            JSONObject instance = new JSONObject();            //为每个样本添加特征，userId和movieId            instance.put("userId", user.getUserId());            instance.put("movieId", m.getMovieId());            instances.put(instance);        }        JSONObject instancesRoot = new JSONObject();        instancesRoot.put("instances", instances);        //请求TensorFlow Serving API        String predictionScores = asyncSinglePostRequest("http://localhost:8501/v1/models/recmodel:predict", instancesRoot.toString());        //获取返回预估值        JSONObject predictionsObject = new JSONObject(predictionScores);        JSONArray scores = predictionsObject.getJSONArray("predictions");        //将预估值加入返回的map        for (int i = 0 ; i  Preferences -\>Plugins -\> 输入 Python -\> 选择插件 Python Community Edition进行安装。 ![](Images/8984b6465e66779b8ba17e1110d5e9f4.png)savepage-src="https://static001.geekbang.org/resource/image/e3/bb/e394886105fyyc1d5da5f4a497d002bb.jpg"}图2 为IDEA安装Python插件**接着是安装本地 Python环境。** 使用过 Python 的同学可能知道，由于 Python的流行版本比较多，不同软件对于 Python环境的要求也不同，所以我们直接更改本地的 Python环境比较危险，因此，我推荐你使用Anaconda来创建不同 Python的虚拟环境，这样就可以为咱们的 SparrowRecsys 项目，专门创建一个使用Python3.7 和支持 TensorFlow2.3 的虚拟 Python环境了。 具体的步骤我推荐你参考 Anaconda的 [官方 TensorFlow环境安装指导slate-object="inline"。这里，我再带你梳理一下其中的关键步骤。首先，我们去\[Anaconda的官方地址\] (https://www.anaconda.com/products/individual) 下载并安装 Anaconda（最新版本使用Python3.8，你也可以去历史版本中安装 Python3.7 的版本）。然后，如果你是Windows 环境，就打开 Anaconda Command Prompt，如果是 Mac 或 Linux环境，你就打开terminal。都打开之后，你跟着我输入下面的命令：    conda create -n tf tensorflow    conda activate tf第一条命令会创建一个名字为 tf 的 TensorFlow 环境，第二条命令会让Anaconda 为我们在这个 Python 环境中准备好所有 Tensorflow 需要的 Python库依赖。接着，我们直接选择 TensorFlow 的 CPU 版本。不过，如果是有 GPU环境的同学，可以把命令中的`tensorflow`替换为`tensorflow-gpu`，来安装支持 GPU的版本。到这里，我们就利用 Anaconda 安装好了 TensorFlow 的 Python环境。 **最后是配置 IDEA 的项目 Python环境。** 现在 IDEA 的 Python 插件有了，本地的 TensorFlow Python环境也有了，接下来，我们就要在 IDEA 中配置它的 Python环境。这个配置的过程主要可以分成三步，我们一起来看看。第一步，在 IDEA 中添加项目 PythonSDK。你直接按照我给出的这个路径配置就可以了：File-\>Project Structure-\> SDKs -\> 点击 + 号 -\>Add Python SDK ，这个路径在操作界面的显示如图3。 ![](Images/2f0533e8b652f1b8c57775ce8d901ca2.png)savepage-src="https://static001.geekbang.org/resource/image/99/bd/996c5740f59752918154c825ab0b01bd.jpg"}图3 添加Python SDK添加完 Python SDK，接下来，我们配置 Conda Environment 为项目的 PythonSDK，IDEA 会自动检测到系统的 Conda环境相关路径，你选择按照自动填充的路径就好，具体的操作你可以看下图4。 ![](Images/55d2965391279e0e49c520eb93b9172d.png)savepage-src="https://static001.geekbang.org/resource/image/62/cf/6220bfb6ce685d4bb2d5688e358a75cf.jpg"}图4 选择Conda Enviroment为IDEA Python环境最后，我们为 TFRecModel 模块配置 Python 环境。我们选择 ProjectStructure Modules 部分的 tfmodel 模块，在其上点击右键来 addpython。 ![](Images/18126225b21b5543691e96fbba40b375.png)savepage-src="https://static001.geekbang.org/resource/image/16/1a/164165823e10fede6114e4ac5244e71a.jpg"}图5 为tfmodel模块配置Python环境设置好的 tfmode 模块的 Python 环境应该如图 6所示。 ![](Images/f5bc560710418c70dc37e5cc58db569e.png)savepage-src="https://static001.geekbang.org/resource/image/47/c2/47105cd66e322260ae455a68cc9fc8c2.jpg"}图6 配置好的Python环境如果你按照上面的步骤，那 Python 和 TensorFlow的环境应该已经配置好了，但我们到底怎么验证一下所有的配置是否成功呢？下面，我们就来写一个测试模型来验证一下。如何在 TensorFlow 上构建你的第一个深度学习模型？这里，我们选择了 TensorFlow官方教程上的例子作为我们深度学习模型的"初体验"，你可以参考https://www.tensorflow.org/tutorials/quickstart/beginner?hl=zh_cn来构建这个模型。这里，我再对其中的关键内容做一个补充讲解。我先把测试模型的代码放到了下面，你可以边看代码边参考我的讲解。首先，我们要清楚的是这个测试模型做了一件什么事情。它要处理的数据集是一个手写数字的MNIST数据集，所以模型其实是一个多分类模型，它的输入是这个手写数字的图片（一个28\*28 维的图片），输出是一个 0-9的多分类概率模型。![](Images/efca746d747d421072ce728ce21b4d98.png)savepage-src="https://static001.geekbang.org/resource/image/0c/44/0cfa5a28c6006d47e25fb6f1f7877f44.jpg"}图7 MNIST数据集其次，我们要清楚如何定义这个深度学习模型的结构。从代码中我们可以看出，测试模型使用了TensorFlow 的 Keras接口，这样就可以很清晰方便地定义一个三层神经网络了，它包括 28\*28的输入层，128 维的隐层，以及由 softmax构成的多分类输出层。之后是模型的训练，这里有 3 个参数的设定是很关键的，分别是 compile函数中的 optimizer、loss，以及 fit 函数中的 epochs。其中，optimizer指的是模型训练的方法，这里我们采用了深度学习训练中经常采用的 adam优化方法，你也可以选择随机梯度下降（SGD），自动变更学习率的AdaGrad，或者动量优化 Momentum等等。 loss指的是损失函数，因为这个问题是一个多分类问题，所以这个测试模型，我们使用了多分类交叉熵（SparseCategoricalCrossentropy）作为损失函数。epochs指的是训练时迭代训练的次数，单次训练指的是模型训练过程把所有训练数据学习了一遍。这里epochs=5 意味着模型要反复 5次学习训练数据，以便模型收敛到一个局部最优的位置。最后是模型评估的过程，因为在构建模型时，我们选择了准确度（Accuracy）作为评估指标，所以model.evaluate函数会输出准确度的结果。    import tensorflow as tf    //载入MINST数据集    mnist = tf.keras.datasets.mnist    //划分训练集和测试集    (x_train, y_train), (x_test, y_test) = mnist.load_data()    x_train, x_test = x_train / 255.0, x_test / 255.0    //定义模型结构和模型参数    model = tf.keras.models.Sequential([        //输入层28*28维矩阵        tf.keras.layers.Flatten(input_shape=(28, 28)),         //128维隐层，使用relu作为激活函数        tf.keras.layers.Dense(128, activation='relu'),         tf.keras.layers.Dropout(0.2),        //输出层采用softmax模型，处理多分类问题        tf.keras.layers.Dense(10, activation='softmax')    ])    //定义模型的优化方法(adam)，损失函数(sparse_categorical_crossentropy)和评估指标(accuracy)    model.compile(optimizer='adam',                  loss='sparse_categorical_crossentropy',                  metrics=['accuracy'])    //训练模型，进行5轮迭代更新(epochs=5）    model.fit(x_train, y_train, epochs=5)    //评估模型    model.evaluate(x_test,  y_test, verbose=2到这里，我们就介绍完了整个测试模型的全部流程。事实上，之后利用TensorFlow构建深度学习推荐模型的过程也是非常类似的，只是把其中特征处理、模型结构、训练方法进行了替换，整体的结构并没有变化。所以，理解测试模型的每一步对我们来说是非常重要的。说回我们的测试模型，如果 Python 和 TensorFlow的环境都配置正确的话，在 IDEA 中执行测试模型程序，你会看到 5轮训练过程，每一轮的准确度指标，以及最终模型的评估结果。    Epoch 1/5    1875/1875 [==============================] - 1s 527us/step - loss: 0.3007 - accuracy: 0.9121    Epoch 2/5    1875/1875 [==============================] - 1s 516us/step - loss: 0.1451 - accuracy: 0.9575    Epoch 3/5    1875/1875 [==============================] - 1s 513us/step - loss: 0.1075 - accuracy: 0.9670    Epoch 4/5    1875/1875 [==============================] - 1s 516us/step - loss: 0.0873 - accuracy: 0.9729    Epoch 5/5    1875/1875 [==============================] - 1s 517us/step - loss: 0.0748 - accuracy: 0.9767    313/313 - 0s - loss: 0.0800 - accuracy: 0.9743小结这节课，我们一起学习了 TensorFlow 的基础知识，搭建起了 TensorFlow 的使用环境，并且编写了第一个基于 Keras 的深度学习模型。TensorFlow的基本原理，就是根据深度学习模型架构构建一个有向图，让数据以张量的形式在其中流动起来。而安装 TensorFlow 有两种方法，一种是采用 Docker+Jupyter的方式，另一种是在本地环境安装 TensorFlow 所需的 python环境和所需依赖库。其中，Docker+Jupyter 的方式比较简单，而利用 IDEA来调试 TensorFlow代码的方法比较常用，我们要重点掌握。想要实现在 IDEA 中调试 TensorFlow代码，我们需要进行三步配置，分别是安装 IDEA 的 python编译器插件，安装本地的 Python 环境，以及配置 IDEA 的 Python环境。配置好了 Python 和 TensorFlow的环境之后，我们还要验证一下是不是所有的配置都成功了。在测试模型中，我们牢牢记住实现它的四个主要步骤，分别是载入数据、定义模型、训练模型和评估模型。当然，我把这些关键知识点总结在了下面的知识表格里，你可以看看。![](Images/dd0d055a1aed5c510a4c47ea3590af38.png)savepage-src="https://static001.geekbang.org/resource/image/d9/33/d906029b35925dd56c5c7270b330ce33.jpeg"}课后思考这是一堂实践课，所以今天的课后题就是希望你能完成 TensorFlow的环境配置。在配置、试验过程中遇到任何问题，你都可以在留言区提问，我会尽力去解答，也欢迎同学们分享自己的实践经验，互相帮助。我们下节课见！