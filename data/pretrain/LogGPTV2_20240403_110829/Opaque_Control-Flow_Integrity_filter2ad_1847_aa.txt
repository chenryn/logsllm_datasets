title:Opaque Control-Flow Integrity
author:Vishwath Mohan and
Per Larsen and
Stefan Brunthaler and
Kevin W. Hamlen and
Michael Franz
Opaque Control-Flow Integrity
Vishwath Mohan∗, Per Larsen†, Stefan Brunthaler†, Kevin W. Hamlen∗, and Michael Franz†
∗{vishwath.mohan,hamlen}@utdallas.edu
The University of Texas at Dallas
†{perl,s.brunthaler,franz}@uci.edu
University of California, Irvine
a result, code-reuse has largely replaced code-injection as one
of the top software security threats.
Abstract—A new binary software randomization and Control-
Flow Integrity (CFI) enforcement system is presented, which
is the ﬁrst to efﬁciently resist code-reuse attacks launched by
informed adversaries who possess full knowledge of
the in-
memory code layout of victim programs. The defense mitigates a
recent wave of implementation disclosure attacks, by which adver-
saries can exﬁltrate in-memory code details in order to prepare
code-reuse attacks (e.g., Return-Oriented Programming (ROP)
attacks) that bypass ﬁne-grained randomization defenses. Such
implementation-aware attacks defeat traditional ﬁne-grained ran-
domization by undermining its assumption that the randomized
locations of abusable code gadgets remain secret.
Opaque CFI (O-CFI) overcomes this weakness through a
novel combination of ﬁne-grained code-randomization and coarse-
grained control-ﬂow integrity checking. It conceals the graph of
hijackable control-ﬂow edges even from attackers who can view
the complete stack, heap, and binary code of the victim process.
For maximal efﬁciency, the integrity checks are implemented
using instructions that will soon be hardware-accelerated on
commodity x86-x64 processors. The approach is highly practical
since it does not require a modiﬁed compiler and can protect
legacy binaries without access to source code. Experiments using
our fully functional prototype implementation show that O-CFI
provides signiﬁcant probabilistic protection against ROP attacks
launched by adversaries with complete code layout knowledge,
and exhibits only 4.7% mean performance overhead on current
hardware (with further overhead reductions to follow on forth-
coming Intel processors).
I. MOTIVATION
Code-reuse attacks (cf., [5]) have become a mainstay of
software exploitation over the past several years, due to the
rise of data execution protections that nullify traditional code-
injection attacks. Rather than injecting malicious payload
code directly onto the stack or heap, where modern data
execution protections block it from being executed, attackers
now ingeniously inject addresses of existing in-memory code
fragments (gadgets) onto victim stacks, causing the victim
process to execute its own binary code in an unanticipated
order [38]. With a sufﬁciently large victim code section, the
pool of exploitable gadgets becomes arbitrarily expressive
(e.g., Turing-complete) [20], facilitating the construction of
arbitrary attack payloads without the need for code-injection.
Such payload construction has even been automated [34]. As
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’15, 8–11 February 2015, San Diego, CA, USA
Copyright 2015 Internet Society, ISBN 1-891562-38-X
http://dx.doi.org/10.14722/ndss.2015.23271
This has motivated copious work on defenses against code-
reuse threats. Prior defenses can generally be categorized into:
CFI [1] and artiﬁcial software diversity [8].
CFI restricts all of a program’s runtime control-ﬂows to a
graph of whitelisted control-ﬂow edges. Usually the graph is
derived from the semantics of the program source code or a
conservative disassembly of its binary code. As a result, CFI-
protected programs reject control-ﬂow hijacks that attempt
to traverse edges not supported by the original program’s
semantics. Fine-grained CFI monitors indirect control-ﬂows
precisely; for example, function callees must return to their
exact callers. Although such precision provides the highest
security, it also tends to incur high performance overheads (e.g.,
21% for precise caller-callee return-matching [1]). Because this
overhead is often too high for industry adoption, researchers
have proposed many optimized, coarser-grained variants of
CFI. Coarse-grained CFI trades some security for better
performance by reducing the precision of the checks. For
example, functions must return to valid call sites (but not
necessarily to the particular site that
invoked the callee).
Unfortunately, such relaxations have proved dangerous—a
number of recent proof-of-concept exploits have shown how
even minor relaxations of the control-ﬂow policy can be
exploited to effect attacks [6, 11, 18, 19]. Table I summarizes
the impact of several of these recent exploits.
Artiﬁcial software diversity offers a different but com-
plementary approach that randomizes programs in such a
way that attacks succeeding against one program instance
have a very low probability of success against other (in-
dependently randomized) instances of the same program.
Probabilistic defenses rely on memory secrecy—i.e., the effects
of randomization must remain hidden from attackers. One
of the simplest and most widely adopted forms of artiﬁcial
diversity is Address Space Layout Randomization (ASLR), which
randomizes the base addresses of program segments at load-
time. Unfortunately, merely randomizing the base addresses
does not yield sufﬁcient entropy to preserve memory secrecy
in many cases; there are numerous successful derandomization
attacks against ASLR [13, 26, 36, 37, 39, 42]. Finer-grained
diversity techniques obtain exponentially higher entropy by
randomizing the relative distances between all code points. For
example, binary-level Self-Transforming Instruction Relocation
(STIR) [45] and compilers with randomized code-generation
(e.g., [22]) have both realized ﬁne-grained artiﬁcial diversity
for production-level software at very low overheads.
Recently, a new wave of implementation disclosure at-
tacks [4, 10, 35, 40] have threatened to undermine ﬁne-grained
artiﬁcial diversity defenses. Implementation disclosure attacks
TABLE I.
CFI [1]
OVERVIEW OF CONTROL-FLOW INTEGRITY BYPASSES
ROPecker [7]
bin-CFI [50]
kBouncer [33]
CCFIR [49]
DeMott [12]
Goktas¸ et al. [18]
Davi et al. [11]
Goktas¸ et al. [19]
Carlini and Wagner [6]
Feb 2014
May 2014 (cid:47)
Aug 2014
Aug 2014
Aug 2014
(cid:47)
(cid:47)
(cid:47)
(cid:47)
(cid:47)
(cid:47)
(cid:47)
(cid:47)
(cid:47)
ROPGuard [16]
EMET [30]
(cid:47)
(cid:47)
(cid:47)
exploit information leak vulnerabilities to read memory pages of
victim processes at the discretion of the attacker. By reading the
in-memory code sections, attackers violate the memory secrecy
assumptions of artiﬁcial diversity, rendering their defenses
ineffective. Since ﬁnding and closing all information leaks
is well known to be prohibitively difﬁcult and often intractable
for many large software products, these attacks constitute a very
dangerous development in the cyber-threat landscape; there is
currently no well-established, practical defense.
This paper presents Opaque CFI (O-CFI): a new approach
to coarse-grained CFI that strengthens ﬁne-grained artiﬁcial
diversity to withstand implementation disclosure attacks. The
heart of O-CFI is a new form of control-ﬂow check that conceals
the graph of abusable control-ﬂow edges even from attackers
who have complete read-access to the randomized binary code,
the stack, and the heap of victim processes. Such access only
affords attackers knowledge of the intended (and therefore non-
abusable) edges of the control-ﬂow graph, not the edges left
unprotected by the coarse-grained CFI implementation. Artiﬁ-
cial diversiﬁcation is employed to vary the set of unprotected
edges between program instances, maintaining the probabilistic
guarantees of ﬁne-grained diversity.
Experiments show that O-CFI enjoys performance overheads
comparable to standard ﬁne-grained diversity and non-opaque,
coarse-grained CFI. Moreover, O-CFI’s control-ﬂow checking
logic is implemented using Intel x86/x64 memory-protection
extensions (MPX) that are expected to be hardware-accelerated
in commodity CPUs from 2015 onwards. We therefore expect
even better performance for O-CFI in the near future.
defense that tolerates implementation disclosures.
Our contributions are as follows:
• We introduce O-CFI, the ﬁrst low-overhead code-reuse
• We describe our implementation of a fully functional
prototype that protects stripped, x86 legacy binaries
without source code.
• Analysis shows that O-CFI provides quantiﬁable se-
curity against state-of-the-art exploits—including JIT-
ROP [40] and Blind-ROP [4].
Performance evaluation yields competitive overheads
of just 4.7% for computation-intensive programs.
•
II. THREAT MODEL
Our work is motivated by the emergence of attacks against
ﬁne-grained diversity and coarse-grained control-ﬂow integrity.
We therefore introduce these attacks and distill them into a
single, uniﬁed threat model.
A. Bypassing Coarse-Grained CFI
Ideally, CFI permits only programmer-intended control-ﬂow
transfers during a program’s execution. The typical approach
is to assign a unique ID to each permissible indirect control-
ﬂow target, and check the IDs at runtime. Unfortunately, this
introduces performance overhead proportional to the degree
2
of the graph—the more overlaps between valid target sets
of indirect branch instructions, the more IDs must be stored
and checked at each branch. Moreover, perfect CFI cannot be
realized with a purely static control-ﬂow graph; for example,
the permissible destinations of function returns depend on the
calling context, which is only known at runtime. Fine-grained
CFI therefore implements a dynamically computed shadow
stack, incurring high overheads [1].
To avoid this, coarse-grained CFI implementations resort
to a reduced-degree, static approximation of the control-ﬂow
graph, and merge identiﬁers at the cost of reduced security. For
example, bin-CFI [49] and CCFIR [50] use at most three IDs
per branch, and omit shadow stacks.
Recent work has demonstrated that these optimizations open
exploitable security holes. By choosing ROP gadgets that start
at a function entry point or are call-preceded, it is possible to
build ROP chains that bypass CFI [19], including subverting
CCFIR and bin-CFI. Related works [6, 11] have similarly
shown that call-preceded gadgets can bypass bin-CFI as well
as other low-overhead approaches that only check control-ﬂow
transfers before potentially dangerous function calls [7, 16,
30, 33]. Table I maps coarse-grained CFI approaches to the
corresponding proof-of-concept bypasses. Note that the bypass
of the original CFI approach assumes that returns are not
tracked precisely using a shadow stack.
Just-In-Time Code Reuse. Until recently, most threat models
for CFI and artiﬁcial diversity defenses assumed that the
memory contents of protected processes were hidden from
attackers. The advent of Just-In-Time ROP (JIT-ROP) [40]
demonstrated that this assumption might be unrealistic in
practice due to the existence of implementation disclosure
vulnerabilities. Using heap feng shui [41], JIT-ROP places a
buffer next to a string and a button object. By overﬂowing the
buffer, the string length is set arbitrarily high, allowing the
attacker to read any byte in the virtual address space. Parsing the
button object through the overﬂowed string yields a reference
to a mapped code page.
Typically, attackers need more than a single 4K page
worth of code to ﬁnd enough gadgets to mount a code-reuse
attack. To discourage brute-force searches for more code pages,
artiﬁcial diversity defenses routinely mine the address space
with unmapped pages that abort the process if accessed [2]. JIT-
ROP evades these mines by disassembling the initial code page
and carefully traversing only direct references to other code
pages to recursively discover enough gadgets to mount a ROP
attack. Since gadget locations are no longer unknown to the
attacker, reliable construction of custom ROP chains becomes
possible despite the ﬁne-grained randomization defense.
Blind ROP. While JIT-ROP targets scripting-enabled clients,
Blind Return Oriented Programming (BROP) [4] targets vul-
nerable Internet-facing services, such as web-servers, that
restart after a crash. It capitalizes on the observation that
child processes created with the fork system call on Linux
must be randomized in the same way as their parent in order
to continue executing. The attack uses a buffer overﬂow to
overwrite the stack byte-by-byte. Byte values are chosen so
that correct guesses cause the server to continue responding
as intended, while incorrect guesses solicit a crash and restart.
By distinguishing these two outcomes, attackers can remotely
infer secret stack cookie values to bypass stack guards and
discover gadget locations. Once the write system function is
located (typically in less than 4000 guesses) the entire code
section can be exﬁltrated to an attacker-controlled server, after
which a traditional ROP attack can be launched against the
vulnerable system. Like JIT-ROP, the attack defeats ASLR,
DEP, stack canaries and ﬁne-grained code randomization on
64-bit systems.
Side Channel Disclosures. Recent work has even shown that
under certain circumstances, gadget locations can be leaked
through side channels, such as timing channels [35]. This
underscores the difﬁculty of fully protecting software against all
implementation disclosure vulnerabilities. Complete protection
entails mitigation of all side channel information leaks, which is
widely recognized as prohibitively difﬁcult for most non-trivial
software products.
B. Assumptions
Given these sobering realities, we adopt a conservative
threat model that assumes that attackers will eventually ﬁnd
and disassemble all code pages in victim processes. Our threat
model therefore assumes that the adversary knows the complete
in-memory code layout—including the locations of any gadgets
required to launch a ROP attack. We also assume that the
attacker can read and write the full contents of the heap and
stack, as well as any data structures used by the dynamic
loader. In keeping with common practice, we assume that data
execution protection is activated, so that code page permissions
can be maintained as either writable or executable but not both.
However, we assume that attackers cannot safely perform a
comprehensive, linear scan of virtual memory, since defenders
may place unmapped guard pages at random locations. Instead,
attackers must follow references from one disclosed memory
page to another [40] or resort to guessing [4] in order to avoid
inadvertently touching one of these mined pages and alerting
defenders (e.g., triggering re-randomization). Successful attacks
against our system are therefore those that reliably traverse
control-ﬂow edges not
intended by the original program
semantics without triggering an invalid access violation.
III. O-CFI OVERVIEW
O-CFI combines insights from CFI and automated soft-
ware diversity. It extends CFI with a new, coarse-grained
CFI enforcement strategy inspired by bounds-checking, that
validates control-ﬂow transfers without divulging the bounds
against which their destinations are checked. Bounds-checking
is fast, the bounds are easier to conceal than arbitrary gadget
locations, and the bounds are randomizable. This imbues CFI
and ﬁne-grained software diversity with an additional layer of
protection against code-reuse attacks aided by implementation
disclosures. As a result, O-CFI enjoys performance similar
to coarse-grained CFI, with probabilistic security guarantees
similar to ﬁne-grained artiﬁcial diversity in the absence of