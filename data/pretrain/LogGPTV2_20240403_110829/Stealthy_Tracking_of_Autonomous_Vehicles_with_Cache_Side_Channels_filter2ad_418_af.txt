622, 2015.
[46] W. Maddern, G. Pascoe, C. Linegar, and P. Newman.
1 year, 1000 km: The Oxford RobotCar dataset. The
International Journal of Robotics Research, 36(1):3–15,
2017.
[47] R. Martin, J. Demme, and S. Sethumadhavan. Time-
Warp: rethinking timekeeping and performance monitor-
ing mechanisms to mitigate side-channel attacks. ACM
SIGARCH Computer Architecture News, 40(3):118–129,
2012.
[48] Y. Michalevsky, D. Boneh, and G. Nakibly. Gyrophone:
Recognizing speech from gyroscope signals. In 23rd
USENIX Security Symposium, pages 1053–1067, 2014.
[49] Y. Michalevsky, A. Schulman, G. A. Veerapandian,
D. Boneh, and G. Nakibly. Powerspy: Location tracking
using mobile device power analysis. In 24th USENIX
Security Symposium, pages 785–800, 2015.
[50] I. Miller and M. Campbell. Particle ﬁltering for map-
aided localization in sparse GPS environments. In IEEE
International Conference on Robotics and Automation
(ICRA), pages 1834–1841, 2008.
[51] I. Miller, M. Campbell, D. Huttenlocher, F.-R. Kline,
A. Nathan, S. Lupashin, J. Catlin, B. Schimpf, P. Moran,
N. Zych, et al. Team Cornell’s Skynet: Robust percep-
tion and planning in an urban environment. Journal of
Field Robotics, 25(8):493–527, 2008.
[52] M. Montemerlo, J. Becker, S. Bhat, H. Dahlkamp,
D. Dolgov, S. Ettinger, D. Haehnel, T. Hilden, G. Hoff-
mann, B. Huhnke, et al. Junior: The Stanford entry in the
urban challenge. Journal of Field Robotics, 25(9):569–
597, 2008.
[53] P. Narváez, K.-Y. Siu, and H.-Y. Tzeng. New dynamic al-
gorithms for shortest path tree computation. IEEE/ACM
Transactions On Networking, 8(6):734–746, 2000.
874    29th USENIX Security Symposium
USENIX Association
[54] Y. Oren, V. P. Kemerlis, S. Sethumadhavan, and A. D.
Keromytis. The spy in the sandbox: Practical cache at-
tacks in JavaScript and their implications. In 22nd ACM
SIGSAC Conference on Computer and Communications
Security (CCS), pages 1406–1418, 2015.
[65] R. Sprabery, K. Evchenko, A. Raj, R. B. Bobba, S. Mo-
han, and R. Campbell. Scheduling, isolation, and cache
allocation: A side-channel defense. In IEEE Interna-
tional Conference on Cloud Engineering (IC2E), pages
34–40, 2018.
[55] D. A. Osvik, A. Shamir, and E. Tromer. Cache at-
tacks and countermeasures: the case of AES. In Cryp-
tographers’ Track at the RSA Conference, pages 1–20.
Springer, 2006.
[56] M. K. Qureshi. CEASER: Mitigating conﬂict-based
cache attacks via encrypted-address and remapping. In
51st Annual IEEE/ACM International Symposium on
Microarchitecture (MICRO), pages 775–787, 2018.
[57] M. K. Qureshi. New attacks and defense for encrypted-
address cache. In 46th IEEE/ACM International Sympo-
sium on Computer Architecture (ISCA), pages 360–371,
2019.
[58] J. Redmon and A. Farhadi. YOLO9000: better, faster,
stronger. In IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), pages 7263–7271, 2017.
[59] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-CNN:
Towards real-time object detection with region proposal
networks. In Advances in Neural Information Process-
ing Systems (NIPS), pages 91–99, 2015.
[60] J. Rohde, I. Jatzkowski, H. Mielenz, and J. M. Zöllner.
Vehicle pose estimation in cluttered urban environments
using multilayer adaptive monte carlo localization. In
19th International Conference on Information Fusion
(FUSION), pages 1774–1779, 2016.
[61] H. Sakoe, S. Chiba, A. Waibel, and K. Lee. Dynamic
programming algorithm optimization for spoken word
recognition. Readings in Speech Recognition, 159:224,
1990.
[62] C. Seiffert, T. M. Khoshgoftaar, J. Van Hulse, and
A. Napolitano. RUSBoost: A hybrid approach to allevi-
ating class imbalance. IEEE Transactions on Systems,
Man, and Cybernetics-Part A: Systems and Humans,
40(1):185–197, 2010.
[63] A. Shusterman, L. Kang, Y. Haskal, Y. Meltser, P. Mittal,
Y. Oren, and Y. Yarom. Robust website ﬁngerprinting
through the cache occupancy channel. In 28th USENIX
Security Symposium, pages 639–656, 2019.
[64] R. Spangenberg, D. Goehring, and R. Rojas. Pole-based
localization for autonomous vehicles in urban scenarios.
In IEEE/RSJ International Conference on Intelligent
Robots and Systems (IROS), pages 2161–2166, 2016.
[66] D. Trilla, C. Hernandez, J. Abella, and F. J. Cazorla.
Cache side-channel attacks and time-predictability
in high-performance critical real-time systems.
In
55th ACM/ESDA/IEEE Design Automation Conference
(DAC), pages 1–6, 2018.
[67] C. Urmson, J. Anhalt, D. Bagnell, C. Baker, R. Bittner,
M. Clark, J. Dolan, D. Duggins, T. Galatali, C. Geyer,
et al. Autonomous driving in urban environments: Boss
and the urban challenge. Journal of Field Robotics,
25(8):425–466, 2008.
[68] V. Varadarajan, T. Ristenpart, and M. M. Swift.
Scheduler-based defenses against cross-VM side-
channels. In 23rd USENIX Security Symposium, pages
687–702, 2014.
[69] Z. Wang and R. B. Lee. New cache designs for thwart-
ing software cache-based side channel attacks. In ACM
SIGARCH Computer Architecture News, volume 35,
pages 494–505, 2007.
[70] M. Yan, C. Fletcher, and J. Torrellas. Cache telepathy:
leveraging shared resource attacks to learn DNN archi-
tectures. In 29th USENIX Security Symposium, 2020.
[71] Y. Yarom and K. Falkner. FLUSH+ RELOAD: A high
resolution, low noise, L3 cache side-channel attack. In
23rd USENIX Security Symposium, pages 22–25, 2014.
A Impact of Destination Selection on Loca-
tion Prediction
The proposed classiﬁcation algorithm cannot predict a loca-
tion that is not in the training set. Our location prediction
experiments are performed using randomly-selected desti-
nations where the training set and the validation set contain
different sets of destinations. Thus, we generate multiple train-
ing/validation samples using the intermediate locations along
each path. The intermediate locations help creating more sam-
ples in both sets that share the same location label even when
the destinations of the entire paths are different. For exam-
ple, a simulation run with a length L to one destination has
L− 1 intermediate locations, and generates L samples with L
different target locations to predict. Intuitively, if the simula-
tion destinations in the training set and the validation set are
spatially close, there will be more intermediate locations that
are common between the two sets, which will lead to more
validation samples whose target locations exist in the training
set.
USENIX Association
29th USENIX Security Symposium    875
Strategy
Identical
Interleaved
Separated Random
Target
locations
Samples
Total
In training
Percentage
Total
In training
Percentage
256
256
100 %
8,627
8,627
100 %
224
199
88.8 %
8,650
8,601
99.4 %
178
84
47.2 %
10,954
9,408
85.9 %
97.0 %
135
131
726
720
99.2 %
Figure 24: Train-
ing set destina-
tions (black) and
validation set des-
tinations
(white)
are separated.
Figure 23: Train-
ing set destina-
tions (black) and
validation set des-
tinations
(white)
are interleaved.
Figure 22: Both
the training and
validation
sets
contain the iden-
the
tical set of
destinations
on
the map (grey).
A.1 Destination Selection Strategy
Here, we study different strategies for selecting destinations
of simulation runs for the training set and the validation set
and their impacts on prediction accuracy.
Identical Destinations
In this strategy, the training set and
the validation set have an identical set of simulation desti-
nations (Figure 22). We select all 256 locations in Maze 1.
For each destination, we use two simulation runs, one for the
training set and one for the validation set, for the total 512
runs.
Interleaved Destinations
In this strategy, the training set
and the validation set have interleaved destinations, forming a
chessboard pattern (Figure 23). There is no overlap between
the training and validation sets. We select the “black” destina-
tions for training and the “white” destinations for validation.
For each destination, we have two runs for the total 512 runs.
The interleaved strategy leads to mutually exclusive desti-
nations in the training and the validation sets, but for each
destination in the validation sets, there is a destination in the
training set is just one grid away.
Separated Destinations
In this strategy, the training set
and the validation set are spatially separated. (Figure 24). We
use the bottom part of Maze 1 for the training set and the top
part of Maze 1 for the validation set. For each destination, we
have two runs for the total 512 runs. In this strategy, the desti-
nations in the training set and the validation set are not only
mutually exclusive, but also spatially far part in the opposite
directions.
In Table 7, we compare the number of overlapped target
locations between the training set and the validation set for
different destination-selection strategies. The table shows the
results for the three strategies discussed above as well as the
random-selection scheme described in Section 4.5.2. Note
that the target locations in the table include the intermediate
Table 7: The number and the percentages of the target loca-
tions and samples in the validation set under different destina-
tion selection strategies.
Strategy
3-grid accuracy
Mean error
Identical
75.9%
2.49
Interleaved
Separated
77.3%
2.40
50.7%
5.44
Random
74.6 %
2.87
Table 8: Prediction results using different strategies for choos-
ing destinations in the training and the validation sets.
locations in each simulation run. The table shows the total
number of unique target locations in the validation set as
well as the number of target locations that also appear in at
least one sample in the training set. The samples indicate the
individual samples in the validation set that are used to obtain
the prediction accuracy; multiple samples may have the same
target location. For the identical-destination strategy, 100%
of the target locations in the validation sets are covered by the
training set. For the interleaved strategy, 88.8% of the target
locations and 99.4% of the validation samples are covered
by the training set. However, in the separated strategy, only
47.2% of the target locations are covered by the training set.
The uncovered target locations have location labels not found
in the training set, thus, they will lead to the same number of
prediction errors. As a consequence, the prediction accuracy
for the separated destination will be lower.
A.2 Prediction Results
We compare the prediction results of the three strategies and
the random destination strategy in Table 8. The prediction ac-
curacy for the interleaved, identical, and random destinations
are similar, while the accuracy for separated destinations is
signiﬁcantly lower. This is consistent with the low percent-
age of the target locations that are covered by the training
set under the separated-destination strategy. The result shows
that the spatial proximity of destinations in the training and
validation sets, rather than the exact overlap of the destina-
tions in the training and the validation set, is important for the
prediction accuracy. The random destination strategy, which
we used in Section 4 and Section 5, preserves the spatial prox-
imity of the destinations between the training and validation
sets. Thus, the prediction accuracy is similar to that of using
identical and interleaved destinations strategies.
876    29th USENIX Security Symposium
USENIX Association