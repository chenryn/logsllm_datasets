Let F +
1→t as:
(12)
1→t = {α
∗
∗
α
1, α
t ≤ 1. Sequence α∗
2 ≤ ... ≤ α∗
1 ≤ α∗
∗
2, ..., α
t},
∗
1→t
and ∆(i, t)|α∗
We deﬁne Λ(i, t)|α∗
and ∆(i, t)|α∗
1→t
where 0 ≤ α∗
1→t contains
false positive rate thresholds that are used to train the indi-
vidual classiﬁers corresponding to the ﬁrst t feature types.
recursively as in
1→t
Figure 5. Hence, Λ(i, t)|α∗
represent the
accumulative set of true positives and false positives in the
i-th fold, respectively, by the sequence of individual classi-
ﬁers trained from the ﬁrst t feature types under false pos-
itive thresholds α∗
and
∆(i, t)|α∗
, which, deﬁned in Figure 6,
is the best conﬁguration found for the t-th feature type when
the sequence of false positive rate thresholds used to train
the individual classiﬁers for the ﬁrst t feature types is α∗
1→t.
Hence, in contrast to the original Neyman-Pearson cri-
terion given in Equation (5), we apply the chain Neyman-
Pearson criterion:
for the individual classiﬁer trained for
the t-th feature type, we search for the conﬁguration with
1→t. The deﬁnitions of Λ(i, t)|α∗
depend on g∗
1→t
1→t
t |α∗
1→t
1→t
Crossover	
  Par*al	
  Muta*on	
  Full	
  Muta*on	
  Best	
  candidates	
  in	
  k-­‐th	
  itera*on	
  Evalua*on	
  and	
  comparison	
  Best	
  candidates	
  in	
  (k+1)-­‐th	
  itera*on	
  125(cid:26) Λ(i, t − 1)|α∗
(cid:26) ∆(i, t − 1)|α∗
1→t−1
1→t−1
Λ(i, t)|α∗
1→t
∆(i, t)|α∗
1→t
=
=
∪ (Θt,i(g∗
∅
∪ (Θt,i(g∗
∅
t |α∗
1→t
) ∩ F +
i )
t |α∗
1→t
) ∩ F
−
i )
t > 0
t = 0
t > 0
t = 0
(10)
(11)
Figure 5: Deﬁnition of Λ(i, t)|α∗
1→t
and ∆(i, t)|α∗
1→t
t |α∗
∗
g
1→t
subject to:
with ˜βt(C, ρ, σ)|α∗
1→t
= argmax(C,ρ,σ)
˜αt(C, ρ, σ)|α∗
1
m
=
˜αt(C, ρ, σ)|α∗
1→t
=
1
m
˜βt(C, ρ, σ)|α∗
,
1→t
≤ α
∗
t ,
1→t
i ) ∪ Λ(i, t − 1)|α∗
|(Θt,i(C, ρ, σ) ∩ F +
|F +
i |
i ) ∪ ∆(i, t − 1)|α∗
|(Θt,i(C, ρ, σ) ∩ F
−
|F
i |
−
1→t
1→t
|
,
|
,
m(cid:88)
m(cid:88)
i=1
i=1
Figure 6: Deﬁnition of g∗
t |α∗
1→t
the highest accumulative detection rate over the ﬁrst t fea-
ture types under the constraint that the accumulative false
positive rate over the ﬁrst t feature types is no higher than
α∗
t . With redeﬁned ˜αt(C, ρ, σ) and ˜βt(C, ρ, σ), we keep the
same method of comparing two conﬁgurations as described
in Section 4. Hence, given the current false positive rate
threshold α∗
t , the algorithm presented in Section 4 can be
used to train each individual classiﬁer sequentially based on
the chain Neyman-Pearson criterion.
5.2 Dynamic Programming
2, ..., α∗
The application of the chain Neyman-Pearson criterion
requires us to know the sequence of false positive thresholds,
T}, where T gives the total number of feature
{α∗
1, α∗
types in the classiﬁcation framework. Given that the overall
false positive rate threshold is α∗, we then should have α∗
T =
α∗. Clearly, how to set these false positive rate thresholds
aﬀects the performance of the ensemble of classiﬁers trained
based on the chain Neyman-Pearson criterion. In an extreme
1 be α∗ and we can ﬁnd a classiﬁer based
case, if we let α∗
on the ﬁrst feature type that has a false positive rate equal
to α∗, then for the remaining feature types, the classiﬁers
trained based on the chain Neyman-Pearson should not lead
to any false positives in order for the ensemble of classiﬁers
to have a false positive rate no greater than α∗.
T} for an
optimal conﬁguration can be computationally prohibitive,
as these parameters are dependent on each other. More-
over, during the search process, we want to tease out those
features that contribute little to the accumulative classiﬁ-
cation performance, which is typically done in a separate
feature selection process. To overcome these challenges, we
propose a dynamic programming method, as illustrated in
Figure 7, to search an optimal setting of α∗
1→T . Consider
the following set of false positive rate thresholds that should
be satisﬁed by individual classiﬁers,
Searching the continuous space of {α∗
2, ..., α∗
1, α∗
{0α
∗
/D, 1α
∗
/D, 2α
∗
/D, ..., Dα
∗
/D},
(13)
where D is a predeﬁned parameter, and we let the false posi-
tive rate thresholds in the sequence {α∗
T} take val-
ues only from this set. For brevity, we deﬁne D = {0, 1, ..., D}.
2, ..., α∗
1, α∗
Figure 7: Dynamic programming for searching op-
g∗
j (iα∗/D), which is the best
timal conﬁgurations.
conﬁguration when the false positive rate threshold
over all the ﬁrst j features is iα∗/D, is obtained based
on the best conﬁgurations in the previous column,
g∗
j (kα∗/D) where k = 0, 1, ..., i. For the last feature
(i.e., feature T), only the conﬁguration under false
positive rate threshold α∗ needs to be computed.
Consider the t-th feature type, where 1 ≤ t ≤ T , and
any d ∈ D. Given that the false positive rate threshold for
the t-th feature type under the chain Neyman-Pearson cri-
terion is dα∗/D, we use the equations in Figure 8 to ﬁnd
recursively the optimal threshold for the false positive rate
of the (t − 1)-th feature type, which is prev(t, d) · α∗/D.
The crux here is that when we search the optimal value for
prev(t, d), we check all possible false positive rate thresholds
for the previous feature type (note that that previous thresh-
old should be no greater than the current threshold), and
use the one that leads to the best conﬁguration for the cur-
rent feature type under the chain Neyman-Pearson criterion.
t |d,d(cid:48) when the
When we calculate the best conﬁguration g∗
current and the last false positive rate thresholds are dα∗/D
and d(cid:48)α∗/D, respectively, we keep track of both Λ(i, t, d) and
∆(i, t, d), which represent the set of true positives and false
positives, respectively, under the condition that the current
false positive threshold is dα∗/D and the previous false pos-
itive thresholds are set to the values that recursively lead to
the best conﬁguration for the current feature type t.
The calculation can be done in an approach based on dy-
namic programming. For the ﬁrst feature type (i.e., t = 1),
126(cid:26) argmaxd(cid:48)∈D g∗
t |d,d(cid:48)
prev(t, d) =
−1
˜βt(C, ρ, σ)|d(cid:48) ,
t |d,d(cid:48) = argmax(C,ρ,σ)
∗
where
g
t > 1
t = 1
subject to:
with ˜βt(C, ρ, σ)|d(cid:48) =
˜αt(C, ρ, σ)|d(cid:48) =
1
m
∗
/D,
˜αt(C, ρ, σ)|d(cid:48) ≤ dα
1
m
|(Θt,i(C, ρ, σ) ∩ F +
i ) ∪ Λ(i, t − 1, d(cid:48))|
,
|F +
i |
|(Θt,i(C, ρ, σ) ∩ F
i ) ∪ ∆(i, t − 1, d(cid:48))|
−
|F
i |
−
,
m(cid:88)
m(cid:88)
i=1
i=1
Figure 8: Deﬁnition of prev(t, d) and g∗
(cid:26) Λ(i, t − 1, prev(t, d)) ∪ (Θt,i(g∗
(cid:26) ∆(i, t − 1, prev(t, d)) ∪ (Θt,i(g∗
∅
t |d,prev(t,d)) ∩ F +
i )
t |d,prev(t,d)) ∩ F
−
i )
t |d,d(cid:48)
∅
t > 0
t = 0
t > 0
t = 0
Λ(i, t, d) =
∆(i, t, d) =
Figure 9: Deﬁnition of Λ(i, t, d) and ∆(i, t, d)
we calculate the best conﬁguration for each possible false
positive rate threshold dα∗/D, where d ∈ D. Once the
best conﬁgurations for the (t − 1)-th feature type have been
found, we search the best conﬁguration for the t-th feature
type for each possible false positive rate threshold dα∗/D,
where d ∈ D. For any such d, we check the d possible false
positive rate thresholds for the previous feature type (i.e.,
0, 1α∗/D, 2α∗/D, ..., dα∗/D), and assuming that the previ-
ous classiﬁer uses its best conﬁguration for each of these false
positive rate thresholds, we look for the best conﬁguration
for the current feature type.
It is noted that for the last feature type, i.e., the T -th
feature type, we only need to consider the false positive rate
threshold Dα∗/D. Deﬁne an operation to be an execution of
the genetic algorithm, which is used to solve Equation (12).
We have the following proposition:
Proposition 3. If the dynamic programming algorithm per-
forms as described, it takes 2(D + 1) + (T − 2) · (D+1)(D+2)
operations to calculate the best conﬁgurations.
2
Proof. For the ﬁrst feature type, the algorithm performs
D + 1 operations that calculate the best conﬁgurations, each
for a threshold dα∗/D with d ∈ D. For the last feature
type (i.e., the T -th feature type), the best conﬁgurations
are only searched under the false positive rate threshold
Dα∗/D; as the previous threshold for the (T − 1)-th fea-
ture type can be any of dα∗/D with 0 ≤ d ≤ D, D + 1
operations that calculate the best conﬁgurations are per-
formed. For the k-th feature type where 2 ≤ k ≤ T −1, when
the current false positive rate threshold is dα∗/D, d oper-
ations that calculate the best conﬁgurations are performed
(note that the previous threshold should be no greater than
d=0 d =
(D + 1)(D + 2)/2 operations are performed. In total, there
are thus 2(D + 1) + (T − 2) · (D+1)(D+2)