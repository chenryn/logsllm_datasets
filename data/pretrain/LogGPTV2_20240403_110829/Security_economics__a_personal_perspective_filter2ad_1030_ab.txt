Upon my return to Cambridge, I became deeply involved in the Trusted Computing initiative, a project spearheaded by Microsoft, Intel, and other major tech firms. The proposal entailed adding a Trusted Platform Module (TPM) to PC motherboards—a smartcard chip designed to monitor the boot process and provide secure key storage—along with modifications to the Windows operating system to support a virtual secure coprocessor.

Given our growing understanding of lock-in and its implications for security, it was evident that this initiative was primarily aimed at increasing the lock-in of Windows and Office, rather than genuinely enhancing user security. In late June 2002, I published the "TCPA FAQ" [6], which laid out these concerns, followed by a more detailed version in July.

This work gained significant traction and introduced basic security-economics concepts to a broad audience. Consequently, I was invited to speak at the prestigious Software Economics conference in Toulouse in November 2002. My presentation, which critiqued Trusted Computing and incorporated ideas from [14] on the dependability of open versus closed systems, was well-received [7].

The core insight was that, under an ideal model, the equipartition property ensures that, over time, an open system subjected to inspection will be as reliable as a closed one. The mean time to failure depends solely on the total testing effort. Therefore, to argue for the superiority of an open or proprietary system, one must demonstrate that the system deviates from the ideal. Just as market failures justify regulatory intervention, deliberate anticompetitive practices may necessitate even more robust action from antitrust authorities. This debate was intense, and Craig Mundie, Microsoft's third-ranking executive, flew in from Redmond to engage in the discussion.

The 2003 Workshop on the Economics of Information Security (WEIS) at the University of Maryland, hosted by Larry and Marty, saw a doubling of attendance, likely due to the attention generated by the Trusted Computing debate. John Manferdelli, the Microsoft executive in charge of trusted computing, gave a keynote, while I discussed the competition policy aspects. The nomenclature itself became a point of contention; I suggested that "trusted computing" should be renamed "trustworthy computing," as the term "trusted computer" in U.S. military parlance implies a system that can be compromised. Richard Stallman, meanwhile, coined the term "treacherous computing." The debate eventually subsided in 2005 when Microsoft released Vista without the TPM, as they were unable to make it functional. However, the interim period provided ample visibility for the topic.

The discussions at WEIS 2003 included papers on Digital Rights Management (DRM), the initial application of Trusted Computing, and the effects of technical lock-in on innovation. The workshop's scope also expanded significantly, covering a wide range of topics that would become central to the field. These included evaluating the costs and benefits of security mechanisms, incentives for sharing vulnerability information, and the factors enabling security innovations to succeed in the marketplace. Additionally, there were further explorations of Marty and Larry's model of capital investment in security and Alessandro's behavioral analysis of privacy, which examined the discrepancy between stated and revealed privacy preferences.

### 4. Econometrics

From this point, the conferences began to feature more papers, panels, and debates on practical issues. The 2004 conference, hosted by Andrew Odlyzko in Minneapolis, opened with a debate on responsible vulnerability disclosure. Eric Rescorla argued that modern systems have so many vulnerabilities that disclosing them, while prompting vendors to fix them, does not sufficiently improve software quality to offset the increased risk of attacks on unpatched systems. Rahul Telang countered that without disclosure, vendors would not patch at all, leading to more widespread attacks as exploit knowledge spread. This debate was directly related to my work on reliability modeling and highlighted the need for empirical data on the distribution of bugs in large software products.

My new research student, Andy Ozment, collected bug report data, concluding by WEIS 2005 at Harvard that software, like wine, improves with age [32, 33]. This finding supported the practice of responsible vulnerability disclosure, for which additional evidence was gathered by Rahul and others.

WEIS 2005 continued to explore security metrics, investment models, and DRM, while introducing a new theme: cyber-insurance. If online risks were as high as claimed, why had the insurance industry not started selling substantial amounts of cyber-risk insurance? Rainer Böhme raised questions about correlated risks, liability assignment, and claims establishment, but no clear answers were available at the time. Subsequent developments, such as security breach disclosure laws, helped address some of these issues by making breaches more financially impactful, thus attracting insurer interest.

These themes marked the emergence of what we might call the econometrics of security. Initially, the Internet was largely academic, with few real-world attacks. Security researchers assumed a Dolev-Yao opponent capable of intercepting and modifying all messages. However, after the dotcom boom, actual malicious actors emerged, and it became impractical to assume Dolev-Yao opponents everywhere. We needed to defend against real-world threats, which required access to data on crime and abuse and the statistical skills to analyze it. Tyler Moore, Richard Clayton, and I wrote several papers collecting and analyzing data on various types of cybercrime [11]. We also collaborated on larger reports on online security and government responses.

One such report, "Security Economics and the Internal Market," was written for ENISA (the European Network and Information Security Agency) and published in 2008 [8]. It surveyed market failures underlying online crime and recommended a security breach disclosure law for Europe, similar to those in most U.S. states. This recommendation was eventually adopted by the European Commission and is now part of the EU Data Protection Regulation.

Another report, "Resilience of the Internet Interconnection Ecosystem," also commissioned by ENISA [21], examined the resilience of the Internet and the incentives for communications service providers to ensure security and redundancy. A specific concern was whether BGP security mechanisms would be deployed, or if ISPs would act selfishly. A broader issue was the consolidation of Tier 1 autonomous systems, which could lead to a few dominant players, such as Level 3, accounting for a significant portion of transit traffic. We concluded that regulatory intervention was premature but recommended that governments pay closer attention to these issues and sponsor more research.

In 2011, Detica, a subsidiary of BAe, published a marketing brochure claiming that cybercrime cost the UK £27 billion annually, with the Cabinet Office endorsing it. This claim was widely ridiculed, and Sir Mark Welland, the Ministry of Defence's chief scientific adviser, asked us to produce more defensible numbers. We assembled a team of experts, including Stefan Savage, Michel van Eeten, Rainer Böhme, Chris Barton, and Michael Levi. Our report revealed that online crimes inflict much greater indirect costs than traditional crimes. For example, the Rustock Botnet, which sent about a third of all spam in 2010, generated $3.5 million for its operators but cost the global economy about $1 billion in anti-spam efforts. This indicated that for every dollar the criminals earned, they inflicted $100 in costs on society. This led to the conclusion that more effort should be directed at apprehending and incarcerating the perpetrators, rather than relying on commercial solutions.

Other work on the econometrics of cybercrime included a survey paper for the Journal of Economic Perspectives [11]. We are currently working on a large grant from the DHS, collaborating with CMU, SMU, and the NCFTA to study the economics of cybercrime. We feel we are at the end of the beginning, with the numbers starting to add up.

### 5. The Behavioral Revolution

Another major thread emerging from successive WEIS conferences was the application of behavioral economics to security. This field, situated at the intersection of economics and psychology, examines the heuristics and biases that lead to systematic errors in market behavior. For example, Alessandro Acquisti explained at WEIS 2002 how people's inability to anticipate future harms can undermine market solutions for privacy issues. Paul Thompson also discussed cognitive hacking at the same conference.

A few months after the first WEIS, Daniel Kahneman won the Nobel Prize in Economics for his work on heuristics and biases, bringing behavioral economics to the forefront. Subsequent WEIS conferences featured a steady stream of behavioral papers, particularly from Berkeley students. At WEIS 2007, hosted at CMU, George Loewenstein, a distinguished behavioral economist, gave a keynote. By then, Alessandro Acquisti had moved to CMU, creating a center of excellence in behavioral economics, security, and usability.

At WEIS 2007, Alessandro, Bruce Schneier, and I decided to launch the Workshop on Security and Human Behavior to foster the growth of behavioral economics in security. This initiative has since seen several successful iterations, contributing to a deeper understanding of the human factors in cybersecurity.