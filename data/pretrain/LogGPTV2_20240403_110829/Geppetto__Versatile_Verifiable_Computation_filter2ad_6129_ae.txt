them. Even under these assumptions, our measurements indi-
cate that key and proof generation, as well as IO veriﬁcation, for
Geppetto’s ﬁrst batch of proofs would be 34-77× slower than
a standard Pinocchio-style proof, while the constant pairing-
based portion of proof veriﬁcation would be 11× slower; sub-
sequent batches would cost more, due to technical challenges in
the way the curves ﬁt together [9].
As a pragmatic alternative, we use a sequence of nested
curves (an option suggested previously [9, Footnote 10]) to in-
stantiate and implement bounded bootstrapping, Speciﬁcally,
we instantiate one version of Geppetto with the same highly
efﬁcient BN curve [6] employed by Pinocchio. We use the
BN curve to generate a collection of digests and proofs for
our MultiQAP-based CP scheme. We then construct a sec-
ond curve capable of efﬁciently embedding the BN curve op-
erations. When instantiated with the second curve, Geppetto
can efﬁciently verify crypto operations on the BN curve. Thus,
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:17 UTC from IEEE Xplore.  Restrictions apply. 
a veriﬁer can, for example, check signatures on the veriﬁcation
key built on the BN curve and then use that key to verify the
BN digests and proofs. To gain greater scalability, this process
can be repeated with a bounded number of additional carefully
constructed curves, each used to verify the digests and proofs
from the previous curve. Unfortunately, none of the curves can
efﬁciently embed later curves, and hence when generating keys,
the client must ultimately commit to the maximum number of
BN proofs that will be veriﬁed. Fortunately, our use of energy-
saving circuits saves the prover effort if it ends up using fewer
proofs.
Details We construct bilinear systems, GIN and GOUT . To
achieve this at the 128-bit security level, we instantiate GIN us-
ing a Barreto-Naehrig (BN) elliptic curve [6], and then construct
GOUT accordingly with the Cocks-Pinch method [21]. Roughly,
the latter constructs a pairing-friendly curve by outputting a ﬁ-
nite ﬁeld corresponding to a given, prescribed group order. We
ﬁx the prime p from the BN parameterization as the group order,
so that the output of the Cocks-Pinch algorithm is the prime ˜p
(as well as the other parameters required in the description of
GOUT ). The following lemma makes this explicit in a special
case that is of most interest in the current work.
Lemma 1 Let x ∈ Z be such that p = 36x4 +36x3 +24x2 +6x+
1 and p(cid:7) = 36x4 + 36x3 + 18x2 + 6x + 1 are prime. If
˜p = 5184x8+10368x7 + 12204x6 + 8856x5 + 4536x4
+1548x3 + 363x2 + 48x + 4
(11)
is also prime, then there exists both an elliptic curve E/Fp of
order #E(Fp) = p(cid:7) with embedding degree k = 12 (with respect
to p(cid:7)), and an elliptic curve ˜E/F ˜p, such that its order # ˜E(F ˜p) is
a multiple of p and ˜E has embedding degree ˜k = 6 (w.r.t. p).
Our full paper contains proofs and construction details [23].
To construct additional nesting curves, given a group order,
we once again apply the Cocks-Pinch approach to produce a
sequence of curves E(i), deﬁned over prime ﬁelds Fpi, respec-
tively, such that pi divides #E(i+1)(Fpi+1
). Each hop creates a
larger curve, and hence will eventually produce curves equal to
or larger than the MNT curves that support unbounded boot-
strapping. For example, for the ﬁrst Cocks-Pinch curve, ˜p is
509 bits (with embedding degree 6), and the next two levels are
1023 bits and 2055 bits with embedding degrees 3 and 1.
Even when we reach these larger sizes, the inner layers (es-
pecially the BN curve where most of the “real” computation
happens) are still more efﬁcient than the MNT curves, and even
at comparable sizes, exponentiations on the Cocks-Pinch curves
are faster due to a CM endomorphism (not available for MNT
curves) and a G2 cubic twist. Of course, for sufﬁciently large
problems, the unbounded approach eventually offers better per-
formance.
Implementation
6
The Geppetto system includes a library for guiding the compila-
tion of banks and buses, a cryptographic compiler that operates
262262
on C programs via LLVM, and libraries that support common
programming patterns and bootstrapped computation.
Although it has been applied to over 10,000 lines of C and
supports many LLVM instructions, Geppetto imposes semantic
restrictions on source programs, thereby reﬂecting limitations
of compilation to QAP encodings. For instance, it offers almost
no support for computations on pointers. Recent work shows
how to remove many of Geppetto’s restrictions [54].
We ﬁrst explain our programming model by example, then
describe the design and selected features of our compiler, and
ﬁnally discuss C libraries and programming patterns.
6.1 Programming Model
A Geppetto programmer deﬁnes the structure of outsourced
computations, their compound proofs, and the shared buses that
connect them, thereby explicitly controlling cost and amortiza-
tion of proof and digest generation. This structure is embed-
ded in source C programs via library invocations. (The design
of higher-level syntactic sugar and programming abstractions is
left as future work.)
From the veriﬁer’s viewpoint, Geppetto’s C programming
model is reminiscent of remote procedure calls (RPCs). The
programmer marks some function calls as outsourced, indicat-
ing that the veriﬁer should remote the calls to an untrusted ma-
chine, then verify their results using the accompanying crypto-
graphic evidence. This approach provides a clear operational
speciﬁcation of the veriﬁed computation, even for complex
proof schedules: when the main program of the veriﬁer com-
pletes, its outputs and return values must be the same as those
that would be obtained by executing the entire program on a
single trusted machine.
We illustrate the deﬁnition of outsourced functions on the
Geppetto program sample.c, outlined in Figure 4.
The
program deﬁnes some application code (elided), notably
compute() that operates on a matrix and a vector of integers.
The programmer intends to ﬁx the matrix across instances
of compute, and vary the input vector.
To this end,
sample.c declares three banks for veriﬁable outsourced com-
putation. For instance, relying on the Geppetto header ﬁle,
BANK(QUERY, vector) deﬁnes a QUERY bank datatype that
carries values of type vector, and functions like save_QUERY
and load_QUERY, analogous to RPC marshalling and unmar-
shalling functions. By convention, each bank instance can be
assigned only once, and must be assigned before being loaded.
The program then deﬁnes two functions: job, the outsourced
function, and main, that repeatedly calls job and processes its
arguments. Note that the call to job is marked as OUTSOURCE,
and that the digest db to the largest input M is computed just
once, outside the loop.
• When compiling sample.c natively outside Geppetto,
geppetto.h provides trivial deﬁnitions that implement
DATA, QUERY, and RESULT as in-memory buffers and
OUTSOURCE as a local call: OUTSOURCE(job, db, q) is
replaced with job(db, q).
• During compilation, Geppetto interprets the outsourced
function of sample.c, using symbolic values for the pay-
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:17 UTC from IEEE Xplore.  Restrictions apply. 
#include "geppetto.h"
// Geppetto banks and proofs
RESULT verify_job(DATA b0, QUERY b1) {
// application code
typedef struct { int M[SIZE][SIZE]; ...} bigdata;
typedef struct { int x[SIZE];
void compute(bigdata *db, vector *in, vector *out);
...} vector;
BANK(DATA, bigdata)
BANK(QUERY, vector)
BANK(RESULT, vector)
// we define 3 IO banks
RESULT job(DATA db, QUERY in) {
bigdata M;
vector query, result;
load_DATA(db,&M);
load_QUERY(in,&query);
compute(&M, &query, &result);
return (save_RESULT(&result));
}
int main() {
bigdata M;
vector query[N], result[N];
... // prepare the data & queries
DATA db = save_DATA(&M); // digest M once into db
for (i=0; id; // use digest produced by save_DATA
D[1] = b1->d; // use digest produced by save_QUERY
RESULT b2 = load_redigest_RESULT();
D[2] = b2->d;
load_verify_digest(&STATE.vk, &D[3], LOCALS);
proof pi;
load_proof("job", &pi);
verify_proof(&STATE.vk, &pi, 4, D);
return b2;
}
Figure 5: Simpliﬁed Veriﬁcation Example. Geppetto replaces the
original outsourced function job with a version that loads the function
result and cryptographic evidence and then veriﬁes that the function
was computed correctly.
evidence, and veriﬁes the computation’s proof.
If any veri-
ﬁcation fails, the program exits with an error. Otherwise, the
resulting bank b2 carries the correct response to the outsourced
computation.
6.2 MultiQAP Programming Patterns
Geppetto provides additional support for common commit-and-
prove patterns, coded as generic C libraries.
Sequential Loops Many large computations consist of a main
loop with a code body that updates loop variables at every iter-
ation, and also reads (but does not modify) outer variables.
Geppetto provides a generic template for outsourcing each
loop iteration (or, more generally, for outsourcing ﬁxed num-
bers of iterations that ﬁt within a single QAP), with a bank for
the outer variables; hence the cost to digest and verify the outer
bank is amortized across all loop iterations.
What about the loop variables? Recall that our commit-and-
prove scheme requires that each bank be assigned at most once
in every proof. Thus, we use two buses for the loop variables,
alternating between odd and even iterations of the loop, and we
compile the loop body twice, once reading the even loop vari-
ables and writing the odd loop variables, and once the other way
round. Hence, our generic template deﬁnes three banks, two
outsourced functions, and a reﬁned loop that alternates calls be-
tween the two. The veriﬁer then checks two digests and one
proof for each iteration, except for the ﬁrst iteration (where it
computes a digest of the initial values of the loop variables) and
the last (where it recomputes a digest of the ﬁnal values returned
by the prover).
MapReduce Geppetto also provides a few generic templates
for parallel loops (like sample.c above) and MapReduce com-
putations. As with sequential loops, for MapReduce computa-
tions, we use a series of buses to succinctly share potentially
many variables between mappers and reducers. Speciﬁcally, we
adopt Pantry’s model [16] in which M mappers feed R reduc-
ers. Geppetto compiles a MapReduce job into a MultiQAP with
two sub-QAPs (Qm for the mapper computation and Qr for the
263263
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:17 UTC from IEEE Xplore.  Restrictions apply. 
reducer computation) with max(M,R) shared buses in between
them. Each reducer reads from M buses and computes its out-
put. Each mapper computation takes an ID as input, telling it
which R buses to write its outputs to. For example, suppose
M = 10 and R = 2, and hence we have 10 shared buses. The
ﬁrst mapper writes its output for reducer 1 to bus 1 and for re-
ducer 2 to bus 2 (and implicitly writes zeros to the other buses).
The second mapper writes its output for reducer 1 to bus 2 and
for reducer 2 to bus 3. This continues until the tenth mapper
writes its output for reducer 1 to bus 10 and its output for re-
ducer 2 to bus 1. The prover sends the digests for all of the
computations and buses, along with the proofs binding them
together, back to the veriﬁer, who ensures (via the digests fed
into each Verify call) that the data was routed correctly between
mappers and reducers. If desired, all of the proofs and digests
can be made zero knowledge, and since the dataﬂow between
mappers and reducers is data independent, the computation as a
whole is zero knowledge as well.
Automated QAP Partitioning As explained above, Gep-
petto’s libraries enable programmer-directed QAP partitioning.
We also experimented with automated partitioning of large
monolithic QAPs, expressed as ﬁnding hyper-graph cuts. We
had some success efﬁciently ﬁnding approximate cuts in graphs
of up to 200,000 equations with the METIS tool [36]. However,
the programmer-directed approach is more ﬂexible and better
exploits regular structure such as loops.
6.3 Symbolic Interpretation via LLVM
Next, we provide details on the construction of the Geppetto
compiler. We elide QAP techniques described elsewhere [46].
General-Purpose LLVM Front-End As a front-end com-
piler, we use clang [40], a fast full-ﬂedged C compiler with rich
syntax, standard semantics, and optimizations. Hence, Gep-
petto compilation to quadratic equations starts from a low-level,
typed, integer-centric representation of the program, obtained
by running (for instance) clang -O2 -S -DQAP -emit-llvm
sample.c -o sample.s, where -DQAP declares but does not
deﬁne Geppetto primitive types and functions.
Compiling to QAPs beneﬁts from clang’s aggressive inlining
and partial evaluation. We disable other, unhelpful clang opti-
mizations, such as its replacement of multiplication by a con-
stant x∗ 8 (free in QAPs) with a bit shift x << 3 (which incurs
bit splitting). Using clang should also facilitate extension to
other LLVM-supported languages, but this may require adding