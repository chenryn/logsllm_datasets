(or relearned) as fast as they see a new sample. Under this
constraint of time, online learning shows promises by only
considering the new data to update the model, which makes it
an efﬁcient approach. Basically, most learning algorithms that
are compatible (but not limited) with the standard optimization
algorithms like stochastic gradient descent (SGD) can learn
incrementally.
Ofﬂine learning: In contrast to online learning, the models in
ofﬂine learning need to be retrained with the whole dataset as
newer data appear. One of the successful examples of ofﬂine
supervised learning techniques is Random Forest (RF), which
has shown promising achievements, and in certain domains,
has even better performance than neural networks [28]. In ad-
dition to RF, deep learning has been shown success in different
domains; however, they are usually practiced on unstructured
data such as images and they require a relatively larger amount
of data to perform well [16]. Moreover, such techniques need
high computational power and longer time to train; hence they
are not suitable for the online fuzzing workﬂow.
4 System Design
4.1 System Overview
MEUZZ is the ﬁrst machine learning-based hybrid fuzzer that
learns from the previously observed seeds and identiﬁes which
kinds of seeds have the potentials to more effectively explore
the program being tested.
Figure 3 shows an overview of MEUZZ. MEUZZ starts
fuzzing (❶) a program with pre-deﬁned or empty seeds. It
then extracts features (❷) from the program as well as the
seeds (§4.3) to model coverage gains. Such features are used
to predict (❸) the coverage that unknown seeds may provide
(§4.5). Concolic engine (❹) then receives the potentially inﬂu-
ential seeds from the prior step and produces mutated seeds.
Next, MEUZZ guides the fuzzer to use these seeds and their
generated mutants–by the evolutionary algorithms–to continu-
ally test the program. In the beginning, the prediction model is
randomly initialized, so the prediction quality is uncertain. But
as fuzzing continues, the model gets improved and will provide
a more reliable prediction. MEUZZ updates the seed selection
model in three steps. First, it infers the descendent trees (❺) of
those seeds selected to the concolic engine in (❹); then, it de-
rives a label (❻) based on the descendant trees of the previously
selected seed (§4.4); ﬁnally, it updates or retrains the model
(❼) depending on the type of learning process (§4.5, §4.6).
4.2 System Requirements
MEUZZ aims to predict the seed utility in a more accurate
and generalizable fashion than the existing heuristic-based
approaches while keeping the fuzzing efﬁciency intact. One
of the steps that contribute the most in achieving these goals
is feature extraction. MEUZZ can potentially derive various
semantic features because it has access to complex program
ML Engine
Hybrid Features
- # Reachable Bugs
- # Indirect calls
- # Cmps
...
Model
Off-L
On-L
En-L
2
6
5
Feature Extraction
Infer Seeds Labels
3
7
Prediction
Model Training
Update Seed Selection Model
Hybrid Fuzzing
1
Fuzzer
4
Concolic
Engine
Seeds descendant
Trees
Seeds
Program
U
s
e
u
f
l
S
e
e
d
s
T
o
p
P
o
e
n
t
t
i
a
l
Figure 3: System overview of MEUZZ. The coordinator is extended
with a ML engine, which consists of 4 modules – Feature extraction,
label inference, prediction and training modules. During fuzzing,
utility prediction and model training are carried out consecutively.
After extracting features for inputs in the fuzzer’s queue, the ML
engine can predict their utilities based on the current model. Then,
with the seed labels inferred from previously selected seeds, the
model is trained iteratively with the new data.
structures, such as the Control Flow Graph (CFG) with san-
itizer instrumentations. However, there are some challenges
that MEUZZ may encounter during feature extraction because
it requires to adapt the ML engine to the online-style fuzzing
workﬂow. To cope with such challenges, the feature engineer-
ing stage should meet the following requirements (R1–R3).
R1 - Utility Relevant: The ultimate goal of fuzzing is higher
code coverage as well as discovering a higher number of
hidden bugs. The features should reﬂect the characteristics that
may improve such measures. For instance, how much a seed is
likely to trigger more potential bugs or how much unexplored
code a mutated seed will reach during its execution. As it is
obvious, a seed is only meaningful in the context, which is the
program it is executed upon. Accordingly, feature extraction
needs to consider the seed and the program as a bundle.
R2 - Seed-/Program-Agnostic: To achieve generalizability,
the features should be seed-/program-agnostic. If a feature
is target-dependent, it downgrades the ability to generalize.
For example, one could engineer a boolean feature based on
the magic number that shows if a generated seed is genuine
or not. Although this feature looks useful to ignore invalid
seeds for fuzzing a speciﬁc program, it needs to be customized
for fuzzing different programs as the inputs’ formats change.
Contrarily, “meta properties” like the execution path triggered
by the input are more preferable, as it is a universally usable
characteristic regardless of the program.
80    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
R3 - Online Friendly: To keep the efﬁciency comparable to
heuristic-based approaches, it is not only important how fast
each feature can be extracted, but also the number of features is
concerned during model construction. If the features are both
light-weight and effective, it is assured that the coordinator
will not be blocked from launching the concolic executor and
at the same time able to construct meaningful models to predict
the seed utility. As a result, suitable features should strike a
balance between analysis richness (i.e., how informative is
the analysis result) and computation complexity (i.e., what
is the time complexity for the analysis).
4.3 Feature Engineering
The aforementioned requirements (R1–R3) guide us to
engineer the following list of features. We discuss them in four
categories.
Bug-triggering: Inspired by existing research [25], we use the
number of reachable sanitizer instrumentations as guidance
for measuring how likely bugs can be triggered. As sanitizer
instrumentations are based on sound analysis (i.e., no missed
bugs), it provides a good over-approximation when trying
to quantify the number of bugs that can be found. Hence, we
extract these two features:
1. Count of reachable sanitizer instrumentations: For all
branches throughout the path triggered by a given seed,
the number of reachable sanitizer instrumentations is
computed and then sum up. For instance, there are two
branches in the left example of Figure 4. There are six
potential bugs by following the branches, so the value
for this feature is six.
2. Count of reached sanitizer instrumentations: For all
branches throughout the path triggered by a given seed,
we sum up the number of reached sanitizer instrumen-
tations by the fuzzer. The major difference between this
feature and the prior one is that this feature reﬂects the
expectation of immediately solvable sanitizer bugs, while
the former feature is an indirect reﬂection. For instance,
the value of this feature in the right example of Figure 4
is two because the potential bugs can be directly reached
by negating the constraints from b1 and b2.
Coverage: Concolic execution is good at solving complex
branch conditions. Hence if there are a lot of previously
unsolved branches the concolic executor may encounter when
executing on the given input, it will signiﬁcantly improve
the code coverage. The most common situations where
concolic execution can help is when a conditional statement
(i.e.,if-then-else or switch-case) exists. As the given
input will only follow one of the branches, we call those
branches stemmed from the same conditional statement
neighbor branches. So we extract the following feature to
estimate each seed’s potential of new coverage.
Seed
Seed
.
.
n
o
C
.
.
n
o
C
Figure 4: The examples that show how bug-triggering and coverage
features are computed.
we compare their neighbors, if any, with all previously
triggered branches. We then sum up the previously
undiscovered neighbors for each branch. For instance,
the value of this feature in the right example of Figure 4
is two if the seed follows the path with continue labels.
Constraint Solving: We also devised a set of features that
impact the solving capabilities of the concolic execution
engine. The incentive behind selecting such features is that the
performance of the concolic executor signiﬁcantly inﬂuences
the entire hybrid fuzzing system.
1. Count of external calls: Existing concolic executors
either rely on a simulated procedure or simply terminate
the path execution when encountering an external
function. As a result, external function calls may have
negative impacts on the concolic executor, such as
misleading the path and causing failure to generate
correct seeds. This feature records the count of external
function calls along the path executed by the given seed.
2. Count of comparison instructions: This feature records
the count of cmp instructions along the path executed by
the given seed. Comparison instructions pose the con-
straints on the execution path, which will later be solved
by the SMT solver. However, constraint-solving is very
time-consuming and is often the reason for the timeout.
3. Count of indirect calls: This is the number of indirect call
instructions along the path executed by the given seed.
Indirect calls may cause state explosion because when
the concolic executor encounters an indirect call with a
symbolic pointer, it simply forks a state for each possible
value that can be resolved for the symbolic pointer [44].
In large programs, there could be many possible values
for a symbolic function pointer.
4. Length of path: This feature records the number of
executed branches (not deduplicated) by the given input.
It helps identify the existence of large loops, which is
another common reason that causes state explosion and
solver timeout.
1. Count of undiscovered neighbor branches: For all
branches along the path triggered by the given seed,
Empirical: This set of features is devised based on the
empirical observations by existing works. They might
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    81
indirectly affect fuzzing performance.
1. Input size: Size of the input is often employed by existing
tools as a heuristic to make a scheduling decision. On
the one hand, smaller size inputs often end the execution
more quickly and then leave more time for the fuzzer or
concolic executor to explore other inputs [13, 53]. On the
other hand, larger input has a better chance to trigger more
functionalities [25]. Therefore, we consider the input
size as one of the potential features for our approach.
2. First seed with new coverage: This is a boolean value in-
dicating whether the given seed is the ﬁrst one to discover
some new branches or not. This is based on the intuition
that such seeds are more likely to trigger more new cover-
age. This feature is used in many popular fuzzers [8, 33].
3. Queue size: This feature records how many inputs are
saved in the fuzzing queue at the time of the query. If the
queue is long, it is less likely to see more new coverage.
Since MEUZZ needs to predict the utility of each seed
during runtime, namely how much more new coverage
can be discovered by fuzzing with the given input, the
prediction should consider the current status of fuzzing.
4.4 Seed Label Inference
Labeling is an indispensable stage of data preprocessing in
supervised learning. Well-deﬁned labels make the prediction
much easier and more reliable. As we aim to predict the utility
of a selected seed and there is no direct indication to show if
the selected seed is deﬁnitely useful, we need to derive a label
by which we show the proportion of the seed utility.
To understand the utility of a seed, we need to fuzz the
program with that seed and check the outcome. Fuzzers that
use genetic algorithms (GAs) for seed generation represent
such an outcome as a forest of input descendant tree, which
depicts the parent-child relationship of the seeds in the fuzzer’s
queue. Each node of the tree represents a seed, and each edge
connects a seed to one of its mutants.
In plain fuzzing, the root nodes are the original seeds
provided by the user. Similarly, in hybrid testing, we model the
inputs that are selected to be executed concolicly as the root
nodes. When an input is selected to explore, the concolic en-
gine will produce mutants of the running input. These mutants
can further cover the neighbor branches (§ 4.3) of the re-visited
path. After these mutants get transferred back to the fuzzer’s
queue, the fuzzer can use GA to further mutate them. As a
result, we can draw the parent-child edges from the selected
input to the mutants generated by the concolic engine, and to
their GA-derived offsprings to form a mega descendant tree.
If the descendant tree of a seed is larger, it comparatively
means the seed contributes more to the fuzzer’s code coverage.
Hence, to derive the label, we measure the size of the input
descendant tree of a seed and consider it as the label.
In reality, it is not feasible to compute the complete
descendant tree since it could grow indeﬁnitely if the user
never terminates the fuzzing process. As a result, we have
to limit the tree analysis to a time window to make the label
inference possible. Speciﬁcally, after the fuzzer imports a
seed from concolic executor, we wait for a certain number of
fuzzing epochs for the fuzzer to explore the imported seed and
then compute the size of its descendant tree.
4.5 Model Construction and Prediction
The next step after preparing the data is to predict the seed
prominence (i.e., label). As the seed labels are the number of
nodes in the seed descendant tree, their values are continuous
so we need a regression model to predict them. Hence, we
embed a regression model in MEUZZ in a way that when
new seeds are generated by the fuzzer, the model predicts the
utility of the seeds and then transfer the potential seeds to the
concolic engine.
MEUZZ predicts very naively or just random at the beginning
of fuzzing because the model just sees a few samples. However,
the prediction becomes more reliable when more seeds are
generated–data plays a crucial role in advancing model–and
the model receives updates.
As seeds are mutated continuously during fuzzing a program
in real-time, prediction and model update need to be done in
a limited time window. Such limitation makes online learning
approaches desirable candidates for model construction. In
online-learning, the model can be incrementally updated by
only considering new data. It does not need to store all previous
data and to learn a model from scratch in every iteration.
Instead, the model can be updated incrementally based on the
incoming input, previous model and historical fuzzing yields.
Such an update is very fast and requires less storage, which
ﬁts our use case very well. Thus we adopt online learning as
one of the techniques for model construction.
4.6 Updating Model
To assure the model is entirely up-to-date with the prevailing
seeds, ideally, we need to dynamically update/retrain the
model, depending on the learning type (i.e., online vs. ofﬂine).
By doing so, we can both predict and learn in real-time.
For online learning, we use the Recursive Least Square
(RLS) algorithm [21, 46] to update our linear model. Suppose