title:Poster: Evaluating Code Coverage for System Call Fuzzers
author:Seoyoung Kim and
Seyeon Jeong and
Mingi Cho and
Soochang Chung and
Taekyoung Kwon
Poster: Evaluating Code Coverage for System Call Fuzzers
Seoyoung Kim, Seyeon Jeong, Mingi Cho, Soochang Chung, and Taekyoung Kwon
{kseoy4046,yeonny,imgc,warpstar,taekyoung}@yonsei.ac.kr
Yonsei University
ABSTRACT
The OS kernel, which has entire system privileges, is an attractive
target of attackers. To reduce this threat, we need to find security
bugs in the kernel prior to the attackers, and system call fuzzing is a
widely used technique for this purpose. However, many system call
fuzzers have not been evaluated for coverage performance which
is an important indicator in fuzzing. In this poster, we propose a
methodology to evaluate the code coverage performance of system
call fuzzers with a strategy that combines virtualization and Intel
Processor Trace (PT). First, we extract all the functions in the kernel
that can be executed by system calls. Then we perform fuzzing with
the target system call fuzzer on the guest OS, and record coverage
information by leveraging the Intel PT. Finally, we evaluate system
call fuzzers by comparing the list of functions related to system
calls with the executed functions logged by Intel PT while fuzzing.
CCS CONCEPTS
• Security and privacy → Software and application security.
KEYWORDS
fuzzing; evaluation; kernel fuzzing
ACM Reference Format:
Seoyoung Kim, Seyeon Jeong, Mingi Cho, Soochang Chung, and Taekyoung
Kwon. 2019. Poster: Evaluating Code Coverage for System Call Fuzzers. In
2019 ACM SIGSAC Conference on Computer and Communications Security
(CCS ’19), November 11–15, 2019, London, United Kingdom. ACM, New York,
NY, USA, 3 pages. https://doi.org/10.1145/3319535.3363288
1 INTRODUCTION
Software bugs cause incorrect and unintended states of a computer
system, exploited as a path for intrusion by attackers. It is, in par-
ticular, crucial to discover and patch such bugs in the OS kernel
ahead of attackers since otherwise, attackers can obtain full control
over the system by exploiting vulnerabilities. Over the past five
years, more than 1,000 CVEs have been assigned to the Linux ker-
nel, indicating that many vulnerabilities are still latent in the OS
kernels [5].
To discover latent bugs in software, people use either static,
dynamic, or combined analysis methods. Fuzzing is a dynamic bug-
finding technique that automatically generates or mutates inputs to
trigger bugs, and it has successfully discovered many bugs in real
software [10]. Fuzzing is also often used for finding bugs in the OS
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’19, November 11–15, 2019, London, United Kingdom
© 2019 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6747-9/19/11.
https://doi.org/10.1145/3319535.3363288
kernels, focused on interfaces that handle user-mode and kernel-
mode communications. Most kernel fuzzers are targeting system
calls that request a service from the kernel, including but not limited
to process control, file management, and device management.
In this context, various system call fuzzers have appeared, but
they are lack of evaluation about the performance of fuzzing. Al-
though the primary goal of a fuzzer is to find more bugs, a typical
list of bugs discovered by the fuzzer (e.g., CVE ID) is not enough
to understand the performance of fuzzing. To evaluate the fuzzer
more rigorously, we need to consider both the number of distinct
bugs and the number of code blocks, discovered while fuzzing [7].
Note that it is necessary to analyze code coverage because the code
coverage can be used as a good indicator to see whether the fuzzer
properly operated. When triggering a kernel bug, a kernel panic
may occur, making it easy to detect whether the bug is triggered.
However, it is hard to measure code coverage since there is no
feedback information immediately produced. These motivate us to
evaluate the performance of the system call fuzzers by measuring
code coverage and gain insight for extending the existing fuzzers
(e.g., to find an uncovered kernel component).
In this poster, we present a methodology to evaluate the code
coverage performance of system call fuzzers with a strategy that
combines virtualization and Intel PT (Process Tracer). To evaluate
system call fuzzers, we first extract a list of functions related to
system calls (§3.1). Then, we build a guest OS environment on the
virtual machine (e.g., KVM), and perform fuzzing using the system
call fuzzer which to be evaluated on the built guest OS environment.
During the fuzzing process, we use Intel PT to record the execution
trace of CoFI (Change of Flow Instruction) that affects the control-
flow (§3.2). Finally, we evaluate the performance of a system call
fuzzer by comparing the list of functions related to system calls
created in §3.1 and the list of functions that are executed by the
fuzzer in §3.2.
The contributions of this poster are:
• Novel coverage evaluating approach for system call fuzzers.
We extracted the functions related to system call, and evaluated
a fuzzer by comparing the number of executed functions with
the number of extracted functions.
• Evaluate open-source system call fuzzer. We performed cov-
erage evaluation on Linux system call fuzzer Trinity [4] with
the proposed approach. As a result, 1,048 functions among 3,990
system call related functions can be executed by Trinity (§4).
2 BACKGROUND
Intel Processor Trace. Intel Processor Trace (PT) records software
execution trace in a packet format using the processor’s hardware
device [8]. Intel PT records the packets when instructions that
change the control-flow of an execution, which are called Change
of Flow Instructions (CoFI), are executed. The types of packets
are Taken Not-Taken (TNT) packets, Target IP (TIP) packets, and
PosterCCS ’19, November 11–15, 2019, London, United Kingdom2689Figure 1: The steps of invoking a system call
Flow Update Packets (FUP). The TNT packet records the result
(true or false) of the branch condition. The TIP packet records the
address of the next instruction to be executed when an indirect
jump instruction that uses the relative address is executed. The FUP
records information about asynchronous events such as interrupts
and traps.
System Call. System call is used by user-level programs to request
privileged service to the OS kernel. Figure 1 shows the processing
steps of the kernel when read(), a function related to system call, is
called. When read() is called in the user space, the kernel finds its
entry function from the syscall table and executes it.
3 SYSTEM DESIGN AND IMPLEMENTATION
Figure 2 shows the system architecture. First, we use the system call
list, System.map, and kernel images to retrieve the memory address
of the functions related to system call. Then, we perform system call
fuzzing with a target fuzzer on the guest OS environment while the
address of executed functions are recorded by the Intel PT. Finally,
we compare the system call related functions with the executed
functions to evaluate the coverage performance of the system call
fuzzer.
3.1 System Call Related Functions
To evaluate the coverage performance of the system call fuzzer,
we first need to extract the system call related functions among
the functions implemented in the kernel and find out the address
loaded onto the memory. Functions related to system call refers
to the kernel functions that construct a function call graph of the
entry function that can be executed when the system call is called.
We generate the list of system call related functions as following:
1) Extracting system call entry list. To get the names of sys-
tem call’s entry functions, we use the arch/x86/entry/syscalls/syscall
_64.tbl, which manages system calls, from the Linux source code.
2) Extracting system call entry function’s address. We use
System.map, which contains kernel image symbols and correspond-
ing addresses, to find the kernel memory address of the entry func-
tion of the system call from the loaded kernel image. Since Sys-
tem.map also contains functions that cannot be called through a
system call (i.e., not a system call related), we get the address of
entry functions obtained in 1) and collect other system call related
functions by the following steps.
3) Generating function call graph. To get all of the system
call related functions, we create a function call graph (FCG) for
each entry functions obtained in 2). We generate the FCG from the
Figure 2: System Architecture
vmlinux, a Linux kernel image, which can be obtained by decom-
pressing the vmlinuz. We use Radare2 [1] to generate a FCG.