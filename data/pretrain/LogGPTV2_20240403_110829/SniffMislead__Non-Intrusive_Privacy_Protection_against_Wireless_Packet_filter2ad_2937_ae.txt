Fall asleep
Wake up
Cooking
Toilet use
Bathing
Getting dressed
Working
0
99
98
95
96
91
92
94
95
94
1
54
54
51
53
45
43
48
39
46
2
31
34
32
30
27
29
30
30
29
3
26
28
25
25
16
28
20
22
20
4
23
26
24
22
12
15
17
14
16
5
17
18
20
18
11
9
10
8
10
6
10
11
11
11
8
9
8
7
8
7
8
7
6
6
4
4
6
5
5
8
6
5
4
3
2
2
4
3
3
Figure 7: Evaluation results of SniffMislead with differ-
ent number of phantom users. The x-axis shows number of
phantom users. The left y-axis shows the average accuracy
of correctly inferring real user behaviors. The right y-axis
shows the increase of CPU and RAM usage, compared with
the case when there is no phantom user.
8.1 Efficiency of Privacy Protection
In our experiment, SniffMislead is used to simulate phantom
users, starting from one user incrementally. We play the role of an
attacker, using the two detectors to infer device events and user
behaviors, and the filters to discard injected decoy packets and
events (both discussed in Section 7.3).
Table 1 shows the evaluation results of inferring some device
events. The recall of the device event inference is the ratio of suc-
cessful inferred events to all triggered events. The precision of
device event inference is the ratio of correctly-inferred events to all
43RAID ’21, October 6–8, 2021, San Sebastian, Spain
Xuanyu Liu, Qiang Zeng and Xiaojiang Du, et al.
inferred events. The F1 score is simply the harmonic mean of pre-
cision and recall. There are no noticeable differences in the recall,
precision, or F1 score, between real and decoy packets, meaning
that an attacker would recognize the injected packets as expected
device events of real users. These decoy events would “change”
device states, from the attacker’s perspective, causing the attacker
to infer wrong device states. However, it needs to be emphasized
that SniffMislead can not always prevent attackers from inferring
correct device states as a decoy event sometimes lets the device
be “in” its real state (e.g., three successive events: (real) ON → (de-
coy) OFF → (decoy) ON). We measure the percentage of cases when
the attacker knows a device’s state correctly with the existence of
SniffMislead. The percentage tends to be 1
k , and k is the number
of mutually-exclusive states of a smart device, during the long-run
period. For instance, a light has two mutually-exclusive states (i.e.,
ON and OFF), and the attacker can only infer its state for 50% of the
time, which is not better than a blind guess.
Table 2 shows the evaluation results of inferring nine typical user
behaviors, with different numbers of phantom users. The precision
of behavior inference is the ratio of correctly-inferred real user
behaviors to all behaviors of the same type caused by real users.
The average precision is calculated to indicate the effectiveness
of SniffMislead simulating different number of phantom users.
As shown in Figure 7, the average precision of the behavior in-
ference decreases as the number of phantom users increases. We
find that using eight phantom users is very effective in our testbed,
undermining a wireless sniffing attacker’s capability of behavior
inferences from 94.8% to 3.5%, also less than λ. When attackers
have lots of behavior inferring errors, user privacy is protected.
In our experimental environment, on average, each day, the real
user generates about 30 behaviors while our system approximately
injects 240 fake behaviors (in the case of 8 phantom users), and
only one real-user behavior is correctly inferred.
We design SniffMislead as a much more advanced solution
than random event injection, which is an intuitive solution that uses
random noise to hide real events. We perform micro-benchmark
experiments to evaluate random event injection against an attacker.
We modify killerbee [48] to randomly generate device events for the
target smart home and use TelosB Dongle [60] to inject correspond-
ing packets. Without the filters, random event injection seemed
to have some effect. The average accuracy of inferring real user
behaviors decreases by 52% because methods like HMM detectors
only care about the current states of devices, and randomly injected
events can change device states to some extent. However, they are
still less efficient than SniffMislead. With the existence of the
filters, the efficiency of random event injection becomes even worse.
Results show that around 76% of random events are discarded. After
that, we use the HMM detector and obtain an average accuracy
of 93%, implying that random event injection could hardly protect
user privacy. This is because many randomly injected decoy events
could not change the home context (i.e., they cannot “change” what
a real user is doing) or they suffer from logical errors. On the con-
trary, only less than 0.05% decoy events injected by SniffMislead
are discarded, i.e., SniffMislead still works well facing such filters.
To sum up, SniffMislead is a much more robust solution than
straightforward and intuitive methods (e.g., random event injection).
In our experiment, SniffMislead can defend against attackers who
use sniffers to analyze packet-level signatures of wireless pack-
ets and infer device states and user behaviors. SniffMislead can
protect user privacy at both device-state and user-behavior levels.
8.2 Overhead and Influence to Smart Home
Injected packets may cause network latency or performance over-
head to the smart home infrastructure, because those packets may
need to be filtered out by smart devices. Since the SmartThings Hub
is close-sourced, we can not measure the overhead directly. Instead,
we use a Raspberry Pi 3B and deploy it with OpenHub [58], to sim-
ulate the network functions of SmartThings Hub, as injected decoy
packets are filtered at the network level. The CPU and RAM usage
of the Raspberry Pi 3B are recorded every second, with and with-
out SniffMislead, with different numbers of phantom users. The
average usage of CPU and RAM is calculated to show the overhead.
Figure 7 gives the evaluation results. The CPU overhead ranges
from 0.1% to 0.4%, and the RAM overhead ranges from 0.3% to 0.45%.
Both overheads are small and acceptable. With more phantom users
simulated, the overhead increases, which is reasonable.
SniffMislead has a very small impact on the power consump-
tion of battery-operated devices. First, ZigBee end devices that are
powered by batteries are not designed to be awakened by RF sig-
nals. Instead, they use periodic polling and stay in the sleep mode
otherwise [47]. It means that our injected packets do not wake up
the device and hence do not increase the RF power consumption.
Second, we have a detailed experiment on a Raspberry Pi 3B as
for the computing power consumption. The injected packets only
increase the CPU usage by 0.4%. Lastly, SniffMislead only injects
packets when needed. Compared with other defenses, such as con-
tinuously injecting a lot of packets randomly, SniffMislead has
its strength.
SniffMislead achieves its goals by injecting decoy packets.
People may worry if those injected packets could have side ef-
fects, such as accidental device state changes or network latency
to their smart home. Actually, SniffMislead causes no security
violation. IoT protocols are usually designed to drop invalid pack-
ets [24, 30, 63] (e.g., to prevent a replay attack or message spoofing).
Using SniffMislead, payloads of injected packets are meaningless.
Also, SniffMislead only injects packets when needed, avoiding
unnecessary packet injections. To detect if there are possible device
state errors caused by SniffMislead, we develop a smart app and
install it in the SmartThings platform in our testbed, which is used
to monitor smart devices’ state changes. Each time packets of a
decoy event are injected, the current states of devices are checked
to detect any unexpected state change. Our experimental results
show that the injected packets cause no device state errors. The
timestamps of device events available in the SmartThings console
are used to calculate the latency of events. In two settings: whether
SniffMislead is deployed or not, the average latency of each event
shows no significant difference. Moreover, according to the feed-
back from the user involved in our experiment, no noticeable delay
was experienced. All the above shows that SniffMislead runs in a
secure and non-intrusive manner, and causes no side effects to the
target smart home and the users.
44SniffMislead: Non-Intrusive Privacy Protection against Wireless Packet Sniffers in Smart Homes
RAID ’21, October 6–8, 2021, San Sebastian, Spain
9 DISCUSSION
9.1 Generality and Applicability
In our current work, we evaluate SniffMislead in the SmartThings
platform with ZigBee devices. All the functions of SniffMislead
are only based on the network traffic patterns of the target smart
home, having nothing to do with specific platforms or protocols.
With some modifications, SniffMislead can be applied to other
smart home platforms and devices using other network proto-
cols. Most IoT devices in a smart home environment are power-
constrained, and the employed wireless protocols are lightweight
(e.g., Z-Wave, ZigBee, BLE, and WiFi). These lightweight proto-
cols, which are typically designed for low transmission rate and
reduced data redundancy for low power consumption, containing
packet-level signatures.
In this work, we mainly consider wireless packet sniffers. We do
not consider other types of attackers, such as Wide Area Network
(WAN) sniffers [64], which target outbound traffic between a home
router and an Internet Service Provider (ISP) network. However,
SniffMislead can be modified to defend against WAN sniffers. The
idea of injecting packets into a wired network to simulate phantom
users would still work, e.g., the home router can be modified to run
the function of SniffMislead.
Side-channel information leakage of encrypted wireless network
traffic has its beneficial use; for example, it enables detection of
misbehaving smart apps [79]. A concern is that SniffMislead’s
injected packets may decrease this kind of security tool’s detection
accuracy. One solution is that SniffMislead gets integrated with
these security tools, which thus knows which packets are injected
by SniffMislead.
Another potential limitation of SniffMislead is that an attacker
may try to identify packets injected by SniffMislead using wire-
less channel characteristics, e.g., received signal strength indicator
(RSSI) and channel-state information (CSI).
The literature (e.g., [78]) shows localization based on RSSI does
not perform well when the receiver is placed in a room different
from that contains IoT devices and SniffMislead. Moreover, RSSI-
based localization is considered inaccurate, particularly in indoor
environments [76]. We can defeat RSSI-based localization by placing
a SniffMislead instance in each room. An instance only injects
packets for devices in the same room (i.e., presumably devices with
strong RSSI), so the attacker cannot distinguish a SniffMislead
instance from other IoT devices. A detailed study of this aspect will
be our future work.
An attacker who has control of a device for collecting CSI is able
to perform more precise localization and thus can distinguish be-
tween packets from SniffMislead and those from real IoT devices.
The threat model of this work (Section 3.1) is mainly concerned
with a remote attacker who sniffs packets based on a compromised
IoT device at the target home. Note that collecting CSI requires a
special network interface card (NIC) [75], and most IoT devices do
not have this kind of NIC.
A local attacker who can physically place a device with a spe-
cial NIC very close the target home can collect CSI, and in this
case SniffMislead will fail, which we admit as a limitation. To
successfully launch this attack, the attacker needs to be physically
very close to the target home and place a device near the home.
The attacker takes risks because he may be captured by the home’s
security camera or doorbell camera.
On the other hand, SniffMislead still has its values, as it can
defeat most remote attackers, who can harvest privacy-sensitive