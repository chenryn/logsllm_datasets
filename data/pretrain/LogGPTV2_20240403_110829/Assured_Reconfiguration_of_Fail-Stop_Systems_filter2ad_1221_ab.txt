We state here the primary assumptions we make on
system requirements. These assumptions are those nec-
essary for our architecture to be applicable to a system;
additional  assumptions  made  for  simplicity  are
addressed as needed throughout the rest of the paper.
First,  we  assume  that  a  system  is  synchronous  and
made  up  of  a  set  of  applications  Apps  =  {a1, a2,  ...,
am}, which may run on an arbitrary processor configu-
ration,  and  which  may  interact.  Each  ai  in  Apps  pos-
sesses  a  set  of  possible  functional  specifications  Si  =
{si1, si2,  ...,  sin}  and  always  operates  in  accordance
with  one  of  those  specifications  unless  engaged  in
reconfiguration.  Any  functional  dependencies  among
the applications in Apps must be acyclic.
Second,  we  assume  that  it  is  possible  to  know  in
advance  all  of  the  desired  potential  system  configura-
tions  C  =  {c1,  c2,  ...,  cp}  and  how  to  choose  between
them. The system will have at least one “safe” configu-
ration,  which  is  built  with  high  enough  dependability
that failures at the rate anticipated for the safe configu-
ration do not compromise system dependability goals.
Third,  we  assume  that  system  function  can  be
restricted while the system is reconfigured. We discuss
time bounds on function restriction in section 5.3.
Finally, we assume fail-stop computers and standard
hardware error detection (and, in some cases, masking)
mechanisms for other system elements. We assume the
existence of a reconfiguration trigger; the source of the
trigger  might  be  a  hardware  failure,  a  software  func-
tional failure, the failure of software to meet its timing
constraints,  or  a  change  in  the  external  environment
that necessitates reconfiguration but involves no failure
at  all.  We  do  not  address  error  detection  mechanisms
for any system component.
5. Fail-stop processors and fail-stop 
processes
Fundamental to the thesis of this paper is that com-
ponent  failure  occurs  in  safety-critical  systems  and
need not be masked, provided the system can be made
reconfigurable. To have confidence in the function and
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:09:48 UTC from IEEE Xplore.  Restrictions apply. 
dependability  of  a  reconfigurable  architecture,  com-
plete definitions of the failure semantics of all compo-
nents  that  are  expected  to  fail  must  be  provided.  The
most  desirable  semantics  are  those  referred  to  as  fail-
stop. In this section, we review the concept underlying
fail-stop  processors,  discuss  their  use,  and  summarize
our approach to reconfiguration using them.
5.1 Fail-stop processors
Schlichting and Schneider define a fail-stop proces-
sor as consisting of one or more processing units, vola-
tile  storage,  and  stable  storage [8].  A  fail-stop
processor’s failure semantics can be summarized as:
• The processor stops executing at the end of the last
instruction that it completed successfully.
• The contents of volatile storage are lost, but the con-
tents of stable storage are preserved.
An  embedded  system  of  the  type  discussed  in  this
paper is made up of a collection of fail-stop processors.
If one processor fails, the others poll its stable storage
to find out what state it was in when it failed. If neces-
sary, the system then reconfigures to meet its reconfig-
uration  specification.  In  a  system  where  faults  are
masked (as is assumed by Schlichting and Schneider),
there must be sufficient equipment available to provide
full  service  if  the  anticipated  number  of  component
failures  occurs  during  the  maximum  planned  mission
time. The total number of required components is thus
the sum of the maximum number expected to fail dur-
ing  the  longest  planned  mission  and  the  minimum
number  needed  to  provide  full  service.  Though  not
impossible,  loss  of  the  maximum  number  expected  to
fail is an extremely unlikely occurrence. Thus, the vast
majority of the time, the system will be operating with
far more computing resources than it needs.
With the approach we advocate, the total number of
required components is the sum of the maximum num-
ber expected to fail during the longest planned mission
and the minimum number needed to provide the most
basic form of safe service. If the system were designed
so that this number equals the number of components
needed  to  provide  full  service,  then,  during  routine
operation (i.e., the vast majority of the time), the sys-
tem would operate with no excess equipment. Even if
some  system  functions  do  not  meet  the  assumptions
listed  in  the  previous  section,  failures  of  those  func-
tions can  be masked, while  failures in other functions
can trigger a reconfiguration. Reconfiguration in place
of masking, or the combination of reconfiguration with
masking, saves power, weight, and space.
5.2 Software considerations in fail-stop 
processors
Schlichting and Schneider introduced the concept of
a fault-tolerant  action  (FTA)  as  a  building  block  for
programming  systems  of  fail-stop  processors.  Briefly,
an  FTA  is  a  software  operation  that  either:  (1)  com-
pletes  a  correctly-executed  action  A  on  a  functioning
processor;  or  (2)  experiences  a  hardware  failure  that
precludes  the  completion  of  A  and,  when  restarted  on
another  processor,  completes  a  specified  recovery
action R. Thus, an FTA is composed of either a single
action, or an action and a number of recoveries equal to
the  number  of  failures  experienced  during  the  FTA’s
execution.  Using  FTAs,  Schlichting  and  Schneider
show  how  application  software  can  be  constructed  so
as to mask the functional effects of a fail-stop proces-
sor failure and how proofs can be constructed to show
that state is properly maintained.
In the original framework, a recovery protocol may
complete only the original action, either by restarting it
or by some alternative means. Our framework takes a
broader view of the recovery protocol, where R might
be the reconfiguration of the system so that the next A
will  complete  some  useful  but  different  function.  An
FTA  in  our  framework,  then,  leaves  the  system  either
having carried out the function requested, or having put
itself  into  a  state  where  the  next  action  can  carry  out
some suitable but possibly different function.
In  the  approach  presented  here,  the  basic  software
building block is a reconfigurable application. Where
the meaning is clear, we refer to a reconfigurable appli-
cation as an application in the remainder of this paper.
An  application  has  a  predetermined  set  of  specifica-
tions with which it can comply and, correspondingly, a
predetermined  set  of  fault-tolerant  actions  that  are
appropriate  under  each  specification.  Which  recovery
protocol  is  appropriate  for  use  when  an  application
fails, however, cannot be determined by the application
alone since the application’s function exists in a system
context. Furthermore, applications may depend on one
another,  so  that  the  initial  failure  of  an  action  in  one
application  could  lead  to  the  failure  of  an  action  in
another application. This issue did not arise in the pre-
vious formulation of fail stop since failures were com-
pletely masked; with the possibility of reconfiguration,
however, a distinction must be drawn between applica-
tion FTAs (AFTAs) and system FTAs (SFTAs).
An AFTA is an action encompassing a single unit of
work  for  an  individual  application.  An  SFTA  is  com-
posed of a set of AFTAs. Because of system synchrony,
there is some time span in which each application will
have executed a fixed number of AFTAs. The AFTAs
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:09:48 UTC from IEEE Xplore.  Restrictions apply. 
that  are  executed  during  that  time  span  make  up  the
SFTA.  If  an  application  experiences  a  failure  but
recovers  from  that  failure  without  affecting  any  other
applications, then the SFTA includes that application’s
action and subsequent recovery, as well as the standard
AFTAs for the other applications.
Because an application failure can affect other appli-
cations,  some  mechanism  for  determining  what  other
application reconfigurations are necessary to complete
an SFTA is required. It is for this purpose that we intro-
duce the System Control Reconfiguration Analysis and
Management  (SCRAM)  kernel.  Possible  configura-
tions to which the system might move to complete its
SFTA are statically defined as set of valid system tran-
sitions  and  a  function  to  determine  which  transitions
must be taken under each possible set of operating cir-
cumstances. The SCRAM signals the remaining appli-
cations to effect the appropriate reconfiguration.
A  software  system  composed  of  reconfigurable
applications  can  be  reconfigured  to  meet  a  given  sys-
tem specification, provided appropriate configurations
exist  for  all  the  applications.  Transition  existence  can
be guaranteed in a straightforward way by including a
coverage  requirement  over  environmental  transitions,
potential failures, and permissible reconfigurations.
Applications  lost  due  to  a  processor  failure  are
known to have been lost because of the static associa-
tion of applications to processors. We assume nothing
about the state of an application when it fails.
5.3 Real-time behavior of fail-stop software
We  define  a  reconfigurable  application  to  have  the
following informal properties:
• The  application  responds  to  an  external  halt  signal
by  establishing  a  prescribed  postcondition  and  halt-
ing in bounded time.
• The application responds to an external reconfigura-
tion  signal  by  establishing  the  precondition  neces-
sary for the new configuration in bounded time.
• The  application  responds  to  an  external  start  signal
by starting operation in whatever configuration it has
been assigned in bounded time.
We model time at the system level by associating uni-
form  timing  bounds  with  each  stage  of  each  AFTA.
Because  of  the  precise  semantics  of  an  SFTA,  timing
guarantees  can  be  given  for  SFTAs  based  on  the
bounds provided for AFTAs for a reconfiguration that
is able to complete with no intervening failures.
While Schlichting and Schneider’s work includes a
discussion  of  system  temporal  properties  in  the  event
of  multiple  successive  failures,  including  how  one
might guarantee liveness, we extend the framework to
cover  reconfiguration  timing  for  systems  that  must
operate in hard real time. Any failures that occur dur-
ing reconfiguration can be either (1) addressed imme-
diately  by  ensuring  the  applications  have  met  their
postconditions  and  choosing  a  different target  specifi-
cation;  or  (2)  buffered  until  the  next  stable  storage
commit  of  other  applications,  depending  on  system
requirements. In the worst case, each failure cannot be
dealt with until the end of the current reconfiguration.
In this case, the longest restriction of system function is
equal  to  the  sum  of  the  maximum  time  allowed
between  each  reconfiguration  in  the  longest  chain  of
transitions  to  some  safe  system  configuration  Cs.  In
other words, for the longest configuration chain C1, C2,
...,  Cs,  the  maximum  restriction  time  is (cid:54)i=2 to s Ti-1, i,
where Ti, j is the maximum time to transition from Ci to
Cj. This time can be reduced in various ways, such as
interposing  a  safe  configuration  Cs  in  between  any
transition between two unsafe configurations. With this
addition, the new maximum time over all possible sys-
tem transitions Ci (cid:111) Cj would be max{Ti, s}.
One caveat of this formula is that cyclic reconfigura-
tion  is  possible  due  to  repeated  failure  and  repair  or
rapidly-changing environmental conditions, and in this
case the time to reconfigure could be infinite. Potential
cycles can be detected through a static analysis of per-
missible transitions. They can be dealt with by forcing
a check that the system has been functional for the nec-
essary amount of time (in a safe configuration, or in a
configuration  appropriate  to  all  environmental  condi-
tions) before a subsequent reconfiguration takes place.
6. Formal model
The above discussion gives an overview of how we
have  extended  Schlichting  and  Schneider’s  work  to
support reconfiguration, but, as an informal discussion,
it lacks the rigor necessary for assurance of dependable
systems. To provide this assurance, we have created an
assurance  argument  that  is  an  extension  of  that  pre-
sented in our previous work [10]. The assurance argu-
ment includes: (1) a formal model of a reconfigurable
system  architecture;  (2)  a  set  of  formal  properties,
stated as putative theorems over the model, that we use
as  our  definition  of  system  reconfiguration;  and  (3)
proofs of the theorems—which constitute a proof that
the architecture satisfies the definition. With this verifi-
cation framework in place, we know that any instance
of that architecture will be a valid instance of a recon-
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:09:48 UTC from IEEE Xplore.  Restrictions apply. 
figurable system as long as the proof obligations gener-