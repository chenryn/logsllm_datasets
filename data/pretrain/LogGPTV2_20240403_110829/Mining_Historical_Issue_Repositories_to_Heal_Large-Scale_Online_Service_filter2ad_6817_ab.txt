Weak-discrimination phenomenon. Some events are
noisy, being weakly-discriminating events, whose ap-
pearance is independent of the transaction status (i.e.,
issue state or compliant state). Examples of such events
are a and z (in Figures 1 and 3) for indicating enter-
ing and leaving actions for each transaction instance,
respectively. These events appear in almost every trans-
action instance. Log messages corresponding to these
events contribute little to distinguish different types of
issues. Thus, due to such weakly-discriminating events,
retrieved historical issues for the given new issue may
not be desirable. For example, assume that another
different issue from the historical issue repository is
dominated by events a, b, d, y2, and z where “y2” is
related to “antivirus timeout”. If we do not address such
phenomenon, we would wrongly retrieve this historical
issue for the given issue related to SQL exception (since
the only difference of events for these two issues is “y1”
vs. “y2”.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. 
III. APPROACH
Our approach consists of three steps. First, we use
concept analysis and contrast analysis to generate the
signature for an issue. Second, we retrieve historical
issues similar to the given new issue from an issue
repository based on their generated signatures. Third,
we produce healing suggestions by adapting the healing
actions of the retrieved historical issues.
A. Signature Generation
Our approach includes
the techniques of con-
cept analysis and contrast analysis to address high-
correlation and weak-discrimination phenomena. Con-
cept analysis applies Formal Concept Analysis (FCA)
to group highly-correlated events together as the in-
tent of a concept. Contrast analysis calculates Mutual
Information to measure the correlation between each
concept and its corresponding transaction status, and
then evaluates the complementary set of intents between
parent and child concepts in concept lattice by measur-
ing their Delta Mutual Information (DMI). We generate
the signature for the issue as the complementary sets
that satisfy the predeﬁned criterion.
1) Concept Analysis: In our problem, each transac-
tion instance corresponds to an event sequence. How-
ever, we ignore the information of temporal ordering
and event-recurrence count, and use an event set to
represent
to each transaction instance. Although the
information of temporal order and event-recurrence
could indicates particular failure characteristic (e.g.,
race-condition, and iterating in a loop, respectively),
service issues relate to such information are very rarely
appeared in practice. So our simpliﬁcation improves
efﬁciency, while preserve enough effectiveness. Then,
we group together highly-correlated events by apply-
ing FCA. The intuition is that highly-correlated events
together indicate one kind of symptom. FCA is a prin-
cipled way to automatically group such events together
[13].
Figure 4 illustrates two concept nodes from the
concept lattice, which is constructed from the logs in
Figure 3. The gray node in the middle of Figure 4 is
“ﬁle-editing” + “ﬁle-reading”, which is the parent to the
gray node in the bottom. More precisely, each concept
c contains a set of events, called the intent, denoted
by Int(c). The intent of a parent node always belongs
to the intent of its child (note that according to FCA
theory, the parent-child relationship is constructed by
such partial-order relation). In addition, the extent of
each concept is a set of transaction instances, denoted by
Ext(c). According to FCA theory, the event set belongs
to each transaction instance in Ext(c) shares the same
Int(c).
314314314
^D E ]`
)((+ :6.4 
^D E ] [ a [4`
)+:6
^D E F G H ]`
)4 :6.41 
0XWXDO,QIRUPDWLRQ
0 +
^\ '0,  0(0 4`
3DUHQW1RGH
^D E F G H ] \`
)4 :6
0XWXDO,QIRUPDWLRQ
0( 
&KLOG1RGH
Figure 4. Relationship between two linked concepts in the lattice
Table I
JOINT DISTRIBUTION OF Xc, Y
Xc = 1
Xc = 0
Y = 1
Y = 0
n − x m − y
x
y
2) Contrast Analysis: By leveraging the fail/success
information of each transaction instance and the rela-
tionship between parent and child concepts, contrast
analysis ﬁnds the subset of the events that are highly
correlated to failed transaction instances. We next give
a deﬁnition about the fail/success label for a transaction
instance, and then present our considerations about
positive correlation and delta mutual information.
Fail/success label. We deﬁne the label for each
transaction instance (reﬂecting the transaction status) as
(cid:2)
f ailure, HttpStatusi ≥ 500
success,
otherwise
labeli =
where i denotes the index of a speciﬁc transaction
instance. Note that, although we use such speciﬁc
deﬁnition in our problem, it can be ﬂexibly and easily
modiﬁed according to the different requirements of
different scenarios.
Positive correlation. We calculate mutual informa-
tion to measure the correlation between a concept and
failures.
Let x and y be the number of failed and succeeded
transaction instances for a given concept c, respectively;
let n and m be the total number of failed and succeeded
transaction instances within the occurring period of a
given new issue, respectively. Then we deﬁne a random
variable Y , which indicates the outcome (1 refers to
fail, and 0 refers to success) of a randomly selected
transaction instance; and another random variable Xc,
which indicates the outcome of a randomly selected
transaction instance belongs to Ext(c).
Then the outcomes x, y, n, m can approximately
represent the joint distribution of Xc and Y as illustrated
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. 
in Table I. In our approach, we adapt the formula of
mutual information as below (by dropping the ,
 items):
M (Xc, Y ) = P (Xc = 1, Y = 1) log
P (Xc = 1, Y = 1)
P (Xc = 1)P (Y = 1)
+P (Xc = 0, Y = 0) log
P (Xc = 0, Y = 0)
P (Xc = 0)P (Y = 0)
Thus we use only the positive correlation part of
mutual information. In general, the negative correlation
( ,  items) happens trivially often in
network traces and are not meaningful [6].
Delta information. To achieve accurate retrieval, we
need to exclude noisy events and keep only “clean”
events. For example, in Figure 4, the mutual information
of the child node is high, but the events {a, b, c, d, e, z}
that it contains are irrelevant to the failures, and should
be eliminated. To address this problem, we analyze
Delta Mutual Information (DMI) between child and
parent concept nodes in the concept lattice, to measure
how the delta events contribute to correlation.
Let (cid:3)Es = Int(chi) \ Int(par) be the extra events
the child node has, e.g., (cid:3)Es being {y1} in
that
Figure 4. Then we deﬁne
DM I((cid:3)Es) = M (Xchild, Y ) − M (Xparent, Y )
Intuitively, DM I((cid:3)Es) represents the contribution
of the extra events (cid:3)Es for failure correlation. By
walking through each edge in the concept lattice graph,
we select (cid:3)Es as a term if it satisﬁes criteriaX:
(cid:2)
M (XInt(par), Y ) > 0
DM I((cid:3)Es) > 0
criteriaX =
∂M
Intuitively, the ﬁrst inequality indicates there exists a
positive correlation between a concept par and failure,
and the second inequality indicates there exists ”more”
failure-correlation due to the extra events that the child
node contains. In addition, Such deﬁnition of term
has a number of important properties. The theorem
below brings a bridge between our criteria and human’s
intuition when diagnosing the service issues.
∂x (cid:3)x + ∂M
∂y (cid:3)y where
Theorem DM I((cid:3)Es) ≈ ∂M
∂x > 0 and ∂M
Intuitively, let (cid:3)Es be a set of events which satisfy
criteriaX, then the higher value of the DM I((cid:3)Es)
means that events in “(cid:3)Es appear more probably
(higher value of ∂M
in failed requests, and less
∂x )
probably (lower value of ∂M
∂y ) in succeeded requests
as well”. We do not give the detailed proof in this
paper due to space limit. Readers can refer to our
project website [7] for the theorem and detailed proof.
This property also inspires us for developing further
similarity measurement.
∂y  |criteriaX = true}
B. Similar-Issue Retrieval
In similar-issue retrieval, we ﬁrst need to have a
representation for issues and then deﬁne a similarity
to measure issue similarity so that the most similar
issue for the given new issue could be retrieved. We
implement
the term-weighting and document-scoring
function of Generalized Variable kernel Similarity Met-
ric (GVSM [8]) to measure the deﬁned similarity metric.
1) Issue Representing: We treat each issue in the his-
torical issue repository as one document, each signature
as a set of terms, and DM I as the weight of each term.
Let D = {d1, d2, ..., dm} be the total m documents in
the issue repository. Consider the given new issue as
a query, denoted as q. So we represent each document
wip (cid:2)tp, where a term is represented by an
di as
(cid:3)
p∈A(i)
abstract vector (cid:2)tp, p is the index of the corresponding
term in di, A(i) is the valid index set, and wip is the
weight of (cid:2)tp. We use DM I as the weight for each
term. Such weight is much different from the TF-IDF
weight [9]. Our evaluations (Section IV) compare the
results of such difference.
2) Similarity Metric: We calculate the cosine score
of two document vectors, each representing one issue. In
particular, given a documents di that di =
wip (cid:2)tp.
(cid:3)
p∈A(i)
We next deﬁne the similarity metric
(cid:3)
sim(di, dj) =
di · dj
(cid:5)di(cid:5)(cid:5)dj(cid:5) =
p∈A(i),q∈A(j) wipwjq (cid:2)tp · (cid:2)tq
(cid:5)di(cid:5)(cid:5)dj(cid:5)
(cid:4)
The metric measures the cosine of
the angle be-
tween the two vectors. Here (cid:5)di(cid:5) =
di · dj. We
deﬁne inner product between two terms: (cid:2)tp · (cid:2)tq =
# of overlapped events in p-th term and q-th term.
We abandon the orthogonal assumption in the conven-
tional vector space model, since the orthogonal assump-
tion is too restrict (this assumption is also referred to as
exact-match: the inner product is equal to 1 if and only
if the two sets are exactly the same; otherwise, 0). We
aim to give a similarity score between 0–1 rather than
yes/no. We prove that our similarity metric satisﬁes the
requirements of GVSM, so our problem can be modeled
as a text retrieving problem, and we could leverage the
corresponding beneﬁts due to the properties of GVSM.
We do not give the detailed proofs here due to space
limit. The detailed deductions can be viewed at our
project website [7].
315315315
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. 
Table II
RULE-BASED MAPPING
CATEGORIES OF STUDIED HEALING ACTIONS
Table III
verb
reboot
recycle
restart
re-image
reboot
patch
restart
restart
restart
target
SQL(Database)
App-Pool (Application Pool)
IIS (Internet Information Service)
WFE (Web Front End)
WAC (Web Application)
Service (SQL/WFE/WAC)
Scanner (Anti-virus Component)
Search (Search Component)
AD (Active Directory)
event of location
ev1
ev2
ev2
ev2
ev3
ev3
ev4
ev1,ev2,ev3
ev2,ev3
C. Healing-Suggestion Adaptation
We use a triple structure 
to represent a healing action, and manually extract the
verb and target from the description of the historical
issue retrieved for the given new issue, and extract the
location from log messages of the given new issue. The
extracted healing actions are reasonably proper, since all
these issues are well-resolved, and the corresponding
healing actions have been veriﬁed according to the
incident management process from the product teams.
Based on empirical investigations of healing actions
for online service systems, we ﬁnd that most healing
actions can be formatted as HealingAction = verb +
target+location. A verb is an action, such as “reboot”
and “re-image” (re-image: to completely replace the op-
erating system with a pre-conﬁgured image). The major
types of verbs in our problem setting are illustrated in
Table II. A target represents a component or a service
role, such as an Internet Information Services (IIS) or a
database, as illustrated in Table II. A location is an exact
affected machine name with its physical location. When
we retrieve a similar historical issue for the given new
issue, we obtain “verb” and “target” from the historical
issue, e.g., from the description text “We found few
SQL servers with high memory usage and few servers
were not able to connect through . Availability is back
up after rebooting the SQL machine SQL32-003”, we
extract the verb as “reboot” and the target as “SQL”.
The combination of a verb and a target is not arbitrary;
Table II shows all the possible combinations according
to our study.
We extract the location (the speciﬁc machine names)
with a rule-based technique. The speciﬁc machine name
is typically mentioned in the log messages associated
with a ﬁxed set of events. For example, the log mes-
sage “Cannot connect to SQL server * ...” is always
associated with event ev1, so we ﬁnd event ev1 from
logs and then extract * from the log message as location
by using regular expression. The complete mapping is
illustrated in Table II.
Note that manually identifying an appropriate healing
action for the given new issue is typically non-trivial
since not only identifying an appropriate healing action
category ID
ID1
ID2
ID3
ID4
ID5
ID6
ID7
ID8
ID9
verb
recycle
reboot
restart
reboot
restart
re-image
patch
restart
restart
target
App-Pool
WAC
IIS
SQL
AD
WFE
Service
Scanner
Search
# of cases