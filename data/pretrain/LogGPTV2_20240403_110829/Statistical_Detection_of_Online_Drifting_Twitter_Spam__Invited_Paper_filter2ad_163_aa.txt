title:Statistical Detection of Online Drifting Twitter Spam: Invited Paper
author:Shigang Liu and
Jun Zhang and
Yang Xiang
Statistical Detection of Online Drifting Twitter Spam
[Invited Paper] 
Shigang Liu
School of Information
Technology
Deakin University
221 Burwood Hwy, Burwood,
PI:EMAIL
Vic 3125, Australia
Jun Zhang
School of Information
Technology
Deakin University
Yang Xiang
School of Information
Technology
Deakin University
221 Burwood Hwy, Burwood,
PI:EMAIL
Vic 3125, Australia
221 Burwood Hwy, Burwood,
PI:EMAIL
Vic 3125, Australia
ABSTRACT
Spam has become a critical problem in online social net-
works. This paper focuses on Twitter spam detection. Re-
cent research works focus on applying machine learning tech-
niques for Twitter spam detection, which make use of the
statistical features of tweets. We observe existing machine
learning based detection methods suﬀer from the problem
of Twitter spam drift, i.e., the statistical properties of spam
tweets vary over time. To avoid this problem, an eﬀective
solution is to train one twitter spam classiﬁer every day.
However, it faces a challenge of the small number of im-
balanced training data because labelling spam samples is
time-consuming. This paper proposes a new method to ad-
dress this challenge. The new method employs two new
techniques, fuzzy-based redistribution and asymmetric sam-
pling. We develop a fuzzy-based information decomposition
technique to re-distribute the spam class and generate more
spam samples. Moreover, an asymmetric sampling tech-
nique is proposed to re-balance the sizes of spam samples
and non-spam samples in the training data. Finally, we ap-
ply the ensemble technique to combine the spam classiﬁers
over two diﬀerent training sets. A number of experiments
are performed on a real-world 10-day ground-truth dataset
to evaluate the new method. Experiments results show that
the new method can signiﬁcantly improve the detection per-
formance for drifting Twitter spam.
Keywords
Twitter spam detection; social network security; security
data analytics
1.
INTRODUCTION
Spam detection is a curious game of cat and mouse, that
is, spammers are trying to mask themselves as legitimate
users while security companies want to stop spam [1]. Spam
has plagued every site. Among these sites, Twitter, which
was founded in 2006, is the fastest growing one. Nowadays,
over 400 million new tweets are produced over 200 million
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
ASIA CCS’16, May 30–June 3, 2016, Xi’an, China.
c(cid:13) 2016 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-4233-9/16/05. . . $15.00
DOI: http://dx.doi.org/10.1145/2897845.2897928
Twitter users every day [2]. Twitter is used to exchange
messages among friends. Unfortunately, spammers usually
use Twitter as a tool to post unsolicited messages that con-
tain malicious links, and even hijack trending topics.
In
this respect, the exponential growth of Twitter contributes
to the increase of online spamming activities. Study show
that more than 3% messages are most probably abused by
spammers [1].
To deal with the increasing threats from spammers, se-
curity companies, as well as Twitter itself, are combating
spammers to make Twitter a spam-free platform. For ex-
ample, a spam can be reported by clicking on the ‘report
as spam’ link in their home page on Twitter [3]. Twitter
also implements blacklist ﬁltering as a component in their
detection system called BotMaker [4]. However, due to time
lag, blacklist usually fails to protect victims from new spam
[5]. The research shows that more than 90% victims may
visit a new spam link before it is blocked by blacklists [2].
In order to address the limitations of blacklists, recently,
researchers proposed machine learning based methods that
regard spam detection as a binary classiﬁcation problem [6].
A number of statistical features, such as account age, num-
ber of followers or friends and number of characters in a
tweet, are extracted to characterise tweets. In conventional
supervised detection paradigm, a set of labelled spam and
non-spam sample tweets are prepared in advance for training
a classiﬁcation model. Afterwards, the classiﬁcation model
is applied to detect spam in the coming tweets. A number
of machine learning methods have been investigated in the
topic of Twitter spam detection [7].
However, we observe a critical problem from the real-world
Twitter data, named “twitter spam drift” [2], which seri-
ously aﬀects the detection performance of existing machine
learning-based methods. The problem is that Twitter spam
is drifting over time in the statistical feature space. Thus,
the classiﬁcation model that is trained of using old spam
samples cannot accurately recognise the drifted spam tweets.
Figure 1 reports the statistics about number of characters in
tweets in our experiment dataset. We can see that the num-
ber of characters in spam tweets changes quickly in the 10
days. Figure 2 shows the account age of tweets. The account
ages of spam tweets have signiﬁcant change in the 10 days.
Although researchers are working to detect spam, spammers
are also trying to avoid being detected. For example, spam-
mers could evade current detection features through posting
more tweets or even use adversarial machine learning strat-
egy to avoid being detected [8]. To address the problem of
twitter spam drift, an eﬀective solution is to train one twit-
1Figure 1: Number of characters in tweets
Figure 2: Account age of tweets
ter spam classiﬁer every day. However, it faces a challenge
of the small number of imbalanced training data because la-
belling spam samples is time-consuming. For example, if we
manually label 100 tweets, we could obtain 5 spam tweets
and 95 non-spam tweets. When a small number of imbal-
anced training data are used to train a classiﬁer, that will
cause the classiﬁer biased toward the non-spam class. The
spam detection performance will become poor.
In this work, we treat Twitter spam detection as a speciﬁc
machine learning problem with a small number of imbal-
anced training data. The major contributions of our work
are summarised as follows.
• We proposes a new detection method to address the
problem of twitter spam drift. The new method can
learn from a small number of imbalance training data
by employing two new techniques, fuzzy-based redis-
tribution and asymmetric sampling.
• We develop a new fuzzy-based re-distribution tech-
nique that applies information decomposition to gen-
erate more spam samples in line with the spam class
distribution.
• We develop a new asymmetric sampling technique to
re-balance the sizes of spam samples and non-spam
samples in the training data. Finally, the ensemble
technique is used to combine the twitter classiﬁers over
two diﬀerent training sets.
A number of experiments are performed on a real-world
10-day ground-truth dataset to evaluate the new method.
Experiments results show that the new method can signiﬁ-
cantly improve the detection performance for drifting Twit-
ter spam. The rest of this paper is organised as follows.
Section 2 presents a review on recent works of Twitter
spam detection. In Section 3, we describe the details of our
new spam detection method. The experiments and results
are reported in Section 4. Finally, Section 5 concludes this
work.
2. RELATED WORK
Recently, many researchers have applied various machine
learning techniques for Twitter spam detection [1], [11], [12].
This section gives a short review of related work from the
machine learning perspective.
Many works have been carried out to have a better un-
derstanding of the nature of Twitter spam. A study based
on a data sample back in 2009 [13] suggested that 3.75%
of tweets were spam.
In 2010, Grier et al. discussed the
URLs obtained from tweets’ data, and realized that 8% of
all crawled unique URLs were spam, which means 2 million
URLs out of 25 million were spam [5]. In 2011, Thomas et
al. reported that 80 million tweets out of 1.8 billion were
spam [14]. Moreover, Najada and Zhu analysed the spam de-
tection problem with spam samples takes 20% of the whole
dataset. Chao et al. collected and analysed tweets spam
over 600 million tweets with URLs and found that around
1% of URLs are spam [11].
Blacklist is commonly used method for the detection and
ﬁltering of spam messages. For example, our industry part-
ner, Trend Micro [15], oﬀers a blacklisting service based on
the Web Reputation Technology, which is able to ﬁlter harm-
ful spam URLs. Blacklist has a critical disadvantage that it
takes considerable time for the new malicious links to be in-
cluded in a blacklist. In real-world scenarios, many damages
should have been caused during the time lag [5].
Heuristic rule based methods are another earlier attempts
for ﬁltering Twitter spam to overcome the limitations of
blacklist. Yardi et al.
[16] introduced a #robotpickupline
(hashtag) for spam detection through three rules, which are
suspicious URL search, username pattern matching and key-
word detection. Kwak et al. [17] recommended that tweets
which contain more than three hashtags to be removed in
order to eliminate the impact of spam for their research.
It has been reported that the basic features used in the
above studies can be easily fabricated by purchasing fol-
lowers, posting more tweets, or mixing spam with normal
tweets. Accordingly, researchers proposed a number of ro-
Day1Day2Day3Day4Day5Day6Day7Day8Day9Day10Spam Tweets020406080100120140160Number of characters in tweetsDay1Day2Day3Day4Day7Day8Day9Day10Day5 Day6 Non-spam Tweets050100150200250Number of characters in tweetDay1Day2Day3Day4Day5Day6Day7Day8Day9Day10Spam Tweets05001000150020002500Account age (days)Day1Day2Day3Day4Day7Day8Day9Day10Day5 Day6 Non-spam Tweets05001000150020002500Account age (days)2Figure 3: New detection framework
bust features that rely on the social graph to avoid feature
fabrication. For example, Song et al. [22] have successfully
improved the performance of several classiﬁers to nearly 99%
True Positive and less than 1% False Positive by merging
these sophisticated features with the basic feature set. Yang
et al. [23] also proposed a few robust spam features, which
include Local Clustering Coeﬃ-cient, Betweenness Central-
ity and Bidirectional Links Ratio. Their research shows that
the new feature set can result in outstanding performance
compared with four existing works [12, 18, 19, 1].
Recently, more studies proposed to apply machine learn-
ing techniques for Twitter spam detection based on a range
of new features, including tweet-based, author-based, and
social graph based attributes [1]. Hamzah and Xingquan
[24] made use of URL based features such as Domain tokens
and path tokens, along with some features from the landing
page, DNS information and domain information. Chao et al.
[25] collected the spam relevant features such as URL, redi-
rect chain length, Relative number of diﬀerent initial URLs
etc. Wang et al.
[2] introduced Bayesian model based ap-
proach to detect spammers on Twitter. Benevenuto et al.
[12] proposed to detect both spammers and spam using the
Support Vector Machine algorithm. Stringhini et al.
[18]
trained a classiﬁer by using the Random Forest algorithm,
which was then used to detect spam in three social networks,
including Twitter, Face-book and MySpace. Lee et al. [19]
deployed some honeypots to derive the spammers’ proﬁles.
They extracted the statistical features for spam detection us-
ing several machine learning algorithms, such as Decorate,
RandomSubSpace and J48.
In our group’s previous work [2, 21], it is observed that
Twitter spams are drifting over time in the statistical feature
space. The problem is named “twitter spam drift”, which se-
riously aﬀects the detection performance of existing machine
learning-based methods. An eﬀective solution for detecting
drifted tweet spam is to train one twitter spam classiﬁer ev-
ery day, while it faces a challenge of the small number of
imbalanced training data. In this situation, the classiﬁers
for spam detection are most likely to be overwhelmed by
the non-spam class and ignore the spam class. For example,
assuming there are only 5% spam class samples and 95%
non-spam samples in a given dataset. If a classiﬁer classiﬁes
all the samples to the non-spam class, the classiﬁcation ac-
curacy would be 95%. However, this classiﬁer is not useful
in practice, because we are most interest in the spam class.
This challenge becomes the motivation of our work.
3. PROPOSED METHOD
This section presents a new detection method that em-
ploys a new fuzzy-based redistribution, a new asymmetric
sampling and the ensemble technique.
3.1 New Detection Framework
In this paper, we treat the detection of drifted spam tweets
as a speciﬁc learning problem with a small number of im-
balanced training data. The spam class is the minority class
and the non-spam class is the majority class. The size of
training data including labelled spam and non-spam sam-
ples is small for the binary classiﬁcation task.
Figure 3 shows the new framework for detecting drifted
spam tweets. In this framework, a new fuzzy-based distri-
bution technique is applied to extend the original training
dataset by creating synthetic spam samples. Then, we con-
duct asymmetric sampling on the two training datasets. In
order to balance the size of spam and non-spam, the new
asymmetric sampling technique applies the over-sampling
strategy to spam training tweets and the under-sampling
strategy to non-spam training tweets. Ensemble training is
combined with the asymmetric sampling to construct a set
of classiﬁers from each training dataset. Finally, two sets
of classiﬁers are combined to detect spam from the testing
tweets.
3.2 Fuzzy-Based Redistribution
To alleviate the imbalance between spam and non-spam
classes in the training data, we develop a new fuzzy-based re-
distribution algorithm. The fuzzy-based redistribution em-
ploys information decomposition, which is a new oversam-
pling technique proposed in our previous work [26] for class
imbalance issue, to generate reliable synthetic spam samples.
It takes the training spam set, S+, and the number of syn-
thetic spam samples to be generated, t, as input. As shown
in the Algorithm 1, there are three steps, small interval par-
tition, weights calculation and synthetic values generation.
Original Training TweetsFuzzy-based RedistributionExtended TrainingTweetsAsymmetricSamplingEnsembleTrainingClassifierCombinationAsymmetricSamplingEnsembleTrainingTesting TweetsSpam DetectionResults3Algorithm 1: Fuzzy-Based Redistribution
Algorithm 2: Asymmetric Sampling
1: INPUT: Minority data S+, number of synthetic samples to be
generated t.
2: OUTPUT: Re-distributed minority class samples: F ID(S+, t).
/*Initialization*/
3: for each column feature vector xi, do
4: According to formula (1) and (2), partition the feature vector-
based interval into t small intervals.
5: Calculate the weights using formula (3) from the observed data
to each intervals.
6: Calculate ˜msi using formula (4), ˜msi is the sth generated value
of xi.
7: end for
Given a set of labelled spam and non-spam tweets, S+
and S−. The spam class is denoted as,
S+ = (y1, ω+), (y2, ω+),··· , (yN , ω+),
where yn, n = 1, 2,··· , N , is a tweet sample. Let’s denote
xi = (x1i, x2i,··· , xN i)T , i = 1, 2,··· , M
as the set of the ith feature value for all tweets, where N
means the number of total spam samples, and M means the
number of total feature values for each sample. Then we can
obtain a value range of the i-th feature,
where
and
Ai = [ai, bi] ,
ai = min{xji|j = 1, 2,··· , m}
bi = max{xji|j = 1, 2,··· , m}.
To generate t synthetic spam samples, we divide the value
range [ai, bi] into t small intervals. These small intervals can
be expressed by
Asi = [ai + (s − 1) ∗ hi, ai + s ∗ hi), s = 1, 2,··· , t − 1, (1)
Ati = [ai + (t − 1) ∗ hi, ai + t ∗ hi],
where hi = (bi − ai)/t.
(2)
The synthetic spam samples are generated according to
the N labelled spam samples. The following map is used for
calculating the weights from the labelled spam samples to
each small interval Asi:
µ : xi × ui → [0, 1],
(xji, usi) → µ(xji, usi).
(cid:40)
where ui is called the discrete universe set of xi. We choose
a fuzzy membership µ(xi, uj) to perform the mapping.
if (cid:107) xji − usi(cid:107) ≤ hi
if (cid:107) xji − usi(cid:107) > hi
1 − (cid:107) xji−usi(cid:107)
µ(xji, usi) =
(3)
hi
0
where hi is called step length. The next equation is used to
create the sth synthetic value for xi:
(cid:40)
˜msi =
¯xi
(cid:80)m
(cid:80)m
j=1 mjsi
j=1 µ(xji,usi)